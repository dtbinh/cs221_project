journal of artificial intelligence research                  

submitted        published      

modeling the lifespan of discourse entities
with application to coreference resolution
marie catherine de marneffe

mcdm   ling   ohio   state   edu

linguistics department
the ohio state university
columbus  oh       usa

marta recasens

recasens   google   com

google inc 
mountain view  ca       usa

christopher potts

cgpotts   stanford   edu

linguistics department
stanford university
stanford  ca       usa

abstract
a discourse typically involves numerous entities  but few are mentioned more than once  distinguishing those that die out after just one mention  singleton  from those that lead longer lives
 coreferent  would dramatically simplify the hypothesis space for coreference resolution models 
leading to increased performance  to realize these gains  we build a classifier for predicting the
singleton coreferent distinction  the models feature representations synthesize linguistic insights
about the factors affecting discourse entity lifespans  especially negation  modality  and attitude
predication  with existing results about the benefits of surface  part of speech and n gram based 
features for coreference resolution  the model is effective in its own right  and the feature representations help to identify the anchor phrases in bridging anaphora as well  furthermore  incorporating
the model into two very different state of the art coreference resolution systems  one rule based and
the other learning based  yields significant performance improvements 

   introduction
karttunen imagined a text interpreting system designed to keep track of all the individuals  that is 
events  objects  etc   mentioned in the text and  for each individual  record whatever is said about it
 karttunen        p        he used the term discourse referent to describe these abstract individuals 
some discourse referents are easily mapped to specific entities in the world  as with most proper
names  others are indeterminate in the sense that they are compatible with many different real world
entities  as with indefinites like a train  in either case  discourse referents can enter into anaphoric
relations in discourse  even if we do not know exactly what real world object a train picks out in
we heard a train in the distance         we can nonetheless refer to it with subsequent pronouns and
ascribe properties to it        it had a loud horn  
not all discourse referents enjoy repeat appearances in the discourse  some lead long lives
and appear in a wide variety of discourse contexts  whereas others never escape their birthplaces 
dying out after just one mention  the central question of this paper is what factors influence the
lifespan of a discourse referent  we focus on noun phrases  which are the most direct identifiers
of discourse referents in english  more specifically  we seek to predict whether a given discourse
c
    
ai access foundation  all rights reserved 

fide

m arneffe   r ecasens   p otts

referent will be coreferent  mentioned multiple times in a given discourse  or singleton  mentioned
just once   the ability to make this distinction based on properties of the noun phrases used to
identify these referents  henceforth  mentions  would benefit coreference resolution models  by simplifying the hypothesis space they consider when predicting anaphoric links  and it could improve
performance on other tasks that require accurately tracking discourse entities  including textual entailment  delmonte  bristot  piccolino boniforti    tonelli        giampiccolo  magnini  dagan 
  dolan        and discourse coherence  hobbs        grosz  joshi    weinstein        kehler 
      barzilay   lapata        prasad  dinesh  lee  miltsakaki  robaldo  joshi    webber        
the existing literature provides numerous generalizations relevant to the singleton coreferent
distinction  it is known  for example  that the internal syntax and morphology of the phrase used
to establish the discourse referent provide important clues as to the lifespan of that referent  prince 
    a      b  wang  mccready    asher         information structuring is also important  certain
grammatical and discourse roles correlate with long lifespans  chafe        hobbs        walker 
joshi    prince        beaver         features based on these insights have long been integrated
into coreference resolution systems  our contribution is to explore the interaction of all of these
features with semantic operators like negation  modals  and attitude predicates  know  be certain 
wonder   such interactions were karttunens primary focus  karttunen               and they have
long dominated work on dynamic approaches to linguistic meaning  kamp        heim       
      roberts        groenendijk   stokhof        bittner         here  we highlight the importance of such interactions for predicting the lifespans of discourse referents in actual text 
our approach also capitalizes on the results of durrett and klein        and hall  durrett  and
klein        concerning the power of surface features for natural language processing  nlp 
tasks  those authors show that large sets of easily extracted part of speech  pos  and n grambased features can achieve results that are at least as good as those achieved with hand engineered
linguistic features  we therefore investigate the contribution of surface features for predicting the
lifespan of discourse entities  we find that surface features alone have substantial predictive value
for this task  but that adding more specialized linguistic features leads to reliable performance gains 
this suggests that some of the linguistic constraints relevant for lifespan prediction go beyond what
can be approximated with surface level information given available data 
the first step in our analysis is to bring the insights from linguistic theories together into a
single logistic regression model  the lifespan model  and assess their predictive power on real
data  we show that the linguistic features generally behave as the existing literature leads us to
expect  and that the model itself is effective at predicting whether a given mention is singleton or
coreferent  the second step is to bring in surface features to obtain a more predictive model  we then
provide an initial assessment of the engineering value of making the singleton coreferent distinction
by incorporating our lifespan model into two very different  state of the art coreference resolution
systems  the rule based stanford coreference system  lee  peirsman  chang  chambers  surdeanu 
  jurafsky        and the learning based berkeley coreference system  durrett   klein         for
both  adding our features results in a significant improvement in precision on the conll      and
conll      shared task data  across all the standardly used coreference resolution measures  and
we see reliable boosts in recall as well 
this article subsumes and extends the work of recasens  de marneffe  and potts         the
specific differences are as follows  first  freed of naacls tight space constraints  we provide a
much more in depth linguistic analysis of the various features in our lifespan model  and include
more details throughout  second  we examine the contribution of surface features to the lifespan
   

fim odeling the l ifespan of d iscourse e ntities

model  third  we assess the value of the lifespan model for predicting which phrases will act as
anchors in bridging anaphora  fourth  to give a fuller evaluation of the coreference applications
of our model  we incorporate our best lifespan model into a learning based system  the berkeley
coreference system   complementing our previous results on the rule based stanford coreference
system  fifth  we use the most recent version of the conll scorer  v      which includes results
according to blanc and fixes a bug that incorrectly boosted b  and ceaf scores by a few points 
sixth  we benefit from kummerfeld and kleins        error analysis tool to gain deeper insights
into the errors that our lifespan model helps with 

   linguistic insights
this section briefly summarizes previous research on anaphora resolution  discourse structure  and
discourse coherence in the linguistic literature  our goal is to obtain a clear picture of how the
lifespan of a discourse referent is shaped by features of its mentions  not only their local morphosyntactic features but also features of the syntactic and semantic environments in which they
occur  the insights we gather in this section inform the design of the feature extraction functions
in our lifespan model  section    and in turn shape our contributions to the stanford and berkeley
coreference systems  section    
karttunen        was primarily concerned with the ways in which the semantic scope of an
indefinite influences the lifespan of its associated discourse referent  in the three sentence discourse
     the indefinite an exam question in sentence   has text level scope  as a result  its associated
discourse referent is free to lead a long life  linking with a mention that is also at the text level
 sentence    and one that is embedded below negation  sentence    
   

kim read over an exam question  it was hard  he didnt understand it 

in contrast  as karttunen observed  if an indefinite is interpreted in the scope of negation  then
it is typically available for anaphoric reference inside that negative environment  as in      but not
outside of it  as in       we use   to mark discourses that are incoherent on the intended construal  
   

kim didnt understand an exam question even after reading it twice 

   

kim didnt understand an exam question    it was too hard 

of course      has a coherent construal on which an exam question is interpreted as taking widescope with respect to negation  there is a question kim didnt understand   such inverse scope
readings are often disfavored  but they become more salient when modifiers like certain and particular are included  fodor   sag        schwarzschild         or where the mention contains
a positive polarity item  that is  an item like some or tons of that resists scoping under negation
semantically  baker        israel              
   

kim didnt understand a particular exam question  she pondered it for hours to no avail 

   

kim didnt understand some exam question  she pondered it for hours to no avail 

conversely  using a negative polarity item  npi  like any inside the indefinite mention essentially ensures a narrow scope reading  ladusaw        israel         which leads to an impossibleto resolve anaphoric link for simple variants of     
   

kim didnt understand any exam question    it was too hard 
   

fide

m arneffe   r ecasens   p otts

the pattern karttunen saw in all this is that semantic scope and anaphoric potential are intimately related  a given mention can participate in anaphoric relationships within its scope  but not
outside of it  broadly speaking  this is familiar from quantificational binding in logical languages
 cresswell        and variable scope in the control structures of programming languages  muskens 
van benthem    visser         thus  an indefinite with text level scope has free reign  whereas one
inside the scope of an operator like negation is restricted to links that do not span the outer boundaries of that scopal environment  these are semantic generalizations that might not be directly
reflected in the surface syntax  but interpretive preferences and internal morphosyntactic features of
the mention can help to disambiguate the intended logical form 
karttunen        immediately generalized his observations about negation and discourse reference to modal auxiliaries and non factive attitude predicates like want and claim  the following are
based on his original examples 
   

bill can make a kite    it has a long string 

   

john wants to catch a fish    do you see it from here 

   

sandy claims that jesse bought a bicycle    it has a green frame 

as with negation  the pattern makes intuitive sense  bills abilities regarding kite construction do
not involve any specific kite  and hence the first sentence of     does not automatically establish the
right sort of discourse referent  similarly  wanting to catch a fish does not guarantee the salience  or
even existence  of a fish  and sandy might be so unreliable as a source that a bicycle has no status
outside of the semantic scope of claim 
all of        cohere if the indefinite is interpreted outside of the scope of the relevant semantic
operator  the relative preferences for surface and inverse scope are harder to characterize than they
were with negation  because they are influenced in complex ways by the semantics and pragmatics
of the attitude predicate  the reliability of the source of the information  and the nature of the conversational issues and goals  for example  if the speaker of     regards sandy as a reliable source
regarding jesses bike buying  then a bicycle will likely attain text level scope as a by product of
jesse bought a bicycle becoming a text level commitment  karttunen        discusses these patterns  observing that  in many contexts  pragmatic pressures encourage embedded content to become
elevated to the text level in this way  de marneffe  manning  and potts        study newspaper data
in which this is an extremely common pattern because the attitude verbs tend to function as evidential markers for the source of the embedded content  rooryck        simons         we will
see later that attitude predicates seem to encourage long lifespans in the ontonotes data too  the
majority of which is news like   arguably as a result of just these pragmatic factors 
we have so far restricted attention to anaphoric links in which an indefinite establishes a new
discourse referent and a pronoun refers to it  our observations carry over directly to links from indefinites to definite noun phrases  which linguistic theories treat roughly as pronouns with additional
descriptive content  for discussion  see the work of elbourne         other mention patterns tend to
be quite different  though  where discourse referents are established by definites or named entities 
the interactions with negation and other operators are simpler because definites and named entities
do not interact scopally with these operators  but see the work of aloni        for related issues
involving presupposition and intensionality   thus  such anaphoric connections are unconstrained
by the factors we have been discussing  conversely  truly quantified phrases like no student and every linguist are severely limited  not only by their interaction with other operators but also by their
   

fim odeling the l ifespan of d iscourse e ntities

own deficiencies when it comes to establishing discourse referents  there are cases in which these
expressions establish new discourse referents  but they seem to be infrequent and unusual  wang
et al         
cross cutting the above considerations are factors that have long been central to studies of coreference and anaphora within computational linguistics and nlp  for instance  animate nouns are
generally the most likely to lead long discourse lives  whereas mentions that refer to abstract objects like quantities  percentages  and other measures tend to be singleton  we assume that these
statistical patterns derive  not from narrow linguistic constraints  but rather from general cognitive
biases concerning how people conceptualize and discuss different kinds of objects  however  there
is evidence that these biases can make their way into the grammars of specific languages in the
form of morpho semantic phenomena like obviation  aissen        and differential object marking
 aissen        
the syntactic environment in which the phrases occur will also modulate their anaphoric potential and hence their lifespans  for example  prince      b  reports that semantically indefinite
phrases using this  as in there was this guy in the back row  are highly likely to be referred to in
a subsequent clause  similarly  chafe        shows that information structuring choices are also
predictive of whether a given noun phrase will serve as the antecedent for later referential devices 
there are also close correlations between being in a syntactic topic position and leading a long discourse life  grosz et al         beaver         for a focused evaluation of these ideas for handling
coreference  see the work of beaver        
we seek to incorporate all of the above observations into our lifespan model  there are additional patterns from the literature that we do not pursue  because they are too infrequent in our
data  for example  karttunen        also identified a natural class of counterexamples to his basic scope generalizations  certain sequences of intensional predicates support exceptional anaphoric
links  a phenomenon that was later studied systematically under the heading of modal subordination
 roberts              
    

frank wants to marry a rich linguist    she is kind 

    

frank wants to marry a rich linguist  she should be kind 

in addition  mentions inside parenthetical clauses are less likely to introduce long term discourse
referents  due to the likelihood that the parenthetical clause itself conveys only secondary content as
compared with the main clause that hosts it  potts         thus  while anaphoric links into and out
of parentheticals are possible  anderbois  brasoveanu    henderson        potts         they seem
to arise relatively rarely  a valuable piece of practical advice for appositive rich texts like scientific
papers but unfortunately not one we could put into action here 
karttunens observations helped set the agenda for dynamic approaches to semantics for the next
few decades  kamp        heim        groenendijk   stokhof         that literature refined and
extended his observations in numerous ways  taken together  the findings suggest that intensional
operators and negation interact in complex ways with discourse anaphora  by default  we expect
phrases introduced in the scope of such operators to lead short lifespans  but it is possible for them
to take wide scope with respect to those operators  which broadens the range of anaphoric links they
can establish  such readings are favored or disfavored by the pragmatics of the situation as well as
the lexical and syntactic nature of the phrases involved  in what follows  we seek to model these
interactions and use them to inform a lifespan model 
   

fide

m arneffe   r ecasens   p otts

   previous engineering efforts and quantitative evaluations
the above insights have inspired nlp researchers to try to predict the roles that different mentions
will play in coreference chains  previous work in this area can be subdivided into detecting four
different targets  non referential mentions  non anaphoric mentions  discourse new mentions  and
non antecedent mentions  the terminology has not always been used in a consistent way in linguistics or nlp  but we believe that the results can ultimately be brought together  here  we aim to
clarify the terminology and find common insights behind the various features that have been used 
we are the first to single out the singleton coreferent detection task as such  but our work finds
important antecedents in the existing literature 
    non referential mentions
some noun phrases do not refer to a discourse referent but rather just fill a syntactic position  in
english  the canonical example of a non referential np is the expletive pronoun it  as in it is obvious
that we will succeed  some lexical nps do not introduce a discourse referent either  such as a
linguist in pat is a linguist  while the mention pat does introduce a discourse referent  a linguist
simply predicates something of her  detecting such non referential uses plays a role in coreference
resolution  since these nps do not pick out discourse referents  new or existing   they cannot enter
into any anaphoric relations of the kind under consideration here 
early work in non referentiality detection focuses on the pronoun it  aiming to distinguish referential uses from non referential ones  paice and husk        develop a rule based system  evans
       uses a supervised approach  and muller        focuses on the use of it in spoken dialog 
these studies mainly employ lexico syntactic features of the immediate surrounding context of the
pronoun  similarly  bergsma  lin  and goebel        explore a system that uses web count features derived from the google n grams data  brants   franz        to capture the most frequent
subjects that can replace the pronoun it  for referential cases  e g   it is able to   other words than it
will be frequent in the n grams  such as he is able to or china is able to  whereas for non referential
cases  the pronoun it will likely be the most frequent subject  e g   it is important to  
more recently  bergsma and yarowsky        develop the nada system  which improves on
bergsma et al         by incorporating lexical features  the lexical features indicate the presence
or absence of some strings at specific positions around the pronoun  three grams to five grams
spanning the pronoun  two tokens before the pronoun to five tokens after the pronoun with their
positions  any token within twenty tokens to the right of the pronoun  and any token within ten
tokens to the left of the pronoun that is a named entity or belongs to the following list  that  this 
and  said  says  it  it  its  itself  using both types of features  lexical and web count  they achieve
    accuracy on different datasets 
byron and gegg harrison        apply some of the linguistic insights highlighted by karttunen
 section    to the special case of pronoun resolution  seeking to discard non referential indefinite
nps from the set of potential antecedents for pronouns  they use a hard filter for non referential
mentions  looking at the presence of indefinites  negation  apposition  hand labeled   modals  adjectival phrases or predication adjuncts  tagged  clr in the penn treebank   predicates of copular
verbs  tagged  prd   and noun phrases that express a value  they found that removing nonreferential mentions gave a small boost in performance for pronoun resolution 
   

fim odeling the l ifespan of d iscourse e ntities

    non anaphoric mentions
non anaphoric nps are those whose interpretation does not depend on a previous mention in the
text  for example  the phrase the new scorsese movie that stars de niro in       while manifesting
many kinds of context dependence  does not depend on any other overt phrases in order to capture all
of its descriptive content  in contrast  the movie in      crucially links back to the previous sentence
for its descriptive content  it superficially involves just the predicate movie  but it is construed as
having the additional property seen by the speaker the previous night 
    

last night  i watched the new scorsese movie that stars de niro 

    

last night  i watched a movie and read a paper  the movie was directed by scorsese 

there is no direct correspondence between anaphora and coreferentiality  coreferent mentions
can be non anaphoric  as in a text containing multiple tokens of the phrase the white house   and
anaphoric mentions can be coreferent or non coreferent  van deemter   kibble         cases of
bridging anaphora  clark        like      involve non coreferent anaphora  here  the ceiling is
interpreted as the ceiling of the room mentioned in the previous sentence  and thus it is anaphoric to
the room without being coreferent with it or any other phrase in the discourse 
    

i looked into the room  the ceiling was very high 

we return to such cases in section    where we use our lifespan model to characterize the sense in
which bridging anchors like the room lead longer lifespans than a count of their strictly coreferent
mentions would suggest 
poesio  uryupina  vieira  alexandrov kabadjov  and goulart        and poesio  alexandrovkabadjov  vieira  goulart  and uryupina        summarize previous approaches to non anaphoricity
detection  which they refer to as discourse new detectors  vieira and poesio        focus on definite nps and use syntactic heuristics based on pre  and post modification to distinguish between
anaphoric and non anaphoric nps  modification is a good indicator of anaphoricity  heavily modified phrases like the new scorsese movie that stars de niro tend to be non anaphoric  whereas short
phrases with general descriptive content like the movie tend to be anaphoric  bean and riloff       
also focus on definite nps  in addition to syntactic heuristics based on pre  and post modification 
they use techniques mining lists of likely non anaphoric nps  such as the presence of nps in the first
sentence of a document   compared to vieira and poesio         they obtain substantially higher
recall  with recall and precision figures around      
in their non anaphoricity detector  poesio et al         use a head feature  distance between
nps with identical heads   syntactic features  e g   occurring inside an appositive or copular clause 
being post modified   capitalization of the mention  presence of the mention in the first sentence of
a web page  position of the mention in the text  and the probability of the mention being definite as
computed from the web using the technique of uryupina         they find that the most important
features are the head feature and the definiteness probabilities 
    discourse new mentions
discourse new mentions are those that introduce a new entity into the discourse  prince      b 
fraurud         the entity might be singleton or involve a chain of coreferring mentions in which
the first phrase is the discourse new one and the rest are considered discourse old  cast as an
   

fide

m arneffe   r ecasens   p otts

information status task  the goal of discourse new mention detection is to find discourse referents
which were not previously available to the hearer reader  e g   see the work of nissim        
ng and cardie        develop a discourse new classifier that targets every kind of np using a
variety of feature types  lexical  string and head matching  conjunction   morpho syntactic  definiteness  quantification  number   grammatical  appositional or copular context  modifier structure 
proper noun embedding   and shallow semantic  e g   wordnet features   they incorporate the
classifier into their coreference resolution system  pre filtering nps that are tagged as discoursenew  however  this pre filtering ultimately hurts coreference resolution system performance  even
though precision increases  recall drops considerably  in section        we report similar results
for our model instantiated with discourse new pre filtering  but we find that the recall drop can be
avoided if filtering is applied only when the mention under analysis is tagged as discourse new and
the antecedent candidate is tagged as singleton 
ng and cardies        work is cast as non anaphoricity detection  but their model is perhaps
better described as trying to distinguish coreferent mentions from those that are singleton or initiate
coreference chains  more specifically  they write  a positive instance is created for each np that is
involved in a coreference chain but is not the head of the chain  ng   cardie        p      which
picks out non initial members of coreference chains  conversely  a negative instance is created for
each of the remaining nps  ng   cardie        p      i e   those without any antecedents 
uryupina        proposes a discourse new mention detector for any kind of np  the classifier
relies on features falling into three categories she defines  lexical  number of words in the mention   syntactic  pos  number  person  determiner  pre  and post modification   semantic  gender  semantic class   and salience  grammatical role  position in the sentence and in the paragraph  
in addition  she includes some of karttunens features as implemented by byron and gegg harrison
        her classifier also checks for mentions with identical heads  and distance between these 
only the syntactic and head features deliver improvements to a majority baseline  which marks
each np as discourse new   performing almost as well as all the features together  uryupina notes 
however  that most of the features  and especially those based in karttunens ideas  have not been
designed for discourse new mention detection 
both ng and cardie        and uryupina        integrated their discourse new detector into a
coreference resolution system in a pipeline manner  for a joint approach to discourse new detection
and coreference resolution  see the work of denis and baldridge        
    non antecedent mentions
as uryupina        observes  for coreference resolution  what matters is the fact that some nps are
unavailable as antecedents  she therefore builds a classifier that marks nps as likely antecedents
or not  her system is based on the same features as her discourse new detector described above
 section       for non antecedenthood detection  only the syntactic and semantic features lead
to a significant precision improvement over a majority baseline  which marks each np as nonantecedent   with the syntactic features alone performing as well as all the features together 
    our approach  singletons
our model cross cuts these four categories  unlike previous models of non referentality  ours is
not restricted to pronouns or to indefinite nps  but tries to identify any kind of non referential np
as well as any referential np whose referent is mentioned only once  i e   singleton   thus  all
   

fim odeling the l ifespan of d iscourse e ntities

dataset

docs

tokens

training
development
test

     
   
   

   m
   k
   k

m entions
coreferent singletons
       
      
      

       
      
      

table    conll      shared task data statistics  we added singletons  noun phrases not annotated as coreferent   which account for     of the referents in the development set 

non referential nps fall into our singleton class  on the other hand  there is no strict correspondence between our singleton coreferent distinction and the non anaphoric anaphoric distinction 
since anaphoricity is based on whether the mention relies on a previous one for its interpretation 
whereas the singleton coreferent divide is based on how long the lifespan of an entity is  similarly 
discourse new mentions can either be coreferent or singleton in our classification  depending on
whether the entity is mentioned again or not 
in terms of feature representations  we have tried to stay as close as possible to karttunens
original insights  we extract the features from full syntactic parses  seeking to remain faithful to the
underlying semantic relationships involved  and we include feature interaction terms to capture the
complex set of dependencies reviewed above in section    this approach allows us to both evaluate
those linguistic ideas quantitatively and to assess their practical contributions to full coreference
systems 

   data
the data used throughout this paper come from the conll      shared task data  pradhan  moschitti  xue  uryupina    zhang         which included the    m english words from ontonotes
v     pradhan   xue        with several common layers of annotation  coreference  parse trees 
named entity tags  etc    the ontonotes corpus contains documents from seven different domains 
broadcast conversation        broadcast news        magazine       newswire        telephone
conversation        weblogs and newsgroups        and pivot text        most of these genres
are news like  with the exception of the pivot texts  which come from the new testament  and the
telephone conversations  we used the training  development  and test splits as defined in the shared
task  table     since the coreference annotations of ontonotes do not contain any singleton mentions  we automatically marked as singleton all the noun phrases not annotated as coreferent  we
excluded verbal mentions 
because we mark as singleton all the noun phrases not annotated as coreferent  our definition of
singletons includes non referential noun phrases such as it in it is raining  and president in he served
as president for two terms  section       this makes practical sense  the starting point of most
coreference resolution systems is to take all noun phrases as possible candidates for coreference
and subsequently find the clusters that are coreferent with one another  the more phrases we can
accurately identify as singleton  the more phrases we can exclude from this clustering step  which
should translate directly into performance gains 
   

fide

m arneffe   r ecasens   p otts

referents

     

    
singleton

 

   

   

   

   

   

  

  

 

 

 

    

     

     

   

mentions

figure    distribution of referent lifespans in the      ontonotes development set 

   predicting lifespans with linguistic features
we now describe our model for predicting the lifespan of discourse referents using the linguistic
factors proposed in section    the model makes a binary distinction between discourse referents
that are not part of a coreference chain  singleton  and those that are part of one  coreferent   the
distribution of lifespans in our data is shown in figure   
this plot gives the number of entities associated with a single mention  the number associated
with two mentions  and so forth  the fact that singletons so dominate the data suggests that the binary singleton coreferent division is a natural one  the propensity toward singletons also highlights
the relevance of detecting singletons for a coreference system  following bergsma and yarowsky
        we use a logistic regression model  which has been shown to perform well on a range of
nlp tasks  we fit the logistic regression model in r  r development core team        on the training data  coding singletons as   and coreferent mentions as    thus  throughout the following
tables of coefficient estimates  positive values favor coreferent mentions and negative values favor
singletons  we turn now to describing and motivating the features of this model 
    morphosyntax of the mention
table   summarizes the features from our model that concern the internal morphology and syntactic
structure of the mention  giving their coefficient estimates  in all the tables  if not indicated otherwise  the coefficient estimates are significant at p          we use  to indicate significance at
p         and  to indicate estimates with p        the morphosyntactic features include type
 pronoun  proper noun  common noun   animacy  named entity tag  person  number  quantification  definite  indefinite  quantified   and number of modifiers of the mention  many are
common in coreference systems  recasens   hovy         but our model highlights their influence
on lifespans  where available  we used gold annotations to derive our features  since our primary
goal is to shed light on the relevance of the features claimed to influence lifespans 
   

fim odeling the l ifespan of d iscourse e ntities

the morphosyntactic features were operationalized using static lists and lexicons as well as the
stanford dependencies as output by the stanford parser  version        de marneffe  maccartney   
manning        on the gold constituent trees  the features are extracted in the following way 
type the type feature captures whether the mention is a pronoun  proper noun  or common noun 
the value is determined by the gold pos tag of the mention and its named entity tag 
animacy we set animacy values  animate  inanimate  unknown  using a static list for pronouns  named entity tags  e g   person is animate whereas location is not   and a dictionary
bootstrapped from the web  ji   lin        
person person values           are assigned only to pronouns  identified by pos tag   using
a static list  mentions that are not pronouns get a value of   
number the number value  singular  plural  unknown  is based on a static list for pronouns 
pos tags  bergsma and lins        static dictionary  and named entity tags   mentions marked
as a named entity are considered singular with the exception of organizations  which can be both
singular and plural and get the value unknown  
quantification as we discussed in section    indefinites and definites can be given a referential
semantics that pairs naturally with discourse anaphora  whereas the anaphoric possibilities of truly
quantified terms are restricted  to operationalize quantification and decide whether a mention is
definite  indefinite  or quantified  we use the dependencies to find possible determiners  possessors 
and numerical quantifiers of a mention  a mention is definite if it is a named entity  if it has a
possessor  e g   car in johns car is definite   or if its determiner is definite  the   demonstrative 
or possessive  a mention is quantified if it has a numerical quantifier  e g   two cars  or if its
determiner is all  both  neither or either  all other mentions are indefinite 
number of modifiers we added a feature counting how many modifiers the mention has  seeking to capture a correlation with specificity and referentiality  as modifiers  we counted adjectival 
participial  infinitival  and prepositional modifiers as well as relative clause modifiers  noun compounds  and possessives   thus  there are four modifiers in the phrase a modern multifunctional
business center costing    million yuan  
named entities our model also includes named entity features for all of the    ontonotes entitytypes  with ner   o true of non named entities  we used the gold entity type annotation 
table   summarizes the coefficient estimates we obtain for these features  in broad terms  the
picture is as one would expect from the taxonomy of given and new defined by prince      b  and
assumed throughout dynamic semantics  kamp        heim         pronouns depend on anaphoric
connections to previous mentions for disambiguation and thus are likely to be coreferent  this is
corroborated by the positive coefficient estimate for type   pronoun 
few quantified phrases participate in discourse anaphora  partee        wang et al         
accounting for the association between quantifiers and singletons  as measured by the negative
coefficient estimate for quantifier   quantified  
the negative coefficient for indefinites is initially surprising  as seen in section    theories
stretching back to karttunen        say that indefinites excel at establishing new discourse entities
and so should be frequent participants in coreference chains  but here the association with such
   

fide

m arneffe   r ecasens   p otts

feature

coefficient

feature

coefficient

type   pronoun
type   proper noun
animacy   inanimate
animacy   unknown
person    
person    
person    
number   singular
number   unknown
quantifier   indefinite
quantifier   quantified
number of modifiers
ner   date
ner   event
ner   facility

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

  gpe
ner   language
ner   law
ner   location
ner   money
ner   norp
ner   o
ner   ordinal
ner   organization
ner   percent
ner   person
ner   product
ner   quantity
ner   time
ner   work of art

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

ner





table    internal morphosyntactic features of the lifespan model   indicates a non significant coefficient  p         no sign indicates a significant coefficient  p          

chains is negative  we return to this in section      where we argue that interactions with semantic
operators explain this fact 
the behavior of the named entity  ner  features is closely aligned with previous models and
our theoretical discussion above  as a rule  named entities behave like type   proper noun in associating with coreferent mentions  the exceptions are money  ordinal  norp  for nationalities
and religions   percent  and quantity  which seem intuitively unlikely to participate in coreference chains  the person  number  and animacy features together suggest that singular animates are
excellent coreferent noun phrases 
the one real surprise for us here concerns the feature number of modifiers  inspired by observations of fodor and sag        and schwarzschild         we expected this feature to positively
correlate with being coreferent  our reasoning was that increased modification would likely result
in increased specificity  thereby making the associated discourse referent more identifiable and more
distinctive  the opposite seems to hold in our data  however  we hesitate to conclude from this that
the original hypothesis is mistaken  rather  we suspect that our model is just insufficiently sensitive
to interactions between modifier counts and the lexical semantics of the modifiers themselves 
    grammatical role of the mention
synthesizing much work in centering theory and information structuring  we hypothesized that
coreferent mentions are likely to appear as core verbal arguments and favor sentence initial  topictracking  positions  ward   birner         to capture these insights  we used the grammatical
relation of the mention given by the stanford dependencies on gold constituents  and the sentence
position of the mention 
   

fim odeling the l ifespan of d iscourse e ntities

feature

coefficient

feature

coefficient

sentence position   end
sentence position   first
sentence position   last
sentence position   middle
in coordination

    
    
    
    
    

relation   noun argument
relation   other
relation   root
relation   subject
relation   verb argument

    
    
    
    
    



table    grammatical role features of the lifespan model   indicates a non significant coefficient
 p         no sign indicates a significant coefficient  p          

sentence position sentence position was determined based on the raw string  first indicates that
the mention is the first word of the sentence  end the last word  and begin  middle  and last
indicate whether the mention is situated in the first  second  or last third of the sentence  respectively 
relation to distinguish among grammatical relations  we check whether the mention is a subject  adjunct  which includes prepositional objects  adverbial modifiers  and temporal modifiers  
verb argument  which includes direct and indirect objects  clausal complements  adjectival complements and attributes   or noun argument  which includes relative clauses  appositions  possessives  noun compounds  and adjectival modifiers  
in coordination we also indicated whether or not the mention is a conjunct to see whether being
inside a coordinate phrase affects coreference in ways that go beyond the grammatical role of the
containing phrase 
the coefficient estimates in table   support our general hypotheses  arguments make good discourse
referents  subjects best of all  whereas sentence final positions disfavor coreference  in addition  we
note that the model identifies a negative correlation between coordination and coreference 
    semantic environment of the mention
table   highlights the complex interactions between discourse anaphora and semantic operators introduced in section    these interactions have been a focus of logical semantics since karttunen
        whose guiding observation is semantic  an indefinite interpreted inside the scope of a negation  modal  or attitude predicate is generally unavailable for anaphoric reference outside of the
scope of that operator  heim        also relates the anaphoric properties of nps to scope taking
and the entailments of attitude predications 
we do not have direct access to semantic scope  but we expect syntactic scope to correlate
strongly with semantic scope  we therefore used dependency representations to define features
capturing syntactic scope for negation  modal auxiliaries  and a broad range of attitude predicates
     verbs and     nouns from saur         technically  for a given mention  we produce a
negation  modal or under attitude verb feature according to the presence of pre defined negation
or modality markers  such as not  can  may  or attitude predicates  e g   accuse  allege  doubt  say 
in the dependency path  for example  the np relief will be given a negation feature in while the
financial storm shows no sign of relief today  since it is under the scope of no sign  similarly  the
mention scientific and technological companies is in the scope of the modal auxiliary would and the
   

fide

m arneffe   r ecasens   p otts

feature

coefficient

presence of negation
presence of modality
under an attitude verb
attitudeverb    type   pronoun 
attitudeverb    type   proper noun 
attitudeverb    quantifier   indefinite 
attitudeverb    quantifier   quantified 
modal    type   pronoun 
modal    type   proper noun 
modal    quantifier   indefinite 
modal    quantifier   quantified 
negation    type   pronoun 
negation    type   proper noun 
negation    quantifier   indefinite 
negation    quantifier   quantified 
negation    number of modifiers 

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    








table    semantic environment features and interactions in the lifespan model   indicates a nonsignificant coefficient  p         no sign indicates a significant coefficient  p           
indicates significance at p        

attitude verb said in firms from taiwan said that they would establish scientific and technological
companies in the zone  and so it receives modal and under attitude verb features 
table   summarizes our models semantic environment features and their interactions  the interaction terms added to the model follow the previous linguistic literature  we expect that the scope
of the semantic operators  negation  modality and attitude predicate  will interact with the internal syntax of the mention  specifically with its type and its definiteness quantification  the results
are beautifully aligned with our guiding linguistic hypotheses  first  negation and modality both
negatively correlate with coreference  as expected given the constraints they impose on lifespans 
interacting these semantic features with those for the internal syntax of mentions also yields the
expected results  since proper names and pronouns are not scope taking  they are largely unaffected
by the environment features  whereas indefinites  which are affected by scope  emerge as even more
restricted  just as karttunen and others would predict 
the coefficient values for attitude predicates and their interactions seem anomalous in light of
the semantics of these items  in section    we noted that non factive attitude predicates like say
cannot offer semantic guarantees that mentions in their scope will survive outside that scope  this
might lead one to think that they will be biased against long lived mentions  when in fact we see the
opposite  however  we also observed that pragmatic factors often facilitate exceptional anaphoric
dependencies in attitude predications  karttunen        referred to this as the leakiness of these
predicates  information introduced in their scope seems often to percolate up to the text level in
a wide range of contexts  rooryck        simons        harris   potts         since the lifespan
   

fim odeling the l ifespan of d iscourse e ntities

  f eatures
l inguistic
s urface
c ombined
c onfident

   
      
      
      

s ingleton
recall precision f 
    
    
    
    

    
    
    
    

    
    
    
    

c oreferent
recall precision f 
    
    
    
    

    
    
    
    

    
    
    
    

accuracy
    
    
    
    

table    recall  precision  f  and accuracy for the three different sets of features on the ontonotes
development set  c onfident is the c ombined model in which singleton is predicted if
pr       and coreferent if pr       

model is trained on real usage data  it is not surprising that it reflects these pragmatic factors rather
than just the lexical semantics  de marneffe et al         
as noted earlier  features in table   are not standardly used in coreference systems  uryupina
       notes that the karttunen features she implemented  see section    do not significantly improve the performance of her discourse new mention and non antecedent detectors  contrary to
uryupina  adding the features in table   to a model which only incorporates the features described
in table   and table   results in a significantly better model  likelihood ratio test  p           the
accuracy on the conll      development set also improves when adding the karttunen features
 mcnemars test  p          
    results
as highlighted above  the lifespan model we built from the ontonotes data confirms the claims by
karttunen and others concerning how semantic operators interact with specific kinds of mention 
this is novel quantitative evidence for such theories  the model also successfully learns to tease
singleton and coreferent mentions apart  suggesting that it has practical value for nlp applications 
the first row of table   summarizes the linguistic model performance on the development set of
the ontonotes data described in section    giving precision  recall  and f  measures for singleton
and coreferent mentions  the accuracy of the model is        a majority baseline  predicting all
mentions as singletons  leads to an accuracy of       

   extension to bridging
the lifespan model suggests a new perspective on bridging anaphora  which we discussed briefly
in section     using example       repeated here 
    

i looked into the room  the ceiling was very high 

the anchor phrase the room is superficially singleton in this discourse  but its intuitive lifespan
is longer  it makes salient a discourse referent for the ceiling of the room  which the ceiling in
the second sentence then refers to  the bridging relationship keeps the room alive as a discourse
referent  extending its lifespan  though not in a way that can be read directly off of the text  together
with the basic tenets of the lifespan model  these observations suggest a testable hypothesis about
   

fide

m arneffe   r ecasens   p otts

bridging  even when bridging anchors are superficially singleton  henceforth  singleton anchors   
our lifespan model should tend to classify them as coreferent  since the model is not designed to
detect later mentions per se  but rather to capture more abstract information about the roles that
entities play in discourse 
ontonotes does not contain annotations for bridging anaphora  so evaluating this hypothesis is
not straightforward  however  hou  markert  and strube        annotated    of the wsj texts in
ontonotes for bridging information  yielding annotations for     bridging anchors  of these     
are singleton anchors in the sense that we identify them  section    and thus can be used to assess
our models ability to detect the abstract sense in which bridging anchors are long lived 
ideally  we would simply run our trained lifespan model on these examples  this proves ineffective  though  because  outside of hou et al s data  the ontonotes annotations treat singleton
anchors as singleton  meaning that our trained lifespan model is optimized on data that obscure the
distinction of interest  nonetheless  we expect the feature representations that form the backbone of
the lifespan model to be able to distinguish true singletons from singleton anchors if given the right
kind of training data  the small number of relevant bridging annotations poses some obstacles to
pursuing this idea  but we sought to navigate around them as follows  using the annotated corpus
of hou et al   we extract all     of the singleton anchors and then sample an additional     true
singletons from those documents  from a total of       such cases   this yields a data set that we
can be confident makes the relevant distinction  we then randomly divide this data set into    
training data and     testing data  and conduct a standard classifier evaluation  we use a logistic
regression classifier  employing recursive feature elimination with cross validation  guyon  weston 
  barnhill         as implemented by pedregosa et al          to try to find a compact model that
is effective for the small data set  the model used an    regularizer with a penalty of      though
   regularization and changes to the penalty delivered essentially the same results  both with and
without the recursive feature elimination step 
because these train and test sets are small  performance varies greatly depending on the nature
of the true singleton sample  so we repeat this experiment       times and average the results  with
this procedure  our lifespan feature representations achieve a mean f  of      standard error       
mean precision      mean recall         indicating our lifespan based features are sensitive to the
distinction between singleton anchors and true singletons  this finding further bolsters the design
of the lifespan feature representations and also shows that lifespan is deeper and more abstract
than merely counting referents  given the right kind of annotations  we believe our model could be
extended to provide an even fuller treatment of bridging  which is governed partly by its own mix
of linguistic and contextual factors  hawkins        prince      b  schwarz        

   predicting lifespans with surface features
durrett and klein        and hall et al         showed that  on the tasks of coreference resolution
and parsing  a large quantity of surface level information can not only implicitly model some linguistic features  but also capture other patterns in the data that are not easily identified manually 
given the large amount of annotated data available in the ontonotes corpus  we might expect a
sufficient amount of surface level data to capture some of the linguistic insights hand engineered in
   some bridging anchors also have literal coreferent mentions  as in i looked into the room  it was empty  and the
ceiling was very high   where the room is coreferent with it in addition to providing discourse support for the ceiling 
we set aside such cases in our bridging experiments 

   

fim odeling the l ifespan of d iscourse e ntities

the lifespan model defined above  we therefore tested how a model using pos tags and n grams
fares on the lifespan task 
we used the following features in this surface model  the lemmas of all the words in the mention 
the pos tags of all the words in the mention  the pos tag of the head of the mention  and the lemma
and pos tags of the two words preceding and following the mention  with dummy begin and end
words to mark the beginning and end of sentences   as suggested by durrett and klein         such
features might capture information encoded in the ner tag  number  person  and sentence position 
the surface models performance is reported in the second row of table    for all models in
table    the    regularization penalty was chosen via five fold cross validation on the training data 
for the linguistic model  using the tuned    regularization penalty rather than the default one makes
almost no difference  but it substantially improves performance for the models with more features 
we additionally experimented with different algorithms for feature selection  but found that the
results were invariably best  for all our models  when we retained their full sets of features  the last
row of the table gives the performance of a model in which we combine both the linguistic and the
surface features to evaluate whether the surface features alone cover all the information captured by
the linguistic features  or whether the linguistic features have additional predictive value 
the surface model performs better than the linguistic only model  especially for the coreferent
category  however  the small number of linguistically motivated features yields results in the same
range as those obtained with the large number of features in the surface model  which might be
of importance for tasks where only a small amount of annotated data is available  such as in the
bridging experiment in section     the obvious trade off here is that the surface features are easier
to specify and implement   as shown in the c ombined row of table    combined with the surface
feature set  the linguistically motivated features give a statistically significant boost in performance 
this suggests that the surface features miss certain long distance interactions between discourse
anaphora and semantic operators  interactions that the linguistic features explicitly encode 
our best model for predicting lifespan is the combined one  instead of using the standard    
threshold as decision boundary  we can also make use of the full distribution returned by the logistic regression model and rely only on confident decisions  the resulting c onfident model is a
c ombined one that predicts singleton if pr       and coreferent if pr        the threshold values
reported here are the best trade off we found between a precision score close to      without losing
too much in recall  as expected  by using such a highly confident model  we increase precision 
though at a cost to recall  which kind of model is preferred will depend on the application  as noted
by ng        and uryupina         when incorporating the lifespan model in downstream nlp
applications  we often want highly accurate predictions  which favors a model like c onfident 

   application to coreference resolution
to further assess the value of the lifespan model for nlp applications  we now incorporate the best
feature combination into two state of the art coreference resolution systems  the stanford system
 lee et al         and the berkeley system  durrett   klein         in both cases  the original
model serves as our baseline  and we focus on the extent to which the lifespan model contributes
to improvements to that baseline  this allows us to quantify the power and effectiveness of the
lifespan model in two very different systems  a rule based one  stanford  and a learning based
one  berkeley  
   

fide

m arneffe   r ecasens   p otts

    evaluation measures
to evaluate the incorporation of the lifespan model into the coreference systems  we use the english
development and test sets from the conll      and conll      shared tasks  although the
conll shared tasks evaluated systems on only multi mention  i e   non singleton  entities  we can
still expect the lifespan model to help  by stopping singletons from being linked to multi mention
entities  we expect to see an increase in precision  our evaluation uses the measures given by the
conll scorer 
 muc  vilain  burger  aberdeen  connolly    hirschman         link based metric that
measures how many links the gold and system partitions have in common 
 b   bagga   baldwin         mention based metric that measures the proportion of mention
overlap between gold and predicted entities 
 ceaf    luo         mention based metric that  unlike b    enforces a one to one alignment between gold and predicted entities 
 ceaf    luo         the entity based version of the above metric 
 conll  denis   baldridge        pradhan  ramshaw  marcus  palmer  weischedel    xue 
       average of muc  b  and ceaf    
 blanc  recasens   hovy         link based metric that takes the mean of coreference
and non coreference links  thereby rewarding  but not over rewarding  singletons 
we use the new conll coreference scorer  pradhan  luo  recasens  hovy  ng    strube       
version       which fixes a bug in previous versions concerning the way gold and predicted mentions
are aligned when evaluating on automatically predicted mentions  the new scorer does not modify
either the gold or system output  but implements the measures as originally proposed  and extends
blanc to successfully handle predicted mentions  following luo  pradhan  recasens  and hovy
       
    incorporating the lifespan model into the stanford coreference system
the stanford system was the highest scoring system in the conll      shared task  pradhan
et al          and was also part of the highest scoring system  fernandes  dos santos    milidiu 
      in the conll      shared task  pradhan et al          it is a rule based system that includes
a total of ten rules  or sieves  for entity coreference  such as exact string match and pronominal
resolution  the sieves are applied from highest to lowest precision  each rule adding coreference
links  in each coreference resolution sieve  the documents mentions are traversed left to right  to
prune the search space  if a mention has already been linked to another one by a previous sieve 
only the mention that is first in textual order is considered by the subsequent sieves  furthermore 
mentions that are headed by an indefinite pronoun  e g   some  other  or start with an indefinite
determiner  a  an  are discarded if there is no antecedent that has the exact same string  each
mention is compared to the previous mentions in the text until a coreferent antecedent is found
 according to the current sieve  or the beginning of the text is reached  candidates are sorted using
a left to right breadth first traversal of the parse tree  which favors subjects and syntactic salience
in general 
the lifespan model can improve coreference resolution in two different ways   i  mentions classified as singletons should not be considered as either antecedents or coreferent  and  ii  mentions
   

fim odeling the l ifespan of d iscourse e ntities

classified as coreferent should be linked with other mention s   by successfully predicting singletons  i   we can enhance the systems precision  by successfully predicting coreferent mentions  ii  
we can improve the systems recall  here we focus on  i  and use the lifespan model for detecting
singletons  this decision is motivated by two factors  first  given the large number of singletons
 figure     we are more likely to see a gain in performance from discarding singletons  second  the
multi sieve nature of the stanford coreference system does not make it straightforward to decide
which antecedent a mention should be linked to even if we know that it is coreferent 
to integrate the singleton model into the stanford coreference system  we depart from previous
work by not letting a sieve consider whether a pair of mentions is coreferent if both mentions are
classified as singletons by our c onfident model and the mentions are not a named entity  in doing
this  we discard     of the nps under consideration  experiments on the development set yielded
higher performance when not taking into account named entities  performance was higher with the
c onfident model than with the s tandard model 
we therefore use the lifespan model to help coreference resolution as a pre filtering step to
coreference resolution  discarding mentions tagged as singletons by the lifespan model  previous
work on incorporating a non referentiality or discourse new detection module as a pre processing
step for coreference resolution has shown mixed results  as we discussed in section    the general
arguments for pipeline vs  joint approaches apply here  pipeline approaches prevent recovering from
errors earlier in the pipeline  but joint approaches tend to increase model complexity and associated
optimization challenges  and they do not easily allow separating different modules  which makes
feature design and error analysis more difficult as well  in any case  in the context of the stanford
systems sieve architecture  it is more natural to add the lifespan model as a pre filtering step 
      r esults
table   summarizes the performance of the stanford system on the conll      and conll     
development and test sets  to evaluate the incorporation of the lifespan model in a realistic setting 
we use the automatic parses  and the pos and ner tags provided in the conll documents  all the
scores are on automatically predicted mentions  the baseline is the stanford coreference system 
and w  lifespan is that system extended with our lifespan model to discard singletons  as explained
above  stars indicate a statistically significant difference  wilcoxon signed rank test  p        
according to jackknifing     partitions of the development set or the test set  balanced over the
different domains  of the corpus   as expected  the lifespan model significantly increases precision
 up to      points  but decreases recall  by     points   overall  however  the gain in precision is
higher than the loss in recall  and we obtain a significant improvement of        points in the f 
score of all evaluation measures 
      e rror a nalysis
kummerfeld and klein        provide a useful tool for automatically analyzing and categorizing
errors made by coreference resolution systems  the tool identifies seven intuitive error types  span
error  conflated entities  entity mentions that do not corefer are clustered together   extra entity
 entities that are not in the gold data are added   extra mention  the system incorrectly introduces
   as mentioned in section    the ontonotes corpus contains documents from seven different domains and coreference
performance has been shown to vary highly depending on the domain  pradhan et al         

   

fide

conll
f 

stanford
     dev set
baseline
w  lifespan
discourse new

r

m arneffe   r ecasens   p otts

muc
p

f 

r

b 
p

f 

r

ceaf  
p
f 

     
      
     

                  
                   
                   

                  
                   
                  

                  
                   
                  

     test set
baseline
     
w  lifespan
      
discourse new       

                  
                   
                   

                  
                   
                   

                  
                   
                 

     dev set
baseline
w  lifespan
discourse new

     
      
     

                  
                   
                 

                  
                   
                 

                  
                   
                  

     test set
baseline
     
w  lifespan
      
discourse new      

                  
                   
                  

                  
                   
                  

                  
                   
                  

 a 

stanford

r

ceaf  
p
f 

r

blanc
p
f 

     dev set
baseline
w  lifespan
discourse new

                  
                   
                  

                  
                   
                  

     test set
baseline
w  lifespan
discourse new

                  
                   
    
             

                  
                   
                   

     dev set
baseline
w  lifespan
discourse new

                  
                   
                 

                  
                   
                 

     test set
baseline
w  lifespan
discourse new

                  
                   
                  

                  
                   
                   

 b 

table    performance of the stanford system on the conll      and conll      development
and test sets  scores  v    of the conll scorer  are on automatically predicted mentions 
using the conll automatic annotations  stars on the w  lifespan and discourse new
rows indicate a significant difference from the baseline  wilcoxon signed rank test  p  
      
   

fim odeling the l ifespan of d iscourse e ntities

error

they 

gold
scientists 
they 
his family 
they 

extra entity

various major hong kong media
no media




extra mention

a book
the book
it


the book
it

conflated entities

system
scientists 
they 

 a  errors affecting precision 

error

system
scientists 
they 
his family 
they 

gold
scientists 
they 
his family 
they 

missing entity




a network
it

missing mention

two mothers
their


two mothers
their
two mothers who lost very loved ones

divided entity

 b  errors affecting recall 

table    illustration of the error types provided by kummerfeld and kleins        system  errors
made by the stanford coreference system on the conll      development set 

a mention as coreferent in a cluster    divided entity  an entity is split into two or more different
clusters    missing entity  the system fails to detect an entity   and missing mention  an entity is
missing one of its mentions   table   illustrates the error types we are interested in   showing errors
made by the stanford system  separated into those affecting precision and those affecting recall 
we ran kummerfeld and kleins        system on the stanford output to quantify the improvement obtained by incorporating the lifespan model into the coreference system for the conll     
development set  figure   shows the difference in errors between the original stanford coreference
system and the system in which the lifespan model is integrated  the lifespan model generally
reduces errors affecting precision  most notably by getting rid of some spurious entities  extra
entity   the top three errors in table    all precision related  are fixed by integrating the lifespan model into the stanford system  on the other hand  the bottom two errors  recall related 
   the distinction between the two categories conflated entities and extra mention makes sense in a corpus like
ontonotes where singletons are not annotated  the former occurs when the system clusters one or more mentions
from a multi mention entity into an incorrect entity  whereas the latter occurs when the system incorrectly clusters
with others a mention that is truly part of a singleton entity  and so not annotated in the gold  
   a conflated entities error and a divided entity error often co occur 
   the span error category is not relevant in the comparison here  both systems  with and without lifespan  work on
the same predicted mentions 

   

fide

m arneffe   r ecasens   p otts

stanford alone

conflated entities

extra entity

extra mention

with lifespan

   

stanford alone

   

with lifespan

stanford alone

   

with lifespan

   

stanford alone

divided entities

missing entity

missing mention

    
    

with lifespan

    
    

   

stanford alone

   

with lifespan

stanford alone

    

with lifespan

    

figure    number of errors for the stanford coreference system  with and without the lifespan
model  on the conll      development set 

are introduced by the lifespan model  however  the cumulative gain in error reduction across error
categories results in a significant improvement in overall coreference performance 
      u sing the l ifespan m odel as a d iscourse  n ew m ention c lassifier
as we discussed in section      previous work  ng   cardie        uryupina        reports a
loss in coreference resolution performance when pre filtering discourse new mentions  i e   singleton mentions as well as mentions that start a coreference chain  to mimic such pre filtering  we
incorporate the lifespan model into the stanford system in the following way  only mentions that
our model does not classify as singletons are considered by every sieve and hypothesized to corefer
with some other previous mention  while discourse new mentions are removed from consideration 
when we do so  we also see a performance loss  as shown in the discourse new rows of table    there are no clear significant gains across the measures  compared to the performance of the
standard stanford system  baseline rows   the improvements we do see in table   result from
pre filtering pairs of mentions both of which our lifespan model classifies as singletons  this stricter
constraint seems to balance out the loss of pre filtering too many mentions at this early stage 
    incorporating the lifespan model into the berkeley coreference system
the berkeley coreference system  durrett   klein        durrett  hall    klein        is currently
the highest scoring coreference system that is publicly available  it uses a mention synchronous
framework  for each mention  the system either chooses one antecedent or decides that the mention
starts a new cluster  perhaps leading to a singleton cluster   it is a log linear model in which features
are extracted over mentions to decide whether or not the mentions are anaphoric  and features are
extracted over pairs of mentions to decide whether or not the pairs corefer  the baseline we compare
   

fim odeling the l ifespan of d iscourse e ntities

against takes the best feature set  the final one  as reported by durrett and klein         which
combines a large number of lexicalized surface features as well as semantic features 
to incorporate the lifespan model into the berkeley system  we use the probabilities of the
mentions given by the lifespan model  for each pair of mentions  we add lifespan features by
adding the lifespan probability for each mention  we also add a singleton feature if both mentions
have a lifespan probability below      and a coreferent feature if both mentions have a lifespan
probability above      unlike the stanford architecture  where exploiting the coreferent predictions
is not straightforward  section       the learning based setup of the berkeley system allows us to
make use of the lifespan probabilities without focusing only on singleton class prediction 
instead of incorporating the lifespan probabilities from the lifespan model  we also tried adding
to the berkeley system all features from the lifespan model not already present in the berkeley
system  i e   all the features in table   and table     however  while it did lead to significant
improvements for the conll      development data  it did not for the conll      test data 
moreover  overall results were less good than when incorporating the probabilities in the manner
described above 
      r esults
table   shows the results of the berkeley system on the conll      and      development and
test sets  as with the stanford system  all the scores are on automatically predicted mentions  we
use the automatic pos tags  parse trees  and ner annotations provided in the conll data both
for training and testing  we restrict training to the training data only   the baseline is the final
berkeley coreference system  and w  lifespan is the same system extended with the lifespan 
singleton and coreferent features  as explained above  significance is computed in the same way as
for the stanford system  we created    partitions of the development set or the test set  balanced
over the different domains of the corpus  
in the learning based context of the berkeley system  the lifespan model increases precision as
well as recall  leading to a final improvement in the conll score of     to     points  since we
use the lifespan model for predicting both singleton and coreferent mentions  we manage to improve both precision and recall  this provides additional empirical support for splitting coreference
resolution into an entity lifespan task that predicts which mentions refer to the long lived entities
in a discourse and a coreference task that focuses on establishing coreference links between these
mentions 
      e rror a nalysis
parallel to our analysis of the stanford coreference system output  we ran kummerfeld and kleins
       system on the berkeley output  figure   shows the difference in errors between the original berkeley coreference system  final feature set  and that system enhanced with the lifespan
model  the enhanced system commits fewer errors affecting precision  upper part of figure    
   we also tried training on the gold pos tags  parse trees  and ner annotations provided in the conll data  but
using the automatic annotations at test time  this does not make any difference for the original berkeley system 
when incorporating the linguistic features  either the lifespan probabilities or all features from the lifespan model
not already in the berkeley system   such a setting does lead to significant improvements over the baseline  however 
improvements do not hold consistently across the development and test sets  when compared to results obtained with
training on automatic annotations  training on gold improves the performance of the linguistically informed systems
only for the test set 

   

fide

berkeley

conll
f 

r

m arneffe   r ecasens   p otts

muc
p

f 

r

b 
p

f 

r

ceaf  
p
f 

     dev set
baseline
     
w  lifespan       

                 
                    

                 
                    

                  
                  

     test set
baseline
     
w  lifespan       

                 
                    

                 
                    

                  
                  

     dev set
baseline
     
w  lifespan       

                 
                    

                 
                    

                  
                   

     test set
baseline
     
w  lifespan       

                 
                    

                 
                    

                  
                  

 a 

berkeley

r

ceaf  
p
f 

r

blanc
p
f 

     dev set
baseline
w  lifespan

                 
                    

                 
                    

     test set
baseline
w  lifespan

     
     

           
            

                 
                    

     dev set
baseline
w  lifespan

     
     

           
             

                 
                    

     test set
baseline
w  lifespan

                 
                    

                 
                    

 b 

table    performance of the berkeley system on the conll      and conll      development
and test sets  scores  v    of the conll scorer  are on automatically predicted mentions 
using the conll automatic annotations  stars indicate a significant difference  wilcoxon
signed rank test  p         

but not significantly for each category  however  the cumulative gains do result in a significant
improvement in overall precision  globally  the lifespan model fixes more errors than it brings in 
   

fim odeling the l ifespan of d iscourse e ntities

berkeley alone

conflated entities

extra entity

extra mention

with lifespan

berkeley alone
with lifespan

   
   

   

berkeley alone
with lifespan

   

berkeley alone

divided entities

missing entity

missing mention

    
    

with lifespan

berkeley alone

   

with lifespan

   

berkeley alone
with lifespan

    
    

   
   

figure    number of errors for the berkeley coreference system  with and without the lifespan
model  on the conll      development set 

   conclusion
what factors determine the fate of a given discourse referent  is it nature  its internal morphosyntax  or nurture  the broader syntactic and semantic environments of its mentions   our lifespan
model  section    suggests that nature  nurture  and their interactions are all important  the model
validates existing linguistic generalizations about discourse anaphora  section     and provides new
insights into previous engineering efforts in a similar direction  section     we also show that
linguistically motivated features bring improvement on top of surface features  section     demonstrating that automatic language processing should not rely only on machine learning and big data 
the lifespan model performs well in its own right  achieving     accuracy in predicting whether
a given mention is singleton or coreferent  this alone could have ramifications for tracking topics 
identifying protagonists  and discourse coherence  in this paper  we demonstrated the benefits of
the lifespan model for coreference resolution  we incorporated the lifespan model into two very
different coreference resolution systems and showed that it yields improvements of practical and
statistical significance in both cases  section    
stepping back  we hope to have provided a compelling illustration of how efforts in theoretical
linguistics and nlp can complement each other  both for developing models and for assessing them
in scientific and engineering contexts 

acknowledgments
we thank jefferson barlew  greg durrett  micha elsner  gregory kierstead  craige roberts  michael
white  the stanford nlp group  and our anonymous reviewers for their helpful suggestions on earlier drafts of this paper  this research was supported in part by onr grant no  n               
and aro grant no  w   nf           
   

fide

m arneffe   r ecasens   p otts

references
aissen  j          on the syntax of obviation  language                
aissen  j          differential object marking  iconicity vs  economy  natural language and
linguistic theory                
aloni  m          quantification under conceptual covers  ph d  thesis  university of amsterdam 
anderbois  s   brasoveanu  a     henderson  r          crossing the appositive at issue meaning
boundary  in li  n     lutz  d   eds    proceedings of semantics and linguistic theory    
pp          clc publications 
bagga  a     baldwin  b          algorithms for scoring coreference chains  in proceedings of the
lrec      workshop on linguistic coreference  pp         
baker  c  l          double negatives  linguistic inquiry               
barzilay  r     lapata  m          modeling local coherence  an entity based approach  computational linguistics             
bean  d  l     riloff  e          corpus based identification of non anaphoric noun phrases  in
proceedings of the   th annual meeting of the association for computational linguistics 
pp          acl 
beaver  d          the optimization of discourse anaphora  linguistics and philosophy        
    
beaver  d  i          corpus pragmatics  something old  something new  paper presented at the
annual meeting of the texas linguistic society 
bergsma  s     lin  d          bootstrapping path based pronoun resolution  in proceedings of the
  st international conference on computational linguistics and   th annual meeting of the
association for computational linguistics  pp        acl 
bergsma  s   lin  d     goebel  r          distributional identification of non referential pronouns 
in proceedings of the   th annual meeting of the association for computational linguistics 
human language technologies  pp        acl 
bergsma  s     yarowsky  d          nada  a robust system for non referential pronoun detection  in hendrickx  i   lalitha devi  s   branco  a     mitkov  r   eds    anaphora processing
and applications  vol       of lecture notes in computer science  pp        springer 
bittner  m          surface composition as bridging  journal of semantics                
brants  t     franz  a          the google web  t  gram corpus version      ldc    t   
byron  d  k     gegg harrison  w          eliminating non referring noun phrases from coreference resolution  in proceedings of the discourse anaphora and reference resolution conference  pp       
chafe  w  l          givenness  contrastiveness  definiteness  subjects  topics  and point of view 
in li  c  n   ed    subject and topic  pp        academic press 
clark  h  h          bridging  in schank  r  c     nash webber  b  l   eds    theoretical issues
in natural language processing  pp          acm 
   

fim odeling the l ifespan of d iscourse e ntities

cresswell  m  j          static semantics for dynamic discourse  linguistics and philosophy      
           
de marneffe  m  c   maccartney  b     manning  c  d          generating typed dependency
parses from phrase structure parses  in proceedings of the fifth international conference on
language resources and evaluation  pp          acl 
de marneffe  m  c   manning  c  d     potts  c          did it happen  the pragmatic complexity
of veridicality assessment  computational linguistics                
delmonte  r   bristot  a   piccolino boniforti  m  a     tonelli  s          entailment and anaphora
resolution in rte   in proceedings of the acl pascal workshop on textual entailment and
paraphrasing  pp       
denis  p     baldridge  j          joint determination of anaphoricity and coreference resolution
using integer programming  in human language technologies       the conference of the
north american chapter of the association for computational linguistics  proceedings of
the main conference  pp          acl 
denis  p     baldridge  j          global joint models for coreference resolution and named entity
classification  procesamiento del lenguaje natural           
durrett  g   hall  d     klein  d          decentralized entity level modeling for coreference
resolution  in proceedings of the   st annual meeting of the association for computational
linguistics  volume    long papers   pp          acl 
durrett  g     klein  d          easy victories and uphill battles in coreference resolution  in
proceedings of the      conference on empirical methods in natural language processing 
pp            acl 
elbourne  p          demonstratives as individual concepts  linguistics and philosophy        
       
evans  r          applying machine learning toward an automatic classification of it  literary
and linguistic computing              
fernandes  e   dos santos  c     milidiu  r          latent structure perceptron with feature induction for unrestricted coreference resolution  in joint conference on emnlp and conll
  shared task  pp        acl 
fodor  j  d     sag  i  a          referential and quantificational indefinites  linguistics and
philosophy               
fraurud  k          definiteness and the processing of noun phrases in natural discourse  journal
of semantics               
giampiccolo  d   magnini  b   dagan  i     dolan  b          the third pascal recognizing
textual entailment challenge  in proceedings of the acl pascal workshop on textual entailment and paraphrasing  pp     
groenendijk  j     stokhof  m          dynamic predicate logic  linguistics and philosophy        
      
grosz  b  j   joshi  a  k     weinstein  s          centering  a framework for modeling the local
coherence of discourse  computational linguistics                
   

fide

m arneffe   r ecasens   p otts

guyon  i   weston  j     barnhill  s          gene selection for cancer classification using support
vector machines  machine learning                 
hall  d   durrett  g     klein  d          less grammar  more features  in proceedings of the   nd
annual meeting of the association for computational linguistics  volume    long papers  
pp          acl 
harris  j  a     potts  c          perspective shifting with appositives and expressives  linguistics
and philosophy                
hawkins  j  a          definiteness and indefiniteness  croom helm 
heim  i          the semantics of definite and indefinite noun phrases  ph d  thesis  umass
amherst 
heim  i          presupposition projection and the semantics of attitude verbs  journal of semantics 
             
hobbs  j  r          coherence and coreference  cognitive science             
hou  y   markert  k     strube  m          global inference for bridging anaphora resolution  in
proceedings of the      conference of the north american chapter of the association for
computational linguistics  human language technologies  pp          acl 
israel  m          polarity sensitivity as lexical semantics  linguistics and philosophy        
       
israel  m          minimizers  maximizers  and the rhetoric of scalar reasoning  journal of semantics                
israel  m          the pragmatics of polarity  in horn  l     ward  g   eds    the handbook of
pragmatics  pp          blackwell 
ji  h     lin  d          gender and animacy knowledge discovery from web scale n grams for
unsupervised person mention detection  in proceedings of the   rd pacific asia conference
on language  information and computation  pp         
kamp  h          a theory of truth and discourse representation  in groenendijk  j   janssen 
t  m  v     stockhof  m   eds    formal methods in the study of language  pp         
mathematical centre 
karttunen  l          presuppositions and compound sentences  linguistic inquiry               
karttunen  l          discourse referents  in mccawley  j  d   ed    syntax and semantics  vol    
notes from the linguistic underground  pp          academic press 
kehler  a          coherence  reference  and the theory of grammar  csli 
kummerfeld  j  k     klein  d          error driven analysis of challenges in coreference resolution  in proceedings of the      conference on empirical methods in natural language
processing  pp          acl 
ladusaw  w  a          negation and polarity items  in lappin  s   ed    the handbook of contemporary semantic theory  pp          blackwell 
   

fim odeling the l ifespan of d iscourse e ntities

lee  h   peirsman  y   chang  a   chambers  n   surdeanu  m     jurafsky  d          stanfords
multi pass sieve coreference resolution system at the conll      shared task  in proceedings of the   th conference on computational natural language learning  shared task  pp 
      acl 
luo  x          on coreference resolution performance metrics  in proceedings of human language technology conference and conference on empirical methods in natural language
processing  pp        acl 
luo  x   pradhan  s   recasens  m     hovy  e          an extension of blanc to system mentions  in proceedings of the   nd annual meeting of the association for computational
linguistics  pp        acl 
muller  c          automatic detection of nonreferential it in spoken multi party dialog  in proceedings of the european chapter of the association for computational linguistics  pp       
acl 
muskens  r   van benthem  j     visser         dynamics  in van benthem  j     ter meulen  a 
 eds    handbook of logic and language  pp          elsevier 
ng  v          learning noun phrase anaphoricity to improve coreference resolution  issues in
representation and optimization  in proceedings of the   nd annual meeting on association
for computational linguistics  pp          acl 
ng  v     cardie  c          identifying anaphoric and non anaphoric noun phrases to improve
coreference resolution  in proceedings of the   th international conference on computational linguistics  pp      acl 
nissim  m          learning information status of discourse entities  in proceedings of the     
conference on empirical methods in natural language processing  pp        
paice  c  d     husk  g  d          towards the automatic recognition of anaphoric features in
english text  the impersonal pronoun it  computer speech   language               
partee  b  h          noun phrase interpretation and type shifting principles  in groenendijk 
j   de jong  d     stokhof  m   eds    studies in discourse representation theory and the
theory of generalized quantifiers  pp          foris publications 
pedregosa  f   varoquaux  g   gramfort  a   michel  v   thirion  b   grisel  o   blondel  m   prettenhofer  p   weiss  r   dubourg  v   vanderplas  j   passos  a   cournapeau  d   brucher  m  
perrot  m     duchesnay  e          scikit learn  machine learning in python  journal of
machine learning research               
poesio  m   alexandrov kabadjov  m   vieira  r   goulart  r     uryupina  o          does
discourse new detection help definite description resolution   in proceedings of the  th international workshop on computational semantics  pp         
poesio  m   uryupina  o   vieira  r   alexandrov kabadjov  m     goulart  r          discoursenew detectors for definite description resolution  a survey and a preliminary proposal  in
harabagiu  s     farwell  d   eds    acl       workshop on reference resolution and its
applications  pp        acl 
potts  c          the logic of conventional implicatures  oxford university press 
   

fide

m arneffe   r ecasens   p otts

potts  c          conventional implicature and expressive content  in maienborn  c   von heusinger 
k     portner  p   eds    semantics  an international handbook of natural language meaning  vol     pp            mouton de gruyter 
pradhan  s   luo  x   recasens  m   hovy  e   ng  v     strube  m          scoring coreference partitions of predicted mentions  a reference implementation  in proceedings of the
  nd annual meeting of the association for computational linguistics  pp        acl 
https   github com conll reference coreference scorers 
pradhan  s   moschitti  a   xue  n   uryupina  o     zhang  y          conll      shared task 
modeling multilingual unrestricted coreference in ontonotes  in joint conference on emnlp
and conll   shared task  pp       acl 
pradhan  s   ramshaw  l   marcus  m   palmer  m   weischedel  r     xue  n          conll     shared task  modeling unrestricted coreference in ontonotes  in proceedings of the
fifteenth conference on computational natural language learning  shared task  pp      
acl 
pradhan  s  s     xue  n          ontonotes  the     solution  in proceedings of human language technologies  the      annual conference of the north american chapter of the association for computational linguistics  companion volume  tutorial abstracts  pp       
acl 
prasad  r   dinesh  n   lee  a   miltsakaki  e   robaldo  l   joshi  a     webber  b          the
penn discourse treebank      in proceedings of the sixth international language resources
and evaluation  pp            european language resources association 
prince  e       a   on the inferencing of indefinite this nps  in webber  b  l   sag  i     joshi 
a   eds    elements of discourse understanding  pp          cambridge university press 
prince  e  f       b   toward a taxonomy of givennew information  in cole  p   ed    radical
pragmatics  pp          academic press 
r development core team         r  a language and environment for statistical computing  r
foundation for statistical computing 
recasens  m   de marneffe  m  c     potts  c          the life and death of discourse entities 
identifying singleton mentions  in human language technologies  the      annual conference of the north american chapter of the association for computational linguistics  pp 
        acl 
recasens  m     hovy  e          a deeper look into features for coreference resolution  in
lalitha devi  s   branco  a     mitkov  r   eds    anaphora processing and applications 
vol       of lecture notes in computer science  pp        springer 
recasens  m     hovy  e          blanc  implementing the rand index for coreference evaluation  natural language engineering                
roberts  c          modal subordination  anaphora  and distributivity  garland 
roberts  c          anaphora in intensional contexts  in lappin  s   ed    the handbook of contemporary semantic theory  pp          blackwell 
rooryck  j          evidentiality  part ii  glot international               
   

fim odeling the l ifespan of d iscourse e ntities

saur  r          a factuality profiler for eventualities in text  ph d  thesis  brandeis university 
schwarz  f          two types of definites in natural language  ph d  thesis  umass amherst 
schwarzschild  r          singleton indefinites  journal of semantics                
simons  m          observations on embedding verbs  evidentiality  and presupposition  lingua 
                 
uryupina  o          high precision identification of discourse new and unique noun phrases 
in proceedings of the   st annual meeting on association for computational linguistics
student research workshop  pp        acl 
uryupina  o          detecting anaphoricity and antecedenthood for coreference resolution  procesamiento del lenguaje natural             
van deemter  k     kibble  r          on coreferring  coreference in muc and related annotation
schemes  computational linguistics                
vieira  r     poesio  m          an empirically based system for processing definite descriptions 
computational linguistics                
vilain  m   burger  j   aberdeen  j   connolly  d     hirschman  l          a model theoretic
coreference scoring scheme  in proceedings of the  th message understanding conference 
pp        morgan kaufman 
walker  m  a   joshi  a  k     prince  e  f   eds            centering in discourse  oxford university press 
wang  l   mccready  e     asher  n          information dependency in quantificational subordination  in von heusinger  k     turner  k   eds    where semantics meets pragmatics  pp 
        elsevier 
ward  g     birner  b          information structure and non canonical syntax  in horn  l  r    
ward  g   eds    the handbook of pragmatics  pp          blackwell publishing ltd 

   

fi