journal of artificial intelligence research               

submitted        published      

natural language inference for arabic using extended tree
edit distance with subtrees
maytham alabbas

maytham alabbas gmail com

department of computer science  university of basrah 
basrah  iraq

allan ramsay

allan ramsay manchester ac uk

school of computer science  university of manchester 
manchester  m    pl  uk

abstract
many natural language processing  nlp  applications require the computation of similarities between pairs of syntactic or semantic trees  many researchers have used tree edit
distance for this task  but this technique suffers from the drawback that it deals with single node operations only  we have extended the standard tree edit distance algorithm to
deal with subtree transformation operations as well as single nodes  the extended algorithm with subtree operations  ted st  is more effective and flexible than the standard
algorithm  especially for applications that pay attention to relations among nodes  e g  in
linguistic trees  deleting a modifier subtree should be cheaper than the sum of deleting
its components individually   we describe the use of ted st for checking entailment
between two arabic text snippets  the preliminary results of using ted st were encouraging when compared with two string based approaches and with the standard algorithm 

   introduction
tree edit distance has been widely used as a component of natural language processing  nlp 
systems that attempt to determine whether one text snippet supports an inference to another
 roughly speaking  whether the first entails the second   with the distance between pairs of
dependency trees being taken as a measure of the likelihood that one entails the other  we
extend the standard algorithm for calculating the distance between two trees by allowing
operations to apply to subtrees  rather than just to single nodes  this extension improves
the performance of our technique for arabic by around    in f score and around    in
accuracy compared with a number of well known techniques  the relative performance
of the standard techniques on our arabic testset replicates the results reported for these
techniques for english testsets  we have also applied our extended version of tree edit
distance  ted st  to the english rte   testset  where it again outperforms the standard
algorithm 
tree edit distance is a generalisation of the standard string edit distance metric  which
measures the similarity between two strings  it has been used to underpin several nlp
applications such as information extraction  ie   information retrieval  ir  and natural
language inference  nli   the edit distance between two trees is defined as the minimum
cost sequence of edit operations to transform one tree to another  there have been numerous
approaches to calculating edit distance between trees  as reported by selkow         tai
c
     
ai access foundation  all rights reserved 

fialabbas   ramsay

        zhang and shasha         klein         demaine  mozes  rossman  and weimann
       and pawlik and augsten         we have chosen to work with zhang shashas
algorithm  zhang   shasha        because the intermediate structures produced by this
algorithm allow us to detect and respond to operations on subtrees  when we refer to the
standard tree edit distance algorithm throughout the rest of this article  we mean zhangshashas algorithm  for which we will use the short form zs ted 
our ultimate goal is to develop an nli system for arabic  alabbas          nli is the
problem of determining whether a natural language hypothesis h can reasonably be inferred
from a natural language premise p  the challenges of nli are quite different from those
encountered in formal deduction  the emphasis is on informal reasoning  lexical semantic
knowledge  and variability of linguistic expression  rather than on long chains of formal
reasoning  maccartney         a more recent  and better known  formulation of the nli
task is the recognising textual entailment challenge  rte   described by dagan and glickman
       as a task of determining  for two text snippets premise p and hypothesis h  whether
      typically  a human reading p would infer that h is most likely true  according to these
authors  entailment holds if the truth of h  as interpreted by a typical language user  can be
inferred from the meaning of p  a popular method that has been used in recent years for such
tasks is the use of tree edit distance  which compares sentence pairs by finding a minimal
cost sequence of editing operations to transform a tree representation of one sentence into a
tree for the other  kouylekov        heilman   smith         approximate tree matching
of this kind allows users to match parts of two trees  rather than demanding a complete
match of every element of each tree  however  one of the main drawbacks of tree edit
distance is that transformation operations are applied solely on single nodes  kouylekov 
       kouylekov and magnini        used the standard tree edit distance  which uses
transformation operations  insert  delete and exchange  solely on single nodes  to check
the entailment between two dependency trees  on the other hand  heilman and smith
       extended the available operations in standard tree edit distance to insert child 
insert parent  delete leaf  delete   merge  relabel node and relabel edge  these
authors also identify three new operations  move subtree  which means move a node x
in a tree t to be the last child on the left right side of a node y in t  s t  y is not
a descendant of x    new root and move sibling  to enable succinct edit sequences for
complex transformation  this extended set of edit operations allows certain combinations
of the basic operations to be treated as single steps  and hence provides shorter  and therefore
cheaper  derivations  the fine grained distinctions between  for instance  different kinds of
insertions also make it possible to assign different weights to different variations on the same
operation  nonetheless  these operations continue to operate on individual nodes rather than
on subtrees  despite its name  even move subtree appears to be defined as an operation
on nodes rather than on subtrees   we have solved this problem by extending the basic
version of the algorithm so that the costs of operations that insert delete exchange subtrees
are derived by some appropriate function of the costs of the operations on their parts 
this makes ted st more effective and flexible than the standard algorithm  especially for
applications that pay attention to relations among nodes  e g deleting a modifier subtree  in
linguistic trees  should be cheaper than the sum of deleting its components individually  
   in particular  for modern standard arabic  msa   when we refer to arabic throughout this article  we
mean msa 

 

finatural language inference for arabic

the rest of the paper is organised as follows  zhang shashas algorithm  zs ted  is
explained in section    section   presents ted st  section   describes dependency trees
matching  dataset preparation is explained in section    the experimental results are
discussed in section    conclusions are given in section   

   zhang shashas ted algorithm
our approach extends zs ted  which uses dynamic programming to provide an o n   
algorithm for finding the optimal sequence of node based edit operations for transforming
one tree into another  this section contains a brief recapitulation of this algorithma more
detailed description is given by bille        
ordered trees are trees in which the left to right order among siblings is significant 
approximate tree matching allows us to match a tree with just some parts of another tree 
there are three operations  namely deleting  inserting and exchanging a node  which can
transform one ordered tree to another  there is a nonnegative real cost associated with each
edit operation  these costs are changed to match the requirements of specific applications 
deleting a node x means attaching its children to the parent of x  insertion is the inverse
of deletion  this means an inserted node becomes a parent of a consecutive sub sequence
in the left to right order of its parent  exchanging a node alters its label  all these editing
operations are illustrated in figure    bille        

 a 

l 

l 

 b 

l 

l 

l 

 b 

l 

l 
l 

figure     a  relabeling the node label  l   l      b  deleting the node labeled  l     
 c  inserting a node labeled l  as the child of the node labeled l     l    

each operation is associated with a cost and is allowed on single nodes only  selecting
a good set of costs for these operations is hard when dealing with complex problems  this
 

fialabbas   ramsay

is because alterations in these costs or choosing a different combination of them can lead to
drastic changes in tree edit distance performance  mehdad   magnini        
in the zs ted algorithm  tree nodes are compared using a postorder traversal  which
visits the nodes of a tree starting with the leftmost leaf descendant of the root and proceeding
to the leftmost descendant of the right sibling of that leaf  the right siblings  and then the
parent of the leaf and so on up the tree to the root  the last node visited will always be
the root  an example of the postorder traversal and the leftmost leaf descendant of a tree is
shown in figure    in this figure  there are two trees  t  with m   nodes and t  with n  
nodes  the subscript for each node is considered the order of this node in the postorder
of the tree  so  the postorder of t  is e f b g c d a and the postorder for t  is g c y z x d a 
the leftmost leaf descendant of the subtrees of t  headed by the nodes e f b g c d a are
              respectively  and similarly the leftmost leaf descendants of g c y z x d a in t 
are               
a 

a 
c 

b 
e 

f 

d 

g 

c 

d 

g 

x 
y 

t 

z 

t 

figure    two trees t  and t  with their postorder traversal 
for all the descendants of each node  the least cost mapping has to be calculated before
the node is encountered  in order that the least cost mapping can be selected right away 
to achieve this  the algorithm pursues the keyroots of the tree  which are defined as a
set that contains the root of the tree plus all nodes having a left sibling  concentrating
on the keyroots is critical to the dynamic nature of the algorithm  since it is the subtrees
rooted at keyroots that allow the problem to be split into independent subproblems of the
same general kind  the keyroots of a tree are decided in advance  permitting the algorithm
to distinguish between tree distance  the distance between two nodes when considered in
the context of their left siblings in the trees t  and t    and forest distance  the distance
between two nodes considered separately from their siblings and ancestors but not from
their descendants   kouylekov         for illustration  the keyroots in each tree in figure  
are marked in bold 
for each node  the computation to find the least cost mapping  the tree distance  between
a node in the first tree and one in the second depends solely on mapping the nodes and their
children  to find the least cost mapping of a node  then  one needs to recognise the least cost
mapping from all the keyroots among its children  plus the cost of its leftmost child  because
the nodes are numbered according to the postorder traversal  the algorithm proceeds in the
following steps  kouylekov          i  the mappings from all leaf keyroots are determined 
 ii  the mappings for all keyroots at the next higher level are decided recursively  and  iii 
the root mapping is found  algorithm   shows the pseudocode of zs ted algorithm  zhang
  shasha         the matrices d and f d are used for recording the results of individual
 

finatural language inference for arabic

subproblems  d is used to store the tree distance between trees rooted at pairs of nodes
in the two trees  and f d is used to store the forest distance between sequences of nodes 
f d is used as a temporary store while the tree edit distance between pairs of keyroots
are being calculated  we have extended the standard algorithm  which computes the cost
of the cheapest edit sequence  so that it also records the edit operations themselves  this
involves adding two new matrices  dpath and fdpath  to hold the appropriate sequences
of edit operationsdpath to hold the edit sequences for trees rooted at pairs of nodes and
fdpath to hold the edit sequences for forests  d and dpath are permanent arrays 
whereas f d and fdpath are reinitialised for each pair of keyroots 
the algorithm iterates over keyroots  and is split into two main stages for each pair of
keyroots  the initialisation phase  lines      deals with the first row and column  where we
assume that every cell in the first row is reached by appending the insert operation i to the
cell to its left and every cell in the first column is reached by appending the delete operation
d to the cell above it  with appropriate costs  this is exactly parallel to the initialisation of
the standard dynamic time warping algorithm for calculating string edit distance  as though
we were treating the task of matching the subsets of the subtrees rooted at t   x  and t   y 
as a string matching problem between the nodes in these two trees as sequences enumerated
in post order 
the second stage  lines       traces the cost and edit sequence for transforming each
sub sequence of the sequence of nodes dominated t   x  to each sub sequence of the sequence
of nodes dominated t   x   by considering whether the nodes in these were reached from the
cell to the left by an insert  or from the cell above by a delete  or by the cell diagonally above
and left by either a match m or an exchange x  there are two cases to be considered
here 
i if the two sequences under consideration are both trees  tested at line      then we know
that we have considered every possible way of exchanging one into the other  and hence
we can record the cost in both f d and d  and the edit sequence in both fdpath and
dpath  in this case  we calculate the cost of moving along the diagonal by inspection
of the two nodes  see figure   for an illustration of this notion 
ii if one or both of the sequences is a forest we retrieve the cost of moving along the diagonal
from dpath  and we just store the cost in f d and the edit sequence in fdpath 
in both cases  we gather the set of  cost  path  pairs that result from considering insert delete exchange operations on the preceding sub sequences  and choose the best such
pair to store in the various arrays  this is again very similar to the corresponding element
of the string edit algorithm  with the added complication that calculating the tree edit costs
and sequences for a pair of keyroots involves calculating the costs and edit sequences for all
pairs of sub sequences of the nodes below those roots  the results for pairs of keyroots are
stored permanently  and are utilised during the calculations for sub sequences at the next
stage 
bille        provides detailed worked examples of the calculation of the costs of transforming one tree into another  figure   shows how fdpath grows as the algorithm iterates
through the keyroots for the trees t  and t  in figure    in this figure  the cells representing
 

fialabbas   ramsay

algorithm   pseudocode for zhang shashas ted algorithm with edit sequences
t  i  j 
ith to jth nodes in the post order enumeration of tree t  t  i  i  is written t  i  
l i 
the leftmost leaf descendant of the subtree rooted at i
k t  
the keyroots of tree t  k t      k  t   k    k with l k      l k  
d i  j 
the tree distance between two nodes t   i  and t   j 
f d t   i  i     t   j  j    
the forest distance from nodes i to i  in t  to nodes j to j  in t 
dp at h i  j 
edit sequence for trees rooted at two nodes t   i  and t   j 
f dat h t   i  i     t   j  j     edit sequence for forests covered by nodes i to i  in t  to nodes j to j  in t 
 t   i    
cost of deleting the ith node from t 
   t   j  
cost of inserting the jth node of t  into t 
 t   i   t   j  
cost of exchanging the ith node of t  with the jth node of t 
m  n
the number of nodes in t  and t  respectively
best
choose the best cost and path from a set of options
   for x    to  k   t     do
  
for y    to  k   t     do
  
f d       
  
f dp at h       
  
for i  l   x  to x do
  
f d t   l   x   i      f d t   l   x   i          t   i    
  
f dp at h t   l   x   i      f dp at h t   l   x   i         d
  
end for
  
for j  l   y  to y do
   
f d   t   l   y   j    f d   t   l   y   y          t   j  
   
f dp at h   t   l   y   j    f dp at h   t   l   y   y       i
   
end for
   
for i  l   x  to x do
   
for j  l   y  to y do
   
if  l   i     l   x  and l   j     l   y   then
   
cost  path  best  f d t   l   x   i     t   l   y   j      t   i     
   
f dp at h t   l   x   i     t   l   y   j     d  
   
 f d t   l   x   i   t   l   y   j          t   j   
   
f dp at h t   l   x   i   t   l   y   j       i  
   
 f d t   l   x   i     t   l   y   j        t   i   t   j    
   
f dp at h t   l   x   i     t   l   y   j       m x  
   
f d t   l   x   i   t   l   y   j    cost
   
d i  j   cost
   
f dp at h t   l   x   i   t   l   y   j    path
   
dp at h i  j   path
   
else
   
cost  path  best  f d t   l   x   i     t   l   y   j      t   i     
   
f dp at h t   l   x   i     t   l   y   j     d  
   
 f d t   l   x   i   t   l   y   j          t   j   
   
f dp at h t   l   x   i   t   l   y   j       i  
   
 f d t   l   x   i     t   l   y   j       d i  j   
   
f dp at h t   l   x   i     t   l   y   j       dp at h i  j   
   
f d t   l   x   i   t   l   y   j    cost
   
f dp at h t   l   x   i   t   l   y   j    path
   
end if
   
end for
   
end for
   
end for
    end for
    return d n  m   dp at h n  m 

 

finatural language inference for arabic

i   j  

i j  

i   j
x m

d

i

i j

figure    the edit operation direction used in our algorithm  each arc that implies an edit
operation is labeled  i for an insertion  d for deletion  x for exchanging and
m for no operation  matching  

the optimal sequence of edit operations that transform t  into t  are highlighted in bold 
with the final optimal path shown in the last cell  at final row and column  
t 
e
f
b
g
c
d
a

t 
d
dd
ddd
dddd
ddddd
dddddd
ddddddd

g
i
x
xd
xdd
dddm
dddmd
dddmdd
dddmddd

c
ii
xi
xid
xdx
dddmi
dddmm
dddmmd
dddmmdd

y
iii
iix
xix
xdxi
xdxx
dddmmi
dddmmx
dddmmxd

z
iiii
iiix
iixx
iixxd
xdxxi
dddmmii
dddmmxi
dddmmxid

x
iiiii
iiixi
xiiix
iixxx
xdxixi
dddmmiii
dddmmxii
dddmmxiid

d
iiiiii
iiixii
xiiiix
iixxxi
xdxixii
xdxixix
dddmmiiim
dddmmiiimd

a
iiiiiii
iiixiii
xiiiixi
iixxxii
iixxxiid
xdxixixi
dddmmiiimi
dddmmiiimm

fdpath

figure    computing the optimal path for the trees in figure   
the mapping between two trees can be found from the final sequence of edit operations
by mapping the nodes corresponding to match operation m only 
the final distance is   which represents the final values  at final row and column  in d  
the last value in dpath represents the final sequence of edit operations  namely dddmmiiimm  according to this path  we can define an alignment between two postorder trees 
the alignment between two trees t  and t  is obtained by inserting a gap symbol  i e    
into either t  or t    according to the type of edit operation  so that the resulting strings s  
and s   are the same length as the sequence of edit operations  the gap symbol is inserted
into s   when the edit operation is delete  d   whereas it is inserted in s   when the edit
operation is insert  i   otherwise  the nodes of t  and t  are inserted into s   and s  
respectively  the following is an optimal alignment between t  and t   
s   
s   

e
d
 

f
d
 

b
d
 

g
m
g

c
m
c

 
i
y

 
i
z

 
i
x

d
m
d

a
m
a

   for simplicity here  we assume that the each single operation will cost   except that matching will cost
   as described by zhang and shasha        

 

fialabbas   ramsay

this means 
d 
d 
d 
m 
m 
i 
i 
i 
m 
m 

delete  e  from t 
delete  f   from t 
delete  b  from t 
leave  g  without change
leave  c  without change
insert  y  into t 
insert  z   into t 
insert  x   into t 
leave  d  without change
leave  a  without change

the final mapping between t  and t  is shown in figure    for each mapping figure
the insertion  deletion  matching and exchanging operations are shown with single  double 
single dashed and double dashed outline respectively  the matching nodes  or subtrees  are
linked with dashed arrows 

a 
c 

b 
e 

f 

a 
d 

g 

c 

d 

g 

x 
y 

t 

z 

t 

figure    zs ted  mapping between t  and t   

   extended ted with subtree operations
the main weakness of the zs ted algorithm is that it is not able to perform transformations
on subtrees  i e  delete subtree  insert subtree and exchange subtree   the output of zsted is the lowest cost sequence of operations on single nodes  we extend this to find the
lowest cost sequence of operations on nodes and subtrees  ted st  as follows 
   run zs ted and compute the standard alignment from the results  algorithm    
   go over the alignment and group subtree operations  where a sequence of identical
operations applies to a set of nodes comprising a subtree  they are replaced by a
 

finatural language inference for arabic

single operation  whose cost is determined by some appropriate function of the costs
of the individual nodes  algorithm     a variety of functions could be applied here 
depending on the application  when using the algorithm for textual entailment we
use the costs in figure    which are derived from those used by punyakanok  roth 
and yih         but for illustration in the current section we will simply take the cost
of a subtree operation to be half the sum of the costs of the individual operations that
make it up 
it should be noted here that while we apply this technique to modify zhang shashas
o n    algorithm  it could also be applied to any other algorithm for finding tree edit distance 
e g  kleins o n  logn   algorithm  klein         demaine et al  o n    algorithm  demaine 
mozes  rossman    weimann        or pawlik and augsten o n    algorithm  pawlik  
augsten         since the extension operates on the output of the original algorithm  the
additional time cost of o n    is negligible since it is less than the time cost for any available
tree edit distance algorithm 
    find a sequence of subtree edit operations
extending zs ted to cover subtree operations will give us more flexibility when comparing
trees  especially linguistic trees   the key to this algorithm is that we have to find maximal
sequences of identical edit operations which correspond to subtrees  a sequence of nodes
in postorder corresponds to a subtree if the following conditions are satisfied   i  the first
node is a leaf  and  ii  the leftmost sibling of the last node in the sequence  i e  the root
of a subtree  is the same as the first node in the sequence  these two conditions can be
checked in constant time  since the leftmost sibling of a node can determined for each node
in advance  we can hence find maximal sequences corresponding to subtrees by scanning
forwards through the sequence of node operations to find sequences of identical operations 
and then scanning backwards through such a sequence until we find the point at which it
covers a subtree  this involves potentially o n    stepsn forward steps to find sequences of
identical operations  and then possibly n   backward steps each time to find sub sequences
corresponding to subtrees  as an example  the sequence of nodes e f b in tree t  in figure  
is a subtree because e is a leaf and the leftmost of the last node b is    which represents
the first node e  on the other hand  the sequence of nodes g c d in the same tree is not a
subtree because g is a leaf  but the leftmost of the last node d is    which represents itself 
not the first node g 
algorithm   contains the pseudocode to find the optimal sequence of single and subtree
edit operations for transforming t  into t    ep    l   d  i  x  m  in this algorithm
is an optimal sequence of node edits for transforming t  into t    obtained by applying the
technique in section    and s   and s   are the alignments for t  and t  obtained after
applying this sequence of node edits 
as shown in algorithm    to find the optimal single and subtree edit operations sequence
that transforms t  into t    each maximal sequence of identical operations is checked to see
whether it contains subtree s  or not  checking whether such a sequence corresponds to a
subtree depends on the type of edit operation  according to the following rules   i  if the
operation is d  the sequence is checked on the first tree   ii  if the operation is i  the
sequence is checked on the second tree  and  iii  otherwise  the sequence is checked on both
 

fialabbas   ramsay

algorithm   pseudocode to find subtree edit operations
e
l
s   s 

the sequence of edit operations that transform tree t  into tree t    ep    l   d i x m 
the length of the sequence of edit operations e
the optimal alignment for t  and t  respectively  when the length of s     s     l

   repeat
  
eroot  el
  
f l
  
repeat
  
while  f    and ef      eroot  do
  
f f  
  
end while
  
if  f    l  then
  
ll 
   
eroot  el
   
f l
   
end if
   
until  f   l and f    and ef      eroot  or  l     
   
f   f
   
while  f   l  do
   
while  f   l  do
   
issubtree  true
   
while  f   l and issubtree  do
 
   
if  eroot  d and sf    sl
is subtree  or
 
 
   
 eroot  i and sf   sl is subtree  or
 
 
   
  eroot in  x m   and  sf    sl
and sf    sl
are subtrees   then
   
replace ef   el  with  
   
lf  
   
f  f 
   
else
   
issubtree  f alse
   
end if
   
end while
   
f f   
   
end while
   
l l 
   
f  f 
   
end while
   
l  f    
    until  l    
    return e

trees  after that  if the sequence of operations corresponds to a subtree  then all the symbols
of the sequence are replaced by   except the last one  which represents the root of the
subtree   otherwise  checking starts from a sub sequence of the original  as explained below 
for instance  let us consider eh        et   where    h   l      t  l  h   t  is a sequence of
the same edit operation  i e  ek h  t   d  i  x  m   let us consider h    h  we firstly
check nodes sh         st  and sh         st  to see whether or not they are the heads of subtrees  if
ek is d  the nodes sh         st  are checked  if it is i the nodes sh         st  are checked  and
otherwise  the nodes sh         st  and sh         st  are checked  all edit operations eh        et 
are replaced by   when this sequence corresponds to a subtree  then  we start checking
from the beginning of another sequence from the left of the subtree eh        et   i e  t   h    
  

finatural language inference for arabic

otherwise  the checking is applied with the sequence starting from the next position  i e 
h   h     the checking is continued until h   t  after that  when the  t  h  sequences that
start with different positions and end with t position do not contain a subtree  the checking
starts from the beginning with the new sequence  i e  h   h  and t   t     the process is
repeated until h   t 
to explain how the subtree operations are applied  let us consider the two trees t  and
t  in figure   
according to ted st  the cost is   and the sequence of operation is as follows  there
is a sequence of d  m and i in the result  these sequences consist of three subtrees
 i e  the three deleted nodes  the first two matched nodes and the three inserted nodes  
ddd mm iii mm  so  the final result is    d  m   i mm  this means 
  d 
 m 
  i 
m 
m 

delete subtree  e f b  from t 
leave subtree  g c  without change
insert subtree  y z x   into t 
leave  d  without change
leave  a  without change

the final mapping between t  and t  obtained using ted st is shown in figure   

a 
c 

b 
e 

f 

a 
d 

g 

c 

d 

g 

x 
y 

t 

z 

t 

figure    ted st  mapping between t  and t   

   matching dependency trees
as mentioned above  our main goal is to design a textual entailment  te  system for arabic
to check whether one text snippet  i e  premise p  entails another text  i e  hypothesis h  
to match p and h dependency tree pairs effectively  we use ted st  this enables us to
find the minimum edit operations to transform one tree to another  this allows us to be
sensitive to the fact that the links in a dependency tree carry linguistic information about
relations between complex units  and hence to ensure that we are paying attention to these
relations when we compare two trees  for instance  this enables us to pay attention to the
  

fialabbas   ramsay

fact that operations involving modifiers  in particular  should be applied to the subtree as
a whole rather than to its individual elements  thus  we transform tree d  to tree d  in
figure   by deleting in the park in a single operation  removing the modifier as a whole 
rather than three operations removing in  the and park one by one  using the costs
in figure   as an initial test for edit operations in our experiments  these costs are an
updated version of the costs used by punyakanok et al           these authors found that
using tree edit distance gives better results than bag of word scoring methods  when they
applied them for question answering  
saw

saw
i

i

man

in

the

park

man
the

the
d 

d 

figure    two dependency trees  d  and d   

by using the costs in figure    the cost of transferring d  into d  according to zs ted
is     i e  one stop word the     and two words        whereas according to ted st
operations it is    therefore  it is easy to decide that d  entails d    whereas the reverse is not
true  we also exploited the subset superset relations encoded by arabic wordnet  awn 
 black  elkateb  rodriguez  alkhalifa  vossen  pease    fellbaum        when comparing
items in a tree  roughly speaking  if comparing one tree to another requires us to swap
two lexical items  we will be happier doing so if the item in the source tree is a synonym or
hyponym of the one in the target treesince wombat is a hyponym of animal  swapping
wombat in a premise such as i saw a wombat at the zoo for animal in i saw an animal
at the zoo is a truth preserving exchange 
approaches that make use of lexical relations of this kind have to cope with the fact that
words often have multiple meanings  we follow hobbs        in assuming that if w  has a
sense which is a hyponym of some sense of w  then a sentence involving w  will entail a
similar sentence involving w  as shown in     
    p 
h 

i saw a peach at yesterdays party 
i saw a very attractive woman at yesterdays party 

   the stop words here are a list that contains some of the most common arabic words  e g  the particle
                 an almdyr mwl  the director is indeed busy
      an indeed   for instance         
           almdyr mwl  the director is busy 
entails        
   the transcription of arabic examples in this document follows habash soudi buckwalter  hsb  transliteration scheme  habash  soudi    buckwalter        for transcribing arabic symbols 

  

finatural language inference for arabic

cost

single node

subtree  more than one node 

delete 

if x is a stop word then cost is   
else cost is  
if a y is a stop word then cost is
  
else cost is    
if x is subsumed by y cost is   
elseif x is a stop word cost is   
elseif y is subsumed by  or is an
antonym of  a x then cost is    
else cost is   

 

insert 

exchange 

double the sum of the costs of its parts

if s  is identical to s  then cost is  
else half the sum of the costs of its parts

figure    edit operation costs 
in   p   for instance  the word peach is ambiguous   a shade of pink tinged with yellow
 hypernym  pink  or downy juicy fruit with sweet yellowish or whitish flesh  hypernym 
drupe  edible fruit  stone fruit  or a very attractive or seductive looking woman  hypernym 
adult female  women  or cultivated in temperate regions  hypernym  fruit tree   in the
context of   h   however  any human reader would assume that the second interpretation of
peach was intended  despite the fact that it is in general a fairly unusual usage 
this reflects the widely accepted view that contextual information is the key to lexical
disambiguation  within the rte task  the premise provides the context for disambiguation
of the hypothesis  and the hypothesis provides the context for disambiguation of the premise 
almost any human reader would  for instance  accept that   p  entails   h   despite the
potential ambiguity of the word bank 
    p 
h 

my money is all tied up at the bank 
i cannot easily spend my money 

   dataset preparation
in order to train and test our te system for arabic  we need an appropriate dataset  to
our knowledge  no such datasets are available for arabic  so we have had to develop one 
we have followed one of the procedures used for collecting the premise hypothesis pairs in
the rte tasks  with a slight alteration  the premises in rte were collected from a variety
of sources  e g  newswire text  they contain one or two sentences and tend to be fairly long
 e g  averaging    words in rte      words in rte      words in rte  and    words in
rte    in contrast  the hypotheses are quite short single sentences  averaging    words in
rte     words in rte  and   words in rte  and rte    which were manually constructed
for each premise  the first three rte challenges were presented as a binary classification
task yes or no with balanced numbers of yes and no problems  beginning with rte  
there were three way classifications  yes  no  or contradict  to distinguish cases in which
h contradicts p from those in which h is compatible with  but not entailed by p   in our
   see sages dictionary online  http   www sequencepublishing com thesageonline php  wordnet also
provides all these senses  and more  for peach 

  

fialabbas   ramsay

dataset  we do not want to produce a set of p h pairs by handpartly because doing so is a
lengthy and tedious process  but more importantly because hand coded datasets are liable
to embody biases introduced by the developer  if the dataset is used for training the system 
then the rules that are extracted will be little more than an unfolding of information explicitly
supplied by the developers  if it is used for testing then it will only test the examples that
the developers have chosen  which are likely to be biased  albeit unwittingly  towards the
way they think about the problem 
our set of arabic p h pairs for the te task was created by a semi automatic technique
through two stages  the first stage  section      is responsible for automatically collecting
p h pairs from news websites  while the second stage  section      uses an online annotation
system that allows annotators to annotate our collected pairs manually  both stages are
explained in detail below 
    collecting p h pairs
we collected candidate p h pairs automatically by the so called headline lead paragraph
technique  burger   ferro        from the web  e g  from newspaper corpora  pairing the
first paragraph of article  as p  with its headline  as h   this is based on the observation
that a news articles headline is very often a partial paraphrase of the first paragraph of this
article  conveying thus a comparable meaning  we use an updated version of the headlinelead paragraph strategy to improve the quality of the p h pair 
the key idea here is that we pose queries to a search engine and automatically filter the
responses for text snippets that might entail the query  these pairs are then manually annotated for entailment non entailment  but the texts themselves are automatically collected
from freely occurring natural texts  this eliminates the possibility  indeed likelihood  of
unconscious bias that is introduced if the hypotheses are manually generated 
we built a corpus of p h pairs by using headlines from the websites of arabic newspapers
and tv channels as queries to be input to google via the standard google api  and then
selecting the first paragraph  which usually represents the most related text snippet s  in
the article with the headline  burger   ferro         of each of the first    returned pages 
this technique produces a large number of potential pairs without any bias in either the
premises or the hypotheses  to improve the quality of the pairs that resulted from the query 
we use two conditions to filter the results   i  the length of a headline must be at least five
words  to avoid very small headlines  and  ii  fewer than     of the words in the headline
should appear in the premise  to avoid having very similar sentences 
the problem here is that if p and h are very similar then there would be very little to
learn from them if they were used in the training phase of a te system  and they would
be almost worthless as a test pairvirtually any te system will get such a pair right  so
they will not serve as a discriminatory test pair  we therefore eliminate excessively similar
p h pairs from both training and testing  which we assess in terms of the number of shared
uncommon words 
in order to overcome this problem  we matched headlines from one source with stories
from another  major stories are typically covered by a range of outlets  usually with variations in emphasis or wording  stories from different sources can be linked by looking for
common words in the headlinesit is unlikely that there will be two stories about  for in  

finatural language inference for arabic

stance  neanderthals in the news at the same time  so very straightforward matching based
on low frequency words and proper names is likely to find articles about the same topic 
the terminology and structure of the first text snippets of these articles  however  are likely
to be quite different  thus using a headline from one source and the first text snippet from
an article about the same story but from another source is likely to produce p h pairs which
are not unduly similar  we can therefore link a headline from one newspaper with related
sentences from another 
    annotating p h pairs
the pairs that are collected in the first stage still have to be marked up by human annotators 
but at least the process of collecting them is as nearly bias free as possible  these pairs cover
a number of subjects such as politics  business  sport and general news  the annotation is
performed by eight expert and non expert human annotators to identify the different pairs as
positive entailment examples yes  where p is judged to entails h  and as negative examples
no  where entailment does not hold  those annotators follow nearly the same annotation
guidelines as those used for building the rte task dataset  dagan  glickman    magnini 
      
each pair was annotated by three annotators  the inter annotator agreement  where all
annotators agree  is around     compared with     where each annotator agrees with at
least one co annotator  this suggests that the annotators found this is a difficult task  the
fact that there was only     agreement when the annotations produced by three independent
annotators are taken into account sets an upper bound on what it is reasonable to expect of
an automatic system for carrying out this task  if human annotators can only agree in about
three quarters of the cases  then it is unlikely that a computer based system can achieve
much more than     agreement with any given pair of annotators  

   experiments
to check the effectiveness of ted st  we used it to check the entailment between p h
arabic pairs of text snippets and compared its results with two string based approaches
 bag of words and levenshtein distance  and zs ted on the same set of pairs  checking
whether one arabic text snippet entails another  however  is particularly challenging because
arabic is more ambiguous than most languages  such as english  for instance  arabic is
written without diacritics  short vowels   often leading to multiple ambiguities  this makes
morphological analysis very difficult  i e  a single written form may easily correspond to as
many as ten different lexemes  see alabbas   ramsay      a      b      a      c   the
preliminary testing dataset contains     pairs  binary annotated as yes and no  a      
split  using the technique explained in section    the distribution of these pairs over p length
is summarised in table    when the h average length is around    words and the average of
common words between p and h is around   words  the average length of sentence in this
dataset is    words per sentence  with some sentences containing     words 
   the dataset  including the dependency tree analysis in conll format  is available in the online appendices to this article or from http   www cs man ac uk  ramsay arabicte 

  

fialabbas   ramsay

ps length
   
     
     
   
total

 pairs
   
   
  
 
   

yes
  
   
  
 
   

no
  
   
  
 
   

table    distribution of sentence lengths in the testset 

in order to check the entailment between p h pairs  we follow three steps  first  each
sentence is preprocessed by a tagger and a parser in order to convert both elements of the p h
pair to dependency trees  a dependency tree is a tree where words are vertices and syntactic
relations are dependency relations  each vertex therefore has a single parent  except the
root of the tree  a dependency relation holds between a dependent  i e  a syntactically
subordinate vertex  and a head  i e  another vertex on which it is dependent  thus the
dependency structure is represented as a head dependent relation between vertices that are
classified by dependency types such as sbj subject  obj object  att attribute  etc 
we have carried out a number of experiments with state of the art taggers such as
amira  diab         mada  habash  rambow    roth        and an in house maximumlikelihood  mxl  tagger  ramsay   sabtan        and parsers such as maltparser  nivre 
hall  nilsson  chanev  eryigit  kbler  marinov    marsi        and mstparser  mcdonald  lerman    pereira          these experiments show in particular that merging mada
     accuracy  with mstparser gives better results  around     for labelled accuracy 
than the other tagger parser combinations  alabbas   ramsay      b   we therefore use
mada mstparser in the current experiments 
after converting p h pairs to dependency trees  we matched these dependency trees using
the zs ted and ted st algorithms  with two string based algorithms  bag of words and
levenshtein distance  to provide a baseline  the tree edit distance algorithms used the edit
operation costs defined in figure   to find the cost of matching between p h pairs  the
bag of words here measures the similarity between p and h as a number of common words
between them  either in surface forms or lemma forms   divided by the length of h  for all
four algorithms we use awn as a lexical resource in order to take account of synonymy and
hyponymy relations when calculating the cost of an edit 
we carried out two kinds of experiments using these algorithms  the first was a simple
yes no experiment  using a single threshold to decide whether the premise was similar enough
to the hypothesis for it to be safe to say that it entailed it  and the second with two thresholds
so that we could say yes dont know no  the results of these experiments are given below 

   these parsers are data driven dependency parsers  for arabic they are usually trained on an arabic
dependency treebank  such as prague arabic dependency treebank  padt   smr  bielicky  kouilov 
krmar  haji    zemnek         or on some version of the penn arabic treebank  patb   maamouri
  bies        that has been converted to dependency trees  scoring of such parsers is a matter of counting
dependency links 

  

finatural language inference for arabic

    binary decision  yes and no 
p entails h when the cost of matching is less  more in case of bag of words  than a threshold 
the results of these experiments  in terms of precision  p   recall  r  and f score  f  for
yes class and overall accuracy  are shown in table    this table shows the substantial
improvement obtained by using ted st over the bag of words  f score for ted st is
around      times the f score for bag of words  and accuracy is about      times better 
and zs ted  around      times better in f score and      times better in total accuracy  
method
bag of words
levenshtein distance
zs ted
ted st

pyes
     
     
     
     

ryes
     
     
     
     

fyes
     
     
     
     

accuracy
     
     
     
     

table    performance of ted st compared with the string based algorithms and zs ted 
binary decision 
although we are primarily interested in arabic  we have carried out parallel sets of experiments on the english rte  testset  using the princeton english wordnet  pwn  as a
resource for deciding whether a word in the premise may be exchanged for one in the hypothesis  because the tree edit distance algorithms work with dependency tree analyses of the input texts  we have used a set that have been analysed using minipar  lin         downloaded
from http   u cs biu ac il  nlp rte  datasets rte  preprocessed datasets html 
the rte  testset contains around     p h pairs  but a number of the minipar analyses have
multiple heads and hence do not correspond to well formed trees  and there are also a
number of cases where the segmentation algorithm that was used produces multi word expressions  after eliminating problematic pairs of this kind we are left with     pairs  split
evenly between positive and negative examples  since we are mainly concerned here with
the difference between zs ted and ted st  we have omitted the levenshtein distance
and have simply kept the basic bag of words algorithm as a baseline  previous authors
have shown that tree edit distance consistently outperforms string based approaches on this
dataset  and there is no need to replicate that result here 
method
bag of words
zs ted
ted st

pyes
     
     
     

ryes
     
     
     

fyes
     
     
    

accuracy
     
     
     

table    performance of ted st compared with the simple bag of words and zs ted 
binary decision  rte  dataset 
the pattern in table   is similar to that in table    zs ted is better than bag of words 
ted st is a further improvement over zs ted  most experiments on textual entailment
tasks only report accuracy  in certain situations it may be more important to have decisions
that are trustworthy  high precision  as in table    or to be sure that you have captured as
  

fialabbas   ramsay

many positive examples as possible  high recall    as in table     or to have a good balance
between these  high f score   it is easy to change the balance between precision and recall 
simply by changing the threshold that is used for determining whether it is safe to say
that p entails hwe could have chosen thresholds for table   that increased the precision
and decreased the recall  so that the results more closely matched table    the key point
here is that in both sets of experiments  the f scores improve as we move from string based
measures to zs ted and then again when we use ted st  and that they are remarkably
similar for the two datasets  despite the fact that they were collected by different means 
are in different languages  and are parsed using different parsers 
    making a three way decision  yes  no and unknown 
for this task we use two thresholds  one to trigger a positive answer if the cost of matching is
lower than the lower threshold  exceeds the higher one for the bag of words algorithm  and
the other to trigger a negative answer if the cost of matching exceeds the higher one  mutatis
mutandis for bag of words   otherwise  the result will be unknown  the reason for making
a three way decision is to drive systems to make more precise distinctions  note that we
are not distinguishing here between  h entails p  h and p are compatible  h contradicts p  
but between  h entails p  i dont know whether h entails p  h does not entail p   this is
a more subtle distinction  reflecting the systems confidence in its judgement  but it can be
extremely useful when deciding how to act on its decision 
the results of this experiment  in terms of precision  p   recall  r  and f score  f  
are shown in table    again  it shows the large improvement of using ted st over the
bag of words  f score is around      times better  and zs ted  f score around      times
better  
method
bag of words
levenshtein distance
zs ted
ted st

p
     
     
     
     

r
     
     
     
     

f
     
     
     
     

table    performance of ted st compared with string based algorithms and zs ted 
three way decision 
the scores for the three way decision on the rte  dataset are lower than for our arabic
dataset  but again ted st outperforms zs ted on all three measures 

   conclusion
we have presented here an extended version  ted st  of tree edit distance that solved
one of the main drawbacks of standard tree edit distance  which is that it only supports
   this might be useful  for instance  with ted st being used as a low cost filter in a question answering
system  where the results of a query to a search engine might be filtered by ted st before being passed
to a system employing full semantic analysis and deep reasoning  which are high precision but are also
very time consuming 

  

finatural language inference for arabic

method
bag of words
zs ted
ted st

p
     
     
     

r
     
     
     

f
     
     
     

table    performance of ted st compared with the simple bag of word and zs ted 
three way decision  rte  dataset 

edit operations  i e  delete  insert and exchange  on single nodes  ted st deals with
subtree transformation operations as well as operations on single nodes  this leads to useful
improvements over the performance of the standard algorithm for determining entailment 
the key here is that subtrees tend to correspond to single information units  by treating
operations on subtrees as less costly than the corresponding set of individual node operations 
ted st concentrates on entire information units  which are a more appropriate granularity
than individual words for considering entailment relations 
the current findings  while preliminary  are quite encouraging  the fact that the results
on our original testset  particularly the improvement in f score  were replicated for a testset
where we had no control over the parser that was used to produce dependency trees from
the p h pairs provides some evidence for the robustness of the approach  we anticipate
that in both cases having a more accurate parser  our parser for arabic attains around    
accuracy on the patb  minipar is reported to attain about     on the suzanne corpus 
would improve the performance of both zs ted and ted st 
we are currently experimenting with different scoring algorithms for zs ted and ted 
st  the performance of any variant of tree edit distance depends critically on the costs for
the various operations  and on the thresholds that are used for deciding whether h entails
p  and we are therefore investigating the use of various optimisation algorithms for choosing
these weights and thresholds  we also intend to use other arabic lexical resources  such
as openoffice arabic dictionary and ms word arabic dictionary  to provide us with more
information about relations between words  because the information in awn  while very
useful  is sparse in comparison to pwn  habash        

acknowledgments
we would like to thank the reviewers for their valuable comments  in particular the reviewer
who suggested evaluating the approach on an english dataset as well as our arabic one 
the extra work has provided support for our belief in the robustness of the approach to a
degree that we did not anticipate 
we would like to extend our thanks to our annotators for the time and effort they have
put into annotating our experimental dataset  maytham alabbas owes his deepest gratitude
to iraqi ministry of higher education and scientific research for financial support in his
phd study  allan ramsays contribution to this work was partially supported by the qatar
national research fund  grant nprp                     
  

fialabbas   ramsay

references
alabbas  m          arbte  arabic textual entailment  in proceedings of the second student
research workshop associated with ranlp       pp        hissar  bulgaria  ranlp
     organising committee 
alabbas  m     ramsay  a       a   evaluation of combining data driven dependency
parsers for arabic  in proceeding of  th language   technology conference  human
language technologies  ltc     pp          pozna  poland 
alabbas  m     ramsay  a       b   evaluation of dependency parsers for long arabic
sentences  in proceeding of international conference on semantic technology and
information retrieval  stair     pp          putrajaya  malaysia  ieee 
alabbas  m     ramsay  a       a   arabic treebank  from phrase structure trees to dependency trees  in meta research workshop on advanced treebanking at the  th
international conference on language resources and evaluation  lrec   pp       
istanbul  turkey 
alabbas  m     ramsay  a       b   combining black box taggers and parsers for modern standard arabic  in federated conference on computer science and information
systems  fedcsis        pp         wroclaw  poland  ieee 
alabbas  m     ramsay  a       c   improved pos tagging for arabic by combining diverse
taggers  in proceedings of  th artificial intelligence applications and innovations
 aiai   pp          halkidiki  greece  springer 
bille  p          a survey on tree edit distance and related problems  theoretical computer
science                    
black  w   elkateb  s   rodriguez  h   alkhalifa  m   vossen  p   pease  a     fellbaum  c 
        introducing the arabic wordnet project  in proceedings of the  rd international wordnet conference  gwc      pp          jeju island  korea 
burger  j     ferro  l          generating an entailment corpus from news headlines  in
proceedings of the acl workshop on empirical modeling of semantic equivalence and
entailment  pp        ann arbor  michigan  usa  association for computational
linguistics 
dagan  i     glickman  o          probabilistic textual entailment  generic applied modeling of language variability  in pascal workshop on learning methods for text
understanding and mining  pp        grenoble  france 
dagan  i   glickman  o     magnini  b          the pascal recognising textual entailment challenge  in quionero candela  j   dagan  i   magnini  b     dalch buc  f 
 eds    machine learning challenges  evaluating predictive uncertainty  visual object classification  and recognising tectual entailment  vol       of lecture notes in
computer science  pp          springer berlin  heidelberg 
demaine  e   mozes  s   rossman  b     weimann  o          an optimal decomposition
algorithm for tree edit distance  acm transactions on algorithms  talg         
        
  

finatural language inference for arabic

diab  m          second generation tools  amira       fast and robust tokenization  pos
tagging  and base phrase chunking  in proceedings of the  nd international conference
on arabic language resources and tools  pp          cairo  eygpt  the medar
consortium 
habash  n          introduction to arabic natural language processing  synthesis lectures
on human language technologies  morgan   claypool publishers 
habash  n   rambow  o     roth  r          mada tokan  a toolkit for arabic tokenization  diacritization  morphological disambiguation  pos tagging  stemming and
lemmatization  in proceedings of the  nd international conference on arabic language
resources and tools  cairo  eygpt  the medar consortium 
habash  n   soudi  a     buckwalter  t          on arabic transliteration  arabic computational morphology       
heilman  m     smith  n          tree edit models for recognizing textual entailments  paraphrases  and answers to questions  in human language technologies  the      annual
conference of the north american chapter of the association for computational linguistics  pp            los angeles  california  usa  association for computational
linguistics 
hobbs  j  r          the handbook of pragmatics  chap  abduction in natural language
understanding  pp          blackwell publishing 
klein  p          computing the edit distance between unrooted ordered trees  in proceedings of the  th annual european symposium on algorithms  esa      pp        
venice  italy  springer verlag 
kouylekov  m          recognizing textual entailment with tree edit distance  application
to question answering and information extraction  ph d  thesis  dit  university of
trento  italy 
kouylekov  m     magnini  b          recognizing textual entailment with tree edit distance algorithms  in proceedings of the st challenge workshop recognising textual
entailment  pp        southampton  uk 
lin  d          dependency based evaluation of minipar  in workshop on the evaluation of
parsing systems  pp          springer 
maamouri  m     bies  a          developing an arabic treebank  methods  guidelines 
procedures  and tools  in proceedings of the workshop on computational approaches
to arabic script based languages  pp      geneva  switzerland 
maccartney  b          natural language inference  ph d  thesis  department of computer
science  stanford university  usa 
mcdonald  r   lerman  k     pereira  f          multilingual dependency parsing with a
two stage discriminative parser  in   th conference on computational natural language learning  conll x   new york  usa 
mehdad  y     magnini  b          optimizing textual entailment recognition using particle
swarm optimization  in proceedings of the      workshop on applied textual inference  textinfer      pp        suntec  singapore  association for computational
linguistics 
  

fialabbas   ramsay

nivre  j   hall  j   nilsson  j   chanev  a   eryigit  g   kbler  s   marinov  s     marsi 
e          maltparser  a language independent system for data driven dependency
parsing  natural language engineering                 
pawlik  m     augsten  n          rted  a robust algorithm for the tree edit distance 
proceedings of the vldb endowment                
punyakanok  v   roth  d     yih  w          natural language inference via dependency
tree mapping  an application to question answering  computational linguistics    
    
ramsay  a     sabtan  y          bootstrapping a lexicon free tagger for arabic  in proceedings of the  th conference on language engineering  esolec       pp         
cairo  egypt 
selkow  s          the tree to tree editing problem  information processing letters        
       
smr  o   bielicky  v   kouilov  i   krmar  j   haji  j     zemnek  p          prague
arabic dependency treebank  a word on the million words  in proceedings of the workshop on arabic and local languages  lrec        pp        marrakech  morocco 
tai  k          the tree to tree correction problem  journal of the acm  jacm          
       
zhang  k     shasha  d          simple fast algorithms for the editing distance between
trees and related problems  siam journal of computing                   

  

fi