journal of artificial intelligence research                  

submitted        published      

datalog  ontology consolidation
cristhian ariel d  deagustini
mara vanina martnez
marcelo a  falappa
guillermo r  simari

cadd cs uns edu ar
mvm cs uns edu ar
mfalappa cs uns edu ar
grs cs uns edu ar

ai r d lab   institute for computer science and engineering  icic 
consejo nacional de investigaciones cientficas y tecnicas  conicet 
universidad nacional del sur  uns   alem      
 b    cpb  baha blanca  argentina 

abstract
knowledge bases in the form of ontologies are receiving increasing attention as they
allow to clearly represent both the available knowledge  which includes the knowledge in itself and the constraints imposed to it by the domain or the users  in particular  datalog 
ontologies are attractive because of their property of decidability and the possibility of
dealing with the massive amounts of data in real world environments  however  as it is the
case with many other ontological languages  their application in collaborative environments
often lead to inconsistency related issues  in this paper we introduce the notion of incoherence regarding datalog  ontologies  in terms of satisfiability of sets of constraints  and
show how under specific conditions incoherence leads to inconsistent datalog  ontologies 
the main contribution of this work is a novel approach to restore both consistency and
coherence in datalog  ontologies  the proposed approach is based on kernel contraction
and restoration is performed by the application of incision functions that select formulas to
delete  nevertheless  instead of working over minimal incoherent inconsistent sets encountered in the ontologies  our operators produce incisions over non minimal structures called
clusters  we present a construction for consolidation operators  along with the properties
expected to be satisfied by them  finally  we establish the relation between the construction and the properties by means of a representation theorem  although this proposal is
presented for datalog  ontologies consolidation  these operators can be applied to other
types of ontological languages  such as description logics  making them apt to be used in
collaborative environments like the semantic web 

   introduction
the integration of different systems  and the interaction resulting from this integration  led
to a host of pervasive practical problems and challenging research opportunities  some of
the most interesting ones occurs in the webs collaborative environments  e g   e commerce 
and with the arrival of the semantic web  such as ontology engineering  however  the
collaboration among systems brings along the problem of conflicting pieces of information
that are likely to appear as knowledge repositories evolve  admittedly  the management of
conflicting information is an important and challenging issue that has to be faced  gomez 
chesnevar    simari        haase  van harmelen  huang  stuckenschmidt    sure       
huang  van harmelen    ten teije        bell  qi    liu         specially when integrating
c
    
ai access foundation  all rights reserved 

fideagustini  martinez  falappa   simari

knowledge coming from different sources  black  hunter    pan        baral  kraus   
minker        amgoud   kaci         or when such knowledge is expected to be exploited
by a reasoning process  in this context  knowledge bases in the form of ontologies are becoming a useful device that provide a convenient way to represent both the intensional and
extensional knowledge of the application domain  moreover  the expressive power of ontologies allows to perform important tasks on data integration  lenzerini         and also plays
a role of great importance in the aforementioned semantic web  berners lee  hendler   
lassila         in this work we adopt datalog  ontologies  a family of rule based ontology
languages  cal  gottlob    lukasiewicz         datalog  enables a modular rule based
style of knowledge representation  and it can represent syntactical fragments of first order
logic  fol  so that answering a boolean conjunctive query  bcqs  q under a set 
of datalog  rules for an input database d is equivalent to the classical entailment check
d      q  tractable fragments of datalog  guarantee termination of query answering
procedures in polynomial time in the data complexity and first order rewritability  moreover  ontologies described using existential rules generalize several well known description
logics  dls   in particular  linear and guarded datalog   two basic tractable fragments of
this family  are strictly more expressive than the whole dl lite family  calvanese  de giacomo  lembo  lenzerini    rosati         and guarded datalog  is strictly more expressive
than el  brandt        baader  brandt    lutz         therefore  the results presented in
this paper extend directly to these dls as well  these properties of datalog  together with
its expressive power  and the fact that it keeps a syntax closer to that used in relational
databases for greater readability  make it very useful in modeling real applications  such as
ontology querying  web data extraction  data exchange  ontology based data access  and
data integration 
we focus on two particular problems that arise from the integration and or evolution
of information systems  inconsistency and incoherence  inconsistency refers to the lack of
models of a theory  on the other hand  in ontological settings  incoherence refers to a set
of ontological rules that cannot be applied without leading to violations of the constraints
imposed on the knowledge  making them unsatisfiable  incoherence and inconsistency  which
can arise from automated procedures such as data integration and ontology matching  may
be serious issues in real world applications  since standard ontology languages adhere to
the classical fol semantics  classical inference semantics fails in the presence of this kind
of problems  thus  it is important to focus on the formalization of methods to address both
inconsistency and incoherence in ontologies that are able to cope with the users expectations
in terms of effectiveness of the procedures for query answering and the meaning of these
answers when potential conflict exists 
this paper addresses the problem of handling inconsistencies and incoherences that
may appear in datalog  ontologies  in this regard  we propose a general framework that
aims at the consolidation of datalog  ontologies  i e   solving every conflict of coherence
and consistency in them   that is  a consolidation operator takes as input a  possibly 
incoherent and inconsistent datalog  ontology and returns another datalog  ontology
where all conflicts are amended  thus ensuring that it is both coherent and consistent  as
it is usual in this setting  an assumption of minimal change is made  that is to say  it is
expected that the consolidation process changes the original ontology as little as possible 
the approach presented is based on the use of incision functions  hansson                   
   

fidatalog  ontology consolidation

      from the belief revision literature  instead of operators that only account for the
information included in the conflicts in a knowledge base  in this work we aim to capture
consolidation operators that can consider all the information included in a kb when solving
conflicts  the main contributions of this work are the following 
 we introduce a notion of incoherence tailored for datalog    to achieve this we adapt
to this setting similar notions from description logics  also  we look into the relationship of incoherence and inconsistency and how it impacts the consolidation process 
 we provide a set of properties expected to be satisfied by consolidation operators
for datalog  ontologies by means of postulates  these postulates provide a formal
characterization of a consolidation operator without focusing on how the consolidation
process is actually performed  thus providing a formal comparison framework for
consolidation operators  the postulates consider some intuitions in classic belief
revision  nevertheless  they are adapted to the datalog  ontological setting  and
could be also adapted to suit other ontological languages   meaning that they have
two versions  one addressing incoherence and another one for inconsistency  
 we present a complete construction of consolidation operators that take a  possibly 
incoherent and inconsistent datalog  ontology and gives as a result a consistent and
coherent one  a noteworthy characteristic of such operators is that it involves a two
steps approach  first considering incoherence conflicts  and then solving inconsistency
conflicts as a latter step  helping to improve the final result in terms of the information
that needs to be deleted to solve conflicts 
 we study the relationship between the formal properties of the operator and the
construction we propose  demonstrating that they are equivalent  thus  this shows that
any consolidation operator satisfying the properties corresponds to the construction
introduced in this work 
the paper is organized as follows  in section   we introduce the necessary notions from
datalog  and belief revision  next  though inconsistency and incoherence are related 
they are also two very distinct problems in the setting of ontological knowledge bases in
particular  where there is a clear separation of the intensional and the extensional knowledge 
therefore  in section    we discuss the two notions in datalog  ontologies  how they relate
to each other  and the reasons why they need to be treated in combination but separately 
then  in section   we present the properties that an ontology consolidation operator must
satisfy  and in section   we introduce the process used to restore consistency and coherence
of datalog  ontologies  and relate the presented process to the given properties by means
of a representation theorem  next  we present a complete example depicting the entire
consolidation process  finally  in sections   and   we discuss related work from different
areas in artificial intelligence and database theory  and provide conclusions and future
lines of research  respectively 

   preliminaries and background
to facilitate the reading  we begin by introducing the notions from datalog  and belief
revision that will be needed in the rest of the paper 
   

fideagustini  martinez  falappa   simari

    preliminaries on datalog 
first  we recall the basic notions of datalog  ontologies that will be used in the paper
 see cal et al        for more details   datalog  extends datalog by allowing existential
quantification in the rule heads  together with other extensions that we enumerate below 
but limiting the interaction of these elements in order to achieve tractability 
we will assume that the domain of discourse of a datalog  ontology consists of a
countable set of data constants   a countable set of nulls n  as place holders for unknown
values   and a countable set of variables v  we also assume that different constants represent
different values  unique names assumption   to distinguish constants from variables  we
adopt the standard notation from logic programming  where variable names begin with
uppercase letters  while constants and predicate symbols begin with lowercase letters 
we assume a relational schema r that is a finite set of predicate symbols  or simply predicates   a term t is a constant  a null  or a variable  an atom a has the form p t            tn   
where p is an n ary predicate and t            tn are terms  an atom is ground iff all terms in
it are constants  let l be a first order language such that r  l  then lr denotes the
sublanguage generated by r  a database  instance  of r is a finite set of atoms with predicates in r and terms in   n   a homomorphism on constants  nulls and variables is
a mapping h     n  v    n  v such that  i  c   implies h c    c   ii 
c  n implies h c     n   and  iii  h is naturally extended to atoms  sets of atoms 
and conjunctions of atoms 
given a relational schema r  a tuple generating dependency  tgd   is a first order
formula of the form xy x  y   z x  z  where  x  y  and  x  z  are conjunctions of atoms over r called the body  denoted body    and the head  denoted head    
respectively  consider a database d for a relational schema r  and a tgd  on r of the
form  x  y   z  x  z   then   is applicable to d if there exists a homomorphism
h that maps the atoms of  x  y  to atoms in d  let  be applicable to d  and h  be
a homomorphism that extends h as follows  for each xi  x  h   xi     h xi    for each
zj  z  h   zj     zj   where zj is a fresh null  i e   zj  n   zj does not occur in d  and zj
lexicographically follows all other nulls already introduced  the application of  on d adds
to d the atom h    x  z   if it is not already in d  after the application we say that  is
satisfied by d  the chase for a database d and a set of tgds t   denoted chase d  t   
is the exhaustive application of the tgds  cal et al         in a breadth first  level saturating  fashion  which leads to a  possibly infinite  chase for d and   it is important
to remark that bcqs q over d and t can be evaluated on the chase for d and t   i e  
d  t    q is equivalent to chase d  t      q  cal et al         
negative constraints  ncs  are first order formulas of the form x x     where
 x  is a conjunction of atoms  without nulls  and the head is the truth constant false 
denoted   an nc  is satisfied by a database d under a set of tgds t iff there does not
exist a homomorphism h that maps the atoms of  x  to d  where d is such that every
tgd in t is satisfied  i e   the atoms in the body cannot all be true together 
equality generating dependencies  egds  are first order formulas of the form
x x   xi   xj   where  x  is a conjunction of atoms  and xi and xj are variables from x  an egd  is satisfied in a database d for r iff  whenever there exists a
homomorphism h such that h  x    d  it holds that h xi     h xj    in this work we
   

fidatalog  ontology consolidation

will focus on a particular class of egds  called separable  cal et al          intuitively 
separability of egds w r t  a set of tgds states that  if an egd is violated  then atoms
contained in d are the reason of the violation  and not the application of tgds   i e   if an
egd in e is violated when we apply the tgds in t for a database d  then the egd
is also violated in d  separability is a standard assumption in datalog  ontology  as one
of the most important features of this family of languages is the focus on decidable  cal 
lembo    rosati         actually tractable  fragments of datalog   
ncs and egds play an important role in the matter of conflicts in datalog  ontologies 
in fact  the approach that we present in this work ensure that neither ncs nor egds are
violated in the resulting ontology  also  as an important remark  note that the restriction
of using only separable egds makes that certain cases of conflicts are not considered in our
proposal  the treatment of such cases  though interesting from a technical point of view 
are outside the scope of this work since we focus on tractable fragments of datalog   
as is the usual case in the literature  in general the universal quantifiers in tgds 
negative constraints and egds are omitted  and the sets of dependencies and constraints
are assumed to be finite  now that we have presented the different ways of expressing
knowledge in datalog    we are ready to formally define datalog  ontologies 
definition    datalog  ontology  a datalog  ontology kb    d     where    t 
e  nc   consists of a database instance d that is a finite set of ground atoms  without
nulls   a set of tgds t   a set of separable egds e and a set of ncs nc  
otherwise explicitly said  through the paper when it is clear from context we will refer
to the component  in kb as the set of constraints in the ontology  without distinguishing
between dependencies and constraints  given a database d for r and a set of constraints
   t  e  nc   the set of models of d and   denoted mods d     is the set of
all databases b such that d  b and every formula in  is satisfied  the following
example shows a simple datalog  ontology  the ontology describes knowledge about the
therapy psychology domain 
example    datalog  ontology 

d   a    in therapy charlie   a    dating kate  charlie  




a    therapist kate   a    belongs to g    charlie  




a

    in therapy patrick    a    belongs to g    ed   



a

    belongs to g    kate  







 nc        treating t   p    dating t   p     
kb  


e        treating t   p    treating t     p    t   t    








t        in therapy p    patient p   




    therapist t    belongs to g  t    leads t   g  




    leads t   g   belongs to g  p    treating t   p   



    treating t   p    therapist t   













































the set t of tgds expresses dependencies such as  tgd   states that if a person p
is in therapy then p is a patient    establishes that a therapist t that belongs to a group
   

fideagustini  martinez  falappa   simari

g is the leader of that group  the only nc   states that a patient cannot be dating his
therapist  and egd   states that every patient is in treatment with at most one therapist 
following the classical notion of consistency  we say that a consistent datalog  ontology
has a non empty set of models 
definition    consistency  a datalog  ontology kb    d    is consistent iff
mods d         we say that kb is inconsistent otherwise 
example   consider the datalog  ontology from the example above  this ontology is clearly

inconsistent  database instance d is clearly not a model in itself since at least tgd   is
applicable to d  but there is no superset of d such that it satisfies all tgds and constraints in  at the same time  for instance tgds   is applicable in d creating the atom
leads kate  g    making now   applicable and resulting in the new atom treating kate  charlie  
which together with dating kate  charlie   that was already in d  violate the nc     as a
therapist is dating one of her patients 
for the rest of the paper  otherwise explicitly stated kb    d    will denote a datalog 
ontology with    t  e  nc   where d is a database instance  t is the set of all
tgds  e the set of all separable egds and nc being the set of all ncs in  
    background in belief revision
establishing the origins of scientific ideas is a difficult task that sometimes can be controversial  nevertheless  it could be argued that the origins of belief change theory go back to
the work of isaac levi         who discussed the problems concerning this field of research 
and to william harpers proposal of a rational way to interrelate belief change operators  harper         however  the main advances on belief change theory came during the
    s when carlos alchourron and david makinson studied changes in legal codes  alchourron   makinson         and peter gardenforss introduced rational postulates for
change operators  gardenfors         after that  the three authors produced a foundational paper containing what became known as the agm model  alchourron  gardenfors 
  makinson         the core contribution of the agm model is the presentation of a
new and more general formal framework for the study of belief change  today  this work is
considered as the cornerstone from which belief change theory evolved 
since the introduction of the agm model  different frameworks for belief dynamics and
their respective epistemic models have been proposed  the epistemic model corresponds to
the formalism in which beliefs are represented  providing the framework in which different
kinds of operators can be defined  the agm model is conceived as an idealistic theory of
rational change in which epistemic states are represented by belief sets  sets of sentences
closed under logical consequence  commonly denoted in boldface   and the epistemic input
is represented by a sentence  in the agm model  three basic change operators are defined 
expansion  contraction  and revision  in the rest of this section  whenever we use the term
consistent or inconsistent  we refer to the traditional notion of inconsistency of a knowledge
base that has no models  let k be a belief set  the change operations are as follows 
   

fidatalog  ontology consolidation

 expansions  the result of expanding k by a sentence  is a possibly larger set which
infers   intuitively  belief   hopefully consistent with the given epistemic state  is
directly added to k 
 contractions  the result of contracting k by  is a possibly smaller set which does
not infer   unless  is a tautology 
 revisions  the result of revising k by  is a set that neither extends nor is part of
the set k  in general  if  is not a fallacy then  is consistently inferred from the
revision of k by  
the great importance of agm comes from providing axiomatic characterizations of contraction and revision in terms of rationality postulates  such rationality postulates regard
the operators as black boxes  characterizing what they do  but not explaining how they
do it  in other words  their behavior is constrained with regard to inputs in basic cases 
without describing the internal mechanisms used for achieving that behavior  so it is crucial
to say that contraction and revision operators can also be obtained via more constructive
approaches  agm contractions can be realized by partial meet contractions  which are
based on a selection among  maximal  subsets of k that do not imply   via the levis
identity  gardenfors         associated revision operations called partial meet revisions are
obtained  another possible approach for contraction is based on a selection among the
 minimal  subsets of k that contribute to make k imply   as in safe contraction  alchourron   makinson         a more general variant of the same approach  known as
kernel contraction  was introduced later  hansson         it has been shown that both safe
contractions and kernel contractions are equivalent to partial meet contractions  and hence
to the agm approach to contraction  hansson              
a particularly interesting characteristic of kernel contraction is that it may be concerned
with changes at the symbolic level since it is suitable of being applied to belief bases  set of
sentences not closed under a consequence relation  as well as belief sets  thus  it matters
how the beliefs are actually represented  this does not happen in the agm approach  as it
studies the changes at the knowledge level since it uses belief sets  the distinction between
knowledge and symbolic level was proposed by allen newell         according to newell 
the knowledge level lies above the symbolic level  and the latter is used to somehow represent
the former  because of this  belief bases with different symbolic content may represent the
same knowledge  the importance of this is that  although they are statically equivalent
 they represent the same beliefs   equivalent belief bases could be dynamically different if
we choose to use an approach working directly with them  as with kernel contraction 
besides the three basic operations mentioned  through the years additional operations
where developed in belief revision to achieve different behaviors  for instance  when a
belief base is inconsistent  the removal of enough sentences from it can lead to a consistent
state  this additional operation is called consolidation  and the consolidation of a belief base
k is denoted k    see hansson               here we will focus on this last operation  which
is inherently different from contraction and revision  since its ultimate goal is to obtain a
consistent belief base from a possibly inconsistent one  without being given any epistemic
input   rather than revising the knowledge base by a specific formula or by removing a
particular formula from it  the consolidation of k can be obtained in a natural way in belief
   

fideagustini  martinez  falappa   simari

bases by contracting them by falsum  i e   k     k    where  represents a contraction
operator  this process restores consistency attending every conflict in k  hansson        

   incoherence and inconsistency problems related to datalog 
ontology consolidation
the problem of obtaining consistent knowledge from an inconsistent knowledge base is
natural in many computer science fields  as knowledge evolves  contradictions are likely to
appear  and these inconsistencies have to be handled in a way that they do not affect the
quality of the information obtained from the database 
in the setting of consistent query answering  cqa   repairing of relational databases 
and inconsistency tolerant query answering in ontological languages  arenas  bertossi   
chomicki        lembo  lenzerini  rosati  ruzzi    savo        lukasiewicz  martinez   
simari         often the assumption is made that the set  expresses the semantics of the
data in the component d  and as such there is no internal conflict on the set of constraints
and these constraints are not subject to changes over time  this means first  that the set 
is always satisfiable  in the sense that their application do not inevitably yield a consistency
problem  second  as a result of this assumption  it must be the case that the conflicts come
from the data contained in the database instance  and that is the part of the ontology that
must be modified in order to restore consistency  although this is a reasonable assumption
to make  specially in the case of a single ontology  in this work we will focus on a more
general setting  and consider that both data and constraints can change through time and
become conflicting  in this more general scenario  as knowledge evolves  and so the ontology
that represents it  not only data related issues can appear  but also constraint related ones 
we argue that it is also important to identify and separate the sources of conflicts
in datalog  ontologies  in the previous section we defined inconsistency of a datalog 
ontology based on the lack of models  from an operational point of view  conflicts appear
in a datalog  ontology whenever a nc or an egd is violated  that is  whenever the body
of one such constraint can be mapped to either atoms in d or atoms that can be obtained
from d by the application of the tgds in t    beside these conflicts  we will also
focus on the relationship between the set of tgds and the set of ncs and egds  as
it could happen that  a subset of  the tgds in t cannot be applied without leading
always to the violation of the ncs or egds  note that in this case clearly the data in the
database instance is not the problem  as any database in which these tgds are applicable
will inevitable produce an inconsistent ontology  this issue is related to the unsatisfiability
problem of a concept in an ontology  and it is known in the description logics community as
incoherence  flouris  huang  pan  plexousakis    wache        schlobach   cornet       
borgida        beneventano   bergamaschi        kalyanpur  parsia  sirin    hendler 
      schlobach  huang  cornet    van harmelen        qi   hunter         incoherence
can be particularly important when combining multiple ontologies since the constraints
imposed by each one of them over the data could  possibly  represent conflicting models of
the application at hand  clearly  the notions of incoherence and inconsistency are highly
related  in fact  flouris et al s        work establish a relation between incoherence and
inconsistency  considering incoherence as a particular form of inconsistency 
   

fidatalog  ontology consolidation

later in this section we present a complete definition of incoherence in datalog    based
on the concept of unsatisfiability of sets of tgds  nevertheless  for now it is sufficient
to know that our proposed notion of incoherence states that given a set of unsatisfiable
constraints  it is not possible to find a set of atoms d such that kb    d    is a consistent
ontology and at the same time all tgds in t   are applicable in d  this means that
a datalog  ontology can be consistent even if the set of constraints is incoherent  as long
as the database instance does not make those dependencies applicable  on the other hand 
a datalog  ontology can be inconsistent even when the set of constraints is satisfiable 
e g   kb     tall peter   small peter     tall x   small x       where the  empty 
set of dependencies is trivially satisfiable and thus the ontology coherent  the ontology is 
nevertheless  inconsistent 
before formalizing the notion of incoherence that we use in our datalog  setting we
need to identify the set of atoms relevant to a given set of tgds  intuitively  we say that
a set of atoms a is relevant to a set t of tgds if the atoms in the set a are such that the
application of t over a generates the atoms that are needed to apply all tgds in t   i e  
a triggers the application of every tgd in t  
definition    relevant set of atoms for a set of tgds  let r be a relational
schema  t be a set of tgds  and a a  possibly existentially closed  non empty set of
atoms  both over r  we say that a is relevant to t iff for all   t of the form
xy x  y   z x  z  it holds that chase a  t      xy x  y  
when it is clear from the context  if a singleton set a    a  is relevant to t  t we
just say that atom a is relevant to t  
example    relevant set of atoms  consider the following constraints 

t        supervises x   y    supervisor  x   
    supervisor  x    makes decisions x    leads department x   d  
    employee x    works in x   d  
consider set a     supervises walter   jesse   makes decisions walter    employee jesse   
this set is a relevant set of atoms to the set of constraints t                 since  
and   are directly applicable to a  and   becomes applicable when we apply    i e   the
chase entails the atom supervisor  walter    which together with makes decisions walter  
triggers     
however  the set a     supervises walter   jesse   makes decisions gus   is not relevant
to t   note that even though   is applicable to a    the tgds   and   are never applied
in chase a    t    since the atoms in their bodies are never generated in chase a    t   
for instance  consider the tgd    t   in the chase of t over d we create the atom
supervisor walter   but nevertheless we still cannot trigger   since we do not have and
cannot generate the atom makes decisions walter    and the atom makes decisions gus  that
is already in a  does not match the constant value 
we now present the notion of coherence for datalog    which adapts efforts made for
dls such as schlobach and cornets        and flouris et al s         our conception
   

fideagustini  martinez  falappa   simari

of  in coherence is based on the notion of satisfiability of a set of tgds w r t  a set of
constraints  intuitively  a set of dependencies is satisfiable when there is a relevant set of
atoms that triggers the application of all dependencies in the set and does not produce the
violation of any constraint in nc  e   i e   the tgds can be satisfied along with the ncs
and egds in the kb  
definition    satisfiability of a set of tgds w r t  a set of constraints  let r be
a relational schema  t  t be a set of tgds  and n  nc  e   both over r  the set
t is satisfiable w r t  n iff there is a set a of  possibly existentially closed  atoms over r
such that a is relevant to t and mods a  t  n        we say that t is unsatisfiable w r t 
n iff t is not satisfiable w r t  n   furthermore  t is satisfiable w r t  nc  e iff there
is no t  t such that t is unsatisfiable w r t  some n with n  nc  e  
in the rest of the paper sometimes we write that a set of tgds is  un satisfiable omitting
the set of constraints  we do this in the context of a particular ontology where we have a
fixed set of constraints nc  e since any set of tgds that is satisfiable w r t  nc  e is
satisfiable w r t  any subset of it and  on the other hand  any set of tgds that is unsatisfiable
w r t  a subset of nc  e is also unsatisfiable w r t  the whole set of constraints 
example    unsatisfiable sets of dependencies  consider the following constraints 

 nc       risky job p    unstable p     
 t        dangerous work  w    works in w  p    risky job p   
    in therapy p    unstable p   
the set  t is a satisfiable set of tgds  and even though the simultaneous application of
  and   may violate some formula in  nc   e   that does not hold for every relevant
set of atoms  consider as an example the relevant set d     dangerous work  police  
works in police  marty   in therapy rust    d  is a relevant set for  t   however  as we
have that mods d     t   nc   e       then  t is satisfiable 
on the other hand  as an example of unsatisfiability consider the following constraints 
 nc        sore throat x   can sing x    
 t        rock singer  x   sing loud  x       sing loud  x   sore throat x  
    rock singer  x   can sing x  
the set  t is an unsatisfiable set of dependencies  as the application of tgds             
on any relevant set of atoms will cause the violation of     for instance  consider the
relevant atom rock singer  axl   we have that the application of  t over  rock singer  axl  
causes the violation of   when considered together with  t   and therefore we have that
mods  rock singer  axl     t   nc   e       note that any set of relevant atoms will
cause the violation of    
we are now ready to formally define coherence for a datalog  ontology  intuitively 
an ontology is coherent if there is no subset of their tgds that is unsatisfiable w r t  the
constraints in the ontology 
   

fidatalog  ontology consolidation

definition    coherence  an ontology kb is coherent if and only if t is satisfiable
w r t  nc  e   also  kb is said to be incoherent iff it is not coherent 
example    coherence  consider the sets of dependencies and constraints defined in ex 

ample   and an arbitrary database instance d  we can see that the datalog  ontology
kb      d   t   nc   e   is coherent  while kb      d   t   nc   e   is incoherent 
considering incoherence of a set of tgds is important in the consolidation process of
datalog  ontologies  since if not treated appropriately within the consolidation process  an
incoherent set of tgds may lead to the trivial solution of removing every single relevant
atom in d  in the worst case  the entire database instance   this may be adequate for some
particular domains  but does not seem to be a desirable outcome in the general case 
looking into definitions   and   we can see that there is a close relationship between the
concepts of incoherence and inconsistency  in fact  it can be inferred from those definitions
that an incoherent kb will induce an inconsistent kb when the database instance contains
any set of atoms that is relevant to the unsatisfiable sets of tgds  this result is captured
in the following proposition  proofs of results are presented in appendix a  
proposition   if kb is incoherent and there exists a  d such that a is relevant to some
unsatisfiable set u  t then kb    d    is inconsistent 
as an instance of this relationship  consider the following representative example 
example    relating incoherence and inconsistency  consider the following ontology 

kb  


d    a    can sing simone   a    rock singer  axl    a    sing loud  ronnie  




a    has fans ronnie   a    rock singer  ronnie   a    rock singer  roy  




a    manage band    richard   








nc        sore throat x   can sing x    




    has private life x   famous x    



e  








t  
















     manage x  y    manage x  z   y   z 
  
 
 
 
 

  rock singer  x   sing loud  x  
  sing loud  x   sore throat x  
  has fans x   famous x  
  rock singer  x   can sing x  
  has fans x   has private life x  

















































as hinted previously in example    there we have the set a  d    rock singer  axl  
and the unsatisfiable set of tgds u  t        rock singer  x   sing loud  x      
sing loud  x   sore throat x       rock singer  x   can sing x    since a is relevant
to u the conditions in proposition   are fulfilled  and indeed the ontology kb    d    is
inconsistent since    t is violated 
a set of constraints such as the one presented in example   may appear when we consider scenarios where both components of an ontology evolve  perhaps being collaboratively
   

fideagustini  martinez  falappa   simari

maintained by a pool of users   as long as new constraints are added  incoherence problems
may arise  in this particular scenario it would seem more sensible to identify and modify 
somehow  the set of incoherent constraints to make them satisfiable  instead of deleting all
the information from the ontology  and only then proceed to solve remaining inconsistencies  if any  that is  it could be beneficial to define consolidation processes in which the
changes performed to achieve coherence are given higher priority than the changes needed
for consistency when possible  to address this we present a twofold proposal for consolidation of datalog  ontologies  that is  to obtain the new kb   we begin by addressing issues in
the component t w r t  the components e and nc in the original ontology to obtain a
new coherent set of constraints  giving up some tgds in t if necessary  then  we address
the problems arising from the component d  obtaining a new one d  that is consistent with
 t  e  nc   in the next section we characterize  by means of a set of postulates  a
consolidation operator that takes into account these considerations 

   characterizing the consolidation  postulates for datalog  ontology
consolidation operators
belief revision is one of the main areas that deals with defined principled methods to solve
incoherences and inconsistencies  as explained in section    it is common to characterize
change operators by means of postulates  which are properties that the operators must satisfy  in this section we introduce a set of postulates with the objective of characterizing
consolidation operators for datalog  ontologies  we start by briefly defining the scenario
underlying the consolidation process and introducing the characteristics of the sets of formulas that we focus on  friedman   halpern        

    defining the consolidation environment
depending on the type of knowledge base  we find two main streams of work in belief
revision  on one hand  some works are based on sets of formulas that are closed under
some consequence relation  called belief sets  alchourron et al          this is known in
the belief revision literature as the coherence model  on the other hand  the option is to
choose belief bases  katsuno   mendelzon              fuhrmann        hansson       
            falappa  kern isberner    simari         i e   non closed sets of formulas  this
is referred to as the foundational model 
opposite to the traditional closed world assumption found in other established areas
like relational databases  one important characteristic of datalog  is that of an open world
assumption  unknown data is represented by means of null values  as a consequence  the
generation of new information in the language by the application of rules is susceptible of
being infinite  cal  gottlob    kifer               which seems to make the foundational
model a more appealing choice when working in this setting  therefore  for the consolidation
of datalog  ontologies we have chosen to follow the foundational model  in this model  the
epistemic state is a  possibly incoherent and inconsistent  datalog  ontology 
   

fidatalog  ontology consolidation

    expected properties for the consolidation operator  postulates
we present now the set of properties that a consolidation operator for datalog  ontologies
must satisfy  we use the following notation through the rest of the paper  let kb    d   
be the original datalog  ontology being consolidated  where    t  e  nc   also 
kb   denotes the datalog  ontology kb      d      resulting from the consolidation of kb  
with d  and   being the consolidated components d and  in kb    respectively  when
necessary we will differentiate kbs by using subscripts  in such cases  given kb i we denote
its consolidation by kb i      di    i    
we are ready now to introduce the ontology consolidation postulates  ocp  expected
to be satisfied by the consolidation operators  let  be the set of all datalog  ontologies 
then  a datalog  ontology consolidation operator        is a function that must
satisfy the following properties 
ocp     inclusion      and d   d 
the consolidation process only includes in the resulting ontology formulas belonging to the original ontology 
ocp     consistency  kb   is consistent 
the ontology obtained by the consolidation process must be consistent  i e  
there are no negative constraints or equality generating dependencies that are
violated when we apply all tgds in   to the atoms in d   and therefore
mods  d           
ocp     coherence  kb   is coherent 
the ontology obtained by the consolidation process must be coherent  i e   t
in   must be satisfiable with respect to nc  e in   
ocp     minimality   if kb    kb is coherent and consistent  then it holds that
kb     kb    
there is no coherent and consistent ontology obtained from the original ontology that strictly contains the consolidated ontology 
some of the postulates presented are inspired by the properties proposed by hansson        and by konieczny and pino perez         nevertheless  they are adapted to
suit the particularities of the ontological setting of datalog    in particular  they take into
account the distinction between incoherence and inconsistency  for instance  inclusion
is a direct adaptation of hanssons homonymous postulate  hansson         which states
that the contraction of a knowledge base should be a  not necessarily proper  subset of the
original one  consistency and coherence  on the other hand  result from adapting to
our setting konieczny and pino perezs postulate ic          which intuitively ask that
the resulting merging must be consistent  in here we ask that the resulting consolidation
is not only consistent but also coherent  minimality is a postulate added to ensure the
quality of the consolidation  w r t  a loss of information aspect   and is not adapted from
any particular work  but rather as a general notion in belief revision  where as noted by
   

fideagustini  martinez  falappa   simari

hansson        it has been given many names such as conservatism  harman         conservativity  gardenfors         minimum mutilation  quine        and minimal change  rott 
      
the proposed postulates capture the notion that changes made with respect to the
original ontology are those that are necessary  and that the resulting ontology is  as expected 
both coherent and consistent  that is  given the original ontology the consolidation process
only removes constraints  tgds  and atoms if they are somehow involved in making the
original ontology incoherent inconsistent  and makes it in such a way that no unnecessary
removal is made 

   a datalog  ontology consolidation operator
in previous sections we have presented examples of incoherences and inconsistencies that can
arise in datalog  ontologies  additionally  we stated the properties that the consolidation
operator should satisfy in order to make adequate changes in the original ontology regaining
coherence and consistency  now  we propose a construction for the consolidation operator
that addresses such incoherence and inconsistency problems in datalog  ontologies 
    a possible construction for the consolidation operator
in the literature of belief revision several constructions for revision and contraction operators have been studied  hansson        presents how a contraction operation on belief
bases can be modeled by means of the application of incision functions  these functions
contract a belief base by a formula  by taking minimal sets that entail   called  kernels 
and producing incisions on these sets so they no longer entail   the resulting belief base
is then conformed by the union of all formulas that are not removed by any function  this
approach is known as kernel contraction  the task of restoring consistency is also known
in the belief revision literature as contraction by falsum  hansson         in this work 
we define the consolidation process as the application of incision functions  nevertheless 
instead of directly considering minimal inconsistent subsets of formulas from the different
components of the ontology  which are equivalent to  kernels   in this work we perform incisions over structures called clusters  martinez  pugliese  simari  subrahmanian    prade 
      lukasiewicz et al         that groups together related kernels  more specifically  to
solve incoherence we begin by establishing the dependency kernels  in an analogous way 
we define the data kernels to solve inconsistencies in d w r t    then  based on them  we
obtain the dependency clusters and data clusters by exploiting an overlapping relation 
      identifying the relation among conflicts
the first step towards conflict resolution in our framework is to calculate the minimal coherence and consistency conflicts  and identify possible relations among such conflicts  if any 
dependency kernels are sets of tgds which are unsatisfiable w r t  the set of ncs and egds
in a datalog  ontology and are minimal under set inclusion  these sets are known as minimal unsatisfiability preserving sub tboxes  mups  and minimal incoherence preserving
sub tboxes  mips   schlobach   cornet        in the dl community 

   

fidatalog  ontology consolidation

definition
   dependency kernels  the set of dependency kernels of kb   denoted
q
with kb   is the set of all x  t such that x is an unsatisfiable set of dependencies
w r t  nc  e and every proper subset x   of x  x     x  is satisfiable w r t  nc  e  
example    dependency kernels  consider the following sets of constraints in a

datalog  ontology kb  

nc        counselor  x    regent x     




    cannot rule x    heir  x     








e        advise x   k    advise x   k      k   k    







t        advise x   k    counselor  x   
kb  
    propose law  x   k    regent x   




    prince p    heir  p   




    son p   k    king k    prince p   




    counselor  c    regent c   




    bastard son x   y    son x   y   



    bastard son x   k    king k    cannot rule x   









































for this kb there exist two dependency kernels  i e  
q
kb

                           

it is easy to show that the dependency kernels for a datalog  ontology are independent
from the particular component d in the ontology  and thus they can be obtained by looking
only into the component   that is  even if we replace the component d in an ontology with
an empty set of atoms  the dependency kernels for the ontology with the empty database
are the same than those in the original one 


lemma   let kb
q      d
q        and kb            be two datalog ontologies such that
        then  kb     kb    

in addition to the removal of the tgds that make a set  unsatisfiable  thus making
an ontology incoherent   to solve inconsistencies we may need to remove atoms from components d in order to address data inconsistency as well  analogously to the definition of
the dependency kernels  we define now data kernels as the minimal subset of atoms in d
that makes a kb    d    inconsistent 

 
definition    data kernels  the set of data kernels of kb   denoted with kb   is the set
of all x  d such that mods x       and for every x     x it holds that mods x           
   

fideagustini  martinez  falappa   simari

example    data kernels  consider the following coherent but inconsistent kb   pro 

posed by lukasiewicz et al         

kb  


d    directs john  d     directs tom  d     directs tom  d    




supervises tom  john   works in john  d     works in tom  d    








nc    supervises x   y    manager  y     




supervises x   y    works in x   d   directs y   d    



e  








t  








 directs x   d   directs x   d      d   d    
     works in x   d   employee x   
    directs x   d   employee x   
    directs x   d   works in x   d   manager  x   





































for this kb   the set of data kernels is
 
kb



  supervises tom  john   directs john  d     works in john  d      
 supervises tom  john   directs john  d     works in tom  d     
 


 directs tom  d     directs tom  d    

once we know the minimal conflicts in the ontology we identify relations among them  if
such relation exists  to do this  we group related kernels together in a new structure called
cluster  which makes possible to achieve an optimal solution in related kernels  clusters are
obtained through an overlapping relation defined as follows 
definition    overlapping  equivalence  let l be a first order language  r  l be a
relational schema  and lr the sublanguage
t generated by r  given a  lr and b  lr  
we say they overlap  denoted a b  iff a b      furthermore  given a multi set of first
 the equivalence relation obtained over m through
order formulas m   lr we denote as m
the reflexive and transitive closure of  
by exploiting the overlapping among dependency kernels and data kernels we can define
dependency clusters and data clusters  respectively 
q
definition    dependency clusters  let kb
set of dependency kernels for
q be the

kb   let  be the overlapping relation  and k   kb  q
the quotient set for the equivkb
q
s
alence relation obtainedq
qover kb   a constraint cluster is a set c        where
    k  we denote by kb the set of all constraint clusters for kb  
 
definition     data clusters   
let kb be the set of data kernels for kb   let  be

the overlapping relation  and k   kb   
the quotient set for the equivalence relation
kb
 
s
obtained
over kb   a data cluster is a set c        where     k  we denote by
 
 
the set of all data clusters for kb  
kb
intuitively  a dependency cluster groups dependency kernels that have some tgd in
common  in a transitive fashion  data clusters groups data kernels in an analogous way 
   

fidatalog  ontology consolidation

example    dependency clusters and data clusters  assume we have kb such that

q

 
                                 and kb     a    a      a    a      a    a    a      then  we
have two dependency clusters based on those kernels  grouping the first two kernels  due to
    and the remaining kernel in another cluster  i e  
kb

q
q
kb

                           

on the other hand  for the case of data clusters we have that
 
 
kb

    a    a    a    a    a     

the following proposition states that  since clusters are based on equivalence classes  every
kernel is included in one and only one cluster 
q
q
q
propositionq
  y  kb is such that y  x for some x  kb if and only if y   x  
q
 
for all
x     analogously 
y  kb is such that y  x for some
 
 
 
 x  kb such that x   
 
 
x  kb if and only if y   x for all x  kb such that x    x    
as a corollary of proposition   we have that a formula in a kernel is included in only
one cluster 
q
corollary    corollary
from
proposition
  
let


y
for
some
y

and  
kb
 
q
q
 
 
y forq
  x for some x  kb if and only if  
  x   for
 
 all
qsome y  kb   then 
 
 
 


y
is
such
that


x
for
some
x

x  kb such that x    x   analogously 
kb
 
 
if and only if  
  x   for all x    kb such that x    x    
the following lemma that we shall use further in the paper shows an example of how 
in the ontological setting of datalog    leibnizs indiscernibility of identicals  von leibniz 
      holds w r t  the clusters in datalog  ontologies  as when two kbs are equivalent they
have the same set of clusters 
 ontologies such that kb   kb   then 
lemma
  let kb  q
and kbq
  be two datalog
 
 
 
 
 
 
q
q
 
and
 
 
kb  
kb  
kb  
kb  

      solving conflicts  incision functions
once we have identified the clusters  we have to establish how the incoherences and inconsistencies are solved  an incision function selects which formulas should be deleted from
the data and dependency clusters 
definition     general incision function  a general incision function for kb is a
function      lr    lr     lr such that all following conditions holds 
sq
q
s 
 
    kb      kb      kb   
q
q
q
   for all x  kb and y  kb such that y  x it holds that  y   kb        
 
 
 
   for all x  kb and y  kb such that y  x it holds that  y   kb        
   

fideagustini  martinez  falappa   simari

q
q
   for all x  kb it holds that t    x   kb    is such that there not exists r  x
where r satisfies conditions   and    and r   t  
 
 
   for all x  kb it holds that t    x   kb    is such that there not exists r  x
where r satisfies conditions   and    and r   t  
definition    states that a general incision function selects from each dependency  data 
respectively  cluster tgds  atoms  respectively  for deletion in order to restore coherence
 consistency   any incision function that complies with definition    can be used as a base
for a consolidation operator  however  note that such an operator may not differentiate
between restoring coherence and consistency  this is not a problem in the classic literature
of belief revision since there is no notion of incoherence  and there is no distinction between
rules and facts in languages like propositional logic  thus  only consistency conflicts can
appear  avoiding the need to treat incoherences  nevertheless  in the ontological setting of
datalog  we have the opportunity of exploiting the fact that we have two different although
related kinds of conflicts to address them separately with the goal of finding a solution that
better suits the needs of applications that rely on this kind of knowledge bases 
the point this paper is trying to make is that  for knowledge bases in the form of
datalog  ontologies it is important to differentiate  and adequately handle  incoherence
from inconsistency as the quality of the consolidated ontology heavily depends on that 
assuming we strive for minimal loss in the process  this  more complex setting  needs a
careful definition of what constitutes a kernel  to see what could happen if this is not done
properly  consider the following example 
example     influence of incoherence on consolidation  consider kb from exam 

ple    there we have     t   e   nc such that  t is unsatisfiable  as explained in example    for the singleton set  rock singer  axl   we have that the nc     sore throat x  
can sing x    is violated  making  rock singer  axl   inconsistent with   then 
 rock singer  axl   is a data kernel  and a data cluster  since it cannot overlap with any
other kernel  and the same is verifiable for every singleton set in d relevant to some dependency cluster  thus  we have that

 
 
kb


 rock singer  axl   



 rock singer  ronnie   
 
 rock singer  roy   



 has fans ronnie  









consider the cluster  rock singer  axl    for this cluster we have that
  rock singer  axl      rock singer  axl  
 
 
 
 
s 
 
this same situation holds for every cluster in kb   and thus   kb       kb   
the problem in this example is that the data kernels  and hence so the data clusters  are
computed w r t  the original  component  which  in this case  contain unsatisfiable sets
of constraints  as can be seen in example     this becomes of utter importance when we
have atoms relevant to unsatisfiable sets  in that case  any general incision function  and
any inconsistency management technique based on deletion that does not treat incoherence
conflicts  will necessarily delete such atoms 
   

fidatalog  ontology consolidation

proposition   let  be a general incision function  if   d is relevant to some x 
then    kb   

q
kb

clearly  as a corollary of proposition   we have that if every atom in d is relevant to
some unsatisfiable set then we have to remove every atom in d to restore consistency 
corollary    corollary from proposition    letq be a general incision function  if
for all   d it holds that  is relevant to some x  kb then d   kb   
as seen  incoherence can have great influence in consolidation if not treated properly
 that is  previously to the consistency restoration   it would seem better to compute the
data clusters based only on the retained satisfiable part of the  components  in lemma  
we show that the dependency kernels can be obtained independently of the d component
from the original ontology  because unsatisfiable sets are such that they violate a negative
constraint or equality generating
dependency for any relevant set of atoms  therefore  we
q
q
can first obtain
 
and
use
the
incision function
kb
 
  on the dependency clusters to select
which tgds will be deleted q
qthen  we calculate kb based on the result of the application
of the incision function on kb   in this way only paying attention to the constraints that
will prevail in the consolidation process 
next  we define both constraint incision functions and data incision functions which
are used to select candidates for deletion  from the original ontology  to restore coherence
and consistency  respectively  first  we define an incision function on dependency clusters
that helps to solve incoherence on the constraints 
definition     constraints incision function  a constraint incision function for kb
is a function      lr    lr     lr such that all following conditions hold 
sq
q
    kb      kb   
q
q
q
   for all x  kb and y  kb such that y  x it holds that  y   kb        
q
q
   for all x  kb it holds that t    x   kb    is such that there not exists r  x
where r satisfies conditions   and    and r   t  
intuitively  a constraint incision function takes dependency clusters and removes tgds
from each of them in such a way that the resulting kb is coherent  analogously to the
constraints
incision functions  we define data incision functions that solve inconsistencies in
 
 
 
kb
definition     data incision function  a data incision function for d is a function
      lr    lr     lr such that all following conditions hold 
s 
 
   kb      kb   
 
 
 
 for all x  kb and y  kb such that y  x it holds that  y    kb        
 
 
 for all x  kb it holds that t    x    kb    is such that there not exists r  x
where r satisfies conditions    and     and r   t  
   

fideagustini  martinez  falappa   simari

finally  it is necessary to make a significant remark regarding our usage of incision
functions  for that  let us first consider the following excerpt quoted from hanssons       
cf  p       regarding the possible parameters passed to selection functions  which in our
case are incision functions  and how this choice affects the possible outcomes 
         the proof of uniformity makes essential use of the fact that selection functions have been defined on remainder sets of the form a  not on pairs of the
form ha  i  if we had instead defined selection functions as follows 
  a    is a non empty subset of  a    if a is non empty 
  a       a  if a is empty 
t
then  a    would have been an operation very similar to partial meet contraction in other respects  but it would have been possible for  a        a   
to hold if a   a  which the standard definition does not allow         
thus  extending hanssons observation to incision functions and their use on consolidation 
we have that if we take only the sets of conflicts as arguments for incisions then the formulas
to be removed from two different ontologies having the same set of conflicts by an operator
using the incision function are identical  the reason for this is that the operator could not
tell the difference between the ontologies since its parameter is only the conflicts  which are
exactly the same  however  here we have chosen not to restrict our family of operators to
such behaviors  instead  we model operators whose behavior could select for removal the
same formula from equal conflicts  but that are not restricted to that choice  to achieve
this  we have chosen to take ontologies as parameters  so  if it fits the application domain
in which the operators are exploited  formulas that are not in any conflict could affect the
outcome of the consolidation 
in the approach presented here  an incision function not only should consider the tgds
effect over a cluster  but its global effect over the whole knowledge base  the reason for
this requirement is that unlike the classic models of belief revision  the language used has
greater expressivity and the fact that a tgd generates multiple inferences  for instance 
in our framework from a tgd of the form xy x  y   z x  z  it is possible to
infer multiple instances of  x  z  
to see the reason behind our choice more clearly consider the following example 
example    consider the following ontologies 


d    p a   q a  





nc    p x    r  x     
kb    





t        q x    r  x   








kb    








d    p a   q a  








 nc    p x    r  x     












     q x    r  x   
    p x    s x   
    p x    t x   













t  








for these kb   the set of data clusters are equal  as we have
   

fidatalog  ontology consolidation

 
 
kb  

 

 
 
kb  

 



 p a   q a  

 

if we use the standard approach and take clusters as arguments for incisions  then we must
remove the same formula in both ontologies  because as it was explained the incision is a
function and therefore it cannot choose differently for the same argument 
nevertheless  suppose that in our particular scenario we want to remove the atoms based
on the information they help to infer  if that is the case  then from kb   we should remove
p a   but from kb   we should take out q a   since in kb   the formula p a  triggers more
tgds  thus inferring more atoms  to achieve this type of behavior  it is necessary to pass
ontologies as parameters  since it is that what provides the adequate context 
      cluster contraction based consolidation operator
lastly  we define the consolidation operator for datalog  ontologies that represents the two
different parts in the consolidation  first  the coherence restoration of the component 
is obtained based on the dependency clusters in the d component in the original ontology 
second  the restoration of consistency in the d component is obtained based on the data
clusters w r t  the   component obtained by applying a constraint incision function on the
original   in this way we achieve the behavior stated earlier in the paper  in a sense  we
give the incoherence resolution higher priority  since if we can retain atoms by addressing
unsatisfiable sets of tgds instead  we choose to follow that path  the cluster contractionbased consolidation operator is formally defined as follows 
definition     cluster contraction based consolidation operator 
let kb be a datalog  ontology   be a constraint incision function and   a data incision
function  also  let kb      d      kb    be the datalog  ontology resulting from deleting
from kb the tgds selected by   the cluster contraction based consolidation operator
kb    is defined as follows 
kb      d     kb          kb   
the result of kbq
  is the datalog  ontology obtained by removing 
first  the tgds
 
 
q
 selected by  from
  and then atoms  selected by   from
  from the original
kb  
kb
ontology kb   it is important to note that  on one hand only tgds are removed from
  as dependency clusters do not contain egds or ncs  on the other hand  as the data
incision function uses kb   instead of kb then only atoms from d that are in conflicts with
    kb   are removed  this is because data clusters are calculated based on the constrains
obtained after the consolidation of  
    relation between postulates and construction  representation theorem
in section   we have introduced the properties that a datalog  consolidation operator
must satisfy  by means of the following representation theorem we can now establish the
relationship between the set of postulates for a datalog  ontology consolidation operator
and the cluster contraction based consolidation operator that we proposed in the previous
section  in what follows we denote with   a consolidation operator defined as in definition   
where  and   correspond to arbitrary constraint and data incision functions  respectively 
   

fideagustini  martinez  falappa   simari

theorem    representation theorem  the operator consolidation   is a cluster
contraction based datalog  ontology consolidation operator for a datalog  ontology kb
iff it satisfies inclusion  coherence  consistency  and minimality 

   a complete example of datalog  ontologies consolidation
we have introduced an operator that allows us to consolidate datalog  ontologies that
satisfies the set of expected properties expressed by the postulates in section    in this
section  the complete process for the consolidation of datalog  ontologies is depicted in the
following example 
example     consolidation of datalog  ontologies  suppose that we have the  in 

coherent and inconsistent  ontology kb shown in figure    which expresses the information
we have collected about certain company 

d 




























nc  













e  
kb  






t  




































 a 
a 
a 
a 
a 
a 

  boss walter    a    supervises walter   jesse  
  makes decisions walter   a    makes decisions jesse  
  supervises skyler   walter    a    employee walter   
  in charge of  jesse  distribution  
  in charge of  walter   cooking  
  on strike mike  

     follows orders x    makes decisions x     
    supervises y   x    supervisor  x     
    absent x    on strike x     
     in charge of  x   y    in charge of  x   y      y   y    
     employee x    is supervised  x   
    is supervised  x    follows orders x   
    boss x    makes profit x   
    supervises y   x    supervisor  y   
    supervises y   x    employee x   
    is supervised  x    makes decisions x   
    is supervised  x    has work  x   
    has work  x    get paid  x   
    has work  x    y in charge of  x   y   
     on strike x    absent x   





















































































figure    the original ontology to be consolidated 
now  to begin with the first part of the consolidation process  i e   solving incoherences by making the set t satisfiable  we obtain  as the first step towards obtaining the
dependency clusters  the dependency kernels for kb  
q
kb

                    

and based on the kernels  we calculate the set of dependency clusters for kb
q
q
                    
kb
   

fidatalog  ontology consolidation

q
q
q
note that  as there is no overlap among dependency kernels  we have kb   kb   next 
we use a cluster incision function to solve incoherency problems  for the sake of the example
assume that we will guide the contraction process by means of a quantitative criterion  i e  
choosing among the possible incisions the ones that removes fewer formulas  and using
the plausibility among formulas when the cardinality of the incisions is the same  in the
following we show the possible incisions  i e   those satisfying the conditions in definition    
these sets are
 for cluster          we could either remove   or     since the two incisions remove
the same number of atoms assume for this example that   is more plausible than    
and thus we prefer to retain the former 
 for cluster       we can only remove     
then  the particular incision in this example will be as follows 
                 
               
now  we move on to the next part in the consolidation process  the consistency recovery 
as explained before  for this part the operator only considers tgds that will effectively be
included in the consolidation  in this particular example this is t     t              from
now on then let kb      d      based on kb   we calculate the data kernels 
q
    a    a      a    a      a    a      a    a    
kb  
then  we obtain the data clusters  which are 
q
q
    a    a    a    a    a    
kb  
now  to solve inconsistencies we need to consider those sets such that the intersection
with all kernels included in the clusters is not empty  using t   instead of t when doing
this  once again  we analyze the possible incisions  the sets respecting all conditions in
definition     in the light of the number of atoms deleted and the plausibility of the formulas
in them  the different possible incisions for the cluster are 
  to remove  a    a    
  to remove  a    a    a    
  to remove  a    a    a    
  to remove  a    a    a    
once again  each of the sets presented is such that its removal induce an operator that
satisfies the postulates  and thus is captured by our framework  nonetheless  as explained
before for this example we will choose to remove as few atoms as possible  that is  we
choose to remove  a    a      and so we have
    a    a    a    a    a         a    a    
then  using a datalog  ontology consolidation operator based on the contraction of
clusters like the one introduced in definition    we can obtain the coherent and consistent
ontology shown in figure   
   

fideagustini  martinez  falappa   simari

kb    


d     boss walter    makes decisions jesse  




supervises skyler   walter    employee walter   




in charge of  jesse  distribution  




in charge of  walter   cooking  




on strike mike  








nc      follows orders x    makes decisions x     




supervises y   x    supervisor  x     




absent x    on strike x     



e    








t    

































































 in charge of  x   y    in charge of  x   y      y   y     







 employee x    is supervised  x   




is supervised  x    follows orders x   




boss x    makes profit x   




supervises y   x    supervisor  y   




supervises y   x    employee x   




is supervised  x    has work  x   




has work  x    get paid  x   



has work  x    y in charge of  x   y   

figure    the ontology resulting from the consolidation 

   related work
the most closely related work to ours is the work by croitoru and rodriguez         in that
work the authors present consolidation operators that are used as the basis for the definition
of semantics for inconsistency tolerant ontology query answering for datalog   a more
expressive language than datalog    cal et al          as for the case with our work  the
work by croitoru and rodriguez        is based on the use of hanssons incision functions
 hansson        to solve conflicts  nevertheless  there are some remarkable differences
between the works as well  among the most important ones is that the operators presented
by croitoru and rodriguez only deal with inconsistent ontologies  but no acknowledgment
of the incoherence problem is made  as we have shown through this work  this can have a
significant impact in the quality of the consolidation when analysed with respect to minimal
loss of information  moreover  this fact makes that  even though the set of postulates in
both works are similar in spirit  the family of operators characterized by croitoru and
rodriguez is a subset of the ones characterized here  this is due to the fact that the setting
that we consider here  i e   both inconsistent and incoherent ontologies  is more general 
since for instance our operators remove not only facts but also tgds  which croitoru and
rodriguezs operators do not since they only focus on inconsistency 
another closely related work is the one by lukasiewicz et al          there  the authors define a general framework for inconsistency tolerant query answering in datalog 
ontologies based on the notion of incision functions  nevertheless  their work is focused on
enforcing consistency at query time obtaining  lazy  consistent answers from an inconsistent ontology instead of consolidating one  clearly  such process must be carried on for
every query posed to the system  while with our approach we obtain a new knowledge base
   

fidatalog  ontology consolidation

in an offline manner  and such knowledge base can be queried without considering inconsistency issues  both approaches can prove useful  depending on the application domain 
additionally  as only one kb is used the rational assumption that there are no conflicts
in the constraints in  is also made  and therefore there are no notions of unsatisfiability
and incoherence  as stated before  in order to gain generality we have chosen to drop that
assumption  and treat incoherence problems as well as inconsistency ones  in addition to
the works by croitoru and rodriguez and lukasiewicz et al   there are several other works
that solve inconsistency or incoherence by means of adapting approaches based on belief
revision techniques in other knowledge representation formalism 
    propositional knowledge bases
there are numerous works in revision and merging of propositional knowledge bases  see  for
instance  konieczny   perez        katsuno   mendelzon        lin   mendelzon       
liberatore   schaerf        everaere  konieczny    marquis        konieczny   perez 
      delgrande  dubois    lang        booth  meyer  varzinczak    wassermann       
delgrande        delgrande   jin        falappa  kern isberner  reis    simari        
which had provided the foundations to further work on  fragments of  first order logics 
as expected  those works have deep connections with ours  but also has some remarkable
differences  as we shall see 
as we have mentioned throughout the paper  the work by sven ove hansson       
provides the inspiration and foundations for our work  we follow an approach akin to kernel
contraction and several intuitions from it  adapted to an ontological language  datalog   
as a consequence  besides treating incoherence we also provide a complete inconsistency
resolution process which takes advantage of the ontological setting  exploiting the relation
between the components of the ontology to define how coherence and consistency should be
restored  also  the classic incision functions introduced by hansson produce their incision
over minimal conflicts  in our approach  however  we work over clusters  which are groupings
of kernels  and thus they are not always minimal  then  we propose a particularization over
hanssons incision functions  focusing on those incision functions that successfully work over
clusters 
konieczny and pino perez        made one of the main contributions on the merging
of conflicting information  in our work we follow some of the intuitions proposed by them 
nevertheless  the main difference between their approach and ours  besides the obvious one
on the aims of the works  merging vs  consolidation  is that they state that the final merging
will be consistent only in presence of a consistent  or  in our terminology  coherent  set of
integrity constraints  and they do not analyze the alternative case 
with respect to the work by lin and mendelzon         besides the difference in the
focus  once again merging vs  consolidation   the main difference in the inconsistency
management strategy chosen with our work is that their conflict solving strategy relies on
the votes of the majority to establish which formulas is retained in the merging  instead 
we have chosen not to introduce a particular strategy  nevertheless  it is possible to adapt
our framework to the use of preference relations to choose between possible incisions  in a
similar way to what we have shown in example      such relations can indeed be designed
to comply with the majority intuition  providing that we have the votes  which does not
   

fideagustini  martinez  falappa   simari

apply to an ontology consolidation environment since there is only one ontology   thus
obtaining a similar strategy 
in the work by katsuno and mendelzon        the problem of knowledge base revision
for the propositional case is addressed  as in our approach  the same language is used to
express both the facts about the world and the constraints imposed to them in some kb  
nevertheless  once again the difference between the  in this case  update of a kb and the
consolidation of a kb arises in the treatment of the integrity constraints  in their work
integrity constraints are considered invariant and the updates to restore consistency are
restricted to facts 
in they works by delgrande         delgrande and jin        the authors present an
approach for revising a propositional knowledge base by a set of sentences  where every
sentence in the set can be independently accepted but there can be inconsistencies when
considering the whole set  the main idea follows from the agm theory  but differs in
that  it is necessary to alter the success postulate so it suits the intuition that not every
sentence in the set have to be in the final revision  since this set can be inconsistent  
guided by the principle of informational economy  they characterize the revision as the most
plausible worlds among the various maximally consistent subsets of the set of sentences  in
a parallel with our datalog  ontology environment  this is as revising the d component in
the ontology to solve inconsistencies  being the set of sentences inconsistent  the union of
it with the original kb will be inconsistent  nonetheless  there is an important difference
between these works and ours  in those works the authors first solve inconsistencies in the
set of sentences  so they can decide which subset of it will characterize the revision  our
approach is different  as we directly consider an inconsistent kb   then  in order to solve
the same problem in our setting  it is necessary to consider the union of the kb with the
entire set of sentences  and then apply a consolidation operator 
    knowledge expressed in description logics ontologies  logic programs
and relational databases
we now focus on other knowledge representation formalisms that are more closely related
to datalog    mainly in the family of description logics  baader  calvanese  mcguinness 
nardi    patel schneider        and logic programming  lloyd        nilsson   maluszynski        gelfond         a remarkable work using belief revision to solve conflicts in dls
is the one by qi  liu  and bell         which is based on the agm theory  alchourron
et al         gardenfors         what makes this work stand out is that they do not only
introduce the generalizations of the agm postulates to the case of dls  but also define two
operators on knowledge bases  based on formulas weakening  that satisfy such postulates 
the main difference with our approach is that they only take into account consistency problems in the ontologies  and no incoherence treatment is provided  as we pointed out earlier 
incoherence can lead to extreme a weakening of the information  where they may have to
take out every individual name from some general concept inclusion 
as we have previously mentioned  our notion of incoherence was inspired by schlobach
and cornets work         among others  in that paper the authors focus on the definition
of processes capable of detecting unsatisfiabilities and incoherences in dls ontologies  introducing complete algorithms along with an empirical analysis of the approach  nevertheless 
   

fidatalog  ontology consolidation

as it is not in the main focus of their work  the authors set aside the issue of how to recover
coherence once a conflict has been detected  and also do not consider inconsistencies  in our
work we presented a consolidation process that treats both incoherence and inconsistency 
based on the use of belief revision techniques  thus  the approach presented by schlobach
and cornet could potentially be useful regarding the implementation of the operators presented in this work  providing an effective way of obtaining the set of kernels in which the
set of clusters will be based 
black et al         propose an approach that is capable of using information coming from
several dl ontologies in order to answer queries  taking care in the process of both incoherence and inconsistency  their approach is based on agents with argumentative capabilities 
each one with a personal knowledge base in the form of a dl ontology  these agents use
dialogue games to interchange arguments until they reach an agreement about the answer
to a certain query  thus  the agents can use the  possible incoherent inconsistent  union
of the ontologies without merging them  and still obtain an answer influenced by every
ontology in play  moreover  this approach has the advantage that no information is lost 
as no formula is deleted from the ontologies  and as a result the inferences obtained by
this approach are a superset of those that can be obtained in the ontology resulting from
the consolidation of the union of dl ontologies  even though the authors argue that one
advantage of the proposed approach is that they do not need to waste time and effort in
performing the consolidation of the kb   one disadvantage is the computational complexity
associated with argumentative reasoning  parsons  wooldridge    amgoud        dunne  
wooldridge        cecchi  fillottrani    simari        as this process has to be conducted
for each query issued and in an online manner  even though a consolidation process can
also be computationally expensive  it is only necessary to perform it once and it can be
done offline before the query answering system becomes available  the choice of one approach over the other depends highly on the environment in which they will be used  i e  
on the size of the ontologies that will be used  how often updates are issued over the kb
or how critical time consumption is for the system  among other considerations  of course
the set of inferences that can be obtained from every approach may differ and this should
also be taken into account  a consolidation based approach could be more suitable for
time dependant systems like real time systems or query intensive systems where the data
tractability associated with  a consolidated  datalog  ontology may be proven handy 
another work worth mentioning is that by kalyanpur  parsia  horridge  and sirins
        this work verses on how to find all justifications of entailments over a description
logics ontology  a justification is simply the precise set of axioms in an ontology responsible
for a particular entailment  kalyanpur et al          in other words  it is a minimal set of
axioms sufficient to produce an entailment  which is related to our use of kernels as a mean to
obtain clusters as part of the consolidation strategy used  moreover  horridge  parsia  and
sattler        state that justifications are important for repairing inconsistent ontologies 
thus  they could be important for the definition of consolidation processes similar to our
cluster based consolidation  as if at least one of the axioms in each of the justifications for
an entailment is removed from the ontology  then the corresponding entailment no longer
holds  kalyanpur et al         p        one of the main contributions of that work is the
definition of practical black box  i e    reasoner independent  techniques that allows us to
find justifications for entailments in the ontology in an efficient way  as such  is evident
   

fideagustini  martinez  falappa   simari

that while our work verses in a different direction we still can benefit from those findings  in
particular  it may be possible to use the developed algorithms as part of our implementation
strategy for our consolidation operators  adapting them to be used in datalog  and our
dual incoherence inconsistency setting 
regarding logic programming  there are also several works that address the problem
of merging knowledge bases expressed as logic programs  solving inconsistency issues in
the process  for instance  hue  papini  and wurbel        introduce a merging process
based on stable model semantics  using the logic of here and there  turner         hue
et al  consider the merging strategy based on pre orders among deletion candidates called
potential removed sets and they do not establish any particular way to obtain these preorders  instead  they assume that for any strategy p there is a given pre order that defines
p   as for the case with lin and mendelzons work         although it falls out of the scope
of the present work we certainly can adapt our framework to use similar techniques when
choosing which incision prevails 
another notorious work in the logic programming field is the one by delgrande  schaub 
tompits  and woltran         in that work two different approaches are proposed  the first
one follows an arbitration approach  selecting the models of a program that differs the least
w r t  the models of the other programs  in this work the case of unsatisfiable programs is
studied  similar to the way we consider incoherence leaded by unsatisfiable sets of tgds 
nevertheless  they consider unsatisfiability of a certain program  and not of some concept
in the union of the programs  furthermore  the strategy to solve unsatisfiability is simply
leaving the unsatisfiable program out of consideration for the merging  instead of trying to
solve the conflict somehow  the second approach is based on the selection of the models of
a special program p    which can be thought as the constraints guiding the merging process 
that has the least variations w r t  the programs for the merging  this approach can be
seen as a particular instance of the approach proposed by konieczny and perez        
in the area of databases  one of the most influential works is the one by arenas et al 
       on consistent query answering  there the authors propose a model theoretic definition of consistent answers to a query in a relational database potentially inconsistent with a
set of integrity constraints  intuitively  the consistent answers to a query is the set of atoms
that are  classical  answers to the query in every repair of the inconsistent database  a
repair is a set of atoms that satisfy the set of constraints and is as close as possible to the
original database  different notions of repairs have been studied in the literature  as well as
different notions of what it means for a set of atoms to be as close as possible to the original
database  most of the proposals are based on repairing by inserting and or deleting tuples
to from the database  actually  the possible actions depend on the form of the integrity
constraints and their expressiveness  and the notion of closeness is defined via set inclusion
or cardinality  the work by arieli  denecker  and bruynooghe         however  proposes
a uniform framework for representing and implementing different approaches to database
repairing based on minimizing domain dependent distances  the main idea of that work is
to show how thinking in terms of  different  distances to express preferences among repairs
leads to different preferences that can be applied in different scenarios  the authors show
that the set of repairs obtained using the proposed distance functions deviate from those
that can be obtained using set inclusion  furthermore  besides insertion and deletion of entire tuples there are other several domain independent approaches  e g   based on cardinality
   

fidatalog  ontology consolidation

or more complex objective functions  in the approach proposed by wijsen        updates
are considered a primitive in the theoretical framework  bohannon et al         present a
cost based framework that allows finding good repairs for databases that exhibit inconsistencies in the form of violations to either functional or inclusion dependencies  allowing
also updates to attribute values  in that work  two heuristics are defining for constructing repairs both based on equivalence classes of attribute values  the algorithms presented
are based on greedy selection of least repair cost  and a number of performance optimizations are also explored  a quite different semantics for repairing is proposed by caroprese 
greco  and zumpano         caroprese and truszczynski        through active integrity
constraints  aics for short   an aic is a production rule where the body is a conjunction
of literals  which should be false for the database to be consistent  whereas the head is a
disjunction of update atoms that have to be performed if the body is true  that is the constraint is violated   repairs are then defined as minimal sets  under set inclusion  of update
actions  tuple deletions insertions  and aics specify the set of update actions that are used
to restore data consistency  hence  among the set of all possible repairs  only the subset
of founded repairs consisting of update actions supported by aics is considered  other
works in this area propose different semantics for repairing by either explicitly or implicitly
considering a preference relation among the set of repairs  cf  andritsos  fuxman    miller 
      staworko  chomicki    marcinkowski        greco   molinaro        
more recently  in the area of ontology based data access  obda   lembo et al        
study the adaptation of cqa for dl lite ontologies  called ar  abox semantics   in that
work  also the intersection  iar  semantics is presented as a sound approximation of consistent answers  this semantics consists of computing the intersection of all repairs and answers
are obtained from there  though  possibly many  ar answers cannot be obtained from under the iar semantics  the latter are computationally easy to obtain for the dl lite family 
i e   it is not necessary to compute the whole set of repairs in order to compute their intersection  the data and combined complexity of these and other semantics were studied  rosati 
      for a wider spectrum of dls  also  rosati        presents intractability results for
query answering for el under the intersection semantics  and a non recursive segment of
that language was proved to be computable in polynomial time  more recently  bienvenu
and rosati        propose another family of approximations to cqa  also for the dl lite
family  the k support semantics allows to  soundly  approximate the set of queries entailed
under the cqa semantics  based on k subsets of the database that consistently entail q 
on the other hand  the k defeater semantics approximates complete approximations seeking
sets that contradict the supporters for q  both semantics are fo rewritable for any ontological language for which standard cq answering is fo rewritable as well  and can be used
in conjunction to over  and under approximate consistent answers 
much like black et al          the treatment of inconsistencies proposed by all these
semantics is related to particular queries instead of the inconsistency of the whole database 
thus  they do not attempt to obtain a final consistent database that can be queried without
considering restrictions  furthermore  they do not address the issues of incoherence and
inconsistency together  instead most of the approaches either assume that the set of integrity
constraint correctly defines the semantics of the database instance  so there is no room for
incoherence  or they treat constraints and data alike at the moment of removing or ignoring
information  which leads to the type of problems that we discuss in example     while
   

fideagustini  martinez  falappa   simari

these techniques may be suitable for the case of one single database  in the presence of
incoherence in the set of ics  as can be the case when we consider several databases together 
this approach would lead to meaningless empty answers  since no subset of the database
could satisfy the constraints as would also be the case for the approach by lukasiewicz
et al         
also related to the databases field is the work by lin and mendelzon         there 
a database is viewed as a first order theory without rules  and ics are used to ensure
consistency in the final result as in the work by konieczny and perez         presenting ways
to solve known database merging problems like synonyms and homonyms  nonetheless  like
konieczny and pino perezs work  they do not consider problems related to the set of ics 
instead  the set of ics used in the merging process is unique  and the choice of such set is
expected to be performed by a merge designer  unlike lin and mendelzon  we do not made
an assumption for our consolidation environment on the set of ics being conflict free 
cholvy        introduces another approach that can be used to reason with contradictory information  the framework is represented through a set of axioms and inference
rules  additionally  in the paper several applications for the framework are introduced 
e g   the solving of conflicts among beliefs represented by first order databases  where facts
are ground literals and there are rules that can be integrity constraints or deduction rules 
in that scenario  contradiction is obtained by the application of the constraints when considering several databases together  this establishes a certain parallel with the case of
inconsistency in a datalog  ontology  however  the main difference with our work lies in
how the strategy for the inconsistency management process is defined  in that work  a
preference order between databases is assumed  instead  we have chosen not to restrict how
to achieve the consolidation  thus presenting a general approach  nevertheless  as stated
before we can adapt incision functions to suit the intuition that no every formula is equally
desirable  choosing for instance preferences between ontologies as a guideline  if we are using
the approach for other tasks rather than consolidation of a single ontology   obtaining an
inconsistency management strategy akin to the one introduced by cholvy 
finally  meyer  lee  and booth        use two well known techniques for knowledge
integration for the propositional case  adapted and refined to the expressiveness of dls 
the proposed approach takes the knowledge bases and produces a disjunctive knowledge
base  dkb  as the result of the integration  one disadvantage of dkbs is that they state the
possible options we can take when the conflicting knowledge is expected to be exploited by a
reasoning process rather than choosing one of them  thus  contrary to our approach where
a final consolidated ontology is given  in theirs there is no definitive final merging  moreover 
they set aside for further research problems related to incoherence in the integration process 

   conclusions and future work
collaborative work and information exchange are becoming key aspects of almost any system  thus  it is of the uttermost importance to have automatic and adequate ways to solve
conflicts  as knowledge evolves in a collaborative environment incoherence and inconsistency are prone to arise  this knowledge is often represented by ontologies that can be
collaboratively built  and often shared among entities that use and modify them  one particular way to deal with the conflicts that can appear in such application environments is
   

fidatalog  ontology consolidation

to try to modify the information contained in the ontology in order to regain coherence and
consistency  in this paper we have shown how to achieve the consolidation of datalog 
ontologies  we introduced the concept of incoherence in datalog  ontologies in terms of
unsatisfiability of sets of tgds  and showed the relationship with the classical notion of
inconsistency of a logical theory that lacks models 
we also proposed a construction for consolidation operators  the construction is inspired by kernel contraction  and uses incision functions on groupings of minimal unsatisfiable inconsistent sets called clusters to solve conflicts  finally  we stated the properties
that the datalog  ontology consolidation operator is expected to satisfy  we showed that
our operators satisfy the respective properties  obtaining as the result of the consolidation a
new datalog  ontology that is always coherent and consistent while minimizing the changes
that are made in the conflict resolution 
as a final remark  notice that these operators take care of all incoherences in the ontology  however  there are rare cases when the ontology designer introduce some unsatisfiable
concepts in an ontology on purpose  to model some particular feature of the application domain  if that is the case then we should not remove the incoherence  and rather we have to
delete the atoms triggering it  if any  clearly  since they were not defined with that setting
in mind this behavior cannot be achieved by the operators presented here  nevertheless  to
modify our present approach to suit such setting is almost straightforward  provide that we
can identify whether or not some unsatisfiable set of tgds is made on purpose or not 
as for future work  we intend to study new constructions for datalog  consolidation
operators  to do this  first we plan to change the general approach  i e   operators based
on formalisms other than kernel contraction  mainly from the agm theory  alchourron
  makinson        alchourron et al          and then  while the proposed framework for
cluster contraction based consolidation operators is fully constructive  depending on the
application domain it may certainly be difficult to asses how to effect the incisions  i e   it
may be hard to decide among the family of possible incisions which one to select  from
a design point of view  it may be easier to select how to perform the consolidation if we
have some additional information about the formulas in the knowledge base  such as a
preference relation that can  for example  be elicited from domain experts  in general  it
could be easier for an expert to provide guidelines and information about the application
domain at hand that could be then modeled into a preference relation on the formulas in
an ontology rather than trying to single out the desired incisions  in this direction we want
to explore constructions based on exploiting preference relations among the formulas in the
ontologies to define different strategies to choose which formulas to delete  possibly tailored
for particular scenarios  mainly  we plan to analyze two different aspects  the relation
between these operators based on preference relations with respect to the ones presented in
this work  and how different strategies affect their behavior 
also  in this work we make a point in differentiating the concept of inconsistency from
that of incoherence  therefore  we need to focus on languages that separate extensional
from intensional knowledge  otherwise the two notions are indistinguishable  as it is the
case in propositional logic   in that sense  the choice of datalog  is due to its desirable
property of generalizing several popular languages such as classical datalog  dl lite  elh 
f logic lite  etc  even though in this paper we do not perform a particular analysis of the
effects of nulls in the proposed solutions to consolidation  the datalog  family of languages
   

fideagustini  martinez  falappa   simari

was chosen because it offers a wide variety of languages with high computational tractability
 some are fo rewritable and others have ptime inference algorithms   the results in this
work pave the way to continue the research line into the next natural step  which is to show
how  or whether  the different syntactic and semantic properties that yield tractability for
query answering allow us to obtain tractability results also for the consolidation problem 
much in the same way as it has happened already in the area of consistent query answering
 where only repairs over the extensional part of the kb are considered   it is  for example  in
the rewriting algorithms where the capability of value invention plays an important role  the
value invention process should be controlled  in general with syntactic restrictions  in order
to keep a low complexity for the reasoning tasks  with this in mind  in the future we will
further look into the role of processes like value invention in the consolidation of datalog 
ontologies  and their impact both on how conflicts should be solved and computational
efficiency 
we are currently working on the implementation of our operators  we plan to study different techniques that can be used in order to produce an efficient implementation  possibly
tailored for specific fragments of datalog    as explained before  the algorithms introduced
by schlobach and cornet        can be proven useful regarding this aspect since they may
provide a way to calculate the kernels in a datalog  ontology  thus providing the first step
towards incoherence resolution  another important work regarding the implementation of
our consolidation operators is the one by wassermann         where the author shows that
the minimal incision functions of a knowledge base can be obtained from the kernels of a kb
by using any algorithm for finding minimal hitting sets  reiter         several works in the
area of ontology debugging and repairs   e g   halaschek wiener   katz        or horridge
et al        as a way to find the justifications for an inconsistency  have exploited reiters
algorithms in order to implement their frameworks  among others  we plan to study how
adequate this techniques are for our operators  as there is an almost direct relation between
minimal incision functions and reiters minimal hitting sets  in this way  it may be possible to adapt reiter techniques to attend incoherences and inconsistencies  moreover  as we
already discussed  we plan to analyze the relation between cluster incision functions and
preference relations  regarding implementation  we hold the conjecture that such relations
can be exploited to further refine the implementation of the operators  reiters algorithm
is based on the expansion of a directed acyclic graph  and such expansion is made in a
breadth first fashion  which in the end generates all possible values for minimal incision
functions  as acknowledged by wassermann  if some kind of ordering among the formulas
is present  this ordering can be used to choose which branch to expand  in other words  not
only it may be possible to implement the construction for operators proposed in this work
by means of exploiting reiters hitting sets algorithm  but also we can use the preference
relation equivalent to the incision  if any  to guide the consolidation process  that is  it
may be possible to adapt the algorithm so it chooses to expand the branch that has the less
preferred set of formulas  thus guiding the graph expansion process 

appendix a  proofs
proof for proposition  
   

fidatalog  ontology consolidation

proof consider some u  t such that u is an unsatisfiable set of dependencies w r t 
nc  e   and a  d a set of atoms relevant to u  
it follows from the definition of satisfiability of a set of dependencies w r t  a set of
constraints that if u is unsatisfiable then there does not exist a relevant set of atoms a 
that makes mods a    u  e  nc        because otherwise u is satisfiable 
then  mods a  u  e  nc       moreover  since a  d and u  t we have that
chase a  u    chase d  t    and thus any nc or egd that is violated in chase a  u   is
also violated in chase d  t    thus  mods d  t  e  nc       i e   kb is inconsistent 
proof for lemma  
proof let kb      d        with      t   e   nc   and kb     q
       with

     t   e   nc be twoqdatalog ontologies such that         kb   be the
dependency kernels of kb     and kb   be the dependency kernels of kb     respectively 
q
consider any x  kb     then  by definition   we have that x   t is an unsatisfiable
set of dependencies w r t   e   nc and every x     x is satisfiable w r t   e   nc  
since         then  t    t    e    e and  nc    nc   and thus it holds that
x   t is an unsatisfiable set of dependencies w r t   e   nc and every x     x is
satisfiable w r t   e   nc  
q
then q
by definition   we q
have that
q x  kb     and since this holds for any arbitrary
kernel in kb   we have that kb     kb    
proof for proposition  
proof we will focus on the case of dependency clusters  omitting theqproof for data
clusters  as they are analogous to each other  consider any arbitrary y  kb  
  we begin by showing that if a kernel
then it is not
q
q part of any
q
qis part of a cluster
 
 
other cluster  i e   if y  x for some x  kb then y   x for all x  kb such that
x    x    
s
this is obtained directly from the definition of clusters  we have that x q
  y    y
where    is an equivalence class in the equivalence relation  obtained from kb   then 
clearly for y we have that if y  x then y      therefore  since by definition two
equivalence
classes are either equal or disjoint then it holds that y 
       for all       let
s
 
 
 
 
x   y        y   then it holds that x    x and that y   x   since this holds for any
q
q
arbitrary equivalence
class      then it holds that if y  x for some x  kb then y   x  
q
q
for all x    kb such that x    x    
  now we show that
to a cluster  i e  
q
q there not exist any  kernel that does not belong
q
q
 
if y   x for all x  kb such that x    x then y  x for x  kb   again q
this arise
q
from the use of equivalence classes in definitions   and     if y   x   for all x    kb such
that x    x     then it holds that y 
       for all             so 
ssince equivalence classes form 
a partition it must holds that y      therefore  as x   y    y we have that y   x
q
q
for all x    kb such that x    x   then y  x 
proof for corollary  
   

fideagustini  martinez  falappa   simari

q
proof consider
  y for some y  kb   by q
proposition
  we have that y  x for
q
q
q
  for all x   
some x  kb if and onlyq
if
y
 
x
such
that
x    x     thus  we have
kb
q
q
q
that   x for some x  kb if and only if  
  x   for all x    kb such that x    x    
 
 
  
analogously 
we
can
show
that


y
for
some
y
is such that   x for some
kb
 
 
 
 
 
 
x  kb if and only if  
  x for all x  kb such that x    x    
proof for lemma  
q
proof consider any x  kb     then  x is a minimal unsatisfiable set of tgds w r t 
 nc   e   since kb     kb     then it holds that x  kb      e    e    nc    nc and
x is an unsatisfiable set of tgds w r t   nc   e   also  there does not exist x     x such
that x   is an unsatisfiable set
contradict
q of tgds w r t   nc  e   since otherwise we wouldq
our hypothesis that x  kb     as  nc
e   then 
q    nc and  e    q
qx  kb     and
since this holds for any arbitrary x  kb     then we have that kb     kb    
q
q
q
consider
any arbitrary x  y  kb   such that xy   since
  kb     then
kb
 
q
q
q
q
q


x  y  kb     thus  q
is equivalent to q
  and then kb     kb    
kb  
kb  
 
 
 
  y     since
   y   
 
such
that
x
likewise  consider
any
arbitrary
x
kb
kb
   
 
  kb    
 
 
 


 
 
 
 
  and thus kb     kb    
is equivalent to 
then x   y  kb     therefore  
kb  

kb  

proof for proposition  
q
proof consider   d and x  kb such that  is relevant to x  from definition  
we have that x is unsatisfiable w r t  n  e  nc   and then from definition   and the
fact that  is relevant to x we have that mods     x  n           also  since    is
singleton then the only a      is a     and clearly
mods   x  n            then  from
 
         
 and definition   it follows that     kb   also  from definition   we have that
    kb   since    cannot overlap with any other kernel  being singleton 
consider the incision over     from definition    it follows that  kb           
then  we have that  kb           and thus    kb   
proof for corollary  
q
proof consider any arbitrary   d  since  is relevant to some x  kb   then by
proposition   it holds that    kb    thus  since this holds for any arbitrary   d we
have that d   kb   
proof for theorem  
proof let kb      d        and kb      d        be two datalog  ontologies such that
kb     kb    
  construction to postulates
consider an operator   defined as in definition     we have to prove that   satisfies every
postulate in theorem    let kb        d          and kb        d          be the two datalog 
ontologies resulting from the consolidation of kb   and kb   by means of    respectively 
be the ontology
furthermore  let kb       d         kb      and kb       d         kb      q
 
resulting from removing the tgds selected by  from kb   and kb     let kb   and kb  
 

   

fidatalog  ontology consolidation

q
 
be the set of dependency and data kernels for kb   and kb    respectively  kb   and kb  
q
q
 
   
be the sets of dependency and data kernels for kb   and kb      finally  let kb   and kb  
q
q
 
   
be the set of dependency and data clusters for kb   and kb    respectively  kb   and kb  
 
be the sets of dependency and data clusters for kb   and kb     
 inclusion         and d     d   
by definition of kb     we have that d      d      kb       and thus d     d   
in a similar way  by definition of kb     we have that            kb      and thus
        
 coherence  kb     is coherent 
to prove that kb     is coherent we have to show that t      is satisfiable for
e  nc       to do this it is sufficient to show that all minimal conflicts are
attended to by the operator  i e   that no dependency kernel is included in     
q
exists
consider
q
q any arbitrary x  kb     from proposition   we have that there q
q
y 
such that x  y   by definition of  it holds that for all y 
kbq
kb  
 
and x  kb   where x  y it holds that   kb      x       then  there exists
some   x such that     kb      x   and thus  
       therefore 
x       
q
i e   the conflict was solved  since this holds for any arbitrary x  kb   then every
unsatisfiable set in   is not included in      and thus t      is satisfiable for
e  nc       i e   kb     is coherent 
 consistency  proof is analogous to that for coherence 
 minimality  if kb    kb   is coherent and consistent  then it holds that kb      
kb    
 
letq
kb   is coherent and consistent  and let cf        
s 
 
s
qkb  kb   be such that
  kb   and cf d    d      kb   be the set of formulas that do not belong to any
kernel in   and d    respectively 
 
suppose
by reductio that kb     skb
 
    by definition of kb     we have that  kb     
s
q
q
  kb     and that   kb        kb    then  cf    kb     and cf d   kb     
therefore  we have that cf    kb   and that cf d   kb    
q
q
 
 
then  since kb      kb   there must exist   kb  kb such that   kb   but

  kb      while kb   is coherent and consistent all the same  that is  there exists a
dependency cluster or a data cluster where the removal is not optimal  since  could
be included in the consolidation  for the rest of the proof and for simplicity reasons 
we consider the case where  belongs to a dependency cluster  this is made without
loss of generality  since the proof for the case where  is included in a data cluster is
analogous to the one presented here 
q
q
let us consider then
such that   kb     by corollary   we have that
kb
q
q 
  x where x  kb   let t    x   kb    be the incision performed over the
cluster  and let r    x   kb   kb      be those formulas removed from xqwhen
obtaining kb     clearly  since kb   is coherent then for all y  x where y  kb it

   

fideagustini  martinez  falappa   simari

holds that r  y      because otherwise
y  kb     which will make kb   incoherent 
q
q
besides  since r  y then r  kb   and thus r satisfies the first two conditions in
definition    
by definition    we have that t is such that there not exists a set of tgds that
satisfies the first two conditions in the definition and at the same time it holds that
    t  r 
since  
  kb     and   x then    kb    and thus   t   however  we know that
  x and   kb     and thus  
  r  therefore we have that     t   r 
from     and     we have that t  r and that t   r  an absurd coming from our
original assumption that kb      kb     and it holds that if kb    kb   is coherent
and consistent then kb       kb    
  postulates to construction
for the second part of the proof  consider an operator   that satisfies all postulates in
theorem    let     be a function based on   defined as follows 
q
q
     kb        x   x  x for some x  kb   and x 
      kb      
let kb       d             kb      be the ontology resulting of removing from kb   the
tgds selected by       then  let     d be another function based on   defined as follows 
 
 
   d   kb      
    d  kb         x   x  x for some x  kb   and x 
 

based on     d and     we define a new operator as follows 
kb         d        d  kb                kb     
we have to show that    is a datalog  ontology consolidation operator based on cluster
contraction  to do this  we first prove that     d is a well defined data incision function
and that     is a well defined constraint incision function  that is  given     we have to
prove that 
      is well defined  i e   if kb     kb     then      kb            kb     
q
q
by definition of     we have that      kb        x   x  x for some x 
kb  
and x 
     kb      
consider
arbitrary
x       kb      since kb     kbq
  then by lemma   we have
 q
q
q any q
q
that kbq
 
 
since
x


 kb
  
then
x

x

  and thus it holds that
 
   
kb  
kb  

 
q
x  x  kb       
q
q
besides  since x  x  kb   then x      thus  since x 
     kb      then x 
  kb     
since kb     kb     from the fact that   is a function we have that kb       kb      and
then it also holds that x 
  kb      thus  x 
     kb        
from     and    q
qit follows that for any x       kb     it holds that x   y   y 
y for some y 
and y 
     kb       by definition of     this is      kb     
kb  
and thus we have that if kb     kb     then      kb            kb     
   

fidatalog  ontology consolidation

       kb     

sq
q
  kb     

this follows directly from q
the definition of       since for every x       kb     it holds
q
that x  x for some x  kb   because of the first condition in the definition 
  if x 

q
q

ey 

q

are such that y     and y  x  then  y       kb          
q
q
q
suppose by reductio
that there exists some x  kb   and y  kb   such that y     
t
y  x and  y      kb         
q
q
then  for all   y it holds that  
       kb
  
i e  


 
x

or      kb      
 
kb  
q
by our hypothesis we have that   y  kb   and y  x  thus   x  and therefore
it must hold that       kb       and by extension   kb     
kb  

kb  

since this holds for any arbitrary   y then we have that y       from definition  
it holds that y is a minimal unsatisfiable set of tgds w r t  e  nc      then 
for any relevant set of atoms a it holds that mods a  y  e  nc       then  since
y      then for any relevant set a  it holds that mods a         e  nc       because
the tgds in y are triggered by a    then      is an unsatisfiable set of tgds w r t 
e  nc     
however  from coherence we have that kb     is coherent  and thus     is satisfiable
w r t  e  nc     
then we have that     is satisfiable w r t  e  nc    and     is unsatisfiable
w r t  e q
nc      an absurd
coming from our initial supposition
q
q
t that there exists
some x  kb   and y  kb
such
that
y
 
 
 
y

x
and
 y
     kb         
 
q
q
q
andtit holds that for all x  kb   and y  kb   such that y  x  if y     then
 y      kb          
q
q
it holds that t    x       kb      is such that there not exists
  for all x 
kb  
r  x where r satisfies the two previous conditions and r   t  
to prove this is sufficient to show that  being clusters disjoint sets  the election in each
cluster is optimal  because otherwise if should exists any cluster where the incision
function does not choose in an optimal way then
q
q minimality would not be satisfied 
so  suppose by reductio that there exists x  kb   where t    x       kb      is such
that there does exist r  x where r satisfies the two previous conditions and r   t  
q
q
let us consider kb          d    such that for all y  kb   such that y    x it holds
that t      y       kb      and r     y   kb   kb       those formulas removed from
y when obtaining kb     are such that t     r    since t     r  then r  is q
such
q that
the two conditions
in
definition
  
are
satisfied 
besides 
let
cf
 

 
and
 
 
kb
 
 
cf d    d    kb be the set of formulas that do not belong to any kernel in   and
d    respectively  and let kb   be such that cf      and cf d   d   
the fact that every formula that is not in any conflict belongs to kb   and that kb   is
built in such a way that the election in each cluster different than x is the same both
in kb   and      kb     makes that kb      x   kb   kb        kb        x       kb      
this is  if there is any difference between kb   and kb     that difference arise from the
election on which formulas to remove from x 
   

fideagustini  martinez  falappa   simari

finally  from our supposition we have that there exists r  x where r satisfies the two
previous conditions and r   t   let kb   and r   t be such that r    x  kb  kb     
is the set of formulas removed from x when obtaining kb     then  we have that kb   is
coherent and consistent  since every conflict in clusters in kb   where solved  whether by
removing r  for cluster x  or the sets r   for every cluster different than x   besides 
since we have that kb      x   kb   kb        kb        x s     kb      and that r   t  
q
then for kb       kb          kb     and kb     kb       y  q
r   r  where
 x 
kb  

 r    y   kb   kb      and r    x   kb   kb      it holds that kb      kb       
that is  if all formulas that are not involved in conflicts belong to both kb     and kb    
in each cluster different than x the same formulas are removed  and the set of formulas
removed from x to obtain kb   are an strict subset of those removed by      kb     to
obtain kb      then kb     is an strict subset of kb     i e   we have removed more formulas
by deleting t than by deleting r 
on the other hand  since kb   is coherent and consistent  then by minimality we have
that kb       kb       
 
therefore  from     and     we have that kb      kb   and kb
q
q       kb   and absurd
where t    x 
coming from our initial supposition that there exists x 
kb  
     kb      is such that there exists r  x where
r
satisfies
the
two
previous
conditions
q
q
and r   t   and we have that for all x 
it
holds
that
t
 
 x


     kb     
kb  
is such that there not exists r  x where r satisfies the two previous conditions and
r   t 
we omit the proof that     d is a well defined data incision function using consistency
and minimality since it is analogous to the proof that     is a well defined constraint
incision function using coherence and minimality 
now that we have shown that     d and     are well defined data incision functions
and constraint incision functions  respectively  to conclude this second part of the proof
we have to show that    coincides with    from inclusion it follows that d     d  and
            also  from our definition of     d it follows that     d  kb        d    d    
and from our definition of     it follows that      kb                    then  from
    and     we have that d      d        d  kb      and                kb      thus     
 d        d  kb                kb       and therefore    coincides with   

references
alchourron  c   gardenfors  p     makinson  d          on the logic of theory change 
partial meet contraction and revision functions  journal of symbolic logic         
       
alchourron  c     makinson  d          hierarchies of regulation and their logic  new
studies in deontic logic         
alchourron  c     makinson  d          on the logic of theory change  safe contraction 
studia logica             
amgoud  l     kaci  s          an argumentation framework for merging conflicting knowledge bases  the prioritized case  in proc  of  th european conferences on symbolic
   

fidatalog  ontology consolidation

and quantitative approaches to reasoning with uncertainty  ecsquaru      pp 
       
andritsos  p   fuxman  a     miller  r  j          clean answers over dirty databases  a
probabilistic approach  in proc  of   nd international conference on data engineering  icde      p     
arenas  m   bertossi  l  e     chomicki  j          consistent query answers in inconsistent databases  in proc  of   th acm sigact sigmod sigart symposium on
principles of database systems  pods      pp       
arieli  o   denecker  m     bruynooghe  m          distance semantics for database repair 
annals of mathematics and artificial intelligence                   
baader  f   brandt  s     lutz  c          pushing the el envelope  in proc  of the   th
international joint conference on artificial intelligence  ijcai      pp         
baader  f   calvanese  d   mcguinness  d  l   nardi  d     patel schneider  p  f   eds   
        the description logic handbook  theory  implementation  and applications 
cambridge university press 
baral  c   kraus  s     minker  j          combining multiple knowledge bases  transactions on knowledge and data engineering                
bell  d  a   qi  g     liu  w          approaches to inconsistency handling in descriptionlogic based ontologies  in proc  of on the move to meaningful internet systems
 otm  workshops      pp           
beneventano  d     bergamaschi  s          incoherence and subsumption for recursive
views and queries in object oriented data models  data and knowledge engineering 
               
berners lee  t   hendler  j     lassila  o          the semantic web  scientific american 
            
bienvenu  m     rosati  r          tractable approximations of consistent query answering
for robust ontology based data access  in proc  of   rd international joint conference
on artificial intelligence  ijcai      pp         
black  e   hunter  a     pan  j  z          an argument based approach to using multiple ontologies  in proc  of  rd international conference on scalable uncertainty
management  sum      pp       
bohannon  p   flaster  m   fan  w     rastogi  r          a cost based model and effective heuristic for repairing constraints by value modification  in proc  of   th acm
sigmod international conference on management of data   principles of database
systems  pods      pp         
booth  r   meyer  t  a   varzinczak  i  j     wassermann  r          horn belief change 
a contraction core  in proc  of   th european conference on artificial intelligence
 ecai      pp           
borgida  a          description logics in data management  transactions on knowledge
and data engineering                
   

fideagustini  martinez  falappa   simari

brandt  s          polynomial time reasoning in a description logic with existential restrictions  gci axioms  and   what else   in proc  of   th european conference on
artificial intelligence  ecai      pp         
cal  a   gottlob  g     kifer  m          taming the infinite chase  query answering under
expressive relational constraints  in brewka  g     lang  j   eds    proc  of   th
international conference on principles of knowledge representation and reasoning
 kr      pp        aaai press 
cal  a   gottlob  g     kifer  m          taming the infinite chase  query answering
under expressive relational constraints  journal of artificial intelligence research     
       
cal  a   gottlob  g     lukasiewicz  t          a general datalog based framework for
tractable query answering over ontologies  journal of web semantic           
cal  a   lembo  d     rosati  r          on the decidability and complexity of query answering over inconsistent and incomplete databases  in proc  of   nd acm sigmod
symposium on principles of database systems  pods      pp          acm 
calvanese  d   de giacomo  g   lembo  d   lenzerini  m     rosati  r          dl lite 
tractable description logics for ontologies  in aaai  pp         
caroprese  l   greco  s     zumpano  e          active integrity constraints for database
consistency maintenance  transactions on knowledge and data engineering         
         
caroprese  l     truszczynski  m          active integrity constraints and revision programming  theory and practice of logic programming                 
cecchi  l   fillottrani  p     simari  g  r          on the complexity of delp through
game semantics  in dix  j     hunter  a   eds    proc  of   th international workshop on non monotonic reasoning  nmr      pp         
cholvy  l          reasoning about merged information  in belief change  vol     pp 
        springer netherlands 
croitoru  m     rodriguez  r  o          using kernel consolidation for query answering in
inconsistent obda  in proc  of the joint ontology workshops      episode    the
argentine winter of ontology 
delgrande  j  p          revising by an inconsistent set of formulas  in proc  of   nd
international joint conference on artificial intelligence  ijcai      pp         
delgrande  j  p   dubois  d     lang  j          iterated revision as prioritized merging 
in proc  of   th international conference on principles of knowledge representation
and reasoning  kr      pp         
delgrande  j  p     jin  y          parallel belief revision  revising by sets of formulas 
artificial intelligence                    
delgrande  j  p   schaub  t   tompits  h     woltran  s          merging logic programs
under answer set semantics  in proc  of   th international conference on logic programming  iclp      pp         
   

fidatalog  ontology consolidation

dunne  p     wooldridge  m          argumentation in artificial intelligence  chap  complexity of abstract argumentation  pp         springer 
everaere  p   konieczny  s     marquis  p          conflict based merging operators  in
proc  of   th international conference on principles of knowledge representation
and reasoning  kr      pp         
falappa  m  a   kern isberner  g   reis  m  d  l     simari  g  r          prioritized and
non prioritized multiple change on belief bases  journal of philosophical logic         
      
falappa  m  a   kern isberner  g     simari  g  r          belief revision  explanations
and defeasible reasoning  artificial intelligence           
flouris  g   huang  z   pan  j  z   plexousakis  d     wache  h          inconsistencies 
negations and changes in ontologies  in proc  of   st national conference on artificial
intelligence  aaai      pp           
friedman  n     halpern  j  y          belief revision  a critique  computer research
repository  corr   cs ai         
fuhrmann  a          theory contraction through base contraction  journal of philosophical logic             
gardenfors  p          rule for rational changes of belief  philosophical essay dediccated
to lennart aqvist on his fiftieth birthday        
gardenfors  p          knowledge in flux  modeling the dynamics of epistemic states  mit
press 
gelfond  m          answer sets  in handbook of knowledge representation  chap     pp 
        elsevier 
gomez  s  a   chesnevar  c  i     simari  g  r          reasoning with inconsistent
ontologies through argumentation  applied artificial intelligence                   
greco  s     molinaro  c          probabilistic query answering over inconsistent databases 
annals of mathematics and artificial intelligence  amai                    
haase  p   van harmelen  f   huang  z   stuckenschmidt  h     sure  y          a framework for handling inconsistency in changing ontologies  in proc  of  th international
semantic web conference  iswc      pp         
halaschek wiener  c     katz  y          belief base revision for expressive description
logics  in proc  of international workshop on owl  experiences and directions
 owled     
hansson  s  o          belief base dynamics  ph d  thesis  uppsala university  department
of philosophy  uppsala  sweden 
hansson  s  o          theory contraction and base contraction unified  journal of symbolic
logic                 
hansson  s  o          kernel contraction  journal of symbolic logic                 
hansson  s  o          semi revision  journal of applied non classical logics          
       
   

fideagustini  martinez  falappa   simari

hansson  s  o          a textbook of belief dynamics  solutions to exercises  kluwer
academic publishers  norwell  ma  usa 
harman  g          change in view  principles of reasoning  cambridge university press 
harper  w          rational belief change  popper functions and counterfactuals  synthese             
horridge  m   parsia  b     sattler  u          explaining inconsistencies in owl ontologies 
in scalable uncertainty management  pp          springer 
huang  z   van harmelen  f     ten teije  a          reasoning with inconsistent ontologies 
in proc  of   th international joint conference on artificial intelligence  ijcai     
pp         
hue  j   papini  o     wurbel  e          merging belief bases represented by logic programs  in proc  of   th european conference on symbolic and quantitative approaches to reasoning with uncertainty  ecsqaru      pp         
kalyanpur  a   parsia  b   horridge  m     sirin  e          finding all justifications of
owl dl entailments  springer 
kalyanpur  a   parsia  b   sirin  e     hendler  j  a          debugging unsatisfiable classes
in owl ontologies  web semantics  science  services and agents on the world wide
web                
katsuno  h     mendelzon  a  o          on the difference between updating a knowledge base and revising it  in proc  of  nd international conference on principles of
knowledge representation and reasoning  kr     pp         
katsuno  h     mendelzon  a  o          propositional knowledge base revision and minimal change  artificial intelligence                 
konieczny  s     perez  r  p          merging information under constraints  a logical
framework  journal of logic and computation                 
konieczny  s     perez  r  p          logic based merging  journal of philosophical logic 
               
lembo  d   lenzerini  m   rosati  r   ruzzi  m     savo  d  f          inconsistencytolerant semantics for description logics  in proc  of  th international conference on
web reasoning and rule systems  rr      pp         
lenzerini  m          data integration  a theoretical perspective  in proc  of   st acm
sigmod symposium on principles of database systems  pods      pp         
levi  i          subjunctives  dispositions and chances  synthese                 
liberatore  p     schaerf  m          arbitration  or how to merge knowledge bases  
knowledge and data engineering               
lin  j     mendelzon  a  o          merging databases under constraints  international
journal of cooperative information systems              
lin  j     mendelzon  a  o          knowledge base merging by majority  applied logic
series             
   

fidatalog  ontology consolidation

lloyd  j  w          foundations of logic programmming  springer verlag 
lukasiewicz  t   martinez  m  v     simari  g  i          inconsistency handling in
datalog    ontologies  in proc  of   th european conference on artificial intelligence  ecai      pp         
martinez  m   pugliese  a   simari  g   subrahmanian  v     prade  h          how dirty
is your relational database  an axiomatic approach  in mellouli  k   ed    proc  of
 th european conference on symbolic and quantitative approaches to reasoning with
uncertainty  ecsqaru      vol       of lecture notes in computer science  pp 
        springer 
meyer  t   lee  k     booth  r          knowledge integration for description logics  in
veloso  m     kambhampati  s   eds    proceedings of aaai    twentieth national
conference on artificial intelligence  pp          aaai press 
newell  a          the knowledge level  artificial intelligence            
nilsson  u     maluszynski  j          logic  programming and prolog   ed   john wiley
  sons ltd 
parsons  s   wooldridge  m     amgoud  l          properties and complexity of some
formal inter agent dialogues  journal of logic and computation                 
qi  g     hunter  a          measuring incoherence in description logic based ontologies 
in proc  of  th international semantic web conference and the  nd asian semantic
web conference  iswc aswc      pp         
qi  g   liu  w     bell  d  a          knowledge base revision in description logics  in
proc  of   th european conference in logics in artificial intelligence  jelia     
pp         
quine  w  v  o          philosophy of logic  harvard university press 
reiter  r          a theory of diagnosis from first principles  artificial intelligence        
     
rosati  r          on the complexity of dealing with inconsistency in description logic
ontologies  in proc  of international joint conference on artificial intelligence  ijcai
     pp           
rott  h          modellings for belief change  prioritization and entrenchment  theoria 
             
schlobach  s     cornet  r          non standard reasoning services for the debugging of
description logic terminologies   in proceedings of the eighteenth international joint
conference on artificial intelligence  ijcai      pp         
schlobach  s   huang  z   cornet  r     van harmelen  f          debugging incoherent
terminologies  journal of automated reasoning                 
staworko  s   chomicki  j     marcinkowski  j          prioritized repairing and consistent query answering in relational databases  annals of mathematics and artificial
intelligence                   
   

fideagustini  martinez  falappa   simari

turner  h          strong equivalence made easy  nested expressions and weight constraints 
theory and practice of logic programming                  
von leibniz  g  w  f          philosophical papers and letters  a selection  vol     springer 
wassermann  r          an algorithm for belief revision  in proc  of international conference on principles of knowledge representation and reasoning  kr      pp     
    
wijsen  j          database repairing using updates  acm transaction on database systems                 

   

fi