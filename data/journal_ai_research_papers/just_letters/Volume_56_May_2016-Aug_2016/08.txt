journal of artificial intelligence research                  

submitted        published      

engineering note
the ibacop planning system  instance based configured portfolios
isabel cenamor
tomas de la rosa
fernando fernandez

icenamor   inf  uc   m   es
trosa   inf  uc   m   es
ffernand   inf  uc   m   es

departamento de informatica  universidad carlos iii de madrid
avda  de la universidad      leganes  madrid   spain

abstract
sequential planning portfolios are very powerful in exploiting the complementary strength
of different automated planners  the main challenge of a portfolio planner is to define which
base planners to run  to assign the running time for each planner and to decide in what order they
should be carried out to optimize a planning metric  portfolio configurations are usually derived
empirically from training benchmarks and remain fixed for an evaluation phase  in this work  we
create a per instance configurable portfolio  which is able to adapt itself to every planning task 
the proposed system pre selects a group of candidate planners using a pareto dominance filtering
approach and then it decides which planners to include and the time assigned according to predictive
models  these models estimate whether a base planner will be able to solve the given problem and 
if so  how long it will take  we define different portfolio strategies to combine the knowledge
generated by the models  the experimental evaluation shows that the resulting portfolios provide
an improvement when compared with non informed strategies  one of the proposed portfolios was
the winner of the sequential satisficing track of the international planning competition held in
     

   introduction
planning is a process that chooses and organizes actions by anticipating their outcomes with the
aim of achieving some pre stated objectives  in artificial intelligence  automated planning  ap  is
the computational study of this deliberation process  ghallab  nau    traverso         automated
planners are systems that  regardless of the application domain  are able to receive a declarative
representation of an environment  an initial state and a set of goals as input  the output is a synthesized plan that will achieve these goals from the initial situation  in this context  the international
planning competition  ipc  is an excellent initiative to foster the studying and development of automated planning systems  ipc was created in      to set a common framework for comparing
automated planners 
different planning systems won awards in previous ipcs  however  one of the main invariants of
the competition is that there is no single planner which is always the best planner  or at least equal 
for every domain or every problem  this means that  although there is a planner which  following the
quality metrics of the competition  can be considered the best  we can always find some problems in
different domains in which other planners outperform the overall winner  therefore  we can assume
that the ap community has generated a set of single planners that are better than all others in specific
situations  for this reason  discarding a priori any of those solvers seems meaningless 
c
    
ai access foundation  all rights reserved 

fic enamor   de la rosa   f ern andez

in fact  the idea of reusing a set of individual or base systems to generate more accurate solutions than those obtained separately is not new in artificial intelligence  for instance  in machine
learning  meta classifiers use different base classifier to increase the coverage of the representation
bias of the resulting classifier  dietterich         in problem solving  portfolios of search algorithms
have also demonstrated that they can outperform the results of a single search strategy  xu  hutter 
hoos    leyton brown        xu  hoos    leyton brown        malitsky  sabharwal  samulowitz    sellmann         for example  the sat competition in      included a special track on
portfolios  in the automated planning community  planner portfolios have also been subject to great
deal of interest  in ipcs from      to       portfolio approaches won or were very close to winning
the tracks in which they took part 
however  although the use of portfolios has become usual in the community  there is still no
agreement as to what a planning portfolio is  vallati  chrpa    kitchin         in this work  we
assume that a portfolio of planners is a set of base planners with a selection strategy  this selection
strategy is what generates a specific portfolio configuration  whose goal is to maximize the performance metrics  therefore  a configuration has to define three main elements      which sub set of
planners to run      how long to run each planner  and     in which order  there are many
techniques to configure a planning portfolio  vallati         and depending on how accurate they
are  the chances of selecting the best planner in a given situation will increase  note that  in this
definition  if a planner has different configuration parameters which modify its behavior  each parameterization is considered a different base planner  so base planners can be considered as black
boxes 
the number of planners in the state of the art is huge  so a first filtering is to select the minimum
number that ensures the best performance is achieved  for each evaluated planning domain  or even
for each problem in each domain   obviously  good results in current domains do not ensure good
results in new domains but  as will be shown  it is a good estimator  in this sense  a pareto efficiencybased approach  censor        to reduce the number of planners that we consider eligible for a
planning portfolio is presented  however  we will show that with this mechanism  the first of the
aforementioned questions can only be answered partially since the number of candidate planners
might still be large 
so the best solution to the portfolio configuration problem is to have an oracle that predicts 
given a domain and a problem  which planner will obtain the best performance and how long it will
take  given that we do not have this oracle  in this work we propose the use of predictive models  automatically generated with machine learning and data mining techniques  these models summarize the results of all the candidate planners from the past  whether they were able to solve planning
problems  as well as the time that they required to generate a good solution  cenamor  de la rosa 
  fernandez               given this knowledge on the past  the inductive hypothesis gives also us
an estimation on how they will behave in future planning domains and with different problems  so
the order in which the planners are implemented can be given by the accuracy of these predictions 
therefore  with these predictive models  we are able to configure a portfolio for each planning problem  like in previous works on the use of portfolios in search  gomes   selman         this is a
renewed idea in automated planning since recent works have focused in static  helmert        or
domain specific portfolios  gerevini  saetti    vallati               in which the configuration of
the portfolio is fixed for all the domains or chosen for each one respectively 
ibac o p  instance based configured portfolio  is a family of planning portfolios that were built
for competing in ipc       in this article we first present ibac o p as a general framework with
   

fit he ibac o p p lanning s ystem

the ultimate goal of building per instance configurable portfolios  the technique can be reproduced
again whenever new automated planners or new planning benchmarks arise  then  we describe how
to build different version of ibac o p following the defined processes  one of these versions was the
winner of the sequential satisficing track of ipc       we also include the results of an empirical
study that confirms the good performance of ibac o p planners when compared to different base
planners and different portfolio configuration strategies  then  we summarize the related work  and
finally  the last section sets out the conclusions and future lines of research 

   system architecture
in this section  we present the general idea of building a planning portfolio that can be configured
for a particular planning task using predictive models  this process should be seen as a general
technique given that the inputs  planners and benchmarks  might change in the future due to progress
in the planning community  so new portfolio configurations can be generated through the use of
these new inputs 
    portfolio construction
we consider that the construction of an instance based planning portfolio comprises three main
parts      planner filtering  for making a pre selection of good candidate planners from the set of
known or available planners  the proposed pre selection technique is based on a multi criteria approximation  this is a previously unexplored technique for selecting a set of planners that provides
enough diversity in the planner portfolio      performance modeling  for providing predictors of
the planners behavior as a function of planning task features  in our research  we include a set of
well known features  cenamor et al          some of which are built into the preprocessing step
of fast d ownward  helmert         we also take advantage of both the output information in
the translation process  fawcett  vallati  hutter  hoffmann  hoos    leyton brown        and the
heuristic values computed in the first step of the search process of fast d ownward  in addition 
the use of several totally new features on the characteristics of the relaxed plan in the initial state is
proposed  finally      strategy selection  to establish a procedure that combines the performance
predictions and then to output a portfolio configuration  we propose a novel strategy selection to
exploit the effectiveness of the predictive models  next  we explain the details of each of these
construction steps 
      p lanner f iltering
the planner filtering process consists of the pre selection of good candidate base planners from a
larger amount of available planners  even though there is a sufficient evidence that there is not
an overall best planner across a variety of benchmarks  it can be verified empirically that there
is a dominance of some planners over others  therefore it does not make sense to include  as base
planners  those that are always worse in terms of performance metrics  we want this filtering process
to select a diverse  but small  subset of planners to have few elements among which to divide the
available execution time 
in this work  we propose a multi criteria pre selection mechanism that focuses in two ipc metrics  quality and time  as alternative to the most extended ones for planner filtering  for example 
fdss  helmert  roger  seipp  karpas  hoffmann  keyder  nissim  richter    westphal       
   

fic enamor   de la rosa   f ern andez

uses the selection of planners that maximizes the coverage  mip lan  nunez  borrajo    linares
lopez        uses the portfolio configuration that obtains the best achievable performance in terms
of score 
for filtering we propose to run the candidate planners on a representative set of benchmarks
and then to evaluate them in terms of time and quality  to consider both metrics we propose an
approach based on pareto efficiency  censor        that allows us to determine the dominance
between planners in a multi criteria fashion  in particular  we select a planner as a candidate for the
portfolio if it is the best planner for at least one domain in terms of the ipc      multi criteria qt
score  linares lopez  celorrio    olaya         briefly  for a single problem  this metric computes
the tuple hq  t i for each planner  where q is the quality of the planners best solution and t the
time used to find this solution  then  for a given planner  p  the dominance relations between p and
the rest of planners are computed 
a tuple hq  t i pareto dominates the tuple hq   t  i if and only if q  q and t   t    planner
p gets nn points  where n is the number of tuples where p pareto dominates another planner  and
n  is the number of different tuples in which planner p appears  finally  the qt pareto score for
a domain is a sum of points achieved in all the problems in the domain  the idea of this selection
mechanism is as follows  if a planner shows good dominance property in a given domain  it should
be included in the portfolio because it will be a good candidate for solving the problems of the same
domain or even other planning tasks that have similar characteristics  therefore  a simple strategy
to filter a first pool of planners is given by the procedure that selects only the planners with the
maximum qt pareto score for at least one domain  we refer to this procedure as qt pareto score
filtering 
      p erformance m odeling
given a planning task  we want to predict how the selected base planners will perform in order
to decide whether to include them or not and to make a good assignment of time and ordering
when configuring the portfolio  thus  modeling the planner behavior as a function of planning
task features becomes a key process in building instance based portfolios  to learn these predictive
models we follow a data mining approach  as shown in figure    in our case  we start from a set of
candidate planners and a set of planning benchmarks  the output of the process is the set of models
that will predict the performance of the candidate planners  we have defined the data mining goal
as the creation of two predictive models  first  whether a planner will be able to solve a problem
 i e  a classification task  and  if so  what will be the time required to compute the best plan  i e   a
regression task  
the first step of the mining process comprises the generation of training and test datasets  on
the one hand  the planners are run on the set of benchmarks to obtain their performance data  this
data includes the outcome of the execution  success or failure  and  for the positive cases  the time
elapsed in finding the best solution  on the other hand  planning tasks are processed to extract a set
of features that characterize them  these features are an extended set of the previously proposed
set  cenamor et al          according to the mechanism for generating these features  we classify
them into the following categories 
 pddl features  basic features extracted from the pddl representation of the domain and
problem files  for instance  the number of actions  objects or goals 
   

fit he ibac o p p lanning s ystem

figure    general diagram for learning the planning performance predictive models
 fd instantiation features  the fast downward pre processor instantiates and translates the
planning tasks into a finite domain representation  helmert         from this output we take
some general information such as the number of instantiated actions or the number of relevant
facts  and data specific to the fd translator  such as the number of auxiliary atoms 
 sas  features  the finite domain representation of sas  has an associated causal graph
 cg  and a set of domain transition graphs  dtgs   from cg we extract basic properties
 e g   number of variables and edges   and the ratios between these properties  as regards
dtgs  the number of graphs in a problem corresponds to the number of edges in the cg 
which makes it difficult to encode the general attributes for each dtg  therefore  we summarize the dtgs characteristics by aggregating the relevant properties of all graphs  thus 
features from dtgs are statistics on them such as the maximum  the average or the standard
deviation of their graph properties 
 heuristic features  for the initial state  we compute heuristic values using a set of widely used
unit cost heuristic functions  e g   hmax   hff           we compute these heuristics only for the
initial state  which can be obtained at a reasonable cost  we use only unit cost heuristics to
obtain a domain independent estimation that helps in the characterization of the problem size
and or difficulty 
 fact balance features  using the relaxed plan  rp   of the initial state  extracted when computing the hff heuristic  we also compute a set of features to represent the fact balance of the
rp   we define the fact balance for fact p  as the number of times that p appears as an added
effect of an action belonging to rp   minus the number of times that p is a deleted effect of
an action in rp   considering original actions where deletes are not ignored  the intuition
behind fact balances is that high positive values would characterize easier  relaxed  problems
for a given domain  since achieved facts do not need to be deleted many times  given that the
number of relevant facts of a planning task is variable  we compute statistics  i e   min  max 
average and variance  for the fact balance of the relevant facts  additionally  we compute
statistics only by considering facts that are goals  following the same procedure 
   

fic enamor   de la rosa   f ern andez

the complete set of    features is listed and organized by their category in appendix a  the
data integration process in figure   receives the features and the performance datasets as inputs
to produce a final dataset according to the modeling goal  in the dataset for the classification task 
a training test instance includes the planning task features plus the planner name and the boolean
feature indicating whether this planner solved the planning task  the dataset for the regression task
only includes the cases in which the planning tasks are solved  we make this exclusion because it
does not make sense to model or estimate the planning time beyond the given time limit and because
in most cases this time is unknown  a training test instance in the regression dataset includes the
planning task features  the planner name and the time this planner used to find its best solution 
the feature selection is an optional process for reducing the number of features used for the
modeling  this procedure is applied because there might be irrelevant or redundant features that
could degrade the modeling capabilities of some learning techniques  blum   langley         the
outcome of the process is dependent on the original data  thus  the decision of whether to apply it
or not is taken based on the results of the model evaluation 
for the modeling process  we use an off the shelf data mining tool that provides a set of learning
algorithms for both classification and regression  the generated models are then evaluated in the
evaluation process to determine the best model for the classification and regression tasks  there
are many different ways of carrying out the model evaluation and comparison  han  kamber    pei 
      witten   frank         which will reflect the generalization ability of the different models
when making predictions of unseen data 
      s trategy s election
the strategy selection is the final step in the construction of an ibac o p planner  selecting a strategy implies that we have to decide how to transform the predictions of the best models into an actual
portfolio configuration  there are several alternatives that range from ignoring both model predictions to trusting them completely  for the classification model  each candidate planner will get a
yes no prediction given a new planning task  the direct use of the boolean variable makes difficult
to decide which planners to include in the portfolio  consider  for instance  the two extreme cases 
    if all planners get a positive prediction  should we include all of them      if all planners get a
negative prediction  which planner should we include in the portfolio  instead of using the boolean
prediction we propose to rank the predictions by their confidence in the positive class  and then
make the selection of planners according to this ranking  then  each planner should be assigned a
slide of the total time  in which this assignment can be carried out uniformly or dependently  again 
from the predictive models learned  therefore  depending on the use that we make of the predictive
models  we propose three basic strategies 
   equal time for all  et   this strategy does not use the predictive models at all  it will assign
equal time for each planner  uniform strategy   the idea behind this strategy is to have more
planners but with less time for each one  this strategy has obtained good results in other
portfolios  seipp  braun  garimort    helmert        
   best n confidence  bn   this strategy will include the subset of n planners with the best
prediction confidence in the positive class in the portfolio  then  they get equal time for
solving the planning task  in this case  the idea is that we select a subset of promising planners
so they can spend more time in solving the planning task 
   

fit he ibac o p p lanning s ystem

   best n estimated time  bne   the subset of planners is selected as mentioned before  but now
the time is assigned proportionally to the estimated time provided by the regression model 
    portfolio configuration
an instance based configuration of a portfolio implies that the subset of base planners and the time
assigned to each one varies as a function of the planning task features  the set of candidate planners 
the predictive models and the configuration strategy are previously fixed in the construction phase 
algorithm   shows how to use these components to configure the portfolio for a given planning
task 
algorithm    algorithm for configuring the portfolio for a particular planning task 
data  problem     domain  d   set of base planners  pini    classification model  c  
regression model  r   available time  t    strategy  sn  
result  portfolio configuration  a sequence of planners with their assigned runtime 
portfolio    hp    t  i          hpc   tc i 
portfolio    
if sn    et then
   no classification nor regression models available   
n   size pini   
for p in pini do
append hp  tn i  portfolio  
else
hf  tf i   extractfeatures d    
for pk in pini do
predictionhpk   confk i  predict  c  hf  pk i  

sorted candidates  sort prediction  key   conf    
p  sorted candidates i       n   
if sn    bn then
  classification model available  applying best n confidence strategy  
for i     to n do
f
append hpi   t t
n i  portfolio  
else
  regression model available  applying best n estimated time  
for i     to n do
ti   predict time r  hf  pi i  
t   scaletime t  t  tf   
for i     to n do
append hpi   ti i  portfolio   

the method receives a problem     a domain  d   the set of base planners  pini    the classification model  c   the regression model  r   the time available  t   and the portfolio configuration
strategy  sn   et  bn  bn e    the procedure calls several functions described below 
   

fic enamor   de la rosa   f ern andez

 extractfeatures  this is the same feature extraction procedure used in the portfolio construction phase  from the pair  domain  problem  the function outputs the set of features f   this
function also computes the time  tf   as the time spent in extracting all features 
 predict  this function is a query to the classification model c  it receives a new instance
represented by the tuple hf  pi  where f is the previously computed features  and p is the
planner name  from the result of the function we ignore the class  and only keep the prediction
confidence of the positive class  forming the tuple hp  conf  i  this output represents the
confidence that the planner p will solve the problem 
 predict time  this function uses the model r to estimate the execution time for the subset
of planners pn  pini that has been established as the best n candidates in terms of classification confidence  as in the classification model  this function receives the input tuple
hf  pi 
 scaletime  this function transforms the vector of estimated times into another proportional
vector for which its sum fits in the available time  which is the original time bound t minus the
time used to compute the features tf   thus  the time t assigned to each planner is computed
f  t
with the formula t    tpt
n
i   ti

the output of the algorithm is a sequence of planners and their assigned time  the execution of
a particular configuration of the portfolio comprises the sequential execution of these base planners
ensuring that each cpu process does not exceed the assigned time 

   ibacop planning system
in this section we describe how we follow the approach presented in section   to build different
portfolios 
    candidate planners
the initial set of planners includes the    planners of the sequential satisficing track of ipc     
plus lpg  td  gerevini  saetti    serina         although lgp  td did not compete in ipc     
we considered worthwhile to include it because it is still considered a state of the art planner due to
its great performance in previous competitions 
the first step is to apply the qt pareto score filtering described in subsection       to reduce
the initial set of candidate planners  the benchmarks for computing the qt pareto score is the set
of domains and problems of the sequential satisficing track of ipc      
table   shows the best planner in terms of qt pareto score for each domain  additionally 
we include the number of problems solved by the best planner to highlight the correlation among
both values  the qt pareto score values closer to    reflect that the planner is able to beat the
other planners in most problems  p robe was the best planner in   domains  however the other
planners only stood out in one domain  this reinforces the motivation to find a diverse subset of
planners  finally  out of    initial planners  the qt pareto score filtering pre selected as candidate
planners the subset of    planners  which was made up of  lama        probe   arvand   fdss    fd   autotune     fd   autotune     lamar   lama        madagascar   yahsp    mt and
lpg  td  a brief description of these planners can be found in appendix d 
   

fit he ibac o p p lanning s ystem

planner
probe
probe
probe
probe
arvand
madagascar
lama      
lama      
fd   autotune   
fd   autotune   
fdss   
lamar
yahsp    mt
lpg  td

domain
scanalyzer
woodworking
tidybot
barman
pegsol
parcprinter
transport
openstacks
sokoban
nomystery
elevators
parking
visitall
floortile

total

qt
     
     
     
     
     
     
     
     
     
     
     
     
     
     
      

coverage
  
  
  
  
  
  
  
  
  
  
  
  
  
  
   

table    list of the best planners ordered by their qt pareto score for each domain of ipc      
table   shows the ranking of planners of the ipc results  i e   planner ordering established by
the quality score   linares lopez et al         and which of them were selected by qt pareto score
filtering  it is worth noting of attention that    of the    best planners in the ipc are built on top
of fd  which reduces the diversity of the planners  however  the qt pareto score filtering only
includes   of them  in addition  it should be pointed out that the last three selections of the qt pareto
score filtering are planners from the lower positions of the table which  as will be demonstrated
later  increases the diversity of the portfolio and its performance 
ranking
 
 
 
 
 
 
 
 
 
  
  
  
  
  

planner
lama      
fdss   
fdss   
fd   autotune   
roamer
forkuniform
fd   autotune   
probe
arvand
lama      
lamar
yahsp    mt
madagascar
lpg  td

eligible












fd











table    list of    best planners ordered by its score at ipc       the third column shows whether
they are selected by the qt pareto score filtering  the forth column shows if the planners
are built on the top of fd 

   

fic enamor   de la rosa   f ern andez

    performance models
the inputs to the performance modeling phase are the candidate planners  i e   the    candidates
selected in the previous section  and the benchmark planning tasks selected for this purpose  next 
we describe the generated training data  and then how these inputs produce specific instances of
ibac o p planners 
      t raining data
the training data for the learning process requires a set of domains and problems used to gather
the input features  we need a wide range of domains and problems to generalize future unknown
planning tasks properly  we have included the planning problems available from ipc      onwards  if we do not mention the test set explicitly  it will always refer to the satisficing tracks of the
competitions  the included domain and problems are 
 ipc       openstacks  pathways  rovers  storage  tpp and trucks 
 ipc       cybersec  elevators  openstacks  pegsol  pipesworld  scanalyzer  sokoban  transport and woodworking 
 ipc       barman  elevators  floortile  nomystery  visitall  tidybot  openstacks  parcprinter 
parking  pegsol  sokoban  scanalyzer  transport and woodworking 
 learning track ipc       gold miner  matching bw  n puzzle  parking  thoughful and sokoban 
 learning track ipc       barman  blockworld  depots  gripper  parking  rovers satellite 
spanner and tpp 
from this list we obtained    different domain descriptions  although some of them represent
alternative encodings of the same domain  all have been included  candidate planners were run on
these benchmarks to obtain the features related to the performance of the planners  thus  we used a
total of        planning tasks  the performance data comprises         instances  i e          problems     planners  where        were successful and        failed  the proportion of instances
solved by each candidate planner is different  table    in appendix c shows a per planner summary
of the performance data 
the    features representing each planning task are automatically generated from the domain
and problem definitions  the pddl features  fd instantiation and sas  features are computed
using the fast d ownward pre processor  the computation time needed to extract these features
is negligible compared to the sas  translation  given that we only compute sums and statistics on
the data provided by the sas  representation  the heuristic features are computed using the fastd ownward search engine  and fact balance features are generated using the relaxed planning
graph structures  of the initial state  provided by the ff planner  hoffmann         the fastd ownward pre processor could fail when instantiating a planning task  in which case  regarding
features are not computed and missing values are assumed 
table   shows the success rate for extracting the features of each type from the training problems  and the average and maximum time in seconds to extract them  the pddl  fd and sas 
features are extracted from the fd pre processor which is why they have the same success rate  the
time required to compute the heuristic features is only the time for calculating the heuristic value of
the initial state  which is calculated only if the fd pre process has finished successfully 
   

fit he ibac o p p lanning s ystem

class
pddl
fd
sas 
heuristic
fact balance
total

success
   
   
   
      
   
 

average  s  
    
     
     
     
    
     

max  s  
     
      
     
     
     
     

  features
 
  
  
 
 
  

table    summary of the extracted features with the average and maximum time in seconds  s   to
extract them  these processes are on the top of the two first step of the all planners based
on fd 

      f eature s election
we have carried out a feature selection process for two main reasons  on the one hand  some features
might be irrelevant whilst others might be redundant for the modeling purpose  therefore we want
to analyze whether it is possible to obtain better models using only a subset of the available features 
on the other hand  this study will allow us to recognize most relevant features for characterizing a
planning task 
the feature selection was carried out using j   algorithm  a top down induction algorithm to
build decision trees  quinlan         by selecting the features that appear in the top nodes of the
tree  grabczewski   jankowski         decision trees make an implicit feature selection as the
model includes queries to those features considered relevant  after applying this feature selection
process on the feature dataset  the total number of features decreased from    to     this leads
to a dataset size reduction of around      table   contains the list of features resulting from the
feature selection process  the selection chooses features from all categories  for the modeling and
evaluation process we kept both datasets separate  one with all available features  f all  and the other
one with the selected features  f     
      c lassification m odels
we have trained the classifiers using    classification algorithms provided by weka  witten   frank 
       which includes different model types such as decision trees  rules  support vector machines
and instance based learning  we recall that training instances include the planning task features
described in section       plus the planner name and the boolean feature indicating whether this
planner solved the planning task or not  the performance of the predictive models was evaluated
with a    fold cross validation on a uniform random permutation of all training data  the best
model for both datasets f all and f    was that generated by rotation forest  rodriguez  kuncheva 
  alonso         achieving       and        of accuracy respectively  these results are quite
better than the result of the default model  zeror   which obtained        of accuracy  see all the
results of the classification models in table    of appendix b 
even though a good accuracy in the classification model does not guarantee a good performance
of the portfolio  this result is a great starting point for selecting promising planners  the accuracy
results of the feature selection only showed small differences compared to results obtained with all
   

fic enamor   de la rosa   f ern andez

type

pddl
   

cg   dtg
    

features
types
goal
objects
functions

numbervariablescg
inputedgecgstd
outputedgecgavg
outputweightcgmax
outputweightcgavg
outputedgehvstd
outputweighthvmax
numbervariablesdtg
totaledgesdtg
inputweightdtgmax
hvratio

type

fd
   

heuristics
   

balance
   

features
auxiliary atoms
implied effects removed
translator facts
translator total mutex groups size
num relevant facts
num instance actions
additive
context enhanced additive
ff
goal count
landmark count
landmark cut
max
rp fact balance avg
rp fact balance var
rp goal balance min
rp goal balance avg
rp goal balance var
h ff ratio

table    list of features from the feature selection  the complete set of features is listed in appendix a 

the features  only   algorithms have statistically better accuracy with f    dataset and nine of them
have the similar accuracy  but in all cases they were below the best achieved accuracy

      r egression m odels
we have trained regression models only with the positive instances of the classification training
phase  in the classification phase  all the planners have the same proportion of instances  but in
this case  not all the planners have the same number of instances given that they solved a different
number of problems  nevertheless we do not consider this a relevant bias because the models
include the planner name  which somehow encodes single models for each planner  but in a grouped
model  we have trained the models with    regression algorithms  also provided by weka 
the best algorithm for f all was decision table  kohavi        with a relative absolute error
 rae  of       and the best one for f    was bagging  breiman        with a rae of       
nevertheless  for simplicity we have selected the decision table model for the regression task in
both datasets  f all and f      this decision is justified because the results do not show a significant
difference with the t test result  in following sections  the regression model will always refer to
that trained with the decision table algorithm  see all the results of the regression models in the
table    of appendix b 
   

fit he ibac o p p lanning s ystem

    ibacop strategies
we have considered various strategies for the configuration of the ibac o p portfolios  the list of the
strategies is ordered depending on the use they make of the knowledge provided by the predictive
models  in the experiments  each configuration will run for      seconds  we have named the
portfolios according to the names given in ipc      
ibac o p  this portfolio uses an equal time strategy  et  on the set of    candidate planners previously filtered by the qt pareto score filtering procedure  therefore  the single planners will
run for     seconds  this strategy does not use the predictive models  the planner using this
strategy was awarded runner up in the sequential satisficing track of ipc      
ibac o p   this portfolio uses the best n confidence strategy  bn   where n      this means
that the   planners with the best prediction confidence in solving the problem are included in
the configuration  the run time is assigned uniformly to each planner      seconds   this
strategy  using the f    model was the winner of the sequential satisficing track of ipc       
ibac o p  b e  this portfolio uses the best estimated time strategy  bne  with n      it follows the same procedure as ibac o p  to select   planners  and then the time is assigned by
scaling the time prediction provided by the regression model  decision table   this strategy
participated in the learning track of ipc      under the name of libac o p   in this case the
training data and models were generated for each domain separately  since the learning track
provides a training problem set for each domain a priori 
in addition  we have built other portfolio configurations that will serve as the baseline for comparison 
overall equal time  oet   this strategy is a non informed strategy which does not carry out any
planner filtering or use predictive models  it assigns equal time for each available planner 
given that we have    planners  all the participants of ipc      plus lpg td   each planner
will run for    seconds  with this planner we see the need for some planner filtering since 
although it already obtains results close to current state of the art base planners  these results
can be improved by selecting a reduced set of planners 
best    planners  b     this strategy selects the top    planners of ipc      ordered by the score
in the competition  as shown in table    although selecting the best    planners is a good
choice intuitively  we show in the table that this selection reduces the planner diversity in the
portfolio  since most top planners in the competition are based on fd  with the only exception of probe  this strategy is comparable with that implemented in bus portfolio  howe 
dahlman  hansen  scheetz    von mayrhauser         in which the control strategy for ordering the planners and allocating time is derived from the performance study data 
random   planners  rand   this strategy is one of the baselines to compare to the best   confidence strategy  ibac o p    given a planning task  this strategy takes a random sample of
  planners from the population of    candidate planners selected by the qt pareto filtering 
   predictive models submitted with ibac o p  to ipc      were trained in a different benchmark set  in that case the
best accuracy was achieved by a random forest  breiman        

   

fic enamor   de la rosa   f ern andez

and assigns equal time to them  we expect that a wise selection of   planners  ibac o p  
will be on average better than a random selection 
default   planners  def   in this case  the strategy always includes the   best planners in terms
of quality score over the training data  these   planners are a subset from the    candidate
planners selected by the qt pareto filtering  i e   lama        probe   fd  autotune    
lama       and fd   autotune      then  the time is assigned equitably  we want to see
whether using the best   planners is better than making a per instance selection of   planners 
    other implementation details
in this section we describe some of the engineering details we have incorporated into ibac o p
planners  for instance  the competition rules proposed to include domains with conditional effects 
because of this  we have included a parser that translates tasks with conditional effects into an
equivalent planning task without this property  this translator was based on a previous translator adl strips  hoffmann  edelkamp  thiebaux  englert  dos santos liporace    trug        
specifically  we have implemented the compilation that creates artificial actions for effect evaluations  nebel        
furthermore  many of the    candidate planners were built on the fast d ownward framework  which among other things  separate the planning process into the sub process of translation 
pre processing and search  indeed  the translation and the pre process steps are already executed
when the feature generation for a given task is performed  we take advantage of this fact to avoid
doing the first two steps repeatedly if some of these planners are included in the configuration of
the portfolio for the regarding task  for version compatibility reasons this procedure is divided
into two groups  the output of the fd pre process  used for feature extraction  is also used as the
search input for lama        fdss    and fd   autotune          the previous fd pre processor
  was used in common for lama        arvand and lamar   this optimization is used by all the
strategies evaluated  the remaining planners are totally independent of the fd pre processing 
moreover  some bugs arose during the execution of ipc       as some issues in the domain
models required updates  vallati  chrpa    mcmcluskey      a   and some planners were updated
such as mercury  vallati  chrpa    mcmcluskey      b   these issues were also fixed prior to
running the experimental evaluation presented in this article 

   experimental evaluation
in this section  we describe the settings of the experimental evaluation and present the results of
the planners on the benchmarks used in the ipc       specifically  in the sequential satisficing
track  in addition  we provide an analysis of the diversity of the planner selection achieved by some
configurations 
    experimental settings
we have evaluated the different portfolio strategies described in section      which permits different
portfolio configurations to be created  ibac o p  and ibac o p  b e were run with two predictive
model versions  one trained with all features  f all  and the other one trained with the selected fea   this version corresponds to the version used to submit planners to ipc     

   

fit he ibac o p p lanning s ystem

tures  f      the random strategy was run for   times and the average is reported  in addition  we
have included the jasper and m ercury planners in the comparison  these planners also competed in ipc       m ercury  domshlak  hoffmann    katz        was the second best planner
in terms of ipc score and jasper  xie  muller    holte        was the second best planner in terms
of problems solved  coverage   as the test set we have used all the benchmarks of ipc       with
the updates described in section      this test set comprises    domains with    problems for each
domain 
experiments were run on a cluster with intel xeon      ghz nodes  each with   gb of ram 
using linux ubuntu       lts  all planners had a cutoff of        seconds and   gb of ram 
for ibac o p configurations requiring feature extraction  this process was limited to   gb of ram
 following ipc competition rules  and     seconds  which is the maximum time used in the training
set to obtain the features  as described in table     the time to extract the features is included in the
execution of the portfolio where  in the worse case  the feature extraction process took     seconds
and  therefore  the candidate planners only have        to run  if the system does not extract the
features in this time  the input features are treated as missing values 
    results
table   shows the results of all evaluated planners using the ipc quality score  we recall that this

score gives the ratio q
qi to planner i for each problem  where qi is the quality of the best solution
found by planner i  and q is the best solution found by any planner  if planner i does not solve the
problem the score is   

hiking
openstacks
thoughtful
ged
barman
parking
visitall
maintenance
tetris
childsnack
transport
floortile
citycar
cavediving
total

ibacop 
f all
f   

ibacop  b s
f all
f   

mercury

jasper

oet

b  

def

rand

ibacop

    
    
    
    
    
    
    
   
    
   
    
   
   
   

    
    
    
    
    
    
    
    
    
   
    
   
    
   

    
    
    
    
    
    
    
    
   
    
   
   
   
   

    
    
    
    
    
    
   
    
    
   
   
   
   
   

    
    
    
    
    
    
    
    
   
   
   
   
   
   

    
    
    
    
    
    
    
    
    
   
   
    
   
   

    
    
    
    
    
    
    
    
    
    
    
    
    
   

    
    
    
    
    
    
    
    
    
    
    
    
   
   

    
    
    
    
    
    
    
    
    
    
    
    
   
   

    
    
    
    
    
    
    
    
    
    
    
    
   
   

    
    
    
    
    
    
    
    
    
    
    
    
    
   

     

     

     

     

     

     

     

     

     

     

     

table    results of ibac o p configurations  the table also includes the results of jasper  mercury
and the four baseline configurations  oet  best     default and random 

the overall best planner was ibac o p  b e  f all   closely followed by ibac o p   f all   the
difference between these two configurations is negligible  all the configurations using predictive
models are much better than oet  default  best    or random  ibac o p has a very good performance  comparable to the best performance  moreover  there is a big difference between our
   

fic enamor   de la rosa   f ern andez

configurations and the other planners  jasper and mercury   ibac o p based configurations are   
or more points higher in all cases 
figure   details the evolution of the number of problems solved as a function of the run time
elapsed  the far right hand point of the figure represents the final coverage  the best planner in
terms of coverage is ibac o p  with     problems  and the second is ibac o p   f all  with      in
figure    the planners show two different behaviors  on the one hand  an asymptotic growing in the
number of problems solved demonstrates that giving more time to the planners does not permit the
number of problems solved to be increased  jasper is an extreme case  which after     seconds is
almost unable to improve  m ercury has the same problem  as well as the portfolio configurations
that do not take care of diversity  however  the ibac o p  ibac o p  and ibac o p  b e  which
selected a diverse set of planners  show a growing behavior throughout the time 
   

   

problems

   

   

ibacop
ibacop 
ibacop  b e
random
jasper
default
mercury
best  
 et

  

 
 

   

   

   

   

    

    

    

    

    

time

figure    comparison of ibac o p configurations  the baseline configurations  and the mercury and
jasper planners 
from the results we can derive some insights regarding different configurations  the score
difference between oet and ibac o p reveals the importance of making a pre selection of candidate
planner with an accurate filtering procedure  the pareto dominance approach allows us to have a
smaller set of planners  which means having more time per planner  there is a trade off between
having more time per planner and loosing the diversity of solvers  and the results suggest that it is
more important to maintain diversity than increasing running time per planner  for instance  the
   best ipc      planners  b    obtain worse results than those using the original     oet   even
though b   base planners have a longer running time  however  the qt pareto filtering approach is
able to reduce the number of planners while not sacrificing the diversity  which produces very good
results 
reducing the number of planners for the portfolio configuration from    to   puts in risk the
diversity of solvers  as shown in the results of the def approach  the best   planners in terms of
   

fit he ibac o p p lanning s ystem

performance  or in rand  the random selection of   planners   nevertheless  ibac o p   f all  and
 f     perform quite better than def and rand  which demonstrates that the classification models
select on average a good subset of planners for solving each particular task  these results are quite
promising for exploiting empirical performance models in planning portfolios  however  in the
current setting  results of ibac o p  are quite similar to ibac o p  thus  the classification models
manage to reduce the set of planners without deteriorating the performance of the fixed portfolio 
but they hardly contribute to a better overall performance 
table   presents the number of problems solved by each of the    candidate planners  the final
column has the maximum number of problems that can be solved by the complete set of candidate
planners  i e   a problem can be solved only if at least one of the candidate planners solved the
problem   the optimal selection of   planners for each planning task would lead to     problems
solved  ibac o p  is close to this optimum  confirming its ability for selecting good candidates for
the portfolio  the default configuration solved     problems  and the average number of problems
solved by the random configuration is     problems  both of them are far from the best possible
value 
hiking
thoughtful
openstacks
tetris
ged
transport
parking
barman
maintenance
citycar
visitall
childsnack
floortile
cavediving
total

lama  
  
  
  
 
  
  
  
  
 
 
  
 
 
 

probe
  
  
 
  
  
  
 
  
 
 
  
 
 
 

fda 
  
  
  
  
  
 
  
  
  
 
 
 
 
 

lama  
  
  
  
 
 
  
  
  
 
 
 
 
 
 

fda 
  
  
  
 
 
 
 
 
 
 
 
 
 
 

lamar
  
  
  
  
 
 
  
  
 
 
 
 
 
 

arvand
  
  
  
  
 
 
 
 
  
  
 
 
 
 

fdss 
  
  
  
  
  
  
  
 
  
 
 
 
 
 

ya  mt
 
  
 
 
 
  
 
 
 
 
  
 
 
 

lpg
  
 
 
 
  
 
 
 
 
 
 
 
  
 

m
 
 
 
 
 
 
 
 
 
  
 
  
 
 

max
  
  
  
  
  
  
  
  
  
  
  
  
  
 

   

   

   

   

  

   

   

   

  

  

  

   

table    results of the candidate planners defined in table   and the maximum number of problems
that can be solved by the complete set of these planners 

once the set of   planners has been selected for the per instance configuration  the regression
models do not contribute to a better performance  the task of estimating the run time needed to
solve a problem is more difficult than the classification task  schwefel  wegener    weinert        
additionally  given that the aggregated time predictions could exceed the time limit  our proposal rescales these estimations and alters the real predictions  one alternative to this proposal is to keep the
real prediction and run the planners in the order established by the confidence in the classification
prediction  until one of them reaches the time limit  however  preliminary experiments during the
development of the planner showed us that this approach does not compensate the risk of losing
diversity due to fewer planner executions 
another aspect to be analyzed is the performance of the planners in the new domains  the ipc     incorporated seven new domains  which means that the qt pareto filtering and the predictive
models have not been trained with them  these domains are cave diving  child snack  citycar 
   

fic enamor   de la rosa   f ern andez

ged  hiking  maintenance and tetris  from the results we can conclude that the behavior of all
ibac o p configurations in new domains is on average similar to the performance in previously seen
domains 
    per instance selection of planners
in the previous section we showed that the benefit of configuring a portfolio per problem is that the
set of selected planners can be better adjusted to the problem  using fewer planners  and providing
more execution time to each planner  in this section we want to analyze the diversity of the planner
selections made by ibac o p  to see if the predictive models are classifying planners by how good
they are at solving specific domains or if they are identifying properties of specific problems in
different domains  note that the test problems of a given domain usually range from easy to hard 
the increase in difficulty is mainly due to a larger size of the problems  nevertheless  this increase
affects the learning features at a different scale and intensity 

lama     
probe
fd autotune  
lama     
fd autotune  
lamar
arvand
fdss  
yahsp  mt
lpg td
madagascar
ll
ita
vis
rt
po
ns
l
tra
tfu
gh
ou
th
tris
te
ng
rki
pa tacks
s
en
e
op nanc
e
int
ma
ing

hik

d
ge e
il
ort
flo r
a
yc
k
cit
ac
sn
ild
ch
ing
div
ve
ca n
a
rm
ba

figure    proportion of the number of times each planner has been selected in a domain  in red
dots  the proportion for ibac o p   f all   and in blue dots  the proportion for ibac o p 
 f     

figure   shows the diversity of planners according to the selection made by ibac o p   blue
dots for f    and red dots for f all   the x axis shows the ipc      domains and the y axis lists
the    candidate planners that the portfolio can use  the size of the dots is proportional to the
number of times a planner has been selected for a particular domain  i e  the number of problems
for which the planner was selected  if a domain has five dots in one column  one domain   it means
that it was selected by the portfolio configuration for all problems in the domain  however  every
   

fit he ibac o p p lanning s ystem

column with more than five dots reveals the use of different   planner sets for different problems
in the same domain  the highlight of this analysis is that the    planners have been selected in
at least one domain  and in    out of    domains the selections involve more than   planners 
note  for instance  that lama       has the best a priori confidence on solving problems  but it
is sometimes not used  i e   it was selected only   times in floortile and    times in openstacks  
furthermore  some planners have a low a priori probability of being selected  but are frequently
used in some domains  like lpg  td in floortile  
table   shows the sum of the number of times that each planner has been selected  the maximum number of times that a planner could be selected is               the last column reports
the average and the standard deviation of the number of times that each planner has been selected
per domain in both approximations  all and the reduced set of features  

lama      
probe
fd   autotune   
lama      
fd   autotune   
lamar
arvand
fdss   
yahsp    mt
lpg  td
madagascar

f   
   
   
   
   
  
   
  
   
  
  
  

f all
   
   
   
   
  
   
   
   
  
  
  

average
     
     
     
     
    
     
    
    
    
    
    














std
    
    
    
    
    
    
    
    
    
    
    

table    number of times a candidate planner has been selected by the two different classification
models  f    and f all  

in addition to the previous analysis  we wanted to delve into the underlying mechanism to
achieve the per instance selection of planners  we recall that planners are selected based on the
confidence of the success prediction  therefore  in order to achieve different   planner sets in
the same domain  the ranking of the prediction confidence should vary throughout the problem 
to visualize and confirm this fact  we have selected the tetris domain  which is one of the new
domains in ipc      and it shows a good diversity selection as shown in figure    this domain is
a simplified version of the well known tetris game 
a heatmap with the success prediction confidences appears in figure    at a glance we realized that in general  a planner with higher success rate in training time obtains higher confidence 
but confidence ranking varies throughout different problems of the same domain  another way to
read the picture is that the   darkest squares per column form the set of selected planners  for instance  lama      was selected in all problems and probe was selected    times  on the other hand
madagascar was not selected  and lpg td was selected   times 
   

fic enamor   de la rosa   f ern andez

lama     
probe
fd autotune  
lama     

score

fd autotune  
lamar
arvand
fdss  
yahsp  mt
lpg td
madagascar
 

 

 

 

 

 

 

 

 

 

                             

figure    success prediction confidence provided by the classification model  f all  for each planner
and problem in the tetris domain  scale goes from      white  or no confidence at all to
     dark blue  or complete confidence 

   related work
in this section  we summarize the relevant research into portfolio configuration and how it relates to
our work  in addition  we summarize different approaches for the characterization of the planning
tasks  which is a cornerstone of this work to predict the behavior of the planners 
the idea of exploiting the synergy of different solvers to improve the performance of the individual ones is applied in propositional satisfiability problems  sat   constraint satisfaction problems
 csp   answer set programming  asp  and in the scope of this paper  automated planning  the
sat area has carried out extensive research into the importance of selecting the components of
the portfolio  xu  hutter  hoos    leyton brown        and how to select each component  lindauer  hoos  hutter    schaub      b  automatically  the study of strategy selection in this area
includes per instance selections  lindauer  hoos    hutter      a   in addition  there is an intensive
study into solver runtime prediction  hutter  xu  hoos    leyton brown         including a good
characterization of the satisfiability task  in other fields of artificial intelligence  csp has portfolio configurations based on machine learning techniques such as sunny  amadini  gabbrielli   
mauro      b  and other empirical research  amadini  gabbrielli    mauro      a   for example
in asp  the asp based solver scheduling  hoos  kaminski  schaub    schneider        is a multicriteria optimization problem and provides the corresponding asp encodings  in this paper we only
report the main systems related to automated planning in detail 
    portfolios in automated planning
howe et al         describes one of the first planner portfolios  they implement a system called
bus that runs   planners and whose goal is to find a solution in the shortest period of time  to
achieve it  they run the planners in portions of time and in circular order until one of them finds
a solution  in this portfolio  the planners are sorted following the estimation provided by a linear
   

fit he ibac o p p lanning s ystem

regression model of their success and run time so  as in our case  they use predictive models of
the behavior of the planners to decide their order of execution  however  they use only   features
extracted from the pddl description  for the domain  they count the number of actions and the
number of predicates  for the problem  they count the number of objects  the number of predicates
in the initial conditions and the number of goals  bus minimizes the expected cost of implementing
a sequence of algorithms until one works  in contrast to ibac o p and ibac o p   that does not stop
until the assigned time is over 
fast downward stone soup  fdss  helmert et al         is based on the fast downward  fd 
planning system  helmert         with several versions for the different tracks  fdss is an approach
to select and combine heuristics and search algorithms  a configuration is a combination of a search
algorithm and a group of heuristics  in training  they evaluate the possible configurations with a time
limit  and select the set of configurations that maximizes the coverage  for the portfolio presented
in the ipc      sequential satisficing track  they sort the configurations by decreasing the order
of coverage  hence beginning with algorithms likely to succeed quickly  the time limit for each
component is the lowest value that would still lead to the same portfolio score in the training phase 
however  the order is important  since each setting communicates the quality of the best solution
found so far to the following one  and this value is used to improve the performance of the next
setting  therefore  fdss can only include configurations within the fd framework  conversely 
ibac o p and ibac o p  build a portfolio using a mixture of generic planners of different styles and
techniques  indeed fdss is one of ibac o p candidate planners 
pbp  gerevini et al         configures a domain specific portfolio  this portfolio incorporates
macro actions in the specific knowledge of the domains  the incorporation of this knowledge establishes the order of a subset of planners which contain macro actions  the running time is assigned
through a round robin strategy  this portfolio incorporates seven planners  the latest version  pbp  
adds lama       see gerevini et al          the automatic portfolio configuration in pbp and iba c o p aims to build different types of planning systems  a domain optimized portfolio planner for
each given domain in pbp and ibac o p is an efficient domain independent planner portfolio  the
ibac o p and pbp configuration processes are significantly different  pbp uses several planners
that focus on macro actions whilst ibac o p only uses generic planners  the execution scheduling
strategy of pbp runs the selected planners in round robin rather than sequentially in the case of
ibac o p 
fast downward cedalion  seipp  sievers  helmert    hutter        is an algorithm for automatically configuring sequential planning portfolios of a parametric planner  given a parametric
planner and a set of training instances  it selects the pair of planner and time iteratively  at the end
of each iteration all instances for which the current portfolio finds the best solution are removed
from the training set  the algorithm stops when the total run time of the added configurations
reaches the portfolio time limit or if the training set becomes empty  configurations are generated
using the smac  hutter  hoos    leyton brown        model based algorithm configurator on
the remaining training instances  cedalion has the same configuration for all the problems but a
different configuration per version and ibac o p has a different configuration per problem  the diversity of the candidate planner is limited while ibac o p may completely include independent base
planners  the configuration processes and the resulting configured portfolios of cedalion are the
same as fdss 
the fast downward uniform  seipp et al         portfolio runs    automatically configured fast
downward instantiations sequentially for the same amount of time  uniform portfolio approaches
   

fic enamor   de la rosa   f ern andez

are configured using the automatic parameter tuning framework paramils  hutter  hoos  leytonbrown    stutzle        to find fast configurations of the fast downward planning system for   
planning domains separately  at runtime  all configurations found are run sequentially for the same
amount of time for at most    seconds 
miplan  nunez et al         is a sequential portfolio using mixed integer programming  which
computes the portfolio that obtains the best achievable performance with respect to a selection
of training planning tasks  in their case they have created a sequential portfolio with a subset of
sequential planners with fixed times whilst ibac o p  has different configurations per problem  for
this approximation  the planner does not consider the other portfolios  only their components  in
contrast  ibac o p and ibac o p  includes the planners as they appear in other competitions  i e  as
black boxes 
    features in planning problems
the construction of models to predict the performance of planners is not a novel idea  roberts et
al               showed that models learned from the planners performance on known benchmarks
up to      obtain a high accuracy when predicting whether a planner will succeed or not  they
use       features extracted from the domain and problem definition  the main difference with our
approach is that we also include features based on sas    the heuristics of the initial state and the
fact balance of the relaxed plan  most of our features come from the ground instantiation of the
problem  which are the key to differentiate tasks that share the same feature values at the pddl
level 
torchlight  hoffmann        is a toolkit which allows the search space topology to be analyzed
without actually running any search  the analysis is based on the relation between the topology
under delete relaxation heuristics and the causal graph as well as dtgs  the feature extraction
process is built on top of the ff planner  hoffmann   nebel        
recently  fawcett et al         has generated models for accurately predicting the planner run
time  these models exploit a large set of instance features  including many of the features depicted
in section        these features are derived from the pddl and sas  representations of the problem  a sat encoding of the planning problem and short runs of planners  some other features are
extracted with torchlight  hoffmann         the experimental results in the work indicate that the
performance models generated are able to produce very accurate run time predictions  this study
of empirical performance models has not been applied to portfolio configurations 

   conclusion and future work
in this work we have introduced a framework for the creation of configurable planning portfolios 
ibac o p  in the first step of the portfolio creation we find a small number of planners that maintains
the diversity of the initial planner set based on the qt pareto score filtering  then we train predictive
models that select a promising sub set of planners for solving a particular planning task 
the experimental evaluation confirmed the great performance of ibac o p and ibac o p  in
ipc       we can summarize the lessons learned from the development of the current ibac o p
portfolios as the following 
 what really matters in the generation of a good portfolio is the selection of a diverse set of
planners  we have shown that the qt pareto score filtering reduces the set of candidate plan   

fit he ibac o p p lanning s ystem

ners while preserving the diversity  this filtering produces better results than other rankings
based on coverage or quality score 
 the selection of smaller sets of planners for the portfolio configuration  e g   a sub set of  
planners in our experiments  is dangerous given that the portfolio might lose planner diversity 
we observed this situation in the def and random configurations  which select   out of   
planners 
 the portfolio configurations using the classification models are able to select a good subset
of   planners  which with uniformly distributed time outperformed the selection provided by
a random and default selection with the same number of planners 
 estimating the runtime for solving a problem is still very difficult and for this reason regression models are not providing additional useful information for the portfolio construction 
 in their current form  predictive models hardly contribute to the overall performance of the
portfolio  per instance configurations using classification models achieve similar performance to the fixed portfolio  but running fewer planners 
even though in the current architecture the benefits of using predictive models are limited 
the results are promising because of the good performance of ibac o p  compared to the baseline
configurations  we think there is some room for research in this direction  our argument is that
static portfolio configurations  including ibac o p  are limited by the components and the fixed
time bound for each base planner  their performance has an upper limit  as computed by miplan 
that is smaller than the achievable performance of a dynamic configuration  this is because in a
per instance configuration the portfolio strategy could assign different times to the base planners 
as future work we want to study additional features for a better characterization of the planning
tasks  any computation that could be carried out as a pre process step  or even with information
on first evaluated search nodes  could help with making predictive models more accurate  our
models could incorporate information  for instance  about the landmark graph or the time elapsed
in computing the initial state heuristics  other future work is a study of importance of the created
features  including a comparison between different groups of them in accordance with the semantics
of the features 

   acknowledgments
we thank the authors of the base planners because our work is based largely on their previous effort 
this work has been partially supported by the spanish projects tin           c       tin          c      and tin           c    r 

   

fic enamor   de la rosa   f ern andez

a  appendix  complete feature description
in this appendix we present the list of the features used to characterize a planning task  for each
feature we include a brief description of what it is or how it is computed  features are grouped by
their category in separate tables 
a   pddl features
n 
 
 
 
 
 
 
 
 

name
objects
goals
init
types
actions
predicates
axioms
functions

description
the number of objects in the problem 
the number of goals in the problem 
the number of in facts in the initial state 
the number of types in the domain 
the number of actions in the domain 
the number of predicates in the domain 
the number of axioms in the domain 
the number of functions in the domain 

table    pddl features 

a   fd instantiation features
n 
 
  
  
  
  

name
relevant facts
cost metric
generated rules
relevant atoms
auxiliary atoms

  

final queue length

  

  

total queue pushes
implied
effects
removed
effect preconditions
added
translator variables

  

derived variables

  
  
  
  
  

translator facts
mutex groups
total mutex size
translator operators
total task size

  
  

description
the number of facts marked as relevant by ff instantiation 
whether action costs are used or not 
the number of created rules in the translation process to create sas  task 
the number of relevant atoms found in the translator process 
the number of auxiliary atoms found in the translator process 
the length of the queue at end of the translation  this queue is an auxiliary
list that is used in the translation process to compute the model 
the number of times an element has been pushed into the queue 
the number of implied effects removed  where the implied effects that the
translator knows are already included 
the number of implied effects added 
the number of created variables in sas  formulation 
the number of state variables that correspond to derived predicates or to
other artificial variables not directly affected by operator applications 
the number of facts that the pre process takes into account 
the number of mutex groups 
the sum of all mutex group sizes 
the number of instantiated operators in sas  formulation 
the allowed memory for the translation process 

table    features extracted from the console output of the fd system 

   

fit he ibac o p p lanning s ystem

a   sas  feature description
we recall that in cg  the high level variables are the variables for which there is a defined value in
the goal  although the common definition of the cg does not consider the edges as weighted  the
fd system computes the edge weights of the cg as the number of instantiated actions that induced
each edge  we also consider these weights for computing our features 
n 

name

  
  
  
  

number variables
high level variables
totaledges
totalweight

  

veratio

  

weratio

  

wvratio

  

hvratio

     

inputedge

     

inputweight

     

outputedge

     

outputweight

     

inputedgehv

     

inputweighthv

     

outputedgehv

     

outputweighthv

description
general features
the number of variables of the cg 
the number of high level variables 
the number of edges 
the sum of the edge weights 
cg ratios
the ratio between the total number of variables and the total number of
edges  this ratio shows the level of connection in the cg 
the ratio between the sum of the weights and the number of edges  this
ratio shows the average weight for the edges 
the ratio between the sum of the weights and the number of variables 
the ratio between the number of high level variables and the total number of variables  this ratio shows the percentage of variables involved
in the problem goals 
statistics of the cg
maximum  average and standard deviation of the number of incoming
edges for each variable 
maximum  average and standard deviation of the sum of the weights of
the incoming edges for each variable 
maximum  average and standard deviation of the number of outgoing
edges for each variable 
maximum  average and standard deviation of the sum of the weights of
the incoming edges for each variable 
statistics of high level variables
the number of incoming edges for each of the high level variables  this
value produces three new features following the same computation as
inputedgecg  features        
the edge weight sum of the incoming edges for each of the high level
variables  this value produces three new features following the same
computation as inputweightcg 
the number of outgoing edges for each of the high level variables 
the sum of the weights of the incoming edges for each high level variables 

table     features from the causal graph 

   

fic enamor   de la rosa   f ern andez

n 

name

  
  

number vertices
total edges

  

total weight

  

edva ratio

  

weedratio

  

wevaratio

     

input edge

     

input weight

     

output edge

     

output weight

description
general aggregated features dtg
the sum of the number of nodes of all dtgs 
the sum of the number of edges of all dtgs 
the sum of the edge weights of all dtgs  the edge weight in a dtg
corresponds to the cost of applying the action that induced the edge 
dtg ratios
the ratio between the total number of edges and the total numbers of
variables  this ratio shows the level of connection in the dtg 
the ratio between the sum of the weights and the number of edges  this
ratio shows the number of restrictions that need to make the transition 
the ratio between the sum of the weights and the number of variables 
statistics of dtgs
maximum  average and standard deviation of the number of incoming
edges for a vertex in a dtg 
maximum  average and standard deviation of the sum of the weights of
the incoming edges of all nodes 
maximum  average and standard deviation of the number of outgoing
edges for a vertex in a dtg 
maximum  average and standard deviation of the sum of the weights of
the outgoing edges of all nodes 

table     features that aggregate the information from the dtgs 

   

fit he ibac o p p lanning s ystem

a   heuristic features
n 

name

  

max

  

landmark cut

  

landmark
count
goal count

  

ff

  

additive

  

causal graph

  

contextenhanced
additive

description
 bonet  loerincs    geffner        bonet   geffner        the maximum
of the accumulated costs of the paths to the goal propositions in the relaxed
problem 
 helmert   domshlak        the sum of the costs of each disjunctive action
landmark that represents a cut in a justification graph towards the goal propositions 
 richter  helmert    westphal        the sum of the costs of the minimum
cost achiever of each unsatisfied or required again landmark 
the number of unsatisfied goals 
 hoffmann   nebel        the cost of a plan that reaches the goals in the
relaxed problem that ignores negative interactions 
 bonet et al         bonet   geffner        the sum of the accumulated costs
of the paths to the goal propositions in the relaxed problem 
 helmert        the cost of reaching the goal from a given search state by
solving a number of sub problems of the planning task which are derived from
the causal graph 
 helmert   geffner        the causal graph heuristic modified to use pivots
that define contexts relevant to the heuristic computation 

table     unit cost heuristics included as features 

a   fact balance
n 

name

     

rp init

     

rp goal

  

ratio ff

description
minimum  average and variance of the number of times that a fact in the
initial state is deleted in the computation of the relaxed plan 
minimum  average and variance of the number of times that a goal is
deleted in the computation of the relaxed plan 
the ratio between the value of the max and ff heuristic  this proportion
shows the idea of parallelization of the plan 

table     fact balance features 

   

fic enamor   de la rosa   f ern andez

b  appendix  learning results
this appendix shows the detailed results for the machine learning algorithms used to train the predictive models 
b   classification
algorithm
rules zeror
rules ridor
rules part
rules jrip
rules decisiontable
rules conjunctiverule
trees reptree
trees randomtree
trees randomforest
trees lmt
trees j  
trees adtree
trees nbtree
trees decisionstump
lazy lwl
lazy ibk  k  
lazy ibk  k  
lazy ibk  k  
meta rotationforest
meta attributeselectedclassifier
meta classificationviaclustering
meta classificationviaregression
meta bagging
meta multiclassclassifier
functions simplelogistic
functions multilayerperceptron
functions rbfnetwork
functions smo
bayes naivebayes
bayes naivebayesupdateable
bayes bayesnet

f all dataset
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           

f    dataset
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           

























table     accuracy and standard deviation for each training algorithm using    fold crossvalidation  also  results of a t test  omahony        for the two training sets is shown 
symbols    means statistically significant improvement or degradation respectively 
the significance level in the t test is      and the baseline is the left column 

   

fit he ibac o p p lanning s ystem

b   regression

trees decisionstump
trees reptree
trees randomtree
trees randomforest
functions m p
rules conjunctiverule
rules decisiontable
rules m rules
meta bagging
meta additiveregression
lazy ibk  
lazy ibk  
lazy ibk  
lazy kstar
lazy lwl
functions linearregression
functions multilayerperceptron
functions leastmedsq
functions rbfnetwork
functions smoreg

f all dataset
rae

                      
                      
                    
                    
                       
                      
                      
                        
                      
                      
                       
                      
                      
                    
                    
                     
                     
                      
                   
                      

f    dataset
rae

                      
                      
                    
                     
                      
                      
                      
                       
                      
                      
                      
                      
                      
          
        
                    
                    
                     
                      
         
        
                      








table     results for the    fold cross validation in the regression models  rae is the relative
absolute error and  is the correlation coefficient  the small rae values are better 
symbols    means statistically significant improvement or degradation respectively 
the significance level in the t test is      and the baseline is the left column 

   

fic enamor   de la rosa   f ern andez

c  appendix  training results
t
openstacks
pathways
rovers
storage
tpp
trucks
pipesworld
cybersec
openstacks adl
openstacks
pegsol
scanalyzer
sokoban
transport
woodworking
elevators
barman
elevators
floortile
nomystery
openstacks
parcprinter
parking
pegsol
scanalyzer
sokoban
tidybot
transport
visitall
woodworking
gold miner
matching bw
n puzzle
parking
sokoban
thoughtful
barman
blocksworld
depots
gripper
parking
rovers
satellite
spanner
tpp
total

l   

probe

fda 

l   

fda 

lamar

arvand

fdss 

ya  mt

lpg

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
  
 
 
  
  
  
 
  

  
  
  
  
  
 
  
  
  
  
  
  
  
  
  
  
  
  
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
  
  
 
 
  
  
 
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
  
  
  
  
  
  
  
  
  
 
  
  
  
  
  
  
 
 
  
 
 
 
  
 
 
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
 
  
  
 
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
  
 
 
  
  
 
 
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
  
 
  
  
  
 
  
  
  
  
  
 
  
  
  
 
  
  
 
 
  
 
  
 
  
  
 
 

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
  
 
  
  
 
  
  
  
  
  
 
  
 
  
  
  
  
  
 
 
 
 
 
  
  
 
 
  

  
  
  
  
  
  
  
  
  
  
  
  
 
  
  
  
 
  
 
  
  
  
 
  
  
 
  
  
  
  
  
  
 
  
  
 
 
 
 
 
 
  
 
 
  

  
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
  
  
  
  
  
  
  
  
  
 
  
 
 
 
 
  
 
  
  
 
 
 
  
  
 
  

 
 
  
  
  
 
  
 
 
 
  
  
 
  
  
 
  
 
 
  
 
  
 
  
  
 
 
  
  
  
  
  
  
  
  
  
 
  
  
 
 
  
  
 
  

  
  
  
  
  
  
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
  
  
  
  
 
 
  
 
  
 
  
  
  
 

m
  
  
  
  
  
  
  
 
  
  
  
  
 
 
 
 
 
 
 
  
 
  
 
  
  
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
  
 
  
 

 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

   

   

   

   

   

   

   

   

   

   

   

    

table     solved problems in the training phase  the first part in this table is the results of ipc      the second part ipc      and ipc      in the satisficing tracks  the two last rows
 from gold miner to tpp  are ipc           in the learning track  the last column is the
number of problems included for training 

   

fit he ibac o p p lanning s ystem

d  appendix  planners
the following list the set of planners pre selected as candidates from the pareto dominance filtering
described in section    
 arvand  nakhost  muller  valenzano    xie         is a stochastic planner that uses monte
carlo random walks to balance exploration and exploitation in heuristic search  this version
uses an online learning algorithm to find the best configuration of the parameters for the given
problem 
 fast downward autotune   and fast downward autotune    fawcett  helmert  hoos  karpas 
roger    seipp         are two instantiations of the fd planning system automatically configured for performance on a wide range of planning domains  using the well known paramils
configurator  the planners use three main types of search in combination with several heuristics 
 fast downward stone soup    helmert et al          fdss     is a sequential portfolio with
several search algorithms and heuristics  given the results of the training benchmarks  the
best combination of algorithms and heuristics is found through a hill climbing search  here 
the only information communicated between the component solvers is the quality of the best
solution found so far 
 lama      and lama       richter   westphal        richter  westphal    helmert 
      is a propositional planner based on the combination of landmark count heuristic and
ff heuristic  the search performs a set of weighted a with iteratively decreasing weights 
the planner was developed within the fd planning system  helmert        
 lamar  olsen   bryce        is a modification of the lama planner that includes a randomized construction of the landmark count heuristic 
 madagascar  rintanen         implements several innovations of sat planning  including
compact parallelized interleaved search strategies and sat based heuristics 
 probe  lipovetzky   geffner         exploits the idea of wisely constructed lookaheads or
probes  which are action sequences computed without searching from a given state that can
quickly go deep into the state space  terminating either in the goal or in failure  this technique
is integrated within a standard greedy best first search 
 yahsp  mt  vidal        extracts information from the relaxed plan in order to generate
lookahead states  this strategy is implemented in a complete best first search algorithm 
modified to take helpful actions into account 
 lpg td  gerevini et al         is based on stochastic local search in the space of particular
action graphs derived from the planning problem specification 

references
amadini  r   gabbrielli  m     mauro  j       a   portfolio approaches for constraint optimization
problems  tplp             
   

fic enamor   de la rosa   f ern andez

amadini  r   gabbrielli  m     mauro  j       b   sunny  a lazy portfolio approach for constraint
solving  tplp                  
blum  a  l     langley  p          selection of relevant features and examples in machine learning 
artificial intelligence                
bonet  b     geffner  h          planning as heuristic search  new results  in recent advances in
ai planning  pp          springer 
bonet  b   loerincs  g     geffner  h          a robust and fast action selection mechanism for
planning  in aaai iaai  pp         
breiman  l          bagging predictors  machine learning                
breiman  l          random forests  machine learning             
cenamor  i   de la rosa  t     fernandez  f          mining ipc      results  in proceedings of
the third workshop on the international planning competition   icaps 
cenamor  i   de la rosa  t     fernandez  f          learning predictive models to configure planning portfolios  in proceedings of the workshop on the planning and learning   icaps 
censor  y          pareto optimality in multiobjective problems  applied mathematics and optimization             
dietterich  t  g          ensemble methods in machine learning  in kittler  j     roli  f 
 eds    multiple classifier systems  first international workshop  mcs       cagliari  italy 
june              proceedings  vol       of lecture notes in computer science  pp      
springer 
domshlak  c   hoffmann  j     katz  m          red black planning  a new systematic approach
to partial delete relaxation  artificial intelligence             
fawcett  c   helmert  m   hoos  h   karpas  e   roger  g     seipp  j          fd autotune 
domain specific configuration using fast downward  proceedings of the workshop on the
planning and learning   icaps          
fawcett  c   vallati  m   hutter  f   hoffmann  j   hoos  h  h     leyton brown  k          improved features for runtime prediction of domain independent planners  in in proceedings of
the   th international conference on automated planning and scheduling  icaps     
gerevini  a   saetti  a     vallati  m          an automatically configurable portfolio based planner
with macro actions  pbp  in proceedings of the   th international conference on automated
planning and scheduling  icaps     
gerevini  a   saetti  a     serina  i          an approach to temporal planning and scheduling in
domains with predictable exogenous events  journal of artificial intelligence research     
       
gerevini  a   saetti  a     vallati  m          planning through automatic portfolio configuration 
the pbp approach  journal of artificial intelligence research             
ghallab  m   nau  d     traverso  p          automated planning  theory   practice  access online
via elsevier 
gomes  c  p     selman  b          algorithm portfolios  artificial intelligence               
   

fit he ibac o p p lanning s ystem

grabczewski  k     jankowski  n          feature selection with decision tree criterion  in proceedings of the fifth international conference on hybrid intelligent systems  his     pp 
        ieee 
han  j   kamber  m     pei  j          data mining  concepts and techniques  elsevier 
helmert  m          a planning heuristic based on causal graph analysis  in in proceedings of the
  th international conference on automated planning and scheduling  icaps      vol     
pp         
helmert  m          the fast downward planning system  journal of artificial intelligence research             
helmert  m          concise finite domain representations for pddl planning tasks  artificial
intelligence              
helmert  m     domshlak  c          landmarks  critical paths and abstractions  whats the difference anyway   in in proceedings of the   th international conference on automated
planning and scheduling  icaps     
helmert  m     geffner  h          unifying the causal graph and additive heuristics  in in proceedings of the   th international conference on automated planning and scheduling  icaps     pp         
helmert  m   roger  g   seipp  j   karpas  e   hoffmann  j   keyder  e   nissim  r   richter  s  
  westphal  m          fast downward stone soup  the seventh international planning
competition  ipc   planner abstracts     
hoffmann  j          the metric ff planning system  translating ignoring delete lists to numeric
state variables  journal of artificial intelligence research             
hoffmann  j          analyzing search topology without running any search  on the connection
between causal graphs and h   journal of artificial intelligence research             
hoffmann  j   edelkamp  s   thiebaux  s   englert  r   dos santos liporace  f     trug  s         
engineering benchmarks for planning  the domains used in the deterministic part of ipc   
journal of artificial intelligence research             
hoffmann  j     nebel  b          the ff planning system  fast plan generation through heuristic
search  journal of artificial intelligence research             
hoos  h   kaminski  r   schaub  t     schneider  m  t          aspeed  asp based solver scheduling  iclp  technical communications              
howe  a  e   dahlman  e   hansen  c   scheetz  m     von mayrhauser  a          exploiting
competitive planner performance  in biundo  s     fox  m   eds    recent advances in ai
planning   th european conference on planning  ecp    durham  uk  september      
      proceedings  vol       of lecture notes in computer science  pp        springer 
hutter  f   hoos  h  h     leyton brown  k          sequential model based optimization for
general algorithm configuration  in learning and intelligent optimization  pp         
springer 
hutter  f   hoos  h  h   leyton brown  k     stutzle  t          paramils  an automatic algorithm
configuration framework  journal of artificial intelligence research             
   

fic enamor   de la rosa   f ern andez

hutter  f   xu  l   hoos  h     leyton brown  k          algorithm runtime prediction  methods
and evaluation  extended abstract   in yang  q     wooldridge  m   eds    proceedings of the
twenty fourth international joint conference on artificial intelligence  ijcai       buenos
aires  argentina  july              pp            aaai press 
kohavi  r          the power of decision tables  in machine learning  ecml     pp         
springer 
linares lopez  c   celorrio  s  j     olaya  a  g          the deterministic part of the seventh
international planning competition  artificial intelligence             
lindauer  m  t   hoos  h  h     hutter  f       a   from sequential algorithm selection to parallel
portfolio selection  in dhaenens  c   jourdan  l     marmion  m   eds    learning and intelligent optimization    th international conference  lion    lille  france  january       
      revised selected papers  vol       of lecture notes in computer science  pp      
springer 
lindauer  m  t   hoos  h  h   hutter  f     schaub  t       b   autofolio  an automatically configured algorithm selector  journal of artificial intelligence research             
lipovetzky  n     geffner  h          searching for plans with carefully designed probes  in in
proceedings of the   st international conference on automated planning and scheduling
 icaps      pp         
malitsky  y   sabharwal  a   samulowitz  h     sellmann  m          algorithm portfolios based
on cost sensitive hierarchical clustering  in proceedings of the twenty third international
joint conference on artificial intelligence  pp          aaai press 
nakhost  h   muller  m   valenzano  r     xie  f          arvand  the art of random walks  the
seventh international planning competition  ipc   planner abstracts       
nebel  b          on the compilability and expressive power of propositional planning formalisms 
journal of artificial intelligence research             
nunez  s   borrajo  d     linares lopez  c          automatic construction of optimal static
sequential portfolios for ai planning and beyond  artificial intelligence             
olsen  a     bryce  d          randward and lamar  randomizing the ff heuristic  the seventh
international planning competition  ipc   planner abstracts     
omahony  m          sensory evaluation of food  statistical methods and procedures  vol     
crc press 
quinlan  j  r          c      programs for machine learning  vol     morgan kaufmann 
richter  s   helmert  m     westphal  m          landmarks revisited  in aaai  vol     pp     
    
richter  s     westphal  m          the lama planner  guiding cost based anytime planning with
landmarks  journal of artificial intelligence research                
richter  s   westphal  m     helmert  m          lama      and       the seventh international
planning competition  ipc   planner abstracts     
rintanen  j          madagascar  efficient planning with sat  the seventh international planning
competition  ipc   planner abstracts     
   

fit he ibac o p p lanning s ystem

roberts  m     howe  a          learning from planner performance  artificial intelligence      
       
roberts  m   howe  a  e   wilson  b     desjardins  m          what makes planners predictable  
in in proceedings of the   th international conference on automated planning and scheduling  icaps      pp         
rodriguez  j  j   kuncheva  l  i     alonso  c  j          rotation forest  a new classifier ensemble
method  ieee transactions on pattern analysis and machine intelligence              
     
schwefel  h  p   wegener  i     weinert  k          advances in computational intelligence  theory
and practice  springer science   business media 
seipp  j   braun  m   garimort  j     helmert  m          learning portfolios of automatically tuned
planners  in mccluskey  l   williams  b   silva  j  r     bonet  b   eds    proceedings of
the twenty second international conference on automated planning and scheduling  icaps
      atibaia  sao paulo  brazil  june              aaai 
seipp  j   sievers  s   helmert  m     hutter  f          automatic configuration of sequential
planning portfolios  in bonet  b     koenig  s   eds    proceedings of the twenty ninth
aaai conference on artificial intelligence  january              austin  texas  usa   pp 
          aaai press 
vallati  m          a guide to portfolio based planning  in multi disciplinary trends in artificial
intelligence  pp        springer 
vallati  m   chrpa  l     kitchin  d  e          portfolio based planning  state of the art  common
practice and open challenges  ai communications          
vallati  m   chrpa  l     mcmcluskey  l       a  
https   helios hud ac uk scommv ipc    benchmark html 

competition

domains 

vallati  m   chrpa  l     mcmcluskey  l       b   source code and erratum deterministic part 
https   helios hud ac uk scommv ipc    errplan html 
vidal  v          yahsp   keep it simple  stupid  the seventh international planning competition 
ipc   planner abstracts     
witten  i  h     frank  e          data mining  practical machine learning tools and techniques 
 nd edition  morgan kaufmann 
xie  f   muller  m     holte  r          jasper  the art of exploration in greedy best first search  in
planner abstracts  ipc      
xu  l   hoos  h     leyton brown  k          hydra  automatically configuring algorithms for
portfolio based selection  in proceedings of the twenty fourth aaai conference on artificial
intelligence  aaai        pp         
xu  l   hutter  f   hoos  h     leyton brown  k          evaluating component solver contributions to portfolio based algorithm selectors  in theory and applications of satisfiability
testingsat       pp          springer 
xu  l   hutter  f   hoos  h  h     leyton brown  k          satzilla  portfolio based algorithm
selection for sat  journal of artificial intelligence research             

   

fi