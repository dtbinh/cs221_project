journal of artificial intelligence research                 

submitted        published     

further experimental evidence against the utility of
occam s razor
geoffrey i  webb

webb deakin edu au

school of computing and mathematics
deakin university
geelong  vic        australia 

abstract

this paper presents new experimental evidence against the utility of occam s razor 
a systematic procedure is presented for post processing decision trees produced by c    
this procedure was derived by rejecting occam s razor and instead attending to the assumption that similar objects are likely to belong to the same class  it increases a decision
tree s complexity without altering the performance of that tree on the training data from
which it is inferred  the resulting more complex decision trees are demonstrated to have 
on average  for a variety of common learning tasks  higher predictive accuracy than the less
complex original decision trees  this result raises considerable doubt about the utility of
occam s razor as it is commonly applied in modern machine learning 

   introduction

in the fourteenth century william of occam stated  plurality should not be assumed without necessity   this principle has since become known as occam s razor  occam s razor
was originally intended as a basis for determining one s ontology  however  in modern times
it has been widely reinterpreted and adopted as an epistemological principle a means of
selecting between alternative theories as well as ontologies  modern reinterpretations of
occam s razor are widely employed in classification learning  however  the utility of this
principle has been subject to widespread theoretical and experimental attack  this paper
adds to this debate by providing further experimental evidence against the utility of the
modern interpretation of occam s razor  this evidence takes the form of a systematic procedure for adding non redundant complexity to classifiers in a manner that is demonstrated
to frequently improve predictive accuracy 
the modern interpretation of occam s razor has been characterized as  of two hypotheses h and h    both of which explain e  the simpler is to be preferred   good        
however  this does not specify what aspect of a theory should be measured for simplicity 
syntactic  semantic  epistemological and pragmatic simplicity are all alternative criteria that
can and have been employed bunge         in practice  the common use of occam s razor
in machine learning seeks to minimize surface syntactic complexity  it is this interpretation
that this paper addresses 
it is to be assumed that occam s razor is usually applied in the expectation that its
application will  in general  lead to some particular form of advantage  there is no widely
accepted articulation of precisely how occam s razor should be applied or what advantages
are to be expected from its application in classification learning  however  the literature
does contain two statements that seem to capture at least one widely adopted approach to

c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fiwebb

the principle  blumer  ehrenfeucht  haussler  and warmuth        suggest that to wield
occam s razor is to adopt the goal of discovering  the simplest hypothesis that is consistent
with the sample data  with the expectation that the simplest hypothesis will  perform well
on further observations taken from the same source   quinlan        states
 given a choice between two decision trees  each of which is correct over the
training set  it seems sensible to prefer the simpler one on the grounds that it is
more likely to capture structure inherent in the problem  the simpler tree would
therefore be expected to classify correctly more objects outside the training set  
while these statements would not necessarily be accepted by all proponents of occam s
razor  they capture the form of occam s razor that this paper seeks to address a learning
bias toward classifiers that minimize surface syntactic complexity in the expectation of
maximizing predictive accuracy 
both of the above statements of occam s razor restrict themselves to classifiers that
correctly classify all objects in a training set  many modern machine learning systems
incorporate learning biases that tolerate small levels of misclassification of the training data
 clark   niblett        michalski        quinlan              for example   in this context 
and extending the scope of the definition beyond decision trees to classifiers in general  it
seems reasonable to modify quinlan s        statement  above  to
given a choice between two plausible classifiers that perform identically on the
training set  the simpler classifier is expected to classify correctly more objects
outside the training set 
this will be referred to as the occam thesis 
the concept of identical performance on a training set could be defined in many different
ways  it might be tempting to opt for a definition that requires identical error rates when
two classifiers are applied to the training set  a less strict interpretation might allow two
classifiers to have differing error rates so long as the difference is within some statistical
confidence limit  however  to maximize the applicability of its results  this paper will adopt
a very strict interpretation of identical performance that for every object o in the training
set  both classifiers provide the same classification for o 
it should be noted that the occam thesis is not claiming that for any two classifiers
with equal empirical support the least complex will always have greater predictive accuracy
on previously unseen objects  rather  it is claiming that more frequently than not the less
complex will have higher predictive accuracy 
this paper first examines some arguments for and against the occam thesis  it then
presents new empirical evidence against the thesis  this evidence was acquired by using a
learning algorithm that post processes decision trees learnt by c     this post processor
was developed by rejecting the occam thesis and instead attending to the assumption
that similarity is predictive of class  the post processor systematically adds complexity to
decision trees without altering their performance on the training data  this is demonstrated
to lead to an increase in predictive accuracy on previously unseen objects for a range of
 real world  learning tasks  this evidence is taken as incompatible with the occam thesis 
   

fifurther experimental evidence against the utility of occam s razor

   previous theoretical and experimental work
to provide a context for the new evidence against the occam thesis  it is worth briey
examining previous relevant theoretical and experimental work  where relevant  an outline
will be provided of reasons why each contribution may have failed to persuade the other
side of the debate 

    the law of conservation of generalization performance

the conservation law of generalization performance  schaffer        proves that no learning
bias can outperform any other bias over the space of all possible learning tasks   it follows
that if occam s razor is a valuable learning bias  it can only be so for some subset of all
possible learning tasks  it might be argued that the set of  real world  learning tasks is such
a subset 
this paper is predicated on accepting the proposition that the set of  real world  learning
tasks is distinguished from the set of all possible learning tasks in respects that render the
conservation law inapplicable  rao  gordon  and spears        argue that this is the case
because learning tasks in our universe are not uniformly distributed across the space of all
possible learning tasks 
but why should this be so  one argument in support of this proposition is as follows 
 real world  learning tasks are defined by people for use with machine learning systems  to
this end  the task constructors will have sought to ensure that the independent variables
 class attributes  are related to the dependent variables  other attributes  in ways that can
be captured within the space of classifiers that are made available for the learning system 
actual machine learning tasks are not drawn randomly from the space of all possible learning
tasks  the human involvement in the formulation of the problems ensures this 
as a simple thought experiment in support of this proposition  consider a learning task
for which the class attribute is generated by a random number generator and in no way
relates to the other attributes  the majority of machine learning researchers would not be in
the slightest disconcerted if their systems failed to perform well when trained on such data 
as a further example  consider a learning task for which the class attribute is a simple count
of the number of missing attribute values for an object  assume that such a learning task
was submitted to a system  such as c     quinlan         that develops classifiers that have
no mechanism for testing during classification whether an attribute value is missing  again 
the majority of machine learning researchers would be unconcerned that their systems failed
to perform well in such circumstances  machine learning is simply unsuited to such tasks 
a knowledgeable user would not apply machine learning to such data  at least not in the
expectation of obtaining a useful classifier therefrom 
this paper explores the applicability of the occam thesis to  real world  learning tasks 

    other theoretical objections to the occam thesis

most machine learning systems explicitly or implicitly employ occam s razor  in addition
to its almost universal use in machine learning  the principle of occam s razor is widely
   the law is only proved for discrete valued learning tasks  but there is no reason to believe it does not
also apply to continuous valued tasks

   

fiwebb

accepted in general scientific practice  that this has persisted  despite occam s razor being
subjected to extensive philosophical  theoretical and empirical attack  suggests that these
attacks have not been found persuasive 
on the philosophical front  to summarize bunge         the complexity of a theory
 classifier  depends entirely upon the language in which it is encoded  to claim that the
acceptability of a theory depends upon the language in which it happens to be expressed
appears indefensible  further  there is no obvious theoretical relationship between syntactic complexity and the quality of a theory  other than the possibility that the world is
intrinsically simple and that the use of occam s razor enables the discovery of that intrinsic
simplicity  however  even if the world is intrinsically simple  there is no reason why that
simplicity should correspond to syntactic simplicity in an arbitrary language 
to merely state that a less complex explanation is preferable does not specify by what
criterion it is preferable  the implicit assumption underlying much machine learning research appears to be that  all other things being equal  less complex classifiers will be  in
general  more accurate  blumer et al         quinlan         it is this occam thesis that
this paper seeks to discredit 
on a straight forward interpretation  for a syntactic measure to be used to predict
expected accuracy appears absurd  if two classifiers have identical meaning  such as if
  age   then pos and if   age   or   age   then pos  then it is
not possible for their accuracies to differ  no matter how greatly their complexities differ 
this simple example highlights the apparent dominance of semantics over syntax in the
determination of predictive accuracy 

    previous experimental evidence against the occam thesis
on the empirical front  a number of recent experimental results have appeared to conict
with the occam thesis  murphy and pazzani        demonstrated that for a number of artificial classification learning tasks  the simplest consistent decision trees had lower predictive
accuracy than slightly more complex consistent trees  further experimentation  however 
showed that these results were dependent upon the complexity of the target concept  a
bias toward simplicity performed well when the target concept was best described by a
simple classifier and a bias toward complexity performed well when the target concept was
best described by a complex classifier  murphy         in addition  the simplest classifiers
obtained better than average  over all consistent classifiers  predictive accuracy when the
data was augmented with irrelevant attributes or attributes strongly correlated to the target
concept  but not required for classification 
webb        presented results that suggest that for a wide range of learning tasks from
the uci repository of learning tasks  murphy   aha         the relative generality of
the classifiers is a better predictor of classification performance than is the relative surface
syntactic complexity  however  it could be argued that while these results demonstrate that
a strategy of selecting the simplest between any pair of theories will not lead to maximization
of predictive accuracy  they do not demonstrate that selecting the simplest of all available
theories would fail to maximize predictive accuracy 
schaffer              has shown that pruning techniques that reduce complexity while
decreasing resubstitution accuracy sometimes increase predictive accuracy and sometimes
   

fifurther experimental evidence against the utility of occam s razor

decrease predictive accuracy of inferred decision trees  however  a proponent of the occam
thesis could explain these results in terms of a positive effect from the application of occam s
razor  the reduction of complexity  being counter balanced by a negative effect from a
reduction of empirical support  resubstitution accuracy  
holte  acker  and porter        have shown that specializing small disjuncts  rules
with low empirical support  to exclude areas of the instance space occupied by no training
objects frequently decreases the error rate of unseen objects covered by those disjuncts  as
this specialization involves increasing complexity  this might be viewed as contrary to the
occam thesis  however  the same research shows that the total error rates for the classifiers
in which the disjuncts are embedded increases when those disjuncts are specialized  a
proponent of the occam thesis could thus dismiss the relevance of the former results by
arguing that the thesis only applies to complete classifiers and not to elements of those
classifiers 

    theoretical and experimental support for the occam thesis
against these theoretical and experimental objections to the occam thesis there exists a
body of apparent theoretical and empirical support 
several attempts have been made to provide theoretical support for the occam thesis
in the machine learning context  blumer et al         pearl        fayyad   irani        
however  these proofs apply equally to any systematic learning bias that favors a small
subset of the hypothesis space  indeed  it has been argued that they equally support a
preference for classifiers with high complexity  schaffer        berkman   sandholm        
holte        compared learning very simple classification rules with the use of a sophisticated learner of complex decision trees  he found that  for a number of tasks from the uci
repository of machine learning datasets  murphy   aha         the simple rules achieved
accuracies of within a few percentage points of the complex trees  this could be considered
as supportive of the occam thesis  however  in no case did the simple rules outperform the
more complex decision trees  nor was it demonstrated that there did not exist yet another
learning bias that consistently outperformed both those studied 
a final argument that might be considered to support the occam thesis is that the
majority of machine learning systems employ some form of occam s razor and they appear to perform well in practice  however  it has not been demonstrated that even better
performance would not be obtained if occam s razor were abandoned 

   new experimental evidence against the occam thesis
the theoretical and experimental objections to the occam thesis do not appear to have
greatly diminished the machine learning community s use of occam s razor  this paper
seeks to support objections to the occam thesis with robust and general experimental
counter evidence  to this end it presents a systematic procedure for increasing the complexity of inferred decision trees without modifying their performance on the training data 
this procedure takes the form of a post processor for decision trees produced by c     quinlan         the application of this procedure to a range of learning tasks from the uci
repository of learning tasks  murphy   aha        is demonstrated to result  on average 
   

fiwebb

in increased predictive accuracy when the inferred decision trees are applied to previously
unseen data 

    theoretical basis for the decision tree post processor
the similarity assumption is a common assumption in machine learning that objects that
are similar have high probability of belonging to the same class  rendell   seshu        
the techniques to be described rely upon this assumption for their theoretical justification
rather than upon the occam thesis 
starting from the similarity assumption  machine learning can be viewed as the inference
of a suitable similarity metric for a learning task  a decision tree can be viewed as a
partitioning of the instance space  each partition  represented by a leaf  contains the
objects that are similar in relevant respects and thus are expected to belong to the same
class 
this raises the issue of how similarity should be measured  instance based learning methods  aha  kibler    albert        tend to map the instance space onto an ndimensional geometric space and then employ geometric distance measures within that
space to measure similarity  such an approach is problematic on a number of grounds 
first  it assumes that the underlying metrics of different attributes are commensurable 
how is it possible to determine a priori whether a difference of five years in age signifies
a greater or lesser difference in similarity than a difference of one inch in height  second 
it assumes that it is possible to provide a priori definitions of similarity with respect to a
single attribute  can one really make a universal prescription that a value of    is always
more similar to a value of   than to a value of     why should it never be the case that the
relevant similarity metric is based on the log  of the surface value  in which case    would
be more similar to    than to   
if we wish to employ induction to learn classifiers expressed in a particular language then
it would appear that we are forced to assume that the language in question in some manner
captures a relevant aspect of similarity  any potential leaf of a decision tree presents a
plausible similarity metric  all objects that fall within that leaf are similar in some respect  
empirical evaluation  the performance of that leaf on the training set  can then be used to
infer the relevance of that similarity metric to the induction task at hand  if a leaf l covers
a large number of objects of class c and few of other classes  then this provides evidence
that similarity with respect to the tests that define l is predictive of c 
figure   illustrates a simple instance space and the partition that c     quinlan       
imposes thereon  note that c    forms nodes for continuous attributes  such as a and b  
that consist of a test on a cut value x  this test takes the form a  x  with respect to
figure   there is one such cut  on value   for attribute a 
c    infers that the relevant similarity metric relates to attribute a only  the partition
 shown by a dashed line  is placed at value   for attribute a  however  if one does not
accept the occam thesis  but does accept the similarity assumption  there is no reason to
believe that the area of the instance space for which b     and a     lightly shaded in
figure    should belong to class    as determined by c     rather than class   
c    uses the occam thesis to justify the termination of partitioning of the instance
space as soon as the decision tree accounts adequately for the training set  in consequence 
   

fifurther experimental evidence against the utility of occam s razor

          
              
          
              
            
 
 
 
 
 
                    
a
figure    a simple instance space
  
 
 
 
 
b 
 
 
 
 

large areas of the instance space that are occupied by no objects in the training set may
be left within partitions for which the similarity assumption provides little support  for
example  with respect to figure    it could be argued that a more relevant similarity metric
with respect to the region a    and b     is similarity with respect to b   within the
entire instance space  all objects with values of b     belong to class    there are five such
objects  in contrast  there are only three objects with values of a    that provide the
evidence that objects in this area of the instance space belong to class    each of these
tests represents a plausible similarity metric on the basis of the available evidence  thus 
an object within this region will be similar in a plausible respect to three positive and five
negative objects  if objects that are similar in relevant respects have high probability of
belonging to the same class  and the only other information available is that it is plausible
that an object is similar to three positive and five negative objects  then it would appear
more probable that the object is negative than positive 
the disagreement between c    and the similarity assumption in this case contrasts
with  for example  the area of the instance space for which a    and b      in this region 
the similarity assumption suggests that c    s partition is appropriate because all plausible
similarity metrics will indicate that an object in this region is similar to positive objects
only   
the post processor developed for this research analyses decision trees produced by c   
in order to identify such regions those occupied by no objects from the training set but
for which there is evidence  in terms of the similarity assumption  favoring relabeling with
   to provide an example of an implausible similarity metric  consider the similarity metric defined by
the root node  that everything is similar  this will not be plausible as there is too great a level of
dissimilarity in classes with respect to this metric  if it were a relevant similarity metric  and the
distribution of training examples was representative of the distribution of objects in the domain as a
whole  then the similarity assumption would be violated  as similar objects would have probability of just
     of belonging to the same class  this probability can be calculated as follows  the probabilities of
an object being   or   are     and     respectively  if an object is   then the probability of it belonging
to the same class as another object to which it is similar is      if an object is   then the probability of
it belonging to the same class as another object to which it is similar is      thus  the probability of an
object belonging to the same class as another similar object is                             the numbers
involved in this simple example are  of course  too small to reach any such conclusion with a high level
of confidence the example is intended as illustrative only 

   

fiwebb

a different class to that assigned by c     when such regions are identified  new branches
are added to the decision tree  creating new partitionings of the instance space  both trees
must provide identical performance with respect to the training set as only regions of the
instance space that are occupied by no objects in the training set are affected 
it is dicult to see how any plausible metric for complexity could interpret the addition
of such branches as not increasing the complexity of the tree 
the end result is that the post processor adds complexity to the decision tree without
altering how the tree applies to the training data  the occam thesis predicts that this will 
in general  lower predictive accuracy while the similarity assumption predicts that it will 
in general  increase predictive accuracy  as will be seen  the latter prediction is consistent
with experimental evidence and the former is not 

    the post processor

while the above process could be applied to both continuous and discrete attributes  the
current implementation addresses only continuous attributes 
the post processor operates by examining each leaf l of the tree in turn  for each l 
each attribute a is considered in turn  for each a  all possible thresholds below and above
the region of the instance space occupied by objects at l are explored  first  the minimum
 min  and maximum  max  are determined for values of a that are possible for objects
that can reach l  if l lies below the  branch of a split on a then the threshold for that
split provides an upper limit  max  on values for a at l  if it lies below a   branch  the
threshold provides a lower limit  min   where the node does not lie below a  branch 
max      where the node does not lie below a   branch  min       only objects
from the training set that have values of a within the range min  max are considered in the
following operations 
for each value observed in the training set for the attribute within the allowable range
but outside the actual range of values of a for objects at l  the evidence is evaluated in
support of reclassifying the region above or below that threshold  the level of support for a
given threshold is evaluated using a laplacian accuracy estimate  niblett   bratko        
because each leaf relates to a binary classification  an object belongs to the class in question
or does not   the binary form of laplace is used  for threshold t on attribute a at leaf l 
the evidence in support of labeling the partition below t with class n is the maximum value
for an ancestor node x of l for the formula
p   
t   
where t is the number of objects at x for which min   a  t  and p is the number of those
objects which belong to class n 
the evidence in support of labeling a partition above a threshold is calculated identically
with the exception that the objects for which t   a  max are instead considered 
if the maximum evidence for a new labeling exceeds the evidence for the current labeling
of the region  a new branch is added for the appropriate threshold creating a new leaf node
labeled with the appropriate class 
in addition to evidence in favor of the current labeling gathered as above  further evidence in support of the current labeling of a region is calculated using the laplace accuracy
   

fifurther experimental evidence against the utility of occam s razor

estimate considering the objects at the leaf  where t is the number of objects at the leaf and
p is the number of those objects that belong to the class with which the node is labeled 
this approach ensures that all new partitions define true regions  that is  for any
attribute a and value v it is not possible to partition on a  v unless it is possible for
both objects from the domain with values of a greater than v and objects with values less
than or equal to v to reach the node being partitioned  even though no objects from the
training set will fall within the new partition   in particular  this ensures that the new cuts
are not simple duplications of existing cuts at ancestors to the current node  thus  every
modification adds non redundant complexity to the tree 
this algorithm is presented in figure    it has been implemented as a modification
to c    release    called c   x  the source code for these modifications is available as an
on line appendix to this paper 
in c   x  where multiple sets of values equally satisfy the specified constraints and
maximize the laplace function  values of na and nb that are deeper in the tree are selected
over those closer to the root and  at a single node  preference for values of aa and ab depends
upon the order of attributes in the definition of the data and preference for values of va
and vb is dependent upon data order  these selection strategies are a side effect of the
implementation of the system  there is no reason to believe that the experimental results
would differ in general if other strategies were used to select between competing constraints 
by default  c    develops two decision trees each time that it is run  an unpruned and a
pruned  simplified  decision tree  c   x produces post processed versions of both of these
trees 

    evaluation
to evaluate the post processor it was applied to all datasets containing continuous attributes
from the uci machine learning repository  murphy   aha        that were then held  due
to previous machine learning experimentation  in the local repository at deakin university 
these datasets are believed to be broadly representative of those in the repository as a
whole  after experimentation with these eleven data sets  two additional data sets  sick
euthyroid and discordant results  were retrieved from the uci repository and added to the
study in order to investigate specific issues  as discussed below 
the resulting thirteen datasets are described in table    the second column contains
the number of attributes by which each object is described  next is the proportion of these
that are continuous  the fourth column indicates the proportion of attribute values in the
data that are missing  unknown   the fifth column indicates the number of objects that
the data set contains  the sixth column indicates the proportion of these that belong to
the class represented by the most objects within the data set  the final column indicates
the number of classes that the data set describes  note that the glass type dataset uses the
float not float other three class classification rather than the more commonly used six
class classification 
each data set was divided into training and evaluation sets     times  each training
set consisted of     of the data  randomly selected  each evaluation set consisted of the
remaining     of the data  both c    and c   x were applied to each of the resulting     
    data sets by     trials  training and evaluation set pairs 
   

fiwebb

let cases n  denote the set of all training examples that can reach node n 
let value a  x  denote the value of attribute a for training example x 
let pos x  c  denote the number of objects of class c in the set of training examples x 
let laplace x  c            where x is a set of training examples  jx j is the number of training
examples and c is a class 
let upperlim n  a  denote the minimum value of a cut on attribute a for an ancestor node of n for
which n lies below a  branch  if there is no such cut  upperlim n  a       this determines an
upper bound on the values for a that may reach n 
let lowerlim n  a  denote the maximum value of a cut on attribute a for an ancestor node of n for
which n lies below a   branch  if there is no such cut  lowerlim n  a        this determines a
lower bound on the values for a that may reach n 
to post process leaf l dominated by class c
   find values of
n   n is an ancestor of l
a   a is a continuous attribute
v    x   x   cases n     v   value a   x    v  min v    y   y   cases l    v  
value a   y     v   lowerlim l  a  
c   c is a class
that maximize l   laplace fx   x   cases n     value a   x   v   value a   x   
lowerlim l  a  g  c   
   find values of
n   n is an ancestor of l
a   a is a continuous attribute
v    x   x   cases n     v   value a   x    v   max v    y   y   cases l    v  
value a   y     v  upperlim l  a  
c   c is a class
that maximize l   laplace fx   x   cases n     value a   x    v   value a   x  
upperlim l  a  g  c   
   if l   laplace cases l   c    l  l then
 a  if c    c
i  replace l with a node n with the test a  v  
ii  set the  branch for n to lead to a new leaf for class c  
iii  set the   branch for n to lead to l 
else if l   laplace cases l   c 
 b  if c    c
i  replace l with a node n with the test a  v  
ii  set the   branch for n to lead to a new leaf for class c  
iii  set the  branch for n to lead to l 
pos x c
jx j

a

a

a

a

a

a

a

a

a

a

a

a

a

a

a

a

b

b

b

b

a

b

b

b

b

a

a

a

b

b

b

a

b

b

b

b

b

b

b

b

a

b

b

a

b

a

a

a

a

b

b

b

b

b

figure    c   x post processing algorithm
   

fifurther experimental evidence against the utility of occam s razor

table    uci data sets used for experimentation
 
  most
no  of contin 
no  of common no  of
name
attrs  uous missing objects class classes
breast cancer wisconsin
 
   
  
   
  
 
cleveland heart disease
  
  
  
   
  
 
credit rating
  
  
 
   
  
 
discordant results
  
  
 
    
  
 
echocardiogram
 
  
 
  
  
 
glass type
 
   
 
   
  
 
hepatitis
  
  
 
   
  
 
hungarian heart disease
  
  
  
   
  
 
hypothyroid
  
  
 
    
  
 
iris
 
   
 
   
  
 
new thyroid
 
   
 
   
  
 
pima indians diabetes
 
   
 
   
  
 
sick euthyroid
  
  
 
    
  
 
table   summarizes the percentage predictive accuracy obtained for the unpruned decision trees generated by both c    and c   x  it presents the mean  x  and standard
deviation  s  over each set of     trials with respect to each data set for both c    and
c   x along with the results of a two tailed matched pairs t test comparing these means 
for twelve of the thirteen data sets c   x obtained a higher mean accuracy than c     for
the remaining data set  hypothyroid  c    obtained higher mean predictive accuracy than
c   cs  albeit by a small margin measured to two decimal places the respective mean accuracies were       and        respectively   for nine of the data sets the advantage toward
c   x is statistically significant at the      level  p         although the advantage with
respect to the discordant results data is too small to be apparent when measured to one
decimal place  measured to two decimal places the values are       and       respectively  
the advantage toward c    for the hypothyroid data is also statistically significant at the
     level  the differences in mean predictive accuracy for the hungarian heart disease 
new thyroid and sick euthyroid data sets are not significant at the      level 
table   uses the same format as table   to summarize the predictive accuracy obtained
for the pruned decision trees generated by both c    and c   x  for the same twelve data
sets c   x obtained a higher mean predictive accuracy than c     for the remaining data
set  hypothyroid  c    again obtained higher mean predictive accuracy  although again the
magnitude of the difference is so small that it is not apparent at the level of precision
displayed  measured to two decimal places the mean accuracies are       and         for
six of the data sets the advantage toward c   x is statistically significant at the     
level  although the difference is only apparent at a precision of two decimal places for the
discordant results data        and        respectively   the advantage toward c    for
the hypothyroid data is also statistically significant at the      level  the differences for
   

fiwebb

table    percentage predictive accuracy for unpruned decision trees 
name
breast cancer wisconsin
cleveland heart disease
credit rating
discordant results
echocardiogram
glass type
hepatitis
hungarian heart disease
hypothyroid
iris
new thyroid
pima indians diabetes
sick euthyroid

c   

x

    
    
    
    
    
    
    
    
    
    
    
    
    

s

   
   
   
   
   
   
   
   
   
   
   
   
   

c   x

x

s

t

p

                   
                   
                   
                   
                    
                   
                   
                   
                  
                   
                   
                   
                   

table    percentage accuracy for pruned decision trees 
name
breast cancer wisconsin
cleveland heart disease
credit rating
discordant results
echocardiogram
glass type
hepatitis
hungarian heart disease
hypothyroid
iris
new thyroid
pima indians diabetes
sick euthyroid

c   

x

    
    
    
    
    
    
    
    
    
    
    
    
    

s

   
   
   
   
   
   
   
   
   
   
   
   
   

c   x

x

    
    
    
    
    
    
    
    
    
    
    
    
    

s

   
   
   
   
   
   
   
   
   
   
   
   
   

t

p

          
          
          
          
           
          
          
          
         
          
          
          
          

breast cancer wisconsin  echocardiogram  hungarian heart disease  iris  new thyroid and
sick euthyroid are not statistically significant at the      level 
after completing experimentation on the initial eleven data sets  the results for the
hypothyroid data stood out in stark contrast from those for the other ten  this raised
the possibility that there might be distinguishing features of the hypothyroid data that
   

fifurther experimental evidence against the utility of occam s razor

accounted for this difference in performance  table   indicates this data set is clearly
distinguishable from the other ten initial data sets in the following six respects 

 having more attributes 
 containing a greater proportion of discrete attributes  which are not directly addressed
by c   x  






containing more objects 
having a greater proportion of the objects belong to the most common class 
having more classes  and
producing decision trees of extremely high predictive accuracy without post processing 

to explore these issues the discordant results and sick euthyroid data sets were retrieved
from the uci repository and added to the study  these data sets are identical to the
hypothyroid data set with the exception that each has a different class attribute  all three
data sets contain the same objects  described by the same attributes  the addition of the
discordant results and sick euthyroid data did little to illuminate this issue however  for
all three data sets the changes in accuracy are of very small magnitude  for hypothyroid
there is a significant advantage to c     for sick euthyroid there is no significant advantage
to either system  for the discordant results data there is a significant advantage to c   x 
the question of whether there is a distinguishing feature of the hypothyroid data that
explains the observed results remains unanswered  further investigation of this issue lies
beyond the scope of the current paper but remains an interesting direction for future research 
these results suggest that c   x s post processing more frequently increases predictive
accuracy than not for the type of data to be found in the uci repository   of the twenty six
comparisons  there was a significant increase for fifteen and there was a significant decrease
for only two  a sign test reveals that this rate of success is significant at the      level 
p          
tables   and   summarize the number of nodes in the decision trees developed  table  
addresses unpruned decision trees and table   addresses pruned decision trees  each postprocessing modification replaces a single leaf with a split and two leaves  at most one such
modification can be performed per leaf in the original tree  for all data sets the postprocessed decision trees are significantly more complex than the original decision trees  in
most cases post processing has increased the mean number of nodes in the decision trees
by approximately      this demonstrates that the post processing is causing substantial
change 

   discussion

the primary objective of this research has been to discredit the occam thesis  to this
end it uses a post processor that disregards the occam thesis and instead is theoretically
founded upon the similarity assumption  experimentation with this post processor has
   

fiwebb

table    number of nodes for unpruned decision trees 
c   
c   x
name
x
s
x
s
t
p
breast cancer wisconsin                               
cleveland heart disease                                
credit rating
                                 
discordant results
                               
echocardiogram
                             
glass type
                             
hepatitis
                             
hungarian heart disease                               
hypothyroid
                             
iris
                            
new thyroid
                             
pima indians diabetes                                   
sick euthyroid
                               
table    number of nodes for pruned decision trees 
c   

c   x

name
x
s
x
breast cancer wisconsin              
cleveland heart disease              
credit rating
              
discordant results
             
echocardiogram
             
glass type
             
hepatitis
             
hungarian heart disease               
hypothyroid
             
iris
            
new thyroid
             
pima indians diabetes                 
sick euthyroid
             

s

   
    
    
   
   
   
   
    
   
   
   
    
   

t

     
     
     
     
     
     
     
     
     
     
     
     
     

p

     
     
     
     
     
     
     
     
     
     
     
     
     

demonstrated that it is possible to develop systematic procedures that  for a range of  realworld  learning tasks increase the predictive accuracy of inferred decision trees as a result
of changes that substantially increase their complexity without altering their performance
upon the training data 
it is  in general  dicult to attack the occam thesis due to the absence of a widely
agreed formulation thereof  however  it is far from apparent how the occam thesis might
   

fifurther experimental evidence against the utility of occam s razor

          
                       
          
              
            
 
 
 
 
 
                    
a
figure    modified simple instance space
  
 
 
 
 
b 
 
 
 
 

be recast to both accommodate these experimental results and provide a practical learning
bias 

    directions for future research
the implications of this research reach beyond its relevance to occam s razor  the postprocessor appears to have practical utility in increasing the quality of inferred decision trees 
however  if the objective of the research were to improve predictive accuracy rather than
to discredit the occam thesis  the post processor would be modified in a number of ways 
the first modification would be to enable the addition of multiple partitions at a single
leaf from the original tree  c   x selects only the single modification for which there is the
maximum support  this design decision originated from a desire to minimize the likelihood
of performing modifications that will decrease accuracy  in principle  however  it would
appear desirable to select all modifications for which there is strong support  each of which
could then be inserted into the tree in order of level of supporting evidence 
even greater increases in accuracy might be expected if one removed the constraint that
the post processing should not alter the performance of the decision tree with respect to
the training set  in this case  new partitions may well be found that employ objects from
other regions of the instance space to provide evidence in support of adding partitions that
correct misclassifications of small numbers of objects at a leaf node from the original tree 
the similarity assumption would provide strong evidence for such repartitioning  such
a situation would occur  for example  with respect to the learning problem illustrated in
figure    if there was an additional object of class   with attribute values a   and b   
this is illustrated in figure    in this case c    would still create the indicated partitions 
however  c   x would be unable to relabel the area containing the additional object due to
the constraint that it not alter the performance of the original decision tree with respect to
the training set  thus the addition of the object prevents c   x from relabeling the shaded
region even though  on the basis of the similarity assumption  it improves the evidence in
support of that relabeling 
such an extended post processor would encourage the following model of inductive inference of decision trees  the role of c     or a similar system  would be to identify clusters
   

fiwebb

of objects within the instance space that should be grouped under a single leaf node  a
second stage would then analyze regions of the instance space that lie outside those clusters
in order to allocate classes to those regions  current decision tree learners  motivated by
the occam thesis  ignore this second stage  leaving regions outside the identified clusters
associated with whatever classes have been assigned to them as a by product of the cluster
identification process 

    other related research
a number of researchers have developed learning systems that can be viewed as considering
evidence from neighboring regions of the instance space in order to derive classifications
within regions of the instance space that are not occupied by examples from the training
set  ting        does this explicitly  by examining the training set to directly explore the
neighborhood of the object to be classified  this system uses instance based learning for
classification within nodes of a decision tree with low empirical support  small disjuncts  
a number of other systems can also be viewed as considering evidence from neighboring
regions for classification  these systems learn and then apply multiple classifiers  ali 
brunk    pazzani        nock   gascuel        oliver   hand         in such a context 
any point within a region of the instance space that is occupied by no training objects is
likely to be covered by multiple leaves or rules  of these  the leaf or rule with the greatest
empirical support will be used for classification 
c   x uses two distinct criteria for evaluating potential splits  the standard c    stage
of tree induction employs an information measure to select splits  the post processor uses
a laplace accuracy estimate  similar uses of dual criteria have been investigated elsewhere 
quinlan        employs a laplace accuracy estimate considering neighboring regions of the
instance space to estimate the accuracy of small disjuncts  lubinsky        and brodley
       employ resubstitution accuracy to select splits near the leaves during induction of
decision trees 
by adding a split to a leaf  c   x is specializing with respect to the class at that leaf
 and generalizing with respect to the class of the new leaf   holte et al         explored a
number of techniques for specializing small disjuncts  c   x differs in that all leaves are
candidates for specialization  not just those with low empirical support  it further differs
in the manner in which it selects the specialization to perform by considering the evidence
in support of alternative splits rather than just the strength of the evidence in support of
individual potential conditions for the current disjunct 

    bias versus variance
breiman  friedman  olshen  and stone        provide an analysis of complexity and induction in terms of a trade off between bias and variance  a classifier partitions the instance
space into regions  when these regions are too large  the degree of fit to an accurate partitioning of the instance space will be poor  increasing error rates  this effect is called bias 
when the regions are too small  the probability that individual regions are labeled with the
wrong class is increased  this effect  called variance  also increases error rates  according to
this analysis  due to variance  too fine a partitioning of the instance space tends to increase
   

fifurther experimental evidence against the utility of occam s razor

the error rate while  due to bias  too coarse a partitioning also tends to increase the error
rate 
increasing the complexity of a decision tree creates finer partitionings of the instance
space  this analysis can be used to argue against the addition of undue complexity to
decision trees on the ground that it will increase variance and hence the error rate 
however  the success of c   x in decreasing the error rate demonstrates that it is
successfully managing the bias variance trade off when it introduces complexity to the
decision tree  by using evidence from neighboring regions of the instance space  c   x
is successful in increasing the error rate resulting from variance at a lower rate than it
decreases the error rate resulting from bias  the success of c   x demonstrates that it is
not adding undue complexity to c    s decision trees 

    minimum encoding length induction

minimum encoding length approaches perform induction by seeking a theory that enables
the most compact encoding of both the theory and available data  two key approaches
have been developed  minimum message length  mml   wallace   boulton        and
minimum description length  mdl   rissanen         both approaches admit to probabilistic interpretations  given prior probabilities for both theories and data  minimization
of the mml encoding closely approximates maximization of posterior probability  wallace   freeman         an mdl code length defines an upper bound on  unconditional
likelihood   rissanen        
the two approaches differ in that mdl employs a universal prior  which rissanen       
explicitly justifies in terms of occam s razor  while mml allows the specification of distinct
appropriate priors for each induction task  however  in practice  a default prior is usually
employed for mml  one that appears to also derive its justification from occam s razor 
neither mdl nor mml with its default prior would add complexity to a decision tree
if doing so were justified solely on the basis of evidence from neighboring regions of the
instance space  the evidence from the study presented herein appears to support the
potential desirability of doing so  this casts some doubt upon the utility of the universal
prior employed by mdl and the default prior usually employed with mml  at least with
respect to their use for maximizing predictive accuracy 
it should be noted  however  that the probabilistic interpretation of these minimum
encoding length techniques indicates that encoding length minimization represents maximization of posterior probability or of unconditional likelihood  maximization of these
factors is not necessarily directly linked with maximizing predictive accuracy 

    appropriate application of grafting and pruning

it is important to note that although this paper calls into question the value of learning
biases that penalize complexity  in no way does it provide support for learning biases that
encourage complexity for its own sake  c   x only grafts new nodes onto a decision tree
when there is empirical support for doing so 
nor do the results in any way argue against the appropriate use of decision tree pruning 
to generate its pruned trees  c    removes branches where statistical estimates of the upper
bounds on the error rates indicate that these will not increase if the branch is removed  it
   

fiwebb

could be argued that c    only reduces complexity when there is empirical support for
doing so  it is interesting to note that for eight of the thirteen data sets examined  c   x s
post processing of the pruned trees resulted in higher average predictive accuracy than
post processing of unpruned trees  these results suggest that both pruning and grafting
can play a valuable role when applied appropriately 

   conclusion
this paper presents a systematic procedure for adding complexity to inferred decision trees
without altering their performance on the training data  this procedure has been demonstrated to lead to increases in predictive accuracy for a range of learning tasks when applied
to both pruned and unpruned trees inferred by c     for only one of the thirteen learning
tasks examined did the procedure lead to a statistically significant loss in accuracy and in
this case the magnitude of the difference in mean accuracy was extremely small  on the
face of it  this provides strong experimental evidence against the occam thesis 
this post processing technique was developed by rejecting the occam thesis and instead attending to the similarity assumption that similar objects have high probability of
belonging to the same class 
the procedure developed was constrained by the need to ensure that the revised decision
tree performed identically to the original decision tree with respect to the training data 
this constraint arose from the desire to obtain experimental evidence against the occam
thesis  it is possible that if this constraint is removed  the basic techniques outlined in this
paper could result in even greater improvements in predictive accuracy than those reported
herein 
this research has considered only one version of occam s razor that favors minimization
of syntactic complexity in the expectation that this will tend to increase predictive accuracy 
other interpretations of occam s razor are also possible  such as that one should minimize
semantic complexity  while others  bunge        have provided philosophical objections to
such formulations of occam s razor  this paper has not sought to investigate them 
the version of occam s razor examined in this research has been used widely in machine
learning with apparent success  the objections to this principle that have been substantiated by this research raise the question  why has it had such apparent success if it is so
awed  webb        suggests that the apparent success of the principle has been due to the
manner in which syntactic complexity is usually associated with other relevant qualities of
inferred classifiers such as generality or prior probability  if this thesis is accepted then one
of the key challenges facing machine learning is to understand these deeper qualities and to
employ that understanding to place machine learning on a sounder theoretical footing  this
paper offers a small contribution in this direction by demonstrating that minimization of
surface syntactic complexity does not  in itself  in general maximize the predictive accuracy
of inferred classifiers 
it is nonetheless important to realize that  the thrust of this paper notwithstanding 
occam s razor will often be a useful learning bias to employ  this is because there will frequently be good pragmatic reasons for preferring a simple hypothesis  a simple hypothesis
will in general be easier to understand  communicate and employ  a preference for simple
   

fifurther experimental evidence against the utility of occam s razor

hypotheses cannot be justified in terms of expected predictive accuracy but may be justified
on pragmatic grounds 

acknowledgements
this research has been supported by the australian research council  i am grateful to
charlie clelland  david dowe  doug newlands  ross quinlan and anonymous reviewers for
extremely valuable comments from which the paper has benefited greatly 

references

aha  d  w   kibler  d     albert  m  k          instance based learning algorithms 
machine learning           
ali  k   brunk  c     pazzani  m          on learning multiple descriptions of a concept 
in proceedings of tools with artificial intelligence new orleans  la 
berkman  n  c     sandholm  t  w          what should be minimized in a decision tree 
a re examination  technical report        university of massachusetts at amherst 
computer science department  amherst  mass 
blumer  a   ehrenfeucht  a   haussler  d     warmuth  m  k          occam s razor 
information processing letters              
breiman  l   friedman  j  h   olshen  r  a     stone  c  j          classification and
regression trees  wadsworth international  belmont  ca 
brodley  c  e          automatic selection of split criterion during tree growing based on
node selection  in proceedings of the twelth international conference on machine
learning  pp        taho city  ca  morgan kaufmann 
bunge  m          the myth of simplicity  prentice hall  englewood cliffs  nj 
clark  p     niblett  t          the cn  induction algorithm  machine learning    
        
fayyad  u  m     irani  k  b          what should be minimized in a decision tree 
in aaai     proceedings eighth national conference on artificial intelligence  pp 
        boston  ma 
good  i  j          explicativity  a mathematical theory of explanation with statistical
applications  proceedings of the royal society of london series a               
holte  r  c          very simple classification rules perform well on most commonly used
datasets  machine learning                
holte  r  c   acker  l  e     porter  b  w          concept learning and the problem
of small disjuncts  in proceedings of the eleventh international joint conference on
artificial intelligence  pp          detroit  morgan kaufmann 
   

fiwebb

lubinsky  d  j          increasing the performance and consistency of classification trees by
using the accuracy criterion at the leaves  in proceedings of the twelth international
conference on machine learning  pp          taho city  ca  morgan kaufmann 
michalski  r  s          a theory and methodology of inductive learning  in michalski 
r  s   carbonell  j  g     mitchell  t  m   eds    machine learning  an artificial
intelligence approach  pp          springer verlag  berlin 
murphy  p  m          an empirical analysis of the benefit of decision tree size biases as
a function of concept distribution  tech  rep         department of information and
computer science  university of california  irvine 
murphy  p  m     aha  d  w          uci repository of machine learning databases 
 machine readable data repository   university of california  department of information and computer science  irvine  ca 
murphy  p  m     pazzani  m  j          exploring the decision forest  an empirical investigation of occam s razor in decision tree induction  journal of artificial intelligence
research             
niblett  t     bratko  i          learning decision rules in noisy domains  in bramer 
m  a   ed    research and development in expert systems iii  pp         cambridge
university press  cambridge 
nock  r     gascuel  o          on learning decision committees  in proceedings of the
twelth international conference on machine learning  pp          taho city  ca 
morgan kaufmann 
oliver  j  j     hand  d  j          on pruning and averaging decision trees  in proceedings
of the twelth international conference on machine learning  pp          taho city 
ca  morgan kaufmann 
pearl  j          on the connection between the complexity and credibility of inferred
models  international journal of general systems             
quinlan  j  r          induction of decision trees  machine learning            
quinlan  j  r          learning logical definitions from relations  machine learning    
        
quinlan  j  r          improved estimates for the accuracy of small disjuncts  machine
learning           
quinlan  j  r          c     programs for machine learning  morgan kaufmann  los
altos 
rao  r  b   gordon  d     spears  w          for every generalization action is there really
an equal and opposite reaction  analysis of the conservation law for generalization performance  in proceedings of the twelth international conference on machine
learning  pp          taho city  ca  morgan kaufmann 
   

fifurther experimental evidence against the utility of occam s razor

rendell  l     seshu  r          learning hard concepts through constructive induction 
framework and rationale  computational intelligence             
rissanen  j          a universal prior for integers and estimation by minimum description
length  annals of statistics              
rissanen  j          stochastic complexity  journal of the royal statistical society series
b                  
schaffer  c          sparse data and the effect of overfitting avoidance in decision tree
induction  in aaai     proceedings of the tenth national conference on artificial
intelligence  pp          san jose  ca  aaai press 
schaffer  c          overfitting avoidance as bias  machine learning              
schaffer  c          a conservation law for generalization performance  in proceedings
of the      international conference on machine learning san mateo  ca  morgan
kaufmann 
ting  k  m          the problem of small disjuncts  its remedy in decision trees  in
proceedings of the tenth canadian conference on artificial intelligence  pp        
morgan kaufmann  
wallace  c  s     boulton  d  m          an information measure for classification  computer journal              
wallace  c  s     freeman  p  r          estimation and inference by compact coding 
journal of the royal statistical society series b                  
webb  g  i          generality is more significant than complexity  toward alternatives to
occam s razor  in zhang  c   debenham  j     lukose  d   eds    ai      proceedings of the seventh australian joint conference on artificial intelligence  pp       
armidale  world scientific 

   

fi