journal of artificial intelligence research                  

submitted        published      

semantic similarity measures applied to an ontology
for human like interaction
esperanza albacete
javier calle
elena castro
dolores cuadra

ealbacet inf uc m es
fcalle inf uc m es
ecastro inf uc m es
dcuadra inf uc m es

computer science department  carlos iii university 
madrid        spain

abstract
the focus of this paper is the calculation of similarity between two concepts from an ontology
for a human like interaction system  in order to facilitate this calculation  a similarity function is
proposed based on five dimensions  sort  compositional  essential  restrictive and descriptive 
constituting the structure of ontological knowledge  the paper includes a proposal for computing a
similarity function for each dimension of knowledge  later on  the similarity values obtained are
weighted and aggregated to obtain a global similarity measure  in order to calculate those weights
associated to each dimension  four training methods have been proposed  the training methods
differ in the element to fit  the user  concepts or pairs of concepts  and a hybrid approach  for
evaluating the proposal  the knowledge base was fed from wordnet and extended by using a
knowledge editing toolkit  cognos   the evaluation of the proposal is carried out through the
comparison of system responses with those given by human test subjects  both providing a
measure of the soundness of the procedure and revealing ways in which the proposal may be
improved 

   introduction
the main purpose of an ontology in a human like interaction system is to unify the representation
of each concept  relating it to the appropriate terms  as well as to other concepts with which it
shares a semantic relation  furthermore  the ontological component should also be able to
perform certain inferential processes  such as the calculation of semantic similarity between
concepts  the subject of similarity has been and continues to be widely studied in the fields and
literature of computer science  artificial intelligence  psychology and linguistics  good similarity
measures are necessary for several techniques from these fields including information retrieval 
clustering  data mining  sense disambiguation  ontology translation and automatic schema
matching  the present paper focuses on the study of semantic similarity between concepts in an
ontology from the framework of natural interaction 
the principal benefit gained from this procedure is the ability to substitute one concept for
another based on a calculation of the similarity of the two  given specific circumstances  from the
users perspective  the procedure allows for the use of synonyms  terms related to a single
concept  of a concept in the case where the user is not familiar with the original concept itself 
moreover  semantic similarity offers the possibility to build explanations for clarifying a concept
to the user based on similar concepts  thereby enhancing communicative effectiveness 
     ai access foundation  all rights reserved 

fialbacete  calle  castro   cuadra

on the other hand  the system may also be able to understand a previously unknown concept 
as long as the user is able to relate it to similar concepts that are previously known by the system 
in this way  the system will learn new concepts and automatically enrich its ontology to improve
future interactions 
the first task of this study is to develop a semantic similarity measure that takes into account
particular ontological dimensions described in an earlier study  calle  castro   cuadra         in
this approach  the conceptualization comprises seven ontological dimensions  semiotic  sort 
compositional  essential  restrictive  descriptive  and comparative  the first three dimensions have
been previously applied in related works  as will be stated in section    essential  restrictive and
descriptive dimensions are part of the nature of the concept  can influence human judgment of
similarity and will be detailed in section    the seventh one  comparative dimension  is derived
from previous dimensions and is in charge of calculating the degree of similarity between
ontological concepts 
the second goal of the present article is to evaluate the quality of the mechanism developed
for the calculation of similarities between two concepts in an ontology which is specially
designed for a human like interaction system  calle f          to achieve this  several
experiments have been designed and performed here  before these experiments and the
consequent evaluation of the semantic similarity measure can be carried out  however  it is
necessary to implement the similarity dimensions defined in the conceptual model and feed the
database with a large number of concepts 
to briefly outline the content that follows in this paper  section   reviews the literature on
similarity measures in ontologies and the methods available for their evaluation  in section    an
approach to similarity measures applied to an ontological model based on several dimensions is
proposed  in section    a detailed explanation is provided of the experiments designed to test the
proposal  as well as the results obtained from their execution  section   discusses the limitations
encountered in the study  finally  section   presents conclusions for future research 

   related work
the present section of this paper has two main objectives  first  it aims to provide an overview of
the different types of approaches available for the comparison of concepts in ontologies and  in so
doing  to identify the foundations on which the desired similarity measure may be modeled 
taking into account the seven dimensions described in a previous study  calle et al         
secondly  it aims to select the best way to evaluate the results yielded from this desired similarity
measure according to other studies regarding similarity metrics assessment 
basically two types of methods exist for the comparison of terms in a graph based ontology 
edge based methods using graph edges and their types as the data source and node based methods
using graph nodes and their properties as the main data source  the simplest and most intuitive
similarity measure  the former method is based mainly on the counting of the number of edges in
a path between two terms on a graph  rada  mili  bicknell   blettner         within the edgebased method  two general approaches exist  firstly  a distance approach that selects either the
shortest path or the average of all paths  when more than one path exists  and secondly a common
   

fisemantic similarity measures applied to an ontology

path approach that calculates similarity directly by the length of the path from the lowest common
ancestor of the two terms to the root node  wu   palmer         over the past few years  a
variety of edge based methods have been defined  resnik        leacock   chodorow        
all edge based methods are grounded in two basic assumptions  firstly  that nodes and links
are uniformly distributed in the ontology  that is  terms at the same depth have the same
specificity  budanitsky        and  secondly  that edges at the same level in the ontology indicate
the same semantic distance between terms  however  these suppositions are rarely true in the
majority of ontologies  for this reason  several strategies have been proposed in response to this
fact  one example of such a strategy is the weighting of edges according to their hierarchical
depth or the use of node density and link type  richardson  smeaton   murphy        
nevertheless  these strategies do not solve the aforementioned problems due to the fact that terms
at the same depth do not necessarily have the same specificity and that edges at the same level do
not necessarily represent the same semantic distance 
the second  or node based  method relies on the comparison of the properties of the terms
involved which can be related to the terms themselves  their ancestors or their descendants  a
commonly used concept in these methods is that of information content  ic   providing a measure
of how specific and informative a term is  the ic of a term c can be quantified as the negative
log likelihood  ic    log p c   where p c  is the probability of the occurrence of c in a specific
corpus  generally being estimated by its annotation frequency  another approach employed to
obtain the ic is based on the number of children a term has in the ontological structure  seco 
veale   hayes         the concept of ic can be applied to the common ancestors of two terms in
order to quantify the information they share and  thereby  measure their semantic similarity  in
this way  two main approaches exist  the first is the most informative common ancestor  mica 
technique in which only the common ancestor with the highest ic is considered  resnik        
the second is the disjoint common ancestor  dca  technique in which all disjoint common
ancestors are considered  the common ancestors that do not subsume any other common
ancestor   in one definition  lin         the similarity between two concepts using the node based
method has been expressed as the ratio between the amount of information needed to state the
commonality between the two concepts and the information needed to fully describe them 
moreover  a similarity measure for hierarchical ontologies called ontology structure based
similarity  oss  has also been defined  schickel zuber        and whose major ingredient is the
computation of an a priori score of a concept c   aps c    which shares some similarities with ic
 i e   both are calculated from the topology and structure of the ontology reflecting the
information contained within and between the concepts  
additionally  several hybrid methods have also been defined in an attempt to improve the
results of both techniques defined above  in the work of jiang and conrath          for example  a
combined model is defined that is derived from the edge based notion by adding information
content as a decision factor  the link strength between two concepts is defined as the difference
of information content between them 
with the aim of collecting all different methods and approaches  simpack  a generic java
library of similarity measures for use in ontologies  has been created  bernstein  kaufmann 
   

fialbacete  calle  castro   cuadra

kiefer   brki        and includes the implementation of ontology based similarity methods
 including edge based and node based measures   it is important to note that the majority of the
techniques described to define semantic similarity between concepts have been applied to
hierarchical ontologies whose structure takes into account only one or two dimensions in the
same graph  for example  wordnet  fellbaum        consists of an ontological graph with over
        concepts and whose edges model the is a and part of relationships  a perl module
 pedersen  patwardhan   michelizzi        was implemented for this lexical database with a
variety of semantic similarity measures  another example of application is the gene ontology
 department of genetics  stanford university school of medicine  california  usa          one
of the most important ontologies within the bioinformatics community  with over        concepts
and modeling is a and part of relationships in the same graph  thus  while none of the
techniques described in this section can be supposed to be appropriate in dealing with more than
two dimensions of similarity  they can nevertheless be useful to attempt to define some of the
dimensions in the present studys ontological model 
the second aim of the present section is to review the assessment techniques for ontological
similarity functions used in earlier studies  the gold standard established in the majority of the
experimental evaluations of similarity  resnik        jiang   conrath        altintas  karsligil 
  coskun        schickel zuber        bernstein et al         is based on the experiment
described in miller and charles study        which has become the benchmark for determining
the similarity of words in natural language processing research  this experiment relies on the
similarity assessments made by    university students when provided with    name pairs chosen
a priori to cover high  intermediate and low levels of similarity and when asked to assess the
similarity of their meaning on a scale from    no similarity  to    perfect synonymy   the average
of scored values represents a good estimation of the degree of similarity between two terms 
in certain evaluations based on human judgment  inkpen        bernstein et al         
variations in the number of participants or the way to administer the questionnaire have been
introduced  in one of these studies  bernstein et al          a website containing a survey tool was
designed to perform the evaluation  in the web experiment  subjects were asked to assess the
similarity between    pairs of concepts on a scale from    no similarity  to    identical   finally 
subjects were also given the possibility of adding comments to their assessment  to evaluate the
quality of the similarity measures  its results were compared with the test subjects assessments
using the corrected spearman rank correlation coefficient 
it can be concluded that human reasoning is one of the most widely used methods of
comparison when performing validation of a similarity measure  for this reason  such a
methodology has also been used in the experimentation section of the present study  since it is
difficult to run a user based evaluation with complicated ontologies  for example  the gene
ontology  lord  stevens  brass   goble         it has been deemed necessary here to find or
model an ontology with elements that test subjects could understand  therefore  once the
ontological module is implemented  it must be populated with a sufficiently good coverage of
domain knowledge  that is  enough knowledge to meet the system requirements 

   

fisemantic similarity measures applied to an ontology

   theoretical approach
the conceptual model grounding the present study  calle et al         distributes ontological
knowledge into seven different dimensions  the semiotic dimension represents the relationship
between concepts  terms and language  for example  as shown in figure    the concept of the
wordnets synset         corresponds to a machine that is able to perform calculations
automatically  and one of the terms associated with this concept is computer  other terms
related to this concept are computing machine  computing device  data processor 
electronic computer and information processing system  all of them also linked to the concept
that corresponds to the english language  synset          

figure    example of semiotic dimension representation

the sort dimension represents the is a relationship between concepts  relates each concept
with other concepts and models a polytree structure  for instance  as shown in figure    the terms
node  server and web site are related to concepts that are instances of computer 

figure    sort dimension example

the essential dimension represents the general taxonomy of concepts  this taxonomy is
located in the nodes at the top of the polytree represented in the sort dimension  therefore  the
relations included in its design are already observed in the sort dimension  but since they
organize the knowledge at the higher abstraction level  they are more discriminative  they should
be taken into account separately  adding extra value to similarity measure 
its design is crucial for attaining good similarity measures  and determines the usefulness of
this dimension  the essential dimension of wordnet  princeton univ          for example 
classifies the concepts into four main linguistic categories  verb  noun  adjective  adverb   such
approach is the most adequate for a linguistic interaction domain  but may be weaker in a general
interaction domain  this proposal includes an essential design inspired in previous  calle et al  
      and related works  gee        miller        and refined through preliminary
experimentation  the design departs from three main categories  abstract  actions and entities 
and develops main classes of concepts  as shown in figure    finally  it should be added that this
proposal is aimed to general interaction domains  and could be improved if suited to specific
domains for particular interaction systems 

   

fialbacete  calle  castro   cuadra

concept
          

 

 

abstract

action

entity

          

          

          

attribute

circumstance

sui generis

          

          

          

place

time

role

language

          

          

          

          

activity

environment

          

          

 

domain

 

interactive

static

active

          

          

          

          

unidirectional
comm  agent

communicative
agent

          

          

human

mechanical

          

          

user

interaction
system

          

reactive

cyclic

          

          

          

figure    essential dimension taxonomy

the compositional dimension represents the part whole relationship between concepts  in
this way  any concept can have relationships with a collection of concepts that are part of it 
figure   shows some of the concepts that are part of a computer  for example hard disk 
ram and alu 
computer
          

hard disk

ram

alu

          

          

          



figure    compositional dimension example

the restrictive dimension shown in figure   describes the compatibility between concepts
related to some action and the rest  for example  the action to compute is related to the
concepts computer  calculator and laptop  among others 

   

fisemantic similarity measures applied to an ontology

computer
          

action concept 
to compute

calculator
          

          

laptop
          

figure    restrictive dimension example

the descriptive dimension shown in figure   is in charge of the relationships between three
kinds of concepts  a generic concept  entity  abstract entity or action   an attribute likely to
characterize that concept  and the domain  of values  on which that attribute is defined  notice
that there could be several available domains for a given attribute  and that a domain could be
numeric  magnitudes regarding a unit  or enumerated  a concept which is composed of a set of
named values which are also concepts   for example  an instance of the generic concept hard
disk will have a value in the numeric domain of information in bytes for the attribute concept
storage capacity 
generic concept 
hard disk

attribute concept 
storage capacity

domain concept 
information in bytes

          

          

          

figure    descriptive dimension example

finally  the comparative dimension is derived from previous dimensions and is responsible
for calculating in real time the degree of similarity between ontological concepts  this paper  in
fact  focuses precisely on that similarity calculation  finally  for reasons of efficiency  most
frequently requested similarities can be buffered  that is  stored when calculated  periodically
updated and retrieved when necessary 

   proposal
this paper proposes and evaluates a similarity measure based on the combination of individual
similarity measures according to each of the dimensions explained  see section     this
combination will be produced as training across numerous observations that will affect the weight
with which each dimension contributes to the final decision  training can be performed according
to different criteria  on one hand  different human subjects support their judgments on different
combinations of the dimensions  on the other hand  the nature of the concept determines the most
relevant dimension for each comparison  for example  when comparing the concept scanner
with the concept printer  the sort dimension could be very influential  since both are types of
computer peripherals  however restrictive dimension could not be as influential because they are
related to different actions  the opposite may happen with the concepts teacher and tutorial

   

fialbacete  calle  castro   cuadra

because both are related to similar actions according to the restrictive dimension  such as
teaching  while the sort dimension has little influence in this case 
the following step is to describe the similarity measure adapted to the described ontological
dimensions except for the semiotic dimension  yet not the only approach  similarity in the
semiotic dimension  or similarity between terms is frequently described as the edit distance or
levenshtein distance         that is  the number of changes necessary to turn one string into
another string  the decision to leave this dimension apart is supported by preliminary studies in
which this measure yields an average error rate above     and in some cases over     
furthermore  for every concept in that study  the accuracy provided by this dimension was lower
than that of some of the other dimensions  the semiotic dimension never produced the best
prediction   being the only dimension which never ranked first when tested separately  for this
reason  it is estimated as it cannot contribute positively to the results  at least  it cannot until it is
properly adapted   last but not least  during preliminary experimentation of the training including
this dimension  it was observed that each weight tended to zero  and with the drawback of
slowing down convergence of the weights of the rest of dimensions  however  as further work 
some evolution of this similarity measure  supported by knowledge on this dimension  can be
incorporated into the global measure of similarity 
    inference mechanisms
this sub section describes the method used to calculate the degree of similarity between two
given concepts in an ontology  since ontological knowledge here is structured into different
dimensions  the similarity measure will also be based on these dimensions  therefore  partial
similarity calculations will be made for the sort  essential  compositional  restrictive and
description dimensions described previously  the resulting overall similarity between the two
concepts is obtained through the calculation of the weighted average of the five partial similarities

where ss  sc  se  sr and sd are the similarity measures according to the sort  compositional 
essential  restrictive and description dimensions  respectively  the values w   w   w   w  and w 
represent the weights assigned to each dimension such that the resulting total similarity between
the two concepts will be a value between    completely different concepts  and    the two
concepts are the same  
the following sections describe in detail the procedures developed for the calculation of each
of the partial similarities 
      similarity according to sort dimension
the sort dimension represents the is a relationship between concepts  this dimension has a
polytree structure  allowing a concept to be a descendant of more than one concept  similarity in
this dimension is often calculated as proportional to the intersection of the list of predecessors of
   

fisemantic similarity measures applied to an ontology

both compared concepts regarding the total size of these lists  to define this measure  a variation
of the edge counting technique  concretely  the conceptual similarity measure defined in the
work of wu and palmer         has been employed  given two concepts  c  and c   this
measure can be defined as

where n  and n  are the number of ancestors of c  and c   while n  is the number of common
ancestors of c  and c   in the most advantageous tree if several are found in the polytree  
      similarity according to compositional dimension
the compositional dimension represents the part whole relationship between concepts  for this
reason  the most appropriate way to calculate the similarity between two concepts based on this
dimension is through the comparison of the parts  or ingredients  of these concepts  furthermore 
the calculation must also take into account the fact that a concept may consist of required and
optional concepts  this detail is important when calculating similarity since a greater weight must
be given to the required ingredients appearing in both concepts  while a lower weight is given to
the optional ingredients  the resulting similarity of two concepts  c  and c   in terms of the
compositional dimension is obtained by applying the formula 

where n  is the number of common components arising from the intersection of all
components of concept c  with those components of concept c  of type required  n  is the
number of common components arising from the intersection of all the components of c  with
those required components of c   n  is the number of required components that both c  and c 
have in common  and n  is the total number of common components  both required and optional 
of the two concepts  m  and m  represent the number of required components of concepts c  and
c   respectively  finally  m  and m  indicate the total number of components that c  and c  have 
      similarity according to essential dimension
the essential dimension contains a set of abstract concepts which define generic types of
concepts  such as action  entity  abstract  circumstance or attribute   this generic classification
frequently influences human speakers when estimating similarity  some other works on similarity
calculation posed that concepts are only comparable if included in the same category of
wordnets taxonomy  rita wordnet         such approach endows a critical value to this
dimension  while omitting the rest of the classification  what is proposed here is that this
dimension can contribute to similarity estimation as any other  albeit with a certain weight that
could be different than the rest   and that all the concepts observed in the design of the essential
dimension may influence the similarity estimation 

   

fialbacete  calle  castro   cuadra

the method for calculating similarity between two concepts c  and c  in the essential
dimension is based on the intersection of their essential ancestors  ancestors within the subset of
essential concepts   this is formalized as follows 

where card e   and card e   are  respectively  the total number of essential ancestors of
concepts c  and c   while card e   e   indicates the number of common essential ancestors 
      similarity according to restrictive dimension
the restrictive dimension is defined between a concept representing an action and another
concept representing an entity  similarity in this dimension is calculated in a different way
depending on the type of concepts to be compared  for this reason  two different similarity
measures exist for the dimension  comparing two actions and comparing two entities  similarity
between two concepts representing an entity will be based on the action concepts that both
entities have in common  the formula used for the calculation of this similarity when comparing
two entities  c  and c   is defined as

where m  and m  are the number of common actions that have a positive or negative
restrictive relationship with the entities c  and c   respectively  the values n   n   n  and n 
represent  respectively  the total number of actions having a positive relationship with the entity
c   a negative relationship with c   a positive relationship with the entity c   and a negative
relationship with c  
as regards the similarity between two concepts representing an action  this is calculated based
on the set of concepts defined on these actions  being more similar the higher the number of
restricted concepts in common  the formula to calculate the similarity between two action
concepts  c   c   of a particular sign  positive or negative  is defined as

where n  is the number of common entities shared by the two actions  and n  and n  are the
total number of entities having a restrictive relationship with c  and c   respectively 
      similarity according to descriptive dimension
the description dimension represents the relationship between a concept  an attribute and a value
in a concrete domain  similarity in this dimension is calculated differently depending on the type
of concepts to be compared  that is  entities  attributes or domains  for pairs of concepts  c   c  
representing an entity  the applicable formula is defined as

   

fisemantic similarity measures applied to an ontology

where n  is the number of common attributes without a default value assigned  n  is the
number of common attributes whose value is the same for both entities and has not been assigned
by default  and n  is the number of common attributes with the same value where one of them has
been assigned by default  the terms m  and m  correspond to the total number of attributes
related to the concepts c  and c   respectively 
if both concepts  c   c   are attributes  the formula to apply is defined as

where n  is the number of common values of both attributes  and n   n  is the total number of
possible values which can have the attributes c  and c   respectively 
finally  if the concepts to be compared  c   c   represent domains  the similarity according to
this dimension is calculated based on the amount of common attributes  for which those domains
apply  and the number of values shared by both domains 

where n  is the number of common attributes shared by the domains  c   c    and n   n  are
the total number of attributes associated with them  finally  m  is the number of common values
defined in both domains  and m   m  are the total number of values of the two domains 
finally  the concepts to be compared  c   c   may be values belonging to a domain  either
enumerated or of a numeric type  for operating domains  it is necessary to define previously a
correspondence between them  numeric domains can be related through a function  typically  a
lineal proportion   relating an enumerated domain to a numeric domain can be achieved by
assigning to each enumerated value a fuzzy label in the numeric domain  finally  the
correspondence between two enumerated domains always involves an intermediate numeric
domain  with a correspondence defined to each of the two other domains   once the values are
comparable  the formula to measure their similarity is defined as follows 

where cinf and csup are  respectively  the lower limit and the upper limit within the range of
values  and c  and c  are the correspondent numeric comparable values 
    preliminary experimentation
before testing the proposal  some preliminary experiments were performed to refine it and to
obtain a first perspective on its validity  these experiments have been instructed on a set of
similarity measures obtained from a total of    pairs of concepts evaluated by    human subjects 
this dataset will be further described in section     
   

fialbacete  calle  castro   cuadra

specifically  the individual influence of each dimension in similarity was tested thorough a set
of experiments involving each of them separately  since there is no combination of them  there is
no need for training either  figure   shows a box plot that represents the error measures produced
individually for each dimension 
   

error    

  
  
  
  
 
sort

compositional

essential

restrictive

descriptive

figure    performance of isolated dimensions of the ontology

figure   shows that in series of twenty pairs  every dimension produced better prediction than
the others at least once  in fact  the essential dimension provided the best response in almost half
of the cases  while the descriptive dimension was best in just one case 
restrictive
   

descriptive
  

sort
   

compositiona
l
   

essential
   

figure    cases in which each dimension is ranked first

this fact can lead to the conclusion that the essential design was appropriate  and that the
descriptive dimension was weak  in further analysis it was found that the latter lacked sufficient
knowledge  and it was improved in this line before evaluation  more knowledge was added  
despite this improvement  since the analysis and introduction of this knowledge is performed
manually  in contrast to other dimensions  for which knowledge was obtained from wordnet   it
could still be enhanced and this would improve the individual results of this dimension  besides 
this result is not definitive  since the weights may be different in other interaction domains  and
the volume of the knowledge base is important too  but a useful consequence is that each one of
   

fisemantic similarity measures applied to an ontology

the five ontological dimensions can contribute to the similarity function  supporting the
hypothesis that an adequate combination of them may yield better results than any of these
individual approaches 
    weights training methods
assigning the proper weight to each dimension is crucial to achieving good results  since a
human test subject does not usually give the same relevance to the five dimensions of similarity  a
basic training program regarding the weights associated with each dimension was developed  this
program is based on the reinforcement learning technique  specifically a variant of the q learning
algorithm  and it has been implemented in order to determine  through several iterations  the
appropriate value of the weights applied to each dimension  previously defined in section      to
minimize the error between the formula result and each human judgment  therefore  the input to
the training algorithm is the set of similarity judgments made by human test subjects  this
algorithm follows the next steps 
a  an initial step  where the five weights w   w   w   w  and w  applied to each dimension
 see formula in section      are initialized to   
b  for each iteration of the training algorithm  results for each dimension of similarity are
calculated according to the formulas described in the sections       to       
subsequently  the five new weights are calculated according to the next criteria 
   if
   if
   failure to meet conditions    and    
where parameter i is ranged from   to    one for each dimension  
represents each individual score and y represents a similarity value from   to    for one
pair of concepts scored by one of the participant 
stands for the increase of the
weight  for the dimension i  at the current iteration  while
represents that increase at
the previous iteration  the max simi  and min simi  represent the maximum and
minimum similarity individual values  respectively  finally  stands for the learning rate 
the training can be focused on different points of view  which will be tested and evaluated 
firstly  a pair oriented training was implemented in order to individually adjust the weights for
each of the    concept pairs  independently of the specific user  the weights are adjusted
individually for each of the pairs of concepts  taking one user per iteration  in this way  after each
iteration  a new array of refined weights is obtained and used for evaluating the similarity  the
test consists of calculating the similarity  with that array of weights  and comparing it with the
human assessment 
since the degree of significance assigned to each dimension may depend on the subjectivity of
the testers  it was of particular interest to make an adjustment of the weights based on each user 
   

fialbacete  calle  castro   cuadra

in this experiment  the training of the weights was performed once for each user and consisted of
   iterations  one for each pair of concepts   for an iteration of this training algorithm  absolute
error committed in relation to the corresponding pair was calculated  after running the training
for the    users  the average of the absolute errors for each of the iterations was calculated 
the third method has been designed in order to address the shortcomings of the pair oriented
training  it should be indicated that storing an array of the weights for each possible pair of
concepts in a medium sized ontology requires unusually extensive physical resources  besides  a
significant coverage of the thus defined knowledge would require far too much training  in short 
it is not realistic to develop that method because of the high number of combinations of concepts 
however  through preliminary experimentation it was checked that the weights applied to a pair
were also likely to be applied to other combinations of each of those two concepts  therefore  a
new training method  feature oriented  was proposed by slightly modifying the pair oriented one 
in the feature oriented method  the array of weights is stored for each concept instead of for each
pair of concepts  which solve both the problems of storage and the extent of training   each time
one concept is compared to any other  its array of weights will be reviewed and refined  the
similarity calculation for a given pair is based on the aggregation of the arrays of both concepts 
finally  it was observed that each method showed a different behavior depending on the pair
of concepts compared  the method achieving the worst results on average was also the best for
some specific pairs  subsequently  a hybrid method was proposed and has been developed 
combining the feature oriented and user oriented trainings  aiming to profit the advantages of
each method  the training will be similar to that focused on the user  but for each iteration the
array of weights will be refined to a different degree  taking into account the array stored for each
particular concept  therefore  if a particular dimension is usually relevant for a concept 
adaptation to the user in that dimension will be strengthened 

   evaluation
once the conceptual model of the ontology has been defined  and the weights training methods
proposed  the next step in this study is to evaluate the proposal  the present section describes the
experiments run for evaluating the proposal  from their design to the results obtained and
discussion  the knowledge base is supported by the relational database management system
oracle   g  and the logic of the ontology component  including the inference mechanisms  was
implemented in java  the knowledge bases were designed to satisfy specific purposes within a
research project  the initial knowledge load was obtained from the large lexical database
wordnet  fellbaum        including all the existing concepts  synsets   terms and relationships
 corresponding to sort and compositional dimensions   since the proposed ontological model
defines more relationships between concepts  essential  restrictive and descriptive   it is necessary
to add more knowledge  the cognos onto tool enables knowledge edition and management for
this specific model  this tool belongs to a larger toolkit  cognos  calle et al         already used
in several research projects  that toolkit seeks to ease the interaction corpus analysis  annotation 
implementation and management  through diverse yet integrated tools aimed to each specific type
of knowledge  pragmatic  nlp related  ontological etc   
   

fisemantic similarity measures applied to an ontology

    experimental design and preparation
first of all  it is necessary to choose an interaction domain which will define the entire
experiment  the concepts involved will be a subset of the whole knowledge base  restricted to
that specific domain  the participants will be chosen in order to constitute a good coverage of the
focused domain  finally  additional knowledge will be fed by experts in that interaction domain
not related to the projects where this research is framed  as the test subjects and any other
participant in the experiments  
the methodology chosen to evaluate the proposed similarity measure is based on millers
benchmark  miller   charles         experiments have been designed to determine whether the
result attained through the application of the similarity function on a pair of concepts is reliable
or  in other words  if the result falls within an acceptable range when compared with the similarity
judgments made by human test subjects 
to begin the experimental phase of the study  an initial loading of concepts must first be made
in the proposed ontology  for this reason  wordnets synsets  princeton univ         were taken
as concepts  together with the corresponding semiotics  sort and compositional relationships 
knowledge domain experts have been responsible for populating the remaining dimensions of the
ontological model  i e   the essential  restrictive and descriptive  in a subset of     concepts 
selected because of their relevance in the interaction domain 
the chosen domain is that labeled as computer science teaching interaction domain within
the spanish academic socio cultural environment  this area of knowledge is familiar to the test
subjects who have been selected as heterogeneous in this domain  different roles  ages  and
genders   to perform the evaluation  a test was designed for which the test subject had to rate the
similarity between pairs of concepts  the set of pairs had to meet a basic criterion  at least two
pairs had to be included to explore each of the proposed dimensions  one with clear incidence in
the dimension and another one without  or of little impact  
a total number of twenty one test subjects were available  from which four outliers were left
apart  they were discarded after checking their judgment because their responses were not
uniform with the rest of the sample  the participant scores follow a normal distribution after
removing the outliers  for that reason  the sample size was calculated through a test of statistical
significance and the result was at least ten subjects to ensure a     confidence  therefore  a
sample size of seventeen participants is sufficient to ensure that the data is representative the
seventeen subjects were all experts in the interaction domain  technical education   specifically
five technical students  seven researchers and five lecturers  their ages ranged from    to    and
were distributed as follows  seven subjects were in the       year old range  six in the      
year old range and the remaining four were in the       year old range  with regard to gender 
slightly more than half of them were female     and the rest were male      the chosen interaction
domain was the applied on the research project thuban  tin             each participant
was provided with a test containing a set of twenty pairs of concepts from this domain  since the
observations follow a normal distribution  it was determined that the minimum significant sample
size would be sixteen with     confidence  therefore  a set of twenty pairs of concepts provides
significant results  however  in a larger domain  the size of the dataset may be different to attain
   

fialbacete  calle  castro   cuadra

statistically significant results  in coherence with some other components of the system where this
proposal was to be integrated  the similarity measures are ranged from zero  no similarity  to ten
 absolutely identical  the same concept   in addition  for each of the pairs  the subjects were asked
to justify their score  indicating the specific parameters of similarity that they took into account in
making their decision after obtaining the individual survey results  the average total of the human
assessments for each pair of concepts was calculated table   shows the    pairs of concepts
included in the test and to the right of each pair  the range  difference between maximum and
minimum scores   the standard deviation and the average rating assigned by the users 
pair id

pair of concepts

range

standard
deviation

average
similarity

 

reading lamp  personal computer

 

    

    

 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  

laptop  server computer
teacher  tutorial
meeting room  laboratory
server computer microwave
office  laboratory
screen  blackboard
stapler  folder
plug power strip
office  meeting room
pencil  cd marker
associate professor  teaching assistant
associate professor  bachelor
to write papers  to program
to give a lecture  to teach
keyboard  mouse
fridge  microwave
hard disk drive  pendrive
scanner  printer
poster  blackboard

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    pairs of concepts and average similarity

all the methods are subject to the iteration order  either analyzed pair or human judge   which
can alter the result of the training  in order to avoid this effect and to endow significance to the
results  through preliminary experiments the minimum number of repetitions  with different
order  was determined to reduce stochastic and gain significance  close to       and consequently
it was decided to program     repetitions with a different order for each method  in the graphs
and tables  error rates of pairs  identified by pair id  are numbered from   to     while iterations
are numbered from   to    
    the experiments
this section presents the results obtained after the execution of the experiments corresponding to
the four weight adjustment algorithms described in section      these experiments were
   

fisemantic similarity measures applied to an ontology

performed on a subset of the ontological knowledge stored acquired from the computer science
teaching domain  the first experiment performed was the pair oriented training and  in order to
evaluate the results of this training  the average of the absolute error was calculated  for each pair 
between the similarity based on each human judgment and the result obtained by applying the
similarity measure proposed according to the following formula 

where i corresponds to an index to iterate over each human judge for a specific pair of
concepts and n is the number of test subjects  finally  errorpairid represents the absolute error
between the human judgment for that pair and the result obtained through the training algorithm
in that iteration  table   shows the absolute errors calculated in this experiment for each pair of
concepts  as well as the average error which  at about       comes slightly closer to the scores
provided by the human subjects 
pair id
 

 

 

 

 

 

 

 

 

 

  

  

  

  

  

  

  

  

  

  

avg

error                                                                                                             

table    pair oriented training error rate

it should be noted that in eleven cases  the error rate is less than the average  in eight cases the
error rate is around the average  and one pair      shows an excessive error rate that requires
further analysis and discussion  see subsection       figure   shows a comparison of the trend
lines regarding the error rate accumulated by the pair oriented training algorithm and the
accumulated error by the similarity function without weights training 

figure    accumulated average error in pair oriented training

in second place  the absolute error obtained for each pair in the feature oriented training is
shown in table    these results  compared with those obtained for the pair oriented training 
show slightly worse performance  with a mean error rate of         however  it should be
recalled that this method has other advantages  realistic storage and training extent  
   

fialbacete  calle  castro   cuadra

pair id
 

 

 

 

 

 

 

 

 

 

  

  

  

  

  

  

  

  

  

  

avg

error                                                                                                             

table    feature oriented training error rate

the third experiment executed was the user oriented training  in order to evaluate the results
of this experiment  the average of the absolute error was calculated  for each human judge 
between the similarity based on each human judgment for the    pairs of concepts and the result
obtained applying the similarity measure proposed  in this way  the error average has been
calculated as follows 

where i corresponds to an index to iterate over each pair of concepts for a specific user  n is
the number of pairs of concepts and errorpairid represents the absolute error between the human
judgment for that pair and the result of the training algorithm in that iteration 
in this case  the average error rate achieved is        even worse than that for the featureoriented training  the absolute error rate obtained for each iteration is shown in table   
pair id
 

 

 

 

 

 

 

 

 

 

  

  

  

  

  

  

  

  

  

  

avg

error                                                                                                             

table    user oriented training error rate

figure    shows a comparison of the trend lines correspondent to the error rate accumulated
by the user oriented training algorithm and the accumulated error without any weight training  as
can be observed  the user oriented training trend line follows a downward curve and after   
iterations reaches an error rate of        comparing both trend lines  it can be concluded that this
training decreases the accumulated error and adapts the calculated similarities to the subjects
judgments  yet it would be desirable to improve that adaptation  since it is still far from featureoriented training  

figure     accumulated average error in user oriented training

   

fisemantic similarity measures applied to an ontology

as observed  both the user oriented and the feature oriented training methods are able to
improve the similarities calculation  becoming noteworthy approaches  consequently  it has been
found of interest to explore a method which combines both of them  this new hybrid method
departs from the user oriented approach  and takes into account the weights vector obtained from
the feature oriented training described in section      as shown in table    the user error rate has
been successfully reduced to       with respect to the user oriented training  however  this
method degrades the performance achieved by the feature alone method 
pair id
 

 

 

 

 

 

 

 

 

 

  

  

  

  

  

  

  

  

  

  

avg

error                                                                                                             

table    user feature hybrid training error rate

    discussion of results obtained
among the results  concept pair    teacher tutorial  scored an error rate above     and the
average similarity assigned by users  see table    was       this latter value is significantly high
considering the fact that the first concept refers to a person and the second is a static entity 
reviewing participant responses to this question  however  it can be understood that test subjects
gave a higher score to the sole feature the concepts have in common  the activity of teaching 
analyzing the results of this outlier  it appears that the algorithm has a tendency to gradually
increase the weight of the restrictive dimension  but longer training will be necessary to adapt the
weight vector so that the only relevant dimension is the restrictive one  using a training algorithm
with faster convergence would ensure a good result in this pair  but could adversely affect the
other results  however  convergence is guaranteed with a larger number of users 
figure    shows the comparison of the absolute error obtained in the four experiments
performed in this work  pair oriented  user oriented  feature oriented and hybrid trainings  for
each pair  and also the average results of each method  the first experiment performed  the pairoriented training  achieves the best average error rate  about        although in the pair
mentioned above the error exceeded      however  this experiment has a major limitation  a
trained weight vector for each pair of concepts possible cannot be stored due to the large number
of combinations of existing concepts in the ontology  this shortcoming was mitigated with the
development of the feature oriented training  achieving an error rate about        a figure which
is slightly worse than that of the pair oriented training error  nevertheless  this result does not
fully reflect the impact of this training because not all test pairs include concepts that appear more
than once in the experiment  if the calculation of the average error is restricted to those pairs
which have concepts repeated in more than one pair  then the error amounts to        in any
case  this experiment has an important advantage since its implementation is more realistic and
can be applied to large ontologies 
the user oriented training was aimed at adapting the weights to each subject in order to
confirm the assumption that not every test subject assigns the same value to all dimensions 
although the error rate achieved         was not as satisfactory as either the pair or the feature   

fialbacete  calle  castro   cuadra

oriented trainings  the figure included in the sub section     for the training shows a decreasing
trend line which  when compared with the trend line without training  allows for the conclusion
that the user oriented experiment is able to adapt to each individual judgment  for this reason  an
improvement was attempted with the user training result through its combination with the
feature oriented experiment 

figure     comparison of the experiment results

the hybrid training detailed in section     achieved       in the error rate  which reduces
that of the user oriented training  and balances the performance of the user oriented method
 reduces standard deviation   taking into account that feature oriented training method depends
on the experience and that for some features the knowledge base might lack of this experience 
the response obtained could not be satisfactory in some cases  in fact  when calculating the error
produced by the feature oriented method over the dataset  not restricted to repeated pairs  the
result amounted to        in sum  the feature oriented method provides better results but only if
enough knowledge is available  the last results presented in figure    concern an experiment
observing only the sort dimension  which is a frequent method for calculating similarities   its
average error rate is        which is higher than that for any of the four methods discussed  in
addition  it can be observed that the error rate of this experiment is  in several cases  far from the
average error  figure    shows a boxplot comparing the performance of the four training methods
proposed and the sort dimension formula 
   

fisemantic similarity measures applied to an ontology

   

error    

  
  
  
  
 
pair

feature

user

hybrid

sort

figure     performance of each training method

as can be seen  regarding the error in the predictions  the sort dimension obtains higher
maximum  although also lower minimum   higher median  except for user training  and higher
deviation than the rest  from this graph  it can be concluded that the error rate achieved by the
sort dimension method  used in previous studies of similarity  is greater than the error rate
achieved by the feature training method  in order to check that statistically  a null hypothesis was
formulated  the average error is the same in both methods  and also an alternative hypothesis   the
average error of the feature oriented method is lower than the sort dimension method error   the
measure of discrepancy has been calculated for the sample of twenty measures of error  one per
pair  and the result         was found to be outside the acceptance range             therefore the
null hypothesis is rejected and the alternative is accepted with a significance level of      
consequently  it is considered true that the error shown by the feature oriented method is lower
than the error produced by the sort dimension method 
finally  figure    shows the average final weights of the four experiments  it shows the
relevance taken through the experiments by each dimension  yet it cannot be extrapolated to other
interaction domains  while dependent on the set of pairs chosen for the experiment  these results
show that how all five dimensions are taken into account  with diverse weights 
descriptive
   

sort    

restrictive
   

compositional
   

essential    

figure     average weights of the ontological dimensions

   

fialbacete  calle  castro   cuadra

   conclusions and perspective for future research
this paper defines a similarity measure for a multi dimensional knowledge model of the ontology
type  specifically an ontology aimed at supporting human like interaction  the proposed
measure is based on five dimensions of ontological knowledge  sort  compositional  essential 
restrictive and descriptive  the five of them are weighted and aggregated in order to obtain a
global similarity measure  the equations applied for each dimension are general and can be used
with other ontologies that observe any of these dimensions  yet observing all of them and
aggregating their similarity result is here proposed for enhanced accuracy 
this solution presents another challenge  in the form of those weights calculation  in fact 
when a person decides the similarity between concepts he unwittingly makes some dimensions
prevail over the others  the criteria may be diverse  and this work has focused on studying the
dependence of these weights on the nature of concepts  either in pairs  pair training method  or
individually  feature training method   both described in section      but this work also explores
the influence of the past behavior of users who perform the concept pair evaluations  and
ultimately  the user who owns a device or usually interacts with it   following this line  a userdependent training is proposed  and finally a hybrid one  merging feature and user benefits  is
included too  all of them have been evaluated and compared in order to ascertain which one
performs better  obtaining the best results for the pair oriented training 
in order to evaluate the performance of the proposed similarity measure  its results were
recorded and compared with those taken from human test subjects  this evaluation technique has
been applied in several studies about similarity measures and is considered the gold standard  in
the experimental phase  four training algorithms were developed according to different
perspectives  thus  this phase included a pair oriented  a feature oriented  a user oriented and a
hybrid experiment  in every case  the error rate was calculated with respect to the human subject
assessments  the best results corresponded to the pair oriented method which achieved an error
rate of        since the implementation of this experiment is not realistic with large ontologies  a
feature oriented experiment was required despite slightly worsening the results from the previous
experiment  concretely  producing an error rate of        however  the feature oriented
experiment has the big advantage of being able to be applied easily to large ontologies 
moreover  the user oriented training aimed to adapt the weights to each subject in order to
confirm the assumption that not every test subject assigns the same value to all dimensions  while
this experiment had the highest error rate of all the algorithms          as has been demonstrated 
the error rate follows a decreasing trend line while  if training is not done  the error rate follows
an asymptotic tendency  in addition to this  this experiment shows slightly better results than
taking into account only the sort dimension  which has an average error rate of       and
maximum         for this reason  it can be concluded that the user oriented experiment is able to
adapt to each individual judgment  although this adaptation is very slow   finally  the hybrid
experiment combines the feature oriented and the user oriented training and  with an error rate of
       nevertheless manages to reduce the error of the user oriented training  as well as
balancing the error in the atypical cases common to the rest of the experiments 

   

fisemantic similarity measures applied to an ontology

since the hybrid experiment manages to balance the results of the other experiments 
currently  an improved hybrid algorithm is being developed  in this algorithm the calculation of
the weights of each iteration will be affected depending on the error produced in the feature
experiment for the pair of concepts corresponding to that iteration 
the performance of the training methods proposed is closely related to the available extent of
knowledge  for this reason  authors are also currently working on mechanisms for increasing the
quality and completeness of the ontological knowledge  the manual acquisition of new
knowledge by an expert requires a great deal of resources and it would be desirable to develop an
advanced mechanism to learn new concepts and relations  the challenge is to attain that
knowledge acquisition through human like interaction with human subjects  therefore  through
the lifetime of the system  the knowledge bases would be enriched by interacting with the users 
finally  refinement of similarities formulation is also an interesting line of work  especially in
the semiotic dimension for reintroducing its influence in the global similarity calculation 

acknowledgments
the development of this approach and its construction as part of the labda interactor humanlike interaction system  part of the research projects semants  tsi                  and
thuban  tin            and cadooh  tsi                  is supported by the spanish
ministry of industry  tourism and commerce and the spanish ministry of education 
respectively  besides  the knowledge bases were populated using the cognos toolkit developed
through the research project ma vicmr  s     tic       supported by the regional
government of madrid 

references
altintas  e   karsligil  e     coskun  v          a new semantic similarity measure evaluated in
word sense disambiguation  procs  of the   th nodalida conference  joensuu 
bernstein  a   kaufmann  e   kiefer  c     brki  c          simpack  a generic java library
for similarity measures in ontologies  zurich  technical report 
budanitsky  a          lexical semantic relatedness and its application in natural language
processing  university of toronto  technical report 
calle  f          interaccin natural mediante procesamiento intencional  modelo de hilos en
dilogos  thesis   phd   politecnic university of madrid 
calle  f  j   albacete  e   snchez  e   del valle  d   rivero  j     cuadra  d          cognos  a
natural interaction knowledge management toolkit  international conference on
applications of natural language to information systems  nldb        pp           
saarbrken  germany  lecture notes in computer science 
calle  f   castro  e     cuadra  d          ontological dimensions applied to natural interaction 
procs  of the first international workshop on ontologies in interactive systems          

   

fialbacete  calle  castro   cuadra

department of genetics  stanford university school of medicine  california  usa          gene
ontology  tool for the unification of biology  the gene ontology consortium  nature
genetics vol      no             
fellbaum  c          wordnet  an electronic lexical database  cambridge  uk  the mit press 
gee  j p          introduction to discourse analysis  routledge 
inkpen  d          semantic similarity knowledge and its applications  studia univ  babesbolyai  informatica  volume lii          
jiang  j  j     conrath  d  w          semantic similarity based on corpus statistics and lexical
taxonomy  in international conference research on computational linguistics  taiwan 
cognos toolkit          retrieved july       from
http   labda inf uc m es doku php id es labda lineas cognos
rita wordnet  a wordnet library for java processing           online   available 
http   www rednoise org rita wordnet documentation 
leacock  c     chodorow  m          combining local context and wordnet similarity for
word sense identification  an electronic lexical database           
levenshtein  v  i          binary codes capable of correcting deletions  insertions and reversals 
soviet physics doklady vol              
lin  d          an information theoretic definition of similarity  proceedings of the   th
international conf  on machine learning   pp            madison  wisconsin usa 
lord  p  w   stevens  r  d   brass  a     goble  c  a          investigating semantic similarity
measures across the gene ontology  the relationship between sequence and annotation 
bioinformatics             
miller  g  a     charles  w  g          contextual correlates of semantic similarity  language
and cognitive processes        
miller  g  a          wordnet  a lexical database for english  communications of the acm vol
    no            
pedersen  t   patwardhan  s     michelizzi  j          wordnet   similarity measuring the
relatedness of concepts  demonstration papers at hlt naacl       pp          boston 
massachusetts  usa  association for computational linguistics
princeton univ   february           wordnet  a lexical database for english  obtenido de
wordnet  a lexical database for english  http   wordnet princeton edu 
rada  r   mili  h   bicknell  e     blettner  m          development and application of a metric
on semantic nets  ieee trans  on systems  man  and cybernetics              
resnik  p          semantic similarity in a taxonomy  an information based measure and its
application to problems of ambiguity in natural language  journal of artificial
intelligence research          
resnik  p          using information content to evaluate semantic similarity in a taxonomy 
ijcai    proceedings of the   th international joint conference on artificial intelligence
 pp           san francisco  usa  morgan kaufmann publishers inc 
   

fisemantic similarity measures applied to an ontology

richardson  r   smeaton  a  f     murphy  j          using wordnet as a knowledge base for
measuring semantic similarity between words  proceedings of aics conference 
dublin  ireland  technical report 
schickel zuber  v          oss  a semantic similarity function based on hierarchical ontologies 
ijcai    proceedings of the   th international joint conference on artifical intelligence
 pp            san francisco  ca  usa  morgan kaufmann publishers inc 
seco  n   veale  t     hayes  j          an intrinsic information content metric for semantic
similarity in wordnet  ecai       the   th european conference on artificial
intelligence   pp              valencia  spain  
wu  z     palmer  m          verb semantics and lexical selection  acl    proceedings of the
  nd annual meeting on association for computational linguistics  pp           
stroudsburg  usa  association for computational linguistics 

   

fi