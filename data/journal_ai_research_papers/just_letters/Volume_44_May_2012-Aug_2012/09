journal artificial intelligence research                  

submitted        published      

modelling observation correlations active exploration
robust object detection
javier velez
garrett hemann
albert s  huang

velezj mit edu
ghemann alum mit edu
ashuang mit edu

mit computer science artificial intelligence laboratory
cambridge  ma  usa

ingmar posner

ingmar robots ox ac uk

mobile robotics group
dept  engineering science  oxford university
oxford  uk

nicholas roy

nickroy csail mit edu

mit computer science artificial intelligence laboratory
cambridge  ma  usa

abstract
today  mobile robots expected carry increasingly complex tasks multifarious  realworld environments  often  tasks require certain semantic understanding workspace 
consider  example  spoken instructions human collaborator referring objects interest  robot must able accurately detect objects correctly understand instructions 
however  existing object detection  competent  perfect  particular  performance
detection algorithms commonly sensitive position sensor relative objects
scene 
paper presents online planning algorithm learns explicit model spatial
dependence object detection generates plans maximize expected performance
detection  extension overall plan performance  crucially  learned sensor model
incorporates spatial correlations measurements  capturing fact successive measurements taken nearby locations independent  show sensor
model incorporated efficient forward search algorithm information space
detected objects  allowing robot generate motion plans efficiently  investigate performance approach addressing tasks door text detection indoor environments
demonstrate significant improvement detection performance task execution alternative methods simulated real robot experiments 

   introduction
years steady progress mapping navigation techniques mobile robots made
possible autonomous agents construct accurate geometric topological maps relatively
complex environments robustly navigate within  e g   newman  sibley  smith  cummins  harrison  mei  posner  shade  schroeter  murphy  churchill  cole    reid         lately 
mobile robots begun perform high level tasks following natural language
instructions interaction particular object  requiring relatively sophisticated interpretation agent workspace  recent literature therefore focuses augmenting
c
    
ai access foundation  rights reserved 

fiv elez   h emann   h uang   p osner   roy

 a 

 b 

figure    traditional geometric environment map  a  represented simple two dimensional
occupancy grid regions free space  cyan   red  useful navigation
localization   b  geometric map augmented semantic information
identity  structure location objects world allowing richer interactions
agent workspace 

metric maps higher order semantic information location identity objects
workspace  see fig     
end  advances vision  laser based object detection recognition
leveraged extract semantic information raw sensor data  e g   posner  cummins   
newman        douillard  fox    ramos        martinez mozos  stachniss    burgard       
anguelov  koller  parker    thrun         commonly  output detection system
accepted prima facie  possibly threshold estimated sensor error  consequence
directly using results object detector quality resulting map strongly
depends shortcomings object detector  vision based object detection  example 
oftentimes plagued significant performance degradation caused variety factors including
change aspect compared encountered training data  changes illumination and 
course  occlusion  e g   coates   ng        mittal   davis         aspect occlusions
addressed naturally mobile robot  robot choose location sensors carefully
acquiring data performing object detection  thereby improving robustness
detection process specifically counteracting known detector issues  rather placing burden providing perfect detections detector itself  robot act improve perception 
rarely  however  ability mobile robot actually exploited building semantic map 
paper  present online planning algorithm robot motion explicitly incorporates model performance object detector  primarily address problem
context robot exploring unknown environment goal building map accurately
labeled location semantic objects interest here  particular  consider doors
textual signs  however  approach applied problem robot must plan
trajectories depend location objects landmarks interest environment 
show planning approach weighs benefit increasing confidence potential
semantic entity cost taking detour succession suitable vantage point 
fig    gives cartoon illustration problem  robot encounters possible new object
   

fim odelling bservation c orrelations f robust bject etection

 a 

 b 

 c 

figure    conceptual illustration  a  robot viewpoint x following original
trajectory  bold line  towards goal  red star    b  perception field particular
object detector centered around object hypothesis   c  alternative path  bold
dash dotted line  along informative route  cell shadings indicate relative value
observations taken cell terms mutual information  lighter values
indicate lower mutual information therefore desirable vantage points  challenge
learning mutual information varies spatially  capturing
mutual information cell changes new measurement 

executing path goal  based expected information available possible vantage
points  robot may decide original path provided accurate model object 
may choose modify path reduce possibility errors object model 
make two primary contributions paper  firstly  describe new sensor model
uses mixture gaussian processes model performance object detection system function robots relative position detected features learn
online model sensor measurements spatially correlated  typical estimation planning algorithms assume sensor measurements conditionally independent given
knowledge robots position  assumption clearly incorrect properties environment introduce strong correlation sensor measurements  rather estimate
possible hidden variables capture full sensor model preserve conditional independence 
explicitly model spatial correlation measurements use correlation model estimate mutual information measurements taken different locations  use
mutual information bias random sampling strategy trajectory generation
evaluate expected cost sampled trajectory  secondly  show incorporate
learned sensor model forward search process using posterior belief distribution  pbd 
algorithm  he  brunskill    roy              perform computationally efficient deep trajectory
planning  pbd approximation allows us compute expected costs sensing trajectories
without explicitly integrating possible sensor measurements 
work first result actively controlling sensor improve accuracy 
previous work largely ignored motion cost typically assumed observations conditionally independent given sensor position  inspired recent progress forward search
planning uncertainty  demonstrate system allows us efficiently find robust observation plans  paper builds previous work presented icaps       velez  hemann 
huang  posner    roy        provides several substantial extensions  specifically  describe
significantly richer sensor model  extend approach improved planning algorithm ad   

fiv elez   h emann   h uang   p osner   roy

dress additional object interest human readable text  demonstrate overall approach
using real robot well simulation studies 
exposition begins problem formulation planning trajectories improve object
detection section    section   describe specific sensor model characterize
sensor models using mutual information  section   gives two different approaches learning
sensor models vary spatially  observations correlated spatially  describe
planning algorithm sensor model incorporated system section   
follow description implementation efficient planning using sensor models
section    section   describes object detectors used results  section   shows simulation
results approach improves object detection compared approaches section  
shows performance system real world trials  sections       conclude
discussion related work future directions 

   problem formulation
consider robot following particular trajectory towards goal environment objects
interest unknown locations  example  rescue robot looking people first responder
scenario  traditionally  object detector used waypoints along trajectory
detection either accepted map rejected based simple detector thresholds  however 
lack introspection approach regarding confidence object detector
quality data gathered lead unnecessary acceptance spurious detections 
systems simply discard lower confidence detections way improve estimate
further  targeted measurements  contrast  would robot modify motion
minimize total travel cost cost errors deciding whether add newly observed
objects map 
let us represent robot point x r  so     so    denotes special orthogonal group representing orientation r  represents location  d euclidean space  without
loss generality  express robot trajectory set waypoints x  k   associated
motion cost cmot  x  k   sum total travel waypoints x  xk   robot
prior map environment planning path pre specified goal  computing
minimum cost path x  k well understood motion planning problem 
robot moves  receives output object detector gives rise belief
whether detected object truly exists location indicated    model presence
ith object location  ui   vi   random variable yi  object  no object   system
runs  object detector fire give rise objects yi given locations system
must reason qualify either genuine objects false firings object
detector 
let us define decision action ai  accept  reject   detected object either accepted
map  the detection determined correspond real object  rejected  the detection
determined spurious   let us define cost dec     accept  reject  object  no object    
r correct incorrect accept reject decision  cannot know true cost decisions
 ai   ultimately know true state objects environment  therefore
   assume robot knows location  sufficiently well calibrated camera determine location
object map  work  uncertainty whether object specific type present
given location  u  v  

   

fim odelling bservation c orrelations f robust bject etection

infer distribution state object p y  generate plan minimize expected
cost e dec   individual decision actions given distribution objects 
formulate planning problem choosing plan   comprised sequence waypoints
decision actions     x  k a  q   path length k q hypothesized objects
minimize total travel cost along trajectory expected costs decision actions
end trajectory  optimal plan given

  arg min cmot  x  k     cdet  x  k   a   
   
x  k  a



cdet  x  k   a    ey x  k dec  a  y   

   

ey x  k    denotes expectation respect robots knowledge regarding object 
y  executed path x  k   number hypothesized objects  q  number possible objects detector fired traversing entire trajectory known beforehand 
note planning problem computing often formulated partially observable
markov decision process pomdp  sondik        kaelbling  littman    cassandra        
pomdp representation grow combinatorial complexity presence multiple
detections  furthermore  pomdp solutions assume stationary markov model parameters 
sensor model non stationary explicitly non markov want represent
environmental features needed support non markov sensor model  since approach
uses sensor model adapts successive observation  new pomdp model would
need constructed solved observation  lastly  explicit pomdp model would
require plan take account possible observations robot might encounter carries
motion trajectory  precisely  expected cost plan must computed respect possible observations objects  rather object distributions  avoid
resulting computational complexity using forward search algorithm similar forward search
approximation techniques solving pomdps  ross  pineau  paquet    chaib draa        
known scale well presence complex representations  avoid explicitly computing observation distribution planning use approximation technique
known posterior belief distribution  pbd  algorithm  adapted sensor model 

   sensor model object detection
order compute expected cost decision actions  must estimate probability objects existing world given observations might see executing motion plan 
therefore require probabilistic model object detector allows us infer distribution object given measurements  p y z   know sensor characteristics vary
robot moves around object interactions environment  hence make
relationship explicit writing posterior p y z  x  include viewpoint x 
furthermore  measurement  z  taken particular viewpoint x consists output
object detector  assumed real number indicating confidence detector
object exists  distribution range confidence measurements dependent
particular object detector captured random variable z defined continuous
range  zmin   zmax    every waypoint x posterior distribution expressed
p y z  x    r

p z y  x p y 
 
yy p z y  x p y 
   

   

fiv elez   h emann   h uang   p osner   roy

 a 

 b 

 c 

figure    different graphical models representing observation function   a  naive bayes
approximation assumes every observation z conditionally independent given
knowledge object y   b  true model assumes observations independent given knowledge environment object y   c  model
employed here  correlations approximated way mixture model
input space waypoints  x r  so      equ     

p z y  x  denotes likelihood  every possible state   observing particular
detector confidence x   the expression would seem require p y x   independent
waypoint measurement z received  
    observation model
observations z directly produced physical device  camera  often treated
conditionally independent given state robot  see fig   a   however  observations
independent given knowledge current state  fact independent given
state environment shown fig    b   one  or both  variables
unknown  measurements longer first order markov fact correlated 
seen intuitively noting robot stationary  aimed static scene 
would expect response object detector successive images independent 
anticipate observations object detector extremely correlated  expectation
new information would gained handful images 
correct observation model maintain history observations  waypoints
visited  knowledge regarding object integrated recursively  let k denote trajectory
k waypoint observation pairs obtained sequence k     x    z       x    z               xk   z k    
knowledge gained step along trajectory integrated posterior distribution


k

k    xk   z k   k   

   

k

   

k

k

p y z   x     p y z   x  
 

k 

  

p z k  y  xk   k   p y t k   
 
p z k  xk   k   

   

z k k th observation  depends current waypoint
history measurements waypoints k    denominator equ    serves moderate
   

fim odelling bservation c orrelations f robust bject etection

influence measurement likelihood posterior based correlations existing
observations taken along trajectory 
difficulty model equ    sensor model p z k  y  xk   k    difficult
arrive at  depending history measurements  furthermore  k arbitrarily
large  need model predicts observations given infinite history observations 
describe new sensor model section   
    perception fields
developing new sensor model  first need way examine sensor model
captures effect measurements posterior belief object y  use reduction
uncertainty relative current belief next observation  given waypoint xk
trajectory k  visited thus far  reduction uncertainty captured mutual information
object state observation z k received xk
i y  z k   xk   k     
h y   k    h y  z k   xk   k    

   

h y   k    h y  z k   xk   k    denote entropy conditional entropy  respectively  we drop xk entropy since distribution independent robot
xk without corresponding observation z k    thus  h y   k    expresses certainty current belief whether object exists given trajectory thus far  unswayed
new measurements  every time step  term constant every waypoint considered
therefore disregarded  conditional entropy equ    expanded terms posterior state hidden variable given previous trajectory k  additional
measurement taken xk   p y z k   xk   k     c f  equs        likelihood z k taking
particular value conditioned trajectory thus far whether object viewed xk
present not  p z k  xk   k    
h y  z k   xzk   k     



p z xk   k   h y  z  xk   k     

   

z

 z  xk   k    computed using sensor model p y z k   xk   k    given equ    

h y
function belief traversing waypoint observation trajectory k  
expected reduction uncertainty given conditional entropy values waypoints
robots workspace form perception field  particular object hypothesis  see fig    b   
use perception field induces sensor model two ways  firstly bias search
informative path  secondly part evaluation expected cost path 

   correlation models
described previously  conventional first order markov sensor models correctly represent
effect successive observations implicitly correlated unmodelled environmental
   reduction position uncertainty robot observations across environment sometimes known
sensor uncertainty field  takeda   latombe        active localization  since application object detection 
use term perception field avoid confusion localization problem  concepts otherwise
identical 

   

fiv elez   h emann   h uang   p osner   roy

variables  images used object detector conditionally independent correlated
environment   robot position scene stationary  probability
individual pixel values successive images strongly correlated shared environmental
representation robot position  varying sensor noise  subsequently  object detector
responses strongly correlated  however  correctly representing observations way
requires environmental model sufficient capture image generation process  intractable
computational modeling burden  image based object detectors detectors
exhibit dependence environment  object detector utilizes properties
environment  geometric otherwise  generate detections cannot priori treated producing
conditionally independent observations given state robot  correctly representing
full generative model object detection takes account environmental properties used
detector frequently intractable task 
overcome difficulty  approximate real process object detection simplistic
model images correlated  replace influence environment correlations observations convex combination fully independent model
depend history observations  correlated observation model depend
history observations  treat whether particular observation correlated previous
observation random variable  new posterior belief state world computed

k
p z k  y  xk   k      p z k k   p zind
 y  xk  
k
     p z k k    p zcorr
 y  xk   k    

   

marginalized whether observation z k actually independent
previous observation not  use notation b represent event independent
b  factorizing likelihood way  equ     allow us capture intuition
repeated observations similar waypoints add little robots knowledge state
world treated correlated  observations afield  however  become
increasingly independent  less correlating effect 
order complete sensor model uses factorization equ     need construct model independent correlated likelihoods well model probability
particular detection independent previous detections  following sections describe
two different approaches modeling likelihood functions probability independent
detections 
    static disc model
first sensor model called static disc sensor model  coarse  assuming
measurements drawn according either learned first order markov model according
nearest previous observation 
k  y  xk approximated using histogramthe distribution independent detections zind
based detector performance labeled training data  is  training data collected placing
robot waypoint grid around training object facing object  robot collects
series images waypoint  generates histogram object detection confidences
waypoint collected images  histogram gives probability measurement z k specific  relative  waypoint xk   contrast  correlated detection model assumes
   

fim odelling bservation c orrelations f robust bject etection

 a  perception field observations

 b  perception field one observation  disc model

figure    perception field possible door using static disc sensor model  unknown
object center  blue  looking towards right  brighter regions correspond
waypoints likely result higher confidence posterior beliefs  observations
taken robot denoted location  magenta  oriented point sensor
directly object 

measurements fully correlated always equal closest  in x  previously seen observation  described equ    treat probability observation independence mixing
parameter  disc express truncated linear function euclidean distance  d 
two viewpoints  distribution normalized respect maximum distance dmax   beyond
observations treated fully independent  thus 

k
k 
dmax   dmax
    
p z

    disc  
 
dmax
words  information gained taking additional measurements waypoint
information content observations increases linearly distance previous ones 
reference equ     model results belief update 


k  y  xk  
p zind
k
p y t     disc
    disc   p y t k    
    
k  xk  
p zind
   

fiv elez   h emann   h uang   p osner   roy

fig    shows two example perception fields object detector trained doors  see section  
training process   fig    a   see highly informative measurements directly
front door   m   m  fig    b   see change perception field
observation  mixture parameter static disc model  disc   dmax value
empirically chosen   meters 
    dynamic time varying correlation model
static disc model shown previous section allow sensor model change
according data actively seen trajectory  purpose introducing correlation
model capture effect environment object detector  object detectors
response individual object appearances captured dependence  for example  door
detector may different behavior detecting highly reflective glass doors versus solid oak
doors   however  static disc model assumes fixed correlation model sensor model
objects particular class  regardless changes detectors response across individual
instances object class  previous model assumes strong  truncated 
linear relationship probability two observations correlated distance
two observations  would relax assumption order better model broad
range object detectors  second sensor model solves aforementioned issues
static disc model  allows time varying correlations observations taken
object  sensor models make use factorization equ     differ models
k  y  xk   p z k  y  xk   k    well structure
used detection likelihoods p zind
corr
p z k k    
would mechanism learning correlation measurements
depend potentially infinite number previous measurements  use gaussian
process  gp  model independent correlated sensor models  gaussian process
collection random variables  finite number joint gaussian distribution 
completely specified mean function covariance function  rasmussen   williams        
use gp regression likelihood models always use zero mean function  
squared exponential  se  variance function following structure 
   scalei    xx     

se x  x      sigma e xx  

 

    

use notation sei  x    mean kernel sei function x parameterized
 
      ndependent c orrelated l ikelihood odels
order model independent observations use gaussian process  gp ind   zero mean function squared exponential covariance function described above  kernel parameters  ind  
learned training data pairs waypoints x observations z described section       
gp takes input particular waypoint x predicts detector output z waypoint 
letting train set labeled waypoint observation pairs used gp ind   observation model
independent observation becomes
k
k
zind
 y  xk   k    zind
 y  xk

gp ind     seind  t train   xk   ind    
   

    

fim odelling bservation c orrelations f robust bject etection

see model depends solely training data provide prediction 
similar independent model use gaussian process  gp corr   zero mean function learned se kernel correlated observation model  equ      trained model nonindependent observations object detector  kernel parameters  corr   learned
training data described section        let corr train set waypoint observations pairs
used train gp corr   but  gp corr uses training data learn kernel parameters makes
predictions data acquired current trajectory k  far  results
following correlated observation model 
k
zcorr
 y  xk   k  gp corr     secorr  t k    xk   corr    

    

unlike independent model gp predicts using training data  equ       correlated
model gps predictions based solely data observations taken current object rather
k  y  xk   k  using
observation histories objects  predicting likelihood zcorr
gp regression marginalizing previous trajectory observations results
normal distribution 
k
 
zcorr
 y  xk   k  n  corr k   corr k
  

    

choice model independent correlated observations using gps results
overall observation model simplifying mixture two gaussian distributions 
 
  
z k  y  xk   k  n  obs   obs

    

      ixture parameter p roxy ndependence
reason factor likelihood independent model correlated model capture intuition nearby observations correlated therefore less informative 
require baseline model observations remaining robot waypoints  model
probability observation independent  p z k k    equ     treating
time varying spatial mixture parameter   mixing parameter chosen function
variance correlation model estimate 
 

p z k
k      p z k
k   xk   k       xk   k        ecorr k  

    

using se kernel function gp corr   know variance prediction
corr k function input space distance independent actual prediction value
 rasmussen   williams         note gp corr function current trajectory
world  k    current waypoint xk function training data corr train  
variance estimate gp corr function distance waypoints
observations taken far particular object  encodes intuition observations
similar waypoints correlated  fact  current waypoint approaches previous
k  y  xk   k  approaches       means
observation waypoints  variance zcorr
trust correlated observation model independent model  similarly  distance
current waypoint previous observation waypoint becomes large   
trust independent observation model almost exclusively  words  little information
gained taking additional measurements waypoint information content
observations increases distance previous ones 
   

fiv elez   h emann   h uang   p osner   roy

shown fig    c   remove add dependency previous waypoints
current observation z k   use pair gps model spatial time varying properties
correlations observation sequence object detector 

 a  learned perception field first
observation 

 b  learned perception field third
observation 

figure    learned perception field door detector  a  first observation  b  third observation   b   previous observations  shown magenta  shift expect
informative vantage points be  panels  unknown object centered
origin facing right  brighter regions correspond waypoints likely result
higher confidence posterior beliefs  observations taken robot denoted
location  magenta  oriented point sensor directly object 

      raining ensor odels
dynamic time varying observation model consist mixture two gaussians  see equ      
modeled using two gaussian processes  gp ind gp corr   every object hypothesis  gaussian process maps locations  x  resulting object detection score
z  every object detector system observation model  independent observation likelihood gps trained using available training data  labeled tuple
 z  x     object  no object   used independent sample fed independent gp corresponding labeled object state   object  no object    training
samples used learn se kernel independent gp models  way learn
model detector output likelihood cases object truly existed not  assuming independent observations  two gps shared across objects constant
measurements 
correlated observation model gps learned se kernel use
different data  se kernel trained data object since trying
learn model correlated detections  split training data set subsets cor   

fim odelling bservation c orrelations f robust bject etection

 a  learned perception field first
observation 

 b  learned perception field third
observation 

figure    learned perception field text detector  a  first observation  b  third observation   b   previous observations  shown magenta  shift expect
informative vantage points be  panels  unknown object centered
origin facing right  brighter regions correspond waypoints likely result
higher confidence posterior beliefs  observations taken robot denoted
location  magenta  oriented point sensor directly object 

respond objects  se kernel parameters chosen maximal likelihood
parameters set subsets  however  kernel parameters learned  correlated model gps initially devoid data  two correlated model gps instantiated
per object basis shared across objects  samples added runtime
robot actively observes detector outputs world  such  correlated model gps track
current set waypoints observed particular object  whereas independent model gps
track training samples since treated independent 
using learned dynamic time varying sensor model derived initial perception field
door shown fig    a   fig    b  shows perception field several observations
taken around door  notice expected amount information significantly
decreased around observed points farther waypoints may still yield useful observations 
initial perception field shows areas high expected information gain observation
according training samples particular object detector  since previous
observations  initial perception field shows use learned independent gaussian process
object detector 
derived perception field text sign shown fig    a   experimentally  truncated
text perception field waypoints aspect    degrees object
   

fiv elez   h emann   h uang   p osner   roy

computational efficiency  given detector fire viewing signs obtuse
angles training data  fig    b  shows perception field several observations
taken around object  notice text detector significantly different perception
field door detector  initial shape well response observations  see
door detector peaks within perception field  signifying regions relatively high
information gain  text detector  hand  smooth perception field
drops mainly function depth 

   planning perceive
given sensor model described previous section  describe planning algorithm
trades necessity gaining additional information object hypothesis
operational cost obtaining information  particular  object first detected  new
path original goal planned based total cost function includes motion
cost cmot along path value measurements waypoints along path expressed
reduction expected cost decision actions  recall cost function consists two
terms  motion cost cmot  x  k   decision cost cdet  x  k   a   optimal plan
given equ     reproduce here 

  arg min cmot  x  k     cdet  x  k   a   
x  k  a



cdet  x  k   a    ey x  k dec  a  y   

ey x  k    denotes expectation respect robots knowledge regarding object 
executed path x  k  
    motion cost
path cost  cmot  x  k    encompasses operational considerations power expended
time taken moving along particular trajectory typically proportional length
trajectory 
    decision cost
decision cost  cdet  x  k   a   captures expected cost accepting  or rejecting 
potential object detection  captures expected yield information observations
along path x  k   trajectory affects cost decision actions terms changing
expectation  rather decision actions themselves  effect allowing algorithm decide
observations needed 
note decision actions treated independently independently
robot motion  allows us compute expected decision costs efficiently 
take advantage efficiency move minimization decision actions directly inside
cost function  abusing notation cdec  
cdet  x  k     arg min cdet  x  k   a 

    



  arg min ey x  k dec  a  y   


   

    

fim odelling bservation c orrelations f robust bject etection

next  write plan terms x  k  

  arg min cmot  x  k     cdet  x  k    

    

x  k

dec  accept    dec  reject    costs associated declaring object exists
not  respectively  measuring z xk following traversal waypoint observation trajectory
k    costs include penalties imposed accepting true positive detection
accepting false positive detection  respectively  chosen user system
reflect value penalty decision particular domain 
expectation inside equ     relies model conditioned trajectory x  k  
seen fig    c   x  k correlated z k   planning  actual z k
received cannot known ahead time  evaluate expectation exactly  must
taken respect object state received observations 
ey x  k  
 a  y    

z dec
k
k 
p z x  
 ey z x  k   dec  a  y    

    

z

p z xk   k    denotes probability obtaining particular detector confidence value
observing object x given previous trajectory k    computed akin
posterior equ     section     show efficiently approximate expectation
observation sequence treating belief normally distributed 
planning process proceeds searching sequences x  k   evaluating paths approximating expectations respect observation sequences object state 
paths lowest decision cost tend leading lowest posterior entropy 
avoiding large penalty false positives negatives 
    multiple objects
formally define vantage point relative object y  vy rm   vector dimensional feature space describing configuration robot relative potential object 
define mapping f   r  so      rm robot waypoint x corresponding vantage point vy   f  x  y   principle  vantage point need restricted spatial
coordinates may incorporate additional information as  example  degree occlusion experienced image contrast  for appearance based detector   work  however 
range  r  aspect    relative object robot oriented directly face object
considered vy r so     see fig   a   important note system must
able accurately compute vantage point  paper stereo camera used estimate
distance orientation potential object  planning approach described far
extended planning environment q object hypotheses considering modified cost
function simply adds cost object  augment dec  a  y  dec  a  y  i 
able provide different decision costs different object types  or even different object instances   augmentation allows us specify relative importance different objects types
algorithm  work consider objects existence independent objects
hence individual object perception fields additive particular waypoint x  restrict
waypoints correspond robot facing particular hypothesized object 
   

fiv elez   h emann   h uang   p osner   roy

given prior information object locations  hypothesize many objects
world  initially let q     run object detector robot motion 
image processed object detector  system judges whether detection belongs object hypothesis already considered  e g   using distance
hypothesized object detection   detector determines probability object
new location threshold belong hypothesis objects 
number object hypotheses q increased robot replans  detection determined
correspond particular object hypothesis  system updates belief replans 
    multi step planning
simple approach planning considers every possible trajectory goal weights
cost taking trajectory  choosing minimum cost trajectory plan  simple
algorithm scales approximately exponentially length planning horizon thus
rapidly becomes intractable observations considered  adopt roadmap scheme
fixed number waypoints sampled every time new waypoint added
current trajectory  graph built sampled poses  straight line edges
samples 
sampling scheme biased towards waypoints likely lead useful observations
using perception field  see section       due correlations individual observations
made trajectory waypoints  perception field changes new observations added 
particular  correlation model imposed work  equs       dynamic time varying
model equ     static disc model  forces
lim

  obs  xk

i y  z k   xk   k      

considering measurements waypoints already visited  words  robot
prefer observe putative object different waypoints taking repeated measurements
place 
algorithm r eplan n n ew etection  fig     summarizes planned waypoints approach
sampling evaluating trajectories balance increased confidence motion costs 
algorithm uses posterior belief distribution framework able quickly sample trajectories
many observations  selects best current plan according cost
metric 
figure   details stages algorithm example run single door detected
going towards goal 

   efficient perception field computation
planning algorithm needs calculate perception field deep planning horizons  t    
variant algorithm uses static disc sensor model must evaluate expected
change belief every potential future waypoint  must carry belief thought
level search tree future trajectories xk   k t   however  using dynamic
time varying sensor model treat belief normally distributed  normal
distribution approximation  limit infinite number observations  mean normal
distribution converge either      depending whether object present not  
   

fim odelling bservation c orrelations f robust bject etection

algorithm r eplan n n ew etection
input  object detection z vantage point x
   step    update belief
   using static disc sensor model
  
dmin   arg min  x xi  
  

  
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

disc  

xi k 
dmin
dm ax
k  y t k  
disc p z
p z k  t k  

equ   

    disc   p y t k   

p y 
else
n  corr k   corr k   predict gp corr   x 
 
  ecorr k
n n    kn  zn w  n    
n  n    gn bn gtn   
   step    sample trajectories
  
sampling time remains
traj   
using static disc sensor model
y 
   
pi compute   perception   field yi   
xi pi    sample vantage point
p yi   ez    p z    xi   k    yi   p yi    
traj traj xi
else
   n
   n
gp  corr gp corr
   
i 
pi compute   perception   field  i     i    gp corr
 
xi pi    sample vantage point
z   predict gp i 
corr   gp ind   xi  
 
gp icorr update   sensor   model gp i 
corr   xi   z  
 i  i    kn  zn   w   i    
 i   i    gn bn gtn   
traj traj xi
traj



    execute   trajectory

equ   

equ   
equs          

equ  

equs     
equs             
equs          

arg min cost t   
t 

figure    waypoint planning algorithm samples trajectories using perception field 
chooses trajectories balance increasing robots confidence object
minimizing trajectory costs  equ     

   

fiv elez   h emann   h uang   p osner   roy

 a  initially  robot  blue
triangle  goal  red star 
detections fired
yet  potential objects
reasoned about 

 b  detector fires 
robot starts reasoning
potential object 
system creates initial
perception field training
data potential object
plans path take
detections 

 c  two detections  magenta  belief high
enough system confident door truly exists
world continues
towards goal  shown
resulting perception field
two taken observations 

figure    sample run system  initially empty set objects reasoned
 a   door detector firing causing new door object hypothesis perception field
created  b   system plans executes path goal allows
take advantageous observations hypothesized door  two observations 
system continues towards goal since belief whether door exists
increase expected reward improving confidence
object model justified additional cost  c   brighter regions perception
fields correspond waypoints likely result higher confidence posterior beliefs 
observations taken robot denoted location  magenta  oriented
point sensor directly object  belief whether door truly exists
denoted green bar 

small variance  additionally  expected cost decision depend variance
distribution  smaller covariance normal posterior  less likely probability
decision error  finally  posterior covariance normal depend sensor
model  observation itself  result  know sensor model information gain
measurement  predict posterior covariance  hence expected cost
decision action  without knowing exact observation sequence itself  approximation
binomial measurement function known posterior belief distribution  pbd  algorithm  he
et al          used efficiently compute resulting belief time steps  sketch
general idea behind pbd below  use compute expected entropy reduction
belief future observations 
   

fim odelling bservation c orrelations f robust bject etection

    belief
reality  object either exists exists world  denoted    labeled training
data output object detector form  z  x     object  no object    pair
detector output particular waypoint knowledge whether object exists not 
order use labeled samples train sensor model  a model object detector  
keep track belief whether object exists not  equs        show independent
correlated observation model likelihood given using likelihood given   marginalize
belief independent correlated observations models  equs        
get
k
k
p zind
   xk   k      p zind
 object  xk   k   
k
       p zind
 no object  xk   k   

    

k
k
p zcorr
   xk   k      p zcorr
 object  xk   k   
k
       p zcorr
 no object  xk   k    

    

likelihood modeled gp similar equ        independent
correlated models respectively 
noting write likelihood z terms using  equs         
similarly rewrite equ    terms likelihoods based
k
p z k    xk   k      p z k k   p zind
   xk   k   
k
     p z k k    p zcorr
   xk   k    

    

    posterior belief distribution
pbd algorithm allows us estimate expected information gain particular waypoint
without integrating potential observations z  begin framing problem exponential family kalman filter  efkf  formulation  he et al         treat state
trying estimate  exponential family observation model 
n   n  n  n   n  

    

zn   exp zn n bn  n     n  zn    

    

given single observation canonical link function w mapping state observation
parameter   posterior mean variance belief computed as 
n   n    kn  zn w  n    
n    n    gn bn gt   

    
    

n

kn   n  gn  gn n  gtn   bn
zn   n bn

n fifi
gn  
n

 

 bn zn  
 

n  n 

   

   

 

    
    
    

fiv elez   h emann   h uang   p osner   roy

gp
object
text gp ind
no object
text gp ind
object
text gp corr
no object
text gp corr
object
door gp ind
no object
door gp ind
object
door gp corr
no object
door gp corr

se kernel
   
    
   
   
    
    
     
    

se kernel l
    
    
    
    
    
    
    
    

table    learned gp parameters  note kernel scale door text differ
correlated observation gps 

particular importance us fact posterior covariance closed form solution 
independent posterior mean  he et al          require integrating
possible observations z  compute posterior covariance observations
future

x
n t    n   
gi bi gti     
    
i  

rather marginalize potential future observations every future waypoint 
compute variance belief observations simply multiplying
variance observations future waypoints  given perception field
function variance belief  since entropy normal distribution function
variance   quickly compute field deep observation trajectories  efficient
computation allows planning algorithm sample potential observation trajectories many
observations  t     thereby increasing effective search depth algorithm improving
plans 

   objects  doors signs
system general agnostic type detector employed even sensing modality
used  constraint formed need able define vantage points  see section
     compute perception field  see section       work  chose test approach
two different vision based object detectors  first leverages parts based object detector
felzenszwalb  mcallester  ramanan        trained find doors  second detector aims
spot human readable text world commonly found signs  use text spotting
inspired work posner  corke  newman        authors kindly provided us
c   software library latest incarnation text spotting engine  provides
detection parsing facilities individual words natural scene images 
door detector trained approximately      positive      negative examples
manually labeled images collected large range indoor areas excluding testing
environment  performance images testing environment low due false positives
triggered visual structures present training images  detector could re trained
   

fim odelling bservation c orrelations f robust bject etection

average
precision
recall
path length  m 
total trials

g reedy    
         
         
          
  

g reedy    
         
         
          
  

p lanneddisc
         
         
          
  

rtbss
         
         
          
  

table    simulation performance single door scenario  standard error values 

improve performance  problem recurs new environments encountered 
examples used train sensor models door detector 
text detector trained exactly described posner et al          dynamic timevarying sensor model determined using approximately      positive      negative examples manually labeled images collected indoor office environment excluding
testing environment  used text detector localize text environment 
actually use contents text itself 
mixture parameter dynamic time varying sensor model  scale factor
chosen maximum likelihood estimator using training data detector system 
learned scaling values door       text        table   shows learned gp parameters
door text detectors 

   simulation results
first assessed planning approach using learned models simulated environment 
simulation environment consisted robot navigating occupancy map  object
detections triggered according learned observation model  simulated false positives
placing non object perceptual features probabilistically triggered object detections using
learned model false alarms  processing delay incurred actual object detector
simulated  the door detector requires approximately     seconds process spatially decimated
   x    pixel image text detector requires   seconds process full     x    pixel
image  
    comparison algorithms
simulation trials compared algorithm two algorithms  g reedy
algorithm selected best waypoint according perception field potential object belief object exceeded threshold   second  compared algorithm
rtbss online pomdp algorithm  paquet  tobin    chaib draa         rtbss algorithm
could use full sensor model markov assumption utilized independent part model  one could augment state space include entire history
detections therefore use full sensor model  however large state space would render
pomdp intractable practice  chose maximum depth equal algorithm
modeled world using resolution     meters rtbss algorithm  denote
algorithm using static disc sensor model p lanneddisc   dynamic time varying sensor
model p lanned 
   

fiv elez   h emann   h uang   p osner   roy

average
precision
recall
path length  m 
total trials

g reedy    
         
         
           
  

g reedy    
         
         
           
  

p lanneddisc
         
         
           
  

rtbss
         
         
           
  

table    simulation performance multiple door scenario  standard error values 

 a  small simulation environment used doors
containing single object  blue  two non object
 black  

 b  multiple object simulation environment used
doors containing   objects  blue    nonobjects  black  

figure    simulation environments static disc sensor model door detector 
    static disc sensor model simulations
first  tested p lanneddisc algorithm small simulation environment one door
object shown fig    a   table   shows simulation results static disc model door
detector  overall  explicitly planning waypoints resulted significantly higher performance 
p lanneddisc algorithm performed better rtbss terms precision recall  likely
algorithm sampled continuous space waypoints rtbss algorithm fixed
discrete representation  rtbss paths shorter 
evaluated p lanneddisc algorithm larger  complex scenario containing four
doors six non door objects  fig    b  shows multiple door simulation environment  table  
shows simulation results multi door scenario  p lanneddisc algorithm resulted
second shortest paths g reedy     superior detection performance  p lanneddisc
resulted significantly shorter paths rtbss given operating point roc
curve 
    dynamic time varying sensor model simulations
tested p lanned algorithm small simulation single text sign
complex simulation environment two signs shown figs         table   shows results
   trials using text detector sensor model single object simulation  text signs 
   

fim odelling bservation c orrelations f robust bject etection

average
precision
recall
path length  m 
total trials

g reedy    
         
         
          
  

p lanned
         
         
          
  

rtbss
         
         
          
  

table    simulation performance single sign scenario  standard error values 

see deep trajectory planning help much  compare g reedy strategy
planned strategy planning horizon     information text detector
spread smoothly  see perception field fig    a   hence greedy strategy best
thing do  however  planner took account cost resulted lower precision recall
performance much shorter path length  saw correlation sensor model allowed
planned algorithm perform better rtbss  belief updates predicted rtbss
overconfident hence rtbss algorithm resulted shorter path lengths worse precision recall
performance planned waypoints algorithm 

figure     small simulation environment used text signs containing single object  blue 
single non object  black  

next  evaluated p lanned algorithm complex scenario containing two objects
two non objects shown fig      table   shows simulation results multiple object
scenario  p lanned algorithm resulted best precision recall performance short path
length  rtbss resulted short path length  lack correlation model
became overconfident belief  performing significantly worse planned waypoints algorithm terms precision recall 
fig     shows density trajectories traversed algorithm simulations
run  brighter spots denote places simulated robot frequented simulation runs 
see p lanned algorithm kept robot close shortest path cost
function  rtbss  however  p lanned algorithm decided spread detections apart
correlation model employed whereas rtbss over valued information gained
nearby observations  g reedy algorithm take account motion cost
taking observation saw widespread set trajectories waypoints visited
simulations 
   

fiv elez   h emann   h uang   p osner   roy

average
precision
recall
path length  m 
total trials

g reedy    
         
         
          
  

p lanned
         
         
          
  

rtbss
         
         
          
  

table    simulation performance multiple signs scenario  standard error values 

 a  g reedy trajectories

 b  p lanned trajectories

 c  rtbss trajectories

figure     multiple object simulation environment used text containing   objects  blue 
  non objects  red   shown density paths taken different algorithms
simulation trials  planned approach results narrower space paths
g reedy avoiding nearby  correlated  observations 

    time improvements pbd
ran comparison updating perception field using pbd algorithm  see section
     update requires computing expectation possible detector outputs 
created histogram potential detector values either        bins used sampled
compute expected mutual information gain  the perception field  detector
output bins  table   shows results computing perception field     times  pbd algorithm
allowed us efficiently calculate perception field since explicitly iterate
possible detector values could use equ     
updating perception field time consuming part algorithm since must
updated reasoning future observations planning  total run time
determined many trajectories sampled using perception field depth
future trajectories  could tuned particular scenario application 
paper let planning algorithm sample evaluate trajectories amount time
running object detector single image passed 
   

fim odelling bservation c orrelations f robust bject etection

min
avg
max

    bins z
    s
    s
    s

   bins z
    s
    s
    s

pbd
    s
    s
    s

table    timing results computing perception field using either pbd algorithm  explicitly enumerating potential detector values z computing expectation
values 

average
precision
recall
path length  m 
total trials

g reedy    
         
         
            
  

p lanneddisc
        
        
           
  

table    results door real world trials using robot wheelchair  standard error values 

 a  trajectory executed actual robot wheelchair using planned waypoints
g robot discovers one true door  cyan   near goal 
detects two possible doors  red dots   detours inspect them   correctly  decides doors 

 b  robotic wheelchair
platform

figure     real world trial door detector using robotic wheelchair platform

   results real world trials
finally  validated results p lanneddisc p lanned algorithms robot wheelchair
platform  fig     b    autonomous wheelchair equipped onboard laser range scanners 
primarily used obstacle sensing navigation  point grey bumblebee  color stereo camera 
quad core laptop main processing unit  stereo camera used accurately
determine vantage point particular detection  door textual signs planar 
   

fiv elez   h emann   h uang   p osner   roy

fit plane detection bounding box  d points stereo camera determine
orientation possible object given detection 
door text real world trials  robot started particular location orientation 
robot given goal position nominal trajectory would bring past
one true object  a door text sign   near several fixtures trigger object detections 
initially  system object hypothesis detector run continuously moved
towards goal shortest path  object detector fired  system started reasoning
object hypothesis corresponding detections  robot deviated shortest
path take observations certain object hypothesis determined cost function  finally 
robot reached goal trial ended  object hypothesis accepted belief
greater      cost incorrect decision set    times cost meter
path length  cost correct decision set negative incorrect decision 
trials capped    minutes done real office environment without special
accommodations realistic possible 
fig     a  shows location door trials  robot always started start location
 marked s  given goal location  g   single door could
seen path start goal  near goal set windows light
fixtures often caused door detector fire  fig     a  illustrates trajectory executed
single trial p lanneddisc algorithm  table   summarizes results trials
doors  g reedy     chosen baseline comparison since best performing
existing algorithms according table    p lanneddisc algorithm resulted significantly
shorter trajectories maintaining comparable precision recall  doors detected substantial uncertainty  algorithm planned advantageous waypoints increase confidence
ignored far away detections high motion cost  interesting see fig     a 
algorithm deviated take observations false detections near goal location  ultimately
correctly deciding object hypothesis fact doors 
similarly conducted experiment using p lanned algorithm g reedy    
robotic wheelchair platform text detection algorithm  robot given nominal
trajectory brought past single textual sign  a poster office number placed
common location poster notifications   trials run daytime hours allow
artificial well natural lighting common environmental changes people
walking robot  table   summarizes results   real world trials algorithms 
see g reedy algorithm outperformed p lanned terms precision  consistent
simulation results  much longer path lengths  p lanned algorithm balanced
cost gaining new observations travel time resulted much shorter trajectories 
large path length associated greedy algorithm came two sources  first  greedy
algorithm take path cost account deciding next observation take  second
greedy algorithm kept taking pictures object hypothesis belief certain
threshold included sporadic object detections caused lights temporary environment
noise 
lastly  ran small set   trials using p lanned algorithm looking text signs
completely different environment previous trial  ran trials night
people walking by  table   shows results  even different environment  algorithms
behaved similarly  g reedy algorithm outperforming p lanned algorithm cost
much longer paths 
   

fim odelling bservation c orrelations f robust bject etection

average
precision
recall
path length  m 
total trials

g reedy    
   
   
           
 

p lanned
         
         
          
 

table    results text real world trials using robot wheelchair 
average
precision
recall
path length  m 
total trials

g reedy    
   
   
            
 

p lanned
         
   
            
 

table    results small text real world trials different location using robot wheelchair 

    related work
problem planning motion trajectories mobile sensor explored number
domains including planning  sensor placement  active vision robot exploration 
general formulation partially observable markov decision process  sondik         exact
solutions pomdps computationally intractable  recent progress led approximate
solvers find good policies many large  real world problems  pineau  gordon    thrun 
      smith   simmons        kurniawati  hsu    lee        kurniawati  du  hsu    lee        
however  complexity representing even approximate pomdp solution led forward
search strategies solving pomdps  ross et al         prentice   roy        et al         
eidenberger scharinger        formulate problem choosing sensor locations active
perception pomdp similar spirit formulation  however  explicitly model
underlying physics object generation  model uncertainty object location rather
object type  unable plan one step future  therefore work
similar g reedy strategies described previous sections  approach inspired
forward search pomdp algorithms  incorporates complex model approximates
correlations observations 
contrast pomdp models active sensing  controls community sensor placement community developed information theoretic models  goal minimize
norm posterior belief  entropy  objective function depend motion costs vehicle  sub modular  krause   guestrin         consequence  greedy
strategies choose next most valuable measurement shown boundedly close
optimal  challenge generate model predicts next best measurement
 guestrin  krause    singh        krause  leskovec  guestrin  vanbriesen    faloutsos        
terms image processing object recognition  denzler brown        sommerlade
reid        showed information theoretic planning could used tune camera parameters improve object recognition performance applied multi camera systems  although
use exhaustive search camera parameters rapidly becomes unwieldy  lastly  sridharan  wyatt  dearden        showed formulating information theoretic problem
decision theoretic pomdp  true multi step policies improve performance computer
   

fiv elez   h emann   h uang   p osner   roy

vision system terms processing time  however  previous algorithms use models
sequential decision making costs actions independent  or negligible   leading
submodular objective function limited improvement greedy strategies 
considerable work view point selection active vision briefly
review here  relevant pieces work include arbel ferrie       
recently laporte arbel        use bayesian approach model detections related
ours  searches next best viewpoint  rather computing full plan  work
deinzer  denzler  niemann        perhaps similar viewpoint
selection problem framed using reinforcement learning  authors neglect costs
camera movement identify absence costs limitation work  similarly 
system mittal davis        learns model object occlusion uses simulated annealing
solve optimal plan  contribution learn predictive model good viewpoints 
work borotschnig  paletta  prantl  pinz        uses appearance based object detection
system plan viewpoints minimize number observations required achieve certain
recognition rate  account correlations different observations 
field object localization search seen recent advancements  use
object object relations seems promising direction shown works aydemir  sjoo 
folkesson  pronobis  jensfelt        joho  senk  burgard         approach differs
system uses spatial relations single object multiple observations rather
different objects  works joho et al         aydemir  gobelbecker  pronobis 
sjoo  jensfelt        model environment achieve good results  whereas system
models correlation observations lieu modeling full environment  idea
attention seems powerful tool visual search  tsotsos        systems
due meger  forssen  lai  helmer  mccann  southey  baumann  little  lowe       
andreopoulos  h   janssen  hasler  tsotsos  korner        exhibiting excellent results  rather
using attention  system utilizes mutual information minimizes cost taking
observations  useful note system minimizes single cost function
encodes information path costs  ye tsotsos        formalized approach
maximizes probability localizing object minimizes cost 
robot exploration  goal generate robot trajectories learn accurate
complete map minimum travel cost  costs motion must incorporated  bourgault 
makarenko  williams  grocholsky  whyte        developed full exploration planner
incorporated explicit trade off motion plans map entropy  stachniss  grisetti 
burgard        described planner minimized total expected cost  performed search
next best action  address computational challenge  kollar roy        used
reinforcement learning learn model expected cost next viewpoint
exploration  minimize total expected cost complete trajectory 
contribution work existing work primarily describe planning model
incorporates action costs detection errors  specifically give approximate
observation model captures dynamic correlations successive measurements
still allows forward search planning operate  leading efficient multi step search improve
object detection 
   

fim odelling bservation c orrelations f robust bject etection

    conclusion future work
previous work planned sensing largely ignored motion costs planned trajectories used
simplified sensor models strong independence assumptions  paper  presented sensor model approximates correlation observations made similar vantage points 
efficient planning algorithm balances moving highly informative vantage points
motion cost taking detours  fully model effects entire environment
sensor intractable endeavor  sensor model simplifies environment interactions treating
correlations entire history sensor readings  placed emphasis spatial
relations model correlations new sensor readings history previous sensor
readings  properties gaussian processes  sensor model allows efficient
deep trajectory sampling utilizing posterior belief distribution framework  tested algorithm two different object detectors  doors signs  found better detector dependent
observation trajectories comparable strategies 
system presented planned deviations particular shortest path trajectory
goal order detect localize objects spotted once  future aim
incorporate large scale spatial model object likely encountered
them  next generation systems deal novel objects exists
prior object detector detector must created fly  goal create
end to end online adaptive semantic mapping solution works arbitrary objects
environments 

references
andreopoulos  a   h   w   janssen  h   hasler  s   tsotsos  j     korner  e          active  d object
localization using asimo  ieee transactions robotics              
anguelov  d   koller  d   parker  e     thrun  s          detecting modeling doors mobile
robots  proc  icra 
arbel  t     ferrie  f  p          viewpoint selection navigation entropy maps  proc 
iccv  kerkyra  greece 
aydemir  a   sjoo  k   folkesson  j   pronobis  a     jensfelt  p          search real world 
active visual object search based spatial relations  proc  icra 
aydemir  a   gobelbecker  m   pronobis  a   sjoo  k     jensfelt  p          plan based object
search exploration using semantic spatial knowledge real world  proc  ecmr 
orebro  sweden 
borotschnig  h   paletta  l   prantl  m     pinz  a          appearance based active object recognition  image vision computing                
bourgault  f   makarenko  a  a   williams  s  b   grocholsky  b     whyte  d  h  f          information based adaptive robotic exploration  proc  iros  epfl  lausanne 
coates  a     ng  a  y          multi camera object detection robotics  proc  icra 
deinzer  f   denzler  j     niemann  h          viewpoint selection   planning optimal sequences
views object recognition  proc  iccv  springer 
   

fiv elez   h emann   h uang   p osner   roy

denzler  j     brown  c  m          information theoretic sensor data selection active object
recognition state estimation  ieee trans  pattern analysis machine intelligence 
              
douillard  b   fox  d     ramos  f          laser vision based outdoor object mapping 
proc  rss 
eidenberger  r     scharinger  j          active perception scene modeling planning
probabilistic  d object poses  proc  iros 
felzenszwalb  p   mcallester  d     ramanan  d          discriminatively trained  multiscale 
deformable part model  proc  cvpr 
guestrin  c   krause  a     singh  a          near optimal sensor placements gaussian processes  proc  icml 
he  r   brunskill  e     roy  n          puma  planning uncertainty macro actions 
proc  aaai  atlanta  ga 
he  r   brunskill  e     roy  n          efficient planning uncertainty macro actions 
journal artificial intelligence research             
joho  d   senk  m     burgard  w          learning search heuristics finding objects structured environments  robotics autonomous systems                
kaelbling  l   littman  m     cassandra  a          planning acting partially observable
stochastic domains  artificial intelligence             
kollar  t     roy  n          trajectory optimization using reinforcement learning map exploration  international journal robotics research                
krause  a     guestrin  c          near optimal observation selection using submodular functions 
proc  aaai 
krause  a   leskovec  j   guestrin  c   vanbriesen  j     faloutsos  c          efficient sensor
placement optimization securing large water distribution networks  journal water resources planning management           
kurniawati  h   du  y   hsu  d     lee  w          motion planning uncertainty robotic
tasks long time horizons  international journal robotics research        
kurniawati  h   hsu  d     lee  w          sarsop  efficient point based pomdp planning
approximating optimally reachable belief spaces  proc  rss 
laporte  c     arbel  t          efficient discriminant viewpoint selection active bayesian
recognition  international journal computer vision                
martinez mozos  o   stachniss  c     burgard  w          supervised learning places
range data using adaboost  proc  icra 
meger  d   forssen  p   lai  k   helmer  s   mccann  s   southey  t   baumann  m   little  j    
lowe  d          curious george  attentive semantic robot  robotics autonomous
systems                
mittal  a     davis  l          general method sensor planning multi sensor systems 
extens ion random occlusion  international journal computer vision           
   

fim odelling bservation c orrelations f robust bject etection

newman  p   sibley  g   smith  m   cummins  m   harrison  a   mei  c   posner  i   shade  r  
schroeter  d   murphy  l   churchill  w   cole  d     reid  i          navigating  recognising describing urban spaces vision laser  international journal robotics
research            
paquet  s   tobin  l     chaib draa  b          real time decision making large pomdps 
  th canadian conference artificial intelligence 
pineau  j   gordon  g     thrun  s          anytime point based approximations large
pomdps  journal artificial intelligence research             
posner  i   corke  p     newman  p          using text spotting query world  proc  iros 
posner  i   cummins  m     newman  p          generative framework fast urban labeling
using spatial temporal context  autonomous robots                
prentice  s     roy  n          belief roadmap  efficient planning belief space factoring
covariance  international journal robotics research                     
rasmussen  c  e     williams  c  k  i          gaussian processes machine learning  mit
press 
ross  s   pineau  j   paquet  s     chaib draa  b          online planning algorithms pomdps 
journal artificial intelligence research                
smith  t     simmons  r          point based pomdp algorithms  improved analysis implementation  proc  uai 
sommerlade  e     reid  i          probabilistic surveillance multiple active cameras  proc 
icra 
sondik  e  j          optimal control partially observable markov processes  ph d  thesis 
stanford university 
sridharan  m   wyatt  j     dearden  r          hippo  hierarchical pomdps planning information processing sensing actions robot  proc  icaps 
stachniss  c   grisetti  g     burgard  w          information gain based exploration using raoblackwellized particle filters  proc  rss  cambridge  ma  usa 
takeda  h     latombe  j          sensory uncertainty field mobile robot navigation  proc 
icra 
tsotsos  j  k          relative complexity active vs  passive visual search  international
journal computer vision               
velez  j   hemann  g   huang  a   posner  i     roy  n          planning perceive  exploiting
mobility robust object detection  proc  icaps  freiburg  germany 
ye  y     tsotsos  j          sensor planning  d object search  computer vision image
understanding                

   


