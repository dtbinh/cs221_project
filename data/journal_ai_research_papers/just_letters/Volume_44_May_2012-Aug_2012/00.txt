journal of artificial intelligence research              

submitted        published      

c olin  planning with continuous linear numeric change
amanda coles
andrew coles
maria fox
derek long

amanda   coles   kcl   ac   uk
andrew  coles   kcl   ac   uk
maria   fox   kcl   ac   uk
derek   long   kcl   ac   uk

department of informatics  kings college london 
strand  london wc r  ls  uk

abstract
in this paper we describe colin  a forward chaining heuristic search planner  capable of reasoning with continuous linear numeric change  in addition to the full temporal semantics of
pddl      through this work we make two advances to the state of the art in terms of expressive reasoning capabilities of planners  the handling of continuous linear change  and the handling of duration dependent effects in combination with duration inequalities  both of which require tightly coupled temporal and numeric reasoning during planning  colin combines ff style
forward chaining search  with the use of a linear program  lp  to check the consistency of the
interacting temporal and numeric constraints at each state  the lp is used to compute bounds on
the values of variables in each state  reducing the range of actions that need to be considered for
application  in addition  we develop an extension of the temporal relaxed planning graph heuristic of crikey    to support reasoning directly with continuous change  we extend the range of task
variables considered to be suitable candidates for specifying the gradient of the continuous numeric
change effected by an action  finally  we explore the potential for employing mixed integer programming as a tool for optimising the timestamps of the actions in the plan  once a solution has
been found  to support this  we further contribute a selection of extended benchmark domains that
include continuous numeric effects  we present results for colin that demonstrate its scalability
on a range of benchmarks  and compare to existing state of the art planners 

   introduction
there has been considerable progress in the development of automated planning techniques for
domains involving independent temporal and metric conditions and effects  eyerich  mattmuller 
  roger        coles  fox  long    smith      a  gerevini  saetti    serina        edelkamp 
      coles  fox  long    smith      b   the development of powerful heuristics for propositional
planning has been shown to offer benefits in the solution of extended planning problems  including
planning under uncertainty  palacios   geffner         planning with numbers and planning with
time  however  the combination and integration of metric and temporal features  in which metric
quantities change in time dependent ways  remains a challenge that has received relatively little
attention 
interaction between time and numbers in planning problems can occur in many ways  in the
simplest case  using pddl      fox   long         the numeric effects of actions are only updated
instantaneously  and only at the start or end points of actions which are known  and fixed  at the
point of action execution  the corpus of domains from past international planning competitions
adhere to these restrictions  time and numbers can interact in at least two more complex ways  first 
actions can have variable  possibly constrained  durations and the  instantaneous  effects of these
c
    
ai access foundation  all rights reserved 

fic oles   c oles   f ox   l ong

actions can depend on the values of the durations  this allows domain models to capture the effects
of processes as discretised step effects  but adjusted according to the demands of specific problem
instances  second  the effects of actions can be considered to be continuous across their execution 
so that the values of metric variables at any time point depend on how long the continuous effects
have been acting on them 
for example  a problem in which sand is loaded into a lorry can be modelled so that the amount
of sand loaded depends on the time spent loading  the first approach is to capture the increase in
the quantity of loaded sand as a step function applied at the end of the loading action  in the second
approach  the process of loading sand is modelled as a continuous and linear function of the time
spent loading  so that the amount of sand in the lorry can be observed at any point throughout the
loading process  if a safety device must be engaged before the lorry is more than three quarters
full  then only the second of these models will allow a planner to have the necessary access to the
underlying process behaviour to make good planning choices about how to integrate this action into
solutions  there are alternative models exploiting duration dependent effects to split the loading
action into two parts around the time point at which the safety device must be engaged  but these
alternatives become very complicated with relatively modest changes to the domain 
continuous change in both of these forms is common in many important problems  these include  energy management  the consumption and replenishment of restricted continuous resources
such as fuel  tracking the progress of chemicals through storage tanks in chemical plants  choreographing robot motion with the execution of tasks  and managing the efficient use of time  in some
cases  a model using discrete time independent change is adequate for planning  however  discretisation is not always practical  to find a reasonable solution  or  indeed  to find one at all  identifying
the appropriate granularity for discretisation is non trivial  perhaps requiring a range of choices
that are so fine grained as to make the discrete model infeasibly large  in other cases  the numeric
change cannot be appropriately discretised  where it is unavoidably necessary to have access to the
values of numeric variables during the execution of actions  in order to manage interactions between
numeric values 
in this paper we present a planner  colin  capable of reasoning with both variable  durationdependent  linear change and linear continuous numeric effects  the key advance that colin makes
is to be able to reason about time dependent change through the use of linear programs that combine metric and temporal conditions and effects into the same representation  colin is a satisficing
planner that attempts to build good quality solutions to this complex class of problems  since colin
is a forward searching planner it requires a representation of states  a means to compute the progression of states and a heuristic function to guide the search for a path from the initial to the goal
state  colin is built on the planner crikey    coles  fox  long et al       a   however  crikey  
requires numeric change to be discrete and cannot reason with continuous numeric change  or duration dependent change  where the duration of actions is not fixed in the state in which the action
begins   being able to reason successfully with problems characterised by continuous change  coping efficiently with a wide range of practical problems that are inspired by real applications  is the
major contribution made by colin 
the organisation of the paper is as follows  in section   we explain the features of pddl    
that colin can handle  and contrast its repertoire with that of crikey    in section   we define
the problem that is addressed by colin  in section   we outline the background in temporal and
metric planning that supports colin  before  in section    describing the details of the foundations of colin that lie in crikey    colin inherits its representation of states from crikey   
 

fic olin   p lanning with c ontinuous c hange

as well as the machinery for confirming the temporal consistency of plans and the basis for the
heuristic function  in section   we describe systems in the literature that have addressed similar
hybrid discrete continuous planning problems to those that colin is designed to handle  section  
explains how state progression is extended in colin to handle linear continuous change  and section   describes the heuristic that guides the search for solutions  in section    we consider several
elements of colin that improve both efficiency and plan quality  without affecting the fundamental
behaviour of the planner  since time dependent numeric change has been so little explored  there
are few benchmarks in existence that allow a full quantitative evaluation  we therefore present
a collection of continuous domains that can be used for such analysis  and we show how colin
fares on these  an appendix containing some explanations of technical detail and some detailed
summaries of background work on which colin depends  ensures that the paper is complete and
self contained 

   language features in c rikey   and colin
colin builds on crikey   by handling the continuous features of pddl      c rikey   was restricted to management of discrete change  while colin can handle the full range of linear continuous numeric effects  the only metric functions of pddl     that are not in the repertoire of colin
are scale up and scale down  which are non linear updates  and the general form of plan metrics  managing plan metrics defined in terms of domain variables remains a challenge for planning
that has not yet been fully confronted by any contemporary planner  colin does handle a restricted
form of quality metric  which exploits an instrumented variable called total cost  this allows
colin to minimise the overall cost of the shortest plan it can find using total time  the default
metric used by most temporal planners  
in common with crikey    colin can cope with timed initial literals  an important feature
that was introduced in pddl      hoffmann   edelkamp         pddl     is backward compatible
with mcdermotts pddl  mcdermott        and therefore supports adl  pednault         colin
does not handle full adl  but it can deal with a restricted form of conditional effect as seen in the
airplane landing problem described in section     this restricted form allows the cost of an action
to be dependent on the state in which it is applied  more general forms of conditional effect cannot
be handled 
with this collection of features  colin is able to fully manage both the discrete and continuous
numeric change that occur directly as a result of its actions  pddl    fox   long        further
supports the modelling of continuous change brought about by exogenous processes and events 
these are triggered by actions  but they model the independent continuous behaviour brought about
by the world rather than by the planners direct action  the key additional features of pddl   that
support this are processes and events  colin does not handle these features but is restricted to the
management of continuous change as expressed through the durative action device 
for detailed explanations of the syntaxes and semantics of pddl     and pddl    including the
semantics on which implementations of state representation and state progression must be constructed  readers should refer to the work of fox and long              
 

fic oles   c oles   f ox   l ong

language
pddl    
pddl    

language feature
numeric conditions and effects
continuous numeric effects

c rikey  
yes
no

colin
yes
yes

pddl    

pddl    

general plan metrics
use of total cost
assign  to discrete variables 
scale up down
 t
durative actions

no
no
yes
no
no
yes

no
yes
yes
no
yes
yes

pddl    

duration inequalities

limited

yes

pddl    

tils
conditional effects
other adl

yes
no
no

yes
partial
no

pddl    
pddl    
pddl    
pddl    

pddl
pddl

comment
basic treatment follows metric ff
modification to state representation
modification to heuristic

section
appendix b
section  
section  

limited form
treatment follows metric ff

section   

as continuous effects
includes required concurrency
colin handles
duration dependent effects

only for limited effects

section   and
appendix c
sections   and  
section  
section   

table    language features handled by crikey   and colin 

   motivation
there are a number of accounts of planning having been successfully applied to real problems 
and the frequency with which applications are reported is increasing  the following examples involve domains with hybrid discrete continuous dynamics  these dynamics are typically being dealt
with by discretising time  packaging continuous numeric effects into step functions  or integrating
propositional planning techniques with specialised solvers  they are all examples in which hybrid
discrete continuous reasoning could be exploited to improve plan quality or solution time 
 operations of refineries  boddy   johnson        lamba  dietz  johnson    boddy       
or chemical plants  penna  intrigila  magazzeni    mercorio         where the continuous
processes reflect flows of materials  mixing and chemical reactions  heating and cooling 
 management of power and thermal energy in aerospace applications in which power management is critical  such as management of the solar panel arrays on the international space
station  knight  schaffer    b clement        reddy  frank  iatauro  boyce  kurklu  aichang    jonsson         for example  knight et al         rely on a high fidelity power
model  turbospeed  to provide support for reasoning about the continuous power supply in
different configurations of the solar panels  power management is a critical problem for most
space applications  including planetary rovers and landers  inspiring the temporal metriccontinuous rovers domain used as one of our benchmark evaluation domains in section     
chien et al         describe the planner used to support operations on earth observing    eo    where the management of thermal energy generated by instruments is sufficiently important that the on board planner uses some of its  highly constrained  cpu cycles to model and
track its value  eo   inspires the temporal metric continuous satellite benchmark described
in section    
 management of non renewable power in other contexts  such as for battery powered devices 
the battery management problem described by fox et al         relies on a non linear model 
 

fic olin   p lanning with c ontinuous c hange

which colin must currently reduce to a discrete or linear approximation  coupled with iterated validation and solution refinement  in order to optimise power use  battery management
is an example of a continuous problem that cannot be solved if the continuous dynamics are
removed 
 assignment of time dependent costs as in the aircraft landing domain  dierks         in
which continuous processes govern the changing costs of the use of the runway as the landing
time deviates from the optimal landing time for each aircraft  this problem inspires the
aircraft landing benchmark domain described in section    
 choreography of mobile robotic systems  in many cases  operations of robotic platforms
involve careful management of motion alongside other tasks  where the continuous motion
of the robot constrains the accessibility of specific tasks  such as inspection or observation 
existing examples of hybrid discrete continuous planning models and reasoning for problems of this kind include work using flow tubes to capture the constraints on continuous
processes  leaute   williams        li   williams         problems involving autonomous
underwater vehicles  auvs  inspired the temporal metric continuous auv benchmark presented in section    

   problem definition
colin is designed to solve a class of problems that are temporal and metric  and that feature linear
continuous metric change  we refer to this as the class of temporal metric continuous problems 
and it contains a substantial subset of the problems that can be expressed in pddl     
as a step towards the class of temporal metric continuous problems  we recall the definition
of a simple temporal metric planning problem  one in which there is no time dependent metric
change  simple temporal metric problems can be represented as a tuple hi  a  g  m i  where 
 i is the initial state  a set of propositions and an assignment of values to a set of numeric
variables  either of these sets may be empty  for notational convenience  we refer to the
vector of numeric values in a given state as v 
 a  a set of actions  each hdur   pre     eff     pre    pre a   eff a i  where 
 pre    pre a   are the start  end  conditions of a  at the state in which a starts  ends   these
conditions must hold  for a detailed account of some of the subtleties in the semantics
of action application  see fox   long        
 eff    eff a   are the start  end  effects of a  starting  ending  a updates the world state
according to these effects  a given collection of effects eff x   x      a   consists of 
 eff 
x   propositions to be deleted from the world state 
 eff  
x   propositions to be added to the world state 
 eff nx   effects acting upon numeric variables 
 pre  are the invariant conditions of a  these must hold at every point in the open interval
between the start and end of a 
 dur are the duration constraints of a  calculated on the basis of the world state in which
a is started  and constraining the length of time that can pass between the start and end
of a  they each refer to the special parameter  duration  denoting the duration of a 
 

fic oles   c oles   f ox   l ong

 g  a goal  a set of propositions and conditions over numeric variables 
 optionally m   a metric optimisation function  defined as a function of the values of numeric
variables at the end of the plan  and the special variable total time  denoting the makespan
of the plan 
a solution to such a problem is a time stamped sequence of actions  with associated durations  that
transforms the initial state into a state satisfying the goal  respecting all the conditions imposed  the
durations of the actions must be specified explicitly  since it is possible that the action specifications
can be satisfied by different duration values 
pddl     numeric conditions used in pre     pre a   pre    dur and g can be expressed in the
form 
hf  v   op  ci  such that op                 c   
where v is the vector of metric fluents in the planning problem  f  v  is a function applied to the
vector of numeric fluents and c is an arbitrary constant  numeric effects used in eff   and eff a are
expressed as 
hv  op  f  v i  such that op                   
a restricted form of numeric expressions is the set of expressions in linear normal form  lnf  
these are expressions in which f  v  is a weighted sum of variables plus a constant  expressible in
the form w  v   c  for a vector of constants  w  a notable consequence of permitting dur to take the
form of a set of lnf constraints over  duration is that  duration need not evaluate to a single
fixed value  for instance  it may constrain the value of  duration to lie within a range of values 
e g    duration  v       duration  v     for some numeric variables v  and v    restricting
conditions and effects to use only lnfs allows the metric expressions to be captured in a linear
program model  a fact that we exploit in colin 
the class of temporal metric problems is extended to temporal metric continuous problems by
two additions 
   each action a  a is described with an additional component  a set of linear continuous
numeric effects  cont  of the form hv  ki  k     denoting that a increases v at the rate of k
per unit of time  this corresponds to the pddl     effect  increase  v      t k   
   the start or end effects of actions  eff n  and eff na may  additionally  include the parameter
 duration  denoting the duration of the action  and hence are written 
hv  op  w  v   k   duration    ci s t  op               c  k   
in temporal metric continuous problems the relationship between time and numbers is more complex than in temporal metric problems  the first extension allows the value of a variable v to depend
on the length of time elapsed since the continuous effect acting upon it began  the second extension implies that  if  duration is not fixed  then the value of variables can depend on the duration
assigned to the action  in fact   very few planners allow the literal  duration to appear in effects 
even in actions where the value of the parameter is constrained to take a single fixed value by the
duration constraint  e g      duration       a typical idiom is to name the intended value of the
duration with a metric fluent in the initial state  e g      durationofaction       and then use this
fluent in the effects 
 

fic olin   p lanning with c ontinuous c hange

  durative action savehard
 parameters   
 duration     duration    
 condition
 and  at start  cansave  
 over all      money      
 effect
 and  at start  not  cansave   
 at end  cansave  
 at start  saving  
 at end  not  saving   
 increase  money      t      

  durative action lifeaudit
 parameters   
 duration     duration  patience  
 condition
 and  at start  saving  
 at end  boughthouse  
 at end      money      
 effect  and  at end  happy     

  durative action takemortgage
 parameters   m   mortgage 
 duration     duration  durationfor  m  
 condition
 and  at start  saving  
 at start      money   depositfor  m   
 over all      money   maxsavings  m    
 effect
 and  at start  decrease  money   depositfor  m   
 decrease  money      t  interestratefor  m   
 at end  boughthouse    

figure    actions for the borrower domain 

temporal metric continuous problems form a significant subset of problems expressible in the
pddl   language  fox   long         including those with linear continuous change within durative
actions  the problems do not include non linear continuous change  nor do they explicitly represent
events or processes  although the use of certain modelling tricks can capture similar behaviours 
    an example problem
as a running example of a temporal metric continuous domain we use the problem shown in figure    in this  the borrower domain  a borrower can use a mortgage to buy a house  the domain is
simplified in order to focus attention on some key aspects of continuous reasoning and is not proposed as a realistic application  furthermore  the domain does not exploit variable duration actions 
even though the ability to handle these is a key feature of colin  the example illustrates required
concurrency  by means of interesting interactions between multiple actions affecting a single continuous variable  and allows us to demonstrate the differences between alternative heuristics described
in section    management of required concurrency is also a key feature of colin  and domains
with variable durations are discussed later in the paper 
in this domain  to obtain a mortgage it is necessary to have an appropriate active savings plan
and to be able to lay down a deposit  these conditions are both achieved by saving hard  an action
that cannot be applied in parallel with itself  preventing the borrower from building up capital at
an arbitrarily high rate by multiple parallel applications of savehard  for the sake of the example
we restrict the saving periods to durations of    years to produce interesting interactions with the
 

fic oles   c oles   f ox   l ong

  objects shortmortgage longmortgage   mortgage 
  init     money    
 cansave 
    patience    
    depositfor shortmortgage    
    durationfor shortmortgage     
    interestratefor shortmortgage      
    maxsavings shortmortgage    
    depositfor longmortgage    
    durationfor longmortgage     
    interestratefor longmortgage       
    maxsavings longmortgage     
  goal  and  happy   
  metric minimize  total time  

figure    an example problem for the borrower domain 

durations of the mortgages in the sample problem  once a person starts saving he or she is tied into
a    year savings plan 
the constraint on being able to start a mortgage leads to required concurrency between saving
and taking a mortgage  the effects of saving and repaying interest therefore combine to yield
different linear effects on the value of the money variable  while the saving action requires this
variable to remain non negative throughout the duration of the savehard action  furthermore  in
order to qualify for tax relief  each mortgage carries a maximum allowed level of savings throughout
the mortgage  which prevents the mortgage being taken too late in the savings plan   finally  the
lifeaudit action places a constraint on the gap between the end of the saving action and the
point at which the mortgage is completed  and also ensures that the borrower does not end up in
debt   this action acknowledges that borrowers will only be happy if they manage to complete their
mortgages within short periods  limited by their patience  of having to save hard 
the simple problem instance we will consider is shown in figure    two possible solutions to
this are shown in figure    in the first solution the borrower takes the longer mortgage  which has
the advantage that it can start earlier because it requires a lower deposit  money rises at rate   over
the first part of the saving action  then decreases by   when the mortgage starts  it then rises at rate
      the difference between the saving and mortgage rates  until the saving action concludes  when
it continues to decrease at rate      until the mortgage ends  the life audit action must start during
a saving action and cannot end until after the end of a mortgage action  in the second solution the
borrower takes the shorter mortgage  but that cannot start as early because it requires a much larger
deposit  as a consequence  the life audit cannot start during the first saving action  the mortgage
finishes too late to be included inside a life audit beginning within the first saving action  to meet
the initial condition of the life audit  the borrower must therefore perform a second saving action
to follow the first  clearly the first solution is preferable since we are interested in minimising the
makespan 
 

fic olin   p lanning with c ontinuous c hange

money

   units
  unit
takemortgage longmortgage
   units
savehard
lifeaudit
  units

money

   units
takemortgage shortmortgage
  units
   units

   units

savehard

savehard
lifeaudit
  units

figure    possible solutions to the borrower problem 

   background in metric and temporal planning
most recent work on discrete numeric planning is built on the ideas introduced in the planner metricff  hoffmann         a discrete numeric planning problem introduces numeric variables into the
planning domain that can hold any real numeric value  or be undefined  if they have not yet been
given a value   actions can have conditions expressed in terms of these variables  and have effects
that act upon them  to provide heuristic guidance  metric ff introduced an extension of the relaxed
planning graph  rpg  heuristic  hoffmann   nebel         the metric rpg heuristic  supporting
the computation of a relaxed plan for a problems involving discrete numeric change  as with the
propositional rpg heuristic  it performs a forwards reachability analysis in which the delete effects
of actions are relaxed  ignored   for numeric effects  ignoring decrease effects does not always
relax the problem  as conditions can require that a variable hold a value less than a given constant 
thus  as the reachability analysis extends forwards  upper  and lower  bounds on the values of
numeric variables are computed  decrease effects have no effect upon the upper bound and increase
effects have no effect upon the lower bound  while assignment effects replace the value of the upper
 lower  bound if the incumbent has a lower  greater  value  respectively  than that which would be
assigned  deciding whether a precondition is satisfied in a given layer is performed  optimistically 
 

fic oles   c oles   f ox   l ong

on the basis of these  for a condition w  v  c    then an optimistically high value for w  v can
be computed by using the upper bound on each fluent v assigned a value in v if its corresponding
weight in w is positive  or  otherwise  using its lower bound 
an alternative to the use of a metric rpg is proposed in lprpg  coles  fox  long et al  
    b   where a linear program is constructed incrementally to capture the interactions between
actions  this approach is restricted to actions with linear effects  so is not as general as metric ff 
but it provides a more accurate heuristic guidance in handling metric problems and can perform
significantly better in problems where metric resources must be exchanged for one another in order
to complete a solution 
numeric planning also gives the opportunity to define metric optimisation functions in terms of
metric variables within the problem description  for example  an objective to minimise fuel consumption can be defined for domains where the quantity of fuel available is a metric variable  this
optimisation function can also include the special variable total time  representing the makespan
 execution duration  of the plan  most planners are restricted to a weighted sum across variables
 although pddl     syntax allows it to be an unrestricted expression across variables   in general 
planners are not yet capable of optimising metric functions effectively  the task of finding any plan
remains difficult  however  there are some planners that attempt to optimise these functions  the
most notable being lpg  gerevini   serina         and  in domains where the only numeric effects
are to count action cost  lama  due to richter   westphal        
although the introduction of pddl     led to an increased interest in temporal planning  earlier
work on planning with time has been influential  ixtet  ghallab   laruelle        introduced
chronicles  consisting of temporal assertions and constraints over a set of state variables  and timelines which are chronicles for single state variables  timelines have since been widely used by
planners that have followed a different trajectory of development than that led by the pddl family of languages  pell  gat  keesing  muscettola    smith        frank   jonsson        cesta 
cortellessa  fratini    oddi         ixtet also pioneered the use of many important techniques 
including simple temporal networks and linear constraints 
the language introduced for the planner temporal graph plan  tgp   smith   weld       
allowed  constant  durations to be attached to actions  the semantics of these actions required their
preconditions  pre  to be true for the entire duration of the action  and the effects of the actions 
eff  to become available instantaneously at their ends  the values of affected variables are treated
as undefined and inaccessible during execution  although the intended semantics  at least in tgp 
is that the values should be considered unobservable during these intervals and  therefore  plans
should be conformant with respect to all possible values of these variables over these intervals  t gp
solves these problems using a temporally extended version of the graphplan planning graph  blum
  furst        to reason with temporal constraints  a temporal heuristic effective for this form of
temporal planning was developed by haslum and geffner        and vidal and geffner        have
explored a constraint propagation approach to handling these problems 
even when using the more expressive temporal model defined in pddl      many temporal planners make use of the restricted tgp semantics  exploiting a simplification of the pddl     encoding
known as action compression  the compression is performed by setting pre to be the weakest
preconditions of the actions  and eff    eff    to be their strongest add  delete  effects  in the propo   conditions w  v  c can be rewritten in this form by negating both sides  further  those stating w  v   c can be
rewritten as a pair of conditions  w  v  c and  w  v   c

  

fic olin   p lanning with c ontinuous c hange

action a
q  not p

p

t

p
action b
r
p

r

q s

action c

action d
s

t  g

ordering of achiever before precondition
ordering of deleter after precondition

figure    a problem for sapa 
sitional case  in terms of the action representation introduced earlier  these are 
pre   pre      pre   pre a     eff  
  

 
eff      eff  
    eff a    eff a
 

 
eff      eff 
    eff      eff a     eff a

many modern temporal planners  such as mips   xxl  edelkamp   jabbar        and earlier versions of lpg  gerevini   serina         make use of this action compression technique  however 
applying the compression can lead to incompleteness  coles  fox  halsey  long    smith       
 in particular  a failure to solve certain temporal problems   the issues surrounding incompleteness
were first discussed with reference to the planner crikey  fox  long    halsey        and  later 
the problem structures causing this were said to introduce required concurrency  cushing  kambhampati  mausam    weld         the borrower domain is one example of a problem in which
the compression prevents solution  both the lifeaudit and takemortgage actions have initial
preconditions that can only be satisfied inside the interval of the savehard action  since this action
adds saving at its start  but deletes it at its end 
required concurrency is a critical ingredient in planning with continuous effects  as both when
change occurs and what change occurs are important throughout the execution of actions  in order to avoid producing poor quality plans or  indeed  excluding possible solutions  we must allow
concurrency between actions wherever the problem description permits it  a nave extension of
the compression approach would discretise continuous numeric change into step function effects
occurring at the ends of the relevant actions  precluding any possibility of managing the interaction
between numeric variables during execution of actions with continuous effects  we therefore build
our approach on a planner capable of reasoning with required concurrency  in the borrower domain  the mortgage action must overlap with the saving action  but it cannot be too early  to meet
the deposit requirement  or too late  to meet the maximum savings constraint and to ensure that the
life audit can be performed as early as possible   as this example illustrates  problems that include
reasoning with continuous linear change typically also require concurrency 
several planners are  currently  capable of reasoning with the pddl     startend semantics  as
opposed to relying on a compression approach  the earliest pddl     planner that reasons successfully with the semantics is vhpop  younes   simmons         which is a partial order planner 
  

fic oles   c oles   f ox   l ong

this planner depends on heuristic guidance based on the same relaxed planning graph that is used in
ff  so the guidance can fail in problems with required concurrency  nevertheless  the search space
explored by vhpop includes the interleavings of action start and end points that allow solution of
problems with required concurrency  v hpop suffers from some of the problems encountered in
earlier partial order planners and its performance scales poorly in many domains  t psys  garrido 
fox    long        garrido  onainda    barber        is a graphplan inspired planner that can
produce plans in domains with required concurrency  time is represented by successive layers of
the graph  using a uniform time increment for successive layers  this approach is similar to the way
that tgp uses a plan graph to represent temporal structure  but tpsys supports a model of actions
that separates the start and end effects of actions as dictated by pddl     semantics 
another planner that adopts a graphplan based approach to temporal planning is lpgp  long
  fox      a   but in its case the time between successive layers is variable  instead of using layers
of the graph to represent the passage of fixed duration increments of time  they are used to represent
successive happenings  time points at which state changes occur  the time between successive state changes is allowed to vary within constraints imposed by the action durations whose end
points are fixed at particular happenings  a linear program is constructed  incrementally  to model
the constraints and the solution of the program is interleaved with the selection of action choices 
this approach suffers from most of the weaknesses of a graphplan planner  the exhaustive iterative
deepening search is impractical for large problems  while computation and storage of mutex relations becomes very expensive in larger problems  nevertheless  lpgp provides a useful approach to
the treatment of pddl     durative actions  by splitting them into their end points which are treated
as instantaneous snap actions  a solution to the  original  planning problem can be expressed in
terms of these  subject to four conditions 
   each start snap action is paired with an end snap action  and no end can be applied without
its corresponding start having been applied earlier  
   between the start and end of an action  the invariants of the action pre are respected 
   no actions must be currently executing for a state to be considered to be a goal state 
   each step in the plan occurs after the preceding step  and the time between the start and end
of an action respect its duration constraints 
s apa  do   kambhampati        is one of the earliest forward search planners to solve temporal pddl     problems  it works with a priority queue of events  when a durative action is started
its end point is queued at the time in the future at which it will be executed  the choice points of
the planner include starting any new action  but also a special wait action  which advances time to
the next entry in the queue  and the corresponding action end point is executed  this allows sapa to
reason with concurrency and to solve some problems with required concurrency  unfortunately  its
search space does not include all necessary interleavings to achieve a complete search  for example 
consider the problem illustrated in figure    to solve this problem  action a must start  then action
b must start early enough to allow c to complete before a ends  and deletes p   and late enough
that action d can start before b ends but end after a ends  all of the actions are required in order
to allow d to be applied  achieving the goal g  after sapa starts action a  the queue will contain
the end of a  the choices now open are to start b immediately  but this will then end too early to
allow d to execute successfully  or else to complete a  which advances time too far to allow b to
  

fic olin   p lanning with c ontinuous c hange

light match
have light
unused match

have light
unused match

have light

mend fuse
needs fixing fuse

have light

needs fixing fuse

fixed fuse

figure    required concurrency

exploit effect p of a  preventing c from being executed  in fact  a simpler problem defeats sapa 
if b were to have end condition q instead of t and end effect g then c and d can be dispensed
with  however  the additional complexity of the existing example is that it is impossible to infer
when to start b by examination of a and b alone  because the timing constraints on the start of b
depends on both actions c and d and it is not immediately obvious how their temporal constraints
will affect the placement of b  the difficulty in adopting the waiting approach is that it is hard to
anticipate how long to wait if the next interesting time point depends on the interaction of actions
that have not yet even been selected 
a different approach to forward search temporal planning is explored in the crikey family of
planners  coles  fox  halsey et al         coles  fox  long et al       a   these planners use the
same action splitting approach used in lpgp  but work with a heuristically guided forward search 
the heuristics in these planners use a relaxed planning graph as a starting point  hoffmann   nebel 
       but extend it by adding some guidance about the temporal structure of the plan  pruning
choices that can be easily demonstrated to violate temporal constraints and inferring choices where
temporal constraints imply them  the planners use a simple temporal network to model and solve
the temporal constraints between the action end points as they are accumulated during successive
action choices  split actions have also been used to extend lpg into a temporal version that respects
the semantics of pddl      gerevini  saetti    serina         earlier versions of lpg use the compressed action models described above   recent work by haslum        has explored other ways
in which heuristics for temporal planning can be constructed  while remaining admissible 
temporal fast downward  eyerich et al          based on helmerts fast downward planner  helmert         uses an approach that is a slight refinement of the compressed action model 
allowing some required concurrency to be managed  the authors demonstrate that this planner can
solve the match problem shown in figure    they mistakenly claim that sapa cannot solve this
problem because it cannot consider applying an action between starting and ending lighting the
match  in fact  sapa can apply the mend fuse action after the match is lit  in much the same
way as is done in temporal fast downward  the problem that both planners face is in situations
in which an action must be started some time after the last happening  but before the next queued
event  neither planner includes this choice in its search space 
huang et al         developed a temporal planner exploiting the planning as satisfiability
paradigm  this uses a graphplan to sat encoding  starting with an lpgp action splitting compilation  and using a fixed time increment between successive layers of the graph  this approach is
  

fic oles   c oles   f ox   l ong

adequate for problems where an appropriate time increment can be identified  but this is not possible  in general  when there are time dependent effects in a domain  furthermore  the approach is
ineffective when there is significant difference between the durations of actions  so that the time increment becomes very short relative to some actions  the planner can produce optimal  makespan 
plans using iterative deepening search  the planner combines existing ideas to achieve its objectives
and it is mainly of interest because of its relationship to other sat based approaches to temporal
planning  such as tm   lpsat discussed below 
c rikey    and the other planners mentioned  are only capable of solving the simple temporal
planning problems described above  they are restricted to the management of discrete change 
duration dependent change cannot be handled by these planners  in fact  not all of these planners
can manage any kind of reasoning with numbers outside the durations of actions  colin therefore
significantly extends the competence of other pddl compliant temporal planners 

   c rikey   a forward chaining temporal planner
temporal forward chaining planners have two kinds of choices to make during the construction of
plans  firstly  as in the non temporal case  a choice must be made of which actions to apply  these
choices can be considered to be the planning element of the problem   secondly  choices must
be made of when to apply the actions  these can be seen as the scheduling choices in construction of solutions   crikey    coles  fox  long et al       a   a temporal forward chaining planner 
exploits the distinction between these choices  using separate procedures to make the planning decisions  which actions to start or end  and the scheduling decisions  when to place actions on the
timeline   both of these decisions must be checked for consistency with respect to the existing
temporal constraints to confirm that all the actions can be completely scheduled  in this section 
we briefly describe how crikey   performs planning and scheduling  since its architecture forms
the basis for colin and the work subsequently described in this paper  full details of temporal
management in crikey   are provided by coles et al 
crikey   uses a forward chaining heuristic state space search to drive its planning decisions  it
makes use of the enforced hill climbing  ehc  algorithm introduced in ff  hoffmann   nebel 
      and repeated  for convenience  as algorithm    ehc is incomplete  so if a solution cannot
be found crikey   plans again  using a weighted a  search  we now discuss how the search described within the basic enforced hill climbing algorithm of ff can be extended to perform temporal
planning  in order to do this  a number of modifications are required  in particular 
   get applicable actions s   the planner must reason with two actions per durative action  a
start action and an end action  rather than applying an action and immediately considering it
to have finished  as in the non temporal case  
   get applicable actions s   apply a  s   invariant conditions of durative actions must be
maintained throughout their execution  which requires active invariants to be recorded in the
state in order to prevent the application of actions that conflict with them 
   is goal state s   for a state to be a goal state  i e  for the path to it to be a solution plan  all
actions must have completed 
  

fic olin   p lanning with c ontinuous c hange

algorithm    enforced hill climbing algorithm
data  p   ha  i  gi   a planning problem
result  p   a solution plan
  best heuristic  evaluate heuristic i  
  if best heuristic     then
 
return    
  closed   i  
  open list   hi    i  
  while open list       do
 
hs  p i  element removed from the front of open list 
 
applic s   get applicable actions s  
apply helpful filter  applic s   
 
  
foreach a  applic s  do
  
s    apply a  s  
  
if s     closed then
  
add s   to closed  
  
p    p followed by a 
if is valid plan p     then
  
  
if is goal state s     then
  
return p    
  
  
  
  
  
  
  
  

  

h  evaluate heuristic s     
if h   best heuristic then
open list   hs     p   i  
best heuristic  h 
break 
else
if h    then
append hs     p   i onto open list 

return with f ailure 

   is valid plan p    the temporal  scheduling  constraints of candidate plans must be respected 
in particular  the duration constraints of durative actions must be satisfied  this is discussed
in section     
we consider each of these modifications in turn  first  durative actions are compiled into
two non temporal actions  a modified version of the lpgp action compilation  long   fox 
    a  is used for this  as described by coles et al          each durative action a  of the form
hdur   pre     eff     pre    pre a   eff a i  is split into two non temporal  in fact  instantaneous  snap
actions of the form hpre  eff i 
 a    hpre     eff   i
 aa   hpre a   eff a i
  

fic oles   c oles   f ox   l ong

by performing search with these snap actions  and taking appropriate care to ensure that the
other constraints are satisfied  the restrictions on expressivity imposed by the use of action compression are avoided  it becomes possible to search for a plan in which the start and end points
of different actions are coordinated  solving problems with required concurrency  the price for
this is that the search space is much larger  each original action is replaced by two snap actions 
so the length of solution plans is doubled  in some circumstances this blow up can be avoided
by identifying actions that are compression safe  coles  coles  fox    long      a   i e  those
for which the use of action compression does not compromise soundness or completeness  in the
approach described by coles et al   these actions are still split into start and end snap actions  but
the end points of compression safe actions are inserted when either their effects are needed or their
invariants would otherwise be violated by another action chosen for application  as a consequence 
only one search decision point is needed per compression safe action  choose to apply its start  
rather than two  recent versions of both crikey   and colin make use of this restricted action
compression technique in search 
having split actions into start and end points  modifications to the basic search algorithm are
needed to handle the constraints that arise as a consequence  crikey   makes use of an extended
state representation  adding two further elements to the state tuple  the resulting state is defined as
s   hf  p  e  t i  where 
 f represents the facts that hold in the current world state  a set of propositions that are
currently true  w   and a vector  v  recording the values of numeric variables 
 p is an ordered list of snap actions  representing the plan to reach s from the initial state 
 e is an ordered list of start events  recording actions that have started but not yet finished 
 t is a collection of temporal constraints over the actions in the plan to reach f  
the purpose of the start event list e is to record information about the currently executing
actions  to assist in the formation of sound plans  each entry e  e is a tuple hop  i   dmin  dmax i
where 
 op is the identifier of an action  for which the start snap action op  has been added to the plan 
 i is the index at which this snap action was added in the plan to reach s 
 dmin  dmax are the minimum and maximum duration of op  determined in the state in which
op is started 
the minimum and maximum duration of an action can depend on the state in which it is applied
 e g  the duration of a recharge action may depend on the level of charge at the time of execution  
so durations must be computed based on the state preceding step i  however  once a given action
has started  the bounds on the duration remain fixed  pddl     also allows actions to have durations
constrained by conditions that hold at the end of the action  but such actions are not supported by
our planners 
this extended state definition leads to corresponding extensions to get applicable actions s  
as before  a snap action is deemed to be logically applicable in a state s if its preconditions pre
are satisfied in s  however  an additional condition must be satisfied  its effects must not violate
  

fic olin   p lanning with c ontinuous c hange

any active invariants  the invariants active in a given state are determined from e  we denote the
invariants in a state s with event list e as 
inv s     e op pre 
ee

to apply the end snap action  aa   there is required to be an entry e  e whose operator entry
op is equal to a  this prevents the planner from attempting to apply the ends of actions that have
not yet been started 
assuming an action  a  is found to be applicable and chosen as step i of a plan  the function
apply a  s   applied to a temporally extended state  s  yields a successor s     hf     p     e     t   i 
the first two elements are updated as in the non temporal case  f     apply a  f    and p     p   a  
to obtain t     we begin by setting t     t   furthermore  if i     
t     t       t i   t i     
where t i  is the variable representing the time at which step i is scheduled to be executed  that
is  the new step must come at least   a small unit of time  after the preceding step  this separation
respects the requirement that interfering actions must be separated by at least   fox   long        
but it is strictly stronger than required where actions are not actually mutually exclusive  a more
accurate realisation of the pddl     semantics could be implemented  but it would incur a cost while
offering very little apparent benefit  finally  the resulting value of e    and whether t   is changed
further  depends on whether a is a start or end snap action 
 if a start action a  is applied  e     e    ha  i  dmin  dmax i   where dmin and dmax correspond to the lower  and upper bounds of the duration of a  as evaluated in the context of
valuation f  
 if an end action aa is applied  a start entry  e  e   e op   a  is chosen  and then e   is
assigned a value e     e   e  it will often be the case that there is only one instance of an
action open  so there is only one choice of pairing  but in the case where multiple instances
of the same action are executing concurrently  search branches over the choice of each such
e  for the e chosen  a final modification is then made to t   to encode the duration constraints
of the action that has just finished 
t     t     e dmin  t i   t e i   e dmax  
with this information encoded in each state about currently executing actions  the extension
needed to is goal state s  is minor  a state s is a goal state if it satisfies the non temporal version
of is goal state s   and if the event list of the state  e  is empty 
this search strategy leads to a natural way to handle pddl     timed initial literals  tils 
directly  dummy til actions are introduced  comprising the effects of the tils at each time
point  and these can be added to the plan if all earlier til actions have already been added  and if
they do not delete the invariants of any open action  as a special case  til actions do not create
an entry in e  only the facts in f are amended by their execution  they do  however  produce an
updated set of temporal constraints  as with snap actions  if a til is added as step i to a plan  the
til must fall no earlier than  after the preceding step  then  t     t     ts  t i   t    ts  
  

fic oles   c oles   f ox   l ong

where ts is the time stamp at which the til is prescribed to happen   is the name denoting the
start of the plan and t        as can be seen  these constraints ensure that the til can only occur
at an appropriate time  that any step prior to the til must occur before it  and that any step after the
til must occur after it 
the changes described in this subsection ensure that the plans produced by crikey   are logically sound  the check for logical applicability  coupled with the maintenance of e throughout
search  ensures that no preconditions  either propositional or numeric  can be broken  use of
get applicable actions s  only guarantees that actions are logically applicable  there is no guarantee that adding a snap action to the plan  judged applicable in this way  will not violate the
temporal constraints  for example  it is possible that all preconditions are satisfied in the plan
p    a    b    ba   aa    so that p is logically sound  however  if the duration of b is greater than
the duration of a then p is not temporally sound  in the next section we discuss how the function
is valid plan p   is modified to identify and reject temporally inconsistent plans 
    temporal plan consistency
a state s is only temporally consistent if the steps      n     in the plan  p   that reaches it can be
assigned values  t      t n       representing the times of execution of each of the corresponding
steps  respecting the temporal constraints  t   this is checked through the use of is valid plan p     
called at line    of algorithm    this function call is trivial in the non temporal case  but in the
temporal case serves to check the temporal consistency of the plan  any state for which the temporal
constraints cannot be satisfied is immediately pruned from search  since no extension of the action
sequence can lead to a solution plan that is valid 
the temporal constraints t built by crikey   in a state s are each expressed in the form 
lb  t b   t a   ub

where lb  ub    and    lb  ub

these constraints are conveniently expressible as a simple temporal problem  stp   dechter 
meiri    pearl         the variables within the stp consist of the timestamps of actions  and
between them inequality constraints can be specified in the above form  crucially  for our purposes 
the validity of an stp  and the assignment of timestamps to the events therein  can be determined
in polynomial time by solving a shortest path problem within a simple temporal network  stn  
a directed graph representation of an stp  each event in the stp is represented by a vertex in the
stn  there is an additional node t   to represent time   and the time of the first action in the
plan  t     is constrained to fall within  of t    each constraint in the above form adds two edges
to the graph  one from a to b with weight ub  and one from b to a with weight lb  attempting
to solve the shortest path problem from t   to each event yields one of two outcomes  either it
terminates successfully  providing a time stamp for each step  or it terminates unsuccessfully due
to the presence of a negative cost cycle within the stn indicating a temporal inconsistency  any
schedule would require at least one step to be scheduled before itself  
in crikey    an stp is used to check the temporal consistency of the choices made to reach
each step s  based on the temporal constraints t that must hold over the plan p to reach s  and
additional constraints that can be determined from e  the list of actions that have started  but not yet
finished  the variables vars in the stp can be partitioned into two sets  the t variables  t i  for
step i  p and the f  variables  one f  i  for each entry hop  i  dmin  dmax i  e  the t variables
correspond to the times of steps that have already been added to the plan  which might be the times
  

fic olin   p lanning with c ontinuous c hange

of start or end points of actions  some of these time points might correspond to the starts of actions
that have not yet finished and it is this subset of actions  only  that will have associated f variables
associated with the pending end times of those actions  for consistency with the terminology we
introduced in crikey    coles  fox  long et al       a   we use now to refer to the time at which the
next event in the plan will occur  which could be during the execution of the last actions applied  
it is the time point at which the next choice is to be made  either the start of a new action or the
completion of an existing one  and can therefore be seen as the time associated with the final state 
s  generated by the current plan head  there is only ever one timepoint called now and its value
moves forward as the plan head extends  the constraints are then as follows 
 t   constraining the t variables  these ensure the temporal consistency of the steps in the
plan to reach s  and include any constraints introduced for timed initial literals  
  dmin  f  i   t i   dmax   hop  i  dmin  dmax i  e   that is  for each future
action end point that has been committed to  but has yet to be applied   the recorded duration
constraint must be respected 
    f  i   t n       hop  i  dmin  dmax i  e   that is  each future action end point
must come after the last step in the current plan  to ensure it is in the future 
 t now    t n        that is  the current time  the time at which the next event in the
plan can occur  is at least  after the last event in the plan 
solving this stp confirms the temporal consistency of the decisions made so far  if the stp
cannot be solved  the state s can be pruned  the plan induced from the startend action representation is temporally invalid  the last two of these categories of constraints are particularly important 
without them  pruning could only be undertaken on the basis of the plan p to reach s  including
them  however  allows the stp to identify cases where the end point of an action can never be added
to the plan  as doing so would lead to temporal inconsistency  as goal states cannot contain any
executing actions  i e  e must be empty   this allows crikey   to prune states earlier from which
there can definitely be no path to a state in which all end points have been added to the plan 
timed initial literals are easily managed in the stp using the dummy til actions described
earlier  the constraints for each dummy til action that has already been applied are included in t  
each dummy til action yet to occur is automatically treated as the end of an action that has yet to
be applied  thus  an f variable is added for each  and in doing so  the last step in the plan so far is
constrained to come before each til event that has yet to happen 

   planning with continuous numeric change
the most challenging variants of temporal and numeric problems combine the two to arrive at problems with time dependent metric fluents  although problems exhibiting hybrid discrete continuous
dynamics have been studied in other research communities for some time  for example  in verification  yi  larsen    pettersson        henzinger  ho    wong toi        henzinger        
where timed automata capture exactly this kind of behaviour  there has been relatively little work
on continuous dynamics in the planning community 
in pddl     the model of mixed discrete continuous change extends the propositional state transition model to include continuous change on the state variables  there is a state transition system
  

fic oles   c oles   f ox   l ong

in which discrete changes transition instantaneously between states  while the system is in a particular state  continuous change can occur on the state variables and time passes  as soon as a discrete
change occurs the system changes state  in pddl    fox   long        this is extended to allow
exogenous events and processes  controlled by nature  as well as durative actions  this leads to
a formal semantics that is based in the theory of hybrid automata  henzinger         an action
causes a discrete state change which might trigger a continuous process  this continues over time
until an event is triggered leading into a new state  some time later another action might be taken 
early work exploring planning with continuous processes includes the zeno system of penberthy and weld         in which processes are described using differential equations  zeno suffers
from the same limitations as other partial order planners of its time  being unable to solve large
planning problems without significant aid from a carefully crafted heuristic function  more importantly  a fundamental constraint on its behaviour is that it does not allow concurrent actions to apply
continuous effects to the same variable  this imposes a very significant restriction on the kinds
of problems that can be solved  making zeno much less expressive than colin  this constraint
follows  in part  from the way that the model requires effects to be specified as differential equations  rather than as continuous update effects  so that simultaneous equations must be consistent
with one another rather than accumulating additive effects  as the authors say we must specify the
entire continuous behaviour over the interval  of the durative action  as our semantics insist that all
continuous behaviours are the result of direct  explicit action 
another early planner to handle continuous processes is mcdermotts o ptop system  mcdermott         which is a heuristic search planner  using a regression based heuristic  the plausible
progression technique used within o ptop to guide search is not sufficiently powerful to recognise
interactions that could prevent future application of actions  thereby restricting its scalability on
problems of the form we consider here  o ptop competed in the international planning competition in       where it solved only a small subset of the problems  although  interestingly  those it
solved involved an expressive combination of adl and temporal windows that no other planner
could manage   o ptop is an interesting variant on the heuristic forward search approach  since it
avoids grounding the representation  using an approach that is similar to a means ends linear planning approach to generate relaxed plan estimates of the number of actions required to achieve the
goal from a given state 
    tm lpsat
more recently  shin and davis developed tm   lpsat  shin   davis         based on the earlier
lpsat system  wolfman   weld         t m   lpsat was the first planner to implement the pddl  
semantics  it is implemented as a compilation scheme by which a horizon bounded continuous
planning problem is compiled into a collection of sat formulas that enforce the pddl   semantics 
together with an associated set of linear metric constraints over numeric variables  this compiled
formulation is then passed to a sat based arithmetic constraint solver  lpsat  l psat consists of
a dpll solver and an lp solver  the sat solver passes triggered constraints to the lp solver 
which hands back conflict sets in the form of nogoods if the constraints cannot be resolved  if there
is no solution the horizon is increased and the process repeats  otherwise the solution is decoded
into a plan  in order to support concurrency the compilation exploits the lpgp separation of action
start and end points  there are different versions of tm   lpsat exploiting different solvers  lpsat
and mathsat     audemard  bertoli  cimatti  kornilowicz    sebastiani        have both been
  

fic olin   p lanning with c ontinuous c hange

exploited  the novelty of tm   lpsat lies in the compilation and decoding phases  since both solvers
are well established systems 
the compilation scheme of tm   lpsat implements the full pddl   semantics  although this
includes events and processes  which are specific to pddl    tm   lpsat can also handle variable duration durative actions  durative actions with continuous effects and duration dependent end effects 
the continuous effects of concurrent actions on a quantity between two time points are summed
over all actions active on the quantity over the period  therefore  tm   lpsat supports concurrent
updates to continuous variables 
t m   lpsat is an interesting approach  in theory capable of solving a large class of problems
with varied continuous dynamics  however  reported empirical data suggests that the planner is
very slow and unable to solve problems requiring plans of more than a few steps  it is not possible
to experiment further because there is no publicly available implementation of the system 
    kongming
hui li and brian williams have explored planning for hybrid systems  li   williams              
this work has focussed on model based control  using techniques based on constraint reasoning 
the continuous dynamics of a system are modelled as flow tubes that capture the envelopes of the
continuous behaviours  leaute   williams         the dimensions of these tubes are a function
of time  typically expanding as they are allowed to extend   with the requirement being made that
successive continuous behaviours must be connected by connecting the start of one tube  the precondition surface  to the cross section of the preceding tube  i e  the intersection of the two spaces must
be non empty  the most relevant work in this area is in the development of the planner kongming 
described by li and williams 
kongming solves a class of control planning problems with continuous dynamics  it is based
on the construction of fact and action layers and flow tubes  within the iterative plan graph structure
introduced in graphplan  blum   furst         as the graph is developed  every action produces
a flow tube which contains the valid trajectories as they develop over time  starting in a feasible
region  actions whose preconditions intersect with the feasible region can be applied and the reachable states at any time point can be computed using the state equations of the system  in the initial
state of the system all the variables have single known values  a valid trajectory must pass through
a sequence of flow tubes  but must also meet the constraints specified in the dynamics of the actions
selected  the mutex relation used in graphplan is extended to the continuous dynamics as well as
the propositional fragment of the language  the graph is iteratively extended as in graphplan  with
a search for a plan conducted after each successive extension 
the plan graph encoding of a problem with continuous dynamics is translated into a mixed
logical quadratic program  mlqp   the metric objective functions used by the planner to optimise its behaviour can be defined in terms of quadratic functions of state variables  an example
problem considered by li and williams        is a   d representation of a simple autonomous underwater vehicle  auv  problem where the auv can glide  ascend and descend while avoiding
obstacles  the language used is a version of pddl     extended to enable dynamics to be encoded 
the continuous nature of the problem lies in the fact that  after a continuous action  the auv will
be in one of a continuous range of positions determined by the control system  because kongming
depends on translation of the planning problems into mlqps the constraints describing the dynamics of the problem must be linear  since the effects of continuous actions involve the product of rate
  

fic oles   c oles   f ox   l ong

of change with time  only one of these values can be treated as a variable  in kongming it is the
rate of change that is variable  but time is discretised  which contrasts with colin in which rates
of change remain constant over continuously variable length intervals  the discretisation of time in
kongming is exploited to support state updates within the plan graph  successive layers of the graph
are separated by a constant and uniform time increment  this approach suffers from a disadvantage
that the duration of a plan is limited by the number of happenings in the plan  since the solver cannot
realistically solve problems with more than a few tens of layers in the plan graph 
kongming does not support concurrent continuous updates to the same state variable  so  in
this respect  pddl     is more expressive than the extended language used in kongming  in part
this is due to a difficulty in resolving precisely what is the semantics of the dynamics described in
the actions used by kongming  each dynamic constraint specifies limits on the rate of change of a
specific variable  it is unclear whether concurrent actions should be combined by taking the union
or the intersection of the bounds each constraint specifies on the rate of change of a given fluent 

    upmurphi
one other recently developed planner that uses pddl     and reasons with continuous processes is
upmurphi  penna  intrigila  magazzeni    mercorio         upmurphi takes a completely different approach to those considered so far  instead of reasoning about continuous change directly 
upmurphi works by guessing a discretisation and iteratively refining it if the solution to the discretised problem does not validate against the original problem specification  the iterative driver is the
coarseness of the discretisation  as well as the planning horizon  making it an interestingly different
basic architecture from tm   lpsat 
upmurphi begins with the continuous representation of the problem and starts by discretising it 
first the actions are discretised by taking specific values from their feasible ranges  this results in
several versions of each action  then upmurphi explores the state space  by explicitly constructing
it under the current discretisation  plans are constructed using the planning as model checking
paradigm  cimatti  giunchiglia  giunchiglia    traverso         there is no heuristic to guide
search  once a plan has been found it is then validated against the original continuous model  using
the plan validator  fox  howey    long         if it is invalid  the discretisation is refined and the
search resumes  if upmurphi fails to find a plan at one discretisation it starts again at a finer grained
discretisation  subsequent refinements lead to ever denser feasible regions  but they are increasingly
complex to construct 
upmurphi can be used to build partial policies to handle the uncertainty that is likely to arise
in practice during the execution of hybrid control plans  a controller table is initially synthesised 
consisting of the  state action  pairs of the plan it first constructs  however  this table might lack
some of the states that could be visited by the controller  so it is not robust  the subsequent step is
to robustify the controller by randomly perturbing some of the states and finding new paths from
these new states  because some of the perturbed states are not reachable  a probability distribution
is used to identify the most likely ones  these are called the safe states  the controller table is
then extended with the safe  state  action  pairs  the controller table  or policy  is referred to as a
universal plan 
  

fic olin   p lanning with c ontinuous c hange

    other approaches to continuous reasoning
a completely different way to manage continuous quantities is to model continuous resource consumption and production in terms of uncertainty about the amount consumed or produced  this
is the approach taken in the hao  algorithm  meuleau  benazera  brafman  hansen    mausam 
      where a markov decision process  mdp  is constructed consisting of hybrid states  each
state contains a set of propositional variables and also a collection of distributions over resource
consumption and production values  because the states are hybrid  standard value iteration approaches cannot be used to find policies  a hybrid ao  approach is described which can be used to
find the best feasible policy  the feasible region constructed by hao  is a continuous distribution
of resource values and the resource is considered to be uncontrollable  unlike in kongming  where
it is assumed that the executive maintains control over which values in the region are eventually
chosen  
planning with continuous processes has important applications and  as with many other application areas of planning  this has led to the development of systems that combine generic planning
technology with more carefully tuned domain specific performance to achieve the necessary combination of problem coverage and performance  a good example of this is the work by boddy and
johnson        and colleagues  lamba et al         on planning oil refinery operations  this work
uses a quadratic program solver  coupled with heuristically guided assignment to discrete decision
variables  corresponding to actions   to solve real problems 

   colin  forward chaining planning with continuous linear change
in this section we will describe how crikey   is extended to reason with duration dependent and
continuous numeric change  building the planner colin   for continuous linear dynamics   we
decided to give the planner a specific name to highlight its capabilities  as demonstrated in section      the key difference introduced with continuous numeric change is that logical and numeric
constraints can no longer be neatly separated from temporal constraints  the values of the numeric
variables in a state depend on the timestamps and durations of actions  and vice versa  the relative
benefits of handling temporal and numeric constraints together  rather than separating them out  are
apparent in the motivating domains outlined in section   and have been amply rehearsed in the
paper describing pddl    fox   long        
the need to cope with integrated numeric and temporal constraints raises a number of important
issues for planning with these domains  first  checking whether an action choice is consistent can
no longer be achieved using an stp  as the numeric constraints now interact with the temporal
constraints  and an stp is not sufficiently expressive to capture this  second  the changing values
of numeric variables over time brings new challenges for determining action applicability  if a
precondition is not satisfied immediately following the application of an action  it might become
satisfied after allowing a certain amount of time to elapse  finally  there is the need to provide
heuristic guidance  we will cover the first two of these issues in this section  and defer discussion
of the heuristic guidance to the next 
    temporal numeric plan consistency through linear programming
we begin with the problem of temporal numeric plan consistency  as the techniques used in dealing
with this issue can also be amended for use in solving the issues encountered when determining
  

fic oles   c oles   f ox   l ong

action applicability  considering the definition of the stp given in section      we make the observation that the stp could equally well be written as a linear program  lp   in crikey    the
stp is more efficiently solved using a shortest path algorithm  however  this observation becomes
important when we wish to reason with continuous change in numeric resources alongside the temporal constraints  in this case  we can use an lp to capture both temporal constraints and numeric
constraints  including the interaction between the two  we will now describe how the lp is built 
serving as a replacement for the is valid plan s  function called during search  which invokes the
stp solver in crikey    a diagram of the structure of the lp we create is shown in figure    for
a plan p    a         an    an    to reach a state s  where an  is the action most recently added to
the plan   for simplicity  it shows a case where the event queue e is empty  
the construction of the lp begins with the variables and  a subset of  the constraints of the
stp  each stp variable ti  the time stamp of the  snap  action ai   has a corresponding lp variable
stepi  shown across the top of figure     and each stp variable ei  for the future end of the action
at step i  has a corresponding lp variable estep i   we also construct the constraints corresponding
to the total ordering of action steps  just as in the stp  each step in p is still sequenced  i e   
stepi  stepi  for all n   i       and each future end snap action has to be later than stepn 
 i e    estepi  stepn  for all estep variables  
we then extend the lp with the numeric constraints of the problem  beginning with the effects
of actions  since numeric effects can be both discrete and continuous  we create two additional
vectors of variables per step in the plan  the first of these  vi   represents the values of the state
variables v immediately prior to ai being executed  in the case of step    vi is equal to the values of
v in the initial state  i   the second  vi    contains the values of v immediately after ai is executed 
in figure    the variables in v  are enumerated as v     vm  and  similarly  those in v    are shown
 
as v      vm 
  to avoid proliferation of indices we do not further index these values with their
time stamp in figure    so vi is the ith value in v at the time step corresponding to the layer in
which the variable appears  the use of two vectors at each layer is required in order to represent
discrete changes caused by actions  a snap action can cause the value of a variable to be different
immediately after its execution  to represent this within the lp  if an action at step i has no effect
on a variable v then vi    vi     otherwise  for a discrete effect hv     w  v   k   duration    ci  a
constraint is introduced to define the value of vi    
vi    vi   w  v   k  ce i   cs i     c
where the functions cs i  and ce i  denote the time stamp variables for the corresponding start and
end of the action at step i  if step i is the end of an action  then ce i    step i   and cs i  is the
step variable for the start of the action that finished at step i  similarly  if step i initiates an action 
then cs i    step i   and ce i  is either estep i if the action has not yet finished or  otherwise  the
step variable for the end of the action started at step i  therefore  substituting ce i   cs i  for
 duration captures the relationship between the effect of the action and its duration 
   note that identities such as this are implemented efficiently by simply not introducing the unnecessary additional
variable  similarly  while a variable is subject to no effects or conditions it is not added to the lp  but it is only
introduced once it becomes relevant 
   for effects using the operator     i e  decrease effects  all but the first term on the right hand side are negated  for
assignment effects  where the operator is    the first term on the right hand side  i e  vi   is omitted entirely  the value
of v after such an assignment does not depend on the value of v beforehand  

  

fic olin   p lanning with c ontinuous c hange

metric fluents v   to v m 
snapactions   to n  and corresponding timepoint variables

v 

v 

v 

v 

v 

v 

v 

v 

v 

v 

v 

v 

v 

v 

v 

v 

v

v

v

v

v

v

a 

v 

v 

v 
step  

v 

v m 

v m 

state  

state  

v
a n 

step n 

 

v 
   

v m 

 

   

v m 

 

a 

   

v m 

 

   


v m 

step  

 

   

   

step  

a 

v 

   

   
state  

 

v 

v 

v m 

 

v m 
state n

   

 

   

v

active continuous change affecting  some  variables
actions cause instantaneous step changes in fluent values
temporal constraints
actions are sequenced and separated 
step i   stepi    
where action i starts a durative action  a  that is ended by action j 
dmin a     step j  step i    dmax a 
metric variable constraints  step effects

metric variable constraints  continuous effects

variables are updated by action effects 

variables are updated by active continuous effects 
v j   vj    vj  stepi    stepi  

v j in state i   is v j in state i updated by effect of a i
including timedependent stepeffects

for values in state i    where  v j is determined by the
accumulated effects of active continuous effects

figure    diagrammatic representation of the lp used in colin  note that the subscripts attached
to the v and v   fluents in this diagram are indices into the vector of fluents in the state 
while indices on step and a represent different time steps in the plan  the metric fluents
are also notionally indexed by the time step  but this is not shown in the diagram in order
to avoid clutter 

continuous numeric change occurs between the steps in the plan  rather than at the instant
of execution of the step itself  to capture continuous effects  when building the lp we consider
each step in turn  from the start of the plan  recording the gradient of the total  linear  continuous
change acting upon each variable v  v  where v denotes the gradient active after ai  and before
the execution of action ai   under the restrictions on the language handled by colin  described
in section    and the total order constraints between snap actions  the value of each variable vi
is known and constant within each interval between successive actions  all continuous change is
linear  the gradient on a variable v can only be changed by either starting an action  initiating an
  

fic oles   c oles   f ox   l ong

adjustment to the prevailing continuous effect on v given by dv
dt    k  for some k     or ending an
action  terminating the effect initiated by its start   the values of the  constants can be computed
as follows   
 for all variables  v       that is  there is no continuous numeric change active on any
variable before the start of the plan 
 if ai has no continuous numeric effect on v then vi     vi  
 if ai initiates a continuous numeric effect 

dv
dt

 if ai terminates a continuous numeric effect 

   k  then vi     vi   k 
dv
dt

   k  then vi     vi  k 

on the basis of these values  we now add constraints to the lp 
vi     vi    vi    step i    step i  
again  the distinction between vi and vi  is important  vi is determined on the basis of any continuous
change in the interval between steps i and i     but immediately prior to any discrete effect that
may occur at that step 
having created variables to represent the values of fluents at each step and having introduced
constraints to capture the effects of actions on them  we now consider the constraints that arise from
the preconditions of each snap action  the invariants that must be respected between the starts and
ends of actions  and any constraints on the durations of each of the actions in the plan  for each
numeric precondition of the form hv           w  v   ci  that must hold in order to apply step i 
we add a constraint to the lp 
vi        w  vi   c
for an action a starting at stepi and ending at stepj   the invariants of a are added to the lp in
 
this form  once for each of the vectors of variables  vi    vj 
  and  vi     vj    vi and v  j are excluded
because the pddl     semantics does not require invariants of an action to hold at its end points   in
the case where the end of the action a  starting at i  has not yet appeared in the plan  the invariants of
a are imposed on all vectors of variables from vi  onwards  as a must end in the future  its invariants
must not be violated at any step in the current plan after the point where it started 
finally  we add the duration constraints  for an action a starting at stepi   we denote the variable
corresponding to the time at which a finishes as ce i   where ce i    step j if the end of the action
has been inserted into the plan at step j  or ce i    estep i otherwise  as defined above   then  for
each duration constraint of a  of the form h duration           w  v   ci  we add a constraint 
ce i   step i        w  vi   c
this process constructs a lp that captures all the numeric and temporal constraints that govern
a plan  and the interactions between them  as with the stp in crikey    a solution to the lp
contains values for the variables  step      step n    i e  an assignment of time stamps to the actions in
the plan  to prevent the lp assigning these variables arbitrarily large  but valid  values  we set the
   variables that can be trivially shown to be constant  i e  where no action has an effect referring to that variable  can
be removed from the lp and replaced throughout by their values in the initial state 

  

fic olin   p lanning with c ontinuous c hange

plan action

delta value lp variable
m     

savehard start

lp constraints

step 

  

m 

  

m  
m     
takemortgage start
m   

 
 

  m 

 

step 

 step    

 step      

m 

  m        step   step   

 

m  

  m    

 

step 
m 

lifeaudit start
m   

 
 

savehard end

  step    
 

m  

 

 
    step 

 step        step      

 step   

m  

  m 

step 

 step    

m 

  m          step   step   

m     

 

 

 step    
 

m  



 
    step 

  step        step     

 step   

m  
lifeaudit end

 

 

  m 

step 
m 

takemortgage end

 

  step        step      
 step     

m  
m       

 

  m 

step 

 step    

  step     

m 

  m       step   step   

 

m  

  m 

table    variables and constraints for the borrower problem
lp objective function to be to minimise step n   where an is the last step in the plan so far  for the
purposes of the is valid plan s  function  if the lp built for a plan p to reach a state s cannot be
solved  we can prune the state s from the search space and need not consider it any further  there is
no path from s to a legal goal state  in this way  the lp scheduler can be used as a replacement for
the stp in order to determine plan validity 
    example  lp for the borrower problem
in order to illustrate lp construction for a plan we consider the example borrower problem introduced in section      recall that one solution plan for this problem has the following structure 
  
  
  
  
  
  

savehard start
takemortgage start longmortgage
lifeaudit start
savehard end
takemortgage end longmortgage
lifeaudit end 

the lp for this six step borrower solution plan contains the variables and constraints shown in
table    the six step variables represent the time stamps of the six snap actions in the plan  and the
variable m represents the money that has been saved by the borrower  in the initial state  m     
  

fic oles   c oles   f ox   l ong

and hence m       starting the savehard action has no instantaneous numeric effects  introducing
the constraint m     m   if it did have an effect on m  for instance an instantaneous increase in the
savings by k  then the constraint would be m     m    k   due to the invariant condition of the
savehard action  that the savings remain above zero  the constraint m      is added  it can be seen
this constraint is duplicated for each mi and m i during the execution of the savehard action  to
ensure that the invariant continues to hold  notice  also  when the action takemortgage is started 
the invariant for that action  the savings level remains less than or equal to the maxsavings cap 
also appears  and applies to all values of m during its execution  additional constraints capture
discrete change by connecting the value of m i to mi   in most cases in this example these values
are equal  but one constraint shows a discrete effect  m     m     captures the deduction of the
deposit caused by initiating the takemortgage action 
as previously described  the temporal constraints in the lp take two forms  first  there are
constraints of the form step i    step i     forcing step i   to follow step i   enforcing the sequencing of the snap actions  second  duration constraints restrict the duration of actions  e g 
step    step       forces that step   the end point of savehard  occurs precisely    units  the
duration of savehard  after step    its start snap action 
the final constraints to consider are those modelling the continuous numeric change  the first
constraint of this type gives the value of m  after the execution of savehard start and before
the execution of takemortgage start  this constraint  m    m        step   step     is based
on the value of m    which is    the only action currently executing with continuous change on
m is savehard  which increases it by   per unit of time  the second such constraint  m   
m          step   step     is based on the value of m  which is now                 found by adding
the active gradients from both of the actions that have started but not yet finished  this illustrates
how two actions can have active linear continuous effects on the same variable simultaneously  note
that when savehard end is applied  at step    the gradient of continuous change  m    becomes
    as the only active continuous effect is now that of the takemortgage action 
solving the temporal constraints in this problem without considering the metric fluents yields
a solution in which step       step      step           step        step          and
step            unfortunately  this proposal violates the constraint m       since 
m     m       m        step   step         m                       
and      the constraint on the start time of the takemortgage action cannot be identified
because it is dependent on the discrete initial effect of that action  the active continuous effect of
the savehard action and the invariant of savehard  this simple example illustrates the strength
of using the lp to perform the scheduling alongside the resolution of numeric constraints  the
timestamps then satisfy both temporal and numeric constraints 
    temporalnumeric search
when performing state space search  a state  s  is a snapshot of the world along some plan trajectory  coming after one action step and before another  in the absence of continuous numeric change 
the valuations that define s are known precisely  both which propositions hold  and the values of
the numeric variables v  in the presence of continuous numeric change  however  the same does
not hold  if a variable v is undergoing continuous numeric change  or is subject to active durationdependent change  the valuations in a state depend on which snap actions have been applied so far 
  

fic olin   p lanning with c ontinuous c hange

on the times at which those snap actions were applied and on how much time has passed since the
last action was applied  within our representation of the state the time stamps of the snap actions in
the plan are not fixed  during plan construction  the lp is used only to confirm that the plan can be
scheduled subject to the current constraints   so the valuation of numeric fluents in s is constrained
only within ranges determined by the constraints on the temporal variables and the interactions
between them 
as a consequence of the flexibility in the commitment to values for temporal and continuously
changing variables  colin requires a different state representation to the one used in crikey   
rather than representing the values of the numeric variables by a single vector v  we use two
vectors  vmax and vmin   these hold the maximum and minimum values  respectively  for each
numeric variable in s  the computation of these bounds on variables can be achieved using a small
extension of the lp described in section      for a state s  reached by plan p  where an is the
last step in p    we add another vector of variables to the lp  denoted vnow   and another time stamp
variable  step now   the variables in vnow represent the values of each state variable at some point
 at time step now   along the state trajectory following an   the numeric variables and time stamp for
now are constrained as if it were an additional action appended to the plan 
 now must follow the previous step  i e  stepnow  stepn  
 now must precede or coincide with the ends of any actions that have started but not yet
finished  i e  for each estep i   estep i   step now
 for each variable vnow  vnow   we compute its value based on any continuous numeric
change 
vnow   vn    vnow  stepnow  stepn  
 finally  for every invariant condition hv           w  v   ci of each action that has started
but not yet finished 
vnow        w  vnow   c
the lp can then be used to find the upper and lower bounds on variables  for each of the variables vnow  vnow   two calls are made to the lp solver  one with objective set to to maximise vnow  
and one to minimise vnow   these are then taken as the values of vmax and vmin in s  in the simplest case  where a variable v is not subject to  direct or indirect  continuous or duration dependent
change  the value of v is time independent  so vmax   vmin   and its value can be determined
through the successive application of the effects of the actions in p   i e  the mechanism used in
crikey    or indeed classical  non temporal  planning 
since we have upper and lower bounds on the value of each variable  rather than a fixed assignment  the action applicability function  get applicable actions s   must be modified  in crikey   
an action is said to be applicable in a state s if its preconditions are satisfied  in colin  the definition
of what it means for a numeric precondition to be satisfied is different  to preserve completeness 
we employ the mechanism used in metric relaxed planning graphs  as discussed in more detail in
section b  specifically  for a numeric precondition w  x  c  we calculate an optimistic value for
w x by using the upper bound on a v  x if its corresponding weight in w is positive  or  otherwise 
using its lower bound  then  if this resulting value is greater than or equal to c  the precondition is
considered to be satisfied   as before  for numeric conditions w  x  c  an equivalent precondition in the appropriate form can be obtained by multiplying both sides of the inequality by   and
  

fic oles   c oles   f ox   l ong

plan action

delta value lp variable
m     

savehard start

lp constraints

step 

  

m 

  

m  
m     
takemortgage start
mnow  

 
 

  m 

 

step 

 step    

 step      

m 

  m        step   step   

 

m  

  m    

 

 step    

stepnow

now

mnow

 

m now

m  

 

 
    stepnow

  mnow

 step   

 

 step        step      
 

 

 

 

table    variables and constraints for the first stages of the borrower problem
constraints of the form w  x   c are replaced with the equivalent pair of conditions w  x  c 
w  x  c  
this test for applicability of an action is relaxed  so it serves only as a filter  eliminating actions
that are certainly inapplicable  for instance  a precondition a   b    could be satisfied if the upper
bounds on a and b are both    even if the assignment of timestamps to actions within the lp to attain
a     conflicts with that needed to attain b     we rely on the subsequent lp consistency check
to determine whether actions are truly applicable  nonetheless  filtering applicable actions on the
basis of the variable bounds in a state is a useful tool for reducing the number of candidates that
must be individually verified by the lp 
      e xample of u se of now in the b orrower p roblem
we briefly illustrate the way in which the now variable is constructed and used in the context of the
borrower problem  consider the situation after the selection of the first two actions  savehard start
and takemortgage start   the lp construction yields the constraints shown in table    solving
this lp for minimum and maximum values of stepnow gives values of      and    respectively 
meaning that the earliest time at which the third action can be applied will be      and the latest
will be      similarly  solving the lp for minimum and maximum values of mnow gives bounds of

  and    this information could  in principle  constrain what actions can be applied in the current
state 
    some comments on lp efficiency
an lp is solved at every node in the search space  so it is important that this process is made as
efficient as possible  when adding the variable vectors to the lp for each step i  it is only necessary
to consider a state variable  v  if it has become unstable prior to step i  because of one of the
following effects acting on it 
   direct continuous numeric change  i e  changing v according to some gradient 
   in practice  for efficiency  colin does not actually solve the lp for minimum and maximum values of stepnow   but
uses the variable only to communicate constraints to the metric variables in this state 

  

fic olin   p lanning with c ontinuous c hange

   direct duration dependent change  i e  a change on v dependent on the duration of an action
 whose duration is non fixed  
   discrete change  where the magnitude of the change was based on one or more variables
falling into either of the previous two categories 
all variables that do not meet one of these conditions can be omitted from the lp  as their values
can be calculated based on the successive effects of the actions applied up to step i  and substituted
as a constant within any lp constraints referring to them  this reduces the number of state variables
and constraints that must be added to the lp and also reduces the number of times the lp must
be solved at each state to find variable bounds  irrelevant variables can be eliminated from the
vector vnow   a similar simplification is that  if applying a plan a     an  reaches a state s where
vmin   vmax   then if there is no continuous numeric change acting on v  v has become stable  i e 
its value is independent of the times assigned to the preceding plan steps  in this case  until the first
step k at which v becomes unstable  the value of v can be determined through simple application of
discrete effects  and hence v can be omitted from all vj   vj    n      j 
a further opportunity we exploit is that the lp solved in each state is similar to that being solved
in its parent state  it represents the same plan  but with an extra snap action appended to the end  the
lower bounds of the time stamp variables in the lp can therefore be based on the values computed
in the parent states  suppose a state s is expanded to reach a state s   by applying a snap action  a 
as step i of the plan  at this point  the lp corresponding to the plan will be built and solved with
the objective being to minimise step i   assuming the plan can indeed be scheduled  if it cannot 
then s   is pruned and no successors will be generated from it   the value of the objective function
is stored in s   as a lower bound on the time stamp of a  in all states subsequently reached from s    
this stored value can be used in the lp as a lower bound on step i  appending actions to the plan
can further constrain and hence increase the value of step i   but it can never remove constraints in
order to allow it to decrease 
as well as storing lower bounds for time stamp variables  we can make use of the bounds
vmin  vmax in the state s   when generating successors from it  in a state s reached via plan of
length i  applying an action a leads to a state s   in which the new action at step i   inherits the
constraints imposed previously on step now when calculating the variable bounds in s     therefore 
the values of vmax and vmin in s serve as upper and lower bounds  respectively  for vi   in the lp
built to determine the feasibility of s     similarly  we can combine any discrete numeric effects of a
with the values of vmax and vmin in s to give bounds on v  i     for each variable v subject to an
effect  an optimistically large  small  outcome for that effect can be computed on the basis of vmax
    otherwise  for variables upon which a has
and vmin   and taken as the upper  lower  bound of vi  
 
no discrete effect  vi     vi  
finally  the presence of timed initial literals  tils  allows us to impose stricter bounds on the
time stamp variables  if step j of a plan is the dummy action corresponding to a til at time t  the
upper bound on step i   i   j  is t   and the lower bound on each step k   j   k  or any estep
variable  is t     similarly  if the plan does not yet contain a step corresponding to a til at time
t  the upper bound on all step variables is t    furthermore  a til at time t corresponds to a
deadline if it deletes some fact p that is present in the initial state  never added by any action  and
never reinstated by any other til  in this case 
 if a plan step i requires p as a precondition  then step i  t   
  

fic oles   c oles   f ox   l ong

 if estep i is the end of an action with an end condition p  then estep i  t   
 if estep i is the end of an action with an invariant condition p  then estep i  t 

   heuristic computation
the search algorithms described so far in this paper all make use of a heuristic to guide the planner
efficiently through the search space towards the goal  having introduced the necessary machinery
to support linear continuous numeric and duration dependent effects we now turn our attention to
the construction of an informed heuristic in the face of time dependent change 
in appendices b and c we revisit the standard metric ff relaxed planning graph  rpg 
heuristic and the temporal rpg  trpg  used in crikey    and provide the details of these approaches for reference  both of these depend on the initial construction of a reachability graph 
based on the plan graph introduced in graphplan  blum   furst         the graph consists of alternating layers of facts  f l  and actions  al   in the trpg  for convenience  we index these layers by
the earliest time they could represent  although they can still be enumerated by consecutive integers
because only finitely many times can be relevant in the process of construction  in this section we
explain how the heuristic computation techniques introduced by these planners can then be modified
to reason with interacting temporalnumeric behaviour  we describe two variants of the heuristic 
a basic version  in which active continuous change is relaxed to discrete step changes  and a refined
variant in which this relaxation is replaced with a more careful approximation of the continuous
values  we show  using the borrower example  the benefits of the refined approach 
the heuristics are based on the underlying use of a relaxed plan step count  we use the relaxed
plan makespan as a tie breaker in ordering plans with the same step count  step count dominates our
heuristic because our first priority is to find a feasible solution to a planning problem and this means
attempting to minimise the number of choices that must be made and resolved during the search 
of course  the emphasis on rapidly finding a feasible plan can compromise the quality of the plan 
particularly in problems where the step count is poorly correlated with the makespan  subsequent
attempts to improve the quality of an initial feasible solution  either by iteratively improving the
solution itself or by further search using the bound derived from the feasible solution to prune the
search space  are possible  but we do not consider them in this work 
    the basic integrated heuristic computation with continuous numeric effects
the first version of colin  coles  coles  fox    long      b  introduced three significant modifications to the trpg used in crikey    in order to generate heuristic values in the presence of
continuous and duration dependent effects  the first modification simply equips the heuristic with
the means to approximate the effects of continuous change 
 if an action a has a continuous effect equivalent to dv
dt    k it is relaxed to an instantaneous
start effect hv      k  dmax  a i  that is  the effect on the changing variable is treated as
the integral of the effect up to an upper bound on the duration of the action and is applied at
the start of the action  doing this ensures that the behaviour is relaxed  in contrast to  say 
applying the effect at the end of the action  dmax  a  is calculated at the point where the
action is added to the trpg  based on the maximum duration constraints of a that refer only
to variables that cannot change after that time  that is  they are state independent   if no such
  

fic olin   p lanning with c ontinuous c hange

constraints exist  the duration is allowed to be infinite  and variables affected by continuous
effects of the action will then have similarly uninformed bounds  
 if an action a has a discrete duration dependent effect on a variable v then  when calculating
the maximum  minimum  effect of a upon v  as discussed  in the non temporal case  in appendix b   the  duration variable is relaxed to whichever of dmin a  or dmax  a  gives
the largest  smallest  effect  relaxation of this effect is achieved without changing its timing 
so it is associated with the start or end of the action as indicated in the action specification 
the second modification affects any action that has a continuous numeric effect on some variable and either an end precondition or invariant that refers to the same numeric variable  if the
invariant or end precondition places a constraint on the way in which the process governed by the
action can affect the value of a variable  then this constraint is reflected in the corresponding upper
or lower bounds of the value of the variable  specifically  if an action a decreases v at rate k and has
an invariant or end precondition v  c  then the upper bound on v by the end of the action must be at
least k  dmin a   elapsed  a     c  where elapsed  a  is the maximum amount of time for which a
could have been executing in the state being evaluated    if a is not currently executing  otherwise 
the maximum from all such entries in e   this condition ensures that the variable could achieve the
necessary value to support the application of the action  it might appear strange that the bound is
set to be higher than c  but the reason is that the relaxation accumulates increase effects and ignores
decrease effects in assessing the upper bound  so it will be necessary  by the end of the action  to
have accumulated increases in the value of the variable that allow for the outstanding consumption
from a in order to still meet the c bound at the end of the action  a corresponding condition is
required for an action that a increases v at rate k  and has an invariant or end precondition v  c 
where the lower bound on v cannot be more than k  dmin a   elapsed  a     c  these conditions
are added as explicit additional preconditions to aa for the purposes of constructing the trpg 
the third modification deals with the problem of constructing an appropriate initialisation of
the bounds for the numeric variables in the first layer of the trpg  in crikey   these values are
initialised to the actual values of the metric variables  since their values in the current state do not
change if time passes without further actions being applied  the same is not true in colin  since
any actions that have started  but not yet finished  and which govern a process  will cause variables
to change simply as a consequence of time passing  as the basic heuristic proposed here relies
on being able to integrate continuous numeric change  we determine the variable bounds in fl      
in two stages  first  the bounds on a variable v are set according to those obtained from the lp
in section      then  for each entry e  e  corresponding to the start of an action  a  with a
continuous effect on v having positive gradient k  the upper bound on v in f l      is increased by
k remaining e   here  remaining e  is the maximum amount of time that could elapse between
the state being evaluated and the future end snap action paired with start event e  the maximum
remaining execution time is calculated by subtracting the lower bound for the amount of time that
has to have elapsed since the start of action a from its maximum duration  in the case where the
gradient is negative  the lower bound is decreased 
    the refined integrated heuristic
time dependent change arises from two sources  continuous numeric effects  initiated by start snapactions  and discrete duration dependent effects which can apply at either end of durative actions 
  

fic oles   c oles   f ox   l ong

for the purposes of the refined heuristic described in this section  we treat continuous effects and
discrete duration dependent effects at the ends of actions of these in the same way  attaching a
continuous linear effect acting on each relevant variable to the effects of the appropriate snap action 
a  denoting the set of all such continuous effects by g a   for continuous effects  cont a   initiated
by a    cont a   g a     that is  the gradient effects of the start of a include all of the continuous
effects of a  for duration dependent effects of an end snap action aa we split the effect into two
parts 
 a discrete effect of aa   hv               w  v   k dmin a    ci and
 a gradient effect on v  added to g aa    the effect is defined as hv  ki if the original effect used
the operator    or   otherwise  it is hv  ki 
thus  instantaneously  at the end of aa   the effect of a is available assuming the smallest possible
duration for a is used  as a executes with a greater duration  a continuous effect is applied with
the gradient of the change being taken from the coefficient k of the  duration variable in the
corresponding effect in a 
unfortunately  the treatment proposed above cannot be applied to duration dependent start effects  since the effects are always available at the start of the action  regardless of the duration  thus 
we employ the approach taken with the basic heuristic used in colin  when calculating the maximum  minimum  effect of a  on the affected variable  v  the  duration variable is substituted
with whichever of dmin a  or dmax  a  gives the largest  smallest  effect 
once we have a collection of linear continuous effects  g a   associated with each snap action 
a  we can adjust the construction of the trpg  first  we identify  for each variable  v  an associated
maximum rate of change  vmax  t   following the layer al t   we set this to be the sum of all the
positive rates of change  affecting v  of any snap actions in al t  
v max  t   

x

x

aal t 

hv kig a 

k

this definition relies on the restriction that only one instance of any action can execute at any
time  if this restriction does not hold  but there is a clear finite bound p a  on the number of instances
of an action that can execute concurrently  then we incorporate this into the calculation of v max  t 
as follows 
x
x
v max  t   
p a  
k
aal t 

hv kig a 

where no such finite bound exists  an action could  in principle  be applied arbitrarily many times in
parallel and hence we set v max  t       following any layer al t  at which v max  t     we no
longer need to reason about the upper bound of the continuous change on v since the upper bound
on v itself will become  immediately after this layer  it should be noted that this degradation
of behaviour will  in the worst case  lead to the same heuristic behaviour as the basic heuristic
where  again  if arbitrarily many copies of the same action can execute concurrently  the magnitude
of its increase or decrease effects becomes unbounded  the extension of the heuristic to consider
   we note that  in our experience  the presence of infinitely self overlapping actions with continuous numeric change
is often a bug in the domain encoding  it is difficult to envisage a real situation in which parallel production is
unbounded 

  

fic olin   p lanning with c ontinuous c hange

continuous effects in a more refined way does not worsen its guidance in this situation  for the
remainder of this section  we consider only variables whose values are modified by actions for
which there are finite bounds on the number of concurrently executing copies allowed 
armed with an upper bound value for the rate of change of each variable following layer al t  
we can deduce the maximum value of each variable at any time t    t  by simply applying the
appropriate change to the maximum value of the variable at time t  the remaining challenge is to
decide how far to advance t  in the construction of the trpg  during construction of the trpg
in crikey   time is constrained to advance by  or until the next action end point  depending on
whether any new facts are available following the most recent action layer  lines      of algorithm     in order to manage the effects of the active continuous processes  we add a third possibility 
time can advance to the earliest value at which the accumulated effect of active continuous change
on a variable can satisfy a previously unsatisfied precondition  the set of preconditions of interest
will always be finite  so  assuming that the variable is subject to a non zero effect  the bound on the
relevant advance is always defined  or  if the set of preconditions is empty  no advance is required  
we can compute the value of this time as follows  each numeric precondition may be written as a
constraint on the vector of numeric variables  v  in the form w  v  c  for vectors of constants w
and c  we define the function ub as follows 
x  w i   y i  if w i    
ub w  x  y   
w i   x i  otherwise
w i w

the upper bound on w  v at t  is then  ub w  vmin  t     vmax  t     
the earliest point at which the numeric precondition w  v  c will become satisfied is then the
smallest value of t  for which ub w  vmin  t     vmax  t      c 
as an example  suppose there is an action with a precondition x    y  z  c  so that w  
h       i  assuming x  y and z are the only numeric fluents in this case   substituting this into the
previous equation yields 
ub h       i  hx  y  zimin  t     hx  y  zimax  t         xmax  t        ymax  t       zmin  t   
     xmax  t    t   t      xmax  t     
    y max  t    t   t      ymax  t     
   z min  t    t   t      zmin  t     
 the values of x  y and z are based on their starting points at t    because this accounts for any
instantaneous changes triggered by actions in al t    if the value of t  produced by this computation
is infinite  then the maximum possible rate of increase of the expression x    y  z must be zero  
otherwise  t  is the time at which a new numeric precondition will first become satisfied due to
active continuous effects and  if this is earlier than the earliest point at which an action end point
can be applied  then the next fact layer in the trgp will be f l t    
      i mproving the b ounds on variables in fact l ayer z ero
previously  setting the bounds in fact layer zero could be thought of as consisting of two stages 
finding initial bounds using the lp and then  because the passage of time could cause these bounds
to further diverge due to active continuous numeric change  integrating this change prior to setting
   to find t  requires only a simple rearrangement of the formula to extract t  directly 

  

fic oles   c oles   f ox   l ong

bounds for layer zero of the trpg  with an explicit model of numeric gradients in the planning
graph  we can now reconsider this approach  the intuition behind our new approach here is as
follows 
   for each variable v  create an associated variable tnow  v  in the lp  and solve the lp to
minimise the value of this variable 
   fixing the value of tnow  v  to this lower bound  maximise and minimise the value of v to find
the bounds on it at this point  these are then used as the bounds on v in fl       
   if v     in the current state  then all vmax  t  values in the trpg are offset by v or 
similarly  if v      all vmin  t  values are offset 
the first of these steps is based on the ideas described in section      but the process is subtly
different because we are trying to determine the bounds on v at a given point in time  rather than
those that appear to be reachable  as before  tnow  v  must still come after the most recent plan step
and is used to determine the value of v  this is reflected by the pair of constraints 
tnow  v   step i  
vnow   vi    vnow  tnow  v   step i  
additionally  since the now variable is associated with only a single v  rather than having to
be appropriate for all v  we can further constrain it if  necessarily  v cannot be referred to  either
in a precondition  duration or within an effect  until at least after certain steps in the plan  rather
than the weaker requirement of just after the most recent step  for our purposes  we observe that
if all actions referring to v require  delete and then add a fact p  and all possible interaction with p
is of this require delete add form  then tnow  v  must come after any plan step that adds p  more
formally  the require delete add idiom holds for p if p is true in the initial state  and for each action
a with preconditions effects on p  the interaction between the action and p can be characterised as
one of the following patterns 
 
   p  pre    a   p  eff 
   a   p  eff    a 
 
   p  pre a  a   p  eff 
a  a   p  eff a  a 
 
   p  pre    a   p  eff 
   a   p  eff a  a 

 an action may exhibit either or both of the first two interactions  or just the third  
the lp variable corresponding to the point at which p is added  which we denote step p   is
determined in one of two ways  first  if p is present in the state being evaluated  step p is the lp
variable corresponding to the plan step that most recently added p  otherwise  from case   above 
we know that p  eff  
a  a  for some action a that is currently executing  in this case  step p is the lp
variable estep i corresponding to the end of a  with this defined variable  we can add the constraint
to the lp 
tnow  v   step p   
solving the lp with the objective being to minimise tnow  v  finds the earliest possible time at
which v can be referred to  then  fixing tnow  v  to this minimised value  we minimise and maximise
  

fic olin   p lanning with c ontinuous c hange

the bounds on vnow   this gives us bounds on v that are appropriate as early as possible after the
actions in the plan so far 
having obtained variable bounds from the lp we must  as before  account for the fact that the
passage of time causes the bounds to change if there is active continuous numeric change  whereas
before we integrated this change prior to the trpg  we now have a mechanism for handling gradients directly during trpg expansion  thus  for each start event queue entry e  e corresponding
to the start of an action  a  with a continuous effect on v with a positive  negative  gradient k 
we add a gradient effect on the upper  lower  bound on v to the trpg  just as we previously restricted the integrated effect of e by remaining e   the maximum remaining time until the action
must end  so here we limit how long the gradient effect is active  it starts at al      and finishes at
al remaining e    then  for a given fact layer t the value of vmax  t  is updated accordingly 
vmax  t   

xx

 k   hv  ki  g op e    k      t  remaining e  

ee

similarly  vmin t  is amended to account for effects hv  ki  k     
    using the two variants of the integrated heuristic in the borrower problem
we now illustrate the computation of the two heuristic functions for a choice point in the borrower
problem  this example shows that the refined heuristic guides the planner to a shorter makespan
plan than the basic heuristic  because the improved heuristic information leads to the selection of
better choices of helpful actions  consider the situation following execution of the first action 
savehard start  figure    top  shows the trpg and relaxed plan constructed using the basic
heuristic 
the heuristic generates a cost for this state of    the four actions shown in the relaxed plan 
together with an extra one to end the savehard action that has already started  this relaxed plan
generates two helpful actions  to start the lifeaudit and to start takemortgage short  an attempt to start the lifeaudit action can quickly be dismissed as temporally inconsistent  depending
as it does on boughthouse becoming true before it ends  so the other helpful action is chosen  unfortunately  once this action is selected the interaction between the saving process and the deposit
requirement  at least five savings must have been acquired  forces the action to start no earlier than
time    this constraint is invisible in the trpg  because the continuous effect of savehard has
been abstracted to a start effect  and a full ten savings therefore appear to be available immediately 
a plan can be constructed using the short mortgage  but only by introducing a second saving action
as shown in the lower plan in figure    this is because the start of the short mortgage is pushed so
late that the life audit cannot both overlap the end of the first savehard action and finish after the
mortgage action 
the lower part of figure   shows what happens when the refined heuristic is used to solve
this problem  the savehard action starts as before  but this time the heuristic does not relax the
behaviour of the continuous savings process so the long mortgage  which requires a smaller deposit
to initiate it  becomes available before the short mortgage  as a consequence of this  the relaxed
plan selects the long mortgage  and this action starts early enough that the life audit can overlap both
its end and the end of the savehard action  the planner is correctly guided to the optimal plan  as
shown at the top of figure    the crucial difference between the two heuristics  is that the refined
heuristic is able to access more accurate information about the value of the savings at timepoints
  

fic oles   c oles   f ox   l ong

   savehard start

saving

  


lifeaudit start
takemortgage start short

money          

money         

savehard end

cansave

takemortgage start long

   

    
lifeaudit end

savehard start
boughthouse

happy

takemortgage end short

   savehard start

saving

 



 

lifeaudit start
takemortgage start long

money      t 

money        t    

takemortgage start short

  

  

money    t    

   
lifeaudit end

savehard end

cansave

takemortgage end long

boughthouse

happy

figure    the trpg and relaxed plan for the borrower problem  following initial execution of
savehard start at time    as constructed using the original version of colin  top 
described in section      and the revised version  bottom  described in section      
action layers are depicted in rounded rectangles and fact layers in ovals  the action
layers are labelled with their times constructed during the reachability analysis 

after the start of the savehard action  this leads to a finer grained structure of the trpg  which
can be seen in the fact that there are six action layers before arrival at the goal  rather than four as in
the case when the basic heuristic is used  the estimated makespan of the final plan is        while
the makespan according to the basic heuristic is         the basic heuristic leads to a non optimal
solution because it requires the extra savehard action  giving a solution makespan of         in
contrast to the makespan of       of the optimal plan 
the benefit of the refined heuristic  and the extra work involved in constructing the modified
trpg  is that better helpful actions are chosen and the makespan estimate is therefore more accurate  the choice between similar length plans is made based on makespan  the trpg  constructed
by the refined heuristic in the borrower problem  does not even contain the short mortgage action at
an early enough layer for it to be considered by the relaxed plan 
  

fic olin   p lanning with c ontinuous c hange

    improving performance
in this section we present two techniques we use to improve the performance of colin  the first
technique  described in section       is a generalisation of our earlier exploitation of one shot actions  coles et al       a  to the situation in which they encapsulate continuous processes  leading
to faster plan construction in problems with these action types  the second technique  described in
section       exploits the lp that defines the constraints within the final plan to optimise the plan
metric  this leads to better quality plans in many cases 
     reasoning with one shot actions
in earlier work  coles et al       a  we have observed that there is a common modelling device in
planning domains that leads to use of actions that can only be applied once  we call these actions
one shot actions  they arise  in particular  when there is a collection of resources that can each be
used only once  the key difference that one shot actions imply for the trpg is that continuous
effects generated by one shot actions lapse once a certain point has been reached 
 if a one shot action a has a continuous numeric effect on v  and a  first appears in action layer
al t   then the gradient on v due to this effect of a finishes  at the latest  at al t   dmax  a   
 if the end aa of a one shot action has a duration dependent effect on v  then the  implicit 
continuous effect acting on v finishes  at the latest  at layer al t   dmax  a  
the termination point is implied  in both cases  by the fact that the action is one shot 
we modify the trpg construction to reflect these restrictions by extending the data recorded
in each action layer to include  for each snap action action a  the maximum remaining execution
time of a  denoted rem t  a   for one shot actions  in the layer al t  in which a  first appears 
rem t  a      dmax  a   and when aa first appears  rem t  aa     dmax  a   dmin a   for actions
that are not one shot rem t  a    and rem t  aa   are both initialised to   we make three minor
changes to the layer update rules to accommodate the rem values  first  when calculating the active
gradient on a variable v following action layer al t  
x
x
v max  t   
p a  
k
aal t  rem a t   

hv kig a 

as can be seen  only the subset of actions with execution time remaining is considered  second 
at the next action layer al t   t  following al t   the value of each positive rem is decremented
by t  the amount of time elapsed since the previous layer  third  as a consequence of this  an
additional criterion must be considered when calculating the time stamp of the next fact layer  t   
described in section      since the time remaining to complete an action may expire  we may
need to insert an additional fact layer to denote the point at which a rem value reaches   and the
continuous effects acting on one or more variables need to be recalculated  the time stamp of the
earliest such layer is 
t    t   min rem t  a        a  al t  
one shot actions can be exploited still further by improving the upper bound on the duration of
the action a  in the case of actions with state dependent duration constraints  i e  where the upperbound is calculated based on variables that can be subjected to the effects of actions   dmax  a  may
  

fic oles   c oles   f ox   l ong

be a gross over estimate of the duration of a  suppose the maximum duration of a is bounded by a
formula w  v   c  in the layer al t  in which a  appears  we can compute the maximum duration
of a  were it to be started in that layer  based on the variable bounds recorded in f l t   we could
use this value to determine a bound on the remaining execution time for a  however  at some future
layer f l t     the variable bounds might have changed  so that beginning a in al t     and calculating
its maximum duration based on f l t     would have allowed a to execute for a possibly longer period
of time  allowing its continuous effects to persist for longer 
to remain faithful to the relaxation  the possibility of exploiting this increased duration of a
 by starting a at t    must be included in the trpg  as well as allowing the possibility of a to start
at t  thereby obtaining its effects sooner  therefore  each one shot action is allowed to start in the
earliest layer al t  in which its preconditions are satisfied  giving it an initial maximum duration of
dmax  a  t  based on the fact later f l t   but  if a later fact layer f l t    admits a greater duration
 dmax  a  t     the value of dmax for action a at layer t     the remaining execution time for a is
reconsidered  first  in the simple case  the variables in the duration constraint are changed in f l t    
but not subject to any active continuous effects  in this case  we apply a pair of dummy effects to
fact layer t     t    dmax  a  t  
hrem a    t         dmax  a  t     dmax  a  t  i
and
hrem aa   t         dmax  a  t     dmax  a  t  i 
note that the increase of the rem values is delayed until layer t   because  in order to benefit from
the longer duration of a  a must have started in layer t   
in the more complex case  the variables in the duration constraint are changed in f l t    but
the duration is also affected by continuous effects on some of the variables it depends on  in this
situation  each subsequent fact layer might admit a marginally bigger duration for a than the last  to
avoid having to recalculate the new duration for a repeatedly  we schedule a pair of dummy effects
based on the global  layer independent  maximum value for the duration of a 
hrem a    t         dmax  a   dmax  a  t  i
and
hrem aa   t         dmax  a   dmax  a  t  i 
this relaxation is weaker than it might be  but is efficient to compute 
     plan optimisation
a plan metric can be specified in pddl     problem files to indicate the measure of quality to
use in evaluating plans  the metric is expressed in terms of the task numeric variables and the
total execution time of the plan  by referring to the variable total time   the use of an lp in
colin offers an opportunity for the optimisation of a plan with respect to such a metric  for a plan
 
consisting of n steps  the numeric variables vn 
are those at the end of the plan  the stepn  is the
time stamp of the final step  i e  the action dictating the makespan of the plan  and the lp objective
can be set to minimise a function over these  the lp must be solved to minimise the time stamp of
the last action  the makespan of the plan  in order to arrive at a lower bound on the time for the next
action  however  it can also be solved to optimise the plan metric 
  

fic olin   p lanning with c ontinuous c hange

although it is possible to consider ways to use the metric optimising lp value during plan
construction  to guide the search  we have focussed on a much more limited  but less costly  use  we
only attempt post hoc optimisation  attempting to exploit any flexibility in the temporal structure of
the final plan to optimise the plan quality at the last stage of plan construction 
in order for such post hoc optimisation to be useful  planning problems must have the property
that it is possible to vary the quality metric of a plan by scheduling the same actions to occur at
different times  this is possible in a wide range of interesting situations  such as scheduling aircraft
to land as close to a given target time as possible  taking images from satellites at certain times of day
when the view is clearer  or minimising wasted fuel by penalising the time elapsing between starting
the engine of a plane and its take off  the last of these represents a general class of problems in
which it may be desirable to minimise the amount of time between two activities  a different metric
to the total time taken for plan execution  to capture these interesting cases  we first extend the
language supported by colin to allow a limited subset of adl conditional effects  to allow the
conditions under which an action is executed to vary the effects the action has on the metric value
of the plan  second  we discuss how a milp can be built  based on the lp described in section     
to support post hoc plan optimisation 
our planner handles most conditional effects by a standard compilation  however  conditional
effects on metric variables that appear in the plan quality metric and not in the preconditions of
any actions are dealt with differently  we call such variables metric tracking variables and we
exploit the fact that rescheduling a plan can affect the values of these variables without changing
the validity of the plan  an example is shown in figure      of an action to land an airplane  with
conditional effects on the metric tracking variable total cost  the domain is structured so that
all land actions must start at the beginning of the plan  and their end points represent the actual
landing times of the aircraft in the problem  the duration of the actions are set to correspond to the
earliest and latest possible points at which each plane could land  as can be seen  the propositional
effects of the action are the same whether the plane lands early or late  the plane has landed  and is
no longer flying  however  the numeric effects  which are all effects on the metric tracking variable
total cost  depend on the duration of the action and  in particular  whether the plane has landed
early or late  if the plane lands early  a penalty is paid at a certain rate per unit time that the plane
lands before the desired target value  if the plane lands late  then a fixed cost is paid  in addition
to a penalty  at a different rate  per unit of time the plane lands after the desired target value  by
considering this action as a single action  with a pair of conditional effects  the planner can decide
upon the actions needed to construct a sound plan  in which all the planes have landed  whilst
leaving to the subsequent optimisation phase the decision about whether a plane should be landed
early  late  or on time 
in general  it is straightforward to exploit the lp described in section     to attempt to reschedule the actions in a plan to optimise the value of the plan metric  provided that the metric function is
linear   however  if the plan contains actions with conditional effects on metric tracking variables 
it becomes possible to exploit the representation of these effects in an extended lp  using integer
variables  in order to offer a more powerful optimisation step  each conditional effect will either be
activated or not  we introduce a     variable to represent which of these is the case for each effect 
the variable is connected to corresponding constraints that determine whether or not the condition
associated with the effect is true or not 
we deal with two kinds of constraints on the     variables in our milp encoding of the plan optimisation problem  one is the special case where actions are scheduled against fixed time windows
  

fic oles   c oles   f ox   l ong

  durative action land
 parameters   p   plane  r   runway 
 duration  and      duration  earliest  p        duration  latest  p   
 condition
 and
 at start  takeoff  
 over all  flying  p  
 at end  scheduled  p  r   
 effect
 and
 at start  flying  p  
 at end  landed  p  
 at end  not  flying  p   
 when  at end      duration   target  p   
 at end
 increase  total cost 
    earlypenaltyrate  p      target  p   duration     
 when  at end     duration  target  p   
 at end
 increase  total cost 
    latepenalty  p 
    latepenaltyrate  p      duration  target  p       
 
 

figure    pddl domain with conditional effects in the airplane landing problem  the literal
takeoff is a special proposition manipulated by a dummy action to force all the landing
actions to be anchored to the same point in time 

governed by timed initial literals that affect whether the conditions are satisfied or not and the other
is the case where the satisfaction of the conditions is determined by the status of continuous effects
controlled by the actions in the plan  so  for example  the cost of an action might depend on whether
a continuously changing value has passed some threshold or not at the time the action is executed  
both of these cases can be handled by a straightforward encoding of the linkage between the value
of the     condition variable and the corresponding conditions  the details are given in appendix d  
we have also extended the conditional effects to allow them to affect the  duration variable in an
action  with similar devices for encoding this in the milp 
the milp can then be solved as a single and final step in the construction of the plan  optimising
the plan metric quality by rescheduling the actions to best exploit the precise timing of the actions
and their interaction  through these limited conditional effects  on the plan quality 

    continuous linear benchmark domains
as colin is one of the first planners to support pddl     models featuring continuous linear change
and duration dependent effects  there are currently no benchmarks available that exploit these fea   specifically  duration dependent effects that depend on non fixed durations 

  

fic olin   p lanning with c ontinuous c hange

tures  to support our evaluation and to foster future comparisons between planners designed to
solve these problems  we have produced a number of domains with these features   
the first of our domains is an extension of the metric time variant of the rovers domain  from
the      international planning competition  ipc        long   fox      b   our focus here is on
the action navigate  responsible for moving a rover from one location to another  in the original
model  it has a discrete effect  at the start of the action  to decrease the energy level of the rover
by   units  coupled with a precondition that there must be at least   units of energy available  we
replace this with a continuous numeric effect on energy  and an over all condition that energy
must be at least zero during the action  as the duration of the original action was specified as    we
use an effect with gradient      written thus  the action has the same net effect and conditions 
energy is decreased by   units  and must not become negative  this continuous change models more
accurately the use of power during the navigate action  whilst power use may not actually be linear 
it is closer to linear than it is to being instantaneous  to make the model still more realistic  we
introduce a new action into the domain  journey recharge  shown in figure    by exploiting
interaction between continuous numeric effects on the same variable  we use this action to capture
the option of the rover tilting its solar panels to face the sun whilst navigating between two points 
to account for the power use in reorienting the solar panels  at the start and end of the action     
units of energy are used  the benefit for this consumption is that  whilst the action is executing  the
energy of the rover is increased according to a constant positive gradient  for our final modification
to the domain  we alter the duration constraint on the existing recharge action  in the original
encoding  the constraint is 
    duration           energy  x    recharge rate  x    

this forces the duration of the action to be sufficient to restore the level of charge to     full capacity   in our new formulation  we replace the   with    so that the duration constraint specifies
the maximum duration for which the battery can be charged  it need not be restored to full capacity
every time the action is applied  following all three of these modifications  the domain can be used
with the standard ipc      benchmark problems  in addition to this  we have also created some
problems considering just a single rover  where the issue of battery power management is of much
greater importance 
the next of our domains is an extension of the time variant of the satellite domain  again
taken from ipc       here  in our continuous variant of the domain  we make three key changes
to the domain model  first  in the original formulation  a proposition was used to indicate whether
power was available to operate the instrumentation on a given satellite  switching an instrument
on required and then deleted this fact  and switching it off added it again  thus  there was no
scope for parallel power usage  and all instrumentation effectively used unit power  now  we use
a numeric variable to represent power  with preconditions and effects on this variable replacing
the preconditions and effects on the proposition previously used  second  exploiting the potential
we now have for differing power requirements  instruments can be operated in one of two modes 
cooled  or uncooled  in cooled mode  active sensor cooling is used to reduce sensor noise  enabling
images to be taken in less time  this cooling  however  requires additional energy  third  and
finally  there is a compulsory sunrise phase at the start of the plan  during which the satellites
   p ddl domain and problem descriptions for all evaluation tasks are available in the online appendix maintained by
jair for this paper 

  

fic oles   c oles   f ox   l ong

  durative action journey recharge
 parameters   x   rover  y   waypoint  z   waypoint 
 duration      duration     
 condition  and  over all  moving  x  y  z  
 over all      energy  x      
 at start      energy  x       
 at end
     energy  x       
 
 effect  and  at start  decrease  energy  x       
 increase  energy  x      t  recharge rate  x   
 at end
 decrease  energy  x       
 
 

figure    the journey recharge action in the continuous numeric rovers domain

move from being shaded by the planet  to being in direct sunlight  this leads to an increase in
power availability  modelled as a linear continuous numeric effect attached to an action  sunrise 
that must be applied  interaction between this effect and the preconditions on powering instruments
ensures they can be operated no sooner than power is available  the problem files we use for this
domain are slightly modified versions of the ipc competition problems  updated to define power
availability as a numeric variable and to encode the power requirements of cooled and uncooled
sensor operation  the problems in this domain have characteristics that are very similar to the
borrower problem we have used as a running example 
further exploring the use of continuous numeric effects  our next domain models the operations
of cooperating autonomous underwater vehicles  auvs   the auvs move between waypoints
underwater and can perform two sorts of science gathering operations  the first is taking a water
sample from a given waypoint  which can be performed by any auv in the appropriate location 
and whose water sample chamber is empty  the second is taking an image of a target of interest 
this requires two auvs to cooperate  one to illuminate the target with a torch  and one to take
an image of it  the auv domain was inspired by the problem described by maria fox in her
invited lecture at the      international conference on automated planning and scheduling  once
data has been acquired  it must be communicated to a ship on the surface  as in the satellite and
rovers domains  the auvs are energy constrained  they have finite battery power  and the
power usage by actions is continuous throughout their execution  the more interesting continuous
numeric aspects of the domain arise from the use of a model of drift  we introduce a variable to
record how far each auv has drifted from its nominal position  and update this in two ways  first 
all activity in the plan is contained within an action drift with small  positive continuous numeric
effect on the drifted distance  second  we add a localise action that sets this drifted distance to
zero  with its duration  and hence energy requirements  depending on the drifted distance prior to
its application  this drifting then affects the other domain actions  in the simplest case  to sample
water or take an image at a given location  an auv cannot have drifted more than two metres  hence
introducing the need to first localise if this is the case  more interestingly  for an auv shining a
torch  drifting affects how much light is falling on the target  thus  the shine torch action for an
auv  v has three effects on the amount of light falling on a given target  t 
  

fic olin   p lanning with c ontinuous c hange

 start   increase  light level  t           distance from waypoint  v   
 throughout   decrease  light level  t      t  fall off   
 end  decrease  light level  t  by any remaining contribution  v was making to its
illumination 
the constant  fall off  is pessimistically derived from formul involving the inverse square
law  giving a linear approximation of the decay in illumination levels due to drift  then  for the
take image action itself  its duration is a function of  light level  t   the less light available  the longer it requires to take the image 
the final domain we use is the airplane landing domain  dierks         first posed as a challenge by kim larsen in his invited lecture at the      international conference on automated
planning and scheduling  this problem models the scheduling of landing aircraft on an airport
runway  for each plane  three landing times are specified  the earliest possible landing time  the
latest possible landing time  and the target  desired  landing time  since time must be allowed for
airplanes to clear the runway once they have landed  and the use of the runway is a heavily subscribed resource  it is not possible for all planes to land at their ideal time  planes can  therefore 
land early or late  but doing so incurs a penalty  this penalty is modelled by a duration dependent
effect  as shown earlier in the paper  figure      in section      we have been able to construct a
set of airplane landing problems using real data from the edinburgh airport arrivals board  results
from running colin on these problems are reported in section    

    evaluation
colin is a temporal planner  able to solve problems with required concurrency  that can handle
both discrete and continuous metric variables  the first question we address is how costly is the
extension of the underlying crikey   system to allow colin to manage continuous effects  colin
is a particularly powerful planner and there are no other general pddl     planners with similar
expressive power available for comparison on the continuous problems  however  the extensions
necessary to support continuous reasoning will add an overhead to the cost of solving problems
where there are no continuous effects  we compare the performance of colin with other temporal
planners on a selection of temporal problems without continuous effects  section       in order to
evaluate how much overhead is paid by colin in setting up and managing  redundant  structures 
in comparison with state of the art planners that do not pay this price 
we then move on to considering the performance of colin on problems with continuous dynamics  our second question is  how much improvement do we obtain from using the refined
heuristic instead of the basic heuristic  when dealing with problems with continuous change  the
planners discussed in section   are not able to scale to large and complex problems  so we compare
the two versions of colin  we present their performances on new benchmark problems with continuous processes  setting the foundation for future comparative evaluation of alternative approaches
to these problems 
the third question considered concerns the quality of the solutions produced by colin  in
comparison with optimal solutions where these can be found  colin is a satisficing planner that
can perform efficiently on a wide range of continuous planning problems  and we are interested
in understanding how much solution quality must be sacrificed in order to obtain the efficiency
achieved by colin 
  

fic oles   c oles   f ox   l ong

finally  we consider the question  just how expensive is the move from solving an stp  sufficient for purely discrete temporal planning  to solving an lp  necessary for handling continuous
effects   in particular  is it practical to solve multiple lps in performing heuristic state evaluations 
since lp construction and solution is central to the architecture of colin it is important that this
can be relied upon to scale appropriately with the range and complexity of problems that colin is
expected to solve 
the following experiments consider a large number of domains and domain variants  for the
temporal comparisons we use the simple time and time variants of depots  driverlog  rovers 
satellite and zeno  all from ipc       and airport and pipes no tankage from ipc       the
airport variant used here is the strips temporal variant 
for the comparisons between the basic and refined heuristics on continuous domains  we use the
new continuous benchmark domains introduced in section     airplane landing  rovers  satellite
cooled  the satellite variant with sensor cooling  and the auv domain 
for the post hoc optimisation experiments we use the airplane landing problem  the cafe domain introduced in the empirical analysis of crikey    coles  fox  halsey et al          a variant of
airport in which the amount of fuel burned is to be minimised  and a version of satellite with time
windows  where rewards are obtained by scheduling observations into the tighter windows 
in all cases we use the competition benchmark sets of instances where available  for the continuous rovers and satellite domains we used the ipc      complex time problem sets  these
instances work with the continuous domain variants and it is possible to get better makespan plans
for them  by respecting the continuous dynamics  than is possible when the same instances are
solved using the discrete domain variants  we generated increasing sized instances for the airplane landing domain in which the number of planes to be landed increased  in the nth instance
of the problem  n planes must be landed   we wrote a problem generator for the auv domain that
increases the number of auvs  waypoints and goals in the instances  they range from   auvs   
waypoints and   goal  to   auvs     waypoints and   goals   all experiments were run on a    ghz
pentium d machine  limited to    minutes and  gb of memory 
     comparison with existing temporal planners
few temporal planners can actually solve a full range of temporal problems  as we have already
observed  many temporal planners cannot solve problems with required concurrency  even within
the class of problems that have required concurrency  there are easier problems  which can be solved
by a left packing of actions within the plan and harder ones for which this is not possible  by left
packing we mean that actions that must be executed concurrently with other actions in the plan can
be started at the same time as each other  this property means that the approach adopted in sapa  of
extending forward search to include a choice to either start a new action or else to advance time to
the earliest point at which a currently executing action terminates  is sufficient to solve the problem 
in contrast  a problem that cannot be left packed will require the possibility of advancing time to
some intermediate point during execution of an action in order to coordinate the correct interleaving
of other actions with it  we describe such problems as requiring temporal coordination  one of
the few planners that can also handle problems requiring temporal coordination is lpg s  gerevini
et al         
we therefore compare colin with lpg td  lpg s  sapa and the temporal baseline planner developed for the temporal satisficing track at the      international planning competition  neither
  

fic olin   p lanning with c ontinuous c hange

depots simple time

driverlog simple time
   

colin solution time  s 

colin solution time  s 

   

  

 

   

  

 

   
lpg td used
temp baseline used

    
    

   

 
  
best of other solution time  s 

lpg td used
lpg s used
temp baseline used
    
    

   

   

rovers simple time

   

satellite simple time
   

colin solution time  s 

   

colin solution time  s 

 
  
best of other solution time  s 

  

 

   

  

 

   
lpg td used
temp baseline used

    
    

   

 
  
best of other solution time  s 

lpg td used
temp baseline used
    
    

   

   

 
  
best of other solution time  s 

   

zeno simple time
    

colin solution time  s 

   

  

 

   

    
    

lpg td used
temp baseline used

   

 
  
best of other solution time  s 

   

    

figure     comparison of time taken to solve problems in simple temporal planning benchmarks 
colin is compared to the best of lpg  td  lpg  s  sapa and a temporal baseline planner 
on each problem file  the shape and colour of the points indicate which planner was
the best and was therefore used in the plot  planners not appearing in a particular dataset
were not the best on any of the problems in that collection 

the temporal baseline planner  sapa nor lpg td can solve problems requiring any kind of temporal
coordination  the temporal baseline planner compiles away temporal information  by using action
  

fic oles   c oles   f ox   l ong

depots time

driverlog time
   

colin solution time  s 

colin solution time  s 

   

  

 

   

  

 

   
lpg td used
temp baseline used

    
    

   

 
  
best of other solution time  s 

lpg td used
temp baseline used
    
    

   

   

rovers time
   

colin solution time  s 

colin solution time  s 

   

satellite time

   

  

 

   

  

 

   
lpg td used
lpg s used

    
    

 
  
best of other solution time  s 

   

 
  
best of other solution time  s 

lpg td used
lpg s used
temp baseline used
    
    

   

   

 
  
best of other solution time  s 

   

figure     comparison of time taken to solve problems in more complex temporal planning benchmarks  first set   colin is compared to the best of lpg td  lpg s  sapa and a temporal
baseline planner  on each problem file  the shape and colour of the points indicate
which was the best  planners not appearing in a particular dataset were not the best on
any of the problems in that collection 

compression  and solves problems as if they were non temporal metric or propositional problems 
when solutions are found  using metric ff as the core planning system  the temporal information
is reintroduced by annotating the plan with suitable timestamps based on a critical path analysis 
no details are published about this planner  but the source code and brief information are available
from the ipc      web site  this approach cannot therefore solve problems with required concurrency  but is fast and effective on simpler problems where the temporal actions can be sequenced 
it is straightforward to identify many cases when action compression can be applied safely and this
analysis is implemented in colin to reduce the overhead of reasoning with action end points where
it is unnecessary  therefore  the behaviour of the temporal baseline planner is similar to that of
colin when all actions can be safely compressed  in figures        and    we show cpu time
comparisons between colin and the best performances of sapa  lpg td  lpg s and the temporal baseline planner  across a wide and representative collection of temporal benchmark domains 
figure    shows performance on simple temporal problems  where action durations are all fixed 
while figures    and    show results for more complex temporal problems  including those where
  

fic olin   p lanning with c ontinuous c hange

airport strips temporal
    

   

   
colin solution time  s 

colin solution time  s 

zeno time
    

  

 

   

    
    

 
  
best of other solution time  s 

   

 

   

lpg td used
lpg s used

   

  

    
    

    

lpg td used
temp baseline used

   

pipes no tankage temporal

 
  
best of other solution time  s 

   

    

pipes tankage temporal
    

   

colin solution time  s 

colin solution time  s 

   
  

 

  

 

   
   

lpg td used
temp baseline used
    
    

   

 
  
best of other solution time  s 

    
    

   

lpg td used
temp baseline used

   

 
  
best of other solution time  s 

   

    

figure     comparison of time taken to solve problems in more complex temporal planning benchmarks  second set   colin is compared to the best of lpg td  lpg s  sapa and a temporal baseline planner  on each problem file  the shape and colour of the points indicate
which was the best  planners not appearing in a particular dataset were not the best on
any of the problems in that collection 

the duration of actions is determined by the context in which they are executed  although none in
which action effects depend on this   and problems with metric variables  none of these problems
feature required concurrency or other forms of temporal coordination  in these figures  planners not
appearing in a dataset were not the best on any problems in that domain 
analysis of figures      shows that colin does indeed pay an overhead in computation time
in the solution of temporal problems that do not feature continuous dynamics  the overhead is particularly significant in the simple temporal problems where there is no interesting temporal structure
and the temporal baseline planner tends to perform very well  the overhead paid by colin is lower
in the complex temporal problems  where the temporal reasoning required is sometimes more challenging  the makespan results in figures        and    show that colin produces good quality
plans  especially for the complex temporal problems  although the temporal baseline planner is still
competitive in terms of both cpu time and makespan  this suggests that the temporal structure 
even in the complex temporal benchmarks  is quite simple and that a planner can do well by ignoring
the temporal structure that is present  rather than trying to reason about it in generating plans 
  

fic oles   c oles   f ox   l ong

depots simple time

driverlog simple time

   

   

   
colin solution quality

colin solution quality

  

  

  

  

lpg td used
lpg s used
sapa used
temp baseline used

 
 

  

  
  
best of other solution quality

  

   

   

   

lpg s used
sapa used
temp baseline used

  

 
   

 

  

   
   
   
best of other solution quality

   

satellite simple time

   

   

   

   

   

   
colin solution quality

colin solution quality

rovers simple time

   

   
   
   
   

   
   
   
   

lpg td used
lpg s used
sapa used
temp baseline used

  
 
 

  

   

   
   
   
best of other solution quality

   

   

lpg td used
lpg s used
temp baseline used

  
 
   

 

  

   

   
   
   
best of other solution quality

   

   

   

zeno simple time
    

colin solution quality

    

    

    

    

lpg td used
lpg s used
sapa used
temp baseline used

    

 
 

    

    
    
    
best of other solution quality

    

    

figure     comparison of plan quality in simple temporal planning benchmarks  colin is compared to the best of lpg td  lpg s  sapa and a temporal baseline planner  on each problem file  the shape and colour of the points indicate which was the best  planners
not appearing in a particular dataset were not the best on any of the problems in that
collection 

the detailed results of these experiments  showing raw runtime and quality comparisons between the planners used in this experiment  are presented in appendix e 
  

fic olin   p lanning with c ontinuous c hange

depots time

driverlog time

   

    

   
   
colin solution quality

colin solution quality

   
   
   
   

   

   

   
   

lpg td used
lpg s used
sapa used

  
 

lpg td used
lpg s used
sapa used
temp baseline used

 
 

  

   

   
   
   
best of other solution quality

   

   

   

 

   

rovers time

   
   
best of other solution quality

   

    

satellite time

   

   

   

   
colin solution quality

colin solution quality

   
   
   
   

   

   

   

   
lpg td used
lpg s used
sapa used

  

lpg td used
lpg s used
sapa used
temp baseline used

   

 

 
 

  

   

   
   
   
best of other solution quality

   

   

   

 

   

   
   
   
best of other solution quality

   

   

figure     comparison of plan quality in more complex temporal planning benchmarks  first set  
colin is compared to the best of lpg  td  lpg  s  sapa and a temporal baseline planner 
on each problem file  the shape and colour of the points indicate which was the best 
planners not appearing in a particular dataset were not the best on any of the problems
in that collection 

     solving problems with continuous linear change and duration dependent effects
our focus in this section is on examining the scalability of colin on the continuous benchmark
domains we have developed and  specifically  on comparing the two variants of the trpg discussed in section    these are  the basic heuristic  which discretises time  and the refined heuristic 
which is capable of handling continuous numeric change directly  the continuous benchmarks  as
described in section     are characterised by sophisticated temporal structure  including required
concurrency  giving rise to interesting opportunities for concurrent behaviour  because these problems have time dependent effects and continuous effects  they are out of the reach of the temporal
planners used in the last experiment  the problems used for this experiment are designed to rely
on the exploitation of these features  so a baseline planner that ignored these continuous dynamics
would be unable to solve the problems 
results comparing the basic and refined heuristics are shown in figure     beginning with the
airplane landing domain and the rovers domain variant  the performance is the same when either
  

fic oles   c oles   f ox   l ong

zeno time

airport strips temporal

   

    

   
   
colin solution quality

colin solution quality

   
   
   
   

   

   

   
   

lpg td used
lpg s used
sapa used

  
 

lpg td used
lpg s used
temp baseline used

 
 

  

   

   
   
   
best of other solution quality

   

   

   

 

   

  

  

  

  

  

  

   

    

pipes no tankage temporal

  

colin solution quality

colin solution quality

pipes no tankage temporal

   
   
best of other solution quality

  

  

  

lpg td used
lpg s used
temp baseline used

 

lpg td used
lpg s used
temp baseline used

 
 

  

  
  
best of other solution quality

  

  

 

  

  
  
best of other solution quality

  

  

figure     comparison of plan quality in more complex temporal planning benchmarks  second
set   colin is compared to the best of lpg td  lpg s  sapa and a temporal baseline
planner  on each problem file  the shape and colour of the points indicate which was
the best  planners not appearing in a particular dataset were not the best on any of the
problems in that collection 

heuristic is used  the relaxed plans found are the same  this is to be expected  because in these two
domains the interaction between time and numbers is relatively limited  in the airplane landing
problem  action durations affect a variable used to measure plan cost but that is not used in any
preconditions  thus  the selection of actions in the trpg is unaffected  in the rovers domain  continuous change arises when consuming power during navigate actions  or producing power when
recharging  capturing the time dependent nature of these more precisely has no effect on the relaxed plans  as the nature of the relaxation leads it to only rarely require recharge actions  and the
conditions under which these are needed are not affected by whether the effects are integrated or
not  nevertheless  these two domains illustrate that in guaranteed like for like situations  where
the heuristic guidance will be the same  the refined heuristic is only negligibly more expensive to
compute  despite the additional overheads of tracking gradient effects as the trpg is expanded 
it can also be seen that colin scales well across the airplane landing instances  although it only
manages to solve   of the    rovers problems  these well within two minutes  
  

fic olin   p lanning with c ontinuous c hange

rovers continuous time

airplane landing edinburgh time
    

   

basic heuristic
refined heuristic

refined heuristic
basic heuristic
   
  

time

time  s 

  
 

 

   
   

    

    
 

  

  

  
  
  
problem number

  

  

  

 

  

 

 

satellite cooled time
    

  

  

satellite cooled makespan
    

basic heuristic
refined heuristic

basic heuristic
refined heuristic

   
   

makespan

   

time  s 

 
  
problem number

  

   
   
   

 

   
   

   

   
 

 

 

 

  
  
problem number

  

  

  

  

 

 

 

auv time

  
  
problem number

  

  

  

  

auv makespan

     

   

basic heuristic
refined heuristic
    

   

   

   
makespan

time

 

  

   

 

   

   

   

    

basic heuristic
refined heuristic

 
 

  

  
  
problem number

  

  

 

  

  
  
problem number

  

  

figure     comparison of the basic and refined trpg variants on continuous domains  the boxed
graphs are makespan comparisons for the satellite cooled and auv domains  placed to
the right of their corresponding runtime graphs 

in the satellite cooled domain  the runtime taken to find the plans when using the refined
heuristic is comparable to that when using the basic heuristic  in some problems  e g          it
is slower  but in others  e g          it is faster  the more interesting comparison to make is in
the makespan data  shown to the right   as can be seen  the refined heuristic generally produces
  

fic oles   c oles   f ox   l ong

better quality plans  the difference in quality is due to the refined heuristic better capturing the
relationship between time and numbers  leading to better actions being chosen in the relaxed plan 
by way of example  consider the state reached after beginning the sunrise action 
 for the basic heuristic  the lp is used to obtain bounds on the power availability in this state 
with free reign over how much time to allow to elapse  the lower bound found is slightly
more than zero  corresponding to allowing  time to elapse   and the upper bound found is
the peak power availability  corresponding to applying the entirety of the sunrise action  
when building a trpg from these bounds  cooled sensor operation is immediately available 
and hence the goals will always be achieved first by actions using sensor cooling  the duration
of such actions is lower  making them more attractive  the resulting relaxed plan  and hence
helpful actions  will therefore lead search to use sensor cooling 
 with the refined heuristic  the lp is used to obtain bounds on the power availability in this
state  but these bounds must be obtained at the soonest possible point  thus  the lowerbound is still slightly more than zero  but the upper bound is also only slightly more than
zero  the positive gradients in effect on the power availability variables are then included in
the trpg  influencing the layers at which different actions become applicable  specifically 
actions without sensor cooling have lower power requirements  and hence appear at earlier
layers  then  for goals first achieved by actions not using sensor cooling  where the increased
duration of acquiring the image without cooling is compensated for sufficiently by being able
to start taking the image sooner  the relaxed plan  and hence helpful actions  will not use
sensor cooling for these goals  it can be seen that this situation is closely analogous to the
differences in alternative mortgages in the borrower domain 
the extent to which this trade off influences plan quality varies between problems  depending
on the initial orientation of the satellites  and the images required  the least benefit arises if a
satellite requires substantial reorientation to point it towards its first target  if this is the case  the
time taken allows the energy level to rise sufficiently to support sensor cooling  the greatest benefit
arises in the opposite situation  where a satellite requires minimal reorientation  then  switching
on a sensor in its cooled mode will require a substantial amount of time to elapse to support its
energy requirement precondition 
to aid understanding of the scalability implications of these results  the satellite problems are
based on those used in the      ipc  so are of a similar fundamental size  however  the continuous
reasoning that has been added to them makes the same underlying problems fundamentally much
more difficult to solve 
in the auv domain  the use of the refined heuristic increases the problem coverage  with   
problems solved rather than     applying the wilcoxon matched pairs signed ranks test to the
paired time taken data for mutually solved problems  we find that we can reject the null hypothesis
that the refined heuristic is no better than the basic heuristic  with p        observing the performance of the planner  this difference in performance arises due to the way in which the drifting
process is handled by the two approaches  specifically  it is accounted for by the difference in how
the bounds for fact layer zero of the trpg are calculated  consider a state in which an action for
an auv to communicate image data has just been started  the domain encoding ensures that until
communication has completed  the auv cannot perform any other activities  at this point  prior to
evaluating the state using a trpg heuristic  the lp is used to give bounds on the values of each state
  

fic olin   p lanning with c ontinuous c hange

variable  considering just the variable recording how far the communicating auv has drifted 
the variable  distance from waypoint auv    from now on abbreviated to dfw  
 the basic heuristic employs the approach set out in section      a single now timestamp
variable is introduced  that must come after the action just started  along with an additional
variable and constraint for dfw   maximising and minimising the value of this additional
variable yields bounds on dfw   the lower bound will be infinitesimally larger than it was
prior to starting the action  due to  time having elapsed  the upper bound corresponds to
allowing a large amount of time to elapse 
 the refined heuristic employs the approach set out in section        here  a now timestamp
variable is introduced for each task variable  in this case we are concerned with tnow  dfw   
as in the prior case  this is constrained to be after the action just applied  additionally 
however  because the domain model enforces that no other action can refer to the value of the
variable until the communicate action has finished  this specific tnow must also come after the
 future  end of the action just applied  the bounds on dfw  are then found by following the
remaining steps of section        the lp is solved to minimise the value of this tnow variable 
the value of the variable is fixed to this minimum and then the lp is solved to maximise and
minimise the value of dfw   critically  because this tnow variable must come after the end
of the action just applied  rather than just after its start  the lower bound on dfw  is larger 
the increase in the lower bound on dfw  then affects whether  in the trpg  preconditions of
the form      dfw   c  are considered satisfied in the initial fact layer  if they are not satisfied 
they are delayed until the earliest layer at which a localise action reduces the value of dfw   this
difference can then affect the relaxed plan found  during solution extraction  if an action a requiring
     dfw   c  is chosen  then if a localise action was necessary to achieve this in the trpg  the
action will be added to the relaxed plan  as a cannot come any earlier than after the end of the
communicate action just applied  that is  the point at which the bounds on dfw  are calculated 
then some sort of localisation is necessary if a is ultimately to be applied  thus  the bounds for
the refined heuristic here lead to better relaxed plans being found  containing localise actions that
would otherwise be omitted 
to give an indication of the difficulty of these problems  the auv problems range from problems
with   auvs    waypoints    objectives and   goals to those at the harder end with   auvs    
waypoints    objectives and   goals  the major hurdle preventing colin from scaling to even
larger problems is the inability to see that an implicit deadline has been created when a shine torch
action is started  the auv shining the torch has finite energy  so if the planner starts a shinetorch action with one auv  in preparation for another auv to take an image  but then adds to
the plan some actions involving the second auv that are unrelated to taking the image  the delay
can lead to there being insufficient energy to shine the torch for long enough to gain the required
exposure when the photograph taking action is eventually started  this leads the planner to a dead
end and it is forced to resort to best first search  which is much less effective than ehc in this
domain  such implicit deadlines can occur in many planning problems with temporal coordination
and the issues colin faces could be avoided by using a branch ordering heuristic that promotes
actions whose applicability is time limited due to the ends of currently executing actions  or perhaps
through relaxing unnecessary ordering constraints imposed by colin due to total order search  both
of these are out of the scope of this paper  but are interesting avenues for future work 
  

fic oles   c oles   f ox   l ong

  durative action burning fuel
 parameters   a   airplane 
 duration
     duration        engines  a   
 condition  and  at start  not burning fuel  a  
 at end  taking off  a   
 effect  and  at start  can start engines  a  
 at start  not  not burning fuel  a   
 increase  wasted fuel      t  engines  a   
 
 

figure     burning fuel action added to the airport domain
     post hoc plan optimisation
in this section we evaluate the effectiveness of our post hoc plan optimisation strategy  as described
in section     the plan optimisation phase occurs after planning is complete and can never change
the actions that are in the plan  by lifting a partial order prior to scheduling  veloso  perez   
carbonell         we can provide the scheduler with a little more flexibility over the order of actions 
as long as the ordering constraints remaining after this  greedy  partial order lifting are respected 
the scheduler can reduce plan cost by altering the time points at which the actions occur and  where
possible  their durations  minimising an objective other than plan makespan can only have an effect
on plan quality in domains where the metric is sensitive to the times at which the actions are applied 
since  by default  colin minimises makespan in the solution of the final lp for a completed plan 
there are few such benchmark domains in the literature  so we make use of the one existing suitable
domain and introduce some new variations on existing benchmarks  in order to test this feature 
the first domain  and the only existing domain with this property  is the airplane landing
domain  used earlier in this section  and described in section     here  the penalties incurred for
each landing depend on whether  and to what extent  it is early or late  therefore  for a given
sequence of landings  the times assigned to them has an impact on the quality of the plan 
the next two of our benchmark problems are variants of problems introduced in the international
planning competitions of       long   fox      b  and       hoffmann   edelkamp        
first  we consider a modified version of the satellite domain  we modify the domain by adding
time windows  modelled using tils  during which there is a clear view of a given objective  if the
photograph of the objective is taken during such a time window  the quality of the plan improves 
as a better quality picture is preferable  in each problem we introduce three such time windows
for each objective  of bounded random duration  during which taking a photograph of the objective
is preferred  the second adapted benchmark is taken from the ipc     airport domain  where
the airplane landing problem described previously is concerned with scheduling landing times for
aircraft  the airport domain is concerned with coordinating the ground traffic  moving planes from
gates to runways  and eventually to take off  whilst respecting the physical separation that must be
maintained between aircraft for safety reasons  we add to this domain the metric to minimise the
total amount of fuel burnt between an aircrafts engines starting up and when it eventually takes
off  to capture this in pddl      we add the action shown in figure     this action must occur
before a planes engines can be started and cannot then finish until the plane has started to take off
 hence its duration is at least that of the startup action   between these two points it increases
  

fic olin   p lanning with c ontinuous c hange

the amount of fuel wasted by a rate proportional to the number of engines fitted to the aircraft 
larger planes  for which the number of engines is greater  waste more fuel per unit of time  in
both the satellite and the airport domains we use the standard problem sets from the competitions 
adding any minor changes needed to support the modifications made  whilst leaving the underlying
problems themselves unaltered 
the final domain we consider is the cafe domain  first used to evaluate crikey  coles  fox 
halsey et al          in this domain  tea and toast must be made and delivered to each table in a
cafe  the kitchen  however  has only one plug socket  preventing the two items from being made
concurrently  this restriction allows the problem to have a number of interesting metric functions 
to minimise the total time to serve all customers  the plan makespan   to minimise the time between
delivery of tea and toast to a given table  or to minimise the amount by which the items have cooled
when each is delivered to the table  we consider the latter two variants here 
the results of our experiments are presented in figure     starting in the top left  with the
airplane landing domain  post hoc optimisation gives only a modest improvement in plan quality 
this is due to the limited scope for optimisation  even after partial order lifting  the order in which
the planes are going to land is fixed by the plan  so all that can be adjusted is the precise times at
which the planes are going to land within that ordering 
moving to the airport domain variant with the burning fuel action  figure    top right 
post hoc scheduling is able to give large improvements in plan quality  in the original plans  before
optimisation  the burning fuel action for a given plane can be started at any point prior to when
the relevant can start engines fact is needed and can be ended at any point after the relevant
taking off fact is true  so not necessarily in a timely manner  following post hoc optimisation 
due to the objective function used  each burning fuel action starts as late as possible and finishes as
early as possible 
in the cafe domain  the results for the two metrics used are shown in the central graphs in
figure     the two diagonal lines correspond to the original plans  on a given problem  the two
plans are identical  only the evaluation metric differs  the two lower lines show the quality of the
plan after scheduling it with respect to the relevant metric  observing the post scheduled plans 
the actions are scheduled as one would intuitively expect  when minimising the total delivery
window times  the items for a given table are delivered in succession  even if the first item loses heat
while waiting for the second item to be prepared  in contrast  when minimising heat loss items are
delivered to tables as soon as they have been prepared  even if there is then a delay between the two
items being delivered 
finally  the results for the variant of the satellite domain with observation windows is shown
in the bottom left of figure     whilst not as marked as the improvements in the previous two
domains  the scheduler is able to make some headway in better scheduling the observations  the
original plan for a given problem will  for each satellite  fix the observations it is to make  and the
order in which they are to be made  there remains enough flexibility to be able to improve plan
quality  reducing plan cost by around a factor of   
     comparison with optimal solutions
we investigated the difference in quality between optimal solutions and the solutions produced by
colin in order to form an impression of how close to optimal colin can get  to do this  we ran
colin with an admissible heuristic that uses the makespan estimate produced by the trpg  using
  

fic oles   c oles   f ox   l ong

airplane landing edinburgh
     

airport fuel loss
    

colin standard
colin optimise

     

    

     

    

     

    

solution quality

solution quality

colin standard
colin optimise

     
     
    

    
    
    

    

    

    

   

    
 

 
 

  

  

  
  
  
problem number

  

  

  

  

 

 

 

cafe  delivery window 
    

 

  
  
problem number

  

  

  

cafe  heat loss 

colin standard
colin optimise

  

   

colin standard
colin optimised

  

  

    
delivery window metric

  

heat loss metric

  
   

   

  

  
  

  
  

   
  
   

  

  

 

 
 

 

 

 

  
  
problem number

  

  

  

  

 
 

 

 

 
  
  
problem number

  

  

  

  

satellite reward
    

colin standard
colin optimise

solution quality

    

   

   

   

   

 
 

 

 

 

  
  
problem number

  

  

  

  

figure     quality of plans produced by colin with and without post hoc optimisation  on all four
graphs  lower is better 

the same value for  as is used by colin in the results presented in figures    and     we call this
variant optimalcolin 
in the auv and rover domains  there are variable duration actions in the domain for which the
durations can be chosen to be as small as  when these actions are used in a plan   length actions
might be chosen  for example  to relocalise having slightly drifted  or to recharge having used a
negligible amount of power  in these domains  optimal search has to consider plans comprising
almost entirely actions of  duration up to the optimal makespan  as an example of the scale of this 
  

fic olin   p lanning with c ontinuous c hange

problem
      instance
  
  
  
  
  
  
  

optimalcolin
makespan time  secs 
      
    
      
    
      
    
      
    
      
    
      
     
 

colin

makespan
      
      
      
      
      
     
      

time  secs 
    
    
    
    
    
    
    

table    comparison of makespans and solution time for airplane landing problems solved by optimalcolin and colin using the refined heuristic  problem   could not be solved by
optimalcolin within the   hour bound 

on auv problem    solved by colin  we find a plan with makespan         careful analysis by
hand suggests that this plan cannot be improved  so is optimal  optimalcolin must consider plans
of up to        steps in order to prove that this plan is optimal  this means that this problem is
completely out of the reach of optimal planning 
a similar problem arises in the rovers domain  where the recharge action can be as little as
 long  and a series of  long recharge actions can be applied  reaching ostensibly different states 
but without making any progress  clearly  the potential for  duration actions can arise in any
continuous temporal domain  the same problem of search space explosion will also arise in any
temporal domain where there are orders of magnitude differences between the longest and shortest
possible actions 
however  in the airplane landing and satellite cooling domains  there are no variable duration
actions in these domains that can be made arbitrarily short during search  therefore  optimalcolin
is in principle able to solve problems in these domains  in fact  given   gb of memory and   hour
of runtime for each instance  it was able to solve   airplane landing instances  as shown in table   
as the table shows  the time required to solve these problems increases very fast  problem   could
be solved in      seconds  problem   in       seconds  and problem   could not be solved within
the hour available  on this basis we decided it was unnecessary to extend the time available to
optimalcolin as it would be unlikely to cope with large instances 
table   shows that colin sacrifices optimality for speed  this sacrifice is important  but it
does pay off in terms of time required to solve problems  colin is able to solve    of the airplane
landing problems  with no instance taking more than       seconds to solve 
we found that optimalcolin could report a candidate solution to the first satellite domain instance  within     seconds  however  it could not prove within the time available that this solution
was optimal  so we did not include it 
     costs associated with lp scheduling
in the transition from crikey   to colin we switch from solving an stp at each state to solving
an lp  an important issue to consider is the impact that this has on the time taken to evaluate the
  

fic oles   c oles   f ox   l ong

feasibility of the plan constructed to reach every state considered in the search  in its default mode
of operation  colin uses an stp to evaluate a state unless it has temporalnumeric constructs that
necessitate use of an lp  to evaluate whether or not this is appropriate  or whether always using an
lp would be faster   and to compare the overheads of stp solving with lp solving on equivalent
problems  we created a variant of colin that  at every state s  schedules the plan to reach s independently using three different schedulers  the original stp solver used in the standard version
of colin  the equivalent lp solved using cplex  ibm ilog cplex optimization studio  and
the equivalent lp solved using clp  lougee heimer         the stp solver used is the incremental stp algorithm due to cesta and oddi         as previously used in crikey    each of the lp
solvers is used with the tighter variable bounds described in section      in order to evaluate the
cost associated with use of an lp instead of an stp  we modified colin to collect data revealing
the costs for each technique applied at each node evaluated during the search for a plan  it is not
possible to compare the performance straightforwardly  simply by running colin using an stp
versus colin with an lp  because minor variations caused by numerical accuracy can lead to very
different trajectories being followed  masking the intended comparison  as an aside  it is interesting to observe that minor  and essentially uncontrollable  differences in computed makespans for
relaxed plans can lead to significant variations in performance  relaxed plans with equal h values
are sorted by makespan estimates for search  
as we wish to compare the stp and lp approaches  it is necessary to consider domains with
which both can reason  that is  those without continuous numeric or duration dependent effects  in
order to consider some problems for which scheduling is interesting and necessary  in contrast to
the temporally simple problems of section       we consider domains with required concurrency 
currently very few such benchmarks exist  as few planners attempt to solve such problems  we
use representatives of the only competition domains with such features  the compiled timed initial
literal domains from ipc      from which we use airport  with time windows  and pipesnotankage  with deadlines   we also use the match lift and driverlog shift domains  halsey        
for completeness  we include results for a domain in which the scheduler is not strictly necessary 
the pipesnotankage temporal domain from ipc     
figure    shows the mean time spent scheduling per state  using each approach  on the problems
from the above domains  we exclude from the graph data from any problems that were solved by
the planner in less than a second  as the accuracy of the profiling data is not sufficiently reliable
to measure the time spent in each scheduler when the overall time taken is small  since there
was no interesting variation in results between domains we present all data together across three
graphs  sorted by scheduling time per node when using cplex  this is intended as a nominal
analogue for how hard the scheduling problems in the given planning problem are  an increase in
the scheduling time for cplex generally corresponds to an increase in the scheduling time for clp
and the stp solver  except on the easier problems where noise can be sufficient to tip the balance
as the figures are small  note the differing y axis scales on the three graphs  sorting problems
according to difficulty allows us to display the data with an appropriate y range to distinguish the
results  for the sake of maintaining reasonable y axis ranges the final problem  problem     has
been omitted from the graphs  on this problem the figures were cplex    ms  clp    ms and
stp   ms 
the results in figure    are  of course  not indicative of the scalability of colin  as it is running
three schedulers at each state  so is significantly slower than in its usual configuration  in practice  in
domains such as these with no continuous or duration dependent effects  colin will automatically
  

fic olin   p lanning with c ontinuous c hange

low difficulty
   

stp
clp
    cplex

mst state  ms 

    
    
   
    
   
    

 

 

 

 

 

 

 

 

          
problem number

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

medium difficulty

mst state  ms 

   

stp
clp
    cplex
 
   
   
   
   
  

  

  

  

  

  

  

  

           
problem number
high difficulty

  
mst state  ms 

  
  

stp
clp
cplex

  
  
  
  
 
 
  

  

  

  

  

  

  

  

           
problem number

  

  

  

  

  

figure     mean scheduling time  mst  per state on temporal planning problems  the problem
number appears under the leftmost of the the three corresponding columns in each case 

disable the lp scheduler and use the more efficient stp solver  further  the planner is here being
run with profiling enabled  so is subject to significant overheads 
  

fic oles   c oles   f ox   l ong

 
 
 
 
 
 

  
   
   
   
    
 
       
   
  
  
   
    
    

  

     

  
 
       

     
      
 
   
              
 
      
    

figure     time spent in various activities by each of the solvers  cplex and clp  viewed as a proportion of the total time spent by cplex  the slice labelled milpsolvercpx clp
is time spent in the destructor for the milp solver in cplex or clp  this is a housekeeping operation in the implementations  which are both written in c    

considering the relative performance of the stp and lp solvers  it is clear that there are overheads incurred by the necessary  for domains with continuous effects  move to using an lp rather
than an stp  the mean ratio of time spent scheduling on the same problems by cplex to that
spent using the stp solver is       the figure for clp is       analysis of the data suggests that
these ratios do not change as problem difficulty increases  rather the overhead is a constant factor
on harder problems 
despite increased scheduling overheads it is still worth noting that solving the scheduling problem is a relatively small fraction of the cost of the reasoning done at each state  once the plan
to a given state has been scheduled to check for feasibility the state is evaluated using the temporal rpg heuristic described in section    it is well known  from analysis of the performance of
ff and other forward search planners  that the majority of search time is spent in evaluating this
heuristic  to give an indication of the relative cost of scheduling versus heuristic computation we
give an admissible estimate of the mean fraction of the time spent  per state  running the scheduler
versus computing the heuristic  this estimate is guaranteed to overestimate the true mean because
in some states the scheduler will demonstrate that the temporal problem has no solution  in such
states the rpg heuristic will never be evaluated  so the heuristic evaluation is actually applied to
fewer states than the scheduler  nonetheless  our data shows that  across these problems  using the
stp solver scheduling accounts for on average less than    of state evaluation time  for clp and
cplex the figures are     and     respectively  this suggests that  although scheduling does
add some overhead to solving problems  these are relatively small compared to the cost of heuristic
computation 
a perhaps surprising observation that can be made from figure    is that clp generally solves
the scheduling problems much more efficiently than cplex  given the reputation of cplex as a
highly efficient commercial lp solver we wanted to investigate why this is the case on our problems 
  

fic olin   p lanning with c ontinuous c hange

we performed a further analysis of the profiling data  breaking down the results by function call  to
observe the time spent in the various aspects of constructing and solving an lp thorough the clp
and cplex library calls  the data  presented in figure    shows the time spent in each function as
a fraction of the total time taken by cplex to schedule plans  each summed across all problems  
the not used section in the clp data represents the time saved using clp versus cplex  this
presentation means that equally sized slices of each of the pies represent the same length of time
being taken by either of the solvers in their respective methods 
the important insight that we can gain from this data is that most of the time in both of the
lp solvers is not spent in the solve function  indeed it can be observed that the search portion is
negligible  it is barely visible  the majority of time is  in fact  spent in adding rows to the lp
matrix  i e  in adding constraints to the lp before it is actually solved  comparing cplex to clp 
it takes over   times longer  on average  to add a row to the matrix  the lps being created for both
are identical  and hence involve adding the same number of rows to the matrix  the other portion
of the chart corresponds to other methods  many of which also take longer than search  but that are
again pre processing steps such as adding new columns  variables  and setting upper bounds  since
adding rows to the matrix is a significant portion of the time taken in constructing then solving the
lps in colin  this results in a large overhead  the lps created by colin are very small and simple
to solve  compared with the difficult industrial sized problems for which cplex is designed 
our results suggest that  in fact  the best type of lp solver to use for this task is a relatively
light weight lp solver  with few overheads  that can create models efficiently  even if perhaps it
would not scale to other large scale problems  the other notable  although less marked  difference
between the two lp solvers is the time spent in the destructor  called to free up the memory used
by the lp solver after each state has been evaluated  here  it takes    times longer  on average 
to call the destructor for cplex than the destructor for clp  this has less impact than the rowadding overheads  since the lp is only deleted once per state  rather than once per lp constraint  in
general  this would not normally be a noticeable issue when solving a single difficult lp  however 
in colin  where the number of lps solved is equal to the number of states evaluated  this overhead
does become noticeable 
one interesting outcome of this study is that if  in the future  colin were to be extended to
non linear continuous change  requiring the use of a mathematical programming solver at each state
 along with other research developments   the overheads may well not be prohibitive  the search
within the solver  which is where the greater overhead would occur due to this change  is in fact not
the major contributor to the time overheads of using an lp 

    conclusions
as the range of problems that can be solved effectively by planners grows  so does the range of
opportunities for the technology to be applied to real problems  in recent years  planning has extended to solve problems with real temporal structure  requiring temporal coordination  problems
that include metric resources and interactions between their use and the causal structure of plans 
we have shown how that range can be extended still further  to include linear continuous process
effects  each extension of the power of planners demands several steps  the first is to model the
extension in a form that allows the relationship between the constraints imposed on plans by the
new expressiveness  and the actions that can be used to solve the problem  to be properly expressed 
the second step is to develop a means by which to represent the world state consistently  in order
  

fic oles   c oles   f ox   l ong

to characterise the space in which the search for a plan is conducted  the third step is to develop
a way to compute the progression of states using the action models in this extended representation 
once this step is complete  it is  in principle  possible to plan  a search space can be constructed
and searched using classic simple search techniques  in practice  this process is unlikely to lead to
solutions of many interesting problems so the fourth step  in order to make the search possible in
large spaces  is to construct an informed heuristic to guide the search 
in this paper we have built on earlier work that completed the first steps  adding the third and
fourth steps that allow us to solve planning problems with continuous effects  the tools we have
used to achieve this are well established operations research tools  lp solvers and their extensions
to milp solvers  the contributions we have made are to show how these tools can be harnessed to
check consistency of states  to model state progression and to compute heuristics that can successfully guide search in the large spaces that develop for these planning problems 
an additional contribution is that we have established a collection of benchmark problems for
this direction of research in planning  the planning community has witnessed that the creation of
benchmarks and their propagation is a powerful aid in the development of the technology  supporting
clear empirical evaluation and challenging researchers to improve on the results of others  we have
shown that colin can solve interesting and complex problems  but there remains much room for
improvement  apart from extending the capability of the planner by improving the informedness
of its heuristic and by improving the early pruning of dead end states  there is also the opportunity
to extend still further the range of problems that can be expressed and solved  in particular  we
are interested in problems with non linear continuous effects  such as power and thermal curves  it
seems possible that such non linear effects might be approached by a similar approach to that used
in colin  adapting a nlp solver to the same role as the lp solver in colin  alternatively  it might
be possible to approximate non linear effects with piecewise linear effects  in much the same way
that we did for the auv domain described in this paper  but performing the process automatically 
planning is becoming an increasingly key technology as robotic systems become more powerful
and more complex and we begin to see the limits of low level control strategies in managing the
control of these systems  autonomy demands more powerful predictive control and it is planning
that offers possible solutions to this problem  planning with continuous effects will be an important
tool in the collection that we can offer in tackling these new demands 

acknowledgments

the authors wish to thank the handling editor  malte helmert  and the anonymous reviewers for
their considerable contributions to this paper  the authors also wish to thank members of our planning group for their helpful discussions during the long gestation of this work 
the authors also wish to acknowledge the epsrc for their support of this work  specifically
through grants ep g         and ep h         
  

fic olin   p lanning with c ontinuous c hange

appendix a  glossary
name
a   i  v 
a   i  v 
action compression

al

ce i 
cs i 

dec i  v 
d
dmin  dmax 

e
eff  
x
eff 
x
eff nx
estepi

elapsed a 

f  i 

description
the lower bound on assignment effects on variable v due to actions at layer i in a reachability graph 
the upper bound on assignment effects on variable v due to actions at layer i in a reachability graph 
a technique for simplifying the structure of durative actions by
treating them as a simple non durative action with the union of the
effects of both ends of the durative action and the union of their
preconditions 
action layer in the reachability graph constructed for heuristic purposes 

first use
  

function returning the variable corresponding to the end time for
a snap action at position i in the current plan 
function returning the variable corresponding to the start time for
a snap action at position i in the current plan 

  

set of  discrete  decreasing effects on variable v at layer i in a
reachability graph 
the rate of change of variable v  associated with some state
achieved during the execution of a plan 
the minimum  maximum  duration of an action  we use dmin a 
 dmax a   where the relevant action is required to be explicit and
dmin a  t   dmax a  t   where the value is anchored to an action
in layer al t  

  

the event list recording action start times for durative actions
whose end points have not yet been included in a plan 
propositional add effects of an action  where x  when present  indicates whether at the start or end of the action 
propositional delete effects of an action  where x  when present 
indicates whether at the start or end of the action 
numeric effects of an action  where x  when present  indicates
whether at the start or end of the action 
the name of the lp variable corresponding to the time at which a
durative action will finish  having started as the ith step in a plan 
but not having finished within the plan constructed so far 
the maximum time for which action a could have been executing
in a state that is being heuristically evaluated 

  

the variable in the stn in crikey   that corresponds to the time
at which a currently incomplete action will eventually finish 

  

  
 

  

  

  
  

 
 
 
  

  

  

fic oles   c oles   f ox   l ong

name
fl

description
fact layer in the reachability graph constructed for heuristic purposes 

first use
  

inc i  v 

set of  discrete  increasing effects on variable v at layer i in a
reachability graph 
the invariants that are active in state s 

  

left packing

a structure of plans with concurrency in which all concurrent actions start simultaneously 

  

now

the name of the variable created to represent the time at the end
of the current plan in each stp or lp used to check temporal consistency of a state 

  

hop  i   dmin  dmax i

event record in a crikey state  containing the durative action  op 
that started at step i  and the minimum and maximum duration of
the action 

  

pre a
pre 
pre  
p a 

conditions required to complete an action 
invariant conditions of a durative action 
conditions required to initiate an action 
the bound on the number of instances of durative action a that
may execute concurrently 

 
 
 
  

remaining e 

the maximum amount of remaining time over which an action in
event record e could continue to be executing following a state
being heuristically evaluated 
information associated with durative action a in al t  in the reachability analysis constructed by colin  indicating how much time
a could continue to execute from this layer 

  

stepi

the name of the lp variable corresponding to the time at which
action ai is applied in a plan 

  

t i 

the variable in the stp in crikey   that represents the time at
which step i in a plan is to be executed 
the property of planning problems that require some for of concurrency in order to manage the interactions between the actions
or deadlines 
action effects that refer to  duration  causing numeric fluents to
change by different amounts according to the length of the action
causing the effect 

  

inv s 

rem t  a 

temporal coordination

time dependent change

  

  

  

  

 

fic olin   p lanning with c ontinuous c hange

name

description
used to describe continuous change  for a complete account
of its use and semantics  see original discussion on its use in
pddl      fox   long        

first use
 

ub w  x  y 

function used to calculate bounds on the effects of continuous numeric change 

  

v

used to represent the vector of metric fluents associated with a
planning domain  and their values in a state  the vector is treated
as indexable  v i  is the ith entry in v 
the vector of values of metric fluents at the start of a state  immediately following step effects of application of an action 
the vectors of lower and upper bounds on the values of the numeric variables in a state  during plan construction  

 

symbol used to represent a vector of constants of equal dimension
to the size of the vector of metric fluents in the relevant planning
problem 

 

 t

v 
vmin   vmax

w

  

  
  

fic oles   c oles   f ox   l ong

appendix b  the metric relaxed planning graph heuristic
the relaxed planning graph  rpg  heuristic of metric ff  hoffmann        has been the most
popular numeric planning heuristic over the last decade  being widely used in many planners  the
intuition behind the heuristic is to generalise the delete relaxation to include numeric variables 
in the case of propositions  the relaxation is to simply ignore propositional delete effects so  as
 relaxed  actions are applied  the set of true propositions is non decreasing  in the case of numbers 
the relaxation replaces exact assignments to numeric variables with bound constraints for their upper
and lower bounds  applying relaxed actions extends the bounds by reducing lower bounds with
decrease effects and increasing upper bounds with increase effects  checking whether a numeric
precondition is satisfied is then simply a matter of testing whether the constraint is satisfied by some
value within the bounds  the delete relaxed problem can be solved  non optimally  in polynomial
time  and the number of actions in the resulting relaxed plan can then be taken as a heuristic estimate
of the distance from the evaluated state to the goal 
the purpose of the rpg is to support this heuristic computation  relaxed planning is undertaken
in two phases  graph expansion  and solution extraction  in the graph expansion phase the purpose
is to build an rpg  identifying which facts and actions become reachable  the rpg consists of
alternate fact layers  consisting of propositions that can hold and optimistic bounds on v  and action
layers  containing actions whose preconditions are satisfied in the preceding fact layer  in the case
of propositional preconditions  a precondition is satisfied if the relevant fact is contained in the
previous layer  in the case of numeric preconditions  these are satisfied if some assignment of the
variables appearing in the precondition  consistent with the upper and lower bounds  lead to it being
satisfied  we define the function ub w  x  y  as 
x  w j   y j  if w j    
ub w  x  y   
w j   x j  otherwise
w j w

 this is the same function as is defined in section      
then  denoting a fact layer i as a set of propositions  f l i   and upper and lower variable bounds
 vmin  i   vmax  i    a precondition w  v  c of an action in layer i is considered true iff 
ub w  vmin  i   vmax  i    c
to seed graph construction  fact layer   contains all facts that are true in s  thus  action layer
  consists of all actions whose preconditions are satisfied in fact layer    fact layer   is then set to
be the optimistic outcome of taking fact layer    and applying each of the actions in action layer   
more formally  considering propositions  applying the actions in action layer i  i e  the actions al i 
leads to a fact layer i     where 
f l i        f l i    eff    a    a  al i  
considering numbers  in action layer i the set of optimistic increase and decrease effects on a
variable v across all actions are  respectively 
inc i  v      ub w  vmin  i   vmax  i     c        a  al i  s t  hv      w  v   ci  eff n  a  
dec i  v      ub w  vmax  i   vmin  i     c        a  al i  s t  hv      w  v   ci  eff n  a  
  

fic olin   p lanning with c ontinuous c hange

the exchange of the minimum and maximum bounds for v in these two expressions is important 
it causes each expression to be as extreme as possible in the appropriate direction  similarly  the
optimistic upper and lower bounds on v  following all available assignment effects  are 
a   i  v    max  ub w  vmin  i   vmax  i     c    a  al i  s t hv     w  v   ci  eff n  a  
a   i  v    min  ub w  vmax  i   vmin  i     c    a  al i  s t hv     w  v   ci  eff n  a  
the new bounds then become 
vmax  i      j    max a   i  v j    vmax  i  j   
vmin  i      j    min a   i  v j    vmin  i  j   

x

x

inc i  v j   

dec i  v j   

that is  to find the upper  lower  bounds of v j  at the next layer  for each we have a choice of
applying the largest  smallest  single assignment effect  or the sum of all increase  decrease  effects  having computed the bounds of all variables in layer i      graph expansion then continues
iteratively  finding actions applicable in action layer i      and hence the facts in layer i      and
so on  graph expansion terminates in one of two cases  either a fact layer satisfies all propositional
and numeric goals  or the addition of further layers would never lead to more preconditions being
satisfied  a condition signalled when no new propositions are appearing and the accumulation of
larger or smaller bounds on variables would not lead to any more numeric preconditions becoming
satisfied  in this case  the relaxed problem cannot be solved and hence  in the original problem  no
plan starting from s can reach g  the heuristic value of the state is then set to  
assuming graph expansion terminates with all goals reached  the second phase is to extract a
solution from the planning graph  this is a recursive procedure  regressing from the goals back to
the initial fact layer  each fact layer is augmented with a set of goals  facts or numeric preconditions 
that are to be achieved at that layer  beginning by inserting the top level goals g into the planning
graph at the first layers at which they each appeared  solution extraction repeatedly picks the latest
outstanding goal in the planning graph and selects a way to achieve it  for propositional goals  a
single action  with an effect adding the goal  is chosen  and its preconditions are inserted as goals
to be achieved  again  at the earliest possible layers   to satisfy the numeric goal w  v  c at layer
i  actions with effects acting upon the variables  with non zero coefficients  in v are chosen  until
the net increase of w  v  k  is sufficient to allow the residual precondition w  v  c  k to be
satisfied at fact layer i     at this point  this residual precondition is added as a goal to be achieved
at layer i     or earlier if possible   and the preconditions of all the actions chosen to support this
precondition are added as goals to be achieved at previous layers 
solution extraction terminates when all outstanding goals are to be achieved in fact layer    since
they are then true in the state being evaluated and need no supporting actions  the actions selected
in solution extraction form the relaxed plan from s to the goal  the length  number of actions  of
this relaxed plan forms the heuristic estimate  h s   additionally  the actions in the relaxed plan
that were chosen from action layer   form the basis of the helpful actions in s  used to restrict
the states explored by enforced hill climbing search  any action with an effect in common with the
actions chosen from action layer   is considered to be helpful 
  

fic oles   c oles   f ox   l ong

appendix c  temporal reasoning in relaxed planning graphs
several approaches have been proposed for building temporal relaxed planning graphs  trpgs  
there are three additional features that trpgs can attempt to manage  compared with rpgs 
   the temporal structure of durative actions  aa can only be applied if a  has been applied
before it 
   action durations  end effects of actions are only available at an appropriate delay after they
have started 
   the pddl     startend semantics  allowing effects and preconditions to be attached to both
the starts and ends of actions 
the trpg employed in sapa  do   kambhampati        satisfies the first two of these  but
not the third  in sapa  each action is compressed into a temporally extended action obeying the
tgp semantics  before discarding delete effects  as a relaxation  and building a tgp  style planning
graph  smith   weld         the use of compression and a time stamped tgp representation
captures durations and the start before end relationships  but the use of compression causes the
heuristic to find false dead ends in cases where there is required concurrency 
the trgp used in crikey  coles  fox  halsey et al         avoids action compression  but
it ignores the durations of actions  a non temporal rpg is built in terms of the snap actions used
during search  with an additional precondition on each end snap action that a particular dummy fact 
added by its corresponding start  has appeared in the preceding fact layer  the use of snap actions
means no preconditions or effects are lost  ensuring that the heuristic no longer identifies the false
dead ends created by the approach used in sapa   but the limitation of the heuristic is that there is
no forced separation between the start and and end of an action  but only an ordering constraint 
in crikey    coles  fox  long et al       a   the heuristic is constructed to combine the
strengths of both of these earlier heuristics  accounting for the durations of actions  whilst also
respecting the startend semantics  we now briefly describe the construction of this trpg  since it
is the basis for the heuristic used in colin  the structure of the trpg is similar to that constructed
in metric ff  but instead of each fact layer being assigned an index  it is assigned a time stamp
 indicating the minimum amount of time that must pass after the initial layer before the facts in the
layer in question can appear   to capture the durations of actions  we record  for each end action aa  
the earliest layer tmin  aa   at which it can appear  this value is set to   for all actions that are already
executing in the state being evaluated  as there is no need to first insert the start of the action into
the rpg   for other actions  the value is initialised to   before commencing trpg construction 
to build a trpg we follow algorithm    first  a number of initialisation steps are performed 
the time zero fact layer fl     is initialised  at line    to contain all the facts true in s      the set
ea is initialised to contain all the end snap actions that must appear in the trpg  if an action is
executing  its end has to be reachable  i e  appear in the trpg   or else the state s is a dead end 
if ea is empty  and s satisfies the goals g  line      then no trpg need be built  since the plan is
complete 
following initialisation  the trpg is expanded  beginning with t     and using the fact layer
f l t  to determine the action layer al t   if the preconditions of an action are satisfied in a fact layer
    for simplicity we omit the handling of numeric fluents from this explanation  this is performed exactly as in the
earlier description of the rpg heuristic implemented in metric ff 

  

fic olin   p lanning with c ontinuous c hange

algorithm    building a temporal rpg in crikey   
data  s   hf  e  t i   state to be evaluated
result  r   hfls  alsi  a relaxed planning graph
  fl      f  
  fls  hfl    i 
  als  h i 
  t    
  ea   
  prev al   
  prev fl  fl     
  foreach aa do
 
if  e  e   e op   a     then
  
tmin  aa     
  
else
  
tmin  aa      
  
ea  ea   aa   
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

if g  fl      ea    then return s is a goal state 
while t    do
fl  t      prev fl  
al  t    aa   pre aa    fl  t   tmin  aa    t  
foreach aa  al  t   prev al do
fl  t      fl  t      eff    aa   
al  t   al  t    a    pre a     fl  t   
foreach a   al  t   prev al do
fl  t      fl  t      eff    a    
tmin  aa     min tmin  aa    t   dmin a   
als  als   al  t  
fls  fls   fls t     
prev al  al  t  
if g  fl  t      ea  al  t  then
return r   hfls  alsi 
if prev fl    fl  t     then
prev fl  fl  t     
t  t    
else
prev fl  fl  t     
ep    tmin  aa     pre aa    fl  t   tmin  aa     t  
if ep     then t  min ep  
else t   
return s is a dead end 

  

fic oles   c oles   f ox   l ong

fl  t  then whether it can appear in al  t  depends on whether it is a start or end snap action  the
first and simpler case  line     is that  if a start snap action a  is applicable  it is added to al  t 
and tmin  aa   is set to t   dmin a   where dmin a  is an a priori lower bound on the duration of
a  if there is a state independent measure of the minimum duration of a  i e  a minimum duration
constraint referring only to constants  then this is taken as the value of dmin a   otherwise  if
all the minimum duration constraints depends on the state in which the action is applied  then
dmin a      all that is certain is that some time must elapse between the start and the end of the
action  the state dependent terms cannot be evaluated since the trpg determines a relaxed state 
not a real state 
the second case  covering end snap actions  is that if the preconditions of an end action aa
become satisfied in a fact layer fl  t   then addition of aa to al  t  depends on whether the start of
the action can have occurred sufficiently far in the past  line      if t  tmin  aa   then aa is added
to al t   if t   tmin  aa       then aa is postponed until al tmin  aa     otherwise  the start of the
action has yet to appear  and aa is postponed until the relevant start appears 
having determined which actions newly appear in al  t   the fact layer fl  t     is updated as
in the non temporal rpg case  by taking fl  t  and  optimistically  applying the effects of all the
actions in al  t   if f l t     and al t  do not contain the necessary goals and end snap actions
 line     then it must be decided which fact layer to consider next  clearly  it is infeasible to create
new fact layers at  spacing between fl     and the fact layer at which the goals appear  fortunately 
it is also unnecessary  as many of the fact and action layers in such a graph would be identical 
instead  we determine the next fact layer to consider as follows 
 if there are new facts in fl  t   that were not true in fl  t   line      the next layer to expand is
fl  t      the appearance of new and potentially useful facts makes it necessary to consider
whether any actions become applicable in that layer 
 if fl  t       fl  t   then we know that visiting fl  t     is futile  in this case  line      the
time stamp of the next fact layer to visit is the earliest future point at which the postponed
end of an action becomes applicable 
min tmin  aa     pre aa    f l t   tmin  aa     t 
if the minimum of these values is   or undefined  then the state can be pruned and the
procedure exits early  signalling the result to the search procedure 
when a trpg is successfully constructed  that is  if the starting state is not a dead end  the graph
that is returned contains a finite set of fact and action layers  each associated with a real time value 
assuming graph expansion terminates with all goals reached  a relaxed solution is extracted 
the solution extraction procedure used in metric ff needs one minor modification to be suitable
for use in a trpg  if the end of an action aa is chosen to support a goal at a given fact layer  then if
the action a is not already executing in the state being evaluated  the corresponding start a  must be
scheduled for selection  at the layer in which it first appeared   the purpose of this corresponds to
that of the dummy facts in crikey  if the end of an action is chosen  its start must also be executed 
as a final remark on this trpg  timed initial literals  tils  can be included by employing the
machinery introduced to delay the ends of actions until an appropriate layer  if the dummy til
actions  tilj    tilm   have yet to be applied then tmin  tilj          since tilj could be applied
in the first action layer  the intuition here is that the state being evaluated is a snapshot of the world 
  

fic olin   p lanning with c ontinuous c hange

taken no earlier than after the end of the previous action  but no later than the point at which the
next til event occurs  due to the constraints discussed in section       the minimum timestamps
for the later tils  each tilk   tilj      tilm    are then set relative to this time point 
tmin  tilk     ts tilk    ts tilj   

appendix d  post hoc plan optimisation
this appendix contains details of the milp construction briefly described in section      
d   optimising for time windows
first let us consider the simple case where an action do has a conditional effect on a metric tracking
variable reward  where the objective of the problem is to maximise reward   and where the effect
occurs depends on the truth value of a single proposition p at some time specifier ts relative to the
action do  either at start  over all  or at end  
 when  ts  p    at end  increase  reward  k    
in the case where p can be manipulated by actions  without allowing the milp to introduce new
actions or completely change the order of the plan steps  with all the complexity these modifications
would entail   there is little scope for optimisation  in the case where the truth value of p is dictated
by timed initial literals  tils   we have a more interesting case  changing the time stamps of the
start or the end of a  lp variables step i and step j    so that the condition is or is not satisfied  has
a direct effect on the metric function  this relationship can be encoded within the lp  by way of
example  consider the case where p becomes true at time a and false at b  then  again  becomes
true at c and false at d  in this case  we have two time windows that could potentially satisfy the
condition on the effect  whether the action has to wholly or only partially within one of these
windows depends on the time specifier attached to p 
 if ts  at start  then a   step i   has to lie within one of the time windows 
 if ts  at end  then aa  step j   has to lie within one of the time windows 
 otherwise  ts  over all  and both a  and aa have to lie within one of the time windows 
in all three cases  the question that must be answered is does the value of this variable lie within
a known range   the over all case requires a conjunction of two such conditions to hold and 
in the other two cases  only one has to hold  for a given step variable step i   and time window  a  b  
we can introduce into the  mi lp a binary variable switch ab corresponding to such an observation 
with constraints that take the logical form 
switch ab   step i   a    step i   b 
thus  if the switch variable takes the value    the time stamp of a point at which p is needed must
fall within the time window  a  b  and vice versa  by introducing two additional binary variables 
denoted ga and lb  this logical constraint can be represented as a series of inequalities  using n to
  

fic oles   c oles   f ox   l ong

denote a large number  
step i   a      switch ab
step i    b     switch ab
step i   n  ga
step i  n  lb
switch ab  ga  lb







 
 
a
b
 

the first two constraints encode the forwards implication  if switch ab is set to    then step i has
to lie in the range  a     b     a non zero amount of separation  here epsilon  is needed under
the pddl semantics to avoid inspecting the value of p at the same time it is being changed by the
til   the latter three constraints encode the reverse implication  if step i is strictly greater than a
and strictly less than b  then both of ga and lb have to hold the value   and thus  so does switch ab  
returning to our example  where the time specifier is over all  and the windows are  a  b 
and  c  d   the constraints that will be added are 
switch ab 
switch ab 
switch ab
switch cd 
switch cd 
switch cd
switch p









 step i   a    step i   b 
 step j   a    step j   b 
 switch ab   switch ab   
 step i   c    step i   d 
 step j   c    step j   d 
 switch cd   switch cd   
 switch ab  switch cd  

that is  switch ab is   if the entirety of the action do falls within  a  b   switch cd is   if it falls
within  c  d  and switch p is   if either of these hold  this final switch variable is used to capture
the benefit of the effect itself  if it holds the value    we increase the value of reward at the end of
the plan by k  that is  we apply the conditional effect  the variable reward will already appear in
the objective function in the form of the lp variable reward  n   where n is the last step of the plan 
thus  we modify the constraints that define reward  n so that k  switch p is added to this value  this
change will then ensure that the variable providing the value of reward in the objective function
will include the reward of k if the condition on the time at which do was executed holds 
generalising  we can extend this to the case where the conditional effect depends on the truth
of a formula f consisting of a conjunction of time specified propositional facts   ts  p       tsj pj    
for each  tsi pi    f   we create constraints  as indicated above  so that the switch variable switch pi
can only take the value   if pi holds at the time specifier tsi   this gives us a list of switch variables
s    switch p     switch pj    then  to encode that in fact the conjunction f must hold  we create a
variable switch f and add the constraints 
j  switch f     switch p            switch pj   
switch f     switch p            switch pj     j
defined thus  switch f takes the value of   iff each of the switch variables in s takes the value   
which is precisely in the case that the conjunct is satisfied  then  much as before  when updating
the constraint dictating the value of the lp variable reward  n   we add k  switch f to this value 
d   optimising numeric dependent conditions
perhaps more complex than the case of time windows is where the conditions of a conditional effect
depend on the values of the numeric variables in the domain   the pddl     definition  hoffmann
  

fic olin   p lanning with c ontinuous c hange

  edelkamp        does not include the case where tils change the values of numeric variables    
so we do not consider that case here   in the simple case  the time specifier of all the numeric
conditions is either at start or at end  more complicated is the case where one or more of the
time specifiers is over all  in this case  potentially  all the snap actions in the plan  between the
start and end of the action to which the condition belongs  could affect whether or not the condition
associated with the effect is met  we must therefore check the status of the condition at each such
point during execution of the action  suppose we have an action o  where stepk and stepl are the
variables denoting the start and end time stamps of the action  and where o has a conditional effect
with a numeric precondition in lnf 
when  over all      w  v  c    at end  increase  reward  k   
to encode this  we need to add constraints to ensure that this conditional outcome occurs iff w 
v  c at all times within o  since all change is linear  then  as with other over all conditions on
o  we only need to check the values of the numeric variables immediately before and immediately
after each action time step within o  and also immediately following the start and immediately
before the end of o itself  thus  the variables corresponding to values of v that we must examine
are those in the list 
 
 
  vl   
       vl    vl 
e    vk    vk     vk  
as stated earlier  the case of at start at end conditions is somewhat easier  for at start 
e    vk    and for at end  e    vl    irrespective of the time specifier  on the basis of this list e 
to capture whether the condition is met  adding a switch variable switch to indicate whether the
condition is met for all vectors  and switch variables  switch t     switch tn   for each element     s  of
the list e  indicating whether it is met for that single vector  the constraints over these  where  is a
small number  are then 


w e x   n    n   c   switch

x     s 



w e x    c      n  switch tx

x     s 

s  switch     switch t            switch ts     s 
the first quantification ensures that if switch      a lower bound of c is imposed on w  v for
each element of e  the second quantification ensures that if the vector v at index x in e satisfies
w  v  c  then the corresponding switch variable switch tx has to take the value    the third
constraint ensures that if all such switch variables switch tx take the value    switch must  too  be set
to    having appropriately constrained the switch variable we can update the constraint governing
the value of the lp variable reward  n  the value of reward at the end of the plan  to increase it by
the value of k  switch 
d   optimising time dependent conditions
the final extension is to allow conditional effects to refer not only to the truth values of timed
propositions  or the values of numeric variables  but also to the value of the duration of an action 
    timed initial fluents have been used in some domain models  as an unofficial extension to the language  the
semantics of such an extension are as straightforward as timed initial literals 

  

fic oles   c oles   f ox   l ong

this situation appears in our example airplane landing problem  section       where the value
 total cost  is updated by a conditional effect  of which both the condition and the effect depend
on  duration  we will consider this example in order to show how the milp can be extended to
handle such updates  first  as in the previous cases  we need to add constraints to ensure that if the
milp solver chooses to obtain the conditioned outcome of a conditioned effect  then the condition
must be met  so  for the example  we introduce a new variable binary switch variable for each
condition  and some new constraints  for the land action for a plane  p  starting and finishing at
time stamps action as step n and step m respectively  we add a pair of constrained switch variables 
for the sake of this example we give these the meaningful names early and late  the constraints
that are added to the lp are then 
target p  step m   step n
step m  step n
target p   step m  step n
step m  step n






n  early
n   n     target p   early
n  late
 target p      late

these new constraints ensure that if the plane lands early  the variable early has to take the value
   and vice versa  similarly  if it lands late  late must take the value   and vice versa  in the case of
our example  the conditional effects of the action are mutually exclusive  though this is not true in
the general case 
having defined the early and late switch variables  the objective function for the milp must be
augmented to reflect the conditional outcomes of the action  two terms must be added  one for
each switch variable  for the effect obtained if the switch variable is    abbreviating the terms
earlypenaltyrate  latepenaltyrate and latepenalty to epr  lpr and lp  respectively 
the objective terms for plane p are 
early   epr p    target p   step m  step n   
late   lpr p     step m  step n    target p    late   lp p 
note that unlike in the previous cases  this objective function is now quadratic  the objective
contains terms where a switch variable is multiplied by both a constant and a step variable  this
arises as  unlike in previous cases  the conditional effect is duration dependent  not a fixed  constant value k  whilst this raises the computational cost of optimising the milp  the cost is acceptable  it is only incurred once  after a solution plan has been found 

appendix e  details of empirical evaluation of colin
the graphs presented here show the detailed runtime and quality comparisons analysed in section     the comparative data is graphed  since the graphs sometimes superimpose curves over one
another  making it difficult to see how colin is performing  tables     show the raw time and
quality results for colin compared with average and best times and qualities for all problems  best
times and qualities are also reported with the corresponding quality or time  respectively  for that
solution  and the planner s  that generated the best result 

  

fic olin   p lanning with c ontinuous c hange

depots simple time
    

   

   

  

time  s 

time  s 

driverlog simple time
    

colin
lpg td
lpg s
sapa
temp baseline

  

 

 

   

   

    

colin
lpg td
lpg s
sapa
temp baseline

    
 

  
problem number

  

  

 

 

 

rovers simple time
   

  

time  s 

time  s 

  
  
problem number

  

  

  

  

  

  

  

  

satellite simple time
   

colin
lpg td
lpg s
sapa
temp baseline

  

 

 

   

colin
lpg td
lpg s
sapa
temp baseline

 

   

    

    
 

 

 

 

  
  
problem number

  

  

  

  

  

  

  

  

 

 

 

 

  
  
problem number

zeno simple time
     

    

colin
lpg td
lpg s
sapa
temp baseline

time  s 

   

  

 

   

    
 

 

 

 

  
  
problem number

figure     comparison of time taken to solve problems in various simple temporal planning benchmarks by the planners colin  lpg td  lpg s  sapa and a temporal baseline planner 
planners not appearing in a particular dataset did not solve any of the problems in that
collection 

  

fic oles   c oles   f ox   l ong

depots simple time
   

driverlog simple time
    

colin
lpg td
lpg s
sapa
temp baseline

   

    

    
makespan

   
makespan

colin
lpg td
lpg s
sapa
temp baseline

   

    

   

    

   

   

 

 
 

  
problem number

  

  

 

 

 

rovers simple time
   

   

   

makespan

makespan

   

  
  
problem number

  

  

  

  

  

  

  

  

satellite simple time
   

colin
lpg td
lpg s
sapa
temp baseline

   

 

   
   

colin
lpg td
lpg s
sapa
temp baseline

   

   

   
   
  
 

 
 

 

 

 

  
  
problem number

  

  

  

  

  

  

  

  

 

 

 

 

  
  
problem number

zeno simple time
    
    

colin
lpg td
lpg s
sapa
temp baseline

makespan

    
    
    
    
    
 
 

 

 

 

  
  
problem number

figure     comparison of plan quality in problems in various simple temporal planning benchmarks by the planners colin  lpg td  lpg s  sapa and a temporal baseline planner 
planners not appearing in a particular dataset did not solve any of the problems in that
collection 

  

fic olin   p lanning with c ontinuous c hange

depots time
   

driverlog time
     

colin
lpg td
lpg s
sapa
temp baseline

  

colin
lpg td
lpg s
sapa
temp baseline

    

time  s 

time  s 

   

 

  

 
   
   

    

    
 

  
problem number

  

  

 

 

 

 

rovers time
   

  

  

  

  

  

  

  

  

satellite time
    

colin
lpg td
lpg s
sapa

   

time  s 

  

time  s 

  
  
problem number

 

colin
lpg td
lpg s
sapa
temp baseline

  

 
   
   

    

    
 

 

 

 

  
  
problem number

  

  

  

  

 

 

 

 

  
  
problem number

figure     comparison of time taken to solve problems in more complex temporal planning benchmarks  first set  by the planners colin  lpg td  lpg s  sapa and a temporal baseline
planner  planners not appearing in a particular dataset did not solve any of the problems
in that collection 

  

fic oles   c oles   f ox   l ong

zeno time
    

airport strips temporal
    

colin
lpg td
lpg s
sapa

   

   

time  s 

  

time  s 

colin
lpg td
lpg s
temp baseline

  

 

 

   

   

    

    
 

 

 

 

  
  
problem number

  

  

  

  

 

  

  

pipes no tankage temporal
     

    

  

  

  

  

  

  

  

  

pipes tankage temporal
     

colin
lpg td
lpg s
temp baseline

    

colin
lpg td
lpg s
temp baseline

   
time  s 

   
time  s 

  
  
  
problem number

  

  

 

 

   

   

    

    
 

  

  

  
  
  
problem number

  

  

  

  

 

  

  

  
  
  
problem number

figure     comparison of time taken to solve problems in more complex temporal planning benchmarks  second set  by the planners colin  lpg td  lpg s  sapa and a temporal baseline
planner  planners not appearing in a particular dataset did not solve any of the problems
in that collection 

  

fic olin   p lanning with c ontinuous c hange

depots time
    

driverlog time

colin
lpg td
lpg s
sapa
temp baseline

    

    
    

colin
lpg td
lpg s
sapa
temp baseline

makespan

makespan

    

    

    
    
    

   

    
 

 
 

 

 

 

  
  
problem number

  

  

  

  

 

 

 

 

rovers time
   

    

   

    

   

    

makespan

makespan

  

  

  

  

  

  

  

  

satellite time
    

colin
lpg td
lpg s
sapa

   

  
  
problem number

   

   

   

   

   

   

   

   

 

colin
lpg td
lpg s
sapa
temp baseline

 
 

 

 

 

  
  
problem number

  

  

  

  

 

 

 

 

  
  
problem number

figure     comparison of plan quality in more complex temporal planning benchmarks  first set 
by the planners colin  lpg td  lpg s  sapa and a temporal baseline planner  planners
not appearing in a particular dataset did not solve any of the problems in that collection 

  

fic oles   c oles   f ox   l ong

zeno time
   

airport strips temporal
    

colin
lpg td
lpg s
sapa

   

   

colin
lpg td
lpg s
temp baseline

   

makespan

makespan

   

   
   

   

   

   
   
  
 

 
 

 

 

 

  
  
problem number

  

  

  

  

 

  

  

pipes no tankage temporal
   
   

  

  

  

  

  

  

  

  

pipes tankage temporal

colin
lpg td
lpg s
temp baseline

   
   

colin
lpg td
lpg s
temp baseline

   
makespan

   
makespan

  
  
  
problem number

  
  

  
  

  

  

  

  

 

 
 

  

  

  
  
  
problem number

  

  

  

  

 

  

  

  
  
  
problem number

figure     comparison of plan quality in more complex temporal planning benchmarks  second
set  by the planners colin  lpg td  lpg s  sapa and a temporal baseline planner  planners not appearing in a particular dataset did not solve any of the problems in that collection 

  

fic olin   p lanning with c ontinuous c hange

colin

time
quality
depotssimpletime
 
    
      
 
    
      
 
             
 
     
      
 
 
 
    
      
 
 
  
    
      
  
  
  
    
      
  
  
  
    
      
  
    
      
  
  
  
  
    
      
  
driverlogsimpletime
 
    
      
 
    
       
 
    
      
 
    
       
 
    
       
 
    
       
 
    
      
 
    
       
 
    
       
  
    
      
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
  
  
  
  

average
time
quality

best
time

planner

quality

planner

lpg  td tbl

            
              
             
            
              
                
             
             
              
             
              
              
             
             
              
             
               
              
             
               
             
                

lpg  s td

             
              
             
             
             
              
            
              
              
              
              
            
              
              
                
                
               
              
                
              

lpg  s

     
     
     
     
     
       
     
     
     
     
     
     
     
     
     
     
     
     
     
      
      
      

      
      
       
      
       
       
      
      
       
      
       
       
      
      
       
      
      
       
       
       
      
       

            
            
             
             
              
              
            
              
              
           
              
              
            
           
              
            
             
             
             
              
            
              

     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
       
     
      
      
     

      
       
      
       
      
      
      
       
       
      
       
       
       
       
       
        
       
       
        
       

           
             
            
             
            
             
            
             
             
            
             
            
              
              
             
                
               
               
                
              

tbl
lpg  td
lpg  td
lpg  td
lpg  td
tbl
lpg  td
lpg  td
tbl
lpg  td
lpg  td
tbl
tbl
lpg  td
tbl
lpg  td
tbl
tbl
lpg  td
tbl
lpg  td
tbl
lpg  td tbl
lpg  s tbl

tbl
lpg  td tbl
lpg  td
tbl
tbl
lpg  td tbl
tbl
tbl
tbl
lpg  td
lpg  td
tbl
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td

sapa
lpg  s

tbl
lpg  td
lpg  s
lpg  s
lpg  s
lpg  td
lpg  td
lpg  td
lpg  td
lpg  s
lpg  s
lpg  td
lpg  td

sapa
lpg  td
lpg  td
lpg  s
lpg  td
lpg  s

lpg  s

sapa
lpg  s

sapa
sapa
sapa
sapa
lpg  s
sapa
sapa
tbl
lpg  s
sapa
sapa
lpg  td
lpg  s
tbl
lpg  td
lpg  td

table    results for simple domains  best results show best time  corresponding quality  and
which planner s  achieved this time and best quality  corresponding time  and planner s 
achieving this quality  tbl is the temporal baseline planner in this and following tables 

  

fic oles   c oles   f ox   l ong

colin

time
quality
roverssimpletime
 
    
      
 
    
      
 
    
     
 
    
      
 
    
       
 
    
       
 
    
       
 
    
       
 
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
satellitesimpletime
 
    
      
 
    
      
 
    
     
 
    
      
 
    
      
 
    
      
 
    
      
 
    
      
 
    
      
  
    
       
  
    
       
  
    
       
  
             
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
             
  

average
time
quality

best
time

planner

quality

planner

tbl
tbl
lpg  td
tbl
lpg  td tbl
lpg  td
tbl
tbl
lpg  td tbl
tbl
tbl
tbl
tbl
tbl
tbl
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td

             
             
                
                 
             
             
             
             
                 
              
              
             
                 
              
                 
                
                
             
            
              

colin

tbl

             
             
             
             
             
            
             
             
             
             
             
             
             
             
             
             
             
             
              
               

     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     

      
      
      
      
       
       
      
       
       
       
       
       
       
       
       
       
       
       
       
       

           
            
            
            
             
              
            
             
              
             
             
            
             
             
             
              
              
             
              
              

     
     
     
     
     
     
     
     
     
     
     
     
     
     
      
      
      
     
     
     

      
      
      
      
      
      
      
      
      
      
      
       
       
       
       
       
       
      
       
       

           
             
            
             
            
            
            
             
             
             
             
             
             
             
              
              
              
             
              
              

colin  tbl

tbl
lpg  td tbl
tbl
tbl
tbl
lpg  td tbl
lpg  td tbl
lpg  td
lpg  td tbl
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td

lpg  s

sapa
sapa
tbl
tbl
lpg  s
tbl
sapa
sapa
colin

sapa
sapa
lpg  td
sapa
sapa
sapa
tbl
tbl
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  s

tbl
lpg  s
lpg  td
lpg  s
lpg  td
lpg  td
lpg  td
lpg  s
lpg  td
lpg  s
lpg  s
lpg  s
lpg  s
lpg  s

sapa

table    results for simple domains  best results show best time  corresponding quality  and
which planner s  achieved this time and best quality  corresponding time  and planner s 
achieving this quality 

  

fic olin   p lanning with c ontinuous c hange

colin

time
zenosimpletime
 
    
 
    
 
    
 
    
 
    
 
    
 
    
 
    
 
    
  
    
  
    
  
   
  
    
  
  
     
  
      
  
      
  
  
     
  
     

quality
       
       
       
       
       
       
       
       
        
        
       
        
       
        
        
        
        
        

average
time
quality
     
     
     
     
     
     
     
     
     
     
     
     
     
       
      
       
       
      
      
      

       
       
       
        
       
        
        
       
        
        
       
        
        
        
        
        
        
        
        
        

best
time

planner

quality

planner

         
             
             
              
            
             
             
             
             
             
            
              
             
             
              
              
              
             
              
             

tbl
tbl
tbl
lpg  td tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl
tbl

              
              
             
              
            
             
             
             
             
             
               
                
             
                   
              
              
              
                 
              
             

colin
colin

tbl
colin

tbl
tbl
tbl
tbl
tbl
tbl
sapa
sapa
tbl
sapa
tbl
tbl
tbl
lpg  s
tbl
tbl

table    results for simple domains  best results show best time  corresponding quality  and
which planner s  achieved this time and best quality  corresponding time  and planner s 
achieving this quality 

  

fic oles   c oles   f ox   l ong

colin

time
quality
airportstripstemporal
 
    
      
 
    
       
 
    
       
 
    
       
 
    
      
 
    
      
 
    
      
 
    
       
 
    
       
  
    
       
  
    
      
  
    
       
  
    
       
  
    
       
  
    
       
  
    
       
  
             
  
             
  
             
  
  
     
     
  
             
  
             
  
             
  
             
  
  
  
  
  
  
  
  
  
  
  
             
  
             
  
             
  
  
  
             
  
  
  
  

average
time
quality
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
      
       
      
      
     
     
     
      
      
     
      
      
     
     
       
      
      
      
      
      
      
       
      
      
       
      
       
       

      
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       

best
time
            
              
             
             
            
             
             
            
              
             
            
             
             
             
             
              
              
              
              
              
             
             
             
             
              
              
             
              
              
              
              
              
               
               
               
              
               
              
                
                
               
                
               
                
                

planner

quality

planner

tbl

             
              
              
              
              
              
              
              
              
              
              
             
              
             
             
             
            
              
              
              
              
             
                 
                 
              
               
          
               
               
              
              
               
               
               
               
              
                 
                 
                
          
                 
                
               
                
                

lgp  td

lgp  td tbl

tbl
tbl
tbl
tbl
tbl
tbl
lgp  td
tbl
tbl
tbl
tbl
tbl
tbl
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
tbl
tbl
tbl
tbl
lgp  td
lgp  td
tbl
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td

lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td

tbl
lgp  s

tbl
tbl
tbl
tbl
tbl
lgp  td
tbl
lgp  td
tbl
lgp  s
lgp  s
tbl
tbl
lgp  s
tbl
tbl
lgp  td
lgp  td
tbl
lgp  td
lgp  td
lgp  td
lgp  td
lgp  s
lgp  s
lgp  td
lgp  s
lgp  s
lgp  td
lgp  td
lgp  td
lgp  td

table    results for more complex domains  best results show best time  corresponding quality  and which planner s  achieved this time and best quality  corresponding time  and
planner s  achieving this quality 

  

fic olin   p lanning with c ontinuous c hange

colin

time
quality
depotstime
 
    
      
 
    
     
 
 
     
       
 
 
 
     
       
 
 
  
     
       
  
  
  
    
       
  
  
  
    
      
  
  
  
  
  
    
      
  
driverlogtime
 
    
       
 
    
       
 
    
       
 
    
       
 
    
       
 
    
       
 
    
       
 
    
       
 
    
       
  
    
       
  
    
       
  
    
        
  
    
        
  
    
       
  
    
       
  
  
  
  
  

average
time
quality

best
time

planner

quality

planner

tbl
tbl
tbl
lgp  td
lgp  td
lgp  td
tbl
lgp  td tbl
lgp  td
tbl
lgp  td
lgp  td
tbl
tbl
lgp  td
tbl
tbl
lgp  td
tbl
lgp  td
tbl
lgp  td

             
             
              
              
              
              
              
              
              
                
              
              
              
              
              
             
           
              
              
              
               
              

lgp  td

tbl

          
               
               
              
               
          
            
               
          
               
              
                  
               
              
              
                
           
               
            
                

lgp  td

     
     
     
      
     
     
     
     
     
      
     
     
     
     
     
     
     
     
     
     
     
      

      
      
       
       
       
       
       
       
        
       
       
       
      
       
       
      
      
       
       
       
      
       

              
              
              
              
               
              
              
               
                
              
               
               
              
              
               
              
            
               
              
                
              
               

     
     
     
     
     
     
     
     
     
     
     
       
     
     
      
      
     
      
       
      

       
       
       
       
       
       
       
       
       
       
       
        
        
        
       
        
        
        
        
        

             
             
             
             
             
          
            
             
          
             
             
             
          
           
             
                 
           
            
            
            

lgp  td tbl

tbl
tbl
tbl
lgp  td
lgp  td tbl
tbl
lgp  td
tbl
tbl
tbl
lgp  td
lgp  td
tbl
lgp  s
lgp  td
lgp  td
lgp  td
lgp  td

lgp  td

tbl
lgp  td

tbl
lgp  td
lgp  s
lgp  td

tbl
sapa
lgp  s
lgp  s
sapa
lgp  s
lgp  s
lgp  s
lgp  td
tbl
lgp  s
lgp  s
sapa
lgp  td

sapa
sapa
lgp  s
sapa
lgp  td
tbl
sapa
lgp  td
sapa
sapa
sapa
sapa
sapa
colin
lgp  s
lgp  td

tbl
lgp  td
lgp  s

table     results for more complex domains  best results show best time  corresponding quality  and which planner s  achieved this time and best quality  corresponding time  and
planner s  achieving this quality 

  

fic oles   c oles   f ox   l ong

colin

time
quality
pipesnotankagetemporal
 
    
     
 
    
      
 
    
      
 
    
      
 
    
      
 
    
      
 
    
      
 
    
      
 
    
      
  
    
      
  
    
      
  
    
      
  
    
      
  
    
      
  
    
      
  
    
     
  
    
      
  
    
      
  
    
     
  
    
      
  
    
     
  
  
    
      
  
     
      
  
  
    
      
  
    
      
  
    
      
  
    
      
  
  
    
      
  
     
      
  
     
      
  
     
      
  
  
  
  
  
    
      
  
  
      
    
  
  

average
time
quality
     
     
     
     
     
     
     
     
     
     
       
       
     
     
     
     
     
     
     
     
     
     
     
      
     
     
     
      
     
     
     
     
      
      
      
      
      
      
     
      
      
       
      

     
      
      
      
      
      
      
      
      
      
     
      
      
      
      
      
      
      
     
      
     
      
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
     
      
      

time
           
            
            
            
             
            
            
             
            
            
           
            
            
             
            
             
           
            
           
           
           
           
             
               
             
            
             
             
            
            
              
            
              
                
              
                
              
              
            
              
           
            
             

best
planner
tbl
tbl
tbl
tbl
lgp  td tbl
tbl
tbl
lgp  td
tbl
tbl
tbl
tbl
tbl
lgp  td
tbl
lgp  td
tbl
tbl
tbl
colin

tbl
tbl
colin
lgp  td
lgp  td

tbl
colin
colin

tbl
tbl
tbl
tbl
colin

tbl
lgp  td
tbl
lgp  td
tbl
tbl
lgp  td
tbl
tbl
tbl

quality

planner

            
             
             
            
             
             
             
             
            
             
           
                
            
            
             
            
              
             
           
               
            
           
             
              
            
             
            
             
            
            
             
            
              
                
         
               
              
               
            
              
            
            
             

lgp  td
colin
colin

tbl
lgp  td
colin
colin
lgp  s

tbl
colin

tbl
lgp  s

tbl
tbl
colin

tbl
lgp  s
colin

tbl
lgp  s
lgp  td

tbl
colin
colin

tbl
lgp  td

tbl
colin

tbl
tbl
lgp  td
tbl
colin

tbl
lgp  s
lgp  td
lgp  td
lgp  td

tbl
lgp  td
lgp  td

tbl
tbl

table     results for more complex domains  best results show best time  corresponding quality  and which planner s  achieved this time and best quality  corresponding time  and
planner s  achieving this quality 

  

fic olin   p lanning with c ontinuous c hange

colin

time
quality
pipestankagetemporal
 
    
     
 
    
      
 
    
      
 
    
      
 
    
      
 
    
     
 
    
      
 
    
      
 
  
    
     
  
    
      
  
  
    
     
  
     
      
  
     
      
  
  
     
      
  
     
      
  
    
      
  
  
  
  
     
      
  
      
      
  
     
      
  
    
      
  
      
      
  
     
      
  
      
      
  
  
  
      
      
  
  
    
      
  
     
      
  
      
    
  
  
     
      

average
time
quality
     
     
     
     
     
     
     
     
       
      
       
      
     
       
      
        
       
       
       
     
      
      
       
       
       
     
       
       
       
       
       
       
       
       
      
       
      
      

     
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
     
      
      

time
           
           
            
            
            
            
            
             
              
            
             
             
            
            
              
                
              
             
             
            
              
              
              
                
              
             
               
              
              
                
                  
             
               
             
              
            
             
              

best
planner
tbl
tbl
tbl
tbl
tbl
tbl
tbl
colin
lgp  td

tbl
colin
lgp  td
colin

tbl
colin
lgp  td
colin

tbl
colin

tbl
lgp  td
lgp  td
colin
lgp  td
colin
colin
colin
colin

tbl
tbl
tbl
tbl
lgp  td
colin
colin

tbl
tbl
colin

quality

planner

            
           
             
            
             
            
             
             
            
            
                
             
              
                
             
                
              
             
             
            
              
              
              
              
              
             
               
              
               
                
                  
               
               
             
              
             
             
              

lgp  s

tbl
colin

tbl
colin

tbl
lgp  td
colin

tbl
colin
lgp  s

tbl
lgp  td
lgp  td

tbl
lgp  td
colin

tbl
colin
tbl
tbl
lgp  td
colin

tbl
tbl
colin
colin
colin
lgp  td
lgp  td

tbl
colin
lgp  td
colin
colin
colin

tbl
colin

table     results for more complex domains  best results show best time  corresponding quality  and which planner s  achieved this time and best quality  corresponding time  and
planner s  achieving this quality 

  

fic oles   c oles   f ox   l ong

colin

time
roverstime
 
    
 
    
 
    
 
    
 
    
 
     
 
    
 
    
 
  
    
  
    
  
    
  
  
  
  
  
    
  
    
  
  
     
satellitetime
 
    
 
    
 
    
 
    
 
    
 
    
 
    
 
    
 
    
  
    
  
    
  
    
  
     
  
    
  
    
  
     
  
     
  
    
  
     
  

quality
      
      
     
      
       
       
       
       
       
       
       

       
       
       
       
       
      
      
      
      
       
       
      
       
       
       
       
      
       
       
      
       
       

average
time
quality

best
time

planner

quality

planner

lgp  td

               
              
            
         
              
               
                 
          
               
                 
              
                  
               
               
               
          
              
               
               
               

colin

     
     
     
     
     
      
     
     
     
     
     
     
     
     
     
     
     
     
     
      

      
      
      
      
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       

         
             
         
         
            
              
               
          
          
               
            
               
               
               
               
          
              
               
               
               

     
     
     
     
     
     
     
     
     
     
     
     
      
      
      
      
      
     
      
      

       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       

             
             
             
             
              
             
             
              
               
              
              
               
              
              
               
               
              
              
              
              

colin
lgp  td
lgp  s  lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  s  lgp  td tbl
lgp  td
colin  tbl

tbl
tbl
tbl
tbl
tbl
lgp  td tbl
lgp  td
tbl
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
lgp  td
tbl
lgp  td
lgp  td

              
              
             
             
                 
             
              
              
             
              
              
              
               
             
               
               
              
              
              
                   

lgp  s
colin
lgp  td

sapa
colin

sapa
lgp  td
lgp  s

sapa
colin

sapa
lgp  s
lgp  s
lgp  td
lgp  td
colin
lgp  td
lgp  td
colin
colin
colin
colin
colin

sapa
colin
colin
colin
colin
lgp  td
colin
colin
colin
colin
lgp  s
colin
colin
colin
lgp  td

table     results for more complex domains  best results show best time  corresponding quality  and which planner s  achieved this time and best quality  corresponding time  and
planner s  achieving this quality 

  

sapa

fic olin   p lanning with c ontinuous c hange

colin

time
zenotime
 
    
 
    
 
    
 
    
 
    
 
    
 
    
 
    
 
    
  
    
  
    
  
     
  
    
  
      
  
    
  
      
  
      
  
      
  
  

quality
     
      
      
      
     
      
     
      
      
      
      
      
      
       
       
       
      
      

average
time
quality
     
     
     
     
     
     
     
     
     
     
     
     
     
       
     
      
       
      
      
      

     
      
      
      
      
      
      
      
      
      
      
      
      
      
       
      
       
      
       
      

best
time

planner

quality

planner

           
           
              
             
              
              
              
              
              
              
              
              
              
              
               
             
               
              
               
               

colin   lpg  td

            
             
             
             
            
             
             
             
              
             
              
              
             
                
               
               
               
             
                
              

lpg  td

colin   lpg  td
lpg  td
lpg  s
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td
lpg  td

lpg  td
colin
colin
colin

sapa
lpg  s
lpg  td

sapa
lpg  s

sapa
sapa
lpg  td
sapa
sapa
sapa
colin
lpg  td
lpg  s
lpg  td

table     results for more complex domains  best results show best time  corresponding quality  and which planner s  achieved this time and best quality  corresponding time  and
planner s  achieving this quality 

  

fic oles   c oles   f ox   l ong

references
audemard  g   bertoli  p   cimatti  a   kornilowicz  a     sebastiani  r          a sat based approach for solving formulas over boolean and linear mathematical propositions  in proceedings of the   th international conference on automated deduction  vol        pp         
springer verlag  lnai series 
blum  a     furst  m          fast planning through planning graph analysis  in proceedings of
the international joint conference on artificial inteligence  ijcai  
boddy  m  s     johnson  d  p          a new method for the global solution of large systems of continuous constraints  in proceedings of the  st international workshop on global
constraint optimization and constraint satisfaction  cocos   vol       of lecture notes
in computer science  pp          springer 
cesta  a     oddi  a          gaining efficiency and flexibility in the simple temporal problem 
in proceedings of the  rd international workshop on temporal representation and reasoning
 time  
cesta  a   cortellessa  g   fratini  s     oddi  a          developing an end to end planning
application from a timeline representation framework  in proceedings of   st conference
on innovative applications of artificial intelligence  ia ai  
chien  s  a   tran  d   rabideau  g   schaffer  s  r   mandl  d     frye  s          timeline based
space operations scheduling with external constraints  in proceedings of the international
conference on ai planning and scheduling  icaps   pp       
cimatti  a   giunchiglia  f   giunchiglia  e     traverso  p          planning via model checking 
a decision procedure for r  in recent advances in ai planning   th european conference
on planning  ecp  pp         
coles  a  i   fox  m   halsey  k   long  d     smith  a  j          managing concurrency in
temporal planning using planner scheduler interaction  artificial intelligence           
coles  a  i   fox  m   long  d     smith  a  j       a   planning with problems requiring temporal
coordination  in proceedings of the   rd aaai conference on artificial intelligence  aaai
    
coles  a  i   fox  m   long  d     smith  a  j       b   a hybrid relaxed planning graphlp
heuristic for numeric planning domains  in proceedings of the   th international conference on automated planning and scheduling  icaps   pp       
coles  a  j   coles  a  i   fox  m     long  d       a   extending the use of inference in temporal planning as forwards search  in proceedings of the   th international conference on
automated planning and scheduling  icaps     
coles  a  j   coles  a  i   fox  m     long  d       b   temporal planning in domains with linear
processes  in proceedings of the   st international joint conference on artificial intelligence
 ijcai   aaai press 
cushing  w   kambhampati  s   mausam    weld  d          when is temporal planning really
temporal planning   in proceedings of the international joint conference on ai  ijcai   pp 
         
  

fic olin   p lanning with c ontinuous c hange

dechter  r   meiri  i     pearl  j          temporal constraint networks  in proceedings of principles of knowledge representation and reasoning  kr   pp        toronto  canada 
dierks  h          finding optimal plans for domains with restricted continuous effects with
uppaal cora  in icaps workshop on verification and validation of model based planning
and scheduling systems 
do  m  b     kambhampati  s          sapa  a multi objective metric temporal planner  journal
of artificial intelligence research  jair              
edelkamp  s          taming numbers and durations in a model checking integrated planning
system  journal of artificial intelligence research  jair              
edelkamp  s     jabbar  s          cost optimal external planning  in proceedings of the   st
national  american  conference on artificial intelligence  aaai   aaai press 
eyerich  p   mattmuller  r     roger  g          using the context enhanced additive heuristic
for temporal and numeric planning  in proceedings of the   th international conference on
automated planning and scheduling  icaps        aaai press 
fox  m     long  d          pddl     an extension of pddl for expressing temporal planning
domains  journal of artificial intelligence research  jair             
fox  m     long  d          modelling mixed discrete continuous domains for planning  journal
of artificial intelligence research  jair              
fox  m   howey  r     long  d          validating plans in the context of processes and exogenous
events  in proceedings of the   th national conference on artificial intelligence and the   th
innovative applications of artificial intelligence conference  aaai   pp           
fox  m   long  d     halsey  k          an investigation into the expressive power of pddl    
in proceedings of the   th european conference of artificial intelligence  ecai  
fox  m   long  d     magazzeni  d          automatic construction of efficient multiple battery
usage policies  in proceedings of the   st international conference on automated planning
and scheduling  icaps  
frank  j     jonsson  a  k          constraint based attribute and interval planning  constraints 
             
garrido  a   fox  m     long  d          a temporal planning system for durative actions
of pddl     in proceedings of the   th eureopean conference on artificial intelligence
 ecai   pp         
garrido  a   onainda  e     barber  f          a temporal planning system for time optimal
planning  in proceedings of the   th portuguese conference on artificial intelligence  pp 
        springer 
gerevini  a   saetti  a     serina  i          an approach to temporal planning and scheduling
in domains with predictable exogenous events  journal of artificial intelligence research
 jair              
gerevini  a   saetti  a     serina  i          temporal planning with problems requiring concurrency through action graphs and local search  in proceedings of the   th international
conference on automated planning and scheduling  icaps  
  

fic oles   c oles   f ox   l ong

gerevini  a     serina  i          fast plan adaptation through planning graphs  local and systematic search techniques  in proceedings of the  th international conference on artificial
intelligence planning systems  aips   pp         
ghallab  m     laruelle  h          representation and control in ixtet  a temporal planner  in
proceedings of the  nd international conference on artificial intelligence planning systems
 aips   pp       
halsey  k          crikey   its co ordination in temporal planning  ph d  thesis  university of
durham 
haslum  p     geffner  h          heuristic planning with time and resources  in proceedings of
the  th european conference on planning  ecp     pp         
haslum  p          admissible makespan estimates for pddl    temporal planning  in proceedings of the icaps workshop on heuristics for domain independent planning 
helmert  m          the fast downward planning system  journal of artificial intelligence  jair  
           
henzinger  t          the theory of hybrid automata  in proceedings of the   th annual symposium on logic in computer science  invited tutorial   pp          ieee computer society
press 
henzinger  t   ho  p  h     wong toi  h          a user guide to hytech  in e  brinksma 
w r  cleaveland  k g  larsen  t  margaria  and b  steffen  editors  tool and algorithms for
the construction and analysis of systems   tacas      volume      of lecture notes in
computer science  pp       
hoffmann  j          the metric ff planning system  translating ignoring delete lists to numeric state variables  journal of artificial intelligence research  jair              
hoffmann  j     edelkamp  s          the deterministic part of ipc    an overview  journal of
artificial intelligence research  jair              
hoffmann  j     nebel  b          the ff planning system  fast plan generation through heuristic
search  journal of artificial intelligence research  jair              
huang  r   chen  y     zhang  w          an optimal temporally expressive planner  initial
results and application to p p network optimization  in proceedings of the international
conference on automated planning and scheduling  icaps  
knight  r   schaffer  s     b clement         power planning in the international space station
domain  in proceedings of the  th international workshop on planning and scheduling for
space  iwpss  
lamba  n   dietz  m   johnson  d  p     boddy  m  s          a method for global optimization of
large systems of quadratic constraints  in proceedings of the  nd international workshop
on global optimization and constraint satisfaction  cocos   vol       of lecture notes in
computer science  pp        springer 
leaute  t     williams  b          coordinating agile systems through the model based execution
of temporal plans  in proceedings of the   th national conference on ai  aaai  
li  h     williams  b          generative systems for hybrid planning based on flow tubes  in proc 
  th int  conf  on aut  planning and scheduling  icaps  
  

fic olin   p lanning with c ontinuous c hange

li  h     williams  b          hybrid planning with temporally extended goals for sustainable
ocean observing  in proceedings of the international conference of the association for the
advancement of ai  aaai   special track on sustainability and ai 
long  d     fox  m       a   exploiting a graphplan framework in temporal planning  in
proceedings of the   th international conference on automated planning and scheduling
 icaps   pp       
long  d     fox  m       b   the  rd international planning competition  results and analysis 
journal of artificial intelligence research  jair           
lougee heimer  r          the common optimization interface for operations research  ibm
journal of research and development              
mcdermott  d          reasoning about autonomous processes in an estimated regression
planner  in proceedings of the   th international conference on automated planning and
scheduling  icaps  
mcdermott  d  v          the      ai planning systems competition  ai magazine              
meuleau  n   benazera  e   brafman  r  i   hansen  e  a     mausam         a heuristic search
approach to planning with continuous resources in stochastic domains  journal of artificial
intelligence research  jair            
palacios  h     geffner  h          compiling uncertainty away in conformant planning problems
with bounded width  journal of artificial intelligence research  jair              
pednault  e  p  d          adl  exploring the middle ground between strips and the situation
calculus  in proceedings of the international conference on knowledge representation  kr  
pp         
pell  b   gat  e   keesing  r   muscettola  n     smith  b  d          robust periodic planning and
execution for autonomous spacecraft  in proceedings of the international joint conference
on ai  ijcai   pp           
penberthy  s     weld  d          temporal planning with continuous change  in proceedings of
the   th national conference on ai  aaai   pp            aaai mit press 
penna  g  d   intrigila  b   magazzeni  d     mercorio  f          upmurphi  a tool for universal planning on pddl  problems  in proceedings of the   th international conference on
automated planning and scheduling  icaps        pp        aaai press 
penna  g  d   intrigila  b   magazzeni  d     mercorio  f          a pddl  benchmark problem 
the batch chemical plant  in proceedings of the international conference on ai planning
and scheduling  icaps   pp         
reddy  s  y   frank  j  d   iatauro  m  j   boyce  m  e   kurklu  e   ai chang  m     jonsson 
a  k          planning solar array operations on the international space station  acm
transactions on intelligent systems technology         
richter  s     westphal  m          the lama planner  guiding cost based anytime planning
with landmarks  journal of artificial intelligence research  jair              
shin  j     davis  e          processes and continuous change in a sat based planner  artificial
intelligence              
  

fic oles   c oles   f ox   l ong

smith  d     weld  d  s          temporal planning with mutual exclusion reasoning  in proceedings of the   th international joint conference on ai  ijcai   pp         
veloso  m   perez  m     carbonell  j          nonlinear planning with parallel resource allocation 
in proceedings of the darpa workshop on innovative approaches to planning  scheduling
and control  pp         
vidal  v     geffner  h          branching and pruning  an optimal temporal pocl planner based
on constraint programming  artificial intelligence                 
wolfman  s     weld  d          the lpsat system and its application to resource planning  in
proceedings of the   th international joint conference on artificial intelligence  ijcai  
yi  w   larsen  k     pettersson  p          uppaal in a nutshell  international journal of
software tools for technology transfer       
younes  h  l  s     simmons  r  g          vhpop  versatile heuristic partial order planner  
journal of artificial intelligence research  jair              

  

fi