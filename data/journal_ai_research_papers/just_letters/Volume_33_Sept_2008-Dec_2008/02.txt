journal of artificial intelligence research                 

submitted        published      

on the use of automatically acquired examples
for all nouns word sense disambiguation
david martinez

davidm csse unimelb edu au

university of melbourne
      melbourne  australia

oier lopez de lacalle

oier lopezdelacalle ehu es

university of the basque country
       donostia  basque country

eneko agirre

e agirre ehu es

university of the basque country
       donostia  basque country

abstract
this article focuses on word sense disambiguation  wsd   which is a natural language processing task that is thought to be important for many language technology
applications  such as information retrieval  information extraction  or machine translation  one of the main issues preventing the deployment of wsd technology is the lack of
training examples for machine learning systems  also known as the knowledge acquisition bottleneck  a method which has been shown to work for small samples of words is
the automatic acquisition of examples  we have previously shown that one of the most
promising example acquisition methods scales up and produces a freely available database
of     million examples from web snippets for all polysemous nouns in wordnet  this
paper focuses on the issues that arise when using those examples  all alone or in addition to
manually tagged examples  to train a supervised wsd system for all nouns  the extensive
evaluation on both lexical sample and all words senseval benchmarks shows that we are
able to improve over commonly used baselines and to achieve top rank performance  the
good use of the prior distributions from the senses proved to be a crucial factor 

   introduction
this paper is devoted to the word sense disambiguation  wsd  task for natural language
processing  nlp   the goal of this task is to determine the senses of the words as they
appear in context  for instance  given the sentence he took all his money from the bank  
if we focus on the word bank  the goal would be to identify the intended sense  which in
this context would be some financial sense  instead of other possibilities like the edge
of river sense  the senses can be defined in a dictionary  knowledge base or ontology 
this task is defined as an intermediate step towards natural language understanding  the
construction of efficient algorithms for wsd would benefit many nlp applications such
as machine translation  mt   or information retrieval  ir  systems  resnik         for
instance  if an mt system was to translate the previous example into french  it would
need to choose among the possible translations of the word bank  this word should be
translated as banque when it is used in the financial sense  as in the example   but as
rive when it is used in the edge of river sense  see the work of vickrey  biewald 
c
    
ai access foundation  all rights reserved 

fimartinez  lopez de lacalle   agirre

teyssier  and koller        for a recent evaluation of cross lingual wsd in mt  for ir
engines  it would also be useful to determine which is the sense of the word in the query in
order to retrieve relevant documents  specially when working with multilingual documents
in cross language information retrieval  clir   or other ir scenarios where recall is a key
performance factor  such as retrieving images by their captions  some evidence in favor of
using wsd in ir has been gathered lately  kim  seo    rim        liu  liu  yu    meng 
      stevenson   clough        vossen  rigau  alegra  agirre  farwell    fuentes        
wsd techniques can also fill an important role in the context of the semantic web 
the web has grown focusing on human communication  rather than automatic processing 
the semantic web has the vision of automatic agents working with the information in the
web at the semantic level  achieving interoperability with the use of common terminologies
and ontologies  daconta  obrst    smith         unfortunately most of the information in
the web is in unstructured textual form  the task of linking the terms in the texts into
concepts in a reference ontology is paramount to the semantic web 
narrower domains like biomedicine are also calling for wsd techniques  the unified
medical language system  umls   humphreys  lindberg  schoolman    barnett        is
one of the most extensive ontologies in the field  and studies on mapping terms in medical
documents to this resource have reported high levels of ambiguity  which calls for wsd
technology  weeber  mork    aronson        
wsd has received the attention of many groups of researchers  with general nlp books
dedicating separate chapters to wsd  manning   schutze        jurafsky   martin       
dale  moisl    somers         special issues on wsd in nlp journals  ide   veronis 
      edmonds   kilgarriff         and books devoted specifically to the issue  ravin  
leacock        stevenson        agirre   edmonds         the interested reader can start
with the dedicated chapter by manning and schutze        and the wsd book  agirre
  edmonds         the widespread interest motivated the senseval initiative    which
has joined different research groups in a common wsd evaluation framework since      
the goal is to follow the example of other successful competitive evaluations  like duc
 document understanding conference  or trec  text retrieval conference  
wsd systems can be classified according to the knowledge they use to build their models  which can be derived from different resources like corpora  dictionaries  or ontologies 
another distinction is drawn on corpus based systems  distinguishing between those that
rely on hand tagged corpora  supervised systems   and those that do not require this resource  unsupervised systems   this distinction is important because the effort required
to hand tag senses is high  and it would be costly to obtain tagged examples for all word
senses and all languages  as some estimations show  mihalcea   chklovski         in spite
of this drawback  referred to as the knowledge acquisition bottleneck   most of recent
efforts have been devoted to the improvement of supervised systems  which are the ones
that obtain the highest performance  even with the current low amounts of training data 
these systems rely on sophisticated machine learning  ml  algorithms that construct their
models based on the features extracted from the training examples 
alternatively  senseval defines two kinds of wsd tasks  lexical sample and all words 
in a lexical sample task the systems need to disambiguate specific occurrences of a handful
   http   www senseval org

  

fion the use of automatically acquired examples for all nouns wsd

of words for which relatively large numbers of training examples are provided  more than
    examples in all cases   in the all words task  no training data is provided  and testing
is done for whole documents  systems need to tag all content words occurring in the texts 
even if only small amounts of external training data are available 
the analysis of the results for the english lexical sample exercise in the third edition of
senseval  mihalcea   edmonds        suggested that a plateau in performance had been
reached for ml methods  for this task  where the systems had relatively large amounts of
training data  there were many systems on the top  performing very close to each other 
the systems were able to significantly improve the baselines and attained accuracies above
     mihalcea  chklovski    killgariff        
the case was different in the all words task  snyder   palmer         where supervised
systems also performed best  they used training examples from semcor  miller  leacock 
tengi    bunker         which is the only sizable all words sense tagged corpus at the time
of writing this paper  the scarcity of examples and the use of test documents from corpora
unrelated to semcor heavily affected the performance  and only a few systems scored above
the baseline method of assigning the most frequent sense in semcor  in order to be useful
for nlp applications  wsd systems have to address the knowledge acquisition bottleneck
for all  or at least a significant part  of the word types  as evaluated by all words tasks 
lexical sample tasks are useful for evaluating wsd systems under ideal conditions  i e 
regarding availability of training data   but they do not show systems to be scalable to
all the words in the vocabulary  in this work we will use a lexical sample task in order to
adjust some parameters of our system  but the main evaluation is on an all words task  our
experiments are designed accordingly  the lexical sample tests show empirical evidence on
specific parameters  and the all words evaluation compares our systems to the state of the
art 
in this article  we explore a method to alleviate the knowledge acquisition bottleneck at
a large scale  we use wordnet  fellbaum        to automatically acquire examples from the
web  the seminal work of leacock  chodorow  and miller        showed that the approach
was promising  with good results on a small sample of nouns  other works in the field of
automatic acquisition of examples have focused on exploring different approaches to the
acquisition process  agirre  ansa  martinez    hovy        mihalcea        cuadros  padro 
  rigau         with a straightforward application to wsd  those explorations typically
required costly querying over the web  and thus tried a limited number of variations for
a handful of words  our approach is different in spirit  we want to go through the whole
process for all nouns  from the acquisition of examples itself to their use on wsd and the
thorough evaluation on the senseval   lexical sample and senseval   all words datasets 
this comes at the cost of not exploring all the different possibilities at each step  but has
the advantage of showing that the results are extensive  and not limited to a small set of
nouns 
for these reasons  and given the prior work on acquisition techniques  we use the most
efficient and effective example acquisition method according to independent experiments
performed by agirre et al         and cuadros et al          the focus of this paper is thus
on the issues that arise when using those examples as training data of a supervised ml
system  this paper will show that the automatically acquired examples can be effectively
  

fimartinez  lopez de lacalle   agirre

used with or without pre existing data  and that deciding the amount of examples to use
for each sense  the prior distribution  is a key issue 
the objectives of this paper are to show that existing methods to acquire examples from
the web scale up to all nouns  and to study other issues that arise when these examples
are to be used as training data in an all nouns wsd system  our goal is to build a stateof the art wsd system for all nouns using automatically retrieved examples 
given the cost of large scale example acquisition  we decided to limit the scope of our
work only to nouns  we think that noun disambiguation on its own can be a useful tool in
many applications  specially in the ir tasks mentioned above  our method can be easily
adapted to verbs and adjectives  cuadros et al          and we plan to pursue this line in
the future 
the work reported here has been partially published in two previous conference papers 
the method for the automatic acquisition of examples was described by agirre and lopez
de lacalle         a first try on the application of those examples to word sense disambiguation was presented in agirre and martinez      b   in this paper we present a global
view of the whole system  together with a more thorough evaluation  which shows that the
automatically acquired examples can be used to build state of the art wsd systems in a
variety of settings 
the article is structured as follows  after this introduction  related work on the knowledge acquisition bottleneck in wsd is described in section    with a focus on automatic
example acquisition  section   introduces the method to automatically build sensecorpus 
our automatically acquired examples for wordnet senses  section   describes the experimental setting  section   explores some factors on the use of sensecorpus and evaluates
them on a lexical sample task  the final systems are thoroughly evaluated on an all nouns
task in section    finally  section   provides some discussion  and the conclusions and
further work are outlined in section   

   related work
the construction of wsd systems applicable to all words has been the goal of many research initiatives  in this section we will describe related work that looks for ways to
alleviate the knowledge acquisition bottleneck using the following techniques  bootstrapping  active learning  parallel corpora  automatic acquisition of examples and acquisition of
topic signatures  sections   and    which evaluate our proposed system in public datasets 
will review the best performing systems in the literature 
bootstrapping techniques consist on algorithms that learn from a few instances of labeled
data  seeds  and a big set of unlabeled examples  among these approaches  we can highlight
co training  blum   mitchell        and their derivatives  collins   singer        abney 
       these techniques are very appropriate for wsd and other nlp tasks because of
the wide availability of untagged data and the scarcity of tagged data  however  these
systems have not been shown to perform well for fine grained wsd  in his well known work 
yarowsky        applied an iterative bootstrapping process to induce a classifier based on
decision lists  with a minimum set of seed examples  disambiguation results comparable
to supervised methods were obtained in a limited set of binary sense distinctions  but this
success has not been extended to fine grained senses 
  

fion the use of automatically acquired examples for all nouns wsd

recent work on bootstrapping applied to wsd is also reported by mihalcea       
and pham  ng  and lee         in the former  the use of unlabeled data significantly
increases the performance of a lexical sample system  in the latter  pham et al  apply their
wsd classifier to the all words task in senseval    but targeting words over a threshold
of frequency in the semcor and wsj corpora  they observe a slight increase in accuracy
relying on unlabeled data 
active learning is used to choose informative examples for hand tagging  in order to
reduce manual cost  in one of the few works directly applied to wsd  fujii  inui  tokunaga  and tanaka        used selective sampling for the acquisition of examples for the
disambiguation of verb senses  in an iterative process with human taggers  the informative
examples were chosen following two criteria  maximum number of neighbors in unsupervised
data  and minimum similarity with the supervised example set  another active learning
approach is the open mind word expert  mihalcea   chklovski         which is a project
to collect sense tagged examples from web users  the system selects the examples to be
tagged applying a selective sampling method based on two different classifiers  choosing
the unlabeled examples where there is disagreement  the collected data was used in the
senseval   english lexical sample task 
parallel corpora is another alternative to avoid the need of hand tagged data  recently
chan and ng        built a classifier from english chinese parallel corpora  they grouped
senses that share the same chinese translation  and then the occurrences of the word on the
english side of the parallel corpora were considered to have been disambiguated and sense
tagged by the appropriate chinese translations  the system was successfully evaluated
in the all words task of senseval    however  parallel corpora is an expensive resource to
obtain for all target words  a related approach is to use monolingual corpora in a second
language and use bilingual dictionaries to translate the training data  wang   carroll 
       instead of using bilingual dictionaries  wang and martinez        applied machine
translation to text snippets in foreign languages back into english and achieved good results
on english lexical sample wsd 
in the automatic acquisition of training examples  an external lexical resource  wordnet 
for instance  or a sense tagged corpus is used to obtain new examples from a very large
untagged corpus  e g  the web   leacock et al         present a method to obtain sensetagged examples using monosemous relatives from wordnet  our approach is based on this
early work  cf  section     in their algorithm  leacock et al         retrieve the same number
of examples per each sense  and they give preference to monosemous relatives that consist
on a multiword containing the target word  their experiment is evaluated over    nouns
with coarse sense granularity and few senses  the results showed that the monosemous
corpus provided precision close to that of hand tagged data 
another automatic acquisition approach  mihalcea   moldovan        used information
in wordnet  e g  monosemous synonyms and glosses  to construct queries  which were later
fed into the altavista  search engine  four procedures were used sequentially  in a decreasing
order of precision  but with increasing levels of coverage  results were evaluated by hand 
showing that     of the examples were correctly retrieved among a set of       instances
of     word senses  however  the corpus resulting from the experiment was not used to
   http   www altavista com

  

fimartinez  lopez de lacalle   agirre

train a real wsd system  agirre and martinez         in an early precursor of the work
presented here  tried to apply this technique to train a wsd system with unsatisfactory
results  the authors concluded that the examples themselves were correct  but that they
somehow mislead the ml classifier  providing biased features 
in related work  mihalcea        generated a sense tagged corpus  gencor  by using a
set of seeds consisting of sense tagged examples from four sources   i  semcor   ii  wordnet 
 iii  examples created using the method above  and  iv  hand tagged examples from other
sources  e g  the senseval   corpus   by means of an iterative process  the system obtained
new seeds from the retrieved examples  in total  a corpus with about         examples was
gathered  however  the evaluation was carried out on the lexical sample task  showing that
the method was useful for a subset of the senseval   testing words  results for   words were
provided   and without analysing which were the sources of the performance gain  even if
the work presented here uses other techniques  our work can be seen as an extension of this
limited study  in the sense that we evaluate on all words tasks 
these previous works focused on the use of two different kinds of techniques for the
automatic acquisition of examples  namely  the use of monosemous relatives alone  leacock
et al         and the use of a combination of monosemous relatives and glosses  mihalcea
  moldovan        mihalcea         in all cases the examples are directly used to feed
a supervised ml wsd system  but with limited evaluation and no indication that the
methods can scale up  unfortunately  no direct comparison of the alternative methods and
parameters to automatically acquire examples for wsd exists  but we can see a preference
to use the web  as existing corpora would contain very few occurrences of the monosemous
terms or gloss fragments 
a closely related area to that of automatic acquisition of examples for wsd is that
of enriching knowledge bases with topic signatures  for instance  agirre et al         and
agirre  ansa  martinez  and hovy        used the combined monosemous relatives plus
glosses strategy to query altavista  retrieve the original documents and build lists of related
words for each word sense  so called topic signatures   the topic signatures are difficult to
evaluate by hand  so they were applied as context vectors to wsd in a straightforward way 
note that the authors did not train a ml algorithm  but rather combined all the examples
in one vector per sense  they showed that using the web compared favorably to using a
fixed corpus  but was computationally more costly  the system first needs to query a search
engine and then retrieve the original document in order to get an example for the sense 
as an alternative  agirre and lopez de lacalle        showed that it is possible to scale up
and gather examples for all nouns in wordnet if the query is limited to using monosemous
relatives and if the snippets returned by google are used instead of the whole document 
at this point  cuadros et al         set up a systematic framework for the evaluation
of the different parameters that affect the construction of topic signatures  including the
methods to automatically acquire examples  the study explores a wide range of querying
strategies  monosemous synonyms  monosemous relatives at different distances  and glosses 
combined using either and or or operators  on both a particular corpus  the british national corpus  and the web  the best results were obtained using infomap  on the british
national corpus and our monosemous relatives method on the web  agirre   lopez de
   http   infomap nlp sourceforge net

  

fion the use of automatically acquired examples for all nouns wsd

lacalle         contrary to our method  infomap returns only lists of related words  and
thus can not be used to retrieve training examples  these results are confirmed in other
experiments reported by cuadros and rigau        
all in all  the literature shows that using monosemous relatives and snippets from the
web  agirre   lopez de lacalle        provides a method to automatically acquire examples
which scales up to all nouns in wordnet  and provides topic signatures of better quality
than other alternative methods  we will now explain how these examples were acquired 

   building a sense tagged corpus for all nouns automatically
in order to build this corpus  which we will refer to as sensecorpus  we acquired      
google snippets for each monosemous noun in wordnet      including multiwords  e g 
church building   then  for each word sense of an ambiguous noun  we gathered the examples of its monosemous relatives  e g  for sense    of church  we gather examples from its
relative church building   the way to collect the examples is simply by querying the corpus
with the word or string of words  e g  church building   this method is inspired in the
work by leacock et al         and  as already mentioned in section    it has been shown to
be both efficient and effective in experiments on topic signature acquisition 
the basic assumption of this method is that for a given word sense of the target word 
if we had a monosemous synonym of the word sense  then the examples of the synonym
should be very similar to those of the target word sense  and could therefore be used to train
a classifier of the target word sense  the same idea   to a lesser extent  can be applied to
other monosemous relatives  such as direct hyponyms  direct hypernyms  siblings  indirect
hyponyms  etc  the expected reliability decreases with the distance in the hierarchy from
the monosemous relative to the target word sense 
the actual method to build sensecorpus is the following  we collected examples from
the web for each of the monosemous relatives  the relatives have an associated number
 type   which correlates roughly with the distance to the target word  and indicates their
relevance  the higher the type  the less reliable the relative  synonyms have type    direct
hyponyms get type    and distant hyponyms receive a type number equal to the distance
to the target sense  direct hypernyms get type    because they are more general than the
target sense  and can thus introduce more noise than direct hyponyms  we also decided to
include less reliable siblings  but with type    more sophisticated schemes could be tried 
such as using wordnet similarity to weight the distance from the target to the relative
word  however  we chose this approach to capture the notion of distance for its simplicity 
and to avoid testing too many parameters  a sample of monosemous relatives for different
senses of church  together with its sense inventory in wordnet     is shown in figure   
in the following subsections we will describe step by step the method to construct the
corpus  first we will explain the acquisition of the highest possible amount of examples per
sense  and then we will explain different ways to limit the number of examples per sense for
better performance 
    collecting the examples
the method to collect the examples has been previously published  agirre   lopez de
lacalle         and comprises the following steps 
  

fimartinez  lopez de lacalle   agirre

 sense inventory  church 
 sense    a group of christians  any group professing christian doctrine or belief 
 sense    a place for public  especially christian  worship 
 sense    a service conducted in a church 
 monosemous relatives for different senses  of church 
 synonyms  type     church building  sense     church service  sense       
 direct hyponyms  type     protestant church  sense     coptic church  sense       
 direct hypernyms  type     house of prayer  sense     religious service  sense       
 distant hyponyms  type           
 sense      

greek church  sense     western church

 siblings  type     hebraism  sense     synagogue  sense       

figure    sense inventory and a sample of monosemous relatives in wordnet     for church 

   we query google  with the monosemous relatives for each sense  and extract the
snippets returned by the search engine  all snippets are used  up to         but some of
them are dropped out in the next step 
   we try to detect full meaningful sentences in the snippets which contain the target
word  we first detect sentence boundaries in the snippet and extract the sentence that
encloses the target word  some of the sentences are filtered out  according to the following
criteria  length shorter than   words  having more non alphanumeric characters than words
divided by two  or having more words in uppercase than in lowercase 
   the automatically acquired examples contain a monosemous relative of the target
word  in order to use these examples to train the classifiers  the monosemous relative  which
can be a multiword term  is substituted by the target word  in the case of the monosemous
relative being a multiword that contains the target word  e g  protestant church for church 
we can choose not to substitute  because protestant  for instance  can be a useful feature
for the first sense of church  we tried both alternatives  and section   will show that we
obtain slightly better results if no substitution is applied for such multiwords 
   for a given word sense  we collect the desired number of examples  see the following
section  in order of their type  we first retrieve all examples of type    then type    etc  up to
type   until the necessary examples are obtained  we did not collect examples from type  
upwards  we did not make any distinctions between the relatives from each type  contrary
to leacock et al         we do not give preference to multiword relatives containing the
target word 
all in all  we have acquired around     million examples for the nouns in wordnet using
this technique  which are publicly available   
   we use the off line xml interface kindly provided by google for research 
   http   ixa si ehu es ixa resources sensecorpus 

  

fion the use of automatically acquired examples for all nouns wsd

    number of examples per sense  prior 
previous work  agirre   martinez        has reported that the distribution of the number
of examples per word sense  prior for short  has a strong influence in the quality of the
results  that is  the results degrade significantly whenever the training and testing samples
have different distributions of the senses  it has also been shown that a type based approach
that predicts the majority sense of a word in the domain can provide good performance by
itself  mccarthy  koeling  weeds    carroll        
as we are extracting examples automatically  we have to decide how many examples we
will use for each sense  in order to test the impact of the prior  different settings have been
tried 
 no prior  we take an equal amount of examples for each sense 
 web prior  we take all examples gathered from the web 
 automatic ranking  the number of examples is given by a ranking obtained following
the method by mccarthy et al         
 sense tagged prior  we take a number of examples proportional to the relative frequency of the word senses in some hand tagged corpus 
the first method assumes uniform priors  the second assumes that the number of
monosemous relatives and their occurrences are correlated to sense importance  that is 
frequent senses would have more occurrences of their monosemous relatives  the fourth
method uses the information in some hand tagged corpus  typically semcor  note that this
last kind of prior requires hand tagged data  while the rest  including the third method
below  are completely unsupervised 
the third method is more sophisticated and deserves some further clarification  mccarthy et al         present a method to acquire sense priors automatically from a domain
corpus  this is a two step process  the first step is a corpus based method  which given
a target word builds a list of contextually similar words  lin        with weights  in this
case  the co occurrence data was gathered from the british national corpus  for instance 
given a target word like authority  the list of the topmost contextually similar words include government  police  official and agency     the second step ranks the senses of the
target word  depending on the scores of a wordnet based similarity metric  patwardhan
  pedersen        relative to the list of contextually similar words  following with the
example  the pairwise wordnet similarity between authority and government is greater for
sense   of authority  which is evidence that this sense has some prominence in the corpus 
the pairwise similarity scores are added  yielding a ranking for the   senses of authority 
table   shows in the column named auto mr the normalized scores assigned to each of
the senses of authority according to this technique 
table   shows the number of examples per type           that are acquired for church
following the semcor prior  the last column gives the number of examples in semcor  note
that the number of examples is sometimes smaller than        maximum number of snippets
returned by google in one query   this can be due to rare monosemous relatives  but is
   actual list of words taken from the demo in http   www cs ualberta ca  lindek demos depsim htm 

  

fimartinez  lopez de lacalle   agirre

sense
church  
church  
church  
overall

 
 
   
   
   

 
   
   
 
   

 
   
   
  
     

 
 
 
 
 

total
     
   
   
     

semcor
  
  
  
   

table    examples per type           that are acquired from the web for the three senses
of church following the semcor prior  and total number of examples in semcor 

sense
authority  
authority  
authority  
authority  
authority  
authority  
authority  
overall

semcor
 ex
  
 
 
 
 
 
 
  

 
    
    
    
   
   
   
   
     

web pr
 ex
 
   
   
     
    
     
    
   
   
    
   
  
   
    
   
     
     

auto 
 ex
   
  
  
  
   
  
  
   

sensecorpus
mr
semcor pr
 
 ex
 
    
   
    
    
   
    
    
   
    
   
   
    
    
  
   
   
  
   
   
 
   
     
    
     

semcor
 ex
   
  
  
  
  
  
 
   

mr
 
    
    
    
   
   
   
   
     

senseval
test
 ex
 
  
    
  
    
 
   
 
   
  
    
  
    
 
   
  
     

table    distribution of examples for the senses of authority in different corpora  pr
 proportional  and mr  minimum ratio  columns correspond to different ways to
apply semcor prior 

usually caused by the sentence extraction and filtering process  which discards around    
of the snippets 
the way to apply the prior is not straightforward  for illustration  we will focus on the
semcor prior  in our first approach for semcor prior  we assigned       examples to the
major sense in semcor  and gave the other senses their proportion of examples  we call this
method proportional  pr   but in some cases the number of examples extracted will be
less than expected by the distribution of senses in semcor  as a result  the actual number
of examples available would not follow the desired distribution 
as an alternative  we computed  for each word  the minimum ratio  mr  of examples
that were available for a given target distribution and a given number of examples extracted
from the web  we observed that this last approach would reflect better the original prior 
at the cost of having less examples 
table   presents the different distributions of examples for authority  there we can see
the senseval testing and semcor distributions  together with the total number of examples
in the web  web pr   the semcor proportional distribution  semcor pr  and minimum
ratio  semcor mr   and the automatic distribution with minimum ratio  auto mr  
getting a maximum of one thousand examples per monosemous relative allows to get up to
       examples for the second sense  web pr column   but only    for the sixth sense 
  

fion the use of automatically acquired examples for all nouns wsd

semcor
word
art
authority
bar
bum
chair
channel
child
church
circuit
day
detention
dyke
facility
fatigue
feeling
average
total

web
prior
      
      
      
      
      
      
      
     
      
      
     
     
      
     
     
      
       

automatic
prior
     
   
     
     
     
      
   
     
     
     
   
   
     
     
   
     
       

semcor
prior
      
   
      
     
     
     
     
     
     
     
     
     
     
     
     
     
       

semcor
word
grip
hearth
holiday
lady
material
mouth
nation
nature
post
restraint
sense
spade
stress
yew

web
prior
      
     
      
      
       
   
   
      
      
      
      
     
      
      

automatic
prior
   
     
     
   
     
   
   
     
     
     
     
     
     
     

semcor
prior
     
     
     
     
     
   
   
      
     
     
     
     
     
     

table    number of examples following different sense distributions for the senseval  
nouns  minimum ratio is applied both for the semcor and automatic priors 

the sixth sense has a single monosemous relative  which is a rare word with few hits in
google  while the second sense has many and frequent monosemous relatives 
regarding the use of minimum ratio  the table illustrates how mr allows to better
approximate the distribution of senses in semcor  the first sense  has     in semcor 
but only gets       in sensecorpus with the proportional semcor prior because there
are only     examples in sensecorpus for the first sense  in contrast sensecorpus with
minimum ratio using semcor does assign       of the examples to the first sense  this
better approximation comes at the cost of getting     examples for authority  in contrast
to       with pr  note that authority occurs only    times in semcor 
the table also shows that for this word the distributions of senses in semcor and
senseval test have important differences  sense   gets      and       respectively   although the most frequent sense is the same  for the web and automatic distributions  the
most salient sense is different from that in semcor  with the web prior  web pr column 
assigning only      to the first sense  note that the automatic method is able to detect that
sense   is salient in the test corpus  while semcor ranks it only  th  in general  distribution
discrepancies similar to those in the table can be observed for the other words in the test
set 
to conclude this section  table   shows the number of examples acquired automatically
for each word in the senseval   lexical sample following three approaches  the web prior 
the semcor prior with minimum ratio  and the automatic prior with minimum ratio  we
can see that retrieving all the examples  web prior  we get        examples in average per
word  and respectively       or       if we apply the semcor prior or the automatic prior 
   the senses in wordnet are numbered according to their frequency in semcor  so the first sense in
wordnet is paramount to the most frequent sense in semcor 

  

fimartinez  lopez de lacalle   agirre

    decision lists
the supervised learning method used to measure the quality of the corpus is decision lists
 dl   this simple method performs reasonably well in comparison with other supervised
methods in senseval all words  as we will illustrate in table       and preliminary experiments showed it to perform better with the automatically retrieved examples than more
sophisticated methods like support vector machines or the vector space model  it is well
known that learning methods perform differently according to several conditions  as showed
for instance by yarowsky and florian         who analyzed in depth the performance of
various learning methods  including dl  in wsd tasks 
we think that the main reason for dl to perform better in our preliminary experiments
is that sensecorpus is a noisy corpus with conflicting features  decision lists use the
single most powerful feature in the test context to make predictions  in contrast to other
ml techniques  and this could make them perform better in this corpus  specially in the
all words task  with only a few hand tagged examples per word in most cases  even the
most sophisticate ml algorithms cannot deal with the problem by themselves  while the
best systems in the senseval   lexical sample rely on complex kernel based methods  in the
all words task the top systems are those that find external ways to deal with the sparseness
of data and then apply well known methods  such as memory based learning or decision
trees  mihalcea   edmonds        
the dl algorithm is described by yarowsky         in this method  the sense sk with
the highest weighted feature fi is selected  according to its log likelihood  see formula    
for our implementation  we applied a simple smoothing method  for the cases where the
denominator is zero  we use     as the denominator  this is roughly equivalent to assigning
a     probability mass to the rest of senses  and has been shown to be effective enough
compared to more complex methods  yarowsky        agirre   martinez      a  
p r sk  fi  
 
j  k p r sj  fi  

weight sk   fi     log  p

   

    feature types
the feature types that we extracted from the context can be grouped in three main sets 
local collocations  bigrams and trigrams formed with the words around the target  these
features are constituted by lemmas  word forms  or pos tags    other local features are those
formed with the previous posterior lemma word form in the context 
syntactic dependencies  syntactic dependencies were extracted using heuristic patterns 
and regular expressions defined with the pos tags around the target    the following relations were used  object  subject  noun modifier  preposition  and sibling 
topical features  we extract the lemmas of the content words both in the whole sentence
and in a   word window around the target  we also obtain salient bigrams in the context 
with the methods and the software described by pedersen        
   the pos tagging was performed with the fntbl toolkit  ngai   florian        
   this software was kindly provided by david yarowskys group  from the johns hopkins university 

  

fion the use of automatically acquired examples for all nouns wsd

the complete feature set was applied for our main experiments on the all words senseval  corpus  however  for our initial experiments in the lexical sample task only local features
and topical features  without salient bigrams  were applied 

   experimental setting
we already noted in the introduction that lexical sample evaluations as defined in senseval
are not realistic  relatively large amounts of training examples are available  those are drawn
from the same corpus as the test examples  and both train and test examples are tagged by
the same team  besides  developing a system for a handful of words does not necessarily
show that it is scalable  in contrast  all words evaluations do not provide training data 
supervised wsd systems typically use semcor  miller et al         for training  this
corpus offers tagged examples for all open class words occurring in a         word subset
of the balanced brown corpus  tagged with wordnet     senses  in contrast to lexicalsample  some polysemous words like authority only get a handful of examples     in this
case  cf  table     note that the test examples  from senseval  and semcor come from
different corpora and thus might be related to different domains  topics or genres  an
added difficulty is posed by the fact that they have been tagged by different teams of
annotators from distinct institutions 
with all this on mind  we designed two sets of experiments  the first set was performed
on a sample of nouns  lexical sample   and it was used to develop and fine tune the method
in basic aspects like the effect of the kinds of features and the importance of the prior  we
did not use the training examples  except to measure the impact of the priors  we provide
a comparison with state of the art systems 
the second set of experiment was used to show that our method is scalable  useful
for any noun  and performs in the state of the art of wsd in a realistic setting  we thus
selected to apply wsd on all the nouns in running text  all nouns   in this setting we apply
the best configurations obtained from the first set of experiments  and explore the use of
sensecorpus alone  combined with priors from semcor  and also with training data from
semcor  we provide a comparison of our results with those of state of the art systems 
for lexical sample evaluation  the test part of the senseval   english lexical sample
task was chosen  which consisted on instances of    nouns  tagged with wordnet     senses 
the advantage of this corpus was that we could focus on a word set with enough examples
for testing  besides  it is a different corpus  and therefore the evaluation is more realistic
than that made using cross validation over semcor  in order to factor out pre processing
and focus on wsd  the test examples whose senses were multiwords or phrasal verbs were
removed  note that they are not as problematic since they can be efficiently detected with
other methods in a preprocess 
it is important to note that the training part of senseval   lexical sample was not used
in the construction of the systems  as our goal was to test the performance we could achieve
with minimal resources  i e  those available for any word   we only relied on the senseval  
training prior in preliminary experiments on local topical features  and as an upperbound
to compare the performance with other types of priors 
for the all words evaluation we relied on the senseval   all words corpus  snyder  
palmer         the test data for this task consisted of       words of text  the data was
  

fimartinez  lopez de lacalle   agirre

extracted from two wall street journal articles and one excerpt from the brown corpus 
the texts represent three different domains  editorial  news story  and fiction  overall       
words were tagged with wordnet        senses        if we do not include multiwords   from
these      occurrences correspond to polysemous nouns that are not part of multiwords 
and these comprise our testing set 
as the rest of senseval participants  we had an added difficulty in that wordnet versions
do not coincide  we therefore used one of the freely available mappings between wordnet
versions  daude  padro    rigau        to convert the training material from semcor
 tagged with wordnet     senses  into wordnet     and wordnet       versions  depending
on the target corpus   we preferred to use this mapping rather that relying on other
available mappings or converted semcors  to our knowledge  no comparative evaluation
among mappings has been performed  and daude et al  show that their mapping obtained
very high scores in an extensive manual evaluation  note that the versions of semcor
available in the web  other than the original one  tagged with wordnet      have also been
obtained using an automatic mapping 
in both lexical sample and all nouns settings  we provide a set of baselines  which are
based on the most frequent heuristic  this heuristic is known to be hard to beat in wsd 
specially for unsupervised systems that do not have access to the priors  and even for
supervised systems in the all nouns setting 

   lexical sample evaluation
we performed four sets of experiments in order to study different factors  and compare our
performance to other state of the art unsupervised systems in the senseval   lexical sample
task  first we analyzed the results of the systems when using different sets of local and
topical features  as well as substituting or not multiwords  the next experiments were
devoted to measure the effect of the prior on the performance  after that  we compared
our approach with unsupervised systems that participated in senseval    as we mentioned
in the introduction  the results obtained in lexical sample evaluations are not realistic  in
that we cannot expect to have hand tagged data for all words in any target corpus  for this
reason we do not report results of supervised systems  which do use the training data   the
next section on all nouns evaluation  which is more realistic  does compare to supervised
systems
    local vs  topical features  substitution
previous work on automatic acquisition of examples  leacock et al         has reported
lower performance when using local collocations formed by pos tags or closed class words 
in contrast  kohomban and lee         in a related approach  used only local features for
wsd because they discriminated better between senses  given the fact that sensecorpus
has also been constructed automatically  and the contradictory results on those previous
works  we performed an initial experiment comparing the results using local features  topical
features  and a combination of both  in this case we used sensecorpus with senseval training
prior  distributed according to the mr approach  and always substituting the target word 
the results  per word and overall  are given in table   
  

fion the use of automatically acquired examples for all nouns wsd

local feats 
word
art
authority
bar
bum
chair
channel
child
church
circuit
day
detention
dyke
facility
fatigue
feeling
grip
hearth
holiday
lady
material
mouth
nation
nature
post
restraint
sense
spade
stress
yew
overall

coverage
    
    
    
     
     
    
     
     
    
    
     
     
    
     
     
     
     
     
     
     
     
     
     
    
    
    
     
     
     
    

precision
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

recall
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

topical
feats 
recall
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

combined
subst 
recall
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

combined
no subst 
recall
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    results per feature type  local  topical  and combination   using sensecorpus with
senseval   training prior  mr   coverage and precision are given only for local
features  topical and combination have full coverage   combination is shown for
both substitution and no substitution options  the best recall per word is given
in bold 

  

fimartinez  lopez de lacalle   agirre

in this experiment  we observed that local collocations achieved the best precision overall  but the combination of all features obtained the best recall  local features achieve
      precision for       coverage overall     while the topical and combined features have
full coverage  the table shows clear differences in the results per word  a fact which is
also known for other algorithms using real training data  yarowsky   florian         this
variability is another important factor to focus on all words settings  where large numbers
of different words are involved 
we also show the results for not substituting the monosemous relative by the target
word when the monosemous relative is a multiword  we can see that the results are mixed 
but that there is an slight overall improvement if we choose not to substitute in those cases 
for the following experiments  we chose to work with the combination of all features with
no substitution  as it achieved the best overall recall 
    impact of prior
in order to evaluate the acquired corpus  our first task was to analyze the impact of the
prior  as we mentioned in section      when training decision lists with the examples in
sensecorpus  we need to decide the amount of examples for each sense  what can be seen
as the estimation of the prior probabilities of the senses  
table   shows the recall   attained by dl with each of the four proposed methods to
estimate the priors for each target word  plus the use of the training part of senseval   lexical
sample to estimate the prior  note that this last estimation method is not realistic  as one
cannot expect to have hand tagged data for all words in a given target corpus  and should
thus be taken as an upperbound  in fact it is presented in this section for completeness 
and will not be used for comparison with other systems 
the results show constant improvement from the less informative priors to the most
informed ones  among the three unsupervised prior estimation methods  the best results are
obtained with the automatic ranking  and the worst by the uniform distribution  no prior
column   with the distribution of examples as returned by sensecorpus  web prior  in
the middle  estimating the priors from hand tagged data improves the results considerably 
even when the target corpus and estimation corpus are different  semcor   but the best
results overall are obtained when the priors are estimated from the training part of senseval  lexical sample dataset  the results word by word show that each word behaves differently 
which is a well known behavior in wsd  note that for all priors except the most informed
one a number of words have performances below      which might indicate that dl trained
on sensecorpus is very sensitive to badly estimated priors 
table   shows the overall results from table    together with those obtained using the
prior on its own  prior only   the results show that the improvement attained by training
on sensecorpus is most prominent for the unsupervised priors  from     to      percentage
points   with lower improvements  around     percentage points  for the priors estimated
from hand tagged corpora  these results show clearly that the acquired corpus has use    note that due to the sparse data problem  some test examples might not have any feature in common
with the training data  in those cases the dl algorithm does not return any result  and thus the coverage
can be lower than     
    all the results in the following tables are given as recall  as the coverage is always      and precision
equals to recall in this case 

  

fion the use of automatically acquired examples for all nouns wsd

unsupervised
word
art
authority
bar
bum
chair
channel
child
church
circuit
day
detention
dyke
facility
fatigue
feeling
grip
hearth
holiday
lady
material
mouth
nation
nature
post
restraint
sense
spade
stress
yew
overall

no
prior
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

web
prior
    
    
    
    
    
    
   
    
    
   
    
    
    
    
    
   
    
   
    
    
    
    
    
    
   
    
    
    
    
    

autom 
ranking
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

minimally supervised
semcor
prior
    
    
    
   
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
   
    
    

senseval  
prior
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    performance  recall  of sensecorpus on the    nouns in senseval   lexical sample 
using different priors to train dl  best results for each word in bold 

ful information about the word senses  and that the estimation of the prior is extremely
important 

prior
no prior
web prior
autom  ranking
semcor prior
senseval  prior

type
unsupervised
minimallysupervised

only prior
    
    
    
    
    

sensecorpus
    
    
    
    
    

diff 
     
    
    
    
    

table    performance  recall  on the nouns in senseval   lexical sample  in each row  results
for a given prior on its own  of sensecorpus using that prior  and the difference
between both 

  

fimartinez  lopez de lacalle   agirre

method
sensecorpus  semcor prior 
uned
sensecorpus  autom  prior 
kenneth litkowski clr ls
haynes iit 
haynes iit 

type
minimallysupervised
unsupervised

recall
    
    
    
    
    
    

table    results for nouns of our best minimally supervised and fully unsupervised systems  in bold  compared to the unsupervised systems that took part in senseval  
lexical sample 

    comparison with other systems
at this point  it is important that we compare the performance of our dl based approach
to other systems in the state of the art  in this section we compare our best unsupervised
system  the one using automatic ranking  and the minimally unsupervised system  using
semcor prior  with those systems participating on senseval   that were deemed as unsupervised  in order to have the results of the other systems  we used the resources available from
the senseval   competition  where the answers of the participating systems in the different
tasks were available     this made possible to compare the results on the same test data 
set of nouns and occurrences 
from the   systems presented in the senseval   lexical sample task as unsupervised  the
wasp bench system relied on lexicographers to hand code information semi automatically
 tugwell   kilgarriff         this system does not use the training data  but as it uses
manually coded knowledge we think it falls in the supervised category 
the results for the other   systems and our own are shown in table    we classified the
uned system  fernandez amoros  gonzalo    verdejo        as minimally supervised  it
does not use hand tagged examples for training  but some of the heuristics that are applied
by the system rely on the prior information available in semcor  the distribution of senses
is used to discard low frequency senses  and also to choose the first sense as a back off
strategy  on the same conditions  our minimally supervised system attains       recall 
nearly   points better 
the rest of the systems are fully unsupervised  and they perform significantly worse
than our unsupervised system 

   all nouns evaluation
as we explained in the introduction  the main goal of this research is to develop a wsd
system that is able to tag all nouns in context  not only a sample of them  in the previous
section we explored different settings for our system  adjusting them according to the results
for a handful of words on a lexical sample task 
    http   www senseval org

  

fion the use of automatically acquired examples for all nouns wsd

in this section we will test sensecorpus in the     occurrences of polysemous nouns
present in the senseval   all words task  and compare our results with the performance of
the systems that participated in the competition  we also present an analysis of the results
according to the frequency of the target nouns 
we have developed three different systems  all based on sensecorpus  but with different requirements of external information  the less informed system is the unsupervised
system  called sensecorpus u   which does not use any hand coded corpus or prior extracted therein  this system relies on the examples in sensecorpus following the automatic ranking  mccarthy et al         to train the dl  see section       the following
system is minimally supervised  sensecorpus ms   in the sense that it uses the priors
obtained from semcor to define the distribution of examples from sensecorpus that are
fed into the dl  lastly  the most informed system trains the dl with the hand tagged
examples from semcor and sensecorpus  following the semcor prior   and is known as
sensecorpus s  the three systems follow a widely used distinction among unsupervised 
minimally supervised and supervised systems  and we will compare each of them to similar
systems that participated on senseval   
these systems respond to realistic scenarios  the unsupervised system is called for in
case of languages for which no all words hand tagged corpus exists  or in cases where the priors coming from semcor are not appropriate  as in domain specific corpora  the minimally
supervised system is useful when there is no hand tagged corpora  but when there is some
indication of the distribution of senses  lastly  the supervised system  sensecorpus s 
shows the performance of sensecorpus on the currently available conditions for english 
that is  when an all words corpus of limited size is available 
in order to measure the real contribution of sensecorpus  we compare our three systems
to each of the following baselines  sensecorpus u vs  the first sense according to the
automatically obtained ranking  sensecorpus ms vs  the most frequent sense in semcor 
and sensecorpus s vs  the decision lists trained on semcor  in order to judge the
significance of the improvements  we applied one tail paired t test 
    comparison with unsupervised systems in senseval  
from the systems that participated in the all words task only three did not rely on any
hand tagged corpora  not even for estimating prior information   we compare the performance of those systems with our unsupervised system sensecorpus u in table    in order
to make a fair comparison with respect to the participants  we removed the answers that did
not correctly guess the lemma of the test instance  discarding errors when pre processing
the senseval   xml data  
we can see that one of the participating systems was the automatic ranking by mccarthy
et al         that we used as a baseline  although we were able to improve this system  our
results are below the best unsupervised system  irst ddd lsi   strapparava  gliozzo   
giuliano         surprisingly  this unsupervised method is able to obtain better performance
on this dataset than the version that relies on semcor frequencies  irst ddd    see next
subsection   but this discrepancy is not explained by the authors  the reasons for the
remarkable results of irst ddd lsi are not clear  and subsequent publications by the
authors do not shed any light on it 
  

fimartinez  lopez de lacalle   agirre

code
irst ddd lsi
sensecorpus u
autops  baseline 
dlsi ua

method
lsi
decision lists
automatic rank 
wordnet domains

attempt 
   
   
   
   

prec 
    
    
    
    

rec 
    
    
    
    

f
    
    
    
    

p value
     

     
     

table    performance of all unsupervised systems participating in senseval   all words for
the     polysemous nouns  accompanied by p values of the one tailed paired t test
with respect to our unsupervised system  in bold  

code
sensecorpus ms
mfs  baseline 
irst ddd   
clr   aw
kunlp
irst ddd   

method
dl
mfs
domain driven
dictionary clues
similar relative in wordnet
domain driven

attempt 
   
   
   
   
   
   

prec 
    
    
    
    
    
    

rec 
    
    
    
    
    
    

f
    
    
    
    
    
    

p value

     
     
     
     
     

table    performance of all minimally supervised systems participating in senseval   allwords for the     polysemous nouns  accompanied by p values of the one tailed
paired t test with respect to sensecorpus ms  in bold  

the improvement over the baseline is lower here than in the lexical sample case  but it
is significant at the      level  significance is  p value   in order to explore the reasons
for this  we performed further experiments separating the words in different sets according
to their frequency in semcor  as reported below in section     
    comparison with minimally supervised systems in senseval  
there were four systems in senseval that used semcor to estimate the sense distribution 
without using the examples of each word for training  we show the performance of these
systems  together with our own and the most frequent sense baseline in table   
the results show that the sensecorpus examples are able to obtain the best performance
of this kind of systems  well above the rest  the improvement over the semcor mfs baseline
is significant at the      level 
    comparison with supervised systems in senseval  
most of the systems that participated in the all words task were supervised systems that
relied mainly on semcor  in table    we present the results of the top    competing systems
and our system  trained on sensecorpus and semcor  we also include the dl system when
trained only in semcor  as a baseline 
the results show that using sensecorpus we are able to obtain a significant improvement
of      points in f score over the baseline  this score places our system as second  close
  

fion the use of automatically acquired examples for all nouns wsd

code
senselearner
sensecorpus s
lccaw
kuaw ans
r d english
gambl aw
upv eaw upv eaw 
meaning
upv eaw upv eaw
prob 
semcor baseline
ujaen 

method
syntactic patterns
dl

ensemble
optim  timbl
ensemble

dl

attempt 
   
   
   
   
   
   
   
   
   
   
   
   

prec 
    
    
    
    
    
    
    
    
    
    
    
    

rec 
    
    
    
    
    
    
    
    
    
    
    
    

f
    
    
    
    
    
    
    
    
    
    
    
    

p value
     

     
     
     
     
     
     
     
     
     
     

table     performance of the top    supervised systems participating in senseval   allwords for the     polysemous nouns  accompanied by p values of the one tailed
paired t test with respect to sensecorpus s  in bold  

to the best system for all nouns  the statistical significance tests score below     for the
top   systems  and over     for the rest of systems  this means that our system performs
similar to the top three systems  but significantly better than the rest 
    analysis of the performance by word frequency
in previous sections we observed that different words achieve different rates of accuracy 
for instance  the lexical sample experiments showed that the precision of the unsupervised
system ranged between       and        cf  table     clearly  there are some words
whose performance is very low when using sensecorpus  in this section  we will group the
nouns in the senseval   all nouns task according to their frequency to see whether there is
a correlation between the frequency of the words and the performance of our system  our
goal is to identify sets of words that can be disambiguated with higher accuracy by this
method  this process would allow us to previously detect the type of words our system can
be applied to  thus providing a better tool to work in combination with other wsd systems
that exploit other properties of language 
for this study  we created separate word sets according to their frequency of occurrence
in semcor  table    shows the different word sets  with their frequency ranges  the number
of nouns in each range  and the average polysemy  we can see that the most frequent words
tend to be also the most polysemous  in the case of supervised systems  polysemy and
number of training examples tend to compensate each other  yielding good results for those
kinds of words  that is  polysemous words are more difficult to disambiguate  but they also
have more examples to train in semcor  agirre   martinez        
table    shows the results for different frequency ranges for the top unsupervised systems in senseval    together with our method  we can see that for all the systems the
performance is very low in the high frequency range  the best performing system  irstddd lsi  profits from the use of a threshold and leaves many of these instances unanswered 
regarding the improvement of sensecorpus u over the automatic ranking baseline  au  

fimartinez  lopez de lacalle   agirre

range
   
    
    
    
    
     
   
overall

 nouns
   
   
  
  
  
  
   
   

avg  polysemy
   
   
   
   
   
   
   
   

table     number of noun occurrences in each of the frequency ranges  in semcor   with
average polysemy 

   
    
    
    
    
     
   
overall

dlsi ua
att 
f sc 
   
     
  
     
  
     
  
     
  
     
  
    
   
     
   
     

irst ddd lsi
att 
f sc 
   
     
  
     
  
     
  
     
  
     
  
     
  
     
   
     

sensecorpus u
att 
f sc 
   
     
  
     
  
     
  
     
  
     
  
     
   
     
   
     

autops
att 
f sc
   
     
  
     
  
     
  
     
  
     
  
     
   
     
   
     

table     results of each of the unsupervised systems in senseval   all words  as evaluated
on the nouns in each semcor frequency range  att  stands for number of words
attempted at each range  best f score per system given in bold 

tops   the best results are obtained in the low frequency range         when the baseline
scores in the        f score range  the results of sensecorpus are lower than the baseline
for words with frequency higher than     this suggests that the system is more reliable for
low frequency words  and a simple threshold that takes into account the frequency of words
would be indicative of the performance we can expect  the same behavior is also apparent
in the other unsupervised systems  which shows that this is a weak spot for this kind of
systems  we think that future research should focus on those high frequency words 

   discussion
in this work we have implemented and evaluated an all words wsd system for nouns
that is able to reach state of the art performance in all three supervised  unsupervised and
semi supervised settings  we have produced different systems combining sensecorpus with
different priors and the actual examples from semcor  the supervised system  trained
with both hand tagged  semcor  and automatically obtained corpora  reaches an f score of
       and would rank second in the senseval   all nouns test data  the semi supervised
system  using the priors from semcor but no manually tagged examples  would rank first
   

fion the use of automatically acquired examples for all nouns wsd

on its class  and the unsupervised system second  in all cases  sensecorpus improves over
the baselines 
the results are remarkable  if we compare our system to those which came out first
in the unsupervised and supervised settings  we see that each of them uses a completely
different strategy  on the contrary  our system  using primarily the automatically acquired
examples  is able to perform in the top ranks in all three settings 
in any case  a deep gap exists among the following three kinds of systems   i  supervised
systems with specific training  e g  senseval lexical sample systems    ii  supervised systems
with all words training  e g  those trained using semcor   and  iii  unsupervised systems 
our algorithm has been implemented as an all words supervised system  and as an unsupervised system  although our implementations obtain state of the art performance in their
categories  there are different issues that could be addressed in order to close these gaps 
and make all words unsupervised performance closer to those of the supervised systems 
we identified three main sources of error  the low quality of the relatives applied to
some words  the different distributions of senses in training and testing data  and the low
performance on high frequency  and highly polysemous  words  we examine each of them
in turn 
the algorithm suffers from the noise introduced by relatives that are far from the target
word  and do not share the local context with it  better filtering would be required to
alleviate this problem  and one way to do this could be to retrieve examples only when they
share part of the local context with the target word and discard other examples  another
interesting aspect of this problem would be to identify the type of words that achieve low
performance with sensecorpus  we already observed that high frequency words obtain low
performance  and another study on performance according to the type of relatives would
be useful for a better application of the algorithm 
in order to deal with words that do not have close wordnet relatives  another source
of examples would be to use distributionally similar words  the words would be obtained
by methods such as the one presented by lin         and the retrieved examples would be
linked to the target senses using the wordnet similarity package  patwardhan   pedersen 
      
the second main problem of systems that rely on automatic acquisition is the fact that
the sense distributions in training and test data can be very different  and this seriously
affects the performance  our system relies on an automatically obtained sense ranking to
alleviate this problem  however  some words still get too many examples for senses that are
not relevant in the domain  in preliminary experiments  we observed the benefit of using
heuristics to filter out these senses  such as using the number of close relatives in wordnet 
with promising results 
finally  a third problem is observed in section      which is the fact that high frequency
words do not profit from automatically acquired examples  for most unsupervised methods 
these frequent  and very polysemous  words get low performances  and threshold based
systems usually discard answering them  a straightforward way to improve the f score of
our system would be to apply a threshold to discard these words and apply another method
or back off strategy on them 
all in all  detecting the limitations of the system can give us important clues to work
towards an accurate unsupervised all words system  the literature shows that no single
   

fimartinez  lopez de lacalle   agirre

unsupervised system is able to perform well for all words  if we were able to identify the type
of words that were more suited to different algorithms and heuristics  the integration of these
algorithms into one single combined system could be the way to go  for instance  we could
detect in which cases the relatives of a target word are too different to apply the sensecorpus
approach  or the cases where the automatic ranking has not enough evidence  we have also
observed that simple heuristics such as the number of close relatives in wordnet can be
successfully applied to some sets of words  meta learning techniques  vilalta   drissi       
could be very useful to exploit the strengths of unsupervised systems 

   conclusions and future work
this paper presents evidence showing that a proper use of automatically acquired examples
allows for state of the art performance on wsd of nouns  we have gathered examples for all
nouns in wordnet     in a resource called sensecorpus  amounting to     million examples 
and made this resource publicly available to the community 
we have used the examples to train a supervised wsd system  in a variety of settings  on
its own  combined with prior information coming from different sources  or combined with
training examples from semcor  depending on the knowledge used  we are able to build 
respectively  an unsupervised system that has not seen any hand labeled training data  a
semisupervised one that only sees the priors in a generic hand labeled corpus  semcor  
and a fully supervised system that also uses the generic hand labeled corpus  semcor  as
training data 
the evaluation in both lexical sample and all words settings has shown that sensecorpus
improves over commonly used baselines in all combinations  and achieves state of the art
performance in the all words senseval   evaluation set for nouns  previous work on automatic example acquisition has been evaluated on a handful of words  in contrast we have
shown that we are able to scale up to all nouns producing excellent results  in the way  we
have learned that the use of the prior of the senses is crucial to apply the acquired examples
effectively 
in the discussion we have outlined different ways to overcome the limitations of our
system  and each of the proposed lines could improve significantly the current performance 
although the recent literature shows that there is no unsupervised system that performs
with high precision for all words  we believe that the different systems complement each
other  as they usually perform well for different sets of words  from a meta learning perspective  we could build a word expert system that is able to apply the best knowledge
source for the problem  sensecorpus  hand tagged examples  simple heuristics  or other
unsupervised algorithms that can be incorporated 
for future work  aside from the proposed improvements  we think that it would be
interesting to apply the method to other testbeds  in order to be applied  the monosemous
relative method requires an ontology and a raw corpus  such resources can be found in many
specific domains  such as biomedicine  that do not have the fine grainedness of wordnet 
and could lead to more practical applications 
   

fion the use of automatically acquired examples for all nouns wsd

acknowledgments
this work has been partially financed by the ministry of education  know project  ict             and the basque government  consolidated research groups grant  it         
oier lopez de lacalle was supported by a phd grant from the basque government  david
martinez was funded by the australian research council  grant no  dp        

references
abney  s          bootstrapping  in proceedings of the   th annual meeting of the association for computational linguistics  acl    philadelphia 
agirre  e   ansa  o   martinez  d     hovy  e          enriching very large ontologies using
the www  in proceedings of the ontology learning workshop  organized by ecai 
berlin  germany  
agirre  e   ansa  o   martinez  d     hovy  e          enriching wordnet concepts with
topic signatures  in procceedings of the siglex workshop on wordnet and other
lexical resources  applications  extensions and customizations  in conjunction with
naacl 
agirre  e     edmonds  p   eds            word sense disambiguation  algorithms and
applications  springer 
agirre  e     lopez de lacalle  o          publicly available topic signatures for all wordnet nominal senses  in proceedings of the  th international conference on language
resources and evaluation  lrec   lisbon  portugal 
agirre  e     martinez  d          exploring automatic word sense disambiguation with decision lists and the web  in procedings of the coling      workshop on semantic
annotation and intelligent content  luxembourg 
agirre  e     martinez  d       a   smoothing and word sense disambiguation  in proceedings of expaa for natural language processing  estal   alicante  spain 
agirre  e     martinez  d       b   unsupervised wsd based on automatically retrieved
examples  the importance of bias  in proceedings of the conference on empirical
methods in natural language processing  barcelona  spain 
blum  a     mitchell  t          combining labeled and unlabeled data with co training 
in proceedings of the   h annual conference on computational learning theory  pp 
       new york  acm press 
chan  y     ng  h          scaling up word sense disambiguation via parallel texts  in
proceedings of the   th national conference on artificial intelligence  aaai       
pittsburgh  pennsylvania  usa 
collins  m     singer  y          unsupervised models for named entity classification 
in proceedings of the joint sigdat conference on empirical methods in natural
language processing and very large corpora  emnlp vlc    college park  md 
usa 
   

fimartinez  lopez de lacalle   agirre

cuadros  m   padro  l     rigau  g          an empirical study for automatic acquisition
of topic signatures  in proceedings of third international wordnet conference  jeju
island  korea  
cuadros  m     rigau  g          quality assessment of large scale knowledge resources  in
proceedings of the      conference on empirical methods in natural language processing  pp          sydney  australia  association for computational linguistics 
daconta  m   obrst  l     smith  k          the semantic web  a guide to the future of
xml  web services  and knowledge management  john wiley   sons 
dale  r   moisl  h     somers  h          handbook of natural language processing  marcel
dekker inc 
daude  j   padro  l     rigau  g          mapping wordnets using structural information 
in   th anual meeting of the association for computational linguistics  acl      
hong kong 
edmonds  p     kilgarriff  a          natural language engineering  special issue on word
sense disambiguation systems  no         cambridge university press 
fellbaum  c          wordnet  an electronic lexical database  mit press 
fernandez amoros  d   gonzalo  j     verdejo  f          the uned systems at senseval   in proceedings of the senseval   workshop  in conjunction with acl  toulouse 
france 
fujii  a   inui  k   tokunaga  t     tanaka  h          selective sampling for example based
word sense disambiguation  in computational linguistics  no          pp         
humphreys  l   lindberg  d   schoolman  h     barnett  g          the unified medical
language system  an informatics research collaboration  journal of the american
medical informatics association        
ide  n     veronis  j          introduction to the special issue on word sense disambiguation 
the state of the art  computational linguistics              
jurafsky  d     martin  j          an introduction to natural language processing  computational linguistics  and speech recognition  prentice hall  upper saddle river 
nj       
kim  s  b   seo  h  c     rim  h  c          information retrieval using word senses  root
sense tagging approach  in sigir     proceedings of the   th annual international
acm sigir conference on research and development in information retrieval  pp 
        new york  ny  usa  acm 
kohomban  u     lee  w          learning semantic classes for word sense disambiguation  in proceedings of the   rd annual meeting of the association for computational
linguistics  acl    
leacock  c   chodorow  m     miller  g  a          using corpus statistics and wordnet
relations for sense identification  in computational linguistics  vol      pp         
lin  d          automatic retrieval and clustering of similar words  in proceedings of
coling acl  montreal  canada 
   

fion the use of automatically acquired examples for all nouns wsd

liu  s   liu  f   yu  c     meng  w          an effective approach to document retrieval
via utilizing wordnet and recognizing phrases  in sigir     proceedings of the
  th annual international acm sigir conference on research and development in
information retrieval  pp          new york  ny  usa  acm 
manning  c  d     schutze  h          foundations of statistical natural language processing  the mit press  cambridge  massachusetts 
mccarthy  d   koeling  r   weeds  j     carroll  j          finding predominant word senses
in untagged text  in proceedings of the   nd annual meeting of the association for
computational linguistics  acl   barcelona  spain 
mihalcea  r          bootstrapping large sense tagged corpora  in proceedings of the
 rd international conference on language resources and evaluation  lrec   las
palmas  spain 
mihalcea  r          co training and self training for word sense disambiguation  in proceedings of the conference on natural language learning  conll        boston 
usa 
mihalcea  r     chklovski  t          open mind word expert  creating large annotated
data collections with web users help  in proceedings of the eacl      workshop
on linguistically annotated corpora  linc        budapest  hungary 
mihalcea  r   chklovski  t     killgariff  a          the senseval   english lexical sample
task  in proceedings of the  rd acl workshop on the evaluation of systems for the
semantic analysis of text  senseval   barcelona  spain 
mihalcea  r     edmonds  p          senseval    third international workshop on the
evaluation of systems for the semantic analysis of text  the association for computational linguistics 
mihalcea  r     moldovan  d          an automatic method for generating sense tagged
corpora  in proceedings of aaai     orlando  fl 
miller  g  a   leacock  c   tengi  r     bunker  r          a semantic concordance 
in proceedings of the arpa human language technology workshop  pp         
princeton  nj  distributed as human language technology by san mateo  ca  morgan
kaufmann publishers 
ngai  g     florian  r          transformation based learning in the fast lane  in proceedings of the second conference of the north american chapter of the association
for computational linguistics  pp        pittsburgh  pa  usa 
patwardhan  s     pedersen  t          the cpan wordnet  similarity package 
http   search cpan org author sid wordnet similarity       

in

pedersen  t          a decision tree of bigrams is an accurate predictor of word sense  in
proceedings of the second meeting of the north american chapter of the association
for computational linguistics  naacl      pittsburgh  pa 
pham  t  p   ng  h  t     lee  w  s          word sense disambiguation with semisupervised learning  in proceedings of the   th national conference on artificial
intelligence  aaai        pp            pittsburgh  pennsylvania  usa 
   

fimartinez  lopez de lacalle   agirre

ravin  y     leacock  c          polysemy  theoretical and computational approaches 
oxford university press 
resnik  p          word sense disambiguation in natural language processing applications 
in agirre  e     edmonds  p   eds    word sense disambiguation  chap      pp     
     springer 
snyder  b     palmer  m          the english all words task  in proceedings of the  rd
acl workshop on the evaluation of systems for the semantic analysis of text  senseval   barcelona  spain 
stevenson  m          word sense disambiguation  the case for combining knowledge
sources  csli publications  stanford  ca 
stevenson  m     clough  p          eurowordnet as a resource for cross language information retrieval  in proceedings of the fourth international conference on language
resources and evaluation  lisbon  portugal 
strapparava  c   gliozzo  a     giuliano  c          pattern abstraction and term similarity
for word sense disambiguation  irst at senseval    in proceedings of the  rd acl
workshop on the evaluation of systems for the semantic analysis of text  senseval   barcelona  spain 
tugwell  d     kilgarriff  a          wasp bench  a lexicographic tool supporting word
sense disambiguation  in proceedings of the senseval   workshop  in conjunction
with acl      eacl       toulouse  france 
vickrey  d   biewald  l   teyssier  m     koller  d          word sense disambiguation for
machine translation  in proceedings of human language technology conference and
conference on empirical methods in natural language processing 
vilalta  r     drissi  y          a perspective view and survey of meta learning  in artificial
intelligence review  no          pp       
vossen  p   rigau  g   alegra  i   agirre  e   farwell  d     fuentes  m          meaningful
results for information retrieval in the meaning project  in proceedings of third
international wordnet conference  jeju island  korea 
wang  x     carroll  j          word sense disambiguation using sense examples automatically acquired from a second language  in proceedings of the joint human language
technologies and empirical methods in natural language processing conference  vancouver  canada 
wang  x     martinez  d          word sense disambiguation using automatically translated sense examples  in proceedings of eacl      workshop on cross language
knowledge induction  trento  italy 
weeber  m   mork  j     aronson  a          developing a test collection for biomedical
word sense disambiguation  in proceedings of amia symposium  pp         
yarowsky  d          decision lists for lexical ambiguity resolution  application to accent
restoration in spanish and french  in proceedings of the   nd annual meeting of the
association for computational linguistics  pp        las cruces  nm 
   

fion the use of automatically acquired examples for all nouns wsd

yarowsky  d          unsupervised word sense disambiguation rivaling supervised methods  in proceedings of the   rd annual meeting of the association for computational
linguistics  pp          cambridge  ma 
yarowsky  d     florian  r          evaluating sense disambiguation across diverse parameter spaces  natural language engineering                

   

fi