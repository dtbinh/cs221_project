journal artificial intelligence research                  

submitted        published      

learning partially observable deterministic action models
eyal   illinois   edu

eyal amir
computer science department
university illinois  urbana champaign
urbana  il        usa

allenc      yahoo   com

allen chang
     latham st   apartment   
mountainview  ca        usa

abstract
present exact algorithms identifying deterministic actions effects preconditions
dynamic partially observable domains  apply one know action model  the
way actions affect world  domain must learn partial observations time 
scenarios common real world applications  challenging ai tasks
traditional domain structures underly tractability  e g   conditional independence  fail
 e g   world features become correlated   work departs traditional assumptions
partial observations action models  particular  focuses problems actions
deterministic simple logical structure observation models features observed
frequency  yield tractable algorithms modified problem domains 
algorithms take sequences partial observations time input  output deterministic action models could lead observations  algorithms output one
models  depending choice   exact model misclassified given
observations  algorithms take polynomial time number time steps state features
traditional action classes examined ai planning literature  e g   strips actions 
contrast  traditional approaches hmms reinforcement learning inexact exponentially intractable domains  experiments verify theoretical tractability guarantees 
show identify action models exactly  several applications planning  autonomous
exploration  adventure game playing already use results  promising
probabilistic settings  partially observable reinforcement learning  diagnosis 

   introduction
partially observable domains common real world  involve situations one
cannot observe entire state world  many examples situations available
walks life  e g   physical worlds  we observe position items rooms  
internet  we observe web pages time   inter personal communications  we observe state mind partners  
autonomous agents actions involve special kind partial observability domains 
agents explore new domain  e g   one goes building meets new person  
limited knowledge action models  actions preconditions effects   action models change time  may depend state features  agents act
intelligently  learn actions affect world use knowledge respond
goals 
c
    
ai access foundation  rights reserved 

fia mir   c hang

learning action models important goals change  agent acted while 
use accumulated knowledge actions domain make better decisions  thus  learning
action models differs reinforcement learning  enables reasoning actions instead
expensive trials world 
learning actions effects preconditions difficult partially observable domains 
difficulty stems absence useful conditional independence structures domains 
fully observable domains include structures  e g   markov property  independence
state time     state time    given  observed  state time t  
fundamental tractable solutions learning decision making 
partially observable domains structures fail  e g   state world time    
depends state time   observe state time t   complex
approximate approaches feasible path  reasons  much work far
limited fully observable domains  e g   wang        pasula  zettlemoyer    kaelbling        
hill climbing  em  approaches unbounded error deterministic domains  e g   ghahramani        boyen  friedman    koller         approximate action models  dawsey  minsker 
  amir        hill  minsker    amir        kuffner    lavalle        thrun        
paper examines application old new structure learning partially observable
domains  namely  determinism logical formulation  focuses deterministic domains tractable learning feasible  shows traditional assumption form
determinism  the strips assumption  generalized adl  pednault        leads tractable
learning state estimation  learning domains immediate applications  e g   exploration planning  shahaf  chang    amir        chang   amir        serve
basis learning stochastic domains  thus  fundamental advance application
structure important opening field new approaches broader applicability 
following details technical aspects advance 
main contribution paper approach called slaf  simultaneous learning
filtering  exact learning actions models partially observable deterministic domains 
approach determines set possible transition relations  given execution sequence actions
partial observations  example  input could come watching another agent act
watching results actions execution  approach online  updates
propositional logical formula called transition belief formula  formula represents possible
transition relations world states every time step  way  similar spirit bayesian
learning hmms  e g   ghahramani        logical filtering  amir   russell        
algorithms present differ range applicability computational
complexity  first  present deduction based algorithm applicable nondeterministic
learning problem  takes time worst case exponential number domain fluents 
then  present algorithms update logical encoding consistent transition relations
polynomial time per step  limited applicability special classes deterministic
actions 
one set polynomial time algorithms present applies action learning scenarios
actions adl  pednault         with conditional effects  one following
holds   a  action model already preconditions known  observe action failures  e g  
perform actions domain    b  actions execution always succeeds  e g  
expert tutor performs actions  
   

fil earning partially bservable eterministic action odels

algorithms output transition belief formula represents possible transition relations
states partial observations state actions  updating component
formula separately linear time  thus  updating transition belief formula every
action execution observation takes linear time size input formula 
processing sequence action executions observations takes time o t   n  case
 b   main reason linear growth representation size transition belief
formula  time t  iterative process updates formula would process formula
size linear t 
case  a  processing sequence length takes polynomial time o t n k    
observe every feature domain every k steps expectation  fixed k  reason
transition belief formula kept k cnf  k conjunctive normal
v form  
w thus
size o nk     recall propositional formula k cnf  form im jk li j  
every li j propositional variable negation   case  b  takes time o t n 
assumption 
another set polynomial time algorithms present takes linear time representation
size  case actions known injective  i e   map states      there  bound
computation time steps o t nk    approximate transition belief formula
representation k cnf formula 
contrast  work learning dynamic bayesian networks  e g   boyen et al          reinforcement learning pomdps  e g   littman         inductive logic programming  ilp 
 e g   wang        either approximate solution unbounded error deterministic domains 
n
take time        inapplicable domains larger    features  algorithms
better respect  scale polynomially practically domains    s features
more  section   provides comparison works 
conduct set experiments verify theoretical results  experiments show
algorithms faster better qualitatively related approaches  example 
learn adl actions effects domains       features exactly efficiently 
important distinction must made learning action models traditional creation
ai planning operators  perspective ai planning  action models result
explicit modeling  taking account modeling decisions  contrast  learning action models
deducing possible transition relations compatible set partially observed
execution trajectories 
particular  action preconditions typically used knowledge engineer control
granularity action model leave aside specification unwanted cases  example 
driving truck insufficient fuel one site another might generate unexpected situations
modeller want consider  simple precondition used avoid considering case  intention paper mimic modeling perspective  instead
find action models generate sound states starting sound state  sound state
state system practice  namely  ones observations real executions
reflect 
technical advance deterministic domains important many applications
automatic software interfaces  internet agents  virtual worlds  games  applications 
robotics  human computer interfaces  program machine diagnosis use deterministic
action models approximations  finally  understanding deterministic case better help us
   

fia mir   c hang

develop better results stochastic domains  e g   using approaches boutilier 
reiter  price         hajishirzi amir        
following  section   defines slaf precisely  section   provides deduction based exact
slaf algorithm  section   presents tractable action model update algorithms  section   gives sufficient conditions algorithms keeping action model representation compact  thus  overall
polynomial time   section   presents experimental results 

   simultaneous learning filtering  slaf 
simultaneous learning filtering  slaf  problem tracking dynamic system
sequence time steps partial observations  systems complete
dynamics initially  solution slaf representation combinations action models
could possibly given rise observations input  representation
corresponding states system may  after sequence time steps
given input occurs  
computing  the solution for  slaf done recursive fashion dynamic programming
determine slaf time step t   solution slaf time t  section
define slaf formally recursive fashion 
ignoring stochastic information assumptions  slaf involves determining set possible
ways actions change world  the possible transition models  defined formally below 
set states system might in  transition model determines set possible states 
solution slaf transition model associated possible states 
define slaf following formal tools  borrowing intuitions work bayesian
learning hidden markov models  hmms   ghahramani        logical filtering  amir  
russell        
definition     transition system tuple hp  s  a  ri 
p finite set propositional fluents 
p ow p  set world states 
finite set actions 
r transition relation  transition model  
thus  world state  s  subset p contains propositions true state  omitted
propositions false state   r s  a  s    means state s  possible result action
state s  goal paper find r  given known p  s  a  sequence actions
partial observations  logical sentences subset p  
another  equivalent  representation use paper following 
literal proposition  p p  negation  p  complete term p conjunction
literals p every fluent appears exactly once  every state corresponds complete
term p vice versa  reason  sometime identify state term  e g  
states s    s    s  s  disjunction complete terms corresponding     s    respectively 
transition belief state set tuples hs  ri state r transition relation 
let r   p ow s s  set possible transition relations s  a  let   r 
hold transition belief state consider every tuple hs  ri possible 

   

fil earning partially bservable eterministic action odels

figure    locked door unknown key domain 
example     consider domain agent room locked door  see figure    
possession three different keys  suppose agent cannot tell observation
key opens door  goal agent unlock door 
domain represented follows  let set variables defining state space
p    locked  locked true door locked  let set states
   s    s    s     locked   the state door locked  s        here
door unlocked   let    unlock    unlock    unlock    three actions wherein agent
tries unlocking door using three keys 
let r     hs    unlock    s  i  hs    unlock    s  i  hs    unlock    s  i  represent transition relation key   unlocks door keys not  define r   r  similar
fashion  e g   r  key   unlocks door keys     not   transition belief state
represents set possibilities consider consistent observations far  consider
transition belief state given    hs    r  i  hs    r  i  hs    r  i   i e   state world
fully known action model partially known 
would agent able open door despite knowing key opens it 
this  agent learn actual action model  i e   key opens door   general 
learning action model useful achieving immediate goal  knowledge
useful agent attempts perform tasks domain  
definition      slaf semantics  let transition belief state  slaf
actions observations haj   oj i jt defined
   slaf  a     
 hs    ri   hs  a  s  r  hs  ri   
   slaf  o       hs  ri   true s  
   slaf  haj   oj iijt      
slaf  haj   oj ii  jt   slaf  oi   slaf  ai       
step   progression a  step   filtering o 
example     consider domain example      progression action unlock  
given slaf  unlock         hs    r  i  hs    r  i  hs    r  i   likewise  filtering
observation locked  the door became unlocked  given slaf  locked       hs     r  i   
   

fia mir   c hang

example     slightly involved example following situation presented figure   
there  two rooms  light bulb  switch  action flipping switch  observation  e  we east room   real states world action  s   s     
respectively  shown top part   known us 
west

east


psfrag replacements

west


s    sw lit e



 
sw on

 s  r  

 

east

s     sw lit e
 s  r  

 s  r  

 s  r  
 s  r  

 s  r  



 s  r  

 

figure    top  two rooms flipping light switch  bottom  slaf semantics  progressing
action  the arrows map state transition pairs  filtering observation
 crossing pairs  
bottom figure   demonstrates knowledge evolves performing action sw on 
there       hs    r  i  hs    r  i  hs    r  i  s    r    s    r    s     e   r  includes hs    sw on  s    the identity full details r    r    r  irrelevant here  omit
them     resulting transition belief state action sw on observation e     
slaf  sw on  e        
assume observations  and observation model relating observations state fluents 
given us logical sentences fluents performing action  denoted
o 
approach transition belief states generalizes version spaces action models  e g  
wang        follows  current state  s  known  version spaces lattice contains
set transition relations    r   hs  ri    thus  perspective version spaces 
slaf semantics equivalent set version spaces  one state might be 
semantics generalizes belief states  transition relation  r  known 
belief state  set possible states  r    s   hs  ri    read restricted r   logical
filtering  amir   russell        belief state action equal  thus  define as 
f ilter a       slaf  a   hs  ri      r  
thus  slaf semantics equivalent holding set belief states  conditioned transition
relation  similar saying transition relation r  belief state  set states  r  

   learning logical inference
learning transition models using definition     directly intractable requires space       
many cases  reason explicit representation large set possible
transition state pairs  instead  section rest paper represent transition belief states compactly using propositional logic  many scenarios amount
structure exploited make propositional representation compact 
 p 

   

fil earning partially bservable eterministic action odels

combinatorial argument implies encoding compact sets  nonetheless 
motivated success propositional  logical  approaches logical filtering  amir   russell 
      shahaf   amir        logical database regression  reiter               observe
propositional logic represents compactly natural sets exponential size 
section re define slaf operation propositional logical formulas
propositional formula output  slafs input propositional formula represents transition
belief state  slaf computes new transition belief formula input sequence
actions observations 
want find algorithms slaf manipulate input formula produce correct
output  use general purpose logical inference task section  later sections
sidestep expensive general purpose inference  make assumptions lead tractable algorithms  rest paper focus deterministic transition relations  namely  transition
relations partial functions  every action one outcome state every state  
    representing transition relations logic
initial algorithm solving slaf  to presented momentarily  compact
representation transition belief states  present logical encoding transition belief states
first  define deduction based algorithm next section 
use following general terminology propositional logical languages  all terminological conventions apply without subscripts superscripts   l denotes vocabulary  i e  
set propositional variables use present context  l denotes language  i e   set
propositional sentences      script greek letters stand propositional formulas
language present context  f  g stand formulas  restricted context
 see below   l   denotes vocabulary   l l  denotes language built propositions
l using standard propositional connectives             l   shorthand l l    
represent deterministic transition relations propositional vocabulary  l   whose
propositions form afg   a  f literal p  g logical formula  f
effect afg   g precondition afg   proposition afg takes truth value true 
intended meaning g holds present state  f holds state
results executing a 
let f p  p   p p  set effects  f   consider  let g
set preconditions  g  consider  rest section section   assume
g represents single state s  recall identify state complete term
conjunction literals hold state  use representation states write fs
instead afg   later build definition consider gs general formulas 
assumption  g now  stated above  conclude l o   p    p 
 a   propositional variables  prove fundamental results language set axioms 
disregarding size language moment  section   focuses decreasing language
size computational efficiency 
semantics vocabulary la lets every interpretation  truth assignment     la correspond transition relation  rm   every transition relation least one  possibly more 
interpretation corresponds it  correspondence surjective  onto  injective
   to     every propositional sentence l la   specifies set transition models follows 
   

fia mir   c hang

set models   satisfying interpretations    i      m interpretation la        
specifies corresponding set transition relations   rm   i    
informally  assume propositions afs        afs k la take value true  
propositions precondition
v take value false  then  r  with action  a  takes
 
state state satisfies ik   identical otherwise  exists  e g  
  fj   i  j k   rm takes s   thus  executable according
rm   
following paragraphs show interpretations l correspond transition relations 
culminate precise definition correspondence formulas l l p 
transition belief states s 
e nterpretation la c orresponds u nique ransition r elation
every interpretations la defines unique transition relation rm follows  let interpretation la   every state action either define unique state  
hs  a  s  rm decide s  hs  a  s  rm  
gives interpretation every proposition afs   f fluent negation 
fluent p p   aps      ap
    true  m    truth value according interpretation
   decide s  hs  a  s  rm   otherwise  define
s     p p      aps    p      ap
 
left hand side consider cases p p  a ps       ap
  
right hand side treat cases p p  aps      ap
    f alse  this
called inertia p keeps previous value lack specifications   put another way 
 
s   p     aps    s p   ap
    view interpretation p  rm well defined  i e  
one rm every  
e ransition r elation
la



l east ne c orresponding nterpretation



possible rm   rm          occurs two circumstances   a  cases
hs  a  s  rm s   b   aps      ap
    f alse  inertia 
p
p
 
 
 as     s p    as     s p   not inertia  
example first circumstance  let p fluent  let interpretation
 
 aps      ap
  g  define interpretation identical propositions
p p
p
 
besides   follows  define  as   opposite truth assignment  aps    false
p
instead true  true instead false   define    ap
     as   
then  rm   rm   map pairs s  way  particular  state
corresponds g  hs  a  s  rm similarly hs  a  s  rm    
finally  every transition relation r least one interpretation r   r   see
this  define mr every hs  a  s  r interpretation aps  p fluent  mr  aps     ru e iff
  s    finally  s 
p s    also  hs  a  s  define mr  ap
    f alse iff p
p
p
s    define mr  as     mr  as     ru e  then  r   rmr  
   overload word model multiple related meanings  model refers satisfying interpretation logical
formula  transition model defined definition     transition relation transition system  action model
define introduction section well defined specification actions preconditions effects 

   

fil earning partially bservable eterministic action odels

e ransition r elation efines f ormula la
every deterministic transition relation r defines logical formula whose set models map
r  many possible formulas  define general one  up logical
equivalence  make use inertia 
define h r  follows 
f
 
 
h   r     afs   af
  la   hs  a  r     f  
p
p
h   r     as   p p  s 

w
 
 
h   r      pp  aps ap
      hs  a  r 
h r    h   r  h   r  h 

h  addresses fluent changes  h  addresses fluent innertia  effectively disallowing innertia
definition   h  addresses conditions actions executable  thus  h r 
includes model every interpretation satisfies rm   r requires inertia
definition rm   represents r models satisfies rm   r 
illuminating see modeling decisions  above throughout section  lead
last definition  one hand  choose every interpretation l correspond
transition relation  we simplify later arguments logical entailment   consequently  associate interpretations  afs      af
    f alse transition relations r s  a  s    keep value f fixed s  s   this inertia f a  s  
hand  define h r  above  choose axioms exclude models  thus 
avoid models include inertia  simplifies later discussion learning algorithms 
summary  consider every interpretation la representing exactly one transition relation  consider set axioms defining r define directly  i e   without inertia
 without  afs      af
    f alse  
ransition b elief tates c orrespond f ormulas la p
thus  every
w transition belief state define formula l l p  corresponds
it  h     hs ri  s h r    formulas exist would characterize similar way 
equivalent  stronger formulas l l  
   h r  h r      every model    satisfies rm   r 
similarly  every formula l la p  define transition belief state       hm p
  rm           i e   state transition pairs satisfy  m p restricted
p  viewed complete term p   say formula transition belief formula 
h      note   t h      always holds  
    transition formula filtering
section  show computing transition belief formula slaf  a    successful
action transition belief formula equivalent logical consequence finding operation 
characterization slaf consequence finding permits using consequence finding
algorithm slaf  important later paper proving correctness
tractable  specialized algorithms 
let cnl    denote set logical consequences restricted vocabulary l  is 
l
cn    contains set prime implicates contain propositions set l 
   

fia mir   c hang

recall implicate formula clause entailed         recall prime implicate formula implicate subsumed  entailed  implicates
 
consequence finding process computes cnl    input    example  propositional resolution  davis   putnam        chang   lee        efficient consequence finder
used properly  lee        del val         marquis        surveys results prime implicates consequence finding algorithms   thus  cn l      l l        
set propositions p  let p   represent set propositions every proposition primed  i e   proposition f annotated become f      typically  use primed
fluent denote value unprimed fluent one step future taking action  let
 p    p  denote formula   primed fluents replaced unprimed counterparts  example  formula  a b    p    p  equal b b p   see section  
discussion comparison relevant formal verification techniques  
following lemma shows logical equivalence existential quantification quantified
boolean formulas consequence finding restricted vocabulary  recall quantified boolean
formulas  qbf  propositional formulas addition existential universal quantifiers
propositions  informally  qbf x  true given interpretation
exists true false valuation x makes true assignment  lemma prove
useful showing equivalence slaf consequence finding 
lemma     x  cnl    x      propositional logic formula propositional variable x 
p roof
see section b     
lemma extends easily case multiple variables 
corollary     formula set propositional variables x  x  cn l   x    
present algorithm updating transition belief formulas whose output equivalent
slaf  when slaf applied equivalent transition belief state   algorithm applies
consequence finding input transition belief formula together set axioms define
transitions time steps  present set axioms first 
deterministic  possibly conditional  action  a  action model  for time t  axiomatized
v
teff  a    lf  gg   alg g  l   
w
v
   
l
 
lf  l   gg  ag g   

first part     says assuming executes time t  causes l g holds  g
holds time t  l holds time      second part says l holds execution 
must alg holds g holds current state  two parts similar
 in fact  somewhat generalize  effect axioms explanation closure axioms used situation
calculus  see mccarthy   hayes        reiter        
now  ready describe zeroth level algorithm  slaf     slaf transition
belief formula  let l    p   la vocabulary includes fluents time t   effect
propositions la   recall  definition      slaf two operations  progression  with
action  filtering  with observation   time apply progression given action
current transition belief formula    apply filtering current observations 
   

fil earning partially bservable eterministic action odels

 

t     slaf   at   ot   t      cnl  t teff  at     p    p  ot

   

identical definition      slaf semantics   replacing     
 
stated above  slaf  implement cnl    using consequence finding algorithms
resolution variants  e g   simon   del val        mcilraith   amir       
lee        iwanuma   inoue         following theorem shows formula slaf algorithm correct exact 
theorem      representation  transition belief formula  action 
slaf  a   hs  ri   hs  ri satisfies     
 hs  ri   hs  ri satisfies slaf   a    
p roof
see section b     
theorem allows us identify slaf  slaf   throughout rest
paper  particular  show polynomial time algorithms slaf special cases correct
showing output logically equivalent slaf    
u sing



utput



slaf 

output algorithm slaf transition belief formula logical formula  way
use formula answering questions slaf depends query form
output formula  wish find transition model state possible  wish see
     interpretation l   p la output slaf   
answer found simple model checking algorithm     example  check
interpretation satisfies logical formula assign truth values variables interpretation formula  computing truth value formula done linear time 
thus  type query slaf takes linear time size output formula
slaf final query propositional interpretation propositional formula 
wish find transition model possible state possible 
propositional satisfiability  sat  solver algorithms  e g   moskewicz  madigan  zhao  zhang   
malik         similarly  wish answer whether possible models satisfy property
use sat solver 
example     recall example     discuss locked door three combinations  let
    locked  let     slaf   unlock    locked       wish find   implies trying
unlock door key   fails open it  equivalent asking models consistent
  give value true unlock locked
locked  
answer query taking slaf  output formula      checking  
unlock locked
locked sat  has model    follows deduction theorem propositional logic 
   iff sat  
one example application approach goal achievement algorithm chang amir
        relies sat algorithms find potential plans given partial knowledge encoded
transition belief formula 
   model checking sense used formal verification literature  there  model transition
model  checking done updating formula obdd transformations

   

fia mir   c hang

zeroth level algorithm may enable compact representation  guarantee
it  guarantee tractable computation  fact  algorithm maintain compact representation tractable computation general  deciding clause true result slaf
conp hard similar decision problem logical filtering conp hard  eiter   gottlob        amir   russell        even deterministic actions   the input representation
problems includes initial belief state formula cnf  input representation filtering
includes propositional encoding cnf  known  transition relation  
also  representation transition belief states uses poly  p   propositions grows exponentially  in number time steps  p   starting transition belief states action
sequences  actions allowed nondeterministic     question whether exponential growth must happen deterministic actions flat formula representations  e g   cnf 
dnf  etc   see darwiche   marquis        open  logical circuits known give solution
deterministic actions  representation given terms fluents time    shahaf et al  
      

   factored formula update
update representation hard must consider set interactions parts
representation  operations used slaf   consider interactions  manipulate
them  add many interactions result  processing broken independent
pieces  computation scales linearly number pieces  i e   computation time
total times takes piece separately   so  important find decompositions
enable independent pieces computation  hereforth examine one type decomposition 
namely  one follows logical connectives 
learning world models easier slaf distributes logical connectives  function 
f   distributes logical connective             f     f    f     computation
slaf becomes tractable  distributes     bottleneck computation case
becomes computing slaf part separately 
section examine conditions guarantee distribution  present linear time
algorithm gives exact solution cases  show algorithm
gives weaker transition belief formula distribution possible 
distribution properties always hold slaf follow set theoretical considerations
theorem     
theorem       transition belief formulas  action 
slaf  a     slaf  a    slaf  a   
   slaf  a     slaf  a    slaf  a   
p roof
see appendix b     
stronger distribution properties hold slaf whenever hold logical filtering 
theorem     let       transition belief states 
slaf  a          slaf  a      slaf  a     
   follows theorem filtering amir russell         even provide proper axiomatization
 note axiomatization deterministic actions only  

   

fil earning partially bservable eterministic action odels

iff every r
r
r
r
f ilter a  r
        f ilter a      f ilter a      

conclude following corollary theorems          theorems amir russell
       
corollary       transition belief formulas  action  slaf  a     slaf  a   
slaf  a    every relation r   one following holds 
   r maps states    
   r conditional effects  includes prime implicates  observe
fails
   state known r  one s  hs  ri  
condition   combines semantics syntax  particularly useful correct computation
slaf later sections  states particular syntactic form  namely  together
include joint prime implicates   simple enough  but necessarily      
computation slaf broken separate slaf  
figure   presents procedure factored slaf  computes slaf exactly conditions corollary     hold  consequently  factored slaf returns exact solution whenever
actions known      actions conditional effects success failure
observed  modified factored slaf solve problem exactly  see section    
procedure factored slaf hai   oi i  it   
i  ai action  oi observation  transition belief formula 
     do 
 a  set step slaf oi  ai    
 b  eliminate subsumed clauses  
   return  
procedure step slaf o a  
observation formula l p   action  transition belief formula 
   literal  return oliteral slaf a   
           return step slaf o a    step slaf o a     
           return step slaf o a    step slaf o a     
procedure literal slaf a  
action  proposition lt negation 
 
   return cnl   teff  a   p    p    

figure    slaf using distribution  
pre compute  and cache   n possible responses literal slaf  every time step
procedure requires linear time representation size   transition belief formula
time step  significant improvement  super exponential  time taken
straightforward algorithm   potentially exponential  time taken general purpose
consequence finding used zeroth level slaf procedure above 
theorem     step slaf a  o    returns formula   slaf  a  o           every run
literal slaf takes time c  step slaf takes time o   c    recall    syntactic 
representation size    finally  assume one assumptions corollary     
  slaf  a  o    
   

fia mir   c hang

belief state formula transition belief formula effect propositions  i e   includes fluent variables propositions form fg   identical traditional
use term belief state formula  e g    amir   russell         give closed form solution slaf belief state formula  procedure literal slaf figure     makes
procedure literal slaf tractable  avoiding general purpose inference filtering single literal 
allows us examine structure belief state formulas detail 
v
theorem     belief state formula l p   action a  ca   gg lf  alg al
g   
g         gm g terms g gi     
slaf  a   

 


 

li
 li ag
  ca


l       lm f i  

v

here  l       lm f means conjunction possible  combinations of  selections literals
f 
p roof
see appendix b     
theorem significant says write result slaf
prescribed form  form still potentially exponential size  boils simple
computations  proof follows straightforward  though little long  derivation possible
prime implicates slaf  a  t   
consequence theorem     implement procedure literal slaf using
equivalence


theorem    
l l  p
slaf  a  l 
l slaf  a  true  otherwise

notice computation theorem       l literal simple g          gm
complete terms l p  include l  computation require general purpose
consequence finder  instead need answer  n   queries initialization phase  namely 
storing table values slaf  a  l  l   p l   p p p
l   true 
general  could high   p    number complete terms g  finding g         gm
may take time exponential  p   still  simplicity computation formula provide
basic ingredients needed efficient computations following sections restricted cases 
give guidelines future developments slaf algorithms 

   compact model representation
previous sections presented algorithms potentially intractable long sequences actions
observations  example  theorem      could high    p    number complete
terms g  consequently  clauses may exponential length  in n    p   may
super exponential number clauses result 
section focus learning action models efficiently presence action preconditions failures  important agents partial domain knowledge
therefore likely attempt inexecutable actions 
restrict attention deterministic actions conditional effects  provide
overall polynomial bound growth representation  size many steps 
   

fil earning partially bservable eterministic action odels

time taken compute resulting model  class actions generalizes strips  fikes  hart 
  nilsson         results apply large part ai planning literature 
give efficient algorithm learning non conditional deterministic action effects
preconditions  well efficient algorithm learning actions effects presence
action failures 
    actions limited effect
many domains assume every action affects k fluents  small k     
common assume actions strips  may fail without us knowing 
leaving world unchanged  assumptions together allow us progress slaf limited
 polynomial factor  growth formula size 
use language similar one section    uses action propositions
alg g
fluent term size k  instead fluent term size n g   semantically 
v
l
al     lk lk        ln all     ln  
theorem     let l p  belief state formula  strips action k fluents
affected precondition term  let g k set terms k fluents l p 
consistent   then 
slaf  a   

 

k
 

li
 li ag
  ca


i  
g         gk g k
g      gk   
l         lk f

v
here      refers conjunction possible  combinations of  selections literals
f g         gk g k g      gk     
p roof
see section b     
main practical difference theorem theorem     smaller number
terms need checked practical computation  limited language enables entails
limited number terms play here  specifically  k literals
preconditions  need check combinations k terms g          gk g k   computation
bounded o exp k   iterations 
proof uses two insights  first  one case change occurs  every
clause theorem     subsumed clause entailed slaf  a      one
algi per literal li  i e   li    lj    j  gi fluent term  has disjunctions   second  every
alg g term equivalent formula algi gi terms length k  affects k
fluents 
thus  encode clauses conjunction using subset  extended  action
effect propositions  alg   g term size k  o nk   terms  o nk    
propositions  every clause length  k  identity clause determined
 
first half  the set action effect propositions   consequently  slaf  a     takes o nk  k k    
 
space represent using o nk  k   clauses length  k 
   

fia mir   c hang

    actions conditional effects  revised language
thisssection reformulate representation presented section      let
l f   aa  af   af   af   a f     a f     every f p  let vocabulary formulas representing transition belief states defined l   p l f   intuition behind propositions
vocabulary follows 
v
al causes l literal l  formally  al ss als  
v
af keeps f   formally  af ss   s f   afs     s f   af
  
v
  
 thus  l
a l  causes false l  formally  a l  ss  s l   als al

precondition executing a  must hold executes  
model transition belief formula l  valuation fluents p defines
state  valuation propositions l f defines unconditional deterministic transition
relation follows  action proposition af  af   true action transition
relation causes f  f   hold executed  action proposition f true
action affect fluent f   action proposition a f    a f     true f  f  
precondition a  assume existence logical axioms disallow inconsistent
impossible models  axioms are 
   af af af
    af af    af af    af af  


   a f   a f  

possible f p  first two axioms state every action model  exactly one
af   af   af must hold  thus  causes f   negation  keeps f unchanged   last axiom
disallows interpretations a f   a f   hold  state axioms
need represent constraints explicitly transition belief formula itself 
use set theoretic propositional logic notations transition belief states interchangeably  note vocabulary defined sufficient describing unconditional
strips action model  deterministic action model general 
example     consider domain example      transition belief state represented transition belief formula 
locked
  unlock locked unlock locked unlock locked  
 unlock locked unlock locked unlock locked  
 unlock locked unlock locked unlock locked    
 
provide axiomatization equivalent slaf special case eff    
notation above  p p     recall intend primed fluents represent
value fluent immediately action taken 
   

fil earning partially bservable eterministic action odels

eff  a 

 

prea f effa f

f p

prea f



 

 a l  l 

l f f  

effa f



 

  al  af l   l     l   al  af l    

l f f  

prea f describes precondition action a  states literal l occurs precondition
literal l must held state taking a  formula eff a f describes effects
action a  states fluents taking action must consistent according
action model defined propositions af   af   af  
show revised axiomatization action models  eff   leads equivalent
definition slaf within restricted action models 
 

theorem     successful action a  slaf  a    cn lp   eff  a   p    p   
p roof

see appendix b     

    always successful non conditional actions
ready present algorithm learns effects actions conditional
effects  algorithm allows actions preconditions fully known  still 
assumes filtered actions executed successfully  without failures   cannot effectively
learn preconditions  e g   would know knew originally
preconditions seeing sequence events   sequence actions might  example 
generated expert agent whose execution traces observed 
algorithm maintains transition belief formulas special fluent factored form  defined below  maintaining formulas special form  show certain logical consequence
finding operations performed efficiently  formula fluent factored  conjunction formulas f f concerns one fluent  f   action propositions 
also  every fluent  f   f conjunction positive element  negative element 
neutral one f  f explf    f explf   af   explf   explf   af formulae action
propositions af   af   a f     a f     af  possibly multiple different actions   intuition
explf explf possible explanations f true false  respectively 
also  af holds knowledge actions effects preconditions f   knowledge
depend f current value  note formula l l f   represented fluentfactored formula  nonetheless  translation sometimes leads space blowup  maintain
representation form construction 
new learning algorithm  as strips slaf    shown figure    simplify exposition 
described case single action observation pair  though obvious
apply algorithm sequences actions observations  whenever action taken  first
subformulas af   explf   explf f updated according steps    a   c   then 
   as strips slaf extends ae strips slaf  amir        allowing preconditions actions

   

fia mir   c hang

algorithm as strips slaf ha  oi   
inputs 
v successful action a  observation term o  fluent factored transition belief formula  
f p f  

returns  fluent factored transition belief formula slaf  ha  oi   
   every f p
 a  set af  a f   explf    a f   explf   af
 b  set explf  af  af a f   explf   
 c  set explf  af  af a f   explf   

 d     f  f observed  seta   f  f     f   af explf
 e     f set f  f    f    af explf  note      f
    f   nothing beyond earlier steps  
   simplify  e g   eliminate subsumed clauses   
   return
a  term  f    new explf    f   new explf   appear without simplification
conform step  a algorithm  emphasizes syntactic nature procedure 
implicit logical simplification assumed 

figure    slaf algorithm always successful strips actions 
observation received  f updated according observation according steps
   d   e   step   merely indicates implementations  likely simplification
procedure used formula subsumption elimination  however  use
simplification procedure strictly necessary order theoretical guarantees
algorithm hold 
example  know nothing actions affect f  e g   start exploration  
f    f ru e   f ru e  ru e  representation  slaf  a  f  
conjunction  f explf   f explf  af computed step   procedure as strips slaf 
similar formula holds observations 
following theorem shows correctness algorithm  shows steps taken
algorithm produce result equivalent logical consequence finding characterization
slaf theorem     
theorem     slaf ha  oi    as strips slaf ha  oi    fluent factored formula  
successfully executed action a  observation term o 
p roof
see appendix b    
time space complexity procedure as strips slaf given following
theorem  time guarantee  shown procedure takes linear time size input
formula  condition algorithm receives observations often enoughspecifically
   

fil earning partially bservable eterministic action odels

every fluent observed least every k calls procedureit possible show
transition belief formula remains k cnf indefinitely  recall k cnf
fixed k  conjunction clauses size k   thus  regardless length actionobservation input sequence  output as strips slaf value throughout
computation k cnf  amounts space guarantee size formula 
theorem     following true as strips slaf 
   procedure takes linear time size input formula single action  observation
pair input 
   every fluent every k steps observation fluent one steps 
input formula k cnf  resulting formula  after arbitrary number
steps  k cnf 
   input as strips slaf fluent factored  output 
p roof
see appendix b    
following corollary follows immediately above 
corollary     order process steps actions observations  as strips slaf requires
 t  p   time  additionally 
every fluentis observed every k steps  resulting
formula always size  p   a k  
corollary holds theorem        guarantees bound size belief state
formula point algorithm 

    learning actions may fail
many partially observable domains  decision making agent cannot know beforehand whether
action decides take fail succeed  section consider possible action failure 
assume agent knows whether action attempts fails succeeds trying
action 
precisely  assume additional fluent ok observed agent
ok true action succeeded  failed action  case  may viewed
extra observation agent preconditions action met  is 
action failure equivalent observation
 

 a f   f    a f   f   
   
f p

action failures make performing slaf operation considerably difficult  particular 
observations form     cause interactions fluents value particular fluent
might longer depend action propositions fluent  action propositions
fluents well  transition belief states longer represented convenient fluentfactored formulas cases  becomes difficult devise algorithms give
useful time space performance guarantees 
   

fia mir   c hang

algorithm pre strips slaf a  o   
inputs  action observation
term o  transition belief formula following facv w
tored form    j i j   i j fluent factored formula 
returns  filtered transition belief formula
      ok 
w
 a  set f  li   li literals appearing precondition 
f  l  v
fluent factored formula equivalent l  i e   f  l      l     l
     f p   f     f       

 b  set i j as strips slaf o  i j   i j
   else  o    ok  
 a  i j

i  set i j as strips slaf p   i j    p precondition
ii  set i j as strips slaf ha  oi  i j  
   i j factored ai j bi j bi j contains  and only  clauses containing
fluent p 
w exists b j  b i j b  replace
w


b

j ai j
j i j
   simplify i j  e g  remove subsumed clauses 
   return
figure    algorithm handling action failures preconditions known 
shall demonstrate  action failures dealt tractably assume action
preconditions known agent  is  agent must learn effects actions
take  need learn preconditions actions  particular  means
action a  algorithm given access formula  more precisely  logical term  p describing
precondition action a  clearly  algorithm need learn preconditions
actions  restrict action proposition vocabulary used describe belief states
ones forms af   af   af   longer need action propositions forms a f  
a f    
present procedure pre strips slaf   figure    performs slaf transition belief
formulas presence action failures actions non conditional effects  maintains transition belief
conjunctions disjunctions fluent factored formulas  formulas
v formulas
w
form   j i j i j fluent factored   naturally  formulas superset
fluent factored formulas 
   pre strips slaf essentially identical cnf slaf  shahaf et al        

   

fil earning partially bservable eterministic action odels

algorithm operates follows  action executes successfully  and ensuing observation received   component fluent factored formulas i j filtered separately
according as strips slaf procedure action observation pair  step    
hand  action fails  disjunction fluent factored formulas appended transition
belief formula  step     component disjunction corresponds one possible reasons action failed  i e   one literals occurring actions precondition   finally 
observations accumulated learning algorithm  collapses disjunctions fluent factored
formulas occurring belief formula together  step    simplifies generally  step    
decreasing total size formula  case as strips slaf  simplification
steps necessary order time space guarantees hold 
proof correctness algorithm pre strips slaf relies distribution results
section    theorem     corollary     
proceed show correctness pre strips slaf  following theorem shows
procedure always returns filtered transition belief formula logically weaker
exact result  always produces safe approximation  additionally  theorem shows
conditions corollary      filtered transition belief formula exact result 
theorem     following true 
   slaf a  o       pre strips slaf a  o   
   pre strips slaf a  o    slaf a  o    corollary     holds 
p roof
see appendix b     
consider time space complexity algorithm  following theorem shows
    procedure time efficient      given frequent enough observations  as theorem
      algorithm space efficient transition belief formula stays indefinitely compact 
theorem     following true pre strips slaf 
   procedure takes time linear size formula single action  observation pair
input 
   every fluent observed every k steps input formula k cnf 
filtered formula k cnf  maximum number literals action
precondition 
p roof
see appendix b     
therefore  get following corollary 
corollary     order process steps actions observations  pre strips slaf requires
 t  p   time  every fluent
observed least
frequently every k steps  resulting
mk
formula always size  p   a 
 

   building results
section describe briefly one might extend approach include elaborate
observation model  bias  parametrized actions 
   

fia mir   c hang

    expressive observation model
observation model use throughout paper simple  every state  fluent
observed value v  value current state  consider observation
model general 
observation model  o  set logical sentences relates propositions set obs
fluents p  obs includes propositions appear p  independent
previous following state  times        given fluents time t 
slaf result conjoining cnlt  oo   i e   finding prime implicates
conjoining   embed extension slaf algorithms above 
maintain structures algorithms use  k cnf every step
observe  at most    variable  finding prime implicates easy  embedding
transition belief formula done conjunction prime implicates formula 
removal subsumed clauses  resulting formula still fluent factored  input
fluent factored  then  algorithms remain applicable time complexity 
replacing ot prime implicates ot ot  
using model algorithms described provide exact solution slaf 
tuples hs  ri solution consistent observations  compute
solution slaf represented logical formula  use sat solver  e g   moskewicz
et al         answer queries formula  checking entails f   action
fluent f   would show consistent models action makes f value true 
number variables result formula always independent   linear  p 
algorithms  therefore  use current sat solvers treat domains     
features more 
preference probabilistic bias many times information leads us prefer
possible action models others  example  sometimes assume actions change
fluents  suspect action  e g   open door  affect features  e g  
position  normally  represent bias using preference model  e g   mccarthy       
ginsberg        probabilistic prior transition relations  e g   robert  celeux    diebolt 
      
add bias end slaf computation  get exact solution
compute effect bias together logical formula efficiently  preferential biases
studied fit easily result algorithms  e g   use implementations
doherty  lukaszewicz    szalas        inference bias  
also  algorithms inference probabilistic bias logical sentences emerging
used  hajishirzi   amir         there  challenge enumerate
tentative models explicitly  challenge overcome success work hajishirzi
amir        similar task filtering  use algorithms apply probabilistic
bias resulting logical formula 
example  given probabilistic graphical model  e g   bayesian networks  set propositional logical sentences  consider logical sentences observations  approach 


logical sentence gives rise characteristic function  
x    
x satisfies
  otherwise  conjunction clauses get set functions  one per clause   thus 
inference combined probabilistic logical system probabilistic inference  example 
   

fil earning partially bservable eterministic action odels

one consider variable elimination  e g   dechter        additional potential
functions 
parametrized actions many systems situations natural use parametrized actions 
action schemas whose effect depend parameters  definition applies
identically instantiations 
example  move b  x  y  action moves b position x position y 
b  x  parameters action  common planning systems  e g   strips 
pddl  situation calculus   complete treatment parameterized actions outside scope
paper  give guidelines generalization current approach actions 
consider domain set fluent predicates universe named objects  propositional fluents defined domain ground instantiations predicate fluents  slaf
work set propositional fluents instantiated actions manner


rest paper  action propositions a  x  lg instantiated every vector object names


x 




 lg  
different treatment comes additional axioms say
x 
 a 
x  lg a 
inference transition belief state axioms able join information collected
different instantiations actions  expect thorough treatment
able provide efficient algorithms whose time complexity depend number action
schemas instead number instantiated actions 
several approaches already start address problem  including work nance  vogel 
amir        filtering work shahaf amir        slaf 

   experimental evaluation
previous sections discussed problem settings consider algorithms solutions  showed modifying traditional settings learning dynamic partially observable
domains important  determinism alone lead tractability  additional assumptions simple  logical action structure bounded   frequency observations fluents
do  specifically  far showed time space computing slaf length t time
sequence n fluents polynomial n 
section considers practical considerations involved using slaf procedures 
particular  examines following questions 
much time space slaf computations take practice 
much time required extract model logical formula result
slaf procedures 
quality learned model  taking arbitrary consistent model   far
true  generating  model 
conditions algorithms correctness hold practice 
learned model used successful planning execution  learning
procedures fit planning execution 
implemented algorithms ran experiments as strips slaf following domains taken  rd international planning competition  ipc   drivelog  zenotravel 
blocksworld  depots  details domains learning results appear appendix c  
   

fia mir   c hang

experiment involves running chosen algorithm sequence randomly generated
action observation sequences      steps  information recorded every     steps 
random sequence generator receives correct description domain  specified
pddl  ghallab  howe  knoblock  mcdermott  ram  veloso  weld    wilkins        fox   long 
       a plannig domain description language   size domain  starting state   the
size domain number propositional fluents it  set specification
number objects domain number arity predicates domain   generates
valid sequence actions observations domain starting state  i e   sequence
consistent input pddl generator actions may fail  action failure
consistent pddl action attempted state canot execute  
experiments  chose observations follows  every time step select   
fluents uniformly random observe  applied additional restrictions  such making sure
fluent observed every fixed k steps  
slaf algorithm receives sequences actions observations  domain
information otherwise  e g   receive size domain  fluents  starting state 
pddl   starting knowledge algorithm empty knowledge  true 
domain ran algorithm different numbers propositional fluents        
fluents   collected time space taken slaf computation plotted
function input sequence length  dividing total computation time steps  
time space results shown figures             graphs broken different
domains compare time space taken different domain sizes  time slaf time
without cnf simplification  e g  remove subsumed clauses 
much time space slaf computations take practice  answer first
question now  observe figures time per step remains relatively constant
throughout execution  consequently  time taken perform slaf different domains grows
linearly number time steps  also  see time slaf grows domain
size  scales easily moderate domain sizes   ms per step slaf domains     fluents  
much time required extract model logical formula result
slaf procedures  slaf procedures return logical formula sequence actions
observations  need apply work extract candidate  consistent  model
formula  computation done sat solver cnf formulas 
quality learned model  taking arbitrary consistent model   far
true  generating  model  sometimes many possible models  little
bias must consider possible likely  decided introduce one
bias  namely  actions instances actions schemas  thus  actions assumed
effect parameters  or objects   given properties parameters  thus 
actions effects assumed independent identity parameter 
so  vanilla implementation  propositions look
  stack
  stack
  stack
  stack
etc 

e
e



g 
g 
b 
a 

causes
causes
causes
causes

 on
 on
 on
 on

e
g



g  
e  
b  
a  

   

fil earning partially bservable eterministic action odels

slaf time step  blocksworld domain
   

   

   

time  ms 

 

   fluents
   fluents
   fluents
    fluents
    fluents

   

   

   

   

 
   

    

    

    

    

    

    

input sequence length

slaf time step  depots domain
   

   

   

time  ms 

 

   fluents
   fluents
    fluents
    fluents
    fluents

   

   

   

   

 
   

    

    

    

    

    

    

input sequence length

figure    slaf time without cnf simplification domains blocksworld depots

instead  replace ground propositions schematized propositions 
  stack  x  y  causes  on  x  y  
  stack  x  y  causes  on  y  x  
  stack  x  y  causes  on  x  y  
etc 
thus  belief state formula looks something like 
   

fia mir   c hang

slaf time step  driverlog domain
   
   
   

time  ms 

   
   fluents
   fluents
    fluents
    fluents
    fluents

 
   
   
   
   
 
   

    

    

    

    

    

    

input sequence length

slaf time step  zeno travel domain
   

   

   

time  ms 

   
   fluents
   fluents
    fluents

   

   

   

   

 
   

    

    

    

    

    

    

input sequence length

figure    slaf time without cnf simplification domains driverlog zeno travel

 and
 and
 or  on e g 
 or   stack  x  y  causes  not  on  x  y   
 and   stack  x  y  keeps  on  x  y  
 not   stack  x  y  needs  on  x  y      
   
   

fil earning partially bservable eterministic action odels

slaf space  blocksworld domain
   k

space   lisp symbols 

   k

   k
   fluents
   fluents
   fluents
    fluents
    fluents

   k

   k

  k

k
   

    

    

    

    

    

    

input sequence length

slaf space  depots domain
   k

   k

space   lisp symbols 

   k

   k

   fluents
   fluents
    fluents
    fluents
    fluents

  k

  k

  k

  k

k
   

    

    

    

    

    

    

input sequence length

figure    slaf space domains blocksworld depots

example fragment model  the complete output given appendix c  consistent
training data
blocksworld domain 
      fluents
       randomly selected actions
     fluents observed per step
   schematized  learning
   

converting cnf
clause count        
variable count     
adding clauses
calling zchaff

fia mir   c hang

slaf space  driverlog domain
   k

space   lisp symbols 

   k

   k

   fluents
   fluents
    fluents
    fluents
    fluents

   k

  k

k
   

    

    

    

    

    

    

input sequence length

slaf space  zeno travel domain
  k

space   lisp symbols 

  k

  k
   fluents
   fluents
    fluents

  k

  k

  k

k
   

    

    

    

    

    

    

input sequence length

figure    slaf space domains driverlog zeno travel

      precondition heuristics

parsing result
slaf time       
inference time        
learned model 

 unstack needs  not  clear  underob   
 unstack needs  clear  ob  
 unstack needs  arm empty  
   

fil earning partially bservable eterministic action odels

 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
 unstack
   

needs  not  holding  ob   
needs  on  ob  underob  
causes  clear  underob  
causes  not  clear  ob   
causes  not  arm empty   
causes  holding  ob  
causes  not  on  ob  underob   
keeps  on table  underob  
keeps  on table  ob  
keeps  holding  underob  
keeps  on  underob  underob  
keeps  on  ob  ob  
keeps  on  underob  ob  

sometimes  multiple possible schematized propositions correspond ground
action proposition  case disjoin propositions together replacement
 i e   single ground propositional symbol gets replaced disjunction schema propositions  
replacement simple procedure  one effective deriving information fewer steps speeding model finding slaf formula  implemented
run slaf runs  one could sat solving portion algorithm 
equivalent result 
regarding latter  ran scaling issues sat solver  zchaff   moskewicz et al  
      tang  yinlei yu    malik        common lisp compiler large experiments  got
around issues applying replacement scheme above  thus reducing greatly number
variables sat solver handles 
another issue ran sat solver tended choose models blank preconditions  the sequences used experiments include action failure  preconditions never eliminated algorithm   add bias extracted action model 
added axioms following form 
 or  not   a causes  f     a needs  not  f   
 or  not   a causes  not  f      a needs  f  
axioms state action causes fluent f hold  requires f hold
precondition  similarly  analagous axiom f    intuitively  axioms cause
sat solver favor     action models  got idea heuristic work wu 
yang  jiang         uses somewhat similar set axioms bias results terms
learning preconditions  clearly  axioms dont always hold  results  one see
learned preconditions often inaccurate 
inaccuracies learned action models reasonable  example  fluent
never changes course action sequence  algorithm may infer arbitrary action
causes fluent hold 
conditions algorithms correctness hold practice  scenarios
report here  conditions guarantee correctness algorithms hold  experiments assumed main conditions algorithms hold  namely  actions
   

fia mir   c hang

deterministic preconditions  enforce observations every fluent
every  fixed  k steps  latter condition necessery correctness algorithm 
necessary guarantee polynomial time computation  experiments verify necessary practice  indeed case algorithms polynomial time guarantee
modified observation
earlier work hlubocky amir        included modified version as stripsslaf architecture tested suite adventure game like virtual environments
generated random  include arbitrary numbers places  objects various kinds 
configurations settings those  there  agents task exit house  starting
knowledge state space  available actions effects  characteristics objects 
experiments show agent learns effects actions efficiently  agent
makes decisions using learned knowledge  inference resulting representation fast
 a fraction second per sat problem domains including    object  modes 
locations  
learned model used successful planning execution  learning
procedures fit planning execution  learned model used planning
translating pddl  however  model always correct one domain 
plan may feasible may lead required goal  cases  interleave
planning  execution  learning  described work chang amir         there 
one finds short plan consistent action model  executes plan  collects observations 
applies slaf those  plan failure detected  e g   goal achieved  
results chang amir        guarantee joint planning execution learning procedure
would reach goal bounded amount time  bounded time fact linear length
longest plan needed reaching goal  exponential complexity action
model need learn 

   comparison related work
hmms  boyen   koller        boyen et al         murphy        ghahramani        used
estimate stochastic transition model observations  initially  expected compare
work hmm implementation murphy         uses em  a hill climbing approach  
unfortunately  hmms require explicit representation state space  smallest domain     features  requires transition matrix         entries  prevents initializing hmms
procedures current computer 
structure learning approaches dynamic bayes nets  dbns   e g   ghahramani   jordan 
      friedman  murphy    russell        boyen et al         use em additional approximations  e g   using factoring  variation  sampling   tractable  however  still
limited small domains  e g      features   ghahramani   jordan        boyen et al         
unbounded errors discrete deterministic domains  usable settings 
simple approach learning transition models devised work holmes
charles lee isbell        deterministic pomdps  there  transition observation models
deterministic  approach close represents hidden state possible models using finite structure  looping prediction suffix tree  structure seen
related representation grow models relate action histories possible
transition models  work interactions realized recursive structure
   

fil earning partially bservable eterministic action odels

transition belief formula built as strips slaf  e g  
 af  af a f   explf   
explf refers similar formula created previous time step 
main difference draw work holmes charles
lee isbell        latter refers states explicitly  whereas work refers features 
consequently  representation  provably  compact procedures scale larger
domains theoretically practice  furthermore  procedure provably maintains reference possible models data insufficient determine single model  whereas
work holmes charles lee isbell        focuses limit case enough information determining single consistent model  down side  procedure consider
stochasticity belief state  remains area development 
similar relationship holds work littman  sutton  singh        
work  model representation given size linear number states  model 
predictive state representation  psr   based action observation histories predicts behavior based histories  work prefers low dimensional vector basis instead featurebased representation states  one traditional hallmarks knowledge representation
approach   necessary correspondence basis vectors intuitive features real world necessarily  enables representation world closely
based behavior 
learning psrs  james   singh        nontrivial one needs find good lowdimensional vector basis  the stage called discovery tests   stage learning psrs requires
matrices size  n     states spaces size n 
work advances line work providing correct results time polylogarithmic number states  specifically  work learns  deterministic  transition models
polynomial time state features  thus taking time o poly log n   
reinforcement learning  rl  approaches  sutton   barto        bertsekas   tsitsiklis       
compute mapping world states preferred actions  highly intractable
partially observable domains  kaelbling  littman    cassandra         approximation  e g  
kearns  mansour    ng        meuleau  peshkin  kim    kaelbling        even dar  kakade   
mansour        mccallum        practical small domains  e g         features 
small horizon time  
contrast hmms  dbns  rl  algorithms exact tractable large domains   
    features   take advantages properties common discrete domains  determinism 
limited effects actions  observed failure 
previous work learning deterministic action models ai planning literature assumes
fully observable deterministic domains  learn parametrized strips actions using  e g   version spaces  gil        wang         general classifiers  oates   cohen         hill climbing
ilp  benson         recently  work pasula et al         gave algorithm learns stochastic actions conditional effects  work schmill  oates  cohen        approximates
partial observability assuming world fully observable  apply partially
observable learning problems  sometimes  using space belief states instead world states 
increases problem size exponentially  practical problem 
finally  recent research learning action models partially observable domains includes
works yang  wu  jiang        shahaf amir         works yang et al 
   

fia mir   c hang

        example plan traces encoded weighted maximum sat problem 
candidate strips action model extracted  general  may many possible action models
given set example traces  therefore approach nature approximate  in contrast
ours  always identifies exact set possible action models   work introduces
additional approximations form heuristic rules meant rule unlikely action models 
work shahaf amir        presents approach solving slaf using logicalcircuit encodings transition belief states  approach performs tractable slaf general deterministic models present section    requires sat solvers
logical circuits  sat solvers optimized nowadays comparison cnf sat
solvers  overall performance answering questions slaf lower ours 
importantly  representation given shahaf amir        grows  linearly  number
time steps  still hinder long sequences actions observations  comparison 
transition belief formula bounded size independent number time steps
track 
encoding language  la typical methods software hardware verification
testing  relevant books methods  e g   clarke  grumberg    peled        closely related
representation  results achieve applicable vice versa 
main distinction draw work done formal methods  e g   model
checking bounded model checking  able conclude size bounds logical formulas involved computation  obdds used success model checking 
cnf representations used success bounded model checking  little
bounds sizes formulas theory practice  conditions available ai applications
used current manuscript deliver bounds yield tractability scalability results
theoretical practical significance 
interestingly  methods use linear temporal logics  ltl  cannot distinguish
happen actually happens  calvanese  giacomo    vardi         thus  cannot
consider causes occurence  method similar consider alternate
futures state explicitly  however  use extended language  namely l   makes
alternatives explicit  allows us forego limitations ltl produce needed result 

   conclusions
presented framework learning effects preconditions deterministic actions
partially observable domains  approach differs earlier methods focuses determining exact set consistent action models  earlier methods not   showed several
common situations done exactly time polynomial  sometime linear  number time steps features  add bias compute exact solution large domains
 hundreds features   many cases  furthermore  show number action observation
traces must seen convergence polynomial number features domain 
positive results contrast difficulty encountered many approaches learning
dynamic models reinforcement learning partially observable domains 
results presented promising many applications  including reinforcement
learning  agents virtual domains  hmms  already  work applied autonomous
agents adventure games  exploration guided transition belief state compute
   

fil earning partially bservable eterministic action odels

information gain criteria  future plan extend results stochastic domains 
domains continuous features 

acknowledgments
wish thank megan nance providing code samples sequence generator 
wish thank dafna shahaf encouraging collaboration enhanced development understanding results  first author wishes acknowledge stimulating
discussion brian hlubocky related topics  wish acknowledge support daf
air force research laboratory award fa                darpa real program   second
author wishes acknowledge support university illinois urbana champaign  college
engineering fellowship  finally  first author acknowledges support joint fellowship
            center advanced studies beckman institute university
illinois urbana champaign 
earlier versions results manuscript appeared conference proceedings  amir 
      shahaf et al         

appendix a  representation domain descriptions
transition relation rm interpretation la defined section     way
similar interpretation domain descriptions  domain descriptions common method
specifying structured deterministic domains  fagin  ullman    vardi        lifschitz       
pednault        gelfond   lifschitz         methods equivalent contexts
include successor state axioms  reiter        fluent calculus  thielscher        
relevance influence work merit separate exposition relationship work 
domain description finite set effect rules form causes f g describe effects actions  f g state formulas  propositional combinations fluent
names   say f head effect g precondition rule  write
causes f   causes f true  denote ed  a  set effect rules action
a  effect rule e  let ge precondition fe effect  rule e active state s 
   ge  s taken interpretation p  
every domain description defines unique transition relation r  s  a  s    follows 
v
let f  a  s  conjunction effects rules active a  i e    fe   e
ed  a      ge    set f  a  s    ru e rule active s 
let i a  s  set fluents affected s  i e   i a  s     f p   e
ed  a   s    ge    f
  l fe     
define  recalling world states sets fluents 
 



   s i a  s      s i a  s  
rd   hs  a 
   
s     f  a  s 

thus  action effect false s  cannot execute s 
definition applies inertia  a fluent keeps value  fluents appear active rule 
contexts useful specify inertia explicitly extra effect rules form
keeps f g  fluent f p  shorthand writing two rules causes f f g
causes f f g  includes inertia  keeps  statements  say
complete domain description 
   

fia mir   c hang

example a   consider scenario figure   assume actions observations occur
figure     actions assumed deterministic  conditional effects  preconditions
must holds execute successfully  then  every action affects every fluent either negatively 
positively  all  thus  every transition relation complete domain description
includes rules form causes l keeps l  l fluent literal  a fluent
negation  
time step
action
location
bulb
switch

 

go w

e
 
sw

 
e
lit
 

go e

 
e
 
sw

sw on

 
e
 
sw

go w

 
e
lit
 

go e

 
e
 
sw

figure     action observation sequence  table entries observations   legend  e  east  e 
west  lit  light on  lit  light off  sw  switch on  sw  switch off 

consequently  every transition relation r completely defined domain description
 viewing tuple set elements 




causes e  causes sw  causes lit 

causes e causes sw causes lit
r



  keeps e
 
keeps lit
keeps sw
  go w  


 
 

 
 

go e  
 
 
 
  sw on  

say initially know effects go e  go w  know sw on does  then 
transition filtering starts product set r  of    possible relations  possible    
states  also  time step   know world state exactly  e  lit  sw   try sw on
get f ilter sw on      includes set transition relations
transition relations projecting state  e  lit  sw  appropriate choice s 
receive observations o    e sw time step        f ilter o    f ilter sw on      
removes transition belief state relations gave rise e sw  left
transition relations satisfying one tuples




sw on causes lit


sw on causes e 
sw on causes lit
sw on causes sw
sw on keeps e


sw on keeps lit

finally  perform action go w  update set states associated every
transition relation set pairs     receive observations time step   
conclude     f ilter o    f ilter go w        





sw on keeps e 
sw on causes e 

 
   e
 e










sw on causes sw 
sw on causes sw 
lit
lit
   
 
 
 
sw on causes lit 
sw on causes lit 










sw
sw





go e   
go e   
 
   

fil earning partially bservable eterministic action odels

appendix b  proofs
b   proof lemma      consequence finding existential quantification
p roof
consider cnf form   suppose clauses containing literal x x
            x             clauses  suppose clauses containing literal x
x             x b   v
suppose clauses
containing x x             c   note
v
l    x 
cn
      ic      ia  jb j    the formula produced adding
resolvents variable x removing clauses belonging l l    x     since
resolution complete consequence finding 
necessity   x     cnl    x      consider model x   definition 
extended l    i e   assigning value m x   m        extend
case  suppose contradiction model cn l    x      cannot
case m k       k  m        contradiction  then  must case
m i j           j b  therefore  m i       m j       
model   m x       m x j        thus either m i      
m j        contradiction 
sufficiency   cnl    x        x   consider model cnl    x      suppose
contradiction m x        is  extended l    m        now  extend
l   m x       cannot case m k       k since models
cnl    x      m x       cannot case m x j       j 
therefore m x         a  therefore  m i        m i j      
  j n  must m j       j  alter m x      
satisfies   contradiction   
b   proof theorem    
p roof
sides equality relation sets state transition relation pairs  show
two sets elements  show first left hand side equality
contained right hand side 
take hs    ri slaf  a   hs  ri   hs  ri satisfies     definition    
 s   hs  ri satisfies   hs  a  s  r  words 
hs  ri satisfies hs  a  s  r 
prove hs    ri satisfies slaf   a    need show teff  at   model
rm   r s  interprets p     let interprets p  s  interprets p     mr
interpreting la previous
section  interpretation

wsatisfy formula
v
v
one conjuncts lf  gg   alg g  l    lf  l    gg  alg g    falsified 
cannot case choice s 
assume contradiction  alg g  l    fails l  then   alg g  hold l 
false  portion interprets la built according mr   r  since hs  r  s 
know s  satisfies l  construction mr   contradicts l   false
 m interprets p   according s     therefore conclude  alg g  l    every l   
w
similarly  assume contradiction  l     gg  alg g    fails l  then  l   holds
s    als fails  again  way constructed mr must als takes value
corresponds l   truth value s    thus  must als takes value true  
done first direction 
   

fia mir   c hang

opposite direction  showing right hand side contained left hand side   take
hs    ri satisfies slaf  a     show
hs    ri slaf  a   hs  ri   hs  ri satisfies    
hs    ri    slaf  a    implies  corollary      hs     r  si   
teff  a   s    r  interpreting p     la   p  respectively   similar argument one give
first part shows hs  a  s  r  hs    ri slaf  a   hs  ri   hs  ri satisfies    
 
b   proof theorem      distribution slaf connectives
first part  show sets models slaf  a     slaf  a   
slaf  a    identical 
take model slaf  a      let   model slaf  a  m      
  then    model model   without loss generalization  assume
model   thus     slaf  a     follows model slaf  a   
slaf  a    
direction  take model slaf  a    slaf  a     then  model
slaf  a    model slaf  a     without loss generalization assume
model slaf  a     take   model   slaf  a  m      so        
follows    slaf  a     
similar argument follows case  take model slaf  a      let  
model slaf  a  m         then    model   thus    
slaf  a       slaf  a     follows model slaf  a   slaf  a    
 
b   proof theorem      closed form slaf belief state formula
p roof sketch
follow characterization offered theorem     formula     
take teff  a  t  resolve literals time t  resolution guaranteed generate
set consequences equivalent cnlt    t teff  a  t   
v
assuming   teff  a  t  logically equivalent teff  a  t     lf  gg g     alg gt  
v
lt     lf  gg g    lt    gt alg     follows two observations  first  notice
implies g g g     get gt alg  alg gt   lt    the
antecedent notwhold  formula true   second  notice that 
v second part
original teff  a  t     gg g    alg gt    equivalent  assuming     gg g    gt alg    
now  resolving literals time teff  a  t   consider
resolutions clauses  gt term  form alg gt lt   clauses form
lt    gt alg   other  yields equivalent
 


 

  lit  
i  
g        
wgm g
   im gi
l         lm f


 
li
algi   
 ag

i  

eliminate w
literals time resolve together sets clauses matching gi    gi   formula encodes resulting clauses chosen
   

fil earning partially bservable eterministic action odels

li

set g         gm chosen set literals l         lm   reason including  al
gi agi  
always choose clause gi   li specific type  either one includes alg
one produces al
g 
finally  get formula theorem afg af
g  g characterizes exactly one
state s   fact one set g         gm stronger rest  it entails
rest  g         gm complete terms  set complete fluent assignments g
satisfy    

b   proof theorem      closed form k affected fluents
p roof sketch
literal l clause c conjunction theorem      aggregate
action propositions single action proposition algl   g disjunction complete
preconditions l c  notice cannot ls negation c tautology  
lemma b   shows gl equivalent fluent term  first prove restricted lemma
b   
w
li
t  
  clause formula theorem      let gl  
lemma b   let c  
ag
i    li

w
 gi   li   l  gi    li    literal l    assume effect deterministic
one case term precondition  if case hold  nothing changes   then  g l
equivalent term 
p roof
gl disjunction complete state terms gi   represents set states
corresponds gi s  intuition apply
w
lit   algi
c
w
vm i  
t  
  i   algi    
i   li  
 
l
gl l c
c   part c affect l  reason complete terms g know
li
l

al
gi agi   thus  choice g includes conditions l
changes  assume precondition algl  
compute action model l updating copy g l   let li fluent literal 
set glt   gl  
   gl  glt gl     li   terms glt include li   thus 
glt glt li   algl algl li   thus  add li conjunct glt  
   otherwise  gl  glt gl     li   terms glt include li  
thus  glt glt li   algl algl li   thus  add li conjunct glt  
   otherwise  know li li value fluent l changes l  
true  since assume value l changes single case preconditions
 i e   conditional effects   either succeeds change  fails change  
li cannot part preconditions  i e   every term g glt replace li
li vice versa  precondition would still entail l action  thus 
algl algl   l     glt    li   result replacing li li true 






   related literal l proof above 

   

fia mir   c hang

result replacements term glt consistent  it consistent
original gl   satisfies   case    algl algl    


w
li
t  
cl  
lemma b   let c  
ag
clause formula theorem      let g
i   li

w
 gi   li   l   literal l  assume effect deterministic one case
cl equivalent
term precondition  if case hold  nothing changes   then  either g
cl
term  c subsumed another clause entailed formula g
equivalent term 
gl  

cl
p roof
consider gl lemma b    let gl  complete fluent term g
l
l
l
thus  g     l  let gt term equivalent g according lemma b   
clause c equivalent algl al
     however  algl already asserts change l l
gl




 

result action a  al
asserts change different condition l l  thus 
gl
 

  get subsuming clause c     c   al
  way
  case    algl al
gl
gl


 

 

remove c literals algi gi gl  

cl   however  clause c
process left clause c gl g
form theorem     gi missing  represent
theorem  must allow gi missing 
 
proof theorem continues thus  representation c    the new clause  takes space o n   
 each propositional symbol encoded o n  space  assuming constant encoding every
fluent p p  
however  number propositional symbols still large  there o   n   fluent terms 
encoding still requires o  n n   all preconditions effects  new propositional symbols 
notice limit attention clauses c k literals l whose action
proposition algl satisfies    gl l  k propositions c 
v
w
l
say  algi l  ik    c   ki   algi l   agk  
    im lit     always subsumed
l


k  
v
l
 

latter


sentence
always true  assume change
  ki   algi l   agk  
l


k  

k fluents  agk  
asserts lk   remains same  algi l asserts li changes
lk  

one conditions satisfied gli   
v
l
 which state k effects 
using clauses form   ki   algi l   agk  
l
l



k  

l

resolve away agj l j   k every clause c original conjunction  thus 
j
w
v
left clauses form c   ki   algi l   im lit     now  since choice literals

l         lk independent rest clause  every polarity
fluents  get clauses resolve  on combinations literals   and
subsumed by 
k
 
 
lit  
   
c   algi l  
i  



   

ik

fil earning partially bservable eterministic action odels

thus  get conjunction clauses form      g li  i k  fluent term  so 
conjunction clauses theorem     equivalent conjunction clauses
clause  k literals  thus  space required represent clause  kn 
finally  use fact every action dependent k fluents  every proposition asserts no change li equivalent conjunction literals stating none
possible k preconditions consistent affect li   example alli     lk lu implies

alli     lk alli     lk  lu      similarly  one elements conjunction implies

alli     lk lu    

b   proof theorem      equivalent restricted definition action axioms
p roof
let     p  eff  a    claim successful actions
a  slaf  a   
 
 p    p    see this  consider model     valuation fluents f p l f define
transition relation r valuation fluents p   define state s  hs    ri    
definition     hs    ri   exists hs  ri eff  a  satisfied  finally note eff  a  satisfied preconditions action met
s  consistent effects action applied s  is  eff  a  satisfied
hs  a  s  r  together  observations corollary     yield theorem   
b   proof theorem      as strips slaf correct
p roof
let shorthand notation c   denote c   cnl    p    p   
definition  slaf  ha  oi    slaf  o  slaf  a      theorem     
slaf  a    c  eff  a    formula equivalent c  eff  a   may generated
resolving
v fluents p  by following procedure proof lemma       suppose
  f p f fluent factored form  may rewrite c  eff  a   as 
 



slaf  a   










 

f p

 

f p

 

f p

 

f p



c prea f   c effa f   c f  

   



c prea f effa f  


c f prea f  


c f effa f  

equivalence holds resolvents generated resolving literals p c 
eff  a   still generated formula  is  pair clauses possibly resolved together  where fluent p resolved out  eff  a  generate new
consequence c   eff  a   appear together one c    components     
   

fia mir   c hang

every clause eff  a  contains one literal p  see possible consequences
generated 
note effa f may rewritten follows 
effa f



 

  al  af l   l     l   al  af l   

   

l f f  



 

 l  l  al     l   al af   

l f f  

straightforward verify equivalence rewritten formula original formula  note
performing rewriting  may discard clauses form f af af   must
true every consistent model  given axioms described section      
consider consequences generated component      may compute
consequences performing resolution  c pre a f   a f   a f    
may discard clauses inconsistent action models violate clause 
definition fluent factored formulas  c f   af   next  remaining components
computed straightforwardly 
 
c effa f  
 l  al af  
l f f  

c f prea f   c f   c prea f  

 

 a l  expll  

l f f  

c prea f effa f   c prea f   c effa f  

 

 l  al a l   

l f f  

c f effa f   c f   c effa f  

 

 l  al expll  

l f f  

finally  difficult see steps  a   c  procedure sets following formula  in
fluent factored form  
 
 
slaf  a   
af
 a l  expll    l  al  af a l  expll  
f p

l f f  

now  note slaf  o  slaf  a     slaf  a    o  note term 
slaf  a    made fluent factored performing unit resolution  exactly
steps    d   e  do   
b   proof theorem      as strips slaf complexity
p roof
consider size formula returned as strips slaf  overview  note
formula i cnf  integer      filtered formula one step
 i      cnf  then  note every observation fluent f resets f  part belief state
formula   cnf  thus       
details  first part  call procedure appends
one literal existing clauses formula  new clauses length k    
   

fil earning partially bservable eterministic action odels

generated  additionally  every fluent observed every k steps  transition belief
formula stays k cnf  i e   indefinitely compact   existing clauses may grow
length    literal per timestep  augmented steps    a   c   appropriate fluent
observed steps    d   e   clauses stop growing  finally  easy see
steps    a   e  performed polynomial time   
b   proof theorem      pre strips slaf correct
p roof
consider semantics slaf filtering strips action known precondition  case action failure  world filtered transition belief state
world meet action precondition  and satisfies observation   clearly  step  
algorithm performs filtering conjoining belief formula negation action
precondition  converted logically equivalent disjunction fluent factored formulas  
case action success  filtering performed first removing worlds
satisfy action precondition  so remaining worlds  action executable 
filtering remaining worlds using algorithm as strips slaf  moreover  theorem    
corollary     follows filtering formula performed filtering
subformulas i j separately  furthermore  slaf ha  oi       pre strips slaf ha  oi    
pre strips slaf ha  oi    slaf ha  oi    conditions corollary     
filtering subformula performed steps     algorithm 
finally  note steps     serve simplify belief formula produce logically
equivalent formula   
b    proof theorem      pre strips slaf complexity
p roof
note call as strips slaf subformula takes time linear size
subformula  steps involving as strips slaf performed linear time 
thus total time complexity linear  additionally  note every fluent observed every
k steps  every fluent factored subformula i j belief formula k cnf 
theorem amir
w         action preconditions contain literals  disjunction
form j i j contains disjuncts  therefore  entire belief formula stays
k cnf  indefinitely   

appendix c  experiments outputs
experiments  section    examine properties algorithms learning action models 
show learning tractable exact  appendix section bring generating models
learned models detailed comparison reader  recall algorithms
output representation set models possible given input  bring
one satisfying model learned formula 
experiments include following domains international planning competition
 ipc   drivelog  zenotravel  blocksworld  depots 
c   driverlog domain
driverlog domain following generating pddl 
 define  domain driverlog 

   

fia mir   c hang

  requirements  typing 
  types
location locatable   object
driver truck obj   locatable  
  predicates
 at  obj   locatable  loc   location 
 in  obj    obj  obj   truck 
 driving  d   driver  v   truck 
 path  x  y   location 
 empty  v   truck   
  action load truck
 parameters
  obj   obj
 truck   truck
 loc   location 
 precondition
 and  at  truck  loc   at  obj  loc  
 effect
 and  not  at  obj  loc    in  obj  truck   
  action unload truck
 parameters
  obj   obj
 truck   truck
 loc   location 
 precondition
 and  at  truck  loc   in  obj  truck  
 effect
 and  not  in  obj  truck    at  obj  loc   
  action board truck
 parameters
  driver   driver
 truck   truck
 loc   location 
 precondition
 and  at  truck  loc   at  driver  loc   empty  truck  
 effect
 and  not  at  driver  loc    driving  driver  truck 
 not  empty  truck    
  action disembark truck
 parameters
  driver   driver
 truck   truck
 loc   location 
 precondition
 and  at  truck  loc   driving  driver  truck  
 effect
 and  not  driving  driver  truck    at  driver  loc 
 empty  truck   
  action drive truck
 parameters
  truck   truck
 loc from   location
 loc to location
 driver   driver 
 precondition
 and  at  truck  loc from 
 driving  driver  truck 
 path  loc from  loc to  
 effect
 and  not  at  truck  loc from    at  truck  loc to   
  action walk
 parameters
  driver   driver
 loc from   location
 loc to   location 
 precondition
 and  at  driver  loc from   path  loc from  loc to  
 effect
 and  not  at  driver  loc from    at  driver  loc to     

one learned model  one possible satisfying model formula  random sequence
input driverlog domain following  brought together experimental parameters  
driverlog domain 
  ipc  problem   
      fluents
       randomly selected actions
     fluents observed per step

   

fil earning partially bservable eterministic action odels

   schematized  learning
      precondition heuristics
  action distribution 
  board truck        drive truck        disembark truck      
 walk         unload truck         load truck        
converting cnf
clause count       
variable count     
adding clauses
calling zchaff
parsing result
slaf time       
inference time       
learned model 
 walk needs  at  driver  loc from  
 walk needs  not  at  driver  loc to   
 walk causes  at  driver  loc to  
 walk causes  not  at  driver  loc from   
 walk keeps  path  loc from  loc from  
 walk keeps  path  loc to  loc to  
 walk keeps  path  loc to  loc from  
 walk keeps  path  loc from  loc to  
 drive truck needs  not  at  truck  loc to   
 drive truck needs  at  truck  loc from  
 drive truck causes  at  truck  loc to  
 drive truck causes  not  at  truck  loc from   
 drive truck keeps  at  driver  loc to  
 drive truck keeps  at  driver  loc from  
 drive truck keeps  driving  driver  truck  
 drive truck keeps  path  loc to  loc to  
 drive truck keeps  path  loc from  loc from  
 drive truck keeps  path  loc from  loc to  
 drive truck keeps  path  loc to  loc from  
 drive truck keeps  empty  truck  
 disembark truck needs  not  at  driver  loc   
 disembark truck needs  driving  driver  truck  
 disembark truck needs  not  empty  truck   
 disembark truck causes  at  driver  loc  
 disembark truck causes  not  driving  driver  truck   
 disembark truck causes  empty  truck  
 disembark truck keeps  at  truck  loc  
 disembark truck keeps  path  loc  loc  
 board truck needs  at  driver  loc  
 board truck needs  not  driving  driver  truck   
 board truck needs  empty  truck  
 board truck causes  not  at  driver  loc   
 board truck causes  driving  driver  truck  
 board truck causes  not  empty  truck   
 board truck keeps  at  truck  loc  
 board truck keeps  path  loc  loc  
 unload truck needs  not  at  obj  loc   
 unload truck needs  in  obj  truck  
 unload truck causes  at  obj  loc  

   

fia mir   c hang

 unload truck causes  not  in  obj  truck   
 unload truck keeps  at  truck  loc  
 unload truck keeps  path  loc  loc  
 unload truck keeps  empty  truck  
 load truck needs  at  obj  loc  
 load truck needs  not  in  obj  truck   
 load truck causes  not  at  obj  loc   
 load truck causes  in  obj  truck  
 load truck keeps  at  truck  loc  
 load truck keeps  path  loc  loc  
 load truck keeps  empty  truck  

c   zeno travel domain
zeno travel domain following generating pddl 
 define  domain zeno travel 
  requirements  typing 
  types aircraft person city flevel   object 
  predicates  at  x    either person aircraft   c   city 
 in  p   person  a   aircraft 
 fuel level  a   aircraft  l   flevel 
 next  l   l    flevel  
  action board
 parameters   p   person  a   aircraft  c   city 
 precondition  and  at  p  c   at  a  c  
 effect  and  not  at  p  c    in  p  a   
  action debark
 parameters   p   person  a   aircraft  c   city 
 precondition  and  in  p  a   at  a  c  
 effect  and  not  in  p  a    at  p  c   
  action fly
 parameters   a   aircraft  c   c    city  l   l    flevel 
 precondition  and  at  a  c    fuel level  a  l    next  l   l   
 effect  and  not  at  a  c     at  a  c    not  fuel level  a  l   
 fuel level  a  l    
  action zoom
 parameters   a   aircraft  c   c    city  l   l   l    flevel 
 precondition  and  at  a  c    fuel level  a  l    next  l   l  
 next  l   l    
 effect  and  not  at  a  c     at  a  c    not  fuel level  a  l   
 fuel level  a  l     
  action refuel
 parameters   a   aircraft  c   city  l   flevel  l    flevel 
 precondition  and  fuel level  a  l   next  l  l    at  a  c  
 effect  and  fuel level  a  l    not  fuel level  a  l     

one learned model  one possible satisfying model formula  random sequence
input zeno travel domain following  brought together experimental parameters  
zenotravel domain 

   

fil earning partially bservable eterministic action odels

 
 
 
 
 
 
 

ipc  problem  
   fluents        possible unique actions
     actions learned action sequence
  observed fluents per step
 schematized  learning
    precondition heuristics
action distribution    zoom        fly         refuel       
 board         debark        

converting cnf
clause count       
variable count     
adding clauses
calling zchaff
parsing result
slaf time       
inference time        
learned model 
 refuel needs  fuel level  a  l  
 refuel needs  not  fuel level  a  l    
 refuel causes  not  fuel level  a  l   
 refuel causes  fuel level  a  l   
 refuel keeps  next  l  l  
 refuel keeps  next  l  l   
 refuel keeps  next  l   l  
 refuel keeps  next  l   l   
 zoom needs  not  fuel level  a  l    
 zoom needs  fuel level  a  l   
 zoom causes  fuel level  a  l   
 zoom causes  not  fuel level  a  l    
 zoom keeps  fuel level  a  l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 zoom keeps  next  l   l   
 fly needs  not  fuel level  a  l    
 fly needs  fuel level  a  l   
 fly causes  fuel level  a  l   
 fly causes  not  fuel level  a  l    
 fly keeps  next  l   l   
 fly keeps  next  l   l   
 fly keeps  next  l   l   
 fly keeps  next  l   l   
 debark needs  in  p  a  
 debark causes  not  in  p  a   
 board needs  not  in  p  a   
 board causes  in  p  a  

   

fia mir   c hang

c   blocks world domain
blocksworld domain following generating pddl 
 define  domain blocksworld 
  requirements  strips 
  predicates  clear  x   object 
 on table  x   object 
 arm empty 
 holding  x   object 
 on  x  y   object  
  action pickup
 parameters   ob   object 
 precondition  and  clear  ob   on table  ob   arm empty  
 effect  and  holding  ob   not  clear  ob    not  on table  ob  
 not  arm empty    
  action putdown
 parameters   ob   object 
 precondition  holding  ob 
 effect  and  clear  ob   arm empty   on table  ob 
 not  holding  ob    
  action stack
 parameters   ob   object
 underob   object 
 precondition  and  clear  underob   holding  ob  
 effect  and  arm empty   clear  ob   on  ob  underob 
 not  clear  underob    not  holding  ob    
  action unstack
 parameters   ob   object
 underob   object 
 precondition  and  on  ob  underob   clear  ob   arm empty  
 effect  and  holding  ob   clear  underob   not  on  ob  underob  
 not  clear  ob    not  arm empty     

one learned model  one possible satisfying model formula  random sequence
input blocksworld domain following  brought together experimental parameters  
blocksworld domain 
      fluents
       randomly selected actions
     fluents observed per step
   schematized  learning
      precondition heuristics
converting cnf
clause count        
variable count     
adding clauses
calling zchaff
parsing result
slaf time       
inference time        

   

fil earning partially bservable eterministic action odels

learned model 
 unstack needs  not  clear  underob   
 unstack needs  clear  ob  
 unstack needs  arm empty  
 unstack needs  not  holding  ob   
 unstack needs  on  ob  underob  
 unstack causes  clear  underob  
 unstack causes  not  clear  ob   
 unstack causes  not  arm empty   
 unstack causes  holding  ob  
 unstack causes  not  on  ob  underob   
 unstack keeps  on table  underob  
 unstack keeps  on table  ob  
 unstack keeps  holding  underob  
 unstack keeps  on  underob  underob  
 unstack keeps  on  ob  ob  
 unstack keeps  on  underob  ob  
 stack needs  clear  underob  
 stack needs  not  clear  ob   
 stack needs  not  arm empty   
 stack needs  holding  ob  
 stack needs  not  on  ob  underob   
 stack causes  not  clear  underob   
 stack causes  clear  ob  
 stack causes  arm empty  
 stack causes  not  holding  ob   
 stack causes  on  ob  underob  
 stack keeps  on table  underob  
 stack keeps  on table  ob  
 stack keeps  holding  underob  
 stack keeps  on  underob  underob  
 stack keeps  on  ob  ob  
 stack keeps  on  underob  ob  
 putdown needs  not  clear  ob   
 putdown needs  not  on table  ob   
 putdown needs  not  arm empty   
 putdown needs  holding  ob  
 putdown causes  clear  ob  
 putdown causes  on table  ob  
 putdown causes  arm empty  
 putdown causes  not  holding  ob   
 putdown keeps  on  ob  ob  
 pickup needs  clear  ob  
 pickup needs  on table  ob  
 pickup needs  arm empty  
 pickup needs  not  holding  ob   
 pickup causes  not  clear  ob   
 pickup causes  not  on table  ob   
 pickup causes  not  arm empty   
 pickup causes  holding  ob  
 pickup keeps  on  ob  ob  

   

fia mir   c hang

c   depot domain
depot domain following generating pddl 
 define  domain depot 
  requirements  typing 
  types place locatable   object
depot distributor   place
truck hoist surface   locatable
pallet crate   surface 
  predicates  at  x   locatable  y   place 
 on  x   crate  y   surface 
 in  x   crate  y   truck 
 lifting  x   hoist  y   crate 
 available  x   hoist 
 clear  x   surface  
  action drive
 parameters   x   truck  y   place  z   place 
 precondition  and  at  x  y  
 effect  and  not  at  x  y    at  x  z   
  action lift
 parameters   x   hoist  y   crate  z   surface  p   place 
 precondition  and  at  x  p   available  x   at  y  p   on  y  z 
 clear  y  
 effect  and  not  at  y  p    lifting  x  y   not  clear  y  
 not  available  x    clear  z   not  on  y  z    
  action drop
 parameters   x   hoist  y   crate  z   surface  p   place 
 precondition  and  at  x  p   at  z  p   clear  z   lifting  x  y  
 effect  and  available  x   not  lifting  x  y    at  y  p 
 not  clear  z    clear  y   on  y  z   
  action load
 parameters   x   hoist  y   crate  z   truck  p   place 
 precondition  and  at  x  p   at  z  p   lifting  x  y  
 effect  and  not  lifting  x  y    in  y  z   available  x   
  action unload
 parameters   x   hoist  y   crate  z   truck  p   place 
 precondition  and  at  x  p   at  z  p   available  x   in  y  z  
 effect  and  not  in  y  z    not  available  x    lifting  x  y     

one learned model  one possible satisfying model formula  random sequence
input depot domain following  brought together experimental parameters  
depots domain 
  ipc  problem  
      fluents
       randomly selected actions
     fluents observed per step
   schematized  learning
      precondition heuristics
converting cnf

   

fil earning partially bservable eterministic action odels

clause count       
variable count     
adding clauses
calling zchaff
parsing result
slaf time       
inference time       
learned model 
 unload needs  in  y  z  
 unload needs  not  lifting  x  y   
 unload needs  available  x  
 unload causes  not  in  y  z   
 unload causes  lifting  x  y  
 unload causes  not  available  x   
 unload keeps  at  z  p  
 unload keeps  at  y  p  
 unload keeps  at  x  p  
 unload keeps  on  y  y  
 unload keeps  clear  y  
 load needs  not  in  y  z   
 load needs  lifting  x  y  
 load needs  not  available  x   
 load causes  in  y  z  
 load causes  not  lifting  x  y   
 load causes  available  x  
 load keeps  at  z  p  
 load keeps  at  y  p  
 load keeps  at  x  p  
 load keeps  on  y  y  
 load keeps  clear  y  
 drop needs  not  at  y  p   
 drop needs  not  on  y  z   
 drop needs  lifting  x  y  
 drop needs  not  available  x   
 drop needs  clear  z  
 drop needs  not  clear  y   
 drop causes  at  y  p  
 drop causes  on  z  z  
 drop causes  not  on  z  z   
 drop causes  on  z  y  
 drop causes  not  on  z  y   
 drop causes  on  y  z  
 drop causes  not  lifting  x  y   
 drop causes  lifting  x  z  
 drop causes  not  lifting  x  z   
 drop causes  available  x  
 drop causes  not  clear  z   
 drop causes  clear  y  
 drop keeps  at  z  p  
 drop keeps  at  x  p  
 drop keeps  on  z  z  
 drop keeps  on  z  y  
 drop keeps  on  y  y  
 drop keeps  lifting  x  z  

   

fia mir   c hang

 lift needs  at  y  p  
 lift needs  on  y  z  
 lift needs  not  lifting  x  y   
 lift needs  available  x  
 lift needs  not  clear  z   
 lift needs  clear  y  
 lift causes  not  at  y  p   
 lift causes  not  on  y  z   
 lift causes  on  z  z  
 lift causes  not  on  z  z   
 lift causes  on  z  y  
 lift causes  not  on  z  y   
 lift causes  lifting  x  y  
 lift causes  lifting  x  z  
 lift causes  not  lifting  x  z   
 lift causes  not  available  x   
 lift causes  clear  z  
 lift causes  not  clear  y   
 lift keeps  at  z  p  
 lift keeps  at  x  p  
 lift keeps  on  y  y  
 lift keeps  on  z  z  
 lift keeps  on  z  y  
 lift keeps  lifting  x  z  
 drive needs  at  x  y  
 drive needs  not  at  x  z   
 drive causes  not  at  x  y   
 drive causes  at  x  z  

references
amir  e          learning partially observable deterministic action models  proc  nineteenth
international joint conference artificial intelligence  ijcai      pp            international joint conferences artificial intelligence 
amir  e     russell  s          logical filtering  proc  eighteenth international joint conference
artificial intelligence  ijcai      pp        morgan kaufmann 
benson  s          inductive learning reactive action models  proceedings   th international conference machine learning  icml     
bertsekas  d  p     tsitsiklis  j  n          neuro dynamic programming  athena scientific 
boutilier  c   reiter  r     price  b          symbolic dynamic programming first order mdps 
proc  seventeenth international joint conference artificial intelligence  ijcai      pp 
        morgan kaufmann 
boyen  x   friedman  n     koller  d          discovering hidden structure complex dynamic
systems  proceedings   th conference uncertainty artificial intelligenceuai
      pp         morgan kaufmann  available http   www cs stanford edu  xb uai    
boyen  x     koller  d          approximate learning dynamic models  kearns  m  s   solla 
s  a     kohn  d  a   eds    advances neural information processing systems     proceedings      conferencenips       pp          cambridge  mit press  available http   www cs stanford edu  xb nips    
   

fil earning partially bservable eterministic action odels

calvanese  d   giacomo  g  d     vardi  m  y          reasoning actions planning
ltl action theories  principles knowledge representation reasoning  proc  eighth
intl conference  kr        pp          morgan kaufmann 
chang  a     amir  e          goal achievement partially known  partially observable domains 
proceedings   th intl conf  automated planning scheduling  icaps    
aaai press 
chang  c  l     lee  r  c  t          symbolic logic mechanical theorem proving  academic
press 
clarke  e  m   grumberg  o     peled  d  a          model checking  mit press 
darwiche  a     marquis  p          knowledge compilation map  journal artificial intelligence research             
davis  m     putnam  h          computing procedure quantification theory  journal
acm            
dawsey  w   minsker  b     amir  e          real time assessment drinking water systems using
bayesian networks  world environmental water resources congress 
dechter  r          bucket elimination  unifying framework reasoning  artificial intelligence 
              
del val  a          new method consequence finding compilation restricted language  proc  national conference artificial intelligence  aaai      pp         
aaai press mit press 
doherty  p   lukaszewicz  w     szalas  a          computing circumscription revisited  reduction algorithm  journal automated reasoning                
eiter  t     gottlob  g          complexity propositional knowledge base revision  updates  counterfactuals  artificial intelligence                  
even dar  e   kakade  s  m     mansour  y          reinforcement learning pomdps 
proc  nineteenth international joint conference artificial intelligence  ijcai      pp 
        international joint conferences artificial intelligence 
fagin  r   ullman  j  d     vardi  m  y          semantics updates databases 
proceedings second acm sigact sigmod symposium principles database
systems  pp          atlanta  georgia 
fikes  r   hart  p     nilsson  n          learning executing generalized robot plans  artificial
intelligence            
fox  m     long  d          pddl     extension pddl expressing temporal planning
domains  http   www dur ac uk d p long ipc pddl html  used aips   competition 
friedman  n   murphy  k     russell  s          learning structure dynamic probabilistic
networks  proc  fourteenth conference uncertainty artificial intelligence  uai     
morgan kaufmann 
gelfond  m     lifschitz  v          action languages  electronic transactions artificial intelligence  http   www etaij org      nr    
   

fia mir   c hang

ghahramani  z          introduction hidden markov models bayesian networks  international journal pattern recognition artificial intelligence             
ghahramani  z     jordan  m  i          factorial hidden markov models  machine learning     
       
ghallab  m   howe  a   knoblock  c   mcdermott  d   ram  a   veloso  m   weld  d     wilkins 
d          pddl planning domain definition language  version      tech  rep  cvc
tr        dcs tr       yale center computational vision control 
gil  y          learning experimentation  incremental refinement incomplete planning domains  proceedings   th international conference machine learning  icml     
pp       
ginsberg  m  l          readings nonmonotonic reasoning  chap     pp       morgan kaufmann  los altos  ca 
hajishirzi  h     amir  e          stochastic filtering probabilistic action models  proc  national conference artificial intelligence  aaai     
hill  d  j   minsker  b     amir  e          real time bayesian anomaly detection environmental
sensor data    nd congress international association hydraulic engineering
research  iahr       
hlubocky  b     amir  e          knowledge gathering agents adventure games  aaai   
workshop challenges game ai  aaai press 
holmes  m  p     charles lee isbell  j          looping suffix tree based inference partially
observable hidden state  proceedings   rd international conference machine
learning  icml      pp          acm press 
iwanuma  k     inoue  k          minimal answer computation sol  logics artificial
intelligence  proceedings eighth european conference  vol       lnai  pp     
     springer verlag 
james  m     singh  s          learning discovery predictive state representations dynamical systems reset  proceedings   st international conference machine
learning  icml      pp          acm press 
kaelbling  l  p   littman  m  l     cassandra  a  r          planning acting partially
observable stochastic domains  artificial intelligence             
kearns  m   mansour  y     ng  a  y          approximate planning large pomdps via reusable
trajectories  proceedings   th conference neural information processing systems
 nips     published       pp            mit press 
kuffner   j  j     lavalle  s  m          rrt connect  efficient approach single query path
planning   ieee international conference robotics automation  icra   pp     
     
lee  r  c  t          completeness theorem computer program finding theorems
derivable given axioms  ph d  thesis  university california  berkeley 
lifschitz  v          semantics strips  allen  j  f   hendler  j     tate  a   eds   
readings planning  pp          morgan kaufmann  san mateo  california 
   

fil earning partially bservable eterministic action odels

littman  m  l          algorithms sequential decision making  ph d  thesis  department
computer science  brown university  technical report cs       
littman  m  l   sutton  r     singh  s          predictive representations state  proceedings
  th conference neural information processing systems  nips     published      
mit press 
marquis  p          consequence finding algorithms  gabbay  d     smets  p   eds    handbook defeasible reasoning uncertainty management systems  vol     algorithms
defeasible uncertain reasoning  kluwer 
mccallum  r  a          instance based utile distinctions reinforcement learning hidden
state  proceedings   th international conference machine learning  icml     
morgan kaufmann 
mccarthy  j          applications circumscription formalizing common sense knowledge 
artificial intelligence            
mccarthy  j     hayes  p  j          philosophical problems standpoint artificial intelligence  meltzer  b     michie  d   eds    machine intelligence    pp         
edinburgh university press 
mcilraith  s     amir  e          theorem proving structured theories  proc  seventeenth
international joint conference artificial intelligence  ijcai      pp          morgan
kaufmann 
meuleau  n   peshkin  l   kim  k  e     kaelbling  l  p          learning finite state controllers
partially observable environments  proc  fifteenth conference uncertainty artificial
intelligence  uai      morgan kaufmann 
moskewicz  m  w   madigan  c  f   zhao  y   zhang  l     malik  s          chaff  engineering
efficient sat solver  proceedings   th design automation conference  dac    
murphy  k          dynamic bayesian networks  representation  inference learning  ph d 
thesis  university california berkeley 
nance  m   vogel  a     amir  e          reasoning partially observed actions  proc  national conference artificial intelligence  aaai      aaai press 
oates  t     cohen  p  r          searching planning operators context dependent
probabilistic effects  proc  national conference artificial intelligence  aaai      pp 
        aaai press 
pasula  h  m   zettlemoyer  l  s     kaelbling  l  p          learning probabilistic relational
planning rules  proceedings   th intl conf  automated planning scheduling
 icaps     aaai press 
pednault  e  p  d          adl  exploring middle ground strips situation
calculus  proc  first international conference principles knowledge representation
reasoning  kr      pp         
reiter  r          knowledge action  logical foundations describing implementing
dynamical systems  mit press 
   

fia mir   c hang

reiter  r          frame problem situation calculus  simple solution  sometimes 
completeness result goal regression  lifschitz  v   ed    artificial intelligence
mathematical theory computation  papers honor john mccarthy   pp         
academic press 
robert  c  p   celeux  g     diebolt  j          bayesian estimation hidden markov chains 
stochastic implementation  statist  prob  letters           
schmill  m  d   oates  t     cohen  p  r          learning planning operators real world  partially observable environments  proceedings  th intl conf  ai planning
scheduling  aips     pp          aaai press 
shahaf  d     amir  e          learning partially observable action schemas  proc  national
conference artificial intelligence  aaai      aaai press 
shahaf  d     amir  e          logical circuit filtering  proc  twentieth international joint conference artificial intelligence  ijcai      pp            international joint conferences
artificial intelligence 
shahaf  d   chang  a     amir  e          learning partially observable action models  efficient
algorithms  proc  national conference artificial intelligence  aaai      aaai press 
simon  l     del val  a          efficient consequence finding  proc  seventeenth international
joint conference artificial intelligence  ijcai      pp          morgan kaufmann 
sutton  r  s     barto  a  g          reinforcement learning  introduction  mit press 
tang  d   yinlei yu  d  r     malik  s          analysis search based algorithms satisfiability quantified boolean formulas arising circuit state space diameter problems 
proceedings seventh international conference theory applications satisfiability testing  sat      
thielscher  m          introduction fluent calculus  electronic transactions artificial
intelligence  http   www etaij org      nr    
thrun  s          robotic mapping  survey  exploring artificial intelligence new millennium  pp       morgan kaufmann 
wang  x          learning observation practice  incremental approach planning operator acquisition  proceedings   th international conference machine learning
 icml      pp          morgan kaufmann 
wu  k   yang  q     jiang  y          arms  automatic knowledge engineering tool learning
action models ai planning  knowledge engineering review                
yang  q   wu  k     jiang  y          learning actions models plan examples incomplete
knowledge   biundo  s   myers  k  l     rajan  k   eds    icaps  pp          aaai 

   


