journal of artificial intelligence research                  

submitted       published      

computational logic foundations of kgp agents
antonis kakas

antonis ucy ac cy

department of computer science  university of cyprus
   kallipoleos str   p o  box      cy      nicosia  cyprus

paolo mancarella

paolo mancarella unipi it

dipartimento di informatica  universita di pisa
largo b  pontecorvo            pisa  italy

fariba sadri

fs doc ic ac uk

department of computing  imperial college london
south kensington campus  london sw  az  uk

kostas stathis

kostas cs rhul ac uk

department of computer science  royal holloway
university of london  egham  surrey tw    ex  uk

francesca toni

ft doc ic ac uk

department of computing  imperial college london
south kensington campus  london sw  az  uk

abstract
this paper presents the computational logic foundations of a model of agency called
the kgp  knowledge  goals and plan  model  this model allows the specification of
heterogeneous agents that can interact with each other  and can exhibit both proactive
and reactive behaviour allowing them to function in dynamic environments by adjusting
their goals and plans when changes happen in such environments  kgp provides a highly
modular agent architecture that integrates a collection of reasoning and physical capabilities  synthesised within transitions that update the agents state in response to reasoning 
sensing and acting  transitions are orchestrated by cycle theories that specify the order in
which transitions are executed while taking into account the dynamic context and agent
preferences  as well as selection operators for providing inputs to transitions 

   introduction
it is widely acknowledged that the concept of agency provides a convenient and powerful
abstraction to describe complex software entities acting with a certain degree of autonomy
to accomplish tasks  often on behalf of a user  wooldridge         an agent in this context
is understood as a software component with capabilities such as reacting  planning and
 inter  acting to achieve its goals in the environment in which it is situated  in this paper 
we present a model of agency  called kgp  knowledge  goals and plan   the model
is hierarchical and highly modular  allowing independent specifications of a collection of
reasoning and physical capabilities  used to equip an agent with intelligent decision making
and adaptive behaviour  the model is particularly suited to open  dynamic environments
where the agents have to adapt to changes in their environment and they have to function
in circumstances where information is incomplete 
c
    
ai access foundation  all rights reserved 

fikakas  mancarella  sadri  stathis   toni

the development of the kgp model was originally motivated by the existing gap between modal logic specifications  rao   georgeff        of bdi agents  bratman  israel   
pollack        and their implementation  for example see the issues raised by rao        
another motivation for the development of kgp comes from our participation in the socs
project  socs         where we had the need for an agent model that satisfies several requirements  more specifically  we aimed at an agent model that was rich enough to allow
intelligent  adaptive and heterogeneous behaviour  formal so that it could lent itself well to
formal analysis  and implementable in such a way that the implementation was sufficiently
close to the formal specification to allow verification  although several models of agency
have been proposed  none satisfies all of the above requirements at once 
to bridge the gap between specification and implementation the kgp model is based
on computational logic  cl   the focus of the work is to extend and synthesise a number
of useful computational logic techniques to produce formal and executable specifications of
agents  for this purpose  the model integrates abductive logic programming  alp   kakas 
kowalski    toni         logic programming with priorities  kakas  mancarella    dung 
      prakken   sartor        and constraint logic programming  jaffar   maher        
each of these techniques has been explored in its own right  but their modular integration
within the kgp model explores extensions of each  as well as providing the high level agent
reasoning capabilities 
the kgp model provides a hierarchical architecture for agents  it specifies a collection
of modular knowledge bases  each formalised in cl  these knowledge bases support a collection of reasoning capabilities  such as planning  reactivity  and goal decision  all of which are
given formal specifications  the model also includes a specification of physical capabilities 
comprising of sensing and actuating  the capabilities are utilised within transitions  that
model how the state of the agent changes as a result of its reasoning  sensing and acting 
transitions use selection operators providing them with inputs  a control component  called
cycle theory  also formalised in cl  specifies in what order the transitions are executed  depending on the environment  the state of the agent  and the preferences of the agent  the
cycle theory takes the agent control beyond the one size fits all approach used by most
agent models  and allows us to specify agents with different preferences and profiles of behaviour  sadri   toni         in particular  whereas the majority of existing agent models
rely upon an observe plan act  by means of our cycle theory we can model behaviours
such as observe revise goals planact or observe plan sense action preconditions act or
observe plan act plan act  we provide one example of cycle theory  that we refer to as
normal  allowing all behaviours above depending on different circumstances  the environment in which the agent is situated and its preferences   note also that  with respect to
other agent models  the kgp model allows agents to revise their goals during their life time 
and observing the environment according to two modalities  active and passive observation 
an agent built with a kgp architecture dynamically determines its goals  plans  partially  how to achieve the goals  interleaves planning with action executions and with making
observations in the environment and receiving any messages from other agents  adapts its
goals and plans to any new information it receives  and any changes it observes  and generates appropriate reactions 
a number of publications have already described aspects of  an initial version of  the
kgp agents  a precursor of the overall model has been described by kakas  mancarella 
   

ficomputational logic foundations of kgp agents

sadri  stathis  and toni      b   its planning component has been presented by mancarella 
sadri  terreni  and toni         its cycle theory has been developed by kakas  mancarella 
sadri  stathis  and toni      a  and its implementation has been discussed by stathis et al 
        by yip  forth  stathis  and kakas         and by bracciali  endriss  demetriou 
kakas  lu  and stathis         in this paper  we provide the full formal specification
of all the components of the kgp model  thus offering the complete technical account
of kgp in one place  in providing this full formal specification  we have adjusted and
further developed the model  in particular  the notion of state and its definition is novel 
the reasoning capabilities have been simplified and some have been added  the physical
capabilities have been extended  to include actuating  and formally defined  the transitions
and the selection operators have been formally defined in full 
the rest of the paper is structured as follows  in sections   and   we give an outline of
the model and then review the background information necessary for the full description  in
sections         and    respectively  we describe the internal state of kgp agents  their reasoning and physical capabilities  and their transitions  in section   we describe the selection
operators which are then used in the cycle theory which is described in section    following
the detailed description of kgp agents we illustrate the model by a series of examples in
section     and then compare the model with others in the literature in section     finally 
we conclude the paper in section    

   kgp model  outline
in this section we give an overview of the kgp agent model and its components  and
provide some informal examples of its functioning  this model relies upon
 an internal  or mental  state  holding the agent knowledge base  beliefs   goals  desires  and plans  intentions  
 a set of reasoning capabilities 
 a set of physical capabilities 
 a set of transition rules  defining how the state of the agent changes  and defined in
terms of the above capabilities 
 a set of selection operators  to enable and provide appropriate inputs to the transitions 
 a cycle theory  providing the control for deciding which transitions should be applied
when 
the model is defined in a modular fashion  in that different activities are encapsulated
within different capabilities and transitions  and the control is a separate module  the
model also has a hierarchical structure  depicted in figure   
    internal state
this is a tuple hkb    f  c  i  where 
   

fikakas  mancarella  sadri  stathis   toni

cycle
theory

transitions
s
t
a

selection
operators

t
e
reasoning

capabilities

physical capabilities

figure    a graphical overview of the kgp model
 kb  holds the beliefs of the agent about the external world in which it is situated
 including past communications   as well as a record of the actions it has already
executed 
 f is a forest of trees whose nodes are goals  which may be executable or not  each
tree in the forest gives a hierarchical presentation of goals  in that the tree represents
the construction of a plan for the root of the tree  the set of leaves of any tree in f
forms a currently chosen plan for achieving the root of the tree  executable goals are
actions which may be physical  communicative  or sensing  for simplicity  we assume
that actions are atomic and do not have a duration  non executable goals may be
mental or sensing  only non executable mental goals may have children  forming
 partial  plans for them  actions have no children in any tree in f  each goal has an
associated time variable  which is implicitly existentially quantified within the overall
state and serves two purposes      indicating the time the goal is to be achieved 
which is instantiated if the goal is achieved at an appropriate time  and     providing
a unique identifier for that goal  in the remainder of the paper  we will often use the
following terminology for goals in f  when we want to emphasise their role and or
their nature  the roots of trees in f will be referred to as top level goals  executable
goals will be referred to as actions  and non executable goals which are not top level
goals will be referred to as sub goals  top level goals will be classified as reactive or
non reactive  as will be explained later    note that some top level  reactive  goals
may be actions 
   roughly speaking  reactive goals are generated in response to observations  e g  communications received
from other agents and changes in the environment  for example to repair plans that have already been
generated  non reactive goals  on the other hand  are the chosen desires of the agent 

   

ficomputational logic foundations of kgp agents

 c is the temporal constraint store  namely a set of constraint atoms in some given
underlying constraint language  these constrain the time variables of the goals in f 
for example  they may specify a time window over which the time of an action can
be instantiated  at execution time 
  is a set of equalities instantiating time variables with time constants  for example 
when the time variables of actions are instantiated at action execution time  records
of the instantiations are kept in  
    reasoning capabilities
kgp supports the following reasoning capabilities 
 planning  which generates plans for mental goals given as input  these plans consist
of temporally constrained sub goals and actions designed for achieving the input goals 
 reactivity  which is used to provide new reactive top level goals  as a reaction to
perceived changes in the environment and the current plans held by the agent 
 goal decision  which is used to revise the non reactive top level goals  adapting the
agents state to changes in the environment 
 identification of preconditions and identification of effects for actions  which are used
to determine appropriate sensing actions for checking whether actions may be safely
executed  if their preconditions are known to hold  and whether recently executed
actions have been successful  by checking that some of their known effects hold  
 temporal reasoning  which allows the agent to reason about the evolving environment 
and to make predictions about properties  including non executable goals  holding in
the environment  based on the  partial  information the agent acquires over its lifetime 
 constraint solving  which allows the agent to reason about the satisfiability of the
temporal constraints in c and  
in the concrete realisation of the kgp model we provide in this paper  we have chosen
to realise the above capabilities in various extensions of the logic programming paradigm 
in particular  we use  conventional  logic programming for identification of preconditions
and effects  abductive logic programming with constraints  see section      for planning 
reactivity and temporal reasoning  and logic programming with priorities  see section     
for goal decision 
    physical capabilities
in addition to the reasoning capabilities  a kgp agent is equipped with physical capabilities  linking the agent to its environment  consisting of
 a sensing capability  allowing the agent to observe that properties hold or do not
hold  and that other agents have executed actions 
 an actuating capability  for executing  physical and communicative  actions 
   

fikakas  mancarella  sadri  stathis   toni

    transitions
the state hkb    f  c  i of an agent evolves by applying transition rules  which employ the
capabilities as follows 
 goal introduction  gi   possibly changing the top level goals in f  and using goal
decision 
 plan introduction  pi   possibly changing f and c and using planning 
 reactivity  re   possibly changing the reactive top level goals in f and c  and using
the reactivity capability 
 sensing introduction  si   possibly introducing new sensing actions in f for checking
the preconditions of actions already in f 
 passive observation introduction  poi   updating kb  by recording unsolicited information coming from the environment  and using sensing 
 active observation introduction  aoi   possibly updating  and kb    by recording
the outcome of  actively sought  sensing actions  and using sensing 
 action execution  ae   executing all types of actions and as a consequence updating
kb  and   and using actuating 
 state revision  sr   possibly revising f  and using temporal reasoning and constraint solving 
    cycle and selection operators
the behaviour of an agent is given by the application of transitions in sequences  repeatedly
changing the state of the agent  these sequences are not determined by fixed cycles of behaviour  as in conventional agent architectures  but rather by reasoning with cycle theories 
cycle theories define preference policies over the order of application of transitions  which
may depend on the environment and the internal state of an agent  they rely upon the
use of selection operators for detecting which transitions are enabled and what their inputs
should be  as follows 
 action selection for inputs to ae  this selection operator uses the temporal reasoning
and constraint solving capabilities 
 goal selection for inputs to pi  this selection operator uses the temporal reasoning
and constraint solving capabilities 
 effect selection for inputs to aoi  this selection operator uses the identification of
effect reasoning capability 
 precondition selection for inputs to si  this selection operator uses the identification
of preconditions  temporal reasoning and constraint solving capabilities 
   

ficomputational logic foundations of kgp agents

the provision of a declarative control for agents in the form of cycle theories is a highly
novel feature of the model  which could  in principle  be imported into other agent systems 
in the concrete realisation of the kgp model we provide in this paper  we have chosen
to realise cycle theories in the same framework of logic programming with priorities and
constraints  see section      that we also use for goal decision 
some of the relationships between the capabilities  transitions and the selection operators
are summarised in tables     and   below  table     indicates which capabilities  rows 
are used by which transitions and selection operators  table   indicates which selection
operators are used to compute possible inputs for which transitions in the cycle theory 

sensing
actuating
  plan
  pre
  gd
  react
  t r
  cs
  ef f

ae
x
x

transitions
aoi gi p oi
x
x

pi

re

sr

si

selection operators
fgs fas fes fp s

x
x

x

x
x

x
x

x
x
x

x
x

x

x
x

x

table    a tabular overview of use of capabilities by transitions and selection operators 
here    plan     pre     gd     react     t r     cs and   ef f   stand for  respectively  the
planning  identification of preconditions  goal decision  reactivity  temporal reasoning  constraint solving and identification of effects  reasoning  capabilities  and
fgs   fas   fes   fp s stand for  respectively  the goal  action  effect and precondition
selection operators 

ae
fgs
fas
fes
fp s

aoi

gi

p oi

pi
x

re

sr

si

x
x
x

table    a tabular overview of the connections between selection operators and transitions 
as required by the cycle theory  here  fgs   fas   fes   fp s stand for  respectively 
the goal  action  effect and precondition selection operators 
before we provide these components  though  we introduce below informally a scenario
and some examples that will be used to illustrate the technical details of the kgp agent
   

fikakas  mancarella  sadri  stathis   toni

model throughout the paper  a full  formal presentation of these as well as additional
examples will be given throughout the paper and in section    
    examples
we draw all our examples from a ubiquitous computing scenario that we call the san
vincenzo scenario  presented by de bruijn and stathis        and summarised as follows 
a businessman travels for work purposes to italy and  in order to make his trip easier 
carries a personal communicator  namely a device that is a hybrid between a mobile phone
and a pda  this device is the businessmans kgp agent  this agent can be considered
as a personal service agent  mamdani  pitt    stathis         or psa for short  because
it provides proactive information management and flexible connectivity to smart services
available in the global environment within which the businessman travels within 
      setting  
the businessmans psa requests from a san vincenzo station agent  svs  the arrival time
of the train tr   from rome  as svs does not have this information it answers with a
refusal  then later  svs receives information of the arrival time of the tr   train from a
central office agent  co  when the psa requests the arrival time of tr   again  svs will
accept the request and provide the information 
this first example requires one to use the reactivity capability to model rules of interaction and the re transition  a  to achieve interaction amongst agents  and  b  to specify
dynamic adjustments of the agents behaviour to changes  allowing different reactions to
the same request  depending on the current situation of the agent  here  the interaction is a
form of negotiation of resources amongst agents  where resources are items of information 
thus  the current situation of the agents amounts to what resources information the agents
currently own 
this example also requires the combination of transitions re  poi  and ae to achieve
the expected agents behaviours  as follows 
   psa makes the initial request by applying ae
   svs becomes aware of this request by performing poi  and changing its kb  accordingly 
   svs decides to reply with a refusal by performing re  and adding the corresponding
action to its plan in f 
   svs utters the refusal by performing ae
   svs becomes aware  by poi  of the arrival time  modifying its kb  accordingly 
   psa makes the second request by applying ae again
   svs decides to reply with the requested information by performing re  and adding
the corresponding action to its plan in f  and communicates the information by
performing ae 
   

ficomputational logic foundations of kgp agents

this sequence of transitions is given by the so called normal cycle theory that we will
see in section   
      setting  
in preparation of the businessmans next trip  his psa aims at getting a plane ticket from
madrid to denver as well as obtaining a visa to the usa  one possible way to buy plane
tickets is over the internet  buying tickets this way is usually possible  but not to all
destinations  depending on whether the airlines flying to the destinations sell tickets over
the internet or not  and not without an internet connection  the psa does not currently have
the connection  nor the information that denver is indeed a destination for which tickets
can be bought online  it plans to buy the ticket over the internet nonetheless  conditionally 
but checks the conditions before executing the planned action  after successfully buying
the ticket  psa focuses on the second goal  of obtaining a visa  this can be achieved by
applying to the usa embassy in madrid  but the application requires an address in the
usa  this address can be obtained by arranging for a hotel in denver 
this example illustrates the form of partial planning adopted by the kgp model
 where non executable sub goals as well as actions may be part of plans  and shows how
the combination of transition pi with si and ae allows the psa agent to deal with partial
information  to generate conditional plans and plans with several layers  as follows 
   psa is initially equipped with the top level goals to get a ticket to denver and to
obtain a visa  through an earlier application of gi 
   by pi for the first goal  psa adds a partial plan to its f  of buying a ticket online
subject to sub goals that there is an internet connection available and that online
tickets can be bought to denver  these sub goals are sensing goals
   by si  sensing actions are added to f to evaluate the sensing sub goals in the environment
   these sensing actions are executed by ae  and kb  is modified accordingly 
   depending on the sensed values of the sensing sub goals the buying action may or
may not be executed by ae  let us assume in the remainder of the example that this
action is executed
   sr is applied to eliminate all actions  since they have already been executed   subgoals and top level goal of getting a ticket to denver  since they have been achieved 
   by pi for the remaining top level goal of obtaining a visa  psa adds a plan to fill in
an application form  action  and acquiring a residence address in denver  sub goal 
   the action cannot be executed  as psa knows that the businessman is not resident in
the usa  further pi introduces a plan for the sub goal of booking a hotel  action  for
the subgoal of acquiring a residence address in denver
   ae executes the booking action
   

fikakas  mancarella  sadri  stathis   toni

    ae executes the action of applying for a visa
    sr eliminates all actions  since they have already been executed   sub goal and toplevel goal of getting a visa  since they have been achieved  

   background
in this section we give the necessary background for the reasoning capabilities and the cycle
theory of kgp agents  namely 
 constraint logic programming  pervasive to the whole model 
 abductive logic programming  at the heart of the planning  reactivity and temporal
reasoning capabilities  and
 logic programming with priorities  at the heart of the goal decision capability and
cycle theories 
    constraint logic programming
constraint logic programming  clp   jaffar   maher        extends logic programming
with constraint predicates which are not processed as ordinary logic programming predicates 
defined by rules  but are checked for satisfiability and simplified by means of a built in 
black box constraint solver  these predicates are typically used to constrain the values
that variables in the conclusion of a rule can take  together with unification which is also
treated via an equality constraint predicate   in the kgp model  constraints are used
to determine the value of time variables  in goals and actions  under a suitable temporal
constraint theory 
the clp framework is defined over a structure   consisting of a domain d    and a set
of constraint predicates which includes equality  together with an assignment of relations
on d    for each such constraint predicate  in clp  constraints are built as first order
formulae in the usual way from primitive constraints of the form c t            tn   where c is a
constraint predicate symbol and t            tn are terms constructed over the domain  d    
of values  then the rules of a constraint logic program  p   take the same form as rules in
conventional logic programming given by
h  l            ln
with h an  ordinary  atom  l            ln literals  and n     literals can be positive  namely
ordinary atoms  or negative  namely of the form not b  where b is an ordinary atom 
or constraint atoms over    the negation symbol not indicates negation as failure  first
introduced by clark         all variables in h and li are implicitly universally quantified 
with scope the entire rule  h is called the head  or the conclusion  and l            ln is called
the body  or the conditions  of a rule of the form above  if n      the rule is called a fact 
a valuation    of a set of variables is a mapping from these variables to the domain
d    and the natural extension which maps terms to d     a valuation   on the set of all
variables appearing in a set of constraints c  is called an   solution of c iff c  obtained by
applying  to c  is satisfied  i e  c evaluates to true under the given interpretation of the
   

ficomputational logic foundations of kgp agents

constraint predicates and terms  this is denoted by      c  a set c is called   solvable
or   satisfiable  denoted by     c  iff it has at least one   solution  i e       c for some
valuation  
one way to give the meaning of a constraint logic program p is to consider the grounding of the program over its herbrand base and all possible valuations  over d     of its
constraint variables  in each such rule  if the ground constraints c in the body are evaluated to true then the rule is kept with the constraints c dropped  otherwise the whole
rule is dropped  let ground p   be the resulting ground program  the meaning of p is
then given by the meaning   lp of ground p    for which there are many different possible
choices  kakas  kowalski    toni         the resulting overall semantics for the constraint
logic program p will be referred to as   lp       more precisely  given a constraint logic
program p and a conjunction n  c  where n is a conjunction of non constraint literals
and c is a conjunction of constraint atoms   in the remainder of the paper we will write
p   lp     n  c
to denote that there exists a ground substitution  over the variables of n  c such that 
      c
 ground p     lp n  
    abductive logic programming with constraints
an abductive logic program with constraints is a tuple h   p  a  ii where 
   is a structure as in section    
 p is a constraint logic program  namely a set of rules of the form
h  l            ln
as in section    
 a is a set of abducible predicates in the language of p   these are predicates not
occurring in the head of any clause of p  without loss of generality  see  kakas et al  
        atoms whose predicate is abducible are referred to as abducible atoms or
simply as abducibles 
 i is a set of integrity constraints  that is  a set of sentences in the language of p   all
the integrity constraints in the kgp model have the implicative form
l            ln  a          am  n     m     
where li are literals  as in the case of rules      aj are atoms  possibly the special
atom f alse   the disjunction a          am is referred to as the head of the constraint
and the conjunction l            ln is referred to as the body  all variables in an integrity
constraint are implicitly universally quantified from the outside  except for variables
occurring only in the head  which are implicitly existentially quantified with scope the
head itself 
   if n      then l            ln represents the special atom true 

   

fikakas  mancarella  sadri  stathis   toni

given an abductive logic program with constraints h   p  a  ii and a formula  query 
q  which is an  implicitly existentially quantified  conjunction of literals in the language
of p   the purpose of abduction is to find a  possibly minimal  set of  ground  abducible
atoms  which  together with p   entails  an appropriate ground instantiation of  q  with
respect to some notion of entailment that the language of p is equipped with  and such
that the extension of p by  satisfies i  see  kakas et al         for possible notions
of integrity constraint satisfaction   here  the notion of entailment is the combined
semantics   lp       as discussed in section     
formally  given a query q  a set  of  possibly non ground  abducible atoms  and a
set c of  possibly non ground  constraints  the pair    c  is an abductive answer  with
constraints  for q  with respect to an abductive logic program with constraints h   p  a  ii 
iff for all groundings  for the variables in q    c such that      c  it holds that
 i  p     lp     q  and
 ii  p    lp     i  i e  for each b  h  i  if p    lp     b then p    lp     h 
here   plays the role of  in the earlier informal description of abductive answer  note
also that  by  ii   integrity constraints are not classical implications 
note also that  when representing knowledge as an abductive logic program  one needs
to decide what should go into the logic program  what in the integrity constraints and what
in the abducibles  intuitively  integrity constraints are normative in that they need to be
enforced  by making sure that their head holds whenever their body does  by condition  ii 
above   whereas logic programming rules enable  with the help of abducibles  the derivation
of given goals  by condition  i  above   finally  abducibles are chosen amongst the literals
that cannot be derived by means of logic programming rules  in this paper  we will represent reactive constraints  that are condition action rules forcing the reactive behaviour of
agents  as integrity constraints  thus to some extent addressing this knowledge representation challenge posed by abductive logic programming by imposing a sort of structure on
the abductive logic programs we use 
the notion of abductive answer can be extended to take into account an initial set
of  possibly non ground  abducible atoms   and an initial set of  possibly non ground 
constraint atoms c    in this extension  an abductive answer for q  with respect to
 h   p  a  ii      c   
is a pair    c  such that
 i          
 ii  c  c        and
 iii         c  c    is an abductive answer for q with respect to h   p  a  ii  in the
earlier sense  
it is worth noticing that an abductive answer    c  for the query true with respect to
 h   p  a  ii      c   
   

ficomputational logic foundations of kgp agents

should be read as the fact that the abducibles in      along with the constraints in
c   c  guarantee the overall consistency with respect to the integrity constraints given in
i  this will be used for the specification of some capabilities of kgp agents 
in the remainder of the paper  for simplicity  we will omit   from abductive logic
programs  which will be written simply as triples hp  a  ii  in addition  all abductive logic
programs that will present in kgp are variants of a core event calculus  kowalski   sergot 
       that we will define in section       
    logic programming with priorities
for the purposes of this paper  a logic program with priorities over a constraint structure
   referred to as t   consists of four parts 
 i  a low level or basic part p   consisting of a logic program with constraints  each rule
in p is assigned a name  which is a term  e g  one such rule could be
n x  y     p x   q x  y    r y  
with name n x  y   naming each ground instance of the rule 
 ii  a high level part h  specifying conditional  dynamic priorities amongst rules in p or
h  e g  one such priority could be
h x    m x   n x   c x 
to be read  if  some instance of  the condition c x  holds  then  the corresponding instance of  the rule named by m x  should be given higher priority than  the
corresponding instance of  the rule named by n x   the rule itself is named h x  
 iii  an auxiliary part a  which is a constraint logic program defining  auxiliary  predicates
occurring in the conditions of rules in p  h and not in the conclusions of any rule in
p or h 
 iv  a notion of incompatibility which  for our purposes  can be assumed to be given as a
set of rules defining the predicate incompatible    e g 
incompatible p x   p   x  
to be read  any instance of the literal p x  is incompatible with the corresponding
instance of the literal p   x   we assume that incompatibility is symmetric and always
includes that r  s is incompatible with s  r for any two rule names r  s  we refer
to the set of all incompatibility rules as i 
any concrete lpp framework is equipped with a notion of entailment  which we denote by   pr   that is defined on top of the underlying logic programming with constraints
semantics   lp       this is defined differently by different approaches to lpp but they all
share the following pattern  given a logic program with priorities t   hp  h  a  ii and a
conjunction  of ground  non auxiliary  atoms  t   pr  iff
 i  there exists a subset p   of the basic part p such that p    a   lp       and
   

fikakas  mancarella  sadri  stathis   toni

 ii  p   is preferred wrt h a over any other subset p    of p that derives  under   lp      
a conclusion that is incompatible  wrt i  with  
each framework has its own way of specifying what is meant for one sub theory p   to be
preferred over another sub theory p      for example  in existing literature  kakas et al  
      prakken   sartor        kowalski   toni        kakas   moraitis           pr is
defined via argumentation  this is also the approach that we adopt  relying on the notion
of an admissible argument as a sub theory that is  i  consistent  does not have incompatible
conclusions  and  ii  whose rules do not have lower priority  with respect to the high level
part h of our theory  than those of any other sub theory that has incompatible conclusions
with it  the precise definition of how sets of rules are to be compared again is a matter of
choice in each specific framework of lpp 
given such a concrete definition of admissible sub theories  the preference entailment 
t   pr   is then given by 
 i  there exists a  maximal  admissible sub theory t   of t such that t     lp       and
 ii  for any  that is incompatible with  there does not exist an admissible sub theory
t    of t such that t      lp      
when only the first condition of the above is satisfied we say that the theory t credulously prefers or possibly prefers   when both conditions are satisfied we say that the
theory sceptically prefers  

   the state of kgp agents
in this section we define formally the concept of state for a kgp agent  we also introduce
all the notation that we will use in the rest of the paper in order to refer to state components 
where necessary  we will also try to exemplify our discussion with simple examples 
    preliminaries
in the kgp model we assume  possibly infinite  vocabularies of 
 fluents  indicated with f  f           
 action operators  indicated with a  a          
 time variables  indicated with              
 time constants  indicated with t  t                         standing for natural numbers  we also
often use the constant now to indicate the current time 
 names of agents  indicated with c  c           
 constants  other than the ones mentioned above  normally indicated with lower case
letters  e g  r  r         
   

ficomputational logic foundations of kgp agents

 a given constraint language  including constraint predicates                  with respect to some structure    e g  the natural numbers  and equipped with a notion of
constraint satisfaction      see section      
we assume that the set of fluents is partitioned into two disjoint sets 
 mental fluents  intuitively representing properties that the agent itself is able to plan
for so that they can be satisfied  but can also be observed  and
 sensing fluents  intuitively representing properties which are not under the control of
the agent and can only be observed by sensing the external environment 
for example  problem f ixed and have resource may represent mental fluents  namely
the properties that a  given  problem has been fixed and a  given  resource should be obtained  whereas request accepted and connection on may represent sensing fluents  namely
the properties that a request for some  given  resource is accepted and that some  given 
connection is active  note that it is important to distinguish between mental and sensing
fluents as they are treated differently by the control of the agent  mental fluents need to
be planned for  whereas sensing fluents can only be observed  this will be clarified later in
the paper 
we also assume that the set of action operators is partitioned into three disjoint sets 
 physical action operators  representing actions that the agent performs in order to
achieve some specific effect  which typically causes some changes in the environment 
 communication action operators  representing actions which involve communications
with other agents 
 sensing action operators  representing actions that the agent performs to establish
whether some fluent  either a sensing fluent or an expected effect of some action 
holds in the environment  or whether some agent has performed some action 
for example  sense connection on     is an action literal representing the act of sensing whether or not a network connection is on at time    do clear table     is an action literal representing the physical action of removing every item on a given table  and
tell c    c    request r     d     is an action literal representing a communication action which
expresses that agent c  is requesting from agent c  the resource r  within a dialogue with
identifier d  at time     
each fluent and action operator has an associated arity  we assume that this arity is
greater than or equal to    in that one argument  the last one  by convention  is always
the time point at which a given fluent holds or a given action takes place  this time point
may be a time variable or a time constant  given a fluent f of arity n      we refer
to f  s            sn    x  and f  s            sn    x   where each si is a constant and x is a time
variable or a time constant as  timed  fluent literals     given a fluent literal    we denote by  
   the role of the dialogue identifier will become clearer in section     intuitively  this is used to link
communication actions occurring within the same dialogue 
   note that  represents classical negation  negation as failure occurs in the model only within the
knowledge bases of agents  supporting the reasoning capabilities and the cycle theory  all other negations
in the state are to be understood as classical negations 

   

fikakas  mancarella  sadri  stathis   toni

its complement  namely f  s            sn    x  if   is f  s            sn    x   and f  s            sn    x  if
  is f  s            sn    x   examples of fluent literals are have resource pen      representing
that a certain resource pen should be obtained at some time    as well as  the ground 
on box  table       representing that at time     a certain  box should not be on  a certain 
table 
note that we assume that fluent literals are ground except for the time parameter  this
will allow us to keep the notation simpler and to highlight the crucial role played by the
time parameter  given this simplification  we will often denote timed fluent literals simply
by   x  
given an action operator a of arity n      we refer to a s            sn    x   where each si
is a constant and x is a time variable or time constant  as a  timed  action literal  similarly
to the case of fluent literals  for simplicity  we will assume that timed action literals are
ground except possibly for the time  hence  we will often denote timed action literals by
a x  
we will adopt a special syntax for sensing actions  that will always have the form  x is
either a time variable or a time constant  
 sense f  x   where f is a fluent  or
 sense c   a  x   where c is the name of an agent and a is an action operator 
in the first case  the sensing action allows the agent to inspect the external environment in
order to check whether or not the fluent f holds at the time x of sensing  in the second
case  the sensing action allows the agent to determine whether  at time x  another agent c
has performed some action a 
we will now define formally the concept of state hkb    f  c  i of an agent 
    forest  f
each node in each tree in f is 
 either a non executable goal  namely a  non ground  timed fluent literal 
 or an executable goal  namely a  non ground  timed action literal 
an example of a tree in f is given in figure    where p  is some given problem that
the agent  c    needs to fix by getting two resources r  and r    and where the agent has
already decided to get r  from some other agent c  and has already planned to ask c  by
the communication action tell c    c    request r     d       for example  in the san vincenzo
scenario  p  may be transfer to airport needs to be arranged  r  may be a taxi  and c 
a taxi company  needed for transportation to some train station  and finally r  may be a
train ticket 
note that the time variable  in non executable goals      and actions a    in  any tree
in  f is to be understood as a variable that is existentially quantified within the whole state
of the agent  whenever a goal or action is introduced within a state  its time variable is to
be understood as a distinguished  fresh variable  also serving as its identifier 
   

ficomputational logic foundations of kgp agents

problem f ixed p      





ppp

pp


p

pp
pp

have resource r       

have resource r       

tell c    c    request r     d     

figure    an example tree in f
as indicated in section    roots of trees are referred to as top level goals  executable
goals are often called simply actions  non executable goals may be top level goals or subgoals  for example  in figure    the node with identifier   is a top level goal  the nodes
with identifiers       are sub goals and the node with identifier   is an action 
notation     given a forest f and a tree t  f 
 for any node n of t   parent n  t    children n  t    ancestors n  t    siblings n  t   
descendents n  t    will indicate the parent of node n in t   the children of n in t  
etc  and leaf  n  t   will have value true if n is a leaf in t   false otherwise 
 for any node n of f  parent n  f   children n  f   ancestors n  f   siblings n  f  
descendents n  f   leaf  n  f  will indicate the parent n  t   for the tree t in f where
n occurs  etc   t is unique  due to the uniqueness of the time variable identifying
nodes  
 nodes t   will represent the set of nodes in t   and nodes f  will represent the set
s
nodes f    t f nodes t   
again  as indicated in section    each top level goal in each tree in f will be either
reactive or non reactive  we will see  in section    that reactive top level goals are introduced into the state by the re transition whereas non reactive top level goals are introduced by the gi transition  for example  f of agent c  may consist of the tree in
figure    with root a non reactive goal  as well as a tree with root the reactive goal  action 
   

fikakas  mancarella  sadri  stathis   toni

tell c    c    accept request r     d         this action may be the reply  planned by agent c   
to some request for resource r  by agent c   for example  in the san vincenzo scenario  r 
may be a meeting requested by some colleague  
notation     given a forest f
 rootsr  f   resp  rootsnr  f   will denote the set of all reactive  resp  non reactive 
top level goals in f
 nodesr  f   resp  nodesnr  f   will denote the subset of nodes f  consisting of nodes
in all trees whose root is in rootsr  f   resp  rootsnr  f  
 r f   resp  nr f   stands for the reactive  resp  non reactive  part of f  namely the
set of all trees in f whose root is in rootsr  f   resp  rootsnr  f   
trivially  r f  and nr f  are disjoint  and f  r f   nr f  
    temporal constraint store  c
this is a set of constraint atoms  referred to as temporal constraints  in the given underlying
constraint language  temporal constraints refer to time constants as well as to time variables
associated with goals  currently or previously  in the state 
for example  given a forest with the tree in figure    c may contain               
indicating that the top level goal  of fixing problem p   needs to be achieved within the time
interval                           indicating that resources r  and r  need to be acquired
before the top level goal can be deemed to be achieved  and         indicating that the
agent needs to ask agent c  first  note that we do not need to impose that   and   are
executed in some order  namely c may contain neither         nor        
    agents dynamic knowledge base  kb 
kb  is a set of logic programming facts in the state of an agent  recording the actions which
have been executed  by the agent or by others  and their time of execution  as well as the
properties  i e  fluents and their negation  which have been observed and the time of the
observation  formally  these facts are of the following forms 
 executed a  t  where a t  is a ground action literal  meaning that action a has been
executed by the agent at time t 
 observed    t  where   t  is a ground fluent literal  meaning that   has been observed
to hold at time t 
 observed c  a t     t  where c is an agents name  different from the name of the agent
whose state we are defining  t and t  are time constants  and a t    is a  ground  action
literal  this means that the given agent has observed at time t that agent c has
executed the action a at time t     
   we will see that  by construction  it will always be the case that t   t  note that the time of executed
actions  t    and the time of their observation  t  will typically be different in any concrete implementation
of the kgp model  as they depend  for example  on the time of execution of transitions within the
operational trace of an agent 

   

ficomputational logic foundations of kgp agents

note that all facts in kb  are variable free  as no time variables occur in them  facts
of the first kind record actions that have been executed by the agent itself  facts of the
second kind record observations made by the agent in the environment  excluding actions
executed by other agents  which are represented instead as facts of the third kind 
for example  if the action labelled by   in figure   is executed  by the ae transition 
at time   then executed tell c    c    request r     d      will be added to kb    moreover  if 
at time    c  observes  e g  by transition poi  that it has resource r    then the observation
observed have resource r        will be added to kb    finally  kb  may contain
observed c    tell c    c    request r     d          
to represent that agent c  has become aware  at time    that agent c  has requested  at the
earlier time    resource r  from c   
    instantiation of time variables  
when a time variable  occurring in some non executable goal      or some action a    in f
is instantiated to a time constant t  e g  at action execution time   the actual instantiation
   t is recorded in the  component of the state of the agent  for example  if the action
labelled by   in figure   is executed at time    then       will be added to  
the use of  allows one to record the instantiation of time variables while at the same
time keeping different goals with the same fluent distinguished  clearly  for each time
variable  there exists at most one equality    t in  
notation     given a time variable    we denote by     the time constant t  if any  such
that    t   
it is worth pointing out that the valuation of any temporal constraint c  c will always
take the equalities in  into account  namely  any ground valuation for the temporal
variables in c must agree with  on the temporal variables assigned to them in   for
example  given           and c            then        is a suitable valuation 
whereas       is not 

   reasoning capabilities
in this section  we give detailed specifications for the various reasoning capabilities  specified within the framework of ordinary logic programming  for temporal reasoning and
identification of preconditions and effects   of abductive logic programming with constraints  section      for planning and reactivity   of logic programming with priorities
with constraints  section      for goal decision   of constraint programming  section     
for constraint solving  
the reasoning capabilities are defined by means of a notion of entailment with respect
to an appropriate knowledge base  and a time point now  where appropriate   as follows 
   

fikakas  mancarella  sadri  stathis   toni

   t r and kbt r for temporal reasoning  where kbt r is a constraint logic program
and a variant of the framework of the event calculus  ec  for reasoning about actions 
events and changes  kowalski   sergot           
   now
plan and kbplan for planning  where kbplan is an abductive logic program with
constraints  extending kbt r  
   now
react and kbreact for reactivity  where kbreact is an extension of kbplan   incorporating additional integrity constraints representing reactive rules 
   pre and kbpre   where kbpre is a logic program contained in kbt r  
   ef f and kbef f   where kbef f is a logic program contained in kbt r  
   now
gd and kbgd   where kbgd is a logic program with priorities and constraints 
the constraint solving capability is defined in terms of an entailment   cs which is
basically     as defined in section     
    temporal reasoning  planning  reactivity  identification of preconditions
and effects  ec based capabilities
these reasoning capabilities are all specified within the framework of the event calculus
 ec  for reasoning about actions  events and changes  kowalski   sergot         below 
we first give the core ec and then show how to use it to define the various capabilities in
this section 
      preliminaries  core event calculus
in a nutshell  the ec allows one to write meta logic programs which talk about objectlevel concepts of fluents  events  that we interpret as action operators      and time points 
the main meta predicates of the formalism are 
 holds at f  t     a fluent f holds at a time t  
 clipped t    f  t      a fluent f is clipped  from holding to not holding  between times
t  and t   
 declipped t    f  t      a fluent f is declipped  from not holding to holding  between
times t  and t   
 initially f     a fluent f holds at the initial time  say time   
 happens o  t     an operation o happens at a time t  
 initiates o  t  f     a fluent f starts to hold after an operation o at time t  
   a more sophisticated  abductive logic programming version of   t r and kbt r is given by bracciali and
kakas        
   in this section we use the original event calculus terminology of events instead of operators  as in the
rest of the paper 

   

ficomputational logic foundations of kgp agents

 terminates o  t  f     a fluent f ceases to hold after an operation o at time t  
roughly speaking  the last two predicates represent the cause effects links between operations and fluents in the modelled world  we will also use a meta predicate
 precondition o  f     the fluent f is one of the preconditions for the executability of
the operation o 
fluent literals in an agents state are mapped onto the ec as follows  the ec like representation of a fluent literal f      resp  f      in an agents state is the atom holds at f    
 resp  holds at f       moreover  when arguments other than the time variable need to be
considered  the ec representation of a fluent literal f  x            xn       resp  f  x            xn      
is holds at f  x            xn        resp  holds at f  x            xn         
similarly  action literals in the state of an agent can be represented in the ec in a
straightforward way  given an action literal a    its ec representation is happens a     
when arguments other than time are considered  as e g  in a x            xn       the ec representation is given by happens a x          xn       
in the remainder of the paper  with an abuse of terminology  we will sometimes refer
to f  x            xn   and f  x            xn   interchangeably as fluent literals or fluents  although
strictly speaking they are fluent literals   and to a x          xn   interchangeably as action
literals or action operators  although strictly speaking they are action literals  
the ec allows one to represent a wide variety of phenomena  including operations with
indirect effects  non deterministic operations  and concurrent operations  shanahan        
the core ec we use in this paper consists of two parts  domain independent rules and
domain dependent rules  the basic domain independent rules  directly borrowed from the
original ec  are 
holds at f  t    
holds at f  t    
holds at f  t   
holds at f  t   
clipped t    f  t    
declipped t    f  t    

happens o  t     initiates o  t    f   
t    t    not clipped t    f  t   
happens o  t     terminates o  t    f   
t    t    not declipped t    f  t   
initially f       t  not clipped    f  t  
initially f       t  not declipped    f  t  
happens o  t    terminates o  t  f    t   t   t 
happens o  t    initiates o  t  f    t   t   t 

the domain dependent rules define initiates  terminates  and initially  e g  in the case
of setting       in section     we may have
initiates tell c  svs  inf orm q  i   d   t  have inf o svs  q  i   
holds at trustworthy c   t  
initially have inf o svs  arrival tr     i 
   note that we write holds at f  x            xn       instead of not holds at f  x            xn        as done e g  by
shanahan        because we want to reason at the object level about properties being true or false in the
environment  we use not within the meta level axioms of the event calculus  see below  to implement
persistence 

   

fikakas  mancarella  sadri  stathis   toni

initially trustworthy co  
namely  an action by agent c of providing information i concerning a query q to the
agent svs  the san vincenzo station agent  initiates the agent svs having the information
about q  provided that c is trustworthy  moreover  initially agent co  the central office
agent  is trustworthy  and agent svs has no information about the arrival time of tr    the
conditions for the rule defining initiates can be seen as preconditions for the effects of the
operator tell to take place  preconditions for the executability of operators are specified by
means of a set of rules  facts  defining the predicate precondition  e g 
precondition tell svs  c  inf orm q  i   d   have inf o svs  q  i  
namely the precondition for agent svs to inform any agent c of i about q is that svs indeed
has information i about q 
notice that the presence in the language of fluents and their negation  e g  f and f  
poses the problem of inconsistencies  i e  it may be the case that both holds at f  t  and
holds at f  t  can be derived from the above axioms and a set of events  i e  a given set
of happens atoms   however  it can easily be shown that this is never the case  provided
that the domain dependent part does not contain two conflicting statements of the form
initially f   and initially f   since inconsistencies cannot be caused except at the initial
time point  see e g  miller   shanahan        p       
in the remainder of the paper we will assume that the domain dependent part is always
consistent for our agents 
to allow agents to draw conclusions from the contents of kb    which represents the
narrative part of the agents knowledge  we add to the domain independent rules the
following bridge rules 
holds at f  t    
holds at f  t    
happens o  t   
happens o  t   

observed f  t     t   t    not clipped t    f  t   
observed f  t     t   t    not declipped t    f  t   
executed o  t  
observed    o t     

notice that these bridge rules make explicit the translation from the state representation
to the ec representation of fluents and actions we have mentioned earlier on in this section 
note also that we assume that a fluent holds from the time it is observed to hold  this
choice is dictated by the rationale that observations can only be considered and reasoned
upon from the moment the agent makes them  on the other hand  actions by other agents
have effect from the time they have been executed    
having introduced the ability to reason with narratives of events and observations  we
need to face the problem of inconsistency due to conflicting observations  e g  an agent
may observe that both a fluent and its negation hold at the same time  as we have done
   if the time of the action is unknown at observation time  then the last rule above may be replaced by
happens o  t    observed    o     t  
namely the value of a fluent is changed according to observations from the moment the observations
are made 

   

ficomputational logic foundations of kgp agents

above for the set of initially atoms  we will assume that the external world is consistent
too  i e  it can never happen that both observed f  t  and observed f  t  belong to kb   
for any fluent f and time point t 
however  we still need to cope with the frame consistency problem  which arises  e g 
given observations observed f  t  and observed f  t     with t    t    this issue is analogous
to the case when two different events happen at the same time point and they initiate and
terminate the same fluent  in the original ec suitable axioms for the predicates clipped
and declipped are added  as given above  to avoid both a fluent and its negation holding at
the same time after the happening of two such events at the same time  we adopt here a
similar solution to cope with observations  namely by adding the following two axioms to
the domain independent part 
clipped t    f  t    
declipped t    f  t    

observed f  t    t   t   t 
observed f  t    t   t   t 

this solution may be naive in some circumstances and more sophisticated solutions may
be adopted  as e g  the one proposed by bracciali and kakas        
      temporal reasoning
the temporal reasoning capability is invoked by other components of the kgp model
 namely the goal decision capability  the state revision transition and some of the selection operators  see section    to prove or disprove that a given  possibly temporally
constrained  fluent literal holds  with respect to a given theory kbt r   for the purposes
of this paper kbt r is an ec theory composed of the domain independent and domaindependent parts as given in section        and of the narrative part given by kb    then 
given a state s  a fluent literal      and a possibly empty set    of temporal constraints t c 
the temporal reasoning capability   t r is defined as
s   t r       t c iff kbt r   lp     holds at        t c 
for example  given the ec formulation in section       for setting       in section     
if the state s   hkb    f  c  i for agent svs contains
kb     observed co  tell co  svs  inf orm arrival tr          d            
then s   t r have inf o svs  arrival tr                   
      planning
a number of abductive variants of the ec have been proposed in the literature to deal with
planning problems  e g  the one proposed by shanahan        here  we propose a novel
variant  somewhat inspired by the e language  kakas   miller         to allow situated
agents to generate partial plans in a dynamic environment 
we will refer to kbplan   hpplan   aplan   iplan i as the abductive logic program where 
    here and in the remainder of the paper sets are seen as conjunctions  where appropriate 

   

fikakas  mancarella  sadri  stathis   toni

 aplan    assume holds  assume happens   namely we consider two abducible predicates  corresponding to assuming that a fluent holds or that an action occurs  respectively  at a certain time point 
 pplan is obtained by adding to the core ec axioms and the narrative given by kb 
the following rules
happens o  t    assume happens o  t  
holds at f  t    assume holds f  t  
 iplan contains the following set of integrity constraints
holds at f  t    holds at f  t    f alse
assume happens o  t    precondition o  p    holds at p  t  
assume happens o  t    not executed o  t    time now t      t   t  
these integrity constraints in iplan prevent the generation of  partial  plans which are
unfeasible  the first integrity constraint makes sure that no plan is generated which entails
that a fluent and its negation hold at the same time  the second integrity constraint makes
sure that  if a plan requires an action to occur at a certain time point  the further goal of
enforcing the preconditions of that action to hold at that time point is taken into account
in the same plan  this means that  if those preconditions are not already known to hold 
the plan will need to accommodate actions to guarantee that they will hold at the time of
execution of the action  finally  the last integrity constraint forces all assumed unexecuted
actions in a plan to be executable in the future  where the predicate time now    is meant
to return the current time 
it is worth recalling that  in concrete situations  pplan and iplan will also contain domaindependent rules and constraints  domain dependent rules may be needed not only to define
initiates  terminates  initially and precondition  but they may also contain additional
rules integrity constraints expressing ramifications  e g 
holds at f  t    holds at f    t           holds at fn   t  
for some specific fluents in the domain  moreover  integrity constraints may represent
specific properties of actions and fluents in the domain  as an example  a domain dependent
constraint could express that two actions of some type cannot be executed at the same time 
e g 
holds at tell c  x  accept request r   d   t   
holds at tell c  x  ref use request r   d   t    f alse
intuitively  constructing a  partial  plan for a goal  that is a given leaf node in the
current forest  amounts to identifying actions and further sub goals allowing to achieve the
goal  while assuming that all other nodes in the forest  both executable and non executable 
are feasible  concretely  the abductive logic program kbplan supports partial planning as
follows  whenever a plan for a given goal requires the agent to execute an action  a    say 
the corresponding atom assume happens a     is assumed  which amounts to intending
to execute the action  at some concrete time instantiating     on the other hand  if a
plan for a given goal requires to plan for a sub goal       say  the corresponding atom
assume holds       may be assumed  which amounts to setting the requirement that further
planning will be needed for the sub goal itself  notice that if only total plans are taken into
account  no atoms of the form assume holds      will ever be generated 
   

ficomputational logic foundations of kgp agents

now be kb
formally  let kbplan
plan   time now now    where now is a time constant  intuitively  the time when the planning capability is invoked   then  the planning capability
    
  now
plan is specified as follows

let s   hkb    f  c  i be a state  and g        be a mental goal labeling a leaf node
in a tree t of f  let also
ca    assume happens a         a       nodes f   
cg    assume holds                       nodes f           
and
     ca  cg
 c    c   
then 
s  g   now
plan  xs   t c 
iff
xs    a        assume happens a                       assume holds             
now      c    if
for some    t c  which is an abductive answer for holds at        wrt  kbplan
 
 
no such abductive answer exists  then s  g   now
 
where

is
used
here
to
indicate
failure
plan
 i e  that no such abductive answer exists  

as an example  consider setting       in section      the domain dependent part of
kbplan for agent psa  looking after the businessman in our scenario  contains
initiates buy ticket online f rom  t o   t  have ticket f rom  t o  
precondition buy ticket online f rom  t o   available connection 
precondition buy ticket online f rom  t o   available destination t o  
the goal g is have ticket madrid  denver      assume f only consists of a single tree
consisting solely of the root g  thus ca   cg       then  s  g   now
plan  xs   t c  where
xs    buy ticket online madrid  denver       
available connection        available destination denver         
and t c                                  now  
      reactivity
this capability supports the reasoning of reacting to stimuli from the external environment
as well as to decisions taken while planning 
as knowledge base kbreact supporting reactivity we adopt an extension of the knowledge
base kbplan as follows  kbreact   hpreact   areact   ireact i where
 preact   pplan
    for simplicity we present the case of planning for single goals only 

   

fikakas  mancarella  sadri  stathis   toni

 areact   aplan
 ireact   iplan  rr
where rr is a set of reactive constraints  of the form
body  reaction  t c
where
 reaction is either assume holds    t      t   being a timed fluent literal  or
assume happens a  t    a t   being a timed action literal     and
 body is a non empty conjunction of items of the form  where   x  is a timed fluent
literal and a x  is a timed action literal  for any x  
 i  observed    t     
 ii  observed c  a t      t      
 iii  executed a  t     
 iv  holds at    t     
 v  assume holds    t     
 vi  happens a  t     
 vii  assume happens a  t     
 viii  temporal constraints on  some of  t  t     t   
which contains at least one item from one of  i    ii  or  iii  
 t c are temporal constraints on  some of  t  t     t     
as for integrity constraints in abductive logic programming  all variables in body are
implicitly universally quantified over the whole reactive constraint  and all variables in
reaction  t c not occurring in body are implicitly existentially quantified on the righthand
side of the reactive constraint    
notice that body must contain at least a trigger  i e  a condition to be evaluated
in kb    intuitively  a reactive constraint body  reaction  t c is to be interpreted as
follows  if  some instantiation of  all the observations in body hold in kb  and  some
corresponding instantiation of  all the remaining conditions in body hold  then  the appropriate instantiation of  reaction  with associated  the appropriate instantiation of  the
    here and below  with an abuse of notation  we use the notions of timed fluent and action literals liberally
and allow them to be non ground  even though we have defined timed fluent and action literals as ground
except possibly for the time parameter 
    strictly speaking  syntactically reactive constraints are not integrity constraints  due to the presence of a
conjunction  represented by    rather than a disjunction in the head   however  any reactive constraint
body  reaction  t c can be transformed into an integrity constraint body  n ew with a new clause
n ew  reaction  t c in preact   thus  with an abuse of notation  we treat reactive constraints as
integrity constraints 

   

ficomputational logic foundations of kgp agents

temporal constraints t c  should be added to f and c  respectively  notice that reaction
is an abducible so that no planning is performed by the reactivity capability 
now be the theory kb
formally  let kbreact
react   time now now    where now is a time
constant  intuitively  the time when the capability is invoked   then  the reactivity capability   now
react is specified as follows  let s   hkb    f  c  i be a state  let

ca    assume happens a       a     nodesnr  f   
cg    assume holds               nodesnr  f  
and
     ca  cg
 c    c   
then 
s   now
react  xs   t c 
iff
xs    a      assume happens a                 assume holds         
now      c    if
for some    t c  which is an abductive answer for the query true wrt  kbreact
 
 
now
no such abductive answer exists  then s   react   where  is used here to indicate failure
 i e  that no such abductive answer exists  

as an example  consider setting       in section      and kbplan as given in sections      
and        let rr of agent svs consist of 
observed c  tell c  svs  request q   d  t     t    holds at have inf o svs  q  i   t  
 assume happens tell svs  c  inf orm q  i   d   t      t     t
observed c  tell c  svs  request q   d  t     t    holds at no inf o svs  q   t  
 assume happens tell svs  c  ref use q   d   t      t     t
then  given now      and s   hkb    f  c  i with
kb     observed co  tell co  svs  inf orm arrival tr          d            
observed psa  tell psa  svs  request arrival tr      d            
we obtain
s   now
react   tell svs  psa  inf orm arrival tr          d               
      identification of preconditions
this capability is used by kgp agents to determine the preconditions for the executability
of actions which are planned for  these preconditions are defined in the domain dependent
part of the ec by means of a set of rules of the form precondition o  f    representing that
the fluent f is a precondition for the executability of an action with action operator o  see
        let kbpre be the subset of kbt r containing the rules defining precondition      
   

fikakas  mancarella  sadri  stathis   toni

then the identification of preconditions capability   pre is specified as follows  given a state
s   hkb    f  c  i and a timed action literal a   
s  a      pre cs
iff
cs  

v

        kbpre   lp precondition a         

      identification of effects
this capability is used by kgp agents to determine the effects of actions that have already
been executed  in order to check whether these actions have been successful  note that
actions may have been unsuccessful because they could not be executed  or were executed
but they did not have the expected effect  both are possible in situations where the agent
does not have full knowledge about the environment in which it is situated 
these effects are defined in the domain dependent part of the ec by means of the set of
rules defining the predicates initiates and terminates  let kbef f be the theory consisting
of the domain dependent and domain independent parts of the ec  as well as the narrative
part kb    then  the identification of effects   ef f is specified as follows  given a state
s   hkb    f  c  i and an action operator a t  
s  a t    ef f  
iff
     f and kbef f   lp initiates a  t  f  
     f and kbef f   lp terminates a  t  f  
    constraint solving
the constraint solving capability can be simply defined in terms of the structure   and
the     notion presented in section      namely  given a state s   hkb    f  c  i and a
set of constraints t c 
 s   cs t c iff     c    t c 
 there exists a total valuation  such that s     cs t c iff there exists a total valuation
 such that      c    t c 
    goal decision
the goal decision reasoning capability allows the agent to decide  at a given time point 
the  non reactive  top level goals to be pursued  for which it will then go on to generate
plans aiming at achieving them  the generated goals are the goals of current preferred
interest but this interest may change over time 
    we assume that

v

     true 

   

ficomputational logic foundations of kgp agents

the goal decision capability operates according to a theory  kbgd   in which the agent
represents its goal preference policy  kbgd includes kbt r and thus the dynamic  observed
knowledge  kb    in the current state of the agent  kbgd is expressed in a variant of lpp
described in section      whereby the rules in the lower or basic part p of the lpp theory
t have the form  t being a possibly empty sequence of variables  
n   t     g   t    b t    c t  
where
  is a time variable  existentially quantified with scope the head of the rule and not a
member of t  
 all variables except for  are universally quantified with scope the rule 
 the head g   t   of the rule consists of a fluent literal conjoined with a  possibly
empty  set of temporal constraints  represented as h      t c   t  i 
 b t   is a non empty conjunction of literals on a set of auxiliary predicates that can
include atoms of the form holds at    t      where   t     is a timed fluent literal  and the
atom time now t      for some variables t     t     
 the conditions of the rule are constrained by the  possibly empty  temporal constraints
c t   
any such rule again represents all of its ground instances under any total valuation of
the variables in t that satisfies the constraints c t    each ground instance is named by the
corresponding ground instance of n   t    intuitively  when the conditions of one such rule
are satisfied at a time now that grounds the variable t    with the current time at which the
capability is applied  then the goal in the head of the rule is sanctioned as one of the goals
that the agent would possibly prefer to achieve at this time  the decision whether such a
goal is indeed preferred would then depend on the high level or strategy part h of kbgd  
containing priority rules  as described in section      between the rules in the lower part or
between other rules in h  these priority rules can also include temporal atoms of the form
holds at    t     and the atom time now t      in their conditions 
to accommodate this form of rules we only need to extend our notion of incompatibility
i in t to be defined on conclusions h      t c   t  i  to simplify the notation  in the
remainder we often write h      t ci instead of h      t c   t  i 
the incompatibility i can be defined in different ways  for example  a  relatively  weak
notion of incompatibility is given as follows  two pairs h         t c  i and h         t c  i are
incompatible iff for every valuation  such that t c  and t c  are both satisfied  the ground
instances of         and         are incompatible  a stronger notion would require that
it is sufficient for only one such valuation  to exist that makes the corresponding ground
literals incompatible 
now the theory kb
let us denote by kbgd
gd   time now now    where now is a time
constant  then  the goal decision capability    now
gd   is defined directly in terms of the
preference entailment    pr   of lpp  see section       as follows 
given a state s   hkb    f  c  i 
s   now
gd gs
   

fikakas  mancarella  sadri  stathis   toni

where
gs    g    g            gn    n     gi   h i  i    t ci i for all i              n
iff gs is a maximal set such that
now
kbgd
  pr h         t c  i         h n  n    t cn i 

this means that a new set of goals gs is generated that is currently  sceptically  preferred
under the goal preference policy represented in kbgd and the current information in kb   
note that any two goals in gs are necessarily compatible with each other  there are two
special cases where there are no sceptically preferred goals at the time now  the first one
concerns the case where there are no goals that are currently sanctioned by the  lower part 
of kbgd   when this is so   now
gd returns an empty set of goals  n       the second special
case occurs when there are at least two goals which are each separately credulously preferred
but these goals are incompatible which each other  then s   now
gd   where  is used to
indicate failure in identifying new goals to be pursued 
as an example  consider the san vincenzo scenario where the psa agent needs to decide whether to return home or to recharge its battery  the agents goals are categorised
and assigned priority according to their category and possibly other factors  the kbgd
expressing this is given as follows 
 the low level part contains the rules 

n rh        hreturn home           t    i 
holds at f inished work  t   
holds at at home  t   
time now t   
t    t    
n rb        hrecharge battery           t    i 
holds at low battery  t   
time now t   
t    t    
 the auxiliary part contains  in addition to kbt r and kb    the following rules that
specify the category of each goal and the relative urgency between these categories 

typeof  return home  required 
typeof  recharge battery  operational 
more urgent wrt type operational  required 

   

ficomputational logic foundations of kgp agents

 the incompatibility part consists of
incompatible return home t    recharge battery t   
namely  the two goals are pairwise incompatible  i e  the agent can only do one of
these goals at a time 
 the high level part contains the following priority rule 

gd pref  x  y     n x     n y     typeof  x  xt   
typeof  y  y t   
more urgent wrt type xt  y t   
then  for now     and current state s   hkb    f  c  i such that finished work and
away from home both hold  by temporal reasoning  at time now  we have that
s   now
gd  hreturn home             i  
suppose instead that kb  contains observed low battery      then  using the weak
notion of incompatibility  requiring that
for every  such that    cs               
it holds that incompatible return home      recharge battery     
we have 
s   now
gd  hreturn home             i  hrecharge battery             i  
indeed  for                    incompatible return home     recharge battery     does
not hold  however  using the stronger notion of incompatibility  requiring that
there exists  such that    cs               
it holds that incompatible return home      recharge battery     
we have 
s   now
gd  hrecharge battery             i  
suppose now that kbgd contains a second operational goal hreplace part             i
that is also sanctioned by a rule in its lower part at time now      then under the stronger
form of incompatibility the goal decision capability at now     will return  as both these
operational goals are credulously preferred but none of them is sceptically preferred 
   

fikakas  mancarella  sadri  stathis   toni

   physical capabilities
in addition to the reasoning capabilities we have defined so far  an agent is equipped with
physical capabilities that allow it to experience the world in which it is situated  this world
consists of other agents and or objects that provide an environment for the agents in which
to interact and communicate 
we identify two types of physical capabilities  sensing and actuating  in representing
these capabilities we abstract away from the sensors and the actuators that an agent would
typically rely upon to access and affect the environment  we will also assume that these
sensors and actuators are part of the agents body  which we classify as an implementation
issue  stathis et al         
the physical sensing capability models the way an agent interacts with its external
environment in order to inspect it  e g  to find out whether or not some fluent holds at
a given time  on the other hand  the physical actuating capability models the way an
agent interacts with its external environment in order to affect it  by physically executing
its actions 
we represent the sensing physical capability of an agent as a function of the form 
sensing l  t    l 
where 
 l is a  possibly empty  set of
 fluent literals f  
 terms of the form c   a  meaning that agent c has performed action a  
all to be sensed at a concrete time t  and
 l  is a  possibly empty  set of elements s  such that
 s  is a term f   v  f being a fluent and v   true  f alse   meaning that fluent f
has been observed to have value v  namely to be true or to be f alse  at time t 
or
 s  is a term of the form c   a t     c being an agent name and a being an action 
meaning that agent c has performed action a at time t   
note that physical sensing requires the time stamp t to specify the time at which it is
applied within transitions  note also that  given a non empty set l  sensing l  t  may be
partial  e g  for some fluent f  l  it can be that neither f   true  l    nor f   f alse  l   
similarly  we represent the physical actuating capability as a function
actuating as  t    as 
where 
 as is a set of action literals  a         an    n      that the agent instructs the body to
actuate at time t 
   

ficomputational logic foundations of kgp agents

 as   as is the subset of actions that the body has actually managed to perform 
the meaning of an action a belonging to as and not belonging to as  is that the physical
actuators of the agents body were not able to perform a in the current situation  it is worth
pointing out that if an action a belongs to as  it does not necessarily mean that the effects
of a have successfully been reached  indeed  some of the preconditions of the executed
action  i  may have been wrongly believed by the agent to be true at execution time  as
other agents may have interfered with them  or  ii  the agent may have been unaware of
these preconditions  for example  after having confirmed availability  the agent may have
booked a hotel by sending an e mail  but  i  some other agent has booked the last available
room in the meanwhile  or  ii  the agent did not provide a credit card number to secure the
booking  in other words  the beliefs of the agent  as held in kb    may be incorrect and or
incomplete 
in section   and section   below  we will see that aoi  active observation introduction 
can be used to check effects of actions  identified by the fes effect selection operator  in
turn using the   ef f reasoning capability  after actions have been executed  moreover  si
 sensing introduction  can be used to check preconditions of actions  identified by the fp s
precondition selection operator  in turn using the   pre reasoning capability  just before they
are executed  to make sure that the actions are indeed executable  overall  the following
cases may occur 
 an action belongs to as  because it was executed and
 its preconditions held at the time of execution and its effects hold in the environment after execution 
 its preconditions were wrongly believed to hold at the time of execution  because
the agent has partial knowledge of the environment or its kbplan is incorrect 
and as a consequence its effects do not hold after execution 
 its preconditions were known not to hold at the time of execution  e g  because
the agent observed only after having planned that they did not hold  but had no
time to  replan  and as a consequence its effects do not hold after execution 
 an action belongs to as   as  because it was not executed  the body could not execute
it  
the actuating physical capability does not check preconditions effects  this is left
to other capabilities called within transitions before and or after the transition invoking
actuating  as we will show below  as before  the way the body will carry out the actions
is an implementation issue  stathis et al         

   transitions
the kgp model relies upon the state transitions gi  pi  re  si  poi  aoi  ae  sr  defined
below using the following representation
 t 

hkb    f  c  i
x
now
 
 
 
 
hkb    f   c    i
   

fikakas  mancarella  sadri  stathis   toni

where t is the name of the transition  hkb    f  c  i is the agents state before the transition is applied  x is the input for the transition  now is the time of application of the
transition  hkb     f     c       i is the revised state  resulting from the application of the transition t with input x at time now in state hkb    f  c  i  please note that most transitions
only modify some of the components of the state  also  for some transitions  namely gi 
re  poi  sr  the input x is always empty and will be omitted  for the other transitions
 namely pi  si  aoi  ae  the input is always non empty  see section    and is selected by
an appropriate selection operator  see section    
below we define each transition formally  by defining hkb     f     c       i  note that we
assume that each transition takes care of possible renaming of time variables in the output
of capabilities  if a capability is used by the transition   in order to guarantee that each
goal action in the forest is univocally identified by its time variable 
    goal introduction
this transition takes empty input  it calls the goal decision capability to determine the
new  non reactive  top level goals of the agent  if this capability returns a set of goals 
this means that the circumstances have now possibly changed the preferred top level goals
of the agent and the transition will reflect this by changing the forest in the new state to
consist of one tree for each new  non reactive  goal  on the other hand  if the goal decision
capability does not return any  non reactive  goals  namely it returns   the state is left
unchanged  as  although the goals in the current state are no longer sceptically preferred
they may still be credulously preferred and  since there are no others to replace them  the
agent will carry on with its current plans to achieve them 
 gi 

hkb    f  c  i
now
hkb    f     c     i

where  given that s   hkb    f  c  i
 i  if s   now
gd   then
 f    f
 c    c
 ii  otherwise  if s   now
gd gs and gs      then
 f   is defined as follows 
 nr f        tg      hg     i  gs  where tg    is a tree consisting solely of the
root g   
 r f         
 c      t c   h   t ci  gs 
this transition drops  top level  goals that have become semantically irrelevant  due
to changed circumstances of the agent or changes in its environment   and replaces them
with new relevant goals  we will see  in section      that goals can also be dropped because
   

ficomputational logic foundations of kgp agents

of the book keeping activities of the state revision  sr  transition  but that transition can
never add to the set of goals 
note that  as gi will replace the whole forest in the old state by a new forest  it is
possible that the agent looses valuable information that it has in achieving its goals  when
one of the new preferred goals of the agent is the same as  or equivalent to  a current goal 
this effect though can be minimized by calling  in the cycle theory  the gi transition only
at certain times  e g  after the current goals have been achieved or timed out  alternatively 
the earlier formalisation of the gi transition could be modified so that  in case  ii   for all
goals in gs that already occur  modulo their temporal variables and associated temporal
constraints  as roots of  non reactive  trees in f  these trees are kept in f     a simple way
to characterise  some of  these goals is as follows  let

xs    hg     t c        i  

hg     t ci  gs 
g       rootsnr  f  and
  cs c iff   cs  c  t c            

gs     hg     t ci  

hg     t c        i  xs 

the new constraints on goals in gs  are equivalent to the old constraints in c  for example 
gs may contain
g   hhave ticket madrid  denver               i
with have ticket madrid  denver       rootsnr  f  and c            
then  g definitely belongs to gs    let
newc  

 

t c           

h  t c      ixs

case  ii  can be redefined as follows  using these definitions of xs  gs  and newc 
 ii    otherwise  if s   now
gd gs and gs      then  if it is not the case that   cs c  newc 
then f   and c   are defined as in the earlier case  ii   otherwise  if   cs c  newc  
 f   is defined as follows 
 nr f        tg      hg     i  gs   gs     f xs 
where tg    is a tree consisting solely of the root g    and
f xs  is the set of all trees in f with roots goals of the form g      such that
hg             i  xs
 r f         
 c     c   t c   h   t ci  gs   gs     newc 
note that we keep all temporal constraints in the state  prior to the application of gi 
but we force all variables of new goals that remain in the state after gi to be rewritten
using the old identifiers of the goals 
   

fikakas  mancarella  sadri  stathis   toni

    reactivity
this transition takes empty input  it calls the reactivity capability in order to determine the
new top level reactive goals in the state  if any   leaving the non reactive part unchanged 
if no new reactive goals exist  the reactive part of the new state will be empty 
hkb    f  c  i
now
hkb    f     c     i

 re 
where  given that s   hkb    f  c  i 
 i  if s   now
react   then
 f   is defined as follows 
 r f         
 nr f       nr f 
 c    c

 ii  otherwise  if s   now
react  x s  t c   then
 f   is defined as follows 
 nr f       nr f 
 r f        tx      x     x s 
where tx    is a tree consisting solely of the root x   
 c    c  t c
note that there is an asymmetry between case  ii  of gi and case  ii  of re  as gi
eliminates all reactive goals in this case  whereas re leaves all non reactive goals unchanged 
indeed  reactive goals may be due to the choice of specific non reactive goals  so when the
latter change the former need to be re evaluated  instead  non reactive goals are not affected
by newly acquired reactive goals  that are the outcome of enforcing reactive rules  
note also that in case  ii   similarly to gi  as re replaces the whole  reactive  forest
in the old state by a new  reactive  forest  it is possible that the agent loses valuable
information that it has in achieving its reactive goals  when one of the new reactive goals
is the same as  or equivalent to  a current goal  a variant of case  ii  for re  mirroring the
variant given earlier for gi and using   cs as well  can be defined to avoid this problem 
    plan introduction
this transition takes as input a non executable goal in the state  that has been selected by
the goal selection operator  see section    and produces a new state by calling the agents
planning capability  if the selected goal is a mental goal  or by simply introducing a new
sensing action  if the goal is a sensing goal 
 pi 

hkb    f  c  i
g
now
 
 
hkb    f   c   i

where g is the input goal  selected for planning in some tree t in f  and thus a leaf  see
section    and
   

ficomputational logic foundations of kgp agents

f      f    t   g is a leaf in t     n ew
c    c  t c
where n ew and t c are obtained as follows  s being hkb    f  c  i 
 i  if g is a mental goal  let s  g   now
plan p   then 
 either p    and
n ew    t   and t c      
 or p    x s  t c  and
n ew    t     where t   is obtained from t by adding each element of x s as a
child of g 
 ii  if g        is a sensing goal  and a child of a goal g  in t  
n ew    t     where t   is t with  a node labelled by  sense         as a new child of g 
 here    is a new time variable  and
t c           
 iii  if g        is a sensing goal  and the root of t  
n ew    t   t     where t   is a tree consisting solely of the root  labelled by  sense        
 here    is a new time variable  and
t c           
    sensing introduction
this transition takes as input a set of fluent literals that are preconditions of some actions
in the state and produces a new state by adding sensing actions as leaves in  appropriate 
trees in its forest component  note that  when si is invoked  these input fluent literals are
selected by the precondition selection operator  and are chosen amongst preconditions of
actions that are not already known to be true  see section    
 si 

hkb    f  c  i
sp s
now
 
 
hkb    f   c   i

with sp s a non empty set of preconditions of actions  in the form of pairs precondition 
action  in some trees in f  where  given that 
  n ew    h      a  sense        i   h      ai  sp s and    is a fresh variable 
  addsibling t   a  sa  denotes the tree obtained by adding all elements in sa as new
siblings of a to the tree t such that leaf  a  t  
then
f     f    t   leaf  a  t   and h      ai  sp s 
  addsibling t   a  sa    leaf  a  t   and
sa    sense         h      a  sense        i  n ew  
c     c           h        sense        i  n ew 
   

fikakas  mancarella  sadri  stathis   toni

basically  for each fluent literal selected by the precondition selection operator as a
precondition of an action a  a new sensing action is added as a sibling of a  and the
constraint expressing that this sensing action must be performed before a is added to the
current set of temporal constraints 
    passive observation introduction
this transition updates kb  by adding new observed facts reflecting changes in the environment  these observations are not deliberately made by the agent  rather  they are
forced upon the agent by the environment  these observations may be properties in the
form of positive or negative fluents  for example that the battery is running out  or actions
performed by other agents  for example messages addressed to the agent  
hkb    f  c  i
now
hkb     f  c  i

 poi 
where  if sensing   now    l  then
kb     kb  

 observed f  now    f   true  l  
 observed f  now    f   f alse  l  
 observed c  a t   now    c   a t   l  
    active observation introduction
this transition updates kb  by adding new facts deliberately observed by the agent  which
seeks to establish whether or not some given fluents hold at a given time  these fluents are
selected by the effect selection operator  see section    and given as input to the transition 
whereas poi is not decided by the agent  the agent is interrupted and forced an
observation by the environment   aoi is deliberate  moreover  poi may observe fluents
and actions  whereas aoi only considers fluents  that are effects of actions executed by the
agent  as we will see in section   and in section    
 aoi 

hkb    f  c  i
sf s
now
 
hkb    f  c  i

where sf s    f            fn    n      is a set of fluents selected for being actively sensed  by
the effect selection operator   and  if sensing sf s  now    l  then
kb     kb  
 observed f  now    f   true  l  
 observed f  now    f   f alse  l  
    action execution
this transition updates kb    recording the execution of actions by the agent  the actions
to be executed are selected by the action selection operator  see section    prior to the
transition  and given as input to the transition 
   

ficomputational logic foundations of kgp agents

 ae 

hkb    f  c  i
sas
now
hkb     f  c    i

where sas is a non empty set of actions selected for execution  by the action selection
operator   and
 let a be the subset of all non sensing actions in sas and s be the subset of all sensing
actions in sas 
 let sensing s     now    l    where s      f   sense f      s 
 let sensing s      now    l     where s       c   a   sense c   a      s 
 let actuating a    now    a     where a     a   a     a  
then 
kb     kb  
 executed a  now    a  a     
 observed f  now    f   true  l    
 observed f  now    f   f alse  l   
 observed c  a t   now    c   a t   l   and
 such that    cs c     t where sense c   a      s 
and
          now   a     sas  a  a     
    now   sense f      sas   f      l    
    t   c   a t   l   and  such that    cs c     t where sense c   a      s  
    state revision
the sr transition revises a state by removing all timed out goals and actions and all goals
and actions that have become obsolete because one of their ancestors is already believed to
have been achieved  we will make use of the following terminology 
notation     given a state s  a timed fluent literal       a timed fluent literal or action
operator x     and a time point now 
 achieved s        now  stands for
there exists a total valuation  such that s     cs   now and s   t r     
 timed out s  x     now  stands for
there exists no total valuation  such that s     cs    now 
   

fikakas  mancarella  sadri  stathis   toni

then  the specification of the transition is as follows 
 sr 

hkb    f  c  i
now
hkb    f     c  i

where f   is the set of all trees in f pruned so that nodes f     is the biggest subset of
nodes f  consisting of all goals actions x    in some tree t in f such that  here s  
hkb    f  c  i  
 i  timed out s  x     now   and
 ii  if x is an action operator  it is not the case that executed x  t   kb  and     t    
and
 iii  if x is a fluent literal  achieved s  x     now   and
 iv  for every y       siblings x     f 
 either y       siblings x     f     
 or y        siblings x     f     and
 if y is a fluent literal then achieved s  y       now  
 if y is an action literal then executed y  t   kb  and      t   
and
 v  if x is a sensing action operator  x      sense        then
 either there exists a       siblings x     f     such that   is a precondition of a  i e 
s  a        pre cs and         cs  and        c 
 or there exists         siblings x     f     such that   is a sensing fluent and   
    c  and
 vi  x    is a top level goal or parent x     f    p and p  nodes f     
all conditions above specify what sr keeps in the trees in the forest in the state  intuitively  these conditions may be understood in terms of what they prevent from remaining
in such trees 
 condition  i  removes timed out goals and actions 
 condition  ii  removes actions that have already been executed 
 condition  iii  removes goals that are already achieved 
 condition  iv  removes goals and actions whose siblings are already timed out and
thus deleted  by condition  i  
 condition  v  removes sensing actions for preconditions of actions that have been
deleted and for sensing goals that have been deleted 
 condition  vi  recursively removes actions and goals whose ancestors have been removed 
the following example illustrates how sr is used to provide adjustment of the agents
goals and plans in the light of newly acquired information 
   

ficomputational logic foundations of kgp agents

    setting  
the agent psa has the goal to have a museum ticket for some  state run  museum that the
businessman wants to visit  and a plan to buy the ticket  but before executing the plan psa
observes that it is the european heritage day  ehd for short   via an appropriate message
from another agent mus  representing the museum   stating that all state run museums in
europe give out free tickets to anybody walking in on that day  then  the psas goal is
already achieved and both goal and plan are deleted from its state 
let the agents initial state be hkb    f  c  i with 
         kb 
f

   t  

c                          
where t consists of a top level goal g    have ticket       with two children 
g    have money     and a    buy ticket      

  

and further assuming that kbt r contains
initiates ehd  t  have ticket  
initiates buy o   t  have o  
precondition buy o   have money  
the remaining knowledge bases do not play any useful role for the purposes of this
example  and can therefore be considered to be empty  the message from the museum
agent mus is added to kb  via poi  e g  at time    in the following form 
observed mus  ehd       
i e  at time   it is observed that at time   mus has announced that all state run museums
in europe are free on that day  then  via sr  at time   say  g    g  and a  are eliminated
from f  as g  is already achieved 

   selection operators
the kgp model relies upon selection operators 
 fgs  goal selection  used to provide input to the pi transition  
 fp s  precondition selection  used to provide input to the si transition  
 fes  effect selection  used to provide input to the aoi transition  
 fas  action selection  used to provide input to the ae transition  
    g  and a  can be reactive or not  as this does not matter for this example 

   

fikakas  mancarella  sadri  stathis   toni

selection operators are defined in terms of  some of the  capabilities  namely temporal
reasoning  identification of preconditions and effects and constraint solving  
at a high level of description  the selection operators can all be seen as returning the set
of all items from a given initial set that satisfy a certain number of conditions  for example 
given a state hkb    f  c  i  the goal selection operator returns the set of all non executable
goals in trees in f that satisfy some conditions  the precondition selection operator returns
the set of all pairs  each consisting of  i  a timed fluent literal which is a precondition of
some action in some tree in f and  ii  that action  satisfying some conditions  the effect
selection operator returns the set of all fluent literals which are effects of actions already
executed  as recorded in kb    that satisfy some conditions  the action selection operator
returns the set of all actions in trees in f that satisfy some conditions 
the selection operators are formally defined below 
    goal selection
informally  the set of conditions for the goal selection operator is as follows  given a state
s   hkb    f  c  i and a time point t  the set of goals selected by fgs is a singleton set
consisting of a non executable goal g in some tree in f such that at time t 
   g is not timed out 
   no ancestor of g is timed out 
   no child of any ancestor of g is timed out 
   neither g  nor any ancestor of g in any tree in f is already achieved 
   g is a leaf
intuitively  condition   ensures that g is not already timed out  conditions     impose
that g belongs to a still feasible plan for some top level goal in f  and condition   makes
sure that considering g is not wasteful 
note that  as already mentioned in section        for simplicity we select a single goal 
formally  given a state s   hkb    f  c  i and a time point t  let g s  t  be the set of all
non executable goals       nodes f  such that 
   timed out s        t 
   timed out s  g  t  for each g  ancestors       f  
   timed out s  x  t  for each x  nodes f  such that x is the child of some p 
ancestors       f 
   achieved s  g  t  for each g          ancestors       f 
   leaf  g  f 
then  if g s  t        
fgs  s  t     g  for some g  g s  t  
otherwise  fgs  s  t       
   

ficomputational logic foundations of kgp agents

    effect selection
informally  the set of conditions for the effect selection operator is as follows  given a state
s   hkb    f  c  i and a time point t  fes selects all fluents f such that f or f is one of
the effects of some action a    that has recently been executed 
note that such f  or f   may not occur in f but could be some other  observable 
effect of the executed action  which is not necessarily the same as the goal that the action
contributes to achieving  for example  in order to check whether an internet connection is
available  the agent may want to observe that it can access a skype network even though
it is really interested in opening a browser  as it needs a browser in order to perform a
booking online  
formally  given a state s   hkb    f  c  i and a time point now  the set of all  timed 
fluents selected by fes is the set of all  timed  fluents f     such that there is an action
operator a with
   executed a  t     kb    t       and now     t    now  where  is a sufficiently
small number  that is left as a parameter here   and
   s  a      ef f    where     f or     f  
    action selection
informally  the set of conditions for the action selection operator is as follows  given a state
s   hkb    f  c  i and a time point t  the set of all actions selected by fas is defined as
follows  let x  s  t  be the set of all actions a in trees in f such that 
   a can be executed 
   no ancestor of a is timed out 
   no child of any ancestor of a is timed out 
   no ancestor of a is already satisfied 
   no precondition of a is known to be false 
   a has not already been executed 
then fas  s  t   x  s  t  such that all actions in fas  s  t  are executable concurrently
at t 
intuitively  conditions     impose that a belongs to a still feasible plan for some toplevel goals in f  note that condition   in the definition of x  s  t  is logically redundant 
as it is also re imposed by definition of fas  s  t   however  this condition serves as a first
filter and is thus useful in practice 
formally  given a state s   hkb    f  c  i  and a time point t  the set of all actions
selected by fas is defined as follows  let x  s  t  be the set of all actions a    occurring as
leaves of some trees in f such that 
   

fikakas  mancarella  sadri  stathis   toni

   there exists a total valuation  such that s     cs    t  and
   timed out s  g  t  for each g  ancestors a     f   and
   timed out s  x  t  for each x  children g  f  and g  ancestors a     f   and
   achieved s  g  t  for each g  ancestors a     f   and
   let s  a      pre cs and cs                   n     
if n      then for no i              n there exists a total valuation  such that s     cs
   t and s   t r  i      and
   there exists no t  such that    t    and executed a  t     kb   
the formalisation of condition   allows for other instances of action a to have been
executed  then 
fas  s  t     a                am  m     x  s  t 
 where m      such that there exists a total valuation  for the variables in c such that
s     cs     t         m   t 
note that the definition of the action selection operator can be extended to take into
account a notion of urgency with respect to the temporal constraints  however  such an
extension is beyond the scope of this work 
    precondition selection
informally  the set of conditions for the precondition selection operator is as follows  given
a state s   hkb    f  c  i and a time point t  the set of preconditions  of actions in
f  selected by fp s is the set of all pairs hc  ai of  timed  preconditions c and actions
a  nodes f  such that 
   c is a precondition of a and
   c is not known to be true in s at t  and
   a is one of the actions that could be selected for execution if fas would be called at
the current time 
the reason why this selection operator returns pairs  rather then simply preconditions 
is that the transition si  which makes use of the outputs of this selection operator  needs to
know the actions associated with the preconditions  this is because si introduces sensing
actions for each precondition returned and has to place these sensing actions as siblings of
the associated actions in f  as seen in section     
formally  given a state s   hkb    f  c  i and a time point t  the set of all preconditions
of actions selected by fp s is the set of all pairs hc  ai of  timed  preconditions c and actions
a  nodes f  such that 
   a   a     and s  a      pre cs and c is a conjunct in cs  and
   

ficomputational logic foundations of kgp agents

   there exists no total valuation  for the variables in c such that s     cs    t and
s   t r c  and
   a  x  s  t   where x  s  t  is as defined in section     

   cycle theory
the behaviour of kgp agents results from the application of transitions in sequences 
repeatedly changing the state of the agent  these sequences are not fixed a priori  as
in conventional agent architectures  but are determined dynamically by reasoning with
declarative cycle theories  giving a form of flexible control  cycle theories are given in the
framework of logic programming with priorities  lpp  as discussed in section   
    formalisation of cycle theories 
here we use the following new notations 
 t  s  x  s     t  to represent the application of transition t at time t in state s given
input x and resulting in state s     and
 t  s  x  to represent that transition t can potentially be chosen as the next transition
in state s  with input x 
recall that  for some of the transitions  x may be the empty set     as indicated in section   
formally  a cycle theory tcycle consists of the following parts 
 an initial part tinitial   that determines the possible transitions that the agent could
perform when it starts to operate  concretely  tinitial consists of rules of the form
t  s    x   c s    x 
which we refer to via the name r  t  s    x   these rules sanction that  if conditions
c hold in the initial state s  then the initial transition could be t   applied to state
s  and input x  for example  the rule
r  gi  s          gi s         empty f orest s   
sanctions that the initial transition should be gi  if the forest in the initial state s 
is empty 
note that c s    x  may be empty  and  if non empty  c s    x  may refer to the
current time via a condition time now t   for example  the rule
r  p i  s    g    p i s    g   gs   fgs  s    t   gs        g  gs  time now t 
sanctions that the initial transition should be pi  if the forest in the initial state s 
contains some goal that can be planned for at the current time  in that the goal
selection operator picks that goal  
 a basic part tbasic that determines the possible transitions following given transitions 
and consists of rules of the form
t    s     x      t  s  x  s     t   ec s     x    
   

fikakas  mancarella  sadri  stathis   toni

which we refer to via the name rt  t    s     x      these rules sanction that  after transition t has been executed  starting at time t in the state s and resulting in state s    
and the conditions ec evaluated in s   are satisfied  then transition t   could be the
next transition to be applied in s     with input x       ec are enabling conditions as
they determine when t   can be applied after t   they also determine input x   for t    
via calls to selection operators  as for the initial part of tcycle   ec may be empty
and  if not  may refer to the current time  for example  the rule
rae p i  s     g    p i s     g   ae s  as  s     t  
gs   fgs  s     t     gs        g  gs  time now t   
sanctions that pi should follow ae if at the current time there is some goal in the
current state that is selected by the goal selection function 
 a behaviour part tbehaviour that contains rules describing dynamic priorities amongst
rules in tbasic and tinitial   rules in tbehaviour are of the form
rt  t    s  x      rt  t     s  x       bc s  x     x     
with t      t      which we will refer to via the name ptt  t      recall that rt  t      and
rt  t       are  names of  rules in tbasic  tinitial   note that  with an abuse of notation 
t could be   in the case that one such rule is used to specify a priority over the first
transition to take place  in other words  when the priority is over rules in tinitial  
these rules in tbehaviour sanction that  after transition t   if the conditions bc hold 
then we prefer the next transition to be t   over t      the conditions bc are behaviour
conditions as they give the behavioural profile of the agent  for example  the rule
t
pgit
    rt  gi  s       rt  t    s  x   empty f orest s 

sanctions that gi should be preferred to any other transition after any transition that
results into a state with an empty forest  as for the other components of tcycle   the
conditions bc may refer to the current time 
 an auxiliary part including definitions for any predicates occurring in the enabling
and behaviour conditions 
 an incompatibility part  in effect expressing that only one  instance of a  transition
can be chosen at any one time 
hence  tcycle is an lpp theory where   i  p   tinitial  tbasic   and  ii  h   tbehaviour  
    operational trace
the cycle theory tcycle of an agent is responsible for its behaviour  in that it induces an
operational trace of the agent  namely a  typically infinite  sequence of transitions
t   s    x    s    t             ti  si    xi   si   ti    ti    si   xi     si     ti           
such that
    note that in order to determine that t   is a possible transition after t   with a rule of the earlier form 
one only needs to know that t has been applied and resulted into the state s     this is conveyed by the
choice of name  rt  t    s     x      in other words  by using a prolog notation  we could have represented
the rule as t    s     x      t       s        ec s     x      thus  the rule is markovian 

   

ficomputational logic foundations of kgp agents

 s  is the given initial state 
 for each i     ti is given by the clock of the system  ti   ti i   
  tcycle  tbasic     time now t       pr t   s    x    
 for each i   
 tcycle  tinitial     ti  si    xi   si   ti    time now ti        pr ti    si   xi    
namely each  non final  transition in a sequence is followed by the most preferred transition 
as specified by tcycle   if  at some stage  the most preferred transition determined by   pr is
not unique  we choose one arbitrarily 
    normal cycle theory
the normal cycle theory is a concrete example of cycle theory  specifying a pattern of
operation where the agent prefers to follow a sequence of transitions that allows it to achieve
its goals in a way that matches an expected normal behaviour  other examples of possible
cycle theories can be found in the literature  kakas  mancarella  sadri  stathis    toni 
      sadri   toni        
basically  the normal agent first introduces goals  if it has none to start with  via gi 
then reacts to them  via re  and then repeats the process of planning for them  via pi 
executing  part of  the chosen plans  via ae  revising its state  via sr  until all goals are
dealt with  successfully or revised away   at this point the agent returns to introducing
new goals via gi and repeating the above process  whenever in this process the agent
is interrupted via a passive observation  via poi  it chooses to introduce new goals via
gi  to take into account any changes in the environment  whenever it has actions which
are unreliable  in the sense that their preconditions definitely need to be checked  the
agent senses them  via si  before executing the action  whenever it has actions which are
unreliable  in the sense that their effects definitely need to be checked  the agent actively
introduces actions that aim at sensing these effects  via aoi  after having executed the
original actions  if initially the agent is equipped with some goals  then it would plan for
them straightaway by pi 
the full definition of the normal cycle theory is given in the appendix  this is used to
provide the control in the examples of the next section  here  note that  although the normal
cycle theory is based on the classic observe plan act cycle of agent control  it generalises
this in several ways giving more flexibility on the agent behaviour to adapt to a changing
environment  for example  the goals of the agent need not be fixed but can be dynamically
changed depending on newly acquired information  let us illustrates this feature with a
brief example here  suppose that the current state of our agent contains the top level nonreactive goal hreturn home             i and that a poi occurs which adds an observation
observed low battery     at time    a subsequent gi transition generated by the normal
cycle theory introduces a new goal hrecharge battery             i which  depending on
the details of kbgd   either replaces the previous goal or adds this as an additional goal 
the normal cycle theory will next choose to do a pi transition for the new and more urgent
goal of recharging its battery 
   

fikakas  mancarella  sadri  stathis   toni

    examples
in this section we revisit the examples introduced in section     and used throughout the
paper to illustrate the various components of the kgp model  overall  the aim here is
to illustrate the interplay of the transitions  and how this interplay provides the variety of
behaviours afforded by the kgp model  including reaction to observations  generation and
execution of conditional plans  and dynamic adjustment of goals and plans 
unless specified differently  we will assume that tcycle will be the normal cycle theory
presented in section      we will provide any domain dependent definition in the auxiliary
part of tcycle explicitly  where required 
     setting   formalised
we formalise here the initial state  knowledge bases and behaviour of svs for setting  
described in section       
       initial state
for simplicity  the observations  goals and the plan of svs can be assumed to be empty
initially  more concretely let the  initial  state of svs be
kb       
f

    

c     
     

       knowledge bases
following section        we formulate the reactivity knowledge base for agent svs in terms
of the utterances query ref  ref use  inf orm inspired by the fipa specifications for communicative acts  fipa      a      b   however  although we use the same names of
communicative acts as in the fipa specification  we do not adopt here their mentalistic
svs is formulated
semantic interpretation in terms of pre  and post conditions  thus  kbreact
as 
observed c  tell c  svs  query ref  q   d  t     t    holds at have inf o q  i   t  
 assume happens tell svs  c  inf orm q  i   d   t      t     t
observed c  tell c  svs  query ref  q   d  t     t    holds at no inf o q   t  
 assume happens tell svs  c  ref use q   d   t      t     t
assume happens tell svs  c  inf orm q  i   d   t   
assume happens tell svs  c  ref use q   d   t    
 f alse
assume happens a  t    not executable a   f alse
executable tell svs  c  s  d    c    svs
   

ficomputational logic foundations of kgp agents

initially no inf o arrival tr    
precondition tell svs  c  inf orm q  i   d   have inf o q  i  
initiates tell c  svs  inf orm q  i   d   t  have inf o q  i  
terminates tell c  svs  inf orm q  i   d   t  no inf o q  
       behaviour
to illustrate the behaviour of the psa we will assume that this agent requests from svs  at
time    say  the arrival time of tr    svs receives a request from psa at time   for the arrival
time of tr    via poi at time   svs records in its kb   
observed psa  tell psa  svs  query ref  arrival tr      d        
where d is the dialogue identifier  then  via re  at time    say  svs modifies its state by
adding to f a tree t rooted at an action a  to answer to psa  this action a  is a refusal
represented as 
a    tell svs  psa  ref use arrival tr      d     
and the temporal constraint      is added to c 
the refusal action is generated via the reactivity capability because svs does not have
information about the requested arrival time  svs executes the planned action a  at time
    say  via the ae transition  instantiating its execution time  adding the following record
to kb   
executed tell svs  psa  ref use arrival tr      d       
and updating  by adding       to it 
suppose then that svs makes two observations as follows  at time    svs receives
information of the arrival time      of the tr   train from co  via poi  svs records in its
kb      
observed co  tell co  svs  inf orm arrival tr          d             
assume further that at time    svs receives another request from psa about the arrival
time of tr   and  via poi  svs records in its kb   
observed psa  tell psa  svs  query ref  arrival tr      d             
with a new dialogue identifier d     this leads to a different answer from svs to the query of
psa  svs adds an action to its state to answer psa with the arrival time  this is done again
via re  say at time     a new tree is added in f rooted at the  reactive  action
tell svs  psa  inf orm arrival tr          d          
and the new temporal constraint         is added to c 
via ae  svs executes the action  instantiating its execution time to     say  and adding
the following record
    d  is the identifier of the dialogue within which this utterance has been performed  and would typically
be different from the earlier d 

   

fikakas  mancarella  sadri  stathis   toni

executed tell svs  psa  inf orm arrival tr          d         
to kb    and adding         to  
eventually  sr will clear the planned  and executed  actions from the f component of
the state of svs 
     setting   formalised
we formalise here the initial state  knowledge bases and behaviour of psa for setting  
described in section       
       initial state
let us assume that initially the state of psa is as follows 
kb       
f

   t    t   

c                   
     
where t  and t  consist of a goals  respectively  
g    have ticket madrid  denver      and
g    have visa usa      
       knowledge bases
psa
to plan for goal g    the kbplan
contains 

initiates buy ticket online f rom  t o   t  have ticket f rom  t o  
precondition buy ticket online f rom  t o   available connection 
precondition buy ticket online f rom  t o   available destination t o   
psa
to plan for goal g    the kbplan
contains 

initiates apply visa usa   t  have visa usa  
precondition apply visa usa   have address usa  
initiates book hotel l   t  have address usa    holds in l  usa   t   
       behaviour
when pi is called on the above state  at time    say  it generates a partial plan for the goal 
changing the state as follows  the goal g  acquires three children in t    these are 
g     available connection      
g     available destination denver       
a     buy ticket online madrid  denver       
also  consequently  the set of temporal constraints is updated to 
c                                                        
   

ficomputational logic foundations of kgp agents

the action a   is generated as an action that initiates goal g    moreover  every plan that
is generated must satisfy the integrity constraints in kbplan   in particular  any precondition
of actions in the tree that do not already hold must be generated as sub goals in the tree 
this is why g   and g   are generated in the tree as above 
now via the transition si  the following sensing actions are added to t  as siblings of
action a       
a     sense available connection      
a     sense available destination denver       
and the constraints
                 
are added to c 
then  via ae  these two sensing actions are executed  before the original action a    
and kb  is updated with the result of the sensing as follows  suppose these two actions are
executed at time    consider the first action that senses the fluent available connection  if
this fluent is confirmed by the physical sensing capability  i e  if available connection   true
is in x such that
sensing  available connection  available destination        x 
then observed available connection     is added to kb    on the other hand  if
available connection   f alse
is in x as above  then observed available connection     is added to kb    in both cases
       is added to  
if neither of these cases occurs  i e  if the sensing capability cannot confirm either of
available connection or available connection  then no fact is added to kb    similarly
for the other precondition  available destination  let us assume that after this step of ae 
kb  becomes
observed available connection    
observed available destination denver     
ae can then execute the original action a     note that the agent might decide to execute
the action even if one or both preconditions are not known to be satisfied after the sensing 
if g  is achieved  sr will eliminate it and a     a     a     g     g   from the state  in the
resulting state  f    t     and pi is called  say at time    this results in generating a
partial plan for g    and changing the state so that in t  the root g  has children
a     apply visa usa      
g     have address usa      
and                  are added to c  then  further pi  say at time    introduces
a     book hotel denver      
    for this we assume that the auxiliary part of tcycle contains the rule
unreliable pre as   buy ticket online         as

   

fikakas  mancarella  sadri  stathis   toni

as a child of g   in t    and adding         to c  then  ae at time   executes a     adding it
to kb    and further ae at time   executes a     also updating kb    finally  sr eliminates
all actions and goals in t  and returns an empty f in the state 

    related work
many proposals exist for models and architectures of individual agents based on computational logic foundations  see e g  the survey by fisher  bordini  hirsch    torroni 
       some of these proposals are based on logic programming  for example impact  arisha  ozcan  ross  subrahmanian  eiter    kraus        subrahmanian  bonatti  dix 
eiter  kraus  ozcan    ross         aaa  balduccini   gelfond        baral   gelfond 
       dali  costantini   tocchio         minerva  leite  alferes    pereira        
golog  levesque  reiter  lesperance  lin    scherl         and indigolog  de giacomo 
levesque    sardina         other proposals are based on modal logic or first order logic
approaches  for example the bdi model  bratman et al         rao   georgeff        and
its extensions to deal with normative reasoning  broersen  dastani  hulstijn  huang   
van der torre         agent   shoham         agentspeak  rao        and its variants 
 apl  hindriks  de boer  van der hoek    meyer        and its variants  dastani  hobo 
  meyer        
at a high level of comparison there are similarities in the objectives of most existing
computational logic models of agency and kgp  in that they all aim at specifying knowledgerich agents with certain desirable behaviours  there are also some similarities in the finer
details of the kgp model and some of the above related work  as well as differences 
a feature of the kgp which  to the best of our knowledge  is novel is the declarative
and context sensitive specification of an agents cycle  to avoid a static cycle of control
 rao   georgeff        rao         kgp relies upon a cycle theory which determines  at
run time  given the circumstances and the individual profile of the agent  what the next
step should be  the cycle theory is sensitive to both solicited and unsolicited information
that the agent receives from its environment  and helps the agent to adapt its behaviour
to the changes it experiences  the approach closest to our work is that of  apl  hindriks
et al         as extended by dastani  de boer  dignum  and meyer         which provides
meta programming constructs for specifying the cycle of an agent such as goal selection 
plan expansion  execution  as well as if then else and while loop statements  unlike the
imperative constructs of  apl  kgp uses a set of selection operators that can be extended
to model different behaviours and types of agents  a flexible ordering of transitions is then
obtained using preference reasoning about which transitions can be applied at a specific
point in time  these preferences may change according to external events or changes in the
knowledge of the agent 
another central distinguishing feature of the kgp model  in comparison with existing
models  including those based on logic programming  is its modular integration within
a single framework of abductive logic programming  temporal reasoning  constraint logic
programming  and preference reasoning based on logic programming with priorities  in order
to support a diverse collection of capabilities  each one of these is specified declaratively
and equipped with its own provably correct computational counterpart  see bracciali 
   

ficomputational logic foundations of kgp agents

demetriou  endriss  kakas  lu  mancarella  sadri  stathis  terreni    toni        for a
detailed discussion  
compared with existing logic programming approaches kgp has two main similarities
with minerva  leite et al          an architecture that exploits computational logic and
gives both declarative and operational semantics to its agents  unlike kgp  a minerva
agent consists of several specialised  possibly concurrent  sub agents performing various
tasks  and relies upon mdlp  multidimensional dynamic logic programming   leite et al  
       mdlp is the basic knowledge representation mechanism of an agent in minerva 
which is based on an extension of answer set programming and explicit rules for updating
the agents knowledge base  in kgp instead we integrate abductive logic programming and
logic programming with priorities combined with temporal reasoning 
closely related to our work in kgp is the logic based agent architecture for reasoning
agents of baral and gelfond         this architecture assumes that the state of an agents
environment is described by a set of fluents that evolve over time in terms of transitions
labelled by actions  an agent is also assumed to be capable of correctly observing the state
of the environment  performing actions  and remembering the history of what happened in
it  the agents knowledge base consists of an action description part specifying the internal
agent transitions  which are domain specific and not generic as in kgp  the knowledge
base also contains what the agent observes in the environment including its own actions 
as in kgps kb    the temporal aspects of agent transitions are specified in the action
language al implemented in a prolog  a language of logic programs under the answerset programming semantics  the answer sets of domain specific programs specified in al
correspond to plans that in kgp are hypothetical narratives of the abductive event calculus 
the control of the agent is based on a static observe think act cycle  an instance of the kgp
cycle theories  a more recent and refined account of the overall approach has given rise to
the aaa architecture  see  balduccini   gelfond        for an overview 
dali  costantini   tocchio        is a logic programming language designed for executable specification of logical agents  like kgp  dali attempts to provide constructs to
represent reactivity and proactivity in an agent using extended logic programs  a dali
agent contains reactive rules  events  and actions aimed at interacting with an external
environment  behaviour  in terms of reactivity or proactivity  of a dali agent is triggered
by different event types  external  internal  present  and past events  all the events and
actions are time stamped so as to record when they occur  external events are like the
observations in kgp  while past events are like past observations  however  kgp does not
support internal events but has instead the idea of transitions that are called by the cycle
theory to trigger reactive or proactive behaviour 
indigolog  de giacomo et al         is a high level programming language for robots
and intelligent agents that supports  like kgp  on line planning  sensing and plan execution
in dynamic and incompletely known environments  it is a member of the golog family of
languages  levesque et al         that use a situation calculus theory of action to perform
the reasoning required in executing the program  instead in the kgp model we rely on
abductive logic programming and logic programming with priorities combined with temporal reasoning  instead of the situation calculus in kgp we use the event calculus for
temporal reasoning  but our use of the event calculus is not a prerequisite of the model as
in interrap  muller  fischer    pischel         but can be replaced with another temporal
   

fikakas  mancarella  sadri  stathis   toni

reasoning framework  if needed  apart from the difference between the use of the situation and event calculi  in indigolog goals cannot be decided dynamically  whereas in the
kgp model they change dynamically according to the specifications in the goal decision
capability 
there is an obvious similarity of the kgp model with the bdi model  bratman et al  
      given by the correspondence between kgps knowledge  goals and plan and bdis
beliefs  desires and intentions  respectively  apart from the fact that the bdi model is
based on modal logic  in kgp the knowledge  beliefs in bdi  is partitioned in modules 
to support the various reasoning capabilities  kgp also tries to bridge the gap between
specification and the practical implementation of an agent  this gap has been criticized in
bdi by rao         when he developed the agentspeak l  language  the computational
model of agentspeak l  has been formally studied by dinverno and luck         while
recent implementations of the agentspeak interpreter have been incorporated in the jason
platform  bordini   hubner         like the kgp implementation in prosocs  bracciali
et al          the jason implementation too seeks to narrow the gap between specification
and executable bdi agent programs  jason also extends bdi with new features like belief
revision  alechina  bordini  hubner  jago    logan        
a particular line of work in bdi is that of padgham and lambrix         who investigate
how the notion of capability can be integrated in the bdi logic of rao and georgeff        
so that a bdi agent can reason about its own capabilities  a capability in this work is
informally understood as the ability to act rationally towards achieving a particular goal 
in the sense of having an abstract plan type that is believed to achieve the goal  formally 
the bdi logic of rao and georgeff is extended to incorporate a modality for capabilities
that constrains agent goals and intentions to be compatible with what the agent believes
are its capabilities  a set of compatibility axioms are then presented detailing the semantic
conditions to capture the desired inter relationships among an agents beliefs  capabilities 
goals  and intentions  the work also summarises how the extensions of the bdi model can
be implemented by adapting the bdi interpreter to include capabilities  further arguing the
benefits of the extension over the original bdi interpreter of rao and georgeff        
in kgp capabilities equate to the reasoning capabilities of an agent that allow the agent
to plan actions from a given state  react to incoming observations  or decide upon which
goals to adopt  however  in kgp  we do not use capabilities at the level of an agents
domain specific knowledge to guide the agent in determining whether or not it is rational
to adopt a particular goal 
the issue of the separation between specification and implementation exists between
the kgp model and agent   shoham         and its later refinement placa  thomas 
       two other differences between the kgp and agent  and placa are the explicit
links that exist in the kgp model amongst the goals  in the structuring of the forest in the
agent state  and the richer theories in the kgp that specify priorities amongst potential
goals which are not restricted to temporal orderings  these explicit links are exploited
when revising goals and state  via the revision transition  in the light of new information
or because of the passage of time 
the boid architecture  broersen et al         extends the well known bdi model  rao
  georgeff        with obligations  thus giving rise to four main components in representing
an agent  beliefs  obligations  intentions and desires  the focus of boid is to find ways of
   

ficomputational logic foundations of kgp agents

resolving conflicts amongst these components  in order to do so they define agent types 
including some well known types in agent theories such as realistic  selfish  social and simple
minded agents  the agent types differ in that they give different priorities to the rules for
each of the four components  for instance  the simple minded agent gives higher priority to
intentions  compared to desires and obligations  whereas a social agent gives higher priority
to obligations than desires  they use priorities with propositional logic formulae to specify
the four components and the agent types 
the existing kgp model already resolves some of the conflicts that boid tries to address  for example  if there is a conflict between a belief and a prior intention  which means
that an intended action can no longer be executed due to the changes in the environment 
the kgp agent will notice this and will give higher priority to the belief than the prior
intention  allowing the agent in effect to retract the intended action and  time permitting 
to replan for its goals  the kgp model also includes a notion of priority used in the goal
decision capability and the cycle theory that controls the behaviour of the agent  the
kgp model has also been extended to deal with normative concepts  the extended model is
known as n kgp  sadri  stathis    toni         what n kgp has in common with boid
is that it seeks to extend kgp with the addition of obligations  the n kgp model also
extends the notion of priorities by incorporating them amongst different types of goals and
actions  a detailed comparison of n kgp with related work is presented by sadri  stathis 
and toni        
there are features that are included in some other approaches that are absent in the
kgp model  bdi and  more so  the impact system  arisha et al         subrahmanian
et al         allow agents to have in their knowledge bases representations of the knowledge
of other agents  these systems allow the agents both some degree of introspection and the
ability to reason about other agents beliefs and reasoning  the kgp model to this date
does not include any such features  impact also allows the incorporation of legacy systems  possibly using diverse languages  and has a richer knowledge base language including
deontic concepts and probabilities  similarly  the  apl  system is based on a combination
of imperative and logic programming languages  and includes an optimisation component
absent from the kgp  this component in  apl includes rules that identify if in a given
situation the agent is pursuing a suboptimal plan  and help the agent find a better way
of achieving its goals   apl also includes additional functionalities such as learning  van
otterlo  wiering  dastani    meyer         which our model does not currently support 
 apl  dastani et al         is an extension of  apl with goals and goal plan rules as well
as external and internal events   apl has a customisable  via graphical interface  cycle
which is fixed once customised 

    conclusions
we have presented the computational logic foundations of the kgp model of agency  the
model allows the specification of heterogeneous agents that can interact with each other  and
can exhibit both proactive and reactive behaviour allowing them to function in dynamic
environments by adjusting their goals and plans when changes happen in such environments  kgp incorporates a highly modular agent architecture that integrates a collection
   

fikakas  mancarella  sadri  stathis   toni

of reasoning and sensing capabilities  synthesised within transitions  orchestrated by cycle
theories that take into account the dynamic context and agent preferences 
the formal specification of the kgp components within computational logic has the
major advantage of facilitating both a formal analysis of the model and a direct verifiable
implementation  this formal analysis has been started by sadri and toni         where
we give a formal analysis of kgp agents by exploring their effectiveness in terms of goal
achievement  and reactive awareness  and the impact of their reasoning capabilities towards
progress in goal achievement  an implementation of a precursor of this model  described
by kakas et al       b   has already been developed within the prosocs platform of
stathis et al         upon provably correct computational counterparts defined for each
component of the model as given by kakas et al       b   concrete choices for these
computational counterparts have been described by bracciali et al          the resulting
development framework allows the deployment and testing of the functionality of the earlier
variant of kgp agents  deployment of these agents relies upon the agent template designed
by stathis et al          which builds upon previous work with the head body metaphor
described by steiner et al         and haugeneder et al          and the mind body architecture introduced by bell        and recently used by huang  eliens  and de bra        
this development platform has been applied to a number of practical applications  and 
in particular  to ambient intelligence by stathis and toni         also  sadri        has
provided guidelines for specifying applications using kgp agents  future work includes implementing and deploying the revised kgp model given in this paper  we envisage that this
will pose limited conceptual challenges  as we will be able to capitalise on our experience
in implementing and deploying the precursor of this model 
sadri  stathis  and toni        have explored how the precursor of the kgp agent
model can be augmented with normative features allowing agents to reason about and
choose between their social and personal goals  prohibitions and obligations  it would be
interesting to continue this work for the finalised kgp model given in this paper 
sadri and toni        have developed a number of different profiles of behaviour 
defined in terms of specific cycle theories  and formally proved their advantages in given
circumstances  it would be interesting to explore this dimension further  to characterise
different agent personalities and provide guidance  through formal properties  as to the
type of personality needed for applications 
future work also includes extending the model to incorporate  i  other reasoning capabilities  including knowledge revision  e g  by inductive logic programming   and more
sophisticated forms of temporal reasoning  including identifying explanations for unexpected
observations   ii  introspective reasoning and reasoning about the beliefs of other agents 
 iii  further experimentation with the model via its implementation  and  iv  development
of a concurrent implementation 

acknowledgments
this work was supported by the eu fet global computing initiative  within the socs
project  ist              we wish to thank all our colleagues in socs for useful discussions
during the development of kgp  we are also grateful to chitta baral and the anonymous
referees for helpful comments on an earlier version of this paper 
   

ficomputational logic foundations of kgp agents

appendix a  normal cycle theory
we give here the main parts of the normal tcycle   but exclude others  for example the
definitions for incompatible and the auxiliary part  including definitions for predicates such
as empty f orest  unreliable pre etc  for more details see  kakas et al         
tinitial   this consists of the following rules 
r  gi  s          gi s         empty f orest s   
r  ae  s    as    ae s    as   empty non executable goals s     as   fas  s    t  
as        time now t 
r  p i  s    g    p i s    g   gs   fgs  s    t   gs        g  gs  time now t 
tbasic   this consists of the following rules 
 the rules for deciding what might follow an ae transition are as follows 
rae p i  s     g    p i s     g   ae s  as  s     t   gs   fgs  s     t     gs       
g  gs  time now t   
 
 
rae ae  s   as     ae s     as     ae s  as  s     t   as    fas  s     t    
as         time now t   
rae aoi  s     f s    aoi s     f s   ae s  as  s     t   f s   fes  s     t    
f s        time now t   
rae sr  s       sr s          ae s  as  s     t 
rae gi  s           gi s          ae s  as  s     t 
namely  ae could be followed by another ae  or by a pi  or by an aoi  or by a sr  or by
a gi  or by a poi 
 the rules for deciding what might follow sr are as follows
rsr p i  s     g    p i s     g   sr s      s     t   gs   fgs  s     t     gs        g  gs 
time now t   
rsr gi  s           gi s          sr s      s     t   gs   fgs  s     t     gs      
time now t   
 
rsr ae  s   as    ae s     as   sr s      s     t   as   fgs  s     t     as       
time now t   
namely  sr can only be followed by pi or gi or ae  depending on whether or not there
are goals to plan for in the state 
 the rules for deciding what might follow pi are as follows
rp i ae  s     as    ae s     as   p i s  g  s     t   as   fas  s     t     as       
time now t   
 
rp i si  s   p s    si s     p s   p i s  g  s     t   p s   fp s  s     t     p s        time now t   
the second rule is here to allow the possibility of sensing the preconditions of an action
before its execution 
 the rules for deciding what might follow gi are as follows
rgi re  s           re s          gi s      s     t 
rgi p i  s     g    p i s     g   gi s      s     t   gs   fgs  s     t     gs        g  gs 
time now t   
namely  gi can only be followed by re or pi  if there are goals to plan for 
 the rules for deciding what might follow re are as follows
   

fikakas  mancarella  sadri  stathis   toni

rre p i  s     g    p i s     g   re s      s     t   gs   fgs  s     t     gs        g  gs 
time now t   
rre si  s     p s    si s     p s   re s      s     t   p s   fp s  s     t     p s       
time now t   
 the rules for deciding what might follow si are as follows
rsi ae  s     as    ae s     as   si s  p s  s     t   as   fas  s     t     as       
time now t   
 
rsi sr  s         sr s          si s  p s  s     t 
 the rules for deciding what might follow aoi are as follows
raoi ae  s     as    ae s     as   aoi s  f s  s     t   as   fas  s     t     as       
time now t   
 
raoi sr  s         sr s          aoi s  f s  s     t 
raoi si  s     p s    si s     p s   aoi s  f s  s     t   p s   fp s  s     t     p s       
time now t   
 the rules for deciding what might follow poi are as follows
rp oi gi  s           gi s          p oi s      s     t 
tbehaviour   this consists of the following rules 
 gi should be given higher priority if there are no trees in the state 
t
pgit
    rt  gi  s       rt  t    s  x   empty f orest s 
for all transitions t  t     t      gi  and with t possibly    indicating that if there are no
trees in the initial state of an agent  then gi should be its first transition  
 gi is also given higher priority after a poi 
p oi   r
 
 
pgit
p oi gi  s        rp oi t  s      s  
for all transitions t    gi 
 after gi  the transition re should be given higher priority 
gi
pret
  rgi re  s       rgi t  s  x 
for all transitions t    re 
 after re  the transition pi should be given higher priority 
ppre
it   rre p i  s  g   rre t  s  x 
for all transitions t    p i 
 after pi  the transition ae should be given higher priority  unless there are actions in
the actions selected for execution whose preconditions are unreliable and need checking 
in which case si will be given higher priority 
pi
paet
  rp i ae  s  as   rp i t  s  x   not unreliable pre as 
for all transitions t    ae 
pi
  rp i si  s  p s   rp i ae  s  as   unreliable pre as 
psiae
 after si  the transition ae should be given higher priority
si
  rsi ae  s  as   rsi t  s  x 
paet
for all transitions t    ae 
 after ae  the transition ae should be given higher priority until there are no more
actions to execute in the state  in which case either aoi or sr should be given higher
priority  depending on whether there are actions which are unreliable  in the sense that
their effects need checking  or not 
   

ficomputational logic foundations of kgp agents

ae
paet
  rae ae  s  as   rae t  s  x 
for all transitions t    ae  note that  by definition of tbasic   the transition ae is applicable
only if there are still actions to be executed in the state 
ae
ae
paoit
  rae aoi  s  f s   rae t  s  x    bcaoi t
 s  f s  t   time now t 
ae
for all transitions t    aoi  where the behaviour condition bcaoi t  s  f s  t  is defined  in
the auxiliary part  by 
ae
bcaoi t
 s  f s  t   empty executable goals s  t   unreliable ef f ect s  t 
similarly  we have 
ae  s  t   time now t 
ae
  rae sr  s       rae t  s  x    bcsr t
psrt
for all transitions t    sr where 
ae  s  t   empty executable goals s  t   not unreliable ef f ect s  t 
bcsr t
here  we assume that the auxiliary part of tcycle specifies whether a given set of actions
contains any unreliable action  in the sense expressed by unreliable ef f ect  and defines
the predicate empty executable goals 

 after sr  the transition pi should have higher priority 
ppsr
it   rsr p i  s  g   rsr t  s  x  
for all transitions t    p i 
note that  by definition of tbasic   the transition pi is applicable only if there are still goals
to plan for in the state  if there are no actions and goals left in the state  then rule rgi t
would apply 
 in the initial state pi should be given higher priority 
pp  it   r  p i  s  g   r  t  s  x 
for all transitions t    p i  note that  by definition of tinitial below  the transition pi is
applicable initially only if there are goals to plan for in the initial state 

   

fikakas  mancarella  sadri  stathis   toni

references
alechina  n   bordini  r  h   hubner  j  f   jago  m     logan  b          belief revision
for agentspeak agents  in nakashima  h   wellman  m  p   weiss  g     stone  p 
 eds     th international joint conference on autonomous agents and multiagent
systems  aamas        pp            hakodate  japan  acm 
arisha  k  a   ozcan  f   ross  r   subrahmanian  v  s   eiter  t     kraus  s         
impact  a platform for collaborating agents  ieee intelligent systems         
     
balduccini  m     gelfond  m          the aaa architecture  an overview  in in aaai
spring symposium on architectures for intelligent theory based agents  aita    
baral  c     gelfond  m          reasoning agents in dynamic domains  in logic based
artificial intelligence  pp          kluwer academic publishers  norwell  ma  usa 
bell  j          a planning theory of practical rationality  in proceedings of aaai  
fall symposium on rational agency  pp      aaai press 
bordini  r  h     hubner  j  f          bdi agent programming in agentspeak using jason
 tutorial paper   in toni  f     torroni  p   eds    computational logic in multiagent systems   th international workshop  clima vi  lecture notes in computer
science  pp          springer 
bracciali  a     kakas  a          frame consistency  reasoning with explanations 
in proceedings of the   th international workshop on non monotonic reasoning
 nmr       whistler bc  canada 
bracciali  a   demetriou  n   endriss  u   kakas  a  c   lu  w   mancarella  p   sadri  f  
stathis  k   terreni  g     toni  f          the kgp model of agency for global
computing  computational model and prototype implementation  in priami  c    
quaglia  p   eds    global computing  pp          rovereto  italy  springer 
bracciali  a   endriss  u   demetriou  n   kakas  a  c   lu  w     stathis  k         
crafting the mind of prosocs agents  applied artificial intelligence               
    
bratman  m   israel  d     pollack  m          plans and resource bounded practical reasoning  computational intelligence    
broersen  j   dastani  m   hulstijn  j   huang  z     van der torre  l          the boid
architecture  conficts between beliefs  obligations  intentions and desires  in proceedings of fifth international conference on autonomous agents  agents        pp 
     acm press  montreal  canada 
clark  k  l          negation as failure  in gallaire  h     minker  j   eds    logic and
data bases  pp          plenum press 
costantini  s     tocchio  a          the dali logic programming agent oriented language  in alferes  j  j     leite  j  a   eds    proceedings of the  th european conference on logics in artificial intelligence   jelia        vol       of lecture notes
in computer science  pp          springer 
   

ficomputational logic foundations of kgp agents

dastani  m   de boer  f   dignum  f     meyer  j  j          programming agent deliberation  an approach illustrated using the  apl language  in autonomous agents
and mult agent systems  aamas     pp         australia 
dastani  m   hobo  d     meyer  j  j          practical extensions in agent programming
languages  in proceedings of the sixth international joint conference on autonomous
agents and multiagent systems  aamas     acm press 
de bruijn  o     stathis  k          socio cognitive grids  the net as a universal human
resource  in kameas  a     streitz  n   eds    proceedings of the conference of tales
of the disappearing computer  pp          santorini  cti press 
de giacomo  g   levesque  h  j     sardina  s          incremental execution of guarded
theories  acm transactions on computational logic                
dinverno  m     luck  m          engineering agentspeak l   a formal computational
model  j  log  comput                 
fipa communicative act library specification      a   experimental specification
xc     h  foundation for intelligent physical agents  http   www fipa org 
fipa query interaction protocol      b   experimental specification xc     f  foundation for intelligent physical agents  http   www fipa org 
fisher  m   bordini  r   hirsch  b     torroni  p          computational logics and agents 
a road map of current technologies and future trends  computational intelligence 
             
haugeneder  h   steiner  d     mccabe  f          imagine  a framework for building
multi agent systems  in deen  s  m   ed    proceedings of the      international
working conference on cooperating knowledge based systems  ckbs      pp    
    dake centre  university of keele  uk 
hindriks  k  v   de boer  f  s   van der hoek  w     meyer  j  c          agent programming in  apl  autonomous agents and multi agent systems               
huang  z   eliens  a     de bra  p          an architecture for web agents  in proceedings
of euromedia    scs 
jaffar  j     maher  m          constraint logic programming  a survey  journal of logic
programming                
kakas  a  c   kowalski  r  a     toni  f          the role of abduction in logic programming  in gabbay  d  m   hogger  c  j     robinson  j  a   eds    handbook of logic in
artificial intelligence and logic programming  vol     pp          oxford university
press 
kakas  a  c   mancarella  p     dung  p  m          the acceptability semantics for logic
programs  in proceedings of the eleventh international conference on logic programming  pp          cambridge  ma  usa  mit press 
kakas  a  c     miller  r          a simple declarative language for describing narratives
with actions  logic programming     
   

fikakas  mancarella  sadri  stathis   toni

kakas  a  c     moraitis  p          argumentation based decision making for autonomous
agents  in rosenschein  j  s   sandholm  t   wooldridge  m     yokoo  m   eds   
proceedings of the second international joint conference on autonomous agents and
multiagent systems  aamas        pp          melbourne  victoria  acm press 
kakas  a   mancarella  p   sadri  f   stathis  k     toni  f          declarative agent
control  in leite  j     torroni  p   eds    clima v  computational logic in multiagent systems  vol       of lecture notes in artificial intelligence  lnai   pp    
     springer verlag 
kakas  a  c   kowalski  r  a     toni  f          abductive logic programming  j  log 
comput                 
kakas  a  c   mancarella  p   sadri  f   stathis  k     toni  f       a   declarative agent
control  in leite  j  a     torroni  p   eds    computational logic in multi agent systems   th international workshop  clima v  vol       of lecture notes in computer
science  pp         springer 
kakas  a  c   mancarella  p   sadri  f   stathis  k     toni  f       b   the kgp model of
agency  in de mantaras  r  l     saitta  l   eds    proceedings of the   th eureopean
conference on artificial intelligence  ecai        pp        ios press 
kowalski  r  a     sergot  m          a logic based calculus of events  new generation
computing              
kowalski  r     toni  f          abstract argumentation  artificial intelligence and law
journal  special issue on logical models of argumentation                   kluwer
academic publishers 
leite  j  a   alferes  j  j     pereira  l  m          min erva  a dynamic logic programming agent architecture  in intelligent agents viii   th international workshop 
atal       seattle  wa  usa  revised papers  vol       of lecture notes in artificial intelligence  pp         
levesque  h  j   reiter  r   lesperance  y   lin  f     scherl  r  b          golog  a
logic programming language for dynamic domains  journal of logic programming 
               
mamdani  e  h   pitt  j     stathis  k          connected communities from the standpoint
of multi agent systems  new generation computing                 
mancarella  p   sadri  f   terreni  g     toni  f          planning partially for situated
agents  in leite  j  a     torroni  p   eds    computational logic in multi agent systems   th international workshop  clima v  vol       of lecture notes in computer
science  pp          springer 
miller  r     shanahan  m          some alternative formulations of the event calculus 
in kakas  a  c     sadri  f   eds    computational logic  logic programming and
beyond   essays in honour of robert a  kowalski  vol       of lecture notes in
computer science  pp          springer 
muller  j   fischer  k     pischel  m          a pragmatic bdi architecture  in huhns 
m  n     singh  m  p   eds    readings in agents  pp          morgan kaufmann
publishers 
   

ficomputational logic foundations of kgp agents

padgham  l     lambrix  p          formalisations of capabilities for bdi agents  autonomous agents and multi agent systems                 
prakken  h     sartor  g          a system for defeasible argumentation  with defeasible
priorities  in international conference on formal and applied practical reasoning 
springer lecture notes in ai       pp         
prakken  h     sartor  g          argument based extended logic programming with defeasible priorities  journal of applied non classical logics              
rao  a  s          agentspeak l   bdi agents speak out in a logical computable language 
in van hoe  r   ed    agents breaking away   th european workshop on modelling
autonomous agents in a multi agent world  maamaw    eindhoven  the netherlands  january              proceedings  vol       of lecture notes in computer
science  pp        springer verlag 
rao  a  s     georgeff  m  p          modeling rational agents within a bdi architecture 
in fikes  r     sandewall  e   eds    proceedings of knowledge representation and
reasoning  kr r      pp          morgan kaufmann publishers 
rao  a  s     georgeff  m  p          modeling rational agents within a bdi architecture 
in huhns  m  n     singh  m  p   eds    readings in agents  pp          morgan
kaufmann publishers  san francisco  ca  usa 
rao  a  s     georgeff  m  p          an abstract architecture for rational agents  in nebel 
b   rich  c     r swartout  w   eds     rd international conference on principles
of knowledge representation and reasoning  kr     pp          cambridge  ma 
usa  morgan kaufmann 
sadri  f          using the kgp model of agency to design applications  tutorial paper  
in toni  f     torroni  p   eds    computational logic in multi agent systems   th
international workshop  clima vi  vol       of lecture notes in computer science 
pp          springer 
sadri  f   stathis  k     toni  f          normative kgp agents  computational   mathematical organization theory                   
sadri  f     toni  f          variety of behaviours through profiles in logic based agents 
in toni  f     torroni  p   eds    computational logic in multi agent systems   th
international workshop  clima vi  vol       of lecture notes in computer science 
pp          springer 
sadri  f     toni  f          a formal analysis of kgp agents  in fisher  m   van der hoek 
w   konev  b     lisitsa  a   eds    logics in artificial intelligence    th european
conference  jelia       vol       of lecture notes in computer science  pp     
     springer 
shanahan  m          solving the frame problem  mit press 
shanahan  m          prediction is deduction but explanation is abduction  in proceedings
of the   th international joint conference on artificial intelligence  pp           
shoham  y          agent oriented programming  artificial intelligence               
   

fikakas  mancarella  sadri  stathis   toni

socs         societies of computees  a computational logic model for the description 
analysis and verification of global and open societies of heterogeneous computees 
http   lia deis unibo it research socs  
stathis  k   child  c   lu  w     lekeas  g  k          agents and environments 
tech  rep  technical report ist      city     dn i a   socs consortium       
ist      city     dn i a  
stathis  k   kakas  a   lu  w   demetriou  n   endriss  u     bracciali  a         
prosocs  a platform for programming software agents in computational logic  in
muller  j     petta  p   eds    proceedings of from agent theory to agent implementation  at ai    emcsr     session m   pp          vienna  austria 
stathis  k     toni  f          ambient intelligence using kgp agents  in markopoulos  p  
eggen  b   aarts  e  h  l     crowley  j  l   eds    ambient intelligence  proceedings
of second european symposium  eusai       vol       of lecture notes in computer
science  pp          springer 
steiner  d  e   haugeneder  h     mahling  d          collaboration of knowledge bases
via knowledge based collaboration  in deen  s  m   ed    ckbs     proceedings of
the international working conference on cooperating knowledge based systems  pp 
        springer verlag 
subrahmanian  v  s   bonatti  p   dix  j   eiter  t   kraus  s   ozcan  f     ross  r         
heterogeneous agent systems  mit press aaai press  cambridge  ma  usa 
thomas  s  r          the placa agent programming language  in wooldridge  m  j    
jennings  n  r   eds    intelligent agents  pp          berlin  springer verlag 
van otterlo  m   wiering  m   dastani  m     meyer  j  j          a characterization
of sapient agents  in hexmoor  h   ed    international conference integration of
knowledge intensive multi agent systems  kimas      pp          boston  massachusetts  ieee 
wooldridge  m          an introduction to multiagent systems  john wiley   sons 
yip  a   forth  j   stathis  k     kakas  a  c          software anatomy of a kgp agent 
in gleizes  m  p   kaminka  g  a   nowe  a   ossowski  s   tuyls  k     verbeeck  k 
 eds    eumas        proceedings of the third european workshop on multi agent
systems  pp          koninklijke vlaamse academie van belie voor wetenschappen
en kunsten 

   

fi