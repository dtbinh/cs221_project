journal artificial intelligence research                  

submitted        published      

latent relation mapping engine 
algorithm experiments
peter d  turney

peter turney nrc cnrc gc ca

institute information technology
national research council canada
ottawa  ontario  canada  k a  r 

abstract
many ai researchers cognitive scientists argued analogy core
cognition  influential work computational modeling analogy making
structure mapping theory  smt  implementation structure mapping engine
 sme   limitation sme requirement complex hand coded representations 
introduce latent relation mapping engine  lrme   combines ideas
sme latent relational analysis  lra  order remove requirement handcoded representations  lrme builds analogical mappings lists words  using
large corpus raw text automatically discover semantic relations among words 
evaluate lrme set twenty analogical mapping problems  ten based scientific
analogies ten based common metaphors  lrme achieves human level performance
twenty problems  compare lrme variety alternative approaches
find able reach level performance 

   introduction
faced problem  try recall similar problems faced
past  transfer knowledge past experience current
problem  make analogy past situation current situation 
use analogy transfer knowledge  gentner        minsky        holyoak   thagard 
      hofstadter        hawkins   blakeslee        
survey computational modeling analogy making  french        cites
structure mapping theory  smt   gentner        implementation structure
mapping engine  sme   falkenhainer  forbus    gentner        influential
work modeling analogy making  sme  analogical mapping   b
source target b  source familiar  known  concrete 
whereas target relatively unfamiliar  unknown  abstract  analogical mapping
used transfer knowledge source target 
gentner        argues two kinds similarity  attributional similarity
relational similarity  distinction attributes relations may understood terms predicate logic  attribute predicate one argument 
large x   meaning x large  relation predicate two arguments 
collides with x     meaning x collides  
structure mapping engine prefers mappings based relational similarity
mappings based attributional similarity  falkenhainer et al          example  sme
able build mapping representation solar system  the source 
c
    
national research council canada  reprinted permission 

fiturney

representation rutherford bohr model atom  the target   sun mapped
nucleus  planets mapped electrons  mass mapped charge  note
mapping emphasizes relational similarity  sun nucleus different
terms attributes  sun large nucleus small  likewise 
planets electrons little attributional similarity  hand  planets revolve
around sun electrons revolve around nucleus  mass sun attracts
mass planets charge nucleus attracts charge electrons 
gentner        provides evidence children rely primarily attributional similarity
mapping  gradually switching relational similarity mature  uses
terms mere appearance refer mapping based mostly attributional similarity  analogy
refer mapping based mostly relational similarity  literal similarity refer
mixture attributional relational similarity  since use analogical mappings solve
problems make predictions  focus structure  especially causal relations 
look beyond surface attributes things  gentner         analogy
solar system rutherford bohr model atom illustrates importance
going beyond mere appearance  underlying structures 
figures     show lisp representations used sme input analogy
solar system atom  falkenhainer et al          chalmers  french 
hofstadter        criticize smes requirement complex hand coded representations 
argue hard work done human creates high level
hand coded representations  rather sme 
 defentity sun  type inanimate 
 defentity planet  type inanimate 
 defdescription solar system
entities  sun planet 
expressions    mass sun   name mass sun 
  mass planet   name mass planet 
  greater mass sun mass planet   name  mass 
  attracts sun planet   name attracts form 
  revolve around planet sun   name revolve 
  and  mass attracts form   name and  
  cause and  revolve   name cause revolve 
  temperature sun   name temp sun 
  temperature planet   name temp planet 
  greater temp sun temp planet   name  temp 
  gravity mass sun mass planet   name force gravity 
  cause force gravity attracts form   name why attracts   

figure    representation solar system sme  falkenhainer et al         
gentner  forbus  colleagues attempted avoid hand coding
recent work sme   cogsketch system generate lisp representations
simple sketches  forbus  usher  lovett  lockwood    wetzel         gizmo system
generate lisp representations qualitative physics models  yan   forbus        
learning reader system generate lisp representations natural language text
 forbus et al          systems require lisp input 
   dedre gentner  personal communication  october          

   

fithe latent relation mapping engine

 defentity nucleus  type inanimate 
 defentity electron  type inanimate 
 defdescription rutherford atom
entities  nucleus electron 
expressions    mass nucleus   name mass n 
  mass electron   name mass e 
  greater mass n mass e   name  mass 
  attracts nucleus electron   name attracts form 
  revolve around electron nucleus   name revolve 
  charge electron   name q electron 
  charge nucleus   name q nucleus 
  opposite sign q nucleus q electron   name  charge 
  cause  charge attracts form   name why attracts   

figure    rutherford bohr model atom sme  falkenhainer et al         

however  cogsketch user interface requires person draws sketch identify basic components sketch hand label terms knowledge
base derived opencyc  forbus et al         note opencyc contains
       hand coded concepts  added hand coded concepts opencyc 
order support cogsketch  gizmo system requires user hand code physical
model  using methods qualitative physics  yan   forbus         learning reader
uses        phrasal patterns  derived researchcyc  forbus
et al          evident sme still requires substantial hand coded knowledge 
work present paper effort avoid complex hand coded representations  approach combine ideas sme  falkenhainer et al         latent
relational analysis  lra   turney         call resulting algorithm latent relation mapping engine  lrme   represent semantic relation two terms
using vector  elements derived pattern frequencies large corpus
raw text  semantic relations automatically derived corpus  lrme
require hand coded representations relations  needs list terms
source list terms target  given two lists  lrme uses corpus
build representations relations among terms  constructs mapping
two lists 
tables     show input output lrme analogy solar
system rutherford bohr model atom  although human effort involved
constructing input lists  considerably less effort sme requires input
 contrast figures     table    
scientific analogies  analogy solar system rutherfordbohr model atom  may seem esoteric  believe analogy making ubiquitous
daily lives  potential practical application work task identifying
semantic roles  gildea   jurafsky         since roles relations  attributes 
appropriate treat semantic role labeling analogical mapping problem 
example  judgement semantic frame contains semantic roles judge 
evaluee  reason  statement frame contains roles speaker  addressee  message  topic  medium  gildea   jurafsky         task identifying
   

fiturney

source
planet
attracts
revolves
sun
gravity
solar system
mass

target b
revolves
atom
attracts
electromagnetism
nucleus
charge
electron

table    representation input lrme 
source
solar system
sun
planet
mass
attracts
revolves
gravity

mapping








target b
atom
nucleus
electron
charge
attracts
revolves
electromagnetism

table    representation output lrme 
semantic roles automatically label sentences roles  following examples  gildea   jurafsky        
 judge she  blames  evaluee government   reason failing enough
help  
 speaker we  talked  topic proposal   medium phone  
training set labeled sentences testing set unlabeled sentences 
may view task labeling testing sentences problem creating analogical
mappings training sentences  sources  testing sentences  targets   table   shows blames government failing enough help  might
mapped blame company polluting environment  mapping
found  transfer knowledge  form semantic role labels  source
target 
source

blames
government
failing
help

mapping






target b

blame
company
polluting
environment

table    semantic role labeling analogical mapping 
section    briefly discuss hypotheses behind design lrme 
precisely define task performed lrme  specific form analogical mapping 
   

fithe latent relation mapping engine

section    lrme builds latent relational analysis  lra   hence summarize lra
section    discuss potential applications lrme section   
evaluate lrme  created twenty analogical mapping problems  ten science analogy problems  holyoak   thagard        ten common metaphor problems  lakoff  
johnson         table   one science analogy problems  intended solution
given table    validate intended solutions  gave colleagues lists
terms  as table    asked generate mappings lists  section  
presents results experiment  across twenty problems  average agreement
intended solutions  as table          
lrme algorithm outlined section    along evaluation twenty
mapping problems  lrme achieves accuracy        difference
performance human average       statistically significant 
section   examines variety alternative approaches analogy mapping task 
best approach achieves accuracy        approach requires hand coded partof speech tags  performance significantly lrme human performance 
section    discuss questions raised results preceding
sections  related work described section     future work limitations considered
section     conclude section    

   guiding hypotheses
section  list assumptions guided design lrme 
results present paper necessarily require assumptions  might
helpful reader  understand reasoning behind approach 
   analogies semantic relations  analogies based semantic relations
 gentner         example  analogy solar system rutherford bohr model atom based similarity semantic relations
among concepts involved understanding solar system semantic
relations among concepts involved rutherford bohr model atom 
   co occurrences semantic relations  two terms interesting  significant semantic relation tend co occur within relatively
small window  e g   five words  relatively large corpus  e g        words  
interesting semantic relation causes co occurrence co occurrence reliable
indicator interesting semantic relation  firth        
   meanings semantic relations  meaning relations among
words individual words  individual words tend ambiguous polysemous 
putting two words pair  constrain possible meanings  putting
words sentence  multiple relations among words sentence 
constrain possible meanings further  focus word pairs  or tuples   instead
individual words  word sense disambiguation less problematic  perhaps word
sense apart relations words  kilgarriff        
   pattern distributions semantic relations  many to many mapping semantic relations patterns two terms co occur 
example  relation causeeffect x    may expressed x causes  
   

fiturney

x  due x  x  on  likewise  pattern
x may expression causeeffect x     sick bacteria 
originentity x     oranges spain   however  given x   statistical distribution patterns x co occur reliable signature
semantic relations x  turney        
extent lrme works  believe success lends support hypotheses 

   task
paper  examine algorithms generate analogical mappings  simplicity 
restrict task generating bijective mappings  is  mappings injective
 one to one  instance two terms source map term
target  surjective  onto  source terms cover target terms 
target term left mapping   assume entities
mapped given input  formally  input algorithms two sets terms 
b 
   ha  bi 

   

since mappings bijective  b must contain number terms  m 
   a    a             

   

b    b    b            bm  

   

term  ai bj   may consist single word  planet  compound two words
 solar system   words may part speech  nouns  verbs  adjectives  adverbs  
output bijective mapping b 
   m   b 

   

 ai   b

   

 a     m  a      a              am      b

   

algorithms consider accept batch multiple independent mapping
problems input generate mapping one output 
   ha    b    ha    b            han   bn i 

   

   m    a  b    m    a  b            mn   bn  

   

suppose terms arbitrary order a 
  ha    a           
mapping function   b  given a  determines unique ordering b b 
   

   

fithe latent relation mapping engine

b   hm  a      a              am  i

    

likewise  ordering b b  given a  defines unique mapping function   since
m  possible orderings b  m  possible mappings b  task
search m  mappings find best one   section   shows
relatively high degree consensus mappings best  
let p  a  b  set m  bijective mappings b   p stands permutation  since mapping corresponds permutation  
p  a  b     m    m            mm   

    

   a     b 

    

m     p  a  b  

    

following experiments    average   most  m  usually around
                           feasible us exhaustively search p  a  b  
explore two basic kinds algorithms generating analogical mappings  algorithms
based attributional similarity algorithms based relational similarity  turney 
       attributional similarity two words  sima  a  b     depends
degree correspondence properties b  correspondence
is  greater attributional similarity  relational similarity two
pairs words  simr  a   b  c   d     depends degree correspondence
relations   b c   d  correspondence is  greater relational
similarity  example  dog wolf relatively high degree attributional similarity 
whereas dog   bark cat   meow relatively high degree relational similarity 
attributional mapping algorithms seek mapping  or mappings  maximizes
sum attributional similarities terms corresponding
terms b   when multiple mappings maximize sum  break tie
randomly choosing one them  
  arg max


x

sima  ai    ai   

    

p  a b  i  

relational mapping algorithms seek mapping  or mappings  mr maximizes
sum relational similarities 
mr   arg max

x

x

simr  ai   aj    ai      aj   

    

p  a b  i   j i  

      assume simr symmetrical  example  degree relational similarity
dog   bark cat   meow degree relational similarity
bark   dog meow   cat 
simr  a   b  c   d    simr  b   a    c 

    

assume simr  a   a  b   b  interesting  example  may constant
value b  therefore      designed always less j 
   

fiturney

let scorer  m   scorea  m   defined follows 

scorer  m    
scorea  m    

x

x

simr  ai   aj    ai      aj   

i   j i  

x

sima  ai    ai   

    

    

i  

mr may defined terms scorer  m   scorea  m   
mr   arg max scorer  m  

    

p  a b 

  arg max scorea  m  

    

p  a b 

mr best mapping according simr best mapping according sima  
recall gentners        terms  discussed section    mere appearance  mostly attributional similarity   analogy  mostly relational similarity   literal similarity  a mixture
attributional relational similarity   take mr abstract model mapping based analogy model mere appearance  literal similarity 
combine mr   take care normalize scorer  m   scorea  m  
combine them   we experiment combining section      

   latent relational analysis
lrme uses simplified form latent relational analysis  lra   turney             
calculate relational similarity pairs words  briefly describe past
work lra present lrme 
lra takes input set word pairs generates output relational
similarity simr  ai   bi   aj   bj   two pairs input 
   a    b    a    b              bn  

    

   simr     

    

lra designed evaluate proportional analogies  proportional analogies form
  b    c   d  means b c d  example  mason   stone    carpenter   wood
means mason stone carpenter wood  mason artisan works
stone carpenter artisan works wood 
consider proportional analogies special case bijective analogical mapping 
defined section     a     b         example  a    a     b    b  equivalent
m       
   a    a      b    b    b      m   a      b    m   a      b   
definition scorer  m         following result m   
   

    

fithe latent relation mapping engine

scorer  m      simr  a    a    m   a      m   a       simr  a    a    b    b   

    

is  quality proportional analogy mason   stone    carpenter   wood given
simr  mason   stone  carpenter   wood  
proportional analogies may evaluated using attributional similarity 
definition scorea  m         following result m   
scorea  m      sima  a    m   a       sima  a    m   a       sima  a    b      sima  a    b   

    

attributional similarity  quality proportional analogy mason   stone    carpenter  
wood given sima  mason  carpenter    sima  stone  wood  
lra handles proportional analogies  main contribution lrme extend
lra beyond proportional analogies bijective analogies     
turney        describes ten potential applications lra  recognizing proportional
analogies  structure mapping theory  modeling metaphor  classifying semantic relations 
word sense disambiguation  information extraction  question answering  automatic thesaurus generation  information retrieval  identifying semantic roles  two
applications  evaluating proportional analogies classifying semantic relations  experimentally evaluated  state of the art results 
turney        compares performance relational similarity      attributional
similarity      task solving     multiple choice proportional analogy questions
sat college entrance test  lra used measure relational similarity variety
lexicon based corpus based algorithms used measure attributional similarity 
lra achieves accuracy         sat questions  significantly
different average human score      hand  best performance
attributional similarity      results show attributional similarity better
random guessing  good relational similarity  result consistent
gentners        theory maturation human similarity judgments 
turney        applies lra task classifying semantic relations nounmodifier expressions  noun modifier expression phrase  laser printer 
head noun  printer  preceded modifier  laser   task identify semantic
relation noun modifier  case  relation instrument 
laser instrument used printer  set     hand labeled noun modifier pairs
five different classes semantic relations  lra attains     accuracy 
turney        employs variation lra solving four different language tests 
achieving     accuracy sat analogy questions      accuracy toefl synonym
questions      accuracy task distinguishing synonyms antonyms     
accuracy task distinguishing words similar  words associated 
words similar associated  core algorithm used
four tests  tuning parameters particular test 

   applications lrme
since lrme extension lra  every potential application lra potential
application lrme  advantage lrme lra ability handle bijective
   

fiturney

analogies      where    a     b    section  consider kinds
applications might benefit ability 
section      evaluate lrme science analogies common metaphors 
supports claim two applications benefit ability handle larger sets
terms  section    saw identifying semantic roles  gildea   jurafsky       
involves two terms  believe lrme superior lra
semantic role labeling 
semantic relation classification usually assumes relations binary  is 
semantic relation connection two terms  rosario   hearst        nastase
  szpakowicz        turney        girju et al          yuret observed binary relations may linked underlying n ary relations   example  nastase szpakowicz
       defined taxonomy    binary semantic relations  table   shows six binary relations nastase szpakowicz        covered one   ary relation 
agent tool action affected theme  agent uses tool perform action  somebody
something affected action  whole event summarized theme 
nastase szpakowicz       
relation
example
agent
student protest
purpose
concert hall
beneficiary
student discount
instrument
laser printer
object
metal separator
object property sunken ship

agent tool action affected theme
agent action
theme tool
affected action
tool agent
affected tool
action affected

table    six binary semantic relations nastase szpakowicz       
viewed different fragments one   ary semantic relation 

semeval task    found easier manually tag datasets expanded
binary relations underlying n ary relations  girju et al          believe
expansion would facilitate automatic classification semantic relations  results
section     suggest applications lra discussed section  
might benefit able handle bijective analogies     

   mapping problems
evaluate algorithms analogical mapping  created twenty mapping problems 
given appendix a  twenty problems consist ten science analogy problems  based
examples analogy science chapter   holyoak thagard         ten
common metaphor problems  derived lakoff johnson        
tables appendix show intended mappings twenty problems  validate mappings  invited colleagues institute information
technology participate experiment  experiment hosted web server
   deniz yuret  personal communication  february           observation context
work building datasets semeval      task    girju et al         

   

fithe latent relation mapping engine

 only accessible inside institute  people participated anonymously  using web
browsers offices     volunteers began experiment   
went way end  analysis  use data    participants
completed mapping problems 
instructions participants appendix a  sequence problems
order terms within problem randomized separately participant 
remove effects due order  table   shows agreement intended
mapping mappings generated participants  across twenty problems 
average agreement        higher agreement figures many
linguistic annotation tasks  agreement impressive  given participants
minimal instructions training 
type

science
analogies

common
metaphors

mapping
a 
a 
a 
a 
a 
a 
a 
a 
a 
a  
m 
m 
m 
m 
m 
m 
m 
m 
m 
m  

source target
solar system atom
water flow heat transfer
waves sounds
combustion respiration
sound light
projectile planet
artificial selection natural selection
billiard balls gas molecules
computer mind
slot machine bacterial mutation
war argument
buying item accepting belief
grounds building reasons theory
impediments travel difficulties
money time
seeds ideas
machine mind
object idea
following understanding
seeing understanding

average

agreement
    
    
    
    
    
    
    
    
    
    
    
    
    
     
    
    
    
    
    
    
    


 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   

table    average agreement intended mappings mappings
   participants  see appendix details 

column labeled gives number terms set source terms
mapping problem  which equal number terms set target terms  
average problem       third column table   gives mnemonic summarizes
mapping  e g   solar system atom   note mnemonic used input
algorithms  mnemonic shown participants experiment 
agreement figures table   individual mapping problem averages
mappings problem  appendix gives detailed view  showing
agreement individual mapping mappings  twenty problems contain
total     individual mappings         appendix shows every one    
   

fiturney

mappings agreement     higher  is  every case  majority
participants agreed intended mapping   there two cases agreement
exactly      see problems a  table    m  table    appendix a  
select mapping chosen majority    participants 
get perfect score twenty problems  precisely  try m  mappings
problem  select mapping maximizes sum number participants
agree individual mapping mappings  score
     twenty problems  strong support intended mappings
given appendix a 
section    applied genters        categories mere appearance  mostly attributional similarity   analogy  mostly relational similarity   literal similarity  a mixture
attributional relational similarity  mappings mr   mr
best mapping according simr best mapping according sima   twenty
mapping problems chosen analogy problems  is  intended mappings
appendix meant relational mappings  mr   mappings maximize relational
similarity  simr   tried avoid mere appearance literal similarity 
section   use twenty mapping problems evaluate relational mapping
algorithm  lrme   section   use evaluate several different attributional
mapping algorithms  hypothesis lrme perform significantly better
attributional mapping algorithms twenty mapping problems 
analogy problems  not mere appearance problems literal similarity problems  
expect relational attributional mapping algorithms would perform approximately
equally well literal similarity problems  expect mere appearance problems
would favour attributional algorithms relational algorithms  test
latter two hypotheses  primary interest paper analogy making 
goal test hypothesis real  practical  effective  measurable
difference output lrme output various attributional mapping algorithms  skeptic might claim relational similarity simr  a   b  c   d 
reduced attributional similarity sima  a  c    sima  b  d   therefore relational mapping
algorithm complicated solution illusory problem  slightly less skeptical claim
relational similarity versus attributional similarity valid distinction cognitive
psychology  relational mapping algorithm capture distinction  test
hypothesis refute skeptical claims  created twenty analogical mapping
problems  show lrme handles problems significantly better
various attributional mapping algorithms 

   latent relation mapping engine
latent relation mapping engine  lrme  seeks mapping mr maximizes
sum relational similarities 
mr   arg max

x

x

simr  ai   aj    ai      aj   

    

p  a b  i   j i  

search mr exhaustively evaluating possibilities  ties broken randomly  use simplified form lra  turney        calculate simr  
   

fithe latent relation mapping engine

    algorithm
briefly  idea lrme build pair pattern matrix x  rows correspond
pairs terms columns correspond patterns  example  row xi  might
correspond pair terms sun   solar system column x j might correspond
pattern x centered   patterns  wild card  match
single word  value element xij x based frequency pattern
x j   x instantiated terms pair xi    example 
take pattern x centered instantiate x   pair sun   solar system 
pattern sun centered solar system   thus value element
xij based frequency sun centered solar system corpus  matrix
x smoothed truncated singular value decomposition  svd   golub   van loan 
      relational similarity simr two pairs terms given cosine
angle two corresponding row vectors x 
detail  lrme takes input set mapping problems generates
output corresponding set mappings 

   ha    b    ha    b            han   bn i 

    

   m    a  b    m    a  b            mn   bn  

    

following experiments  twenty mapping problems  appendix a  processed
one batch  n       
first step make list r contains pairs terms input i 
mapping problem ha  bi i  add r pairs ai   aj   ai aj
members a     j  pairs bi   bj   bi bj members b     j 
 a     b    m  m m    pairs m m    pairs b  
typical pair r would sun   solar system  allow duplicates r  r list
pair types  pair tokens  twenty mapping problems  r list       pairs 
pair r r  make list s r  phrases corpus contain
pair r  let ai   aj terms pair r  search corpus phrases
following form 
     words  ai      words  aj      words 

    

ai   aj r  aj   ai r  find phrases members pairs
orders  s ai   aj   s aj   ai    search template      used
turney        
following experiments  search corpus        english words  about    
gb plain text   consisting web pages gathered web crawler   retrieve phrases
   m m    here  m m       need pairs orders  want
calculate simr one order pairs  always less j       however  ensure
simr symmetrical        need make matrix x symmetrical  rows
matrix orders every pair 
   corpus collected charles clarke university waterloo  provide copies
corpus request 

   

fiturney

corpus  use wumpus  buttcher   clarke         efficient search engine
passage retrieval large corpora  
      pairs r  find total           phrases corpus  average
      phrases per pair  pair r   sun   solar system  typical phrase
s r  would sun centered solar system illustrates 
next make list c patterns  based phrases found  pair
r r  r   ai   aj   found phrase s r   replace ai x
replace aj   remaining words may either left replaced
wild card symbol   replace ai aj x  replace
remaining words wild cards leave are  n remaining
words s  ai aj replaced  generate  n   patterns s  add
patterns c  add new patterns c  is  c list pattern types 
pattern tokens  duplicates c 
example  pair sun   solar system  found phrase sun centered solar
system illustrates  replace ai   aj x     x centered
illustrates  three remaining words  generate eight patterns 
x illustrates  x centered   x illustrates  on 
patterns added c  replace ai   aj   x  yielding centered x
illustrates  gives us another eight patterns  centered x   thus
phrase sun centered solar system illustrates generates total sixteen patterns 
add c 
revise r  make list pairs correspond rows frequency
matrix f  remove pairs r phrases found corpus 
terms either order  let ai   aj terms pair r  remove
r r s ai   aj   s aj   ai   empty  remove rows
would correspond zero vectors matrix f  reduces r       pairs      
pairs  let nr number pairs r 
next revise c  make list patterns correspond columns
frequency matrix f  following experiments  stage  c contains millions
patterns  many efficient processing standard desktop computer  need
reduce c manageable size  select patterns shared
pairs  let c pattern c  let r pair r  phrase s r  
pattern generated identical c  say r one
pairs generated c  sort patterns c descending order number
pairs r generated pattern  select top tnr patterns
sorted list  following turney         set parameter     hence c reduced
top        patterns  tnr                       let nc number patterns
c  nc   tnr   
rows r columns c defined  build frequency matrix
f  let ri i th pair terms r  e g   let ri sun   solar system  let cj
j th pattern c  e g   let cj x centered    instantiate x
pattern cj terms ri   sun centered solar system    element fij f
frequency instantiated pattern corpus 
   wumpus developed stefan buttcher available http   www wumpus search org  

   

fithe latent relation mapping engine

note need search corpus instantiated pattern
fij   order find frequency  process creating pattern  keep track
many phrases generated pattern  pair  get frequency fij
checking record patterns generated ri  
next step transform matrix f raw frequencies form x
enhances similarity measurement  turney        used log entropy transformation 
suggested landauer dumais         kind tf idf  term frequency
times inverse document frequency  transformation  gives weight elements
matrix statistically surprising  however  bullinaria levy        recently
achieved good results new transformation  called ppmic  positive pointwise mutual
information cosine   therefore lrme uses ppmic  raw frequencies f used
calculate probabilities  calculate pointwise mutual information
 pmi  element matrix  element negative pmi set zero 

fij
pij   pnr pnc

j   fij

i  

    

pnc

j   fij
pi   pnr pnc

    

pnr
f
pncij
  pnr i  

    

i  

pj

i  



j   fij
j   fij

pij
pi pj



pmiij   log

pmiij pmiij    
xij  
  otherwise

    
    

let ri i th pair terms r  e g   let ri sun   solar system  let cj
j th pattern c  e g   let cj x centered          pij estimated probability
pattern cj instantiated pair ri   sun centered solar system    pi
estimated probability ri   pj estimated probability cj   ri cj
statistically independent  pi pj   pij  by definition independence   thus
pmiij zero  since log          interesting semantic relation
terms ri   pattern cj captures aspect semantic relation 
expect pij larger would ri cj indepedent  hence find
pij   pi pj   thus pmiij positive   see hypothesis   section    
hand  terms completely different domains may avoid other  case
find pmiij negative  ppmic designed give high value xij
pattern cj captures aspect semantic relation terms ri   otherwise 
xij value zero  indicating pattern cj tells us nothing
semantic relation terms ri  
experiments  f density       the percentage nonzero elements 
x density       lower density x due elements negative pmi 
transformed zero ppmic 
   

fiturney

smooth x applying truncated singular value decomposition  svd   golub
  van loan         use svdlibc calculate svd x   svdlibc designed
sparse  low density  matrices  svd decomposes x product three matrices
uvt   u v column orthonormal form  i e   columns orthogonal
unit length  ut u   vt v   i  diagonal matrix singular values
 golub   van loan         x rank r  rank r  let k  
k   r  diagonal matrix formed top k singular values  let uk vk
matrices produced selecting corresponding columns u v  matrix
uk k vkt matrix rank k best approximates original matrix x  sense
minimizes approximation errors  is  x   uk k vkt minimizes kx xkf
matrices x rank k  k       kf denotes frobenius norm  golub   van
loan         may think matrix uk k vkt smoothed compressed version
original matrix x  following turney         set parameter k     
relational similarity simr two pairs r inner product two
corresponding rows uk k vkt   rows normalized unit length 
simplify calculations dropping vk  deerwester  dumais  landauer  furnas    harshman 
       take matrix uk k normalize row unit length  let w
resulting matrix  let z wwt   square matrix size nr nr   matrix contains
cosines combinations two pairs r 
mapping problem ha  bi i  let   a  pair terms let b   b 
pair terms b  suppose ri     a  rj   b   b    ri rj
i th j th pairs r  simr  a   a    b   b      zij   zij element i th
row j th column z  either   a  b   b  r  s a   a     s a    a  
s b   b     s b    b  empty  set similarity zero  finally  mapping
problem i  output map mr maximizes sum relational similarities 

mr   arg max

x

x

simr  ai   aj    ai      aj   

    

p  a b  i   j i  

simplified form lra used calculate simr differs lra used turney
       several ways  lrme  use synonyms generate alternate forms
pairs terms  lrme  morphological processing terms  lrme uses
ppmic  bullinaria   levy        process raw frequencies  instead log entropy 
following turney         lrme uses slightly different search template      lrme
sets number columns nc tnr   instead using constant  section     
evaluate impact two changes  ppmic nc    tested
changes  mainly motivated desire increased efficiency
simplicity 
    experiments
implemented lrme perl  making external calls wumpus searching corpus
svdlibc calculating svd  used perl net  telnet package interprocess
   svdlibc work doug rohde available http   tedlab mit edu dr svdlibc  

   

fithe latent relation mapping engine

communication wumpus  pdl  perl data language  package matrix manipulations  e g   calculating cosines   list  permutor package generate permutations
 i e   loop p  a  b   
ran following experiments dual core amd opteron    computer  running
   bit linux  running time spent searching corpus phrases  took
   hours    minutes wumpus fetch           phrases  remaining steps
took    minutes  svd took    minutes  running time could cut half
using raid   speed disk access 
table   shows performance lrme baseline configuration  comparison 
agreement    volunteers intended mapping copied table   
difference performance lrme         human participants
        statistically significant  paired t test      confidence level  

mapping
a 
a 
a 
a 
a 
a 
a 
a 
a 
a  
m 
m 
m 
m 
m 
m 
m 
m 
m 
m  
average

source target
solar system atom
water flow heat transfer
waves sounds
combustion respiration
sound light
projectile planet
artificial selection natural selection
billiard balls gas molecules
computer mind
slot machine bacterial mutation
war argument
buying item accepting belief
grounds building reasons theory
impediments travel difficulties
money time
seeds ideas
machine mind
object idea
following understanding
seeing understanding

accuracy
lrme humans
     
    
     
    
     
    
     
    
    
    
     
    
    
    
     
    
    
    
     
    
    
    
     
    
     
    
     
     
     
    
     
    
     
    
    
    
     
    
     
    
    
    

table    lrme baseline configuration  compared human performance 
table    column labeled humans average    people  whereas lrme
column one algorithm  it average   comparing average several scores
individual score  whether individual human algorithm  may give
misleading impression  results individual person  typically several
     scores scores        range  average mapping problem seven
terms  possible exactly one term mapped incorrectly 
incorrect mappings  must two incorrect mappings  follows
nature bijections  therefore score             uncommon 
   

fiturney

table   looks results another perspective  column labeled lrme wrong
gives number incorrect mappings made lrme twenty problems 
five columns labeled number people n wrong show  various values n  
may    people made n incorrect mappings  average mapping problem 
      participants perfect score  n       remaining   participants   
made two mistakes  n       table   shows clearly table   lrmes
performance significantly different  individual  human performance   for yet
another perspective  see section      

mapping
a 
a 
a 
a 
a 
a 
a 
a 
a 
a  
m 
m 
m 
m 
m 
m 
m 
m 
m 
m  
average

lrme
wrong
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

number people n wrong
n    n    n    n    n  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 


 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

table    another way viewing lrme versus human performance 
table    examine sensitivity lrme parameter settings  first row
shows accuracy baseline configuration  table    next eight rows show
impact varying k  dimensionality truncated singular value decomposition 
        eight rows show effect varying t  column factor 
      number columns matrix  nc   given number rows  nr
         multiplied t  second last row shows effect eliminating singular
value decomposition lrme  equivalent setting k        number
rows matrix  final row gives result ppmic  bullinaria   levy 
      replaced log entropy  turney         lrme sensitive
manipulations  none variations table   perform significantly differently
baseline configuration  paired t test      confidence level    this necessarily mean
manipulations effect  rather  suggests larger sample problems
would needed show significant effect  
   

fithe latent relation mapping engine

experiment
baseline configuration

varying k

varying

dropping svd
log entropy

k
   
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
    
   


  
  
  
  
  
  
  
  
  
 
  
  
  
  
  
  
  
  
  

nc
      
      
      
      
      
      
      
      
      
     
      
      
      
      
      
      
      
      
      

accuracy
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    exploring sensitivity lrme various parameter settings modifications 

   attribute mapping approaches
section  explore variety attribute mapping approaches twenty mapping
problems  approaches seek mapping maximizes sum
attributional similarities 
  arg max


x

sima  ai    ai   

    

p  a b  i  

search exhaustively evaluating possibilities  ties broken randomly  use variety different algorithms calculate sima  
    algorithms
following experiments  test five lexicon based attributional similarity measures
use wordnet   hso  hirst   st onge         jc  jiang   conrath         lc  leacock   chodrow         lin  lin         res  resnik         five implemented
perl package wordnet  similarity   builds wordnet  querydata  package  core idea behind treat wordnet graph measure semantic
distance two terms length shortest path graph 
similarity increases distance decreases 
   wordnet developed team princeton available http   wordnet princeton edu  
   ted pedersens wordnet  similarity package http   www d umn edu tpederse similarity html 
   jason rennies wordnet  querydata package http   people csail mit edu jrennie wordnet  

   

fiturney

hso works nouns  verbs  adjectives  adverbs  jc  lc  lin  res
work nouns verbs  used wordnet  similarity try possible parts speech
possible senses input word  many adjectives  true valuable 
noun verb senses wordnet  jc  lc  lin  res still able
calculate similarity them  raw form word found wordnet 
wordnet  similarity searches morphological variations word 
multiple similarity scores  multiple parts speech multiple senses  select
highest similarity score  similarity score  word wordnet 
jc  lc  lin  res could find alternative noun verb form
adjective adverb  set score zero 
evaluate two corpus based attributional similarity measures  pmi ir  turney 
      lsa  landauer   dumais         core idea behind word
characterized company keeps  firth         similarity two terms
measured similarity statistical distributions corpus  used corpus
section   along wumpus implement pmi ir  pointwise mutual information
information retrieval   lsa  latent semantic analysis   used online
demonstration    selected matrix comparison option general reading
 st year college      factors  topic space term to term comparison type  pmi ir
lsa work parts speech 
eighth similarity measure based observation intended mappings
map terms part speech  see appendix a   let pos a  partof speech tag assigned term a  use part of speech tags define measure
attributional similarity  simpos  a  b   follows 

      b
   pos a    pos b 
    
simpos  a  b   

  otherwise
hand labeled terms mapping problems part of speech tags  santorini 
       automatic taggers assume words tagged embedded
sentence  terms mapping problems sentences  tags
ambiguous  used knowledge intended mappings manually disambiguate
part of speech tags terms  thus guaranteeing corresponding terms
intended mapping always tags 
first seven attributional similarity measures above  created seven
similarity measures combining simpos  a  b   example  let simhso  a  b 
hirst st onge        similarity measure  combine simpos  a  b  simhso  a  b 
simply adding them 
simhso pos  a  b    simhso  a  b    simpos  a  b 

    

values returned simpos  a  b  range        whereas values returned
simhso  a  b  much smaller  chose large values      getting pos tags
match weight similarity measures  manual pos tags
    online demonstration lsa work team university colorado boulder 
available http   lsa colorado edu  

   

fithe latent relation mapping engine

high weight simpos  a  b  give unfair advantage attributional mapping
approach  relational mapping approach afford generous 
    experiments
table   presents accuracy various measures attributional similarity 
best result without pos labels        hso   best result pos labels      
 lin pos         accuracy lrme  see table    significantly higher
      accuracy lin pos  and thus  course  significantly higher everything else
table    paired t test      confidence level   average human performance      
 see table    significantly higher       accuracy lin pos  paired t test 
    confidence level   summary  humans lrme perform significantly better
variations attributional mapping approaches tested 
algorithm
hso
jc
lc
lin
res
pmi ir
lsa
pos  hand labeled 
hso pos
jc pos
lc pos
lin pos
res pos
pmi ir pos
lsa pos

reference
hirst st onge       
jiang conrath       
leacock chodrow       
lin       
resnik       
turney       
landauer dumais       
santorini       
hirst st onge       
jiang conrath       
leacock chodrow       
lin       
resnik       
turney       
landauer dumais       

accuracy
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    accuracy attribute mapping approaches wide variety measures
attributional similarity 

   discussion
section  examine three questions suggested preceding results 
difference science analogy problems common metaphor
problems  advantage combining relational attributional mapping approaches  advantage relational mapping approach attributional
mapping approach 
    science analogies versus common metaphors
table   suggests science analogies may difficult common metaphors 
supported table     shows agreement    participants
intended mapping  see section    varies science problems metaphor
   

fiturney

problems  science problems lower average performance greater variation
performance  difference science problems metaphor problems
statistically significant  paired t test      confidence level  
participant
 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
average
standard deviation

  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
   

average accuracy
   science    metaphor
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
   

table     comparison difficulty science problems versus metaphor problems    participants  numbers bold font scores
scores lrme 
average science problem terms       average metaphor problem
       might contribute difficulty science problems  however  table   
shows clear relation number terms problem  m
table    level agreement  believe people find metaphor problems
easier science problems common metaphors entrenched
language  whereas science analogies peripheral 
table    shows    algorithms studied perform slightly worse science
problems metaphor problems  difference statistically significant
 paired t test      confidence level   hypothesize attributional mapping approaches performing well enough sensitive subtle differences science
analogies common metaphors 
incidentally  tables give us another view performance lrme comparison human performance  first row table    shows performance lrme
   

fithe latent relation mapping engine

num terms
 
 
 
 
 

agreement
    
    
    
    
    

table     average agreement among    participants function number
terms problems 

algorithm
lrme
hso
jc
lc
lin
res
pmi ir
lsa
pos
hso pos
jc pos
lc pos
lin pos
res pos
pmi ir pos
lsa pos
average
standard deviation

  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

average accuracy
   science    metaphor
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table     comparison difficulty science problems versus metaphor problems    algorithms 

science metaphor problems  table     marked bold font cases
human scores greater lrmes scores     problems   
cases     science problems    cases     metaphor problems     cases  evidence lrmes performance
significantly different human performance  lrme near middle range
performance    human participants 
    hybrid relational attributional approaches
recall definitions scorer  m   scorea  m   given section   
   

fiturney

scorer  m    
scorea  m    

x

x

simr  ai   aj    ai      aj   

i   j i  

x

sima  ai    ai   

    

    

i  

combine scores simply adding multiplying them  scorer  m  
scorea  m   may quite different scales distributions values  therefore
first normalize probabilities 
scorer  m  
mi p  a b  scorer  mi  

    

scorea  m  
mi p  a b  scorea  mi  

    

probr  m     p
proba  m     p

probability estimates  assume scorer  m     scorea  m     
necessary  constant value may added scores  ensure negative 
combine scores adding multiplying probabilities 


mr a   arg max probr  m     proba  m  

    

p  a b 



mra   arg max probr  m   proba  m  

    

p  a b 

table    shows accuracy lrme combined lin pos  the best attributional mapping algorithm table    accuracy        hso  the best
attributional mapping algorithm use manual pos tags  accuracy
        try adding multiplying probabilities  own  lrme
accuracy        combining lrme lin pos increases accuracy       
improvement statistically significant  paired t test      confidence level   combining lrme hso results decrease accuracy  decrease significant
probabilities multiplied          significant probabilities
added         
summary  experiments show significant advantage combining lrme
attributional mapping  however  possible larger sample problems would
show significant advantage  also  combination methods explored  addition
multiplication probabilities  elementary  sophisticated approach 
weighted combination  may perform better 
    coherent relations
hypothesize lrme benefits kind coherence among relations 
hand  attributional mapping approaches involve kind coherence 
   

fithe latent relation mapping engine

components
relational attributional
lrme
lin pos
lrme
lin pos
lrme
hso
lrme
hso

combination
add probabilities
multiply probabilities
add probabilities
multiply probabilities

accuracy
    
    
    
    

table     performance four different hybrids relational attributional mapping
approaches 

suppose swap two terms mapping  let original mapping
let   new mapping     a       a        a       a        ai      ai  
     attributional similarity  impact swap score mapping
limited  part score affected 

scorea  m     sima  a     a       sima  a     a      


x

sima  ai    ai   

    

sima  ai    ai   

    

i  

scorea  m       sima  a     a       sima  a     a      


x
i  

hand  relational similarity  impact swap limited
way  change part mapping affects whole score  kind global
coherence relational similarity lacking attributional similarity 
testing hypothesis lrme benefits coherence somewhat complicated 
need design experiment coherence effect isolated
effects  this  move terms outside accuracy calculation 
let   b one twenty mapping problems  intended
mapping    a     b   let a  randomly selected subset size m    let b  
 a     subset b maps a   

a 

    

 

b b
 

    
 

b    a  

m    a    b  
 

 m

    
    
    

two ways might use lrme generate mapping     a  b  
new reduced mapping problem  internal coherence total coherence 
   internal coherence  select   based ha    b   alone 
   

fiturney

a     a         am   

    

 

b    b         bm   

    
m 

    arg max

m 

x x

p  a   b     i   j i  

simr  ai   aj    ai      aj   

    

case    chosen based relations internal ha    b   i 
   total coherence  select   based ha  bi knowledge  
must satisfy constraint    a      b      this knowledge embedded
internal coherence  

   a          

    

b    b         bm  


p  a  b      p  a  b   a      b  
x

x
 
  arg max
simr  ai   aj    ai      aj   
 

    
    
    

p    a b  i   j i  

case    chosen using relations internal ha    b  
relations ha  bi external ha    b   i 

suppose calculate accuracy two methods based subproblem ha    b   i  first might seem advantage total coherence 
must explore larger space possible mappings internal coherence  since
 p    a  b   larger  p  a    b        additional terms explores
involved calculating accuracy  however  hypothesize total coherence
higher accuracy internal coherence  additional external relations
help select correct mapping 
test hypothesis  set m    randomly generated ten new reduced
mapping problems twenty problems  i e   total     new problems size
    average accuracy internal coherence        whereas average accuracy
total coherence        difference statistically significant  paired t test     
confidence level  
hand  attributional mapping approaches cannot benefit total
coherence  connection attributes ha    b  
attributes outside  decompose scorea  m   two independent parts 
   

fithe latent relation mapping engine

a       a 
 

    
  

a a


p  a  b      p  a  b   a      b  
x
    arg max
sima  ai    ai   

    

 

    
    

p    a b 



  arg max
p    a b 


x

ai

sima  ai    ai     

a 

x
ai

sima  ai    ai   

    

a  

two parts optimized independently  thus terms external
ha    b   influence part   covers ha    b   i 
relational mapping cannot decomposed independent parts way 
relations connect parts  gives relational mapping approaches inherent
advantage attributional mapping approaches 
confirm analysis  compared internal total coherence using lin pos
    new problems size    average accuracy internal coherence
       whereas average accuracy total coherence        difference
statistically significant  paired t test      confidence level    the reason
difference that  two mappings score  break ties randomly 
causes random variation accuracy  
benefit coherence suggests make analogy mapping problems easier
lrme adding terms  difficulty new terms cannot randomly
chosen  must fit logic analogy overlap existing terms 
course  important difference relational attributional mapping approaches  believe important difference relations
reliable general attributes  using past experiences make
predictions future  hofstadter        gentner         unfortunately  hypothesis difficult evaluate experimentally hypothesis coherence 

    related work
french        gives good survey computational approaches analogy making 
perspective cognitive science  where emphasis well computational systems
model human performance  rather well systems perform   sample
systems survey add mentioned 
french        categorizes analogy making systems symbolic  connectionist  symbolicconnectionist hybrids  gardenfors        proposes another category representational
systems ai cognitive science  calls conceptual spaces  spatial geometric systems common information retrieval machine learning  widdows       
van rijsbergen         influential example latent semantic analysis  landauer  
dumais         first spatial approaches analogy making began appear around
time frenchs        survey  lrme takes spatial approach analogy making 
   

fiturney

     symbolic approaches
computational approaches analogy making date back analogy  evans       
argus  reitman         systems designed solve proportional analogies
 analogies  a     b       see section     analogy could solve proportional
analogies simple geometric figures argus could solve simple word analogies 
systems used hand coded rules able solve limited range problems
designers anticipated coded rules 
french        cites structure mapping theory  smt   gentner        structure
mapping engine  sme   falkenhainer et al         prime examples symbolic
approaches 
smt unquestionably influential work date modeling
analogy making applied wide range contexts ranging
child development folk physics  smt explicitly shifts emphasis analogymaking structural similarity source target domains  two
major principles underlie smt 
relation matching principle  good analogies determined mappings relations attributes  originally identical predicates
mapped 
systematicity principle  mappings coherent systems relations
preferred mappings individual relations 
structural approach intended produce domain independent mapping process 
lrme follows principles  lrme uses relational similarity  attributional similarity involved  see section       coherent systems relations preferred
mappings individual relations  see section       however  spatial  statistical 
corpus based  approach lrme quite different symbolic  logical  hand coded 
approach sme 
martin        uses symbolic approach handle conventional metaphors  gentner 
bowdle  wolff  boronat        argue novel metaphors processed analogies 
conventional metaphors recalled memory without special processing  however 
line conventional novel metaphor unclear 
dolan        describes algorithm extract conventional metaphors
dictionary  semantic parser used extract semantic relations longman
dictionary contemporary english  ldoce   symbolic algorithm finds metaphorical
relations words  using extracted relations 
veale              developed symbolic approach analogy making  using wordnet lexical resource  using spreading activation algorithm  achieved score
      set     multiple choice lexical proportional analogy questions sat
college entrance test  veale        
lepage        demonstrated symbolic approach proportional analogies
used morphology processing  lepage denoual        apply similar approach
machine translation 
   

fithe latent relation mapping engine

     connectionist approaches
connectionist approaches analogy making include acme  holyoak   thagard       
lisa  hummel   holyoak         symbolic approaches  systems use handcoded knowledge representations  search mappings takes connectionist approach  nodes weights incrementally updated time 
system reaches stable state 
     symbolic connectionist hybrid approaches
third family examined french        hybrid approaches  containing elements
symbolic connectionist approaches  examples include copycat  mitchell 
      tabletop  french         much work fluid analogies research
group  farg  concerns symbolic connectionist hybrids  hofstadter   farg        
     spatial approaches
marx  dagan  buhmann  shamir        present coupled clustering algorithm 
uses feature vector representation find analogies collections text  example 
given documents buddhism christianity  finds related terms   school 
mahayana  zen  buddhism  tradition  catholic  protestant  christianity 
mason        describes cormet system extracting conventional metaphors
text  cormet based clustering feature vectors represent selectional preferences
verbs  given keywords source domain laboratory target domain finance 
able discover mappings liquid income container institution 
turney  littman  bigham  shnayder        present system solving lexical
proportional analogy questions sat college entrance test  combines thirteen
different modules  twelve modules use either attributional similarity symbolic
approach relational similarity  one module uses spatial  feature vector  approach
measuring relational similarity  module worked much better
modules  therefore  studied detail turney littman        
relation pair words represented vector  elements pattern
frequencies  similar lrme  one important difference turney
littman        used fixed  hand coded set     patterns  whereas lrme automatically
generates variable number patterns given corpus         patterns
experiments here  
turney        introduced latent relational analysis  lra   examined
thoroughly turney         lra achieves human level performance set    
multiple choice proportional analogy questions sat college entrance exam  lrme
uses simplified form lra  similar simplification lra used turney        
system processing analogies  synonyms  antonyms  associations  contribution
lrme go beyond proportional analogies  larger systems analogical mappings 
     general theories analogy metaphor
many theories analogy making metaphor either involve computation
suggest general principles concepts specific particular computational
   

fiturney

approach  design lrme influenced several theories type  gentner 
      hofstadter   farg        holyoak   thagard        hofstadter        gentner 
      
lakoff johnson        provide extensive evidence metaphor ubiquitous
language thought  believe system analogy making able
handle metaphorical language  ten analogy problems derived
lakoff johnson         agree claim metaphor merely
involve superficial relation couple words  rather  involves systematic set
mappings two domains  thus analogy problems involve larger sets words 
beyond proportional analogies 
holyoak thagard        argue analogy making central daily thought 
especially finding creative solutions new problems  ten scientific analogies
derived examples analogy making scientific creativity 

    limitations future work
section    mentioned ten applications lra  section   claimed
results experiments section     suggest lrme may perform better lra
ten applications  due ability handle bijective analogies     
focus future work testing hypothesis  particular  task semantic
role labeling  discussed section    seems good candidate application lrme 
input lrme simpler input sme  compare figures    
section   table     still human effort involved creating input 
lrme immune criticism chalmers  french  hofstadter        
human generates input work computer makes
mappings  although trivial matter find right mapping           
choices 
future work  would relax requirement ha  bi must bijection
 see section     adding irrelevant words  distractors  synonyms  mapping
algorithm forced decide terms include mapping terms
leave out 
would develop algorithm take proportional analogy  m     
input  e g   sun planet  nucleus electron  automatically expand larger analogy
 m      e g   table     is  would automatically search corpus new terms
add analogy 
next step would give computer topic source domain  e g  
solar system  topic target domain  e g   atomic structure   let work
rest own  might possible combining ideas lrme ideas
coupled clustering  marx et al         cormet  mason        
seems analogy making triggered people encounter problem
 holyoak   thagard         problem defines target us  immediately
start searching source  analogical mapping enables us transfer knowledge
source target  hopefully leading solution problem  suggests
input ideal analogical mapping algorithm would simply statement
   

fithe latent relation mapping engine

problem  e g   structure atom    ultimately  computer might
find problems well  input would large corpus 
algorithms considered perform exhaustive search set
possible mappings p  a  b   acceptable sets small  here 
problematic larger problems  future work  necessary use
heuristic search algorithms instead exhaustive search 
takes almost    hours lrme process twenty mapping problems  section    
better hardware changes software  time could significantly
reduced  even greater speed  algorithm could run continuously  building large
database vector representations term pairs  ready create mappings
soon user requests them  similar vision banko etzioni        
lrme  lra lsa  landauer   dumais         uses truncated singular value
decomposition  svd  smooth matrix  many algorithms proposed
smoothing matrices  past work lra  turney         experimented
nonnegative matrix factorization  nmf   lee   seung         probabilistic latent semantic analysis  plsa   hofmann         iterative scaling  is   ando         kernel
principal components analysis  kpca   scholkopf  smola    muller        
interesting results small matrices  around             none algorithms
seemed substantially better truncated svd  none scaled matrix
sizes                 however  believe svd unique 
future work likely discover smoothing algorithm efficient effective
svd  results section     show significant benefit svd  table  
hints ppmic  bullinaria   levy        important svd 
lrme extracts knowledge many fragments text  section      noted
found average       phrases per pair  information      
phrases combined vector  represent semantic relation pair 
quite different relation extraction  for example  automatic content extraction
 ace  evaluation    task ace identify label semantic relation single
sentence  semantic role labeling involves labeling single sentence  gildea   jurafsky 
      
contrast lrme ace analogous distinction cognitive
psychology semantic episodic memory  episodic memory memory
specific event ones personal past  whereas semantic memory memory basic facts
concepts  unrelated specific event past  lrme extracts relational information
independent specific sentence  semantic memory  ace concerned
extracting relation specific sentence  episodic memory  cognition  episodic
memory semantic memory work together synergistically  experience event 
use semantic memory interpret event form new episodic memory 
semantic memory constructed past experiences  accumulated
episodic memories  suggests synergy combining lrme like
semantic information extraction algorithms ace like episodic information extraction
algorithms 
    ace annual event began       relation detection characterization  rdc 
introduced ace       information  see http   www nist gov speech tests ace  

   

fiturney

    conclusion
analogy core cognition  understand present analogy past 
predict future analogy past present  solve problems searching
analogous situations  holyoak   thagard         daily language saturated
metaphor  lakoff   johnson         metaphor based analogy  gentner et al  
       understand human language  solve human problems  work humans 
computers must able make analogical mappings 
best theory analogy making structure mapping theory  gentner        
structure mapping engine  falkenhainer et al         puts much burden
analogy making human users  chalmers et al          lrme attempt
shift burden onto computer  remaining consistent general
principles smt 
shown lrme able solve bijective analogical mapping problems
human level performance  attributional mapping algorithms  at least  tried
far  able reach level  supports smt  claims relations
important attributes making analogical mappings 
still much research done  lrme takes load human
user  formulating input lrme easy  paper incremental step
towards future computers make surprising useful analogies minimal
human assistance 

acknowledgments
thanks colleagues institute information technology participating
experiment section    thanks charles clarke egidio terra corpus 
thanks stefan buttcher making wumpus available giving advice use 
thanks doug rohde making svdlibc available  thanks wordnet team
princeton university wordnet  ted pedersen wordnet  similarity perl package 
jason rennie wordnet  querydata perl package  thanks lsa team
university colorado boulder use online demonstration lsa 
thanks deniz yuret  andre vellino  dedre gentner  vivi nastase  yves lepage  diarmuid
seaghdha  roxana girju  chris drummond  howard johnson  stan szpakowicz 
anonymous reviewers jair helpful comments suggestions 

appendix a  details mapping problems
appendix  provide detailed information twenty mapping problems 
figure   shows instructions given participants experiment
section    instructions displayed web browsers  tables            
   show twenty mapping problems  first column gives problem number
 e g   a   mnemonic summarizes mapping  e g   solar system atom  
second column gives source terms third column gives target terms 
mappings shown tables intended mappings  fourth column
shows percentage participants agreed intended mappings  example 
   

fithe latent relation mapping engine

systematic analogies metaphors
instructions
presented twenty analogical mapping problems  ten based scientific
analogies ten based common metaphors  typical problem look this 
horse
legs
hay
brain
dung













 
 
 
 
 

may click drop down menus above  see options available 
task construct analogical mapping  is  one to one mapping
items left items right  example 
horse
legs
hay

car
wheels
gasoline





brain
dung

driver
exhaust




mapping expresses analogy horse car  horses legs
cars wheels  horse eats hay car consumes gasoline  horses brain controls
movement horse cars driver controls movement car  horse
generates dung waste product car generates exhaust waste product 
duplicate items answers right hand side 
duplicates missing items  question marks   get error message
submit answer 
welcome use dictionary work problems  would find
helpful 
find instructions unclear  please continue exercise 
answers twenty problems used standard evaluating output
computer algorithm  therefore  proceed confident
understand task 
figure    instructions participants experiment section   

   

fiturney

mapping
a 
solar system
atom

a 
water flow
heat transfer

a 
waves
sounds

a 
combustion
respiration

a 
sound
light

source
solar system
sun
planet
mass
attracts
revolves
gravity
average agreement 
water
flows
pressure
water tower
bucket
filling
emptying
hydrodynamics
average agreement 
waves
shore
reflects
water
breakwater
rough
calm
crashing
average agreement 
combustion
fire
fuel
burning
hot
intense
oxygen
carbon dioxide
average agreement 
sound
low
high
echoes
loud
quiet
horn
average agreement 










target
atom
nucleus
electron
charge
attracts
revolves
electromagnetism










heat
transfers
temperature
burner
kettle
heating
cooling
thermodynamics










sounds
wall
echoes
air
insulation
loud
quiet
vibrating










respiration
animal
food
breathing
living
vigorous
oxygen
carbon dioxide









light
red
violet
reflects
bright
dim
lens

agreement
    
     
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     
    
    
    
    

pos
nn
nn
nn
nn
vbz
vbz
nn
nn
vbz
nn
nn
nn
vbg
vbg
nn
nns
nn
vbz
nn
nn
jj
jj
vbg
nn
nn
nn
vbg
jj
jj
nn
nn
nn
jj
jj
vbz
jj
jj
nn

table     science analogy problems a  a   derived chapter   holyoak
thagard        

   

fithe latent relation mapping engine

mapping
a 
projectile
planet

a 
artificial selection
natural selection

a 
billiard balls
gas molecules

a 
computer
mind

a  
slot machine
bacterial mutation

source
projectile
trajectory
earth
parabolic
air
gravity
attracts
average agreement 
breeds
selection
conformance
artificial
popularity
breeding
domesticated
average agreement 
balls
billiards
speed
table
bouncing
moving
slow
fast
average agreement 
computer
processing
erasing
write
read
memory
outputs
inputs
bug
average agreement 
slot machines
reels
spinning
winning
losing
average agreement 










target
planet
orbit
sun
elliptical
space
gravity
attracts









species
competition
adaptation
natural
fitness
mating
wild










molecules
gas
temperature
container
pressing
moving
cold
hot











mind
thinking
forgetting
memorize
remember
memory
muscles
senses
mistake







bacteria
genes
mutating
reproducing
dying

agreement
     
     
     
     
     
    
    
    
     
    
    
    
    
    
    
    
    
    
    
    
    
    
     
     
    
    
    
     
    
    
    
    
    
     
    
    
    
    
    
     
    

pos
nn
nn
nn
jj
nn
nn
vbz
nns
nn
nn
jj
nn
vbg
jj
nns
nn
nn
nn
vbg
vbg
jj
jj
nn
vbg
vbg
vb
vb
nn
nns
nns
nn
nns
nns
vbg
vbg
vbg

table     science analogy problems a  a    derived chapter   holyoak
thagard        

   

fiturney

mapping
m 
war
argument

m 
buying item
accepting belief

m 
grounds building
reasons theory

m 
impediments travel
difficulties

m 
money
time

source
war
soldier
destroy
fighting
defeat
attacks
weapon
average agreement 
buyer
merchandise
buying
selling
returning
valuable
worthless
average agreement 
foundations
buildings
supporting
solid
weak
crack
average agreement 
obstructions
destination
route
traveller
travelling
companion
arriving
average agreement 
money
allocate
budget
effective
cheap
expensive
average agreement 










target
argument
debater
refute
arguing
acceptance
criticizes
logic









believer
belief
accepting
advocating
rejecting
true
false








reasons
theories
confirming
rational
dubious
flaw









difficulties
goal
plan
person
problem solving
partner
succeeding








time
invest
schedule
efficient
quick
slow

agreement
    
     
    
    
    
    
    
    
     
    
    
     
    
    
    
    
    
    
    
    
    
    
    
     
     
     
     
     
     
     
     
    
    
    
    
    
    
    

pos
nn
nn
vb
vbg
nn
vbz
nn
nn
nn
vbg
vbg
vbg
jj
jj
nns
nns
vbg
jj
jj
nn
nns
nn
nn
nn
vbg
nn
vbg
nn
vb
nn
jj
jj
jj

table     common metaphor problems m  m   derived lakoff johnson        

   

fithe latent relation mapping engine

mapping
m 
seeds
ideas

m 
machine
mind

m 
object
idea

m 
following
understanding

m  
seeing
understanding

source
seeds
planted
fruitful
fruit
grow
wither
blossom
average agreement 
machine
working
turned
turned
broken
power
repair
average agreement 
object
hold
weigh
heavy
light
average agreement 
follow
leader
path
follower
lost
wanders
twisted
straight
average agreement 
seeing
light
illuminating
darkness
view
hidden
average agreement 










target
ideas
inspired
productive
product
develop
fail
succeed









mind
thinking
awake
asleep
confused
intelligence
therapy







idea
understand
analyze
important
trivial










understand
speaker
argument
listener
misunderstood
digresses
complicated
simple








understanding
knowledge
explaining
confusion
interpretation
secret

agreement
    
    
    
    
    
     
    
    
    
     
     
     
     
    
     
    
    
    
    
    
    
    
     
     
     
     
    
    
    
     
    
    
    
    
    
    
    
    

pos
nns
vbd
jj
nn
vb
vb
vb
nn
vbg
jj
jj
jj
nn
nn
nn
vb
vb
jj
jj
vb
nn
nn
nn
jj
vbz
jj
jj
vbg
nn
vbg
nn
nn
jj

table     common metaphor problems m  m    derived lakoff johnson
       

   

fiturney

problem a         participants         mapped gravity electromagnetism 
final column gives part of speech  pos  tags source target terms 
used penn treebank tags  santorini         assigned tags manually 
intended mappings tags chosen mapped terms tags 
example  a   sun maps nucleus  sun nucleus tagged nn 
pos tags used experiments section    pos tags used lrme
shown participants experiment section   

references
ando  r  k          latent semantic space  iterative scaling improves precision interdocument similarity measurement  proceedings   rd annual acm sigir
conference research development information retrieval  sigir        pp 
       
banko  m     etzioni  o          strategies lifelong knowledge extraction web 
proceedings  th international conference knowledge capture  k cap
       pp        
bullinaria  j     levy  j          extracting semantic representations word cooccurrence statistics  computational study  behavior research methods         
       
buttcher  s     clarke  c          efficiency vs  effectiveness terabyte scale information retrieval  proceedings   th text retrieval conference  trec       
gaithersburg  md 
chalmers  d  j   french  r  m     hofstadter  d  r          high level perception  representation  analogy  critique artificial intelligence methodology  journal
experimental   theoretical artificial intelligence                
deerwester  s  c   dumais  s  t   landauer  t  k   furnas  g  w     harshman  r  a 
        indexing latent semantic analysis  journal american society
information science  jasis                  
dolan  w  b          metaphor emergent property machine readable dictionaries  proceedings aaai      spring symposium series  representation
acquisition lexical knowledge  polysemy  ambiguity generativity  pp       
evans  t          heuristic program solve geometric analogy problems  proceedings
spring joint computer conference  pp         
falkenhainer  b   forbus  k  d     gentner  d          structure mapping engine 
algorithm examples  artificial intelligence              
firth  j  r          synopsis linguistic theory           studies linguistic
analysis  pp       blackwell  oxford 
forbus  k   usher  j   lovett  a   lockwood  k     wetzel  j          cogsketch  opendomain sketch understanding cognitive science research education 
proceedings fifth eurographics workshop sketch based interfaces modeling  annecy  france 
   

fithe latent relation mapping engine

forbus  k  d   riesbeck  c   birnbaum  l   livingston  k   sharma  a     ureel  l         
prototype system learns reading simplified texts  aaai spring symposium
machine reading  stanford university  california 
french  r          subtlety sameness  theory computer model analogymaking  mit press  cambridge  ma 
french  r  m          computational modeling analogy making  trends cognitive
sciences                
gardenfors  p          conceptual spaces  geometry thought  mit press 
gentner  d          structure mapping  theoretical framework analogy  cognitive
science                
gentner  d          language career similarity  gelman  s     byrnes  j 
 eds    perspectives thought language  interrelations development  pp 
        cambridge university press 
gentner  d          smart  gentner  d     goldin meadow  s   eds   
language mind  advances study language thought  pp         
mit press 
gentner  d   bowdle  b  f   wolff  p     boronat  c          metaphor analogy 
gentner  d   holyoak  k  j     kokinov  b  n   eds    analogical mind  perspectives cognitive science  pp          mit press  cambridge  ma 
gildea  d     jurafsky  d          automatic labeling semantic roles  computational
linguistics                 
girju  r   nakov  p   nastase  v   szpakowicz  s   turney  p     yuret  d          semeval     task     classification semantic relations nominals  proceedings
fourth international workshop semantic evaluations  semeval        pp 
      prague  czech republic 
golub  g  h     van loan  c  f          matrix computations  third edition   johns
hopkins university press  baltimore  md 
hawkins  j     blakeslee  s          intelligence  henry holt 
hirst  g     st onge  d          lexical chains representations context detection
correction malapropisms  fellbaum  c   ed    wordnet  electronic
lexical database  pp          mit press 
hofmann  t          probabilistic latent semantic indexing  proceedings   nd
annual acm conference research development information retrieval  sigir      pp        berkeley  california 
hofstadter  d          epilogue  analogy core cognition  gentner  d   holyoak 
k  j     kokinov  b  n   eds    analogical mind  perspectives cognitive
science  pp          mit press 
hofstadter  d     farg         fluid concepts creative analogies  computer models
fundamental mechanisms thought  basic books  new york  ny 
   

fiturney

holyoak  k     thagard  p          analogical mapping constraint satisfaction  cognitive
science             
holyoak  k     thagard  p          mental leaps  mit press 
hummel  j     holyoak  k          distributed representations structure  theory
analogical access mapping  psychological review              
jiang  j  j     conrath  d  w          semantic similarity based corpus statistics
lexical taxonomy  proceedings international conference research
computational linguistics  rocling x   pp        tapei  taiwan 
kilgarriff  a          dont believe word senses  computers humanities     
      
lakoff  g     johnson  m          metaphors live by  university chicago press 
landauer  t  k     dumais  s  t          solution platos problem  latent semantic analysis theory acquisition  induction  representation knowledge 
psychological review                  
leacock  c     chodrow  m          combining local context wordnet similarity
word sense identification  fellbaum  c   ed    wordnet  electronic lexical
database  mit press 
lee  d  d     seung  h  s          learning parts objects nonnegative matrix
factorization  nature              
lepage  y          solving analogies words  algorithm  proceedings   th
annual conference association computational linguistics  pp         
lepage  y     denoual  e          purest ever example based machine translation  detailed
presentation assessment  machine translation                 
lin  d          information theoretic definition similarity  proceedings   th
international conference machine learning  icml     
martin  j  h          computer understanding conventional metaphoric language  cognitive science                 
marx  z   dagan  i   buhmann  j     shamir  e          coupled clustering  method
detecting structural correspondence  journal machine learning research    
       
mason  z          cormet  computational  corpus based conventional metaphor extraction system  computational linguistics               
minsky  m          society mind  simon   schuster  new york  ny 
mitchell  m          analogy making perception  computer model  mit press  cambridge  ma 
nastase  v     szpakowicz  s          exploring noun modifier semantic relations 
fifth international workshop computational semantics  iwcs     pp         
tilburg  netherlands 
reitman  w  r          cognition thought  information processing approach  john
wiley sons  new york  ny 
   

fithe latent relation mapping engine

resnik  p          using information content evaluate semantic similarity taxonomy 
proceedings   th international joint conference artificial intelligence
 ijcai      pp          san mateo  ca  morgan kaufmann 
rosario  b     hearst  m          classifying semantic relations noun compounds
via domain specific lexical hierarchy  proceedings      conference
empirical methods natural language processing  emnlp      pp       
santorini  b          part of speech tagging guidelines penn treebank project  tech 
rep   department computer information science  university pennsylvania 
  rd revision   nd printing  
scholkopf  b   smola  a  j     muller  k  r          kernel principal component analysis 
proceedings international conference artificial neural networks  icann       pp          berlin 
turney  p  d          mining web synonyms  pmi ir versus lsa toefl 
proceedings twelfth european conference machine learning  ecml     
pp          freiburg  germany 
turney  p  d          measuring semantic similarity latent relational analysis  proceedings nineteenth international joint conference artificial intelligence
 ijcai      pp            edinburgh  scotland 
turney  p  d          similarity semantic relations  computational linguistics         
       
turney  p  d          uniform approach analogies  synonyms  antonyms  associations  proceedings   nd international conference computational
linguistics  coling        pp          manchester  uk 
turney  p  d     littman  m  l          corpus based learning analogies semantic
relations  machine learning                  
turney  p  d   littman  m  l   bigham  j     shnayder  v          combining independent
modules solve multiple choice synonym analogy problems  proceedings
international conference recent advances natural language processing
 ranlp      pp          borovets  bulgaria 
van rijsbergen  c  j          geometry information retrieval  cambridge university
press  cambridge  uk 
veale  t          analogical thesaurus  proceedings   th innovative applications artificial intelligence conference  iaai        pp          acapulco 
mexico 
veale  t          wordnet sits sat  knowledge based approach lexical analogy 
proceedings   th european conference artificial intelligence  ecai       
pp          valencia  spain 
widdows  d          geometry meaning  center study language
information  stanford  ca 
yan  j     forbus  k  d          similarity based qualitative simulation  proceedings
  th annual meeting cognitive science society  stresa  italy 

   


