journal artificial intelligence research                  

submitted        published      

anytime point based approximations large pomdps
joelle pineau

jpineau   cs   mcgill   ca

school computer science
mcgill university
montreal qc  h a  a  canada

geoffrey gordon

ggordon   cs   cmu   edu

machine learning department
carnegie mellon university
pittsburgh pa        usa

sebastian thrun

thrun   stanford   edu

computer science department
stanford university
stanford ca        usa

abstract
partially observable markov decision process long recognized rich framework real world planning control problems  especially robotics  however exact solutions framework typically computationally intractable smallest problems 
well known technique speeding pomdp solving involves performing value backups
specific belief points  rather entire belief simplex  efficiency approach 
however  depends greatly selection points  paper presents set novel techniques
selecting informative belief points work well practice  point selection procedure
combined point based value backups form effective anytime pomdp algorithm called
point based value iteration  pbvi   first aim paper introduce algorithm
present theoretical analysis justifying choice belief selection technique  second aim
paper provide thorough empirical comparison pbvi state of the art
pomdp methods  particular perseus algorithm  effort highlight similarities
differences  evaluation performed using standard pomdp domains realistic robotic
tasks 

   introduction
concept planning long tradition ai literature  fikes   nilsson        chapman 
      mcallester   roseblitt        penberthy   weld        blum   furst         classical
planning generally concerned agents operate environments fully observable 
deterministic  finite  static  discrete  techniques able solve increasingly
large state space problems  basic assumptions classical planningfull observability  static
environment  deterministic actionsmake unsuitable robotic applications 
planning uncertainty aims improve robustness explicitly reasoning type
uncertainty arise  partially observable markov decision process  pomdp   astrom 
      sondik        monahan        white        lovejoy      b  kaelbling  littman    cassandra        boutilier  dean    hanks        emerged possibly general representation
 single agent  planning uncertainty  pomdp supersedes frameworks terms
c
    
ai access foundation morgan kaufmann publishers  rights reserved 

fip ineau   g ordon   hrun

representational power simply combines essential features planning
uncertainty 
first  pomdps handle uncertainty action effects state observability  whereas many
frameworks handle neither these  handle stochastic action effects  handle partial state observability  plans expressed information states  instead world states 
since latter ones directly observable  space information states space
beliefs system might regarding world state  information states easily calculated
measurements noisy imperfect sensors  pomdps  information states typically
represented probability distributions world states 
second  many pomdp algorithms form plans optimizing value function  powerful approach plan optimization  since allows one numerically trade alternative
ways satisfy goal  compare actions different costs rewards  well plan multiple
interacting goals  value function optimization used planning approachesfor example markov decision processes  mdps   bellman       pomdps unique expressing
value function information states  rather world states 
finally  whereas classical conditional planners produce sequence actions  pomdps
produce full policy action selection  prescribes choice action possible
information state  producing universal plan  pomdps alleviate need re planning 
allow fast execution  naturally  main drawback optimizing universal plan computational complexity so  precisely seek alleviate work described
paper
known algorithms exact planning pomdps operate optimizing value function
possible information states  also known beliefs   algorithms run wellknown curse dimensionality  dimensionality planning problem directly related
number states  kaelbling et al          suffer lesser known curse
history  number belief contingent plans increases exponentially planning
horizon  fact  exact pomdp planning known pspace complete  whereas propositional
planning np complete  littman         result  many pomdp domains
states  actions sensor observations computationally intractable 
commonly used technique speeding pomdp solving involves selecting finite set
belief points performing value backups set  sondik        cheng        lovejoy 
    a  hauskrecht        zhang   zhang         usefulness belief point updates
well acknowledged  backups applied thoroughly
explored 
paper describes class point based value iteration  pbvi  pomdp approximations
value function estimated based strictly point based updates  context 
choice points integral part algorithm  approach interleaves value backups
steps belief point selection  one key contributions paper presentation
analysis set heuristics selecting informative belief points  range naive
version combines point based value updates random belief point selection  sophisticated algorithm combines standard point based value update estimate error
bound approximate exact solutions select belief points  empirical theoretical evaluation techniques reveals importance taking distance points
consideration selecting belief points  result approach exhibits good perfor   

fia nytime p oint based pproximations l arge pomdp

mance belief points  sometimes less number states   thereby overcoming
curse history 
pbvi class algorithms number important properties  discussed
greater length paper 
theoretical guarantees  present bound error value function obtained
point based approximation  respect exact solution  bound applies number
point based approaches  including pbvi  perseus  spaan   vlassis        
others 
scalability  able handle problems order     states  order magnitude larger problems solved traditional pomdp techniques 
empirical performance evaluated extensively realistic robot tasks  including search formissing person scenario 
wide applicability  approach makes assumptions nature structure
domain  pbvi framework assume known discrete state  action observation spaces
known model  i e   state to state transitions  observation probabilities  costs rewards  
additional specific structure  e g   constrained policy class  factored model  
anytime performance  anytime solution achieved gradually alternating phases
belief point selection phases point based value updates  allows effective
trade off planning time solution quality 
pbvi many important properties  number recent pomdp approaches exhibit competitive performance  braziunas   boutilier        poupart   boutilier 
      smith   simmons        spaan   vlassis         provide overview techniques later part paper  provide comparative evaluation algorithms
pbvi using standard pomdp domains  effort guide practitioners choice
algorithm  one algorithms  perseus  spaan   vlassis         closely related pbvi
design performance  therefore provide direct comparison two approaches
using realistic robot task  effort shed light comparative strengths weaknesses two approaches 
paper organized follows  section   begins exploring basic concepts pomdp
solving  including representation  inference  exact planning  section   presents general
anytime pbvi algorithm theoretical properties  section   discusses novel strategies select good belief points  section   presents empirical comparison pomdp algorithms using
standard simulation problems  section   pursues empirical evaluation tackling complex robot
domains directly comparing pbvi perseus  finally  section   surveys number existing
pomdp approaches closely related pbvi 

   review pomdps
partially observable markov decision processes provide general planning decision making
framework acting optimally partially observable domains  well suited great
number real world problems decision making required despite prevalent uncertainty 
generally assume complete correct world model  stochastic state transitions  imperfect state tracking  reward structure  given information  goal find action
   

fip ineau   g ordon   hrun

strategy maximizes expected reward gains  section first establishes basic terminology essential concepts pertaining pomdps  reviews optimal techniques pomdp
planning 
    basic pomdp terminology
formally  pomdp defined six distinct quantities  denoted  s  a  z  t  o  r   first three
are 
states  state world denoted s  finite set states denoted  
 s    s            state time denoted st   discrete time index  state
directly observable pomdps  agent compute belief state
space s 
observations  infer belief regarding worlds state s  agent take sensor measurements  set measurements  observations  denoted z    z    z           
observation time denoted zt   observation zt usually incomplete projection
world state st   contaminated sensor noise 
actions  act world  agent given finite set actions  denoted  
 a    a            actions stochastically affect state world  choosing right action
function history core problem pomdps 
throughout paper  assume states  actions observations discrete finite 
mathematical convenience  assume actions observations alternated
time 
fully define pomdp  specify probabilistic laws describe state transitions
observations  laws given following distributions 
state transition probability distribution 
 s  a  s       p r st   s    st    s  at    a  t 

   

probability transitioning state s    given agent state selects action a   s  a  s     since conditional probability distribution 
p
 
s   s  a          s  a   notation suggests  time invariant 
observation probability distribution 
o s  a  z     p r zt   z   st    s  at    a  t 

   

probability agent perceive observation z upon executing action state s 
p
conditional probability defined  s  a  z  triplets  zz o s  a  z   
    s  a   probability function time invariant 
finally  objective pomdp planning optimize action selection  agent given
reward function describing performance 
   

fia nytime p oint based pproximations l arge pomdp

reward function  r s  a       assigns numerical value quantifying
utility performing action state s  assume reward bounded  rmin  
r   rmax   goal agent collect much reward possible time 
precisely  wants maximize sum 
e 


x

tt  rt   

   

t t 

rt reward time t  e    mathematical expectation       
discount factor  ensures sum equation   finite 
items together  states s  actions a  observations z  reward r  probability
distributions  o  define probabilistic world model underlies pomdp 
    belief computation
pomdps instances markov processes  implies current world state  st   sufficient predict future  independent past  s    s         st     key characteristic
sets pomdps apart many probabilistic models  such mdps  fact state
st directly observable  instead  agent perceive observations  z            zt   
convey incomplete information worlds state 
given state directly observable  agent instead maintain complete trace
observations actions ever executed  use select actions  action observation trace known history  formally define
ht     a    z            zt    at    zt  

   

history time t 
history trace get long time goes on  well known fact history
need represented explicitly  instead summarized via belief distribution  astrom         following posterior probability distribution 
bt  s     p r st     zt   at    zt            a    b    

   

course requires knowing initial state probability distribution 
b   s     p r s    s  

   

defines probability domain state time      common either
specify initial belief part model  give runtime system tracks
beliefs selects actions  work  assume initial belief  or set possible
initial beliefs  available planner 
belief distribution bt sufficient statistic history  suffices condition
selection actions bt   instead ever growing sequence past observations
actions  furthermore  belief bt time calculated recursively  using belief one time
step earlier  bt    along recent action at  observation zt  
   

fip ineau   g ordon   hrun

define belief update equation      as 
 bt    at    zt     bt  s   
x

 

o s    at    zt    s  at    s    bt   s 

s 

p r zt  bt    at   

   

denominator normalizing constant 
equation equivalent decades old bayes filter  jazwinski         commonly
applied context hidden markov models  rabiner         known forward
algorithm  continuous generalization forms basis kalman filters  kalman        
interesting consider nature belief distributions  even finite state spaces 
belief continuous quantity  defined simplex describing space distributions
state space s  large state spaces  calculating belief update  eqn    computationally challenging  recent research led efficient techniques belief state computation
exploit structure domain  dean   kanazawa        boyen   koller        poupart  
boutilier        thrun  fox  burgard    dellaert         however  far complex aspect pomdp planning generation policy action selection  described next 
example robotics  calculating beliefs state spaces     states easily done realtime  burgard et al          contrast  calculating optimal action selection policies exactly appears
infeasible environments dozen states  kaelbling et al         
directly size state space  complexity optimal policies 
hence assume throughout paper belief computed accurately  instead
focus problem finding good approximations optimal policy 
    optimal policy computation
central objective pomdp perspective compute policy selecting actions 
policy form 
 b  a 

   

b belief distribution action chosen policy  
particular interest notion optimal policy  policy maximizes expected future discounted cumulative reward 


 bt      argmax e



x

t t 




tt  rt fibt   


   

two distinct interdependent reasons computing optimal policy challenging  widely known reason so called curse dimensionality  problem
n physical states  defined belief states  n    dimensional continuous space 
less well known reason curse history  pomdp solving many ways search
space possible pomdp histories  starts searching short histories  through
select best short policies   gradually considers increasingly long histories  unfortunately number distinct possible action observation histories grows exponentially
planning horizon 
   

fia nytime p oint based pproximations l arge pomdp

two cursesdimensionality historyoften act independently  planning complexity
grow exponentially horizon even problems states  problems
large number physical states may still small number relevant histories  curse
predominant depends problem hand  solution technique  example 
belief point methods focus paper specifically target curse history  leaving
vulnerable curse dimensionality  exact algorithms hand typically
suffer far curse history  goal therefore find techniques offer best
balance both 
describe straightforward approach finding optimal policies sondik        
overall idea apply multiple iterations dynamic programming  compute increasingly
accurate values belief state b  let v value function maps belief states values
   beginning initial value function 
v   b    max


x

r s  a b s  

    

ss

t th value function constructed  t    th following recursive equation 
 

vt  b    max


 
x

x

r s  a b s   

ss

p r z   a  b vt     b  a  z    

    

zz

 b  a  z  belief updating function defined equation    value function update
maximizes expected sum  possibly discounted  future pay offs agent receives
next time steps  belief state b  thus  produces policy optimal planning
horizon t  optimal policy directly extracted previous step value function 
 

 

 b 

  argmax


x

r s  a b s   

x

p r z   a  b vt     b  a  z    

    

zz

ss

sondik        showed value function finite horizon expressed set
vectors                         vector represents  s  dimensional hyper plane 
defines value function bounded region belief 
x

vt  b    max


 s b s  

    

ss

addition   vector associated action  defining best immediate policy
assuming optimal behavior following  t    steps  as defined respectively sets
 vt         v     
t horizon solution set    computed follows  first  rewrite equation    as 


vt  b    max
aa


x

ss

r s  a b s   

x
zz

max

t 

xx
ss

 s  a  s   o s    a  z  s   b s        

s 

notice representation vt  b   nonlinearity term p  z a  b  equation   
cancels nonlinearity term  b  a  z   leaving linear function b s  inside max
operator 
   

fip ineau   g ordon   hrun

value vt  b  cannot computed directly belief b b  since infinitely
many beliefs   corresponding set generated sequence operations
set t   
a z
first operation generate intermediate sets a 
  a  z z  step    
a   s    r s  a 
a 

a z




ia z  s 

 

x

    
 

 

 

 s  a   o s   a  z i  s    t 

s 

a  ia z  s  dimensional hyper plane 
next create  a a   cross sum observations    includes one a z
a z
 step    
a z 
 
   
a z
  a 

 

    

finally take union sets  step    
  aa  

    

forms pieces backup solution horizon t  actual value function vt
extracted set described equation    
using approach  bounded time pomdp problems finite state  action  observation
spaces solved exactly given choice horizon   environment
agent might able bound planning horizon advance  policy  b  approximation optimal one whose quality improves expectation planning horizon  assuming
       
mentioned above  value function vt extracted directly set   important aspect algorithm  and optimal finite horizon pomdp solutions 
value function guaranteed piecewise linear  convex  continuous function belief  sondik         piecewise linearity continuous properties direct result fact
vt composed finitely many linear  vectors  convexity property result
a 

maximization operator  eqn      worth pointing intermediate sets a z
 
represent functions belief composed entirely linear segments  property
holds intermediate representations incorporate expectation observation
probabilities  eqn     
worst case  exact value update procedure described could require time doubly exponential planning horizon  kaelbling et al          better understand complexity
exact update  let  s  number states   a  number actions   z  number
observations   t    number  vectors previous solution set  step   creates
 a   z   t    projections step   generates  a   t    z  cross sums  so  worst case 
new solution requires 
 t     o  a  t    z   

    

   symbol denotes cross sum operator  cross sum operation defined two sets   
 a    a              b    b    b            bn    produces third set  c    a    b    a    b            a    bn   a   
b    a    b                      bn   

   

fia nytime p oint based pproximations l arge pomdp

 vectors represent value function horizon t  computed time
o  s    a   t    z    
often case vector completely dominated another vector
entire belief simplex 
b   j b  b 
    
similarly  vector may fully dominated set vectors  e g     fig    dominated combination        vector pruned away without affecting
solution  finding dominated vectors expensive  checking whether single vector
dominated requires solving linear program  s  variables  t   constraints  nonetheless
time effective apply pruning iteration prevent explosion solution
size  practice   t   often appears grow singly exponentially t  given clever mechanisms
pruning unnecessary linear functions  enormous computational complexity long
key impediment toward applying pomdps practical problems 

v                  

figure    pomdp value function representation

    point based value backup
exact pomdp solving  outlined above  optimizes value function beliefs  many
approximate pomdp solutions  including pbvi approach proposed paper  gain computational advantage applying value updates specific  and few  belief points  rather
beliefs  cheng        zhang   zhang        poon         approaches differ significantly
 and great consequence  select belief points  set points selected 
procedure updating value standard  describe procedure updating
value function set known belief points 
section      value function update implemented sequence operations
set  vectors  assume interested updating value function fixed
set belief points  b    b    b         bq    follows value function contain
one  vector belief point  point based value function therefore represented
corresponding set                  q   
given solution set t    simply modify exact backup operator  eqn    
one  vector per belief point maintained  point based backup gives  vector
valid region around b  assumes belief points region
action choice lead facets vt  point b  key idea behind
algorithms presented paper  reason large computational savings associated
class algorithms 
   

fip ineau   g ordon   hrun

obtain solution set previous set t    begin generating intera z
mediate sets a 
  a  z z  exactly eqn      step    
a 
a   s    r s  a 

a z




ia z  s 

 

    
 

x

 

 

 s  a   o s   a  z i  s    t   

s 

next  whereas performing exact value update requires cross sum operation  eqn     
operating finite set points  instead use simple summation  construct  
 step    
ba   a 
 

x

argmax 

a z
zz

x

 s b s    b b 

    

ss

finally  find best action belief point  step    
b   argmax 

x


 aa ss

 s b s    b b 

  bb b

    
    

operations preserve best  vector belief point b b  estimate
value function belief simplex  including b
  b  extracted set
before 
x

vt  b    max


 s b s  

    

ss

better understand complexity updating value set points b  let  s 
number states   a  number actions   z  number observations   t    number
 vectors previous solution set  exact update  step   creates  a   z   t   
projections  in time  s    a   z   t      steps     reduce set  b  components
 in time  s   a   t     z   b    thus  full point based value update takes polynomial time 
even crucially  size solution set remains constant every iteration 
point based value backup algorithm summarized table   
note algorithm outlined table   includes trivial pruning step  lines        
whereby refrain adding vector already included it  result  often
case  t    b   situation arises whenever multiple nearby belief points support
vector  pruning step computed rapidly  without solving linear programs  clearly
advantageous terms reducing set  
point based value backup found many pomdp solvers  general serves improve estimates value function  integral part pbvi framework 

   anytime point based value iteration
describe algorithmic framework new class fast approximate pomdp algorithms called point based value iteration  pbvi   pbvi class algorithms offer anytime solution
large scale discrete pomdp domains  key achieving anytime solution interleave
   

fia nytime p oint based pproximations l arge pomdp

 backup b  t   
action
observation z z
solution vector t 
p
ia z  s    s   s  a  s   o s    a  z i  s    
end
a z
a z
 
end
end
 
belief point hb b

p
p
p
b   argmaxaa
 
 s b s  
ss r s  a b s   
zz maxa z
ss

if b
   
  b
end
return

 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  

table    point based value backup

two main components  point based update described table   steps belief set selection  approximate value function find guaranteed bounded error  compared
optimal  discrete pomdp domain 
current section focuses overall anytime algorithm theoretical properties  independent belief point selection process  section   discusses detail various novel
techniques belief point selection 
overall pbvi framework simple  start  small  initial set belief points
applied first series backup operations  set belief points grown 
new series backup operations applied belief points  old new   on 
satisfactory solution obtained  interleaving value backup iterations expansions
belief set  pbvi offers range solutions  gradually trading computation time solution
quality 
full algorithm presented table    algorithm accepts input initial belief point
set  binit    initial value       number desired expansions  n    planning horizon
 t    common choice binit initial belief b    alternately  larger set could used 
especially cases sample trajectories available  initial value      typically set
min
purposefully low  e g      s    r 
  s   this  show pointbased solution always lower bound exact solution  lovejoy      a   follows
simple observation failing compute  vector lower value function 
problems finite horizon  run value backups expansion
belief set  infinite horizon problems  select horizon
 rmax rmin      
rmax   maxs a r s  a  rmin   mins a r s  a  
   

    

fip ineau   g ordon   hrun

complete algorithm terminates fixed number expansions  n   completed  alternately  algorithm could terminate value function approximation reaches
given performance criterion  discussed below 
algorithm uses backup routine described table    assume moment
expand subroutine  line    selects belief points random  performs reasonably
well small problems easy achieve good coverage entire belief simplex 
however scales poorly larger domains exponentially many points needed guarantee
good coverage belief simplex  sophisticated approaches selecting belief points
presented section    overall  pbvi framework described offers simple yet flexible
approach solving large scale pomdps 
 pbvi main binit       n    
b binit
   
n expansions
iterations
 backup b  
end
bnew  expand b  
b   b bnew
end
return

 
 
 
 
 
 
 
 
 
  
  

table    algorithm point based value iteration  pbvi 
belief set b horizon t  algorithm table   produce estimate value
function  denoted vtb   show error vtb optimal value function v
bounded  bound depends densely b samples belief simplex   denser
sampling  vtb converges vt   t horizon optimal solution  turn bounded error
respect v   optimal solution  cutting pbvi iterations sufficiently large
horizon  show difference vtb optimal infinite horizon v
large  overall error pbvi bounded  according triangle inequality  by 
kvtb v k kvtb vt k   kvt v k  

    

second term bounded kv  v k  bertsekas   tsitsiklis         remainder
section states proves bound first term  denote  
begin assuming h denotes exact value backup  h denotes pbvi backup 
define  b  error introduced specific belief b performing one iteration
point based backup 
 b     hv b  b  hv b  b    
next define maximum total error introduced one iteration point based backup 
   hv b hv b  
  max  b  
b

   

fia nytime p oint based pproximations l arge pomdp

finally define density b set belief points b maximum distance belief
simplex belief set b  precisely 
b   max
min kb b  k   
 
b bb

    

prove following lemma 
lemma    error introduced pbvi performing one iteration value backup b 
instead   bounded
 rmax rmin  b

 
proof  let b  point pbvi makes worst error value update  b b
closest    norm  sampled belief b    let vector maximal b   
vector would maximal b    failing include   solution set  pbvi makes error
  b  b    hand  since maximal b    b b  so 
  b   b 
 

 



  b  b       b   b 
  b  b     b   b
      b  b 
k  k kb  bk 
k  k b



 rmax rmin  b
 

add zero
assume optimal b
re arrange terms
holder inequality
definition b

last inequality holds  vector represents reward achievable starting
state following sequence actions observations  therefore sum rewards
min
max
must fall r 
r 
 
lemma   states bound approximation error introduced one iteration point based
value updates within pbvi framework  look bound multiple value updates 
theorem      belief set b horizon t  error pbvi algorithm   kvtb
vt k bounded
 rmax rmin  b

     
proof 
    vtb vt   
b hv   
    hvt 
t 




 


definition h

b hv b        hv b hv   
  hvt 
t 
t 
t 
 rmax rmin  b
b

    hvt  hvt    
 
 rmax rmin  b
b v   
    vt 
t 
 

triangle inequality

 rmax rmin  b
 
 rmax rmin  b
    

definition t 

  t 

lemma  
contraction exact value backup

sum geometric series
   

fip ineau   g ordon   hrun

bound described section depends densely b samples belief simplex  
case beliefs reachable  pbvi need sample densely 
 fig      error bounds convergence results
replace set reachable beliefs
 


hold   simply need re define b lemma   
side note  worth pointing pbvi makes assumption regarding
initial value function v b   point based solution v b guaranteed improve
addition belief points  nonetheless  theorem presented section shows bound
error vtb  the point based solution  v  the optimal solution  guaranteed
decrease  or stay same  addition belief points  cases vtb initialized
min
pessimistically  e g   v b  s    r 
  s  suggested above   vtb improve  or stay
same  value backup addition belief points 
section thus far skirted issue belief point selection  however bound presented
section clearly argues favor dense sampling belief simplex  randomly
selecting points according uniform distribution may eventually accomplish this  generally
inefficient  particular high dimensional cases  furthermore  take advantage
fact error bound holds dense sampling reachable beliefs  thus seek
efficient ways generate belief points random entire simplex  issue
explored next section 

   belief point selection
section    outlined prototypical pbvi algorithm  conveniently avoiding question
belief points selected  clear trade off including fewer
beliefs  which would favor fast planning good performance   versus including many beliefs
 which would slow planning  ensure better bound performance   brings
question many belief points included  however number points
consideration  likely collections belief points  e g   frequently encountered 
likely produce good value function others  brings question
beliefs included 
number approaches proposed literature  example  exact value
function approaches use linear programs identify points value function needs
improved  cheng        littman        zhang   zhang         however typically
expensive  value function approximated learning value regular points 
using fixed resolution  lovejoy      a   variable resolution  zhou   hansen        grid 
less expensive solving lps  scales poorly number states increases  alternately  one use heuristics generate grid points  hauskrecht        poon         tends
scalable  though significant experimentation required establish heuristics
useful 
section presents five heuristic strategies selecting belief points  fast naive
random sampling  increasingly sophisticated stochastic simulation techniques 
effective strategy propose one carefully selects points likely largest
impact reducing error bound  theorem      
strategies consider focus selecting reachable beliefs  rather getting
uniform coverage entire belief simplex  therefore useful begin discussion
looking reachability assessed 
   

fia nytime p oint based pproximations l arge pomdp

exact pomdp value iteration solutions optimal initial belief  pbvi  and
related techniques  assume known initial belief b    shown figure    use
initial belief build tree reachable beliefs  representation  path tree
corresponds sequence belief space  increasing depth corresponds increasing plan
horizon  selecting set belief points pbvi  including reachable beliefs would guarantee optimal performance  conditioned initial belief   expense computational
grow exponentially planning horitractability  since set reachable beliefs   
sufficiently small computational
zon  therefore  best select subset b
tractability  sufficiently large good value function approximation  

b 

   
ba z ba z

ba z

  q

    a  z 

   

ba z

  q

   

ba z

   

   
   

   

   

ba z ba z

   
ba z ba z
p  

p  

ba z

p q

   

   

   

   
   

   

   

   
ba z

    ap zq

ba z

    a  z 

ba z

    ap zq

   

   

   

   

figure    set reachable beliefs
domains initial belief known  or unique   still possible use reachability analysis sampling initial beliefs  or using set known initial beliefs  seed
multiple reachability trees 
discuss five strategies selecting belief points  used within
pbvi framework perform expansion belief set 
    random belief selection  ra 
first strategy simplest  consists sampling belief points uniform distribution entire belief simplex  sample simplex  cannot simply sample
p
b s  independently         this would violate constraint b s        instead  use
algorithm described table    see devroye        details including proof uniform
coverage  
random point selection strategy  unlike strategies presented below  focus
reachable beliefs  reason  necessarily advocate approach  however
include obvious choice  far simplest implement  used
related work hauskrecht        poon         smaller domains  e g       states  
   strategies discussed assume belief point set  b  approximately doubles size belief
expansion  ensures number rounds value iteration logarithmic  in final number belief
points needed   alternately  strategy could used  with little modification  add fixed number new
belief points  may require many rounds value iteration  since value iteration much expensive
belief computation  seems appropriate double size b expansion 

   

fip ineau   g ordon   hrun

bnew  expandra  b   
bnew   b
foreach b b
   number states
     
btmp  i  randuniform      
end
sort btmp ascending order
       
bnew  i  btmp  i      btmp  i 
end
bnew   bnew bnew
end
return bnew

 
 
 
 
 
 
 
 
 
  
  
  
  
  

table    algorithm belief expansion random action selection

performs reasonably well  since belief simplex relatively low dimensional  large domains
 e g        states   cannot provide good coverage belief simplex reasonable number
points  therefore exhibits poor performance  demonstrated experimental results
presented section   
remaining belief selection strategies make use belief tree  figure    focus
reachable beliefs  rather trying cover entire belief simplex 
    stochastic simulation random action  ssra 
generate points along belief tree  use technique called stochastic simulation  involves
running single step forward trajectories belief points already b  simulating single step
forward trajectory given b b requires selecting action observation pair  a  z  
computing new belief  b  a  z  using bayesian update rule  eqn     case
stochastic simulation random action  ssra   action selected forward simulation
picked  uniformly  random full action set  table   summarizes belief expansion
procedure ssra  first  state drawn belief distribution b  second  action
drawn random full action set  next  posterior state s  drawn transition
model  s  a  s     finally  observation z drawn observation model o s    a  z   using
triple  b  a  z   calculate new belief bnew    b  a  z   according equation    
add set belief points bnew  
strategy better picking points random  as described above   restricts
bnew belief tree  fig      however belief tree still large  especially
branching factor high  due large numbers actions observations  selective
paths belief tree explored  one hope effectively restrict belief set
further 
   

fia nytime p oint based pproximations l arge pomdp

bnew  expandssra  b   
bnew   b
foreach b b
s randmultinomial  b 
a randuniform  a 
s   randmultinomial  t  s  a    
z randmultinomial  o s    a    
bnew    b  a  z   see eqn   
bnew   bnew bnew
end
return bnew

 
 
 
 
 
 
 
 
 
  
  

table    algorithm belief expansion random action selection

similar technique stochastic simulation discussed poon         however belief set initialized differently  not using b     therefore stochastic simulations
restricted set reachable beliefs 
    stochastic simulation greedy action  ssga 
procedure generating points using stochastic simulation greedy action  ssga 
based well known  greedy exploration strategy used reinforcement learning  sutton  
barto         strategy similar ssra procedure  except rather choosing
action randomly  ssea choose greedy action  i e   current best action given belief
b  probability     chose random action probability  we use        
action selected  perform single step forward simulation ssra yield new belief
point  table   summarizes belief expansion procedure ssga 
similar technique  featuring stochastic simulation using greedy actions  outlined
hauskrecht         however case  belief set included extreme points belief
simplex  stochastic simulation done extreme points  rather initial
belief 
    stochastic simulation exploratory action  ssea 
error bound section   suggests pbvi performs best belief set uniformly dense
set reachable beliefs  belief point strategies proposed thus far ignore information 
next approach propose gradually expands b greedily choosing new reachable beliefs
improve worst case density 
unlike ssra ssga select single action simulate forward trajectory
given b b  stochastic sampling exploratory action  ssea  one step forward
simulation action  thus producing new beliefs  ba    ba          however accept
new beliefs  ba    ba          rather calculates l  distance ba closest
neighbor b  keep point ba farthest away point already b 
   

fip ineau   g ordon   hrun

bnew  expandssga  b   
bnew   b
foreach b b
s randmultinomial  b 
randuniform         
a randuniform  a 
else
p
a argmax ss  s b s 
end
s   randmultinomial  t  s  a    
z randmultinomial  o s    a    
bnew    b  a  z   see eqn   
bnew   bnew bnew
end
return bnew

 
 
 
 
 
 
 
 
 
  
  
  
  
  
  

table    algorithm belief expansion greedy action selection

use l  norm calculate distance belief points consistent error bound
theorem      table   summarizes ssea expansion procedure 
bnew  expandssea  b   
bnew   b
foreach b b
foreach
s randmultinomial  b 
s   randmultinomial  t  s  a    
z randmultinomial  o s    a    
ba    b  a  z   see eqn   
end
p
bnew   maxaa minb  bnew ss  ba  s  b   s  
bnew   bnew bnew  see eqn   
end
return bnew

 
 
 
 
 
 
 
 
 
  
  
  
  

table    algorithm belief expansion exploratory action selection

    greedy error reduction  ger 
ssea strategy able improve worst case density reachable beliefs 
directly minimize expected error  would directly minimize
   

fia nytime p oint based pproximations l arge pomdp

error  measure bound error  lemma     therefore propose final strategy
greedily adds candidate beliefs effectively reduce error bound 
empirical results  presented below  show strategy successful one discovered
thus far 
understand expand belief set ger strategy  useful re consider
belief tree  reproduce figure    node tree corresponds specific belief 
divide nodes three sets  set   includes belief points already b 
case b  ba  z    set   contains belief points immediate descendants points
b  i e   nodes grey zone   candidates select new
points added b  call set envelope  denoted b   set   contains reachable
beliefs 

b 

   
ba z ba z

  q

  q

   

   

   

   
   

 

  a  z 

   

   

ba z

   

   
ba z

   

ba z ba z
p  

p  

ba z

p q

   

   

ba z ba z

   
   

   

   

ba z

ba z

    ap zq

   

   

figure    set reachable beliefs
need decide belief b removed envelope b added set
active belief points b  every point added b improve estimate value
function  new point reduce error bounds  as defined section   points
already b  however  error bound new point might quite large  means
largest error bound points b monotonically decrease  however  particular
point b  such initial belief b    error bound decreasing 
find point reduce error bound  look analysis
lemma    lemma   bounds amount additional error single point based backup introduces  write b  new belief considering adding  write b belief
already b  write value hyper plane b  write   b    lemma
points out 
 b          b  b 
evaluating error  need minimize b b  also  since know
  done backups b    make conservative assumption choose
worst case value    rmin        rmax        s    thus  evaluate 
 

 b    min
bb

x
ss

max
 s   b   s  b s   b   s  b s 
  r 
rmin
     s   b   s  b s   b   s    b s 

   

    

fip ineau   g ordon   hrun

one could simply pick candidate b  b currently largest error bound  
would ignore reachability considerations  rather  evaluate error b b 
weighing error fringe nodes reachability probability 
 b    

x

 b    max
aa

o b  a  z     b  a  z  


x

  max
aa

    

zz


xx


zz

 s  a  s   o s    a  z b s     b  a  z   

ss s 

noting  b  a  z  b     b  a  z   evaluated according equation    
using equation     find existing point b b largest error bound 
directly reduce error adding set one descendants  select next step belief
 b  a  z  maximizes error bound reduction 
b

 

b  b  a  z  

b     argmax

    
x

o b  a  z     b  a  z  

    

bb aa zz

z    argmax o b  a  z     b  a  z  

    

zz

table   summarizes ger approach belief point selection 
bnew  expandger  b   
bnew   b
n   b 
      n
p
b     argmaxbb aa zz o b  a  z     b  a  z  
z    argmaxzz o b  a  z     b  a  z  
bnew    b  a  z 
bnew   bnew bnew
end
return bnew

 
 
 
 
 
 
 
 
 
  

table    algorithm belief expansion

complexity adding one new points ger o sazb   where s  states 
a  actions  z  observations  b  beliefs already selected   comparison  value backup  for
one point  o s   azb   point typically needs updated several times  point
empirical results below  belief selection  even ger  takes minimal time compared
value backup 
concludes presentation belief selection techniques pbvi framework 
summary  three factors consider picking belief point      likely
   tried this  however perform well empirically suggest equation    
consider probability reaching belief 

   

fia nytime p oint based pproximations l arge pomdp

occur      far belief points already selected      current approximate
value point  simplest heuristic  ra  accounts none these  whereas
others  ssra  ssga  ssea  account one  ger incorporates three factors 
    belief expansion example
consider simple example  shown figure    illustrate difference various
belief expansion techniques outlined above   d pomdp  littman        four states  one
goal  indicated star   two actions  left right  expected
 deterministic  effect  goal state fully observable  observation goal   three
states aliased  observation none   reward    received goal state 
otherwise reward zero  assume discount factor         initial distribution
uniform non goal states  system resets distribution whenever goal reached 

figure     d pomdp
belief set b always initialized contain initial belief b    figure   shows part
belief tree  including original belief set  top node   envelope  leaf nodes  
consider belief expansion method might do 
b                      
a left

a right

                 

pr z none     

b             

                    

pr z goal       

pr z none     

b             

b                 

pr z goal       

b             

figure     d pomdp belief tree
random heuristic pick belief point  with equal probability  entire belief
simplex  directly expand branches belief tree  eventually put samples
nearby 
stochastic simulation random action     chance picking action 
then  regardless action picked  theres     chance seeing observation none 
    chance seeing observation goal  result  ssra select  p r bnew   b             
p r bnew   b              p r bnew   b              p r bnew   b             
   

fip ineau   g ordon   hrun

stochastic simulation greedy action first needs know policy b   
iterations point based updates  section      applied initial  single point  belief set reveal
 b      lef t   result  expansion belief greedily select action lef proba
bility      a 
        assuming        a        action right selected belief

expansion probability  a 
        combining along observation probabilities 
tell ssga expand follows  p r bnew   b               p r bnew   b              
p r bnew   b               p r bnew   b              
predicting choice stochastic simulation exploratory action slightly complicated  four cases occur  depending outcomes random forward simulation b   
   action left goes b   p r        action right goes b   p r         b 
selected   b  b            whereas   b  b             case occur
p r       
   action left goes b   p r        action right goes b   p r         b 
selected   b  b           case occur p r       
   action left goes b   p r        action right goes b   p r         b 
selected   b  b           case occur p r       
   action left goes b   p r        action right goes b   p r         either
selected  since equidistant b     case b  b  p r       
selected 
told  p r bnew   b          p r bnew   b           p r bnew   b        p r bnew   b    
     
looking belief expansion using greedy error reduction  need compute
error    b    a  z    a  z  consider equation     since b one point  b    necessarily b   b    estimate   apply multiple steps value backup b  obtain
                         using b such  estimate error candidate belief   b             b             b             b            note b
one point  dominating factor distance b    next  factor observation
probabilities  eqns        allows us determine   lef z   none 
therefore select bnew   b   
summary  note ssga  ssea ger favor selecting b    whereas ssra picks
option equal probability  considering b  b  actually same   general 
problem size  reasonable expand entire belief tree  techniques
discussed quickly  except ra pick exact nodes belief
tree  select equally good nearby beliefs  example provided simply illustrate
different choices made strategy 

   review point based approaches pomdp solving
previous section describes new class point based algorithms pomdp solving  idea
using point based updates pomdps explored previously literature 
   may obvious reader  follows directly repeated application equations      

   

fia nytime p oint based pproximations l arge pomdp

section summarize main results  approaches discussed below  procedure
updating value function given point remains unchanged  as outlined section      
rather  approaches mainly differentiated belief points selected 
updates ordered 
    exact point based algorithms
earlier exact pomdp techniques use point based backups optimize value function limited regions belief simplex  sondik        cheng         techniques
typically require solving multiple linear programs find candidate belief points value
function sub optimal  expensive operation  furthermore  guarantee exact solution found  relevant beliefs must generated systematically  meaning reachable
beliefs must considered  result  methods typically cannot scale beyond handful
states actions observations 
work zhang zhang         point based updates interleaved standard dynamic programming updates accelerate planning  case points generated
systematically  rather backups applied set witness points lp points 
witness points identified result standard dynamic programming updates  whereas
lp points identified solving linear programs identify beliefs value
yet improved  procedures significantly expensive belief selection heuristics presented paper results limited domains dozen
states actions observations  nonetheless approach guaranteed converge optimal solution 
    grid based approximations
exists many approaches approximate value function using finite set belief points
along values  points often distributed according grid pattern belief
space  thus name grid based approximation  interpolation extrapolation rule specifies
value non grid points function value neighboring grid points  approaches
ignore convexity pomdp value function 
performing value backups grid points relatively straightforward  dynamic programming
updates specified equation    adapted grid points simple polynomial time
algorithm  given set grid points g  value bg g defined by 
 
g

v  b     max


 
x

x

g

b  s r s  a   

ss

p r z   a  b v    b  a  z    

    

zz

 b  a  z  part grid  v    b  a  z   defined value backups  otherwise 
v    b  a  z   approximated using interpolation rule as 
v    b  a  z   

 g 
x

 i v  bg
  

    

i  

p g 

 i    i    i       produces convex combination grid points 
two interesting questions respect grid based approximations     calculate
interpolation function      select grid points 
   

fip ineau   g ordon   hrun

general  find interpolation leads best value function approximation point
b requires solving following linear program 
minimize

 g 
x

 i v  bg
 

    

i  

subject

b 

 g 
x

 i bg


    

i  
 g 
x

 i     

    

i  

   i        g  

    

different approaches proposed select grid points  lovejoy      a  constructs
fixed resolution regular grid entire belief space  benefit value interpolations
calculated quickly considering neighboring grid points  disadvantage number
grid points grows exponentially dimensionality belief  i e   number
states   simpler approach would select random points belief space  hauskrecht 
       requires slower interpolation estimating value new points 
methods less ideal beliefs encountered uniformly distributed 
particular  many problems characterized dense beliefs edges simplex  i e  
probability mass focused states  states zero probability   low
belief density middle simplex  distribution grid points better reflects
actual distribution belief points therefore preferable 
alternately  hauskrecht        proposes using corner points belief simplex  e g  
                                                          generating additional successor belief points
one step stochastic simulations  eqn    corner points  proposes approximate
interpolation algorithm uses values  s   critical points plus one non critical point
grid  alternative approach brafman         builds grid starting
critical points belief simplex  uses heuristic estimate usefulness gradually
adding intermediate points  e g   bk      bi      bj   pair points   hauskrechts
brafmans methodsgenerally referred non regular grid approximationsrequire fewer
points lovejoys regular grid approach  however interpolation rule used calculate
value non grid points typically expensive compute  since involves searching
grid points  rather neighboring sub simplex 
zhou hansen        propose grid based approximation combines advantages
regular non regular grids  idea sub sample regular fixed resolution grid
proposed lovejoy  gives variable resolution grid since parts beliefs
densely sampled others restricting grid points lie fixed resolution grid
approach guarantee fast value interpolation non grid points  nonetheless  algorithm
often requires large number grid points achieve good performance 
finally  bonet        proposes first grid based algorithm pomdps  optimality
 for       approach requires thorough coverage belief space every point
within grid point  value update grid point fast implement  since
interpolation rule depends nearest neighbor one step successor belief
grid point  which pre computed   main limitation fact  coverage belief
   

fia nytime p oint based pproximations l arge pomdp

space attained using exponentially many grid points  furthermore  method
requires good coverage entire belief space  opposed algorithms section   
focus coverage reachable beliefs 
    approximate point based algorithms
similar pbvi class algorithms approaches update value
gradient grid point  lovejoy      a  hauskrecht        poon         methods able
preserve piecewise linearity convexity value function  define value function
entire belief simplex  methods use random beliefs  and or require inclusion large number fixed beliefs corners probability simplex  contrast 
pbvi class algorithms propose  with exception pbvi ra  select reachable beliefs 
particular belief points improve error bounds quickly possible  idea
using reachability analysis  also known stochastic simulation  generate new points explored earlier approaches  hauskrecht        poon         however analysis
indicated stochastic simulation superior random point placements  re visit
question  and conclude otherwise  empirical evaluation presented below 
recently  technique closely related pbvi called perseus proposed  vlassis
  spaan        spaan   vlassis         perseus uses point based backups similar ones
used pbvi  two approaches differ two ways  first  perseus uses randomly generated
trajectories belief space select set belief points  contrast beliefpoint selection heuristics outlined pbvi  second  whereas pbvi systematically updates
value belief points every epoch value iteration  perseus selects subset points
update every epoch  method used select points following  points randomly
sampled one time value updated  continues value points
improved  insight resides observing updating  vector one point often
improves value estimate nearby points  which removed sampling set  
approach conceptually simple empirically effective 
hsvi algorithm  smith   simmons        another point based algorithm  differs
pbvi picks belief points  orders value updates  maintains lower
upper bound value function approximation  uses select belief points 
updating upper bound requires solving linear programs generally expensive
step  ordering value update follows  whenever belief point expanded
belief tree  hsvi updates value direct ancestors  parents  grand parents  etc  
way back initial belief head node   contrast pbvi performs batch
belief point expansions  followed batch value updates points  respects 
hsvi pbvi share many similarities  offer anytime performance  theoretical guarantees 
scalability  finally hsvi takes reachability account  evaluate empirical
differences hsvi pbvi next section 
finally  rtbss algorithm  paquet        offers online version point based algorithms 
idea construct belief reachability tree similar figure    using current belief
top node  terminating tree fixed depth d  value node
computed recursively finite planning horizon d  algorithm eliminate subtrees
calculating bound value  comparing value computed subtrees 
rtbss fact combined offline algorithms pbvi  offline algorithm
   

fip ineau   g ordon   hrun

used pre compute lower bound exact value function  used increase subtree
pruning  thereby increasing depth online tree construction thus quality
solution  online algorithm yield fast results large pomdp domains  however
overall solution quality achieve error guarantees offline approaches 

   experimental evaluation
section looks variety simulated pomdp domains evaluate empirical performance
pbvi  first three domainstiger grid  hallway  hallway are extracted established pomdp literature  cassandra         fourthtagwas introduced
earlier work new challenge pomdp algorithms 
first goal experiments establish scalability pbvi framework 
accomplished showing pbvi type algorithms successfully solve problems excess
    states  demonstrate pbvi algorithms compare favorably alternative approximate
value iteration methods  finally  following example section      study larger scale
impact belief selection strategy  confirms superior performance ger
strategy 
    maze problems
exists set benchmark problems commonly used evaluate pomdp planning algorithms  cassandra         section presents results demonstrating performance pbviclass algorithms problems  benchmark problems relatively small
 at    states    actions     observations  compared robotics planning domains 
useful analysis point view comparison previous work 
initial performance analysis focuses three well known problems pomdp literature  tiger grid  also known maze     hallway  hallway   three maze navigation
problems various sizes  problems fully described littman  cassandra  kaelbling
     a   parameterization available cassandra        
figure  a presents results tiger grid domain  replicating earlier experiments brafman         test runs terminate     steps  theres automatic reset every time goal
reached  results averaged     runs 
figures  b  c present results hallway hallway  domains  respectively 
case  test runs terminated goal reached     steps  whichever occurs first  
results averaged     runs  consistent earlier experiments littman 
cassandra  kaelbling      b  
three figures compare performance three different algorithms 
   pbvi greedy error reduction  ger  belief point selection  section      
   qmdp  littman et al       b  
   incremental pruning  cassandra  littman    zhang        
qmdp heuristic  littman et al       b  takes account partial observability current step  assumes full observability subsequent steps 
qm dp  b    argmax
aa

   

x
ss

b s qm dp  s  a  

    

fia nytime p oint based pproximations l arge pomdp

resulting policy ability resolve uncertainty  cannot benefit long term
information gathering  compare actions different information potential  qmdp seen
providing good performance baseline  three problems considered  finds policy
extremely quickly  policy clearly sub optimal 
end spectrum  incremental pruning algorithm  zhang   liu        cassandra et al         direct extension enumeration algorithm described above  principal insight pruning dominated  vectors  eqn     interleaved directly
cross sum operator  eqn      resulting value function same  algorithm
efficient discards unnecessary vectors earlier on  incremental pruning algorithm
theoretically find optimal policy  three problems considered would take far
long  fact  iterations exact backups completed reasonable time  three
problems  resulting short horizon policy worse corresponding pbvi policy 
shown figure    pbvi ger provides much better time performance trade off  finds
policies better obtained qmdp  matter seconds  thereby
demonstrating suffer paralyzing complexity incremental pruning 
take closer look results may surprised see performance
pbvi actually decreases points  e g   dip fig   c   unexpected 
important remember theoretical properties pbvi guarantee bound
estimate value function  shown here  necessarily imply policy
needs improve monotonically  nonetheless  value function converges  policy
 albeit slower rate  
    tag problem
previous section establishes good performance pbvi well known simulation problems  quite small fully demonstrate scalability algorithm 
provide better understanding pbvis effectiveness large problems  section presents
results obtained applying pbvi tag problem  robot version popular game
lasertag  problem  agent must navigate environment goal searching for 
tagging  moving target  rosencrantz  gordon    thrun         real world versions
problem take many forms  section   present similar problem domain
interactive service robot must find elderly patient roaming corridors nursing home 
synthetic scenario considered order magnitude larger      states 
pomdp benchmarks literature  cassandra         formulated pomdp problem  goal robot optimize policy allowing quickly find person  assuming
person moves  stochastically  according fixed policy  spatial configuration
environment used throughout experiment illustrated figure   
state space described cross product two position features  robot  
 s            s     person    s            s     sf ound    start independently selected random
positions  scenario finishes person   sf ound   robot select five actions 
 north  south  east  west  tag   reward   imposed motion action  tag action
results     reward robot person cell     otherwise  throughout scenario  robots position fully observable  move action predictable
deterministic effect  e  g  
p r robot   s     robot   s    n orth      
   

fip ineau   g ordon   hrun

   

   
pbvi ger
qmdp
incprune

pbvi ger
qmdp
incprune

   

 

   

reward

reward

   

 

   
   
   

   
   
   
  

 

 

  

 

 

  
  
time  secs 

   
  

 

  

  

 

 

  

 

  
  
time  secs 

 a  tiger grid

 

  

 

  

 b  hallway

    
   

pbvi ger
qmdp
incprune

    

reward

   
    
   
    
   
    
   
  

 

 

  

 

  
time  secs 

 

  

  

 c  hallway 

figure    pbvi performance well known pomdp problems  figure shows sum
discounted reward function computation time different problem domain 

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

 

 

 

 

 

 

 

 

 

 

figure    spatial configuration domain

   

fia nytime p oint based pproximations l arge pomdp

adjacent cell direction  position person  hand 
completely unobservable unless agents cell  meanwhile step 
person  with omniscient knowledge  moves away robot p r       stays place
p r        e  g  
p r p erson   s     p erson   s    robot   s         
p r p erson   s     p erson   s    robot   s         
p r p erson   s     p erson   s    robot   s          
figure   shows performance pbvi greedy error reduction tag domain  results averaged      runs  using different  randomly chosen  start positions run 
qmdp approximation tested provide baseline comparison  results show gradual improvement pbvis performance samples added  each shown data point represents
new expansion belief set value backups   confirms computation time directly related number belief points  pbvi requires fewer     belief points overcome
qmdp  performance keeps improving points added  performance appears
converging approximately     belief points  results show pbvi class algorithm
effectively tackle problem     states 
 
pbvi ger
qmdp
 

reward

  
  
  
  
  
    
  

 

  

 

 

  
  
time  secs 

 

  

 

  

figure    pbvi performance tag problem  show sum discounted reward function
computation time 

problem far beyond reach incremental pruning algorithm  single iteration
optimal value iteration problem size could produce       vectors pruning 
therefore  applied 
section describes one version tag problem  used simulation purposes
work others  braziunas   boutilier        poupart   boutilier        smith  
simmons        vlassis   spaan         fact  problem re formulated variety
ways accommodate different environments  person motion models  observation models 
section   discusses variations problem using realistic robot person models 
presents results validated onboard independently developed robot simulator 
   

fip ineau   g ordon   hrun

    empirical comparison pbvi class algorithms
establish good performance pbvi ger number problems  consider
empirical results different pbvi class algorithms  allows us compare effects
various belief expansion heuristics  repeat experiments tiger grid  hallway 
hallway  tag domains  outlined above  case compare performance five
different pbvi class algorithms 
   pbvi ra  pbvi belief points selected randomly belief simplex  section      
   pbvi ssra  pbvi belief points selected using stochastic simulation random action  section      
   pbvi ssga  pbvi belief points selected using stochastic simulation greedy action
 section      
   pbvi ssea  pbvi belief points selected using stochastic simulation exploratory
action  section      
   pbvi ger  pbvi belief points selected using greedy error reduction  section      
pbvi class algorithms converge optimal value function given sufficiently large
set belief points  rate converge depends ability generally pick
useful points  leave points containing less information  since computation time
directly proportional number belief points  algorithm best performance
generally one find good solution fewest belief points 
figure   shows comparison performance five pbvi class algorithms
enumerated four problem domains  pictures  present performance
results function computation time  
seen results  smallest domaintiger gridpbvi ger similar performance random approach pbvi ra  hallway domain  pbvi ger reaches nearoptimal performance earlier algorithms  hallway   unclear five
algorithms best  though ger seems converge earlier 
larger tag domain  situation interesting  pbvi ger combination
clearly superior others  reason believe pbvi ssea could match performance  would require order twice many points so  nonetheless  pbvi ssea
performs better either pbvi ssra pbvi ssga  random heuristic  pbvi ra  
reward improve regardless many belief points added          therefore include results  results presented figure   suggest choice
belief points crucial dealing large problems  general  believe ger  and
ssea lesser degree  superior heuristics solving domains large numbers
action observation pairs  ability selectively chooses branches
reachability tree explore 
side note  surprised ssgas poor performance  in comparison ssra 
tiger grid tag domains  could due poorly tuned greedy bias  
   nearly identical graphs produced showing performance results function number belief points 
confirms complexity analysis showing computation time directly related number belief
points 

   

fia nytime p oint based pproximations l arge pomdp

   

   
ra
ssra
ssga
ssea
ger

   

   

reward

reward

 

   

 

ra
ssra
ssga
ssea
ger

   
   
   

   
   
   
  

 

 

  

 

  
  
time  secs 

 

  

   
  

 

  

 

  

 a  tiger grid

 

 

  
time  secs 

 

  

  

 b  hallway
 

    

reward

   

 

ssra
ssga
ssea
ger

  
reward

   
    

ra
ssra
ssga
ssea
ger

    
   
    

  
  
  

   
  

    
   
  

 

  

 

  
time  secs 

 

  

    
  

 

  

 c  hallway 

 

  

 

 

  
  
time  secs 

 

  

 

  

 d  tag

figure    belief expansion results showing execution performance function computation
time 

investigate length  future investigations using problems larger number actions may
shed better light issue 
terms computational requirement  ger expensive compute  followed
ssea  however cases  time perform belief expansion step generally negligible
       compared cost value update steps  therefore seems best use
effective  though expensive  heuristic 
pbvi framework accommodate wide variety strategies  past described
paper  example  one could extract belief points directly sampled experimental traces 
subject future investigations 
    comparative analysis
results outlined show pbvi type algorithms able handle wide spectrum
large scale pomdp domains  sufficient compare performance pbvi
   

fip ineau   g ordon   hrun

qmdp incremental pruningthe two ends spectrumas done section      fact
significant activity recent years development fast approximate pomdp
algorithms  worthwhile spend time comparing pbvi framework
alternative approaches  made easy fact many validated using
set problems described above 
table   summarizes performance large number recent pomdp approximation algorithms  including pbvi  four target domains  tiger grid  hallway  hallway   tag 
algorithms listed selected based availability comparable published results available
code  cases algorithm could re implemented easily 
compare empirical performance  terms execution performance versus planning 
set simulation domains  however often case  results show
single algorithm best solving problems  therefore compile summary
attributes characteristics algorithm  attempt tell algorithm may best
types problems  table   includes  whenever possible  goal completion rates  sum
rewards  policy computation time  number required belief points  policy size  number
 vectors  number nodes finite state controllers   number belief points policy
size often identical  however latter smaller single  vector best multiple
belief points 
results marked     computed us  ghz pentium    results likely
computed different platforms  therefore time comparisons may approximate best 
nonetheless number samples size final policy useful indicators
computation time  results reported pbvi correspond earliest data point figures     pbvi ger achieves top performance 
algorithms listed order performance  starting algorithm s  achieving highest reward  results assume standard  not lookahead  controller  see hauskrecht       
definition  
overall  results indicate algorithms achieve sub par performance terms
expected reward  case qmdp  fundamental limitations algorithm 
incremental pruning exact value directed compression theoretically reach optimal
performance  would require longer computation time so  grid method  see tiger grid
results   bpi  see tiger grid  hallway tag results  pbua  see tag results  suffer
similar problem  offer much graceful performance degradation  worth noting none
approaches assumes known initial belief  effect solving harder problems 
results bbsls sufficiently extensive comment length  appears able
find reasonable policies small controllers  see tag results  
remaining algorithmshsvi  perseus  pbvi gerall offer comparable
performance relatively large pomdp domains  hsvi seems offer good control performance full range tasks  requires bigger controllers  therefore probably slower 
especially domains high stochasticity  e g   tiger grid  hallway  hallway    trade offs
perseus pbvi ger less clear  planning time  controller size performance
quality quite comparable  fact two approaches similar  similarities
differences two approaches explored section   

   

fia nytime p oint based pproximations l arge pomdp

method
tiger grid  maze   
hsvi  smith   simmons       
perseus  vlassis   spaan       
pbua  poon       
pbvi ger   
bpi  poupart   boutilier       
grid  brafman       
qmdp  littman et al       b    
incprune  cassandra et al           
exact vdc  poupart   boutilier          
hallway
pbua  poon       
hsvi  smith   simmons       
pbvi ger   
perseus  vlassis   spaan       
bpi  poupart   boutilier       
qmdp  littman et al       b    
exact vdc  poupart   boutilier          
incprune  cassandra et al           
hallway 
pbvi ger   
perseus  vlassis   spaan       
hsvi  smith   simmons       
pbua  poon       
bpi  poupart   boutilier       
grid  brafman       
qmdp  littman et al       b    
exact vdc  poupart   boutilier          
incprune  cassandra et al           
tag
hsvi  smith   simmons       
pbvi ger   
perseus  vlassis   spaan       
bbsls  braziunas   boutilier       
bpi  poupart   boutilier       
qmdp  littman et al       b    
pbua  poon          
incprune  cassandra et al           

goal 

reward conf int 

time s 

 b 

  

n a 
n a 
n a 
n a 
n a 
n a 
n a 
n a 
n a 

    
    
    
         
    
    
     
   
   

     
   
     
   
      
n v 
    
  hrs 
  hrs 

n v 
     
   
   
n a 
   
n a 
n a 
n a 

    
   
n v 
   
    
n a 
 
n v 
n v 

   
   
   
n v 
n v 
  
  
  

    
    
         
    
    
     
     
     

   
     
  
  
      
    
  hrs 
  hrs 

   
n v 
  
     
n a 
n a 
n a 
n a 

n v 
    
  
  
    
 
n v 
n v 

   
n v 
   
   
n v 
  
  
  
  

         
    
    
    
    
n v 
     
     
     

 
  
     
     
      
n v 
    
  hrs 
  hrs 

  
     
n v 
    
n a 
   
n a 
n a 
n a 

  
  
    
n v 
    
n a 
 
n v 
n v 

   
   
n v 
n v 
n v 
  
 
 

     
          
     
     
     
      
     
     

     
    
    
      
     
    
  hrs 
  hrs 

n v 
   
     
n a 
n a 
n a 
    
n a 

    
   
   
  
   
 
n v 
n v 

n a  not applicable

n v  not available

    results computed us

table    results pbvi standard pomdp domains

   

fip ineau   g ordon   hrun

    error estimates
results presented thus far suggest pbvi framework performs best using
greedy error reduction  ger  technique selecting belief points  scheme  decide belief points included  estimate error bound set candidate points
pick one largest error estimate  error bound estimated described
equation     consider question estimate evolves points
added  natural intuition first points  error estimates large 
density belief set increases  error estimates become much smaller 
figure    reconsiders four target domains  tiger grid  hallway  hallway  tag 
case  present reward performance function number belief points  top
row graphs   error estimate point selected according order points
picked  bottom row graphs   addition  bottom graphs show  in dashed line  trivial
rmin
bound error   vt vt    rmax 
  valid t step value function arbitrary
policy  expected  bound typically tighter trivial bound  tag  occurs
number belief points exceeds number states  surprising  given
bound depends distance reachable beliefs  states reachable beliefs
domain  overall  seems reasonably good correspondence improvement
performance decrease error estimates  conclude figure even
though pbvi error quite loose  fact informative guiding exploration belief
simplex 
note significant variance error estimates one belief point next 
illustrated non monotonic behavior curves bottom graphs figure    
behavior attributed possibilities  first  fact error estimate
given belief approximate  value function used calculate error estimate
approximate  addition  fact new belief points always selected
envelope reachable beliefs  set reachable beliefs  suggests ger could
improved maintaining deeper envelope candidate belief points  currently envelope
contains points   step forward simulations points already selected  may
useful consider points    steps ahead  predict would reduce jaggedness seen
figure     importantly  reduce number points necessary good performance 
course  tradeoff time spent selecting points time spent planning would
re evaluated light 

   robotic applications
overall motivation behind work described paper desire provide high quality
robust planning real world autonomous systems  particular robots  practical side  search robust robot controller large part guided nursebot
project  pineau  montermerlo  pollack  roy    thrun         overall goal project
develop personalized robotic technology play active role providing improved care
services non institutionalized elderly people  pearl  shown figure     main robotic
platform used project 
many services nursing assistant robot could provide  engelberger        lacey
  dawson howe         much work date focused providing timely cognitive reminders  e g   medications take  appointments attend  etc   elderly subjects  pollack        
   

fia nytime p oint based pproximations l arge pomdp

tigergrid

hallway

   

reward

 

hallway 

   

   

   

   

   

   

   

   

tag
 

  

   
 

  

   
 
 
  

 

  

 

  

 

  

 
 
  

  belief points
  

 

  

 

  

 
 
  

 

  

  belief points

 

  

 

  

  

  

error

 

  

 

  

  belief points

   

  
  

  

   

  

  

   

  
 

   

  
 
 
  

 

  

   

  

  

  
 
 
     

  belief points

 

  

 

  

  belief points

 
 
 
     

 

  

 

  

 

  

  belief points

 
 
  

 

  

 

  

  belief points

 

  

 
 
  

 

  

 

  

 

  

  belief points

figure     sum discounted reward  top graphs  estimate bound error  bottom
graphs  function number selected belief points 

figure     pearl nursebot  interacting elderly people nursing facility
important component task finding patient whenever time issue reminder 
task shares many similarities tag problem presented section      case 
however  robot generated map real physical environment used basis spatial
configuration domain  map shown figure     white areas correspond free
space  black lines indicate walls  or obstacles  dark gray areas visible
accessible robot  one easily imagine patients room physiotherapy unit lying
either end corridor  common area shown upper middle section 
overall goal robot traverse domain order find missing patient
deliver message  robot must systematically explore environment  reasoning
spatial coverage human motion patterns  order find person 
   

fip ineau   g ordon   hrun

figure     map environment
    pomdp modeling
problem domain represented jointly two state features  robotposition  personposition 
feature expressed discretization environment  experiments
assume discretization   meters  means    discrete cells feature  total
    states 
assumed person robot move freely throughout space  robots
motion deterministically controlled choice action  north  south  east  west   robot
fifth action  delivermessage   concludes scenario used appropriately  i e  
robot person location  
persons motion stochastic falls one two modes  part time  person
moves according brownian motion  e g   moves cardinal direction p r        otherwise stays put   times  person moves directly away robot  tag domain
section     assumes person always moves always moves away robot  realistic person cannot see robot  current experiment instead assumes person
moves according brownian motion robot far away  moves away robot
closer  e g      m   person policy designed way encourage robot
find robust policy 
terms state observability  two components  robot sense
position  sense persons position  first case  assumption
robot knows position times  may seem generous  or
optimistic  assumption  substantial experience domains size maps quality
demonstrated robust localization abilities  thrun et al          especially true
planning operates relatively coarse resolution    meters  compared localization precision
    cm   exact position information assumed planning domain  execution
phase  during actually measure performance  update belief using full localization
information  includes positional uncertainty whenever appropriate 
regarding detection person  assumption robot knowledge
persons position unless s he within range   meters  plausible given robots
sensors  however  even short range  small probability  p r         robot
miss person therefore return false negative 
general  one could make sensible assumptions persons likely position  e g   based
knowledge daily activities   however currently information therefore assume uniform distribution initial positions  persons subsequent movements
   

fia nytime p oint based pproximations l arge pomdp

expressed motion model described  i e   mix brownian motion purposeful avoidance  
reward function straightforward  r     motion action  r     
robot decides delivermessage cell person  r      
robot decides delivermessage persons absence  task terminates robot
successfully delivers message  i e     deliverm essage srobot   sperson    assume
discount factor      
assume known initial belief  b    consisting uniform distribution states 
used selecting belief points planning  subsequently executing testing
final policy 
initial map  fig      domain collected mobile robot  slightly cleaned
hand remove artifacts  e g   people walking by   assumed model parameters
described here  applied pbvi planning problem such  value updates belief point
expansions applied alternation  in simulation  policy able find person
    trials  trials terminated person found     execution steps  
final policy implemented tested onboard publicly available carmen robot simulator  montemerlo  roy    thrun        
    comparative evaluation pbvi perseus
subtask described here      states  beyond capabilities exact pomdp solvers 
furthermore  demonstrated below  mdp type approximations equipped handle
uncertainty type exhibited task  main purpose analysis evaluate
effectiveness point based approach described paper address problem 
results tag domain  section      hint fact pbvi algorithms may able
handle task  realistic map modified motion model provide new challenges 
begin investigation directly comparing performance pbvi  with ger belief points selection  perseus algorithm complex robot domain  perseus
described section    results presented produced using code provided authors  perseus         results algorithms assume fixed pomdp model generated
robot simulator  model stored solved offline algorithm 
pbvi perseus parameters set  pbvi requires  number new belief
points add expansion  badd   planning horizon expansion  h   perseus
requires  number belief points generate random walk  b  maximum planning
time  t    results presented assume following parameter settings  badd       h      
b                algorithms fairly robust changes parameters  
figure    summarizes results experiment  suggest number observations 
shown figure    a   algorithms find best solution similar time 
pbvi ger better anytime performance perseus  e g   much better policy found
given     sec  
shown figure    b   algorithms require similar number  vectors 
shown figure    c   pbvi ger requires many fewer beliefs 
       change parameter value yielded sensibly similar results terms reward number vectors 
though course time  memory  number beliefs varied 

   

fip ineau   g ordon   hrun

 
  

   
pbvi ger
ger
perseus
qmdp

pbvi ger
perseus
   

  
  alpha vectors

reward

  
  
  
  

  
  
  

  
  
  
    
  

 

 

  

 

 

  
  
time  secs 

  

   
  

 

  

 

  

 

  

pbvi ger
perseus
 

  

  beliefs

 

  

 

  

 

  

 

    
  

 

  

 

  
time  secs 

 

  

 

  

 b 
memory requirement     alphas    beliefs   states

 a 

 

  
time  secs 

 

  

 

  

 c 

 

  

pbvi ger
perseus
 

  

 

  

 

  

 

  

 

  

 

  

 

  
time  secs 

 

  

 

  

 d 

figure     comparison pbvi perseus robot simulation domain
requires fewer beliefs  pbvi ger much lower memory requirements 
quantified figure    d  
new results suggest pbvi perseus similar performance objective
find near optimal solution  time memory constrained  cases one willing
trade accuracy time  pbvi may provide superior anytime performance  cases
memory limited  pbvis conservative approach respect belief point selection
advantageous  properties suggest pbvi may scale better large domains 
    experimental results robot simulator
results presented assume pomdp model used planning testing  i e   compute reward figure    a    useful carry large number
experiments  model however cannot entirely capture dynamics realistic robot system 
therefore concern policy learned point based methods perform
well realistic robot  verify robustness approach  final pbvi control policy
implemented tested onboard publicly available carmen robot simulator  montemerlo
et al         
   

fia nytime p oint based pproximations l arge pomdp

resulting policy illustrated figure     figure shows five snapshots obtained
single run  particular scenario  person starts far end left corridor 
persons location shown figures since observable robot 
figure instead shows belief person positions  represented distribution point samples
 grey dots fig       point represents plausible hypothesis persons position 
figure shows robot starting far right end corridor  fig    a   robot moves toward
left rooms entrance  fig    b   proceeds check entire room  fig    c  
relatively certain person nowhere found  exits room  fig    d  
moves left branch corridor  finally finds person end
corridor  fig    e  
policy optimized start position  for person robot   scenario
shown figure    one longer execution traces since robot ends searching entire
environment finding person  interesting compare choice action
snapshots  b   d   robot position practically identical  yet  b  robot chooses
go room  whereas  d  robot chooses move toward left  direct
result planning beliefs  rather states  belief distribution person positions
clearly different two cases  therefore policy specifies different course
action 
figure    looks policy obtained solving problem using qmdp heuristic  four snapshots offered different stages specific scenario  assuming person
started far left side robot far right side  fig    a   proceeding
room entrance  fig    b   robot continues corridor almost reaches end
 fig    c   turns around comes back toward room entrance  stations
 fig    d  scenario forcibly terminated  result  robot cannot find person
s he left edge corridor room  whats more  runningaway behavior adopted subject  even person starts elsewhere corridor 
robot approaches person gradually retreat left similarly escape robot 
even though qmdp explicitly plan beliefs  generate different policy actions
cases state identical belief different  seen comparing figure     b   d   these  robot identically located  however belief person
positions different   b   probability mass left robot  therefore travels direction   d   probability mass distributed evenly three branches
 left corridor  room  right corridor   robot equally pulled directions therefore stops
there  scenario illustrates strength qmdp  namely  many cases
necessary explicitly reduce uncertainty  however  shows sophisticated
approaches needed handle cases 
results show pbvi perform outside bounds simple maze domains 
able handle realistic problem domains  particular  throughout evaluation  robot
simulator way constrained behave described pomdp model  sec       
means robots actions often stochastic effects  robots position always
fully observable  belief tracking performed asynchronously  i e   always
straightforward ordering actions observations   despite misalignment model
assumed planning  execution environment  control policy optimized pbvi could
successfully used complete task 

   

fip ineau   g ordon   hrun

 a  t  

 b  t  

 c  t   

 d  t   

 e  t   
figure     example pbvi policy successfully finding person

   

fia nytime p oint based pproximations l arge pomdp

 a  t  

 b  t  

 c  t   

 d  t   
figure     example qmdp policy failing find person

   

fip ineau   g ordon   hrun

   discussion
paper describes class anytime point based pomdp algorithms called pbvi  combines point based value updates strategic selection belief points  solve large pomdps 
extensions pbvi framework  whereby value updates applied groups belief
points according spatial distribution  described  pineau  gordon    thrun        
main contributions pertaining pbvi framework summarized 
scalability  pbvi framework important step towards truly scalable pomdp solutions 
achieved bounding policy size selection small set belief points 
anytime planning  pbvi class algorithms alternates steps value updating steps
belief point selection  new points added  solution improves  expense increased
computational time  trade off controlled adjusting number points  algorithm terminated either satisfactory solution found  planning time
elapsed 
bounded error  provide theoretical bound error approximation introduced
pbvi framework  result holds range belief point selection methods  lead
directly development new pbvi type algorithm  pbvi ger  estimates
error bound used directly select belief points  furthermore find bounds
useful assessing stop adding belief points 
exploration  proposed set new point selection heuristics  explore tree
reachable beliefs select useful belief points  successful technique described  greedy
error reduction  ger   uses estimate error bound candidate belief points select
useful points 
improved empirical performance  pbvi demonstrated ability reduce planning time
number well known pomdp problems  including tiger grid  hallway  hallway  
operating set discrete points  pbvi algorithms perform polynomial time value updates 
thereby overcoming curse history paralyzes exact algorithms  ger technique used
select points allows us solve large problems fewer belief points alternative approaches 
new problem domain  pbvi applied new pomdp planning domain  tag  
generated approximate solution outperformed baseline algorithms qmdp incremental
pruning  new domain since adopted test case algorithms  vlassis  
spaan        smith   simmons        braziunas   boutilier        poupart   boutilier        
fosters increased ease comparison new techniques  comparative analysis
provided section     highlighting similarities differences pbvi perseus 
demonstrated performance  pbvi applied context robotic search and rescue
type scenario  mobile robot required search environment find non stationary
individual  pbvis performance evaluated using realistic  independently developed  robot
simulator 
significant portion paper dedicated thorough comparative analysis point based
methods  includes evaluating range point based selection methods  well evaluating
mechanisms ordering value updates  comparison point based selection techniques suggest ger method presented section     superior naive techniques  terms
ordering value updates  randomized strategy used perseus algorithm appears
effective accelerate planning  natural next step would combine ger belief selection
heuristic perseuss random value updates  performed experiments along lines 
   

fia nytime p oint based pproximations l arge pomdp

achieve significant speed up current performance pbvi perseus  e g  
reported figure    a    likely belief points chosen carefully  as ger  
points needs updated systematically therefore additional benefit
using randomized value updates 
looking towards future  important remember demonstrated
ability solve problems large pomdp standards  many real world domains far exceed
complex domains considered paper  particular  unusual problem
expressed number multi valued state features  case number states grows
exponentially number features  concern belief point
 vector dimensionality  s   where  s  number states  dimensions updated
simultaneously  important issue address improve scalability point based value
approaches general 
various existing attempts overcoming curse dimensionality pomdps 
thesee  g  belief compression techniques roy gordon       cannot
incorporated within pbvi framework without compromising theoretical properties  as discussed section     others  particular exact compression algorithm poupart boutilier
        combined pbvi  however  preliminary experiments direction
yielded little performance improvement  reason believe approximate value compression would yield better results  expense forgoing pbvis theoretical properties  challenge therefore devise function approximation techniques reduce
dimensionality effectively  maintaining convexity properties solution 
secondary  but less important  issue concerning scalability pbvi pertains
number belief points necessary obtain good solution  problems addressed thus far
usually solved o  s   belief points  need true  worse case  number
belief points necessary may exponential plan length  pbvi framework accommodate wide variety strategies generating belief points  greedy error reduction
technique seems particularly effective  however unlikely definitive answer belief
point selection  general terms  relates closely well known issue exploration
versus exploitation  arises across wide array problem solving techniques 
promising opportunities future research aside  pbvi framework already
pushed envelope pomdp problems solved existing computational resources 
field pomdps matures  finding ways computing policies efficiently likely continue
major bottleneck  hope point based algorithms pbvi play leading
role search efficient algorithms 

acknowledgments
authors wish thank craig boutilier  michael littman  andrew moore matthew mason
many thoughtful comments discussions regarding work  thank darius braziunas 
pascal poupart  trey smith nikos vlassis  conversations regarding algorithms
results  contributions michael montemerlo nicholas roy conducting empirical
robot evaluations gratefully acknowledged  finally  thank three anonymous reviewers
one dedicated editor  sridhar mahadevan  whose feedback significantly improved paper 
work funded darpa mars program nsfs itr program  project  robotic
assistants elderly  pi  j  dunbar jacob  
   

fip ineau   g ordon   hrun

references
astrom  k  j          optimal control markov decision processes incomplete state estimation  journal mathematical analysis applications             
bellman  r          dynamic programming  princeton university press 
bertsekas  d  p     tsitsiklis  j          neuro dynamic programming  athena scientific 
blum  a  l     furst  m  l          fast planning planning graph analysis  artificial
intelligence                  
bonet  b          epsilon optimal grid based algorithm partially obserable markov decision
processes  machine learning  proceedings      international conference  icml  
pp       
boutilier  c   dean  t     hanks  s          decision theoretic planning  structural assumptions
computational leverage  journal artificial intelligence research          
boyen  x     koller  d          tractable inference complex stochastic processes  proceedings fourteenth conference uncertainty artificial intelligence  uai   pp       
brafman  r  i          heuristic variable grid solution method pomdps  proceedings
fourteenth national conference artificial intelligence  aaai   pp         
braziunas  d     boutilier  c          stochastic local search pomdp controllers  proceedings nineteenth national conference artificial intelligence  aaai   pp         
burgard  w   cremers  a  b   fox  d   hahnel  d   lakemeyer  g   schulz  d   steiner  w     thrun 
s          experiences interactive museum tour guide robot  artificial intelligence 
         
cassandra  a         
tonys
research ai pomdp code index html 

pomdp

page 

http   www cs brown edu 

cassandra  a   littman  m  l     zhang  n  l          incremental pruning  simple  fast  exact
method partially observable markov decision processes  proceedings thirteenth
conference uncertainty artificial intelligence  uai   pp       
chapman  d          planning conjunctive goals  artificial intelligence                
cheng  h  t          algorithms partially observable markov decision processes  ph d  thesis 
university british columbia 
dean  t     kanazawa  k          probabilistic temporal reasoning  proceedings seventh
national conference artificial intelligence  aaai   pp         
devroye  l          non uniform random variate generation  springer verlag  new york 
engelberger  g          handbook industrial robotics  john wiley sons 
fikes  r  e     nilsson  n  j          strips  new approach application theorem
proving problem solving  artificial intelligence            
hauskrecht  m          incremental methods computing bounds partially observable markov
decision processes  proceedings fourteenth national conference artificial intelligence  aaai   pp         
   

fia nytime p oint based pproximations l arge pomdp

hauskrecht  m          value function approximations partially observable markov decision
processes  journal artificial intelligence research           
jazwinski  a  m          stochastic processes filtering theory  academic  new york 
kaelbling  l  p   littman  m  l     cassandra  a  r          planning acting partially
observable stochastic domains  artificial intelligence             
kalman  r  e          new approach linear filtering prediction problems  transactions
asme  journal basic engineering           
lacey  g     dawson howe  k  m          application robotics mobility aid
elderly blind  robotics autonomous systems             
littman  m  l          algorithms sequential decision making  ph d  thesis  brown university 
littman  m  l   cassandra  a  r     kaelbling  l  p       a   learning policies partially obsevable environments  scaling up  tech  rep  cs        brown university  department
computer science 
littman  m  l   cassandra  a  r     kaelbling  l  p       b   learning policies partially obsevable environments  scaling up  proceedings twelfth international conference
machine learning  pp         
lovejoy  w  s       a   computationally feasible bounds partially observed markov decision
processes  operations research                
lovejoy  w  s       b   survey algorithmic methods partially observable markov decision
processes  annals operations research           
mcallester  d     roseblitt  d          systematic nonlinear planning  proceedings ninth
national conference artificial intelligence  aaai   pp         
monahan  g  e          survey partially observable markov decision processes  theory  models  algorithms  management science             
montemerlo  m   roy  n     thrun  s          perspectives standardization mobile robot
programming  carnegie mellon navigation  carmen  toolkit  proceedings
ieee rsj international conference intelligent robots systems  iros   vol     pp  pp
         
paquet  s          distributed decision making task coordination dynamic  uncertain
real time multiagent environments  ph d  thesis  universite laval 
penberthy  j  s     weld  d          ucpop  sound  complete  partial order planning adl 
proceedings third international conference knowledge representation reasoning  pp         
perseus        http   staff science uva nl mtjspaan software approx 
pineau  j   gordon  g     thrun  s          applying metric trees belief point pomdps 
neural information processing systems  nips   vol     
pineau  j   montermerlo  m   pollack  m   roy  n     thrun  s          towards robotic assistants
nursing homes  challenges results  robotics autonomous systems                  
pollack  m          planning technology intelligent cognifitve orthotics  proceedings
 th international conference ai planning   scheduling  aips  
   

fip ineau   g ordon   hrun

poon  k  m          fast heuristic algorithm decision theoretic planning  masters thesis 
hong kong university science technology 
poupart  p     boutilier  c          value directed belief state approximation pomdps 
proceedings sixteenth conference uncertainty artificial intelligence  uai   pp 
       
poupart  p     boutilier  c          value directed compression pomdps  advances neural
information processing systems  nips   vol     
poupart  p     boutilier  c          bounded finite state controllers  advances neural information processing systems  nips   vol     
rabiner  l  r          tutorial hidden markov models selected applications speech
recognition  proceedings ieee                
rosencrantz  m   gordon  g     thrun  s          locating moving entities dynamic indoor
environments teams mobile robots  second international joint conference
autonomous agents multiagent systems  aamas   pp         
roy  n     gordon  g          exponential family pca belief compression pomdps 
advances neural information processing systems  nips   vol      pp           
smith  t     simmons  r          heuristic search value iteration pomdps  proceedings
twentieth conference uncertainty artificial intelligence  uai  
sondik  e  j          optimal control partially observable markov processes  ph d  thesis 
stanford university 
spaan  m     vlassis  n          perseus  randomized point based value iteration pomdps 
journal artificial intelligence research  jair          
sutton  r  s     barto  a  g          reinforcement learning  introduction  mit press 
thrun  s   fox  d   burgard  w     dellaert  f          robust monte carlo localization mobile
robots  artificial intelligence                  
vlassis  n     spaan  m  t  j          fast point based algorithm pomdps  proceedings
belgian dutch conference machine learning 
white  c  c          survey solution techniques partially observed markov decision
process  annals operations research             
zhang  n  l     liu  w          planning stochastic domains  problem characteristics approximation  tech  rep  hkust cs       dept  computer science  hong kong university science technology 
zhang  n  l     zhang  w          speeding convergence value iteration partially
observable markov decision processes  journal artificial intelligence research        
   
zhou  r     hansen  e  a          improved grid based approximation algorithm pomdps 
proceedings   th international joint conference artificial intelligence  ijcai  
pp         

   


