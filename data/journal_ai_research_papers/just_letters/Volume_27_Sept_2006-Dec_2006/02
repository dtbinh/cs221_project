journal artificial intelligence research                

submitted        published      

cognitive principles robust multimodal interpretation
joyce y  chai
zahar prasov
shaolin qu

jchai cse msu edu
prasovza cse msu edu
qushaoli cse msu edu

department computer science engineering
michigan state university
east lansing  mi       usa

abstract
multimodal conversational interfaces provide natural means users communicate computer systems multiple modalities speech gesture 
build eective multimodal interfaces  automated interpretation user multimodal inputs
important  inspired previous investigation cognitive status multimodal
human machine interaction  developed greedy algorithm interpreting user
referring expressions  i e   multimodal reference resolution   algorithm incorporates
cognitive principles conversational implicature givenness hierarchy applies constraints various sources  e g   temporal  semantic  contextual  resolve
references  empirical results shown advantage algorithm eciently
resolving variety user references  simplicity generality  approach
potential improve robustness multimodal input interpretation 

   introduction
multimodal systems provide natural eective way users interact computers
multiple modalities speech  gesture  gaze  since rst appearance
put that there system  bolt         number multimodal systems
built  among systems combine speech  pointing  neal   shapiro       
stock         gaze  koons  sparrell    thorisson         systems integrate speech
pen inputs  e g   drawn graphics   cohen  johnston  mcgee  oviatt  pittman  smith 
chen    clow        wahlster         systems combine multimodal inputs outputs
 cassell  bickmore  billinghurst  campbell  chang  vilhjalmsson    yan         systems
mobile environments  oviatt      a   systems engage users intelligent
conversation  gustafson  bell  beskow  boye  carlson  edlund  granstrom  house    wiren 
      stent  dowding  gawron  bratt    moore         earlier studies shown
multimodal interfaces enable users interact computers naturally eectively
 oviatt            b  
one important aspect building multimodal systems multimodal interpretation 
process identies meanings user inputs  particular  key element
multimodal interpretation known reference resolution  process nds
proper referents referring expressions  referring expression phrase
given user inputs  most likely speech inputs  refer specic
entity entities  referent entity  e g   specic object  user refers 
suppose user points house   screen says much one 
c
    
ai access foundation  rights reserved 

fichai  prasov    qu

case  reference resolution must infer referent house   assigned
referring expression one  paper particularly addresses problem reference
resolution multimodal interpretation 
multimodal conversation  way users communicate system depends
available interaction channels situated context  e g   conversation focus  visual
feedback   dependencies form rich set constraints various aspects  e g  
semantic  temporal  contextual   correct interpretation attained
simultaneously considering constraints 
previous studies shown user referring behavior multimodal conversation
occur randomly  rather follows certain linguistic cognitive principles 
human machine interaction  earlier work shown strong correlations
cognitive status givenness hierarchy form referring expressions  kehler        
inspired early work  developed greedy algorithm multimodal reference
resolution  algorithm incorporates principles conversational implicature
givenness hierarchy applies constraints various sources  e g   gesture  conversation
context  visual display   empirical results shown promise algorithm
eciently resolving variety user references  one major advantage greedy
algorithm prior linguistic cognitive knowledge used guide
search prune search space constraint satisfaction  simplicity
generality  approach potential improve robustness interpretation
provide practical solution multimodal reference resolution  chai  prasov  blaim 
  jin        
following sections  rst demonstrate dierent types referring behavior
observed studies  briey introduce underlying cognitive principles
human human communication describe principles used computational model eciently resolve multimodal references  finally  present
experimental results 

   multimodal reference resolution
previous work  chai  hong    zhou      b  chai  hong  zhou    prasov        
multimodal conversational system developed users acquire real estate information   
figure   snapshot graphical user interface  users interact interface
speech gesture  table   shows fragment conversation 
fragment  user exhibits dierent types referring behavior  example 
input u  considered simple input  type simple input one
referring expression spoken utterance one accompanying gesture  multimodal
fusion combines information speech gesture likely resolve
refers to  second user input  u     accompanying gesture referring
expression explicitly used speech utterance  time  system needs
use conversation context infer object interest house mentioned
previous turn conversation  third user input  multiple referring
expressions multiple gestures  types inputs considered complex inputs 
   first prototype system developed ibm t  j  watson research center p  hong 
m  zhou  colleagues intelligent multimedia interaction group 

  

fiminimizing conflicts  heuristic repair method

figure    snapshot multimodal conversational system 

u 
s 
u 
s 
u 
s 

speech  much cost 
gesture  point position screen
speech  price    k
graphics  highlight house discussion
speech  large 
speech       square feet
speech  compare house one
gesture      circle    cirle  put two consecutive circles screen 
speech  comparison results
graphics  show table comparison

table    fragment demonstrating interaction dierent types referring behavior
complex inputs dicult resolve  need consider temporal relations
referring expressions gestures  semantic constraints specied
referring expressions  contextual constraints prior conversation 
example  case u    system needs understand refers house
focus previous turn  house one aligned
two consecutive gestures  subtle variations constraints  including
temporal ordering  semantic compatibility  gesture recognition results lead
dierent interpretations 
example  see multimodal conversation  way user interacts system dependent available input channels  e g   speech
gesture   upon his her conversation goals  state conversation 
multimedia feedback system  words  rich context involves
  

fichai  prasov    qu

dependencies many dierent aspects established interaction  interpreting
user inputs situated rich context  example  temporal relations
speech gesture important criteria determine information
two modalities combined  focus attention prior conversation
shapes users refer objects  thus  inuences interpretation referring
expressions  therefore  need simultaneously consider temporal relations
referring expressions gestures  semantic constraints specied referring expressions  contextual constraints prior conversation  paper 
present ecient approach driven cognitive principles combine temporal 
semantic  contextual constraints multimodal reference resolution 

   related work
considerable eort devoted studying user multimodal behavior  cohen       
oviatt      a  mechanisms interpret user multimodal inputs  chai et al       b 
gustafson et al         huls  bos    classen        johnston  cohen  mcgee  oviatt 
pittman    smith        johnston        johnston   bangalore        kehler        koons
et al         neal   shapiro        oviatt  deangeli    kuhn        stent et al         stock 
      wahlster        wu   oviatt        zancanaro  stock    strapparava        
multimodal reference resolution  early work keeps track focus space
dialog  grosz   sidner        display model capture objects visible
graphical display  neal  thielman  dobes  m     shapiro         checks semantic
constraints type candidate objects referenced properties
reference resolution  modied centering model multimodal reference resolution
introduced previous work  zancanaro et al          idea based
centering movement turns  segments discourse constructed 
discourse entities appearing segment accessible current turn
used constrain referents referring expressions  another approach introduced
use contextual factors multimodal reference resolution  huls et al         
approach  salience value assigned instance based contextual factors 
determine referents multimodal referring expressions  approach retrieves
salient referent satises semantic restrictions referring expressions 
earlier approaches greedy nature  largely dependent semantic
constraints and or constraints conversation context 
resolve multimodal references  two important issues  first mechanism combine information various sources modalities  second capability obtain best interpretation  among possible alternatives  given set
temporal  semantic  contextual constraints  section  give brief introduction
three recent approaches address issues 
    multimodal fusion
approaches multimodal fusion  johnston        johnston   bangalore         although
focus dierent problem overall input interpretation  provide eective solutions
reference resolution  two major approaches multimodal fusion  unication  

fiminimizing conflicts  heuristic repair method

based approaches  johnston        nite state approaches  johnston   bangalore 
      
unication based approach identies referents referring expressions unifying
feature structures generated speech utterances gestures using multimodal grammar  johnston et al         johnston         multimodal grammar combines
temporal spatial constraints  temporal constraints encode absolute temporal relations speech gesture  johnston          grammar rules predened
based empirical studies multimodal interaction  oviatt et al          example  one
rule indicates speech gesture combined speech either overlaps
gesture follows gesture within certain time frame  unication approach
process certain complex cases  as long satisfy predened multimodal
grammar  speech utterance accompanied one gesture dierent
types  johnston         using approach accommodate various situations
described figure   require adding dierent rules cope situation 
specic user referring behavior exactly match existing integration rules
 e g   temporal relations   unication would fail therefore references would
resolved 
nite state approach applies nite state transducers multimodal parsing
understanding  johnston   bangalore         unlike unication based approach
chart parsing subject signicant computational complexity concerns  johnston
  bangalore         nite state approach provides ecient  tight coupling
multimodal understanding speech recognition  approach  multimodal contextfree grammar dened transform syntax multimodal inputs semantic
meanings  domain specic semantics directly encoded grammar  based
grammars  multi tape nite state automata constructed  automata
used identifying semantics combined inputs  rather absolute temporal
constraints unication based approach  approach relies temporal order
dierent modalities  parsing stage  gesture input gesture
tape  e g   pointing particular person  combined speech expression
speech tape  e g   person  considered referent expression 
problem approach multi tape structure takes input speech
gesture incorporate conversation history consideration 
    decision list
identify potential referents  previous work investigated givenness hierarchy  to
introduced later  multimodal interaction  kehler         based data collected
wizard oz experiments  investigation suggests users tend tailor
expressions perceive systems beliefs concerning cognitive status
referents prominence  e g   highlight  display  tailored referring
expressions resolved high accuracy based following decision list 
   object gestured to  choose object 
   otherwise  currently selected object meets semantic type constraints imposed
referring expression  choose object 
  

fichai  prasov    qu

   otherwise  visible object semantically compatible  choose
object 
   otherwise  full np  such proper name  used uniquely identify referent 
studies  chai  prasov    hong      a   found decision list
following limitations 
depending interface design  ambiguities  from systems perspective  could
occur  example  given interface one object  e g   house  sometimes
created top another object  e g   town   pointing gesture could result
multiple potential objects  furthermore  given interface crowded objects 
nger point could result multiple objects dierent probabilities 
decision list able handle ambiguous cases 
user inputs always simple  consisting one referring expression
one gesture indicated decision list   fact  study  chai et al  
    a   found user inputs complex  consisting multiple referring
expressions and or multiple gestures  referents referring expressions
could come dierent sources  gesture inputs conversation context 
temporal alignment speech gesture important determining
correct referent given expression  decision list able handle
types complex inputs 
nevertheless  previous ndings  kehler        inspired work provided
basis algorithm described paper 
    optimization
recently  probabilistic approach developed optimizing reference resolution based
graph matching  chai et al       b   graph matching approach  information
gathered multiple input modalities conversation context represented
attributed relational graphs  args   tsai   fu         specically  two graphs used 
one graph represents referring expressions speech utterances  i e   called referring
graph   referring graph contains referring expressions used speech utterance
relations expressions  node corresponds one referring expression
consists semantic temporal information extracted expression 
edge represents semantic temporal relation two referring expressions 
resulting graph fully connected  undirected  graph  example  shown
figure   a   speech input compare house  green house  brown one 
three nodes generated referring graph representing three referring expressions 
node contains semantic temporal features related corresponding referring
expression  include expressions semantic type  house  town  etc    number
potential referents  type dependent features  size  price  etc    syntactic category
expression  timestamp expression produced  edge contains
features describing semantic temporal relations pair nodes  semantic
features simply indicate whether two nodes share semantic type
  

fiminimizing conflicts  heuristic repair method

figure    reference resolution probabilistic graph matching

inferred utterance  otherwise  semantic type relation deemed
unknown  temporal features indicate two expressions uttered rst 
similarly  another graph represents potential referents gathered gestures  history  visual display  i e   called referent graph   node referent graph
captures semantic temporal information potential referent  together
selection probability  selection probability particularly applied objects indicated gesture  gesture pointing circle potentially introduce
ambiguity terms intended referents  selection probability used indicate
likely object selected particular gesture  selection probability
derived function distance location entity focus point
recognized gesture display  referring graph  edge referent
graph captures semantic temporal relations two potential referents
whether two referents share semantic type temporal order
two referents introduced discourse  example  since gesture input
consists two pointings  referent graph  figure  b  consists potential referents
two pointings  objects rst dashed rectangle potential referents
selected rst pointing  second dashed rectangle correspond
second pointing  furthermore  salient objects prior conversation included referent graph since could potential referents well  e g  
rightmost dashed rectangle figure  b  
given graph representations  reference resolution problem becomes probabilistic graph matching problem  gold   rangarajan         goal nd match
referring graph gs referent graph gc   achieves maximum
compatibility  i e   maximizes q gc   gs    described following equation 
   subscription gs refers speech referring expressions c gc refers candidate referents 

  

fichai  prasov    qu

q gc   gs    


 x    n odesim x    
x
p




 

x





n p  x    p  y   n  edgesim xy   mn  

   

p  x     matching probability referent node x referring node
  overall compatibility q gc   gs   depends node compatibility n odesim
edge compatibility edgesim  dened temporal semantic
constraints  chai et al          algorithm converges  p  x     gives matching
probabilities referent node x referring node maximizes overall
compatibility function  using matching probabilities  system able identify
probable referent x referring node   specically  referring expression
matches potential referent assigned referent probability match
exceeds empirically computed threshold  threshold met  referring
expression remains unresolved 
theoretically  approach provides solution maximizes overall satisfaction
semantic  temporal  contextual constraints  however  many optimization
approaches  algorithm non polynomial  relies expensive matching process 
attempts every possible assignment  order converge optimal interpretation
based constraints  however  previous linguistic cognitive studies indicate
user language behavior occur randomly  rather follows certain cognitive principles  therefore  question arises whether knowledge cognitive principles
used guide matching process reduce complexity 

   cognitive principles
motivated previous work  kehler         specically focus two principles  conversational implicature givenness hierarchy 
    conversational implicature
grices conversational implicature theory indicates interpretation inference
utterance communication guided set four maxims  grice         among
four maxims  maxim quantity maxim manner particularly useful
purpose 
maxim quantity two components      make contribution informative required  for current purposes exchange       make
contribution informative required  context multimodal conversation 
maxim indicates users generally make unnecessary gestures speech
utterances  especially true pen based gestures since usually require special
eort user  therefore  pen based gesture intentionally delivered user 
information conveyed often crucial component used interpretation 
grices maxim manner four components      avoid obscurity expression     
avoid ambiguity      brief      orderly  maxim indicates users
intentionally make ambiguous references  use expressions  either speech
gesture  believe uniquely describe object interest listeners  in
case computer system  understand  expressions choose depend
  

fiminimizing conflicts  heuristic repair method

status
expression form
f ocus


activated
that  this  n

f amiliar
n

u nique identif iable
n

ref erential
indef inite n

identif iable

figure    givenness hierarchy

information mental models current state conversation  however 
information users mental model might dierent information system
possesses  information gap happens  dierent ambiguities could occur
system point view  fact  ambiguities intentionally caused
human speakers  rather systems incapability choosing among alternatives
given incomplete knowledge representation  limited capability contextual inference 
factors  e g   interface design issues   therefore  system anticipate
deliberate ambiguities users  e g   user utters house refer particular
house screen   rather focus dealing types ambiguities
caused systems limitations  e g   gesture ambiguity due interface design
speech ambiguity due incorrect recognition  
two maxims help positioning role gestures reference resolution 
particular  maxims put potential referents indicated gesture
important position  described section   
    givenness hierarchy
givenness hierarchy proposed gundel et al  explains dierent determiners
pronominal forms signal dierent information memory attention state  i e  
cognitive status   gundel  hedberg    zacharski         figure    six
cognitive statuses hierarchy  example  focus indicates highest attentional
state likely continue topic  activated indicates entities short term
memory  statuses associated forms referring expressions 
hierarchy  cognitive status implies statuses list  example  focus
implies activated  familiar  etc  use particular expression form signals
associated cognitive status met  signals lower statuses
met  words  given form used describe lower status used
refer higher status  vice versa  cognitive statuses necessary conditions
  

fichai  prasov    qu

appropriate use dierent forms referring expressions  gundel et al  found dierent
referring expressions almost exclusively correlate six statuses hierarchy 
givenness hierarchy investigated earlier algorithms resolving pronouns demonstratives spoken dialog systems  eckert   strube        byron       
multimodal interaction  kehler         particular  would extend previous work  kehler        investigate whether conversational implicature givenness hierarchy used resolve variety references simple complex 
precise ambiguous  furthermore  decision list used kehler        proposed based data analysis implemented evaluated real time
system  therefore  second goal design implement ecient algorithm
incorporating cognitive principles empirically compare performance
optimization approach  chai et al          nite state approach  johnston   bangalore 
       decision list approach  kehler        

   greedy algorithm
greedy algorithm always makes choice looks best moment processing 
is  makes locally optimal choice hope choice lead globally optimal solution  simple ecient greedy algorithms used approximate
many optimization problems  explore use conversational implicature
givenness hierarchy designing ecient greedy algorithm  particular  extend
decision list kehler        utilize concepts two cognitive principles
following way 
corresponding givenness hierarchy  following hierarchy holds potential
referents  f ocus   v isible  hierarchy indicates objects focus higher
status terms attention states objects visual display  focus
corresponds cognitive statuses focus activated givenness hierarchy 
visible corresponds statuses familiar uniquely identifiable  note
givenness hierarchy ne grained terms dierent statuses  application
may able distinguish dierence statuses  e g   focus
activated  eectively use them  therefore  focus visible introduced
group similar statuses  with respect application  together  since
need dierentiate objects mentioned recently  e g  
focus activated  objects accessible either graph display
domain model  e g   familiar unique identiable   assign
dierent modied statuses  e g   focus visible  
based conversational implicature  since pen based gesture takes special effort deliver  must convey certain useful information  fact  objects indicated
gesture highest attentional state since deliberately singled
user  therefore  combining          derive modied hierarchy
gesture   f ocus   v isible   others  others corresponds indenite cases
givenness hierarchy  modied hierarchy coincides processing order
kehlers decision list         modied hierarchy guide greedy
  

fiminimizing conflicts  heuristic repair method

algorithm search solutions  next  describe detail algorithm
related representations functions 
    representation
turn   i e   receiving user input  conversation  use three vectors
represent rst three statuses modied hierarchy  objects selected gesture 
objects focus  objects visible display follows 
gesture vector  g   captures objects selected series gestures  element gi
object potentially selected gesture  elements gi gj   j 
gesture selects objects gi should     temporally precede gesture selects
gj    gesture selects gj since one gesture could result
multiple objects 
focus vector  f  captures objects focus selected
gesture  element represents object considered focus attention
previous turn conversation  temporal precedence relation
elements  consider corresponding objects simultaneously
accessible current turn conversation 
captures objects visible display neither
display vector  d 
selected gesture  i e   g  focus  f   temporal precedence relation elements  elements simultaneously accessible 
based representations  object domain interest belongs either
one vectors others  object vectors consists
following attributes 
semantic type object  example  semantic type could house
town 
attributes object  domain dependent feature  set attributes
associated semantic type  example  house object price  size 
year built  etc  attributes  furthermore  object visual properties
reect appearance object display color object icon 
identier object  object unique name 
selection probability  refers probability given object selected 
depending interface design  gesture could result list potential referents 
use selection probability indicate likelihood object selected
gesture  calculation selection probability described later  objects
focus vector display vector  selection probabilities set   n
n total number objects respective vector 
   currently  user inactivity  i e     seconds input either speech gesture  used
boundary decide interaction turn 

  

fichai  prasov    qu

temporal information  relative temporal ordering information corresponding gesture  instead applying time stamps previous work  chai et al  
    b   use index gestures according order occurrences  object selected rst gesture  temporal information
would   
addition vectors capture potential referents  user input  vector
represents referring expressions speech utterance  r  maintained 
element  i e   referring expression  following information 
identier potential referent indicated referring expression 
example  identier potential referent expression house number eight
house object identier eight 
semantic type potential referents indicated expression  example 
semantic type referring expression house house 
number potential referents indicated referring expression
utterance context  example  singular noun phrase refers one object 
phrase three houses provides exact number referents  i e      
type dependent features  features associated potential referents 
color price  extracted referring expression 
temporal ordering information indicating order referring expressions
uttered  again  instead specic time stamp  use
temporal ordering information  utterance consists n consecutive referring
expressions  temporal ordering information would      
n  
syntactic categories referring expressions  currently  referring
expression  assign one six syntactic categories  e g   demonstrative
pronoun   details explained later 
four vectors updated user turn conversation based current
user input system state  e g   shown screen identied
focus previous turn conversation  
    algorithm
ow chart pseudo code algorithm shown figure   
multimodal input particular turn conversation  algorithm takes inputs
vector  r  referring expressions size k  gesture vector  g   size m  focus
size l  rst creates three matrices
vector  f   size n  display vector  d 
g i  j   f  i  j   d i  j  capture scores matching referring expression
r object three vectors  calculation matching score described later 
note that  g  f  empty  corresponding matrix  i e   g  f  
d  empty 
  

fiminimizing conflicts  heuristic repair method

initializematchmatrix       
 i      m  j      k  g i  j    match gi  rj 
 i      n  j      k  f i  j    match fi  rj 
 i      l  j      k  d i  j    match di  rj 
 

yes

g empty


greedysortinggesture  
index max        index column
 i      m   
find j index max  g i  j  largest among elements row i 
add mark   g i  j  
index max   j      complete finding best match view object
assignreferentsfrommatrix  g  
 

references resolved 



yes

yes
f empty



return results

greedysortingfocus 
 j      k 
 rj resolved 
cross column j f   only keep ones resolved
       n  
find j f i  j  largest among elements row i 
mark   f i  j    
assignreferentsfrommatrix  f  
 

references resolved 



greedysortingdisplay 
 j      k 
 rj resolved 
cross column j d 
       l  
find j d i  j  largest among elements row i 
mark   d i  j    
assignreferentsfrommatrix  d  
 

return results

assignreferentsfrommatrix  matrix x  
 i      k     i e   expression ri column
 ri indicates specific number n n elements
ith column x   
assign n largest elements   ri referents 
else assign elements   ri referents 
 

figure    greedy algorithm multimodal reference resolution

  

yes

return results

fichai  prasov    qu

based matching scores three matrices  algorithm applies greedy
search guided modied hierarchy described earlier  since gesture
highest status  algorithm rst searches gesture matrix  g  keeps track
matching scores referring expressions objects gestures  identies
highest  or multiple highest  matching scores assigns possible objects
gestures expressions  greedysortinggesture  
referring expressions left resolved gestures processed 
algorithm looks objects focus matrix  f   since focus next highest cognitive status  greedysortingfocus   still expressions resolved 
algorithm looks objects display matrix  d   greedysortingdisplay   currently 
algorithm focuses three statuses  certainly  still expressions
resolved steps  algorithm consult proper name resolution 
referring expressions resolved  system output results 
next multimodal input  system generate four new vectors apply greedy
algorithm again 
note greedysortinggesture  use index max keep track column index
corresponds largest matching value  algorithm incrementally processes
row matrix  index max incrementally increase  referring expressions gesture aligned according order occurrences 
since objects focus matrix display matrix temporal precedence
relations  greedysortingfocus greedysortingdisplay use constraint 
reason call algorithm greedy always nds best assignment
referring expression given cognitive status hierarchy  words  algorithm
always makes best choice referring expression one time according
order occurrence utterance  one imagine mistaken assignment
made expression aect assignment following expressions  therefore 
greedy algorithm may lead globally optimal solution  nevertheless  general
user behavior following guiding principles makes greedy algorithm useful 
one major advantage greedy algorithm use modied hierarchy signicantly prune search space compared graph matching approach 
given referring expressions n potential referents various sources  e g   gesture 
conversation context  visual display   algorithm nd solution o mn  
furthermore  algorithm goes beyond simple precise inputs illustrated
decision list kehler         scoring mechanism  described later  greedy
sorting process accommodate complex ambiguous user inputs 
    matching functions
important component algorithm matching score object  o 
referring expression  e   use following equation calculate matching score 
atch o  e     



p  o s  p  s e   compatibility o  e 

   

s g f d 

formula  represents possible associated status object o  could
three potential values  g  representing gesture   f  focus    display  
function determined three components 
  

fiminimizing conflicts  heuristic repair method

rst  p  o s   object selectivity component measures probability
object referent given status  s  object  i e   gesture  focus 
visual display  
second  p  s e   likelihood status component measures likelihood
status potential referent given particular type referring expression 
third  compatibility o  e   compatibility component measures
semantic temporal compatibility object referring expression
e 
next explain three components detail 
      object selectivity
calculate p  o s   gesture   use function takes consideration
distance object focus point gesture display  chai et al  
    b  
given object focus  i e   selected gesture   p  o s   f ocus      n  
n total number objects focus vector  object neither
selected gesture  focus  visible screen  p  o s   display   
  m   total number objects display vector  currently 
applied simplest uniform distribution objects focus graphical
display  future  intend incorporate recency conversation discourse
model p  o s   f ocus  use visual prominence  e g   based visual characteristics 
model p  o s   display   note that  discussed earlier section      object
associated one three statuses  words  given object o 
one p  o s   gesture   p  o s   f ocus   p  o s   display  non zero 
      likelihood status
motivated givenness hierarchy earlier work  kehler        form
referring expressions reect cognitive status referred entities users mental
model  use likelihood status measure probability reected status given
particular type referring expression  particular  use data reported kehler
       derive likelihood status potential referents given particular type
referring expression p  s e   categorize referring expressions following six
categories 
empty  referring expression used utterance 
pronouns  it  they 
locative adverbs 
demonstratives  this  that  these 
denite noun phrases  noun phrases denite article
full noun phrases  types proper nouns 
  

fichai  prasov    qu

p  s e 
visible
focus
gesture
sum

empty
 
    
    
 

pronoun
 
    
    
 

locative
 
    
    
 

demonstratives
 
    
    
 

definite
 
    
    
 

full
 
    
    
 

table    likelihood status referents given particular type expression
table   shows estimated p  s e   note that  original data provided kehler
        zero count certain combination referring type referent status 
zero counts result zero probability table  use smoothing
techniques re distribute probability mass  furthermore  probability mass
assigned status others 
      compatibility measurement
term compatibility o  e  measures compatibility object referring
expression e  similar compatibility measurement earlier work  chai et al  
       dened multiplication many factors following equation 
compatibility o  e    id o  e  sem o  e 



attrk  o  e  emp o  e 

   

k

equation 
id o  e  captures compatibility identier  or name  identier
 or name  specied e  indicates identier potential referent 
expressed referring expression  match identier true referent 
particularly useful resolving proper nouns  example  referring
expression house number eight  correct referent identier
number eight  id o  e      identities e dierent  id o  e     
identities e either one both unknown 
sem o  e  captures semantic type compatibility e  indicates
semantic type potential referent expressed referring expression
match semantic type correct referent  sem o  e      semantic types
e dierent  sem o  e      unknown 
attrk  o  e  captures type specic constraint concerning particular semantic feature
 indicated subscript k   constraint indicates expected features
potential referent expressed referring expression compatible
features associated true referent  example  referring expression
victorian house  style feature victorian  therefore  object
possible referent style object victorian  thus  dene following 
attrk  o  e      e feature k values feature k
equal  otherwise  attrk  o  e      
  

fiminimizing conflicts  heuristic repair method

 house  
 house    house  
town   
town    town   
gesture input        i  i   i
speech input  compare houses 
time

figure    example complex input

emp o  e  captures temporal compatibility e  consider temporal ordering speech gesture  specically  temporal
compatibility dened following 
emp o  e    exp  orderindex o  orderindex e   

   

order speech accompanying gestures occur important
deciding gestures aligned referring expressions 
order accompanying gestures introduced discourse
consistent order corresponding referring expressions
uttered  example  suppose user input consists three gestures g    g    g 
two referring expressions  s    s    possible g  align s 
g  align s    note that  status object either focus visible 
emp o  e       denition temporal compatibility dierent
function used previous work  chai et al         takes real time stamps
consideration  section     shows dierent performance results based dierent
temporal compatibility functions 
    example
figure   shows example complex input involves multiple referring expressions
multiple gestures  interface displays house icons top town icons 
point  or circle  could result house town object  example  rst
gesture results house   town    second gesture results house  
town    third results house   town    suppose input takes
place  house   highlighted screen previous turn conversation  i e  
house   focus   furthermore  eight objects visible screen 
resolve referents expressions houses  greedy algorithm takes
following steps 
r created lengths             respectively
   four input vectors  g  f  d 
represent six objects gesture vector  one object focus  eight objects
graphical display  two referring expressions used utterance 
   gesture matrix g     focus matrix f     display matrix d   created 
   three matrixes initialized equation    figure   shows resulting
gesture matrix  probability values p  s e  come table    dierence
  

fichai  prasov    qu

status
 g 

referring expression match

potential
referent

j     



j      houses

               

     house  

                   

gesture  
     town  

            

            

     house  

                   

                

     town  

            

            

gesture  
     house  

                  

                   

     town  

            

            

gesture  

 a  gesture matrix
status
 f 

potential
referent

referring expression match

focus

     house  

j     



j      houses

               

 b  focus matrix

figure    gesture matrix  a  focus matrix  b  processing example figure   
cell referring expression match columns corresponds instantiation
matching function 

compatibility values house objects gesture matrix mainly due
temporal ordering compatibilities 
   next greedysortinggesture procedure executed  row gesture matrix  algorithm nds largest legitimate value marks corresponding cell
   legitimate means corresponding cell row    
either column column right corresponding cell
row i  values shown bold figure   a   next  starting
column  algorithm checks referring expression whether exists
corresponding column  so  objects assigned referring
expressions based number constraints  case  since specic number
given referring expression houses  three marked objects assigned
houses 
   houses  still left resolved  algorithm continues
execute greedysortingfocus  focus matrix prior executing greedysortingfocus
shown figure   b   note since houses longer considered 
corresponding column deleted focus matrix  similar previous step 
largest non zero match value marked  shown bold figure   b   assigned
remaining referring expression it 
   resulting display matrix shown point  referring expressions resolved 
  

fiminimizing conflicts  heuristic repair method

s    the adj   n  n s 
s     this that  adj  n
s     these those  num    adj  n
s    it this that  this that the adj one
s     these those num  adj ones them
s    here there
s    empty expression
s    proper nouns
s    multiple expressions
total num 

g 

gest 
 
 
 
 
 
 
 
 
 
  

g 
one
pt
 
  
 
 
 
 
 
 
 
  

g 
mult 
pts
 
 
 
 
 
 
 
 
 
  

g 
one
cir
 
  
  
  
 
 
 
 
  
  

g 
mult 
cirs
 
 
 
 
 
 
 
 
  
  

g 
pts  
cirs
 
 
 
 
 
 
 
 
 
  

total
num
  
  
  
  
 
 
 
  
  
   

table    detailed description user referring behavior

   evaluation
use data collected previous work  chai et al         evaluate greedy
algorithm  questions addressed evaluation following 
impact temporal alignment speech gesture performance greedy algorithm 
role modeling cognitive status greedy algorithm 
eective greedy algorithm compared graph matching algorithm
 section      
error sources contribute failure real time reference resolution 
greedy algorithm compared nite state approach  section     
decision list approach  section      
    experiment setup
evaluation data collected eleven subjects participated study 
subjects asked interact system using speech gestures
 e g   pointing circle  accomplish tasks related real estate information seeking 
rst task nd least expensive house populated town  order
accomplish task  user would rst nd town highest
population nd least expensive house town  next task involved
obtaining description house located previous task  next task
compare house located rst task houses particular
town terms price  additionally  least expensive house second town
determined  another task nd expensive house particular town 
  

fichai  prasov    qu

s    referring expression
s    one referring expression
s    multiple referring expressions
total num 

g   
gesture
   a 
    a 
   c 
  

g    one
gesture
   a 
     b 
    c 
   

g    multigesture
   c 
    c 
    c 
  

total
num
 
   
  
   

table    summary user referring behavior
last task involved comparing resulting houses previous four tasks 
last task  previous four tasks may completely partially repeated 
tasks designed users required explore interface acquire various
types information 
acoustic model subject trained individually minimize speech recognition errors  study session videotaped capture audio video
screen movement  including gestures system responses   ibm viavoice speech
recognizer used process speech input 
table   provides detailed description referring behavior observed study 
columns indicate whether gesture  one gesture  pointing circle   multiple gestures involved multimodal input  rows indicate type referring expressions
speech utterance  table entry shows number particular combination
speech gesture inputs 
table   summarizes table   terms whether gesture  one gesture  multiple
gestures  shown columns  whether referring expression  one referring expression 
multiple referring expressions  shown rows  involved input  note
table intended input counted one input even input may split
turns system run time 
based table    categorize user inputs following three categories 
simple inputs one zero alignment  inputs contain speech referring
expression gesture  i e    s    g      one referring expression zero gesture
 i e    s    g      referring expression one gesture  i e     s    g     
types inputs require conversation context visual context resolve
references  one example type u  table    data  total
   inputs belong category  marked  a  table    
simple inputs one one alignment  inputs contain exactly one referring
expression one gesture  i e     s    g      types inputs resolved
mostly combining gesture speech using multimodal fusion  total    
inputs belong category  marked  b  table    
complex inputs  inputs contain one referring expression and or gesture  corresponds entry   s    g       s    g      s    g    
  s    g    table    one example type u  table    total   
  

fiminimizing conflicts  heuristic repair method

no  correctly resolved
simple one zero alignment
simple one one alignment
complex
total
accuracy

ordering
 
   
  
   
     

absolute
 
   
  
   
     

combined
 
   
  
   
     

table    performance comparison based dierent temporal compatibility functions
inputs belong category  marked  c  table     types inputs
particularly challenging resolve 
section  focus dierent performance evaluations based three
types referring behaviors 
    temporal alignment speech gesture
multimodal interpretation  align speech gesture based temporal
information important question  especially case complex inputs
multimodal input consists multiple referring expressions multiple gestures 
evaluated dierent temporal compatibility functions greedy approach  particular 
compared following three functions 
ordering temporal constraint equation   
absolute temporal constraint dened following formula 
emp o  e    exp  begint ime o  begint ime e   

   

here  absolute timestamps potential referents  e g   indicated gesture 
referring expressions used instead relative orders relevant entities
user input 
combined temporal constraint combines two aforementioned constraints 
giving equal weight determining compatibility score object
referring expression 
results shown table    dierent temporal constraints aect processing complex inputs  ordering temporal constraint worked slightly better
absolute temporal constraint  fact  temporal alignment speech gesture often one problems may aect interpretation results  previous studies found
gestures tend occur corresponding speech unit takes place  oviatt et al  
       ndings suggest users tend tap screen rst start
speech utterance  behavior observed simple command based system  oviatt
et al         speech unit corresponds single gesture  i e   simple inputs
work  
  

fichai  prasov    qu

non overlap
overlap
total  

speech first
  
  
   

gesture first
   
   
   

total
   
   
    

table    overall temporal relations speech gesture

study  found temporal alignment gesture corresponding
speech units still issue needs investigated order improve
robustness multimodal interpretation  table   shows percentage dierent
temporal relations observed study  rows indicate whether overlap
speech referring expressions accompanied gestures  columns indicate
whether speech  more precisely  referring expressions  gesture occurred rst 
consistent previous ndings  oviatt et al          cases      time  
gestures occurred referring expressions uttered  however      cases
speech referring expressions uttered corresponding gesture occurred 
among cases     overlap referring expressions gesture
   overlap 
furthermore  although multimodal behaviors sequential  i e   non overlap 
simultaneous  e g   overlap  integration quite consistent course interaction  oviatt  coulston  tomko  xiao  bunsford  wesson    carmichael        
exceptions  figure   shows temporal alignments individual users study 
user     user    user   maintained consistent behavior user  s gesture always
happened overlapped corresponding speech referring expressions  user
 s gesture always occurred ahead speech expressions without overlapping  user
 s speech referring expressions always occurred corresponding gestures  without
overlap   users exhibited varied temporal alignment speech
gesture interaction  dicult system using pre dened temporal
constraints anticipate accommodate dierent behaviors  therefore 
desirable mechanism automatically learn user behavior alignment
automatically adjust behavior 
one potential approach introduce calibration process real human computer
interaction  calibration process  two tasks performed user  rst
task  user asked describe objects graph display speech
deictic gestures  second task  user asked respond system
questions using speech deictic gestures  reason users perform
two tasks identify whether dierence user initiated inputs
system initiated user responses  based tasks  temporal relations
speech units corresponding gestures captured used real time
interaction 
  

fiminimizing conflicts  heuristic repair method

percentage occurance

non overlap speech first
overlap speech first

non overlap gesture first
overlap gesture first

 
   
   
   
   
   
   
   
   
   
 
 

 

 

 

 

 

 

 

 

  

  

user index

figure    temporal alignment behavior user study

no  correctly resolved
simple one zero alignment
simple one one alignment
complex
total

cognitive principles
 
   
  
   

without cognitive principles
 
  
  
   

table    role cognitive principles greedy algorithm

    role cognitive principles
examine role modeling cognitive status multimodal reference  compared two congurations greedy algorithm  rst conguration based
matching score dened equation    incorporates cognitive principles described
earlier  second conguration uses matching score completely dependent compatibility referring expression gesture  i e   section       
without using cognitive principles  i e   p  o s  p  s e  included equation
   
table   shows comparison results terms two congurations  algorithm
using cognitive principles outperforms algorithm use cognitive
principles      performance dierence applies simple inputs
one one alignment complex inputs  results indicate modeling cognitive
status potentially improve reference resolution performance 
  

fichai  prasov    qu

total num
total
simple one zero alignment
simple one one alignment
complex

   
  
   
  

graph matching
num  
   
     
 
     
   
     
  
     

greedy
num  
   
     
 
     
   
     
  
     

table    performance comparison graph matching algorithm greedy
algorithm

    greedy algorithm versus graph matching algorithm
compared greedy algorithm graph matching algorithm terms
performance runtime  table   shows performance comparison  overall  greedy
algorithm performs comparably graph matching algorithm 
compare runtime  ran algorithm user    times input
run     times  words  user input run      times algorithm
get average runtime measurement  experiment done ultrasparc iii
server    mhz   bit 
greedy algorithm graph matching algorithm function
calls process speech inputs  e g   parsing  gesture inputs  e g   identify potentially
intended objects   dierence algorithms specic implementations
regarding graph creation matching graph matching algorithm greedy
search greedy algorithm  result  average time greedy algorithm
process simple inputs complex inputs      milliseconds      milliseconds
respectively  average time graph matching algorithm process simple
complex inputs      milliseconds      milliseconds respectively  results show
average greedy algorithm runs slightly faster graph matching algorithm
given current implementation  although worst case  graph matching algorithm
asymptotically complex 
    real time error analysis
understand bottleneck real time multimodal reference resolution  examined
error cases algorithm failed provide correct referents 
spoken dialog systems  speech recognition major bottleneck  although
trained users acoustic model individually  speech recognition rate still
low      inputs correctly recognized referring expressions  among
inputs      resolved correct referents  fusing inputs multiple
modalities together sometimes compensate recognition errors  oviatt        
among    inputs referring expressions incorrectly recognized    
correctly assigned referents due mutual disambiguation  mechanism reduce
  

fiminimizing conflicts  heuristic repair method

recognition errors  especially utilizing information modalities 
important provide robust solution real time multimodal reference resolution 
second source errors comes another common problem spoken dialog
systems  namely out of vocabulary words  example  area vocabulary 
additional semantic constraint expressed area captured  therefore 
system could identify whether house town referred user uttered
area  important system capability acquire knowledge  e g  
vocabulary  dynamically utilizing information modalities interaction
context  furthermore  errors came lack understanding spatial relations
 as house close red one  superlatives  as expensive house  
algorithms aligning visual features resolve spatial references desirable  gorniak
  roy        
addition two main sources  errors caused unsynchronized inputs 
currently  use idle status  i e     seconds input either speech gesture 
boundary delimit interaction turn  two types synchronization
observed  rst type unsynchronized inputs user  such big pause
speech gesture  comes underlying system implementation 
system captures speech inputs gesture inputs two dierent servers
tcp ip protocol  communication delay sometimes split one synchronized input
two separate turns inputs  e g   one turn speech input alone turn
gesture input alone   better engineering mechanism synchronizing inputs desired 
disuencies users accounted small number errors  current algorithm incapable distinguishing disuent cases normal cases  fortunately 
disuent situations occur frequently study  only   inputs disuency   consistent previous ndings speech disuency rate lower
human machine conversation spontaneous speech  brennan         humancomputer conversation  users tend speak carefully utterances tend short  recent
ndings indicated gesture patterns could used additional source identify
dierent types speech disuencies human human conversation  chen  harper   
quek         based limited cases  found gesture patterns could indicators
speech disuencies occur  example  user says show red
house  point house a   green house  still point house a   behavior
pointing house dierent speech description usually indicates repair  furthermore  gestures involve disuencies  example  repeatedly pointing object
gesture repetition  failure identifying disuencies caused problems reference
resolution  ideal mechanism identify disuencies using
multimodal information 
    comparative evaluation two approaches
examine greedy algorithm compared nite state approach
 section      decision list approach  section       conducted comparative evaluation  original nite state approach  n best speech hypotheses maintained
speech tape  data here  best speech hypothesis speech
input  therefore  manually updated incorrectly recognized words nite
  

fichai  prasov    qu

no  correctly resolved
simple inputs one one alighment
simple inputs zero one alighment
complex inputs
total

greedy
   
 
  
   

finite state
   
 
  
   

decision list
  
  
 
   

table    performance comparison two approaches
state approach would penalized lack n best speech hypotheses    
modied data used three approaches  table   shows comparison results 
shown table  greedy algorithm correctly resolved inputs
nite state approach decision list approach  major problem nite state
approach incorporate conversation context nite state transducer 
problem contributes failure resolving simple inputs zero one alignment
complex inputs  major problem decision list approach 
described earlier  lack capabilities process ambiguous gestures complex
inputs 
note greedy algorithm algorithm obtain full semantic interpretation multimodal input  rather algorithm specically reference
resolution  uses information context gesture resolve speech referring expressions  regard  greedy algorithm dierent nite state approach
whose goal get full interpretation user inputs reference resolution
part process 

   conclusion
motivated earlier investigation cognitive status human machine interaction 
paper describes greedy algorithm incorporates cognitive principles underlying human referring behavior resolve variety references human machine multimodal
interaction  particular  algorithm relies theories conversation implicature
givenness hierarchy eectively guide system searching potential referents  empirical studies shown modeling form referring experssions
implication cognitive status achieve better results algorithm
considers compatibility referring expressions potential referents 
greedy algorithm eciently achieve comparable performance previous optimization
approach based graph matching  furthermore  greedy algorithm handles
variety user inputs ranging precise ambiguous simple complex 
outperforms nite state approach decision list approach experiments 
simplicity generality  approach potential improve robustness multimodal interpretation  learned investigation prior
   note corrected inputs direct correspondence recognized
words transcribed words maintain consistency timestamps 

  

fiminimizing conflicts  heuristic repair method

knowledge linguistic cognitive studies benecial designing ecient
practical algorithms enabling multimodal human machine communication 

acknowledgments
work supported nsf career award iis          authors would
thank anonymous reviewers valuable comments suggestions 

references
bolt  r          put there  voice gesture graphics interface  computer
graphics                 
brennan  s          processes shape conversation implications computational linguistics  proceedings   th annual meeting acl  pp     
byron  d          resolving pronominal reference abstract entities  proceedings
  th annual meeting acl  pp       
cassell  j   bickmore  t   billinghurst  m   campbell  l   chang  k   vilhjalmsson  h    
yan  h          embodiment conversational interfaces  rea  proceedings
chi    pp         
chai  j   hong  p   zhou  m     prasov  z          optimization multimodal interpretation  proceedings   nd annual meeting association computational
linguistics  acl   pp     
chai  j   prasov  z   blaim  j     jin  r          linguistic theories ecient multimodal
reference resolution  empirical study  proceedings   th international
conference intelligent user interfaces iui   pp       
chai  j   prasov  z     hong  p       a   performance evaluation error analysis
multimodal reference resolution conversational system  proceedings hltnaacl       companion volumn   pp       
chai  j  y   hong  p     zhou  m  x       b   probabilistic approach reference resolution multimodal user interfaces  proceedings  th international conference
intelligent user interfaces  iui   pp       
chen  l   harper  m     quek  f          gesture patterns speech repairs 
proceedings international conference multimodal interfaces  icmi   pp     
    
cohen  p          pragmatics referring modality communication  computational linguistics            
cohen  p   johnston  m   mcgee  d   oviatt  s   pittman  j   smith  i   chen  l     clow  j 
        quickset  multimodal interaction distributed applications  proceedings
acm multimedia  pp       
eckert  m     strube  m          dialogue acts  synchronising units anaphora resolution  journal semantics  vol         pp       
  

fichai  prasov    qu

gold  s     rangarajan  a          graduated assignment algorithm graph matching 
ieee trans  pattern analysis machine intelligence                 
gorniak  p     roy  d          grounded semantic composition visual scenes  journal
artificial intelligence research             
grice  h  p          logic conversation  cole  p     morgan  j   eds    speech acts 
pp        new york  academic press 
grosz  b  j     sidner  c          attention  intention  structure discourse 
computational linguistics                 
gundel  j  k   hedberg  n     zacharski  r          cognitive status form
referring expressions discourse  language                 
gustafson  j   bell  l   beskow  j   boye  j   carlson  r   edlund  j   granstrom  b   house 
d     wiren  m          adapt   multimodal conversational dialogue system
apartment domain  proceedings  th international conference spoken
language processing  icslp   vol     pp         
huls  c   bos  e     classen  w          automatic referent resolution deictic
anaphoric expressions  computational linguistics               
johnston  m          unication based multimodal parsing  proceedings colingacl    pp         
johnston  m     bangalore  s          finite state multimodal parsing understanding 
proceedings coling    pp         
johnston  m   cohen  p   mcgee  d   oviatt  s   pittman  j     smith  i          unicationbased multimodal integration  proceedings acl    pp         
kehler  a          cognitive status form reference multimodal human computer
interaction  proceedings aaai    pp         
koons  d  b   sparrell  c  j     thorisson  k  r          integrating simultaneous input
speech  gaze  hand gestures  maybury  m   ed    intelligent multimedia
interfaces  pp          mit press 
neal  j  g     shapiro  s  c          intelligent multimedia interface technology  sullivan 
j     tyler  s   eds    intelligent user interfaces  pp        acm  new york 
neal  j  g   thielman  c  y   dobes  z  h   m   s     shapiro  s  c          natural language
integrated deictic graphic gestures  maybury  m     wahlster  w   eds   
intelligent user interfaces  pp        ca  morgan kaufmann press 
oviatt  s   coulston  r   tomko  s   xiao  b   bunsford  r   wesson  m     carmichael  l 
        toward theory organized multimodal integration patterns humancomputer interaction  proceedings fifth international conference multimodal
interfaces  pp       
oviatt  s   deangeli  a     kuhn  k          integration synchronization input
modes multimodal human computer interaction  proceedings conference
human factors computing systems  chi    pp         
  

fiminimizing conflicts  heuristic repair method

oviatt  s  l          multimodal interfaces dynamic interactive maps  proceedings
conference human factors computing systems  chi    pp        
oviatt  s  l       a   multimodal system processing mobile environments  proceedings
thirteenth annual acm symposium user interface software technology
 uist       pp       
oviatt  s  l       b   mutual disambiguation recognition errors multimodal architecture  proceedings conference human factors computing systems 
chi    pp         
stent  a   dowding  j   gawron  j  m   bratt  e  o     moore  r          commandtalk
spoken dialog system  proceedings acl    pp         
stock  o          alfresco  enjoying combination natural language processing
hypermedia information exploration  maybury  m   ed    intelligent multimedia
interfaces  pp          mit press 
tsai  w  h     fu  k  s          error correcting isomorphism attributed relational
graphs pattern analysis  ieee trans  sys   man cyb             
wahlster  w          user discourse models multimodal communication  maybury  m     wahlster  w   eds    intelligent user interfaces  pp          acm press 
wu  l     oviatt  s          multimodal integration   statistical view  ieee transactions
multimedia                
zancanaro  m   stock  o     strapparava  c          multimodal interaction information
access  exploiting cohesion  computational intelligence                 

  


