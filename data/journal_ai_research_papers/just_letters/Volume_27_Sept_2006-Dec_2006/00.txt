journal of artificial intelligence research               

submitted        published      

a variational inference procedure allowing internal
structure for overlapping clusters and deterministic
constraints
dan geiger

dang cs technion ac il

computer science dept   technion 
haifa         israel

christopher meek

meek microsoft com

microsoft research  microsoft corporation 
redmond  wa        usa

ydo wexler

ywex cs technion ac il

computer science dept   technion 
haifa         israel

abstract
we develop a novel algorithm  called vip   for structured variational approximate
inference  this algorithm extends known algorithms to allow efficient multiple potential
updates for overlapping clusters  and overcomes the difficulties imposed by deterministic
constraints  the algorithms convergence is proven and its applicability demonstrated for
genetic linkage analysis 

   introduction
probabilistic graphical models are an elegant framework to represent joint probability distributions in a compact manner  the independence relationships between random variables
which are nodes in the graph are represented through the absence of arcs in the model 
this intuitively appealing presentation also naturally enables the design of efficient generalpurpose algorithms for computing marginal probabilities  called inference algorithms 
the general inference problem is np hard  cooper        dagum   luby         and
although there are many cases where the model is small  or  more precisely  has a small
treewidth  and exact inference algorithms are feasible  there are others in which the time
and space complexity makes the use of such algorithms infeasible  in these cases fast yet
accurate approximations are desired 
we focus on variational algorithms  a powerful tool for efficient approximate inference
that offers guarantees in the form of a lower bound on the marginal probabilities  this
family of approaches aims to minimize the kl divergence between a distribution q and the
target distribution p by finding the best distribution q from some family of distributions
for which inference is feasible  in particular  we have a joint distribution p  x  over a set of
discrete variables x and our goal is to compute the marginal probability p  y   y  where
y  x  further assume that this exact computation is not feasible  the idea is to replace
p with a distribution q which can be used to compute a lower bound for p  y   y   we
c
    
ai access foundation  all rights reserved 

figeiger  meek   wexler

let h   x   y   then  by using jensens inequality we get the following bound 
log p  y    log

x
h

q h 

p  y  h  x
p  y  h 

q h  log
  d q h     p  y   y  h  
q h 
q h 
h

where d       denotes the kl divergence between two probability distributions  the quantity d q    p   is often called the free energy where p and q are possibly un normalized
distributions  variational techniques aim to choose a distribution q such that the lower
bound is as high as possible  or equivalently  such that the kl divergence between q h 
and p  h y   y  is minimized 
variational approaches such as the mean field  generalized mean field  and structured
mean field differ only with respect to the family of approximating distributions that can
be used  with the structural mean field approach subsuming the remaining approaches as
special cases  the research of several authors guided our work  saul   jordan        
ghahramani   jordan         wiegerinck        and bishop   winn        
the contributions of this paper are threefold  first we develop an extension to the
algorithm by wiegerinck         which we call vip    that allows for a set potentials of the
approximating distribution q to be updated simultaneously even if the clusters of q overlap  algorithm vip  is n  fold faster than wiegerincks algorithm for n n grid like models
and yields two orders of magnitude improvement for large graphs such as genetic linkage
analysis model of large pedigrees  note that simultaneous updates were first presented for
phylogenic trees by jojic et al          second  we prove the convergence of vip  and of previous variational methods via a novel proof method  using properties of the kl divergence 
third  we extend vip  to allow deterministic constraints in the model and demonstrate the
applicability of this extension to genetic linkage analysis 

   background
this background section is based primarily on the paper by weigerinck         which in
turn builds on pioneering works such as the papers of saul   jordan        and ghahramani
  jordan         our review provides a new exposition of this material 
we denote distributions by p  x  and q x  and related un normalized distributions by
p  x   p  x  and q x   q x   let
x be a finite set of variables and x be an instantiation
  q
of these variables  let p  x    zp i i  di   where di is the projection of the instantiation
x to the variables in di  x and where i is a non negative function  commonly called a
potential  the constant zp normalizes the product of potentials and the subsets  di  ii  
are allowed to overlap  we often suppress the arguments of a potential and of a distribution 
using i instead of i  di   and p instead of p  x  
our goal is to find a distribution q that minimizes q
the kl divergence between q and p  
we further constrain q to be of the form q x    z q j j  cj   where zq is a normalizing
constant and where c            cj are possibly overlapping subsets of x  which we call clusters  finding an optimum q  however  can be difficult  a more modest and common goal
is devising iterative converging algorithms such that in each iteration the kl divergence
between an approximating distribution q and p decreases unless q is a stationary point 
throughout  we define q w u     w  u   for instantiations u   u for which q u      
consequently  all terms in the equality q w  u    q u q w u  are well defined even if
 

fia variational inference procedure

p
q u       moreover  this convention maintains properties such as
w  u q w u     
 
 
 
and q w  z u    q w z  u q z u     w   u z     z u       w z  u     we also note that
q x  log q x      whenever q x      and thus the kl divergence
d q    p    

x

q x  log

x

q x 
p  x 

is not finite if and only if p  x      and q x      for some instance x 
our starting point is the algorithm developed by wiegerinck         the algorithm finds
such a distribution q as follows  it iterates over the clusters cj and their instantiations cj
to update the potentials j  cj     ej  cj   via the following update equation 

j  cj    

x

x

q ck  cj   log k  ck    

 k gkj     ck  cj

x

x

q di  cj   log i  di  

   

 i fij     di  cj

where gkj and fij are two indicator functions defined via gkj     if q ck  cj     q ck   for
every instance cj of cj and   otherwise  and fij     if q di  cj     q di   for every instance
cj of cj and   otherwise  wiegerinck        proved convergence of this algorithm to a stationary point using lagrangians  throughout we call this iterative procedure  wiegerincks
algorithm 
wiegerincks algorithm relies at each step on an algorithm to compute the conditional
probabilities q ck  cj   and q di  cj   from an un normalized distribution q represented by
a set of potentials j  cj    this can be accomplished by any inference algorithm such as
bucket elimination algorithm or the sum product algorithm described by dechter       
and
q
kschischang  frey   loeliger          it is important to note that for q x    j j  cj  
the computation of these conditionals is not affected by multiplying any j by a constant
 
wiegerincks algorithm generalizes the mean field  mf  algorithm and the generalized
mean field  gmf  algorithm  xing  jordan   russell               the mean field algorithm is the special case of wiegerincks algorithm in which each cj contains a single
variable  similarly  the generalized mean field algorithm is the special case in which the cj
are disjoint subsets of variables  when cj are disjoint clusters  the formula for j in eq   
simplifies to the gmf equations as follows  first term drops out  
j  cj   

x

x

q di  cj   log i  di   

   

 i fij     di  cj

the term q di  cj   can be made more explicit when cj are disjoint clusters  bishop   winn
       in particular  the set di   cj partitions into dik    di   cj    ck q
for k              j
where k    j  note that dik   di  ck   using this notation  q di  cj     k q dki   where
q dki       whenever dik     this factorization further simplifies the formula for j as
follows 
x
x x
j  cj   
q d i        
q dji   log i  di   
   
 i fij     di 

dij

 

figeiger  meek   wexler

this simplification is achieved automatically when using bucket elimination for computing
j   the iterated sums in eq    are in fact the buckets formed by bucket elimination when
cj are disjoint 
eq    requires repeated computation of the quantities q ck  cj   and q di  cj    this repetition can be significant because there could be many indices k such that q ck  cj      q ck   
and many indices i such that q di  cj      q di    as these computations share many subcomputations it is therefore reasonable to add a data structure to facilitate a more efficient
implementation for these function calls  in particular  it is possible to save computations if
the sets c            cj form a junction tree 
a set of clusters c            cj forms a junction tree iff there exists a set of trees jt having one node  called cj   for each cluster of variables cj   and for every two nodes ci and
cj of jt  which are connected with a path in jt  and for each node ck on this path 
ci  cj  ck holds  by a set of trees we mean an undirected graph  not necessarily
connected  with no cycles  note that this definition allows a junction tree to be a disconnected graph 
when
q
q c            cj form a junction tree  q x  has the decomposable form
q x    j j  cj    e e  se    where j are marginals on the subsets cj of x  and where
e are the marginals on intersections se   ci  cj   one for each two neighboring clusters
in the junction tree  jensen       
wiegerinck        enhanced his basic algorithm so that it maintains
a consistent
junction
p
p
tree jt for the distribution q x   consistency means that cj  ck j   ck  cj k for
every two clusters  in a consistent junction tree  each potential j  cj   is proportional to
q cj    an update of a potential during the algorithm may yield an inconsistent junction
tree  however  consistency is maintained by applying distributeevidence j    jensen
      after each update of a potential  the procedure distributeevidence  j   accepts
as input a consistent junction tree and a new cluster marginal  j for cj   and updates the
potential of every neighboring cluster ck of cj via
cj  ck

 j  cj  

cj  ck

j  cj  

p
 k  ck  

 k  ck   p

   

and each neighboring cluster recursively propagates the update by applying eq    to all its
neighbors except the one from which the update came  the output of this procedure is a
consistent junction tree  having the same clusters  where  j is the  possibly un normalized 
marginal probability of q on cj   and where the conditional probability q x cj   remains
unchanged  jensen       pp      
wiegerincks enhanced algorithm  which uses a junction tree  iteratively updates the
potential of each cluster  node in the junction tree   using the potentials of other clusters
and separators  however  since the junction tree may not be consistent after the update 
the algorithm applies the procedure distributeevidence j   to the junction tree  after
each update  note that our description omits a normalization step in wiegerinck       
that is not needed for convergence 
the most time consuming computation in variational algorithms is computing conditional probabilities of the form q ck  cj   and q di  cj    we distinguish among these conditional probabilities as follows 

 

fia variational inference procedure

definition  a conditional probability q a cj   is subsumed by q if the set of target variables a is a subset of some cluster ck of q  i e    a   cj    ck   
wiegerincks enhanced algorithm has substantial computational benefits when the conditional probabilities are subsumed  in such cases the needed quantities in eq     q di  cj  
and q ck  cj    are obtained by a mere lookup in the junction tree  and only one call to
distributeevidence is made for each update 
weigerincks basic and enhanced algorithms do not assume any structure for j   namely 
the algorithms hold tables j with an explicit entry for every instantiation of cj   since
the computations q ck  cj   and q di  cj   grow exponentially in the size of di and ck   the
algorithms become infeasible for large cliques or clusters  for simplification  additional
structure to j was suggested by wiegerinck        section    of the form 

j  cj    

nj
y

jl  cjl   

   

l  

where the sets cjl   l              nj   are possibly overlapping subsets of cj   and cjl is the
projection of the instantiation cj on the variables in cjl   using such structure it is sufficient
to hold tables for the subsets cjl which are considerably smaller  note that when j has
an entry to each instantiation cj   then nj     and j  cj     j   cj     weigerinck uses this
structure for the potentials j under the following assumptions 
definition  selfq
compatibility   a distribution q with clusters cj and subsets cjl of the
 
form q x    zq j j  cj    with clusters that factor according to eq     is self compatible
if for every cj and ck the set of indices njk    l   q ck  cj     q ck  cjl    is non empty
regardless of the values of the potentials j   where cj is an arbitrary instantiation of cj
and cjl is the projection of cj on cjl  
definition  compatibility
wrt p    a distribution q with clusters cj and subsets cjl of
q
the form q x    z q j j  cj    with clusters that factor according to eq     is compatible
q
wrt a distribution p with sets di of the form p  x    z p i i  di   if for every di and cj
the set of indices mij    l   q di  cj     q di  cjl    is non empty  where cj is an arbitrary
instantiation of cj and cjl is the projection of cj on cjl  
note that self compatibility and compatibility wrt p depend on the form of q and not on
a particular realization of the potentials j  
under these assumptions weigerinck states that considerable simplifications can be deduced  and provides some examples for this statement 
we note that the algorithms of bishop   winn        and jojic et al         use a
stronger assumption that the clusters cj of the approximating distribution q are disjoint
and that q ck  cj     q ck    this assumption  which implies that q ck  cj     q ck  cjl  
and q di  cj     q di  cjl   for every index l  is relaxed by requiring each of these equalities
to hold for a single index l  but possibly for multiple indices  
 

figeiger  meek   wexler

   multiple potential update using overlapping clusters
in this section we develop a new algorithm  called vip    that uses the additional structure
of potentials offered by eq    to speed up computations  in particular  rather than updatnj
ing each potential jl separately  we offer a way to update the set of potentials  jl  l  
simultaneously  saving considerable computations  furthermore  this simultaneous update
is enhanced by using a junction tree  despite the fact that the sets  cjl   need not form a
junction tree  and only  cj   form a junction tree 
our algorithm uses the definitions of self compatibility and compatibility wrt p   defined
earlier  and the following definition of indices 
definition  let the indicator function gjk  l  equal   for a single fixed index l  njk and
  for all other indices in njk when q ck  cj      q ck    and equal   otherwise  let the
indicator function fij  l  equal   for a single fixed index l  mij and   for all other indices
in mij when q di  cj      q di    and equal   otherwise 
algorithm vip  is given in figure    its convergence is proved in section    the proof
requires q to be self compatible  compatible wrt p   and in addition  to satisfy  p  x       
 q x        note that d q    p      for distributions q which do not satisfy the last
assumption 
the main improvement of the algorithm is an efficient update of potentials  for potentials j that factorize into smaller potentials jl according to eq     algorithm vip  only
updates jl instead of updating the whole potential j   as done in weigerincks algorithms 
the update of the potentials jl as done by vip  is equivalent to updating j according to
eq     up to an irrelevant constant  but does not require to compute the update equation for
each instance of the cluster cj   the proposed change considerably speeds up the previous
algorithms 
the algorithm gets as input a target distribution p with sets di of the form p  x   
  q
i i  di   and an approximating distribution q with clusters cj which is self compatible 
zp
compatible wrt p and satisfies
the condition  p  x         q x        distribution q is
q
of the form q x    z q j j  cj   where the potential of every cluster cj factors according
qnj
jl  cjl   and the clusters form a consistent junction tree  the algorithm
to j  cj     l  
iterates over the clusters  updating the potential of every instantiation of each of the subsets
cjl according to eq     to apply the update equation  the quantities q di  cjl   are computed
via variable propagation  jensen  pp        on the junction tree  when these quantities are
subsumed  they are obtained by a mere lookup in the junction tree  then  after updating
the potentials of all subsets cjl for a cluster cj   procedure distributeevidence is applied
once to make the junction tree consistent with respect to j   since the clusters cj form a
junction tree only via their subsets cjl   eq    is replaced with eq     after convergence 
algorithm vip  outputs the approximating distribution q with its revised potentials 
example   the target distribution p is an n n grid of pairwise potentials  see figure  a 
and the approximating family is defined by a single row and the set of columns in the grid 
each augmented with edges to the middle vertex  see figure  b  where c  is a row of the
grid and ci  i              n      are the columns  using the notation xi j to denote the
vertex at row i and column j in the grid  cluster c  is associated with n    subsets
 

fia variational inference procedure

algorithm vip   q p 
q
q
input  two probability distributions p  x    z p i i  di   and q x    z q j j  cj   where
qnj
the initial potentials j  cj     l  
jl  cjl   form a consistent junction tree  and where q is
self compatible  compatible wrt p   and satisfies  p  x         q x       
output 
a revised set of potentials jl  cj   defining a probability distribution q via q x  
q

 c
j l jl jl   such that q is a stationary point of d q    p   
iterate over all clusters cj until convergence
step   
for l              nj  
for every instantiation cjl of cjl apply the following update equation 
jl  cjl    

x

x

x

q ck  cjl   log k  ck    

 k gjk  l     ck  cjl

x

q di  cjl   log i  di      

 i fij  l     di  cjl

jl  cjl    ejl  cjl  
note  q di  cjl   is computed via variable propagation  jensen  pp        on the junction
tree jt  however  when these quantities are subsumed  they are obtained by a mere lookup
in jt 
step    make jt consistent with respect to j  

distributeevidence jt  j  

distributeevidence jt   j  
input  a junction tree jt with nodes ck and potentials k  ck    
node cj with a revised potential  j  
output  a consistent junction tree 

qnk

l   kl  ckl   

a starting

initialization source j      updated  j 
while  updated    
  first element in updated  updated updated   
for all neighboring nodes ck of c in jt such that k    source  
p
qn  
c
 c
l   l  cl  
 km  ckm    km  ckm   p  k qn
c  ck
l   l  cl  
for a single subset m of ck for which  c  ck    ckm
source k   
updated updated k 
figure    algorithm vip 
 

   

figeiger  meek   wexler

 a 

 b 

 c 

figure     a  grid like p distribution  b     c  approximating distributions q 
c l    x  l   x  l      each column cluster cj is associated with  n     subsets cjl from
which cjl    xl j   xl   j   for n   subsets  l                  cjl    x  j   x  j   for l   n   and
cjl    xln    j   x  j   for each of the additional n   subsets  l         
this choice induces a self compatible approximating distribution q  every column cluster
cj is independent of another cluster given a subset that contains x  j  such as cj     in
addition  the row cluster c  is independent of every column cluster cj given c j   the
induced distribution is also compatible wrt p   for each vertical edge dv    xi j   xi   j  
of p   distribution q satisfies q dv  ck     q dv  ck    for a column cluster ck such that
k    j  and q dv  c      q dv  c j    in addition  for each horizontal edge dh    xi j   xi j    
in p   distribution q satisfies q dh  c      q dh  c j    and q dh  ck     q dh  ck    for k   
j  j      finally  for the edge dh and k   j  j      the approximating distribution satisfies
q dh  ck     q dh  ckl   where ckl    xi k   x  k    due to the additional n    edges added
to each column cluster 
like wiegerincks enhanced algorithm  algorithm vip  has substantial computational
benefits when the conditional probabilities q di  cjl   are subsumed  in such cases the needed
quantities  q di  cjl   and q ck  cjl    are obtained by a mere lookup in the junction tree in
step   of the algorithm  and only one call to distributeevidence is made in step   
as demonstrated in the next paragraph  the computational efficiency of vip  is achieved
even if the quantities q di  cjl   are not subsumed but only factor to subsumed probabilities 
disjoint clusters is one such special case  in which the quantities q di  cjl   can factor into
subsumed probabilities q dki  cjl    where dik   di  ck   which are obtainable by lookup in
a junction tree 
consider example   to compare the computational cost of vip  versus wiegerincks
basic and enhanced algorithms  assume wiegerincks basic algorithm  eq      uses the
distribution q given in figure  c  with    clusters cj  and    sets di   therefore  when a
junction tree is not used                     conditionals are computed for each cluster cj 
 edge  not on the boundary of the grid     for each of the four possible values for the edge
cluster cj    clearly  if additional clusters are introduced  as shown for example by figure  b 
then the computational cost grows  by using a junction tree  as done by wiegerincks enhanced algorithm  the subsumed conditional probabilities  which are computed separately
by wiegerincks basic algorithm  are computed with a single call to distributeevidence 
these computation covers all subsets in figure  c  the only conditionals that are not sub 

fia variational inference procedure

 a 

 b 

 c 

figure    the target distribution p is a grid of pairwise potentials as in  a   two different
partitions of the grid into clusters are shown in figures  b  and  c   both contain
the same subsets 

sumed are q di  cj   of horizontal edges di that are not contained in a single cluster  namely 
edges in  a but not in  c  these factor to two subsumed probabilities  one computed by the
single call described earlier and the other requires a second call to distributeevidence 
for example  let di    x    x    be a horizontal edge in p which does not overlap with cj   
then q x    x   c j     q x   c j   x   q x   c j    the two conditionals are subsumed  but a second
call to distributeevidence is needed to obtain q x   c j   x     this yields    calls to distributeevidence  however  in example    one call to distributeevidence is sufficient
to compute the conditionals for two adjacent horizontal edges  yielding the need only for
   calls  therefore  since there are            calls to distributeevidence  and since
the cost of the junction tree algorithm is typically twice the cost of computing conditional
probabilities without using a junction tree  this yields a   fold speedup for wiegerincks
enhanced algorithm versus wiegerincks basic algorithm  for edges on a boundary  the
speedup factor is less than    as the size of the grid grows  a smaller fraction of the edges
are on the boundary  and  thus  the speedup approaches a   fold speedup 
a significant speedup is obtained by using algorithm vip  with clusters cj and subsets
as described in figure  b  note that the additional subsets are needed to meet the compatibility assumption of vip    algorithm vip  makes one call to distributeevidence
per cluster cj for each non subsumed conditional  rather than for every edge cluster cj   
since vip  uses n     clusters cj   the speedup when compared to wiegerincks enhanced
algorithm approaches n as the the n  n grid grows  this o n   speedup is confirmed in
the experiments section  figure    
another potential benefit of vip  is the possibility of alternating between different
choices of clusters which contain identical subsets cjl   a simple example is the grid in
figure  a  where two such choices are illustrated in figures  b and  c  the two sets of clusters update of the potentials j differently and therefore can yield better approximations as
the distance d q    p   is reduced with every alternation  in general  we can iterate through
a set of choices for clusters and execute vip  for one choice using as initial potentials the
potentials jl found for an earlier choice of clusters  the practical benefit of this option of
added flexibility remains to be tested in an application 
 

figeiger  meek   wexler

   proof of convergence
we develop several lemmas that culminate with a proof of convergence of algorithm vip   
lemma   states that for two un normalized probability distributions p  x  and q x  the
kl divergence is minimized when q x  is proportional to p  x   lemma   rewrites the
kl divergence d q    p   in terms of the potentials p
of q and p using the quantity j  cj  
which  according to lemma    differs from j  cj     l jl  cjl   only by a constant  finally 
theorem   asserts that the kl divergence between q and p decreases with each iteration
of algorithm vip  unless q is a stationary point  the proof exploits the new form of
d q    p   provided by lemma    and replaces the term j  cj   with the terms jl  cjl   used
in the update equation of vip    a final observation  which uses lemma    closes the proof
showing that when the potentials are updated as in algorithm vip    the kl divergence is
minimized wrt j  
the first lemma provides a variant of a well known property of kl  recall that for
every two probability distributions q x  and p  x   the kl divergence d q x     p  x     
and equality holds if and only if q x    p  x   cover   thomas       theorem         a
similar result holds also for un normalized probability distributions 
lemma   let q x  and p  x  be non negative functions such that
let
q x   
d q x     p  x  
p min
 q 

x

p

x p  x 

  zp      and

q x  zq  

where zq is a positive constant  then q x   

zq
zp p  x  

proof  we observe that
p  x 
d q x     p  x     zq  d  q x 
zq    zp     zq log

zq
zp

which implies  using the cited result about normalized distributions  that the minimum is
p  x 
obtained when q x 
zq   zp   yielding the desired claim  
the next lemma rewrites the kl divergence so that an optimizing update equation for
cluster cj becomes readily available 
lemma   let p  x   
tions  then 

 
zp

q

i i  di  

d q    p    

x
cj

and q x   

q cj   log

 
zq

q

j

j  cj   be two probability distribu 

j  cj  
  log zp    log zq  
j  cj  

   

where j  cj     ej  cj     and where
j  cj     

x x

q ck  cj   log k  ck    

x x
i

k ck  cj

  

di  cj

q di  cj   log i  di  

   

fia variational inference procedure

proof  recall that
d q    p    

x

q x  log

x

q x 
    h q    eq  log p  x   
p  x 

    

where h q  denotes the entropy of q x  and eq denotes expectation with respect to q 
the entropy term can be written as
x x
h q    
q cj  q x cj    log q cj     log q x cj   
cj x cj

 

p

cj

q cj   log q cj   

p

cj

q cj  

p

x cj

q x cj   log q x cj   

this is a variation of a well known form of h q  which is derived by splitting
summation
p
over x into summation over cj and x   cj   and using the fact that q cj   x cj q x cj    
q cj   which holds for every distribution  to split the sum over x   cj for q cj       we use
  q
x
k k  ck  
zq
 
log k  ck    log q cj    log zq  
log q x cj     log
q cj  
k

thus 
x

q x cj   log q x cj    

x cj

p p

p
q ck  cj  q x ck   cj   log k  ck    x cj q x cj    log q cj     log zq   
p
and by using q ck   cj   x  ck cj   q x ck   cj     q ck   cj   this term is further rewritten as
x
h q    
q cj   log q cj  
k

x cj

cj



p

cj q cj   

hp

k  j

p

ck  cj q ck  cj   log k  ck     log

j  cj  
q cj  

i

  log zq  

note that when q cj       the bracketed term is multiplied by zero  and due to the equality
  log        the product is also zero 

the second term of eq     is similarly written as
xx
x
eq  log p  x    
q cj  
q x cj   log i  di    log zp  
i

 

x

q cj  

cj

x x
i

cj

    

x cj

q di  cj   log i  di    log zp  

di  cj

hence eq     is rewritten as
x
d q    p    
q cj   log q cj  
cj




x
cj

q cj   


x x

q ck  cj   log k  ck    

x x
i

k ck  cj

  

di  cj

q di  cj   log i  di  

figeiger  meek   wexler



x
cj

q cj   log

q cj  
  log zp    log zq  
j  cj  

denoting the bracketed term by j  cj    and letting j  cj     ej  cj     we get
d q    p    

x
cj

q cj   log

j  cj  
  log zp    log zq   
j  cj  



p
the next lemma shows that j  cj    defined in eq     and j  cj     l jl  cjl    used to
update potentials of q in vip    differ only by an additive constant which does not depend
on cj   as argued in theorem    the fact that this difference is a constant enables vip  to
use the latter form  which is a more efficient representation 
q
q
q
lemma   let p  x    z p i i  di   and q x    z q j j  cj   where j  cj     l jl  cjl   
be two probability distributions such that q is self compatible and compatible wrt p   let
x
x
x
x
jl  cjl     
q ck  cjl   log k  ck    
q di  cjl   log i  di       
 k gjk  l     ck  cjl

 i fij  l     di  cjl

then  the difference between j  cj   defined by eq    and j  cj    
that does not depend on cj  

p

l

jl  cjl   is a constant

p
proof  we first argue that each term of the form ck  cj q ck  cj   log k  ck   and each term
p
of the form di  cj q di  cj   log i  di   in eq    that depends on cj appears exactly once for
a single subset cjl in eq      we then argue that every term in eq     appears once in
eq    
since q is self compatible  it follows that for every cluster ck that depends on cj the
function gkj  l  equalspone for a single subset cjl   namely q ck  cj     q ck  cjl    in which
case the expression
ck  cj q ck  cjl   log k  ck   appears in eq      similarly  since q is
compatible wrt p it follows that for every set di that depends on cj the function fij  l 
equals
one for a single subset cjl   namely q di  cj     q di  cjl    in which case the expression
p
di  cj q di  cjl   log i  di   appears in the second term of eq     
it remains to show that every term in eq     appears once in eq     since q is selfcompatible  it is implied that ck  cj  cjl and thus summing over ck   cj is equivalent
to summing over ck   cjl   therefore  for every k such that gjk  l       the first term of
eq     appears once in eq     similarly  since q is compatible wrt p   it is implied that
di  cj  cjl and thus summing over di   cj is equivalent to summing over di   cjl and
therefore for every i such that fij  l      the second term of eq     appears once in eq    


theorem    convergence of vip    let the initial approximating distribution q be selfcompatible and compatible wrt a given distribution p   and assume that  p  x       
 q x        then  the revised distribution q retains these properties  and in each iteration
of algorithm vip  the kl divergence between q and p decreases unless q is a stationary
point 
  

fia variational inference procedure

q
proof  let q x    z q jl jl  cjl   where jl  cjl     ejl  cjl     we need to show that
 
 
at the start
q of  each iteration of vip the function q defined by the revised potentials
 
j  cj     l jl  cjl   is a probability distribution with the listed properties and that it is
closer to p in kl divergence than q at the start of the previous iteration 
first  we show that q  maintains the properties listed in the theorem throughout the
updates done in vip    the properties of self compatibility and compatibility wrt p are
derived from the form of q and thus are not affected by the updates done in vip    for
the property
 p  x         q x        consider an instance x for which p  x       since
  q
p  x    zp i i  di   there exists a potential i of p for which i  di        where di is the
q
projection of x on the set di   since q x      and q x    z q jl jl  cjl   there exists a
subset cjl for which q cjl        where cjl is the projection of x on cjl   algorithm vip 
 
by convention 
updates jl  cjl   to  because log i  di      and q di  cjl      di  c
jl  
 
yielding q  x       as claimed 
now  we show that no additional zeroes are introduced into q whenever  p  x       
 q x        hence  the normalizing constant zq     and therefore the revised q  is a
probability distribution  for instances cjl for which q cjl       the terms q ck  cjl   log  ck  
and q di  cjl   log  di   are finite as long as  p  x         q x        this implies jl  cjl  
is updated to a positive value and thus  no additional zeroes are introduced into q 
using the given form of q  we have


  x y
q cj    
k  ck   j  cj   
    
zq
x cj k  j

we denote the bracketed coefficient of j  cj   by bj  cj   and note that it is constant in the
sense that it does not depend on the quantity j being optimized 
we now use eq     to rewrite the kl divergence as justified by eq    in lemma   


j  cj  bj  cj   
  x
d q    p    
j  cj  bj  cj   log
  log zp    log zq   
    
zq
j  cj  bj  cj  
cj

due to lemma    the distance d q    p
j  cj  
p  only changes by a constant when replacing

 c
 
 
j
j
with j  cj     e
  where j  cj     l jl  cjl   as computed via eq    of vip   note that
j  cj   does not depend on  cj   and is a function of q x  only through the conditional
distribution of x   cj given cj  via q ck  cj     hence  lemma   states that the minimum
of d q    p   wrt j is achieved when j  cj   is proportional to j  cj    as the potential j
is only held implicitly through the partial potentials jl   step   of vip  updates j  cj   via
eq    to be proportional to j  cj   by setting each potential jl  cjl   to be proportional to
jl  cjl    the proportionality constant does not matter because if j is multiplied by   and
the arbitrary constraining constant zq is also multiplied by   these influences cancel in
eq      for simplicity  the algorithm uses      and therefore j  cj    ej  cj     algorithm
vip  implicitly computes j  cj   according to this formula and hence decreases d q    p   at
each iteration by improving j  cj   while holding all other cluster potentials fixed  since
the kl divergence is lower bounded by zero  vip  converges  

  

figeiger  meek   wexler

the properties of q required by theorem   of self compatibility and compatibility wrt
p are derived from the form of q and are satisfied by setting the clusters cj appropriately 
in addition  the condition  p  x         q x       is trivially satisfied for strictly positive
distributions p  
note that the difference between j  cj   defined by eq    and j  cj   defined by eq    is
a constant that does not depend on cj   consequently  our convergence proof also applies to
wiegerincks algorithm  because this algorithm is a special case of vip  where every cluster
cj has a single subset cj    cj  

   handling deterministic potentials
when the distribution p is not strictly positive the property  p  x         q x      
must hold for the convergence proof of vip  to apply  in this section we provide a sufficient
condition for q to retain this property 
definition  an instantiation w   w is feasible  wrt to a distribution p   if p  w   w      
otherwise  the instantiation is infeasible 
q
definition  a constraining set wrt a distribution p  x    z p i i  di   with sets di is a
minimal set of variables   di which has an infeasible instantiation  
q
definition  a distribution q x    z q j j  cj   with clusters cj is containable wrt a
q
distribution p  x    z p i i  di    if for every constraining set  of p there exists at least
one cluster cj such that   cj  
q
q
theorem   let p  x    z p i i  di   and q x    z q j j  cj   be two distributions where
q
j  cj     l jl  cjl   and where q is containable and compatible wrt p and strictly positive  then  after vip  iterates once over all clusters cj   the revised distribution q satisfies
 p  x         q x       
proof  from the definition of a constraining set  for every infeasible instantiation x  there
exists an infeasible instantiation  of a constraining set  such that  is a projection of x
on   we show that vip  updates q x      for such instantiations  since q is containable
wrt p there exists a cluster cj which contains   furthermore  since   di where di is
a set of p and since q is compatible wrt p   there exists a subset cjl that contains   for
every instantiation cjl which is a projection of  on cjl the expression jl  cjl   is updated
to  according q
to eq    of vip    this is true because q di  cjl       and log  di      
 
since q x    zq j l jl  cjl   this update implies q x      
whenever the first two compatibility conditions of theorem   hold  it follows that vip 
converges for containable distributions  note that since every iteration of vip  decreases the
kl divergence  following iterations can not change q to be greater than zero for instantiation
which are infeasible wrt p   as this leads to an infinite distance  however  containability
implies a stronger property stated in the next theorem 

  

fia variational inference procedure

q
q
theorem   let p  x    z p i i  di   and q x    z q j j  cj   be two distributions where
q
j  cj     l jl  cjl   and where q is containable wrt p and  p  x         q x        then 
after vip  iterates once over all clusters cj   the revised distribution q satisfies  q x       
 p  x       
proof  consider an instantiation x for which p  x 
     we show that eq    of vip  upq
dates q x  to a positive value  since q x    z q j l jl  cjl    it is sufficient to show that
the revised potential jl  cjl   is positive for each subset cjl and an instance cjl which is
the projection of x on the cjl   for such instances cjl the value jl  cjl   is set by eq    to
a finite value since i  di       for every instance di which is a projection of x on a set di  
and k  ck       implies q ck  cjl        therefore  jl  cjl     ejl  cjl       and q x      
the consequence of theorem   is that q x      iff p  x       conditions weaker than
containability may be sufficient to ensure the requirement needed for convergence  however 
containability is easily satisfiable in applications of variational techniques as explicated in
the next section 

   genetic linkage analysis via variational algorithms
genetic linkage analysis takes as input a family pedigree in which some individuals are
affected with a genetic disease  affection status of members of the pedigree  marker readings
across the genome  and mode of inheritance  the output is the likelihood of data as a function of the location of a disease gene and the given pedigree  locations yielding maximum
or close to maximum likelihood are singled out as suspect regions for further scrutiny  the
exact computation of this likelihood is often too complex and approximations are needed 
algorithm vip  has been developed to facilitate such likelihood computations  in particular  vip  allows there to be overlapping clusters which minimizes the loss of valuable
information and  more importantly  can handle the deterministic constraints that are common in these models  in this section  we describe the standard probabilistic model for
genetic linkage  several approximate distributions that we use when applying vip  to the
genetic linkage model  and demonstrate vip  on a real world data set of a large pedigree
with     individuals 
the standard probabilistic model for genetic linkage is based on a pedigree which contains several variables for each person at each location and conditional probability tables
for each variable xm given a set of variables called parents of xm and denoted by  xm   
the distribution p  x  that represents the joint distribution of the variables in the pedigree
is written using multiple indices  one set of indices for persons  i   one for loci  j   and
another for the type of variable  t  as follows 
p  x   

yy
j

i t
p  xi t
j   xj     

y

i t ps ms pg mg f  

  yy
zp
j

y

i t ps ms pg mg f  

  

i t
i t
i t
j  xj   xj   

    

figeiger  meek   wexler

where the five possible types of variables are  paternal selector  ps   maternal selector  ms  
paternal genotype  pg   maternal genotype  mg  and phenotype  f   thus  the set dji t
equals  xji t    xji t    
we denote the variables of the different types  ps  ms  pg  mg and f  of individual i at
i m
locus j by sji p   sji m   gi p
and fji respectively  in this notation the possible potentials
j   gj
a p
a m
i p
i m
b p
b m
i m
i p
i p
i m
i m
of p are  gi p
j   gj   gj   sj     gj   gj   gj   sj     sj   sj      sj   sj    and
i m
 fji   gi p
j   gj   where a and b are is father and mother in the pedigree  respectively  some
i p
a p
a m
i ms
i m
exemplifying sets are dji pg    gi p
   sji m   sj 
   and dji f  
j   sj   gj   gj    dj
i m
 fji   gi p
j   gj    where a is the father of individual i in the pedigree  we note that the first
two types of potentials and possibly the last one are deterministic potentials which equal
zero for some instantiations 
a directed
q acyclic graph along with a probability distribution r that factors according
to r z    i r zi   zi    is called a bayesian network  a bayesian network defined by
eq      that describes parents offspring interaction in a simple genetic analysis problem
with two siblings and their parents across   loci  is given in figure    the dashed boxes
contain all variables that describe the variables in a single location  in this example we
assume that each phenotype variable depends on the genotype at a single locus  this is
reflected by the fact that only edges from a single locus point into each phenotype variable 
the full semantics of all variables and more details regarding the conditional probability
tables can be found in the paper by fishelson   geiger         these details are not needed
here 
we use several choices to cluster the bayesian network for p  x  such that q is selfcompatible and compatible wrt p   in addition  since some potentials in p are constrained
 e g  i pg
j    we choose clusters such that q is containable wrt p   according to theorem  
this choice ensures that q satisfies all conditions necessary for convergence of vip    and in
particular  p  x         q x       
consider a partition of the network into slots  each containing a set of consecutive loci 
in the most simple case every slot is a single locus and each of the subsets cji contains
variables related to one individual i and the genotypes of his parents in that slot  we set
s
 i 
cji    gj   sji   and cj   i  cji   where  i  denotes the union of i and his parents 
an illustration of such a setting in a pedigree of two siblings and their parents over three
loci is given in figure    in this setting  self compatibility is trivially satisfied because the
clusters cj of q are disjoint  and q is containable wrt p since only sets dji ps and dji ms   the
potentials of which are not constrained  span across more than a single locus  it remains to
show that compatibility of q wrt p is satisfied  for sets dji t contained in a single subset

cji this is trivial as q dji t  cj     q dji t  cji        otherwise  t equals ps or ms and without
i p
i p
i p
i p
loss of generality  q sj 
  sji p  cj     q sj 
 cj     q sj 
 cji     q sj 
  sji p  cji   
in a more complex setup  which is similar to example    we add a cluster cj   which
cuts across the loci for selector variables of an individual r  as shown in figure    the
s
 i 
subset cji are set to cji    gjs   sji   sjr   and the clusters are cj   i  cji    for j           j 
r
in addition  we set cj     l  cj   l   and the subsets cj   l    sl l  
   for a single
chosen individual r  we verify that q still satisfies the conditions of theorem    selfcompatibility is maintained since q cj  cj       q cj  cj   j    q cj    cj     q cj    cjr   

  

fia variational inference procedure

figure    a bayesian network representation of a pedigree of two siblings and their parents
in a   loci model  the circles  squares and diamond shapes represent genotype 
phenotype and selector variables respectively 

and q ck  cj     q ck  cjr   for every two clusters cj   ck such that j  k  j  sets dji t
such that t    ms  ps are contained in cluster cj and thus maintain independence given a
subset  for t   ms  ps the sets dji t that connect two adjacent loci are independent of cj  
given cj   j   and are independent of other clusters cj given the subset cji   maintaining
compatibility of q wrt p   finally  q is containable wrt p since all clusters from the previous
option remain 
immediate extensions of the above clustering schemes allow every slot to contain several
consecutive loci and a set of possibly more than one individual r to cut across the loci  to
maintain the compatibility of q wrt p in the latter extension  the subsets cjr are set to
 r 
cjr    gj   sjr    where  r  denotes the union of individuals in r and their parents 
we now describe the experiments performed using a large pedigree with     individuals
spanning across    locations  which was studied by narkis et al         to locate an area
that contains a gene that causes a fatal neurological disorder  lccs type     first  the
proximity of the disease gene to each of the markers was tested through two point analysis
  a model selection method in which only two loci are considered simultaneously  with one
of them being the disease locus  in this method  loci which yield likelihood maxima suggest
probable locations of the disease locus  two point analysis of the abovementioned pedigree
took several days using the exact inference software superlink v    designed for genetic
linkage analysis 
  

figeiger  meek   wexler

figure    a schematic division of a pedigree into clusters  where each locus is a cluster 
in cluster c  the variables of every individual are in a separate ellipse and the
number of that individual is written  in the other two clusters the marked areas
are c   and c    

the log likelihood probabilities obtained by vip  using the abovementioned extended
clustering scheme with   clusters across all loci and with no cluster cutting across the
loci  are shown in figure    the figure shows clearly that the exact and approximate loglikelihood curves have a similar shape and almost identical extremum points  but have a
major difference in absolute value 
next  we tested vip  on three point analysis problems on the same pedigree  where
two markers are considered simultaneously along with one disease locus  we note that
exact inference for this task on the specified pedigree is hard on a single pc  taking several
weeks  since the exact location of the disease gene is known with high probability  we
wished to test whether or not the lower bounds found by vip  indicate this location  we
considered two nearby markers  number   and    and seven models which differ by the
location of the speculated disease gene  in the first two  the disease locus was positioned
left to marker   at distances      and      centi morgan  cm   and in the remaining five it
was positioned to the right of marker   at distances      to      cm with      cm difference
between locations  the location of the disease gene is     cm to the right of marker    the
algorithm was run three times on each model with random initial potentials  taking into
account only the maximum value obtained  the results of this test are plotted in figure  
versus the approximation found by the sampling software simwalk  introduced by sobel 
papp   lange        which is designed for approximate pedigree analysis  as shown  the
probabilities found by vip  are higher as we approach the location of the disease gene  the
same in not true for the probabilities found by simwalk   however  we note that vip  is
  

fia variational inference procedure

ln likelihood

figure    a pedigree partitioned into clusters  where each locus is a cluster and an additional cluster c    in the striped area  contains the variables of one of the individuals 

 
   
   
   
   
    
    
    
    
    
    
                                                     

exact

locus

vip      clusters across all loci
vip    disjoint clusters

figure    approximations to the log likelihood of two point analysis using vip   

much slower on this problem than simwalk   taking several hours for each run  in addition 
  

figeiger  meek   wexler

we note that the ln likelihood probabilities in figures   a  and  b  are drawn on different
scales due to the markedly different output of the two methods 

    

   
   

    

ln likelihood

ln likelihood

    

    
    
    
    

   
   
   
   

     

     

    

    

    

    

    

     

location  relative to marker   

     

    

    

    

    

    

location  relative to marker   

 a  using vip 

 b  using simwalk 

figure    approximations to the log likelihood of three point analysis 
we compared the convergence times of vip  and wiegerincks algorithm on various size
problems of genetic linkage analysis  the original network on which we performed the test
includes     variables and represents a pedigree with    individuals over four loci  to create
various sized problems  subsets of the original pedigree with increasing number of individuals
were considered  in addition  for a fair comparison  the clusters of wiegerincks algorithm
were chosen to be a subset of the subsets used by vip    since the number of iterations until
convergence did not vary significantly between the two algorithms  we report the ratio of
iteration times which also tests the theoretical speedup predicted in section   of vip  over
wiegerincks algorithm  figure   illustrates the ratio of time for an update iteration of the
two algorithms  where it is evident that the ratio increases linearly with the problem size 
the ratios indicated are averaged over   runs each with    iterations for every problem size 
finally we examine the convergence of vip  in figure    using six representatives of
the original    two point analysis runs described earlier  each on a different network  the
algorithm is halted when the change in the lower bound is smaller than     for more than
  iterations  although not all runs converge at the same rate  it seems that they obey a
certain pattern of convergence where the first few iterations show significant improvements
in the lower bound  followed by slow convergence to a local maximum  and then another
moderate improvement to a better maximum point 

   discussion
in this paper we present an efficient algorithm called vip  for structured variational approximate inference  this algorithm  which extends known algorithms  can handle overlapping
clusters and overcome the difficulties imposed by deterministic constraints  we show that
for n  n grid like models  algorithm vip  is n fold faster than wiegerincks algorithm 
  

fia variational inference procedure

  
  

ratio of iteration times

  
  
  
  
 
 
 
 
 
  

  

  

  

  

  

  

  

  

  

number of individuals

figure    speedup of vip  over wiegerincks algorithm 

   
   

ln likelihood

    
    
    
    
    
    
    
 

 

 

 

 

  

  

  

  

  

  

  

iteration

figure     convergence of vip  for   runs of two point analysis 
when a junction tree is used  in addition  we prove the convergence of vip  and of previous
variational methods via a novel proof method  using properties of the kl divergence 
finally  algorithm vip  is tested on bayesian networks that model genetic linkage analysis problems  these graphs resemble grid like models and are notoriously difficult to
approximate due to the numerous deterministic constraints  the results show a linear
improvement in speed of vip  versus wiegerincks algorithm  and that the approximation
  

figeiger  meek   wexler

follows the shape of the real likelihood probabilities  nevertheless  figure   shows that variational methods such as wiegerincks algorithm or vip  are still not appropriate to produce
accurate approximation of the likelihood for genetic linkage analysis 

acknowledgments
this paper is an extension of a paper that originally appeared at the   th workshop on
artificial intelligence and statistics  geiger   meek        we thank d  heckerman  n 
jojic and v  jojic for helpful discussions  we also thank the two anonymous reviewers
for correcting several errors that appeared in the early version as well as improving the
presentation  part of the work was done while the first author was a visitor at microsoft
research  this work is supported by the israeli science foundation and the israeli science
ministry 

references
bishop  c    winn  j          structured variational distributions in vibes  in artificial
intelligence and statistics  society for artificial intelligence and statistics 
cooper  g          probabilistic inference using belief networks is np hard  artificial
intelligence             
cover  t  m    thomas  j  a          elements of information theory  wiley 
dagum  p    luby  m          approximating probabilistic inference in bayesian belief
networks is np hard  artificial intelligence                 
dechter  r          bucket elimination  a unifying framework for reasoning  artificial
intelligence                  
fishelson  m    geiger  d          exact genetic linkage computations for general pedigrees 
bioinformatics      s   s    
geiger  d    meek  c          structured variational inference procedures and their realizations  in proceedings of tenth international workshop on artificial intelligence
and statistics  the barbados  the society for artificial intelligence and statistics 
ghahramani  z    jordan  m  i          factorial hidden markov models  machine learning             
jensen  f  v          an introduction to bayesian networks  springer 
jojic  v   jojic  n   meek  c   geiger  d   siepel  a   haussler  d     heckerman  d 
        efficient approximations for learning phylogenetic hmm models from data 
bioinformatics             
kschischang  f  r   frey  b  j     loeliger  h  a          factor graphs and the sum product
algorithm  ieee transactions on information theory                 
  

fia variational inference procedure

narkis  g   landau  d   manor  e   elbedour  k   tzemach  a   fishelson  m   geiger  d  
ofir  r   carmi  r     birk  o          homozygosity mapping of lethal congenital
contractural syndrome type    lccs   to a   cm interval on chromosome   q   
american journal of medical genetics                  
saul  l    jordan  m  i          exploiting tractable substructures in intractable networks 
in advances in neural information processing systems  nips   mit press 
sobel  e   papp  j     lange  k          detection and integration of genotyping errors in
statistical genetics  american journal of human genetics             
wiegerinck  w          variational approximations between mean field theory and the junction tree algorithm  in uncertainty in artificial intelligence   pp           morgan
kaufmann 
xing  e  p   jordan  m  i     russell  s          a generalized mean field algorithm for
variational inference in exponential families  in uncertainty in artificial intelligence 
 pp           morgan kaufmann 
xing  e  p   jordan  m  i     russell  s          graph partition strategies for generalized
mean field inference  in uncertainty in artificial intelligence   pp             morgan
kaufmann 

  

fi