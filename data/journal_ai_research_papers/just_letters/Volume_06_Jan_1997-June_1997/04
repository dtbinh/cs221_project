journal artificial intelligence research                 

submitted       published     

query dags  practical paradigm implementing
belief network inference
adnan darwiche

darwiche aub edu lb

department mathematics
american university beirut
po box           beirut  lebanon

gregory provan

provan risc rockwell com

rockwell science center
     camino dos rios
thousand oaks  ca      

abstract

describe new paradigm implementing inference belief networks  consists two steps      compiling belief network arithmetic expression called
query dag  q dag       answering queries using simple evaluation algorithm 
node q dag represents numeric operation  number  symbol evidence  leaf node q dag represents answer network query  is 
probability event interest  appears q dags generated using standard algorithms exact inference belief networks   show
generated using clustering conditioning algorithms  time space
complexity q dag generation algorithm worse time complexity
inference algorithm based  complexity q dag evaluation algorithm
linear size q dag  inference amounts standard evaluation
arithmetic expression represents  intended value q dags reducing
software hardware resources required utilize belief networks on line  real world
applications  proposed framework facilitates development on line inference
different software hardware platforms due simplicity q dag evaluation
algorithm  interestingly enough  q dags found serve purposes  simple techniques reducing q dags tend subsume relatively complex optimization techniques
belief network inference  network pruning computation caching 

   introduction
consider designing car self diagnostic system alert driver range
problems  figure   shows simplistic belief network could provide ranked set
diagnoses car troubleshooting  given input sensors hooked battery 
alternator  fuel tank oil system 
standard approach building diagnostic system put belief network 
along inference code  onto car s computer  see figure    encountered
number diculties using approach embody belief network technology industrial applications  first  asked provide technology multiple platforms 
applications  technology implemented ada pass certain certification procedures  others  implemented domain specific hardware
supports primitive programming languages  second  memory limited keep

c      ai access foundation morgan kaufmann publishers  rights reserved 

fidarwiche   provan

fuel sensor
fuel
battery

oil pressure
battery sensor

fault

oil pressure
sensor
alternator
alternator
sensor

figure    simple belief network car diagnosis 
cost unit certain threshold maintain product profitability  dilemma
following  belief network algorithms trivial implement  especially optimization crucial  porting algorithms multiple platforms languages would
prohibitively expensive  time consuming demanding qualified manpower 
overcome diculties  devised exible approach implementing
belief network systems  based following observation  almost work
performed standard algorithms belief networks independent specific evidence
gathered variables  example  run algorithm battery sensor set
low run later variable set dead  find almost algorithmic
difference two runs  is  algorithm branch differently
key decisions makes  difference two runs specific
arguments invoked numeric operations  therefore  one apply standard inference
algorithm network evidence parameter instead specific value 
result returned algorithm arithmetic expression parameters
depend specific evidence  parameterized expression call query
dag  example shown figure    
approach proposing consists two steps  first  given belief network  set
variables evidence may collected  evidence variables   set variables need compute probability distributions  query variables   q dag
compiled off line  shown figure    compilation typically done sophisticated software hardware platform  using traditional belief network inference algorithm
conjunction q dag compilation method  part process far away
costly computationally  second  on line system composed generated
q dag evaluator specific given platform used evaluate q dag  given
evidence  parameterized arithmetic expression evaluated straightforward manner
using simple arithmetic operations rather complicated belief network inference 
   sharing subexpressions makes directed acyclic graph instead tree 

   

fia practical paradigm implementing belief network inference

traditional approach

compiled approach

fault
variables
causal
network


n
l

n
e

sensor
values

causal network
inference
software

sensor
variables

q dag
compiler

query
dag

q dag
evaluator


f
f
l

n
e

 
n
l

n
e

fault
probabilities

figure    figure compares traditional approach exact belief network inference
 shown left  new compiled approach  shown right 
context diagnostic reasoning  traditional approach  belief network
sensor values used on line compute probability distributions
fault variables  compiled approach  belief network  fault variables
sensor variables compiled off line produce q dag  evaluated
on line using sensor values compute required distributions 
computational work needed perform on line evaluation straightforward
lends easy implementations different software hardware platforms 
approach shares commonality methods symbolically manipulate probability expressions  spi  li   d ambrosio        shachter  d ambrosio   
del favero         differs spi objective manipulations and  hence 
results obtained  spi explicates notion arithmetic expression state
belief network inference viewed expression factoring operation  allows
results optimization theory utilized belief network inference 
hand  define arithmetic expression explicate formalize boundaries
on line off line inference  goal identifying minimal piece software
required on line  results therefore oriented towards purpose include 
 a  formal definition q dag evaluator   b  method generating q dags
using standard inference algorithms   algorithm need subscribe inference as   

fidarwiche   provan

query variables

evidence variables

causal network

q dag compiler
off line

on line
query dag

evidence

q dag evaluator

figure    proposed framework implementing belief network inference 

 a 

 b 

pr a on      

pr b off  c 

pr b on  c 



 

 

   

    

 

pr b on a 

   

    

b

c



 

 

 

 



 

pr c on a 



   



  



  



  

  

 
  

 c on 

 
 

 
  

 c off 

figure    belief network  a   corresponding query dag  b   here  c evidence
variable  interested probability variable b  
factoring view used q dag generation   c  computational guarantees
size q dags terms computational guarantees inference algorithm used
generate them  although spi framework positioned formulate related results 
pursued direction 
important stress following properties proposed approach  first  declaring evidence variable compilation process mean evidence must
collected variable on line this important evidence values  e g  
sensors  may lost practice it means evidence may collected  therefore  one declare variables evidence one wishes  second  variable
declared evidence query  allows one perform value of information
   

fia practical paradigm implementing belief network inference

computations decide whether worth collecting evidence specific variable 
third  space complexity q dag terms number evidence variables
worse time complexity underlying inference algorithm  therefore 
simple enumerate all possible cases approach  finally  time space complexity
generating q dag worse time complexity standard belief network
algorithm used generation  therefore  network solved using standard
inference algorithm  time complexity algorithm worse space
complexity   construct q dag network 
following section explains concept q dag concrete example
provides formal definitions  section   dedicated generation q dags
computational complexity  showing standard belief network inference algorithm
used compile q dag long meets general conditions  section  
discusses reduction q dag generated  showing reduction
subsumes key optimizations typically implemented belief network algorithms 
section   contains detailed example application framework diagnostic
reasoning  finally  section   closes concluding remarks 

   query dags

section starts treatment q dags concrete example  consider
particular belief network  define set queries interest  show q dag
used answer queries  discuss q dag generated 
used  allow concrete introduction q dags help us
ground formal definitions follow 
belief network consider one figure   a   class queries
interested pr  b j c    is  probability variable b takes value
given known  or unknown  value c   figure   b  depicts q dag answering
queries  essentially parameterized arithmetic expression values
parameters depend evidence obtained  q dag actually answer queries
form pr  b  c    use normalization compute pr  b j c   
first  number observations q dag figure   b  
q dag two leaf nodes labeled pr  b on   c  pr  b off   c  
called query nodes values represent answers queries pr  b on   c 
pr  b off   c  
q dag two root nodes labeled  c     c     called
evidence specific nodes  esns  since values depend evidence collected
variable c on line 
according semantics q dags  value node  v  v     variable v
observed v unknown    otherwise  values esns determined 
evaluate remaining nodes q dag using numeric multiplication addition 
numbers get assigned query nodes result evaluation answers
queries represented nodes 
   algorithms based join trees property 

   

fidarwiche   provan

     

     

     

pr b off  c 

pr b on  c 

pr b off  c 

     

pr b on  c 

 

 
   

     

   

 

 

 

 

  

     

   

 

 

  

  

 

 

  

 

  

 

  

 

 

  

 

 

 

 

 

 

 c on 

  

  

  

 
 c off 

 

 b 

   

    

 

  

 

 

   

    

   

     

  

 

 a 

   

    

   

    

 

 

     

 c on 

 

  

 

 
  
 
 c off 

figure    evaluating q dag figure   respect two pieces evidence   a 
c on  b  c off  
example  suppose evidence c     esn  c   
evaluated   esn  c    evaluated    q dag figure   b 
evaluated given figure   a   thus leading
pr  b on   c on           



pr  b off   c on           
conclude pr  c            compute conditional
probabilities pr  b on j c on   pr  b off j c on   using 
pr  b on j c on     pr  b on   c on   pr  c on   
pr  b off j c on     pr  b off   c on   pr  c on   
evidence c off   however   c    evaluates    c   
evaluates    q dag figure   b  evaluated given figure   b  
thus leading
pr  b on   c off           

pr  b off   c off           
use following notation denoting variables values  variables
denoted using uppercase letters  a  b  c   variable values denoted
lowercase letters  a  b  c  sets variables denoted boldface uppercase letters 
a  b  c  instantiations denoted boldface lowercase letters 
a  b  c  use e denote set variables evidence  therefore 
   

fia practical paradigm implementing belief network inference

use e denote instantiation variables represents evidence  finally 
family variable set containing variable parents directed acyclic
graph 
following formal definition q dag 

definition   q dag tuple  v       d  z  
   v distinguished set symbols  called evidence variables 
   symbol  called unknown value 
   maps variable v set symbols  called variable values  different
 
   directed acyclic graph
  non root node labeled either  
  root node labeled either
  number       
  pair  v  v   v evidence variable v value

   z distinguished set nodes  called query nodes 

evidence variables v correspond network variables expect collect
evidence on line  example  figure    c evidence variable  one
variables set possible values captured function   example 
figure    evidence variable c values   special value used
value variable known  example  may sensor variable
values  low    medium    high   lose sensor value on line reasoning 
case  set sensor value    query nodes representing answers
user queries  example  figure    b query variable  leads query nodes
pr b on   c  pr b off   c  
important notion evidence 

definition   given q dag  v       d  z    evidence defined function e
maps variable v v set values  v     fg 
variable v mapped v    v    evidence tells us v instantiated
value v   v mapped   evidence tell us anything value
v  
state formally evaluate q dag given evidence  first
need notation 
   numeric node  n p  denotes node labeled number p          
   esn  n v  v   denotes node labeled  v  v   
   useful cases variable measured value information justifies
that 

   

fidarwiche   provan

   operation node  n 
     
ni denotes node labeled parents
n           ni  
   operation node  n        ni denotes node labeled   parents
n           ni  
following definition tells us evaluate q dag evaluating nodes 
recursive definition according value assigned node function
values assigned parents  first two cases boundary conditions  assigning
values root nodes  last two cases recursive ones 
definition   q dag  v       d  z   evidence e   node evaluator defined
function maps node number        that 
    n p     p
 the value node labeled number number itself  
 
e  v     v e  v      
    n v  v           ifotherwise
 the value evidence specific node depends available evidence    v
consistent evidence   otherwise  
    n 
     
ni      n          ni  
 the value node labeled product values parent nodes  
    n        ni      n              ni  
 the value node labeled   sum values parent nodes  
one typically interested values nodes q dag since
nodes represent intermediate results interest user  query nodes
q dag represent answers user queries values nodes one
seeks constructing q dag  values queries captured notion
q dag output 
definition   node evaluator extended q dags follows 
  v       d  z      f n   n   j n   zg 
set   v       d  z    called q dag output 
output one seeks q dag  element output represents
probabilistic query answer 
let us consider evaluations q dag shown figure    shown
figure    given evidence e  c      assuming qnode b     qnode b  
  stand q dag nodes labeled pr  b on   c  pr  b off   c   respectively 

 n c         
 n c         
 qnode b on                                                     
 qnode b off                                                     
   

fia practical paradigm implementing belief network inference

meaning pr  b on   c on           pr  b off   c on            instead
evidence e  c   off   set analogous computations done 
possible evidence tells us nothing value variable c   is 
e  c       case  would

 n c         
 n c         
 qnode b on                                                    
 qnode b off                                                    
meaning pr  b on          pr  b off          

    implementing q dag evaluator

q dag evaluator implemented using event driven  forward propagation scheme 
whenever value q dag node changes  one updates value children 
on  possible update values possible  another way implement evaluator
using backward propagation scheme one starts query node updates
value updating values parent nodes  specifics application
typically determine method  or combination  appropriate 
important stress level refinement enjoyed q dag propagation scheme implications eciency query updates  propagation
q dags done arithmetic operation level  contrasted propagation
message operation level  used many standard algorithms   propagation schemes
typically optimized keeping validity ags messages invalid messages
recomputed new evidence arrives  clearly avoid unnecessary computations never avoid unnecessary computations message typically
coarse purpose  example  one entry message invalid 
whole message considered invalid  recomputing message lead many unnecessary computations  problem avoided q dag propagation since validity
ags attributed arithmetic operations  building blocks message operations  therefore  necessary arithmetic operations recomputed q dag
propagation scheme  leading detailed level optimization 
stress process evaluating updating q dag done outside
probability theory belief network inference  makes development ecient online inference software accessible larger group people may lack strong backgrounds
areas  

    availability evidence

construction q dag requires identification query evidence variables 
may give incorrect impression must know front variables observed
not  could problematic     applications one may lose sensor
reading  thus changing status variable observed unobserved 
   fact  appears background compiler theory may relevant generating ecient
evaluator background belief network theory 

   

fidarwiche   provan



  

  

pr b true a 
  
  

true
false

pr b true b 

 

 

pr a 



b

pr a true b 


true

pr b false b 

 

pr a false b 

 

 

 

  

 

  

 b true 

 b false 

  

 

  

  

figure    belief network corresponding q dag variable b declared
query evidence 
    applications variable may expensive observe  leading on line
decision whether observe  using value of information computation  
situations dealt q dag framework  first  mentioned
earlier  q dags allow us handle missing evidence use notation
denotes unknown value variable  therefore  q dags handle missing sensor
readings  second  variable declared query evidence  means
incorporate evidence variable available  compute
probability distribution variable case evidence available  figure   depicts
q dag variable declared query variable  variable b declared
evidence query variable  both variables true false values  
case  two esns variable b two query nodes  see figure    
q dag used two ways 
   compute probability distributions variables b evidence
available b   situation  values n b  true   n b  false  
set   
pr  a   true                       
pr  a   false                       
pr  b   true                        
   

fia practical paradigm implementing belief network inference

pr  b   false                        

   compute probability variable evidence available b  
example  suppose observe b false   value n b  true  
set   value n b  false   set   
pr  a   true   b   false                
pr  a   false   b   false                

ability declare variable evidence query variable seems
essential applications     decision may need made whether collect
evidence variable b       making decision requires knowing probability
distribution variable b   example  suppose using following formula
 pearl        page      compute utility observing variable b  
x
utility observing  b     pr b   bje  u  b   b  
b

u  b   b  utility decision maker finding variable b value b 
suppose u  b   true          u  b   false          use q dag
compute probability distribution b use evaluate utility observing  b   
utility observing  b                                    

leads us observe variable b   observing b   find value false  
accommodate evidence q dag continue analysis 

   generating query dags

section shows q dags generated using traditional algorithms exact
belief network inference  particular  show q dags generated using
clustering  join tree  jensen  ls  algorithm  jensen  lauritzen    olesen        shachter 
andersen    szolovits        shenoy   shafer         polytree algorithm  cutset
conditioning  pearl        peot   shachter         outline properties must
satisfied belief network algorithms order adapt generating q dags
propose 

    clustering algorithm

provide sketch clustering algorithm section  readers interested
details referred  shachter et al         jensen et al         shenoy   shafer        
according clustering method  start by 
   constructing join tree given belief network  
   join tree tree clusters satisfies following property  intersection two clusters
belongs clusters path connecting them 

   

fidarwiche   provan

   assigning matrix variable belief network cluster contains
variable s family 
join tree secondary structure inference algorithm operates  need
following notation state algorithm 
  s          sn clusters  cluster corresponds set variables
original belief network 
  potential function cluster si   mapping instantiations
variables si real numbers 
  pi posterior probability distribution cluster si   mapping
instantiations variables si real numbers 
  mij message sent cluster si cluster sj   mapping instantiations variables si   sj real numbers 
  e given evidence  is  instantiation evidence variables e 
assume standard multiplication marginalization operations potentials 
goal compute potential pr  x  e  maps instantiation x
variable x belief network probability pr  x  e   given notation 
state algorithm follows 
potential functions initialized using

  pr x x  
x



  x variable whose matrix assigned cluster si 
  pr x matrix variable x   mapping instantiations family
x conditional probabilities 
  x likelihood vector variable x   x  x    x consistent given

evidence e   otherwise 
posterior distributions computed using

pi  


k

mki  

sk clusters adjacent cluster si  
messages computed using
x
mij  
mki  
si nsj

k  j

sk clusters adjacent cluster si  
   

fia practical paradigm implementing belief network inference

potential pr  x  e  computed using
pr  x  e   

x
si nfx g

pi  

si cluster x belongs 
equations used follows  compute probability variable  must
compute posterior distribution cluster containing variable  compute
posterior distribution cluster  collect messages neighboring clusters  message
cluster si sj computed collecting messages clusters adjacent si
except sj  
statement join tree algorithm appropriate situations evidence
changing frequently since involves computing initial potentials time evidence
changes  necessary general one provide optimized versions
algorithm  issue  however  irrelevant context generating q dags
updating probabilities face evidence changes take place q dag level 
includes optimization technique discuss later 

    generating q dags

generate q dags using clustering method  go two steps  first 
modify initialization potential functions join tree quantified
using q dag nodes instead numeric probabilities  second  replace numeric
addition multiplication algorithm analogous functions operate q dag
nodes  particular 
   numeric multiplication replaced operation
takes q dag nodes
n          ni arguments  constructs returns new node n label parents
n          ni  
   numeric addition   replaced operation takes q dag nodes n           ni
arguments  constructs returns new node n label   parents n           ni 
therefore  instead numeric operations  q dag node constructors  instead
returning number computation result  return q dag node 
state q dag clustering algorithm  realize evidence
e  instead set evidence variables e collect evidence 
therefore  q dag algorithm compute answer query pr  x  e   instead
compute q dag node evaluates pr  x  e  instantiation e variables
e 
following equations  potentials mappings variable instantiations qdag nodes  instead numbers   example  matrix variable x map
instantiation x  s family q dag node n p  instead mapping number
p  q dag operations
extended operate new potentials
way   extended clustering algorithm 
new set equations is 
   

fidarwiche   provan

potential functions initialized using


  n pr x  
n e   
x

e



  x variable whose matrix assigned cluster si 
  n pr x   q dag matrix x   mapping instantiations x  s family

q dag nodes representing conditional probabilities 
  e evidence variable whose matrix assigned cluster si 
  n e   q dag likelihood vector variable e   n e   e    n e  e  
means node n e   e  evaluates   e consistent given evidence
  otherwise 
posterior distributions computed using

pi   mki  
k

sk clusters adjacent cluster si  
messages computed using

mij  
mki  
si nsj

k  j

sk clusters adjacent cluster si  
q dag nodes answering queries form pr  x  e  computed using

qnode x    
pi  
si nfx g

si cluster x belongs 
qnode x   potential maps instantiation x variable x q dag
node qnode x   x  evaluates pr  x  e  given instantiation e variables e 
hence  modifications made clustering algorithm  a  changing
initialization potential functions  b  replacing multiplication addition
q dag constructors multiplication addition nodes 

    example

show proposed q dag algorithm used generate q dag
belief network figure   a  
one evidence variable example  c   interested generating q dag answering queries variable b   is  queries form pr  b  e  
figure   a  shows join tree belief network figure   a   tables contain
potential functions needed probabilistic clustering algorithm  figure   b  shows
   

fia practical paradigm implementing belief network inference

s 

ac




c on
  
  

 

 a 

ab


c off
  

s 

s 

ac


 

  




b on
        
       

b off
        
       

ab


c off

c on



n    

n c on 

n    

n c off 



n    

n c on 

n    

n c off 


 

 b 

b on

s 

 

b off



n      

n      



n     

n     

figure    join tree quantified numbers  a   q dag nodes  b  
join tree again  tables contain potential functions needed q dag
clustering algorithm  note tables filled q dags instead numbers 
apply q dag algorithm  compute q dag nodes evaluate
pr  b  e   must compute posterior distribution p  cluster s  since
cluster variable b belongs  sum distribution variable
obtain want  compute distribution p  must first compute message
m   cluster s  cluster s   
message m   computed summing
potential function   cluster s 
possible values variable c   i e   m         leads to 
c

m    a on      n    
n c      n    
n c     
m   a off      n    
n c      n    
n c     
posterior distribution cluster s    p    computed using p     
m    

leads

p   a on   b on     n      
  n    
n c      n    
n c     
p  a on   b off     n      
  n    
n c      n    
n c     
p  a off   b on     n     
  n    
n c      n    
n c     
p  a off   b off     n     
  n    
n c      n    
n c      
q dag node qnode b  answering queries
form pr  b  e  computed
summing posterior p  variable a  qnode  
p    leading
nfb g
qnode b on      n      
  n    
n c      n    
n c      
 n     
  n    
n c      n    
n c      
qnode b off      n      
  n    
n c      n    
n c      
 n     
  n    
n c      n    
n c       
 

   

fidarwiche   provan

q dag depicted figure   b   therefore  result applying algorithm
two q dag nodes  one evaluate pr  b     e  evaluate
pr  b off   e  instantiation e evidence variables e 

    computational complexity q dag generation

computational complexity algorithm generating q dags determined
computational complexity clustering algorithm  particular  proposed algorithm applies  operation precisely clustering algorithm applies additionoperation  similarly  applies
 operation precisely clustering algorithm applies
multiplication operation  therefore  assume
take constant time 
algorithms time complexity 
application
ends adding new node q dag 
way new node added q dag  moreover  number parents
added node equal number arguments corresponding arithmetic operation
invoked clustering algorithm  therefore  space complexity q dag
time complexity clustering algorithm 
particular  means space complexity q dags terms number
evidence variables time complexity clustering algorithm
terms  moreover  evidence variable e add evidence specific nodes
q dag  number values variable e take  important
stress without complexity guarantee may hard distinguish
proposed approach brute force approach builds big table containing possible
instantiations evidence variables together corresponding distributions query
variables 

    generation algorithms

polytree algorithm special case clustering algorithm shown  shachter
et al          therefore  polytree algorithm modified suggested
compute q dags  means cutset conditioning easily modified
compute q dags  instantiation c cutset c  compute q dag node
pr  x  c  e  using polytree algorithm take  sum resulting nodes 
algorithms exact inference belief networks adapted generate qdags  general  algorithm must satisfy key condition adaptable computing
q dags suggested above  condition behavior algorithm
never depend specific evidence obtained  depend variables
evidence collected  is  whether variable e instantiated value v 
value v  affect complexity algorithm  whether variable e
instantiated matter 
belief networks algorithms aware satisfy property  reason
seems notion probabilistic independence algorithms
based  specifically  read topology belief network relation
 x  z  y   stating variables x independent given variables z  is 
pr  x  j z    pr  x j z pr  y j z 
   

fia practical paradigm implementing belief network inference

instantiations x  y  z variables  possible  however  hold
instantiations z specific ones  standard algorithms aware
take advantage instantiation specific notion independence   therefore 
cannot attach computational significance specific value variable
instantiated  property existing algorithms makes easily adaptable
generation q dags 

    soundness q dag clustering algorithm

soundness proposed algorithm stated below  proof given appendix a 

theorem   suppose qnode x   q dag potential generated q dag clustering algorithm query variable x evidence variables e  let e  instantiation
variables e  let q dag evidence e defined follows 
 
evidence e  sets variable e value e 
e  e     e   otherwise 


 qnode x   x     pr  x  e   

is  theorem guarantees q dag nodes generated algorithm
always evaluate corresponding probabilities partial full instantiation
evidence variables 

   reducing query dags

section focused reducing q dags generated  main
motivation behind reduction twofold  faster evaluation q dags less space
store them  interestingly enough  observed few  simple reduction techniques
tend certain cases subsume optimization techniques uential practical implementations belief network inference  therefore  reducing q dags
important practically 
section structured follows  first  start discussing four simple reduction
operations form rewrite rules  show examples reductions subsume two key optimization techniques known network pruning computation caching 

    reductions

goal q dag reduction reduce size q dag maintaining
arithmetic expression represents  describing equivalence arithmetic expressions 
define notion q dag equivalence 
definition   two q dags equivalent iff set evidence specific
nodes output possible q dag evidence 
   algorithms two level binary networks  bn   networks   versions spi algorithm
take advantage independences 

   

fidarwiche   provan

q



 

 

 
p

 

q
q 

q

p

 

 

q 

 
q 

q 

 
q  q  

 

 

q

 

q 

q 

b  numeric
reduction

c  associative
merging

q 

q 
q 

 a  identity
elimination

q 

q 

d  commutative
merging

figure    four main methods q dag reduction 
figure   shows four basic reduction operations experimented with 
   identity elimination  eliminates numeric node identity element child
operation node 
   numeric reduction  replaces operation node numeric node parents
numeric nodes 
   associative merging  eliminates operation node using operation associativity 
   commutative merging  eliminates operation node using operation commutativity 
rules applied successively different order applications
possible 
proven operations sound  darwiche   provan         based
analysis network structure preliminary empirical results  observed
many factors govern effectives operations  degree reduction
operations  numeric reduction particular  reduce size q dag depends
topology given belief network set evidence query variables 
example  root nodes evidence variables belief network  leaf nodes
query variables  numeric reduction lead little q dag reduction 
focus numeric reduction  showing sometimes subsumes two optimization techniques uential belief network algorithms  optimizations  show examples unoptimized algorithm employs numeric reduction
yields q dag optimized algorithm  major implication optimizations done uniformly q dag level  freeing underlying belief network
algorithms implementational complications 
following examples assume applying polytree algorithm singlyconnected networks 
   

fia practical paradigm implementing belief network inference





p a 



  




b

  
  

  



b



  
  

p b on a 
  
  




p c on b 

b

 a 

p a 

p b on a 




c




 b 

figure    simple belief network pruning  a  pruning  b   light shaded
node  a  query node  dark shaded node  b   evidence node 

p a on b b 

p a on b b 

 

 

 

 b on 

 

  

  

  

 

 b off 

  

  

 

 

 

 
  

 

  

  

 b on 

 b off 

  

  

 a  original q dag

 b  reduced q dag

figure     q dag  a  reduction  b  

    network pruning
pruning process deleting irrelevant parts belief network invoking inference  consider network figure   a  example  b evidence variable
query variable  one prune node c network  leading network
figure   b   query form pr  a j b  value respect either
network  clear working smaller network preferred  general 
pruning lead dramatic savings since reduce multiply connected network
singly connected one 
   

fidarwiche   provan

generate q dag network figure   a  using polytree algorithm 
obtain one figure    a   q dag corresponds following expression 
x
x
pr  a on   e    pr  a on   b  b pr  b j a on   pr  c j b  
c

b

generate q dag network figure   b   however  obtain one
figure    b  corresponds following expression 
x
pr  a on   e    pr  a on   b  b pr  b j a on   
b

expected  q dag smaller q dag figure    a   contains subset
nodes figure    a  
key observation  however  optimized q dag figure    b 
obtained unoptimized one figure    a  using q dag reduction  particular 
nodes enclosed dotted lines collapsed using numeric reduction single
node value    identity elimination remove resulting node  leading
optimized q dag figure    b  
general observation  however  prunable nodes contribute identity elements computing answers queries  contributions appear q dag nodes
evaluate identity elements instantiations evidence  nodes
easily detected collapsed identity elements using numeric reduction  identity
elimination remove q dag  leading effect network
pruning   whether q dag reduction replace possible pruning operations open
question outside scope paper 

    computation caching

caching computations another uential technique optimizing inference belief networks  consider example  suppose applying polytree algorithm
compute pr  c  b  network figure     given evidence  say b  on   algorithm
compute pr  c  b     passing messages shown figure     evidence
changes b off   however  algorithm employing caching recompute message b  a   which represents causal support b  pearl         since value
message depend evidence b    kind optimization typically
   note  however  q dag reduction reduce computational complexity generating qdag  although network pruning may  example  multiply connected network may become singlyconnected pruning  thereby  reducing complexity generating q dag  using q dag
reduction  still generate q dag working multiply connected network 
   seen considering following expression  evaluated incrementally polytree
algorithm message passes 
pr  c  e   

x
b

pr  c j b  b  b 

 

x


pr  b j a  pr  a   

 z

c  b 

   z  
b
 
   

clear subexpression corresponding message b  a  b independent
evidence b  

   

fia practical paradigm implementing belief network inference


b
c



pr a 



  



pr b on a 
  
  




pr c on b 

b

  
  




figure     simple belief network demonstrating relationship q dag reduction computation caching  light shaded node  c   query node 
dark shaded node  b   evidence node 



 a 
b
b

 b 
c
c

figure     message passing c queried b observed 
implemented caching values messages keeping track messages
affected evidence 
now  consider q dag corresponding problem shown figure    a  
nodes enclosed dotted lines correspond message b    nodes
evidence specific nodes ancestor set and  therefore  never change values
due evidence changes  fact  numeric reduction replace one nodes
ancestors single node shown figure    b  
general  numeric reduction applied q dag  one guaranteed following 
 a  q dag node represents message depend evidence  node
re evaluated given evidence changes   b  numeric reduction guarantee
p pr  b a pr  a  
   precisely  correspond expression


   

j

fidarwiche   provan

p c on b b 

p c on b b 

 

 

 

  

 
 

 

 

 b on 

 

  

 

   
 

 b off 

 

 b off 

 b on 

  

 

  

   

 

 

 

 

cached value
  

  

  

  
  

     

  

 a  original q dag

 b  reduced q dag

figure     q dag  a  reduction  b  
q dag evaluation method since replace node ancestor set
single root node   

    optimization belief network inference

network pruning computation caching proven uential practical
implementations belief network inference  fact  experience shown
optimizations typically make difference usable non usable beliefnetwork system 
one problem optimizations  however  algorithm specific implementations although based general principles  e g   taking advantage network
topology   another problem make elegant algorithms complicated hard
understand  moreover  optimizations often hard define succinctly  hence
well documented within community 
contrast  belief network inference optimized generating q dags using unoptimized inference algorithms  optimizing generated q dag reduction techniques  shown examples earlier respect pruning
caching optimizations  however  whether alternate approach optimization always
feasible yet known  positive answer clearly provide algorithm independent
    note q dags lead refined caching mechanism q dag evaluator     caches value
q dag node     updates cached values need  that is 
value parent node changes   refined mechanism allows caching values messages
depend evidence well 

   

fia practical paradigm implementing belief network inference

fuel sensor
fuel
battery

oil pressure
battery sensor

fault

oil pressure
sensor
alternator
alternator
sensor

figure     simple belief network car diagnosis 
approach optimizing belief network inference  practically important least
two reasons  first  q dag reduction techniques seem much simpler understand
implement since deal graphically represented arithmetic expressions  without
invoke probability belief network theory  second  reduction operations applicable q dags generated belief network algorithm  therefore  optimization
approach based q dag reduction would systematic accessible bigger
class developers 

   diagnosis example
section contains comprehensive example illustrating application q dag
framework diagnostic reasoning 
consider car troubleshooting example depicted figure     simple case
want determine probability distribution fault node  given evidence four
sensors  battery   alternator   fuel  oil sensors  sensor provides information
corresponding system  fault node defines five possible faults  normal  cloggedfuel injector  dead battery  short circuit  broken fuel pump 
denote fault variable f   sensor variables e  want build
system compute probability pr  f  e   fault f evidence e 
probabilities represent unnormalized probability distribution fault variable
given sensor readings  q dag framework  realizing diagnostic system involves three
steps  q dag generation  reduction  evaluation  first two steps accomplished
off line  final step performed on line  discuss one steps
detail 

    q dag generation
first step generate q dag  accomplished applying q dag
clustering algorithm fault query variable sensors evidence vari   

fidarwiche   provan

p f normal e 

p f normal 
   

p f pump 
   

fuel
 normal 

p f pump e 

fuel
subtree

 pump 

battery
 normal 

battery
 pump 

alternator
 normal 

oil
alternator
 pump 

 normal 

oil
 pump 

structure sharing

figure     partial q dag car example  displaying two five query nodes 
broken fuel pump normal  shaded regions portions q dag
shared multiple query nodes  values nodes relevant
value one query node 
ables  resulting q dag five query nodes  qnode f   normal   e   qnode f  
clogged fuel injector   e   qnode f   dead battery   e   qnode f   short circuit   e  
qnode f   broken fuel pump  e   node evaluates probability corresponding fault instantiation evidence  probabilities constitute differential
diagnosis tells us fault probable given certain sensor values 
figure    shows stylized description q dag restricted two five query
nodes  corresponding pr  f   broken fuel pump   e  pr  f   normal   e   q dag
structure symmetric fault value sensor 
given q dag symmetric possible faults  clarity exposition
look subset needed evaluate node pr  f   broken fuel pump   e   figure   
shows stylized version q dag produced node  following observations q dag  first  evidence specific node every instantiation
sensor variables  corresponding forms sensor measurements possible  second 
roots q dag probabilities  third  one five parents query node
pr f   broken fuel pump   e  prior f   broken fuel pump   four
contributions four sensors  example  figure    highlights  in dots 
part q dag computing contribution battery sensor 

    q dag reduction

generating q dag  one proceeds reducing using graph rewrite rules  figure   
shows example reduction q dag restricted one query node
simplicity  give idea kind reduction applied  consider
partial q dag enclosed dots figure  figure    compares reduced q dag
unreduced one generated  given goal generating q dags
 a  evaluated eciently possible  b  require minimal space store 
   

fia practical paradigm implementing belief network inference

key
f s fuel sensor
b s battery sensor
a s alternator sensor
o s oil sensor

p f pump e 

 

 

p f pump 
   

 

 

 

 

 

full 

 

 

 

 

 

    esn b s      esn a s      esn a s      esn o s      esn o s 

   esn f s     esn b s 

esn f s 
empty 

 

dead 

charged 

not ok 

ok 

low 

   

normal 

figure     partial q dag car example 
 
 

 

 a  reduced q dag
esn b s 

    esn b s     

dead 

charged 

 

 b  original q dag

 

 

 
esn b s 

esn b s 

 

charged 

dead 

p b s charged  p b charged 
f pump b charged  f pump 
  

 

 

  

esn b s 

 

charged 

p b s dead 
p b s charged 
p b charged 
f pump b dead 
f pump b charged  f pump 
  

  

  

 
 
p b dead 
f pump 
  

esn b s 
dead 
p b s dead 
f pump b dead 
  

 
p b dead 
f pump 
  

figure     reduced unreduced q dags car diagnosis example 
important see  even simple example  q dag reduction make big difference
size 
   

fidarwiche   provan

    q dag evaluation

reduced q dag  use compute answers diagnostic queries 
section presents examples evaluation respect generated q dag 
suppose obtain readings dead  normal  ok full battery  oil 
alternator fuel sensors  respectively  let us compute probability distribution
fault variable  obtained evidence formalized follows 
  e  battery sensor     dead  
  e  oil sensor     normal  
  e  alternator sensor     ok  
  e  fuel sensor     full  
evidence specific nodes evaluated according definition    example 

 n battery sensor   charged       

 n battery sensor   dead        
evaluation evidence specific nodes shown pictorially figure    a   definition  
used evaluate remaining nodes  values node s parents
known  value node determined  figure    b  depicts results
evaluating nodes  result interest probability         assigned
query node pr  fault   broken fuel pump   e  
suppose evidence changed value fuel sensor empty instead
full  update probability assigned node pr  fault   broken fuel pump   e   brute
force method re evaluate whole q dag  however  forward propagation scheme
used implement node evaluator  four nodes need re evaluated
figure    b   those enclosed circles  instead thirteen  the total number nodes  
stress point refined updating scheme  easy implement
framework  much harder achieve one attempts embed standard beliefnetwork algorithms based message passing 

   concluding remarks

introduced new paradigm implementing belief network inference oriented towards real world  on line applications  proposed framework utilizes knowledge
query evidence variables application compile belief network arithmetic expression called query dag  q dag   node q dag represents numeric
operation  number  symbol depends available evidence  leaf node
q dag represents answer network query  is  probability event
interest  inference q dags linear size amounts standard evaluation
arithmetic expressions represent 
important point stress work reported proposing
new algorithm belief network inference  proposing paradigm
   

fia practical paradigm implementing belief network inference

pr f pump e 
 a  evaluating esns

 

 

   
pr f pump 

 

 
 

 
 

  

esn f s 
empty 

 

 

 

 

  

 

     

esn b s 
dead 

esn f s 
full 

 

   

esn b s 
charged 

 

 

 

     

esn a s 
not ok 

   

esn a s 
ok 

 
   

 

esn o s 
low 

 

esn o s 
normal 

   

esn values

        

pr f pump e 
 b  propagating probabilities

 

   
 
esn f s 
empty 

     

    

   
pr f pump 

     

    
  

 
esn f s 
full 

  

 
esn b s 
dead 

     

  

     
esn b s 
charged 

  
   

 
esn a s 
not ok 

     

    
     
esn a s 
ok 

   
   

 

esn o s 
low 

     

   

 

esn o s 
normal 

   

esn values

figure     evaluating q dag car diagnosis example given evidence sensors 
bar  a  indicates instantiation esns  shaded numbers
 b  indicate probability values computed node evaluator 
circled operations left hand side  b  ones need
updated evidence fuel system sensor altered  denoted circled
esns 

   

fidarwiche   provan

implementing belief network inference orthogonal standard inference algorithms
engineered meet demands real world  on line applications  class
applications typically demanding following reasons 
   typically requires short response time  i e   milliseconds 
   requires software written specialized languages  ada  c   
assembly pass certification procedures 
   imposes severe restrictions available software hardware resources order
keep cost  unit   such electromechanical device  low possible 
address real world constraints  proposing one compile belief network
q dag shown figure   use q dag evaluator on line reasoning 
brings required memory needed storing q dag evaluator 
brings required software needed implementing q dag evaluator 
simple seen earlier 
proposed approach still requires belief network algorithm generate q dag 
makes eciency algorithm less critical factor    example 
show standard optimizations belief network inference  pruning
caching  become less critical q dag framework since optimizations tend
subsumed simple q dag reduction techniques  numeric reduction 
work reported paper extended least two ways  first  qdag reduction techniques could explored  oriented towards reducing evaluation
time q dags  others towards minimizing memory needed store them  second 
shown optimization techniques dramatically improve belief network
algorithms may become irrelevant size q dags q dag reduction employed 
investigation needed prove formal results guarantees effectiveness
q dag reduction 
close section noting framework proposed applicable
order of magnitude  omp  belief networks  multiplication addition get replaced
addition minimization  respectively  goldszmidt        darwiche   goldszmidt 
       omp q dag evaluator  however  much ecient probabilistic
counterpart since one may evaluate minimization node without evaluate
parents many cases  make considerable difference performance q dag
evaluator 

acknowledgements
work paper carried first author rockwell science
center  special thanks jack breese  bruce d ambrosio anonymous reviewers
useful comments earlier drafts paper 
    shown clustering conditioning algorithms used q dag generation 
algorithms spi  li   d ambrosio        shachter et al         used well 

   

fia practical paradigm implementing belief network inference

appendix a  proof theorem  

without loss generality  assume proof variables declared evidence
variables  prove soundness theorem  need show q dag potential evaluate corresponding probabilistic potential possible evidence 
formally  cluster variables x   matrices assigned  
need show


  n pr x  
n x      pr x x
   
x

x

given evidence e   establish this  guaranteed qnode x   x 
evaluate probability pr  x  e  application
q dag algorithm isomorphic application   probabilistic algorithm  respectively 
prove equation    extend q dag node evaluator mappings
standard way  is  f mapping instantiations q dag nodes   f  
defined follows 
 f   x   def  f  x   
is  simply apply q dag node evaluator range mapping f  
note  f
g   equal  f  me  g    therefore 

  n pr x  
n x   
xy
 
 n pr x   me  n x   
x

 
pr x  n x    definition n pr x   
x

note definition n x    n x   x  equals n x  x   therefore 
 n x    x     n x   x  
 
  e  n x  x  
   e  x     x e  x    
 
   otherwise
  x  x  
therefore 


  n pr x  
n x      pr x x  
x

x

references

darwiche  a     goldszmidt  m          relation kappa calculus probabilistic reasoning  proceedings tenth conference uncertainty artificial
intelligence  uai   pp          
darwiche  a     provan  g          query dags  practical paradigm implementing
on line causal network inference  tech  rep         rockwell science center  thousand
oaks  ca 
   

fidarwiche   provan

goldszmidt  m          qualitative probabilities  normative framework commonsense
reasoning  tech  rep  r      university california los angeles  ph d  thesis 
jensen  f  v   lauritzen  s     olesen  k          bayesian updating recursive graphical
models local computation  computational statistics quarterly             
li  z     d ambrosio  b          ecient inference bayes networks combinatorial
optimization problem  international journal approximate reasoning            
pearl  j          probabilistic reasoning intelligent systems  networks plausible inference  morgan kaufmann publishers  inc   san mateo  california 
peot  m  a     shachter  r  d          fusion propagation multiple observations
belief networks  artificial intelligence                  
shachter  r   andersen  s     szolovits  p          global conditioning probabilistic
inference belief networks  proc  tenth conference uncertainty ai  pp 
        seattle wa 
shachter  r   d ambrosio  b     del favero  b          symbolic probabilistic inference
belief networks  proc  conf  uncertainty ai  pp          
shenoy  p  p     shafer  g          propagating belief functions local computations 
ieee expert               

   


