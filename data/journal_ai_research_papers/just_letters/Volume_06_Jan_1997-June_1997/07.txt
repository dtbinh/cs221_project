journal of artificial intelligence research                 

submitted       published     

flaw selection strategies for partial order planning

martha e  pollack

department of computer science and intelligent systems program 
university of pittsburgh  pittsburgh  pa       usa

david joslin

computational intelligence research laboratory 
university of oregon  eugene  or       usa

pollack cs pitt edu
joslin cirl uoregon edu

massimo paolucci

intelligent systems program 
university of pittsburgh  pittsburgh  pa       usa

paolucci pitt edu

abstract

several recent studies have compared the relative eciency of alternative aw selection
strategies for partial order causal link  pocl  planning  we review this literature  and
present new experimental results that generalize the earlier work and explain some of the
discrepancies in it  in particular  we describe the least cost flaw repair  lcfr  strategy
developed and analyzed by joslin and pollack         and compare it with other strategies 
including gerevini and schubert s        zlifo strategy  lcfr and zlifo make very
different  and apparently conicting claims about the most effective way to reduce searchspace size in pocl planning  we resolve this conict  arguing that much of the benefit that
gerevini and schubert ascribe to the lifo component of their zlifo strategy is better
attributed to other causes  we show that for many problems  a strategy that combines
least cost aw selection with the delay of separable threats will be effective in reducing
search space size  and will do so without excessive computational overhead  although such
a strategy thus provides a good default  we also show that certain domain characteristics
may reduce its effectiveness 

   introduction
much of the current research in plan generation centers on partial order causal link  pocl 
algorithms  which descend from mcallester and rosenblitt s        snlp algorithm  pocl
planning involves searching through a space of partial plans  where the successors of a node
representing partial plan p are refinements of p   as with any search problem  pocl
planning requires effective search control strategies 
in pocl planning  search control has two components  the first  node selection  involves choosing which partial plan to refine next  once a partial plan has been selected for
refinement  the planner must then perform aw selection  which involves choosing either a
threat to resolve or an open condition to establish 
over the past few years  several studies have compared the relative eciency of alternative aw selection strategies for pocl planning and their extensions  peot   smith       
joslin   pollack        srinivasan   howe        gerevini   schubert        williamson  
hanks         these studies have been motivated at least in part by a tension between the
attractive formal properties of the pocl algorithms  and the limitations in putting them

c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fipollack  joslin    paolucci
to practical use that result from their relatively poor performance  to date  the pocl
algorithms cannot match the eciency of the so called industrial strength planners such as
sipe  wilkins        wilkins   desimone        and o plan  currie   tate        tate 
drabble    dalton         flaw selection strategy has been shown to have a significant
effect on the eciency of pocl planning algorithms  and thus researchers have viewed
the design of improved aw selection strategies as one means of making pocl planning
algorithms more practical 
in this paper  we review the literature on aw selection strategies  and present new
experimental results that generalize the earlier work and explain some of the discrepancies
in it  in particular  we describe the least cost flaw repair  lcfr  strategy developed
and analyzed by joslin and pollack         and compare it with other strategies  including
gerevini and schubert s zlifo strategy         lcfr and zlifo make very different 
and apparently conicting claims about the most effective way to reduce search space size
in pocl planning  we resolve this conict  arguing that much of the benefit that gerevini
and schubert ascribe to the lifo component of their zlifo strategy is better attributed
to other causes  we show that for many problems  a strategy that combines least cost aw
selection with the delay of separable threats will be effective in reducing search space size 
and will do so without excessive computational overhead  although such a strategy thus
provides a good default  we also show that certain domain characteristics may reduce its
effectiveness 

   background
    node and flaw selection

although the main ideas of pocl planning have been in the literature for more than
two decades  serious efforts at comparing alternative plan generation algorithms have been
relatively recent  what made these comparisons possible was the development of a set
of clear algorithms with provable formal properties  notably tweak  chapman        
and snlp  mcallester   rosenblitt         these algorithms were not intended to add
functionality to known planning methods  but rather to capture the essential elements of
these known methods in a readily analyzable fashion 
in analyzing pocl algorithms  researchers have found it useful to decouple the search
control strategy from the underlying plan refinement process  figure   is a generic pocl
algorithm  in which we highlight the two search decisions   following convention  we use
choose to indicate that node selection is a backtracking point  and select to indicate
that aw selection is not  a given node may not lead to a solution  and so it may be necessary
to backtrack and consider alternative nodes  on the other hand  if a node does lead to a
solution  that solution will be found regardless of the order in which its aws are selected 
see weld s        tutorial paper for more discussion of this difference 
the generic algorithm sketched in the figure must be supplemented with search strategies
that implement the choose and select operators  most pocl algorithms perform
node selection using a best first ranking that computes some function of the number of
   various versions of this well known algorithm have appeared in the literature  weld        russell  
norvig        kambhampati  knoblock    yang         the version we give corresponds most directly
to that given by williamson and hanks        

   

fiflaw selection strategies

pocl  init goal 

dummy plan make skeletal plan init goal  
nodes f dummy plan g 
while nodes is not empty do 

choose  and remove  a partial plan p from nodes   node selection 
if p has no aws
then return p
else do 

select a aw from p   flaw selection 

add all refinements of p to nodes 
return failure  because nodes has become empty without a aw free plan being found  
figure    the basic pocl planning algorithm
steps  denoted s    open conditions  oc    and unsafe conditions  uc   i e   threats  in the
partial plan  gerevini and schubert        have argued that  in general  only steps and
open conditions should be included in the ranking function  and we adopt that strategy in
our experiments  except where otherwise indicated 
having chosen a node  a pocl planning algorithm must then select a aw open condition or threat within that node to repair  open conditions are repaired by establishment 
which consists either in adding a new step that has a unifying condition as an effect  along
with a causal link from that new step to the condition   or else in simply adding a new
causal link from an existing step with a unifying effect  we use the term repair cost to
denote the number of possible ways to repair a aw 
for an open condition o  the repair cost r o  is i   s   n   where

i   the number of conditions in the initial state that unify with o given the
current binding constraints 
s   the number of conditions in the effects of existing plan steps that unify
with o given the current binding constraints  counting only existing plan
steps that are not constrained to occur after the step associated with o  and
n   the number of conditions in the effects of operators in the library that
unify with o given the current binding constraints 
note that over time  the repair cost for an open condition that is not resolved may either
increase  as new steps that might achieve the condition are added to the plan  or decrease 
as steps already in the plan are constrained by temporal ordering or variable binding so
that they can no longer achieve the condition 
in considering the cost of threat repair  it is useful to distinguish between nonseparable
and separable threats  nonseparable threats consist of a step s  with effect e   and a
causal link  s   f  s    where e and f are complementary literals that necessarily unify 
either they are complementary ground literals  e   f    or else they are complementary
literals where each of e  s variables is identical with  or forced by a binding constraint to be
   

fipollack  joslin    paolucci
equivalent to the variable in the same position in f  e g   e   p x  y   and f    p x  z   
where there is currently a binding constraint that y   z    
nonseparable threats can be repaired in at most two ways  by promoting s   requiring
it to occur after s    or by demoting it  requiring it to occur before s    of course  already
existing temporal ordering constraints may block one or both or these repair options  which
is why there are at most two possible repairs   over time  the repair cost for an unresolved
nonseparable threat can only decrease 
a separable threat consists of a step s  with an effect e   and a causal link  s    f  s   
where e and f are complementary literals that can be unified  but where such a unification
is not forced  e g   where e   p x  and f   p y   and there does not exist a binding
constraint x   y    in such circumstances  the threat may disappear if a subsequent variable
binding blocks the unification   a nonseparable threat may also disappear if a subsequent
ordering constraint has the effect of imposing promotion or demotion   the repair cost
for a separable threat may be higher than that for an nonseparable threat  not only can
promotion and demotion be used  but so can separation  which involves forcing a variable
binding that blocks the unification  separation can introduce one repair for each unbound
variable in the threat  for example  if the effect p  x  y  z   threatens  s     p  t  u  v    s   
there are three possible repairs  x    t  y    u  and z    v   as with nonseparable threats  the
repair cost for a separable threat that remains unresolved can only decrease over time 

    notation

the aw selection strategies that have been discussed in the literature typically have been
given idiosyncratic names  e g   dunf  lcfr  zlifo   it is useful  in comparing them 
to have a precise unifying notation  we therefore specify a aw strategy as a sequence of
preferences  a strategy begins by attempting to find a aw that satisfies its first preference 
if it is unable to do so  it then looks for a aw that satisfies the second preference  and
so on  to ensure that a pocl algorithm using the strategy is complete  the sequence of
preferences must be exhaustive  every aw must satisfy some preference  if a aw satisfies
more than one preference in a strategy  we assume that the first match is what counts 
in principle  a preference could identify any feature of a aw  in practice  however  aw
selection strategies have only made use of a small number of features  the type of a aw
 open condition  nonseparable threat  or separable threat   the number of ways it can be
repaired  and the time at which it was introduced into the plan  often  more than one aw
will have a given feature  in which case a tie breaking strategy may be specified for choosing
among the relevant aws 
we therefore describe a preference using the following notation

faw typesgrepair cost rangetie breaking strategy
   an alternative approach also treats cases in which e  f as threats  this is required to make the planner
systematic  i e   guaranteed never to generate the same node more than once  mcallester   rosenblitt 
      
   conditional planners make use of an additional method of threat resolution confrontation but we
ignore that within this paper  peot   smith        etzioni  hanks  weld  draper  lesh    williamson 
       joslin        provides a detailed account of generalizing the treatment of aws to other types of
planning decisions 

   

fiflaw selection strategies
which indicates a preference for any aw f of the specified type or types  provided that the
repair cost for f falls within the range of values specified   if there are no restrictions on
repair cost  we omit the repair cost range   if more than one aw meets these criteria  then
the tie breaking strategy is applied to select among them 
we abbreviate aw type as  o   for open condition    n   for nonseparable threat   and
 s   for separable threat   we also use abbreviations for common tie breaking strategies 
e g    lc   least  repair  cost    lifo  and  r   random   in the case of lc  if a choice
must be made between aws that have the same repair cost  lifo selection is used 
thus  for example
fng   r
specifies a preference for nonseparable threats with a repair cost of zero or one  if more than
one aw meets these conditions  a random selection will be made among them  we use the
term forced to describe aws with repair cost of one or less 
an example of a complete aw selection strategy is then 
fng   r   foglifo   fn sgr
this strategy would begin by looking for a forced nonseparable threat  if more than one aw
meets this criterion  the strategy would select randomly among them  if there are no forced
nonseparable threats  it would then look for an open condition  with any repair cost  using a
lifo scheme to select among them  finally  if there are neither forced nonseparable threats
nor open conditions  it would randomly select either an unforced nonseparable threat or a
separable threat 
while we have distinguished between aw type and maximum repair cost  on the one
hand  and tie breaking strategy  on the other  it is easy to describe strategies that use
something other than aw type as the main criterion for selection  for example  a pure
lifo selection strategy would be encoded as follows   henceforth  we give the name of a
strategy in boldface preceding the specification  
lifo fo n sglifo

   flaw selection strategies

we begin by reviewing the aw selection strategies that have been proposed and studied in
the literature to date 

    threat preference and delay

the original snlp algorithm  mcallester   rosenblitt        adopted a aw selection
strategy in which threats are resolved before open conditions  and early versions of the
widely used ucpop planning system  penberthy   weld        did the same   snlp
does not specify a principle for selecting among multiple threats or multiple opens  ucpop
used lifo for this purpose  employing the notation above  we can describe the basic
ucpop strategy as 
   in the current version of ucpop  v     the aw selection strategy that is run by default is the dsep
strategy  discussed just below  for historical reasons  we maintain the name dsep for that strategy  and
use ucpop for the older default strategy 

   

fipollack  joslin    paolucci

ucpop fn sglifo   foglifo
the first study of alternative aw selection strategies was done by peot and smith        
who relaxed the requirement that threats always be resolved before open conditions  and
examined several strategies for delaying the resolution of some threats  they analyzed five
different strategies for delaying the repair of threats  of these  two are provably superior 
dsep and dunf 
dsep  delay separable threats  was motivated by the observation that sometimes separable threats can simply disappear in the planning process as blocking variable bindings
are introduced  as we pointed out earlier  nonseparable threats may also  disappear  
but typically this is less frequent  moreover  if the resolution of all threats separable and
nonseparable were delayed  then nonseparable threats would only disappear early as a side
effect of step reuse  making their disappearance even less frequent 
the dsep strategy therefore defers the repair of all separable threats until the very end of
the planning process  however  like ucpop  it continues to give preference to nonseparable
threats 
dsep fnglifo   foglifo   fsglifo
actually  peot and smith do not specify a tie breaking strategy for choosing among multiple
threats  we have here indicated this as lifo  they explored three different tie breaking
strategies for selecting open conditions  fifo  lifo  and least cost   here we list lifo 
but one can also specify the alternatives 
dsep lc fnglifo   foglc   fsglifo
dsep fifo fnglifo   fogfifo   fsglifo
peot and smith prove that the search space generated by a pocl planner using dsep will
never be larger than the search space generated using the ucpop strategy  this result
holds when the tie breaking strategy for open conditions is lifo or fifo  but not lc  a
point we will return to later in the paper 
peot and smith s second successful strategy is dunf  delay unforced threats   it makes
use of the notion of forced aws  as we stated earlier  a aw is forced if there is at most
one possible way to repair it  the dunf strategy delays the repair of all unforced threats 
dunf fn sg lifo   fn sg lifo   foglifo   fn sg   lifo
we can define dunf lc and dunf fifo in a manner analogous to that used for dsep lc
and dsep fifo 
dunf lc fn sg lifo   fn sg lifo   foglc   fn sg   lifo
dunf fifo fn sg lifo   fn sg lifo   fogfifo   fn sg   lifo
peot and smith proved that the dunf strategy would never generate a larger search
space than either of the remaining two strategies that they examined  they also proved
that that dsep and dunf are incomparable  there exist planning problems for which dsep
generates a smaller search space than dunf  and other problems for which the reverse is
true 
   

fiflaw selection strategies
peot and smith support their theoretical results on dsep and dunf with experiments
showing that  at least for the domains they examined  these strategies can result in significant decrease in search space size  the decrease in search is correlated with the diculty of
the problem  and consequently  as the problems get more dicult  these strategies reduce
search time as well as space  that is  on large enough problems  they  pay for  their own
overhead 
in follow on work  peot and smith        describe a strategy called dmin  which generates smaller search spaces than both dsep and dunf  dmin combines a process of pruning
dead end nodes with the process of aw selection  it gives preference to forced threats  if
there are no forced threats  it checks to see whether all the remaining nonseparable threats
could be repaired simultaneously  if so  it leaves them as threats  and selects an open condition to repair  if there are no open conditions  then presumably it selects a remaining
unforced threat to repair  on the other hand  if it is impossible to repair all the unforced 
nonseparable threats  then the node is a dead end  and can be pruned from the search
space  note that some dead end nodes can be recognized immediately  even without doing
the complete consistency checking of dmin  this is because an unrepairable aw cannot
subsequently become repairable  hence  any node containing a aw with repair cost of zero
is a dead end  consequently  all aw selection strategies should give highest priority to such
aws  joslin   pollack        joslin        

    least cost flaw repair

peot and smith s work provided the foundation for our subsequent exploration of the leastcost aw repair  lcfr  strategy  joslin   pollack         we hypothesized that the power
of the dunf strategy might come not from its relative ordering of threats and open conditions  but instead from the fact that dunf has the effect of imposing a partial preference
for least cost aw selection  dunf will always prefer a forced threat  which  by definition
has a repair cost of at most one  thus  in cases in which there is a forced threat  dunf will
make a low cost selection  what about cases in which there are no forced threats  then
dunf will have to select among open conditions  assuming there are any  if our hypothesis is correct  a version of dunf that makes this selection using a least cost strategy  i e  
dunf lc  ought to perform better than a version that uses one of the other strategies  i e  
bare dunf or dunf fifo   in fact  if it is the selection of low cost repairs that is causing
the search space reduction  then the idea of treating threat resolution differently from open
condition establishment ought to be abandoned  instead  a strategy that always selects
the aw with minimal repair cost  regardless of whether it is a threat or an open condition 
ought to show the best performance  this is the least cost flaw repair  lcfr  strategy  

lcfr fo n sglc
there are strong similarities between lcfr and certain heuristics that have been proposed and studied in the literature on constraint satisfaction problems  csps   this is
perhaps not surprising  given that aw selection in pocl planning corresponds in some
   the lcfr strategy is similar to the branch   branch n search heuristics included in the o plan system
 currie   tate         the contribution of our original work on this topic was to isolate this strategy
and examine it in detail 

   

fipollack  joslin    paolucci
fairly strong ways to variable selection in constraint programming  flaws in a pocl planner represent decisions that are yet to be made  and that must be made before the plan
will be complete  unbound variables play a similar role in constraint satisfaction problems
 csps    although there exist a number of heuristics for selecting a variable to branch on
in solving a csp  kumar         one well known heuristic that is often quite effective is the
fail first principle  which picks the variable that is the  most constrained  when selecting
a variable to branch on  a simple and common implementation of the fail first principle
selects the variable with the smallest domain  tsang        
the intuition behind the fail first principle is that one should prune dead end regions
of the search as early as possible  the unbound variables that are most tightly constrained
are likely to be points at which the current partial solution is most  brittle  in some sense 
and by branching on those variables we hope to find a contradiction  if one exists  quickly 
similarly  lcfr can be thought of as selecting the  most constrained  aws  resulting in
better pruning 
a similar heuristic has also been adopted in recent work on controlling search in hierarchical task network  htn  planning  in the dynamic variable commitment strategy  dvcs   dvcs  like lcfr  is based on a minimal branching heuristic  experimental
analyses demonstrate that dvcs generally produces a well focused search  tsuneto  erol 
hendler    nau        
our own initial experimental results  presented in joslin and pollack         similarly
supported the hypothesis that a uniform least cost aw repair strategy could be highly
effective in reducing the size of the search space in pocl planning  in those experiments 
we compared lcfr against four other strategies  ucpop  dunf  and dunf lc  as defined
above  and a new strategy  ucpop lc which we previously called lcos  joslin   pollack 
      
ucpop lc fn sglifo   foglc
we included ucpop lc to help verify that search space reduction results from a preference
for aws with minimal repair costs  if this is true  then ucpop lc ought to generate a
smaller search space then dunf  even though it does not delay any threats  our results were
as expected  ucpop and dunf  which do not do least cost selection of open conditions 
generated the largest search spaces  ucpop lc generated significantly smaller spaces  and
dunf lc and lcfr generated the smallest spaces 
at the same time  we observed that lcfr incurred an unwieldy overhead  often taking
longer to solve a problem than ucpop  despite the fact that it was searching far fewer
nodes  in part this was due a particularly inecient implementation of lcfr that we were
using  but in part it resulted from the fact that computing repair costs is bound to take more
time than simply popping a stack  as in a lifo strategy   or finding a aw of a particular
type  as in a strategy that prefers threats   we therefore explored approximation strategies 
which reduce the overhead of aw selection by accepting some inaccuracy in the repair cost
calculation  for example  we developed the  quick lcfr   or qlcfr  strategy  which
calculates the repair cost of any aw only once  when that aw is first encountered  in
any successor node in which the aw remains unresolved  qlcfr assumes that its repair
   when planning problems are cast as csps in the planner descartes  joslin   pollack        joslin 
       this correspondence is even more direct 

   

fiflaw selection strategies
cost has not changed  our experiments with qlcfr showed it to be a promising means
of making a least cost approach suciently fast to pay for its own overhead  additional
approximation strategies were studied by srinivasan and howe         who experimented
with three variations of lcfr  along with a fourth  novel strategy that moves some of the
control burden to the user 

    threat delays revisited

recently  gerevini and schubert        have revived the idea that a aw selection strategy
should treat open conditions and threats differently  and have suggested that lifo should
be used as the tie breaking strategy for deciding among open conditions  they combine
these ideas in their zlifo strategy 
zlifo fnglifo   fog lifo   fog new   fog   lifo   fsglifo
the zlifo strategy gives highest priority to nonseparable threats  and then to forced open
conditions  if there are neither nonseparable threats nor forced open conditions  zlifo
will select an open condition using lifo  it defers all separable threats to the end of the
planning process  the name zlifo is intended to summarize the overall strategy  the  z 
stands for  zero commitment   indicating that preference is given to forced open conditions 
in repairing these  the planner is not making any commitment beyond what must be made
if the node is ultimately to be refined into a complete plan  the  lifo  indicates the
strategy used for selecting among unforced open conditions 
for open conditions with a repair cost of exactly one  the zlifo strategy uses a tiebreaking strategy here called  new   it prefers the repair of an open condition that can only
be established by introducing a new action over the repair of an open condition that can only
be established by using an element of the start state  gerevini and schubert state that this
preference  gave improvements in the context of russell s tire changing domain      without
significant deterioration of performance in other domains         p        however the
difference was apparently not dramatic  and gerevini believes this to be an implementation
detail  though is open to the possibility that further study might show this preference to be
significant  gerevini        
gerevini and schubert make three primary claims about zlifo 
   a pocl planner using zlifo will tend to generate a smaller search space than one
using a pure lifo strategy 
   the reduction in search space using zlifo  relative to lifo  is correlated with the
complexity of the planning problem  where complexity is measured by the number of
nodes generated by the pure lifo strategy  
   zlifo performs comparably with lcfr on relatively easy problems  and generates
a smaller search space on harder problems 
the first two claims are consistent with what we found in the earlier lcfr studies 
while a lifo strategy pays no attention to repair costs  zlifo does  at least indirectly 
both in its initial preference for nonseparable threats  which have a repair cost of no more
than two  and in its secondary preference for forced opens 
   

fipollack  joslin    paolucci
the third claim is harder to square with our earlier lcfr study  in which the lifobased strategies  such as ucpop and dunf  generated much larger search spaces than the
least cost based strategies  what explains zlifo s performance  gerevini and schubert
answer this question as follows 
based on experience with search processes in ai in general   a lifo  strategy
has much to recommend it  as a simple default  in the first place  its overhead
cost is low compared to strategies that use heuristic evaluation or lookahead to
prioritize goals  as well  it will tend to maintain focus on the achievement of a
particular higher level goal by regression      rather than attempting to achieve
multiple goals in a breadth first fashion   p      
their point about overhead is an important one  zlifo is a relatively inexpensive control
strategy  and a competing strategy that does a better job of pruning the search space may
end up paying excessive overhead  but it is the second point that addresses the question
we are asking here  namely  how zlifo could produce smaller search spaces  gerevini and
schubert go on to say that 
 m aintaining focus on a single goal should be advantageous at least when
some of the goals to be achieved are independent  for instance  suppose that two
goals g  and g  can both be achieved in various ways  but choosing a particular
method of achieving g  does not rule out any of the methods of achieving g  
then if we maintain focus on g  until it is solved  before attempting g   the
total cost of solving both goals will just be the sum of the costs of solving
them independently  but if we switch back and forth  and solutions of both
goals involve searches that encounter many dead ends  the combined cost can
be much larger  this is because we will tend to search any unsolvable subtree
of the g  search tree repeatedly  in combination with various alternatives in the
g  search tree         p      
this is certainly a plausible explanation  a key remaining question  of course  is the extent to which this explanation carries over to the many planning problems that involve
interacting goals 

   experimental comparison of flaw selection strategies

as discussed in the previous section  several different proposals have been made in the
literature about how best to reduce the size of the search space during pocl planning 
these include 
 giving preference to threats over open conditions 
 giving preference only to certain kinds of threats  either separable or forced threats  
and delaying other threats until after all open conditions have been resolved 
 giving preference to aws that have minimal repair cost 
 giving preference to the most recently introduced aws 
   

fiflaw selection strategies
moreover  different strategies have combined these preference schemes in different ways 
and apparently conicting claims have been made about the effects of these preferences on
search space size 
to resolve these conicts  we performed experimental comparisons of pocl planners
using a variety of aw selection strategies  we gave particular attention to the comparison
of lcfr and zlifo  because of the their apparently conicting claims  lcfr generates
its search space treating all aws uniformly  using a least cost approach to choose among
them  zlifo distinguishes between aw types  non separable threats  open conditions  and
separable threats   and uses a modified lifo approach to select among the aws in each
class  the original lcfr studies would have led us to predict that zlifo would generate
larger search spaces than did lcfr  but gerevini and schubert found just the opposite to
be true  we aimed  then  to explain this discrepancy 
our principal focus was on search space size  for two reasons  first  the puzzle raised
by lcfr and zlifo is one of space  not time  as we mentioned earlier  it is easy to see
why zlifo would be faster than lcfr  even on a per node basis  a least cost strategy
must compute repair costs  while zlifo need only pop a stack containing the right type
of aws  the puzzle for us was not why zlifo was faster  but why it generated smaller
search spaces  second  we believe that understanding the effect of search control strategies
on search space size can lead to development of approximation techniques that produce
speed up as well  the qlcfr strategy  joslin   pollack        and srinivasan and howe s
strategies        are examples of this 
however  a secondary goal was to analyze the time requirements of the strategies we
compared  and we therefore collected timing data for all our experiments  as we discuss in
section      the strategy that tends to generate the smallest search space achieves enough
of a reduction to pay for its own overhead  by and large 

    experimental design

to conduct our comparison  we implemented a set of aw selection strategies in ucpop
v     table   lists the strategies that we implemented  except for lcfr dsep and dunfgen  which are discussed later  all the implemented strategies were described in section
  
we tested all the strategies on three problem sets  also used in our earlier work  joslin
  pollack        and in gerevini and schubert s        
   the basic problems     problems taken from the test suite distributed with the
ucpop system  these include problems from a variety of domains  including the
   note that the experiments in both our earlier lcfr paper  joslin   pollack        and gerevini and
schubert s        zlifo paper were run using an earlier version  v    of ucpop  as a result  the
number of nodes produced in our experiments sometimes differs from what is reported in these other
two papers  this appears to be largely due to the fact that ucpop v   puts the elements of a new set
of open conditions onto the aw list in the reverse order of the way in which ucpop v   does  gerevini 
       as discussed below in sections          we studied the inuence of this ordering change by also
collecting data using a modified version of ucpop v   in which we reversed the order of conditions
entered in the open list  while the resulting numbers are similar to those previously published  they
are not identical  leading us to conclude that there are additional subtle differences between v   and
v    however  because all the experiments on which we report here were run using the same version of
ucpop  we believe this to be a fair comparison of the strategies 

   

fipollack  joslin    paolucci
ucpop
ucpop lc
dsep
dsep lc
dunf
dunf lc
dunf gen
lcfr
lcfr dsep
zlifo

fn sglifo   foglifo
fn sglifo   foglc
fnglifo   foglifo   fsglifo
fnglifo   foglc   fsglifo
fn sg lifo   fn sg lifo   foglifo   fn sg   lifo
fn sg lifo   fn sg lifo   foglc   fn sg   lifo
fn s og lifo   fn s og lifo   fn s og   lifo
fo n sglc
fn oglc   fsglc
fnglifo   fog lifo   fog new   fog   lifo   fsglifo
table    implemented flaw selection strategies

blocks world  the monkeys and bananas problem  pednault s        briefcase andoce problem  russell s        tire changing world  etc 
   the trains problems  three problems taken from the trains transportation domain
 allen  schubert    et al         
   the tileworld problems  seven problems taken from the tileworld domain  pollack  
ringuette        
we ran each strategy on each problem twice  the first time  we imposed a node limit 
of        nodes for the basic problems  and of         nodes for the trains and tileworld
problems  the second time  we imposed a time limit  of     seconds for the basic problems 
and of      seconds for the trains and tileworld problems 
gerevini and schubert experimented with several different node selection strategies for
the trains and tileworld domains  so to facilitate comparison we also used the same node
selection strategies as they did  for the basic problems  we used s   oc  
in reporting our results  we make use not only of raw counts of nodes generated and
computation time in seconds taken  but we also compute a measure of how badly a strategy
performed on a given problem or set of problems  we call this measure   overrun  and
compute it as follows  let m be the minimum node count on a given problem for any of
the strategies we tested  and let c be the node count for a particular strategy s   then
  overrun s       c   m  m      
thus  for example  if the best strategy on a given problem generated     nodes  then a
strategy that generated     nodes would have a       overrun on that problem  the
strategy that does best on a given problem will have a   overrun of   on that problem  in
section      we make use of similarly computed   overruns for computation time 
if a strategy hit the node limit  we set c to the relevant node limit         or         
to compute its node count   overrun   similarly  if a strategy hit the time limit  we used
the relevant time limit      or       to compute the computation time   overrun 
   because of the way in which ucpop completes its basic iteration  it sometimes will go somewhat beyond
the specified node limit before terminating the run  in such cases  we used the node limit value  rather
than the actual number of nodes generated  in our computation of   overrun 

   

fiflaw selection strategies
online appendix a provides the raw data node counts and computation time taken 
for all the experiments we conducted  it also includes computed   overruns 
in conducting experiments such as these  one has to set either a node  or time limit
cutoff for each strategy problem pair  however  there is always a danger that these cutoffs
unfairly bias the data  if the limits are set in such a way that certain strategies that fail
would instead have succeeded were the limits increased slightly  we have carefully analyzed
our data to help eliminate the possibility of such a bias  details are given in appendix a 

    the value of least cost selection

having described our overall experimental design  we now turn to the analysis of the results  to begin  we sought to re establish the claims we originally made in our earlier
work  specifically  we wanted first to reconfirm  using a larger data set  that least cost
aw selection is an effective technique for reducing the size of the search space generated
by a pocl planner  we therefore ran an experiment in which we compared the the node
counts for the five strategies we had earlier studied lcfr  dunf  dunf lc  ucpop  and
ucpop lc plus one new one  dunf gen  explained below 
the results of this experiment are shown in figures   and    the former is a log log
scatter plot  showing the performance of each of the six strategies on the    problems in the
basic set  the problems were sorted by the minimal number of nodes generated on them
by any of the six strategies  thus  the left hand side of the graph includes the problems
that at least one of the six strategies found to be relatively easy  while the right hand side
has the problems that were hard for all six strategies  we omitted problems that none
of the six strategies were able to solve  the actual number of nodes generated by each
strategy is plotted on the y axis  against the minimal number of nodes for that problem 
on the x axis  lcfr s performance is highlighted with a line connecting its data points 
this graph shows that  in general  lcfr generates small search spaces on this problem set 
relative to the other strategies in this class  there were only six problems for which lcfr
was not within     of the minimum  three of these are in the get paid uget paid class
of problems including two of the  hardest  problems  uget paid  and uget paid    we
discuss this class of problems more in section     
an alternative view of the data is given in figure    which shows the aggregate performance of the six strategies  i e   the average of their node count   overrun on the basic
problems  as can be seen  lcfr has the smallest average   overrun 
figures   and   present similar views of the data for the tileworld domain  while figure
  gives the data for the trains problems  on the trains domain  these six strategies were
only able to solve the easiest problem  trains    so we simply show the actual node counts
in figure    we have omitted two data points  because they were so extreme that their
inclusion on the graph made it impossible to see the differences among the other strategies 
lcfr and dunf gen with s   oc   uc node selection took         and        nodes 
respectively  to solve the problem 
for the tileworld and trains problems  we observed the same sorts of interactions between node and aw selection strategies as were seen by gerevini and schubert  specifically 
lcfr performs relatively poorly with s   oc on the tileworld problems  and it performs
very poorly with s   oc   uc on the trains problems  however  when paired with the
   

fipollack  joslin    paolucci
     

nodes generated  log 

    
ucpop
dunf
ucpop lc
dunf lc
dunf gen
lcfr
   

  
  

   

    

     

minimum number of nodes generated  log 

figure    basic problems  node counts for strategies without forced flaw delay
other node selection strategies  lcfr produces the smallest search spaces of any strategies
in this class 
in sum  lcfr does tend to produce smaller search spaces than the other strategies in
this class  but a question remains  lcfr uses a least cost strategy  and a side effect of
this is that it will prefer forced aws  since forced aws are low cost aws  it is therefore
conceivable that lcfr s performance is mostly or even fully due to its preference for forced
aws  and not  or not greatly  inuenced by its use of a least cost strategy for unforced
aws  this same hypothesis could explain why dunf lc consistently outperforms dunf 
and why ucpop lc consistently outperforms ucpop 
it was to address this issue that we included dunf gen in our experiment  dunf gen is
a simple strategy that prefers forced aws of any kind  and otherwise uses a lifo regime 
we would expect dunf gen and lcfr to perform similarly  since they frequently make
the same decision  specifically  they will both select the same aw in any node in which
there is a forced aw  they will differ when there are only unforced aws  with dunf gen
selecting a most recently introduced aw and lcfr selecting a least cost aw 
in practice  dunf gen s performance closely mimicked that of lcfr s  on the basic
problem set it did only marginally worse than lcfr  in fact  it does marginally better
when we reverse the order in which the planner adds the preconditions of each new step
to the open list  see section       lcfr does somewhat better than dunf gen on both
the trains and tileworld problems  and this is true regardless of the order in which the
preconditions were added to the open list  but the extent to which it does better varies 
thus  the data is inconclusive about the value of using a least cost strategy for unforced
aws  lcfr clearly benefits from selecting forced aws early  as a side effect of preferring
   

fiflaw selection strategies
    

    

node count   overrun

    

    

    

    

   

 
lcfr

dunf gen

ucpop lc

ucpop

dunf lc

dunf

figure    basic problems  aggregate performance for strategies without forced flaw delay
      

     

nodes generated  log 

ucpop s oc
ucpop lc s oc
dunf s oc
dunf lc s oc
dunf gen s oc

    

dunf gen s oc uc
dunf gen s oc   uc f
lcfr s oc
lcfr s oc uc
lcfr s oc   uc f
   

  
  

   

    

minimum number of nodes generated  log 

figure    tileworld problems  node counts for strategies without forced flaw delay
   

fipollack  joslin    paolucci

     

     

     

     

     

     

    

ucpop
s oc

ucpop lc
s oc

dunf
s oc

dunf lc
s oc

lcfr
s oc

dunf gen
s oc

dunf gen
s oc   uc f

dunf gen
s oc uc

lcfr
s oc   uc f

lcfr
s oc uc

 

figure    tileworld problems  aggregate performance for strategies without forced flaw
delay
   

   

nodes generated

   

   

   

   

   

   

ucpop
s oc

dunf
s oc

dunf gen
s oc   uc f

dunf gen
s oc

ucpop lc
s oc

dunf lc
s oc

lcfr
s oc

lcfr
s oc   uc f

 

figure    trains    node counts for strategies without forced flaw delay
   

fiflaw selection strategies
least cost aws   but it may not matter whether it continues to use a least cost strategy for
the unforced aws  if indeed it is generally sucient to use a least cost strategy only for
forced aws  then zlifo s performance is somewhat less puzzling  since zlifo also prefers
forced aws  however the puzzle is not completely resolved  after all  dunf gen  like
zlifo  prefers forced aws and and then makes lifo based decisions about unforced aws 
and while its performance is not clearly inferior to lcfr s  neither is it clearly superior 
even if the use of lifo for unforced aws does not obviously increase the search space 
neither does it appear to decrease it 

    comparing lcfr and zlifo

we next turn to a direct comparison of lcfr and zlifo  gerevini and schubert compared
these strategies on only a few problems  to get a more complete picture of the performance
of both lcfr and zlifo  we ran them both on all the problems from our three problem
sets 
the data for the basic problem set is shown in figure    we have sorted the problems
by the difference between the node counts produced by lcfr and zlifo  thus  problems
near the left hand side of the graph are those for which lcfr generated a smaller search
space  while problems near the right hand side are the ones on which zlifo had a space
advantage  we omit problems which neither strategy could solve 
as can be seen  on some problems  notably r test   move boxes  and monkey test   
lcfr generates a much smaller search space than zlifo  while on other problems  notably
get paid   hanoi  uget paid   and uget paid    zlifo generates a much smaller search
space  these are problems on which lcfr also did worse than the strategies mentioned
above in section     
as we noted earlier  one of the major changes between ucpop v   and v   is that
v   puts the elements of a new set of open conditions onto the aw list in the reverse
order from that of v    this ordering may make a difference  particularly for lifo based
strategies  indeed  other researchers have suggested that one reason a lifo based strategy
may perform well is because it can exploit the decisions made by the system designers in
writing the domain operators  since it is in some sense natural to list the most constraining
preconditions of an operator first  williamson   hanks         we therefore also collected
data for a modified version of ucpop  in which the preconditions for each step are entered
onto the open condition in the reverse of the order in which they would normally be entered 
we discuss the results of this modification in more detail in the next two sections  but for
now  we simply present the node counts for lcfr and zlifo with the reversed precondition
insertion  in figure    as can be seen  there are a few problems on which reversing the
precondition ordering has a significant effect  notably fixb and monkeytest    but by and
large lcfr and zlifo showed the same relative performance 
for the problems in the basic set  it is dicult to discern an obvious pattern of performance  in contrast to what gerevini and schubert suggest  there does not seem to be a clear
correlation between the diculty of the problem  measured in terms of nodes generated 
and the relative performance of lcfr and zlifo   in fact  it is a little dicult to determine which strategy s node count should serve as the measure of diculty   on the other
hand  it is true that in the aggregate  zlifo generates smaller search spaces than lcfr
   

fir test 

   

uget paid 

uget paid 

monkey test 

hanoi

get paid 

get paid 

get paid 

uget paid 

uget paid

road test

fix 

fix 

get paid

fixa

r test 

fix 

test ferry

monkey test 

fix 

suss anom

two inv 

fix 

rat insulin

prodigy suss

two inv 

fixb

move boxes

nodes generated  log 

r test 

uget paid 

uget paid 

hanoi

get paid 

get paid 

test ferry

get paid 

uget paid 

ho demo

tow inv 

uget paid

tow inv 

road test

fix 

fix 

get paid

r test 

suss anom

fix 

fix 

fix 

monkey test 

prodigy suss

rat insulin

fixa

monkey test 

move boxes

nodes generated  log 

pollack  joslin    paolucci

     

    

   
lcfr  default

zlifo  default

  

 

figure    basic problems  node counts for lcfr and zlifo

     

    

   
zlifo reversed

lcfr reversed

  

 

figure    basic problems  node counts for lcfr and zlifo with reversed precondition
insertion

fiflaw selection strategies
on the basic problems  with the default precondition ordering  zlifo obtains an average
  overrun of         while lcfr obtains         with reverse ordering  zlifo s average
  overrun is         while lcfr s is         the fact that lcfr s relative performance is
worse when the preconditions are entered in the reverse direction results primarily from its
failure on monkeytest  in the reverse direction 
the trains data is scant  neither lcfr nor zlifo can solve the hardest problem 
trains   regardless of whether the preconditions are entered in the default or the reverse
order   in fact  none of the strategies we studied were able to solve trains    but  at least
when the preconditions are entered in the default order  zlifo can solve trains   and
lcfr cannot  with reverse precondition insertion  neither strategy can solve trains   the
data are shown in figure    note that lcfr s performance is essentially the same for both
node selection strategies shown 
finally  the tileworld data  for the default order of precondition insertion  is shown in
figure     here is the only place in which lcfr clearly generates smaller search spaces
than zlifo  we have not also plotted the data for reverse precondition insertion  because
most of the strategies are not affected by this change  there is however  one very notable
exception  with reversed insertion  zlifo  with s   oc     uc   f   does much better 
indeed  it does as well as lcfr  we return to the inuence of precondition ordering on the
tileworld problems in section     
for now  however  it is enough to observe that our experiments show that zlifo does
tend to generate smaller search spaces than lcfr  it does so on the basic problem set 
regardless of the order of precondition insertion  it does so on trains for one ordering  and
does no worse than lcfr on the other ordering   and it does as well as lcfr for the
tileworld problems when the preconditions are inserted in the reverse order  the only
exception is the tileworld problem set when the preconditions are inserted in default order 
there lcfr does better 

    the value of separable threat delay

our first two analyses were essentially aimed at replicating earlier results from the literature 
namely the lcfr results and the zlifo results  we next address the question of how to
square these results with one another 
recall that lcfr and zlifo differ in two key respects  first  lcfr treats all aws
uniformly  while zlifo distinguishes among aw types  giving highest preference to nonseparable threats  medium preference to open conditions  and lowest preference to separable
threats  second  while lcfr uniformly makes least cost selections  zlifo uses a lifo
strategy secondary to its aw type preferences  but after giving preference to forced open
conditions   the comparisons made in section     suggest that the use of a lifo strategy
for unforced aws should at best make little difference in search space size  and may possibly lead to to the generation of larger search spaces  on the other hand  the first difference
presents an obvious place to look for a relative advantage for zlifo  after all  what zlifo
is doing is delaying separable threats  and peot and smith demonstrated the effectiveness
of that approach in their dsep strategy 
peot and smith s proof that dsep will never generate a larger search space than ucpop
does not transfer to lcfr  there are planning problems for which lcfr will generate a
   

fipollack  joslin    paolucci

      

nodes generated  log 

     

    
zlifo s oc
zlifo s oc   uc f
lcfr s oc
lcfr s oc   uc f
   

  

 
trains   default 

trains   reverse 

trains   default 

figure    trains problems  node counts for lcfr and zlifo
      

nodes generated  log 

     

zlifo s oc

    

zlifo s oc   uc f
lcfr s oc
lcfr s oc uc
lcfr s oc   uc f
   

  

 
tw ez

tw  

tw  

tw  

tw  

tw  

tw  

figure     tileworld problems  node counts for lcfr and zlifo
   

fiflaw selection strategies
smaller search space than dsep  their proof relies on the fact that  in dsep  open conditions
will be selected in the same order  regardless of when threats are selected  but the selection
of a threat in lcfr can inuence the repair cost of an open condition  e g   by promoting
an action so that it is no longer available as a potential establisher for some condition   and
this in turn can affect the order in which the remaining open conditions are selected 
nonetheless  despite the fact that one can t guarantee that delaying separable threats
will lead to a reduction in search space size  the motivation behind dsep is still appealing 
separable threats may often simply disappear during subsequent planning  which will naturally lead to a reduction in search space size  for this reason  we implemented a slightly
modified version of lcfr  which we called lcfr dsep  in which separable threats are
delayed  note that it is relatively easy to do this in the ucpop system  which provides
a switch  the dsep switch  which when turned on will automatically delay the repair of all
separable threats  as defined earlier in table    the definition of lcfr dsep is 
lcfr dsep fn oglc   fsglc
our hypothesis was that if zlifo s reduction in search space size were largely due to its
incorporating a dsep approach  then lcfr dsep ought to be  the best of both worlds  
combining the advantages of lcfr s least cost approach with the advantages of a dsep
approach 
on the basic problems  lcfr dsep proved to have the smallest average node count  overrun of on the basic problems of all of the strategies tested  moreover  this was true even
when we reversed the order in which the preconditions of an operator were added to the open
list  figure    gives the average node count   overruns for both the unmodified ucpop v  
 labeled  default   and the modified version in which we reversed the precondition ordering
 labeled  reverse    reversing the ordering does not effect the conclusion that lcfr dsep
generates the smallest search spaces for these problems  in fact  in general it had very little
affect on the relative performance of the strategies at all  the only notable exception  which
we mentioned earlier  is that the relative performance of lcfr and dunf gen ips 
for more detailed comparison  we plot node counts on the basic problems for lcfr 
zlifo  and the separable threat delay strategies in figure     for ease of comparison  we
again show the data sorted by the difference between lcfr and zlifo s node counts  the
problems near the left hand side of the graph are  again  those for which lcfr generated
a smaller search space than zlifo  the problems near the right are those for which it
generated a larger search space  as can be seen  lcfr dsep nearly always does as well
as  or better than lcfr  it does much better than zlifo on the problems that lcfr is
good at  and it also does much better than lcfr on the problems that zlifo is good at 
however  zlifo still outperforms lcfr dsep on this latter class of problems 
another view of the data is given in figure     the log log scatter plot for the basic
problems  for all the strategies we studied  this time we have highlighted lcfr dsep s
performance  although there are some problems for which it does not produce a minimal
search space  its performance on the individual problems is actually quite good  consistent
with its good aggregate performance 
at least for the basic problems  augmenting the simple lcfr strategy with a delay of
separable threats reduces the search space as expected  this in turn suggests that when
lcfr generates a larger search space than zlifo  that is due in large part to the fact that
   

fipollack  joslin    paolucci

    

    

node count   overrun

    

    

default

    

reverse

    

    

   

 
lcfrdsep

dseplc

zlifo

dsep

lcfr

dunfgen

uc
pop lc

ucpop

dunflc

dunf

figure     basic problems  aggregate performance for all strategies

     

nodes generated  log 

    

zlifo
   

lcfr
lcfr dsep

  

uget paid 

hanoi

uget paid 

get paid 

get paid 

get paid 

test ferry

ho demo

uget paid 

tow inv 

tow inv 

uget paid

road test

fix 

prodigy p  

r test 

fix 

get paid

fix 

suss anom

fix 

fix 

prodigy suss

monkey test 

fixa

rat insulin

move boxes

monkey test 

r test 

 

figure     basic problems  node counts for lcfr  zlifo  and dsep strategies
   

fiflaw selection strategies
     

    
nodes generated  log 

ucpop
dsep
dunf
ucpop lc
dunf lc
zlifo
dunf gen
lcfr
dsep lc

   

lcfr dsep

  
  

   

    

     

minimum number of nodes generated  log 

figure     basic problems  node counts for all strategies
it does not delay separable threats  zlifo s primary advantage relative to lcfr seems
not to be its use of a lifo strategy for unforced threats  but rather its separable threat
delay component  combining separable threat delay with a least cost approach yields a
strategy that tends to generate smaller search spaces than either strategy by itself for the
basic problem set  however  analysis of the trains and tileworld problem sets reveals the
situation to be a little more complicated than the comparison of the basic problems would
suggest  as we discuss in the next section 

    the need for domain information

the tileworld and trains domains problems challenge overly simple conclusions we might
draw from the basic problem sets  we consider each set of problems in turn 
      the tileworld problems

the tileworld domain involves a grid with tiles and holes  and the goal is to fill each hole
with a tile  this goal can be achieved with a fill operator  which has two preconditions 
the agent must be at the hole  and it must be holding a tile  in our encoding  an agent can
hold up to four tiles at a time  the go operator is used to achieve the  sub goal of being
at a hole  while the pickup operator is used to achieve the  sub goal of holding a tile  in
the normal way  go has a precondition of being at some location  namely whatever location
the agent will move from  pickup has a precondition of being at the location of some tile 
the problems in the tileworld problem set differ from one another in the number of holes
that the agent must fill  each problem adds another hole 
   

fipollack  joslin    paolucci
      

lcfr s oc uc
     

lcfr s oc   uc f
dunf gen s oc uc

nodes generated  log 

dunf gen s oc   uc f
dunf gen s oc
lcfr s oc
lcfr dsep s oc uc
zlifo s oc   uc f

    

zlifo s oc
lcfr dsep s oc   uc f
dsep lc s oc
lcfr dsep s oc
dunf s oc
dsep s oc
   

ucpop lc s oc
dunf lc s oc
ucpop s oc

  
  

   

    

minimum number of nodes generated  log 

figure     tileworld problems  node counts for all strategies
figures    gives the log log plot for the various strategies on the tileworld problems 
when the preconditions were entered in the default order  note that lcfr  s   oc   uc  
is the strategy highlighted  three other strategies were almost indistinguishable from lcfr
 s   oc   uc    namely  lcfr  s   oc     uc   f    dunf gen  s   oc   uc   and
dunf gen s   oc     uc   f    all the other strategies performed worse  this can more
easily be seen in figure     which gives the aggregate performance for the leading strategies 
those that were able to solve all seven tileworld problems  in fact  these leading strategies
were able to solve the seven tileworld problems without generating more than      nodes
for any problem  in contrast  the remaining strategies failed on at least one  and up to four 
of the seven problems  given the limit of         nodes generated 
what was originally surprising to us is that on the tileworld problems  delaying separable threats actually seems to hurt performance  the strategies that did best were those like
lcfr and dunf gen that do not delay separable threats  lcfr dsep  zlifo  dsep lc 
and dsep all generated larger search spaces  in contrast to what we would have predicted
given the experiments on the basic problem set 
to understand this result  we looked in detail at the planning trace for these problems 
what that revealed is that for the tileworld domain  the early resolution of separable threats
has an important advantage  it imposes what turns out to be the correct temporal ordering
between the steps of going to up a tile  to pick it up   and carrying it to a hole  virtually
all the strategies create subplans like the one shown in figure     the goals involve filling
holes  so the planners insert steps to go to and pick up a tile  and to go to the hole  at this
point  there are two separable threats      the effect of going to the hole   at x    threatens
the link between going to the tile and picking it up  at z     and     the effect of going to
   

fiflaw selection strategies
   

  

  

node count   overrun

  

  

  

  

  

  

  

 
lcfr
s oc uc

lcfr
s oc   uc f

dunf gen
s oc uc

dunf gen
s oc   uc f

dunf gen
s oc

figure     tileworld problems  aggregate performance for leading strategies

at x 

go x y 

at y 
loc h y 
holding t 

 at w 
at w 

go w z 

at z 
tile t 
loc t z 

 at x 

fill h 

filled h 

pickup t 

figure     typical partial plan for the tileworld domain
the tile   at w    threatens the link between going to the hole and filling it  at y     both
threats are separable  because x and w will be unbound  the planner does not yet know
where it will be traveling from  but there is only one valid temporal ordering that will
resolve these threats  going to the tile must precede picking up the tile  which in turn must
precede going to the hole  once this temporal ordering is determined  further planning goes
smoothly 
in contrast  if this ordering decision is not made  the planner can often  get lost  
attempting to find plans in which it goes from some location to the hole and then from the
hole to the tile  there are many ways to attempt this  because there are many different
   

fipollack  joslin    paolucci
      

lcfr dsep s oc   uc f
     

zlifo s oc   uc f
lcfr s oc uc

nodes generated  log 

lcfr s oc   uc f
dunf gen s oc   uc f
lcfr dsep s oc uc
dunf gen s oc
dunf gen s oc uc

    

dunf lc s oc
lcfr dsep s oc
dsep lc s oc
lcfr s oc
zlifo s oc
ucpop lc s oc
   

dunf s oc
dsep s oc
ucpop s oc

  
  

   

    

minimum number of nodes generated  log 

figure     tileworld problems  node counts with reversed precondition insertion
tiles to select  and many different locations to move among  the planner may try many
of these alternatives before determining that there is a fundamental inconsistency in these
plans  and that they are destined to fail  the larger the number of holes to be filled  the
worse the situation becomes 
sometimes the planner may make the right decision about temporal ordering even if it
has deferred separable threats  when faced with the partial plan in figure     if the planner
does not select a threat  it will select from among several open conditions  it can attempt
to establish the precondition of going to the hole  at x    by reusing the effect of going to
the tile  at z     or it can do the reverse  and attempt to establish the precondition of going
to the tile  at w    by reusing the effect of going to the hole  at x     of course  the first
solution is the right one  and includes the critical temporal ordering constraint  while the
second will eventually fail 
the order in which the open conditions are selected will determine which of these two
choices the planner makes  when preconditions are entered in the default order  planners
that delay separable threats end up making the latter  problematic choice  in contrast 
when the preconditions are entered in the reverse order  the planners make what turns
out to be the correct choice  thus  for the experiments in which we reversed precondition
insertion  we see a different pattern of performance  as shown in figures        
when the preconditions are entered in the reverse order  a larger number of strategies
perform well  solving all the problems  in particular  with s   oc     uc   f node   to preserve readability  in figure     we have used       to denote s   oc         for s   oc   u c  
and       for s   oc   u c     f  

   

fi   
ucpop    

dunf    

dsep    

ucpop lc    

lcfr    

zlifo    

dsep lc    

lcfr dsep    

dunf lc   

dunf gen    

dunf gen    

lcfr dsep    

dunf gen    

lcfr    

lcfr    

zlifo    

lcfr dsep    

node count   overrun

flaw selection strategies

     

     

     

     

     

     

     

     

     

    

 

figure     tileworld problems  aggregate performance for all strategies with reversed
precondition insertion

fipollack  joslin    paolucci
     

     

     
trains 
trains 
     

    

dsep lc
s oc

lcfr dsep
s oc

lcfr dsep
s oc   uc f

zlifo
s oc   uc f

dunf
s oc

lcfr dsep
s oc uc

zlifo
s oc

dsep
s oc

 

figure     trains problems  node counts
selection  the performance of lcfr  dunf gen  zlifo  and lcfr dsep is virtually indistinguishable  it is important to note that the leading strategies that do not delay separable
threats lcfr and dunf gen are not affected much by the reversal of precondition insertion for the tileworld problems  in fact  lcfr s performance is identical in both cases 
in contrast  the strategies that use separable threat delay lcfr dsep  zlifo  and dseplc all perform much better when we reverse precondition insertion  this is explained by
our analysis above 
in sum  what is most important for the tileworld domain is for the planner to recognize 
as early as possible  that there are certain required temporal orderings between some of the
steps in any successful plan  every successful plan will involve going to a tile before going
to a hole  although there is exibility in the order in which multiple holes are visited  and
in the interleaving of picking up tiles and dropping them in holes  for the strategies we
studied  there were two different methods that led to this temporal constraint being added
to the plan  it was added when the planner selected a separable threat to resolve  and it
was added when it selected one particular precondition to resolve before another 
      the trains and get paid problems

the trains domain present a somewhat different variation on our original conclusions  the
trains domain involves a set of locations and objects  and the goal is to transport various
objects from specific starting locations to specified destinations  gerevini and schubert
studied three trains problems  all of our strategies failed to successfully complete the
hardest of these  trains   within either the         node or the      second limit  moreover 
many of them also failed on the second hardest  trains    caution must therefore be taken
in interpreting the results  as there are a limited number of data points 
   

fiflaw selection strategies
figure    gives the node counts for the trains domain  with preconditions inserted in the
default order  we only show the strategies that were able to solve both trains  and trains  
these results are closer to what we would have predicted from the basic problem set than
were the results with the tileworld  in particular  lcfr dsep does very well  generating
much smaller search spaces than lcfr  however  it does slightly worse than zlifo 
recall that we saw the same pattern of performance on a subset of the basic problems 
specifically on the get paid uget paid problems  there  lcfr dsep again improved on
lcfr  but did not generate as small search spaces as zlifo  it turns out that there are
similar factors inuencing both sets of problems  and it is instructive to consider in some
detail the planning done by zlifo and lcfr dsep for the get paid uget paid problems
to understand what is occurring 
like the trains domain problems  the get paid uget paid problems involve moving
particular objects to specified locations  in the get paid uget paid domain there are three
objects  a paycheck  a dictionary  and a briefcase  as generally formulated  in the initial
state all three are at home  and the paycheck is in the briefcase  the goal is to deposit
the paycheck at the bank  bring the dictionary to work  and have the briefcase at home 
both the dictionary and the paycheck can be moved only in the briefcase  for a human 
the solution to this problem is obvious  the dictionary must be put into the briefcase  and
it must then be carried to work  where the dictionary is taken out  the briefcase must then
be carried home  in addition  a stop must be made at the bank  either on the way to work
or on the way home  at which point the paycheck must be taken out of the briefcase and
deposited 
zlifo and lcfr dsep take different paths in solving this problem  zlifo begins by
forming plans to get the paycheck to the bank and the dictionary to work  these goals
are selected first because they are forced  there is only one way to get the paycheck to the
bank  carry it there   and similarly only one way to get the dictionary to the oce  carry
it there   in contrast  there are two possible ways to get the briefcase home  either by
leaving it there  i e   reusing the initial state  or by carrying it there from somewhere else
 i e   adding a new step   the lifo mechanism then proceeds to complete the plans for
achieving the goals of getting the paycheck to the bank and the dictionary to work  before
beginning to work on the remaining goal  of getting the briefcase home  at this point  that
goal is easy to solve  all that is needed is to plan a route home from wherever the briefcase
is at the end of these two errands 
lcfr dsep  like zlifo  begins by selecting the forced goals of getting the dictionary
to the oce and getting the paycheck to the bank  however  instead of next completing
the plans for these goals  lcfr dsep continues to greedily select least cost aws  and thus
begins to work on achieving the goal of getting the briefcase home  unfortunately  at this
point it is not clear where the briefcase needs to be moved home from  and hence lcfrdsep begins to engage in a lengthy process of  guessing  where the briefcase will be at the
end of the other tasks  before it has planned for those tasks   
    the diculty that lcfr dsep encounters by greedily picking low cost aws might be reduced by doing
a lookahead of several planning steps  to determine a more accurate repair cost  this is the approach
taken in the branch n mechanism in o plan  currie   tate         significant overhead can be involved
in such a strategy  however 

   

fipollack  joslin    paolucci
the key decision for the get paid uget paid domain and  as it turns out  for the trains
domain is related to  but subtly different from the key decision in the tileworld domain 
for get paid uget paid and trains  the key insight for the planner is again that there is
an important temporal ordering between goals  the goal of getting the briefcase home is
going to have to be achieved after the goal of taking the dictionary to work  however 
recognition of this constraint is not affected by separable threat delay  as it was for the
tileworld  instead  what happens in these domains is that a higher cost aw interacts with
a lower cost one  causing the latter to become fully constrained 
it is tempting to think that here finally is a case in which a lifo based strategy is
advantageous  after all  for this example  by completely determining what you will do to
achieve one goal  you make it much easier to know how to solve the another goal  but the use
of zlifo  or an alternative lifo based strategy  does not guarantee that the interactions
between high  and lower cost aws will be exploited  in particular if the interactions are
among two or more unforced aws  then the order of the goals in the agenda can lead zlifo
to make an inecient choice  thus  when we modified the problem so that the briefcase was
at work in the initial state  zlifo and lcfr dsep both solved the problem very quickly
     nodes for zlifo and     for lcfr dsep   note that this modification removes the
problematic interaction between a low cost and a high cost aw 
finally  note that the effectiveness of the lifo strategies is again heavily dependent
on the the order in which preconditions are entered onto the open list  figure    gives
the node counts for the trains domain with reverse precondition insertion  we once again
plot only the strategies that can solve both trains   and trains   in this case  there are
only two such strategies  lcfr dsep and dsep lc  the strategies that rely on lifo for
open condition selection  zlifo  dsep  dunf gen  and ucpop  all do significantly worse
than they did when the preconditions were in the correct order  to the extent that lifo
helps in such domains  it appears to be because of its ability to exploit the decisions made
by the system designers in writing the domain operators  as suggested by williamson and
hanks        

    computation time
we have now covered the key questions we set out to address  what are the relative effects
of alternative search control strategies on search space size  and  in particular  how can
we reconcile the apparently conicting approaches of lcfr and zlifo  we concluded
that lcfr dsep combines the main advantages for reducing search space size of these two
strategies  namely lcfr s use of a least cost selection mechanism  at least for forced aws 
with zlifo s use of separable threat delay  a final question concerns the price one has to
pay to use lcfr dsep or for that matter  any of the alternative strategies  to achieve a
reduction in search space size  is it necessary to spend vastly more time in processing  or
do these strategies pay for themselves 
to answer these questions  we collected timing data on all our experiments  figures   
and    gives this data for the basic problems  for both the experiments run with the node
limit and those run with the time limit   as detailed in appendix a  the results for the
experiments with the node limit and the time limit were very similar   because we saw
little inuence of precondition ordering on the basic problems  we analyze only the data for
   

fiflaw selection strategies
     

     

     

trains 

     

trains 

     

    

 
lcfr dsep
s oc uc

lcfr dsep
s oc   uc f

lcfr dsep
s oc

dsep lc
s oc

figure     trains problems  node counts with reversed precondition insertion
   

   

computation time   overrun

   

   
time limit
node limit
   

   

  

 
dsep lc

zlifo

lcfr dsep

dsep

figure     basic problems  aggregate computation time performance for leading strategies
the default precondition ordering  we show one graph with all the strategies  and another
that includes only the  leading strategies   to make it possible to see the distinctions among
them 
   

fipollack  joslin    paolucci
     

computation time   overrun

     

     

time limit

     

node limit

     

    

 
dseplc

zlifo

lcfrdsep

dsep

ucpop

uc
pop lc

dunfgen

lcfr

dunflc

dunf

figure     basic problems  aggregate computation time performance
the timing data show that lcfr dsep does  by and large  pay for its own overhead
on the basic problems by generating smaller search spaces  and therefore having to process
fewer nodes   when run with a time limit  lcfr dsep s time performance is almost
identical with zlifo s  despite the fact that repair cost computations are more expensive
than the stack popping of a lifo strategy  when run with a node limit  lcfr dsep does
show worse time performance than zlifo in aggregate  but still performs markedly better
than most of the other strategies  the change in relative performance results from the cases
in which both strategies fail at the node limit  lcfr dsep takes longer to generate       
nodes 
another interesting observation is that dsep lc has the best time performance of all
on the basic problem set  this should perhaps not be a surprise  because dsep lc closely
approximates lcfr dsep  it differs primarily in its preference for nonseparable threats 
which in any case will tend to have low repair costs  whenever a node includes a nonseparable threat  dsep lc can quickly select that threat  without having to compute repair
costs  this speed advantage outweighs the cost of processing the extra nodes it sometimes
generates 
figures       provide the timing data for the trains and tileworld domains    here
there are no real surprises  the computation times taken parallel quite closely the size
of the search spaces generated  the strategies that generate the smallest search spaces
are also the fastest  with the trains problems  we again see the dsep lc can serve as
    we have omitted the strategies that did very poorly  performing worse both on the node  and time limit
experiments than did any of the strategies graphed  note that we ran the reverse order experiments only
with a node limit 

   

fiflaw selection strategies
    

    

computation time   overrun

    

    
default node limit
default time limit
    

    

    

 
lcfr
   

dunfgen
   

lcfr
   

dunfgen
   

dunfgen
   

zlifo
   

lcfr
   

zlifo
   

lcfrdsep
   

lcfrdsep
   

dsep
   

figure     tileworld problems  aggregate computation time performance for leading
strategies
a good approximation technique for lcfr dsep  although it generates more nodes than
lcfr dsep  it is somewhat faster   

   conclusion
in this paper  we have synthesized much of the previous work on aw selection for partialorder causal link planning  showing how earlier studies relate to one another  and have
developed a concise notation for describing alternative aw selection strategies 
we also presented the results of a series of experiments aimed at clarifying the effects
of alternative search control preferences on search space size  in particular  we aimed at
explaining the comparative performance of the lcfr and zlifo strategies  we showed
that neither of these aw selection strategies consistently generates smaller search spaces 
but that by combining lcfr s least cost approach with the delay of separable threats
that is included in the zlifo strategy  we obtain a strategy lcfr dsep whose space
performance was nearly always as good as the better of lcfr or zlifo on a given problem 
we therefore concluded that much of zlifo s advantage relative to lcfr is due to its delay
of separable threats rather than to its use of a lifo strategy  although we were unable
to resolve the question of whether least cost selection is required for unforced  as well as
forced aws  we found no evidence that a lifo strategy for unforced aws was better  on
the other hand  separable threat delay is clearly advantageous  an open question is exactly
why it is so advantageous  we have conducted preliminary experiments that suggest that
    in interpreting the trains timing data  it is important to note that some of the strategies shown notably
ucpop  ucpop lc  and dunf  failed to solve trains  within either the node or the time limit 

   

fipollack  joslin    paolucci
   

   

computation time   overrun

   

   

   

   

   

   

   

s oc uc
dunf gen

s oc
dunf gen

s oc
lcfr dsep

s oc
dunf lc

s oc
dsep lc

s oc   uc f
dunf gen

s oc   uc f
lcfr

s oc uc
lcfr

s oc   uc f
lcfr dsep

s oc   uc f
zlifo

s oc uc
lcfr dsep

 

figure     tileworld problems  aggregate computation time performance for leading
strategies with reversed precondition insertion
    

computation time   overrun

    

    
default   node limit
default time limit
    

   

s oc
ucpop

s oc
lcfr dsep

s oc uc
lcfr dsep

s oc   uc f
lcfr dsep

s oc
dsep lc

s oc   uc f
zlifo

s oc
zlifo

s oc
dunf

s oc
dsep

 

figure     trains problems  aggregate computation time performance for leading strategies
   

fiflaw selection strategies

    
    

computation time   overrun

    
    
    
    
   
   
   
   

s oc
dsep

s oc   uc f
zlifo

s oc
zlifo

s oc uc
lcfr dsep

s oc   uc f
lcfr

s oc
dunf lc

s oc
lcfr

s oc
ucpop lc

s oc
lcfr dsep

s oc   uc f
lcfr dsep

s oc
dsep lc

 

figure     trains problems  aggregate computation time performance for leading strategies with reversed precondition insertion

   

fipollack  joslin    paolucci
much of the search space reduction that results from delaying separable threats can also be
achieved by making separation systematic  something that ucpop v   does not do 
we also considered the question of computation time  and showed that often lcfr dsep
only requires computation time comparable to that of zlifo  lcfr dsep can therefore be
seen as paying for its own computational overhead by its search space reduction  moreover 
peot and smith s dsep lc provides a good approximation of lcfr dsep  although it
produces somewhat larger search spaces  it does so more quickly 
these conclusions  however  are tempered by the fact that for certain clusters of problems  our combined strategy  lcfr dsep  does not generate minimal search spaces  as
we saw  for the tileworld problems  what is most important is to recognize the need for
a particular temporal ordering among plan steps  and this recognition can be obtained by
resolving separable threats early  for the trains and get paid uget paid domains  what
matters most is recognizing that a particular effect can in fact only be achieved in one
way  and this is only recognized when a particular aw is selected a aw which happens
generally not to be the least cost aw available  the lesson to be learned from these sets of
problems is that although we now understand the reasons that lcfr and zlifo perform
the way they do  and how to combine the best features of both to create good default strategies for pocl planning  it is clear that domain dependent characteristics such as those we
identified in the trains and tileworld domains must still be taken into account in settling
on a aw selection strategy for any domain 

acknowledgments
martha pollack s work on this project has been supported by the air force oce of scientific
research  f                 and an nsf young investigator s award  iri           david
joslin has been supported by rome labs  rl arpa  f                 and an nsf cise
postdoctoral research award  cda           massimo paolucci has been supported by the
oce of naval research  cognitive and neural sciences division  n         j       
we are very grateful to alfonso gerevini for providing us with the code he used in his
earlier study  and allowing us to use it in our experiments  we would also like to thank
arthur nunes and yazmine deleon  who assisted us in carrying out experiments done in
the preliminary stages of this work  finally  we thank alfonso gerevini  len schubert 
michael wellman  and the anonymous reviewers for their helpful comments on this work 

appendix a  ruling out ceiling effects
for the data collected using a node limit  we examined all the problems in which at least
one of the strategies hit the node limit  table    gives the second worst node count for
all such problems  it shows that  for all the basic problems in which at least one strategy
failed  and at least one other succeeded  the second worst strategy generally created fewer
than      nodes 
similarly  for the trains and tileworld problems  in all such cases except tw   the
second worst strategy took fewer than        nodes  and in tw  it took          recall
that the node limit for the basic problems was        nodes  while for the trains and
tileworld problems it was         nodes  it is thus clear that the strategies that hit the
   

fiflaw selection strategies
problem
hanoi
r test 
monkey test 
monkey test 
get paid 
get paid 
get paid 
fixit
ho demo
fixb
uget paid 
uget paid 
uget paid 
prodigy p  
move boxes
move boxes  

default

reverse
    
    
    
     
   
    
    
     

trains 
trains 
tw  
tw  
tw  
tw  
tw  

     
   
    
    
    
    
     

    
    
    
     
   
    
    
     
     
    
   
    
    
    
    
     

     
      

     
      

     
    
     
    

     
   
    
     
    

figure     second worst node counts on problems with failing strategies
node limit are doing substantially worse than the strategies that succeed  even if they were
to succeed by increasing the node limit slightly  their comparative performance would still
be poor 
thus  by using the node limits we imposed  we are not making any strategies look worse
than they actually are  on the other hand  in computing   overrun  we may be making
some strategies look better than they actually are  because we use a value of         or
         nodes generated when a strategy hits the limit  and the actual number of nodes it
might take  if run to completion  could be significantly higher  this is why  in our analyses 
we considered both the absolute performance of strategies on individual problems  and their
aggregate performance  as measured by average   overrun 
we also compared the experiments that were run with a time limit and those that were
run with a node limit  for the basic problem set  the time limit of     seconds was high
enough that  in most cases  strategies could compute significantly more nodes than they
   

fipollack  joslin    paolucci
could with the node cutoff  nonetheless  the results were almost identical  in nearly all
cases  if a strategy failed with the node cutoff  it also failed with the time limit cutoff  there
were only four exceptions to this 
   hanoi  with the        nodes limit  dsep fails  while with the     second time limit 
it succeeds  taking        nodes 
   uget paid   with the        node limit  ucpop lc fails  while with the     second
time limit  it succeeds  taking        nodes 
   uget paid   with the        node limit  ucpop lc fails  while with     second
time limit  it succeeds  taking        nodes 
   fixit  with the        nodes limit  dsep lc  ucpop lc  and zlifo fail  while
with the     second time limit  they succeed in                 and        nodes
respectively  all the other strategies fail to solve this problem under either limit 
there was a similarly strong correspondence between the results we obtained on the
trains and tileworld problems using a node limit and a time limit  in a few cases  a
strategy that was able to succeed within the         node limit was not able to succeed
within the       second time limit  the nature of these problems is that the computation
time per node can be very great  specifically 
   on tw   dunf succeeded in        nodes when run with a node limit  but failed
with the       second time limit 
   on tw   lcfr dsep  with an s oc node selection strategy  succeeded in       
nodes  but failed on the time limit 
   on tw   lcfr dsep  with an s oc uc node selection strategy  succeeded in
        but failed on the limit 
   on tw   lcfr  with an s oc node selection strategy  succeeded in       nodes 
but failed with the time limit 
in only one case did a strategy fail under the node limit but succeed within the time limit 
   on tw   dsep  with an s oc node selection strategy  failed with a         node
limit  but succeeded with         nodes using a     second time limit  note that
this is significantly worse than the second worst strategy  which solved this problem
generating        nodes 
given this close correspondence between the experiments with node and time limits  we
collected only node limit data for the experiments in which we reversed the precondition
insertion 

   

fiflaw selection strategies

references

allen  j  f   schubert  l  k   ferguson  g  m   heeman  p  a   hwant  c  h   kato  t   light 
m   margin  n  g   miller  b  w   poesio  m     traum  b  r          the trains
project  a case study in building a conversational planning agent  experimental and
theoretical artificial intelligence          
chapman  d          planning for conjunctive goals  artificial intelligence                  
currie  k     tate  a          o plan  the open planning architecture  artificial intelligence            
etzioni  o   hanks  s   weld  d   draper  d   lesh  n     williamson  m          an
approach to planning with incomplete information  in proceedings of the third international conference on principles of knowledge representation and reasoning  pp 
        
gerevini  a          personal communication 
gerevini  a     schubert  l          accelerating partial order planners  some techniques
for effective search control and pruning  journal of artificial intelligence research    
       
joslin  d          passive and active decision postponement in plan generation  ph d 
thesis  intelligent systems program  university of pittsburgh 
joslin  d     pollack  m  e          least cost aw repair  a plan refinement strategy for
partial order planning  in proceedings of the twelfth national conference on artificial
intelligence  aaai   pp            seattle  wa 
joslin  d     pollack  m  e          is  early commitment  in plan generation ever a good
idea   in proceedings of the thirteenth national conference on artificial intelligence
 aaai   pp            portland  or 
kambhampati  s   knoblock  c  a     yang  q          planning as refinement search  a
unified framework for evaluating design tradeoffs in partial order planning  artificial
intelligence                    
kumar  v          algorithms for constraint satisfaction problems  a survey  ai magazine 
              
mcallester  d     rosenblitt  d          systematic nonlinear planning  in proceedings of
the ninth national conference on artificial intelligence  pp          anaheim  ca 
pednault  e  p  d          synthesizing plans that contain actions with context dependent
effects  computational intelligence                 
penberthy  j  s     weld  d          ucpop  a sound  complete  partial order planner for
adl  in proceedings of the third international conference on knowledge representation and reasoning  pp          cambridge  ma 
   

fipollack  joslin    paolucci
peot  m     smith  d  e          conditional nonlinear planning  in proceedings of the first
international conference on ai planning systems  aips      pp          college
park  md 
peot  m     smith  d  e          threat removal strategies for partial order planning  in
proceedings of the eleventh national conference on artificial intelligence  pp         
washington  d c 
pollack  m  e     ringuette  m          introducing the tileworld  experimentally evaluating agent architectures  in proceedings of the eighth national conference on artificial
intelligence  pp          boston  ma 
russell  s     norvig  p          artificial intelligence  a modern approach  prentice hall 
englewood cliffs  nj 
russell  s  j          ecient memory bounded search algorithms  in proceedings of the
tenth european conference on artificial intelligence  pp      
smith  d  e     peot  m  a          a note on the dmin strategy  unpublished manuscript 
srinivasan  r     howe  a  e          comparison of methods for improving search eciency
in a partial order planner  in proceedings of the   th international joint conference
on artificial intelligence  pp            
tate  a   drabble  b     dalton  j          reasoning with constraints within o plan  
tech  rep  arpa rl o plan  tp   v     aiai  edinburgh 
tsang  e          foundations of constraint satisfaction  academic press 
tsuneto  r   erol  k   hendler  j     nau  d          commitment strategies in hierarchical task network planning  in proceedings of the thirteenth national conference on
artificial intelligence  aaai   pp          portland  or 
weld  d  s          an introduction to least commitment planning  ai magazine         
      
wilkins  d  e          practical planning  extending the classical ai paradigm  morgan
kaufmann  san mateo  ca 
wilkins  d  e     desimone  r  v          applying an ai planner to military operations
planning  in fox  m     zweben  m   eds    intelligent scheduling  pp          
morgan kaufmann publishers  san mateo  ca 
williamson  m     hanks  s          flaw selection strategies for value directed planning  in
proceedings of the third international conference on artificial intelligence planning
systems  pp          

   

fi