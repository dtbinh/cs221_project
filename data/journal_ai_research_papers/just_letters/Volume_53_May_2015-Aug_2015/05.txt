journal of artificial intelligence research                  

submitted        published      

autofolio 
an automatically configured algorithm selector
marius lindauer

lindauer cs uni freiburg de

university of freiburg

holger h  hoos

hoos cs ubc ca

university of british columbia

frank hutter

fh cs uni freiburg de

university of freiburg

torsten schaub

torsten cs uni potsdam de

university of potsdam
inria rennes

abstract
algorithm selection  as  techniques  which involve choosing from a set of algorithms
the one expected to solve a given problem instance most efficiently  have substantially
improved the state of the art in solving many prominent ai problems  such as sat  csp 
asp  maxsat and qbf  although several as procedures have been introduced  not too
surprisingly  none of them dominates all others across all as scenarios  furthermore  these
procedures have parameters whose optimal values vary across as scenarios  this holds
specifically for the machine learning techniques that form the core of current as procedures  and for their hyperparameters  therefore  to successfully apply as to new problems 
algorithms and benchmark sets  two questions need to be answered   i  how to select an as
approach and  ii  how to set its parameters effectively  we address both of these problems
simultaneously by using automated algorithm configuration  specifically  we demonstrate
that we can automatically configure claspfolio    which implements a large variety of
different as approaches and their respective parameters in a single  highly parameterized
algorithm framework  our approach  dubbed autofolio  allows researchers and practitioners across a broad range of applications to exploit the combined power of many different
as methods  we demonstrate autofolio can significantly improve the performance of
claspfolio   on   out of the    scenarios from the algorithm selection library  leads
to new state of the art algorithm selectors for   of these scenarios  and matches state ofthe art performance  statistically  on all other scenarios  compared to the best single
algorithm for each as scenario  autofolio achieves average speedup factors between    
and      

   introduction
over the last decade  tremendous progress in boolean constraint solving technology has been
achieved in several areas within ai  such as sat  biere         asp  gebser  kaufmann 
  schaub         csp  tamura  taga  kitagawa    banbara         max sat  abrame
  habet        and qbf  janota  klieber  marques silva    clarke         in all these
areas  multiple algorithms with complementary solving strategies exist  and none dominates all others on all kinds of problem instances  this fact can be exploited by algorithm selection  as   rice        methods  which use characteristics of individual probc
    
ai access foundation  all rights reserved 

filindauer  hoos  hutter    schaub

lem instances  so called instance features  to choose a promising algorithm for each instance  algorithm selectors have empirically been shown to improve the state of the art
for solving heterogeneous instance sets and  as a result  have won many prizes at competitions  for instance  satzilla  xu  hutter  hoos    leyton brown        won several
categories in multiple sat competitions  claspfolio    gebser  kaminski  kaufmann 
schaub  schneider    ziller      b  won the np track of the      asp competition  cphydra  omahony  hebrard  holland  nugent    osullivan        won the the      csp
competition  isac    ansotegui  malitsky    sellmann        won the partial max sat
crafted and industrial track of the      max sat competition  and aqme  pulina  
tacchella        won the first stage of the main track of the      qbf competition 
although many new as approaches have been proposed over the years  cf  smith miles 
      kotthoff         there are only two flexible frameworks that allow for re implementing
and comparing existing approaches in a fair and uniform way  llama  kotthoff       
and claspfolio    hoos  lindauer    schaub         of these  claspfolio   is more
comprehensive  encompassing strategies from the algorithm selection systems  s  kadioglu 
malitsky  sabharwal  samulowitz    sellmann         aspeed  hoos  kaminski  lindauer 
  schaub         claspfolio    gebser et al       b   isac  kadioglu  malitsky  sellmann    tierney         me asp  maratea  pulina    ricca         snnap  collautti 
malitsky  mehta    osullivan        and satzilla  xu et al         xu  hutter  hoos 
  leyton brown        
figure   illustrates the performance benefits these existing selection strategies  as realized in claspfolio    yield across the wide range of as benchmarks in the algorithm selection library  bischl et al       b      a   we observe that each approach has strengths
and weaknesses on different scenarios  the satzilla   like approach  the default of
claspfolio    performs best overall  but only achieves better performance than the other
approaches considered on   out of the    scenarios  with  s  aspeed and isac yielding
better performance in the remaining cases 
we further note that each of the selection approaches used a fixed default parameter
configuration and might therefore fall short of its full performance potential  for example  imputation of missing instance features was not used at all in the approaches considered in figure    while its use does not improve performance on some scenarios  e g  
asp potassco   it yields improvements on others  e g   sat   rand  where the
satzilla   like approach plus mean imputation outperforms the single best algorithm
by a factor of      
generally  it is well known that the performance of many machine learning techniques
depends on hyper parameter settings  e g   in the case of an svm  the kernel  kernel hyperparameter and soft margin  cf  bergstra  bardenet  bengio    kegl        snoek  larochelle 
  adams        thornton  hutter  hoos    leyton brown         however  the hyperparameters of the machine learning models used in figure   were fixed manually  based on
limited experiments  therefore  the performance of some of the algorithm selection systems
we considered could likely be improved by using more carefully chosen hyper parameter
settings 
facing a new algorithm selection problem  we thus have to answer three salient questions   i  which selection approach to use   ii  how to set the parameters of the selection
approach  and its underlying machine learning model  effectively  and  iii  how to make
   

filio
   
  l
isa
ike
c l
ike
me
 as
p l
ike
sa
tzi
lla
   
 lik
sa
e
tzi
lla
   
 lik
au
e
tof
oli
o

cla

sp
fo

d
asp

ee

 s

 lik

e

autofolio  an automatically configured algorithm selector

asp potassco
csp     
maxsat   pms
premarshalling
proteus     
qbf     
sat   hand
sat   indu
sat   rand
sat   all
sat   hand
sat   indu
sat   rand

   
   
   
   
    
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
    
   
   
    
   
   
   
   

geo  mean

   

   

   

   

   

   

   

   

figure    factors by which the selection approach re implemented in claspfolio   outperformed the single best algorithm in the    aslib scenarios w r t  penalized average runtime
 par    which counts each timeout as    times the given runtime cutoff   these results
are for    fold cross validation  ignoring test instances that were not solved by any solver 
the last row shows the geometric mean over all    scenarios 

best use of techniques augmenting pure as  such as pre solving schedules  xu et al        
kadioglu et al          instead of the common  manual trial and error approach  we propose to automatically answer these questions by using automated algorithm configuration
methods  hutter  hoos  leyton brown    stutzle        to configure flexible as frameworks  while the manual approach is error prone  potentially biased and requires substantial human expert time and knowledge  the approach we introduce here is fully automatic 
unbiased  and leverages the full power of a broad range of as methods  it thus facilitates
an easier and more effective use of algorithm selection and makes as techniques accessible
to a broader community 
specifically  we present autofolio  a general approach for automatically determining a
strong algorithm selection method for a particular dataset  by using algorithm configuration
to search through a flexible design space of algorithm selection methods  we also provide an
open source implementation of autofolio  www ml aad org autofolio   based on the
algorithm configurator smac  hutter  hoos    leyton brown        and the algorithm
selection framework claspfolio    hoos et al          the last column of figure   previews
the results obtained with autofolio and clearly shows significant improvements over
claspfolio   on    of the    scenarios in aslib 
   

filindauer  hoos  hutter    schaub

instance

algorithm
portfolio

compute
features

select algorithm

solve instance
with algorithm

figure    general outline of algorithm selection 

   background  algorithm configuration and selection
in this section  we briefly introduce standard approaches to algorithm selection and algorithm configuration that form the basis of our autofolio approach 
    algorithm selection
figure   shows the general outline of algorithm selection  rice         for a given problem
instance  we first compute cheap instance features  these are numerical characteristics 
including simple ones  such as the number of variables or clauses in a sat instance  and
more complex ones  such as statistics gathered from short probing runs of an actual sat
solver on the given instance   based on these features  an appropriate algorithm from an
algorithm portfolio  huberman  lukose    hogg        gomes   selman        is selected
to solve the given instance  the overall workflow is subject to a runtime cutoff 
one major challenge in algorithm selection is to find a good mapping from instance
features to algorithms  in the general offline algorithm selection approach we consider  this
is done based on training data  specifically  given a portfolio of algorithms a and a set of
problem instances i  we use as training data a performance matrix of size  i   a and a
feature matrix containing a fixed size feature vector for each i  i  based on this training
data  we learn a mapping from instance features to algorithms using machine learning
techniques  such as k nn  maratea et al          g means  kadioglu et al         or random
forests  xu et al         
      related work on algorithm selection systems
recent successful algorithm selection systems include satzilla  xu et al         xu  hutter  hoos    leyton brown      a    s  kadioglu et al         malitsky  sabharwal  samulowitz    sellmann            b   isac  kadioglu et al         ansotegui et al         
cshc  malitsky  sabharwal  samulowitz    sellmann      a  and claspfolio    gebser
et al       b   in recent years  these systems showed excellent performance in competitions
for sat  maxsat and asp  we briefly review them in the following 
the original version of the pioneering algorithm selection system satzilla  xu et al  
      learned the mapping from instance features to algorithms by training ridge regression models  each regression model predicts the performance of an algorithm for a given
instance  based on these predicted performances  satzilla selects the algorithm with the
best predicted performance  satzillas latest version  xu et al         uses classification
models that  for each pair of algorithms  predict the better performing one  and selects the
algorithm to be run using simple voting over the predictions thus obtained  these models
are also cost sensitive  that is  each training instance in the pairwise classification models is
   

fiautofolio  an automatically configured algorithm selector

weighted by the performance loss incurred when selecting the worse of the two algorithms 
furthermore  satzilla introduced the concept of pre solving schedules  that is  a short
instance independent schedule of algorithms running for a limited amount of time  if one
algorithm of the pre solving schedule solves the given instance  satzilla can immediately
terminate successfully  saving the time required to compute instance features  furthermore 
pre solving schedules increase the robustness of algorithm selectors by not only relying on
one selected algorithm but also on the pre solvers to solve a given instance  one drawback
of satzilla is its use of grid search over all possible pre solving schedules with up to three
pre solvers  for each schedule considered  satzilla performs algorithm subset selection
and trains the classification models  which can require substantial amounts of time  in our
experiments  up to   cpu days  
 s  kadioglu et al         malitsky et al             b  uses a k nearest neighbour
approach to select an algorithm  for a given problem instance to be solved  it determines
a set of similar training instances in the instance feature space and selects the algorithm
with the best performance on this instance set  the performance of this k nn approach
is further improved by distance based weighting  that is  weighting algorithm performance
on an instance by the instances distance to the new given instance  and using a clusteringbased adaptive neighbourhood size  to adjust the size of the neighbourhood in different
areas of the feature space   furthermore   s uses mixed integer programming to compute
pre solving schedules more efficiently than satzilla 
isac  kadioglu et al         clusters instances in the instance feature space using the
g means algorithm and stores the cluster centre as well as the best performing algorithm for
each cluster  for each new problem instance  it then determines the nearest cluster centre
   nn  and selects the algorithm associated with it 
the cost sensitive hierarchical clustering system cshc  malitsky et al       a  also
partitions the feature space into clusters  but instead of isacs unsupervised clustering
approach  it creates this partitioning in a supervised top down fashion  much like a decision
or regression tree algorithm  starting with all instances  the entire feature space  at the
root of a tree  it recursively splits the instances associated with a node into two child
nodes  choosing each split along a single feature value  such that the performance of the
best performing algorithm in each child node is optimized  this cost sensitive supervised
approach based on trees closely resembles the cost sensitive random forests in satzilla 
with the difference that  in contrast to satzillas pairwise voting approach  it only builds
a single model 
last but not least  claspfolio    gebser et al       b  is the predecessor of claspfolio    which we use here  and describe in section         in contrast to the flexible framework of claspfolio    claspfolio   was inspired by the earlier version of satzilla and
uses the same regression approach  but with a different machine learning method  support
vector regression instead of ridge regression  
further systems for algorithm selection combine and extend these techniques  for example  by combining regression and clustering approaches  collautti et al          or by
selecting algorithm portfolios  yun   epstein        lindauer  hoos    hutter      a 
or schedules  amadini  gabbrielli    mauro        instead of a single algorithm  for additional information  we refer the interested reader to two recent surveys on algorithm
selection  smith miles        kotthoff        
   

filindauer  hoos  hutter    schaub

feature
generator

training instances

algorithms

instance features
and groups

algorithm
performance
aslib scenario

feature
preprocessing

performance
preprocessing
train
selection model s 

i

performance estimation

pre solving schedule
by aspeed

selection

scheduling
offline training

 test  instance

compute features

select algorithm

failed
run backup
algorithm

run pre solving
schedule
if not successful
run selected
algorithm
online solving

figure    general workflow of claspfolio    objects such as algorithms and instances
are shown as rectangles  and activities are depicted as rectangles with rounded corners 
activities related to algorithm selection are shown in red and activities related to algorithm
schedules in yellow 
      the algorithm selection framework claspfolio  
we now explain the algorithm selection framework claspfolio    hoos et al         lindauer  hoos    schaub      c  in some more detail  since it provides the basis for the
concrete implementation of our general autofolio approach  as used in our experiments 
the claspfolio   framework implements the idea of algorithm selection in a flexible
and general way  it provides a general view on the individual components of algorithm
selectors  based on which it implements many different selection approaches and associated
techniques  therefore  claspfolio   is a natural candidate to serve as a basis for our
autofolio approach 
figure   shows the workflow of claspfolio    which is divided into an aslib scenario
as input of claspfolio    offline training of selection and scheduling  and online solving
a new instance 
aslib scenario  as an input  claspfolio   reads an algorithm selection scenario  supporting the format of the algorithm selection library  aslib  this consists of a
performance matrix  instance features  groups of instance features  and some optional information  such as cross validation splits or ground truth about the problem
   we note that  according to the definition of aslib  each feature group enables a list of instance features
that are computed with a common block of feature computation code  and jointly incur the cost for
running this code 

   

fiautofolio  an automatically configured algorithm selector

instances  for example  whether a sat instance is satisfiable or unsatisfiable   for a
full specification of the aslib format  we refer the interested reader to aslib net 
offline training  selection  based on the given scenario  training  data  claspfolio  
pre processes the instance features  for example  normalization or feature imputation 
and performance data  for example  log transformation   using machine learning
techniques  claspfolio   learns a selection model that maps instance features to
algorithms 
offline training  scheduling  to compute an efficient pre solving schedule  claspfolio   first estimates the performance of the selection module by using an internal
cross validation on the training data  arrow i   based on this performance estimation 
claspfolio   computes a timeout minimal pre solving schedule using answer set
programming in aspeed  hoos et al          assigning each algorithm a  potentially
zero length  time slice of the overall runtime budget  the estimation of the selection
module is necessary to compute the runtime budget for the pre solving schedule  if
the selection module performs well  the pre solving schedule may be empty  because
the pre solving schedule cannot perform better than a perfect predictor  that is  a predictor that always selects the best solver   in contrast  if the prediction performs very
poorly  for example  as a result of non informative instance features   the pre solving
schedule may be allocated the complete time budget  with the selection module being
ignored 
online solving  the solving workflow is as follows  a feature generator computes the
instance features of a new problem instance to be solved  if this computation fails
 for example  because of time or memory constraints  and no feature imputation
strategy is selected  a backup solver  i e   the single best performing solver in the
offline training  is run on the instance  otherwise  the previously trained selection
model uses the instance features to select an algorithm expected to perform well  if
a pre solving schedule is available  the schedule runs either before instance feature
computation or after the selection of the algorithm  depending on a parameter setting
of claspfolio    this latter version being shown in figure    the former has the
advantage that the time to compute instance features can be saved if the instance is
solved during pre solving  the latter has the advantage that the algorithm chosen by
the selector can be removed from the pre solving schedule to prevent running it twice 
a list of all techniques we implemented for these modules is given in section     
    algorithm configuration
figure   shows a general outline for algorithm configuration methods  given a parameterized algorithm a with possible parameter settings c  a set of training problem instances
i  and a performance metric m   c  i  r  the objective in the algorithm configuration
problem is to find a parameter configuration c  c that minimizes m across the instances
in i  prominent examples for the performance metric to be optimized are the runtime 
solution quality  or misclassification cost the target algorithm achieves  the configuration
   

filindauer  hoos  hutter    schaub

instances i

algorithm a and
its configuration space c

select c  c

assess a c  on
some i    i

returns
best found
configuration c

return performance
configuration task

figure    general outline of algorithm configuration 
procedure  or short configurator   iteratively evaluates the performance of parameter configurations c  c  by running a with them on one or more instances in i  and uses the
result to decide about the next configurations to evaluate  after a given budget for the configuration process has been exhausted  the configurator returns the best known parameter
configuration it found until then 
when a has n parameters p            pn   with respective domains d            dn   the parameter
configuration space c   d       dn is the cross product of these domains  and each
parameter configuration c  c assigns a value to each parameter  there are several types of
parameters  including real valued  integer valued and categorical ones  which have a finite 
unordered domain  for example  a choice between different machine learning algorithms  
furthermore  configuration spaces can be structured  specifically  a parameter pi can be
conditional on another parameter pj   such that the value of pi is only relevant if the parent
parameter pj is set to a specific value  for example  this is the case when pj is a categorical
choice between machine learning algorithms  and pi is a sub parameter of one of these
algorithms  pi will only be active if pj chooses the algorithm it parameterizes further 
to date  there are four general configuration procedures  paramils  hutter et al  
       gga  ansotegui  sellmann    tierney         irace  lopez ibanez  dubois lacoste 
stutzle    birattari         and smac  hutter et al          in principle  we could use any
of these as the configurator in our general autofolio approach  in practice  we have
found smac to often yield better results than paramils and gga  hutter et al        
hutter  lindauer  balint  bayless  hoos    leyton brown        lindauer  hoos  hutter   
schaub      b   and thus use it as the basis for the concrete implementation of autofolio
discussed in the following  we now describe smac in more detail 
      smac  sequential model based algorithm configuration
the sequential model based algorithm configuration method smac  hutter et al        
hutter  hoos    leyton brown      a  uses regression models that approximate the performance metric m   c  i  r  hutter  xu  hoos    leyton brown         it follows the
general algorithm configuration workflow from above  alternating evaluations of m for some
parameter configurations and instances with decision phases  in which the configurator uses
the data gathered so far to select which configurations to evaluate next on which instances 
smacs decision phases involve constructing a regression model m   c  i  r based
on the data observed so far  and then using this model  as well as the models uncertainty
in its predictions  to select promising configurations to try next  this step automatically
   

fiautofolio  an automatically configured algorithm selector

trades off exploration  evaluating in regions of the configuration space where the model m
is very uncertain  and exploitation  evaluating configurations predicted to perform well  
in order to save time in evaluating new configurations cnew  c  smac first evaluates
them on a single instance i  i  additional evaluations are only carried out  using a doubling
schedule  if  based on the evaluations to date  cnew appears to outperform smacs best
known configuration c  once it has evaluated the same number of runs for cnew as for c  if
cnew still performs better  smac updates its best known configuration c to cnew  
      previous applications of algorithm configuration
algorithm configuration has been demonstrated to be very effective in optimizing algorithms for a wide range of problems  including sat based formal verification  hutter  babic 
hoos    hu         timetabling  chiarandini  fawcett    hoos         multi objective optimization  lopez ibanez   stutzle         mixed integer programming  hutter  hoos   
leyton brown         ai planning  vallati  fawcett  gerevini  hoos    saetti         generation of heuristics  mascia  lopez ibanez  dubois lacoste    stutzle         occupancy
scheduling  lim  van den briel  thiebaux  backhaus    bent        and kidney exchange
matching  dickerson   sandholm         an important special case of algorithm configuration is hyperparameter optimization in machine learning  bergstra et al         snoek
et al         eggensperger et al         
the previous line of work most related to our application of configuration to algorithm
selection is auto weka  thornton et al          auto weka addresses the combined
problem of selecting a machine learning algorithm from the weka framework  hall  frank 
holmes  pfahringer  reutemann    witten        and optimizing its hyperparameters 
autofolio also needs to solve this combined algorithm selection and hyperparameter
optimization problem  and in particular needs to do so for each of the problem formulations
it considers  regression  classification and clustering  further important design choices in
autofolio are pre solving and its parameters  as well as which instance features to use 
autofolio applies one meta solving strategy  algorithm configuration  to another one
 algorithm selection   a previous application of a meta solving strategy to itself was the selfconfiguration of paramils  hutter et al          however  in that case  self configuration
only yielded a modest improvement over the default configuration of paramils  whereas
here  we achieve substantial improvements over the default configuration of claspfolio   
algorithm configuration and algorithm selection have previously been combined in a
different way  by using configuration to find good parameter settings of a highly parameterized algorithm  and then using selection to choose between these on a per instance
basis  two systems implement this approach to date  isac  kadioglu et al         and
hydra  xu  hoos    leyton brown         isac first clusters training problem instances
into homogeneous subsets  uses a configurator to find a good solver parameterization for
each cluster  and then uses a selector to choose between these parameterizations  hydra
iteratively adds new solver parameterizations to an initially empty portfolio based selector 
at each step tasking a configurator to find the solver parameterization that most improves
the current portfolio 
   

filindauer  hoos  hutter    schaub

training data

test data

   fold cross validation      meta instances

figure    split of instance sets in algorithm selection scenarios  cross validation is performed
inside the configuration process  the test set is withheld for evaluating the configured selector 

   configuration of algorithm selectors
we now present our autofolio approach of using algorithm configurators to automatically
customize flexible algorithm selection  as  frameworks to specific as scenarios  to apply
algorithm configuration in this context  we need to specify a parameterized selector and its
configuration space  as well as the performance metric by which we judge its performance 
    formal problem statement
to judge the performance of an algorithm selection  as  system on an as scenario  it is
crucial to partition the given set of problem instances into a training and a test set  use the
as system only on the training set to train a selector s  and evaluate s only on the test
set instances   if the training set was instead used to evaluate performance  a perfect as
system could simply memorize the best solver for each instance without learning anything
useful for new problem instances   this is the standard notion of a training test split from
machine learning 
an as scenario includes algorithms a  problem instances i  performance and feature
data d  and a loss function l   a  i  r to be minimized  for example  the algorithms
runtime or solution cost   with the data split into disjoint sets dtrain and dtest   let
s dtrain     i  a denote the selector learned by the as system s when trained on the data
in dtrain   then  the performance of s  p  s  is the average performance of the algorithms
it selects on the instances in the test data set dtest  
p  s   

x
 

l s dtrain    i  
 dtest  

   

idtest

likewise  we can evaluate the performance of an as system sc parameterized by a
configuration c as p  sc    however  we can not perform algorithm configuration by simply
minimizing p  sc   with respect to c  c  this would amount to peeking at the test set
many times  and even though it would yield a configuration c with low p  sc    it could
not be expected to perform well on instances not contained in dtest   instead  in order to
obtain an unbiased evaluation of the configured selectors performance in the end  we need
to hold back a test set of instances that is not touched during the configuration process  in
order to still be able to optimize parameters without access to that test set  the standard
solution in machine learning is to partition the training set further  into k cross validation
folds  overall  we use the instance set for each selection scenario as illustrated in figure   
 i  we split the full set of instances into a training and a test set and  ii  the training data
   

fiautofolio  an automatically configured algorithm selector

algorithm    autofolio  automated configuration of an algorithm selector
input   algorithm configurator ac  algorithm selector s  configuration space c of
s  training data of algorithm scenario d  with performance and feature
matrix   number of folds k

 

randomly split d into d              d k 
start ac with d              d k  as meta instances  using average loss across
meta instances as performance metric m  and using s as target algorithm with
configuration space c
while configuration budget remaining do
ac selects configuration c  c and meta instance n           k 
train sc on d d n    assess its loss on d n  and return that loss to ac

 

return best configuration c of s found by ac

 
 

 
 

is further partitioned into k folds  in our experiments  we use k        which are used as
follows 
   
 k 
let dtrain           dtrain be a random partition of the training set dtrain   the crossvalidation performance cv  sc   of sc on the training set is then 


k
x
x
 
 


 j 
cv  sc     
l sc  dtrain  dtrain    i 
   
  j  
k
 dtrain  
 j 
j  
idtrain

in the end  we optimize the performance cv  sc   by determining a configuration c  c
of the selector s with good cross validation performance
c  arg min cv  sc   

   

cc

and evaluate c by training a selector sc with it on the entire training data and evaluating
p  sc   on dtest   as defined in equation   
 j 
following thornton et al          we use each of the k folds dtrain as one instance within
the configuration process  in order to avoid confusion between these as instances and the
base level problem instances  e g   sat instances  to be solved inside the as instance  we
refer to the as instance as a meta instance  we note that many configurators  such as focusedils  hutter et al          irace  lopez ibanez et al         and smac  hutter et al  
       can discard configurations when they perform poorly on a subset of meta instances
and therefore do not have to evaluate all k cross validation folds for every configuration 
this saves time and lets us evaluate more configurations within the same configuration
budget  based on these considerations  algorithm   outlines the process to configure an
algorithm selector with autofolio 
since the instances in an as scenario could be split into configuration and testing sets in
many different ways  one such split does not necessarily yield a representative performance
estimate  therefore  to yield more confident results in our evaluation  we perform an additional outer cross validation  as given by an aslib scenario  instead of a single training test
   

filindauer  hoos  hutter    schaub

split  that is  we consider multiple training test splits  configure the selector for each training set  assess its final configurations on the respective test data sets  and average results 
we note  however  that in a practical application of as  one would only have a single training set  which we would still split into k cross validation splits internally  and a single test
set 
    configuration space of selectors
most existing algorithm selectors implement one specific algorithm selection approach  using
one specific machine learning technique  we note  however  that most selection approaches 
at least implicitly  admit more flexibility  and in particular could be used with a range of
machine learning techniques  for example  satzilla    xu et al         uses voting on
pairwise performance predictions obtained from cost sensitive random forest classifiers  but 
in principle  it could use other cost sensitive binary classifiers instead of random forests 
based on this observation  we consider a hierarchically structured configuration space
with a top level parameter that determines the overall algorithm selection approach 
for example  a regression approach  as used in satzilla    xu et al         or a k nn
approach  as used in me asp  maratea et al          for most selection approaches  we
can then choose between different regression techniques  for example  ridge regression  lasso
regression  support vector regression or random forest regression  each of these machine
learning techniques can be configured by its own  hyper  parameters 
besides the selection approach  further techniques are used for preprocessing the training data  for example  z score feature normalization as a feature preprocessing step or
log transformation of runtime data as a performance preprocessing step   preprocessing
techniques can be configured independently from the selection approach  and are therefore
also handled by top level parameters 
we use a third group of parameters to control pre solving schedules  kadioglu et al  
      xu et al          including parameters that determine the time budget for pre solving
and the number of pre solvers considered  pre solving techniques can be freely combined
with selection approaches  because they are not always needed  we added a top level binary
parameter that completely activates or deactivates the use of pre solvers  all other presolving parameters are conditional on this switch 
we implemented these choices in the claspfolio   system described in section       
figure   illustrates the complete configuration space thus obtained  our current version 
which we use for the concrete implementation of our autofolio approach  covers six
different algorithm selection approaches 
 hierarchical  regression  inspired by satzilla    xu et al         learns a regression
model for each algorithm  for a new instace  it then selects the algorithm with best
predicted performance 
multiclass classification  inspired by llama  kotthoff        learns a classification
model that directly selects an algorithm based on the features of a new instance 
pairwise classification  inspired by satzilla    xu et al         learns a  cost sensitive 
classification model for all pairs of algorithms  for a new instance  it evaluates all models and selects the algorithm with the most votes 
   

fiautofolio  an automatically configured algorithm selector

transformation

pre solving

yes

instance
weighting

contribution
filtering

normalization

as approach

imputation

p   pca

performance preprocessing

max feature time

feature preprocessing

 
multi class
classification

pairwise
classification

c  svm 
gamma svm 

 hierarchical 
regression

clustering

snnap

k   k nn

max cluste r

k
best n

random
forest

svm

gradient
boosting

random
forest

svm

gradient
boosting

ridge

lasso

svr

random
forest

ridge

lasso

svr

random
forest

 

 

 

 

 

 

 

 

 

 

 

 

 

 

k means

gaussian
mixture

spectral
clustering

figure    configuration space of claspfolio    including    categorial parameters    
integer valued parameters and    continous parameters  parameters in double boxes are
top level parameters  single boxes represent algorithm selection approaches based on classes
of machine learning techniques  dashed boxes machine learning techniques and dotted boxes
indicate the number of low level parameters  parameter boxes used in the default configuration are filled in grey 
clustering  inspired by isac  kadioglu et al         determines subsets of similar training
instances in the feature space and the best algorithm on these subsets  for a new
instance  it determines the nearest cluster center and selects the associated algorithm 
k nn  inspired by  s  kadioglu et al         and me asp  maratea et al         determines a set of similar training instances in the feature space for a given new instance
and selects the algorithm with the best performance on this instance set 
snnap  inspired by collautti et al         predicts the performance of each algorithm
with regression models and uses this information for a k nn approach in the predicted
performance space 
for each of these approaches  claspfolio   covers at least three different machine
learning techniques  where appropriate   these are listed in figure    for example  pairwise
classification can be based on random forests  svms or gradient boosting  with      and  
hyper parameters  respectively   for preprocessing strategies  it supports 
performance preprocessing 
transformation applies log  xu et al         or z score normalization  collautti
et al         to the performance data 
instance weighting weights the instances by their impact on the performance of
an algorithm selector  that is  instances get a low weight if all available algorithms perform equally  and high weight if the algorithms differ substantially in
performance  kotthoff  gent    miguel        
contribution filtering removes algorithms that have less than a specified contribution to the performance of the oracle  also known as virtual best solver   xu
et al       a   this is a form of algorithm subset selection 

   

filindauer  hoos  hutter    schaub

feature preprocessing 
normalization transforms the instance features with min max  z score  decimalpoint  log scheme or by application of pca 
p pca applies principal component analysis on the features and selects the top p
principal components  where p is a parameter  if pca was activated  
imputation fills in missing feature values as the median  average or most frequent
value of a feature  if imputation is deactivated and a feature vector is incomplete
for a given instance  the single best solver is statically selected 
max feature time limits the amount of time spent to collect features  this ensures
that not too much time is spent on feature computation  however  it can result
in incomplete features with missing values  which get imputed if imputation is
active  
we chose the default configuration of claspfolio    used to initialize the algorithm
configurator  to be a satzilla   like configuration  since this was shown to be effective on
sat  xu et al       a  and asp  hoos et al          and since its overall high performance is
evident from the results in figure    this configuration uses pairwise cost sensitive random
forest classifiers  z score feature normalization and a pre solving schedule with at most three
pre solvers  since we assume no prior knowledge about the algorithm selection scenarios  the
default configuration uses the default instance features as defined by the scenario designers 
we chose claspfolio   as the basis for autofolio  because it has been designed to
be flexible and is known to perform well   we note that in principle  other selectors  such
as satzilla  xu et al          isac  kadioglu et al          snnap  collautti et al  
      and llama  kotthoff         could be generalized in a similar way 
in addition to using claspfolio   as its algorithm selection framework  our current
version of autofolio employs the algorithm configurator smac  described in section
        like the selection framework  this configurator is also exchangeable  while we chose
smac  because it performed best across the algorithm configuration problems we studied
so far  in principle  other configurators could also be used  such as  gga  ansotegui et al  
      or irace  lopez ibanez et al          preliminary results  lindauer et al       b 
showed that paramils can also optimize the performance of claspfolio    but was
inferior to smac in all but one scenario  on which its performance advantage was small 

   empirical performance analysis
in this section  we empirically analyze the performance of our autofolio approach  in
these experiments  autofolio employs claspfolio   using the well known machine learning package scikit learn  pedregosa et al          version         and the algorithm configurator smac  version           we ran autofolio on the thirteen algorithm selection
scenarios that make up the algorithm selection library      bischl et al       b   
   results on the performance of claspfolio   compared to other state of the art algorithm selectors can
be found at aslib net 
   we note that for experiments on aslib scenarios  claspfolio   and other algorithm selectors do not
need to perform actual runs of algorithms or feature generators  because the aslib scenarios already

   

fiautofolio  an automatically configured algorithm selector

as shown in table    these scenarios comprise a wide variety of hard combinatorial
problems  each of them includes the performance data of a range of solvers  between   and
    for a set of instances  and instance features organized in feature groups with associated
costs  for all scenarios we consider here  the performance objective is runtime minimization 
on a high level  these scenarios comprise the following data 
 asp potassco  runtimes of different parameter configurations of the asp solver
clasp on a broad range of asp instances collected by the potassco group  gebser 
kaminski  kaufmann  ostrowski  schaub    schneider      a  
 csp       runtimes of a single solver with two different configurations  with and
without lazy learning  gent  jefferson  kotthoff  miguel  moore  nightingale    petrie 
      on a collection of csp instances 
 maxsat   pms  runtime data from the      maxsat evaluation 
 premarshalling  runtimes of a  based and ida  based solvers for the premarshalling problem  on real world  time sensitive pre marshalling problem instances
from the operations research literature 
 proteus       runtimes of different csp and sat solvers on a range of csp
instances  preprocessed with various csp to sat translation techniques 
 qbf       runtime data for the qbf solvers from the aqme system  pulina  
tacchella        on qbf instances from the      qbf solver evaluation 
 sat   hand  sat   indu and sat   rand  runtime data from the respective tracks of the      sat competition 
 sat   all  sat   hand  sat   indu and sat   rand  runtimes of various sat solvers on a broad range of sat instances used to train the algorithm
selection system satzilla  xu  hutter  shen  hoos    leyton brown      b  for
the respective tracks of the      sat challenge 
we refer to bischl et al       b  for further details on these scenarios  including baseline
experiments showing that algorithm selection can be applied effectively to all these scenarios  we point out that using this common library allows us to compare autofolio in a
fair and uniform way against other algorithm selection methods  however  the price we pay
for this uniform comparison is that we do not necessarily consider current state of the art
algorithms for solving the respective problems  since some of the aslib data was collected
several years ago  furthermore  we note that the current version of aslib only consists of
deterministic performance data  we expect that future versions will also consider scenarios with stochastic performance data and multiple runs per algorithm and instance  using
different pseudo random number seeds  autofolio can be applied to such stochastic scenarios in a straightforward manner  by optimizing mean performance across all runs for the
same instance
contain all necessary performance data and feature vectors  in order to allow for a fair comparison of
algorithm selectors based on the same data  without confounding factor due to the hardware platform
used to run experiments  

   

filindauer  hoos  hutter    schaub

scenario
asp potassco
csp     
maxsat   pms
premarshalling
proteus     
qbf     
sat   hand
sat   indu
sat   rand
sat   all
sat   hand
sat   indu
sat   rand

 i
    
    
   
   
    
    
   
   
   
    
   
    
    

 u  a  f  fg
  
   
   
 
   
   
  
  
   
  
   
   
   

  
 
 
 
  
 
  
  
 
  
  
  
  

   
  
  
  
   
  
   
   
   
   
   
   
   

 
 
 
 
 
 
  
  
  
  
  
  
  

tc
   
    
    
    
    
    
    
    
    
    
    
    
    

reference
 hoos et al        
 gent et al        
 malitsky et al        
 tierney   malitsky       
 hurley et al        
 pulina   tacchella       
 xu et al        
 xu et al        
 xu et al        
 xu et al       b 
 xu et al       b 
 xu et al       b 
 xu et al       b 

table    overview of algorithm selection scenarios in the algorithm selection library 
showing the number of instances  i  number of unsolvable instances  u  u  i   number
of algorithms  a  number of features  f   number of feature groups  fg   cutoff time tc
and literature reference 

    algorithm configuration setup
following standard practice  hutter et al          we performed multiple  in our case     
independent runs of the algorithm configurator smac for each scenario and then selected
the configuration of claspfolio   with the best performance on training data  each configurator run was allocated a total time budget of   cpu days  a single run of claspfolio  
was limited to   cpu hour  using the runsolver tool  roussel         as a performance
metric  we used penalized average runtime with penalty factor     par     which counts
each timeout as    times the given runtime cutoff  runtime cutoffs differ between the aslib
scenarios   we further study how the optimization of par   influenced other metrics  such
as the number of timeouts  the time required to evaluate a single configuration of claspfolio   varied between    cpu seconds and   cpu hour on our reference machine  see
below   mostly depending on the difficulty of optimizing pre solving schedules 
to obtain a robust estimate of autofolios performance  we used    fold outer crossvalidation as given in the specific aslib scenarios  that is  we configured claspfolio   ten
times for each scenario  with different training test splits   therefore  in total  we performed
             configuration runs of   cpu days each for three different configuration spaces
 see section      and each of the thirteen aslib benchmarks  requiring a total of      
cpu days     cpu years   we note that although our thorough evaluation of autofolio
required substantial amounts of computation  applying it to a single benchmark set with
a given training test split would only require    independent configuration runs of two
days each and could thus be performed over the weekend on a modern desktop machine 
furthermore  applying autofolio to a new algorithm selection benchmark set is cheap
in comparison to collecting the data for a new benchmark set  for instance  to collect
   

fiautofolio  an automatically configured algorithm selector

autofoliovote
autofolio
autofolioext

categorical

integer

real

conditionals

configurations

      
      
       

 
  
  

 
  
  

  
  
  

              
                
                

table    overview of configuration spaces with the number of categorical  integer valued
and real valued parameters  the number of conditionals  and an estimation of the number
of configurations by ignoring the real valued parameters  the number of categorical values
varies between the scenarios depending on the number of algorithms  features and feature
groups 
the algorithm performance data for the aslib scenarios required between      cpu days
 asp potassco  and       cpu days  proteus        with an average of      
cpu days    times as much as our configuration budget for autofolio  
we performed these experiments on the bwunicluster in karlsruhe  whose machines
are equipped with two octa core intel xeon e            ghz     mb cache  cpus and
   gb ram each  running hat enterprise linux      we note  however  that the runtimes
of the selected algorithms and feature computations are part of the aslib scenarios and do
not depend on the hardware we used 
    different configuration spaces
as mentioned earlier  autofolio can be used to optimize the performance of single approach algorithm selectors  such as satzilla  or multi approach selectors  such as llama
or claspfolio    with much larger configuration spaces  see figure     therefore  we studied three different parameter spaces of autofolio based on claspfolio   
autofolio considers the configuration space described in section     and additionally
adds binary parameters that enable or disable feature groups  that are defined by
the specific algorithm selection scenario  algorithm subset selection is done using a
heuristic based on the marginal contribution of each algorithm to the oracle performance 
autofoliovote considers only a subset of the configuration space of autofolio  that
fixes the algorithm selection approach to pairwise classification with a voting scheme 
autofolioext considers the same configuration space as autofolio  but instead of parameters for each feature group  we added binary parameters for each instance feature
and for each selectable algorithm  this increases the number of parameters substantially  for example  it adds     additional parameters for the proteus     
scenario 

   if the selected feature groups result in an empty feature set  claspfolio   will statically select the single
best algorithm on training data 

   

filindauer  hoos  hutter    schaub

scenario
asp potassco
csp     
maxsat   pms
premarshalling
proteus     
qbf     
sat   hand
sat   indu
sat   rand
sat   all
sat   hand
sat   indu
sat   rand

default
par    tos
     
     
     
      
      
      
      
      
      
      
      
      
     

  
  
 
  
   
  
  
  
  
   
  
  
  

autofoliovote
par  
 tos
     
     
     
      
      
     
      
      
      
     
      
     
     

  
 
 
  
   
  
  
  
  
   
  
  
  

autofolio
par  
 tos
     
     
     
      
      
     
      
      
     
     
      
     
     

  
 
 
  
   
  
  
  
 
   
  
  
  

autofolioext
par  
 tos
     
     
     
      
      
     
      
      
      
      
      
     
     

  
 
 
  
   
  
  
  
  
   
  
  
  

table    comparing different configuration spaces of autofolio based on test performance  the best performance is shown in bold face   and  indicate performance significantly better than that of the default configuration of claspfolio   at significance levels
        and         respectively  according to a one sided permutation test with        
permutations  performances values that  according to the permutation test  are not significantly worse  at          than the best performance for a given scenario are marked with
 

we fixed the selection approach in autofoliovote to pairwise classification with a
voting scheme  since satzilla   like was the most promising single approach in our experiments  see  e g   figure     on the other hand  the extended configuration space 
autofolioext   was obtained by adding algorithm subset selection and feature selection to
the configuration task  feature selection is well known to improve many machine learning
models  and often only a small subset of instance features is necessary to predict the runtime
of algorithms  hutter  hoos    leyton brown        
we note that each configuration in autofoliovote can also be found in autofolio 
and each configuration of autofolio is also part of autofolioext   that is  autofoliovote
 autofolio  autofolioext   table   gives an overview of the configuration space sizes 
    analysis of configuration process
in table    we compare the performance of the default configuration of claspfolio  
 namely  satzilla   like  with that of the configurations optimized by autofoliovote  
autofolio and autofolioext   for all selection scenarios  autofoliovote improved
performance on test data in comparison to the default configuration of claspfolio   
autofolio improved on all but one scenario and autofolioext on all but three scenarios 
performance improvements on test data were statistically significant at        and        
for ten and seven scenarios for autofoliovote   for nine and seven for autofolio  and
five and four for autofolioext   respectively  according to a one sided permutation test
with         permutations 
   

fiautofolio  an automatically configured algorithm selector

on    of the    aslib scenarios  configuration in at least one of the configuration
spaces we considered led to statistically significant improvements           we now discuss
the remaining two scenarios  asp potassco and csp       on asp potassco 
performance improved substantially on the training data  autofolio reduced the par  
score by        but this did not transfer to test data  with none of the differences between
test performances being statistically significant   we note that the default configuration
of claspfolio   was manually optimized on this scenario  hoos et al          and that
autofolio found very similar configurations with very similar performance  on csp      all autofolio variants improved over the default  but only insignificantly so  we
note that it is hard to improve performance substantially on this benchmark  which only
contains two algorithms 
on premarshalling  autofolio solved   additional problem instances and reduced par   by more than      nevertheless  this performance difference was only weakly
significant  at          this is due to the strong constraints on the pre solving schedule
in the default configuration of claspfolio    at most   solvers for at most     seconds  
while more extensive pre solving schedules decreased the number of timeouts on premarshalling  they also introduced overhead on many of the other instances in this
scenario  making it harder for autofolio to achieve more significant performance improvements  the scatter plot of figure  a shows that autofolio produced fewer timeouts
than default claspfolio    but autofolio required higher runtime on some other instances  points above the diagonal   similarly  autofolio solved a lot more instances on
proteus      and some more on qbf       but autofolio had a higher runtime
on some other instances  see figure  c and  b   however  the number of timeouts improved so much on proteus       from     to      that the performance improvement
was statistically significant here  finally  sat   all is an example of a more clear cut
case  autofolio improved the performance of claspfolio   on most instances and also
substantially reduced the number of timeouts  see figure  d  
overall  autofoliovote performed best in these experiments  followed by autofolio 
and with some distance  autofolioext   with respect to statistical significance  autofoliovote and autofolio performed quite similarly  the former being better three times
and the latter being better once  based on the results  we suspect that the added flexibility
in autofolio as compared to autofoliovote pays off when the configuration budget
is large enough to evaluate enough configurations to effectively search its larger space 
this was the case for the three sat   scenarios  for which autofolio reached the best
performance  these scenarios only contain relatively few problem instances  making each
evaluation of claspfolio   quite fast and allowing smac to evaluate about        configurations within   days  in contrast  an evaluation of a configuration on the largest aslib
scenario  proteus       can cost up to an hour  and smac evaluated only about    
configurations  which was not enough to explore the design space of autofolio  accordingly  the performance of autofolioext on proteus      improved only slightly in
comparison to the default configuration  while autofoliovote made progress faster and
performed statistically significantly better than autofolio  therefore  we believe that
autofolio is a good choice when we can evaluate many configurations  be it because the
scenario is small or because a large configuration budget is available  on the other hand 
   

filindauer  hoos  hutter    schaub

   x

  x

 x

   x

  x

 x

 x

 x

    

    
  x

  x

   

   
   x

configured

configured

   x

  

  

 

 

   

   

    
    

   

 

  
default

   

    
    

    

   

 

  
default

   

    

 a  premarshalling  number of timeouts  b  qbf       number of timeouts reduced
reduced from     default  to     configured  
from     default  to     configured  
   x

  x

 x

   x

    

 x

  x

 x
 x

    
  x

   

  x

  

   x

   

configured

configured

   x

  

 

 

   

   
    
    

   

 

  
default

   

    
    

    

   

 

  
default

   

    

 c  proteus       number of timeouts
 d  sat   all  number of timeouts reduced
reduced from      default  to      configured   from      default  to      configured  

figure    scatter plots comparing the per instance performance of default claspfolio  
 satzilla   like  and autofolio  left  on premarshalling  autofolio improved penalized average runtime  par    by reducing the number of timeouts  at the
cost of increased runtimes on many other instances  right  on sat   all  autofolio
improved performance on most instances and also reduced the number of timeouts 

autofoliovote should be used on larger scenarios or when the configuration budget is
quite small 
figure   shows the progress of the configuration process in terms of training performance
as a function of time for sat   hand and proteus       as the scenarios with the
   

fiautofolio  an automatically configured algorithm selector

    
    
performance

par  

    
    
    

autofolio
autofolio ext
autofolio vote

    
  

   

   

   

       
time  s 

    
    

autofolio
autofolio ext
autofolio vote

    
    
   

   

   

  

   

 a  sat   hand

   

   

       
time  s 

   

   

   

 b  proteus     

figure    the training par   performance of the best configuration over time  the line
shows the median over the    folds of the outer cross validation and the filled area indicates
performance between the    and    quantile 

most and the fewest configuration evaluations performed in the fixed configuration budget 
for both scenarios  the very large configuration space of autofolioext resulted in a period
of stagnation before performance improved  on proteus       the performance started
to improve only near the end of the configuration budget  in contrast  autofolio and
autofoliovote performed quite similarly on both scenarios  with autofoliovote being
somewhat faster to make progress  note the logarithmic time axis   surprisingly to us  very
different selection approaches were chosen for autofolio and autofoliovote   because
of its restricted configuration space  autofoliovote had to choose pairwise classification
with a voting scheme  but autofolio also used other approaches for some outer folds of
these scenarios  regression    times in each of the two scenarios   clustering    and   times 
resp   and snnap    and   times  resp   
from figure    we can also estimate the influence of the configuration budget on the
performance of our final algorithm selector  for example  if we halve the configuration time
budget to   day  the penalized average runtime on the training set only increases by about
   
    which choices lead to good performance 
to analyze which choices were most important in autofolio  we applied two complementary methods for assessing parameter importance in algorithm configuration spaces 
functional anova  hutter  hoos    leyton brown            b  for a global measure of
parameter importance and ablation analysis  fawcett   hoos      b      a  for a local
measure  for a high level overview of the parameters in autofolio  we refer back to
section      full details  including the default values and ranges of all parameters  are given
in an online appendix available at www ml aad org autofolio 
   

filindauer  hoos  hutter    schaub

      functional anova  fanova 
functional anova  fanova  see  e g   sobol        is a general method for partitioning the
variance of a function into components corresponding to subsets of its arguments  hutter
et al         demonstrated that this technique can be applied to efficiently quantify the
importance of an algorithms parameters  their approach can re use the performance data
collected during the configuration process for this purpose  without requiring new algorithm
executions  and is therefore computationally very efficient  in our experiments  it required
minutes   the overall approach is to fit an empirical performance model  hutter  xu  hoos 
  leyton brown        m   c  i  r to the measured performance data  which can be
used to predict performance for arbitrary configurations and instances  and to then study
parameter importance in that model  after fitting that model  fanova marginalizes it
across problem instances 
  x
f c   

m c  i  
   
 i 
ii

it then computes the variance of the function f across the entire configuration space c
and partitions this variance into additive components due to each subset of the algorithms
parameters  of particular interest are unary subsets  which often explain a substantial part
of the variance and tend to be easiest to interpret  it is important to note that fanova
partitions the variance of f over the entire configuration space  while this provides a
global measure of parameter importance  it takes into account many poorly performing
configurations 
to use fanova in the context of our study  for each aslib scenario  we merged the
performance data from    independent smac runs and removed all data points that reported a timeout  or that resulted in an empty feature set  we did the latter  because in
this case claspfolio   statically selects the single best solver  causing most parameters to
become unimportant for the performance of claspfolio   
for brevity  we only report results for scenario sat   all  table   shows the ten
most important parameters of autofolio and autofolioext for this scenario  in both
configuration spaces  the maximal time spent to compute the instance features  max featuretime  turned out to be the most important parameter  this parameter is so important 
because setting it too small will result in too few features  or even none  disabling the
selection mechanism  and setting it too large will lead to an increased overhead in feature
computation  see figure    
the second most important parameter of autofolio was the marginal contribution
filtering as a heuristic for algorithm subset selection  algorithm subset selection is especially important for the as scenarios based on sat solving  because they include many sat
solvers and because the performance of these solvers is often highly correlated  xu et al  
    a   for autofolioext   the contribution filtering heuristic is less important  because
the configuration space includes binary parameters for each individual algorithm  allowing
the configurator  here smac  to directly perform subset selection  in this context  including mphasesatm and marchrw is of special importance  the solver mphasesatm is the
single best algorithm on sat   all and has one of the highest marginal contributions to
   we only observed timeouts for a particular configuration on the larger data sets  the clustering approach
with spectral clustering 

   

fiautofolio  an automatically configured algorithm selector

parameter

main effect

max feature time
contr filter
approach
feature step cg
pre solving
impute
perf transformation
time pre solving
feature normalization
pre solving max solver

parameter

            
           
           
           
           
           
           
           
           
           

main effect

max feature time
approach
pre solving
contr filter
algorithms mphasesatm
imputation
f algorithms marchrw
time pre solving
pre solving sec mode
perf transformation

 a  autofolio

            
           
           
           
           
           
           
           
           
           

 b  autofolioext

table    average main effects   stdev  over outer cross validation splits of the ten most
important claspfolio   parameters on sat   all according to fanova 

marginal par   scores

    

    

     

                       
max feat time  sec 

figure    marginal performance predictions for parameter max feature time on the data of
one outer fold in the configuration space of autofolio  the blue line indicates the mean
of the predicted marginal performance and the red area its standard deviation 
the oracle  similarly  marchrw has a high marginal contribution and is the only algorithm
whose performance is not highly correlated with that of another solver  see the exploratory
data analysis by bischl et al       b  
we note once again that this analysis determines global parameter importance with
respect to the entire parameter space  for example  the importance of the maximal feature
computation time is mostly so high  not because it is crucial to change it to improve the
performance of claspfolio    but because the configuration space contains settings that
will drastically worsen its performance  to gain complementary insights about which parameters should be changed to improve performance  we next performed ablation analysis  
   we note that fanova can also be used to yield a more local analysis of parameter importance by partitioning the variance of performance in high performance regions of a given configuration space  hutter

   

fi    

    

    

    

    

    

    

    
par  

par  

lindauer  hoos  hutter    schaub

    
    

    
    

   

    

   

   

   
ute ime lter lize  sp ans opt  cg eaf aps sic res jois
impture t ontr finorma  stepsnce trspeed  steps ples pl s ls s eps ba featups lob
a
c
ure ma a ature n same ste ure st f max re ste
 fe
featperfor
fe f mi atur feat ing r eatu
max
vot f
ng r fe
i
t
o
v

   

e e t e s s s p f s r c
s cg put tim  op aliz ran joi sap s s lea ure filte asi
tep im ature  speed normance teps lobps ls re stepmples x featcontr  teps b
s
e
t te
 s
a a
ur
 fe a
form re s e s atu n s f m eature
feat
max
per featu featur fge rf mioting r
f
v
n
voti

 a   nd outer fold

 b   th outer fold

figure     ablation paths on two outer folds of sat   all  in  a   the most important
parameter is impute and feature step cg has a smaller effect  in  b   feature step cg is the
most important parameter and impute has no effect on the performance 

      ablation analysis
ablation analysis provides an answer to the question which changes in parameter values
from one configuration to another caused the biggest improvement in performance   it
does so by iteratively changing the parameter value with the largest impact on performance
on a path between two given configurations  e g   the default configuration of an algorithm
and an optimized configuration  unlike fanova  ablation analysis does not attempt to
summarize parameter importance across an entire configuration space  but focusses locally
on paths between configurations of interest  the results obtained from ablation analysis
are therefore complementary to those from fanova  unfortunately  ablation is costly 
since it requires new algorithm runs to assess the performance of configurations on the path
between the two given configurations  for our autofolio experiments on sat   all 
we allocated a time budget of   days  the maximum wall clock time permitted for jobs
on our cluster  for ablation on each of our    outer cross validation folds  and within that
budget  obtained results for   of those 
our ablation results indicate that feature step cg  a boolean parameter that enables or
disables the computation of clause graph features  is the single most important parameter
to change from claspfolio  s default  by default  feature step cg was activated  but
it turns out that the clause graph features are often too expensive to compute within the
time we allow for feature computation  therefore  it was indeed a good decision by the
configuration procedure to deactivate this optional feature computation step  according to
our ablation results  this was done in   out of   outer cross validation folds and  on average 
on these   folds  it was responsible for     of the performance improvements achieved
et al          here  we did not do this  since we used ablation analysis to study parameter importance
locally 

   

fiautofolio  an automatically configured algorithm selector

by configuration  standard deviation         in contrast  as seen in our fanova results 
feature step cg is quite unimportant globally  with a main effect of only        the second
most important parameter to change was the activation of feature imputation  impute   on
average  this was responsible for     of the overall performance improvement  standard
deviation      and was made in all   outer cross validation folds we analyzed   however 
impute only had an effect on the performance if feature step cg was not deactivated before
impute was changed in the ablation path  this was only the case in   out of the   ablation
paths  e g   see figure   a  and hence  impute had no impact on performance for the other  
paths  e g   see figure   b   these two parameters have dependent effects  since imputation
is particularly important if clause graph features are computed  these features time out for
many large instances and thus require imputation 
the globally most important parameter  according to fanova  max feature time  was
found to be rather unimportant to change from its default value  the parameter was
changed between the default and optimized configuration in all outer folds of sat   all 
but  since the default value already was very good  on average only    of the overall performance improvement could be attributed to this change  we note that along the
ablation path  max feature time was never flipped to a value that resulted in worse performance than the default configuration  while many such such poorly performing values
exist and explain the globally high importance of this parameter 
    comparison against other algorithm selectors
in table    we compare autofolio with satzilla     xu et al          snnap  version      collautti et al         and isac  implementation in snnap      kadioglu
et al            we note that isac and snnap are pure algorithm selectors  whereas
satzilla   and claspfolio   can additionally use pre solver schedules  furthermore 
we added a nave approach  randsel  by simulating an uninformed user who selects uniformly at random between snnap  isac and satzilla    overall  autofolio performed best for   out of the    scenarios and was statistically indistinguishable from the
best system for all other scenarios  according to a one sided permutation test with        
permutations and significance level          therefore  autofolio is the only system
that achieves state of the art performance for all scenarios 
satzilla   performed second best  but yielded statistically significantly worse performance than autofolio on   of the    scenarios  even though not statistically significant 
satzilla   performed slightly better than autofolio on   scenarios  the reason for
   this large standard deviation arises from the fact that in some folds  the parameter change was actually
responsible for more than      of the performance difference  in those folds  this change alone would
have sufficed to achieve better performance than the optimized configuration 
   the sum of the relative performance of a subset of parameter improvements is not limited to       since
it was computed relative to the difference between the default and the optimized configuration  in   out
of the   ablation paths  some parameter changes lead to a better performance than the final optimized
configuration  and some parameter changed worsened the performance again 
   alexandre frechette  the current main developer of satzilla  provided an internal new implementation
of satzilla  version      b count cheap feat     that is no longer limited to sat 
    other state of the art selectors  such as  s  kadioglu et al         and cshc  malitsky et al       a  
are not publicly available with their training procedures  and we were therefore unable to train them on
our scenarios 

   

filindauer  hoos  hutter    schaub

asp potassco
csp     
maxsat   pms
premarshalling
proteus     
qbf     
sat   hand
sat   indu
sat   rand
sat   all
sat   hand
sat   indu
sat   rand

oracle

sb

snnap

isac

    
     
    
     
    
    
     
     
     
    
     
    
    

     
      
      
      
       
      
       
      
       
      
      
      
     

     
      
   
      
      
      
      
      
    
      
      
   
     

     
    
     
      
    
      
       
      
      
      
      
      
     

satzilla   randsel autofolio
   
   
     
      
      
      
      
      
     
     
      
     
     

     
     
     
    
      
      
    
      
      
      
      
      
     

   
   
     
      
      
   
      
      
   
   
    
     
   

table   
performance comparison between autofolio  snnap  isac  and
satzilla    as well as the single best solver  sb  selected based on par   on the training
set  as a baseline  and the oracle  also known as virtual best solver  as a bound on the optimal performance of an algorithm selector  we show par   scores averaged over    outer
cross validation folds  with instances not solved by any solver removed from the test set
to avoid artificially inflating the par   scores  the randsel column shows the expected
performance by picking uniformly at random one of snnap  isac and satzilla   
the best performance is shown in bold face  all performance values that are not statistically significantly better than the best performing system for a given scenario  according to
a one sided permutation test with         permutations and a significance level         
are marked with  
this might be that satzilla   performs an extensive search to determine the best combination of pre solving schedule  grid search   algorithm subset  iterated local search  and
trained selection model 
we note that  in order to compensate for the    cpu days spent to find a well performing
configuration of autofolio  compared to simply using the single best solver  on average
across all scenarios autofolio would have to consecutively solve instances for    cpu
days  standard deviation      less than two times the configuration budget 
although autofolio improved substantially over the single best solver  sb  on all
scenarios  up to a speedup factor of      on sat   rand   there is still a gap to the
oracle performance  also known as virtual best solver in the sat community   this
gap could be closed further in at least two ways   i  using a larger configuration budget
for autofolio  or  ii  by developing better instance features  which are the basis for all
algorithm selection methods 

   conclusions
we presented autofolio  to the best of our knowledge  the first approach to automatically configuring algorithm selectors  using a concrete realization of this approach based
on the highly parameterized algorithm selection framework claspfolio    we showed that
by using state of the art algorithm configurators  algorithm selectors can be customized to
   

fiautofolio  an automatically configured algorithm selector

robustly achieve peak performance across a range of algorithm selection scenarios  the
resulting approach performs significantly  and sometimes substantially  better than manually configured selectors and can be applied out of the box to previously unseen algorithm
selection scenarios 
in comprehensive experiments with the    algorithm selection scenarios from different
domains  sat  max sat  csp  asp  qbf  and container pre marshalling  that make up the
algorithm selection library aslib  our concrete realization autofolio outperformed the
best single solver for each selection benchmark by factors between     and       geometric
average       in terms of par   scores  overall  autofolio established improved stateof the art performance on   out of    scenarios and performed on par with the previous
state of the art approaches on all other scenarios  overall  it clearly yielded the most robust
performance across our diverse set of benchmarks 
we also studied the effect of different configuration spaces  here  we showed that the
medium size configuration space of autofolio can lead to state of the art performance
if the configuration budget allows the evaluation of sufficiently many configurations  in
contrast  if the selection scenario is large  in terms of number of algorithms and problem
instances   or if the configuration budget is limited  configuration in a more constrained
space  as used in autofoliovote   typically leads to better performance 
the performance of autofoliovote was independently verified in the icon challenge
on algorithm selection  kotthoff         which evaluated   different as systems with a
small configuration budget of    cpu hours with respect to three metrics  par   score 
number of instances solved and misclassification penalty  as throughout this paper  the
metric we optimized in autofolio was par   score  and autofolio ranked first with
respect to this metric  it also ranked first with respect to number of instances solved and
second with respect to misclassification penalty  leading to an overall second place  
in future work  we plan to investigate how the potential gains of larger configuration
spaces  including feature and algorithm subset selection  can be used more effectively  to
this end  we would like to  i  study performance with larger configuration budgets that
allow the configurator to assess more configurations   ii  evaluate other algorithm configurators  such as irace  lopez ibanez et al         and gga  ansotegui et al           iii 
extend the configuration space of autofolio by implementing more algorithm selection
approaches  e g   cshc  malitsky et al       a    iv  shrink the larger configuration space
based on the analysis of parameter importance through fanova  hutter et al         and
ablation  fawcett   hoos      b   allowing the configurator to focus on the most important parameters  and  v  automatically select between pre configured algorithm selectors 
based on features of a given algorithm selection scenario  and further improve performance
by starting automatic configuration from the configurations thus selected  feurer  springenberg    hutter         another promising avenue for reducing the computational cost of our
approach would be to pre select algorithms  features  and problem instances based on the
techniques proposed by hoos et al         or based on the collaborative filtering approach
by misir and sebag         finally  we plan to investigate to which extent autofolio
can configure algorithm selection systems for selecting parallel portfolios  lindauer et al  
    a  to exploit the increasing availability of parallel computing resources 
overall  we believe that the automated configuration of algorithm selection systems improves the performance and versatility of those systems across a broad range of application
   

filindauer  hoos  hutter    schaub

domains  our autofolio approach also facilitates future improvements  by making it easier to realize and assess the performance potential inherent in new design choices for the
various components of an algorithm selection system  our open source implementation of
autofolio is available at www ml aad org autofolio  

acknowledgements
m  lindauer was supported by the dfg  german research foundation  under emmy
noether grant hu          and project scha          h  hoos by an nserc discovery
grant  f  hutter by the dfg under emmy noether grant hu          and t  schaub
by the dfg under project scha          respectively  this work was performed on the
computational resource bwunicluster funded by the ministry of science  research and arts
and the universities of the state of baden wurttemberg  germany  within the framework
program bwhpc 

references
abrame  a     habet  d          on the extension of learning for max sat  in endriss  u  
  leite  j   eds    proceedings of the  th european starting ai researcher symposium
 stairs     vol      of frontiers in artificial intelligence and applications  pp   
    ios press 
amadini  r   gabbrielli  m     mauro  j          sunny  a lazy portfolio approach for
constraint solving  theory and practice of logic programming                   
ansotegui  c   malitsky  y     sellmann  m          maxsat by improved instance specific
algorithm configuration  in brodley  c     stone  p   eds    proceedings of the twentyeighth national conference on artificial intelligence  aaai     pp            aaai
press 
ansotegui  c   sellmann  m     tierney  k          a gender based genetic algorithm
for the automatic configuration of algorithms  in gent  i   ed    proceedings of the
fifteenth international conference on principles and practice of constraint programming  cp     vol       of lecture notes in computer science  pp          springerverlag 
bergstra  j   bardenet  r   bengio  y     kegl  b          algorithms for hyper parameter
optimization  in shawe taylor  j   zemel  r   bartlett  p   pereira  f     weinberger 
k   eds    proceedings of the   th international conference on advances in neural
information processing systems  nips     pp           
biere  a          lingeling  plingeling and treengeling entering the sat competition      
in balint  a   belov  a   heule  m     jarvisalo  m   eds    proceedings of sat competition       solver and benchmark descriptions  vol  b        of department of
computer science series of publications b  pp        university of helsinki 
bischl  b   kerschke  p   kotthoff  l   lindauer  m   malitsky  y   frechette  a   hoos  h  
hutter  f   leyton brown  k   tierney  k     vanschoren  j       a   www aslib net 
   

fiautofolio  an automatically configured algorithm selector

bischl  b   kerschke  p   kotthoff  l   lindauer  m   malitsky  y   frechette  a   hoos 
h   hutter  f   leyton brown  k   tierney  k     vanschoren  j       b   aslib  a
benchmark library for algorithm selection  computing research repository  corr  
abs            
chiarandini  m   fawcett  c     hoos  h          a modular multiphase heuristic solver
for post enrolment course timetabling  in proceedings of the seventh international
conference on the practice and theorysy of automated timetabling  patat    pp 
   
collautti  m   malitsky  y   mehta  d     osullivan  b          snnap  solver based
nearest neighbor for algorithm portfolios  in blockeel  h   kersting  k   nijssen 
s     zelezny  f   eds    machine learning and knowledge discovery in databases
 ecml pkdd     vol       of lecture notes in computer science  pp         
springer verlag 
dickerson  j     sandholm  t          futurematch  combining human value judgments
and machine learning to match in dynamic environments  in bonet  b     koenig 
s   eds    proceedings of the twenty nineth national conference on artificial intelligence  aaai     pp          aaai press 
eggensperger  k   feurer  m   hutter  f   bergstra  j   snoek  j   hoos  h     leyton brown 
k          towards an empirical foundation for assessing bayesian optimization of
hyperparameters  in nips workshop on bayesian optimization in theory and practice 
fawcett  c     hoos  h       a   www cs ubc ca labs beta projects ablation  
fawcett  c     hoos  h       b   analysing differences between algorithm configurations
through ablation  journal of heuristics      
feurer  m   springenberg  t     hutter  f          initializing bayesian hyperparameter
optimization via meta learning  in bonet  b     koenig  s   eds    proceedings of the
twenty nineth national conference on artificial intelligence  aaai     pp      
      aaai press 
gebser  m   kaminski  r   kaufmann  b   ostrowski  m   schaub  t     schneider  m 
     a   potassco  the potsdam answer set solving collection  ai communications 
               
gebser  m   kaminski  r   kaufmann  b   schaub  t   schneider  m     ziller  s       b  
a portfolio solver for answer set programming  preliminary report  in delgrande  j  
  faber  w   eds    proceedings of the eleventh international conference on logic
programming and nonmonotonic reasoning  lpnmr     vol       of lecture notes
in computer science  pp          springer verlag 
gebser  m   kaufmann  b     schaub  t          conflict driven answer set solving  from
theory to practice  artificial intelligence                
gent  i   jefferson  c   kotthoff  l   miguel  i   moore  n   nightingale  p     petrie  k 
        learning when to use lazy learning in constraint solving  in coelho  h   studer 
r     wooldridge  m   eds    proceedings of the nineteenth european conference on
artificial intelligence  ecai     pp          ios press 
   

filindauer  hoos  hutter    schaub

gomes  c     selman  b          algorithm portfolios  artificial intelligence            
     
hall  m   frank  e   holmes  g   pfahringer  b   reutemann  p     witten  i          the
weka data mining software  an update  sigkdd explorations               
hoos  h   kaminski  r   lindauer  m     schaub  t          aspeed  solver scheduling via
answer set programming  theory and practice of logic programming             
hoos  h   kaufmann  b   schaub  t     schneider  m          robust benchmark set selection for boolean constraint solvers  in pardalos  p     nicosia  g   eds    proceedings
of the seventh international conference on learning and intelligent optimization
 lion     vol       of lecture notes in computer science  pp          springerverlag 
hoos  h   lindauer  m     schaub  t          claspfolio    advances in algorithm selection
for answer set programming  theory and practice of logic programming             
huberman  b   lukose  r     hogg  t          an economic approach to hard computational
problems  science            
hurley  b   kotthoff  l   malitsky  y     osullivan  b          proteus  a hierarchical
portfolio of solvers and transformations  in simonis  h   ed    proceedings of the
eleventh international conference on integration of ai and or techniques in constraint programming  cpaior     vol       of lecture notes in computer science 
pp          springer verlag 
hutter  f   babic  d   hoos  h     hu  a          boosting verification by automatic tuning
of decision procedures  in oconner  l   ed    formal methods in computer aided
design  fmcad     pp        ieee computer society press 
hutter  f   hoos  h     leyton brown  k          automated configuration of mixed integer
programming solvers  in lodi  a   milano  m     toth  p   eds    proceedings of the
seventh international conference on integration of ai and or techniques in constraint programming  cpaior     vol       of lecture notes in computer science 
pp          springer verlag 
hutter  f   hoos  h     leyton brown  k          sequential model based optimization
for general algorithm configuration  in coello  c   ed    proceedings of the fifth
international conference on learning and intelligent optimization  lion     vol 
     of lecture notes in computer science  pp          springer verlag 
hutter  f   hoos  h     leyton brown  k          an efficient approach for assessing
hyperparameter importance  in xing  e     jebara  t   eds    proceedings of the   th
international conference on machine learning   icml     vol      pp         
omnipress 
hutter  f   hoos  h     leyton brown  k       a   www ml aad org smac 
hutter  f   hoos  h     leyton brown  k       b   www ml aad org fanova 
hutter  f   hoos  h   leyton brown  k     stutzle  t          paramils  an automatic
algorithm configuration framework  journal of artificial intelligence research     
       
   

fiautofolio  an automatically configured algorithm selector

hutter  f   hoos  h  h     leyton brown  k          identifying key algorithm parameters
and instance features using forward selection  in pardalos  p     nicosia  g   eds   
proceedings of the seventh international conference on learning and intelligent optimization  lion     vol       of lecture notes in computer science  pp         
springer verlag 
hutter  f   lindauer  m   balint  a   bayless  s   hoos  h     leyton brown  k          the
configurable sat solver challenge  cssc   artificial intelligence  under review 
hutter  f   xu  l   hoos  h     leyton brown  k          algorithm runtime prediction 
methods and evaluation  artificial intelligence             
janota  m   klieber  w   marques silva  j     clarke  e          solving qbf with counterexample guided refinement  in cimatti  a     sebastiani  r   eds    proceedings
of the fifteenth international conference on theory and applications of satisfiability testing  sat     vol       of lecture notes in computer science  pp         
springer verlag 
kadioglu  s   malitsky  y   sabharwal  a   samulowitz  h     sellmann  m          algorithm selection and scheduling  in lee  j   ed    proceedings of the seventeenth international conference on principles and practice of constraint programming  cp    
vol       of lecture notes in computer science  pp          springer verlag 
kadioglu  s   malitsky  y   sellmann  m     tierney  k          isac   instance specific
algorithm configuration  in coelho  h   studer  r     wooldridge  m   eds    proceedings of the nineteenth european conference on artificial intelligence  ecai    
pp          ios press 
kotthoff  l          llama  leveraging learning to automatically manage algorithms 
computing research repository  corr   abs           
kotthoff  l          algorithm selection for combinatorial search problems  a survey  ai
magazine       
kotthoff  l          icon challenge on algorithm selection  
icon fet eu challengeas 

http   challenge 

kotthoff  l   gent  i     miguel  i          an evaluation of machine learning in algorithm
selection for search problems  ai communications                 
lim  b   van den briel  m   thiebaux  s   backhaus  s     bent  r          hvac aware
occupancy scheduling  in bonet  b     koenig  s   eds    proceedings of the twentynineth national conference on artificial intelligence  aaai     pp          aaai
press 
lindauer  m   hoos  h     hutter  f       a   from sequential algorithm selection to parallel
portfolio selection  in dhaenens  c   jourdan  l     marmion  m   eds    proceedings of the nineth international conference on learning and intelligent optimization
 lion     lecture notes in computer science  pp       springer verlag 
lindauer  m   hoos  h   hutter  f     schaub  t       b   autofolio  algorithm configuration for algorithm selection  in proceedings of the workshops at twenty nineth
national conference on artificial intelligence  aaai    
   

filindauer  hoos  hutter    schaub

lindauer  m   hoos  h     schaub  t       c   www cs uni potsdam de claspfolio  
lopez ibanez  m   dubois lacoste  j   stutzle  t     birattari  m          the irace package 
iterated race for automatic algorithm configuration  tech  rep   iridia  universite
libre de bruxelles  belgium 
lopez ibanez  m     stutzle  t          automatic configuration of multi objective aco
algorithms  in dorigo  m   m birattari  caro  g  d   doursat  r   engelbrecht 
a  p   floreano  d   gambardella  l   gro  r   sahin  e   sayama  h     stutzle 
t   eds    proceedings of the seventh international conference on swarm intelligence
 ants     lecture notes in computer science  pp         springer verlag 
malitsky  y   mehta  d     osullivan  b          evolving instance specific algorithm
configuration  in helmert  m     roger  g   eds    proceedings of the sixth annual
symposium on combinatorial search  socs     aaai press 
malitsky  y   sabharwal  a   samulowitz  h     sellmann  m          parallel sat solver
selection and scheduling  in milano  m   ed    proceedings of the eighteenth international conference on principles and practice of constraint programming  cp    
vol       of lecture notes in computer science  pp          springer verlag 
malitsky  y   sabharwal  a   samulowitz  h     sellmann  m       a   algorithm portfolios
based on cost sensitive hierarchical clustering  in rossi  f   ed    proceedings of the
  rd international joint conference on artificial intelligence  ijcai     pp     
    
malitsky  y   sabharwal  a   samulowitz  h     sellmann  m       b   boosting sequential solver portfolios  knowledge sharing and accuracy prediction  in pardalos  p  
  nicosia  g   eds    proceedings of the seventh international conference on learning and intelligent optimization  lion     vol       of lecture notes in computer
science  pp          springer verlag 
maratea  m   pulina  l     ricca  f          a multi engine approach to answer set programming  theory and practice of logic programming             
mascia  f   lopez ibanez  m   dubois lacoste  j     stutzle  t          grammar based
generation of stochastic local search heuristics through automatic algorithm configuration tools  computers   or             
misir  m     sebag  m          algorithm selection as a collaborative filtering problem 
tech  rep   inria   lri  universite paris sud xi 
omahony  e   hebrard  e   holland  a   nugent  c     osullivan  b          using casebased reasoning in an algorithm portfolio for constraint solving  in bridge  d   brown 
k   osullivan  b     sorensen  h   eds    proceedings of the nineteenth irish conference on artificial intelligence and cognitive science  aics    
pedregosa  f   varoquaux  g   gramfort  a   michel  v   thirion  b   grisel  o   blondel 
m   prettenhofer  p   weiss  r   dubourg  v   vanderplas  j   passos  a   cournapeau 
d   brucher  m   perrot  m     duchesnay  e          scikit learn  machine learning
in python  journal of machine learning research               
pulina  l     tacchella  a          a self adaptive multi engine solver for quantified boolean
formulas  constraints                
   

fiautofolio  an automatically configured algorithm selector

rice  j          the algorithm selection problem  advances in computers            
roussel  o          controlling a solver execution with the runsolver tool  journal on
satisfiability  boolean modeling and computation            
smith miles  k          cross disciplinary perspectives on meta learning for algorithm
selection  acm computing surveys         
snoek  j   larochelle  h     adams  r  p          practical bayesian optimization of machine learning algorithms  in bartlett  p   pereira  f   burges  c   bottou  l    
weinberger  k   eds    proceedings of the   th international conference on advances
in neural information processing systems  nips     pp           
sobol  i          sensitivity estimates for nonlinear mathematical models  mathematical
modeling and computational experiment                
tamura  n   taga  a   kitagawa  s     banbara  m          compiling finite linear csp
into sat  constraints                 
thornton  c   hutter  f   hoos  h     leyton brown  k          auto weka  combined
selection and hyperparameter optimization of classification algorithms  in i dhillon 
koren  y   ghani  r   senator  t   bradley  p   parekh  r   he  j   grossman  r    
uthurusamy  r   eds    the   th acm sigkdd international conference on knowledge discovery and data mining  kdd     pp          acm press 
tierney  k     malitsky  y          an algorithm selection benchmark of the container premarshalling problem  in dhaenens  c   jourdan  l     marmion  m   eds    proceedings of the nineth international conference on learning and intelligent optimization
 lion     lecture notes in computer science  pp        springer verlag 
vallati  m   fawcett  c   gerevini  a   hoos  h     saetti  a          automatic generation of
efficient domain optimized planners from generic parametrized planners  in helmert 
m     roger  g   eds    proceedings of the sixth annual symposium on combinatorial
search  socs     aaai press 
xu  l   hoos  h     leyton brown  k          hydra  automatically configuring algorithms for portfolio based selection  in fox  m     poole  d   eds    proceedings of the
twenty fourth national conference on artificial intelligence  aaai     pp         
aaai press 
xu  l   hutter  f   hoos  h     leyton brown  k          satzilla  portfolio based algorithm selection for sat  journal of artificial intelligence research             
xu  l   hutter  f   hoos  h     leyton brown  k          hydra mip  automated algorithm configuration and selection for mixed integer programming  in rcra workshop
on experimental evaluation of algorithms for solving problems with combinatorial
explosion at the international joint conference on artificial intelligence  ijcai  
xu  l   hutter  f   hoos  h     leyton brown  k       a   evaluating component solver
contributions to portfolio based algorithm selectors  in cimatti  a     sebastiani 
r   eds    proceedings of the fifteenth international conference on theory and applications of satisfiability testing  sat     vol       of lecture notes in computer
science  pp          springer verlag 
   

filindauer  hoos  hutter    schaub

xu  l   hutter  f   shen  j   hoos  h     leyton brown  k       b   satzilla      improved
algorithm selection based on cost sensitive classification models  in balint  a   belov 
a   diepold  d   gerber  s   jarvisalo  m     sinz  c   eds    proceedings of sat
challenge       solver and benchmark descriptions  vol  b        of department of
computer science series of publications b  pp        university of helsinki 
yun  x     epstein  s          learning algorithm portfolios for parallel execution  in
hamadi  y     schoenauer  m   eds    proceedings of the sixth international conference on learning and intelligent optimization  lion     vol       of lecture notes
in computer science  pp          springer verlag 

   

fi