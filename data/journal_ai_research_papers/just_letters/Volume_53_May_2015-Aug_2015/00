journal artificial intelligence research               

submitted        published      

coactive learning
pannaga shivaswamy

pshivaswamy linkedin com

linkedin corporation
     stierlin ct
mountain view  ca        usa

thorsten joachims

tj cs cornell edu

department computer science
cornell university
ithaca  ny        usa

abstract
propose coactive learning model interaction learning system
human user  common goal providing results maximum utility
user  interactions coactive learning model take following form 
step  system  e g  search engine  receives context  e g  query  predicts object
 e g  ranking   user responds correcting system necessary  providing slightly
improved necessarily optimal object feedback  argue preference
feedback inferred large quantity observable user behavior  e g   clicks
web search   unlike optimal feedback required expert model cardinal
valuations required bandit learning  despite relaxed requirements feedback 
show possible adapt many existing online learning algorithms
coactive

framework  particular  provide algorithms achieve o      average regret
terms cardinal utility  even though learning algorithm never observes cardinal utility
values directly  provide algorithm o log t   t   average regret
case  strongly convex loss functions  extensive empirical study demonstrates
applicability model algorithms movie recommendation task  well
ranking web search 

   introduction
wide range systems use today  interaction human system takes
following form  user issues command  e g  query  receives possibly
structured result response  e g  ranking   user interacts results  e g 
clicks   thereby providing implicit feedback users utility function  three
examples systems typical interaction patterns 
web search  response query  search engine presents ranking  a  b  c  d      
observes user clicks documents b d 
movie recommendation  online service recommends movie user  however 
user rents movie b browsing collection 
machine translation  online machine translator used translate wiki page
language b  system observes corrections user makes translated text 
c
    
ai access foundation  rights reserved 

fishivaswamy   joachims

examples  user provides feedback results
system  however  feedback incremental improvement  necessarily
optimal result  example  clicks web search results infer
user would preferred ranking  b  d  a  c       one presented  however 
unlikely best possible ranking  similarly recommendation example 
movie b preferred movie a  may even better movies
user find browsing  machine translation example  corrected text need best possible translation language language b 
three examples  algorithm typically receives slightly improved result user
feedback  necessarily optimal prediction cardinal utilities  conjecture
many applications fall schema  ranging news filtering personal
robotics 
paper  propose coactive learning model system user interactions 
formalize coactive learning general model interaction learning system
user  define suitable notion regret  validate key modeling assumption
namely whether observable user behavior provide valid feedback model
user study web search  new model viewed cooperative learning process
system user  parties aim optimize utility lack means
achieve goal own  specifically   boundedly rational  user computationally
limited maximizing utility space alternatives  system limited
well knows users utility function 
proposed online learning framework differs significantly existing online learning
models terms observed feedback  see related works section comparison  
strength proposed framework possible derive wide range coactive
learning algorithms adapting existing online algorithms convex optimization 
provide template coactive learning algorithms show several instances
template paper  case  prove worst case analysis
algorithm carries conventional online learning framework coactive
learning despite differences two models in particular  cases linear
utility models convex cost functions show o      regret bounds matching
lower bound  show regret bound improved second order
algorithm strongly convex functions  learning algorithms perform structured output
prediction  see bakir  hofmann  scholkopf  smola  taskar    vishwanathan        thus
applied wide variety problems  study several interesting extensions
framework using batch updates  expected feedback  exponentiated learning
algorithm  finally  provide extensive empirical evaluations algorithms movie
recommendation web search task  showing algorithms highly efficient
effective practical settings 
rest paper organized follows  discuss related work section   
section   formally introduce coactive learning model motivate model
real world user study  present linear version algorithm along
several extensions section    section    detail general schema deriving
coactive learning algorithms regret bounds  particular  derive exponentiated gradient algorithm section      propose coactive learning algorithms
minimizing general convex losses  strongly convex losses sections         
 

ficoactive learning

empirical evaluation proposed framework algorithms done section  
conclude section    include proofs appendix 

   related works
coactive learning model bridges gap two forms feedback
well studied online learning  one side multi armed bandit model  e g  
auer  cesa bianchi  freund    schapire      b  auer  cesa bianchi    fischer      a  
algorithm chooses action observes utility  only  action 
side  utilities possible actions revealed case learning
expert advice  e g   cesa bianchi   lugosi      a   online convex optimization  zinkevich 
      hazan  agarwal    kale        online convex optimization bandit setting
 flaxman  kalai    mcmahan        continuous relaxations expert
bandit problems respectively  model  information two arms revealed
iteration  the one presented one receive feedback user  
sits expert bandit setting  closely related coactive learning
dueling bandits setting  yue  broder  kleinberg    joachims        yue   joachims 
       key difference arms chosen algorithm dueling
bandits setting  whereas one arms chosen user coactive learning
setting  model allows contextual information contextual bandits  langford  
zhang         however  arms problem structured objects rankings 
summary framework compares existing frameworks shown
table    types feedback explored literature  example 
multi class classification problems  algorithm makes prediction based
context  feedback received whether prediction correct wrong opposed
actual label  crammer   gentile        kakade  shalev shwartz    tewari        
seen observing partial feedback  as opposed actual cardinal feedback 
bandit problem 
pointed above  coactive learning algorithms conventional online learning
algorithms operate different types environments  coactive learning algorithms present
object observe another object feedback  online convex learning algorithms
pick vector step observe gradient vector feedback  despite
contrast online learning coactive learning  two algorithms presented
paper closely related work zinkevich        hazan et al 
        show possible adapt regret bounds algorithms
corresponding regrets bounds coactive learning  heart algorithms
analysis well known idea  polyak   tsypkin        descent algorithms
necessarily need know gradients  vector positive inner product
gradient expectation suffices 
feedback coactive learning takes form preference  different
ordinal regression ranking  ordinal regression  e g   crammer   singer        assumes
training examples  x  y   rank  coactive learning model  absolute ranks
never revealed  closely related learning pairs examples  herbrich  graepel    obermayer        freund  iyer  schapire    singer        chu   ghahramani        
since circumvents need absolute ranks  relative orderings required  vari 

fishivaswamy   joachims

framework
bandits
experts
dueling bandits
coactive learning

algorithm
pull arm
pull arm
pull two arms
pull arm

feedback
observe cardinal reward arm pulled
observe cardinal rewards arms
observe feedback one better
observe another arm better

table    comparison different online learning frameworks 

ants pairwise ranking algorithms applied natural language processing
 haddow  arun    koehn        zhang  lei  barzilay  jaakkola    globerson       
image annotation  weston  bengio    usunier         however  existing approaches require
iid assumption typically perform batch learning  finally  large body
work ranking  see liu         approaches different coactive learning
require training data  x  y  optimal ranking query x  however 
draw upon structured prediction approaches ranking problems design
models 
coactive learning first proposed shivaswamy joachims         paper
serves journal extension paper  adding complete discussion batch updates
expected feedback  exponentiated gradient algorithm  o log t   t   algorithm
 strongly convex loss functions  substantially extended empirical evaluation 
since then  coactive learning applied intrinsically diverse retrieval  raman 
shivaswamy    joachims         learning ranking function click feedback  raman 
joachims  shivaswamy    schnabel         optimizing social welfare  raman   joachims 
       personal robotics  jain  wojcik  joachims    saxena         pattern discovery  boley 
mampaey  kang  tokmakov    wrobel         robotic monitoring  somers   hollinger 
       extended allow approximate inference  goetschalckx  fern    tadepalli        

   coactive learning model
introduce coactive learning model interaction  in rounds  learning
system  e g  search engine  human  search user  human learning
algorithm goal  of obtaining good results   round t  learning
algorithm observes context xt x  e g  search query  presents structured object
yt  e g  ranked list urls   utility yt user context xt x
described utility function u  xt   yt    unknown learning algorithm 
feedback human user returns improved object yt  e g  reordered list urls  
i e   
u  xt   yt     u  xt   yt   

   

object yt exists  fact  allow violations     formally
model user feedback section     
process user generates feedback yt understood
approximately utility maximizing action  user modeled boundedly rational
   improvements strict  margin  clear section     

 

ficoactive learning

agent  particular  user selects feedback object yt approximately maximizing
utility user defined subset yt possible y 
yt   argmaxyy u  xt   y 

   

approximately boundedly rational user may employ various tools  e g   query
reformulations  browsing  construct subset perform search  importantly 
however  feedback yt typically optimal label defined as 
yt    argmaxyy u  xt   y  

   

way  coactive learning covers settings user cannot manually optimize
argmax full  e g  produce best possible ranking web search  
difficulty expressing bandit style cardinal rating u  xt   yt   yt consistent manner 
puts preference feedback yt stark contrast supervised learning approaches
require  xt   yt    even importantly  model implies reliable preference feedback     derived observable user behavior  i e   clicks  
demonstrate section     web search  conjecture similar feedback strategies
exist many application settings  e g   jain et al         boley et al         somers  
hollinger        goetschalckx et al          especially users assumed act
approximately boundedly rational according u  
despite weak preference feedback  aim algorithm nevertheless present
objects utility close optimal yt   whenever  algorithm presents
object yt context xt   say suffers regret u  xt   yt   u  xt   yt   time
step t  formally  consider average regret suffered algorithm steps
follows 
regt  


 x
 u  xt   yt   u  xt   yt     


   

t  

goal learning algorithm minimize regt   thereby providing human
predictions yt high utility  note  however  cardinal value u never observed
learning algorithm  u revealed ordinally preferences     
    quantifying preference feedback quality
provide theoretical guarantees regret learning algorithm coactive
setting  need quantify quality user feedback  note quantification
tool theoretical analysis  prerequisite parameter algorithm  quantify
feedback quality much improvement provides utility space  simplest case 
say user feedback strictly  informative following inequality satisfied 
u  xt   yt   u  xt   yt    u  xt   yt   u  xt   yt    

   

inequality         unknown parameter  feedback utility
yt higher yt fraction maximum possible utility range u  xt   yt  
u  xt   yt    term right hand side inequality ensures user feedback
 

fishivaswamy   joachims

yt better yt   better margin  u  xt   yt  u  xt   yt     violations
feedback model allowed introducing slack variables   
u  xt   yt   u  xt   yt      u  xt   yt   u  xt   yt     

   

note restricted positive  negative well  refer
feedback model  informative feedback  note possible express
feedback quality using     appropriate value   regret bounds
contain   quantifying extent  informative modeling assumption violated 
finally  consider even weaker feedback model positive utility
gain achieved expectation user actions 
et  u  xt   yt   u  xt   yt       u  xt   yt   u  xt   yt     

   

refer feedback expected  informative feedback  equation 
expectation users choice yt given yt context xt  i e  
distribution pxt  yt  yt   dependent xt   
rest paper  use linear model utility function 
u  x  y    w   x  y  

   

w rn parameter vector unknown learning system users
  x rn known joint feature map known system that 
k x  y k   r 

   

x x y  note x structured objects 
    user study  preferences clicks
validate reliable preferences specified equation     indeed inferred
implicit user behavior  particular  focus preference feedback clicks
web search draw upon data user study  joachims  granka  pan  hembrooke 
radlinski    gay         study  subjects  undergraduate students  n      
asked answer    identical questions   informational    navigational using google
search engine  queries  result lists  clicks recorded  subject  queries
grouped query chains question    average  query chain contained    
queries     clicks result lists 
use following strategy infer ranking users clicks  prepend
ranking first query chain results user clicked throughout
whole query chain  assess whether u  x  y  indeed larger u  x  y  assumed
learning model  measure utility terms standard
measure retrieval quality
p   r x y i  
information retrieval  use dcg    x  y    i   log i     r x  y i  
relevance score i th document ranking  see manning  raghavan    schutze 
   strictly speaking  value slack variable depends choice definition utility 
however  brevity  explicitly show dependence notation 
   make slightly different assumption section     
   done manually  automated high accuracy  jones   klinkner        

 

ficumulative distribution function

coactive learning

 
   
   
   
   
   
   
   
   
   
 

normal condition
swapped condition
reversed condition
conditions
  

  

  

  

  
 
 
dcg x ybar  dcg x y 

 

 

 

 

figure    cumulative distribution utility differences presented ranking
click feedback ranking terms dcg    three experimental conditions
overall 
       get ground truth relevance assessments r x  d   five independent human assessors
 students  asked manually rank set results encountered query
chain  assessors given true answers navigational queries 
linearly normalize resulting ranks relative relevance score r x  d        
document 
evaluate whether feedback ranking indeed better ranking
originally presented  i e   dcg    x  y    dcg    x  y   figure   plots
cumulative distribution functions  cdfs  dcg    x  y  dcg    x  y  three
experimental conditions  well average conditions  cdfs shifted far
right    showing preference feedback strategy highly accurate
informative  focusing first average conditions  utility difference strictly
positive     queries  strictly negative      imbalance
significant  binomial sign test  p            among remaining     cases
dcg    difference zero      due    i e  click top   click  
note learning algorithm easily detect cases may explicitly eliminate
feedback  overall  shows implicit feedback indeed produce accurate
preferences 
remains shown whether reliability feedback affected
quality current prediction  i e   u  xt   yt    user study  users actually
received results retrieval quality degraded purpose  particular 
one third subjects received googles top    results reverse order  condition reversed  another third received rankings top two positions swapped  condition
swapped   figure   shows  find users provide accurate preferences across
substantial range retrieval quality  intuitively  worse retrieval system may make
harder find good results  makes easier baseline yt improve upon 
intuition formally captured definition  informative feedback  optimal value
vs  trade off  however  likely depend many application specific factors 
user motivation  corpus properties  query difficulty  following  therefore
present algorithms require knowledge   theoretical bounds hold
value   experiments explore large range  
 

fishivaswamy   joachims

algorithm   preference perceptron 
initialize w   
   
observe xt
present yt argmaxyy wt   xt   y 
obtain feedback yt
update  wt   wt    xt   yt    xt   yt  
end

   preference perceptron coactive learning
section  start presenting analyzing basic algorithm coactive learning model  call preference perceptron  algorithm     preference
perceptron maintains weight vector wt initialized    time step t 
algorithm observes context xt presents object maximizes wt   xt   y  
algorithm observes user feedback yt weight vector wt updated
direction  xt   yt    xt   yt   
although update preference perceptron appears similar standard perceptron multi class classification problems  key differences  first  standard
perceptron algorithm requires true label feedback  whereas much weaker feedback
suffices algorithm  second  standard analysis perceptron bounds
number mistakes made algorithm based margin radius examples 
contrast  analysis bounds different regret captures graded notion utility 
further  standard perceptron mistake bound  novikoff        contains r  kwk 
bound following theorem contains rkwk r defined     
theorem   average regret preference perceptron algorithm upper bounded 
       w follows 


  x
 rkw k
 
regt
 


t  

    

proof first  consider kwt    k    have 
wt    wt      wt  wt    wt    xt   yt    xt   yt   
    xt   yt    xt   yt       xt   yt    xt   yt  
wt  wt    r   r  t 
line one  simply used update rule algorithm    line two  used
fact wt    xt   yt    xt   yt      choice yt algorithm  
k x  y k r  further  update rule algorithm    have 
wt    w   wt  w     xt   yt    xt   yt     w
 


x

 u  xt   yt   u  xt   yt     

t  

 

    

ficoactive learning

use fact wt    w kw kkwt    k  cauchy schwarz inequality  
implies

x

 u  xt   yt   u  xt   yt     r kw k 
t  

 informative modeling user feedback     



x

 u  xt   yt   u  xt   yt   

t  


x


 r kw k 

t  

claimed result follows 
first term regret bound denotes quality feedback terms violation
 informative feedback  particular  user feedback strictly
 informative

  slack variables      vanish regt   o      
trivial design algorithms  with even better regret  strict  informative
assumption cardinality context set x finite  one interesting aspects
bound  theorem    subsequent results minimize
regret even context xt different every step  thus   x   could infinite
regret bound still holds 
note bound theorem   holds w         slacks
based corresponding w  
though user feedback modeled via  informative feedback  algorithm
require knowledge   plays role analysis 
far  characterized user behavior terms deterministic feedback actions 
however  bound expected regret suffices  weaker model expected informative feedback equation     applicable 
corollary   expected  informative feedback model  expected regret  over
user behavior distribution  preference perceptron algorithm upper bounded
follows 


e regt  

  x  rkw k
 
 



t  

    

corollary proved following argument theorem    taking
expectations user feedback 
e wt    wt        e wt  wt     e  wt    xt   yt    xt   yt    
  et    xt   yt    xt   yt       xt   yt    xt   yt   
e wt  wt      r   
above  e denotes expectation user feedback yt given yt context
xt   follows e wt    wt       t r   
 

fishivaswamy   joachims

algorithm   batch preference perceptron 
initialize w   
l 
s 
   
observe xt
present yt argmaxyy wl   xt   y 
obtain feedback yt
     k
p
update  wl   wl   tj s  xj   yj    xj   yj  
l l  
st
end
end

applying jensens inequality concave function   get 
q
 
e wt w   kw ke kwt k  kw k e wt  wt   
corollary follows definition expected  informative feedback 
    lower bound
show upper bound theorem   cannot improved general respect
scaling   following lemma  given coactive learning algorithm 
construct sequence examples
where  even     feedback  algorithm suffers

average regret       
lemma   coactive learning algorithm
linear utility  exist xt   objects
w regt steps       
proof consider problem            x    x rt   kxk       define
joint feature map  x  y    yx  consider contexts e            et ej
j th component equal one others equal zero  let y     
    yt
t 
sequence outputs



contexts
e
 
 
 
 
 
e
 
construct
w
 
 y
 
 

 

 
y              yt       construction kw k      let user feedback
tth step yt   choices  user feedback
always  informative    
  pt

since yt   yt   yet  regret algorithm t    w   et   yt   w   et   yt     
   t   
    batch update
preference perceptron stated algorithm   makes update every iteration 
applications  due high volumes feedback  might possible
update frequently  scenarios  natural consider variant algorithm  
makes update every k iterations  algorithm simply uses wt obtained
  

ficoactive learning

algorithm   generic template coactive learning algorithms
initialize w 
   
observe xt
present yt argmaxyy wt   xt   y 
obtain feedback yt
perform update wt using gradient w    xt   yt   xt   yt    obtain wt    
end
previous update next update  type updates shown algorithm   called
mini batch updates used distributed online optimization  dekel  giladbachrach  shamir    xiao         steps batch update algorithm shown
algorithm    easy show following regret bound batch updates 
lemma   average regret batch preference perceptron algorithm upper
bounded         w follows 


  x
 rkw k k

regt
 
 



t  
lemma implies mini batches slow learning factor equal
batch size  see section       empirically convergence substantially faster 

   deriving algorithms coactive learning
preference perceptron regret minimizes  defined eqn      
one point design space different regret definitions learning algorithms
coactive learning  section  outline general strategy deriving coactive
learning algorithms existing algorithms online optimization  furthermore 
demonstrate general notions regret meaningful feasible coactive
learning  derive coactive learning algorithms general convex  strongly convex
losses 
coactive learning algorithms derive section follow general template
outlined algorithm    initializing w    iteration context xt observed
algorithm presents yt maximizing current utility estimate represented wt  
feedback yt observed  algorithm simply takes gradient w    xt   yt  
 xt   yt    uses update standard online convex optimization algorithm
obtain wt   wt  
case  upper bound regret proposed algorithm derived
using following strategy  first  start notion regret suited
coactive learning  upper bound regret first reducing form
results standard online convex opimization regret bound applied 
gives regret bound original coactive algorithm turn  case  use
template algorithm derive specific algorithm  however  still provide self contained
proof  in appendix  clearly pointing used regret bound
corresponding online convex optimization algorithm 
  

fishivaswamy   joachims

algorithm   exponentiated preference perceptron
intialize w i n 
 s t
   
observe xt
present yt argmaxyy wt   xt   y 
obtain feedback yt

wt  
wti exp  i  xt   yt    xt   yt     zt   zt weights add
one 
end

    exponentiated preference perceptron
illustrate generic strategy deriving coactive learning algorithms  first derive
exponentiated gradient algorithm coactive learning used alternative
preference perceptron  exponentiated gradient algorithm inherits ability
learn quickly sparse weight vectors 
unlike additive updates preference perceptron  exponentiated gradient
algorithm summarized algorithm   performs multiplicative updates  exponentiated
algorithm closely related exponentiated algorithms classification  kivinen  
warmuth         start  initializes weights uniformly  subsequent update
step rate associated it  rate depends upper bound   norm
features  i e   k    k  s  time horizon   multiplicative
update  weights normalized sum one  steps algorithm repeat 
since updates multiplicative weights initially positive  wt guaranteed
remain positive orthant algorithm  note algoithm   assumed
know s  standard techniques  see cesa biachi   lugosi      b 
convert algorithm dependence   however  extensions
focus paper 
provide regret bound algorithm    regret bounds algorithm  
algorithm   depended    norm features  bound exponentiated
algorithm depends   norm features 
theorem   w rn kw k        w     expected  informative feedback average  expected  regret exponentiated preference perceptron upper bounded as 

  x
  log m s


regt
 
   


 
t  

e regt  


  x   log m s


 
   


 
t  

k x  y k  s 
  

ficoactive learning

proof start regret coactive learning algorithm defined     
regt  

 


 x
 u  xt   yt   u  xt   yt   

t  

x

 


 
 


 u  xt   yt   u  xt   yt     

t  

x


  x


t  

w   xt   yt  

t  





w   xt   yt  


  x

 


    

t  

equation  used definition  informative feedback defined
eqn       viewing algorithm   exponentiated online gradient descent algorithm 
easy derive following regret bound using techniques initially introduced kivinen
warmuth        



x
x


 
 wt   xt   yt    xt   yt    
 u  xt   yt   u  xt   yt        log n  s  
 
 
t  

t  

since could find specific bound literature  self contained proof provided
appendix a  proof  regt first upper bounded terms difference
kl w  wt     kl w  wt    telescoping argument used get result 
observing wt    xt   yt    xt   yt       get 

x
t  




 u  xt   yt   u  xt   yt      log n  s  
 
 

    

combining            obtain average regret bound  proof expected
regret bound analogous preference perceptron 
result theorem    result  theorem    bounds regret
terms noisein feedback  first term  additional terms converge zero
rate o       key difference theorem   regret bound
exponentiated algorithm scales logarithmically number features 
    norm w  advantageous optimal w sparse 
    convex preference perceptron
generalizing definition regret eqn       allow every time step
t   unknown  convex loss function ct   r r determines loss
ct  u  xt   yt   u  xt   yt    time based difference utility yt
optimal yt   functions ct assumed non increasing  non increasing assumption
ct based intuition loss higher u  xt   yt   farther
u  xt   yt    further  sub derivatives ct assumed bounded  formally  c t   
 g     r c t    denotes sub derivative ct     
vector w determines utility yt context xt assumed closed
  

fishivaswamy   joachims

algorithm   convex preference perceptron 
initialize w   
   
set  t
observe xt
present yt argmaxyy wt   xt   y 
obtain feedback yt
update  wt   wt     xt   yt    xt   yt   
project  wt   arg minub ku wt   k 
end
bounded convex set b whose diameter denoted  b   case convex losses 
consider following notion regret 


 x
 x

cregt   
ct  u  xt   yt   u  xt   yt   
ct    


t  

    

t  

bound       ct     minimum possible convex loss since u  xt   yt   u  xt   yt  
never greater zero definition yt   hence regret compares loss
algorithm best loss could achieved convex loss  note that 
case ct        definition regret reduces earlier definition regret
linear case  eqn       
algorithm   minimizes average convex loss  two differences
algorithm algorithm    first  rate associated update time
t  second  every update  resulting vector wt   projected back set b 
algorithm   closely related online convex optimization algorithm propsed
zinkevich         however  online convex optimization algorithm assumes
gradient loss  ct     observed iteration  algorithm doesnt observe
gradient directly  observes improved object yt presenting object
yt  
earlier regret bounds expressed terms slack variables   however 
following section  bounds expressed terms clipped version
slack variables defined t     max      
theorem   convex preference perceptron  informative feedback  nonincreasing convex losses ct    bounded sub derivative  have        
w b 



 g x   g
 b 
 b   r 
 
cregt
 
 
 

 


t  

    

similarly  expected  informative feedback  have 



 g x   g
 b 
 b   r 
 
e cregt  
 
 
 

 


t  
  

    

ficoactive learning

proof theorem provided appendix b  idea proof
first divide time steps two types depending
nature feedback 
pt
allows us upper bound cregt terms t    wt w      xt   yt    xt   yt    
term upper bounded following argument zinkevich        even
coactive learning framework 
definition cregt eqn        theorem upper bounds
average convex loss via minimum achievable loss quality feedback 
previous result  theorem     strict
 informative feedback  average loss approaches best achievable loss o       albeit larger constant factors 
case linear utility bounds theorem   theorem    sufficient
average slack variables zero achieve zero regret  however 
case convex losses  upper bound regret approaches zero average
clipped slack variables zero 
    second order preference perceptron
particular class convex functions  turns give much stronger
regret bounds general convex losses  improvement special class losses
parallels improvements online convex optimization general convex losses  zinkevich 
       strongly convex losses  hazan et al         
definition   convex function f   r  strongly convex points x
d  following condition satisfied fixed     
f  x  f  y    f  x    x y 


  y x     
 

    

f  x  denotes sub derivative x 
algorithm   shows second order preference perceptron  strongly convex losses 
previous algorithms  second order preference perceptron maintains
weight vector wt   step presenting yt based context xt still
previous algorithms  however  addition weight vector  maintains
additional matrix constructed outer product vector  xt   yt  
 xt   yt    update step projection steps involve shown
algorithm    algorithm   closely related online convex optimization algorithm
proposed hazan et al          however  pointed case algorithm   
algorithm observes user preference feedback step unlike online convex
optimization algorithms observe gradients  still possible prove regret bound
 strongly convex case  following result 
theorem   second order preference learning algorithm   expected   strongly
convex  non increasing functions ct   bounded sub derivatives  have 
 



x      g x   g b 
gn
 r
cregt
 
 
 
log
    
    
 t  


 t

t  
t  
 



 r
x     g x   g b 
gn
e cregt  
 
 
 
log
    
    
 t  


 t

t  

t  

  

fishivaswamy   joachims

algorithm   second order preference perceptron 
intialize w   
a 
 g 
   
observe xt
present yt argmaxyy wt   xt   y 
obtain feedback yt
at      xt   yt    xt   yt     xt   yt    xt   yt    
update  wt   wt   a 
  xt   yt    xt   yt   
project  wt     arg minwb  wt   w    wt   w 
end
where      initialization parameter  shown algorithm   
prove theorem appendix c  proof theorem    divide
time steps two types  starting this  possible upper bound cregt
form resulting terms upper bounded using similar arguments
online strongly convex optimization  hazan et al         
user feedback strictly  informative w b  first two
terms regret bound      result o  logt   scaling   however 
linear dependence dimensionality joint feature map regret bound
second order preference perceptron algorithm 
even though appears need invert matrix second order preference perceptron  avoided since updates rank one 
woodbury matrix inversion lemma  have 
     
a 
   at      xt   yt    xt   yt     xt   yt    xt   yt       

  a 
t 

   
a 
t    xt   yt    xt   yt     xt   yt    xt   yt    at 

         xt   yt    xt   yt     a 
t    xt   yt    xt   yt   

 

thus  practice  second order preference perceptron update
bt iteration  nevertheless  projection step obtain wt   involves solving
quadratically constrained quadratic program b ball fixed radius  still
takes o n     time  hence  second order preference perceptron computationally
demanding convex preference perceptron  show experiments 
second order preference perceptron might still quite useful low noise data 

   experiments
empirically evaluate coactive learning algorithms two real world datasets 
two datasets differ nature prediction feedback  first dataset 
algorithms operate structured objects  rankings  whereas second dataset  atomic
items  movies  presented received feedback 
  

ficoactive learning

    datasets user feedback models
first  provide detailed description two datasets used experiments  along this  provide details strategies used dataset
generating user feedback 
      structured feedback  web search
first dataset publicly available dataset yahoo   chapelle   chang       
learning rank web search  dataset consists query url feature vectors  denoted
xqi query q url i   relevance rating riq ranges zero  irrelevant 
four  perfectly relevant   pose ranking structured prediction problem  defined
joint feature map follows 
w   q  y   

 
x
w  xqyi
 
log i     

    

i  

equation  denotes ranking yi index url
placed position ranking  thus  measure considers top five urls
query q computes score based graded relevance  note utility
function defined via feature map analogous dcg    see  manning et al        
replacing relevance label linear prediction based features 
query qt time step t  coactive learning algorithms present ranking ytq
maximizes wt   qt   y   note merely amounts sorting documents
scores wt  xqi   done efficiently  utility regret eqn       based
p
definition utility w   q  y  given t  tt   w    qt   yqt    qt   yqt     yqt
denotes optimal ranking respect w   consider best least
squares fit relevance labels features using entire dataset  obtain
yqt eqn     is  yqt   argmaxyy w   qt   y   experiments  query
ordering randomly permuted twenty times report average standard error
results 
used following two user models generating simulated user feedback
experiments  first feedback model idealized version feedback whereas second
feedback based directly relevance labels available dataset 
strict  informative feedback  model  user assumed provide
strictly  informative feedback given value  i e   slacks zero   given predicted ranking yt   user would go list found five urls that 
placed top list  resulting yt satisfied strictly  informative
feedback condition w r t  optimal w   model assumes user
access w hence idealized feedback 
noisy feedback depth k  feedback model  given ranking query 
user would go list inspecting top k urls  or urls list
shorter  specified k value  five urls highest relevance labels  riq  
placed top five locations user feedback  note produces noisy
feedback since linear model perfectly fit relevance labels dataset 
  

fishivaswamy   joachims

      item feedback  movie recommendation
contrast structured prediction problem previous dataset  considered
second dataset atomic predictions  namely movie recommendation  iteration 
movie presented user  feedback consists single movie well 
used movielens dataset grouplense org consists million ratings
     movies rated      users  movie ratings range one five 
randomly divided users two equally sized sets  first set used obtain
feature vector xj movie j using svd embedding method collaborative
filtering  see bell   koren        eqn         dimensionality feature vectors
regularization parameters chosen optimize cross validation accuracy
first dataset terms squared error  second set users  considered
problem recommending movies based movie features xj   experiment setup
simulates task recommending movies new user based movie features old
users 
tx
user second set  found best least squares approximation wi
j
users utility functions available ratings  enabled us impute utility
values movies explicitly
rated user  furthermore  allowed us
p
   x x    average difference
measure regret user t  tt   wi


utility recommended movie xt best available movie xt   denote
best available movie time xt obtained eqn     experiment 
user gave particular movie feedback  recommended movie
feedback movie removed set candidates subsequent recommendations 
experiments report  average  regret values averaged      users
test set 
simulate user behavior  considered following two feedback models
dataset 
strict  informative feedback  previous dataset  model  user
assumed provide strictly  informative feedback given value  i e   slacks
zero   given predicted movie yt   user assumed watch movie
already highest rating remaining corpus movies  not  user
picks another movie corpus lowest utility still satisfies strict informative assumption  model assumes user access w  
hence idealized feedback 
noisy feedback  feedback model  given movie y  user assumed
access either actual rating movies  when available  assumed
round imputed rating nearest legal rating value  used two sub strategies
user provides feedback  better feedback  user provides
smallest rating  actual rating rounded rating  strictly better
rating y  best feedback  user provides
highest rating  actual rating rounded rating  remaining corpus  could
multiple movies satisfying criteria  ties broken uniformly
random among movies  note feedback model results noisy feedback
due rounding movie ratings discrete values 
  

ficoactive learning

    preference perceptron
first set experiments  analyze empirical performance scaling behavior
basic preference perceptron algorithm variants 
      strong versus weak feedback
goal first experiment explore regret algorithm changed feedback quality  get feedback different quality levels   used strict  informative
feedback various values 
   

 

     
     
     

   

     
     
     

 

avg  util regret

avg  dcg regret

   
   
 
   

 

 

 

   
   

 
   
   
  

 

  

 

 

  

  

   
  

 

  



 

 

  

  

 

  



figure    regret based strict  informative feedback various values websearch  left  movie recommendation  right  
figure   shows results experiment three different values  overall  regret
typically substantially reduced tens hundreds iterations  expected 
regret       lower compared regret lower values  note  however 
difference two curves much smaller factor ten  note
differences less prominent case web search  strictly
 informative feedback strictly  informative feedback   so 
user feedback model  could providing much stronger feedback required
particular value  expected theoretical bounds  since user feedback
based linear model noise  utility regret approaches zero cases  note
show standard error plots  giving indication statistical significance 
left plots figure    standard errors high lower iterations become lower
iterations  plots rest paper  error bars small
may difficult visually identify 
rest paper  strict  informative feedback  consider      
unless explicitly mention otherwise 
      noisy feedback
previous experiment  user feedback based actual utility values computed
optimal w   next study regret changes noisy feedback user behavior
  

fishivaswamy   joachims

follow linear utility model  web search dataset  use noisy feedback
depths        movie dataset use noisy feedback
better best variant it 
   

 

depth   
depth   

   

better
best

 

avg  util regret

avg  util regret

   
 
   
   

 

 

 

   
 

   
   
  

 

  

 

 

  

  

   
  

 

  



 

 

  

  

 

  



figure    regret based noisy feedback web search  left  movie recommendation
 right  

results experiment shown figure    first observation make
case web search  regret values converge zero  similarly 
case movie recommendation regret values higher previous
experiment  results line theory shows regret converging
average slack variables user provide strict informative feedback
  interestingly  case web search average regret slightly higher
user goes greater depth providing feedback  due fact relevance
labels dataset noisy user maximizes  noisy  utility larger set
urls  selection  true  utility maximizers becomes less reliable  degrades
user feedback quality 
rest paper  web search consider noisy feedback depth    
case movie recommendation  consider better version noisy feedback
unless explicitly mention otherwise 
      batch updates
section  consider batch preference perceptron
algorithm  algorithm    

regret bound section     scales factor k strict  informative feedback 
update made every k iterations algorithm  verify whether
empirical performance scales suggested bound  web search movies 
considered strict  informative feedback noisy feedback  types
feedback  use batch perceptron algorithm various values k report
resulting average regret 
results experiments shown figure   figure    expected 
value k becomes smaller  regret converges faster  however  observe
  

ficoactive learning

   

 

k  
k     
k   
k   

   

k  
k   
k   
k   

 

avg  util regret

avg  util regret

   
 
   
   

 

 

 

   
 

   
   
  

 

  

 

 

  

  

   
  

 

  

 

 

  



  

 

  



figure    regret versus time based batch updates strict  informative feedback
web search  left  movie recommendation  right  

   
   
   
 

 

 

   

 

   

 

     
  

 

  

 

 

  

  

k  
k   
k   
k   

 

avg  util regret

avg  util regret

 

k  
k     
k   
k   

   
  

 

  



 

 

  

  

 

  



figure    regret versus time based batch updates noisy feedback web search
 left  movie recommendation  right  


empirical scaling k substantially better k factor suggested lemma   
results show feasibility using coactive learning algorithms systems
might impractical update every iteration 
      expected user feedback
user feedback deterministic experiments far  sub section  consider probabilistic feedback study behavior preference perceptron algorithm 
recall provided upper bound expected regret expected user feedback
corollary   
provide  informative feedback expectation  consider following strategy 
given object yt context xt   user would first generate deterministic feedback yt
  

fishivaswamy   joachims

following strict  informative feedback model         web search      
movie recommendation    addition  consider five randomly generated objects
feedback  put uniform probability mass randomly generated objects
remaining mass deterministic feedback user feedback still
 informative       expectation 
 

expct  feedback
det  feedback

   
   

expct  feedback
det  feedback

 

avg  util regret

avg  util regret

   
 
   
   

 

 

 

   
 
   
   
  

 

  

 

 

  

  

   
  

 

  



 

 

  

  

 

  



figure    expected feedback versus deterministic feedback web search  left  movie
recommendation  right  

results experiment shown figure    reference  plot
regret curve deterministic  informative feedback        seen
much difference deterministic expected feedback higher numbers
iterations  seen regret converges zero even  informative
feedback expectation suggested corollary   
      comparison ranking svm
compare algorithms several baselines  starting conventional
ranking svm  joachims        repeatedly trained  iteration  previous
qt
svm model used present ranking user  ysvm
   user returns ranking
qt
 ysvm   based strict  informative feedback one experiment based noisy
qt
qt
feedback other  pairs examples  qt   ysvm
   qt   ysvm
  used training
pairs ranking svm  note training ranking svm iteration would
prohibitive expensive  since involves solving quadratic program cross validating
regularization parameter c  thus  retrained svm whenever     examples
added training set  first training first iteration
one pair examples  starting random yq     c value fixed    
   pairs examples  reliable cross validation became possible 
   pairs training set  c value obtained via five fold cross   note that  case web search  user model provide strictly  informative larger
    

  

ficoactive learning

validation  c value determined  svm trained training
examples available time  svm model used present rankings
next retraining 
   

 

svm
pref  perceptron

   

svm
pref  perceptron

 

avg  util regret

avg  util regret

   
 
   
   

 
 
 

   
 
   
   
  

 

  

 

 

  

  

   
  

 

  

 

 

  

  

 

  





figure    preference perceptron versus ranking svm strict  informative feedback web search  left  movie recommendation  right  

 

svm
pref  perceptron

   

 

   

 

avg  util regret

avg  util regret

   

 

 

   

 

   

 

     
  

 

  

 

 

  

  

   
  

 

  

svm
pref  perceptron

 

 

  

  

 

  





figure    preference perceptron versus ranking svm noisy feedback web search
 left  movie recommendation  right  

results experiment shown figure   figure    case
strict  informative feedback  preference perceptron performed much better
svm movie recommendation  comparably web search  case
noisy feedback  preference perceptron performs significantly better svm
range datasets  took around    minutes run
preference perceptron experiment  took    hours run svm experiment
  

fishivaswamy   joachims

web dataset permutation dataset  similary  movie recommendation
task took around     seconds run preference perceptron user took
around     seconds run svm user  results show preference
perceptron perform par better svms tasks fraction
computational cost 
      comparison dueling bandit
second baseline  compare preference perceptron algorithm dueling
bandit approach yue joachims         step  dueling bandit algorithm
makes comparison vector w perturbed version w   in random
direction u w    w   u   results produced two weight vectors
assessed user techniques interleaving  radlinski  kurup    joachims 
       providing preference w w    preference feedback determines
update dueling bandits algorithm makes w  w preferred  retained
next round  w  preferred  small step length taken direction
perturbation u 
   

dueling bandit
pref  perceptron

   

   

   

   

   

   

avg  util regret

avg  util regret

   

 
   

 
   

   

   

   

   

   

   

   
  

 

  

 

 

  

  

   
  

 

  



dueling bandit
pref  perceptron

 

  

 

 

  

  

 

  



figure    preference perceptron versus dueling bandit web search  left plot based
strict  informative feedback  right plot shows noisy feedback 
first experiment web search  step  first obtained two ranked lists
based w w    features used obtain ranked lists identical
used preference perceptron  two rankings interleaved  interleaved
ranking presented user  first experiment  user provided strict informative feedback interleaved ranking  second experiment  user
provided noisy feedback  depending feedback  inferred two rankings preferred using team game method proposed radlinski et al         
w preferred tie  step taken  w  preferred 
step length taken direction u  regret dueling bandit algorithm
measured considering utility interleaved ranking  unlike preference
perceptron algorithm  dueling bandit algorithm two parameters     need
  

ficoactive learning

tuned  considered    values parameters   x  grid  simply chose
best parameter values dueling bandits algorithm hindsight 
results experiment shown figure    despite advantage setting
parameters best possible values  seen dueling bandit algorithm performs
significantly worse compared preference perceptron algorithm orders magnitude 
example  performance dueling bandit around        iterations matched
preference perceptron less     iterations types feedback 
surprising  since dueling bandit algorithm basically relies random vectors
determine direction step needs taken  coactive learning model 
user feedback provides  better random  direction guide algorithm 
 

dueling bandit
pref  perceptron

 

 

 

 

avg  util regret

avg  util regret

 

 

 

 

 

 

 

   
  

 

 

  

  

   
  

 

  



dueling bandit
pref  perceptron

 

 

  

  

 

  



figure     preference perceptron versus dueling bandit movie recommendation 
left plot based utility values whereas right plot shows results
rounded values 

similarly  conducted comparison dueling bandit algorithm
movie recommendation dataset  however  unlike web search experiment  dueling
bandit model somewhat unnatural dataset experimental setup  since interleaving two rankings natural whereas interleaving two items not  therefore consider
different setup  two movies obtained based w w  dueling bandit
algorithm  user feedback merely indicate two movies higher
rating  noisy case  user feedback based actual rating rounded rating  noise free case  user feedback based utility values  either case 
utility dueling bandit considered average utility two movies selected
comparison 
performance dueling bandit algorithm experiment shown figure     preference perceptron algorithm  regret curves strict  informative
feedback          better noisy feedback shows reference 
seen dueling bandit algorithm performs substantially worse compared
preference perceptron algorithm 
  

fishivaswamy   joachims

    exponentiated versus additive updates
experiment  compare exponentiated algorithm  algorithm    additive
preference perceptron algorithm  exponentiated algorithm  components
must non negative   obtained non negative follows 
 we  i


 

min     w  i  
  m 
max     w  im        m 

    

equation   we  i denotes ith component   moreover  modified
joint feature map exponentiated algorithm follows 
e



   x  y  i  

   x  y  i
 im
  x  y  im      m

    

modifications  non negative components moreover  easy verify   e  x  y    w   x  y   makes regret
exponentiated algorithm directly comparable regret additive algorithm 
exponentiated algorithm fixed rate parameter inversely depends
time horizon   large  small  situation  consider update
algorithm   

wt  
wti exp  i  xt   yt    xt   yt     zt  
since  small  approximate exponential term equation
first order approximation 
exp  i  xt   yt    xt   yt          i  xt   yt    xt   yt    
thus exponentiated updates resemble updates additive algorithm
normalization factor  despite normalization factor  empirically observed behavior two algorithms nearly identical  though exact   thus empirically
evaluated exponentiated algorithm variable rate parameter    s t time t 
note empirical result without formal theoretical guarantees variable
rate 
results experiment shown figure    figure    strict  informative
feedback noisy feedback respectively  seen exponentiated algorithm tends performs slightly better additive algorithm small number
iterations  time horizon becomes large  two algorithms seem comparable
performance cases 
    minimizing convex losses
section  empirically evaluate convex preference perceptron  algorithm   
second order preference perceptron  algorithm    
   put superscript e distinguish joint feature map w used experiments
exponentiated algorithm 

  

ficoactive learning

   

 

exponentiated
pref  perceptron

   

exponentiated
pref  perceptron

 

avg  util regret

avg  util regret

   
 
   
   

 

 

 

   
 

   
   
  

 

  

 

 

  

  

   
  

 

  

 

 

  



  

 

  



figure     exponentiated versus additive strict  informative feedback websearch  left  movie recommendation  right  

   

 

exponentiated
pref  perceptron

   

exponentiated
pref  perceptron

 

avg  util regret

avg  util regret

   
 
   
   

 

 

 

   
 

   
   
  

 

  

 

 

  

  

   
  

 

  



 

 

  

  

 

  



figure     exponentiated versus additive noisy feedback web search  left 
movie recommendation  right  

      convex perceptron versus second order algorithm
regret bounds section   show one get lower regret  strongly convex
functions using second order algorithm  first order convex perceptron applies
general convex functions  section  evaluate relative performance
first order second order algorithms empirically  purpose  considered
quadratic loss c          largest utility value possible  x  y 
w convex ball radius kw k  verified loss function  strongly
convex  b set     algorithms datasets 
  

fishivaswamy   joachims

second order
convex perceptron

    

   

    

   

    

   

    

   

    

   

   
  

 

 

  

second order
convex perceptron

   

util regret

quad regret

    

 

  

  

   
  

 

  

 

 

  

 

  



  

 

  



figure     cumulative regret convex perceptron second order convex perceptron web search 

    

   

second order
convex perceptron

   

    

util regret

quad  regret

     

second order
convex perceptron

     

   

   

    
  

     
   
  

 

 

  

  

   
  

 

  



 

 

  

  

 

  



figure     cumulative regret convex perceptron second order convex perceptron movie recommendation 

first set experiments  considered strict  informative feedback  ran
second order algorithm well convex preference perceptron algorithm   
value second order perceptron simply set one  recorded regt
cregt values methods  note regt corresponds utility
regret defined   
results experiment shown figure    figure     demonstrate
qualitative difference two algorithms  plot cumulative regret  i e 
regt cregt   figures  cumulative regret second order
algorithm linear log scale  shows convergence regret indeed
  

ficoactive learning

logarithmic  compared much slower convergence convex preference perceptron 
interestingly  even cumulative regret based raw utility values empirically shows
similar behavior  purely empirical result  since theoretically  o log t   t   average
regret holds strongly convex losses linear loss strongly convex 
 

  

weak     
strong     
weak      
strong      
weak      
strong      

 

util  regret

quad regret

  

 

weak     
strong     
weak      
strong      
weak      
strong      

  

 

  

 

  

 

  

 

 

 

  

 

  

 

  

  

 

  

    
  

 

  

 

 

  

 

  



  

 

  

 

  



figure     sensitivity second order preference perceptron algorithm parameter
value  

   

  

weak     
strong     
weak      
strong      
weak      
strong      

quad  regret

   

  

  

   

  
util  regret

   

  

weak     
strong     
weak      
strong      
weak      
strong      

   

   

  

   

  

   

  

   

  
   

  

   

 

  

 

 

  

  

 

  

 

  



  

 

  

 

 

  

  

 

  

 

  



figure     sensitivity second order preference perceptron algorithm parameter
value movie recommendation 

previous experiment  fixed value second order algorithm one 
study sensitivity second order algorithm value parameter 
figures       show regret values given number iterations swept
range values  dotted lines show performance convex preference
perceptron comparison  case web search  wide range parameter
  

fishivaswamy   joachims

values performance algorithm good  parameter takes extreme
value either side  performance algorithm deteriorates  range suitable
values much broader web search dataset movie recommendation 
interesting note algorithms performed empirically best     among
values tried 
    

     

second order
convex perceptron

     

   

second order
convex perceptron

util regret

quad regret

     
    
    
    

    
    

    
   
  

    

    
 

 

  

 

  

  

   
  

 

  

 

 

  

 

  

  

 

  





figure     strong convex versus weak convex noisy feedback web seach 

    

second order
convex perceptron

    

    

    

    

   

util regret

quad  regret

    

    

second order
convex perceptron

   
   

    
   

    

   

    
   
  

 

 

  

  

   
  

 

  



 

 

  

  

 

  



figure     strong convex versus weak convex noisy feedback movie recommendation 

tested convex algorithms noisy feedback  regret bounds contain slack terms right hand side  thus  user feedback  informative
  regret bounds second order algorithm first order algorithm
dominated slack variables  empirical performance two algorithms noisy feedback shown figures        case web search 
results second order algorithm first order algorithm nearly identi  

ficoactive learning

cal  however  case movie recommendation  still advantage
second order algorithm 
summary  second order algorithm performs substantially superior no noise
circumstances  presence noise feedback  two algorithms show
drastically different behaviors 

   conclusions
proposed coactive learning new model online learning preferences
especially suited implicit user feedback  unlike supervised learning approaches 
coactive learning algorithms require optimal labels  merely  noisy  feedback
improves prediction  model  cardinal utilities observed 
sits experts bandits settings  argue coactive learning
applicable wide range systems aim optimize based observable
user actions 
provide several algorithms provably optimize regret coactive learning
framework  empirically validate effectiveness proposed framework
web search ranking movie recommendation datasets simulations noisy
noise free feedback  recurring theme paper wide variety conventional
online learning algorithms converted coactive learning algorithms  despite
differences learning model itself  nature feedback notion regret 
conjecture many online learning algorithms could similarly converted
practically useful coactive learning algorithms 
coactive learning model  algorithms proposed  ability use weak
feedback observable user behavior offer wide range opportunities new learning
approaches application problems ranging natural language processing information retrieval robotics  several opportunities developing
algorithms coactive learning model  example  algorithm convex loss
minimization assume gradient convex losses bounded  however 
practical situations  convex loss minimized known apriori 
interesting research direction study whether algorithms utilize
gradient loss perform better either theoretically empirically  another question
whether better algorithms exist special cases linear utility model  lower
bound based argument dimensionally joint feature maps grow
given horizon   dimensionality joint feature map fixed 
interesting research question is  algorithms better regret proposed
algorithms 

acknowledgments
work funded part nsf awards iis          iis          iis         
work done pannaga shivaswamy postdoctoral associate cornell
university  thank peter frazier  bobby kleinberg  karthik raman  tobias schnabel
  

fishivaswamy   joachims

yisong yue helpful discussions  thank anonymous reviewers thoughtful
comments earlier version paper 

appendix a  proof theorem  
proof look kl divergence w wt evolves 
kl w  wt   kl w  wt      

 

n
x
i  
n
x


wi log wt  
 wti  

wi   i  xt   yt    xt   yt     log zt  

i  

  w    xt   yt    xt   yt    log zt   
    
p

second line  pulled log zt   sum since n
i   w      now  consider


last term equation  denoting  xt   yt    xt   yt   brevity 
have  definition 
 
n
x
log zt     log
wti exp i  
log

i  
n
x

wti   



 



 

 

     

i  



log     wt       
wt         

    

second line used fact exp x      x   x  x    rate ensures
 i      last line  used fact log     x  x  combing     
      get 
 w wt   

kl w  wt   kl w  wt    
     


adding inequalities  get 


 
x
x
kl w  wt   kl w  wt     x  
 w wt      xt   yt    xt   yt   
 
 

t  

t  



t  

kl w  w   
    t 


rearranging inequality  substituting value algorithm   
get 



x
x


 
 u  xt   yt   u  xt   yt   
wt   xt   yt    xt   yt        log n  s  
 
t  
t  



  log n  s  
 
 
  

ficoactive learning

above  used fact kl w  w    log n   since w  initialized uniformly  moreover  holders inequality  obtained
wt   xt   yt   kwt k   k xt   yt  k  s 
inequality along  informative feedback gives claimed result 

appendix b  proof theorem  
proof first  divide set time steps two different sets based nature
feedback 
    t   u  xt   yt   u  xt   yt           
j     t   u  xt   yt   u  xt   yt             
brevity denote  xt   a   xt   b  by   a  b  rest proof  start
considering following term single time step t 
ct  u  xt   yt   u  xt   yt    ct    

 
wt  yt   yt  

ct  u  xt   yt   u  xt   yt    ct


 

 
wt  yt   yt  
w  yt   yt  

ct
 ct




 

 
 w wt    yt   yt     w  yt   yt  


ct






 
 
 
 wt  yt   yt     w  yt   yt   g 


 wt   yt   yt     t   g 
j 
w   y  y  

inequalities  second line follows fact   ct   
non increasing  third line follows  informative feedback  eqn        fourth
line follows since function ct convex   obtain first term next inequality
 in either case  since c t     g     wt   yt   yt     choice yt
algorithm  second terms  in either case  obtained fact c t  w   yt   yt   
upper bounded t  g  step clipped version slack variables
needed proof  finally  w   yt   yt   either positive negative depending
feedback leads two different cases depending whether j 
   since context xt always clear  suppress notation brevity 
   convex function f   f  y  f  x   y x f    y  f    y  denotes sub derivative f y 

  

fishivaswamy   joachims

summing inequalities     get 

x

ct  w   yt   yt   

t  






gx


g


wt   yt   yt    

t  

x


x

ct    

t  

x

g


t 

t  

ti

 wt w     yt   yt    

t  

gx  
w  yt   yt  


g



x
t  

t   

gx  
w  yt   yt   


    

tj

p
obtained last line simply adding subtracting g tj w   yt   yt   
right side previous inequality  point  mostly follow proof
techniques online convex optimization  zinkevich        
bound first term right hand side       purpose  consider
following 
kwt   w k    kwt    yt   yt   w k 
  kwt w k    t  k yt   yt  k     t  wt w     yt   yt   

    

rearranging terms equation  get 
 
kwt w k 
 t
 

kwt w k 
 t

 wt w     yt   yt    

 

kwt   w k    k yt   yt  k 
 t
 
 
kwt   w k     t r 
 t

where  last line  used fact kwt   w k  kwt   w k  since wt  
projection wt   convex set b  which contains vector w   
bound first term      using following telescoping argument 


x
 
 
 
 
 
kwt w k
kwt   w k    t r
 t
 t
t  



x
x
 
 
 
 
kw  w k  

kwt w k     r 


  
 t  t 
t  
t  


x

 
 
 

 b   

 b     r       
  
 t  t 
t  


  

 b     r   
 
above  obtained second line simply rearranging terms expression
above 
line  used boundedness property set b  well

pton third
fact t  
     final line follows cancelling terms fact
      
  

ficoactive learning

now  consider third term right hand side      

w   yt   yt  
 
 
w   yt   yt      




first inequality follows  informative feedback  whereas second inequal

ity follows fact w   yt   yp
    definition yt   finally  bound     
 
g
follows trivial fact   ti  
obtain bound expected regret  consider convex loss step conditioned user behavior far 


wt   yt   yt  
et ct



 

 
et  w  yt   yt    
wt  yt   yt  
ct
et ct




 
 

w  yt   yt  
wt  yt   yt  
et ct
et ct



 
 
 

get  wt  yt   yt     w  yt   yt    


get  wt   yt   yt     t    
tj
ct  w   yt   yt   



second line follows definition expected  informative feedback
third line follows jensens inequality  obtain last line following argument
similar proof theorem    bound follows expected version
     

appendix c  proof theorem  
proof first  divide time steps two different sets based nature feedback 

    t   u  xt   yt   u  xt   yt           
j     t   u  xt   yt   u  xt   yt             
  

fishivaswamy   joachims

start considering single time step t  have 
ct  w   yt   yt    ct    
 

wt  yt   yt  
 

ct  w  yt   yt    ct

 
 

 
w  yt   yt  
wt  yt   yt  
ct
ct






 

   
 
w  yt   yt   t 
 w wt     yt   yt   t 
 w wt    yt   yt  
 
ct









 







 
 
 
 
 



wt   yt  yt  
 yt  

ti
  w  y
   w wt    yt  yt  
g






    





 
   
   y  y  
   y  y  



w
 w
w
 








   

j 
g


w   y  y  

inequalities  second line follows fact   ct   
non increasing  third line follows fact function ct    non increasing
following inequality follows definition t   
u  xt   yt   u  xt   yt      u  xt   yt   u  xt   yt    t   
fourth line follows strong convexity  last line follows line
reasoning proof theorem   
consider last term cases 


 
 


 

 


 




 




 

 
 w wt     yt   yt   t 





 
 
 w wt     yt   yt  
t 
t   w wt     yt   yt  

 

  
 


 
 
 w wt     yt   yt  
  w   yt   yt   t  wt   yt   yt   t 
   




 
  

 


 
 w wt     yt   yt  
t 
t 
t 
 

 
w  yt   yt    




  


 
 
 w wt     yt   yt  
 
    
    

 


equations  second third lines follow simple algebraic expansion
expression first line  fourth line follows definition  informative
feedback fact wt   yt   yt      last line follows fact
w   yt   yt     definition yt  
  

ficoactive learning

now  summing terms      substituting bound  get 


x

ct  w   yt   yt   

t  


x

ct    

t  

   
x w   yt   yt   pt    
 w wt     yt   yt  

t  
g
 
g


  
t  
ti
 


 

 
 
x  wt w    yt   yt    w wt    yt   yt  
g


 

t  
p
p
 
tt   t 
g tt   t 
gx  
 
w  yt   yt    
 

  

tj

  pt      g pt  
gx

 
 
t  
t  

 wt w    yt   yt  
 wt w    yt   yt  
 
 
 

 
  


x

wt   yt   yt   t 
 



 



t  

 
p
 yt  
above  obtained third inequality adding subtracting g tj w  y
 

 
obtain last line  used fact       since    

p      finally 
   y    
used argument similar proof theorem   bound g
w



tj

obtained factor two sum slacks term  point  use arguments
similar online convex optimization strongly convex losses  hazan et al  
      

next  consider  wt   w     wt   w   express interms wt at   

 wt   w     wt   w  
 
 
  wt a 
 yt   yt   w    wt  yt   yt   w  
 
  wt w     wt w      yt   yt    a 
 yt   yt     wt w    yt   yt  

  wt w     yt   yt   yt   yt     wt w      wt w    at   wt w  
 
   yt   yt    a 
 yt   yt       w wt    yt   yt  

rearranging terms equation  get 


 wt w     yt   yt   yt   yt     wt w  
 
 wt w    at   wt w    wt   w     wt   w      yt   yt    a 
 yt   yt   
  wt w     yt   yt  

  

fishivaswamy   joachims

identify term left hand side inequality occurs
expression would bound       therefore have 
 




x

t  

x

 wt w     yt   yt     wt w     yt   yt    




 wt w    at   wt w    wt   w     wt   w      yt   yt    a 
  byt   yt  

t  

 w  w    a   w  w    


x

 yt   yt    a 
 yt   yt  

t  

 b   

n
log




 r 



    

p
 
above  used fact tt    yt   yt    a 
 yt   yt   n log  r      
n dimens ionality  x  y  r upper bound norm joint
feature maps  i e  k x  y k   r  proof fact found hazan et al         

references
auer  p   cesa bianchi  n     fischer  p       a   finite time analysis multiarmed
bandit problem  machine learning                   
auer  p   cesa bianchi  n   freund  y     schapire  r       b   non stochastic multiarmed bandit problem  siam journal computing               
bakir  g  h   hofmann  t   scholkopf  b   smola  a   taskar  b     vishwanathan  s   eds   
        predicting structured data  mit press 
bell  r  m     koren  y          scalable collaborative filtering jointly derived neighborhood interpolation weights  icdm 
boley  m   mampaey  m   kang  b   tokmakov  p     wrobel  s          one click mining 
interactive local pattern discovery implicit preference performance learning  proceedings acm sigkdd workshop interactive data exploration
analytics  pp       
cesa bianchi  n     lugosi  g       a   prediction  learning  games  cambridge university press 
cesa bianchi  n     lugosi  g       b   prediction  learning  games  cambridge
university press  cambridge  uk 
chapelle  o     chang  y          yahoo  learning rank challenge overview  jmlr proceedings track          
chu  w     ghahramani  z          preference learning gaussian processes  icml 
crammer  k     singer  y          pranking ranking  nips 
  

ficoactive learning

crammer  k     gentile  c          multiclass classification bandit feedback using
adaptive regularization  proceedings   th international conference machine learning  icml  
dekel  o   gilad bachrach  r   shamir  o     xiao  l          optimal distributed online
prediction using mini batches  jmlr             
flaxman  a   kalai  a  t     mcmahan  h  b          online convex optimization
bandit setting  gradient descent without gradient  soda 
freund  y   iyer  r  d   schapire  r  e     singer  y          efficient boosting algorithm
combining preferences  journal machine learning research            
goetschalckx  r   fern  a     tadepalli  p          coactive learning locally optimal
problem solving   conference american association artificial intelligence
 aaai   pp           
haddow  b   arun  a     koehn  p          samplerank training phrase based machine
translation  proceedings sixth workshop statistical machine translation 
pp          edinburgh  scotland  association computational linguistics 
hazan  e   agarwal  a     kale  s          logarithmic regret algorithms online convex
optimization  machine learning                   
herbrich  r   graepel  t     obermayer  k          large margin rank boundaries
ordinal regression  advances large margin classifiers  mit press 
jain  a   wojcik  b   joachims  t     saxena  a          learning trajectory preferences
manipulators via iterative improvement  neural information processing systems
 nips   pp         
joachims  t          optimizing search engines using clickthrough data  acm sigkdd
conference knowledge discovery data mining  kdd   pp         
joachims  t   granka  l   pan  b   hembrooke  h   radlinski  f     gay  g          evaluating accuracy implicit feedback clicks query reformulations web
search  acm transactions information systems  tois          
jones  r     klinkner  k          beyond session timeout  automatic hierarchical
segmentation search topics query logs  cikm 
kakade  s  m   shalev shwartz  s     tewari  a          efficient bandit algorithms
online multiclass prediction  proceedings   th international conference
machine learning  icml  
kivinen  j     warmuth  m          exponentiated gradient versus gradient gradient descent linear predictors  journal information computation               
langford  j     zhang  t          epoch greedy algorithm multi armed bandits
side information  nips 
liu  t  y          learning rank information retrieval  foundations trends
information retrieval    
manning  c   raghavan  p     schutze  h          introduction information retrieval 
cambridge university press 
  

fishivaswamy   joachims

novikoff  a          convergence proofs perceptrons  proceedings symposium
mathematical theory automata  vol  xii  pp         
polyak  b     tsypkin  y          pseudogradient adaptation training algorithms 
automatic remote control           
radlinski  f   kurup  m     joachims  t          clickthrough data reflect retrieval quality   conference information knowledge management  cikm  
raman  k     joachims  t          learning socially optimal information systems
egoistic users  european conference machine learning  ecml   pp         
raman  k   joachims  t   shivaswamy  p     schnabel  t          stable coactive learning
via perturbation  international conference machine learning  icml   pp 
       
raman  k   shivaswamy  p     joachims  t          online learning diversify
implicit feedback  kdd 
shivaswamy  p     joachims  t          online structured prediction via coactive learning 
icml 
somers  t     hollinger  g          coactive learning human expert robotic
monitoring  rss workshop robotic monitoring 
weston  j   bengio  s     usunier  n          wsabie  scaling large vocabulary
image annotation  proceedings international joint conference artificial
intelligence  ijcai  
yue  y   broder  j   kleinberg  r     joachims  t          k armed dueling bandits
problem  colt 
yue  y     joachims  t          interactively optimizing information retrieval systems
dueling bandits problem  icml 
zhang  y   lei  t   barzilay  r   jaakkola  t     globerson  a          steps excellence  simple inference refined scoring dependency trees  proceedings
  nd annual meeting association computational linguistics  volume
   long papers   pp          baltimore  maryland  association computational
linguistics 
zinkevich  m          online convex programming generalized infinitesimal gradient
ascent  icml 

  


