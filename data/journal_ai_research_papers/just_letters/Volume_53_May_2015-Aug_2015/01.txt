journal of artificial intelligence research                

submitted        published      

learning relational event models from video
krishna s  r  dubba
anthony g  cohn
david c  hogg

krishna dubba gmail com
a g cohn leeds ac uk
d c hogg leeds ac uk

school of computing  university of leeds 
leeds  uk  ls   jt

mehul bhatt
frank dylla

bhatt informatik uni bremen de
dylla informatik uni bremen de

cognitive systems  sfb tr   spatial cognition
university of bremen  bremen        germany

abstract
event models obtained automatically from video can be used in applications ranging
from abnormal event detection to content based video retrieval  when multiple agents are
involved in the events  characterizing events naturally suggests encoding interactions as
relations  learning event models from this kind of relational spatio temporal data using
relational learning techniques such as inductive logic programming  ilp  hold promise 
but have not been successfully applied to very large datasets which result from video data 
in this paper  we present a novel framework remind  relational event model induction 
for supervised relational learning of event models from large video datasets using ilp 
efficiency is achieved through the learning from interpretations setting and using a typing
system that exploits the type hierarchy of objects in a domain  the use of types also
helps prevent over generalization  furthermore  we also present a type refining operator
and prove that it is optimal  the learned models can be used for recognizing events from
previously unseen videos  we also present an extension to the framework by integrating
an abduction step that improves the learning performance when there is noise in the input
data  the experimental results on several hours of video data from two challenging real
world domains  an airport domain and a physical action verbs domain  suggest that the
techniques are suitable to real world scenarios 

   introduction
with the advent of digital technology and wide availability of cameras and video recorders 
the quantity of video data has increased enormously over recent years  e g   youtube users
upload about     hours of video to the site every minute  youtube         this data is
semantically rich but there is a lack of algorithms to process and utilize this data effectively 
there are a number of applications that demand video processing  especially event modelling
and recognition  such as content based video search  robotics  automatic description of
activities  video surveillance etc  the main objective of our work is to provide a supervised
relational learning framework to learn high level human understandable event models and
use them to recognize events in video  supervised learning is the machine learning task of
inferring a model from labelled training data 
c
    
ai access foundation  all rights reserved 

fidubba  cohn  hogg  bhatt   dylla

video is considered as a sequence of images and the area of video analysis poses several
challenges  the most interesting aspect of video when compared to images is that objects
 or parts of objects  in video can be perceived to move in space over time  these changes of
state in the space dimension are interesting and we call them events if they satisfy certain
properties such as being sufficiently frequent and having sufficiently well defined boundaries
etc  an event can be a change of state of a single object  such as moving some parts of its
body  for example people waving their hands  or it can be an interaction between multiple
objects  by interactions  in this context  we mean the movement of all the objects relative
to their surroundings as well as relative to each other  for example  an interaction between
two objects might be both objects moving towards each other or one at rest and the other
moving away from it  before events can be recognized  we assume that the objects involved
have been detected and tracked from the source video  this is not a requirement in general
since some approaches  laptev        do not require detection of objects prior to event
detection 
in events involving multiple objects  interactions between the objects become a distinguishing factor in recognizing the event instance  capturing these interactions is the crux of
event modelling and recognition as it is our hypothesis that each event can be distinguished
by the interactions between the objects involved  some events might have more than one
interaction pattern that identifies the event  one way to capture these interactions is to
abstract the interactions into relations between the objects  in order to represent the interactions of objects in an abstract form  we can use relations between the objects that depend
on the spatial configuration or motion pattern of objects over a period of time  we call
these spatio temporal relations and in this paper we focus purely on the use of qualitative
spatial relations since these abstract away from the metric details of particular object trajectories and thus facilitate the recognition of interactions as being instances of some event
class  cohn et al          there is no unique way to represent interactions using qualitative
spatio temporal relations  and the best set of relations to use depends on the domain  kind
of data available  speed  orientation  size of moving objects  etc   and the objectives of the
task 
though each event class has distinguishing interaction patterns  there are two particular
challenges in event learning from examples expressed as qualitative spatio temporal relations  firstly  automatic object detection and tracking from video is not perfect and will
introduce errors into the relations  secondly  the same event may be performed in different
ways 
    overview of the framework
we follow the relational learning approach to the cognitive vision task of learning event
models from videos and using them for recognition  cohn et al         dubba  cohn   
hogg         the video data  sequence of images with pixel data  is converted to relational
facts involving qualitative spatio temporal relations using the tracking data of the objects
involved in the scenes  we use several qualitative spatial calculi to represent the video
data in relational form  event instances are annotated temporally and spatially though the
objects involved in each event are not delineated separately and these annotations are used
for obtaining the positive and negative examples of events  the learning procedure as well
  

filearning relational event models from video

as the extension of this procedure using abduction  explained in later sections  is applied
on this relational data to obtain the event models  these event models are in the form of
prolog rules that can be used as queries in the relational data from an unseen video  from
the answer substitutions we extract the spatial and temporal extensions of recognized event
instances 
the main contributions  of the paper are 
 a novel supervised relational learning framework remind for learning event models
from video and recognizing event instances using these models 
 an optimal type refinement operator for upward refinement of hypotheses that exploits a type hierarchy in a domain for finding better event models 
 an extended framework to integrate induction and abduction in an interleaved fashion
with an embedded spatial theory for improving the learning of event models 
 an evaluation of the framework on two real world video data sets  aircraft turn arounds
where the events include aircraft arrival  luggage loading and human interactions
where the events are common action verbs such as exchange  follow  dig etc  
though we concentrate on relational data obtained from tracking objects from video 
the principles and techniques in this work equally apply to spatio temporal relational data
acquired from non visual sources  e g  laser mapping  gps tracks  textual descriptions etc  

   related work
much of the work in event analysis  ivanov   bobick        medioni  cohen  bremond 
hongeng    nevatia        vu  bremond    thonnat        albanese  moscato  picariello 
subrahmanian    udrea        ryoo   aggarwal              morariu   davis         does
not involve learning of the models used  instead high level event models are hand coded
using different representations  nevatia  hobbs    bolles        hakeem  sheikh    shah 
      
techniques that are based on a similarity based metric in a space of low level pixel based
features such as local space time features  laptev        are frequently used for modelling
and recognizing events  these are generally more suitable for single agent events like human
activities based on motion  these kind of activities generally include a particular motion
signature with which an event can be recognized such as running  jumping  waving hands
etc  in some event recognition systems  hand coded high level event models are used on top
of the learned low level human activity models  ivanov   bobick        ryoo   aggarwal 
            
one of the best performances to date in event recognition using low level pixel based
features is obtained by the stack convolutional independent subspace analysis  scisa   le 
zou  yeung    ng        algorithm  scisa is based on pixel level flow based features
which are then used to model events using a hierarchical representation using deep learning
techniques  bengio         the authors present an extension of independent subspace
   this paper is an extended version of the work by dubba et al               

  

fidubba  cohn  hogg  bhatt   dylla

analysis to learn invariant spatio temporal features in an unsupervised fashion instead of
using predefined features 
if events are considered as a sequence of primitive states or events  state space models
are useful in representing the event models  it is also easy to hand code the structure of the
state space models  though the parameters are better if learned than encoded by hand  they
provide a more robust statistical event model than hand coded models and event recognition
is done using inference on these models  bayesian networks are not very popular in event
modelling as they lack the temporal aspect though other state space models such as hidden
markov models  hmm   rabiner        and dynamic bayesian networks  dbn   ghahramani        are extensively used in event modelling and recognition  a simple hmm is not
very effective in modelling complex events  several extensions of hmm are used to suit the
context and the type of event models  hoogs and perera        proposed a dbn for jointly
solving event recognition and broken tracks linking problems  the event model is a set of
discrete states which expresses how the actors in the event interact over time  they assume
the states are strictly ordered and this may limit learning some events that involve complex
temporal relations such as during  overlaps etc 
the main problem with state space models is that it is difficult to encode high level
temporal relations such as during  overlaps etc  the states or sub events in an event are
assumed to be in a sequential order which is not the case in many domains  also the
states are propositional in nature and hence are semantically less complex than a relational
representation 
veeraraghavan et al         learn stochastic context free grammar based models from
traffic videos using predefined regions in the image  each event model is a spatio temporal
pattern of primitive actions expressed as a string  s   a    a            an   the event learning
algorithm aims to find a grammar that can generate the corresponding pattern for an event 
the primitive actions are sequentially arranged  hence allens temporal relations are not
used to connect the primitive actions  gupta et al         claim that the fixed structure of
the dbns poses serious limitations for modelling events if there are many variations in the
way an event can happen  instead they use and or graphs for modelling event models 
the order of the nodes imposes the causal relationship among the nodes  because of this 
some allen relationships such as during  overlaps etc  cannot be modelled which limits its
application since modelling these relations is very important in many domains 
though low level features and state space models are popular for simple motion patterns 
it is possible to build high level event recognition systems through several layers of reasoning 
these systems use simple pattern recognition techniques to detect primitive events and then
use a temporal structure to reason about complex events  the main motivation for using
a high level temporal structure is that the low level features  like bag of features  discard
most of the information regarding the relations between different entities in the data and
thus makes it hard to recognize events involving complex interactions between multiple
objects 
moyle and muggleton demonstrated using a simple blocks world that domain specific
axioms can be learned from temporal observations using an ilp framework  moyle   muggleton         in work by needham et al          the progol system  muggleton       
was used to learn the protocols of table top games from real sensory data from a video camera and microphone  a key aspect of this work is a method for spatio temporal attention
  

filearning relational event models from video

applied to the sensor data from audio and video devices  this identifies subsets of the sensor
data relating to discrete concepts  symbolic description of the continuous data is obtained
by clustering within continuous feature spaces from processed sensor data  the progol
ilp system is subsequently used to learn symbolic models of the temporal protocols present
in the presence of noise and over representation in the symbolic input data  the framework
is based on time points and used only the successor temporal relation 
konik and laird        proposed a learning by observation framework to learn an agent
program that mimics a human experts behaviour in domains such as games  the learned
concepts are used to generate behaviour rather than classification  they applied ilp techniques on artificially created examples from expert behaviour traces and goal annotations 
the relational data used is simple as each predicate is valid in a situation  an abstract time
point  and hence concepts with sophisticated temporal relations such as allens interval
algebra  allen        that use intervals cannot be learned  this limits the real world applicability of the framework where there are different events occurring in parallel and hence
requires using allens interval algebra to model them  the framework uses only positive
examples and the negative examples are generated randomly in a controlled fashion 
fern  givan and siskind        introduced a system  leonard  that learns event definitions from videos by following a standard specific to general learning approach from only
positive data  there are seven simple event types that are learned in this system namely
pick up  put down  stack  unstack  move  assemble and disassemble  the relational data is
obtained by tracking objects in indoor scenarios  no negative examples are supplied and
the event models are found by computing the least general covering formula  lgcf  of
each positive example and then computing the least general generalisation  lgg  of all
these resulting formulae  when computing the lgcf of each example  the resulting lgcf
will not have any interval information  hence the model can only support before and equal
temporal relations between states 
the important aspect to note for the above review is that most of the work in this area
has been done on either artificial or simulated data  moyle   muggleton        konik  
laird        or very simple real world data  fern et al         needham et al         that
involves few objects  the events are of short duration and all the objects in the scene are
involved in the events  in our case  the tracked data from videos is very large and at the
same time more complex and noisy and contains more objects 
several attempts were made in the literature for integrating induction and abduction for
learning better theories  it was pointed out by tammaddoni nezhad et al         that abduction and induction are integrated in general when two conditions hold  the background
knowledge is incomplete and the hypothesis language is disjoint from the observation language  the setting in which the latter condition holds is called non observation predicate
learning  non opl  setting  i e  in the opl setting  the examples and hypotheses define
the same predicate   they assume the existence of a theory that connects the hypothesis
language and the observation language to start with  since this theory is not learned  it
can be considered as the background theory  the general strategy in this case is to abduce  kakas   riguzzi        the missing observations using background theory and use
this abduced data for inducing new theories  muggleton and bryant        proposed theory completion using inverse entailment  tcie  in the non opl setting  tcie abduces
and adds facts called the start set that connect the target predicate with observable pred  

fidubba  cohn  hogg  bhatt   dylla

icates to the observation data and generalizes this data  in our case  the missing facts are
because of noise in the observed data and the set of target predicates is the same as the set
of observables whereas in tcie  it is because the target predicate is not observable and the
set of target predicates and the set of observables are disjoint 
moyle        introduces an ilp system  alecto  that combines abduction and induction to learn theories for robot navigation  one limitation of this system is that it is
restricted to positive observations only learning  the integration is not interleaved in nature as abduction is first used to generate explanations for each example and induction is
applied on this set of explanations  this means the abduction phase does not take into
consideration the concepts learned in the induction phase and dealing with noise in data
was left as future work 

   relational representation of scenes in video
to represent interactions of objects by relational data  we use spatial and temporal relations 
since the input in this work is from video  the spatial relations are defined either in the
image plane or in the ground plane  if a homography is used to map the image plane to
the ground plane   the spatial relations are necessary to encode the state a particular pair
of objects is in  these states between two objects change as time progresses  hence we
need temporal relations to connect these states  in this section  we explain how objects
interactions are converted to relational data 
notation  we use a first order typed language  l  with the following alphabet        
       r   let r    r    r            rm   denote a set of m qualitative spatial relationships
in an arbitrary qualitative spatial calculus  there are sorts  and corresponding variables 
as given below  upper case letter denotes a set and lower case letter denotes a set element  
time points

t  t

time intervals

 

spatial objects

o o

events

e  

temporal relations

a 

object types

 

the special event predicate tran ri   ok   ol   tm    e denotes a transition from a spatial
relation ri between objects ok and ol at time point tm   note that in this work   can only
take values from the set of    allens base relations  allen        i e  a    before  after 
meets  met by  overlaps  overlapped by  during  contains  equals  finishes  finished by  starts 
started by   we say two intervals are disjoint if the allen relation between them is from
the set  before  after  meets  met by  
    spatial relations
in order to get a high level description of the interactions of objects in videos  we need relations that can encode the interactions of objects without loss of essential information  cohn
et al          there are several possibilities on what kind of relations we have to choose 
since the interactions of objects in video take place in spatial dimensions  it is natural to
  

filearning relational event models from video

  

 







 





 









  

figure    qualitative trajectory calculus  qt cl     van de weghe et al          each
blob is a possible qt cl  spatial relation  in a blob  an asterix  left object  or circle  right
object  represent objects in motion while a star and black dot represent objects at rest and
the direction of the arrow shows the direction of motion of the object  for example  the
top left ellipse is interpreted as two objects moving towards each other and the bottom left
ellipse is interpreted as the right object is moving away from the left object while the left
object is moving towards the right object  i e the left object is chasing the right object  
though nine relations are possible in qt cl  as shown in the figure  in practice we can
reduce them to six exploiting symmetry in some relations  when only one object changes
its motion state  note that an object cannot change direction without going through the
rest state   the qtc relation changes along a thick line connecting two relations  when
both objects change motion state instantaneously  the relation changes along a dotted line 

use qualitative spatial calculi to model the interactions  these interactions also have a
temporal dimension as they occur over a period of time  so we extend the spatial relations
with arguments modelling the temporal dimension  when we say interactions of objects we
mean the interactions of the bounding boxes   aligned to the axes  of these objects that we
get from tracking the objects using computer vision algorithms  yilmaz  javed    shah 
       there are different kinds of spatial calculi that target different aspects of object
interactions like topology  orientation  direction  trajectories etc  and which calculi to use
is a domain dependent choice  chen  cohn  liu  wang  ouyang    yu         we primarily use three spatial relations that encode the object interactions at the topological level 
dc  discrete  when the intersection of pixels in the bounding boxes of two objects is empty 
in  inside  when the intersection of pixels is the same as the pixels in the bounding box of
one of the objects and touch in every other case  this set of simple topological relations
is an abstracted version  of rcc    randell  cui    cohn        spatial calculus  reduced
for practical purposes without loss of essential information for event analysis  we also use
qt cl   van de weghe et al          fig    and domain specific relations as primitives to
represent the interactions of objects in the videos 
   in principle  other shape abstractions could be used as well  e g  convex hulls  silhouettes  bounding ovals
etc 
   the other two relations in this version of rcc called rcc   are equal and contains  inverse of in   the
relation equal rarely occurs in our experiments and we do not use contains as we can convert it to in by
reversing the arguments 

  

fidubba  cohn  hogg  bhatt   dylla

o 

o 

o 
o 

o 

 

 

 

dc

o 

touch

in

dc o    o       
touch o    o       
in o    o       
meets        
meets        
before        

figure    converting interactions of objects to relational data 
    temporal interval relations
we can define temporal relations between time intervals based on allens interval algebra 
we use start and end frames of an interval to represent the intervals  an advantage of this
approach is  we do not have to precalculate temporal relations and store them beforehand in
the database for inference  instead  prolog rules that calculate temporal relations given start
and end time points of two intervals are used  in order to incorporate temporal information
in describing a scenario  we extend the spatial relations with a temporal interval as an extra
argument 
      temporally extending a spatial relation
the state where a spatial relation r between objects o  and o  holds throughout an interval 
is represented as r o    o      where r  r   o    o   o and     grounding this expression
with objects and intervals from a database will provide us with spatio temporal facts 
a temporal relation between two spatio temporal facts is the allen relation between the
intervals in the spatio temporal facts 
    representing an event class
an event class is represented by a set of horn clauses where the head predicate is the same
as the event name under consideration and the body is a non empty conjunction of atoms
consisting of spatial and temporal predicates 
the structure of each clause in an event model for an event class  is as follows 
                  i           n
where each i is either of the form r o    o      where r  r  o    o   o and     or is
of the form          where   a and         
 
  

filearning relational event models from video

   deictic supervision
for supervised learning  we need positive and preferably negative examples too of event
instances  one major problem in supervised learning is collecting the labelled training
data  because of the general ambiguity in defining the spatial and in particular the temporal
extent of an event  i e  where do events precisely start and finish   it is difficult to annotate
videos with event labels  a possible approach is to annotate the objects involved in each
event and give the events temporal extent  but annotating objects is tedious and prone
to human error and for some events there may be uncertainty in the objects involved  we
can avoid this by using deictic supervision  dubba et al          instead of annotating the
exact objects involved in the training event instances  we only give a bounding spatial and
temporal extent of each event instance which may contain other objects  the spatial extent
is a region indicating where the event is happening in the video  the temporal extent is
an interval which includes the actual temporal extent of the event  but may be deliberately
longer in order to avoid accidentally truncating state changes relevant for the event  this
makes preparation of training data easier and the learning process more robust and less
biased to the labelling and the learning algorithm should be able to induce reasonable
models even with this data 
delineating spatio temporal volumes in videos from which to learn feature based representations of actions such as hand gestures is not without precedent in the computer vision
literature  laptev   perez         but our use here extends it to multiple simultaneous actors and relational descriptions and resilience to perturbations in the placement of cuboids
provided events are fully enclosed 
    deictic interval and region
in this work  a deictic spatial region is a rectangle on the image plane indicating where
the event happened and the deictic interval is a time interval indicating when the event
happened  a deictic spatial region is obtained by hand delimiting the event in the image
plane with a rectangle    hence can be represented using a coordinate point  top left corner
vertex   height and width of the rectangle  x  y  h  w   a deictic temporal interval is provided
by specifying the start and end time points of the interval  together they define a space time
cuboid which delimits the spatial and temporal extension of an event 
a deictic cuboid defines a set of spatial facts and temporal relations between them 
an event instance is a subset of these facts and corresponds to a positive example in the
learning from interpretations setting  obtaining positive and negative examples for learning
using event annotations in the form of deictic spatial regions and deictic temporal intervals
is explained in the following sections  note that the deictic interval and region are regarded
as any other interval and object in  and o respectively and the spatial relations are
computed accordingly  after the positive and negative examples are computed  the spatial
relations involving the deictic regions as one of the objects are discarded from the database
as they are of no further use 
   if the tracking data is on the ground plane then we can back project this rectangle automatically into a
minimum enclosing rectangle on the ground plane using homography  hartley   zisserman        

  

fidubba  cohn  hogg  bhatt   dylla

    herbrand interpretation for an event
let si and i be the deictic spatial region and deictic temporal interval for an instance i of
an event class  in video v  let v be the set of spatio temporal facts present in v  ov be
the set of objects in v and v be the set of all time intervals in v  the set of facts ei  v
is the herbrand interpretation for the event i over v iff all the facts contained in it are
entailed by v   whose temporal intervals are not disjoint with the deictic interval and whose
objects have relation touch or in within the deictic region 

ei    r o    o        v  r o    o      
v   i     where  
   before after meets metby  
   v  r   si   o        where r    touch in 
v     i       where   
   before after meets metby  
   v  r   si   o        where r    touch in 
v     i       where   
   before after meets metby  
o    o    si  ov  r  r         v
 

an example interpretation for an event instance of aft bulk loadunload in the airport
domain is illustrated in fig    the interpretation includes all those spatial facts involving
objects that have the relation touch or in with the deictic region and which lie within
the two vertical dashed lines  the deictic interval   the set of herbrand interpretations
corresponding to the set of deictic regions and intervals for an event form the positive
examples for the learning phase  the rest of the relational facts in each video form the
negative example where if an event model fires an instance in the database  it is considered
as a false positive  when a herbrand interpretation is extracted from a set of spatiotemporal facts of a video  this interpretation is independent of all the other facts in the
spatio temporal database  for the video and hence other facts can be assumed false from
this interpretations point of view 
note that by definition the spatio temporal facts that do not spatio temporally overlap
the deictic region and interval of an event instance are not relevant to the event  considering
facts outside the indicated event occurrence not only increases the size of the training data
but also makes the example instances for different event classes less distinct 
one limitation of using a cuboid shaped deictic region for delineating an event instance
is that it is not possible to differentiate among multiple co occurring instances of the same
event type involving different objects in a region  one way to overcome this limitation is to
use more than one cuboid to enclose an event instance allowing the elimination of unwanted
facts 
   this spatio temporal database is itself a subset of the herbrand base of the video obtained using the
predicates  spatio temporal relations  and the constants  objects and time intervals  from the video 

  

filearning relational event models from video

figure    an example interpretation for the event aft bulk loadunload in the airport
domain  the vertical black lines are the start and end of the deictic interval  each row
represents the interactions of two of the objects present in the deictic region during the
deictic interval in the video  the colours of the lines represent the spatial relations between
the pairs of objects at that point of time  this figure does not show the effect of a deictic
spatial region  but this would correspond to the elimination of certain rows  where the
objects do not have a spatial relation of touch or in whilst in the deictic spatial region
during the deictic temporal interval 
    herbrand interpretation for a non event interval  negative example 
in our framework  the negative examples are not explicitly labelled  the negative example
for a given event in a video is the set of spatio temporal facts from the database of the
video that are not present in the positive examples of the event in that video  note that
the negative example will in general contain data that might be in positive examples of
other event classes in that video  another alternative is to use labelled positive examples
of other events as negative examples for the event we are learning  this is convenient for
classification purposes but not in recognition tasks as this will miss the background data
that might be useful to minimize detections in the background regions 
let v be the union of all spatio temporal facts from all herbrand interpretations of
event  in video v  the set of facts niv  v is the herbrand interpretation for a negative
example for event  in video v iff it contains all the facts in v which are not in v   i e  
niv   v  v  

   typed ilp
in any event learning and recognition system  low level image processing and computer
vision techniques may introduce noise into the system  one kind of noise  in particular
when video quality is bad as in videos from some cctvs  is that the wrong type may be
assigned by the tracker to an object history  an object detector is typically trained with
  

fidubba  cohn  hogg  bhatt   dylla

person
aircraft
gpu
transporter

object

light vehicle
push back
service vehicle
mobile stairs
vehicle
loader
conveyor belt
passenger boarding bridge
heavy vehicle
container
catering
tanker
bulk loader

figure    tree structured object type hierarchy in the airport domain 
many example images of objects to be detected  even though many example images are
given for training  it is not possible to capture all the possible ways an object can appear
because of lighting  viewing direction  size  shape  etc   lowe         this may result in
correctly localized objects but with the wrong categories of the objects  especially those
that look visually similar in low contrast images 
when the input data is huge and noisy  there are several problems an ilp system can
face  one of these is that hypothesis evaluation can take a lot of time because of the size of
the data  also the noise will tend to make the hypothesis over specific as the system learns
more rules to cover the inconsistent examples  using a typed ilp system can speed up
evaluation because of typed arguments in the hypothesis  walther        cohn        and
also reduce the number of false positives through avoiding certain cases where the types of
the arguments do not match  any event model that has objects with a specialized type will
fail to recognize some event instances where the object appears with a different type  in
contrast  if the event model does not have any type system and uses a very generic type for
all the objects such as object  thing etc   then this approach will have many false positives
as it cannot differentiate between events with same structure but involving different types
of objects  one possible approach is to find an appropriate type generalization instead of
using one of the two extremes  most generic type and most specialized type 
in most ilp systems  the type hierarchy of objects is not integrated into the learning
process  for example  in progol  types of the objects are used only in mode declarations
and since it assumes a flat type hierarchy of the domain  the search procedure cannot
take any type hierarchy into consideration  for example  if the tracking system sometimes
confuses two types of objects          such that some objects of type   are misclassified as
  

filearning relational event models from video

s 
s 

s 
s 
s 

figure    tree structured example object type hierarchy  s  is the most general type and
s    s    s  are the most specific types 
type     then progol generates two rules  one with   and another with     even if we
are not dealing with a vision system that introduces noise into the high level learning and
reasoning system  in some cases an event might involve objects from a particular sub group
of objects  in this case  instead of using a very generic type like object or very particular
types like the type of the object itself  it is more efficient to use an intermediate generic type
that represents this sub group  a variable without type restrictions will be satisfied by any
type of object when instantiating the horn clause  however  an appropriate generalization
can be enforced by the learning system with a variable of type   t  from the type hierarchy 
which is satisfied  only by objects of type   or     thereby reducing false positives 
    representing a typed hierarchy
if we wish to use an existing prolog engine for hypothesis evaluation then some way of
encoding type using terms must be found  there are several ways of doing this depending
on whether the structure of the object type hierarchy is a tree or a lattice  we use the
type representation proposed by bundy  byrd and mellish        that can deal with tree
structured type hierarchies  we then develop a refinement operator by incorporating this
representation in the hypothesis search procedure  an advantage of using this representation
is that ordinary unification can be used to determine whether two types are compatible 
we will write i   j   if i is a subtype of j and i    j   every object o of type n
in a hypothesis can be represented by the term             n  o          where             n is the
maximal sequence of types such that n                   we denote this representation
function by   note that we need a constraint  i e  a tree structured type hierarchy  in
order to guarantee the uniqueness of the sequence             n  
for example  let s    s    s    s    s  be types such that s    s    s    s    s    s  and
s    s  as shown in fig    then any object o of type s  can be represented as follows 
 o    s   s   s   o   

an object oi is not compatible with an object oj in a hypothesis if  oi   is not unifiable
with  oj    for example  s   s   o     will not unify with s   s   o     but will unify with
s   s   s   o      and s   s   s   o       hence they are compatible 
      example of representing a type hierarchy
an object type hierarchy that occurs in one of the two domains used in the evaluation
section of this work is shown in fig    the hierarchy from fig   is hand defined based
   a variable of type   t   can unify with a term of type   or    

  

fidubba  cohn  hogg  bhatt   dylla

on observed errors in object classification of the tracking data from the airport domain 
in the airport domain  the ground power unit  gpu   transporter and push back vehicle
are small vehicles that look similar as the videos from cctv cameras in the airport have
low resolution contrast without much colour or sharp edges  this makes it challenging to
train an object detector and use it for detecting objects in these videos  the objects from
the verbs domain present no particular challenges from an automatic classification point
of view but some events involve objects from a particular subset of objects  for example 
the throw event involves balls of different types like small ball  basket ball  etc  hence using
a type hierarchy based on utility is expected to help find event models that have better
performance in detecting events in unseen videos 
a vehicle v of type gpu will be represented as obj veh light veh gpu v      
while v of type light veh is represented as obj veh light veh v      note that
obj veh light veh v     unifies with vehicles of type gpu and vehicles of type transporter  so using obj veh light veh v     in a model can cover examples that either
involve a gpu or a transporter and hence can handle the noise from an object detector if
it confuses these vehicles by outputting gpu in place of transporter or vice versa 
    type refinement operator
a refinement operator is used to traverse through the hypothesis lattice  there are two
types of refinement operators  upward and downward  nienhuys cheng   de wolf        
we write hg  hs if hg is a more generic  hypothesis than hs   if we assume that the
top most element of the hypothesis lattice is the most generic hypothesis and the bottom
most hypothesis is the most specific hypothesis  then the upward refinement operator can be
defined as follows  the downward refinement operator can be defined in a similar fashion  
let l be the set of all possible hypotheses  an  upward  refinement operator  is defined
such that for a hypothesis h   produces only generalizations of h   h     hg   hg 
h  hg  l  
we define the  upward  type refinement operator t as an operator that generalizes
the object types of h  apart from object types  the structure of h and members of t  h 
is identical 
we define a type generalizing operator as follows 
generalize type             n   n  o                          n   o         
the type refinement operator  t   applies the generalize type operator to a selected
object type present in a hypothesis  resulting in a more generic hypothesis by moving up
exactly one level in the type hierarchy 
though the specific current representation of type hierarchy using functors requires a
tree structured hierarchy  having a tree structured hierarchy is beneficial from a computational viewpoint in limiting the type generalizations  i e   there are no multiple ancestors 
a tree like type hierarchy is very natural in many domains though some domains might not
   note the short forms used for object  vehicle and light vehicle 
   there are several possible generality orders  most important are subsumption and logical implication  nienhuys cheng   de wolf        

  

filearning relational event models from video

have a well defined tree like object type hierarchy  in such cases  a lattice structured type
hierarchy is more suitable though this will increase the size of the search space since the
number of possible refinements is increased  in particular in a tree structure type generalization is deterministic whilst this is not the case in a lattice structure 
      optimality of the type refinement operator
refinement operators can be ideal or optimal  nienhuys cheng   de wolf           an
optimal refinement operator generates any hypothesis in the hypothesis lattice only once
and there is a unique way to produce each hypothesis  this kind of refinement operator is
desirable in complete search algorithms as duplicate generation of hypotheses will increase
the cost of the search procedure  the optimality of the type refinement operator is proved
in appendix a 

   learning from interpretations setting for learning event models
the result of deictic supervision gives us examples that are sets of spatio temporal facts 
though these examples  sets of facts  come from the same or different videos  they are
independent of each other  i e   the mapping of each example to a class is independent of
other examples  for this kind of learning setting where each example is independent of
each other and each example is a set of facts  the learning from interpretations setting is
an apt choice  blockeel  de raedt  jacobs    demoen         the setting can be specified
formally thus 
given 
 a set of classes c  each class label c is a nullary predicate  
 a set of classified examples e  each element of e is of the form  ei   c  with ei a set
of facts and c a class label 
 and a background theory b 
find   a hypothesis h  a set of horn clauses   such that for all  ei   c   e 
 h  ei  b  c  and
 c   c   c    h  ei  b   c 
in the current event learning problem  the above setting is applied for each event class
where in each case the set of classes has only two elements  the event class and the background class  background class represents the negative examples and each class label c is a
nullary predicate 
   an ideal refinement operator is proper and complete whereas an optimal refinement operator is weaklycomplete and non redundant  see appendix a for formal definitions 

  

fidubba  cohn  hogg  bhatt   dylla

    traversing the search space
the search process for a hypothesis starts with an initial hypothesis which has a nullary
predicate as head and an empty body  the hypothesis lattice is traversed using the progol
and type refinement operators in an interleaved fashion  the progol refinement operator
is a specialization operator that adds atoms from the bottom clause to a hypothesis  a
specialization operator moves from the top  empty clause  to bottom in the hypothesis
space which is a lattice bounded by the bottom clause from the bottom  adding atoms
from the bottom clause makes the hypothesis more specialized because the body of the
hypothesis is a conjunction of atoms and each atom can be considered as a constraint 
adding more atoms to the body increases the constraints it has to satisfy to become true 
the progol refinement operator that we use here is based on the bottom clause also
called the most specific clause and is non redundant though it is not weakly complete with
respect to the general subsumption order  tamaddoni nezhad   muggleton         the
most specific clause that the progol refinement operator uses can be computed from training examples  mode declarations and the background knowledge  muggleton         mode
declarations are user defined syntactic biases in the form of predicates that specify what
predicates from the background knowledge are expected in the target hypothesis and also
the nature of the variables  input  output  or constant   the selection of atoms to be
added to the hypothesis from bottom clause is done in a controlled manner  the atoms
are only considered starting from left and moving to the right and each atom can be added
only once  tamaddoni nezhad   muggleton         these constraints on the selection of
atoms makes the refinement process non redundant  i e   a hypothesis is not generated twice 
there is an additional refinement operator that refines by unifying two variables arbitrarily
selected from the hypothesis or by substituting a variable with a constant  we do not use
this operator as unifying two variables needs checking the hypothesis for consistency with
respect to the underlying spatial theory and there are no fixed constants  apart from frame
numbers  in the domain as constants in any example are independent from constants from
other examples  for example  consider the three relations from section     for the spatial
theory and allens relations for the temporal relations  we cannot unify two arguments of
a predicate  spatial or temporal  as this violates the semantics of these relations 
the type refinement operator generalizes a hypothesis by generalizing the type of an
object in the hypothesis  fig     there are two possible approaches to apply the type
refinement operator  type first approach is to select a type from the set of types for a
hypothesis and generalize the type of the variables that belong to the selected type and
variable first approach is to select a variable from the hypothesis and generalize the type
of all occurrences of this variable in the hypothesis  the type first approach generalizes the
selected type throughout the hypothesis and this may involve several variables while the
variable first approach only generalizes the type of one variable  in our work  we use the
type first approach as this has a fewer number of refined hypotheses and a smaller search
space while the variable first approach has a larger number of choices and hence a larger
search space  one more reason to use the type first approach is that the computer vision
algorithm might confuse the type of a whole group of objects that belong to a particular
type rather than a single object in a video because of an inaccurate object detector 
  

filearning relational event models from video

figure    type refinement operator  generalization  
    searching the event model
once the most specific clause is computed  the sub lattice bounded from below by the mostspecific clause is searched using a best first search for the hypothesis that has a maximum
score calculated based on a combination of     the number of positive examples covered     
the number of answer substitutions in the negative examples      the length of hypothesis
and     the number of distinct variables in the hypothesis subject to the given constraints
 discussed in the next subsection  
score h      p      n   l   v 
where
   weight to positive examples
p   number of positive examples covered
    weight to answer substitutions in negative examples
n   number of answer substitutions in negative examples
l   length of the hypothesis
v   number of distinct variables in the hypothesis
an answer substitution  for an example e is a substitution that grounds the hypothesis 
h  b            bn   and the query  b            bn  succeeds in the database of e  note that in
the learning from interpretations setting each positive example is a separate database and
when a hypothesis is used as a prolog query in each database  it might result in multiple
answer substitutions  an example is considered covered by the hypothesis if there are one
or more answer substitutions  while testing the hypothesis in a test database  each answer
substitution is considered as one recognized event instance  if the recognized event interval
falls outside the event ground truth in a test video  it is considered as false positive  in the
event recognition domain  the hypothesis is used for recognizing events in unseen videos
  

fidubba  cohn  hogg  bhatt   dylla

instead of classifying videos  a hypothesis with fewer false positives is desirable  hence
hypotheses are penalized using the number of answer substitutions   in negative examples 
if the number of positive and negative examples are disproportionate in numbers  giving
more weight to the positive examples and negative examples using  and   will result in an
hypothesis that has better performance in test data 
since the starting hypothesis is empty and completely generic  it will cover all the
negative examples  as the hypothesis is specialized by progols refinement operator  the
number of false positives decreases  when the score of the hypothesis no longer increases  the
type refinement operator is used to generalize the types thereby increasing the generality
of the hypothesis with a possible increase of positive examples covered  as well as false
positives   this process of interleaved application of both operators is continued until the
hypothesis score no longer increases 
once a satisfactory hypothesis is found  an argument representing temporal information
in the form of a list of time intervals formed using the time intervals in the body of the
event model can be introduced into the head in order to explicitly represent when the event
occurs  this is useful when using the hypothesis for event monitoring  it allows the interval
during which the event occurs to be explicitly flagged when viewing the video 
the learning algorithm uses a set covering method  quinlan        to learn an event
model that is a set of clauses interpreted as a disjunction  the covering method starts with
an empty model and learns a clause using the provided positive and negative examples and
adds this clause to the model  it repeats this procedure but now with positive examples
that are not covered by the earlier clause  this process is repeated until all the positive
examples are covered 
    constraining the search space
the size of the search space depends on the size of the bottom clause  muggleton        
thus  in the event learning domain  it depends on the number of spatial relations being
used and the number of objects in the event instances used as positive examples  the size
of the bottom clause increases with the number of allens temporal relations as each interval
in the atoms with spatial predicates is temporally connected to every other interval in other
atoms with spatial predicates  this creates many atoms with temporal predicates in the
bottom clause 
in order to decrease the size of the search space  the algorithm makes use of domaindependent and domain independent constraints on the structure of the hypothesis  the
constraints the algorithm uses such as restrictions on the hypothesis length and the number
of variables in the hypothesis etc  are domain independent structural constraints as they
do not depend on the predicates used or any domain knowledge  the following are the two
domain dependent constraints that reduce the search space and time thereby making the
learning process more efficient 
 upper bounds on the number of atoms in the body of a rule 
    counting the number of answer substitutions instead of number of examples covered is a heuristic used
in the foil system  quinlan   cameron jones        

  

filearning relational event models from video

 any interval in an atom with spatial  temporal  predicate should appear in an atom
with a temporal  spatial  predicate  any hypothesis with atoms that do not satisfy
this criteria is not semantically meaningful since it might be satisfied by facts not at
all related to the event in question 
however the constraints listed above are domain dependent constraints rather than application specific constraints  i e   these constraints that involve the spatial and temporal
predicates should be applicable in most  if not all event learning scenarios  note that some
of the constraints are hard  i e  inviolate   if a hypothesis violates any such constraint  then
it is discarded without scoring or refining  for example  the domain independent constraints
and the first domain dependent constraint mentioned above are hard  in contrast  if a hypothesis violates a constraint that is not hard  for example  the second domain dependent
constraint listed above  it is not scored and discarded only after generating refined hypotheses from it  this is because discarding such hypotheses without refining might obstruct the
traversal of the lattice  for example  in the current work  the algorithm starts the search
process with an empty hypothesis and the initial hypotheses obtained by refining the empty
hypothesis do violate the second domain dependent constraint listed above  since they contain exactly one predicate and therefore cannot contain both a spatial and a temporal
predicate  
    event recognition
the learned event models are used for event recognition in unseen videos  for this purpose 
the test video is converted to relational data and used as a database and the event models
are used as prolog queries  the querying is done in the whole database and the intervals
extracted from the answer substitutions from these queries give the temporal extent of the
recognized instances of the events  in order to record when the event takes place  we change
the arity of the event predicate  the rule head  to be monadic such that the argument is a
list of all interval variables occurring in the body  note that it would also be possible to
introduce a second argument to record which objects are involved in the event  i e  a list
of all variables of type object   or equivalently that occur as the first two arguments of any
spatial predicate in the body  
an issue that arises is exactly when an event occurs given that it consists of multiple
overlapping temporal intervals from the instantiated predicates in any given answer substitution  given the list of all intervals  occurring in the instantiated body of the hypothesis 
various possibilities present themselves  one could take the maximal interval which exactly
spans all intervals in   or one could take the interval which exactly spans the interval from
the first transition  i e  pair of meeting intervals involving the same pair of objects  to the
last such transition  clearly there are other possibilities too  ultimately this is probably a
domain dependent decision  for our experiments  we take the list of all intervals in  and
the temporal extension of the event is obtained by taking the minimum and maximum of
the time points in  
note that there may be several rules for an event class  each rule capturing a variation
in which an event can happen  these rules do not have weights specifying how important
or reliable a rule is for recognizing events  when recognizing events  all the rules of an event
class are used and this may result in multiple answer substitutions 
  

fidubba  cohn  hogg  bhatt   dylla

   interleaved induction and abduction  iia 
in the previous section we showed how ilp can be applied to learn rule based relational
event activity models  given an observation dataset  positive and negative examples of
events whose models have to be learnt  however  data from visual and other sensors tend
to be noisy with high variability in the sample space  this leads to over fitted models  i e  
more rules   as the model has to cover some of the examples that are corrupt because of
the sensor noise  a model with more rules can result in many false positives when used for
event recognition in test data 
in this section  we show how well fitted  semantically meaningful event models can be
learned from noisy data by interleaving induction and abduction  this acquires significance
in cases where training data is scarce and noisy  we apply the typed ilp system presented
in the previous section to learn event based models and using these models as the domain
theory  we explain the examples observations not covered by the induced theory using
abduction  the uncovered examples are either noisy  or are examples for the same event
that in reality happened in a different way  using the explanation we rectify the errors in the
noisy examples corrupted by tracking errors and thus reduce the requirement for additional
rules  in our framework  the examples themselves are noisy  i e  incorrect  thereby requiring
observation data revision in a manner that is consistent with the initially learned theory 
and general common sense knowledge about space  spatial change  and the dynamics of the
domain  note that many ilp approaches discard examples considering them as noisy by
using a heuristic stopping criteria  this is not acceptable in cases where there is scarcity of
training data  where learning from every example is potentially important 
    domain independent spatial theory
in order to pursue our goal  an axiomatic characterisation of the spatial theory is necessary  many spatial calculi exist  each corresponding to a different aspect of space  here  it
suffices to focus on one spatial domain  e g   topology  with a corresponding mereotopological axiomatization by way of the binary relationships of the rcc   fragment rrcc    from an
axiomatic viewpoint  a spatial calculus defined on r has some general properties  p p   
which can be assumed to be known apriori  to realize a domain independent spatial theory
that can be used for reasoning  e g   spatio temporal abduction  across dynamic domains 
it is necessary to formalize a domain independent spatial theory  space   which preserves
the high level axiomatic semantics of these generic properties  for reasons of space we only
sketch the properties p p  and neglect the formal axiomatization 
 p p   the basic calculus properties  cp   describe the jointly exhaustive   pairwise disjoint  jepd  property  i e   for any two entities in o  one and only one spatial
relationship from r holds in a given situation  the jointly exhaustive property of n    r 
base relations can be axiomatized by n ordinary state constraints and  similarly  the pairwise disjoint property can be axiomatized by  n n         constraints  other miscellaneous
properties such as symmetry and asymmetry can be expressed in the same manner 
 p   the primitive relationships in r have a continuity structure  referred to as its conceptual neighbourhood  cn    cnd   freksa         which determines the direct  continuous changes in the quality space  e g   by deformation and or translational motion  
 p   from an axiomatic viewpoint  a spatial calculus defined on r is  primarily  based
  

filearning relational event models from video

on the derivation of a set of composition theorems  ct   between the jepd set r 
in general  for a calculus consisting of n jepd relationships   n  n  compositions are
precomputed  each of these composition theorems is equivalent to an ordinary state constraint  which every n clique spatial situation description should satisfy 
 p   additionally  axioms of interaction  ai   are necessary when more than one spatial calculus is modelled in a non integrated manner  i e   with independent composition
theorems   these axioms explicitly characterize the relative entailments between interdependent aspects of space  e g   topology and size 
now  let space def  cp  cn  ct  ai   denote a domain independent spatial theory
that is based on the axiomatizations encompassing  p p   
    physically plausible scenarios
corresponding to each spatial situation  e g   within a hypothetical situation space   there
exists a situation description that characterizes the spatial state of the system  it is necessary that the spatial component of such a state be a complete specification  possibly with
disjunctive information  for k spatial calculi being modelled  the initial situation description involving m domain objects requires a complete n clique specification with  m m      
spatial relationships for each calculus  therefore  we need to define a scene description to
be c consistent  i e   compositionally consistent  if the n clique state or spatial situation
description corresponding to the situation satisfies all the composition constraints of every
spatial domain  e g   topology  orientation  size  being modelled  if more than one calculus
is modelled the inter dependent constraints  p   must hold as well 
from the viewpoint of model elimination of narrative descriptions during an  abductive 
explanation process  c consistency of scenario descriptions is a key  contributing  factor
determining the commonsensical notion of the physically realizability of the  abduced  scenario completions  bhatt and loke        show that a standard completion semantics with
causal minimization in the presence of frame assumptions and ramification constraints preserves this notion of c consistency for space within a logic programming framework  as
well as with arbitrary basic action theories 
    the inductive abductive framework
we interleave inductive and abductive commonsense reasoning about space  events and
change within a logic programming framework  induction is used as a means to learn event
models by generalizing from sensory data  whereas abductive reasoning is used for noisy
data correction by scenario and narrative completion  thereby improving the learning 
      explanation by abduction
diametrically opposite to projection and planning is the task of post dictum or explanation  poole  goebel    aleliunas         where given a set of time stamped observations
or snap shots  the objective is to explain which events and or actions may have caused
the observed state of affairs  explanation problems demand the inclusion of a narrative
description  which is essentially a distinguished course of actual events about which we may
have incomplete information  miller   shanahan         narrative descriptions are typi  

fidubba  cohn  hogg  bhatt   dylla

cally available as sensory observations from the real execution of a system or process  given
narratives  the objective is often to assimilate explain them with respect to an underlying
process model 
the abductive explanation problem can be stated as follows  kakas  kowalski    toni 
      
given  theory t and observations g  find an explanation   such that 
 t

s

 g

 t

s

  is consistent

i e   the observation follows logically and non trivially from the theory extended given the
explanation  abductive explanations are usually restricted to ground literals with predicates that are undefined in theory  namely the abducibles  abductive explanations are
derived by trying to prove the observation from the initial theory alone  whenever a literal is encountered for which there is no clause to resolve with  the literal is added to the
explanation 
the abduction procedure results in many valid explanations  in order to reduce the
number of explanations  several restrictions as listed below can be used  kakas et al         
explanations should be basic this means one explanation should not explain another
explanation  this is enforced by not allowing abducibles in the head of any rule 
explanations should be minimal this means one explanation should not subsume another explanation 
explanations should satisfy all integrity constraints with this restriction  we obtain explanations that are valid in the domain under consideration  in our work 
explanations should satisfy all the spatial constraints of the underlying spatial theory 
      scenario and narrative completion
it is easy to intuitively infer the general structure of narrative completion by abductive
explanation  consider the illustration in fig   for a hypothetical situation space that characterizes the complete evolution of a system  in fig   the situation based history given
by the solid arrows represents one path  corresponding to an actual time line discretized
into intervals h                m i  within the overall branching tree structured situation space 
given incomplete narrative descriptions  e g   corresponding to only some ordered intervals
in terms of high level spatial  e g   topological  orientation  and occurrence information  the
objective of explanation is to derive one or more paths from the branching situation space 
that could best fit the available narrative information  formally 


   touch a  c     












dc a 
c 

 

in b 
a 

 

dc b 
c 

 


 
 
 
 








 



 
  

 
where


space
 
 


    i   j     meets     i    bef ore i        dc b  a  i  






 touch a  c  i    dc b  c  i   











 
meets 
 

 

meets 
 

 

touch b 
a 

 


i
j
j
 
j






 touch a  c  j    dc b  c  j   
  

     

filearning relational event models from video

a
a

c

b
a

c
a

c

b

a

c
a

b
c

ab

c

b
c
a

b

c

figure    branching hypothetical situation space  only a few possibilities are shown 
there are clearly more paths from the initial scenario to the target scenario  there are also
more possible states 

in          denotes the initial situation and   denotes the final situation represented in
terms of spatial relations  rcc    among the objects present in the scene  the abductive
derivation of   that explains how the scene changed from situation   to situation    
primarily involves non monotonic reasoning in the form of minimizing change  in addition to
making the default assumptions about inertia  and an appropriate treatment of ramification
constraints  bhatt   loke        
    iia algorithm
most ilp systems use a covering algorithm to learn models from examples  the search
ranges over a hypothesis lattice and each hypothesis is evaluated based on the number of
positive and negative examples it covers  if it is selected as a suitable hypothesis based on
some scoring function  this hypothesis  rule  is added to the model  the covered examples are
removed and this process is repeated until all the positive examples are covered  examples
can be corrupted by noise resulting in missing or incorrect facts  in such cases  more
rules are learned than necessary in order to cover all the examples  as the number of
rules for a concept increases  this may result in many false positives when the rules are
used for classification recognition in test examples  in order to avoid learning from corrupt
examples  the framework identifies examples as being corrupted by explaining them through
abduction using the already induced model and the background theory  dubba et al         
  

fidubba  cohn  hogg  bhatt   dylla

the main assumption we make here is that the noise in the examples is not consistent  if
the noise is consistent  i e   present in most of the examples in a similar fashion  then it
becomes part of the pattern that defines the concept and might be learned by the learning
algorithm 
the pseudo algorithm is given in algorithm    the induction algorithm induces an
initial hypothesis based on the score function explained in previous sections  the positive
 
examples covered  erule
  by this hypothesis are removed from the list of positive examples
yet to be covered  the induced theory along with background knowledge is used to explain
the uncovered examples treating each example as a narrative  abduction gives several
possible explanations each with different cost  based on the nature and the number of facts
in the explanation   the explanations are rejected if they have a cost more than a specified
threshold  furthermore  given the formulation of the spatial theory space   c consistency of
 
abduced explanations is ensured  the examples  e 
  that have an explanation whose cost
is less than the specified threshold are removed from the positive examples list that are yet
to be covered  as they are now considered to be covered by the already induced model  this
process of induction and abduction is repeated until all the positive examples are covered 
apart from the constraints enforced by the spatial theory to filter abduced explanations 
several heuristics can be used to give a score to each explanation so that a low cost consistent
explanation can be selected by the system  one of the several possible heuristics is to prefer
explanations where the number of transitions in spatial relations is minimal  hazarika  
cohn         this heuristic is a direct consequence of mccarthys common sense law of
inertia  mccarthy        which states that change is abnormal and persistence is to be
preferred in the absence of data  in a spatio temporal domain  each explanation abduced in
the absence of data is a set of spatio temporal facts and there are three ways to add them to
the explanation   i  extend the current relation between two objects  can be done in both
directions of the timeline if the situation permits   ii  change the current relation between
two objects to its neighbouring relation in a cnd  iii  introduce a new object  hypothetical 
into the scene and its spatial relations with other objects in the scene as well  the cost of
each explanation is based on the type of spatio temporal fact chosen and is calculated as
explained below 
      cost of an abduced explanation
let   be an explanation from the abduction procedure where   is a set of grounded spatiotemporal facts of the form r oi   oj   k   denoted as fijrk   ep  is the current positive example
 an interpretation  i e   a set of facts  and let r be from the set of spatial relations r in a
spatial calculus  let o be the set of objects in ep    let cfijrk be the cost of abducing fijrk  
x
the total cost of   denoted as c  is
cfijrk  
fijrk  

the cost of

  
 
cfl  

  n 

abducing fijrk is calculated as follows 
if there exists a fijrm in ep  such that k and m are disjoint
if there exists a fijsm in ep  such that k and m are disjoint and r  
  s
where n is the number of hypothetical objects  objects not in o  in fijrk

where        
  

filearning relational event models from video

the first case in the cost function occurs when the system abduces a fact that extends
a relation between two objects in the temporal dimension  this does not count as a spatial
transition and hence has a very low cost  in contrast  the second case occurs when the
system abduces a fact that extends the existence of two objects in temporal dimension with
a different relation  the new spatial relation must be a neighbour to the existing relation
in the cnd  than the one that already exists between them  this counts as a spatial
transition and has a cost more than the first case  the third case occurs if it is necessary
to have a hypothetical object to satisfy the hypothesis in ep    this case is used when an
object involved in an event is completely missed by the object tracker while first two cases
are used in scenarios where an object is not detected in some temporal slice in its life time 
note that the first case is clearly the most preferred if the abduction procedure has to find a
low cost explanation and the third case which is the most expensive applies when an object
is completely missed by the object tracker  though it is possible to avoid transitions to
reduce the score  sometimes it is mandatory to consider transitions  for example  consider a
scenario where two objects have a dc relation and in the final state they have an in relation 
in this case  the algorithm has to abduce facts where there are two transitions  one when
the dc relation changes to touch and another when touch changes to in relation   note that
it is not necessary to abduce temporal relational facts as the prolog definitions for temporal
relations in the background theory can be used to compute them when needed  this can
be achieved by not including temporal predicates in the list of abducibles 
the abduction procedure uses the existing constants in the database and one issue with
this is that though the number of relations and objects is small  the number of possible
intervals is very large if not constrained  in order to constrain the possible explanations 
we introduce intervals with predefined duration into the database so that abduction uses
only these intervals for abducing explanations  note that abduction as we have defined
it only adds missing spatio temporal information and cannot be used to retract corrupted
data resulting from noise 

algorithm   interleaved induction and abduction algorithm  iia 
procedure iia e     e    b    training sets and background knowledge  includes spatial
theory 
h
 
while e       do
rule  s
induce b  e     e   
h  h  rule 
 
e    e    erule
   abduce b  h  e    
 
e    e    e 
end while
return h
  learned theory
end procedure

  

fidubba  cohn  hogg  bhatt   dylla

figure    airport domain  the videos are recorded using   static cameras looking at the
same scene from different angles 

   experimental results
in this section  we present an evaluation of remind  as well as the extension presented in
section    for the experiments  we used two real world video datasets that are different from
each other in many aspects  the videos from these datasets are shot in outdoor settings and
in different weather and light conditions  rainy  cloudy  sunny  night   these variations in
the videos present various challenges to the vision system and subsequently to the learning
system both in the training phase and the event recognition phase 
the two datasets used in this work for evaluation are from airport logistics and verb
videos  the datasets from these domains differ in many aspects such as number of objects
in the video  length of video  duration of events  background structures  the number of
cameras used to capture the events and also the plane  image plane or ground plane  in
which the tracking data is made available  we view the differences in the datasets as a
positive aspect   the framework shown to work in two very different kinds of scenarios 
remind   is implemented in python and for speed  some modules are implemented
in cython  swi prolog is used as the underlying prolog engine for storing and querying
relational facts and background knowledge 
    airport logistics
for experiments in the airport logistics domain     turn arounds   were used where each
turn around was shot using   cameras from different angles  fig    and each video is on
average one hour long     frames per sec  
the following are informal descriptions of the international air transport association  iata  events we aim to learn models for 
    available on request from the first author and will be made public in the near future 
    a turn around is the duration of a plane entering and leaving the apron area 

  

filearning relational event models from video

aircraft arrival

aircraft comes into the apron

aircraft departure

aircraft moves away from its position on the apron

gpu positioning

ground power unit comes and positions in its zone

left refuelling

fuel truck arrives on the left side of aircraft for refuelling

pb positioning

push back vehicle positioning in front of the aircraft

pbb positioning

passenger boarding bridge attaches itself to the aircraft

pbb removing

passenger boarding bridge detaches itself from the aircraft

fwd cn loadunload

container loading unloading at the front end of the aircraft

aft cn loadunload

container loading unloading at the rear end of the aircraft

aft bulk loadunload

baggage loading unloading at the rear end of the aircraft

fwd bulk loadunload

catering loading unloading at the front end of the aircraft

within each event  there is high variability because of noise in tracking and also because
of objects extraneous to the event entering the event scene  note that some events might
not be present or may occur multiple times in some turn arounds  the scenes involve
interactions of vehicles and people with zones on the apron  these zones are specified
on the ground plane according to the iata specifications and the position of the zones
depends on the type of aircraft  these zones are used for parking and steering vehicles
for different operations carried out in a turn around  note that these zones are static
throughout the video and do not change size or position  unlike the bounding boxes of the
vehicles obtained through tracking  hence zones are not included in the type hierarchy used
for the domain  fig    since they do not suffer from visual noise  the main reason to use
zones is that the rcc   spatial relations between bounding boxes of vehicles and people
in the ground plane rarely touch  hence most of the interactions are encoded as dc if zones
are not used  it is important to use the zones as most of these interactions happen in the
zones  according to the iata specifications  a vehicle transition through the zones and the
position of the vehicle in particular zones is important to determine the events 
we use the object tracks provided by a partner in the co friend project  ferryman 
borg  thirde  fusier  valentin  bremond  thonnat  aguilera    kampel         certain
details in some events are not detectable with this tracking system such as the direction of
baggage on the rail of the loader vehicle and whether the trolleys are empty when they arrive
at the scene  the load unload events obtained from iata events differ in such details  if
the trolleys are loaded when they arrive at the scene and the baggage is moving towards
the aircraft  then the event is loading and if the trolleys are empty when they arrive at the
scene and the baggage is moving away from the aircraft  the event is unloading   apart from
these details  they are semantically similar and hence are regarded as the same events  for
example  fwd cn load and fwd cn unload are regarded as the same events and named
fwd cn loadunload  the same strategy is followed with other load unload events  
      tracking and obtaining relational data
the apron scene area is too large to be covered by a single static camera  the events
on the apron occur on both sides of the aircraft which is very difficult to cover with a
  

fidubba  cohn  hogg  bhatt   dylla

single camera and because of the size of the aircraft it is possible to have many occluded
objects in the scene  in order to solve these problems  six cameras are used to shoot the
scene from different angles so that the entire area is covered and the number of occluded
objects is minimized  working on the ground plane data results in learned models that are
independent of the camera view and the airport as these models can be readily applied at
different airports with different camera configurations 
the tracking data is obtained for each of the videos from six cameras of a turn around
and fused together to get  d data on the ground plane  ferryman et al          the tracking
data is noisy because of low quality  bad light and weather conditions and low contrast
of cctv videos  the noise can be the presence of phantom objects  missing objects 
wrong types of vehicles  inaccurate bounding boxes  broken trajectories  object identity 
inconsistencies etc  which are typical problems in any computer vision tracking system 
each turn around is separately processed to get relational data that consists of a set of
spatial relations among the vehicles and zones on the apron  prolog rules that decide the
temporal relationships among intervals are considered as background information in the ilp
system  the data for each video has between     and     spatial relational facts  excluding
temporal relational facts  depending on the number of objects and the interactions between
these objects 
note that an event requires at least one change in the state  here  spatio temporal
relations between pairs of objects  of the objects  if the relation between any two objects
is dc and does not change during the life span of the objects  it signifies that the objects
are not interacting and the relational fact is discarded as these spatio temporal facts do not
contain relevant information in defining event models  the tracking data also consists of
bounding boxes for people in the scenes  but these are discarded as people are not germane
in the semantics of the events and also these increase the size of the relational data 
      annotation of events
for supervised learning we need positive and preferably negative example instances of
events  in the airport domain  the temporal extent of the events is provided by individuals who have expertise in the iata protocols and apron activities  by specifying the
start and end frame numbers of the event instance in that video  the spatial extent was
obtained by using a tool with which a polygon can be drawn on one of the image planes
and the corresponding ground plane region is obtained using an homography  it was easier
for a human annotator to watch an actual video to provide the spatial annotation rather
than view a  d visualization in the ground plane  which being the fusion of the imperfectly
tracked data that does not always show all relevant objects   this region gives a spatial
extent for the event instance 
    physical action verbs dataset
the action verbs dataset   is a corpus of video vignettes  fig    that portray motion verbs
such as approach  exchange  jump  collide  etc  enacted in natural environments like parks 
    this dataset  minds eye year   recognition task videos  is provided by darpa and publicly available
from http   www visint org datasets

  

filearning relational event models from video

 a  approach event with tracked objects

 b  snatch event with tracked objects

figure    example event instances for approach and snatch in action verbs dataset
urban places  etc  these vignettes are short in duration when compared to videos from the
airport domain  a few tens of seconds  the full list of verbs is given in table   
though each vignette was shot to portray a single verb action  other verbs are inevitably
present as well  sometimes overlapping in time  this is primarily unavoidable  for example  a
vignette that portrays the verb carry  will automatically include walk if a person is carrying
some object in their hand  this aspect is taken into consideration while annotating the
vignettes  we were able to obtain tracked data from an external source  morariu  harwood 
  davis        including object type information  fig     
the new challenge in using this dataset is the different ways a verb can be enacted 
there are    verbs in the dataset and a total of      vignettes are used for training and
     vignettes are used for testing 
      tracking and obtaining relational data
the tracking data available to us often suffers from errors  e g   a bouncing ball is often only
tracked once it is being held and fast moving objects such as a running person are missed 
we used qualitative trajectory calculus relations  qt cl     van de weghe et al        
as the primitive spatio temporal relations  we did not choose rcc for this dataset as it
seemed unlikely that a purely topological representation would be sufficient  in contrast 
the qt cl  relations capture the typical movements in the verbs dataset like moving away 
approaching  follow etc  for example  in a chase event where one object is following another
object the relation is dc  using rcc  which is also the same for two objects standing still
with some distance in between 
it is difficult to model motion patterns of objects like run  walk  raise  bend etc  using
only relational data without referring to parts of a person  the verbs dataset contains some
events that involve such motion patterns and to recognize these  pixel based models are
more appropriate  the primitive events were recognized in all the videos using the method
proposed by jiang  lin and davis         where an action is represented as a sequence
of joint hog flow descriptors  dalal   triggs        extracted independently from each
frame  instead of applying this approach to the entire frame and video as proposed by
jiang et al          the input was restricted to sliding temporal windows along the spatio  

fidubba  cohn  hogg  bhatt   dylla

person
object

vehicle
other

figure     tree structured object type hierarchy in the action verbs domain 
temporal volume defined by a persons bounding box  these primitive events   in addition
to qt cl  relations provide the relational data in the verbs domain 
      annotation of events
the ground truth for events in the verbs dataset vignettes is of a different nature to the
ground truth in the airport domain  the development and the test set were annotated
by    people using amazon mechanical turk  amt   each vignette was presented to the
annotator and    questions were presented in the form  is verb x present in this vignette 
only verbs annotated by more than     of the annotators are considered as events present
in the vignette  for the development set  the annotations were extended by providing for
each event instance its temporal extent 
    experimental results and evaluation for the typed ilp framework
sample rules   learned for aircraft arrival and aft bulk loadunload events are given
below  for example  the aircraft arrival rule can be interpreted as  an aircraft arrives
when the aircraft bounding box has the in relation with the right aft bulk ts zone and
then moves forward thereby changing the relation to touch  this happens when the aircraft
arrives and is moving to its position  the rule also correctly identifies that this bounding
box should belong to an object of type aircraft  the goals in the rule are ordered such that
spatial predicates come before  to the left of  the temporal predicates since there are more
temporal facts   compared to spatial facts and this ordering speeds up the query execution 
aircraft arrival  intv t  t    intv t  t      in obj aircraft v    right aft bulk ts zone  intv t  t    
touch right aft bulk ts zone  obj aircraft v    intv t  t    
meets intv t  t    intv t  t    
aft bulk loadunload  intv t  t    intv t  t      touch left tk zone  obj veh heavy veh v      intv t  t    
touch obj veh v     left tk zone  intv t  t    
meets intv t  t    intv t  t    
we followed the standard leave one out methodology for testing performance in the
airport domain  all turn arounds except one are used for training and the remaining one is
used as a test case  this process is iterated until each turn around is used as the test case
    this data was provided by vlad morariu from university of maryland 
    a temporal interval is represented as intv t    t    for programming convenience where t  and t  are the
starting and ending frame numbers of the interval 
    as already noted  temporal facts are not explicitly stored but are computed via background knowledge
rules 

  

filearning relational event models from video

event

 examples

without type generalization

with type generalization

fwd cn loadunload

 

    

    

    

    

    

    

gpu positioning

  

   

    

    

    

    

    

aircraft arrival

  

    

    

    

    

    

    

aft bulk loadunload

  

    

    

    

    

    

    

pbb removing

  

    

    

    

    

    

    

left refuelling

 

    

    

    

    

    

    

pb positioning

  

    

    

    

    

    

    

aircraft departure

  

    

    

    

    

    

    

aft cn loadunload

  

    

    

    

    

    

    

pbb positioning

  

    

    

    

    

    

    

fwd bulk loadunload

 

    

    

    

    

    

    

weighted average

    

    

table    performance comparison of models obtained without and with using types using
rcc   primitives in the airport domain  the first  second and third columns for each
category are recall  precision and f  respectively  the best f  value in each case is presented
in bold  it is clear from the table that using types improves the overall performance  by
without type generalization we mean  type information from tracker is ignored  all objects
have the same type  and type generalization is not performed during learning 

exactly once  the results of our experiments are summarised in table    the third and
fourth columns show the recall and precision without using types in the    turn arounds
 i e   type information from the tracker is ignored  hence all objects have the same type and
type generalization is not performed during learning   the fifth and sixth columns show
the recall and precision using the type hierarchy  from the tables it is clear that using type
information can increase the accuracy of event recognition  also the combined execution
time for all the experiments using type generalization was reduced by roughly     when
compared to the execution time of experiments without type generalization 
the detailed recognition results  temporal localization  for events in a turn around is
shown in fig      best seen in colour   the plot shows a turn around with one subplot showing ground truth of event instances and another subplot showing the recognized instances
by the typed ilp system in that turn around  each event is colour coded for comparing
ground truth with the recognized instance intervals  note that a recognized event instance
is considered a true positive if it overlaps at least     with the corresponding event ground
truth interval  oh et al          in some cases the temporal extent of recognized event in  

fidubba  cohn  hogg  bhatt   dylla

figure     recognition of events in turn around   in the airport domain  best viewed in
colour  

stances is long because some spatial relations that are important in the event extend beyond
the deictic interval of the event 
      evaluating learned event models against hand coded event models
the learned models are also evaluated by comparing them with hand coded models  the
hand coded models were provided by domain experts using a set of domain dependent
spatial relations  ferryman et al          in order to directly compare performance without
any change in underlying representation  rather than using the rcc    we recomputed
relational data for remind using the same domain dependent primitives  the comparisons
are given in table    it is clear from the table that learned models have a better performance
in all the event categories when compared to the performance of hand coded models  the
hand coded models were single primitives rather than a set of primitives connected by
temporal relations  these kind of models with only one single predicate have far more
false positives when compared to models that have a set of spatial relations connected by
  

filearning relational event models from video

event

 examples

learned  rcc   

learned  d d 

hand coded  d d 

fwd cn loadunload

 

    

    

    

    

    

    

    

    

    

gpu positioning

  

    

    

    

    

    

    

    

    

    

aircraft arrival

  

    

    

    

    

    

    

    

    

    

aft bulk loadunload

  

    

    

    

    

    

    

    

    

    

pbb removing

  

    

    

    

    

    

    

    

    

    

left refuelling

 

    

    

    

    

    

    

    

    

    

pb positioning

  

    

    

    

    

    

    

    

    

    

aircraft departure

  

    

    

    

    

    

    

    

    

    

aft cn loadunload

  

    

    

    

    

    

    

    

    

    

pbb positioning

  

    

    

    

    

    

    

    

    

    

fwd bulk loadunload

 

    

    

    

    

    

    

    

    

    

weighted average

    

    

    

table    table comparing learned  rcc     learned  domain dependent  and hand coded
models performance  domain dependent   the first  second and third columns for each
category are recall  precision and f  respectively  the best f  value in each case is presented
in bold 
temporal relations  also the hand coded models use a very specific vehicle type in the event
models which affects the performance by reducing the true positives as there is noise in the
object type detection  whereas the learned models use an appropriate generalized object
type to cover these instances 
      evaluating learned event models with different spatial relations
we also performed an evaluation to investigate the effects of different spatial relations 
for comparison we used rcc   and domain specific relations in the airport domain  we
did not use qtc relations for this domain as there were very few examples to learn from
and because of the many spatial relations in the qtc spatial calculus  the patterns for
events do not emerge  the results are given in table    from the table it is clear that
models learned using rcc   have a better recognition performance  mean f         when
compared to the models learned using domain dependent relations  mean f          one
reason might be that rcc   has a better representation granularity when compared to the
domain dependent primitives  also rcc   has the jepd  jointly exhaustive and pair wise
disjoint  property while the domain dependent primitives in the airport domain does not
 it lacks the pair wise disjoint property  
      evaluating on the verbs dataset
the framework that uses the type generalization has also been applied to the verbs dataset
for the    verbs  table   shows the precision  recall and f  scores for the classification task 
for each video in the test set  all the event models are used as queries and if an event model
  

fidubba  cohn  hogg  bhatt   dylla

succeeds  that particular verb is considered to be present in the video  and the variable
bindings give the time of the occurrence and what objects are involved   this is compared
with the ground truth to obtain the precision and recall values 
below we provide sample rules learned for the events approach and snatch which cover
the instances shown in fig    the qt cl  relations moto  short form for moving towards a
stationary object   static and depart  short form for moving away from a stationary object 
corresponds to the relations in blobs in row   and column    row   and column    row  
and column   respectively in fig    also note that unlike the models learned in the airport
dataset  there is no list of temporal intervals as an argument in the head of the rules here 
this is because we just want to recognize the events in the videos in the action verbs
dataset and the videos are too short to find the temporal extent of an event 
approach    moto obj vehicle j    obj person k    intv v    v      
static obj vehicle j    obj person k    intv v    v      
meets intv v    v      int v    v      
snatch    static obj person j    obj person k    intv v    v      
moto obj other l    obj person j    intv v    v      
depart obj other l    obj person k    intv v    v      
overlaps intv v    v      int v    v      
during intv v    v      intv v    v      
during intv v    v      intv v    v      
the proposed framework  was compared with other existing systems and the results
are presented in tables      one of the systems that we compared with  the redvine
system  is a supervised learning version of the framework proposed by sridhar  cohn and
hogg         it is based on a graphical representation of relational facts  where an event
is represented by a histogram of graphemes  small graphs that represent spatio temporal
interactions of the objects involved in the event  mapped into a vector space to facilitate
classification  the stack convolutional independent subspace analysis  scisa   le et al  
        is based on pixel level flow based features which are then used to model events
using a neural network  the spatio temporal features used in this algorithm are learned
in unsupervised fashion instead of using predefined features such as sift  lowe        
hog  dalal   triggs         etc 
the evaluation dataset as provided by darpa has a total of      vignettes  it was
found that some vignettes        in the training set also appeared in the evaluation set 
we call the dataset with      vignettes the verb evaluation dataset    ved   and the
remaining vignettes after discarding the      vignettes that appeared in training dataset
ved   evaluation on ved  gives interesting insights into overfitting and underfitting
in the different learning frameworks that are compared  we chose two different average
mechanisms  macro and micro    to get an overall f  and matthews correlation coefficient
 mcc  scores over all the verbs and vignettes  true negatives do not play a role in f 
    results using this system have been provided by tuyen huynh of sri 
    macro average is calculated by first calculating precision and recall for each category and then taking
the average of these values  while micro average is calculated by constructing a global contingency table
and then calculating precision and recall using these sums 

  

filearning relational event models from video

verb

precision recall

approach
arrive
attach
bounce
bury
carry
catch
chase
close
collide
dig
drop
enter
exchange
exit
fall

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

f 

verb

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

flee
fly
follow
get
give
go
hand
haul
have
hit
hold
jump
kick
leave
lift
move

precision recall
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

f 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

verb
open
pass
pickup
push
putdown
raise
receive
replace
run
snatch
stop
take
throw
touch
turn
walk

precision recall
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

f 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    classification results per verb in the physical action verbs domain 

scores but have a considerable effect on mcc scores as mcc does not differentiate between
positive and negative classes  mcc will give the same scores even if the class labels are
interchanged while f  scores change  note that much of the work in the literature on activity
recognition use f  scores 
from the tables      it is clear that scisa has better mcc scores in all cases while
remind has a better f  score on the ved   though it has lower mcc scores than the
mcc scores of the other two algorithms  also note the drop of performance of scisa
in ved  set when compared to ved   whereas remind and redvine have almost the
same performance indicating scisa is overfitting the data while remind and redvine are
underfitting the data  the reason for the very high f  but very low mcc score in remind
is because of few true negatives 
scisa performs quite well  w r t  mcc score  but does not have the modelling capability
our framework has since it underutilizes the temporal domain  while we do not outperform
the state of the art for all evaluation measures  the proposed scheme is still general  i e  
 i  it gives good interpretations of activities in video scenes   ii  does take the temporal
domain into account unlike the scisa and therefore provides better modelling capabilities 
 iii  gives high recall while precision can be improved with further post processing and
 iv  provides  elegant  logical rules which can be easily interpreted by a human observer 
one major drawback of scisa is the lack of spatio temporal localization of the recognized
event  it is suitable only for the event classification tasks  verbs dataset  but not for the
event recognition tasks  airport domain   although we do not report on localization here
 owing to the short videos in the data set   deriving localization  or position  information
from remind is trivial once the event is recognized since the intervals and objects involved
are explicitly identified in the rule body 
  

fidubba  cohn  hogg  bhatt   dylla

method
remind
redvine
scisa

avg prec
    
    
    

avg rec
    
    
    

f 
    
    
    

mcc
    
    
    

table    performance in the verbs domain  ved   macro average per verb 

method
remind
redvine
scisa

total prec
    
    
    

total rec
    
    
    

f 
    
    
    

mcc
   
    
    

table    performance in the verbs domain  ved   micro average  total detection classification 

method
remind
redvine
scisa

avg prec
    
    
    

avg rec
    
    
    

f 
    
    
    

mcc
    
    
    

table    performance in the verbs domain  ved   macro average per verb

method
remind
redvine
scisa

total prec
    
    
    

total rec
    
    
    

f 
    
    
    

mcc
    
    
    

table    performance in the verbs domain  ved   micro average  total detection classification 

    experimental results and evaluation for iia
the iia framework has been evaluated on both the airport and verb datasets  we use
hyprolog  a logic programming framework capable of abductive inference  christiansen  
dahl        
      embedding spatial theory for the airport domain
for the airport domain  we have encoded the rcc   spatial theory space into the framework that contains the conceptual neighbourhood graph  the jepd relationships and the
composition theorems of the spatial relations used as follows 
  

filearning relational event models from video

  sample
dc x  y 
dc x  y 
dc x  y 
dc x  y 
dc x  y 

jepd
t   
t   
t   
t   
t   

constraints
touch x  y 
touch x  y 
touch x  y 
touch x  y 
touch x  y 

 p    p   for rcc  
t 
t    during t   t  
t    during t   t  
t    overlaps t   t  
t    overlaps t   t  

   
   
   
   
   

fail 
fail 
fail 
fail 
fail 

  conceptual neighbourhood constraints  p   for rcc  
dc x  y  t    in x  y  t    meets t   t       fail 
in x  y  t    dc x  y  t    meets t   t       fail 
  sample composition theorem  p   for rcc  
in x  y  t    dc y  z  t    touch x  z  t    during t   t   
during t   t       fail 

the jepd and the cnd property constraints forbid the abduction of facts which contradict the spatial theory thus avoiding physically impossible scenarios and this also helps
abduction to complete in reasonable time 
to explain our approach  consider the following fragments of actually occurring datasets
 ex     ex    for the event aircraft arrival  

ex  

dc arr zone obj aircraft obj     intv            
touch arr zone obj aircraft obj     intv             
touch arr zone obj veh light veh gpu obj       intv            
dc arr zone obj veh heavy veh loader obj      intv            

ex  

dc arr zone obj aircraft obj     intv            
touch arr zone obj aircraft obj     intv             

ex  

dc arr zone obj veh light veh trolley obj      intv            
touch arr zone obj aircraft obj     intv             
touch arr zone obj veh light veh trolley obj      intv             

ex  

dc arr zone obj aircraft obj     intv            
touch arr zone obj veh heavy veh loader obj       intv            
dc arr zone obj veh heavy veh loader obj       intv            

we obtain the following model for aircraft arrival event learned by the ilp approach from
the first two examples of the given examples with arr zone denoting a specific zone on the
apron and any ti denotes a time point  each fact has two time points indicating the start
and end of an interval in which the spatio temporal fact holds 

aircraft arrival  intv t  t    intv t  t      dc arr zone  obj aircraft v    intv t  t    
touch arr zone  obj aircraft v    intv t  t    
meets intv t  t    intv t  t    
  

fidubba  cohn  hogg  bhatt   dylla

obj

obj

z 
z 

z 
z 
z 

z 

arr zone

z 

z 

arr zone

z 

z 

time

aircraft arrival t  t  
dis arr zone obj aircraft v   t  t 
con arr zone obj aircraft v   t   t  
 a  spatial primitive based event modelling

   

   

z 
z 
z 
z 

z 
z 
z 

arr zone
z 

z 

arr zone
z 

time

aircraft arrival            
rel  arr zone obj             
con arr zone obj aircraft obj                  
 b  narrative completion  of data video  and previously learned model

figure     iia scenario and narrative completion  e g   aircraft arrival
this rule states that an aircraft arrival takes place if there is some interval in which an
aircraft is disconnected from arr zone directly followed by an interval  i e   meets  where
the same aircraft is connected to arr zone  this model does not cover any other examples
apart from ex   and ex    ex   has a missing dc relation related to the aircraft whereas
ex   has a missing touch relation  fig    b   these represent the typical data corruption
at a higher level because of tracking error at lower level video processing at different stages
in the video 
      narrative completion in the airport domain
multiple explanations are interesting as they give several possible scenarios that are all consistent with the narrative  for example  consider ex   where a touch fact related to aircraft
arrival event is missing in the narrative  this happens when the vision algorithm fails to
detect the aircraft when it is coming towards the parking zone as such a big object changes
the light conditions in the scene  the abduction system comes up with two explanations  as
shown in the following sample interactive run of the system   one filling the missed fact that
is consistent with the narrative and the background knowledge and constraints  another
explanation is using a hypothetical object   g       that is not present in the database 
  

filearning relational event models from video

this explanation is more expensive than the first explanation  so the system chose the first
explanation 
 a small narrative with three observations  the touch fact
 is missing  this happens  when the vision algorithm fails
 to detect the aicraft when it is close  approximate
 interval can be specified for aircraft arrival query
 dc arr zone obj aircraft obj     intv            
 touch arr zone obj veh heavy veh loader obj      intv            
 dc arr zone obj veh heavy veh loader obj      intv            
   aircraft arrival intv              
touch arr zone obj aircraft obj     intv            
true  
dc arr zone obj aircraft  g        intv            
touch arr zone obj aircraft  g        intv            
true   false 
with narrative completion  it is possible to cover all the examples given above  with one
single aircraft arrival model learned  this avoids learning spurious rules to cover these
corrupted examples thus giving us compact and semantically meaningful models 
to evaluate our approach  we compare the rules learned using only induction and rules
learned using the iia algorithm  the first column in table   shows the events that we
considered for the experiments  the second column shows the number of instances of that
particular event in the    turnarounds  the third column shows the number of rules learned
by using only ilp while the fourth column shows the results using the iia algorithm while
fifth column shows the number of examples that were not covered by the induced rules
but were explained using abduction and hence no rules learned from them  by interleaving
induction and abduction  we were able to avoid learning spurious rules as shown by the
results  for most classes  the number of rules are reduced by about     and the overall
performance is also increased  we also observed that the rules which had been previously
learned for the examples now covered by abduction did not semantically correspond to the
events 
      evaluating iia on the verbs dataset
for the verbs domain  we encoded the spatial theory for qt cl  spatial calculi  though
we also used domain dependent primitive events for this domain besides qt cl    we did
not encode any spatial theory for these relations as it is not well defined  for example  the
domain dependent primitives for this domain are neither jointly exhaustive nor pair wise
disjoint  we also avoided abducing explanations with these relations by not including these
relations in the list of abducibles     fold cross validation was used for evaluation for verbs
dataset  since each video is short in duration with around     frames  we used classification
instead of recognition  from table   it is clear that using abduction reduces the number
of rules in event model thereby giving a more compact model  in the verbs dataset results 
there is no considerable change in performance as this is a classification task rather than a
recognition task  the main performance increase with iia during inference comes when
  

fidubba  cohn  hogg  bhatt   dylla

airport events

 pos

fwd cn loadunload
 
gpu positioning
  
aircraft arrival
  
aircraft departure
  
aft bulk loadunload
  
left refuelling
 
pb positioning
  
aft cn loadunload
 
pbb positioning
  
pbb removing
  
fwd bulk loadunload
 
num of rules with only induction  

 
 
 
 
 
 
 
 
 
 
 
num of



 

roi

poi

ria

pia

 
 
   
   
   
 
 
 
   
 
 
 
    
    
    
 
 
   
    
    
 
 
    
    
    
 
 
    
   
    
 
 
    
    
    
 
 
    
   
    
 
 
 
    
 
 
 
    
    
    
 
 
 
 
 
rules with iia  avg num of examples covered

   
   
    
    
    
    
    
    
    
    
 
by abd

table    airport domain iia results averaged from all iterations in leave one out testing 
roi  poi   recall and precision with only induction  ria  pia   recall and precision using
iia 
verb events

 pos

 



roi

approach
   
  
 
  
    
arrive
 
 
 
 
    
attach
  
 
 
  
    
bounce
  
 
 
 
    
catch
   
 
 
  
    
chase
   
  
 
  
    
collide
   
 
 
  
    
dig
   
  
 
  
    
drop
  
 
 
 
    
exchange
  
 
 
 
    
fall
   
 
 
  
    
give
   
  
  
  
    
jump
   
 
 
  
    
kick
  
 
 
 
    
leave
   
  
 
  
    
lift
  
 
 
  
    
pass
  
 
 
  
    
pickup
  
 
 
 
    
run
  
 
 
 
    
throw
  
 
 
 
    
num of rules with only induction   num of rules with iia  avg

poi

ria

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
num of examples covered

pia
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
by abd

table    verbs dataset iia results averaged from all iterations in    fold cross validation
testing  roi  poi   recall and precision with only induction  ria  pia   recall and precision
using iia 

there is reduction of false positives because of fewer rules and in recognition there is a high
possibility of multiple rules firing in the test data thereby giving many false positives  in
classification  this is not the case  as once a vignette is classified as being a member of a
particular event class by a rule  the classification by other rules of the event class does not
affect the overall outcome for that vignette 

  

filearning relational event models from video

   limitations and future work
the models used by remind are local  i e   without the context of a wider activity model
that could be used to filter out recognized instances thereby increasing performance  for
example  in some turn arounds in the airport domain  the aircraft departure event is
sometimes recognized even before aircraft arrival is recognized resulting in false positives
for aircraft departure  another limitation of the learned models is the lack of representation
of duration for events  many recognized event instances are rejected by the system because
the temporal extent of the recognized instances is long and fails our criteria of     overlap
with the ground truth  these can be reduced by learning a global model  greenall  cohn   
hogg        that constrains the ordering of events such that aircraft departure detections
can happen only after aircraft arrival  the activity models can also represent expected
duration of events  the temporal separation of events and the number of occurrences 
the framework is sensitive to the initial example selected to start the learning procedure 
the induction system used is based on the algorithm that uses a bottom clause  muggleton 
      constructed from the selected example to guide the refinement of the hypothesis while
searching in the lattice  hence it is possible it might select a corrupted example initially and
this might affect the whole induction process  this is a typical problem in machine learning
and there are several ways to avoid this  one promising approach that we followed in this
work is to repeat the learning with different examples chosen randomly as the starting point
then selecting the iteration that gives the minimum number of rules 
another limitation of the framework is its dependency on the tracking of objects as it
uses the interactions of objects to model events  challenging scenarios for object tracking
pose limitations for the current framework  the current framework is not probabilistic  i e  
neither the input data nor the learned models are probabilistic  one direction of future work
is to extend the framework using statistical relational learning so that it can use soft evidence
and learn more robust probabilistic relational models  since the current framework does
not handle hierarchies of events  the framework could be extended to handle hierarchical
composition of events  one possible approach for this is to learn models of events at a
particular layer using the events at lower layers as primitives 

    conclusion
in this paper  we have proposed a supervised relational learning framework  and an extension using abduction  to learn event models from complex videos  such event models can
be used to recognize event instances from unseen videos  we presented a type refinement
operator that exploits the object type hierarchy in the domain to search for better hypotheses and also proved that it is an optimal refinement operator  we presented an empirical
evaluation of the proposed framework on two real world video data sets and the results are
encouraging  showing that the framework can be effectively used in real world systems for
event recognition in various domains  we also showed that the proposed framework has
better generalization capabilities and performance when compared to the state of the art
systems in event modelling  finally  we note that although we have focused on learning
from video data here  in fact the approach would also be suitable for learning from other
data sources which provide tracks of interacting moving objects  e g  from gps streams  
  

fidubba  cohn  hogg  bhatt   dylla

acknowledgements
we thank colleagues in the co friend  race  strands and vigil projects consortia
for their valuable inputs to this research  and the respective funding from eu framework
   fp  ict         fp  ict        fp  ict         and darpa  w   nf    c       
also financial support by the deutsche forschungsgemeinschaft in the transregional collaborative research center sfb tr   spatial cognition project r   q shape  is gratefully
acknowledged 

appendix a  proof of optimality of type refinement operator 
let t be the type hierarchy tree with set of nodes tv   and set of leaf nodes tl   i e  most
specific types  tl  tv   and r be the root of the tree  most generic type   a type at a
parent node  in t is more generic than the types i at its children nodes and we write
   i  
let g be a function  g   tv  tv   that maps a child node to its immediate parent  the
function g can be considered as a generalizing operator that generalizes a type to its nearest
generic type  g can be applied as long as i    r
let si be an ordered  from most specific to most general  set of all possible generalizations of i including i  
si    i   g i    g g i             r  
for any set of types                  n    we can define corresponding sets s    s            sn  
let  h    h            hm   be the set of types   in the clause c where  h    h            hm    tv   for
 h    h            hm    we can define sh    sh            shm   we can make the set  h    h            hm  
more generic by applying g  one or more times  on any arbitrarily selected subset of types
one type at a time 
the cartesian product sh   sh          shm is the set of tuples where each tuple is a
possible generalization of  h    h            hm   
let l be a function mapping a non leaf type node to an integer that specifies how many
times g was applied to the original leaf node to obtain the non leaf node   in t   l   tv  n  
using l  we can generate a new set nhi from shi by replacing i by l i    now we can
generate a new cartesian product nh   nh          nhm  
example     let              be the set of types from a clause c and let the type hierarchy
be as given in fig     then we can define s    s    s  and n    n    n  as follows and the
tree representation of the cartesian products s   s   s  and n   n   n  are given
in fig    and fig    respectively 
    if we consider the list of types from a clause c where some types may be repeated because of some
arguments have the same type  the results in this appendix are still valid 
    note that in general  a non leaf node can be obtained from any of the leaf nodes that are its descendants
but a unique leaf node can be obtained if we store the original leaf node that is generalized using g to
get the non leaf type node 

  

filearning relational event models from video

r

  g      g    

   

figure     an example type hierarchy 

s         g     
s         g      g g      
s         g      g g      
n          
n             
n             

 
 

g    

g    
 

g g     

g    

g g     

  g     g g        g     g g        g     g g        g     g g        g     g g        g     g g     

figure     representing the cartesian product s   s   s  as a tree  the root is empty
and the next layer corresponds to s  and so on  note that g       g g        g g        r  
each path in the tree to a leaf is a possible generalization of               the leftmost path
being the null generalization  i e               
definition      type substitution     a type substitution  is a set
 h       h               hn  n   where each hi is the type of a subset of variables in the
clause c and i is the immediate generic type of hi  parent node of hi in the tree t    we
say i is substituted for hi in the clause  the set  h    h            hn   is called the domain of
   denoted dom    and the set                  n   is called range of    denoted rng    
a type substitution is used to generalize the type of a subset of variables in the clause 
definition      most generic type substitution  r   a most generic type substitution is
a type substitution whose range is the set  r   where r the root of type hierarchy tree t  
a most generic type substitution is used to check if two clauses are structurally equivalent
 def    by substituting the types of all variable by r   note that every clause c has a unique
most generic type substitution  cr   whose domain is the set of all types in c and range is
the set  r   
  

fidubba  cohn  hogg  bhatt   dylla



 

 

 

 

 

 

 

 

                                   

figure     representing the cartesian product n   n   n  as a tree  the root is empty
and the next layer corresponds to n  and so on  each path to a leaf represents a possible
generalization of               each generalization is obtained by following the path from
root to leaf and generalizing the type at each layer the number of times indicated by the
node value  for example  the highlighted sequence         corresponds to the generalization
 g      g g       g       this can be obtained by generalizing   once and generalizing  
twice and generalizing   once  if a top to bottom order  left to right in case of tuples 
is followed  this is the only unique way to achieve the generalization  g      g g       g     
from              
definition      structurally equivalent    two clauses  c and c   are structurally equiv 
alent  denoted c  c     if ccr  c   cr  
a clause c is structurally equivalent to all the clauses obtained by replacing a subset of
types of variables in c by any of their generalizations 
definition      generic order w r t  types     a clause c is said to be more general
w r t  type than another clause c     denoted c  c     iff c  c   and the set of types of c
are correspondingly more generic than the set of types of c    
definition      type refinement operator  let  be a clausal language  t a type hierarchy
and c a clause in   ct is a subset of  defined over t and c where a clause c    ct is
structurally equivalent to c  i e   c  c     let  be the subsumption order as defined above 
the type refinement operator  for hct    i is a function such that   c    d d  c  
 a one step type refinement of c is defined when  is applied only once  i e     
  c   an n step type refinement can be defined similarly  i e  n    d   e  e 
n 
 c  such that d    e    the set of all type refinements on c is given by

  c       c      c         
  is locally finite if for every c      c  is finite and computable 
  is proper if for every c      c    d d  c  
  is complete if for every c  d   such that d  c  there is an e    c  such
that d  e  i e  d and e are equivalent in the  order  
  

filearning relational event models from video

  is weakly complete for hct    i if   c    ct  
  is non redundant if for every c  d  e    e    c  and e    d  implies
c    d  or d    c 
  is ideal if it is locally finite  proper and complete 
  is optimal if it is locally finite  non redundant and weakly complete 
the type refinement operator selects a type hi from the set  h    h            hm   for c and applies the type generalizing operator to the type and the resulting set  h    h            g hi            hm  
is used for substitution in c to obtain a more generic clause c   with respect to type  i e  
c    c   the type refinement operator follows a left to right order in generalizing types
to avoid generating redundant clauses  i e   if a type at position i is generalized then in the
next step of refinement of h  no type at position j  j   i is selected for generalizing 
theorem      is locally finite
proof  let t be the type hierarchy tree and tv be the set of all nodes in t and tc  
 h    h            hm   be the set of types in the clause c where tc  tv   let g be the type
generalizing operator and  be the type refinement operator   operates on c by selecting
a type from the set  h    h            hm   and generalizing it by applying g  there are only  tc  
possibilities to select from and for each possible type selected there is only one possible
generalization  as a type only has one parent in the tree t   also each type can only be
generalized finite number of times  i e   until it becomes r    hence the number of possible
refinements  i e      c   is finite making  locally finite 
theorem      is weakly complete
proof  for any given clause c with set of types  h    h            hm   and t as defined above 
                obtained from one step type refinement
let x  be the set of substitutions    
  
  and c       c   let x   x  x        where x is the set of
such that ci    c i
 
 
 

i
                      be
substitutions obtained from two step type refinement and so on and  i 
i 
im
    
the rng  i
                                                                i e    is the
let   be the set of tuples     
  
 m
i  i 
im
set of tuples where each tuple represents a possible type refinement of  h    h            hm  
through one step type refinement and let                
it is easy to observe that any tuple p   is also a tuple in the cartesian product
sh   sh          shm   in fact there is an exact one to one matching for the members of 
and members of sh   sh          shm   it is easy to obtain each member tuple  say p where
p                    m   of the cartesian product by generalizing  h    h            hm    a type hi
is generalized until it is equal to i before moving to the next type on the immediate right
of hi   in this way all possible type generalizations of  h    h            hm   are reachable from
 h    h            hm    i e   all possible type generalized clauses are reachable from c  hence 
is weakly complete 
theorem      is non redundant
  

fidubba  cohn  hogg  bhatt   dylla

proof  let nh   nh          nhm be as defined previously for a set of types  h    h            hm  
from a clause c  this cartesian product can be represented as a tree where the root is
empty and the next level is the elements from nh  and so on  each path to a leaf represents
a possible generalization of  h    h            hm    each generalization is obtained by following
the path from root to leaf and generalizing the type at each layer the number of times
indicated by the node value  if a top to bottom order  left to right in case of tuples  is
followed  there is a unique way to obtain the generalization that path generates  hence 
is non redundant 
example      for example in fig     the sequence         in bold corresponds to the generalization  g      g g       g       this can obtained by generalizing   once and generalizing
  twice and generalizing   once  if a top to bottom order is followed  this is the only
unique way to achieve the generalization  g      g g       g      from              
theorem       is optimal
proof  since the type refinement operator is locally finite  weakly complete and non redundant 
it is optimal 

references
albanese  m   moscato  v   picariello  a   subrahmanian  v     udrea  o          detecting
stochastically scheduled activities in video  in proceedings of the international joint
conference on aritificial intelligence  ijcai   pp           
allen  j  f          maintaining knowledge about temporal intervals  communications of
the acm             
bengio  y          learning deep architectures for ai  foundations and trends in machine
learning              
bhatt  m     loke  s          modelling dynamic spatial systems in the situation calculus 
spatial cognition   computation                 
blockeel  h   de raedt  l   jacobs  n     demoen  b          scaling up inductive logic
programming by learning from interpretations  data mining and knowledge discovery              
bundy  a   byrd  l     mellish  c          special purpose  but domain independent  inference mechanisms  in progress in artificial intelligence  pp         london  ellis
horwood 
chen  j   cohn  a  g   liu  d   wang  s   ouyang  j     yu  q          a survey of
qualitative spatial representations  the knowledge engineering review             
christiansen  h     dahl  v          hyprolog  a new logic programming language
with assumptions and abduction  logic programming         
cohn  a  g          taxonomic reasoning with many sorted logics  artificial intelligence
review               
  

filearning relational event models from video

cohn  a  g   hogg  d  c   bennett  b   devin  v   galata  a   magee  d  r   needham  c  
  santos  p          cognitive vision  integrating symbolic qualitative representations
with computer vision   vol       of lncs  chap      pp          springer 
dalal  n     triggs  b          histograms of oriented gradients for human detection  in
ieee conference on computer vision and pattern recognition  cvpr   vol     pp 
       
dubba  k  s   bhatt  m   dylla  f   hogg  d  c     cohn  a  g          interleaved
inductive abductive reasoning for learning complex event models  in inductive logic
programming  pp          springer 
dubba  k  s   cohn  a  g     hogg  d  c          event model learning from complex
videos using ilp  in proceedings of the european conference on artificial intelligence
 ecai   vol       pp       
fern  a   givan  r     siskind  j          specific to general learning for temporal events
with application to learning event definitions from video  journal of artificial intelligence research             
ferryman  j   borg  m   thirde  d   fusier  f   valentin  v   bremond  f   thonnat  m  
aguilera  j     kampel  m          automated scene understanding for airport aprons 
lncs       springer verlag            
freksa  c          conceptual neighborhood and its role in temporal and spatial reasoning 
in singh  m     trave massuyes  l   eds    decision support systems and qualitative
reasoning  pp          north holland  amsterdam 
ghahramani  z          learning dynamic bayesian networks  adaptive processing of
sequences and data structures         
greenall  j   cohn  a  g     hogg  d  c          temporal structure models for event
recognition  british machine vision conference  bmvc  
gupta  a   srinivasan  p   shi  j     davis  l          understanding videos  constructing
plots learning a visually grounded storyline model from annotated videos  in ieee
conference on computer vision and pattern recognition  cvpr   pp           
hakeem  a   sheikh  y     shah  m          casee   a hierarchical event representation
for the analysis of videos  in proceeding of the national conference on artificial
intelligence  aaai   pp         
hartley  r     zisserman  a          multiple view geometry in computer vision  second
edition   cambridge university press 
hazarika  s  m     cohn  a  g          abducing qualitative spatio temporal histories
from partial observations  in international conference on principles of knowledge
representation and reasoning  pp       
hoogs  a     perera  a  g  a          video activity recognition in the real world  in
proceedings of the national conference on artificial intelligence  aaai   pp      
     
  

fidubba  cohn  hogg  bhatt   dylla

ivanov  y     bobick  a          recognition of visual activities and interactions by stochastic parsing  ieee transactions on pattern analysis and machine intelligence  pami  
       
jiang  z   lin  z     davis  l  s          a tree based approach to integrated action localization  recognition and segmentation  third workshop on human motion  in
conjuntion with eccv  
kakas  a   kowalski  r     toni  f          abductive logic programming  journal of logic
and computation             
kakas  a     riguzzi  f          abductive concept learning  new generation computing 
               
konik  t     laird  j          learning goal hierarchies from structured observations and
expert annotations  machine learning                 
laptev  i          on space time interest points  international journal of computer vision 
               
laptev  i     perez  p          retrieving actions in movies  in ieee international conference on computer vision  iccv   pp     
le  q   zou  w   yeung  s     ng  a          learning hierarchical invariant spatio temporal
features for action recognition with independent subspace analysis  in ieee conference on computer vision and pattern recognition  cvpr   pp            ieee 
lowe  d          distinctive image features from scale invariant keypoints  international
journal of computer vision                
mccarthy  j          applications of circumscription to formalizing common sense knowledge  artificial intelligence                
medioni  g   cohen  i   bremond  f   hongeng  s     nevatia  r          event detection
and analysis from video streams  ieee transactions on pattern analysis and machine
intelligence  pami                  
miller  r     shanahan  m          narratives in the situation calculus  journal of logic
and computation                
morariu  v  i     davis  l  s          multi agent event recognition in structured scenarios  
in ieee conference on computer vision and pattern recognition  cvpr   pp      
     
morariu  v  i   harwood  d     davis  l  s          tracking peoples hands and feet
using mixed network and or search   in ieee transactions on pattern analysis and
machine intelligence  pami  
moyle  s          using theory completion to learn a robot navigation control program 
proceedings of the international conference on ilp         
moyle  s     muggleton  s          learning programs in the event calculus  lnai      
springer verlag         
muggleton  s          inverse entailment and progol  new generation computing           
       
  

filearning relational event models from video

muggleton  s     bryant  c  h          theory completion using inverse entailment  in proceedings of the international conference on ilp  pp          uk  springer verlag 
needham  c   santos  p   magee  d   devin  v   hogg  d     cohn  a          protocols
from perceptual observations  artificial intelligence                    
nevatia  r   hobbs  j     bolles  b          an ontology for video event representation 
in computer vision and pattern recognition workshop  cvprw      pp         
ieee 
nienhuys cheng  s     de wolf  r          foundations of inductive logic programming 
vol        springer verlag 
oh  s   hoogs  a   perera  et al          a large scale benchmark dataset for event recognition in surveillance video  in ieee conference on computer vision and pattern
recognition  cvpr   pp           
poole  d   goebel  r     aleliunas  r          theorist  a logical reasoning system for
defaults and diagnosis  in the knowledge frontier  pp         
quinlan  j     cameron jones  r          foil  a midterm report  in proceedings of the
european conference on machine learning  ecml   pp      
quinlan  j          learning logical definitions from relations  machine learning        
       
rabiner  l          a tutorial on hidden markov models and selected applications in speech
recognition  proceedings of the ieee                 
randell  d  a   cui  z     cohn  a          a spatial logic based on regions and connection  in proceedings of the international conference on knowledge representation
and reasoning  pp          morgan kaufmann 
ryoo  m  s     aggarwal  j  k          semantic representation and recognition of continued
and recursive human activities  international journal of computer vision           
   
ryoo  m     aggarwal  j          stochastic representation and recognition of high level
group activities  international journal of computer vision                 
sridhar  m   cohn  a  g     hogg  d  c          unsupervised learning of event classes from
video  in proceedings of the national conference on artificial intelligence  aaai  
pp           
tamaddoni nezhad  a   chaleil  r   kakas  a     muggleton  s          application of
abductive ilp to learning metabolic network inhibition from temporal data  machine
learning                 
tamaddoni nezhad  a     muggleton  s          the lattice structure and refinement
operators for the hypothesis space bounded by a bottom clause  machine learning 
             
van de weghe  n   cohn  a   de tre  g     de maeyer  p          a qualitative trajectory calculus as a basis for representing moving objects in geographical information
systems  control and cybernetics             
  

fidubba  cohn  hogg  bhatt   dylla

veeraraghavan  h   papanikolopoulos  n     schrater  p          learning dynamic event
descriptions in image sequences  in ieee conference on computer vision and pattern
recognition  cvpr   pp     
vu  v  t   bremond  f     thonnat  m          automatic video interpretation  a novel
algorithm for temporal scenario recognition  in proceedings of the international joint
conference on artifical intelligence  ijcai   vol     pp           
walther  c          a mechanical solution of schuberts steamroller by many sorted resolution  artificial intelligence                 
yilmaz  a   javed  o     shah  m          object tracking  a survey  acm computing
surveys  csur              
youtube        http   www youtube com yt press statistics html  accessed january          

  

fi