journal of artificial intelligence research                  

submitted        published      

tree width and the computational complexity
of map approximations in bayesian networks
johan kwisthout

j kwisthout donders ru nl

radboud university nijmegen
donders institute for brain  cognition and behaviour
montessorilaan         hr nijmegen  the netherlands

abstract
the problem of finding the most probable explanation to a designated set of variables given partial evidence  the map problem  is a notoriously intractable problem in
bayesian networks  both to compute exactly and to approximate  it is known  both from
theoretical considerations and from practical experience  that low tree width is typically
an essential prerequisite to efficient exact computations in bayesian networks  in this
paper we investigate whether the same holds for approximating map  we define four
notions of approximating map  by value  structure  rank  and expectation  and argue
that all of them are intractable in general  we prove that efficient value approximations 
structure approximations  and rank approximations of map instances with high tree width
will violate the exponential time hypothesis  in contrast  we show that map can sometimes be efficiently expectation approximated  even in instances with high tree width  if
the most probable explanation has a high probability  we introduce the complexity class
fert  analogous to the class fpt  to capture this notion of fixed parameter expectationapproximability  we suggest a road map to future research that yields fixed parameter
tractable results for expectation approximate map  even in graphs with high tree width 

   introduction
one of the most important computational problems in bayesian networks is the map problem  i e   the problem of finding the joint value assignment to a designated set of variables
 the map variables  with the maximum posterior probability  given partial observation of
the remaining variables  the map problem is notably intractable  as it is nppp  hard  it
is strictly harder  given usual assumptions in computational complexity theory  than the
pp hard inference problem  park   darwiche         in a sense  it can be seen as combining
an optimization problem with an inference problem  both of which potentially contribute
to the problems complexity  park   darwiche        p        even when all variables in
the network are binary and the network has the  very restricted  polytree topology  map
remains np hard  de campos         only when both the optimization and the inference
part of the problem can be computed tractably  for example  if both the tree width of the
network is small  the cardinality of the variables is low  and the most probable joint value
assignment has a high probability  map can be computed tractably  kwisthout        
it is known that  for arbitrary probability distributions and under the assumption of the
exponential time hypothesis  low tree width of the moralized graph of a bayesian network
is a necessary condition for the inference problem in bayesian networks to be tractable

     ai access foundation  all rights reserved 

fikwisthout

 kwisthout  bodlaender    van der gaag         this result can easily be extended to map 
as we will show in section   
map is also intractable to approximate  abdelbar   hedetniemi        kwisthout 
            park   darwiche         while it is obviously the case that a particular instance
to the map problem can be approximated efficiently when it can be computed exactly
efficiently  it is as yet unclear whether approximate map computations can be rendered
tractable under different conditions than exact map computations  crucial here is the
question what we mean with a statement as algorithm a approximates the map problem 
typically  in computer science  approximation algorithms guarantee that the output of the
algorithm has a value that is within some bound of the value of the optimal solution  for
example  the canonical approximation algorithm to the vertex cover problem selects an
edge at random  puts both endpoints in the vertex cover  and removes these nodes from
the instance  this algorithm is guaranteed to get a solution that has at most twice the
number of nodes in the vertex cover as the optimal vertex set  however  typical bayesian
approximation algorithms have no such guarantee  in contrast  they may converge to the
optimal value given enough time  such as the metropolis hastings algorithm   or they may
find an optimal solution with a high probability of success  such as repeated local search
strategies  
in this paper we assess four different notions of approximation relevant for the map
problem  in particular value approximation  structure approximation  rank approximation 
and expectation approximation of map  after introducing notation and providing some
preliminaries  section     we show that each of these approximations is intractable under
the assumption that p    np  respectively np   bpp  section     building on the result
by kwisthout et al         we show in section   that bounded tree width is indeed a
necessary condition for efficient value approximation  structure approximation  and rankapproximation of map  in section   we argue that this need not be the case for expectationapproximation  we introduce the parameterized complexity classes fert  fixed error
randomized tractable  and fpert  fixed parameter and error randomized tractable 
as natural extensions to the class fpt  we introduce a map variant with some additional
constraints and we show that constrained map is intractable  pp hard  in general 
however  constrained map is in fert when parameterized by the probability of the
most probable explanation  even when tree width is high  we conclude the paper in section
  

   preliminaries
in this section  we introduce our notational conventions and provide some preliminaries on
bayesian networks  graph theory  and complexity theory  in particular definitions of the
map problem  tree width  parameterized complexity theory  and the exponential time
hypothesis  for a more thorough discussion of these concepts  the reader is referred to
textbooks such as those by darwiche         arora and barak         and downey and
fellows        
   

fitree width and map approximations

    bayesian networks
a bayesian network b    gb   pr  is a graphical structure that succinctly represents a joint
probability distribution over a set of stochastic variables  b includes a directed acyclic graph
gb    v  a   where v models  in a one to one mapping  the stochastic variables and a
models the conditional  in dependences between them  and a set of parameter probabilities
pr in the form of conditional probability tables  cpts   capturing the strengths of the
relationships
q between the variables  the network models a joint probability distribution
pr v    ni   pr vi    vi    over its variables  here   vi   denotes the parents of vi in gb  
as notational convention we will use upper case letters to denote individual nodes in the
network  upper case bold letters to denote sets of nodes  lower case letters to denote value
assignments to nodes  and lower case bold letters to denote joint value assignments to sets
of nodes  we will use node and variable interchangeably 
one of the key computational problems in bayesian networks is the problem to find the
most probable explanation for a set of observations  i e   a joint value assignment to a designated set of variables  the explanation set  that has maximum posterior probability given
the observed variables  the joint value assignment to the evidence set  in the network  if
the network is bi partitioned into explanation variables and evidence variables this problem
is known as most probable explanation  mpe   the more general problem  where
the network also includes variables that are neither observed nor to be explained  referred
to as intermediate variables  is known as  partial or marginal  map  this problem is
typically defined formally as follows 
map
instance  a bayesian network b    gb   pr   where v is partitioned into a set of
evidence nodes e with a joint value assignment e  a set of intermediate nodes i  and an
explanation set h 
output  a joint value assignment h to h such that for all joint value assignments h  to
h  pr h   e   pr h    e  
in the remainder  we use the following definitions  for an arbitrary map instance
 b  h  e  i  e   let cansol b refer to the set of candidate solutions to  b  h  e  i  e   with
optsol b  cansol b denoting the optimal solution  or  in case of a draw  one of the optimal
solutions  to the map instance  when cansol b is ordered according to the probability of the
candidate solutions  breaking ties between candidate solutions with the same probability
arbitrarily   then optsol     m
refers to the set of the first m elements in cansol b   viz  the m
b
most probable solutions to the map instance  for a particular notion of approximation 
we refer to an  unspecified  approximate solution as approxsol b  cansol b  
    tree width
an important structural property of a bayesian network b is its tree width  which can be
defined as the minimum width of any tree decomposition  or equivalently  the minimal size
of the largest clique in any triangulation  of the moralization gm
b of the network  treewidth plays an important role in the complexity analysis of bayesian networks  as many
otherwise intractable computational problems can be rendered tractable  provided that the
tree width of the network is small  the moralization  or moralized graph  gm
b is the
   

fikwisthout

undirected graph that is obtained from gb by adding arcs so as to connect all pairs of
parents of a variable  and then dropping all directions  a triangulation of gm
b is any
m
chordal graph gt that embeds gb as a subgraph  a chordal graph is a graph that does
not include loops of more than three variables without any pair being adjacent 
a tree decomposition  robertson   seymour        of a triangulation gt now is a tree
tg such that each node xi in tg is a bag of nodes which constitute a clique in gt   and
for every i  j  k  if xj lies on the path from xi to xk in tg   then xi  xk  xj   in the
context of bayesian networks  this tree decomposition is often referred to as the junction
tree or clique tree of b  the width of the tree decomposition tg of the graph gt is defined
as the size of the largest bag in tg minus    i e   maxi   xi        the tree width tw of
a bayesian network b now is the minimum width over all possible tree decompositions of
triangulations of gm
b  
    complexity theory
we assume that the reader is familiar with basic notions from complexity theory  such
as intractability proofs  the computational complexity classes p and np  and polynomialtime reductions  in this section we shortly review some additional concepts that we use
throughout the paper  namely the complexity classes pp and bpp  the exponential time
hypothesis and some basic principles from parameterized complexity theory 
the complexity classes pp and bpp are defined as classes of decision problems that are
decidable by a probabilistic turing machine  i e   a turing machine that makes stochastic
state transitions  in polynomial time with a particular  two sided  probability of error  the
difference between these two classes is in the bound on the error probability  yes instances
for problems in pp are accepted with probability         where  may depend exponentially
on the input size  i e        cn for a constant c       yes instances for problems in bpp
are accepted with a probability that is polynomially bounded away from      i e        nc   
pp complete problems  such as the problem of determining whether the majority of truth
assignments to a boolean formula  satisfies   are considered to be intractable  indeed  it
can be shown that np  pp  in contrast  problems in bpp are considered to be tractable 
informally  a decision problem  is in bpp if there exists an efficient randomized  monte
carlo  algorithm that decides  with high probability of correctness  given that the error is
polynomially bounded away from      the probability of answering correctly can be boosted
to be arbitrarily close to   while still requiring only polynomial time  while obviously
bpp  pp  the reverse is unlikely  in particular  it is conjectured that bpp   p  clementi 
rolim    trevisan        
the exponential time hypothesis  eth   introduced by impagliazzo and paturi        
states that there exists a constant c     such that deciding any  sat instance with n
variables takes at least  cn   time  note that the eth is a stronger assumption than
the assumption that p    np  a sub exponential
but not polynomial time algorithm for

 
 sat  such as an algorithm running in o   n    would contradict the eth but would not
imply that p   np  we will assume the eth in our proofs that show the necessity of low
tree width for efficient approximation of map 
sometimes problems are intractable  i e   np hard  in general  but become tractable
if some parameters of the problem can be assumed to be small  a problem  is called
   

fitree width and map approximations

fixed parameter tractable for a parameter   or a set              m   of parameters  if it can
be solved in time  exponential  or even worse  only in  and polynomial in the input size
 x   i e   in time o f      x c   for a constant c     and an arbitrary computable function
f   in practice  this means that problem instances can be solved efficiently  even when
the problem is np hard in general  if  is known to be small  in contrast  if a problem
is np hard even when  is small  the problem is denoted as para np hard for   the
parameterized complexity class fpt consists of all fixed parameter tractable problems  
while traditionally  is defined as a mapping from problem instances to natural numbers
 e g   flum   grohe        p      one can easily enhance the theory for rational parameters
 kwisthout         in the context of this paper  we will in particular consider rational
parameters in the range         and we will liberally mix integer and rational parameters 

   approximating map
it is widely known  both from practical experiences and from theoretical results  that small
tree width is often a necessary constraint to render exact bayesian inferences tractable 
however  it is often assumed that such intractable computations can be efficiently approximated using inexact algorithms  this assumption appears to be warranted by the observation
that in many cases approximation algorithms seem to do a reasonable job in  e g   estimating posterior distributions  even in networks with high tree width where exact computations
are infeasible  cheng   druzdzel        sontag  meltzer  globerson  weiss    jaakkola 
       whether this observation has a firm theoretical basis  i e   whether approximation
algorithms can or cannot in principle perform well even in situations where tree width can
grow large  is to date not known 
crucial in answering this question is to make precise what efficiently approximated actually pertains to  the on line merriam webster dictionary lists as one of its entries for
approximate to be very similar to but not exactly like  something   in computer science 
this similarity is typically defined in terms of value  approximate solution a has a value
that is close to the value of the optimal solution  however  other notions of approximation
can be relevant  one can think of approximating not the value of the optimal solution  but
the appearance  approximate solution a  closely resembles the optimal solution  also  one
can define an approximate solution as one that ranks close to the optimal solution  approximate solution a   ranks within the top m solutions  note that these notions can refer
to completely different solutions  one can have situations where the second best solution
does not resemble the optimal solution at all  whereas solutions that look almost the same
have a very low value as compared to the optimal solution  van rooij   wareham       
kwisthout         similarly  the second best solution may either have a value that is almost
as good as the optimal solution  or much worse 
in many practical applications  in particular of bayesian inferences  these definitions
of approximation do not  fully  capture the actual notion we are interested in  for example  when trying to approximate the map explanation using some sort of randomized
computation  we have no guarantee on the quality of the solution found  however  we may
have a bound on the likeliness of a good solution  the current state of the art approximate
algorithms for map  annealedmap  yuan  lu    druzdzel        p loc  park   darwiche        bp ls  park   darwiche        all employ this strategy  the added notion of
   

fikwisthout

approximation here  induced by the use of randomized computations  is the allowance of a
bounded amount of error  
in the remainder of this section we will elaborate on these notions of approximation
when applied to the map problem  we will give formal definitions of these approximate
problems and show why all of them are intractable in general  for map approximation
by value and by structure we will interpret known results in the literature  for mapapproximation by rank we give a formal proof of intractability  for map approximation
using randomized algorithms we give an argument from complexity theory 
    value approximation
value approximating map is the problem of finding an explanation approxsol b  cansol b
that has a value  close to the value of the optimal solution  this closeness can be defined in
an additive or in a relative manner  additive meaning that the absolute difference between
the probability of the optimal and the approximate solution is smaller than some value  
relative that the ratio between the probability of the optimal and the approximate solution
is smaller than some value   both problems are intractable in general  abdelbar and
hedetniemi        proved np hardness of relative value approximation for any constant
     this result holds for networks with only binary variables  with at most three incoming
arcs per variable  and no evidence  in addition  kwisthout        showed that it is np hard
in general to find an explanation approxsol b with pr approxsol b   e     for any constant
      and thus that pr optsol b   e   pr approxsol b   e    for    pr optsol b   e    
the latter result holds even for networks with only binary variables  at most two incoming
arcs per variable  a single evidence variable  and no intermediate variables  i e   when we
approximate an mpe problem  
definition      additive value approximation of map  let optsol b be the optimal
solution to a map problem  an explanation approxsol b  cansol b is defined to  additive
value approximate optsol b if pr optsol b   e   pr approxsol b   e    
result      kwisthout        it is np hard to  additive value approximate map for
   pr optsol b   e    for any constant      
definition      relative value approximation of map  let optsol b be the optimal
solution to a map problem  an explanation approxsol b  cansol b is defined to  relative
pr optsol b   e 
value approximate optsol b if pr approxsol
  e    
b

result      abdelbar   hedetniemi        it is np hard to  relative value approximate
pr optsol b   e 
map for pr approxsol
  e    for any      
b

   observe that some algorithms always converge to the optimal solution  but may take exponential time
to do so  e g   mcmc type approaches   however  we can turn such an algorithm into an expectationapproximation algorithm by adding a clock that halts computations after time  polynomially in the input
size  and returning the current best solution which may or may not be optimal  gill        

   

fitree width and map approximations

    structure approximation
structure approximating map is the problem of finding an explanation approxsol b 
cansol b that structurally resembles the optimal solution  this is captured using a solution
distance function  a metric associated with each optimization problem relating candidate
solutions with the optimal solution  hamilton  muller  van rooij    wareham         for
map  the typical structure distance function dh  approxsol b   optsol b   is the hamming distance between explanation approxsol b and the most probable explanation optsol b   it has
been shown by kwisthout        that no algorithm can calculate the value of even a single
variable in the most probable explanation in polynomial time  unless p   np  that is  it
is np hard to find an explanation with dh  approxsol b   optsol b     optsol b       even if
the variables of the network are bi partitioned into explanation and evidence variables  and
each variable has at most three possible values 
definition      structure approximation of map  let optsol b be the optimal solution to a map problem and let dh be the hamming distance  an explanation approxsol b 
cansol b is defined to d structure approximate optsol b if dh  approxsol b   optsol b    d 
result      kwisthout        it is np hard to d structure approximate map for any
d   optsol b      
    rank approximation
apart from allowing an explanation that resembles  or has a probability close to  the most
probable explanation  we can also define an approximate solution approxsol b as an explanation which is one of the m best explanations  for a constant m  that is  approxsol b 
optsol     m
for some m  note that this explanation may not resemble the most probable
b
explanation nor needs to have a relatively high probability  only that it is ranked within the
m most probable explanations  we will denote this approximation as a rank approximation 
definition      rank approximation of map  let optsol     m
 cansol b be the set of
b
the m most probable solutions to a map problem and let optsol b be the optimal solution  an
explanation approxsol b  cansol b is defined to m rank approximate optsol b if approxsol b 
optsol     m
 
b
we will prove that it is np hard to m rank approximate map for any constant m  we do so
by a reduction from a variant of lexsat  based on the reduction in kwisthout  bodlaender 
and van der gaag         lexsat is defined as follows 
lexsat
instance  a boolean formula  with n variables x            xn  
output  the lexicographically largest truth assignment x to x    x            xn   that
satisfies   the output is  if  is not satisfiable 
here  the lexicographical order of truth assignments maps a truth assignment x   x            xn
to a string       n   with    n  all variables set to false  is the lexicographically smallest  and
   n  all variables set to true  is the lexicographically largest truth assignment  lexsat is
np hard  in particular  lexsat has been proven to be complete for the class fpnp  krentel 
   

fikwisthout

v









x 

x 





x 

x 

x 

x
figure    example construction of bex from lexsat  instance ex
       in our proofs we will use the following variant that always returns a truth assignment
 rather than   in case  is unsatisfiable  
lexsat 
instance  a boolean formula  with n variables x            xn  
output  the lexicographically largest satisfying truth assignment x to     x     
that satisfies  
note that if  is satisfiable  then x  is never set to false in the lexicographically largest
satisfying truth assignment to   yet x  is necessarily set to false if  is not satisfiable 
hence  unsatisfying truth assignments to  are always ordered after satisfying truth assignments in the lexicographical ordering  note that lexsat trivially reduces to lexsat  using
a simple transformation  we claim the following 
theorem     no algorithm can find an approximation approxsol b  optsol     m
  for any
b
constant m  in polynomial time  unless p   np 
in our proof we describe a polynomial time one turing reduction  from lexsat  to mrank approximated map for an arbitrary constant m  the reduction largely follows the
reduction as presented by kwisthout et al         with some additions  we will take the
following lexsat   instance as running example in the proof  ex   x    x   x    
correspondingly  ex    x      x    x   x     in this example  we set m     in the
example construct  we now construct a bayesian network b from  as follows  figure    
for each variable xi in   we introduce a binary root variable xi in b with possible
values true and false  we set the prior probability distribution of these variables to
i    
pr xi   true           n  
  in addition  we include a uniformly distributed variable
xn   in b with m values x n             xm
n     the variables x            xn together form the set
x  note that the prior probability of a joint value assignment x to x is higher than the prior
probability of a different joint value assignment x  to x  if and only if the corresponding
   a a function problem f is polynomial time one turing reducible to a function problem g if there exist
polynomial time computable functions t  and t  such that for every x f  x    tl  x  g t   x     toda 
       one turing reductions can be seen as equivalent to many one reductions  but then applied to
function problems 

   

fitree width and map approximations

truth assignment x to the lexsat  instance has a lexicographically larger truth assignment
than x    in the running example  we have that pr x    true           pr x    true   
       pr x    true          and pr x    true          and pr x    x      pr x   
 
x       pr x    x            observe that we have that pr x            pr xi     pr xi    
pr x         pr xi     pr xi   for every i  i e   the ordering property such as stated above
is attained 
for each logical operator t in   we introduce an additional binary variable in b
with possible values true and false  and with as parents the sub formulas  or single subformula  in case of a negation operator  that are bound by the operator  the conditional
probability distribution of that variable matches the truth table of the operator  i e   pr t  
true    t        if and only if the operator evaluates to true for that particular truth
value of the sub formulas bound by t   the top level operator is denoted by v   it is readily
seen that pr v   true   x      if and only if the truth assignment to the variables in
 that matches x satisfies   and pr v   true   x      otherwise  observe that the
m valued variable xn   is independent of every other variable in b   further note that the
network  including all prior and conditional probabilities  can be described using a number
of bits which is polynomial in the size of   in the map instance constructed from   we set
v as evidence set with v   true as observation and we set x   xn     as explanation
set 
proof  let  be an instance of lexsat    and let b be the network constructed from 
as described above  we have for any joint value assignment x to x that pr x   x   v  
true      pr x   x  for a normalization constant      if x corresponds to a satisfying
truth assignment to   and pr x   x   v   true      if x corresponds to a non satisfying
truth assignment to   given the prior probability distribution of the variables in x  we
have that all satisfying joint assignments x to x are ordered by the posterior probability
pr x   v   true       where all non satisfying joint value assignments have probability
pr x   v   true      and thus are ordered after satisfying assignments  the joint value
assignment that has the highest posterior probability thus is the lexicographically largest
satisfying truth assignment to  
if we take the m th valued variable xn   into account  we have that for every x  the m
joint value assignments to x   xn     have the same probability since pr x  xn     v  
true    pr x   v   true   pr xn      but then  the m joint value assignments xm to
x   xn     that correspond to the lexicographically largest satisfying truth assignment x
to  all have the same posterior probability pr xm   v   true   thus  any algorithm that
returns one of the m th ranked joint value assignments to the explanation set x   xn    
with evidence v   true can be transformed in polynomial time to an algorithm that
solves lexsat    we conclude that no algorithm can m rank approximate map  for any
constant m  in polynomial time  unless p   np 

note that  technically speaking  our result is even stronger  as lexsat  is fpnp complete and the reduction described above actually is a one turing reduction from lexsat 
to m rank approximation map  the latter problem is fpnp  hard  we can strengthen the
result further by observing that all variables  minus v   that mimic operators deterministically depend on their parents and thus can be added to the explanation set without
substantially changing the proof above  this implies that m rank approximation mpe is
also fpnp  hard  lastly  we can strengthen the result by replacing the m th valued variable
   

fikwisthout

xn   by dlog  me unconnected binary variables xn   to xn dlog  me with uniform probability  still  any algorithm returning one of the m th ranked joint value assignments to
x xn             xn dlog  me   in polynomial time will effectively solve lexsat  in polynomial
time 
result     it is np hard to m rank approximate map for any constant m 
    expectation approximation
the last notion of map approximation we will discuss here returns in polynomial time
an explanation approxsol b  cansol b that is likely to be the most probable explanation 
but allows for a small margin of error  i e   there is a small probability that the answer is
not the optimal solution  and then no guarantees are given on the quality of that solution 
these approximations are closely related to randomized algorithms that run in polynomial
time but whose output has a small probability of error  viz   monte carlo algorithms  this
notion of approximationwhich we will refer to as expectation approximation  kwisthout  
van rooij       is particularly relevant for typical bayesian approximation methods  such
as monte carlo sampling and repeated local search algorithms 
definition       expectation approximation of map  let optsol b be the optimal solution to a map problem and let e be the the expectation function  papoulis        
an explanation approxsol b  cansol b is defined to  expectation approximate optsol b if
e pr optsol b      pr approxsol b       
in order to be of practical relevance  we want the error to be small  i e   when casted
as a decision problem  we want the probability of answering correctly to be bounded away
from      in that case  we can amplify the probability of answering correctly arbitrarily
close to   in polynomial time  by repeated evocation of the algorithm  otherwise  e g   if
the error depends exponentially on the size of the input  we need an exponential number
of repetitions to achieve such a result  problems that enjoy polynomial time monte carlo
algorithms are in the complexity class bpp  problems that may need exponential time to
reduce the probability of error arbitrarily close to   are in the complexity class pp 
as map is np hard  an efficient randomized algorithm solving map in polynomial time
with a bounded probability of error  would imply that np  bpp  this is considered to be
highly unlikely  as almost every problem that enjoys an efficient randomized algorithm has
been proven to be in p  i e   be decidable in deterministic polynomial time   on various
grounds it is believed that bpp   p  clementi et al          and thus an efficient randomized algorithm for map would  under that assumption  establish p   np  therefore  no
algorithm can expectation approximate map in polynomial time with bounded margin of
error unless np  bpp  this result holds also for mpe  which is in itself already np hard 
even for binary variables and in degree    kwisthout         
   the most dramatic example of such a problem is primes  given a natural number  decide whether
it is prime  while efficient randomized algorithms for primes have been around quite some time
 establishing that primes  bpp   only fairly recently it has been proven that primes is in p  agrawal 
kayal    saxena        
   in fact  it holds for value approximation  structure approximation  and rank approximation of map as
well  as all three problems are in themselves np hard  see also abdelbar   hedetniemi        p      

   

fitree width and map approximations

result      there cannot exist a randomized algorithm that  expectation approximates
map in polynomial time for           nc for a constant c unless np  bpp 
    discussion
in the previous subsections we showed that all approximation notions we established are in
fact intractable  under various assumptions  the results hold for map in general  but can
in many cases be strengthened to hold for mpe  i e   where the network is two partitioned
into evidence and explanation variables   in either case  both the cardinality c and in degree
d of the nodes  and consequently  the size of the cpts  is bounded  the results hold with
empty  or singleton  evidence sets  the results are summarized in table   
approximation
value  additive
value  ratio
structure
rank
expectation

constraints
c      d     
 e       i   
c      d     
e 
c      d     
i 
c      d     
 e       i   
c      d     
 e       i   

assumption
p    np

reference
 kwisthout        p       

p    np

 abdelbar   hedetniemi        p     

p    np

 kwisthout        p      

p    np

section    

np   bpp

section    

table    summary of intractability results for map approximations

   the necessity of low tree width for efficient approximation of map
in the previous section we have shown that for four notions of approximating map  no
efficient general approximation algorithm can be constructed unless either p   np or np 
bpp  however  map is fixed parameter tractable for a number of problem parameters 
for example   tw  c  q map is in fpt for parameters tree width  tw   cardinality of the
variables  c   maxi   vi  v     and probability of the most probable solution  q  
pr optsol b   e    surely  if we can compute              m  map exactly in fpt time  we can
also approximate              m  map in fpt time  a question remains  however  whether
approximate map can be fixed parameter tractable for a different set of parameters than
exact map 
tree width has been shown to be a necessary parameter for efficient exact computation of the inference problem  and  by a trivial adjustment illustrated in section     
also of map   under the assumption that the eth holds  kwisthout et al          in
this section  we will show that low tree width is also a necessary parameter for efficient
approximate computation for value approximations  structure approximations  and rankapproximations  we also argue  in section    that it is not a necessary parameter for
efficient expectation approximation  in the next sub section we will review so called treewidth preserving reductions  tw reductions   a special kind of polynomial many one reductions that preserve tree width of the instances  kwisthout et al          in sub section
   

fikwisthout

    we sketch how this notion can be used to tw reduce constraint satisfaction to
inference  together with the known result that constraint satisfaction instances
with high tree width cannot have sub exponential algorithms  unless the eth fails  marx 
       it was established by kwisthout et al  that there cannot be a  general purpose  algorithm that decides inference on instances with high tree width in sub exponential time 
unless the eth fails  here  the inference problem is the problem of deciding whether in
a bayesian network b with designated sets h and e and a rational number q  it is the case
that pr h   h   e   e    q  more precisely  the following theorem was proved 
theorem     if there exists a computable function f such that inference can be decided
by an algorithm running in time
f  gm
b  

o 

 kbk

tw gm
b    
log tw gm  
b

for arbitrary inference instances  b  h  h  e  e  q  with a moralized graph gm
b with treem
width tw gb    then the eth fails 
the reader is referred to kwisthout et al         for the full proof   in the remainder of
this section  we will show how this proof can be augmented to establish similar results for
map  value approximate map  structure approximate map  and rank approximate map
 sub sections     and      
    tree width preserving reductions
tree width preserving reductions are defined by kwisthout et al         as a means to reduce
constraint satisfaction to inference while ensuring that tree width is preserved
between instances in the reduction  modulo a linear factor 
definition      kwisthout et al         let a and b be computational problems such
that tree width is defined on instances of both a and b  we say that a is polynomialtime tree width preserving reducible  or tw reducible  to b if there exists a polynomial time
computable function g and a linear function l such that x  a if and only if g x   b and
tw g x     l tw x    the pair  g  l  is called a tw reduction 
we will use this notion to show that constraint satisfaction also tw reduces to map 
value approximate map  structure approximate map  and rank approximate map 
    proof sketch
the tw reduction from  binary  constraint satisfaction to inference  as presented by
kwisthout et al          constructs a bayesian network bi from an instance i    v  d  c 
of constraint satisfaction  where v denotes the set of variables of i  d denotes the set
of values of these variables  and c denotes the set of binary constraints defined over v  v 
   the results by kwisthout et al         did not rule out the existence of special case algorithms  that
assume  and utilize  a particular property of the instance  such as a particular orientation of the arcs
or particular planarity properties of the graph structure  failing when the assumption is violated  the
results in the current paper  that are built on this result  inherit this constraint 

   

fitree width and map approximations

r 

r 
x 

x 

x 
x 
r 

r 

figure    example construction of bi from example csp instance i
the constructed network bi includes uniformly distributed variables xi   corresponding
with the variables in v  and binary variables rj   corresponding with the constraints in c 
the parents of the variables rj are the variables xi that are bound by the constraints 
their conditional probability distributions match the imposed constraints on the variables
 i e   pr rj   true   x    rj         if and only if the joint value assignment x to
the variables bound by rj matches the constraints imposed on them by rj   figure   
taken from kwisthout et al   shows the result of the construction so far for an example
constraint satisfaction instance with four variables x  to x    where c contains four
constraints that bind respectively  x    x      x    x      x    x     and  x    x    
the tree width of the thus obtained network equals max    tw gi     where gi is the
primal graph of i  note that the tree width of bi at most increases the tree width of gi by
   in order to enforce that all constraints are simultaneously enforced  the constraint nodes
rj need to be connected by extra nodes mimicking and operators  a crucial aspect of
the tw reduction is the topography of this connection of the nodes rj   care must be taken
not to blow up tree width by arbitrarily connecting the nodes  e g   by a log deep binary
tree  the original proof uses a minimal tree decomposition of the moralization of bi and
describes a procedure to select which nodes need to be connected such that the tree width
of the resulting graph is at most the tree width of gi plus    the conditional probability
distribution of the nodes ak is defined as follows 
v

  if x   v  ak    v   true 
pr ak   true   x   
  otherwise
for a node ak without any parents  pr ak   true       the graph that results from
applying this procedure to the example is given in figure    also taken from kwisthout
et al          now  pr a    true   x      if x corresponds to a satisfying value assignment
to v and   otherwise  correspondingly  pr a    true      if and only if the constraint
satisfaction instance is satisfiable 
    map result
the tw reduction described in the previous sub section can be easily modified to a twreduction from constraint satisfaction to map  we do this by adding a binary node
   

fikwisthout

r 

r 
x 

x 

x 
x 

a 

r 

r 

a 

a 

a 

a 

a 

figure    resulting graph bi after adding nodes ak and appropriate arcs
vi to the thus obtained graph  with a  as its only parent and with conditional probability
pr vi   true   a    true      and pr vi   true   a    false           where 
is a number  smaller than    d  v    consequently  we have that pr vi   true        if i
is satisfiable  and pr vi   true        if i is not satisfiable  hence  a map query with
explanation set h    vi   will return vi   true if and only if i is satisfiable  we added a
single node to bi   with a  as only parent  thus increasing the tree width of bi by at most
   hence  constraint satisfaction tw reduces to map 
    approximation intractability results
in a similar way we can modify the reduction from sub section     to show that valueapproximations  structure approximations  and rank approximations can be tw reduced
from constraint satisfaction  as sketched below 
      value approximation
we add a binary node vi   with a  as its only parent  and with conditional probability
pr vi   true   a    true      and pr vi   true   a    false       we observe
this variable to be set to true  this enforces that pr a    true   vi   true  has
a non zero probability  i e   i is solvable  since otherwise there is conflicting evidence in
the thus constructed network  thus  any value approximation algorithm with explanation
set h    a    and evidence e    vi   true  that can return a solution approxsol b 
cansol b with pr approxsol b   e     for any constant        that is  approximates additively
b 
  effectively solves constraint
for    pr optsol b     or relatively for    pr optsol

satisfaction  if there exists a solution with non zero probability  the construction dictates
that i must be solvable  given that we added a single node to bi   with a  as only parent 
this increases the tree width of bi by at most    hence  constraint satisfaction twreduces to value approximate map 
   

fitree width and map approximations

      structure approximation
observe from the tw reduction to map in sub section     that  since h consists of a
singleton binary variable  we trivially have that no algorithm can find an explanation
approxsol b  cansol b with dh  approxsol b   optsol b     optsol b          since that would
solve the map query  we can extend this result to hold for explanation sets with size
k for any constant k  i e   no structure approximation algorithm can guarantee to return
the correct value of one of the k variables in h in polynomial time in instances of high
tree width  unless the eth fails 
instead of adding a single binary node vi as in the tw reduction to map  we add k
binary nodes vi        vik   all with a  as their only parent and with pr vij   true   a   
true      and pr vij   true   a    false          for    j  k and with  as
s
described in sub section      a map query with explanation set h    jk vij will
then return  jk vik   true if and only if i is satisfiable  if i is not satisfiable  a map
query will return  jk vik   false as most probable explanation  hence  any structureapproximation algorithm that can correctly return the value of one of the variables in h 
effectively solves constraint satisfaction  as we added k nodes to bi   with a  as
their only parent and no outgoing arcs  the tree width of bi increases by at most    hence 
constraint satisfaction tw reduces to structure approximate map 
      rank approximation
we modify the proof of sub section     as follows  in addition to adding a binary node
vi as specified in that section  we also add dlog  me unconnected binary variables mi  
dlog me
 mi        mi     with uniform probability to h  an m rank approximate map query with
explanation set h    vi    mi will return vi   true  and mi set to an arbitrary value 
if and only if i is satisfiable  the addition of mi does not increase tree width  hence 
constraint satisfaction tw reduces to m rank approximate map 
    discussion
for efficient exact computation  value approximation  structure approximation  and rankapproximation of map we showed that bounded tree width is a necessary condition  under the assumption of the eth  for any general purpose algorithm that accepts arbitrary
instances  this does not rule out the possibility that there may exist special purpose algorithms that can compute or approximate map explanations of specific networks with
a special structure or distribution  as was already concluded by kwisthout et al        
for the inference problem in bayesian networks   however  as the previous sub section
shows  the approximation problems are intractable even for extreme lower bounds on the
approximation quality  and by the very nature of the reductions it follows that if we can
effectively approximate map explanations by value  structure  or rank  we can decide the
problem exactly as well  this leaves little room for efficient approximation algorithms for
map instances with high tree width when we approximate by value  structure  or rank 
   

fikwisthout

   expectation approximation and the classes fert and fpert
in the previous section we showed that we cannot value approximate  structure approximate 
or rank approximate map on instances with high tree width  unless the eth fails  now
what about expectation approximation  it appears that the strategy that was employed in
the previous subsection cannot be used to show a similar result for expectation approximation  in fact  we have reasons to believe that efficient expectation approximation of map
indeed depends on a different set of parameters than the other notions of approximation
discussed above  and that bounded tree width is not necessary for this particular notion
of approximation  this notion of parameterized approximability is not well captured by
the traditional fixed parameter tractable class fpt  therefore  we will introduce the parameterized complexity classes fert  fixed error randomized tractable  and fpert
 fixed parameter and error randomized tractable  that characterize this notion of efficient parameterized expectation approximation  intuitively  in contrast to the class fpt 
that parameterizes running time  these classes parameterize the error probability  fert  
respectively both the running time and the error probability  fpert  
to the best of our knowledge  there is no previous work that proposes to parameterize the probability of acceptance of a probabilistic turing machine  montoya and muller
       define the class bpfpt that assumes a bounded error which is independent of the
parameterization   but where the amount of randomness  operationalized by the number
of coins used  is bounded  arvind and raman        propose randomized approximation
algorithms for counting problems  where both the running time and the approximation ratio
are parameterized  but the error probability is constant  both authors  however  assume a
bounded  rather than parameterized  error 
in the next section we will set up the formal machinery for our results  we introduce natural parameterizations of majsat  respectively e majsat  that are in fert 
respectively fpert  we will show that a restricted variant of map indeed is in fert  parameterized by the probability of the most probable explanation  and that the most frugal
explanations problem  kwisthout        is in fpert for a number of parameterizations 
we will elaborate on the relation between these classes and the classes bpp  pp  and fpt 
and finally  we will propose a road map for future research 
    parameterizing the error bound in randomized algorithms
we formally define the complexity class fert as follows 
definition     let  be a decision problem and let  be a parameterization of   we
have that   fert if and only if there exists a probabilistic turing machine m that
halts after time  polynomial in the size of the input x  with the following acceptance criteria 
m accepts yes instances of  with probability       min f        x c   for a constant c and
arbitrary function f   r  h         no instances are accepted with probability at most     
observe that in this definition we demand that m halts after time  polynomial in the input
size  and independent from the parameterization    yet that the probability of acceptance
of yes instances may depend on any function of   intuitively  the class fert characterizes
problems that can be efficiently computed with a randomized algorithm  i e   in polynomial
time  with error arbitrarily close to    if  is bounded  the canonical parameterized problem
   

fitree width and map approximations

that is in fert is  r majsat  where r denotes the fraction of satisfying truth assignments  or  equivalently  the probability that a random truth assignment accepts   this
follows as a corollary from the following result by littman  majercik  and pitassi        
lemma      adapted from littman et al         let v be the number of accepting
truth assignments to a boolean formula   and let v be the estimate of v found via random
sampling using w samples over the variables of   let      be a target approximation
 
error  the probability that  v  v     is less than  e  w  
note that when solving a majsat instance  the target approximation error  directly
depends on the probability r that a random truth assignment accepts  as the acceptable error
 i e   the error that still gives the correct answer to the majsat instance  in the random
sampling algorithm is     r        so  if the probability of acceptance of a random truth
assignment is polynomially bounded away from      we can guarantee an arbitrarily small
error using only polynomially many samples using a straightforward randomized algorithm 
corollary      r majsat  fert 
when we allow both parameterization of the running time and of the probability of acceptance  we get the complexity class fpert defined as follows 
definition     let  be a decision problem and let          be a parameterization of
  we have that           fpert if and only if there exists a probabilistic turing
machine m that halts after time o f         x c     that accepts yes instances of  with
probability       min f           x c     and accepts no instances with probability at most     
here  f    r  r and f    r  h        are arbitrary computable functions and c  and c  are
constants 
we can also define a canonical problem in fpert  based on the observation that  p  sat
is in fpt  flum   grohe        here parameter p denotes the number of variables in the
formula  and on corollary     
e majsat
instance  let  be a boolean formula with n variables xi   i              n  n    
furthermore we partition the variables into sets xe and xm  
question  is there a truth assignment to xe such that the majority of the truth
assignments to xm satisfy  
parameter      p      r  here p is the number of variables in the set xe   we define r
as follows  let rxe denote the ratio of accepting truth assignments to xm given a
particular truth assignment xe to xe   we then define r   minxe        rxe    
informally  r describes the minimum absolute distance to     of the fraction of accepting
truth assignments for any truth assignment xe to xe   observe that we can try  bruteforce  all truth assignments to xe and  for each truth assignment  expectation approximate
whether that truth assignment is such that the majority of truth assignments to xm satisfy
  this algorithm runs in time o  p  nc   for a constant c  and has a probability at least
      f  r  of answering correctly  using a polynomial number of samples  
corollary      p  r e majsat  fpert 
   

fikwisthout

    parameterized expectation approximation of map
proving that a problem  is in fpt is normally done constructively  i e   by giving a
deterministic algorithm that decides  in time o f      x c   for a constant c      similarly 
proving that  is in fert is done by giving a randomized algorithm  that decides  in
polynomial time with error at most      min f        x c    we did not succeed in giving such
an algorithm for map in general  however  we can prove that a restricted variant of map
is in fert when parameterized only by the probability of the most probable explanation 
despite that this restricted variant remains pp complete in general and that bounded treewidth is a necessary parameter to approximate this problem by value  structure  or rank 
constrainedmap
instance  as in map  in addition  we demand that e     h consists of a singleton
node h with no outgoing edges  and  h     true  false  
question  is pr h   true        
parameter  q   pr h   true  
pp completeness of constrained map follows from a trivial modification of the ppcompleteness proof of inference as described by kwisthout        lemma     and lemma
      furthermore  given that the reductions from constraint satisfaction to map 
value approximate map  structure approximate map  and rank approximate map respect
the same restrictions as imposed to constrained map  the necessity of bounded treewidth follows 
to show that  q constrained map is in fert  for the parameter q   pr h  
true   we give the following approximation algorithm  observe that h is a binary sink
node  i e   has no outgoing edges  and that b has no evidence  a simple forward sampling
strategy  henrion        can approximate the distribution of h by sampling values for
the variables in the network according to the probability distribution in the cpts  we
thus estimate pr h  by taking samples  we decide upon approxsol b using this estimation 
note that the degree of error given a particular number of samples depends directly on the
probability q  to be precise  using the chernoff bound we can compute than the number

of samples n needed to have a degree of error lower than  is    q        ln      this gives
us a fixed parameter randomized tractable algorithm for parameter  q  
corollary      q constrained map  fert 
another parameterized problem that can be shown to be fixed error  fixed parameter
randomized tractable is the most frugal explanations heuristic approach to map  introduced by kwisthout         this heuristic  that either marginalizes or samples over intermediate variables  based on some subjective partition of these intermediate variables  into
a set i  and a set i   according to their expected contribution to deciding upon the map
explanation  can be expectation approximated tractably when the tree width of the network is low  the cardinality of the variables is small  the set i  is small  and the probability
distribution is such that a few samples over i suffice to decide upon the mfe explanation
with high probability  the first three parameters ensure bounded running time  whereas
   we will refer to such an algorithm as a fixed error randomized tractable algorithm 

   

fitree width and map approximations

para nppp
fpert

para pp

fert

para np

bpp

fpt
p

figure    inclusion properties for the complexity classes p  bpp  fert  fpert  fpt 
para np  para pp  and para nppp

the final parameter ensures bounded probability of error  hence   tw  c   i       b mfe
is in fpert  where tw denotes the tree width of the network  c denotes the cardinality of
the variables   i    denotes the number of variables we marginalize  not sample  over  and b
denotes some parameter describing a bias towards a particular explanation  in addition it
can be shown that   h   c   i       b mfe is in fpert  where  h  denotes the size of the
explanation set 
corollary      tw  c   i       b mfe  fpert and   h   c   i       b mfe  fpert 
    the relation between fert  fpert  and other complexity classes
the complexity class fert introduced here is the randomized analog of fpt  rather than
parameterizing the running time  as an arbitrary function of  and polynomially in the
input size   here we parameterize the probability of acceptance of yes instances  bpp  fert 
and para pp form natural analogs of p  fpt  and para np  respectively  the class fpert
parameterizes both the running time and the probability of acceptance  using two parameter
sets   and     we thus have that bpp  fert  pp  that fert  fpert  and that
fpt  fpert  obviously  fpert  para nppp   as every slice            nppp  see
flum   grohe        for a discussion of slices of parameterized problems   the inclusion
relations are depicted in figure   
it is conjectured that bpp   p  clementi et al          however  it is not clear whether
this conjecture can be transposed to the parameterized world  that is  whether it can be
conjectured that fert   fpt  it is known that  q   i  map and  q  tw map are fixed
parameter tractable  kwisthout         as constrained map is a special case of map 
these results also hold for constrained map  however  in the intractability proof above
neither  i  nor tw is bounded  to the best of our knowledge there is no parameterized
complexity result known  in either direction  for  q constrained map 
   

fikwisthout

    efficient map approximation  a road map for future research
we have established that a particular  constrained version of map can be efficiently approximated under expectation approximations if the probability of the map explanation
is high  where the tree width of the instance may be unbounded   a next step would be
to investigate the parameterized approximability of current state of the art approximation
algorithms for map and show under which parameterization regimes these algorithms can
be shown to be in fert or fpert 
from a different perspective  it is interesting to further explore the parameterization
of the error in randomized algorithms and  for example  establish an analog for the whierarchy for these parameterizations  that allows us to derive more fine grained negative
parameterization results  in a similar way as proving w    hardness leads to more finegrained negative results than proving para np hardness 

   conclusion
in this paper we analyzed whether low tree width is a prerequisite for approximating map
in bayesian networks  we formalized four distinct notions of approximating map  by value 
structure  rank  or expectation  and argued that approximate map is intractable in general
using either of these notions  in case of value approximation  structure approximation  and
rank approximation we showed that map cannot be approximated using these notions
in  non trivial  instances with high tree width  if the eth holds  however  we showed
that a constrained version of map  despite being pp hard in general  can be tractably
expectation approximated when the most probable explanation has a high probability  we
proposed the complexity classes fert and fpert that capture the parameterization of the
error  respectively error and running time   rather than running time  with these results
we contributed to a fuller understanding of what does and does not make state of the art
approximation algorithms for map feasible in practice 

   acknowledgements
a previous version of this paper  kwisthout        was published in the proceedings of the
seventh european workshop on probabilistic graphical models  pgm        the author
wishes to thank the workshop participants and  both sets of  anonymous reviewers for stimulating discussion and worthwhile suggestions  he thanks in particular hans bodlaender
and todd wareham for valuable comments on an earlier version of this manuscript 

references
abdelbar  a  m     hedetniemi  s  m          approximating maps for belief networks is
np hard and other theorems  artificial intelligence            
agrawal  m   kayal  n     saxena  n          primes is in p  annals of mathematics 
                
arora  s     barak  b          computational complexity  a modern approach  cambridge
university press 
   

fitree width and map approximations

arvind  v     raman  v          approximation algorithms for some parameterized counting problems  in bose  p     morin  p   eds    algorithms and computation  vol      
of lecture notes in computer science  pp          springer berlin heidelberg 
cheng  j     druzdzel  m          ais bn  an adaptive importance sampling algorithm
for evidential reasoning in large bayesian networks  journal of artificial intelligence
research                 
clementi  a   rolim  j     trevisan  l          recent advances towards proving p bpp 
in allender  e   ed    bulletin of the eatcs  vol      eatcs 
darwiche  a          modeling and reasoning with bayesian networks  cambridge university press 
de campos  c  p          new complexity results for map in bayesian networks  in
walsh  t   ed    proceedings of the twenty second international joint conference on
artificial intelligence  pp           
downey  r  g     fellows  m  r          parameterized complexity  springer verlag  berlin 
flum  g     grohe  m          parameterized complexity theory  springer  berlin 
gill  j  t          computational complexity of probabilistic turing machines  siam
journal on computing                
hamilton  m   muller  m   van rooij  i     wareham  h          approximating solution
structure  in demaine  e   gutin  g   marx  d     stege  u   eds    structure theory
and fpt algorithmics for graphs  digraphs and hypergraphs  no        in dagstuhl
seminar proceedings 
henrion  m          propagating uncertainty in bayesian networks by probabilistic logic
sampling  in kanal  l     lemmer  j   eds    proceedings of the second annual
conference on uncertainty in artificial intelligence  pp          new york  elsevier
science 
impagliazzo  r     paturi  r          on the complexity of k sat  journal of computer
and system sciences                   
krentel  m  w          the complexity of optimization problems  journal of computer
and system sciences             
kwisthout  j          the computational complexity of probabilistic networks  ph d 
thesis  faculty of science  utrecht university  the netherlands 
kwisthout  j          most probable explanations in bayesian networks  complexity and
tractability  international journal of approximate reasoning                     
kwisthout  j          structure approximation of most probable explanations in bayesian
networks  in van der gaag  l   ed    proceedings of the twelfth european conference
on symbolic and quantitative approaches to reasoning with uncertainty  vol      
of lnai  pp          springer verlag 
kwisthout  j          treewidth and the computational complexity of map approximations 
in van der gaag  l     feelders  a   eds    proceedings of the seventh european
workshop on probabilistic graphical models  vol       of lecture notes in computer
science  pp          springer international publishing 
   

fikwisthout

kwisthout  j          most frugal explanations in bayesian networks  artificial intelligence 
            
kwisthout  j   bodlaender  h  l     van der gaag  l  c          the necessity of bounded
treewidth for efficient inference in bayesian networks  in coelho  h   studer  r  
  wooldridge  m   eds    proceedings of the   th european conference on artificial
intelligence  pp          ios press 
kwisthout  j   bodlaender  h  l     van der gaag  l  c          the complexity of finding
kth most probable explanations in probabilistic networks  in cerna  i   gyimothy  t  
hromkovic  j   jefferey  k   kralovic  r   vukolic  m     wolf  s   eds    proceedings
of the   th international conference on current trends in theory and practice of
computer science  vol  lncs       pp          springer 
kwisthout  j     van rooij  i          bridging the gap between theory and practice of
approximate bayesian inference  cognitive systems research         
littman  m  l   majercik  s  m     pitassi  t          stochastic boolean satisfiability 
journal of automated reasoning                 
marx  d          can you beat treewidth   in proceedings of the   th annual ieee
symposium on foundations of computer science  pp         
montoya  j  a     muller  m          parameterized random complexity   theory of computing systems                 
papoulis  a          probability  random variables  and stochastic processes   nd edition  
new york  mcgraw hill 
park  j  d     darwiche  a          approximating map using local search  in proceedings
of the   th conference on uncertainty in artificial intelligence  pp          morgan
kaufmann publishers  san francisco  california       
park  j  d     darwiche  a          complexity results and approximation settings for
map explanations  journal of artificial intelligence research             
robertson  n     seymour  p          graph minors ii  algorithmic aspects of tree width 
journal of algorithms            
sontag  d   meltzer  t   globerson  a   weiss  y     jaakkola  t          tightening lp
relaxations for map using message passing  in proceedings of the   th conference in
uncertainty in artificial intelligence  pp          auai press 
toda  s          simple characterizations of p  p  and complete problems  journal of
computer and system sciences          
van rooij  i     wareham  h          intractability and approximation of optimization
theories of cognition  journal of mathematical psychology                   
yuan  c   lu  t     druzdzel  m  j          annealed map  in chickering  d     halpern 
j   eds    proceedings of the twentieth conference in uncertainty in artificial intelligence  pp          aua 

   

fi