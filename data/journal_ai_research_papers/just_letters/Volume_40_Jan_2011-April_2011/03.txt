journal of artificial intelligence research                 

submitted        published      

narrowing the modeling gap 
a cluster ranking approach to coreference resolution
altaf rahman
vincent ng

altaf hlt utdallas edu
vince hlt utdallas edu

human language technology research institute
university of texas at dallas
    west campbell road  mail station ec  
richardson  tx            u s a 

abstract
traditional learning based coreference resolvers operate by training the mention pair
model for determining whether two mentions are coreferent or not  though conceptually
simple and easy to understand  the mention pair model is linguistically rather unappealing
and lags far behind the heuristic based coreference models proposed in the pre statistical
nlp era in terms of sophistication  two independent lines of recent research have attempted to improve the mention pair model  one by acquiring the mention ranking model to
rank preceding mentions for a given anaphor  and the other by training the entity mention
model to determine whether a preceding cluster is coreferent with a given mention  we
propose a cluster ranking approach to coreference resolution  which combines the strengths
of the mention ranking model and the entity mention model  and is therefore theoretically
more appealing than both of these models  in addition  we seek to improve cluster rankers
via two extensions      lexicalization and     incorporating knowledge of anaphoricity by
jointly modeling anaphoricity determination and coreference resolution  experimental results on the ace data sets demonstrate the superior performance of cluster rankers to
competing approaches as well as the effectiveness of our two extensions 

   introduction
noun phrase  np  coreference resolution is the task of identifying which nps  or mentions in
ace terminology    in a text or dialogue refer to the same real world entity or concept  from
a computational perspective  coreference is a clustering task  with the goal of partitioning
a set of mentions into coreference clusters where each cluster contains all and only the
mentions that are co referring  from a mathematical perspective  a coreference relation is
an equivalence relation defined on a pair of mentions  as it satisfies reflexivity  symmetry 
and transitivity  following our previous work on coreference resolution  we use the term
anaphoric to describe a mention that is part of a coreference chain but is not the head of a
chain  given an anaphoric mention mk   an antecedent of mk is a mention that is coreferent
with mk and precedes it in the associated text  and the set of candidate antecedents of mk
consists of all mentions that precede mk   
   more precisely  a mention is an instance of reference to an entity in the real world  in this article  we
treat the terms mention and noun phrase as synonymous and use them interchangeably 
   note that these definitions are somewhat overloaded  linguistically  an anaphor is a noun phrase that
depends on its antecedent for its semantic interpretation  hence  barack obama can be anaphoric in
our definition but not in the formal definition 
c
    
ai access foundation  all rights reserved 

firahman   ng

the research focus of computational coreference resolution exhibited a gradual shift from
heuristic based approaches to machine learning approaches in the past decade  the shift
can be attributed in part to the advent of the statistical natural language processing  nlp 
era  and in part to the public availability of coreference annotated corpora produced as a
result of the muc   and muc   conferences and the series of ace evaluations  one of the
most influential machine learning approaches to coreference resolution is the classificationbased approach  where coreference is recast as a binary classification task  e g   aone  
bennett        mccarthy   lehnert         specifically  a classifier that is trained on
coreference annotated data is used to determine whether a pair of mentions is co referring
or not  however  the pairwise classifications produced by this classifier  which is now commonly known as the mention pair model  may not satisfy the transitivity property inherent
in the coreference relation  since it is possible for the model to classify  a b  as coreferent 
 b c  as coreferent  and  a c  as not coreferent  as a result  a separate clustering mechanism is needed to coordinate the possibly contradictory pairwise classification decisions and
construct a partition of the given mentions 
the mention pair model has significantly influenced learning based coreference research
in the past fifteen years  in fact  many of the recently published coreference papers are
still based on this classical learning based coreference model  e g   bengtson   roth       
stoyanov  gilbert  cardie    riloff         despite its popularity  the model has at least
two major weaknesses  first  since each candidate antecedent for a mention to be resolved
 henceforth an active mention  is considered independently of the others  this model only
determines how good a candidate antecedent is relative to the active mention  but not
how good a candidate antecedent is relative to other candidates  in other words  it fails
to answer the critical question of which candidate antecedent is most probable  second 
it has limitations in its expressiveness  the information extracted from the two mentions
alone may not be sufficient for making an informed coreference decision  especially if the
candidate antecedent is a pronoun  which is semantically empty  or a mention that lacks
descriptive information such as gender  e g   clinton  
recently  coreference researchers have investigated alternative models of coreference that
aim to address the aforementioned weaknesses of the mention pair model  to address the
first weakness  researchers have proposed the mention ranking model  this model determines which candidate antecedent is most probable given an active mention by imposing
a ranking on its candidate antecedents  e g   denis   baldridge      b        iida  inui 
  matsumoto         ranking is arguably a more natural formulation of coreference resolution than classification  as a ranker allows all candidate antecedents to be considered
simultaneously and therefore directly captures the competition among them  another desirable consequence is that there exists a natural resolution strategy for a ranking approach 
a mention is resolved to the candidate antecedent that has the highest rank  this contrasts
with classification based approaches  where many clustering algorithms have been employed
to co ordinate the pairwise coreference decisions  because it is unclear which one is the best  
to address the second weakness  researchers have proposed the entity mention coreference
model  e g   luo  ittycheriah  jing  kambhatla    roukos        yang  su  zhou    tan 
      yang  su  lang  tan    li         unlike the mention pair model  the entity mention
model is trained to determine whether an active mention belongs to a preceding  possibly
partially formed  coreference cluster  hence  it can employ cluster level features  i e   fea   

fia cluster ranking approach to coreference resolution

tures that are defined over any subset of mentions in a preceding cluster   which makes it
more expressive than the mention pair model 
while the entity mention model and the mention ranking model are conceptually simple
extensions to the mention pair model  they were born nearly ten years after the mention pair
model was proposed  and in particular  their contributions should not be under estimated 
they paved a new way of thinking about supervised modeling of coreference that represents
a significant departure from their mention pair counterpart  which for many years is the
learning based coreference model for nlp researchers  the proposal of these two models
is facilitated in part by advances in statistical modeling of natural languages  statistical
nlp models have evolved from capturing local information to global information  and
from employing classification based models to ranking based models  in the context of
coreference resolution  the entity mention model enables us to compute features based on a
variable number of mentions  and the mention ranking model enables us to rank a variable
number of candidate antecedents  nevertheless  neither of these models addresses both
weaknesses of the mention pair model satisfactorily  while the mention ranking model allows
all candidate antecedents to be ranked and compared simultaneously  it does not enable the
use of cluster level features  on the other hand  while the entity mention model can employ
cluster level features  it does not allow all candidates to be considered simultaneously 
motivated in part by this observation  we propose a learning based approach to coreference resolution that is theoretically more appealing than both the mention ranking model
and the entity mention model  the cluster ranking approach  specifically  we recast coreference as the problem of determining which of a set of preceding coreference clusters is the
best to link to an active mention using a learned cluster ranking model  in essence  the
cluster ranking model combines the strengths of the mention ranking model and the entitymention model  and addresses both weaknesses associated with the mention pair model 
while the cluster ranking model appears to be a conceptually simple and natural extension of the entity mention model and the mention ranking model  we believe that such
simplicity stems primarily from our choice of a presentation of these concepts that is easiest
for the reader to understand  in particular  we note that the mental processes involved in
the design of the cluster ranking model are by no means as simple as the way the model
is presented  it requires not only an analysis of the strengths and weaknesses of existing
approaches to learning based coreference resolution and the connection between them  but
also our formulation of the view that the entity mention model and the mention ranking
model are addressing two complementary weaknesses of the mention pair model  we believe
that the significance of our cluster ranking model lies in bridging two rather independent
lines of learning based coreference research that have been going on in the past few years 
one involving the entity mention model and the other the mention ranking model 
in addition  we seek to improve the cluster ranking model with two sources of linguistic knowledge  first  we propose to exploit knowledge of anaphoricity  i e   knowledge of
whether a mention is anaphoric or not   anaphoricity determination is by no means a new
problem  and neither is the use of anaphoricity information to improve coreference resolution  our innovation lies in the way we learn knowledge of anaphoricity  specifically 
while previous work has typically adopted a pipeline coreference architecture  in which
anaphoricity determination is performed prior to coreference resolution and the resulting
information is used to prevent a coreference system from resolving mentions that are de   

firahman   ng

termined to be non anaphoric  for an overview  see the work of poesio  uryupina  vieira 
alexandrov kabadjov    goulart         we propose a model for jointly learning anaphoricity determination and coreference resolution  note that a major weakness of the pipeline
architecture lies in the fact that errors in anaphoricity determination could be propagated
to the coreference resolver  possibly leading to a deterioration of coreference performance
 ng   cardie      a   our joint model is a potential solution to this error propagation
problem 
second  we examine a kind of linguistic features that is not exploited by the majority
of existing supervised coreference resolvers  word pairs that are composed of the strings  or
the head nouns  of an active mention and one of its preceding mentions  intuitively  these
word pairs contain useful information  for example  they may help improve the precision
of a model  by allowing a learner to learn that it only has a moderate probability of
being anaphoric  and that the contrary taken from the phrase on the contrary is never
anaphoric  they may also help improve its recall  by allowing the learner to determine 
for instance  that airline and carrier can be coreferent  hence  they offer a convenient
means to attack one of the major problems in coreference research  identifying coreferent
common nouns that are lexically dissimilar but semantically related  note that they are
extremely easy to compute  even more so than the so called cheap features such as stringmatching and grammatical features  yang  zhou  su    tan         but the majority of
the existing supervised coreference systems are unlexicalized and hence are not exploiting
them  somewhat unexpectedly  however  for researchers who do lexicalize their coreference
models by employing word pairs as features  e g   luo et al         daume iii   marcu       
bengtson   roth         their feature analysis experiments indicate that lexical features
are at best marginally useful  for instance  luo et al  and daume iii and marcu report
that leaving out lexical features in their feature ablation experiments causes the ace value
to drop only by     and      respectively  while previous attempts on lexicalization merely
append all word pairs to a conventional coreference feature set  our goal is to investigate
whether we can make better use of lexical features for learning based coreference resolution 
to sum up  we propose a cluster ranking approach to coreference resolution and a joint
model for exploiting anaphoricity information  and investigate the role of lexicalization in
learning based coreference resolution  besides empirically demonstrating that our clusterranking model significantly outperforms competing approaches on the ace      coreference
data set  and that our two extensions to the model  namely lexicalization and joint modeling 
are effective in improving its performance  we believe our work makes four contributions to
coreference resolution 
narrowing the modeling gap  while machine learning approaches to coreference resolution have received a lot of attention since the mid     s  the mention pair model has
heavily influenced learning based coreference research for more than a decade  and yet this
model lags far behind the heuristic based coreference models proposed in the     s and
    s in terms of sophistication  in particular  the notion of ranking can be traced back to
centering algorithms  for more information  see the books by mitkov        walker  joshi 
  prince         and the idea behind ranking preceding clusters  in a heuristic manner  can
be found in lappin and leasss        influential paper on pronoun resolution  while our
cluster ranking model does not completely close the gap between the simplicity of machine
learning approaches and the sophistication of heuristic approaches to coreference resolu   

fia cluster ranking approach to coreference resolution

tion  we believe that it represents an important step towards narrowing this gap  another
important gap that our cluster ranking model helps to bridge is the two independent lines
of learning based coreference research that have been going on in the past few years  one
involving the entity mention model and the other mention ranking model 
promoting the use of ranking models  while the mention ranking model has been
empirically shown to outperform the mention pair model  denis   baldridge      b        
the former has not received as much attention among coreference researchers as it should 
in particular  the mention pair model continues to be more popularly used and investigated
in the past few years than the mention ranking model  we believe the lack of excitement for
ranking based approaches to coreference resolution can be attributed at least in part to a
lack of theoretical understanding of ranking  as previous work on ranking based coreference
resolution has employed ranking algorithms essentially as a black box  without opening the
black box  it could be difficult for researchers to appreciate the subtle difference between
ranking and classification  in an attempt to promote the use of ranking based models 
we provide a brief history of the use of ranking in coreference resolution  section     and
tease apart the differences between classification and ranking by showing the constrained
optimization problem a support vector machine  svm  attempts to solve in classificationbased and ranking based coreference models  section    
gaining a better understanding of existing learning based coreference models 
recall that lexicalization is one of the two linguistic knowledge sources that we propose to
use to improve the cluster ranking model  note that lexicalization can be applied to not only
the cluster ranking model  but essentially any learning based coreference models  however 
as mentioned before  the vast majority of existing coreference resolvers are unlexicalized  in
fact  the mention ranking model has only been shown to improve the mention pair model on
an unlexicalized feature set  in an attempt to gain additional insights into the behavior of
different learning based coreference models  we compare their performance on a lexicalized
feature set  furthermore  we analyze them via experiments involving feature ablation and
data source adaptability  as well as report their performance on resolving different types of
anaphoric expressions 
providing an implementation of the cluster ranking model  to stimulate further
research on ranking based approaches to coreference resolution  and to facilitate the use of
coreference information in high level nlp applications  we make our software that implements the cluster ranking model publicly available  
the rest of this article is organized as follows  section   provides an overview of the use
of ranking in coreference resolution  section   describes our baseline coreference models 
the mention pair model  the entity mention model  and the mention ranking model  we
discuss our cluster ranking approach and our joint model for anaphoricity determination
and coreference resolution in section    section   provides the details of how we lexicalize the
coreference models  we present evaluation results and experimental analyses of different
aspects of the coreference models in section   and section    respectively  finally  we
conclude in section   
   the software is available at http   www hlt utdallas edu   altaf cherrypicker  

   

firahman   ng

   ranking approaches to coreference resolution  a bit of history
while ranking is theoretically and empirically a better formulation of learning based coreference resolution than classification  the mention ranking model has not been as popularly
used and investigated as its mention pair counterpart since it was proposed  to promote
ranking based coreference models  and to set the stage for further discussion of learningbased coreference models in the next section  we provide in this section a brief history of
the use of ranking in heuristic based and learning based coreference resolution 
in a broader sense  many heuristic anaphora and coreference resolvers are rankingbased  for example  to find an antecedent for an anaphoric pronoun  hobbss        seminal syntax based resolution algorithm considers the sentences in a given text in reverse
order  starting from the sentence in which the pronoun resides and searching for potential
antecedents in the corresponding parse trees in a left to right  breadth first manner that
obeys binding and agreement constraints  hence  if we keep searching until the beginning
of the text is reached  i e   we do not stop even after the algorithm proposes an antecedent  
we will obtain a ranking of the candidate antecedents for the pronoun under consideration  where the rank of a candidate is determined by the order in which it is proposed by
the algorithm  in fact  the rank of an antecedent obtained via this method is commonly
known as its hobbss distance  which has been used as a linguistic feature in statistical
pronoun resolvers  e g   ge  hale    charniak        charniak   elsner         in general 
search based resolution algorithms like hobbss consider candidate antecedents in a particular order and  typically  propose the first candidate that satisfies all linguistic constraints
as the antecedent 
strictly speaking  however  we may want to consider a heuristic resolution algorithm as
a ranking based algorithm only if it considers all candidate antecedents simultaneously  for
example by assigning a rank or score to each candidate and selecting the highest ranked
or highest scored candidate to be the antecedent  even under this stricter definition of
ranking  there are still many heuristic resolvers that are ranking based  these resolvers
typically assign a rank or score to each candidate antecedent based on a number of factors 
or knowledge sources  and then propose the one that has the highest rank or score as an
antecedent  e g   carbonell   brown        cardie   wagstaff         a factor belongs to
one of two types  constraints and preferences  mitkov         constraints must be satisfied
before two mentions can be posited as coreferent  examples of constraints include gender
and number agreement  binding constraints  and semantic compatibility  preferences indicate the likelihood that a candidate is an antecedent  some preference factors measure the
compatibility between an anaphor and its candidate  e g   syntactic parallelism favors candidates that have the same grammatical role as the anaphor   while other preference factors
are computed based on the candidate only  typically capturing the salience of a candidate 
each constraint and preference is manually assigned a weight indicating its importance 
for instance  gender disagreement is typically assigned a weight of   indicating that a
candidate and the anaphor must agree in gender  whereas preference factors typically have
a finite weight  the score of a candidate can then be obtained by summing the weights of
the factors associated with the candidate 
some ranking based resolution algorithms do not assign a score to each candidate antecedent  rather  they simply impose a ranking on the candidates based on their salience 
   

fia cluster ranking approach to coreference resolution

perhaps the most representative family of algorithms that employ salience to rank candidates is centering algorithms  for descriptions of specific centering algorithms  see the
work of grosz  joshi    weinstein              walker et al         mitkov         where
the salience of a mention  typically estimated using its grammatical role  is used to rank
forward looking centers 
the work most related to ours is that of lappin and leass         whose goal is to perform pronoun resolution by assigning an anaphoric pronoun to the highest ranked preceding
cluster  and is therefore a heuristic cluster ranking model  like many other heuristic based
resolvers  lappin and leasss algorithm identifies the highest ranked preceding cluster for
an active mention by first applying a set of linguistic constraints to filter candidate antecedents that are grammatically incompatible with the active mention  and then ranking
the preceding clusters  which contain the mentions that survive the filtering process  using
salience factors  examples of salience factors include sentence recency  whether the preceding cluster contains a mention that appears in the sentence currently being processed  
subject emphasis  whether the cluster contains a mention in the subject position   existential emphasis  whether the cluster contains a mention that is a predicate nominal in an
existential construction   and accusative emphasis  whether the cluster contains a mention
that appears in a verbal complement in accusative case   each salience factor is associated
with a manually assigned weight that indicates its importance relative to other factors  and
the score of a cluster is the sum of the weights of the salience factors that are applicable to
the cluster  while lappin and leasss paper is a widely read paper on pronoun resolution 
the cluster ranking aspect of their algorithm has rarely been emphasized  in fact  we are
not aware of any recent work on learning based coreference resolution that establishes the
connection between the entity mention model and lappin and leasss algorithm 
despite the conceptual similarities  our cluster ranking model and lappin and leasss
       algorithm differ in several respects  first  lappin and leass only tackle pronoun resolution rather than the full coreference task  second  while they apply linguistic constraints
to filter incompatible candidate antecedents  our resolution strategy is learned without applying hand coded constraints in a separate filtering step  third  while they attempt to
compute the salience of a preceding cluster with respect to an active mention  we attempt
to determine the compatibility between a cluster and an active mention  using factors that
determine not only salience but also lexical and grammatical compatibility  for instance 
finally  their algorithm is heuristic based  where the weights associated with each salience
factor are encoded manually rather than learned  unlike our system 
the first paper on learning based coreference resolution was written by connolly  burger 
and day        and was published in the same year as lappin and leasss        paper 
contrary to common expectation  the coreference model this paper proposes is a rankingbased model  not the influential mention pair model  the main idea behind connolly et
al s approach is to convert a problem of ranking n candidate antecedents into a set of
pairwise ranking problems  each of which involves ranking exactly two candidates  to
rank two candidates  a classifier can be trained using a training set where each instance
corresponds to the active mention as well as two candidate antecedents and possesses a
class value that indicates which of the two candidates is better  this idea is certainly ahead
of its time  as it is embodied in many of the advanced ranking algorithms developed in
the machine learning and information retrieval communities in the past few years  it is
   

firahman   ng

later re invented at almost the same time  but independently  by yang et al         and
iida  inui  takamura  and matsumoto         who refer to it as the twin candidate model
and the tournament model  respectively  the name twin candidate model is motivated by
the fact that the model considers two candidates at a time  whereas the name tournament
model was assigned because each ranking of two candidates can be viewed as a tournament
 with the higher ranked candidate winning the tournament  and the candidate that wins
the largest number of tournaments is chosen as the antecedent for the active mention  this
bit of history is rarely mentioned in the literature  but it reveals three somewhat interesting
and perhaps surprising facts  first  ranking was first applied to train coreference models
much earlier than people typically think  second  despite being the first learning based
coreference model  connolly et al s ranking based model is theoretically more appealing
than the classification based mention pair model  and is later shown by yang et al  and
iida et al   to be empirically better as well  finally  despite its theoretical and empirical
superiority  connolly et al s model was largely ignored by the nlp community and received
attention only when it was re invented nearly a decade later  while during this time period
its mention pair counterpart essentially dominated learning based coreference research  
we conclude this section by making the important observation that the distinction between classification and ranking applies to discriminative models but not generative models 
generative models try to capture the true conditional probability of some event  in the context of coreference resolution  this will be the probability of a mention having a particular
antecedent or of it referring to a particular entity  i e   preceding cluster   since these probabilities have to normalize  this is similar to a ranking objective  the system is trying to raise
the probability that a mention refers to the correct antecedent or entity at the expense of
the probabilities that it refers to any other  thus  the antecedent version of the generative
coreference model as proposed by ge et al         resembles the mention ranking model 
while the entity version as proposed by haghighi and klein        is similar in spirit to the
cluster ranking model 

   baseline coreference models
in this section  we describe three coreference models that will serve as our baselines  the
mention pair model  the entity mention model  and the mention ranking model  for illustrative purposes  we will use the text segment shown in figure    each mention m in the
segment is annotated as  m cid
mid   where mid is the mention id and cid is the id of the cluster
to which m belongs  as we can see  the mentions are partitioned into four sets  with barack
obama  his  and he in one cluster  and each of the remaining mentions in its own cluster 

   it may not be possible  and perhaps not crucial  to determine why the mention pair model received a
lot more attention than connolly et al s model  but since those were the days when academic papers
could not be accessed easily in electronic form  we speculate that the publication venue played a role 
connolly et al s work was published in the new methods in language processing conference in     
 and later as a book chapter in        whereas the mention pair model was introduced in aone and
bennetts        paper and mccarthy and lehnerts        paper  which appeared in the proceedings
of two comparatively higher profile ai conferences  acl      and ijcai      

   

fia cluster ranking approach to coreference resolution

 barack obama    nominated  hillary rodham clinton    as   his    secretary of state    on  monday     
 he       

figure    an illustrative example
    mention pair model
as noted before  the mention pair model is a classifier that decides whether or not an
active mention mk is coreferent with a candidate antecedent mj   each instance i mj   mk  
represents mj and mk   in our implementation  an instance consists of the    features shown
in table    these features have largely been employed by state of the art learning based
coreference systems  e g   soon  ng    lim        ng   cardie      b  bengtson   roth 
       and are computed automatically  as can be seen  the features are divided into four
blocks  the first two blocks consist of features that describe the properties of mj and mk  
respectively  and the last two blocks of features describe the relationship between mj and
mk   the classification associated with a training instance is either positive or negative 
depending on whether mj and mk are coreferent 
if one training instance were created from each pair of mentions  the negative instances
would significantly outnumber the positives  yielding a skewed class distribution that will
typically have an adverse effect on model training  as a result  only a subset of mention
pairs will be generated for training  following soon et al          we create     a positive
instance for each anaphoric mention mk and its closest antecedent mj   and     a negative
instance for mk paired with each of the intervening mentions  mj     mj             mk    in
our running example shown in figure    three training instances will be generated for he 
i monday  he   i secretary of state  he   and i his  he   the first two of these instances will
be labeled as negative  and the last one will be labeled as positive  to train the mention pair
model  we use the svm learning algorithm from the svmlight package  joachims         
as mentioned in the introduction  while previous work on learning based coreference
resolution typically treats the underlying machine learner simply as a black box tool  we
choose to provide the reader with an overview of svms  the learner we are employing in our
work  note that this is a self contained overview  but it is by no means a comprehensive
introduction to maximum margin learning  our goal here is to provide the reader with only
the details that we believe are needed to understand the difference between classification
and ranking and perhaps appreciate the importance of ranking  
to begin with  assume that we are given a data set consisting of positively labeled
points  which have a class value of     and negatively labeled points  which have a class
   since svmlight assumes real valued features  it cannot operate on features with multiple discrete values
directly  hence  we need to convert the features shown in table   into an equivalent set of features
that can be used directly by svmlight   for uniformity  we perform the conversion for each feature in
table    rather than just the multi valued features  as follows  we create one binary valued feature for
svmlight from each feature value pair that can be derived from the feature set in table    for example 
pronoun   has two values  y and n  so we will derive two binary valued features  pronoun   y and
pronoun   n  one of them will have a value of   and the other will have a value of   for each instance 
   for an overview of the theory of maximum margin learning  we refer the reader to burgess       
tutorial 

   

firahman   ng

features describing mj   a candidate antecedent
  pronoun  
y if mj is a pronoun  else n
  subject  
y if mj is a subject  else n
  nested  
y if mj is a nested np  else n
features describing mk   the mention to be resolved
  number  
singular or plural  determined using a lexicon
male  female  neuter  or unknown  determined using a list of
  gender  
common first names
y if mk is a pronoun  else n
  pronoun  
  nested  
y if mk is a nested np  else n
  semclass  
the semantic class of mk   can be one of person  location  organization  date  time  money  percent  object  others  determined using wordnet  fellbaum        and the stanford ne recognizer  finkel  grenager    manning       
  animacy  
y if mk is determined as human or animal by wordnet and an ne
recognizer  else n
the nominative case of mk if it is a pronoun  else na  e g   the
   pro type  
feature value for him is he
features describing the relationship between mj   a candidate antecedent and mk  
the mention to be resolved
   head match
c if the mentions have the same head noun  else i
   str match
c if the mentions are the same string  else i
   substr match
c if one mention is a substring of the other  else i
c if both mentions are pronominal and are the same string  else i
   pro str match
   pn str match
c if both mentions are proper names and are the same string  else i
   nonpro str match c if the two mentions are both non pronominal and are the same
string  else i
   modifier match
c if the mentions have the same modifiers  na if one of both of them
dont have a modifier  else i
c if both mentions are pronominal and are either the same pronoun
   pro type match
or different only with respect to case  na if at least one of them is
not pronominal  else i
   number
c if the mentions agree in number  i if they disagree  na if the
number for one or both mentions cannot be determined
   gender
c if the mentions agree in gender  i if they disagree  na if the gender
for one or both mentions cannot be determined
   agreement
c if the mentions agree in both gender and number  i if they disagree
in both number and gender  else na
   animacy
c if the mentions match in animacy  i if they dont  na if the
animacy for one or both mentions cannot be determined
c if both mentions are pronouns  i if neither are pronouns  else na
   both pronouns
   both proper nounsc if both mentions are proper nouns  i if neither are proper nouns 
else na
   maximalnp
c if the two mentions does not have the same maximial np projection  else i
   span
c if neither mention spans the other  else i
   indefinite
c if mk is an indefinite np and is not in an appositive relationship 
else i
   appositive
c if the mentions are in an appositive relationship  else i
   copular
c if the mentions are in a copular construction  else i

   

fia cluster ranking approach to coreference resolution

features describing the relationship between mj   a candidate antecedent and mk  
the mention to be resolved  continued from the previous page 
   semclass
c if the mentions have the same semantic class  where the set of
semantic classes considered here is enumerated in the description of
the semclass   feature   i if they dont  na if the semantic class
information for one or both mentions cannot be determined
   alias
c if one mention is an abbreviation or an acronym of the other  else
i
   distance
binned values for sentence distance between the mentions
additional features describing the relationship between mj   a candidate antecedent
and mk   the mention to be resolved
   number
the concatenation of the number   feature values of mj and mk  
e g   if mj is clinton and mk is they  the feature value is singularplural  since mj is singular and mk is plural
   gender
the concatenation of the gender   feature values of mj and mk
   pronoun
the concatenation of the pronoun   feature values of mj and mk
   nested
the concatenation of the nested   feature values of mj and mk
   semclass
the concatenation of the semclass   feature values of mj and mk
   animacy
the concatenation of the animacy   feature values of mj and mk
the concatenation of the pro type   feature values of mj and mk
   pro type

table    feature set for coreference resolution  non relational features describe a mention
and in most cases take on a value of yes or no  relational features describe the relationship
between the two mentions and indicate whether they are compatible  incompatible or
not applicable 
value of    when used in classification mode  an svm learner aims to learn a hyperplane
 i e   a linear classifier  that separates the positive points from the negative points  if
there is more than one hyperplane that achieves zero training error  the learner will choose
the hyperplane that maximizes the margin of separation  i e   the distance between the
hyperplane and the training example closest to it   as a larger margin can be proven to
provide better generalization on unseen data  vapnik         more formally  a maximum
margin hyperplane is defined by w  x  b      where x is a feature vector representing
an arbitrary data point  and w  a weight vector  and b  a scalar  are parameters that are
learned by solving the following constrained optimization problem 
optimization problem    hard margin svm for classification
arg min
subject to

 
kwk 
 

yi  w  xi  b     

   i  n 

where yi          is the class of the i th training point xi   note that for each data point
xi   there is exactly one linear constraint in this optimization problem that ensures xi is
correctly classified  in particular  using a value of   on the right side of each inequality
   

firahman   ng

constraint ensures a certain distance  i e   margin  between each xi and the hyperplane  it
can be shown that the margin is inversely proportional to the length of the weight vector 
hence  minimizing the length of the weight vector is equivalent to maximizing the margin 
the resulting svm classifier is known as a hard margin svm  the margin is hard because
each data point has to be on the correct side of the hyperplane 
however  in cases where the data set is not linearly separable  there is no hyperplane
that can perfectly separate the positives from the negatives  and as a result  the above
constrained optimization problem does not have a solution  instead of asking the svm
learner to give up and return no solution  we solve a relaxed version of the problem where
we also consider hyperplanes that produce non zero training errors as potential solutions 
in other words  we have to modify the linear constraints associated with each data point
so that training errors are allowed  however  if we only modify the linear constraints but
leave the objective function as it is  then the learner will only search for a maximum margin
hyperplane regardless of the training error it produces  since training error correlates
positively with generalization error  it is crucial for the objective function to also take into
consideration the training error so that a hyperplane with a large margin and a low training
error can be found  however  it is non trivial to maximize the margin and minimize the
training error simultaneously  since training error typically increases as we maximize the
margin  as a result  we need to find a trade off between these two criteria  resulting in
an objective function that is a linear combination of margin size and training error  more
formally  we find the optimal hyperplane by solving the following constrained optimization
problem 
optimization problem    soft margin svm for classification
arg min

x
 
kwk    c
i
 
i

subject to
yi  w  xi  b      i      i  n 
as before  yi          is the class of the i th training point xi   c is a regularization
parameter that balances training error and margin size  finally  i is a non negative slack
variable that represents the degree of misclassification of xi   in particular  if i      then
data point i is on the wrong side of the hyperplane  because this svm allows data points
to appear on the wrong side of the hyperplane  it is also known as a soft margin svm 
given this optimization problem  we rely on the training algorithm employed by svmlight
for finding the optimal hyperplane 
after training  the resulting svm classifier is used by a clustering algorithm to identify
an antecedent for a mention in a test text  specifically  each active mention is compared in
turn to each preceding mention  for each pair  a test instance is created as during training
and presented to the svm classifier  which returns a value that indicates the likelihood that
the two mentions are coreferent  mention pairs with class values above   are considered
coreferent  otherwise the pair is considered not coreferent  following soon et al          we
apply a closest first linking regime for antecedent selection  given an active mention mk  
   

fia cluster ranking approach to coreference resolution

we select as its antecedent the closest preceding mention that is classified as coreferent with
mk   if mk is not classified as coreferent with any preceding mention  it will be considered
non anaphoric  i e   no antecedent will be selected for mk   
    entity mention model
unlike the mention pair model  the entity mention model is a classifier that decides whether
or not an active mention mk belongs to a partial coreference cluster cj that precedes mk  
each training instance  i cj   mk    represents cj and mk   the features for an instance can be
divided into two types      features that describe mk  i e  those shown in the second block
of table     and     cluster level features  which describe the relationship between cj and
mk   a cluster level feature can be created from a feature employed by the mention pair
model by applying a logical predicate  for example  given the number feature  i e   feature
    in table     which determines whether two mentions agree in number  we can apply
the all predicate to create a cluster level feature that has the value yes if mk agrees in
number with all of the mentions in cj and no otherwise  motivated by previous work  luo
et al         culotta  wick    mccallum        yang et al          we create cluster level
features from mention pair features using four commonly used logical predicates  none 
most false  most true  and all  specifically  for each feature x shown in the last two
blocks in table    we first convert x into an equivalent set of binary valued features if it
is multi valued  then  for each resulting binary valued feature xb   we create four binaryvalued cluster level features      none xb is true when xb is false between mk and each
mention in cj       most false xb is true when xb is true between mk and less than half
 but at least one  of the mentions in cj       most true xb is true when xb is true between
mk and at least half  but not all  of the mentions in cj   and     all xb is true when xb
is true between mk and each mention in cj   hence  for each xb   exactly one of these four
cluster level features evaluates to true  
following yang et al          we create     a positive instance for each anaphoric mention
mk and the preceding cluster cj to which it belongs  and     a negative instance for mk
paired with each preceding cluster whose last mention appears between mk and its closest
antecedent  i e   the last mention of cj    consider again our running example  three
training instances will be generated for he  i  monday   he   i  secretary of state   he  
and i  barack obama  his   he   the first two of these instances will be labeled as negative 
and the last one will be labeled as positive  as in the mention pair model  we train the
entity mention model using the svm learner 
since the entity mention model is a classifier  we will again use svmlight in classification
mode  resulting in a constrained optimization problem that is essentially the same as optimization problem    except that each training example xi represents an active mention
and one of its preceding clusters rather than two mentions 
   note that a cluster level feature can also be represented as a probabilistic feature  specifically  recall that
the four logical predicates partitions the       interval  which predicate evaluates to true for a given
cluster level feature depends on the probability obtained during the computation of the feature  instead
of applying the logical predicates to convert the probability into one of the four discrete values  we can
simply use the probability as the value of the cluster level feature  however  we choose not to employ
this probabilistic representation  as preliminary experiments indicated that using probabilistic features
yielded slightly worse results than using logical features 

   

firahman   ng

after training  the resulting classifier is used to identify a preceding cluster for a mention
in a test text  specifically  the mentions are processed in a left to right manner  for each
active mention mk   a test instance is created between mk and each of the preceding clusters
formed so far  all the test instances are then presented to the classifier  finally  we adopt
a closest first clustering regime  linking mk to the closest preceding cluster that is classified
as coreferent with mk   if mk is not classified as coreferent with any preceding cluster  it
will be considered non anaphoric  note that all partial clusters preceding mk are formed
incrementally based on the predictions of the classifier for the first k    mentions  no
gold standard coreference information is used in their formation 
    mention ranking model
as noted before  a ranking model imposes a ranking on all the candidate antecedents of an
active mention mk   to train the ranking model  we use the svm ranker learning algorithm
from joachimss        svmlight package 
like the mention pair model  each training instance i mj   mk   represents mk and a
preceding mention mj   in fact  the features that represent an instance and the method
for creating training instances are identical to those employed by the mention pair model 
the only difference lies in labeling the training instances  assuming that sk is the set of
training instances created for anaphoric mention mk   the rank value for i mj   mk   in sk
is the rank of mj among competing candidate antecedents  which is   if mj is the closest
antecedent of mk   and   otherwise   to exemplify  consider again our running example  as
in the mention pair model  three training instances will be generated for he  i monday 
he   i secretary of state  he   i his  he   the third instance will have a rank value of   
and the remaining two will have a rank value of   
at first glance  it seems that the training set that is generated for learning the mentionranking model  is identical to the one for learning the mention pair model  as each instance
represents two mentions and is labeled with one of two possible values  since previous work
on ranking based coreference resolution does not attempt to clarify the difference between
the two  we believe that it could be difficult for the reader to appreciate the idea of using
ranking for coreference resolution 
let us first describe the difference between classification and ranking at a high level 
beginning with the training sets employed by the mention ranking model and the mentionpair model  the difference is that the label associated with each instance for training the
mention ranking model is a rank value  whereas the label associated with each instance for
training the mention pair model is a class value  more specifically  since a ranking svm
learns to rank a set of candidate antecedents  it is the relative ranks between two candidates 
rather than the absolute rank of a candidate  that matter in the training process  in other
words  from the point of view of the ranking svm  a training set where instance    has
a rank value of   and instance    has a rank value of   is functionally equivalent to one
where    has a rank value of    and    has a rank value of    assuming that the remaining
instances generated for the same anaphor in the two training sets are identical to each other
and do not have a rank value between   and    
   a larger rank value implies a better rank in svmlight  

   

fia cluster ranking approach to coreference resolution

next  we take a closer look at the ranker training process  we denote the training set
that is created as described above by t   in addition  we assume that an instance in t
is denoted by  xjk   yjk    where xjk is the feature vector created from anaphoric mention
mk and candidate antecedent mj   and yjk is its rank value  before training a ranker  the
svm ranker learning algorithm derives a training set t  from the original training set t as
follows  specifically  for every pair of training instances  xik   yik   and  xjk   yjk   in t where
yik    yjk   we create a new training instance  xijk   yijk   for t    where xijk   xik  xjk   and
yijk          is   if xik has a larger rank value than xjk  and   otherwise   in a way 
the creation of t  resembles connolly et al s        pairwise ranking approach that we saw
in section    where we convert a ranking problem into a pairwise classification problem  
the goal of the ranker learning algorithm  then  is to find a hyperplane that minimizes the
number of misclassifications in t    note that since yijk           the class value of an
instance in t  depends only on the relative ranks of two candidate antecedents  not their
absolute rank values 
given the conversion from a ranking problem to a pairwise classification problem  the
constrained optimization problem that the svm ranker learning algorithm attempts to
solve  as described below  is similar to optimization problem   
optimization problem    soft margin svm for ranking
x
 
ijk
arg min kwk    c
 
subject to
yijk  w   xik  xjk    b      ijk  
where ijk is a non negative slack variable that represents the degree of misclassification of
xijk   and c is a regularization parameter that balances training error and margin size 
two points deserve mention  first  this optimization problem is equivalent to the one
for a classification svm on pairwise difference feature vectors xik  xjk   as a result  the
training algorithm that was used to solve optimization problem   is also applicable
to this optimization problem  second  while the number of linear inequality constraints
generated from document d in the optimization problems for training the mention pair
model and the entity mention model is quadratic in the number of mentions in d  the
number of constraints generated for a ranking svm is cubic in the number of mentions 
since each instance now represents three  rather than two  mentions 
after training  the mention ranking model is applied to rank the candidate antecedents
for an active mention in a test text as follows  given an active mention mk   we follow denis
and baldridge        and use an independently trained classifier to determine whether mk
is non anaphoric  if so  mk will not be resolved  otherwise  we create test instances for mk
by pairing it with each of its preceding mentions  the test instances are then presented to
the ranker  which computes a rank value for each instance by taking the dot product of the
   the main difference between t  and the training set employed by connolly et al s approach is that in
t    each instance is formed by taking the difference of the feature vectors of two instances in t   whereas
in connolly et al s training set  each instance is formed by concatenating the feature vectors of two
instances in t  

   

firahman   ng

instance vector and the weight vector  the preceding mention that is assigned the largest
value by the ranker is selected as the antecedent of mk   ties are broken by preferring the
antecedent that is closest in distance to mk  
the anaphoricity classifier used in the resolution step is trained using a publicly available
implementation   of maximum entropy  maxent  modeling  each instance corresponds
to a mention and is represented by    features that are deemed useful for distinguishing
between anaphoric and non anaphoric mentions  see table   for details   linguistically 
these features can be broadly divided into three types  string matching  grammatical  and
semantic  each of them is either a relational feature  which compares a mention to one of its
preceding mentions  or a non relational feature  which encodes certain linguistic property of
the mention whose anaphoricity is to be determined  e g   np type  number  definiteness  

   coreference as cluster ranking
in this section  we describe our cluster ranking approach to np coreference  as noted
before  our approach aims to combine the strengths of the entity mention model and the
mention ranking model 
    training and applying a cluster ranker
for ease of exposition  we will describe in this subsection how to train and apply the clusterranking model when it is used in a pipeline architecture  where anaphoricity determination
is performed prior to coreference resolution  in the next subsection  we will show how the
two tasks can be learned jointly 
recall that the cluster ranking model ranks a set of preceding clusters for an active
mention mk   since the cluster ranking model is a hybrid of the mention ranking model
and the entity mention model  the way it is trained and applied is also a hybrid of the
two  in particular  the instance representation employed by the cluster ranking model is
identical to that used by the entity mention model  where each training instance i cj   mk  
represents a preceding cluster cj and an anaphoric mention mk and consists of clusterlevel features formed from predicates  unlike in the entity mention model  however  in the
cluster ranking model      a training instance is created between each anaphoric mention mk
and each of its preceding clusters  and     since we are training a model for ranking clusters 
the assignment of rank values to training instances is similar to that of the mention ranking
model  specifically  the rank value of a training instance i cj   mk   created for mk is the
rank of cj among the competing clusters  which is   if mk belongs to cj   and   otherwise 
to train the cluster ranking model  we use the svm learner in ranking mode  resulting in
a constrained optimization problem that is essentially the same as optimization problem
   except that each training example xijk represents an active mention mk and two of its
preceding clusters  ci and cj   rather than two of its preceding mentions 
applying the learned cluster ranker to a test text is similar to applying the mentionranking model  specifically  the mentions are processed in a left to right manner  for each
active mention mk   we first apply an independently trained classifier to determine if mk is
non anaphoric  if so  mk will not be resolved  otherwise  we create test instances for mk by
    see http   homepages inf ed ac uk s        maxent toolkit html 

   

fia cluster ranking approach to coreference resolution

feature type
lexical

feature
str match

head match

grammatical
 np type 

uppercase
definite
demonstrative
indefinite
quantified
article

grammatical
 np
property 
relationship

pronoun
proper noun
bare singular
bare plural
embedded
appositive
prednom
number

contains pn
grammatical
 syntactic
pattern 

the n
the  n
the pn
the pn n
the adj n
the num n
the ne
the sing n

semantic

alias

description
y if there exists a mention mj preceding mk such that  after
discarding determiners  mj and mk are the same string  else
n 
y if there exists a mention mj preceding mk such that mj and
mk have the same head  else n 
y if mk is entirely in uppercase  else n 
y if mk starts with the  else n 
y if mk starts with a demonstrative such as this  that 
these  or those  else n 
y if mk starts with a or an  else n 
y if mk starts with quantifiers such as every  some  all 
most  many  much  few  or none  else n 
definite if mk is a definite np  quantified if mk is a quantified np  else indefinite 
y if mk is a pronoun  else n 
y if mk is a proper noun  else n 
y if mk is singular and does not start with an article  else n 
y if mk is plural and does not start with an article  else n 
y if mk is a prenominal modifier  else n 
y if mk is the first of the two mentions in an appositive
construction  else n 
y if mk is the first of the two mentions in a predicate nominal
construction  else n 
singular if mk is singular in number  plural if mk is plural
in number  unknown if the number information cannot be
determined 
y if mk is not a proper noun but contains a proper noun  else
n 
y if mk starts with the followed exactly by one common
noun  else n 
y if mk starts with the followed exactly by two common
nouns  else n 
y if mk starts with the followed exactly by a proper noun 
else n 
y if mk starts with the followed exactly by a proper noun
and a common noun  else n 
y if mk starts with the followed exactly by an adjective and
a common noun  else n 
y if mk starts with the followed exactly by a cardinal and a
common noun  else n 
y if mk starts with the followed exactly by a named entity 
else n 
y if mk starts with the followed by a singular np not containing any proper noun  else n 
y if there exists a mention mj preceding mk such that mj and
mk are aliases  else n 

table    feature set for anaphoricity determination  each instance represents a single mention 
mk   characterized by    features 
   

firahman   ng

pairing it with each of its preceding clusters  the test instances are then presented to the
ranker  and mk is linked to the cluster that is assigned the highest value by the ranker  ties
are broken by preferring the cluster whose last mention is closest in distance to mk   note
that these partial clusters preceding mk are formed incrementally based on the predictions
of the ranker for the first k    mentions 
    joint anaphoricity determination and coreference resolution
the cluster ranker described above can be used to determine which preceding cluster an
anaphoric mention should be linked to  but it cannot be used to determine whether a mention is anaphoric or not  the reason is simple  all the training instances are generated from
anaphoric mentions  hence  to jointly learn anaphoricity determination and coreference
resolution  we must train the ranker using instances generated from both anaphoric and
non anaphoric mentions 
specifically  when training the ranker  we provide each active mention with the option to
start a new cluster by creating an additional instance that     contains features that solely
describe the active mention  i e   the features shown in the second block of table     and    
has the highest rank value among competing clusters  i e      if it is non anaphoric and the
lowest rank value  i e      otherwise  the main advantage of jointly learning the two tasks
is that it allows the ranking model to evaluate all possible options for an active mention
 i e   whether to resolve it  and if so  which preceding cluster is the best  simultaneously 
essentially the same method can be applied to jointly learn the two tasks for the mentionranking model 
after training  the resulting cluster ranker processes the mentions in a test text in a
left to right manner  for each active mention mk   we create test instances for it by pairing
it with each of its preceding clusters  to allow for the possibility that mk is non anaphoric 
we create an additional test instance that contains features that solely describe the active
mention  similar to what we did in the training step above   all these test instances are then
presented to the ranker  if the additional test instance is assigned the highest rank value
by the ranker  then mk is classified as non anaphoric and will not be resolved  otherwise 
mk is linked to the cluster that has the highest rank  with ties broken by preferring the
antecedent that is closest to mk   as before  all partial clusters preceding mk are formed
incrementally based on the predictions of the ranker for the first k    mentions 
finally  we note that our model for jointly learning anaphoricity determination and coreference resolution is different from recent attempts to perform joint inference for anaphoricity
determination and coreference resolution using integer linear programming  ilp   where an
anaphoricity classifier and a coreference classifier are trained independently of each other 
and then ilp is applied as a postprocessing step to jointly infer anaphoricity and coreference decisions so that they are consistent with each other  e g   denis   baldridge      a  
joint inference is different from our joint learning approach  which allows the two tasks to
be learned jointly and not independently 

   lexicalization for coreference resolution
next  we investigate the role of lexicalization  i e   the use of word pairs as linguistic features 
in learning based coreference resolution  the motivation behind our investigation is two   

fia cluster ranking approach to coreference resolution

fold  first  lexical features are very easy to compute and yet they are under investigated
in coreference resolution  in particular  only a few attempts have been made to employ
them to train the mention pair model  e g   luo et al         daume iii   marcu       
bengtson   roth         in contrast  we want to determine whether they can improve
the performance of our cluster ranking model  second  the mention pair model and the
mention ranking model have only been compared with respect to a non lexical feature set
 denis   baldridge      b         so it is not clear how they will perform relative to each
other when they are trained on lexical features  we desire an answer to this question 
as it will allow us to gain additional insights into the strengths and weaknesses of these
learning based coreference models 
recall from the introduction that previous attempts on lexicalizing the mention pair
model show that lexical features are at best marginally useful  hence  one of our goals
here is to determine whether we can make better use of lexical features for a learning based
coreference resolver  in particular  unlike the aforementioned attempts on lexicalization 
which simply append all word pairs to a conventional coreference feature set consisting of
string matching  grammatical  semantic  and distance  i e   proximity based  features  e g  
the feature set shown in table     we investigate a model that exploits lexical features
in combination with only a small subset of these conventional coreference features  this
would allow us to have a better understanding of the significance of these conventional
features  for example  features that encode agreement on gender  number  and semantic
class between two mentions are employed by virtually all learning based coreference resolver 
but we never question whether there are better alternatives to these features  if we could
build a lexicalized coreference model without these commonly used features and did not
observe any performance deterioration  it would imply that these conventional features were
replaceable  and that there was no prototypical way of building a learning based coreference
system 
the question is  what is the small subset of conventional features that we should use in
combination with the lexical features  as mentioned above  since one of the advantages of
lexical features is that they are extremely easy to compute  we desire only those conventional
features that are also easy to compute  especially those that do not require a dictionary to
compute  as we will see  we choose to use only two features  the alias feature and the
distance feature  see features    and    in table     and rely on an off the shelf named
entity  ne  recognizer to compute ne types 
note  however  that the usefulness of lexical features could be limited in part by data
sparseness  many word pairs that appear in the training data may not appear in the test
data  while employing some of the conventional features described above  e g   distance 
will help alleviate this problem  we seek to further improve generalizability by introducing
two types of features  semi lexical and unseen features  we will henceforth refer to the
feature set that comprises these two types of features  the lexical features  the alias feature 
and the distance feature as the lexical feature set  in addition  we will refer to the feature
set shown in table   as the conventional feature set 
below we first describe the lexical feature set for training the mention pair model and
the mention ranking model  section       after that  we show how to create cluster level
features from this feature set for training the entity mention model and the cluster ranking
   

firahman   ng

model  as well as issues in training a joint model for anaphoricity determination and coreference resolution  section      
    lexical feature set
unlike previous work on lexicalizing learning based coreference models  our lexical feature
set consists of four types of features  lexical features  semi lexical features  unseen features 
as well as two conventional features  namely  alias and distance  
to compute these features  we preprocess a training text by randomly replacing    
of its nominal mentions  i e   common nouns  with the label unseen  if a mention mk is
replaced with unseen  all mentions that have the same string as mk will also be replaced
with unseen  a test text is preprocessed differently  we simply replace all mentions whose
strings are not seen in the training data with unseen  hence  artificially creating unseen
labels from a training text will allow a learner to learn how to handle unseen words in a
test text  potentially improving generalizability 
after preprocessing  we can compute the features for an instance  assuming that we are
training the mention pair model or the mention ranking model  each instance corresponds
to two mentions  mj and mk   where mj precedes mk in the text  the features can be
divided into four groups  unseen  lexical  semi lexical  and conventional  before describing
these features  two points deserve mention  first  if at least one of mj and mk is unseen 
no lexical  semi lexical  or conventional features will be created for them  since features
involving an unseen mention are likely to be misleading for a learner in the sense that they
may yield incorrect generalizations from the training set  second  since we use an svm for
training and testing  each instance can contain any number of features  and unless otherwise
stated  a feature has the value   
unseen feature  if both mj and mk are unseen  we determine whether they are the
same string  if so  we create an unseen same feature  otherwise  we create an unseendiff feature  if only one of them is unseen  no feature will be created 
lexical feature  we create a lexical feature between mj and mk   which is an ordered
pair consisting of the heads of the mentions  for a pronoun or a common noun  the head
is assumed to be the last word of the mention     for a proper noun  the head is taken to be
the entire noun phrase 
semi lexical features  these features aim to improve generalizability  specifically  if
exactly one of mj and mk is tagged as an ne by the stanford ne recognizer  finkel et al  
       we create a semi lexical feature that is identical to the lexical feature described above 
except that the ne is replaced with its ne label  i e   person  location  organization  
if both mentions are nes  we check whether they are the same string  if so  we create the
feature  ne  same  where  ne  is replaced with the corresponding ne label  otherwise 
we check whether they have the same ne tag and a word subset match  i e   whether all
    as we will see in the evaluation section  our mention extractor is trained to extract base nps  hence 
while our heuristic for extracting head nouns is arguably overly simplistic  it will not be applied to
recursive nps  e g   nps that contain prepositional phrases   which are phrases on which it is likely to
make mistakes  however  if we desire a better extraction accuracy  we can extract the head nouns from
syntactic parsers that provide head information  such as collinss        parser 

   

fia cluster ranking approach to coreference resolution

word tokens in one mention appear in the others list of tokens   if so  we create the feature
 ne  subsame  where  ne  is replaced with their ne label  otherwise  we create a feature
that is the concatenation of the ne labels of the two mentions 
conventional features  to further improve generalizability  we incorporate two easy to
compute features from the conventional feature set  alias and distance 
    feature generation
now that we have a lexical feature set for training the mention pair model and the mentionranking model  we can describe the two extensions to this feature set that are needed to
    train the entity mention model and the cluster ranking model  and     perform joint
learning for anaphoricity determination and coreference resolution 
the first extension concerns the generation of cluster level features for the entity mention
model and the cluster level model  recall from section     that to create cluster level features given the conventional feature set  we first convert each feature employed by the
mention pair model into an equivalent set of binary valued features  and then create a
cluster level feature from each of the resulting binary valued features  on the other hand 
given the lexical feature set  this method of producing cluster level features is only applicable to the two conventional features  i e   alias and distance   as they also appear
in the conventional feature set  for an unseen  lexical  or semi lexical feature  we create a
feature between the active mention and each mention in the preceding cluster  as described
in section         and the value of this feature is the number of times it appears in the instance  encoding feature values as frequency rather than binary values allows us to capture
cluster level information in a shallow manner 
the second extension concerns the generation of features for representing the additional
instance that is created when training the joint version of the mention ranking model and
the cluster ranking model  recall from section     that when the conventional feature set
was used  we represented this additional instance using features that were computed solely
from the active mention  on the other hand  given the lexical feature set  we can no longer
use the same method for representing this additional instance  as there is no feature in
the lexical feature set that is computed solely from the active mention  as a result  we
represent this additional instance using just one feature  null x  where x is the head of the
active mention  to help the learner learn that x is likely to be non anaphoric 

   evaluation
our evaluation is driven by the following questions  focusing on     the comparison among
different learning based coreference models  and     the effect of lexicalization on these
models  specifically 
 how do the learning based coreference models  namely  the mention pair model  the
entity mention model  the mention ranking model  and our cluster ranking model 
compare with each other 
    strictly speaking  the resulting feature is not a cluster level feature  as it is computed between an active
mention and only one of the mentions in the preceding cluster 

   

firahman   ng

 does joint modeling for anaphoricity determination and coreference resolution offer
any benefits over the pipeline architecture  where anaphoricity is performed prior to
coreference resolution 
 do lexicalized coreference models perform better than their unlexicalized counterparts 
in the rest of this section  we will first describe the experimental setup  section      
and then show the performance of the four models  including the effect of lexicalization and
joint modeling whenever applicable  on three different feature sets  section      
    experimental setup
we begin by providing the details on the data sets  our automatic mention extraction
method  and the scoring programs 
      corpus
we use the ace      coreference corpus as released by the ldc  which consists of the    
training documents used in the official ace evaluation    to ensure diversity  the corpus was
created by selecting documents from six different sources  broadcast news  bn   broadcast
conversations  bc   newswire  nw   webblog  wb   usenet  un   and conversational
telephone speech  cts   the number of documents belonging to each source is shown in
table   
data set
  of documents

bn
   

bc
  

nw
   

wl
   

un
  

cts
  

table    statistics for the ace      corpus

      mention extraction
we evaluate each coreference model using system mentions  to extract system mentions
from a test text  we trained a mention extractor on the training texts  following florian
et al          we recast mention extraction as a sequence labeling task  where we assign
to each token in a test text a label that indicates whether it begins a mention  is inside
a mention  or is outside a mention  hence  to learn the extractor  we create one training
instance for each token in a training text and derive its class value  one of b  i  and o 
from the annotated data  each instance represents wi   the token under consideration  and
consists of    linguistic features  many of which are modeled after the systems of bikel 
schwartz  and weischedel        and florian et al          as described below 
lexical     

tokens in a window of     wi            wi     

capitalization      determine whether wi isallcap  isinitcap  iscapperiod  and
isalllower 
    since we did not participate in ace       we do not have access to the official test set 

   

fia cluster ranking approach to coreference resolution

morphological      wi s prefixes and suffixes of length one  two  three  and four 
grammatical      the part of speech  pos  tag of wi obtained using the stanford loglinear pos tagger  toutanova  klein  manning    singer        
semantic      the named entity  ne  tag of wi obtained using the stanford crf based
ne recognizer  finkel et al         
dictionaries      we employ eight dictionary based features that indicate the presence
or absence of wi in a particular dictionary  the eight dictionaries contain pronouns    
entries   common words and words that are not names       k   person names      k  
person titles and honorifics        vehicle words        location names     k   company
names      k   and nouns extracted from wordnet that are hyponyms of person     k  
we employ crf       a c   implementation of conditional random fields  for training
the mention detector on the training set  overall  the detector achieves an f measure of
           recall       precision  on the test set  these extracted mentions are to be used
as system mentions in our coreference experiments 
      scoring programs
to score the output of a coreference model  we employ two scoring programs  b   bagga
  baldwin        and    ceaf    luo         which address the inherent weaknesses of
the muc scoring program  vilain  burger  aberdeen  connolly    hirschman          
both b  and ceaf score a response  i e   system generated  partition  r  against a key
 i e   gold standard  partition  k  and report coreference performance in terms of recall 
precision  and f measure  b  first computes recall and precision for each mention  mk   as
follows 
recall mk    

 rmk  kmk  
 rmk  kmk  
  precision mk    
 
 kmk  
 rmk  

where rmk is the coreference cluster containing mk in r  and kmk is the coreference cluster
containing mk in k  then it computes overall recall  resp  precision  by averaging the
per mention recall  resp  precision  scores 
on the the hand  ceaf first constructs the optimal one to one mapping between the
clusters in the key partition and those in the response partition  specifically  assume that
k    k    k            km   is the set of clusters in the key partition  and r    r    r            rn  
is the set of clusters in the response partition  to compute recall  ceaf first computes the
score of each cluster  ki   in k as follows 
score ki      ki  rj   
    available from http   crfpp sourceforge net
    ceaf has two versions     ceaf and    ceaf  the two versions differ in how the similarity of two
aligned clusters is computed  we refer the reader to luos        paper for details     ceaf is chosen
here because it is the more commonly used version of ceaf 
    briefly  the muc scoring program suffers from two often cited weaknesses  first  as a link based measure 
it does not reward successful identification of singleton clusters  since the mentions in these clusters are
not linked to any other mentions  second  it tends to under penalize partitions with overly large clusters 
see the work of bagga and baldwin         luo         and recasens and hovy        for details 

   

firahman   ng

where rj is the cluster to which ki is mapped in the optimal one to one mapping  which
can be constructed efficiently using the kuhn munkres algorithm  kuhn         note that
if ki is not mapped to any cluster in r  then score ki        ceaf then computes recall
by summing the score of each cluster in k and dividing the sum by the number of mentions
in k  precision can be computed in the same manner  except that we reverse the roles of
k and r 
a complication arises when b  is used to score a response partition containing system
mentions  recall that b  constructs a mapping between the mentions in the response and
those in the key  hence  if the response is generated using gold standard mentions  then
every mention in the response is mapped to some mention in the key and vice versa  in
other words  there are no twinless  i e   unmapped  mentions  stoyanov et al          this
is not the case when system mentions are used  but the original description of b  does
not specify how twinless mentions should be scored  bagga   baldwin         to address
this problem  we set the per mention recall and precision of a twinless mention to zero 
regardless of whether the mention appears in the key or the response  note that ceaf can
compare partitions with twinless mentions without any modification  since it operates by
aligning clusters  not mentions 
additionally  we apply a preprocessing step to a response partition before scoring it 
we remove all and only those twinless system mentions that are singletons  the reason is
simple  since the coreference resolver has successfully identified these mentions as singletons 
it should not be penalized  and removing them allows us to avoid such penalty  note that
we only remove twinless  as opposed to all  system mentions that are singletons  this allows
us to reward a resolver for successful identification of singleton mentions that have twins 
on the other hand  we retain     twinless system mentions that are non singletons  as the
resolver should be penalized for identifying spurious coreference relations  and     twinless
mentions in the key partition  as we want to ensure that the resolver makes the correct
coreference or non coreference decisions for them    
    results
before showing the results of the learning based coreference models  let us consider the head
match baseline  which is a commonly used heuristic baseline for coreference resolution  it
posits two mentions as coreferent if and only if their head nouns match  head nouns are
determined as described in section      the head of a proper noun is the string of the entire
mention  whereas the head of a pronoun or a common noun is the last word of the mention 
since one of our goals is to examine the effect of lexicalization on a coreference model  the
head match baseline can provide information on how well we can do with one of the simplest
kinds of string matching  results of this baseline  shown in row   of table    are expressed
in terms of recall  r   precision  p   and f measure  f  obtained via b  and ceaf  as we
can see from table    this baseline achieves f measure scores of      and      according to
b  and ceaf  respectively 
    in addition to the method described here  a number of methods have been proposed to address the
mapping problem  we refer the reader to the work of enrique  gonzalo  artiles  and verdejo        
stoyanov et al          and cai and strube        for details 

   

fia cluster ranking approach to coreference resolution

next  we train and evaluate the learning based coreference models using five fold cross
validation  for each data set si shown in table    we partition the documents in si into
five folds of approximately equal size  si            si    we then train each coreference model
on four folds and use it to generate coreference chains for the documents in the remaining
fold  repeating this step five times so that each fold is used as the test fold exactly once 
after that  we apply b  and ceaf to the entire set of automatically coreference annotated
documents to obtain the scores in table    below we discuss the results of the learningbased coreference models obtained when used in combination with three feature sets  the
conventional feature set  section         the lexical feature set  section         and the
combined feature set  which is composed of all the features from conventional and lexical
 section        
      results using the conventional features
to gauge the performance of our cluster ranking model  we employ as baselines the mentionpair model  the entity mention model  and the mention ranking model 
the mention pair baseline  we train our first learning based baseline  the mentionpair model  using the svm learning algorithm as implemented in the svmlight package   
as we can see from row   of table    the mention pair model achieves f measure scores of
      b    and       ceaf   which represent a statistically significant improvement of     
and      in f measure over the corresponding results for the head match baseline   
the entity mention baseline  next  we train our second learning based baseline  the
entity mention model  using the svm learner  as we can see from row   of table    this
baseline achieves f measure scores of       b    and       ceaf   which represent small but
statistically significant improvements over the mention pair model  the significant performance difference is perhaps not particularly surprising given the improved expressiveness
of the entity mention model over the mention pair model 
the mention ranking baseline  our third baseline is the mention ranking model  which
is trained using the ranker learning algorithm in svmlight   to identify non anaphoric mentions  we employ two methods  in the first method  we follow denis and baldridge       
and adopt a pipeline architecture  where we train a maxent classifier for anaphoricity determination independently of the mention ranker on the training set using the    features
described in section      we then apply the resulting classifier to each test text to filter nonanaphoric mentions prior to coreference resolution  results of this pipeline mention ranker
are shown in row   of table    as we can see  the ranker achieves f measure scores of     
 b    and       ceaf   yielding a significant performance deterioration in comparison to
the entity mention baseline 
in the second method  we perform anaphoricity determination jointly with coreference
resolution using the method described in section      while we discussed this joint learning
method in the context of cluster ranking  it should be easy to see that the method is
equally applicable to the mention ranking model  results of the mention ranker using this
    for this and subsequent uses of the svm learner  we set all parameters to their default values  in
particular  we employ a linear kernel to obtain all the results in this article 
    all statistical significance results in this article are obtained using the paired t test  with p        

   

firahman   ng

r
    

b 
p
    

ceaf
p
f
         

 

coreference model
head match

f
    

r
    

 
 
 
 
 
 

using the conventional feature set
mention pair model
              
entity mention model
              
mention ranking model  pipeline 
              
mention ranking model  joint 
              
cluster ranking model  pipeline 
              
cluster ranking model  joint 
              

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

 
 
  
  
  
  

using the lexical feature set
mention pair model
              
entity mention model
              
mention ranking model  pipeline 
              
mention ranking model  joint 
              
cluster ranking model  pipeline 
              
cluster ranking model  joint 
              

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

  
  
  
  
  
  

using the combined
mention pair model
    
entity mention model
    
mention ranking model  pipeline 
    
mention ranking model  joint 
    
cluster ranking model  pipeline 
    
cluster ranking model  joint 
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

feature
    
    
    
    
    
    

set
    
    
    
    
    
    

table    five fold cross validation coreference results obtained using b  and ceaf  the
best f measure achieved for each feature set scoring program combination is boldfaced 

joint architecture are shown in row   of table    as we can see  the ranker achieves fmeasure scores of       b    and       ceaf   which represent significant improvements
over the entity mention model and its pipeline counterpart  not only do these results
demonstrate the superiority of the joint mention ranking model to the entity mention model 
they substantiate the hypothesis that joint modeling offers benefits over pipeline modeling 
our cluster ranking model  finally  we evaluate our cluster ranking model  as in the
mention ranking baselines  we employ both the pipeline architecture and the joint architecture for anaphoricity determination  results are shown in rows   and   of table   
respectively  for the two architectures  as we can see  the pipeline architecture yields fmeasure scores of       b    and       ceaf   which represent a significant improvement
over the mention ranker adopting the pipeline architecture  with the joint architecture 
the cluster ranker achieves f measure scores of       b    and       ceaf   this also rep   

fia cluster ranking approach to coreference resolution

resents a significant improvement over the mention ranker adopting the joint architecture 
the best of the baselines  taken together  these results demonstrate the superiority of the
cluster ranker to the mention ranker  finally  the fact that the joint cluster ranker performs
significantly better than its pipeline counterpart provides further empirical support for the
benefits of joint modeling over pipeline modeling 
      results using the lexical features
next  we evaluate the learning based coreference models using the lexical features  results
are shown in rows     of table    in comparison to the results obtained using the conventional features  we see a different trend  the joint mention ranking model replaces the
cluster ranking model as the best performing model  moreover  its improvement over the
second best performing model  which is the entity mention model according to b  and the
pipeline mention ranking model according to ceaf  is statistically significant regardless of
which scoring program is used  a closer examination of the results reveals that employing
lexical rather than conventional features substantially improves the performance of the
mention ranking model  in comparison to the unlexicalized joint mention ranking model
 row     the f measure scores of the lexicalized joint mention ranking model  row     rise
by       b    and       ceaf   this increase in f measure can be attributed primarily
to a substantial rise in recall  even though there is also a large increase in ceaf precision 
besides the joint mention ranking model  the mention pair model and the entity mention
model also benefit substantially when the conventional features are replaced with the lexical features  we see that the f measure scores increase by       b    and       ceaf  for
the mention pair model  and by       b    and       ceaf  for the entity mention model 
the gains in f measure for these two models can be attributed to large increases in both
recall and precision  on the other hand  the joint cluster ranking model does not always
improve when we replace the conventional features with the lexical features  in fact  the
performance difference between the cluster ranking model and the entity mention model is
statistically indistinguishable  finally  we see the benefits of jointly learning anaphoricity
determination and coreference resolution again  when the joint version of the mentionranking model is used rather than the pipeline version  compare rows    and      the
f measure scores rise significantly by       b    and       ceaf   similarly for the clusterranking model  the joint version improves the pipeline version significantly by       b   
and       ceaf  in f measure 
overall  these results are somewhat unexpected  recall that the lexical features are
very knowledge lean  consisting of lexical  semi lexical  and unseen features  as well as only
two conventional features  in particular  it does not employ any conventional coreference
features that encode agreement on gender and number  this implies that many existing
implementations of the mention pair model  the entity mention model  and the mentionranking model  which are unlexicalized and rely heavily on the conventional features  are not
making effective use of the labeled data  perhaps more importantly  our results indicate that
these coreference models can perform well  and in fact better  even without the conventional
coreference features  since all of the lexical can be computed extremely easily  they can
readily be applied to other languages  which is another advantage of this feature set  on the
other hand  it is interesting to see that both versions of the cluster ranking model exhibit
   

firahman   ng

less dramatic changes in performance as we replace the conventional features with the
lexical features 
      results using the combined features
since the conventional features and the lexical features represent two fairly different sources
of knowledge  we examine whether we can improve the coreference models by combining
these two feature sets  results of the coreference models using the combined features are
shown in rows      of table    these results exhibit essentially the same trend as those that
we obtained with the conventional features  with the joint cluster ranking model performing
the best and the mention pair model performing the worst  in fact  the joint cluster ranking
model yields significantly better performance when used with the combined features than
with the conventional features or the lexical features alone  similarly for the pipeline
cluster ranking model  which achieves significantly better performance with the combined
features than with the conventional or lexical features  these results seem to suggest that
the cluster ranking model is able to exploit the potentially different sources of information
provided by the two feature sets to improve its performance  in addition  they demonstrate
the benefits of joint modeling  for the mention ranking model  the joint version improves
the pipeline version significantly by       b    and       ceaf  in f measure  and for the
cluster ranking model  the joint version improves its pipeline counterpart significantly by
      b    and       ceaf  in f measure 
the remaining coreference models all exhibit a drop in performance when the combined
features are used in lieu of the lexical features  these results seem to suggest that the
cluster ranking model offers more robust performance in the face of changes in the underlying feature set than the other coreference models  and that feature selection  an issue that is
under explored in coreference resolution  may be crucial when we employ the other coreference models    perhaps more importantly  despite the fact that the conventional features
and the lexical features represent two fairly different sources of information  all but the
cluster ranking model are unable to exploit the potentially richer amount of information
contained in the combined feature set  hence  while virtually all the linguistic features
that are recently developed for supervised coreference resolution have been evaluated using
the mention pair model  see  for example  the work of strube  rapp    muller        ji 
westbrook    grishman        ponzetto   strube         the utility of these features may
be better demonstrated using the cluster ranking model 
a natural question is  how does our joint cluster ranking model compare to the existing
coreference systems  since we did not participate in the ace evaluations  we do not have
access to the official test sets with which we can compare our model against the ace
participating coreference systems  the comparison is further complicated by the fact that
existing coreference systems have been evaluated on different data sets  including the two
muc data sets  muc          muc          and the various ace data sets  e g   ace   
ace       ace       ace        as well as on different partitions of a given data set 
to our knowledge  the only coreference model that has been evaluated on the same test
data as ours is haghighi and kleins        unsupervised coreference model  their model
    in fact  ng and cardie      b   strube and muller         and ponzetto and strube        show that
the mention pair model can be improved using feature selection 

   

fia cluster ranking approach to coreference resolution

has recently been shown to surpass the performance of stoyanov et al s        system 
which is one of the best existing implementations of the mention pair model  on our test
data  haghighi and kleins model achieves a b  f measure of       while ours achieves a
b  f measure of         these results provide suggestive evidence that our cluster ranking
model achieves performance that is comparable with one of the best existing coreference
models 
nevertheless  we caution that these results do not allow one to claim anything more
than the fact that our model compares favorably to haghighi and kleins        model  for
instance  one cannot claim that their model is better because it achieves the same level of
performance as ours without using any labeled data  the reasons are that     the mentions
used by the two models in the coreference process are extracted differently and     the
linguistic features employed by the two models and the way these features are computed
are also different from each other  since previous work has shown that these linguistic
preprocessing steps can have a considerable impact on the performance of a resolver  barbu
  mitkov        stoyanov et al          it is possible that if one model employed the features
or the mentions that the other model is currently using  then the results would be different 
hence  if one is to fairly compare two coreference models  they should be evaluated on the
same set of mentions  rather than just the same set of documents  and are given access to
the same set of knowledge sources  in essentially the same way as we compare the various
learning based coreference models in this article 

   experimental analyses
in an attempt to gain insights into the different aspects of our coreference models  we
conduct additional experiments and analyses  rather than report five fold cross validation
results  in this section we report results on one fold  i e   the fold we designate as the test
set  and use the remaining four folds solely for training 
    improving classification based coreference models
given the generally poorer performance of classification based coreference models  a natural question is  can they be improved  to answer this question  we investigate whether
these models can be improved by employing a different clustering algorithm and a different
learning algorithm  there are reasons for our decision to focus on these two dimensions 
first  as noted in the introduction  one of the weaknesses of these models is that it is
not clear which clustering algorithm offers the best performance  given this observation 
we will examine whether we can improve these models by replacing soon et al s       
closest first linking regime with the best first linking strategy  which has been shown
to offer better performance for the mention pair model on the muc data sets  ng   cardie 
    b   second  as discussed at the end of section    we may be able to achieve some of the
advantage of ranking in classification based models by employing a learning algorithm that
optimizes for conditional probabilities instead of     decisions  motivated by this observation  we will examine whether we can improve classification based models by training them
using maxent  which employs a likelihood based loss function  note that maxent is one
    note that haghighi and klein did not report any ceaf scores in their paper 

   

firahman   ng

of the most popular learning algorithms for training coreference models  see  for example 
morton        kehler  appelt  taylor    simma        ponzetto   strube        denis  
baldridge        finkel   manning        ng        
to evaluate these two modifications  we apply them in isolation and in combination to
the two classification based models  i e   the mention pair model and the entity mention
model  when they are trained using three different feature sets  i e   conventional  lexical  and combined   we train the maxent based coreference models using yasmet    
and follow ng and cardies      b  implementation of the best first clustering algorithm 
specifically  among the candidate antecedents or preceding clusters that are classified as
coreferent with active mention mk   best first clustering links mk to the most likely one 
for a maxent model  a pair is classified as coreferent if and only if its classification value
is above      and the most likely antecedent preceding cluster for mk is the one that has
the highest probability of coreference with mk   for an svmlight  trained model  a pair is
classified as coreferent if and only if its classification value is above    and the most likely
antecedent preceding cluster for mk is the one that has the most positive classification
value 
table   presents b  and ceaf results of the two classification based coreference models
when they are trained using two learning algorithms  i e   svm and maxent  and used
in combination with two clustering algorithms  i e   closest first clustering and best first
clustering   to study how the choice of the clustering algorithm impacts performance  we
should compare the results of closest first clustering and best first clustering in table  
for each combination of learning algorithm  feature set  coreference model  and scoring
program  for instance  comparing rows   and   of table   enables us to examine which of
the two clustering algorithms is better for the mention pair model when it is trained with
the conventional feature set and each of the two learners  overall  we see a fairly consistent
trend  best first clustering yields results that are slightly worse than those obtained using
closest first clustering  regardless of the choice of the clustering algorithm  the learning
algorithm  the feature set  and the scoring program  at first glance  these results seem
contradictory to those by ng and cardie      b   who demonstrate the superiority of bestfirst clustering to closest first clustering for coreference resolution  we speculate that the
contradictory results can be attributed to two reasons  first  in our best first clustering
experiments  we still employed soon et al s        training instance selection method 
where we created a positive training instance between an anaphoric mention and its closest
antecedent preceding cluster  unlike ng and cardie  who claim that for the proposed bestfirst clustering to be successful  however  a different method for training instance selection
would be needed  in particular  they propose to use the most confident antecedent 
rather than the closest antecedent  to generate positive instances from an anaphoric mention 
second  ng and cardie demonstrate the success of best first clustering on the muc data
sets  and it is possible that this success may not carry over to the ace data sets  additional
experiments are needed to determine the reason  however 
    see http   www fjoch com yasmet html  the reason why yasmet is chosen is that it provides the
capability to rank  which allows us to compare the results of maxent trained classification models and
ranking models  see the work of ravichandran  hovy  and och        for a discussion of the differences
between the training of these two types of maxent models 

   

fia cluster ranking approach to coreference resolution

coreference model

r

svm
p

f

r

maxent
p
f

 
 
 
 

b  results using the conventional feature
mention pair model  closest first 
              
mention pair model  best first 
              
entity mention model  closest first                
entity mention model  best first 
              

set
    
    
    
    

    
    
    
    

    
    
    
    

 
 
 
 

b  results using the lexical feature set
mention pair model  closest first 
              
mention pair model  best first 
              
entity mention model  closest first                
entity mention model  best first 
              

    
    
    
    

    
    
    
    

    
    
    
    

combined feature set
              
    
              
    
                   
              
    

    
    
    
    

    
    
    
    

  
  
  
  

ceaf results using the conventional feature set
mention pair model  closest first 
              
    
mention pair model  best first 
              
    
entity mention model  closest first                
    
entity mention model  best first 
              
    

    
    
    
    

    
    
    
    

  
  
  
  

ceaf results using
mention pair model  closest first 
mention pair model  best first 
entity mention model  closest first 
entity mention model  best first 

    
    
    
    

    
    
    
    

  
  
  
  

ceaf results using the combined
mention pair model  closest first 
         
mention pair model  best first 
         
entity mention model  closest first           
entity mention model  best first 
         

    
    
    
    

    
    
    
    

 
  
  
  

b  results using the
mention pair model  closest first 
mention pair model  best first 
entity mention model  closest first 
entity mention model  best first 

 a  b  results

the lexical feature set
              
    
              
    
                   
              
    
feature
    
    
    
    

set
    
    
    
    

 b  ceaf  results

table    svm vs  maxent results for classification based coreference models  these one fold
b  and ceaf scores are obtained by training coreference models using svm and maxent  the
best f measure achieved for each feature set scoring program combination is boldfaced 
   

firahman   ng

next  to examine whether minimizing likelihood based loss via maxent training instead
of svms classification loss would enable us to achieve some of the advantage of ranking
 and hence leads to better performance   we compare the two columns of table    as we can
see  when the conventional feature set is used  maxent outperforms svm  regardless of the
choice of the clustering algorithm  the scoring program  and the coreference model  on the
other hand  when the lexical features or the combined features are used  svm outperforms
maxent consistently  overall  these mixed results seem to suggest that whether maxent
offers better performance than svm is to some extent dependent on the underlying feature
set 
    performance of maximum entropy based ranking models
some prior work suggests that maxent based ranking may provide better gains than svmbased ranking  since it can generate reliable confidence values and can dynamically adjust
relative ranks according to baseline results  e g   ji  rudin    grishman         to determine whether this is the case for coreference resolution  we conduct experiments in which
we train the ranking based coreference models using the ranker learning algorithm in yasmet 
b  and ceaf results for the mention ranking model and the cluster ranking model when
they are trained using maxent in combination three different feature sets  i e   conventional 
lexical  and combined  are shown in the maxent column of table    for comparison 
we also show the corresponding results obtained via svm based ranking in the same table
 see the svm column   comparing these two columns  we see mixed results  of the   
experiments that involve ranking models  maxent based ranking outperforms svm based
ranking in six of them  in other words  our results suggest that for the coreference task 
svm based ranking is generally better than maxent based ranking 
    accuracy of anaphoricity determination
in section      we saw that a joint ranking model always performs significantly better than
its pipeline counterpart  in other words  joint modeling for coreference and anaphoricity
improves coreference resolution  a natural question is  does joint modeling also improve
anaphoricity determination 
to answer this question  we measure the accuracy of the anaphoricity information resulting from pipeline modeling and joint modeling  recall that for pipeline modeling  we rely
on the output of an anaphoricity classifier that is trained independently of the coreference
system that uses the anaphoricity information  see section       the accuracy of this classifier on the test set is shown under the acc column in row   of table    in addition  we
show in the table its recall  r   precision  p   and f measure  f  on identifying anaphoric
mentions  as we can see  the classifier achieves an accuracy of      and a f measure score
of      
on the other hand  for joint modeling  we can compute the accuracy of anaphoricity
determination from the output of a joint coreference model  specifically  given the output
of a joint model  we can determine which mentions are resolved to a preceding antecedent
and which are not  assuming that a mention that is resolved is anaphoric and one that is
not resolved is non anaphoric  we can compute the accuracy of anaphoricity determination
   

fia cluster ranking approach to coreference resolution

coreference model

r

svm
p

f

r

maxent
p
f

 
 
 
 

b  results using the conventional feature
mention ranking model  pipeline 
              
mention ranking model  joint 
              
cluster ranking model  pipeline 
              
cluster ranking model  joint 
              

set
    
    
    
    

    
    
    
    

    
    
    
    

 
 
 
 

b  results using the lexical feature set
mention ranking model  pipeline 
              
mention ranking model  joint 
              
cluster ranking model  pipeline 
              
cluster ranking model  joint 
              

    
    
    
    

    
    
    
    

    
    
    
    

combined feature set
              
    
              
    
              
    
                   

    
    
    
    

    
    
    
    

conventional feature set
              
    
              
    
              
    
                   

    
    
    
    

    
    
    
    

 
  
  
  

b  results using the
mention ranking model  pipeline 
mention ranking model  joint 
cluster ranking model  pipeline 
cluster ranking model  joint 

 a  b  results

  
  
  
  

ceaf results using the
mention ranking model  pipeline 
mention ranking model  joint 
cluster ranking model  pipeline 
cluster ranking model  joint 

  
  
  
  

ceaf results using
mention ranking model  pipeline 
mention ranking model  joint 
cluster ranking model  pipeline 
cluster ranking model  joint 

the lexical feature set
              
    
                   
              
    
              
    

    
    
    
    

    
    
    
    

  
  
  
  

ceaf results the
mention ranking model  pipeline 
mention ranking model  joint 
cluster ranking model  pipeline 
cluster ranking model  joint 

combined feature set
              
              
              
              

    
    
    
    

    
    
    
    

    
    
    
    

 b  ceaf results

table    svm vs  maxent results for ranking basd coreference models  these one fold b 
and ceaf scores are obtained by training coreference models using svm and maxent  the best
f measure achieved for each feature set scoring program combination is boldfaced 
   

firahman   ng

 
 
 
 
 
 
 

source of anaphoricity information
anaphoricity classifier
mention ranking  conventional 
cluster ranking  conventional 
mention ranking  lexical 
cluster ranking  lexical 
mention ranking  combined 
cluster ranking  combined 

acc
    
    
    
    
    
    
    

r
    
    
    
    
    
    
    

p
    
    
    
    
    
    
    

f
    
    
    
    
    
    
    

table    anaphoricity determination results 

as well as the precision  recall  and f measure on identifying anaphoric mentions  since all
these performance numbers are derived from the output of a joint model  we can compute
them for each of the two joint ranking models  i e   the mention ranking model and the
cluster ranking model  when used in combination with each of the three coreference feature
sets  i e   conventional  lexical  and combined   this results in six sets of performance
numbers  which are shown in rows    of table    as we can see  the accuracies range from
     to       and the f measure scores range from      to      
in comparison to the results of the anaphoricity classifier shown in row    we can see
that joint modeling improves the performance of anaphoricity determination except for two
cases  namely  mention ranking conventional and mention ranking combined  in other
words  in these two cases  joint modeling benefits coreference resolution but not anaphoricity determination  while it seems counter intuitive that one can achieve better coreference
performance with a lower accuracy on determining anaphoricity  it should not be difficult
to see the reason  the joint model is trained to maximize the pairwise ranking accuracy 
which presumably correlates with coreference performance  whereas the anaphoricity classifier is trained to maximize the accuracy of determining the anaphoricity of a mention 
which may not always have any correlation with coreference performance  in other words 
improvements in anaphoricity accuracy generally but not necessarily imply corresponding
improvements in clustering level coreference accuracy 
finally  it is important to bear in mind that the conclusions we have drawn regarding
pipeline and joint modeling are based on the results of an anaphoricity classifier trained
on    features  it is possible that different conclusions could be drawn if we trained the
anaphoricity classifier on a different set of features  therefore  an interesting future direction
would be to improve the anaphoricity classifier by employing additional features  such as
those proposed by uryupina         we may also be able to derive sophisticated features
by harnessing recent advances in lexical semantics research  specifically by using methods
for phrase clustering  e g   lin   wu         lexical chain discovery  e g   morris   hirst 
       and paraphrase discovery  see the survey papers by androutsopoulos   malakasiotis 
      madnani   dorr        
   

fia cluster ranking approach to coreference resolution

    joint inference versus joint learning for the mention pair model
as mentioned at the end of section      joint modeling for anaphoricity determination and
coreference resolution is fundamentally different from joint inference for these two tasks 
recall that in joint inference using ilp  an anaphoricity classifier and a coreference classifier
are trained independently of each other  and then ilp is applied as a postprocessing step
to jointly infer anaphoricity and coreference decisions so that they are consistent with each
other  e g   denis   baldridge      a   in this subsection  we investigate how joint learning
compares with joint inference for anaphoricity determination and coreference resolution 
let us begin with an overview of the ilp approach proposed by denis and baldridge
     a  for joint inference for anaphoricity determination and coreference resolution  the
ilp approach is motivated by the observation that the output of an anaphoricity model and
that of a coreference model for a given document have to satisfy certain constraints  for
instance  if the coreference model determines that a mention mk is not coreferent with any
other mentions in the associated text  then the anaphoricity model should determine that
mk is non anaphoric  in practice  however  since the two models are trained independently
of each other  this and other constraints cannot be enforced 
denis and baldridge      a  provide an ilp framework for jointly determining anaphoricity and coreference decisions for a given set of mentions based on the probabilities provided
by the anaphoricity model pa and the mention pair coreference model pc   such that the
resulting joint decisions satisfy the desired constraints while respecting as much as possible the probabilistic decisions made by the independently trained pa and pc   specifically  an ilp program is composed of an objective function to be optimized subject to
a set of linear constraints  and is created for each test text d as follows  let m be
the set of mentions in d  and p be the set of mention pairs formed from m  i e   p  
  mj   mk     mj   mk  m  j   k    each ilp program has a set of indicator variables  in
our case  we have one binary valued variable for each anaphoricity decision and coreference
decision to be made by an ilp solver  following denis and baldridges notation  we use
yk to denote the anaphoricity decision for mention mk   and xhj ki to denote the coreference
decision involving mentions mj and mk   in addition  each variable is associated with an
assignment cost  specifically  let cc
hj ki    log pc  mj   mk    be the cost of setting xhj ki to
c
   and chj ki    log    pc  mj   mk    be the complementary cost of setting xhj ki to    we
can similarly define the cost associated with each yk   letting ca
k    log pa  mk    be the
 

log  

p
 m
  
be
the
complementary
cost of setting
cost of setting yk to    and ca
a
k
k
yk to    given these costs  we aim to optimize the following objective function 
min

x

c
cc
hj ki  xhj ki   chj ki      xhj ki    

x

a
ca
k  yk   ck      yk  

mk m

 mj  mk  p

subject to a set of manually specified linear constraints  denis and baldridge specify four
types of constraints      each indicator variable can take on a value of   or        if mj and
mk are coreferent  xhj ki      then mk is anaphoric  yk          if mk is anaphoric  yk     
then it must be coreferent with some preceding mention mj   and     if mk is non anaphoric 
then it cannot be coreferent with any mention 
two points deserve mention  first  we are minimizing the objective function  since each
assignment cost is expressed as a negative logarithm value  second  since transitivity is
   

firahman   ng

not guaranteed by the above constraints     we use the closest link clustering algorithm to
put any two mentions that are posited as coreferent into the same cluster  note that the
best link clustering strategy is not applicable here  since a binary decision is assigned to
each pair of mentions by the ilp solver  we use lp solve     a publicly available ilp solver 
to solve this program 
b  and ceaf results of performing joint inference on the outputs of the anaphoricity
model and the mention pair model using ilp are shown in the joint inference column of
tables  a and  b  respectively  where the rows correspond to results obtained by training
the coreference models on different feature sets  since one of our goals is to compare joint
inference and joint learning  we also show in the joint learning column the results of the
joint mention ranking model  where anaphoricity determination and coreference resolution
are learned in a joint fashion  note that the reason for using the mention ranking model
 rather than the cluster ranking model  as our joint model here is that we want to ensure a
fair comparison of joint learning and joint inference as much as possible  had we chosen the
cluster ranking model as our joint model  the difference between the joint learning results
and the joint inference results could have been caused by the increased expressiveness of
the cluster ranking model  finally  to better understand whether the mention pair model
benefits from joint inference using ilp  we show in the no inference column the relevant
mention pair model results from table    where the output of the model is not postprocessed
with any inference mechanism 
from table    we can see that the joint learning results are substantially better than the
joint inference results  except for one case  conventional ceaf   where the two achieve
comparable performance  previous work by roth        and roth and yih        has
suggested that it is often more effective to learn simple local models and use complicated
integration strategies to make sure constraints on the output are satisfied than to learn
models that satisfy the constraints directly  our results imply that this is not true for the
coreference task 
comparing the joint inference and no inference results in table    we can see that the
mention pair model does not benefit from the application of ilp  in fact  its performance
deteriorates when ilp is used  these results are inconsistent with those reported by denis
and baldridge      a   who show that joint inference using ilp can improve the mentionpair model  we speculate that the inconsistency accures from the fact that denis and
baldridge evaluate the ilp approach on true mentions  i e   gold standard mentions   while
we evaluate it on system mentions  additional experiments are needed to determine the
reason  however 
    data source adaptability
one may argue that since we train and test a model on documents from the same data
source  i e   the model trained on the documents from bc is tested on the documents from
    finkel and manning        show how to formulate linear constraints so that the ilp solver outputs
coreference decisions that satisfy transitivity  however  since the number of additional constraints needed
to guarantee transitivity grows cubically with the number of mentions and previous work shows that
having these additional constraints do not yield substantial performance improvements when applied to
system mentions  ng         we decided not to employ them in our experiments 
    available from http   lpsolve sourceforge net 

   

fia cluster ranking approach to coreference resolution

 
 
 

feature set
conventional
lexical
combined

joint learning
r
p
f
              
              
              

joint inference
r
p
f
              
              
              

no
r
    
    
    

inference
p
f
         
         
         

no
r
    
    
    

inference
p
f
         
         
         

 a  b  results

 
 
 

feature set
conventional
lexical
combined

joint learning
r
p
f
              
              
              

joint inference
r
p
f
              
              
              

 b  ceaf results

table    joint learning vs  joint inference results  the joint modeling results are obtained
using the mention ranking model  the joint inference results are obtained by applying ilp to the
anaphoricity classifier and the mention pair model  the no inference results are those produced
by the mention pair model  all coreference models are trained using maxent 

bc  for example   it should not be surprising that lexicalization helps  since word pairs in
a training set are more likely to be found in a test set if the training and test texts are
from the same data source  to examine whether models that employ the lexical features
will suffer if they are trained and tested on different data sources  we perform a set of data
source adaptability experiments  where we apply a coreference model that is trained with
the lexical features on documents from one data source to documents from all data sources 
here  we show the results obtained using the mention ranking model  primarily because it
yielded the best performance with the lexical features among the learning based coreference
models  for comparison  we also show the data source adaptability results obtained using
the mention ranking model that is trained with the  non lexical  conventional feature set 
the b  and ceaf f measure scores of these experiments are shown in tables  a and
 b  where the left half and the right half of the table contain the lexicalized mention ranking
model results and the unlexicalized mention ranking model results  respectively  each row
corresponds to a data source on which a model is trained  except for the last two rows 
which we will explain shortly  each column corresponds to a test set from a particular data
source 
to answer the question of whether the performance of a coreference model that employs
the lexical features will deteriorate if they are trained and tested on different data sources 
we can look at the diagonal entries in the left half of tables  a and  b  which contain
the results obtained when the lexicalized mention ranking model is trained and tested on
documents from the same source  if the model indeed performs worse when it is trained
and tested on documents from different sources  then a diagonal entry should contain the
highest score among the entries in the same column  as we can see from the left half of
the two tables  this is to a large extent correct  four of the six diagonal entries contain the
highest scores in their respective columns according to both scoring programs  this provides
   

firahman   ng

lexical features
pp
pp test
train ppp
p
bc
bn
cts
nw
un
wl
maxmin
std  dev 

conventional features

bc

bn

cts nw un

wl

bc

bn

cts nw un

wl

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

 a  b  results

lexical features
pp
pp test
train ppp
p
bc
bn
cts
nw
un
wl
maxmin
std  dev 

conventional features

bc

bn

cts nw un

wl

bc

bn

cts nw un

wl

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
    
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

    
    
    
    
    
    
   
    

 b  ceaf results

table    results for data source adaptability  each row shows the results obtained by training
the mention ranking model on the data set shown on the first column of the row  and each column
corresponds to the test set from a particular data source  the best result obtained on each test set
for each of the two coreference models is boldfaced 

suggestive evidence that the answer to our question is affirmative  nevertheless  if we look
at right half of the two tables  where we show the results obtained using the unlexicalized
mention ranking model  we see a similar  but perhaps weaker  trend  according to ceaf 
four of the six diagonal entries contain the highest scores in their respective columns  and
according to b    two of the six diagonal entries exhibit this trend  hence  the fact that
a model performs worse when it is trained and tested on different data sources cannot be
attributed solely to lexicalization 
perhaps a more informative question is  do lexicalized models trained on different data
sources exhibit more varied performance on a given test set  composed of documents from
the same source  than unlexicalized models trained on different data sources  an affirmative
answer to this question will provide empirical support for the hypothesis that a lexicalized
model fits the data on which it is trained more than its unlexicalized counterpart  to answer
this question  we compute for each column and each of the two models     the difference
between the highest and lowest scores  see the maxmin row   and     the standard
deviation of the six scores in the corresponding column  see the std  dev  row   if we
   

fia cluster ranking approach to coreference resolution

compare the corresponding columns of the two coreference models  we can see that except
for bn  the lexicalized model does exhibit more varied performance on a given test set than
the unlexicalized model according to both scoring programs  regardless of whether we are
measuring the variation using maxmin or standard deviation 
    feature analysis
in this subsection  we analyze the effects of the linguistic features on the performance of
the coreference models  given the large number of models trained on each of the three
feature sets  it is not feasible for us to analyze the features for each model and each feature
set  since the cluster ranking model  when used with the combined feature set  yields the
best performance  we will analyze its features  in addition  since the lexical features have
yielded good performance for the mention ranking model  it would be informative to see
which lexical features have the greatest contribution to its performance  as a result  we
will perform feature analysis on these two model feature set combinations 
although we have identified two particular model feature set combinations  we actually
have a total of    model feature set combinations  recall that except for row    each row in
table   shows the aggregated result for the six data sets  where we trained one model for
each data set  in other words  for each of the two combinations we selected above  we have
six learned models  to reduce the number of models we need to analyze and yet maximize
the insights we can gain  we choose to analyze the models that were trained on data sets
from two fairly different domains  newswire  nw  and broadcast news  bn  
the next question is  how can we analyze the features  we apply the backward elimination feature selection algorithm  see the survey paper by blum   langley         which
starts with the full feature set and removes in each iteration the feature whose removal
yields the best system performance  despite its greedy nature  this algorithm runs in time
quadratic to the number of features  making it computationally expensive to run on our
feature sets  to reduce computational cost  we divide our features into feature types and
apply backward elimination to eliminate one feature type per iteration 
the features are grouped as follows  for the lexical feature set  we divide the features
into five types      unseen features      lexical features      semi lexical features      distance  and     alias  in other words  the division corresponds roughly to the one described
in section      except that we put the two conventional features into two different groups 
since linguistically one is a positional feature and the other is a semantic feature  for the
combined feature set  we divide the features into seven groups  the first four of which are
identical to those in the division of the lexical features above  for the remaining features 
we divide them into string matching features  which comprise features      in table   
grammatical features  which comprise features                      and       and
semantic features  which comprise features        and     note that alias  the only semantic feature in the lexical feature set  is combined with other semantic features in the
conventional feature set to form the semantic feature type 
results are shown in tables       specifically  tables   a and   b show the b  and
ceaf f measure scores of the feature analysis experiments involving the mention ranking
model  using the lexical feature set on the nw data set  in each table  the first row shows
how the system would perform if each class of features were removed  we remove the least
   

fi    
    
    
    

    
    
    
    

    
    
    

    
    

ee
n
u
ns

a
lia
s

d
ist
an
ce

i l
ex
ic
al
se
m

le
xi
ca
l

rahman   ng

    

    
    
    
    

    
    
    
    

    
    
    

    
    

ee
n
u
ns

a
lia
s

d
ist
an
ce

le
xi
ca
l

se
m

i l
ex
ic
al

 a  b  results

    

 b  ceaf results

table     feature analysis results  in terms of f measure scores  for the mention ranking
model using the lexical features on the nw data set  when all feature types are used to train
the model  the b  and ceaf f measure scores are      and       respectively 

important feature class  i e   the feature class whose removal yields the best performance  
and the next row shows how the adjusted system would perform without each remaining
class  according to both scoring programs  removing the unseen features yields the least
drop to performance  note from the caption that with the full feature set  the b  score
is      and the ceaf score is        in fact  the two scorers agree that the lexical and
semi lexical features are more important than the unseen  alias  and distance features 
nevertheless  these results suggest that all five feature types are important  since the best
performance is achieved using the full feature set 
tables   a and   b show the b  and ceaf f measure scores of the feature analysis
experiments involving the cluster ranking model  using the combined feature set on the nw
data set  recall that in the combined feature set  we have seven types of features  as we can
see  the two scorers agree completely on the order in which the features should be removed 
in particular  the most important features are the lexical and semi lexical features 
whereas the least important features are those that are not present in the lexical feature
set  namely  the grammatical  string matching  and semantic features  this suggests
that the lexical features are in general more important than the non lexical features when
they are used in combination  this is somewhat surprising  as the non lexical features
are the commonly used features for coreference resolution  whereas lexical features are
comparatively much less investigated by coreference researchers  nevertheless  unlike what
we saw in table     where all feature types appear to be relevant  in table   a  we see that
   

fi    
    
    
    

at
ica
l
m

at
ch
m
g

an
tic
se
m
    
    
    

g
ra
m

    
    
    
    
    

d
ist
an
ce

u
ns

ee
n

i l
ex
ica
l
    
    
    
    
    
    

st
rin

    
    
    
    
    
    

se
m

le
xi
ca
l

a cluster ranking approach to coreference resolution

    
    

    

    
    
    
    

at
ica
l
m

at
ch
m
g

an
tic
se
m
    
    
    

g
ra
m

    
    
    
    
    

d
ist
an
ce

u
ns

ee
n

i l
ex
ica
l
    
    
    
    
    
    

st
rin

    
    
    
    
    
    

se
m

le
xi
ca
l

 a  b  results

    
    

    

 b  ceaf results

table     feature analysis results  in terms of f measure  for the cluster ranking model
using the combined features on the nw data set  when all feature types are used to train the
model  the b  and ceaf f measure scores are      and       respectively 

the best b  f measure score is       which is achieved using only the lexical features 
this represents a      absolute gain in f measure over the model trained on all seven
feature types  suggesting a learning based coreference model could be improved via feature
selection 
next  we investigate whether similar trends can be observed when the models are trained
on a different source  broadcast news  specifically  we show in tables   a and   b the b 
and ceaf f measure scores of the feature analysis experiments involving the mentionranking model  using the lexical feature set on the bn data set  as in table     we
see that the two scorers agree completely on the order in which the features should be
removed  in fact  similar to what we observed in table     on the nw data set   both
scorers determine that the lexical and semi lexical features are the most important 
whereas the distance and alias features are the least important  although all five feature
types appear to be relevant according to both scorers 
finally  we show in tables   a and   b the b  and ceaf f measure scores of the feature
analysis experiments involving the cluster ranking model  using the combined feature set
   

fi    
    
    
    

    
    
    
    

    
    
    

    
    

a
lia
s

ee
n
u
ns

d
ist
an
ce

i l
ex
ica
l
se
m

le
xi
ca
l

rahman   ng

    

    
    
    
    

    
    
    
    

    
    
    

    
    

a
lia
s

ee
n
u
ns

d
ist
an
ce

i l
ex
ica
l
se
m

le
xi
ca
l

 a  b  results

    

 b  ceaf results

table     feature analysis results  in terms of f measure  for the mention ranking model
using the lexical features on the bn data set  when all feature types are used to train the
model  the b  and ceaf f measure scores are      and       respectively 

on the bn data set  as in tables    and     the two scorers agree completely on the order in
which the features should be removed  as far as feature contribution is concerned  these two
tables resemble tables   a and   b  in both cases  the lexical  semi lexical  and unseen
features are the most important  the string matching and grammatical features are the
least important  and the semantic and distance features are in the middle  in this case 
however  all seven feature types seem to be relevant  as the best performance is achieved
using the full feature set according to both scorers  perhaps most interestingly  the numbers
in each column are generally increasing as we move down the column  this means that a
feature type becomes progressively less useful as we remove more and more feature types 
this also suggests that the interactions between different feature types are non trivial and
that a feature type may be useful only in the presence of another feature type 
in summary  results on two data sets  nw and bn  and two scoring programs demonstrate that     in general all feature types are crucial to overall performance  and    
the little investigated lexical features contribute more to overall performance than the
commonly used conventional features 
    resolution performance
to gain additional insights into our results  we analyze the behavior of the coreference
models for different types of anaphoric expressions when they are trained with different
feature sets  specifically  we partition the mentions into different resolution classes  while
   

fiat
ica
l
m

m

at
ch
    
    
    

g

d
ist
an
ce

an
tic
    
    
    
    

g
ra
m

    
    
    
    
    

se
m

u
ns

ee
n

i l
ex
ica
l
    
    
    
    
    
    

st
rin

    
    
    
    
    
    

se
m

le
xi
ca
l

a cluster ranking approach to coreference resolution

    
    

    

at
ica
l
m

m

at
ch
    
    
    

g

d
ist
an
ce

an
tic
    
    
    
    

g
ra
m

    
    
    
    
    

se
m

u
ns

ee
n

i l
ex
ica
l
    
    
    
    
    
    

st
rin

    
    
    
    
    
    

se
m

le
xi
ca
l

 a  b  results

    
    

    

 b  ceaf results

table     feature analysis results  in terms of f measure  for the cluster ranking model
using the combined features on the bn data set  when all feature types are used to train the
model  the b  and ceaf f measure scores are      and       respectively 

previous work has focused mainly on three rather coarse grained resolution classes  namely 
pronouns  proper nouns  and common nouns   we follow stoyanov et al         and subdivide
each class into three fine grained classes  it is worth mentioning that none of stoyanov et
al s classes corresponds to non anaphoric expressions  since we believe that non anaphoric
expressions play an important role in the analysis of the performance of a coreference
model  we propose three additional classes that correspond to non anaphoric pronouns 
non anaphoric proper nouns  and non anaphoric common nouns  finally  there are certain
types of anaphoric pronouns  e g   wh pronouns  that do not fall into any of stoyanov et
al s pronoun categories  to fill this gap  we create another category that serves as the
default category for any anaphoric pronouns not covered by stoyanov et al s classes  this
results in    resolution classes  which are discussed below in detail 
proper nouns  four classes are defined for proper nouns      e  a proper noun is assigned
to this exact string match class if there is a preceding mention such that the two are
coreferent and are the same string      p  a proper noun is assigned to this partial string
match class if there is a preceding mention such that the two are coreferent and have some
   

firahman   ng

content words in common      n  a proper noun is assigned to this no string match class
if there is no preceding mention such that the two are coreferent and have some content
words in common  and     na  a proper noun is assigned to this non anaphor class if it is
not coreferent with any preceding mention 
common nouns  four analogous resolution classes are defined for mentions whose head
is a common noun      e      p      n  and     na 
pronouns  we have three pronoun classes            st and  nd person pronouns      
g   gendered  rd person pronouns  e g   she        u   ungendered  rd person pronouns 
     oa  any anaphoric pronouns that do not belong to            and       and      na 
non anaphoric pronouns 
next  we score each resolution class  unlike stoyanov et al          who use a modified
version of the muc scorer  we employ b    the reasons are that the muc scorer     does
not reward singleton clusters  and     can inflate a systems performance when the clusters
are overly large  to compute the score for class c  we process the mentions in a test text in
a left to right manner  for each mention encountered  we check whether it belongs to c  if
so  we use our coreference model to decide how to resolve it  otherwise  we use an oracle to
make the correct resolution decision    so that in the end all the mistakes can be attributed
to the incorrect resolution of the mentions in c  thus allowing us to directly measure its
impact on overall performance   after all the test documents are processed  we compute
the b  f measure score on only the mentions that belong to c 
performance of each resolution class  when aggregated over the test sets of the six data
sources in the same way as before  are shown in table     which provides a nice diagnosis
of the strengths and weaknesses of each coreference model when used in combination with
each feature set  we also show in the table the percentage of mentions belonging to each
class below the name of each class  and abbreviate the name of each model as follows  hm
corresponds to the head match baseline  whereas mp  em  mr  and cr denote the mentionpair model  the entity mention model  the mention ranking model  and the cluster ranking
model  respectively  each ranking model has two versions  the pipeline version  denoted by
p  and the joint version  denoted by j  
a few points deserve mention  recall from table   that when the conventional features
are used  the joint mention ranking model performs better than the mention pair model
and the entity mention model  comparing row   with rows   and   of table     we can
see that the improvements can be attributed primarily to its better handling of one proper
    if the oracle determines that a mention is anaphoric and that its antecedents are not in the same cluster
 because our model has previously made a mistake   we employ the following heuristic to select which
antecedent to resolve the mention to  we try to resolve it to the closest preceding antecedent that does
not belong to class c  and if no such antecedent exists  we resolve it to the closest preceding antecedent
that belongs to class c  the reason behind the heuristics preference for a preceding antecedent that does
not belong to class c is simple  since we are resolving the mention using an oracle  we want to choose
the antecedent that allows us to maximize the overall score  resolving the mention to an antecedent
that does not belong to c is more likely to yield a better score than resolving it to an antecedent that
belongs to c  since the former was resolved using an oracle but the latter was not  the same heuristic
applies if we are trying to use the oracle to resolve a mention to a preceding cluster  we first attempt to
resolve it to the closest preceding cluster containing a mention that does not belong to c  and if no such
antecedent exists  we resolve it to the closest preceding cluster containing a mention that belongs to c 

   

fia cluster ranking approach to coreference resolution

proper nouns
p
n
na
   
   
    

e
   

common nouns
p
n
na
   
   
    

class
 

e
    

 

hm

    

    

    

    

    

 
 
 
 
 
 

mp
em
mr p
mr j
cr p
cr j

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

using
    
    
    
    
    
    

 
 
  
  
  
  

mp
em
mr p
mr j
cr p
cr j

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

using the lexical feature set
                        
                        
                        
                        
                        
                        

  
  
  
  
  
  

mp
em
mr p
mr j
cr p
cr j

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

using the
         
         
         
         
         
         

pronouns
u 
oa
   
   

   
    

g 
   

    

    

    

    

    

the conventional feature set
                        
                        
                        
                        
                        
                        

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

    

    

    

combined feature set
              
              
              
              
              
              

na
   

table     b  f measure scores of different resolution classes 
noun class  e  and all three classes that correspond to non anaphoric mentions  na   these
results indicate that it is important to take into account the non anaphoric mentions when
analyzing the performance of a coreference model  at the same time  we can see that the
joint mention ranking model does not resolve the type e common nouns as well as the
mention pair model and the entity mention model  also  results in rows   and   indicate
that the joint cluster ranking model is better than the joint mention ranking model due to
its better handling of the type e common nouns  the non anaphoric common nouns  as
well as the anaphoric pronouns 
next  recall from table   that when the lexical features are used in lieu of the conventional features  the mention pair model  the entity mention model  and the joint mentionranking model all exhibit significant improvements in performance  for the mention pair
model and the entity mention model  such improvements stem primarily from better handling of three proper noun classes  e p na   two common noun classes  e na   and the nonanaphoric pronouns  compare rows   and   as well as rows   and   of table      for the joint
mention ranking model  on the other hand  the improvements accrue from better handling
of two proper noun classes  p n   two common classes  e na   and the anaphoric pronouns 
   

firahman   ng

as can be seen from rows   and     while the joint cluster ranking model does not show
overall improvement as we switch from conventional to lexical features  compare rows  
and      the resulting models behave differently  specifically  using the lexical features  the
model gets worse at handling one proper noun class  e  and one common noun class  e  
but better at handling another proper noun class  n   two other common noun classes  p n  
one anaphoric pronoun class        and the non anaphoric pronouns 
finally  recall that when the combined features are used in lieu of the lexical features 
all but the cluster ranking model show a deterioration in performance  for the mention pair
model and the entity mention model  the deterioration in performance can be attributed
to poorer handling of two proper noun classes  e na   two common noun classes  e na  
and the non anaphoric pronouns  although they are better at handling one proper noun
class  n  and the anaphoric pronouns  compare rows   and    as well as rows   and    of
table      overall  poorer handling of anaphoricity appears to be a major factor responsible
for the performance deterioration  for the joint mention ranking model  the reasons for the
performance deterioration are slightly different  comparing rows    and     we see its poorer
handling of two proper noun classes  p n   three common noun classes  p n na   and the
anaphoric pronouns  although it is better at handling the non anaphoric proper nouns and
pronouns  as mentioned before  the two versions of the cluster ranking model improve
when they are trained on the combined features  however  such improvements do not stem
from improvements for all classes  compare rows    and    as well as rows    and     
for instance  when replacing the lexical features with the combined features in the joint
cluster ranking model  we see improvements for two proper noun classes  e na   one common
noun class  e   and several pronoun classes      g  u    but performance drops for another
proper noun class  p   three other common noun classes  p n na   and two pronoun classes
 oa na  
overall  these results provide us with additional insights into the strengths and weaknesses of a learning based coreference model as well as directions for future work  in particular  even if two models yield similar overall performance  they can be quite different at
the resolution class level  since there is no single coreference model that outperforms the
others on all resolution classes  it may be beneficial to apply an ensemble approach  where
an anaphor belonging to a particular resolution class is resolved by the model that offers
the best performance for that class 

   conclusions
as mitkov        p       puts it  coreference resolution is a difficult  but not intractable
problem  and researchers have been making steady progress on improving machine learning approaches to the problem in the past fifteen years  the progress is slow  however 
despite its deficiencies  the mention pair model was widely thought to be the only learningbased coreference model for almost a decade  the entity mention model and the mentionranking model emerged only after the mention pair model has dominated learning based
coreference research for nearly ten years  although these two models are conceptually simple  they represent a significant departure from the mention pair model and a new way of
thinking about how alternative models of coreference can be designed  our cluster ranking
model further advances learning based coreference research theoretically by combining the
   

fia cluster ranking approach to coreference resolution

strengths of these two models  thereby addressing two commonly cited weaknesses of the
mention pair model  it not only bridges the gap between two independent lines of learningbased coreference research  one concerning the entity mention model and the other the
mention ranking model  that has been going on for the past few years  but also narrows the modeling gap between the sophistication of rule based coreference models and
the simplicity of learning based coreference models  empirically  we have shown using the
ace      coreference data set that the cluster ranking model acquired by jointly learning
anaphoricity determination and coreference resolution surpasses the performance of several
competing approaches  including the mention pair model  the entity mention model  and
the mention ranking model  perhaps equally importantly  our cluster ranking model is the
only model considered here that can profitably exploit the information provided by two
fairly different sources of information  the conventional features and the lexical features 
while ranking is a more natural formulation of coreference resolution than classification 
ranking based coreference models have not been more popularly used than the influential
mention pair model  one of our goals in this article is to promote the application of ranking
techniques to coreference resolution  specifically  we attempted to clarify the difference between classification based and ranking based coreference models by showing the constrained
optimization problem that an svm learner needs to solve for each type of models  hoping
that this will help the reader appreciate the importance of ranking for coreference resolution  in addition  we have provided ample empirical evidence that ranking based models
are superior to classification based models for coreference resolution 
another contribution of our work lies in the empirical demonstration of the benefits of
lexicalizing learning based coreference models  while previous work showed that lexicalization only provides marginal benefits to a coreference model  we showed that lexicalization can significantly improve the mention pair model  the entity mention model  and the
mention ranking model  to the point where they approach or even surpass the performance
of the cluster ranking model  interestingly  we showed that these models benefit from lexicalization the most when no conventional coreference features are used  this challenges
the common belief that there is a prototypical set of linguistic features  e g   gender and
number agreement  that must be used for constructing learning based coreference systems 
in addition  our feature analysis experiments indicated that the conventional features contributed less to overall performance than the rarely studied lexical features for our joint
cluster ranking coreference model when the two types of features are used in combination 
finally  we examined the performance of each coreference model in resolving mentions
belonging to different resolution classes  we found that even if two models achieve similar
overall performance  they can be quite different at the resolution class level  overall  these
results provide us with additional insights into the strengths and weaknesses of a learningbased coreference model as well as promising directions for future research 

bibliographic note
portions of this work were previously presented in a conference publication  rahman  
ng         the current article extends this work in several ways  most notably      an
overview of the literature on ranking approaches to coreference resolution  section         a
detailed explanation of the difference between classification and ranking  section         an
   

firahman   ng

investigation of the issues in lexicalizing coreference models  section     and     an in depth
analysis of the different aspects of our coreference system  section    

acknowledgments
the authors acknowledge the support of national science foundation  nsf  grant iis         we thank the three anonymous reviewers for insightful comments and for unanimously recommending this article for publication in jair  any opinions  findings  conclusions or recommendations expressed in this article are those of the authors and do not
necessarily reflect the views or official policies  either expressed or implied  of nsf 

references
androutsopoulos  i     malakasiotis  p          a survey of paraphrasing and textual
entailment methods  journal of artificial intelligence research              
aone  c     bennett  s  w          evaluating automated and manual acquisition of
anaphora resolution strategies  in proceedings of the   rd annual meeting of the
association for computational linguistics  acl   pp         
bagga  a     baldwin  b          algorithms for scoring coreference chains  in proceedings
of the linguistic coreference workshop at the first international conference on
language resources and evaluation  lrec   pp         
barbu  c     mitkov  r          evaluation tool for rule based anaphora resolution methods  in proceedings of the   th annual meeting of the association for computational
linguistics  acl   pp       
bengtson  e     roth  d          understanding the values of features for coreference
resolution  in proceedings of the      conference on empirical methods in natural
language processing  emnlp   pp         
berger  a  l   della pietra  s  a     della pietra  v  j          a maximum entropy
approach to natural language processing  computational linguistics               
bikel  d  m   schwartz  r     weischedel  r  m          an algorithm that learns whats
in a name  machine learning  special issue on natural language learning          
       
blum  a     langley  p          selection of relevant features and examples in machine
learning  artificial intelligence                  
burges  c  j  c          a tutorial on support vector machines for pattern recognition 
data mining and knowledge discovery                
cai  j     strube  m          evaluation metrics for end to end coreference resolution
systems  in proceedings of the   th annual sigdial meeting on discourse and dialogue
 sigdial   pp       
carbonell  j     brown  r          anaphora resolution  a multi strategy approach  in
proceedings of the   th international conference on computational linguistics  coling   pp        
   

fia cluster ranking approach to coreference resolution

cardie  c     wagstaff  k          noun phrase coreference as clustering  in proceedings
of the      joint sigdat conference on empirical methods in natural language
processing and very large corpora  emnlp vlc   pp       
charniak  e     elsner  m          em works for pronoun anaphora resolution  in proceedings of the   th conference of the european chapter of the association for computational linguistics  eacl   pp         
collins  m  j          head driven statistical models for natural language parsing  ph d 
thesis  department of computer and information science  university of pennsylvania 
philadelphia  pa 
connolly  d   burger  j  d     day  d  s          a machine learning approach to anaphoric
reference  in proceedings of international conference on new methods in language
processing  pp         
culotta  a   wick  m     mccallum  a          first order probabilistic models for coreference resolution  in human language technologies       the conference of the north
american chapter of the association for computational linguistics  proceedings of
the main conference  naacl hlt   pp       
daume iii  h     marcu  d          a large scale exploration of effective global features
for a joint entity detection and tracking model  in proceedings of human language
technology conference and conference on empirical methods in natural language
processing  hlt emnlp   pp        
denis  p     baldridge  j       a   global  joint determination of anaphoricity and coreference resolution using integer programming  in human language technologies      
the conference of the north american chapter of the association for computational
linguistics  proceedings of the main conference  naacl hlt   pp         
denis  p     baldridge  j       b   a ranking approach to pronoun resolution  in proceedings
of the twentieth international conference on artificial intelligence  ijcai   pp      
     
denis  p     baldridge  j          specialized models and ranking for coreference resolution 
in proceedings of the      conference on empirical methods in natural language
processing  emnlp   pp         
enrique  a   gonzalo  j   artiles  j     verdejo  f          a comparison of extrinsic clustering evaluation metrics based on formal constraints  information retrieval         
       
fellbaum  c          wordnet  an electronic lexical database  mit press  cambridge  ma 
finkel  j  r   grenager  t     manning  c          incorporating non local information into
information extraction systems by gibbs sampling  in proceedings of the   rd annual
meeting of the association for computational linguistics  acl   pp         
finkel  j  r     manning  c          enforcing transitivity in coreference resolution  in
proceedings of acl     hlt short papers  companion volume   pp       
florian  r   hassan  h   ittycheriah  a   jing  h   kambhatla  n   luo  x   nicolov  n    
roukos  s          a statistical model for multilingual entity detection and tracking 
in hlt naacl       main proceedings  pp     
   

firahman   ng

ge  n   hale  j     charniak  e          a statistical approach to anaphora resolution 
proceedings of the sixth workshop on very large corpora  wvlc   pp         
grosz  b  j   joshi  a  k     weinstein  s          providing a unified account of definite noun phrases in discourse  in proceedings of the   th annual meeting of the
association for computational linguistics  acl   pp       
grosz  b  j   joshi  a  k     weinstein  s          centering  a framework for modeling
the local coherence of discourse  computational linguistics                 
haghighi  a     klein  d          coreference resolution in a modular  entity centered
model  in human language technologies  the      annual conference of the north
american chapter of the association for computational linguistics  naacl hlt  
pp         
hobbs  j          resolving pronoun references  lingua             
iida  r   inui  k     matsumoto  y          capturing salience with a trainable cache
model for zero anaphora resolution  in proceedings of the joint conference of the   th
annual meeting of the acl and the  th international joint conference on natural
language processing of the afnlp  acl ijcnlp   pp         
iida  r   inui  k   takamura  h     matsumoto  y          incorporating contextual cues
in trainable models for coreference resolution  in proceedings of the eacl workshop
on the computational treatment of anaphora 
ji  h   rudin  c     grishman  r          re ranking algorithms for name tagging  in
proceedings of workshop on computationally hard problems and joint inference in
speech and language processing  pp       
ji  h   westbrook  d     grishman  r          using semantic relations to refine coreference
decisions  in proceedings of human language technology conference and conference
on empirical methods in natural language processing  hlt emnlp   pp       
joachims  t          making large scale svm learning practical  in scholkopf  b   burges 
c     smola  a   eds    advances in kernel methods  support vector learning  pp 
      mit press  cambridge  ma 
joachims  t          optimizing search engines using clickthrough data  in proceedings
of the eighth acm sigkdd international conference on knowledge discovery and
data mining  kdd   pp         
kehler  a   appelt  d   taylor  l     simma  a          the  non utility of predicateargument frequencies for pronoun interpretation  in proceedings of the human language technology conference of the north american chapter of the association for
computational linguistics  hlt naacl   pp         
kuhn  h  w          the hungarian method for the assignment problem  naval research
logistics quarterly          
lappin  s     leass  h          an algorithm for pronominal anaphora resolution  computational linguistics                 
lin  d     wu  x          phrase clustering for discriminative learning  in proceedings of
the joint conference of the   th annual meeting of the acl and the  th international
   

fia cluster ranking approach to coreference resolution

joint conference on natural language processing of the afnlp  acl ijcnlp   pp 
         
luo  x          on coreference resolution performance metrics  in proceedings of human
language technology conference and conference on empirical methods in natural
language processing  hlt emnlp   pp       
luo  x   ittycheriah  a   jing  h   kambhatla  n     roukos  s          a mentionsynchronous coreference resolution algorithm based on the bell tree  in proceedings
of the   nd annual meeting of the association for computational linguistics  acl  
pp         
madnani  n     dorr  b          generating phrasal and sentential paraphrases  a survey
of data driven methods  computational linguistics                 
mccarthy  j     lehnert  w          using decision trees for coreference resolution  in proceedings of the fourteenth international conference on artificial intelligence  ijcai  
pp           
mitkov  r          robust pronoun resolution with limited knowledge  in proceedings of
the   th annual meeting of the association for computational linguistics and   th
international conference on computational linguistics  coling acl   pp     
    
mitkov  r          outstanding issues in anaphora resolution  in gelbukh  a   ed   
computational linguistics and intelligent text processing  pp          springer 
mitkov  r          anaphora resolution  longman 
morris  j     hirst  g          lexical cohesion computed by thesaural relations as an
indicator of the struture of text  computational linguistics               
morton  t          coreference for nlp applications  in proceedings of the   th annual
meeting of the association for computational linguistics  acl  
muc           proceedings of the sixth message understanding conference  muc    
morgan kaufmann  san francisco  ca 
muc           proceedings of the seventh message understanding conference  muc    
morgan kaufmann  san francisco  ca 
ng  v          graph cut based anaphoricity determination for coreference resolution  in
proceedings of the      conference of the north american chapter of the association
for computational linguistics  human language technologies  naacl hlt   pp 
       
ng  v     cardie  c       a   identifying anaphoric and non anaphoric noun phrases to
improve coreference resolution  in proceedings of the   th international conference
on computational linguistics  coling   pp         
ng  v     cardie  c       b   improving machine learning approaches to coreference resolution  in proceedings of the   th annual meeting of the association for computational
linguistics  acl   pp         
   

firahman   ng

poesio  m   uryupina  o   vieira  r   alexandrov kabadjov  m     goulart  r         
discourse new detectors for definite description resolution  a survey and a preliminary
proposal  in proeedings of the acl workshop on reference resolution 
ponzetto  s  p     strube  m          exploiting semantic role labeling  wordnet and
wikipedia for coreference resolution  in proceedings of the human language technology conference and conference of the north american chapter of the association
for computational linguistics  hlt naacl   pp         
rahman  a     ng  v          supervised models for coreference resolution  in proceedings of the      conference on empirical methods in natural language processing
 emnlp   pp         
ravichandran  d   hovy  e     och  f  j          statistical qa   classifier vs  re ranker 
whats the difference  in proceedings of the acl      workshop on multilingual
summarization and question answering  pp       
recasens  m     hovy  e          blanc  implementing the rand index for coreference
resolution  natural language engineering  to appear  
roth  d          reasoning with classifiers   in proceedings of the   th european conference
on machine learning  ecml   pp         
roth  d     yih  w  t          a linear programming formulation for global inference in
natural language tasks   in proceedings of the eighth conference on computational
natural language learning  conll   pp     
soon  w  m   ng  h  t     lim  d  c  y          a machine learning approach to coreference
resolution of noun phrases  computational linguistics                 
stoyanov  v   gilbert  n   cardie  c     riloff  e          conundrums in noun phrase
coreference resolution  making sense of the state of the art  in proceedings of the
joint conference of the   th annual meeting of the acl and the  th international
joint conference on natural language processing of the afnlp  acl ijcnlp   pp 
       
strube  m     muller  c          a machine learning approach to pronoun resolution in
spoken dialogue  in proceedings of the   st annual meeting of the association for
computational linguistics  acl   pp         
strube  m   rapp  s     muller  c          the influence of minimum edit distance on
reference resolution  in proceedings of the      conference on empirical methods in
natural language processing  emnlp   pp         
toutanova  k   klein  d   manning  c  d     singer  y          feature rich part of speech
tagging with a cyclic dependency network  in hlt naacl       proceedings of the
main conference  pp         
uryupina  o          high precision identification of discourse new and unique noun
phrases  in proceedings of the   st annual meeting of the association for computational linguistics  companion volume  pp       
vapnik  v  n          the nature of statistical learning  springer  new york 
   

fia cluster ranking approach to coreference resolution

vilain  m   burger  j   aberdeen  j   connolly  d     hirschman  l          a modeltheoretic coreference scoring scheme  in proceedings of the sixth message understanding conference  muc     pp       
walker  m   joshi  a     prince  e   eds            centering theory in discourse  oxford
university press 
yang  x   su  j   lang  j   tan  c  l     li  s          an entity mention model for
coreference resolution with inductive logic programming  in proceedings of the   th
annual meeting of the association for computational linguistics  human language
technologies  acl     hlt   pp         
yang  x   su  j   zhou  g     tan  c  l          an np cluster based approach to coreference
resolution  in proceedings of the   th international conference on computational
linguistics  coling   pages        
yang  x   zhou  g   su  j     tan  c  l          coreference resolution using competitive
learning approach  in proceedings of the   st annual meeting of the association for
computational linguistics  acl   pp         

   

fi