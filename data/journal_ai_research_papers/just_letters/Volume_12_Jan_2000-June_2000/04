journal articial intelligence research                  

submitted        published     

robust agent teams via socially attentive monitoring

gal a  kaminka
milind tambe

galk isi edu
tambe isi edu

information sciences institute computer science department
university southern california
     admiralty way
los angeles  ca        usa

abstract
agents dynamic multi agent environments must monitor peers execute individual group plans  key open question much monitoring agents 
states required eective  monitoring selectivity problem  investigate
question context detecting failures teams cooperating agents  via sociallyattentive monitoring  focuses monitoring failures social relationships
agents  empirically analytically explore family socially attentive
teamwork monitoring algorithms two dynamic  complex  multi agent domains 
varying conditions task distribution uncertainty  show centralized scheme
using complex algorithm trades correctness completeness requires monitoring
teammates  contrast  simple distributed teamwork monitoring algorithm results
correct complete detection teamwork failures  despite relying limited  uncertain
knowledge  monitoring key agents team  addition  report design
socially attentive monitoring system demonstrate generality monitoring several coordination relationships  diagnosing detected failures  on line o line
applications 

   introduction
agents complex  dynamic  multi agent environments must able detect  diagnose 
recover failures run time  toyama   hager        

instance  robot s

grip may slippery  opponents  behavior may intentionally dicult predict  communications may fail  etc  examples environments include virtual environments
training  johnson   rickel        calder  smith  courtemanche  mar    ceranowicz        
high delity distributed simulations  tambe  johnson  jones  koss  laird  rosenbloom   
schwamb        kitano  tambe  stone  veloso  coradeschi  osawa  matsubara  noda   
asada         multi agent robotics  parker        balch         rst key step
process execution monitoring  doyle  atkinson    doshi        ambros ingerson  
steel        cohen  amant    hart        reece   tate        atkins  durfee    shin 
      veloso  pollack    cox        
monitoring execution multi agent settings requires agent monitor peers 
since correct execution depends state peers  cohen   levesque 
      jennings        parker        jennings        grosz   kraus        tambe        
monitoring peers particular importance teams  since team members rely
work closely together related tasks 

c      ai access foundation morgan kaufmann publishers  rights reserved 

fikaminka tambe

monitoring allows team members coordinate actions plans team 

mates  help teammates cooperate without interference  example  drivers
cars convoy cannot drive without monitoring cars convoy 
disband convoy  help drivers cars break down 
monitoring allows team members use peers dynamic information sources 

learning new information  instance  driver convoy sees cars
front suddenly turn left  infer existence obstacle
milestone despite directly seeing herself 
previous work investigated dierent ways monitoring context teams cooperating agents  example  theoretical work sharedplans  grosz   kraus       

passive monitoring  agent notied proposition
changes  e g   via communications   active monitoring  agent actively seeks
distinguished

nd proposition changes  e g   via observations inference unobservable
attributes   practical implementations investigated use passive monitoring via
communications  jennings         active monitoring via plan recognition  huber   durfee         active implicit monitoring via environment  fenster  kraus    rosenschein 
       dierent combinations methods  parker        jennings        tambe 
      lesh  rich    sidner        

approach clearly superior another 

passive

monitoring generally perceived less costly active monitoring  less
reliable  grosz   kraus        huber   durfee        kaminka   tambe        
regardless monitoring method  bandwidth computational limitations prohibit
monitoring agent monitoring agents full extent  time  jennings 
      durfee        grosz   kraus         thus key open question much monitoring agents required eective  in teams   jennings        grosz   kraus 
             call challenging problem

monitoring selectivity problem 

i e  

problem selectivity observing others inferring state  based observations  monitoring 

although raised past  framework

minimal constraints answers provided  jennings        grosz   kraus        
instance  theory sharedplans requires agents verify intentions
conict teammates  grosz   kraus         however  methods
verication take place left investigation  grosz   kraus        p 
      section   provides details related work 
paper begins address monitoring selectivity problem teams  investigating monitoring requirements eective failure detection 

focus investigation

detecting failures social relationships ideally hold agents monitored team  call monitoring social relationships

socially attentive monitoring 

dierentiate types monitoring  monitoring failures
progress agents towards goals  here  term social relationship used denote
relation attributes multiple agents  states  socially attentive monitoring convoy
example involves verifying agents common destination heading 
beliefs driving convoy mutual  etc  instance  agents observed
head dierent directions  clearly common heading  dierent
monitoring whether chosen  common  heading leads towards  agreed upon 
destination 

   

firobust agent teams via socially attentive monitoring

monitoring relationships team  socially attentive monitoring  critical task
monitoring team members 

failures maintain team s relationships often lead

catastrophic failures part team  lack cooperative behavior lack
coordination  failures often result individual agent failures  failures
agent s sensors actuators  thus socially attentive monitoring covers large class
failures  promotes robust individual operation 
explore socially attentive monitoring algorithms detecting teamwork failures various conditions uncertainty 

analytically show despite presence

uncertainty actual state monitored agents  centralized

active

monitoring

scheme guarantee failure detection either sound incomplete  complete
unsound  however  requires reasoning multiple hypotheses actual
state monitored agents  monitoring agents team 

show active

distributed teamwork monitoring results sound complete detection capabilities 
despite using much simpler algorithm  distributed algorithm   a  uses single 
possibly incorrect hypothesis actual state monitored agents   b  involves monitoring key agents team  necessarily team members  using transformation
analytical constructs  show analogous results centralized failure detection
mutual exclusion coordination relationships 
conduct empirical investigation socially attentive monitoring teams 
present implemented general socially attentive monitoring framework
expected ideal social relationships maintained agents compared
actual social relationships  discrepancies detected possible failures diagnosed  apply framework two dierent complex  dynamic  multi agent domains 
service monitoring various social relationships  on line o line 
domains involve multiple interacting agents collaborative adversarial settings 
uncertainties perception action 

one domain  provide empirical results

active monitoring conrm analytical results  another domain show
o line socially attentive monitoring provide quantitative teamwork quality feedback
designer  provide initial diagnosis procedures detected failures 
focus explorations practical algorithms guarantees performance real world applications  algorithms present seek complement use
passive communications based monitoring  which unreliable many domains  explore
use unintrusive key hole plan recognition alternative  however  rule
use communicationswe simply seek provide techniques work even
communications fail 

analytical guarantees failure detection soundness

completeness hold whether monitoring done communications plan recognition 
paper organized follows  section   presents motivating examples background  section   presents socially attentive monitoring framework  section   explores
monitoring selectivity centralized teamwork monitoring 

section   explores monitoring

selectivity distributed teamwork monitoring  section   demonstrates generality
framework applying o line conguration  section   presents investigations additional relationship models  section   presents related work  section   concludes 
two appendices contain proofs theorems presented  appendix a   pseudo code
socially attentive monitoring algorithms  appendix b  

   

fikaminka tambe

   motivation background
monitoring selectivity problem paper addresseshow much monitoring required
failure detection teamsrose growing frustration signicant software
maintenance eorts two application domains 

modsaf domain  high 

delity battleeld virtual environment  calder et al          involved
development synthetic helicopter pilots  tambe et al         

robocup soccer

simulation domain  kitano et al         involved developing synthetic soccer players  marsella  adibi  al onaizan  kaminka  muslea  tallis    tambe        
environments domains dynamic complex  many uncertainties 
behavior agents  some adversarial  cooperative   unreliable communications sensors  actions may execute intended  etc 

agents

environments therefore presented countless opportunities failure despite
designers  best eorts 
examples may serve illustrate  following two examples actual failures
occurred modsaf domain 

use two illustrate explore

socially attentive monitoring throughout paper 

example   

here  team three helicopter pilot agents specied way 

point  a given position   one team members 

attackers  

towards enemy  teammates  

scout 

forward

land wait signal 

agents monitored way point  however  due unexpected sensor failure  one
attackers failed sense way point 

attacker correctly landed 

failing attacker continued forward scout  see figure   screen shot
illustrating failure  

example   

dierent run  three agents reached way point detected it 

scout gone forward identied enemy  sent message waiting
attackers join attack enemy  one attackers receive message 
remained behind indenitely scout attacker continued
mission alone 
collected dozens similar reports modsaf robocup domain 
general  failures dicult anticipate design time  due huge number
possible states  agents therefore easily nd novel states
foreseen developer  monitoring conditions communications place
proved insucient  none failure cases reported agents involved detect  let
alone correct  erroneous behavior  agent believed agents acting
coordination it  since communication received agents indicate
otherwise  however  agents violating collaboration relationships them 
agents came disagree plan executeda collaboration relationship
failure occurred 

preliminary empirical results show upwards     failures

reported involved relationship violations  relationship failures  
human observers  however  typically quick notice failures 
clear social misbehavior agents cases  able infer failure
occurred despite knowing exactly happened  instance  seeing attacker
continuing ahead despite teammates  switching dierent plan  which human

   

firobust agent teams via socially attentive monitoring

enemy

scout  ahead  failing attacker  trailing 

landing attacker

figure    plan view display  the modsaf domain  illustrating failure example   
thick wavy lines contour lines 

observers inferred fact one teammates  attacker  landed 
sucient observer detect something gone amisswithout knowing
dierent plan was 
analysis showed agents monitoring suciently  however  naive solution continuous communications agents clearly impractical since   i  agents operating hostile environment   ii  communications
overheads would prohibitive   iii  fact  communications equipment broke cases  therefore sought practical ways achieve
quick detection failure  based limited ambiguous knowledge available
monitoring agent 

   socially attentive monitoring
begin overview general structure socially attentive monitoring system  shown figure    consists of      social relationship knowledge base containing
models relationships hold among monitored agents  enabling generation

expected ideal behavior

terms relationships  section           agent

team modeling component  responsible collecting representing knowledge
monitored agents 

actual behavior

 section           relationship failure detection compo 

nent monitors violations relationships among monitored agents contrasting
expected actual behavior  section           relationship diagnosis component
veries failures  provides explanation  section       resulting

   

fikaminka tambe

explanation  diagnosis  used recovery  e g   negotiations system  kraus 
sycara    evenchik         general  re planner  ambros ingerson   steel        

expected
attribute
values

agents monitor 
agent attributes

social relationships knowledge base
expected behavior
relationship
diagnosis

relationship
failure
detections

detected
failure

observations 
communications

actual
behavior

actual values

monitored agent

agent team modeling component

diagnosis

socially attentive monitoring system

monitored agent

figure    general structure socially attentive monitoring system 

    knowledge base relationship models
take relationship among agents relation state attributes  relationship
model thus species dierent attributes agent s state related
agents multi agent system  attributes include beliefs held
agents  goals  plans  actions  etc  example  many teamwork relationship models
require team members mutual belief joint goal  cohen   levesque       
jennings        

spatial formation relationship  parker        balch        species

relative distances  velocities maintained group agents  in
domain  helicopter pilots  

coordination relationships may specify temporal relationships

hold among actions two agents  e g   business contractors  malone  
crowston        

relationships

social

explicitly specify multiple

agents act believe maintain relationships
them 
relationship knowledge base contains models relationships supposed
hold system  species agents participating relationships 
knowledge base guides agent modeling component selecting agents monitored 
attributes state need represented  for detection diagnosis  
used failure detection component generate expectations contrasted
actual relationships maintained agents  provides diagnosis component
detailed information agents  states  attributes related  drive diagnosis
process 

implementation socially attentive monitoring teams uses four types

relationships 


formations  role similarity  mutual exclusion  teamwork 

teamwork

monitoring



use



steam

 tambe 

     

general

domain 

independent model teamwork  based cohen levesque s joint intentions
framework  levesque  cohen    nunes        cohen   levesque        grosz  sidner 
kraus s sharedplans  grosz   sidner        grosz   kraus              

   

however 

firobust agent teams via socially attentive monitoring

teamwork models may used instead steam  although steam used
pilot soccer agents generate collaborative behavior  reused independently
service monitoring  i e   monitored agents assumed team  steam
used monitoring teamwork  steam teamwork models  e g  

cohen  

levesque        jennings        rich   sidner        require mutual belief team members joint goals plans  characteristic used monitor teamwork
system  relationship models used secondary monitoring role 
discussed greater length section   

    knowledge monitored agents team
agent modeling component responsible acquiring maintaining knowledge

actual relations exist
ideal expected relations 

monitored agents  knowledge used construct
agents  states  attributes  compared

section  describe plan recognition capabilities agent modeling component
implementation experiments  i e   extent knowledge could maintained
monitored agents  plans necessary  later sections show fact limited  possibly
inaccurate  knowledge sucient eective failure detection  thus implementations may
use optimized agent modeling algorithms rather full capabilities  section    
discuss additional agent modeling capabilities  necessary diagnosis 

      representation

monitoring teamwork relationships  found representing agents terms
selected hierarchical reactive plans enables quick monitoring state 
facilitates inference monitored agents  beliefs  goals  unobservable actions 
since capture agents  decision processes 
representation  reactive plans  firby        newell        form single decomposition hierarchy  a tree  represents alternative controlling processes agent 
reactive plan hierarchy  hereafter referred simply plan  selection
conditions  also referred preconditions  applicable  termination conditions used terminate suspend plans  given moment  agent
executing single path  root leaf   hierarchy 

path composed

plans dierent levels 
figure   presents small portion hierarchy  created modsaf domain 
case example    prior way point 

agents

executing path be 

execute mission highest level plan  fly flight plan  fly route 
traveling low level  upon reaching way point  supposed switch
fly flight plan descendents wait at point  attackers would
select just wait child wait at point  scout would select scout forward
ginning

descendents  course  failing attacker detect way point

fly flight plan selection conditions wait at point
failing attacker continued execute fly flight plan

termination conditions
satised
descendents 

   

fikaminka tambe

execute mission
fly flight plan  f 
fly route

wait point  w 

join scout  j 

ordered halt  h 

low level

wait

scout forward
traveling

nap earth

contour

figure    portion hierarchical reactive plan library modsaf domain  team plans
boxed  explained section      

      acquisition

practical perspective  agents may cooperatively report monitoring
agent state using communications  requires communication channels
suciently fast  reliable secure 

unfortunately possible many realistic

domains  examples demonstrate  section    
alternatively  monitor may use plan recognition infer agents  unobservable state
observable behavior  approach unintrusive robust face communication failures  course  monitor may still benet focused communications
agents  would critically dependent them 
enable plan recognition using reactive plans  our chosen representation  
employed reactive plan recognition algorithm called resl  real time situated leastcommitments   key capability required allow explicit maintenance hierarchical
plan hypotheses matching agent s observed behavior  pruning hypotheses
deemed incorrect useless monitoring purposes 

resl works expanding

entire plan library hierarchy modeled agent  tagging paths matching
observed behavior agent modeled  see appendix b pseudo code
algorithm   heuristics external knowledge may used eliminate paths  hypotheses 
deemed inappropriateindeed heuristics explored shortly  resl s
basic approach similar previous work reactive plan recognition  rao       
team tracking  tambe         used successfully modsaf domain 
share many resl s properties 

however  resl adds belief inference capabilities

used diagnosis process  discussed  section      
figure   gives simplied presentation plan hierarchies variation example
   agents correctly detected way point  i e   failure occurred  note
plans intermediate levels abstracted gure   scout
 figure  a  two attackers  figures  b   c  switched
 denoted

fly flight plan plan

f  wait at point plan  denoted w   outside observer using resl

infers explanations agent s behavior observing agents  scout continues

   

firobust agent teams via socially attentive monitoring

low level  one possible ight methods
wait at point  w  plans  thus

ahead  speed altitude matching


fly flight plan  f 



tagged possible hypotheses scout s executing plan hierarchy 

similarly 

just wait
ordered halt  h 

attackers land  resl recognizes executing
plan used service either

w



plan 

plana plan

helicopters ordered headquarters land immediately 

h



w

thus

tagged explanations attackers  states  at second level

hierarchies   agents  resl identies plan
plan 

however 

execute mission

top level

illustration  actual executing paths agents marked lled

arrows 

individual modeling

hypotheses match observed behavior marked

using dashed arrows  outside observer  course  way knowing
possible hypotheses correct 

execute mission

wait at point  w 

execute mission

execute mission

fly flight plan  f 

wait at point  w 

ordered halt  h 

wait at point  w 

low level

just wait

just wait

just wait

low level

 b 

 a 

ordered halt  h 

just wait

 c 

figure    scout  a  attackers   b  c  actual recognized

abbreviated

reactive plan

hierarchies 

individual modeling hypotheses acquired individual agent  using planrecognition implementation  potentially communications   monitoring
agent must combine create team modeling hypotheses state team
whole  monitoring agent selects single individual modeling hypothesis
individual agent combines single team modeling hypothesis  several
team modeling hypotheses possible given multiple hypotheses individual agents 
instance  figure    team hypotheses

execution mission

top 

level plan  eight dierent team hypotheses dierentiated
second level plan 

 w w w    w w h    w h w    w h h    f w w    f w h    f h w    f h h  

observer member team  knows executing itself  would still
multiple hypotheses teammates  states  instance  attacker figure  b
monitoring teammates  hypotheses second level would  w w w    w w h  

 f w w    f w h  

avoid explicitly representing combinatorial number hypotheses  resl explicitly
maintains candidate hypotheses agent individually  combinations
individual models team hypotheses  instead  combinations implicitly represented  thus number hypotheses explicitly maintained grows linearly number
agents 

   

fikaminka tambe

    relationship violation detection
failure detection component detects violations social relationships
hold among agents 

done comparing ideal expected relationships

actual maintenance agents  teamwork specically  relationship model requires
team members always agree

team plan jointly executed team  similarly

joint responsibility  jennings         sharedplans  grosz   kraus        
requirement fails actuality  i e   agents executing dierent team plans 
teamwork failure occurred 
basic teamwork failure detection algorithm follows 
plan hierarchies processed top down manner 

monitored agents 

detection component uses

teamwork model tag specic plans team plans  explicitly representing joint activity
team  these plans boxed figures         

team plans equal depths

hierarchies used create team modeling hypotheses  hypothesis 
plans dierent agents compared detect disagreements  dierence found
indication failure 

dierences found  comparison reaches individual

plans  non team  therefore non boxed gures  failure detected  individual plans 
may chosen agent individually service team plans boxed
gures  handled using relationships discussed section  
instance  suppose failing attacker example   monitoring attacker  figure   shows view hierarchical plan left  path
right represents state attacker  who landed   state inferred example observations made monitoring attacker  here 
assuming plan recognition process resulted one correct hypothesis
agent  discuss realistic settings below   figure    dierence would
detected marked arrow two plans second level top 

fly flight plan team plan  on
wait at point team plan  on right  

failing attacker executing

left  

attacker executing

disagreement

team plan executed failure teamwork 

execute mission

execute mission

fly flight plan

wait at point

fly route
traveling
low level

just wait

figure    comparing two hierarchical plans  top most dierence level   

   

firobust agent teams via socially attentive monitoring

detecting disagreements dicult multiple team modeling hypotheses  since
may imply contradictory results respect failure detection  hypotheses may imply failure occurred team  others may not  unfortunately 
expected realistic applications  instance  figure    section      shows several hypotheses possible based observations  however  one hypotheses 
 w w w   implies failure occurredall agents agreement team plan

executingwhile another hypothesis   f w h   implies failures occurred 

limit reasoning small number team hypotheses  restricting
failure detection capabilities  use disambiguation heuristic ranks team modeling
hypotheses level

coherence

represent  heuristic provided initial

solution  later sections examine additional heuristics 

denition   



coherence

level multi agent modeling hypothesis dened

ratio number agents modeled number plans contained hypothesis 
denition results partial ordering hypotheses set  least coherent
hypothesis  one assigns agent dierent plan team mates  
coherent hypothesis  that assigns plan team members  

instance 

hypothesis  f w h  would lowest level coherence     since implies complete

breakdown teamworkevery agent executing dierent plan  hypothesis  w w w 
would coherence level    highest level coherence group three agents 
since assigned plan  ranked would hypothesis
 w w h   single teamwork failure  disagreement w h  coherence level
    
detection component selects single maximally coherent team modeling hypothesis
 ties broken randomly  

intuition using coherence failures agree occur

despite agents  attempts teamwork  thus expect agreements disagreements team 

coherence level team hypothesis inversely related

number teamwork failures implied hypothesis  selecting maximally coherent hypothesis therefore corresponds minimum number of failures heuristic commonly used
diagnosis  hamscher  console    de kleer        
case depicted figure    complete detection process may conceptu 

 

alized follows  

suppose one attackers  whose hierarchy described

figure  b  monitoring team 

first  collects plan hypotheses top

hierarchy agent  including    case   execute mission  

 execute mission    execute mission   one team modeling hypothesis built
these   execute mission 

execute mission  execute mission  

since hypoth 

esis shows disagreement occurs level  process continues second level 
here  hypotheses rst agent left  f w   monitoring second agent
 since knows state  one possibility  w   third agent  w h  

saw above  maximally team coherent hypothesis  w w w  selected  since
indicate failure  process continues third level 

agents

executing individual plans  comparison process stops  algorithm   appendix
b provides greater details process 
   implementations may make use optimized algorithms heuristics integrated
agent modeling algorithm 

   

fikaminka tambe

sub teams introduced  dierence team plans may explained
agents question part dierent sub teams 

sub team members still

agree joint sub team plans  may dier one
sub team next  now  let us assume teams consideration

teams  dened denition   

simple

make denition service later analytical results

appear condition  return issue sub teams section     

denition   

say team

simple 

plan hierarchy involves dierent

team plans executed dierent sub teams 
intuitively  idea simple team  members team jointly execute
team plans hierarchy  denition somewhat similar denition


ground team

 kinny  ljungberg  rao  sonenberg  tidhar    werner        

allow sub team members team joint plan dierent
members 

    relationship diagnosis
diagnosis component constructs explanation detected failure  identifying
failure state facilitating recovery 

diagnosis given terms set agent

belief dierences  inconsistencies  explains failure maintain relationship 
starting point process detected failure  e g   dierence team plans  
diagnosis process compares beliefs agents involved produce set
inconsistent beliefs explain failure 
two problems exist practical applications procedure 

first  monitoring

agent likely access beliefs held monitored agents  since
feasible practice communicate agents  beliefs other  second 
agent real world domain may many beliefs  many vary among
agents  though irrelevant diagnosis  thus relevant knowledge
may simply accessible  may hidden mountains irrelevant facts 
gain knowledge beliefs monitored agents without relying communications 
diagnosis process uses process belief ascription  agent modeling component  using resl implementation  maintains knowledge selection termination
conditions recognized plans  hypotheses   recognized plan hypothesis  modeling component infers termination conditions plan believed false
monitored agent  since terminated plan   found useful
use additional heuristic  infer selection conditions  preconditions 
plan

begun execution

true  idea plan selected

execution  preconditions likely hold  least short period time 
heuristic involves explicit assumption part system new plan
recognized soon begins execution 

designers domains need verify

assumption holds 
agent i  inferred termination selection conditions make set beliefs
bi agent  instance  suppose agent hypothesized switched

executing

fly flight plan



wait at point 

resl infers agent believes

way point detected  a selection condition

   

wait at point  

addition 

firobust agent teams via socially attentive monitoring

resl infers agent believes enemy seen  order

wait at point  

received base halt mission  negated termination conditions

determine facts relevant failure  diagnosis component uses
teamwork model  teamwork model dictates beliefs agents hold must
mutually believed agents team 

dierence detected

beliefs certain failure  team members agree issues agreement
mandatory participation team 

teamwork model thus species

beliefs contained bi sets mutual  therefore consistent 

 

bi    



inconsistency detected  diagnosis procedure looks contradictions  disagreements  would cause dierence team plan selection  dierence beliefs serves
diagnosis  allowing monitoring agent initiate process recovery  e g  
negotiating conicting beliefs  kraus et al         
example  shown section      two attackers example    section    dier
choice team plan  one attacker continuing execution

fly flight plan

plan  helicopters formation  attacker detected waypoint  terminated

fly flight plan

wait at point 

switched

landing immedi 

ately  figure     failing attacker monitors team mate  detects dierence
team plans  section       detected dierence passed diagnosis  failing
attacker makes following inferences 
  

fly flight plan three termination conditions 

 a  seeing enemy   b  detecting

way point   c  receiving order halt  failing attacker  left hierarchy
figure    knows belief none conditions hold  thus
b 

  

wait at point

 

f w ayp oint   e nemy   h altorderg

one selection condition 

way point detected 



termination condition scout sent message join it  identied
enemy s position  diagnosis component case therefore infers
attacker  right hierarchy figure   
b 

 

fw ayp oint   s coutm essagereceivedg

then 
b    b 





 

f w ayp oint  w ayp oint   e nemy   s coutm essagereceived   h altorderg

inconsistent 



inconsistency

 disagreement





attackers 



f w ayp oint  w ayp ointg  i e   contradictory beliefs w aypoint  thus failing

attacker knows team mate seen way point  choose quietly adapt
belief  thereby terminating

fly flight plan

   

selecting

wait at point 



fikaminka tambe

may choose recovery actions  negotiating attacker whether
way point reached 
found diagnosis procedures useful many failures detected
socially attentive monitoring  see section   evaluation discussion  
since paper focuses monitoring selectivity problem

however 

detection  leave

investigation diagnosis procedures future work 

   monitoring selectivity centralized teamwork monitoring
using socially attentive framework section   systematically examine failure
permutations examples      section    centralized teamwork monitoring
conguration  single team member monitoring team 

vary agents

failing  attacker  attacker scout  etc   role monitoring agent  attacker
scout   report empirical results detecting diagnosing failures cases 
using empirical results guide  explore centralized teamwork monitoring analytically  show even monitoring uncertainty  centralized teamwork monitoring
provide either sound complete detection results  but both  
starting point exploration  monitoring agent uses single maximallycoherent team modeling hypothesis discussed section      begin example   
normal order execution

w 

execution
enemy s position 

wait at point  w  

followed

join scout  j  



two attackers land wait scout visually identify

upon identication  scout sends message join it 

triggers selection

j

plan  termination

w

plan  executing

j 

scout hovers low altitude  waiting attackers join it  failures
part attackers  they cannot receive message  part scout  it
cannot send it   failures arise  instance  radio broken team members
range  agent fails  continues execute

w

instead switching

j 

table   summarizes permutations example    permutation number appear
rst column 

next three columns show actual plans selected three

agents a   a  a  permutation 

second to last column shows whether

relationship failure occurred case  i e   whether disagreement exists
agents  finally  last column details physical conditions case 
possible failure permutations  case    none agents failed 
attacker failed 

cases     one

case   scout failed send message attackers failed

receive it  case   scout identify enemy s position  so message sent 
three agents continue execute
since attacker switch

j

w

plan   permutations possible 

plan without scout 

instance  case   table   corresponds example    scout  a   detected
enemy  switched plan

j 

sent message attackers join it  one attacker

 a   received message  switched plan

j  began ying towards scout 

however 

remaining attacker  a   failed receive message  maintains position 
continuing execute

w failing switch j  since agents longer agreement

team plan jointly executed  teamwork failure occurred  condition
monitors used original failure case monitor scout s message  however
failures communications resulted monitoring conditions rendered useless 

   

firobust agent teams via socially attentive monitoring

case

 

actual executing plans

relationship failure

physical

 

attacker a 

attacker a 

scout a 

occurred

failure

 

j

j

j

 

 

 

w

j

j

 

a  fails receive

 

j

w

j

 

a  fails receive

 

w

w

j

 

a  s message lost

 

w

w

w

 

enemy identied

table    possible failure permutations broken radio link scenario  example    

one key issue raised case   table    here  due scout s inability identify
enemy s position  perhaps due failure scout s part  perhaps enemy
simply there   three helicopter pilots remain agreement enemy
identied  here  even though clearly pilots failing make progress towards
task goals  the scout continues search enemy indenitely   relationship failure
taking place  since agents maintaining teamwork relationship failing
make progress  clearly demonstrates failures necessarily relationship
failures 
table   presents results scout monitoring teammates example    using
maximally team coherent hypothesis basis detection  rst column shows
case number  reference table    next three columns show scout s  a  s 
hypothesis plan agent executing according maximal coherence
heuristic  next two columns show whether failure detected  whether
diagnosed correctly  last column shows detection class  discussed below  

case

 

a  s hypothesized executing plans

relationship failure

diagnosis

detection

detected 

success 

class

j

 

n a

true negative

j

 

 

true positive

w

j

 

 

true positive

h

j

 

 

true positive

w

w

 

n a

true negative

attacker a 

attacker a 

scout a 

 

j

j

 

w

j

 

j

 

h

 

w

table    scout s  a   monitoring results permutations example   
example  case   table   shows results scout monitoring original
failure example    section     using resl  selecting maximally coherent hypothesis  scout hypothesizes non moving attacker executing
moving attacker executing
selected plan

j

j  case    column    

w  case

   column    

scout course knows

 case    column     violation teamwork relationship thus

detected  case    column     since a  s

w

agreement rest team s

j 

furthermore  diagnosis successful identifying cause failure  i e  
fact enemy s position identied scout  knowledge
passed failing attacker  case    column    

   

fikaminka tambe

last column table   shows detection class failure  detection class
case one of  true positive  true negative  false positive  false negative 
correspond following possible monitoring outcomes  true positive outcome
relationship failure actually occurred  detected  true negative
failure occurred  system correctly reports none detected 
false positive failure occurred  system nevertheless incorrectly
detects one  false negative failure occurred  system fails
detect it  table   shows permutations example   teamwork monitoring
techniques encounter problematic false positive false negative cases 
closer look results hints key contribution paper addressing
monitoring selectivity problem  eective failure detection take place despite use
uncertain  limited  knowledge monitored agents  case   table    monitoring agent able detect failure

involved 

despite wrong state agents

scout believes two attackers executing

w  h

plan  actually executing 

h  ordered halt 

selected command received

headquarters halt execution hover place 

scout s perspective  hov 

ering attacker therefore inferred executing

h



w 

thus two equally ranked

maximally coherent hypotheses exist  two attackers either executing
executing

h 

w



random selection made  case resulted wrong hypothe 

sis selected  nevertheless  violation teamwork relationships detected 
neither

h



w

agrees scout s

j 

however  last column case   shows  in table     diagnosis procedures
sensitive selection team modeling hypothesis  hypothesis used case
correctly reect true state agents  despite scout s success
detect failure case  diagnosis procedures fail provide correct diagnosis  the
diagnosis successful two failure cases   phenomenon repeats
empirical results provide below 

diagnosis failed whenever hypothesis chosen

incorrect  although sucient detection 

intend explore ways improve

accuracy hypotheses future work  therefore address issue
paper anymore  failure detection capabilities signicant improvement
themselves  since agents know certainty failure occurred  even
diagnosis incorrect 
many social physical failures successfully captured using team coherence
heuristic monitoring selectivity  fact  permutations example    matter
one agents monitor  failures maintain relationship  i e   physical
failures except one team remains agreement  detected reliably 
although sometimes diagnosis failed 

result especially surprising considering

single agent monitoring  previous monitoring methods  condition monitors
communications  unable detect failures  despite used three
agents  
tables     present empirical results  basis example   

table  

presents failure permutations example   format table    normal or 

fly flight plan
wait at point  w  plan 

der execution plans follows  agents jointly execute
 f  plan detect way point  switch

two attackers land scout continues ahead identify enemy 

   

firobust agent teams via socially attentive monitoring

failures part agents detect way point  thus switch


w

plan 

case

 

actual executing plans

relationship failure

physical

 

attacker a 

attacker a 

scout a 

occurred

failure

 

w

w

w

 

 

 

f

w

w

 

a  vision fails

 

w

f

w

 

a  vision fails

 

f

f

w

 

a   a  vision fails

 

w

w

f

 

a  vision fails

 

f

w

f

 

a   a  vision fails

 

w

f

f

 

a   a  vision fails

 

f

f

f

 

a      vision fails

table    failure permutations undetected way point scenario  example    

case

 

a  s hypothesized executing plans

relationship failure

detection

attacker a 

attacker a 

scout a 

detected 

class

w

w

w

 

true negative

 

f

w

f

 

true positive

 

w

f

w

 

 

true positive

false negative
false negative

 

 
 

f
w

f
w

f
w

 

f

w

f

 

true positive

 

w

f

f

 

true positive

 

f

f

f

 

true negative

table    attacker s  a   monitoring results permutations example   

table   present monitoring results permutations example   



attacker a  monitoring team using maximally team coherent hypothesis
detecting failures  results show a  successful detecting teamwork failures
two  cases      highlighted bold face  
two false outcomes false negatives  cases  monitoring
attacker a  picked incorrect hypothesis scout  since scout s actions lead
ambiguous interpretations  scout forward  to scout enemy  detected
way point  plan

w    then would ying formationplan f  

use maximal team coherence heuristic causes a  prefer hypothesis
scout agreement attackers fact not  example  case    two
attackers failed detect way point executing

f  observing scout 
f w  however  believing

monitoring attacker a  sure whether scout executing
scout executing

f results maximally coherent

team modeling hypothesis  all

agents agreement   believing scout executing

   

w

results less

fikaminka tambe

coherent hypothesis  thus a  selects wrong hypothesis  case fails detect
teamwork failure 
maximal team coherence heuristic detect failures despite using incorrect hypotheses  unfortunately  hypotheses lead false negatives seen
table    however  none experiments resulted false positive result  i e   result
system detected failure reality none occurred  thus heuristic
provided sound results cases  able formally prove property holds
general maximal team coherence heuristic used 
first  address matter notation  let agent monitor agent b  
executing plan p  

denote  a  b  p   set agent modeling hypotheses

a s agent modeling component constructs based b  s observable behavior
execution p   words   a  b  p   a s set plans match b  s observable
behavior 

note monitors itself  direct access state

 a  a p  

 fp g  using modeling notation  make following denitions

ground assumptions underlying knowledge used monitoring 

denition   

agent modeling

given monitoring agent a  monitored agent b   say a s
agent b

complete

plan p may executed b  p  

 a  b p   

set  a  b p   typically include matching hypotheses besides correct
hypothesis p  guaranteed include p  following denition

individual

agent 

modeling completeness  dene group wide team modeling completeness 

denition   
a s

let agent monitoring team agents b      bn   say

team modeling

team

complete

a s agent modeling b      bn

complete 
denition   critical guarantee capabilities explore analytically
section next  generally holds use resl modsaf robocup
domains  make explicit service applications techniques
domains 
armed denitions  formalize failure detection capabilities suggested empirical evidence theorem   

theorem    let monitoring agent

monitor simple team   a s team modeling
complete  uses maximally team coherent hypothesis detection 
teamwork failure detection results sound 

proof 

show failure occurred  none detected  thus

failure detected fact failure  let a            agent members  
agent ai executing plan pi    n   thus collectively  group executing

 p            pn    failure occurred  agents executing plan

p   

i e    i  pi   p    since a s team modeling complete  correct hypothesis  p            p   
going set team modeling hypotheses h  

since maximally team 

coherent hypothesis  either selected  dierent hypothesis

coherence level



selected  hypothesis coherence level correct

one implies failure detected  thus detection procedure sound 

   

firobust agent teams via socially attentive monitoring

despite uncertainty knowledge used  sound failure detection guaranteed using
maximal team coherence heuristic 

one answer monitoring selectivity

problem  however  seen table    failures may pass undetected using
heuristic  i e   may result false negatives  
may therefore unfortunately

complete guaranteed

incomplete 

detection using maximal team coherence

may prefer monitoring system

detect teamwork failures 

incoherence

therefore experimented maximal team 

heuristic  inverse

maximal team coherence heuristic  heuristic prefers hypotheses suggest
failures  rather less 



table   gives monitoring attacker a  s view team 

incoherent

similar table    using maximally team 

hypothesis  shows indeed

using maximally team incoherent hypothesis lead false negative detections
cases      in contrast cases table    
case

relationship failure

detection

attacker a 

scout a 

detected 

 

class

 

w

attacker a 

false positive

 

f

h

w

 

true positive

 

w

f

f

 

true positive

f

f

w

 

true positive

 

a  s hypothesized executing plans

 
 

h

f

w

h

f

 

true positive

 

f

h

w

 

true positive

 

w

 

f

f

f

f

 

w

 

true positive

false positive

table    attacker s  a   monitoring results permutations example    using team 

incoherence 

guided results  formally show team incoherence heuristic leads
detection procedure

complete 

theorem    let monitoring agent monitor simple team   a s team modeling
complete  uses maximally team incoherent hypothesis detection 
teamwork failure detection results complete 
proof  analogous theorem    proof provided appendix a 
however  successes oset false positive outcomes cases     table   
cases  failures occurred  monitoring system falsely reported detected
failures  practice  may lead costly processing many false alarms 
ideally  detection capabilities sound



complete  unfortunately 

show coherence based disambiguation scheme exists results sound
complete detection  show theorem   provide sound complete detection 
disambiguation method inconsistent  given set possible matching
hypotheses  sometimes rank one hypothesis top  sometimes another 

theorem    let

h complete team modeling hypotheses set  modeling simple team 
exists disambiguation scheme     uses coherence alone basis

   

fikaminka tambe

disambiguation h       deterministic selection      results sound
complete failure detection 
proof 

let disambiguation scheme leads complete sound detection

uses knowledge coherence hypotheses selecting disambiguated hypothesis  suppose contradiction deterministic  thus consistent  selection
hypothesis h   i e   given h   set candidate hypotheses  applies
deterministic procedure choose one hypothesis based coherence 

since

use knowledge outside coherence candidate hypotheses  given
set candidates  always choose hypothesis 

let

monitoring agent using   let b monitored agent  whose actions identical
executing team plans p    p   
p     am   b  p   

 

thus  cannot determine whether b executing p 

 am   b  p   

 

fp    p  g  b executing p     s

h

 

f p    p    

hypotheses set

 p    p   g

since leads complete sound detection  choose  p    p     now 
b executing p  p    respectively  matching hypothesis set h dened

above  must select  p    p     since set candidate hypothesis h
used case  information supplied  must non deterministic
selection disambiguated hypothesis  contradicting assumption 
empirical analytical results show use single disambiguated hypothesis leads improved  imperfect  failure detection results  compared monitoring
conditions communications previously used  empirical results tables      
  establish benets teamwork monitoring technique  physical failures
detected  however  analytical results  theorems          show results less
perfect  algorithms either sound complete  both  complete monitoring  would require additional procedures dierentiate true positives
false ones  e g   focused communication  procedures often expensive 
reduce need costly verication letting go insistence single
hypothesis  focusing instead maintaining two hypotheses  maximally coherent hypothesis maximally incoherent hypothesis 

table   shows portion full set

team hypotheses available attacker a  monitoring team  total number
hypotheses presented table     many   co existing single case 
thus maintaining full set hypotheses would expensive  however  two inverse
heuristicsteam coherence incoherencerepresent two extremes space
hypotheses 

agree failure exists  failure actually occurred  since

team coherent hypothesis guarantees soundness  theorem     agree failure
exists  failure took place  since team incoherent hypothesis guarantees completeness  theorem     disagree  i e   team coherent hypothesis imply
failure  team incoherent hypothesis does   monitoring system cannot sure
either way  must revert back verication 
revised detection algorithm oers signicant computational savings compared
single team incoherent hypothesis approach  complete unsound  signicantly

   

firobust agent teams via socially attentive monitoring

case

 
 

 

 
 
 

 

 
 

a  s hypothesized executing plans

relationship failure

detection

scout a 

detected 

class

h

f

 

false positive

h

w

 

false positive

w

w

f

 

false positive

w

w

w

 

true negative

f

h

f

 

true positive

f

h

w

 

true positive

f

w

f

 

true positive

f

w

w

 

true positive

w

f

f

 

true positive

w

f

w

 

true positive

f

f

w

 

true positive

f

f

f

 

false negative

w

h

f

 

true positive

w

h

w

 

true positive

w

w

f

 

true positive

w

w

w

 

false negative

f

h

w

 

true positive

attacker a 

attacker a 

w
w

f

h

f

 

true positive

f

w

w

 

true positive

f

w

f

 

true positive

w

f

f

 

true positive

w

f

w

 

true positive

f

f

w

 

false positive

f

f

f

 

true negative

table    portion attacker s  a   monitoring hypotheses implied results
ranking used select single hypothesis case 

reduces need verication  since least team coherent hypothesis implies
failures  verication necessary  requires representing two hypotheses 
thus still computationally cheaper maintaining exponential number hypotheses 
example  using maximally team incoherent hypothesis permutations example
  results need verify eight cases seen      however  combine
hypothesis maximally team coherent hypothesis  e g   table    
need verify four        cases  cases            agreement
two hypotheses failure occurred  thus verication required 
monitoring agent therefore address monitoring selectivity problem balancing
resource usage guaranteed performance monitoring algorithm used 
either simpler single hypothesis algorithms would utilize one hypothesis
case  detection capabilities guaranteed sound complete  both 
complex algorithm  two hypotheses would reasoned case 

   

fikaminka tambe

algorithm would complete require verication fewer cases compared
simple hypothesis complete algorithm 

   monitoring selectivity distributed teamwork monitoring
section focuses monitoring selectivity exploiting key opportunity execution monitoring multi agent environmentsit monitored agents
distributed  monitoring agents distributed well  begin
simple scheme selecting single maximally team coherent hypothesis  since centralized
teamwork monitoring successful addressing permutations example    focus
permutations example    table     centralized teamwork monitoring
attacker resulted false negative detections  cases     table    
distributed teamwork monitoring scheme  single attacker monitor
teammates  scout  and attacker  engage monitoring  table
  presents monitoring results failure permutations  scout
monitoring agent 

nd scout successfully detects two failure cases

attacker failed detect  compensating attackers  monitoring mistakes  furthermore  since scout used maximal coherence heuristic  detection sound
verication required  reason scout s success attackers  actions
case  although ambiguous  support hypothesis matched
scout s plan  words  regardless plan attackers executing
two cases  dierent plan executed scout 
case

relationship failure

detection

detected 

class

w

 

true negative

f

 

true positive

f

w

 

true positive

f

w

 

true positive

h

h

f

 

true positive

f

h

f

 

true positive

 

h

f

f

 

true positive

 

f

f

f

 

true negative

 

a  s hypothesized executing plans
attacker a 

attacker a 

scout a 

 

w

w

 

f

w

 

w

 

f

 
 

table    scout s  a   monitoring results permutations example    using teamcoherence 

thus agents engaged monitoring permutations example    detection would
sound complete  actual failure cases  and those  would least one
team member detects failure  attempt formally dene general conditions
phenomenon holds 

denition   

say two team plans p    p   

observably dierent roles

r    r 

given agent b fullls roles r    r  two plans  resp   monitoring agent
 dierent b    a  b  p       a  b  p   

observably dierent roles p  p    call b

   

 

key agent 

  

say b

firobust agent teams via socially attentive monitoring

intuitively  b key agent observably dierent roles two plans
monitoring agent dierentiate b  s behavior executing p  executing
p    instance  attackers observably dierent roles

w

 in land  

f

 in y 

however  observably dierent roles

require land  scout observably dierent roles


h

w h 
w  ying 

 landing  

key agent basis conditions self monitoring team
detect failure agent using team coherence  rst prove lemma
conditions single given agent detect failure  use lemma
prove conditions least one agent given team detect failure 

lemma    suppose simple team

self monitoring  all members team monitor
other  using maximally team coherent heuristic  and assumption
agent  team modeling complete   let a    a  monitoring agents members
executing p    p    respectively  a  would detect failure maintaining teamwork
relationships agent a    a  key agent p    p   

proof 

see appendix a 

a  knows executing p   

a  executing p    key agent p  p   

a  guaranteed notice dierence exists a    since a 
acting observably dierent would executing p    note  however 
a  may may detect dierence  since a   s perspective  a   s behavior may

may explained p    a  detect dierence a   s roles p  p 
observably dierent  however  since a  detected failure  alert
teammates  diagnose failure  choose corrective action 
want guarantee teamwork failure always detected least
one agent  must make sure possible combination plans 
least one key agent whose roles observably dierent 

lemma shows

agents monitoring agent notice failure one occurs  aim  dene
observably partitioned set plans employed team 

denition   

set p team plans said

observably partitioned

two plans

pi   pj   p exists key agent aij   set aij agents called

set p  

key agents

instance  set team plans helicopter pilots team using
examples  fly flight plan  f  

wait at point  w   ordered halt  h   join scout
 j   observably partitioned  attackers land w h  f j  scout
lands j h  ies w f  table   shows agents observably dierent
roles two plans set  instance  nding cell intersection

h

row

w

column  nd scout observably dierent roles two

plans  indeed  scout lands command received halt execution  h   ies
scout enemy s position executing

w 

here  since agents observably 

dierent roles least two plans  key agents set  
teamattackers scout 

   

w   f   h  j  

includes members

fikaminka tambe

fly flight plan  f 

wait at point  w 

ordered halt  h 

 

attackers

attackers

scout

attackers

 

scout

scout attackers

f
w
h
j

join scout  j 

attackers

scout

 

attackers

scout

scout attackers

attackers

 

table    observable partitioning helicopter pilot team modsaf 

theorem    simple team     employs observably partitioned set team plans o 

team members monitor members key agents set o      using complete teammodeling     maximally team coherent hypotheses  teamwork failure detection
results sound complete 
proof 

theorem   know detection would sound  show complete 

prove least one agent detect dierence others whenever
team members executing plan  i e   failure occurring   suppose
team currently divided team plans must executed  i e   agents
ai   aj team executing team plans pi   pj   respectively  pi    pj  

thus failure occurred  let k key agents set   since team observablypartitioned  pi   pj exists least one key agent a    k   three cases 

case  i  

a  executing pi   case agent executing pj would detect dierence

a  would therefore detect failure  lemma    

case  ii  

a  executing pj   case agent executing pi would detect dierence

a  would therefore detect failure  lemma    

case  iii  

a  executing plan q  roles must observably dierent q

pi   q pj  or both   thus agent executing pj and or pi would detect
failure  case a   s roles observably dierent q pi



q

pj impossible  since monitoring agent
 am   a   pi      am   a   p j   fqg     

contradicting a  key agent pi   pj  
since three cases  least one agent would detect failure one occurred 
therefore  failure detection complete  since sound seen  detection
sound complete 
theorem shows distributed teamwork monitoring result

sound complete
key

failure detection  using simple algorithm  team member monitors

agents     using maximally team coherent

hypothesis  detects failure  certainly

one occurred  agent detects failure  indeed failure occurred 
simple distributed algorithm  attention focusing features guaranteed
soundness completeness contrasts complex centralized algorithm
discussed previous section  section     algorithm s eectiveness relies
   monitoring team member know key agents are  knows exist 
monitor team members  increases monitoring  sound complete failure detection
still guaranteed 

   

firobust agent teams via socially attentive monitoring

condition observably partitioned set plans  distribution monitoring 
corollary theorems     key agents available distributed
case  failure detection either sound complete  both  even key agents
available  centralized teamwork monitoring still complete sound 
fortunately  observable partitioning dicult property design  teams
often composed agents role plan  general 
roles observable dierences them  instance  helicopter pilot team
modsaf domain typically executes set plans property  table  
demonstrates 
team  however  observably partitioned  may case two agents
executing dierent plan  agent able detect using teamcoherence heuristic  minimal case occurs two agents  a  a 
executing plans p  p    respectively  p  p  observably dierent 

 a    a   p       a    a   p   

 

fp    p  g

result a  a  believing agreement them 
check situation made part plan design process  marking

points

risky

execution detection either sound complete  theorem    

verication  e g   communications  prescribed pro actively  or  check could
inserted protocol run time analysisthe agent would simulate other s
hypotheses matching actions  detect risky points dynamically 

   using socially attentive monitoring o line conguration
demonstrate generality socially attentive monitoring framework 
section examines re use teamwork monitoring domains diagnosis recovery
every failure infeasible execution  examples domains include team
sports  military human team training  volpe  cannon bowers    salas        
multi agent domains 

dynamic nature domain  hard real time deadlines 

complexity agents involved  e g   human team members  make diagnosis recovery
dicult 

even failure diagnosed  often late eective recovery 



environments  monitoring agent often concerned trends performance 
information important long term design evaluation analysis  need
necessarily calculated on line  results analysis meant feedback
agents  designer  coach supervisor  humans  
end  developing o line socially attentive monitoring system called
teamore  teamwork monitoring review   teamore currently uses execution traces

monitored agents perform monitoring  rather using plan recognition  thus
need worry uncertainty plan recognition  real time performance  instead  knows certainty agent s plans execution  teamore
accumulates several quantitative measures related teamwork  including average timeto agreement measure  ata  short   measure level agreement team 
build failure detection algorithm  aggregate failures quantitatively 
focus ata measure 

   

fikaminka tambe

teamore denes

switch

time interval beginning point team 

member  at least one  selects new team plan execution team  ending
point team agreement team plan executed 



perfect teamwork  team members select new team plan jointly  always remain
agreement 

realistic scenario  agents take longer switch 

initially teamwork failure occur  rst team member select new plan
disagreement teammates  either rejoins executing
original plan  join selecting new plan  switch begins detected
failure ends failures detected 
figure   shows illustration switch  three agents begin initial state
agreement joint execution plan    lled line   agent   rst agent switch
plan    dotted line   followed agent    nally agent   

switch

interval begins instance agents   selected plan    time three agents
regained agreement  but time plan    

switch
legend 
plan  

agent  

plan  
agent  
agent  
time
figure    illustration switch  three agents switch plan   plan   
teamore keeps track lengths time failures detected

resolved  ata measure average switch length  in time ticks  per complete
team run  e g   mission modsaf  game robocup   perfect team would
switches length zero  therefore ata    worst team would one
beginning task execution end it  would agree
team plan executed  instance  robocup game lasts      ticks 
worst possible team would one switch game  length       thus
ata scale robocup goes    perfect        worst  
used ata measure analyze series games two robocup simulationleague teams  isis    isis     marsella et al         xed opponent  andhill   
 andou        

games  varied use communications teams

evaluate design decisions use communications  approximately half games 
players allowed use communications service teamwork  half 
communications agents disabled  isis    played approximately    games
settings  isis    played    games communication settings 
table   shows mean ata values games  two sub teams  each
three members  isis    isis     ata values calculated separately subteam   rst column shows sub team results refer row  second

   

firobust agent teams via socially attentive monitoring

columns shows mean ata sub team  communications used 
third column shows mean ata communications used  next column shows
size ata reductionthe drop mean ata values communications
introduced 

last column shows probability null hypothesis two tailed

t test dierence ata means  probability dierence due
chance  thus smaller numbers indicate greater signicance 

isis

mean ata

mean ata

ata

t test prob 

sub team

comm 

comm 

reduction

null hypothesis

     

    

     

    e   

    goalies
    defenders

    

    

     

   e   

    goalies

     

    

    

    e   

    defenders

     

    

    

    e  

table    average time to agreement  ata  games andhill    

clearly  signicant dierence emerges communicating noncommunicating versions sub team 

ata values indicate sharing infor 

mation way communications signicantly decreases time takes team members
come agreement selected plan  result agrees intuitions
role communications  sense  may surprising 
however  ata reduction magnitudes indicate isis    may much less sensitive loss communications isis     dierences ata values isis   
approximately triple  nearly four times  great isis    

explanation

phenomenon isis    composed players improved capabilities monitoring environment  such better knowledge environment  

isis   

therefore dependent communications teams  isis     composed
players lesser environment monitoring capabilities  isis    players better able
select correct plan without relying teammates 

thus  would able

maintain level performance communications used  contrast 
isis    players rely passing information  monitoring other 
communications  took much longer establish agreement communications available 
validate hypothesis suggested ata measurements looking overall
team performance games  measured score dierence end game 
table    shows mean score dierence series games andhill    
rst column lists communications settings  with without  
third columns show

mean

second

score dierence games isis    isis    



bottom row summarizes results t tests run set games  determine
signicance level dierence mean score dierences  score dierence
results corroborate ata results  dierence mean score dierence indeed
statistically signicant isis    games  signicant isis    games  supports
explanation situationally aware isis    indeed better able handle
loss communications isis    

   

fikaminka tambe

isis   

isis   

communication used

     

     

communication used

     

     

t test p null hypothesis

p      

p     

table     isis    isis    mean score dierence andhill     changing communications settings

general lesson emerging experiments trade o exists addressing monitoring selectivity problem  knowledge maintained teammates
 here  via communications  traded  extent  knowledge maintained
environment 

designer therefore range alternative capabilities

choose agents  dierent domains may better facilitate implicit coordination monitoring environment  others require agents rely communications explicit
knowledge team members handle coordination 
ata results support additional conclusions  especially combined general
performance measure score dierence 

illustrate  consider plots

actual data games  figure   plots ata values four variants 
goalies sub team 

graph plots approximately    data points 

see figure

  communications used  isis    s ata values still generally better
isis    s ata without communications  thus  despite importance  individual situational
awareness able fully compensate lack communications 

average time agreement  ata 

  
  
  
  
  

  
  
  
  
 
isis   comm 

isis   comm 

isis   no comm  isis   no comm 

goalies sub team
 a  ata values goalies subteam

figure    ata values goalies sub teams games andhill    

   

firobust agent teams via socially attentive monitoring

teamore demonstrates reuse teamwork monitoring techniques developed

earlier sections o line conguration  designer isis    set agents
use communications  since signicant improvement score dierence 
contrast  without communications  isis    players able maintain
collaboration  thus communications takes precious resources  relatively safely
eliminated isis    agents  design  development eorts directed
components agents 

   beyond teamwork
presented general socially attentive monitoring framework detect failures
maintaining agreement joint team plans 

however  eective operation teams often

relies additional relationships  briey address section 

    richer agreement model  agreeing disagree
teamwork model requires joint execution team plans  service agreed upon
joint plans  agents may sometimes agree execute dierent sub plans individually  split
sub teams execute dierent sub team plans  two examples may serve illustrate 

example   

modsaf domain  helicopters engage enemy repeatedly following

masking    popping  unmask 

following three steps  hiding behind hill trees  

ing   

shooting missiles enemy  back hiding  variations

plan  required make sure two helicopters shooting time 
course  due limits communications  helicopters fail unmask time 

example   

robocup domain     players isis    isis     marsella

et al         divided four sub teams  mid elders  attackers  defenders  goalies
 the goalie two close defenders   division sub teams modeled agents

play team plan  see figure     mid elders
must select midfield plan  goalies must select defend goal plan  etc  again  ideally
attacker would never select plan attack  defender would select
plan defend  etc  however  due communication failures  players may sometimes
selecting one four team plans service

accidently abandon intended sub team  execute team plan another sub team 
 wingame 
 play 

 attack 
 simple
advance 
     
scoregoal

 flank
attack 
   
pass

 interrupt 
   

 defend 
      

 midfield 
           

 defendgoal 

 careful
defense 
intercept

kickout

 simplegoal
defense 
     
reposition

figure    portion plan hierarchy used isis robocup agents 

examples  certain dierences agents agreed upon
sign correct execution  failure  indeed  lack dierence selected plans

   

fikaminka tambe

would indicate failure cases  use term

mutual exclusion coordination

refer relationships  example    ideally two pilots executing
plan time 



shooting

example    two members dierent sub teams  e g  

attacker defender  executing plan service

play  e g   defend  



examples demonstrate  clear need monitoring mutual exclusion coordination 
results previous sections re used service socially attentive monitoring
mutual exclusion relationships  require transformation implementation
theory  hierarchies compared usual manner  except failures signied
equalities  rather dierences  instance  attacker staying team s
half eld  teammates may come suspect mistakenly defected
attackers  sub team believes defender 
analytical results inverted well  maximal team coherence heuristic
lead completeness  since prefers hypotheses contain equalities among agents 
failures mutual exclusion coordination  maximal team incoherence heuristic lead sound detection  prefers hypotheses imply equalities
occurred  properties proven formally 

theorem    let monitoring agent

monitor mutual exclusion relationships group
agents g  a s modeling g complete  uses maximally team incoherent
hypothesis detection  failure detection results sound 

proof 

provided appendix a 

theorem    let monitoring agent

monitor mutual exclusion relationships group
agents g  a s modeling g complete  uses maximally team coherent
hypothesis detection  failure detection results complete 
proof 



provided appendix a 

thus mutual exclusion relationships  teamwork relationships  guaranteed failuredetection results may still provided despite use limited  uncertain knowledge
monitored agents  centralized teamwork monitoring algorithms easily transformed monitoring mutual exclusion relationships  unfortunately  results
distributed case  theorem    cannot easily transformed  since rely
property observable partitioning  associated dierences  equalities 
leave issue future work 

    monitoring using role similarity relationships
section applies socially attentive monitoring role similarity relationships  monitoring individual performance within teams  particular  service team plans agents
may select individual sub plans  necessitate agreement team members 
constrained agents  roles 

fly flight plan

instance  service executing team plan

 figure    pilots individually select individual plans set

velocity heading within constraints formation ight method specied
mission 
role similarity relationships specify ways given individual plans similar 
extent 

two agents role executing dissimilar plans

   

firobust agent teams via socially attentive monitoring

considered violation role similarity relationships  enables sociallyattentive monitoring system detect failure role execution  monitor individual plans
agent executing  compares selection agents

role 

similarly method used teamwork  plans considered similar
role similarity relationship model  failure detected 

otherwise  failure may

occurred  diagnosis component called verify provide explanation 
let us illustrate failure modsaf domain system able
detect using role similarity relationship 

example   

team three helicopters take base head

mission  however  one pilot agents failed correctly process mission statement 
therefore kept helicopter hovering base  teammates left execute
mission themselves 
failures detected using role similarity relationship monitoring  agreed upon
team plan selected agents  problem teamwork relationship
detected  team plan involved agent selecting individual methods ight 
determine altitude velocity 

agents diered 

failing helicopter

remained hovering  teammates moved forward  using role similarity relationship 
failing helicopter compared selected plan teammate  who shared
role subordinate formation   realized plans dissimilar enough
announce possible failure 
unfortunately  actual similarity metrics seem domain  task specic 
thus easy re use across domains  furthermore  detected failures necessarily real failures  detected failures weight 

currently

investigating ways address challenging issues 

   related work
investigation socially attentive monitoring  relationship knowledge
maintained agents  states monitoring eectiveness builds research dierent subelds multi agent systems  address sub elds section  explain
investigation related existing literature 

    related work teamwork
previous work teamwork recognized monitoring agents critical teams 
past investigations raised monitoring selectivity problem  addressed
depth  building upon investigations  paper begins provide in depth
answers problem 
theory sharedplans  grosz   kraus              touches teamwork monitoring selectivity problem several ways  provides initial answers  first 
theory requires agents know teammates capable carrying tasks
team 

authors note agents must communicate enough plans

convince teammates ability carry actions  grosz   kraus       
p        second  theory requires agents mutual belief shared recipe 

   

fikaminka tambe

state requires agents reason innite recursion agent s beliefs 

un 

fortunately  attainment mutual belief undecidable theory  halpern   moses       
hence must approximated practice  jennings        rich   sidner        
approximations may still impose strong monitoring requirements  third  theory introduces
intention that construct service coordination helpful behavior  implying monitoring others  progress assess need behavior  grosz   kraus       
axiom a  a   

fourth  sharedplans requires intentions agent must con 

ict  grosz   kraus        axiom a    since intentions  in particular 
intentions that  may involve attitudes agents  monitoring others
detect avoid conicts implied  authors point theoretically
conicts detected  infeasible practice  grosz   kraus        p       
suggest conict detection prevention investigated problem specic manner
within minimal constraints  i e   monitoring capabilities  mutual belief  progress  lack
conicts  provided sharedplans framework  p           
joint intentions  levesque et al         cohen   levesque        requires agent
privately comes believe joint goal either achieved  unachievable  irrelevant 
must commit entire team mutually believe case  theory
sharedplans  joint intentions  use mutual belief approximated practice 
imposes strong monitoring requirements  thus  monitoring selectivity problem
raised practical implementations joint intentions 
jennings hypothesized two central constructs cooperative multi agent coordination

commitments

made agents 

conventions  rules used monitor

commitments  jennings         conventions used decide information needs
monitored agents  monitored  instance  convention may
require agent report teammates changes privately detects respect
attainability team goal 

jennings raises monitoring selectivity problem

provides example specic conventions high  low bandwidth situations
knowledge communicated agents bandwidth available 
however  jennings explore in depth question conventions selected  trade os guarantees associated selection particular
conventions  instance  guarantees eects using low bandwidth
convention example 
theoretical investigations described raise monitoring selectivity problem  implicitly explicitly   work builds upon address problem depth 
context socially attentive monitoring teams  paper reports soundness
and or completeness properties teamwork relationship failure detection analytically guaranteed  despite uncertainty knowledge acquired monitored agents 
analytical guarantees applicable plan recognition communications 
corroborated empirical results 
building theoretical work  practical teamwork systems include  jennings        rich
  sidner         tambe        

jennings  investigation joint responsibility

teamwork model grate   jennings        builds joint intentions  similarly
implementation  requires agents agree team plans execute 
however  grate  used industrial settings foolproof communications
assumed  jennings        p 

      thus passive monitoring  via communica 

   

firobust agent teams via socially attentive monitoring

tions  used  although jennings provides evaluation grate  s performance
respect communication delays  guarantees provided respect failure detection  grate  maintains knowledge agents acquaintances models 
used keep track team members  capabilities  in service forming
teams   however  question much knowledge used models
left unaddressed 
rich sidner investigate collagen collaborative user interface system 
communications reliable  rich   sidner         however  human usability
perspective  limiting amount communications still desirable 

address is 

sue  recent empirical work lesh  sidner rich        utilizes plan recognition
collagen  focus work using collaborative settings make
plan recognition tractable 

instance  ambiguities plan recognition may resolved

asking user clarication  work collagen investigate much
knowledge maintained eective collaborative dialogue user  contrast 
able provide guarantees failure detection results algorithms  also 
analysizing dialogue plans

risky points

may allow systems collagen

decide whether use communications clarication regardless plan recognition ambiguity 
steam  tambe        maintains limited information ability team members
carry roles  steam allows team members reason explicitly
cost communication deciding whether communicate not  work signicantly
extends capabilities via plan recognition  provides analytically guaranteed faultdetection results  furthermore  teamwork failure detection capabilities useful
trigger steam s re planning capabilities 

    related work coordination
huber        investigated use probabilistic plan recognition service active teamwork monitoring  motivated unreliability costs passive communications based
monitoring military applications  washington explores observation based coordination using markov models  washington         focusing making computations tractable 
contrast huber washington  work focuses monitoring selectivity problem 
showed strengths limitations centralized distributed approaches guaranteed failure detection results using coherence based disambiguation plan recognition
hypotheses 
durfee        discusses various methods reducing amount knowledge agents
need consider coordinating others  methods discussed involve pruning parts
nested models  using communications  using hierarchies abstractions  etc 
focus work methods modeling limited  focus
work question much modeling required guaranteed performancethe
monitoring selectivity problem  provide analytical guarantees trade os involved
using limited knowledge agents failure detection purposes 
sugawara lesser        report use comparative reasoning analysis techniques service learning specializing coordination rules system distributed agents coordinate diagnosing faulty network  investigation focused

   

fikaminka tambe

optimizing coordination rules minimize ineciency redundancy agent s coordinating messages  upon detecting sub optimal coordination  via fault model   agents
exchange information local views system problem solving activity 
construct global view  compare local view global view nd
critical values attributes missing local view therefore gave rise
sub optimal performance problem  values attributes used constructing
situation specic rules optimize coordination particular situations 

example 

network diagnosis agents may learn rule guides choose coordination strategy one agent performs diagnosis shares result rest
diagnosis agents  work socially attentive monitoring similarly uses comparison
agents views drive monitoring process  however  use comparison
product relationship monitoring 

sugawara lesser s work

viewed letting agents incrementally optimize monitoring requirements 
results analytically explore level monitoring required eective failure detection 
dierent congurations  teamwork monitoring technique addresses uncertainty
acquired information  construct global view attributes systemas
would extremely expensive  instead  technique focuses triggering failure detection via contrasting plans  incrementally expanding search dierences
diagnosis process 
robotics literature raised monitoring selectivity problem 

parker       

investigated monitoring selectivity problem dierent perspective  formationmaintenance task  empirically examined eects combining socially attentive information  which referred local  knowledge team s goals  concludes
fault tolerant strategy one agents monitor well
progress towards goals 

kuniyoshi et al 

 kuniyoshi  rougeaux  ishii  kita  sakane 

  kakikura        present framework cooperation observations  robots
visually attend others prerequisite coordination  framework presents several
standard attentional templates  i e   monitors whom  dene team attentional
structure one agents monitor other 

work focuses mon 

itoring selectivity problem within socially attentive monitoring teamwork relationships 
provides analytical well empirical results  treat attentional templates
product relationships hold system  results show monitoring
teams may necessarily require monitoring team members 

    related work
horling et al 

 horling  lesser  vincent  bazzan    xuan        present distributed

diagnosis system multi agent intelligent home environment the system uses faultmodels identify failures ineciencies components  guide recovery  schroeder
wagner        proposed distributed diagnosis technique cooperating agents
receive requests tests diagnoses  send responses agents 



construct global diagnosis based local ones produce receivewith
assumption conicts occur 

frohlich nejdl        investigates scheme

multiple diagnosis agents cooperate via blackboard architecture diagnosing
physical system  agents may use dierent diagnosis models systems  centralized

   

firobust agent teams via socially attentive monitoring

conict resolution agent employed handle conicts diagnoses found  three
approaches address monitoring selectivity problem 
social measures related ata  goldberg mataric        in 

interference amount time robots
social entropy  bailey        measure be 

vestigate multi robot foraging task measure
spend avoiding other  balch        uses

havioral diversity

multi agent tasks soccer  foraging  formation maintenance 

investigations focus characterizing heterogeneity multi agent systems relation
performance  contrast  focus work providing useful feedback
designer 

possible correlation task performance ata values remains

investigated 

   conclusions future work
work presented paper motivated practical concerns  begun
investigation monitoring selectivity problem result observation failures
continue occur despite agents  use monitoring conditions communications 
analysis failures revealed agents suciently informed other s
state  need monitor one s teammates recognized repeatedly past
 jennings        grosz   kraus        tambe         monitoring selectivity problem
question much monitoring requiredremained largely unaddressed  jennings 
      grosz   kraus        
provide key answers monitoring selectivity problem 

within context

socially attentive monitoring teams  demonstrate teamwork relationship failures
detected eectively even uncertain  limited  knowledge team members  states 
show analytically centralized active teamwork monitoring provides failure detection
either complete unsound  sound incomplete  however  centralized teamwork monitoring requires multiple hypotheses monitoring team members 



contrast  distributed active teamwork monitoring results complete sound failuredetection  despite using simpler algorithm monitoring key agents team 
using implemented general framework socially attentive monitoring  empirically validate results modsaf domain  provide initial results monitoring mutual exclusion role similarity relationships  initial diagnosis procedures 
demonstrate generality framework applying robocup
domain  show useful quantitative analysis generated o line 
modsaf robocup dynamic  complex  multi agent domains involve many uncertainties perception action 
attempted demonstrate results techniques applied
domains 

explicitly pointed necessary conditions theorems hold 

observable partitioning team modeling completeness  presented diagnosis
algorithm sensitive accuracy knowledge used  may require assuming
plans recognized soon selected  conditions veried
designer target application domain  reactive plans  our chosen representation 
commonly used many dynamic multi agent domains  focus monitoring agreements
joint plans stems centrality similar notions agreement agent human
teamwork literature  jennings        grosz   kraus        volpe et al         tambe        

   

fikaminka tambe

made several references additional areas would conduct
investigations 

one important topic plan investigate depth strong

requirements distributed teamwork monitoring algorithm terms observability 
order provide soundness completeness guarantees  distributed algorithm relies
ability team members monitor key agents  investigating ways
relax requirement still providing guaranteed results  addition  diagnosis
procedures extended formalized  would investigate ways
alleviate sensitivity procedures choice team modeling hypothesis 

acknowledgments
article partially based aaai    paper  kaminka   tambe        
agents    paper  kaminka   tambe        authors  research supported part nsf grant isi          part afosr contract  f                thank je rickel  george bekey  victor lesser  dan o leary  david pynadath
many useful comments  anonymous reviewers thanks helping us crystallize ideas contributions revisions paper 

appendix a  proofs
theorem        page       let monitoring agent monitor simple team   a s
team modeling complete  uses maximally team coherent hypothesis detection  teamwork failure detection results sound 
proof 

show failure occurs detected  thus failures

detected  let a            agent members   agent ai executing
plan pi    n  

thus collectively  group executing  p            pn   

failure

occurred  two agents ak   aj     j  k n aj executing plan
pj ak executing plan pk pj    pk  

since a s team modeling complete 

correct hypothesis  p            pj           pk         pn   set team modeling hypotheses 
since choose maximally team incoherent hypothesis  either choose correct
hypothesis  incoherent hypothesis implying failure occurred 
select hypothesis greater incoherence hypothesis  or equivalent level  
case  failure would detected  detection procedure complete 

lemma    

   page       suppose simple team self monitoring  all members
team monitor other  using maximally team coherent heuristic  and
assumption agent  team modeling complete   monitoring agent a 
member executing p  would detect failure maintaining teamwork relationships
agent a   also member   executing dierent plan p    a  observably
dierent role p  p   

proof 

a  knows executing p   

since members monitor

themselves  a  monitoring a    observably dierent role p  p    since a 
executing p    following observably dierent role  p   
   a    a   p     therefore
perspective a    cannot case assigns p 
hypothesis  therefore

team modeling

agent modeling

hypothesis a  a  executing

   

firobust agent teams via socially attentive monitoring

p    a  executing plan p    words  a   s perspective

team coherent hypothesis  dierence would detected a  a   

theorem        page       let monitoring agent monitor mutual exclusion relation 

ships group agents g  a s modeling g complete  uses maximally
team incoherent hypothesis detection  failure detection results sound 
proof 

show failure occurred  none detected  thus

failure detected fact failure 
g 

let a            agent members

agent ai executing plan pi    n   thus collectively  group

executing  p            pn    failure occurred  agent executing dierent
plan  i    j   pi    pj    since a s group modeling complete  correct hypothesis
going set group modeling hypotheses h   since maximally incoherent
hypothesis  either selected  dierent hypothesis

level

selected 

coherence

hypothesis coherence level correct one

implies failure detected  thus detection procedure sound 

theorem        page       let monitoring agent monitor mutual exclusion relation 

ships group agents g  a s modeling g complete  uses maximally
team coherent hypothesis detection  failure detection results complete 
proof 

show failure occurs detected  thus procedure

complete  let a            agent members g  agent ai executing
plan pi    n  

thus collectively  group executing  p            pn   

failure

occurred  two agents ak   aj     j  k n aj executing plan
pj ak executing plan pk pj

 

pk  

since a s group modeling complete 

correct hypothesis  p            pj           pk         pn   set group modeling hypotheses 
since choose maximally team coherent hypothesis  either choose correct
hypothesis  coherent hypothesis implying failure occurred 
select hypothesis greater coherence hypothesis  or equivalent level  
case  failure would detected  therefore  detection procedure complete 

appendix b  socially attentive monitoring algorithms
bring algorithms  in pseudo code  resl plan recognition algorithm 
comparison test supporting detection simple non simple teams 
monitoring algorithms centralized distributed cases 

b   resl
resl works rst expanding complete operator hierarchy agents modeled  tagging plans non matching  plans  preconditions termination conditions
agged non matching well  plans  actions set used expectations
behavior  initializing plan recognition hierarchy monitored agent  observations agent continuously matched actions expected plans 
plans whose expectations match observations tagged matching  ags
propagated along hierarchy  down  complete paths hierarchy

   

fikaminka tambe

agged matching not  paths specify possible matching interpretations
observations  addition  precondition termination conditions agged true
not  signifying inferred appropriate belief modeled agents 

process

described algorithm   

algorithm   resl s main loop  matching

observation making inferences given

plan recognition hierarchy  a single agent  
  

get observations agent

  

plan set expected observations 
 a  compare observations expectations
 b  succeed  ag plan matching successfully  otherwise ag plan failing match

  

plan agged matching successfully
 a  flag parents matching successfully    propagate matching

  

plan whose children  all them  agged failing match
 a  flag failing match    propagate non matching

b   detection failure  centralized distributed teamwork monitoring
algorithm   shows comparison hierarchical plans carried out  limit
simple teams  algorithm accepts input two sets hierarchical plan hypotheses  two associated agents  for clarity  algorithms assume two agents 
generalization n agents straightforward   algorithm accepts policy ag 

policy 



optimistic

policy causes algorithm use maximal team coherence

provide sound  incomplete detection 

pessimistic policy causes algorithm use

maximal team incoherence provide complete  unsound detection 

hierarchy   hierarchy    two agents
agent    algorithm makes use predicate sub team 
true two agents  agent   agent   belong dierent sub teams given
level hierarchy  depth  
set hierarchical plans marked

marked

agent  



aid algorithm    dene centralized distributed failure detection algorithms 

centralized teamwork monitoring algorithm  algorithm   

utilizes algorithm   twice  checking failures

pessimistic



optimistic

policies  results policies agree  certain  results agree 
 i e  

pessimistic

policy causes failure detected 

optimistic

policy

causes failure detected   monitoring agent cannot certain failure
taken place  therefore needs verify failure 

algorithm   therefore returns

failure  no failure  possible failure 
distributed monitoring algorithm given pseudo code form 
nothing call algorithm  

   

optimistic

policy parameter  power

firobust agent teams via socially attentive monitoring

algorithm   hierarchical comparison two agents  allowing sub teams 
  

set depth     

  

plans depth depth team plans
 a 

look top most dierence rst

policy    optimistic
i  let plan    plan   maximally team coherent plans level depth
hierarchy   hierarchy    respectively 
ii  else let plan    plan   maximally team incoherent plans level depth
hierarchy   hierarchy    respectively 

 b 

plan   equal plan  
i  return failure
ii  else bottom hierarchies reached  return no failure  otherwise increase depth go   

  

one plan team plan  return failure  else return no failure 

algorithm   centralized teamwork monitoring  applying optimistic pessimistic
views 
  

  

let optimistic result   detect agent    agent    hierarchies   
hierarchies    optimistic 
   algorithm     
let pessimistic result   detect agent    agent    hierarchies   
hierarchies    pessimistic 
   algorithm     

  

optimistic result    pessimistic result

  

return optimistic result   

  

else return possible failure

either

   

failure 



no failure   

fikaminka tambe

derived fact members team using monitor key agents
team 

references
ambros ingerson  j  a     steel  s          intergrating planning  execution monitoring 


proceedings seventh national conference articial intelligence  aaai    

minneapolis st  paul  mn  aaai press 
andou  t          renement soccer agents  positions using reinforcement learning 
kitano  h   ed   

robocup     robot soccer world cup    vol  lnai       pp         

springer verlag 
atkins  e  m   durfee  e  h     shin  k  g          detecting reacting unplanned 

proceedings fourteenth national conference articial
intelligence  aaai      pp         providence  ri  aaai press 
world states 

bailey  k  d         
balch  t         

social entropy theory 

state university new york press 

behavioral diversity learning robot teams 

ph d  thesis  georgia

institute technology 
calder  r  b   smith  j  e   courtemanche  a  j   mar  j  m  f     ceranowicz  a  z         

modsaf behavior simulation control  proceedings third conference
computer generated forces behavioral reresentation orlando  florida  institute
simulation training  university central florida 

cohen  p  r   amant  r  s     hart  d  m         

early warnings plan failure  false

positives  envelopes  experiments model 

tech  rep  cmpsci technical

report        university massachusetts 
cohen  p  r     levesque  h  j          teamwork 

nous     

doyle  r  j   atkinson  d  j     doshi  r  s          generating perception requests
expectations verify execution plans 



conference articial intelligence  aaai     
durfee  e  h         

blissful ignorance 

proceedings fifth national

knowing enough coordinate well 



proceedings first international conference multiagent systems  icmas     
pp         

fenster  m   kraus  s     rosenschein  j  s         

coordination without communica 

proceedings first
international conference multiagent systems  icmas      pp         california 
tion  experimental validation focal point techniques 
usa 

firby  r  j          investigation reactive planning complex domains 

ceedings sixth national conference articial intelligence  aaai     
   

pro 

firobust agent teams via socially attentive monitoring

frohlich  p     nejdl  w          resolving conicts distributed diagnosis  wahlster 
w   ed   

  th europeach conference articial intelligence  ecai     

john

wiley   sons  inc 
goldberg  d     mataric  m  j         

interference tool designing evaluat 

proceedings fourteenth national conference
articial intelligence  aaai      pp         providence  ri  aaai press 
ing multi robot controllers 

grosz  b  j     kraus  s          evolution sharedplans  wooldridge  m     rao 
a   eds   

foundations theories rational agency  pp         

grosz  b  j     kraus  s          collaborative plans complex group actions 

intelligence             

articial

grosz  b  j     sidner  c  l          plans discourse  cohen  p  r   morgan  j    
pollack  m   eds   

intentions communication  pp          mit press  cambridge 

ma 
halpern  j  y     moses  y          knowledge common knowledge distributed
environment 

distributed computing                 

hamscher  w   console  l     de kleer  j   eds           

nosis 

readings model based diag 

morgan kaufmann publishers  san mateo  ca 

horling  b   lesser  v  r   vincent  r   bazzan  a     xuan  p         

diagnosis

integral part multi agent adaptability  tech  rep  cmpsci technical report         university massachusetts amherst 
huber  m  j     durfee  e  h         

acting together  without communication 



working notes aaai spring symposium representing mental states
mechanisms  pp       stanford  ca 

jennings  n  r          commitments conventions  foundations coordination
multi agent systems 

knowledge engineering review                

jennings  n  r          controlling cooperative problem solving industrial multi agent
systems using joint intentions 

articial intelligence                 

johnson  w  l     rickel  j          steve  animated pedagogical agent procedural
training virtual environments 

sigart bulletin                

kaminka  g  a     tambe  m          what s wrong us  improving robustness

proceedings fifteenth national conference articial
intelligence  aaai      pp        madison  wi  aaai press 
social diagnosis 

kaminka  g  a     tambe  m         

i m ok  you re ok  we re ok  experiments

distributed centralized social monitoring diagnosis 



proceedings

third international conference autonomous agents  agents     seattle  wa  acm
press 

   

fikaminka tambe

kinny  d   ljungberg  m   rao  a   sonenberg  e   tidhar  g     werner  e          planned
team activity 

castelfranchi  c     werner  e   eds   

articial social systems 

lecture notes ai      pp          springer verlag  new york 

kitano  h   tambe  m   stone  p   veloso  m   coradeschi  s   osawa  e   matsubara  h  

proceedings international joint conference articial intelligence  ijcai    

noda  i     asada  m          robocup synthetic agent challenge     
nagoya  japan 

kraus  s   sycara  k     evenchik  a          reacing agreements negotiations 
logical model implementation 

articial intelligence                 

kuniyoshi  y   rougeaux  s   ishii  m   kita  n   sakane  s     kakikura  m          cooperation observation framework basic task patterns 

international conference robotics automation 

ieee

pp         san diego  ca 

ieee computer society press 
lesh  n   rich  c     sidner  c  l          using plan recognition human computer col 

proceedings seventh international conference user modelling
 um     ban  canada 
laboration 

levesque  h  j   cohen  p  r     nunes  j  h  t          acting together 

eigth national conference articial intelligence  aaai    

proceedings

menlo park 

ca  aaai press 
malone  t  w     crowston  k         
tion 

toward interdisciplinary theory coordina 

tech  rep  ccs tr     ss wp          msa  massachusetts institute

technology 
marsella  s  c   adibi  j   al onaizan  y   kaminka  g  a   muslea  i   tallis  m     tambe 
m         

teammate 

experiences acquired design robocup

proceedings third international conference autonomous agents
 agents     seattle  wa  acm press 

teams  

newell  a         

unied theories cognition 

harvard university press  cambridge 

massachusetts 

proceedings
ieee robotics automation conference  pp         atlanta  ga 

parker  l  e          designing control laws cooperative agent teams 

rao  a  s          means end plan recognition towards theory reactive recognition 

proceedings international conference knowledge representation reasoning  kr      pp         

reece  g  a     tate  a          synthesizing protection monitors causal structure 


proceedings articial intelligence planning systems  aips     chicago  il 

rich  c     sidner  c  l         

collagen  agents collaborate people 

johnson  w  l   ed    proceedings first international conference autonomous agents  agents      pp         marina del rey  ca  acm press 

   

firobust agent teams via socially attentive monitoring

proceedings
first international conference autonomous agents  agents      pp        

schroeder  m     wagner  g          distributed diagnosis vivid agents 
marina del rey  ca  acm press 

sugawara  t     lesser  v  r          learning improve coordinated actions cooperative
distributed problem solving environments 

machine learning                   

tambe  m          tracking dynamic team activity 

ence articial intelligence  aaai  

tambe  m          towards exible teamwork 

         

proceedings national confer 

journal articial intelligence research 

tambe  m   johnson  w  l   jones  r   koss  f   laird  j  e   rosenbloom  p  s     schwamb 
k         

       

intelligent agents interactive simulation environments 

ai magazine 

proceedings
fourteenth national conference articial intelligence  aaai      pp     provi 

toyama  k     hager  g  d          rst don t succeed    
dence  ri 

veloso  m   pollack  m  e     cox  m  t          rationale based monitoring planning
dynamic environments 

 aips     pittsburgh  pa 

proceedings articial intelligence planning systems

volpe  c  e   cannon bowers  j  a     salas  e          impact cross training
team functioning  empirical investigation 

human factors                

markov tracking agent coordination  proceedings
second international conference autonomous agents  agents      pp       min 

washington  r         

neapolis st  paul  mn  acm press 

   


