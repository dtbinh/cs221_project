journal of artificial intelligence research                  

submitted        published     

an application of reinforcement learning to dialogue
strategy selection in a spoken dialogue system for email
marilyn a  walker

walker research att com

at t shannon laboratory
    park ave   bldg      room e   
florham park  nj      

abstract

this paper describes a novel method by which a spoken dialogue system can learn
to choose an optimal dialogue strategy from its experience interacting with human users 
the method is based on a combination of reinforcement learning and performance modeling of spoken dialogue systems  the reinforcement learning component applies q learning
 watkins         while the performance modeling component applies the paradise evaluation framework  walker et al         to learn the performance function  reward  used
in reinforcement learning  we illustrate the method with a spoken dialogue system named
elvis  email voice interactive system   that supports access to email over the phone  we
conduct a set of experiments for training an optimal dialogue strategy on a corpus of    
dialogues in which human users interact with elvis over the phone  we then test that
strategy on a corpus of    dialogues  we show that elvis can learn to optimize its strategy
selection for agent initiative  for reading messages  and for summarizing email folders 

   introduction
in the past several years  it has become possible to build spoken dialogue systems that can
communicate with humans over the telephone in real time  systems exist for tasks such as
finding a good restaurant nearby  reading your email  perusing the classified advertisements
about cars for sale  or making travel arrangements  seneff  zue  polifroni  pao  hetherington  goddeau    glass        baggia  castagneri    danieli        sanderman  sturm 
den os  boves    cremers        walker  fromer    narayanan         these systems are
some of the few realized examples of real time  goal oriented interactions between humans
and computers  yet in spite of    years of research on algorithms for dialogue management in task oriented dialogue systems   carbonell        winograd        simmons  
slocum        bruce        power        walker        allen        cohen        pollack 
hirschberg    webber        grosz        woods        finin  joshi    webber       
carberry        moore   paris        smith   hipp        kamm        inter alia  the
design of the dialogue manager in real time  implemented systems is still more of an art
than a science  sparck jones   galliers         this paper describes a novel method  and
experiments that validate the method  by which a spoken dialogue system can learn from
its experience with human users to optimize its choice of dialogue strategy 
the dialogue manager of a spoken dialogue system processes the user s utterance and
then chooses in real time what information to communicate to the human user and how to
communicate it  the choice it makes is called its strategy  the dialogue manager can be
naturally formulated as a state machine  where the state of the dialogue is defined by a set
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fiwalker

of state variables representing observations of the user s conversational behavior  the results
of accessing various information databases  and aspects of the dialogue history  transitions
between states are driven by the system s dialogue strategy  in a typical system  there are
a large number of potential strategy choices at each state of a dialogue 
for example  consider one choice faced by elvis  email voice interactive system  a
spoken dialogue system that supports access to a user s email by phone  elvis provides
verbal summaries of a user s email folders  but there are many ways to summarize a folder
 sparck jones               a summary could consist of a simple statement about the
number of messages in different folders  e g   you have   new messages  or it could provide
much more detail about the messages in a particular folder  e g   in your messages from
kim  you have one message about a meeting  and a second about interviewing antonio 
elvis must decide which of many properties of a message to mention  such as the message s
status  its sender  or the subject of the message  
decision theoretic planning can be applied to the problem of choosing among dialogue
strategies  by associating a utility u with each strategy  action  choice and by positing
that spoken dialogue systems should adhere to the maximum expected utility principle
 keeney   raiffa        russell   norvig        

maximum expected utility principle  an optimal action is one that maximizes the expected utility of outcome states 

thus  elvis can act optimally by choosing a strategy a in state si that maximizes u  si   
this formulation however simply leaves us with the problem of how to derive the utility
values u  si   for each dialogue state si   several reinforcement learning algorithms based on
dynamic programming specify a way to calculate u  si   in terms of the utility of a successor
state sj  bellman        watkins        sutton        barto  bradtke    singh         so
if the utility for the final state of the dialogue were known  it would be possible to calculate
the utilities for all the earlier states  and thus determine a policy which selects only optimal
dialogue strategies 
previous work suggested that it should be possible to treat dialogue strategy selection as
a stochastic optimization problem in this way  walker        biermann   long        levin 
pieraccini    eckert        mellish  knott  oberlander    o donnell         however in
 walker         we argued that the lack of a performance function for assigning a utility
to the final state of a dialogue was a critical methodological limitation  there seemed to
be three main possibilities for a simple reward function  user satisfaction  task completion 
or some measure of user effort such as elapsed time for the dialogue or the number of
user turns  but it appeared that any of these simple reward functions on their own fail
to capture essential aspects of the system s performance  for example  the level of user
effort to complete a dialogue task is system  domain and task dependent  moreover  high
levels of effort  e g   the requirement that users confirm the system s understanding of each
utterance  do not necessarily lead to concomitant increases in task completion  but do
   all of the strategies implemented in elvis are summarized in figure    note that due to practical
constraints  we have only implemented strategy choices in a subset of states  and that elvis uses a fixed
strategy in other states  in section    we describe in detail the strategy choices that elvis explores in
addition to choices about summarization  namely choices among strategies for controlling the dialogue
initiative and for reading multiple messages 

   

fireinforcement learning in the elvis system

lead to significant decreases in user satisfaction  shriberg  wade    price        danieli  
gerbino        kamm        baggia et al          furthermore  user satisfaction alone fails
to reect the fact that the system will not be successful unless it helps the user complete
a task  we concluded that the relationship between these measures is both interesting
and complex and that a method for deriving an appropriate performance function was
a necessary precursor to applying stochastic optimization algorithms to spoken dialogue
systems  in  walker  litman  kamm    abella      a   we proposed the paradise method
for learning a performance function from a corpus of human computer dialogues 
in this work  we apply the paradise model to learn a performance function for elvis 
which we then use for calculating the utility of the final state of a dialogue in experiments
applying reinforcement learning to elvis s selection of dialogue strategies  section   describes the implementation of a version of elvis that randomly explores alternate strategies
for initiative  for reading messages  and for summarizing email folders  section   describes
the experimental design in which we first use this exploratory version of elvis to collect
a training corpus of conversations with    human users carrying out a set of three email
tasks  section   describes how we apply reinforcement learning to the corpus of     dialogues to optimize elvis s dialogue strategy decisions  we then test the optimized policy
in an experiment in which six new users interact with elvis to complete the same set of
tasks  and show that the learned policy performs significantly better than the exploratory
policy used during the training phase 

   elvis spoken dialogue system
we started the process of designing elvis by conducting a wizard of oz experiment in
which we recorded dialogues with six people accessing their email remotely by talking to
a human who was playing the part of the spoken dialogue system  the purpose of this
experiment was to identify the basic functionality that should be implemented in elvis 
the analysis of the resulting dialogues suggested that elvis needed to support contentbased access to email messages by specification of the subject or the sender field  verbal
summaries of email folders  reading the body of an email message  and requests for help
and repetition of messages  walker et al       b        
given these requirements  we then implemented elvis using a general purpose platform
for spoken dialogue systems  kamm et al          the platform consists of a dialogue
manager  described in detail in section       a speech recognizer  an audio server for both
voice recordings and text to speech  tts   an interface between the computer running
elvis and the telephone network  and modules for specifying the rules for spoken language
understanding and application specific functions 
the speech recognizer is a speaker independent hidden markov model  hmm  system 
with context dependent phone models for telephone speech  and constrained grammars
defining the vocabulary that is permitted at any point in a dialogue  rabiner  juang   
lee         the platform supports barge in  so that the user can interrupt the system 
barge in is very important for this application so that the user can interrupt the system
when it is reading a long email message 
the audio server can switch between voice recordings and text to speech  tts  and
integrate voice recordings with tts  the tts technology is concatenative diphone synthe   

fiwalker

sis  sproat   olive         elvis uses only tts since it would not be possible to pre record 
and then concatenate  all the words necessary for realizing the content of email messages 
the spoken language understanding  slu  module consists of a set of rules for specifying
the vocabulary and allowable utterances  and an associated set of rules for translating the
user s utterance into a domain specific semantic representation of its meaning  the syntactic
rules are converted into an fsm network that is used directly by the speech recognizer
 mohri  pereira    riley         the semantic rule that is associated with each syntactic
rule maps the user s utterance directly to an application specific template consisting of an
application function name and its arguments  these templates are then converted directly to
application specific function calls specified in the application module  the understanding
module also supports dynamic grammar generation and loading because the recognizer
vocabulary must change during the interaction  e g   to support selection of email messages
by content fields such as sender and subject 
the application module provides application specific functions  e g   functions for accessing message attributes such as subject and sender  and functions for making these realizable
as speech so that they can be used to instantiate variables in spoken language generation 

    elvis s dialogue manager and strategies

 s dialogue manager is based on a state machine where one or more dialogue strategies
can be explored in each state  the state of the dialogue manager is defined by a set of
state variables representing various items of information that the dialogue manager uses
in deciding what to do next  the state variables encode various observations of the user s
conversational behavior  such as the results of processing the user s speech with the spoken
language understanding  slu  module  and results from accessing information databases
relevant to the application  as well as certain aspects of the dialogue history  a dialogue
strategy is a specification of what the system should say  in elvis this is represented as a
template with variables that must be instantiated by the current context  in some states the
system always executes the same dialogue strategy and in other states alternate strategies
are explored  all of the strategies implemented in elvis are summarized in figure    a
complete specification of which dialogue strategy should be executed in each state is called
a policy for a dialogue system 
to develop a version of elvis that supported exploring a number of possible policies 
we implemented several different choices in particular states of the system  our goal was to
implement strategy choices in states where the optimal strategy was not obvious a priori 
for the purpose of illustrating the dialogue strategies we explored  consider a situation in
which the user is attempting to execute the following task  one of the tasks used in the
experimental data collection described in section    
elvis

 task      you are working at home in the morning and plan to go directly to a meeting

when you go into work  kim said she would send you a message telling you where
and when the meeting is  find out the meeting time and the meeting place 

to complete this task  the user needs to find a message from kim about a meeting in
her inbox and listen to it  there are many possible strategies that elvis could use to help
the user accomplish this task  below  we first describe the dialogue strategies from figure  
   

fireinforcement learning in the elvis system

strategy type
initiative
summarization

choices
explored 
yes
yes

reading

yes

request info

no

provide info
help

no
no

timeout

no

rejection

no

strategy choices
system initiative  si   mixed initiative  mi 
summarizeboth  sb   summarizesystem  ss  
summarizechoiceprompt  scp 
read first  rf   read summary only  rso  
read choice prompt  rcp 
askusername  ask which selection  askws  
ask selection criteria  asksc  
read message
askusername help  si top help  mi top help 
read message help  askws help  asksc help
askusername timeout 
read timeout 
si top timeout  mi top timeout  read messagetimeout  askws timeout  asksc timeout
askusername reject 
sitop reject  mi top reject  askws reject  askscreject  read message reject

figure    elvis s dialogue strategies  elvis explores choices in initiative  summarization
and read strategies and uses fixed strategies elsewhere 
that elvis makes choices among  then describe in detail the complete state machine  the
dialogue strategies from figure   that are used in states where there is no choice among
dialogue strategies  and the space of policies that elvis can execute  we provide several
detailed examples of dialogues that can be generated by elvis s dialogue manager s state
machine 
      strategy choices in elvis

one strategy choice in our experiments involved the exploration of two different strategies
for managing the dialogue initiative  system initiative and mixed initiative  in the implementation of elvis tested here  the choice of initiative was made early in the dialogue and
the same style of initiative was then used throughout the dialogue whenever there could
have been a choice between the two in order to avoid confusing the user 
previous research suggested that the system initiative strategy in figure   in which
elvis is directive with the user might be the best strategy  given the current state of the
art in speech recognition  kamm         in figure    each of elvis s utterances is labelled
with the name of the dialogue strategy that elvis is using to produce the utterance  e g  
utterance e  is labelled si top  the name for the system initiative top level strategy  the
choice of the system initiative strategy also affects utterances e  and e   in these utterances
elvis continues the dialogue by requesting particular items of information  in general  the
system initiative strategy constrains what the user can say at each point in the dialogue 
by requesting particular items of information one at a time  and the user is constrained to
only providing the information that has been asked for  the reason why this strategy is
recommended given the current state of the art in speech recognition is that it guides the
   

fiwalker

e   hi  elvis here   you have   new or unread messages in your
inbox  say read  summarize  or say help for more options 
u   read 
e   select by sender  subject or in order of arrival 
u   sender 
e   which sender 
u   kim 
e   in the messages from kim  there s   message about  interviewing
antonio  and   message about  meeting today   the first message is
titled   interviewing antonio   it says   i d like to interview him  i
could also go along to lunch  kim  
u   next 
e   this is a message about meeting today  it says the meeting this
morning is at       in  d     see you there  kim 
u   i m done here 

si top
ask which selection
ask selection criterion
read first  rf 

read message

figure    system initiative  si  dialogue strategy  elvis explicitly prompts the user with
what to say at each point of the dialogue  elvis s utterances are labelled with
the strategy names 
user into saying things that the system is more likely to understand  and the recognizer
vocabulary at each state is constrained to responses to the question that is asked  this
strategy might be dispreferred by users however  because it could be tedious for the user to
be constrained to providing one item of information at a time  in the dialogue in figure   
it takes four user utterances to access the message from kim needed to complete task     
other research suggested that a better strategy is a mixed initiative strategy that allows
the user to take the initiative except when the user fails to say anything or the system is
having trouble understanding the user  smith   hipp        levin  pieraccini  eckert 
fabbrizio    narayanan        webber   joshi        walker   whittaker         the
dialogue in figure   illustrates the mixed initiative dialogue strategy  each of elvis s
utterances in figure   is labelled with the name of the dialogue strategy that elvis is using
to produce the utterance  e g   utterance e  is labelled mi top  the name for the mixedinitiative top level strategy  note that unlike the si top strategy  the mi top strategy
does not volunteer information and does not tell the user what she can say  instead  the
mixed initiative strategy allows the user to take control of the dialogue and specify exactly
what she wants to do in a single utterance  as in utterance u  in figure    however 
if there is evidence that the user is having trouble or is confused  as when the user says
nothing in utterance u   the mixed initiative strategy will take the initiative to ask the
user for information or tell the user what she can say  in utterance e  in figure   the
read timeout strategy is triggered by the fact that the user s response was delayed longer
than a pre set timeout threshhold  and the system tells the user what actions are available
at this point in the dialogue  in general  the mixed initiative strategy can support more
ecient dialogues  in the dialogue in figure    it takes two user utterances to access the
message from kim needed to complete task      however this eciency gain may be offset
by the increased likelihood of misunderstandings and user confusion 
   

fireinforcement learning in the elvis system

e   hi  elvis here  i ve got your mail 
u   read me my messages from kim 
e   in the messages from kim  there s   message about  interviewing
antonio  and   message about  meeting today   the first message is
titled   interviewing antonio   it says   i d like to interview him  i could
also go along to lunch  kim  
u    user says nothing within   seconds so the system takes the initiative 
e   you can say repeat  to repeat the last message  or you can say next 
to read the next message in this folder  you can say  i m done here to
exit this folder 
u   next message 
e   this is a message about meeting today  it says the meeting this
morning is at       in  d     see you there  kim 
u   i m done here 

mi top
read first  rf 

read timeout
readmessage

figure    mixed initiative  mi  dialogue strategy  elvis leaves it up to the user to take
the initiative  unless the user seems to be having trouble with the system
summarize strategy
summarize both  sb 

summarize system  ss 
summarize choice prompt
 scp 

example prompt
in your top level inbox  from kim  there s   message about
 lunch   from michael  there s   message about  evaluation
group meeting   from noah  there s   message about  call me
tomorrow  and   message about  interviewing antonio   and
from owen  there s   message about  agent personality  
in your top level inbox  there s   message from kim    messages
from noah    message from michael  and   message from owen 
e  summarize by subject  by sender  or both 
u  subject 
e  in your top level inbox  there s   message about  lunch    
message about  interviewing antonio     message about  call
me tomorrow     message about  evaluation group meeting  
and   message about  agent personality  

figure    alternate summarization strategies in response to a request to  summarize my
messages 
a different type of strategy choice involves elvis s decisions about how to present information to the user  we mentioned above that there are many different ways to summarize a
set of items that the user wants information about  elvis explores the set of alternate summarization strategies illustrated in figure    these strategies vary the message attributes
that are included in a summary of the messages in the current folder  the summarize both
strategy  sb  uses both the sender and the subject attributes in the summary  when employing the summarize system strategy  ss   elvis summarizes by subject or by sender
based on the current context  for instance  if the user is in the top level inbox  elvis will
summarize by sender  but if the user is situated in a folder containing messages from a par   

fiwalker

ticular sender  elvis will summarize by subject  as a summary by sender would provide no
new information  the summarize choice prompt  scp  strategy asks the user to specify
which of the relevant attributes to summarize by  see figure   
another type of information presentation choice occurs when a request from the user
to read some subset of messages  e g   read my messages from kim  results in multiple
matching messages  the strategies explored in elvis are summarized in figure    one
choice is the read first strategy  rf  which involves summarizing all the messages from
kim  and then taking the initiative to read the first one  elvis used this read strategy
in the dialogues in figures   and    an alternate strategy for reading multiple matching
messages is the read summary only  rso  strategy  where elvis provides information
that allows users to refine their selection criteria  another strategy for reading multiple
messages is the read choice prompt  rcp  strategy  where elvis explicitly tells the user
what to say in order to refine the message selection criteria  see figure   
read strategy
read first  rf 
read summary only
 rso 
read choice prompt
 rcp 

example prompt
in the messages from kim  there s   message about  interviewing antonio  and   message about  meeting today   the first message is
titled   interviewing antonio   it says   i d like to interview him  i
could also go along to lunch  kim  
in the messages from kim  there s   message about  interviewing antonio  and   message about  meeting today  
in the messages from kim  there s   message about  interviewing antonio  and   message about  meeting today   to hear the messages 
say   interviewing antonio  or  meeting  

figure    alternate read strategies in response to a request to  read my messages from
kim 
the remainder of elvis s dialogue strategies  as summarized in figure    are fixed  i e 
multiple versions of these strategies are not explored in the experiments presented here 
      elvis s dialogue state machine

as mentioned above  a dialogue strategy is a choice the system makes  in a particular
state  about what to say and how to say it  a policy for a dialogue system is a complete
specification of which strategy to execute in each system state  a state is defined by a set
of state variables  ideally  the state representation corresponds to a dialogue model that
summarizes the dialogue history compactly  but retains all the relevant information about
the dialogue interaction so far  the notion of a dialogue model retaining all the relevant
information is more formally known in reinforcement learning as a state representation that
satisfies the markov property  a state representation satisfying the markov property is one
in which the probability of being in a particular state s with a particular reward r after
doing some action a in a prior state can be estimated as a function of the action and the
prior state  and not as a function of the complete dialogue history  sutton   barto        
more precisely 
pr st     s   rt     rjst   at     pr st     s    rt     rjst  at   rt   st     at     rt           r   s    a   
   

fireinforcement learning in the elvis system

for all s    r  st and at  
the markov property is guaranteed if the state representation encodes everything that
the system has been able to observe about everything that happened in the dialogue so far 
however  this representation would be too complex to estimate a model of the probability
of various state transitions  and systems as complex as spoken dialogue system must in
general utilize state representations which are as compact as possible   however if the state
representation is too impoverished  the system will lose too much relevant information to
work well 
operations variable
knowusername
initstrat
summstrat
readstrat
taskprogress
currentusergoal
nummatches
whichselection
knowselectioncriteria
confidence
timeout
help
cancel

abbrev
 u 
 i 
 s 
 r 
 p 
 g 
 m 
 w 
 sc 
 c 
 t 
 h 
 l 

possible values
   
  si mi
  ss scp sb
  rf rso rcp
     
  read summarize
    n  
  sender  snd  subject  sub  inorder  ino 
   
   
   
   
   

figure    operations variables and possible values that define the operations vector for
controlling all aspects of elvis s behavior  the abbreviations for the variable
names and values are used as column headers for the operations variables in
figures      and   
 s state space representation must obviously discriminate among states in which
various strategy choices are explored  but in addition  there must be state variables to
capture distinctions between a number of states in which elvis always executes the same
strategy  the state variables that elvis keeps track of and their possible values are given in
figure    the knowusername  u  variable keeps track of whether elvis knows the user s
name or not  the initstrat  i   summstrat  s  and readstrat  r  variables keep track of
whether elvis has already employed a particular initiative strategy  summarize strategy
or a reading strategy in the current dialogue  and if so  which strategy it has selected 
this variable is needed because once elvis employs one of these strategies  that strategy is
used consistently throughout the rest of the dialogue in order to avoid confusing the user 
the taskprogress  p  variable tracks how much progress the user has made completing the
experimental task  the currentusergoal  g  variable corresponds to the system s belief
elvis

   in some respects this is driven by implementation requirements since system development and maintenance is impossible without compact state representations 

   

fiwalker

u
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

operations variables
action choices
i s
r p g
m w sc c t h l
   
     
 
            askusername
   
     
 
            si top  mi top
si  
     
 
            si top help
si  
     
 
            si top reject
si  
    s
 
            ss sb scp
si  
    r
 
            askws
si  
    r
 
            askws reject
si  
    r
  snd           asksc
si  
    r
  snd           asksc timeout
si  
    r n   snd           rf rso rcp
si   rcp   r
  snd           readmessage
si   rcp    
 
            si top
mi  
     
 
            mi top help
mi  
     
 
            mi top reject
mi  
    s
 
            ss sb scp
mi ss
    r n   snd           rf rso rcp
mi ss rf   r
  snd           readmessage

figure    a portion of elvis s operations state machine using the full operations vector
to control elvis s behavior
about what the user s current goal is  the whichselection  w  variable tracks whether
the system knows what type of selection criteria the user would like to use to read her
messages  the knowselectioncriteria  sc  variable tracks whether the system believes
it understood either a sender name or a subject name to use to select messages  the
nummatches  m  variable keeps track of how many messages match the user s selection
criteria  the confidence  c  variable is a threshholded variable indicating whether the
speech recognizer s confidence that it understood what the user said was above a pre set
threshhold  the timeout  t  variable represents the system s belief that the user didn t
say anything in the allotted time  the help  h  variable represents the system s belief that
the user said help  and leads to the system providing context specific help messages  the
cancel  l  variable represents the system s belief that the user said cancel  which leads
to the system resetting the state to the state before the last user utterance was processed 
thus there are         possible states used to control the operation of the system  although
not all of the states occur  
in order for the reader to achieve a better understanding of the range of elvis s capabilities and the way the operations vector is used  figure   shows a portion of elvis s state
machine that can generate the sample system and mixed initiative dialogue interactions
in figures   and    each of these figures provides the state representation and the strategy choices made in each state of the sample dialogues  for example  row two of figure
  shows that after the system acquires the user s name  knowusername  u       with
high confidence  confidence  c        that it can explore the system initiative  si top  or
   for example until the system knows the user name  none of the other variable values change from their
initial value 

   

fireinforcement learning in the elvis system

mixed initiative  mi top  strategies  figure   illustrates a dialogue in which the si strategy
was chosen while figure   illustrates a dialogue in which the mi top strategy was chosen 
here we discuss in detail how the dialogue in figure   was generated by the state machine
in figure   
in figure    the first row shows that elvis s strategy askusername is executed in
the initial state of the dialogue where all the operations variables are set to    elvis s
utterance e  is the surface realization of this strategy s execution  note that according to
the state machine in figure    there are no other strategy choices for the initial state of
the dialogue  the user responds with her name and the slu module returns the user s
name to the dialogue manager with high confidence  confidence  c        the dialogue
manager updates the operations variables with knowusername u      and confidence  c 
     as shown in row two of figure    now  according to the state machine in figure   
there are two choices of strategy  the system initiative strategy whose initial action is si top
and the mixed initiative strategy whose initial action is mi top  figure   illustrates one
potential path when the si top strategy is chosen  elvis s utterance e  is the realization
of the si top strategy  the user responds with the utterance help which is processed by
slu  and the dialogue manager receives as input the information that slu believes that
the user said help  help  h       with high confidence  confidence  c        the dialogue
manager updates the operations variables to reect the information from slu as well as
the fact that it executed the system initiative strategy  initstrat  i    si   this results in
the operations vector shown adjacent to elvis s utterance e   the third row of the state
machine in figure   shows that in this state  elvis has no choice of strategies  so elvis
simply executes the si top help strategy  which is realized as utterance e   the user
responds by saying read  utterance u   and the dialogue manager updates the operations
variables with the results of the slu module saying that it believes that the user said read
 goal  g    r  with high confidence  confidence  c        the state machine in figure  
specifies that in this state elvis should execute the askwhichselection  askws  strategy 
which corresponds to elvis s utterance e  in figure    this time  however  when the user
responds to the system s query with the word sender  utterance u    the slu module
is not confident of its understanding  confidence  c       and the operations variable is
updated with this confidence value  according to the state machine in figure    the strategy
that elvis executes in this state is the askws reject strategy  a specific rejection strategy
designed to be executed in the context of a goal to acquire the value of the whichselection
operations variable  see the list of operations variables in figure     the realization of
the askws reject strategy is utterance e   the user responds by saying sender again
 utterance u   and this time the slu module understands the user s utterance with high
confidence  the dialogue manager updates the whichselection  w  variable with snd and
the confidence variable  resulting in the operations vector shown adjacent to utterance
e   the state machine in figure   specifies that in this state elvis should execute the
askselectioncriterion  asksc  strategy which is realized as utterance e   the user says
nothing  utterance u   and the slu module detects a silence above a pre set timeout
threshhold with high confidence  the dialogue manager updates the operations variables
to reect this observation  timeout  t       confidence  c        the state machine in
figure   specifies that the asksc timeout strategy should be executed in this state  this is a
context specific strategy that re attempts the system s initial goal by providing information
   

fiwalker

operations variables

utterance

u i
   

s r
   

p
 

g
 

m w
   

sc c t
 
   

 

 

 

 

 

 

 

 

 

 

 

 

si

 

 

 

 

 

 

 

 

 

 

si

 

 

 

r

 

 

 

 

 

 

si

 

 

 

r

 

 

 

 

 

 

si

 

 

 

r

 

snd

 

 

 

 

si

 

 

 

r

 

snd

 

 

 

 

si

 

 

 

r

n

snd

 

 

 

 

si

 

rcp

 

r

 

snd

 

 

 

 

si

 

rcp

 

 

 

 

 

 

 

h l
    e   hi  elvis here  who is
that 
u   susan 
    e   hi susan  please wait 
i ll get your mail     seconds  
okay susan  you have   new
or unread messages in your inbox  say read  summarize or
say help for more options 
u   help 
    e   to access your messages 
you can say read or summarize 
to switch the active messages 
say new messages  or all messages  if you want me to repeat
a message or a summary  say repeat  you can always say cancel
or help  say goodbye elvis  to
hang up 
u   read 
    e   select by sender  by subject
or in order of arrival 
u   sender
    e   i didn t understand you  do
you want to select messages by
sender  subject or in order of
arrival 
u   sender
    e   which sender 
u    user says nothing 
    e   the senders are  kim 
noah  michael  and owen 
which sender do you want 
u   kim 
    e   in the messages from kim 
there s   message about  interviewing antonio  and   message about  meeting today   to
hear the messages  say   interviewing antonio  or  meeting  
u   meeting 
    e   this is a message about
meeting today  it says the meeting this morning is at       in
 d     see you there  kim 
u   i m done here 
    e    you are back to your
toplevel inbox  say read  summarize or say help for more
options 

strategy
name
askusername
si top

si top help

askws
askwsreject
asksc
asksctimeout
rcp

readmessage

si top

figure    a system initiative dialogue  completing task     in figure     illustrating
elvis s ability to provide help  and use timeout and confidence information
that is intended to help the user and then re asking the original query  as realized by
utterance e   the user responds with the name of the sender  utterance u   which is
understood by slu with high confidence  knowselectioncriteria  sc       confidence  
   

fireinforcement learning in the elvis system

    when elvis retrieves messages from the mail server matching this selection criteria 
multiple matches are found  nummatches   n  as per the list of operations variables in
figure     this time row ten of the state machine in figure   specifies that this state
has a choice of dialogue strategies  namely a choice between the read first  rf   readsummary only  rso  and read choice prompt  rcp  strategies illustrated in figure   
elvis randomly chooses to explore the rcp strategy  which is realized as utterance e  
the information the user needs to complete task     is then provided by utterance e  after
the user responds in utterance u  by saying meeting  and slu understands this with high
confidence   the row with utterance e  in figure   shows the updated operations vector
reecting the fact that the system executed the rcp strategy  the readstrat  r  variable
is used to enforce the fact that in this implementation of elvis  once a particular reading 
strategy is selected  it is then used consistently throughout the dialogue to avoid confusing
the user  in the last exchange of figure    the slu module s confident understanding of
the user s utterance in u   i m done here  results in resetting the g m w  and sc variables
and the dialogue manager also updates the variable taskprog  p  to   to reect progress on
the experimental task  figure   shows that  in this state  the system has only one strategy 
since the initstrat variable has been set to si  the system executes the si top strategy  as
realized in this context by utterance e   
the dialogue in figure   illustrates a potential dialogue with elvis when the mi top
strategy is selected rather than the si top strategy after the user name is acquired  the
reader may also track the path of this dialogue by utilizing the state machine in figure   
note that the operations vector that elvis utilizes is needed to make elvis a fully operational system that provides all the functionality equired to support users  the dialogues
in figures   and   also show how elvis provides 

 context specific help strategies  illustrated by the strategies si top help and mitop help  and supported by the help variable 

 timeout strategies  that the system uses for taking the initiative in each context  trig 

gered by the delay for the user s response going above a time threshhold  as illustrated
by the strategy asksc timeout  and supported by the timeout variable 

 rejection strategies  backoff dialogue actions that become more directive to the user
when the asr returns a confidence value lower than its confidence threshhold  as
illustrated by strategies askws reject and mi top reject  and supported by the
confidence variable 

however  the operations vector state representation needed to control the operation of
the system is not necessarily required or even optimal for applying reinforcement learning
 barto et al         sutton   barto         sometimes it may be advantageous to aggregrate states for the purpose of applying reinforcement learning  even if it is not possible
to guarantee that the state representation obeys the markov property  sutton   barto 
       note that in many of the states defined in figure   alternate strategies are not
explored  for example  the confidence variable is used by the system to determine whether
it should apply a backoff rejection strategy  but we do not vary the rejection strategies  the
incentive for aggregrating states by ignoring state variables that are irrelevant to learning
   

fiwalker

operations variables

utterance

u i
   

s
 

r
 

p g
   

m w
   

sc c
 
 

t
 

h l
   

 

 

 

 

 

 

 

 

 

 

 

 

 

e   hi  elvis here  who is askusername
that 
u   susan 
e   hi susan  please wait  i ll
get your mail  delay of about   
seconds  

 

mi  

 

 

 

 

 

 

 

 

 

 

 

mi  

 

 

 

 

 

 

 

 

 

 

 

mi  

 

 

s

 

 

 

 

 

 

 

 

mi ss

 

 

r

n

snd

 

 

 

 

 

 

mi ss

rf

 

r

 

snd

 

 

 

 

 

strategy
name

okay susan  i ve got your mail 
u   help 
e   you can read or summarize messages using values from
the sender or the subject field 
for example  you can say  read
the message from lee about the
meeting  or  read my messages
from kim  or  summarize my
messages  to access messages in
the current folder  you can also
say next  previous  first  or last 
if you want me to repeat a message or a summary  say repeat 
you can always say cancel or
help  to exit the current folder
say  i m done here  to hangup 
say  goodbye elvis  
u   summarize my messages 
e   i didn t understand you 
what do you want to do with
your messages 
u   summarize them 
e   in your top level inbox 
there s   messages from kim 
  message from noah    message from michael  and   message from owen 
u   read my messages from
kim
e   in the messages from kim 
there s one message about interviewing antonio and one message about meeting today  the
first message says  user barges
in 
u   next message
e   next message  this is a
message about meeting today  it
says the meeting this morning is
at       in  d     see you there 
kim 

mi top
mi top help

mi topreject
ss

rf

readmessage

figure    a mixed initiative dialogue completing task     in figure     illustrating elvis s
ability to provide help  and use timeout and confidence information
is a reduction in the state space size  this means that fewer dialogue samples are needed to
collect a large enough sample of state action pairs for the purpose of applying reinforcement
learning  from this perspective  our goal is to aggregrate the state space in such a way as
to only distinguish states where different dialogue strategies are explored 
   

fireinforcement learning in the elvis system

however  there is an additional constraint on state aggregration  reinforcement learning 
backs up rewards received in the final states of the dialogue sf to earlier states si where
strategy choices were explored  however the algorithm can only distinguish strategy choices
when the trajectory between si and sf are distinct for each strategy choice  in other words 
if two actions at some point lead to the same state  then without local reward  the q values
of these two actions will be equal 
username  u  init  i  taskprog  p  usergoal  g 
   
  si mi       
  r s
figure     reinforcement learning state variables and values
figure    specifies the subset of the state variables given in figure   that we developed to represent the state space for the purpose of applying reinforcement learning  the
combination of these state variables is very compact  but provides distinct trajectories for
different strategy choices  the reduced state space has only    states  but supports dialogue
optimization over a policy space of                  different policies  all of the policies
are prima facie candidates for optimal policies in that they can all support human users in
completing a set of experimental email tasks 

   experimental design
experimental dialogues for both the training and testing phase were collected via experiments in which human users interacted with elvis to complete three representative application tasks that required them to access email messages in three different email inboxes 
we collected data from    users performing three tasks      dialogues  for training elvis 
and then tested the learned policy against a corpus from six users performing the same
three tasks     dialogues  
instructions to the users were given on a set of web pages  with one page for each experimental dialogue  the web page for each dialogue also contained a brief general description
of the functionality of the system  a list of hints for talking to the system  a description of
the tasks that the user was supposed to complete  and information on how to call elvis 
each page also contained a form for specifying information acquired from elvis during the
dialogue  and a survey  to be filled out after task completion  designed to probe the user s
satisfaction with elvis  users read the instructions in their oces before calling elvis
from their oce phone 
each of the three calls to elvis was made in sequence  and each conversation consisted
of two task scenarios where the system and the user exchanged information about criteria
for selecting messages and information within the message  the tasks are given in figure
    where  e g   task     and task     were done in the same conversation with elvis  the
motivation for asking the caller to complete multiple tasks in a call was to create subdialogue
structure in the experimental dialogues  litman        grosz   sidner        
   when applied without local rewards 

   

fiwalker











task      you are working at home in the morning and plan to go directly to a meeting when
you go into work  kim said she would send you a message telling you where and when the
meeting is  find out the meeting time and the meeting place 
task      the second task involves finding information in a different message  yesterday
evening  you had told lee you might want to call him this morning  lee said he would send
you a message telling you where to reach him  find out lee s phone number 
task      when you got into work  you went directly to a meeting  since some people were
late  you ve decided to call elvis to check your mail to see what other meetings may have
been scheduled  find out the day  place and time of any scheduled meetings 
task      the second task involves finding information in a different message  find out if you
need to call anyone  if so  find out the number to call 
task      you are expecting a message telling you when the discourse discussion group can
meet  find out the place and time of the meeting 
task      the second task involves finding information in a different message  your secretary
has taken a phone call for you and left you a message  find out who called and where you
can reach them 

figure     sample task scenarios





dialogue eciency metrics  elapsed time  system turns  user turns
dialogue quality metrics mean recognition score  timeouts  rejections  helps  cancels 

bargeins  timeout   rejection   help   cancel   bargein 
task success metrics  task completion as per survey
user satisfaction  the sum of tts performance  asr performance  task ease  interaction
pace  user expertise  system response  expected behavior  comparable interface  future
use 

figure     metrics collected for spoken dialogues 
we collect a number of of different measures for each dialogue via four different methods 
    all of the dialogues are recorded      the dialogue manager logs each state that the
system enters and the dialogue strategy that elvis selects in that state      the dialogue
manager logs information for calculating a number of dialogue quality and dialogue eciency
metrics summarized in figure    and described in more detail below  and     at the end
of the dialogue  users fill out web page forms to support the calculation of task success and
user satisfaction measures  we explain below how we use these measures in the paradise
framework and in reinforcement learning 
   

fireinforcement learning in the elvis system

the dialogue eciency metrics were calculated from the dialogue recordings and the
system logs  the length of the recording was used to calculate the elapsed time in seconds
 et  from the beginning to the end of the interaction  measures for the number of system
turns  and the number of user turns  were calculated on the basis of the system logging
everything it said and everything it heard the user say 
the dialogue quality measures were derived from the recordings  the system logs and
hand labeling  a number of system behaviors that affect the quality of the resulting dialogue
were automatically logged  these included the number of timeout prompts  timeouts 
played when the user didn t respond as quickly as expected  the number of recognizer
rejections  rejects  where the system s confidence in its understanding was low and it said
something like i m sorry i didn t understand you  user behaviors that the system perceived
that might affect the dialogue quality were also logged  these included the number of times
the system played one of its context specific help messages because it believed that the
user had said help  helps   and the number of times the system reset the context and
returned to an earlier state because it believed that the user had said cancel  cancels  
the recordings were used to check whether users barged in on system utterances  and these
were labeled on a per state basis  bargeins  
another measure of dialogue quality was recognizer performance over the whole dialogue 
calculated in terms of concept accuracy  the recording of the user s utterance was compared
with the logged recognition result to calculate a concept accuracy measure for each utterance
by hand  concept accuracy is a measure of semantic understanding by the system  rather
than word for word understanding  for example  the utterance read my messages from
kim contains two concepts  the read function  and the sender kim selection criterion  if the
system understood only that the user said read  then concept accuracy would be      mean
concept accuracy was then calculated over the whole dialogue and used  in conjunction with
asr rejections  to compute a mean recognition score  mrs  for the dialogue 
because our goal is to generate models of performance that will generalize across systems
and tasks  we also thought it important to introduce metrics that are likely to generalize 
all of the eciency metrics seemed unlikely to generalize since  e g   the elapsed time to
complete a task depends on how dicult the task is  other research suggested that the
dialogue quality metrics were more likely to generalize  litman  walker    kearns        
but we thought that the raw counts were likely to be task specific  thus we normalized the
dialogue quality metrics by dividing the raw counts by the total number of utterances in the
dialogue  this resulted in the timeout   rejection   help   cancel   and bargein 
metrics 
the web page forms are the basis for calculating task success and user satisfaction
measures  users reported their perceptions as to whether they had completed the task
 comp    they also had to provide objective evidence that they had in fact completed the
task by filling in a form with the information that they had acquired from elvis  
   yes no responses are converted to     
   this supports an alternative way of calculating task success objectively by using the kappa statistic
to compare the information that the users filled in with a key for the task  walker et al       a   however
some of our earlier results indicated that the user s perception of task success was a better predictor of
overall satisfaction  so here we simply use perceived task success as measured by comp 

   

fiwalker











was elvis easy to understand in this conversation   tts performance 
in this conversation  did elvis understand what you said   asr performance 
in this conversation  was it easy to find the message you wanted   task ease 
was the pace of interaction with elvis appropriate in this conversation   interaction pace 
in this conversation  did you know what you could say at each point of the dialogue   user
expertise 
how often was elvis sluggish and slow to reply to you in this conversation   system
response 
did elvis work the way you expected him to in this conversation   expected behavior 
in this conversation  how did elvis s voice interface compare to the touch tone interface to
voice mail   comparable interface 
from your current experience with using elvis to get your email  do you think you d use
elvis regularly to access your mail when you are away from your desk   future use 

figure     user satisfaction survey
in order to calculate user satisfaction  users were asked to evaluate the system s performance with the user satisfaction survey in figure     some of the question responses were
on a five point likert scale and some simply required yes  no or yes  no  maybe responses 
the survey questions probed a number of different aspects of the users  perceptions of their
interaction with elvis in order to focus the user on the task of rating the system  as in
 shriberg et al         jack  foster    stentiford        love  dutton  foster  jack   
stentiford         each multiple choice survey response was mapped into the range of   to
   then the values for all the responses were summed  resulting in a user satisfaction
measure for each dialogue with a possible range of   to    

   training and testing an optimized dialogue strategy
given the experimental training data  we first apply paradise to estimate a performance
function for elvis as a linear combination of the metrics described above  we apply the
performance function to each dialogue in the training corpus to estimate a utility for the
final state of the dialogue and then apply q learning using this utility  finally we test the
learned policy against a new population of users 

   

paradise

performance modeling

the first step in developing a performance model for spoken dialogue systems was the specification of the causal model of performance illustrated in figure     walker et al       a  
according to this model  the system s primary objective is to maximize user satisfaction 
   

fireinforcement learning in the elvis system

maximize user satisfaction

maximize task
success

minimize costs

efficiency
measures

figure    

qualitative
measures

 s structure of objectives for spoken dialogue performance 

paradise

task success and various costs that can be associated with the interaction are both contributors to user satisfaction  task success can be measured quantitatively in a number of
ways  it could be represented by a continuous variable representing quality of solution or
by a boolean variable representing binary task completion  dialogue costs are of two types 
dialogue eciency and quality  eciency costs are measures of the system s eciency in
helping the user complete the task  such as the number of utterances to completion of the
dialogue  dialogue quality costs are intended to capture other aspects of the system that
may have strong effects on user s perception of the system  such as the number of times the
user had to repeat an utterance in order to make the system understand the utterance 
given this model  a performance metric for a dialogue system can be estimated from
experimental data by applying multivariate linear regression with user satisfaction as the
dependent variable and task success  dialogue quality  and dialogue eciency measures as
independent variables   a stepwise linear regression on the training data over the measures
discussed above  showed that comp  mrs  bargein  and rejection  were significant
contributors to user satisfaction  accounting for     of the variance in r squared  f
              p          
performance        comp        mrs        bargein         rejection 
we tested how well this performance function should generalize to unseen test dialogues
with tenfold cross validation  by randomly sampling     of the training dialogues and
testing the goodness of fit of the performance model on the remaining     of the dialogues
   one advantage of this approach is that once the performance function is derived  it is no longer necessary
to collect user satisfaction reports from users  which opens up the possibility of estimating the reward
function from fully automatic measures  this latter possibility might also be useful for online calculation
of the reward function or for calculating a local reward 
   we normalize the metrics before doing the regression so that the magnitude of the coecients directly
indicates the contribution of that factor to user satisfaction  cohen        walker et al       a  

   

fiwalker

in the training set  the average r  for the training set was     with a standard error of
      while the average r  for the held out     of the dialogues was     with a standard
error of      since the average r  for the test set is statistically indistinguishable from the
training set  we assume that the performance model will generalize to new elvis dialogues 

    training an optimized policy

given the learned performance function described above  we apply this function to the
measures logged for each dialogue di   thereby replacing a range of measures with a single performance value pi   which is used as the utility  reward  for the final state of each
dialogue   we then apply reinforcement learning with pi as the utility of the final state
of the dialogue di  bellman        sutton        tesauro        russell   norvig       
watkins         the utility of doing action a in state si   u  a  si    its q value   can be
calculated in terms of the utility of a successor state sj   by obeying the recursive equation 
u  a  si     r a  si     mija max
u  a    sj  
a

x

 

j

where r a  si   is the immediate reward received for doing action a in si   a is a strategy
from a finite set of strategies a that are admissable in state si  and mija is the probability
of reaching state sj if strategy a is selected in state si   in the experiments reported here 
the reward associated with each state  r si    is zero  in addition  since reliable a priori
prediction of a user action in a particular state is not possible  for example the user may say
help or the speech recognizer may fail to understand the user   the state transition model
mija is estimated from the logged state strategy history for the dialogue 
the utility values can be estimated to within a desired threshold using value iteration 
which updates the estimate of u  a  si    based on updated utility estimates for neighboring
states  so that the equation above becomes 

un    a  si     r si   

xm
j

a
ij

max
un a    sj  
a
 

where un  a  si   is the utility estimate for doing a in state si after n iterations  sutton  
barto        pp       value iteration stops when the difference between un  a  si   and
un    a  si   is below a threshold  and utility values have been associated with states where
strategy selections were made    once value iteration is completed the optimal policy is
obtained by selecting the action with the maximal q value in each dialogue state 
figure    enumerates the subset of the states in the aggregrated state space used for
reinforcement learning and potential actions defining the policy space  the strategy with
the greatest q value in each state after training is indicated by boldface in figure    
this optimized policy will then be tested as a fixed policy in the operation of elvis  in
all the states of the task  the system initiative strategy in figure   is predicted to be the
optimal initiative strategy  and the read first strategy in figure   is predicted to have
the best performance of the read strategies  as figure    shows  the learned strategy
   each dialogue is treated as having a unique final state 
    after experimenting with various threshholds  we used a threshold of    of the performance range of
the dialogues 

   

fireinforcement learning in the elvis system

state variables
u i p g
       
       
  si   s
  si   r
  si    
  si   s
  si   r
  si    
  si   s
  si   r
  mi   s
  mi   r
  mi    
  mi   s
  mi   r
  mi    
  mi   s
  mi   r

strategy choices
askusername
si top  mi top
ss sb scp
rf rso rcp
si top
ss sb scp
rf rso rcp
si top
ss sb scp
rf rso rcp
ss sb scp
rf rso rcp
mi top
ss sb scp
rf rso rcp
mi top
ss sb scp
rf rso rcp

figure     the subset of the state space that defines the policy class explored in our experiments  the learned policy is indicated by boldface 
for summarization varies according to the state of the task  the different summarization
strategies were illustrated in figure    the policy that is learned is to use the summarizeboth strategy at the beginning of the dialogue  when taskprog       and then to switch to
using the summarize system strategy at later phases of the dialogue  this strategy makes
sense in terms of giving the user complete information about all the messages in her inbox
at the beginning of the dialogue 

    testing an optimized policy

we first constructed a deterministic version of elvis that implemented the learned policy as
discussed above  with one variation  the variation was based on the fact that the decision
on whether to use the summarize both or summarize system summarization strategy was
conditioned on the value of the taskprog variable  however  we intended to utilize the optimized version of the system in situations where we would not have access to the taskprog
variable  namely situations where the task that the user was attempting to perform were not
under the control of the experimenter  when we examined the q values for the summarization strategies over the course of the dialogue  we found that the summarize system strategy
had the greatest average q value  being strongly preferred to the summarize both strategy
except in the initial phase of the dialogue  where the q value for the summarize both was
   

fiwalker

only slightly greater  thus we implemented the learned policy  see figure      with the
exception that the summarize system strategy was used throughout the dialogue   
in terms of the operations state machine in figure    implementation of the learned
policy means that the choices between the si top and mi top strategies are replaced by
the si top strategy  choices between the different read strategies in different states are
replaced by the read first  rf  strategy and choices between the different summarization
strategies in different states are replaced by the summarize system  ss  strategy 
we then tested this policy on six new users who had never used elvis before  these
users conversed with elvis to perform the same set of six email tasks that were used
in the training phase  as described in figure    above  in addition  identical performance
measures were collected for each testing dialogue and training dialogue  overall performance
measures for the training and test dialogues are given in table    with the training data split
in terms of system initiative  mixed initiative and overall means  the table shows that all
versions of elvis have high levels of task completion  which is important for testing the
utility of reinforcement learning  statistical analysis of these results indicated a statistically
significant increase in user satisfaction from training to test  f         p         

   discussion and future work

this paper proposes a novel method by which a dialogue system can learn to choose an
optimal dialogue strategy and tests it in experiments with elvis  a dialogue system that
supports access to email by phone  with strategies for initiative  and for reading and summarizing messages  we reported experiments in which elvis learned that the system initiative
strategy has higher utility than the mixed initiative strategy  that read first is the best
read strategy  and that summarize system is generally the best summary strategy  we
then tested the policy that elvis learned on a new set of users performing the same set of
tasks and showed that the learned policy resulted in a statistically significant increase in
user satisfaction in the test set of dialogues 
previous work has also treated a system s choice of dialogue strategy as a stochastic
optimization problem  walker        biermann   long        levin   pieraccini       
levin et al          to our knowledge  walker        first proposed that reinforcement
learning algorithms could be applied to dialogue strategy selection  in simulation experiments reported by walker               dialogues between two agents in an artificial world
were used to test which dialogue strategies were optimal under various conditions  these
experiments varied      the dialogue agent s resource bounds  and     the performance function used to assess the agent s performance  the experiments showed that strategies that
were not optimal under one set of assumptions about the performance function could be
highly ecacious when the performance function reected the fact that the dialogue agent
was resource bounded  walker        suggested that the optimal dialogue strategy could be
    obviously this choice of the strategy to test risked testing a non optimal policy  an alternative that we
would like to try in future work is to utilize only the summstrat state variable from the operations vector
in the state representation for reinforcement learning and simply distinguish states where no summarize
strategy has been selected  no summary has been produced  and states where at least one summary has
been produced  if the analysis about dialogue phase carries through  then the policy that should be
learned is to use the summarize both strategy for the first summary in a dialogue and then afterwards
use the summarize system strategy 

   

fireinforcement learning in the elvis system

measure train si train mi overall train test
comp
   
   
   
   
user turns
    
    
         
system turns
    
    
         
elapsed time  sec        
      
            
mean recognition score
   
   
   
   
timeouts
   
   
   
   
timeout 
   
   
   
   
cancs
   
   
   
   
canc 
   
   
   
   
help requests
   
   
         
help 
   
   
   
   
bargeins
   
   
   
   
bargein 
   
   
   
   
rejects
  
   
   
   
reject 
   
   
   
   
user satisfaction
    
    
         
table    performance measure means per dialogue for training and testing dialogues  si
  system initiative  mi   mixed initiative
learned via reinforcement learning  if an appropriate performance function could be determined  and described an experiment using genetic algorithms to learn an optimal dialogue
strategy  in subsequent work  utilized here  the paradise model was proposed as a way to
learn an appropriate performance function  walker et al       a   in addition  related work
utilizing elvis  that varied the reward function  and applied other reinforcement learning
algorithms  was carried out by fromer  fromer        
biermann and long         proposed the use of similar techniques in the context of
learning optimal dialogue strategies for a multi modal dialogue tutor  the goal of the tutor
was to instruct students taking their first programming class and the tutor interacted with
the students by highlighting parts of their code and printing text on the screen telling them
what was wrong with their program  biermann and long describe a planned experiment in
which the system would vary its instructional style  and the system s reward would be the
amount of time between the system s instructions and the student s response  this reward
function was based on the assumption that a delayed response suggested a greater cognitive
load for the student  and that cognitive load should be minimized in an instructional setting 
levin and colleagues also proposed treating dialogue systems as markov decision processes and suggested that system designers could determine what an appropriate objective
function might be  levin et al         levin   pieraccini         they carried out a series
of experiments in which a simulated user interacted with an implemented spoken dialogue
system for travel planning by exchanging messages at the semantic meaning level  they
showed that the system could learn strategy choices at the level of database interaction 
   

fiwalker

e g   that the system should not query the database until it had determined many of the
constraints necessary in order to find ights that matched the user s goals 
stochastic optimization techniques have also been applied to similar problems in textbased dialogue interaction and graphical user interfaces  mellish and colleagues applied
stochastic optimization to the problem of determining the content and structure of the
system s utterances in the ilex system  an interactive museum tour guide  mellish et al  
       this work was not tested against a user population and the performance  reward 
measure was based on heuristics about good text plans formulated by experts  christensen
and colleagues applied genetic algorithms to the design of a graphical user interface for an
automated teller machine  the goal was to automatically learn the best layout of a sequence
of interaction screens for intracting with a user  christensen  marks    shieber         in
this work  as in that of levin and colleagues  the user population was simulated 
here  the method for optimizing dialogue strategy selection was illustrated by evaluating strategies for managing initiative and for information presentation by interaction with
human callers  we applied the paradise performance model to derive an empirically motivated performance function  that combines both subjective user preferences and objective
system performance measures into a single function  it would have been impossible to predict a priori which dialogue factors inuence the usability of a dialogue system  and to what
degree  our performance equation shows that task success and dialogue quality measures
are the primary contributors to system performance  furthermore  in contrast to assuming an a priori model  we use the dialogues from real user system interactions to provide
realistic estimates of mija   the state transition model used by the learning algorithm  it
is impossible to predict a priori the transition frequencies  given the imperfect nature of
spoken language understanding  and the unpredictability of user behavior 
the use of this method introduces several open issues and possible areas for future
work  first  the results of the learning algorithm are dependent on the representation of
the state space  in spoken dialogue systems  the system designers construct the state space
and decide what state variables the system needs to monitor  whereas in other applications of reinforcement learning  e g  backgammon   the state space is pre defined  in the
experiments reported here  we fixed the state representation and carried out experiments
on a particular state representation  however in future work we hope to be able to learn
which aspects of the state history should be represented using similar techniques to those
described in  langkilde  walker  wright  gorin    litman         for example  it may be
beneficial for the system to represent additional state variables representing more of the
dialogue history  in order for elvis to be able to learn dialogue strategies that reect those
aspects of the dialogue history 
second  in advance of actually running experiments  it is not clear how much experience
a system will need to determine which strategy is better  in the experiments reported here 
we were able to show an improvement for a policy that had converged on the initiative and
read strategies but had not yet converged on the appropriate summarization strategy  it
is possible that if our local rewards had been nonzero that the optimal policy could have
been learned from less training data  in future work  we hope to explore the interaction of
training set size and the use of a local reward 
third  our experimental data is based on fixing particular experimental parameters  all
of the experiments are based on short term interactions with novice users  but we might
   

fireinforcement learning in the elvis system

expect that users of an email system would engage in many interactions with the same
system  and that preferences for system interaction strategies could change over time with
user expertise  this means that the performance function might change over time  we also
used a fixed set of tasks that were representative of the domain  but it is possible that some
aspects of the policies we learned might be sensitive to our experimental tasks  another
limitation is that the experiments were carried out in a scenario where each email folder
only had a small number of messages  the strategies tested here might not be optimal when
an email folder contains hundreds of messages 
fourth  the optimal strategy is potentially dependent on various system parameters  for
example  the readfirst strategy takes the initiative to read a message  which might result
in messages being read that the user wasn t interested in  but since the user can barge in
on system utterances  there is little overhead with taking this decision  if the system did
not support barge in  our results might have been different 
fifth  the learned policy depends on the reward function  for example  since elvis
is a fully functional system  users can complete the experimental task with any version of
the system using any of the strategies that we explored  this means that if we had used
task completion as the reward function  reinforcement learning would have predicted that
there were no differences between the different strategies  on the other hand  by using the
paradise performance function  we utilized a reward function that was fit to our data and
elvis s performance  and we have some evidence that this reward function may generalize
to other systems  walker  kamm    litman        
sixth  the experiments that we report here are limited in the way that they demonstrate
the utility of reinforcement learning for dialogue strategy optimization  a more traditional
way of selecting the best dialogue strategies would be with experiments which treated
dialogue strategy selection as a factor  and standard statistical hypothesis testing would be
used to compare the performance of different strategies  the scale of the experiment here
is small enough that it is imaginable that the space of policies could possibly have been
tested in the more traditional way  however  the primary goal of the experiments reported
here was simply to test the feasibility of these methods  which required working out in
detail many of the issues of state and strategy representation discussed above  now that
many of these details have been worked out  the methods presented here can be applied to
much more complex dialogue strategy optimization problems  such as varying the initiative
depending on the dialogue state  chu carroll   brown        webber   joshi         or
exploring combinations of strategies for information presentation  summarization  sparckjones         error recovery  hirschman   pao         database query  levin et al         
cooperative responses  joshi  webber    weischedel        finin et al         chu carroll  
carberry         and content selection for generation  mckeown        kittredge  korelsky 
  rambow         inter alia 
finally  the learning algorithm that we report here is an off line algorithm  i e  elvis
collects a set of dialogues and then decides on an optimal strategy as a result  in contrast  it
should be possible for elvis to learn on line  during the course of a dialogue  once methods
are developed for the performance function to be automatically calculated or approximated 
our primary goal with the experiments reported here was to explore the application
of reinforcement learning to spoken dialogue systems and to identify open issues such as
those discussed above  in current work  we are exploring these issues in several ways  we
   

fiwalker

have codified the notion of a state estimator so that we can systematically vary the state
representation in order to explore the effect of the state representation on the value function
and the optimal policy  singh  kearns  litman    walker         we are also in the process
of using reinforcement learning to conduct a set of experiments on a spoken dialogue system
for accessing information about activities in new jersey  in these experiments we explore
a number of different reward functions and also explore a much broader range of strategies
for user initiative  for reprompting the user  and for confirming the system s understanding 

   acknowledgements
i received many useful questions and comments on this research when i presented some
initial results at an invited talk given at aaai      in providence  r i  the design and
implementation of the basic functionality of elvis was done in collaboration with j  fromer 
g  difabbrizio  d  hindle and c  mestel  initial experiments on reinforcement learning with
elvis were done in collaboration with j  fromer and s  narayanan  this work has also
benefited from discussions with w  eckert  c  kamm  m  kearns  e  levin  d  litman  d 
mcallester  r  pieraccini  r  sutton  and s  singh  special thanks are to s  whittaker  j 
wiebe and four reviewers for detailed comments on earlier versions of this manuscript 
v

references
allen  j  f          a plan based approach to speech act recognition  tech  rep   university of toronto 
baggia  p   castagneri  g     danieli  m          field trials of the italian arise train
timetable system  in interactive voice technology for telecommunications applications  ivtta  pp         
barto  a   bradtke  s  j     singh  s  p          learning to act using real time dynamic
programming  artificial intelligence journal                  
bellman  r  e          dynamic programming  princeton university press  princeton  n j 
biermann  a  w     long  p  m          the composition of messages in speech graphics
interactive systems  in proceedings of the      international symposium on spoken
dialogue  pp         
bruce  b          belief systems and language understanding  tech  rep  ai     bolt 
berenak and newman 
carberry  s          plan recognition and its use in understanding dialogue  in kobsa 
a     wahlster  w   eds    user models in dialogue systems  pp           springer
verlag  berlin 
carbonell  j  r          mixed initiative man computer dialogues  tech  rep        bolt
beranek and newman  cambridge  ma 
   

fireinforcement learning in the elvis system

christensen  j   marks  j     shieber  s          placing text labels on maps and diagrams 
in heckbert  p   ed    graphics gems iv  academic press 
chu carroll  j     brown  m  k          tracking initiative in collaborative dialogue interactions  in proceedings of the   th annual meeting of the association for computational
linguistics  pp          
chu carroll  j     carberry  s          a plan based model for response generation in
collaborative task oriented dialogue  in aaai     pp          
cohen  p  r          empirical methods for artificial intelligence  mit press  boston 
cohen  p  r          on knowing what to say  planning speech acts  tech  rep      
university of toronto  department of computer science 
danieli  m     gerbino  e          metrics for evaluating dialogue strategies in a spoken
language system  in proceedings of the      aaai spring symposium on empirical
methods in discourse interpretation and generation  pp        
finin  t  w   joshi  a  k     webber  b  l          natural language interactions with
artificial experts  proceedings of the ieee                 
fromer  j  c          learning optimal discourse strategies in a spoken dialogue system 
tech  rep   mit ai lab m s  thesis 
grosz  b  j          team  a transportable natural language interface system  in proc   st
applied acl  association of computational linguistics  santa monica  ca 
grosz  b  j     sidner  c  l          attention  intentions and the structure of discourse 
computational linguistics              
hirschman  l     pao  c          the cost of errors in a spoken language system  in proceedings of the third european conference on speech communication and technology 
pp            
jack  m   foster  j  c     stentiford  f  w          intelligent dialogues in automated telephone services  in international conference on spoken language processing  icslp 
pp            
joshi  a  k   webber  b     weischedel  r  m          some aspects of default reasoning
in interactive discourse  tech  rep  ms cis        university of pennsylvania 
kamm  c   narayanan  s   dutton  d     ritenour  r          evaluating spoken dialog systems for telecommunication services  in  th european conference on speech
technology and communication  eurospeech     pp            
kamm  c          user interfaces for voice applications  in roe  d     wilpon  j 
 eds    voice communication between humans and machines  pp           national
academy press 
   

fiwalker

keeney  r     raiffa  h          decisions with multiple objectives  preferences and value
tradeoffs  john wiley and sons 
kittredge  r   korelsky  t     rambow  o          on the need for domain communication
knowledge  computational intelligence                 
langkilde  i   walker  m   wright  j   gorin  a     litman  d          automatic prediction
of problematic human computer dialogues in how may i help you   in proceedings of
the ieee workshop on automatic speech recognition and understanding  asruu   
levin  e     pieraccini  r          a stochastic model of computer human interaction for
learning dialogue strategies  in eurospeech    
levin  e   pieraccini  r     eckert  w          learning dialogue strategies within the
markov decision process framework  in proc  ieee workshop on automatic speech
recognition and understanding 
levin  e   pieraccini  r   eckert  w   fabbrizio  g  d     narayanan  s          spoken
language dialogue  from theory to practice  in proc  ieee workshop on automatic
speech recognition and understanding  asruu   
litman  d          plan recognition and discourse analysis  an integrated approach for
understanding dialogues  tech  rep       university of rochester 
litman  d  j   walker  m  a     kearns  m  j          automatic detection of poor speech
recognition at the dialogue level  in proceedings of the thirty seventh annual meeting
of the association of computational linguistics  pp          
love  s   dutton  r  t   foster  j  c   jack  m  a     stentiford  f  w  m          identifying salient usability attributes for automated telephone services  in international
conference on spoken language processing  icslp  pp            
mckeown  k  r          discourse strategies for generating natural language text  artificial
intelligence               
mellish  c   knott  a   oberlander  j     o donnell  m          experiments using stochastic search for text planning  in proceedings of international conference on natural
language generation  pp         
mohri  m   pereira  f  c  n     riley  m  d          fsm library   general purpose finitestate machine software tools  
moore  j  d     paris  c  l          planning text for advisory dialogues  in proc    th
annual meeting of the association of computational linguistics 
pollack  m   hirschberg  j     webber  b          user participation in the reasoning process
of expert systems  in proceedings first national conference on artificial intelligence 
pp  pp          
power  r          a computer model of conversation  ph d  thesis  university of edinburgh 
   

fireinforcement learning in the elvis system

rabiner  l  r   juang  b  h     lee  c  h          an overview of automatic speech
recognition  in lee  c  h   soong  f  k     paliwal  k  k   eds    automatic speech
and speaker recognition  advanced topics  pp        kluwer academic publishers 
russell  s     norvig  p          artificial intelligence  a modern approach  prentiss hall 
englewood cliffs  n j 
sanderman  a   sturm  j   den os  e   boves  l     cremers  a          evaluation of
the dutchtrain timetable information system developed in the arise project  in
interactive voice technology for telecommunications applications  ivtta  pp     
   
seneff  s   zue  v   polifroni  j   pao  c   hetherington  l   goddeau  d     glass  j         
the preliminary development of a displayless pegasus system  in arpa spoken
language technology workshop 
shriberg  e   wade  e     price  p          human machine problem solving using spoken language systems  sls   factors affecting performance and user satisfaction  in
proceedings of the darpa speech and nl workshop  pp        
simmons  r     slocum  j          generating english discourse from semantic networks 
cacm                   
singh  s   kearns  m  s   litman  d  j     walker  m  a          reinforcement learning
for spoken dialogue systems  in proc  nips   
smith  r  w     hipp  d  r          spoken natural language dialog systems  a practical
approach  oxford university press 
sparck jones  k          what might be in a summary   in proceedings of information
retrieval     von der modellierung zur anwendung  pp       universitatsverlag knstanz 
sparck jones  k          automatic summarizing  factors and directions  in mani  i    
maybury  m   eds    advances in automatic text summarization  mit press 
sparck jones  k     galliers  j  r          evaluating natural language processing systems 
springer 
sproat  r     olive  j          an approach to text to speech synthesis  in kleijn  w  b  
  paliwal  k  k   eds    speech coding and synthesis  pp           elsevier 
sutton  r  s          planning by incremental dynamic programming  in proceedings ninth
conference on machine learning  pp           morgan kaufmann 
sutton  r  s     barto  a  g          reinforcement learning  mit press 
tesauro  g          practical issues in temporal difference learning  machine learning 
                 
walker  d          understanding spoken language  elsevier  north holland  new york 
   

fiwalker

walker  m   fromer  j   fabbrizio  g  d   mestel  c     hindle  d          what can i say 
evaluating a spoken language interface to email  in proceedings of the conference on
computer human interaction  chi      pp          
walker  m  a   litman  d   kamm  c  a     abella  a       a   paradise  a general
framework for evaluating spoken dialogue agents  in proceedings of the   th annual
meeting of the association of computational linguistics  acl eacl     pp      
    
walker  m   hindle  d   fromer  j   fabbrizio  g  d     mestel  c       b   evaluating
competing agent strategies for a voice email agent  in proceedings of the european
conference on speech communication and technology  eurospeech   
walker  m  a          informational redundancy and resource bounds in dialogue  ph d 
thesis  university of pennsylvania 
walker  m  a          the effect of resource limits and task complexity on collaborative
planning in dialogue  artificial intelligence journal                    
walker  m  a   fromer  j  c     narayanan  s          learning optimal dialogue strategies  a case study of a spoken dialogue agent for email  in proceedings of the   th
annual meeting of the association of computational linguistics  coling acl    
pp            
walker  m  a   kamm  c  a     litman  d  j          towards developing general models
of usability with paradise  natural language engineering  special issue on best
practice in spoken dialogue systems 
walker  m  a     whittaker  s          mixed initiative in dialogue  an investigation into
discourse segmentation  in proc    th annual meeting of the acl  pp        
watkins  c  j          models of delayed reinforcement learning  ph d  thesis  cambridge
university 
webber  b     joshi  a          taking the initiative in natural language database interaction  justifying why  in coling     pp          
winograd  t          understanding natural language  academic press  new york  n y 
woods  w  a          natural language communication with machines  an ongoing goal 
in reitman  w   ed    artificial intelligence applications for business  pp          
ablex publishing corp  norwood  n j 

   

fi