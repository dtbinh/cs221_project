journal of articial intelligence research                  

submitted        published     

robust agent teams via socially attentive monitoring

gal a  kaminka
milind tambe

galk isi edu
tambe isi edu

information sciences institute and computer science department
university of southern california
     admiralty way
los angeles  ca        usa

abstract
agents in dynamic multi agent environments must monitor their peers to execute individual and group plans  a key open question is how much monitoring of other agents 
states is required to be eective  the monitoring selectivity problem  we investigate this
question in the context of detecting failures in teams of cooperating agents  via sociallyattentive monitoring  which focuses on monitoring for failures in the social relationships
between the agents  we empirically and analytically explore a family of socially attentive
teamwork monitoring algorithms in two dynamic  complex  multi agent domains  under
varying conditions of task distribution and uncertainty  we show that a centralized scheme
using a complex algorithm trades correctness for completeness and requires monitoring all
teammates  in contrast  a simple distributed teamwork monitoring algorithm results in
correct and complete detection of teamwork failures  despite relying on limited  uncertain
knowledge  and monitoring only key agents in a team  in addition  we report on the design
of a socially attentive monitoring system and demonstrate its generality in monitoring several coordination relationships  diagnosing detected failures  and both on line and o line
applications 

   introduction
agents in complex  dynamic  multi agent environments must be able to detect  diagnose 
and recover from failures at run time  toyama   hager        

for instance  a robot s

grip may be slippery  opponents  behavior may be intentionally dicult to predict  communications may fail  etc  examples of such environments include virtual environments for
training  johnson   rickel        calder  smith  courtemanche  mar    ceranowicz        
high delity distributed simulations  tambe  johnson  jones  koss  laird  rosenbloom   
schwamb        kitano  tambe  stone  veloso  coradeschi  osawa  matsubara  noda   
asada         and multi agent robotics  parker        balch         the rst key step in
this process is execution monitoring  doyle  atkinson    doshi        ambros ingerson  
steel        cohen  amant    hart        reece   tate        atkins  durfee    shin 
      veloso  pollack    cox        
monitoring execution in multi agent settings requires an agent to monitor its peers 
since its own correct execution depends also on the state of its peers  cohen   levesque 
      jennings        parker        jennings        grosz   kraus        tambe        
monitoring peers is of particular importance in teams  since team members rely on each
other and work closely together on related tasks 

c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fikaminka and tambe

 monitoring allows team members to coordinate their actions and plans with team 

mates  to help teammates and cooperate without interference  for example  drivers
of cars in a convoy cannot drive without monitoring other cars in the convoy  so as to
not disband the convoy  and to help other drivers if cars break down 
 monitoring allows team members to use peers as dynamic information sources  for

learning new information  for instance  if a driver in a convoy sees that the other cars
in front of it suddenly turn to the left  she can infer the existence of an obstacle or
milestone despite not directly seeing it herself 
previous work has investigated dierent ways of monitoring in the context of teams of cooperating agents  for example  theoretical work on sharedplans  grosz   kraus        has

passive monitoring  in which an agent is notied when a proposition
changes  e g   via communications   and active monitoring  in which an agent actively seeks
distinguished between

to nd out when a proposition changes  e g   via observations and inference of unobservable
attributes   practical implementations have investigated the use of passive monitoring via
communications  jennings         active monitoring via plan recognition  huber   durfee         active implicit monitoring via the environment  fenster  kraus    rosenschein 
       and dierent combinations of these methods  parker        jennings        tambe 
      lesh  rich    sidner        

no approach is clearly superior to another 

passive

monitoring is generally perceived as being less costly than active monitoring  but also less
reliable  grosz   kraus        huber   durfee        kaminka   tambe        
regardless of the monitoring method  bandwidth and computational limitations prohibit
a monitoring agent from monitoring all other agents to full extent  all the time  jennings 
      durfee        grosz   kraus         thus a key open question is how much monitoring of other agents is required to be eective  in teams   jennings        grosz   kraus 
             we call this challenging problem the

monitoring selectivity problem 

i e   the

problem of selectivity in observing others and inferring their state  based on the observations  for monitoring 

although it has been raised in the past  only a framework and

minimal constraints for answers were provided  jennings        grosz   kraus         for
instance  the theory of sharedplans requires agents to verify that their intentions do not
conict with those of teammates  grosz   kraus         however  the methods by which
such verication can take place are left for further investigation  grosz   kraus        p 
      section   provides more details on related work 
this paper begins to address the monitoring selectivity problem in teams  by investigating monitoring requirements for eective failure detection 

we focus our investigation

on detecting failures in the social relationships that ideally hold between agents in a monitored team  we call such monitoring of social relationships

socially attentive monitoring 

to dierentiate it from other types of monitoring  such as monitoring for failures in the
progress of agents towards their goals  here  the term social relationship is used to denote a
relation on attributes of multiple agents  states  socially attentive monitoring in the convoy
example involves verifying that agents have common destination and heading  that their
beliefs in driving as a convoy are mutual  etc  for instance  if the agents are observed to
head in dierent directions  they clearly do not have a common heading  this is dierent
than monitoring whether their chosen  common  heading leads towards their  agreed upon 
destination 

   

firobust agent teams via socially attentive monitoring

monitoring relationships in a team  socially attentive monitoring  is a critical task in
monitoring team members 

failures to maintain the team s relationships can often lead

to catastrophic failures on the part of the team  lack of cooperative behavior and lack of
coordination  such failures are often the result of individual agent failures  such as failures
in an agent s sensors and actuators  thus socially attentive monitoring covers a large class
of failures  and promotes robust individual operation 
we explore socially attentive monitoring algorithms for detecting teamwork failures under various conditions of uncertainty 

we analytically show that despite the presence of

uncertainty about the actual state of monitored agents  a centralized

active

monitoring

scheme can guarantee failure detection that is either sound and incomplete  or complete
and unsound  however  this requires reasoning about multiple hypotheses as to the actual
state of monitored agents  and monitoring all agents in the team 

we show that active

distributed teamwork monitoring results in both sound and complete detection capabilities 
despite using a much simpler algorithm  this distributed algorithm   a  uses only a single 
possibly incorrect hypothesis of the actual state of monitored agents  and  b  involves monitoring only key agents in a team  not necessarily all team members  using a transformation
on the analytical constructs  we show analogous results for centralized failure detection in
mutual exclusion coordination relationships 
we also conduct an empirical investigation of socially attentive monitoring in teams 
we present an implemented general socially attentive monitoring framework in which the
expected ideal social relationships that are to be maintained by the agents are compared
to the actual social relationships  discrepancies are detected as possible failures and diagnosed  we apply this framework to two dierent complex  dynamic  multi agent domains 
in service of monitoring various social relationships  both on line and o line  both of these
domains involve multiple interacting agents in collaborative and adversarial settings  with
uncertainties in both perception and action 

in one domain  we provide empirical results

for active monitoring which conrm our analytical results  in another domain we show how
o line socially attentive monitoring can provide quantitative teamwork quality feedback to
a designer  we also provide initial diagnosis procedures for detected failures 
our focus in these explorations is on practical algorithms that have guarantees on performance in real world applications  the algorithms we present seek to complement the use of
passive communications based monitoring  which is unreliable in many domains  and explore
the use of unintrusive key hole plan recognition as an alternative  however  we do not rule
out the use of communicationswe simply seek to provide techniques that can work even
when communications fail 

our analytical guarantees of failure detection soundness and

completeness hold whether monitoring is done through communications or plan recognition 
this paper is organized as follows  section   presents motivating examples and background  section   presents the socially attentive monitoring framework  section   explores
monitoring selectivity in centralized teamwork monitoring 

section   explores monitoring

selectivity in distributed teamwork monitoring  section   demonstrates the generality of our
framework by applying it in an o line conguration  section   presents investigations of additional relationship models  section   presents related work  and section   concludes  the
two appendices contain the proofs for theorems presented  appendix a   and pseudo code
for the socially attentive monitoring algorithms  appendix b  

   

fikaminka and tambe

   motivation and background
the monitoring selectivity problem this paper addresseshow much monitoring is required
for failure detection in teamsrose out of growing frustration with the signicant software
maintenance eorts in two of our application domains 

in the modsaf domain  a high 

delity battleeld virtual environment  calder et al          we have been involved in the
development of synthetic helicopter pilots  tambe et al         

in the robocup soccer

simulation domain  kitano et al         we have been involved in developing synthetic soccer players  marsella  adibi  al onaizan  kaminka  muslea  tallis    tambe         the
environments in both domains are dynamic and complex  and have many uncertainties 
the behavior of other agents  some of it adversarial  some cooperative   unreliable communications and sensors  actions which may not execute as intended  etc 

agents in these

environments are therefore presented with countless opportunities for failure despite the
designers  best eorts 
some examples may serve to illustrate  the following two examples are actual failures
that occurred in the modsaf domain 

we will use these two to illustrate and explore

socially attentive monitoring throughout this paper 

example   

here  a team of three helicopter pilot agents were to y to a specied way 

point  a given position   where one of the team members  the

attackers  

towards the enemy  while its teammates  

scout 

was to y forward

land and wait for its signal  all of the

agents monitored for the way point  however  due to an unexpected sensor failure  one of
the attackers failed to sense the way point 

so while the other attacker correctly landed 

the failing attacker continued to y forward with the scout  see figure   for a screen shot
illustrating this failure  

example   

in a dierent run  after all three agents reached the way point and detected it 

the scout has gone forward and identied the enemy  it then sent a message to the waiting
attackers to join it and attack the enemy  one of the attackers did not receive the message 
and so it remained behind indenitely while the scout and the other attacker continued the
mission alone 
we have collected dozens of similar reports in both the modsaf and robocup domain 
in general  such failures are dicult to anticipate in design time  due to the huge number of
possible states  the agents therefore easily nd themselves in novel states which have not
been foreseen by the developer  and the monitoring conditions and communications in place
proved insucient  in none of the failure cases reported did the agents involved detect  let
alone correct  their erroneous behavior  each agent believed the other agents to be acting in
coordination with it  since no communication was received from the other agents to indicate
otherwise  however  the agents were violating the collaboration relationships between them 
as the agents came to disagree on what plan is being executeda collaboration relationship
failure had occurred 

preliminary empirical results show that upwards of     of failures

reported involved relationship violations  relationship failures  
human observers  however  were typically quick to notice these failures  because of the
clear social misbehavior of the agents in these cases  they were able to infer that a failure
has occurred despite not knowing what exactly happened  for instance  seeing an attacker
continuing to y ahead despite its teammates  switching to a dierent plan  which the human

   

firobust agent teams via socially attentive monitoring

enemy

scout  ahead  and failing attacker  trailing 

landing attacker

figure    a plan view display  the modsaf domain  illustrating the failure in example   
the thick wavy lines are contour lines 

observers inferred from the fact that one of the teammates  the other attacker  has landed 
is sucient for an observer to detect that something has gone amisswithout knowing what
the dierent plan was 
our analysis showed that the agents were not monitoring each other suciently  however  a naive solution of continuous communications between the agents was clearly impractical since   i  the agents are operating in a hostile environment   ii  the communications
overheads would have been prohibitive  and  iii  in fact  it was the communications equipment itself that broke down in some cases  we therefore sought practical ways to achieve
quick detection of failure  based on the limited ambiguous knowledge that was available to
a monitoring agent 

   socially attentive monitoring
we begin with an overview of the general structure of a socially attentive monitoring system  shown in figure    it consists of      a social relationship knowledge base containing
models of the relationships that should hold among the monitored agents  enabling generation of

expected ideal behavior

in terms of relationships  section           an agent and

team modeling component  responsible for collecting and representing knowledge about the
monitored agents 

actual behavior

 section           a relationship failure detection compo 

nent that monitors for violations of relationships among monitored agents by contrasting
the expected and actual behavior  section       and     a relationship diagnosis component
that veries the failures  and provides an explanation for them  section       the resulting

   

fikaminka and tambe

explanation  diagnosis  is then used for recovery  e g   by a negotiations system  kraus 
sycara    evenchik         or a general  re planner  ambros ingerson   steel        

expected
attribute
values

what agents to monitor 
what agent attributes

social relationships knowledge base
expected behavior
relationship
diagnosis

relationship
failure
detections

detected
failure

observations 
communications

actual
behavior

actual values

monitored agent

agent team modeling component

diagnosis

socially attentive monitoring system

monitored agent

figure    the general structure of a socially attentive monitoring system 

    a knowledge base of relationship models
we take a relationship among agents to be a relation on their state attributes  a relationship
model thus species how dierent attributes of an agent s state are related to those of
other agents in a multi agent system  these attributes can include the beliefs held by the
agents  their goals  plans  actions  etc  for example  many teamwork relationship models
require that team members have mutual belief in a joint goal  cohen   levesque       
jennings        

a spatial formation relationship  parker        balch        species

relative distances  and velocities that are to be maintained by a group of agents  in our
domain  helicopter pilots  

coordination relationships may specify temporal relationships

that are to hold among the actions of two agents  e g   business contractors  malone  
crowston        

all such relationships are

social they

explicitly specify how multiple

agents are to act and what they are to believe if they are to maintain the relationships
between them 
the relationship knowledge base contains models of the relationships that are supposed
to hold in the system  and species the agents that are participating in the relationships  the
knowledge base guides the agent modeling component in selecting agents to be monitored 
and what attributes of their state need be represented  for detection and diagnosis   it is
used by the failure detection component to generate expectations which are contrasted with
actual relationships maintained by the agents  and it provides the diagnosis component with
detailed information about how agents  states  attributes are related  to drive the diagnosis
process 

our implementation of socially attentive monitoring in teams uses four types of

relationships 
for

formations  role similarity  mutual exclusion  and teamwork 

teamwork

monitoring

we

use

the

steam

 tambe 

     

general

domain 

independent model of teamwork  which is based on cohen and levesque s joint intentions
framework  levesque  cohen    nunes        cohen   levesque        and grosz  sidner 
and kraus s sharedplans  grosz   sidner        grosz   kraus              

   

however 

firobust agent teams via socially attentive monitoring

other teamwork models may be used instead of steam  although steam is used by our
pilot and soccer agents to generate collaborative behavior  it is reused here independently
in service of monitoring  i e   monitored agents are assumed to be a team  and steam is
used in monitoring their teamwork  steam and other teamwork models  e g  

cohen  

levesque        jennings        rich   sidner        require mutual belief by team members in their joint goals and plans  this characteristic is used to monitor teamwork in our
system  the other relationship models are used only in a secondary monitoring role  they
will be discussed in greater length in section   

    knowledge of monitored agents and team
the agent modeling component is responsible for acquiring and maintaining knowledge

actual relations that exist
ideal expected relations  in this

about monitored agents  this knowledge is used to construct the
between agents  states  attributes  which are compared to the

section  we describe the plan recognition capabilities of the agent modeling component in our
implementation and experiments  i e   the extent of the knowledge that could be maintained
about monitored agents  plans if necessary  later sections show that in fact limited  possibly
inaccurate  knowledge is sucient for eective failure detection  thus implementations may
use optimized agent modeling algorithms rather than these full capabilities  section     will
discuss additional agent modeling capabilities  necessary for diagnosis 

      representation

for monitoring teamwork relationships  we have found that representing agents in terms of
their selected hierarchical reactive plans enables quick monitoring of their state  and also
facilitates further inference of the monitored agents  beliefs  goals  and unobservable actions 
since they capture the agents  decision processes 
in this representation  reactive plans  firby        newell        form a single decomposition hierarchy  a tree  that represents the alternative controlling processes of each agent 
each reactive plan in the hierarchy  hereafter referred to simply as a plan  has selection
conditions  also referred to as preconditions  for when it is applicable  and termination conditions which are used to terminate or suspend plans  at each given moment  the agent is
executing a single path  root to a leaf   through the hierarchy 

this path is composed of

plans at dierent levels 
figure   presents a small portion of such a hierarchy  created for the modsaf domain  in
the case of example    prior to the way point 

each of the agents

was executing the path be 

execute mission as highest level plan  through fly flight plan  fly route 
traveling and low level  upon reaching the way point  they were all supposed to switch
from fly flight plan and its descendents to wait at point  the attackers would then
select just wait as a child of wait at point  while the scout would select scout forward
ginning with

and its descendents  of course  the failing attacker did not detect the way point and so the

fly flight plan and the selection conditions for wait at point
the failing attacker continued to execute fly flight plan and its

termination conditions for
were not satised and
descendents 

   

fikaminka and tambe

execute mission
fly flight plan  f 
fly route

wait at point  w 

join scout  j 

ordered halt  h 

low level

just wait

scout forward
traveling

nap of the earth

contour

figure    portion of hierarchical reactive plan library for modsaf domain  team plans
are boxed  these are explained in section      

      acquisition

from a practical perspective  while the agents may cooperatively report to the monitoring
agent on their own state using communications  it requires communication channels to be
suciently fast  reliable and secure 

this is unfortunately not possible in many realistic

domains  as our examples demonstrate  section    
alternatively  a monitor may use plan recognition to infer the agents  unobservable state
from their observable behavior  this approach is unintrusive and robust in face of communication failures  of course  the monitor may still benet from focused communications with
the other agents  but would not be critically dependent on them 
to enable plan recognition using reactive plans  our chosen representation   we have
employed a reactive plan recognition algorithm called resl  real time situated leastcommitments   the key capability required is to allow explicit maintenance of hierarchical
plan hypotheses matching each agent s observed behavior  while pruning of hypotheses which
are deemed incorrect or useless for monitoring purposes 

resl works by expanding the

entire plan library hierarchy for each modeled agent  and tagging all paths matching the
observed behavior of the agent being modeled  see appendix b for pseudo code for the
algorithm   heuristics and external knowledge may be used to eliminate paths  hypotheses 
which are deemed inappropriateindeed such heuristics will be explored shortly  resl s
basic approach is very similar to previous work in reactive plan recognition  rao        and
team tracking  tambe         which have been used successfully in the modsaf domain 
and share many of resl s properties 

however  resl adds belief inference capabilities

which are used in the diagnosis process  discussed below  section      
figure   gives a simplied presentation of the plan hierarchies for a variation of example
   in which all the agents correctly detected the way point  i e   no failure has occurred  note
that some plans at intermediate levels have been abstracted out in the gure   the scout
 figure  a  and the two attackers  figures  b   c  switched from the
 denoted by

fly flight plan plan

f  to the wait at point plan  denoted by w   an outside observer using resl

infers explanations for each agent s behavior by observing the agents  the scout continues

   

firobust agent teams via socially attentive monitoring

low level  one of the possible ight methods
wait at point  w  plans  thus they are both

to y ahead  its speed and altitude matching
under both the

fly flight plan  f 

and

tagged as possible hypotheses for the scout s executing plan hierarchy 

similarly  as the

just wait
ordered halt  h 

attackers land  resl recognizes that they are executing the
this plan can be used in service of either the

w

or the

plan 

plana plan in

which the helicopters are ordered by their headquarters to land immediately 

h

and

w

thus both

are tagged as explanations for each of the attackers  states  at the second level of

the hierarchies   for all agents  resl identies the plan
plan 

however 

execute mission

as the top level

in this illustration  the actual executing paths of the agents are marked with lled

arrows  other

individual modeling

hypotheses that match the observed behavior are marked

using dashed arrows  an outside observer  of course  has no way of knowing which of the
possible hypotheses is correct 

execute mission

wait at point  w 

execute mission

execute mission

fly flight plan  f 

wait at point  w 

ordered halt  h 

wait at point  w 

low level

just wait

just wait

just wait

low level

 b 

 a 

ordered halt  h 

just wait

 c 

figure    scout  a  and attackers   b  c  actual and recognized

abbreviated

reactive plan

hierarchies 

once individual modeling hypotheses are acquired for each individual agent  using planrecognition in our implementation  but potentially also by communications   the monitoring
agent must combine them to create team modeling hypotheses as to the state of the team
as a whole  the monitoring agent selects a single individual modeling hypothesis for each
individual agent and combines them into a single team modeling hypothesis  several such
team modeling hypotheses are possible given multiple hypotheses for individual agents  for
instance  in figure    while all team hypotheses will have

execution mission

as the top 

level plan  there are eight dierent team hypotheses which can be dierentiated by their
second level plan 

 w w w    w w h    w h w    w h h    f w w    f w h    f h w    f h h   if the

observer is a member of the team  it knows what it is executing itself  but would still have
multiple hypotheses about its teammates  states  for instance  if the attacker in figure  b
is monitoring its teammates  its hypotheses at the second level would be  w w w    w w h  

 f w w    f w h  

to avoid explicitly representing a combinatorial number of hypotheses  resl explicitly
maintains all candidate hypotheses for each agent individually  but not all combinations
of individual models as team hypotheses  instead  these combinations are implicitly represented  thus the number of hypotheses explicitly maintained grows linearly in the number
of agents 

   

fikaminka and tambe

    relationship violation detection
the failure detection component detects violations of the social relationships that should
hold among agents 

this is done by comparing the ideal expected relationships to their

actual maintenance by the agents  for teamwork specically  the relationship model requires
team members to always agree on which

team plan is jointly executed by the team  similarly

to joint responsibility  jennings         and sharedplans  grosz   kraus         if this
requirement fails in actuality  i e   the agents are executing dierent team plans  then a
teamwork failure has occurred 
the basic teamwork failure detection algorithm is as follows 
plan hierarchies are processed in a top down manner 

the monitored agents 

the detection component uses the

teamwork model to tag specic plans as team plans  explicitly representing joint activity by
the team  these plans are boxed in figures      and    

the team plans in equal depths

of the hierarchies are used to create team modeling hypotheses  for each hypothesis  the
plans of dierent agents are compared to detect disagreements  any dierence found is an
indication of failure 

if no dierences are found  or if the comparison reaches individual

plans  non team  therefore non boxed in the gures  no failure is detected  individual plans 
which may be chosen by an agent individually in service of team plans are not boxed in
these gures  and are handled using other relationships as discussed in section  
for instance  suppose the failing attacker from example   is monitoring the other attacker  figure   shows its view of its own hierarchical plan on the left  the path on the
right represents the state of the other attacker  who has landed   this state has been inferred in this example from observations made by the monitoring attacker  here  we are
assuming that the plan recognition process has resulted in one correct hypothesis for each
agent  we will discuss more realistic settings below   in figure    the dierence that would
be detected is marked by the arrow between the two plans at the second level from the top 

fly flight plan team plan  on
wait at point team plan  on the right   the

while the failing attacker is executing the

the left   the

other attacker is executing the

disagreement

on which team plan is to be executed is a failure of teamwork 

execute mission

execute mission

fly flight plan

wait at point

fly route
traveling
low level

just wait

figure    comparing two hierarchical plans  the top most dierence is at level   

   

firobust agent teams via socially attentive monitoring

detecting disagreements is dicult with multiple team modeling hypotheses  since they
may imply contradictory results with respect to failure detection  some hypotheses may imply that a failure had occurred in the team  while others may not  unfortunately  this is to
be expected in realistic applications  for instance  figure    section      shows several hypotheses that are possible based on the same observations  however  one of the hypotheses 
 w w w   implies no failure has occurredall the agents are in agreement on which team plan

is executingwhile another hypothesis   f w h   implies failures have occurred 

to limit reasoning to only a small number of team hypotheses  while not restricting
failure detection capabilities  we use a disambiguation heuristic that ranks team modeling
hypotheses by the level of

coherence

they represent  this heuristic is provided as an initial

solution  later sections will examine additional heuristics 

denition   

the

coherence

level of a multi agent modeling hypothesis is dened as the

ratio of the number of agents modeled to the number of plans contained in the hypothesis 
this denition results in a partial ordering of the hypotheses set  from the least coherent
hypothesis  one that assigns each agent a dierent plan than its team mates   to the most
coherent hypothesis  that assigns the same plan to all team members  

for instance  the

hypothesis  f w h  would have the lowest level of coherence     since it implies complete

breakdown of teamworkevery agent is executing a dierent plan  the hypothesis  w w w 
would have a coherence level of    the highest level of coherence for the group of three agents 
since they are all assigned the same plan  ranked between them would be the hypothesis
 w w h   with a single teamwork failure  disagreement on w and h  and a coherence level of
    
the detection component selects a single maximally coherent team modeling hypothesis
 ties broken randomly  

the intuition for using coherence is that failures to agree occur

despite the agents  attempts at teamwork  thus we expect more agreements than disagreements in the team 

the coherence level of a team hypothesis is inversely related to the

number of teamwork failures implied by the hypothesis  selecting a maximally coherent hypothesis therefore corresponds to the minimum number of failures heuristic commonly used
in diagnosis  hamscher  console    de kleer        
for the case depicted in figure    the complete detection process may be conceptu 

 

alized as follows  

suppose that one of the attackers  whose hierarchy is described in

figure  b  is monitoring the team 

first  it collects the plan hypotheses at the top of

the hierarchy for each agent  including itself    in this case  they are  execute mission  

 execute mission    execute mission   only one team modeling hypothesis can be built
from these   execute mission 

execute mission  execute mission  

since this hypoth 

esis shows no disagreement occurs at this level  the process continues to the second level 
here  the hypotheses for the rst agent on the left are  f w   for the monitoring second agent
 since it knows its own state  there is only one possibility  w   and for the third agent  w h  

as we saw above  the maximally team coherent hypothesis is  w w w  which is selected  since
it does not indicate failure  the process continues to the third level 

here the agents are

executing individual plans  and so the comparison process stops  algorithm   in appendix
b provides greater details about this process 
   other implementations may make use of optimized algorithms in which the heuristics are integrated into
the agent modeling algorithm 

   

fikaminka and tambe

when sub teams are introduced  a dierence between team plans may be explained by
the agents in question being a part of dierent sub teams 

sub team members still have

to agree between themselves on the joint sub team plans  but these may dier from one
sub team to the next  for now  let us assume that the teams under consideration are

teams  as dened in denition   

simple

we make this denition in service of later analytical results

in which it will appear as a condition  we return to the issue of sub teams in section     

denition   

we say that a team t is

simple 

if its plan hierarchy involves no dierent

team plans which are to be executed by dierent sub teams 
intuitively  the idea is that in a simple team  all members of the team jointly execute
each of the team plans in the hierarchy  this denition is somewhat similar to the denition
of a

ground team

in  kinny  ljungberg  rao  sonenberg  tidhar    werner         but it

does not allow sub team members of a team to have a joint plan which is dierent than that
of other members 

    relationship diagnosis
the diagnosis component constructs an explanation for the detected failure  identifying the
failure state and facilitating recovery 

the diagnosis is given in terms of a set of agent

belief dierences  inconsistencies  that explains the failure to maintain the relationship 
the starting point for this process is the detected failure  e g   the dierence in team plans  
the diagnosis process then compares the beliefs of the agents involved to produce a set of
inconsistent beliefs that explain the failure 
two problems exist in practical applications of this procedure 

first  the monitoring

agent is not likely to have access to all of the beliefs held by the monitored agents  since it
is not feasible in practice to communicate all the agents  beliefs to each other  second  each
agent in a real world domain may have many beliefs  and many of them will vary among the
agents  though most of them will be irrelevant to the diagnosis  thus relevant knowledge
may be simply not be accessible  or may be hidden in mountains of irrelevant facts 
to gain knowledge of the beliefs of monitored agents without relying on communications 
the diagnosis process uses a process of belief ascription  the agent modeling component  using resl in our implementation  maintains knowledge about the selection and termination
conditions of recognized plans  hypotheses   for each recognized plan hypothesis  the modeling component infers that any termination conditions for the plan are believed to be false
by the monitored agent  since it has not terminated the plan   we have also found it useful
to use an additional heuristic  and infer that the selection conditions  preconditions  for
any plan which

has just begun execution

are true  the idea is that when a plan is selected

for execution  its preconditions are likely to hold  at least for a short period of time  this
heuristic involves an explicit assumption on the part of our system that the new plan is
recognized as soon as it begins execution 

designers in other domains will need to verify

that this assumption holds 
for each agent i  the inferred termination and selection conditions make up a set of beliefs
bi for the agent  for instance  suppose an agent is hypothesized to have just switched from

executing

fly flight plan

to

wait at point 

resl infers that the agent believes that

the way point was just detected  a selection condition for

   

wait at point  

in addition 

firobust agent teams via socially attentive monitoring

resl infers that the agent believes that an enemy was not seen  and that no order was

wait at point  

received from base to halt the mission  negated termination conditions of

to determine the facts that are relevant to the failure  the diagnosis component uses
the teamwork model  the teamwork model dictates which beliefs the agents hold must be
mutually believed by all the agents in the team 

any dierence that is detected in those

beliefs is a certain failure  as the team members do not agree on issues on which agreement
is mandatory to participation in the team 

the teamwork model thus species that the

beliefs contained in the bi sets should be mutual  and should therefore be consistent 

 

bi    

i

if an inconsistency is detected  the diagnosis procedure looks for contradictions  disagreements  that would cause the dierence in team plan selection  a dierence in beliefs serves
as the diagnosis  allowing the monitoring agent to initiate a process of recovery  e g   by
negotiating about the conicting beliefs  kraus et al         
for example  as shown in section      the two attackers in example    section    dier
in their choice of a team plan  one attacker is continuing execution of the

fly flight plan

plan  in which the helicopters y in formation  the other attacker has detected the waypoint  terminated

fly flight plan

wait at point 

and has switched to

landing immedi 

ately  figure     when the failing attacker monitors its team mate  it detects a dierence in
the team plans  section       and the detected dierence is passed to diagnosis  the failing
attacker makes the following inferences 
  

fly flight plan has three termination conditions 

 a  seeing the enemy   b  detecting

the way point  or  c  receiving an order to halt  the failing attacker  left hierarchy in
figure    knows its own belief that none of these conditions hold  and thus
b 

  

wait at point

 

f w ayp oint   e nemy   h altorderg

has one selection condition 

the way point has been detected 

its

termination condition is that the scout has sent a message to join it  having identied
the enemy s position  the diagnosis component in this case therefore infers that for
the other attacker  right hierarchy in figure   
b 

 

fw ayp oint   s coutm essagereceivedg

then 
b    b 

which

is

 

f w ayp oint  w ayp oint   e nemy   s coutm essagereceived   h altorderg

inconsistent 

the

inconsistency

 disagreement

between

the

attackers 

is

f w ayp oint  w ayp ointg  i e   contradictory beliefs about w aypoint  thus now the failing

attacker knows that its team mate has seen the way point  it can choose to quietly adapt
this belief  thereby terminating its own

fly flight plan

   

and selecting

wait at point 

or

fikaminka and tambe

it may choose other recovery actions  such as negotiating with the other attacker on whether
the way point has been reached 
we have found these diagnosis procedures to be useful in many of the failures detected
by socially attentive monitoring  see section   for evaluation and discussion  
since this paper focuses on the monitoring selectivity problem in

however 

detection  we leave further

investigation of the diagnosis procedures to future work 

   monitoring selectivity in centralized teamwork monitoring
using the socially attentive framework of section   we systematically examine all failure
permutations of examples   and    section    under a centralized teamwork monitoring
conguration  where a single team member is monitoring the team 

we vary the agents

failing  attacker  attacker and scout  etc   and the role of the monitoring agent  attacker or
scout   we report on the empirical results of detecting and diagnosing failures in all cases 
using these empirical results as a guide  we explore centralized teamwork monitoring analytically  we show that even under monitoring uncertainty  centralized teamwork monitoring
can provide either sound or complete detection results  but not both  
as a starting point for our exploration  the monitoring agent uses a single maximallycoherent team modeling hypothesis as discussed in section      we begin with example   
the normal order of execution is

w 

the execution of
enemy s position 

wait at point  w  

followed by

join scout  j  

during

the two attackers land and wait for the scout to visually identify the

upon identication  the scout sends them a message to join it  which

triggers the selection of the

j

plan  and the termination of the

w

plan  when executing

j 

the scout hovers at low altitude  waiting for the attackers to join it  any failures here are
on the part of the attackers  they cannot receive the message  or on the part of the scout  it
cannot send it   these failures arise  for instance  if the radio is broken or team members
are out of range  when an agent fails  it continues to execute

w

instead of switching to

j 

table   summarizes the permutations of example    the permutation number appear
in the rst column 

the next three columns show the actual plans selected by the three

agents a   a  and a  in each permutation 

the second to last column shows whether a

relationship failure has occurred in each case  i e   whether disagreement exists between the
agents  finally  the last column details the physical conditions in each case  there are ve
possible failure permutations  in case    none of the agents failed 
attacker failed 

in cases   and   one

in case   the scout failed to send a message or both attackers failed to

receive it  in case   the scout does not identify the enemy s position  so no message is sent 
and all three agents continue to execute the
since no attacker can switch to the

j

w

plan   other permutations are not possible 

plan without the scout 

for instance  case   in table   corresponds to example    the scout  a   has detected
the enemy  switched to plan

j 

and sent a message to the attackers to join it  one attacker

 a   received the message  switched to plan

j  and began ying towards the scout 

however 

the remaining attacker  a   failed to receive the message  and so it maintains its position 
continuing to execute

w and failing to switch to j  since the agents are no longer in agreement

on which team plan should be jointly executed  a teamwork failure has occurred  condition
monitors were used in the original failure case to monitor for the scout s message  however
failures in communications resulted in these monitoring conditions to be rendered useless 

   

firobust agent teams via socially attentive monitoring

case

 

actual executing plans

relationship failure

physical

 

attacker a 

attacker a 

scout a 

occurred

failure

 

j

j

j

 

 

 

w

j

j

 

a  fails to receive

 

j

w

j

 

a  fails to receive

 

w

w

j

 

a  s message lost

 

w

w

w

 

enemy not identied

table    all possible failure permutations of the broken radio link scenario  example    

one key issue is raised by case   in table    here  due to the scout s inability to identify
the enemy s position  perhaps due to failure on the scout s part  perhaps because the enemy
is simply not there   the three helicopter pilots remain in agreement that the enemy has not
been identied  here  even though clearly the pilots are failing to make progress towards the
task goals  the scout continues to search for the enemy indenitely   no relationship failure
is taking place  since the agents are maintaining the teamwork relationship while failing to
make progress  this clearly demonstrates that not all failures are necessarily relationship
failures 
table   presents the results of the scout monitoring its teammates in example    using a
maximally team coherent hypothesis as the basis for detection  the rst column again shows
the case number  for reference into table    the next three columns show the scout s  a  s 
hypothesis about what plan each agent is executing according to the maximal coherence
heuristic  the next two columns show whether a failure was detected  and whether it was
diagnosed correctly  the last column shows the detection class  discussed below  

case

 

a  s hypothesized executing plans

relationship failure

diagnosis

detection

detected 

success 

class

j

 

n a

true negative

j

 

 

true positive

w

j

 

 

true positive

h

j

 

 

true positive

w

w

 

n a

true negative

attacker a 

attacker a 

scout a 

 

j

j

 

w

j

 

j

 

h

 

w

table    scout s  a   monitoring results in all permutations of example   
for example  case   in table   shows the results of the scout monitoring in the original
failure in example    section     using resl  and selecting a maximally coherent hypothesis  the scout hypothesizes that the non moving attacker is executing
while the moving attacker is executing
its own selected plan

j

j  case    column    

w  case

   column    

the scout of course knows that

 case    column     a violation of the teamwork relationship is thus

detected  case    column     since a  s

w

is not in agreement with the rest of the team s

j 

furthermore  the diagnosis was successful in identifying the cause for the failure  i e   the
fact that the enemy s position has been identied by the scout  but no knowledge of this
was passed on to the failing attacker  case    column    

   

fikaminka and tambe

the last column of table   shows the detection class of each failure  the detection class
of a case can be one of  true positive  true negative  false positive  and false negative  these
correspond to the following possible monitoring outcomes  a true positive is an outcome
where a relationship failure has actually occurred  and has been detected  a true negative
is where no failure has occurred  and the system correctly reports none is being detected 
a false positive is where no failure has occurred  but the system nevertheless incorrectly
detects one  and a false negative is where a failure has occurred  but the system fails to
detect it  table   shows that in all permutations of example   the teamwork monitoring
techniques did not encounter the problematic false positive or false negative cases 
a closer look at these results hints at a key contribution of this paper in addressing the
monitoring selectivity problem  eective failure detection can take place despite the use of
uncertain  limited  knowledge about monitored agents  in case   of table    the monitoring agent was able to detect the failure

involved 

despite being wrong about the state of the agents

the scout believes that the two attackers are executing the

w  h

plan  but they are actually executing 

h  ordered halt 

is selected when a command is received from

headquarters to halt execution and hover in place 

from the scout s perspective  a hov 

ering attacker can therefore be inferred to be executing

h

or

w 

thus two equally ranked

maximally coherent hypotheses exist  the two attackers are either both executing
executing

h 

w or

both

a random selection was made  and in this case resulted in the wrong hypothe 

sis being selected  nevertheless  a violation of the teamwork relationships was detected  as
neither

h

or

w

agrees with the scout s

j 

however  as the last column of case   shows  in table     the diagnosis procedures are
sensitive to the selection of the team modeling hypothesis  the hypothesis used in this case
does not correctly reect the true state of the agents  and so despite the scout s success to
detect a failure in this case  the diagnosis procedures fail to provide correct diagnosis  the
diagnosis was successful in the two other failure cases   this phenomenon repeats in other
empirical results we provide below 

diagnosis failed whenever the hypothesis chosen was

incorrect  although it was sucient for detection 

we intend to explore ways to improve

the accuracy of the hypotheses in future work  and therefore will not address this issue
in this paper anymore  the failure detection capabilities are a signicant improvement in
themselves  since the agents know with certainty that a failure has occurred  even if their
diagnosis of it is incorrect 
many social and physical failures are successfully captured using the team coherence
heuristic for monitoring selectivity  in fact  in our permutations of example    no matter
which one of the agents was the monitor  all failures to maintain relationship  i e   all physical
failures except for one in which the team remains in agreement  were detected reliably 
although sometimes diagnosis failed 

this result is especially surprising considering that

only a single agent did the monitoring  previous monitoring methods  condition monitors
and communications  were unable to detect the failures  despite being used by all three
agents  
tables   and   present further empirical results  on the basis of example   

table  

presents all failure permutations of example   in the same format as table    the normal or 

fly flight plan
wait at point  w  plan 

der of execution of these plans is as follows  all agents jointly execute the
 f  plan until they detect the way point  they then switch to the

in which the two attackers land while the scout continues to y ahead to identify the enemy 

   

firobust agent teams via socially attentive monitoring

the failures here are all on the part of the agents to detect the way point  and thus to switch
to the

w

plan 

case

 

actual executing plans

relationship failure

physical

 

attacker a 

attacker a 

scout a 

occurred

failure

 

w

w

w

 

 

 

f

w

w

 

a  vision fails

 

w

f

w

 

a  vision fails

 

f

f

w

 

a   a  vision fails

 

w

w

f

 

a  vision fails

 

f

w

f

 

a   a  vision fails

 

w

f

f

 

a   a  vision fails

 

f

f

f

 

a      vision fails

table    all failure permutations of the undetected way point scenario  example    

case

 

a  s hypothesized executing plans

relationship failure

detection

attacker a 

attacker a 

scout a 

detected 

class

w

w

w

 

true negative

 

f

w

f

 

true positive

 

w

f

w

 

 

true positive

false negative
false negative

 

 
 

f
w

f
w

f
w

 

f

w

f

 

true positive

 

w

f

f

 

true positive

 

f

f

f

 

true negative

table    attacker s  a   monitoring results in all permutations of example   

table   present the monitoring results for all permutations of example   

here the

attacker a  is monitoring the team using again a maximally team coherent hypothesis in
detecting failures  the results show that a  is successful in detecting all teamwork failures
but two  cases      highlighted in bold face  
these two false outcomes are both false negatives  in both these cases  the monitoring
attacker a  picked an incorrect hypothesis for the scout  since the scout s actions lead to
ambiguous interpretations  the scout is to y forward  to scout the enemy  if it detected the
way point  plan

w   but also if it did not  then it would be ying in formationplan f   the

use of the maximal team coherence heuristic causes a  to prefer a hypothesis in which the
scout is in agreement with the attackers when in fact it is not  for example  in case    the two
attackers have failed to detect the way point and are executing

f  observing the scout  the
f or w  however  believing

monitoring attacker a  is not sure whether the scout is executing
that the scout is executing

f results in a maximally coherent

team modeling hypothesis  all

the agents are in agreement   while believing that the scout is executing

   

w

results in a less

fikaminka and tambe

coherent hypothesis  thus a  selects a wrong hypothesis  which in this case fails to detect
the teamwork failure 
the maximal team coherence heuristic can detect failures despite using incorrect hypotheses  unfortunately  such hypotheses can also lead to false negatives as we have seen in
table    however  none of our experiments resulted in a false positive result  i e   a result
in which the system detected a failure but in reality none had occurred  thus the heuristic
provided sound results in these cases  we are able to formally prove this property holds in
general when the maximal team coherence heuristic is used 
first  we address a matter of notation  let an agent a monitor an agent b   which is
executing some plan p  

we denote by m  a  b  p   the set of agent modeling hypotheses

that a s agent modeling component constructs based on b  s observable behavior during the
execution of p   in other words  m  a  b  p   is a s set of all plans that match b  s observable
behavior 

note that when a monitors itself  it has direct access to its own state and so

m  a  a p  

 fp g  using the modeling notation  we make the following denitions which

ground our assumptions about the underlying knowledge used in monitoring 

denition   

agent modeling

given a monitoring agent a  and a monitored agent b   we say that a s
of agent b is

complete

if for any plan p that may be executed by b  p  

m  a  b p   

the set m  a  b p   will typically include other matching hypotheses besides the correct
hypothesis p  but is guaranteed to include p  following this denition of

individual

agent 

modeling completeness  we can dene group wide team modeling completeness 

denition   
a s

let a be an agent monitoring a team t of agents b         bn   we say that

team modeling

of the team t is

complete

if a s agent modeling of each of b         bn is

complete 
denition   is critical to guarantee the capabilities we will explore analytically in this
section and the next  it generally holds in our use of resl in the modsaf and robocup
domains  and we make it explicit here in service of applications of the techniques in other
domains 
armed with these denitions  we now formalize the failure detection capabilities suggested by the empirical evidence in theorem   

theorem    let a monitoring agent

a monitor a simple team t   if a s team modeling
of t is complete  and a uses a maximally team coherent hypothesis for detection  then the
teamwork failure detection results are sound 

proof 

we will show that if no failure has occurred  none will be detected  and thus that any

failure that is detected is in fact a failure  let a            an be the agent members of t   each
agent ai is executing some plan pi     i  n   thus collectively  the group is executing

 p            pn    if no failure has occurred  then all the agents are executing the same plan

p   

i e    i  pi   p    since a s team modeling is complete  the correct hypothesis  p            p   
is going to be in the set of team modeling hypotheses h  

since it is a maximally team 

coherent hypothesis  either it will be selected  or that a dierent hypothesis

coherence level

of the same

will be selected  any hypothesis with the same coherence level as the correct

one implies no failure is detected  thus the detection procedure is sound 

   

firobust agent teams via socially attentive monitoring

despite uncertainty in the knowledge used  sound failure detection can be guaranteed using
the maximal team coherence heuristic 

this is one answer to the monitoring selectivity

problem  however  as we have seen in table    some failures may pass undetected using this
heuristic  i e   it may result in false negatives  
may therefore unfortunately be

complete guaranteed

incomplete 

detection using maximal team coherence

we may prefer our monitoring system to be

to detect all teamwork failures 

incoherence

we therefore experimented with the maximal team 

heuristic  the inverse of

the maximal team coherence heuristic  this heuristic prefers hypotheses that suggest
failures  rather than less 

more

table   gives the monitoring attacker a  s view of the team 

incoherent

similar to table    but using a maximally team 

hypothesis  it shows that indeed

using a maximally team incoherent hypothesis will not lead to the false negative detections
in cases   and    in contrast to these cases in table    
case

relationship failure

detection

attacker a 

scout a 

detected 

 

class

 

w

attacker a 

false positive

 

f

h

w

 

true positive

 

w

f

f

 

true positive

f

f

w

 

true positive

 

a  s hypothesized executing plans

 
 

h

f

w

h

f

 

true positive

 

f

h

w

 

true positive

 

w

 

f

f

f

f

 

w

 

true positive

false positive

table    attacker s  a   monitoring results in all permutations of example    using team 

incoherence 

guided by these results  we formally show that the team incoherence heuristic leads to
a detection procedure that is

complete 

theorem    let a monitoring agent a monitor a simple team t   if the a s team modeling
of t is complete  and a uses a maximally team incoherent hypothesis for detection  then the
teamwork failure detection results are complete 
proof  analogous to that of theorem    the proof is provided in appendix a 
however  these successes are oset by false positive outcomes in cases   and   of table    in
these cases  no failures have occurred  but the monitoring system falsely reported detected
failures  in practice  this may lead to costly processing of many false alarms 
ideally  the detection capabilities should be sound

and

complete  unfortunately  we can

show that no coherence based disambiguation scheme exists that results in both sound and
complete detection  we show in theorem   that to provide sound and complete detection  a
disambiguation method will have to be inconsistent  given the same set of possible matching
hypotheses  it will have to sometimes rank one hypothesis on top  and sometimes another 

theorem    let

h be a complete team modeling hypotheses set  modeling a simple team 
there does not exists a disambiguation scheme s that     uses coherence alone as the basis

   

fikaminka and tambe

for disambiguation of h   and     is deterministic in its selection  and     results in sound
and complete failure detection 
proof 

let s be a disambiguation scheme that leads to complete and sound detection and

uses only knowledge of the coherence of the hypotheses in selecting a disambiguated hypothesis  suppose for contradiction that it is deterministic  and thus consistent  in its selection
of an hypothesis out of h   i e   given h   a set of candidate hypotheses  it applies some
deterministic procedure to choose one hypothesis based on its coherence 

since it does

not use any other knowledge outside of the coherence of the candidate hypotheses  given
the same set of candidates  it will always choose the same hypothesis 

let am be the

monitoring agent using s   let b be a monitored agent  whose actions are identical when
executing team plans p    p   
p    m  am   b  p   

 

thus  am cannot determine whether b is executing p  or

m  am   b  p   

 

fp    p  g  if am and b are both executing p    am  s

h

 

f p    p    

hypotheses set is

 p    p   g

since s leads to complete and sound detection  it will choose  p    p     now  when am and
b are executing p  and p    respectively  the matching hypothesis set is again h as dened

above  but now s must select  p    p     since the same set of candidate hypothesis h was
used in each case  and no other information was supplied  s must be non deterministic in
its selection of a disambiguated hypothesis  contradicting the assumption 
the empirical and analytical results show that our use of a single disambiguated hypothesis leads to improved  but imperfect  failure detection results  compared to the monitoring
conditions and communications previously used  the empirical results in tables       and
  establish the benets of the teamwork monitoring technique  most physical failures were
detected  however  the analytical results  theorems          show that the results are less
than perfect  the algorithms are either sound or complete  but not both  for complete monitoring  we would require additional procedures that can dierentiate the true positives from
the false ones  e g   by focused communication  these procedures are often very expensive 
we can reduce the need for costly verication by letting go of our insistence on a single
hypothesis  focusing instead of maintaining two hypotheses  a maximally coherent hypothesis and a maximally incoherent hypothesis 

table   shows a portion of the full set of

team hypotheses available when the attacker a  is monitoring the team  the total number
of hypotheses presented in the table is     with as many as   co existing in a single case 
and thus maintaining a full set of hypotheses would be expensive  however  the two inverse
heuristicsteam coherence and incoherencerepresent two extremes of the space of these
hypotheses 

if they agree that a failure exists  then a failure actually occurred  since the

team coherent hypothesis guarantees soundness  theorem     if they agree that no failure
exists  then no failure took place  since the team incoherent hypothesis guarantees completeness  theorem     if they disagree  i e   the team coherent hypothesis does not imply
a failure  but the team incoherent hypothesis does   the monitoring system cannot be sure
either way  and must revert back to verication 
this revised detection algorithm oers signicant computational savings compared to the
single team incoherent hypothesis approach  it is complete and unsound  but signicantly

   

firobust agent teams via socially attentive monitoring

case

 
 

 

 
 
 

 

 
 

a  s hypothesized executing plans

relationship failure

detection

scout a 

detected 

class

h

f

 

false positive

h

w

 

false positive

w

w

f

 

false positive

w

w

w

 

true negative

f

h

f

 

true positive

f

h

w

 

true positive

f

w

f

 

true positive

f

w

w

 

true positive

w

f

f

 

true positive

w

f

w

 

true positive

f

f

w

 

true positive

f

f

f

 

false negative

w

h

f

 

true positive

w

h

w

 

true positive

w

w

f

 

true positive

w

w

w

 

false negative

f

h

w

 

true positive

attacker a 

attacker a 

w
w

f

h

f

 

true positive

f

w

w

 

true positive

f

w

f

 

true positive

w

f

f

 

true positive

w

f

w

 

true positive

f

f

w

 

false positive

f

f

f

 

true negative

table    a portion of the attacker s  a   monitoring hypotheses and implied results when
no ranking is used to select a single hypothesis for each case 

reduces the need for verication  since at least when the team coherent hypothesis implies
failures  verication is not necessary  it requires representing only two hypotheses  and is
thus still computationally cheaper than maintaining an exponential number of hypotheses 
for example  using a maximally team incoherent hypothesis on permutations of example
  results in a need to verify in all eight cases as we have seen      however  when we combine
such an hypothesis with a maximally team coherent hypothesis  e g   as in table     we only
need to verify four        of the cases  in cases            there is agreement between the
two hypotheses that a failure has occurred  and thus no verication is required 
a monitoring agent can therefore address the monitoring selectivity problem by balancing
its resource usage against the guaranteed performance of the monitoring algorithm used 
either of the simpler single hypothesis algorithms would utilize only one hypothesis in each
case  with detection capabilities that are guaranteed to be sound or complete  but not both 
in the more complex algorithm  two hypotheses would be reasoned about in each case  and

   

fikaminka and tambe

the algorithm would be complete and require verication in fewer cases compared to the
simple hypothesis complete algorithm 

   monitoring selectivity in distributed teamwork monitoring
this section focuses on monitoring selectivity when exploiting a key opportunity for execution monitoring in multi agent environmentsit is not only the monitored agents that
are distributed  but the monitoring agents can be distributed as well  we begin with the
simple scheme of selecting a single maximally team coherent hypothesis  since centralized
teamwork monitoring was successful in addressing all permutations of example    we focus
here on the permutations of example    table     in which centralized teamwork monitoring
by the attacker resulted in false negative detections  cases     in table    
in a distributed teamwork monitoring scheme  not only will a single attacker monitor
its teammates  but the scout  and the other attacker  will also engage in monitoring  table
  presents the monitoring results of the same failure permutations  with the scout as the
monitoring agent 

we nd that the scout successfully detects the two failure cases that

the attacker failed to detect  compensating for the attackers  monitoring mistakes  furthermore  since the scout used the the maximal coherence heuristic  detection is sound and no
verication is required  the reason for the scout s success is that the attackers  actions in
this case  although ambiguous  do not support any hypothesis that can be matched to the
scout s plan  in other words  regardless of what plan the attackers are executing in these
two cases  it is dierent that the plan executed by the scout 
case

relationship failure

detection

detected 

class

w

 

true negative

f

 

true positive

f

w

 

true positive

f

w

 

true positive

h

h

f

 

true positive

f

h

f

 

true positive

 

h

f

f

 

true positive

 

f

f

f

 

true negative

 

a  s hypothesized executing plans
attacker a 

attacker a 

scout a 

 

w

w

 

f

w

 

w

 

f

 
 

table    scout s  a   monitoring results in all permutations of example    using teamcoherence 

thus if all agents engaged in monitoring in permutations of example    detection would
be sound and complete  in all actual failure cases  and only in those  there would at least one
team member who detects the failure  we attempt to formally dene the general conditions
under which this phenomenon holds 

denition   

we say that two team plans p    p    have

observably dierent roles

r    r  if

given an agent b who fullls the roles r    r  in the two plans  resp   any monitoring agent
a  dierent than b   will have m  a  b  p      m  a  b  p   

observably dierent roles in p  and p    and call b a

   

 

key agent 

  

we then say that b has

firobust agent teams via socially attentive monitoring

intuitively  b is a key agent that has observably dierent roles in the two plans if a
monitoring agent can dierentiate between b  s behavior in executing p  and in executing
p    for instance  both attackers have observably dierent roles in

w

 in which they land  

f

 in which they y  and

however  they do not have observably dierent roles in

both of which require them to land  the scout has observably dierent roles in
and

h

w and h 
w  ying 

 landing  

the key agent is the basis for the conditions under which a self monitoring team will
detect a failure with each agent using only team coherence  we rst prove a lemma on the
conditions in which a single given agent will detect a failure  we then use this lemma to
prove the conditions under which at least one agent in a given team will detect a failure 

lemma    suppose a simple team

t is self monitoring  all members of the team monitor
each other  using the maximally team coherent heuristic  and under the assumption that for
each agent  team modeling is complete   let a    a  be monitoring agents who are members of
t and are executing p    p    respectively  a  would detect a failure in maintaining teamwork
relationships with an agent a    if a  is a key agent in p    p   

proof 

see appendix a 

a  knows that it is executing p   

if a  is executing p    and is a key agent in p  and p   

then a  is guaranteed to notice that a dierence exists between itself and a    since a  is
acting observably dierent than it would if it had been executing p    note  however  that
a  may or may not detect this dierence  since from a   s perspective  a   s behavior may

or may not be explained by p    a  will detect a dierence only if a   s roles in p  and p 
are also observably dierent  however  since a  has detected the failure  it can now alert
its teammates  diagnose the failure  or choose corrective action 
if we want to guarantee that a teamwork failure will always be detected by at least
one agent  we must make sure that in each possible combination of plans  there has to be
at least one key agent whose roles are observably dierent 

the lemma shows that other

agents monitoring this agent will notice a failure if one occurs  to this aim  we dene an
observably partitioned set of plans employed by a team 

denition   

a set p of team plans is said to be

observably partitioned

if for any two plans

pi   pj   p there exists a key agent aij   the set of these aij agents is called the

set of p  

key agents

for instance  the set of team plans our helicopter pilots team has been using in the
examples  fly flight plan  f  

wait at point  w   ordered halt  h   and join scout
 j   is observably partitioned  the attackers land in w and h  but y in f and j  the scout
lands in j and h  but ies in w and f  table   shows which agents have observably dierent
roles in any two plans in the set  for instance  by nding the cell at the intersection of the

h

row and the

w

column  we nd that the scout has observably dierent roles in these two

plans  indeed  the scout lands when a command is received to halt execution  h   but ies
out to scout the enemy s position when executing

w 

here  since all agents have observably 

dierent roles in at least two plans  the key agents set of  
of the teamattackers and scout 

   

w   f   h  j  

includes all members

fikaminka and tambe

fly flight plan  f 

wait at point  w 

ordered halt  h 

 

attackers

attackers

scout

attackers

 

scout

scout and attackers

f
w
h
j

join scout  j 

attackers

scout

 

attackers

scout

scout and attackers

attackers

 

table    observable partitioning of the helicopter pilot team in modsaf 

theorem    if a simple team     employs an observably partitioned set of team plans o 

and all team members monitor members of the key agents set of o      using complete teammodeling and     maximally team coherent hypotheses  then the teamwork failure detection
results are sound and complete 
proof 

from theorem   we know that detection would be sound  to show that it is complete 

we will prove at least one agent will detect a dierence between itself and others whenever
team members are not all executing the same plan  i e   a failure is occurring   suppose the
team is currently divided on the team plans that must be executed  i e   there are agents
ai   aj in the team that are executing team plans pi   pj   respectively  such that pi    pj  

thus a failure has occurred  let k be the key agents set of o   since the team is observablypartitioned  for pi   pj there exists at least one key agent a    k   there are three cases 

case  i  

a  is executing pi   in this case any agent executing pj would detect a dierence

with a  and would therefore detect the failure  lemma    

case  ii  

a  is executing pj   in this case any agent executing pi would detect a dierence

with a  and would therefore detect the failure  lemma    

case  iii  

a  is executing some other plan q  its roles must be observably dierent in q

and pi   or in q and pj  or in both   and thus any agent executing pj and or pi would detect
the failure  the case that a   s roles are not observably dierent in q and pi

and

in q and

pj is impossible  since then for a monitoring agent am
m  am   a   pi     m  am   a   p j    fqg     

contradicting a  being a key agent for pi   pj  
since in all three cases  at least one agent would detect a failure where one occurred 
therefore  failure detection is complete  since it is also sound as we have seen  detection is
sound and complete 
the theorem shows that distributed teamwork monitoring can result in

sound and complete
only the key

failure detection  while using a simple algorithm  each team member monitors

agents     using a maximally team coherent

hypothesis  if it detects a failure  then certainly

one has occurred  if no agent detects a failure  then indeed no failure has occurred 
this simple distributed algorithm  with its attention focusing features and guaranteed
soundness and completeness contrasts with the more complex centralized algorithm which
we discussed in the previous section  section     the algorithm s eectiveness relies on the
   if the monitoring team member does not know who the key agents are  but knows they exist  it can
monitor all other team members  this increases monitoring  but sound and complete failure detection
is still guaranteed 

   

firobust agent teams via socially attentive monitoring

condition of an observably partitioned set of plans  and on the distribution of the monitoring 
a corollary of theorems   and   is that if key agents are not available in the distributed
case  failure detection is either sound or complete  but not both  and even when key agents
are available  centralized teamwork monitoring is still not complete and sound 
fortunately  observable partitioning is not a dicult property to design  teams are very
often composed such that not all agents have the same role in the same plan  and in general 
roles do have observable dierences between them  for instance  our helicopter pilot team
in the modsaf domain typically executes a set of plans with this property  as table  
demonstrates 
if the team  however  is not observably partitioned  there may be a case where two agents
are each executing a dierent plan  but no agent will be able to detect it using the teamcoherence heuristic  the minimal case where this occurs is when two agents  a  and a  are
executing plans p  and p    respectively  and p  and p  are not observably dierent  such
that
m  a    a   p      m  a    a   p   

 

fp    p  g

this will result in a  and a  each believing that the other is in agreement with them  a
check for such a situation can be made a part of the plan design process  marking

points

risky

in the execution in which detection is either sound or complete  theorem     and

verication  e g   by communications  can be prescribed pro actively  or  the check could
be inserted into the protocol for run time analysisthe agent would simulate the other s
hypotheses matching their own actions  and detect risky points dynamically 

   using socially attentive monitoring in an o line conguration
to further demonstrate the generality of our socially attentive monitoring framework  this
section examines re use of teamwork monitoring in domains in which diagnosis and recovery
from every failure are infeasible during execution  examples of such domains include team
sports  military human team training  volpe  cannon bowers    salas         and other
multi agent domains 

the dynamic nature of the domain  hard real time deadlines  and

complexity of the agents involved  e g   human team members  make diagnosis and recovery
dicult 

even if a failure can be diagnosed  it is often too late for eective recovery 

in

such environments  the monitoring agent is often concerned with trends of performance 
this information is important for long term design evaluation and analysis  and need not
necessarily be calculated on line  the results of the analysis are meant as feedback to the
agents  designer  coach or supervisor  for humans  
to this end  we are developing an o line socially attentive monitoring system called
teamore  teamwork monitoring review   teamore currently uses execution traces of

the monitored agents to perform the monitoring  rather than using plan recognition  thus it
does not need to worry about the uncertainty in plan recognition  nor about real time performance  instead  it knows with certainty each agent s plans during execution  teamore
accumulates several quantitative measures related to teamwork  including the average timeto agreement measure  ata  for short   and a measure of the level of agreement in a team 
these build on the failure detection algorithm  but aggregate failures in quantitatively  we
focus here on the ata measure 

   

fikaminka and tambe

teamore denes a

switch

as the time interval beginning at the point where any team 

member  at least one  selects a new team plan for execution by the team  and ending
at the point where the team is again in agreement on the team plan being executed 

in

perfect teamwork  all team members select a new team plan jointly  and so always remain
in agreement 

in more realistic scenario  some agents will take longer to switch  and so

initially a teamwork failure will occur  the rst team member to select a new plan will be
in disagreement with some of its teammates  until either it rejoins them in executing the
original plan  or they join it in selecting the new plan  such a switch begins with a detected
failure and ends when no more failures are detected 
figure   shows an illustration of a switch  the three agents begin in an initial state of
agreement on joint execution of plan    lled line   agent   is the rst agent to switch to
plan    dotted line   and is followed by agent    and nally agent   

the switch is the

interval which begins at the instance agents   selected plan    to the time all three agents
regained their agreement  but this time on plan    

a switch
legend 
plan  

agent  

plan  
agent  
agent  
time
figure    an illustration of a switch  the three agents switch from plan   to plan   
teamore keeps track of the lengths of time in which failures are detected until they

are resolved  the ata measure is the average switch length  in time ticks  per a complete
team run  e g   a mission in modsaf  a game in robocup   a perfect team would have
all switches of length zero  and therefore an ata of    the worst team would be one that
from the very beginning of their task execution to the very end of it  would not agree on
the team plan being executed  for instance  each robocup game lasts for      ticks  the
worst possible team would have only one switch during the game  of length       thus the
ata scale in robocup goes from    perfect  to       worst  
we used the ata measure to analyze a series of games of our two robocup simulationleague teams  isis    and isis     marsella et al         against a xed opponent  andhill   
 andou        

in these games  we varied the use of communications by our teams to

evaluate design decisions on the use of communications  in approximately half of the games 
players were allowed to use communications in service of teamwork  in the other half  all
communications between agents were disabled  isis    played approximately    games in
each settings  and isis    played    games in each communication settings 
table   shows the mean ata values over these games  for two sub teams  each having
three members  of isis    and isis     ata values are calculated separately for each subteam   the rst column shows which sub team the results refer to in each row  the second

   

firobust agent teams via socially attentive monitoring

columns shows the mean ata for each sub team  when no communications were used  the
third column shows the mean ata when communications were used  the next column shows
the size of the ata reductionthe drop in the mean ata values when communications are
introduced 

the last column shows the probability of the null hypothesis in a two tailed

t test of the dierence in the ata means  this is the probability that the dierence is due
to chance  thus smaller numbers indicate greater signicance 

isis

mean ata

mean ata

ata

t test prob 

sub team

no comm 

comm 

reduction

null hypothesis

     

    

     

    e   

    goalies
    defenders

    

    

     

   e   

    goalies

     

    

    

    e   

    defenders

     

    

    

    e  

table    average time to agreement  ata  for games against andhill    

clearly  a very signicant dierence emerges between the communicating and noncommunicating versions of each sub team 

the ata values indicate that sharing infor 

mation by way of communications signicantly decreases the time it takes team members
to come to agreement on a selected plan  this result agrees with our intuitions about the
role of communications  and in that sense  may not be surprising 
however  the ata reduction magnitudes indicate that isis    may be much less sensitive to loss of communications than isis     the dierences in ata values for isis    are
approximately triple  nearly four times  as great as for isis    

our explanation for this

phenomenon is that isis    is composed of players with improved capabilities for monitoring the environment  such that they have better knowledge of the environment  

isis   

is therefore not as dependent on communications as are teams  such as isis     composed
of players with lesser environment monitoring capabilities  isis    players are better able
to select the correct plan without relying on their teammates 

thus  they would be able

to maintain the same level of performance when communications are not used  in contrast 
isis    players rely on passing information to and from each other  monitoring each other 
through communications  and so took much longer to establish agreement when communications were not available 
we can validate the hypothesis suggested by ata measurements by looking at the overall
team performance in the games  measured by the score dierence at the end of the game 
table    shows the mean score dierence from the same series of games against andhill    
the rst column lists the communications settings  with or without  
third columns show the

mean

the second and

score dierence in the games for isis    and isis    

the

bottom row summarizes the results of t tests run on each set of games  to determine the
signicance level of the dierence between the mean score dierences  the score dierence
results corroborate the ata results  while the dierence in mean score dierence is indeed
statistically signicant in isis    games  it is not signicant in isis    games  this supports
our explanation that the more situationally aware isis    is indeed better able to handle
loss of communications than isis    

   

fikaminka and tambe

isis   

isis   

communication used

     

     

communication not used

     

     

t test p null hypothesis

p      

p     

table     isis    and isis    mean score dierence against andhill     with changing communications settings

the general lesson emerging from these experiments is that a trade o exists in addressing the monitoring selectivity problem  the knowledge that is maintained about teammates
 here  via communications  can be traded  to an extent  with knowledge maintained about
the environment 

a designer therefore has a range of alternative capabilities that it can

choose for its agents  dierent domains may better facilitate implicit coordination by monitoring the environment  while others require agents to rely on communications or explicit
knowledge of team members to handle the coordination 
the ata results support additional conclusions  especially when combined with a general
performance measure such as the score dierence 

to illustrate  consider the plots of the

actual data from these games  figure   plots all the ata values for all four variants  for
the goalies sub team 

the graph plots approximately    data points 

we see in figure

  that when communications are used  isis    s ata values are still generally better than
isis    s ata without communications  thus  despite its importance  individual situational
awareness is not able to fully compensate for lack of communications 

average time to agreement  ata 

  
  
  
  
  

  
  
  
  
 
isis   comm 

isis   comm 

isis   no comm  isis   no comm 

goalies sub team
 a  ata values for goalies subteam

figure    ata values for the goalies sub teams in games against andhill    

   

firobust agent teams via socially attentive monitoring

teamore demonstrates the reuse of the teamwork monitoring techniques developed in

earlier sections in an o line conguration  the designer of isis    should set its agents to
use communications  since those will have signicant improvement on the score dierence 
in contrast  with or without communications  isis    players are able to maintain their
collaboration  thus if communications takes precious resources  it can be relatively safely
eliminated from the isis    agents  design  and the development eorts can be directed at
some other components of the agents 

   beyond teamwork
we have presented a general socially attentive monitoring framework to detect failures in
maintaining agreement on joint team plans 

however  eective operation in teams often

relies on additional relationships  which we briey address in this section 

    a richer agreement model  agreeing to disagree
the teamwork model requires joint execution of team plans  in service of such agreed upon
joint plans  agents may sometimes agree to execute dierent sub plans individually  or split
into sub teams to execute dierent sub team plans  two examples may serve to illustrate 

example   

in the modsaf domain  helicopters engage the enemy by repeatedly following

masking    then popping up  unmask 

the following three steps  hiding behind a hill or trees  

ing   

then shooting missiles at the enemy  and back to hiding  in some variations of this

plan  they are required to make sure that no two helicopters are shooting at the same time 
of course  due to limits of communications  helicopters do fail and unmask at the same time 

example   

in the robocup domain  our    players in both isis    and isis     marsella

et al         are divided into four sub teams  mid elders  attackers  defenders  and goalies
 the goalie and two close defenders   this division into sub teams is modeled by the agents

play team plan  see figure     mid elders
must select the midfield plan  goalies must select the defend goal plan  etc  again  ideally
an attacker would never select any other plan but attack  a defender would select no other
plan but defend  etc  however  due to communication failures  players may sometimes
selecting one of four team plans in service of the

accidently abandon their intended sub team  and execute a team plan of another sub team 
 wingame 
 play 

 attack 
 simple
advance 
     
scoregoal

 flank
attack 
   
pass

 interrupt 
   

 defend 
      

 midfield 
           

 defendgoal 

 careful
defense 
intercept

kickout

 simplegoal
defense 
     
reposition

figure    a portion of the plan hierarchy used by isis robocup agents 

in both of these examples  certain dierences between agents are agreed upon and are a
sign of correct execution  not of failure  indeed  it is the lack of dierence in selected plans

   

fikaminka and tambe

that would indicate failure in these cases  we use the term

mutual exclusion coordination

refer to these relationships  in example    ideally no two pilots are executing the
plan at the same time 

to

shooting

in example    no two members of dierent sub teams  e g   an

attacker and a defender  are executing the same plan in service of

play  e g   defend  

as the

examples demonstrate  there is a clear need for monitoring mutual exclusion coordination 
our results of previous sections are re used in service of socially attentive monitoring of
mutual exclusion relationships  they require a transformation both in implementation and
theory  the hierarchies are compared in the usual manner  except that failures are signied
by equalities  rather than dierences  for instance  if an attacker is staying in the team s
own half of the eld  its teammates may come to suspect that it mistakenly defected the
attackers  sub team and believes itself to be a defender 
the analytical results are inverted as well  the maximal team coherence heuristic will
now lead to completeness  since it prefers hypotheses that contain equalities among agents 
which are failures in mutual exclusion coordination  the maximal team incoherence heuristic will now lead to sound detection  as it prefers hypotheses that imply no equalities have
occurred  these properties can be proven formally 

theorem    let a monitoring agent

a monitor mutual exclusion relationships in a group
of agents g  if a s modeling of g is complete  and a uses a maximally team incoherent
hypothesis for detection  then the failure detection results are sound 

proof 

provided in appendix a 

theorem    let a monitoring agent

monitor mutual exclusion relationships in a group
of agents g  if a s modeling of g is complete  and a uses a maximally team coherent
hypothesis for detection  then the failure detection results are complete 
proof 

a

provided in appendix a 

thus in mutual exclusion relationships  as in teamwork relationships  guaranteed failuredetection results may still be provided despite the use of limited  uncertain knowledge
about monitored agents  the centralized teamwork monitoring algorithms can now be easily transformed for monitoring mutual exclusion relationships  unfortunately  the results in
the distributed case  theorem    cannot be so easily transformed  since they rely on the
property of observable partitioning  which is associated with dierences  not with equalities 
we leave this issue for future work 

    monitoring using role similarity relationships
this section applies socially attentive monitoring to role similarity relationships  for monitoring individual performance within teams  in particular  in service of team plans agents
may select individual sub plans  which do not necessitate agreement by team members  but
are constrained by the agents  roles 

fly flight plan

for instance  in service of executing the team plan

 figure    pilots individually select their own individual plans which set

the velocity and heading within the constraints of the formation and ight method specied
in the mission 
role similarity relationships specify the ways in which given individual plans are similar 
and to what extent 

two agents of the same role who are executing dissimilar plans can

   

firobust agent teams via socially attentive monitoring

be considered to be in violation of the role similarity relationships  this enables a sociallyattentive monitoring system to detect failure in role execution  to monitor individual plans
the agent is executing  it compares its selection with that of other agents of

the same role 

similarly to the method we used for teamwork  if the plans are considered similar by the
role similarity relationship model  no failure is detected 

otherwise  a failure may have

occurred  and the diagnosis component is called to verify it and provide an explanation 
let us illustrate with a failure from the modsaf domain which our system was able to
detect using the role similarity relationship 

example   

a team of three helicopters was to take o from the base and head out on a

mission  however  one of the pilot agents failed to correctly process the mission statement 
it therefore kept its helicopter hovering above the base  while its teammates left to execute
the mission by themselves 
this failures was detected using role similarity relationship monitoring  the agreed upon
team plan was selected by all the agents  and so no problem with teamwork relationship was
detected  this team plan involved each agent then selecting individual methods of ight 
which determine altitude and velocity 

here the agents diered 

the failing helicopter

remained hovering  while its teammates moved forward  using a role similarity relationship 
the failing helicopter compared its own selected plan to that of its teammate  who shared its
role of a subordinate in the formation   and realized that their plans were dissimilar enough
to announce a possible failure 
unfortunately  the actual similarity metrics seem to be domain  and task specic  and
thus are not as easy to re use across domains  furthermore  detected failures are not necessarily real failures  nor do all detected failures have the same weight 

we are currently

investigating ways to address these challenging issues 

   related work
our investigation of socially attentive monitoring  and the relationship between knowledge
maintained of agents  states and monitoring eectiveness builds on research in dierent subelds of multi agent systems  we address these sub elds in this section  and explain how
our investigation is related to existing literature 

    related work on teamwork
previous work in teamwork has recognized that monitoring other agents is critical to teams 
past investigations have raised the monitoring selectivity problem  but have not addressed
it in depth  building upon these investigations  this paper begins to provide some in depth
answers to this problem 
the theory of sharedplans  grosz   kraus              touches on the teamwork monitoring selectivity problem in several ways  but provides only some initial answers  first  the
theory requires agents to know that their teammates are capable of carrying out their tasks
in the team 

the authors note that agents must communicate enough about their plans

to convince their teammates of their ability to carry out actions  grosz   kraus       
p        second  the theory requires agents to have mutual belief in the shared recipe  a

   

fikaminka and tambe

state that requires agents to reason to innite recursion about other agent s beliefs 

un 

fortunately  attainment of mutual belief is undecidable in theory  halpern   moses       
and hence must be approximated in practice  jennings        rich   sidner         such
approximations may still impose strong monitoring requirements  third  theory introduces
the intention that construct in service of coordination and helpful behavior  implying monitoring of others  progress to assess the the need for such behavior  grosz   kraus       
axiom a  a   

fourth  sharedplans requires that intentions of an agent must not con 

ict  grosz   kraus        axiom a    and since some of these intentions  in particular 
intentions that  may involve the attitudes of other agents  some monitoring of others to
detect and avoid conicts is implied  the authors point out that while theoretically all such
conicts can be detected  this is infeasible in practice  grosz   kraus        p        they
suggest that conict detection and prevention be investigated in a problem specic manner
within the minimal constraints  i e   monitoring for capabilities  mutual belief  progress  lack
of conicts  provided by the sharedplans framework  p      and      
joint intentions  levesque et al         cohen   levesque        requires an agent who
privately comes to believe that a joint goal is either achieved  unachievable  or irrelevant 
must commit to having the entire team mutually believe it to be the case  as in the theory
of sharedplans  joint intentions  use of mutual belief can only be approximated in practice 
and imposes strong monitoring requirements  thus  the monitoring selectivity problem is
raised for practical implementations of joint intentions 
jennings has hypothesized that two central constructs in cooperative multi agent coordination are

commitments

made by the agents  and

conventions  rules used to monitor these

commitments  jennings         such conventions are used to decide what information needs
to be monitored about agents  and how it is to be monitored  for instance  a convention may
require an agent to report to its teammates any changes it privately detects with respect
to the attainability of the team goal 

jennings raises the monitoring selectivity problem

and provides an example of specic conventions for high  and low bandwidth situations in
which some knowledge is not communicated to all agents if the bandwidth is not available 
however  jennings does not explore in depth the question of how such conventions are selected  and what are the trade os and guarantees associated with the selection of particular
conventions  for instance  there are no guarantees on the eects of using the low bandwidth
convention in the example 
the theoretical investigations described above all raise the monitoring selectivity problem  implicitly or explicitly   our work builds upon these to address this problem in depth 
in the context of socially attentive monitoring in teams  this paper reports on soundness
and or completeness properties of teamwork relationship failure detection that can be analytically guaranteed  despite uncertainty in knowledge acquired about monitored agents 
the analytical guarantees are applicable to plan recognition and communications  and are
corroborated by empirical results 
building on theoretical work  practical teamwork systems include  jennings        rich
  sidner        and  tambe        

jennings  investigation of the joint responsibility

teamwork model in grate   jennings        builds on joint intentions  and similarly to
our own implementation  requires agents to agree on the team plans which are to execute 
however  grate  is used in industrial settings in which foolproof communications can
be assumed  jennings        p 

      and thus only passive monitoring  via communica 

   

firobust agent teams via socially attentive monitoring

tions  is used  although jennings provides an evaluation of grate  s performance with
respect to communication delays  no guarantees are provided with respect to failure detection  grate  maintains knowledge about other agents through acquaintances models 
which are used to keep track of what team members  capabilities are  in service of forming
teams   however  the question of how much knowledge should be used in these models is
left unaddressed 
rich and sidner investigate collagen in a collaborative user interface system  in
which communications are reliable  rich   sidner         however  from a human usability
perspective  limiting the amount of communications is still desirable 

to address this is 

sue  recent empirical work by lesh  sidner and rich        utilizes plan recognition in
collagen  the focus of that work is on using the collaborative settings to make the
plan recognition tractable 

for instance  ambiguities in plan recognition may be resolved

by asking the user for clarication  work on collagen does not investigate how much
knowledge is to be maintained for eective collaborative dialogue with the user  in contrast 
we are able to provide guarantees on the failure detection results of our algorithms  also 
analysizing the dialogue plans for

risky points

may allow systems such as collagen to

decide whether to use communications for clarication regardless of plan recognition ambiguity 
steam  tambe        maintains limited information about the ability of team members
to carry out their roles  steam also allows team members to reason explicitly about the
cost of communication in deciding whether to communicate or not  our work signicantly
extends these capabilities via plan recognition  and provides analytically guaranteed faultdetection results  furthermore  our teamwork failure detection capabilities can be useful to
trigger steam s re planning capabilities 

    related work on coordination
huber        investigated the use of probabilistic plan recognition in service of active teamwork monitoring  motivated by the unreliability and costs of passive communications based
monitoring in military applications  washington explores observation based coordination using markov models  washington         focusing on making the computations tractable  in
contrast to huber and washington  our work focuses on the monitoring selectivity problem 
we showed strengths and limitations of centralized and distributed approaches that guaranteed failure detection results using coherence based disambiguation of plan recognition
hypotheses 
durfee        discusses various methods of reducing the amount of knowledge that agents
need to consider in coordinating with others  the methods discussed involve pruning parts
of the nested models  using communications  using hierarchies and abstractions  etc  while
the focus of this work is on methods by which modeling can be limited  the focus of our
work is on the question of how much modeling is required for guaranteed performancethe
monitoring selectivity problem  we provide analytical guarantees on trade os involved in
using limited knowledge of agents for failure detection purposes 
sugawara and lesser        report on the use of comparative reasoning analysis techniques in service of learning and specializing coordination rules for a system in which distributed agents coordinate in diagnosing a faulty network  the investigation is focused on

   

fikaminka and tambe

optimizing coordination rules to minimize ineciency and redundancy in the agent s coordinating messages  upon detecting sub optimal coordination  via a fault model   the agents
exchange information on their local views of the system and the problem solving activity 
and construct a global view  they then compare the local view to the global view to nd
critical values attributes which were missing from the local view and therefore gave rise to
the sub optimal performance problem  these values and attributes are used in constructing
situation specic rules that optimize coordination in particular situations 

for example 

network diagnosis agents may learn a rule that guides them to choose a coordination strategy in which only one agent performs the diagnosis and shares its result with the rest of
the diagnosis agents  our work on socially attentive monitoring similarly uses comparison
between agents views to drive the monitoring process  however  our use of comparison is
a product of the relationship we are monitoring 

while sugawara and lesser s work can

be viewed as letting the agents incrementally optimize their monitoring requirements  our
results analytically explore the level of monitoring required for eective failure detection  in
dierent congurations  our teamwork monitoring technique addresses uncertainty in the
acquired information  and does not construct a global view of all attributes the systemas
that would be extremely expensive  instead  our technique focuses on triggering failure detection via contrasting of plans  then incrementally expanding the search for dierences in
the diagnosis process 
robotics literature has also raised the monitoring selectivity problem 

parker       

investigated the monitoring selectivity problem from a dierent perspective  for a formationmaintenance task  she empirically examined the eects of combining socially attentive information  which she referred to as local  and knowledge of the team s goals  and concludes
that the most fault tolerant strategy is one where the agents monitor each other as well as
progress towards the goals 

kuniyoshi et al 

 kuniyoshi  rougeaux  ishii  kita  sakane 

  kakikura        present a framework for cooperation by observations  in which robots
visually attend to others as a prerequisite to coordination  the framework presents several
standard attentional templates  i e   who monitors whom  they dene a team attentional
structure as one in which all agents monitor each other 

our work focuses on the mon 

itoring selectivity problem within socially attentive monitoring of teamwork relationships 
and provides analytical as well as empirical results  we treat the attentional templates as
a product of the relationships that hold in the system  our results show that monitoring in
teams may not necessarily require monitoring all team members 

    other related work
horling et al 

 horling  lesser  vincent  bazzan    xuan        present a distributed

diagnosis system for a multi agent intelligent home environment the system uses faultmodels to identify failures and ineciencies in components  and to guide recovery  schroeder
and wagner        proposed a distributed diagnosis technique in which cooperating agents
receive requests for tests and diagnoses  and send responses to other agents 

they each

construct a global diagnosis based on the local ones they produce and receivewith the
assumption that no conicts will occur 

frohlich and nejdl        investigates a scheme

in which multiple diagnosis agents cooperate via a blackboard architecture in diagnosing a
physical system  the agents may use dierent diagnosis models or systems  but a centralized

   

firobust agent teams via socially attentive monitoring

conict resolution agent is employed to handle any conicts in diagnoses found  all three
approaches do not address the monitoring selectivity problem 
there are a few social measures related to the ata  goldberg and mataric        in 

interference the amount of time robots
social entropy  bailey        to measure be 

vestigate a multi robot foraging task and measure
spend avoiding each other  balch        uses

havioral diversity

in multi agent tasks of soccer  foraging  and formation maintenance  both

investigations focus on characterizing heterogeneity in multi agent systems and its relation
to performance  in contrast  the focus of our work is on providing useful feedback to the
designer 

possible correlation between task performance and ata values remains to be

investigated 

   conclusions and future work
the work presented in this paper is motivated by practical concerns  we have begun our
investigation of the monitoring selectivity problem as a result of our observation that failures
continue to occur despite our agents  use of monitoring conditions and communications 
analysis of the failures revealed that agents were not suciently informed about each other s
state  while the need to monitor one s teammates has been recognized repeatedly in the past
 jennings        grosz   kraus        tambe         the monitoring selectivity problem
the question of how much monitoring is requiredremained largely unaddressed  jennings 
      grosz   kraus        
we provide key answers to the monitoring selectivity problem 

within the context of

socially attentive monitoring in teams  we demonstrate that teamwork relationship failures
can be detected eectively even with uncertain  limited  knowledge of team members  states 
we show analytically that centralized active teamwork monitoring provides failure detection
that is either complete and unsound  or sound and incomplete  however  centralized teamwork monitoring requires multiple hypotheses and monitoring of all team members 

in

contrast  distributed active teamwork monitoring results in complete and sound failuredetection  despite using a simpler algorithm and monitoring only key agents in a team 
using an implemented general framework for socially attentive monitoring  we empirically validate these results in the modsaf domain  we also provide initial results in monitoring mutual exclusion and role similarity relationships  and initial diagnosis procedures 
we further demonstrate the generality of the framework by applying it in the robocup
domain  in which we show how useful quantitative analysis can be generated o line  both
modsaf and robocup are dynamic  complex  multi agent domains that involve many uncertainties in perception and action 
we attempted to demonstrate how the results and techniques can be applied in other
domains 

we have explicitly pointed out necessary conditions for the theorems to hold 

such as observable partitioning and team modeling completeness  the presented diagnosis
algorithm is sensitive to the accuracy of the knowledge used  and may require assuming that
plans can be recognized as soon as they are selected  these conditions should be veried by
the designer in the target application domain  reactive plans  our chosen representation  are
commonly used in many dynamic multi agent domains  our focus on monitoring agreements
on joint plans stems from the centrality of similar notions of agreement in agent and human
teamwork literature  jennings        grosz   kraus        volpe et al         tambe        

   

fikaminka and tambe

we made several references to additional areas in which we would like to conduct further
investigations 

one important topic which we plan to investigate in depth is the strong

requirements of the distributed teamwork monitoring algorithm in terms of observability  in
order to provide its soundness and completeness guarantees  the distributed algorithm relies
on the ability of all team members to monitor the key agents  we are investigating ways
to relax this requirement while still providing guaranteed results  in addition  the diagnosis
procedures should be extended and formalized  and we would like to investigate ways to
alleviate the sensitivity of these procedures to the choice of team modeling hypothesis 

acknowledgments
this article is partially based on an aaai    paper  kaminka   tambe         and an
agents    paper  kaminka   tambe        by the same authors  this research was supported in part by nsf grant isi          and in part by afosr contract  f                we thank je rickel  george bekey  victor lesser  dan o leary  and david pynadath
for many useful comments  the anonymous reviewers have our thanks for helping us to crystallize our ideas and contributions in revisions of this paper 

appendix a  proofs
theorem        page       let a monitoring agent a monitor a simple team t   if a s
team modeling of t is complete  and a uses a maximally team coherent hypothesis for detection  then the teamwork failure detection results are sound 
proof 

we will show that any failure that occurs is detected  and thus that all failures will

be detected  let a            an be the agent members of t   each agent ai is executing some
plan pi     i  n  

thus collectively  the group is executing  p            pn   

if a failure

has occurred  then there are two agents ak   aj      j  k  n such that aj is executing plan
pj and ak is executing plan pk and pj    pk  

since a s team modeling is complete  the

correct hypothesis  p            pj           pk         pn   will in the set of team modeling hypotheses 
since a will choose a maximally team incoherent hypothesis  either it will choose the correct
hypothesis  which is more incoherent than a hypothesis implying no failure has occurred  or
that it will select a hypothesis with greater incoherence hypothesis  or equivalent level   in
any case  a failure would be detected  and the detection procedure is complete 

lemma    

   page       suppose a simple team t is self monitoring  all members of
the team monitor each other  using the maximally team coherent heuristic  and under the
assumption that for each agent  team modeling is complete   a monitoring agent a  who is a
member of t and is executing p  would detect a failure in maintaining teamwork relationships
with an agent a   also a member of t   executing a dierent plan p    if a  has an observably
dierent role in p  and p   

proof 

a  knows that it is executing p   

since all members of t monitor each other and

themselves  a  is monitoring a    who has an observably dierent role in p  and p    since a 
is executing p    and following the observably dierent role  p   
  m  a    a   p     therefore
from the perspective of a    it cannot be the case that it assigns p  in any
hypothesis  and therefore any

team modeling

agent modeling

hypothesis that a  has will have a  executing

   

firobust agent teams via socially attentive monitoring

p    and a  executing some plan other than p    in other words  from a   s perspective there is

no team coherent hypothesis  and so a dierence would be detected between a  and a   

theorem        page       let a monitoring agent a monitor mutual exclusion relation 

ships in a group of agents g  if a s modeling of g is complete  and a uses a maximally
team incoherent hypothesis for detection  then the failure detection results are sound 
proof 

we will show that if no failure has occurred  none will be detected  and thus that

any failure that is detected is in fact a failure 
g 

let a            an be the agent members of

each agent ai is executing some plan pi     i  n   thus collectively  the group is

executing  p            pn    if no failure has occurred  then each agent is executing a dierent
plan  i    j   pi    pj    since a s group modeling is complete  the correct hypothesis is
going to be in the set of group modeling hypotheses h   since it is a maximally incoherent
hypothesis  either it will be selected  or that a dierent hypothesis

level

will be selected 

of the same coherence

any hypothesis with the same coherence level as the correct one

implies no failure is detected  thus the detection procedure is sound 

theorem        page       let a monitoring agent a monitor mutual exclusion relation 

ships in a group of agents g  if a s modeling of g is complete  and a uses a maximally
team coherent hypothesis for detection  then the failure detection results are complete 
proof 

we will show that any failure that occurs is detected  and thus that the procedure

is complete  let a            an be the agent members of g  each agent ai is executing some
plan pi     i  n  

thus collectively  the group is executing  p            pn   

if a failure

has occurred  then there are two agents ak   aj      j  k  n such that aj is executing plan
pj and ak is executing plan pk and pj

 

pk  

since a s group modeling is complete  the

correct hypothesis  p            pj           pk         pn   will in the set of group modeling hypotheses 
since a will choose a maximally team coherent hypothesis  either it will choose the correct
hypothesis  which is more coherent than a hypothesis implying no failure has occurred  or
that it will select a hypothesis with greater coherence hypothesis  or equivalent level   in
any case  a failure would be detected  therefore  the detection procedure is complete 

appendix b  socially attentive monitoring algorithms
we bring here the algorithms  in pseudo code  for the resl plan recognition algorithm 
the comparison test supporting detection in both simple and non simple teams  and the
monitoring algorithms for the centralized and distributed cases 

b   resl
resl works by rst expanding the complete operator hierarchy for the agents being modeled  tagging all plans as non matching  all plans  preconditions and termination conditions
are agged as non matching as well  all plans  actions are set to be used as expectations
on behavior  after initializing the plan recognition hierarchy for each monitored agent  observations of an agent are continuously matched against the actions expected by the plans 
plans whose expectations match observations are tagged as matching  and these ags are
propagated along the hierarchy  up and down  so that complete paths through the hierarchy

   

fikaminka and tambe

are agged as matching or not  these paths specify the possible matching interpretations of
the observations  in addition  precondition and termination conditions are agged as true
or not  signifying the inferred appropriate belief by the modeled agents 

this process is

described in algorithm   

algorithm   resl s main loop  matching

observation and making inferences for a given

plan recognition hierarchy  a single agent  
  

get observations about agent

  

for each plan that has a set of expected observations 
 a  compare observations to expectations
 b  if succeed  ag plan as matching successfully  otherwise ag plan as failing to match

  

for each plan that is agged as matching successfully
 a  flag its parents as matching successfully    propagate matching

  

for each plan whose children  all of them  are agged as failing to match
 a  flag it as failing to match    propagate non matching

b   detection of failure  centralized and distributed teamwork monitoring
algorithm   shows how comparison of hierarchical plans is carried out  we limit ourselves
here to simple teams  the algorithm accepts as input two sets of hierarchical plan hypotheses  and their two associated agents  for clarity  the algorithms assume only two agents 
the generalization to n agents is straightforward   the algorithm also accepts a policy ag 

policy 

an

optimistic

policy causes the algorithm to use maximal team coherence to

provide sound  but incomplete detection  a

pessimistic policy causes the algorithm to use

maximal team incoherence to provide complete  but unsound detection 

hierarchy   and hierarchy    the two agents
agent    the algorithm makes use of the predicate sub team 
which is true if the two agents  agent   agent   belong to dierent sub teams at the given
level of the hierarchy  depth  
the set of hierarchical plans are marked

are marked

agent  

and

with the aid of algorithm    we can now dene the centralized and distributed failure detection algorithms 

the centralized teamwork monitoring algorithm  algorithm   

utilizes algorithm   twice  checking for failures with both

pessimistic

and

optimistic

policies  if the results of both policies agree  they are certain  if the results do not agree 
 i e   the

pessimistic

policy causes a failure to be detected  while the

optimistic

policy

causes no failure to be detected   then the monitoring agent cannot be certain that a failure
has taken place  and therefore needs to verify the failure 

algorithm   therefore returns

failure  no failure  possible failure 
the distributed monitoring algorithm is not given in pseudo code form  because it is
nothing more than a call to algorithm   with an

   

optimistic

policy parameter  its power

firobust agent teams via socially attentive monitoring

algorithm   hierarchical comparison of two agents  allowing for sub teams 
  

set depth to     

  

while both plans at depth depth are team plans do
 a 

look for top most dierence rst

if policy    optimistic
i  then let plan    plan   be maximally team coherent plans at level depth
of hierarchy   and hierarchy    respectively 
ii  else let plan    plan   be maximally team incoherent plans at level depth
of hierarchy   and hierarchy    respectively 

 b 

if plan   is not equal to plan  
i  then return failure
ii  else if bottom of hierarchies reached  return no failure  otherwise increase depth and go to   

  

if only one plan is a team plan  return failure  else return no failure 

algorithm   centralized teamwork monitoring  applying both optimistic and pessimistic
views 
  

  

let optimistic result   detect agent    agent    hierarchies   
hierarchies    optimistic 
   algorithm     
let pessimistic result   detect agent    agent    hierarchies   
hierarchies    pessimistic 
   algorithm     

  

if optimistic result    pessimistic result

  

then return optimistic result   

  

else return possible failure

either

   

failure 

or

no failure   

fikaminka and tambe

is derived from the fact that all members of the team are using it to monitor the key agents
of the team 

references
ambros ingerson  j  a     steel  s          intergrating planning  execution and monitoring 
in

proceedings of the seventh national conference on articial intelligence  aaai    

minneapolis st  paul  mn  aaai press 
andou  t          renement of soccer agents  positions using reinforcement learning  in
kitano  h   ed   

robocup     robot soccer world cup    vol  lnai       pp         

springer verlag 
atkins  e  m   durfee  e  h     shin  k  g          detecting and reacting to unplanned 

proceedings of the fourteenth national conference on articial
intelligence  aaai      pp         providence  ri  aaai press 
for world states  in

bailey  k  d         
balch  t         

social entropy theory 

state university of new york press 

behavioral diversity in learning robot teams 

ph d  thesis  georgia

institute of technology 
calder  r  b   smith  j  e   courtemanche  a  j   mar  j  m  f     ceranowicz  a  z         

modsaf behavior simulation and control  in proceedings of the third conference on
computer generated forces and behavioral reresentation orlando  florida  institute
for simulation and training  university of central florida 

cohen  p  r   amant  r  s     hart  d  m         

early warnings of plan failure  false

positives  and envelopes  experiments and a model 

tech  rep  cmpsci technical

report        university of massachusetts 
cohen  p  r     levesque  h  j          teamwork 

nous     

doyle  r  j   atkinson  d  j     doshi  r  s          generating perception requests and
expectations to verify the execution of plans 

in

conference on articial intelligence  aaai     
durfee  e  h         

blissful ignorance 

proceedings of the fifth national

knowing just enough to coordinate well 

in

proceedings of the first international conference on multiagent systems  icmas     
pp         

fenster  m   kraus  s     rosenschein  j  s         

coordination without communica 

in proceedings of the first
international conference on multiagent systems  icmas      pp         california 
tion  experimental validation of focal point techniques 
usa 

firby  r  j          an investigation into reactive planning in complex domains  in

ceedings of the sixth national conference on articial intelligence  aaai     
   

pro 

firobust agent teams via socially attentive monitoring

frohlich  p     nejdl  w          resolving conicts in distributed diagnosis  in wahlster 
w   ed   

the   th europeach conference on articial intelligence  ecai     

john

wiley   sons  inc 
goldberg  d     mataric  m  j         

interference as a tool for designing and evaluat 

proceedings of the fourteenth national conference on
articial intelligence  aaai      pp         providence  ri  aaai press 
ing multi robot controllers  in

grosz  b  j     kraus  s          the evolution of sharedplans  in wooldridge  m     rao 
a   eds   

foundations and theories of rational agency  pp         

grosz  b  j     kraus  s          collaborative plans for complex group actions 

intelligence             

articial

grosz  b  j     sidner  c  l          plans for discourse  in cohen  p  r   morgan  j    
pollack  m   eds   

intentions in communication  pp          mit press  cambridge 

ma 
halpern  j  y     moses  y          knowledge and common knowledge in a distributed
environment 

distributed computing                 

hamscher  w   console  l     de kleer  j   eds           

nosis 

readings in model based diag 

morgan kaufmann publishers  san mateo  ca 

horling  b   lesser  v  r   vincent  r   bazzan  a     xuan  p         

diagnosis as an

integral part of multi agent adaptability  tech  rep  cmpsci technical report         university of massachusetts amherst 
huber  m  j     durfee  e  h         

on acting together  without communication 

in

working notes of the aaai spring symposium on representing mental states and
mechanisms  pp       stanford  ca 

jennings  n  r          commitments and conventions  the foundations of coordination in
multi agent systems 

knowledge engineering review                

jennings  n  r          controlling cooperative problem solving in industrial multi agent
systems using joint intentions 

articial intelligence                 

johnson  w  l     rickel  j          steve  an animated pedagogical agent for procedural
training in virtual environments 

sigart bulletin                

kaminka  g  a     tambe  m          what s wrong with us  improving robustness through

in proceedings of the fifteenth national conference on articial
intelligence  aaai      pp        madison  wi  aaai press 
social diagnosis 

kaminka  g  a     tambe  m         

i m ok  you re ok  we re ok  experiments in

distributed and centralized social monitoring and diagnosis 

in

proceedings of the

third international conference on autonomous agents  agents     seattle  wa  acm
press 

   

fikaminka and tambe

kinny  d   ljungberg  m   rao  a   sonenberg  e   tidhar  g     werner  e          planned
team activity 

in castelfranchi  c     werner  e   eds   

articial social systems 

lecture notes in ai      pp          springer verlag  new york 

kitano  h   tambe  m   stone  p   veloso  m   coradeschi  s   osawa  e   matsubara  h  

proceedings of the international joint conference on articial intelligence  ijcai    

noda  i     asada  m          the robocup synthetic agent challenge      in
nagoya  japan 

kraus  s   sycara  k     evenchik  a          reacing agreements through negotiations  a
logical model and implementation 

articial intelligence                 

kuniyoshi  y   rougeaux  s   ishii  m   kita  n   sakane  s     kakikura  m          cooperation by observation  the framework and the basic task patterns  in

international conference on robotics and automation 

the ieee

pp         san diego  ca 

ieee computer society press 
lesh  n   rich  c     sidner  c  l          using plan recognition in human computer col 

proceedings of the seventh international conference on user modelling
 um     ban  canada 
laboration  in

levesque  h  j   cohen  p  r     nunes  j  h  t          on acting together  in

of the eigth national conference on articial intelligence  aaai    

proceedings

menlo park 

ca  aaai press 
malone  t  w     crowston  k         
tion 

toward an interdisciplinary theory of coordina 

tech  rep  ccs tr     ss wp          msa  massachusetts institute of

technology 
marsella  s  c   adibi  j   al onaizan  y   kaminka  g  a   muslea  i   tallis  m     tambe 
m         

on being a teammate 

experiences acquired in the design of robocup

proceedings of the third international conference on autonomous agents
 agents     seattle  wa  acm press 

teams   in

newell  a         

unied theories of cognition 

harvard university press  cambridge 

massachusetts 

the proceedings
of the ieee robotics and automation conference  pp         atlanta  ga 

parker  l  e          designing control laws for cooperative agent teams  in

rao  a  s          means end plan recognition  towards a theory of reactive recognition 

in proceedings of the international conference on knowledge representation and reasoning  kr      pp         

reece  g  a     tate  a          synthesizing protection monitors from causal structure 
in

proceedings of articial intelligence planning systems  aips     chicago  il 

rich  c     sidner  c  l         

collagen  when agents collaborate with people 

in johnson  w  l   ed    proceedings of the first international conference on autonomous agents  agents      pp         marina del rey  ca  acm press 

   

firobust agent teams via socially attentive monitoring

proceedings
of the first international conference on autonomous agents  agents      pp        

schroeder  m     wagner  g          distributed diagnosis by vivid agents  in
marina del rey  ca  acm press 

sugawara  t     lesser  v  r          learning to improve coordinated actions in cooperative
distributed problem solving environments 

machine learning                   

tambe  m          tracking dynamic team activity  in

ence on articial intelligence  aaai  

tambe  m          towards exible teamwork 

         

proceedings of the national confer 

journal of articial intelligence research 

tambe  m   johnson  w  l   jones  r   koss  f   laird  j  e   rosenbloom  p  s     schwamb 
k         

       

intelligent agents for interactive simulation environments 

ai magazine 

proceedings of the
fourteenth national conference on articial intelligence  aaai      pp     provi 

toyama  k     hager  g  d          if at rst you don t succeed     in
dence  ri 

veloso  m   pollack  m  e     cox  m  t          rationale based monitoring for planning
in dynamic environments  in

 aips     pittsburgh  pa 

proceedings of articial intelligence planning systems

volpe  c  e   cannon bowers  j  a     salas  e          the impact of cross training on
team functioning  an empirical investigation 

human factors                

markov tracking for agent coordination  in proceedings of the
second international conference on autonomous agents  agents      pp       min 

washington  r         

neapolis st  paul  mn  acm press 

   

fi