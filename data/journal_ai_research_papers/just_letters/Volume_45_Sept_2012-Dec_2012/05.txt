journal of artificial intelligence research                  

submitted        published      

the time complexity of a with approximate heuristics on
multiple solution search spaces
hang dinh

htdinh iusb edu

department of computer   information sciences
indiana university south bend
     mishawaka ave  p o  box     
south bend  in       usa

hieu dinh

hieu dinh mathworks com

mathworks
  apple hill drive
natick  ma            usa

laurent michel
alexander russell

ldm engr uconn edu
acr cse uconn edu

department of computer science   engineering
university of connecticut
    fairfield way  unit     
storrs  ct            usa

abstract


we study the behavior of the a search algorithm when coupled with a heuristic h satisfying
       h  h          h   where               are small constants and h denotes the optimal
cost to a solution  we prove a rigorous  general upper bound on the time complexity of a search
on trees that depends on both the accuracy of the heuristic and the distribution of solutions  our
upper bound is essentially tight in the worst case  in fact  we show nearly matching lower bounds
that are attained even by non adversarially chosen solution sets induced by a simple stochastic
model  a consequence of our rigorous results is that the effective branching factor of the search
will be reduced as long as           and the number of near optimal solutions in the search tree
is not too large  we go on to provide an upper bound for a search on graphs and in this context
establish a bound on running time determined by the spectrum of the graph 
we then experimentally explore to what extent our rigorous upper bounds predict the behavior
of a in some natural  combinatorially rich search spaces  we begin by applying a to solve the
knapsack problem with near accurate admissible heuristics constructed from an efficient approximation algorithm for this problem  we additionally apply our analysis of a search for the partial
latin square problem  where we can provide quite exact analytic bounds on the number of nearoptimal solutions  these results demonstrate a dramatic reduction in effective branching factor of
a when coupled with near accurate heuristics in search spaces with suitably sparse solution sets 

   introduction
the classical a search procedure  hart  nilson    raphael        is a method for bringing heuristic
information to bear on a natural class of search problems  one of a s celebrated features is that
when coupled with an admissible heuristic function  that is  one that always returns a lower bound
on the distance to a solution  a is guaranteed to find an optimal solution  while the worst case
behavior of a  even with an admissible heuristic function  is no better than that of  say  breadthfirst search  both practice and intuition suggest that availability of an accurate heuristic should
decrease the running time  indeed  methods for computing accurate admissible heuristic functions
for various search problems have been presented in the literature  see  e g   felner  korf    hanan 
       in this article  we investigate the effect of such accuracy on the running time of a search 
     ai access foundation  all rights reserved 

fidinh  dinh  michel    russell

specifically  we focus on rigorous estimates for the running time of a when coupled with accurate
heuristics 
the initial notion of accuracy we adopt is motivated by the standard framework of approximation algorithms  if f    is a hard combinatorial optimization problem  e g   the permanent of
a matrix  the value of an euclidean traveling salesman problem  etc    an algorithm a is an efficient  approximation to f if a runs in polynomial time and      f  x   a x         f  x  
for all inputs x  where f  x  is the optimal solution cost for input x and a x  is the solution cost
returned by algorithm a on input x  the approximation algorithms community has developed
efficient approximation algorithms for a wide swath of np hard combinatorial optimization problems and  in some cases  provided dramatic lower bounds asserting that various problems cannot be
approximated beyond certain thresholds  see vazirani        hochbaum        for surveys of this
literature   considering the great multiplicity of problems that have been successfully addressed in
this way  including problems believed to be far outside of np  like matrix permanent   it is natural to
study the behavior of a when coupled with a heuristic function possessing such properties  indeed 
in some interesting cases  e g   euclidean travelling salesman  matrix permanent  knapsack   hard
combinatorial problems can be approximated in polynomial time to within any fixed constant      
in these cases  the polynomial depends on the constant   we remark  also  that many celebrated
approximation algorithms with provable performance guarantees proceed by iterative update methods coupled with bounds on the local change of the objective value  e g   basis reduction in lenstra 
lenstra    lovasz        and typical primal dual methods in vazirani        
encouraged both by the possibility of utilizing such heuristics in practice and the natural question
of understanding the structural properties of heuristics  and search spaces  that indeed guarantee
palatable performance on the part of a   we study the behavior of a when provided with a heuristic
function that is an  approximation to the cost of a cheapest path to a solution  as certain natural
situations arise where approximation quality is asymmetric  i e   the case of an admissible heuristic  
we slightly refine the notion of accuracy by distinguishing the multiplicative factors in the two sides
of an approximation  we say that a heuristic h is an          approximation to the actual cost
function h   or simply          approximate  if        h  h          h   in particular  admissible
heuristics with  approximation are       approximate  we will call a heuristic  accurate if it is
         approximate and            a detailed description appears in section     
    a sketch of the results
we initially model our search space as an infinite b ary tree with a distinguished root  a problem
instance is determined by a set s of nodes of the treethe solutions to the problem  the cost
associated with a solution s  s is simply its depth  the search procedure is equipped with  i   an
oracle which  given a node n  determines if n  s  and  ii   an heuristic function h  which assigns
to each node n of the tree an estimate of the actual length h  n  of the shortest  descending  path
to a solution  let s be a solution set in which the first  and hence optimal  solution appears at
depth d  we establish a family of upper bounds on the number of nodes expanded by a   if h is an
         approximation of h   then a finds a solution of cost no worse than         d and expands
no more than  b       d   dn     nodes  where n denotes the number of solutions at depth less
than       d  see lemma     below for stronger results  we emphasize that this bound applies to
any solution space and can be generalized to search models with non uniform branching factors and
non uniform edge costs  see section    
we go on to show that this upper bound is essentially tight  in fact  we show that the bound is
nearly achieved even by non adversarially determined solution spaces selected according to a simple
stochastic rule  see theorems     and        we remark that these bounds on running time fall off
rapidly as the accuracy of the heuristics increases  as long as the number of near optimal solutions
is not too large  although it may grow exponentially   for instance  the effective branching factor
of a guided by an admissible  accurate heuristic will be reduced to b if n   o bd    however 
   

fithe time complexity of a with approximate heuristics

in the worst cases  which occur when the search space has an overwhelming number of near optimal
solutions  a still has to expand almost as many nodes as brute force does  regardless of heuristic
accuracy  likewise  strong guarantees on      are  in general  necessary to effect appreciable
changes in average branching factor  this is discussed in theorem     
after establishing bounds for the tree based search model  we examine the time complexity of
a on a graph by unrolling the graph into an equivalent tree and then bounding the number of
near optimal solutions in the tree which are a lift of a solution in the original graph  this appears
in section    using spectral graph theory  we show that the number n of lifted solutions on the
tree corresponding to a b regular graph g is o     d    assuming the optimal solution depth d is
o logb  g   and the number solutions in g is constant  where  is the second largest eigenvalue  in
absolute value  of the adjacency matrix of g  in particular for almost all b regular graphs in which
b does not grow with the size of graphs  we have     b  which yields the effective branching
factor of a search on such graphs is roughly at most  b       if the heuristic is  accurate  we
also experimentally evaluate these heuristics 
experimental results and the relationship to a in practice  of course  these upper
bounds are most interesting if they reflect the behavior of search problems in practice  the bounds
above guarantee  in general  that e  the number of nodes expanded by a with a  accurate heuristic 
satisfies
e  bd   dn  
under the plausible condition that n  bd   we have simply e  cbd node expansions for a
constant c that does not depend on   c may depend on k and or other properties of the search
space   this suggests the hypothesis that for hard combinatorial problems with suitably sparse
near optimal solutions 
e  cbd

or  equivalently 

log e  log c   d log b  

   

in particular  this suggests a linear dependence of log e on  
to explore this hypothesis  we conducted a battery of experiments on the natural search tree
presentation of the well studied knapsack problem  here we obtain an admissible  accurate heuristic by applying the fully polynomial time approximation scheme  fptas  for the problem due
to the work of ibarra and kim         see also vazirani        p       which provides us with a
convenient method for varying  without changing the other parameters of the search  we remark
that the natural search space for the problem is a quite irregular edge weighted directed graph on
which a can avoid reopening any node  thus  this search space is equivalent to one of its spanning
subtrees in terms of a s behaviors  in order to focus on computationally nontrivial examples  we
generate knapsack instances from distributions that are empirically hard for the best known exact
algorithms  pisinger         the results of these experiments yield remarkably linear behavior  of
log e as a function of   for a quite wide window of values  indeed  our tests yield r  correlation
coefficients  of the least square linear regression model  in excess of     with  in the range        
for most knapsack instances  see section     for details 
while the experimental results discussed above for the knapsack problem support the linear
scaling of      several actual parameters of the search are unknown  for example  we cannot rule
out the possibility that the approximation algorithm  when asked to produce an  approximation 
does not in fact produce a significantly better approximation  while this seems far fetched  such
behavior could provide spurious evidence for linear scaling  to explore the hypothesis in more
detail  we additionally explore a more artificial search space for the partial latin square completion
 pls  problem in which we can provide precise control of   and  in fact  n    the pls problem is
featured in a number of benchmarks for local search and complete search methods  roughly  this
is the problem of finding an assignment of values to the empty cells of a partially filled n  n table
so that each row and column in the completed table is a permutation of the set             n   in our
formulation of the problem  the search space is a  n regular graph  thus the brute force branching
   

fidinh  dinh  michel    russell

factor is  n  on this search space  by controlling n   we prove an asymptotic upper bound of

                n on the effective branching factor of a coupled with any  accurate heuristic 
we also experimentally evaluate the effective branching factor of a with the admissible  accurate
heuristic    h   with which a expands more nodes than with any admissible  accurate heuristic
strictly larger than      h  
we remark that while the pls problem itself is well studied and natural  we invent specific search
space structure on the problem that allows us to analytically control the number of near optimal
solutions  unlike the knapsack problem  where we can construct an efficient admissible  accurate
heuristic for every fixed  thanks to the given fptas  known approximation algorithms for the pls
problem are much weakerthey provide approximations for specific constants    e   to avoid this
hurdle  we construct instances of pls with known solution  from which we extract the heuristics
     h   despite these planted solutions and contrived heuristics  the infrastructure provides
an example of a combinatorially rich search space with known solution multiplicity and a heuristic
of known quality  and so provides a means for experimentally measuring the relationship between
heuristic accuracy and running time  our empirical data results in remarkable agreement with the
theoretical upper bounds  more subtly  by empirically analyzing the linear dependence of log e on
  we see that the effective branching factor of a using the heuristic      h on the given pls
search space is roughly   n       see section     
as far as we are aware  these are the first experimental results that explore the relationship
between  and e  understanding heuristic accuracy and solution space structure in general  and
the ensuing bounds on a running time  for problems and heuristics of practical interest remains
an intriguing open problem  we remark that for problems such as the  n      puzzle  which have
been extensively used as test cases for a   it seems difficult to find heuristics with accuracy sufficient
to significantly reduce average branching factor  the best rigorous algorithms can only give rather
large constant guarantees  ratner   warmuth        parberry         in particular  parberry       
shows that one can quickly compute solutions  and hence approximate heuristics  that are no more
than a factor    worse than optimal  the situation is somewhat better for random instances  where
he establishes a     factor  see demaines        work for a general discussion 
observe that any search algorithm not privy to heuristic information requires  bd   running
time  in general  to find a solution  high probability statements of the same kind can be made if the
solution space is selected from a sufficiently rich family  such pessimistic lower bounds exist even
in situations where the search space is highly structured  aaronson         our results suggest that
accurate heuristic information can have a dramatic impact on a search  even in face of substantial
solution multiplicity 
this article expands the conference article  dinh  russell    su        where the complexity of
a with an  approximate heuristic function was studied over trees  in this article  we generalize this
to asymmetric approximation  develop analogous bounds over general search spaces  establishing a
connection to algebraic graph theory  and report on a battery of supporting experimental results 
    motivation and related work
the a algorithm has been the subject of an enormous body of literature  often investigating its
behavior in relation to a specific heuristic and search problem combination   e g   zahavi  felner 
schaeffer    sturtevant        sen  bagchi    zhang        korf   reid        korf  reid   
edelkamp        helmert   roger         both space complexity  korf        and time complexity
have been addressed at various levels of abstraction  abstract formulations  involving accuracy
guarantees like those we consider  have been studied  but only in tree models where the search
space possesses a single solution  in this single solution framework  gaschnig        has given
exponential lower bounds of  bd   on the time complexity for admissible  accurate heuristics  where
def
b   b      b  see also pearl        p        while pohl        has studied more restrictive
 additive  approximation guarantees on h which result in linear time complexity  average case
   

fithe time complexity of a with approximate heuristics

analysis of a based on probabilistic accuracy of heuristics has also been given for single solution
search spaces  huyn  dechter    pearl         these previous analysis suggested that the effect of
heuristic functions would reduce the effective branching factor of the search  which is consistent with
our results when applied to the single solution model  the special case when n     for all       
the single solution model  however  appears to be an inappropriate abstraction of most search
problems featuring multiple solutions  as it has been recognized that       the presence of multiple
solutions may significantly deteriorate a s ability to benefit from improved precision   pearl       
p        emphasis added  
the problem of understanding the time complexity in terms of structural properties of h on
multiple solution spaces has been studied by korf and reid         korf et al          and korf
        using an estimate based on the distribution of h   values  in particular  they studied an
abstract search space given by a b ary tree and concluded that the effect of a heuristic function is
to reduce the effective depth of a search rather than the effective branching factor  korf   reid 
      korf et al          for the case of accurate heuristics with controlled solution multiplicity  this
conclusion directly contradicts our findings  which indicate dramatic reduction in effective branching
factor for such cases  to explain this discrepancy  we observe that their analysis relies on an equilibrium assumption that fails for accurate heuristics  in fact  it fails even for much weaker heuristic
guarantees  such as h v   h  v  for small        the basic structure of their argument  however 
can be naturally adapted to the case of accurate heuristics  in which case it yields a reduction in
effective branching factor  we give a detailed discussion in section   
as a follow up to korf and reid         korf et al          and korfs        work  edelkamp
       examined a  indeed  ida   on undirected graphs  relying on the equilibrium assumption 
edelkamps new technique is the use of graph spectrum to estimate the number n    of nodes at
certain depth   in the brute force search tree  same as our cover tree   however  unlike our spectral
analysis  which is of the original search graph g  edelkamp analyzed the spectrum of a related
equivalence graph  which has quite different structural properties  specifically  edelkamp found
that the asymptotic branching factor  defined by the ratio n     n     for large    equals the largest
eigenvalue of the adjacency matrix of the equivalence graph for certain puzzle problems  to compare 
our spectral analysis depends on the second largest eigenvalue of the adjacency matrix ag of the
original search graph g  while the largest eigenvalue of ag always equals the branching factor 
assuming g is regular 
additionally  the analyses of korf and reid         korf et al          and korf         and
therefore  of edelkamp        focus on a particular subclass of admissible heuristics  called consistent
heuristics  we remark that the heuristics used in our experiments for the knapsack problem are
admissible but likely inconsistent  zhang  sturtevant  holte  schaeffer  and felner        and zahavi
et al         discuss usages of inconsistent heuristics in practice 
our work below explores both worst case and average case time complexity of a search on
both trees and graphs with multiple solutions when coupled with heuristics possessing accuracy
guarantees  we make no assumptions regarding consistency or admissibility of the heuristics  though
several of our results can be naturally specialized to this case  in addition to studying the effect of
heuristic accuracy  our results also shed light on the sensitivity of a to the distribution of solutions
and the combinatorial structure of the underlying search spaces  e g   graph eigenvalues  which
measure  among other things  the extent of connectedness for graphs   as far as we are aware  these
are the first rigorous results combining search space structure and heuristic accuracy in a single
framework for predicting the behavior of a  

   preliminaries
a typical search problem is defined by a search graph with a starting node and a set of goal nodes
called solutions  any instance of a search on a graph  however  can be simulated by a search on
a cover tree without reducing running time  this is discussed in section      since the number of
   

fidinh  dinh  michel    russell

expansions on the cover tree of a graph is larger than or equal to that on the original graph  it is
sufficient to upper bound the running time of a search on the cover tree  with this justification 
we begin with considering the a algorithm for search problems on a rooted tree 
problem definition and notations  let t be a tree representing an infinite search space  and
let r denote the root of t   for convenience  we also use the symbol t to denote the set of vertices
in the tree t   solutions are specified by a nonempty subset s  t of nodes in t   each edge on t
is assigned a positive number called the edge cost  for each vertex v in t   let
 subtree v  denote the subtree of t rooted at v 
 path v  denote the path in t from root r to v 
 g v  denote the total  edge  cost of path v   and
 h  v  denote the cost of the least costly path from v to a solution in subtree v    we write
h  v     if no such solution exists  
the objective value of this search problem is h  r   the cost of the cheapest path from the root r
to a solution  the cost of a solution s  s is the value of g s   a solution of cost equal to h  r  is
referred to as optimal 
the a algorithm is a best first search employing an additive evaluation function f  v    g v   
h v   where h is a function on t that heuristically estimates the actual cost h   given a heuristic
function h   t         the a algorithm using h for our defined search problem on the tree t is
described as follows 
algorithm   a search on a tree
   initialize open     r  
   repeat until open is empty 
 a  remove from open a node v at which the function f   g   h is minimum 
 b  if v is a solution  exit with success and return v 
 c  otherwise  expand node v  adding all its children in t to open 
   exit with failure 
it is known  e g   dechter   pearl        lemma    that at any time before a terminates  there
is always a vertex v present in open such that v lies on a solution path and f  v   m   where m is
the min max value defined as follows 


def
m   min
max f  u   
   
ss

upath s 

this fact leads to the following node expansion conditions 
 any vertex v expanded by a  with heuristic h  must have f  v   m    cf   dechter   pearl 
      thm      we say that a vertex v satisfying f  v   m is potentially expanded by a  
 any vertex v with
max

f  u    m

upath v 

must be expanded by a  with heuristic h   cf   dechter   pearl        thm      in particular 
when the function f monotonically increases along the path from the root r to v  the node v
must be expanded if f  v    m  
   

fithe time complexity of a with approximate heuristics

the value of m will be obtained on the solution path with which a search terminates  dechter  
pearl        lemma     which implies that m is an upper bound for the cost of the solution found
by the a search 
we remark that if h is a reasonable approximation to h along the path to the optimal solution 
this immediately provides some control on m   in particular 
proposition       see also davis  bramanti gregor    wang        suppose that for some     
h v   h  v  for all vertices v lying on an optimal solution path  then m  h  r  
proof  let s be an optimal solution  for all v  path s  
f  v   g v    h  v    g v     g s   g v    g s   
hence m 

max

f  v   g s    h  r  

vpath s 

in particular  m   h  r  if the heuristic function satisfies h v   h  v  for all v  t   in which
case the heuristic function is called admissible  the observation above recovers the fact that a
always finds an optimal solution when coupled with an admissible heuristic function  cf   pearl 
      thm           admissible heuristics also possess a natural dominance property  pearl       
thm     p       for any admissible heuristic functions h  and h  on t   if h  is more informed than
h    i e   h   v    h   v  for all v  t  s  then a using h  dominates a using h    i e   every node
expanded by a using h  is also expanded by a using h   
    approximate heuristics
recall from the introduction that we shall focus on heuristics providing an          approximation to
the actual optimal cost to reach a solution 
definition  let                a heuristic function h is called          approximate if
       h  v   h v           h  v 

for all v  t  

an          approximate heuristic is simply called  approximate if both     and      if a
heuristic function h is          approximate  we shall say that h has a heuristic error         or h is
         accurate 
as we will see below  these two approximation factors control the performance of a search
in rather different ways  while   only effects the running time of a     has impact on both the
running time and the quality of the solution found by a   particularly  the special case      
corresponds to admissible heuristics  with which a always finds an optimal solution  in general  by
proposition      we have 
fact    if h is          approximate  then m          h  r  
hence  the solution found by a using an          approximate heuristic must have cost no more
than         h  r  and thus exceeds the optimal cost by no more than a multiplicative factor equal
   
definition  let      a solution of cost less than       h  r  is called a  optimal solution 
assumptions  to simplify the analysis for now  we assume that the search tree t is b ary and
that every edge is of unit cost unless otherwise specified  in this case  the cost g v  is simply the
depth of node v in t and h  v  is the shortest distance from v to a solution that is a descendant of v 
throughout  the parameters b     the branching factor of the search space  and                     
 the quality of the approximation provided by the heuristic function  are fixed  we rule out the case
      for simplicity 
   

fidinh  dinh  michel    russell

   upper bounds on running time of a on trees
we are now going to establish upper bounds on the running time of a search on the tree model 
we will first show a generic upper bound that applies to any solution space  we then apply this
generic upper bound to a natural stochastic solution space model 
    a generic upper bound
as mentioned in the introduction  we begin with an upper bound on the time complexity of a
search depending only on the weight distribution of the solution set  in addition to the heuristics
approximation factors  we shall  in fact  upper bound the number of potentially expanded nodes 
which is clearly an upper bound on the number of nodes actually expanded by a  
lemma      let s be a solution set whose optimal solutions lie at depth d  then  for every     
the number of nodes expanded by a search on the tree t with an          approximate heuristic is
no more than
 b         d          dn    
nodes  where n is the number of  optimal solutions 
the presence of the independent parameter  offers a flexible way to apply the upper bound in
lemma      in particular  applying lemma     with      and using the fact that          we
arrive at the upper bound of  b       d   dn     mentioned in the introduction  this bound works
best when  n        b       d    in general  if n       o b       d    we should choose the least
    for which n       o b       d    in the opposite case  if n        b       c d   for some
positive constant c         we can obtain a better bound by choosing       c              since
n     dominates both terms  b         d   and n     given such a choice of  
proof of lemma      let d   h  r  and let            consider a node v which does not lie on
any path from the root to a  optimal solution  so that h  v         d  g v   then
f  v   g v                  d  g v                  d     g v   
recall that a node is potentially expanded by a if its f  value is less than or equal to m   since
m          d  the node v will not be potentially expanded if
             d     g v            d  

   

since        the inequality     is equivalent to
g v                     d                d  
in other words  any node at depths in the range

             d          d
can be potentially expanded only when it lies on the path from the root to some  optimal solution 
on the other hand  on each  optimal
solution path  there are at most        d nodes at depths

in              d          d   pessimistically assuming that all nodes with depth no more than
             d are potentially expanded in addition to those on paths to  optimal solutions
p 
yields the statement of the lemma   note that as b     i   bi   b  and that every potentially
expanded node v must have depth g v   f  v   m          d  
   recall some asymptotic notations  f  n     g n   means there exist constants c    c      such that c  g n  
f  n   c  g n  for sufficiently large n  f  n     g n   means there exists a constant c     such that cg n   f  n 
for sufficiently large n 

   

fithe time complexity of a with approximate heuristics

    an upper bound on a natural search space model
while actual time complexity will depend  of course  on the precise structure of s and h  we show
below that this bound is essentially tight for a rich family of solution spaces  we consider a sequence
of search problems of increasing difficulty  expressed in terms of the depth d of the optimal solution 
a stochastic solution space model  for a parameter p          consider the solution set s
which is obtained by independently placing each node of t into s with probability p  in this
setting  s is a random variable and is written sp   when solutions are distributed according to sp  
observe that the expected number of solutions at depth d is precisely pbd and that when p   bd an
optimal solution lies at depth d with constant probability  for this reason  we focus on the specific
values pd   bd and consider the solution set spd for each d      recall that under this model  it
is likely for the optimal solutions to lie at depth d and  more generally  we can see that with very
high probability the optimal solutions of any particular subtree will be located near depth d  with
respect to the root of the subtree   we make this precise below 
lemma      suppose the solutions are distributed according to spk   then for any node v  t and
t     
td
    btd  pr h  v    t   eb  
pt
proof  in the tree subtree v   there are n   i   bi    bt        b     nodes at depths t or less 
so pr h  v    t        bd  n   we have

   nbd      bd  n  exp nbd  
the first inequality is obtained by applying bernoullis inequality  and the last one is implied from
the fact that    x  ex for all x  observing that
bt 

bt     
  bt
b 

for b    completes the proof 
observe that in the spd model  conditioned on the likely event that the optimal solutions appear
at depth d  the expected number of  optimal solutions is  bd    in this situation  according to
lemma      a expands no more than o b         d     o db       d   vertices in expectation 
for any      the leading exponential term in this bound is equal to
max               d          d   
which is minimal when       this suggests the best upper bound that can be inferred from the
family of bounds in lemma     is poly d b       d  for spd   
before discussing the average case time complexity of a search  we record the following wellknown chernoff bound  which will be used to control the tail bounds in our analysis later 
lemma      chernoff bound  chernoff         let z be the sum of mutually independent indicator
random variables with expected value    e  z   then for any      


e
pr z            
 
        
a detailed proof can be found in the book of motwani and raghavan         in several cases
below  while we do not know exactly the expected value of the variable to which we wish to apply
the tail bound in lemma      we can compute sufficiently good upper bounds on the expected value 
in order p
to apply the chernoff
in such a case  we actually require a monotonicity argument 
pbound
n
n
 
 
if z  
x
and
z
 
x
i   i
i   i are sums of independent and identically distributed  i i d  
indicator random variables so that e  xi    e  xi     then pr z      pr z       for all   with this
argument and by applying lemma     for    e     we obtain 
   

fidinh  dinh  michel    russell

corollary      let z be the sum of n i i d  indicator random variables so that e  z     n  then
pr z   e    e  
adopting the search space whose solutions are distributed according to spd   we are ready to
bound the running time of a on average when guided by an          approximate heuristic 
 

theorem      let d be sufficiently large  with probability at least    ed  e d   a search on the
tree t using an          approximate heuristic function expands no more than   d  b       d vertices
when solutions are distributed according to the random variable spd  
proof  let x be the random variable equal to the total number of nodes expanded by the a with
an          approximate heuristic  of course the exact value of  say  e  x  depends on h  we will prove
upper bounds achieved with high probability for any          approximate h  applying lemma    
with       we conclude

x   b       h  r           h  r n      
thus it suffices to control both h  r  and the number n     of          optimal solutions 
we will utilize the fact that in the spd model  the optimal solutions are unlikely to be located
far from depth d  to this end  let efar be the event that h  r    d    for some    d to be set

later  lemma     immediately gives pr efar    eb  
observe that conditioned on efar   we have h  r   d  and n      z  where z is the random
variable equal to the number of solutions with depth no more than              d      we have
d
          d  
   b       d              b       d  
e z   b   b

and  applying the chernoff bound in corollary     to control z 
h
i


 
pr z    eb       d    exp  b       d    e b  
letting ethick be the event that z   b       d     observe
h
i
 
pr ethick    pr z    eb       d    e b  
to summarize  when neither efar nor ethick occurs 
x   b        d             d     b       d  
   d    b       d  
   db       d    
hence 
h
i

 
pr x     db       d    pr efar  ethick    eb   e b  
to infer the bound stated in our theorem  set b   d so that b       d     d  b       d   completing
the proof 
remark by similar methods  other trade offs between the error probability and the resulting bound
on the number of expanded nodes can be obtained 
   

fithe time complexity of a with approximate heuristics

   lower bounds on running time of a on trees

we establish that the upper bounds in theorem     are tight to within a o    d  term in the
exponent  we begin by recording the following easy fact about solution distances in this discrete
model 
fact    let   h  r  be a nonnegative integer  then for every solution s  there is a node v 
path s  such that h  v     
proof  fix a distance   h  r   we will prove the lemma by induction on the depth of solutions 
the lemma clearly holds for optimal solutions  consider a solution s which may not be optimal 
and let v  path s  be the node which is  level far from s so that h  v     if h  v      there
must be another solution s   subtree v  that is closer to v  by the induction assumption  there
is a node v    path s    with h  v         this node v   must be an ancestor of v  since the distance
between v and s  is less than  while the distance between v   and s  is at least   completing the
proof 
we proceed now to the lower bound 
theorem     let d be sufficiently large  for solutions distributed according to spd   with probability
at least    b d   there exists an          approximate heuristic function 
h so that the number of
vertices expanded by a search on the tree t using h is at least b       d  d    
proof  our plan is to define a pathological heuristic function that forces a to expand as many
nodes as possible  note that the heuristic function here is allowed to overestimate h   intuitively 
we wish to construct a heuristic function that overestimates h at nodes close to a solution and
underestimates h at nodes far from solutions  leading a astray whenever possible  recall that for
every vertex v  it is likely to have a solution lying at depth d of subtree v   thus we can use the
quantity h  v   d   to formalize the intuitive notion that the node v is close to a solution  where
the quantity    d will be determined later  our heuristic function h is formally defined as follows 
 
        h  v  if h  v   d   
h v   
       h  v  otherwise 
observe that the chance for a node to be overestimated is small since  by lemma     
pr v is overestimated    pr h  v   d      b

   

for any node v  also note that if a node v does not have any overestimated ancestor  then the f
values will monotonically increase along the path from root to v 
naturally  we also wish to ensure that the optimal solution is not too close to the root  let eclose
be the event that h  r   d    again by lemma     
pr eclose     b  
we then will see that conditioned on the event eclose   which means h  r    d    every
solution will be obscured by an overestimated node that is not too close to a solution  concretely 
up to issues of integrality  fact   asserts that for every solution s  there must be a node v on the
path from the root to s with h  v    d    as long as d     h  r  
assume eclose   then whenever h  v    d    we have g v   h  r    d        and h v   
         d     and thus f  v             d     since every solution is obscured by some
overestimated node whose f value is larger than          d     we have m            d     where
m is the min max value defined in      it follows that a node v must be expanded if path v  does
   

fidinh  dinh  michel    russell

not contain any overestimated node and f  v            d     when path v  does not contain
an overestimated node  we have f  v    g v           h  v   so
f  v            d            h  v            d     g v   
since        therefore  we say a node v is required if there is no overestimated node in path v  and
       h  v            d     g v   to recap  conditioned on eclose   the set of required nodes is
a subset of the set of nodes expanded by a search using our defined heuristic function  we will use
the chernoff bound to control the size of r  which denotes the set of non required nodes at depth
  
let v be a node at depth             d  equation     implies
pr  an overestimated node in path v      b         
the last inequality holds for sufficiently large d  as long as    poly d   on the other hand  if
       we have




         d      
pr v  r    pr h  v   
    


       d  
d
  
 exp b
 by lemma     


       d       
  
 
   
  exp b
now set             d            logb    then equation     implies
 logd   


pr v  r   exp b     e         
in the case        the event        h  v            d       never
given the value
fi
fi happens
of   that has been set  hence  in any case  pr v  r       so that e fir  fi  b      applying the
chernoff bound in corollary     again yields
fi fi

pr fir  fi   eb      exp b       
fi fi
let ethin be the event that fir  fi  b      since b       eb     
pr ethin    exp b       
putting the pieces together  we have


 
pr a expands less than b     nodes  pr eclose  ethin     b   eb     


setting      d we have             d            d  logb    and thus
h
i


pr a expands less than b       d  d    nodes  b d
for sufficiently large d 
for contrast  we now explore the behavior of a with an adversarially selected solution set  this
achieves a lower bound which is nearly tight  in comparison with the general upper bound on the
worst case running time of a obtained by setting      in the bound of lemma     above  
   

fithe time complexity of a with approximate heuristics

theorem      for any d      there exists a solution set s whose optimal solutions lie at depth d
and an          approximate heuristic function h such that the a on the tree t using h expands at
least b      d      nodes 
proof  consider a solution set s in which all    optimal solutions share an ancestor u lying at depth
   furthermore  s contains every node at depth         d that is not a descendant of u  where
d   h  r  
now define an          approximate heuristic h as follows  h u            h  u  and h v   
       h  v  for all v    u  with this heuristic  every    optimal solution is hidden from the search
procedure by its ancestor u  precisely  since f  u                 d               d      every
   optimal solution s  which is a descendant of u  will have
max
vpath s 

f  v   f  u            d     

thus m          d      where m is the min max value defined in equation     
let v be any node at depth            d that does not lie inside of subtree u   note that the
f values monotonically increase along the path from root r to v  which implies that the node v must
be expanded if f  v    m   on the other hand  since every non descendant of u at depth         d is
a solution  we have     h  v           d  and thus
f  v                       d                      d        
hence  the node v must be expanded if                d                 d      which is equivalent
to             d         it follows that the number of nodes expanded by a is at least
      d     

x
   

      d     

b  

x

b    b      d       

   

according to theorem      if we set       and let   be arbitrarily small provided        then
we can obtain a near accurate heuristic which forces a to expand at least as many as bd  nodes 
this lower bound partially explains why a can perform so poorly  even with an almost perfect
heuristic  in certain applications  helmert   roger         the adversarially chosen solution set
given in the proof of theorem     has an overwhelming number of near optimal solutions  indeed 
n    b      d  b      d   b      d 
for any      

   generalizations  non uniform edge costs and branching factors
in this section  we discuss how the generic upper bounds of lemma     can be generalized to apply
to more natural search models such as those with non uniform branching factors and non uniform
edge costs  in section    we show how these can be extended to general graph search models 
now we consider a general search tree without the assumptions of uniform branching factor and
uniform edge costs  from the same argument given in the proof of lemma      we derive the assertion
that when the heuristic is          approximate  any node of cost more than              c will
not be potentially expanded if it does not lie on a          optimal solution path  where  is an
arbitrary nonnegative number and c   h  r  is the optimal solution cost 
hence  the number of nodes potentially expanded by a with an          approximate heuristic
is bounded by


f              c   r              c          
   
   

fidinh  dinh  michel    russell

here f    is the number of nodes with cost no more than   which we call free nodes  r     is the
number of nodes with cost in the range            c   that lie on a  optimal solution path  which
we call restricted nodes 
to bound the number of free and restricted nodes  respectively  we assume that the branching
factors are upper bounded and edge costs are lower bounded  let b    be the maximal branching
factor and let m be the minimal edge cost  since any node with cost no more than  must lie at
depth no larger than  m  we have
f      b  m  
on each  optimal solution path  there are at most          c    m nodes of cost in the range
           c    thus 
        c  
 n  
r     
m
letting                 c              and applying the bounds for f    and r     to the
bound in      we obtain another upper bound on the number of expanded nodes when the heuristic
is          approximate 


 b          c

 m

  n            c  m

   

for any      this equation     is a generalized version of the bound in lemma      substituting
     in      we arrive at the following simpler upper bound on the number of expanded nodes 
 b        c



 m

  n            c  m  

   

   bounding running time of a on graphs
in previous parts  we have established bounds on the running time of a on the tree model  now
we will apply those bounds to a on the graph model  in order to do that  we will first unroll the
graph into a cover tree  and then bound the number of solutions lifted to the cover tree 
    unrolling graphs into trees
the preceding generic upper bounds are developed for tree based models  in this section we discuss
a natural extension to general graph search models  the principal connection is obtained by unrolling a graph into a tree on which a expands at least as many nodes as it does on the original
graph  including repetitions   more specifically  given a directed graph g and starting node x  in g 
we define a cover tree t  g  whose nodes are in one to one correspondence with finite length paths
in g from x    we shall write a path  x            x    in g as a node in t  g   the root of t  g  is
 x     the parent of a node  x    x            x    in t  g  is the node  x    x            x      and the edge cost
between the two nodes  x    x            x     and  x    x            x    in t  g  equals the cost of the edge
 x     x    in g  hence  for each node p in t  g   the cost value g p   is equal to the total edge
cost on the path p in g  a node  x            x    in t  g  is designated as a solution whenever x  is a
solution in g 
a node in t  g  that corresponds to a path ending at node x  g will be called a copy of x 
observe that a solution in g may lift multiple times to solutions in t  g   as each node in g may
have multiple copies in t  g   figure   illustrates an example of unrolling a graph into a cover tree 
in this example  node s is a solution in the graph and its first two copies in the cover tree correspond
to the paths        s  and           s   where   is the starting node in the given graph 
the a search on graph g is described in algorithm   below  in which h x  is the heuristic
at node x  g x  is the cost of the current path from x  to x  and c x  x    denotes the cost of the
edge  x  x    in g  we assume the value of h x  depends only on x  i e   h x  does not depend on
a particular path from x  to x  unlike a search on a tree  for each node x in open or closed 
   

fithe time complexity of a with approximate heuristics

 
 
 

 

 

 

 

 

s

 

 

 

 

 

 

s

 
 

 

 
s

figure    unrolling a graph into a cover tree 
algorithm   also keeps track of the current path p from x  to x through the pointers  and the
current f  value of x is equal to g p     h x   this current path is the cheapest path from x  to x
that passes only nodes that have been expanded 
algorithm   a search on a graph  pearl        p     
   initialize open     x    and g x         
   repeat until open is empty 
 a  remove from open and place on closed a node x for which the function f   g   h is
minimum 
 b  if x is a solution  exit with success and return x 
 c  otherwise  expand x  generating all its successors  for each successor x  of x 
i  if x  is not on open or closed  estimate h x    and calculate f  x      g x      h x   
where g x      g x    c x  x     and put x  to open with pointer back to x 
ii  if x  is on open or closed  compare g x    and g x    c x  x     if g x    c x  x     
g x     direct the pointer of x  back to x and reopen x  if it is in closed 
   exit with failure 
now consider a search on the cover tree t  g  of graph g using the same heuristic function h 
for each node p in t  g   set the heuristic value h p   to be equal to h x  if p is a copy of node
x  g  i e   p is a path in g from x  to x  observe that the cover tree t  g  and the graph g share
the same threshold m  defined in equation       hence  whenever a node x  g is expanded with
current path p   we must have g p     h x   m   which implies that p is potentially expanded by
a search on the cover tree t  g   this shows the following fact 
fact    the number of node expansions by a on g is no more than the number of nodes potentially
expanded by a on t  g  using the same heuristic 
here  by node expansion  we mean an execution of the expand step of a   i e  step   c   note
that  in general  a node in g can be expanded many times along different paths 
remark the running time of a on the cover tree can also be used to upper bound the running time
of iterative deepening a  ida   on the graph  recall that the running time of ida is dominated
by its last iteration  on the other hand  the last iteration of ida on g is merely depth first search
   

fidinh  dinh  michel    russell

on the cover tree t  g  up to the cost threshold m   hence  the number of expansions in the last
iteration of ida is no more than the number of nodes potentially expanded by a on the cover
tree 
so  to upper bound time complexity of a or ida on a graph  it suffices to unroll the graph
into the cover tree and apply upper bounds on the number of nodes potentially expanded by a on
the cover tree  in particular  the bound in equation     can be applied directly to the a search on
g 
note that while these bounds can be applied directly  the problem of determining exactly how
solutions in g lift to solutions in the cover tree depends on delicate structural properties of g
specifically  it depends on the growth of the number of distinct paths from x  to a solution as
a function of the length of these paths  in particular  in order to obtain general results on the
complexity of a in this model  we must invoke some measure of the connectedness of the graph g 
below we show how to bound the complexity of a in terms of spectral properties of g  we choose
this approach because it offers a single parameter notion of connectedness  the second eigenvalue 
that is both analytically tractable and can actually be analyzed or bounded for many graphs of
interest  including various families of cayley graphs and combinatorial graphs by methods such as
conductance 
    an upper bound via graph spectra
we shall consider an undirected  graph g on n vertices as the search space  let x  be the starting
node and let s be the set of solutions in g  for simplicity  assume g is b regular      b  n  and
the edge costs are uniformly equal to one  so the cover tree t  g  is b ary and has uniform edge cost 
we assume  additionally  that  s  is treated as a constant when n   
by fact   and lemma      the number of node expansions by a on g with an         approximate heuristic is at most  b       d   dn       where d is the optimal solution cost  which
equals the optimal solution depth in t  g   and n is the number of  optimal solutions in t  g  
our goal now is to upper bound n  of the cover tree t  g   in terms of spectral properties of g 
we introduce the principal definitions of spectral graph theory below  primarily to set down
notation  a more complete treatment of spectral graph theory can be found in the work of chung
       
graph spectra  for a graph g  let a be the adjacency matrix of g  a x  y      if x is adjacent
to y  and   otherwise  this is a real  symmetric matrix  at   a  and thus has real eigenvalues
b     b  a
b                n  b  by the spectral theorem  horn   johnson         let a
b
denote the normalized adjacency matrix of g  then a has eigenvalues                  n    
which are referred to as the spectrum of g  where i   i  b  these eigenvalues  along with their
associated eigenvectors  determine many combinatorial aspects of the graph g  in most applications
def
of graph eigenvalues  however  only the critical value     g    max         n    is invoked
and  moreover  the real parameter of interest is the gap between     b and the largest eigenvalue
      of the normalized adjacency matrix  intuitively   measures the connectedness of g 
sparsely connected graphs have      for the n cycle  for example        o   n   the hypercube
on n    n vertices has           log n    similar bounds on  and   are known for many
families of cayley graphs  random graphs  even of constant degree b     achieve    o    with
high probability  in fact  a recent result of friedman        strengthens this 
theorem       friedman        fix a real c     and an integer b     then with probability
   o     as n    

 gn b      b      c
   while one can produce an analogous cover tree in the directed case  the spectral machinery we apply in the next
section is somewhat complicated by the presence of directed edges  see the work of chung        and horn and
johnson        perron frobenius theorem  for details 

   

fithe time complexity of a with approximate heuristics

where gn b is a random b regular graph on n vertices 
we remark that for any non bipartite connected graph with diameter d  we always have  
b     dn   under stronger conditions  when the graph is vertex transitive  which is to say that
for any pair v    v  of vertices of g there is an automorphism of g sending v  to v     one has
  b     d     babai         while vertex transitivity is a strong condition  it is satisfied by
many natural algebraic search problems  e g      puzzle like search spaces and the rubiks cube  
the principal spectral tool we apply in this section is described in lemma     below  we begin
with some notation 
notations  any function  on g can be viewed as a column vector indexed by the vertices in g
and vice versa  for each vertex x  g  let  x denote the function on g that has value   at x and
  at everypvertex other than x  for any real valued functions    on g  define the
pinner product
h  i   xg  x  x   we shall use k  k to denote the l   norm  i e   kk   h  i for any
function  on g 
b is symmetric and real  by spectral theorem  horn   johnson         there
recall that since a
exist associated eigenfunctions             n that form an orthonormal basis for the space of real valued
b in particular 
functions on g  where i is the eigenfunction associated with the eigenvalue i of a 
b
we have
pn ai   i i and ki k     for all i  and hi   j i     for all i    j  in this basis  we can write
   i   h  i i i for any real valued function  on g 
lemma      let g be an undirected b regular graph with n vertices  and     g  b  for any
probability distributions p and q on vertices of g  and any integers s  t    
fi
fid


e
fi
fi s
b p  a
bt q    fi  s t kpk  kqk     
fi a
fi
nfi
n
pn

pn
ai i and q   j   bj j where ai   hp  i i   bj   hq  j i  then
 
  n
n
n
n
d
e
x
x
x
x
t
s
t
s
b p  a
bq  
s t
ai bi  
ai bj si tj hi   j i  
bj j j  
a
ai i i  
i

proof  write p  

i  

i  

i j  

j  

i  

by the cauchy schwartz inequality 
n
x

v
 
  n
u n
x
u x
 
 
t
 ai bi   
bi   kpk  kqk  
ai

i  

i  

i  
  n

without loss of generality  assume    x   
for all vertices x  g  since p is a probability
distribution 
x
 
  x
p x      
a    hp    i  
p x    x    
n
n
xg

similarly  b   

   
n

thus  a  b   

xg

 
n 

so we have
fi n
fi
fid
fi
e   fifi fix
fi s
fi
fi
s t
b p  a
bt q  fi   fi
fi a

a
b
fi
i
i
i
fi
fi
nfi fi
i  

 s t

n
x

 ai bi  

 as    max  i   
 in

i  



 s t kpk  kqk 
completing the proof of the lemma 
   

 
n


 

fidinh  dinh  michel    russell

with lemma     in hand  we establish the following bound on the number of paths of a prescribed
length   connecting a pair of vertices  we then apply this to control the number of  optimal solutions
in the cover tree of g  let p   u  v  denote the number of paths in g of length   from u to v 
lemma      let g be an undirected b regular graph with n vertices  and     g   for any vertices
u  v in g and      
fi
fi


 fi
fi
fip   u  v   b fi              
fi
nfi
n
proof  since p   u  v  is the number of   length paths from u to v  we have p   u  v    b  p     v   where
p     v  is the probability that a natural random walk on g of length
  starting
from u ends up at
d
e


ff
p   u v 
 
   
 
   
   
b
b
   v   a  u   applying lemma    
v  since p   a  u and p  v     v   p   we have
 
b

yields
fi
fi fi




e   fifi
fi p   u  v 
  fifi fifid
 
b
fi
fi    k v k  k u k              
 
 
a
 


 
v
u
fi b 
nfi fi
nfi
n
n
as     b  multiplying both sides of the last inequality by b  completes the proof for the lemma 
the major consequence of lemma     in our application is the following bound on the number
of  optimal solutions in t  g  
theorem      let g be an undirected b regular graph with n vertices  and     g   for sufficiently
large n and any      the number of  optimal solutions in t  g  is
     d

b
n     s 
      d  
n
where d is the depth of optimal solutions in t  g   and s is the set of solution nodes in g 
proof  for each solution s  s  the number of copies of s at level   in t  g  equals p   x    s   which
is less than b  n     by lemma      hence  the number of solutions at level   in t  g  is
  

x
b
p   x    s     s 
     
   
n
ss

summing up both sides of     for   ranging from d to       d  we have


    d
    d
    d
x x
x
x
 
n  
p   x    s     s  
b   
    
n
  d ss

  d

  d

when n is sufficiently large  we have      thus 


      d
n    s 
 b
       d  
n

note that b    d
 n   o    if d  o logb n   as mentioned earlier  theorem       most b regular
graphs have     b      o       b  assuming g has this spectral property and d   o logb n  
theorem     gives


n   o     d     o      d b    d    
in such cases  the number of node expansions by a on g using an            approximate heuristic
is o d     d b    d      which implies the effective branching factor of a is roughly bounded by
    b          b        
   

fithe time complexity of a with approximate heuristics

   experimental results
as discussed in the introduction  the bounds established thus far guarantee that e  the number of
nodes expanded by a using a  accurate heuristic  satisfies
e   bd   dn  cbd
under the assumption that n  bd    here  as before  b is the branching factor  d is the optimal
solution depth  and c is some constant   this suggests the hypothesis that for hard combinatorial
problems with suitably sparse near optimal solutions 
log e  d log b     

    

where  is a constant determined by the search space and heuristic but independent from   in
particular  this suggests a linear dependence of log e on   we experimentally investigated this
hypothesized relationship with a family of results involving the knapsack problem and the partial
latin square problem  as far as we are aware  these are the first experimental results specifically
investigating this dependence 
we remark that in order for such an experimental framework to really cast light on the bounds we
have presented for a   one must be able to furnish a heuristic with known approximation guarantees 
    a search for knapsack
we begin with describing a family of experimental results for a search coupled with approximate
heuristics for solving the knapsack problem  this problem has been extremely well studied by a
wide variety of fields including finance  operations research  and cryptography  kellerer  pferschy 
  pisinger         as the knapsack problem is np hard  karp         no efficient algorithm can
solve it exactly unless np   p  despite that  this problem admits an fptas  vazirani        p 
     an algorithm that will return an  approximation to the optimal solution in time polynomial in
both    and the input size  we use this fptas to construct approximate admissible heuristics for
the a search  which yields an exact algorithm for knapsack that may expand far fewer nodes than
straightforward exhaustive search   indeed  the resulting algorithm is  in general  more efficient than
exhaustive search  
      a search model for knapsack
consider a knapsack instance given by n items  and let  n                n   each item i   n  has
weight wi     and profit pi      the knapsack has capacity c      the task is to find a set of items
with maximal total profit such that its total weight is at most c  this knapsack instance will be
denoted as a tuple h n   p  w  ci  the knapsack instance restricted to a subset x   n  is denoted
hx  p  w  ci  for each subset x   n   we will let w x  p
and p x  denote the p
total weight and the
total profit  respectively  of all items in x  i e   w x    ix wi and p x    ix pi  
search space  we represent the knapsack instance h n   p  w  ci as a search space as follows  each
state  or node  in the search space is a nonempty subset x   n   a move  or edge  from one state
x to another state is taken by removing an item from x  the cost of such a move is the profit of
the removed item  a state x   n  is designated as a solution if w x   c  the initial state is the
set  n   see figure   for an example of the search space with n     
this search space is an irregular directed graph whose out degrees span in a wide range  from  
to n     moreover  for any two states x    x  with x   x    n   there are  x    x     paths on
this search graph from x  to x    moreover  every path from x  to x  has the same cost equal to
p x     p x     this feature of the search graph makes a behave like it does on a spanning subtree
of the graph  no state in this search graph will be reopened  hence  for any state x   n   the cost
   

fidinh  dinh  michel    russell

            

         

      

         

      

         

      

   

      

   

         

      

   

      

   

figure    the search space for a knapsack instance given by the set of   items               solution
states and edge costs are not indicated in this figure 
of any path from the starting state to x is
g x    p  n    x    p  n    p x   
and the cheapest cost to reach a solution from a state x   n  is
h  x    p x   opt x   
where opt x  is the total profit of an optimal solution to the knapsack instance hx  p  w  ci  i e  
opt x    max  p x       x    x and w x      c   
def

observe that a solution state x    n  on the search space h n   p  w  ci is optimal if and only if
g x    is minimal  or equivalently  p x    is maximal  which means that x  is an optimal solution
to the knapsack instance h n   p  w  ci 
heuristic construction  fix a constant           in order to prove the linear dependence of
log e on   we wish to have an efficient  accurate heuristic h on the aforementioned knapsack
search space h n   p  w  ci  moreover  in order to guarantee that the solution returned by the a
search is optimal  we insist that h be admissible  so h must satisfy 
     h  x   h  x   h  x  x   n   
the main ingredient for constructing such a heuristic is an fptas described in the book of vazirani
       p       this fptas is an algorithm  denoted a  that returns a solution with total
 profit
at least      opt x  to each knapsack instance hx  p  w  ci and runs in time o  x       for any
          for each nonempty subset x   n   let a  x  denote the total profit of the solution
returned by algorithm a with error parameter  to the knapsack instance hx  p  w  ci  then we
have for any          
     opt x   a  x   opt x   
which implies
p x  

a  x 
 h  x   p x   a  x   
 

    

  x 
thus we may work with the heuristic h  x    p x   a 
  which guarantees admissibility 
however  this definition of h does not guarantee  approximation for h   with this definition  the
condition      h  x   h  x  is equivalent to

     h  x   p x  
   

a  x 
 
 

    

fithe time complexity of a with approximate heuristics

which does not always hold  since h  x   p x   a  x   the condition of      will be satisfied if
      p x   a  x    p x  

a  x 
 
 

    

  x 
if equation      holds  otherwise  we will define
hence  we will define h  x    p x   a 
h  x  differently  still ensuring that it is  approximate and admissible  note that if x is not a
solution  at least one item in x must be removed in order to reach a solution contained in x  thus
h  x    p x   opt x   m  where m is the smallest profit of all items  this gives another option
to define h  x  that will guarantee the admissibility  in summary  we define the heuristic function
h as follows  for all non solution state x 
 
  x 
if      holds
p x   a 
def
    
h  x   
m
otherwise 

where  will be determined later so that h is  approximate  if x is a solution  we simply set
h  x       because h  x      in this case  then h is admissible  regardless of  
to make sure that h is  approximate  it remains to consider the case when      does not hold 
  x 
i e   p x   a 
        p x   a  x    for any non solution state x  in such a case  we have
p x   a  x  



a  x  
 p  n    m   
     
     

    

the last inequality is due to the assumption that x is not a solution  now we want to choose  such
that

m
 p  n    m  
    
     
 
which  combining with      and       will imply      h  x   m   h  x   therefore  we will
choose  such that

               p  n   m      

   
since the running time to
compute
a
 x 
is
o
 x 

  the running time to compute h  x 


   
will be o  x   p  n   m   which is polynomial in both n and    if all the profits are bounded
some range  m  poly n m   the a search using the heuristic h for the given knapsack space
h n   p  w  ci is described in algorithm   below 
      experiments
in order to avoid easy instances  we focus on two families of knapsack instances identified and studied
by pisinger        that are difficult for existing exact algorithms  including dynamic programming
algorithms and branch and bound algorithms 
strongly correlated  for each item i   n   choose its weight wi as a random integer in the
range     r  and set its profit pi   wi   r     this correlation between weights and profits
reflects a real life situation where the profit of an item is proportional to its weight plus some
fixed charge 
subset sum  for each item i   n   choose its weight wi as a random integer in the range     r 
and set its profit pi   wi   knapsack instances of this type are instances of the subset sum
problem 
for our tests
p we set the data range parameter r         and choose the knapsack capacity as
c    t      i n  wi   where t is a random  integer in the range          
   in the paper of pisinger         t is a fixed integer between   and      and the average runtime of all tests
corresponding to all values of t was reported 

   

fidinh  dinh  michel    russell

algorithm   a search for knapsack
input  hn  p  w  c  i  where n is the number of items  pi and wi are the profit and weight of item
i   n   c is the capacity of the knapsack  and          is an error parameter for the heuristic 
oracle  the fptas algorithm a for the knapsack problem
       p      
p described by vazirani
p
notation  for each subset x   n  of items  let p x    ix pi   w x    ix wi  
output  a subset x    n  of items such that w x     c and p x    is maximal 
   put the start node  n  on open  let m   min in pi   set  such that

               p  n   m      
   repeat until open is empty 
 a  remove from open and place on closed a node x for which g x    h x  is minimum 
 b  if w x   c  exit with success and return x  an optimal solution 
 c  otherwise  expand x  for each item i  x  let x     x    i  
i  if x   is not on open or closed  set g x        g x    p i    p  n    p x      and
compute the heuristic h x     as follows 
a  if x   is a solution  set h x          
b  otherwise  run algorithm a on the knapsack input hx     p  w  ci with error parameter   and let a x     denote the total profit of the solution returned by algorithm
a  then set
 
 
 
 
 
 
 
if p x      a x
p x      a x
 
 
         p x    a x   
h x     
m
otherwise 
then put x   to open with pointer back to x 
ii  otherwise  x   is on open or closed  so g x     has been calculated   if g x  p i   
g x      direct the pointer of x   back to x and reopen x   if it is in closed 
 remark  since all paths from the starting node to x   have the same cost  the
condition g x    p i    g x     never holds  in fact  this step can be discarded  
   exit with failure 

   

fithe time complexity of a with approximate heuristics

after generating a knapsack instance h n   p  w  ci of either type described above  we run a series
of the a search using the given heuristic h   with various values of   as well as breath first search
 bfs   to solve the knapsack instance  when each search finishes  the values of e and d are reported 
where e is the number of nodes  states  expanded by the search  and d is the depth of the optimal
solution found by the search  in this knapsack search space  k equals the number of items removed
from the original set  n  to obtain the optimal solution found by the search  the overall runtime for
each search  including the time for computing the heuristic  is also reported  in addition  we report
the optimal value h   n   and the minimal edge cost m  i e   minimal profit  of the search space for
each knapsack instance tested 
to specify appropriate size n for each knapsack instance type  we ran a few exploratory experiments and identified the largest possible value of n for which most search instances would finish
within a few hours  then we chose those values of n  n      for the strongly correlated type  and
n      for the subset sum type  for our final experiments  observing that the optimal solution
depths resulted from knapsack instances of these sizes are fairly small  ranging from   to     we
selected sample points for  in the high interval          with a distance between two consecutive
points large enough so that the sensitiveness of e to  can be seen  in particular  we selected eight
sample points for  from            to                with the distance of               between
two consecutive points  in our final experiments  we generated    knapsack instances of each type
with the selected parameters for n and  
experimental results  results for our final experiments are shown in tables                and   
in which the rows corresponding to breath first search are indicated with bfs under the column
of   these data show  as expected  that a search outperforms breath first search in terms of
the number of nodes expanded and  naturally  that the smaller   the fewer nodes a expands  as
a result  the effective branching factor of a will decrease as  decreases  as long as all optimal
solutions in the given search space are located at the same depth   recall that if a expands e
nodes and finds a solution at depth d  then its effective branching factor is the branching factor of a
uniform tree of depth d and e nodes  russell   norvig        p        i e   the number b satisfying
e       b    b            b  d   clearly   b  d  e and  if b     we have e    b  d   as we shall
focus solely on values of b     we simply use e   d as a proxy for effective branching factor  content
that this differs from the actually quantity by a factor no more than    d    of course  as b grows
this error decays even further   the effective branching factors  calculated as e   d   of a search
and breath first search for knapsack instances of type strongly correlated are shown in tables   
   and    note that for knapsack instances of the subset sum type  one cannot directly compare
effective branching factors  as the optimal solutions found by different search instances can appear
at different depths 
our primary goal in these experiments is to investigate the proposed linear dependence which 
in this case of non uniform branching factors and non uniform edge costs  we may express
log e  d log bbfs     

    

where d is the average optimal solution depth  bbfs is the effective branching factor of breath first
search  and  is a constant not depending on   to examine to what extend our data supports
this hypothesis  we calculate the least squares linear fit  or linear fit for short  of log e  for
each knapsack instance  varying   using the least squares linear regression model  and measure
the coefficient of determination r    in our experiments     out of    knapsack instances of type
strongly correlated and all    knapsack instances of type subset sum have the r  value at least
     for these instances  over     of the variation in log e depends linearly on   a remarkable fit 
see figure   for detailed histograms of r  values for our knapsack instances  the median r  is
       for knapsack instances of type strongly correlated  and is        for those of type subset
sum  graphs of log e and its linear fit for knapsack instances with the median r  among those of
the same type are shown in figures   and    note that as there are an even number of instances of
   

fidinh  dinh  michel    russell

each type  there is no single instance with the median value  the instances shown in these graphs
actually have the r  value below the median 
knapsack instance of type strongly correlated with median r 
instance   
linear fit
bfs

log   e

 
 
 
 
 
   

   

   
   
   
heuristic error 

 

figure    graph of log   e and its least squares linear fit for the knapsack instance of type strongly
correlated with the median r   see data in table    

knapsack instance of type subset sum with median r 
   

instance   
linear fit
bfs

log   e

    

   

    
   

   

   
   
   
heuristic error 

 

figure    graph of log   e and its least squares linear fit for the knapsack instance of type subset
sum with the median r   see data in table    

remark of course  there may be instances that poorly fit our prediction of linear dependence  such
as instance     of strongly correlated type whose r  value is only        though those instances
   

fithe time complexity of a with approximate heuristics

rarely show up in our experiments  in such an instance  the a search using heuristic function h
may explore even fewer nodes than the a search using h does  for some small       this
phenomenon can be explained by the degree to which we can control the accuracy of our heuristic
function h   in particular  we can only guarantee that h is admissible and  approximate  while
in reality it may provide an approximation better than  to all nodes that are opened  note that h
is not proportional to        hence  h may be occasionally more accurate than h for some
small       resulting in fewer nodes expanded 

frequency

histograms of r  values for knapsack instance families
strongly correlated
subset sum

  

 

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

 

r  value bin limits
figure    histograms of the r  values for knapsack instances 
to analyze more deeply how our data fit the model of equation       we calculate the slope of
the least squares linear fit of log   e for each knapsack instance of type strongly correlated  note
that for such an instance  every search has the same optimal solution depth  denoted d  and thus 
d   d  our data  given in figure    show that for all but one instance with the worst r  value  the
slope a of the linear fit of log   e is fairly close to d log   bbfs   which is the slope of the hypothesized
line given in equation       specifically  for any knapsack instance of type strongly correlated 
except instance     
    d log   bbfs  a      d log   bbfs  

    a search for partial latin square completion
the experimental results discussed above for the knapsack problem support the hypothesis of linear
scaling  cf   equation     or        however  several structural features of the search space and
heuristic are unknown  for example  we cannot rule out the possibility that the approximation
algorithm  when asked to produce an  approximation  does not in fact produce a significantly
better approximation  likewise  we have no explicit control on the number of near optimal solutions 
in order to explore the hypothesis in more detail  we experimentally and analytically investigate a
search space for the partial latin square completion problem in which we can provide precise analytic
control of heuristic error  as well as the number of  optimal solutions n  
      the partial latin square completion  pls  problem
a latin square of order n is an n  n table in which each row and column is a permutation of the
set  n                n   if only a few cells in an n  n table are filled with values from  n  in such a
   

fidinh  dinh  michel    russell

knapsack instance type  strongly correlated
instance
 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  

optimal
solution
depth d
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

effective branching
factor of breath first
search bbfs
      
      
       
      
      
       
      
      
       
      
      
       
      
       
       
      
      
      
      
      

slope
of
linear fit a

a  d log   bbfs  

coefficient of
determination r 

      
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

figure    slopes of the least squares linear fits of log   e  varying   for the knapsack instances of
type strongly correlated  details of these least squares linear fits are given in tables       and   
the r  values for these knapsack instances are also included in this figure 
way that no value appears twice in a single row or column  then the table is called a partial latin
square  a completion of a partial latin square l is a latin square that can be obtained by filling
the empty cells in l  see figure   for an example  note that not every partial latin square has a
completion  since the problem of determining whether a partial latin square has a completion is
np complete  colbourn         its search version  denoted pls   i e   given a partial latin square
l find a completion of l if one exists  is np hard 
 

 
 

 
 
 

 
 

 
 
 
 
 

 
 

 
 
 
 
 

 
 
 
 
 

 
 
 
 
 

 
 
 
 
 

figure    a      partial latin square  right  and its unique completion  left  
the pls problem  also known as partial quasi group completion  has been used in the recent
past as a source of benchmarks for the evaluation of search techniques in constraint satisfaction
and boolean satisfiability  gomes   shmoys         indeed  partially filled latin squares carry
embedded structures that are the trademark of real life applications in scheduling and time tabling 
furthermore  hard instances of the partially filled latin square trigger heavy tail behaviors in
backtrack search algorithms which are common place in real life applications and require randomization and or restarting  gomes  selman    kautz         additionally  the pls problem exhibits
a strong phase transition phenomena at the satisfiable unsatisfiable boundary  when     of the
cells are filled  which can be exploited to produce hard instances  we remark that the underlying
   

fithe time complexity of a with approximate heuristics

structure of latin squares can be found in other real word applications including scheduling  timetabling  tay         error correcting code design  psychological experiments design and wavelength
routing in fiber optics networks  laywine   mullen        kumar  russell    sundaram        
      a search model for pls
fix a partial latin square l of order n with c     completions  we divide the cells of the n  n table
into two types  the black cells  those that have been filled in l  and the white cells  those that are
left blank in l  let k be the number of white cells  the white cells are indexed from   to k    in a
fixed order  e g   left to right and top to bottom of the table  the task of a search now is to find a
completion of l  hard instances are obtained when the white cells are uniformly distributed within
every row and every column and when the density of black cells is  n   k  n       to tap into
the phase transition  we further insure that the number of completions is c   o     c is exactly  
for the experiments  
to structure the search space for this problem  we place the white cells on a virtual circle so that
the white cells of index i and  i      mod k are adjacent  we can move along the circle  each step is
either forward  from a white cell of index i to the cell of index  i      mod k  or backward  from a
white cell of index i to the cell of index  i     mod k  and may set the content of the current cell 
formally  we define the search graph  denoted gl   for the pls instance given by l as follows  each
state  or node  of gl is a pair    p   in which p            k     indicates the index of the current
white cell  and                k                  n  is a function representing the current assignment of
values to the white cells  we adopt the convention that  j      means the white cell of index j
has not been filled   there is a directed link  or edge  from state    p  to state    q  in the search
graph gl if and only if q    p     mod k   q       and  j     j  for all j    q  in other words 
the link from state    p  to state    q  represents the step consisting of moving from the white
cell of index p to the white cell of index q  and setting the value  q  to the white cell of index q 
figure   illustrates the links from one state to another in gl   the cost of every link in gl is a unit 
obviously  this search graph is regular and has  out  degree of  n 
the starting state is         where    j      for all j  a goal state  or solution  is of the form
    p   where  is the assignment corresponding to a completion of l  and p              k      so 
a solution on the cover tree of gl is a path in the search graph gl from the starting state to a
goal state  and the length of an optimal solution is equal to k  we will show that the number of
 optimal solutions in the cover tree of gl is not too large 
lemma      let l be an n  n partial latin square with k white cells  let  be the assignment
corresponding to a completion of l  for any    t   k  the number of paths
 of length k   t in gl

from the starting state to a goal state of the form       is no more than   t       t k t
nt  
t
proof  we represent a path in gl of length k   t from the starting state as a pair hp   v i  in which
p is a  k   t  length path in the circle of white cells starting from the white cell of index    and
 v    v            vk t   is a sequence of values in  n  with vi being the value assigned to the white cell
visited at the ith step of the path p   consider a pair hp   v i that represents a path in gl ending up at
a goal state        since   j       for all j  every white cell must be visited at some non zero step
of p   let sj     be the last step at which the white cell of index j is visited  then we must have
vsj     j  for all j              k      given such a path p   there are nt ways of assigning values to
the white cells in order to eventually obtain the assignment    thus  the number of  k   t  length
paths in gl from the starting state to a goal state       is equal to  pt  nt   where pt is the set of
 k   t  length paths on the circle of white cells that start at white cell of index   and visit every
white cell 
it remains to upper bound  pt    consider a path p  pt   our strategy is to bound the number of
backward  or forward  steps in p   as t   k  there are at least k  t    white cells visited exactly
   

fidinh  dinh  michel    russell

 

k 

 

k 

 

 

 

 

 

 

 
 

k 

 

k 

 

 

 

 

   v
h

 

 

 

i

 

 

 

 

 

 

 

 

 

 

 

 

 

k 
k 

 

 
 

p

 
 

p

 

 

 

p 

v

 

 

h 

   v
i

 

 

 

 

 

 

 

 

p

v

 

p  

 

 
 

 

 

figure    the links connecting states in a pls search graph  the label h    vi  resp   h   vi  on
the links means moving forward  resp   backward  and setting value v   n  to the next white cell 

once in p   let w be the index of a white cell that is visited exactly once in p and let s be the step
at which the white cell w is visited 
assume the step s is a forward step  i e   the white cell visited at step s    is  w     mod k 
let w  be the farthest white cell from w in the backward direction that is visited before step s 
precisely  w     w     mod k  where   is the maximal number in             k     for which the white
cell  w     mod k is visited before step s  let wj    w    j  mod k  for j              k     note that
w    w  then the set of white cells visited at the first s steps is  w    w            w     and by deleting
some steps among the first s steps in p we will obtain the path  w    w            w    from w  to w  in
the forward direction  each of the white cells w              wk  must be visited at a step after step
s and also in the forward direction because the white cell w  is visited only once and at a forward
step  thus  by deleting t steps from p we obtain a path visiting the white cells w    w            wk  in
the forward direction  let s            sk  be the steps in p that are not deleted  where wj is visited
at step sj in p   and    s    s            sk   k   t  then steps s            sk  are all forward steps
 step s  can be forward or backward   moreover  the number of backward steps and the number of
forward steps between sj  and sj must be equal for all j              k     let  be the number of
deleted steps before s  and after sk  so that there are exactly  t      backward steps between
s  and sk   this shows there are at most
        t             t        t     backward steps

in p   note that there at most k t
paths in pt that have exactly j backward steps  path p has
j
t     backward steps only when    t  and thus sj   sj      for all j              k     and every
step from   to s  and after sk  is backward  there are t     such paths in pt   each corresponding
to a choice of s               t      
similarly  if the step s is a backward step  then there are at most t     forwardsteps in p   also 
there are t     paths in pt that have exactly t     forward steps  and at most k t
paths in pt that
j
   

fithe time complexity of a with approximate heuristics

have exactly j forward steps  hence 

 pt      t      


t 
x
k t
j  

the last inequality holds since the coefficient

j






  t   t k t
 
t

k t
j



increases as j increases for j    k   t    

the upper bound in lemma     is achieved when t      in fact  there are four ways to visit
every white cell in k steps starting from the white cell    taking either k forward steps or k backward
steps or one backward step followed by k    forward steps or one forward steps followed by k   
backward steps  so the number of optimal solutions in the cover tree of gl is equal to  c  since
there are c completions of the initial partial latin square 
theorem      let l be an n  n partial latin square with k white cells and c completions  for
any           the number of nodes expanded by a search on gl with a  accurate heuristic is no
more than b    where
b    

 
   n k    ck 
   n 

k

if k      

   ck bkc       bkc

k bkc
bkc



n

bkc

if k     

proof  by lemma      the number of nodes expanded by a search on gl with a  accurate heuristic
is upper bounded by    n k   kn   where n is the number of  optimal solutions in the cover tree
of gl   so  we only need to bound n  
if k      then n equals the number of optimal solutions  which implies the upper bound of
   n k    ck on the number of expanded nodes by a  
in the general case  let     bkc  since k   k  by lemma      we have



 
x
k t
  t   t
nt
t
t  
 

 x
 
 
x
k  
t
t
  c
 t     n    c
tn
 
t  
t  


k  
 
  c       n    c
 n   
 

n  c



the second inequality holds because k t
 k  
for all t     the last inequality is obtained by
t
 
p 
p 
t
 
applying the fact that t   tn    n and t   nt   n  for all integers n    and       which
can be proved easily by induction on    hence  the number of nodes expanded by a is no more
than



k  
   n k    ck          
n   
 

corollary      suppose           then the number of nodes expanded by a search on gl with
a  accurate heuristic is


k
k
o k                     nk  

proof  by theorem      all we need is an upper bound on the binomial coefficient k  
for large k 
 
where     bkc  since both k and   are large  we will bound this binomial coefficient using stirlings
   

fidinh  dinh  michel    russell



n
formula  which asserts that n    n ne   more precisely  write n     n
as n    we have


k  
 k      
 
 
k   
p
k  
  k      k  
k  
e
 


 
k
 k ke k     e   

k      k     k  
k  

 
 
 
k  
k k   
 k 


n n
e

n   then n   

by stirlings formula  the term k    k   is o     since
k  
k
k
   
  
       
 
bkc
k   



for k       the term k       k  is o    k   the remaining term is
 k     k  
 
k k   


k 
 

k
 
k
 
k
  
  
           
k
 

x

since    k and the function g x         k x  monotonically increases for x      hence 



k  
k  
 
 
  o        k    
 
 

k
from theorem      the number of nodes expanded by a is no more than
 
 
k     k
b        n k   o k  
n
 
 

k
 
   
k
k
  o k           
n
 


it follows from the above corollary that the effective branching factor of a using a  accurate

heuristic on gl is asymptotically at most                 n   which is significantly smaller than

the brute force branching factor of  n  since both       n and          converge to   as     
      experiments
given the search model for the pls problem described above  we provide experimental results of
a search on a few pls instances  each of which is determined by a large partial latin square with
a single completion  for each pls instance in our experiments  we run a search with different
heuristics of the form      h given by various values of           we emphasize that by the dominance property of admissible heuristics  the number of nodes expanded by a using any admissible
 accurate heuristic strictly larger than      h is less than or equal to that by the a using the
heuristic      h   in other words  the heuristic      h is worse than most admissible  accurate
heuristics 
to build the oracle for the heuristic      h on a search graph gl   we use the information
about the completion of the partial latin square l to compute h   consider a partial latin square
l with k white cells  and an arbitrary state    p  in gl   we will show how to compute the optimal
   

fithe time complexity of a with approximate heuristics

cost h    p  to reach a goal state in gl from state    p   let x   be the set of white cells at
which  disagrees with the completion of l  then h    p  is equal to the length of the shortest
paths on the cycle starting from p and then visiting every point in x    the case in which
 x      p       is easy to handle  so we shall assume  x      p       from now on  in particular 
suppose x      p     p            p    with        where pj is the j th point in x      p  that is visited
when moving forward  clockwise  from p  see figure    there are two types of paths on the cycle
starting from p and visiting every point in x      p   type i includes those that do not visit p  type
ii includes those visiting p  let    and    be the length of the shortest paths of type i and type ii 
respectively  then
 
min           
if p   x    

h    p   
min               if p  x    
so now we only need to compute    and      computing    is straightforward  it is realized by either
moving forward from p to p  or moving backward from p to p    that is
     min  p   p  p  p   
def

where z   z mod k for any integer z  to compute      we consider two options for each j  option
 a  moving forward from p to pj and then moving backward from pj to pj     option  b  moving
backward from p to pj   and then moving forward from pj   to pj   thus 


     min min  pj  p  p  pj       pj  pj    
 j  

moving forward
p 

p

p  

p 

pm

p 

pm 
pj  

pj

figure    layout of the points in x   
now we describe our experiments in detail  we generate six partial latin squares with orders
from    to    in the following way  initially  we generate several partial latin squares obtained at or
near the phase transition with white cells uniformly distributed within every row and column  each
instance is generated from a complete latin square with a suitably chosen random subsets of its
cells cleared  each candidate partial latin square is solved again with an exhaustive backtracking
search method to find all completions  the subset of candidates with exactly one completion is
retained for the experiments  for each partial latin square l and each chosen value of   we record
the total number e of nodes expanded by a on the search graph gl with the      h heuristic 
then  as in the knapsack experiments  the effective branching factor of a is calculated as e   k  
since the optimal solution depth in gl equals the number of white cells in l  our first purpose is to
compare these effective branching factors obtained from experiments to our upper bound obtained
   

fidinh  dinh  michel    russell

from theoretical analysis  recall from theorem     that e  b    where in this case
b    

 
   n k    k 
   n 

k

if k      

   k bkc       bkc

k bkc
bkc



n

bkc

if k     

  k

therefore  we calculate the theoretical upper bound b  
on the effective branching factor e   k  
  k
for deeper comparison  we calculate the multiplicative gap b    e   k between our theoretical
bound and the actual values  in our empirical results given in tables   and    these multiplicative
gaps are close to   when  is small and k is large  notice that for each given k  the upper bounds
of b   are almost the same for the s with the same value of bkc  this is why the multiplicative
gaps for those s sometimes increase when  decrease  however  the multiplicative gaps decrease
as bkc decreases  for each fixed k  our upper bounds in the cases with k     are much tighter
than in the others  with the same k  because in the cases of k     we can compute the number of
 optimal solutions exactly  also observe that  for each fixed   the multiplicative gaps decrease as k
increases  finally  the experiments show a dramatic gap between the effective branching factors and
the corresponding brute force branching factor  which equals  n  in fact  for each instance  both the
  k
effective branching factor e   k and our theoretical upper bound b  
approach   as  approaches
  
as in the experiments for the knapsack problem  our data for the partial latin square problem
also support the linear dependance of log e on   in particular  all but one partial latin square
instances have the r  larger than      the worst one has r  value equal to          the median r 
value for our partial latin square instances is         the graph for the instance with the median
r  is shown in figure    
partial latin square instance with median r 
instance  
linear fit

 

log   e

 
 
 
 
 

   

 
   
 
heuristic error 

   

 
   

figure     graph of log   e and its least squares least squares linear fit  or linear fit  for the
partial latin square instance with the median r   see data in table    
we also investigate how the slope of the least squares linear fit of log e approximates the slope
of d log b in the hypothesized linear dependence of equation       recall that in this case  the
branching factor is b    n and the optimal solution depth is d   k  figure    shows that  for every
pls instance in our experiment  the slope  of the least squares linear fit of log   e approximates
   

fithe time complexity of a with approximate heuristics

to k log     n  by a factor of      i e        k log     n   in other words  our experimental results
for the pls indicate the following relationship 
log   e       k log     n      

or equivalently  e    n    k  

thus  empirically  the effective branching factor of a search using the heuristic    h on the given
pls search space approximates to   n       by the dominance property of admissible heuristics 
this is also an empirical upper bound on the effective branching factor of a using any admissible
 accurate on the same search space 
instance  

n

k

 
 
 
 
 
 

  
  
  
  
  
  

  
  
  
   
   
   

slope of linear
fit line 
       
       
       
        
        
        

  k log     n  
      
      
      
      
      
      

figure     slopes of the least squares linear fits of log   e for the partial latin square instances 

   reduction in depth vs  branching factor  comparison with previous
work
in this section we compare our results with those obtained by korf et al   korf   reid        korf
et al          as mentioned in the introduction  they concluded that the effect of a heuristic function
is to reduce the effective depth of a search rather than the effective branching factor  considering
the striking qualitative difference between their findings and ours  it seems interesting to discuss
why their conclusions do not apply to accurate heuristics 
they study the b ary tree search model  as above  and permit multiple solutions  however  their
analysis depends critically on the following equilibrium assumption 
equilibrium assumption  the number of nodes at depth i with heuristic value not exceeding  
is bi p      where p     is the probability that h v     when v is chosen uniformly at random among
all nodes of given depth  in the limit of large depth 
we remark that while the equilibrium assumption is a strong structural requirement  it holds in
expectation for a rich class of symmetric search spaces  to be specific  for any state transitive
search space   like the rubiks cube  the quantity bi p     is precisely the expected number of vertices
at depth i with h v     if the goal state  or initial state  is chosen uniformly at random  korf
et al         observe that under the equilibrium assumption  one can directly control the number
of expanded
p nodes of total weight no more than    a quantity we denote e     indeed  in this case
e      i  bi p     i   with this in hand  they consider the ratio
p 
p 
i
bi  p     i 
e   
i   b p     i 
  p  
  b  pi  
 b 
    
 
i
i  p     i 
e      
i   b p        i 
i   b
and conclude that e d   bd  e     thus the effective branching factor is
q
p
d
bd  e     b d e   
   we say that a search space is state transitive if the structure of the search graph is independent of the starting
node  note that any cayley graph has this property  so natural search spaces formed from algebraic problems
like the rubiks cube or    puzzle  with the right choice of generators  have this property 

   

fidinh  dinh  michel    russell

if the optimal solution lies at depth d 
a difficulty with this approach is that even in the presence of a mildly accurate heuristic satisfying  for example 
h v   h  v  for small  constant        
the actual values of these quantities satisfy
e      e           e t     
for all t  d   even the root of the tree has h root     d   observe 
then  that 
if e d      the
p
d
argument above actually results in an effective branching factor of d bdd e d    b   d   b   
yielding reduction in the branching factor  indeed  applying this technique to infer estimates on
the complexity of a   even assuming the equilibrium
p i assumption  appears to require control of
the threshold quantity    at which the quantities
b p      i  become non negligible  of course 
the equilibrium assumption may well apply to heuristics with weaker or  for example  nonuniform
accuracy 
one perspective on this issue can be obtained by considering the case of search on a b regular
 non bipartite  connected  graph g    v  e  and observing that the selection of a node uniformly
at random from all nodes of a given depth  in the limit of large depth is  in this case  equivalent
to selection of a random node in the graph  if we again consider a mildly accurate heuristic h for
which  say  h v   h  v  for a small constant   we have bi p      bi prv    dist v  s       where v
is chosen uniformly at random in the graph  s is the set of solution nodes  and dist v  s  denotes
the length of the shortest path from v to a node of s  as
 s   b 
  v   dist v  s       

pr dist v  s        
v
 v  
 v  

 

in any b regular graph  we can only expect the relation of equation      to hold past the threshold
value      logb   s   v    

acknowledgments
we wish to thank anonymous reviewers for their constructive comments  author hang dinh was
supported by iu south bend faculty research grant  author laurent michel was supported by
the nsf under grant           author alexander russell was supported by the nsf under grant
         

   

fithe time complexity of a with approximate heuristics

appendix a  tables of experimental results
 

n

heuristic
error 

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

total
node
expansions
e
    
    
      
      
      
       
       
       
       

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

 

  
  
  
  
  
  
  
  
  

 

optimal
solution
depth d

search
time
 seconds 

  
  
  
  
  
  
  
  
  

   
   
   
   
    
    
    
    
    

         
         
         
         
         
         
         
         

     
     
      
      
       
       
       
       
       

 
 
 
 
 
 
 
 
 

   
   
    
    
    
    
    
    
   

        
        
        
        
        
        
        
        

   
      
     
      
    
      
     
      
bfs

  
   
    
    
     
      
      
       
       

 
 
 
 
 
 
 
 
 

 
 
  
   
   
   
   
   
   

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

    
     
     
     
      
      
       
       
       

 
 
 
 
 
 
 
 
 

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

     
     
     
      
      
       
       
       
       

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

h   n   m

effective
branching

d
factor
e
        
        
        
        
       
        
        
        
        

log   e

linear
fit to
log   e

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

        
        
        
        
        
        
        
      
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
         
         

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  
   
   
   
   
   
   
   
   

        
        
        
        
        
        
        
        

        
       
        
       
        
        
       
        
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 
 
 
 
 
 
 
 
 

   
   
   
   
    
    
   
   
   

        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

    
     
     
     
      
      
       
       
       

 
 
 
 
 
 
 
 
 

  
   
   
   
   
   
   
   
   

        
        
        
        
        
        
        
        

        
       
        
        
        
        
         
         
         

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

    
    
    
     
     
      
      
       
       

 
 
 
 
 
 
 
 
 

  
  
  
   
   
   
   
   
   

        
        
        
        
        
        
        
        

        
        
        
       
        
        
       
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

r 

      

      

      

      

      

      

      

table    results for the knapsack instances of type strongly correlated 

   

fidinh  dinh  michel    russell

 

n

heuristic
error 

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

total
node
expansions
e
    
    
     
     
      
      
       
       
       

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

  

  
  
  
  
  
  
  
  
  

  

optimal
solution
depth d

search
time
 seconds 

 
 
 
 
 
 
 
 
 

   
   
   
   
   
   
    
    
   

        
        
        
        
        
        
        
        

   
   
    
    
     
     
      
       
       

 
 
 
 
 
 
 
 
 

  
  
  
  
  
   
   
   
   

        
        
        
        
        
        
        
        

   
      
     
      
    
      
     
      
bfs

     
     
      
      
      
       
       
       
       

 
 
 
 
 
 
 
 
 

   
   
   
   
    
    
    
    
   

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

   
   
   
     
     
      
      
       
       

 
 
 
 
 
 
 
 
 

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

    
    
    
    
     
     
      
       
       

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

h   n   m

effective
branching

d
factor
e
        
        
        
        
        
        
        
        
      

log   e

linear
fit to
log   e

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

        
        
        
        
        
        
        
         
         

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  
  
  
   
   
   
   
   
   

        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 
 
 
 
 
 
 
 
 

  
  
  
  
  
   
   
   
   

        
        
        
        
        
        
        
        

        
        
        
        
        
        
         
         
         

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

    
    
     
     
     
      
       
       
       

 
 
 
 
 
 
 
 
 

   
   
   
   
   
   
   
   
   

        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

   
    
    
    
     
      
      
      
      

 
 
 
 
 
 
 
 
 

  
  
  
  
   
   
   
   
   

        
        
        
        
        
        
        
        

        
        
        
        
        
        
         
         
         

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

r 

      

      

      

      

      

      

      

table    results for the knapsack instances of type strongly correlated 

   

fithe time complexity of a with approximate heuristics

 

n

heuristic
error 

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

total
node
expansions
e
     
     
      
      
      
      
      
      
       

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

  

  
  
  
  
  
  
  
  
  

  

optimal
solution
depth d

search
time
 seconds 

 
 
 
 
 
 
 
 
 

   
   
   
   
   
   
   
   
   

        
        
        
        
        
        
        
        

    
    
    
    
     
     
      
       
       

 
 
 
 
 
 
 
 
 

  
  
  
  
   
   
   
   
    

        
        
        
        
        
        
        
        

   
      
     
      
    
      
     
      
bfs

   
   
   
     
     
      
      
       
       

 
 
 
 
 
 
 
 
 

  
  
  
   
   
   
   
   
   

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

   
   
     
     
      
      
       
       
       

 
 
 
 
 
 
 
 
 

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

    
    
     
     
     
      
       
       
       

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

h   n   m

effective
branching

d
factor
e
        
        
        
        
        
        
        
        
         

log   e

linear
fit to
log   e

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

        
        
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
       
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  
  
   
   
   
   
   
    
   

        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 
 
 
 
 
 
 
 
 

  
  
   
   
   
   
   
   
   

        
        
        
        
        
        
        
        

        
        
        
       
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 
 
 
 
 
 
 
 
 

   
    
   
   
   
   
   
   
   

        
        
        
        
        
        
        
        

        
       
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

r 

      

      

      

      

      

      

table    results for the knapsack instances of type strongly correlated 

   

fidinh  dinh  michel    russell

linear fit
to log   e
      
      
      
      
      
      
      
      

 

n

total
node
expansions e
      
      
      
      
      
      
      
      
      

optimal
soln  depth d
  
  
  
  
  
  
  
  
  

search time 
seconds
    
   
   
   
   
   
   
   
  

log   e

  
  
  
  
  
  
  
  
  

heuristic
error 
   
      
     
      
    
      
     
      
bfs

h   n   m

 

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

     
     
     
     
     
     
     
     
      

 
 
 
 
 
 
 
 
 

   
   
   
   
   
  
  
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
 
 
 
 
  
 
 

   
   
   
   
   
   
   
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
 
 
 
  
 
 
 

   
   
   
   
   
   
  
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
  
  
  
  
  
  
  

   
   
   
   
   
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

     
     
     
     
      
      
      
      
      

  
 
 
 
 
 
 
 
 

   
   
   
   
   
   
  
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
  
  
  
  
  
  
  

    
   
   
   
   
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

r 

      

      

      

      

      

      

      

table    results for the knapsack instances of type subset sum 

   

fithe time complexity of a with approximate heuristics

linear fit
to log   e
      
      
      
      
      
      
      
      

 

n

total
node
expansions e
      
      
      
      
      
      
      
      
      

optimal
soln  depth d
  
  
 
  
 
  
  
 
 

search time 
seconds
    
    
    
   
   
   
   
   
  

log   e

  
  
  
  
  
  
  
  
  

heuristic
error 
   
      
     
      
    
      
     
      
bfs

h   n   m

 

      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      

 

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

 
 
 
 
 
 
  
  
 

   
   
   
   
   
   
   
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
  
  
  
  
  
  
  

    
   
   
   
   
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
  
  
  
  
  
  
  

   
   
   
   
   
   
   
   
  

        
        
        
        
        
        
        
        

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
 
  
 
  
  
  
  
  

   
   
   
   
   
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
  
  
  
  
  
  
  

    
    
    
   
   
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

 
 
  
 
 
 
 
 
  

   
   
   
   
   
   
   
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

r 

      

      

      

      

      

      

      

table    results for the knapsack instances of type subset sum 

   

fidinh  dinh  michel    russell

linear fit
to log   e
      
      
      
      
      
      
      
      

 

n

total
node
expansions e
     
     
     
     
     
     
     
     
     

optimal
soln  depth d
 
 
  
 
  
 
 
 
 

search time 
seconds
    
   
   
   
   
   
   
  
 

log   e

  
  
  
  
  
  
  
  
  

heuristic
error 
   
      
     
      
    
      
     
      
bfs

h   n   m

  

      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
  
  
 
  
  
  
  

    
    
    
    
   
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
  
  
  
  
  
  
  
  

    
    
    
    
    
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

 
  
 
  
 
  
 
  
  

    
   
   
   
   
   
   
   
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

 
 
  
 
 
 
  
 
 

   
   
   
   
   
  
  
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

  

  
  
  
  
  
  
  
  
  

   
      
     
      
    
      
     
      
bfs

      
      
      
      
      
      
      
      
      

  
 
 
 
 
 
 
  
 

   
   
   
   
   
   
  
  
  

       
       
       
       
       
       
       
       

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      

r 

      

      

      

      

      

      

table    results for the knapsack instances of type subset sum 

   

fithe time complexity of a with approximate heuristics

effective
branching
factor
e   k
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

upper
bound
b d   k

b d   k

 
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      

total
node
expansions
e
  
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
    
    
    
    
     
     
     
     
     
     
     
     
     
     
      
      
      
      
      
      

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

 
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    

   
   
   
   
   
   
   
   
   
   
   
    
    
    
    
     
     
     
     
     
      
      
      
      
      
    e   
    e   
    e   
    e   

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

 

n

k

heuristic
error 

 

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

 

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

log   e

linear
fit to
log   e

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

e   k

r 

      

      

table    results for partial latin square instances 

   

fidinh  dinh  michel    russell

effective
branching
factor
e   k
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

upper
bound
b d   k

b d   k

 
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      
    
      
     
      

total
node
expansions
e
   
   
   
   
   
   
   
   
   
   
    
     
     
     
      
      
      
      
      
    e   

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

   
   
   
   
   
   
   
   
   
   
   
   
   

 
      
     
      
    
      
     
      
    
      
     
      
    

   
   
   
   
   
    
    
    
     
      
      
      
    e   

          
          
          
          
          
          
          
          
          
          
          
          
          

  
  
  
  
  
  
  
  
  

   
   
   
   
   
   
   
   
   

 
      
     
      
    
      
     
      
    

   
   
   
   
    
    
     
      
      

  
  
  
  
  
  
  

   
   
   
   
   
   
   

 
      
     
      
    
      
     

   
   
   
    
    
      
      

 

n

k

heuristic
error 

 

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

 

  
  
  
  
  
  
  
  
  
  
  
  
  

 

 

log   e

linear
fit to
log   e

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

          
          
          
          
          
          
          
          
          
          
          
          
          

          
          
          
          
          
          
          
          
          
          
          
          
          

      
      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      
      

          
          
          
          
          
          
          
          
          

          
          
          
          
          
          
          
          
          

          
          
          
          
          
          
          
          
          

      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      

          
          
          
          
          
          
          

          
          
          
          
          
          
          

          
          
          
          
          
          
          

      
      
      
      
      
      
      

      
      
      
      
      
      
      

e   k

r 

      

      

      

      

table    results for partial latin square instances 

   

fithe time complexity of a with approximate heuristics

references
aaronson  s          lower bounds for local search by quantum arguments  in proceedings of the
  th annual acm symposium on theory of computing  stoc   acm press 
babai  l          local expansion of vertex transitive graphs and random generation in finite groups 
in proceedings of the   rd annual acm symposium on symposium of theory of computing 
pp         
chernoff  h          a measure of asymptotic efficiency for tests of hypothesis based on the sum of
observations  annals of mathematical statistics             
chung  f          the diameter and laplacian eigenvalues of directed graphs  electronic journal
of combinatorics         
chung  f  r  k          spectral graph theory  american mathematical society 
colbourn  c  j          the complexity of completing partial latin squares  discrete applied
mathematics              
davis  h   bramanti gregor  a     wang  j          the advantages of using depth and breadth
components in heuristic search  in ras  z     saitta  l   eds    proceedings of the third
international symposium on methodologies for intelligent systems  pp        north holland 
amsterdam  elsevier 
dechter  r     pearl  j          generalized best first search strategies and the optimality of a   j 
acm                 
demaine  e  d          playing games with algorithms  algorithmic combinatorial game theory 
in proc    th symp  on math found  in comp  sci   lect  notes in comp  sci   pp       
springer verlag 
dinh  h   russell  a     su  y          on the value of good advice  the complexity of a  with
accurate heuristics  in proceedings of the twenty second conference on artificial intelligence
 aaai      pp           
edelkamp  s          prediction of regular search tree growth by spectral analysis  in proceedings
of the joint german austrian conference on ai  advances in artificial intelligence  ki    
pp          london  uk  uk  springer verlag 
felner  a   korf  r  e     hanan  s          additive pattern database heuristics  journal of
artificial intelligence research             
friedman  j          a proof of alons second eigenvalue conjecture  in stoc     proceedings of
the thirty fifth annual acm symposium on theory of computing  pp          new york  ny 
usa  acm 
gaschnig  j          perfomance measurement and analysis of certain search algorithms  ph d 
thesis  carnegie mellon university  pittsburgh  pa 
gomes  c     shmoys  d          completing quasigroups or latin squares  a structured graph
coloring problem  in johnson  d  s   mehrotra  a     trick  m   eds    proceedings of the
computational symposium on graph coloring and its generalizations  pp        ithaca  new
york  usa 
gomes  c  p   selman  b     kautz  h          boosting combinatorial search through randomization  in aaai    iaai     proceedings of the fifteenth national tenth conference on artificial intelligence innovative applications of artificial intelligence  pp          menlo park 
ca  usa  american association for artificial intelligence 
hart  p   nilson  n     raphael  b          a formal basis for the heuristic determination of minimum
cost paths  ieee transactions on systems science and cybernetics  scc               
   

fidinh  dinh  michel    russell

helmert  m     roger  g          how good is almost perfect   in proceedings of aaai    
hochbaum  d          approximation algorithms for np hard problems  brooks cole 
horn  r     johnson  c          matrix analysis  cambridge university press  cambridge  uk 
huyn  n   dechter  r     pearl  j          probabilistic analysis of the complexity of a   artificial
intelligence             
ibarra  o  h     kim  c  e          fast approximation algorithms for the knapsack and sum of
subset problems  journal of the acm                 
karp  r  m          reducibility among combinatorial problems  in miller  r  e     thatcher 
j  w   eds    complexity of computer computations  p         new york  plenum 
kellerer  h   pferschy  u     pisinger  d          knapsack problems  springer 
korf  r          depth first iterative deepening  an optimal admissible tree search  artificial
intelligence            
korf  r     reid  m          complexity analysis of admissible heuristic search  in proceedings of
the national conference on artificial intelligence  aaai      pp         
korf  r   reid  m     edelkamp  s          time complexity of iterative deepening a   artificial
intelligence                    
korf  r  e          recent progress in the design and analysis of admissible heuristic functions  in
aaai iaai       pp            also in sara     proceedings of the  th international
symposium on abstraction  reformulation  and approximation 
kumar  r   russell  a     sundaram  r          approximating latin square extensions  in cocoon     proceedings of the second annual international conference on computing and
combinatorics  pp          london  uk  springer verlag 
laywine  c     mullen  g          discrete mathematics using latin squares  interscience series in
discrete mathematics and optimization  wiley 
lenstra  a  k   lenstra  h  w     lovasz  l          factoring polynomials with rational coefficients 
tech  rep         universiteit amsterdam 
motwani  r     raghavan  p          randomized algorithms  cambridge university press 
parberry  i          a real time algorithm for the  n      puzzle  inf  process  lett           
pearl  j          heuristics  intelligent search strategies for computer problem solving  addisonwesley  ma 
pisinger  d          where are the hard knapsack problems   computers and operations research 
             
pohl  i          practical and theoretical considerations in heuristic search algorithms  in elcock 
w     michie  d   eds    machine intelligence  vol     pp        ellis horwood  chichester 
ratner  d     warmuth  m          the  n      puzzle and related relocation problems  journal
for symbolic computation                 
russell  s     norvig  p          artificial intelligence   a modern approach  prentice hall  new
jersey 
sen  a  k   bagchi  a     zhang  w          average case analysis of best first search in two
representative directed acyclic graphs  artif  intell                     
tay  t  s          some results on generalized latin squares  graphs and combinatorics         
    
vazirani  v          approximation algorithms  springer verlag 
   

fithe time complexity of a with approximate heuristics

vazirani  v          primal dual schema based approximation algorithms  in theoretical aspects of
computer science  advanced lectures  pp          springer verlag  new york 
zahavi  u   felner  a   schaeffer  j     sturtevant  n          inconsistent heuristics  in proceedings
of aaai     pp           
zhang  z   sturtevant  n  r   holte  r   schaeffer  j     felner  a          a  search with inconsistent
heuristics  in proceedings of the   st international jont conference on artifical intelligence 
ijcai    pp          san francisco  ca  usa  morgan kaufmann publishers inc 

   

fi