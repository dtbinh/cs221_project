journal of artificial intelligence research                  

submitted        published      

transforming graph data for statistical relational learning
ryan a  rossi

rrossi purdue edu

department of computer science  purdue university
west lafayette  in       usa

luke k  mcdowell

lmcdowel usna edu

department of computer science  u s  naval academy
annapolis  md        usa

david w  aha

david aha nrl navy mil

navy center for applied research in artificial intelligence
naval research laboratory  code      
washington  dc        usa

jennifer neville

neville purdue edu

department of computer science  purdue university
west lafayette  in       usa

abstract
relational data representations have become an increasingly important topic due to
the recent proliferation of network datasets  e g   social  biological  information networks 
and a corresponding increase in the application of statistical relational learning  srl 
algorithms to these domains  in this article  we examine and categorize techniques for
transforming graph based relational data to improve srl algorithms  in particular  appropriate transformations of the nodes  links  and or features of the data can dramatically
affect the capabilities and results of srl algorithms  we introduce an intuitive taxonomy
for data representation transformations in relational domains that incorporates link transformation and node transformation as symmetric representation tasks  more specifically 
the transformation tasks for both nodes and links include  i  predicting their existence   ii 
predicting their label or type   iii  estimating their weight or importance  and  iv  systematically constructing their relevant features  we motivate our taxonomy through detailed
examples and use it to survey competing approaches for each of these tasks  we also discuss general conditions for transforming links  nodes  and features  finally  we highlight
challenges that remain to be addressed 

   introduction
in this article  we examine and categorize techniques for transforming relational data to improve statistical relational learning  srl  algorithms  below  section     first introduces
relational data and srl  we summarize the primary types of representations for relational
data  and explain that we focus on data represented as graphs  section     also describes
how transforming the content  rather than the type  of this representation can improve srl
analysis  for instance  predicting new links in a graph can increase accuracy for relational
node classification  section     then identifies the scope of this article  finally  section    
summarizes the organization and approach of this article  and includes a description of our
taxonomy for relational representation transformation 
c
    
ai access foundation  all rights reserved 

firossi  mcdowell  aha    neville

    relational data  srl  and representation choices
the majority of research in machine learning assumes independently and identically distributed data  this independence assumption is often violated in relational data  which encode dependencies among data instances  for instance  people are often linked by business
associations  and information about one person can be highly informative for a prediction
task involving an associate of that person  more generally  relational data can be described
as a set of nodes  which can be connected by one or more types of relations  or links  
relational information is seemingly ubiquitous  it is present in domains such as the internet
and the world wide web  faloutsos  faloutsos    faloutsos        broder et al         albert  jeong    barabasi         scientific citation and collaboration  mcgovern et al        
newman      b   epidemiology  pastor satorras   vespignani        moore   newman 
      may   lloyd        kleczkowski   grenfell        communication analysis  rossi
  neville         metabolism  jeong  tombor  albert  oltvai    barabasi        wagner
  fell         ecosystems  dunne  williams    martinez        camacho  guimera   
nunes amaral         bioinformatics  maslov   sneppen        jeong  mason  barabasi 
  oltvai         fraud and terrorist analysis  neville et al         krebs         and many
others  the links in these data may represent citations  friendships  associations  metabolic
functions  communications  co locations  shared mechanisms  or many other explicit or implicit relationships 
statistical relational learning  srl  methods have been developed to address the problems of reasoning and learning in domains with complex relations and probabilistic structure
 getoor   taskar         in particular  srl algorithms leverage relational information in
an attempt to learn models with higher predictive accuracy  a key characteristic of many
relational datasets is a correlation or statistical dependence between the values of the same
attribute across linked instances  e g   two friends are more likely to share political views
than two randomly selected people   this relational autocorrelation provides a unique opportunity to increase the accuracy of statistical inferences  jensen  neville    gallagher 
       similarly  relational information can be exploited for many other reasoning tasks
such as identifying useful patterns or optimizing systems  easley   kleinberg        
representation issuesincluding knowledge  model  and data representationhave been
at the heart of the artificial intelligence community for decades  amarel        minsky       
russell   norvig         all of these are important  but here we focus on data representation issues  simple examples of which include the choices of whether to discretize continuous
features or to add higher order polynomial features  such decisions can have a significant
effect on the accuracy and efficiency of ai algorithms  they are especially critical for the
performance of srl algorithms because  in relational domains  there is an even larger space
of potential data representations to consider  the complex structure of relational data can
often be represented in a variety of ways and the choice of specific data representation
can impact both the applicability of particular models algorithms and their performance 
specifically  there are two categories of decisions that need to be considered in the context
of relational data representation 
first  we have to consider the type of data representation to use  cf   the hierarchy
of de raedt        ch      for instance  relational data can be propositionalized for the
application of standard  non relational learning algorithms  more often  in order to fully
   

fitransforming graph data for statistical relational learning

exploit the relational information  srl researchers have chosen to represent the data either
using an attributed graph in a relational database  see e g   friedman  getoor  koller   
pfeffer         or via logic programs  see e g   kersting   de raedt          each choice
has different strengths  in this article  we focus on the graph based representation  which
has been a common choice for addressing the growing interest in network data and applications for analyzing electronic communication and online social networks such as facebook 
twitter  flickr  and linkedin  mislove  marcon  gummadi  druschel    bhattacharjee 
      ahmed  berchmans  neville    kompella         specifically  we assume a graphbased data representation g   hv  e  xv   xe i where the nodes v are entities  e g   people 
places  events  and the links e represent relationships among those entities  e g   friendships  citations   xv is a set of features about the entities in v   likewise  the set of features
xe provides information about the relation links in e 
next  given the type of representation  we must consider the specific content of the data
representation  for which there is a large space of choices  for instance  features for the nodes
and links of a graph can be constructed using a wide range of aggregation functions  based on
multiple kinds of links and paths  srl researchers have already recognized the importance
of such data representation choices  e g   getoor   diehl         and many separate studies
have examined techniques for feature construction  neville  jensen  friedland    hay        
node weighting  tang  musolesi  mascolo    latora         link prediction  taskar  wong 
abbeel    koller         etc  however  this article is the first to comprehensively survey
approaches to relational representation transformation for graph based data 
given a set of  graph based  relational data  we define relational representation transformation as any change to the space of links  nodes  and or features used to represent
the data  typically  the goal of this transformation is to improve the performance of some
subsequent srl application  for instance  in figure   the original graph representation g
is transformed into a new representation g where links  nodes  and features  such as link
weights  have been added  and some links have been removed  some srl algorithm or
analysis is then applied to the new representation  for instance to classify the nodes or to
identify anomalous links  the particular transformations that are used to produce g will
vary depending upon the intended application  but can sometimes substantially improve
the accuracy  speed  or complexity of the final application  for instance  gallagher  tong 
eliassi rad  and faloutsos        found that adding links between similar nodes could increase node classification accuracy by up to     on some tasks  similarly  neville and
jensen        demonstrated that adding nodes which represent underlying groups enabled
both simpler inference and increased accuracy 
    scope of this article
this article focuses on examining and categorizing various techniques for changing the
representation of graph based relational data  as shown in figure    we typically view
these changes as a pre processing step that enables increased accuracy or speed for some
other task  such as object classification  however  an output of these techniques can itself
be valuable  for instance  the administrators of a social network may be interested in
   in the latter case  the applicable srl algorithms are often referred to as probabilistic inductive logic
programming  ilp   de raedt   kersting        

   

firossi  mcdowell  aha    neville

c  

c  
srl  analysis     
application  

representation  
transformation  

l  
l  

l  

g  


g  
  

result  

figure    example transformation and subsequent analysis  the original relational representation g is transformed into g where dotted lines represent predicted links  squares represent predicted nodes  and bold links represent link
weighting  changes may be based on link structure  link features  and node features  here  similar node shadings indicate similar feature values   some srl
analysis is then applied to the new representation  in this example  the srl
analysis produces a label  c or l  for each node  as with the example task discussed in section      this article focuses on the representation transformation
 left side of the figure   not the subsequent analysis 

link prediction so that predicted links can be presented to their users as potential new
friendship links  alternatively  these techniques may also be applied to improve the
comprehensibility of a model  for example  the prediction of protein protein interactions
provides insights into protein function  ben hur   noble         thus  the techniques
we survey may be used for multiple purposes  and relevant publications may have used
them in different contexts  regardless of the original context  we will examine the general
applicability and benefits of each technique  after such techniques have been applied  the
transformed data can be used as is  e g   for friendship suggestions   examined for greater
understanding  used for some other task  e g   for object classification   or used recursively
as the input for another representation change  e g   as in object node prediction followed
by link prediction  
we do not attempt to survey the many methods that could be used for srl analysis
 e g   the right side of figure     although the relevant set of methods for such analysis
overlaps with the set of methods that facilitate the transformations we consider  for instance  collective classification  neville   jensen        taskar  abbeel    koller        is
an important srl application that we define in section   and use as a running example
of an srl analysis task  the output of such classification could also be used to create
new attributes for the nodes  a data representation change   we discuss this possibility in
section      but focus on a few cases where such node labeling is particularly useful as a
pre processing step  e g   before applying certain stacked algorithms   rather than surveying the wide range of possible classification algorithms  whether collective or not  likewise 
we do not survey issues in model and knowledge representation  such as whether the sta   

fitransforming graph data for statistical relational learning

tistical dependencies between nodes  links  and features should be modeled with structural
logistic regression  popescul  popescul    ungar      b  or with a markov logic network
 domingos   richardson         we consider such issues only briefly  in section     
furthermore  we focus on transformations that change the content of the graph data
representation  in particular  we examine transformations to graph data that modify the
set of links or nodes  or modify their features  we do not consider changing the graph data
to a different type of representation  e g   by propositionalizing the data or by changing to
a logic program  however  some of the transformations we discuss  such as node or link
feature aggregation  are a form of propositionalization  in addition  section       describes
a number of techniques for structure learning of logic programs  because these techniques
are closely related to the analogous problem of feature construction for graph based representations  finally  many of the other techniques that we discuss are also applicable to
logical representations  for instance  link weighting could be applied to weight the known
relations before using a logic program to detect anomalous objects  we focus  however  on
the methods most useful for transforming graph based representations 
    approach and organization of this article
there are many dimensions of relational data transformation  which complicate the task of
understanding and selecting the most appropriate techniques  to assist in this process  we
introduce a simple and intuitive taxonomy for representation transformation that identifies link transformation and node transformation as symmetric representation tasks  more
specifically  the transformation tasks for both nodes and links include  i  predicting their
existence   ii  predicting their label or type   iii  estimating their weight or importance  and
 iv  constructing their relevant features  in addition  we propose a taxonomy for constructing both link and node features that consists of non relational features  topology features 
relational node value features  and relational link value features  for each relational transformation task  we survey the applicable techniques  examine necessary conditions  and
provide detailed examples and comparisons 
this article is organized as follows  the next section presents our taxonomy for relational
representation transformation and discusses a motivating example  in section    we review
the algorithms for link prediction  while section   examines the task of link interpretation
 i e   constructing link labels  link weights  and link features   sections   and   consider
the corresponding prediction and interpretation tasks for nodes instead of links  in section
   we summarize algorithms that jointly transform nodes and links  section   discusses
methods for evaluating representation transformations and challenges for future work  and
section   concludes 

   overview and motivating example
in this section we first introduce a running example based on the classification of data
from facebook  then describe how relational algorithms could be used to perform this task 
next  we introduce a taxonomy for relational representation transformation and explain
how each type of transformation could aid the facebook classification task  finally  we
formally define each type of relational representation transformation 
   

firossi  mcdowell  aha    neville

    motivating srl analysis example  a classification task
as an example  we consider hypothetical data inspired by facebook  www facebook com  
one of the most popular online social networks  we assume that we are given a graph
g   hv  e  xv   xe i where the nodes v are users   and the links e represent friendships in
facebook  xv is a set of features about the users in v such as their gender  relationship
status  school  favorite movies  or musical preference  though information may be missing
for some users   likewise  the set of features xe provides information about the friendship
links in e such as the time of formation or possibly the contents of the message that was
sent when the link formation was requested by one of the users 
the example srl analysis task  see figure    is to predict the political affiliation  liberal 
moderate  or conservative  of every node  person  in g  we assume that this affiliation 
which we call the class label of a node  is known for some but not all of the people in g  
moreover  we assume that a users political affiliation is likely to be correlated with the
characteristics of that user and  to a lesser degree  that users friends  the next section
summarizes how these correlations can be used for classification 
for this example  we assume that links are simple  binary friendship connections  however  other link types could be used to represent other kinds of relationships  for instance 
a link might indicate that two people have communicated via a wall post message  or that
two people have chosen to join the same facebook group  in addition  the notion of friendship in facebook is very weak and thus a significant portion of a persons friends are often
only casual acquaintances  thus  representation changes such as link deletion or weighting
may have a significant impact on classification accuracy  for notational purposes  we add a
tilde to the top of each graph components symbol to indicate that it has undergone some
transformation  e g   the modified link set e is denoted by e  
    background  features and methods for classification
to predict the political affiliation of facebook users  conventional classification approaches
would ignore the links and classify each user using only information known about that user 
such as their gender or location  we assume that such information is represented in the
form of non relational features  which are those features that can be computed directly
from xv without considering the links e  we refer to classification based only on these
features as non relational classification  alternatively  in relational classification  the links
are explicitly used to construct additional relational features to capture information about
each users friends  for instance  a relational feature could compute  for each user  the
proportion of friends that are male or that live in a particular region  using such relational
information can potentially increase classification accuracy  though may sometimes decrease
accuracy as well  chakrabarti  dom    indyk         finally  even greater  and usually
more reliable  increases can occur when the class labels  e g   political affiliations  of the
linked users are used instead to derive relevant features  jensen et al          for instance 
   in general  there may be more than one type of node  for instance  nodes in a citation network may
represent papers or authors 
   later  we discuss the representation change of node labeling  which also constructs an estimated label
for every node  as discussed in section      representation changes can sometimes resemble the output
of srl analysis  but we focus on changes that are particularly useful as pre processing before some
subsequent srl analysis 

   

fitransforming graph data for statistical relational learning

a class label relational feature could compute  for each user  the proportion of friends
that have liberal views  however  using such features is challenging since some or all of
the labels are initially unknown  and thus typically must be estimated and then iteratively
refined in some way  this process of jointly inferring the labels of interrelated nodes is
known as collective classification  cc  
cc requires both models and inference procedures that use inferences about one user to
affect inferences about related users  many such algorithms have been considered for cc 
including gibbs sampling  jensen et al          relaxation labeling  chakrabarti  dom   
indyk         belief propagation  taskar et al          ica  neville   jensen        lu  
getoor         and weighted neighbor techniques  macskassy   provost         see the
work of sen et al         for a survey 
as a concrete example of srl analysis  we explain many of the techniques in this survey
in terms of the facebook classification task  with a special emphasis on cc  however  the
features and the transformation techniques apply to many other srl tasks and data sets
such as relationship classification  anomalous link detection  entity resolution  or group
discovery  getoor   diehl        
    representation transformation tasks for improving srl
figure   shows our proposed taxonomy for relational representation transformation  the
two main tasks in this taxonomy are link transformation and node transformation  we
find that there is a powerful and elegant symmetry between these two tasks  in particular 
the link and node representation transformation tasks can be decomposed into prediction
and interpretation tasks  the former task involves predicting the existence of new nodes
and links  the latter task of interpretation involves three parts  constructing the weights 
labels  or features of nodes or links  together  this yields eight distinct transformation tasks
as shown in the leaves of the taxonomy in figure    underneath these eight tasks in the
figure  we list the primary graph component that is modified by each task  i e   v   e  xv  
or xe    followed by an illustration of a possible representation change for that task  in
the text below  we summarize figure    organized around the four larger categories of link
prediction  link interpretation  node prediction  and node interpretation 
first  link prediction adds new links to the graph  the sample graph for this task
 figure  a  shows a link being predicted where the similarity between two nodes has been
used to predict a new link between them  intuitively  facebook users that share the values
of many non relational features may also share the same political affiliation  thus  adding
links between such people should increase autocorrelation and improve the accuracy of collective classification  there are many simple link prediction algorithms based on similarity 
neighbor properties  shortest path distances  infinite sums over paths  i e  random walks  
and other strategies  section   provides more detail on these techniques 
second  there are several types of link interpretation  which involves constructing
weights  labels  or features for the existing links  for instance  in many graphs  including
our facebook data   not all links  or friendships  are of equal importance  thus  figure  b
shows the result of performing link weighting  in this case  weights are based on the similarity between the feature values of each pair of linked nodes  under the assumption that
high similarity may indicate stronger relationships   link prediction techniques may also
   

firossi  mcdowell  aha    neville

relational
representation
transformation

input  

  
e   

weighted  link  

labeled  link  

predicted  node  

weighted  node  

labeled  node  

node  transformation  

link  interpretation  

node  prediction  

link  weighting  

link  labeling  

link  feature  
construction  

x  e  

x  e  

x  e  

v    

node  interpretation  

node  weighting  

node  labeling  

node  feature  
construction  

x  v  

x  v  

x  v  

p  
p  

b   

c  
w  

w  

a   

p  

l  

link  transformation  

link  prediction  

predicted  link  

      

   

      

      

p  

c   

   

c  

m  

d   

e   

f   

l  
g   

        b  

        a  

l  

   

        b  

        a  

        a  

h   

figure    relational representation transformation taxonomy  link and node
transformation are formulated as symmetric tasks leading to four main transformation tasks  predicting links  interpreting links  predicting nodes  and interpreting nodes  each task yields a modified graph component  e  xe   v   or
xv   respectively  interpretation is further divided into weighting  labeling  or
constructing features  examples of each of the tasks in relational representation
transformation are shown under the leaves of the taxonomy  in these example
graphs  nodes with similar shadings have similar feature values 

   

fitransforming graph data for statistical relational learning

use such similarity measures  but for identifying probable new links  rather than weighting
existing links   alternatively  link labeling may be used to assign some kind of discrete label
to each link  for instance  figure  c shows how links might be labeled as either personal
 p  or work  w  related  e g   based on known feature values or an analysis of communication events between the linked users  on the other hand  links might instead be labeled
as having positive or negative influence  i e   labeled as      finally  figure  d shows
how link feature construction can be used to add more general kinds of feature values to
each link  for instance  a link feature might count the number of communication events
that occurred between two people or the number of friends in common  link weighting
and labeling could perhaps be viewed as special cases of link feature construction  but we
separate them because later sections will show how the most useful techniques for each task
differ  all three of these link interpretation tasks could help with our example classification
problem  in particular  a model learned to predict political affiliation might choose to place
special emphasis on links that are highly weighted or that are labeled as personal  other
link features might be used to represent more complex dependencies  for instance modeling influence from a users work friendships  but only for friendship links between nodes
where there are a large number of friends in common  more details on these techniques are
provided in section   
third  node prediction adds additional nodes  and associated links  to the graph 
for instance  figure  e shows the result after relational clustering has been applied to
discover two latent groups in the graph  where each user is now connected to one latent
group node  a discovered node in facebook might represent types of social processes 
influences  or a tightly knit group of friends  the clustering or other techniques used to
identify the new nodes could be designed to identify people that are particularly similar
with respect to a relevant characteristic  such as their political affiliation  the new nodes
and associated links could then be used in several ways  for instance  though not present
in the small example of figure  e  some nodes that were far away  in terms of shortest
path length  in the original graph may be much closer in the new graph  thus  links to a
latent node may allow influence to propagate more effectively when an algorithm such as
cc is applied  alternatively  identification of distinct latent groups may even enable more
efficient or accurate algorithms to be applied separately to each group  neville   jensen 
       node prediction is discussed further in section   
finally  there are several types of node interpretation  which involves constructing
weights  labels  or feature values for existing nodes  for instance  as with links  some
nodes may be more influential than others and thus should have more weight  figure  f
demonstrates node weighting  where the weights might be assigned based on the numbers
of friends or via the pagerank eigenvector techniques  see section     for more details 
alternatively  figure  g shows an example of node labeling  here the graph represents
a training graph  and each node has been given an estimated label of conservative  c  
liberal  l   or moderate  m   such labels might be estimated using only the non relational
features or via textual analysis  while most classification algorithms learn a model based
on true labels in the training graph  some approaches instead first compute such estimated
labels  then learn a model from this new representation  kou   cohen         section    
discusses how this can simplify inference  finally  figure  h shows the result of node feature
construction  where arbitrary feature values are added to each node  for instance  suppose
   

firossi  mcdowell  aha    neville

we find that users with relatively few facebook friends are often moderate while those with
many friends are often liberal  in this case  a feature counting the number of friends for each
node would be useful  to more directly exploit autocorrelation  a different feature might
count the proportion of a users friends that are conservative  or the most common political
affiliation of a users friends  any feature that is correlated with political affiliation could
be used to improve the performance of a classification algorithm for our example problem 
identifying and or computing such features is essential to the performance of most srl
algorithms but can be very challenging  section     considers this process 
in table      we summarize some of the most prominent techniques for performing
these tasks of link prediction  link interpretation  node prediction  and node interpretation 
sections     provide more detail about each category in turn 
    relational representation transformation  definitions and terminology
we assume that the initial relational data is represented as a graph g   hv  e  xv   xe i
such that each vi  v corresponds to node i and each edge eij  e corresponds to a
 directed  link between nodes i and j  xv is a set of features about the nodes in v   and
xkv  xv is the k th such feature  likewise  xe is a set of features about the links in
e  and xke  ve is the k th such feature  the features xe could refer to link weights 
distances  or types  among other possibilities  the preceding notation lets us identify  for
instance  the values of a particular feature xkv for all nodes  alternatively  xvi refers to a
vector containing all of the feature values for a particular node vi   and xeij contains all of
the feature values for a particular edge eij   table     summarizes this notation 
relational representation transformation is the process of transforming the original
graph g into some new graph g   hv   e  xv   xe i by an arbitrary set of transformation techniques  during this process  nodes  links  weights  labels  and general features may
be added  and nodes and links may be removed  in theory  the transformation seeks to
optimize some objective function  for instance  to maximize the autocorrelation   although
in practice the objective function may not be completely specified or guaranteed to be improved by the transformation  we now define more specifically the four primary parts of
relational representation transformation 
definition      link prediction  given the nodes v   observed links e and or the feature
set x    xe   xv    the link prediction task is defined as the creation of a modified link set
e such that e    e  usually  this involves adding new links that were not present in e 
but links may also be deleted 
definition      link interpretation  given the nodes v   observed links e and or the
feature set x    xe   xv    the link interpretation task is defined as the creation of a new
link feature xke where xke 
  xe   this task may estimate a feature value for every link 
alternatively  the values of xke may be only partially estimated  for example  if the original
features have missing values or if additional links are also introduced during link prediction 
definition      node prediction  given the nodes v   links e and or the feature set
x    xe   xv    node transformation is defined as the creation of a modified node set v
such that v  v   in addition  many node prediction tasks simultaneously create new links 
   

fitransforming graph data for statistical relational learning

relational representation transformation
links
 

prediction

 
 

 

weighting

 

 

 
 

labeling

 
 

feature

nodes

adamic adar  adamic  
adar         katz  katz        
and others  liben nowell  
kleinberg       
text or feature similarity
 macskassy       
classification
via
rmn
 taskar et al         or svm
 hasan  chaoji  salem    zaki 
     
latent variable estimation  xiang  neville    rogati 
     
linear combination of features  gilbert   karahalios 
     
aggregating intrinsic information  onnela  saramaki 
hyvonen  szabo  lazer  kaski 
kertesz    barabasi       
lda  blei et al          plsa
 hofmann        
link classification via logistic regression  leskovec  huttenlocher    kleinberg        
bagged decision trees  kahanda   neville        
link
feature
similarity
 rossi   neville       
link aggregations  kahanda
  neville       

 

graph features  lichtenwalter  lussier    chawla       

 

 
 

 

betweenness  freeman        
closeness  sabidussi       

 

hits  kleinberg         prob 
hits  cohn   chang        
simrank  jeh   widom       
pagerank  page  brin  motwani    winograd         topical pagerank  haveliwala       
richardson   domingos       
lda  blei et al          plsa
 hofmann        
node
classification
via
stacked model  kou   cohen        or rn  macskassy  
provost       

 

 
 

 
 

construction
 

spectral clustering  neville
  jensen 
      
mixedmembership
relational
clustering  long et al        
lda  blei  ng    jordan        
plsa  hofmann        
hierarchical clustering via
edge betweenness  newman  
girvan       

mln structure learning  kok
  domingos             
database
query
search
 popescul et al       b   rpt
 neville  jensen  friedland  et al  
     
foil  nfoil  landwehr  kersting    de raedt         kfoil
 landwehr  passerini  de raedt 
  frasconi         aleph  srinivasan        

table    summary of techniques  a summary of prominent graph transformation techniques for the tasks of predicting the existence of nodes and links and interpreting
them by weighting  labeling  and constructing general features 

   

firossi  mcdowell  aha    neville

symbol

description

g

initial graph

g

transformed graph

e

initial link set

v

initial node set

e

initial set of link features

v

initial set of node features

x
x

xke
xkv
xeij
xvi
other symbols
a
 vi  


initial link feature k  xke xe    for one feature  values for all links 
initial node feature k  xkv xv    for one feature  values for all nodes 
initial feature vector for eij  for one link  values for all link features 
initial feature vector for vi  for one node  values for all node features 
description
adjacency matrix of the graph
neighbors of vi
cut off value

table    summary of notation used in this survey  the top half of the table shows
symbols that are sometimes written with a tilde on top of the symbol  indicating
the result of some transformation  for conciseness  the table demonstrates this
notation only for g and g 

e g   between an initial node vi  v and a predicted node vj  v   thus  this task may also
produce a modified link set e 
definition      node interpretation  given the nodes v   observed links e and or the
feature set x    xe   xv    the node interpretation task is defined as the creation of a new
  xv   as with link interpretation  the values of xkv may be
node feature xkv where xkv 
estimated for only some of the nodes  the node feature xkv could represent node weights 
labels  or other general features 
section     introduced the notion of a non relational feature  which is a node feature
xkv that can be constructed without making use of the links  i e   without using e or xe   
such features are sometimes referred to in other articles as attributes or intrinsic features 
other important terms can also be referred to in multiple different ways  to aid the reader 
table     summarizes the key synonyms for the terms that are found most often in the
literature 

   link prediction
this section focuses on predicting the existence of links while section   considers link
interpretation  given the initial graph g   hv  e  xv   xe i  we are interested in creating
a modified link set e  usually through the prediction of new links that were not present
   

fitransforming graph data for statistical relational learning

term

potential synonyms

nodes

vertices  points  objects  entities  individuals  users  constants     

links

edges  relationships  ties  arcs  events  interactions  predicates

topology

link network graph structure  relational information

features

attributes  variables  co variates  queries  predicates     

graph measures

topology based metrics  such as proximity  centrality  betweenness      

similarity

distance  the inverse of similarity   likeness

clusters

classes  communities  groups  roles  topics

non relational features

intrinsic attributes features  local attributes features     

relational features

features  link based features  graph features  aggregates  queries     

structure learning

feature generation construction  hypothesis learning

parameter learning

model selection  function learning

table    synonyms in the literature  a summary of possible synonyms found in the
literature for important terms related to relational data 

in e  this task can be motivated in several ways  for instance  there may be a need
to predict missing links that are not present in e because of incomplete data collection
or other problems  similarly  we may be interested in predicting hidden links  where we
assume that there exists some unobservable interactions and the goal is to discover and
model these interactions  for example  in a network representing criminals or terrorist
activity  we may seek to predict a link between two people  nodes  that are not directly
connected but whose actions share some common motivation or cause  for both missing
and hidden links  predicting such links may improve the accuracy of a subsequent learned
model  alternatively  we may seek to predict future links in an evolving network  such as
new friendships or connections that will be formed next year  we might also be interested in
predicting links between objects that are spatially related  finally  we may wish to predict
beneficial links  for instance  predicting pairs of individuals that are likely to be successful
working together 
figure   summarizes one general approach that is often used for these link prediction
tasks  in summary  scores or weights are computed for every pair of nodes in the graph  as
shown in figure   b   predicted links with a weight greater than some threshold   along
with the original links  are used to create the new link set e    shown in figure   e     at
this step  original links with very low weight could also be deleted if appropriate   as a
final step  the weights of the predicted links are often discarded  yielding a new graph with
uniform link weights as shown in figure   f  
the key challenge in this approach is how to compute a weight or score for each possible
link  the information used for this computation provides a natural way to categorize
the link prediction techniques  below  section     describes techniques that use only the
non relational features of the nodes  ignoring the initial links   while section     describes
topology based techniques that use only the graph structure  i e   the links or relations  
   

firossi  mcdowell  aha    neville

 a  initial graph g   he  v i

 b  weighted links wij  e

 c  predicted links  e  e 

 d  pruning predicted links
 e    

 e  e      e     e

 f  e   with uniform link
weights

figure    example demonstrating a general approach to link prediction 
the initial graph  a  is used as input to a link predictor  yielding a complete
graph  b  where the weights wij are estimated between all pairs of nodes  the
next step shows the removal of the initial  observed  links from consideration  c  
followed by a pruning of all predicted links with a weight below some cut off value
  d   the remaining predicted links are then combined with the initial links  e  
often  the estimated weights on the initial and predicted links are then discarded 
leaving a uniform weight graph  f  

finally  section     describes hybrid techniques that exploit both the node features and the
graph structure 
    non relational  feature based  link prediction
in this section  we consider link predictors that do not exploit the graph structure or relational features derived using the graph structure  we are given an arbitrary pair of nodes
   

fitransforming graph data for statistical relational learning

vi and vj from the graph such that each node is represented by a feature vector xvi and
xvj   respectively  feature based link prediction is defined as using an arbitrary similarity
measure s xvi   xvj   as a means to estimate the likelihood that a link should exist between vi
and vj   typically  a link is created if the similarity exceeds some fixed cut off value  another
strategy is to predict links among the n  of all such node pairs with highest similarity 
a traditional approach is to simply define a measure of similarity between two objects 
possibly based on knowledge of the application and or problem domain  there are many
similarity metrics that have been proposed such as mutual information  cosine similarity 
and many others  lin         for instance  macskassy        represents the textual content
of each node as a feature vector and uses cosine similarity to create new links between nodes
in a graph  macskassy showed that the combination of the initial links with the predicted
text based links increased classification accuracy compared to using only the initial links
or the text based links  in addition to leveraging textual information to predict links  we
might use any arbitrary set of features combined with a proper measure of similarity for
link prediction  for instance  many recommender systems implicitly predict a link between
two users based on the similarity between their ratings of items such as movies or books
 adomavicius   tuzhilin        resnick   varian         in this case  cosine similarity or
correlation are commonly used as similarity metrics 
alternatively  a similarity measure can be learned for predicting link existence  the link
prediction problem can be transformed into a standard supervised classification problem
where a binary classifier is trained to determine the similarity between two nodes based on
their feature vectors  one such approach from the work of hasan et al          who have used
support vector machines  svms  for link prediction and found that a non relational feature
 keyword match count  was most useful for predicting links in a bibliographic network 
there are many link prediction approaches  taskar et al         getoor  friedman  koller 
  taskar        that apply traditional machine learning algorithms  however  most of them
use features based on the graph structure as well as the non relational features that are the
focus of this section  thus  we discuss such techniques further in section     
finally  variants of topic models can be used for link prediction  these types of models
traditionally use only the text from documents  non relational information  to infer a mixture of latent topics for each document  inter document topic similarity can then be used as
a similarity metric for link prediction  chang   blei         however  because many topic
models are capable of performing joint transformation of the nodes and links  we defer full
discussion of such techniques to section   
    topology based link prediction
topology based link prediction uses the local relational neighborhood and or the global
graph structure to predict the existence of unobserved links  table     summarizes some
of the most common metrics that have been used for this task  below  we discuss many of
these approaches  starting from the simplest local metrics and moving to the more complex
techniques based on global measures and or supervised learning  for a systematic study of
many of these approaches applied to social network data  see the work of liben nowell and
kleinberg        
   

firossi  mcdowell  aha    neville

local node metrics

description

common neighbors

number of common neighbors between x and y  w x  y      x  y    newman 
    a 

jaccards coefficient

probability that x and y share common neighbors  normalized  
  x  y  
 jaccard        salton   mcgill       
  x  y  

adamic adar

similar topcommon neighbors  but assigns more weight to rare neighbors 
 
w x  y    z x  y  log   z  
 adamic   adar       

ra

essentially equivalent to adamic adar if   z   is small 
p
 
w x  y    z x  y    z  
 zhou  lu    zhang       

preferential attachment

probability of a link between x and y is the product of the degree of x and y 
w x  y      x      y    barabasi   albert       

cosine similarity

  x  y  
w x  y    

 salton   mcgill       

sorensen index

w x  y   

 green        zhou et al        

hub index

nodes with large degree are likely to be assigned a higher score 
w x  y   

  x    y  
   x  y  
  x     y  

  x  y  
min   x     y   

w x  y   

 ravasz  somera  mongru  oltvai    barabasi       
  x  y  
max   x     y   

 ravasz et al        

hub depressed index

analogous to hub index  w x  y   

leicht holme newman

assigns large weight to pairs that have many common neighbors  normalized
  x  y  
by the expected number of common neighbors  w x  y      x    y    leicht 
holme    newman       

global graph metrics

description

graph distance

length of the shortest path between x and y

katz

number of all paths between x and y  exponentially damped by length thereby
assigning more weight to shorter paths  w x  y      i  a    xy  katz       

hitting time

number of steps required for a random walk starting at x to reach y  brightwell
  winkler       

commute time

expected number of steps to reach node y when starting from x and then returning
 
 
back to x  defined as w x  y    l 
xx   lyy   lxy where l is the laplacian matrix
 gobel   jagers       

rooted pagerank

similar to hitting time  but at each step there is some probability that the random
walk will reset to the starting node x  w x  y      ip    xy where p   d  a
 page et al        

simrank

x and y are similar to the extent that they are joined with similar neighbors 
p

w x  y   

p

v y  sim u v 
  x    y  

u x 

 jeh   widom       

k walks

number of walks of length k from x to y  defined as w x  y     ak  xy

meta approaches

description

low rank approximation

compute the rank k matrix ak that best approximates a  hopefully reducing
noise   then compute similarity over ak using some local or global metric
 eckart   young        golub   reinsch       

unseen bigrams

compute initial scores using some local or global metric  then augment the scores
w x  y  using values from w z  y  for nodes z that are similar to x  essen  
steinbiss        lee       

clustering

compute initial scores using some local or global metric  discard links with the
lowest scores  and then re compute the scores on the modified graph  johnson 
      hartigan   wong       

table    topology metrics  summary of the most common metrics for link prediction 
notation  let  x  be the neighbors of x and a be the adjacency matrix of g 
   

fitransforming graph data for statistical relational learning

      metrics based on the local neighborhood of nodes
the simplest approaches use only the local neighborhood of nodes in a graph to devise a
measure of topology similarity  then use pairwise similarities between nodes to predict the
most likely links  as shown in table      there are numerous such metrics  often based
on the number of neighbors that two nodes share in common  with varying strategies for
normalization 
zhou et al         compares nine such local similarity measures on six datasets and finds
that the simplest link predictor  common neighbors  performs the best overall  they also
propose a new metric  ra  that outperforms the initial nine metrics on two of the datasets 
this new metric is very similar to the adamic adar metric  but uses a different normalization factor that yields better performance in networks with higher average degree  they
also propose a method that uses additional two hop information to avoid degenerate cases
where links are assigned the same similarity score  their results highlight the importance
of selecting the appropriate metrics for specific problems and datasets  in another related
investigation  clauset  moore  and newman        evaluate a hierarchical random graph
predictor against local topology metrics such as common neighbors  jaccards coefficient and
the degree product on three types of networks  a metabolic  ecology and a social network 
they find that a baseline measure based on shortest paths performs best for the metabolic
network  where the relationships are more homogeneous  but that their hierarchical metric
performs best when the links create more complex relationships  as in the predator prey
relationships found in the ecology network 
liu and lu        proposed a local random walk algorithm as an efficient alternative to
the global random walk predictors for large networks  this method is evaluated alongside
other metrics  i e   common neighbors  local paths  ra  and a few random walk variants 
and shown to perform better on most of the networks and more efficiently than the global
random walk models 
      metrics based on the global graph structure
more sophisticated similarity metrics are based on global graph properties  often involving
some weighted computation based on the number of paths between a pair of nodes  for
instance  the katz measure        counts the number of paths between a pair of nodes 
where shorter paths count more in the computation  rattigan and jensen        demonstrated that even this fairly simple metric could be effective for the task of anomalous link
prediction  which is the identification of statistically unlikely links from among the links
in the initial graph 
a related measure is the hitting time metric  which is the average number of steps
required for a random walk starting at node x to reach node y  gallagher et al        
use such random walks with restart to estimate the similarity between every pair of nodes 
they focus on sparsely labeled networks where unlabeled nodes may have only a few labeled
nodes to support learning and or inference in relational classification  the prediction of
new links improves the flow of information from labeled to unlabeled nodes  leading to an
increase in classification accuracy of up to      note that adding teleportation probabilities
to this random walk approach roughly yields the pagerank algorithm which is said to be
at the heart of the google search engine  page et al         
   

firossi  mcdowell  aha    neville

the simrank metric  jeh   widom        proposes that two nodes x and y are similar
if they are linked to neighbors that are similar  interestingly  they show that this approach
is equivalent to a metric based on the time required for two backwards  random walks
starting from x and y to arrive at the same node  as with the other approaches based
on random walks  this metric could be computed via repeated simulations  but is more
efficiently computed via a recursive set point approach 
      meta approaches and supervised learning approaches
the metrics above can be modified or combined in multiple ways  liben nowell and kleinberg        consider several such meta approaches that use some local or global similarity
metric as a subroutine  for instance  the metrics discussed above can each be defined in
terms of an arbitrary adjacency matrix a  given this formulation  we can imagine first
computing a low rank approximation ak of this matrix using a technique such as singular
value decomposition  svd   and then computing a local or global graph metric using the
modified ak   the idea is that ak retains the key structure of the original matrix  but noise
has been reduced  liben nowell and kleinberg also propose two other meta approaches
based on removing spurious links suggested by a first round of similarity computation  the
clustering approach  or based on augmenting similarity scores for a node x based on the
scores for other nodes that are similar to x  the unseen bigrams approach   they compare the performance of these three meta approaches vs  multiple local and global metrics
on the task of predicting future links in a social network  the katz measure and metaapproaches based on clustering and low rank approximation perform the best on three of the
five arxiv datasets  but simple local measures such as common neighbors and adamic adar
also perform surprisingly well 
supervised learning methods can also be used to combine or augment the similarity
metrics that we have discussed  for instance  lichtenwalter et al         investigate several
supervised methods for link prediction in sparsely labeled networks  using many of the metrics from table      these metrics are used as features in simple classifiers such as c    
j    and naive bayes  they find the supervised approach leads to a     improvement in
auc over the simple unsupervised link prediction metrics  similarly  kashima and abe
       propose a supervised probabilistic model that assumes that a biological network
has evolved over time  and uses only topological features to estimate the model parameters  they evaluate the proposed method on protein protein and metabolic networks and
report increased precision compared to simpler metrics such as adamic adar  preferential
attachment  and katz 
      discussion
in general  the local topology metrics sacrifice an amount of accuracy for computational
gains while the global graph metrics may perform better but are costly to estimate and
infeasible on huge networks  where appropriate  supervised methods that combine multiple
local metrics may offer a promising alternative  the next subsection discusses additional
work on link prediction that has used supervised methods 
link prediction using these metrics is especially sensitive to the characteristics of the
domain and application  for instance  many networks in biology  where the identification of
   

fitransforming graph data for statistical relational learning

links is costly  contain missing or incomplete links  while the removal of insignificant links is
a more significant issue for social networks  for that reason  researchers have analyzed and
proposed many different metrics when working in the domains of web analysis  kleinberg 
      broder et al          social network analysis  zheleva  getoor  golbeck    kuter 
      xiang et al         koren  north    volinsky         citation analysis  borgman  
furner         ecology communities  zhou et al          biological networks  jeong et al  
       and many others  barabasi   crandall        newman        
    hybrid link prediction
in this subsection  we examine approaches that perform link prediction using both the
attributes and the graph topology  for such approaches  there are two key questions  first 
what kinds of features should be used  second  how is the information from multiple
features combined into a single measure or probability to be used for prediction 
we first consider the mix of non relational and relational features that should be used 
as expected  the best features vary based on the domain and specific network  for instance 
taskar et al         studied link prediction for a network of web pages and found that simple
local topology metrics  which they called transitivity and similarity  were more important
than non relational features based on the words presents in the pages  similarly  hasan
et al         found that another topology metric  shortest distance  was the most useful for
predicting co authorship links in a bibliographic network based on dblp 
if only a single metric feature  such as hitting time  will be used for link prediction 
then we must ensure that the metric works well for all nodes and yields a consistent ranking 
however  if multiple feature values will be combined in some way  then it may be more
acceptable to use a wider range of features  especially if a supervised learner will later select
or weight the most important features based on the training data  thus  hybrid systems
for link prediction tend to have a more diverse feature set  for instance  zheleva et al 
       propose new features based on combining two different kinds of networks  social
and affiliation networks   features based on the groups and topology are constructed from
the combined network and are used along with descriptive non relational features  yielding
an improvement of        compared to a system without the combined network features 
a second example of more complex features is provided by ben hur and noble        
who design a new pairwise kernel for predicting links between proteins  protein protein
interactions   the pairwise kernel is a tensor product of two linear kernels on the original
feature space  and is especially useful in domains where two nodes might have only a few
common features  this approach has also been applied for user preference prediction and
recommender systems  basilico   hofmann         vert and yamanishi        propose
a related approach  where supervised learning is used to create a mapping of the original
nodes into a new euclidean space where simple distance metrics can then be used for link
prediction 
given the great diversity of possible features for link prediction  an interesting approach
is a system that automatically searches for relevant features to use  for example  popescul 
popescul  and ungar      a  propose a unique link prediction approach that systematically
generates and searches over a space of relational features to learn potential link predictors  they use logistic regression for link prediction and consider the search space covering
   

firossi  mcdowell  aha    neville

equi joins  equality selections  and aggregation operations  in their approach  the model selection algorithm continues to add one feature at a time to the model as long the bayesian
information criterion  bic  score over the training set can be improved  they find that the
search algorithm discovers a number of useful topology based features  such as co citation
and bibliographic coupling  as well as more complex features  however  the complexity of
searching a large feature space and avoiding overfitting present challenges 
we next consider the second key question  how should the information from multiple
features be combined into a single measure to be used for link prediction  most prior
work has taken a supervised learning approach  where both non relational and topologybased metrics are used as features that describe each possible link  as with the supervised
techniques discussed in section      a model is learned from training data which can then
be used to predict unseen links 
most of these supervised approaches apply the classifier separately to each possible link 
using a classifier such as a support vector machine  decision tree  or logistic regression
 popescul et al       a  ben hur   noble        hasan et al          in these approaches 
a flat feature representation for each link is created  and the prediction made for each
possible link is independent of the other predictions 
in contrast  early work on relational bayesian networks  rbns   getoor et al        
and relational markov networks  rmns   taskar et al         involved a joint inference
computation for link prediction  where each prediction could be influenced by nearby link
predictions  and sometimes also by newly predicted node labels   using a webpage network
and a social network  taskar et al  demonstrated that joint inference using belief propagation could improve accuracy compared to the independent inference approach  however  this
approach is computationally intensive  and they noted that getting the belief propagation
algorithm to converge was a significant problem  a possible solution to this computational
challenge is the simpler approach presented by bilgic  namata  and getoor         their
method involved repeatedly predicting labels for each node  predicting links between the
nodes using all available features  including predicted labels   then re predicting the labels
with the new links  and so forth  the link prediction was based on an independent inference
step using logistic regression  as with the simpler approaches discussed above  however  the
repeated application of this step allows the possibility of link feature values changing in
between iterations based on the intermediate predictions  thus allowing link predictions to
influence each other 
recently  backstrom and leskovec        proposed a novel approach that is supervised 
but where the final predictions are based on a random walk rather than directly on the
output of some learned classifier  given a particular target node v in a social network 
along with nodes that are known to link to v  they study how to predict which other
links from v are likely to arise in the future  or should be recommended   they define
a few simple link features based on node profile similarity and messaging behavior  then
use these features to estimate initial link weights  they show how to learn these weights
 or transition probabilities  in a manner that optimizes the likelihood that a subsequent
random walk  starting at v  will arrive at nodes already known to link to v  because the
random walk is thus guided by the links that are already known to exist  they call this
process a supervised random walk  they argue that this learning process greatly reduces
the need to manually specify complex graph based features  and show that it outperforms
   

fitransforming graph data for statistical relational learning

other supervised approaches as well as unsupervised approaches such as the adamic adar
measure 
a final approach for link prediction is to use some kind of unsupervised dimensionality
reduction that yields a new matrix that in some way reveals possible new links  for instance 
hoff  raftery  and handcock        propose a latent space approach where the initial link
information is projected into a low dimensional space  link existence can then be predicted
based on the spatial representation of the nodes in the new latent space  these models
perform a kind of factorization of the link adjacency matrix and thus are often referred to
as matrix factorization techniques  an advantage of such models is that the spatial representation enables simpler visualization and human interpretation  related approaches have
also been proposed for temporal networks  sarkar   moore         for mixed membership
models  nowicki   snijders        airoldi  blei  fienberg    xing         and for situations
where the latent vector representing each node is usefully constrained to be binary  miller 
griffiths    jordan         typically  these models have the capability of including the
attributes as covariates that affect the link prediction but are not directly part of the latent
space representation  however  zhu  yu  chi  and gong        demonstrated how such attributes can also be represented in a related but distinct latent space  more recently  menon
and elkan        showed how a matrix factorization technique for link prediction can scale
to much larger graphs by training with stochastic gradient descent instead of mcmc 
    discussion
link prediction remains a challenge  in part because of the very large number of possible
links  i e   n   possible links given n observed nodes   and because of widely varying data
characteristics  depending on the domain  the best approach may use only a single nonrelational metric or topology metric  or it may use a richer set of features that are evaluated
by some learned model  future work may also wish to consider using an ensemble of link
predictors to yield even better accuracy 
our discussion of link prediction has focused on predicting new links based on existing
links and properties of the nodes  in the context of the web  however  link prediction
has sometimes taken other forms  for instance  sarukkai        used web server traces to
predict the next page that a user will visit  given their recent browsing history  in particular 
they use markov chains  which are related to the random walks discussed in section     
for this task that they also call link prediction  more recently  dubois and smyth       
model relational events  i e   links  using latent classes where each event link arises from
a latent class and the properties of the event  i e  sender  receiver  and type  are chosen
from distributions over the nodes conditioned on the assigned class  in this work  the local
community of a node influences the distribution computed for each node  in a way related
to the computations of stochastic block modeling  airoldi et al          dubois   smyths
task is also a form of link prediction  but where the goal is not to predict the presence or
absence of a static link  but the frequency of occurrence for each possible event link 
one might also be interested in deleting or pruning away noisy  less informative links 
for instance  friendship links in facebook are usually extremely noisy since the cost of
adding friendship links is insignificant  most of the techniques used in this section could
   

firossi  mcdowell  aha    neville

also be used to remove existing links wherever the link prediction algorithm yields a very
low score  or weight  for an observed link in the original graph 
indeed  since most link prediction algorithms effectively assign a score to every possible
link  they could also be used to assign a weight to just the set of initial links in g  this
link weighting is one of the three subtasks of link interpretation shown in the taxonomy
of figure    however  in practice if weights are needed only for the initial links  different
features and algorithms will often be possible and or more effective  the next section
discusses such link weighting algorithms  as well as link interpretation in general  also 
in section   we discuss some additional methods for link prediction that seek to jointly
transform both nodes and links 

   link interpretation
link interpretation is the process of constructing weights  labels  or general features for the
links  these three tasks of link interpretation are related and somewhat overlapping  first 
link weighting is the task of assigning some weight to each link  these weights may represent
the relevance or importance of each link  and are typically expressed as continuous values 
thus the weights provide an explicit order over the links  second  link labeling is similar 
except that it usually assigns discrete values to each link  this could represent a positive
or negative relationship  or could be used  for instance  to assign one of five topics to email
communication flows  finally  link feature construction is the process of generating a set of
discrete or continuous features for the links  for instance  these features might count the
frequency of particular words that appeared in messages between the two nodes connected
by some link  or simply count the number of such messages 
in a sense  link feature construction subsumes link weighting and labeling  since the
weights and labels can be viewed simply as possible link features to be discovered  however  for many tasks it makes sense to compute one particular feature that summarizes the
relevance of each link  the weight  and or one particular feature that summarizes the type
of each link  the label   such weights and labels may be especially useful to later processing  for example with collective classification  moreover  the techniques used for general
feature construction tend toward simpler approaches such as aggregation and discretization  whereas the best techniques for computing weights and labels may involve much more
complexity  including global path computations or supervised learning  for this reason  we
treat link weighting  section      and link labeling  section      separately from general
link feature construction  section      
    link weighting
given the initial graph g   hv  e  xv   xe i  the task is to assign a continuous value  the
weight  to each existing link in g  representing the importance or influence of that link  as
previously discussed  link weighting could potentially be accomplished by applying some link
prediction technique and simply retaining the computed scores as link weights  for instance 
lassez  rossi  and jeev        perform link prediction and weighting by applying singular
value decomposition to the adjacency matrix  then retaining only the k most significant
singular vectors  similar to the low rank approximation techniques discussed in section      
   

fitransforming graph data for statistical relational learning

they show that querying  e g   with pagerank  on the resultant weighted graph can yield
more relevant results compared to an unweighted graph 
unlike with link prediction  however  most link weighting techniques are designed to
work only with links that already exist in the graph  these techniques dont work for
predicting unseen links because they weight links based on known properties features of
the existing links  or because they compute some additional link features that only yield
sensible results for links that already exist 
in the simplest case  link weighting can be just aggregating an intrinsic property of links 
for example  onnela et al         defines link weights based on the aggregated duration of
phone calls between individuals in a mobile communication network  in other cases  simply
counting the number of interactions between two nodes may be appropriate 
thus  when link features like duration  direction  or frequency are known  they can be
aggregated in some way to generate link weights  if actual link weights are already known
for some of the links  then supervised methods can be used for weight prediction  using
the known weights as training data  for instance  kahanda and neville        predict link
strength within a facebook dataset  where stronger relationships are identified based on
a users explicit identification of their top friends via a popular facebook application 
gilbert and karahalios        also predict link strength for facebook  but form their training data from survey data collected from    participants  yielding strength ratings for about
     links   both of these algorithms generate a large number         of features about
each link in the network  then learn a predictive model via regression or some other technique such as bagged decision trees  which kahanda and neville finds performs best among
several alternatives  gilbert and karahalios generate features based on profile similarity
 e g   do two users have similar education levels   and based on user interactions  e g  
how frequently and about what topics do two users communicate    they find the interaction features to be most helpful  especially a feature based on the number of days since
the last communication event  kahanda and neville use similar kinds of features  which
they term attribute based and transactional features  and also add topological features  such
as the adamic adar discussed in section      and network transactional  ntr  features 
ntr features are those that are based on communications between users  e g   the number
of email messages exchanged  but moderated in some way by the larger network context 
this moderation often takes the form of normalization  for instance to dampen the influence
of a node that has sent a large number of messages to many different friends  they find
that these ntr features are by far the most helpful for prediction  but that many other
features also contribute to the overall predictive accuracy 
when training data with sample link weights is not available  approaches based on a
parameterized probabilistic model are still possible  however  since candidate link features
can no longer be evaluated against the training data  these approaches must  manually 
choose the features that they use much more carefully  for instance  xiang et al        
examine link weight prediction on two social network datasets  facebook and linkedin   but
use only      features for each link  they hypothesize that relationship strength is a hidden
cause of user interactions  and propose a link based latent variable model to capture this
dependence  for inference  they use a coordinate ascent optimization procedure to predict
the strength of each link  since the actual strength of each link is not known  prediction
tasks in this domain cannot directly evaluate accuracy  however  xiang et al  demonstrate
   

firossi  mcdowell  aha    neville

that using the link strengths produced by their method leads to higher autocorrelation and
higher collective classification accuracy when predicting user attributes such as gender or
relationship status 
a number of researchers have considered the importance of recency in evaluating link
weight  under the assumption that events or interactions that occurred more recently should
have more weight  for instance  roth et al         propose the interactions rank metric
for weighting a link based on the messages between two nodes  the formula separately
weights incoming and outgoing messages for each link  and imposes an exponential decay
on the importance of each message based on how old it is  roth et al  use this metric to
weight the links in what they call the implicit social network  where each node represents
a group of users  they demonstrate that this metric can be used to accurately predict users
that are missing from an email distribution list  however  the basic metric is simple to
compute and could be applied to many other tasks 
the interactions rank metric weights a link more heavily if it connects two nodes that
have frequently and or recently communicated  alternatively  sharan and neville       
have considered how to weight links in a graph where the links  such as hyperlinks or
friendships  may themselves appear or disappear over time  in particular  they construct a
summarized graph where all nodes and links that have ever existed in the past are present 
each link in this new graph is weighted based on a kernel function that can provide more
weight to links that have been present more often or more recently in the past  they explain
how to modify standard relational classifiers to use these weighted links  and demonstrate
that a variety of kernels  including exponential and linear decay kernels  produce weighted
links that yield higher classification accuracy compared to a non weighted graph  more
recently  rossi and neville        have extended this work to handle time varying attribute
values  which may serve as a basis for incorporating temporal dynamics into additional
tasks 
    link labeling
given the initial graph g   hv  e  xv   xe i  the task is to construct some discrete label for
one or more links in g  these labels can be used to describe the type of relationship that
each link represents  for instance  in the facebook example  a link labeling algorithm may
create labels representing work or personal relationships  such labels would enable
subsequent classification models to separately account for the influence of these different
kinds of relationships 
most prior work on link labeling has assumed that some text  such as a message  describes each link  and has been based on unsupervised textual analysis techniques such
as latent dirichlet allocation  lda   blei et al          latent semantic analysis  lsa 
 deerwester  dumais  furnas  landauer    harshman         or probabilistic latent semantic analysis  plsa   hofmann         traditionally  these techniques have been used
to assign one or more latent topics to each document in a collection of documents  the
topics that are formed are defined implicitly by a probability distribution over how likely
each word is to appear  given that the topic is associated with a document  these topics
will not always be semantically meaningful  but often manual inspection reveals that most
prominent topics do represent sensible concepts such as advertising or government re   

fitransforming graph data for statistical relational learning

lations  however  even when such semantic associations are not obvious  inferring such
topics for a set of links can still aid further analysis  since the topics identify which links
represent similar kinds of relationships 
these textual analysis techniques were developed with independent documents in mind 
not inter linked nodes  but they can be adapted to label links in several ways  for instance 
rossi and neville        examined messages between developers contributing to an opensource software project  they treat each message as a separate document  and use lda to
infer the single most likely latent topic for each message  i e   a link label   this technique
could be used for any graph with textual content associated with the links  rossi and neville
also go further  to consider the impact of time varying topics and time varying topic word
associations  by running multiple iterations of lda  one per time epoch  using this model 
they study the problem of predicting the effectiveness of different developers  nodes  in the
network  they demonstrate that the accuracy of predictions is significantly improved by
modeling the temporal evolution of the communication topics 
mccallum  wang  and corrada emmanuel        describe an alternative way of extending lda like approaches for link labeling  lda is essentially a bayesian network that
models the probabilistic dependencies between documents  associated topics  and words associated with those topics  they propose to extend this model with the author recipienttopic  art  model  where the choice of topic for each document  message  depends on
both the author and the recipient of the message  once parameters are learned for the
model  inference  e g   with gibbs sampling  can be used to infer the most likely latent
topics for each message  they make use of these topics to assign roles to people in an email
communication network  and demonstrate that it outperforms simpler models 
supervised techniques can also be used for link labeling  for instance  taskar et al 
       study an academic webpage network and consider how to predict node labels  such
as student or professor  while simultaneously predicting link labels  such as adviserof   given a labeled training graph  they learn a complex relational markov network
 rmn  that can predict these labels and the existence of new links  to make the link
prediction tractable  only some candidate new links are considered  such as those links
suggested by a textual reference  inside a page  to some other entity in the graph  the
rmn utilizes text based features  for instance based on the anchor text for known links
or the heading for the html section in which a possible link reference is found  they
demonstrate that the rmns joint inference over nodes and links improves performance
compared to separate inference  however  learning and inference with rmns can often be
a significant challenge  which in practice limits the number and types of feature that can
be considered 
the rmn approach learns from some training data and then uses joint inference over
the entire graph  a simpler supervised approach is to create a set of features for each link
and use these features for learning and inference with an arbitrary classifier that treats each
link separately  leskovec  huttenlocher  and kleinberg        study a particular form of
this approach where there are only two link labels  representing a positive or negative relationship  such as friendship vs  animosity   they create link features based on the  signed 
degree of the nodes involved in each link and also based on transitivity like properties computed from the known labels of nearby links  they demonstrate this approach using data
from epinions  wikipedia  and slashdot  where users have manually indicated positive or
   

firossi  mcdowell  aha    neville

negative relationships to other users  given a network with almost all edges labeled  the
label classifier is able to predict the label  positive or negative  of a single unlabeled edge
with high accuracy  interestingly  they show that a classifiers predictive accuracy for a
particular dataset decreases only slightly when the classifier is trained on a different dataset
vs  being trained on the same dataset that is used for predictions  they argue that theories
of balance and status from social psychology partially explain this ability of their predictive
models to generalize across datasets  unlike most of the other techniques discussed in this
section  this work does not make use of text based features  however  the general problem
of predicting the sign of a link is related to sentiment analysis  or opinion mining  in
natural language processing  godbole  srinivasaiah    skiena        pang   lee        
these sentiment analysis algorithms could be reformulated to predict the label  such as
positive or negative  of a link given its associated text 
because a link between two nodes can be established based on many different kinds of
relationships  there are many other types of algorithms that could potentially be used for
labeling links  even if the original algorithm was not designed for this purpose  for instance 
markov logic networks  mlns  have been used to extract semantic networks from text 
yielding a graph where the nodes represent objects or concepts  kok   domingos        
this process produces relations such as teaches that or is written in between the nodes 
which could be used as link labels in further analysis  another example is the group topic
 gt  model proposed by mccallum  wang  and mohanty         which  like the previously
mentioned art model  is a bayesian network  the model is intended for graphs where two
nodes  such as people  become connected when they both participate in the same event 
such as both voting yes for the same political bill  rather than directly labeling links  like
art   the gt model clusters these nodes  such as people  into latent groups based on
textual descriptions of the events votes  however  the gt model also simultaneously infers
a set of likely topics for each event  which could be used to label the implicit links between
the nodes  the results of the model could also be used to add new nodes to the graph that
represent the latent groups that were discovered 
    link feature construction
link feature construction is the systematic construction of features on the links  typically for
the purpose of improving the accuracy or understandability of srl algorithms  link feature
construction can be important for many prediction tasks  but has received considerably
less attention than node feature construction in the literature  fortunately  many of the
computations that have been developed for node feature construction can also apply to link
features  to avoid redundancy  we defer most of our analysis of feature construction to the
discussion of node feature construction in section      this section briefly discusses how
such techniques for node feature construction can be applied to links  then summarizes the
major types of link features that can be computed 
section     will later describe how feature values for relational data are often based on
aggregating values from multiple nodes  for instance  such a feature might compute the
average or the most common feature value among all of the neighbors of a particular node 
such aggregation based features help to account for the varying number of neighbors that a
node may have  for links  aggregation is less essential  since  usually  each link has precisely
   

fitransforming graph data for statistical relational learning

 a  before link aggregation

 b  after link aggregation

figure    link feature aggregation example  the figure demonstrates how an unknown link feature value can be computed by aggregating the link feature values
of surrounding links  here the aggregation operator is mode 

two endpoint nodes  however  aggregation can still be useful for computing features that
collect information from a larger area of the graph  for instance  in figure    a link feature
value is being computed for the link in the center of the subgraph  the target link   the
computation considers the feature values  positive or negative signs  for all of the links that
are adjacent to the target link  in this case  the aggregation operator is mode  and the
result is the new link feature value  this example used link features as the input  but node
feature values  e g   of the lightly shaded nodes in figure    could also be aggregated to
form a new link feature  in this way  all of the aggregation operators discussed for nodes in
section     can also be applied to links 
figure   summarizes the kinds of features that can be constructed for a link  this figure
is organized around the sources of information that go into computing a single link feature
 i e   the inputs   rather than the details of the feature computation  such as the type of
aggregation or other function used   the bottom of the figure shows the four types of link
features  each represented by a subgraph  in each case  the emphasized link at the bottom
of the subgraph is the target link for which a new feature value is being computed  each
of the subgraphs shows varying amounts of information because each displays only those
features  nodes  and or links that can be used as inputs for that kind of link feature 
the simplest type is the non relational link feature  which can be computed for each
link solely from information that is already known about that link  thus  figure  a shows
only the feature values which are already known for the target link  which can be used to
construct a new feature value  for instance  if a message is associated with each link  then
a link feature could count the number of times that a certain word occurs  or the number
of distinct words  alternatively  if a date is associated with the link  then a feature might
compute the number of months since the link was formed  onnela et al         computed
this kind of feature when they aggregated the duration of all phone calls between two people
to form a new link feature  which they also used as a link weight  
the remaining feature types are all relational  meaning that they depend in some way
on the graph  not just a single link   first  topology features  figure  b  are those that
can be computed using only the topology of the graph  such a feature might  for instance 
compute the total number of links that are adjacent to the target link  likewise  kahanda
and neville        computed the clustering coefficient of a pair of linked nodes  which
measures the extent to which the two nodes have neighbors in common  newman         as
well as other topological features such as the adamic adar measure discussed in section     
   

firossi  mcdowell  aha    neville

input  

v e xv xe  

target  link  

link  feature    
construction  
  
e  
x

link value  

p  

v e xv xe  

node value          

l  
non relational  
link  features  

relational  features  

v e   v e xe   v e xv  
topology  
features  

link value  
features  

node value  
features  

c  
p  

w  

c  
l  

w  

l  
a   

b   

  e  

c   

l  
d   

x

figure    link feature taxonomy  the link feature classes are non relational features 
topology features  relational link value features  and relational node value features 
in the subgraphs at bottom  only the information that is potentially used by
that class of link feature  i e   nodes v   links e  node features x v   and or link
features x e   is shown  the emphasized link represents where the feature value
is computed  i e   the target link  

they used these link features to help predict link strength  but they could also be used for
other tasks 
next  relational link value features are those that are computed using the feature values
of nearby links  for instance  figure  c shows how link labels of personal  p  or work
 w  might be identified from links adjacent to the target link  a new link feature could
be formed by representing the distribution of these labels  by taking the most common
label  or  when the link features are numeric  by averaging  leskovec  huttenlocher  and
kleinberg        used such link value features when working with graphs where each link
had a sign feature of positive or negative  as with figure     they computed features
based on the signed degree of the two nodes connected by the target link as well as more
complex measures based on other paths between these two nodes  e g   to measure sign
transitivity  
   

fitransforming graph data for statistical relational learning

finally  relational node value features are those that are computed using the feature
values of the nodes that are close to or are attached to the target link  for instance 
figure  d shows how node labels of conservative  c  or liberal  l  might be identified for
nodes close to the target link  as with link value features  these labels could be used to
create a new feature value by summarization or aggregation  often  only the two nodes
that are directly attached to the target link are used  for instance  both the work of gilbert
and karahalios        and kahanda and neville        construct link features based on the
similarity of two nodes social network profiles  however  the feature values of more distant
nodes could also be used  for instance to compute a new link feature based on how similar
the friends of two people  nodes  are 

   node prediction
node transformation includes node prediction  e g   predicting the existence of new nodes 
and node interpretation  e g   constructing node weights  labels  or features   this section
focuses on node prediction  while section   considers node interpretation 
given a graph with existing nodes v   node prediction can be used in two distinct ways 
first  a node prediction algorithm could be used to discover additional nodes that are of
the same type as those that are already present in v   for instance  given a set of people
that communicate via email  a simple algorithm might be used to create new nodes that
represent email recipients that are implied by the messages  but not explicitly represented in
the original graph  alternatively  supervised or unsupervised machine learning techniques
could be used to discover  for instance  new research papers or people from information
available on the web  craven et al         cafarella  wu  halevy  zhang    wang        
these techniques are valuable  and can certainly be used to add new nodes to a graph 
however  most such work has been examined in the context of general knowledge base
construction  rather than relational learning  
we focus on the second type of node prediction  which involves predicting nodes of a
different type than those that are already present in the graph  these new nodes might
represent locations  communities  kleinberg         roles  mccallum  wang    corradaemmanuel        rossi  gallagher  neville    henderson         shared characteristics 
social processes  tang   liu        hoff et al          functions  letovsky   kasif        
or some other kind of relationship  for instance  in the running facebook example  a
newly discovered node may represent a common interest or hobby that multiple people
share  these nodes are usually referred to as latent nodes  and the nodes connected to
each such node form a latent group    the meaning of these nodes will depend upon
what features and or links were included as input to the node prediction algorithm  for
instance  including work based friendships will lead to very different groups than if only
personal friendships are considered 
   the recent work of kim and leskovec        is an exception  their technique uses em to infer the
existence of missing nodes and links based on only the known topology of the graph 
   prior work sometimes refers to such nodes as hidden nodes  especially when they are thought to
represent concrete characteristics  such as geographic location  that could be measured but were  for
some reason  not observed in the data 

   

firossi  mcdowell  aha    neville

figure    alternative representations for newly predicted groups  the left
figure shows how a new feature  with value x or y  could be added to each node 
while the right figure demonstrates the creation of two new nodes to represent
the groups 

there are many advantages of this type of representation change with regards to accuracy and understandability  for instance  nodes that are not directly connected in the
original graph but are similar in some way become  because of the links to the new nodes 
closer in graph space  intuitively  nodes connected to a high level concept should share some
latent properties and representing that latent structure can directly impact classification 
network analysis  and many other tasks  for instance  reducing the path length between
similar nodes enables influence from these nodes to propagate more effectively if collective
classification  cc  is performed on these nodes  a model can still learn about and exploit
these new nodes and relationships  even if the semantic meaning of the new nodes is not
precisely understood 
the most popular methods for predicting new nodes are based on clustering  which in
our context means the grouping of nodes such that nodes within a group are more similar
to each other than they are to the nodes in other groups  typically  one new node is created
for each group  and then links are added between each existing node and its corresponding
group node  see right side of figure     some techniques may also associate each node with
multiple groups  with link weights representing the affinity to each group 
when new groups are discovered  whether via clustering or via some other technique  an
alternative to creating new nodes and links is to simply add new feature s  to each node that
represent the group information  the left side of figure   demonstrates this alternative 
for instance  a new node feature might represent having running as hobby  or it may simply
represent belonging to discovered group      which is of unknown meaning  popescul and
ungar        use the citeseer dataset to demonstrate that this technique can derive features
that can improve predictive accuracy  an advantage of this approach  as opposed to adding
new nodes  is that it potentially enables simpler  non relational algorithms to make use of
the new information  a potential disadvantage  though  is that it also does not allow for
algorithms such as cc to propagate influence between newly connected nodes  as discussed
above  however  some such methods use this general strategy to generate much larger
   

fitransforming graph data for statistical relational learning

numbers of latent features that can be used for classification  tang   liu        menon  
elkan         tang   liu demonstrate that  in some cases  the resultant large number of
link based features may make collective inference unnecessary for obtaining good accuracy 
naturally  whether the information discovered from these clusterings is best represented
via new nodes or new features will depend upon the dataset and the inference task  in
this section  for simplicity we will discuss each algorithm assuming that new nodes will be
created  even if the algorithm was originally described in terms of creating new features  
as with our discussion of link prediction  we organize our discussion around the kinds
of information that are used for prediction  section     discusses non relational  attributebased  node prediction  section     discusses topology based node prediction  and section     discusses hybrid approaches that use both the node feature values and the topology
of the graph 
    non relational  attribute based  node prediction
there are many clustering algorithms that can be used to cluster existing nodes using only
their non relational features  attributes   which can then be used to add new nodes to a
graph  the two primary types are hierarchical clustering algorithms  e g   agglomerative or
divisive clustering  and partitioning algorithms such as k means  k medoids  berkhin       
zhu         em based algorithms  and self organizing maps  kohonen         we do not
discuss these algorithms further since they have been well studied for non relational data
and can be easily applied to relational data if clustering based only on attribute values is
desired 
    topology based node prediction
the techniques described in this section link existing nodes to one or more new nodes  i e  
latent groups   based only on the original link structure of the graph  in most cases  finding
this grouping depends upon computing some kind of similarity metric between every pair
of nodes  two key questions thus serve to identify these techniques  first  what kind
of similarity metric should be used  second  how should the metric be used to predict
groupings  we address each question in turn 
      types of metrics for group prediction
any type of topology based link weighting metric  see table      could conceivably be used
for latent node prediction  a metric will be suitable so long as it produces high values
for pairs of nodes that should belong to the same group and lower values for other pairs 
for instance  a high value of the katz metric  see section      indicates that two nodes
have many short paths between them  and thus may belong to the same group  metrics
representing distance rather than similarity can also be used after negating the metric  for
instance  girvan and newman        focus on detecting community structure by extending
the concept of node betweenness to links  intuitively  if a network contains latent groups
that are only loosely connected by a few intergroup links  then all shortest paths between
different groups must go along these links  these links that connect the different groups
are assigned a high link betweenness value  which corresponds to a low similarity value  
   

firossi  mcdowell  aha    neville

the underlying group structure can then trivially be revealed by removing the links with
highest betweenness 
this idea of using link betweenness for relational clustering has been extended in a
number of directions  for instance  newman and girvan        introduced random walk
betweenness  which is the expected number of times that a random walk between a pair of
nodes will pass down a particular link  in addition  radicchi  castellano  cecconi  loreto 
and parisi        proposed using a link based clustering coefficient metric  they showed
that this metric performs comparably to the original link betweenness metric of girvan and
newman  but is much faster because it is a local graph measure instead of a global graph
measure 
zhou        describes a new metric  the dissimilarity index  which can be computed
as follows  for each node i  compute a vector di where each value dij represents the
distance from node i to node j  zhou measures distance based on the average number of
steps needed for a random walk starting at node i to reach node j  but any distance metric
could be used   if nodes i and k are very similar  they should have very similar distance
vectors  thus  the dissimilarity index for nodes i and k is defined based on a euclidean like
distance computation between vectors di and dk   zhou demonstrates that this technique
outperforms the link betweenness approach of girvan   newman for some random modular
networks 
relatively simple metrics can often lead to useful results  for instance  ravasz et al 
       used a simple clustering coefficient metric to study metabolic networks  their study
reveals that the metabolic networks of forty three organisms are organized into many small 
highly connected modules  furthermore  they find that for e  coli  the hidden hierarchical
modularity closely overlaps with known metabolic functions 
      using the metrics for group prediction
the simplest techniques for identifying new groups is to perform some kind of hierarchical
clustering  for instance  after similarities or weights have been computed for every pair of
nodes  all links can be removed from the graph  next  the weighted links are placed between
the nodes one by one  ordered by their weights  the intuition is that varying degrees of
clusters are formed as more links are added  in particular  this approach forms a hierarchical
tree where the leaves represent the finest granularity of clustering where every node is a
separate cluster  as we move up the tree larger clusters are formed  until we reach the top
where all the nodes are joined in one large cluster  this type of hierarchical approach was
used in the work of zhou         girvan and newman        use a similar strategy  but
start instead with the original graph and iteratively remove the less similar links from the
graph to reveal the underlying community structure  a challenge with these approaches 
as with clustering in general  is to select the appropriate number of final clusters  which
corresponds to selecting a level in the clustering tree 
spectral clustering  dhillon        ng  jordan    weiss        kamvar  klein    manning        can also be used for group identification  spectral clustering relies upon computing a similarity matrix s that describes all the data points  then transforming the matrix
in a way that yields a new matrix u where clustering the rows of u using a simple clustering
algorithm  such as k means  can trivially identify the interesting groups in the data  the
   

fitransforming graph data for statistical relational learning

matrix transformation has several variants  but involves computing some kind of laplacian
of s  then computing the eigenvectors of the resultant matrix and using those eigenvectors to represent the original data  the motivation for this transformation can be seen
as identifying good graph cuts in the original graph  those that yield good separations of
highly connected nodes into groups  or as identifying those nodes that are closely related
in terms of random walks  see the work of von luxburg        for an overview  spectral
clustering was originally applied to non relational data  but  as with the hierarchical techniques described above  it can be applied to relational data by using link based metrics
for computing the similarity matrix  for instance  neville and jensen        use the node
adjacency matrix and the spectral clustering technique described by shi and malik       
to identify latent groups in their graphs  they show that this technique enables simpler
inference  since each group can be handled separately   and ultimately yields more accurate
classification compared to approaches that ignore the group structure  tang and liu       
also use spectral clustering on the link graph  but do so in order to create a much larger
number of latent features that are then used to learn a supervised classifier  unlike the
latent groups from the work of neville and jensen  this technique allows each node to be
associated with more than one cluster in the output of the spectral clustering  which tang
  liu claim leads to improved classification accuracy  spectral clustering can also be used
with more complex similarity metrics  as described in the next subsection 
techniques borrowed from web search can also be useful for node prediction  for instance  given the adjacency matrix a for a webpage graph  the hits algorithm  kleinberg 
      computes the first few eigenvectors of aat and at a  which represent the most
authoritative nodes  the authorities  as well as prominent nodes that point to them  the
hubs   normally  this algorithm is used to find only the single most prominent community of authorities and hubs  to assist with a web search   but secondary communities can
be discovered by also considering the non principal eigenvectors of aat and at a  gibson  kleinberg    raghavan         a node prediction algorithm could then treat each
such community as a latent group and add a new node and links to represent this group 
these techniques may be especially useful for detecting patterns of influence in a graph and
adding more explicit links to represent this influence 
    hybrid node prediction
the techniques in the previous section added new nodes to the graph  often based on
clustering  using only the topology of the graph  in principle  a technique that also used
the nodes attributes should produce more meaningful latent groups nodes  this section
considers how to add such attribute information to techniques for node prediction 
a simple approach is to define some kind of similarity metric that combines nonrelational and topology based similarity into a single value  then provide that similarity
metric to one of the previously mentioned clustering algorithms  for instance  neville 
adler  and jensen        use a weighted combination of attribute and link information
 x
s i  j     
sk  i  j           l
k
k

as a metric  where sk  i  j      iff nodes i and j have the same value for the kth attribute 
and l     iff a link exists between i and j  here the constant  controls the relative
   

firossi  mcdowell  aha    neville

importance of the attributes vs  the links  they use this metric with the ncut spectral
clustering technique to add new nodes to the graph  and demonstrate that these additional
nodes increase the performance of relational classification  a similar weighted combination
of attribute and link based similarity is used by bhattacharya and getoor        for entity
resolution 
attribute based information can also be incorporated on an ad hoc basis  for instance 
adibi  chalupsky  melz  valente  et al         describe a group finding algorithm where an
initial seed set of clusters is formed based on a handcrafted set of logical rules  and then
these clusters are refined using a probabilistic system based on mutual information  in their
system  the logic based component primarily uses the attributes about each node  person  
while the probabilistic system primarily uses the links that describe connections between
the people  however  both components make some use of both attributes and links 
a more principled approach is to define some kind of generative model that represents
the dependence of the observed attributes and links on some latent group nodes  then use
that model to estimate group membership  for instance  kubica  moore  schneider  and
yang        define a generative model where each node belongs to one or more groups  and
group members tend to link to each other  in particular  they use a group membership
chart to track whether each node belongs to each group  and do a local search over possible
states of the chart  using stochastic hill climbing  to try to identify membership changes
that would better explain the known data  at each step  maximum likelihood is used to
estimate the parameters of the model  they demonstrate the usefulness of their technique
on news articles  webpages  and some synthetic data 
generative models can also be used with more sophisticated inference  for example 
taskar  segal  and koller        treat group membership as a latent variable and then uses
loopy belief propagation to implicitly perform a clustering of the nodes  likewise  mixed
membership relational clustering  mmrc   long et al         uses em variants to estimate group memberships  in particular  it uses a first round of hard clustering  where each
object is assigned to exactly one cluster   following by a round of soft clustering where continuous strength values are associated with each membership assignment  mixed membership stochastic blockmodels  airoldi et al         also assign continuous group membership
values to each node  but use only topological information  not attributes  for their group
assignments and use variational inference techniques with the generative model  finally 
long  zhang  wu  and yu        demonstrate how node clustering can be performed instead using spectral clustering  and focuses particularly on how to simultaneously cluster
multiple types of nodes  e g   to simultaneously cluster web pages and web users into two
distinct sets of groups  
most group prediction algorithms assume that links are more likely to connect nodes
that belong to the same group  an exception is the work of anthony and desjardins        
who also use a generative model where the links and attributes depend on some latent group
memberships  but where some types of links are more likely to occur between nodes that
do not belong to the same group  for instance  they note that if groups in a social network
are defined by gender  then a link representing dating is more likely to connect two nodes
from different groups 
   

fitransforming graph data for statistical relational learning

figure    lifted graph representation  the initial graph g is clustered and transformed into a lifted graph representation g  the lifted graph representation is
created by clustering nodes  links  or both 

    discussion
most of the techniques described above produce a single clustering of the nodes  usually
based on assigning every node to a single group  in contrast  multi clustering is an emerging
research area that aims to provide multiple orthogonal clusterings of complex data  strehl
  ghosh        topchy  law  jain    fred         for instance  individuals in facebook
might be clustered in multiple ways where latent node types might represent friend groups 
work relations  socioeconomic status  locations  or family circles  a type of multi clustering
is performed by mccallum  wang  and corrada emmanuel        where latent nodes are
created based on roles and topics  in addition  kok and domingos        propose statistical predicate invention  spi   a node transformation approach based on markov logic
networks  richardson   domingos         spi clusters nodes  features and links forming the basis for the prediction of predicates  or potential nodes   spi considers multiple
relational clusterings based on the observation that multiple distinct clusterings may be
necessary to  for instance  group individuals based on their friendships and their work relationships  they demonstrate that mln inference can estimate these clusters and improves
performance compared to two simpler baselines  a similar node prediction approach applies
mlns for role labeling  riedel   meza ruiz        
node deletion may also be useful in some cases  for instance  node deletion might be
beneficial for removing outdated or spurious nodes from the graph  alternatively  there
may be multiple nodes that represent the same real world object or concept  in which case
deletion for the purposes of entity resolution can be important  pasula  marthi  milch 
russell    shpitser        bhattacharya   getoor        singla   domingos        
finally  node representation changes can be used to not only to improve accuracy  but
also to yield graphs that can be processed more efficiently or that have other desirable
properties  section     already discussed how neville and jensen        used the addition of
latent nodes to enable simpler inference  another possibility is the creation of super nodes
that represent more than one of the original nodes  for instance  figure   demonstrates how
five original nodes can  after clustering  be collapsed into three super nodes  yielding a lifted
graph representation  this kind of representation change can be used for more efficient
   

firossi  mcdowell  aha    neville

inference in markov logic networks  see section      and for network anonymization  see
section      

   node interpretation
node interpretation is the process of constructing weights  labels  or general features for
the nodes  as with the symmetric tasks for link interpretation  node weighting seeks to
assign a continuous value to each node  representing the nodes importance  while node
labeling seeks to assign a discrete value to each link  representing the type  group  or class
of a node  likewise  node feature construction is the process of systematically generating
general purpose node features based on  for instance  aggregation  dimensionality reduction 
or subgraph patterns 
as discussed in section   for links  node feature construction could be viewed as subsuming node weighting and node labeling  since general feature construction could always
be used to construct feature values that are treated as weights or labels for the nodes  in
practice  however  the techniques used tend to be rather different  for instance  pagerank
is often used for node weighting and supervised classification is often used for node labeling 
but these techniques are rarely used for general feature construction  nonetheless  for node
interpretation  more so than with link interpretation  there is some substantial overlap between the techniques actually used for weighting and labeling vs  those used for general
feature construction  below  we first discuss node weighting in section     and labeling in
section      section     then discusses node feature construction  mentioning only briefly
the relevant techniques that were previously discussed for weighting and labeling 
    node weighting
given the initial graph g   hv  e  xv   xe i  the task is to assign a continuous value  the
weight  to each existing node in g  representing the importance or influence of that node 
node weighting techniques have been used for information retrieval  search engines  social
network analysis  and many other domains as a way to discover the most important nodes
with respect to some defined measure  as with node prediction they can be classified based
on whether they use only the node attributes  only the graph topology  or both to construct
a weighting 
      non relational  attribute based  node weighting
the simplest node weighting techniques use only the node features xv  i e   the attributes  
for instance  nodes representing documents might be weighted based on the number of
query relevant words they contain  while nodes representing companies might be ranked
based on their gross annual sales  many more sophisticated strategies have also been considered  for instance  latent semantic indexing  deerwester et al         can be used to
identify the most important semantic concepts in a corpus of text  then nodes can be ranked
based on their connection to these concepts  these methods have been extensively applied
to quantify or rank the importance of scientific publications  egghe   rousseau        
however  because these techniques have been extensively studied elsewhere and also ignore
graph structure  such as citations   we do not discuss them further here 
   

fitransforming graph data for statistical relational learning

      topology based node weighting
several node weighting algorithms that use only the topology of the graph were developed
to support early search engines  examples of this kind of algorithm include pagerank
 page et al          hits  kleinberg         and salsa  lempel   moran         each
of these algorithms rank the relative importance of web sites  conceptually based on some
kind of eigenvector analysis  langville   meyer         though in practice iterative computation may be used  for instance  pagerank models the web as a markov chain and is
implemented by systematically computing the principal eigenvector of limk ak e where
a is the adjacency matrix and e is the unit vector  hits  as previously described  instead computes the principal eigenvectors of aat and at a  these algorithms continue
to be very important for webpage ranking  but can also be applied to many other kinds of
graphs  kosala   blockeel        
in social network analysis  the objective of topology based node weighting is typically
to identify the most influential or significant individuals in a social network  there have
been a variety of centrality measures devised that use the local and global network structure to characterize the importance of individuals  wasserman   faust         examples
of these metrics include node degree  clustering coefficient  watts   strogatz         betweenness  freeman         closeness  i e   distance shortest paths   eigenvector centrality  bonacich   lloyd         and many others  jackson        newman        sabidussi 
       in addition  white and smyth        considered how to compute relative node
rankings  i e   rankings relative to a set of particularly interesting nodes  they show how
to compute such relative rankings both for metrics based on shortest paths as well as for
markov chain based techniques  e g   to produce pagerank with priors   in addition 
some of the similarity metrics described in table     can alternatively be formulated for
computing weights on nodes 
more recently  node weighting techniques have been extended to measure the relative
importance of nodes in temporally varying data  for instance  both kossinets  kleinberg 
and watts        and tang et al         define notions of temporal distance based on an
analysis of how frequently information is exchanged between nodes  this information can
be used to define a range of new graph metrics  such as global temporal efficiency  local temporal efficiency  and the temporal clustering coefficient  tang et al          more recently 
tang  musolesi  mascolo  latora  and nicosia        define notions of temporal betweenness
and temporal closeness  they argue that incorporating temporal information with these
metrics provides both a better understanding of dynamic processes in the network and more
accurately identifies the most important nodes  people   all of these metrics primarily concern networks that have time varying interactions  e g   communications between people  
but they could also be applied to other types of data with intermittent interactions between
nodes or where nodes link join and leave the network over time  some of these metrics also
apply to links  and could possibly be used to improve link prediction algorithms 
      hybrid node weighting
there are also hybrid node weighting approaches that use both the attributes and the graph
topology  bharat   henzinger        cohn   hofmann         for instance  there are
various approaches that modify hits  chakrabarti  dom  raghavan  et al         bharat
   

firossi  mcdowell  aha    neville

  henzinger        and pagerank  haveliwala        to construct node weights based on
both content and links  topic sensitive pagerank  haveliwala        seeks to compute a
biased set of pagerank vectors using a set of representative topics  alternatively  kolda 
bader  and kenny        propose tophits  a hybrid approach that adds anchor text  i e  
the clickable text on each hyperlink  to the adjacency matrix representation used by hits 
they then use a higher order analogue of svd known as parallel factors  parafac 
decomposition  harshman        to identify both the key topics in the graph as well as the
most important nodes  other hybrid approaches have been proposed such as simrank  jeh
  widom         topical methods  haveliwala        nie  davison    qi        kolda
  bader         probabilistic hits  cohn   chang         and many others  richardson
  domingos        lassez et al          section   discusses further relevant work in the
context of joint node and link transformation techniques 
recently  node weighting approaches have been applied in adversarial information retrieval  air  to detect or moderate the influence of spam web sites  typically  these techniques produce weights using both the topology of the graph and some other information 
but not necessarily the kind of attribute information that is used by the techniques discussed
above  for instance  trustrank  gyongyi  garcia molina    pedersen        is based on
pagerank and uses a set of trusted sites evaluated by humans to propagate the trust to
other locally reachable sites  on the other hand  spamrank  benczur  csalogany  sarlos   
uher        measures the amount of undeserved pagerank by analyzing the backlinks of a
site  there are other algorithms that try to identify link farms and link spam alliances  wu
  davison         given a seed set of known link farm pages  among these air methods 
trustrank is the most widely known but suffers from biases where the human selected set
of trustworthy sites may favor certain communities over others 
    node labeling
given the initial graph g   hv  e  xv   xe i  the task is to assign some discrete label for
some or all of the nodes in g  we first discuss labeling techniques based on classification 
then consider unsupervised textual analysis techniques 
in many cases  node labeling may be considered an end in itself  for instance  in our
running facebook example  the stated goal is to predict the political affiliation of each
node where that label is not already known  in other cases  however  node labeling is
more properly understood as a representation change that supports the desired task  for
instance  for some definitions of anomalous link detection  rattigan   jensen         having
estimated node labels would allow us to identify links between nodes whose labels indicate
they should rarely  if ever  be connected  alternatively  for some datasets estimating node
labels may enable us to subsequently partition the data based on node type  enabling us to
learn more accurate models for each type of node 
even when node labeling is the final goal  as with our facebook example  intermediate
label estimation may still be useful as a representation change  in particular  kou and cohen
       describe a stacked model for relational classification that relabels the training set
with estimated node labels using a non relational classifier  they then use these estimated
labels to learn a new classifier  one that uses both attributes and relational features   and
use the new classifier to perform relational classification on the test graph  this approach
   

fitransforming graph data for statistical relational learning

yields high accuracy  comparable to that of much more complex algorithms for collective
classification  cc   fast and jensen        analyze this result and discuss how it can be
explained by a natural bias in most cc algorithms  training is performed with the given
node labels but the inference depends in part on estimated labels  mcdowell  gupta   
aha         stacked models compensate for this bias by instead training with the relabeled
 estimated  training set  in addition  inference with the new classifier needs only a single
pass over the test graph  yielding much faster inference than cc techniques like gibbs
sampling or belief propagation  more recently  maes  peters  denoyer  and gallinari       
extend these ideas of node relabeling in order to generate a larger training set via multiple
simulated iterations of classification  they show that in some cases this approach can
outperform stacked models and other cc algorithms like gibbs sampling 
thus  there are multiple reasons for creating new labels for the nodes in a graph  this
labeling can be accomplished by relational aware algorithms like those described above as
well as by earlier algorithms used for relational or collective classification  chakrabarti 
dom    indyk        neville   jensen        taskar et al         lu   getoor       
macskassy   provost         node labeling can of course also be done by traditional 
non relational algorithms such as svm  decision trees  knn  logistic regression  and naive
bayes  among various others  lim  loh    shih        michie  spiegelhalter  taylor   
campbell        burges        cristianini   shawe taylor        joachims         these
methods simply use features xv and do not exploit topology or link structure 
the above techniques all assign new labels via supervised learning  labels can also
be assigned via unsupervised techniques for textual analysis  there are many networks in
the real world that contain textual content such as social networks  email communication
networks  citation networks  and many others  traditional textual analysis models such as
lsa  deerwester et al          plsa  hofmann        and lda  blei et al         can be
used to assign each node a topic representing an abstraction of the textual information 
more recent techniques such as link lda  erosheva  fienberg    lafferty        and linkplsa  cohn   hofmann        aim to incorporate the link structure into the traditional
techniques in order to more accurately discover a nodes type   in particular  the work
of cohn and hofmann demonstrate that their technique can produce more accurate node
labels than techniques that use only the node attributes or only the link topology  there
have also been more sophisticated topic models that have been developed for specific tasks
such as social tagging  lu  hu  chen    ran park        or temporal data  huh   fienberg 
      he   parker        
    node feature construction
node feature construction is the systematic construction of features for the nodes  typically
for the purpose of improving the accuracy or understandability of srl algorithms  feature
construction is the most common relational representation change  and is very frequently
done before performing a task such as classification  for instance  before performing cc to
classify the nodes in our example facebook political affiliation task  we are likely to compute
   the names for link lda and link plda come from the work of nallapati  ahmed  xing  and cohen
        not from the original papers describing the techniques 

   

firossi  mcdowell  aha    neville

some new features representing the information about each node  e g   age bracket   and
the known information about each nodes neighbors  e g   how many are liberal   
different techniques for node feature construction have been described by many previous
investigations  though feature construction was not necessarily the focus of many of those
investigations  in this section  we summarize and explain the different aspects of feature
construction  in particular  section       presents and discusses a taxonomy of features
based on what kinds of inputs  such as topology information or link feature values  they
use for computing the new feature values  next  section       describes the possible operators  such as aggregation or discretization  that can be applied to these inputs  finally 
section       examines how to perform automatic feature search and selection to support a
desired computational task 
      relational feature inputs
a node feature can be categorized according to the types of information that it uses for
computing feature values  the possible information to use includes the set of nodes v or
links e  the node features xv   and the link features xe   figure   shows our taxonomy of
node features based on which of these sources of information  the inputs  they use  this
taxonomy is consistent with some distinctions that have been previously made in the literature  e g   between non relational and relational features   but to the best of our knowledge
this more complete taxonomy has never been previously described  the taxonomy consists
of four basic types  non relational features and three types of relational features  topology features  relational link value features  and relational node value features   below we
describe and give examples of each 
 non relational features  a node feature is considered a non relational feature if
the value of the feature for a particular node is computed using only the non relational
features  i e   attributes  of that node  ignoring any link based information  for instance  figure  a shows a node and the corresponding nodes feature vector  a new
feature value might be constructed from this vector using some kind of dimensionality reduction  by adding together several feature values  by thresholding a particular
value  etc 
 topology features  a feature is considered a topology based feature if values of
the feature are computed using only the nodes v and links e  ignoring any existing
node and link feature values  for instance  in figure  b  a new feature value is being
computed for the node in the bottom left of the figure  the target node   using only
the topological information shown  in particular  the new feature value might count
the number of adjacent nodes  or count how many shortest paths in the graph pass
through the target node 
 relational link value features  a feature is considered a relational link value
feature if the feature values of the links that are adjacent to the target node are
used for computing the new feature  typically  some kind of aggregation operator is
applied to these values  such as count  mode  average  proportion  etc  for instance 
in figure  c  the values on the links shown represent communication topics  work or
personal   and a new link value feature might compute the mode of these values  p  
   

fitransforming graph data for statistical relational learning

input  

v e xv xe  

target  node  

node  feature    
construction  

xv  

  

link value  

p  

v e xv xe  

node value          

l  

non relational  
node  features  

relational  features  

v e   v e xe   v e xv  
topology  
features  

link value  
features  

node value  
features  

c  
p  

l  

p  

        p  

a   

w  

b   

  v  

c   

l  
d   

x

figure    node features taxonomy based on inputs used  the classes of node
features are non relational features  topology features  relational link value features  and relational node value features  these classes are defined with respect
to the relational information used in the construction of the features  i e   nodes
v   links e  node features xv   link features xe    the double lined target node
represents where the new feature value is being computed  parts c and d show
only a single feature value for each link or node for simplicity  but in general more
than one such feature may exist and be used 

usually this computation will include only the links directly connected to the target
node  but links a few hops away could also be used 
 relational node value features  a feature is considered a relational node value
feature if the feature values of nodes linked to the target node are used in the construction  links are used only for identifying these nodes  although nodes more than
one hop away from the target node may also be included  for instance  figure  d
shows the feature values of adjacent nodes  c or l  which could  for instance  be
used to compute a new node value feature based on the mode  l  of those values 
alternatively  one feature might count the number of adjacent c nodes and another
might count the number of adjacent l nodes 
   

firossi  mcdowell  aha    neville

feature computation may also be applied recursively  for instance  the refex system  henderson  gallagher  li  akoglu  eliassi rad  tong    faloutsos        first computes features for every node based on their degree  a topology based feature   then considers recursive combinations of these features  such as the mean out degree of a nodes
neighbors   henderson et al  show that such recursive features can often improve classification accuracy for datasets where the network structure is predictive  alternatively  a
topology based feature such as betweenness might be computed  then a relational nodevalue feature might compute the average betweenness of the nodes that are neighbors of
the target and have a label of c  this is an example of a hybrid feature that uses both
node value and topology based information 
another interesting aspect of relational features is the potential for feature value recomputation  in particular  many techniques for collective classification involve computing
a node feature  such as the number of neighbors currently labeled c  where that feature
depends on other feature values that are estimated  e g   the predicted node labels  and
thus may change  jensen et al         sen et al          in addition  mcdowell  gupta 
and aha        describe features that have a similar need for recomputation  because the
meta features they use depend upon the estimated label probabilities for each node in the
neighborhood of the target node  in contrast  this kind of feature re computation has much
less applicability for non relational data  where the nodes are assumed to be independent
of each other  however  it can occur with techniques such as semi supervised learning or
co learning 
      relational feature operators
the previous section described features according to the different kinds of inputs that they
use during feature value computation  whereas this section describes the different operators
that can be used for this computation  table   summarizes these operators  in some
cases  an operator can be used for many different types of relational input  for instance 
aggregation operators can be computed using the graph topology  relational node value
inputs  and or relational link value inputs  as indicated by the appropriate checkmarks in
table    in contrast  path or walk based operators generally use only the graph topology  for
these operators  the lighter colored checkmarks in table   indicate that path walk based
operators could sensibly be used in conjunction with relational link value or node values
inputs  but this has been rarely if ever done  below we discuss each of the operators from
table   in more detail 
relational aggregates  aggregation refers to a function that returns a single value
from a collection of input values such as a set  bag  or list  the most classical statistical
aggregation operators are average  mode  exists  count  max  min  and sum  neville
  jensen        lu   getoor         for srl  another frequent operator is proportion 
which computes  for instance  the fraction of a nodes neighbors that meet some criteria
such as having the label c  mcdowell  gupta    aha         these operators may also
be combined with thresholds  e g   to evaluate whether the count of a nodes neighbors
labeled c is at least    the thresholding turns the numerical aggregate into a boolean
feature  which is needed for tree based algorithms  neville  jensen  friedland  et al         
perlich and provost        describe a set of more complex relational aggregates that depend
   

fitransforming graph data for statistical relational learning

relational aggregates

mode  average  count  proportion  degree     

temporal aggregates

exponential linear decay  union     

x

set operators

union  intersection  multiset     

x

clique potentials

direct link cliques  co citation cliques  triads     

subgraph patterns

two star  three star  triangle  i e   transitivity      

dimensionality reduction

pca  svd  factor analysis  principal factor analysis  independent component analysis     

path walk based measures

betweenness  common neighbors  jaccards coefficient  adamic adar  shortest paths  random walks 
   

textual analysis

lsa  lda  plsa  link lda  link plsa     

x

relational clustering

spectral partitioning  hierarchical clustering  partitioning relocation methods  k means  k medoids  
   

x

x

relational node value

example techniques

relational link value

relational operators

topology

non relational

inputs

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

table    relational feature operators  summary of the most popular types of relational feature operators  a check is used to indicate the classes of inputs  see
section        that each operator most naturally uses for constructing feature values  while a lighter check indicates that the operator could sensibly be used with
that input but that this combination has rarely if ever been used 

   

firossi  mcdowell  aha    neville

on the distribution of attribute values that are associated with each node  e g   via links or a
relational join   for instance  these aggregates may use a function such as the edit distance
to compare each nodes distribution to a reference distribution computed from the training
data  perlich and provost demonstrate that these aggregations can in some cases improve
performance compared to simpler alternatives  there are also aggregate operators that use
only topology based information  for instance  the operator degree  which simply counts
the number of adjacent links  can be a predictive feature  but should be applied carefully
to relational data to avoid bias  jensen  neville    hay        
temporal aggregates  relational information might also contain temporal information
in the form of timestamps or durations for the links  node  or features  in general  such data
can be handled by defining special temporal aggregation features computed over the raw
data  mcgovern  collier  matthew gagne  brown    rodger        or by defining a graph
that summarizes all of the temporal information  usually by decreasing the importance of
less recent information   sharan   neville        rossi   neville         rossi and neville
discuss an example of the latter approach  where they explore the impact of using various
temporal relational information and various kernels for summarization  alternatively  section     discusses how notions of temporal distance can be used to modify path walk based
metrics such as node betweenness and closeness 
set operators  the traditional domain independent set operators such as set union 
intersection  and difference can be applied to construct features  kohavi   john        
for instance  if there are two attributes that both represent the presence of some word
in a page  node   a new feature might represent the case where a page contains both
of those words  i e   feature intersection   for relational data  more complex set based
features are possible  for instance  a feature for collective classification might represent the
union of all the class labels of the nodes adjacent to the target node  neville  jensen  and
gallagher        propose a more complex approach where the feature value is a multiset
that represents the complete distribution of adjacent nodes labels  e g     c   m   l  to
indicate the labels of ten adjacent nodes   using this feature representation  they show
that the independent value approach that assumes that the labels are independently
drawn from the same distribution yields the most effective relational classification  recently 
mcdowell et al         showed that  for cc  this multiset approach usually outperformed
other types of features such as the proportion or count based aggregates discussed above 
clique potentials  some probabilistic models such as relational markov networks  rmns 
 taskar et al         perform inference over related nodes without computing aggregates 
instead  they use clique specific potential functions to represent the probabilistic dependencies  and a product term in the probability computation naturally expands to accommodate
a varying number of neighbors for each node  in one sense  this is a featureless approach 
since there is no need to choose a relational aggregation function  however  different kinds
of dependencies can still be represented by different cliques  for instance  taskar et al 
consider different sets of cliques for webpage classification  one based only on hyperlinks 
the other including information based on where links appear within a page  likewise  later
work added additional types of cliques to enable link prediction  taskar et al          thus 
even with these models there remain important feature choices to be made 
   

fitransforming graph data for statistical relational learning

figure    subgraph patterns with link labels  each subgraph represents a possible
pattern that a particular feature could look for in relation to the target node  the
bottom left node in each case  

other probabilistic models also use link based information without computing explicit
features  such as the random walk based classifier of lin and cohen        or the weightedneighbor approach of macskassy and provost         even in these cases  however  choices
remain about what types of links to use  for instance  in webpage graphs  co citation
links may be more predictive of class labels than direct links  macskassy   provost       
mcdowell et al         
subgraph patterns  a subgraph pattern feature is one that is based on the existence of a
particular pattern in the graph adjacent to the target node  such a feature might count how
many times a particular pattern exists for the target node  or produce a value of true if at
least one such pattern exists  the simplest such pattern is called reciprocity  it is true when
the target node i links to node j and j links back to i  in most cases  however  the patterns
are more complex and involve more nodes  robins  pattison  kalish  and lusher       
define many such patterns including two star  a node with at least two links   three star  a
node with at least three links   and triangle  also known as transitivity  where i  j  k
and i  k   most such patterns can be defined for both directed and undirected links 
many other patterns are possible  for instance  robins  snijders  wang  and handcock
       use subgraph patterns for probabilistically modeling graphs  they argue that using
more complex patterns such as the alternating k triangle  based on finding k triangles that
all share a common side  can help to avoid degeneracy that might otherwise arise during
graph generation  furthermore  subgraph patterns can also be extended to exploit labels
on the links and or nodes  for instance  assume some links are labeled with   or    representing different topics  and some links are labeled with a plus or minus sign  representing
positive or negative relationships   figure   demonstrates three possible subgraph patterns 
based on different link labelings  relative to the target node shown at the bottom left of
each subgraph  a subgraph feature could compute  for each node  the number of matches
for one of these patterns  and this feature could be used for later analysis 
dimensionality reduction the goal of dimensionality reduction is to find a lower kdimensional representation of the initial n features  sarwar  karypis  konstan    riedl 
      fodor         more formally  given an initial n dimensional feature vector x  
 x    x         xn    find a lower k dimensional representation x such that x    x    x         xk  
with k  n where the most significant information of the original data is captured  according to some criterion  there are many dimensionality reduction methods such as principal
   

firossi  mcdowell  aha    neville

component analysis  pca   principal factor analysis  pfa   and independent component
analysis  ica  
dimensionality reduction techniques can be applied on the adjacency matrix a of the
graph g to create a low dimensionality graph representation  section     explained how this
can be used for link prediction  these techniques can also be useful for feature computation 
for instance  bilgic  mihalkova  and getoor        investigate active learning to improve
the accuracy of collective classification  their technique involves both non relational and
relational features  but they demonstrate that first applying dimensionality reduction  with
pca  to the non relational features simplifies learning  leading to substantial gains in accuracy 
other operators  we mention only briefly those operators that have already been discussed extensively elsewhere  path based measures  such as betweenness and distance 
and walk based measures  such as pagerank  were discussed in sections      these
types of measures have been used as features in a classifier to predict links  lichtenwalter
et al         as well as for validating relational sampling techniques  leskovec  chakrabarti 
kleinberg  faloutsos    ghahramani        moreno   neville        ahmed  neville   
kompella      a      b   these measures typically use only the topology  not the features   but one could easily imagine computing metrics based  for instance  only on paths
where each edge had a particular label or type  textual analysis techniques were discussed
in sections     and      and relational clustering techniques were discussed in section   
these operators were used specifically for node link prediction  weighting  or labeling  but
can also be used for more general feature construction 
finally  there are operators based on similarity measures  similarity between two
nodes is often computed  for instance for link prediction  section    or weighting  section       such computations can easily lead to a feature value for a link  since the link
obviously refers to two endpoint nodes that can be compared  however  for computing a
node feature value  there is usually no obvious other node for comparison  so similarity measures are not typically used for node feature values  such measures can  however  be used for
node prediction  and section   discusses how in some cases newly discovered nodes groups
can be used to create new node features  as a particular instance of relational similarity
functions  graph kernels for structured data  gartner        can also be used  such kernels
can be used either between the nodes of a single graph  kondor   lafferty        or to
compute the similarity between two graphs  vishwanathan  schraudolph  kondor    borgwardt         for instance  the former type of kernel is another technique that could also
be used for link or group prediction 
discussion  many of the feature operators discussed can naturally be used to compute feature values for links in additions to nodes  for instance  textual analysis can be applied to
links if there is text associated with each link  and most node centered path based measures
have analogous formulations for links  one difference is that nodes naturally may link to
many other nodes  whereas we assume links with just two endpoints  thus  relational aggregates such as count do not initially seem as useful for computing link features  however 
figure   previously demonstrated how link aggregation can be accomplished by broadening the computation to include the multiple links or nodes that are logically connected to
each endpoint node of the target link  naturally  some feature inputs and operators are
   

fitransforming graph data for statistical relational learning

better suited for computing node features vs  for computing link features  the next section
examines how to select the most appropriate features for a given task 
      searching  evaluating  and selecting relational features
given the large number of possible features that could be used for some task  such as the
example facebook classification task   which features should actually be used to learn a
model  in some cases  such selection is done manually based on prior experience or trial
and error  in many situations  though  more automatic feature selection is desirable  for
non relational data  this has been a widely studied topic in machine learning  guyon  
elisseeff        koller   sahami        yang   pedersen        dash   liu        jain
  zongker        pudil  novovicova    kittler         but selecting relational features has
received considerably less attention  given the large number of possible features  efficient
strategies for searching over and evaluating the possible features is needed  in this section 
we first summarize these two key problems of feature search and feature evaluation  then
give examples of how these issues have been resolved in actual srl systems 
search  the first step in searching over the relational features is to define the possible
relational feature space by specifying the possible raw feature inputs  e g   node and link
feature values  and operators to consider  the possible operators can include domainindependent operators  e g   mode  count  and or problem specific operators  e g   count the
number of friends divided by the number of groups   domain independent operators are
obviously more general and easier to apply  while the problem specific operators can reduce
the number of possibilities that must be considered but require more effort and expert
knowledge  however  both approaches are vulnerable to selection biases  jensen et al        
jensen   neville         the second step is to pick an appropriate search strategy  usually
either exhaustive  random  or guided  an exhaustive strategy will consider all features
that are possible given the specified inputs and operators  while a random strategy will
consider only a fraction of this space  a guided strategy will use some heuristic or subsystem to identify the features that should be considered  in all three cases  each feature
that is considered is subjected to some evaluation strategy that assesses it usefulness  these
strategies are described next 
evaluation and selection  each feature that is considered must be evaluated in some
way to determine if it will be retained for use in the final model  for instance  a candidate
feature may be evaluated by adding it to the current classification model  if it improves
accuracy on a holdout set  then it is immediately  and greedily  added to the set of retained
features  davis  burnside  castro dutra  page    costa        davis  ong  struyf  burnside 
page    costa         in other cases  every candidate feature is assigned some score and
then only the best scoring feature is retained  neville  jensen  friedland  et al          or
features are added to the model based on decreasing score  so long as the new features
continue to improve the model  mihalkova   mooney         simpler techniques that do
not require evaluating the overall model can also be used  for instances  metrics such as
correlation or mutual information can be used to estimate how useful the feature is for the
desired task  other metrics or strategies that could be used include akaikes information
criterion  aic   akaike         mallows cp  mallows         bayesian information criterion
 bic   hannan   quinn        schwarz        and many others  shao        george  
   

firossi  mcdowell  aha    neville

proposed system

search method

feature evaluation

exhaustive

chi square statistic p value

rdn boosting  natarajan  khot  kersting  gutmann    shavlik        khot 
natarajan  kersting    shavlik       

exhaustive

weighted variance

refex  henderson et al        

exhaustive

log binning disagreement

random

chi square statistic p value

sayu  davis et al        

aleph

auc pr

nfoil  landwehr et al        

foil

conditional log likelihood

sayu vista  davis et al        

aleph

auc pr

probfoil  de raedt   thon       

foil

m estimate

kfoil  landwehr et al        

foil

kernel target alignment

greedy hill climbing

bayesian model selection

beam search

wpll

template based

wpll

level wise search

pseudo likelihood

aleph  

m estimate

rpt  neville  jensen  friedland  et al  
     

spatiotemporal

rpt

 mcgovern

et al        

prm struct  learning  getoor  friedman  koller    taskar       

tsdl  kok   domingos       
busl  mihalkova   mooney       
pbn

learn and join

 khosravi 

tong man  xu    bina       

discriminative mln structure
learning  huynh   mooney        biba 
ferilli    esposito       

table    systems for searching for and selecting node features  a summary
of some of the systems that can be used to automatically search for and select the
most appropriate features for a given task  note that  depending on the context 
these papers may be describe their function in terms of learning the best rules for
a system or of learning the structure  e g   of a mln   only some of the mlnbased systems are described  for some of these  wpll is the weighted pseudo
log likelihood 

mcculloch         frequently  a possible feature may have a particular parameter whose
value must be set  such as a threshold   selecting the best value for a given feature can
use the same evaluation metrics or may use a simpler estimation technique  e g   based on
maximum likelihood 
examples  table   summarizes the strategies used by a number of srl systems that automatically search for features  the columns of the table describe how each system searches
   

fitransforming graph data for statistical relational learning

for features and how the features are evaluated  for instance  relational probability trees
 rpts   neville  jensen  friedland  et al         are an extension of probability estimation
trees for relational data that use an exhaustive search strategy for feature selection  in particular  rpt learning involves automatically searching over the space of possible features
using aggregation functions such as mode  average  count  proportion  min  max 
exists  and degree  these aggregations can involve node and link feature values  e g  
for average  or just topology information  e g   for degree   these features are used
for classification tasks  such as predicting the class label for a document  each feature is
evaluated based on using the chi square statistic to measure the correlation between the
feature and the class label  this yields a feature score and an associated p value  features
with p values below the level of statistical significance are discarded  then the remaining
feature with the highest score is chosen for inclusion in the model  this selection process
has also been extended to use randomization tests to adjust for biases that are common in
relational data  jensen et al         jensen   neville         rpts have also been extended
for temporal domains  sharan   neville        rossi   neville        
rpts represent the conditional probability distributions using a single tree  in contrast 
natarajan et al         propose using gradient boosting  friedman        such that each
conditional probability distribution is represented as a weighted sum of regression trees
grown in a stage wise optimization  the features for each tree are selected via a depthlimited  exhaustive search  though they note that domain knowledge could also be used to
guide this search  natarajan et al  argue that the resultant set of multiple  relatively shallow
trees allows efficient learning of complex structures  and demonstrate that this technique
can outperform alternatives based on single trees or the markov logic networks discussed
below 
another system that uses exhaustive search is refex  henderson et al          which
uses aggregates of sum and mean operators to recursively generate features based on the
degree of a node and its local neighborhood  to prune the resultant large set  refex uses
logarithmic binning of the feature values  clusters features based on their similarity in the
binned space  and then retains only one feature from each cluster  the logarithmic binning
is chosen because it favors features that are more discriminative for high degree nodes 
this recursive approach has also been modified for constructing features over dynamic
networks  rossi  gallagher  neville    henderson        
alternatively  spatiotemporal rpts  mcgovern et al         use a random search strategy  in particular  these rpts add temporal and spatial based features to the set of possible
features  the resultant feature space is too large for exhaustive search  so instead random
sampling is used  after a pre defined number of features have been considered  the best
scored feature is added to the model 
the remaining systems that we will discuss all use a guided search strategy  where
some heuristic or sub system provides candidate features that are considered  for instance 
several such systems  davis et al         landwehr et al         use an ilp system to
generate candidate features  then evaluate those features and select some for ultimate use 
in particular  sayu  davis et al         uses the ilp system aleph  srinivasan        to
generate a candidate feature  which they consider to be a new view on the original data  
aleph creates candidates features based on positive examples  from the training data  of
the concept which is being predicted  each proposed feature is evaluated by learning a
   

firossi  mcdowell  aha    neville

new model that includes the feature and then computing the area under the precision recall
curve  auc pr   if a feature improves the auc pr score  it is permanently added to
the model and the feature search continues  sayu vista  davis et al         retains this
same general approach but extends the types of features that can be considered  in particular
adding the ability to dynamically link together objects of different types and to recursively
build new features from other constructed features  davis et al  demonstrate that the link
connections are especially helpful in improving performance compared to the original sayu
system  landwehr et al         describe the nfoil system which is very similar to sayu
but was developed independently  while de raedt and thon        describe how probfoil
upgrades a deterministic rule learner like foil to be probabilistic  landwehr et al        
describe the related kfoil system which integrates foil with kernel methods  they also
consider the impact of several different feature scoring functions 
a number of systems have considered how to perform structure learning for probabilistic relational models  prms   getoor et al         or for markov logic networks
 mlns   domingos   richardson         which is a more general case of the feature selection problems described above  for instance  a mln is a weighted set of first order formulas 
structure learning corresponds to learning these formulas while weight learning corresponds
to learning the associated weights  the first mln structure learning approaches systematically construct candidate clauses by starting from an empty clause  greedily adding literals
to it  and testing the resulting clauses fit to the training data using a statistical measure  kok
  domingos        biba et al          however  these top down approaches are inefficient
because the initial proposal of clauses ignores the training data  resulting in a large number
of possible features being considered and possible problems with local minima  in response 
a number of bottom up approaches have been proposed  in particular  mihalkova and
mooney        use a propositional markov network structure learner to construct template
networks to guide the construction of features based on the training data  more recent
work has examined how to enable bottom up approaches to learn longer clauses based on
constraining the search to only consider features consistent with certain patterns or motifs  kok   domingos         or by clustering the input nodes to create a lifted graph
representation  enabling feature search over a smaller graph  kok   domingos        
khosravi et al         perform mln structure learning by first learning the structure of
a simpler parametrized bayes net  pbn   poole         then converting the result into a
mln  for data that contains a significant number of descriptive attributes  they show that
this approach dramatically improves the runtime of structure learning and also improves
predictive accuracy  schulte        has given a theoretical justification for this approach 
another alternative  proposed by khot et al          is to extend the previously mentioned
work of natarajan et al         on gradient boosting to mlns  essentially  the problem
of learning mlns is transformed into a series of relational regression problems where the
functional gradients are represented as clauses or trees  for several datasets they demonstrate faster mln structure learning that is as accurate or better than baselines including
the algorithms of mihalkova and mooney        and kok and domingos        
the above techniques for mlns all seek to learn a network structure that best explains
the training data as a whole  in contrast  for situations where the prediction of a specific predicate is desired  e g   to predict the political affiliation in our facebook example  
huynh and mooney        and biba et al         both propose discriminative approaches
   

fitransforming graph data for statistical relational learning

to mln structure learning  for instance  huynh and mooney use a modified version of
aleph  srinivasan        to compute a large number of candidate clauses  then use a form
of l   regularization to force the weights that are subsequently learned for these clauses to
be zero when the clause is not very helpful for predicting the predicate  this regularization 
in conjunction with an appropriate optimization function  effectively leads to selecting a
smaller set of features that are useful for the desired task 
discussion  we focus in this article on graph based data representations  see section      
however  many of the examples discussed above use a logical representation instead  we
include them in this section because the techniques used for constructing and searching
for features or rules are very similar in both settings  for instance  both rpts  a graphbased approach  and rdn boosting  a logical approach  use an exhaustive search over
probabilistic decision trees  with different feature scoring strategies 
popescul et al       a  examine how to automatically learn new relational features for
links  to support link prediction   but their techniques could also be applied to constructing
node features  in particular  they treat each feature as a relational database query  and use
the concept of refinement graphs  shapiro        to consider refining an initial query with
equi joins  equality selections  and statistical aggregates  after each refinement  further
refinements can be considered  this search is guided by sampling over some possible further refinements and proceeding only if the results of a particular refinement or type seems
promising  the features chosen are combined with a logistic regression classifier  for evaluation of the specific features  they use the bayesian information criterion  bic   schwarz 
       which includes a term than penalizes feature complexity to reduce the danger of
overfitting 
we discussed multiple systems that include notions of aggregation including rpts 
sayu vista  and the work of popescul et al       a  discussed above  there are also
other aggregate based learning approaches such as crossmine  yin  han  yang    yu        
clamf  frank  moser    ester         multi relational decision trees  mrdtl   leiva 
gadia    dobbs         confidence based concept discovery  c  d   kavurucu  senkul   
toroslu         and many others  perlich   provost        krogel   wrobel        knobbe 
siebes    marseille         there are also other possibilities for feature evaluation  for
instance  gleanersrl  goadrich   shavlik        uses aleph  srinivasan        to search
for clauses and then uses a metric of precision  recall for evaluating the clauses 

   jointly transforming nodes and links
in the previous sections  we primarily discussed relational representation transformation
techniques that are applied independently of one another  for instance  one technique
might be used to predict links  while another builds on the transformed representation by
applying a node labeling technique  this section instead examines joint transformation
tasks that combine node and link transformation in some way  for instance to label the nodes
and weight the links simultaneously  such techniques may enable each subtask to influence
the other in helpful ways  and avoids any bias that might be introduced by requiring the
serialization of two tasks  such as link weighting and node labeling  that might usefully be
performed jointly 
   

firossi  mcdowell  aha    neville

one recent approach proposed by namata  kok  and getoor        collectively performs link prediction  node labeling  and entity resolution  which can be seen as a form
of node deletion merging   they present an iterative algorithm that solves all three tasks
simultaneously by propagating information among solutions to the above three tasks  in
particular  they introduce the notion of inter relational features  which are relational features for one task that depend upon the predicted values for another  their results show
that using such features can improve accuracy  and that inferring predicted values for all
three tasks simultaneously can significantly improve accuracy compared to performing the
three tasks in sequence  even if all possible orderings are considered 
techniques that model the full distribution across links and attributes such as rmns
 taskar et al          prms  friedman et al          and mlns  domingos   richardson 
      can also be used in this scenario  for instance to jointly predict node and link labels 
in this section  however  we focus particularly on recent techniques that all presume the
existence of some textual content that is associated with the nodes or links of the graph
 although the basic algorithms would also work with other kinds of features   we consider
three types of techniques  based on what kind of input text they use  stand alone text
documents  e g   legal memos with no links   text documents connected by links  e g  
webpages with hyperlinks   or entities connected by links that have associated text  e g  
people connected by email messages   table   lists some of the most prominent models 
grouped according to these three types  the columns of this table indicate what kinds of
input the models use  middle section  and the types of transformation they can perform
 right hand section   the text documents corresponds to node features in this table  while
text associated with links yields link features  below we discuss each of the three types of
techniques in more detail 
    using text documents with no links
first  many techniques can be used to assign topics or labels to the nodes when those nodes
 such as documents  have associated text  for instance  the first row of table   indicates
that lda and plsa use only the nodes and node features and can perform node prediction 
weighting  and labeling  section   already mentioned how these techniques can be used to
label each node with one or more discovered topics  which is their more typical use  however 
these techniques can also perform node weighting  using the weights associated with the
topics  and or node prediction  by converting the discovered topics to new latent nodes
as discussed in the introduction to section     in table    we use lighter checkmarks to
represent these kind of situations where a transformation task could be performed by a
particular model but is not its primary use output 
lda and plsa treat each document as a bag of words and seek to assign one or more
topics  labels  to each document based on the words  in contrast  nubbi  chang  boydgraber    blei        designs an approach based on lda where a graph is defined based on
objects  nodes  that are referenced in a set of documents  then links are predicted based on
the relationships that are implied in the text of the documents  in addition  the nodes and
links are associated with their most likely topic s  based on these relationships  thus  this
model simultaneously performs link prediction  link labeling  and node labeling  a similar
   

fitransforming graph data for statistical relational learning

link labeling

node prediction

node weighting

node labeling

e

xe

xe

v

xv

xv

v

xv

lda plsa

x

x

nubbi

x

x

x

joint transformation model

e

xe

link weighting

input

nodes

link prediction

links

x

x

x

x

x

x

x

link lda  link plsa

x

x

x

x

x

x

x

x

pairwise link lda

x

x

x

x

x

x

x

x

link plsa lda

x

x

x

x

x

x

x

x

relational topic model  rtm 

x

x

x

x

x

x

x

x

topic link lda

x

x

x

x

x

x

x

x

group topic  gt 

x

x

x

x

x

x

x

x

author recipient topic  art 

x

x

x

x

x

block lda

x

x

x

x

x

x
x

x

x

table    summary of the joint transformation models  the middle section of the
table indicates what types of graph features are used as inputs to the model  while
the right side of the table indicates what types of link or node transformation can
be performed by the model  lighter checkmarks indicate that the output of the
model can be transformed to perform a particular transformation task  e g   to
use the node labels to create new latent group nodes   but where that task was
not the primary goal of the specified model 

   

firossi  mcdowell  aha    neville

result is produced by the semantic network extraction of kok and domingos        that
was discussed in section     
    using text document with links
the second type of joint transformation also uses text documents  but adds known links
between the documents to the model  for instance  section   discussed how link lda and
link plsa add link modeling to lda and plsa in order to perform node labeling  as
discussed above for lda and plsa this can be modified to also achieve node prediction
and weighting  as shown in table    link lda and link plsa can also be used for link
prediction and weighting by learning a model from a training graph and then using it to
predict unseen links on a new test graph  nallapati et al         
link lda and link plsa model links in a way that is very similar to how they model
the presence of words in a document  node   for instance  in link ldas generative model 
to generate one word  each document chooses a topic  then chooses a word from a topicspecific multinomial  the identical process  using a topic specific multinomial  is used to
generate  for a particular document  one target document to link to  thus  link lda and
link plsa directly extend the original lda and plsa models to add links 
nallapati et al         argue that link ldas and link plsas extensions for links 
while pragmatic  do not adequately capture the topical relationship between two documents
that are linked together  instead  they propose two alternatives  the first  pairwise linklda  replaces the link model of link lda with a model based on mixed membership
stochastic blockmodels  airoldi et al          where each possible link is modeled as a
bernoulli variable that is conditioned on a topic chosen based on the topic distributions of
each of the two endpoints of the link  the second approach  link plsa lda  retains the
link generation model of link lda  but changes the word generation model for some of the
documents  the ones with incoming links  so that the words in such a document depend on
the topics of other documents that link to it  the downside of this latter approach is that
it only works when the nodes can be divided into a set with only outgoing links and a set
with only incoming links  however  nallapati et al  argue that this limitation can be largely
overcome by duplicating any nodes that have both incoming and outgoing links  moreover 
this approach is much faster and more scalable than pairwise link lda  nallapati et al 
demonstrate that both models outperform link lda on a likelihood ranking task  and that
link plsa lda also outperforms link lda on a link prediction task  they also show
that link plsa lda and link lda were comparable in terms of execution time  but that
pairwise link lda was much slower 
changes to the generative model used by each of these approaches encode different assumptions about the data and can lead to significant performance differences  for instance 
chang and blei        introduce the relational topic model  rtm  and compare it to the
pairwise link lda model discussed above  both models allow similar flexibility in terms
of how links are defined  but chang and blei argue that their model forces the same topic
assignments that are used to generate the words in the documents to also generate the
links  which is not true of pairwise link lda  they then demonstrate that rtm provides
more accurate predictions and link suggestions than pairwise link lda and several other
baselines 
   

fitransforming graph data for statistical relational learning

another possible change to the model is to add other types of objects  for instance 
topic link lda  liu  niculescu mizil    gryc        models not only documents  links 
and the most likely topics associated with each document  but also explicitly considers the
author of each document and clusters these authors into multiple communities  creating
this new clustering is not equivalent to finding per document topics because each author
is associated with more than one document  they argue that this approach is analogous
to unifying the separate tasks of     assigning topics to documents and     analyzing the
social network of authors  they show that their approach can in some cases outperform
lda and link lda 
    using text associated with links
the final type of joint transformation techniques form link features based on text associated
with links  such as the text of email messages  mccallum  wang    corrada emmanuel 
      or scientific abstracts that relate to a particular protein protein interaction  balasubramanyan   cohen         several such techniques were discussed previously in the
context of link interpretation  for instance  section     discussed how models such as the
author recipient topic  art  model  mccallum  wang    corrada emmanuel        and
the group topic  gt  model  mccallum  wang    mohanty        extend lda to perform
link labeling  the strength of these predicted labels  topics  can also be used to weight the
links  in addition  the gt model directly assigns nodes to groups  i e   node labeling   while
the labels that art associates with each link could also be used to label the associated
nodes  the rart model  mccallum  wang    corrada emmanuel        extends art
by allowing a node to have multiple roles  more recently  block lda  balasubramanyan
  cohen        merges the ideas from these latent variables models with stochastic blockmodels  more specifically  the block lda shares information through three components 
the link model shares information with a block structure which is then shared by the topic
model  unlike gt and art  however  block lda focuses on labeling the nodes rather
than the links  balasubramanyan and cohen evaluate block lda on a protein dataset and
the enron email corpus and demonstrate that it outperforms link lda and several other
baselines on the task of protein functional category prediction 
    discussion
most of the techniques discussed above are variants of latent group models that focus on
node and or link label prediction  but they can also be used for node prediction where the
new nodes represent newly discovered topics or latent groups  these models have also been
extended to incorporate notions of time  dietz  bickel    scheffer        wang  blei   
heckerman        wang   mccallum         topic hierarchies  li   mccallum         and
correlations between topics  blei   lafferty         in addition  links are usually assumed
to be generated based on the overall topic s  of a node or link  in contrast  the latent
topic hypertext model  lthm   gruber  rosen zvi    weiss        models each link as
originating from some specific word in a document  somewhat surprisingly  they show
that this approach leads to a model with fewer parameters than models like link lda 
and demonstrate that their approach outperforms both link lda and link plsa when
evaluated on a link prediction task 
   

firossi  mcdowell  aha    neville

 a  initial graph

 b  joint transformation

figure     example of joint transformation  in this example  new latent nodes
are added to represent discovered topics  and weighted links are added from
each original node to a new latent node  in addition  weighted links are added
between the latent nodes  representing connection strength between these topics 
finally  new links between the original nodes may be also be predicted  note
this example is adapted from results found in the work of nallapati et al         

if new nodes are added to the graph to represent discovered topics  then links are
invariably added to connect existing nodes to the new nodes  however  some models may
also learn information about how the discovered topics are related to each other  for
instance  figure    shows how two new topics are discovered in a graph and how they are
connected to the existing nodes  in addition  the topics are connected to each other with
new links where the weight of each link represents how frequently a document from that
topic cites a document representing a different topic  adding these additional links to the
graph lets the original nodes be connected more closely not only to their primary topics but
also to related topics 

   discussion and challenges
in this section we discuss additional issues that are related to relational representation
transformation and highlight important challenges for future work 
    guiding and evaluating representation transformation
the goal of representation transformation is often to improve the data representation in
some way that leads to better results for a subsequent task or possibly to a more understandable representation  how can we evaluate whether a particular transformation technique
has accomplished this goal  we first address this question  then consider when the final
goal can be used to more directly guide the initial transformation 
for some tasks  representation evaluation is straightforward provided that ground truth
values are known for a hold out data set  for instance  to test if a technique for link
   

fitransforming graph data for statistical relational learning

prediction is effective  accuracy can be measured for links predicted for the hold out set
 taskar et al         liu et al          the particular evaluation metric can be modified as
appropriate for the domain  for instance  chang and blei        evaluate the precision of
the twenty highest ranked links suggested for each document  while nallapati et al        
consider a custom metric called rkl that measures the rank of the last true link suggested
by the model  likewise  if the desired task involves classification  then a classification
algorithm can be run on the hold out data  with and without the representation change  to
see if the change increases classification accuracy 
in other cases  it may be difficult to directly measure how well a representation change
has performed  but classification can be used as a surrogate measure  if accuracy increases 
the change is assumed to be beneficial  for instance  classification has been used to evaluate link prediction  gallagher et al          link weighting  xiang et al          link labeling  rossi   neville        macskassy         and node prediction  neville   jensen 
       in addition  node labeling is naturally a classification problem  while node weighting
is usually evaluated in other ways  e g   based on query relevance 
other techniques can be used when direct evaluation is not feasible  but there exists
some other metric that is believed to be related  for instance  higher autocorrelation in a
graph can be associated with the presence of more sensible links  and algorithms such as
collective classification typically perform better when the level of autocorrelation is higher 
thus  xiang et al         demonstrate the success of their technique for estimating relationship strengths  link weights  based in part on showing an increase in autocorrelation when
measured for several attributes in a social network  likewise  increased information gain
for some of the attributes could be used to demonstrate an improved representation  lippi 
jaeger  frasconi    passerini         or link perplexity could be used to assess topic labelings  balasubramanyan   cohen         naturally  the most appropriate evaluation
techniques vary based upon the task  and a comparison of transformation techniques may
yield different results depending upon what metric is chosen 
ideally  representation transformation would be guided more directly by the final goal
as it is executed  rather than only being evaluated when the transformation is complete 
this is often the case for the feature selection and structure learning algorithms discussed
in section      task accuracy  or a surrogate measure  is evaluated with a particular feature
added  and it is retained if accuracy has improved  in other cases  the transformation is
even more directly specified by the desired end goal  for instance  the supervised random
walk approach discussed in section     uses a gradient descent method to obtain new link
weights such that links predicted by a subsequent random walk  their final goal  will be
more accurate  likewise  menon and elkan        show how to add supervision to methods
for generating latent features  see introduction to section    so that the features learned
would be more relevant to their final classification task  they show  however  that adding
such supervision is not always helpful  as a final example  shi  li  and yu        use a
quadratic program to optimize a linear combination of link weights such that the final link
weights will lead directly to more accurate classification via a label propagation algorithm 
in general  ensuring that a particular transformation will improve performance on the
final srl task remains challenging  many transformations cannot be directly guided by the
final goal  either because suitable supervised data is not available  or because it is not clear
   

firossi  mcdowell  aha    neville

how to modify the transformation algorithms to use such information  e g   with the latent
topic models of section   or the group detection algorithms of section    
    causal discovery
causal discovery refers to identifying cause and effect relationships  i e   smoking causes
cancer  from either online experimentation  aral   walker        or from observational
data  the challenge is to distinguish true causal relationships from mere statistical correlations  one approach is to use quasi experimental designs  qeds   which take advantage of
circumstances in non experimental data to identify situations that provide the equivalent of
experimental control and randomization  jensen  fast  taylor  and maier        propose a
system to discover knowledge by applying qeds that were discovered automatically  more
recently  oktay  taylor  and jensen        apply three different qeds to demonstrate how
one can gain causal understanding of a social media system  there is also another causal
discovery technique for linear models proposed by wang and chan         the challenge
remains of how to extend these techniques to apply to a broader range of relational data 
    subgraph transformation and graph generation
the majority of this article focused on transformation tasks centered around the nodes or
links of the graphs  however  there are also useful tasks for subgraph transformation which
seek to identify frequent informative substructures in a set of graphs or to create features
or classify such subgraphs  inokuchi  washio    motoda        deshpande  kuramochi 
wale    karypis         for instance  kong and yu        consider how to use semisupervised techniques to perform feature selection for subgraph classification given only a
few labeled subgraphs  as with nodes and links  for subgraphs the tasks of prediction 
labeling  weighting  and feature generation can all be described  many of the techniques
that we described for node centered features can also be used in this context  but a full
discussion of subgraph transformation is beyond the scope of this article 
recently  graph generation algorithms have attracted significant interest  these algorithms use some model to represent a family of graphs  and present a way to generate multiple samples from this family  two prominent models are kronecker product graph models
 kpgms   leskovec  chakrabarti  et al         and those based on preferential attachment
 price        barabasi   albert         these graph generation methods take advantage
of global  with kpgms  and local  with preferential attachment models  graph properties
to generate a distribution of graphs that can potentially include attributes  sampling from
these models can be useful for creating more robust algorithms  for instance by training a
classifier on a family of related graphs instead of on a single graph  newman        surveys
additional network models and properties that are relevant to graph generation 
    model representation
in srl there is also the notion of model representation  what kind of statistical model is
learned to represent the relationship between the nodes  links  and their features  some of
the most prominent models for srl are probabilistic relational models  prms   friedman
et al          relational markov networks  rmns   taskar et al          relational depen   

fitransforming graph data for statistical relational learning

dency networks  rdns   neville   jensen         structural logistic regression  popescul
et al       b   conditional random fields  crfs   lafferty  mccallum    pereira        
and markov logic networks  mlns   domingos   richardson        richardson   domingos         full discussion of these models is beyond the scope of this article  in many cases
techniques for relational representation transformation  such as link prediction  can be performed regardless of what kind of statistical model will be subsequently used  however  the
choice of statistical model does strongly interact with what kinds of node and link features
are useful  or even possible to use   section     describes some of these connections  while
a number of relevant comparisons have already been published  jensen et al         neville
  jensen        macskassy   provost        sen et al         mcdowell et al         crane
  mcdowell         more work is needed to evaluate the interaction between the choice of
statistical model and feature selection  and to evaluate which statistical models work best
in domains with certain characteristics 
    temporal and spatial representation transformation
where appropriate  we have already discussed multiple techniques that can incorporate
temporal information from graph data  see especially sections           and       these
techniques focused on solving particular problems such as node classification  but dealing
with such data invariably requires studying how to represent the time varying elements 
however  more work is needed to examine the general tradeoffs involved with different
temporal representations  for instance  hill  agarwal  bell  and volinsky        provide a
generic framework for modeling any temporal dynamic network where the central goal is to
build an approximate representation that satisfies pre specified objectives  they focus on
summarization  representing historical behavior between two nodes in a concise manner  
simplification  removing noise from both edges and nodes  spurious transactions  or stale relationships   efficiency  supporting fast analysis and updating   and predictive performance
 optimizing the representation to maximize predictive performance   this work provides a
number of useful building blocks  but more comparisons are needed to  for instance  evaluate the merits of using summarized networks with general purpose algorithms vs  using
more specialized algorithms with data that maintains the temporal distinctions 
temporal data is one particular kind of data that can be represented as a relational
sequence  kersting  de raedt  gutmann  karwath  and landwehr        survey the area
of relational sequence learning and explains multiple tasks related to such data  such as
sequence mining and alignment  these tasks often involve the need to identify relevant
features or structure  such as identifying frequent patterns or useful similarity functions 
thus  the set of useful techniques for feature construction and search in this domain overlap
with those discussed in section     
    privacy preserving representation
there is sometimes a desire to make private graph based data publicly available  e g   to
support research or public policy  in a way that preserves the privacy of the individuals
described by the data  the goal of privacy preserving representation is to transform the
data in a way that minimizes information loss while maximizing anonymization  e g   to
prevent individuals in the anonymized network from being identified  naive approaches to
   

firossi  mcdowell  aha    neville

anonymization operate by simply replacing an individuals name  or other attributes  with
arbitrary and meaningless unique identifiers  however  in social networks there are many
adversarial methods through which the true identity of a user can often be discovered from
such an anonymized network  in particular  the adversarial methods can use the network
structure and or remaining attributes to discover the identities of users within the network
 liu   terzi        zhou  pei    luk        narayanan   shmatikov        
an early approach by zheleva and getoor        examines how a graph may be modified
to prevent sensitive relationships  a particular kind of labeled link  from being disclosed 
they describe their approach in terms of node anonymization and edge anonymization 
node anonymization clusters the nodes into m equivalence classes based on node attributes
only  while most of the edge anonymization approaches are based on cleverly removing
sensitive edges  backstrom  dwork  and kleinberg        address a related family of attacks
where an adversary is able to learn whether an edge exists between targeted pairs of nodes 
more recently  hay  miklau  jensen  towsley  and weis        study privacy issues in
graphs that contain no attributes  their goal is to prevent structural re identification
 i e   identity reconstruction using graph topology information  by anonymizing a graph via
creating an aggregate network model that allows for samples to be drawn from the model 
the approach generalizes a graph by partitioning the nodes and then summarizing the graph
at the partition level  this approach differs from the other approaches described above
because it drastically changes the representation as opposed to making more incremental
changes  however  this method enforces privacy while still preserving enough of the network
properties to allow for a wide variety of network analyses to be performed 
in each of these investigations the key factors are the information available in the graph 
the resources of the attacker  and the type of attacks that must be defended against  in
addition  if an attacker can possibly obtain additional information related to the graph
from other sources  then the challenges are even more difficult  more work is needed to
provide strong privacy guarantees while still enabling partial public release of graph based
information 

   conclusion
given the increasing prevalence and importance of relational data  this article has surveyed
some of the most significant current issues in relational representation transformation  after presenting a new taxonomy of important transformation tasks in section    we next
discussed the four primary tasks of link prediction  link interpretation  node prediction 
and node interpretation  section   considered how some of these tasks can be accomplished
simultaneously via techniques for joint transformation  finally  section   considered how
to perform representation evaluation and key challenges for future work 
there are additional possible representation transformations that we have not had space
to discuss  or that do not fit cleanly in the taxonomy of figure    for instance  in a bipartite
graph of customers and products  it may be useful to eliminate all product nodes  replacing
their information content with new links among the customers that purchased the same
product  this is somewhat related to the group discovery techniques of section    we
have also not considered in any depth the potential for transforming nodes into edges or
   

fitransforming graph data for statistical relational learning

vice versa  though the representation choices of figure   are also relevant here   and this
technique can sometimes be a useful pre processing step 
the taxonomy presented in section   highlighted the symmetry between the possible
transformation tasks for links and those for nodes  this symmetry helped to organize this
survey  and also suggests areas where techniques developed for one of these entities can
be used for an analogous task with the other  for instance  liben nowell and kleinberg
       reformulated traditional node weighting algorithms to weight links  likewise  topic
discovery techniques based on lda can be used both for node labeling and for link labeling 
finally  many of the techniques used to create node features can also be used to create link
features  and vice versa  although node features have been studied much more thoroughly 
as discussed in section    there remains much work to do  for instance  link prediction
remains a very difficult problem  especially for the general case where any two arbitrary
nodes might be connected together  even more significantly  while we have described a
wide range of techniques that can address each of the transformation tasks  at the end of
the day the practitioner is left with a wide range of choices without many guarantees about
what might work best  for instance  node weighting may improve classification accuracy
for one dataset but decrease it on another  this challenge is made all the more difficult
because the techniques that we have described come from a wide range of areas  including
graph theory  social network analysis  numerical linear algebra  e g   matrix factorization  
metric learning  information theory  information retrieval  inductive logic programming 
statistical relational learning  and probabilistic graphical models  while the breadth of
techniques relevant to relational transformation is a wonderful resource  it also means that
evaluating the representation change techniques that are relevant to a particular task is
a time consuming  technically challenging  and incomplete process  therefore  much more
work is needed to establish a theoretical understanding of how different representation
changes affect the data  how different data characteristics interact with this process  and
how the combination of these techniques and the data characteristics affect the final results
of an analysis with relational data 

acknowledgments
we thank all the reviewers for many helpful suggestions and feedback  the majority of this
work was completed at the naval research laboratory  where ryan rossi was supported
by an asee onr nreip summer internship in      and by a nsf graduate research
fellowship  at purdue university   luke mcdowell was supported in part by nsf award
number         and by a grant from onr  this research was also partly supported by
the nsf under the contract number iis          the views and conclusions contained
herein are those of the authors and should not be interpreted as necessarily representing
the official policies or endorsements  either expressed or implied  of onr  nsf  or the u s 
government 

references
adamic  l  a     adar  e          friends and neighbors on the web  social networks 
               
   

firossi  mcdowell  aha    neville

adibi  j   chalupsky  h   melz  e   valente  a   et al          the kojak group finder 
connecting the dots via integrated knowledge based and statistical reasoning  in
proceedings of the   th conference on innovative applications of artifical intelligence 
pp         
adomavicius  g     tuzhilin  a          toward the next generation of recommender
systems  a survey of the state of the art and possible extensions  ieee transactions
on knowledge and data engineering                 
ahmed  n   neville  j     kompella  r       a   network sampling designs for relational
classification  in proceedings of the  th international aaai conference on weblogs
and social media 
ahmed  n   neville  j     kompella  r       b   space efficient sampling from social activity
streams  in bigmine  pp     
ahmed  n   berchmans  f   neville  j     kompella  r          time based sampling of
social network activity graphs  in proceedings of the  th workshop on mining and
learning with graphs  pp     
airoldi  e  m   blei  d  m   fienberg  s  e     xing  e  p          mixed membership
stochastic blockmodels  journal of machine learning research              
akaike  h          a new look at the statistical model identification  ieee transactions
on automatic control                 
albert  r   jeong  h     barabasi  a          internet  diameter of the world wide web 
nature                     
amarel  s          on representations of problems of reasoning about actions  machine
intelligence            
anthony  a     desjardins  m          data clustering with a relational push pull model 
in proceedings of the seventh ieee international conference on data mining workshops  icdmw     pp         
aral  s     walker  d          creating social contagion through viral product design  a
randomized trial of peer influence in networks  in proceedings of the   st international conference on information systems 
backstrom  l     leskovec  j          supervised random walks  predicting and recommending links in social networks  in proceedings of the  th international conference
on web search and data mining  pp         
backstrom  l   dwork  c     kleinberg  j  m          wherefore art thou r    x  
anonymized social networks  hidden patterns  and structural steganography  in proceedings of the   th international world wide web conference  pp         
balasubramanyan  r     cohen  w          block lda  jointly modeling entity annotated
text and entity entity links  in proceedings of the  th siam international conference
on data mining 
barabasi  a     albert  r          emergence of scaling in random networks  science 
                   
   

fitransforming graph data for statistical relational learning

barabasi  a     crandall  r          linked  the new science of networks  american journal
of physics                 
basilico  j  b     hofmann  t          unifying collaborative and content based filtering 
in proceedings of the   st international conference on machine learning  pp       
ben hur  a     noble  w          kernel methods for predicting protein protein interactions  bioinformatics      suppl           
benczur  a   csalogany  k   sarlos  t     uher  m          spamrankfully automatic link
spam detection  in adversarial information retrieval on the web  pp       
berkhin  p          survey of clustering data mining techniques  grouping multidimensional
data  recent advances in clustering           
bharat  k     henzinger  m          improved algorithms for topic distillation in a hyperlinked environment  in proceedings of the   st international sigir conference on
research and development in information retrieval  pp         
bhattacharya  i     getoor  l          relational clustering for multi type entity resolution 
in proceedings of the  th international workshop on multi relational mining  pp      
bhattacharya  i     getoor  l          collective entity resolution in relational data  transactions on knowledge discovery from data             
biba  m   ferilli  s     esposito  f          discriminative structure learning of markov
logic networks  inductive logic programming             
bilgic  m   mihalkova  l     getoor  l          active learning for networked data  in
proceedings of the   th international conference on machine learning 
bilgic  m   namata  g  m     getoor  l          combining collective classification and link
prediction  in proceedings of the  th ieee international conference on data mining
workshops  pp         
blei  d   ng  a     jordan  m          latent dirichlet allocation  journal of machine
learning research             
blei  d     lafferty  j          a correlated topic model of science  the annals of applied
statistics              
bonacich  p     lloyd  p          eigenvector like measures of centrality for asymmetric
relations  social networks                 
borgman  c     furner  j          scholarly communication and bibliometrics  annual
review of information science and technology          
brightwell  g     winkler  p          maximum hitting time for random walks on graphs 
random structures   algorithms                
broder  a   kumar  r   maghoul  f   raghavan  p   rajagopalan  s   stata  r   tomkins 
a     wiener  j          graph structure in the web  computer networks           
       
burges  c          a tutorial on support vector machines for pattern recognition  data
mining and knowledge discovery                
   

firossi  mcdowell  aha    neville

cafarella  m  j   wu  e   halevy  a   zhang  y     wang  d  z          webtables  exploring
the power of tables on the web  in proceedings of vldb  pp         
camacho  j   guimera  r     nunes amaral  l          robust patterns in food web
structure  physical review letters                      
chakrabarti  s   dom  b     indyk  p          enhanced hypertext categorization using
hyperlinks  in proceedings of the acm sigmod international conference on management of data  pp         
chakrabarti  s   dom  b   raghavan  p   rajagopalan  s   gibson  d     kleinberg  j 
        automatic resource compilation by analyzing hyperlink structure and associated text  computer networks and isdn systems                 
chang  j     blei  d          relational topic models for document networks  in the
 th international conference on artificial intelligence and statistics  aistats   pp 
     
chang  j   boyd graber  j     blei  d          connections between the lines  augmenting
social networks with text  in proceedings of the   th acm sigkdd international
conference on knowledge discovery and data mining  pp         
clauset  a   moore  c     newman  m          hierarchical structure and the prediction
of missing links in networks  nature                    
cohn  d     chang  h          learning to probabilistically identify authoritative documents  in proceedings of the   th international conference on machine learning  pp 
       
cohn  d     hofmann  t          the missing link a probabilistic model of document content and hypertext connectivity  advances in neural information processing systems 
           
crane  r     mcdowell  l  k          evaluating markov logic networks for collective
classification  in proceedings of the  th mlg workshop at the   th acm sigkdd
conference on knowledge discovery and data mining 
craven  m   dipasquo  d   freitag  d   mccallum  a   mitchell  t   nigam  k     slattery 
s          learning to construct knowledge bases from the world wide web  artificial
intelligence                   
cristianini  n     shawe taylor  j          an introduction to support vector machines
and other kernel based learning methods  cambridge university press 
dash  m     liu  h          feature selection for classification  intelligent data analysis 
              
davis  j   burnside  e   castro dutra  i   page  d     costa  v          an integrated
approach to learning bayesian networks of rules  in proceedings of the european
conference on machine learning  pp       
davis  j   ong  i   struyf  j   burnside  e   page  d     costa  v  s          change of representation for statistical relational learning  in proceedings of the   th international
joint conference on artificial intelligence  pp           
   

fitransforming graph data for statistical relational learning

de raedt  l          logical and relational learning  springer 
de raedt  l     kersting  k          probabilistic inductive logic programming  springerverlag 
de raedt  l     thon  i          probabilistic rule learning  inductive logic programming 
           
deerwester  s   dumais  s  t   furnas  g  w   landauer  t  k     harshman  r         
indexing by latent semantic analysis  journal of the american society for information
science             
deshpande  m   kuramochi  m   wale  n     karypis  g          frequent substructurebased approaches for classifying chemical compounds  ieee transactions on knowledge and data engineering               
dhillon  i          co clustering documents and words using bipartite spectral graph partitioning  in proceedings of the seventh acm sigkdd international conference on
knowledge discovery and data mining  pp         
dietz  l   bickel  s     scheffer  t          unsupervised prediction of citation influences  in
proceedings of the   th international conference on machine learning  pp         
domingos  p     richardson  m          markov logic  a unifying framework for statistical
relational learning  in proceedings of the icml workshop on statistical relational
learning  pp       
dubois  c     smyth  p          modeling relational events via latent classes  in proceedings of the   th acm sigkdd international conference on knowledge discovery
and data mining  pp         
dunne  j   williams  r     martinez  n          food web structure and network theory 
the role of connectance and size  proceedings of the national academy of sciences of
the united states of america                 
easley  d     kleinberg  j          networks  crowds  and markets  reasoning about a
highly connected world  cambridge university press 
eckart  c     young  g          the approximation of one matrix by another of lower rank 
psychometrika                
egghe  l     rousseau  r          introduction to informetrics  elsevier science publishers 
erosheva  e   fienberg  s     lafferty  j          mixed membership models of scientific
publications  proceedings of the national academy of sciences of the united states of
america       suppl          
essen  u     steinbiss  v          cooccurrence smoothing for stochastic language modeling  in proceedings of the international conference on acoustics  speech  and signal
processing  pp         
faloutsos  m   faloutsos  p     faloutsos  c          on power law relationships of the
internet topology  in proceedings of the acm sigcomm international conference
on applications  technologies  architectures  and protocols for computer communication  pp         
   

firossi  mcdowell  aha    neville

fast  a     jensen  d          why stacked models perform effective collective classification 
in proceedings of the ieee international conference on data mining  pp         
fodor  i          a survey of dimension reduction techniques  us doe office of scientific
and technical information     
frank  r   moser  f     ester  m          a method for multi relational classification
using single and multi feature aggregation functions  proceedings of the principles
and practice of knowledge discovery in databases            
freeman  l  c          a set of measures of centrality based on betweenness  sociometry 
         
friedman  j          greedy function approximation  a gradient boosting machine   the
annals of statistics                   
friedman  n   getoor  l   koller  d     pfeffer  a          learning probabilistic relational models  in proceedings of the   th international joint conference on artificial
intelligence  pp            springer verlag 
gallagher  b   tong  h   eliassi rad  t     faloutsos  c          using ghost edges for
classification in sparsely labeled networks  in proceedings of the   th acm sigkdd
international conference on knowledge discovery and data mining  pp         
gartner  t          a survey of kernels for structured data  acm sigkdd explorations
newsletter              
george  e     mcculloch  r          variable selection via gibbs sampling  journal of the
american statistical association             
getoor  l   friedman  n   koller  d     taskar  b          learning probabilistic models of
link structure  journal of machine learning research            
getoor  l     taskar  b   eds            introduction to statistical relational learning 
mit press 
getoor  l     diehl  c  p          link mining  sigkdd explorations         
getoor  l   friedman  n   koller  d     taskar  b          learning probabilistic models of
relational structure  in proceedings of international conference on machine learning 
pp         
gibson  d   kleinberg  j     raghavan  p          inferring web communities from link
topology  in proceedings of the  th acm conference on hypertext and hypermedia 
pp         
gilbert  e     karahalios  k          predicting tie strength with social media  in proceedings of the   th chi international conference on human factors in computing
systems  pp         
girvan  m     newman  e  j          community structure in social and biological networks 
proceedings of the national academy of sciences                    
goadrich  m     shavlik  j          combining clauses with various precisions and recalls
to produce accurate probabilistic estimates  in proceedings of the   th international
conference on inductive logic programming  pp         
   

fitransforming graph data for statistical relational learning

gobel  f     jagers  a          random walks on graphs  stochastic processes and their
applications                
godbole  n   srinivasaiah  m     skiena  s          large scale sentiment analysis for news
and blogs  in proceedings of the international conference on weblogs and social
media 
golub  g     reinsch  c          singular value decomposition and least squares solutions 
numerische mathematik                 
green  j          latitudinal variation in associations of planktonic rotifera  journal of
zoology                
gruber  a   rosen zvi  m     weiss  y          latent topic models for hypertext  in
proceedings of the   th conference on uncertainty in artificial intelligence  pp     
    
guyon  i     elisseeff  a          an introduction to variable and feature selection  journal
of machine learning research              
gyongyi  z   garcia molina  h     pedersen  j          combating web spam with trustrank 
in proceedings of vldb  pp         
hannan  e     quinn  b          the determination of the order of an autoregression 
journal of the royal statistical society  series b  methodological              
harshman  r          foundations of the parafac procedure  models and conditions
for an explanatory multi modal factor analysis  ucla working papers in phonetics 
           
hartigan  j     wong  m          a k means clustering algorithm  journal of the royal
statistical society  series c  applied statistics             
hasan  m  a   chaoji  v   salem  s     zaki  m          link prediction using supervised
learning  in proceedings of the sdm workshop on link analysis  counterterrorism
and security 
haveliwala  t          topic sensitive pagerank  a context sensitive ranking algorithm for
web search  ieee transactions on knowledge and data engineering             
hay  m   miklau  g   jensen  d   towsley  d     weis  p          resisting structural reidentification in anonymized social networks  in proceedings of vldb  pp         
he  d     parker  d          topic dynamics  an alternative model of bursts in streams
of topics  in proceeding of the   th acm sigkdd international conference on
knowledge discovery and data mining  pp         
henderson  k   gallagher  b   li  l   akoglu  l   eliassi rad  t   tong  h     faloutsos 
c          its who you know  graph mining using recursive structural features 
in proceedings of the   th acm sigkdd international conference on knowledge
discovery and data mining  pp      
hill  s   agarwal  d   bell  r     volinsky  c          building an effective representation
for dynamic networks  journal of computational and graphical statistics         
       
   

firossi  mcdowell  aha    neville

hoff  p   raftery  a     handcock  m          latent space approaches to social network
analysis  journal of the american statistical association                     
hofmann  t          probabilistic latent semantic analysis  in proceedings of uncertainty
in artificial intelligence  pp         
huh  s     fienberg  s          discriminative topic modeling based on manifold learning 
in proceeding of the   th acm sigkdd international conference on knowledge
discovery and data mining  pp         
huynh  t     mooney  r          discriminative structure and parameter learning for
markov logic networks  in proceedings of the   th international conference on machine learning 
inokuchi  a   washio  t     motoda  h          an apriori based algorithm for mining
frequent substructures from graph data  in principles of data mining and knowledge
discovery  pp       
jaccard  p          etude comparative de la distribution florale dans une portion des alpes
et du jura  impr  corbaz 
jackson  m          social and economic networks  princeton univ press 
jain  a     zongker  d          feature selection  evaluation  application  and small sample performance  ieee transactions on pattern analysis and machine intelligence 
               
jeh  g     widom  j          simrank  a measure of structural context similarity  in
proceedings of the eighth acm sigkdd international conference on knowledge discovery and data mining  pp         
jensen  d     neville  j          linkage and autocorrelation cause feature selection bias in
relational learning  in proceedings of the   th international conference on machine
learning  pp         
jensen  d   neville  j     gallagher  b          why collective inference improves relational
classification  in proceedings of the   th acm sigkdd international conference on
knowledge discovery and data mining  pp         
jensen  d   neville  j     hay  m          avoiding bias when aggregating relational data
with degree disparity  in proceedings of the   th international conference on machine
learning  pp         
jensen  d   fast  a   taylor  b     maier  m          automatic identification of quasiexperimental designs for discovering causal knowledge  in proceeding of the   th
acm sigkdd international conference on knowledge discovery and data mining 
pp         
jeong  h   mason  s   barabasi  a     oltvai  z          lethality and centrality in protein
networks  nature                   
jeong  h   tombor  b   albert  r   oltvai  z     barabasi  a          the large scale
organization of metabolic networks  nature                     
   

fitransforming graph data for statistical relational learning

joachims  t          text categorization with support vector machines  learning with many
relevant features  in proceedings of the european conference on machine learning 
pp         
johnson  s          hierarchical clustering schemes  psychometrika                 
kahanda  i     neville  j          using transactional information to predict link strength in
online social networks  in proceedings of the  th international conference on weblogs
and social media  pp         
kamvar  s   klein  d     manning  c          spectral learning  in proceedings of the   th
international joint conference on artificial intelligence  pp         
kashima  h     abe  n          a parameterized probabilistic model of network evolution
for supervised link prediction  in proceedings of the ieee international conference
on data mining  pp         
katz  l          a new status index derived from sociometric analysis  psychometrika 
             
kavurucu  y   senkul  p     toroslu  i          aggregation in confidence based concept discovery for multi relational data mining  in proceedings of iadis european conference
on data mining  pp       
kersting  k     de raedt  l          basic principles of learning bayesian logic programs 
tech  rep       institute for computer science  university of freiburg 
kersting  k   de raedt  l   gutmann  b   karwath  a     landwehr  n          relational
sequence learning  probabilistic inductive logic programming             
khosravi  h   tong man  o   xu  x     bina  b          structure learning for markov logic
networks with many descriptive attributes  in proceedings of the   th conference on
artificial intelligence  pp         
khot  t   natarajan  s   kersting  k     shavlik  j          learning markov logic networks via functional gradient boosting  in data mining  icdm        ieee   th
international conference on  pp          ieee 
kim  m     leskovec  j          the network completion problem  inferring missing nodes
and edges in networks  in proceedings of the siam international conference on data
mining 
kleczkowski  a     grenfell  b          mean field type equations for spread of epidemics 
the small worldmodel  physica a  statistical mechanics and its applications                   
kleinberg  j          authoritative sources in a hyperlinked environment  journal of the
acm                 
knobbe  a   siebes  a     marseille  b          involving aggregate functions in multirelational search  in principles of data mining and knowledge discovery  pp     
    
kohavi  r     john  g          wrappers for feature subset selection  artificial intelligence 
                 
   

firossi  mcdowell  aha    neville

kohonen  t          the self organizing map  proceedings of the ieee                   
kok  s     domingos  p          learning the structure of markov logic networks  in
proceedings of the   nd international conference on machine learning  pp         
kok  s     domingos  p          statistical predicate invention  in proceedings of the   th
international conference on machine learning  pp         
kok  s     domingos  p          extracting semantic networks from text via relational clustering  in proceedings of the european conference on machine learning and principles
and practice of knowledge discovery in databases  pp         
kok  s     domingos  p          learning markov logic network structure via hypergraph
lifting  in proceedings of the   th international conference on machine learning  pp 
       
kok  s     domingos  p          learning markov logic networks using structural motifs 
in proceedings of the   th international conference on machine learning 
kolda  t  g   bader  b  w     kenny  j  p          higher order web link analysis using
multilinear algebra  in proceedings of the ieee international conference on data
mining  pp         
kolda  t     bader  b          the tophits model for higher order web link analysis 
in proceedings of the siam data mining conference workshop on link analysis 
counterterrorism and security  pp       
koller  d     sahami  m          toward optimal feature selection  in proceedings of the
  th international conference on machine learning  pp         
kondor  r     lafferty  j          diffusion kernels on graphs and other discrete structures 
in proceedings of the   th international conference on machine learning  pp     
    
kong  x     yu  p          semi supervised feature selection for graph classification  in proceeding of the   th acm sigkdd international conference on knowledge discovery
in data mining  pp         
koren  y   north  s     volinsky  c          measuring and extracting proximity graphs
in networks  transactions on knowledge discovery from data  tkdd              
      
kosala  r     blockeel  h          web mining research  a survey  acm sigkdd
explorations newsletter             
kossinets  g   kleinberg  j     watts  d          the structure of information pathways in a
social communication network  in proceeding of the   th acm sigkdd international
conference on knowledge discovery and data mining  pp         
kou  z     cohen  w          stacked graphical models for efficient inference in markov
random fields  in proceedings of the  th siam international conference on data
mining  pp         
krebs  v          mapping networks of terrorist cells  connections               
   

fitransforming graph data for statistical relational learning

krogel  m     wrobel  s          transformation based learning using multirelational aggregation  inductive logic programming               
kubica  j   moore  a   schneider  j     yang  y          stochastic link and group detection 
in proceedings of the   th aaai conference on artificial intelligence  pp         
lafferty  j   mccallum  a     pereira  f          conditional random fields  probabilistic models for segmenting and labeling sequence data  in proceedings of the   th
international conference on machine learning  pp         
landwehr  n   kersting  k     de raedt  l          nfoil  integrating nave bayes and
foil  in proceedings of the   th aaai conference on artificial intelligence  pp 
       
landwehr  n   passerini  a   de raedt  l     frasconi  p          fast learning of relational
kernels  machine learning                 
langville  a     meyer  c          a survey of eigenvector methods for web information
retrieval  siam review                 
lassez  j  l   rossi  r     jeev  k          ranking links on the web  search and surf
engines  in iea aie  pp         
lee  l          measures of distributional similarity  in proceedings of the   th annual meeting of the association for computational linguistics on computational linguistics 
pp       
leicht  e   holme  p     newman  m          vertex similarity in networks  physical review
e                 
leiva  h  a   gadia  s     dobbs  d          mrdtl  a multi relational decision tree learning
algorithm  in proceedings of the   th international conference on inductive logic
programming  pp       
lempel  r     moran  s          the stochastic approach for link structure analysis
 salsa  and the tkc effect  computer networks                   
leskovec  j   chakrabarti  d   kleinberg  j   faloutsos  c     ghahramani  z          kronecker graphs  an approach to modeling networks  journal of machine learning
research              
leskovec  j   huttenlocher  d     kleinberg  j          predicting positive and negative
links in online social networks  in proceedings of the   th international world wide
web conference  pp         
letovsky  s     kasif  s          predicting protein function from protein protein interaction
data  a probabilistic approach  bioinformatics      suppl     i    
li  w     mccallum  a          pachinko allocation  dag structured mixture models of
topic correlations  in proceedings of the   rd international conference on machine
learning  pp         
liben nowell  d     kleinberg  j          the link prediction problem for social networks 
journal of the american society for information science and technology              
     
   

firossi  mcdowell  aha    neville

lichtenwalter  r   lussier  j     chawla  n          new perspectives and methods in link
prediction  in proceeding of the   th acm sigkdd international conference on
knowledge discovery and data mining  pp         
lim  t   loh  w     shih  y          a comparison of prediction accuracy  complexity  and
training time of thirty three old and new classification algorithms  machine learning 
               
lin  d          an information theoretic definition of similarity  in proceedings of the   th
international conference on machine learning  pp         
lin  f     cohen  w  w          semi supervised classification of network data using
very few labels  in proceedings of the international conference on advances in social
network analysis and mining 
lippi  m   jaeger  m   frasconi  p     passerini  a          relational information gain 
machine learning              
liu  k     terzi  e          towards identity anonymization on graphs  in proceedings of
the acm sigmod international conference on management of data  pp        
liu  w     lu  l          link prediction based on local random walk  europhysics letters 
          
liu  y   niculescu mizil  a     gryc  w          topic link lda  joint models of topic and
author community  in proceedings of the   th international conference on machine
learning  pp         
long  b   zhang  z     yu  p          a probabilistic framework for relational clustering 
in proceedings of the   th acm sigkdd international conference on knowledge
discovery and data mining  pp         
long  b   zhang  z   wu  x     yu  p  s          spectral clustering for multi type relational
data  in proceedings of the   rd international conference on machine learning  pp 
       
lu  c   hu  x   chen  x     ran park  j          the topic perspective model for social
tagging systems  in proceeding of the   th acm sigkdd international conference
on knowledge discovery and data mining  pp         
lu  q     getoor  l          link based classification  in proceedings of the   th international conference on machine learning  pp         
macskassy  s     provost  f          a simple relational classifier  in proceedings of the
sigkdd  nd workshop on multi relational data mining  pp       
macskassy  s     provost  f          classification in networked data  a toolkit and a
univariate case study  journal of machine learning research            
macskassy  s  a          improving learning in networked data by combining explicit and
mined links  in proceedings of the   nd aaai conference on artificial intelligence 
pp         
maes  f   peters  s   denoyer  l     gallinari  p          simulated iterative classification a new learning procedure for graph labeling  machine learning and knowledge
discovery in databases             
   

fitransforming graph data for statistical relational learning

mallows  c          some comments on cp   technometrics               
maslov  s     sneppen  k          specificity and stability in topology of protein networks 
science                     
may  r     lloyd  a          infection dynamics on scale free networks  physical review
e                
mccallum  a   wang  x     corrada emmanuel  a          topic and role discovery in
social networks with experiments on enron and academic email  in journal of artificial
intelligence research  pp         
mccallum  a   wang  x     mohanty  n          joint group and topic discovery from
relations and text  in statistical network analysis  models  issues and new directions 
lecture notes in computer science       pp       
mcdowell  l   gupta  k     aha  d          cautious collective classification  journal of
machine learning research               
mcdowell  l   gupta  k     aha  d          cautious inference in collective classification 
in proceedings of the   nd aaai conference on artificial intelligence 
mcdowell  l   gupta  k     aha  d          meta prediction for collective classification 
in proceedings of the   rd international flairs conference 
mcgovern  a   friedland  l   hay  m   gallagher  b   fast  a   neville  j     jensen  d 
        exploiting relational structure to understand publication patterns in highenergy physics  sigkdd explorations                
mcgovern  a   collier  n   matthew gagne  i   brown  d     rodger  a          spatiotemporal relational probability trees  an introduction  in eighth ieee international
conference on data mining  icdm   pp         
menon  a     elkan  c          link prediction via matrix factorization  in proceedings of
the european conference on machine learning and principles and practice of knowledge discovery in databases  pp         
menon  a     elkan  c          predicting labels for dyadic data  data mining and
knowledge discovery                 
michie  d   spiegelhalter  d   taylor  c     campbell  j          machine learning  neural
and statistical classification  ellis horwood limited 
mihalkova  l     mooney  r          bottom up learning of markov logic network structure 
in proceedings of the   th international conference on machine learning  pp     
    
miller  k   griffiths  t     jordan  m          nonparametric latent feature models for link
prediction  advances in neural information processing systems  nips           
     
minsky  m          a framework for representing knowledge  tech  rep   massachusetts
institute of technology  cambridge  ma  usa 
mislove  a   marcon  m   gummadi  k   druschel  p     bhattacharjee  b          measurement and analysis of online social networks  in proceedings of the  th acm sigcomm
conference on internet measurement  pp       
   

firossi  mcdowell  aha    neville

moore  c     newman  m          epidemics and percolation in small world networks 
physical review e                   
moreno  s     neville  j          an investigation of the distributional characteristics
of generative graph models  in proceedings of the  st workshop on information in
networks 
nallapati  r   ahmed  a   xing  e     cohen  w          joint latent topic models for text
and citations  in proceeding of the   th acm sigkdd international conference on
knowledge discovery and data mining  pp         
namata  g   kok  s     getoor  l          collective graph identification  in proceedings of
the   th acm sigkdd international conference on knowledge discovery and data
mining  pp        acm 
narayanan  a     shmatikov  v          de anonymizing social networks  in proceedings
of the   th ieee symposium on security and privacy  pp         
natarajan  s   khot  t   kersting  k   gutmann  b     shavlik  j          gradient based
boosting for statistical relational learning  the relational dependency network case 
machine learning           
neville  j   adler  m     jensen  d          spectral clustering with links and attributes 
tech  rep         dept of computer science  university of massachusetts amherst 
neville  j     jensen  d          iterative classification in relational data  in proceedings of
the workshop on srl    th aaai conference on artificial intelligence  pp       
neville  j     jensen  d          leveraging relational autocorrelation with latent group
models  in proceedings of the  th ieee international conference on data mining 
pp         
neville  j     jensen  d          relational dependency networks  journal of machine
learning research            
neville  j   jensen  d   friedland  l     hay  m          learning relational probability
trees  in proceedings of the  th acm sigkdd international conference on knowledge
discovery and data mining  pp         
neville  j   jensen  d     gallagher  b          simple estimators for relational bayesian
classifers  in proceedings of the  rd ieee international conference on data mining 
pp         
neville  j   simsek  o   jensen  d   komoroske  j   palmer  k     goldberg  h          using
relational knowledge discovery to prevent securities fraud  in proceedings of the   th
acm sigkdd international conference on knowledge discovery in data mining 
pp         
newman  m          networks  an introduction  oxford univ press 
newman  m  e  j          the structure and function of complex networks  siam review 
           
newman  m       a   clustering and preferential attachment in growing networks  physical
review e                 
   

fitransforming graph data for statistical relational learning

newman  m       b   the structure of scientific collaboration networks  proceedings of the
national academy of sciences                 
newman  m     girvan  m          finding and evaluating community structure in networks  physical review e                
ng  a   jordan  m     weiss  y          on spectral clustering  analysis and an algorithm 
in advances in neural information processing systems  pp         
nie  l   davison  b     qi  x          topical link analysis for web search  in proceedings
of the   th international acm sigir conference on research and development in
information retrieval  p     
nowicki  k     snijders  t          estimation and prediction for stochastic blockstructures 
journal of the american statistical association               
oktay  h   taylor  b     jensen  d          causal discovery in social media using quasiexperimental designs  in proceedings of the acm sigkdd  st workshop on social
media analytics  soma kdd  
onnela  j  p   saramaki  j   hyvonen  j   szabo  g   lazer  d   kaski  k   kertesz  j    
barabasi  a  l          structure and tie strengths in mobile communication networks 
proceedings of the national academy of sciences                
page  l   brin  s   motwani  r     winograd  t          the pagerank citation ranking 
bringing order to the web  tech  rep   technical report  stanford digital library
technologies project 
pang  b     lee  l          opinion mining and sentiment analysis  foundations and trends
in information retrieval                
pastor satorras  r     vespignani  a          epidemic spreading in scale free networks 
physical review letters                    
pasula  h   marthi  b   milch  b   russell  s     shpitser  i          identity uncertainty
and citation matching  in in nips  mit press 
perlich  c     provost  f          aggregation based feature invention and relational concept classes  in proceedings of the  th acm sigkdd international conference on
knowledge discovery and data mining  pp         
perlich  c     provost  f          acora  distribution based aggregation for relational
learning from identifier attributes  machine learning            
poole  d          first order probabilistic inference  in international joint conference on
artificial intelligence  pp         
popescul  a   popescul  r     ungar  l  h       a   statistical relational learning for
link prediction  in proceedings of the workshop on learning statistical models from
relational data at ijcai 
popescul  a   popescul  r     ungar  l  h       b   structural logistic regression for link
analysis  in proceedings of the second international workshop on multi relational
data mining  pp        
   

firossi  mcdowell  aha    neville

popescul  a     ungar  l  h          cluster based concept invention for statistical relational learning  in proceedings of the   th acm sigkdd international conference
on knowledge discovery and data mining  pp         
price  d          a general theory of bibliometric and other cumulative advantage processes 
journal of the american society for information science                 
pudil  p   novovicova  j     kittler  j          floating search methods in feature selection 
pattern recognition letters                    
radicchi  f   castellano  c   cecconi  f   loreto  v     parisi  d          defining and
identifying communities in networks  proceedings of the national academy of sciences 
                  
rattigan  m  j     jensen  d          the case for anomalous link discovery  sigkdd
explorations newsletter              
ravasz  e   somera  a   mongru  d   oltvai  z     barabasi  a          hierarchical organization of modularity in metabolic networks  science                       
resnick  p     varian  h          recommender systems  communications of the acm 
             
richardson  m     domingos  p          the intelligent surfer  probabilistic combination
of link and content information in pagerank  in advances in neural information
processing systems  pp           
richardson  m     domingos  p          markov logic networks  machine learning         
       
riedel  s     meza ruiz  i          collective semantic role labelling with markov logic  in
proceedings of the twelfth conference on computational natural language learning 
pp         
robins  g   pattison  p   kalish  y     lusher  d          an introduction to exponential
random graph  p   models for social networks  social networks             
robins  g   snijders  t   wang  p     handcock  m          recent developments in exponential random graph  p   models for social networks  social networks             
rossi  r   gallagher  b   neville  j     henderson  k          dynamic behavioral mixedmembership model for large evolving networks  in arxiv preprint arxiv           
pp      
rossi  r     neville  j          modeling the evolution of discussion topics and communication to improve relational classification  in proceedings of the acm sigkdd  st
workshop on social media analytics  soma kdd   pp      
rossi  r   gallagher  b   neville  j     henderson  k          role dynamics  fast mining
of large dynamic networks  in lsna www  pp     
rossi  r     neville  j          time evolving relational classification and ensemble methods 
in proceedings of the   th pacific asia conference on knowledge discovery and data
mining  pp      
   

fitransforming graph data for statistical relational learning

roth  m   ben david  a   deutscher  d   flysher  g   horn  i   leichtberg  a   leiser  n  
merom  r     mattias  y          suggesting friends using the implicit social graph 
in proceeding of the   th acm sigkdd international conference on knowledge
discovery and data mining  pp         
russell  s  j     norvig  p          artificial intelligence  a modern approach   rd international edition edition   prentice hall 
sabidussi  g          the centrality index of a graph  psychometrika                 
salton  g     mcgill  m          introduction to modern information retrieval  vol    
mcgraw hill new york 
sarkar  p     moore  a          dynamic social network analysis using latent space
models  sigkdd explorations newsletter              
sarukkai  r  r          link prediction and path analysis using markov chains  in proceedings of the  th international world wide web conference on computer networks  the
international journal of computer and telecommunications networking  pp         
sarwar  b   karypis  g   konstan  j     riedl  j          application of dimensionality
reduction in recommender systema case study  in acm webkdd      web mining
for e commerce workshop 
schulte  o          a tractable pseudo likelihood function for bayes nets applied to relational
data  in sdm  pp         
schwarz  g          estimating the dimension of a model  the annals of statistics        
       
sen  p   namata  g   bilgic  m   getoor  l   galligher  b     eliassi rad  t          collective classification in network data  ai magazine             
shao  j          bootstrap model selection  journal of the american statistical association 
                 
shapiro  e          algorithmic program debugging  acm distinguished dissertation  
sharan  u     neville  j          temporal relational classifiers for prediction in evolving
domains  in proceedings of the  th ieee international conference on data mining 
pp         
shi  j     malik  j          normalized cuts and image segmentation  ieee transactions
on pattern analysis and machine intelligence                 
shi  x   li  y     yu  p          collective prediction with latent graphs  in proceedings
of the   th acm conference on information and knowledge management  pp      
     
singla  p     domingos  p          entity resolution with markov logic  in proceedings of
the  th ieee international conference on data mining  pp         
srinivasan  a          the aleph manual  computing laboratory  oxford university    
strehl  a     ghosh  j          cluster ensemblesa knowledge reuse framework for combining multiple partitions  journal of machine learning research            
   

firossi  mcdowell  aha    neville

tang  j   musolesi  m   mascolo  c     latora  v          temporal distance metrics for
social network analysis  in proceedings of the  nd acm workshop on online social
networks  pp       
tang  j   musolesi  m   mascolo  c   latora  v     nicosia  v          analysing information
flows and key mediators through temporal centrality metrics  in proceedings of the
 rd workshop on social network systems  pp     
tang  l     liu  h          relational learning via latent social dimensions  in proceedings
of the   th acm sigkdd international conference on knowledge discovery and
data mining  pp         
tang  l     liu  h          leveraging social media networks for classification  journal of
data mining and knowledge discovery             
taskar  b   abbeel  p     koller  d          discriminative probabilistic models for relational
data  in eighteenth conference on uncertainty in artificial intelligence  pp         
taskar  b   segal  e     koller  d          probabilistic classification and clustering in
relational data  in proceedings of the   th international joint conference on artificial
intelligence  pp         
taskar  b   wong  m   abbeel  p     koller  d          link prediction in relational data 
in advances in neural information processing systems 
topchy  a   law  m   jain  a     fred  a          analysis of consensus partition in cluster
ensemble  in proceedings of the  th ieee international conference on data mining 
pp         
vert  j     yamanishi  y          supervised graph inference  advances in neural information processing systems               
vishwanathan  s   schraudolph  n   kondor  r     borgwardt  k          graph kernels 
journal of machine learning research               
von luxburg  u          a tutorial on spectral clustering  statistics and computing         
       
wagner  a     fell  d          the small world inside large metabolic networks  proceedings
of the royal society of london  series b  biological sciences                       
wang  c   blei  d     heckerman  d          continuous time dynamic topic models  in
proceedings of uncertainty in artificial intelligence 
wang  x     mccallum  a          topics over time  a non markov continuous time model
of topical trends  in proceedings of the   th acm sigkdd international conference
on knowledge discovery and data mining  pp         
wang  z     chan  l          an efficient causal discovery algorithm for linear models 
in proceeding of the   th acm sigkdd international conference on knowledge
discovery and data mining  pp           
wasserman  s     faust  k          social network analysis  methods and applications 
cambridge university press 
   

fitransforming graph data for statistical relational learning

watts  d     strogatz  s          collective dynamics of small worldnetworks  nature 
                   
white  s     smyth  p          algorithms for estimating relative importance in networks 
in proceedings of the ninth acm sigkdd international conference on knowledge
discovery and data mining  pp         
wu  b     davison  b          identifying link farm spam pages  in special interest tracks
and posters of the   th international conference on world wide web  pp         
xiang  r   neville  j     rogati  m          modeling relationship strength in online social
networks  in proceedings of the   th international world wide web conference  pp 
       
yang  y     pedersen  j          a comparative study on feature selection in text categorization  in proceedings of the   th international conference on machine learning 
pp         
yin  x   han  j   yang  j     yu  p          crossmine  efficient classification across multiple
database relations  transactions on knowledge and data engineering                 
zheleva  e   getoor  l   golbeck  j     kuter  u          using friendship ties and family
circles for link prediction  in advances in social network mining and analysis  pp 
      
zheleva  e     getoor  l          preserving the privacy of sensitive relationships in graph
data  in pinkdd  pp         
zhou  b   pei  j     luk  w          a brief survey on anonymization techniques for privacy
preserving publishing of social network data  sigkdd explorations               
zhou  h          distance  dissimilarity index  and network community structure  physical
review e                
zhou  t   lu  l     zhang  y          predicting missing links via local information  the
european physical journal b condensed matter and complex systems             
    
zhu  s   yu  k   chi  y     gong  y          combining content and link for classification
using matrix factorization  in proceedings of the   th annual international acm
sigir conference on research and development in information retrieval  pp     
     acm 
zhu  x          semi supervised learning literature survey  computer science tech reports 
          

   

fi