journal of artificial intelligence research               

submitted        published      

complex question answering  unsupervised learning
approaches and experiments
yllias chali

chali cs uleth ca

university of lethbridge
lethbridge  ab  canada  t k  m 

shafiq r  joty

rjoty cs ubc ca

university of british columbia
vancouver  bc  canada  v t  z 

sadid a  hasan

hasan cs uleth ca

university of lethbridge
lethbridge  ab  canada  t k  m 

abstract
complex questions that require inferencing and synthesizing information from multiple
documents can be seen as a kind of topic oriented  informative multi document summarization where the goal is to produce a single text as a compressed version of a set of
documents with a minimum loss of relevant information  in this paper  we experiment
with one empirical method and two unsupervised statistical machine learning techniques 
k means and expectation maximization  em   for computing relative importance of the
sentences  we compare the results of these approaches  our experiments show that the
empirical approach outperforms the other two techniques and em performs better than
k means  however  the performance of these approaches depends entirely on the feature
set used and the weighting of these features  in order to measure the importance and
relevance to the user query we extract different kinds of features  i e  lexical  lexical semantic  cosine similarity  basic element  tree kernel based syntactic and shallow semantic 
for each of the document sentences  we use a local search technique to learn the weights
of the features  to the best of our knowledge  no study has used tree kernel functions
to encode syntactic semantic information for more complex tasks such as computing the
relatedness between the query sentences and the document sentences in order to generate
query focused summaries  or answers to complex questions   for each of our methods of
generating summaries  i e  empirical  k means and em  we show the effects of syntactic
and shallow semantic features over the bag of words  bow  features 

   introduction
the vast increase in the amount of online text available and the demand for access to different types of information have led to a renewed interest in a broad range of information
retrieval  ir  related areas that go beyond the simple document retrieval  these areas
include question answering  topic detection and tracking  summarization  multimedia retrieval  chemical and biological informatics  text structuring  text mining  genomics  etc 
automated question answering  qa the ability of a machine to answer questions  simple
or complex  posed in ordinary human languageis perhaps the most exciting technological development of the past six or seven years  strzalkowski   harabagiu         the
c
    
ai access foundation  all rights reserved 

fichali  joty    hasan

expectations are already tremendous  reaching beyond the discipline  a subfield of natural
language processing  nlp   itself 
as a tool for finding documents on the web  search engines are proven to be adequate 
although there is no limitation in the expressiveness of the user in terms of query formulation  certain limitations exist in what the search engine does with the query  complex
question answering tasks require multi document summarization through an aggregated
search  or a faceted search  that represents an information need which cannot be answered
by a single document  for example  if we look for the comparison of the average number of
years between marriage and first birth for women in the u s   asia  and europe  the answer
is likely contained in multiple documents  multi document summarization is useful for this
type of query and there is currently no tool on the market that is designed to meet this
kind of information need 
qa research attempts to deal with a wide range of question types including  fact  list 
definition  how  why  hypothetical  semantically constrained  and cross lingual questions 
some questions  which we will call simple questions  are easier to answer  for example  the
question  who is the president of bangladesh  asks for a persons name  this type of
question  i e  factoid  requires small snippets of text as the answer  again  the question 
which countries has pope john paul ii visited  is a sample of a list question  asking only
for a list of small snippets of text 
after having made substantial headway in factoid and list questions  researchers have
turned their attention to more complex information needs that cannot be answered by
simply extracting named entities  persons  organizations  locations  dates  etc   from documents  unlike informationally simple factoid questions  complex questions often seek multiple different types of information simultaneously and do not presuppose that one single
answer can meet all of its information needs  for example  with a factoid question like 
how accurate are hiv tests  it can be safely assumed that the submitter of the question is looking for a number or a range of numbers  however  with complex questions like 
what are the causes of aids  the wider focus of this question suggests that the submitter
may not have a single or well defined information need and therefore may be amenable to
receiving additional supporting information that is relevant to some  as yet  undefined informational goal  harabagiu  lacatusu    hickl         these questions require inferencing
and synthesizing information from multiple documents 
a well known qa systems is the korean navers knowledge in search    who were the
pioneers in community qa  this tool allows users to ask just about any question and get
answers from other users  navers knowledge in now has roughly    times more entries
than wikipedia  it is used by millions of korean web users on any given day  some people
say koreans are not addicted to the internet but to naver  as of january      the knowledge search database included more than    million pages of user generated information 
another popular answer service is yahoo  answers which is a community driven knowledge market website launched by yahoo   it allows users to both submit questions to be
answered and answer questions from other users  people vote on the best answer  the site
gives members the chance to earn points as a way to encourage participation and is based
on the naver model  as of december       yahoo  answers had    million users and   
   http   kin naver com 

 

ficomplex question answering  unsupervised approaches

million answers  google had a qa system  based on paid editors which was launched in
april      and fully closed in december      
however  from a computational linguistics point of view information synthesis can be
seen as a kind of topic oriented informative multi document summarization  the goal is to
produce a single text as a compressed version of a set of documents with a minimum loss
of relevant information  unlike indicative summaries  which help to determine whether a
document is relevant to a particular topic   informative summaries must attempt to find
answers 
in this paper  we focus on an extractive approach of summarization where a subset of
the sentences in the original documents are chosen  this contrasts with abstractive summarization where the information in the text is rephrased  although summaries produced by
humans are typically not extractive  most of the state of the art summarization systems are
based on extraction and they achieve better results than the automated abstraction  here 
we experimented with one empirical and two well known unsupervised statistical machine
learning techniques  k means and em and evaluated their performance in generating topicoriented summaries  however  the performance of these approaches depends entirely on the
feature set used and the weighting of these features  in order to measure the importance
and relevance to the user query we extract different kinds of features  i e  lexical  lexical
semantic  cosine similarity  basic element  tree kernel based syntactic and shallow semantic 
for each of the document sentences  we have used a gradient descent local search technique
to learn the weights of the features 
traditionally  information extraction techniques are based on the bow approach augmented by language modeling  but when the task requires the use of more complex semantics  the approaches based on only bow are often inadequate to perform fine level textual
analysis  some improvements on bow are given by the use of dependency trees and syntactic parse trees  hirao    suzuki  isozaki    maeda        punyakanok  roth    yih       
zhang   lee      b   but these too are not adequate when dealing with complex questions
whose answers are expressed by long and articulated sentences or even paragraphs  shallow
semantic representations  bearing more compact information  could prevent the sparseness
of deep structural approaches and the weakness of bow models  moschitti  quarteroni 
basili    manandhar         as pinpointing the answer to a question relies on a deep understanding of the semantics of both  attempting an application of syntactic and semantic
information to complex qa seems natural  to the best of our knowledge  no study has used
tree kernel functions to encode syntactic semantic information for more complex tasks such
as computing the relatedness between the query sentences and the document sentences in
order to generate query focused summaries  or answers to complex questions   for all of
our methods of generating summaries  i e  empirical  k means and em  we show the effects
of syntactic and shallow semantic features over the bow features 
over the past three years  complex questions have been the focus of much attention in
both the automatic question answering and multi document summarization  mds  communities  typically  most current complex qa evaluations including the      aquaint
relationship qa pilot  the      text retrieval conference  trec  relationship qa task 
and the trec definition  and others  require systems to return unstructured lists of can   http   answers google com 

 

fichali  joty    hasan

didate answers in response to a complex question  however recently  mds evaluations  including the            and      document understanding conference  duc   have tasked
systems with returning paragraph length answers to complex questions that are responsive 
relevant  and coherent 
our experiments based on the duc      data show that including syntactic and semantic features improves the performance  comparison among the approaches are also shown 
comparing with duc      participants  our systems achieve top scores and there is no
statistically significant difference between the results of our system and the results of duc
     best system 
this paper is organized as follows  section   focuses on the related work  section  
gives a brief description of our intended final model  section   describes how the features
are extracted  section   discusses the learning issues and presents our learning approaches 
section   discusses how we remove the redundant sentences before adding them to the final
summary  and section   describes our experimental study  we conclude and discuss future
directions in section   

   related work
researchers all over the world working on query based summarization are trying different
directions to see which methods provide the best results 
there are a number of sentence retrieval systems based on ir  information retrieval 
techniques  these systems typically dont use a lot of linguistic information  but they still
deserve special attention  murdock and croft        propose a translation model specifically
for monolingual data  and show that it significantly improves sentence retrieval over query
likelihood  translation models train on a parallel corpus and they used a corpus of question answer pairs  losada        presents a comparison between multiple bernoulli models
and multinomial models in the context of a sentence retrieval task and shows that a multivariate bernoulli model can really outperform popular multinomial models for retrieving
relevant sentences  losada and fernandez        propose a novel sentence retrieval method
based on extracting highly frequent terms from top retrieved documents  their results reinforce the idea that top retrieved data is a valuable source to enhance retrieval systems 
this is specially true for short queries because there are usually few query sentence matching terms  they argue that this method improves significantly the precision at top ranks
when handling poorly specified information needs 
the lexrank method addressed by erkan and radev        was very successful in
generic multi document summarization  a topic sensitive lexrank is proposed by otterbacher  erkan  and radev         as in lexrank  the set of sentences in a document cluster
is represented as a graph where nodes are sentences  and links between the nodes are induced by a similarity relation between the sentences  the system then ranks the sentences
according to a random walk model defined in terms of both the inter sentence similarities
and the similarities of the sentences to the topic description or question 
concepts of coherence and cohesion enable us to capture the theme of the text  coherence represents the overall structure of a multi sentence text in terms of macro level
relations between clauses or sentences  halliday   hasan         cohesion  as defined by
halliday and hasan         is the property of holding text together as one single grammat 

ficomplex question answering  unsupervised approaches

ical unit based on relations  i e  ellipsis  conjunction  substitution  reference  and lexical
cohesion  between various elements of the text  lexical cohesion is defined as the cohesion
that arises from the semantic relations  collocation  repetition  synonym  hypernym  hyponym  holonym  meronym  etc   between the words in the text  morris   hirst        
lexical cohesion among words are represented by lexical chains which are the sequences of
semantically related words  the summarization methods based on lexical chain first extract the nouns  compound nouns and named entities as candidate words  li  sun  kit   
webster         then using wordnet  the systems find the semantic similarity between
the nouns and compound nouns  after that lexical chains are built in two steps 
   building single document strong chains while disambiguating the senses of the words 
   building a multi chain by merging the strongest chains of the single documents into
one chain 
the systems rank sentences using a formula that involves a  the lexical chain  b  keywords from the query and c  named entities  for example  li et al         uses the following
formula 
score   p  chain    p  query    p  namedentity 
where p  chain  is the sum of the scores of the chains whose words come from the
candidate sentence  p  query  is the sum of the co occurrences of key words in a topic and
the sentence  and p  namedentity  is the number of name entities existing in both the topic
and the sentence  the three coefficients    and  are set empirically  the top ranked
sentences are then selected to form the summary 
harabagiu et al         introduce a new paradigm for processing complex questions
that relies on a combination of  a  question decompositions   b  factoid qa techniques 
and  c  multi document summarization  mds  techniques  the question decomposition
procedure operates on a markov chain  that is  by following a random walk with a mixture
model on a bipartite graph of relations established between concepts related to the topic
of a complex question and subquestions derived from topic relevant passages that manifest
these relations  decomposed questions are then submitted to a state of the art qa system
in order to retrieve a set of passages that can later be merged into a comprehensive answer by a mds system  they show that question decompositions using this method can
significantly enhance the relevance and comprehensiveness of summary length answers to
complex questions 
there are approaches that are based on probabilistic models  pingali  k     varma 
      toutanova  brockett  gamon  jagarlamudi  suzuki    vanderwende         pingali
et al         rank the sentences based on a mixture model where each component of the
model is a statistical model 
score s      qiscore s           qf ocus s  q 

   

   wordnet  http   wordnet princeton edu   is a widely used semantic lexicon for the english language 
it groups english words  i e  nouns  verbs  adjectives and adverbs  into sets of synonyms called synsets 
provides short  general definitions  i e  gloss definition   and records the various semantic relations
between these synonym sets 

 

fichali  joty    hasan

where score s  is the score for sentence s  query independent score  qiscore  and
query dependent score  qfocus  are calculated based on probabilistic models  toutanova
et al         learns a log linear sentence ranking model by maximizing three metrics of
sentence goodness   a  rouge oracle   b  pyramid derived  and  c  model frequency 
the scoring function is learned by fitting weights for a set of feature functions of sentences
in the document set and is trained to optimize a sentence pair wise ranking criterion  the
scoring function is further adapted to apply to summaries rather than sentences and to take
into account redundancy among sentences 
pingali et al         reduce the document sentences by dropping words that do not
contain any important information  toutanova et al          vanderwende  suzuki  and
brockett         and zajic  lin  dorr  and schwartz        heuristically decompose the
document sentences into smaller units  they apply a small set of heuristics to a parse
tree to create alternatives after which both the original sentence and  possibly multiple 
simplified versions are available for selection 
there are approaches in multi document summarization that do try to cluster sentences
together  guo and stylios        use verb arguments  i e  subjects  times  locations and
actions  for clustering  for each sentence this method establishes the indices information
based on the verb arguments  subject is first index  time is second  location is third and
action is fourth   all the sentences that have the same or closest subjects index are put
in a cluster and they are sorted out according to the temporal sequence from the earliest
to the latest  sentences that have the same spaces locations index value in the cluster
are then marked out  the clusters are ranked based on their sizes and top    clusters are
chosen  then  applying a cluster reduction module the system generates the compressed
extract summaries 
there are approaches in recognizing textual entailment  sentence alignment  and
question answering that use syntactic and or semantic information in order to measure
the similarity between two textual units  this indeed motivated us to include syntactic and
semantic features to get the structural similarity between a document sentence and a query
sentence  discussed in section       maccartney  grenager  de marneffe  cer  and manning
       use typed dependency graphs  same as dependency trees  to represent the text and
the hypothesis  they try to find a good partial alignment between the typed dependency
graphs representing the hypothesis  contains n nodes  and the text  graph contains m
nodes  in a search space of o  m     n   they use an incremental beam search combined
with a node ordering heuristic to do approximate global search in the space of possible
alignments  a locally decomposable scoring function was chosen such that the score of an
alignment is the sum of the local node and edge alignment scores  the scoring measure
is designed to favor alignments which align semantically similar subgraphs  irrespective of
polarity  for this reason  nodes receive high alignment scores when the words they represent
are semantically similar  synonyms and antonyms receive the highest score and unrelated
words receive the lowest  alignment scores also incorporate local edge scores which are based
on the shape of the paths between nodes in the text graph which correspond to adjacent
nodes in the hypothesis graph  in the final step they make a decision about whether or
not the hypothesis is entailed by the text conditioned on the typed dependency graphs as
well as the best alignment between them  to make this decision they use a supervised
 

ficomplex question answering  unsupervised approaches

statistical logistic regression classifier  with a feature space of    features  with a gaussian
prior parameter for regularization 
hirao et al         represent the sentences using dependency tree path  dtp  to incorporate syntactic information  they apply string subsequence kernel  ssk  to measure
the similarity between the dtps of two sentences  they also introduce extended string
subsequence kernel  esk  to incorporate semantics in dtps  kouylekov and magnini
       use the tree edit distance algorithms on the dependency trees of the text and the
hypothesis to recognize the textual entailment  according to this approach  a text t entails
a hypothesis h if there exists a sequence of transformations  i e  deletion  insertion and
substitution  applied to t such that we can obtain h with an overall cost below a certain
threshold  punyakanok et al         represent the question and the sentence containing
answer with their dependency trees  they add semantic information  i e  named entity 
synonyms and other related words  in the dependency trees  they apply the approximate
tree matching in order to decide how similar any given pair of trees are  they also use the
edit distance as the matching criteria in the approximate tree matching  all these methods
show the improvement over the bow scoring methods 

   our approach
to accomplish the task of answering complex questions we extract various important features for each of the sentences in the document collection to measure its relevance to the
query  the sentences in the document collection are analyzed in various levels and each
of the document sentences is represented as a vector of feature values  our feature set
includes lexical  lexical semantic  statistical similarity  syntactic and semantic features  and
graph based similarity measures  chali   joty      b   we reimplemented many of these
features which are successfully applied to many related fields of nlp 
we use a simple local search technique to fine tune the feature weights  we also use
the statistical clustering algorithms  em and k means to select the relevant sentences for
summary generation  experimental results show that our systems perform better when
we include the tree kernel based syntactic and semantic features though summaries based
on only syntactic or semantic feature do not achieve good results  graph based cosine
similarity and lexical semantic features are also important for selecting relevant sentences 
we find that the local search technique outperforms the other two and the em performs
better than the k means based learning  in the later sections we describe all the subparts
of our systems in details 

   feature extraction
in this section  we will describe the features that will be used to score the sentences  we
provide detailed examples  to show how we get the feature values  we will first describe
the syntactic and semantic features that we are introducing in this work  we follow with
a detailed description of the features more commonly used in the question answering and
summarization communities 
   all the query and document sentences used in the examples are taken from the duc      collection 

 

fichali  joty    hasan

    syntactic and shallow semantic features
for the task like query based summarization that requires the use of more complex syntactic
and semantics  the approaches with only bow are often inadequate to perform fine level
textual analysis  the importance of syntactic and semantic features in this context is
described by zhang and lee      a   moschitti et al          bloehdorn and moschitti
     a   moschitti and basili        and bloehdorn and moschitti      b  
an effective way to integrate syntactic and semantic structures in machine learning algorithms is the use of tree kernel functions  collins   duffy        moschitti   quarteroni 
      which has been successfully applied to question classification  zhang   lee      a 
moschitti   basili         syntactic and semantic information are used effectively to measure the similarity between two textual units by maccartney et al          to the best
of our knowledge  no study has used tree kernel functions to encode syntactic semantic
information for more complex tasks such as computing the relatedness between the query
sentences and the document sentences  another good way to encode some shallow syntactic
information is the use of basic elements  be   hovy  lin  zhou    fukumoto        which
uses dependency relations  our experiments show that including syntactic and semantic
features improves the performance on the sentence selection for complex question answering
task  chali   joty      a  
      encoding syntactic structures
basic element  be  overlap measure shallow syntactic information based on dependency relations was proved to be effective in finding similarity between two textual
units  hirao et al          we incorporate this information by using basic elements that
are defined as follows  hovy et al         
 the head of a major syntactic constituent  noun  verb  adjective or adverbial phrases  
expressed as a single item 
 a relation between a head be and a single dependent  expressed as a triple 
 head modifier relation  
the triples encode some syntactic information and one can decide whether any two units
match or not  more easily than with longer units  hovy et al          we extracted bes for
the sentences  or query  by using the be package distributed by isi   
once we get the bes for a sentence  we computed the likelihood ratio  lr  for each be
following zhou  lin  and hovy         sorting bes according to their lr scores produced
a be ranked list  our goal is to generate a summary that will answer the users questions 
the ranked list of bes in this way contains important bes at the top which may or may not
be relevant to the users questions  we filter those bes by checking whether they contain
any word which is a query word or a queryrelatedwords  defined in section       for
example  if we consider the following sentence we get the be score of         
query  describe steps taken and worldwide reaction prior to introduction of the euro on
january          include predictions and expectations reported in the press 
   be website http   www isi edu  cyl be

 

ficomplex question answering  unsupervised approaches

sentence  the frankfurt based body said in its annual report released today that it has
decided on two themes for the new currency  history of european civilization and
abstract or concrete paintings 
be score         
here  the be decided themes obj is not considered as it does not contain any word
from the query words or query relevant words but be report annual mod is taken as it
contains a query word report  in this way  we filter out the bes that are not related to
the query  the score of a sentence is the sum of its be scores divided by the number of bes
in the sentence  by limiting the number of the top bes that contribute to the calculation
of the sentence scores we can remove the bes with little importance and the sentences with
fewer important bes  if we set the threshold to     only the topmost     bes in the ranked
list can contribute to the normalized sentence be score computation  in this paper  we did
not set any threshold we took all the bes counted when calculating the be scores for the
sentences 
tree kernels approach in order to calculate the syntactic similarity between the query
and the sentence we first parse the sentence as well as the query into a syntactic tree
 moschitti        using a parser like charniak         then we calculate the similarity
between the two trees using the tree kernel  we reimplemented the tree kernel model as
proposed by moschitti et al         
once we build the trees  our next task is to measure the similarity between the trees  for
this  every tree t is represented by an m dimensional vector v t      v   t    v   t       vm  t    
where the i th element vi  t   is the number of occurrences of the i th tree fragment in tree
t   the tree fragments of a tree are all of its sub trees which include at least one production
with the restriction that no production rules can be broken into incomplete parts  moschitti
et al          figure   shows an example tree and a portion of its subtrees 

figure     a  an example tree  b  the sub trees of the np covering the press 
implicitly we enumerate all the possible tree fragments            m  these fragments are
the axis of this m dimensional space  note that this could be done only implicitly since
the number m is extremely large  because of this  collins and duffy        define the tree
kernel algorithm whose computational complexity does not depend on m 
the tree kernel of two trees t  and t  is actually the inner product of v t    and v t    
 

fichali  joty    hasan

t k t    t      v t    v t   

   

we define the indicator function ii  n  to be   if the sub tree i is seen rooted at node n
and   otherwise  it follows 

vi  t     

x

x

ii  n     vi  t     

n  n 

ii  n   

   

n  n 

where n  and n  are the set of nodes in t  and t  respectively  so  we can derive 
t k t    t      v t    v t     

x

vi  t   vi  t   

i

x

 

x x

n  n  n  n 

x

 

x

ii  n   ii  n   

i

c n    n   

   

n  n  n  n 

where we define c n    n      i ii  n   ii  n     next  we note that c n    n    can be
computed in polynomial time due to the following recursive definition 
p

   if the productions at n  and n  are different then c n    n       
   if the productions at n  and n  are the same  and n  and n  are pre terminals  then
c n    n       
   else if the productions at n  and n  are not pre terminals 
nc n   

c n    n     

y

     c ch n    j   ch n    j   

   

j  

where nc n    is the number of children of n  in the tree  because the productions at n 
and n  are the same we have nc n      nc n     the i th child node of n  is ch n    i  
in cases where the query is composed of two or more sentences we compute the similarity
between the document sentence  s  and each of the query sentences  qi   then we take the
average of the scores as the syntactic feature value 
syntactic similarity value  

pn

i   t k qi   s 

n

where n is the number of sentences in the query q and s is the sentence under consideration  tk is the similarity value  tree kernel  between the sentence s and the query
sentence q based on the syntactic structure  for example  for the following sentence s and
query q we get the score 
  

ficomplex question answering  unsupervised approaches

figure    example of semantic trees
query  q   describe steps taken and worldwide reaction prior to introduction of the euro
on january          include predictions and expectations reported in the press 
sentence  s   europes new currency  the euro  will rival the u s  dollar as an international
currency over the long term  der spiegel magazine reported sunday 
scores        
average score      
      semantic features
though introducing syntactic information gives an improvement on bow  by the use of
syntactic parses  this too is not adequate when dealing with complex questions whose answers are expressed by long and articulated sentences or even paragraphs  shallow semantic
representations  bearing more compact information  could prevent the sparseness of deep
structural approaches and the weakness of bow models  maccartney et al         moschitti
et al         
initiatives such as propbank  pb   kingsbury   palmer        have made the design of
accurate automatic semantic role labeling  srl  systems like assert  hacioglu  pradhan  ward  martin    jurafsky        possible  hence  attempting an application of srl
to qa seems natural as pinpointing the answer to a question relies on a deep understanding
of the semantics of both  for example  consider the pb annotation 
 arg  all  target use  arg  the french franc  arg  as their currency 
such annotation can be used to design a shallow semantic representation that can be
matched against other semantically similar sentences  e g 
 arg  the vatican  target use  arg  the italian lira  arg  as their currency 
in order to calculate the semantic similarity between the sentences we first represent the
annotated sentence  or query  using the tree structures like figure   called semantic tree
 st  as proposed by moschitti et al          in the semantic tree arguments are replaced
with the most important wordoften referred to as the semantic head  we look for a noun
first  then a verb  then an adjective  then adverb to find the semantic head in the argument 
if none of these is present we take the first word of the argument as the semantic head 
  

fichali  joty    hasan

figure    two sts composing a stn
however  sentences rarely contain a single predicate  rather typically propositions contain one or more subordinate clauses  for instance  let us consider a slight modification of
the second sentence  the vatican  located wholly within italy uses the italian lira as their
currency  here  the main predicate is uses and the subordinate predicate is located 
the srl system outputs the following two annotations 
     arg  the vatican located wholly within italy  target uses  arg  the italian
lira  arg  as their currency 
     arg  the vatican  target located   argm loc wholly  argm loc within
italy  uses the italian lira as their currency
giving the sts in figure    as we can see in figure   a   when an argument node
corresponds to an entire subordinate clause we label its leaf with st  e g  the leaf of
arg    such st node is actually the root of the subordinate clause in figure   b   if
taken separately  such sts do not express the whole meaning of the sentence  hence  it
is more accurate to define a single structure encoding the dependency between the two
predicates as in figure   c   we refer to this kind of nested sts as stns 
note that the tree kernel  tk  function defined in section       computes the number of
common subtrees between two trees  such subtrees are subject to the constraint that their
nodes are taken with all or none of the children they have in the original tree  though this
definition of subtrees makes the tk function appropriate for syntactic trees  it is not well
suited for the semantic trees  st   for instance  although the two sts of figure   share
most of the subtrees rooted in the st node  the kernel defined above computes no match 
the critical aspect of steps           and     of the tk function is that the productions
of two evaluated nodes have to be identical to allow the match of further descendants  this
means that common substructures cannot be composed by a node with only some of its
children as an effective st representation would require  moschitti et al         solve this
problem by designing the shallow semantic tree kernel  sstk  which allows portions of
an st to match 
shallow semantic tree kernel  sstk  we reimplemented the sstk according to
the model given by moschitti et al          the sstk is based on two ideas  first  it changes
  

ficomplex question answering  unsupervised approaches

the st  as shown in figure   by adding slot nodes  these accommodate argument labels
in a specific order with a fixed number of slots  possibly filled with null arguments that
encode all possible predicate arguments  leaf nodes are filled with the wildcard character  
but they may alternatively accommodate additional information  the slot nodes are used
in such a way that the adopted tk function can generate fragments containing one or more
children like for example those shown in frames  b  and  c  of figure    as previously
pointed out  if the arguments were directly attached to the root node the kernel function
would only generate the structure with all children  or the structure with no children  i e 
empty   moschitti et al         

figure    semantic tree with some of its fragments
second  as the original tree kernel would generate many matches with slots filled with
the null label we have set a new step   in the tk calculation 
    if n   or n    is a pre terminal node and its child label is null  c n    n        
and subtract one unit to c n    n     in step   
nc n   

    c n    n     

y

j  

     c ch n    j   ch n    j      

   

the above changes generate a new c which  when substituted  in place of original c  
in eq     gives the new sstk 
for example  for the following sentence s and query q we get the semantic score 
query  q   describe steps taken and worldwide reaction prior to introduction of the euro
on january          include predictions and expectations reported in the press 
sentence  s   the frankfurt based body said in its annual report released today that it
has decided on two themes for the new currency history of european civilization and
abstract or concrete paintings 
scores       
average score   
  

fichali  joty    hasan

    lexical features
here  we will discuss the lexical features that are most commonly used in the qa and
summarization communities  we reimplemented all of them in this research 
      n gram overlap
n gram overlap measures the overlapping word sequences between the candidate document
sentence and the query sentence  with the view to measure the overlap scores  a query pool
and a sentence pool are created  in order to create the query  or sentence  pool  we took
the query  or document  sentence and created a set of related sentences by replacing its
content words  by their first sense synonyms using wordnet  for example  given a stemmed
document sentence  john write a poem  the sentence pool contains  john compose a
poem  john write a verse form along with the given sentence 
we measured the recall based n gram scores for a sentence p using the following formula 
n gramscore p     maxi  maxj n gram si   qj   
p
gram s countmatch  gramn  
n gram s  q    p n
gramn s count  gramn  

   
   

where n stands for the length of the n gram  n                and countmatch  gramn   is
the number of n grams co occurring in the query and the candidate sentence  qj is the j th
sentence in the query pool  and si is the i th sentence in the sentence pool of sentence p  
  gram overlap measure
a   gram overlap score measures the number of words common in the sentence in hand
and the query related words  this can be computed as follows 
 gram overlap score  

p

countmatch  w   
w  s count  w   

w  s

p

   

where s is the set of content words in the candidate sentence and countmatch is the
number of matches between the sentence content words and query related words  count  gramn  
is the number of w   
note that in order to measure the   gram score we took the query related words instead
of the exact query words  the motivation behind this is the sentence which has word s 
that are not exactly the query words but their synonyms  hypernyms  hyponym or gloss
words  will get counted 
example 
query describe steps taken and worldwide reaction prior to introduction of the euro on
january          include predictions and expectations reported in the press 
sentence the frankfurt based body said in its annual study released today that it has
decided on two themes for the new currency  history of european civilization and
abstract or concrete paintings 
   hence forth content words are the nouns  verbs  adverbs and adjectives 

  

ficomplex question answering  unsupervised approaches

  gram score          after normalization    
note that the above sentence has a   gram overlap score of         even though it has
no exact word common with the query words  it got this score because the sentence word
study is a synonym of the query word report 
other n gram overlap measures
as above  we can calculate the other n gram overlap scores  for example  considering
the following query sentence and document sentence  from duc      collection   we have  
matching   grams          of euro  on january and january     hence  employing
the formula given above  we get the following   gram score after normalization    gram score
is also found accordingly 
query sentence  describe steps taken and worldwide reaction prior to introduction of
the euro on january          include predictions and expectations reported in the
press 
document sentence  despite skepticism about the actual realization of a single european currency as scheduled on january          preparations for the design of the
euro note have already begun 
  gram         
  gram        
      lcs and wlcs
a sequence w    w    w         wn   is a subsequence of another sequence x    x    x         xm    
if there exists a strict increasing sequence  i    i         in   of indices of x such that for all
j              n we have xij   wj  cormen  leiserson    rivest         given two sequences
s  and s    the longest common subsequence  lcs  of s  and s  is a common subsequence
with maximum length  lin        
the longer the lcs of two sentences is  the more similar the two sentences are  we
used lcs based f measure to estimate the similarity between the document sentence s of
length m and the query sentence q of length n as follows 
lcs s  q 
m
lcs s  q 
plcs  s  q   
n
flcs  s  q           plcs  s  q      rlcs  s  q 
rlcs  s  q   

    
    
    

where lcs s  q  is the length of a longest common subsequence of s and q  and  is
a constant that determines the importance of precision and recall  while computing the
lcs measure each document sentence and query sentence are viewed as a sequence of words 
   we normalize each of the feature values corresponding to a sentence with respect to the entire context
of a particular document 

  

fichali  joty    hasan

the intuition is that the longer the lcs of these two is the more similar they are  here
the recall  rlcs  s  q   is the ratio of the length of the longest common subsequence of s and
q to the document sentence length that measures the completeness  whereas the precision
 plcs  s  q   is the ratio of the length of the longest common subsequence of s and q to the
query sentence length which is a measure of exactness  to obtain the equal importance
to precision and recall we set the value of  as      equation    is called the lcs based
f measure  notice that flcs is   when  s q  and flcs is   when there is nothing in
common between s and q 
one advantage of using lcs is that it does not require consecutive matches but insequence matches that reflect sentence level word order as n grams  the other advantage is
that it automatically includes longest in sequence common n grams  therefore  no predefined n gram length is necessary  moreover  it has the property that its value is less than or
equal to the minimum of the unigram  i e    gram  f measure of s and q  unigram recall
reflects the proportion of words in s that are also present in q  while unigram precision
is the proportion of words in q that are also in s  unigram recall and precision count all
co occurring words regardless of their orders  while lcs counts in sequence co occurrences 
by only awarding credit to in sequence unigram matches  lcs measure also captures
sentence level structure in a natural way  consider the following example 
s  john shot the thief
s  john shot the thief
s  the thief shot john
using s  as reference sentence  and s  and s  as the sentences under consideration s 
and s  would have the same   gram score since they both have one bigram  i e  the thief 
in common with s   however  s  and s  have very different meanings  in case of lcs s 
has a score of          and s  has a score of         with         therefore  s  is better
than s  according to lcs 
however  lcs suffers one disadvantage in that it only counts the main in sequence
words  therefore  other alternative lcses and shorter sequences are not reflected in the
final score  for example  given the following candidate sentence 
s  the thief john shot
using s  as its reference  lcs counts either the thief or john shot but not both 
therefore  s  has the same lcs score as s  while   gram would prefer s  over s  
in order to measure the lcs score for a sentence we took a similar approach as the previous section using wordnet  i e  creation of sentence pool and query pool   we calculated
the lcs score using the following formula 

lcs score   maxi  maxj flcs  si   qj   

    

where qj is the j th sentence in the query pool  and si is the i th sentence in the
sentence pool 
  

ficomplex question answering  unsupervised approaches

the basic lcs has a problem in that it does not differentiate lcses of different spatial
relations within their embedding sequences  lin         for example  given a reference
sequence s and two candidate sequences y  and y  as follows 
s  a b c d e f g
y    a b c d h i k
y    a h b k c i d
y  and y  have the same lcs score  however  y  should be better choice than y  because
y  has consecutive matches  to improve the basic lcs method we can store the length of
consecutive matches encountered so far to a regular two dimensional dynamic program table
computing lcs  we call it weighted lcs  wlcs  and use k to indicate the length of the
current consecutive matches ending at words xi and yj   given two sentences x and y 
the wlcs score of x and y can be computed using the similar dynamic programming
procedure as stated by lin         we use wlcs as it has the advantage of not measuring
the similarity by taking the words in a higher dimension like string kernels which indeed
reduces the time complexity  as before  we computed the wlcs based f measure in the
same way using both the query pool and the sentence pool 
w lcs score   maxi  maxj fwlcs  si   qj   

    

example 
query sentence  describe steps taken and worldwide reaction prior to introduction of
the euro on january          include predictions and expectations reported in the
press 
document sentence  despite skepticism about the actual realization of a single european currency as scheduled on january          preparations for the design of the
euro note have already begun 
we find   matching strings   of on   euro      january  in the longest common
subsequence considering this sentence and related sentences  for wlcs we set the
weight as      after normalization  we get the following lcs and wlcs scores for
the sentence applying the above formula 
lcs score         
wlcs score         
      skip bigram measure
a skip bigram is any pair of words in their sentence order allowing for arbitrary gaps  skipbigram measures the overlap of skip bigrams between a candidate sentence and a query
sentence  lin         we rely on the query pool and the sentence pool as before using
wordnet  considering the following sentences 
  

fichali  joty    hasan

s  john shot the thief
s  john shoot the thief
s  the thief shoot john
s  the thief john shot
we get that each sentence has c        skip bigrams    for example  s  has the following
skip bigrams   john shot  john the  john thief  shot the  shot thief and the
thief  s  has three skip bi gram matches with s   john the  john thief  the thief  
s  has one skip bi gram match with s   the thief   and s  has two skip bi gram matches
with s   john shot  the thief  
the skip bi gram score between the document sentence s of length m and the query
sentence q of length n can be computed as follows 
skip   s  q 
c m    
skip   s  q 
pskip   s  q   
c n    
fskip   s  q           pskip   s  q      rskip   s  q 
rskip   s  q   

    
    
    

where skip   s  q  is the number of skip bi gram matches between s and q  and
 is a constant that determines the importance of precision and recall  we set the value
of  as     to associate the equal importance to precision and recall  c is the combination
function  we call the equation    the skip bigram based f measure  we computed the skip
bigram based f measure using the formula 

skip bigram   maxi  maxj fskip   si   qj   

    

for example  given the following query and the sentence  we get   skip bigrams   on   
january    january       of euro          on       on january and of on  
applying the equations above  we get skip bi gram score of         after normalization 
query describe steps taken and worldwide reaction prior to introduction of the euro on
january          include predictions and expectations reported in the press 
sentence despite skepticism about the actual realization of a single european currency
as scheduled on january          preparations for the design of the euro note have
already begun 
skip bi gram score         
   c n  r   

n 
r  nr  

  

ficomplex question answering  unsupervised approaches

note that skip bi gram counts all in order matching word pairs while lcs only counts
one longest common subsequence  we can put the constraint on the maximum skip distance 
dskip   between two in order words to form a skip bi gram which avoids the spurious matches
like the the or of from  for example  if we set dskip to   then it is equivalent to bi gram
overlap measure  lin         if we set dskip to   then only word pairs of at most   words
apart can form skip bi grams  in our experiment we set dskip     in order to ponder at
most   words apart to get the skip bi grams 
modifying the equations          and    to allow the maximum skip distance limit is
straightforward  following lin        we count the skip bi gram matches  skip   s  q  
within the maximum skip distance and replace the denominators of the equations with
the actual numbers of within distance skip bi grams from the reference sentence and the
candidate sentence respectively 
      head and head related words overlap
the number of head words common in between two sentences can indicate how much they
are relevant to each other  in order to extract the heads from the sentence  or query   the
sentence  or query  is parsed by minipar  and from the dependency tree we extract the
heads which we call exact head words  for example  the head word of the sentence  john
eats rice is eat 
we take the synonyms  hyponyms  and hypernyms   of both the query head words and
the sentence head words and form a set of words which we call head related words  we
measured the exact head score and the head related score as follows 
p

w  headset countmatch  w   

    

w  headrelset countmatch  w   

    

exactheadscore  
headrelatedscore  

p

p

p

w  headset count  w   

w  headrelset count  w   

where headset is the set of head words in the sentence and countmatch is the number
of matches between the headset of the query and the sentence  headrelset is the set of
synonyms  hyponyms  and hypernyms of head words in the sentence and countmatch is
the number of matches between the head related words of the query and the sentence  for
example  below we list the head words for a query and a sentence and their measures 
query  describe steps taken and worldwide reaction prior to introduction of the euro on
january          include predictions and expectations reported in the press 
heads for query  include  reaction  step  take  describe  report  euro  introduction  press 
prediction        expectation
sentence  the frankfurt based body said in its annual report released today that it has
decided on two themes for the new currency  history of european civilization and
abstract or concrete paintings 
   http   www cs ualberta ca  lindek minipar htm
    hypernym and hyponym levels are restricted to   and   respectively 

  

fichali  joty    hasan

heads for sentence  history  release  currency  body  report painting  say  civilization 
theme  decide 
exact head score 

 
  

      

head related score   
    lexical semantic features
we form a set of words which we call queryrelatedwords by taking the content words from
the query  their first sense synonyms  the nouns hypernyms hyponyms  and the nouns
gloss definitions using wordnet 
      synonym overlap
the synonym overlap measure is the overlap between the list of synonyms of the content
words extracted from the candidate sentence and query related words  this can be computed
as follows 
synonym overlap score  

p

w  synset countmatch  w   
w  synset count  w   

p

    

where synset is the synonym set of the content words in the sentence and countmatch is
the number of matches between the synset and query related words 
      hypernym hyponym overlap
the hypernym hyponym overlap measure is the overlap between the list of hypernyms  level
   and hyponyms  level    of the nouns extracted from the sentence in consideration and
query related words  this can be computed as follows 
hypernym hyponym overlap score  

p

h  hypset countmatch  h   
h  hypset count  h   

p

    

where hypset is the hyponym hyponym set of the nouns in the sentence and countmatch is
the number of matches between the hypset and query related words 
      gloss overlap
the gloss overlap measure is the overlap between the list of content words that are extracted
from the gloss definition of the nouns in the sentence in consideration and query related
words  this can be computed as follows 
gloss overlap score  

p

g  glossset countmatch  g   

p

g  glossset count  g   

    

where glossset is the set of content words  i e  nouns  verbs and adjectives  taken from
the gloss definition of the nouns in the sentence and countmatch is the number of matches
between the glossset and query related words 
  

ficomplex question answering  unsupervised approaches

example 
for example  given the query the following sentence gets synonym overlap score of
         hypernym hyponym overlap score of           and gloss overlap score of           
query describe steps taken and worldwide reaction prior to introduction of the euro on
january          include predictions and expectations reported in the press 
sentence the frankfurt based body said in its annual report released today that it has
decided on two themes for the new currency  history of european civilization and
abstract or concrete paintings 
synonym overlap score         
hypernym hyponym overlap score           
gloss overlap score           
    statistical similarity measures
statistical similarity measures are based on the co occurrence of similar words in a corpus 
two words are termed as similar if they belong to the same context  we used the thesaurus
provided by dr  dekang lin   for these purpose  we have used two statistical similarity
measures 
dependency based similarity measure
this method uses the dependency relations among words in order to measure the similarity  lin      b   it extracts the dependency triples and then uses a statistical approach
to measure the similarity  using the given corpus one can retrieve the most similar words
for a given word  the similar words are grouped into clusters 
note that for a word there can be more than one cluster  each cluster represents the
sense of the word and its similar words for that sense  so  selecting the right cluster for a
word is itself a problem  our goals are  i  to create a bag of similar words to the query
words and ii  once we get the bag of similar words  dependency based  for the query words
to measure the overlap score between it and the sentence words 
creating bag of similar words 
for each query word we extract all of its clusters from the thesaurus  now in order
to determine the right cluster for a query word we measure the overlap score between the
query related words  i e  exact words  synonyms  hypernyms hyponyms and gloss  and the
clusters  the hypothesis is that the cluster that has more words in common with the query
related words is the right cluster under the assumption that the first synonym is the correct
sense  we choose the cluster for a word which has the highest overlap score 

overlap scorei  

p

w  queryrelatedw ords countmatch  w   

    

cluster   argmaxi  overlap scorei  

    

w  queryrelatedw ords count  w   

p

    http   www cs ualberta ca  lindek downloads htm

  

fichali  joty    hasan

where queryrelatedwords is the set of exact words  synonyms  hyponyms hypernyms 
and gloss words for the words in the query  i e query words  and countmatch is the number
of matches between the query related words and the ith cluster of similar words 
measuring overlap score 
once we get the clusters for the query words we measured the overlap between the
cluster words and the sentence words which we call dependency based similarity measure 

dependencym easure  

w  senw ords countmatch  w   

p

p

w  senw ords count  w   

    

where senwords is the set of words for the sentence and countmatch is the number
of matches between the sentence words and the cluster of similar words 
proximity based similarity measure
this similarity is computed based on the linear proximity relationship between words
only  lin      a   it uses the information theoretic definition of similarity to measure the
similarity  the similar words are grouped into clusters  we took the similar approach to
measure this feature as the previous section except that we used a different thesaurus 
example 
considering the following query and sentence we get the following measures 
query  describe steps taken and worldwide reaction prior to introduction of the euro on
january          include predictions and expectations reported in the press 
sentence  the frankfurt based body said in its annual report released today that it has
decided on two themes for the new currency  history of european civilization and
abstract or concrete paintings 
dependency based similarity score           
proximity based similarity score            
    graph based similarity measure
erkan and radev        used the concept of graph based centrality to rank a set of sentences
for producing generic multi document summaries  a similarity graph is produced for the
sentences in the document collection  in the graph each node represents a sentence  the
edges between nodes measure the cosine similarity between the respective pair of sentences 
the degree of a given node is an indication of how important the sentence is  figure  
shows an example of a similarity graph for   sentences 
once the similarity graph is constructed  the sentences are ranked according to their
eigenvector centrality  the lexrank performed well in the context of generic summarization  to apply lexrank to query focused context a topic sensitive version of lexrank is
proposed by otterbacher et al          we followed a similar approach in order to calculate
this feature  the score of a sentence is determined by a mixture model of the relevance of
the sentence to the query and the similarity of the sentence to other high scoring sentences 
  

ficomplex question answering  unsupervised approaches

figure    lexrank similarity
relevance to the question
we first stem out all the sentences in the collection and compute the word idfs  inverse
document frequency  using the following formula 
n   
idfw   log
      sfw




    

where n is the total number of sentences in the cluster  and sfw is the number of
sentences that the word w appears in 
we also stem out the questions and remove the stop words  the relevance of a sentence
s to the question q is computed by 
rel s q   

x

wq

log  tfw s       log  tfw q       idfw

    

where tfw s and tfw q are the number of times w appears in s and q  respectively 
mixture model
in the previous section we measured the relevance of a sentence to the question but a
sentence that is similar to the high scoring sentences in the cluster should also have a high
score  for instance  if a sentence that gets a high score based on the question relevance
model is likely to contain an answer to the question then a related sentence  which may
not be similar to the question itself  is also likely to contain an answer  otterbacher et al  
      
we capture this idea by the following mixture model 

p s q   

 

x
sim s  v 
rel s q 
p
      d  
d p
zc rel z q 
zc sim z  v 
vc

 

 p v q 

    

where p s q   the score of a sentence s given a question q  is determined as the sum
of its relevance to the question and the similarity to the other sentences in the collection 
c is the set of all sentences in the collection  the value of the parameter d which we call
  

fichali  joty    hasan

bias is a trade off between two terms in the equation and is set empirically  for higher
values of d we prefer the relevance to the question to the similarity to other sentences 
the denominators in both terms are for normalization  although it is computationally
expensive  equation    calculates the sum over the entire collection since it is required for
the model to sense the global impact through the voting of all sentences  we measure the
cosine similarity weighted by word idfs as the similarity between two sentences in a cluster 

sim x  y    qp

p

wx y

tfw x  tfw y   idfw   

 
xi x  tfxi  x  idfxi   

qp

 
yi y  tfyi  y  idfyi  

    

equation    can be written in matrix notation as follows 
p    da       d b t p

    

a is the square matrix such that for a given index i  all the elements in the i th column
are proportional to rel i q   b is also a square matrix such that each entry b i j  is
proportional to sim i j   both matrices are normalized so that row sums add up to   
note that as a result of this normalization all rows of the resulting square matrix q  
 da       d b  also add up to    such a matrix is called stochastic and defines a markov
chain  if we view each sentence as a state in a markov chain then q i j  specifies the
transition probability from state i to state j in the corresponding markov chain  the
vector p we are looking for in eq     is the stationary distribution of the markov chain 
an intuitive interpretation of the stationary distribution can be understood by the concept
of a random walk on the graph representation of the markov chain  with probability d a
transition is made from the current node to the nodes that are similar to the query  with
probability    d  a transition is made to the nodes that are lexically similar to the current
node  every transition is weighted according to the similarity distributions  each element
of the vector p gives the asymptotic probability of ending up at the corresponding state in
the long run regardless of the starting state  the stationary distribution of a markov chain
can be computed by a simple iterative algorithm called power method  erkan   radev 
       it starts with a uniform distribution  at each iteration the eigenvector is updated
by multiplying with the transpose of the stochastic matrix  since the markov chain is
irreducible and aperiodic the algorithm is guaranteed to terminate 

   ranking sentences
we use several methods in order to rank sentences to generate summaries applying the
features described in section    in this section we will describe the systems in detail 
    learning feature weights  a local search strategy
in order to fine tune the weights of the features  we have used a local search technique  initially we set all the feature weights  w         wn   as equal values  i e        see algorithm    
then we train the weights using the duc      data set  based on the current weights we
score the sentences and generate summaries accordingly  we evaluate the summaries using
  

ficomplex question answering  unsupervised approaches

input  stepsize l  weight initial value v
output  a vector w
  of learned weights
initialize the weight values wi to v 
for i    to n do
rg    rg    prev    
while  true  do
scoresentences w 
 
generatesummaries  
rg    evaluaterouge  
if rg   rg  then
prev   wi
wi     l
rg    rg 
else
break
end
end
end
return w
 
algorithm    tuning weights using local search technique
the automatic evaluation tool rouge  lin         described in section    and the rouge
value works as the feedback to our learning loop  our learning system tries to maximize the
rouge score in every step by changing the weights individually by a specific step size  i e 
       that means  to learn weight wi we change the value of wi keeping all other weight
values  wj j  i   stagnant  for each weight wi the algorithm achieves the local maximum
 i e  hill climbing  of rouge value 
once we have learned the feature weights we compute the final scores for the sentences
using the formula 
scorei   x i  w
 

    

where x i is the feature vector for i th sentence  w
  is the weight vector  and scorei is the
score of i th sentence 
    statistical machine learning approaches
we experimented with two unsupervised statistical learning techniques with the features
extracted in the previous section for the sentence selection problem 
   k means learning
   expectation maximization  em  learning
      the k means learning
k means is a hard clustering algorithm that defines clusters by the center of mass of their
members  we start with a set of initial cluster centers that are chosen randomly and go
  

fichali  joty    hasan

through several iterations of assigning each object to the cluster whose center is closest 
after all objects have been assigned we recompute the center of each cluster as the centroid
  of its members  the distance function we use is squared euclidean distance
or mean  
instead of the true euclidean distance 
since the square root is a monotonically growing function squared euclidean distance
has the same result as the true euclidean distance but the computation overload is smaller
when the square root is dropped 
once we have learned the means of the clusters using the k means algorithm our next
task is to rank the sentences according to a probability model  we have used bayesian
model in order to do so  bayes law says 

x qk    p  qk   
p x
x  
p x
x qk    p  qk   
p x
pk
x qk    p qk   
k   p x

x     
p  qk  x
 

    

where qk is a cluster  x is a feature vector representing a sentence  and  is the parameter
set of all class models  we set the weights of the clusters as equiprobable  i e  p  qk     
x qk     using the gaussian probability distribution  the gaussian
  k   we calculated p x
probability density function  pdf  for the d dimensional random variable x is given by 

x   
p  
    x

e

 
x
  t     x
x
 
 x
 

 dp
 
  det 

    

where    the mean vector  and    the covariance matrix  are the parameters of the
  from the k means algorithm and we calculate
gaussian distribution  we get the means  
the covariance matrix using the unbiased covariance estimation procedure 

j  

n
  x
xi  j   x
x i  j  t
 x
n    i  

    

      the em learning
the em algorithm for gaussian mixture models is a well known method for cluster analysis 
a useful outcome of this model is that it produces a likelihood value of the clustering model
and the likelihood values can be used to select the best model from a number of different
models providing that they have the same number of parameters  i e  same number of
clusters  
  

ficomplex question answering  unsupervised approaches

x  each represented by a feature vector of length
input  a sample of n data points  x
l
input  number of clusters k
output  an array s of k means based scores
data  array dnk   k   k
data  array c k   y nk
randomly choose k data points as k initial means   k   k           k 
repeat
for i    to n do
for j    to k do
xi   j k     x
xi   j  t  x
xi   j  
d ij   kx
end
if d ik   d il   l    k then
assign x i to c k  
end
end
for i  p
  to k do
c
x c

xj

j
i
i  
c i 
 c
end
until no further change occurs  
   calculating the covariances for each cluster
for i    to k do
c i 
m    c
for j    to m do
c ij   i     c
c ij   i  t
 i      c
end
 i        m     
end
   calculating the scores for sentences
for i    to n do
for j    to k do
t  
 


   x i  j    j  x i  j  
yij   e  d 

 

  

  

j  
det 

end
for j    to k do
p
   where  wj     k
zij    yij  wj    k
j   yij  wj  
end
k   k
m   max 
push zim to s
end
return s
algorithm    computing k means based similarity measure

  

fichali  joty    hasan

a significant problem with the em algorithm is that it converges to a local maximum
of the likelihood function and hence the quality of the result depends on the initialization 
this problem along with a method for improving the initialization is discussed later in this
section 
em is a soft version of the k means algorithm described above  as with k means we
start with a set of random cluster centers c     ck   in each iteration we do a soft assignment
of the data points to every cluster by calculating their membership probabilities  em is
an iterative two step procedure     expectation step and    maximization step  in the
expectation step we compute expected values for the hidden variables hi j which are cluster
membership probabilities  given the current parameters we compute how likely it is that
an object belongs to any of the clusters  the maximization step computes the most likely
parameters of the model given the cluster membership probabilities 
the data points are considered to be generated by a mixture model of k gaussians of
the form 

p  x   

k
x

p  c   i p  x c   i   

i  

k
x

i    i  
p  c   i p  x 

    

i  

where the total likelihood of model  with k components  given the observed data points
x   x          x n   is 

l  x 

 


n x
k
y

i   j  

x i  j    
p  c   j p  x

n
x

k
x

i  

log

j  

n x
k
y

i   j  

xi  
j    j  
wj p  x

xi  
 j    j     taking the log likelihood  
wj p  x

    
    

where p is the probability density function  i e  eq       j and  j are the mean and
covariance matrix of component j  respectively  each component contributes a proportion 
p
wj   of the total population such that  k
j   wj     
log likelihood can be used instead of likelihood as it turns the product into a sum  we
describe the em algorithm for estimating a gaussian mixture 
singularities the covariance matrix  above must be non singular or invertible  the
em algorithm may converge to a position where the covariance matrix becomes singular
       or close to singular  that means it is not invertible anymore  if the covariance
  
matrix becomes singular or close to singular then em may result in wrong clusters  we
restrict the covariance matrices to become singular by testing these cases at each iteration
of the algorithm as follows 
q

     e    then update 
if    
else do not update 
  

ficomplex question answering  unsupervised approaches

discussion  starting values for the em algorithm
the convergence rate and success of clustering using the em algorithm can be degraded
by a poor choice of starting values for the means  covariances  and weights of the components  we experimented with one summary  for document number d    a from duc
      in order to test the impact of these initial values on the em algorithm  the cluster
means are initialized with
p a heuristic that spreads them randomly around m ean dat a 
with standard deviation cov dat a       their initial covariance is set to cov dat a 
and the initial values of the weights are wj     k where k is the number of clusters 
that is  for d dimensional data points the parameters of j th component are as follows 

 j   rand         d  
j    dat a 
wj

q

  dat a          dat a 

    k

the highly variable nature of the results of the tests is reflected in the very inconsistent values for the total log likelihood and the results of repeated experiments indicated
that using random starting values for initial estimates of the means frequently gave poor
results  there are two possible solutions to this problem  in order to get good results
from using random starting values  as specified by the algorithm  we will run the em algorithm several times and choose the initial configuration for which we get the maximum
log likelihood among all configurations  choosing the best one among several runs is a very
computer intensive process  so  to improve the outcome of the em algorithm on gaussian
mixture models  it is necessary to find a better method of estimating initial means for the
components 
the best starting position for the em algorithm  in regard to the estimates of the means 
would be to have one estimated mean per cluster which is closer to the true mean of that
cluster 
to achieve this aim we explored the widely used k means algorithm as a cluster
 means  finding method  that is  the means found by the k means clustering above will
be utilized as the initial means for the em and we calculate the initial covariance matrices
using the unbiased covariance estimation procedure  equation     
ranking the sentences
once the sentences are clustered by the em algorithm  we identify the sentences which
xi     where qr denotes the clusare question relevant by checking their probabilities  p  qr  x
x i           then x i is considered to
ter question relevant  if for a sentence x i   p  qr  x
be question relevant  the cluster which has the mean values greater than the other one is
considered as the question relevant cluster 
our next task is to rank the question relevant sentences in order to include them in the
summary  this can be done easily by multiplying the feature vector x i with the weight
vector w
  that we learned by applying the local search technique  equation     
  

fichali  joty    hasan

input  a sample of n data points   x   each represented by a feature vector of length
l
input  number of clusters k
output  an array s of em based scores
k   k   k           k  with equal priors set
start with k initial gaussian models  n  
to p  qk       k 
repeat
 i 
x j    i    for each
   estimation step  compute the probability p  qk  x
 i 

data point xj   j           n  to belong to the class qk
for j    to n do
for k    to k do
 i 
x j    i     
p  qk  x

 i 

 i 

xj  qk    i   
p  qk   i   p x
xj   i   
p x
 i 

 
end
end
   maximization step 
for k    to k do
for j    to n do
   update the means 
 i  
k

 

 i 

 i 

x j  
k    k  
p  qk   i   p x

 i 
 i 
 i 
x j  
 i 
k   p  qk    p x
k   k  

pk

  

 

   update the variances 
 i   
k

  

 i 
xj    i   
j   x j p  qk  x
pn
 i 
xj    i   
j   p  qk  x

pn

 i 
xj
xj    i    x
xj    i   
  x
j   p  qk  x
k
pn
 i 
xj    i   
j   p  qk  x

pn

 i    t
 

 k

   update the priors 

p  qk  i       i       

n
 x
 i 
x j    i   
p  qk  x
n j  

end
end
until the total likelihood increase falls under some desired threshold  
return s
algorithm    computing em based similarity measure

  

ficomplex question answering  unsupervised approaches

   redundancy checking and generating summary
once the sentences are scored the easiest way to create summaries is just to output the
topmost n sentences until the required summary length is reached  in that case  we are
ignoring other factors  such as redundancy and coherence 
as we know that text summarization clearly entails selecting the most salient information and putting it together in a coherent summary  the answer or summary consists of
multiple separately extracted sentences from different documents  obviously  each of the
selected text snippets should individually be important  however  when many of the competing sentences are included in the summary the issue of information overlap between parts
of the output comes up and a mechanism for addressing redundancy is needed  therefore 
our summarization systems employ two levels of analysis  first a content level where every
sentence is scored according to the features or concepts it covers  and second a textual level 
when  before being added to the final output  the sentences deemed to be important are
compared to each other and only those that are not too similar to other candidates are included in the final answer or summary  goldstein  kantrowitz  mittal  and carbonell       
observed this in what the authors called maximum marginal relevance  mmr   following hovy et al         we modeled this by be overlap between an intermediate summary
and a to be added candidate summary sentence 
we call this overlap ratio r  where r is between   and   inclusively  setting r      
means that a candidate summary sentence  s  can be added to an intermediate summary 
s  if the sentence has a be overlap ratio less than or equal to     

   experimental evaluation
this section describes the results of experiments conducted using duc        dataset
provided by nist      some of the questions these experiments address include 
 how do the different features affect the behavior of the summarizer system 
 which one of the algorithms  k means  em and local search  performs better for
this particular problem 
we used the main task of duc      for evaluation  the task was 
given a complex question  topic description  and a collection of relevant documents 
the task is to synthesize a fluent  well organized     word summary of the documents that
answers the question s  in the topic 
the documents of duc      came from the aquaint corpus comprising newswire
articles from the associated press and new york times             and xinhua news
agency              nist assessors developed topics of interest to them and choose a set
of    documents relevant  document cluster  to each topic  each topic and its document
cluster were given to   different nist assessors including the developer of the topic  the
assessor created a     word summary of the document cluster that satisfies the information
    http   www nlpir nist gov projects duc 
    national institute of standards and technology

  

fichali  joty    hasan

need expressed in the topic statement  these multiple reference summaries are used in
the evaluation of summary content 
the purpose of our experiments is to study the impact of different features  to accomplish this we generated summaries for the    topics of duc      by each of our seven
systems defined as below 
 the lex system generates summaries based on only lexical features  section      
n gram  n           lcs  wlcs  skip bi gram  head  head synonym and be overlap 
 the lexsem system considers only lexical semantic features  section       synonym  hypernym hyponym  gloss  dependency based and proximity based similarity 
 the syn system generates summary based on only syntactic feature  section        
 the cos system generates summary based on the graph based method  section      
 the sys  system considers all the features except the syntactic and semantic features
 all features except section      
 the sys  system considers all the features except the semantic feature  all features
except section        and
 the all system generates summaries taking all the features  section    into account 
    automatic evaluation
rouge we carried out automatic evaluation of our summaries using the rouge  lin 
      toolkit  which has been widely adopted by duc for automatic summarization evaluation  rouge stands for recall oriented understudy for gisting evaluation  it is a
collection of measures that determines the quality of a summary by comparing it to reference summaries created by humans  the measures count the number of overlapping units
such as n gram  word sequences  and word pairs between the system generated summary to
be evaluated and the ideal summaries created by humans  the available rouge measures
are  rouge n  n           rouge l  rouge w and rouge s  rouge n is n gram
recall between a candidate summary and a set of reference summaries  rouge l measures
the longest common subsequence  lcs  which takes into account sentence level structure
similarity naturally and identifies longest co occurring insequence n grams automatically 
rouge w measures the weighted longest common subsequence  wlcs  providing an improvement to the basic lcs method of computation to credit the sentences having the
consecutive matches of words  rouge s is the overlap of skip bigrams between a candidate summary and a set of reference summaries where skip bigram is any pair of words in
their sentence order allowing for arbitrary gaps  most of these rouge measures have been
applied in automatic evaluation of summarization systems and achieved very promising
results  lin        
for all our systems  we report the widely accepted important metrics  rouge   and
rouge su  we also present the rouge   scores since this has never been shown to not
correlate with human judgement  all the rouge measures were calculated by running
  

ficomplex question answering  unsupervised approaches

rouge       with stemming but no removal of stopwords  rouge run time parameters
were set as the same as duc      evaluation setup  they are 
rouge       pl        u  r       t    n    w      m  l      a
we also show     confidence interval of the important evaluation metrics for our systems
to report significance for doing meaningful comparison  we use the rouge tool for this
purpose  rouge uses a randomized method named bootstrap resampling to compute the
confidence interval  we used      sampling points in the bootstrap resampling 
we report the evaluation scores of one baseline system  the base column  in each of
the tables in order to show the level of improvement our systems achieve  the baseline
system generates summaries by returning all the leading sentences  up to     words  in the
ht ext i field of the most recent document s  
while presenting the results we highlight the top two f scores and bottom one f score
to indicate significance at a glance 
      results and discussion
the k means learning table   shows the rouge   scores for different combinations
of features in the k means learning  it is noticeable that the k means performs best for
the graph based cosine similarity feature  note that including syntactic feature does not
improve the score  also  including syntactic and semantic features increases the score
but not by a significant amount  summaries based on only lexical features give us good
rouge   evaluation 
scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

all
     
     
     

base
     
     
     

table    rouge   measures in k means learning

table   shows the rouge   scores for different combinations of features in the k means
learning  just like rouge   graph based cosine similarity feature performs well here  we
get a significant improvement in rouge   score when we include syntactic feature with all
other features  semantic features do not affect the score much  lexical semantic features
perform well here 

scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

all
     
     
     

table    rouge   measures in k means learning

  

base
     
     
     

fichali  joty    hasan

as table   shows  rouge su scores are the best for all features without syntactic and
semantic  including syntactic semantic features with other features degrades the scores 
summaries based on only lexical features achieve good scores 
scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

all
     
     
     

base
     
     
     

table    rouge su measures in k means learning
table   shows the     confidence interval  for f measures in k means learning  of the
important rouge evaluation metrics for all our systems in comparison to the confidence
interval of the baseline system  it can be seen that our systems have performed significantly
better than the baseline system in most of the cases 
systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

rouge  
                   
                   
                   
                   
                   
                   
                   
                   

rouge  
                   
                   
                   
                   
                   
                   
                   
                   

rouge su
                   
                   
                   
                   
                   
                   
                   
                   

table        confidence intervals for k means system

the em learning table   to table   show different rouge measures for the feature
combinations in the context of the em learning  it can be easily noticed that for all these
measures we get significant amount of improvement in rouge scores when we include
syntactic and semantic features along with other features  we get       improvement over
sys  in f score when we include syntactic feature and       improvement when we include
syntactic and semantic features  the cosine similarity measure does not perform as well as
it did in the k means experiments  summaries considering only the lexical features achieve
good results 
table   shows the     confidence interval  for f measures in em learning  of the important rouge evaluation metrics for all our systems in comparison to the confidence
interval of the baseline system  we can see that our systems have performed significantly
better than the baseline system in most of the cases 
local search technique the rouge scores based on the feature combinations are
given in table   to table     summaries generated by including all features perform the
  

ficomplex question answering  unsupervised approaches

scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

all
     
     
     

base
     
     
     

all
     
     
     

base
     
     
     

all
     
     
     

base
     
     
     

table    rouge   measures in em learning

scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

table    rouge   measures in em learning

scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

table    rouge su measures in em learning

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

rouge  
                   
                   
                   
                   
                   
                   
                   
                   

rouge  
                   
                   
                   
                   
                   
                   
                   
                   

rouge su
                   
                   
                   
                   
                   
                   
                   
                   

table        confidence intervals for em system

  

fichali  joty    hasan

best scores for all the measures  we get       improvement over sys  in f score when
we include syntactic feature and       improvement over sys  in f score when we include
syntactic and semantic features  in this case also lexical features  lex  perform well but
not better than all features  all  
scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

all
     
     
     

base
     
     
     

table    rouge   measures in local search technique

scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

all
     
     
     

base
     
     
     

table     rouge   measures in local search technique

scores
recall
precision
f score

lex
     
     
     

lexsem
     
     
     

syn
     
     
     

cos
     
     
     

sys 
     
     
     

sys 
     
     
     

all
     
     
     

base
     
     
     

table     rouge su measures in local search technique
table    shows the     confidence interval  for f measures in local search technique 
of the important rouge evaluation metrics for all our systems in comparison to the confidence interval of the baseline system  we find that our systems have performed significantly
better than the baseline system in most of the cases 
      comparison
from the results reported above we can see for all three algorithms our systems clearly outperform the baseline system  table    shows the f scores of the reported rouge measures
while table    reports the     confidence intervals for the baseline system  the best system
in duc       and our three techniques taking all features  all  into consideration  we
can see that the method based on local search technique outperforms the other two and the
em algorithm performs better than the k means algorithm  if we analyze deeply  we find
that in all cases but rouge su with local search the confidence intervals do not overlap
with the best duc      system 
  

ficomplex question answering  unsupervised approaches

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

rouge  
                   
                   
                   
                   
                   
                   
                   
                   

rouge  
                   
                   
                   
                   
                   
                   
                   
                   

rouge su
                   
                   
                   
                   
                   
                   
                   
                   

table         confidence intervals for local search system

algorithms
baseline
best system
k means
em
local search

rouge  
     
     
     
     
     

rouge  
     
     
     
     
     

rouge su
     
     
     
     
     

table     rouge f scores for different systems

algorithms
baseline
best system
k means
em
local search

rouge  
                   
                   
                   
                   
                   

rouge  
                   
                   
                   
                   
                   

rouge su
                   
                   
                   
                   
                   

table         confidence intervals for different systems

  

fichali  joty    hasan

    manual evaluation
for a sample of     summaries   drawn from our different systems generated summaries
we conduct an extensive manual evaluation in order to analyze the effectiveness of our
approaches  the manual evaluation comprised a pyramid based evaluation of contents and
a user evaluation to get the assessment of linguistic quality and overall responsiveness 
      pyramid evaluation
in the duc      main task     topics were selected for the optional community based
pyramid evaluation  volunteers from    different sites created pyramids and annotated
the peer summaries for the duc main task using the given guidelines       sites among
them created the pyramids  we used these pyramids to annotate our peer summaries to
compute the modified pyramid scores     we used the ducview jar   annotation tool for
this purpose  table    to table    show the modified pyramid scores of all our systems for
the three algorithms  a baseline systems score is also reported  the peer summaries of the
baseline system are generated by returning all the leading sentences  up to     words  in
the ht ext i field of the most recent document s   from these results we see that all our
systems perform better than the baseline system and inclusion of syntactic and semantic
features yields better scores  for all three algorithms we can also notice that the lexical
semantic features are the best in terms of modified pyramid scores 
      user evaluation
   university graduate students judged the summaries for linguistic quality and overall
responsiveness  the given score is an integer between    very poor  and    very good  and
is guided by consideration of the following factors     grammaticality     non redundancy 
   referential clarity     focus and    structure and coherence  they also assigned a
content responsiveness score to each of the automatic summaries  the content score is an
integer between    very poor  and    very good  and is based on the amount of information
in the summary that helps to satisfy the information need expressed in the topic narrative 
these measures were used at duc       table    to table    present the average linguistic
quality and overall responsive scores of all our systems for the three algorithms  the same
baseline systems scores are given for meaningful comparison  from a closer look at these
results  we find that most of our systems perform worse than the baseline system in terms
of linguistic quality but achieve good scores in case of overall responsiveness  it is also
obvious from the tables that the exclusion of syntactic and semantic features often causes
lower scores  on the other hand  lexical and lexical semantic features show good overall
responsiveness scores for all three algorithms 
    we have   systems for each of the   algorithms  cumulatively we have    systems  randomly we chose
  summaries for each of these    systems 
    http   www  cs columbia edu  becky duc          pyramid guidelines html
    this equals the sum of the weights of the summary content units  scus  that a peer summary matches 
normalized by the weight of an ideally informative summary consisting of the same number of contributors
as the peer 
    http   www  cs columbia edu  ani duc     tool html

  

ficomplex question answering  unsupervised approaches

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

modified pyramid scores
       
       
       
       
       
       
       
       

table     modified pyramid scores for k means system

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

modified pyramid scores
       
       
       
       
       
       
       
       

table     modified pyramid scores for em system

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

modified pyramid scores
       
       
       
       
       
       
       
       

table     modified pyramid scores for local search system

  

fichali  joty    hasan

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

linguistic quality
    
    
    
    
    
    
    
    

overall responsiveness
    
    
    
    
    
    
    
    

table     linguistic quality and responsive scores for k means system

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

linguistic quality
    
    
    
    
    
    
    
    

overall responsiveness
    
    
    
    
    
    
    
    

table     linguistic quality and responsive scores for em system

systems
baseline
lex
lexsem
syn
cos
sys 
sys 
all

linguistic quality
    
    
    
    
    
    
    
    

overall responsiveness
    
    
    
    
    
    
    
    

table     linguistic quality and responsive scores for local search system

  

ficomplex question answering  unsupervised approaches

   conclusion and future work
in this paper we presented our works on answering complex questions  we extracted eighteen important features for each of the sentences in the document collection  later we used
a simple local search technique to fine tune the feature weights  for each weight  wi   the
algorithm achieves the local maximum of the rouge value  in this way  once we learn
the weights we rank the sentences by multiplying the feature vector with the weight vector 
we also experimented with two unsupervised learning techniques     em and    k means
with the features extracted  we assume that we have two clusters of sentences     queryrelevant and    query irrelevant  we learned the means of the clusters using the k means
algorithm then we used bayesian model in order to rank the sentences  the learned means
in the k means algorithm are used as the initial means in the em algorithm  we applied the em algorithm to cluster the sentences into two classes      query relevant and   
query irrelevant  we take out the query relevant sentences and rank them using the learned
weights  i e  in local search   for each of our methods of generating summaries we filter
out the redundant sentences using a redundancy checking module and generate summaries
by taking the top n sentences 
we also experimented with the effects of different kinds of features  we evaluated our
systems automatically using rouge and report the significance of our results through
    confidence intervals  we conducted two types of manual evaluation     pyramid and
   user evaluation to further analyze the performance of our systems  our experimental
results mostly show the following   a  our approaches achieve promising results   b  the
empirical approach based on a local search technique outperforms the other two learning
techniques and em performs better than the k means algorithm   c  our systems achieve
better results when we include the tree kernel based syntactic and semantic features  and
 d  in all cases but rouge su with local search the confidence intervals do not overlap
with the best duc      system 
we are now experimenting with the supervised learning techniques  i e  svm  maxent  crf etc  and analyzing how they perform for this problem  prior to that  we produced huge amount of labeled data automatically using similarity measures such as rouge
 toutanova et al         
in the future we plan to decompose the complex questions into several simple questions
before measuring the similarity between the document sentence and the query sentence 
this will certainly serve to create more limited trees and subsequences which might increase
the precision  thus  we expect that by decomposing complex questions into the sets of
subquestions that they entail systems can improve the average quality of answers returned
and achieve better coverage for the question as a whole 

acknowledgments
we thank the anonymous reviewers for their useful comments on the earliest version of this
paper  special thanks go to our colleagues for proofreading the paper  we are also grateful
to all the graduate students who took part in the user evaluation process  the research
reported here was supported by the natural sciences and engineering research council
 nserc  research grant and the university of lethbridge 
  

fichali  joty    hasan

appendix a  stop word list

reuters
may
nov
tue
a
accordingly
against
alone
am
another
anyway
appropriate
ask
awfully
becomes
being
better
by
cant
certainly
comes
containing
currently
didnt
dont
each
else
etc
everyone
except
followed
forth
get
goes
h
hasnt

ap
jun
dec
wed
as
across
aint
along
amid
any
anyways
are
asking
b
becoming
believe
between
c
cannot
changes
concerning
contains
d
different
done
edu
elsewhere
etc 
everything
f
following
four
gets
going
had
have

jan
jul
tech
thu
able
actually
all
already
among
anybody
anywhere
arent
associated
be
been
below
beyond
cmon
cant
clearly
consequently
corresponding
definitely
do
down
eg
enough
even
everywhere
far
follows
from
getting
gone
hadnt
havent

  

feb
aug
news
fri
about
after
allow
also
amongst
anyhow
apart
around
at
became
before
beside
both
cs
cause
co
consider
could
described
does
downwards
e g 
entirely
ever
ex
few
for
further
given
got
happens
having

mar
sep
index
sat
above
afterwards
allows
although
an
anyone
appear
as
available
because
beforehand
besides
brief
came
causes
com
considering
couldnt
despite
doesnt
during
eight
especially
every
exactly
fifth
former
furthermore
gives
gotten
hardly
he

apr
oct
mon
s
according
again
almost
always
and
anything
appreciate
aside
away
become
behind
best
but
can
certain
come
contain
course
did
doing
e
either
et
everybody
example
five
formerly
g
go
greetings
has
hes

ficomplex question answering  unsupervised approaches

hello
hereafter
hi
how
im
immediate
indicated
inward
its
keep
l
less
likely
m
mean
most
my
nearly
nevertheless
non
nothing
of
old
onto
our
overall
perhaps
probably
r
regarding

help
hereby
him
howbeit
ive
in
indicates
is
its
keeps
lately
lest
little
mainly
meanwhile
mostly
myself
necessary
new
none
novel
off
on
or
ours
own
placed
provides
rather
regardless

hence
herein
himself
however
ie
inasmuch
inner
isnt
itself
kept
later
let
look
many
merely
mr 
n
need
next
noone
now
often
once
other
ourselves
p
please
q
rd
regards

her
hereupon
his
i
i e 
inc
insofar
it
j
know
latter
lets
looking
may
might
ms 
namely
needs
nine
nor
nowhere
oh
one
others
out
particular
plus
que
re
relatively

  

here
hers
hither
id
if
indeed
instead
itd
just
knows
latterly
like
looks
maybe
more
much
nd
neither
no
normally
o
ok
ones
otherwise
outside
particularly
possible
quite
really
respectively

heres
herself
hopefully
ill
ignored
indicate
into
itll
k
known
least
liked
ltd
me
moreover
must
near
never
nobody
not
obviously
okay
only
ought
over
per
presumably
qv
reasonably
right

fichali  joty    hasan

s
says
seemed
sensible
shall
so
sometime
specified
sup
tell
thanx
theirs
theres
thereupon
theyve
those
thus
towards
twice
unless
us
usually
via
was
were
werent
whenever
wherein
whither
whose
within
wouldnt
youd
yourself

said
second
seeming
sent
she
some
sometimes
specify
sure
tends
that
them
thereafter
these
think
though
to
tried
two
unlikely
use
uucp
viz
wasnt
weve
what
where
whereupon
who
why
without
x
youll
yourselves

same
secondly
seems
serious
should
somebody
somewhat
specifying
t
th
thats
themselves
thereby
they
third
three
together
tries
u
until
used
v
vs
way
welcome
whats
wheres
wherever
whos
will
wont
y
youre
z

saw
see
seen
seriously
shouldnt
somehow
somewhere
still
ts
than
thats
then
therefore
theyd
this
through
too
truly
un
unto
useful
value
w
we
well
whatever
whereafter
whether
whoever
willing
wonder
yes
youve
zero

  

say
seeing
self
seven
since
someone
soon
sub
take
thank
the
thence
therein
theyll
thorough
throughout
took
try
under
up
uses
various
want
wed
went
when
whereas
which
whole
wish
would
yet
your

saying
seem
selves
several
six
something
sorry
such
taken
thanks
their
there
theres
theyre
thoroughly
thru
toward
trying
unfortunately
upon
using
very
wants
well
were
whence
whereby
while
whom
with
would
you
yours

ficomplex question answering  unsupervised approaches

references
bloehdorn  s     moschitti  a       a   combined syntactic and semantic kernels for text
classification  in   th european conference on ir research  ecir       pp        
rome  italy 
bloehdorn  s     moschitti  a       b   structure and semantics for expressive text kernels 
in cikm       pp         
chali  y     joty  s  r       a   improving the performance of the random walk model
for answering complex questions   in proceedings of the   th annual meeting of the
acl hlt  short paper section  pp      oh  usa 
chali  y     joty  s  r       b   selecting sentences for answering complex questions  in
proceedings of emnlp  pp         hawaii  usa 
charniak  e          a maximum entropy inspired parser  in technical report cs      
brown university  computer science department 
collins  m     duffy  n          convolution kernels for natural language  in proceedings
of neural information processing systems  pp         vancouver  canada 
cormen  t  r   leiserson  c  e     rivest  r  l          introduction to algorithms  the
mit press 
erkan  g     radev  d  r          lexrank  graph based lexical centrality as salience
in text summarization  journal of artificial intelligence research             
goldstein  j   kantrowitz  m   mittal  v     carbonell  j          summarizing text documents  sentence selection and evaluation metrics  in proceedings of the   nd international acm conference on research and development in information retrieval 
sigir  pp         berkeley  ca 
guo  y     stylios  g          a new multi document summarization system  in proceedings of the document understanding conference  nist 
hacioglu  k   pradhan  s   ward  w   martin  j  h     jurafsky  d          shallow
semantic parsing using support vector machines  in technical report tr cslr        university of colorado 
halliday  m     hasan  r          cohesion in english  longman  london 
harabagiu  s   lacatusu  f     hickl  a          answering complex questions with random
walk models  in proceedings of the   th annual international acm sigir conference
on research and development in information retrieval  pp            acm 
hirao  t     suzuki  j   isozaki  h     maeda  e          dependency based sentence
alignment for multiple document summarization  in proceedings of coling       pp 
       geneva  switzerland  coling 
  

fichali  joty    hasan

hovy  e   lin  c  y   zhou  l     fukumoto  j          automated summarization evaluation with basic elements  in proceedings of the fifth conference on language
resources and evaluation genoa  italy 
kingsbury  p     palmer  m          from treebank to propbank  in proceedings of the
international conference on language resources and evaluation las palmas  spain 
kouylekov  m     magnini  b          recognizing textual entailment with tree edit distance
algorithms  in proceedings of the pascal challenges workshop  recognising textual
entailment challenge 
li  j   sun  l   kit  c     webster  j          a query focused multi document summarizer based on lexical chains  in proceedings of the document understanding
conference rochester  nist 
lin  c  y          rouge  a package for automatic evaluation of summaries  in proceedings of workshop on text summarization branches out  post conference workshop
of association for computational linguistics  pp       barcelona  spain 
lin  d       a   an information theoretic definition of similarity  in proceedings of
international conference on machine learning  pp         madison  wisconsin 
lin  d       b   automatic retrieval and clustering of similar words  in proceedings
of the international conference on computational linguistics and association for
computational linguistics  pp         montreal  canada 
losada  d          language modeling for sentence retrieval  a comparison between
multiple bernoulli models and multinomial models  in information retrieval and theory workshop glasgow  uk 
losada  d     fernandez  r  t          highly frequent terms and sentence retrieval  in
proc    th string processing and information retrieval symposium  spire    pp 
       santiago de chile 
maccartney  b   grenager  t   de marneffe  m   cer  d     manning  c  d          learning to recognize features of valid textual entailments  in proceedings of the human
language technology conference of the north american chapter of the acl  p      
new york  usa 
morris  j     hirst  g          lexical cohesion computed by thesaural relations as an
indicator of structure of text  computational linguistics               
moschitti  a          efficient convolution kernels for dependency and constituent syntactic
trees  in proceedings of the   th european conference on machine learning berlin 
germany 
moschitti  a     basili  r          a tree kernel approach to question and answer classification in question answering systems  in proceedings of the  th international
conference on language resources and evaluation genoa  italy 
  

ficomplex question answering  unsupervised approaches

moschitti  a     quarteroni  s          kernels on linguistic structures for answer extraction  in proceedings of the   th conference of the association for computational
linguistics  acl     short paper section columbus  oh  usa 
moschitti  a   quarteroni  s   basili  r     manandhar  s          exploiting syntactic and
shallow semantic kernels for question answer classificaion  in proceedings of the
  th annual meeting of the association of computational linguistics  pp        
prague  czech republic  acl 
murdock  v     croft  w  b          a translation model for sentence retrieval  in hlt    
proceedings of the conference on human language technology and empirical methods
in natural language processing  pp         morristown  nj  usa  acl 
otterbacher  j   erkan  g     radev  d  r          using random walks for questionfocused sentence retrieval  in proceedings of human language technology conference
and conference on empirical methods in natural language processing  pp        
vancouver  canada 
pingali  p   k   r     varma  v          iiit hyderabad at duc       in proceedings of
the document understanding conference rochester  nist 
punyakanok  v   roth  d     yih  w          mapping dependencies trees  an application
to question answering  in proceedings of ai   math florida  usa 
strzalkowski  t     harabagiu  s          advances in open domain question answering 
springer 
toutanova  k   brockett  c   gamon  m   jagarlamudi  j   suzuki  h     vanderwende 
l          the pythy summarization system  microsoft research at duc       in
proceedings of the document understanding conference rochester  nist 
vanderwende  l   suzuki  h     brockett  c          microsoft research at duc     
task focused summarization with sentence simplification and lexical expansion  in
proceedings of the document understanding conference rochester  nist 
zajic  d  m   lin  j   dorr  b  j     schwartz  r          sentence compression as a component of a multi document summarization system  in proceedings of the document
understanding conference rochester  nist 
zhang  a     lee  w       a   question classification using support vector machines  in
proceedings of the special interest group on information retrieval  pp       toronto 
canada  acm 
zhang  d     lee  w  s       b   a language modeling approach to passage question
answering  in proceedings of the twelfth text retreival conference  pp        
gaithersburg  maryland 
zhou  l   lin  c  y     hovy  e          a be based multi dccument summarizer with
query interpretation  in proceedings of document understanding conference vancouver  b c   canada 

  

fi