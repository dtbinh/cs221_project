journal of artificial intelligence research                  

submitted        published      

optimal value of information in graphical models
andreas krause

krausea   caltech   edu

california institute of technology 
     e california blvd  
pasadena  ca       usa

carlos guestrin

guestrin   cs   cmu   edu

carnegie mellon university 
     forbes ave  
pittsburgh  pa       usa

abstract
many real world decision making tasks require us to choose among several expensive observations  in a sensor network  for example  it is important to select the subset of sensors that is
expected to provide the strongest reduction in uncertainty  in medical decision making tasks  one
needs to select which tests to administer before deciding on the most effective treatment  it has
been general practice to use heuristic guided procedures for selecting observations  in this paper 
we present the first efficient optimal algorithms for selecting observations for a class of probabilistic
graphical models  for example  our algorithms allow to optimally label hidden variables in hidden
markov models  hmms   we provide results for both selecting the optimal subset of observations 
and for obtaining an optimal conditional observation plan 
furthermore we prove a surprising result  in most graphical models tasks  if one designs an
efficient algorithm for chain graphs  such as hmms  this procedure can be generalized to polytree graphical models  we prove that the optimizing value of information is nppp  hard even for
polytrees  it also follows from our results that just computing decision theoretic value of information objective functions  which are commonly used in practice  is a  p complete problem even on
naive bayes models  a simple special case of polytrees  
in addition  we consider several extensions  such as using our algorithms for scheduling observation selection for multiple sensors  we demonstrate the effectiveness of our approach on several
real world datasets  including a prototype sensor network deployment for energy conservation in
buildings 

   introduction
in probabilistic reasoning  where one can choose among several possible but expensive observations 
it is often a central issue to decide which variables to observe in order to most effectively increase
the expected utility  howard        howard   matheson        mookerjee   mannino       
lindley         in a medical expert system  for example  multiple tests are available  and each test
has a different cost  turney        heckerman  horvitz    middleton         in such systems 
it is thus important to decide which tests to perform in order to become most certain about the
patients condition  at a minimum cost  occasionally  the cost of testing can even exceed the value
of information for any possible outcome  suggesting to discontinue any further testing 
the following running example motivates our research and is empirically evaluated in section   
consider a temperature monitoring task  where wireless temperature sensors are distributed across a

c
    
ai access foundation  all rights reserved 

fik rause   g uestrin

building  the task is to become most certain about the temperature distribution  whilst minimizing
energy expenditure  a critically constrained resource  deshpande  guestrin  madden  hellerstein   
hong         such fine grained building monitoring is required to obtain significant energy savings
 singhvi  krause  guestrin  garrett    matthews        
many researchers have suggested the use of myopic  greedy  approaches to select observations  scheffer  decomain    wrobel        van der gaag   wessels        dittmer   jensen 
      bayer zubek        kapoor  horvitz    basu         unfortunately  in general  this heuristic does not provide any performance guarantees  in this paper  we present efficient algorithms 
which guarantee optimal nonmyopic value of information in chain graphical models  for example 
our algorithms can be used for optimal active labeling of hidden states in hidden markov models  hmms  baum   petrie         we address two settings  subset selection  where the optimal
subset of observations is obtained in an open loop fashion  and conditional plans  a sequential 
closed loop plan where the observation strategy depends on the actual value of the observed variables  c f   figure     to our knowledge  these are the first optimal and efficient algorithms for
observation selection and diagnostic planning based on value of information for this class of graphical models  for both settings  we address the filtering and the smoothing versions  filtering is
important in online decision making  where our decisions can only utilize observations made in the
past  smoothing arises for example in structured classification tasks  where there is no temporal
dimension in the data  and hence all observations can be taken into account  we call our approach
vo idp as the algorithms use dynamic programming to optimize value of information  we evaluate our vo idp algorithms empirically on three real world datasets  and also show that they are
well suited for interactive classification of sequential data 
most inference problems in graphical models  such as computing marginal distributions and
finding the most probable explanation  that can be solved efficiently for chain structured graphs 
can also be solved efficiently for polytrees  we prove that the problem of selecting the best k
observations for maximizing decision theoretic value of information is nppp  complete even for
discrete polytree graphical models  giving a complexity theoretic classification of a core artificial
intelligence problem  nppp  complete problems are believed to be significantly harder than npcomplete or even  p complete problems commonly arising in the context of graphical models  we
furthermore prove that just evaluating decision theoretic value of information objective functions is
 p complete even in the case of naive bayes models  a simple special case of polytree graphical
models that is frequently used in practice  c f   domingos   pazzani        
unfortunately  these hardness results show that  while the problem of scheduling a single sensor can be optimally solved using our algorithms  the problem of scheduling multiple  correlated
sensors is wildly intractable  nevertheless  we show how our vo idp algorithms for single sensor
scheduling can be used to approximately optimize a multi sensor schedule  we demonstrate the
effectiveness of this approach on a real sensor network testbed for building management 
in summary  we provide the following contributions 
 we present the first optimal algorithms for nonmyopically computing and optimizing value
of information on chain graphical models 
 we show that optimizing decision theoretic value of information is nppp  hard for discrete
polytree graphical models  just computing decision theoretic value of information is  phard even for naive bayes models 

   

fio ptimal value of i nformation in g raphical m odels

no

tmorn  high 

tnoon  high 

yes

teve  high 

figure    example of a conditional plan 
 we present several extensions of our algorithms  e g   to tree graphical models with few
leaves  and to multiple correlated chains  for multi sensor scheduling  
 we extensively evaluate our algorithms on several real world problems  including sensor
scheduling on a real sensor testbed and active labeling in bioinformatics and natural language processing 

   problem statement
we will assume that the state of the world is described by a collection of random variables
xv    x            xn    where v is an index set  for example  v could denote a set of locations  and xi
models the temperature reading of a sensor placed at location i  v  for a subset
a    i            ik    v  we use the notation xa to refer to the random vector xa    xi            xik   
while some of our algorithms extend to continuous distributions  we generally assume that the variables xv are discrete  we take a bayesian approach  and assume a prior probability distribution
p  xv   over the outcomes of the variables  suppose we select a subset of the variables  xa  for
a  v   and observe xa   xa   for example  a is the set of locations where we place sensors 
or a set of medical tests we decide to perform  after observing the realization of these variables
xa   xa   we can compute the posterior distribution over all variables p  xv   xa   xa    based
on this posterior probability we obtain a reward r p  xv   xa   xa     for example  this reward function could depend on the uncertainty  e g   measured by the entropy  of the distribution
p  xv   xa   xa    we will describe several examples in more detail below 
in general  when selecting observation  we will not know ahead of time what observations we
will make  instead  we only have a distribution over the possible observations  hence  we will be
interested in the expected reward  where we take the expectation over the possible observations 
when optimizing the selection of variables  we can consider different settings  in subset selection  our goal is to pick a subset a  v of the variables  maximizing
x
a   argmax
p  xa   xa  r p  xv   xa   xa    
   
a

xa

where we impose some constraints on the set a we are allowed to pick  e g   on the number of
variables that can be selected  etc    in the subset selection setting  we commit to the selection of
the variables before we get to see their realization 
instead  we can also sequentially select one variable after the other  letting our choice depend
on the observations made in the past  in this setting  we would like to find a conditional plan  

   

fik rause   g uestrin

that maximizes
    argmax


x

p  xv  r p  xv   x xv     x xv      

   

xv

hereby   is a conditional plan that can select a different set of variables for each possible state of
the world xv   we use the notation  xv    v to refer to the subset of variables selected by the
conditional plan  in state xv   xv   figure   presents an example of a conditional plan for the
temperature monitoring example  we will define the notion of conditional planning more formally
in section     
this general setup of selecting observations goes back in the decision analysis literature to
the notion of value of information by howard        and in the statistical literature to the notion
of bayesian experimental design by lindley         in this paper  we refer to the problems    
and     as the problems of optimizing value of information 
in this paper  we show how the complexity of solving these value of information problems depend on the properties of the probability distribution p   we give the first algorithms for optimally
solving value of information for an interesting and challenging class of distributions including hidden markov models  we also present hardness results showing that optimizing value of information
is wildly intractable  nppp  complete  even for probability distributions for which efficient inference is possible  even for naive bayes models and discrete polytrees  
    optimization criteria
in this paper  we will consider a class of local reward  functions ri   which are defined on the
marginal probability distributions of the variables xi   this class has the computational advantage
that local rewards can be evaluated using probabilistic inference techniques  the total reward will
then be the sum of all local rewards 
let a be a subset of v  then p  xj   xa   xa   denotes the marginal distribution of variable xj conditioned on observations xa   xa   for example  in our temperature monitoring
application  xj models the temperature at location j  v  the conditional marginal distribution
p  xj   xj   xa   xa   then models the conditional distribution of the temperature at location j
after observing the temperature at locations a  v 
for classification purposes  it can be more appropriate to consider the max marginals
p max  xj   xj   xa   xa     max p  xv   xv   xj   xj   xa   xa   
xv

that is  for xj set to value xj   the probability of the most probable assignment xv   xv to all
other random variables  including xj for simplicity of notation  conditioned on the observations
xa   xa  
the local reward rj is a functional on the probability distribution p or p max over xj   that
is  rj takes an entire distribution over the variable xj and maps it to a reward value  typically  the
reward functions will be chosen such that certain or peaked distributions obtain higher reward 
to simplify notation  we write
rj  xj   xa     rj  p  xj   xa   xa   
   local reward functions are also widely used in additively independent utility models   c f   keeney   raiffa        

   

fio ptimal value of i nformation in g raphical m odels

to denote the reward for variable xj upon observing xa   xa   and
x
rj  xj   xa    
p  xa   xa  rj  xj   xa  
xa

to refer to expected local rewards  where the expectation is taken over all assignments xa to the
observations a  important local reward functions include 
residual entropy  if we set
rj  xj   xa     h xj   xa    

x

p  xj   xa   log  p  xj   xa   

xj

the objective in the optimization problem becomes to minimize the sum of residual entropies  optimizing this reward function attempts to reduce the uncertainty in predicting the marginals xi   we
choose this reward function in our running example to measure the uncertainty about the temperature distribution 
p
joint entropy  instead of minimizing the sum of residual entropies i h xi    we can also attempt to minimize the joint entropy of the entire distribution 
x
h xv     
p  xv   log  p  xv   
xv

note  that the joint entropy depends on the full probability distribution p  xv    rather than on the
marginals p  xi    and hence it is not local  nevertheless  we can exploit the chain rule for the joint
entropy h xb   of a set of random variables b               m   c f   cover   thomas        
h xb     h x      h x    x      h x    x    x           h xm   x            xm    
hence  if we choose the local reward functions rj  xj   xa     h xj   x            xj    xa    we
can optimize a non local reward function  the joint entropy  using only local reward functions 
decision theoretic value of information  the concept of local reward functions also includes
the concept of decision theoretic value of information  the notion of value of information is widely
used  c f   howard        lindley        heckerman et al          and is formalized  e g   in the
context of influence diagrams  howard   matheson        and partially observable markov decision processes  pomdps  smallwood   sondik         for each variable xj   let aj be a finite set
of actions  also  let uj   aj  dom xj  r be a utility function mapping an action a  aj and an
outcome x  dom xj to a real number  the maximum expected utility principle states that actions
should be selected as to maximize the expected utility 
x
euj  a   xa   xa    
p  xj   xa  uj  a  xj   
xj

the more certain we are about xj   the more economically we can choose our action  this idea is
captured by the notion of value of information  where we choose our local reward function
rj  xj   xa     max euj  a   xa   
a

   

fik rause   g uestrin

margin for structured prediction  we can also consider the margin of confidence 
rj  xj   xa     p max  xj   xa    p max  xj   xa   
where
xj   argmax p max  xj   xa   and xj   argmax p max  xj   xa   
xj   xj

xj

which describes the margin between the most likely outcome and the closest runner up  this reward
function is very useful for structured classification purposes  as shown in section   
weighted mean squared error  if the variables are continuous  we might want to minimize the
mean squared error in our prediction  we can do this by choosing
rj  xj   xa     wj var xj   xa   
where
z
var xj   xa    


p  xj   xa   xj 

z

x j p  x j

 

xa  dx j

 
dxj

is the conditional variance of xj given xa   xa   and wj is a weight indicating the importance of
variable xj  
monitoring for critical regions  hotspot sampling   suppose we want to use sensors for detecting fire  more generally  we want to detect  for each j  whether xj  cj   where cj  dom xj is a
critical region for variable xj   then the local reward function
rj  xj   xa     p  xj  cj   xa  
favors observations a that maximize the probability of detecting critical regions 
function optimization  correlated bandits   consider a setting where we have a collection of
random variables xv taking numerical
p values in some interval  m  m   and  after selecting some
of the variables  we get the reward i xi   this setting arises if we want to optimize an unknown
 random  function  where evaluating the function is expensive  in this setting  we are encouraged to
only evaluate the function where it is likely to obtain high values  we can maximize our expected
total reward if we choose the local reward function
z
rj  xj   xa     xj p  xj   xa  dxj  
i e   the expectation of variable xj given observations xa   this setting of optimizing a random
function can also be considered a version of the classical k armed bandit problem with correlated
arms  more details about the relationship with bandit problems are given in section   
these examples demonstrate the generality of our notion of local reward  note that most examples apply to continuous distributions just as well as for discrete distributions 

   

fio ptimal value of i nformation in g raphical m odels

    cost of selecting observations
we also want to capture the constraint that observations are expensive  this can mean that each
observation xj has an associated positive penalty cj that effectively decreases the reward  in our
example  we might be interested in trading off accuracy with sensing energy expenditure  alternatively  it is also possible to define a budget b for selecting observations  where each one is associated
with an integer cost j   here  we want to select observations whose sum cost is within the budget 
but these costs do not decrease the reward  in our running example  the sensors could be powered
by solar power  and regain a certain amount of energy per day  which allows a certain amount of
sensing  our formulation of the optimization
both for penalties and budgets  to
p problems allows p
simplify notation we also write c a    ja cj and  a    ja j to extend c and  to sets 
instead of fixed penalties and costs per observation  both can also depend on the state of the
world  for example  in the medical domain  applying a particular diagnostic test can bear different
risks for the health of the patient  depending on the patients illness  the algorithms we will develop
below can be adapted to accommodate such dependencies in a straight forward manner  we will
present details only for the conditional planning algorithm in section     

   decomposing rewards
in this section  we will present the key observation that allows us to develop efficient algorithms
for nonmyopically optimizing value of information in the class of chain graphical models  the
algorithms will be presented in section   
the set of random variables xv    x            xn   forms a chain graphical model  a chain   if
xi is conditionally independent of xv  i  i i    given xi  and xi     without loss of generality
we can assume that the joint distribution is specified by the prior p  x    of variable x  and the
conditional probability distributions p  xi     xi    the time series model for the temperature
measured by one sensor in our example can be formulated as a chain graphical model  note that the
transition probabilities p  xi     xi   are allowed to depend on the index i  i e   the chain models
are allowed to be nonstationary   chain graphical models have been extensively used in machine
learning and signal processing 
consider for example a hidden markov model unrolled for n time steps  i e   v can be partitioned into the hidden variables  x            xn   and the emission variables  y            yn    in hmms 
the yi are always observed and the variables xi form a chain  in many applications  some of which
are discussed in section    we can observe some of the hidden variables xi as well  e g   by asking
an expert  in addition to observing the emission variables  in these cases  the problem of selecting
expert labels also belongs to the class of chain graphical models addressed by this paper  since the
variables xi form a chain conditional on the observed values of the emission variables yi   this idea
can be generalized to the class of dynamic bayesian networks where the separators between time
slices have size one  and only these separators can be selected for observation  this formulation
also includes certain conditional random fields  lafferty  mccallum    pereira        which form
chains  conditional on the emission variables  the features  
chain graphical models originating from time series have additional  specific properties  in a
system for online decision making  only observations from the past and present time steps can be
taken into account  not observations which will be made in the future  this is generally referred
to as the filtering problem  in this setting  the notation p  xi   xa   will refer to the distribution
of xi conditional on observations in xa prior to and including time i  for structured classification
   

fik rause   g uestrin

figure    illustration of the decomposing rewards idea  the reward for chain     when observing
variables x    x  and x  decomposes as the sum of chain     plus the reward for chain
    plus the immediate reward for observing xp
  minus the cost of observing x    hereby
for brevity we use the notation rew a   b    bj a rj  xj   x    x    x    

problems as discussed in section    in general observations made anywhere in the chain must be
taken into account  this situation is usually referred to as the smoothing problem  we will provide
algorithms both for filtering and smoothing 
we will now describe the key insight  which allows for efficient optimization in chains  consider
a set of observations a  v  if the j variable is observed  i e   j  a  then the local reward
is simply r xj   xa     r xj   xj    now consider j 
  a  and let aj be the subset of a
containing the closest ancestor  and for the smoothing problem also the closest descendant  of xj
in xa   the conditional independence property of the graphical model implies that  given xaj   xj
is independent of the rest of the observed variables  i e   p  xj   xa     p  xj   xaj    thus  it
follows that r xj   xa     r xj   xaj   
these observations imply that the expected reward of some set of observations decomposes
along the chain  for simplicity of notation  we add two independent dummy variables x  and xn    
where r    c        rn     cn     n        let a    i          p
  im     where il   il    
i      and im     n      using this notation  the total reward r a    j rj  xj   xa   for the
smoothing case is given by 


iv    
m
x
x
riv  xiv   xiv    civ  
rj  xj   xiv   xiv      
v  

j iv   

in filtering settings  we simply replace rj  xj   xiv   xiv     by rj  xj   xiv    figure   illustrates
this decomposition 

   efficient algorithms for optimizing value of information
in this section  we present algorithms for efficiently and nonmyopically optimizing value of information in chain graphical models 
    efficient algorithms for optimal subset selection in chain models
in the subset selection problem  we want to find a most informative subset of the variables to observe
in advance  i e   before any observations are made  in our running example  we would  before
deploying the sensors  identify k time points that are expected to provide the most informative
sensor readings according to our model 

   

fio ptimal value of i nformation in g raphical m odels

first  define the objective function l on subsets of v by
l a   

n
x

rj  xj   xa    c a  

   

j  

the subset selection problem is to find the optimal subset
a  

argmax l a 
av  a b

maximizing the sum of expected local rewards minus the penalties  subject to the constraint that the
total cost must not exceed the budget b 
we solve this optimization problem using a dynamic programming algorithm  where the chain
is broken into sub chains using the insight from section    consider a sub chain from variable xa
to xb   we define lsm
a b  k  to represent the expected total reward for the sub chain xa           xb   in the
lt
smoothing setting where xa and xb are observed  and with a budget level of k  lfa b
 k  represents
the expected reward in the filtering setting where only xa is observed  more formally 
lt
 k 
lfa b

 

b 
x

max

a a     b  
j a  
 a k

rj  xj   xa   xa    c a  

for the filtering version  and
lsm
a b  k   

b 
x

max

rj  xj   xa   xa   xb    c a  

a a     b  
j a  
 a k

for the smoothing version  note that in both cases  l  n    b    maxa  a b l a   as in equation      i e   by computing the values for la b  k   we compute the maximum expected total reward
for the entire chain 
f lt
we can compute lsm
a b  k  and la b  k  using dynamic programming  the base case is simply 
lt
lfa b
     

b 
x

rj  xj   xa   

j a  

for filtering  and
b 
x

lsm
a b      

rj  xj   xa   xb   

j a  

for smoothing  the recursion for la b  k  has two cases  we can choose not to spend any more of the
budget  reaching the base case  or we can break the chain into two sub chains  selecting the optimal
observation xj   where a   j   b  in both filtering and smoothing we have


la b  k    max la b     
max
 rj  xj   xj    cj   la j       lj b  k  j     
j a j b j k

   

fik rause   g uestrin

input  budget b  rewards rj   costs j and penalties cj
output  optimal selection a of observation times
begin
for    a   b  n     do compute la b     
for k     to b do
for    a   b  n     do
sel       la b     
for j   a     to b    do sel j     rj  xj   xj    cj   la j       lj b  k  j   
la b  k    maxj a       b     sel j  
a b  k    argmaxj a       b     sel j  
end
end
a       b    n      k    b  a     
repeat
j    a b  k  
if j    then a    a   j   a    j  k    k  j  
until j      
end
algorithm    vo idp algorithm for optimal subset selection  for both filtering and smoothing  
at first  it may seem that this recursion should consider the optimal split of the budget between the
two sub chains  however  since the subset problem is open loop and the order of the observations
is irrelevant  we only need to consider split points where the first sub chain receives zero budget 
a pseudo code implementation for this dynamic programming approach  which we call vo idp
for subset selection is given in algorithm    the algorithm fills the dynamic programming tables in
two loops  the inner loop ranging over all pairs  a  b   a   b  and the outer loop increasing k  within
the inner loop  when computing the best reward for the sub chain from a to b  it fills out a table sel 
where sel j  is the reward that could be obtained by making an observation at j  and sel    is the
reward if no observation is made 
in addition to computing the optimal rewards la b  k  that could be achieved for sub chain a   b
and budget k  the algorithm also stores the choices a b  k  that realize this maximum score  here 
a b  k  is the index of the next variable that should be selected for sub chain a   b with budget
k  or   if no variable should be selected  in order to recover the optimal subset for budget k 
algorithm   uses the quantities a b to recover the optimal subset by tracing the maximal values
occurring in the dynamic programming equations  using an induction proof  we obtain 
theorem    subset selection   the dynamic programming algorithm described above computes
the optimal subset with budget b in      n    o n    b evaluations of expected local rewards 
note that if we do not consider different costs  for each variable  we would simply choose j  
  for all variables and compute la b  n    further note that if the variables xi are continuous 
our algorithm is still applicable when the integrations and inferences necessary for computing the
expected rewards can be performed efficiently  this is the case  for example  in a gaussian linear
model  i e   the variables xi are normally distributed  and the local reward functions are the residual
entropies or the residual variances for each variable 

   

fio ptimal value of i nformation in g raphical m odels

    efficient algorithms for optimal conditional planning in chain models
in the conditional plan problem  we want to compute an optimal sequential querying policy   we
observe a variable  pay the penalty  and depending on all values observed in the past  select the next
query  proceeding as long as our budget suffices  the objective is to find the plan with the highest
expected reward  where  for each possible sequence of observations  the budget b is not exceeded 
for filtering  we can only select observations in the future  whereas in the smoothing case  the next
observation can be anywhere in the chain  in our running example  the filtering algorithm would be
most appropriate  the sensors would sequentially follow the conditional plan  deciding on the most
informative times to sense based on the previous observations  figure   shows an example of such
a conditional plan 
      f rom s ubset s election to c onditional p lanning
note that in contrast to the subset selection setting that we considered in section      in conditional planning  the set of variables depends on the state of the world xv   xv   hence  for each
such state  the conditional plan  could select a different set of variables   xv    v  as an example  consider figure    where the set of possible observations is v    morn  noon  eve   and
xv    tmorn   tnoon   teve    if the world is in state xv    high  low  high   then the conditional
plan  presented in figure   would select  xv      morn  eve   whereas  if
xv    low  low  high   it would select  xv      morn  noon   since the conditional plan is
a function of the  random  state of the world  it is a set valued random variable  in order to optimize
problem      we define the objective function 
j    

x

p  xv  

xv

n
x



rj  xj   x xv      c  xv     

j  

i e   the expected sum of local rewards given the observations made by plan  xv   in state xv   xv
minus the penalties of the selected variables  where the expectation is taken with respect to the
distribution p  xv    in addition to defining the value of a policy j    we also define the cost   
     max   xv    
xv

as maximum cost  a   as defined in section      of any set a    xv   that could be selected by
the policy   in any state of the world xv   xv  
based on this notation  our goal is to find a policy   such that
    argmax j   such that     b 


i e   a policy that has maximum value  and is guaranteed to never have cost exceeding our budget
b  hereby  is the class of sequential policies  i e   those  where the observations are chosen
sequentially  only based on observations that have been previously made  
it will be useful to introduce the following notation 
j xa   k    max j    xa   xa   such that     k 


   

   recall that  in the filtering setting  r xj   x xv       r xj   xa     where a     t   xv   s t  t  j   i e   only
observations from the past are taken into account 

   

fik rause   g uestrin

where
j    xa   xa    

x

n
x


p  xv   xa   xa  
rj  xj   x xv      c  xv     

xv

j  

hence  j xa   k  is the best possible reward that can be achieved by any sequential policy with cost
at most k  after observing xa   xa   using this notation  our goal is to find the optimal plan with
reward j   b  
the value function j satisfies the following recursion  the base case considers the exhausted
budget 
x
j xa       
rj  xj   xa    c a  
jv

for the recursion  it holds that





x
j xa   k    max j xa       max
 
p  xj   xa  j xa   xj   k  j  


j a
  

   

xj

i e   the best one can do in state xa   xa with budget k is to either stop selecting variables  or
chose the best next variable and act optimally thereupon 
note that we can easily allow the cost j depend on the state xj of variable xj   in this case  we
would simply replace j by j  xj    and define j xa   r     whenever r      equivalently  we
can let the penalty c a  depend on the state by replacing c a  by c xa   
relationship to finite horizon markov decision processes  mdps   note that the function
j xa   k  defined in     is analogous to the concept of a value function in markov decision processes  c f   bellman         in finite horizon mdps  the value function v  s  k  models the maximum expected reward obtainable when starting in state s and performing k actions  for this value
function it holds that
x
v  s  k    r s  k    max
p  s    s  a v  s    k     
a

s 

where p  s    s  a  is the probability of transiting to state s  when performing action a in state s 
and r s  k  is the immediate reward obtained in state s if k steps are still left  this recursion 
which is similar to eq       is exploited by the value iteration algorithm for solving mdps  the
conditional planning problem with unit observation cost  i e    a     a   could be modeled as a
finite horizon mdp  where states correspond to observed evidence xa   xa   actions correspond
to observing variables  or not making any observation  and transition probabilities are given by the
probability of observing a particular instantiation of the selected variable  the immediate reward is
r s  k      for k      and r s     is the expected reward  in the value of information problem  of
observing assignment s  i e   r p  xv   s    c s    if all observations have unit cost  then for this
mdp  it holds that v  xa   k    j xa   k   unfortunately  in the conditional planning problem  since
the state of the mdp is uniquely determined by the observed evidence xa   xa   the state space is
exponentially large  hence  existing algorithms for solving mdps exactly  such as value iteration 
cannot be applied to solve large value of information problems  in section        we develop an
efficient dynamic programming algorithm for conditional planning in chain graphical models that
avoids this exponential increase in complexity 
   

fio ptimal value of i nformation in g raphical m odels

      dynamic p rogramming for o ptimal c onditional p lanning in c hains
we propose a dynamic programming algorithm for obtaining the optimal conditional plan that is
similar to the subset algorithm presented in section      again  we utilize the decomposition of
rewards described in section    the difference here is that the observation selection and budget
allocation now depend on the actual values of the observations  in order to compute the value
function j xa   k  for the entire chain  we will compute the value functions ja b  xa   k  for subchains xa           xb  
the base case of our dynamic programming approach deals with the zero budget setting 
f lt
ja b
 xa     

 

b 
x

rj  xj   xa   xa   

j a  

for filtering  and
sm
 xa   xb       
ja b

b 
x

rj  xj   xa   xa   xb   xb   

j a  

for smoothing  the recursion defines ja b  xa   k   or ja b  xa   xb   k  for smoothing   the expected
reward for the problem restricted to the sub chain xa           xb conditioned on the values of xa   xa
 and xb   xb for smoothing   and with budget limited by k  to compute this quantity  we again
iterate through possible split points j  such that a   j   b  here we observe a notable difference
between the filtering and the smoothing case  for smoothing  we now must consider all possible
splits of the budget between the two resulting sub chains  since an observation at time j might
require us to make an additional  earlier observation 
x

n
sm
sm
p  xj   xj   xa   xa   xb   xb  
ja b  xa  xb   k    max ja b  xa   xb       max
a j b

rj  xj   xj    cj  xj    

max
 lkj  xj  

xj



sm
ja j
 xa   xj   l 

 

sm
 xj   xb   k
jj b


o
 
 l  j  xj   

looking back in time is not possible in the filtering case  hence the recursion simplifies to

x
n
f lt
f lt
ja b  xa   k    max ja b  xa      
max
p  xj   xj   xa   xa  
a j b j  xj  k

rj  xj   xj    cj  xj    

xj

f lt
ja j
 xa     

 

f lt
jj b
 xj   k

o
 j  xj   
 

for both j f lt and j sm   the optimal reward is obtained by j  n      b    j   b    j     
algorithm   presents a pseudo code implementation for the smoothing version  the filtering case
is a straight forward modification  we call algorithm   the vo idp algorithm for conditional planning  the algorithm will fill the dynamic programming tables using three loops  the inner loop
ranging over all assignments xa   xb   the middle loop ranging over all pairs  a  b  where a   b  and
the outer loop covers increasing values of k  b  within the innermost loop  the algorithm again
computes a table sel such that sel j  is the optimal reward achievable by selecting variable j next 
   

fik rause   g uestrin

this value is now an expectation over any possible observation that variable xj can make  note that
for every possible instantiation xj   xj a different allocation of the remaining budget k  j  xj  
to the left and right sub chain  a   j and j   b respectively  can be chosen  the quantity  j  xj  
tracks this optimal budget allocation 
input  budget b  rewards rj   costs j and penalties cj
output  optimal conditional plan  a b   a b  
begin
sm  x   x      
for    a   b  n      xa  dom xa   xb  dom xb do compute ja b
a b
for k     to b do
for    a   b  n    xa  dom xa   xb  dom xb do
sm     
sel       ja b
for a   j   b do
sel j       
for xj  dom xj do
for    l  k  j  xj   do
sm  x   x   l    j sm  x   x   k  l    x    
bd l     ja j
j
j j
a j
b
j b
end
sel j     sel j    p  xj   xa   xb     rj  xj   xj    cj  xj     maxl bd j   
 j  xj     argmaxl bd j  
end
end
sm  k    max
ja b
j a       b     sel j  
a b  xa   xb   k    argmaxj a       b     sel j  
for xj  dom xa b  k  do a b  xa   xb   xj   k     a b  k   xj   
end
end
end
algorithm    vo idp algorithm for computating an optimal conditional plan  for the smoothing
setting  
input  budget k  observations xa   xa   xb   xb     
begin
j    a b  xa   xb   k  
if j    then
observe xj   xj  
l    a b  xa   xb   xj   k  
recurse with k    l  xa   xa and xj   xj instead of xb   xb  
recurse with k    k  l  j   xj   xj instead of xa   xa   and xb   xb  
end
end
algorithm    observation selection using conditional planning 
the plan itself is compactly encoded in the quantities a b and a b   hereby  a b  xa   xb   k 
determines the next variable to query after observing xa   xa and xb   xb   and with remaining budget k  a b  xa   xb   xj   k  determines the allocation of the budget after the new observation
xj   xj has been made  considering the exponential number of possible sequences of observations 
   

fio ptimal value of i nformation in g raphical m odels

it is remarkable that the optimal plan can be represented using only polynomial space  algorithm  
indicates how the computed plan can be executed  the procedure is recursive  requiring the parameters a       xa       b    n      xb      and k    b for the initial call  in our temperature
monitoring example  we could first collect some temperature timeseries as training data  and then
learn the chain model from this data  offline  we would then compute the conditional plan  for the
filtering setting   and encode it in the quantities a b and a b   we would then deploy the computed
plan on the actual sensor node  together with an implementation of algorithm    while computation of the optimal plan  algorithm    is fairly computationally expensive  the execution of the plan
 algorithm    is very efficient  selecting the next timestep for observation requires a single lookup
in the a b and a b tables  and hence well suited for deployment on a small  embedded device 
we summarize our analysis in the following theorem 
theorem    conditional planning   the algorithm for smoothing presented above computes an
optimal conditional plan in d   b         n    o n     evaluations of local rewards  where d is
the maximum domain size of the random variables x            xn   in the filtering case  the optimal plan can be computed using d   b       n    o n     evaluations  or  if no budget is used  in
d        n    o n     evaluations 
the faster computation for the filtering   no budget case is obtained by observing that we do not
require the third maximum computation  which distributes the budget into the sub chains 
also  note that contrary to the algorithm for computing optimal subsets in section      algorithm   only requires evaluations of the form r xj   xa   xa    which can in general be computed
d  times faster than the expectations r xj   xa    under this consideration  the subset selection
algorithm is in general only a factor d  b faster  even though the conditional planning algorithm has
more nested loops 
    efficient algorithms for trees with few leaves
in sections     and     we have presented dynamic programming based algorithms that can optimize value of information on chain graphical models  in fact  the key observations of section   that
local rewards decompose along chains holds not just in chain graphical models  but also in trees 
more formally  a tree graphical model is a joint probability distribution p  xv   over a collection
of random variables xv if p  xv   factors as
p  xv    

  y
i j  xi   xj   
z
 i j e

where i j is a nonnegative potential function  mapping assignments to xi and xj to the nonnegative
real numbers  e  v  v is a set of edges that form an undirected tree over the index set v  and z
is a normalization constant enforcing a valid probability distribution 
the dynamic programming algorithms presented in the previous sections can be extended to
such tree models in a straightforward manner  instead of identifying optimal subsets and conditional
plans for sub chains  the algorithms would then select optimal subsets and plans for sub trees of
increasing size  note however that the number of sub trees can grow exponentially in the number
of leaves of the tree  a star on n leaves for example has a number of subtrees that is exponential
in n  in fact  counting the number of subtrees of an arbitrary tree with n vertices is believed to
be intractable   p complete  goldberg   jerrum         however  for trees that contain only a
   

fik rause   g uestrin

small  constant  number of leaves  the number of subtrees is polynomial  and the optimal subset
and conditional plans can be computed in polynomial time 

   theoretical limits
many problems that can be solved efficiently for discrete chain graphical models can also be efficiently solved for discrete polytrees    examples include probabilistic inference and the most probable explanation  mpe  
in section     however we have seen that the complexity of the dynamic programming algorithms for chains increases dramatically when extended to trees  the complexity increases exponentially in the number of leafs of the tree 
we prove that  perhaps surprisingly  for the problem of optimizing value of information  this
exponential increase in complexity cannot be avoided  under reasonable complexity theoretic assumptions  before making this statement more formal  we briefly review the complexity classes
used in our results 
    brief review of relevant computational complexity classes
we briefly review the complexity classes used in the following statements by presenting a complete
problem for each of the class  for more details see  e g   the references by papadimitriou       
or littman  goldsmith  and mundhenk         the class np contains decision problems which
have polynomial time verifiable proofs  a well known complete problem is  sat for which the
instances are boolean formulas  in conjunctive normal form containing at most three literals per
clause   cnf form   the complexity class  p contains counting problems  a complete problem
for the class  p is   sat which counts the number of satisfying instances to a  cnf formula 
pp is a decision version of the class  p  a complete problem is m ajsat   which decides
whether a given  cnf formula  is satisfied by the majority  i e   by more than half of all its
possible assignments  if a and b are turing machine based complexity classes  then ab is the
complexity class derived by allowing the turing machines deciding instances of a oracle calls to
turing machines in b  we can intuitively think of the problems in class ab as those that can be
solved by a turing machine for class a  that has a special command which solves any problem in b 
pp is similar to  p in that ppp   p p   i e   if we allow a deterministic polynomial time turing
machine to have access to a counting oracle  we cannot solve more complex problems than if we give
it access to a majority oracle  combining these ideas  the class nppp is the class of problems that
can be solved by nondeterministic polynomial time turing machines that have access to a majority
 or a counting  oracle  a complete problem for nppp is em ajsat which  given a  cnf on
variables x            x n   it decides whether there exists an assignment to x            xn such that 
is satisfied for the majority of assignments to xn             x n   nppp has been introduced and
found to be a natural class for modeling ai planning problems in the seminal work by littman et al 
        as an example  the map assignment problem is nppp  complete for general graphical
models  as shown by park and darwiche        
the complexity classes satisfy the following set of inclusions  where the inclusions are assumed 
but not known to be strict  
p  np  pp  ppp   p p  nppp  
   polytrees are bayesian networks that form trees if the edge directions are dropped 

   

fio ptimal value of i nformation in g raphical m odels

    complexity of computing and optimizing value of information
in order to solve the optimization problems  we will most likely have to evaluate the objective
function  i e   the expected local rewards  our first result states that  even if we specialize to decision theoretic value of information objective functions as defined in section      this problem is
intractable even for naive bayes models  a special case of discrete polytrees  naive bayes models
are often used in classification tasks  c f   domingos   pazzani         where the class variable is
predicted from noisy observations  features   that are assumed to be conditionally independent given
the class variable  in a sense  naive bayes models are the next simplest  from the perspective of
inference  class of bayesian networks after chains  note that naive bayes models correspond to the
stars referred to in section      that have a number of subtrees that is exponential in the number
of variables 
theorem    hardness of computation for naive bayes models   the computation of decision
theoretic value of information functions is  p complete even for naive bayes models  it is also
hard to approximate to any factor unless p   np 
we have the immediate corollary that the subset selection problem is pp hard for naive bayes
models 
corollary    hardness of subset selection for naive bayes models   the problem of determining 
given a naive bayes model  constants c and b  cost function  and a set of decision theoretic value
of information objective functions ri   whether there is a subset of variables a  v such that
l a   c and  a   b is pp hard 
in fact  we can show that subset selection for arbitrary discrete polytrees  that are more general
than naive bayes models  but inference is still tractable  is even nppp  complete  a complexity
class containing problems that are believed to be significantly harder than np or  p complete
problems  this result provides a complexity theoretic classification of value of information  a core
ai problem 
theorem    hardness of subset selection computation for polytrees   the problem of determining  given a discrete polytree  constants c and b  cost function  and a set of decision theoretic
value of information objective functions ri   whether there is a subset of variables a  v such that
l a   c and  a   b is nppp  complete 
for our running example  this implies that the generalized problem of optimally selecting k sensors
from a network of correlated sensors is most likely computationally intractable without resorting to
heuristics  a corollary extends the hardness of subset selection to the hardness of conditional plans 
corollary    hardness of conditional planning computation for polytrees   computing conditional plans is pp hard for naive bayes models and nppp  hard for discrete polytrees 
all proofs of results in this section are stated in the appendix  they rely on reductions of complete
problems in np   p and nppp involving boolean formulae to problems of computing   optimizing value of information  the reductions are inspired by the works of littman et al         and park
and darwiche         but require the development of novel techniques  such as new reductions of
boolean formulae to naive bayes and polytree graphical models associated with appropriate reward
functions  ensuring that observation selections lead to feasible assignments to the boolean formulae 
   

fik rause   g uestrin

percent improvement

  

 

optimal conditional plan

 

mean margin of optimal subset
mean margin of greedy heuristic

 
    

   

mean f  score

    

 

    

   

 
 

   
optimal subset
greedy heuristic

 
 

 

 
  
  
  
number of observations

  

 a  sensor scheduling

   

   

mean accuracy of
greedy heuristic
 

 
 
 
 
number of observations

 b  cpg island detection

mean margin

    

mean accuracy of
optimal subset

 

    
    
 

  
  
  
  
number of observations

  

 c  part of speech tagging

figure    experimental results   a  temperature data  improvement over the uniform spacing
heuristic   b  cpg island data set  effect of increasing the number of observations on
margin and classification accuracy   c  part of speech tagging data set  effect of increasing the number of observations on margin and f  score 

   experiments
in this section  we evaluate our algorithms on several real world data sets  a special focus is on the
comparison of the optimal methods with the greedy heuristic and other heuristic methods for selecting observations  and on how the algorithms can be used for interactive structured classification 
    temperature time series
the first data set consists of temperature time series collected from a sensor network deployed at
intel research berkeley  deshpande et al         as described in our running example  data was
continuously collected for    days  linear interpolation was used in case of missing samples  the
temperature was measured once every    minutes  and it was discretized into    bins of   degrees
kelvin  to avoid overfitting  we used pseudo counts        when learning the model  using
parameter sharing  we learned four sets of transition probabilities  from    am    am    am      pm 
   pm     pm and   pm      am  combining the data from three adjacent sensors  we got    sample
time series 
the goal of this task was to select k out of    time points during the day  during which sensor
readings are most informative  the experiment was designed to compare the performance of the
optimal algorithms  the greedy heuristic  and a uniform spacing heuristic  which distributed the k
observations uniformly over the day  figure   a  shows the relative improvement of the optimal algorithms and the greedy heuristic over the uniform spacing heuristic  the performance is measured
in decrease of expected entropy  with zero observations as the baseline  it can be seen that if k is less
than about the half of all possible observations  the optimal algorithms decreased the expected uncertainty by several percent over both heuristics  the improvement gained by the optimal plan over
the subset selection algorithms appears to become more drastic if a large number of observations
 over half of all possible observations  is allowed  furthermore  for a large number of observations 
the optimal subset and the subset selected by the greedy heuristic were almost identical 

   

fio ptimal value of i nformation in g raphical m odels

    cpg island detection
we then studied the bioinformatics problem of finding cpg islands in dna sequences  cpg islands
are regions in the genome with a high concentration of the cytosine guanine sequence  these areas
are believed to be mainly located around the promoters of genes  which are frequently expressed in
the cell  in our experiment  we considered the gene loci hs   k    af       and al        for
which the genbank annotation listed three  two and one cpg islands each  we ran our algorithm
on a    base window at the beginning and end of each island  using the transition and emission
probabilities from durbin  eddy  krogh  and mitchison        for our hidden markov model  and
we used the sum of margins as reward function 
the goal of this experiment was to locate the beginning and ending of the cpg islands more
precisely by asking experts  whether or not certain bases belong to the cpg region or not  figure   b  shows the mean classification accuracy and mean margin scores for an increasing number
of observations  the results indicate that  although the expected margin scores are similar for the
optimal algorithm and the greedy heuristic  the mean classification performance of the optimal algorithm was still better than the performance of the greedy heuristic  for example  when making  
observations  the mean classification error obtained by the optimal algorithm is     lower than the
error obtained by the greedy heuristic 
    part of speech tagging
in our third experiment  we investigated the structured classification task of part of speech  pos 
tagging  conll         problem instances are sequences of words  sentences   where each word
is part of an entity  e g   european union   and each entity belongs to one of five categories 
location  miscellaneous  organization  person or other  imagine an application  where automatic
information extraction is guided by an expert  our algorithms compute an optimal conditional plan
for asking the expert  trying to optimize classification performance while requiring as little expert
interaction as possible 
we used a conditional random field for the structured classification task  where each node corresponds to a word  and the joint distribution is described by node potentials and edge potentials 
the sum of margins was used as reward function  measure of classification performance was the f 
score  the geometric mean of precision and recall  the goal of this experiment was to analyze how
the addition of expert labels increases the classification performance  and how the indirect  decomposing reward function used in our algorithms corresponds to real world classification performance 
figure   c  shows the increase of the mean expected margin and f  score for an increasing number of observations  summarized over ten    word sequences  it can be seen that the classification
performance can be effectively enhanced by optimally incorporating expert labels  requesting only
three out of    labels increased the mean f  score from by more than five percent  the following
example illustrates this effect  in one scenario both words of an entity  the sportsman p  simmons 
were classified incorrectly  p  as other and simmons as miscellaneous  the first request of the
optimal conditional plan was to label simmons  upon labeling this word correctly  the word p 
was automatically labeled correctly also  resulting in an f  score of     percent 

   

fik rause   g uestrin

   applying chain algorithms for more general graphical models
in section   we have seen algorithms that can be used to schedule a single sensor  assuming the time
series of sensor readings  e g   temperature  form a markov chain  this is a very natural assumption
for sensor networks  deshpande et al          when deploying sensor networks however  multiple
sensors need to be scheduled  if the time series for all the sensors were independent  we could use
our algorithms to schedule all the sensors independently of each other  however  in practice  the
measurements will be correlated across the different sensors  in fact  this dependence is essential
to allow generalization of measurements to locations where no sensor has been placed  in the following  we will describe an approach for using our single sensor scheduling algorithm to coordinate
multiple sensors 
more formally  we are interested in monitoring a spatiotemporal phenomenon at a set of locations s               m   and time steps t               t    with each locationtime pair s  t  we
associate a random variable xs t that describes the state of the phenomenon at that location and
time  the random vector xs t fully describes the relevant state of the world and the vector xs t
describes the state at a particular time step t  as before  we make the markov assumption  assuming
conditional independence of xs t from xs t  given xs t  for all t    t    
similarly as in the single chain case  we consider reward functions rs t that are associated with
each variable xs t   our goal is then to select  for each timestep  a set at  s of sensors to activate 
in order to maximize the sum of expected rewards  letting a  t   a       at   the expected total
reward is then given as
x
rs t  xs t   xa  t  
s t

for the filtering setting  i e   only observations in the past are taken into account for evaluating the
rewards   and
x
rs t  xs t   xa  t  
s t

for the smoothing setting  where all observations are taken into account   the generalization to
conditional planning is done as described in section   
note that in the case of a single sensor          the problem of optimal sensor scheduling can
be solved using algorithm    unfortunately  the optimization problem is wildly intractable even for
the case of two sensors        
corollary    hardness of sensor selection for two chains   given a model with two dependent
chains  constants c and b  a cost function  and a set of decision theoretic value of information
functions rs t   it is nppp  complete to determine whether there is a subset a  t of variables such
that l a  t    c and  a  t    b 
in the following  we will develop an approximate algorithm that uses our optimal single chain algorithms and performs well in practice 
    approximate sensor scheduling by lower bound maximization
the reason for the sudden increase in complexity in the case of multiple chains is that the decomposition of rewards along sub chains  as described in section    does not extend to the case of multiple

   

fio ptimal value of i nformation in g raphical m odels

s    

s    

s    

s    

s    

s    

s    

s    

s    

s    

figure    scheduling multiple correlated sensors in dynamic processes 
sensors  since influence can flow across chains  figure   visualizes this problem  there  the distri   
   
   
bution for sensor     depends on all three observations s  and s  from sensor     and s  from
sensor     
we address this complexity issue using an  approximate  extension of the decomposition approach used for single chains  we will focus on the decision theoretic value of information objective  as described in section       but other local reward functions  such as residual entropy  can be
used as well 
considering only recent observations  as a first approximation  we only allow a sensor to take
into account the most recent observations  intuitively  this appears to be a reasonable approximation 
especially if the potential scheduling times in t are reasonably far apart  formally  when evaluating
the local rewards at time t  we replace the set of observations up to time t  a  t  t by a subset
a   t  a  t such that

 
a   t    s  t   a  t   t  t  for all  s  t     a  t  
i e  for each sensor s  only the last observation  with largest time index t  is kept  we then
approximate rs t  xs t   a  t   by rs t  xs t   a   t    in figure   for example  where a     
  s         s         s         the total expected utility at time t  would be computed using only observations a         s         s         i e   using time t  for sensor one  and time t  for sensor two 
   
ignoring influence originating from observation s  and flowing through the chains as indicated by
the dashed arrow  the following proposition proves that this approximation is a lower bound to the
true value of information 
proposition    monotonicity of value of information   the decision theoretic value of information rs t  a  of a set a of sensors is monotonic in a 
rs t  a     rs t  a 
for all a   a 
proposition   proves that conditioning only on the most recent observations can only decrease our
objective function  hence maximizing this approximate objective implies maximizing a lower bound
on the true objective 
a coordinate ascent approach  we propose the following heuristic for maximizing the lower
bound on the expected utility  instead of jointly optimizing over all schedules  timesteps selected
for each sensor   the algorithm will repeatedly iterate over all sensors  for all sensors s  it will
optimize the selected observations as  t   holding the schedules for all other sensors fixed  this
   

fik rause   g uestrin

procedure resembles a coordinate ascent approach  where each coordinate ranges over all possible
schedules for a fixed sensor s 
when optimizing for sensor s  the algorithm finds a schedule as  t such that


 
x
as  t   argmax
rs t xs t   xa   t
xa s  such that  as  t    b 
   
a  t

s    s

s t

  t

i e   that maximizes  over all schedules a  t   the sum of expected rewards for all time steps and
 
sensors  given the schedules as  t for all non selected sensors s   
solving the single chain optimization problem  in order to solve the maximization problem
    for the individual sensors  we use the same dynamic programming approach as introduced in
lt
section    the recursive case lfa b
 k  for k     is exactly the same  however  the base case is
computed as
b  x


x
 
f lt
la b      
rs j xs j   xa
xa s   
s    s

j a   s

  j

i e   it takes into account the most recent observation for all non selected sensors s   
lt
     first of all  in
several remarks need to be made about the computation of the base case lfa b
a naive implementation  the computation of the expected utility


 
rs j xs j   xa
xa s 
s    s

  j

requires time exponential in the number of chains  this is the case since  in order to compute the
reward rs t   for each chain  all possible observations xa s
  xa s
that could be made need to be
  t
  t
taken into account  this computation requires computing the expectation over the joint distribution
p  xa   t    which is exponential in size  this increase in complexity can be avoided using a sampling
approximation  hoeffdings inequality can be used to derive polynomial bounds on sample complexity for approximating the value of information up to arbitrarily small additive error   similarly
as done in the approach of krause and guestrin      a     in practice  a small number of samples
appears to provide reasonable performance  secondly  inference itself becomes intractable with an
increasing number of sensors  approximate inference algorithms such as the algorithm proposed
by boyen and koller        provide a viable way around this problem 
analysis  since all sensors maximize the same global objective l a  t    the coordinated ascent
approach is guaranteed to monotonically increase the global objective with every iteration  ignoring
possible errors due to sampling or approximate inference   hence it must converge  to a local
optimum  after a finite number of steps  the procedure is formalized in algorithm   
although we cannot in general provide performance guarantees for the procedure  we are building on an algorithm that provides an optimal schedule for each sensor in isolation  which should
benefit from observations provided by the remaining sensors  also  note that if the sensors are all
independent  algorithm   will obtain the optimal solution  even if the sensors are correlated  the
obtained solution will be at least as good as the solution obtained when scheduling all sensors independently of each other  algorithm   will always converge  and always compute a lower bound on
   an absolute error of at most  when evaluating each reward rs t can accumulate to a total error of at most  t   s 
for all variables and hence to the error of the optimal schedule 

   

fio ptimal value of i nformation in g raphical m odels

input  budget b
output  selection a            a  of observation times for each sensor
begin
select ai      i    at random 
repeat
for i     to   do
use algorithm   to select observations ai for sensor i  but conditioning on current
sensor scheduling aj   j    i  for remaining sensors 
end
compute improvement  in total expected utility 
until  small enough  
end
algorithm    multi sensor scheduling 
the expected total utility  considering the intractability of the general problem even for two chains
 c f     corollary     these properties are reassuring  in our experiments  the coordinated sensor
scheduling performed very well  as discussed in section     
    proof of concept study on real deployment
in the work by singhvi et al          we presented an approach for optimizing light control in
buildings  with the purpose of satisfying building occupants preferences about lighting conditions 
and simultaneously minimizing energy consumption  in our approach  a wireless sensor network
is deployed that monitors the building for environmental conditions  such as the sunlight intensity
etc    the sensors feed their measurements to a building controller that actuates the lighting system
 lamps  blinds  etc   accordingly  at every timestep t  t   the building controller can choose
an action that affects the lighting conditions at all locations s in the building  utility functions
ut  a  xs t   are specified that map the chosen actions and the current lighting levels to a utility
value  this utility is chosen to capture both users preferences about light levels  as well as the
energy consumption of the lighting system  details on the utility functions are described in detail
by singhvi et al  
we evaluated our multi sensor scheduling approach in a real building controller testbed  as
described in detail by singhvi et al   in our experiments  we used algorithm   to schedule three
sensors  allowing each sensor to choose a subset out of ten time steps  in one hour intervals during
daytime   we varied the number of timesteps during which each sensor is activated  and computed
the total energy consumption and total user utility  as defined by singhvi et al    figure   a  shows
the mean user utility and energy savings achieved  for a number of observations varying from no
observations to continuous sensing     observations in our discretization     these results imply that
using the predictive model and our active sensing strategy  even a very small number of observations
achieves results approximately as good as the results achieved by continuous sensing 
figure   b  presents the mean total utility achieved using no observations  one observation or ten
observations per sensor each day  it can be seen that even a single observation per sensor increases
the total utility close to the level achieved by continuous sensing  figure   c  shows the mean energy
   note that in figure   a   energy cost and utility are plotted in different units and should not be directly compared 

   

fik rause   g uestrin

 

  
energy cost

  

  observ  
sensor

  

   observ  
sensor
energy cost

 

total utility

user utility and energy cost

  

 
no observ 

 

 

no observ 

  

 

 

  observ  
sensor

measured user utility
 

 

 

   
number of observations

  

 

 a  sensing scheduling evaluation

  

  
  
hour of day

  

  

 

 b  total utility

  

   observ  
sensor

  
  
hour of day

  

  

 c  energy cost

figure    active sensing results 
consumption required for the same experiment  here  the single sensor observation strategy comes
even closer to the power savings achieved for continuous sensing 
since the sensor network battery lifetime is in general inversely proportional to the amount of
power expended for sensing and communication  we conclude that our sensor scheduling strategy
promises to lead to drastic increases in sensor network lifetime  deployment permanence and reduced maintenance cost  in our testbed  the network lifetime could be increased by a factor of  
without significant reduction in user utility and increase in energy cost 

   related work
in this section  we review related work in a number of different areas 
    optimal experimental design
optimal experimental design is a general methodology for selecting informative experiments to infer
about aspects of the state of the world  such as the parameters of a particular nonlinear function 
etc    there is a large literature about different approaches to experimental design  c f   chaloner  
verdinelli        krause  singh    guestrin        
in bayesian experimental design  a prior distribution over possible states of the world is assumed  and experiments are chosen  e g   to reduce the uncertainty in the posterior distribution  in
its general form  bayesian experimental design was pioneered by lindley         the users encode
their preferences in a utility function u  p          where the first argument  p     is a distribution
over states of the world  i e   the parameters  and the second argument      is the true state of the
world  observations xa are collected  and the change in expected utility under the prior p    and
posterior p     xa   xa   can be used as a design criterion  in this sense  the value of observation problems considered in this paper can be considered instances of bayesian experimental design
problems  typically  bayesian experimental design is employed for continuous distributions  often
the multivariate normal distribution  by choosing different utility functions  different notions of
optimality are defined  including a  and d  optimality can be developed  chaloner   verdinelli 
       if we have the posterior covariance matrix  a   whose
maximum

 eigenvalue is max   then
bayesian a   d   and e  optimality minimizes tr  a   det  a   and max  a   respectively  in the terminology of section      d optimality corresponds to choosing the total entropy 
and a optimality corresponds to the  weighted  mean squared error criteria 

   

fio ptimal value of i nformation in g raphical m odels

even for multivariate normal distributions  optimal bayesian experimental design is np hard
 ko  lee    queyranne         in some applications of experimental design  the number of experiments to be selected is often large compared to the number of design choices  in these cases  one can
find a fractional design  i e   a non integral solution defining the proportions by which experiments
should be performed   and round the fractional solutions  in the fractional formulation  a   d   and
e optimality criteria can be solved exactly using a semi definite program  boyd   vandenberghe 
       there are however no known bounds on the integrality gap  i e   the loss incurred by this
rounding process 
the algorithms presented in section     can be used to optimally solve non fractional bayesian
experimental design problems for chain graphical models  even for continuous distributions  as
long as inference in these distributions is tractable  such as normal distributions   this paper hence
provides a new class of combinatorial algorithms for an interesting class of bayesian experimental
design problems 
    value of information in graphical models
decision theoretic value of information has been frequently used for principled information gathering  c f   howard        lindley        heckerman et al          and popularized in decision
analysis in the context of influence diagrams  howard   matheson         in a sense  value of
information problems are special cases of bayesian experimental design problems  where the prior
distribution has a particular structure  typically given by a graphical model as considered in this
paper 
several researchers  scheffer et al         van der gaag   wessels        dittmer   jensen 
      kapoor et al         suggested myopic  i e   greedy approaches for selectively gathering
evidence in graphical models  as considered in this paper  which  unlike the algorithms presented
in this paper  while these algorithms are applicable to much more general graphical models  they
do not have theoretical guarantees  heckerman et al         propose a method to compute the
maximum expected utility for specific sets of observations  while their work considers more general
graphical models than this paper  naive bayes models and certain extensions   they provide only
large sample guarantees for the evaluation of a given sequence of observations  and use a heuristic
without guarantees to select such sequences  bilgic and getoor        present a branch and bound
approach towards exactly optimizing value of information in more complex probabilistic models 
in contrast to the algorithms described in this paper however  their approach has running time that
is worst case exponential  munie and shoham        present algorithms and hardness results for
optimizing a special class of value of information objective functions that are motivated by optimal
educational testing problems  their algorithms apply to a different class of graphical models than
chains  and only apply for specific objective functions  rather than general local reward functions as
considered in this paper  radovilsky  shattah  and shimony        extended the previous version
of our paper  krause   guestrin      a  to obtain approximation algorithms with guarantees in the
case of noisy observations  i e   selecting a subset of the emission variables to observe  rather than
selecting among the hidden variables as considered in this paper  
    bandit problems and exploration   exploitation
an important class of sequential value of information problems is the class of bandit problems  in
the classical k armed bandit problem  as formalized by robbins         a slot machine is given
   

fik rause   g uestrin

with k arms  a draw from arm i results in a reward with success probability pi that is fixed for each
arm  but different  and independent  across each arm  when selecting arms to pull  an important
problem is to trade off exploration  i e   estimation of the success probabilities of the arms  and
exploitation  i e   repeatedly pulling the best arm known so far   a celebrated result by gittins
and jones        shows that for a fixed number of draws  an optimal strategy can be computed in
polynomial time  using a dynamic programming based algorithm  while similar in the sense that
an optimal sequential strategy can be computed in polynomial time  gittins algorithm however has
different structure from the dynamic programming algorithms presented in this paper 
note that using the function optimization objective function described in section      our
approach can be used to solve a particular instance of bandit problems  where the arms are not
required to be independent  but  in contrary to the classical notion of bandit problems  can not be
chosen repeatedly 
    probabilistic planning
optimized information gathering has been also extensively studied in the planning community 
bayer zubek        for example proposed a heuristic method based on the markov decision process framework  however  her approach makes approximations without theoretical guarantees 
the problem of optimizing decision theoretic value of information can be naturally formalized
as a  finite horizon  partially observable markov decision process  pomdp  smallwood   sondik 
       hence  in principle  algorithms for planning in pomdps  such as the anytime algorithm by
pineau  gordon  and thrun         can be employed for optimizing value of information  unfortunately  the state space grows exponentially with the number of variables that are considered in
the selection problem  in addition  the complexity of planning in pomdps grows exponentially in
the cardinality of the state space  hence doubly exponentially in the number of variables for selection  this steep increase in complexity makes application of black box pomdp solvers infeasible 
recently  ji  parr  and carin        demonstrated the use of pomdp planning on a multi sensor
scheduling problem  while presenting promising empirical results  their approach however uses
approximate pomdp planning techniques without theoretical guarantees 
in the robotics literature  stachniss  grisetti  and burgard         sim and roy        and
kollar and roy        have presented approaches to information gathering in the context of simultaneous localization and mapping  slam   none of these approaches however provide guarantees
about the quality of the obtained solutions  singh  krause  guestrin  kaiser  and batalin       
present an approximation algorithm with theoretical guarantees for the problem of planning an informative path for environmental monitoring using gaussian process models  in contrast to the
algorithms presented in this paper  while dealing with more complex probabilistic models and more
complex cost functions arising from path planning  their approach requires submodular objective
functions  a property that does not hold for value of information as we show in proposition    
    sensor selection and scheduling
in the context of wireless sensor networks  where sensor nodes have limited battery and can hence
only enable a small number of measurements  optimizing the value of information from the selected
sensors plays a key role  the problem of deciding when to selectively turn on sensors in order to
conserve power was first discussed by slijepcevic and potkonjak        and zhao  shin  and reich
        typically  it is assumed that sensors are associated with a fixed sensing region  and a spatial
   

fio ptimal value of i nformation in g raphical m odels

domain needs to be covered by the regions associated with the selected sensors  abrams  goel 
and plotkin        present an efficient approximation algorithm with theoretical guarantees for this
problem  deshpande  khuller  malekian  and toossi        present an approach for this problem
based on semidefinite programming  sdp   handling more general constraints and providing tighter
approximations  the approaches described above do not apply to the problem of optimizing sensor schedules for more complex utility functions such as  e g   the increase in prediction accuracy
and other objectives considered in this paper  to address these shortcomings  koushanfary  taft 
and potkonjak        developed an approach for sensor scheduling that guarantees a specified prediction accuracy based on a regression model  however  their approach relies on the solution of
a mixed integer program  which is intractable in general  zhao et al         proposed heuristics
for selectively querying nodes in a sensor network in order to reduce the entropy of the prediction  unlike the algorithms presented in this paper  their approaches do not have any performance
guarantees 
    relationship to machine learning
decision trees  quinlan        popularized the value of information as a criterion for creating
conditional plans  unfortunately  there are no guarantees on the performance of this greedy method 
the subset selection problem as an instance of feature selection is a central issue in machine
learning  with a vast amount of literature  see molina  belanche    nebot       for a survey  
however  we are not aware of any work providing similarly strong performance guarantees than the
algorithms considered in this paper 
the problem of choosing observations also has a strong connection to the field of active learning
 c f   cohn  gharamani    jordan        tong   koller        in which the learning system designs
experiments based on its observations  while sample complexity bounds have been derived for
some active learning problems  c f   dasgupta        balcan  beygelzimer    langford         we
are not aware of any active learning algorithms that perform provably optimal  even for restricted
classes of problem instances  
    previous work by the authors
a previous version of this paper appeared in the work by krause and guestrin      b   some of
the contents of section   appeared as part of the work by singhvi et al          the present version
is much extended  with new algorithmic and hardness results and more detailed discussions 
in light of the negative results presented in section    we cannot expect to be able to optimize value of information in more complex models than chains  however  instead of attempting
to solve for the optimal solution  one might wonder whether it is possible to obtain good approximations  the authors showed  krause   guestrin      a  krause et al         krause  leskovec 
guestrin  vanbriesen    faloutsos        that a large number of practical objective functions satisfy an intuitive diminishing returns property  adding a new observation helps more if we have few
observations so far  and less if we have already made many observations  this intuition can be formalized using the combinatorial concept called submodularity  a fundamental result by nemhauser
et al  proves that when optimizing a submodular utility function  the myopic greedy algorithm in
fact provides a near optimal solution  that is within a constant factor of     e       of optimal 
unfortunately  decision theoretic value of information does not satisfy submodularity 

   

fik rause   g uestrin

proposition    non submodularity of value of information   decision theoretic value of information is not submodular  even in naive bayes models 
intuitively  value of information can be non submodular  if we need to make several observations in
order to convince ourselves that we need to change our action 

   conclusions
we have described novel efficient algorithms for optimal subset selection and conditional plan computation in chain graphical models  and trees with few leaves   including hmms  our empirical
evaluation indicates that these algorithms can improve upon commonly used heuristics for decreasing expected uncertainty  our algorithms can also effectively enhance performance in interactive
structured classification tasks 
unfortunately  the optimization problems become wildly intractable for even a slight generalization of chains  we presented surprising theoretical limits  which indicate that even the class of
decision theoretic value of information functions  as widely used  e g   in influence diagrams and
pomdps  cannot be efficiently computed even in naive bayes models  we also identified optimization of value of information as a new class of problems that are intractable  nppp  complete 
for polytrees 
our hardness results  along with other recent results for polytree graphical models  the npcompleteness of maximum a posteriori assignment  park   darwiche        and np hardness
of inference in conditional linear gaussian models  lerner   parr         suggest the possibility of
developing a generalized complexity characterization of problems that are hard in polytree graphical
models 
in light of these theoretical limits for computing optimal solutions  it is a natural question to ask
whether approximation algorithms with non trivial performance guarantees can be found  recent
results by krause and guestrin      a   radovilsky et al         and krause et al         show that
this is the case for interesting classes of value of information problems 

acknowledgments
we would like to thank ben taskar for providing the part of speech tagging model  and reuters
for making their news archive available  we would also like to thank brigham anderson and andrew moore for helpful comments and discussions  this work was partially supported by nsf
grants no  cns          cns          aro muri w   nf        and a gift from intel 
carlos guestrin was partly supported by an alfred p  sloan fellowship  an ibm faculty fellowship and an onr young investigator award n                             andreas krause was
partially supported by a microsoft research graduate fellowship 

appendix a
proof of theorem    membership in  p for arbitrary discrete polytrees is straightforward since
inference in such models is in p  let  be an instance of   sat   where we have to count
the number of assignments to x            xn satisfying   let c    c            cm   be the set of
clauses  now create a bayesian network with  n     variables  x            xn   u            un and y 
where the xi are conditionally independent given y  let y be uniformly distributed over the values
   

fio ptimal value of i nformation in g raphical m odels

y
u 

u 

un


x 

x 

xn

figure    graphical model used in the proof of theorem   
 n   n                            m     m   and each ui have bernoulli prior with p        let the
observed variables xi have cpts defined the following way 

   if xi   u satisfies clause cj  
xi    y    j  ui   u  
   otherwise 

   if i   j 
xi    y   j  ui   u  
u  otherwise 
in this model  which is presented in figure    it holds that x    x         xn     iff u            un
encode a satisfying assignment of   and y      hence  if we observe x    x         xn     
we know that y     with certainty  furthermore  if at least one xi      we know that
p  y       x   x       let all nodes have zero reward  except for y  which is assigned a
reward function with the following properties  we will show below how we can model such a local
reward function using the decision theoretic value of information  
  n m  n
  if p  y       xa   xa       
m
r y   xa   xa    
  
otherwise 
by the above argument  the expected reward
x
r y   x            xn    
p  y   y p  u   u p  x  u r y   x   x 
u y x

 

x

p  y     p  u 

u sat 

x
 n   m  n
 
 
m
u sat 

is exactly the number of satisfying assignments to   note that the model defined above is not yet a
naive bayes model  however  it can easily be turned into one by marginalizing out u 
we will now show how we can realize a reward function with the above properties in the maximum expected utility sense  let d    d    d    be a set of two decisions  define a utility function
with the property 

 n m  n

 
if d   d  and y     

m
 n m   n  
u y  d   
  if d   d  and y     

    n
otherwise 
the reward r y   xa   is then given as the decision theoretic value of information 
x
x
r y   xa    
p  xa   max
p  y   xa  u y  d  
xa

d

   

y

fik rause   g uestrin

figure    graphical model used in proof of theorem   
the utility function u is based on the following consideration  upon observing a particular instantiation of the variables x            xn we make a decision d about variable y  our goal is to achieve
that the number of times action d  is chosen exactly corresponds to the number of satisfying assignments to   this is accomplished in the following way  if all xi are    then we know that the ui had
encoded a satisfying assignment  and y     with probability    in this case  action d  is chosen 
now we need to make sure that whenever at least one xi      which indicates either that y    
or u is not a satisfying assignment  decision d  is chosen  now  if at least one xi      then either
y   j     and clause j was not satisfied  or y      the utilities are designed such that unless
n
p  y       xa   xa       n  m   the action d  gives the higher expected reward of    hereby 
n n
 m is a lower bound on the probability of misclassification p  y       xa   xa   
note that the above construction immediately proves the hardness of approximation  suppose
there were a polynomial time algorithm which computes an approximation r that is within any
factor       which can depend on the problem instance  of r   r y   x            xn    then r    
implies that r      and r     implies that r      hence  the approximation r can be used to
decide whether  is satisfiable or not  implying that p   np 
proof of corollary    let  be a  cnf formula  we convert it into a naive bayes model over variables x            xn and y as in the construction of theorem    the function l v  where
v               n  is the set of all variables xi counts the number of satisfying assignments to  
note that the function l a  for a  v               n  is monotonic  i e   l a   l v  for all
a  v  as shown in proposition    hence the majority of assignments satisfies  if and only if
l v     n   
proof of theorem    membership follows from the fact that inference in polytrees is in p for discrete polytrees  a nondeterministic turing machine with  p oracle can first guess the selection
of variables  then compute the value of information using theorem    since such computation is
 p complete for arbitrary discrete polytrees   and compare against constant c 
to show hardness  let  be an instance of em ajsat   where we have to find an instantiation
of x            xn such that  x            x n   is true for the majority of assignments to xn             x n  
let c    c            cm   be the set of  cnf clauses  create the bayesian network shown in figure   
with nodes ui   each having a uniform bernoulli prior  add bivariate variables yi    seli   pari   
   i   n  where seli takes values in             m  and pari is a parity bit  the cpts for yi are

   

fio ptimal value of i nformation in g raphical m odels

defined as  sel  uniformly varies over             m   par       and for y            y n  

   if j      or ui satisfies cj  
seli    seli    j  ui   ui   
j  otherwise 
pari    pari    bi    ui    bi   ui  
where  denotes the parity  xor  operator  we now add variables zit and zif for    i  n and
let

uniform          if ui     
t
zi    ui   ui   
  
otherwise 
where uniform denotes the uniform distribution  similarly  let

uniform          if ui     
zif    ui   ui   
  
otherwise 
intuitively  zit     guarantees us that ui      whereas zit     leaves us uncertain about ui   the
case of zif is symmetric 
we use the subset selection algorithm to choose the zi s that encode the solution to em ajsat  
if zit is chosen  it will indicate that xi should set to true  similarly zif indicates a false assignment
to xi   the parity function is going to be used to ensure that exactly one of  zit   zif   is observed
for each i 
we first assign penalties  to all nodes except zit   zif for    i  n  and uj for
n      j   n  which are assigned zero penalty  let all nodes have zero reward  except for
y n   which is assigned the following reward 
 n
     if p  sel n       xa   xa       and
 p  par n       xa   xa       or p  par n       xa   xa        
r y n   xa   xa    

  
otherwise 
note that sel n     with probability   iff u            u n encode a satisfying assignment of   furthermore  we get positive reward only if we are both certain that sel n      i e   the chosen observation
set must contain a proof that  is satisfied  and we are certain about par n   the parity certainty
will only occur if we are certain about the assignment u            u n   it is only possible to infer the
value of each ui with certainty by observing one of ui   zit or zif   since  for i              n  the cost
of observing ui is   to receive any reward we must observe at least one of zit or zif   assume
that we compute the optimal subset o for budget  n  then we can only receive positive reward by
observing exactly one of zit or zif  
we interpret the selection of zit and zif as an assignment to the first n variables of em ajsat  
let r   r y n   o   we claim that   em ajsat if and only if r        first let
  em ajsat   with assignment x            xn to the first n variables  now add un             u n
to o and add zit to o iff xi     and zif to o iff xi      this selection guarantees r       
now assume r        we call an assignment to u            u n consistent if for any    i  n 
if zit  o  then ui     and if zif  o then ui      for any consistent assignment  the chance
that the observations zi prove the consistency is  n   hence r       implies that the majority of
all provably consistent assignments satisfy  and hence   em ajsat   this proves that subset
selection is nppp complete 
note that we can realize the local reward function r in the sense of maximum expected utility
similarly as described in the proof of theorem   
   

fik rause   g uestrin

proof of corollary    the constructions in the proof of theorem   and theorem   also prove that
computing conditional plans is pp hard and nppp  hard respectively  since  in these instances 
any plan with positive reward must observe variables corresponding to valid instantiations  i e   all
x            xn in corollary    and all un             u n and one each of the z            zn to satisfy the
parity condition in theorem     in these cases  the order of selection is irrelevant  and  hence  the
conditional plan effectively performs subset selection 
proof of corollary    the proof follows from the observation that polytree construction from the
proof of theorem   can be arranged into two dependent chains  for this transformation  we revert
the arc between zit and ui by applying bayes rule  to make sure there are the same number of
nodes for each sensor in each timeslice  we triple the variables yi   calling the copies yi  and yi    
the conditional probability tables are given as equality constraints  yi    yi and yi     yi    after
this transformation  the variables associated with timesteps  i     for i     are given by the sets
     z t    timesteps  i    are associated with the sets  u   y    and timesteps  i are associated
 yi 
i
i
i
with  zif   yi    
proof of proposition    this bound follows from the fact that maximization over a is convex  and
an application of jensens inequality  using an induction argument  we simply need to show that
l a   l   
 
x
x
l a   
p  xa   xa  
max eu  a  t  x   xa  t   xa  t  
xa

a

tv

 


x
tv

 

x
tv

max
a

x

p  xa   xa  eu  a  t  x   xa  t   xa  t  

xa

max eu  a  t  x    l  
a

where
eu  a  t  x   xa  t   xa  t    

x

p  xt   xa  t   xa  t  ut  a  xt  

xt

is the expected utility of action a at time t after observing xa  t   xa  t  
proof of proposition    consider the following binary classification problem with assymetric cost 
we have one bernoulli random variable y  the class label  with p  y            and
p  y             we also have two noisy observations x    x    which are conditionally independent given y  let p  xi   y         i e   the observations agree with the class label with
probability      and disagree with probability      we have three actions  a   classifying y as    
a   classifying y as     and a   not assigning any label   we define our utility functon u such that
we gain utility   if we assign the label correctly  u  a         u  a               is we misassign
the label  u  a         u  a             and   if we choose a    i e   not assign any label  now 
 
 
 
    
we can verify that l     l  x       l  x          but l  x    x                    
hence  adding x  to x  increases the utility more than adding x  to the empty set  contradicting
submodularity 

   

fio ptimal value of i nformation in g raphical m odels

references
abrams  z   goel  a     plotkin  s          set k cover algorithms for energy efficient monitoring
in wireless sensor networks   in ipsn 
balcan  n   beygelzimer  a     langford  j          agnostic active learning  in icml 
baum  l  e     petrie  t          statistical inference for probabilistic functions of finite state
markov chains  ann  math  stat               
bayer zubek  v          learning diagnostic policies from examples by systematic search  in uai 
bellman  r          a markovian decision process  journal of mathematics and mechanics    
bilgic  m     getoor  l          voila  efficient feature value acquisition for classification  in
twenty second conference on artificial intelligence  aaai  
boyd  s     vandenberghe  l          convex optimization  cambridge up 
boyen  x     koller  d          tractable inference for complex stochastic processes  in uncertainty in artificial intelligence  uai  
chaloner  k     verdinelli  i          bayesian experimental design  a review  statistical science 
              
cohn  d  a   gharamani  z     jordan  m  i          active learning with statistical models  j ai
research            
conll        
conference on computational natural language learning shared task 
http   cnts uia ac be conll     ner  
cover  t  m     thomas  j  a          elements of information theory  wiley interscience 
dasgupta  s          coarse sample complexity bounds for active learning  in nips 
deshpande  a   guestrin  c   madden  s   hellerstein  j     hong  w          model driven data
acquisition in sensor networks  in vldb 
deshpande  a   khuller  s   malekian  a     toossi  m          energy efficient monitoring in
sensor networks  in latin 
dittmer  s     jensen  f          myopic value of information in influence diagrams  in uai  pp 
        san francisco 
domingos  p     pazzani  m          on the optimality of the simple bayesian classifier under
zero one loss  machine learning             
durbin  r   eddy  s  r   krogh  a     mitchison  g          biological sequence analysis   probabilistic models of proteins and nucleic acids  cambridge university press 
gittins  j  c     jones  d  m          a dynamic allocation index for the discounted multiarmed
bandit problem  biometrika                
goldberg  l  a     jerrum  m          counting unlabelled subtrees of a tree is  p complete  lms
j comput  math             
heckerman  d   horvitz  e     middleton  b          an approximate nonmyopic computation for
value of information  ieee trans  pattern analysis and machine intelligence             

   

fik rause   g uestrin

howard  r  a          information value theory  in ieee transactions on systems science and
cybernetics  ssc    
howard  r  a     matheson  j          readings on the principles and applications of decision
analysis ii  chap  influence diagrams  pp          strategic decision group  menlo park 
reprinted      in decision analysis              
ji  s   parr  r     carin  l          non myopic multi aspect sensing with partially observable
markov decision processes  ieee transactions on signal processing                  
kapoor  a   horvitz  e     basu  s          selective supervision  guiding supervised learning with
decision theoretic active learning  in international joint conference on artificial intelligence
 ijcai  
keeney  r  l     raiffa  h          decisions with multiple objectives  preferences and value
trade offs  wiley 
ko  c   lee  j     queyranne  m          an exact algorithm for maximum entropy sampling 
operations research                
kollar  t     roy  n          efficient optimization of information theoretic exploration in slam  in
aaai 
koushanfary  f   taft  n     potkonjak  m          sleeping coordination for comprehensive sensing
using isotonic regression and domatic partitions  in infocom 
krause  a     guestrin  c       a   near optimal nonmyopic value of information in graphical
models  in proc  of uncertainty in artificial intelligence  uai  
krause  a     guestrin  c       b   optimal nonmyopic value of information in graphical models
  efficient algorithms and theoretical limits  in proc  of ijcai 
krause  a   leskovec  j   guestrin  c   vanbriesen  j     faloutsos  c          efficient sensor
placement optimization for securing large water distribution networks  journal of water resources planning and management         
krause  a   singh  a     guestrin  c          near optimal sensor placements in gaussian processes  theory  efficient algorithms and empirical studies  in jmlr 
lafferty  j   mccallum  a     pereira  f          conditional random fields  probabilistic models
for segmenting and labeling sequence data  in icml 
lerner  u     parr  r          inference in hybrid networks  theoretical limits and practical algorithms  in uai 
lindley  d  v          on a measure of the information provided by an experiment  annals of
mathematical statistics              
littman  m   goldsmith  j     mundhenk  m          the computational complexity of probabilistic
planning  journal of artificial intelligence research         
molina  l   belanche  l     nebot  a          feature selection algorithms  a survey and experimental evaluation  in icdm 
mookerjee  v  s     mannino  m  v          sequential decision models for expert system optimization  ieee trans  knowl  data eng                

   

fio ptimal value of i nformation in g raphical m odels

munie  m     shoham  y          optimal testing of structured knowledge  in twenty third conference on artificial intelligence  aaai  
papadimitriou  c  h          computational complexity  addison wesley 
park  j  d     darwiche  a          complexity results and approximation strategies for map
explanations  journal of aritificial intelligence research             
pineau  j   gordon  g     thrun  s          anytime point based approximations for large pomdps 
jair             
quinlan  j  r          induction of decision trees  machine learning           
radovilsky  y   shattah  g     shimony  s  e          efficient deterministic approximation algorithms for non myopic value of information in graphical models  in ieee international
conference on systems  man and cybernetics  smc   vol     pp           
robbins  h          some aspects of the sequential design of experiments  bulletin of the american
mathematical society             
scheffer  t   decomain  c     wrobel  s          active learning of partially hidden markov models
for information extraction  in ecml pkdd workshop on instance selection 
sim  r     roy  n          global a optimal robot exploration in slam  in ieee international
conference on robotics and automation  icra  
singh  a   krause  a   guestrin  c   kaiser  w  j     batalin  m  a          efficient planning of
informative paths for multiple robots  in international joint conference on artificial intelligence  ijcai   pp            hyderabad  india 
singhvi  v   krause  a   guestrin  c   garrett  j     matthews  h          intelligent light control
using sensor networks  in proc  of the  rd acm conference on embedded networked sensor
systems  sensys  
slijepcevic  s     potkonjak  m          power efficient organization of wireless sensor networks 
in icc 
smallwood  r     sondik  e          the optimal control of partially observable markov decision
processes over a finite horizon  operations research               
stachniss  c   grisetti  g     burgard  w          information gain based exploration using raoblackwellized particle filters  in robotics science and systems  rss  
tong  s     koller  d          active learning for parameter estimation in bayesian networks  in
nips 
turney  p  d          cost sensitive classification  empirical evaluation of a hybrid genetic decision
tree induction algorithm  journal of artificial intelligence research            
van der gaag  l     wessels  m          selective evidence gathering for diagnostic belief networks 
aisb quart            
zhao  f   shin  j     reich  j          information driven dynamic sensor collaboration for tracking
applications  ieee signal processing              

   

fi