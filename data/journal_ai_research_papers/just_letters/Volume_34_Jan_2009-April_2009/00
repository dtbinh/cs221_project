journal artificial intelligence research               

submitted        published     

interactive policy learning
confidence based autonomy
sonia chernova
manuela veloso

soniac cs cmu edu
veloso cs cmu edu

computer science dept 
carnegie mellon university
pittsburgh  pa usa

abstract
present confidence based autonomy  cba   interactive algorithm policy
learning demonstration  cba algorithm consists two components take
advantage complimentary abilities humans computer agents  first component  confident execution  enables agent identify states demonstration
required  request demonstration human teacher learn policy based
acquired data  algorithm selects demonstrations based measure action
selection confidence  results show using confident execution agent requires fewer demonstrations learn policy demonstrations selected
human teacher  second algorithmic component  corrective demonstration  enables
teacher correct mistakes made agent additional demonstrations
order improve policy future task performance  cba individual components compared evaluated complex simulated driving domain  complete
cba algorithm results best overall learning performance  successfully reproducing
behavior teacher balancing tradeoff number demonstrations
number incorrect actions learning 

   introduction
learning demonstration growing area artificial intelligence research explores
techniques programming autonomous agents demonstrating desired behavior
task  demonstration based approaches  teacher  typically human  shows agent
perform task  agent records demonstrations sequences stateaction pairs  learns policy reproduces observed behavior 
many learning demonstration approaches inspired way humans animals
teach other  aiming provide intuitive method transfer human task knowledge
autonomous systems  compared exploration based methods  demonstration learning
often reduces learning time eliminates frequently difficult task defining
detailed reward function  smart        schaal        
article  present interactive demonstration learning algorithm  confidencebased autonomy  cba   enables agent learn policy interaction
human teacher  learning approach  agent begins initial knowledge
learns policy incrementally demonstrations acquired practices task 
demonstration consists training point representing correct action performed
particular state  agents state represented using n dimensional feature vector
c
    
ai access foundation  rights reserved 

fichernova   veloso

composed continuous discrete values  agents actions bound
finite set action primitives  basic actions combined together perform
overall task  given sequence demonstrations  si   ai    state si teacherselected action ai a  goal agent learn imitate teachers behavior
generalizing demonstrations learning policy mapping possible
states actions a 
method gathering demonstrations heart demonstration learning
algorithms  cba performs function two algorithmic components  confident
execution  enables agent select demonstrations real time interacts
environment using automatically calculated confidence thresholds  corrective demonstration  enables teacher improve learned policy correct
mistakes additional demonstrations  complete confidence based autonomy
algorithm provides fast intuitive method policy learning  incorporating shared
decision making learner teacher  experimental evaluation 
highlight strengths learning components compare learning performance
five different demonstration selection techniques  results indicate complex
domain  confident execution algorithm reduces number demonstrations required
learn task compared demonstration selection performed human teacher 
additionally  find teachers ability correct mistakes performed agent
critical optimizing policy performance 
section    discuss related work learning demonstration  present
overview complete confidence based autonomy learning algorithm section   
followed detailed descriptions confident execution corrective demonstration
components sections      respectively  section    present experimental
evaluation complete algorithm components complex simulated driving
domain  section   presents summary discussion possible extensions work 

   related work
wide variety algorithms policy learning demonstration proposed
within machine learning robotics communities  within context reinforcement
learning  sutton   barto         demonstration viewed source reliable
information used accelerate learning process  number approaches
taking advantage information developed  deriving modifying
reward function based demonstrations  thomaz   breazeal        abbeel   ng 
      papudesi        atkeson   schaal         using demonstration experiences
prime agents value function model  takahashi  hikita    asada        price  
boutilier        smart        schaal        
demonstration coupled supervised learning algorithms policy
learning  including locally weighted regression low level skill acquisition  grollman  
jenkins        browning  xu    veloso        smart         bayesian networks high level
behaviors  lockerd   breazeal        inamura  inaba    inoue         k nearest
neighbors algorithm fast paced games robot navigation tasks  saunders  nehaniv 
  dautenhahn        bentivegna  ude  atkeson    cheng         recent survey covers
 

fiinteractive policy learning confidence based autonomy

demonstration learning algorithms detail  argall  chernova  browning 
  veloso        
addition policy learning demonstration  several areas research
explored algorithms demonstration selection  within machine learning research  active
learning  blum   langley        cohn  atlas    ladner        enables learner query
expert obtain labels unlabeled training examples  aimed domains
large quantity data available labeling expensive  active learning directs
expert label informative examples goal minimizing number
queries  context reinforcement learning  ask help framework enables
agent request advice agents confused action take 
event characterized relatively equal quality estimates possible actions given
state  clouse         similarly motivated techniques used robotics identify
situations robot request demonstration teacher  grollman  
jenkins        lockerd   breazeal        nicolescu        inamura et al         
closely related work dogged learning algorithm  grollman   jenkins        
confidence based learning approach teaching low level robotic skills  algorithm 
robot indicates teacher certainty performing various elements task 
teacher may choose provide additional demonstrations based feedback 
similarly motivated  work differs dogged learning algorithm number
ways  important use classification instead regression policy
learning  algorithms ability adjust confidence threshold data instead
using fixed value 

   confidence based autonomy overview
confence based autonomy algorithm enables human user train task policy
demonstration  algorithm consists two components 
confident execution  ce   algorithm enables agent learn policy based
demonstrations obtained regulating autonomy requesting help
teacher  demonstrations selected based automatically calculated classification
confidence thresholds 
corrective demonstration  cd   algorithm enables teacher improve
learned policy correcting mistakes made agent supplementary
demonstrations 
figure   shows interaction components  using confident execution algorithm  agent selects states demonstration real time interacts
environment  targeting states unfamiliar current policy action
uncertain  timestep  algorithm evaluates agents current state actively
decides autonomously executing action selected policy requesting
additional demonstration human teacher 
assume underlying model agents task mdp  agents policy
represented learned using supervised learning based training data acquired
demonstrations  confidence based autonomy combined supervised
 

fichernova   veloso

figure    confidence based autonomy learning process 
learning algorithm provides measure confidence classification  policy
represented classifier c    a  c  db   trained using state vectors si inputs 
actions ai labels  classification query  model returns model selected
action a  action selection confidence c  decision boundary db highest
confidence query  e g  gaussian component gmms  
effectively select demonstrations  learner must able autonomously identify
situations demonstration provide useful information improve policy 
confident execution selects agent autonomy request demonstration based
measure action selection confidence c returned classifier  given current
state learner  algorithm queries policy obtain confidence selecting
action state  regulates autonomy based confidence  learner
executes returned action ap confidence c threshold   determined
decision boundary classifier  db  confidence threshold indicates
agent uncertain action take  seeks help teacher
form demonstration  receiving additional demonstration  ad   low confidence
situation improves policy  leading increased confidence  therefore autonomy 
future similar states  training data becomes available  quality policy
improves autonomy agent increases entire task performed
without help teacher  section   compare two methods using classification
confidence select states demonstration 
using confident execution algorithm  agent incrementally acquires demonstrations explores environment  practices task  agent uses policy
learned point make decisions demonstration autonomous execution  however  relying policy learning complete  algorithm likely
 

fiinteractive policy learning confidence based autonomy

make mistakes due factors overgeneralization classifier incomplete
data area state space  address problem article introduces
second algorithmic component  corrective demonstration  allows teacher provide corrections agents mistakes  using method  incorrect action
observed  teacher provides additional demonstration agent indicating
action executed place  addition indicating wrong action selected  method provides algorithm correct action perform
place  ac   correction therefore informative negative reinforcement
punishment techniques common algorithms  leading agent learn quickly
mistakes 
together  confident execution corrective demonstration form interactive learning algorithm learner human teacher play complimentary roles  learner
able identify states demonstration required  fact  results show
algorithm able better human teacher due differences perception
representation abilities  teacher  hand  possesses expert knowledge
overall task  applied performing demonstrations spotting execution
mistakes  function agent cannot perform yet learned
desired behavior  way  confidence based autonomy takes advantage
complimentary abilities human agent  sections     present confident
execution corrective demonstration components detail 

   confident execution algorithm
confident execution policy learning algorithm agent must select demonstration examples  real time  interacts environment  timestep 
algorithm uses thresholds determine whether demonstration correct action
agents current state provide useful information improve agents policy 
demonstration required  agent requests help teacher  updates policy based resulting action label  otherwise agent continues perform task
autonomously based policy 
two distinct situations agent requires help teacher 
unfamiliar states ambiguous states  unfamiliar state occurs agent encounters situation significantly different previously demonstrated state 
represented outlying points figure    want demonstrate
every possible state  therefore need model generalize  would prevent
over generalization truly different states 
ambiguous states occur agent unable select multiple actions
certainty  situation result demonstrations different actions similar
states make accurate classification impossible  region overlapping data classes
figure    cases  additional demonstrations may help disambiguate situation 
goal confident execution algorithm divide state space regions
high confidence  autonomous execution  low confidence  demonstration 
unfamiliar ambiguous regions fall low confidence areas  given world state 
two evaluation criteria used select demonstration autonomy 
 

fichernova   veloso

nearest neighbor distance  given   n earestn eighbor s   distance
current state nearest  most similar  training datapoint  agent may act
autonomously distance threshold dist  
classification confidence  given c  classification confidence current state 
agent may act autonomously value c confidence threshold
conf  
methods calculating thresholds dist conf presented sections         
section  continue discussion confident execution algorithm assuming
values given 
algorithm   presents details confident execution algorithm  assume
preexisting knowledge task  initialize algorithm empty set
training points   since classifier initially available  threshold conf initialized
infinity ensure agent controlled demonstration initial
learning stage  distance threshold dist initialized   
main learning algorithm consists loop  lines        iteration
represents single timestep  behavior algorithm determined whether
agent currently executing action  action progress  algorithm performs
additional computation timestep  line      action complete 
algorithm evaluates state determine next action perform  lines       
evaluation begins obtaining agents current state environment  line    
information used calculate nearest neighbor distance query
learned classifier c obtain policy action ap confidence c  values
compared confidence distance thresholds decide demonstration
autonomy  line     similar states previously observed  learned model
confident selection  algorithm finishes timestep initiating autonomous

figure    outlying points regions overlapping data classes represent unfamiliar
ambiguous state regions  respectively 

 

fiinteractive policy learning confidence based autonomy

algorithm   confident execution algorithm
     
   conf inf
   dist  
   true
  
actioncomplete
  
getsensordata  
  
  nearestneighbor s 
  
 ap   c  db  c s 
  
c   conf   dist
   
executeaction ap  
   
else
   
requestdemonstration  
   
ad getteacheraction  
   
ad    n u
   
  s  ad   
   
c updateclassifier t  
   
 conf   dist   updatethresholds  
   
executeaction ad  
   
else
   
  do nothing

execution policy selected action ap  line      otherwise initiates request
teacher demonstration  lines        
agent requests demonstration pausing indicating teacher
demonstration required  note assume domain allows agent pause
execution  following demonstration request  algorithm checks whether demonstration performed  lines         teachers response available  new training
datapoint consisting current state corresponding demonstrated action ad
added training set  line      model classifier retrained  threshold
values updated  executing teacher selected action  lines        
teachers response immediately available  timestep terminates
whole process repeated next iteration  agent senses state  performs
threshold comparison checks demonstration  non blocking mechanism
enables agent wait demonstration teacher without losing awareness
surroundings  cases agents environment dynamic  maintaining
date information important state may change time initial
request demonstration  associating action label agents recent
state  one teacher likely responding to  therefore critical learning
accurate model  additionally  changes environment result agent attaining
high confidence state without actions own  cases  autonomous execution
task automatically resumed  summary  demonstration request made 
actions taken agent either demonstration received
teacher  changes environment result high confidence state 
 

fichernova   veloso

using approach  confident execution enables agent incrementally acquire
demonstrations representing desired behavior  datapoints acquired  fewer
states distant training data encountered  performance classification
confidence improve  autonomy agent increases  task learning complete
agent able repeatedly perform desired behavior without requesting demonstrations  following sections present methods calculating distance
confidence thresholds 
    distance threshold
purpose distance threshold evaluate similarity agents
current state previous demonstrations  evaluation metric uses nearest neighbor
distance  defined euclidian distance query closest point
dataset  agent state query  obtain nearest neighbor distance representing
similar previously demonstrated state  value compared distance
threshold dist  
value distance threshold dist calculated function average nearest
neighbor distance across dataset demonstrations  evaluating average similarity
states provides algorithm domain independent method detecting
outliers  points unusually far previously encountered states  trials article 
value dist set three times average nearest neighbor distance across
dataset 
alternate method detecting outliers would use classification confidence
request demonstrations low confidence states  however  situations arise
confidence directly correlated state similarity  example  many classifiers
set datapoints encircling empty region  similar shape donut  would result
highest classification confidence associated empty center region far
previous demonstrations  distance provides reliable prediction similarity  even
cases 
    confidence threshold
confidence threshold used select regions uncertainty points
multiple classes overlap  agents perspective  points regions represent
demonstrations two distinct actions states appear similar  difficult
distinguish based sensor data  problem frequently arises demonstration
learning number reasons  teachers inability demonstrate task
consistently  noise sensor readings  inconsistency agents
teachers sensing abilities  would set confidence threshold value
prevents either model classifying overlapping region high confidence   
following section discuss use limitations single fixed threshold value 
present algorithm using multiple adjustable thresholds section       
   see section     discussion data regions 

 

fiinteractive policy learning confidence based autonomy

 a 

 b 

 c 

figure    examples fixed threshold failure cases   a  fully separable data classes
overly conservative threshold value  b  overlapping data classes overly
general threshold value  c  data classes different distributions common
threshold value

      single fixed threshold
single  fixed confidence threshold value provides simple mechanism approximate
high confidence regions state space  previous algorithms utilizing classification confidence threshold behavior arbitration used manually selected single threshold
value  inamura et al         lockerd   breazeal        grollman   jenkins         however  choosing appropriate value difficult constantly changing dataset
model  figure   presents examples three frequently encountered problems 
figure   a  presents case two action classes distinct fully separable 
model trained dataset able classify points complete accuracy  without
misclassifications  however  current threshold value classifies     points
high confidence  marking remaining     points uncertain  case 
lower threshold value would preferred would allow model generalize
freely  resulting larger high confidence region would reduce number redundant
demonstrations without increasing classification error rate either data class 
figure   b  presents example opposite case  stricter threshold value
would preferred  example data classes overlap  resulting middle region
points cannot classified high accuracy  higher threshold value would
prevent classification points region either data class  initiating instead
request demonstration would allow teacher disambiguate situation 
figure   c  presents case datapoints two data classes
different distributions  fixed threshold value appropriate left class     
points right class labeled low confidence 
classification complex multi class data depends upon multiple decision boundaries 
using value decision boundaries exacerbate problems highlighted
above  single value often cannot found constrains model classification
areas allowing generalization others  resulting effect agent requests
many demonstrations things already knows  demonstrations
unlearned behavior  address problem  present algorithm calculating
unique threshold value decision boundary 
 

fichernova   veloso

 a 

 b 

 c 

figure    autonomy threshold calculation   a  example dataset  highlighted overlapping region  b  learned decision boundary  misclassified points marked
confidence values  c  learned threshold values data class  low confidence region containing overlapping points remains center 

      multiple adjustable thresholds
section  contribute algorithm calculating confidence threshold
decision boundary  customized unique distribution points  analysis 
assume able query classifier obtain confidence score representing
likelihood particular input belongs within specified decision boundary 
algorithm begins dividing dataset training test set training
classifier c  resulting learned model used classify withheld test set 
correct action labels known  algorithm calculates unique confidence
threshold decision boundary based confidence scores misclassified points 
given confidence scores set points mistakenly classified decision boundary 
assume future classifications confidences values likely
misclassifications well  threshold therefore calculated function
confidence scores 
specifically  define classified point tuple  o  a    c   original
observation  demonstrated action label  model selected action  c
model action confidence  let mi     o  ai     c  am    ai   set points
mistakenly classified decision boundary i  confidence threshold
pvalue set
mi

c

average classification confidence misclassified points  conf    mi     take
average avoid overfitting noisy data  values  based maximum standard
deviation  used conservative estimate required  threshold value  
indicates misclassifications occurred model able generalize freely 
figure   presents example threshold calculation process  figure   a  presents
small sample dataset  rectangular box figure highlights region state
space points classes overlap  figure   b  shows learned decision
boundary  in case svm  separating two data classes  six misclassified points
marked  mis  classification confidences returned model  misclassified points
side decision boundary used calculate respective confidence
thresholds  figure   c  shows confidence threshold lines values based
  

fiinteractive policy learning confidence based autonomy

 a 

 b 

 c 

figure    multiple adjustable thresholds applied failure cases shown figure   

calculations  resulting low confidence region middle image captures
noisy datapoints 
given multi threshold approach  classification new points performed first
selecting action class highest confidence query  comparison
line   algorithm   performed using threshold decision boundary
highest confidence query  using method  threshold value
likely decision boundary represent point used decide demonstration
autonomy 
figure   shows example failure cases discussed section       addressed
multi thresholded approach  customizing threshold value unique data
distribution enables algorithm correctly classify      points figures   a 
 c   since misclassifications  model generalizes freely examples 
dataset figure   b   perfect classification possible  confidence
thresholds set overlapping region falls low confidence area 
example uses gaussian mixture model  elliptical confidence gradient around
mean results large low confidence area even far overlapping region 
classification methods  support vector machines  drawback 
presented multi threshold approach algorithm independent  figure   presents
classification results four different classification methods  gaussian mixture models  random forests  rf   support vector machine quadratic kernel  svm radial
basis function  rbf  kernel  table summarizes classification performance
algorithm lists threshold values models 
algorithm
gmm
rf
svm quad 
svm rbf

correct misclas  unclass 
               
               
               
               

thresholds
             
              
                
               

table    classifier comparison 

  

fichernova   veloso

 a  gaussian mixture model

 b  random forest

 c  svm  quadratic 

 d  svm  rbf 

figure    classification dataset high low confidence regions using different classification methods 

   corrective teacher demonstration
presented confident execution algorithm enables agent identify unfamiliar
ambiguous states prevents autonomous execution situations  however  states
incorrect action selected high confidence autonomous execution
still occur  typically due over generalization classifier  article present
corrective demonstration algorithm which  coupled confident execution  enables
teacher correct mistakes made agent  algorithm   combines corrective
demonstration  lines denoted   confident execution presents complete
confidence based autonomy algorithm 
corrective demonstration technique comes play time agent executes
autonomous action  action selected autonomous execution  algorithm
records agents state led decision saves value within variable sc
 line      execution autonomously selected action  algorithm checks
teacher demonstration every timestep  lines         corrective demonstration
made  new training datapoint consisting recorded demonstration state sc
corrective action ac added training set  line      classifier thresholds
retrained using new information 
  

fiinteractive policy learning confidence based autonomy

algorithm   confidence based autonomy algorithm  confident execution corrective
demonstration
     
   conf inf
   dist  
   true
  
getsensordata  
  
actioncomplete
  
 ap   c  db  c s 
  
  nearestneighbor s 
  
c   conf   dist
   
executeaction ap  
   
sc

   
else
   
requestdemonstration  
   
ad getteacheraction  
   
ad    n u
   
  s  ad   
   
c updateclassifier t  
   
 conf   dist   updatethresholds  
   
executeaction ad  
   
else
   
autonomousaction

   
ac getteacheraction  

   
ac    n u

   
  sc   ac   

   
c updateclassifier t  

   
 conf   dist   updatethresholds  


using algorithm  teacher observes autonomous execution agent
corrects incorrect actions  unlike previous demonstration technique
agent given next action perform  correction performed relation
agents previous state mistake made  example  observing
driving agent approaching close behind another car  teacher able indicate
instead continuing drive forward  agent merging
passing lane  way  addition indicating wrong action performed 
corrective demonstration provides algorithm action
performed place  technique effective negative reinforcement 
punishment  techniques common algorithms  leading agent learn quickly
mistakes 
  

fichernova   veloso

figure    screenshot driving simulator  agent  black car currently
center lane  drives fixed speed must navigate around cars avoid
collisions  road consists five lanes  three traffic lanes two shoulder
lanes 

   evaluation comparison
section present evaluation comparison complete confidence based
autonomy algorithm components simulated car driving domain  abbeel   ng 
       shown figure   
    domain description
driving domain  agent represents car driving busy highway 
learners car travels fixed speed    mph  cars move lanes
predetermined speeds       mph  road three normal lanes
shoulder lane sides  agent allowed drive shoulder pass
cars  cannot go off road  since learner cannot change speed  must
navigate cars use shoulder lanes avoid collision  agent
limited three actions  remaining current lane  shifting one lane left
right current position  a    forward left right    teacher demonstrates task
keyboard interface  simulator framerate   fps paused
demonstration requests 
agents state represented by     l  dl   dc   dr    state feature l discrete value
symbolizing agents current lane number  remaining three features  denoted
letter d  represent distance nearest car three driving lanes
 left  center right   distance features continuously valued          range 
note nearest car lane behind agent  distance measurements
corrupted noise create complex testing environment  agents policy
relearned time    new demonstrations acquired 
driving domain presents varied challenging environment  car distances
discretized rounding nearest integer value  domain would contain
        possible states  due complexity domain  agent requires large
  

fiinteractive policy learning confidence based autonomy

number demonstrations initialize classifier  resulting nearly constant demonstration requests early training process  simplify task teacher  add
short     datapoint  approximately    second  non interactive driving demonstration
session initialize learning process  learning stage required  simplifies task teacher continuous demonstration preferred frequent
pauses demonstration requests 
performance learning algorithm evaluated time     new demonstrations acquired  evaluation  agent drove      timesteps road
segment fixed consistent traffic pattern  road segment used
training  instead algorithm trained using randomly generated car traffic pattern 
since algorithm aims imitate behavior expert  true reward function
exists evaluate performance given policy  present two domain specific evaluation metrics capture key characteristics driving task  first evaluation
metric agents lane preference  proportion time agent spends
lane course trial  metric provides estimate similarity driving
styles  since demonstrated behavior attempts navigate domain without collisions 
second evaluation metric number collisions caused agent  collisions
measured percentage total timesteps agent spends contact
another car  always driving straight colliding every car middle lane results
    collision rate 
    experimental results
present performance evaluation comparison following demonstration
selection techniques 
g teacher guided  demonstrations selected teacher without confidence feedback algorithm without ability perform retroactive
corrections
ces confident execution  demonstrations selected agent using single
fixed confidence threshold
cem confident execution  demonstrations selected agent using multiple
adjustable confidence thresholds
cd corrective demonstration  demonstrations selected teacher performed corrections response mistakes made agent
cba complete confidence based autonomy algorithm combining confident
execution using multiple adjustable confidence thresholds corrective demonstration
demonstration selection method  underlying policy agent learned
using multiple gaussian mixture models  one action class  chernova   veloso 
       videos driving task available www cs cmu edu soniac 
figure   presents performance results five algorithms respect
defined lane preference collision metrics  describe discuss elements
  

fichernova   veloso

figure    evaluation agents driving performance     demonstration intervals
five demonstration selection methods  bar graphs indicate
percentage time agent spent road lane  values bar
indicate percentage collision timesteps accrued evaluation trial 
teacher performance bar right figure shows teachers driving
lane preference collision rate evaluation road segment  goal
algorithm achieve performance similar teacher 

  

fiinteractive policy learning confidence based autonomy

figure detail following sections  evaluation  figure presents bar
representing composite graph showing percentage time spent agent
lane  value bar indicates number demonstrations upon
evaluated policy based  value bar indicates percentage incurred
collisions evaluation 
bar right figure shows performance teacher evaluation road segment  evaluation indicates teacher prefers drive center
left lanes  followed preference left shoulder  right shoulder right lane 
teacher successfully avoids collisions  resulting collision rate     goal
learning algorithm achieve driving lane pattern similar teacher
without collisions  note that  described previous section  policy learning
initialized     demonstration dataset algorithms  initialization
results identical performance across algorithms initial learning segment 
      g demonstration selection
top row figure   summarizes performance teacher guided demonstration
selection approach  approach  teacher performed training alternating
observing performance agent selecting demonstrations that  opinion 
would improve driving performance  teacher selected training examples without
receiving feedback action selection confidence  without ability provide
corrective demonstrations incorrect actions already executed agent 
instead  teacher required anticipate data would improve policy 
training process terminated teacher saw improvement agent
performance 
figure   shows results agents performance evaluations     demonstration
intervals throughout learning process  similarity driving lane preference
agent improves slowly course learning  significant fluctuations 
example      demonstrations  agents preference drive empty left
shoulder  thereby incurring collisions  one hundred demonstrations later  policy
shifted prefer center lane  however  agent yet learned avoid
cars  resulting       collision rate  policy stabilizes approximately     
demonstrations  representing driving style similar teacher  small
number collisions  without confidence feedback agent  difficult
teacher select exact termination point learning  training continued until 
     demonstrations  learners policy showed little improvement  final policy
resulted lane preference similar expert       collision
rate 
      ces demonstration selection
second row figure   presents results confident execution algorithm
single autonomy threshold  demonstration selection approach  demonstrations
selected agent learning terminated agent stopped requesting
demonstrations performed actions autonomously  autonomy threshold value
  

fichernova   veloso

selected hand evaluated multiple performance trials  results best fixed
threshold presented 
compared teacher guided approach  policy learned using ces algorithm
stabilizes quickly  achieving performance similar teachers     demonstrations  number collisions low persistent  even agent gains full
confidence stops requesting demonstrations      demonstrations  final lane
preference similar expert  collision rate      
      cem demonstration selection
third row figure   presents results confident execution algorithm
multiple autonomy thresholds  calculated using algorithm presented section        demonstration selection methods  cem required fewest number
demonstrations learn task  completing learning     demonstrations 
result indicates use multiple adjustable thresholds successfully focuses demonstration selection informative areas state space greatly reducing number
redundant demonstrations  throughout learning process  number gaussian
components within model varied       large variation highlights
importance automating threshold calculation process  since hand selecting individual
thresholds component would impractical  lane preference final policy
similar expert  however  agent still maintained small collision
rate      
      cd demonstration selection
evaluation first three algorithms highlights difficulty driving problem 
approaches able select demonstrations resulted policy
mimics overall driving style teacher  however  policies resulted
small number collisions  typically occurred agent merged close
another vehicle touched bumper  mistakes difficult correct using
techniques evaluated far  even within teacher guided demonstration selection
method  human teacher full control demonstration training data 
time collision observed incorrect decision already made
algorithm  instead  retroactive demonstration required correct already made
mistakes  corrective demonstration algorithm 
fourth row figure   present evaluation demonstration selection
using corrective demonstration algorithm  approach  demonstrations
selected teacher corrections response mistakes made agent 
behavior corrected teacher included collisions  well incorrect lane preference
 e g  always driving shoulder  rapid oscillations lanes  enable
teacher accurately perform corrections  simulation slowed     frames
per second  learning terminated agent required corrections 
shown figure    complete training process using corrective demonstration took    
demonstrations  achieving final policy correctly imitates teachers driving style
   collision rate  following section  discuss performance compares
complete cba algorithm 
  

fiinteractive policy learning confidence based autonomy

      cba demonstration selection
final row figure   presents evaluation complete confidence based autonomy algorithm  combines cem cd  using approach  learning complete
agent longer requests demonstrations able perform driving task
without collisions  using cba agent required total     demonstrations learn
task  successfully learning navigate highway without collisions 
analyze impact two cba learning components comparing number
distribution demonstrations acquired algorithm learning process 
section refer learning components cba cba ce cba cd
differentiate algorithm evaluations presented previous sections  note
behavior confident execution component dependent upon method used
set autonomy thresholds  evaluation use multiple adjustable thresholds
calculated average value misclassified points 
figure   a   datapoint along x axis represents number demonstrations
requested using cba ce  top  initiated teacher using cba cd  bottom 
    timestep interval  approximately    seconds simulator runtime  excluding pauses
demonstration requests   since first three     demonstration timesteps consist entirely non interactive demonstration  values timesteps     and  due
scaling  exceed bounds graph  figure   b  shows cumulative number
demonstrations component  total  grows respect training time 
complete training process lasts approximately hour half 
analysis graphs shows demonstrations occur early training
process  importantly  confident execution accounts     total number demon 

 a 

 b 

figure     a  timeline showing number demonstrations initiated agent
confident execution  top  initiated teacher corrective demonstrations  bottom  changes course training   b 
cumulative number demonstrations acquired component  total 
time 

  

fichernova   veloso

strations  indicating agent guides learning  demonstration requests occur first minutes training agent encounters
many novel states classification confidence remains low  agent requires
corrections stage many mistakes prevented requesting demonstration instead performing low confidence action  corrective demonstration plays
greatest role towards end training process  accounts     final
    demonstrations  stage learning agents action selection confidence
high enough rarely asks demonstrations  policy already closely imitates
teachers driving style small number collisions remain  corrective demonstration
enables teacher fine tune policy eliminate collisions  result highlights
importance corrective demonstration  whether alone conjunction another
selection technique  optimizing policy performance 
cba achieves similar final performance compared cd algorithm evaluated
previous section  requires approximately     additional demonstrations learn
policy  additional demonstrations attributed confident execution demonstration requests served increase classification confidence change
outcome agents action  viewed another way  datapoints correspond states
agent would performed correct action even asked
demonstration  result appears allowing agent make mistakes
correcting fact  done cd evaluation  may best demonstration
selection approach respect performance metrics defined overall
number demonstrations 
however  eliminating ability request demonstrations utilizing retroactive correction several drawbacks  namely requiring constant full attention
teacher  and  importantly  requiring agent make many mistakes learns
correct policy  comparison  cba algorithm enables agent request demonstrations low confidence states  thereby avoiding many incorrect actions  original
lane preference collision metrics take difference account focus
final policy performance agent 
evaluate difference algorithms  additionally examine number
collisions agent incurs course learning  using cd algorithm 
agent incurs     collisions      vs       training using cba 
therefore  allowing agent request demonstrations low confidence states 
cba algorithm requires slightly greater number demonstrations greatly reducing
number incorrect actions performed learning  reduction number
action errors significant due importance many learning domains  especially
robotic applications errors may pose dangers system 
summary  evaluation shown ability retroactively correct mistakes
crucial optimizing policy eliminating collisions  best performance
achieved corrective demonstration confidence based autonomy methods 
cd requiring fewer demonstrations incurring greater number collisions
training  choice cd cba therefore viewed tradeoff
number demonstrations frequency undesired actions training 
fact  cd special case cba autonomy threshold set classify
points high confidence  adjusting selectiveness cba autonomy thresholds
  

fiinteractive policy learning confidence based autonomy

could  therefore  provide user sliding control mechanism effects agents
tendency perform autonomous actions versus demonstration requests  importantly 
note overall number demonstrations required either approach less
teacher guided method tiny fraction overall state space 

   discussion
section  discuss several promising directions future work  well number
existing extensions presented learning methods 
    evaluation non technical users
presented demonstration learning algorithm provides fast intuitive method
programming adapting behavior autonomous agents  believe general
representation classifier independent approach makes cba usable wide range
applications  one particular application interest use demonstration learning
enable non technical users program autonomous agents  believe cba would
highly suitable application assume teacher technical
knowledge policy learning  requiring teacher expert task 
results presented article obtained using single teacher  one
authors  additional studies could evaluate algorithm usability performance wider
user base  non programmers particular 
    representation action choices
demonstration based learning provides natural intuitive interface transferring human task knowledge autonomous agents  however  operating rich environments 
agents inevitably face situations multiple actions equivalently applicable 
example  agent encounters obstacle directly path option moving
left right avoid it  surrounding space empty  directions equally valid
performing desired task  human demonstrators faced choice equivalent
actions typically perform demonstrations consistently  instead selecting among
applicable actions arbitrarily time choice encountered  result  training
data obtained agent lacks consistency  identical  nearly identical  states
associated different actions  presented cba algorithm  inconsistent
demonstrations would result persistent region low confidence  leading agent
repeatedly request demonstrations within inconsistent domain region  successfully extended cba identify regions state space conflicting demonstrations
represent choice multiple actions explicitly within agents policy  chernova   veloso      a  
    improvement beyond teacher performance
policy learned confidence based autonomy algorithm inherently limited
quality demonstrations provided human teacher  assuming
teacher expert task  approach aims imitate behavior teacher 
however  many domains teacher demonstrations may suboptimal limited
  

fichernova   veloso

human ability  several demonstration learning approaches developed enable
agent learn experiences addition demonstrations  thereby improving
performance beyond abilities teacher  stolle   atkeson        smart        
extending cba algorithm include similar capability remains promising direction
future work  possible approaches include incorporating high level feedback  argall 
browning    veloso        reward signal  thomaz   breazeal        teacher 
well filtering noisy inaccurate demonstrations 
    policy use learning
cba algorithm considers learning complete agent able perform
required behavior  repeatedly correctly  without requesting demonstrations
requiring corrections  policy learning complete  standard procedure
vast majority policy learning algorithms turn learning process freeze
policy  approach used algorithm  propose
continuing use confident execution component may long term benefits
beyond policy learning  particular  algorithms ability identify anomalous states
may enable agent detect notify user system errors unexpected input 
studies needed evaluate use algorithm  believe
mechanism would provide useful safety feature long term autonomous operation
negligible cost performing threshold comparison timestep 
    richer interaction
presented demonstration learning approach relies limited form interaction agent teacher  agent requests demonstrations teacher 
teacher responds single recommended action  level interaction
typical traditional active learning approaches  fails take full advantage
vast task knowledge teacher possesses  believe extending algorithm
include richer interaction abilities could provide faster intuitive training
method  many promising directions future research exist area  example 
developing domain independent dialog exchange agent teacher incorporates clarification questions high level advice could speed learning enable
agent represent high level goals task  ability play back rewind
demonstration sequences would additionally enable teacher agent reexamine
reevaluate past learning experiences 
    application single robot multi robot systems
learning demonstration techniques extensively studied within robotics
community due interactive nature fast learning times  work 
shown cba algorithm highly effective learning variety single robot tasks
 chernova   veloso            a  
furthermore  many complex tasks require collaboration multiple robots 
now  one greatest challenges preventing demonstration learning algorithms
generalizing multi robot domains problem limited human attention 
  

fiinteractive policy learning confidence based autonomy

fact teacher able pay attention to  interact with  robots
time  based cba algorithm  developed first multi robot
demonstration learning system addresses limited human attention problem
taking advantage fact confident execution component cba prevents
autonomous execution actions low confidence states  chernova   veloso      b  
flexmlfd system utilizes individual instances cba robot  learner
acquires unique set demonstrations learns individual task policy  preventing
autonomous execution low confidence states  cba makes learner robust periods
teacher neglect  allowing multiple robots taught time 

   conclusion
article presented confidence based autonomy  interactive algorithm policy
learning demonstration  using algorithm  agent incrementally learns
action policy demonstrations acquired practices task  cba algorithm
contains two methods obtaining demonstrations  confident execution component
enables agent select demonstrations real time interacts environment 
using confidence distance thresholds target states unfamiliar
current policy action uncertain  corrective demonstration component allows
teacher additionally perform corrective demonstrations incorrect action
selected agent  teacher retroactively provides demonstrations specific error
cases instead attempting anticipate errors ahead time  combined  techniques
provide fast intuitive approach policy learning  incorporating shared decision
making learner teacher 
experimentally  used complex simulated driving domain compare five methods
selecting demonstration training data  manual data selection teacher  confidencebased selection using single fixed threshold  confidence based selection using multiple
automatically calculated thresholds  corrective demonstration  confidence based selection combined corrective demonstration  based evaluation  conclude
confidence based methods able select informative demonstrations
human teacher  single multiple threshold approaches  multiple adjustable
threshold technique required significantly fewer demonstrations focusing onto regions
uncertainty reducing number redundant datapoints  best final policy performance  however  achieved corrective demonstration complete confidencebased autonomy algorithms  achieved lane preference similar
teacher without collisions  together  demonstration selection algorithms represent
tradeoff number demonstrations frequency undesired actions
training  corrective demonstration required slightly fewer demonstrations
learn final policy  compared cba resulted significant increase number
errors made agent course learning process  cba algorithm 
therefore  provides best demonstration selection method domains incorrect
actions desirable training process 
  

fichernova   veloso

acknowledgments
research partially sponsored department interior  national business
center contract no  nbchd       sri international subcontract no 
           bbnt solutions subcontract no             via prime air force
contract no  sa         c       views conclusions contained document
authors interpreted representing official policies 
either expressed implied  sponsoring institution  u s  government
entity  additional thanks paul rybski making simulation package available 

references
abbeel  p     ng  a          apprenticeship learning via inverse reinforcement learning 
proceedings international conference machine learning  new york  ny 
usa  acm press 
argall  b   chernova  s   browning  b     veloso  m          survey robot learning
demonstration  robotics autonomous systems  appear 
argall  b   browning  b     veloso  m          learning demonstration critique human teacher  second annual conference human robot interactions
 hri      arlington  virginia 
atkeson  c  g     schaal  s          robot learning demonstration  proceedings
international conference machine learning  pp        san francisco  ca 
usa  morgan kaufmann publishers inc 
bentivegna  d  c   ude  a   atkeson  c  g     cheng  g          learning act
observation practice  international journal humanoid robotics        
blum  a  l     langley  p          selection relevant features examples machine
learning  artificial intelligence                   
browning  b   xu  l     veloso  m          skill acquisition use dynamicallybalancing soccer robot  proceedings nineteenth national conference artificial
intelligence  pp         
chernova  s     veloso  m          confidence based policy learning demonstration
using gaussian mixture models  proceedings international conference
autonomous agents multiagent systems  pp     
chernova  s     veloso  m       a   learning equivalent action choices demonstration 
proceedings international conference intelligent robots systems 
pp           
chernova  s     veloso  m       b   teaching collaborative multi robot tasks
demonstration  proceedings ieee ras international conference humanoid robots 
clouse  j  a          integrating apprentice learning reinforcement learning  ph d 
thesis  university massachisetts  department computer science 
cohn  d   atlas  l     ladner  r          improving generalization active learning 
machine learning                 
  

fiinteractive policy learning confidence based autonomy

grollman  d     jenkins  o          dogged learning robots  ieee international
conference robotics automation  pp           
inamura  t   inaba  m     inoue  h          acquisition probabilistic behavior decision model based interactive teaching method  proceedings ninth
international conference advanced robotics  pp         
lockerd  a     breazeal  c          tutelage socially guided robot learning  proceedings ieee rsj international conference intelligent robots systems 
pp           
nicolescu  m  n          framework learning demonstration  generalization
practice human robot domains  ph d  thesis  university southern california 
papudesi  v          integrating advice reinforcement learning  masters thesis  university texas arlington 
price  b     boutilier  c          accelerating reinforcement learning implicit
imitation   journal artificial intelligence research             
saunders  j   nehaniv  c  l     dautenhahn  k          teaching robots moulding behavior scaffolding environment  proceeding  st acm sigchi sigart
conference human robot interaction  pp          new york  ny  usa  acm
press 
schaal  s          learning demonstration  advances neural information processing systems  pp            mit press 
smart  w  d          making reinforcement learning work real robots  ph d  thesis 
department computer science  brown university  providence  ri 
stolle  m     atkeson  c  g          knowledge transfer using local features  proceedings ieee international symposium approximate dynamic programming
reinforcement learning  pp       
sutton  r     barto  a          reinforcement learning  introduction  mit press 
cambridge  ma 
takahashi  y   hikita  k     asada  m          hierarchical multi module learning system
based self interpretation instructions coach  proceedings robocup      
robot soccer world cup vii  pp          
thomaz  a  l     breazeal  c          reinforcement learning human teachers  evidence feedback guidance implications learning performance  proceedings twenty first conference artificial intelligence  pp           

  


