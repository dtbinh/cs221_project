journal of artificial intelligence research                  

submitted        published      

compressing optimal paths with run length encoding
ben strasser

strasser   kit  edu

karlsruhe institute of technology
karlsruhe  germany

adi botea

adibotea   ie   ibm   com

ibm research
dublin  ireland

daniel harabor

daniel   harabor   nicta   com   au

nicta
sydney  australia

abstract
we introduce a novel approach to compressed path databases  space efficient oracles used to
very quickly identify the first edge on a shortest path  our algorithm achieves query running times
on the     nanosecond scale  being significantly faster than state of the art first move oracles from
the literature  space consumption is competitive  due to a compression approach that rearranges
rows and columns in a first move matrix and then performs run length encoding  rle  on the
contents of the matrix  one variant of our implemented system was  by a convincing margin  the
fastest entry in the      grid based path planning competition 
we give a first tractability analysis for the compression scheme used by our algorithm  we
study the complexity of computing a database of minimum size for general directed and undirected
graphs  we find that in both cases the problem is np complete  we also show that  for graphs which
can be decomposed along articulation points  the problem can be decomposed into independent
parts  with a corresponding reduction in its level of difficulty  in particular  this leads to simple and
tractable algorithms with linear running time which yield optimal compression results for trees 

   introduction
a compressed path database  cpd  is an index based data structure for graphs that is used to very
quickly answer first move queries  such a query takes as input a pair of nodes  namely a source node
s and a target node t  and asks for the first edge on a shortest st path  i e   a path from s to t   cpds
have successfully been applied in a number of contexts important to ai  for instance  copa  botea 
       a cpd based pathfinding algorithm  was one of the joint winners in the      edition of the
grid based path planning competition  or shorter gppc  sturtevant      b   a related algorithm 
mtscopa  is a fast method for moving target search over known and partially known terrain  botea 
baier  harabor    hernandez        baier  botea  harabor    hernandez        
given a graph g    v  e   a trivial cpd consists of a square matrix m with dimensions
 v     v    the matrix m  constructed during a precomputation step  stores in each cell m s  t  the
identity of a first edge on a shortest st path  we call this a first move matrix  by convention we
say that rows of m correspond to fixed source nodes and the columns to fixed target nodes  this is
optimal in terms of query time but the o  v      space consumption quickly becomes prohibitive for
larger graphs  the challenge is to design a compact representation of m that trades a small increase
in query times for a large decrease in space consumption 
c
    
ai access foundation  all rights reserved 

fis trasser   b otea     h arabor

a number of different techniques to compress a first move matrix have been suggested for this
purpose  sankaranarayanan  alborzi    samet        botea        botea   harabor      a   in
each case the objective is to conserve space by grouping together entries of m which all share a
common source node and which all store the same first edge information 
in this work we present the single row compression  src  and the multi row compression
 mrc  indexing algorithms for compressing all pairs shortest paths  in     s gppc  src outperformed all competitors in terms of query running time  the contributions presented in this article
go in three main directions  a new approach to compressing a first move matrix  experiments that
demonstrate advancing state of the art in terms of both response time and memory consumption 
and a thorough theoretical analysis  discussing np hardness results and islands of tractability 
we introduce a new matrix compression technique based on run length encoding  rle   the
main idea of our algorithm is simple  we compute an order for the nodes in the input graph and
assign numeric ids to nodes  e g   from   to  v    in this order  the purpose of the ordering is that
nodes which are located in close proximity in the graph have a small id difference  this ordering
is used to order the rows and the columns of a first move matrix  which is also computed during
preprocessing  then  we apply run length encoding  rle  to each row of the first move matrix  we
study three types of heuristic orderings  graph cut order  depth first order and input graph order  we
also study two types of run length encoding  the first involves a straightforward application of the
algorithm to each row  the second type is a more sophisticated multi row scheme that eliminates
redundancies between adjacent rle compressed rows  to answer first move queries we employ a
binary search on a fragment on the compressed result 
we undertake a detailed empirical analysis including comparisons of our techniques with stateof the art variants of cpds  botea         and hub labeling  delling  goldberg  pajor    werneck 
       copa is a recent and very fast cpd oracle which was among the joint winners at the     
international grid based path planning competition  gppc   using a variety of benchmarks from
the competition we show that our techniques improve on copa  both in terms of storage and query
time  hub labeling is a technique initially developed to speedup queries on roads  but they also
work on other graphs  such as gridmaps  hub labeling is to the best of our knowledge the fastest
technique known on roads  in experiments  we show that our approach leads to better query times
than hub labeling on graphs where we can reasonably compute m 
as our technique relies on an all pairs shortest path pre computation  it plays a tradeoff between
its query response speed  the preprocessing time and the memory required to store the compressed
path database  thus  our algorithm is faster  but it also requires a larger preprocessing time and
more memory than some of the other techniques from the literature  in other words  when memory
and preprocessing time are available  our technique will provide a state of the art speed performance  on the other hand  when larger and larger graphs create a memory and preprocessing time
bottleneck  other techniques should be considered  see a detailed comparison in the experiments
section 
in the theoretical analysis  we formally define and study optimal rle compression of first move
matrices produced from input graphs  we consider the case of directed input graphs and the case of
undirected weighted input graphs  we show that both versions are np complete  focusing on such
distinct types of graphs  each result brings something new compared to the other  related  kou 
      oswald   reinelt        and weaker  less specific  mohapatra        results on rle based
matrix compression are available in the literature  however  as known  the np hardness of a class
of problems does not necessarily imply the np hardness of a subset of the class  thus  despite
   

fic ompressing o ptimal paths with run l ength e ncoding

previous related results  mohapatra         it has been an open question whether the optimal rlecompression of a first move matrix computed from an input graph is tractable 
we also show that  for graphs which can be decomposed along articulation points  the problem
can be decomposed into independent subproblems  if optimal orderings are available for the subproblems  a global optimal ordering can easily be obtained  in particular  a depth first preorder is
optimal on trees  and the general ordering problem is fixed parameter tractable in the size of the
largest   connected component 
our approach and part of the evaluation have previously been reported in a shorter conference
paper  strasser  harabor    botea         the theoretical analysis was the topic of another conference paper  botea  strasser    harabor         putting these together in the current submission
provides a unique source that describes our method  its performance and its theoretical properties 
compared to the previous conference papers  we now provide complete proofs for all the theoretical
results  we have included more details and more examples in the presentation  for a better clarity 
we report additional results  such as the performance in the pathfinding competition gppc      
which were originally published in a paper about the competition  sturtevant  traish  tulip  uras 
koenig  strasser  botea  harabor    rabin        

   related work
many techniques from the literature can be employed in order to quickly answer first move queries 
standard examples include optimal graph search techniques such as dijkstras algorithm  dijkstra 
      and a   hart  nilsson    raphael         significant improvements over these methods can
be achieved by preprocessing the input graph  as done in cpds  for instance  as shortest paths
have numerous applications in various fields  a plethora of different preprocessing based algorithms
have been proposed  for an overview  we refer the interested reader to a recent survey article  bast 
delling  goldberg  mullerhannemann  pajor  sanders  wagner    werneck         a common
approach consists of adding online pruning rules to dijkstras algorithm  which rely on data computed in the preprocessing phase  significantly reducing the explored graphs size  as this approach
significantly differs from the technique described in this paper  we omit the details and refer the
interested reader to the aforementioned survey article 
silc  sankaranarayanan et al         and copa  botea   harabor      a  are cpd based techniques for a fast first move computation  silc employs a recursive quad tree mechanism for compression while copa uses a simpler and more effective  botea        decomposition with rectangles 
hub labels  hl  were initially introduced as   hop labels  cohen  halperin  kaplan    zwick 
       for nearly a decade there has not been much research on the topic  until abraham  delling 
goldberg  and werneck        showed that the technique is practical on huge road networks  and
coined the term hub labels  this realization drastically increased the interest in hl and thus
spawned numerous follow up works  such as  abraham  delling  goldberg    werneck       
delling  goldberg    werneck        abraham  delling  fiat  goldberg    werneck        akiba 
iwata    yoshida         in our context  the most relevant one is probably rxl  delling et al  
       which is a hl variant  the authors show that their algorithm works well not only on road
graphs but on a variety of graphs from different sources including graphs derived from maps used
during gppc  we compare our algorithm against rxl 
the hl index consists of a forward and backward label for each node  that contains a list of hub
nodes and the exact distances to them  for each st pair there must exist a meeting hub h that is a
   

fis trasser   b otea     h arabor

forward hub of s and a backward hub of t and is on a shortest st path  a shortest distance query
from a node s to a node t is answered by enumerating all common hubs of s and t  a labeling is
good if all labels only contain very few hubs  computing a labeling minimizing the index size is
np hard  babenko  goldberg  kaplan  savchenko    weller        
most works do not consider hl in its most general form  but consider a more restrictive variant
called hierarchical hub labels  hhl   this term was introduced by abraham et al         but
labels used in previous work  abraham et al         were already hierarchical  a labeling is called
hierarchical if an ordering of the vertices exists  such that every hub h of a vertex v comes after v
in the order  given a fixed node order  an optimal labeling can be computed efficiently  abraham
et al          the difficult task with hhl consists of computing the node order  computing a node
order minimizing the index size is also an np hard task  babenko et al         
hhl is deeply coupled with a different popular speedup technique for shortest path computations called contraction hierarchies  ch   geisberger  sanders  schultes    delling         ch
does not achieve the query speeds of hhl but has significantly smaller index sizes  however  for
most applications even ch query times are already faster than necessary  which makes ch a very
strong competitor  ch iteratively contracts nodes while inserting shortcuts to maintain all shortest
path distances in the remaining graph  by following the so inserted shortcuts only a small fraction
of the graph needs to be explored from every node  a node order is good for ch if the search
spaces of every node is small  again  computing an optimal order is np hard  bauer  columbus 
katz  krug    wagner         the first hl paper on road graphs  abraham et al         computed
the label of v by explicitly storing all nodes reachable from v in the ch search space and then applying some pruning rules  later papers have refined these rules  but every hierarchical label can be
viewed as an explicitly stored and pruned ch search space  a consequence is that node orders that
are good for ch are also good for hhl and vice versa  even though the formal optimization
criteria differ and therefore an optimal order for one of them with respect some criterion can be
slightly suboptimal for the other 
the node orders used for hhl and the original ch depend on the weights on the input graph 
substantial changes to the weights requires recomputing the node ordering  more recent work
 bauer  columbus  rutter    wagner        dibbelt  strasser    wagner        has introduced
customizable contraction hierarchies  cch  and shown that node orders exist and work well that
only depend on the structure of the input graph  these node orders exploit that the input graph has
small balanced node separators or has a comparative small treewidth 
in our paper we also consider two types of node orders  the first is a depth first search preorder
and the second is based on small balanced edge cuts  they are thus also independent of the input
graphs weights  however  do not confuse our orders with the cch node orders  they are not
interchangeable  using a cch ordering will result in bad performance with our technique  just as
using one of our node orders with cch will not work well  in fact  using a preorder with cch
maximizes the maximum search space in terms of vertices instead of minimizing it  that is  an
order that works well with our technique is a cch worst case node order  further  our orders can
also not be interchanged with the weight dependent orders needed for hhl and ch 
as described in the literature  hl answers distance queries  however  as hinted by abraham
et al          it is easy to extend hub labels to first move queries  to achieve this  the entries in
the forward and backward labels are extended with a third component  a first move edge id  if h
is a forward hub of s then the corresponding entry is extended using the first edge id of a shortest
sh path  if h is backward hub of t then the entry is extended with the first edge of a shortest ht path 
   

fic ompressing o ptimal paths with run l ength e ncoding

for a st query first the corresponding meeting hub h is determined  if s    h then the first move is
the edge id stored in the forward label s and otherwise the first move is contained in the backward
label of t  this slightly increases memory consumption but should have a negligible impact on
performance  note that distance values are needed even if one only wishes to compute first moves
as we need the distances to determine the right hub if s and t have several hubs in common 
in the context of program analysis it is sometimes desirable to construct an oracle that determines if a particular section of code can ever be reached  pwah  van schaik   de moor        is
one such example  similarly to our work  the authors precompute a quadratic matrix and employ
a compression scheme based on run length encoding  the main difference is that such reachability
oracles only return a yes no answer for every query rather than the identity of a first edge 
another speedup technique with low average query times is transit node routing  tnr   bast 
funke    matijevic        bast  funke  matijevic  sanders    schultes        antsfeld  harabor 
kilby    walsh         however  two independent studies  abraham et al         arz  luxen   
sanders        have come to the conclusion that  at least on roads  tnr is dominated by hl in
terms of query time  further  tnr does not optimize short range queries  a scenario that often
arises is a unit that chases another unit  in most situations both units tend to be very close  which
results in many short range queries  tnr is rather ineffective in this scenario 
bulitko  bjornsson  and lawrence        present a subgoal based approach to pathfinding  similarities to our work include a preprocessing stage where paths on a map are precomputed  after
which the results are compressed and stored into a database  the database is used to speed up the
response time when a path query is posed to the system  there are substantial differences between
the two approaches as well  our method precomputes all pairs shortest paths  eliminating graph
search entirely in the production mode  i e   the stage where the system is queried to provide full
shortest paths or fragments of shortest paths   in contrast  bulitko et al  restrict their precomputed
database to a subset of nodes  which in turn requires some additional search in the production mode 
the compression method is different in each case  our system provides optimal paths  which is not
guaranteed in the case of bulitko et al s method  besides bulitko et al         work  pathfinding
with sub goals turned out to be a popular and successful idea in more recent work  hernandez  
baier        bulitko  rayner    lawrence        lawrence   bulitko        uras  koenig   
hernandez        
pattern databases  pdbs   culberson   schaeffer        are lookup tables that provide heuristic
estimations of the true distance from a search node to a goal state  they are obtained by abstracting
an original search space into a smaller space  optimal distances in the abstracted space  from every
state to a pre established goal  are precomputed and stored into the pattern database as estimations
of the distances in the original space  as such  both techniques are memory based enhancements
in problems where the solution can be represented as a path in a graph  there are several key
distinctions between pdbs and cpds  pdbs are lossy abstractions  and they are specific to a goal
or subset of goals  cpds are lossless compressions  and encode shortest paths for every starttarget
pair  given their lossy nature  pdbs need to be used as heuristic within in a search algorithm  such
for example as a   as opposed to a complete and optimal method on its own  pdbs are commonly
used in large graphs  such as implicitly defined search spaces  where exploring the entire graph in
the preprocessing is impractical  in pdbs  the coarseness of the abstraction impacts the accurracy of
heuristic estimations  a finer abstraction has a better quality  but it can also result in a larger pdb 
work on addressing this bottleneck include compressing pattern databases  felner  korf  meshulam 
   

fis trasser   b otea     h arabor

  holte        samadi  siabani  felner    holte         in contrast  cpds compress all pairs
shortest paths 

   preliminaries
we denote by g    v  e  a graph with node set v and edge  set e  v  v   we denote by
deg u  the number of outgoing edges of u   the maximum out degree is denoted by   a node
order o   v       v    assigns to every node v a unique node id o v   the out going edges of every
node are ordered in an arbitrary but fixed order and their position  index in the ordering  is referred
to as their out edge id 
further  there is a weight function w   e  r       an st path is a sequence of edges a        ak
such that a  starts at s and ak ends at tp
and for every i the edge ai ends at the node where ai  
starts  the weight  or cost  of a path is i w ai    an st path is shortest if no other st path exists
with a strictly smaller weight  the distance between two nodes s and t is the weight of a shortest
st path  if one exists  if no st path exists  the distance is   notice that there may be multiple
shortest st paths but all of them have the same weight 
without loss of generality we can assume that no duplicate edges  multi edges  exist in our
graphs  as if there were  we could just drop all but a shortest edge  as the other edges are not used
by any shortest path  further  using a similar argument  we can assume without loss of generality
that no reflexive loops exist 
for s    t  an st first move is the first edge of a shortest st path  if there are multiple shortest
st paths  there may also be multiple st first moves  if no st path exists  no st first move exists  the
formal problem we consider is the following  given a pair of nodes s and t  find an st first move 
if there are several valid first moves  the algorithm can freely choose which to return 
given a oracle that answers first move queries  we can easily extract shortest paths  compute
an st first move a  in other words  a is the first edge of the shortest path  next  set s to the end of a 
as long as s    t  apply this procedure iteratively  notice  that this only works as edge weights are
guaranteed to be non zero  if we allowed zero weights  we could run into an infinite loop problem 
as the following example illustrates  consider a graph g with two nodes x and y connected by edges
xy and yx with weights zero  denote by t some other node in g  a valid xt first move is using xy 
further a valid yt first move is using yx  if the oracle always returned these two first moves  our
path extraction algorithm would oscillate between x and y and would not terminate 
a depth first search  dfs  is a way of traversing a graph and constructing a special sort of
spanning tree using backtracking  a depth first preorder is a node order that orders nodes in the
way that a dfs first sees them  the search is parameterized on the root node and on the order
in which the neighbors of each node are visited  in this work we will regularly refer to depthfirst preorders without stating these parameters  we always implicitly assume that the root is some
arbitrary node and that the neighbors are visited in some arbitrary order 
   the term arc is also used in the literature  sometimes  the distinction is made on whether the graph is directed  in
which case some authors prefer to say arcs  or undirected  in this paper  we stick with the term edge in all cases 
   in a directed graph  every ordered pair  u  v   e is an outgoing edge of u  in an undirected graph  every edge
incident to u is an outgoing edge of u 
   we assume that this is a function e  r   to be able to apply dijkstras algorithm during the preprocessing phase 
however  one could consider arbitrary weights without negative cycles and replace every occurrence of dijkstras
algorithm with the algorithm of bellman and ford  bellman        ford        

   

fic ompressing o ptimal paths with run l ength e ncoding

run length encoding  rle  compresses a string of symbols by representing more compactly
substrings  called runs  consisting of repetitions of the same symbol  for instance  string aabbbaaa
has three runs  namely aa  bbb  and aaa  a run is replaced with a pair that contains the start and the
value of the run  the start is the index of the first element in the substring  whereas the value is the
symbol contained in the substring  in our example  the first run aa has the start   and the value a 
run bbb has the start   and the value b  whereas the last run has the start   and the value a  
when the first and the last run have the same value  there is no need to encode both  the first
run can easily be reconstructed in constant time in this case  first  decide whether the first run has
been removed or not  this can be done by checking if the first run among the preserved ones has the
start equal to    secondly  if needed  reconstruct the first run  using   as a start position and a value
equal to the value of the last encoded run  another way of looking at this is that  if the first and
the last run have the same value  we can allow them to merge  as if we wrapped around the string
to form a cycle  when we allow this  we say we are using cyclic runs  otherwise  never consider
merging the ends of a string   we say we use sequential runs  see example   below 
given an ordered sequence of elements  string   we say that two positions are  adjacent if they
are next to each other  cyclic adjacent if they are adjacent or one is the first and the other is the last
position in the ordering  separated otherwise 
let  be an ordered sequence of elements  symbols  over a dictionary  or alphabet    given a
symbol     let an  run be an rle run containing symbol   for every string   we denote by
n    the total number of occurrences of symbol  in   further  the number of sequential  runs
is denoted by rs    and the number of of cyclic by rc     notice that    rs   rc        in
other words  the number of sequential runs and the number of cyclic runs never differ by more than
   finally  we denote by rs    the total number of sequential runs and by rc    the total number
of cyclic runs  in this paper  we assume that first move compression uses cyclic runs  unless we
explicitly say otherwise 
example    consider again the string    aabbbaaa  compressing  yields    a     b     a  this
means that after position   the string consists of as  similarily after position   there are bs and
finally after position   all elements are as until the string ends  we have na        and nb        
there are three sequential runs  namely aa  bbb and aaa  the first and the third ones are a runs 
whereas the middle one is a b run  thus  we have ras         rbs         and rs                
at the same time   has one cyclic a run  indeed  if we put next to each other the two ends of
the string  as if the string were cyclic  all occurrences of a in the string become one solid block  i e  
one cyclic a run   thus  rac         rbc         and rc                

   basic idea
as mentioned in the introduction  our algorithm starts by building a  v     v   all pairs first move
matrix m  the entry at position m i  j  is an ij first move  the central idea of our algorithm is
to compress each row of m using rle  the compression is performed gradually  as the matrix
rows are being computed  so that the uncompressed matrix does not have to be kept in memory  to
answer an st first move query  we run a binary search for t in the row of s  however  to achieve a
good compression ratio  we first reorder the columns of m to decrease the total number of runs  as
the columns correspond to nodes  we can regard the problem of reordering the columns as a problem
   alternative encodings exist  such as the value followed by the run length  e g   a     b     a    in the example 

   

fis trasser   b otea     h arabor

 
b  

a  
e  
 

c  
 

d  
 a  input

 
f   
 

t
s      
 a a a a
  ae f e
  e ed c
  f f dd
  c c c c
 b  first move matrix

 
 
 
 
 

  a
  a   e   f   e
  e   d   c
  f   d
  c

 c  compressed path database

figure    a toy example of our algorithm
of computing a good node order  computing an optimal node order that minimizes the number of
runs is np hard  as we show in our theoretical analysis  fortunately  a simple depth first preorder
works well in practice 
sometimes  in a formal analysis  some technical details are annoying in the sense that they
can make the presentation somewhat more complicated  the question of what symbol we should
use for m i  i  is such an example  in our practical implementation  we say that we do not care about
the symbol  as we never query for it  to reduce the number of runs we therefore assign it either the
value of m i     i  or m i      i   in our theoretical analysis  we make a similar assumption  i e  
a dont care symbol  in sections   and    as we will state in section    the assumption there is
that m i  i  is a symbol different from any edge symbol  in every case  our assumptions have the
purpose of keeping the analysis as simple as possible 
example    figure  a shows a toy weighted and undirected graph  with   nodes and   edges  for
each edge  we show its weight  cost   as a number  and a unique label  as a letter  a first move
matrix m of this graph  corresponding to the node ordering                is shown in figure  b 
recall that the entry m r  c   where r is a row and c is a column  is the id of the first move of a
shortest path from node r to node c  for example  m         e because e is the first step of ea 
an optimal path from node   to node    another optimal path would be the single step path b  as
both ea and b have an optimal weight  cost  of    thus  we are free to choose between m         e
and m         b  we prefer e because this leads to a better compression of row   in m  since the
first two symbols of the third row  being identical  will be part of the same rle run  we will show
in section   that breaking such ties in an optimal way is feasible and computationally easy  the
compression of m for the given node ordering  or equivalently  matrix column ordering  is shown
in figure  c 
notice that the ordering of the nodes impacts the size of a compressed matrix  in example   
swapping nodes   and    as illustrated in figure    would further reduce the number of rle runs
on row    as the two e symbols will become adjacent  the total number of runs decreases from   
runs to    runs  thus  the challenge is to find an optimal or at least a good enough node ordering 
where the objective function is the size of the compressed first move matrix 
the compression strategy with rle illustrated in example   is a key component of our approach  we study it theoretically in the next three sections  showing that computing an optimal
node ordering is np hard in general  and identifying tractability islands  we present a number of
effective heuristic node orderings in section    a variant of our implemented method  called src 
   

fic ompressing o ptimal paths with run l ength e ncoding

 
b  

a  
e  
 

c  
 

d  
 a  input

 
f   
 

t
s      
 a a a a
  af e e
  f f d d
  e e dc
  c c c c
 b  first move matrix

 
 
 
 
 

  a
  a   f   e
  f   d
  e   d   c
  c

 c  compressed path database

figure    the same toy example as in figure   but with a different node ordering  i e   nodes   and
  swapped  
performs the compression as illustrated in the example  another version of our program  called
mrc  goes beyond the idea of compressing each row independently  implementing a multi row
compression strategy  these are discussed in section   and evaluated empirically in section    

   first move compression for directed graphs
recall that the ordering of the columns of a first move matrix m affects the number of rle runs in
the matrix  in this section we show that obtaining an optimal ordering is intractable in general when
the input graph is directed  our construction works with uniform edge weights  for simplicitly we
therefore omit the weights in this section 
definition    the fmcomp d  first move compressiondirected  problem 
input  a directed graph g    v  e   a matrix m of size  v     v   where each cell m i  j  encodes
the first move on an optimal path from node i to node j  an integer k 
question  is there an ordering of the columns of m such that  if we apply rle on each row  the
total number of cyclic rle runs summed up for all rows is k 
theorem    the fmcomp d problem is np complete 
proof  it is easy to see that the problem belongs to np  as a solution can be guessed and verified in
polynomial time 
the np hardness is shown as a reduction from the hamiltonian path problem  hpp  in an
undirected graph  let gh    vh   eh   be an arbitrary undirected graph  and define n    vh  
and e    eh    starting from gh   we build an instance of the fmcomp d problem  according to
definition    such an instance includes a directed graph  which we call gf   the first move matrix
m of gf   and a number 
gf    vf   ef   is defined as follows  for each node u  vh   define a node in vf   we call
these nodes in vf type n nodes  to indicate they are created from original nodes in vh   for each
edge  u  v   eh   define a new node nuv  vf  type e nodes   for each new node nuv   define
two edges in ef   one from nuv to u and one from nuv and v  there are no other edges in ef   see
figure   for an example 
table   shows the first move matrix of the running example  given a type n node u  all other
nodes are unreachable from u in the graph gf   thus  the matrix row corresponding to u has only
   

fis trasser   b otea     h arabor

nxy

y

x

x

y

w

z

nxw
w

z

nwz
figure    left  sample graph gh   right  gf built from gh   in gf   x  y  w  z are type n nodes 
nodes nij have type e 

x
y
w
z
nxy
nxw
nwz

x
 
 
 
 
 
 

y
 
 
 
 
 
 

w
 
 
 
 
 
 

z
 
 
 
 
 
 

nxy
 
 
 
 
 
 

nxw
 
 
 
 
 
 

nwz
 
 
 
 
 
 
 

nr  cyclic runs
 
 
 
 
 
 
 

table    first move matrix for the running example  both rows and columns follow the node
ordering x  y  w  z  nxy   nxw   nwz  
one non trivial symbol   which we chose to be symbol    and which denotes that a node is not
reachable  such rows have one rle run each  regardless of the node ordering 
a matrix row corresponding to a type e node nuv has three distinct  non trivial  symbols in total 
one symbol for the edge to node u  another symbol for the edge to node v  and the non reachable
symbol   for every other node  without any generality loss  we use symbol   for the edge to u  and
symbol   for the edge to v  it is easy to see that  when nodes u and v are cyclic adjacent in a given
ordering  the nuv s row has   rle runs  when u and v are separated  the row will have   rle runs 
see table   for a few sample orderings 
we claim that hpp has a solution iff fmcomp d has a solution with  e     rle runs  let
vi    vi          vin be a solution of hpp  i e   a hamiltonian path in gh    and let p  eh be the set of
all edges included in this solution  we show that the node ordering in vf starting with vi            vin  
followed by the type e nodes in an arbitrary order  will result in  e       n     en    n
runs  with  n    runs in total for the type e rows  corresponding to edges in p     e  n      runs
in total for the remaining type e rows  and n runs in total for the type n rows 
   by trivial symbol we mean the that dont care symbol   recall that it has no impact on the number of runs  for
simplicity  we can safely ignore this symbol in our discussion 
   we say that a row has a type n  or type e  iff its associated node has that type 

   

fic ompressing o ptimal paths with run l ength e ncoding

indeed  for each edge  u  v   p   the type e row in m corresponding to node nuv  vf will
have   rle runs  since u and v are adjacent in the ordering  there are n    edges in a hamiltonian
path  with a total number of rle runs of   n     for all these rows 
for an edge  u  v  
  p   the two nodes are separated and therefore the corresponding matrix row
will have   runs  this sums up to   e  n      rle runs for all rows corresponding to edges not
included in the hamiltonian path 
conversely  consider a node ordering that creates  e         n         e  n        n rle
runs in total  we show that the ordering has all type n nodes as a contiguous block   and that their
ordering is a hamiltonian path in gh   this is equivalent to saying that there exist n    pairs of
type n nodes u and v such that u and v are cyclic adjacent in the ordering  and  u  v   eh  
here is a proof by contradiction  assume there are only p   n    pairs of type n nodes u and v
such that u and v are cyclic adjacent in the ordering  and  u  v  is an edge in eh   for each of these
p pairs  the row corresponding to the type e node nuv will have   rle runs  the remaining e  p
type e rows will be   rle runs each  as mentioned earlier  the type n rows have n runs in total 
regardless of the ordering  thus  the total number of rle runs is  p     e  p    n    e  p   n  
 e   n       n    e      contradiction 

   compression for undirected weighted graphs
we turn our attention to undirected weighted graphs  showing that computing an optimal ordering
is np complete 
definition    the fmcomp uw problem  first move compressionundirected  weighted  is defined as follows 
input  an undirected weighted graph g    v  e   a matrix m of size  v     v   where a cell m i  j 
stores the first move on an optimal path from node i to node j  an integer k 
question  is there an ordering of ms columns such that  if we apply run length encoding  rle  on
each row  the total number of cyclic rle runs in the matrix is at most k 
as a stepping stone in proving the np hardness of fmcomp uw  we introduce a problem that
we call simmini runs  definition     and prove its np completeness  simmini runs is inspired
by the work of oswald and reinelt         who have studied the complexity of a problem involving
the so called k augmented simultaneous consecutive ones property  c sk   for a     matrix  i e  
a matrix with only two symbols    and     by definition  a     matrix has the c sk property if 
after replacing at most k  s with  s  the columns and the rows of the matrix can be ordered so that 
for each row and for each column  all  s on that row or column come as one contiguous block 
oswald and reinelt        have proven that checking whether a     matrix has the c sk property
is np complete  our proof for simmini runs is related  as we point out later in the proof 
given a     matrix o  an ordering of its columns  and an ordering of its rows  let the global
sequential   runs count gs   o  be the number of sequential   runs summed over all rows and all
columns  that is 
x
gs   o   
r s    


   here  the notion of a contiguous block allows the case when part of the block is at the end of the sequence  and the
other part is at the beginning  as if the sequence were cyclic 

   

fis trasser   b otea     h arabor

o 

r 
r 



c 

c 

c 

 
 

 
 

 
 



figure    running example     matrix o  rows are labelled as ri   whereas cj represent column
labels 
where  is iterated through os rows and columns  for instance  gs   o      for the matrix o shown
in figure   
definition    the simultaneous mini   runs  simmini runs  problem is defined as follows 
input  a     matrix o so that every row and column contain at least one value of    an integer k 
question  is there an ordering of the columns  and an ordering of the rows  so that gs   o   k 
theorem    simmini runs is np complete 
the proof is available in appendix a 
lemma    let  be a     string so that it starts with a    or it ends with a    or both  then
r s      r c    
proof  case  i    starts with a   and ends with a    as the two end symbols are different  sequential
runs and cyclic runs are identical  as   runs and   runs alternate  their numbers are identical  case
 ii   when  starts with a   and ends with a    is similar to the previous one 
case  iii    has a   at both ends  as   runs and   runs alternate  and we have   runs at both
ends  it follows that r s      r s         r c    
theorem    fmcomp uw is np complete 
proof  the np hardness is shown with a reduction from simmini runs  consider an arbitrary
simmini runs instance o with m rows and n columns  figure   shows a running example  we
build an undirected weighted graph g    v  e  as follows  v has   types of nodes  to a total of
m   n     nodes  each column of o generates one node in v   we call these c nodes  each row
generates one node as well  r nodes   there is an extra node p called the hub node 
one r node ri and one c node cj are connected through a unit cost edge iff o ri   cj        in
addition  there is an edge with a weight of      between p and every other node  no other edges
exist in graph g  see figure   for an example 
let m be the first move matrix of g  the row of p has a fixed number of runs  namely m   n  
regardless of the ordering of ms columns  let v be a c node or r node  apart from vs adjacent
nodes  all other nodes are reached through a shortest path of cost     whose first move is the edge
 v  p   the matrix m for the running example is shown in figure   
let t  be the total number of occurrences of symbol   in matrix o  we claim that there is an
ordering of os rows and columns that results in at most k sequential   runs  summed up for all rows
and all columns  iff there is an ordering of the columns of m resulting in at most k    t    m   n
   recall that we can ignore the dont care symbol m p  p      which has no impact on the number of rle runs 

   

fic ompressing o ptimal paths with run l ength e ncoding

p

c 

c 

c 

r 

r 

figure    graph in the running example  dashed edges have a weight of      whereas solid lines
are unit cost edges 

r 

m 

r 



r 









c 
c 
c 
p

r 

c 

c 

c 

p

          
          
          
          
          
          










figure    the first move matrix for the running example  without any generality loss    is the move
towards p  the incident edges of a given node are counted starting from   
cyclic rle runs in total  summed up for all rows   thus all rows of m  except for ps row  have at
most k    t  runs in total 
let ri          rim and cj          cjn be the row and column orderings in o that result in at most k
sequential rle runs on all rows and columns  we show that the ordering ri          rim   cj          cjn   p
of ms columns generates at most k    t    m   n cyclic runs  clearly  for every row or column
 in o  there is a corresponding row    in m  see again figures   and   for an example   according
to the steps explained earlier and illustrated in figures   and       is obtained from  as follows 
all original  s are preserved  all original  s are replaced with distinct consecutive integers starting
from    in addition     is padded with  s at one or both of its ends  since    has  s at one or both its
ends  it follows that r s      r c         it follows that rc         r c       n       r s    n     
summing up rc       over all rows    of m  except for ps row  we obtain
x
    m   p 

rc        

x

r s     

 o 

x
 o 

n      k    t   

where  denotes the set of rows of a matrix   is the set of columns  and        it follows that
ms rows have at most k    t    m   n cyclic rle runs in total  that is  summed up for all rows  
conversely  assume an ordering of ms columns with at most k    t    m   n cyclic rle runs
in total  for all rows   this means that summing up the runs of all rows of m  except for node ps
row  results in at most k    t  runs  as there are exactly  t  distinct runs different from   runs  it
   r s      r c    from lemma    and r c      r c       by construction 

   

fis trasser   b otea     h arabor

follows that there are at most k   runs in total 
x
    m   p 

r c        k 

let ri          rim   cj          cjn   p be a re arragement of ms columns so that  all r nodes come in
one contiguous block  and their relative ordering is preserved  all c nodes are one contiguous block 
and their relative ordering is preserved 
since g restricted to c nodes and r nodes is bi partite  this rearrangement cannot possibly increase the number of rle runs   if anything  it could eliminate some   runs   this is not hard
to prove  for example  if the current matrix row corresponds to an r node a as a source node  we
have that m a  b      for every other r node b  since a  p  b is an optimal path from a to b  also 
m a  p       our rearrangement moves all nodes b into a block that is cyclic adjacent to p  which
does not create any new run  the case with a c node source is similar 
we order os columns as cj          cjn   and os rows as ri          rim   with these orderings  the
relation between a row or column  of o and its corresponding row    in m is as follows  all
non zero values in    are converted into  s in   some of     s from one or both of its ends are cut
away in   since    contains some  s at one or both ends  r s      r c        according to lemma   
it follows that
x
x
r s     
r c        k 
 o  o 

    m   p 

   fighting complexity with decomposition
so far all our results have been negative  we have shown that computing an optimal order on a large
class of graphs is np hard  in this section we identify tractability islands  we show that the problem
can be decomposed along articulation points  which are related to cuts of size     in particular  this
implies  as shown in this section  that a depth first preorder is an optimal node ordering on trees 
further we are able to construct optimal orders efficiently on a broader class of graphs than trees 
we show that the problem is fixed parameter tractable in the size of the largest component of the
graph that has no articulation points 
definition    we say that a node x of a graph g is an articulation point if removing x and its adjacent edges from g would split the graph into two or more disjoint connected subgraphs g        gn  
figure   shows an example  in the rest of this section we focus on graphs g with articulation
points x  we consider cyclic runs  in previous sections  we treated m s  s  as a dont care symbol 
with no impact on the number of runs  in this section  we make a different assumption  every cell
m s  s  gets its own distinct symbol  called the s singleton  which always creates its own run  and
which can not be merged with adjacent symbols into a common run  this makes the proofs easier
and clearly does not have a significant impact on the number of runs 
definition    we call an x block ordering any node ordering where x comes first  the nodes of g 
come next as a contiguous block  and so on all the way to block gn  
   

fic ompressing o ptimal paths with run l ength e ncoding

figure    a graph with an articulation point x  removing x would decompose the graph into four
disjoint components  depicted as g  to g   

in the example shown in figure    the ordering o   x  a  b  c  d  e  f  g is an example of an
x block ordering 
we use o g  to denote the projection of the node ordering o to a subset of nodes corresponding
to a subgraph g  of g  we use i to denote the subgraph induced by the nodes from gi   x    
we say that an order o is a rotation of another order o  when o is obtained from o  by taking a block
of o  s elements from the beginning and appending it to the end  for instance  d  e  f  g  x  a  b  c is
a rotation of x  a  b  c  d  e  f  g  more formally  o is a rotation of o  when two sub orders  and 
exist such that o       and o      
lemma    let x be an articulation point of a graph g  every node order o can be rearranged into
an x block ordering o  without increasing the number of runs on any row 
given a graph g  a node ordering o and a row subset s  let n  o  g  s  be the number of runs
restricted to subset s  clearly  n  o  g  g  is the total number of runs 
lemma    given any x block ordering o  we have that 
   n  o  g  gi     n  o i   i   gi    and
p
   n  o  g   x        n   i n  o i   i    x    and
p
   n  o  g  g       n   i n  o i   i   i   
the proofs to lemmas   and   are available in appendix b 
theorem    given an optimal order oi for every subgraph induced by i   we can construct an
optimal global ordering o for g as following  obtain new orderings o i by rotating oi such that x
comes first  and then removing x  then  o   x  o             o n is optimal 
proof  we show  by contradiction  that the global ordering o is optimal  notice that o i is optimal
for i   assume there is a strictly better ordering o    according to lemma    there exists an x block
    a subgraph induced by a subset of nodes s contains all nodes from s and all edges whose both ends belong to s 

   

fis trasser   b otea     h arabor

ordering o   at least as good as o    we have
n  o  g  g       n  

x

  n 

x

n  o i   i   i  

i

i

n  o    i   i   i  

  n  o     g  g   n  o    g  g 
which is a contradiction with o  being strictly better  i e   n  o    g  g    n  o  g  g   
lemma    if g is a tree and o is a depth first preorder of g  with arbitrary root  then o is a rotated
x block order for every node x 
proof  every preorder induces a rooted tree  with respect to this root every node x  except the root 
has a parent p and a possibly empty sequence of direct children c        cn ordered in the way that
the depth first search visited them  when removing x  g is decomposed into the subgraphs gp  
gc        gcn   if x is the root then gp is the empty graph  the order o has the following structure 
some nodes of gp   x  all nodes of gc        all nodes of gcn   the remaining nodes of gp   clearly this
is a rotated x block ordering 
theorem    if g    v  e  is a tree and o a depth first preorder of g then n  o  g  g      v      
proof  a direct consequence of lemma   is that every node v has as many runs as d v       where
d v  is the degree of the node  the    comes from the v singleton  we have thus
n  o  g  g   

x
vv

 d v           e     v       v      

theorem    computing an optimal order for graph g is fixed parameter tractable in the size of
largest two connected component of g  i e   the largest component with no articulation points  
proof  recursively decompose g at articulation points until only two connected parts are left  as
the size of the parts does not depend on the size of g we can enumerate all orders and pick the
best one  given optimal orders for every part we can use theorem   to construct an optimal global
order 
being able to decompose graphs along articulation points is useful on real world road networks 
these graphs tend to have a large two connected component with many small trees attached  for example the europe graph made available during the  th dimacs challenge  demetrescu  goldberg 
  johnson        has about   m nodes in total of which only     m are within the largest twoconnected component  our result allows us to position    m nodes in the order fast and optimally
using only local information 
   

fic ompressing o ptimal paths with run l ength e ncoding

   heuristic node orderings
in sections   and   we have shown that computing an optimal order is np hard in theory  fortunately  np hardness does not rule out the existence of good heuristic orderings that can be
computed quickly  indeed  a simple depth first preorder works very well in practice  this observation can partially be explained by the fact that  as shown in section    a depth first preorder is
optimal for trees  however  we can also explain it using more informal and intuitive terms 
an ordering is good if neighboring nodes in the graph are assigned neighboring ids  this is
consistent with the previous observation  sankaranarayanan et al         botea        that  if two
target nodes are close to each other  chances are that the first move from a current node towards
any of these targets is the same  a depth first preorder achieves the goal of assigning close ids to
neighboring nodes in low degree graphs  a node is either an interior node  the root  or a leaf in the
dfs tree  most of the nodes of a graph tend to be interior nodes  for these  a depth first preorder
will assign to two neighboring nodes adjacent ids  denote by v an internal node  by p its parent
and by c the first child of v  the id of p will be the id of v minus    whereas the id of c is the id
of v plus one  we can guarantee nothing for other children  however  if the average node degree is
low  as is the case in for example road graphs  then there just are not that many other children 
besides using depth first preorders  we also propose another heuristic that is based on the intuition of assigning close ids to close nodes  it is based on cuts  the above formulated intuitive
optimization criterion can also be formulated as following  for every edge  both endpoints should
have a close id  obviously this can not be fulfilled for all edges at once  for this reason the proposed ordering tries to identify a small set of edges for which this property may be violated  it does
this using balanced edge cuts  given a graph with n nodes we want to assign ids in the range     n 
using recursive bisection  in the first step our algorithm bisects the graph into two parts of nearly
equal node counts and a small edge cut size  it then divides the id range in the middle and assigns
the lower ids to one part and the upper ids to the other part  it continues by recursively bisecting
the parts and further dividing the associated id ranges until only parts of constant size are left  as
described so far the algorithm is free to decide to which part it assigns the lower and to which the
upper id ranges  for this reason we augment it by tracking for every node v two counters h v  and
  v  representing the number of neighbors with guaranteed higher and a lower ids  initially these
counters are zero  at every bisection after the ranges are assigned the algorithm iterates over the
edge cut increasing the counters for the border nodes  when deciding which of two parts p and q
gets which ranges it uses these counters to estimate the id distance of both parts to the nodes around
them  it evaluates
x
x
x
x
h v  
  v   
h v  
  v 
vq

vq

vp

vp

and assigns the higher ids to p if the condition holds  when the algorithm encounters a part that is
too small to be bisected it assigns the ids ordered by   v   h v  

   compression
let a        an denote an uncompressed row in the first move matrix  as stated previously  src
compresses it as a list of runs ordered by their start  as the compressed rows vary in size  we need
an additional index array that maps each source node s onto the memory offset of the first run in the
   

fis trasser   b otea     h arabor

row corresponding to s  we arrange the rows consecutively in memory and therefore the end of ss
row is also the start of s    s row  we therefore do not need to store the row ends 
    memory consumption
we required node ids to be encodable in    bits and out edge ids in   bits  we encode each runs
start in the upper    bits of a    bit machine word and its value in the lower   bits  the total memory
consumption is therefore      v         r  bytes where r is the total number of runs over all rows and
 v       is the number of offsets in the index array  notice that  in our implementation  we assume
that   bytes per index entry are sufficient  which is equivalent to saying that r         the formula
can easily be adapted to other sizes  i e   number of bits  for node ids  edge ids  and index entries 
for instance  when the sum of one node id and one edge id is k bytes  and j bytes are sufficient
to encode the index of any run  in other words  the number r fits into j bytes   the formula becomes
j    v          k  r bytes 
    computing rows
rows are computed individually by running a variant of dijkstras one to all algorithm for every
source node s and then compressed as described in detail in section      however  depending on the
graph it is possible that shortest paths are not unique and may differ in their first edge  it is therefore
possible that multiple valid uncompressed rows exist that tie break paths differently  these rows
may also differ in their number of runs and therefore have different compressed sizes  to minimize
the compressed size of a row  instead of using dijkstras algorithm to compute one specific row
a        an we modify it to compute sets a        an of valid first move edges  we require that for each
at  at a shortest st path must exist that uses at as its first edge  our algorithm maintains alongside
the tentative distance array d t  for each node t a set of valid first move edges at   if the algorithm
relaxes an edge  u  v  decreasing d v  it performs av  au   if d u    w u  v    d v  then it
performs av  av  au   as we restricted the out degree of each node to    we can store the at
sets as    bit bitfields  set union is performed using a bitwise or operation 
    compressing rows with run length encoding
for every target the compression method is given a set of valid first move edges and may pick the one
that minimizes the compressed size  we formalize this subproblem as following  given a sequence
of sets a        an find a sequence a        an with ai  ai that minimizes the number of runs  we
show that this subproblem can be solved optimally using a greedy algorithm  our algorithm begins
by determining the longest run t
that includes a    this
t is done by scanning over the a        ai ai  
until the intersection is empty  j   i  aj     but j   i    aj     the algorithm then chooses
a value from the intersection  it does not matter which  and assigns it to a        ai   it continues
by determining the longest run that starts at and contains ai   in the same way  this procedure
is iterated until the rows end is reached  this approach is optimal because we can show that an
optimal solution with a longest first run exists  no valid solution can have a longer first run  an
optimal solution with a shorter first run can be transformed by increasing the first runs length and
decreasing the second ones without modifying their values  as subsequences can be exchanged
without affecting their surroundings we can conclude that the greedy strategy is optimal 
   

fic ompressing o ptimal paths with run l ength e ncoding

 
b  

a  
e  
 

c  
 

d  

 
f   
 

 
 
 
 
 

  a
  a   f   e
  f   d
  e   d   c
  c

 a  input

 b  src

 
 
 
 
 

x
x   f   e
y   f
y   e   c
z

 c  mrc per row info 

x   a
y   d
z   c

 d  mrc per group info 

figure    mrc applied to the toy graph from figure    reproduced here for convenience  at the left 
part  b  illustrates the src input and the full runs rs of every row  part  c  show the groups  x 
y   or z  of each row and the row specific runs r  s   finally  part  d  depicts the runs r  g shared by
the rows in each group 

    merging rows using groups
to compress individual rows we have exploited that shortest paths from s to t  and t  often have
the same first move if t  and t  are close  a similar observation can be made for close source nodes
s  and s    their compressed rows tend to resemble each other  we want to further compress the
data by exploiting this redundancy  we call this technique multi row compression  mrc  and we
illustrate it in figure    we partition the nodes into groups and store for each group the information
shared by all nodes in the group  at each row we only store the information unique to it  denote
by g s  the unique group of node s  two runs in different rows with the same start and same value
will have the same    bit pattern  denote by rs the set of runs in the row of s  instead of storing
for each row t
s the whole set rs we store for each group h the intersection of all rows  that is  we
 
store r h   ih ri   for each row s we store r  s   rs   rg s    recall that a query with target t
consists of finding max x  rs   x   t     where t      t        notice that this formula can be
rewritten using basic set logic as max max x  r  s   x   t     max x  r  g s    x   t     which
can be implemented using two binary searches if all r  i are stored as ordered arrays  note that we
need a second index array to lookup the r  g for the groups g 
    computing row groups
by design close source nodes have close node ids and thus neighbouring rows  this motivates
restricting ourselves to row run groupings  that is  for each group h there are rows i and j such
that all rows in  i  j  belong to the group  an optimal row run grouping can be computed using
dynamic programming  denote by s n  the maximum number of runs saved compared to using no
group compression restricted to the first n rows  notice that s         given s          s n  we
want to compute s n       obviously the n    s row must be part of thet
last group  suppose that
the last group has length   then we save in total s n                     i n    n    ri   runs 
as there are only n different values for   we can enumerate  with brute force  all possible values 
resulting in an algorithm with a running time in  n     we observe that the intersection of large
groups often seems to be nearly empty and therefore we only test values for        resulting in a
 n  heuristic 
   

fis trasser   b otea     h arabor

    queries
given a source node s and a target node t  with s    t  the algorithm determines the first edge of
a shortest st path  it does this by first determining the start and the end of the compressed row
of s using the index array  it then runs a binary search to determine the run containing t and the
corresponding out edge id  more precisely the algorithm searches for the run with the largest start
that is still smaller or equal to t  recall that we encode each run in a single    bit machine word
with the higher    bits being the runs start  we can reinterpret these    bits as unsigned integers 
the algorithm then consists of a binary search in an ordered    bit integer for the largest element
not larger than   t       i e   t in the higher    bits and all   lower bits set  
extracting a path using cpds is an extremely simple recursive procedure  beginning at the start
node we extract the first move toward the target  we follow the resultant edge to a neighbouring
node and repeat the process until the target is reached 

    experimental setup
to evaluate our work we consider two types of graphs  road graphs and grid based graphs  in
all cases we assume that node ids can be encoded within    bit integers  further we assume that
      and that we use a distinct value      to indicate an invalid edge  this allows us to encode
out edge ids within   bits  note that the concatenation of a node id and an out edge id fits into a
single    bit machine word 
our experiments were performed on a quad core i       cpu       ghz with  mb of combined cache   gb of ram running ubuntu        all algorithms were compiled using g        
with  o   all reported query times use a single core 
     grid graphs
we have chosen three benchmark problem sets drawn from real computer games  the first two sets
of benchmark instances have appeared in the      grid based path planning competition  the third
benchmark set consists of two worst case maps in terms of size  these two maps are available as part
of nathan sturtevants extended problem repository at http   movingai com benchmarks 
but are not part of the      competition set 
 the first benchmark set features    maps that come from the game dragon age origins 
these maps have   k nodes and    k edges  on average 
 the second benchmark set features    maps that come from the game starcraft  these
maps have    k nodes and     m edges  on average 
 the third benchmark set comprises two large grids which we evaluate separately  these are
the largest maps available for the two games  from the extended dragon age origins
problem set we choose the map called ost   d  it has    k nodes and    m edges  from
the extended starcraft problem set we choose the map called thefrozensea  it has
   k nodes and    m edges  note that ost   d  while being the largest dragon age
origins map  is smaller than the average starcraft map 
all grid maps under evaluation are undirected and feature two types
 of edges  straight edges which
have a weight of     and diagonal edges which have a weight of   
   

fic ompressing o ptimal paths with run l ength e ncoding

     road graphs
in the case of road graphs we have chosen several smaller benchmarks made available during the
 th dimacs challenge  demetrescu et al         
 the new york city map  henceforth  ny  has    k nodes and    k edges 
 the san francisco bay area  henceforth  bay  has    k nodes and    k edges 
 finally  the state of colorado  henceforth  col  has    k nodes and  m edges 
for all three graphs travel time weights  denoted using a  t suffix  and geographic distance weights
 denoted using  d  are available 
     comparisons
we implemented our algorithm in two variants  single row compression  src  not using the row
merging optimization  and multi row compression  mrc   using this optimization  we compare
both these approaches with two recent and state of the art methods  copa  botea   harabor      b 
and rxl  delling et al          we evaluate two variants of copa  the first variant  which we
denote copa g  appeared at the      gppc and is optimised for grid graphs  we use the original
c   implementation which is available from the competition repository  sturtevant      a   the
second variant  which we denote copa r  is optimised for road graphs  this algorithm is described
in  botea   harabor      a   we used the original c   implementation of this program version as
well 
rxl is the newest version of the hub labeling algorithm  we asked the original authors to
run the experiments for us presented below  these experiments were carried out on a xeon e             ghz  to compensate for the lower clock speed  when compared to our test machine 
we scale the query times of rxl by a factor of                  it is important to note that this
implementation of rxl computes path distances instead of first moves  as discussed in section  
this should not make a significant difference for query times  however it is unclear to us whether it is
possible to incorporate the additional data needed for first move computation into the compression
schemes presented by delling et al          the reported rxl database sizes should therefore be
regarded as lower bounds 

    results
we evaluate our two algorithms  src and mrc  in terms of preprocessing time  compression
performance and query performance  we also study the impact of a range of heuristic node orderings
using these same metrics  there are three such variants  each distinguished by suffix  the suffix  cut
indicates a node ordering based on the balanced edge separators graph cutting technique described
in section    the suffix  dfs indicates a node ordering based on depth first search traversal  again as
described in section    the suffix  input  or shorter  inp  indicates the order of the nodes is taken
from the associated input file  in the case of grid graphs we ordered nodes lexicographically  first by
y  and then by x coordinates  where applicable we compare our work against the state of the art
first move algorithms copa r and copa g  we also compare against the very recent hub labeling
technique known as rxl and a more space efficient  but not as fast  variant called crxl 
   

fis trasser   b otea     h arabor

benchmark
dimacs
dragon age origins
starcraft
ost   d
thefrozensea

average preprocessing time  seconds 
compute order
single row compression
multi row compression
 cut
 dfs
 input
 cut
 dfs
 input
 cut
 dfs
 input
  
  
 
    
    
    
    
    
    
 
  
 
  
  
  
  
  
  
  
  
 
    
    
    
    
    
    
  
  
n m
   
   
n m
   
   
n m
   
  
n m
    
    
n m
    
    
n m

table    preprocessing time for road and grid graphs  we give results for  i  the average time required to
compute each node ordering   ii  the total time required to compute the entire database for each of src and
mrc  values are given to the nearest second  the ost   d and thefrozensea preprocessing experiments
were run on an amd opteron      with    cores       ghz to accelerate the apsp computation  the
experiments on the smaller graphs clearly show that the input order is fully dominated  we therefore omit the
numbers for the two larger test graphs  n m stands for not measured 
graph
 v  

 e 
 v  

copag

 cut

min    k
 
q 
 k    
med
 k    
avg   k    
q 
  k    
max    k    

  
  
 
  
  
  

  
  
  
 
 
  

min
q 
med
avg
q 
max

  
   
   
   
   
   

  
  
  
   
   
   

   k
   k
   k
   k
   k
   k

   
   
   
   
   
   

db size  mb 
query time  nano seconds 
mrc
src
mrc
src
um copag
 dfs  inp  cut  dfs  inp
 cut  dfs  inp  cut  dfs
dragon age  origins     maps 
              
  
  
        
     
              
 
  
        
     
 
 
    
 
    
  
        
     
 
  
 
 
  
     
   
        
     
  
  
 
  
  
    
   
               
                     
   
                
starcraft     maps 
  
  
                    
               
                      
   
                
                        
   
                
                         
   
                 
                          
   
                 
                                
                   

 inp
  
  
  
  
  
   
  
   
   
   
   
   

table    performance of src and mrc on grid graphs  we use two problem sets taken from the     
gppc and compare against copa g  one of the winners of that competition  we measure  i  the size of the
compressed database  in mb  and   ii  the time needed to extract a first query  in nanos   all values are
rounded to the nearest whole number  either mb or nano  respectively   as a baseline  column um shows
the size of a naive  non compressed first move matrix 

     preprocessing time
table   gives the average preprocessing time for src and mrc on the   road graphs and the two
competition sets  the time in each case is dominated by the need to compute a full apsp table 
as we have previously commented  apsp compression is the central point of our work  not the
apsp computation  our preprocessing approach involves executing dijkstras algorithm repeatedly
resulting in a total running time of o n  log n  on sparse graphs with non negative weights  using
modern apsp techniques  e g   delling  goldberg  nowatzyk  and werneck       succeeded in
significantly reducing the hidden constants behind the big o and are able to exploit more specific
graphs structures  e g   road graphs  to get the running time down  however  these techniques do
not give a benefit over repeatedly running dijkstras algorithm in the asymptotic worst case 
   

fic ompressing o ptimal paths with run l ength e ncoding

graph
name

 v  

 e 
 v  

bay d
bay t
col d
col t
ny d
ny t

   k
   k
   k
   k
   k
   k

   
   
   
   
   
   

db size  mb 
query time  nano seconds 
copa hub labels
mrc
src
copa hub labels
mrc
src
um
 r rxl crxl  cut  dfs  cut  dfs
 r rxl crxl  cut  dfs  cut  dfs
      
  
                                               
      
  
                                             
          
                                                
      
  
                                              
      
  
                                                
      
  
                                               

table    comparative performance of src  mrc  copa r and two recent hub labeling algorithms  we
also report the size um of an uncompressed matrix  we test each one on six graphs from the  th dimacs
challenge  we measure  i  database sizes  in mb    ii  the time needed to extract a first query  in nanos  
values are rounded to the nearest whole number  graph sizes are rounded to the nearest thousand nodes 

creating a node order is fast   dfs requires only fractions of a second  even the  cut order
requires no more than    seconds on average using metis  karypis   kumar         meanwhile 
the difference between the running times of src and mrc indicate that multi row compression
does not add more than a small overhead to the total time  for most of our test instances the
recorded preprocessing overhead was on the order of seconds 
     compression and query performance
in table   we give an overview of the compression and query time performance for both copa g
and a range of src and mrc variants on the competition benchmark sets  to measure the query
performance we run     random queries with source and target nodes picked uniformly at random
and average their running times 
mrc outperforms src in terms of compression but at the expense of query time  node orders
significantly impact the performance of src and mrc  in most cases  cut yields a smaller database
and faster queries  src and mrc using  cut and  dfs convincingly outperform copa g on the
majority of test maps  both in terms of space consumption and query time 
a naive  non compressed first move matrix is impractical due to the very large memory requirements  the size an uncompressed matrix would have is     v    bits  reflecting our assumption that
an outgoing edge can be stored in   bits  for tables       and   we specify in column um the memory consumption of an uncompressed matrix  for example  for the ost   d game graph with    k 
a non compressed matrix requires a bit more than  gb of memory  which is more than two orders of magnitude higher than the   mb  respectively   mb that src cut respectively mrc cut
need  for larger graphs  the difference is more striking  for example thefrozensea  our largest
game graph  with    k nodes leads to a    mb mrc cut database compared to    gb in a noncompressed matrix  on the other hand  for the smaller graphs where the matrix would fit in memory 
fetching up moves would be extremely fast  being one table lookup per move  for comparison  to
fetch one move  our method performs a binary search in a compressed string whose length is no
larger  and usually much smaller than  v   
in table   we look at the performance for the   road graphs and compare copa r  src  mrc 
rxl and crxl  the main observations are that on road graphs  dfs leads to smaller cpds than
 cut  surprisingly  the lower average row lengths do not yield faster query times  copa r is dominated by rxl  src  and mrc  src cut outperforms all competitors by several factors in terms of
   

fis trasser   b otea     h arabor

graph
name
ost   d
frozensea

 v  

 e 
 v  

   k
   k

   
   

db size  mb 
mrc
src
um
rxl crxl  cut  dfs  cut  dfs
  
  
  
  
  
  
    
       
                      
hub labels

query time  nano seconds 
hub labels
mrc
src
rxl crxl  cut  dfs  cut  dfs
        
      
  
  
                        

table    performance of src and mrc on large grid graphs from nathan sturtevants extended repository 
we compare against the hub labeling methods rxl  and crxl  we also report the size um of an uncompressed matrix  we run tests on thefrozensea  drawn from the game starcraft  and ost   d  which comes
from the game dragon age origins  we measure  i  database sizes  in mb    ii  the time needed to extract a
first query  in nanos   values are rounded to the nearest whole number  rxl   crxl exploit that the graphs
are undirected while src   mrc do not  for directed graphs the space consumption of rxl would double 

graph
bay d
bay t
col d
col t
ny d
ny t
frozensea
ost   d

average row and label
length
space  bytes 
src
sampg
src
sampg
 cut  dfs   plain  cut  dfs
  
       
   
       
  
  
  
   
       
  
       
   
       
  
   
  
   
       
  
       
    
       
  
       
   
       
  
       
    
         
  
  
   
    
       

table    we report the average number of hubs per label  length   number of runs per row  length   and
average space usage per node for sampg plain and src 

speed  rxl wins in terms of the database size  however the factor gained in space is smaller than
the factor lost in query time compared to src  crxl clearly wins in terms of space but is up to two
orders of magnitude slower than the competition  on road graphs distance weights are harder than
travel time weights  this was already known for algorithms that exploit similar graph features as
rxl  however  it is interesting that seemingly unrelated first move compression based algorithms
incur the same penalties 
in table   we evaluate the performance of src  mrc  rxl and crxl on the larger game
maps  we dropped copa r because from the experiments on the smaller graphs it is clear that it is
fully dominated  other than on road graphs  the space consumption for src and mrc is lower for
the  cut order than for  dfs  as a result the  cut order is clearly superior to  dfs on game maps 
on ost   d both src and mrc beat rxl in terms of query time and of space consumption  on
thefrozensea rxl needs less space than src and mrc  however  note that on game maps rxl
gains a factor of   by exploiting that the graphs are undirected which src and mrc do not 
crxl employs powerful compression techniques specific to shortest paths  rxl does not use
them but it is not uncompressed as it uses some basic encoding techniques such as delta encoding  a
basic hl variant that stores all nodes and distances explicitly needs more memory  we refer to this
basic variant as sampg plain  sampg is the ordering algorithm used in rxl   and plain refers
    the rxl paper describes several node orders  however  sampg is the order they suggest using  all other rxl and
crxl numbers in our paper use sampg 

   

fic ompressing o ptimal paths with run l ength e ncoding

 
b  

a  
e  

 
f   

 
c  
 

d  

 

 a  input graph

 b  computing rectangles

 c  list of rectangles

figure    copas rectangle decomposition on the toy example from figures   and   for the first
moves from source node    similar decompositions are needed for every other source node 

to an elementary hl encoding with   bytes per hub id and   bytes per distance value  we want
to comparse src with sampg plain  we therefore report in table   the average number of hubs
per label and the average number of runs per row using src  the reported number of hubs is per
label  note that on directed graphs every node needs two labels  a forward and a backward label 
on undirected graphs the two labels coincide and only one has to be stored  this contrasts with
src which cannot exploit that the input graph is undirected  the numbers in the table therefore
assume that two hl labels are needed per node for better comparability  for hl we need to store
a    bit distance value  a    bit node id and a   bit out edge id and this times   because of there
being two labels per node  the total space consumption is thus   h bytes where h is the average
number of hubs per label  for src we need to store a    bit node id and a   bit out edge id per
run  this results in  r bytes where r is the average number of runs per row  for table   it can be
seen that sampg plain consistently occupies more space than src  even though the experiments
thus far suggest that rxl is more compact  the basic compression techniques in rxl are therefore
important and are enough to make the performance ordering of the algorithms tip with respect to
space consumption 
rxl has some advantages not visible in the tables  for example it does not require computing
an apsp in the preprocessing step significantly reducing preprocessing time  further it computes
besides the first move also the shortest path distance 
     discussion
we compared src and mrc with copa and rxl  copa is a recent and successful technique for creating compressed path databases  as one of the joint winners at the      grid based path planning
competition  gppc     we regard copa as the current state of the art for a range of pathfinding
problems including the efficient storage and extraction of optimal first moves  rxl is the newest
version of the hub labeling algorithm and to our knowledge the state of the art in terms of minimizing query times on road graphs 
   

fis trasser   b otea     h arabor

src and mrc have been illustrated in figures      and    figure   illustrates how copa
works in preprocessing  for a better understanding of this section  without any intention of a fully
detailed description  copa assumes that every node in the graph is labelled with x  y coordinates 
our toy example has   rows and   columns  as shown in figure    a   copa iterates through all
nodes in the graph  let n be the current node  source node  at a given iteration  copa splits the
map into rectangles  and labels each rectangle with the id of an outgoing edge from n  when a
target t belongs to a given rectangle  the optimal move from n towards t is precisely the label of that
rectangle  figure    a  shows the map decomposition for the source node    with rectangles depicted
with a dashed line  there are three rectangles constructed in the figure  one at the bottom left  with
size      and label e  one at the top left  with size      and label a  and one at the bottom right 
having size      and label f   in part  b   each rectangle is represented with   symbols each  upper
row  left column  width  height  label  here we show just the rectangles for source node    but this
is concatenated with the lists of all other nodes  some of the rectangles can safely be removed  list
trimming  but we skip this in our example  then  each of the   columns in figure    a  is treated
as a separate string  and it is further compressed with sliding window compression and run length
encoding 
we performed experiments on a large number of realistic grid graphs used at gppc    and find
that both src and mrc significantly improve on both the query time and compression power of
copa  for a large number of experiments and on a broad range of input maps we were able to extract
a first move in just tens or hundreds of nano seconds  a factor of   to   faster than copa   there are
two main reasons why src and mrc are performant vs  copa  our approach uses less memory
and our query running time is logarithmic  cf  linear  in the label size 
our approach requires less memory than copa  part of the explanation stems from the differences between the sizes of the building blocks in each approach  in src and mrc  the building
block is an rle run represented with two numbers  the start of the run  which is a node id and
thus requires log    v    bits  and the value of the run  which is an out edge id and requires log    
bits  in copa  a building block is a rectangle that requires   log    v      log     bits  in the actual
implementations  both src and mrc store only a single    bit machine word per run  which allows for graphs with up to     nodes  the copa code used in the      grid based path planning
competition stores a rectangle on    bits  corresponding to a max node count of      
clearly  the size of the building blocks is not the only reason for the different compression
results  the number of rle runs in src or mrc can differ from the total number of rectangles
in copa  when more than one optimal out edge exists  src and mrc select an edge that will
improve the compression  whereas copa sticks with one arbitrary optimal out edge  on the other
hand  besides rectangle decomposition  copa implements additional compression methods  such as
list trimming  run length encoding and sliding window compression  all performed on top of the
original rectangle decomposition  botea   harabor      a  
our approach has an asymptotic query time of o log   k   where k is the number of compressed
labels that must be searched  by comparison  given a source node  copa stores its corresponding
list of rectangles in the decreasing order of their size  rectangles are checked in order  while  in the
worst case  the total number of rectangle checks is linear in the size of the list  the average number
is much improved due to the ordering mentioned  botea        botea   harabor      a  
the reason why a cpd is faster than rxl is due to the basic query algorithm  the algorithm
underlying rxl consists of a merge sort like merge of two integer arrays formed by the forward
label of s and the backward label of t  this is a fast and cache friendly operation but needs to look
   

fic ompressing o ptimal paths with run l ength e ncoding

at each entry resulting in an inherently linear time operation  src on the other hand builds upon a
binary search which is slightly less cache friendly as memory accesses are not sequential it but has
a logarithmic running time 
one can regard the compressed src rows as one sided labels  for each st pair the first move
can be determined using only the label of s  hl on the other hand needs the forward label of s and
the backward label of t  hl labels tend to have less entries than the src labels  however  each
hl entry needs more space as they need to store the distance values in addition to node ids 

    results from the      grid based path planning competition
we have recently submitted the algorithms src cut and src dfs to the      edition of the gridbased path planning competition gppc  sturtevant         in this section we give a brief overview
of the competition and a short summary of results  a full description of the methodology employed
by the organisers  as well as a full account of the results  is given in  sturtevant et al         
     competition setup
the grid based path planning competition features over one hundred grid maps from which more
than three hundred thousand distinct problem instances are drawn  individual maps differ in size 
ranging from several thousand to several million nodes  the topography of the maps is also varied
with many maps originating from the computer games starcraft  dragon age  origins and dragon
age    other maps appearing as part of the competition are synthetically generated grids  mazes 
rooms and randomly placed obstacles of varying density  in the      edition of the competition
there were a total    different entries  submitted by   different teams  several entries are variants of
the same algorithm and are submitted by the same team 
   entries employ symmetry breaking to speed up search  the entries bljps  bljps   jps 
and jps bucket can roughly be described as extensions of jump point search  harabor  
grastien        and jps   harabor   grastien         the entry nsubgoal makes use of
multi level subgoal graphs  uras   koenig         finally the entry named bljps sub is a
hybrid algorithm that makes use of both jump point search and subgoal graphs 
   entry  ch  employs a variation on contraction hierarchies  dibbelt et al         
   entries directly improve the performance of the a  algorithm  either through the use of faster
priority queues  a  bucket  or by trading optimality for speed  ra  and ra  subgoal  
   entries use compressed path databases  two of these  src dfs i and src cut i  are
incremental algorithms that return the optimal path one segment at a time  that is  they must
be called repeatedly until the target location is returned  the other two algorithms  src dfs
and src cut  are non incremental and when queried return a complete path 
unfortunately    entries contained some bugs and therefore did not finish on all instances 
src cut was one of them  we therefore omit them from the tables and the discussion 
     results
a summary of results from the competition is given in table    we observe the following 
   

fis trasser   b otea     h arabor

entry


ra 
bljps
jps 
bljps 

ra  subgoal
jps  bucket
bljps  sub
nsubgoal
ch
src dfs
src dfs i

averaged query time over all test paths  s 
slowest move
first    moves
full path
in path
of path
extraction
       
       
       
      
      
      
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
   
   
   
   
   
   
   
   
   
 
 
   

preprocessing requirements
db size
time
 mb 
 minutes 
 
   
  
   
   
   
  
   
   
   
   
   
   
   
   
   
     
     
      
       
      
       

table    results from the      grid based path planning competition  figures are summarised
from the official competition results  which appear in  sturtevant et al          entries denoted
by  indicate approximate algorithms that are not guaranteed to always find the shortest path  the
measurments in bold indicate which entry performed best with regard to this single criterion  the
entries whose name are in bold are those that are not fully pareto dominated with respect to every
criterion  the preprocessing running times are the time needed to process all     test maps 
   our cpd based entries are the fastest methods at the competition across all query time metrics  this includes the fastest  average  time to required to extract a complete optimal path  the
fastest  average  time to extract the first    steps of an optimal path and the fastest  average 
time required to extract any single step of an optimal path 
   performing a first move query with our algorithm is faster than the resolution of the competitions microsecond timer  even iteratively extracting    edges of a path is only barely
measurable without a finer timer resolution  during testing we observed that a significant
amount of the query running time was spent within the benchmarking code provided by the
competition  we therefore opted to submit two variants  src dfs extracts the path as a
whole  the benchmarking code is thus only run once per path  on the other hand src dfs i
extracts the path one edge at a time  this allows measuring the time needed by an individual
first move query  unfortunately  it also requires executing the benchmarking code once per
edge  the difference in path extraction running times between src dfs and src dfs i  i e  
  s  is the time spent in the benchmarking code 
   our algorithm is the only competitor that is able to answer first move queries faster than a
full path extraction 
   because our entries are database driven they require generous amounts of preprocessing time
and storage space  src dfs therefore had the largest total preprocessing time and the largest
total storage cost of all entries at the competition 

    conclusion and future work
we study the problem of creating an efficient compressed path database  cpd   a shortest path
oracle which  given two nodes in a weighted directed graph  always returns the first move of an
   

fic ompressing o ptimal paths with run l ength e ncoding

optimal path connecting them  starting with an all pairs first move matrix  which we assume is
given  we create oracles that are more compact and that can answer arbitrary first move queries
optimally and many orders faster than is otherwise possible using conventional online graph search
techniques  we employ a run length encoding  rle  compression scheme throughout and analyse
the problem from both a theoretical perspective and an empirical one  our main idea is simple  we
look to re order the nodes  i e   columns  of the input first move matrix in a good way such that
its rle compressed size is subsequently reduced 
on the theoretical side we show that the problem of finding an optimal node ordering  in the
general case for both directed and directed graphs  is np complete  in more specific cases  such as
graphs that can be decomposed along articulation points  the same problem can be efficiently tackled
by solving a series of independent sub problems  in particular we show that a depth first traversal
of a tree provides an optimal node ordering  these results give a first theoretical underpinning to the
problem of creating space efficient cpds using rle  our work also extends theoretical results from
the areas of information processing and databases  oswald   reinelt        mohapatra        
on the empirical side we study the efficacy of three heuristic node orderings   i  a depth first
ordering   ii  a graph cut ordering based on balanced edge separators   iii  a naive baseline given by
the ordering specified by the input graph  given an ordering and a first move matrix  we describe
two novel approaches for creating cpds  the first of these  src  uses simple run length encoding
to compress the individual rows of the matrix  the second approach  mrc  is more sophisticated
and identifies commonalities between sets of labels compressed by src 
in a range of experiments we show that src and mrc can compress the apsp matrix for graphs
with hundreds of thousands of nodes in as little as      mb  associated query times regularly
require less than     nanoseconds  we also compare our approaches with copa  botea       
botea   harabor      a   and rxl  delling et al          in a range of experiments on both grid
and road graphs we show that src and mrc are not only competitive with copa but often several
factors better  both in terms of compression and query times  we also show that src and mrc
outperform rxl in terms of query time  we also summarise results from the      grid based
path planning competition  in particular we can report that src was the fastest method at the
competition across all query time metrics and that src performed better than the resolution of the
competitions microsecond timer 
there appear several promising directions in which the current work could be extended  one
immediate possibility is to harness the available results on efficient appproximate tsp algorithms
in order to compute better and more space efficient node orderings  another immediate possibility
is to improve the current mrc compression scheme by devising an algorithm that optimizes the
assignment of first move ids 
looking more broadly  a strength that all cpds have  in addition to fast move extraction  is
that they can compress any kind of path  not just those that are network distance optimal    in
multi agent pathfinding for example it is sometimes useful to guarantee properties like there must
always be a local detour available  wang   botea         another example are turn costs in road
graphs  thus one possible a possible direction for future work is to create cpds that store only
paths satisfying such constraints 
a weakness of our approach is that in the preprocessing an apsp computation is required 
while delling et al         have shown that an apsp can sometimes be computed reasonably fast
    suboptimal paths  however  introduce the additional challenge of avoiding infinite loops when extracting such a path
from a cpd 

   

fis trasser   b otea     h arabor

on graphs with many nodes  apsp remains inherently quadratic in the number of nodes on any
graph class as its output size is quadratic  our approach would therefore hugely profit from an
algorithm that can directly compute the compressed cpd without first computing the first move
matrix in an intermediate step 

    acknowledgments
we thank patrik haslum  akihiro kishimoto  jakub marecek  anika schumman and jussi rintanen
for feedback on earlier versions of parts of this work  we would like to thank daniel delling  
thomas pajor for running the hub labeling experiments for us 

appendix a  proof to theorem  
theorem    simmini runs is np complete 
proof  the membership to np is straightforward  the hardness proof uses a reduction from the
hamiltonian path problem  hpp  in an undirected graph  let g    v  e  be an arbitrary undirected
graph  without duplicate edges  and define n    v   and e    e   figure    shows a toy graph used
as a running example 
starting from g  we build a simmini runs instance as follows  we define a     matrix m with
e rows and n columns  let r be the row corresponding to an edge  u  v   and let cu and cv be the
columns associated with nodes u and v  then m r  cv     m r  cu       and m r  c      for all other
columns  notice that m has at least a value of   on every row and column  figure    shows the
matrix in the running example 
x

y

w

z

figure     sample graph g 
let r be the matrix row corresponding to an edge  u  v   it is easy to see that  when a given
ordering of the columns  nodes  makes the two nodes u and v adjacent  the number of sequential

 x  y 
 x  w 
 x  z 
 w  z 

x
 
 
 
 

y
 
 
 
 

w
 
 
 
 

z
 
 
 
 

figure     matrix m built for g 
   

fic ompressing o ptimal paths with run l ength e ncoding

 x  z 
 w  z 
 x  w 
 x  y 

y
 
 
 
 

x
 
 
 
 

w
 
 
 
 

z
 
 
 
 

figure     the matrix after  i  converting some  s into  s  shown in bold   ii  re ordering columns
on the hamiltonian path  and iii  re ordering rows lexicographically 

 x  z 
 w  z 
 x  w 
 x  y 

y
 
 
 
 

x
 
 
 
 

w
 
 
 
 

z
 
 
 
 

figure     matrix after restoring back the previously replaced  s  shown in bold  
rle   runs   for row r is    if the nodes are not adjacent  the number of sequential rle   runs for
row r is   
we claim the hpp has a solution iff simmini runs has a solution with t    e  n     rle
  runs  let vi            vin be a solution of hpp  i e   a hamiltonian path   and let p be the set of all
edges included in this solution  in the running example  let p contain  y  x    x  w  and  w  z  
in every row corresponding to an edge not contained in p   switch one of its two   entries to
   then  order the columns with respect to the sequence of the nodes in the hamiltonian path and
rearrange the rows in lexicographical order  figure    illustrates these changes 
the construction of the matrix  the trick of converting some of the  s into  s  and the ordering
of the rows and columns are reused from oswald and reinelts proof for the hardness of deciding
whether a     matrix has the c sk property  oswald   reinelt         the rest of the proof 
coming below  is significantly different 
now  restore the previously replaced  s  as shown in figure     each of the e  n      s that
were replaced and restored have no adjacent  s in the matrix    as such  each of them counts as two
  runs  one horizontal and one vertical  this sums up to a total of   e  n        runs corresponding
to the  s replaced and restored  in addition  each row and column has one more   run  it follows
that the matrix has  e  n       runs 
conversely  consider a row and column ordering that creates  e  n     rle   runs in total  we
show that the matrix has at least e     vertical   runs  regardless of the row ordering  consider the
rows  in order  starting from the top  the first row introduces exactly   vertical   runs  one for each
column where it contains a value of    each subsequent row introduces at least one more vertical
  run  otherwise  the new row would be identical to the previous one  which contradicts the fact
that the graph has no duplicate edges 
    all runs used in this proof are sequential 
    if they had an adjacent   on a column  this would imply that we have two identical rows  which would further mean
that g has duplicate edges  if they had an adjacent   on a row  it would mean that the edge at hand belongs to the
hamiltonian path  which contradicts the fact that  s were replaced and restored on the complementary set of edges 

   

fis trasser   b otea     h arabor

as there are at least e     vertical   runs  the number of horizontal   runs will be at most
  e  n        e         e  n      we show that the column ordering is a hamiltonian path 
assuming the contrary  there are only p   n    edges such that their nodes are adjacent in the
ordering  it follows that the number of horizontal   runs is p     e  p     e  p    e  n     
contradiction 

appendix b  proofs to lemma   and lemma  
we start by pointing out two simple but important properties stemming from the notion of an articulation point 
remark    given a graph g  let x be an articulation point  and let g        gn be the corresponding
connected components obtained after removing x 
   given a source node s  gi   the first optimal move from s towards anywhere outside gi is
the same   
   given two distinct components gi and gj   the first optimal move from x towards anywhere
in gi is different from the first optimal move from x towards anywhere in gj  
remark   follows easily from the obvious observation that there is no way of going from one
subgraph gi to another subgraph gj other than passing through x  see figure   for an illustration 
lemma    let x be an articulation point of a graph g  every node order o can be rearranged into
an x block ordering o  without increasing the number of runs on any row 
proof  we construct the desired ordering o  by applying the following steps 
   rotate o so that x comes first 
   for every i           n  project the resulting order onto gi   obtaining a suborder o i  
   define o  as  o    x  o             o n  
it is clear by construction that the nodes in every subgraph gi are consecutive in o    it remains
to show that the number of runs per row does not grow 
denote by s a source node  we distinguish between two cases 
 case when s  gi for some i  being just a rotation 
step   has no impact on the number of
s
cyclic runs  steps   and   take all nodes from k  i gk and put them into one or two blocks
that are cyclic s
adjacent to x  we know from remark    point   that m s  x    m s  n  for
all nodes n in k  i gk   thus  the re arrangement brings next to x nodes n with the same
first move symbol as x  clearly  this does not increase the number of runs 
 case when s   x  as in the previous case  the rotation performed at step   does not increase
the number of cyclic runs  after step    cyclic runs and sequential runs are equivalent  since
the first position contains a distinct symbol  namely the x singleton  steps   and   separate
    assuming that we split the ties among optimal paths in a consistent manner  which is easy to ensure 

   

fic ompressing o ptimal paths with run l ength e ncoding

each gi into a contiguous block  this does not increase the number of sequential runs since 
according to remark    point    every two blocks corresponding to gi and gj   with i    j 
have no common symbol  it follows that the number of cyclic runs does not increase either 

lemma    given any x block ordering o  we have that 
   n  o  g  gi     n  o i   i   gi    and
p
   n  o  g   x        n   i n  o i   i    x    and
p
   n  o  g  g       n   i n  o i   i   i   
proof  we prove each point as follows 
   as o is an x block ordering  the nodes come in the order x  g          gi         gn   consider a
node s  gi and its corresponding row in the first move matrix  as pointed out in remark   
every path from s to a node outside gi has to pass through x  and therefore the first move from
s to anywhere outside gi is the same  it follows that all nodes in the sequence x  g          gi   
together with all nodes in the sequence gi  s
        gn   form one cyclic run  in effect  removing
from consideration all nodes contained in k  i gk leaves the number of runs unchanged 
which completes the proof of this case 
   this is the case focused on x as a start node  according to remark    if gi    gj   then the
first move from x towards anywhere in gi is different from the first move from x towards
anywhere in gj   it follows that two runs from two adjacent subsets gi and gi   never merge
into one run  thus 
x
n  o  g   x        
 n  o i   i    x      
i

   n 

x
i

n  o i   i    x   

   this case follows from the previous two  with standard arithmetic manipulation 
x
n  o  g  g    n  o  g   x    
n  o  g  gi  
i

   n 

x

   n 

x
 n  o i   i    x     n  o i   i   gi   

i

n  o i   i    x    

x

i

x
   n 
 n  o i   i    x   gi  
i

   n 

x

n  o i   i   i   

i

   

n  o i   i   gi  

i

fis trasser   b otea     h arabor

references
abraham  i   delling  d   fiat  a   goldberg  a  v     werneck  r  f          hldb  locationbased services in databases  in proceedings of the   th acm sigspatial international
symposium on advances in geographic information systems  gis     pp          acm
press  best paper award 
abraham  i   delling  d   goldberg  a  v     werneck  r  f          a hub based labeling algorithm
for shortest paths on road networks  in proceedings of the   th international symposium on
experimental algorithms  sea     vol       of lecture notes in computer science  pp 
        springer 
abraham  i   delling  d   goldberg  a  v     werneck  r  f          hierarchical hub labelings
for shortest paths  in proceedings of the   th annual european symposium on algorithms
 esa     vol       of lecture notes in computer science  pp        springer 
akiba  t   iwata  y     yoshida  y          fast exact shortest path distance queries on large networks by pruned landmark labeling   in proceedings of the      acm sigmod international
conference on management of data  sigmod     pp          acm press 
antsfeld  l   harabor  d   kilby  p     walsh  t          transit routing on video game maps   in
aiide 
arz  j   luxen  d     sanders  p          transit node routing reconsidered  in proceedings of the
  th international symposium on experimental algorithms  sea     vol       of lecture
notes in computer science  pp        springer 
babenko  m   goldberg  a  v   kaplan  h   savchenko  r     weller  m          on the complexity of hub labeling  in proceedings of the   th international symposium on mathematical
foundations of computer science  mfcs     lecture notes in computer science  springer 
baier  j   botea  a   harabor  d     hernandez  c          a fast algorithm for catching a prey
quickly in known and partially known game maps  computational intelligence and ai in
games  ieee transactions on  pp     
bast  h   delling  d   goldberg  a  v   mullerhannemann  m   pajor  t   sanders  p   wagner  d    
werneck  r  f          route planning in transportation networks  tech  rep  abs            
arxiv e prints 
bast  h   funke  s     matijevic  d          ultrafast shortest path queries via transit nodes  in
the shortest path problem  ninth dimacs implementation challenge  vol     of dimacs
book  pp          american mathematical society 
bast  h   funke  s   matijevic  d   sanders  p     schultes  d          in transit to constant shortestpath queries in road networks  in proceedings of the  th workshop on algorithm engineering
and experiments  alenex     pp        siam 
bauer  r   columbus  t   katz  b   krug  m     wagner  d          preprocessing speed up
techniques is hard  in proceedings of the  th conference on algorithms and complexity
 ciac     vol       of lecture notes in computer science  pp          springer 
bauer  r   columbus  t   rutter  i     wagner  d          search space size in contraction hierarchies  in proceedings of the   th international colloquium on automata  languages  and
   

fic ompressing o ptimal paths with run l ength e ncoding

programming  icalp     vol       of lecture notes in computer science  pp        
springer 
bellman  r          on a routing problem  quarterly of applied mathematics           
botea  a          ultra fast optimal pathfinding without runtime search  in proceedings of the seventh aaai conference on artificial intelligence and interactive digital entertainment  aiide     pp          aaai press 
botea  a          fast  optimal pathfinding with compressed path databases  in proceedings of the
symposium on combinatorial search  socs    
botea  a   baier  j  a   harabor  d     hernandez  c          moving target search with compressed
path databases  in proceedings of the international conference on automated planning and
scheduling icaps 
botea  a     harabor  d       a   path planning with compressed all pairs shortest paths data  in
proceedings of the   rd international conference on automated planning and scheduling 
aaai press 
botea  a     harabor  d       b   path planning with compressed all pairs shortest paths data  in
proceedings of the international conference on automated planning and scheduling icaps 
botea  a   strasser  b     harabor  d          complexity results for compressing optimal paths 
in proceedings of the national conference on ai  aaai    
bulitko  v   bjornsson  y     lawrence  r          case based subgoaling in real time heuristic
search for video game pathfinding  j  artif  intell  res   jair              
bulitko  v   rayner  d  c     lawrence  r          on case base formation in real time heuristic
search  in proceedings of the eighth aaai conference on artificial intelligence and interactive digital entertainment  aiide     stanford  california  october            
cohen  e   halperin  e   kaplan  h     zwick  u          reachability and distance queries via
  hop labels  in proceedings of the thirteenth annual acm siam symposium on discrete
algorithms  soda     pp          philadelphia  pa  usa  society for industrial and applied mathematics 
culberson  j  c     schaeffer  j          pattern databases  computational intelligence        
       
delling  d   goldberg  a  v   nowatzyk  a     werneck  r  f          phast  hardwareaccelerated shortest path trees  journal of parallel and distributed computing            
    
delling  d   goldberg  a  v   pajor  t     werneck  r  f          robust distance queries on massive
networks  in proceedings of the   nd annual european symposium on algorithms  esa    
vol       of lecture notes in computer science  pp          springer 
delling  d   goldberg  a  v     werneck  r  f          hub label compression  in proceedings
of the   th international symposium on experimental algorithms  sea     vol       of
lecture notes in computer science  pp        springer 
demetrescu  c   goldberg  a  v     johnson  d  s   eds            the shortest path problem  ninth
dimacs implementation challenge  vol     of dimacs book  american mathematical
society 
   

fis trasser   b otea     h arabor

dibbelt  j   strasser  b     wagner  d          customizable contraction hierarchies  in proceedings
of the   th international symposium on experimental algorithms  sea     vol       of
lecture notes in computer science  pp          springer 
dijkstra  e  w          a note on two problems in connexion with graphs  numerische mathematik 
          
felner  a   korf  r  e   meshulam  r     holte  r  c          compressed pattern databases   j 
artif  intell  res   jair              
ford  jr   l  r          network flow theory  tech  rep  p      rand corporation  santa monica 
california 
geisberger  r   sanders  p   schultes  d     delling  d          contraction hierarchies  faster
and simpler hierarchical routing in road networks  in proceedings of the  th international
conference on experimental algorithms  wea     pp         
harabor  d  d     grastien  a          online graph pruning for pathfinding on grid maps  in burgard  w     roth  d   eds    proceedings of the twenty fifth aaai conference on artificial
intelligence  aaai       san francisco  california  usa  august             aaai press 
harabor  d  d     grastien  a          improving jump point search  in chien  s   do  m  b  
fern  a     ruml  w   eds    proceedings of the twenty fourth international conference on
automated planning and scheduling  icaps       portsmouth  new hampshire  usa  june
             aaai 
hart  p  e   nilsson  n     raphael  b          a formal basis for the heuristic determination of
minimum cost paths  ieee transactions on systems science and cybernetics            
hernandez  c     baier  j  a          fast subgoaling for pathfinding via real time search   in
proceedings of the international conference on automated planning and scheduling icaps   
karypis  g     kumar  v          metis  a software package for partitioning unstructured graphs 
partitioning meshes  and computing fill reducing orderings of sparse matrices  version      
kou  l  t          polynomial complete consecutive information retrieval problems  siam journal
on computing             
lawrence  r     bulitko  v          database driven real time heuristic search in video game
pathfinding  computational intelligence and ai in games  ieee transactions on           
    
mohapatra  a          optimal sort ordering in column stores is np complete  tech  rep   stanford university 
oswald  m     reinelt  g          the simultaneous consecutive ones problem  theoretical computer science                       
samadi  m   siabani  m   felner  a     holte  r          compressing pattern databases with
learning  in proceedings of the      conference on ecai         th european conference
on artificial intelligence  pp          amsterdam  the netherlands  the netherlands  ios
press 
   

fic ompressing o ptimal paths with run l ength e ncoding

sankaranarayanan  j   alborzi  h     samet  h          efficient query processing on spatial networks  in proceedings of the   th annual acm international workshop on geographic information systems  gis     pp         
strasser  b   harabor  d     botea  a          fast first move queries through run length encoding  in proceedings of the symposium on combinatorial search  socs    
sturtevant  n       a        grid based path planning competition  https   code google 
com p gppc       
sturtevant  n       b   the website of the grid based path planning competition       http 
  movingai com gppc  
sturtevant  n          the website of the grid based path planning competition       http 
  movingai com gppc  
sturtevant  n   traish  j   tulip  j   uras  t   koenig  s   strasser  b   botea  a   harabor  d    
rabin  s          the grid based path planning competition       entries and results  in
proceedings of the  th international symposium on combinatorial search  socs     aaai
press 
uras  t     koenig  s          identifying hierarchies for fast optimal search  in brodley  c  e    
stone  p   eds    proceedings of the twenty eighth aaai conference on artificial intelligence 
july               quebec city  quebec  canada   pp          aaai press 
uras  t   koenig  s     hernandez  c          subgoal graphs for optimal pathfinding in eightneighbor grids   in proceedings of the international conference on automated planning and
scheduling icaps    
van schaik  s  j     de moor  o          a memory efficient reachability data structure through bit
vector compression  in proceedings of the      acm sigmod international conference on
management of data  sigmod     pp          new york  ny  usa  acm 
wang  k  h  c     botea  a          mapp  a scalable multi agent path planning algorithm with
tractability and completeness guarantees  journal of artificial intelligence research  jair  
         

   

fi