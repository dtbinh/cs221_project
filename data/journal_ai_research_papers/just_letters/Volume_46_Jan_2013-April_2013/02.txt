journal of artificial intelligence research                 

submitted        published      

automatic aggregation by joint modeling
of aspects and values
christina sauper
regina barzilay

csauper csail mit edu
regina csail mit edu

computer science and artificial intelligence laboratory
massachusetts institute of technology
   vassar st 
cambridge  ma       usa

abstract
we present a model for aggregation of product review snippets by joint aspect identification and sentiment analysis  our model simultaneously identifies an underlying set of
ratable aspects presented in the reviews of a product  e g   sushi and miso for a japanese
restaurant  and determines the corresponding sentiment of each aspect  this approach
directly enables discovery of highly rated or inconsistent aspects of a product  our generative model admits an efficient variational mean field inference algorithm  it is also easily
extensible  and we describe several modifications and their effects on model structure and
inference  we test our model on two tasks  joint aspect identification and sentiment analysis on a set of yelp reviews and aspect identification alone on a set of medical summaries 
we evaluate the performance of the model on aspect identification  sentiment analysis 
and per word labeling accuracy  we demonstrate that our model outperforms applicable
baselines by a considerable margin  yielding up to     relative error reduction on aspect
identification and up to     relative error reduction on sentiment analysis 

   introduction
online product reviews have become an increasingly valuable and influential source of information for consumers  the ability to explore a range of opinions allows consumers to both
form a general opinion of a product and gather information about its positive and negative
aspects  e g   packaging or battery life   however  as more reviews are added over time  the
problem of information overload gets progressively worse  for example  out of hundreds of
reviews for a restaurant  most consumers will read only a handful before making a decision 
in this work  our goal is to summarize a large number of reviews by discovering the most
informational product aspects and their associated user sentiment 
to address this need  online retailers often use simple aggregation mechanisms to represent the spectrum of user sentiment  many sites  such as amazon  simply present a
distribution over user assigned star ratings  but this approach lacks any reasoning about
why the products are given that rating  some retailers use further breakdowns by specific
predefined domain specific aspects  such as food  service  and atmosphere for a restaurant 
these breakdowns continue to assist in effective aggregation  however  because the aspects
are predefined  they are generic to the particular domain and there is no further explanation of why one aspect was rated well or poorly  instead  for truly informative aggregation 
c
    
ai access foundation  all rights reserved 

fisauper   barzilay

each product needs to be assigned a set of fine grained aspects specifically tailored to that
product 
the goal of our work is to provide a mechanism for effective unsupervised content
aggregation able to discover specific  fine grained aspects and associated values  specifically 
we represent each data set as a collection of entities  for instance  these can represent
products in the domain of online reviews  we are interested in discovering fine grained
aspects of each entity  e g   sandwiches or dessert for a restaurant   additionally  we would
like to recover a value associated with the aspect  e g   sentiment for product reviews   a
summary of the input and output can be found in figure    our input consists of short
text snippets from multiple reviews for each of several products  in the restaurant domain 
as in figure    these are restaurants  we assume that each snippet is opinion bearing
and discusses one of the aspects which are relevant for that particular product  our output
consists of a set of dynamic  i e   not pre specified  aspects for each product  snippets labeled
with the aspect which they discuss  and sentiment values for each snippet individually and
each aspect as a whole  in figure    the aspects identified for tasca spanish tapas include
chicken  dessert  and drinks  and the snippets are labeled with the aspects they describe
and the correct polarity 
one way to approach this problem is to treat it as a multi class classification problem 
given a set of predefined domain specific aspects  it would be fairly straightforward for
humans to identify which aspect a particular snippet describes  however  for our task
of discovering fine grained entity specific aspects  there is no way to know a priori which
aspects may be present across the entire data set or to provide training data for each  instead 
we must select the aspects dynamically  intuitively  one potential solution is to cluster the
input snippets  grouping those which are lexically similar without prior knowledge of the
aspects they represent  however  without some knowledge of which words represent the
aspect for a given snippet  the clusters may not align to ones useful for cross review analysis 
consider  for example  the two clusters of restaurant review snippets shown in figure   
while both clusters share many words among their members  only the first describes a
coherent aspect cluster  namely the drinks aspect  the snippets of the second cluster do
not discuss a single product aspect  but instead share expressions of sentiment 
to successfully navigate this challenge  we must distinguish between words which indicate aspect  words which indicate sentiment  and extraneous words which do neither  for
both aspect identification and sentiment analysis  it is crucial to know which words within
a snippet are relevant for the task  distinguishing them is not straightforward  however 
some work in sentiment analysis relies on a predefined lexicon or wordnet to provide some
hints  but there is no way to anticipate every possible expression of aspect or sentiment 
especially in user generated data  e g   use of slang such as deeeeeee lish for delicious  
in lieu of an explicit lexicon  we can attempt to use other information as a proxy  such as
part of speech  for example  aspect words are likely to be nouns  while value words are more
likely to be adjectives  however  as we show later in this paper  this additional information
is again not sufficient for the tasks at hand 
instead  we propose an approach to analyze a collection of product review snippets and
jointly induce a set of learned aspects  each with a respective value  e g   sentiment   we
capture this idea using a generative bayesian topic model where the set of aspects and
any corresponding values are represented as hidden variables  the model takes a collection
  

fiautomatic aggregation by joint modeling of aspects and values

input

output

tasca spanish tapas

tasca spanish tapas

review  
the chicken was cooked perfectly
the dessert was good

chicken
  the chicken was cooked perfectly
 the chicken was tough and not tasty
  moist and delicious chicken

review  
the red wines not too cheap
an excellent creme brulee
review  
they used frozen small shrimp
the chicken was tough and not tasty
pitcher sangria was pretty good

douzo sushi bar
review  
the sushi is creative and pretty good
the ponzu was overpowering
review  
real wasabi thats so fresh 
my torched roll tasted rather bland


dessert
  the dessert was good
  an excellent creme brulee

 



drinks
 the red wines not too cheap
  pitcher sangria was pretty good

douzo sushi bar
sushi
  the sushi is creative and pretty good
 my torched roll tasted rather bland
condiments
 the ponzu was overpowering
  real wasabi thats so fresh 



figure    an example of the desired input and output of our system in the restaurant
domain  the input consists of a collection of review snippets for several restaurants  the
output is an aggregation of snippets by aspect  e g   chicken and dessert  along with an
associated sentiment for each snippet  note that the input data is completely unannotated 
the only information given is which snippets describe the same restaurant 

of snippets as input and explains how the observed text arises from the latent variables 
thereby connecting text fragments with the corresponding aspects and values 
specifically  we begin by defining sets of sentiment word distributions and aspect word
distributions  because we expect the types of sentiment words to be consistent across all
products  e g   any product may be labeled as great or terrible   we allow the positive
and negative sentiment word distributions to be shared across all products  on the other
hand  in the case of restaurant reviews and similar domains  aspect words are expected to
be quite distinct between products  therefore  we assign each product its own set of aspect
word distributions  in addition to these word distributions  our model takes into account
several other factors  first  we model the idea that each particular aspect of a product has
some underlying quality  that is  if there are already    snippets praising a particular aspect 
its likely that the   th snippet will be positive as well  second  we account for common
patterns in language using a transition distribution between types of words  for example 
it is very common to see the pattern value aspect  such as in phrases like great pasta 
third  we model the distributions over parts of speech for each type of distribution  this
  

fisauper   barzilay

coherent aspect cluster
 

the martinis
were very good 
         
the drinks
both
wine and          
martinis   were tasty 
       
     

 

the wine
list was pricey 
         
their      
wine           
selection is horrible 

incoherent aspect cluster

 

the sushi is the      
best      
ive      
ever     
had 
best
paella
id
ever
had 
     
              
the fillet was the best
steak wed ever had 
                           
its the best
soup
ive
ever had 
                          

figure    example clusters of restaurant review snippets generated by a lexical clustering
algorithm  words relevant to clustering are highlighted  the first cluster represents a coherent aspect of the underlying product  namely the drinks aspect  the latter cluster simply
shares a common sentiment expression and does not represent snippets discussing the same
product aspect  in this work  we aim to produce the first type of aspect cluster along with
the corresponding values 

covers the intuition that aspect words are frequently nouns  whereas value words are often
adjectives  we describe each of these factors and our model as a whole in detail in section   
this formulation provides several advantages  first  the model does not require a set
of predefined aspects  instead  it is capable of assigning latent variables to discover the
appropriate aspects based on the data  second  the joint analysis of aspect and value
allows us to leverage several pieces of information to determine which words are relevant
for aspect identification and which should be used for sentiment analysis  including part
of speech and global or entity specific distributions of words  third  the bayesian model
admits an efficient mean field variational inference procedure which can be parallelized and
run quickly on even large numbers of entities and snippets 
we evaluate our approach on the domain of restaurant reviews  specifically  we use a set
of snippets automatically extracted from restaurant reviews on yelp  this collection consists
of an average of    snippets for each of     restaurants in the boston area  representing
a wide spectrum of opinions about several aspects of each restaurant  we demonstrate
that our model can accurately identify clusters of review fragments that describe the same
aspect  yielding       relative error reduction      absolute f    over a standalone clustering
baseline  we also show that the model can effectively identify snippet sentiment  with a
      relative error reduction       absolute accuracy  over applicable baselines  finally 
we test the models ability to correctly label aspect and sentiment words  discovering that
the aspect identification has high precision  while the sentiment identification has highrecall 
additionally  we apply a slimmed down version of our model which focuses exclusively
on aspect identification to a set of lab  and exam related snippets from medical summaries
provided by the pediatric environmental health clinic  pehc  at childrens hospital
boston  these summaries represent concise overviews of the patient information at a par  

fiautomatic aggregation by joint modeling of aspects and values

ticular visit  as relayed from the pehc doctor to the childs referring physician  our model
achieves           absolute f    over the standalone clustering baseline 
the remainder of this paper is structured as follows  section   compares our work with
previous work on both aspect identification and sentiment analysis  section   describes our
specific problem formulation and task setup more concretely  section   presents the details
of our full model and various model extensions  and section   describes the inference procedure and the necessary adjustments for each extension  the details of both data sets  the
experimental formulation  and results are presented in section    we summarize our findings
and consider directions for future work in section    the code and data used in this paper
are available online at http   groups csail mit edu rbg code review aggregation 

   related work
our work falls into the area of multi aspect sentiment analysis  in this section  we first
describe approaches toward document level and sentence level sentiment analysis  section
      which provide the foundation for future work  including our own  then  we describe
three common directions of multi aspect sentiment analysis  specifically  those which use
data mining or fixed aspect analysis  section         those which incorporate sentiment
analysis with multi document summarization  section         and finally  those focused on
topic modeling with additional sentiment components  section        
    single aspect sentiment analysis
early sentiment analysis focused primarily on identification of coarse document level sentiment  pang  lee    vaithyanathan        turney        pang   lee         specifically 
these approaches attempted to determine the overall polarity of documents  these approaches included both rule based and machine learning approaches  turney        used
a rule based method to extract potentially sentiment bearing phrases and then compared
them to the sentiment of known polarity words  while pang et al         used discriminative
methods with features such as unigrams  bigrams  part of speech tags  and word position
information 
while document level sentiment analysis can give us the overall view of an opinion  looking at individual sentences within the document yields a more fine grained analysis  the
work in sentence level sentiment analysis focuses on first identifying sentiment bearing sentences and then determining their polarity  yu   hatzivassiloglou        dave  lawrence 
  pennock        kim   hovy              pang   lee         both identification of
sentiment bearing sentences and polarity analysis can be performed through supervised
classifiers  yu   hatzivassiloglou        dave et al         or similarity to known text  yu
  hatzivassiloglou        kim   hovy         through measures based on distributional
similarity or by using wordnet relationships 
by recognizing connections between parts of a document  sentiment analysis can be
further improved  pang   lee        mcdonald  hannan  neylon  wells    reynar       
pang   lee         pang and lee        leverage the relationship between sentences to
improve document level sentiment analysis  specifically  they utilize both the subjectivity
of individual sentences and information about the strength of connection between sentences
in a min cut formulation to provide better sentiment focused summaries of text  mcdonald
  

fisauper   barzilay

et al         examine a different connection  instead constructing a hierarchical model of
sentiment between sentences and documents  their model uses complete labeling on a
subset of data to learn a generalized set of parameters which improve classification accuracy
at both document level and sentence level 
while none of the above approaches attempt to identify aspects or analyze sentiment in
an aspect based fashion  the intuitions provide key insight into the approaches we take in
our work  for example  the importance of distinguishing opinion sentences follows our own
intuition about the necessity of identifying sentiment bearing words within a snippet 
    aspect based sentiment analysis
following the work in single aspect document level and sentence level sentiment analysis
came the intuition of modeling aspect based  also called feature based  sentiment for review analysis  we can divide these approaches roughly into three types of systems based on
their techniques  systems which use fixed aspect approaches or data mining techniques for
aspect selection or sentiment analysis  systems which adapt techniques from multi document
summarization  and systems which jointly model aspect and sentiment with probabilistic
topic models  here  we examine each avenue of work with relevant examples and contrast
them with our own work 
      data mining and fixed aspect techniques for sentiment analysis
one set of approaches toward aspect based sentiment analysis follow the traditional techniques of data mining  hu   liu        liu  hu    cheng        popescu  nguyen   
etzioni         these systems may operate on full documents or on snippets  and they generally require rule based templates or additional resources such as wordnet both to identify
aspects and to determine sentiment polarity  another approach is to fix a predetermined
relevant set of aspects  then focus on learning the optimal opinion assignment for these
aspects  snyder   barzilay         below  we summarize each approach and compare and
contrast them to our work 
one set of work relies on a combination of association mining and rule based extraction
of nouns and noun phrases for aspect identification  hu and liu        and liu et al        
developed a three step system  first  initial aspects are selected by an association miner
and pruned by a series of rules  second  related opinions for each aspect are identified in
a rule based fashion using word positions  and their polarity is determined by wordnet
search based on a set of seed words  third  additional aspects are identified in a similar
fashion based on position of the selected polarity words  in each of these steps  part ofspeech information provides a key role in the extraction rules  in the later work  there is
an additional component to identify implicit aspects in a deterministic fashion  e g   heavy
maps deterministically to  weight   liu et al          while their task is similar to ours
and we utilize part of speech information as an important feature as well  we additionally
leverage other distributional information to identify aspects and sentiment  furthermore 
we avoid the reliance on wordnet and predefined rule mappings in order to preserve the
generality of the system  instead  our joint modeling allows us to recover these relationships
without the need for additional information 
  

fiautomatic aggregation by joint modeling of aspects and values

other approaches also rely on wordnet relationships to identify not only sentiment
polarity  but also aspects  using the parts and properties of a particular product class 
popescu et al         first use these relations to generate the set of aspects for a given
product class  e g   camera   following that  they apply relaxation labeling for sentiment
analysis  this procedure gradually expands sentiment from individual words to aspects to
sentences  similar to the cascade pattern mentioned in the work of mcdonald et al         
like the system of liu et al          their system requires a set of manual rules and several
outside resources  while our model does require a few seed words  it does not require any
manual rules or additional resources due to its joint formulation 
a separate direction of work relies on predefined aspects while focusing on improvement
of sentiment analysis prediction  snyder and barzilay        define a set of aspects specific
to the restaurant domain  specifically they define an individual rating model for each aspect 
plus an overall agreement model which attempts to determine whether the resulting ratings
should all agree or disagree  these models are jointly trained in a supervised fashion using
an extension of the pranking algorithm  crammer   singer        to find the best overall
star rating for each aspect  our problem formulation differs significantly from their work
in several dimensions  first  we desire a more refined analysis using fine grained aspects
instead of coarse predefined features  second  we would like to use as little supervised
training data as possible  rather than the supervised training required for the pranking
algorithm 
in our work  we attempt to capture the intuitions of these approaches while reducing the
need for outside resources and rule based components  for example  rather than supplying
rule based patterns for extraction of aspect and sentiment  we instead leverage distributional patterns across the corpus to infer the relationships between words of different types 
likewise  rather than relying on wordnet relationships such as synonymy  antonymy  hyponymy  or hypernymy  hu   liu        liu et al         popescu et al          we bootstrap
our model from a small set of seed words 
      multi document summarization and its application to sentiment
analysis
multi document summarization techniques generally look for repetition across documents
to signal important information  radev   mckeown        barzilay  mckeown    elhadad 
      radev  jing    budzikowska        mani         for aspect based sentiment analysis 
work has focused on augmenting these techniques with additional components for sentiment
analysis  seki  eguchi  kanodo    aono              carenini  ng    pauls        kim  
zhai         in general  the end goal of these approaches is the task of forming coherent text
summaries using either text extraction or natural language generation  unlike our work 
many of these approaches do not explicitly identify aspects  instead  they are extracted
through repeated information  additionally  our model explicitly looks at the connection
between content and sentiment  rather than treating it as a secondary computation after
information has been selected 
one technique for incorporating sentiment analysis follows previous work on identification of opinion bearing sentences  seki et al               present duc summarization
  

fisauper   barzilay

systems designed to create opinion focused summaries of task topics   in their system  they
employ a subjectivity component using a supervised svm with lexical features  similar to
those in the work of yu and hatzivassiloglou        and dave et al          this component
is used to identify subjective sentences and  in the work of seki et al          their polarity 
both in the task and in the sentences selected for the response summary  however  like
previous work and unlike our task  there is no aspect based analysis in their summarization
task  it is also fully supervised  relying on a hand annotated set of about        sentences
to train the svm 
another line of work focuses on augmenting the summarization system with aspect
selection similar to the data mining approaches of hu and liu         rather than using
single aspect analysis  carenini  ng  and zwart        and carenini et al         augment
the previous aspect selection with a user defined hierarchical organization over aspects  e g  
digital zoom is part of the lens  polarity of each aspect is assumed to be given by previous
work  these aspects are then incorporated into existing summarization systems  mead 
sentence extraction  radev et al         or sea natural language generation  carenini  
moore         to form final summaries  like the work of seki et al                this work
does not create new techniques for aspect identification or sentiment analysis  instead  they
focus on the process of integrating these sources of information with summarization systems 
while the aspects produced are comparable across reviews for a particular product  the
highly supervised nature means that this approach is not feasible for a large set of products
such as our corpus of reviews from many types of restaurants  instead  we must be able to
dynamically identify relevant aspects 
a final line of related work relies on the traditional summarization technique of identifying contrastive or contradictory sentences  kim and zhai        focus on generating
contrastive summaries by identifying pairs of sentences which express differing opinions on
a particular product feature  to do this  they define metrics of representativeness  coverage of opinions  and contrastiveness  alignment quality  using both semantic similarity
with wordnet matches and word overlap  in comparison to our work  this approach follows an orthogonal goal  as we try to find the most defining aspects instead of the most
contradictory ones  additionally  while the selected pairs hint at disagreements in rating 
there is no identification of how many people agree with each side or the overall rating of
a particular aspect  in our work  we aim to produce both a concrete set of aspects and the
user sentiment for each  whether it is unanimous or shows disagreement 
overall  while these methods are designed to produce output summaries which focus on
subjective information  they are not specifically targeted for aspect based analysis  instead 
aspects are identified in a supervised fashion  carenini et al               or are not defined
at all  seki et al               kim   zhai         in our work  it is crucial that we have
dynamically selected aspects because it is not feasible to preselect aspects in a supervised
fashion 
      probabilistic topic modeling for sentiment analysis
the work closest to our own in the direction of aspect based analysis focuses on the use of
probabilistic topic modeling techniques for identification of aspects  these may be aggre   for task examples  see the work of dang              

  

fiautomatic aggregation by joint modeling of aspects and values

gated without specific sentiment polarity  lu   zhai        or combined with additional
sentiment modeling either jointly  mei  ling  wondra  su    zhai        blei   mcauliffe 
      titov   mcdonald      a  or as a separate post processing step  titov   mcdonald 
    b   like our work  these approaches share the intuition that aspects may be represented
as topics 
several approaches focus on extraction of topics and sentiment from blog articles  in
one approach  they are used as expert articles for aspect extraction in combination with a
larger corpus of user reviews  lu and zhai        introduce a model with semi supervised
probabilistic latent semantic analysis  plsa  which identifies sentiment bearing aspects
through segmentation of an expert review  then  the model extracts compatible supporting
and supplementary text for each aspect from the set of user reviews  aspect selection is
constrained as in the rule based approaches  specifically  aspect words are required to be
nouns  our work differs from their work significantly  while we share a common goal of
identifying and aggregating opinion bearing aspects  we additionally desire to identify the
polarity of opinions  a task not addressed in their work  in addition  obtaining aspects
from an expert review is unnecessarily constraining  in practice  while expert reviewers may
mention some key aspects  they will not mention every aspect  it is crucial to discover
aspects based on the entire set of articles 
there is work in the direction of aspect identification from blog posts  for example 
mei et al         use a variation on latent dirichlet allocation  lda  similar to our own to
explicitly model both topics and sentiment  then use a hidden markov model to discover
sentiment dynamics across topic life cycles  a general sentiment polarity distribution is
computed by combining distributions from several separate labeled data sets  e g   movies 
cities  etc    however  in their work  sentiment is measured at the document level  rather
than topic level  additionally  the topics discovered by their model are very broad  for example  when processing the query the da vinci code  returned topics may be labeled as
book  movie  and religion  rather than the fine grained aspects we desire in our model  such
as those representing major characters or events  our model expands on their work by discovering very fine grained aspects and associating particular sentiment with each individual
aspect  in addition  by tying sentiment to aspects  we are able to identify sentiment bearing
words and their associated polarities without the additional annotation required to train
an external sentiment model 
sentiment may also be combined with lda using additional latent variables for each
document in order to predict document level sentiment  blei and mcauliffe        propose
a form of supervised lda  slda  which incorporates an additional response variable  which
can be used to represent sentiment such as the star rating of a movie  they can then jointly
model the documents and responses in order to find the latent topics which best predict
the response variables for future unlabeled documents  this work is significantly different
from our work  as it is supervised and does not predict in a multi aspect framework 
building on these approaches comes work in fine grained aspect identification with sentiment analysis  titov and mcdonald      a      b  introduce a multi grain unsupervised
topic model  specifically built as an extension to lda  this technique yields a mixture of
global and local topics  word distributions for all topics  both global and local  are drawn
at the global level  however  unlike our model  the consequence of this is that topics are
very easy to compare across all products in the corpus  however  the topics are more gen  

fisauper   barzilay

eral and less dynamic than we hope to achieve because they must be shared among every
product  one consequence of defining global topics is difficulty in finding relevant topics for
every product when there is little overlap  for example  in the case of restaurant reviews 
italian restaurants should have a completely different set of aspects than indian restaurants 
of course  if these factors were known  it would be possible to run the algorithm separately
on each subset of restaurants  but these distinctions are not immediately clear a priori  increasing the number of topics could assist in recovering additional aspects  however because
the aspects are still global  it will still be difficult to identify restaurant specific aspects 
for sentiment analysis  the pranking algorithm of snyder and barzilay        is incorporated in two ways  first  the pranking algorithm is trained in a pipeline fashion after all
topics are generated  titov   mcdonald      b   later  it is incorporated into the model
during inference in a joint formulation  titov   mcdonald      a   however  in both cases 
as in the original algorithm  the set of aspects is fixed  each of the aspects corresponds to a
fixed set of of topics found by the model  additionally  the learning problem is supervised 
because of the fixed aspects  necessary additional supervision  and global topic distribution  this model formulation is not sufficient for our problem domain  which requires very
fine grained aspects 
all of these approaches have structural similarity to the work we present  as they are
variations on lda  none  however  has the same intent as our model  mei et al        
model aspect and sentiment jointly  however their aspects are very vague  and they treat
sentiment at the document level rather than the aspect level  likewise  titov and mcdonald
     b      a  model fine grained aspects  but they are still coarser than the aspects we
require  even if we were to increase the number of aspects  as their distributions are shared
globally  finally  lu and zhai         blei and mcauliffe         and titov and mcdonald
     b      a  require supervised annotation or a supervised expert review that we do not
have  we attempt to solve each of these issues with our joint formulation in order to proceed
with minimal supervision and discover truly fine grained aspects 

   problem formulation
before explaining the model details  we describe the random variables and abstractions of
our model  as well as some intuitions and assumptions   a visual explanation of model
components is shown in figure    we present complete details and the generative story in
section   
    model components
our model is composed of five component types  entities  snippets  aspects  values  and
word topics  here  we describe each type and provide examples 

   here  we explain our complete model with value selection for sentiment in the restaurant domain  for
the simplified case in the medical domain where we would like to use only aspects  we may simply ignore
the value related components of the model 

  

fiautomatic aggregation by joint modeling of aspects and values

tasca spanish tapas
entity
aspects

chicken
 

 

the chicken was cooked perfectly
the chicken was tough and not tasty
moist and delicious chicken
snippets

values

dessert
 
 

the dessert was good
an excellent creme brulee


douzo sushi bar
sushi
 


the sushi is creative and pretty good
my torched roll tasted rather bland



figure    labeled model components from the example in figure    note that aspects
are never given explicit labels  and the ones shown here are presented purely for ease of
understanding  aspects exist simply as groups of snippets which share a common subject 
also  word topics are not pictured here  a word topic  aspect  value  or background  is
assigned to each word in each snippet  these model components are described at high level
in section     and in depth in section   

      entity
an entity represents a single object which is described in the review  in the restaurant
domain  these represent individual restaurants  such as tasca spanish tapas  douzo sushi
bar  and outback steakhouse 
      snippet
a snippet is a user generated short sequence of words describing an entity  these snippets
can be provided by the user as is  for example  in a quick reaction box  or extracted
from complete reviews through a phrase extraction system such as the one from sauper 
haghighi  and barzilay         we assume that each snippet contains at most one single
aspect  e g   pizza  and one single value type  e g   positive   in the restaurant domain  this
corresponds to giving an opinion about one particular dish or category of dishes  examples
from the restaurant domain include their pasta dishes are perfection itself   they had
fantastic drinks  and the lasagna rustica was cooked perfectly 
  

fisauper   barzilay

      aspect
an aspect corresponds to one of several properties of an entity  in the restaurant domain
where entities represent restaurants  aspects may correspond to individual dishes or categories of dishes  such as pizza or alcoholic drinks  for this domain  each entity has its
own unique set of aspects  this allows us to model aspects at the appropriate granularity 
for example  an italian restaurant may have a dessert aspect which pertains to information about a variety of cakes  pies  and gelato  however  most of a bakerys menu would
fall under that same dessert aspect  instead  to present a useful aspect based summary 
it would require separate aspects for each of cakes  pies  and so on  because aspects are
entity specific rather than shared  there are no ties between restaurants which have aspects
in common  e g   most sushi restaurants will have a sashimi aspect   we consider this a
point for potential future work  note that it is still possible to compare aspects across
entities  e g   to find the best restaurant for a burger   by comparing their respective word
distributions 
      value
values represent the information associated with an aspect  in the review domain  the two
value types represent positive and negative sentiment respectively  in general  it is possible
to use value to represent other distinctions  for example  in a domain where some aspects
are associated with a numeric value and others are associated with a text description  each
of these can be set as a value type  the intended distinctions may be encouraged by the
use of seed words  see section       or they may be left unspecified for the model to assign
whatever it finds to best fit the data  the number of value types must be prespecified 
however  it is possible to use either very few or very many types 
      word topic
while the words in each snippet are observed  each word is associated with an underlying
latent topic  the possible latent topics correspond to aspect  value  and a background
topic  for example  in the review domain  the latent topic of words great or terrible would
be value  of words which represent entity aspects such as pizza would be aspect  and of
stop words like is or of in domain white noise like food would be background 
    problem setup
in this work  we assume that the snippet words are always observed  and the correlation
between snippets and entities is known  i e   we know which entity a given snippet describes  
in addition  we assume part of speech tags for each word in each snippet  as a final source of
supervision  we may optionally include small sets of seed words for a lexical distribution  in
order to bias the distribution toward the intended meaning  for example  in the sentiment
case  we can add seed words in order to bias one value distribution toward positive and one
toward negative  seed words are certainly not required  they are simply a tool to constrain
the models use of distributions to fit any prior expectations 
note that in this formulation  the relevant aspects for each restaurant are not observed 
instead  they are represented by lexical distributions which are induced at inference time  in
   

fiautomatic aggregation by joint modeling of aspects and values

the system output  aspects are represented as unlabeled clusters over snippets   given this
formulation  the goal of this work is then to induce the latent aspect and value underlying
each snippet 

   model
our model has a generative formulation over all snippets in the corpus  in this section 
we first describe in detail the general formulation and notation of the model  then discuss
novel changes and enhancements for particular corpora types  inference for this model will
be discussed in section    as mentioned previously  we will describe the complete model
including aspect values 
    general formulation
for this model  we assume a collection of all snippet words for all entities  s  we use si j w to
denote the wth word of the jth snippet of the ith entity  we also assume a fixed vocabulary
of words w  
we present a summary of notation in table    a concise summary of the model in
figure    and a model diagram in figure    there are three levels in the model design 
global distributions common to all snippets for all entities in the collection  entity level
distributions common to all snippets describing a single entity  and snippet  and word level
random variables  here  we describe each in turn 
      global distributions
at the global level  we draw a set of distributions common to all entities in the corpus  these
include everything shared across a domain  such as the background stop word distribution 
value types  and word topic transitions 
background distribution a global background word distribution b is drawn to represent stop words and in domain white noise  e g   food becomes white noise in a corpus
of restaurant reviews   this distribution is drawn from a symmetric dirichlet with concentration parameter b   in our experiments  this is set to     
value distributions a value word distribution vv is drawn for each value type v  for
example  in a review domain with positive and negative sentiment types  there will be a
distribution over words for the positive type and one for the negative type  seed words
wseedv are given additional probability mass on the value priors for type v  specifically 
a non seed word receives  hyperparameter  while a seed word receives    v   in our
experiments  this is set to      
transition distribution a transition distribution  is drawn to represent the transition
probabilities of underlying word topics  for example  it may be very likely to have a
value aspect transition in a review domain  which fits phrases like great pizza  in our
experiments  this distribution is given a slight prior bias toward more helpful transitions  for
   if a label is desired  we can automatically extract one by selecting from the highest probability words
for a particular aspect  for simplicity and exactness  we provide manual cluster labels for the examples
in this paper 

   

fisauper   barzilay

data set
s
si j w
ti j w 
w
wseedv

collection of all snippet words from all entities
wth word of jth snippet of ith entity
part of speech tag corresponding to si j w
fixed vocabulary
seed words for value type v

lexical distributions
b
i a
a  
a
 a
v
v
i 

background word distribution
aspect word distribution for aspect a of entity i
value word distribution for type v
ignored words distribution

other distributions

i a  a   
 i     
 

transition distribution over word topics
aspect value multinomial for aspect a of entity i
aspect multinomial for entity i
part of speech tag distribution

latent variables
i j
za
zvi j
i j w
zw

aspect selected for si j
value type selected for si j
word topic  a  v  b  i    selected for si j w

other notation
k
a
v
b
i 

number of aspects a
indicator corresponding
indicator corresponding
indicator corresponding
indicator corresponding

to
to
to
to

aspect word
value word
background word
ignored word

table    notation used in this paper  items marked with
in section     



relate to extensions mentioned

example  encouraging sticky behavior by providing a small boost to self transitions  this
bias is easily overridden by data  however  it provides a useful starting point 
      entity specific distributions
there are naturally variations in the aspects which snippets describe and how many snippets
describe each aspect  for example  a mobile device popular for long battery life will likely
have more snippets describing the battery than a device which is known for its large screen 
some domains may have enormous variation in aspect vocabulary  for example  in restaurant
reviews  two restaurants may not serve any of the same food items to compare  to account
   

fiautomatic aggregation by joint modeling of aspects and values

global level 
draw background word distribution b  dirichlet b w  
for each value type v 
draw value word distribution vv  dirichlet w   v wseedv  
entity level 
for each entity i 
i a
draw aspect word distributions a
 dirichlet a w   for a              k

draw aspect value multinomial i a  dirichlet av n   for a              k
draw aspect multinomial  i  dirichlet m k 
snippet level 
for each snippet j describing the ith entity 
i j
 i
draw snippet aspect za
i j

draw snippet value zvi j  i za

i j w 
i j w
  zw
draw sequence of word topic indicators zw
i j
and value zvi j
draw snippet word given aspect za

si j w 


i z i j

a a  

z i j

v v  



b  

i j w
 a
when zw
i j w
 v
when zw
i j w
when zw   b

figure    a summary of our generative model presented in section      we use dirichlet w   to denote a finite dirichlet prior where the hyper parameter counts are a scalar
times the unit vector of vocabulary items  for the global value word distribution  the prior
hyper parameter counts are  for all vocabulary items and v for wseedv   the vector of
vocabulary items in the set of seed words for value v 

for these variations  we define a set of entity specific distributions which generate both
aspect vocabulary and popularity  as well as a distribution over value types for each aspect 
i a
aspect distributions an aspect word distribution a
is drawn for each aspect a  each
of these represents the distribution over unigrams for a particular aspect  for example  in
the domain of restaurant reviews  aspects may correspond to menu items such as pizza 
while in reviews for cell phones  they may correspond to details such as battery life  each

   

fisauper   barzilay

value v
background word
distribution

transition
distribution

value word
distributions

b



vv

entity i

aspect a
aspect
multinomial

aspect word
distributions

aspect value
multinomial

i

ai a

i a

snippet j

snippet aspect

snippet value

zai j

zvi j

hmm over snippet words



i j w 
zw

i j w
zw

i j w  
zw

si j w 

si j w

si j w  

zai j   ai a
zvi j   vv
b
figure    a graphical description of the model presented in section      a written description of the generative process is located in figure    curved arrows indicate additional links
which are present in the model but not drawn for readability 

   

fiautomatic aggregation by joint modeling of aspects and values

aspect word distribution is drawn from a symmetric dirichlet prior with hyperparameter
a   in our experiments  this is set to       
aspect value multinomials aspect value multinomials i a determine the likelihood
of each value type v for the corresponding aspect a  for example  if value types represent
positive and negative sentiment  this corresponds to agreement of sentiment across snippets 
likewise  if value types represent formatting such as integers  decimals  and text  each aspect
generally prefers the same type of value  these multinomials are drawn from a symmetric
dirichlet prior using hyperparameter av   in our experiments  this is set to     
aspect multinomial the aspect multinomial  i controls the likelihood of each aspect
being discussed in a given snippet  this encodes the intuition that certain aspects are more
likely to be discussed than others for a given entity  for example  if a particular italian
restaurant is famous for their pizza  it is likely that the pizza aspect will be frequently
discussed in reviews  while the drinks aspect may be mentioned only occasionally  the
aspect multinomial will encode this as a higher likelihood for choosing pizza as a snippet
aspect than drinks  this multinomial is drawn from a symmetric dirichlet distribution with
hyperparameter m   in our experiments  this is set to     
      snippet  and word specific random variables
using the distributions described above  we can now draw random variables for each snippet
to determine the aspect and value type which will be described  as well as the sequence of
underlying word topics and words 
i j
which this snippet will describe is drawn from the aspect
aspect a single aspect za
i
multinomial    all aspect words in the snippet  e g   pizza in a corpus of restaurant
i j
i za

reviews  will be drawn from the corresponding aspect word distribution a

 

value type a single value type zvi j is drawn conditioned on the selected aspect from the
i j
corresponding aspect value multinomial i za   all value words in the snippet  e g   great
z i j

in the review domain  will be drawn from the corresponding value word distribution v v  
i j  
i j m
is generword topic indicators a sequence of word topic indicators zw
          zw
ated using a first order markov model parameterized by the transition matrix   these
indicators determine which unigram distribution generates each word in the snippet  for
i j w
example  if zw
  b  the wth word of this snippet is generated from the background word
distribution b  

    model extensions
there are a few optional components of the model which may improve performance for some
cases  we briefly list them here  then present the necessary modifications to the model in
detail for each case  modifications to the inference procedure will be presented in section     
first  for corpora which contain irrelevant snippets  we may introduce an additional word
distribution i and word topic ignore to allow the model to ignore certain snippets or
pieces of snippets altogether  second  if it is possible to acquire part of speech tags for the
   

fisauper   barzilay

snippets  using these as an extra piece of information is quite beneficial  finally  for corpora
where every entity is expected to share the same aspects  the model can be altered to use
the same set of aspect distributions for all entities 
      ignoring snippets
when snippet data is automatically extracted  it may be noisy  and some snippets may
violate our initial assumptions of having one aspect and one value  for example  we find
some snippets which were mistakenly extracted that have neither aspect nor value  these
extraneous snippets may be difficult to identify a priori  to compensate for this  we modify
the model to allow partial or entire snippets to be ignored through the addition of a global
unigram distribution  namely the ignore distribution i   this distribution is drawn from a
symmetric dirichlet with concentration parameter i  
the ignore distribution differs from the background distribution in that it includes both
common and uncommon words  it is intended to select whole snippets or large portions of
snippets  so some words may overlap with the background distribution and other distributions  in order to successfully incorporate this distribution into our model  we must allow
i j w
to consider the ignore topic i  additionally  to ensure that
the word topic indicator zw
it selects long segments of text  we give a large boost to the prior of the ignore ignore
sequence in the transition distribution   similar to the boost for self transitions 
      part of speech tags
part of speech tags can provide valuable evidence in determining which snippet words are
drawn from each distribution  for example  aspect words are often nouns  as they represent
concrete properties or concepts in a domain  likewise  in some domains  value words
describe aspects and therefore tend to be expressed as numbers or adjectives 
this intuition can be directly incorporated into the model in the form of additional
outputs  specifically  we modify our hmm to produce both words and tags  additionally 
a    v   and    similar to the corresponding unigram
we define distributions over tags a
v
b
distributions 
      shared aspects
when domains are very regular  and every entity is expected to express aspects from a
consistent set  it is beneficial to share aspect information across entities  for example  in a
medical domain  the same general set of lab tests and physical exam categories are run on all
patients  note that this is quite unlike the restaurant review case  where each restaurants
aspects are completely different  e g   pizza  curry  scones  and so on  
sharing aspects in this way can be accomplished by modifying the aspect distributions
i a
a   likewise  aspect value multinomials i a become
a
to become global distributions a
shared across all entities as as a   treatment of the aspect multinomials depend on the
domain properties  if the distribution over aspects is expected to be the same across all
entities  it can also be made global  however  if each individual entity is expected to exhibit
variation in the number of snippets related to each aspect  they should be kept as entityspecific  for example  reviews for a set of cell phones may be expected to focus on varying
   

fiautomatic aggregation by joint modeling of aspects and values

value v
background word
distribution

transition
distribution

value word
distributions

b



vv

entity i

aspect a
aspect
multinomial

aspect word
distributions

aspect value
multinomial

i

aa

a

snippet j

snippet aspect

snippet value

zai j

zvi j

hmm over snippet words



i j w 
zw

i j w
zw

i j w  
zw

si j w 

si j w

si j w  

zai j   ai a
zvi j   vv
b
figure    a graphical description of the model with shared aspects presented in section     
note the similarities to figure    however in this version  aspects are shared for the entire
corpus  rather than being entity specific  it would also be possible to share the aspect
multinomial corpus wide  in that case it would indicate that all entities share the same
general distribution over aspects  while in this version the individual entities are allowed to
have completely different distributions 

parts  depending on what is most unique or problematic about those phones  a graphical
description of these changes compared to the original model is shown in figure   
   

fisauper   barzilay

mean field factorization
q  b   v     a       z 
  q  b   q   

n
y

 
q  vv  

v  

y


q 

i



k
 
y

i a
q a
q i a

 

a  

i

 
y  i j   i j  y  i j w 

q zv q za
q zw
w

j

snippet aspect indicator
i j
log q za
  a   eq i   log  i  a   

x

i j w
i a i j w
q zw
  a eq i a   log a
 s
  
a

w

n
x

q zvi j   v eq i a   log i a  v 

v  

snippet value type indicator
x
x
i j
i j w
log q zvi j   v  
q za
  a eq i a   log i a  v   
q zw
  v  eq vv   log vv  si j w  
a

w

word topic indicator
 x





i j w   
i j
i j i j w 
i j w 
i j w
 
  a eq i a   log a
  a  a  zw
q za
s
log q zw
  a  log p zw   a   eq   log  zw
a

a














i j w   

i j w 
i j w
  v  log p zw   v   eq   log  zw
  v  v  zw
log q zw



 

x

q zvi j   v eq vv   log vv si j w


v

log q

i j w
zw

  b  log p zw   b   eq   log 


i j w 
 b 
zw

i j w   
b  zw



  eq b   log b si j w



figure    the mean field variational algorithm used during learning and inference to obtain posterior predictions over snippet properties and attributes  as described in section   
mean field inference consists of updating each of the latent variable factors as well as a
straightforward update of latent parameters in round robin fashion 

   inference
the goal of inference in this model is to predict the aspect and value for each snippet i and
product j  given the text of all observed snippets  while marginalizing out the remaining
hidden parameters 
i j
p  za
  zvi j  s 
we accomplish this task using variational inference  blei  ng    jordan         specifically  the goal of variational inference is to find a tractable approximation q   to the full
posterior of the model 
p  b   v     a       z s   q b   v     a       z 
for our model  we assume a full mean field factorization of the variational distribution 
shown in figure    this variational approximation is defined as a product of factors q   
which are assumed to be independent  this approximation allows for tractable inference of
each factor individually  to obtain the closest possible approximation  we attempt to set
   



fiautomatic aggregation by joint modeling of aspects and values

the q   factors to minimize the kl divergence to the true model posterior 
arg min kl q b   v     a       z kp  b   v     a       z s  
q  

    optimization
we optimize this objective using coordinate descent on the q   factors  concretely  we
update each factor by optimizing the above criterion with all other factors fixed to their
current values 
q    eq q   log p  b   v     a       z  s 
a summary of the variational update equations is given in figure    and a graphical
representation of the involved variables for each step is presented in figure    here  we will
present the update for each factor 
      snippet aspect indicator
i j
first  we consider the update for the snippet aspect indicator  za
 figure  a  
i j
log q za
  a   eq i   log  i  a 
x
i j w
i a i j w
 
q zw
  a eq i a   log a
 s
 

 

  b 

a

w
n
x

  a 

q zvi j   v eq i a   log i a  v 

  c 

v  

the optimal aspect for a particular snippet depends on three factors  first  we include the
likelihood of discussing each aspect a  eqn   a   as mentioned earlier  this encodes the
prior probability that some aspects are discussed more frequently than others  second  we
examine the likelihood of a particular aspect based on the words in the snippet  eqn   b  
for each word which is identified as an aspect word  we add the probability that it discusses
this aspect  third  we determine the compatibility of the chosen aspect type with the
current aspect  eqn   c   for example  if we know the value type is most likely an integer 
the assigned aspect should accept integers 
      snippet value type indicator
next  we consider the update for the snippet value type indicator  zvi j  figure  b  
x
i j
log q zvi j   v  
q za
  a eq i a   log i a  v 

  a 

a

 

x

i j w
q zw
  v  eq vv   log vv  si j w  

  b 

w

the best value type for a snippet depends on two factors  first  like the snippet aspect
indicator  we must take into consideration the compatibility between snippet aspect and
value type  eqn   a   second  for each word identified as a value word  we include the
likelihood that it comes from the given value type 
   

fisauper   barzilay

v
b

v
vv



i

i

a
i a
a

i

j



zv    v
za    a
b

i

j

zvi j

w 
zw

w
zw

w  
zw

sw 

sw

sw  

zv   v
za   a
b

i

vv



j

i j
za

w 
zw



za
sw  a

z





j

i



w
zw

w  
zw

sw 

sw

sw  

vv

i a
a

w  
zw



w 
zw


sw

sw  

z

zv
sw  v





vv

i a
a

i a

b
i

i j
za

w
zw

w
i  zw
 a

w 
zw

v

a

i a

zvi j



b
i

i a
a

zvi j

v

a
i

i a

 b  inference procedure for snippet value  zvi j

v


i a
a

i j
za



i j
 a  inference procedure for snippet aspect  za

b

vv

a

i a

i j
za



b

a

i a

zvi j



j

w
zw

w  
zw



sw

sw  

z

i

i j
za

w 
zw

zvi j
w
zw

w  
zw

sw

sw  



w
ii  zw
 v

sw  b

w
iii  zw
 b

i j w
 c  inference procedure for word topic  zw

figure    variational inference update steps for each latent variable  the latent variable
currently being updated is shown in a double circle  and the other variables relevant to the
update are highlighted in black  those variables which have no impact on the update are
grayed out  note that for snippet aspect  a  and snippet value type  b   the update takes
the same form for each possible aspect or value type  however  for word topic  c   the
update is not symmetric as the relevant variables are different for each possible word topic 

   

fiautomatic aggregation by joint modeling of aspects and values

      word topic indicator
i j w
finally  we consider the update for the word topic indicators  zw
 figure  c   unlike
the previous indicators  each possible topic has a slightly different equation  as we must
marginalize over all possible aspects and value types 






i j w
i j w 
i j w   
log q zw
  a  log p zw   a   eq   log  zw
  a  a  zw
x

i j
i j i j w 
 
q za
  a eq i a   log a
s

  a 

a

a






i j w
i j w 
i j w   
log q zw
  v  log p zw   v   eq   log  zw
  v  v  zw
x


 
q zvi j   v eq vv   log vv si j w

  b 

v






i j w   
i j w 
i j w
  b  b  zw
  b  log p zw   b   eq   log  zw
log q zw

  eq b   log b si j w

  c 

the update for each topic is composed of the prior probability of having that topic  transition probabilities using this topic  and the probability of the word coming from the appropriate unigram distribution  marginalized over all possibilities for snippet aspect and value
indicators 
      parameter factors
updates for the parameter factors under variational inference are derived through simple
counts of the latent variables za   zv   and zw   note that these do include partial counts 
i j
  a            it would contribute     
if a particular snippet has aspect probability p  za
i
count to   a    
      algorithm details
given this set of update equations  the update procedure is straightforward  first  iterate
over the corpus computing the updated values for each random variable  then do a batch
update for all factors simultaneously  this update algorithm is run to convergence  in
practice  convergence is achieved by the   th iteration  so the algorithm is quite efficient 
note that the batch update means each update is computed using the values from the
previous iteration  unlike gibbs sampling which uses updated values as it runs through the
corpus  this difference allows the variational update algorithm to be parallelized  yielding
a nice efficiency boost  specifically  to parallelize the algorithm  we simply split the set
of entities evenly among processors  updates for entity specific factors and variables are
computed during the pass through the data  and updates for global factors are collected
and combined at the end of each pass 
   

fisauper   barzilay

    inference for model extensions
as discussed in section      we can add additional components to the model to improve
performance for data with certain attributes  here  we briefly discuss the modifications to
the inference equations for each extension 
      ignoring snippets
the main modifications to the model for this extension are the addition of the unigram
distribution i and word topic i  which can be chosen by zw   the update equation for zw
is modified by the addition of the following 
i j w
log q zw
  i   log p  zw   i    eq i   log i  si j w  

as in the other pieces of this equation  eqn      this is composed of the prior probability
for the word topic i and the likelihood that this word is generated by i  
in addition  the transition distribution  must be updated to include transition probabilities for i and i  as mentioned earlier  the ii transition receives high weight  while
all other transitions to and from i receive very low weight 
      part of speech tags
to add part of speech tags  the model is updated to include part of speech distributions
i a
a   v   and b   one for each word topic  note that unlike the unigram distributions a
and vv   the corresponding tag distributions are not dependent on snippet entity  aspect  or
value  these are included and referenced in the updates for zw as follows 





i j w   
i j w
i j w 
  a  a  zw
log q zw
  a  log p zw   a   eq   log  zw
 x

i j i j w 
i j
  eq a   log a ti j w  
  a eq i a   log a
s
q za
a

a






i j w   
i j w 
i j w
  v  v  zw
  v  log p zw   v   eq   log  zw
log q zw
 x


q zvi j   v eq vv   log vv si j w
  eq v   log v ti j w  
v






i j w
i j w 
i j w   
log q zw
  b  log p zw   b   eq   log  zw
  b  b  zw


  eq b   log b ti j w   eq b   log b si j w
here  we define t as the set of all tags and ti j w as the tag corresponding to the word si j w  
      shared aspects
a global set of shared aspects is a simplification of the model in that it reduces the total
a and aspect value
number of parameters  this model redefines aspect distributions to be a
multinomials to be a   depending on domain  it may also redefine the aspect multinomial
to be   the resulting latent variable update equations are the same  only the parameter
   

fiautomatic aggregation by joint modeling of aspects and values

factor updates are changed  rather than collecting counts over snippets describing a single
entity  counts are collected across the corpus 

   experiments
we perform experiments on two tasks  first  we test our full model on joint prediction of
both aspect and sentiment on a corpus of review data  second  we use a simplified version
of the model designed to identify aspects only on a corpus of medical summary data  these
domains are structured quite differently  and therefore present very different challenges to
our model 
    joint identification of aspect and sentiment
our first task is to test our full model by jointly predicting both aspect and sentiment on
a collection of restaurant review data  specifically  we would like to dynamically select a
set of relevant aspects for each restaurant  identify the snippets which correspond to each
aspect  and recover the polarity of each snippet individually and each aspect as a whole 
we perform three experiments to evaluate our models effectiveness  first  we test the
quality of learned aspects by evaluating the predicted snippet clusters  second  we assess
the quality of the polarity classification  third  we examine per word labeling accuracy 
      data set
our data set for this task consists of snippets selected from yelp restaurant reviews by our
previous system  sauper et al          the system is trained to extract snippets containing
short descriptions of user sentiment towards some aspect of a restaurant   for the purpose
of this experiment  we select only the snippets labeled by that system as referencing food 
in order to ensure that there is enough data for meaningful analysis  we ignore restaurants
that have fewer than    snippets across all reviews  while our model can easily operate on
restaurants with fewer snippets  we want to ensure that the cases we select for evaluation
are nontrivial  i e   that there are a sufficient number of snippets in each cluster to make
a valid comparison  there are        snippets in total  taken from     restaurants in and
around the boston cambridge area  the average snippet length is     words  and there
are an average of      snippets per restaurant  we use the mxpost tagger  ratnaparkhi 
      to gather pos tags for the data  figure   shows some example snippets 
for this domain  the value distributions consist of one positive and one negative distribution  these are seeded using    and    seed words respectively  seed words are hand selected
based on the restaurant review domain  therefore  they include domain specific words such
as delicious and gross  a complete list of seed words is included in table   
      domain challenges and modeling techniques
this domain presents two challenging characteristics for our model  first  there are a wide
variety of restaurants within our domain  including everything from high end asian fusion
cuisine to greasy burger fast food places  if we were to try to represent these using a single
   for exact training procedures  please reference that paper 

   

fisauper   barzilay

positive
amazing
delightful
extraordinary
flavorful
generous
heaven
inexpensive
perfect
recommend
stimulating
wonderful

negative
awesome
divine
fantastic
free
good
huge
love
phenomenal
rich
strong
yummy

best
enjoy
fav
fresh
great
incredible
nice
pleasant
sleek
tasty

delicious
excellent
favorite
fun
happy
interesting
outstanding
quality
stellar
tender

average
bland
disappointed
expensive
gross
lame
meh
poor
tacky
tiny
uninspiring

awful
boring
disgusting
fatty
horrible
less
mushy
pricey
tasteless
unappetizing
worse

bad
confused
dry
greasy
inedible
mediocre
overcooked
salty
terrible
underwhelming
worst

table    seed words used by the model for the restaurant corpus     positive words and   
negative words in total  these words are manually selected for this data set 
shared set of aspects  the number of aspects required would be immense  and it would
be extremely difficult for our model to make fine grained distinctions between them  by
defining aspects separately for each restaurant as mentioned in section    we can achieve
the proper granularity of aspects for each individual restaurant without an overwhelming
or overlapping selection of choices  for example  the model is able to distinguish that an
italian restaurant may need only a single dessert aspect  while a bakery requires separate
pie  cake  and cookie aspects 
second  while there are usually a fairly cohesive set of words which refer to any particular
aspect  e g   the pizza aspect might be commonly be seen with the words slice  pepperoni 
and cheese   there are a near unlimited set of potential sentiment words  this is especially
pronounced in the social media domain where there are many novel words used to express
sentiment  e g   deeeeeeeelish as a substitute for delicious   as mentioned in section    the
part of speech and transition components of the model helps to identify which unknown
words are likely to be sentiment words  however  we additionally need to identify the polarity of their sentiment  to do this  we can leverage the aspect value multinomial  which
represents the likelihood of positive or negative sentiment for a particular aspect  if most
of the snippets about a given aspect are positive  it is likely that the word deeeeeeeelish
represents positive sentiment as well 
      cluster prediction
i j
the goal of this task is to evaluate the quality of aspect clusters  specifically the za
variable
in section    in an ideal clustering  the predicted clusters will be cohesive  i e   all snippets
predicted to discuss a given aspect are related to each other  and comprehensive  i e   all
snippets which discuss an aspect are selected as such   for example  a snippet will be
assigned the aspect pizza if and only if that snippet mentions some aspect of pizza  such as
its crust  cheese  or toppings 

annotation for this experiment  we use a set of gold clusters on the complete sets
of snippets from    restaurants       snippets in total  an average of      snippets per
restaurant   cluster annotations were provided by graduate students fluent in english  each
annotator was provided with a complete set of snippets for a particular restaurant  then
asked to cluster them naturally  there were     clusters in total  which yields an average
   

fiautomatic aggregation by joint modeling of aspects and values

the noodles and the meat were actually         
pretty       
good 
i               
recommend the chicken noodle pho 
soggy 
the noodles were        
the chicken pho was also   good 
     
though 
the spring rolls and coffee were   good 
     

the spring roll wrappers were a little
dry tasting 
                  
crispy
spring
rolls 
my   favorites
were
the
         
the crispy tuna spring rolls are   fantastic 
         
the
the
the
the

lobster roll my mother ordered was      
dry and  scant 
     
portabella mushroom is my   go to
sandwich 
     
bread on the sandwich was  stale 
     
rather         
measly 
slice of tomato was        

the shumai and california maki sushi were          
decent 
 
the spicy tuna roll and eel roll were perfect 
       
not    
so      
great 
the rolls with spicy mayo were     
 
love thai rolls 
i      

figure    example snippets from our data set  grouped according to aspect  aspect words
are underlined and colored blue  negative value words are labeled   and colored red  and
positive value words are labeled   and colored green  the grouping and labeling are not
given in the data set and must be learned by the model 

of      clusters per restaurant  these annotations are high quality  the average annotator
agreement is      by the muc evaluation metric  described in detail below   while we could
define a different number of clusters for each restaurant by varying the number of aspect
distributions  for simplicity we ask both baseline systems and our full model to produce
   aspect clusters per restaurant  matching the average annotated number  varying the
number of clusters will simply cause existing clusters to merge or split  there are no large
or surprising changes in clustering 
baseline we use two baselines for this task  both using a clustering algorithm weighted
by tf idf as implemented by the publicly available cluto package  karypis         
using agglomerative clustering with the cosine similarity distance metric  chen  branavan 
barzilay    karger        chen  benson  naseem    barzilay        
the first baseline  cluster all  clusters over entire snippets in the data set  this
baseline will put a strong connection between things which are lexically similar  because our
model only uses aspect words to tie together clusters  this baseline may capture correlations
between words which our model does not correctly identify as aspect words 
   available at http   glaros dtc umn edu gkhome cluto cluto overview 

   

fisauper   barzilay

cluster all
cluster noun
our model

precision

recall

    
    
    

    
    
    

f 
    
    
    

table    results using the muc metric on cluster prediction for the joint aspect and value
identification task  while muc has a deficiency in that putting everything into a single
cluster will artificially inflate the score  all models are set to use the same number of clusters 
note that for this task  the cluster noun significantly outperforms the cluster all
baseline  indicating that part of speech is a crucial piece of information for this task 

the second baseline  cluster noun  works over only the nouns from the snippets 
each snippet is pos tagged using mxpost  ratnaparkhi          and any non noun  i e  
not nn  nns  nnp  or nnps  words are removed  because we expect that most aspects contain
at least one noun  this acts as a proxy for the aspect identification in our model 
metric we use the muc cluster evaluation metric for this task  vilain  burger  aberdeen 
connolly    hirschman         this metric measures the number of cluster merges and
splits required to recreate the gold clusters given the models output  therefore  it can
concisely show how accurate our clusters are as a whole  while it would be possible to
artificially inflate the score by putting everything into a single cluster  the parameters on
our model and the likelihood objective are such that the model prefers to use all available
clusters  the same number as the baseline system 
results results for our cluster prediction task are in table    our model shows strong
performance over each baseline  for a total error reduction of     over the cluster noun
baseline and     over the cluster all baseline  the most common cause of poor cluster
choices in the baseline systems is their inability to distinguish which words are relevant
aspect words  for example  in the cluster all baseline  if many snippets use the word
delicious  there may end up being a cluster based on that alone  the cluster noun
baseline is able to avoid some of these pitfalls thanks to its built in filter  it is able to
avoid common value words such as adjectives and also focus on what seems to be the most
concrete portion of the aspect  e g   blackened chicken   however  it still cannot make the
correct distinctions where these assumptions are broken  because our model is capable
of distinguishing which words are aspect words  i e   words relevant to clustering   it can
choose clusters which make more sense overall 
      sentiment analysis
we evaluate the systems predictions of snippet sentiment using the predicted posterior
i j
over the value distributions for the snippet  i e   za
   for this task  we consider the binary
i j
judgment to be simply the one with higher value in q za
   see section     the goal of this
task is to evaluate whether our model correctly distinguishes the sentiment of value words 
   available at http   www inf ed ac uk resources nlp local doc mxpost html 

   

fiautomatic aggregation by joint modeling of aspects and values

majority
discriminative small
seed
discriminative large
our model

accuracy
    
    
    
    
    

table    sentiment prediction accuracy of our model compared to the discriminative and
seed baselines  as well as majority representing the majority class  positive  baseline 
one advantage of our system is its ability to distinguish aspect words from sentiment words
in order to restrict judgment to only the relevant terms  another is the leverage that it gains
from biasing unknown sentiment words to follow the polarity observed in other snippets
relating to the same aspect 
annotation for this task  we use a set of     randomly selected snippets from the yelp
reviews which express opinions  to get a clear result  this set specifically excludes neutral 
mixed  or potentially ambiguous snippets such as the fries were too salty but tasty or the
blackened chicken was very spicy  which make up about     of the overall data  this set is
split into a training set of     snippets and a test set of     snippets  then each snippet is
manually labeled positive or negative  for one baseline  we use the set of positive and
negative seed words which were manually chosen for our model  shown in table    note
that as before  our model has access to the full corpus of unlabeled data plus the seed words 
but no labeled examples 
baseline we use two baselines for this task  one based on a standard discriminative
classifier and one based on the seed words from our model 
the discriminative baseline for this task is a standard maximum entropy discriminative binary classifier  over unigrams  given enough snippets from enough unrelated aspects 
the classifier should be able to identify that words like great indicate positive sentiment and
those like bad indicate negative sentiment  while words like chicken are neutral and have
no effect  to illustrate the effect of training size  we include results for discriminativesmall  which uses     training examples  and discriminative large  which uses    
training examples 
the seed baseline simply counts the number of words from the same positive and
negative seed lists used by the model  vseed  and vseed   as listed in table    if there are
more words from vseed    the snippet is labeled positive  and if there are more words from
vseed   the snippet is labeled negative  if there is a tie or there are no seed words  we split
the prediction  because the seed word lists are manually selected specifically for restaurant
reviews  i e   they contain food related sentiment words such as delicious   this baseline
should perform well 
results the overall sentiment classification accuracy of each system are shown in table     our model outperforms both baselines  the obvious flaw in the seed baseline is
   available at https   github com lzhang   maxent 

   

fisauper   barzilay

  

accuracy

    
    

  

    

         
    

    

  
discriminative
seed
our model

    
  

 

                       
number of snippets in training data

figure     discriminative baseline performance as the number of training examples increases  while performance generally increases  there are some inconsistencies  the main
issue with this baseline is that it needs to see examples of words in training data before it
can improve  this phenomenon can be seen at the plateau in this graph 

the inability to pre specify every possible sentiment word  it does perform highly  due to
its tailoring for the restaurant domain and good coverage of the most frequent words  e g  
delicious  good  great   but the performance of our model indicates that it can generalize
beyond these seed words 
the discriminative large outperforms the seed baseline on this test set  however 
given the smaller training set of discriminative small  it performs worse  the training
curve of the discriminative baseline is shown in figure     while the discriminative
baseline system can correctly identify the polarity of statements containing information it
has seen in the past  it has two main weaknesses  first  every sentiment word must have
been present in training data  for example  in our test data  rancid appears in a negative
sentence  however  it does not appear in the training data  so the model labels the example
incorrectly  this is problematic  as there is no way to find training data for every possible
sentiment word  especially in social media data where novel words and typos are a frequent
occurrence  our models ability to generalize about the polarity of snippets describing a
particular aspect allows it to predict sentiment values for words of unknown polarity  for
example  if there are already several positive snippets describing a particular aspect  the
system can guess that a snippet with unknown polarity will likely also be positive 
      per word labeling accuracy
the goal of this task is to evaluate whether each word is correctly identified as an aspect
word  value word  or background word  this distinction is crucial in order to achieve
correctness of both clustering and sentiment analysis  so errors here may help us identify
weaknesses of our model 
   

fiautomatic aggregation by joint modeling of aspects and values

the rolls also were nt
very well made  
                    
the pita was         
beyond dry
and        
tasted like
cardboard  
   
               
falafel  
the falafel king has the best
    
the rolls with spicy mayo were not
so good  
            
 
ordered the spicy tuna and california roll  they were amazing
         

table    correct annotation of a set of phrases containing elements which may be confusing 
on which annotators are tested before they are allowed to annotate the actual test data  aspect words are colored blue and underlined  value words are colored orange and underlined
with a wavy line  some common mistakes include  annotating nt as background  because
it is attached to the background word was   annotating cardboard as an aspect because it
is a noun  annotating falafel king as an aspect because it is in subject position 
annotation per word annotation is acquired from mechanical turk  the per word labeling task seems difficult for some turk annotators  so we implement a filtering procedure
to ensure that only high quality annotators are allowed to submit results  specifically  we
ask annotators to produce labels for a set of difficult phrases with known labels  shown
in table     those annotators who successfully produced correct or mostly correct annotations are allowed to access the annotation tasks containing new phrases  each of these
unknown tasks is presented to   annotators  and the majority label is taken for each word 
in total  we test on     labeled phrases  for a total of       labeled words 
baseline the baseline for this task relies again on the intuition that part of speech is a
useful proxy for aspect and value identification  we know that aspects usually represent
concrete entities  so they are often nouns  and value words are descriptive or counting  so
they are often adjectives or adverbs  therefore  we again use the mxpost tagger to find
pos for each word in the snippet  for the main baseline  tags full  we assign each noun
 nn   an aspect label  and each numeral  adjective  adverb  or verb participle  cd  rb  
jj   vbg  vbn  a value label  for comparison  we also present results for a smaller tagset 
small tags  labeling only nouns  nn   as aspect and adjectives  jj   as values  note that
each of the tags added in the tags full baseline are beneficial to the baselines score 
tree expansion because our full model and the baselines are all designed to pick out
relevant individual words rather than phrases  they may not correspond well to the phrases
which humans have selected as relevant  therefore  we also evaluate on a set of expanded
labels identified with parse trees from the stanford parser  klein   manning          specifically  for each non background word  we identify the largest containing noun phrase  for
both aspects and values  or adjective or adverb phrase  for values only  which does not
also contain oppositely labeled words  for example  in the noun phrase blackened chicken 
if chicken was labeled as an aspect word and blackened was labeled as a background word 
both will now be labeled as aspect words  however  in the noun phrase tasty chicken where
tasty is already labeled as a value  the label will not be changed and no further expansion
will be attempted  as a final heuristic step  any punctuation  determiners  and conjunctions
   available at http   nlp stanford edu software lex parser shtml 

   

fisauper   barzilay

tree expansion procedure for aspect words 
   find noun phrases which contain the aspect word  pork  
the

  innovative

            

appetizers and the pork with apple glaze were the
np 
np 
np 

  highlights
           

   select the largest noun phrase that does not contain value  sentiment  words 
 np  is valid  it does not contain value words  however  it is not the largest valid np 
 np  is valid  it does not contain value words  it is the largest valid np  so it is selected 
 np  contains a value word    innovative  
so it is invalid 
            

   convert all background words within the selected noun phrase to aspect words
except punctuation  determiners  and conjunctions 
the

  innovative

            

appetizers and the pork with apple glaze were the

  highlights
           

figure     the tree expansion procedure for value words  with an example snippet  the
procedure is similar for aspect words  except adjective phrases and adverb phrases are also
considered for expansion 
aspect
precision recall

f 

value
precision recall

f 

tags small
tree

    
    

    
    

    
    

    
    

    
    

    
    

tags full
tree

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

our model
tree

table    per word labeling precision and recall of our model compared to the tags small
and tags full baselines  both with and without expansion by trees  our model is most
precise on aspect and has better recall on value  note that in general the process of expanding labels with the tree structure increases recall at the expense of precision 
which would be newly labeled as aspect or value words are ignored and kept as background
words  the steps of this procedure with an illustrative example are shown in figure    
results we evaluate all systems on precision and recall for aspect and value separately 
results for all systems are shown in table    our model without the tree expansion is
highly precise at the expense of recall  however when the expansion is performed  its recall
improves tremendously  especially on value words 
while this result is initially disappointing  it is possible to adjust model parameters to
increase performance at this task  for example  for aspect words we could put additional
   

fiautomatic aggregation by joint modeling of aspects and values

the moqueca was delicious
and        
perfect winter food         
warm   filling and hearty but    
not    
too       
heavy  
         
the bacon wrapped almond dates were         
amazing but the plantains with cheese were boring
 
      
the artichoke and homemade pasta appetizers were      
great

table    high precision  low recall aspect word labeling by our full model  note that a
human would likely identify complete phrases such as bacon wrapped almond dates and
homemade pasta appetizers  however  the additional noise degrades performance on the
clustering task 

start
a
v
b
i

a
    
    
    
    
    

v
    
    
    
    
    

b
    
    
    
    
    

i
    
    
    
    
    

end
    
    
    
    
    

table    learned transition distribution from our model  the pattern of high precision of
aspect words is represented by a preference against continuing a string of several aspect
words  causing the model to prefer single  precise aspect words  likewise  the better recall
of value words is indicated by a higher value of the v v transition  which can encourage
several words in a row to be marked as value words 
i j w
mass on the prior for zw
  a or increase the dirichlet hyperparameter a   however 
while this increases performance on the word labeling task  it also decreases performance
correspondingly on the clustering task  by examination of the data  this correlation is
perfectly reasonable  in order to succeed at the clustering task  the model selects only the
most relevant portions of the snippet as aspect words  when the entire aspect and value
are identified  clustering becomes noisy  table   shows some examples of the high precision
labeling which achieves high clustering performance  and table   shows an example of the
learned transition distribution which creates this labeling 

    aspect identification with shared aspects
our second task uses a simplified version of our model designed for aspect identification
only  for this task  we use a corpus of medical visit summaries  in this domain  each
summary is expected to contain similar relevant information  therefore  the set of aspects is
shared corpus wide  to evaluate our model in this formulation  we examine the predicted
clusters of snippets  as in the full model 
      data set
our data set for this task consists of phrases selected from dictated patient summaries at the
pediatric environmental health clinic  pehc  at childrens hospital boston  specializing
in treatment of children with lead poisoning  specifically  after a patients office visit and lab
results are completed  a pehc doctor dictates a letter to the referring physician containing
   

fisauper   barzilay

information about previous visits  current developmental and family status  in office exam
results  lab results  current diagnosis  and plan for the future 
for this experiment  we select phrases from the in office exam and lab results sections
of the summaries  phrases are separated heuristically on commas and semicolons  in a domain which contains a significant amount of extraneous information  such as the restaurant
domain  we must extract phrases which we believe bear some relevance to the task at hand 
however  because the medical text is dense and nearly all relevant  a heuristic separation
is sufficient to extract relevant phrases  there are      snippets in total  taken from    
summaries  the average snippet length is     words  and there are an average of    snippets
per summary  as in the yelp domain  we use the mxpost tagger  ratnaparkhi       
to gain pos tags  figure    shows some example snippets  for this domain  there are
no values  we simply concentrate on the aspect identification task  unlike the restaurant
domain  we use no seed words 
      domain challenges and modeling techniques
in contrast to the restaurant domain  the medical domain uses a single global set of aspects 
these represent either individual lab tests  e g   lead level  white blood cell count  or particular body systems  e g   lungs or cardiovascular    some aspects are far more common than
others  and it is very uncommon for a summary to include more than one or two snippets
about any given aspect  therefore  as mentioned in section      we model the aspect word
distributions and the aspect multinomial as shared between all entities in the corpus 
also in contrast to the restaurant domain  aspects are defined by words taken from the
entire snippet  rather than having aspects only associated with names of measurements
 e g   weight   units and other descriptions of measurement  e g   kilograms  are also
relevant for aspect definition  this property extends to both numeric and written measurements  for example  the aspect lungs is commonly described as clear to auscultation
bilaterally  in order to achieve high performance  our model must leverage all of these
clues to provide proper aspect identification when the name of the measurement is missing
 e g   patient is     cm   while part of speech will still be an important factor to model 
we predict that there will be greater importance on additional parts of speech other than
nouns 
finally  our data set is noisy and contains some irrelevant snippets  such as section
headings  e g   physical examination and review of systems  or extraneous information 
as described in section      we modify our model so that it can ignore partial or complete
snippets 
      cluster prediction
as for joint aspect and sentiment prediction  the goal of this task is to evaluate the quality
of aspect identification  because the aspects are shared across all documents  clusters are
generally much larger  and the set of annotated snippets represents only a fraction of each
cluster 
annotation for this experiment  we use a set of gold clusters gathered over       snippets  annotated by a doctor who is an expert in the domain from the pediatric environmental health clinic at childrens hospital boston  note that as mentioned before  clusters
   

fiautomatic aggregation by joint modeling of aspects and values

he was     cm in height
patients height was       cm
lungs  clear bilaterally to auscultation
lungs were normal
heart regular rate and rhythm  no murmurs
heart normal s  s 

figure     example snippets from the medical data set  grouped according to aspect 
aspect words are underlined and colored blue  this grouping and labeling are not given in
the data set and must be learned by the model 

cluster all
cluster noun
our model

precision

recall

    
    
    

    
    
    

f 
    
    
    

table    results using the muc metric on cluster prediction for the aspect identification
only task  note that the cluster all baseline significantly outperforms cluster noun 
the opposite of what we observe in the joint aspect and value prediction task  this is due
to the dependence of aspect identification on more than just the name of a lab test  such
as the units or other description of the test results  as mentioned in section       

here are global to the domain  e g   many patients have snippets representing blood lead
level  and these are all grouped into one cluster   the doctor was asked to cluster    
snippets at a time  spanning several patients   as clustering the entire set would have been
infeasible for a human annotator  after all    sets of snippets were clustered  the resulting
clusters were manually combined to match up similar clusters from each set  for example  the blood lead level cluster from the first set of     snippets was combined with the
corresponding blood lead level clusters from each other set of snippets  any cluster from
this final set with fewer than   members was removed  in total  this yields a gold set of
   clusters  there are       snippets total  for an average of      snippets per cluster  to
match this  baseline systems and our full model are asked to produce    clusters across the
full data set 
baselines   metric to keep these results consistent with those on the previous task 
we use the same baselines and evaluation metric  both baselines rely on a tf idfweighted clustering algorithm  specifically implemented with cluto package  karypis 
      using agglomerative clustering with the cosine similarity distance metric  as before 
cluster all represents a baseline using unigrams of snippets from the entire data set 
while cluster noun works over only the nouns from the snippets  we again use the
muc cluster evaluation metric for this task  for more details on both baselines and the
evaluation metric  please see section       
   

fisauper   barzilay

results for this experiment  our system demonstrates an improvement of    over the
cluster all baseline  absolute performance is relatively high for all systems in the
medical domain  indicating that the lexical clustering task is less misleading than in the
restaurant domain  it is interesting to note that unlike in the restaurant domain  the
cluster all baseline outperforms the cluster noun baseline  as mentioned in section        the medical data is notable for the relevance of the entire snippet for clustering
 e g   both weight and kilograms are useful to identify the weight aspect   because of
this property  using only nouns to cluster in the cluster noun baseline hurts performance
significantly 

   conclusions and future work
in this paper  we have presented an approach for fine grained content aggregation using
probabilistic topic modeling techniques to discover the structure of individual text snippets 
our model is able to successfully identify clusters of snippets in a data set which discuss
the same aspect of an entity as well as the associated values  e g   sentiment   it requires
no annotation  other than a small list of seed vocabulary to bias the positive and negative
distributions in the proper direction 
our results demonstrate that delving into the structure of the snippet can assist in
identifying key words which are important and unique to the domain at hand  when there
are values to be learned  the joint identification of aspect and value can help to improve the
quality of the results  the word labeling analysis reveals that the model learns a different
type of labeling for each task  specifically  a strict  high precision labeling for the clustering
task and a high recall labeling for sentiment  this follows the intuition that it is important
to identify specific main points for clustering  while in the sentiment analysis task  there
may often be several descriptions or conflicting opinions presented which all need to be
weighed together to determine the overall sentiment 
this model admits a fast  parallelized inference procedure  specifically  the entire inference procedure takes roughly    minutes to run on the restaurant corpus and less than  
minutes on the medical corpus  additionally  the model is neatly extensible and adjustable
to fit the particular characteristics of a given domain 
there are a few limitations of this model which can be improved with future work 
first  our model makes no attempt to explicitly model negation or other word interactions 
increasing the difficulty of both aspect and sentiment analysis for our model  by performing error analysis  we find that negation is a common source of error for the sentiment
analysis task  likewise  on the aspect side  the model can make errors when attempting to
differentiate aspects such as ice cream and cream cheese which share the common aspect
word cream  despite these phrases occurring as bigrams  by using these connections in a
stronger way  such as with an indicator variable for negation or a higher order hmm  the
model could make more informed decisions 
second  while defining aspects per entity as in the restaurant domain has advantages in
that it is possible to get a very fine grained set of applicable aspects  it also fails to leverage
some potential information in the data set  specifically  we know that restaurants sharing
the same type  e g   italian  indian  bakery  etc   should share some common aspects 
however  there are no ties between them in the current model  likewise  even at a global
   

fiautomatic aggregation by joint modeling of aspects and values

level  there may be some aspects which tie in across all restaurants  a hierarchical version
of this model would be able to tie these together and identify different types of aspects 
global  e g   presentation   type level  e g   pasta for the italian type   and restaurant level
 e g   the restaurants special dish  

bibliographic note
portions of this paper have been published previously in a conference publication  sauper 
haghighi    barzilay         however this paper significantly extends that work  we describe several model generalizations and extensions  section      and their effects on our
inference procedure  section       we present new experimental results  including additional baseline comparisons and an additional experiment  section       we also introduce
a new domain  medical summary text  which is quite different than the domain of restaurant
reviews and therefore requires several fundamental changes to the model  section      

acknowledgments
the authors acknowledge the support of the nsf  career grant iis           nih  grant
  r   lm            nokia  and the darpa machine reading program  afrl prime
contract no  fa        c        thanks to peter szolovits and the mit nlp group for
their helpful comments  any opinions  findings  conclusions  or recommendations expressed
in this paper are those of the authors  and do not necessarily reflect the views of the funding
organizations 

references
barzilay  r   mckeown  k  r     elhadad  m          information fusion in the context of
multi document summarization  in proceedings of acl  pp         
blei  d  m     mcauliffe  j          supervised topic models  in advances in nips  pp 
       
blei  d  m   ng  a  y     jordan  m  i          latent dirichlet allocation  journal of
machine learning research             
carenini  g     moore  j  d          generating and evaluating evaluative arguments 
artificial intelligence              
carenini  g   ng  r     pauls  a          multi document summarization of evaluative text 
in proceedings of eacl  pp         
carenini  g   ng  r  t     zwart  e          extracting knowledge from evaluative text 
in proceedings of k cap  pp       
chen  h   benson  e   naseem  t     barzilay  r          in domain relation discovery with
meta constraints via posterior regularization  in proceedings of acl  pp         
chen  h   branavan  s  r  k   barzilay  r     karger  d  r          global models of
document structure using latent permutations  in proceedings of acl hlt  pp     
    
   

fisauper   barzilay

crammer  k     singer  y          pranking with ranking  in advances in nips  pp 
        mit press 
dang  h  t          overview of duc       in proceedings of duc at emnlp hlt 
dang  h  t          overview of duc       in proceedings of duc at naacl hlt 
dave  k   lawrence  s     pennock  d  m          mining the peanut gallery  opinion
extraction and semantic classification of product reviews  in proceedings of www 
pp         
hu  m     liu  b          mining and summarizing customer reviews  in proceedings of
sigkdd  pp         
karypis  g          cluto a clustering toolkit  tech  rep          dept  of computer
science  university of minnesota  available at http   www cs umn educluto 
kim  h  d     zhai  c          generating comparative summaries of contradictory opinions
in text  in proceedings of cikm  pp         
kim  s     hovy  e          automatic detection of opinion bearing words and sentences 
in proceedings of ijcnlp  pp       
kim  s  m     hovy  e          automatic identification of pro and con reasons in online
reviews  in proceedings of coling acl  pp         
klein  d     manning  c  d          accurate unlexicalized parsing  in proceedings of acl 
pp         
liu  b   hu  m     cheng  j          opinion observer  analyzing and comparing opinions
on the web  in proceedings of www  pp         
lu  y     zhai  c          opinion integration through semi supervised topic modeling  in
proceedings of www  pp         
mani  i          automatic summarization  vol     john benjamins pub co 
mcdonald  r   hannan  k   neylon  t   wells  m     reynar  j          structured models
for fine to coarse sentiment analysis  in proceedings of acl  pp         
mei  q   ling  x   wondra  m   su  h     zhai  c          topic sentiment mixture  modeling
facets and opinions in weblogs  in proceedings of www  pp         
pang  b     lee  l          a sentimental education  sentiment analysis using subjectivity
summarization based on minimum cuts  in proceedings of acl  pp         
pang  b     lee  l          opinion mining and sentiment analysis  foundations and trends
in information retrieval          
pang  b   lee  l     vaithyanathan  s          thumbs up  sentiment classification using
machine learning techniques  in proceedings of emnlp  pp       
popescu  a  m   nguyen  b     etzioni  o          opine  extracting product features
and opinions from reviews  in proceedings of emnlp hlt  pp         
radev  d     mckeown  k          generating natural language summaries from multiple
on line sources  computational linguistics                 
   

fiautomatic aggregation by joint modeling of aspects and values

radev  d  r   jing  h     budzikowska  m          centroid based summarization of multiple documents  sentence extraction  utility based evaluation  and user studies  in
proceedings of the naacl anlp workshop on automatic summarization  pp    
   
ratnaparkhi  a          a maximum entropy model for part of speech tagging  in proceedings of emnlp  pp         
sauper  c   haghighi  a     barzilay  r          incorporating content structure into text
analysis applications  in proceedings of emnlp  pp         
sauper  c   haghighi  a     barzilay  r          content models with attitude  in proceedings of acl  pp         
seki  y   eguchi  k   kanodo  n     aono  m          multi document summarization with
subjectivity analysis at duc       in proceedings of duc at emnlp hlt 
seki  y   eguchi  k   kanodo  n     aono  m          opinion focused summarization and
its analysis at duc       in proceedings of duc at naacl hlt  pp         
snyder  b     barzilay  r          multiple aspect ranking using the good grief algorithm 
in proceedings of naacl hlt  pp         
titov  i     mcdonald  r       a   a joint model of text and aspect ratings for sentiment
summarization  in proceedings of acl  pp         
titov  i     mcdonald  r       b   modeling online reviews with multi grain topic models 
in proceedings of www  pp         
turney  p  d          thumbs up or thumbs down   semantic orientation applied to unsupervised classification of reviews  in proceedings of acl  pp         
vilain  m   burger  j   aberdeen  j   connolly  d     hirschman  l          a modeltheoretic coreference scoring scheme  in proceedings of muc  pp       
yu  h     hatzivassiloglou  v          towards answering opinion questions  separating
facts from opinions and identifying the polarity of opinion sentences  in proceedings
of emnlp  pp          association for computational linguistics 

   

fi