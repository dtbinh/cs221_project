journal artificial intelligence research                 

submitted       published      

incremental clustering expansion faster
optimal planning decentralized pomdps
frans a  oliehoek

frans oliehoek maastrichtuniversity nl

maastricht university
maastricht  netherlands

matthijs t j  spaan

m t j spaan tudelft nl

delft university technology
delft  netherlands

christopher amato

camato csail mit edu

massachusetts institute technology
cambridge  ma  usa

shimon whiteson

s a whiteson uva nl

university amsterdam
amsterdam  netherlands

abstract
article presents state of the art optimal solution methods decentralized
partially observable markov decision processes  dec pomdps   general models
collaborative multiagent planning uncertainty  building generalized multiagent a    gmaa   algorithm  reduces problem tree one shot collaborative
bayesian games  cbgs   describe several advances greatly expand range decpomdps solved optimally  first  introduce lossless incremental clustering
cbgs solved gmaa   achieves exponential speedups without sacrificing
optimality  second  introduce incremental expansion nodes gmaa  search
tree  avoids need expand children  number worst case
doubly exponential nodes depth  particularly beneficial little clustering
possible  addition  introduce new hybrid heuristic representations
compact thereby enable solution larger dec pomdps  provide theoretical
guarantees that  suitable heuristic used  incremental clustering incremental expansion yield algorithms complete search equivalent  finally 
present extensive empirical results demonstrating gmaa  ice  algorithm
synthesizes advances  optimally solve dec pomdps unprecedented size 

   introduction
key goal artificial intelligence development intelligent agents interact
environment order solve problems  achieve goals  maximize utility 
agents sometimes act alone  researchers increasingly interested collaborative multiagent
systems  teams agents work together perform manner tasks  multiagent
systems appealing  tackle inherently distributed problems 
facilitate decomposition problems complex tackled single
c
    
ai access foundation  rights reserved 

fioliehoek  spaan  amato    whiteson

agent  huhns        sycara        panait   luke        vlassis        busoniu  babuska   
de schutter        
one primary challenges multiagent systems presence uncertainty  even
single agent systems  outcome action may uncertain  e g   action may fail
probability  furthermore  many problems state environment may
uncertain due limited noisy sensors  however  multiagent settings problems
often greatly exacerbated  since agents access sensors  typically
small fraction complete system  ability predict agents
act limited  complicating cooperation  uncertainties properly addressed 
arbitrarily bad performance may result 
principle  agents use communication synchronize beliefs coordinate
actions  however  due bandwidth constraints  typically infeasible agents
broadcast necessary information agents  addition  many realistic
scenarios  communication may unreliable  precluding possibility eliminating uncertainty agents actions 
especially recent years  much research focused approaches  collaborative 
multiagent systems deal uncertainty principled way  yielding wide variety
models solution methods  pynadath   tambe        goldman   zilberstein       
seuken   zilberstein         article focuses decentralized partially observable
markov decision process  dec pomdp   general model collaborative multiagent planning uncertainty  unfortunately  solving dec pomdp  i e   computing optimal
plan  generally intractable  nexp complete   bernstein  givan  immerman    zilberstein 
      fact even computing solutions absolutely bounded error  i e    approximate
solutions  nexp complete  rabinovich  goldman    rosenschein         particular 
number joint policies grows exponentially number agents observations
doubly exponentially respect horizon problem   though complexity results preclude methods efficient problems  developing better optimal
solution methods dec pomdps nonetheless important goal  several reasons 
first  since complexity results describe worst case  still great potential
improve performance optimal methods practice  fact  evidence
many problems solved much faster worst case complexity bound indicates
 allen   zilberstein         article  present experiments clearly demonstrate
point  many problems  methods propose scale vastly beyond would
expected doubly exponential dependence horizon 
second  computer speed memory capacity increase  growing set small
medium sized problems solved optimally  problems arise naturally
others result decomposition larger problems  instance  may possible
extrapolate optimal solutions problems shorter planning horizons  using
starting point policy search longer horizon problems work eker
akn         use shorter horizon  no communication solutions inside problems
communication  nair  roth    yohoo        goldman   zilberstein         generally 
optimal policies smaller problems potentially used find good solutions larger
problems  instance  transfer planning  oliehoek        oliehoek  whiteson    spaan 
   surprisingly  number states dec pomdp less important  e g   brute force search depends
number states via policy evaluation routine  scales linearly number states 

   

fiincremental clustering expansion faster optimal planning dec pomdps

      employs optimal solutions problems agents better solve problems
many agents  performing  approximate  influence based abstraction influence search
 witwicki        oliehoek  witwicki    kaelbling         optimal solutions component
problems potentially used find  near  optimal solutions larger problems 
third  optimal methods offer important insights nature specific dec pomdp
problems solutions  instance  methods introduced article enabled
discovery certain properties broadcastchannel benchmark problem make
much easier solve 
fourth  optimal methods provide critical inspiration principled approximation methods  fact  almost successful approximate dec pomdp methods based optimal
ones  see  e g   seuken   zilberstein      b      a  dibangoye  mouaddib    chai draa       
amato  dibangoye    zilberstein        wu  zilberstein    chen      a  oliehoek       
locally optimal ones  velagapudi  varakantham  scerri    sycara           clustering technique presented article forms basis recently introduced approximate
clustering technique  wu  zilberstein    chen        
finally  optimal methods essential benchmarking approximate methods  recent
years  huge advances approximate solution dec pomdps  leading
development solution methods deal large horizons  hundreds agents
many states  e g   seuken   zilberstein      b  amato et al         wu et al       a 
oliehoek        velagapudi et al         
however  since computing even  approximate
solutions nexp complete  method whose complexity doubly exponential cannot
guarantees absolute error solution  assuming exp  nexp   such 
existing effective approximate methods quality guarantees  
consequently  difficult meaningfully interpret empirical performance without
upper bounds optimal methods supply  approximate methods benchmarked lower bounds  e g   approximate methods   comparisons cannot
detect method fails find good solutions  requires benchmarking
upper bounds and  unfortunately  upper bounds easier compute  qmdp
qpomdp  loose helpful  oliehoek  spaan    vlassis         such 
benchmarking respect optimal solutions important part verification
approximate algorithm  since existing optimal methods tackle small problems 
scaling optimal solutions larger problems critical goal 
    contributions
article presents state of the art optimal solution methods dec pomdps 
particular  describes several advances greatly expand horizon many decpomdps solved optimally  addition  proposes evaluates complete algorithm
synthesizes advances  approach based generalized multiagent a 
 gmaa   algorithm  oliehoek  spaan    vlassis         makes possible reduce
problem tree one shot collaborative bayesian games  cbgs   appeal
   method velagapudi et al         repeatedly computes best responses way similar dp jesp
 nair  tambe  yokoo  pynadath    marsella         best response computation  however  exploits
sparsity interactions 
   note refer methods without quality guarantees approximate rather heuristic avoid
confusion heuristic search  used throughout article exact 

   

fioliehoek  spaan  amato    whiteson

approach abstraction layer introduces  led various insights decpomdps and  turn  improved solution methods describe 
specific contributions article are  
   introduce lossless clustering cbgs  technique reduce size cbgs
gmaa  enumerates possible solutions  preserving optimality 
exponentially reduce number child nodes gmaa  search tree  leading
huge increases efficiency  addition  applying incremental clustering  ic 
gmaa   gmaa  ic method avoid clustering exponentially sized cbgs 
   introduce incremental expansion  ie  nodes gmaa  search tree  although
clustering may reduce number children search node  number
worst case still doubly exponential nodes depth  gmaa  ice  applies
ie gmaa  ic  addresses problem creating next child node
candidate expansion 
   provide theoretical guarantees gmaa  ic gmaa  ice  particular  show that  using suitable heuristic  algorithms complete
search equivalent 
   introduce improved heuristic representation  tight heuristics based
underlying pomdp solution  qpomdp   value function resulting
assuming   step delayed communication  qbg   essential heuristic search methods gmaa   oliehoek  spaan    vlassis         however  space needed
store heuristics grows exponentially problem horizon  introduce hybrid representations compact thereby enable solution larger
problems 
   present extensive empirical results show substantial improvements
current state of the art  whereas seuken zilberstein        argued gmaa 
best optimally solve dec pomdps one horizon brute force
search  results demonstrate gmaa  ice much better  addition 
provide comparative overview results competitive optimal solution methods
literature 
primary aim techniques introduced article improve scalability
respect horizon  empirical results confirm techniques highly
successful regard  added bonus  experiments demonstrate improvement
scalability respect number agents  particular  present first optimal
results general  non special case  dec pomdps three agents  extensions
techniques achieve improvements respect number agents 
well promising ways combine ideas behind methods state of the art
approximate approaches  discussed future work section   
   article synthesizes extends research already reported two conference papers  oliehoek 
whiteson    spaan        spaan  oliehoek    amato        

   

fiincremental clustering expansion faster optimal planning dec pomdps

    organization
article organized follows  section   provides background dec pomdp model 
gmaa  heuristic search solution method  well suitable heuristics  section   
introduce lossless clustering cbgs integration gmaa   section   introduces incremental expansion search nodes  empirical evaluation proposed
techniques reported section    give treatment related work section    future
work discussed section   conclusions drawn section   

   background
dec pomdp  multiple agents must collaborate maximize sum common
rewards receive multiple timesteps  actions affect immediate
rewards state transition  current state known
agents  timestep agent receives private observation correlated
state 



definition    dec pomdp tuple d  s  a  t  o  o  r  b    h  
             n  finite set agents 


  s           s s  finite set states 

  ai set joint actions   ha            i  ai finite set actions
available agent i 
transition function specifying state transition probabilities pr s  s a  
  oi finite set joint observations  every stage one joint observation
  ho       on received  agent observes component oi  
observation function  specifies observation probabilities pr o a s   
r s a  immediate reward function mapping  s a  pairs real numbers 
b   s  initial state distribution time       s  denotes infinite
set probability distributions finite set s 
h horizon  i e   number stages  consider case h finite 
stage           h    agent takes individual action receives individual
observation 
example    recycling robots   illustrate dec pomdp model  consider team robots tasked
removing trash office building  depicted fig     robots sensors find marked
trash cans  motors move around order look cans  well gripper arms grasp carry
can  small trash cans light compact enough single robot carry  large trash cans
require multiple robots carry together  people use them  larger trash
cans fill quickly  robot must ensure battery remains charged moving
charging station expires  battery level robot degrades due distance
robot travels weight item carried  robot knows battery level
robots location robots within sensor range  goal
problem remove much trash possible given time period 
problem represented dec pomdp natural way  states  s  consist
different locations robot  battery levels different amounts trash
cans  actions  ai   robot consist movements different directions well decisions
   

fioliehoek  spaan  amato    whiteson

figure    illustration recycling robots example  two robots remove
trash office environment three small  blue  trash cans two large  yellow  ones 
situation  left robot might observe large trash next full 
robot small trash empty  however  none sure trash
cans state due limited sensing capabilities  see state trash cans
away  particular  one robot knowledge regarding observations robot 
pick trash recharge battery  when range charging station  
observations  oi   robot consist battery level  location  locations
robots sensor range amount trash cans within range  rewards  r  could consist
large positive value pair robots emptying large  full  trash can  small positive value
single robot emptying small trash negative values robot depleting battery
trash overflowing  optimal solution joint policy leads expected behavior  given
rewards properly specified   is  ensures robots cooperate empty
large trash cans appropriate small ones individually considering battery usage 

explanatory purposes  consider much simpler problem  so called decentralized tiger problem  nair et al         
example    dec tiger   dec tiger problem concerns two agents find hallway two doors  behind one door  treasure behind tiger  state
describes door tiger behindleft  sl   right  sr  each occurring     probability
 i e   initial state distribution b  uniform   agent perform three actions  open left
door  aol    open right door  aor   listen  ali    clearly  opening door treasure
yield reward  opening door tiger result severe penalty  greater reward
given agents opening correct door time  such  good strategy
probably involve listening first  listen actions  however  minor cost  negative reward  
every stage agents get observation  agents either hear tiger behind left
 ohl   right  ohr   door  agent     chance hearing incorrectly  getting wrong
observation   moreover  observation informative agents listen  either agent opens
door  agents receive uninformative  uniformly drawn  observation problem resets
sl sr equal probability  point problem continues  agents may
able open door treasure multiple times  note that  since two observations
agents get ohl   ohr   agents way detecting problem reset 
one agent opens door listens  agent able tell
door opened  complete specification  see discussion nair et al         

given dec pomdp  agents common goal maximize expected cumulative
reward return  planning task entails finding joint policy   h           n
space joint policies   specifies individual policy agent i 
   

fiincremental clustering expansion faster optimal planning dec pomdps

individual policy general specifies individual action action observation history
 aoh   it    a i  o i          ait   oti    e g     it     ati   however  possible restrict
attention deterministic pure policies  case maps observation history
  action  e g     o       number policies
 oh   o i          oti      oit



h      o    
  o
 

 ai  
number joint policies therefore

n o  h  
 a    o     
     
denote largest individual action observation sets  quality
particular joint policy expressed expected cumulative reward induces  referred
value 
definition    value v    joint policy
v      e

h 
hx
t  




r st  at  fi b   

     

expectation sequences states  actions observations 
planning problem dec pomdp find optimal joint policy   i e   joint
policy maximizes value    arg max v    
individual policy depends local information  oi available
agent  on line execution phase truly decentralized  communication takes place
modeled via actions observations  planning however  may take place
off line phase centralized  scenario consider article 
detailed introduction dec pomdps see  e g   work seuken zilberstein
       oliehoek        
    heuristic search methods
recent years  numerous dec pomdp solution methods proposed 
methods fall one two categories  dynamic programming heuristic search methods 
dynamic programming methods take backwards bottom up perspective first considering policies last time step   h   using construct policies stage
  h    etc  contrast  heuristic search methods take forward top down perspective
first constructing plans     extending later stages 
article  focus heuristic search approach shown state of the art
results  make clear section  method interpreted searching
tree collaborative bayesian games  cbgs   cbgs provide convenient abstraction
layer facilitates explanation techniques introduced article 
section provides concise background heuristic search methods 
detailed description  see work oliehoek  spaan  vlassis         description dynamic programming methods relationship heuristic search methods 
see work oliehoek        
      multiagent a 
szer  charpillet  zilberstein        introduced heuristically guided policy search method
called multiagent a   maa    performs a  search partially specified joint policies 
   

fioliehoek  spaan  amato    whiteson

t  

t  

t  

i 

ali
  

 i

ohr

ohl
aol

i 

aol

ohl

ohr

ohl

ohr

ali

ali

aol

ali

i 

  
figure    arbitrary policy dec tiger problem  figure illustrates different
types partial policies used paper  shown past policy  i consists two decision
rules i    i    shown two sub tree policies          introduced section        
pruning joint policies guaranteed worse best  fully specified  joint policy
found far  oliehoek  spaan  vlassis        generalized algorithm making explicit
expand selection operators performed heuristic search  resulting algorithm 
generalized maa   gmaa   offers unified perspective maa  forward sweep
policy computation method  emery montemerlo         differ implement
gmaa s expand operator  forward sweep policy computation solves  i e   finds best
policy for  collaborative bayesian games  maa  finds policies collaborative
bayesian games  describe section       
gmaa  algorithm considers joint policies partially specified respect
time  partially specified policies formalized follows 
definition    decision rule agent decision stage mapping action  ai  
observation histories stage actions  

article  consider deterministic policies  since policies need condition
actions observation histories  made decision rules map length  ai   joint decision rule   h          nt specifies
observation histories actions   
 

decision rule agent  fig    illustrates concept  well past policy 
introduce shortly  discussed below  decision rules allow partial policies
defined play crucial role gmaa  algorithms developed article 
definition    partial past policy stage t  ti   specifies part agent policy
relates stages   t  is  specifies decision rules first stages 
ti    i   i           it     past policy stage h regular  fully specified  policy
hi     past joint policy                     t    specifies joint decision rules first
stages 
gmaa  performs heuristic search partial joint policies constructing
search tree illustrated fig   a  node q   ht   vi search tree specifies
past joint policy heuristic value v  heuristic value v node represents
optimistic estimate past joint policy vb  t    computed via
vb  t     v     t   t     h t   h   t   
   

     

fiincremental clustering expansion faster optimal planning dec pomdps

b    

 
 

 

 

 
 

 
 

 
 

 

   

b    

 

 

 

   

b    

b    

 

 a  maa  perspective 

   

b    

 

   

b    

 b  cbg perspective 

figure    generalized maa   associated every node heuristic value  search
trees two perspectives shown equivalent certain assumptions heuristic 
explained section     
h t   h  heuristic value remaining h stages v     t   t   actual
expected reward achieves first stages  for definition  see appendix a    
clearly  h t   h  admissible heuristica guaranteed overestimationso vb  t    
algorithm   illustrates gmaa   starts creating node q   completely unspecified joint policy   placing open list l  then  selects nodes  algorithm   
expands  algorithm     repeating process certain found
optimal joint policy 
select operator returns highest ranked node  defined following comparison operator 
definition    node comparison operator   defined two nodes q   ht  vi  q  
ht  v follows 



  v    v
v   v
q   q   depth q    depth q     otherwise depth q     depth q  
     



 
  otherwise 
is  comparison operator first compares heuristic values  equal 
compares depth nodes  finally  nodes equal value equal depth 
lexically compares past joint policies  ranking leads a  behavior  i e   selecting
node open list highest heuristic value  gmaa   well guaranteeing
selection order incremental expansion technique  introduced section    
ranking nodes greater depth higher case equal heuristic value helps find tight
lower bounds early first expanding deeper nodes  szer et al         useful
incremental expansion 
   formally  h underestimate value  note that  unlike classical a  applications
path planningin admissible heuristic overestimatein setting maximize reward 
rather minimize cost 

   

fioliehoek  spaan  amato    whiteson

algorithm   generalized multiagent a  
input  dec pomdp  admissible heuristic h  empty open list l
output  optimal joint policy
   vgm aa
   q   h        v    i
   l insert q    
   repeat
  
q select l 
  
qexpand expand q  h 
  
depth q    h  
  
  qexpand contains fully specified joint policies  interested best one  
  
h  vi bestjointpolicyandvalue qexpand  
   
v   vgm aa
   

 found new best joint policy 
   
vgm aa v
   
l prune vgm aa  
  optionally  prune open list 
   
end
   
else


 add expanded children open list 
   
l insert  q qexpand   q  v   vgm aa  
   
end
   
postprocessnode q  l 
    l empty
    return

algorithm   select l   return highest ranked node open list 
input  open list l  total order nodes  
output  highest ranked node q
   q q l s t  q l  q    q   q   q 
   return q

expand operator constructs qexpand   set child nodes  is  given node
contains partial joint policy                     t     constructs t     set
t                       t       appending possible joint decision rules next time
step t  t     heuristic value computed node constructed 
expansion  algorithm checks  line    expansion resulted fully specified
joint policies  not  children sufficient heuristic value placed open list
algorithm   expand q  h   expand operator plain maa  
input  q   ht   vi search node expand  h admissible heuristic 
output  qexpand set containing expanded child nodes 
   qexpand   
   t    t     t      t     
   t   t  
  
vb  t     v     t  t       h t    
  
q ht     vb  t    i
  
qexpand  insert q  
   end
   return qexpand

   

 create child node 

fiincremental clustering expansion faster optimal planning dec pomdps

algorithm   postprocessnode q l 
input  q expanded parent node  l open list 
output  expanded node removed 
   l pop q 

 line      children fully specified  bestjointpolicyandvalue returns best
joint policy  and value  qexpand  see algorithm    appendix a   details
bestjointpolicyandvalue   gmaa  maintains lower bound vgm aa corresponds actual value best fully specified joint policy found far  newly
found joint policy higher value lower bound updated  lines         also 
nodes partial joint policies t   upper bound lower best solution
far  vb  t       vgm aa   pruned  line      pruning takes additional time 
save memory  finally  postprocessnode simply removes parent node open
list  this procedure augmented incremental expansion section     search ends
list becomes empty  point optimal joint policy found 
gmaa  complete  i e   search finds solution  therefore  theory 
gmaa  guaranteed eventually produce optimal joint policy  szer et al         
however  practice  often infeasible larger problems  major source complexity
full expansion search node  number joint decision rules stage
form children node depth search tree 



 a  n  o      
     
doubly exponential t  comparing              see worst case
complexity expanding node deepest level tree   h   comparable
brute force search entire dec pomdp  consequently  seuken zilberstein
       conclude maa  best solve problems whose horizon   greater
already solved nave brute force search 
      bayesian game perspective
gmaa  makes possible interpret maa  solution collection collaborative
bayesian games  cbgs   employ approach throughout article  facilitates
improvements gmaa  introduce  results significant advances
state of the art dec pomdp solutions 
bayesian game  bg  models one shot interaction number agents 
extension well known strategic game  also known normal form game 
agent holds private information  osborne   rubinstein         cbg bg
agents receive identical payoffs  bayesian game perspective  node q
gmaa  search tree  along corresponding partial joint policy   defines
cbg  oliehoek  spaan    vlassis         is  given state distribution b     
possible construct cbg b b   t   represents decision making problem
stage given followed first stages starting b    clear
b  is  simply write b t   
   follow convention root depth   

   

fioliehoek  spaan  amato    whiteson

definition    collaborative bayesian game  cbg  b b   t     hd  a    pr    ui modeling
stage dec pomdp  given initial state distribution b  past joint policy   consists
of 
d  set agents          n  
a  set joint actions 
  set joint types  specifies type agent  
h           n i 
pr    probability distribution joint types 
u   heuristic  payoff function mapping joint type action real number  u  a  
bayesian game  type agent represents private information holds 
instance  bayesian game modeling job recruitment scenario  type agent
may indicate whether agent hard worker  cbg dec pomdp  agents
private information individual aoh  therefore  type agent corresponds
 it   history actions observations   it   similarly  joint type corresponds
joint aoh     
consequently  u provide  heuristic  estimate long term payoff
    a  pair  words  payoff function corresponds heuristic q value  u  a 
b    a   discuss compute heuristics section      given   b   
q 
correspondence joint types aohs  probability distribution joint types is 
pr     pr    b   t   

     

latter probability marginal pr s    b   t   defined  a    used
computation value partial joint policy v     t   t   appendix a    note due
correspondence types aohs  size cbg b b   t   stage
exponential t 
cbg  agent uses bayesian game policy maps individual types actions 
 i     ai   correspondence types aohs   joint  policy
cbg corresponds  joint  decision rule    remainder article 
assume deterministic past joint policies   implies one   non zero
probability given observation history  o   thus  effectively maps observation histories
actions  number b b   t   given        value joint cbg
policy cbg b b   t   is 
x
b          
pr    b   t  q 
     
vb     
 


       hi   it  ii     n denotes joint action results application
individual cbg policies individual aoh  it specified    
example    consider cbg dec tiger given past joint policy   specifies listen first two stages  stage      agent four possible observation histories 
        ohl  ohl     ohl  ohr     ohr  ohl     ohr  ohr    correspond directly possible types 


probabilities joint types given   listed fig   a  since joint ohs together
  determine joint aohs  correspond so called joint beliefs  probability distributions
states  introduced formally section       fig   b shows joint beliefs  serve
basis heuristic payoff function  as discussed section      
   

fiincremental clustering expansion faster optimal planning dec pomdps

 o  
 ohl  ohl  
 ohl  ohr  
 ohr  ohl  
 ohr  ohr  

 o  
 ohl  ohl  
     
     
     
     

 ohl  ohr  
     
     
     
     

 ohr  ohl  
     
     
     
     

 ohr  ohr  
     
     
     
     

 a  joint type probabilities 

 o  
 ohl  ohl  
 ohl  ohr  
 ohr  ohl  
 ohr  ohr  

 o  
 ohl  ohl  
     
     
     
   

 ohl  ohr  
     
   
   
     

 ohr  ohl  
     
   
   
     

 ohr  ohr  
   
     
     
     

 b  induced joint beliefs  listed probability pr sl       b   
tiger behind left door 

figure    illustration dec tiger problem past joint policy   specifies
listen actions first two stages 

algorithm   expand cbg q  h   expand operator gmaa  makes use cbgs 
input  q   ht   vi search node expand 
b   a  
input  h admissible heuristic form q 
output  qexpand set containing expanded child nodes 
b
   b b   t   constructbg b   t   q 
   qexpand generateallchildrenforcbg b b   t   
   return qexpand

 as explained section       

solution cbg maximizes        cbg equivalent team
decision process finding solution np complete  tsitsiklis   athans         however 
bayesian game perspective gmaa   illustrated fig   b  issue solving
cbg  i e   finding highest payoff   relevant need expand  
is  expand operator enumerates appends form set
extended joint policies


t      t       joint cbg policy b b   t  
uses set construct qexpand   set child nodes  heuristic value
child node q qexpand specifies t      t     given
vb  t       v     t   t     vb    

     

expand operator makes use cbgs summarized algorithm    uses
generateallchildrenforcbg subroutine  algorithm    appendix a     fig   b illustrates
bayesian game perspective gmaa  
   

fioliehoek  spaan  amato    whiteson

    heuristics
perform heuristic search  gmaa  defines heuristic value vb  t   using        contrast  bayesian game perspective uses        two formulations equivalent
b faithfully represents expected immediate reward  oliehoek  spaan    vlasthe heuristic q
sis         consequence gmaa  via cbgs complete  and thus finds optimal
solutions  stated following theorem 
theorem    using heuristic form
b    a    est  r st  a          e  t    vb    t           a  
q 


     

vb    t     q    t        t      overestimation value optimal joint
policy   gmaa  via cbgs complete 
proof  see appendix 
theorem  q     a  q value  i e   expected future cumulative reward
performing   joint policy  oliehoek  spaan p
  vlassis         expectation

 
immediate reward written r   a    ss r s a  pr s    b    
computed using pr s    b     quantity refer joint belief resulting  
denote b  joint belief computed via repeated application
bayes rule  kaelbling  littman    cassandra         conditional  a    
rest subsection reviews several heuristics used gmaa  
      qmdp
b   a  solve underlying mdp  i e  
one way obtain admissible heuristic q 
assume joint action chosen single puppeteer agent observe true
state  approach  known qmdp  littman  cassandra    kaelbling         uses

mdp value function qt 
 s  a   computed using standard dynamic programming

b  t
techniques  puterman         order transform qt 
 s  a  values qm    a  values 
compute 
x t 
b     a   
      
q
q  s a  pr s    b    


ss

solving underlying mdp time complexity linear h  makes it 
especially compared dec pomdp  easy compute  addition  necessary
store value  s a  pair  stage t  however  bound provides
optimal dec pomdp q  value function loose  oliehoek   vlassis        
      qpomdp
similar underlying mdp  one define underlying pomdp dec pomdp 
i e   assuming joint action chosen single agent access joint observation  
   alternatively one view pomdp multiagent pomdp agents instantaneously
broadcast private observations 

   

fiincremental clustering expansion faster optimal planning dec pomdps

tree

vector

t  
t  
t  
t  
figure    visual comparison tree vector based q representations 

resulting solution used heuristic  called qpomdp  szer et al         roth 
simmons    veloso         optimal qpomdp value function satisfies 

qp  bt   a    r bt  a   

x

p  ot    bt  a  max qp  bt    at     
at  

ot  

      

p
bt joint belief  r bt  a    ss r s a bt  s  immediate reward  bt  
joint belief resulting bt action joint observation ot     use qpomdp  
b p     a    qt  b t  a  
    directly use value induced joint belief  q
p

two approaches computing qpomdp   one construct belief mdp
tree joint beliefs  illustrated fig     left   starting b   corresponding
empty joint aoh        compute resulting     corresponding
  
belief b continue recursively  given tree  possible compute values
nodes standard dynamic programming 
another possibility apply vector based pomdp techniques  see fig     right   
q value function stage qtp  b a  represented using set vectors joint
   kaelbling et al          qt  b a  defined maximum
action v    v t          v a 
p
inner product 
qtp  b a    max b vat  
v
va


given v h    vector representation last stage  compute v h    etc  order
limit growth number vectors  dominated vectors pruned 
since qmdp upper bound pomdp value function  hauskrecht         qpomdp
provides tighter upper bound q qmdp   however  costly compute
store  tree based vector based approach may need store number
values exponential h 
   

fioliehoek  spaan  amato    whiteson

      qbg
third heuristic  called qbg   assumes agent team access
individual observation communicate   step delay   define qbg
x
qb     a    r    a    max
pr ot       a qb    t     ot      
      


ot  

t  
  h   ot  
        n  on  i tuple individual policies   oi ai cbg

constructed    a  qpomdp   qbg represented using vectors  varaiya  
walrand        hsu   marcus        oliehoek  spaan    vlassis        two
manners computation  tree vector based  apply  yields tighter heuristic
qpomdp   computation additional exponential dependence maximum
number individual observations  oliehoek  spaan    vlassis         particularly
troubling vector based computation  since precludes effective application incremental pruning  a  cassandra  littman    zhang         overcome problem  oliehoek
spaan        introduce novel tree based pruning methods 

   clustering
gmaa  solves dec pomdps repeatedly constructing cbgs expanding joint
bg policies them  however  number equal number regular
maa  child nodes given       thus grows doubly exponentially horizon h 
section  propose new approach improving scalability respect h
clustering individual aohs  reduces number therefore number
constructed child nodes gmaa  search tree  
previous research investigated clustering  emery montemerlo  gordon 
schneider  thrun        propose clustering types based profiles payoff
functions cbgs  however  resulting method ad hoc  even given bounds
error clustering two types cbg  guarantees made quality
dec pomdp solution  bound respect heuristic payoff function 
contrast  propose cluster histories based probability histories induce
histories agents states  critical advantage criterion 
call probabilistic equivalence  pe   resulting clustering lossless 
solution clustered cbg used construct solution original cbg
values two cbgs identical  thus  criterion allows clustering aohs
cbgs represent dec pomdps preserving optimality   
section      describe histories dec pomdps clustered using
notions probabilistic best response equivalence  allows histories clustered
   name qbg stems fact   step delayed communication scenario modeled
cbg  note  however  cbgs used compute qbg different form b b   t  
discussed section        latter  types correspond length t  action   observation histories 
former  types correspond length   observation histories 
   cbgs essential clustering  provide convenient level abstraction simplifies
exposition techniques  moreover  level abstraction makes possible employ results
concerning cbgs outside context dec pomdps 
    probabilistic equivalence criterion lossless clustering introduced oliehoek et al         
article presents new  simpler proof optimality clustering based pe 

   

fiincremental clustering expansion faster optimal planning dec pomdps

rational always choose action  section      describe application
results gmaa   section     introduces improved heuristic representations
allow computation longer horizons 
    lossless clustering dec pomdps
section  discuss lossless clustering based notion probabilistic equivalence 
show clustering lossless demonstrating probabilistic equivalence implies
best response equivalence  describes conditions rational agent select
action two types  prove implication  show best response
depends multiagent belief  i e   probability distribution states policies
agents   two probabilistically equivalent histories  relations
equivalence notions discussed section   
      probabilistic equivalence criterion
first introduce probabilistic equivalence criterion  used decide whether
two individual histories  ia   ib clustered without loss value 
criterion    probabilistic equivalence   two aohs  ia   ib agent probabilistically
equivalent  pe   written p e  ia   ib    following holds 
   i

pr s  
  i   ia     pr s  
  i   ib   

     

probabilities computed conditional pr s    b   t    defined  a    
subsections             formally prove pe sufficient criterion guarantee
clustering lossless  remainder section       discuss key properties
pe criterion order build intuition 
note criterion decomposed following two criteria 
   i
   i

pr  
  i   ia     pr  
  i   ib   

     

pr s  
  i   ia     pr s  
  i   ib   

     

criteria give natural interpretation  first says probability distribution
agents aohs must identical  ia  ib   second demands
resulting joint beliefs identical 
probabilities well defined without initial state distribution b 
past joint policy   however  since consider clustering histories within particular cbg
 for stage t  constructed particular b   t   implicitly specified  therefore
drop arguments  clarifying notation 
example    example    types  ohl  ohr    ohr  ohl   agent pe  see this  note
rows  columns second agent  histories identical fig   a
fig   b  thus  specify distribution histories agents  cf  equation       
induced joint beliefs  cf  equation        

probabilistic equivalence convenient property algorithms exploit  holds
particular pair histories  hold identical extensions
histories  i e   propagates forwards regardless policies agents 
   

fioliehoek  spaan  amato    whiteson

definition    identical extensions   given two aohs  ia t   ib t   respective extensions
  a t        a t  ai  oi     b t        b t  a  o   called identical extensions






ai   ai oi   oi  







lemma    propagation pe   given  ia t   ib t pe  regardless decision rule
agents use   t  i    identical extensions pe 
ati ot   st    t  


  i

  i

t  

t     t     b t t  
    i  i  ai  oi     i        
pr st     
  i   ia t  ati  ot  
    i     pr s

proof  proof listed appendix  holds intuitively probabilities
described before  taking action
seeing observation 
note that  probabilities defined       superficially resemble beliefs used
pomdps  substantially different  pomdp  single agent compute
individual belief using aoh  use belief determine value
future policy  sufficient statistic history predict future rewards
 kaelbling et al         bertsekas         thus  trivial show equivalence aohs
induce individual belief pomdp  unfortunately  dec pomdps
problematic  next section elaborates issue discussing relation multiagent
beliefs 
      sub tree policies  multiagent beliefs expected future value
describe relationship multiagent beliefs probabilistic equivalence 
must first discuss policies agent may follow resulting values  begin
introducing concept sub tree policies  illustrated fig     on page      
 deterministic  policy represented tree nodes labeled using actions
edges labeled using observations  root node corresponds first action taken 
nodes specify action observation history encoded path root node 
such  possible define sub tree policies    correspond sub trees agent
policy  also illustrated fig      particular  write
w
 o    ht
     


sub tree policy corresponding w
observation history  oit specifies actions
last   h stages  refer policy consumption operator  since
w
consumes part policy corresponding  oit   similarly write  k  o l    kl

 note          h steps to go sub tree policy  use similar notation 
 k   joint sub tree policies  extensive treatment different forms
policy  refer discussion oliehoek        
given concepts  define value   k stages to go joint policy starting
state s 
xx
w
pr s  o s a v  s    k   
     
v  s   k     r s a   




here  joint action specified roots individual sub tree policies specified
 k stage   h k 
   

fiincremental clustering expansion faster optimal planning dec pomdps

definition  follows directly probability distribution states
sub tree policies agents   i sufficient predict value sub tree policy  
fact  distribution known multiagent belief bi  s    i    hansen  bernstein   
zilberstein         value given
xx
v  bi     max
bi  s    i  v  s hi     i i  
     




  i

refer maximizing agent best response bi   illustrates
multiagent belief sufficient statistic  contains sufficient information predict value
sub tree policy  
possible connect action observation histories multiagent beliefs fixing
policies agents  given agents act according profile
policies   i   agent multiagent belief first stage dec pomdp  bi  s    i    
b   s   moreover  agent maintain multiagent belief execution  such 
given   i   history  i induces multiagent belief  write bi  s    i   i     i  
make dependence  i     i explicit  multiagent belief history defined
bi  s    i   i     i     pr s    i   i   b      i   

     

induces best response via       
br  i     i     arg max


xx


bi  s    i   i     i  v  s    i  i   

     

  i

conclude two aohs  ia   ib clustered together induce
multiagent belief 
however  notion multiagent belief clearly quite different distributions
used notion pe  particular  establish whether two aohs induce
multiagent belief  need full specification   i   nevertheless  show two aohs
pe best response equivalent therefore cluster them 
crux show that  criterion   satisfied  aohs always induce
multiagent beliefs   i  consistent current past joint policy   i   
      best response equivalence allows lossless clustering histories
relate probabilistic equivalence multiagent belief follows 
lemma    pe implies multiagent belief equivalence     i   probabilistic equivalence
implies multiagent belief equivalence 


p e  ia   ib   s   i bi  s    i   ia     i     bi  s    i   ib     i  
      
proof  see appendix 
lemma shows two aohs pe  produce multiagent belief 
intuitively  gives us justification cluster aohs together  since multiagent
belief sufficient statistic act multiagent belief 
since lemma   shows  ia   ib induces multiagent beliefs   i
pe  conclude always act histories  formally 
prove  ia   ib best response equivalent pe 
   

fioliehoek  spaan  amato    whiteson

theorem    pe implies best response equivalence   probabilistic equivalence implies bestresponse equivalence 


p e  ia   ib     i br  ia     i     br  ib     i  
proof  assume arbitrary   i  
br  ia     i     arg max

xx

bi  s    i   ia  v  s    i  i  

  arg max

xx

bi  s    i   ib  v  s    i  i     br  ib     i   









  i

  i

lemma   employed assert equality bi    ia   bi    ib   
theorem key demonstrates two aohs  ia   ib agent
pe  agent need discriminate future  thus 
searching space joint policies  restrict search assign
sub tree policy  ia  ib   such  directly provides intuition lossless
clustering possible  formally  define clustered joint policy space follows 
definition    clustered joint policy space   let c subset joint policies
clustered  i e   part c assigns sub tree policy action
observation histories probabilistically equivalent 
corollary    existence optimal clustered joint policy   exists optimal joint
policy clustered joint policy space 
max v      max v   

c



      

proof  clear left hand side        upper bounded right hand side 
since c   suppose   arg max v    strictly higher value
best clustered joint policy  least one agent one pair pe histories  ia    ib   must
assign different sub tree policies ia    ib  otherwise would clustered   without loss
generality assume one pair  follows directly theorem  
policy construct clustered policy c c  by assigning either ia ib
 ia    ib   guaranteed value less   thereby contradicting
assumption strictly higher value best clustered joint policy 
formally proves restrict search c   space clustered joint
policies  without sacrificing optimality 
      clustering commitment cbgs
though clear two aohs pe clustered  making result
operational requires additional step  end  use abstraction layer provided
bayesian games  recall cbg stage  aohs correspond types 
   

fiincremental clustering expansion faster optimal planning dec pomdps

therefore  want cluster types cbg  accomplish clustering two
types ia  ib   introduce new type ic replace them  defining 
  i pr ic     i     pr ia     i     pr ib     i  
j

u hic     i  a 




pr ia     i  u hia     i  a    pr ib     i  u  ib     i  a 
 
 
pr ia     i     pr ib     i  

      
      

theorem    reduction commitment   given agent collaborative bayesian
game b committed selecting policy assigns action two types
ia  ib   i e   selecting policy  ia      ib    cbg reduced without
loss value agents  is  result new cbg b agent employs
policy reflects clustering whose expected payoff original

cbg  v b  i     i     v b  i     i   
proof  see appendix 
theorem shows that  given agent committed taking action
types ia  ib   reduce collaborative bayesian game b smaller one b

translate joint cbg policy found
b back joint cbg policy b 
necessarily mean       i solution b  best response
agent   i may select action ia  ib   rather best response
  i given action needs taken ia  ib    
even though theorem   gives conditional statement depends agent
committed select action two types  previous subsection discussed
rational agent make commitment  combining results gives
following corollary 
corollary    lossless clustering pe   probabilistically equivalent histories  ia   ib
clustered without loss heuristic value merging single type cbg 
proof  theorem   shows that  given agent committed take action
two types  types clustered without loss value  since  ia   ib pe 
best response equivalent  means agent committed use
sub tree policy hence action ai   therefore directly apply clustering
without loss expected payoff  cbg stage dec pomdp means loss
expected heuristic value given       
intuitively  maximizing action  ia  ib regardless  future 
joint policies   i agents use hence cluster without loss
heuristic value  note depend heuristic used hence
holds optimal heuristic  i e   using optimal q value function gives
true value   directly relates probabilistic equivalence equivalence optimal value   
    although focus cbgs  results generalize bgs individual payoff functions  thus 
could potentially exploited algorithms general payoff bgs  developing methods
interesting avenue future work 
    proof originally provided oliehoek et al         based showing histories pe
induce identical q values 

   

fioliehoek  spaan  amato    whiteson

algorithm   clustercbg b 
input  cbg b
output  losslessly clustered cbg b
   agent
  
individual type b i
  
pr i      
  
b i b i  i
  
continue
  
end
  
individual type b i
  
isprobabilisticallyequivalent true
  
hs    i
   
pr s    i  i      pr s    i  i  
   
isprobabilisticallyequivalent false
   
break
   
end
   
end
   
isprobabilisticallyequivalent
   
b i b i  i
   

   
  i
   
u i     i  a  min u i     i  a  u i     i  a  
   
pr i     i   pr i     i     pr i     i  
   
pr i     i    
   
end
   
end
   
end
   
end
   
end
    end
    return b

 prune b  

 prune b  
  take lowest upper bound  

note result establishes sufficient  necessary condition lossless clustering 
particular  given policies agents  many types best response equivalent
clustered  however  far know  criterion must hold order guarantee
two histories best response policy agents 
    gmaa  incremental clustering
knowing individual histories clustered together without loss value
potential speed many dec pomdp methods  article  focus application
within gmaa  framework 
emery montemerlo et al         showed clustering incorporated every stage
algorithm  cbg stage constructed  clustering individual
histories  types  performed first afterwards  reduced  cbg solved 
approach employed within gmaa  modifying expand procedure  algorithm   
cluster cbg calling generateallchildrenforcbg 
algorithm   shows clustering algorithm  takes input cbg returns
clustered cbg  performs clustering performing pairwise comparison types
   

fiincremental clustering expansion faster optimal planning dec pomdps

b
algorithm   constructextendedbg b  t    q 

input  cbg b stage    joint bg policy followed t   
b   a  
input  admissible heuristic form q 

output  cbg b stage t 
   b b
 make copy b subsequently alter 
   agent
  
b  i   constructextendedtypeset i 
 overwrite individual type sets 
   end
   b   id
 the new joint type set  does explicitly stored  
   joint type     t   at   ot   b  
  
state st
  
compute pr st   
 from pr st    t    via bayes rule  
  
end
   
pr   pr ot   t   at    pr  t   
   

   
q
   
history   represented
b    a  
b take lowest upper bound  
   
q min q q 
  q q
   
end
   
b  u  a  q
   
end
    end
    return b

agent see satisfy criterion  yielding o  i      comparisons agent i 
comparison involves looping hs    i  line     many states  efficiency
could gained first checking       checking        rather taking
average         line    take lowest payoff  done using
upper bound heuristic values 
following theorem demonstrates that  incorporating clustering gmaa  
resulting algorithm still guaranteed find optimal solution 
theorem    using heuristic form       clustering cbgs gmaa 
using pe criterion  resulting search method complete 
proof  applying clustering alter computation lower bound values  also 
heuristic values computed expanded nodes admissible fact unaltered
guaranteed corollary    therefore  difference regular gmaa 
class considered joint policies restricted c   class clustered joint policies 
possible child nodes expanded  clustering effectively prunes away policies
would specify different actions aohs pe thus clustered  however  corollary  
guarantees exists optimal joint policy restricted class 
modification expand proposed rather naive  construct b b   t  
must first construct  oi  t possible aohs agent  given past policy ti   
subsequent clustering involves pairwise comparison exponentially many types 
clearly  tractable later stages 
however  pe aohs propagates forwards  i e   identical extensions pe histories pe   efficient approach possible  instead clustering exponentially
   

fioliehoek  spaan  amato    whiteson

algorithm   expand ic q  h   expand operator gmaa  ic 
input  q   ht   vi search node expand 
b   a  
input  h admissible heuristic form q 
output  qexpand set containing expanded child nodes 
   b t    t   cbg
 retrieve previous cbg  note    t    t    
t  b

t 
   b    constructextendedbg b 
     q 
   b t   clusterbg b t   
    cbg b t  
 store pointer cbg 
   qexpand generateallchildrenforcbg b t   
   return qexpand

growing set types  simply extend already clustered types previous stages
cbg  shown algorithm    is  given   set types agent previous
stage    it  policy agent took stage  set types stage t   
constructed


     i  it   i   oti      oti oi  
      
means size newly constructed set  i      i    oi     type set
previous stage   much smaller set histories  i    oi  t   
new type set much smaller   i    oi  t   way  bootstrap clustering
stage spend significantly less time clustering  refer algorithm
implements type clustering gmaa  incremental clustering  gmaa  ic  
approach possible perform exact  value preserving clustering
lemma   guarantees identical extensions clustered without loss
value  performing procedure lossy clustering scheme  e g   emerymontemerlo et al          errors might accumulate  better option might re cluster
scratch every stage 
expansion gmaa  ic node takes exponential time respect number
agents types  o  a  n      joint cbg policies thus child nodes
gmaa  ic search tree  a largest action set largest type set   clustering
involves pairwise comparison types agent comparisons needs
check o    n   s   numbers equality verify        total cost clustering
therefore written
o n         n   s   
polynomial number types  clustering decreases number
types      therefore significantly reduce number child nodes thereby
overall time needed  however  clustering possible  overhead incurred 
    improved heuristic representation
since clustering reduce number types  gmaa  ic potential scale
larger horizons  however  important consequences computation
heuristics  previous research shown upper bound provided qmdp often
loose effective heuristic search  oliehoek  spaan    vlassis         however 
space needed store tighter heuristics qpomdp qbg grows exponentially
horizon  recall section        see fig     two approaches computing
   

fiincremental clustering expansion faster optimal planning dec pomdps

b minimum size 
algorithm   compute hybrid q
  
  
  
  
  
  
  
  
  
   
   
   
   
   

qh   r           r a   
z  a   s 
  h    
     a 
 
z  
v vectorbackup qt    
v prune v 
qt v
z  v    s 
end
z
qt treebackup qt    
end
end

 vector representation last stage 
 the size  a  vectors 
 size aoh representation 

 from z y 

qpomdp qbg   first constructs tree joint aohs heuristic values 
simple implement requires storing value      a  pair  number
grows exponentially t  second approach maintains vector based representation 
common pomdps  though pruning provide leverage  worst case  pruning
possible number maintained vectors grows doubly exponentially h t 
number stages to go  similarly  initial belief subsequently reachable beliefs
used reduce number vectors retained stage  number reachable
beliefs exponential horizon exponential complexity remains 
oliehoek  spaan  vlassis        used tree based representation qpomdp qbg heuristics  since
computational cost solving dec pomdp bottleneck  inefficiencies representation could overlooked  however  approach longer feasible
longer horizons made possible gmaa  ic 

hybrid

t  

mitigate problem  propose hybrid represent  
tation heuristics  illustrated fig     main
insight exponential growth two existing representations occurs opposite directions  therefore 
t  
use low space complexity side representations 
later stages  fewer vectors  use vector based representation  earlier stages  fewer histot  
ries  use history based representation  similar
idea utilizing reachable beliefs reduce size figure    illustration
vector representation described but  rather stor  hybrid representation 
ing vectors appropriate aohs step 
values needed using tree based representation 
algorithm   shows how  mild assumptions  minimally sized representation
computed  starting last stage  algorithm performs vector backups  switching
tree backups become smaller option  last time step h    represent
   

fioliehoek  spaan  amato    whiteson

qt set immediate reward vectors     variable z  initialized line    keeps track
number parameters needed represent qt vectors time step hand 
note z depends effective vector pruning is  i e   large parsimonious
representation piecewise linear convex value function is  since problem
dependent  z updated pruning actually performed  line    
contrast y  number parameters tree representation  computed directly
dec pomdp  line     z   y  algorithm switches tree backups   

   incremental expansion
clustering technique presented previous section potential significantly
speed planning much clustering possible  however  little clustering possible 
number children gmaa  search tree still grow super exponentially  section
presents incremental expansion  complementary technique deal problem 
incremental expansion exploits recent improvements effectively solving cbgs  first
note expansion last stage   h   particular h   
interested best child  h    h      corresponds optimal solution
bayesian game h     such  last stage  use new methods solving
cbgs  kumar   zilberstein      b  oliehoek  spaan  dibangoye    amato       
provide speedups multiple orders magnitude brute force search  enumeration    
unfortunately  improvements gmaa  afforded approach limited  order
guarantee optimality  still relies expansion  child nodes corresponding all 
joint cbg policies intermediate stages  thus necessitating brute force approach 
however  many expanded child nodes may low heuristic values vb may therefore
never selected expansion 
incremental expansion overcomes problem exploits following key observation  generate children decreasing heuristic order using admissible
heuristic  expand children  before  a  search performed
partially specified policies new cbg constructed extending cbg
parent node  however  rather fully expanding  i e   enumerating cbg policies
thereby constructing children for  search node  instantiate incremental
cbg solver corresponding cbg  incremental solver returns one joint cbg
policy time  used construct single child t      t      revisiting
nodes  promising child nodes expanded incrementally 
below  describe gmaa  ice  algorithm combines gmaa  ic incremental expansion  establish theoretical guarantees describe modifications
bagabab  cbg solver gmaa  ice employs  necessary deliver
child nodes decreasing order 
    exceptional cases short horizon combined large state action spaces representing last time step vectors minimal  cases  algorithm trivially adapted 
    assumes vector representation shrink earlier stages  although unlikely
practice  cases would prevent algorithm computing minimal representation 
    kumar zilberstein      b  tackle slightly different problem  introduce weighted constraint satisfaction approach solving point based backup dynamic programming dec pomdps  however 
point based backup interpreted collection cbgs  oliehoek et al         

   

fiincremental clustering expansion faster optimal planning dec pomdps

    gmaa  incremental clustering expansion
begin formalizing incremental expansion incorporating gmaa  ic  yielding gmaa  incremental clustering expansion  gmaa  ice   core
incremental expansion lies following lemma 
lemma    given two joint cbg policies   cbg b b   t    vb    vb     
corresponding child nodes vb  t     vb  t     
proof  holds directly definition vb  t   given       
vb  t       v      t    t     vb   
v      t    t     vb       vb  t     

follows directly that  b b   t   use cbg solver generate sequence
policies          
vb    vb          

then  sequence corresponding children

vb  t     vb  t            

exploiting knowledge  expand first child t   compute heuristic
value vb  t     using        since unexpanded siblings heuristic values less
equal that  modify gmaa  ic reinsert node q open list l
act placeholder non expanded children 
definition    placeholder node least one child expanded 
placeholder heuristic value equal last expanded child 
thus  expansion search node qs child  update q v  heuristic value
node  vb  t      value expanded child  i e   set q v vb  t      such 
reinsert q l placeholder  mentioned above  correct
unexpanded siblings  for parent node q placeholder  heuristic values
lower equal vb  t      therefore next sibling q represented placeholder
always expanded time  q always created nodes lower heuristic value
selected expansion  keep track whether node previously expanded
placeholder not 
before  gmaa  ice performs a  search partially specified policies 
gmaa  ic  new cbg constructed extending cbg parent node
applying lossless clustering  however  rather expanding children  gmaa  ice
requests next solution incremental cbg solver  single child
t      t     constructed  principle gmaa  ice use cbg solver able
incrementally deliver descending order vb     propose modification
bagabab algorithm  oliehoek et al          briefly discussed section     
fig    illustrates process incremental expansion gmaa  ice  indexed
letters  first  cbg solver root node ha   i created  optimal solution
computed  value    results child hb   i  root replaced placeholder
node ha   i  per definition    the node comparison operator   b appears
   

fioliehoek  spaan  amato    whiteson

legend 

v




 


 

root node


 




b
 

t  

b
 


new b a   vb   
c
 

t  
ht   vi
open list

ha   i


   

new b b   vb   

ha   i
hc   i
hb   i

hb   i
ha   i

b
 

c
 


   
next solution
b a   vb     

hd     i
ha     i
hc   i
hb   i

figure    illustration incremental expansion  nodes open list bottom 
past joint policies indexed letters  placeholder nodes indicated dashes 
open list hence selected expansion  best child hc   i added hb   i replaced
placeholder hb   i  search returns root node  second best solution
obtained cbg solver  leading child hd     i  placeholder nodes retained
long unexpanded children  values updated 
using gmaa  ice  derive lower upper bounds cbg solution 
exploited incremental cbg solver  incremental cbg solver
b t   initialized lower bound
vcbg   vgm aa v      t    t   

     

vgm aa value current best solution  v      t    t   true expected
value first stages  therefore  vcbg minimum value candidate
must generate remaining h stages order beat current best solution  note
time incremental cbg solver queried solution  vcbg re evaluated
 using         vgm aa may changed 
used heuristic faitfully represents immediate reward  i e   form
        then  last stage   h    specify upper bound solution
cbg
vcbg   vb  h    v      h    h    
     
upper bound attained  solutions required cbg solver 
upper bound holds since      
vb      vb  h   v      h    h   

  v  h   v      h    h   
vb  h    v      h    h    

first step  vb  h     v  h    h fully specified policy heuristic value
given       equals actual value heuristic faithfully represents expected
   

fiincremental clustering expansion faster optimal planning dec pomdps

algorithm    expand ice q  h   expand operator gmaa  ice 
input  q   ht   vi search node expand 
b   a  
input  h admissible heuristic form q 
output  qexpand set containing     expanded child nodes 
   isplaceholder q 
  
b t    cbg
 reuse stored cbg 
   else
  
b t    t   cbg
 retrieve previous cbg  note    t    t    
t 
b
  
b t   constructextendedbg b t       q 


  
b    clusterbg b    
  
b t   solver createsolver b t   
  
 cbg b t  
 store pointer cbg 
   end
 set lower bound cbg solution 
    vcbg   vgm aa v      t    t  
      h  
   
vcbg   vb  h    v      h    h   
 upper bound used last stage cbg 
    else
   
vcbg    
    end
b    i b t   solver nextsolution vcbg  vcbg  
 compute next cbg solution 
    h   v

   
   
t    t    
 create partial joint policy 

t  
    t 

b
b
   
v     v
      v    
 compute heuristic value 
   
q ht     vb  t    i
 create child node 
   
qexpand  q  
    else
   
qexpand
 fully expanded  exists solution s t  v   h    vcbg  
    end
    return qexpand

algorithm    postprocessnode ice q  l   post processing node gmaa  ice 
input  q last expanded node  l open list 
output  q either removed updated 
   l pop q 
   q fully expanded depth q    h  
  
cleanup q
 delete node associated cbg solver 
  
return
   else
  
c last expanded child q
  
q v c v
 update heuristic value parent node 
  
isplaceholder q  true
 remember q placeholder 
  
l insert q 
 reinsert appropriate position 
    end

   

fioliehoek  spaan  amato    whiteson

immediate reward used  implies vb    lower bound  second step
v  h   vb  h     vb  h    admissible  therefore  stop expanding
find  lower bound  heuristic value equal upper bound vcbg   applies
last stage first step valid 
gmaa  ice implemented replacing expand postprocessnode
procedures algorithms     algorithms        respectively  expand ice first
determines placeholder used either reuses previously constructed incremental cbg solver constructs new one  then  new bounds calculated next
cbg solution obtained  subsequently  single child node generated  rather
expanding children algorithm      postprocessnode ice removes last node
returned select children expanded  otherwise 
updates nodes heuristic value reinserts open list  see appendix a  
gmaa  ice shown single algorithm 
    theoretical guarantees
section  prove gmaa  ic gmaa  ice search equivalent  direct
result establish gmaa  ice complete  means integrating incremental
expansion preserves optimality guarantees gmaa  ic 
definition     call two gmaa  variants search equivalent select exactly
sequence non placeholder nodes corresponding past joint policies expand
search tree using select operator 
gmaa  ic gmaa  ice show set selected nodes same 
however  set expanded nodes different  fact  precisely differences
incremental expansion exploits 
theorem    gmaa  ice gmaa  ic search equivalent 
proof  proof listed section a   appendix 
note theorem   imply computational space requirements
gmaa  ice gmaa  ic identical  contrary  expansion 
gmaa  ice generates one child node stored open list  contrast 
gmaa  ic generates number child nodes is  worst case  doubly exponential
depth selected node    however  gmaa  ice guaranteed
efficient gmaa  ic  example  case child nodes still
generated  gmaa  ice slower due overhead incurs 
corollary    using heuristic form       gmaa  ice complete 
proof  stated conditions  gmaa  ic complete  see theorem    
gmaa  ice search equivalent gmaa  ic  complete 

since

    problem allows clustering  number child nodes grows less dramatically  see section    

   

fiincremental clustering expansion faster optimal planning dec pomdps

    incremental cbg solvers
implementing gmaa  ice requires cbg solver incrementally deliver
descending order vb     end  propose modify bayesian game branch
bound  bagabab  algorithm  oliehoek et al          bagabab performs a  search
 partially specified  cbg policies  thus  applied within gmaa  ice  performs
second  nested a  search  expand node gmaa  search tree  nested a 
search computes next cbg solution    section briefly summarizes main ideas
behind bagabab  for information  see oliehoek et al         modifications 
bagabab works creating search tree nodes correspond partially
specified joint cbg policies  particular  represents joint action vector  vector
h                    i joint actions specifies joint type  node g
bagabab search tree represents partially specified vector thus partially specified
joint cbg policy  example  completely unspecified vector h           i corresponds
root node  internal node

g depth  root beingff depth    specifies joint
actions first joint types g                                     value node v  g 
value best joint cbg policy consistent it  since value known
advance  bagabab performs a  search guided optimistic heuristic 
particular  compute upper bound value achievable
partially specified vector computing maximum value complete information joint
policy consistent  i e   non admissible joint policy selects maximizing
joint actions remaining joint types   since value guaranteed upper bound
maximum value achievable consistent joint cbg policy  admissible heuristic 
propose modification bagabab allow solutions incrementally delivered 
main idea retain search tree first call bagabab particular cbg
b t   update subsequent calls  thereby saving computational effort 
standard a  search terminates single optimal solution found 
behavior incremental bagabab called first time b t   
however  standard a   nodes whose upper bound lower best known lower
bound safely deleted  never lead optimal solution  contrast 
incremental setting nodes cannot pruned  could possibly result k th
best solution therefore might need expanded subsequent calls bagabab 
nodes returned solutions pruned order avoid returning solution
twice  modification requires memory affect a  search process
otherwise 
asked k th solution  bagabab resets internal lower bound value
next best solution previously found returned  or vcbg defined
      solution found   starts a  search initialized using search
tree resulting  k    th solution  essence  method similar searching
best k solutions  k incremented demand  recently shown that 
fixed k  modification preserves theoretical guarantees  soundness  completeness 
    gmaa  ice could use incremental cgb solver  avoid enumerating
providing first result thus potential work incrementally  exception may
method kumar zilberstein      b   employs and or branch bound search
edac heuristic  and thus limited two agent case   heuristic search method  may
amenable incremental implementation though knowledge attempted 

   

fioliehoek  spaan  amato    whiteson

optimal efficiency  a  algorithm  dechter  flerova    marinescu         results
trivially transfer setting k allowed increase 

   experiments
section  empirically test validate proposed techniques  lossless clustering
joint histories  incremental expansion search nodes  hybrid heuristic representations 
introducing experimental setup  compare performance gmaa  ic
gmaa  ice gmaa  suite benchmark problems literature 
next  compare performance proposed methods state of the art optimal
approximate dec pomdp methods  followed case study scaling behavior
respect number agents  finally  compare memory requirements
hybrid heuristic representation tree vector representations 
    experimental setup
well known dec pomdp benchmarks dec tiger  nair et al        
broadcastchannel  hansen et al         problems  dec tiger discussed extensively
section    broadcastchannel  two agents transmit messages communication channel  agents transmit time collision occurs
noisily observed agents  firefighting problem models team n firefighters
extinguish fires row nh houses  oliehoek  spaan    vlassis        
agent choose move houses fight fires location  two agents
house  completely extinguish fire there   negative  reward
team firefighters depends intensity fire house  fires
extinguished  reward zero received  hotel   problem  spaan   melo        
travel agents need assign customers hotels limited capacity  send
customer resort yields lower reward  addition  use following problems  recycling robots  amato  bernstein    zilberstein         scaled down version
problem described section    gridsmall two observations  amato  bernstein   
zilberstein        cooperative box pushing  seuken   zilberstein      a   larger
two robot benchmark  table   summarizes problems numerically  listing number
joint policies different planning horizons 
experiments run intel core i  cpu running linux  gmaa   gmaa  ic 
gmaa  ice implemented code base using madp toolbox  c   
 spaan   oliehoek         vector based qbg representation computed using variation incremental pruning  adapted computing q functions instead regular value functions   corresponding naiveip method described oliehoek spaan        
implement pruning  employ cassandras pomdp solve software  a  r  cassandra 
      
results sections          limited process  gb ram
maximum cpu time      s  reported cpu times averaged    independent runs
resolution     s  timings given maa  search processes  since
   

fiincremental clustering expansion faster optimal planning dec pomdps

problem primitives

dec tiger

num  h

n

 s 

 ai  

 oi  

 

 

 

 

 

 

 

    e 

    e  

    e  

broadcastchannel

 

 

 

 

    e 

    e 

    e  

gridsmall

 

  

 

 

     e 

     e  

     e  

cooperative box pushing

 

   

 

 

    e 

    e   

    e    

recycling robots

 

 

 

 

    e 

    e  

    e  

hotel  

 

  

 

 

    e 

    e  

    e    

firefighting

 

   

 

 

    e 

    e  

    e  

table    benchmark problem sizes number joint policies different horizons 
computation heuristic methods amortized multiple
runs    problem definitions available via http   masplan org 
    comparing gmaa   gmaa  ic  gmaa  ice
compared gmaa   gmaa  ic  gmaa  ice using hybrid qbg representation  methods compute optimal policy  expect gmaa  ic efficient
gmaa  lossless clustering possible  furthermore  expect gmaa  ice
provide improvements terms speedup scaling longer planning horizons 
results shown table    entries report results  qbg heuristics
could computed  thanks hybrid representation  consequently  performance
gmaa  ic much better previously reported results  including oliehoek
et al          often required resort qmdp larger problems and or horizons 
entries marked show limits using qmdp instead qbg  
problems reach longer horizons qbg   firefighting gmaa  ice
qmdp compute solutions higher h possible qbg  hence missing  
showing gmaa  ice efficient using loose heuristic gmaa  ic  
furthermore  entries indicate horizon solve problem
tree based qbg representation often much shorter 
results clearly illustrate gmaa  ic leads significant improvement
performance  problems  gmaa  ic able produce solution quickly
increase largest solvable horizon gmaa   cases  gmaa  ic able
drastically increase solvable horizon 
furthermore  results clearly demonstrate incremental expansion allows significant additional improvements  fact  table demonstrates gmaa  ice significantly outperforms gmaa  ic  especially problems little clustering possible 
results table   illustrate efficacy hybrid representation  problems
gridsmall  cooperative box pushing  firefighting hotel   neither
tree vector representation able provide compact qbg heuristic longer hori    heuristics computation time ranges less second hours  for high h difficult
problems   table   presents heuristic computation time results 

   

fioliehoek  spaan  amato    whiteson

h
 
 
 
 
 
 

v tgmaa   s 
dec tiger
        
    
        
    
        
      
        

         

tic  s 

tice  s 

h

    
    
    
     


    
    
    
    
     


 
 
 
 
 
  
  
  
  
  
  
  
  
  
  

firefighting hnh     nf    i
          
    
    
    
          
    
    
    
          
              
    
          


    
          
    
    
 
 
 
gridsmall
 
        
    
    
    
 
        
    
    
    
 
        
 
         
 
        

    
 
        

    
 
 
 
hotel  
           
   
    
    
           
 
    
    
           
         
           
    
    
           
    
    
           
    
    
           
    
    
           
    
    
  
 
 
cooperative box pushing
 
         
    
    
    
 
         

         
 
         
      
 
 
 

 
 
 
 
 
 
  
  
  
  
  
  
  
   
   
   
   
   
   
   
    

v tgmaa   s  tic  s  tice  s 
recycling robots
        
         
    
         
         
    
         
           
    
         
         
         
    
    
         
    
    
         
    
    
         
         
         
    
    
         
    
    
          
    
    
          
    
    
          
    
    
          

     


broadcastchannel
        
         
    
        
         
    
        
         
    
        
         
    
        
    
    
        
         
        
    
    
         
    
    
         
    
    
         
    
    
         
    
    
         
    
    
         
         
         
    
    
          
    
    
          
    
    
          
     
     
          
    
    


          
    
     



table    experimental results comparing regular gmaa   gmaa  ic  gmaa  ice 
listed computation times gmaa   tgmaa     gmaa  ic  tic   
gmaa  ice  tice    using hybrid qbg representation  use following symbols 
memory limit violations  time limit overruns    heuristic computation exceeded memory time limits  maximum planning horizon using qmdp   maximum planning horizon
using tree based qbg   bold entries indicate methods proposed article
computed results 
zons  apart dec tiger firefighting  computing storing qbg  or another
tight heuristic  longer horizons bottleneck scalability 
together  algorithmic improvements lead first optimal solutions many
problem horizons  fact  vast majority problems tested  provide results
longer horizons previous work  the bold entries   improvements quite sub   

fiincremental clustering expansion faster optimal planning dec pomdps

h
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 bgh   

 cbgt  
dec tiger
          
                
                       
                              
firefighting hnh     nf    i
          
                 
                       
                               
                                  
gridsmall
          
                  
                        
hotel  
           
                  
                        
                              
    e                                  
    e                                  
    e                                  
    e                                  
cooperative box pushing
           
                  

h
 
 
 
 
  
  
  
  
  
  
  
  
 
 
 
 
 
 
  
  
  
  
  
  
   
   

 bgh     cbgt  
recycling robots
       remaining stages
        remaining stages
        remaining stages
         remaining stages
            remaining stages
    e       remaining stages
    e        remaining stages
    e        remaining stages
    e        remaining stages
     remaining stages
     remaining stages
     remaining stages
broadcastchannel
       for t 
        for t 
        for t 
         for t 
          for t 
          for t 
            for t 
    e        for t 
    e        for t 
    e        for t 
     for t 
     for t 
     for t 
     for t 

   
   
   
   
   
   
   
   
   
   
   
   

table    experimental results detailing effectiveness clustering  listed size
cbgs   h   without clustering   bgh      average cbg size stages
clustering   cbgt    
stantial  especially given lengthening horizon one increases problem difficulty
exponentially  cf  table    
      analysis clustering histories
table   provides additional details performance gmaa  ic  listing
number joint types gmaa  ic search   cbgt    stage t  averages
since algorithm forms cbgs different past policies  leading clusterings different
sizes    see impact clustering  table lists  bgh     number joint types
cbgs constructed last stage without clustering  constant 
dec tiger  time needed gmaa  ic   orders magnitude less
gmaa  horizon h      h      test problem     e   joint
policies  method able optimally solve it  gmaa  ic  however 
able reasonable time  dec tiger  clear symmetries
    note problem domains report smaller clusterings oliehoek et al          due
implementation mistake  clustering overly conservative  cases treat two histories
probabilistically equivalent  fact were 

   

fioliehoek  spaan  amato    whiteson

observations allow clustering  demonstrated fig     another key property
opening door resets problem  may facilitate clustering 
firefighting  short planning horizons lossless clustering possible
stage  such  clustering incurs overhead  however  gmaa  ic still faster
gmaa  constructing bgs using bootstrapping previous cbg
takes less time constructing cbg scratch  interesting counterintuitive results
occur h      solved within memory limits  contrast h      fact  using
qmdp could compute optimal values v h      turns equal
h      reason optimal joint policy guaranteed extinguish
fires   stages  subsequent stages  rewards   
influence clustering  analysis table   reveals cbg instances encountered
h     search happen cluster much better h      possible
heuristics vary horizon  fact  h     sends agents
middle house      h      agents dispatched different houses 
agents fight fires house  fire extinguished completely  resulting joint
observations provide new information  result  different joint types lead
joint belief  means clustered  agents visit different houses 
observations convey information  leading different possible joint beliefs  which cannot
clustered  
hotel   allows large amount clustering  gmaa  ic outperforms gmaa 
large margin  former reaching h     latter h      problem
transition observation independent  becker  zilberstein  lesser    goldman       
nair  varakantham  tambe    yokoo        varakantham  marecki  yabu  tambe    yokoo 
       facilitates clustering  discuss section      unlike methods
specifically designed exploit transition observation independence  gmaa  ic exploits
structure without requiring predefined explicit representation it  scalability
limited computation heuristic 
broadcastchannel  gmaa  ic achieves even dramatic increase performance  allowing solution horizon h        analysis reveals cbgs
constructed stages fully clustered  contain one type agent 
reason follows  constructing cbg      one joint type
previous cbg so  given     solution previous cbg  uncertainty
respect previous joint action a    crucial property broadcastchannel
 joint  observation reveals nothing new state  joint action
taken  e g   collision agents chose send   result  different individual
histories clustered  cbg constructed stage      one joint
type previous game  therefore  given past policy  actions agents
perfectly predicted  observation conveys information process repeats  thus  problem special property could described non observable
given past joint policy  gmaa  ic automatically exploits property  consequently 
time needed solve cbg grow horizon  solution time  however  still increases super linearly increased amount backtracking 
firefighting  performance monotonic planning horizon  case however 
clustering clearly responsible difference  rather  explanation
certain horizons  many near optimal joint policies  leading backtracking
higher search cost 
   

fiincremental clustering expansion faster optimal planning dec pomdps

  

nodes depth

  

dectiger  h   full exp 
dectiger  h   inc  exp 
gridsmall  h   full exp 
gridsmall  h   inc  exp 
firefighting  h   full exp 
firefighting  h   inc  exp 

 

  

 

  

 

 

 


 

 

figure    number expanded partial joint policies intermediate stages             h  
 in log scale  

      analysis incremental expansion
dec tiger h      gmaa  ice achieves speedup three orders magnitude
compute solution h      unlike gmaa  ic  gridsmall  achieves large
speedup h     fast solutions h        gmaa  ic runs memory  similar positive results obtained firefighting  cooperative box pushing
recycling robots  fact  using qmdp   gmaa  ice able compute
solutions well beyond h        firefighting problem  stands stark contrast gmaa  ic computes solutions h     heuristic  note
broadcastchannel problem gmaa  ic  slightly  faster
gmaa  ice  problem exhibits clustering single joint type  overhead
incremental expansion pay off 
analyze incremental expansion  examined impact number nodes
expanded intermediate stages             h    fig    shows number nodes expanded
gmaa  ice number would expanded gmaa  ic  which
easily computed since search tree equivalent   clear relationship
results fig    table    illustrating  e g   gmaa  ic runs memory
gridsmall h      plots confirm hypothesis that  practice  small number
child nodes queried 
      analysis hybrid heuristic representation
fig    illustrates memory requirements terms number parameters  i e   real numbers  tree  vector  hybrid representations qbg   latter computed
following algorithm    results vector representation omitted representations grew beyond limits  effectiveness vector pruning depends problem
complexity value function  increase suddenly  instance happens fig   c  results show that  several benchmark dec pomdps  hybrid
representation allows significant savings memory  allowing computation tight
heuristics longer horizons 
   

fioliehoek  spaan  amato    whiteson

h

milp

dp lpc

dp ipg

gmaa qbg
ic

ice

heur

broadcastchannel  ice solvable h      
 
    
    
    
    
 
    
    
     
    
 
     

 
    
 
     
    

    
    
    
    

    
    
    
    

dec tiger  ice
 
    
 
     
 

 

    
    
    
    

    
    
    
    

solvable h    
    
    
     
     

       


    
    
    
     

firefighting    agents    houses    firelevels   ice
 
    
    
     
    
 


      
    
 

      
gridsmall  ice solvable h    
 
    
     
    
 


    
 
     

    
    
    

recycling robots  ice solvable h     
 
    
    
    
    
 
 
    
    
    
 
       
     
    
 

       
    
hotel
 
 
 
 
 
  
  

   ice solvable h    
    
    
    
      
       
    


    
    
    
     
      

cooperative box pushing
 
    
     
 
       
 


    
    
    
    
    
 

solvable h     
         
    
    
    
    
    
    
    

    
    
     

    
    
    
    

    
    
    
    

    
    
    
    
    
 

    
    
    
    
     

 qpomdp    ice solvable h    
    
              
    
    
    
    
       
 
           

table    comparison runtimes methods  total time gmaa  methods
given taking time method column  ic ice  adding heuristic
computation time  heur   use following symbols  memory limit violations   
time limit overruns    heuristic computation exceeded memory time limits 

   

fiincremental clustering expansion faster optimal planning dec pomdps

  

memory required

 

  

 

  

 

  

 

 

 

 
 
horizon

 

  

 

 a  dec tiger 

 

  

 

  

 

 
 
horizon

 

  

 

 d  recycling robots 

  

 

                 
horizon

  

  

tree
vector
hybrid

  

  

 

  

 

                    
horizon

tree
vector
hybrid

 c  hotel   

  

tree
vector
hybrid

memory required

memory required

  

  

 

  

  

 b  firefighting 

  

  

  

tree
vector
hybrid

  

  
memory required

memory required

  

tree
vector
hybrid

memory required

  

  

tree
vector
hybrid

  

  

 

  

 

                    
horizon

 e  broadcastchannel 

  

 

 

 
 
horizon

 

 

 f  gridsmall 

figure    hybrid heuristic representation  y axis shows number real numbers stored
different representations qbg several benchmark problems  in log scale  
    comparing methods
section  compare gmaa  ic gmaa  ice methods literature  begin comparing runtimes methods following state ofthe art optimal dec pomdp methods  milp    aras   dutech        converts decpomdp mixed integer linear program  numerous solvers available 
used mosek version      dp lpc    boularias   chaib draa        performs dynamic programming lossless policy compression  cplex      lp solver 
dp ipg  amato et al         performs exact dynamic programing incremental policy
    results reported deviate reported aras dutech         number
problems  aras et al  employed solution method solves milp series  a tree  smaller
milps branching continuous realization weight variables earlier stages  is  past
joint policy stage t  solve different milp involving subset consistent sequences 
additionally  firefighting gridsmall  use benchmark versions standard literature
 oliehoek  spaan    vlassis        amato et al          whereas aras dutech        use non standard
versions  explains difference results ones reported article  personal
communication  raghav aras  
    goal boularias chaib draa        find non dominated joint policies initial beliefs 
previously reported results concerned run time compute non dominated joint policies  without
performing pruning full length joint policies  contrast  report time needed compute
actual optimal dec pomdp policy  given b     additionally requires final round pruning
subsequently computing value remaining joint policies initial belief  additional overhead explains differences run time report previously
reported  personal communication  abdeslam boularias  

   

fioliehoek  spaan  amato    whiteson

problem
dec tiger
cooperative box pushing
gridsmall

h
 
 
 


 
 
 

vmbdp
    
     
    

v
     
     
    

table    comparison optimal  v   approximate  vmbdp   values 

generation exploits known start state knowledge states reachable
dp backup 
table    shows results comparison  demonstrates that  almost cases 
total time gmaa  ice  given sum heuristic computation time time
gmaa  phase  significantly less state of the art methods 
moreover  demonstrated table    gmaa  ice compute solutions longer horizons problems  except cooperative box pushing hotel     
problems  possible compute qbg longer horizons  overcoming
problem could enable gmaa  ice scale horizons well 
dp lpc algorithm proposed boularias chaib draa        improves
efficiency optimal solutions form compression  performance algorithm 
however  weaker gmaa  ic  two main explanations performance difference  first  dp lpc uses compression compactly represent values
sets useful sub tree policies  using sequence form representation  policies themselves  however  compressed  still specify actions every possible observation
history  for policy needs select exponential amount sequences make
policy   hence  cannot compute solutions long horizons  second  gmaa  ic
exploit knowledge initial state distribution b   
overall  gmaa  ice substantially improves state of the art optimally solving
dec pomdps  previous methods typically improved feasible solution horizon
one  or provided speed ups horizons could already solved   contrast 
gmaa  ice dramatically extends feasible solution horizon many problems 
consider mbdp based approaches  leading family approximate algorithms 
table    reports vmbdp values produced pbip ipg  amato et al          with
typical maxtrees parameter setting m   demonstrates optimal solutions produced
gmaa  ic gmaa  ice higher quality  pbip ipg chosen
mbdp algorithms parameters achieve value 
exhaustive  comparison illustrates even best approximate dec pomdp methods
practice provide inferior joint policies problems  conducting analysis
possible optimal solutions computed  clearly  data becomes
available  thorough comparisons made  therefore  scalable optimal
solution methods gmaa  ice critical improving analyses 
   

fiincremental clustering expansion faster optimal planning dec pomdps

problem primitives

num  h

n

 s 

 a 

 o 

 

 

 

 

  

 

 

  

    e 

    e  

 

  

 

 

   

    e  

    e  

 

   

  

  

    e 

    e  

    e  

 

   

  

  

    e 

    e  

    e  

 

    

  

  

    e 

    e  

    e   

table    firefightinggraph  number joint policies different numbers agents
horizons    possible fire levels 
    scaling agents
benchmark problems results presented far limited two agents  here 
present case study firefightinggraph  oliehoek  spaan  whiteson    vlassis 
       variation firefighting allowing agents  agent
fight fires two houses  instead them  table   highlights size
problems  including total number joint policies different horizons  compared
gmaa   gmaa  ic  gmaa  ice  all using qmdp heuristic   bruteforcesearch 
dp ipg  maximum run time    hours running intel core i  cpu 
averaged    runs  bruteforcesearch simple optimal algorithm enumerates
evaluates joint policies  implemented codebase gmaa 
variations  dp ipg results use original implementation run intel xeon
computer  hence  timing results directly comparable  overall trends
apparent  also  since dp ipg implementation limited   agents  results shown
agents 
fig     shows computation times firefightinggraph across different numbers
agents planning horizons  table   lists optimal values obtained  expected 
baseline bruteforcesearch performs poorly  scaling beyond h      
agents  dp ipg reach h      hand  regular gmaa  performs
relatively well  scaling maximum   agents  however  gmaa  ic gmaa  ice
improve efficiency gmaa     orders magnitude  such  substantially
outperform three methods  scale   agents  benefit incremental expansion clear n        gmaa  ice reach higher horizon gmaa  ic 
hence  although article focuses scalability horizon  results show
methods propose improve scalability number agents 
    discussion
overall  empirical results demonstrate incremental clustering expansion offers
dramatic performance gains diverse set problems  addition  results broad    hotel    dp ipg performs particularly well problem structure limited reachability 
is  agent fully observe local state  but agent  local states
except one one action dominates others  result  dp ipg generate small number
possibly optimal policies 

   

fioliehoek  spaan  amato    whiteson

 

 

  

  

 

 

  

 

  

 

  

 

  

 

  

 

  

 

 

 

 

 

 

 

 

 

 

 

 

 

  

 

  

computation time  s 

computation time  s 

computation time  s 

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 

 

 

h

 agents

 

 

 

 

 

 

 

 

 

 

  

  

 

  

 

  

 

  

 

  

 

  

 

  

 

 

h

 agents

 a  gmaa  results 

 

 

 

 

 

 

 

 

 

  

h

 agents

 b  gmaa  ic results 

 

 c  gmaa  ice results 

 

  

  

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 

 

 

 

 

 

 

 

 

 

 

 

 

  

computation time  s 

 

computation time  s 

 

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 
h

 agents

 

 

 

 

 

 

 

 

 

 

 

 

  

h

 agents

 d  bruteforcesearch results 

 e  dp ipg results 

figure     comparison gmaa   gmaa  ic  gmaa  ice  bruteforcesearch 
dp ipg firefightinggraph problem  shown computation time  in log
scale  various number agents horizons  missing bars indicate method
exceeded time memory limits  however  dp ipg implementation supports  
agents 

h
 
 
 
 
 

n  
        
        
        
        
        

n  
        
        
        

n  
        
        
        

n  
        

n  
        

table    value v optimal solutions firefightinggraph problem  different
horizons numbers agents 

castchannel illustrate key advantage approach  problem possesses property makes large amount clustering possible  clustering method exploits
property automatically  without requiring predefined explicit representation it 
   

fiincremental clustering expansion faster optimal planning dec pomdps

course  problems admit great reductions via clustering  one domain property
allows clustering past joint policy encountered gmaa  makes
observations superfluous  broadcastchannel firefighting  dec tiger 
see certain symmetries lead clustering  however clustering occur even
without properties  fact  problems nearly horizons tested 
size cbgs reduced  moreover  accordance analysis section     
improvements planning efficiency huge  even modest reductions cbg size 
one class problems say something priori amount clustering
possible class dec pomdps transition observation independence
 becker et al          problems  agents local states transitions
independent  two agents expressed
pr s    s   s    s    a    a      pr s   s    a    pr s   s    a    

     

similarly  observations assumed independent  means agent
observation probability depends action local state  pr oi  ai   si   
problems  probabilistic equivalence criterion       factors too  particular  due
transition observation independence           holds true  ia   ib   moreover       
factors product pr s    s               pr s        pr s        thus holds pr s     a    
pr s     b    is  two histories clustered induce local belief 
such  size cbgs directly corresponds product number reachable local
beliefs  since transition observation independent hotel   problem locally
fully observable  local state spaces consist four states  four possible
local beliefs  which consistent cbg size    table     moreover  see
maximum size typically reached end search  good
policies defer sending customers hotel thus visit local states hotel
filled earlier stages 
general classes problems  even weakly coupled models  e g   becker 
zilberstein    lesser        witwicki   durfee         criterion       factor 
hence direct correspondence number local beliefs  such 
applying clustering algorithm determine well problem clusters 
analogous to  e g   state aggregation mdps  e g   discussed givan  dean   
greig        known predict priori large minimized model
be  fortunately  empirical results demonstrate that  domains admit little
clustering  overhead small 
expected  incremental expansion helpful problems allow
much clustering  however  results for  e g   dec tiger illustrate limit
amount scaling method currently provide  bottleneck solution
large cbgs later stages  cbg solver solve large cbgs
returning first solution order guarantee optimality  takes takes long time 
expect improvements cbg solvers directly add efficacy
incremental expansion 
experiments clearly demonstrate dec pomdp complexity results 
important  worst case results  fact  scalability demonstrated experiments
clearly show many problems successfully scale dramatically beyond would
    assumes external state variable s   

   

fioliehoek  spaan  amato    whiteson

expected doubly exponential dependence horizon  even smallest problems 
doubly exponential scaling horizon implies impossible compute solutions
beyond h     all  indicated following simple calculation  let n       ai      
actions   oi        observations 
 

 ai   n  oi  

  

 

  ai   n  oi  

  

        e  

thus  even simplest possible case  see increase factor       e   h    
h      similarly  next increment  h     h      increases size search
space factor       e    however  experiments clearly indicate almost
cases  things dire  is  even though matters look bleak light
complexity results  many cases able perform substantially better worst
case 

   related work
section  discuss number methods related proposed
article  methods already discussed earlier sections  section   
indicated clustering method closely related approach emery montemerlo
et al         fundamentally different method lossless  section     
discussed connections approach boularias chaib draa        clusters
policy values  contrasts approach clusters histories thus
policies themselves  leading greater scalability 
section        discussed relationship notion probabilistic equivalence  pe  multiagent belief  however  yet another notion belief  employed
jesp solution method  nair et al          superficially similar pe
distribution  jesp belief aoh  i probability distribution pr s  o  i   i   b      i  
states observation histories agents given  deterministic  full policy
agents  sufficient statistic  since induces multiagent belief  thus
allows clustering histories  crucial difference with  utility of  pe lies
fact pe criterion specified states aohs given past joint policy 
is        induce multiagent belief 
clustering approach resembles number methods employ equivalence
notions  first  several approaches exploit notion behavioral equivalence  pynadath  
marsella        zeng et al         zeng   doshi         consider  perspective
protagonist agent i  possible models another agent j  since j affects
actions  i e   behavior  agent cluster together models agent j lead
policy j agent  is  cluster models agent j
behaviorally equivalent  contrast  cluster models agents j  histories
agent agents  well environment  guaranteed behave
expectation  thus leading best response agent i  is  method
could seen clustering histories expected environmental behavior equivalent 
notion utility equivalence  pynadath   marsella        zeng et al         closer
pe takes account  value the  best response agent  in particular 
clusters two models mj mj using br mj  the best response mj achieves
value mj    however  remains form behavior equivalence
clusters models agents  histories protagonist agent 
   

fiincremental clustering expansion faster optimal planning dec pomdps

connections pe work influence based abstraction  becker et
al         witwicki   durfee        witwicki        oliehoek et al          since influence
 or point parameter space  becker et al         compact representation
agents policies  models agents clustered lead influence
agent i  however  though fine grained  ultimately still form behavioral
equivalence 
final relation equivalence notion work dekel  fudenberg  morris
        constructs distance measure topology space types
goal approximating infinite universal type space  the space possible beliefs
beliefs beliefs  etc   one shot bayesian games  setting  however  considers
simple finite type space types directly correspond private histories  in
form aohs  sequential problem  thus  need approximate universal
type space  instead want know histories lead future dynamics
perspective agent  dekel et al s topology address question 
incremental expansion technique related approaches extending deal
large branching factors context multiple sequence alignment  ikeda   imai       
yoshizumi  miura    ishida         however  approach different
discard unpromising nodes rather provide mechanism generate necessary
ones  also  proposing maa   szer et al         developed superficially similar approach could applied last stage  particular  proposed generating
child nodes one one  time checking child found value equal
parents heuristic value  since value child specifies full policy  value
lower bound therefore expansion remaining child nodes skipped  unfortunately  number issues prevent approach providing substantial leverage
practice  first  cannot applied intermediate stages     h   since lower bound
values expanded children available  second  many problems unlikely
child node exists  third  even does  szer et al  specify efficient way
finding it  incremental expansion overcomes issues  yielding approach that 
experiments demonstrate  significantly increases size dec pomdps
solved optimally 
article focuses optimal solutions dec pomdps finite horizon  part
evaluation  compare milp approach  aras   dutech         dpilp  boularias   chaib draa        dp ipg  amato et al          extension
exact dynamic programming algorithm  hansen et al          research finite horizon decpomdps considered many approaches bounded approximations  amato 
carlin    zilberstein         locally optimal solutions  nair et al         varakantham  nair 
tambe    yokoo        approximate methods without guarantees  seuken   zilberstein 
    b      a  carlin   zilberstein        eker   akn        oliehoek  kooi    vlassis       
dibangoye et al         kumar   zilberstein      b  wu et al       a  wu  zilberstein   
chen      b  
particular  much research considered optimal and or approximate solution
subclasses dec pomdps  one subclass contains dec pomdps
agents local states agents cannot influence  resulting models 
toi dec mdp  becker et al         dibangoye  amato  doniec    charpillet        ndpomdp  nair et al         varakantham et al         marecki  gupta  varakantham  tambe 
  yokoo        kumar   zilberstein         interpreted independent  po mdps
   

fioliehoek  spaan  amato    whiteson

agent coupled reward function  and possibly unaffectable state
feature   hand  event driven interaction models  becker et al         consider
agents individual rewards influence others transitions 
recently  models allow limited transition reward dependence
introduced  examples interaction driven markov games  spaan   melo         decmdps sparse interactions  melo   veloso         distributed pomdps coordination locales  varakantham et al         velagapudi et al          event driven interactions
complex rewards  edi cr   mostafa   lesser         transition decoupled dec pomdps
 witwicki   durfee        witwicki         methods developed models often exhibit better scaling behavior methods standard dec  po mdps  typically
suitable agents extended interactions  e g   collaborate transporting
item  also  specialized models consider timing actions whose
ordering already determined  marecki   tambe        beynier   mouaddib        
another body work addresses infinite horizon problems  amato  bernstein    zilberstein        amato  bonet    zilberstein        bernstein  amato  hansen    zilberstein 
      kumar   zilberstein      a  pajarinen   peltonen         possible
represent policy tree  approaches represent policies using finite state controllers
optimized various ways  also  since infinite horizon case undecidable
 bernstein et al          approaches approximate optimal given particular controller size  exists boundedly optimal approach theoretically construct
controller within optimal  feasible small problems large
 bernstein et al         
great interest dec pomdps explicitly take account communication  approaches try optimize meaning communication actions without
semantics  xuan  lesser    zilberstein        goldman   zilberstein        spaan  gordon 
  vlassis        goldman  allen    zilberstein        others use fixed semantics  e g  
broadcasting local observations   ooi   wornell        pynadath   tambe        nair et
al         roth et al         oliehoek  spaan    vlassis        roth  simmons    veloso       
spaan  oliehoek    vlassis        goldman   zilberstein        becker  carlin  lesser    zilberstein        williamson  gerding    jennings        wu et al          since models used
first category  e g   dec pomdp com  converted normal dec pomdps
 seuken   zilberstein         contributions article applicable settings 
finally  numerous models closely related dec pomdps  posgs
 hansen et al          interactive pomdps  i pomdps   gmytrasiewicz   doshi        
graphical counterparts  doshi  zeng    chen         models general sense consider self interested settings agent individual
reward function  i pomdps conjectured require doubly exponential time  seuken
  zilberstein         however  i pomdp number recent advances
 doshi   gmytrasiewicz         current paper makes clear link best response
equivalence histories notion best response equivalence beliefs i pomdps 
particular  article demonstrates two pe action observation histories  aohs  induce  given past joint policy  distribution states aohs agents 
therefore induce multiagent belief future policies agents 
induced multiagent beliefs  turn  interpreted special cases i pomdp beliefs
model agents sub intentional models form fixed policy
tree  rabinovich rosenschein        introduced method that  rather optimizing
   

fiincremental clustering expansion faster optimal planning dec pomdps

expected value joint policy  selects coordinated actions uncertainty tracking
dynamics environment  approach  however  requires model ideal system
dynamics input many problems  considered article  identifying
dynamics difficult 

   future work
several avenues future work made possible research presented article 
perhaps promising development new approximate dec pomdp algorithms 
article focused optimal methods  gmaa  ice seen framework approximate methods  methods could derived limiting amount
backtracking  employing approximate cbg solvers  emery montemerlo  gordon  schneider 
  thrun        kumar   zilberstein      b  wu et al       a   integrating gmaa  methods factored dec pomdps  oliehoek  spaan  whiteson    vlassis        oliehoek       
oliehoek et al          performing lossy clustering  emery montemerlo        wu et al        
using bounded approximations heuristics  particular  seems promising combine approximate clustering approximate factored gmaa  methods 
lossy clustering could achieved generalizing probabilistic equivalence criterion 
currently strict little clustering may possible many problems 
obvious approach cluster histories distributions states histories
agents merely similar  measured by  e g   kullback leibler divergence  alternately 
histories could clustered induce individual belief states 
pr s  i    

x

pr s  
  i   i   

     

 
  i

individual beliefs sufficient statistics history  hypothesize
constitute effective metrics approximate clustering  since individual belief simply
marginalizes agents histories probabilities used probabilistic
equivalence criterion  intuitive heuristic metric approximate clustering 
article focuses increasing scalability respect horizon  developing
techniques deal larger number agents important direction future work 
plan explore performing gmaa  using factored representations  oliehoek  spaan 
whiteson    vlassis         previous work  could exploit factorization
last stage  since earlier stages required full expansions guarantee optimality  however 
larger problems  number joint bg policies  i e   number child nodes 
directly large  earlier stages tightly coupled   therefore incremental expansion
crucial improving scalability optimal solution methods respect number
agents 
another avenue future work generalize gmaa  ice  particular 
may possible flatten two nested searches single search 
could lead significant savings would obviate need solve entire cbg
expanding next one  work  employed plain algorithm basis 
promising direction future work investigate enhancements literature
 edelkamp   schrodl        benefit gmaa  most  particular  described
experiments  different past joint policies lead cbgs different sizes  one idea
   

fioliehoek  spaan  amato    whiteson

first expand parts search tree lead small cbgs  biasing selection
operator  but pruning operator  maintain optimality  
yet another important direction future work development tighter heuristics 
though researchers addressing topic  results presented article underscore important heuristics solving larger problems  currently  heuristic
bottleneck four seven problems considered  moreover  two
problems bottleneck already solved long  h       horizons 
therefore  believe computing tight heuristics longer horizons single
important research direction improving scalability optimal dec pomdp
solution methods respect horizon 
different direction employ theoretical results clustering beyond decpomdp setting develop new solution methods cbgs  instance  well known
method computing local optimum alternating maximization  am   starting
arbitrary joint policy  compute best response agent given agents keep
policies fixed select another agents policy improve  etc  one idea start
completely clustered cbg  agents types clustered together thus
random joint cbg policy simple form  agent selects single action 
improving policy agent consider actual possible types compute
best response  subsequently  cluster together types agent selects
action proceed next agent  addition  since clustering results
restricted collaborative setting  may possible employ them  using similar
approach  develop new solution methods general payoff bgs 
finally  two contributions significant impact beyond problem
optimally solving dec pomdps  first  idea incrementally expanding nodes introduced
gmaa  ice applied search methods  incremental expansion
useful children generated order decreasing heuristic value without prohibitive
computational effort  problems large branching factor multiple sequence
alignment problems computational biology  carrillo   lipman        ikeda   imai        
second  representing pwlc value functions hybrid tree set vectors
wider impact well  e g   online search pomdps  ross  pineau  paquet    chaib draa 
      

   conclusions
article presented set methods advance state of the art optimal solution
methods dec pomdps  particular  presented several advances aim extend
horizon optimal solutions found  advances build gmaa 
heuristic search approach include lossless incremental clustering cbgs solved
gmaa   incremental expansion nodes gmaa  search tree  hybrid heuristic
representations  provided theoretical guarantees that  suitable heuristic used 
incremental clustering incremental expansion yield algorithms complete search equivalent  finally  presented extensive empirical results demonstrating
gmaa  ice optimally solve dec pomdps unprecedented size  significanty
increase planning horizons tackledin cases order
magnitude  given increase horizon one results exponentially larger
search space  constitutes large improvement  moreover  techniques im   

fiincremental clustering expansion faster optimal planning dec pomdps

prove scalability respect number agents  leading first ever solutions
general dec pomdps three agents  results demonstrated
optimal techniques yield new insights particular dec pomdps  incremental
clustering revealed properties broadcastchannel make much easier solve 
addition facilitating optimal solutions  hope advances inspire new principled
approximation methods  incremental clustering already done  wu et al         
enable meaningfully benchmarked 

acknowledgments
thank raghav aras abdeslam boularias making code available us  research supported part afosr muri project  fa               part nwo
catch project               m s  funded fp  marie curie actions individual
fellowship          fp  people      ief  

appendix a  appendix
a   auxiliary algorithms
algorithm    implements bestjointpolicyandvalue function  prunes child
nodes fully specified  algorithm    generates children particular cbg 
algorithm    bestjointpolicyandvalue qexpand    prune fully expanded nodes set
nodes qexpand returning best one value 
input  qexpand set nodes fully specified joint policies 
output  best full joint policy input set value 
   v  
   q qexpand
  
qexpand  remove q 
  
h  vi q
  
v   v
  
v v
  

  
end
   end
    return h   v

a   detailed gmaa  ice algorithm
complete gmaa  ice algorithm shown algorithm    
a   computation v     t   t  
quantity v     t   t   defined recursively via 
v     t   t     v     t   t      est    t   r st    t     t       b      
   

 a   

fioliehoek  spaan  amato    whiteson

algorithm    generateallchildrenforcbg b t    
input  cbg b t   
output  qexpand set containing expanded child nodes cbg 
   qexpand   
   jointp
cbg policies b
  
vb    pr  u     
  
t    t    
 create partial joint policy 

t  
    t 

b
b
  
v     v
      v    
 compute heuristic value 
  
q ht     vb  t    i
 create child node 
  
qexpand  insert q  
   end
   return qexpand

expectation taken respect joint probability distribution states
joint aohs induced  
x
pr st     b   t    
pr ot  at   st   pr st  st   at    pr at   t    t    pr st     t   b   t   
st 

 a   
here         t   at   ot   pr at   t    t    probability specifies at 
aoh   t   which     case deterministic past joint policy   
a   proofs
proof theorem  
substituting             yields
x
b          
vb      vb      
pr    b   t  q 
 


 

x
 




pr    b   t   est  r st                 e t    vb    t                

  est   t  r st          b        e t    vb    t       b       

est   t  r st          b        e t    q    t        t        b    t      t     
  est   t  r st          b        h  t     h   t     

h optimal admissible heuristic  substituting       obtain
vb  t      t        v     t   t     est   t  r st          b        e t    vb    t       b       
v     t   t     est   t  r st           b    t       h  t     h   t    

 via  a       v     t  t       h  t     h   t     
demonstrates heuristic value vb  t   used gmaa  via cbgs using heuristic
form       admissible  lower bounded actual value first plus
admissible heuristic  since performs heuristic search admissible heuristic 
algorithm complete 
   

fiincremental clustering expansion faster optimal planning dec pomdps

algorithm    gmaa  ice
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

vgm aa
    
v  
q   h    vi
lie  q    
repeat
q select lie  
 q   ht   vi 
ie
l  pop q 
isplaceholder q 
b t    cbg
 reuse stored cbg 
else
 construct extended bg solver  
b t    t   cbg
 note    t    t    
t 

t 
b    constructextendedbg b      
b t   clusterbg b t   
b t   solver createsolver b t   
 cbg b t  
end
 expand single child  
vcbg   vgm aa v      t    t  
vcbg    
last stage   h  
vcbg   vb  h    v      h    h   
end
h   vb    i b t   solver nextsolution vcbg  vcbg  

 fully expanded  solution s t  v   h    vcbg  
delete q  and cbg   solver 
continue
  i e  goto line    
end
t    t    
vb  t     v     t   t     vb    
last stage   h  
 note   t     v      vb  t      
v      vgm aa
vgm aa v   
 found new lower bound 

lie  prune vgm aa  
end
delete q  and cbg   solver 
else
q ht     vb  t    i
lie  insert q  
q ht   vb  t    i
  update parent node q  placeholder  
lie  insert q 
end
lie empty

   

fioliehoek  spaan  amato    whiteson

proof lemma  

t  

t    
proof  assume arbitrary ati  ot  
  i  at  i  ot  
  i     
    i  s
  i    
t  

  a t
pr st     
  i  ot  
 i  ai     i  
x


t  
t  
  i   ia t  
pr ot  
  pr st    st  ati  at  i   pr at  i   
  i   t  i   pr st   
 
 o  i  ai  a  i  s
st

 

x



t  
t  
  i   ib t  
  pr st    st  ati  at  i   pr at  i   
  i   t  i   pr st   
pr ot  
 o  i  ai  a  i  s

st

t  
  b t
  pr st     
  i  ot  
 i  ai     i  
t  

assumed arbitrary st     
  i  ot  
 
st     t    ot  
  i



t  
t     t   t     b t
  a t
    i  oi  i  ai     i  
pr st     
  i  ot  
 i  ai     i     pr s

 a   

general
t  

pr s

t  

t  

  
  i   it  ati  ot  
    i    

 t
pr st     
  i  ot  
 i  ai     i  
pr ot       at    


 





  i

t  
 t
pr st     
  i  ot  
 i  ai     i  
p
t   t  
t     
 

t   pr s
  i  oi  i  ai     i  
t  
 

 
  i

now   a     numerator denominator substituting
 ia t   ib t equation  consequently  conclude
t  

t     t     b t t  
    i  i  ai  oi     i  
pr st     
  i   ia t  ati  ot  
    i     pr s
t  


t      
finally  ati   ot  
  i arbitrarily chosen  conclude
    i  s
      holds 

proof lemma  
proof  assume arbitrary   i  s   i  
bi  s    i   ia     i     pr s    i   ia     i  b   
x
 
pr s    i   
  i   ia     i  b   
 
  i

 factoring joint distribution 

 

x

pr s  
  i   ia     i  b    pr    i  s  
  i    ia     i  b   

 
  i

   

fiincremental clustering expansion faster optimal planning dec pomdps

    i depends  
  i     i    

x

pr s  
  i   ia     i  b    pr    i   
  i     i  

  s  
  i depend   i    

x

pr s  
  i   ia    i  b    pr    i   
  i     i  

 due pe   

x

pr s  
  i   ib    i  b    pr    i   
  i     i  

 
  i

 
  i

 
  i

          pr s    i   ib     i  b      bi  s    i   ib     i  
conclude holds   i  s   i  
proof theorem    search equivalence 
prove search equivalence  explicitly write node tuple q   ht   v  phi 
past joint policy  v nodes heuristic value  ph boolean indicating whether
placeholder  consider equivalence maintained open lists  open list
l maintained gmaa  ic contains non expanded nodes q  contrast  open
list lie gmaa  ice contains non expanded nodes q placeholders  previously
expanded nodes   q  denote ordered subset lie containing non expanded nodes
q containing placeholders q  treat open lists ordered sets
heuristic values associated nodes 
definition     l lie equivalent  l lie if 
   q l 
   qs ordering  l remove l   q    q   
   nodes q l q placeholder q parent higher ranked
q 
q ht  vq  falsei l q 

q ht   vq  trueiq s t   t    t      q   q  

   placeholders 
fig     illustrates two equivalent lists past joint policies indexed letters 
note placeholders lie ranked higher nodes l represent 
let us write it ic l  it ice lie   one iteration  i e   one loop main repeat
algorithm    respective algorithms  let it ice  denote operation repeats
it ice long placeholder selected  so ends q expanded  
lemma    l lie   executing it ic l  it ice  lie   leads new open lists
equivalent  l lie  
proof  it ice  selects placeholder q  generates child q already present
l  due properties     definition     inserts it  insertion occurs
relative location it ic algorithms use comparison operator
 definition     together facts guarantee insertion preserves properties     
    a remove b  removes elements b without changing ordering 

   

fioliehoek  spaan  amato    whiteson

lie

l
q
vb



 
 
   

c

e

 
 
   
 
   

f
g
h

j

q

vb



 



 
 

f
g

vb
 

 




b



placeholder  c e j 



nodes  position




placeholder  h i 
consistent ordering
equal values

figure     illustration equivalent lists  past joint policies indexed letters 
example  b expanded earlier  but yet fully expanded ice case  
remaining unexpanded children q  it ice  reinserts q updated heuristic
value q v q  v guaranteed upper bound value unexpanded siblings
q since q  v   vb  q    vb  q      q  v  preserving properties      
it ice  finally selects non placeholder q  guaranteed q
selected it ic  due properties       expansion ice generates one child q  again
inserted relative location ic  inserts placeholder q   hq   q  v  truei
siblings q  again preserving properties      
proof theorem    fact gmaa  ice gmaa  ic search equivalent follows directly lemma    search equivalence means algorithms select
non placeholders q expand  since algorithms begin identical  and therefore trivially equivalent  open lists  maintain equivalent open lists throughout search  such 
property   definition    ensures every time it ice  selects non placeholder  it ic
selects too 

references
allen  m     zilberstein  s          agent influence predictor difficulty decentralized
problem solving  proceedings twenty second aaai conference artificial
intelligence 
amato  c   bernstein  d  s     zilberstein  s          optimal fixed size controllers
decentralized pomdps  proc  aamas workshop multi agent sequential
decision making uncertain domains 
amato  c   bernstein  d  s     zilberstein  s          optimizing memory bounded controllers
decentralized pomdps  proc  uncertainty artificial intelligence 
amato  c   bernstein  d  s     zilberstein  s          optimizing fixed size stochastic controllers pomdps decentralized pomdps  autonomous agents multi agent
systems                 
   

fiincremental clustering expansion faster optimal planning dec pomdps

amato  c   bonet  b     zilberstein  s          finite state controllers based mealy
machines centralized decentralized pomdps  proceedings twentyfourth aaai conference artificial intelligence 
amato  c   carlin  a     zilberstein  s          bounded dynamic programming decentralized pomdps  proc  aamas workshop multi agent sequential
decision making uncertain domains 
amato  c   dibangoye  j  s     zilberstein  s          incremental policy generation
finite horizon dec pomdps  proc  international conference automated
planning scheduling 
aras  r     dutech  a          investigation mathematical programming finite
horizon decentralized pomdps  journal artificial intelligence research          
    
becker  r   carlin  a   lesser  v     zilberstein  s          analyzing myopic approaches
multi agent communication  computational intelligence               
becker  r   zilberstein  s     lesser  v          decentralized markov decision processes
event driven interactions  proc  international conference autonomous
agents multi agent systems 
becker  r   zilberstein  s   lesser  v     goldman  c  v          transition independent
decentralized markov decision processes  proc  international conference
autonomous agents multi agent systems 
bernstein  d  s   amato  c   hansen  e  a     zilberstein  s          policy iteration
decentralized control markov decision processes  journal artificial intelligence
research             
bernstein  d  s   givan  r   immerman  n     zilberstein  s          complexity
decentralized control markov decision processes  mathematics operations research 
               
bertsekas  d  p          dynamic programming optimal control   rd ed   vol  i   athena
scientific 
beynier  a     mouaddib  a  i          solving efficiently decentralized mdps temporal
resource constraints  autonomous agents multi agent systems             
    
boularias  a     chaib draa  b          exact dynamic programming decentralized
pomdps lossless policy compression  proc  international conference
automated planning scheduling 
busoniu  l   babuska  r     de schutter  b          comprehensive survey multi agent
reinforcement learning  ieee transactions systems  man  cybernetics  part c 
applications reviews                 
carlin  a     zilberstein  s          value based observation compression dec pomdps 
proc  international conference autonomous agents multi agent systems 
   

fioliehoek  spaan  amato    whiteson

carrillo  h     lipman  d          multiple sequence alignment problem biology 
siam journal applied mathematics                   
cassandra  a   littman  m  l     zhang  n  l          incremental pruning  simple  fast 
exact method partially observable markov decision processes  proc  uncertainty
artificial intelligence 
cassandra  a  r          exact approximate algorithms partially observable markov
decision processes  unpublished doctoral dissertation  brown university 
dechter  r   flerova  n     marinescu  r          search algorithms best solutions
graphical models  proceedings twenty sixth aaai conference artificial
intelligence 
dekel  e   fudenberg  d     morris  s          topologies types  theoretical economics 
              
dibangoye  j  s   amato  c   doniec  a     charpillet  f          producing efficient errorbounded solutions transition independent decentralized mdps  proc  international conference autonomous agents multi agent systems   submitted
publication 
dibangoye  j  s   mouaddib  a  i     chai draa  b          point based incremental pruning heuristic solving finite horizon dec pomdps  proc  international
conference autonomous agents multi agent systems 
doshi  p     gmytrasiewicz  p          monte carlo sampling methods approximating
interactive pomdps  journal artificial intelligence research              
doshi  p   zeng  y     chen  q          graphical models interactive pomdps  representations solutions  autonomous agents multi agent systems                 
edelkamp  s     schrodl  s          heuristic search  theory applications  morgan
kaufmann 
eker  b     akn  h  l          using evolution strategies solve dec pomdp problems 
soft computinga fusion foundations  methodologies applications            
   
eker  b     akn  h  l          solving decentralized pomdp problems using genetic
algorithms  autonomous agents multi agent systems                 
emery montemerlo  r          game theoretic control robot teams  unpublished
doctoral dissertation  carnegie mellon university 
emery montemerlo  r   gordon  g   schneider  j     thrun  s          approximate solutions partially observable stochastic games common payoffs  proc 
international conference autonomous agents multi agent systems 
emery montemerlo  r   gordon  g   schneider  j     thrun  s          game theoretic
control robot teams  proc  ieee international conference robotics
automation 
givan  r   dean  t     greig  m          equivalence notions model minimization
markov decision processes  artificial intelligence                  
   

fiincremental clustering expansion faster optimal planning dec pomdps

gmytrasiewicz  p  j     doshi  p          framework sequential planning multi agent
settings  journal artificial intelligence research            
goldman  c  v   allen  m     zilberstein  s          learning communicate decentralized environment  autonomous agents multi agent systems               
goldman  c  v     zilberstein  s          optimizing information exchange cooperative
multi agent systems  proc  international conference autonomous agents
multi agent systems 
goldman  c  v     zilberstein  s          decentralized control cooperative systems 
categorization complexity analysis  journal artificial intelligence research      
       
goldman  c  v     zilberstein  s          communication based decomposition mechanisms
decentralized mdps  journal artificial intelligence research              
hansen  e  a   bernstein  d  s     zilberstein  s          dynamic programming partially observable stochastic games  proc  national conference artificial
intelligence 
hauskrecht  m          value function approximations partially observable markov decision processes  journal artificial intelligence research            
hsu  k     marcus  s          decentralized control finite state markov processes  ieee
transactions automatic control                  
huhns  m  n   ed            distributed artificial intelligence  pitman publishing ltd 
ikeda  t     imai  h          enhanced a  algorithms multiple alignments  optimal
alignments several sequences k opt approximate alignments large cases  theoretical computer science                  
kaelbling  l  p   littman  m  l     cassandra  a  r          planning acting partially
observable stochastic domains  artificial intelligence                   
kumar  a     zilberstein  s          constraint based dynamic programming decentralized
pomdps structured interactions  proc  international conference
autonomous agents multi agent systems 
kumar  a     zilberstein  s       a   anytime planning decentralized pomdps using
expectation maximization  proc  uncertainty artificial intelligence 
kumar  a     zilberstein  s       b   point based backup decentralized pomdps  complexity new algorithms  proc  international conference autonomous
agents multi agent systems 
littman  m   cassandra  a     kaelbling  l          learning policies partially observable environments  scaling up  proc  international conference machine
learning 
marecki  j   gupta  t   varakantham  p   tambe  m     yokoo  m          agents
equal  scaling distributed pomdps agent networks  proc  international
conference autonomous agents multi agent systems 
   

fioliehoek  spaan  amato    whiteson

marecki  j     tambe  m          opportunistic techniques solving decentralized
markov decision processes temporal constraints  proc  international
conference autonomous agents multi agent systems 
melo  f  s     veloso  m          decentralized mdps sparse interactions  artificial
intelligence                     
mostafa  h     lesser  v          compact mathematical formulation problems
structured agent interactions  proc  aamas workshop multi agent sequential decision making uncertain domains 
nair  r   roth  m     yohoo  m          communication improving policy computation
distributed pomdps  proc  international conference autonomous agents
multi agent systems 
nair  r   tambe  m   yokoo  m   pynadath  d  v     marsella  s          taming decentralized pomdps  towards efficient policy computation multiagent settings  proc 
international joint conference artificial intelligence 
nair  r   varakantham  p   tambe  m     yokoo  m          networked distributed pomdps 
synthesis distributed constraint optimization pomdps  proc  national conference artificial intelligence 
oliehoek  f  a          value based planning teams agents stochastic partially observable environments  amsterdam university press   doctoral dissertation  university
amsterdam 
oliehoek  f  a          decentralized pomdps  m  wiering   m  van otterlo  eds   
reinforcement learning  state art  vol       springer berlin heidelberg 
oliehoek  f  a   kooi  j  f     vlassis  n          cross entropy method policy search
decentralized pomdps  informatica              
oliehoek  f  a     spaan  m  t  j          tree based solution methods multiagent
pomdps delayed communication  proceedings twenty sixth aaai conference artificial intelligence 
oliehoek  f  a   spaan  m  t  j   dibangoye  j     amato  c          heuristic search identical payoff bayesian games  proc  international conference autonomous
agents multi agent systems 
oliehoek  f  a   spaan  m  t  j     vlassis  n          dec pomdps delayed communication  proc  aamas workshop multi agent sequential decision making
uncertain domains 
oliehoek  f  a   spaan  m  t  j     vlassis  n          optimal approximate q value
functions decentralized pomdps  journal artificial intelligence research      
       
oliehoek  f  a   spaan  m  t  j   whiteson  s     vlassis  n          exploiting locality
interaction factored dec pomdps  proc  international conference
autonomous agents multi agent systems 
oliehoek  f  a     vlassis  n          q value functions decentralized pomdps  proc 
international conference autonomous agents multi agent systems 
   

fiincremental clustering expansion faster optimal planning dec pomdps

oliehoek  f  a   whiteson  s     spaan  m  t  j          lossless clustering histories
decentralized pomdps  proc  international conference autonomous
agents multi agent systems 
oliehoek  f  a   whiteson  s     spaan  m  t  j          approximate solutions factored dec pomdps many agents  proc  international conference
autonomous agents multi agent systems   submitted publication 
oliehoek  f  a   witwicki  s     kaelbling  l  p          influence based abstraction
multiagent systems  proceedings twenty sixth aaai conference artificial
intelligence 
ooi  j  m     wornell  g  w          decentralized control multiple access broadcast
channel  performance bounds  proc    th conference decision control 
osborne  m  j     rubinstein  a          course game theory  mit press 
pajarinen  j     peltonen  j          efficient planning factored infinite horizon decpomdps  proc  international joint conference artificial intelligence 
panait  l     luke  s          cooperative multi agent learning  state art 
autonomous agents multi agent systems                 
puterman  m  l          markov decision processesdiscrete stochastic dynamic programming  john wiley   sons  inc 
pynadath  d  v     marsella  s  c          minimal mental models  proceedings
twenty second aaai conference artificial intelligence 
pynadath  d  v     tambe  m          communicative multiagent team decision problem 
analyzing teamwork theories models  journal artificial intelligence research 
            
rabinovich  z   goldman  c  v     rosenschein  j  s          complexity multiagent
systems  price silence  proc  international conference autonomous
agents multi agent systems 
rabinovich  z     rosenschein  j  s          multiagent coordination extended markov
tracking  proc  international conference autonomous agents multi
agent systems 
ross  s   pineau  j   paquet  s     chaib draa  b          online planning algorithms
pomdps  journal artificial intelligence research              
roth  m   simmons  r     veloso  m          reasoning joint beliefs executiontime communication decisions  proc  international conference autonomous
agents multi agent systems 
roth  m   simmons  r     veloso  m          exploiting factored representations decentralized execution multi agent teams  proc  international conference
autonomous agents multi agent systems 
seuken  s     zilberstein  s       a   improved memory bounded dynamic programming
decentralized pomdps  proc  uncertainty artificial intelligence 
   

fioliehoek  spaan  amato    whiteson

seuken  s     zilberstein  s       b   memory bounded dynamic programming decpomdps  proc  international joint conference artificial intelligence 
seuken  s     zilberstein  s          formal models algorithms decentralized decision
making uncertainty  autonomous agents multi agent systems             
    
spaan  m  t  j   gordon  g  j     vlassis  n          decentralized planning uncertainty teams communicating agents  proc  international conference
autonomous agents multi agent systems 
spaan  m  t  j     melo  f  s          interaction driven markov games decentralized
multiagent planning uncertainty  proc  international conference
autonomous agents multi agent systems 
spaan  m  t  j     oliehoek  f  a          multiagent decision process toolbox 
software decision theoretic planning multiagent systems  proc  aamas
workshop multi agent sequential decision making uncertain domains 
spaan  m  t  j   oliehoek  f  a     amato  c          scaling optimal heuristic search
dec pomdps via incremental expansion  proc  international joint conference
artificial intelligence 
spaan  m  t  j   oliehoek  f  a     vlassis  n          multiagent planning uncertainty
stochastic communication delays  proc  international conference
automated planning scheduling 
sycara  k  p          multiagent systems  ai magazine               
szer  d   charpillet  f     zilberstein  s          maa   heuristic search algorithm
solving decentralized pomdps  proc  uncertainty artificial intelligence 
tsitsiklis  j     athans  m          complexity decentralized decision making
detection problems  ieee transactions automatic control                  
varaiya  p     walrand  j          delayed sharing patterns  ieee transactions
automatic control                  
varakantham  p   kwak  j  young  taylor  m  e   marecki  j   scerri  p     tambe  m         
exploiting coordination locales distributed pomdps via social model shaping 
proc  international conference automated planning scheduling 
varakantham  p   marecki  j   yabu  y   tambe  m     yokoo  m          letting loose
spider network pomdps  generating quality guaranteed policies  proc 
international conference autonomous agents multi agent systems 
varakantham  p   nair  r   tambe  m     yokoo  m          winning back cup distributed pomdps  planning continuous belief spaces  proc  international
conference autonomous agents multi agent systems 
velagapudi  p   varakantham  p   scerri  p     sycara  k          distributed model shaping
scaling decentralized pomdps hundreds agents  proc  international conference autonomous agents multi agent systems 
vlassis  n          concise introduction multiagent systems distributed artificial
intelligence  morgan   claypool publishers 
   

fiincremental clustering expansion faster optimal planning dec pomdps

williamson  s  a   gerding  e  h     jennings  n  r          reward shaping valuing communications multi agent coordination  proc  international conference
autonomous agents multi agent systems 
witwicki  s  j          abstracting influences efficient multiagent coordination
uncertainty  unpublished doctoral dissertation  university michigan  ann arbor 
michigan  usa 
witwicki  s  j     durfee  e  h          influence based policy abstraction weakly coupled
dec pomdps  proc  international conference automated planning
scheduling 
wu  f   zilberstein  s     chen  x       a   point based policy generation decentralized
pomdps  proc  international conference autonomous agents multi
agent systems 
wu  f   zilberstein  s     chen  x       b   rollout sampling policy iteration decentralized
pomdps  proc  uncertainty artificial intelligence 
wu  f   zilberstein  s     chen  x          online planning multi agent systems
bounded communication  artificial intelligence                  
xuan  p   lesser  v     zilberstein  s          communication decisions multi agent cooperation  model experiments  proc  international conference autonomous
agents 
yoshizumi  t   miura  t     ishida  t          a  partial expansion large branching
factor problems  proc  national conference artificial intelligence 
zeng  y     doshi  p          exploiting model equivalences solving interactive dynamic
influence diagrams  journal artificial intelligence research              
zeng  y   doshi  p   pan  y   mao  h   chandrasekaran  m     luo  j          utilizing
partial policies identifying equivalence behavioral models  proceedings
twenty fifth aaai conference artificial intelligence 

   


