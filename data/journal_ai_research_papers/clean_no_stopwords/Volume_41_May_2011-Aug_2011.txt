Journal Artificial Intelligence Research 41 (2011) 445475

Submitted 02/11; published 08/11

Intertranslatability Argumentation Semantics
Wolfgang Dvorak
Stefan Woltran

dvorak@dbai.tuwien.ac.at
woltran@dbai.tuwien.ac.at

Technische Universitat Wien,
Institute Information Systems 184/2
Favoritenstrasse 9-11, 1040 Vienna, Austria

Abstract
Translations different nonmonotonic formalisms always important topic field, particular understand knowledge-representation capabilities
formalisms offer. provide investigation terms different semantics
proposed abstract argumentation frameworks, nonmonotonic yet simple formalism
received increasing interest within last decade. Although properties
different semantics nowadays well understood, explicit results intertranslatability. provide translations wrt. different properties also give
novel complexity results underlie negative results.

1. Introduction
Studies intertranslatability different approaches nonmonotonic reasoning
always considered important contribution field order understand
expressibility representation capacity various formalisms. intertranslatability
understand function Tr maps theories one formalism another
intended models theory source formalism certain relation
intended models Tr (). Several desired properties translation functions
identified, including polynomial (Tr () computed polynomial time
wrt. size ) modular (roughly speaking, allows transform parts
theory independently other). particular, relationship (variants of)
default logic (Reiter, 1980) nonmonotonic modal logics, e.g. autoepistemic logic (Moore,
1985), always received lot attention, (see, e.g., Denecker, Marek, & Truszczynski,
2003; Konolige, 1988; Marek & Truszczynski, 1993). Perhaps notably, Gottlob (1995)
showed modular translation default logic autoepistemic logic impossible.
important contributions direction include translations default logic
circumscription (Imielinski, 1987), modal nonmonotonic logics logic programs (see,
e.g., de Bruijn, Eiter, & Tompits, 2008 overview recent applications) work
Janhunen (1999). Let us also refer recent work Pearce Uridia (2011),
show translations aforementioned kind already known context
non-classical logics related results date back work Godel.
work, study translation functions within particular formalism nonmonotonic reasoning wrt. different semantics proposed formalism. area
default logic, similar research undertaken, instance Liberatore (2007) Delgrande Schaub (2005). Likewise, work concerning relationship different
logic programming semantics refer work Janhunen, Niemela, Seipel, Simons,
c
2011
AI Access Foundation. rights reserved.

fiDvorak & Woltran

(2006) references therein. formalism focus paper
Dungs argumentation frameworks (Dung, 1995) received increasing interest within
last decade. nutshell, argumentation frameworks (AFs, short) represent
abstract statements1 together relation denoting attacks them. Different
semantics provide different ways solve inherent conflicts statements selecting acceptable subsets usually called extensions them. Several semantics
already proposed Dung seminal paper (Dung, 1995), also alternative
approaches play major role nowadays (see, e.g., Baroni, Dunne, & Giacomin, 2011; Baroni, Giacomin, & Guida, 2005; Caminada, 2006; Dung, Mancarella, & Toni, 2007; Verheij,
1996). Compared nonmonotonic formalisms (which built top classical
logical syntax), argumentation frameworks much simpler formalism (in end,
directed graphs). However, simplicity made attractive modeling tool
several diverse areas, like formalizations legal reasoning (Bench-Capon & Dunne, 2005)
multi-agent negotiation (Amgoud, Dimopoulos, & Moraitis, 2007).
field argumentation, intertranslatability mainly studied connection
generalizations Dungs argumentation frameworks. generalization mean
augmentation simple frameworks concepts priorities additional relations arguments. context, translations used show proposed
semantics generalizations close relation corresponding semantics standard AFs. words, given generalized AF one interested
translating standard AFs preserving semantics. translations
discussed, instance, terms bipolar AFs (Cayrol & Lagasquie-Schiex, 2009), valuebased AFs (Bench-Capon & Atkinson, 2009), AFs recursive attacks (Baroni, Cerutti,
Giacomin, & Guida, 2011), abstract dialectical frameworks (Brewka, Dunne, & Woltran,
2011). recent exception intertranslatability within Dung AFs discussed,
work Baumann Brewka (2010), consider enforce desired extension Dung
AFs adding new arguments switching semantics. slightly different perspective, also work Gabbay (2009) related, since investigates substitution
argumentation framework node another framework.
focus exclusively standard argumentation frameworks following
main objective: Given AF F argumentation semantics , find function Tr
-extensions F certain correspondence -extensions Tr (F ).
believe results important different points view.
Firstly, consider advanced argumentation engine semantics , one
wants evaluate AF F wrt. different semantics . Then, might good plan
transform F way AF F evaluating F wrt. semantics allows
easy reconstruction -extensions F . required transformations efficiently computable, leads potentially successful approach implementing
distinguished algorithm -semantics scratch. Figure 1 illustrates idea.
concept filter required case Tr (F ) introduces arguments (which thus
might appear -extensions Tr (F )) course translation making filter1. general, arguments considered simple statements contain number reasons
lead conclusion (see, e.g., Besnard & Hunter, 2001; Caminada & Amgoud, 2007). However,
purpose work, treat arguments atomic entities thus abstracting internal
structure.

446

fiOn Intertranslatability Argumentation Semantics

Input AF: F

Translation


Tr (F )

Solver


(Tr (F ))

(F )
Filter

Figure 1: Solver semantics .

ing new arguments necessary obtain desired original extensions. However,
also consider translations back-translation necessary.
second motivation work concerned meta(level) argumentation (see,
e.g., Modgil & Bench-Capon, 2011; Villata, 2010) explained follows:
meta-level Dung argumentation framework instantiated arguments make
statements arguments, interactions, evaluation object-level argumentation framework(Modgil & Bench-Capon, 2011). translations shall present
exactly fit picture sense model certain features
semantics within another semantics , giving translation .
concrete example, let complete semantics denote stable semantics
(we provide formal details different semantics Section 2; sake
illustration details required). Then, transformation capture
concept admissibility (informally speaking, set arguments defend itself)
implicitly present complete semantics suitable introduction new arguments,
stable semantics perform type reasoning. words, translatability results different semantics AFs yield understanding certain
properties, specified implicitly within one semantics, made (syntactically)
explicit within AF order make properties amenable another semantics.
third important application work, consider situations different
semantics argumentation dealt simultaneously. might case
different agents share views certain situation (modeled AFs)
agents use different semantics reason frameworks. well, problem
combining frameworks constructed assumption
evaluated different semantics falls possible application area work.
Finally, emphasize understanding translations efficiently performed
wrt. different semantics complements picture expressibility argumentation
semantics. instance, exists efficient translation semantics semantics
, translation direction, could understood
expressible , although complexity analysis typical decision problems associated
AFs show difference . example consider semi-stable
stage semantics. semantics credulous acceptance problem P2 -complete
skeptical acceptance problem P2 -complete (Dvorak & Woltran, 2010).
considering call efficient exact translations one map stage semantics semistable semantics vice versa. Thus semi-stable semantics expressible
stage semantics wrt. efficient exact translations. However argue notion
exact translations may restrictive comparing expressibility argumentation
semantics.
447

fiDvorak & Woltran

Beside aspects motivation, would like mention positive results
intertranslations indicate certain form independence semantics argumentation.
particular importance, mind argumentation community nowadays overwhelmed different proposals semantics. Thus understanding basic
principles underlying different semantics crucial, believe results provided
paper contribute question.
organization remainder paper main contributions follows:
Section 2, introduce argumentation frameworks different semantics
deal paper. also review known complexity results complement sense show known tractable problems P -hard;
fact use impossibility results Section 5.
Section 3 defines properties translations basically along lines Janhunen
(1999). particular, consider desired properties efficiency (the translation
computed logarithmic space wrt. given AF), modularity (the translation
done independently certain parts framework) faithfulness (there
clear correspondence extensions translated AF
original AF). However, also consider additional features needed
deal argumentation semantics (for instance, admissible semantics
always yields empty set one solution; thus filtering entire solution
necessary).
Section 4 contains main results, particular provide translations
Dungs original semantics (admissible, preferred, stable, complete, grounded), stage
semantics (Verheij, 1996) semi-stable semantics (Caminada, 2006). analyze
translations wrt. properties mentioned using minimal desiderata
efficiency (a particular form of) faithfulness.
already mentioned, Section 5 provides negative results, i.e. show
certain translations semantics possible. impossibility
results make use typical complexity-theoretic assumptions; others genuine due
different properties compared semantics.
Finally, Section 6 conclude paper summary discussion
presented results. well, outlook potential future work given there.

2. Argumentation Frameworks
section introduce (abstract) argumentation frameworks (Dung, 1995) recall
semantics study paper (see also Baroni & Giacomin, 2009, overview).
Moreover, highlight complement complexity results typical decision problems
associated frameworks.
Definition 1. argumentation framework (AF) pair F = (A, R) nonempty set arguments 2 R attack relation. given AF F = (A, R)
2. technical reasons consider AFs 6= .

448

fiOn Intertranslatability Argumentation Semantics

use AF denote set arguments RF denote attack relation R.
pair (a, b) R means attacks b.
sometimes use notation R b instead (a, b) R. A,
also write R (resp. R S) case exists argument b S,
b R (resp. R b). case ambiguity arises, use instead R .
AF naturally represented directed graph. Semantics argumentation
frameworks given via function assigns AF F = (A, R) set (F ) 2A
extensions. shall consider functions stb, adm, prf , com, grd , stg,
sem stand stable, admissible, preferred, complete, grounded, stage,
respectively, semi-stable semantics. giving actual definitions semantics,
require formal concepts.
Definition 2. Given AF F = (A, R), argument defended (in F ) set
b A, b a, also b holds. Moreover, set A,
+
define range S, denoted SR
, set {b | b}.
continue definitions considered semantics. Observe common feature concept conflict-freeness, i.e. arguments extension allowed
attack other.
Definition 3. Let F = (A, R) AF. set conflict-free (in F ),
a, b S, (a, b) R. conflict-free set S, holds
+
stb(F ), \ S, a, i.e. SR
= A;

adm(F ), defended S;
prf (F ), adm(F ) adm(F ) S;
com(F ), adm(F ) defended S, S;
grd (F ), com(F ) com(F ) S;
+
stg(F ), conflict-free set F , TR+ SR
;
+
sem(F ), adm(F ) adm(F ) TR+ SR
.

semantics , sets defined ones (F ).
recall AF F ,
stb(F ) sem(F ) prf (F ) com(F ) adm(F )
holds, considered semantics except stable semantics, (F ) 6=
holds. grounded semantics always yields exactly one extension. Moreover AF
least one stable extension stable, semi-stable, stage extensions coincide.
Example 1. Consider AF F = (A, R), = {a, b, c, d, e} R = {(a, b), (c, b),
(c, d), (d, c), (d, e), (e, e)}. graph representation F given follows.


b

c
449



e

fiDvorak & Woltran

x

xy z

yz x

x



z


Figure 2: Argumentation framework FT,z = { x, x z, z x}.
stb(F ) = stg(F ) = sem(F ) = {{a, d}}. admissible sets F
collection {}, {a}, {c}, {d}, {a, c}, {a, d}, thus prf (F ) = {{a, c},{a, d}}. Finally
complete extensions F {a}, {a, c} {a, d}, {a} grounded extension
F .

turn complexity reasoning AFs. end, define following
decision problems semantics introduced Definition 3.
Credulous Acceptance Cred : Given AF F = (A, R) argument A.
contained (F )?
Skeptical Acceptance Skept : Given AF F = (A, R) argument A.
contained (F )?
Verification extension Ver : Given AF F = (A, R) set arguments
A. (F )?
Existence extension Exists : Given AF F = (A, R). (F ) 6= ?
Existence nonempty extension Exists
: Given AF F = (A, R). exist
set 6= (F )?
giving overview known results, provide lower bounds which,
best knowledge, established yet.
Proposition 1. problems Credgrd = Skeptgrd = Skeptcom well Vergrd P-hard
(under L-reductions, i.e. reductions using logarithmic space).
Proof. use reduction P-hard problem decide, given propositional definite
Horn theory atom x, whether x true minimal model .
Let, definite Horn theory = {rl : bl,1 bl,il hl | 1 l n} atoms X
atom z X, FT,z = (A, R) AF defined follows:
= X {t}
R = {(x, x), (t, x) | x X} {(z, t)}
{(rl , hl ), (bl,j , rl ) | rl T, 1 j il )}
fresh argument. See Figure 2 example. Clearly AF FT,z
constructed using logarithmic space size .
450

fiOn Intertranslatability Argumentation Semantics

following show z minimal model iff grounded
extension FT,z iff grd (FT,z ) = {T {t}}.
First attend grounded extension E FT,z iff E = {T {t}}. Obviously
if-direction holds. Thus let us assume E, x X attacked E
thus r defended E. Hence E = {T {t}}.
remains show z minimal model iff grounded extension
E FT,z . recall definition characteristic function FF AF F , defined
FF (S) = {x AF | x defended S}, grounded extension F least
fix-point FF . show only-if part, let us assume z minimal model
. Thus exists finite sequence rules (rli )1ik , (i) rule rli
atom bli ,s exists rule rlj , j < hlj = bli ,s (ii) hlk = z. Clearly rl1
empty body thus corresponding argument attackers FT,z , i.e. rl1 E.
claim i, 1 k, rli E holds well prove induction.
end, assume claim holds < i, i.e. rlm E, thus E hlm
< holds. Using (i) get argument rli , holds
E a. Hence rli E. particular rlk E (ii) E z. z
argument attacking also E.
show if-part, let us assume contained grounded extensions E
FT,z . construction E z thus exists integer k, FFk () z
< k : FFm () 6 z. claim 1 k x X holds
FFm () x x minimal model . proof induction
m. induction base consider FF (). construction FF () set arguments
correspond rules empty body. arguments attacked FF ()
head atoms rules, clearly minimal model. induction step
assume FFm1 () attacks arguments corresponding atoms minimal model.
FFm1 () 6 z 6 FFm1 (). Let x X argument FFm () x,
FFm1 () 6 z. exists ri hi = x ri FFm ().
construction FT,z argument ri defended FFm1 () iff atom
body ri attacked FFm1 (). Hence, assumption atom body ri
contained minimal model . head hi ri minimal model
. Hence, FFk () z, get z minimal model .
Proposition 2. Verstg coNP-hard.
Proof. prove assertion reducing (NP-hard) problem 3-SAT complementary problem Verstg . assume 3-CNF formula given set C clauses,
clause set atoms negated atoms (denoted x). CNF
variables X, define AF F = (A, R)
= X X C {s, t, b}
R = {(x, x), (x, x) | x X} {(l, c) | l c, c C}
{(c, t) | c C} {(s, y), (y, s) | \ {s, b}} {(t, b), (b, b)}
X = {x | x X} s, t, b fresh arguments. See Figure 3 illustrating
example. show satisfiable iff {s} stage extension F . First let
us assume satisfiable let satisfying assignment . set
451

fiDvorak & Woltran


c1
x1

c2
x2

x1

b
c3
x3

x2

x4

x3

x4


Figure 3: AF F{c1 ,c2 ,c3 } c1 = {x1 , x2 , x3 }, c2 = {x2 , x3 , x4 }, c3 = {x1 , x2 , x4 }.
E = {t} {x | x X, (x) = true} {x | x X, (x) = f alse} stable extension
+
F , i.e. ER
= A, since {s}+
R = \ {b}, {s} stage extension F .
let us assume {s} stage extension. argumentation above, i.e.
using {s}+
R A, get F stable extension. seen
satisfying assignment corresponds stable extension F . Thus conclude
unsatisfiable.
Together results literature (Coste-Marquis, Devred, & Marquis, 2005;
Dimopoulos & Torres, 1996; Dung, 1995; Dunne & Bench-Capon, 2002; Dunne & Caminada, 2008; Dvorak & Woltran, 2010), obtain complexity-landscape abstract
argumentation given Table 1.

3. Properties Translations
follows, understand translation Tr function maps AFs AFs.
particular, seek translations, given semantics , , extensions (F )
certain relation extensions (F ) AF F . start with, introduce
additional properties seem desirable translations. end, define,
Cred

Skept

Ver

Exists

Exists


grd

P-c

P-c

P-c

trivial

L

stb

NP-c

coNP-c

L

NP-c

NP-c

adm

NP-c

trivial

L

trivial

NP-c

com

NP-c

P-c

L

trivial

NP-c

prf

NP-c

coNP-c

trivial

NP-c

sem

P2 -c
P2 -c

P2 -c
P2 -c
P2 -c

coNP-c

trivial

NP-c

coNP-c

trivial

L



stg

Table 1: Complexity abstract argumentation (C-c denotes completeness class C).
452

fiOn Intertranslatability Argumentation Semantics

AFs F = (A, R), F = (A , R ), union AFs F F = (A , R R ), inclusion
F F iff jointly R R .
Definition 4. translation Tr called
efficient every AF F , AF Tr (F ) computed using logarithmic space
wrt. |F |;
covering every AF F , F Tr (F );
embedding every AF F , AF ATr (F ) RF = RTr (F ) (AF AF );
monotone AFs F, F , F F implies Tr (F ) Tr (F );
modular AFs F, F , Tr (F ) Tr (F ) = Tr (F F ).
translation reduce expressiveness semantic using expensive
computation. Thus computational cost translation less computational cost semantic focus, i.e. less P. Thus using class
logarithmic space computable functions appropriate purposes. addition, one
could seek translations minimal wrt. certain parameters (for instance, number
additional arguments attacks). However, decided design translations
towards aims, since would partly hide main intuitions underlying translations.
property efficiency clearly motivated, let us spend words
properties. Covering holding ensures translation hide original
arguments conflicts. embedding, addition, ensures additional attacks
original arguments pretended. efficiency motivated expressiveness possibility reuse reasoning algorithms, properties covering
embedding motivated meta-argumentation scenario. Translations
covering embedding preserve arguments conflicts (meta)-argue about,
assumption one usually mind context meta-argumentation. put
words, embedding translation, original framework meta-level
part clearly separated translated framework.
Monotonicity modularity crucial extending source AF translation.
Let us first consider monotonicity. multi-agent scenarios may impossible one
agent withdraw already interchanged arguments attacks, agents may
agree forget arguments conflicts already know about; hence, re-translating
augmented source AF respect already existing translation. let us consider
modularity adding arguments/attacks huge AF. updating
translation suffices consider new arguments/attacks, instead whole
source AF, indeed computational value. field meta-argumentation,
modular translations particular interesting compatible merging
AFs. Thus one interchange merge- translation-operations, i.e. make
difference one first merges two AFs translates union first translates
AFs merges translations. Moreover, easily checked modular
transformation also monotone.
453

fiDvorak & Woltran

Next, give two properties refer semantics. note concept
faithfulness follows definition used Janhunen (1999); exactness spirit
bijective faithfulness wrt. equivalence used Liberatore (2007).
Definition 5. semantics , call translation Tr
exact every AF F , (F ) = (Tr (F ));
faithful every AF F , (F ) = {E AF | E (Tr (F ))}
|(F )| = | (Tr (F ))|.
However, due nature different semantics want consider, need
less restricted notions. instance, consider translation stable
semantics, face fact AFs possess stable extension,
semantics always yield least one extension. following definition takes
care issue.
Definition 6. semantics , , call translation Tr
weakly exact exists collection sets arguments,
AF F , (F ) = (Tr (F )) \ S;
weakly faithful exists collection sets arguments,
AF F , (F ) = {E AF | E (Tr (F )) \ S} |(F )| = | (Tr (F )) \ S|.
sometimes refer elements remainder sets. Note depends
translation, input AF. Thus, definition,
contains arguments never occur AFs subject translation. words,
reserve certain arguments introduction weak translations.
Finally, mention properties Definition 4 well exact, weakly
exact faithful transitive, i.e. two transformations satisfying one properties, also concatenation satisfies respective property. However, transitivity
guaranteed weakly faithful.

4. Translations
section, provide numerous faithful translations semantics introduced
Definition 3. minimal desiderata, want translations efficient, monotone,
covering (see Definition 4). Thus, section speaking translations
tacitly assume satisfy least three properties.
4.1 Exact Translations
start rather simple translation, show exact prf sem
adm com.
Translation 1. translation Tr 1 defined Tr 1 (F ) = (A , R ),
= AF AF
R = RF {(a, ), (a , a), (a , ) | AF },
AF = {a | AF }.
454

fiOn Intertranslatability Argumentation Semantics



b

c



e



b

c



e

Figure 4: Tr 1 (F ) AF F Example 1.
words intuition behind translation (for illustration see Figure 4 depicts translation example AF Example 1): new arguments
AF self-attacking thus never appear extension resulting framework. However, attacks original argument (and attacks ), thus argument
defended set E Tr 1 (F ) E. Consequently, Tr 1 (F )
admissible set also complete one.
Lemma 1. AF F set E arguments, following propositions equivalent:
1. E adm(F )
2. E adm(Tr 1 (F ))
3. E com(Tr 1 (F ))
Proof. arguments AF self-conflicting, every conflict-free set E Tr 1 (F ) satisfies E AF . Further, since Tr 1 embedding, E conflict-free F iff E conflict-free
Tr 1 (F ). Moreover, since Tr 1 adds symmetric attacks arguments AF ,
E defends arguments F iff E defends arguments Tr 1 (F ). Thus,
adm(F ) = adm(Tr 1 (F )) (1)(2) follows. (2)(3), let arbitrary
argument E A. Tr 1 (F ) argument attacked
attacker (except itself) . Hence, A, E defends E
thus every admissible set Tr 1 (F ) also complete one. Finally, (2)(3) holds since
com(F ) adm(F ) true AF F .
Concerning Tr 1 observe another side effect. already mentioned
argument attacking . Thus different preferred extensions Tr 1 (F ) incomparable
range (recall Definition 2), therefore preferred extension Tr 1 (F ) also semistable extension Tr 1 (F ).
Lemma 2. AF F set E arguments, following propositions equivalent:
1. E prf (F )
2. E prf (Tr 1 (F ))
3. E sem(Tr 1 (F ))
Proof. (1)(2), sufficient show E adm(F ) iff E adm(Tr 1 (F )) holds
E. captured Lemma 1. (2)(3), let D, E prf (Tr 1 (F )) and,
+
+
towards contradiction, assume DR
/ sem(Tr 1 (F )).
ER , i.e.
455

fiDvorak & Woltran



b

c



e



b

c



e

Figure 5: Tr 2 (F ) AF F Example 1.
E preferred extensions, 6 E. Thus, exists argument \ E.
+
/ E + , contradiction + E + .
construction Tr 1 (F ), get DR

R
R
R
(2)(3) follows fact sem(F ) prf (F ) AF F .
Obviously Tr 1 embedding translation introduction new argument
attack Tr 1 depends one original argument also modular. Together
results Lemma 1 2 thus get first main result.
Theorem 1. Tr 1 modular, embedding, exact translation prf sem
adm com.
next translation, Tr 2 , concerned stage semi-stable semantics. addition Tr 1 , make attacks original AF symmetric (thus Tr 2
embedding) add original attack (a, b) also attack (a, b ).
Translation 2. translation Tr 2 defined Tr 2 (F ) = (A , R ),
= AF AF
R = RF {(b, a), (a, b ) | (a, b) RF }
{(a, b) | AF , (b, b) RF }
{(a, ), (a , ) | AF }
symmetric attacks Tr 2 (F ) mirror fact mind orientation
attacks considering conflict-freeness. words, exploit well known
property symmetric frameworks conflict-free admissible sets coincide. However,
making attacks symmetric destroys original range extensions. Thus make use
arguments AF sense that, given set E arguments, argument
+
+
contained ER
Likewise, add attacks self iff contained ER .
defeating arguments. technical reason require original
argument attacked maximal conflict-free non-empty set Tr 2 (F ) (see also
proof forthcoming lemma). illustration refer Figure 5.
Lemma 3. AF F set E arguments, following propositions
equivalent:
1. E stg(F )
2. E stg(Tr 2 (F ))
3. E sem(Tr 2 (F ))
456

fiOn Intertranslatability Argumentation Semantics



c

b



e


Figure 6: Tr 3 (F ) AF F Example 1.
Proof. First, mention every stage extension AF F also maximal (wrt.
) conflict-free F . Let us consider case stg(F ).
stg(F ) = {} equivalent to, AF also (a, a) RF . construction
Tr 2 also (a, a) R therefore stg(Tr 2 (F )) = sem(Tr 2 (F )) = {}.
Hence lemma holds AFs, remainder proof assume
6 stg(F ).
(1)(2), observe set E conflict-free F iff conflict-free
+
+
Tr 2 (F ). following use (ER
) short hand {a | ER
}.
F
F
+
+


(ERF ) ER , since (a, b) RF , (a, b ) R . Furthermore,
+
maximal conflict-free set E F (and thus Tr 2 (F )), holds AF ER
.
+
show contradiction. end, let us assume AF 6 ER
, i.e.
+
exists AF 6 ER
. E 6= self-attacking arguments
+
+
R 6R E,
contained ER , thus (a, a) 6 R . 6 ER
E 6
set E {a} conflict-free F E maximal E; contradiction. Hence,
maximal conflict-free set E AF F , i.e. candidates stage extensions,
+
+
+
+
holds ER
maximal (wrt. subset inclusion) iff ER
= AF (ER ) thus ER

F
F
maximal.
(2)(3), observe AF (a, a) 6 R defends Tr 2 (F )
arguments AF self-conflicting. Thus, admissible conflict-free sets coincide
Tr 2 (F ). Consequently, stage semi-stable extensions Tr 2 (F ) coincide.
definition translation Tr 2 covering, embedding. Moreover, selfattacking argument attacked arguments Tr 2 modular. Together
lemma, thus obtain following result.
Theorem 2. Tr 2 exact translation stg sem.
next translations consider stable semantics source formalism. Recall
AFs possess stable extension, holds semantics (also recall
excluded empty AFs considerations). Thus use weak translations
introduced Definition 6. first translation weakly exact uses single
remainder set {t} (recall definition remainder sets given Definition 6).
Translation 3. translation Tr 3 (F ) defined Tr 3 (F ) = (A , R )
= AF {t}
R = RF {(t, a), (a, t) | AF }
457

fiDvorak & Woltran

intuition rather simple, see also Figure 6. fact, new argument
Tr 3 (F ) encodes might exist stable extension F . Thus none
(other) arguments Tr 3 (F ) accepted, whenever accepted. Since argument
guards exists least one stable extension Tr 3 (F ) (for AF F ), namely
{t}, make use fact stable, semi-stable stage semantics thus coincide
Tr 3 (F ).
Lemma 4. Let F = (A, R) AF E A. following statements
equivalent:
1. E stb(F )
2. E stb(Tr 3 (F ))
3. E sem(Tr 3 (F ))
4. E stg(Tr 3 (F ))
E (Tr 3 (F )) {stb, sem, stg} either E = {t} 6 E holds.
Proof. translation modify original AF F , i.e. Tr 3 embedding,
E AF , E conflict-free F iff E conflict-free Tr 3 (F ).
+
(1)(2): E stb(F ) definition non-empty, conflict-free satisfies ER
=
F

+
R

AF . construction also holds E thus ER = , i.e. E stb(Tr 3 (F )).
(1)(2) consider E stb(Tr 3 (F )), E AF . definition E
+

conflict-free Tr 3 (F )) thus F ; moreover, ER
= Tr 3 embedding also
+
ER
= AF . Hence E stb(F ).
(2)(3)(4), mention {t} stable extension Tr 3 (F ) AF
F . Furthermore, know exists stable extension AF, stable,
semi-stable stage extensions coincide.
Finally argument conflict arguments extension
E E set {t}.
Adding argument corresponding attacks source AF modular operation attacks added Tr 3 also embedding.
Theorem 3. Tr 3 modular, embedding weakly exact stb , {sem, stg}.
Proof. result follows Lemma 4, states sem(Tr 3 (F )) = stg(Tr 3 (F )) =
stb(F ) {{t}}. Thus taking remainder set = {{t}}, Tr 3 weakly exact.
continue different translation stable semantics.
Translation 4. Tr 4 defined Tr 4 (F ) = (A , R )
= AF AF
R = RF {(b , a) | a, b AF }
{(a , ), (a, ) | AF }
{(a, b ) | (a, b) RF }.
458

fiOn Intertranslatability Argumentation Semantics



b

c



e



b

c



e

Figure 7: Tr 4 (F ) AF F Example 1.
translation Tr 2 , new arguments AF used encode range
extension sense attacked set E Tr 4 (F ) range
E F . However, given fact AF attacks back original arguments
A, accept argument set E arguments range
E. illustration running example, see Figure 7. Observe example
arguments , b , c , , e attacks arguments a, b, c, d, e.
Lemma 5. Let F = (A, R) AF E E 6= . Then, following
statements equivalent:
1. E stb(F )
2. E stb(Tr 4 (F ))
3. E adm(Tr 4 (F ))
4. E prf (Tr 4 (F ))
5. E com(Tr 4 (F ))
6. E sem(Tr 4 (F ))
conflict-free set E Tr 4 (F ) holds E A.
Proof. First, arguments self-attacking, conflict-free set E
Tr 4 (F ) holds E A. Since translation embedding, set E conflict-free
F iff conflict-free Tr 4 (F ). show (1)(2), let E stb(F ). Hence,
\ E, E R a. claim argument \ E attacked E
Tr 4 (F ). distinguish two cases different arguments \ E:
(i) \ E: construction Tr 4 (F ) preserves attacks R. Thus

\ E satisfies E R a, obtain E R


(ii) : case E E R , since (a, ) R case \ E,
assumption E stb(F ), exists argument b E (b, a) R.

construction (b, ) R thus E R .
Together observations conflict-free sets, get E stb(Tr 4 (F )).

Vice versa, show (1)(2) get, E stb(Tr 4 (F )), E R a, \ E,
thus, particular, \ E. definition Tr 4 , also E R
\ E. Thus E stb(F ) follows.
459

fiDvorak & Woltran

show (2)(3), let E nonempty admissible extension Tr 4 (F ) E.
construction, := {b | (b, a) R } . E adm(Tr 4 (F )),


E R . E either E E R a. Thus every

holds either E E R a; hence, E stb(Tr 4 (F )).
remaining implications follow well-known relations semantics, i.e.
stb(G) sem(G) prf (G) com(G) adm(G), AF G. Hence, particular, since Tr 4 (F ), stable extensions non-empty admissible sets coincide, claim
follows.
Clearly Tr 4 embedding translation, new argument add attacks
original arguments, Tr 4 modular.
Theorem 4. Tr 4 embedding weakly exact translation stb
{adm, com, prf , sem}.
Proof. Lemma 5, particular stb(F ) = (Tr 4 (F )) \ {}, AF
F . Thus taking remainder set, obtain Tr 4 weakly exact involved
semantics.
Thus Tr 3 Tr 4 weakly exact translations stb sem,
course different remainder sets. Due different properties two translations
depends concrete application would better choice.
4.2 Faithful Translations
far, introduced exact weakly exact translations. present
translations relax semantical property, i.e. switch faithful translations.
first example, consider translation stg sem faithful embedding,
exact. contrast translation Tr 2 exact stg sem
embedding. see Section 5 impossible give translation
embedding exact stg sem, thus one decide property
important concrete application scenario.
Translation 5. translation Tr 5 (F ) defined Tr 5 (F ) = (A , R )
= AF AF AF
R = RF {(a, a), (a, a) | AF }
{(a, ), (a , ) | AF }
{(a, b ) | (a, b) RF }
Tr 2 (F ) arguments AF handle range original extensions.
instead making original attacks symmetric (as Tr 2 ) add arguments AF
encode argument extension (also compare Figures 5 8).
fact, meta-arguments indicating extension used
faithful translations presented subsection.
Lemma 6. Let F = (A, R) AF, E E = E (A \ E). following
statements equivalent:
460

fiOn Intertranslatability Argumentation Semantics



b

c



e



b

c



e



b

c



e

Figure 8: Tr 5 (F ) AF F Example 1.
1. E stg(F )
2. E stg(Tr 5 (F ))
3. E sem(Tr 5 (F ))
Moreover sem(Tr 5 (F )) exists set E = E (A \ E).
Proof. First prove stg(Tr 5 (F )) form = E (A \ E).
conflict-free AF = (each self-attacking)
{a, a} 6 E (as attacks vice versa). stage extension also
-maximal conflict-free set either S. Hence
exists E = E (A \ E).
(1)(2): Let E stg(F ). easy see E conflict-free Tr 5 (F ).
construction argument either E E holds mutual
attacks a, hence (E )+
R . Next observe
. definition
iff
E
self-attacking thus (E )+
R
Tr 5 (F ) argument attacked arguments b (b, a) R.
+
(E )+
R iff either E exists b (b, a) R iff (E)R .
+
assumption E stage extension F thus (E)R -maximal. Using
observation also (E )+
R -maximal Tr 5 (F ) therefore
E stg(Tr 5 (F )).
(1)(2): Let E stg(Tr 5 (F )). recall E form = E (A \ E),
E A. easily checked E conflict-free F . observation
+
+
(E )+
R iff (E)R fact (E )R -maximal Tr 5 (F ) get
+
also ER
-maximal F . Hence, E stg(F ).
(2)(3): Let us consider E stg(Tr 5 (F )). already observed, E
desired form AF AF either E E a. construction
argument b AF attack E . conclude stage extension defends
attackers, i.e. admissible set. Hence, stage semi-stable extensions
Tr 5 (F ) coincide.
lemma construction Tr 5 , following result immediate.
Theorem 5. Tr 5 modular, embedding faithful translation stg sem.
Next give faithful translation admissible semantics stable, semi-stable
stage semantics.
461

fiDvorak & Woltran



b

c



e



b

c



e

(a, b)

(c, b)

(d, c)

(c, d)

(d, e)

(e, e)

Figure 9: Tr 6 (F ) AF F Example 1.
Translation 6. translation Tr 6 (F ) defined Tr 6 (F ) = (A , R )
= AF AF RF
R = RF {(a, a), (a, a) | AF }
{(r, r) | r RF }
{(a, r) | r = (y, a) RF }
{(a, r) | r = (z, y) RF , (a, z) RF }
main idea use additional arguments (a, b) represent attack
relations source framework order capture admissibility follows: (a, b)
attacked extension E Tr 6 (F ) (a, b) critical wrt. corresponding
extension E F , meaning either b
/ E exists c E (c, b) RF , i.e.
defended E. instance, consider argument (c, b) translation
example framework depicted Figure 9. Then, (1) b attacks (c, b) since b
chosen (i.e. b chosen in), need defend b; (2) attacks (c, b) since
chosen in, defends b attacker c (recall (d, c) present source
AF). Thus, long (c, b) attacked argument, b treated corrected terms
admissibility (wrt. attacker c). Note example b cannot defended
a, thus way get (a, b) range select b out.
Lemma 7. Let F = (A, R) AF, E E = E (A \ E). following
statements equivalent:
1. E adm(F )
2. E stb(Tr 6 (F ))
3. E sem(Tr 6 (F ))
4. E stg(Tr 6 (F ))
Moreover E (Tr 6 (F )) ( {stb, sem, stg}) exists set E
E = E (A \ E).
Proof. (1)(2): Let E adm(F ). easy see E conflict-free Tr 6 (F )

(E )+
R . remains show argument r r R
462

fiOn Intertranslatability Argumentation Semantics



attacked E . Let (a, b) argument r. b
/ E b E thus E R r.

Otherwise, b E (thus b E ) and, assumption, E defends b F , i.e. (c, a) R

c E (thus c E ). construction, (c, r) R E R r.
(1)(2): Let E stb(Tr 6 (F )). E conflict-free, thus R E = {a, a} 6 E
A. construction, E conflict-free F . remains show E defends
arguments F . Let b \ E b R E. exists
argument (b, a) Tr 6 (F ) attacked E. E
/ E thus
exists argument c E (c, b) R.
(2)(3)(4): empty set always admissible always stable
extension Tr 6 (F ). Hence, stable, semi-stable stage extensions coincide Tr 6 (F ),
AF F .
Observe construction Tr 6 drawing attacks {(a, r) | r = (z, y) RF , (a, z)
RF } depends two attacks three arguments original framework. Hence Tr 6
modular. Lemma 7 next result follows quite easily.
Theorem 6. Translation Tr 6 embedding faithful adm ( {stb, sem, stg}).
faithful translation complete stable semantics present next,
extend given AF arguments represent whether argument attacked
corresponding extension not. add arguments ensure admissibility
completeness. entire translation thus slightly complicated; see also Figure 10
depicts translated framework running example.
Translation 7. translation Tr 7 (F ) defined Tr 7 (F ) = (A , R )
= AF AF AF AF AF RF
R = RF {(x, x) | x AF RF }
{(a, a), (a, a), (a , ), (a, ) | AF }
{(a, b ), (a , b ) | (a, b) RF }
{(a, r ), (b , r ) | r = (b, a) RF }
intuition behind arguments AF , AF , RF similar previous translations.
argument AF indicates attacked extension E F , AF
says attacked E.
Lemma 8. Let F = (A, R) AF, E E = E (A \ E) {a | E R a} {a |
E 6R a}. following statements equivalent:
1. E com(F )
2. E stb(Tr 7 (F ))
3. E sem(Tr 7 (F ))
4. E stg(Tr 7 (F ))
Moreover E (Tr 6 (F )) ( {stb, sem, stg}) exists set E
E = E (A \ E) {a | E R a} {a | E 6R a}.
463

fiDvorak & Woltran



b

c



e



b

c



e



b

c



e



b

c



e



b

c



e

(a, b)

(c, b)

(d, c)

(c, d)

(d, e)

(e, e)

Figure 10: Tr 7 (F ) AF F Example 1.
Proof. show (1)(2), let E com(F ). construction E conflict-free

Tr 7 (F ) (for x, E x R x R y). Moreover, definition E ,

+
verified (E )+
R . Thus remains show (i) (E )R
(ii) R (E )+
R .
(i) Let arbitrary argument F . E complete extension
either E, thus E , exists attack (b, a) R E 6R b,

thus b E . construction (b , ) R thus E R .
(ii) Let r = (b, a) R arbitrary attack F . E admissible holds either


/ E, thus E , E R b, thus b E . cases E R r.
Putting things together, get R = (E )+
R
equivalent E stable extension Tr 7 (F ).
show (1)(2), let E stb(Tr 7 (F )). First prove E desired form.
E conflict-free -maximal clearly E (A A) = E \ E
E A. Let arbitrary argument. E iff
6 E . E stable 6 E iff exists attack (b, ) b E .
construction Tr 7 (F ) equivalent b E therefore E R a. Thus E
desired form, remains show E complete. mentioned

x, E : x R x R thus E conflict-free F . Thus remains show
(i) E defends arguments F (ii) E contains argument defended
E F .
(i) Let us assume exists argument E defended E. Thus exists
r = (b, a) R, E 6 b. construction also
/ E (as E)


b 6 E (as E 6 b). Tr 7 (F ) self-attacking argument r attacked
arguments a, b (and itself). Hence, contradiction E stable
extension.
464

fiOn Intertranslatability Argumentation Semantics

(ii) Let argument defended E. arguments b R
E R b thus b E b
/ E . Recall Tr 7 (F ) argument
self-attacking thus belong E attacked arguments
b a. E stable extension 6 E E E.
(2) (3) (4): always exists complete extension know framework Tr 7 (F ) stable extension. stable, stage semi-stable extensions
coincide.
Translation Tr 7 introduces huge number new arguments, despite introduction concrete argument attack depends single argument attack. Hence
Tr 7 modular. easily checked Tr 7 also embedding. Together Lemma 8
thus state following result Tr 7 .
Theorem 7. Tr 7 modular, embedding faithful translation com (
{stb, sem, stg}).
Finally present translation grounded semantics semantics
focus, i.e. semantics except admissible semantics. main idea
simulate computation least fixed-point characteristic function FF (S) =
{x AF | x defended S} AF F within target AF.
Translation 8. translation Tr 8 (F ) defined Tr 8 (F ) = (A , R )
= AF,1 AF,1 AF,l AF,l
R = RF {(ai , bi ) | (a, b) R, [l]}
{(ai , bi+1 ) | (a, b) R, [l 1]}
AF = AF,l l = |A2F | .
illustration, use slightly different example depicted Figure 11(a). Observe AF {a, c, d} grounded extension. translated framework
given Figure 11(b).
intuition behind arguments ai AF,i FFi (), intuition
(i1)
() 6 a. integer l upper bound number
ai AF,i FF
iterations need reach least fixed-point, i.e. grounded extension.
Lemma 9. Let F = (A, R) AF E grounded extension Tr 8 (F ).
E grounded extension F . Tr 8 (F ) grounded,
stable, complete, preferred, semi-stable stage extensions coincide.
Proof. recall definition characteristic function FF AF F , defined
FF (S) = {x AF | x defended S}, grounded extension F least
fix-point FF . use shorthand F = Tr 8 (F ). One show
arbitrary
(i) ai E iff FFi ();
(ii) ai E iff FFi1 () 6R a;
465

fiDvorak & Woltran



c

b



e

a1

b1

c1

d1

e1

a1

b1

c1

d1

e1

a2

b2

c2

d2

e2

a2

b2

c2

d2

e2

a3

b3

c3

d3

e3



b

c



e

(a) AF F

(b) Tr 8 (F )

Figure 11: example Tr 8 .
(iii) AF,i (E )+
R .
(iv) AF,i (E )+
R .
prove structural induction. induction base show (ii) (iv)
arguments a1 . a1 E attacked argument.
coincides fact FF0 () = doesnt attack argument thus (ii)
(iv) holds.
two induction steps: (1) Showing (i) (iii) hold arbitrary n iff (ii)
(iv) hold n; (2) showing (ii) (iv) hold arbitrary n iff (i) (iii)
hold n 1.
(1) assume (ii) (iv) hold . definition FF FFn ()
iff b = {b | b a} attacked FFn1 (). Applying induction
hypothesis (ii) b obtain FFn () iff bi {bi | (b, a) R}
attacked E . Further, construction Tr 8 (F ) attackers
a, equivalent argument ai defended E . recall
argument defended grounded extension indeed contained grounded
extension. Hence, FFn () iff ai E (i) holds.
show (iii) consider ai AF,i . ai E clearly ai (E )+
R . Thus let
us consider ai
/ E . Then, observations, exists bi
bi ai E 6 bi . Using latter induction hypothesis (iv) obtain
bi E . E ai , hence ai (E )+
R obtain (iii).
(2) let us assume (i) (iii) hold an1 . FFn1 ()
iff exists b FFn1 () {b | (b, a) R }. induction hypothesis holds iff
466

fiOn Intertranslatability Argumentation Semantics

exists bi1 E (b, a) R. words exists bi1 E

bi1 R ai , implies ai 6 E . Moreover bi1 E

bi1 R ai , assumption (iii) E defends ai thus
ai E . Hence (ii) (iv) hold.
Furthermore applying FF operator either add new argument set
attack additional argument reach fixed-point. step make
decision least two arguments thus FFl () = grd (F ). combination (i),
get al E iff grd (F ). Moreover (iii) (iv) holds E also stable
extension thus grd (F ) = stb(F ) = com(F ) = prf (F ) = sem(F ) = stg(F ).
Tr 8 integer value l depends size source AF, Tr 8 modular.
However, verified computation translation requires logarithmic
space wrt. Tr 8 embedding (the original AF indeed contained resulting
AF; see also bottom layer Figure 11(b)). final result concerning translations thus
follows immediately Lemma 9.
Theorem 8. Tr 8 embedding faithful translation grd ( {stb, com,
prf , stg, sem}).

5. Negative Results
section, present results fortifying several semantics exist
translation desired properties. first result, rather straight forward,
relies fact grounded semantics unique-status semantics.
Proposition 3. (weakly) faithful translation grd {sem,
stg, prf , com, stb, adm}.
Proof. instance consider AF F = ({a, b}, {(a, b), (b, a)}). {{a}, {b}}
(F ) {sem, stg, prf , com, stb, adm} grounded semantics always proposes
unique extension.
observe general holds multiple status semantics
unique status semantics (weakly) faithful translation .
results based complexity gaps different semantics (see Table 1)
fact certain translations preserve decision problem. start cases
impossible find efficient faithful translations; even allow weakly
faithful translations, cf. Definition 6. Afterwards, give negative results concerning
(weakly) exact translations.
following theorem concerns intertranslatability preferred, semi-stable
stage semantics, i.e. semantics skeptical acceptance P2 -complete. underlying reason impossibility result complexity gap credulous acceptance
problems.
Theorem 9. efficient (weakly) faithful translation sem prf stg prf
unless P2 = NP.
467

fiDvorak & Woltran

Proof. Let Tr efficient (weakly) faithful translation {sem, stg} prf .
definition translation L-computable show next reduces Cred Credprf :
Let F = (A, R) arbitrary AF, x argument. First let us assume x
credulously accepted wrt. . Hence, exists E (F ) x E. Tr
weakly faithful translation, E prf (Tr (F )), E = E. Thus
x E , i.e. x credulously accepted wrt. preferred semantics Tr (F ).
assume x credulously accepted Tr (F ) wrt. prf , i.e. x E E
prf (Tr (F )). x E conclude E remainder set Tr . Tr
weakly faithful translation E = E (F ), thus x credulously
accepted F wrt. . Thus, Tr L-reduction P2 -hard problem Cred
NP-easy problem Credprf .
following theorem makes use complexity gaps skeptical acceptance.
Theorem 10. efficient (weakly) faithful translation ,
{sem, stg, prf } {com, stb, adm}, unless P2 = NP.
Proof. Given efficient weakly faithful translation Tr remainder set
Skept translated problem Skept , deciding whether argument
-extension set S. Next show problem Skept
remains coNP. One disprove Skept , guessing set E A, 6 E
verify E (F ) E 6 S. Ver P set fixed, i.e.
depend input, NP-algorithm. Hence proving Skept coNP. Thus
Tr would L-reduction P2 -hard problem Skept coNP-easy problem
Skept , implies P2 = NP.
One might prefer (weakly) exact (weakly) faithful translations. seen
Section 4, several translations exact faithful. cases
interested either finding exact translation evidence exact translation
possible. following theorems approve appropriate given
(weakly) faithful translation Section 4, cannot exact translation.
Theorem 11. (weakly) exact translation {adm, com}
{stb, prf , sem, stg}.
Proof. basically fact admissible resp. complete extensions may
-relation; consider e.g. F = ({a, b}, {(a, b), (b, a)}) (F ) = {{a}, {b}, }. Let us
assume exists (weakly) exact translation Tr . definition, (F ) =
{{a}, {b}, } (Tr (F )), {a} contradicts {stb, prf , sem, stg}.
Theorem 12. (weakly) exact translation com adm.
Proof. observe every AF F holds adm(F ), AFs

/ com(F ). Thus weakly exact translation Tr , collection
remainder sets, holds S. then, given AF F com(F ), e.g.
F = ({a, b}, {(a, b), (b, a)}), conclude adm(Tr (F )) \ S, contradiction.
Theorem 13. efficient (weakly) exact translation grd
{stb, adm, com}, unless L = P.
468

fiOn Intertranslatability Argumentation Semantics

f

h
g1


g2

e
c

b



Figure 12: Counterexample exact translations stg ( {sem, prf }).
Proof. Let us, towards contradiction, assume exists efficient (weakly) exact
translation Tr grd . given AF F = (A, R) set E holds
E grd (F ) iff E (Tr (F )). Thus Tr would L-reduction P-hard problem
Ver grd (see Proposition 1) Ver ( {stb, adm, com}) L.
Section 4 presented two translations stg sem: Tr 2 exact
translation, embedding, Tr 5 embedding faithful translation,
exact. Let us also mention point Tr 2 translation presented
Section 4 embedding. Hence natural question occurs whether
translation embedding exact stg sem possible. give negative
answer question.
Theorem 14. embedding (weakly) exact translation stg sem.
Proof. Let us assume exists embedding (weakly) exact translation Tr
stg sem. Consider AF F = ({a, b}, {(a, a), (a, b)}) stg(F ) = {{b}}. Tr
(weakly) exact translation {b} sem(Tr (F )) thus {b} adm(Tr (F )).
(a, b) RTr (F ) (Tr (F ) embedding) thus {b} must attack
a. (b, a) RTr (F ) contradiction Tr embedding
translation.
Finally present impossibility result prf stg sem stg.
Theorem 15. (weakly) exact translation stg ( {sem, prf }).
Proof. Consider AF F = ({a, b, c, d, e, f, g1 , g2 , h}, {(g1 , g1 ), (g2 , g2 ), (a, b), (b, a), (c, d),
(d, c), (a, g1 ), (b, e), (c, e), (d, g2 ), (e, f ), (f, h), (h, e)}) illustrated Figure 12.
sem(F ) = {{b, d, f }, {a, c, f }, {a, d}} prf (F ) = sem(F ) {{b, c, f }}.
prove weakly exact translation stg ( {sem, prf }),
show exists AF F sem(F ) stg(F ). end, let us assume
F = (A , R ) AF {{b, d, f }, {a, c, f }, {a, d}} stg(F ). Using fact
{b, d, f } conflict-free F obtain (d, f ), (f, d) 6 R similar using
{a, c, f } conflict-free F get (a, f ), (f, a) 6 R . assumption {a, d} stg(F )
thus {a, d} maximal conflict-free set F , observations set
{a, d, f } also conflict-free F , contradiction.

469

fiDvorak & Woltran

grd
adm
stb
com
prf
sem
stg
grd id Tr 4 Tr 8 / - Tr 8 / - Tr 8 / Tr 8 / ?
Tr 8 / ? Tr 8 / ?
adm
id
Tr 6 / - Tr 1 Tr 4 Tr 6 / - Tr 6 / - Tr 6 / stb

Tr 4
id
Tr 4
Tr 4
Tr 3 , Tr 4 Tr 3
com Tr 4 Tr 7 / - Tr 7 / id
Tr 4 Tr 7 / - Tr 7 / - Tr 7 / prf




id
Tr 1
? /sem




id
? /stg





Tr 2
id
Table 2: Results (weakly) faithful / exact translations.

6. Conclusion
work, investigated intertranslations different semantics abstract argumentation. focused translations efficiently computable faithful (with
relaxations due certain differences implicit semantics). overview results given Table 2.3 entry row column read follows: states
shown (Section 5) efficient faithful (even weakly faithful) translation
exists. entry refers translation (or concatenation translations),
found efficient (weakly) exact translation . entry split
two parts, e.g. Tr 8 / -, means found efficient (weakly) faithful translation,
exact translation. ? indicates open problem. mention
concatenated translations weakly faithful built weakly exact
translation Tr 4 (which remainder set empty set) faithful translation
(either Tr 6 , Tr 7 , Tr 8 ).
Figure 13 illustrates intertranslatability results one glance. Here, solid arrow
expresses efficient faithful translation dotted arrow depicts
may exist translation, far neither found one argument
existence. Furthermore, two semantics , path
proven (partly typical complexity theoretical assumptions)
efficient faithful translation . consider relations semantics
wrt. exactness rather faithfulness, overall picture changes; see Figure 14. Here,
get detailed picture relations stable, admissible, complete
semantics. One conclusion, draw pictures semi-stable semantics
expressive one, since investigated semantics efficiently
embedded. Moreover, believe investigations complements recent results
comparisons different semantics proposed argumentation frameworks.
Let us point also mention that, instead considering different properties
translations, could also used slightly revised semantics. notion remainder
sets (as given Definition 6) partly circumvented by, instance, using quasiadmissible semantics instead admissible semantics, quasi-admissible extensions
3. One may notice Tr 5 appear table. Recall Tr 5 proposed alternative
Tr 2 satisfying slightly different properties stg sem; see also discussion Theorem 14.

470

fiOn Intertranslatability Argumentation Semantics

AF non-empty admissible extensions (in case ones exist),
empty set otherwise. Also obvious restricted properties translation are, less translations exist (compare Figures 13 14). Hence, observe
certain trade-off translation criteria comparability semantics.
alternative option obtain translations would exploit known relations
argumentation semantics logic-programming semantics (see, e.g., Dung, 1995;
Wu, Caminada, & Gabbay, 2009) making use known translatability results
latter. However, refrained approach here, since might blur minimal
requirements translations consideration. particular, point
meta-argumentation, translations via logic-programming semantics might introduce new
arguments technical reasons due logic-programming syntax,
meaning level AFs.
semi-stable

preferred

stage

admissible, complete, stable

grounded

Figure 13: Intertranslatability argumentation semantics wrt. weakly faithful translations.

semi-stable

preferred

stage

stable

admissible

complete

grounded

Figure 14: Intertranslatability argumentation semantics wrt. weakly exact translations.
471

fiDvorak & Woltran

future work, identify following tasks: First, want solve open slots
Table 2. Second, properties translations could interest. instance,
one could even strengthen property exact (which defined terms
extensions) requirement labelings (Caminada & Gabbay, 2009) source
target framework coincide. Labelings provide additional information, particular
arguments contained extension. Likewise, would interesting investigate
intertranslatability general approach equational semantics argumentation
frameworks (Gabbay, 2011). properties translations could given terms
graph properties. example, acyclic AFs remain acyclic translations,
parameters tree-width remain unchanged. Requirements form also
termed structural preservation (Janhunen et al., 2006). properties interest
computational point view sense that, case source AF easy
evaluate (because structure), advantage lost translation;
recall Figure 1 suggested use translations rapid prototyping
approach compute extensions semantics via argumentation engine based
different semantics. Finally, plan extend considerations important
semantics like ideal semantics (Dung et al., 2007), cf2-semantics (which proposed
among others Baroni et al., 2005), resolution-based semantics (Baroni, Dunne, &
Giacomin, 2011), among resolution-based grounded semantics particular
interest. well studying translations semantics generalizations Dung-style
AFs EAFs (Modgil, 2009) AFRAs (Baroni, Cerutti, et al., 2011) interesting
subject future work.

Acknowledgments
work supported Vienna Science Technology Fund (WWTF) grant
ICT08-028. preliminary version paper presented International
Conference 30 Years Nonmonotonic Logic.
authors grateful Christof Spanring suggesting counterexample used
proof Theorem 15. Moreover, authors want thank Tomi Janhunen well
anonymous referees 30 Years Nonmonotonic Logic symposium
JAIR valuable comments helped improve paper.

References
Amgoud, L., Dimopoulos, Y., & Moraitis, P. (2007). unified general framework
argumentation-based negotiation. Durfee, E. H., Yokoo, M., Huhns, M. N., & Shehory, O. (Eds.), Proceedings 6th International Joint Conference Autonomous
Agents Multiagent Systems (AAMAS 2007), pp. 963970. IFAAMAS.
Baroni, P., Dunne, P. E., & Giacomin, M. (2011). resolution-based family abstract
argumentation semantics grounded instance. Artif. Intell., 175 (3-4), 791813.
Baroni, P., Cerutti, F., Giacomin, M., & Guida, G. (2011). AFRA: Argumentation framework recursive attacks. Int. J. Approx. Reasoning, 52 (1), 1937.
472

fiOn Intertranslatability Argumentation Semantics

Baroni, P., & Giacomin, M. (2009). Semantics abstract argument systems. Rahwan,
I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp. 2544. Springer.
Baroni, P., Giacomin, M., & Guida, G. (2005). SCC-recursiveness: general schema
argumentation semantics. Artif. Intell., 168 (1-2), 162210.
Baumann, R., & Brewka, G. (2010). Expanding argumentation frameworks: Enforcing
monotonicity results. Baroni, P., Cerutti, F., Giacomin, M., & Simari, G. R. (Eds.),
Proceedings 3rd Conference Computational Models Argument (COMMA
2010), Vol. 216 Frontiers Artificial Intelligence Applications, pp. 7586. IOS
Press.
Bench-Capon, T. J. M., & Atkinson, K. (2009). Abstract argumentation values.
Rahwan, I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp. 4564.
Springer.
Bench-Capon, T. J. M., & Dunne, P. E. (2005). Argumentation AI law: Editors
introduction. Artif. Intell. Law, 13 (1), 18.
Besnard, P., & Hunter, A. (2001). logic-based theory deductive arguments. Artif.
Intell., 128, 203235.
Brewka, G., Dunne, P. E., & Woltran, S. (2011). Relating semantics abstract dialectical frameworks standard AFs. Proceedings 22nd International Joint
Conference Artificial Intelligence (IJCAI 2011), pp. 780785. AAAI Press.
Caminada, M. (2006). Semi-stable semantics. Dunne, P. E., & Bench-Capon, T. J. M.
(Eds.), Proceedings 1st Conference Computational Models Argument
(COMMA 2006), Vol. 144 Frontiers Artificial Intelligence Applications, pp.
121130. IOS Press.
Caminada, M., & Amgoud, L. (2007). evaluation argumentation formalisms.
Artif. Intell., 171 (5-6), 286310.
Caminada, M., & Gabbay, D. (2009). logical account formal argumentation. Studia
Logica, 93 (2), 109145.
Cayrol, C., & Lagasquie-Schiex, M. (2009). Bipolar abstract argumentation systems.
Rahwan, I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp. 6584.
Springer.
Coste-Marquis, S., Devred, C., & Marquis, P. (2005). Symmetric argumentation frameworks. Godo, L. (Ed.), Proceedings 8th European Conference Symbolic
Quantitative Approaches Reasoning Uncertainty (ECSQARU 2005), Vol.
3571 Lecture Notes Computer Science, pp. 317328. Springer.
de Bruijn, J., Eiter, T., & Tompits, H. (2008). Embedding approaches combining rules
ontologies autoepistemic logic. Brewka, G., & Lang, J. (Eds.), Proceedings
11th International Conference Principles Knowledge Representation
Reasoning (KR2008), pp. 485495. AAAI Press.
Delgrande, J. P., & Schaub, T. (2005). Expressing default logic variants default logic. J.
Log. Comput., 15 (5), 593621.
473

fiDvorak & Woltran

Denecker, M., Marek, W., & Truszczynski, M. (2003). Uniform semantic treatment
default autoepistemic logics. Artif. Intell., 143 (1), 79122.
Dimopoulos, Y., & Torres, A. (1996). Graph theoretical structures logic programs
default theories. Theor. Comput. Sci., 170 (1-2), 209244.
Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person games. Artif. Intell., 77 (2),
321358.
Dung, P. M., Mancarella, P., & Toni, F. (2007). Computing ideal sceptical argumentation.
Artif. Intell., 171 (10-15), 642674.
Dunne, P. E., & Bench-Capon, T. J. M. (2002). Coherence finite argument systems.
Artif. Intell., 141 (1/2), 187203.
Dunne, P. E., & Caminada, M. (2008). Computational complexity semi-stable semantics
abstract argumentation frameworks. Holldobler, S., Lutz, C., & Wansing, H.
(Eds.), Proceedings 11th European Conference Logics Artificial Intelligence
(JELIA 2008), Vol. 5293 Lecture Notes Computer Science, pp. 153165. Springer.
Dvorak, W., & Woltran, S. (2010). Complexity semi-stable stage semantics argumentation frameworks. Inf. Process. Lett., 110 (11), 425430.
Gabbay, D. M. (2009). Fibring argumentation frames. Studia Logica, 93 (2-3), 231295.
Gabbay, D. M. (2011). Equational approach argumentation networks. Unpublished draft.
Gottlob, G. (1995). Translating default logic standard autoepistemic logic. J. ACM,
42 (4), 711740.
Imielinski, T. (1987). Results translating defaults circumscription. Artif. Intell.,
32 (1), 131146.
Janhunen, T. (1999). intertranslatability non-monotonic logics. Ann. Math. Artif.
Intell., 27 (1-4), 79128.
Janhunen, T., Niemela, I., Seipel, D., Simons, P., & You, J.-H. (2006). Unfolding partiality
disjunctions stable model semantics. ACM Trans. Comput. Log., 7 (1), 137.
Konolige, K. (1988). relation default autoepistemic logic. Artif. Intell.,
35 (3), 343382.
Liberatore, P. (2007).
abs/0707.3781.

Bijective faithful translations among default logics.

CoRR,

Marek, W., & Truszczynski, M. (1993). Nonmonotonic Logic: Context Dependent Reasoning.
Springer.
Modgil, S. (2009). Reasoning preferences argumentation frameworks. Artif. Intell.,
173 (9-10), 901934.
Modgil, S., & Bench-Capon, T. J. M. (2011). Metalevel argumentation. Accepted publication J. Log. Comput.. Available http://dx.doi.org/doi:10.1093/logcom/
exq054.
Moore, R. C. (1985). Semantical considerations nonmonotonic logic. Artif. Intell., 25,
7594.
474

fiOn Intertranslatability Argumentation Semantics

Pearce, D., & Uridia, L. (2011). Godel splitting translations. Submitted Draft.
Preliminary Version presented International Conference 30 Years
Nonmonotonic Logic.
Reiter, R. (1980). logic default reasoning. Artif. Intell., 13 (12), 81132.
Verheij, B. (1996). Two approaches dialectical argumentation: admissible sets argumentation stages. Meyer, J., & van der Gaag, L. (Eds.), Proceedings 8th
Dutch Conference Artificial Intelligence (NAIC96), pp. 357368.
Villata, S. (2010). Meta-Argumentation Multiagent Systems: Coalition Formation, Merging Views, Subsumption Relation Dependence Networks. Ph.D. thesis, Universita
degli Studi di Torino.
Wu, Y., Caminada, M., & Gabbay, D. M. (2009). Complete extensions argumentation
coincide 3-valued stable models logic programming. Studia Logica, 93 (2-3),
383403.

475

fiJournal Artificial Intelligence Research 41 (2011) 131-154

Submitted 11/10; published 5/11

Redistribution Mechanisms Assignment
Heterogeneous Objects
Sujit Gujar
Narahari

sujit@csa.iisc.ernet.in
hari@csa.iisc.ernet.in

Dept Computer Science Automation
Indian Institute Science, Bangalore, 560012

Abstract
p heterogeneous objects assigned n competing agents (n > p)
unit demand. required design Groves mechanism assignment
problem satisfying weak budget balance, individual rationality, minimizing budget
imbalance. calls designing appropriate rebate function. objects
identical, problem solved refer WCO mechanism. measure
performance mechanisms redistribution index. first prove impossibility theorem rules linear rebate functions non-zero redistribution index
heterogeneous object assignment. Motivated theorem, explore two approaches
get around impossibility. first approach, show linear rebate functions
non-zero redistribution index possible valuations objects
certain type relationship design mechanism linear rebate function
worst case optimal. second approach, show rebate functions nonzero efficiency possible linearity relaxed. extend rebate functions
WCO mechanism heterogeneous objects assignment conjecture worst
case optimal.

1. Introduction
Consider p resources available n > p agents interested utilizing
one them. desirable assign resources agents value
most. Since classical Vickery-Clarke-Groves mechanisms (Vickrey, 1961; Clarke, 1971;
Groves, 1973) attractive properties dominant strategy incentive compatibility
(DSIC) allocative efficiency (AE), Groves mechanisms quite appealing use
context. However, general, Groves mechanism need budget balanced.
is, total transfer money system may zero. system left
surplus deficit. Using Clarkes (1971) mechanism, ensure fairly
weak conditions, deficit money (that mechanism weakly budget
balanced). case, system auctioneer left money.
Often, surplus money really needed many social settings allocations
Government among departments, etc. Since strict budget balance cannot coexist
DSIC AE (Green-Laffont theorem, see Green & Laffont, 1979), would like
redistribute surplus participants far possible, preserving DSIC AE.
idea originally proposed Laffont (1979). total payment made mechanism
redistribution referred rebate agents.

c
2011
AI Access Foundation. rights reserved.

fiGujar & Narahari

paper, consider following problem. n agents p heterogeneous
objects (n > p > 1). agent desires one object p objects. agents
valuation objects independent valuations objects.
Valuations different agents also mutually independent. goal design
mechanism assignment p objects among n agents allocatively efficient,
dominant strategy incentive compatible, maximizes rebate (which equivalent
minimizing budget imbalance). addition, would like mechanism satisfy
feasibility individual rationality. Thus, seek design Groves mechanism
assigning p heterogeneous objects among n agents satisfying:
1. Feasibility (F) weak budget balance. is, total payment agents
less equal total received payment.
2. Individual Rationality (IR), means agents utility participating
mechanism non-negative.
3. Minimizes budget imbalance.
call Groves mechanism redistributes Clarkes Payment Groves redistribution mechanism simply redistribution mechanism. Designing redistribution mechanism involves design appropriate rebate function. redistribution mechanism,
rebate function agent linear function valuations remaining
agents, refer mechanism linear redistribution mechanism (LRM). many
situations, design appropriate LRM reduces problem solving linear program.
Due Green-Laffont theorem , cannot guarantee 100% redistribution type
profiles. performance index redistribution mechanism would worst case
redistribution, is, fraction surplus guaranteed redistributed
irrespective bid profiles. fraction referred redistribution index
rest paper. advantage worst case analysis that, require
distributional information type sets agents. desirable rebate
function deterministic anonymous. rebate function said anonymous two
agents bids get rebate. Also, valuation spaces identical
agents, without loss generality, restrict attention anonymous
rebate functions. Thus, aim design anonymous, deterministic rebate function
maximizes redistribution index satisfies feasibility individual rationality.
work paper seeks non-trivially extend results Moulin (2009)
Guo Conitzer (2009) independently designed Groves mechanism order
redistribute surplus objects identical (homogeneous objects case).
mechanism deterministic, anonymous, maximum redistribution index
possible Groves redistribution mechanisms. refer mechanism worst
case optimal (WCO) mechanism. WCO Mechanism linear redistribution mechanism. paper, concentrate designing linear redistribution mechanism
heterogeneous objects case.

132

fiRedistribution Mechanisms

1.1 Relevant Work
impossible achieve allocative efficiency, DSIC, strict budget balance simultaneously, compromise one properties. Faltings (2005) Guo
Conitzer (2008a) achieve budget balance compromising AE. interested
preserving AE DSIC, settle non-zero surplus non-zero deficit
money (budget imbalance) system. reduce budget imbalance, various rebate
functions designed Bailey (1997), Cavallo (2006), Moulin (2009), Guo
Conitzer (2009). Moulin (2009) Guo Conitzer (2009) designed Groves redistribution mechanism assignment p homogeneous objects among n > p agents unit
demand. Guo Conitzer (2009) generalize work earlier paper (Guo & Conitzer,
2007) multi-unit demand identical items. work Guo Conitzer (2008b),
authors designed redistribution mechanism optimal expected sense
homogeneous objects setting. Thus, require distributional information
type sets agents. Clippel co-authors (2009) use idea destroying
items maximize agents utilities. preliminary version results presented
paper appeared earlier papers (Gujar & Narahari, 2009, 2008).
1.2 Contributions Outline
objective paper design Groves redistribution mechanism assignment
heterogeneous objects unit demand. best knowledge, first
attempt design redistribution mechanism assignment heterogeneous objects.
First, investigate question existence linear rebate function redistribution surplus assignment heterogeneous objects. result shows general,
domain valuations agent Rp+ , impossible design linear rebate
function, non-zero redistribution index, heterogeneous settings. However,
relax assumption independence valuations different objects get linear
rebate function non-zero redistribution index. Another way get around impossibility theorem relax linearity requirement rebate function. particular,
contributions paper summarized follows.
first prove impossibility existence linear rebate function non-zero
redistribution index heterogeneous settings, domain valuations
agent Rp+ valuations objects independent.
objects heterogeneous values objects agent
derived one single number, design Groves redistribution mechanism
linear, anonymous, deterministic, feasible, individually rational, efficient.
addition, mechanism worst case optimal non-zero redistribution index.
show existence non-linear rebate function non-zero redistribution index.
propose mechanism, HETERO, extends Moulin/WCO mechanism
heterogeneous settings. conjecture HETERO non-zero redistribution index
worst case optimal.

133

fiGujar & Narahari

paper organized follows. Section 2, introduce notation followed
paper describe relevant background work literature. also explain
WCO mechanism there. Section 3, state prove impossibility result. derive
extension WCO mechanism heterogeneous objects single dimensional
private information Section 4. impossibility result rule possibility
non-linear rebate functions strictly positive redistribution index. show
redistribution mechanism, BAILEY-CAVALLO, Baileys mechanism (1997)
applied settings consideration Section 5. design another non-linear rebate
function, HETERO, actually matches Moulins rebate function objects
identical. describe construction HETERO Section 5. carried
simulations provide empirical evidence conjecture regarding HETERO.
experimental setup results described Section 6. conclude paper Section
7 provide directions future work. analysis, need ordering
bids agents define Appendix A. proofs lemmas
paper presented Appendix B.

2. Preliminaries Notation
section first define notation used paper preliminaries
redistribution mechanisms.
2.1 Model Notation
notation used summarized Table 1. context clear, use
t, ti , ri , k, vi indicate t(b), ti (b), ri (b), k(b), vi (k(b)) respectively. paper,
assume payment made agent form ti () P
ri (), ti () agent
payment Clarke pivotal mechanism (1971). refer ti , total Clarke
payment surplus system.
general, assume n agents p distinct objects. also assume
allocation rule satisfies allocative efficiency (AE) property.
2.2 Important Definitions
provide important definitions conceptual way.
Definition 1 (DSIC) say mechanism Dominant Strategy Incentive Compatible
(DSIC) best response agent report type truthfully, irrespective
types reported agents.
Definition 2 (Allocative Efficiency) say mechanism allocatively efficient (AE)
mechanism chooses, every given type profile, allocation objects among
agents sum valuations1 allocated agents maximized.
Definition 3 (Redistribution Mechanism) refer Groves mechanism Groves
redistribution mechanism simply redistribution mechanism, allocates objects
1. Sum valuations allocated agents allocation also referred total value value
allocation.

134

fiRedistribution Mechanisms

n
N
p

j
R+

bi
b
K
k(b)
k (b)
(b)
ki
vi (k(b))
v
ti (b)
t(b)
ti
ri (b)
e

Number agents
Set agents = {1, 2, . . . , n}
Number objects
Index agent, = 1, 2, . . . , n
Index object, j = 1, 2, . . . , p
Set positive real numbers
space valuations agent i, = Rp+
Bid submitted agent i, = (bi1 , bi2 , . . . , bip )
(b1 , b2 , . . . , bn ), bid vector
set allocations p objects n agents,
getting one object
allocation, k() K, corresponding bid profile b
allocatively efficient allocation bid profile b
allocatively efficient allocation bid profile b
agent excluded system
Valuation allocation k agent i,
b bid profile
P
v : K R, valuation function, v(k(b)) = vi (k(b))
Payment made agent Clarke pivotal mechanism,
(b))
bid profile b, ti (b) = vi (k (b)) v(k (b)) v(ki
Clarke payment,
P is, total payment received
agents, t(b) = ti (b)
Clarke payment received absence agent
Rebate agent bid profile b
P
ri (b)
redistribution index mechanism, = inf b:t(b)6=0 t(b)
Table 1: Notation: redistribution mechanisms

agents allocatively efficient way redistributes Clarke surplus system
form rebates agents net payment made agent still follows
Groves payment structure.
Definition 4 (Linear Rebate Function) say rebates agent follow linear
rebate function rebate linear combination bid vectors remaining
agents. Moreover, redistribution mechanism uses linear rebate functions
agents, say mechanism linear redistribution mechanism.
Definition 5 (Redistribution Index) redistribution index redistribution mechanism defined worst case fraction Clarkes surplus gets redistributed
among agents. is,
P
ri (b)
e = inf
b:t(b)6=0 t(b)

135

fiGujar & Narahari

2.3 Optimal Worst Case Redistribution Objects Identical
objects identical, every agent value object, call
vi . Without loss generality, assume, v1 v2 . . . vn . Clarkes pivotal
mechanism, first p agents receive objects p agents pay
vp+1 . So, surplus system pvp+1 . situation, Moulin (2009) Guo
Conitzer (2009) independently designed redistribution mechanism.
Guo Conitzer (2009) maximize worst case fraction total surplus gets
redistributed. mechanism called WCO mechanism. Moulin (2009) minimizes
ratio budget imbalance value optimal allocation, value
allocatively efficient allocation. WCO mechanism coincides Moulins feasible
individually rational mechanism. mechanisms work follows.
receiving bids agents, bids sorted decreasing order. first p agents
receive objects. agents Clarke payment calculated, say ti . Every agent pays,
pi = ti ri , where, ri rebate function agent i.
riW CO = cp+1 vp+2 + cp+2 vp+3 + . . . + cn1 vn
= 1, . . . p + 1
W
CO
= cp+1 vp+1 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vn = p + 2, . . . n
ri

(1)

where,
(1)i+p1 (n

p)



n1
p1




n1
X




ci =
n 1 Pn1 n 1 j=i

j=p

j

n1
j




;

= p + 1, . . . , n 1

(2)



Suppose y1 y2 . . . yn1 bids (n 1) agents excluding agent i,
equivalently rebate agent given by,
riW CO =

n1
X

c j yj

(3)

j=p+1

redistribution index mechanism e , e given by,


n1
p


e = 1
Pn1 n 1
j=p
j

optimal mechanism, since mechanism guarantee
e fraction redistribution worst case.
proceed present impossibility theorem state following theorem
Guo Conitzer (2009) used design mechanism.
Theorem 1 (Guo & Conitzer, 2009) x1 x2 . . . xn 0,
a1 x1 + a2 x2 + . . . xn 0 iff

j
X
i=1

136

ai 0 j = 1, 2 . . . , n

fiRedistribution Mechanisms

3. Impossibility Linear Rebate Function Non-Zero Redistribution
Index
reviewed design redistribution mechanism homogeneous objects.
seen WCO mechanism linear function types agents.
explore general case. homogeneous case, bids real numbers
arranged decreasing order. Clarke surplus linear function ordered bids.
heterogeneous scenario, would case. bid bi belongs Rp+ ;
hence, unique way defining order among bids. Moreover, Clarke
surplus linear function received bids heterogeneous case. So, cannot
expect linear/affine rebate function types work well type profiles.
prove formally.
first generalize theorem work Guo Conitzer (2009). context
Guo Conitzer stated proved theorem homogeneous setting.
show result holds true heterogeneous objects case also. symbol <
denotes order bids agents, defined A.2.
Theorem 2 Groves redistribution mechanism, deterministic, anonymous rebate
function f DSIC iff,
ri = f (v1 , v2 , . . . , vi1 , vi+1 , . . . , vn ) N

(4)

where, v1 < v2 < . . . < vn .
Proof:
part: ri takes form given equation (4), rebate agent
independent valuation. allocation rule satisfies allocative efficiency.
So, mechanism still Groves hence DSIC. rebate function defined
deterministic. two agents bids, then, per ordering defined
Appendix, <, ranking. Suppose agents + 1
bids. Thus vi < vi+1 vi+1 < vi . So, ri = f (v1 , v2 , . . . , vi1 , vi+1 , . . . , vn )
ri+1 = f (v1 , v2 , . . . , vi , vi+2 , . . . , vn ). Since vi = vi+1 , ri = ri+1 . Thus rebate
function anonymous.
part: mechanism strategyproof, rebate function
agent independent bid. So, ri depend vi . So,
deterministic rebate function, ri = fi (vi ). Now, desire anonymous rebate
function. is, rebate independent identity agent. Thus,
vi = vj , ri = rj . loss generality, say vi = vi+1 , vi =
v(i+1) . So, ri = ri+1 implies, fi = fi+1 . Similarly fi+1 = fi+2 on. Thus,
ri = f (vi ) N .

state prove main result paper.
Theorem 3 redistribution mechanism feasible individually rational,
cannot exist linear rebate function simultaneously satisfies following properties:
137

fiGujar & Narahari

DSIC
deterministic
anonymous
non-zero redistribution index.
Proof : Assume contrary exists linear function, say f , satisfies
properties. Let v1 < v2 < . . . < vn . according Theorem 2, agent
i,
ri = f (v1 , v2 , . . . , vi1 , vi+1 , . . . , vn )
= (c0 , ep ) + (c1 , v1 ) + . . . + (cn1 , vn )
where, ci = (ci1 , ci2 , . . . , cip ) Rp , ep = (1, 1, . . . , 1) Rp , (, ) denotes inner
product two vectors Rp . Now, show worst case performance f
zero. end, study structure f , step step.
Observation 1: Consider type profile (v1 , v2 , . . . , vn ) v1 = v2 = . . . = vn = (0, 0, . . . , 0).
type profile, total Clarke surplus zero ri = (c0 , ep ) N . Individual
rationality implies,
(c0 , ep ) 0
(5)
Feasibility implies total redistributed amount less surplus, is,
X
ri = n(c0 , ep ) 6 0

(6)



From, (5) (6), easy see that, (c0 , ep ) = 0.
Observation 2: Consider type profile (v1 , v2 , . . . , vn ) v1 = (1, 0, 0, . . . , 0) v2 =
. . . , vn = (0, 0, . . . , 0). type profile, r1 = 0 6= 1, ri = c11 0 individual
rationality. type profile, seen
straight forward calculations
P
Clarke surplus zero. Thus, feasibility, ri = (n 1)c11 = 0. implies,
c11 = 0.
profile, considering v1 = (0, 1, 0, . . . , 0), get c12 = 0. Similarly, one
show c13 = c14 = . . . = c1p = 0.
Observation 3: Continuing lines with, v1 = v2 = . . . = vi = ep ,
vi+1 = (1, 0 . . . , 0)
(0, 1, 0 . . . , 0), . . . (0, . . . , 0, 1), get, ci+1 = (0, 0, . . . , 0) p 1. Thus,

ri


: p + 1
(cp+1 , vp+2 ) + . . . + (cn1 , vn )
(cp+1 , vp+1 ) + . . . + (ci1 , vi1 )
=

+(ci , vi+1 ) + . . . + (cn1 , vn ) : otherwise

(7)

Thus rebate function linear redistribution mechanism necessarily
form Equation (7). claim redistribution index mechanism
138

fiRedistribution Mechanisms

zero. individually rational redistribution mechanism, trivial lower bound
redistribution index zero. prove linear redistribution mechanism,
exists type profile, fraction Clarke surplus gets redistributed
zero. Consider type profile:
v1
v2
..
.

= (2p 1, 2p 2, . . . , p + 1, p)
= (2p 2, 2p 3, . . . , p, p 1)

vp1 = (p + 1, p, . . . , 3, 2)
vp = (p, p 1, . . . , 2, 1)
vp+1 = vp+2 . . . = vn = (0, 0, . . . , 0).
seen, straightforward calculations Clarke payments, that,
type profile, agent 1 pays (p 1), agent 2 pays (p 2), . . . , agent (p 1) pays
1 remaining agents pay 0. Thus, Clarke payment received non-zero
seen ri = 0 agents. Hence, redistribution index linear
redistribution mechanism zero.

theorem provides disappointing piece news. rules possibility
linear redistribution mechanism heterogeneous settings non-zero
redistribution index. However, two ways get around it.
1. domain types Theorem 3 holds is, = Rp+ , N . One idea
restrict domain types. Section 4, design worst case optimal linear
redistribution mechanism valuations agents heterogeneous objects
certain type relationship.
2. Explore existence rebate function linear yields non-zero
redistribution index. explore Section 5.
noted impossibility result holds true defining linear
rebate functions Definition 4. result may hold types linearity.
example, sort bid components (n 1) agents define rebate function
linear combination (n 1)p elements. point, explored
linear rebate functions.

4. Redistribution Mechanism Heterogeneous Objects
Valuations Scaling Based Relationship
Consider scenario objects identical valuations objects
related derived single parameter. motivating example, consider
website people put ads free assume p
slots available advertisements n agents interested displaying ads.
Naturally, every agent higher preference higher slot. Another motivating
example could be, university web site p slots display news
139

fiGujar & Narahari

various departments. Define click rate slot number times ad
clicked, ad displayed slot, divided number impressions. Let
click rates slots 1 2 3 . . . p . Assume agent
value click user, say vi . So, agents value j th slot
j vi . Let us use phrase valuations scaling based relationship describe
valuations. define formally below.
Definition 6 say valuations agents scaling based relationship
exist positive real numbers 1 , 2 , 3 , . . . , p > 0 that, agent N , valuation object j, say j , form j = j vi , vi R+ private signal
observed agent i.
Without loss generality, assume, 1 2 3 . . . p > 0. (For simplifying
equations, assume (n p) virtual objects, p+1 = p+2 = . . . =
n = 0). immediately note homogeneous setting special case arises
1 = 2 = 3 = . . . = p > 0
setting, design Groves mechanism almost budget balanced
optimal worst case. mechanism similar Guo Conitzer (2009)
proof uses line arguments.
4.1 Proposed Mechanism
use linear rebate function. propose following mechanism:
agents submit bids.
bids sorted decreasing order.
highest bidder allotted first object, second highest bidder
allotted second object, on.
Agent pay ti ri , ti Clarke payment ri rebate.
ti =

p
X

(j j+1 )vj+1

j=i

Let agent rebate be,
ri = c0 + c1 v1 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vn
ci defined follows.
mechanism required individually rational feasible.
mechanism individually rational iff ri 0 N . is, N ,
c0 + c1 v1 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vn 0.

140

fiRedistribution Mechanisms

mechanism feasible
theP
total redistributed
payment less equal
P
P
surplus. is, ri = ti ri 0, where,
t=

p
X

j(j j+1 )vj+1 .

j=1

setup, derive c0 , c1 , . . . , cn1 maximize fraction
surplus redistributed among agents.
Step 1: First, claim c0 = c1 = 0. proved follows. Consider
type profile, v1 = v2 = . . . = vn = 0.
Pthis type profile, individual rationality implies
ri = c0 0 = 0. feasibility, ri = nc0 = 0. is, c0 zero.
Similarly, considering type profile v1 = 1, v2 = . . . = vn = 0, get c1 = 0.
Step 2: Using c0 = c1 = 0,
feasibility condition written as:
)
(
n1
X
(j 1)(j1 j ) (j 1)cj1 (n j)cj vj (n 1)cn1 vn 0

(8)

j=2

individual rationality condition written
c2 v2 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vn 0
Step 3: say mechanisms redistribution index e, mean,
is,
n1
X
j=2


e(j 1)(j1 j ) + (j 1)cj1 + (n j)cj vj +

(n 1)cn1 vn 0

(9)
P

ri

et,

(10)

Step 4: Define 1 = 1 2 , = 2, . . . , n 1, let = i(i i+1 ) + i1 . Now,
inequalities (8), (9), (10) satisfied values v1 v2 . . . vn 0.
Theorem (1), need satisfy following set inequalities:
Pj
i=2 ci 0 j = 2, . . . n 1
e (n 2)c2 1
Pi1 1
ei1 n j=2 cj + (n i)ci i1 = 3, . . . , p
P
ep n i1
p = p + 1, . . . , n 1
j=2 cj + (n i)c
Pn1
ep n j=2 cj p

Now, mechanism designer wishes design mechanism maximizes e subject
constraints.
P
Define xj = ji=2 ci j = 2, . . . , n 1. equivalent solving following
linear program.
141

fiGujar & Narahari

maximize e
s.t.
e1 (n 2)x2 1
ei1 ixi1 + (n i)xi i1 = 3, . . . , p
ep ixi1 + (n i)xi p = p + 1, . . . , n 1
ep nxn1 p
xi 0 = 2, . . . , n 1

(11)


So, given n p, social planner solve optimization problem
determine optimal values e, c2 , c3 , . . . , cn1 . would interest derive closed
form solution problem.
discussion summarized following theorem.
Theorem 4 valuations agents scaling based relationship, p
n > p + 1, linear redistribution mechanism obtained solving LP (11) worst case
optimal among Groves redistribution mechanisms feasible, individually rational,
deterministic, anonymous. mechanism example mechanism
non-zero redistribution index.
Proof:
worst case optimality mechanism proved following line arguments
Guo Conitzer (2009).
per impossibility Theorem 3, linear redistribution mechanism general heterogeneous setting non-zero efficiency. However, objects scaling
based relationship, linear redistribution mechanism, obtained solving LP (11)
non-zero efficiency least (n, p) instances. obtained actually solving
LP (for example, using MATLAB) various values n p. certainly proves
that, least n = 10, 12, 14, p = 2, 3, 4, . . . , 8 valuations scaling based
correlation, worst case optimal mechanism given LP (11) non-zero redistribution index. obtain upper bound redistribution index redistribution
mechanism LP (11).
Claim 1 e solution LP (11),


B

e min
,
B




P
P
n
n
.
B = i=2,4,6,... i1
where, = i=1,3,5,... i1


LP (11) written

maximize e
s.t.
e x
x0
142

fiRedistribution Mechanisms

x = (x2 , x3 , . . . , xn1 ) R+ n2 = (1 , 2 , . . . , p , p , . . . , p ) R+ n1


n2
0
0

0
3
n3
0

0



0
4
n

4



0


= .
..
..
..
..
..
.
.
.
.


0
n1 1
0
0
n
Now, = (y1 , y2 , . . . , yn1 ) Rn1 range iff








n
n
n
n
y1 +
y3 + =
y2 +
y4 +
2
4
3
5

(12)








n
n
n
Now,

(M x)i
{1, 2, 3, . . . , n 1}.

i+1
i+1
i+1
summing inequalities odd using (12), get e B summing
even get e B A. proves claim.
e


verified using MATLAB n = 10, 12, 14 p= 2, 3,
. . . 8, redistribution
B
index proposed mechanism fact, e = min B
,A .

5. Non-linear Redistribution Mechanisms Heterogeneous Setting

note homogeneous objects case special case heterogeneous
objects case bidder submits bid objects. Thus, cannot
expect redistribution mechanism perform better homogeneous objects case.
n p + 1, worst case redistribution zero homogeneous case
heterogeneous case (Guo & Conitzer, 2009; Moulin, 2009). So, assume
n > p + 1. section, propose two redistribution mechanisms non-linear rebate
functions. construct redistribution scheme applying mechanism proposed
Bailey (1997) heterogeneous settings. refer proposed mechanism
heterogeneous objects BAILEY-CAVALLO redistribution mechanism. crucial
note non-zero redistribution index BAILEY-CAVALLO mechanism
trivially follow mechanism work Bailey. rewrite WCO
mechanism extend rebate functions heterogeneous objects settings. call
mechanism HETERO.
mechanisms, namely BAILEY-CAVALLO HETERO, objects
assigned agents value most. Clarke payments collected
agents surplus redistributed among agents according rebate functions
defined mechanism. Hence, Groves redistribution mechanisms hence
DSIC.
stated above, n (p + 1), redistribution index redistribution mechanism zero. case n > p + 1, redistribution index linear
redistribution mechanism zero (Theorem 3). prove, n (2p + 1),
143

fiGujar & Narahari

BAILEY-CAVALLO non-zero redistribution index. conjecture HETERO
worst case optimal, mechanism better redistribution index HETERO. also conjecture HETEROs redistribution index WCO,
non-zero n > (p + 1). Thus, n {p + 2, p + 3, . . . , 2p}, still
redistribution mechanism non-zero redistribution index proved.
5.1 BAILEY-CAVALLO Mechanism
First, consider case p = 1. Let valuations agents object be,
v1 v2 . . . vn . agent highest valuation receive object would
pay second highest bid. Cavallo (2006) proposed rebate function as:
r1 = r2 = n1 v3
ri = n1 v2 > 2
similar mechanism independently proposed Porter et al (2004). Motivated
scheme, propose scheme heterogeneous setting. Suppose agent excluded
system. let ti Clarke surplus system (defined Table 1).
Define,
1
ri B = ti N
(13)
n
Clarke surplus always positive, ri B 0 i. Thus, scheme satisfies
individual rationality.
P 1
P B
n n1 = t. Thus,
=
ti (revenue monotonicity). So,
nt
ri
scheme feasible. (The revenue monotonicity follows fact
valuations non-negative unit demand preferences. Gul Stacchetti (1999)
showed unit demand preferences, VCG payments coinside
smallest Walrasian prices turn would decrease addition agent.
Thus addition agent cannot decrease total payments.)2
show BAILEY-CAVALLO scheme non-zero redistribution index
n 2p + 1. First state two lemmas. proof given Appendix B.
lemmas useful designing redistribution mechanisms heterogeneous settings
well analysis mechanisms. Lemma 2 used show redistribution index
BAILEY-CAVALLO mechanism non-zero. Lemma 1 used find allocatively
efficient outcome settings consideration. Lemma 1 also useful determining
Clarke payments.
Lemma 1 sort bids agents object, then:
1. optimal allocation, allocatively efficient allocation, consist
agents bids among p highest bids object.
2. Consider optimal allocation k . p agents receiving objects k
optimal allocation (on
dropped, always exists allocation ki
2. thank annonymous reviewer pointing reference.

144

fiRedistribution Mechanisms

remaining n 1 agents) allocates objects remaining (p 1) agents.
, may however
objects (p 1) agents receive ki
objects allocated k .
Lemma 2 2p agents involved deciding Clarke payment.
Note: objects identical, bids (p + 1) agents involved determining Clarke payments.
Now, show redistribution index BAILEY-CAVALLO mechanism
non-zero.
Theorem 5 sufficient number agents (in particular, n > 2p),
BAILEY-CAVALLO redistribution mechanism non-zero redistribution index.
Proof: Lemma 2, shown 2p agents involved
determining Clarke surplus. Thus, given type profile, (n 2p) agents,
whom, ti = implies least n2p
n redistributed.
redistribution index mechanism least n2p
n > 0.

Note mechanism may worst case optimal. because,
objects identical, WCO mechanism performs better worst case analysis
mechanism. So, suspect heterogeneous settings well,
mechanism would optimal worst case analysis. next subsection, explore
another rebate function, namely HETERO.
5.2 HETERO: Redistribution Mechanism Heterogeneous Setting
objects identical, WCO mechanism given equation (3). give
novel interpretation it. Consider scenario one agent absent
scene. Clarke payment received either pvp+1 pvp+2 depending upon
agent absent. remove two agents, surplus pvp+1 pvp+2 pvp+3 , depending
upon two agents removed. Till (n p 1) agents removed, get non-zero
surplus. remove (n p) agents system, need
mechanism assignment objects. So, consider cases remove k
agents, where, 1 k < n p.
let ti,k average payment received agent removed along k
agents is, total (k + 1) agents removed comprising i. average
taken possible selections k agents remaining (n 1) agents.
rewrite WCO mechanism terms ti , ti,k . Observe that, ti , ti,k defined
heterogeneous settings well. propose use rebate function defined as,
riH

= 1



+

k=np1
X

k ti,k1

(14)

k=2

k suitable weights assigned surplus generated total k
agents removed system. using different k s, get different mechanisms.
However, prefer choose k following.
145

fiGujar & Narahari

5.2.1 Equivalence HETERO WCO Objects Identical
desirable HETERO match WCO mechanism objects
homogeneous. choose Equation (14) way ensures that,
objects identical, riH equation (14) equal riW CO equation (3)
type profiles. Since rebate function remaining (n 1) bids, write
as, ri = f (x1 , x2 , . . . , xn1 ) x1 , x2 , . . . , xn1 bids without agent i,
decreasing order. Note, case, bidder submitting bid bi R+ .
Now, write, ti,k , riH , ri terms x1 , x2 , . . . , xn1 , as,



p+l
np2l
k1
X
p
k1l
i,k1



=
xp+1+l
n1
l=0
k1
riH

=

riW CO =

k=np1
X

k=1
np1
X

k ti,k1

(15)

cp+1+l xp+1+l

(16)

l=0

where, ci , = p + 1, p + 2, . . . , n 1 given equation (2).
Consider type profile (x1 = 1, x2 = 1, . . . , xp+1 = 1, xp+2 = 0, . . . , xn1 = 0).
HETERO agree WCO, coefficients xp+1 equation (15) equation (16)
same. consider type profile (x1 = 1, x2 = 1, . . . , xp+2 = 1, xp+3 =
0, . . . , xn1 = 0). coefficients xp+1 equation (15) equation (16)
same, coefficients xp+2 also equal equation (15) equation (16).
Thus, coefficients xp+1 , xp+2 , . . . , xn1 equation (15) equation (16)
agree.
Let L = n p 1. Thus, = p + 1, . . . , n 1,



i1
ni1
ni1
X
p
k


Lk
ci =
(17)
n

1
k=0
p+1+k
system equations yields, = 1, 2, . . . , L,



n1

Li
(i+1)
X
X
(1)
(L i)!p!
i+j1
n1
=

j
l


(n i)!
j=0

given by, =



n1
p1



n1
j

(np)

Pn1
j=p



l=p+i+j




.


146

(18)

fiRedistribution Mechanisms

5.2.2 Properties HETERO
HETERO mechanism matches WCO objects identical, HETERO mechanism satisfies individual rationality feasibility homogeneous case.
two properties, however, remain shown heterogeneous case.
Conjecture 1 HETERO mechanism satisfies individual rationality, feasibility, worst
case optimal, redistribution index WCO.
5.2.3 Intuition Behind Individual Rationality HETERO
show agent i, riH 0 type profiles. convenience,

i,j1 , j = 2, . . . , L.
assume implicitly. So, say, riH = r
P 1 = , j =
Now, rebate given equation, r =
j j j . show r 0.
Note that, 1 2 . . . L 0. monotone absence
agents
would either decrease VCG payments payments remain same. So,
Pj

i=1 0 j = 1 L, individual rationality would follow Theorem 1. observe
that, general, true. important observation is, though decreasing
positive real numbers, related. example, show 1 > 0,
2 > 0. experiments, describe next section, keep track 12 .
observed ratio [0.5, 1]. Theorem 1 applicable, ratio
value [0, 1].
Thus, though alternately positive negative, relation among would
make r become negative within limits way total rebate
agents less equal total Clarke payment. remains show individual
rationality analytically general case. are, however, able show
following cases.
1. Consider case p = 2. (i). n = 4, 1 = 14 . (ii). n = 5, 1 = 0.27273,
2 = 0.18182. (iii). n = 6, 1 = 0.29487, 2 = 0.25641, 3 = 0.12821.
2. Consider case p = 3. (i). n = 5, 1 = 15 . (ii). n = 6, 1 = 0.21875,
2 = 0.15625. (iii). n = 7, 1 = 0.23810, 2 = 0.21429, 3 = 0.11905.
Theorem 1, follows cases, proposed mechanism satisfies individual rationality.
5.2.4 Feasibility Worst Case Optimality HETERO
Similarly, also believe that, adjust rebate functions optimally that, HETERO remains feasible worst case optimal redistribution index
WCO. Though analytical proof, provide empirical evidence
conjecture Section 6.

6. Experimental Analysis
perform experiments two sets. first set, consider bids real numbers.
second set consider bidders submitting binary bids. use experiments
provide empirical evidance Conjecture 1.
147

fiGujar & Narahari

6.1 Empirical Evidence Individual Rationality HETERO
Solving equations (18) challenging task. Though new mechanism extension
Moulin WCO mechanism, yet, able prove individual rationality
feasibility HETERO analytically. therefore seek empirical evidence.
6.1.1 Simulation 1
consider various combinations n p. agent, object,
valuation generated uniform random variable [0, 100]. run simulations
following combinations n p.
p = 2, n = 5, 6, . . . , 14, p = 3, n = 7, 8, . . . , 14 p = 4, n = 9, 10, . . . , 14.
combination n p = 2, generated randomly 100,000 bid profiles evaluated mechanism. also kept track worst case performance mechanism
100,000 bid profiles. mechanism feasible individually rational
100,000 bid profiles. redistribution index mechanism upper bounded
WCO mechanism. observed worst case performance
100,000 random bid profiles WCO. strong indication
mechanism perform well general.
6.1.2 Simulation 2: Bidders Binary Valuation
Suppose bidder valuation object, either 0 1. 2np possible
bid profiles. ran experiment evaluate mechanism possible bid profiles
agents binary valuations. considered p = 2 n = 5, 6, . . . , 12. found
mechanism feasible, individually rational, worst case performance
WCO mechanism. Note, indicated earlier, mechanism perform
better WCO mechanism worst case. mechanism performs equally
well WCO. Thus, though analytical proof elusive, binary valuation settings,
p = 2 n = 5, 6, . . . , 12, mechanism worst case optimal.
6.2 BAILEY-CAVALLO vs HETERO
subsection, compare worst case redistribution index BAILEY-CAVALLO
worst case redistribution index HETERO varying number objects
10 agents system. is, study worst case redistribution index
various p n = 10. worst case taken randomly generated 50K bid profiles.
comparison depicted Figure 1. redistribution index WCO upper bound
Redistribution Mechanism heterogeneous settings. However, simulations
exhaustive, worst case performance mechanisms could perhaps better
WCO. Exact worst case may worse WCO. However, simulations,
never encountered situation HETERO worse WCO. see
Figure 1 BAILEY-CAVALLO mechanisms worst case performance better
HETERO, p = 3, 4, 5, 6, 7. worst case worst 50,000 randomly generated
bid profiles simulations.

148

fiRedistribution Mechanisms

observation made simulations time (70%),
BAILEY-CAVALLO redistributes VCG surplus HETERO ever though worst
case performance worse HETERO.
observations also lead question Cavallo (2008) raised context
dynamic redistribution mechanisms. really need highly sophisticated mechanism,
worst case optimal, simple mechanism performs quite well general.

1

0.9

HETERO
BAILEYCAVELLO
WCO

0.8

redistribution index

0.7

0.6

n = 10

0.5

0.4

0.3

0.2

0.1

0

2

3

4

5
Number objects, (p)

6

7

8

Figure 1: Redistribution index vs number objects number agents = 10

7. Conclusion
addressed problem assigning p heterogeneous objects among n > p competing
agents. valuations agents independent valuations object independent valuations objects, proved
impossibility existence linear redistribution mechanism non-zero redistribution
index (Theorem 3). explored two approaches get around impossibility.
first approach, showed linear rebate functions non-zero redistribution index possible valuations objects scaling based
relationship. settings, proposed strategyproof linear redistribution
mechanism optimal worst case analysis, individually rational, feasible
(Theorem 4).

149

fiGujar & Narahari

second approach, relaxed linearity requirement. showed nonlinear rebate functions non-zero redistribution index possible applying
BAILEY-CAVALLO mechanism settings (Theorem 5).
proposed mechanism, namely HETERO, general settings objects
heterogeneous private values agent objects independent
other. mechanism deterministic, anonymous, DSIC. HETERO
mechanism extends Moulin /WCO mechanism. Though analytically
proved feasibility individual rationality, sufficient empirical evidence
conjecture mechanism feasible individually rational (Conjecture 1).
would interesting see characterize situations linear redistribution mechanisms non-zero redistribution indices possible heterogeneous
settings.
interesting research direction investigate individual rationality feasibility
proposed HETERO mechanism. Also, strongly believe mechanism
worst case optimal. immediate future direction prove fact design
mechanism worst case optimal.
Another interesting problem explore characterize redistribution mechanisms
worst case optimal heterogeneous settings.

Acknowledgments
first author would like acknowledge Infosys Technologies Ltd., awarding Infosys
fellowship pursue Ph.D. authors would like thank Professor David Parkes
useful comments. authors would also like thank anonymous reviewers, whose
feedback helped lot improving paper.

Appendix A. Ordering Agents Based Bid Profiles
define ranking among agents. ranking used proving Theorem
2 rebate function. theorem similar Cavallos theorem characterization
DSIC, deterministic, anonymous rebate functions homogeneous objects. would
actually computing order among bidders. use order proving
impossibility linear rebate function desired properties.
A.1 Properties Ranking System
defining ranking/ordering among agents, expect following properties
hold true:
permutation objects corresponding permutation bid vector,(bi1 , bi2 ,
. . . , bi p ) agent i, change ranking. is, ranking
independent order agents expected bid objects.
Two bidders bid vectors rank.
increasing bid objects, rank agent decrease.
150

fiRedistribution Mechanisms

A.2 Ranking among Agents
crucial step. First, find feasible allocations p objects among
n agents, agent receiving one object. Sort allocations, according
valuation allocation. Call list L. find ranking j, uses
following algorithm.
1. Lij = L
2. Delete allocations Lij contain j.
3. Find first allocation Lij contains one agent j. Say k .
(a) Suppose allocation contains value strictly greater
remaining allocations Lij containing j, say, j.
(b) Suppose allocation contains j value strictly greater
remaining allocations Lij containing i, say, j i.
4. step able decide ordering j, let = {k
K|v(k) = v(k )}. Update Lij = Lij \ recur step (2) till EITHER
allocation containing agent j
ordering j decided.
5. steps give either j j i, say, j < j well
j < i.
state properties ranking system <, explain
example. Let two items B, four bidders. is, p = 2, n = 4 let
bids be: b1 = (4, 5), b2 = (2, 1), b3 = (1, 4), b4 = (1, 0).
Now, allocation (A = 1, B = 3) highest valuation among allocations. So,
agent
agent
agent
agent

1
1
3
3

agent
agent
agent
agent

2
4
2
4

Now, L13 defined procedure above, allocation (A = 2, B = 1) strictly
higher value allocation agent 3 present. So,
agent 1 agent 3.
Thus,
agent 1 agent 3 agent 2
agent 1 agent 3 agent 4
L24 , allocation (A = 2, B = 1) strictly higher value allocation
agent 4 present. Thus, ranking agents is,
agent 1 agent 3 agent 2 agent 4
seen ranking defined above, satisfies following properties.
151

fiGujar & Narahari

1. < defines total order set bids.
2. < independent order objects.
3. two bids same, equivalent order.
4. increasing bid, agent decrease rank.
agent < agent j, also say vi < vj .

Appendix B. Proofs
B.1 Proof Lemma 1
Suppose optimal allocation contains agent whose bid winning object,
say j, top p bids j th object. (p 1) winners
optimal allocation. So, exists least one agent whose bid top
p bids j th object win object. Thus, allocating j th
object, allocation higher valuation declared optimal
allocation.
Suppose agent receives object optimal allocation removed
system. agent one bid top p bids object. So,
agents bids top p bids, pth position. seen
one agent optimal allocation pth position
object wins. one agent optimal allocation
pth position object win, improve allocation. Hence,
removing i, one agent part new
optimal allocation.

B.2 Proof Lemma 2
argument follows.
1. Sort bids agents object.
2. optimal allocation consists agents bids p highest bids
objects (Lemma 1).
3. computing Clarke payment agent i, remove agent determine
optimal allocation. And, using bid, valuation optimal allocation
without determine payment. done agent i.
per Lemma 1, agent optimal allocation removed system,
exists new optimal allocation consists least (p 1) agents
received objects original optimal allocation.

152

fiRedistribution Mechanisms

4. p agents receiving objects determining payments
involve removing one time, p agents
influence payment. Thus, 2p agents involved determining
Clarke payment.


References
Bailey, M. J. (1997). demand revealing process: distribute surplus. Public
Choice, 91 (2), 10726.
Cavallo, R. (2006). Optimal decision-making minimal waste: strategyproof redistribution VCG payments. AAMAS 06: Proceedings Fifth International Joint
Conference Autonomous Agents Multiagent Systems, pp. 882889, New York,
NY, USA. ACM.
Cavallo, R. (2008). Efficiency redistribution dynamic mechanism design. EC 08:
Proceedings 9th ACM conference Electronic commerce, pp. 220229, New
York, NY, USA. ACM.
Clarke, E. (1971). Multi-part pricing public goods. Public Choice, 11, 1723.
de Clippel, G., Naroditskiy, V., & Greenwald, A. (2009). Destroy save. EC 09:
Proceedings tenth ACM conference Electronic commerce, pp. 207214, New
York, NY, USA. ACM.
Faltings, B. (2005). budget-balanced, incentive-compatible scheme social choice.
Agent-Mediated Electronic Commerce, AMEC, pp. 3043. Springer.
Green, J. R., & Laffont, J. J. (1979). Incentives Public Decision Making. North-Holland
Publishing Company, Amsterdam.
Groves, T. (1973). Incentives teams. Econometrica, 41, 617631.
Gujar, S., & Narahari, Y. (2009). Redistribution mechanisms assignment heterogeneous objects. Formal Approaches Multi-Agent Systems, (FAMAS09), Vol. 494
CEUR Workshop Proceedings. CEUR-WS.org.
Gujar, S., & Narahari, Y. (2008). Redistribution VCG payments assignment heterogeneous objects. Papadimitriou, C. H., & Zhang, S. (Eds.), WINE, Vol. 5385
Lecture Notes Computer Science, pp. 438445. Springer.
Gul, F., & Stacchetti, E. (1999). Walrasian equilibrium gross substitutes. Journal
Economic Theory, 87 (1), 95124.
Guo, M., & Conitzer, V. (2007). Worst-case optimal redistribution VCG payments.
EC 07: Proceedings 8th ACM conference Electronic Commerce, pp. 3039,
New York, NY, USA. ACM.
Guo, M., & Conitzer, V. (2008a). Better redistribution inefficient allocation multiunit auctions unit demand. EC 08: Proceedings 9th ACM conference
Electronic commerce, pp. 210219, New York, NY, USA. ACM.

153

fiGujar & Narahari

Guo, M., & Conitzer, V. (2008b). Optimal-in-expectation redistribution mechanisms.
AAMAS 08: Proceedings 7th international joint conference Autonomous
agents multiagent systems, pp. 10471054, Richland, SC. International Foundation
Autonomous Agents Multiagent Systems.
Guo, M., & Conitzer, V. (2009). Worst-case optimal redistribution vcg payments
multi-unit auctions. Games Economic Behavior, 67 (1), 6998.
Laffont, J., & Maskin, E. (1979). differential approach expected utility maximizing
mechanisms. Laffont, J. J. (Ed.), Aggregation Revelation Preferences.
Moulin, H. (2009). Almost budget-balanced VCG mechanisms assign multiple objects.
Journal Economic Theory, 144, 96119.
Porter, R., Shoham, Y., & Tennenholtz, M. (2004). Fair imposition. Journal Economic
Theory, 118 (2), 209228.
Vickrey, W. (1961). Counterspeculation, auctions, competitive sealed tenders. Journal
Finance, 16 (1), 837.

154

fiJournal Artificial Intelligence Research 41 (2011) 367395

Submitted 03/2011; published 07/2011

Opposite Smoothing: Language Model Approach
Ranking Query-Specific Document Clusters
Oren Kurland
Eyal Krikon

kurland@ie.technion.ac.il
krikon@tx.technion.ac.il

Faculty Industrial Engineering Management
Technion Israel Institute Technology

Abstract
Exploiting information induced (query-specific) clustering top-retrieved documents long proposed means improving precision top ranks
returned results. present novel language model approach ranking query-specic
clusters presumed percentage relevant documents contain.
previous cluster ranking approaches focus cluster whole, model utilizes
also information induced documents associated cluster. model substantially outperforms previous approaches identifying clusters containing high relevantdocument percentage. Furthermore, using model produce document ranking yields
precision-at-top-ranks performance consistently better initial ranking upon clustering performed. performance also favorably compares
state-of-the-art pseudo-feedback-based retrieval method.

1. Introduction
Users search engines want see results pertaining queries highest
ranks returned document lists. However, attaining high precision top ranks still
dicult challenge search engines cope various (types of) queries
(Buckley, 2004; Harman & Buckley, 2004).
High precision top ranks also important applications rely search
intermediate step; example, question answering systems (Voorhees, 2002; CollinsThompson, Callan, Terra, & Clarke, 2004). systems provide answer
users query rather return list documents. Often, question answering systems
employ search given document corpus using question hand query
(Voorhees, 2002). Then, passages highest ranked documents analyzed extracting (compiling) answer question. Hence, important documents
contain question-pertaining information.
cope fact search engine often return highest ranks
result list quite documents relevant users query, researchers
proposed, among others, cluster-based result interfaces (Hearst & Pedersen, 1996; Leuski,
2001). is, documents initially highest ranked clustered clusters
similar documents. Then, user potentially exploit clustering information
quickly locate relevant documents initial result list. important question
devising cluster-based result interfaces order present clusters
users (Leuski, 2001). order potentially reect presumed percentage
relevant documents clusters.
c
2011
AI Access Foundation. rights reserved.

fiKurland & Krikon

Clusters top-retrieved documents (a.k.a. query-specific clusters) also utilized
without user (or application uses search intermediate step) aware
clustering performed. Indeed, researchers proposed using information
induced clusters automatically re-rank initially retrieved list improve precision top ranks (Preece, 1973; Willett, 1985; Hearst & Pedersen, 1996; Liu &
Croft, 2004; Kurland & Lee, 2006; Yang, Ji, Zhou, Nie, & Xiao, 2006; Liu & Croft, 2008).
Much motivation employing clustering top-retrieved documents comes van
Rijsbergens cluster hypothesis (van Rijsbergen, 1979), states closely associated
documents tend relevant requests. Indeed, shown applying
various clustering techniques documents highly ranked initial search
produces clusters contain high percentage relevant documents (Hearst
& Pedersen, 1996; Tombros, Villa, & van Rijsbergen, 2002; Kurland, 2006; Liu & Croft,
2006a). Moreover, positioning clusters constituent documents top ranks
returned results yields precision-at-top-ranks performance substantially better state-of-the-art document-based retrieval approaches (Hearst & Pedersen,
1996; Tombros et al., 2002; Kurland, 2006).
Thus, whether used creating eective result interfaces automatic re-ranking
search results, whether utilized help serve users search engines applications
rely search, query-specic clustering (i.e., clustering top-retrieved documents)
result much merit. Yet, long standing challenge progress yield
substantial retrieval eectiveness improvements state-of-the-art retrieval approaches
show ability identify query-specic clusters contain high percentage
documents relevant query.
present novel language-model-based approach ranking query-specic clusters
presumed percentage relevant documents contain. key insight
guides derivation cluster-ranking model documents strongly
associated cluster serve proxies ranking it. Since documents
considered focused units clusters, serve, example, mediators
estimating cluster-query match. Thus, previous approaches ranking
various types clusters focus cluster whole unit (Jardine & van Rijsbergen,
1971; Croft, 1980; Voorhees, 1985; Willett, 1985; Kurland & Lee, 2004; Liu & Croft,
2004, 2006b), model integrates whole-cluster-based information induced
documents associated cluster. Hence, conceptually take opposite approach
cluster-based smoothing document language models recently
proposed document ranking (Azzopardi, Girolami, & van Rijsbergen, 2004; Kurland &
Lee, 2004; Liu & Croft, 2004; Tao, Wang, Mei, & Zhai, 2006; Wei & Croft, 2006);
is, using cluster-based information enrich document representation purpose
document ranking.
model integrates two types information induced clusters proxy
(associated) documents. rst estimated similarity query. second
centrality element (document cluster) respect reference set (documents
initially-retrieved list clusters documents); centrality dened terms
textual similarity central elements reference set (Kurland & Lee, 2005).
Using either, both, types information described induced cluster
whole and/or proxy documents yields several novel cluster ranking criteria
368

fiA Language Model Approach Ranking Query-Specific Document Clusters

LM
Relevance model
Optimal cluster

AP
45.7
50.3
79.6

TREC8
50.0
54.4
83.6

WSJ
53.6
58.8
81.5

WT10G
33.9
35.7
65.9

Table 1: resultant p@5 performance nding optimal cluster comparison
initial LM-based ranking upon clustering performed,
optimized relevance model.

integrated model. study relative contribution criteria
overall eectiveness approach. Furthermore, show previously proposed
cluster ranking methods, developed independently, derived explained
using ranking framework.
Empirical evaluation shows cluster ranking model consistently substantially
outperforms previously proposed methods identifying clusters contain high percentage relevant documents. Furthermore, positioning constituent documents
cluster highly ranked model top list results yields precision-attop-ranks performance substantially better initial document ranking
upon clustering performed. resultant performance also favorably compares
state-of-the-art pseudo-feedback-based document retrieval method; and,
approaches utilize inter-document similarities (e.g., using clusters) directly
(re-)rank documents.

2. Motivation
rst start demonstrating performance merits ability eectively rank
query-specic clusters presumed percentage relevant documents contain.
Suppose initial list documents retrieved response
query using standard language model (LM) approach (Ponte & Croft, 1998; Laerty &
Zhai, 2001). Suppose also clustering algorithm used cluster 50 highest
ranked documents, resultant clusters contain 5 documents each. (Specic
details experimental setup provided Section 5.2.) dene optimal cluster
one contains highest percentage relevant documents. position
constituent documents cluster rst ranks document list returned
response query, resultant precision 5 (p@5) performance percentage
relevant documents cluster. contrast p@5 performance
initial LM-based ranking. additional reference comparison use optimized
relevance model, RM3, state-of-the-art pseudo-feedback-based query expansion
approach (Lavrenko & Croft, 2001; Abdul-Jaleel et al., 2004). performance numbers
four TREC corpora presented Table 1. (Details regarding corpora queries
used provided Section 5.2.)
message rising Table 1 clear. able automatically identify
optimal cluster, resultant performance would much better
initial LM-based ranking upon clustering performed. Furthermore,
369

fiKurland & Krikon

performance also substantially better state-of-the-art retrieval approach.
Similar conclusions echoed previous work using clusters top-retrieved documents (Hearst & Pedersen, 1996; Tombros et al., 2002; Crestani & Wu, 2006; Kurland,
2006; Liu & Croft, 2006a; Kurland & Domshlak, 2008).

3. Ranking Framework
Throughout section assume following xed: query q, corpus
N (henceforth
documents D, initial list N documents Dinit
init )
highest ranked search performed response q. assume Dinit clustered
set document clusters C l(Dinit ) = {c1 , . . . , cM } clustering algorithm1 .
goal rank clusters C l(Dinit ) presumed percentage relevant documents
contain. follows use term cluster refer either set
documents composed of, (language) model induced it. use py (x)
denote language-model-based similarity (a document cluster) x (a
query cluster); describe language-model induction method Section 5.1.
3.1 Cluster Ranking
Similarly language model approach ranking documents (Ponte & Croft, 1998;
Croft & Laerty, 2003), deference recent growing interest automatically
labeling document clusters topic models (Geraci, Pellegrini, Maggini, & Sebastiani,
2006; Treeratpituk & Callan, 2006; Mei, Shen, & Zhai, 2007), state problem
ranking clusters follows: estimate probability p(c|q) cluster c labeled
(i.e., content described) terms q. hypothesize higher
probability is, higher percentage documents pertaining q c contains.
Since q xed, use rank equivalence
rank

p(c|q) = p(q|c) p(c)
rank clusters C l(Dinit ). Thus, c ranked combining probability p(q|c)
q generated2 label c cs prior probability (p(c)) generating label.
Indeed, prior work ranking various types clusters (Jardine & van Rijsbergen,
1971; Croft, 1980; Willett, 1985; Voorhees, 1985; Kurland & Lee, 2004; Liu & Croft, 2004)
implicitly uses uniform distribution p(c), estimates p(q|c) (in spirit) comparing
representation c whole unit q.
Here, suggest incorporate document mediated approach estimating probability p(q|c) generating label q cluster c. Since documents considered
coherent units clusters, might help generate informative/focused
labels generated using representations clusters whole units.
1. Clustering documents highly ranked search performed response query often termed
query-specific clustering (Willett, 1985). assume, however, clustering algorithm
knowledge query hand.
2. term generate convenient, assume clusters documents literally generate
labels, assume underlying generative theory presented Lavrenko Croft (2001)
Lavrenko (2004), inter alia.

370

fiA Language Model Approach Ranking Query-Specific Document Clusters

approach conceptually opposite smoothing document representation (e.g., language model) cluster (Azzopardi et al., 2004; Kurland & Lee, 2004; Liu &
Croft, 2004; Wei & Croft, 2006). follows use p(q|d) denote probability
q generated label describing document ds content cf., language modeling approach ranking documents (Ponte & Croft, 1998; Croft & Laerty, 2003). Also,
assume p(d) prior probability document generates label
probability distribution documents corpus D.
let all, only, documents corpus serve proxies label generation
cluster C l(Dinit ). Consequently, assume p(d|c), probability
chosen proxy c label generation, probability distribution dened
documents D. Then, write using probability algebra
rank

p(c|q) = p(c)

X

p(q|c, di )p(di |c).

(1)

di

use p(q|c) + (1 )p(q|di ), free parameter, estimate p(q|c, di )
(Si, Jin, Callan, & Ogilvie, 2002; Kurland & Lee, 2004) Equation 1, applying
probability algebra get following scoring principle3 clusters
p(c)p(q|c) + (1 )

X

p(q|di )p(c|di )p(di ).

(2)

di

Equation 2 scores c mixture (i) probability q directly generated c
combined cs prior probability generating label, (ii) (average) probability
q generated documents strongly associated c (as measured
p(c|di )) high prior probability p(di ) generating labels.
next derive specic ranking algorithms Equation 2 making assumptions
estimation choices.
3.2 Algorithms
rst make assumption, underlies (in spirit) pseudo-feedback-based retrieval models (Buckley, Salton, Allan, & Singhal, 1994; Xu & Croft, 1996; Lavrenko &
Croft, 2003), probability generating q directly di (p(q|di )) quite small
documents di initially retrieved list Dinit ; hence, documents
relatively little eect summation Equation 2. Furthermore, clusters
C l(Dinit ) produced reasonable clustering algorithm, p(c|di ) clusterdocument association strength might assumed signicantly higher documents
Dinit c documents Dinit c. Consequently,
truncate summation Equation 2 allowing cs constituent documents serve
proxies generating q. truncation alleviate computational
cost estimating Equation 2, also yield improved eectiveness show Section 5.3. addition, follow common practice language model framework (Croft
rank

3. shift notation terminology p(c|q) = score c echoes transition using
(model) probabilities estimates probabilities.

371

fiKurland & Krikon

& Laerty, 2003), specically, work utilizing cluster-based language models document retrieval (Liu & Croft, 2004; Kurland & Lee, 2004), use language-model estimates
conditional probabilities produce primary ranking principle:
def

core(c) = p(c)pc (q) + (1 )

X

pdi (q)pdi (c)p(di ).

(3)

di c

Note using pd (c) p(c|d) means use probability generating label c
(i.e., term-based representation c) document surrogate documentcluster association strength.
remaining task estimate document cluster priors, p(d) p(c), respectively.
3.2.1 Document cluster biases
Following common practice work language-model-based retrieval use uniform distribution document prior p(d) (Croft & Laerty, 2003), similarly assume
uniform distribution cluster prior p(c). practice would natural choice clusters want rank produced query-independent fashion.
However, would like exploit fact clusters C l(Dinit ) composed
documents initially retrieved list Dinit . case point, since Dinit retrieved
response q, documents Dinit considered reecting Dinit content might
good candidates generating label q (Kurland & Lee, 2005); similar argument
made clusters C l(Dinit ) reect content. Therefore, instead using true
prior distributions, use biases represent centrality (Kurland & Lee, 2005)
documents respect Dinit centrality clusters respect C l(Dinit ).4
adopt recently proposed approach inducing document centrality based
measuring similarity document Dinit central documents Dinit (Kurland & Lee, 2005). quantify recursive centrality denition, compute PageRanks
(Brin & Page, 1998) stationary distribution graph wherein vertices represent documents Dinit edge-weights represent inter-document language-model-based similarities
def

(Kurland & Lee, 2005). set p(d) = Cent(d) Dinit 0 otherwise,
Cent(d) ds PageRank score; hence, p(d) probability distribution entire
corpus D.
def

Analogously, set p(c) = Cent(c) c C l(Dinit ), Cent(c) cs PageRank
score computed graph wherein vertices clusters C l(Dinit ) edge-weights
represent language-model-based inter-cluster similarities; therefore, p(c) probability distribution given set clusters C l(Dinit ). construction method document
cluster graphs follows constructing document-solely graphs (Kurland & Lee,
2005), elaborated Appendix A.
Using document cluster induced biases fully instantiate Equation 3
derive ClustRanker, primary cluster ranking algorithm:
4. biases true prior distributions, virtue Dinit created, is,
response query. However, take care biases form valid probability distributions
show later.

372

fiA Language Model Approach Ranking Query-Specific Document Clusters

Algorithm
ClustCent
ClustQueryGen
ClustCent ClustQueryGen
DocCent
DocQueryGen
DocCent DocQueryGen
ClustCent DocCent
ClustQueryGen DocQueryGen
ClustRanker

Scoring function (S core(c))
Cent(c)
pc (q)
Cent(c)p
c (q)
P
p

Pdi c (c)Cent(di )
Pdi c pdi (q)pdi (c)
i)
di c pdi (q)pdi (c)Cent(d
P
Cent(c) + (1 P
) di c pdi (c)Cent(di )
pc (q) + (1 ) di c pdi (q)pdi (c)
P
Cent(c)pc (q) + (1 ) di c pdi (q)pdi (c)Cent(di )

Table 2: Summary methods ranking clusters.

def

coreClustRanker (c) = Cent(c)pc (q) + (1 )

X

pdi (q)pdi (c)Cent(di ).

(4)

di c

3.2.2 Methods ranking clusters
ClustRanker algorithm ranks cluster c integrating several criteria: (i) ClustCent
cs centrality (Cent(c)), (ii) ClustQueryGen possibility generate label
q directly c measured pc (q), (iii) DocCent centrality cs constituent
documents (Cent(d)), (iv) DocQueryGen possibility generate q cs
constituent documents measured pd (q). (Note latter two combined
cluster-document association strength, pd (c)).
study eectiveness criteria (and combinations)
ranking clusters, apply following manipulations ClustRanker algorithm:
(i) setting 1 (0) cluster (documents) generate q, (ii) using uniform
distribution Cent(c) (over C l(Dinit )) and/or Cent(d) (over Dinit ) hence assuming
clusters C l(Dinit ) and/or documents Dinit central extent; assume
number clusters C l(Dinit ) number documents Dinit ,
case clustering method employ Section 5; hence, document
uniform prior cluster uniform prior same; (iv) setting pc (q) (pd (q))
constant value thereby assuming clusters C l(Dinit ) (documents
Dinit ) probability directly generating q same. instance, setting 0
pd (q) constant, rank c byPDocCent weighted-average centrality
values constituent documents:
di c pdi (c)Cent(di ). Table 2 presents resultant
cluster ranking methods explore. ( indicates method utilizes two criteria.)
3.3 Explaining Previous Methods Ranking Clusters
ClustRanker method, generally, Equation 3 based, used
help explain, derive, previously proposed methods ranking clusters.
methods developed independently, part single framework,
foundations described terms approach. following discussion
use uniform prior documents clusters, rank cluster c, using Equation 3,
373

fiKurland & Krikon

P
pc (q)+(1) di c pdi (q)pdi (c). Furthermore, recall framework committed
language models; i.e., px (y), language-model-based estimate p(y|x),
replaced another estimate.
Now, setting = 1, consequently considering cluster whole unit, yields
common cluster ranking method. is, ranking cluster based match
representation whole unit query; cluster represented,
example, using concatenation constituent documents (Kurland & Lee,
2004; Liu & Croft, 2004) centroid-based representation constituent document
representations (Voorhees, 1985; Leuski, 2001; Liu & Croft, 2008). ClustQueryGen
method Table 2, also used previous work (Liu & Croft, 2004; Kurland
& Lee, 2004; Liu & Croft, 2006b; Kurland & Lee, 2006), example approach
language modeling framework.
hand, setting = 0 results
P ranking c using constituent documents
rather using c whole unit:
di c pdi (q)pdi (c). Several cluster ranking methods
proposed past literature ignore document-cluster association strength.
practice amounts setting pdi (c) constant clusters documents.
Assuming also clusters contain number documents, case
experimental setup Section 5, rank
c arithmetic mean query1 P
match values constituent documents, |c|
di c pdi (q); |c| number documents
c. arithmetic mean bounded maxdi c pdi (q), used
previous work ranking clusters (Leuski, 2001; Shanahan, Bennett, Evans, Hull,
& Montgomery, 2003; Liu & Croft,
qQ2008), geometric mean
5
|c|
document-query match values,
di c pdi (q) (Liu & Croft, 2008; Seo & Croft, 2010).
Alternatively, minimal query-document match value, mindi c pdi (q), also
utilized ranking clusters (Leuski, 2001; Liu & Croft, 2008), also constitutes lower
bound arithmetic mean.

4. Related Work
Query-specic clusters often used visualize results search help users
quickly detect relevant documents (Hearst & Pedersen, 1996; Leuski & Allan, 1998;
Leuski, 2001; Palmer et al., 2001; Shanahan et al., 2003). Leuski (2001), example,
orders (hard) clusters interactive retrieval system highest lowest querysimilarity exhibited constituent documents. showed Section 3.3
ranking methods, others, used several reports using queryspecic clustering (Shanahan et al., 2003; Liu & Croft, 2006a), explained using
framework. Furthermore, Section 5.3 demonstrate merits ClustRanker
respect approaches.
work uses information query-specic clusters smooth language models
documents initial list improve document-query similarity estimate
(Liu & Croft, 2004; Kurland, 2009). related vein, graph-based approaches reranking initial list, using document clusters, utilize inter-document similarity
5. Liu Croft (2008) Seo Croft (2010) used geometric-mean-based language model representation clusters, rather geometric mean query-match values.

374

fiA Language Model Approach Ranking Query-Specific Document Clusters

information also proposed (Diaz, 2005; Kurland & Lee, 2005, 2006; Yang et al., 2006).
approaches potentially help improve performance ClustRanker
algorithm, provide higher quality document ranking begin with. Graph-based
approaches modeling inter-item textual similarities, similar spirit methods
inducing document cluster centrality, also used text summarization, question
answering, clustering (Erkan & Radev, 2004; Mihalcea, 2004; Mihalcea & Tarau, 2004;
Otterbacher, Erkan, & Radev, 2005; Erkan, 2006a, 2006b).
Ranking query-specic (and query-independent) clusters response query traditionally based comparing cluster representation query (Jardine
& van Rijsbergen, 1971; Croft, 1980; Voorhees, 1985; Willett, 1985; Kurland & Lee, 2004;
Liu & Croft, 2004, 2006b, 2006a). ClustQueryGen criterion, used work
ranking query-specic clusters language model framework (Liu & Croft, 2004;
Kurland, 2009), language-model manifestation ranking approach. show
eectiveness ClustQueryGen inferior ClustRanker Section 5.3.
previous cluster-based document-ranking models (Kurland & Lee, 2004; Kurland,
2009) viewed conceptual opposite ClustRanker method use
clusters proxies ranking documents. However, models use query-similarity
information ClustRanker integrates information centrality information.
fact, show Section 5.3 centrality information often eective querysimilarity (generation) information ranking query-specic clusters; and, integration yields better performance using alone.
Recently, researchers identied properties query-specic clusters contain high percentage relevant documents (Liu & Croft, 2006b; Kurland & Domshlak, 2008); among cluster-query similarity (ClustQueryGen) (Liu & Croft,
2006b), query similarity clusters constituent documents (DocQueryGen) (Liu
& Croft, 2006b; Kurland & Domshlak, 2008), dierences two (Liu &
Croft, 2006b). properties utilized automatically deciding whether employ
cluster-based document-based retrieval response query (Liu & Croft, 2006b),
ranking query-specic clusters (Kurland & Domshlak, 2008). latter approach
(Kurland & Domshlak, 2008) relies rankings induced clusters models entire
corpus, contrast approach focuses context within initially retrieved
list. However, centrality-based methods Table 2 potentially incorporated
cluster-ranking framework (Kurland & Domshlak, 2008).
work ranking query-specic clusters resembles utilizes clustercentrality information (Kurland & Lee, 2006); contrast approach, centrality
induced based cluster-document similarities. discuss approach compare Section 5.3.

5. Evaluation
next evaluate eectiveness cluster ranking approach detecting query-specic
clusters contain high percentage relevant documents.
375

fiKurland & Krikon

5.1 Language-Model Induction
language model induction, treat documents queries term sequences.
several possible approaches representing clusters whole units (Voorhees,
1985; Leuski, 2001; Liu & Croft, 2006b; Kurland & Domshlak, 2008), focus
underlying principles ranking framework. Therefore, adopt approach
commonly used work cluster-based retrieval (Kurland & Lee, 2004; Liu & Croft, 2004;
Kurland & Lee, 2006; Liu & Croft, 2006a), represent cluster term sequence
results concatenating constituent documents. order concatenation
eect since dene unigram language models assume term independence.
Dir[]
use px
() denote Dirichlet-smoothed unigram language model induced
term sequence x (Zhai & Laerty, 2001); smoothing parameter. avoid
length bias underow issues assigning language-model probabilities long texts
(Lavrenko et al., 2002; Kurland & Lee, 2005), case pd (c), adopt following
measure (Laerty & Zhai, 2001; Kurland & Lee, 2004, 2005, 2006), used
language-model-based estimates experiments follow, unless otherwise specied
(specically, relevance-model construction):
fifi



def
fifi Dir[]
p
()
;
py (x) = exp pDir[0]
()
fi
fi

x
x term sequences, Kullback-Leibler (KL) divergence. estimate
empirically demonstrated eective settings wherein long texts assigned
language-model probabilities (Kurland & Lee, 2004, 2005, 2006).
Although estimate described constitute probability distribution
case unigram language models previous work demonstrates merits
using without normalization (Kurland & Lee, 2005, 2006).
5.2 Experimental Setup
conducted experiments following TREC corpora:
corpus
AP
TREC8
WSJ
WT10G

# docs
242,918
528,155
173,252
1,692,096

queries
51-64, 66-150
401-450
151-200
451-550

disk(s)
1-3
4-5
1-2
WT10G

data sets used previous work ranking query-specic clusters (Liu
& Croft, 2004; Kurland & Lee, 2006; Liu & Croft, 2008) compare
methods. used titles TREC topics queries. applied tokenization
Porter stemming via Lemur toolkit (www.lemurproject.org), also used
language model induction.
set Dinit , list upon clustering performed, 50 highest ranked
Dir[]
documents initial ranking induced entire corpus using pd
(q) i.e.,
standard language-model approach. initial ranking reasonable quality,
set smoothing parameter, , value results optimized MAP (calculated
standard 1000 cuto) performance. practice also facilitates comparison
376

fiA Language Model Approach Ranking Query-Specific Document Clusters

previous work cluster ranking (Kurland & Lee, 2006), employs
approach creating initial list 50 documents clustered. motivation
using relatively short initial list rises previous observations regarding eectiveness
methods utilize inter-document similarities among top-retrieved documents (Liu &
Croft, 2004; Diaz, 2005; Kurland, 2006, 2009). documents highly ranked exhibit
high query similarity, hence, short retrieved lists could viewed providing
concise corpus context query longer lists. Similar considerations echoed
work pseudo-feedback-based query expansion, wherein top-retrieved documents
used forming new query model (Xu & Croft, 1996; Zhai & Laerty, 2001; Lavrenko &
Croft, 2001; Tao & Zhai, 2006).
produce set C l(Dinit ) query-specic clusters, use simple nearest-neighborsbased clustering approach known produce (some) clusters contain high
percentage relevant documents (Kurland, 2006; Liu & Croft, 2006a). Given Dinit
dene cluster contains k 1 documents di Dinit (di 6= d) yield
highest language-model similarity pdi (d). (We break ties document IDs.) high
percentages relevant documents optimal cluster presented Table 1
clusters. generally, clustering approach shown eective
cluster-based retrieval (Griths, Luckhurst, & Willett, 1986; Kurland & Lee, 2004;
Kurland, 2006; Liu & Croft, 2006b, 2006a; Tao et al., 2006), specically, respect
using hard clusters (Kurland, 2009).
posed cluster ranking methods means increasing precision
top ranks returned document list. Thus, evaluate cluster ranking method
percentage relevant documents highest ranked cluster. use p@k denote
percentage relevant documents cluster size k (either 5 10),
precision top k documents obtained clusters (k) constituent documents
positioned top ranks results. cluster ranking evaluation approach
also employed previous work ranking clusters (Kurland & Lee, 2006; Liu & Croft,
2008) compare methods. determine statistically signicant dierences
p@k performance using Wilcoxons two-sided test condence level 95%.
focus underlying principles approach potential eectiveness,
specically, compare relative eectiveness contribution overall
performance dierent information types utilized methods, rst ameliorate
free-parameter-values eects. end, set values free parameters incorporated methods optimize average (over queries per corpus) p@k performance
clusters size k. (Optimization based line search free-parameter values
ranges.) employ practice reference comparisons. is, independently optimize performance respect free-parameter values p@5 p@10.
Then, Section 5.3.5 analyze eect free-parameter values eectiveness
approach. addition, Section 5.3.6 study performance approach
free-parameter values set using cross validation performed queries. value ,
interpolation parameter ClustRanker algorithm, selected {0, 0.1, . . . , 1}.
values (two) parameters controlling graph-construction methods (for inducing document cluster biases) chosen previously suggested ranges (Kurland
& Lee, 2005). (See Appendix details graph construction.) value ,
language model smoothing parameter, set 2000 following previous recommenda377

fiKurland & Krikon

tions (Zhai & Laerty, 2001), except estimating pd (q) use value chosen
creating Dinit maintain consistency initial ranking.
important point computational overhead approach top
initial search signicant. Clustering top-retrieved documents (50
case) performed quickly (Zamir & Etzioni, 1998); note framework
committed specic clustering approach. Furthermore, computing PageRank scores
graph 50 documents (clusters) induce document (cluster) centrality takes
iterations Power method (Golub & Van Loan, 1996). Finally, note
number documents corpus eect eciency approach,
methods based clustering documents highly ranked initial search.
5.3 Experimental Results
follows present analyze performance numbers cluster ranking
approach, study impact various factors eectiveness. Section 5.3.1
study eectiveness ClustRanker means improving precision top ranks.
end, use comparison initial ranking upon clustering performed,
relevance models (Lavrenko & Croft, 2001). Then, Section 5.3.2 study
relative performance eect various cluster ranking criteria integrated ClustRanker.
compare eectiveness ClustRanker previously proposed methods
cluster ranking Section 5.3.3. Section 5.3.4 compare performance ClustRanker document-based re-ranking approaches utilize inter-documents
similarities various ways. Section 5.3.5 analyze performance sensitivity
ClustRanker respect free-parameter values. Finally, Section 5.3.6 analyze
performance ClustRanker, contrast various reference comparisons,
free-parameter values set using cross validation performed queries.
5.3.1 Comparison Document-Based Retrieval
rst question interested eectiveness (or lack thereof) ClustRanker
improving precision top ranks. Recall use ClustRanker rank
clusters k ( {5, 10}) documents Dinit initially retrieved document list.
described above, evaluate ClustRankers eectiveness percentage relevant
documents cluster highly ranked. percentage p@k attained
clusters constituent documents positioned highest ranks nal result list.
Table 3 compare performance ClustRanker initial ranking. Since
initial ranking created using standard language-model-based document retrieval
performed corpus pd (q) scoring function, document language
model smoothing parameter () optimized MAP, also consider optimized baselines
reference comparisons: ranking documents corpus pd (q) set
optimize (independently) p@5 p@10.
see Table 3, ClustRanker posts performance substantially better
initial ranking relevant comparisons (corpus evaluation measure). AP WT10G performance improvements also statistically signicant.
Furthermore, ClustRanker almost always outperforms optimized baselines, often
substantial extent; several cases, improvements also statistically signicant.
378

fiA Language Model Approach Ranking Query-Specific Document Clusters

init. rank.
opt. base.
ClustRanker

AP
p@5 p@10
45.7
43.2
46.5
43.7

52.7 50.6io

TREC8
p@5 p@10
50.0
45.6
51.2
46.4
57.6 50.6

WSJ
p@5 p@10
53.6
48.4
56.0 49.4
56.0 51.2

WT10G
p@5 p@10
33.9
28.0
34.1
28.2
39.8io 33.9io

Table 3: Comparison ClustRanker initial document ranking optimized baselines. Boldface marks best result column; mark statistically
signicant dierences initial ranking, optimized baselines, respectively.

init. rank.
Rel Model
Rel Model(Re-Rank)
ClustRanker

AP
p@5 p@10
45.7
43.2

50.3
48.6i
51.1i 48.3i
52.7i 50.6i

TREC8
p@5 p@10
50.0
45.6
54.4
50.2
53.6
49.8
57.6 50.6

WSJ
p@5 p@10
53.6
48.4

58.4 53.2i
58.8i 53.4i
56.0
51.2

WT10G
p@5 p@10
33.9
28.0
35.7
29.9
36.3
30.1

39.8 33.9i

Table 4: Comparison ClustRanker relevance model (RM3) used either rank
entire corpus (Rel Model) re-rank initial list (Rel Model(Re-Rank)).
Boldface marks best result column; marks statistically signicant difference initial ranking.

Comparison Pseudo-Feedback-Based Retrieval ClustRanker algorithm
helps identify relevant documents Dinit exploiting clustering information. Pseudofeedback-based query expansion approaches, hand, dene query model based
Dinit use (re-)ranking entire corpus (Buckley et al., 1994; Xu & Croft,
1996). contrast two paradigms, use relevance model RM3 (Lavrenko & Croft,
2001; Abdul-Jaleel et al., 2004; Diaz & Metzler, 2006), state-of-the-art pseudofeedback-based query expansion approach. use RM3 ranking entire corpus
standard, refer implementation Rel Model. Since ClustRanker
thought means re-ranking initial list Dinit , also experiment using RM3
re-ranking Dinit , rather entire corpus; Rel Model(Re-Rank) denotes
implementation. set values free parameters Rel Model Rel Model(ReRank) independently optimize p@5 p@10 performance. (See Appendix B
details regarding relevance model implementation.)
see Table 4 ClustRanker outperforms relevance models AP,
TREC8 WT10G; WSJ, relevance models outperform ClustRanker. performance dierences ClustRanker relevance models, however, statistically signicant. Nevertheless, results attest overall eectiveness
approach attaining high precision top ranks. later show, previous methods
ranking clusters often yield performance comparable initial
ranking, much inferior relevance model.
379

fiKurland & Krikon

init. rank.

p@5
45.7

AP
p@10
43.2

TREC8
p@5
p@10
50.0
45.6

WSJ
p@5
p@10
53.6
48.4

WT10G
p@5
p@10
33.9
28.0

ClustCent
ClustQueryGen
ClustCent ClustQueryGen

51.7
39.2i
49.7

48.6i
38.8i
48.0i

52.4
39.6i
55.2

49.4
40.6i
50.4

54.8
44.0i
52.4

50.0
37.0i
47.8

39.8i
30.0
39.6i

33.0i
24.1
33.1i

DocCent
DocQueryGen
DocCent DocQueryGen

52.9i
43.6
52.7i

48.8
46.7
50.6i

52.0
47.6
54.8

48.8
43.2
49.0

55.6
55.2
56.0

50.6
47.0
51.2

31.0
33.5
37.1

28.1
27.0
31.4

ClustCent DocCent
ClustQueryGen DocQueryGen

53.5i
43.6

48.8i
46.7

54.8
47.6

49.8
43.2

56.0
55.2

51.4
47.8

39.8i
36.5

33.0i
29.1

ClustRanker

52.7i

50.6i

57.6

50.6

56.0

51.2

39.8i

33.9i

Table 5: Comparison cluster ranking methods Table 2. Boldface marks best
result column indicates statistically signicant dierence
initial ranking.

5.3.2 Deeper Inside ClustRanker
turn analyze performance various cluster ranking criteria (methods)
ClustRanker integrates study relative contribution overall eectiveness. (Refer back Table 2 specication dierent methods.) performance
numbers presented Table 5.
rst interested comparison two types information utilized
ranking, is, centrality query-similarity (generation). see Table 5
almost relevant comparisons (corpus evaluation metric), using centrality information yields performance superior using query-similarity (generation)
information. (Compare ClustCent ClustQueryGen, DocCent DocQueryGen,
ClustCent DocCent ClustQueryGen DocQueryGen.) Specically, see
cluster-query similarity (ClustQueryGen), main ranking criterion previous
work cluster ranking, yields performance much worse cluster centrality (ClustCent) cluster ranking criterion novel study. addition,
note integrating centrality query-similarity (generation) information often
yield performance better using alone, case DocCent
DocQueryGen respect DocCent DocQueryGen.
next turn examine relative eectiveness using cluster whole versus
using constituent documents. using query-similarity (generation) information, see using documents cluster much eective using
cluster whole. (Compare DocQueryGen ClustQueryGen.) nding
attests merits using documents proxies ranking clusters underlying
idea approach. using centrality information, picture split across corpora:
AP WSJ using documents cluster yields better performance using
whole cluster, reverse holds TREC8 WT10G. (Compare DocCent
ClustCent.) Integrating whole-cluster-based document-based information results
performance corpora (much) better using less eective
two, sometimes even better eective two.
380

fiA Language Model Approach Ranking Query-Specific Document Clusters

init. rank.
Dinit
dc

AP
p@5 p@10
45.7
43.2
49.5
47.6

52.7 50.6i

TREC8
p@5 p@10
50.0
45.6
54.0
49.8
57.6 50.6

WSJ
p@5 p@10
53.6
48.4
52.8
49.6
56.0 51.2

WT10G
p@5 p@10
33.9
28.0
39.6i 33.2i
39.8i 33.9i

Table 6: Performance numbers ClustRanker either documents Dinit serve
proxies cluster c (denoted Dinit ), cs constituent documents serve
proxies, original implementation (denoted c). Boldface marks
best result column; marks statistically signicant dierences
initial ranking.

surprise, then, ClustRanker method, integrates centrality
information query-similarity (generation) information induced
cluster whole constituent documents, relevant comparisons
eective cluster ranking method among presented Table 5.
Documents Proxies Clusters ndings presented demonstrated
merits using documents proxies clusters. turn study eect performance documents selected proxies. derivation ClustRanker based
truncating summation Equation 2 (Section 3) allow cs constituent documents serve proxies. examine variant ClustRanker wherein documents
initial list Dinit serve cs proxies:
X
def
core(c) = Cent(c)pc (q) + (1 )
pdi (q)pdi (c)Cent(di ).
di Dinit

seen Table 6, variant (represented row labeled Dinit )
posts performance almost always better initial document ranking
Dinit derived. However, performance also consistently worse
original implementation ClustRanker (represented row labeled c)
lets cs constituent documents serve proxies. Furthermore, variant
ClustRanker posts less statistically signicant improvements initial ranking
original implementation. (The performance dierences two variants
ClustRanker, however, statistically signicant.) Thus, mentioned Section
3, using clusters constituent documents proxies computationally
convenient, also yields performance improvements.
5.3.3 Comparison Past Approaches Ranking Clusters
Table 7 compare performance ClustRanker previously proposed
methods ranking clusters. follows rst discuss methods,
analyze performance patterns.
previous approaches ranking (various types of) clusters compare cluster representation query (Jardine & van Rijsbergen, 1971; Croft, 1980; Kurland
& Lee, 2004; Liu & Croft, 2004, 2006b). Specically, language model framework,
381

fiKurland & Krikon

query-specic clusters ranked probability assigned induced language
models query (Liu & Croft, 2004, 2006b; Kurland & Lee, 2006). Note
exactly ClustQueryGen method setup, ranks c pc (q).
work using maximal (Leuski, 2001; Shanahan et al., 2003;
Liu & Croft, 2008) minimal (Leuski, 2001; Liu & Croft, 2008) query-similarity values
documents cluster ranking it. showed Section 3.3 approaches explained terms framework; specically, score cluster c
maxdi c pdi (q) mindi c pdi (q), respectively. However, methods originally proposed ranking hard clusters. clusters rank overlapping, ranking
criteria somewhat less appropriate result many ties cluster scores. Still,
use methods baselines break ties arbitrarily also used
recent work ranking nearest-neighbors-based clusters (Liu & Croft, 2008).6 Following
observations regard merits representing clusters using geometric mean constituent documents representations (Liu & Croft, 2008; Seo & Croft,
2010), also consider
geometric mean query-similarity values documents
qQ
c ranking it; is, |c| di c pdi (q).7

additional reference comparison consider, shown yield eective
cluster ranking performance, recently proposed (bipartite-)graph-based approach (Kurland & Lee, 2006). Documents Dinit vertices one side, clusters C l(Dinit )
vertices side; edge connects document clusters ci
yield highest language-model similarity pci (d), also serves weight function
edges. Then, Kleinbergs (1997) HITS (hubs authorities) algorithm run
graph, clusters ranked induced authority values. shown
cluster highest authority value tends contain high percentage relevant
documents (Kurland & Lee, 2006). implementation, follow details provided
Kurland Lee (2006); specically, choose value {2, 4, 9, 19, 29, 39, 49}
optimize p@k performance clusters size k.
Table 7 presents comparison ClustRanker reference comparisons
described. p@k (k {5, 10}) reported cluster ranking method percentage
relevant documents highest ranked cluster, wherein clusters contain k documents
each.
see Table 7 ClustRanker outperforms reference comparisons almost cases. Many performance dierences also statistically signicant.
Furthermore, ClustRanker cluster ranking method Table 7 consistently
outperforms initial ranking. Moreover, ClustRanker posts statistically signicant
improvements initial ranking cluster ranking methods do.
6. noted above, previous work cluster-based retrieval demonstrated merits using overlapping
nearest-neighbors-based clusters respect using hard clusters (Kurland, 2009). Indeed, recent work
cluster ranking focused ranking nearest-neighbor-based clusters (Kurland & Lee,
2006; Liu & Croft, 2006b, 2006a, 2008; Seo & Croft, 2010).
7. note original proposals (Liu & Croft, 2008; Seo & Croft, 2010) geometric mean
language models used term level rather query-assigned score level use here.
maintain consistency cluster-ranking methods explored, use geometric mean
query-assigned score level; and, hasten point geometric-mean-based language
model (Liu & Croft, 2008; Seo & Croft, 2010) could used instead standard language model
clusters ClustRanker reference comparisons potentially improve performance.

382

fiA Language Model Approach Ranking Query-Specific Document Clusters

p@5
45.7

AP
p@10
43.2

p@5
50.0

39.2i

38.8i

39.6i

40.6i

44.0i

37.0i

30.0

24.1

41.8

40.3

38.8i

41.6

51.2

46.6

33.9

29.2

SM (c) = mindi Dinit pdi (q)
qQ
def
SGeoM ean (c) = |c| di c pdi (q)

47.0

46.7

46.4

48.4

48.4

47.8

31.4

25.9

44.4

46.7i

50.0

49.6

56.0

50.6

37.4

31.8i

SHIT (c)

49.5

47.2

50.8

46.6

53.6

49.0

26.7i

23.9i

SClustRanker (c)

52.7icM
g

50.6icM

57.6cM
mh

50.6cM


56.0cm

51.2c

39.8icM
mh

33.9icM
mh

init. rank.
def

SClustQueryGen (c) = pc (q)
def

SM ax (c) = maxdi Dinit pdi (q)
def

TREC8
p@10
45.6

p@5
53.6

WSJ
p@10
48.4

p@5
33.9

WT10G
p@10
28.0

Table 7: Comparison ClustRanker previously proposed methods ranking clusters. (S stands cluster-scoring function.) Boldface marks best result
column; marks statistically signicant dierence method
initial ranking; c, M, m, g, h mark statistically signicant dierences
ClustRanker ClustQueryGen, Max, Min, GeoMean HITS methods,
respectively.

AP
init. rank.
HITS
ClustCent
DocCent
ClustCent DocCent

p@5
45.7
49.5
51.7
52.9ih
53.5ih

p@10
43.2
47.2
48.6i
48.8
48.8i

TREC8
p@5 p@10
50.0
45.6
50.8
46.6
52.4
49.4
52.0
48.8
54.8 49.8

WSJ
p@5 p@10
53.6
48.4
53.6
49.0
54.8
50.0
55.6
50.6
56.0 51.4

WT10G
p@5
p@10
33.9
28.0

26.7
23.9i
39.8ih 33.0ih
31.0h
28.1h
ih
39.8
33.0ih

Table 8: Comparison centrality-solely approaches ranking clusters HITSbased method (Kurland & Lee, 2006). Boldface marks best performance
column; h mark statistically signicant dierences initial ranking
HITS method, respectively.

Comparison HITS-Based Approach HITS-based method (Kurland & Lee, 2006) utilizes cluster centrality information induced cluster-document
graph. ClustRanker method, hand, integrates centrality information
induced document-solely cluster-solely graphs query-similarity (generation) information. Table 8 contrast resultant performance using dierent
notions centrality utilized two methods. present performance
centrality-solely-based methods ClustCent, DocCent, ClustCent DocCent
HITS approach (Kurland & Lee, 2006).
see Table 8 centrality-solely-based approaches outperform
HITS-based method relevant comparisons. results attest eective utilization (a specic type of) centrality information framework.
383

fiKurland & Krikon

5.3.4 Comparison Utilizing Inter-Document Similarities Directly
Rank Documents
Ranking clusters based presumed percentage relevant documents contain,
ClustRanker, one approach utilizing inter-document similarities improve
document-ranking eectiveness. Alternatively, inter-document similarities exploited
directly rank documents. example, re-ranking principle demonstrated
eective rewarding documents initially highly ranked, highly
similar many documents initial list (Balinski & Danilowicz, 2005; Diaz,
2005; Kurland & Lee, 2005). Specically, using DocCent component ClustRanker,
is, PageRank score document (Cent(d)) induced document-similarity
graph, scaling value pd (q) initial (query similarity) score
shown eective re-ranking criterion (Kurland & Lee, 2005). use
PR+QuerySim denote method.
Another approach consider ranking documents using clusters form
extended document representation. (In language model terms translates clusterbased smoothing.) Specically, use Interpolation algorithm (Kurland & Lee, 2004),
shown highlyPeective re-ranking (Kurland, 2009). document
scored pd (q) + (1 ) cC l(Dinit) pc (q)pd (c); free parameter. is,
document rewarded direct match query (pd (q)), criterion
used creating initial ranking, query match clusters (pc (q))
strongly associated (as measured pd (c)). words, Interpolation
model backs document representation cluster-based representation.
Interpolation model could conceptually viewed generalization methods use
single cluster (Liu & Croft, 2004; Tao et al., 2006) topic model (Wei & Croft, 2006)
smoothing document language model. Furthermore, note Interpolation
uses clusters document proxies ranking documents, ClustRanker method uses
documents cluster proxies ranking clusters.
Table 9 compare performance ClustRanker PR+QuerySim
Interpolation methods described. performance Interpolation independently optimized p@5 p@10 using clusters 5 10 documents, respectively,
case ClustRanker; value chosen {0, 0.1, . . . , 0.9}. performance PR+QuerySim also independently optimized p@5 p@10, setting
graph degree parameter () 4 9 respectively, selecting value
{2, 4, 9, 19, 29, 39, 49}. (Setting graph out-degree parameter value x amounts
document transfer centrality support x documents; hence, using
values 4 9 amounts considering local neighborhoods 5 10 documents
similarity space, respectively; conceptually reminiscent using clusters size 5
10 respectively. Refer Appendix details.)
see Table 9 ClustRanker outperform PR+QuerySim Interpolation
relevant comparisons. (Several performance dierences former
statistically signicant, latter not.) Specically, relative
performance improvements WT10G quite substantial. (We hasten point out,
however, Interpolation posts statistically signicant performance improvements
initial ranking ClustRanker does.)
384

fiA Language Model Approach Ranking Query-Specific Document Clusters

init. rank.
PR+QuerySim
Interpolation
ClustRanker

AP
p@5 p@10
45.7
43.2
49.5
49.5i
51.3i 50.3i
52.7ip 50.6i

TREC8
p@5 p@10
50.0
45.6
56.0 51.0i
55.6i 49.6i
57.6 50.6

WSJ
p@5 p@10
53.6
48.4

57.2
50.4
56.8
52.4
56.0
51.2

WT10G
p@5 p@10
33.9
28.0
35.9
30.4
36.1
31.8i
39.8ip 33.9ip

Table 9: Comparison re-ranking methods utilize inter-document similarities
directly rank documents. Boldface marks best result column. Statistically
signicant dierences initial ranking PR+QuerySim marked
p, respectively. statistically signicant dierences
ClustRanker Interpolation.

all, see ranking clusters done ClustRanker result (document)
re-ranking performance least eective (and often eective)
methods utilize inter-document similarities directly rank documents.
5.3.5 Performance-Sensitivity Analysis
next turn analyze eect varying values free parameters ClustRanker incorporates performance. rst parameter, , controls reliance
cluster whole unit versus constituent documents. (Refer back Equation 4
Section 3 details.) Figure 1 depicts p@5 performance ClustRanker, clusters
5 documents, function ; p@10 performance patterns ClustRanker
clusters 10 documents similar, omitted avoid cluttering presentation.
see Figure 1 AP, TREC8 WT10G, values result
performance (much) better initial ranking; WSJ, 0.4 results
performance superior initial ranking. Furthermore, AP, TREC8,
WT10G, = 0.4, strikes good balance using cluster whole
using constituent documents, yields (near) optimal performance; WSJ, smaller values
(specically, = 0), result weight put clusters constituent
documents, eective. Thus, witness importance using clusters
constituent documents proxies ranking cluster.
graph-based method used ClustRanker inducing document (and cluster)
centrality depends two free parameters: (the number nearest neighbors considered
element graph), (PageRanks damping factor); see Appendix
details. noted above, document graph cluster graph constructed
using values two parameters. Figures 2 3 depict eect
values , respectively, p@5 performance ClustRanker clusters 5
documents.
see Figure 2 values result performance (often much)
better initial ranking. general, small values yield best performance. nding accordance reported previous work using
385

fiKurland & Krikon

AP

TREC8

Effect p@5, corpus=AP

Effect p@5, corpus=TREC8

54

58

52
56

54

48

p@5

p@5

50

46

52

44
50
42

ClustRanker
init. rank.

40
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

ClustRanker
init. rank.

48
0.9

1

0

0.1

0.2

0.3

0.4



0.5

0.6

0.7

0.8

0.9

1

0.9

1



WSJ

WT10G

Effect p@5, corpus=WSJ

Effect p@5, corpus=WT10G

58
40

57
56

38
54

p@5

p@5

55

53

36
34

52
51

32

50

ClustRanker
init. rank.

49
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

ClustRanker
init. rank.

30
0.9

1

0



0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8



Figure 1: Eect varying p@5 performance ClustRanker.
nearest-neighbor-based graphs ranking documents initially retrieved list using
document-solely graphs (Diaz, 2005; Kurland & Lee, 2005).
Figure 3 shows almost every value , resultant performance ClustRanker
transcends initial ranking; many cases, improvement quite substantial.
5.3.6 Learning Free-Parameter Values
Heretofore, studied performance ClustRanker, analyzed eectiveness
information types utilizes, ameliorating free-parameter values eects.
is, reported performance parameter values result optimized average p@k
entire set queries per corpus. applied practice reference
comparisons considered, resulted comparing potential eectiveness
approach previously suggested ones. addition, studied
previous section eect values free parameters incorporated ClustRanker
(average) performance.
turn study question whether eective values free parameters
ClustRanker generalize across queries; is, whether values learned.
perform study, employ leave-one-out cross validation procedure. query,
free parameters ClustRanker set values yield optimal average p@k
386

fiA Language Model Approach Ranking Query-Specific Document Clusters

AP

TREC8

Effect p@5, corpus=AP

Effect p@5, corpus=TREC8

54

58

52

56

50
p@5

p@5

54
48

52
46
50

44
ClustRanker
init. rank.

42
2 4

9

19

29

39

ClustRanker
init. rank.

48
49

2 4

9

19



29

39

49



WSJ

WT10G

Effect p@5, corpus=WSJ

Effect p@5, corpus=WT10G

58

42

57
40

56

38

54

p@5

p@5

55

53

36

52
51

34

50

ClustRanker
init. rank.

49
2 4

9

19

29

39

ClustRanker
init. rank.

32
49

2 4



9

19

29

39

49



Figure 2: Eect varying , one graph parameters (refer Appendix A),
p@5 performance ClustRanker.

queries corpus. Then, report resultant average p@k
queries per corpus. Thus, reported p@k numbers based learning performed
p@k optimization metric.
contrast performance ClustRanker reference comparisons
used above. Specically, document-based ranking baselines: (i) initial ranking, (ii)
relevance model used rank entire corpus (Rel Model), (iii) relevance model
used re-rank initial list (Rel Model(Re-Rank)); and, cluster ranking methods: (i)
def

def

def

coreClustQueryGen (c) = pc (q), (ii)S coreM ax (c) = maxdi Dinit pdi (q), (iii) coreM (c) =
qQ
def
mindi Dinit pdi (q), (iv) coreGeoM ean (c) = |c| di c pdi (q), (v) coreHIT (c).

reference comparisons incorporate free parameters Rel Model, Rel Model(Re-Rank),
HITS employ leave-one-out cross validation set free-parameter values
ClustRanker. performance numbers methods presented Table
10.
rst observation based Table 10 ClustRanker outperforms initial
ranking relevant comparisons; improvements quite substantial.
387

fiKurland & Krikon

AP

TREC8

Effect p@5, corpus=AP

Effect p@5, corpus=TREC8

54

58

52

56

50
p@5

p@5

54
48

52
46
50

44
42
0.050.1

ClustRanker
init. rank.
0.2

0.3

0.4

0.5

0.6

0.7

0.8

48
0.050.1

0.90.95

ClustRanker
init. rank.
0.2

0.3

0.4



0.5

0.6

0.7

0.8

0.90.95



WSJ

WT10G

Effect p@5, corpus=WSJ

Effect p@5, corpus=WT10G

58

42

57
40

56

38

54

p@5

p@5

55

53

36

52
51

34

50
49
0.050.1

ClustRanker
init. rank.
0.2

0.3

0.4

0.5

0.6

0.7

0.8

32
0.050.1

0.90.95



ClustRanker
init. rank.
0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.90.95



Figure 3: Eect varying , one graph parameters (refer Appendix A),
p@5 performance ClustRanker.

exception WSJ corpus, relevance models also
outperform initial ranking terms p@5. Thus, seems query-variability issues,
aect ability learn eective free-parameter values, quite eect
performance methods WSJ.
also see Table 10 except WSJ, ClustRanker outperforms previously proposed cluster ranking methods almost relevant comparisons. Many
performance improvements substantial statistically signicant.
seen Table 10, ClustRanker method also outperforms
relevance models (Rel Model Rel Model(Re-Rank)) majority relevant comparisons (corpus evaluation measure). single case ClustRanker
outperformed statistically signicantly manner relevance models (p@10
WSJ), WT10G ClustRanker posts statistically signicant improvements relevance models, performance dierences quite striking. Furthermore,
observe contrast ClustRanker, previously proposed cluster ranking methods often post performance much worse many cases statistically signicant
degree relevance models. Somewhat exception ranking clusters
388

fiA Language Model Approach Ranking Query-Specific Document Clusters

AP

TREC8
p@10
45.6

init. rank.

p@5
45.7

p@10
43.2

p@5
50.0

Rel Model
Rel Model(Re-Rank)

49.9
51.1i

48.4i
45.8

50.8
50.4

50.2
49.8

52.0
52.0

39.2ir

38.8ir

39.6ir

40.6ir

41.8r

40.3r

38.8ir

def

SClustQueryGen (c) = pc (q)
def

SM ax (c) = maxdi Dinit pdi (q)
def

p@5
53.6

WSJ
p@10
48.4

p@5
33.9

WT10G
p@10
28.0

30.4i
36.3

29.2
27.8

44.0ir 37.0ir

30.0

24.1r

41.6r

51.2r 46.6r

33.9

29.2

48.4r 47.8r

31.4

25.9

37.4r

31.8i

52.6
52.6

SM (c) = mindi Dinit pdi (q)
qQ
def
SGeoM ean (c) = |c| di c pdi (q)

47.0

46.7

46.4

48.4r

44.4r

46.7i

50.0

49.6

56.0r 50.6r

SHIT (c)

48.5

47.2

50.8

43.2r

53.6

46.8

25.5i

23.9r

ClustRanker

52.3icM g

48.3ic


53.2c

46.2c

38.6rcM

31.2cm

56.8cM mh 49.4cM

Table 10: Performance results using leave-one-out cross validation set freeparameter values. Boldface marks best performance per column. Statistically signicant dierences method initial ranking marked
i. Statistically signicant dierences ClustRanker cluster ranking
methods, ClustQueryGen, Max, Min, GeoMean, HITS marked c,
M, m, g, h, respectively. Statistically signicant dierences cluster
ranking method Rel Model Rel Model(Re-Rank) marked r
, respectively.

geometric mean constituent documents query-similarity values (GeoMean):
WT10G WSJ performance better relevance models; however,
TREC8 AP performance somewhat inferior relevance models.
all, ndings presented attest ClustRanker, learning free
parameter values, (i) highly eective method obtaining high precision top ranks,
(ii) much eective previously proposed methods ranking clusters.

6. Conclusions Future Work
presented novel language model approach ranking query-specific clusters, is,
clusters created documents highly ranked initial search performed response
query. ranking clusters based presumed percentage relevant documents contain.
cluster ranking model integrates information induced cluster whole
unit induced documents associated cluster. Two types
information exploited approach: similarity query centrality.
latter reects similarity central items reference set, may documents
initial list, clusters documents.
Empirical evaluation showed using approach results precision-at-top-ranks
performance substantially better initial ranking upon clustering employed. Furthermore, performance often transcends state-of-the-art
pseudo-feedback-based query expansion method, namely, relevance model. addition,
showed approach substantially eective identifying clusters contain389

fiKurland & Krikon

ing high percentage relevant documents previously proposed methods ranking
clusters.
future work intend explore additional characteristics document clusters
might attest percentage relevant documents contain; example, cluster
density measured inter-document-similarities within cluster. Incorporating
characteristics framework principled way interesting challenge.
Acknowledgments
thank reviewers helpful comments. also thank Lillian Lee helpful
comments work presented paper, discussions led ideas presented
here; specically, cluster-centrality induction method fruit joint work Lillian
Lee. paper based upon work supported part Israel Science Foundation
grant no. 557/09, National Science Foundation grant no. IIS-0329064,
Googles faculty research award, IBMs SUR award. opinions, ndings
conclusions recommendations expressed material authors
necessarily reect sponsoring institutions.

Appendix A. Centrality Induction
briey describe previously proposed graph-based approach inducing document
centrality (Kurland & Lee, 2005), use inducing document cluster centrality.
Let (either Dinit , initial list documents, C l(Dinit ), set clusters)
set items, G = (S, S) complete directed graph dened S.
weight w t(s1 s2 ) edge s1 s2 (s1 , s2 S) dened
(
ps2 (s1 ) s2 N bhd(s1 ; ),
def
w t(s1 s2 ) =
0
otherwise,
N bhd(s1 ; ) set items {s1 } yield highest ps (s1 ). (Ties
broken item ID.)
use PageRank approach (Brin & Page, 1998) smooth edge-weight function:
w t[] (s1 s2 ) = (1 )

w t(s1 s2 )
1
;
+ P

|S|
w t(s1 )

free parameter.
Thus, G edge-weight function w t[] constitutes ergodic Markov chain,
stationary distribution exists. set Cent(s), centrality value s,
stationary probability visiting s.
Following previous work (Kurland & Lee, 2005), values chosen
{2, 4, 9, 19, 29, 39, 49} {0.05, 0.1, . . . , 0.9, 0.95}, respectively, optimize p@k
performance given algorithm clusters size k. use parameter setting
document-graph (S = Dinit ) cluster-graph (S = C l(Dinit )), therefore inducing document cluster centrality methods based two free
parameters.
390

fiA Language Model Approach Ranking Query-Specific Document Clusters

Appendix B. Relevance Model
estimate standard relevance model, RM1, shown yield better performance RM2 relevance model (Lavrenko & Croft, 2003), employ
implementation detailed Lavrenko Croft (2003). Let w denote term voJM []
cabulary, {qi } set query terms, pd
() denote Jelinek-Mercer smoothed
document language model smoothing parameter (Zhai & Laerty, 2001). RM1
dened
def

pRM 1 (w; ) =

X

dDinit

JM []
(w) P
pd

JM []
(qi )
pd
.
Q JM []
(qi )
dj Dinit
pdj

Q

practice, RM1 clipped setting pRM 1 (w; ) 0 terms
highest pRM 1 (w; ) begin (Connell et al., 2004; Diaz & Metzler, 2006); normalization performed yield probability distribution, denote
pRM 1 (; , ). improve performance, RM1 anchored original query via interpolation using free parameter (Abdul-Jaleel et al., 2004; Diaz & Metzler, 2006).
results RM3 model:
def

pRM 3 (w; , , ) = pqM LE (w) + (1 )pRM 1 (w; , );

pqM LE (w) maximum likelihood estimate term w respect q. Documents
fifi


fifi Dir[]
() .
corpus ranked minus cross entropy CE pRM 3 (; , , ) fifi pd
free-parameter values chosen following ranges independently optimize p@5 p@10 performance: {0, 0.1, 0.3, . . . , 0.9}, {25, 50, 75, 100, 500,
1000, 5000, ALL}, stands using terms corpus (i.e., clipping),
{0, 0.1, 0.2, . . . , 0.9}; set 2000, cluster-based algorithms, following
previous recommendations (Zhai & Laerty, 2001).

References
Abdul-Jaleel, N., Allan, J., Croft, W. B., Diaz, F., Larkey, L., Li, X., Smucker, M. D., &
Wade, C. (2004). UMASS TREC 2004 novelty hard. Proceedings
Thirteenth Text Retrieval Conference (TREC-13), pp. 715725.
Azzopardi, L., Girolami, M., & van Rijsbergen, K. (2004). Topic based language models
ad hoc information retrieval. Proceedings International Conference Neural
Networks IEEE International Conference Fuzzy Systems, pp. 32813286.
Balinski, J., & Danilowicz, C. (2005). Re-ranking method based inter-document distances. Information Processing Management, 41 (4), 759775.
Brin, S., & Page, L. (1998). anatomy large-scale hypertextual web search engine.
Proceedings 7th International World Wide Web Conference, pp. 107117.
Buckley, C. (2004). current IR engines fail. Proceedings SIGIR, pp. 584585.
Poster.
391

fiKurland & Krikon

Buckley, C., Salton, G., Allan, J., & Singhal, A. (1994). Automatic query expansion using
SMART: TREC3. Proceedings Third Text Retrieval Conference (TREC-3),
pp. 6980.
Collins-Thompson, K., Callan, J., Terra, E., & Clarke, C. L. (2004). eect document
retrieval quality factoid question answering performance. Proceedings SIGIR,
pp. 574575. Poster.
Connell, M., Feng, A., Kumaran, G., Raghavan, H., Shah, C., & Allan, J. (2004). UMass
TDT 2004. TDT2004 System Description.
Crestani, F., & Wu, S. (2006). Testing cluster hypothesis distributed information
retrieval. Information Processing Management, 42 (5), 11371150.
Croft, W. B. (1980). model cluster searching based classication. Information
Systems, 5, 189195.
Croft, W. B., & Laerty, J. (Eds.). (2003). Language Modeling Information Retrieval.
No. 13 Information Retrieval Book Series. Kluwer.
Diaz, F. (2005). Regularizing ad hoc retrieval scores. Proceedings Fourteenth
International Conference Information Knowledge Management (CIKM), pp.
672679.
Diaz, F., & Metzler, D. (2006). Improving estimation relevance models using large
external corpora. Proceedings SIGIR, pp. 154161.
Erkan, G. (2006a). Language model based document clustering using random walks.
Proceedings HLT/NAACL, pp. 479486.
Erkan, G. (2006b). Using biased random walks focused summarization. Proceedings
Document Understanding Conference (DUC).
Erkan, G., & Radev, D. R. (2004). LexPageRank: Prestige multi-document text summarization. Proceedings EMNLP, pp. 365371. Poster.
Geraci, F., Pellegrini, M., Maggini, M., & Sebastiani, F. (2006). Cluster generation
cluster labeling Web snippets: fast accurate hierarchical solution. Proceedings 13th international conference string processing information
retrieval (SPIRE), pp. 2537.
Golub, G. H., & Van Loan, C. F. (1996). Matrix Computations (Third edition). Johns
Hopkins University Press.
Griths, A., Luckhurst, H. C., & Willett, P. (1986). Using interdocument similarity information document retrieval systems. Journal American Society Information
Science (JASIS), 37 (1), 311. Reprinted Karen Sparck Jones Peter Willett,
eds., Readings Information Retrieval, Morgan Kaufmann, pp. 365373, 1997.
Harman, D., & Buckley, C. (2004). NRRC reliable information access (RIA) workshop.
Proceedings SIGIR, pp. 528529. Poster.
Hearst, M. A., & Pedersen, J. O. (1996). Reexamining cluster hypothesis: Scatter/Gather retrieval results. Proceedings SIGIR, pp. 7684.
392

fiA Language Model Approach Ranking Query-Specific Document Clusters

Jardine, N., & van Rijsbergen, C. J. (1971). use hierarchic clustering information
retrieval. Information Storage Retrieval, 7 (5), 217240.
Kleinberg, J. (1997). Authoritative sources hyperlinked environment. Tech. rep. Research Report RJ 10076, IBM.
Kurland, O. (2006). Inter-document similarities, language models, ad hoc retrieval.
Ph.D. thesis, Cornell University.
Kurland, O. (2009). Re-ranking search results using language models query-specic
clusters. Journal Information Retrieval, 12 (4), 437460.
Kurland, O., & Domshlak, C. (2008). rank-aggregation approach searching optimal
query-specic clusters. Proceedings SIGIR, pp. 547554.
Kurland, O., & Lee, L. (2004). Corpus structure, language models, ad hoc information
retrieval. Proceedings SIGIR, pp. 194201.
Kurland, O., & Lee, L. (2005). PageRank without hyperlinks: Structural re-ranking using
links induced language models. Proceedings SIGIR, pp. 306313.
Kurland, O., & Lee, L. (2006). Respect authority! HITS without hyperlinks utilizing
cluster-based language models. Proceedings SIGIR, pp. 8390.
Laerty, J. D., & Zhai, C. (2001). Document language models, query models, risk
minimization information retrieval. Proceedings SIGIR, pp. 111119.
Lavrenko, V. (2004). Generative Theory Relevance. Ph.D. thesis, University Massachusetts Amherst.
Lavrenko, V., Allan, J., DeGuzman, E., LaFlamme, D., Pollard, V., & Thomas, S. (2002).
Relevance models topic detection tracking. Proceedings Human
Language Technology Conference (HLT), pp. 104110.
Lavrenko, V., & Croft, W. B. (2001). Relevance-based language models. Proceedings
SIGIR, pp. 120127.
Lavrenko, V., & Croft, W. B. (2003). Relevance models information retrieval. Croft,
& Laerty (Croft & Laerty, 2003), pp. 1156.
Leuski, A. (2001). Evaluating document clustering interactive information retrieval.
Proceedings Tenth International Conference Information Knowledge
Management (CIKM), pp. 3340.
Leuski, A., & Allan, J. (1998). Evaluating visual navigation system digital library.
Proceedings Second European conference research advanced technology
digital libraries (ECDL), pp. 535554.
Liu, X., & Croft, W. B. (2004). Cluster-based retrieval using language models. Proceedings
SIGIR, pp. 186193.
Liu, X., & Croft, W. B. (2006a). Experiments retrieval optimal clusters. Tech. rep. IR478, Center Intelligent Information Retrieval (CIIR), University Massachusetts.
Liu, X., & Croft, W. B. (2006b). Representing clusters retrieval. Proceedings
SIGIR, pp. 671672. Poster.
393

fiKurland & Krikon

Liu, X., & Croft, W. B. (2008). Evaluating text representations retrieval best
group documents. Proceedings ECIR, pp. 454462.
Mei, Q., Shen, X., & Zhai, C. (2007). Automatic labeling multinomial topic models.
Proceedings 13th ACM SIGKDD international conference, pp. 490499.
Mihalcea, R. (2004). Graph-based ranking algorithms sentence extraction, applied
text summarization. Companion Volume Proceedings 42nd Annual
Meeting Association Computational Linguistics, pp. 170173.
Mihalcea, R., & Tarau, P. (2004). TextRank: Bringing order texts. Proceedings
EMNLP, pp. 404411. Poster.
Otterbacher, J., Erkan, G., & Radev, D. R. (2005). Using random walks question-focused
sentence retrieval. Proceedings Human Language Technology Conference
Conference Empirical Methods Natural Language Processing (HLT/EMNLP),
pp. 915922.
Palmer, C. R., Pesenty, J., Veldes-Perez, R., Christel, M., Hauptmann, A. G., Ng, D., &
Wactlar, H. D. (2001). Demonstration hierarchical document clustering digital
library retrieval results. Proceedings 1st ACM/IEEE-CS joint conference
digital libraries, p. 451.
Ponte, J. M., & Croft, W. B. (1998). language modeling approach information retrieval.
Proceedings SIGIR, pp. 275281.
Preece, S. E. (1973). Clustering output option. Proceedings American Society
Information Science, pp. 189190.
Seo, J., & Croft, W. B. (2010). Geometric representations multiple documents.
Proceedings SIGIR, pp. 251258.
Shanahan, J. G., Bennett, J., Evans, D. A., Hull, D. A., & Montgomery, J. (2003). Clairvoyance Corporation experiments TREC 2003. High accuracy retrieval
documents (HARD) track. Proceedings Twelfth Text Retrieval Conference
(TREC-12), pp. 152160.
Si, L., Jin, R., Callan, J., & Ogilvie, P. (2002). language modeling framework resource
selection results merging. Proceedings 11th International Conference
Information Knowledge Management (CIKM), pp. 391397.
Tao, T., Wang, X., Mei, Q., & Zhai, C. (2006). Language model information retrieval
document expansion. Proceedings HLT/NAACL, pp. 407414.
Tao, T., & Zhai, C. (2006). Regularized esitmation mixture models robust pseudorelevance feedback. Proceedings SIGIR, pp. 162169.
Tombros, A., Villa, R., & van Rijsbergen, C. (2002). eectiveness query-specic hierarchic clustering information retrieval. Information Processing Management,
38 (4), 559582.
Treeratpituk, P., & Callan, J. (2006). Automatically labeling hierarchical clusters.
Proceedings sixth national conference digital government research, pp. 167
176.
394

fiA Language Model Approach Ranking Query-Specific Document Clusters

van Rijsbergen, C. J. (1979). Information Retrieval (second edition). Butterworths.
Voorhees, E. M. (1985). cluster hypothesis revisited. Proceedings SIGIR, pp.
188196.
Voorhees, E. M. (2002). Overview TREC 2002 question answering track.
Eleventh Text Retrieval Conference TREC-11, pp. 115123.
Wei, X., & Croft, W. B. (2006). LDA-based document models ad-hoc retrieval.
Proceedings SIGIR, pp. 178185.
Willett, P. (1985). Query specic automatic document classication. International Forum
Information Documentation, 10 (2), 2832.
Xu, J., & Croft, W. B. (1996). Query expansion using local global document analysis.
Proceedings SIGIR, pp. 411.
Yang, L., Ji, D., Zhou, G., Nie, Y., & Xiao, G. (2006). Document re-ranking using cluster
validation label propagation. Proceedings CIKM, pp. 690697.
Zamir, O., & Etzioni, O. (1998). Web document clustering: feasibility demonstration.
Proceedings SIGIR, pp. 4654.
Zhai, C., & Laerty, J. D. (2001). study smoothing methods language models
applied ad hoc information retrieval. Proceedings SIGIR, pp. 334342.

395

fiJournal Artificial Intelligence Research 41 (2011) 477526

Submitted 11/10; published 08/11

Probabilistic Framework Learning Kinematic Models
Articulated Objects
Jurgen Sturm
Cyrill Stachniss
Wolfram Burgard

sturm@informatik.uni-freiburg.de
stachnis@informatik.uni-freiburg.de
burgard@informatik.uni-freiburg.de

Department Computer Science,
University Freiburg,
Georges-Koehler-Allee 79, 79100 Freiburg, Germany

Abstract
Robots operating domestic environments generally need interact articulated
objects, doors, cabinets, dishwashers fridges. work, present novel,
probabilistic framework modeling articulated objects kinematic graphs. Vertices
graph correspond object parts, edges model kinematic
relationship. particular, present set parametric non-parametric edge models
robustly estimated noisy pose observations. furthermore
describe estimate kinematic structure use learned kinematic
models pose prediction robotic manipulation tasks. finally present
learned models generalized new previously unseen objects. various
experiments using real robots different camera systems well simulation,
show approach valid, accurate efficient. Further, demonstrate
approach broad set applications, particular emerging fields mobile
manipulation service robotics.

1. Introduction
Service robots operating domestic environments typically faced variety
objects deal manipulate fulfill task.
complicating factor many relevant objects articulated, doors,
windows, also pieces furniture like cupboards, cabinets, larger objects
garage doors, gates cars. Understanding spatial movements individual parts
articulated objects essential service robots allow plan relevant actions
door-opening trajectories assess whether actually successful.
work, investigate problem learning kinematic models articulated objects
using robotic manipulation tasks. illustrating example, consider Fig. 1
mobile manipulation robot interacts various articulated objects kitchen
environment, learns kinematic properties infers kinematic structure.
problem formulated follows: Given sequence pose observations
object parts, goal learn compact kinematic model describing whole articulated object. kinematic model define (i) connectivity parts,
(ii) number degrees freedom object, (iii) kinematic function
articulated object. result, obtain generative model used
robot generating reasoning future unseen configurations.

c
2011
AI Access Foundation. rights reserved.

fiSturm, Stachniss, & Burgard

revolute

prismatic

Figure 1: service robot learns kinematic models articulated objects kitchen environment.

contribution paper novel approach enables real robot learn
kinematic models articulated objects sensor data. models describe
kinematics object include part connectivity, degrees freedom objects,
kinematic constraints. utilize models subsequently control motion
manipulator. Furthermore, show robot improve model learning exploiting
past experience. Finally, show framework generalized deal
closed-chain objects, i.e., objects contain kinematic loops.
past, several researchers addressed problem handle doors drawers
(Jain & Kemp, 2009a; Klingbeil, Saxena, & Ng, 2009; Meeussen et al., 2010; Wieland,
Gonzalez-Aguirre, Vahrenkamp, Asfour, & Dillmann, 2009; McClung, Zheng, & Morrell,
2010). approaches, however, either entirely model-free assume substantial knowledge model parameters. Whereas model-free approaches
release designers providing a-priori model information, knowledge objects articulation properties supports state estimation, motion prediction,
planning.

478

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

pose
observations

model
fitting

candidate
link models

structure
selection

kinematic
graph

Figure 2: Schematic overview approach. robot observes articulated object
different poses. uses observations generate set candidate models,
selects kinematic structure maximizes posterior probability.

previous work, introduced simpler version probabilistic framework
modeling articulated objects, presented estimators fitting link models, showed
efficiently find kinematic structure kinematic trees (Sturm, Pradeep, Stachniss,
Plagemann, Konolige, & Burgard, 2009). observations, used motion capture studio
data simulation. Further, used stereo camera system learning models
kitchen furniture (Sturm, Konolige, Stachniss, & Burgard, 2010). described
manipulation robot learn kinematic models direct interaction articulated
objects, improve time learning experience (Sturm, Jain, Stachniss,
Kemp, & Burgard, 2010). work, present unified framework learning kinematic models articulated objects extended set experiments. contrast
previous work, generalize approach kinematic trees general kinematic
graph objects add strategy efficiently find locally optimal graph. this,
becomes possible model articulated objects contain kinematic loops. Furthermore,
finding effective number degrees freedom (DOFs) articulated object directly
follows approach. general software framework implements presented
approach available online1 BSD license, including source code, documentation,
tutorials.
paper organized follows. Section 2, introduce unified framework
modeling kinematics articulated objects. Section 3, present several extensions
including exploitation prior information, kinematic loops, estimation
degrees freedom. Section 4, describe different options perceive control
motion articulated objects. analyze approach extensive set experiments
simulation real robots report results Section 5. Finally,
conclude article discussion related work Section 6.

2. Probabilistic Framework Articulated Objects
define articulated object consist multiple object parts one
passively actuated mechanical links them. links constrain motion parts. example, hinge door constrains door move arc,
shaft drawer constrains drawer move line segment. simplest
articulated object consists two rigid parts one mechanical link. complex ob1. http://www.ros.org/wiki/articulation

479

fiSturm, Stachniss, & Burgard

jects may consist several articulated parts, like door door handle, car
several doors, windows, wheels.
Fig. 2 gives high-level overview proposed system. robot observes pose
articulated object manipulated. relative motion two parts,
fits different candidate models describe different mechanical links. set
candidate link models, selects kinematic structure best explains observed
motion, i.e., kinematic structure maximizes posterior probability.
2.1 Notation
assume robot, external object, observes pose articulated object
consisting p object parts. denote true pose object part {1, . . . , p}
vector xi SE (3) representing 3D pose part (including position orientation),
SE (3) = R3 SO(3) stands special Euclidean group. Further, refer
full object pose (containing poses parts) vector x1:p = (x1 , . . . , xp )T .
Two object parts j related relative transformation ij = xi xj .
use referring motion composition operator inverse2 .
denote kinematic link model two object parts j Mij
associated parameter vector ij Rkij , kij N0 denotes number parameters
model describing link. kinematic graph G = (VG , EG ) consists set
vertices VG = {1, . . . , p}, corresponding parts articulated object, set
undirected edges EG VG VG describing kinematic link two object parts.
edge (ij), corresponding kinematic link model Mij parameter vector ij
associated.
kinematic link models consider (except trivial rigid link)
latent variable qij Cij Rd ij describes configuration link. door,
opening angle. Cij stands configuration space link. variable
dij represents number DOFs mechanical link two parts.
object articulated, robot observes object pose; denote
n
n-th pose observation object part yi . Correspondingly, denote n-th pose
n
1 , . . . , yn ).
observation parts y1:p sequence n pose observations Dy = (y1:p
1:p
n
Further, refer Dzij = (z1ij , . . . , zij ) sequence relative transformations
zij = yi yj robot observed far edge (ij).
Fig. 3a depicts graphical model simple articulated object consists two
object parts. use so-called plate notation simplify notation
graphical model. Here, nodes inside rectangle (the plate) copied n times,
i.e., time step object observed. time steps,
articulated object takes particular configuration q12 defining together model
parameters noise-free relative transformation 12 noise-free pose
object parts x1 x2 . that, robot observes noisy poses y1 y2 ,
infers virtual measurement z12 = y1 y2 . model learning,
robot infers observations link model M12 link parameters 12 .
2. E.g., poses x1 , x2 R44 represented homogeneous matrices, operators correspond
matrix multiplication x1 x2 = x1 x2 inverse multiplication x1 x2 = (x1 )1 x2 , respectively.

480

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

M12 , 12

qt12
xt1

q
xt2

x1

x2

x1

x2
M12 , 12

t12
y1t

y2t

M12 , 12

zt12
1, . . . ,

(a) Full graphical model

(b) Reduced graphical model

(c) Kinematic graph

Figure 3: (a) Graphical model articulated object consisting two parts x1 x2 ,
observed time steps. model M12 , 12 shared time
steps. (b) shows simplified version graphical model. (c) shows
corresponding kinematic graph.

reduced version graphical model depicted Fig. 3b. improve readability,
leave nodes, i.e., node corresponding relative transformation 12
observation nodes y1 , y2 , z12 . Instead, visualize dependency x1
x2 direct link label corresponding model. Further, collapse
configuration link single node corresponding configuration whole
object. Finally, refer kinematic graph graph models connectivity
object parts, depicted Fig. 3c).
2.2 Problem Definition
problem consider find likely kinematic graph G given
sequence pose observations Dy articulated object. Bayesian terms, means
aim finding kinematic graph G maximizes posterior probability
observing poses Dy articulated object, i.e.,
G = arg max p(G | Dy ).

(1)

G

However, finding global maximum posterior p(G | Dy ) difficult,
highly non-convex function high-dimensional parameter space consisting discrete
well continuous dimensions encode kinematic structure kinematic
properties, respectively.
Therefore, section, consider simplified problem. restrict structure
space kinematic trees only, focus general problem Section 3. Kinematic
481

fiSturm, Stachniss, & Burgard

trees property individual edges independent other.
result, estimate link parameters independently also independent
kinematic structure. means learning local kinematic relationship
n
object parts j, relative transformations Dzij = (z1ij , . . . , zij )
relevant estimating edge model. this, rephrase maximization
problem (1) kinematic trees
G = arg max p(G | Dz )

(2)

G

= arg max p({(Mij , ij ) | (ij) EG } | Dz ).
G

= arg max
p(Mij , ij | Dzij ).
G

(3)
(4)

(ij)EG

latter transformation follows mutual independence edges kinematic
trees.
important insight work kinematic link models representing
edges estimated independently actual structure kinematic tree.
result, problem solved efficiently: first, estimate link models
possibles edges (ij) VG VG :
(Mij , ij ) = arg max p(Mij , ij | Dzij ).

(5)

Mij ,ij

link models independent independent whether
actually part kinematic structure EG . Second, given link models, estimate
kinematic structure. two-step process also visualized Fig. 2.
Solving (5) still two-step process (MacKay, 2003): first level inference,
assume particular model (e.g., like revolute model) true, estimate
parameters. applying Bayes rule, may write
ij = arg max p(ij | Dzij , Mij )

(6)

ij

= arg max

p(Dzij | ij , Mij ) p(ij | Mij )
p(Dzij | Mij )

ij

.

(7)

term p(ij | Mij ) defines model-dependent prior parameter space,
assume work uniform, thus may dropped. Further, ignore
normalizing constant p(Dzij | Mij ), influence choice parameter
vector. results
ij = arg max p(Dzij | ij , Mij ),

(8)

ij

means fitting link model observations corresponds problem
maximizing data likelihood.

482

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

second level inference, need compare probability different models
given data select model highest posterior:
Z
Mij = arg max p(Mij , ij | Dzij ) dij .
(9)
Mij

Computing exact posterior probability model general difficult, therefore
use work Bayesian information criterion (BIC) selecting best model
according (9).
result inference, obtain edge (ij) VG VG model Mij
parameter vector ij , best describes motions Dzij observed two
parts. denote set possible link models
= {(Mij , ij ) | (ij) VG VG }.

(10)

Given maximum-likelihood estimate links, efficiently estimate
kinematic structure EG VG VG . this, aim finding subset,
maximizes posterior probability resulting kinematic graph, i.e.,
Z
EG = arg max p(EG , | Dz ) dM.
(11)
EG

solve equation maximizing BIC possible structures EG , using
maximum-likelihood estimate approximating integral.
this, provide efficient way solve (2), first fitting models data,
selecting best model link, finally estimating kinematic structure
whole articulated object. Section 2.3 Section 2.7, show solve
model fitting problem (8) model selection problem (9) efficiently robustly
noisy observations. Section 2.8, show one efficiently solve (11),
given link models. Section 3.2, show solution kinematic trees
generalized general kinematic graphs, including kinematic structures containing
loops.
2.3 Observation Model
beginning, consider simple objects consisting p = 2 rigid parts, drop
ij indices increase readability. consider case robot observed
sequence n relative transformations Dz = (z1 , . . . , zn ) two adjacent rigid
parts articulated object. assume presence Gaussian noise
measurements zn zero mean covariance z R66 .
Further, assume small fraction observations real outliers cannot
explained Gaussian noise assumption alone. outliers may result
poor perception, bad data association, sensor failures hard modeled
explicitly. outliers related true value = x1 x2 all, assume
come uniform prior, i.e., assume constant likelihood p(zoutlier ) = const.
One think latent variable v {0, 1} indicating whether observation

483

fiSturm, Stachniss, & Burgard

inlier (v = 1) outlier (v = 0). Further, denote probability drawing
outlier, i.e., p(v = 0) = . full observation model becomes

+ N (0, z ) v = 1
z
.
(12)
U
v = 0
resulting data likelihood single observation z thus mixture Gaussian
uniform distribution mixing constant :
p(z | , ) = (1 )p(z | v = 1) + p(z | v = 0).

(13)

Note general neither true transformation outlier ratio directly
observable, thus need estimated data. comparing models
different outlier ratios, assume global prior p() exp(w) w
weighting constant, thereby favor models fewer outliers models
outliers. resulting data likelihood observation z given true value thus
becomes:
p(z | ) = p(z | , )p().

(14)

2.4 Candidate Models
considering set objects relevant service robot, one quickly realizes
joints many objects belong generic model classes. particular, revolute
prismatic joints used often, although objects composed
mechanical linkages, example spherical joints, screws, two-bar links. Examples
revolute joints include doors, door handles, windows. also includes doors
dishwashers, microwave ovens washing machines. Examples articulated objects
belonging prismatic class include drawers, sliding doors, window blinds. However,
also objects different mechanical linkages, garage doors twobar office lamps. motivates use set candidate models, well suited
describing kinematic properties particular class articulated links. candidate
set consists parametrized non-parametrized models, particular, includes model
revolute joints (Mrevolute ), prismatic joints (Mprismatic ), rigid transformations
(Mrigid ). Additionally, may articulations correspond standard
motions, consider parameter-free model (MGP ). model joints using
combination dimensionality reduction Gaussian process regression.
framework, model class defines conditional probability distribution p( |
q, M, ) p(q | , M, ) means forward kinematic function fM, (q) =
1
inverse kinematic function fM,
(z) = q. means assume link
models deterministic, attribute noise measurement noise observations
object parts, i.e., means observation model p( | z) defined Section 2.3.
Since prior information nature connection two
rigid parts, aim fit single model, instead aim fitting
candidate models observed data, select best model set.

484

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

candidate model

rigid model
prismatic model
revolute model
Gaussian process model

DOFs

0
1
1
1, . . . , 5

parameters
k
6
9
12
1 + + 6n

Table 1: Overview different candidate models articulated links.
2.5 Model Fitting using Maximum Likelihood Consensus
estimating parameters above-mentioned models, need find
parameter vector Rk maximizes data likelihood given model, i.e.,
= arg max p(Dz | M, ).

(15)



presence noise outliers, finding right parameter vector minimizes (15)
trivial, least squares estimation sensitive outliers thus sufficient given
observation model. Therefore, use MLESAC (maximum likelihood consensus)
algorithm introduced Torr Zisserman (2000). estimate initial kinematic
parameters minimal set randomly drawn samples observation sequence
refine using non-linear optimization data likelihood.
MLESAC procedure model works follows: First, generate guess
parameter vector (15) minimal set samples Dz . guess,
compute data likelihood whole observation sequence Dz product
data
p(Dz | M, ) =

n


p(zt | M, ).

(16)

t=1

repeat sampling step fixed number iterations, finally select parameter vector maximizing (16). initial guess, apply non-linear optimization
data likelihood refine parameter vector using Broyden-Fletcher-Goldfarb-Shanno
(BFGS) optimization, quasi-Newton method function maximization.
maximization data likelihood, MLESAC iteratively also estimates outlier
ratio , using Expectation Maximization algorithm.
following, show link models (i) estimate parameter
vector minimal sample set observations, (ii) estimate transformation z given
configuration q, (iii) estimate configuration q given transformation z. brief
overview model candidates given Table 1.
2.5.1 Rigid Model
parametrize rigid link fixed relative transformation two object parts.
Thus, parameter vector k = 6 dimensions. sampling consensus step,
draw single observation z training data Dz gives us initial guess
485

fiSturm, Stachniss, & Burgard

parameter vector . parameter vector thus corresponds estimated fixed
relative transformation two parts. rigid transformation model,
forward kinematics function equals parameter vector corresponds estimated
fixed relative transform two parts:
fMrigid , (q) = .

(17)

rigid model zero DOFs (d = 0), inverse kinematic function needed.
2.5.2 Prismatic Model
Prismatic joints move along single axis, thus one-dimensional configuration
space. prismatic model describes translation along vector unit length e R3
relative fixed origin SE (3). results parameter vector = (a; e)
k = 9 dimensions.
estimating parameters, sample two observations training data.
this, pick transformation first sample origin normalized
vector prismatic axis e.
configuration q R encodes distance origin along direction
motion e. forward kinematics function prismatic model Mprismatic
fMprismatic , (q) = qe.

(18)

Let trans() function removes rotational components. inverse kinematic
function becomes
1
fM
prismatic , (z) =< e, trans(a z) >,

(19)

< , > refers dot product.
2.5.3 Revolute Model
revolute model describes motion revolute joint, i.e., one-dimensional motion
along circular arc. parametrize model center rotation c SE (3),
rigid transformation r SE (3), center moving part. yields parameter
vector = (c; r) k = 12 dimensions.
revolute model, sample three observations zi , zj zk training
data. First, estimate plane spanned three points; plane normal
parallel rotation axis. Second, compute circle center intersection
perpendicular lines line segments three observations. Together
rotation axis, gives us center rotation c. Finally, estimate rigid
transformation r circle first sample.
forward kinematic function, obtain revolute links
fMrevolute , (q) = c RotZ (q) r,

(20)

RotZ (q) denotes rotation around Z-axis q. Thus, q R specifies angle
rotation. estimating configuration revolute joint use
1
1
fM
revolute , (z) = RotZ ((z c) r),

Rot1
Z () gives rotation around Z-axis.
486

(21)

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

2.5.4 Gaussian Process Model
Although rigid transformations combination revolute prismatic joints might
seem first glance sufficient huge class kinematic objects, many realworld objects cannot described single shifting rotation axis. Examples
objects include garage doors office table lamps, also furniture whose joints aged
became loose.
Therefore, provide additionally non-parametric model able describe
general kinematic links. model based dimensionality reduction discovering latent manifold configuration space Gaussian process regression
learning generative model. Consider manifold described observations
Dz two rigid bodies. Depending number DOFs link, data
samples lie close d-dimensional manifold 1 6 non-linearly
embedded SE (3).
many different dimensionality reduction techniques principal component analysis (PCA) linear manifolds, Isomap locally linear embedding (LLE)
non-linear manifolds (Tenenbaum, de Silva, & Langford, 2000; Roweis & Saul, 2000).
experiments, used PCA LLE dimensionality reduction. PCA
advantage robust noise near-linear manifolds, LLE
general also model strongly non-linear manifolds.
general idea use dimensionality reduction technique obtain
1

inverse kinematics function fM
GP : SE (3) R . result, assign configurations
observations, i.e.,
1
fM
GP (z) = q.

(22)

assignments observations configurations used learn forward
kinematics function fMGP , () observations. Except linear actuators, expect
function strongly non-linear.
flexible approach solving non-linear regression problems given noisy observations Gaussian processes (GPs). One main features Gaussian process
framework observed data points explicitly included model. Therefore,
parametric form fMGP : Rd SE (3) needs specified. Data points added
GP time, facilitates incremental online learning. model,
aim learn GP fits dependency
fMGP (q) + = z

(23)

unknown forward model underlying articulated link consideration.
assume homoscedastic noise, i.e., independent identically, normally distributed noise
terms N (0, z ). simplicity, train 12 independent Gaussian processes
free components homogeneous 4 4 transformation matrix. consequence
over-parametrization, predicted transformation matrices necessarily valid.
practice, however, close valid transformation matrices,
found using ortho-normalization via singular value decomposition. approach, use
standard choice covariance function, squared exponential. describes

487

fiSturm, Stachniss, & Burgard

relationship two configurations qi qj configuration space


1
2
1
k(qi , qj ) = f exp (qi qj ) (qi qj ) ,
2

(24)

f2 signal variance, 1 = diag(l1 , . . . , ld ) diagonal matrix
length-scale parameters. results (1 + d)-dimensional hyper-parameter vector
= (f2 , l1 , . . . , ld ). GPs data-driven, require training data making predictions. Therefore, count data samples parameters model,
number parameters becomes k = (1 + d) + 6n, n = |Dz | number
observations. refer interested reader text book Rasmussen Williams
(2006) details GP regression.
Note GP link model directly generalizes higher-dimensional configuration
spaces, i.e., > 1: dimensionality reduction observations SE (3)
configurations Rd , learn Gaussian process regression learns
mapping configuration space Rd back transformations SE (3). Note
GP model present similar GPLVM model introduced Lawrence
(2005). contrast GPLVM, optimize latent configurations maximizing
data likelihood. would invalidate inverse kinematics function (22), limits
GPLVM model map latent space data space. approach,
also infer configuration new relative transformations available training.
2.6 Model Evaluation
evaluate well single observation z explained model, evaluate
p(z | M, ). configuration latent, i.e., directly observable robot,
integrate possible values q, i.e.,
Z
p(z | M, ) = p(z | q, M, )p(q | M, ) dq.
(25)
assumption DOFs link independent other,
configuration state q likely another (or equivalently, p(q | M, )
uniformly distributed), may write
p(q | M, ) n ,

(26)

n = |Dz | number observations far, thus number estimated
configurations d-dimensional configuration space. this, (25) simplified

Z
p(z | M, ) n p(z | q, M, ) dq.
(27)
assume p(z | q, M, ) uni-modal distribution, approximation
integral evaluate estimated configuration q given observation z using
inverse kinematics function model consideration, i.e.,
1
q = fM,
(z).

488

(28)

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

using forward
configuration, compute expected transformation
kinematics function model,
= fM, (q).


(29)

efficiently compute
Given observation z expected transformation ,
data likelihood (27) using observation model (14)

p(z | M, ) n p(z | ).

(30)

Note approximation integral based forward inverse kinematics
model corresponds projection noisy observations onto model. Finally,
marginal data likelihood whole observation sequence becomes

p(Dz | M, ) =
p(z | M, ).
(31)
zDz

2.7 Model Selection
fitted model candidates observation sequence Dz , need select
model explains data best. Bayesian model selection, means
need compare posterior probability models given data
Z
p(Dz | M, )p( | M)p(M)
p(M | Dz ) =
d.
(32)
p(Dz )
evaluation model posterior general difficult, approximated
efficiently based Bayesian information criterion (BIC) (Schwarz, 1978). denote
k number parameters current model consideration, n
number observations training data. Then, BIC defined
BIC(M) = 2 log p(Dz | M, ) + k log n,

(33)

maximum likelihood parameter vector. Model selection reduces
selecting model lowest BIC, i.e.,
= arg min BIC(M).

(34)



refer interested reader work Bishop (2007) information
BIC.
2.8 Finding Connectivity
far, ignored question connectivity described evaluate select
model single link two parts object only. section, extend
approach efficiently find kinematic trees articulated objects consisting multiple
parts.
adopt connectivity model Featherstone Orin (2008) modeling
kinematic structure undirected graph G = (VG , EG ). nodes VG graph
489

fiSturm, Stachniss, & Burgard

correspond poses individual object parts, edges EG correspond
links parts. re-introduce ij-indices, i.e., use Dzij
refer observations link (ij), Dz refer observations whole
articulated object. Dz thus contains observations edges graph G, i.e.,
Dz = {Dzij | (ij) EG }. previous section, established algorithm fits
selects given edge (ij) graph corresponding link model Mij parameter
vector ij . Given this, need select kinematic structure EG , i.e.,
link models actually present articulated object consideration.
moment, consider kinematic tree mechanisms, i.e., mechanisms
without kinematic loops. Now, consider fully connected graph p vertices, i.e., one
vertex object part articulated object. set possible kinematic trees
articulated object given spanning trees graph. endeavor
explicitly computing, evaluating, reasoning kinematic trees, however,
tractable practice.
therefore seek find kinematic structure EG maximizes posterior
stated previously (11),
EG = arg max p(EG | Dz )

(35)

EG

= arg max p({(Mij , ij ) | (ij) EG } | Dz )

(36)

EG

= arg max
EG

= arg max
EG



p(Mij , ij | Dz )

(37)

log p(Mij , ij | Dz ).

(38)

(ij)EG

X
(ij)EG

Note independence assumption individual links kinematic
trees, posterior kinematic model whole object (36) written
product posteriors individual links (37). taking logarithm (38),
structure selection problem takes form solved efficiently. key insight
kinematic tree maximizes (38) corresponds problem selecting
minimum spanning tree fully connected graph edge costs corresponding
negative log posterior,
costij = log p(Mij , ij |Dzij ),

(39)

approximate BIC value. sum edge costs corresponds
negative log posterior kinematic tree, minimum spanning tree thus maximizes posterior (38). best kinematic structure found efficiently, i.e.,
O(p2 log p) time, using example Prims Kruskals algorithm finding minimum
spanning trees (Cormen, Leiserson, Rivest, & Stein, 2001).

3. Framework Extensions
approach described far enables robot learn kinematic models articulated
objects scratch. following, consider three extensions. first extension
490

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

enables robot exploit priors learned previous interactions learning new
models. Second, generalize framework general kinematic graphs, i.e., consider
additionally objects contain closed kinematic chains. Third, show estimating
number DOFs articulated objects follows directly approach.
3.1 Learning Exploiting Priors
Using approach described above, robot always starts learning model scratch
observes movements new articulated object. learning perspective,
may seen unsatisfactory since articulated objects encountered man-made
environments belong different classes similar parameters. example,
specific office kitchen, many cabinet doors open way, i.e.,
radius rotation axis. Furthermore, countries size furniture
standardized. Thus, robot operating environments extended periods
time significantly boost performance learning priors space possible
articulated object models.
section describes approach learning priors articulated objects
means exploiting early possible manipulating previously unseen
articulated object. addition previous section, explicitly want transfer model
information contained already learned models newly seen articulated objects. key
idea identify small set representative models articulated objects
utilize prior information increase prediction accuracy handling new
objects.
keep notation simple, consider case previously encountered
two articulated objects consisting two parts thus single link only. observed
motion given two observation sequences Dz,1 Dz,2 . question whether
trajectories described two distinct models M1 M2 joint
model M1+2 . first case, split posterior two models mutually
independent, i.e.,
p(M1 , M2 | Dz,1 , Dz,2 ) = p(M1 | Dz,1 )p(M2 | Dz,2 ).

(40)

latter case, trajectories explained single, joint model M1+2
parameter vector 1+2 , estimated joint data Dz,1 Dz,2 . future
reference, denote corresponding posterior probability
p(M1+2 | Dz,1 , Dz,2 ).

(41)

determine whether joint model better two separate models comparing posterior probabilities (40) (41), i.e, evaluating
p(M1+2 | Dz,1 , Dz,2 ) > p(M1 | Dz,1 )p(M2 | Dz,2 ).

(42)

expression efficiently evaluated using BIC follows. joint model
learned n = n1 + n2 data points, using k parameters, data likelihood
L = p(M1+2 | Dz,1 , Dz,2 ), two separate models learned n1 n2

491

fiSturm, Stachniss, & Burgard

samples, using k 1 k 2 parameters, data likelihoods L1 = p(Dz,1 | M1 )
L2 = p(Dz,2 | M2 ), respectively. Accordingly, check whether
BIC(M1+2 | Dz,1 , Dz,2 ) < BIC(M1 | Dz,1 ) + BIC(M2 | Dz,2 )

(43)

i.e., whether
2 log L + k log n < 2 log(L1 L2 ) + k 1 log n1 + k 2 log n2 .

(44)

Informally, merging two models one beneficial joint model explain data
equally well (i.e., L L1 L2 ), requiring single set parameters.
two trajectories considered, one evaluate possible assignments
trajectories models select assignment highest posterior.
quickly becomes intractable due combinatorial explosion, use approximation
consider trajectories sequentially order robot observes them. check
whether merging new trajectory one existing models leads higher
posterior compared adding new model trajectory set previously
encountered models.
identified set models prior information, exploit knowledge
making better predictions observing far unseen articulated object. Consider
situation partial trajectory new object observed. exploit
prior information, proceed exactly before. compute compare posteriors
according (44), treating newly observed data points new model respectively
merging one w previously identified models evaluating
p(Mnew , M1 , . . . , Mw ) < max p(M1 , . . . , Mj+new , . . . , Mw ).
j=1,...,w

(45)

newly observed data merged existing model, parameter vector
estimated much larger dataset Dz,j Dz,new instead Dz,new leads better
estimation. Note step carried observation new sequence.
Thus, currently manipulated object ceases explained known models,
method instantaneously creates new model. successful object manipulation,
model serves additional prior information future.
3.2 Closed Kinematic Chains
Although articulated objects connectivity kinematic trees, exist
mechanisms containing closed kinematic chains (Featherstone & Orin, 2008). intuitive
example closed-loop system robot opens door manipulator.
robot door described individually kinematic tree using
approach, combined system robot, door floor creates kinematic loop.
Another example humanoid robot multiple contact points, e.g., standing
feet, robot manipulates object two arms (Sentis, Park, & Khatib,
2010). describe closed-loop systems, need extend approach.
Recall finding kinematic structure Section 2.8, established correspondence finding graph maximizes posterior probability. that,
needed compute data likelihood graph based edge constraints,
492

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

easy kinematic trees. case, links evaluated independently other.
However, computing data likelihood kinematic graph based edge constraints
difficult. results complex (joint) prediction poses
object parts involved kinematic loop. general, chained predictions
relative transformations object parts lead globally consistent prediction, needed compute overall data likelihood case closed kinematic
chains.
problem, however, closely related loop-closing graph-based formulation
simultaneous localization mapping (SLAM) problem (Lu & Milios, 1997; Dellaert,
2005; Frese, 2006; Grisetti, Stachniss, & Burgard, 2009). type problem, closedform solutions exist simple cases. popular solution general case
iterative optimization approaches deal underlying non-linear least squares
problem.
obtain consistent pose estimation whole graph, use optimization
engine HOG-Man Grisetti, Kummerle, Stachniss, Frese, Hertzberg (2010), originally
designed solve SLAM problem. generate input graph HOG-Man,
proceed follows. add vertex object part representing initial pose
x01 , . . . , x0n , estimate (arbitrary) spanning tree graph. Then,
link model Mij graph G, add edge constrains relative transformation
(in SLAM, corresponds
x0i x0j expected transformation
ij
observation). optimization approach compute set new poses x1 , . . . , xn
line constraints sense best prediction terms
squared error obtained given links (in SLAM, corresponds
corrected trajectory robot).
pose observations yi , assume Gaussian noise zero mean covariance
, i.e.,
yi = xi +
N (0, ).

(46)
(47)

data likelihood single object part observed pose expected
pose x given kinematic graph G configuration q becomes


1
1
p(yi | G, q) exp (xi yi ) (xi yi ) .
(48)
2
Using this, global data likelihood articulated object particular configuration
computed product likelihoods individual object parts, i.e.,

p(y1:p | G, q) =
p(yi | G, q).
(49)
i1,...,p

configuration q articulated object latent thus known, need
integrate possible configurations, i.e., calculate
Z
p(y1:p | G) = p(y1:p | G, q)p(q | G)dq.
(50)

493

fiSturm, Stachniss, & Burgard

Similar (25), approximate integral evaluating likely configuration q articulated object. assume configurations q uniformly
distributed, i.e., p(q | G) n , n number pose observations
total number DOFs articulated object. data likelihood pose
observation y1:p becomes
p(y1:p | G) n p(y1:p | G, q).

(51)
n

1 , . . . , ) whole articulated
data likelihood observation sequence Dy = (y1:p
1:p
object


p(Dy | G)
n p(y1:p
| G, qi )
(52)
i1,...,n

= n nD




p(y1:p
| G, qi ).

(53)

i1,...,n

data likelihood used select best kinematic structure. Note
principle, possible graphs need evaluated super-exponential
number object parts, polynomial number template models. contrast,
finding exact solution case kinematic trees polynomial complexity
O(mp2 ). Obviously, massive set possible graph structures fully evaluated
small articulated objects template models.
absence efficient exact solution, propose efficient approximation
able find locally best graph initial guess using randomized search
strategy polynomial time. idea given spanning tree initial solution
evaluate graphs neighborhood current structure, i.e., graphs whose
topology similar current one, e.g., adding removing one edge time.
see experimental section, heuristic able find optimal (or nearoptimal) graph structure cases. Additionally, guarantee
randomized search strategy never gets worse initial solution, i.e., case
spanning tree.
3.3 Finding Number DOFs
current configuration articulated object given stacked vector
individual configurations articulated links, i.e.,


q1
q
2
qlinks = ..
(54)
.
qDlinks
. question is, whether articulated object actually many DOFs
sum DOFs individual links might suggest. Clearly, case articulated
object kinematic tree, DOFs object
P articulated object directly equals
sum DOFs links links = (ij)EG ij links actuated
494

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

(a)

(b)

Figure 4: Example open closed kinematic chain. Whereas open chain (a)
three DOFs, closed chain (b) also single DOF.

independently other. However, articulated objects containing loops, finding
number DOFs articulated object trivial.
example, consider object Fig. 4a consists four object parts
total three DOFs. contrast, object Fig. 4b consists four object parts,
connected four revolute links form loop. four links single
DOF, therefore configuration vector defining configuration links
qlinks = (q1 , q2 , q3 , q4 ) R4 . Yet, overall system single DOF:
first joint brought particular configuration, joints fixed well,
result loop closure. means object configuration qobject R
single dimension, thus object configuration space one-dimensional manifold
embedded four-dimensional link configuration space.
Finding mapping high-dimensional link configuration space RD links
lower-dimensional object configuration space RD object example achieved using
PCA linear manifolds, LLE ISOMAP non-linear manifolds. case
PCA, results finding projection matrix P RD object links describing mapping
qobject = P qlinks

(55)

Recall (53), number DOFs strong influence data likelihood
configuration, higher dimensional configuration space results lower
likelihood single configuration. result, model fewer DOFs preferred
model DOFs. time, additional parameters need estimated
dimension reduction, parameters also model parameters thus
need considered model selection.
Informally speaking, kinematic graph fewer DOFs explains data equally
well, higher data likelihood thus favored structure selection
step. experimental section, see use accurately robustly
estimate DOFs various articulated objects.

495

fiSturm, Stachniss, & Burgard

4. Perception Articulated Objects
estimating kinematic model articulated object, approach needs sequence
1 , . . . , yn ) includes poses p parts
n pose observations Dy = (y1:p
1:p
object. experiments, used different sources acquiring pose observations:
marker-based perception, described Section 4.1, domain-specific marker-less perception described Section 4.2, perception based internal forward kinematic
model manipulator using joint encoders described Section 4.3.
4.1 Marker-Based Perception
observing pose articulated object, used experiments three different
marker-based systems, different noise outlier characteristics: motion capture
studio low noise outliers, ARToolkit markers relatively high noise
frequent outliers, OpenCVs checkerboard detector moderate noise occasional
outliers.
4.1.1 Motion Capturing Studio
conducted first experiments PhaseSpace motion capture studio Willow
Garage, collaboration Pradeep Konolige (Sturm et al., 2009). tracking
system uses several high-speed cameras installed rig along ceiling, active LED
markers attached individual parts articulated object. data
PhaseSpace device virtually noise- outlier-free. noise PhaseSpace system
specified y,pos < 0.005 y,orient < 1 .
4.1.2 ARToolkit Markers
Additionally, used passive marker-based system ARToolkit registering 3D
pose objects Fiala (2005). system advantage requires
single camera, used without infrastructure. ARToolkit markers
consist black rectangle error-correcting code imprinted 6x6-grid inside
rectangle distinguishing individual markers. found noise
system strongly depends distance angle marker camera.
marker size 0.08 distance 2 camera, typically obtained
noise values y,pos = 0.05 y,orient = 15 .
4.1.3 Checkerboard Markers
OpenCVs checkerboard detector provides much higher pose accuracy. detector
searches camera images strong black white corners sub-pixel accuracy (Bradski & Kaehler, 2008). system, typically obtained measurement noise around
y,pos = 0.005 y,orient = 5 marker sizes 0.08 side length 2 distance camera. One distinguish different markers system using
checkerboards varying numbers rows columns.

496

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

Figure 5: Marker-less pose estimation using stereo camera. segmented plane,
iteratively fit rectangle (left image). right two images show observed
tracks cabinet drawer cabinet door.

4.2 Marker-Less Pose Estimation
contrast using artificial markers, also possible estimate object pose directly,
example, dense depth images acquired stereo camera system. recently
developed system collaboration Konolige (Sturm et al., 2010). Using
marker-less camera-based tracking system several advantages. First, rely
artificial markers attached articulated objects, second, require
expensive range scanners additional disadvantage poorly deal
moving objects, making inconvenient learning articulation models. However,
recognize general registration arbitrary objects point clouds still
open issue. Therefore, restrict fronts kitchen cabinets.
solve general perception problem, provides useful working solution mobile
manipulation robots performing service tasks households. concrete scenario,
perception articulated drawers doors kitchen environment requires accurate
detection rectangular objects depth image sequences.
stereo processing system, obtain frame disparity image
R640480 , contains pixel (u, v) perceived disparity D(u, v) R.
details camera system, particular choice suitable texture projection
pattern, refer interested reader recent work Konolige (2010). relationship 2D pixels disparity image 3D world points defined
projection matrices calibrated stereo camera, calculated single matrix
multiplication pixel coordinates disparity.
apply RANSAC-based plane fitting algorithm segmenting dense depth
image planes. next step find rectangles segmented planes. start
sampled candidate rectangle optimize pose size iteratively, minimizing
objective function evaluates accurately rectangle candidate matches
points segmented plane. search converges, determine quality
found rectangle evaluating pixel precision recall. example iterative
pose fitting given left image Fig. 5: rectangle candidate started lower
left door, iteratively converged correct pose size door.

497

fiSturm, Stachniss, & Burgard

Articulated Object

Position
End Effector

Arm Control

Cartesian
Equilibrium
Point Generation

y1:t

Model Fitting
Selection
M,

xCEP


xt , Jt

Model Prediction

Figure 6: Overall control structure (Sturm et al., 2010). robot uses trajectory
end effector estimate model articulated object. Subsequently,
uses model generating next Cartesian equilibrium point.

Finally, sequence depth images D1:n , detected rectangles need integrated set consistent tracks, one visible rectangle. result, obtain
1 , . . . , yn ) use model estimation model
set pose sequences Dy = (y1:p
1:p
selection. middle right image Fig. 5 show tracks obtained
observing drawer door kitchen cabinet. details approach
recently described Sturm et al. (2010).
4.3 Perception using Joint Encoders Mobile Manipulation Robot
Next visual observation articulated objects, mobile manipulation robot also
estimate kinematic model physically interacts articulated object.
evaluating joint encoders, robot compute pose gripper using
forward model manipulator. robot establishes firm contact handle
cabinet door, position end-effector directly corresponds position
door handle. result, robot sense position handle well control
moving manipulator.
approach described section developed collaboration Jain
Kemp Healthcare Robotics Lab Georgia Tech. robot use
research statically stable mobile manipulator named Cody. consists two arms
MEKA Robotics omni-directional mobile base Segway. end-effector,
uses hook inspired prosthetic hooks human fingers, described
detail recent work Jain Kemp (2009a). Furthermore, used PR2 robot
Willow Garage additional experiments, using standard 1-DOF gripper two
fingers, located lab.
Fig. 6 shows block diagram approach. robot observes pose
end effector Cartesian space, denoted SE (3). operating mechanism,
robot records trajectory y1:t time sequence poses. partial
trajectory, continuously estimates kinematic model articulated object,
robot uses turn predict continuation trajectory (Sturm et al., 2010).

498

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

actively operate articulated object robot, use trajectory controller
updates Cartesian equilibrium point based estimated Jacobian kinematic
model articulated object. controller uses kinematic model generate
Cartesian equilibrium point (CEP) trajectories fixed world frame, attached initial
location handle. time step t, controller computes new equilibrium point
xCEP


mechanism
xCEP
= xCEP
+ vthook ,

t1 + vt

(56)

vtmechanism vector intended operate mechanism, vthook vector
intended keep hook slipping handle. controller computes
vtmechanism = L mechanism

Jt
kJt k

(57)

vector length L mechanism = 0.01 along Jacobian learned kinematic
function mechanism, i.e.,
fi
Jt = fM, (q)fiq=qt .
(58)
vthook , use proportional controller tries maintain force 5 N
hook handle direction perpendicular Jt . controller uses force
measured wrist force-torque sensor robot. refer reader work
Jain Kemp (2009b) details implementation equilibrium point control,
used coordinate motion mobile base compliant arm
(Jain & Kemp, 2010).
positional accuracy manipulator high, i.e., y,pos 0.01 m.
However, using hook end-effector, robot cannot sense orientation
handle. manipulator mounted mobile base, robot move around,
thus positional accuracy sensed position hook global coordinate system
(and thus including localization errors base) reduces y,pos 0.05 m.

5. Experiments
section, present results thorough evaluation aspects approach.
First, show approach accurately robustly estimates kinematic models
typical household objects using markers. Second, show also holds data
acquired marker-less pose estimation using active stereo camera system. Third,
show approach also works data acquired different mobile manipulation
robots operating various pieces furniture domestic environments.
5.1 Microwave Oven, Office Cabinet, Garage Door
first experiments, use pose observations three typical objects domestic
environments: door microwave oven, drawers office cabinet, garage
door. goal experiments show approach robustly
accurately estimates link models, well correct kinematic structure whole
499

fiSturm, Stachniss, & Burgard

articulated object. addition, show range configuration space
obtained model estimation.
motion microwave oven cabinet tracked using motion capture
studio collaboration Pradeep Konolige (Sturm et al., 2009), garage
door using checkerboard markers. object, recorded 200 data samples
manually articulating object. evaluation, carry 10 runs. run,
sampled n = 20 observations use fitting model parameters. used
remaining observations measuring prediction accuracy fitted model (10-folds
cross-validation).
5.1.1 Model Fitting
quantitative results model fitting model selection given Table 2.
seen table, revolute model well suited predicting opening
movement microwave door (error 0.001 m) prismatic model predicts
accurately motion drawer (error 0.0016 m), expected
result. Note also revolute model also explain motion drawer
accuracy 0.0017 m, estimating rotary joint large radius. noted
flexible GP model provides roughly accuracy parametric models
able robustly predict poses datasets (0.0020 door,
0.0017 drawer). case simulated garage door, however, parametric
models fail whereas GP model provides accurate estimates.
reader might wonder GP model alone suffice, GP model
represent many different types kinematic models, including revolute prismatic
ones. However, even GP model fits data, best choice terms
resulting posterior likelihoods. GP model cases overly complex,
over-fit data hand. high complexity GP model penalized
BIC. contrast, specialized models smaller number free parameters,
therefore robust noise outliers. Furthermore, require less
observations converge. experiments illustrate system takes advantage
expert-designed parametric models appropriate keeping flexibility
also learn accurate models unforeseen mechanical constructions.
learned kinematic models also provide configuration range C articulated
object. visualization purposes, sample configurations range,
project object poses using learned forward function. Fig. 7, Fig. 8, Fig. 9
illustrate learned configuration range door microwave oven, garage
door, two drawers office cabinet, respectively.
5.1.2 Model Structure Selection
fitting model candidates observed data, next goal select model
best explains data, corresponds finding model maximizes
posterior probability (or minimizes BIC score).
right image Fig. 7 shows resulting graph microwave oven dataset,
BIC score indicated edge. expected, revolute model selected,

500

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

Dataset

Rigid
Model

Prismatic
Model

Revolute
Model

GP
Model

Microwave
(z,pos. = 0.002 m,
z,orient. = 2.0 )

pos. error =
orient. error =
=

0.3086
37.40
0.891

0.1048
32.31
0.816

0.0003
0.15
0.000

0.0020
0.16
0.000

Drawer
(z,pos. = 0.002 m,
z,orient. = 2.0 )

pos. error =
orient. error =
=

0.0822
2.06
0.887

0.0016
1.36
0.000

0.0018
1.60
0.003

0.0017
1.09
0.000

Garage Door
(z,pos. = 0.050 m,
z,orient. = 5.0 )

pos. error =
orient. error =
=

1.0887
14.92
0.719

0.3856
10.79
0.238

0.4713
10.34
0.418

0.0450
0.93
0.021

Table 2: Prediction errors estimated outlier ratios articulation models learned
microwave oven, office cabinet, real garage door.

(a)

microwave oven

door

x1

x2

rigid
BIC(M12 ) =

2568507.7

prism.
BIC(M12
)=

686885.1

BIC(Mrev.
12 ) =

461.9

BIC(MGP
12 ) =

165.8
(b)

Figure 7: Visualization kinematic model learned door microwave oven.
(a) configuration range. (b) kinematic graph. numbers edges indicate
BIC score corresponding model candidate.

lowest BIC score. Correspondingly, right image Fig. 8 shows
BIC scores edges garage door dataset, GP model gets selected.
typical articulated object consisting multiple parts cabinet drawers
depicted Fig. 9. experiment, track poses cabinet (x1 ),
two drawers (x2 x3 ). first 20 samples, opened closed lower
drawer. Accordingly, prismatic joint model Mprism.
selected (see top row images
23
Fig. 9). also upper drawer gets opened closed, rigid model Mrigid

12
prism.
prism.
prism.
replaced prismatic model M12 , M23
replaced M13 , resulting
kinematic tree EG = {(1, 2), (1, 3)}. Note required articulate drawers
one other. done illustration purposes.
501

fiSturm, Stachniss, & Burgard

building

garage door

x1

x2

rigid
BIC(M12 ) =

9893.4

prism.
BIC(M12
)=

5450.8

BIC(Mrev.
12 ) =

5870.7

BIC(MGP
12 ) =

620.2

(a)

(b)

Figure 8: Visualization kinematic model learned garage door. (a) 10 uniformly
sampled configurations. (b) kinematic graph.

5.1.3 Multi-Dimensional Configuration Spaces
illustrate approach also able find models higher-dimensional configuration spaces > 1, let robot monitor table moved floor.
robot equipped monocular camera tracking Artoolkit marker attached
table. experiment, table moved never turned, lifted, tilted
therefore configuration space table two dimensions. Fig. 10 shows four
snapshots learning. Initially, table perfectly explained rigid object
room (top left). Then, prismatic joint model best explains data since table
moved one direction (top right). moving sideways, best model 1-DOF
Gaussian process model follows simple curved trajectory (bottom left). Finally,
full planar movement explained 2-DOF Gaussian process model (bottom right),
model movements lie 2D surfaces.
5.1.4 Additional Examples
ran similar experiments large set different articulated objects typically
occur domestic environments, including office cabinets, office doors, desk lamps, windows,
kitchen cabinets, fridges dishwashers garage door. Four examples given
Fig. 11. Videos (and other) experiments available homepage
corresponding author3 . videos show original movie well overlay
inferred kinematic model. experiments, attached checkerboards
different sizes movable parts, used consumer-grade video camera
low-cost laptop webcam acquiring image data. software also visualizes
learned articulation models 3D back-projects onto image allow easy
visual inspection. detected poses checkerboards visualized red/green/blue
coordinate axes systems, selected links indicated using colored
connection. software also displays configuration range generating poses
3. http://www.informatik.uni-freiburg.de/ sturm

502

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

cabinet

drawer 1

drawer 2

x1

x2

x3

rigid
BIC(Mij ) =
prism.
BIC(Mij
)=

189.3

997.2

993.0

63.9

61.7

62.6

BIC(Mrev. ) =

41.8

58.1

59.3

BIC(MGP
ij ) =

277.2

279.0

278.4

ij

(a)

(b)
cabinet

drawer 1

drawer 2

x1

x2

x3

rigid
BIC(Mij ) =
prism.

793.7

2892.2

3660.1

)=

88.8

86.9

84.7

BIC(Mrev. ) =

84.9

84.4

82.4

BIC(MGP
ij ) =

331.6

331.0

331.8

BIC(Mij

ij

(c)

(d)

Figure 9: Incrementally estimating model two drawers cabinet. (a) Initially,
lower drawer opened closed. (b) Corresponding kinematic graph. (c)
drawers opened closed independently. (d) Corresponding kinematic
graph.

estimated range. revolute joints, additionally indicates rotation axis using line
surrounding circle.
visual inspection objects Fig. 11, one see accurate model
estimation works conjunction marker-based tracking: motion drawers
cabinet well matched, rotation axes door hinge door handle
estimated close true position. upper part garage door moves
slider ceiling, lower part connected via revolute joint. resulting
motion clearly neither revolute prismatic, consequently approach selects
GP model. desk lamp consists two-bar links keep light housing always
upright (or, loosely speaking, rigid orientation), move positional domain along
circle. link type well explained GP model. existence
objects shows necessity supply domestic service robot general, nonparametric model deal wide variety different articulated objects.
noted majority articulated objects domestic environments consist
revolute prismatic joints robustly estimated using parametrized
models. motivates approach enables robot fit parametric

503

fiSturm, Stachniss, & Burgard

Figure 10: Learning model table moving ground plane. arrows indicate
recovered manifold configuration space.

nonparametric models time compare terms posterior likelihoods
consistent model selection framework.
Another interesting object car, doors windows tree- chainlike elements. Fig. 12, observed motion drivers door window.
first observations, approach estimates structure rigid, links
door window parallel car body. open window
half, approach attaches drivers window door, selects prismatic model.
Surprisingly us, open window (and thus acquire observations),
approach switches revolute model drivers window associated large
radius (r = 1.9 m). looking carefully data car, confirm
window indeed moves circular path, due curved window glass. Finally,
driver closes door, also revolute model link car body
door selected.

504

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

x1
prismatic
x2

x1
revolute

prismatic
x2
x3

x3
revolute
(a) Office cabinet

(b) Room door

x2
GP

x2
x1

x3

GP

GP
x1

(c) Garage door

(d) Desk lamp

Figure 11: Visualization learned articulation models several domestic
objects. (a) cabinet two drawers, (b) room door including handle, (c)
garage door, (d) desk lamp two-bar links.

conclude results, approach able estimate kinematic
parameters kinematic structure different household objects high accuracy, i.e.,
prediction error learned models around 0.001 1 objects tracked
motion capture studio, around 0.003 3 checkerboard markers.
accuracy, learned models well suited mobile manipulation tasks.
5.2 Evaluation Marker-Less Model Estimation
goal next set experiments show kinematic models learned
certain environments without requiring artificial markers. particular, focus
kitchen environments rectangular cabinet fronts, employ pose detector
described previously (Sturm et al., 2010).
505

fiSturm, Stachniss, & Burgard

x3
x3
rigid
x1

x1

rigid

prismatic
rigid

x2

x2

(a)

(b)

x3
x3
x1

rigid

revolute

x1

revolute
revolute

x2
(c)

x2
(d)

Figure 12: Snapshots learning process incrementally observing motion
car door window camera images. Due shape glass
drivers window actually moves circular arc radius r = 1.9 m. Images
taken (a) 10, (b) 40, (c) 60, (d) 140 pose observations.

first experiment carried motion capture studio, evaluated detector
found detected cabinet drawer 75% images
distance 2.3 camera.
evaluated robustness articulation model learner detailed logfiles
door (0.395 0.58 m) drawer (0.395 0.125 m) typical kitchen interior.
repeatedly opened closed objects approximately 1 distance robot;
total, recorded 1,023 5,202 images. downsampled logs stochastically
100 images, ran pose estimation, model estimation, structure selection 50
times. outcome model selection process, accuracy selected model
depicted Fig. 14 door dataset.

506

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

(a)

(b)

Figure 13: Articulation model learned observing drawer (a) door (b).

p(model)

1

rigid
prismatic
revolute

0.75
0.5
0.25

error position
error orientation

0.05
0.04
0.03
0.02
0.01
0

10
8
6
4
2
0
10

20
30
40
number observations (door)

50

orientation error [deg]

position error [m]

0

60

Figure 14: Evaluation articulation models learned cabinet door, averaged
50 runs. plot top shows probability articulation model templates, plot bottom shows prediction error standard deviation
learned model.

datasets, found roughly first 10 observations, mostly rigid
model selected, substantial motion drawer door yet detected.
observations added track, higher error (rigid) model

507

fiSturm, Stachniss, & Burgard

Figure 15: Images showing robot Cody Georgia Tech operating five mechanisms
using approach described Section 4.3. objects (from left right):
cabinet door opens right, cabinet door opens left,
dishwasher, drawer, sliding cabinet door. Images courtesy Jain
Kemp.

predictions observations becomes. result, prismatic revolute models
selected frequently. 30 observations, model selection converged
cases true model.
models learned drawer datasets predictive accuracy approximately
0.01 7 ; 0.01 3.5 door dataset. Although predictive accuracy
learned models slightly lower comparison marker-based tracking systems
due higher noise tracking system, learned models accuracy
usable mobile manipulator operating objects.
5.3 Operating Articulated Objects Mobile Manipulators
section, show real robots utilize approach learn kinematic
models objects active manipulation. Here, control arm done using
equilibrium point control described Section 4.3, result collaboration
Jain Kemp (Sturm et al., 2010). experiments conducted two different
platforms, robot Cody PR2 robot.

508

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

5.3.1 Task Performance
evaluated performance approach five different mechanisms using robot
Cody: cabinet door opens right, cabinet door opens left,
dishwasher, drawer, sliding cabinet door. performed eight trials mechanism. robot started approximately 1 location handle. manually
specified grasp location selecting point 3D point cloud recorded robot,
orientation hook end effector, initial pulling direction. task
robot navigate mechanism operate it, learning articulation
model using methods described Section 3.1. deemed trial successful
robot navigated mechanism opened angle greater 60
revolute mechanisms 0.3 prismatic mechanisms.
Fig. 15 shows robot pulled open five mechanisms one
respective trials. robot successfully opened 3 rotary mechanisms 21
24 trials 2 linear mechanisms 16 trials. robot able open doors
70 , estimate radii average error 0.02 m. Further,
robot pulled open drawer sliding cabinet repeatedly average 0.49 m.
Overall robot successful 37 40 trials (92.5%).
three failures due robot failing hook onto handle prior operating
mechanism, likely due odometry errors errors provided location
handle. experiments, observe model learning caused
errors. principle, however, hook could slip handle wrong model
estimated.
5.3.2 Model Fitting Selection End-Effector Trajectories
Fig. 1 Fig. 16 show examples PR2 robot operating several articulated objects
common domestic environments, i.e., fridge, drawer, dishwasher door, tray
dishwasher, valve heater. experiments, use feedback control
described Section 4.3 tele-operated manipulator manually. First, recorded
set trajectories guiding manipulator operate various articulated objects.
execution, played trajectories back using different implementation equilibrium
point control available PR2 platform, recorded end-effector trajectories
robot. used trajectories subsequently learn kinematic models. Finally,
visualized models superimposing images taken calibrated wide-angle
camera mounted head robot, see Fig. 16. experiments, approach
always selected correct model candidate. One easily verify visual inspection
approach estimates kinematic properties (like rotation axis prismatic
axis) accurately.
experiments show robots successfully learn accurate kinematic models
articulated objects end-effector trajectories using approach. PR2,
achieved average predictive accuracy learned models 0.002 (in terms
residual error observed trajectory respect learned model),
sufficient using models mobile manipulation tasks domestic settings.

509

fiSturm, Stachniss, & Burgard

revolute

(a) Cabinet door

revolute

(b) Dishwasher door

prismatic

(c) Dishwasher tray

revolute

(d) Valve heater

Figure 16: PR2 robot learns kinematic models different pieces furniture
actuating using manipulator. Objects top bottom: fridge,
cabinet door, drawer, dishwasher door, dishwasher tray, water tap, valve
heater.

510

fi0.4

0.4

0.2

0.2

0

0

-0.2

-0.2

-0.4

-0.4
-0.4

-0.2
x [m]

0

-0.4

-0.2
x [m]

z [m]

[m]

Probabilistic Framework Learning Kinematic Models Articulated Objects

0

Figure 17: plots show observed trajectories 5 recovered models
minimizing overall BIC using approach. Trajectories assigned
model depicted color.

prediction error [m]

without learned prior models
learned prior models
0.3

0.2

0.1

0
0

0.1

0.2
0.3
0.4
0.5
0.6
0.7
0.8
ratio observed trajectory vs. full trajectory

0.9

1

Figure 18: graph shows average prediction error (line) standard deviation
(shaded area) learned model full trajectory without prior
information.

511

fiSturm, Stachniss, & Burgard

5.4 Improving Model Estimation Based Experience
experiments described previous section, learned kinematic models
kitchen furniture independent other. using approach described
Section 3.1 data Cody, exploit correlation models different
objects searching set model clusters maximize posterior probability.
Fig. 17 shows result experiment. colors indicate cluster
trajectories assigned to. approach correctly recognized robot
operated 5 different mechanisms assigned 37 different trajectories correctly
corresponding models.
measured average prediction error without learning prior models (see
Fig. 18), using leave-one-out cross-validation randomized ordering trajectories.
found prior models reduce prediction error considerably, especially
new trajectory partially observed. 30% 70% new trajectory
observed, prediction error reduced factor three more. result,
robot comes substantially accurate model early utilize
knowledge better control manipulator.
Throughout experiments Cody, used fixed noise term z,pos = 0.05m.
accounts inaccuracies observation end effector position, due variations
hooking position, small errors kinematic forward model robot base
localization. found repeated experiments range 0.02m z,pos
0.20m, results similar previous results obtained z,pos = 0.05m.
significantly smaller values z,pos models created, example due small
variations grasping point inaccuracies. much larger values, observations
different mechanisms clustered joint model. Thus, results insensitive
moderate variations observation noise z,pos .
experiment illustrates approach enables mobile robot learn
experience exploit prior information manipulating new objects. experience
increases prediction accuracy factor approximately three.
5.5 Detecting Kinematic Loops
final set experiments, evaluated approach objects containing kinematic
loops. goal experiments show approach estimate correctly
kinematic connectivity, well correct number DOFs.
purpose, used first four segments yardstick. results
open kinematic chain consisting three revolute joints (see top left image Fig. 19).
object three DOFs, revolute joints independent other. second
experiment, taped fifth segment yardstick together first one.
creates kinematic loop, see top right image Fig. 19: resulting object consists
four revolute joints single DOF. resulting mechanism effectively
single DOF. articulated objects manually, recorded object pose datasets
|Dy | = 200 samples using checkerboard markers.
second third row Fig. 19 visualize learned kinematic model
open closed kinematic model, respectively, fourth row shows
kinematic structure learned model. figure, seen ap512

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

proach correctly recognizes open kinematic chain consists three revolute links
rev.
rev.
(Mrev.
12 , M23 , M34 ), three DOFs q = (q1 , q2 , q3 ) total. closed kinematic
rev.
rev.
rev.
chain, approach selects four revolute links (Mrev.
12 , M23 , M34 , M14 ), correctly
infers object exhibits single DOF q = (q1 ).
also analyzed progression model selection training data incorporated. left plot Fig. 20 shows DOFs learned kinematic model
open kinematic chain. Note opened yardstick segment segment, therefore
number DOFs increases step-wise zero three. right plot shows estimated number DOFs closed kinematic chain: approach correctly estimates
number DOFs one already first observations.
detail, analyzed evolution BIC scores runtime
different approaches closed kinematic chain Fig. 21. plot top shows
evolution BIC scores possible kinematic structures. colorized
curves corresponding spanning tree solution (solid red), heuristic search (dashed
blue) global optimum (dotted green). spanning tree solution use
starting point heuristic search average 35.2% worse terms BIC
optimal solution. contrast, BIC heuristic search 4.3% worse,
equals optimal solution 57.5% cases. time complexity computing
spanning tree independent number training samples, see bottom plot Fig. 21.
contrast that, evaluation kinematic graphs requires kinematic structure
consideration evaluation whole object poses, thus linear number
training samples n. heuristic search evaluates kinematic graphs along trace
structure space. result, yardstick object p = 4 object parts,
heuristic search requires average 82.6% less time full evaluation.
conducted similar experiments objects containing kinematic loops
reduced DOFs. Two examples depicted first row Fig. 22: artificial object
consisting four parts single revolute joint, common domestic step ladder
consisting two revolute joints single, shared DOF. cases, approach
able correctly estimate kinematic parameters correct number
DOFs.
experiments, shown approach able detect closed
chains articulated objects, correctly estimates correct number DOFs. loop
closures (or reduced DOFs) reduce configuration space object significantly,
valuable information mobile manipulator, example reasoning possible
configurations object.
5.5.1 Evaluation Model Selection Robustness
Finally, investigated influence choice observation noise variable z
model selection process artificial data. analysis, sampled noisy observations
true = 0.05. resulting
revolute model true observation noise z,pos
observation sequence, fitted candidate models, selected best model.
repeated experiment 10 independent runs evaluated mean standard
deviation. number training samples n kept fixed, higher noise
assumption favors selection simpler models, vice versa. Fig. 23 illustrates

513

fiSturm, Stachniss, & Burgard

x3
revolute

x1

revolute

revolute

x2

x4
revolute
x2

x1
revolute

q1 q2 q3 . . .
x1
Mrev.
12

x4

x2

x3

revolute

revolute
x3

q1 q2 q3 . . .
x4

x1

Mrev.
Mrev.
23
34

Mrev.
12

x2

x3

x4

Mrev.
Mrev.
Mrev.
23
34
14

Figure 19: Open kinematic chain three DOFs (left column) closed kinematic chain
single DOF (right column). First row: images objects. Second
third row: learned kinematic models two different perspectives. Fourth
row: learned graphical model, showing connectivity DOFs
learned kinematic model. selected kinematic model visualized bold
edges, DOFs given boldly type-set configuration variables.

514

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

open kinematic chain

closed kinematic chain
DOFs

DOFs

4

4

3

3

2

2

1

1

0

0

50

100

150

0

200

0

50

training samples n

100

150

200

training samples n

Figure 20: Estimated number DOFs open closed kinematic chain object
(see Fig. 19). Left: open kinematic chain. Right: closed kinematic chain.

spanning tree

search heuristic

global optimum

BIC

10,000
0

time [s]

10,000
200
150
100
50
0

0

20

40

60

80

100

120

140

160

180

200

training samples n

Figure 21: Top: BIC scores possible kinematic structures closed kinematic
chain, depicted top right image Fig. 20. Bottom: Computation
times function number training samples.

515

fiSturm, Stachniss, & Burgard

x3
x2
rigid
x1

revolute
x4

rigid
revolute

revolute

x2

x3
x1

q1 q2 q3 . . .
x1

x2

x3

q1 q2 . . .
x4

x1

x2

x3

rigid

Mrot.
12


Mrigid
23 24

Mrot.
Mrot.
13
12

Figure 22: articulated object consisting single revolute joint (left), stepladder
consisting two revolute joints (right).

516

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

2,000

BIC

1,500
1,000

500
0

Gaussian process model
revolute model
prismatic model
rigid model

selected model
0.0001

0.001

0.01

0.1

1.0

observation noise z,position

Figure 23: BIC score function assumed observation noise. low noise assumption favors selection complex models, vice versa.

dependency: n = 50 assumed noise level z,pos 0.02, GP model
selected. 0.02 z,pos 0.2, revolute model yields best trade-off
model complexity data likelihood. 0.2 z,pos , rigid model best explains
observations noise level magnitudes hides underlying model.
experiment, demonstrated model selection procedure robust
large intervals observation noise assumption, i.e., even though true observation
true = 0.05, approach selected revolute model noise
noise set z,pos
assumption 0.02 z,pos 0.2, thus robust whole magnitude.
also performed experiments synthetic data verify estimators robust
normally distributed noise MLESAC-based estimators additionally
robust uniformly distributed outliers.
5.6 Open-Source Availability
source code, documentation, code samples, tutorials fully available opensource, licensed BSD. also provide step-by-step guide repeat experiments using consumer-grade laptop webcam4 .

6. Related Work
paper, combined several techniques come different fields, i.e.,
system identification fitting kinematic models, information theory model comparison
structure selection, computer vision estimating tracking objects, service robotics
control actually manipulating articulated objects mobile manipulators.
4. http://www.ros.org/wiki/articulation

517

fiSturm, Stachniss, & Burgard

following, review related approaches, contrast approach, highlight
contributions.
6.1 Kinematic Model Fitting
Calibrating kinematic models manipulation robots sensor data long history
system identification. good overview existing techniques found work
Hollerbach, Khalil, Gautier (2008). He, Zhao, Yang, Yang (2010) recently
analyzed identifiability parameters serial-chain manipulators, proposed
generic approach calibration. Pradeep, Konolige, Berger (2010) recently presented
system implementation sensor-actuator calibration complex service robot consisting
two arms, laser scanner several cameras. works, kinematic
model specified advance, typically expected initial parameter set
available. taking multiple pose observations robot different configurations,
error prediction observation computed, finally parameter
vector optimized using non-linear, iterative least-squares methods.
case, neither kinematic model initial parameter set available,
needs estimated observations alone. particular observations
disturbed noise outliers, sample consensus methods proven provide
robust estimates (Fischler & Bolles, 1981; Torr & Zisserman, 2000; Nister, 2005; Rusu,
Marton, Blodow, Dolha, & Beetz, 2008). model estimators, use MLESAC
first described Torr Zisserman (2000) contrast least-squares fitting
robust reasonable amounts outliers training data.
6.2 Kinematic Structure Selection
Estimating kinematic structure observations studied intensively before, however, without subsequently using models robotic manipulation (Taycher, Fisher,
& Darrell, 2002; Kirk, OBrien, & Forsyth, 2004; Yan & Pollefeys, 2006; Ross, Tarlow, &
Zemel, 2008; Pekelny & Gotsman, 2008). Taycher et al. (2002) address task estimating underlying topology observed articulated body. focus lies recovering
topology object rather learning generative model. Also, compared
work, approach handle links complex link models, e.g., multiple
DOFs non-parametric models. Kirk et al. (2004) extract human skeletal topologies using 3D markers motion capture system, however assuming joints revolute.
Yan Pollefeys (2006) present approach learning structure articulated
object feature trajectories affine projections. researchers addressed
problem identifying different object parts image data. Ross et al. (2008) use
multi-body structure motion extract links image sequence fit
articulated model links using maximum likelihood learning.
exist several approaches tracking articulated objects key motivation
often a-priori model assumed. Krainin, Henry, Ren, Fox (2010), example,
described recently approach tracking articulated objects manipulator using
depth camera texture projector. However, require geometric model
manipulator. Kragic, Petersson, Christensen (2002) describe integrated navigation
system mobile robots includes vision-based system detection door
518

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

handles enables robot successfully open doors. Anguelov, Koller, Parker,
Thrun (2004) model doors line segments rotate around hinge. EM used
find model parameters 2D range data images. Nieuwenhuisen, Stuckler,
Behnke (2010) describe approach mobile robot increases localization
accuracy learning positions doors.
Although learning structure general Bayesian networks proven
NP-complete (Chickering, 1996), many approximate methods proposed
solve structure search problem efficiently. methods include greedy search, iterated hill climbing, genetic algorithms ant colony optimization (Chickering, 2002; Daly
& Shen, 2009). cases, size search space reduced significantly
evaluating number statistical independence tests (Margaritis & Thrun, 1999; Bromberg,
Margaritis, & Honavar, 2009). paper, consider special Bayesian networks representing kinematic structures. allows us exploit mutual independence edges
kinematic trees efficiently recovering kinematic structure. closed kinematic
chains, use greedy search heuristic similar work Chickering (2002).
Estimating structure models requires trade data fit model
complexity. corresponds Bayesian model selection problem, described
MacKay (2003). approach problem work using Bayesian Information
Criterion (BIC) introduced Schwarz (1978). BIC provides method selecting
alternate model hypotheses, based data likelihood model complexity.
paper, use BIC select kinematic models individual links
well multi-part articulated objects.
6.3 Pose Estimation
Many approaches estimating pose objects sensory data proposed
past, solving general problem still ongoing research effort. Marker-based
approaches using active passive markers advantage easy use
providing full 3D pose information, require artificial markers attached upon
object parts interest. Early work area articulated object tracking presented
Lowe (1991) assumption object model (and good initialization)
known. Nieuwenhuisen et al. (2010) use 2D laser range finder detecting doors
office environment storing map. Tilting lasers line stripe systems
provide dense 3D point clouds used localizing doors door handles,
cannot deal moving objects (Rusu, Meeussen, Chitta, & Beetz, 2009; Quigley,
Batra, Gould, Klingbeil, Le, Wellman, & Ng, 2009). Camera-based approaches provide
higher frame rates. good survey state-of-the-art camera-based pose estimation
techniques found work Lepetit Fua (2005). context, work
Murillo, Kosecka, Guerrero, Sagues (2008) Andreopoulos Tsotsos (2008)
visual door detection pose estimation particular relevance. Stereo systems
employ matching algorithms produce dense results provide 3D point clouds video
frame rates, suffer occasional dropouts areas low texture illumination
(Konolige, 1997; Brox, Rosenhahn, Gall, & Cremers, 2010; Wedel, Rabe, Vaudrey, Brox,
Franke, & Cremers, 2008). overcome active camera systems add texture

519

fiSturm, Stachniss, & Burgard

scene using projector LED. Two examples systems described
Konolige (2010) Fox Ren (2010).
work, use several different approaches estimating pose articulated
object showing approach specific specific data source. particular,
use marker-based pose estimation monocular camera, marker-less pose estimation
stereo data, proprioceptive tracking using robots joint encoders.
6.4 Operating Articulated Objects
Several researchers addressed problem operating articulated objects robotic
manipulators. large number techniques focused handling doors drawers (Klingbeil et al., 2009; Kragic et al., 2002; Meeussen et al., 2010; Petrovskaya & Ng,
2007; Parlitz, Hagele, Kleint, Seifertt, & Dautenhahn, 2008; Niemeyer & Slotine, 1997;
Andreopoulos & Tsotsos, 2008; Rusu et al., 2009; Chitta, Cohen, & Likhachev, 2010).
majority approaches, however, assumes implicit kinematic model articulated object. Meeussen et al. (2010) describe integrated navigation system mobile
robots including vision- laser-based detection doors door handles enables
robot successfully open doors using compliant arm. Diankov, Srinivasa, Ferguson,
Kuffner (2008) formulate door drawer operation kinematically constrained
planning problem propose use caging grasps enlarge configuration space,
demonstrate integrated system performing various fetch-and-carry tasks
(Srinivasa, Ferguson, Helfrich, Berenson, Romea, Diankov, Gallagher, Hollinger, Kuffner,
& Vandeweghe, 2010). Wieland et al. (2009) combine force visual feedback reduce
interaction forces opening kitchen cabinets drawers. contrast work,
approaches make strong assumptions articulated objects, deal
problem inferring kinematic structure. Therefore, neither deal unknown objects, improve performance learning. Katz Brock (2008)
enabled robot first interact planar kinematic object table order
visually learn kinematic model, manipulate object using model
achieve goal state. contrast work, approach assumes planar objects
learns 2D models. Jain Kemp (2009b, 2010) recently presented approach
enabled robot estimate radius location axis rotary joints move
plane parallel ground, opening novel doors drawers using equilibrium
point control. Recently, combined (in collaboration Jain Kemp) model
learning approach equilibrium point controller (Sturm et al., 2010). enabled
robot operate larger class articulated objects, i.e., objects non-vertical
rotation axes.

7. Conclusion
paper, presented novel approach learning kinematic models articulated
objects. approach infers connectivity rigid parts constitute object
including articulation models individual links. model links, approach
considers both, parametrized well parameter-free representations. extensive studies
synthetic real data, evaluated behavior model estimation, model
selection, structure discovery. shown approach applicable
520

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

wide range articulated objects, used conjunction variety
different sensor modalities. approach enables mobile manipulators operate unknown
articulated objects, learn models, improve time.
Despite promising results presented paper, several open research
questions remain future investigation. current approach, learn kinematic models static pose observations. would interesting include velocities
accelerations object body parts. would allow robot learn dynamic
parameters well enable plan time-optimal motion trajectories. dynamical
model would enable robot accurately execute motions higher speeds. Furthermore,
robot measure forces torques actuating object could additionally
learn friction damping profiles include information learned model
well. robot could benefit information assess, example, whether door
drawer jammed.

8. Acknowledgments
authors gratefully acknowledge help Advait Jain Charlie Kemp Georgia
Tech, particular collaboration joint development online model estimation
control approach described Section 4.3, evaluating approach
mobile manipulation robot Cody described Section 5.3. Further, authors would like
thank Vijay Pradeep Kurt Konolige Willow Garage inspired authors
work subject, contributed experiments motion capture device
reported Section 5.1. Additional thanks go Kurt Konolige joint development
marker-less perception algorithm stereo data outlined Section 4.2 well
evaluation presented Section 5.2. work partly supported European
Commission grant agreement numbers FP7-248258-First-MM, FP7-260026-TAPAS,
FP7-ICT-248873-RADHAR, DFG contract number SFB/TR-8.

References
Andreopoulos, A., & Tsotsos, J. K. (2008). Active vision door localization door
opening using playbot. Proc. Canadian Conf. Computer Robot Vision
(CRV), pp. 310 Washington, DC, USA.
Anguelov, D., Koller, D., Parker, E., & Thrun, S. (2004). Detecting modeling doors
mobile robots. Proc. IEEE Int. Conf. Robotics & Automation (ICRA),
pp. 37773784.
Bishop, C. (2007). Pattern Recognition Machine Learning (Information Science
Statistics). Springer.
Bradski, G., & Kaehler, A. (2008). Learning OpenCV: Computer Vision OpenCV
Library. OReilly Media, Inc.
Bromberg, F., Margaritis, D., & Honavar, V. (2009). Efficient markov network structure
discovery using independence tests. Journal Artificial Intelligence Research (JAIR),
35.
521

fiSturm, Stachniss, & Burgard

Brox, T., Rosenhahn, B., Gall, J., & Cremers, D. (2010). Combined region- motionbased 3D tracking rigid articulated objects. IEEE Transactions Pattern
Analysis Machine Intelligence, 32(2), 402415.
Chickering, D. M. (1996). Learning Bayesian networks NP-Complete. Fisher, D.,
& Lenz, H. (Eds.), Learning Data: Artificial Intelligence Statistics V, pp.
121130. Springer-Verlag.
Chickering, D. M. (2002). Learning equivalence classes bayesian-network structures.
Journal Machine Learning Research (JMLR), 2, 445498.
Chitta, S., Cohen, B., & Likhachev, M. (2010). Planning autonomous door opening
mobile manipulator. Proc. IEEE Int. Conf. Robotics & Automation
(ICRA) Anchorage, AK, USA.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms. MIT Press.
Daly, R., & Shen, Q. (2009). Learning bayesian network equivalence classes ant colony
optimization. Journal Artificial Intelligence Research (JAIR), 35, 391447.
Dellaert, F. (2005). Square Root SAM. Proc. Robotics: Science Systems (RSS),
pp. 177184 Cambridge, MA, USA.
Diankov, R., Srinivasa, S., Ferguson, D., & Kuffner, J. (2008). Manipulation planning
caging grasps. Proc. IEEE-RAS Intl. Conf. Humanoid Robots (Humanoids)
Daejeon, Korea.
Featherstone, R., & Orin, D. (2008). Dynamics. Siciliano, B., & Khatib, O. (Eds.),
Handbook Robotics, pp. 3566. Springer, Secaucus, NJ, USA.
Fiala, M. (2005). Artag, fiducial marker system using digital techniques. Proc.
IEEE Conf. Computer Vision Pattern Recognition (CVPR).
Fischler, M., & Bolles, R. (1981). Random sample consensus: paradigm model fitting
application image analysis automated cartography. Commun. ACM., 24,
381395.
Fox, D., & Ren, X. (2010). Overview RGB-D cameras open research issues.
Proceedings Workshop Advanced Reasoning Depth Cameras Robotics:
Science Systems Conference (RSS) Zaragoza, Spain.
Frese, U. (2006). Treemap: o(logn) algorithm indoor simultaneous localization
mapping. Autonomous Robots, 21 (2), 103122.
Grisetti, G., Kummerle, R., Stachniss, C., Frese, U., & Hertzberg, C. (2010). Hierarchical
optimization manifolds online 2D 3D mapping. Proc. IEEE Int.
Conf. Robotics Automation (ICRA) Anchorage, AK, USA.
Grisetti, G., Stachniss, C., & Burgard, W. (2009). Non-linear constraint network optimization efficient map learning. Trans. Intell. Transport. Sys., 10 (3), 428439.
522

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

He, R., Zhao, Y., Yang, S., & Yang, S. (2010). Kinematic-parameter identification
serial-robot calibration based poe formula. IEEE Transactions Robotics, 26 (3),
411 423.
Hollerbach, J., Khalil, W., & Gautier, M. (2008). Model identification. Siciliano, B., &
Khatib, O. (Eds.), Handbook Robotics, pp. 321344. Springer, Secaucus, NJ, USA.
Jain, A., & Kemp, C. (2009a). Behavior-based door opening equilibrium point control. Proc. RSS Workshop Mobile Manipulation Human Environments
Seattle, WA, USA.
Jain, A., & Kemp, C. (2009b). Pulling open novel doors drawers equilibrium point
control. Proc. IEEE-RAS Intl. Conf. Humanoid Robots (Humanoids) Paris,
France.
Jain, A., & Kemp, C. (2010). Pulling open doors drawers: Coordinating omnidirectional base compliant arm equilibrium point control. Proc.
IEEE Int. Conf. Robotics & Automation (ICRA) Anchorage, AK, USA.
Katz, D., & Brock, O. (2008). Manipulating articulated objects interactive perception.
Proc. Robotics: Science Systems (RSS), pp. 272277 Pasadena, CA, USA.
Kirk, A., OBrien, J. F., & Forsyth, D. A. (2004). Skeletal parameter estimation
optical motion capture data. Proc. Int. Conf. Computer Graphics
Interactive Techniques (SIGGRAPH).
Klingbeil, E., Saxena, A., & Ng, A. (2009). Learning open new doors. Proc.
RSS Workshop Robot Manipulation Seattle, WA, USA.
Konolige, K. (1997). Small vision systems: hardware implementation. Proc.
Int. Symp. Robotics Research, pp. 111116.
Konolige, K. (2010). Projected texture stereo. Proc. IEEE Int. Conf. Robotics
& Automation (ICRA) Anchorage, AK, USA.
Kragic, D., Petersson, L., & Christensen, H. (2002). Visually guided manipulation tasks.
Robotics Autonomous Systems, 40 (2-3), 193 203.
Krainin, M., Henry, P., Ren, X., & Fox, D. (2010). Manipulator object tracking
hand model acquisition. Proc. IEEE Int. Conf. Robotics & Automation
(ICRA) Anchorage, AK, USA.
Lawrence, N. (2005). Probabilistic non-linear principal component analysis gaussian
process latent variable models. J. Mach. Learn. Res., 6, 17831816.
Lepetit, V., & Fua, P. (2005). Monocular model-based 3d tracking rigid objects. Foundations Trends Computer Graphics Vision, 1, 189.
Lowe, D. (1991). Fitting parameterized three-dimensional models images. IEEE Transactions Pattern Analysis Machine Intelligence, 13, 441450.
523

fiSturm, Stachniss, & Burgard

Lu, F., & Milios, E. (1997). Globally consistent range scan alignment environment
mapping. Autonomous Robots, 4, 333349.
MacKay, D. (2003). Information Theory, Inference, Learning Algorithms. Cambridge
University Press.
Margaritis, D., & Thrun, S. (1999). Bayesian network induction via local neighborhoods.
Proc. Conf. Neural Information Processing Systems (NIPS), pp. 505511.
MIT Press.
McClung, A., Zheng, Y., & Morrell, J. (2010). Contact feature extraction balancing
manipulation platform. Proc. IEEE Int. Conf. Robotics & Automation
(ICRA).
Meeussen, W., Wise, M., Glaser, S., Chitta, S., McGann, C., Patrick, M., Marder-Eppstein,
E., Muja, M., Eruhimov, V., Foote, T., Hsu, J., Rusu, R., Marthi, B., Bradski, G.,
Konolige, K., Gerkey, B., & Berger, E. (2010). Autonomous door opening plugging
personal robot. Proc. IEEE Int. Conf. Robotics & Automation
(ICRA) Anchorage, AK, USA.
Murillo, A. C., Kosecka, J., Guerrero, J. J., & Sagues, C. (2008). Visual door detection
integrating appearance shape cues. Robotics Autonomous Systems, 56(6),
pp. 512521.
Niemeyer, G., & Slotine, J.-J. (1997). simple strategy opening unknown door.
Proc. IEEE Int. Conf. Robotics & Automation (ICRA) Albuquerque, NM,
USA.
Nieuwenhuisen, M., Stuckler, J., & Behnke, S. (2010). Improving indoor navigation
autonomous robots explicit representation doors. Proc. IEEE
Int. Conf. Robotics & Automation (ICRA) Anchorage, AK, USA.
Nister, D. (2005). Preemptive ransac live structure motion estimation. Mach. Vision
Appl., 16 (5), 321329.
Parlitz, C., Hagele, M., Kleint, P., Seifertt, J., & Dautenhahn, K. (2008). Care-o-bot 3
- rationale human-robot interaction design. Proc. Int. Symposium
Robotics (ISR) Seoul, Korea.
Pekelny, Y., & Gotsman, C. (2008). Articulated object reconstruction markerless motion capture depth video. Computer Graphics Forum, 27 (2), 399408.
Petrovskaya, A., & Ng, A. (2007). Probabilistic mobile manipulation dynamic environments, application opening doors. Proc. Int. Conf. Artificial
Intelligence (IJCAI) Hyderabad, India.
Pradeep, V., Konolige, K., & Berger, E. (2010). Calibrating multi-arm multi-sensor robot:
bundle adjustment approach. Int. Symp. Experimental Robotics (ISER) New
Delhi, India.
524

fiA Probabilistic Framework Learning Kinematic Models Articulated Objects

Quigley, M., Batra, S., Gould, S., Klingbeil, E., Le, Q., Wellman, A., & Ng, A. (2009).
High-accuracy 3D sensing mobile manipulation: Improving object detection
door opening. Proc. IEEE Int. Conf. Robotics & Automation (ICRA)
Kobe, Japan.
Rasmussen, C., & Williams, C. (2006). Gaussian Processes Machine Learning.
MIT Press, Cambridge, MA.
Ross, D., Tarlow, D., & Zemel, R. (2008). Unsupervised learning skeletons motion.
Proc. European Conf. Computer Vision (ECCV) Marseille, France.
Roweis, S., & Saul, L. (2000). Nonlinear dimensionality reduction locally linear embedding. Science, 290 (5500), 23232326.
Rusu, R. B., Meeussen, W., Chitta, S., & Beetz, M. (2009). Laser-based perception door
handle identification. Proc. Int. Conf. Advanced Robotics (ICAR)
Munich, Germany.
Rusu, R. B., Marton, Z. C., Blodow, N., Dolha, M., & Beetz, M. (2008). Towards 3D point
cloud based object maps household environments. Robot. Auton. Syst., 56 (11),
927941.
Schwarz, G. (1978). Estimating dimension model. Annals Statistics, 6 (2).
Sentis, L., Park, J., & Khatib, O. (2010). Compliant control multi-contact center
mass behaviors humanoid robots. IEEE Trans. Robotics, 26 (3), 483501.
Srinivasa, S., Ferguson, D., Helfrich, C., Berenson, D., Romea, A. C., Diankov, R., Gallagher, G., Hollinger, G., Kuffner, J., & Vandeweghe, J. M. (2010). HERB: home
exploring robotic butler. Autonomous Robots, 28 (1), 520.
Sturm, J., Konolige, K., Stachniss, C., & Burgard, W. (2010). Vision-based detection
learning articulation models cabinet doors drawers household environments.
Proc. IEEE Int. Conf. Robotics & Automation (ICRA) Anchorage, AK,
USA.
Sturm, J., Pradeep, V., Stachniss, C., Plagemann, C., Konolige, K., & Burgard, W. (2009).
Learning kinematic models articulated objects. Proc. Int. Joint Conf.
Artificial Intelligence (IJCAI) Pasadena, CA, USA.
Sturm, J., Jain, A., Stachniss, C., Kemp, C., & Burgard, W. (2010). Operating articulated objects based experience. Proc. IEEE International Conference
Intelligent Robot Systems (IROS) Taipei, Taiwan.
Taycher, L., Fisher, J., & Darrell, T. (2002). Recovering articulated model topology
observed rigid motion. Proc. Conf. Neural Information Processing Systems
(NIPS) Vancouver, Canada.
Tenenbaum, J., de Silva, V., & Langford, J. (2000). global geometric framework
nonlinear dimensionality reduction.. Science, 290 (5500), 23192323.
525

fiSturm, Stachniss, & Burgard

Torr, P. H. S., & Zisserman, A. (2000). Mlesac: new robust estimator application
estimating image geometry. Computer Vision Image Understanding, 78, 2000.
Wedel, A., Rabe, C., Vaudrey, T., Brox, T., Franke, U., & Cremers, D. (2008). Efficient
dense scene flow sparse dense stereo data. Proc. European Conf.
Computer Vision (ECCV) Marseille, France.
Wieland, S., Gonzalez-Aguirre, D., Vahrenkamp, N., Asfour, T., & Dillmann, R. (2009).
Combining force visual feedback physical interaction tasks humanoid robots.
Proc. IEEE-RAS Intl. Conf. Humanoid Robots (Humanoids) Paris, France.
Yan, J., & Pollefeys, M. (2006). Automatic kinematic chain building feature trajectories articulated objects. Proc. IEEE Conf. Computer Vision
Pattern Recognition (CVPR) Washington, DC, USA.

526

fiJournal Artificial Intelligence Research 41 (2011) 329-365

Submitted 02/11; published 06/11

Sequential Diagnosis Abstraction
Sajjad Siddiqi
National University Sciences Technology
(NUST) Islamabad, Pakistan

sajjad.ahmed@seecs.edu.pk

Jinbo Huang
NICTA Australian National University
Canberra, Australia

jinbo.huang@nicta.com.au

Abstract
system behaves abnormally, sequential diagnosis takes sequence measurements system faults causing abnormality identified, goal
reduce diagnostic cost, defined number measurements. propose
measurement points, previous work employs heuristic based reducing entropy
computed set diagnoses. approach generally good performance terms
diagnostic cost, fail diagnose large systems set diagnoses
large. Focusing smaller set probable diagnoses scales approach generally
leads increased average diagnostic costs. paper, propose new diagnostic
framework employing four new techniques, scales much larger systems good
performance terms diagnostic cost. First, propose new heuristic measurement
point selection computed efficiently, without requiring set diagnoses,
system modeled Bayesian network compiled logical form known
d-DNNF. Second, extend hierarchical diagnosis, technique based system abstraction previous work, handle probabilities applied sequential
diagnosis allow larger systems diagnosed. Third, largest systems
even hierarchical diagnosis fails, propose novel method converts system
one smaller abstraction whose diagnoses form superset
original system; new system diagnosed result mapped back
original system. Finally, propose novel cost estimation function
used choose abstraction system likely provide optimal average
cost. Experiments ISCAS-85 benchmark circuits indicate approach scales
circuits suite except one flat structure susceptible useful
abstraction.

1. Introduction
system behaves abnormally, task diagnosis identify reasons
abnormality. example, combinational circuit Figure 1, given inputs
P Q R, output V 0, actually 1 due faults gates J
B. Given system comprising set components, knowledge base modeling
behavior system, along (abnormal) observed values system variables,
(consistency-based) diagnosis set components whose failure (assuming
components healthy) together observation logically consistent
system model. example, {V }, {K}, {A}, {J, B} diagnoses given
c
2011
AI Access Foundation. rights reserved.

fiSiddiqi & Huang



BUFFER

1
P

1
Q



1

1


J

1
B



1

1


V

1
K

0
R

Figure 1: faulty circuit.

observation. general, number diagnoses exponential number
system components, one correspond set actual faults.
paper, therefore, consider problem sequential diagnosis (de Kleer &
Williams, 1987), sequence measurements system variables taken
actual faults identified. goal reduce diagnostic cost, defined
number measurements. propose measurement points, state-of-the-art gde (general
diagnosis engine) framework (de Kleer & Williams, 1987; de Kleer, Raiman, & Shirley, 1992;
de Kleer, 2006) considers heuristic based reducing entropy set computed
diagnoses. approach generally good performance terms diagnostic cost,
fail diagnose large systems set diagnoses large (de Kleer & Williams,
1987; de Kleer et al., 1992; de Kleer, 2006). Focusing smaller set probable diagnoses
scales approach generally leads increased average diagnostic costs (de Kleer,
1992).
propose new diagnostic framework employing four new techniques, scales
much larger systems good performance terms diagnostic cost. First, propose
new heuristic require computing entropy diagnoses. Instead consider
entropies system variables measured well posterior probabilities
component failures. idea select component highest posterior
probability failure (Heckerman, Breese, & Rommelse, 1995) variables
component, measure one highest entropy. compute probabilities,
exploit system structure joint probability distribution faults
system variables represented compactly Bayesian network (Pearl, 1988),
compiled deterministic decomposable negation normal form (d-DNNF) (Darwiche, 2001;
Darwiche & Marquis, 2002). d-DNNF logical form exploit structure present
many systems achieve compactness used compute probabilistic queries
efficiently. Specifically, required posterior probabilities exactly computed
evaluating differentiating d-DNNF time linear d-DNNF size (Darwiche,
2003).
330

fiSequential Diagnosis Abstraction

Second, extend hierarchical diagnosis, technique previous work (Siddiqi
& Huang, 2007), handle probabilities applied sequential diagnosis
allow larger systems diagnosed. Specifically, self-contained subsystems, called cones,
treated single components diagnosed found faulty
top-level diagnosis. significantly reduces number system components, allowing
larger systems compiled diagnosed. example, subcircuit dotted box
Figure 1 cone (with output {P, D} inputs) contains fault. First,
cone A, whole, determined faulty. compiled separately
diagnosed. previous work (Siddiqi & Huang, 2007) dealt task
computing diagnoses, involve measurements probabilities; present
paper, present several extensions allow technique carry sequential
diagnosis.
Third, abstraction system still large compiled diagnosed,
use novel structure based technique called cloning, systematically modifies
structure given system C obtain new system C0 smaller abstraction
whose diagnoses form super-set original system; new system
diagnosed result mapped back original system. idea select
system component G part cone hence cannot abstracted away
hierarchical diagnosis, create one clones G, distribute Gs parents (from
graph point view) among clones, way G clones become parts
cones disappear abstraction. Repeated applications operation
allow otherwise unmanageable system small enough abstraction diagnosis
succeed.
Finally, propose novel cost estimation function predict expected
diagnostic cost given abstraction system used diagnosis. aim
find abstraction system likely give optimal average cost.
purpose, use function various abstractions system different
abstractions obtained destroying different cones system (by destroying
cone mean overlook fact cone include components
abstraction). abstraction lowest predicted cost used actual
diagnosis.
Experiments ISCAS-85 benchmark circuits (Brglez & Fujiwara, 1985) indicate
solve first time nontrivial multiple-fault diagnostic cases benchmarks, good diagnostic costs, except one circuit flat structure susceptible
useful abstraction, new cost estimation function often accurately predict
abstraction likely give optimal average cost.

2. Background Previous Work
Suppose system diagnosed formally modeled joint probability distribution P r(X H) set variables partitioned X H. Variables X
whose values either observed measured, variables H health variables, one component describing health mode. joint probability distribution
P r(X H) defines set system states.
331

fiSiddiqi & Huang

Diagnosis starts initial (belief) state
I0 = P r(X H | Xo = xo )

(1)

values xo variables Xo X (we using boldface uppercase letters mean
sets vectors) given observation, wish reach goal state
= P r(X H | Xo = xo , Xm = xm )

(2)

measuring values xm variables Xm X\Xo , |Xm | = n, one time,
(the boldface 0 1 denote vectors 0s 1s):
Hf H, P r(Hf = 0 | Xo = xo , Xm = xm ) = 1
P r(Hf = 0, H\Hf = 1 | Xo = xo , Xm = xm ) > 0.
is, goal state set components Hf known faulty certainty
logical inconsistency arises components assumed healthy.
types goal conditions possible. example, health states components
determined certainty, condition P r(H = 0 | Xo = xo , Xm = xm )
0 1 H H (such goals possible reach strong fault models given,
strong fault models explicit descriptions abnormal behavior, opposed
weak fault models normal behavior known).
Two special cases worth mentioning: (1) initial state I0 satisfies goal
condition Hf = observation normal diagnosis required. (2)
initial state I0 satisfies goal condition Hf 6= , observation
abnormal diagnosis already completed (assuming able check
probabilities necessary); words, sequence length 0 solves problem.
Following de Kleer Williams (1987) assume measurements unit
cost. Hence objective reach goal state fewest measurements possible.
classical gde framework, receiving abnormal observation Xo = xo , considers
Shannons entropy probability distribution set computed diagnoses,
either set minimum-cardinality diagnoses set probable/leading diagnoses. proposes measure variable X whose value reduce entropy most,
average. idea probability distribution diagnoses reflects
uncertainty actual faults, entropy captures amount uncertainty.
measurement taken entropy updated updating posterior probabilities
diagnoses, potentially reducing 0.
results reported de Kleer et al. (1992) involving single-fault cases ISCAS-85
circuits indicate method leads measurement costs close optimal
policies. However, major drawback impractical number
diagnoses large (e.g., set minimum-cardinality diagnoses exponentially
large). Focusing smaller set probable diagnoses scales approach increase
likelihood irrelevant measurements generally leads increased average diagnostic
costs (de Kleer, 1992).
on, shall use combinational circuits example type systems
wish diagnose. approach, however, applies well types systems
332

fiSequential Diagnosis Abstraction

P
1
0

P
0.5
0.5

P
1
1
1
1
0
0
0
0

okJ
1
1
0
0
1
1
0
0

okJ
1
0
J
1
0
1
0
1
0
1
0

okJ
0.9
0.1

J|P,okJ
0
1
0.5
0.5
1
0
0.5
0.5

Figure 2: Bayesian network circuit Figure 1 (left). CPTs nodes P , J,
okJ (right).

long probabilistic model given defines behavior system. Sections 4
5 present new techniques introduced significantly enhance
scalability sequential diagnosis. start, however, presenting following section
system modeling compilation method underlies new diagnostic system.

3. System Modeling Compilation
order define joint probability distribution P r(X H) system behavior,
first assume prior probability failure P r(H = 0) given component
H H part input diagnosis task (de Kleer & Williams, 1987). example,
small table two entries top-right Figure 2 gives prior probability
failure gate J 0.1.
3.1 Conditional Probability Tables
Prior fault probabilities alone define joint probability distribution P r(X H).
addition, need specify component output related inputs
health mode. conditional probability table (CPT) component job.
CPT shown bottom (right) Figure 2, example, defines behavior
gate J: entry gives probability output (J) particular value given
value input (P ) value health variable (okJ). case okJ = 1,
probabilities always 0 1 behavior healthy gate deterministic.
case okJ = 0 defines fault model gate, also part input
diagnosis task. example, assume output values probability 0.5
gate broken. simplicity assume gates two health modes
333

fiSiddiqi & Huang

(i.e., health variable binary); encoding compilation described later,
however, allows arbitrary number health modes.
Given tables, joint probability distribution circuit behavior
obtained realizing gates circuit satisfy independence property, known
Markov property: Given inputs health mode, output gate independent
wire descendant gate (a wire X descendant gate X
reached following path output circuit direction towards
circuit outputs). means circuit effectively treated Bayesian
network straightforward way, node wire health variable,
edge going input gate output, also health
variable gate output. Figure 2 shows result translation circuit
Figure 1.
joint probability distribution encoded Bayesian network provides basis
computing posterior probabilities may need proposing measurement
points (by chain rule). However, provide efficient way so.
Specifically, computing posterior P r(X = x | = y) given values variables
known values involves summing variables X Y,
complexity exponential number variables done naively.
3.2 Propositional Modeling
known Bayesian network encoded logical formula compiled
d-DNNF, which, successful, allows posterior probabilities variables computed efficiently (Darwiche, 2003). purposes sequential diagnosis, encode
Bayesian network follows.
Consider subcircuit dotted box Figure 1 example,
modeled following formula:
okJ (J P ), okA (A (J D)).
Specifically, signal circuit translates propositional variable (A, D,
P , J), gate, extra variable introduced model health (okA, okJ).
formula health variables true remaining variables
constrained model functionality gates. general, component X,
okX NormalBehavior(X).
Note formula fails encode half CPT entries, okJ = 0.
order complete encoding CPT node J, introduce extra Boolean variable
J , write okJ (J J ). Finally, health variables (okA, okJ) associated
probabilities respective gates healthy (0.9 experiments),
-variable (J ) associated probability corresponding gate giving
output 1 broken (0.5 experiments; thus assuming output faulty
gate probabilistically independent inputs).
encoding circuit similar encoding Bayesian networks described Darwiche (2003) following way: According encoding Darwiche,
every node Bayesian network every value indicator variable.
Similarly every conditional probability network parameter variable.
334

fiSequential Diagnosis Abstraction

encoding, variables wires analogous network indicators,
encoding optimized single indicator values wire. Also,
encoding exploits logical constraints generate network parameters
zeros ones CPT. Finally, encoding node represents health variable optimized need single ok-variable serves
indicator network parameter.
components encoded described above, union (conjunction)
formulas compiled d-DNNF. required probabilities exactly computed
evaluating differentiating d-DNNF time linear size (Darwiche, 2003).
Details compilation process discussed Darwiche (2004), computation
probabilities described Appendix A.
present hierarchical diagnosis approach propose new measurement
selection heuristic.

4. Hierarchical Sequential Diagnosis
optimal solution sequential diagnosis would policy, is, plan measurements conditioned previous measurement outcomes, path plan leads
diagnosis system (Heckerman et al., 1995). computing optimal policies
intractable general, follow approach heuristic measurement point selection
previous work.
start definition Shannons entropy , defined respect
probability distribution discrete random variable X ranging values x1 , x2 , . . . , xk .
Formally:
k
X
(X) =
P r(X = xi ) log P r(X = xi ).
(3)
i=1

Entropy measures amount uncertainty value random variable.
maximal probabilities P r(X = xi ) equal, minimal one
probabilities 1, corresponding nicely intuitive notion degree uncertainty.
gde entropy computed probability distribution set computed
diagnoses (i.e., value random variable X ranges set diagnoses).
mentioned earlier, entropy difficult compute number diagnoses
large (de Kleer & Williams, 1987; de Kleer, 2006).
4.1 Baseline Approach
Able compute probabilities efficiently exactly following successful d-DNNF compilation, propose new two-part heuristic circumvents limitation scalability.
First, consider entropy candidate variable measured.
4.1.1 Heuristic Based Entropy Variable
Since wire X two values, entropy written as:
(X) = (px log px + px log px )
335

(4)

fiSiddiqi & Huang

px = P r(X = 1 | = y) px = P r(X = 0 | = y) posterior probabilities
X values 1 0, respectively, given values wires whose values
known.
(X) captures uncertainty value variable, also interpret
expected amount information gain provided measuring variable. Hence
first idea consider selecting variable maximal entropy measurement
step.
4.1.2 Improving Heuristic Accuracy
idea alone, however, work well initial experiments. would
confirmed subsequent experiments, largely due fact (implicit) space
diagnoses generally large include large number unlikely diagnoses,
tends compromise accuracy information gain provided entropy.
experiments confirm explanation follows.
d-DNNF compilation produced, used compute probabilities, prune d-DNNF graph models (satisfying variable assignments)
corresponding diagnoses k broken components removed.1 set
initial k number actual faults experiments, observed significant
reduction diagnostic cost resulted almost cases. improved performance apparently due fact pruning updates posterior probabilities variables,
making accurate since many unlikely diagnoses eliminated.
practice, however, number faults known beforehand choosing
appropriate k pruning nontrivial (note k need exactly
number actual faults pruning help). Interestingly, following heuristic,
one actually use, appears achieve similar performance gain
automatic way: select component highest posterior probability failure
(an idea Heckerman et al., 1995; see Section 8), variables
component, measure one highest entropy. heuristic require
pruning d-DNNF, appears improve diagnostic cost similar
extent focusing measurement selection component likely broken
(empirical results effect given discussed Section 7.1).
4.1.3 Algorithm
start encoding system logical formula discussed Section 3,
subset variables associated numbers representing prior fault probabilities
probabilities involved fault models components, compiled
d-DNNF .
overall sequential diagnosis process propose summarized Algorithm 1.
inputs system C, d-DNNF compilation , set faults (which empty
used hierarchical approach), set known values variables,
integer k specifying fault cardinality bound (this running model pruning
experiments described Section 4.1.2, required diagnosis using final
1. complete pruning easy; however, approximation achieved time linear d-DNNF
size, variant minimization procedure described Darwiche (2001); see Appendix B.

336

fiSequential Diagnosis Abstraction

Algorithm 1 Probabilistic sequential diagnosis
function psd(C, , D, y, k)
inputs: {C: system}, {: d-DNNF}, {y: measurements}, {k: fault cardinality}, {D: ordered set
known faults}
output: {pair< , >}
1: Reduce ( , D, k |D| ) changed
2: Given variables Y, Evaluate (, y) obtain P r(y)
3: Differentiate () obtain P r(X = 1, y) variables X
4: Deduce fault = {X : P r(okX = 1, y) = 0}
5: changed && MeetsCriteria(,D,y)
6:
return < , >
7: Measure variable X best given heuristic
8: Add measured value x X y, go back line 1

heuristic). reduce pruning models (line 1) fault cardinality bound
k given, using function reduce(, D, k |D|). reduce accepts arguments
current DNNF , set known faults D, upper bound given k
cardinality remaining faults, whereas returns pruned DNNF. Reduce excludes
known faults computing minimum cardinality , uses k |D|
bound remaining faults (explained Appendix B). reduced first
time psd called later time changed (i.e., component found
faulty). evaluate (line 2) differentiate (line 3) (see Appendix A), select
measurement point take measurement (line 7), repeat process (line 8)
stopping criteria met (line 5).
stopping criteria line 5 given earlier Section 2 goal condition, i.e.,
stop abnormal observation explained faulty components already
identified assuming components healthy. faulty component X identified
P r(okX = 1, y) = 0 values variables already known,
mentioned earlier probabilities obtained variables simultaneously
d-DNNF differentiation process. Finally, condition current set faulty
components, health modes Hf , explains observation satisfied P r(Hf =
0, H\Hf = 1, y) > 0, checked single evaluation original d-DNNF.
algorithm returns actual faults together new set known values variables
(line 6).
4.2 Hierarchical Approach
scale approach handle larger systems using idea abstraction-based
hierarchical diagnosis (Siddiqi & Huang, 2007). basic idea compilation
system model d-DNNF efficient scalable number
system components reduced. achieved abstraction, subsystems,
known cones, treated single components. example cone depicted
Figure 1. objective use single health variable failure probability
entire cone, hence significantly reducing size encoding difficulty
compilation. cone identified faulty top-level diagnosis,
compiled diagnosed, recursive fashion.
337

fiSiddiqi & Huang

give formal definition abstraction previous work:
4.2.1 Abstraction System
Abstraction based upon structural dominators (Kirkland & Mercer, 1987) system.
component X dominates component , X called dominator , path
output system contains X. cone corresponds precisely set
components dominated component. cone may contain cones leading
hierarchy cones.
system abstracted treating maximal cones black boxes (a maximal
cone one either contained cone contained exactly one cone
whole system). example, cone treated virtual gate
two inputs {P, D} output A. abstraction system formally defined
as:
Definition 1 (Abstraction System). Given system C, let C0 = C C single
output; otherwise let C0 C augmented dummy component collecting outputs
C. Let output C0 . abstraction AC system C set
components X C X dominated C0 component X
O.
example, AC = {A, B, D, K, V }. J 6 AC J cannot reach output without
passing A, dominator J.
previous work (Siddiqi & Huang, 2007), dealt task computing minimum-cardinality diagnoses, involve probabilities measurement
selection. context sequential diagnosis, several additional techniques
introduced, particularly computation prior failure probabilities cones
way measurement points selected, outlined below.
4.2.2 Propositional Encoding
start discussion hierarchical encoding probabilistic reasoning,
similar hierarchical encoding presented previous work (Siddiqi & Huang, 2007).
Specifically, diagnosis abstraction AC given system C, health variables
associated components AC \IC , gates {A, B, D, K, V }
example (IC stands set inputs system C). Thus gate J Figure 1
associated health variable, J wire internal cone rooted
A. Consequently, nodes representing components AC \IC health
nodes associated corresponding Bayesian network. Hence node okJ
removed Bayesian network Figure 2.
addition, define failure cone outputs wrong value,
introduce extra clauses model abnormal behavior cone. example,
encoding given Section 3.2 cone Figure 1 (in dotted box) follows:
J P, okA (A (J D)), okA (A 6 (J D))
first part formula encodes normal behavior gate J (without health
variable); next encodes normal behavior cone; last encodes
338

fiSequential Diagnosis Abstraction

cone outputs wrong value fails. gates (that roots cones)
abstraction AC encoded normally described Section 3.2.
Note formulas components cone together encode single CPT
whole cone, provides conditional probability cones output given
health inputs cone, instead health inputs component
root cone. example, encoding meant provide conditional
probability given P , D, okA (instead J, D, okA), okA represents
health mode whole cone associated prior failure probability,
initially unknown us computed cones (explained below).
encoding whole system provides joint probability distribution variables
AC IC H, H = {okX | X AC \IC }.
4.2.3 Prior Failure Probabilities Cones
cone treated single component, prior probability failure whole
computed given prior probabilities components cones inside it.
creating two copies h f cone, h models healthy behavior
cone (without health variables), f includes faulty behavior well (i.e.,
full encoding described Section 3.2). outputs h f collected
XOR-gate X(when output XOR-gate X equals 1, inputs forced
different value). compute probability P r(X = 1) giving probability
outputs h f different. probability computed compiling
encoding d-DNNF evaluating X = 1.
Note procedure also abstraction-based hierarchical, performed
bottom-up probabilities inner cones computed outer
ones. Also note performed per system pre-processing step.
4.2.4 Measurement Point Selection Stopping Criteria
principle, heuristic select variables measurement stopping criteria
baseline approach; however, couple details worth mentioning.
First, diagnosing abstraction given system (or cone) C, measurement
candidates restricted variables AC IC , ignoring internal variables maximal
conesthose measured cone whole found faulty.
Second, generally important full knowledge values cones inputs
final diagnosis cone concluded. diagnosis cone concluded
partial knowledge inputs may include faults vital validity
global diagnosis. reason diagnosis cone assumes unknown
inputs take either value, reality values may become fixed variables
parts system measured, causing diagnosis certain cones become
invalid, possibly requiring affected cones diagnosed meet
global stopping criteria (see line 17 Algorithm 2).
avoid situation retaining effectiveness heuristic, modify
measurement point selection follows diagnosing cone. selecting component
highest probability failure, consider variables component plus
inputs cone, measure one highest entropy. conclude
339

fiSiddiqi & Huang

Algorithm 2 Hierarchical probabilistic sequential diagnosis
function hpsd(C, uC , k)
inputs: {C : system},{uC : obs. across system} {k: fault cardinality}
local variables: {B, D, : set components} {y, z, uG : set measurements} {i, k 0 : integer}
output: {pair< , uC >}
1: Compile2dDNNF (AC , uC )
2: 0 , , uC
3: < B, > psd (C, , B, y, k)
4: {; < |B|; + +}
5:
G Element (B, i)
6:
G cone
7:
z Implications (, y)
8:
uG {x : x z, X IG OG }
9:
k 0 k |D| |B| + + 2
10:
< T, uG > hpsd(DG IG , uG , k 0 )
11:
uG ,
12:
Evaluate (, y), Differentiate ( )
13:
else
14:
{G}
15: z Implications (, y)
16: uC uC {x : x z, X IC OC }
17: MeetsCriteria (C, D, y)
18:
return < , uC >
19: else
20:
goto line 3

diagnosis cone values inputs become known (through measurement
deduction), except health components cone determined
without knowing inputs cone (it possible identify faulty component,
strong fault models also healthy component, without knowing inputs).
Note restriction measure inputs cone lead significant
increase cost compared cost baseline approach; especially number
inputs cone large. discussed detail Section 6.
4.2.5 Algorithm
Pseudocode hierarchical approach given Algorithm 2 recursive function.
inputs system C, set known values uC variables inputs IC
outputs OC system, optional integer k specifying fault cardinality
bound purpose experimenting effect model pruning. start
d-DNNF compilation abstraction given system (line 1) use
function psd Algorithm 1 get diagnosis B abstraction (line 3), assuming
measurement point selection stopping criteria Algorithm 1 modified
according described Section 4.2.4. abstract diagnosis B used
get concrete diagnosis loop (lines 414). Specifically, component G B
root cone, added (line 14); otherwise cone G recursively
diagnosed (line 10) result added (line 11). recursively diagnosing
340

fiSequential Diagnosis Abstraction

cone G, subsystem contained G represented DG IG , DG set
components dominated G IG set inputs cone G.
recursively diagnosing cone G, compute abnormal observation uG
inputs output (IG {G}) cone G. values Gs inputs output
either measured deduced current set measurements. value
variable X implied x measurements P r(X = x, y) = 0,
easy check differentiated y. function Implications(, y)
(lines 7 15) implements operation, used compute partial abnormal
observation uG (line 8). fault cardinality bound k 0 cone G inferred (line 9),
algorithm called recursively diagnose G, given uG k 0 .
recursive call returns faults inside cone G together updated
observation uG . observation uG may contain new measurement results regarding
variables IG {G}, added set measurements abstraction
(line 11); measurement results obtained inside cone ignored due reasons
explained Section 4.2.4. concrete diagnosis augmented faults found
inside cone (line 11), evaluated differentiated light new
measurements (line 12).
loop ends, variable uC updated known values inputs
IC outputs OC system C (line 16). stopping criteria checked
diagnosis (line 17) met function returns pair < D, uC > (line 18); otherwise
measurements taken stopping criteria (line 17) met.
Since contain faults inside cones, compilation cannot used
check stopping criteria (note change parameters function
MeetsCriteria line 17) probabilistic information regarding variables inside cones
available . criteria checked follows instead: maintain depth
level every component system. outputs system depth level 1
rest components assigned depth levels based upon length shortest
route output system. example, Figure 1 gates B J depth
level 3, depth level 2. Hence, B J deeper A. first propagate
values inputs system, propagate fault effects components
D, one one, flipping values abnormal ones propagating towards
system outputs way deeper faults propagated first (Siddiqi & Huang,
2007), check values system outputs obtained equality
observation (y).
4.2.6 Example
Suppose diagnose abstraction circuit Figure 1, observation
uC = {P = 1, Q = 1, R = 0, V = 1}, take sequence measurements = {D =
1, K = 1, = 1}. concluded, abstract system model, given values
P D, value 1 abnormal. algorithm concludes fault A. Note
Q = 1 = 1 suggests presence another fault besides A, triggering
measurement gate B, also found faulty. abstract diagnosis {A, B} meets
stopping criteria respect abstract circuit.
341

fiSiddiqi & Huang

1
P

1
Q

1

1
E

J

1
B

1


1

1


V

1
K

0
R

Figure 3: faulty circuit faults B J.
1
P

1
J

1
E

1


1
B
1
Q

1
B'

1

1


V

1
K

0
R

Figure 4: Creating clone B 0 B according D.
enter diagnosis cone recursive call observation uA = {P =
1, B = 1, = 1}. diagnosis cone immediately reveals cone E
faulty. Hence make recursive call order diagnose E observation
uE = {P = 1, B = 1, E = 1}. unknown wire J measured gate J found
faulty, explains observation outputs cones E well A, given
inputs P B. recursion terminates abstract diagnosis B = {A, B} generates
concrete diagnosis = {J, B}, meets stopping criteria algorithm
terminates.

5. Component Cloning
preceding section, proposed abstraction-based approach sequential diagnosis, reduces complexity compilation diagnosis reducing number
system components diagnosed. take one step further, aiming handle
systems large remain intractable even abstraction, case
largest circuits ISCAS-85 benchmark suite.
solution novel method systematically modifies structure system
reduce size abstraction. Specifically, select component G parents P (a
component X parent component , child X, output
input X) part cone hence cannot abstracted away hierarchical
342

fiSequential Diagnosis Abstraction

diagnosis, create clone G0 according parents P0 P sense
G0 inherits children G feeds P0 G longer feeds P0 (see
Figures 3 4 example). idea create sufficient number clones G
G clones become part cones hence abstracted away.
Repeated applications operation allow otherwise unmanageable system
small enough abstraction compilation diagnosis succeed. hierarchical
algorithm extended diagnose new system result mapped
original system. show solve almost benchmark circuits, using
approach.
go details new method, differentiate technique
known node splitting (Choi, Chavira, & Darwiche, 2007), used solve MPE
queries Bayesian network. Node splitting breaks enough number edges
nodes network MPE query resulting network becomes easy
solve. broken edge replaced root variable uniform prior. resulting
network relaxation approximation original MPE solution,
may computed compilation, gives upper bound MPE solution
original network. depth-first branch bound search algorithm searches
optimal solution using bounds prune search space. similar approach also
used solve Weighted Max-SAT problems (Pipatsrisawat & Darwiche, 2007).
version node splitting directly applicable present setting
following reasons. edges system broken redirected new root variables
(primary inputs), resulting system represents different input-output function
original system. abnormal observation original system may hence
become normal one new system (if edges fault propagates
broken), eliminating basis diagnosis. technique component cloning,
also viewed version node splitting, introduces clones component instead
primary inputs preserves input-output function system. Also, new
system relaxation original diagnoses superset
original.
formally define component cloning:
Definition 2 (Component Cloning). Let G component system C parents
P. say G cloned according parents P0 P system C results
system C0 follows:
edges going G parents P0 removed.
new component G0 functionally equivalent G added system
G0 shares inputs G feeds P0 .
Figures 3 4 show example creating clone B 0 B according {D}
results new circuit whose abstraction contains gates {A, D, K, V }, whereas
abstraction original circuit contains also gate B.
5.1 Choices Component Cloning
two choices made component cloning: components clone,
many clones create split parents?
343

fiSiddiqi & Huang

Since goal cloning reduce abstraction size, clear wish
clone components lie abstraction (i.e., within cones). Among these,
cloning root cone cannot reduce abstraction size destroy existing
cone reintroducing components inside cone abstraction.
example, cloning according K Figure 4 produce circuit clone
abstracted away B 0 longer dominated hence reintroduced
abstraction. Therefore, final candidates cloning precisely components
abstract system roots cones. Note order
candidates processed unimportant cloned produce equal
reduction, namely reduction precisely 1 abstraction size, any.
remains determine candidate many clones create
connect parents. understand final method, helps consider
naive method simply creates |P| 1 clones (where P set parents)
clone, well original, feed exactly one parent. way every parent
component becomes root cone component clones
abstracted away. Figure 3, example, B three parents {E, A, D}, naive
method would create two clones B total three instances gate split
three parents, would result abstraction Figure 4.
trick number clones reduced knowing parents
component may lie cone single clone component according
parents sufficient clone abstracted away. example
Figure 3, again, parents E, B lie cone would suffice create
single clone B according {E, A}, resulting same, efficient cloning
Figure 4.
formally, partition parents component G subsets P1 , P2 , . . . , Pq
parents G lie cone placed subset
rest separate ones. create q 1 clones G according q 1
subsets, resulting G clones abstracted away. process repeated
candidate component abstraction size small enough reduction
possible.
5.2 Diagnosis Component Cloning
new system functionally equivalent original smaller abstraction,
equivalent original diagnostic purposes. new model allows
component clones fail independently other, relaxation
original model diagnoses new system form superset
original. Specifically, diagnosis new system assigns health state
component clones components corresponds diagnosis original
system; diagnoses spurious ignored.
core diagnosis process given Algorithm 2 continues applicable new
system, two minor modifications necessary. First, spurious diagnoses
(implicitly) filtered assuming health state clones (including
original) component soon health state one known. Second,
whenever measurement clone component proposed, actual measurement
344

fiSequential Diagnosis Abstraction

c7552
Number Cone Inputs

60
50
40
30
20
10
0
0

500

1000

1500

2000

2500

Cones

Figure 5: Cones ISCAS-85 circuits.

taken original component original system, obvious reasons (in words,
new system used reasoning original measurements).
principle, presence spurious diagnoses model potentially skew
measurement point selection heuristic (at least early stages diagnosis,
spurious diagnoses gradually filtered out). However, using smaller benchmarks
could diagnosed without cloning, conducted empirical analysis
indicates, interestingly, overall diagnostic cost slightly affected.
discuss detail Section 7.3.

6. Diagnostic Cost Estimation
address interesting issue stemming observation made conducting experiments (to detailed next section): system abstraction always beneficial
compilation, diagnostic cost always improve associated hierarchical
diagnosis. one hand, hierarchical diagnosis approach help cases
otherwise result high costs using baseline approach quickly finding faulty portions
system, represented set faulty cones, directing sequential diagnosis
take measurements inside cones, resulting useful measurements.
hand, introduce overhead cases needlessly go hier345

fiSiddiqi & Huang

archies locate actual faults, measure inputs cones involved, baseline
version find directly efficiently.
overhead hierarchical approach quite high faults lie cones
large number inputs. example, graphs Figure 5 show number inputs,
represented dots, various cones ISCAS-85 circuits. Note cones
small number inputs; however, cones 30 inputs, especially
c432 circuits beyond c1908, contribute increased diagnostic cost
several cases (such increase cost due cones also confirmed separate set
experiments using large set systematically generated combinational circuits, detailed
Appendix C). avoid potential high cost diagnosis faults lie cone
large number inputs tempting destroy cone compilation
fault directly found. However, due associated increase
abstraction size, destroying cones may cause increased costs cases could
previously solved efficiently, thus may show negative impact, overall.
calls automatic mechanism predict effect destroying certain cones
overall diagnostic cost, subject section.
propose novel cost estimation function predict average diagnostic cost
given abstraction system considered diagnosis, different abstractions
obtained destroying different cones system. Since cones destroyed
automatically, function used automatically propose abstraction system, used diagnosis, likely give optimal average cost. function
uses hierarchical structure given abstraction predict cost
take account parameters may also contribute cost, probabilities. addition function limited single fault cases only. Therefore, expected
cost computed function indicative cannot always correct. However,
experiments show function often quite useful proposing abstraction
system likely give optimal cost (to discussed next section).
estimate expected diagnostic cost assume composed two quantities
namely isolation cost abstraction cost, inversely proportional
other. isolation cost captures well given system abstraction isolate
faulty portions system. Therefore isolation cost minimum complete
abstraction system used (i.e., cones considered) generally increases
cones destroyed. abstraction cost captures overhead cost due introduction
cones. Hence, abstraction cost minimum (zero) abstraction considered
generally increases cones introduced.
define isolation cost diagnosis considering abstraction system
average cost required isolate single fault system using abstraction.
Similarly, define abstraction cost diagnosis average overhead cost required
diagnose single fault system using abstraction. expected average
cost diagnosis abstraction system considered diagnosis sum
isolation abstraction costs abstraction. different cones destroyed
given abstraction system expect changes values abstraction
isolation costs, determine whether overall cost go (if changes
uneven) stay constant (if changes even). idea obtain abstraction
346

fiSequential Diagnosis Abstraction

system strike balance two quantities get overall optimal cost.
discuss isolation abstraction costs estimated.
noted experiments using baseline approach heuristic
isolate single fault system cost average comparable log2
number measurement points system, provided us basis
computing isolation cost. hierarchical approach, fault lies inside cone
one first estimate isolation cost diagnosing cone, separately, add
isolation cost diagnosing abstract system get average isolation cost
(single) faults lie cone. example, cones considered
cost isolating fault circuit Figure 3 log2 (6) = 2.58 (values P , Q, R
V already known). However, cones considered cost isolating fault
lies inside cone sum isolation cost abstract circuit
isolation cost subcircuit inside cone A, log2 (4) + log2 (1) = 2. Similarly,
get average isolation cost single faults system, using hierarchical
approach, one add isolation cost diagnosing abstract system average
isolation costs diagnosing abstract components (where isolation cost
abstract component cone zero). Note isolation cost
diagnosing cone computed taking abstraction cone.
estimate abstraction cost diagnosis given abstraction first need
estimate overhead cost involved individual component system
abstraction. estimate overhead cost a, possibly faulty, component one
take union inputs outputs cones component lies,
number measurement points (approximately) constitutes required overhead
cost component. component lie cone overhead cost
component zero. example, circuit Figure 3 diagnosed using
hierarchical approach, find gate J faulty one must first find cone
faulty cone E faulty gate J faulty. overhead
cost gate J case 1 + 2 + 1 = 4 (i.e., measure wires A, B, E,
J, assuming Q known). abstraction cost diagnosis given abstraction
system average overhead costs system components
abstraction.
give formal definitions related cost estimation function. Let Pu (C)
set measurement points system C whose values unknown,
Pu (G) set inputs output abstract concrete component G whose
values unknown. Let p number abstract components abstraction AC
system C. Let Gi AC abstract component (either concrete component cone
abstraction; concrete component abstraction regarded trivial
cone containing component itself). Let DGi subsystem dominated Gi
AGi abstraction subsystem.
isolation cost IC(C, AC ) abstraction AC system C considered
diagnosis sum log2 (|M Pu (AC )|) average isolation costs computed,
similar manner, subsystems contained abstract components AC :
347

fiSiddiqi & Huang

(
Pp
log2 (|M Pu (AC )|) + p1
i=1 IC(DGi , AGi ), |M Pu (AC )| > 0
IC(C, AC ) = 1 Pp
otherwise
i=1 IC(DGi , AGi )
p

(5)

IC(DGi , AGi ) recursively computes isolation cost subsystem contained
abstract component Gi , using Equation 5, taking abstraction AGi . Note
computing IC(DGi , AGi ) assume inputs output Gi already
measured. Thus Pu (DGi ) excludes inputs output cone Gi . Gi
concrete
component IC(DGi , AGi ) = 0. cones considered (AC = C)
Pp
IC(D
Gi , AGi ) = 0 isolation cost simply equal log2 (|M Pu (C)|).
i=1
compute abstraction cost diagnosing system given abstraction
first compute overhead costs diagnosing individual cones abstraction.
multiply abstraction cost cone number components contained
cone get total overhead cost components cone. Adding
overhead costs computed way cones abstraction dividing
number total number concrete components whole system gives us
average overhead cost per component, call abstraction cost. Formally: Let
q cones AC . abstraction cost AC(C, AC ) abstraction AC
system C considered diagnosis given as:

AC(C, AC ) =

q
1 X
|DGi | {M Pu (Gi ) + AC(DGi , AGi )} : Gi AC cone
n

(6)

i=1

|DGi | number (concrete) components contained cone Gi , Pu (Gi )+
AC(DGi , AGi ) recursively computes abstraction cost diagnosing cone Gi , using
Equation 6, taking abstraction AGi . abstraction cost Gi multiplied
|DGi | effectively add cost measuring cone inputs output overhead cost
every component inside cone. note computing AC(DGi , AGi )
assume variables Pu (Gi ) already measured. Thus Pu (DGi )
excludes inputs output cone Gi .
Finally total expected cost EDC(C, AC ) diagnosing system C abstraction AC system considered diagnosis given as:
EDC(C, AC ) = IC(C, AC ) + AC(C, AC ).

(7)

7. Experimental Results
section provides empirical evaluation new diagnostic system, referred
sda (sequential diagnosis abstraction), implements baseline, hierarchical,
cloning-based approaches described Sections 4 5, cost estimation function
described Section 6. experiments conducted cluster 32 computers consisting two types (comparable) CPUs, Intel Core Duo 2.4 GHz AMD Athlon 64
X2 Dual Core Processor 4600+, 4 GB RAM running Linux. time limit 2
348

fiSequential Diagnosis Abstraction

hours memory limit 1.5 GB imposed test case. d-DNNF compilation done using publicly available d-DNNF compiler c2d (Darwiche, 2004, 2005).
CNF simplified compilation using given observation, allowed us
compile circuits, expense requiring fresh compilation per observation
(see Algorithm 2, line 1).
generated single- multiple-fault scenarios using ISCAS-85 benchmark circuits,
scenario set gates assumed faulty. single-fault cases circuits
c1355 simulated equal prior probability faults generating n fault scenarios
circuit, n equals number gates circuit: scenario contains
different faulty gate. randomly generated 5 test cases (abnormal observations)
n scenarios. multiple-fault scenarios would practical
due large number combinations, circuit c1355 (respectively, larger
c1355) simply generated 500 (respectively, 100) random scenarios given
fault cardinality random test case scenario.
Thus test case faulty circuit gate gates give incorrect
outputs. inputs outputs circuit observed. values internal wires
computed propagating inputs normal circuit towards outputs followed
propagating outputs assumed faulty gates one one deeper faults
propagated first. obtained values internal wires used simulate
results taking measurements. use P r(okX = 1) = 0.9 gates X circuit.
Note cases, gates fail equal probability, conceivably harder
solve diagnoses tend less differentiable. Then, gate, two output
values given equal probability gate faulty. Again, tend make
cases harder solve due high degree uncertainty. circuit fault
cardinality, report cost (number measurements taken) time (including
compilation time, CPU seconds) locate faults, averaged test cases solved.
present experiments four subsections demonstrating effectiveness
four techniques proposed paper, namely new heuristic, hierarchical sequential
diagnosis, component cloning, cost estimation function.
7.1 Effectiveness Heuristic
start comparison baseline algorithm sda gde show sda
achieves similar diagnostic costs scales much larger circuits, hence illustrating
effectiveness new heuristic (along new way compute probabilities).
7.1.1 Comparison gde
could obtain tutorial version gde (Forbus & de Kleer, 1993) comparison, downloadable http://www.qrg.northwestern.edu/BPS/readme.html. gde uses
ATCON, constraint language developed using LISP programming language, represent diagnostic problem cases. detailed account language given Forbus
de Kleer (1993). Further, employs interactive user interface proposes measurement points respective costs lets user enter outcomes measurements.
purpose comparison translated problem descriptions language accepted gde, also modified gde automatically read measurement outcomes
349

fiSiddiqi & Huang

size system
13
14
15
16
17

gde
sda
gde
sda
gde
sda
gde
sda
gde
sda

single-fault
cost time
3.6
2.0
3.6 0.01
3.5 6.66
4.2 0.01
3.4
111
3.9 0.01
3.3
398
3.5 0.01
3.7 2876
3.8 0.01

double-fault
cost time
3.8
1.81
3.4
0.01
3.3
15.1
2.9
0.01
3.5
88
3.4
0.01
3.5
556
3.3
0.01
4.6
4103
4.2
0.01

triple-fault
cost time
4.0
1.9
2.8 0.01
3.0
14
2.9 0.01
4.3
299
3.7 0.01
3.2
509
2.8 0.01
4.5 2067
4.2 0.01

Table 1: Comparison gde.
input problem description. also compiled LISP code machine dependent
binary code using native C compiler improve run-time performance.
version gde, developed tutorial purposes, computes set minimal diagnoses instead probable diagnoses. makes comparison less informative. Nevertheless, able make reasonable comparison terms diagnostic cost set
minimal diagnoses also serve large set probable diagnoses components
equal prior probabilities. According de Kleer (1992) availability diagnoses
aids heuristic accuracy, whereas focusing smaller set probable diagnoses
computationally efficient increase average diagnostic cost.
version gde fact unable solve circuit ISCAS-85. enable
useful comparison, extracted set small subcircuits ISCAS-85 circuits:
50 circuits size 13, 14, 15 16, 10 circuits size 17. circuit randomly generated 5 single-fault, 5 double-fault, 5 triple-fault scenarios, one test
case (input/output vector) fault scenario. comparison gde sda
(baseline) benchmarks given Table 1 shows sda performs well gde
terms diagnostic cost.
7.1.2 Larger Benchmarks
evaluate performance sda larger ISCAS-85 circuits, conducted three sets experiments, time involving single, double, five faults, respectively. version gde available us unable handle circuits, order
provide systematic reference point comparison implemented random strategy random order measurement points generated circuit used
test cases. strategy also uses d-DNNF check whether stopping
criteria met.
Table 2 shows comparison random strategy sda using baseline
approach two different heuristics, one based entropies wires alone (ew)
based also failure probabilities (fp). three systems ran
set experiments without pruning d-DNNF (using known fault cardinality
described Section 4.1.2), indicated third column table. test
cases first four circuits could solved. circuits failure occurred
compilation phase, hence affected random strategy sda.
350

fiSequential Diagnosis Abstraction

circuit system pruning
c432

rand

(160 gates)

sda(ew)
sda(fp)

c499

rand

(202 gates)

sda(ew)
sda(fp)

c880

rand

(383 gates)

sda(ew)
sda(fp)

c1355

rand

(546 gates)

sda(ew)
sda(fp)


yes

yes

yes

yes

yes

yes

yes

yes

yes

yes

yes

yes

single-fault
cost time
92.3 20.7
4.5 11.4
42.0 16.6
3.7 11.1
6.7 11.7
4.3 11.0
109.6 0.8
5.5
0.2
58.1 0.7
3.6
0.2
6.5
0.2
4.8
0.2
221.0 1.9
5.4
0.2
26.8 0.3
4.0
0.2
10.8 0.2
5.6
0.2
327.2 4.3
7.4
0.4
82.6 1.3
4.9
0.4
34.1 0.8
8.0
0.4

double-fault
cost time
97.7 23.2
36.8 12.4
42.5 21.3
8.6
12.0
6.4
12.5
5.0
12.3
120.6 1.2
20.1
0.2
54.0
0.5
3.7
0.2
4.3
0.2
3.0
0.2
251.3 1.9
47.3
0.3
32.8
0.4
6.8
0.2
9.2
0.2
6.7
0.2
365.7 5.7
59.0
1.0
91.2
1.5
5.5
0.4
14.8
0.5
9.4
0.6

five-fault
cost time
117.8 26.5
99.7 17.2
68.4 25.5
33.8 12.8
9.4 13.0
9.1 12.6
150.0 1.4
104.9 0.7
95.8 0.8
35.7 0.3
7.2 0.2
7.1 0.2
306.4 2.3
205.7 1.3
79.0 0.7
30.5 0.4
15.8 0.3
14.0 0.3
437.4 5.6
328.6 3.5
203.9 3.4
65.9 1.1
19.3 0.8
18.4 0.6

Table 2: Effectiveness heuristic.
clear diagnostic cost significantly lower heuristics sda
random strategy whether pruning used. also interesting
note pruning significantly reduces diagnostic cost random sda-ew
strategies, much less effect sda-fp except cases (c1355 single-fault).
Moreover, sda-fp generally dominates sda-ew, without pruning.
may also observe (i) five-fault cases, sda-fp without pruning results
much lower diagnostic cost sda-ew pruning; (ii) double-fault cases, two
largely comparable; (iii) single-faults cases, comparison reversed.
indicates fault cardinality rises, combination failure probabilities wire
entropies appears achieve effect similar pruning. sda-ew pruning
performs better sda-fp without pruning single-fault cases attributed
fact cases pruning always exact hence likely result maximum
benefit.
7.2 Effectiveness Abstraction
report, Table 3, results repeating experiments sda-fp using
hierarchical approach.
notably, running time generally reduces cases able
handle two circuits, namely c1908 c2670, solving 139 300 cases c1908 (25
single-, 15 double-, 99 five-fault cases) 258 300 cases c2670 (100
351

fiSiddiqi & Huang

circuit

pruning

c432


yes

yes

yes

yes

yes

yes

(64 cones)

c499
(90 cones)

c880
(177 cones)

c1355
(162 cones)

c1908
(374 cones)

c2670
(580 cones)

single-fault
cost time
15.4
0.4
4.9
0.3
7.3
0.1
4.5
0.1
9.5
0.1
5.6
0.1
9.3
0.3
5.8
0.2
11.0
222
3.0
214
16.3
213
6.5
196

double-fault
cost
time
15.8
0.5
10.4
0.4
5.8
0.1
3.9
0.1
10.2
0.1
7.6
0.1
8.2
0.2
6.3
0.2
17.1
587
8.5
463
19.2
172
13.3
90

five-fault
cost time
22.2 0.5
21.5 0.4
10.5 0.2
9.6 0.2
17.4 0.2
16.3 0.2
14.0 0.3
14.4 0.3
34.9 505
32.4 383
25.4 58
24.3 45

Table 3: Effectiveness abstraction.

circuit
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

total
gates
160
202
383
58
880
1193
1669
2307
2416
3512

abstraction
size
59
58
77
58
160
167
353
385
1456
545

cloning
time
0.03
0.02
0.1
0.05
0.74
0.77
5.64
3.6
0.16
6.68

total
clones
27
0
24
0
237
110
489
358
0
562

abstraction size
cloning
39
58
57
58
70
116
165
266
1456
378

Table 4: Results preprocessing step cloning.

single-, 60 double-, 98 five-fault cases). failures occurred
compilation phase. Note observations cause sufficient simplification
theory successfully compiled even abstraction. terms diagnostic
cost, cases hierarchical approach comparable baseline approach.
c432, baseline approach consistently performs better hierarchical fault
cardinality, reverse true c1355. Note also pruning helps reduce
diagnostic cost various degrees baseline approach.
discussed earlier, results confirm main advantage hierarchical approach
larger circuits solved. circuits also solved baseline
approach, hierarchical approach may help reduce diagnostic cost quickly finding
faulty portions circuit, represented set faulty cones, directing
measurements inside them, result useful measurements (e.g. case
c1355). hand, may suffer cases needlessly go
hierarchies locate actual faults, baseline version find directly
efficiently (e.g. case c432). discussed Section 7.4.
352

fiSequential Diagnosis Abstraction

circuit
c432
c880

single-fault
cost
time
7.2
10.3
11.2
0.2

double-fault
cost
time
6.6
7.8
9.3
0.2

five-fault
cost time
9.6
9.7
16.2
0.3

Table 5: Effect component cloning diagnostic performance.
circuit
c432
c880
c1908
c2670
c3540
c5315
c7552

single-fault
cost
time
15.2
0.1
8.8
0.1
13.6
2.8
13.5
4.5
27.8
382
7.2
2.5
70.6
1056

double-fault
cost
time
14.8
0.1
9.3
0.1
18.3
5.0
15.3
0.7
30.5
72.5
21.1
5.9
43.1
129.0

five-fault
cost
time
20.2
0.1
15.8
0.2
35.4
5.1
20.1
2.3
36.1
108.6
24.4
6.6
104.8 1108

Table 6: Hierarchical sequential diagnosis component cloning (c499 c1355 omitted already easy diagnose cloning lead reduced
abstraction).

7.3 Effectiveness Component Cloning
subsection discuss experiments component cloning. show cloning
significantly affect diagnostic cost allows us solve much larger circuits,
particular, nearly circuits ISCAS-85 suite.
Table 4 shows result pre-processing step cloning circuit.
columns give name circuit, total number gates circuit, size
abstraction circuit cloning, time spent cloning, total number
clones created circuit, abstraction size circuit obtained cloning.
circuits except c499, c1355, c6288, significant reduction abstraction size
achieved. c6288 appears extreme case large abstraction
lacks hierarchy; gates abstractions c499 c1355 roots cones,
affording opportunities reduction (note two circuits already
simple easy diagnose).
start investigating effect component cloning diagnostic performance.
isolate effect component cloning use baseline version sda (i.e., without
abstraction), without pruning. Table 5 summarizes performance baseline sda
cloning circuits c432 c880. Comparing results corresponding entries Table 2 shows overall diagnostic cost slightly affected
cloning. observed significant number cases proposed measurement sequence change cloning, cases changed
insubstantially. Moreover, number cases, although substantially different
sequence measurements proposed, actual diagnostic cost change much.
Finally, note diagnosis time case c432 reduced cloning,
ascribed general reduction complexity compilation due smaller
abstraction.
353

fiSiddiqi & Huang

circuit
c432

c499

c880

c1355

c1908

c2670

total max. cone abstraction measurement
AC IC EDC
cases inputs
size
points
38
39
32
11.51 5.67 17.1
800
18
49
42
5.22 6.05 11.2
14
52
45
4.87 6.11 10.9
9
53
46
4.64 6.14 10.8
4
104
97
2.11 6.72 8.8
0
187
180
0.00 7.50 7.5
8
58
26
3.77 5.32 9.0
1010
5
74
42
3.13 5.91 9.0
3
170
138
0.71 7.10 7.8
0
202
170
0.0 7.40 7.4
16
57
31
6.54 5.42 11.9
1915
14
74
48
5.75 6.02 11.7
10
105
79
4.22 6.72 10.9
6
170
144
2.70 7.48 10.1
0
407
381
0.0 8.57 8.5
8
58
26
3.59 6.34 9.9
2730
5
98
66
2.74 7.20 9.9
4
114
82
2.47 7.27 9.7
3
266
234
1.43 8.23 9.6
2
426
394
0.43 8.77 9.2
0
546
514
0.0 9.00 9.0
40
70
45
14.37 7.07 21.4
859
29
76
51
12.85 7.15 20.0
28
80
55
12.70 7.23 19.9
27
82
57
12.62 7.27 19.8
20
138
113
8.36 7.82 16.2
18
150
125
7.79 7.92 15.7
55
56
52
17.84 6.40 24.2
989
34
58
57
16.19 6.53 22.7
33
128
64
15.63 6.68 22.3
25
178
114
11.52 7.44 18.9

cases
solved
800
800
800
800
800
800
1010
1010
1010
1010
1915
1915
1915
1915
1915
2730
2730
2730
2730
2730
2730
859
859
859
859
859
859
989
989
989
970

single-fault
cost time
15.2 0.06
11.0 0.1
11.0 0.1
10.7 0.1
8.8
0.3
7.3
7.3
7.3
0.1
7.7
0.1
9.4
0.1
6.4
0.1
8.7
0.1
8.5
0.1
8.0
0.1
8.6
0.1
10.8 0.2
9.30 0.1
12.55 0.2
12.39 0.2
22.5 0.3
33.5 0.4
34.0 0.4
18.7 2.6
17.8 5.8
18.3 5.9
18.2 5.9
17.7 15.0
17.7 47.5
19.2 0.7
19.1 0.8
18.6 0.8
16.1 79.0

Table 7: Effectiveness diagnostic cost estimation.
final set experimental results ISCAS-85 circuits, summarized Table 6,
illustrates performance hierarchical sequential diagnosis component cloning
scalable version sda. test cases circuits c1908 2670
solved, largest circuits benchmark suite could handled: cases
c5315, 164 300 cases c3540 (34 single-, 65 double-, 65 five-fault
cases), 157 300 cases c7552 (60 single-, 26 double-, 71 fivefault cases) solved. terms diagnostic cost cloning generally resulted slight
improvement. terms time difference insignificant c432 c880,
larger circuits (c1908 c2670) diagnosis cloning clearly order
magnitude faster.
7.4 Effectiveness Diagnostic Cost Estimation
Finally, demonstrate effectiveness cost estimation function. show
often possible destroy different cones obtain different abstractions system
354

fiSequential Diagnosis Abstraction

successfully compiled, then, using cost estimation function, select
abstraction used diagnosis likely give optimal average cost.
results also help explain cases hierarchical approach causes diagnostic cost
increase compared baseline approach.
experiments, use sda cloning include circuits c2670, considering single-fault test cases. include largest circuits analysis
circuits often could compiled cones destroyed; therefore possible obtain overall picture actual cost circuits. Test
cases circuits c1355 used before, whereas circuits c1908
c2670, time, use complete set cases done smaller circuits. Specifically, generate n fault scenarios circuit, n equals number gates
circuit: scenario contains different faulty gate. randomly generate
1 test case n scenarios (in cases, could obtain test case
reasonable time corresponding scenarios used).
results experiments summarized Table 7. circuit first row
shows results cones considered subsequent rows show results
cones specified number inputs (in column 3)
destroyed. value column 3 0 get trivial abstraction, cones
destroyed, equivalent using baseline approach. last two
columns show (actual) average cost time diagnosing circuit using given
abstraction. columns labeled AC, IC, EDC show values obtained using
equations 6, 5, 7, respectively, given abstraction.
results show often able destroy several cones still able
compile circuit successfully. However, quite naturally, compilation time increases
cones destroyed point circuits start fail compile,
stop destroying cones. actual diagnostic cost different circuits show different
trends time cones destroyed. example, c432 shows significant
improvement reverse true c1355. remaining circuits actual cost shows
somewhat mixed trends; however, relative increase decrease costs generally
less significant.
Comparison isolation abstraction costs (i.e., IC AC, respectively)
various abstractions confirms time cones destroyed isolation cost
increases abstraction cost decreases. potentially imbalanced change
two costs determines whether cost might go cones
destroyed. example, case c432 abstraction cost drops rapidly
isolation cost increases cones destroyed, case c1355 two
costs change almost pace.
Comparison predicted costs EDC actual costs shows c432,
c499, c1908, c2670 predicted costs often quite close actual costs,
demonstrates relative accuracy approach. result, circuits
cost estimation function accurately predict abstraction likely give
optimal cost. example, correctly suggests one use baseline approach
c432. two circuits, c880 c1355, predicted actual costs
significantly different, cost estimation function fails give good predictions. c1355
355

fiSiddiqi & Huang

seems special case actual diagnostic cost increases quite rapidly
cones destroyed, reason interesting topic future work.

8. Related Work
et al. (1994) considered two kinds hierarchical models discussed automatic
methods constructing abstractions. first kind, components given
detailed model aggregated single components abstract model, every
diagnosis detailed model, refined diagnosis abstract model, guaranteed
valid. Thus need check validity detailed diagnoses afterwards.
second kind, abstract model constructed always possible
determine unique diagnosis every level hierarchy reasonable cost,
measurements less costly make appear abstract model
costly measurements appear detailed model. techniques automatic
abstraction-based system observability discussed Torta Torasso (2003, 2008).
papers provide alternative techniques automatic abstraction; however,
address sequential diagnosis.
idea testing likely failing component comes Heckerman et al. (1995),
testing component considered unit operation components
tested decreasing order likelihood failure, computed assuming
single fault (this assumption could compromise quality measurement sequence
multiple-fault cases authors pointed out). case, contrast, testing
variable component unit operation, calling complex heuristic
order minimize number tests; also, need assume single fault.
work also goes scalability using several structure-based techniques: compilation,
abstraction, component cloning.
Chittaro & Ranon (2004) considered computation diagnoses using hierarchical
algorithm. method takes hierarchical decomposition system input,
sets components aggregated units, computes set diagnoses
abstract level, refined hierarchically detailed level. Feldman &
van Gemund (2006) developed hierarchical diagnosis algorithm tested reverse
engineered ISCAS-85 circuits (Hansen, Yalcin, & Hayes, 1999) available highlevel form. idea decompose system hierarchies way minimize
sharing variables them. done well engineered problems
formed hierarchies hand ISCAS-85 circuits. system represented
hierarchical logical formula hierarchy represented traditional CNF
formula. representation translated fully hierarchical DNF, fully flattened
DNF, partially flattened DNF dictated depth parameter, hierarchical
search algorithm employed find diagnoses. hierarchical aspect two
approaches similar ours; however, require hierarchical decomposition
system either given part input, obtained hand, approach
searches hierarchies automatically. Another major difference consider
computation diagnoses address problem sequential diagnosis.
Based gde framework, de Kleer (2006) studied sensitivity diagnostic
cost called -policy, policy quantifies posterior
356

fiSequential Diagnosis Abstraction

probabilities diagnoses estimated gde computes heuristic.
case, probabilities diagnoses required all, probabilities
required computed exactly evaluating differentiating d-DNNF.
Nevertheless, algorithm sensitive initial probabilistic model given
sensitivity analysis regard may lead interesting findings.
Recently, Flesch, Lucas, & van der Weide (2007) proposed new framework integrate
probabilistic reasoning model-based diagnosis. framework based upon notion
conflict measure, originated tool detection conflicts
observation given Bayesian network (Jensen, 2001). system modeled
Bayesian network diagnostic reasoning, possible use conflict measure
differentiate diagnoses according degree consistency given set
observations. work, however, address problem sequential diagnosis,
i.e., locating actual faults taking measurements.
recently, Feldman, Provan, van Gemund (2009) proposed related method
reducing diagnostic uncertainty. work attempts identify actual faults
fewest individual measurements, heuristic aimed reducing number
diagnoses fewest test vectors.

9. Conclusion
presented new system sequential diagnosis, called sda, employs four
new structure-based techniques scale diagnosis larger systems. Specifically, uses
heuristic measurement selection computed efficiently d-DNNF
compilation system. diagnose larger systems, automatically computes structural abstraction system performs diagnosis hierarchical fashion.
employs structure-based technique reducing abstraction size system,
scales diagnosis largest benchmark systems. Finally, automatically
select abstraction system likely give optimal average cost.

Acknowledgments
thank anonymous reviewers comments. NICTA funded Australian
Government represented Department Broadband, Communications
Digital Economy Australian Research Council ICT Centre Excellence
program. Part work appeared KR 2010 (Siddiqi & Huang, 2010); another
part work carried JulySeptember 2010 first author
visiting NICTA.

Appendix A. Computing Probabilities d-DNNF
briefly describe computation probabilities based d-DNNF compilations
Bayesian networks. d-DNNF graph representation nested and/or expression
negation appears next variables, children every and-node disjoint sets
variables (decomposability), children every or-node pairwise logically inconsistent
357

fiSiddiqi & Huang



0.0475

0.0475




1





0.0475

0.95

okA
0.9



0

0.1



1


1


1



0.95

J



0

0.05

0.05

okA

P

0

okJ

0.5

0.1

0.05

J J

0.5

1

J
0.5

okJ
0.9

Figure 6: d-DNNF compilation subcircuit (dotted) Figure 1 given observation
P computation posterior probability J = 1.

(determinism). example, Figure 6 shows d-DNNF compilation subcircuit
dotted box Figure 1 observation P D.
Given d-DNNF compilation, probability P r(E = e) instantiation e set
variables E obtained following linear-time procedure: (i) Set variables E
Boolean constants according instantiation e, (ii) set literals (not E)
true except numbers associated (negative literals associated
1 minus corresponding numbers positive literals), (iii) evaluate dDNNF bottom-up treating true 1, false 0, remaining leaves associated
numbers, or-nodes additions, and-nodes multiplications. number root
P r(E = e). example, Figure 6 shows computation probability J = 1
given observation P D. Thus e = {A = 1, P = 1, = 1, J = 1}. d-DNNF,
set = 1, P = 1, = 1, J = 1, J = 0. rest literals given values
associated (discussed Section 3.2).
Furthermore, second traversal d-DNNF, top down, effectively
differentiate d-DNNF updated probabilities computed every
possible change value variable (e.g., unknown known) (Darwiche, 2003).
useful measurement point selection need update entropies
candidate measurement points.

Appendix B. Cardinality-based Model Pruning
present technique referred Section 4 used remove significantly large number (if all) diagnoses cardinality > k d-DNNF.
value k must greater equal minimum-cardinality d-DNNF
pruning occur. k equal minimum-cardinality d-DNNF
diagnoses cardinality > k removed using minimization procedure described
358

fiSequential Diagnosis Abstraction

Figure 7: Pruning d-DNNF improve heuristic accuracy.
Darwiche (2001). If, however, k greater minimum-cardinality d-DNNF
need similar modified minimization algorithm make sure remove
diagnoses cardinality k.
complete pruning difficult achieve general, approximation possible.
naive approach, one may remove every child l every or-node n minimumcardinality (mc) l greater k, sound never remove
diagnoses cardinality k may result little pruning many cases.
increase amount pruning performed computing local value k(n) every node n
given global k whole d-DNNF using top-down traversal d-DNNF:
Every node n suggests value k(l) child l largest values accepted
final value k(l) (this essential avoid possibly removing diagnoses cardinality
k). pruning occur way k(n) often less global
k. k(n) computed every node, every child l every or-node n
mc(l) > k(l) pruned.
give pruning algorithm performs two pass traversal
d-DNNF. mc(n) updated upward traversal represents minimumcardinality diagnoses node n, whereas k(n) updated downward
traversal represents upper bound fault-cardinality node used
prune branches emanating node whose mc(n) exceeds k(n).
two passes procedure follows: Initialize mc(n) 0 k(n) -
(least possible value) n. Traverse d-DNNF children visited
parents every leaf node, set mc(n) 1 n negated health variable 0
otherwise; every or-node, set mc(n) minimum values mc children;
every and-node set mc(n) sum values mc children. traverse
d-DNNF parents visited children set k(n) root node
value k; every or-node, remove every child p n mc(p) > k(n)
every remaining child v set k(v) k(n) k(n) > k(v); every child p every and-node,
let tp sum values mc children set k(p) value tp
tp > k(p).
procedure conditions k(n) > k(v) tp > k(p) updating k
node ensure safe value k set. example shown Figure 7.
mc (left) k (right) values shown node. branches labeled , , ,
359

fiSiddiqi & Huang

I1

G1

I2
G2

C1

G3

I3
G5
G4
G6
C2

Figure 8: combinational circuit generated randomly set components consisting
gates G1 , G2 , . . . , G6 cones C1 , C2 , processed order:
G1 , C1 , G2 , G3 , G4 , C2 , G5 , G6 .

N
32
40
48
56
64
72
80
88
96
104
112
120
128
136
144
152

total
gates
104
130
156
182
208
234
260
286
312
338
364
390
416
442
468
494

average
depth
26.9
31.6
30.3
34.8
37.6
41.1
39.3
41.6
46.3
43.4
41.8
48.5
48.1
50.7
48.2
50.8

approx.
treewidth
13
16
17
21
24
26
29
32
34
36
39
43
45
48
51
51

abstraction
size
26
31
38
45
51
59
66
71
79
82
90
97
104
112
116
123

total
clones
32
42
69
68
84
108
128
158
172
177
194
218
194
243
265
272

abstraction size
cloning
17
20
24
28
32
38
41
42
48
49
57
61
65
72
70
78

Table 8: Randomly generated combinational circuits (N, 25, 5).

subgraphs associated hypothetical values mc. figure shows
minimum-cardinality every node (mc) less equal bound (k) except
branch labeled , gets pruned accordingly.

Appendix C. Randomly Generated Combinational Circuits
section use novel method systematically generate series combinational
circuits structure size controlled. enables evaluation
techniques circuits ISCAS-85 benchmarks, helped us identify
factors affect diagnostic cost, leading us cost estimation function given
Section 6. Specifically, observe circuits similar structure, diagnostic cost
generally increases circuit size, helped us devise notion isolation cost;
360

fiSequential Diagnosis Abstraction

circuit size held constant, diagnostic cost generally increases number
cones circuit, helped us devise notion abstraction cost.
circuits generated composing set pre-formed building blocks. latter
consist gates cones. gates taken pool six gates types OR,
NOR, AND, NAND, NOT, BUFFER, cones pool eight cones,
10 gates extracted ISCAS-85 benchmark circuits.
composition method inspired method generating random Bayesian
networks described Marinescu, Kask, Dechter (2003). circuits generated
according formula (N, P, I), N number components (building blocks)
use, P percentage cones components, maximum number inputs
gate have. generate N components randomly pick (P/100) N cones (with
repetition) pool cones N (P/100) N gates (with repetition)
pool gates place random order. number inputs gate set
randomly 2 I, except BUFFER gate one
input.
process component follows: Suppose components placed
order C1 , C2 , . . . , CN . Let Pi set components precede Ci
order. process component Ci connect every input Ci output
randomly chosen component Pi two inputs Ci connected
component. input Ci cannot connected (either Pi empty
components Pi used) treated primary input circuit.
example, circuit Figure 8 randomly generated according formula
(8, 25, 2), components shown boxes represent cones.
varying parameters (N, P, I) obtain circuits varying size structure.
First fix P = 25, = 5 vary N generate range circuits increasing size.
N generate 10 circuits. circuits summarized Table 8. numbers
columns averaged circuits given size, rounded off. Generally,
N increased see increase abstraction size well estimated treewidth,
corresponding increase perceived difficulty circuit (e.g., note
largest circuit set smaller c1355, estimated treewidth c1355 much
lower, 25; actual compilation indeed harder former circuit).
circuit randomly generate 10 single-fault, 10 double-fault, 10 five-fault scenarios
single test case scenario.
results experiments circuits given Tables 9, 10, 11, using
baseline, hierarchical, cloning techniques, respectively. results generally
consistent obtained using ISCAS-85 circuits. baseline sda could
solve circuit beyond (72, 25, 5). hierarchical sda solved circuits could
solve circuit beyond (80, 25, 5). scalable version sda, component
cloning, solved much larger circuits, (168, 25, 5).
Note general trend increase diagnostic cost increase N .
consistent ones intuitive expectation diagnostic uncertainty would increase
system size. Also note diagnostic cost often significantly higher hierarchical
approach baseline approach. discussed earlier, attributed
fact hierarchical approach often go hierarchies cones reach
faulty gate, baseline approach may able reach directly.
361

fiSiddiqi & Huang

total
single-fault
double-fault
five-fault
pruning
gates
solved cost time solved cost time solved cost
time
32 104

100 5.86 0.56
100 6.34 0.57
100
9.19
0.60
yes
100 4.81 0.54
100 5.24 0.55
100
8.22
0.59
40 130

100 5.82 4.31
100 7.05 4.51
100 11.53 5.09
yes
100
4.5
4.16
100 5.08 4.28
100 10.35 4.93
48 156

100 6.58 32.43
100 8.72 32.75
100 11.19 34.87
yes
100 4.73 31.27
100
5.9 31.14
100
9.46 33.84
56 182

80
5.26 190.99
80
6.9 192.69
80
11.05 202.4
yes
80
3.58 185.32
80
5.62 190.25
80
8.325 197.05
64 208

50
5.58 532.82
50
6.9 540.31
50
13.94 581.11
yes
50
5.02 527.24
50
4.72 525.02
50
9.84 558.79
72 234

10
6.2 207.89
10
9.5 230.72
10
27.5 354.80
yes
10
6.2 207.49
10
5.8 205.41
10
11.4 248.20
N

Table 9: Baseline heuristic randomly generated circuits (N, 25, 5).
total
single-fault
double-fault
five-fault
pruning
gates
solved cost time solved cost time solved cost
time
32 104

100 7.81 0.15
100 8.78 0.16
100 12.59 0.18
yes
100 3.42 0.15
100 5.87 0.16
100 11.88 0.17
40 130

100
7.2
0.71
100 8.19 0.72
100 13.77 0.75
yes
100 3.07 0.70
100 5.18 0.71
100 12.94 0.73
48 156

100 7.03 4.10
100 8.12 4.14
100 12.78 4.26
yes
100 3.18 4.01
100 4.96 4.02
100 11.51 4.08
56 182

100 7.81 42.63
100
9.1 43.58
100 11.92 43.64
yes
100 2.98 41.60
100 6.31 42.23
100
11.1 42.19
64 208

80
8.35 108.61
80
9.11 107.96
80
14.85 111.04
yes
80
3.31 107.05
80
5.35 106.31
80
13.56 107.71
72 234

30
7.56 120.59
30
9.83 122.50
30
12.66 123.81
yes
30
2.8 118.35
30
5.53 118.57
30
11.2 119.93
80 260

10
6.9 190.66
10
9.2 193.58
10
12.4 197.29
yes
10
2.8 188.95
10
4.6 189.73
10
10.5 190.07
N

Table 10: Hierarchical heuristic randomly generated circuits (N, 25, 5).
also observe that, again, pruning leads general improvement diagnostic cost.
improvement significant hierarchical approach, explained
fact effect pruning much greater abstract model, branch
pruned correspond large part original system.
perform another set experiments study impact hierarchy
controlled manner. time hold size circuits less constant
vary percentage cones them. Specifically, generate large number random
circuits P ranging 0 50, value P generated circuits
contain 120 gates average.
experiments circuits summarized Table 12. Note P increases
estimated treewidth circuits decreases, would expected, actual
compilation time indeed also decreases. diagnostic cost, hand, increases
steadily P = 25 remains less flat afterwards. confirms potential
362

fiSequential Diagnosis Abstraction

N
32
40
48
56
64
72
80
88
96
104
112
120
128
136
144
152
160
168

total
single-fault
double-fault
five-fault
gates solved cost
time solved cost
time solved cost
time
104
100
7.86
0.04
100
8.78
0.05
100 12.13 0.06
130
100
8.12
0.05
100
9.6
0.06
100 13.58 0.08
156
100
8.25
0.07
100
9.34
0.08
100
12.6
0.10
182
100
9.03
0.12
100
10.4
0.13
100 13.37 0.15
208
100 10.06 0.45
100 10.73 0.46
100 15.41 0.49
234
100
9.15
0.78
100 11.38 0.80
100 15.44 0.84
260
100
9.78
0.83
100 11.38 0.85
100
15.5
0.89
286
100
9.56
0.78
100 10.87 0.79
100
16.6
0.84
312
100
10.4
1.85
100 10.81 1.87
100 17.87 1.97
338
100 10.03 4.23
100 11.79 4.26
100 16.95 4.34
364
100 10.44 29.20
100 11.76 29.39
100 17.62 29.93
390
100 10.36 39.88
100
13.6 40.15
100 20.76 41.17
416
90
11.17 98.70
90
13.73 99.08
90
19.33 100.73
442
90
11.82 220.41
90
13.76 221.63
89
20.25 225.58
468
80
12.08 207.69
80
15.05 207.68
80
19.92 210.86
494
40
12.7 256.43
40
14.72 257.5
40
23.02 260.41
520
40
12.5 476.93
40
14.15 479.33
40
18.5 479.83
546
10
8.7
84.16
10
10.1 84.44
10
15.1 85.27

Table 11: Component cloning randomly generated circuits (N, 25, 5).
P
0
5
10
15
20
25
50

total
single-fault
treewidth
circuits
cost time
1000
32
5.7
8.8
600
23
6.7
0.9
900
21
7.5
0.5
1000
18
7.7
0.1
1100
17
8.0
0.1
1300
15
9.2
0.1
800
12
8.6
0.06

double-fault
cost
time
7.7
8.8
8.0
0.9
8.7
0.5
9.1
0.1
9.4
0.1
10.3
0.1
10.0
0.07

five-fault
cost time
13.5 9.0
13.0 0.9
13.2 0.5
12.2 0.1
12.3 0.1
13.6 0.1
12.4 0.1

Table 12: Component cloning randomly generated circuits (N ,P ,5).
negative impact hierarchy diagnostic cost hypothesized: P increases
likelihood fault occurring inside cone also increases thus average one
take measurements, many inputs cones, locate fault. diagnostic cost
increase P = 25 consistent observation since
circuit size fixed roughly 120 cone contributes 10 gates circuit,
P increases point, gates lying outside cones hence
likelihood fault occurring cone less plateaued.

References
Brglez, F., & Fujiwara, H. (1985). neutral netlist 10 combinational benchmark circuits target translator Fortran. Proceedings IEEE International
Symposium Circuits Systems (ISCAS), pp. 695698.
Chittaro, L., & Ranon, R. (2004). Hierarchical model-based diagnosis based structural
abstraction. Artificial Intelligence, 155 (1-2), 147182.
363

fiSiddiqi & Huang

Choi, A., Chavira, M., & Darwiche, A. (2007). Node splitting: scheme generating upper bounds Bayesian networks. Proceedings 23rd Conference
Uncertainty Artificial Intelligence (UAI), pp. 5766.
Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal Artificial
Intelligence Research, 17, 229264.
Darwiche, A. (2001). Decomposable negation normal form. Journal ACM, 48 (4),
608647.
Darwiche, A. (2003). differential approach inference Bayesian networks. Journal
ACM, 50 (3), 280305.
Darwiche, A. (2004). New advances compiling CNF decomposable negation normal form. Proceedings 16th European Conference Artificial Intelligence
(ECAI), pp. 328332.
Darwiche, A. (2005). c2d compiler user manual. Tech. rep. D-147, Computer Science
Department, UCLA. http://reasoning.cs.ucla.edu/c2d/.
de Kleer, J., & Williams, B. C. (1987). Diagnosing multiple faults. Artificial Intelligence,
32 (1), 97130.
de Kleer, J. (1992). Focusing probable diagnosis. Readings model-based diagnosis,
pp. 131137. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
de Kleer, J. (2006). Improving probability estimates lower diagnostic costs. 17th
International Workshop Principles Diagnosis (DX).
de Kleer, J., Raiman, O., & Shirley, M. (1992). One step lookahead pretty good.
Readings model-based diagnosis, pp. 138142. Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA.
Feldman, A., & van Gemund, A. (2006). two-step hierarchical algorithm modelbased diagnosis. Proceedings 21st AAAI Conference Artificial Intelligence
(AAAI), pp. 827833.
Feldman, A., Provan, G. M., & van Gemund, A. J. C. (2009). FRACTAL: Efficient fault
isolation using active testing. Proceedings 21st International Joint Conference
Artificial Intelligence (IJCAI), pp. 778784.
Flesch, I., Lucas, P., & van der Weide, T. (2007). Conflict-based diagnosis: Adding uncertainty model-based diagnosis. Proceedings 20th International Joint
Conference Artificial Intelligence (IJCAI), pp. 380385.
Forbus, K. D., & de Kleer, J. (1993). Building problem solvers. MIT Press, Cambridge,
MA, USA.
Hansen, M. C., Yalcin, H., & Hayes, J. P. (1999). Unveiling ISCAS-85 benchmarks:
case study reverse engineering. IEEE Design Test Computers, 16 (3), 7280.
364

fiSequential Diagnosis Abstraction

Heckerman, D., Breese, J. S., & Rommelse, K. (1995). Decision-theoretic troubleshooting.
Communications ACM, 38 (3), 4957.
Jensen, F. V. (2001). Bayesian networks decision graphs. Springer-Verlag New York,
Inc., Secaucus, NJ, USA.
Kirkland, T., & Mercer, M. R. (1987). topological search algorithm ATPG.
Proceedings 24th Conference Design Automation (DAC), pp. 502508.
Marinescu, R., Kask, K., & Dechter, R. (2003). Systematic vs. non-systematic algorithms
solving MPE task. Proceedings 19th Conference Uncertainty
Artificial Intelligence (UAI), pp. 394402.
Out, D.-J., van Rikxoort, R., & Bakker, R. (1994). construction hierarchic models.
Annals Mathematics Artificial Intelligence, 11 (1-4), 283296.
Pearl, J. (1988). Probabilistic reasoning intelligent systems: Networks plausible inference. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
Pipatsrisawat, K., & Darwiche, A. (2007). Clone: Solving weighted Max-SAT reduced
search space. Proceedings 20th Australian Joint Conference Artificial
Intelligence (AI), pp. 223233.
Siddiqi, S., & Huang, J. (2007). Hierarchical diagnosis multiple faults. Proceedings
20th International Joint Conference Artificial Intelligence (IJCAI), pp. 581
586.
Siddiqi, S., & Huang, J. (2010). New advances sequential diagnosis. Proceedings
Twelfth International Conference Principles Knowledge Representation
Reasoning (KR), pp. 1725.
Torta, G., & Torasso, P. (2003). Automatic abstraction component-based diagnosis driven
system observability. Proceedings 18th International Joint Conference
Artificial Intelligence (IJCAI), pp. 394402.
Torta, G., & Torasso, P. (2008). symbolic approach component abstraction modelbased diagnosis. 19th International Workshop Principles Diagnosis (DX).

365

fiJournal Artificial Intelligence Research 41 (2011) 231-266

Submitted 11/2010; published 06/2011

Probabilistic Relational Planning
First Order Decision Diagrams
Saket Joshi

joshi@eecs.oregonstate.edu

School Electrical Engineering Computer Science
Oregon State University
Corvallis, 97331, USA

Roni Khardon

roni@cs.tufts.edu

Department Computer Science
Tufts University
Medford, MA, 02155, USA

Abstract
Dynamic programming algorithms successfully applied propositional stochastic planning problems using compact representations, particular algebraic decision
diagrams, capture domain dynamics value functions. Work symbolic dynamic
programming lifted ideas first order logic using several representation schemes.
Recent work introduced first order variant decision diagrams (FODD) developed
value iteration algorithm representation. paper develops several improvements
FODD algorithm make approach practical. include, new reduction
operators decrease size representation, several speedup techniques,
techniques value approximation. Incorporating these, paper presents planning
system, FODD-Planner, solving relational stochastic planning problems. system
evaluated several domains, including problems recent international planning
competition, shows competitive performance top ranking systems.
first demonstration feasibility approach shows abstraction
compact representation promising approach stochastic planning.

1. Introduction
Planning uncertainty one core problems Artificial Intelligence.
years research automated planning produced number planning formalisms
systems. STRIPS planning system (Fikes & Nilsson, 1971) led generation automated planning research. produced number successful systems deterministic
planning using various paradigms like partial order planning (Penberthy & Weld, 1992),
planning based planning graphs (Blum & Furst, 1997), planning satisfiability (Kautz
& Selman, 1996) heuristic search (Bonet & Geffner, 2001). ideas later employed solving problem planning uncertainty (Blum & Langford, 1998; Weld,
Anderson, & Smith, 1998; Majercik & Littman, 2003; Yoon, Fern, & Givan, 2007; TeichteilKoenigsbuch, Infantes, & Kuter, 2008). these, approaches using forward heuristic search
related planning graph (Blum & Furst, 1997) successful recent
international planning competitions (Yoon et al., 2007; Teichteil-Koenigsbuch et al., 2008).
Another approach probabilistic planning based Markov decision processes (MDPs).
fact solutions MDPs generate policies rather action sequences particuc
2011
AI Access Foundation. rights reserved.

fiJoshi & Khardon

larly attractive probabilistic planning, approach came known Decision
Theoretic Planning (Boutilier, Dean, & Hanks, 1999a). Classical solution techniques
MDPs, like value iteration (VI) (Bellman, 1957) policy iteration (PI) (Howard, 1960),
based dynamic programming. early solutions, however, require enumeration
state space. Owing curse dimensionality (Bellman, 1957), even reasonably
small problems, state space large. seen easily propositionally factored domains state defined N binary variables number
possible states 2N .
Several approaches developed handle propositionally factored domains
(Boutilier, Dearden, & Goldszmidt, 1999b; Kearns & Koller, 1999; Guestrin, Koller, Parr, &
Venkataraman, 2003b; Hoey, St-Aubin, Hu, & Boutilier, 1999). One successful,
SPUDD (Hoey et al., 1999), demonstrated MDP represented using algebraic decision diagrams (ADDs) (Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi,
1993), VI performed entirely using ADD representation thereby avoiding
need enumerate state space. Propositionally factored representations show
impressive speedup taking advantage propositional domain structure. However,
benefit structure exists objects relations. Boutilier,
Reiter, Price (2001) developed foundations provably optimal solutions relational problems provided Symbolic Dynamic Programming (SDP) algorithm
context situation calculus. algorithm provided framework dynamic programming solutions Relational MDPs later employed several formalisms
systems (Kersting, van Otterlo, & De Raedt, 2004; Holldobler, Karabaev, & Skvortsova,
2006; Sanner & Boutilier, 2009; Wang, Joshi, & Khardon, 2008).
advantage relational representation abstraction. One plan abstract level without grounding domain, potentially leading efficient algorithms.
addition, solution abstract level optimal every instantiation domain
reused multiple problems. However, approach raises difficult computational issues one must use theorem proving reason abstract level,
problems optimal solutions abstract level infinite size. Following Boutilier et al. (2001) several abstract versions value iteration (VI) algorithm
developed using different representation schemes. example, approximate
solutions based linear function approximations developed successfully applied several problems international planning competitions (Sanner & Boutilier,
2009).
alternative representation motivated success algebraic decision diagrams
solving propositional MDPs (Hoey et al., 1999; St-Aubin, Hoey, & Boutilier, 2000).
Following work, relational variants decision diagrams defined used
VI algorithms (Wang et al., 2008; Sanner & Boutilier, 2009). Sanner Boutilier report
implementation scale well yield exact solutions large problems.
previous work (Wang et al., 2008) introduced First Order Decision Diagrams (FODD),
developed algorithms reduction operators them. However, FODD representation
requires non-trivial operations reductions (to maintain small diagrams efficiency)
leading difficulties implementation scaling.
paper develops several algorithmic improvements extensions FODD
based solution make approach practical.
232

fiProbabilistic Planning FODD

First, introduce new reduction operators, named R10 R11, decrease
size FODD representation. R10 makes global analysis FODD removes
many redundant portions diagram simultaneously. R11 works locally targets
particular redundancy arises quite often two FODDs composed
binary operation; procedure used repeatedly VI algorithm. prove
soundness reductions showing applied diagrams maintain
correct value.
Second, present novel FODD operation, sub-apart(A, B) identifies minimal
conditions (in terms variables) one FODD dominates value another
FODD B. new operation simultaneously expands applicability R7 reduction
(Wang et al., 2008) cover situations simplifies test applicability,
must implemented system. prove soundness operation showing
applied R7 diagrams maintain correct value.
Third, present several techniques speed FODD-based planning algorithm.
include sound simplification one steps algorithm addition
several approximation techniques trade-off accuracy improvements run time.
Fourth, extend system allow handle action costs universal goals.
Incorporating ideas paper presents FODD-Planner, planning system
solving relational stochastic planning problems using FODDs.
Fifth, perform experimental evaluation FODD-Planner system several
domains, including problems recent international planning competition (IPC).
experiments demonstrate new reductions provide significant speedup
algorithm crucial practicality. importantly show FODDPlanner exhibits competitive performance top ranking systems IPC.
knowledge first application pure relational VI algorithm without linear
function approximation problems scale. results demonstrate abstraction
compact representation promising approach stochastic planning.
rest paper organized follows. Section 2 gives short introduction
relational MDPs FODDs. Section 3 presents techniques speed FODDPlanner. section 4 introduce new operators removing redundancies FODDs.
Section 5 describes FODD-Planner system Section 6 present results
experiments planning domains IPC. Section 7 provides additional discussion
related work Section 8 concludes summary ideas future work.

2. Preliminaries
section gives overview Relational MDPs, First Order Decision Diagrams
Symbolic Dynamic Programming algorithm.
2.1 Relational Markov Decision Processes
Markov decision process (MDP) mathematical model interaction
agent environment (Puterman, 1994). Formally MDP 5-tuple < S, A, T, R, >
defining
set fully observable states S.
233

fiJoshi & Khardon

set actions available agent.
state transition function defining probability P (s |s, a) getting state
state taking action a.
reward function R(s, a) defining immediate reward achieved agent
state taking action a. simplify notation assume reward
independent R(s, a) = R(s). However general case handled
way.
discount factor 0 1 captures relative value immediate actions
future actions.
objective solving MDP generate policy maximizes agents total,
expected, discounted, reward. Intuitively, expected utility value state equal
reward obtained state plus discounted value state reached
best action state. captured Bellman equation V (s) = axa [R(s)
+ P (s |s, a)V (s )]. discount factor < 1 guarantees V (s) finite even
considering infinite number steps. episodic tasks planning provides
incentive find short solutions. VI algorithm treats Bellman equation
update rule V (s) axa [R(s) + P (s |s, a)V (s )], iteratively updates value
every state convergence. optimal value function known, policy
generated assigning state action maximizes expected value.
Relational MDP (RMDP) MDP world represented objects
relations among them. RMDP specified
1. set world predicates. literal, formed instantiating predicate using
objects domain, either true false given state. example boxworld domain, world literals form box-in-city(box, city),
box-on-truck(box, truck), truck-in-city(truck, city).
2. set action predicates. action literal formed instantiating action predicate using objects domain defines concrete action. boxworld domain, actions form load-box-on-to-truck-in-city(box, truck, city), unload-box
-from-truck-in-city(box, truck, city), drive-truck(truck, source.city, dest.city).
3. state transition function provides abstract description probabilistic
move one state another. example, using STRIPS-like notation,
transition defined action load-box-on-to-truck-in-city described
Action: load-box-on-to-truck-in-city(box, truck, city):
Preconditions: box-in-city(box, city), truck-in-city(truck, city)
Outcome 1: Probability 0.8 box-on-truck(box, truck), box-in-city(box, city)
Outcome 2: Probability 0.2 nothing changes.
preconditions action, box-in-city(box, city) truck-in-city(truck, city)
satisfied, probability 0.8, action succeed generating effect
box-on-truck(box, truck) box-in-city(box, city). predicate instantiations remain unchanged. state remains unchanged probability 0.2.
234

fiProbabilistic Planning FODD

4. abstract reward function describing conditions rewards obtained.
example boxworld domain, reward function described boxcity,
destination(box, city) box-in-city(box, city) constructed capture goal
transporting boxes source cities respective destination cities.
Boutilier et al. (2001) developed SDP, first VI algorithm RMDPs.
important theoretical result RMDPs finite horizon, SDP guaranteed
produce optimal value function independent domain size. Thus value
function applicable logistics problem 2 cities, 2 trucks 2 boxes, logistics
problem 100 cities, 1000 trucks 2000 boxes, instance domain.
One important ideas SDP represent stochastic actions deterministic
alternatives natures control. helps separate regression deterministic action
alternatives probabilities action effects. separation necessary
transition functions represented relational schemas abstracting structure
states. basic outline relational value iteration algorithm follows:
1. Regression: n step-to-go value function Vn regressed every deterministic
variant Aj (~x) every action A(~x) produce Regr(Vn , Aj (~x)). first iteration V0 assigned reward function. necessary correctness
algorithm convenient starting point VI. Regr(Vn , Aj (~x)) describes
conditions action alternative Aj (~x) causes state transition
abstract state description V n+1 .
2. Add Action Variants: Q-function
A(~
x)

QVn

= R [ j (prob(Aj (~x)) Regr(Vn , Aj (~x)))]

action A(~x) generated. step different alternatives action
combined. alternative Aj (~x) produces Regr(Vn , Aj (~x)) regression
step. Regr(Vn , Aj (~x))s added weighted probability
A(~
x)
Aj (~x). produces parametrized function QVn describes utility
state taking concrete action A(~x).
A(~
x)

3. Object Maximization: Maximize action parameters QVn produce
x), thus obtaining value achievable best ground
QA
Vn action A(~
instantiation A(~x).
4. Maximize Actions: n + 1 step-to-go value function Vn+1 = maxA QA
Vn ,
generated.
description algorithm intermediate constructs (R, P , V etc.)
represented compact form capture mapping states values
probabilities. operations Bellman update performed functions
maintaining compact form. variant SDP developed previous work
(Wang et al., 2008) employed First Order Decision Diagrams represent intermediate
constructs.
235

fiJoshi & Khardon

p(x)
q(y)
q(y)
1
1

0

0
(a)

(b)

Figure 1: Two example FODDs. diagrams paper, left going edges
represent branch taken predicate true right going edges
represent false branches.
2.2 First Order Decision Diagrams
section briefly reviews previous work FODDs use relational MDPs
(Wang et al., 2008). use standard terminology First-Order logic (Lloyd, 1987).
First Order Decision Diagram labeled directed acyclic graph, non-leaf
node exactly 2 outgoing edges true false labels. non-leaf nodes
labeled atoms generated predetermined signature predicates, constants
enumerable set variables. Leaf nodes non-negative numeric values. signature
also defines total order atoms, FODD ordered every parent smaller
child according order. Two examples FODDs given Figure 1;
diagrams paper left going edges represent true branches right
edges false branches.
Thus, FODD similar formula first order logic shares syntactic
elements. meaning similarly defined relative interpretations symbols.
interpretation defines domain objects, identifies constant object,
specifies truth value predicate objects. context relational
MDPs, interpretation represents state world objects relations
among them. Given FODD interpretation, valuation assigns variable
FODD object interpretation. Following Groote Tveretina (2003),
semantics FODDs defined follows. B FODD interpretation,
valuation assigns domain element variable B fixes truth
value every node atom B I. FODD B traversed order
reach leaf. value leaf denoted apB (I, ). apB (I) defined
max apB (I, ), i.e. aggregation apB (I, ) valuations . example,
consider FODD Figure 1(a) interpretation objects a, b
true atoms p(a), q(b). valuations {x/a, y/a}, {x/a, y/b}, {x/b, y/a},
{x/b, y/b}, produce values 0, 1, 0, 0 respectively. max aggregation semantics,
apB (I) = max{0, 1, 0, 0} = 1. Thus, FODD equivalent formula x, y, p(x)
q(y).
236

fiProbabilistic Planning FODD

general, max aggregation yields existential quantification leaves binary.
using numerical values similarly capture value functions relational MDPs.
Thus, every FODD binary leaves equivalent formula First-Order logic,
variables existentially quantified. Conversely, every function free formula FirstOrder logic, variables existentially quantified, equivalent FODD representation.1 FODDs cannot capture universal quantification. Recently introduced
generalized FODD based formalism capture arbitrary quantifiers (Joshi, Kersting,
& Khardon, 2009); however expensive use computationally used
paper.
Akin ADDs, FODDs combined arithmetic operations, reduced
order remove redundancies. Intuitively, redundancies FODDs arise two different
ways. first, observes edges never traversed valuation. Reduction operators redundancies called strong reduction operators. second
requires subtle analysis: may parts FODD traversed
valuations max aggregation, valuations traverse
parts never instrumental determining map. Operators redundancies
called weak reductions operators. Strong reductions preserve apB (I, ) every valuation
(thereby preserving apB (I)) weak reductions preserve apB (I) necessarily
apB (I, ) every . Groote Tveretina (2003) introduced four strong reduction operators (R1 R4). Wang et al. (2008) added strong reduction operator R5. also
introduced notion weak reductions developed weak reduction operators (R6
R9). Another subtlety arises RMDP domains may background
knowledge predicates domain. example, blocksworld, block
clear on(x, a) false values x. denote background knowledge
B allow reductions rely knowledge. Below, discuss operator R7
detail relevance next section.
use following notation. e edge node n node m, source(e)
= n, target(e) = sibling(e) edge n. node n, symbols
nt nf denote true false edges n respectively. l(n) denotes
atom associated node n. Node formulas (NF) edge formulas (EF) defined
recursively follows. node n labeled l(n) incoming edges e1 , . . . , ek , node
formula NF(n) = (i EF(ei )). edge formula true outgoing edge n
EF(nt ) = NF(n) l(n). edge formula false outgoing edge n EF(nf ) =
NF(n) l(n). formulas, variables existentially quantified, capture
conditions node edge reached. Similarly, B FODD
p path root leaf B, path formula p, denoted PF(p)
conjunction literals along p. variables p, denoted x~p . x~p
existentially quantified, satisfiability PF(p) interpretation necessary
sufficient condition path p traversed valuation I.
valuation, define P athB (I, ) = p. leaf reached path p denoted
leaf (p). let PF(p)\Lit denote path formula path p literal Lit removed
(if present) conjunction. B denotes background knowledge domain.
1. seen translating formula f disjunctive normal form f = fi , representing
every conjunct fi FODD, calculating disjunction using apply procedure Wang et al.
(2008).

237

fiJoshi & Khardon

Figure 2: example R7 reduction.

process algorithm, also reductions, need perform operations functions represented FODDs. Let B1 B2 two FODDs representing
function states real values (B1 : , B2 : ). Let B function
S, B(S) = B1 (S) + B2 (S). Wang et al. (2008) provide algorithm calculating
FODD representation B. denote operation B = B1 B2 similarly use
, etc. denote operations diagrams.
R7 Reduction: Weak reductions arise two forms - edge redundancies node redundancies. Corresponding these, R7 reduction operator (Wang et al., 2008) two
variants - R7-replace (for removing redundant edges) R7-drop (for removing redundant
nodes). edge redundant valuations going dominated
valuations. Intuitively, given FODD B edges e1 e2 B, every valuation
going edge e2 , always another valuation going e1 gives better
value, replace target(e2 ) 0 without affecting apB (I) interpretation I.
Figure 2 shows example reduction. FODD left, consider valuation
reaching 1 leaf traversing path p(x)p(y) interpretation I.
generate another valuation (by substituting value value x) reaches
1 leaf path p(x). Therefore, intuitively path p(x) p(y) redundant
removed diagram. R7-replace reduction formalizes notion
number conditions certain combinations conditions
satisfied, edge reduction becomes applicable. example, following conditions
occur together FODD, reduced replacing target edge e2 0 leaf.
(P7.2) : B |= ~u, [[w,
~ EF(e2 )] [~v , EF(e1 )]] ~u variables appear
target(e1 ) target(e2 ), ~v variables appear EF(e1 ) ~u,
w
~ variables appear EF(e2 ) ~u.
condition requires every valuation 1 reaches e2 valuation
2 reaches e1 1 2 agree variables appear target(e1 )
target(e2 ).
(V7.3) : leaves = target(e1 ) target(e2 ) non-negative values, denoted
0. case fixed valuation potentially reaching e1 e2 better
follow e1 instead e2 .
(S1) : path root leaf contains e1 e2 .

238

fiProbabilistic Planning FODD

operator R7-replace(e1 , e2 ) replaces target(e2 ) leaf valued 0. Notice
FODD Figure 2 satisfies conditions P7.2, V7.3, S1. (P7.2) shared
variable z holds z, [[xy, p(x) p(y)] [x, p(x)]]. (V7.3) holds
target(e1 ) = target(e2 ) 0. definitions Wang et al. (2008) show
safe perform R7-replace conditions P7.2, V7.3, S1 hold:
Lemma 1 ((Wang et al., 2008)) Let B FODD, e1 e2 edges conditions
P7.2, V7.3, S1 hold, B result R7-replace(e1 , e2 ), interpretation
MAPB (I) = MAPB (I).
Similarly R7-drop formalizes conditions nodes dropped diagram. Several alternative conditions applicability R7 (R7-replace R7-drop)
given Wang et al. (2008). provided set alternative conditions applicability R7 none dominates others, result effectively one
check conditions reducing diagram. next section shows process
applying R7 simplified generalized.
R7 captures fundamental intuition behind weak reductions hence widely
applicable. Unfortunately also expensive run. practice R7-replace conditions
tested pairs edges diagram. test requires theorem proving
disjunctive First-Order formulas.
2.3 VI FODDs
previous work (Wang et al., 2008) showed capture reward function
dynamics domain using FODDs presented value iteration algorithm along
lines described last section. Reward value functions captured directly
using FODDs. Domains dynamics captured FODDs describing probabilities
action variants prob(Aj (~a)), special FODDs, Truth Value Diagrams (TVD),
capture deterministic effects action variant, similar successor state axioms
used Boutilier et al. (2001). every action variant Aj (~a) predicate schema
p(~x) TVD (A(~a), p(~x)) FODD {0, 1} leaves. TVD gives truth value
p(~x) next state A(~a) performed current state. TVDs
therefore capture action preconditions within FODD structure p(~x) potential
effect formalism specifies truth value directly instead saying whether
changes not. operations needed SDP algorithm (regression, plus,
times, max) performed special algorithms combining FODDs. details
representations algorithms previously described (Wang et al., 2008)
directly needed discussion paper thus omitted here.
hand, direct application operations yield large FODDs
redundant structure therefore, keep diagram size manageable, FODDs
reduced every step algorithm. Efficient successful reductions
key procedure. reductions R1-R9 (Groote & Tveretina, 2003; Wang et al.,
2008) provide first step towards efficient FODD system. However, cover
possible redundancies expensive apply practice. Therefore direct
implementation sufficient yield effective stochastic planner.
239

fiJoshi & Khardon

p(x)
e1

q(x)

p(y)
e2

10

q(x)

r(z)
3

q(x)
0

1

r(z)
2

0

Figure 3: FODD example showing applicability Sub-Apart.

following sections present new reduction operations speedup techniques make VI
FODDs practical.

3. Speedup Techniques
section presents two techniques speed VI algorithm Wang et al. (2008)
maintaining exact solution.
3.1 Subtracting Apart - Improving Applicability R7
applicability R7 increased certain branches variables standardized
apart way preserves evaluation FODD max aggregation
semantics. Consider FODD B Figure 3. Intuitively weak reduction applicable
diagram following argument. Consider valuation = {x \ 1, \ 2,
z \ 3} crossing edge e2 interpretation I. |= B p(1) p(2). Therefore
must valuation = {x \ 2, z \ 3} (and value y), crosses edge e1 .
depending truth value |= B q(1) |= B q(2), four
possibilities would reach crossing nodes target(e2 ) target(e1 )
respectively. However, cases, apB (I, ) apB (I, ). Therefore
able replace target(e2 ) 0 leaf. similar argument shows also
able drop node source(e2 ). Surprisingly, though, none R7 conditions apply
case diagram cannot reduced. closer inspection find
reason conditions (P7.2) (V7.3) restrictive. (V7.3)
holds (P7.2) requires x, z,[[y, p(x) p(y)] [p(x)]] implying every
valuation crossing edge e2 , another valuation crossing edge e1
valuations agree value x z hold. However,
argument above, dominate , two valuations need agree value x.
observe rename variable x instances different sub-FODDs
240

fiProbabilistic Planning FODD

rooted target(e1 ) target(e2 ) (i.e. standardized apart w.r.t. x) (P7.2)
(V7.3) go diagram reduced. Notice type
simplification go must case B1 B2 0 already holds.
variables standardize apart harder keep condition. develop
idea, introduce new FODD subtraction algorithm Sub-apart: Given diagrams B1
B2 algorithm tries standardize apart many common variables possible,
keeping condition B1 B2 0 true. algorithm returns 2-tuple {T, V },
Boolean variable indicating whether combination produce diagram
negative leaves variables except ones V standardized apart.
algorithm uses standard recursive template combining ADDs FODDs
(Bahar et al., 1993; Wang et al., 2008) root node chosen root two
diagrams operation recursively performed corresponding sub-diagrams.
addition roots two diagrams identical Sub-apart considers possibility
making different standardizing apart. Sub-apart uses recursive calls
collect constraints specifying variables cannot standardized apart; sets
combined returned calling procedure.
Procedure 1 Sub-apart(A, B)
1. B leaves,
(a) B 0 return {true, {}} else return {f alse, {}}
2. l(A) < l(B), let
(a) {L, V1 } = Sub-apart(target(At ), B)
(b) {R, V2 } = Sub-apart(target(Af ), B)
Return {L R, V1 V2 }
3. l(A) > l(B), let
(a) {L, V1 } = Sub-apart(A, target(Bt ))
(b) {R, V2 } = Sub-apart(A, target(Bf ))
Return {L R, V1 V2 }
4. l(A) = l(B), let V variables (or B). Let
(a) {LL, V3 } = Sub-apart(target(At ), target(Bt ))
(b) {RR, V4 } = Sub-apart(target(Af ), target(Bf ))
(c) {LR, V5 } = Sub-apart(target(At ), target(Bf ))
(d) {RL, V6 } = Sub-apart(target(Af ), target(Bt )
(e) RR = f alse, return {f alse, V3 V4 }
(f ) LR RL = f alse return {true, V V3 V4 }
(g) Return {true, V3 V4 V5 V6 }
241

fiJoshi & Khardon

next theorem shows procedure correct. variables common B1
B2 denoted ~u B w~ denotes combination diagram B1 B2
subtract operation variables except ones w
~ standardized apart. Let n1
n2 roots nodes B1 B2 respectively.
Theorem 1 Sub-apart(n1 , n2 ) = {true, ~v } implies B~v contains negative leaves
Sub-apart(n1 , n2 ) = {f alse, ~v } implies w
~ w
~ ~u B w~ contains negative
leaves.
Proof: proof induction k, sum number nodes B1 B2 .
base case k = 2, B1 B2 single leaf diagrams statement
trivially true. Assume statement true k consider case
k = + 1. l(n1 ) < l(n2 ), resultant diagram combination subtraction,
expect n1 root node n1t n2 n1f n2 left right
sub-FODDs respectively. Hence, Sub-apart algorithm recursively calls Sub-apart(n1t ,
n2 ) Sub-apart(n1f , n2 ). Since sum number nodes diagrams
recursive calls always m, statement true recursive calls. Clearly,
top level return true iff calls return true. addition, keep variables
V1 V2 (of step 2) original form (that is, standardized apart)
branches new root n1 guaranteed positive leaves therefore
true diagram rooted n1 . similar argument shows statement true
l(n1 ) > l(n2 ).
l(n1 ) = l(n2 ), inductive hypothesis, statement theorem
true recursive calls. 2 choices. could either standardize apart
variables V l(n1 ) l(n2 ) keep identical. same, resultant
diagram combination subtraction expect n1 root node n1t n2t
n1f n2f left right sub-FODDs respectively. top level
return true iff calls return true. set shared variables requires variables
l(n1 ) addition recursive calls order ensure l(n1 ) = l(n2 ).
standardize apart l(n1 ) l(n2 ), fall back one cases n1
6= n2 except algorithm checks second level recursive calls n1t n2t ,
n1t n2f , n1f n2t n1f n2f . top level algorithm return true
four calls return true return union sets variables returned four
calls. four calls return true, algorithm still keep variables l(n1 )
l(n2 ) identical return true conditions case met.

theorem shows algorithm correct guarantee minimality.
fact, smallest set variables w
~ B w~ negative leaves may unique
(Wang et al., 2008). One also show output Sub-apart may minimal.
principle, one use greedy procedure standardizes apart one variable time
arrives minimal set w.
~ However, although Sub-apart produce minimal
set, prefer greedy approach fast often generates small set w
~
practice. define new conditions applicability R7:
(V7.3S) : Sub-apart(target(e1 ), target(e2 )) = {true, V1 }.
(P7.2S) : B |= V1 , [[w,
~ EF(e2 )] [~v , EF(e1 )]] ~v , w
~ remaining variables (i.e. V1 ) EF(e1 ), EF(e2 ) respectively.
242

fiProbabilistic Planning FODD

(P7.2S) guarantees whenever 2 running target(e2 ), always
1 running target(e1 ) 1 2 agree V1 . (V7.3S) guarantees
condition, 1 provides better value 2 . Using exactly proof Lemma 1
given Wang et al. (2008), show following:
Lemma 2 Let B FODD, e1 e2 edges conditions P7.2S, V7.3S,
S1 hold, B result R7-replace(e1 , e2 ), interpretation
MAPB (I) = MAPB (I).
Importantly, conditions (P7.2S) , (V7.3S) subsume previous conditions applicability safety R7-replace previously given (Wang et al., 2008). Therefore, instead testing multiple conditions sufficient test (P7.2S)
(V7.3S) . similar argument one shows Sub-apart extends simplifies conditions R7-drop. Thus use Sub-apart simplifies conditions
tested provides opportunities reductions. implementation,
use new conditions Sub-apart whenever testing applicability R7-replace
R7-drop.
3.2 Standardizing Apart
Recall FODD-based VI algorithm must add functions represented FODDs (in
Steps 2 4) take maximum functions represented FODDs (in Step
4). Since individual functions independent functions state, variables
different functions related one another. Therefore, adding maximizing,
algorithm Wang et al. (2008) standardizes apart diagrams. is, variables
diagrams given new names constrain other. hand,
since different diagrams structurally related often introduces redundancies (in
form renamed copies atoms) must removed reduction operators.
However, reduction operators ideal avoiding step lead significant
speedup system. observe maximization (in Step 4) standardizing
apart needed therefore avoided.
Theorem 2 Let B1 B2 FODDs. Let B result combining B1 B2
max operation B1 B2 standardized apart. is, s, MAPB (s) =
max{MAPB1 (s), MAPB2 (s)}. Let B result combining B1 B2 max
operation B1 B2 standardized apart. interpretations I, apB (I) =
apB (I).
Proof: theorem proved showing valuation maximizing
diagram completed valuation combined diagram giving
value. Clearly apB (I) apB (I) since every substitution path exist B
also possible B. show direction holds well. Let ~u
variables common B1 B2 . Let u~1 variables B1 B2 u~2
variables B2 B1 . definition, interpretation I,
apB (I) = ax[M apB1 (I), apB2 (I)] = ax[M apB1 (I, 1 ), apB2 (I, 2 )]
243

fiJoshi & Khardon

Figure 4: FODD example illustrating need DPO.

valuations 1 ~uu~1 2 ~uu~2 . Without loss generality let us assume
apB1 (I, 1 ) = ax[M apB1 (I, 1 ), apB2 (I, 2 )]. construct valuation
~uu~1 u~2 1 share values variables ~u u~1 . Obviously apB1 (I, )
= apB1 (I, 1 ). Also, definition FODD combination, apB (I)
apB1 (I, ) = apB (I).


4. Additional Reduction Operators
section introduce two new reduction operators improve efficiency
VI algorithm. following definitions important developing reductions
understand potential scope reducing diagrams.
Definition 1 descending path ordering (DPO) ordered list paths
root leaf FODD B, sorted descending order value leaf reached
path. relative order paths reaching leaf set arbitrarily.
Definition 2 B FODD, P DPO B, path pj P instrumental
respect P iff
1. interpretation valuation, , P athB (I, ) = pj ,
2. valuations , P athB (I, ) = pk , k j.
example Figure 4 shows DPO needed. paths p(x) p(y)
p(x) p(z) imply other. Whenever valuation traversing one
paths always another valuation traversing other. Removing one path
diagram would safe meaning map changed. cannot remove
paths. Without externally imposed order paths, clear path
labeled redundant. DPO exactly make reduction possible.
clear outset best choose DPO maximally reduce
size diagram. lexicographic ordering paths equal value makes easy
implementation may best. describe heuristic approach choosing
DPOs next section context implementation FODD-Planner.
244

fiProbabilistic Planning FODD

4.1 R10 Reduction
path FODD B dominated whenever valuation traverses it, always
another valuation traversing another path reaching leaf greater equal value.
paths edge e dominated, valuation crossing edge
ever determine map max aggregation semantics. cases replace
target(e) 0 leaf. basic intuition behind R10 operation.
Although objective R7-replace, R10 faster compute
cases two advantages R7-replace. First, paths ranked
value leaf reach, perform single ranking check dominated
paths (and hence dominated edges). Hence, reduction operators
local, R10 global reduction. Second, theorem proving required R10 always
conjunctive formulas existentially quantified variables, decidable
function free case (e.g., Khardon, 1999). gives speedup R7-replace.
hand R10 must explicitly enumerate DPO therefore efficient
FODD exponential number non-zero valued paths. case R7
edge based procedure likely efficient.
Consider example shown Figure 5. following list specifies DPO
diagram:
1. p(y), p(z), p(x) 3
2. p(y), p(z), p(x), q(x) 3
3. p(y), p(x), q(x) 2
4. p(y), p(z), p(x), q(x) 2
Notice relative order paths reaching leaf DPO defined
ranking shorter paths higher longer ones. requirement correctness
algorithm good heuristic. According reduction procedure, edges
path 1 important cannot reduced. However, since 1 subsumes 2, 3 4,
edges (those belonging paths 2, 3 4 appearing
ranked paths) reduced. Therefore reduction procedure replaces targets
edges ones path 1, value 0. Path 1 thus instrumental path
paths 2, 3 4 not. process formalized following algorithm.
Procedure 2 R10(B)
1. Let E set edges B
2. Let P = [p1 , p2 pn ] DPO B. Thus p1 path reaching highest leaf
pn path reaching lowest leaf.
3. j = 1 n, following
(a) Let Epj set edges pj
(b) i, < j B |= (x~pj , PF(pj )) (x~pi , PF(pi )), set E =
E E pj
245

fiJoshi & Khardon

p(y)

p(y)
R10

p(z)

0

p(x)
q(x)

2

p(x)

q(x)

2

0

p(z)
0

0

0

p(x)

0

3

3
Figure 5: FODD example illustrating R10 reduction.

4. every edge e E, set target(e) = 0 B
example Figure 5 none paths 2, 3 4 pass conditions step 3b
algorithm. Therefore edges removed E assigned
value 0 algorithm. R10 able identify one pass, one path
(shown along curved indicator line) dominates paths. achieve
reduction, R7-replace takes 2-3 passes depending order application. Since every
pass R7-replace check implication edge formulas every pair edges,
expensive. hand, cases R10 applicable
R7-replace is. example shown diagram Figure 6. diagram
easy see e2 reached e1 e1 always gives strictly better value.
R10 cannot applied tests subsumption complete paths. case
path e2 implies disjunction two paths going e1 .
next present proof correctness R10. Lemma 3 shows test
instrumental paths correct. Lemma 4 shows that, result, edges marked deletion
end algorithm belong instrumental path. theorem uses
fact argue correctness algorithm.
Lemma 3 path pj P , pj instrumental i, < j B |= (x~pj ,
PF(pj )) (x~pi , PF(pi )).
Proof: pj instrumental definition, interpretation valuation,
, P athB (I, ) = pj , valuations , < j P athB (I, ) = pi .
words, |= [B (x~pj , PF(pj ))] 6|= [B (x~pi , PF(pi ))] < j.
implies i, < j (B x~pj , PF(pj )) |= (B x~pi , PF(pi )). Hence i, < j
B |= [(x~pj , PF(pj )) (x~pi , PF(pi ))].

Lemma 4 E set edges left end R10 procedure e E
instrumental path goes e.
246

fiProbabilistic Planning FODD

Figure 6: FODD example R7 applicable R10 not.

Proof: Lemma 3 proves path pj instrumental, i, < j B |= [(x~pj ,
PF(pj )) (x~pi , PF(pi ))]. Thus step 3b R10, path instrumental, edges
removed E. Therefore e E end R10 procedure, cannot
pj . Since pj constrained way argument above, e cannot
instrumental path.

Theorem 3 Let B FODD. B = R10(B) interpretations I, apB (I) =
apB (I).
Proof: definition R10, difference B B
edges pointed sub-FODDs B, point 0 leaf B . edges
left set E end R10 procedure. Therefore valuation crossing
edges achieves value 0 B could achieved value B
interpretation. Valuations crossing edges achieve value B
B. Therefore interpretation valuation , apB (I, ) apB (I, )
hence apB (I) apB (I).
Fix interpretation v = apB (I). Let valuation apB (I, )
= v. one gives value v, choose one whose path pj
least index P . definition pj instrumental lemma 4, none
edges pj removed R10. Therefore apB (I, ) = v = apB (I). Finally,
definition max aggregation semantics, apB (I) apB (I, ) therefore

apB (I) apB (I).
R10 procedure similar reduction decision list rules ReBel (Kersting
et al., 2004). difference, however, R10 reduction procedure FODDs
therefore uses individual rules subroutine gather information
redundant edges. Thus ReBel removes paths R10 removes edges affecting multiple
paths diagram. main potential disadvantage R10 representation
ReBel case number paths prohibitively large. case R7
edge based reduction likely efficient. experiments show
case IPC domains tested. general case, meta-reduction heuristic trading
advantages different operators would useful. discuss implementation
experimental results next sections.
247

fiJoshi & Khardon

4.2 R11 Reduction
Consider FODD B Figure 1(a). Clearly, background knowledge diagram cannot reduced. assume background knowledge B contains rule
x, [q(x) p(x)]. case exists valuation reaches 1 leaf, must
another valuation agrees values x y. dominates
valuations max aggregation semantics. background knowledge rule implies
, test root node redundant. However, cannot set left child
root 0 since entire diagram eliminated. Therefore R7 applicable,
similarly none existing reductions applicable. Yet redundancies like
given example arise often runs value iteration algorithm. happens naturally,
without artificial background knowledge used example corresponding
diagrams large include text. main reason redundancies
standardizing apart (which discussed above) introduces multiple renamed copies
atoms different diagrams. diagrams added, many
atoms redundant removed old operators. atoms may end
parent-child relation weak implication child parent, similar
example given. introduce R11 reduction operator handle situations.
R11 reduces FODD Figure 1(a) FODD Figure 1(b).
Let B FODD, n node B, e edge e {nt , nf }, e = sibling(e)
(so e = nt , e = nf vice versa), P set paths root
non-zero leaf going edge e. reduction R11(B, n, e) drops node n
diagram B connects parents target(e). need two conditions
applicability R11. first requires sibling zero valued leaf.
Condition 1 target(e ) = 0.
second requires valuations rerouted R11 traversing B ,
valuations previously reached 0 leaf traverse path P ,
dominated valuations giving value.


Condition 2 p P , B |= [x~p , PF(p)\ne .lit ne .lit] [x~p , PF(p)].
next theorem shows R11 sound. proof shows condition 2
rerouted valuations add value diagram.
Theorem 4 B = R11(B, n, e), conditions 1 2 hold, interpretations I,
apB (I) = apB (I).
Proof: Let interpretation let Z set valuations. divide Z
three disjoint sets depending path taken valuations B I. Z e -

set valuations crossing edge e, Z e - set valuations crossing edge e Z
- set valuations reaching node n. analyze behavior valuations
sets I.
Since structurally difference B B B node n bypassed, paths root leaf cross node n remain untouched.
Therefore Z , apB (I, ) = apB (I, ).
248

fiProbabilistic Planning FODD

Since, B parents node n connected target(e), valuations crossing
edge e reaching target(e) B unaffected B will, therefore,
produce map. Thus Z e , apB (I, ) = apB (I, ).


Now, let denote node target(e) B. I, valuations Z e reach
0 leaf B cross node B . Depending leaf reached

e
crossing node m, set Z e divided 2 disjoint subsets. Zzero

e
set valuations reaching 0 leaf Znonzero - set valuations reaching
e , ap (I, ) = ap (I, ).
non-zero leaf. Clearly Zzero
B
B


e
structure B, every Znonzero
, traverses p P , is, (PF(p)\ne .lit

e
n .lit) true I. Condition 2 states every , another
valuation (PF(p)) true I, traverses path. However,
every valuation must belong set Z e definition set Z e .
e
dominated valuation Z e .
words, B every valuation Znonzero

argument conclude B I, every valuation either produces
map B dominated valuation. max aggregation

semantics, therefore, apB (I) = apB (I).

5. FODD-Planner
section discuss system FODD-Planner implements VI algorithm
FODDs. FODD-Planner employs number approximation techniques yield
speedup. system also implements extensions basic VI algorithm
allow handle action costs universal goals. following sections describe
details.
5.1 Value Approximation
Reductions help keep diagrams small size removing redundancies
true n step-to-go value function large, legal reductions cannot help.
domains true value function unbounded. example tireworld domain
international planning competition, goal always get vehicle
destination city, one chain cities linked one another destination.
chain length. Therefore value function represented using
state abstraction, must unbounded. result SDP-like algorithms less effective
domains dynamics lead transitive structure every iteration value
iteration increases size n step-to-go value function (Kersting et al., 2004; Sanner
& Boutilier, 2009). cases value function infinite simply large
manipulate efficiently. happens resort approximation keeping much
structure value function possible maintaining efficiency. One must
careful tradeoff here. Without approximation runtime prohibitive
much approximation causes loss structure value. next present three methods
get approximations act different levels algorithm.
249

fiJoshi & Khardon

5.1.1 Standardizing Apart Action Variants
Standardizing apart diagrams action variants adding required
correctness FODD based VI algorithm. is, standardize apart action
variant diagrams adding them, value given states may lower
true value (Wang et al., 2008). Intuitively, true since different paths value
function share atoms variables. Now, fixed action, best variable binding
corresponding value different action variants may different. Thus, variables
forced variants, may rule viable combinations value.
hand, value obtained standardize apart lower bound true
value. every path diagram resulting standardizing apart
present diagram resulting standardizing apart. Although value exact,
standardizing apart leads compact diagrams, therefore useful
speeding algorithm. call approximation method non-std-apart use
heuristic speed computation. Although heuristic may cause loss structure
representation value function, observed practice gives significant
speedup maintaining relevant structure. approximation used
experiments described below.
5.1.2 Merging Leaves
use FODDs also allows us approximate value function simple controlled way. follow approximation techniques APRICODD (St-Aubin et al.,
2000) used propositional problems. idea reduce size
diagram merging substructures similar values. One way
reduce precision leaf values. is, given precision value , join leaves
whose value within . This, turn, leads reduction diagram subparts
diagram previously pointed different leaves, point leaf.
granularity approximation, however, becomes extra parameter system
chosen carefully. Details provided experiments below.
5.1.3 Domain Determinization
Previous work stochastic planning discovered domains one get good
performance pretending domain deterministic re-planning unexpected
outcomes reached (Yoon et al., 2007). use similar idea determinize
domain process policy generation. saves significant amount computation
avoids typical increase size value function encountered step 2 VI
algorithm. Domains determinized many ways. choose perform determinization replacing every stochastic action probable deterministic alternative.
done prior running VI. Although method determinization
sub-optimal many domains, makes sense domains probable outcome corresponds successful execution action (Little & Thibaux, 2007)
case domains experimented with. Note determinization applies
process policy generation. generated policy deployed solve planning
problems, original stochastic environment. approximation used
experiments described below.
250

fiProbabilistic Planning FODD

5.2 Extensions VI Algorithm
FODD-Planner makes two additional extensions basic algorithm. allows
handling action costs, arbitrary conjunctive goals well universal goals.
5.2.1 Handling Action Costs
standard way handle action costs replace R(s, a) R(s, a) Cost(s, a)
VI algorithm. However, formalism using FODDs relies fact
leaves (and thus values) non-negative. avoid difficulty, note action costs
supported long least one zero cost action. see recall VI
algorithm. appropriate place add action costs Object Maximization
step. However, step followed maximizing action diagrams,
least one action 0 cost (if create no-op action), resultant diagram
maximization never negative leaves. Therefore safely convert negative leaves
maximization step 0 thereby avoid conflict reduction procedures.
5.2.2 Handling Universal Goals
FODDs max aggregation cannot represent universal quantifiers. Therefore VI
algorithm cannot handle universal goals abstract level (though see Joshi et al. (2009)
formalism accept arbitrary quantifiers). concrete planning problem
known set objects instantiate universal goal get large conjunctive
goal. principle run VI policy generation large conjunctive goal.
However, would mean cannot plan off-line get generic policy must
replan problem instance scratch. follow alternative heuristic
approach previously introduced Sanner Boutilier (2009) use approximation
true value function, results simple additive decomposition goal
predicates.
Concretely, off-line planning plan separately generic version
predicate. example transportation domain discussed plan
generic predicate box-in-city(box, city) well individual predicates.
execution time, given concrete goal, approximate true value function
sum generic versions ground goal predicate. clearly exact
calculation work every case. hand, considerably extends
scope technique works well many situations.
5.3 FODD-Planner System
implemented FODD-Planner system, plan execution routines evaluation
routines Yap Prolog 5.1.2. code domain encodings used experiments
reported next section available http://code.google.com/p/foddplanner/
tag release11-JAIR2011.
implementation uses simple theorem prover supports background knowledge
procedure call state flooding. is, prove B |= X , X ground
conjunction (represented Prolog list), flood X using rules background
knowledge using following simple steps convergence.
251

fiJoshi & Khardon

1. Generate Z, set ground literals derived X rules
background knowledge.

2. Set X = X Z.

X converged test membership X. restricted
language, reasoning problem decidable theorem prover complete.2
overall algorithm SDP except operations performed
FODDs reductions applied keep intermediate diagrams compact.
experiments reported below, use previously mentioned reductions (R1 R11)
except R7-replace. applied reductions iteratively reduction applicable
FODD. correct order apply reductions sense reduction
applied give rise reductions. Heuristically chose order
hope get much diagram reduced soon possible. apply reductions
following order. start applying R10 twice different DPO time. first
DPO generated breaking ties favor shorter paths. second generated
reversing order equal valued paths first DPO. R10 hope catch many
redundant edges early. R10 followed R7-drop remove redundant nodes connected
edges removed R10. this, apply round strong reductions followed
R9 remove redundant equality nodes. R9 followed another round strong
reductions. sequence performed iteratively diagram stable.
FODD-Planner strong reductions automatically applied every time two diagrams
combined (using apply algorithm (Wang et al., 2008)) weak reductions applied
every time two diagrams combined except regression block combination.
chose apply R11 twice every iteration - regression
next iteration. setting application reduction operators investigated
experimentally discussed Section 6.1.
handle complex goals use additive goal decomposition. generic goal
atom g run system specified number iterations, last iteration
perform step 4 algorithm. yields set functions, Qg,A , parameterized
action generic goal implicitly represent policy. improve line execution
time using policy extract set paths Q functions perform logical
simplification paths removing implied atoms directly applying equalities
path formula. final form policy off-line planning
phase. on-line phase, given concrete problem state goal identify potential
actions, action find top ranking rule concrete goal atom g.
combined give total value action action highest value
chosen, breaking ties randomly unique.
2. alternative list representation X would utilize Prolog database store
literals X employ Prolog engine query . However, experience Yap,
becomes expensive assert (and retract) literals X (from) Prolog database list
representation faster.

252

fiProbabilistic Planning FODD

6. Experimental Results
ran experiments standard benchmark problem well probabilistic planning
domains international planning competitions (IPC) held 2004, 2006 2008.
probabilistic track IPC provides domain descriptions PPDDL language
(Younes, Littman, Weissman, & Asmuth, 2005). encoded TVDs probability
reward functions domains translating PPDDL manually straightforward
manner.3 experiments run Linux machine Intel Pentium processor
running 3 GHz, 2 GB memory. Following IPC standards, timings, rewards
plan-lengths report averages 30 rounds. domain, constructed
hand background knowledge restricting arguments predicates (e.g. box
one city time Bin(b, c1 ), Bin(b, c2 ) (c1 = c2 )). discussed above,
useful process simplifying diagrams.
6.1 Merits Reduction Operators
following subsections present main results showing performance solving planning
problems IPC. discussing first investigate illustrate merits
various reduction operators terms effect off-line planning time.
experiments performed tireworld boxworld domains described
detail below. section suffices consider domains typical cases
might address solving planning problems focus differences
reductions.
first set experiments compare run time R7 R10 context
reductions. Since R10 R7 edge removal reductions R7-drop used
conjunction both, compare R10 R7-replace directly configurations
R9 R11. Except choice reductions used experimental setup exactly
detailed above. Figures 7 8 show time build policy varying
number iterations different settings weak reduction operators boxworld
tireworld domains. figures clearly show superiority R10 R7-replace.
combinations R7-replace prohibitively large run times 3 4 iterations.
without R9 R11, R10 orders magnitude efficient R7-replace.
reason future experiments used R10 instead R7-replace.
experiments also demonstrate without new reduction operators presented
paper FODD-Planner would slow run sufficient iterations VI
algorithm done following subsections yield good planning performance. Figure 8
shows boxworld R11 hinders R7. appears case, application
R11 limits applicability R7 causing larger diagrams thus slowing
VI.
Figures 9 10 show relative merits R9 R11 presence R10
two domains. figures similar previous two plots except focus
relevant portion CPU time axis. Clearly R11 important reduction makes
3. FODD formalism cannot capture PPDDL. particular since FODDs cannot represent universal quantification, cannot handle universal action preconditions. hand FODDs
handle universal action effects. Wang (2007) provides algorithm detailed discussion translation PPDDL FODDs.

253

fiJoshi & Khardon

Tireworld: R7 vs. R10

100000

CPU Time (seconds)

80000

R10
R10+R11
R10+R9
R10+R9+R11
R7
R7+R11
R7+R9
R7+R9+R11

60000

40000

20000

0

0

1

2

3

4
# iterations

5

6

7

8

Figure 7: comparison planning time taken various settings reduction operators
varying number iterations tireworld. Four settings R10 compared
four settings R7. R7 variants complete 5 iterations within
time range graph therefore points plotted.

Boxworld: R7 vs. R10
R10
R10+R11
R10+R9
R10+R9+R11
R7
R7+R11
R7+R9
R7+R9+R11

40000

CPU Time (seconds)

30000

20000

10000

0

0

1

2

3
# iterations

4

5

6

Figure 8: comparison planning time taken various settings reduction operators
varying number iterations boxworld. Four settings R10 compared
four settings R7. R7 variants complete 5 iterations within
time range graph therefore points plotted.

planning efficient settings (just R10 R10+R9). R9 less effective
tireworld. boxworld, however presence R9 clearly improves planning efficiency
settings, best performance achieved setting using R10+R9+R11.
addition, R9 targets removal equality nodes reduction directly.
254

fiProbabilistic Planning FODD

Tireworld: Merits R9 R11
25000

CPU Time (seconds)

20000

R10
R10+R11
R10+R9
R10+R9+R11

15000

10000

5000

0

0

1

2

3

4
# iterations

5

6

7

8

Figure 9: comparison merits R9 R11 presence R10 tireworld.
Boxworld: Merits R9 R11
30000

25000

CPU Time (seconds)

20000

R10
R10+R11
R10+R9
R10+R9+R11

15000

10000

5000

0
0

1

2

3
# iterations

4

5

6

Figure 10: comparison merits R9 R11 presence R10 boxworld.

Based results choose setting employ R10 along R9 R11
remaining experiments.
6.2 Logistics Benchmark Problem
boxworld problem introduced Boutilier et al. (2001) used
standard example exact solution methods relational MDPs. domain consists
boxes, cities trucks. objective get certain boxes certain cities loading,
unloading driving. benchmark problem, goal existence box
Paris. load unload actions probabilistic probability success unload
depends whether raining not. domain, cities reachable
other. result domain compact abstract optimal value function. Note
challenge domain concrete planning instances solve. Instead goal
255

fiJoshi & Khardon

GPT
Policy Iteration
policy language bias
Re-Engg NMRDPP
FODD-Planner

Coverage
100%

Time (ms)
2220

Reward
57.66

46.66%
10%
100%

60466
290830
231270

36
-387.7
70.0

Table 1: fileworld domain results
solve off-line problem produce (abstract) optimal solution efficiently.
domain description 3 predicates arity 2 3 actions 2 arguments.
Like ReBel (Kersting et al., 2004) FOADD (Sanner & Boutilier, 2009) able
solve MDP identify relevant partitions optimal value function
fact value function converges 10 iterations. FODD-Planner performed 10
iterations 2 minutes.
6.3 Fileworld Domain
domain part probabilistic track IPC-4 (2004) (information competitions accessible http://ipc.icaps-conference.org/). domain consists
files folders. Every file obtains random assignment folder execution time
goal place file assigned folder. cost 100 handle folder
cost 1 place file folder. optimal policy domain first get
assignments files folders handle folder once, placing files
assigned it. domain description 8 predicates arity 0 2 16 actions
0 1 arguments.
Results published one problem instance consisted thirty files
five folders. Since goal conjunctive used additive goal decomposition
discussed above. used off-line planning generic goal f iled(a) use policy
solve number files. domain ideal abstract solvers
optimal value function policy generic goal compact found quickly.
FODD-Planner able achieve convergence within 4 iterations even without
approximation. Policy generation execution together took 4 minutes. 6
systems competed track, results published 3 website cited
above. Table 1 compares performance FODD-Planner others. observe
rank ahead terms total reward coverage (both FODD-Planner
GPT achieve full coverage).
6.4 Tireworld Domain
domain part probabilistic track IPC-5 (2006). domain consists
network locations (or cities). vehicle starts one city moves city city
objective reaching destination city. Moves made cities
directly connected road. addition, move, vehicle may lose tire
40% probability. cities spare tire loaded onto vehicle.
vehicle contains spare tire, flat tire changed 50% success probability.
domain simple trivial owing possibility complex network topology
256

fiProbabilistic Planning FODD

Tireworld: Percentage Runs Solved vs. Problem Instance

100

Percentage Runs Solved

80

60

40
FOALP
FPG
Paragraph
FF-Replan
FODDPlanner

20

0
0

2

4

6

8
10
Problem Instance ID

12

14

16

Figure 11: Coverage result tireworld experiments
Tireworld: Average Running Time vs. Problem Instance
1e+06

Average Running Time (ms)

FOALP
FPG
Paragraph
FF-Replan
100000 FODDPlanner

10000

1000

100

10
0

2

4

6

8

10

12

14

16

Problem Instance ID

Figure 12: Timing result tireworld experiments
high probabilities failure. IPC description domain 5 predicates
arity 0 2 3 actions 0 2 arguments.
Participants IPC-5 competed 15 problem instances domain varying
degree difficulty. problem 1 16 locations progressively increased
2 per problem 44 locations problem 15.
limit off-line planning time restricted FODD-Planner 7 iterations without
approximation first 3 iterations non-std-apart approximation
remaining iterations. policy generated 55 minutes; together online
planning time within competition time bound. performance FODD-Planner
257

fiJoshi & Khardon

Tireworld: Average # Actions Goal vs. Problem Instance

12

FOALP
FPG
Paragraph
FF-Replan
FODDPlanner

Average # Actions Goal

10

8

6

4

2

0
0

2

4

6

8
10
Problem Instance ID

12

14

16

Figure 13: Plan length result tireworld experiments
systems competing probabilistic track IPC-5, data published,
summarized Figures 11, 12, 13. figures indexed problem instance
show comparison percentage runs planner able solve (coverage),
average time per instance taken planner generate online solution,
average number actions taken planner reach goal every instance.
observe overall performance FODD-Planner competitive (and
cases better than) systems. Runtimes generate online solutions high
FODD-Planner comparable FOALP First-Order
planner. hand, comparison systems, able achieve
high coverage short plans many problems.
6.5 Value Approximation Merging Leaves
Although tireworld domain solved within IPC time limit, one might
wish even faster execution. show next, heuristic merging leaves provides
tool, potentially trading quality coverage plan length faster planning
execution times. Table 2 shows average reduction planning time, coverage
planning length achieved approximation merging leaves used. highest
reward obtained state 500. experimented reducing precision leaves
values 50.0 150.0. results demonstrate, loss coverage
planning length, system gain terms execution time planning time.
example, leaf precision 50.0 (10% total value) get 95.53% reduction
planning time (22 fold speedup) lose 15.29% coverage.4
4. Note measure plan length, average problems solved, good representation
performance coverage full. case, coverage goes dropping harder
problems longer solutions, plan length appear better, clearly indication
improved performance.

258

fiProbabilistic Planning FODD

Precision
50
75
100
125
150

Reduction
Planning Time
93.53%
98.13%
98.28%
99.65%
99.73%

Reduction
Execution Time
88.3%
95.21%
95.21%
95.48%
95.61%

Reduction
Coverage
15.29%
15.29%
15.29%
31.76%
31.76%

Reduction
Plan length
14.54%
6.23%
6.23%
-30.86%
-30.86%

Table 2: Percentage average reduction planning time, execution time, coverage plan
length tireworld approximation merging leaves varying leaf precision values. example, first row table states reducing
precision leaves 50, 10% largest achievable reward
state, planning time reduced 93.53% original value, average
execution time reduced 88.3%, average coverage reduced 15.29%
average plan length reduced 14.54%

6.6 Boxworld
domain IPC 2008, world consists boxes, trucks, planes map
cities. objective get boxes source cities destination cities using trucks
planes. Boxes loaded unloaded trucks planes. Trucks (and
planes) driven (flown) one city another long direct road (or
air route) source destination city. probabilistic action drive.
drive works expected (transporting truck source city destination
city) probability 0.8. Occasionally drive teleports truck wrong city. IPC
description domain includes 11 predicates arity 2 6 actions 3 arguments.
IPC posted 15 problems varying levels difficulty domain. problems
world consisted 4 trucks 2 airplanes. problems 1 3 10 boxes
5 cities. Problems 4 5 10 boxes 10 cities. Problems 6 7 10 boxes
15 cities. Problems 8 9 15 boxes 10 cities. Problems 10, 11 12 15 boxes
15 cities. Competition results show RFF (Teichteil-Koenigsbuch et al., 2008)
system solved 15 problems. Neither RFF FODD-Planner
could solve problems 13 15; hence omit results those.
limit off-line planning time determinized domain (making drive deterministic)
restricted FODD-Planner 5 iterations. Since domain determinized,
one alternative per action. Therefore non-std-apart approximation
effect here. policy generated 42.6 minutes. performance FODDPlanner RFF summarized Figures 14, 15, 16. figures show comparison
percentage runs planner able solve (coverage), average reward
achieved per problem instance, average number actions taken planner
reach goal every instance.
seen FODD-Planner lower coverage RFF. However, performance close RFF terms accumulated reward consistently better terms
plan length even problems achieve full coverage.
259

fiJoshi & Khardon

Boxworld: Percentage Runs Solved vs. Problem Instance

100

Percentage Runs Solved

80

FODDPlanner
RFF

60

40

20

0
0

2

4

6
8
Problem Instance ID

10

12

Figure 14: Coverage results boxworld experiments

Boxworld: Average # Actions Goal vs. Problem Instance
1800
1600

Average # Actions Goal

1400

FODDPlanner
RFF

1200
1000
800
600
400
200
0
0

2

4

6

8

10

Problem Instance ID

Figure 15: Plan length results boxworld experiments

260

12

fiProbabilistic Planning FODD

Boxworld: Average Reward vs. Problem Instance
2000
1800
FODDPlanner
RFF

1600

Average Reward

1400
1200
1000
800
600
400
200
0
0

2

4

6
8
Problem Instance ID

10

12

Figure 16: Average reward results boxworld experiments
domain experienced long plan execution times (10 minutes per round hard
problems 15 seconds per round easier problems). points complexity instances could one reason failure planning systems
IPC strict time bound observed, failure RFF problems 13,
14 15. Thus, although performance system promising, reducing online execution time crucial. shown above, domains technique merging leaves
lead improvement cost reduction performance. Unfortunately,
domain merging leaves provide advantage. tireworld,
clear tradeoff quality coverage planning time. However switch
abrupt gain significantly execution time one incurs significant loss coverage.
Improving runtime online application policies important aspect future
work.

7. Related Work
introduction briefly reviewed previous work MDPs, propositionally factored MDPs
RMDPs focusing work directly related ideas used paper.
several solution formalisms RMDPs combine dynamic programming ideas yield successful systems. include approaches combine
dynamic programming linear function approximation (Sanner & Boutilier, 2009), forward search (Holldobler et al., 2006) machine learning (Fern, Yoon, & Givan, 2006;
Gretton & Thiebaux, 2004). yielded strong implementations participated
planning competitions. works directly use dynamic programming.
instance Guestrin, Koller, Gearhart, Kanodia (2003a) present approach using
additive value functions based object classes employ linear programming solve
RMDP. Mausam Weld (2003) employ SPUDD (Hoey et al., 1999) solve ground
instances RMDP, generate training data solutions learn lifted value
261

fiJoshi & Khardon

function training data using relational tree learner. Gardiol Kaelbling (2003)
apply methods probabilistic planning solve RMDPs.
closely related work preceded effort, Sanner Boutilier (2009)
developed relational extension linear function approximation techniques factored
MDPs. value function represented weighted sum basis functions, denoting
partition state space. difference work factored MDPs
basis functions First-Order formulas thus value function valid domain
size (this fundamental advantage RMDP solvers ground MDP
solvers). develop methods automatic generation First-Order constraints
linear program automatic generation basis functions show promise solving
domains IPC. work Sanner Boutilier thus extension
work linear representations propositionally factored MDPs (e.g., Guestrin et al.,
2003b) capture relational structure. similar view work FODD-Planner
relational extension work ADD based solvers propositionally factored MDPs
(Hoey et al., 1999). context interesting note Sanner Boutilier also
developed relational extension ADDs call FOADDs. contrast FODDs,
nodes FOADDs labeled closed First-Order formulas.5 Sanner Boutilier
report implementation able provide exact solutions simple problems,
developed applied approach using linear function approximation
complex problems. experiments use approximation demonstrate
FODDs used solve problems least complexity currently employed
IPC.
Another important body work pursued Relational Reinforcement Learning
(RRL) (Tadepalli, Givan, & Driessens, 2004) techniques reinforcement learning
used learn construct value functions policies relational domains. RRL
followed seminal work Dzeroski, De Raedt, Driessens (2001) whose algorithm involved generating state-value pairs state space exploration (biased favor
state-action pairs high estimated value) learning relational value function tree
collected data. sense First-Order decision trees used Dzeroski et al.
(2001) similar FODDs. However, important difference semantics
representations strong implications computational properties.
trees employ semantics based traversal single path, FODD semantics based
aggregating values generated traversal multiple paths. previously argued
(Wang et al., 2008) FODD semantics much better suited dynamic programming solutions. several approaches RRL recent years showing nice
performance (for example, Driessens & Dzeroski, 2004; Kersting & De Raedt, 2004; Walker,
5. discussed Sanner Boutilier (2009) hard characterize exact relationship
FOADDs FODDs terms representation computational properties. anonymous reviewer
kindly provided following example shows cases FODDs might compact
FOADDs. Consider domain n unary predicates A1 (), . . . , () capturing object properties
consider formula x, A1 (x) Xor A2 (x) Xor . . . Xor (x) n odd. formula requires
exists object odd number properties Ai () hold. Due restriction
use connectives And, Not, FOADDs must rewrite formula way yields
representation (for example DNF form) whose size exponential number predicates.
hand, one represent formula linear size FODD, similar representation
parity functions propositional BDDs.

262

fiProbabilistic Planning FODD

Torrey, Shavlik, & Maclin, 2007; Croonenborghs, Ramon, Blockeel, & Bruynooghe, 2007)
although applied problems smaller scale ones IPC.
excellent overview various solutions methods RMDPs provided van Otterlo
(2008).

8. Conclusion Future Work
main contribution paper introduction FODD-Planner, relational
planning system based First Order Decision Diagrams. first planning system
uses lifted algebraic decision diagrams representation language successfully
solves planning problems international planning competition. FODD-Planner
provides several improvements previous work FODDs (Wang et al., 2008). improvements include reduction operators R10, R11 Sub-apart operator, several
speedup value approximation techniques. Taken together, improvements provide substantial speedup making approach practical. Therefore, results show
abstraction compact representation promising approach stochastic planning.
work raises many questions concerning foundations FODDs application solve RMDPs. first question reductions. set reductions
still heuristic guarantee canonical form diagrams instrumental
efficiency propositional algorithms. Identifying complete sets reductions
operators canonical forms interesting challenge. Identifying practically good
set operators trading complexity reduction power crucial applicability. recent work (Joshi, Kersting, & Khardon, 2010) developed practical variants
model-checking reductions (Joshi et al., 2009) demonstrating significant speedup
system presented here. Another improvement may possible using FODD based
policy iteration algorithm (Wang & Khardon, 2007). may allow us avoid approximation infinite size value functions cases policy still compact. Another
direction use expressive GFODDs (Joshi et al., 2009) handle arbitrary quantification therefore applied widely. Finally work suggests
potential using FODDs underlying representation relational reinforcement
learning. Therefore, interesting develop learning algorithms FODDs.

Acknowledgments
work partly supported NSF grants IIS 0936687 IIS 0964457. Saket Joshi
additionally supported Computing Innovation Postdoctoral Fellowship.
experiments reported paper performed Tufts Linux Research
Cluster supported Tufts UIT Research Computing. thank Kristian Kersting
valuable input system insightful discussions.

References
Bahar, R., Frohm, E., Gaona, C., Hachtel, G., Macii, E., Pardo, A., & Somenzi, F. (1993).
Algebraic decision diagrams applications. IEEE /ACM ICCAD, pp.
188191.
263

fiJoshi & Khardon

Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.
Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90(1-2), 279298.
Blum, A., & Langford, J. (1998). Probabilistic planning graphplan framework.
Proceedings Fifth European Conference Planning, pp. 812.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129,
533.
Boutilier, C., Dean, T., & Hanks, S. (1999a). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research, 11,
194.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1999b). Stochastic dynamic programming
factored representations. Artificial Intelligence, 121, 49107.
Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming First-Order
MDPs. Proceedings International Joint Conference Artificial Intelligence,
pp. 690700.
Croonenborghs, T., Ramon, J., Blockeel, H., & Bruynooghe, M. (2007). Online learning
exploiting relational models reinforcement learning. Proceedings
International Joint Conference Artificial Intelligence, pp. 726731.
Driessens, K., & Dzeroski, S. (2004). Integrating guidance relational reinforcement
learning. Machine Learning, 57, 271304.
Dzeroski, S., De Raedt, L., & Driessens, K. (2001). Relational reinforcement learning.
Machine Learning, 43, 752.
Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration policy language
bias. Journal Artificial Intelligence Research, 25(1), 75118.
Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2(3-4), 189208.
Gardiol, N., & Kaelbling, L. (2003). Envelope-based planning relational MDPs. Proceedings International Conference Neural Information Processing Systems,
pp. 10401046.
Gretton, C., & Thiebaux, S. (2004). Exploiting First-Order regression inductive policy
selection. Proceedings Workshop Uncertainty Artificial Intelligence.
Groote, J., & Tveretina, O. (2003). Binary decision diagrams First-Order predicate
logic. Journal Logic Algebraic Programming, 57, 122.
Guestrin, C., Koller, D., Gearhart, C., & Kanodia, N. (2003a). Generalizing plans new
environments relational MDPs. Proceedings International Joint Conference
Artificial Intelligence, pp. 10031010.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003b). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.
264

fiProbabilistic Planning FODD

Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using decision diagrams. Proceedings Workshop Uncertainty Artificial
Intelligence, pp. 279288.
Holldobler, S., Karabaev, E., & Skvortsova, O. (2006). FluCaP: heuristic search planner
First-Order MDPs. Journal Artificial Intelligence Research, 27, 419439.
Howard, R. (1960). Dynamic Programming Markov Processes. MIT Press.
Joshi, S., Kersting, K., & Khardon, R. (2009). Generalized First-Order decision diagrams
First-Order Markov decision processes. Proceedings International Joint
Conference Artificial Intelligence, pp. 19161921.
Joshi, S., Kersting, K., & Khardon, R. (2010). Self-Taught decision theoretic planning
First-Order decision diagrams. Proceedings International Conference
Automated Planning Scheduling, pp. 8996.
Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic,
stochastic search. Proceedings National Conference American Association Artificial Intelligence, pp. 11941201.
Kearns, M., & Koller, D. (1999). Efficient reinforcement learning factored MDPs.
Proceedings International Joint Conference Artificial Intelligence, pp. 740
747.
Kersting, K., & De Raedt, L. (2004). Logical Markov decision programs convergence
logical TD(). Proceedings Inductive Logic Programming, pp. 180197.
Kersting, K., van Otterlo, M., & De Raedt, L. (2004). Bellman goes relational. Proceedings
International Conference Machine Learning, pp. 465472.
Khardon, R. (1999). Learning function free Horn expressions. Machine Learning, 37 (3),
249275.
Little, I., & Thibaux, S. (2007). Probabilistic planning vs. replanning. Proceedings
ICAPS Workshop IPC: Past, Present Future.
Lloyd, J. (1987). Foundations Logic Programming. Springer Verlag. Second Edition.
Majercik, S., & Littman, M. (2003). Contingent planning uncertainty via stochastic
satisfiability. Artificial Intelligence, 147 (1-2), 119162.
Mausam, & Weld, D. (2003). Solving relational MDPs First-Order machine learning.
Proceedings ICAPS Workshop Planning Uncertainty Incomplete
Information.
Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order planner
ADL. Principles Knowledge Representation Reasoning, pp. 103114.
Puterman, M. L. (1994). Markov decision processes: Discrete stochastic dynamic programming. Wiley.
Sanner, S., & Boutilier, C. (2009). Practical solution techniques First-Order MDPs.
Artificial Intelligence, 173, 748788.
265

fiJoshi & Khardon

St-Aubin, R., Hoey, J., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. Proceedings International Conference Neural
Information Processing Systems, pp. 10891095.
Tadepalli, P., Givan, R., & Driessens, K. (2004). Relational reinforcement learning:
overview. Proceedings International Conference Machine Learning 04
Workshop Relational Reinforcement Learning.
Teichteil-Koenigsbuch, F., Infantes, G., & Kuter, U. (2008). RFF: robust FF-based MDP
planning algorithm generating policies low probability failure. Sixth
IPC ICAPS.
van Otterlo, M. (2008). logic Adaptive behavior: Knowledge representation
algorithms adaptive sequential decision making uncertainty First-Order
relational domains. IOS Press.
Walker, T., Torrey, L., Shavlik, J., & Maclin, R. (2007). Building relational world models
reinforcement learning. Proceedings Inductive Logic Programming, pp. 280291.
Wang, C. (2007). First-Order Markov decision processes. Ph.D. thesis, Tufts University.
Wang, C., Joshi, S., & Khardon, R. (2008). First-Order decision diagrams relational
MDPs. Journal Artificial Intelligence Research, 31, 431472.
Wang, C., & Khardon, R. (2007). Policy iteration relational MDPs. Proceedings
Workshop Uncertainty Artificial Intelligence, pp. 408415.
Weld, D., Anderson, C., & Smith, D. (1998). Extending graphplan handle uncertainty
sensing actions. Proceedings National Conference Artificial Intelligence.
Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning.
Proceedings International Conference Automated Planning Scheduling,
pp. 352359.
Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic track
international planning competition. Journal Artificial Intelligence Research,
24 (1), 851887.

266

fiJournal Artificial Intelligence Research 41 (2011) 407-444

Submitted 02/11; published 07/11

Efficient Multi-Start Strategies Local Search Algorithms
Andras Gyorgy

gya@szit.bme.hu

Machine Learning Research Group
Computer Automation Research Institute
Hungarian Academy Sciences
1111 Budapest, Hungary

Levente Kocsis

kocsis@sztaki.hu

Data Mining Web Search Research Group, Informatics Laboratory
Computer Automation Research Institute
Hungarian Academy Sciences
1111 Budapest, Hungary

Abstract
Local search algorithms applied optimization problems often suffer getting
trapped local optimum. common solution deficiency restart
algorithm progress observed. Alternatively, one start multiple instances
local search algorithm, allocate computational resources (in particular, processing
time) instances depending behavior. Hence, multi-start strategy
decide (dynamically) allocate additional resources particular instance
start new instances. paper propose multi-start strategies motivated
works multi-armed bandit problems Lipschitz optimization unknown
constant. strategies continuously estimate potential performance algorithm
instance supposing convergence rate local search algorithm unknown
constant, every phase allocate resources instances could converge
optimum particular range constant. Asymptotic bounds given
performance strategies. particular, prove quadratic increase
number times target function evaluated needed achieve performance
local search algorithm started attraction region optimum. Experiments
provided using SPSA (Simultaneous Perturbation Stochastic Approximation) kmeans local search algorithms, results indicate proposed strategies work
well practice, and, cases studied, need logarithmically evaluations
target function opposed theoretically suggested quadratic increase.

1. Introduction
Local search algorithms applied optimization problems often suffer getting trapped
local optimum. Moreover, local search algorithms guaranteed converge
global optimum conditions (such Simulated Annealing Simultaneous
Perturbation Stochastic Approximation, SPSA, see, e.g., Spall, Hill, & Stark, 2006), usually
converge slow pace conditions satisfied. hand,
algorithms employed aggressive settings, much faster convergence local
optima achievable, guarantee find global optimum. common soluc
2011
AI Access Foundation. rights reserved.

fiGyorgy & Kocsis

tion escape local optimum restart algorithm progress observed
(see e.g., Mart, Moreno-Vega, & Duarte, 2010; Zabinsky, Bulger, & Khompatraporn, 2010,
references therein).
Alternatively, one start multiple instances local search algorithm, allocate
computational resources, particular, processing time, instances depending
behavior. Instances started time, number instances may grow
time depending allocation strategy. (see, e.g., Chapter 10 Battiti, Brunato, &
Mascia, 2008 references therein). type problems computational cost
usually measured total number steps made search algorithm instances:
often reflects situation evaluation target function optimized
expensive, costs related determine algorithms use next negligible
compared former (e.g., clearly case task tune parameters
system whose performance tested via lengthy experiments, see, e.g., BartzBeielstein, 2006; Hutter, Hoos, Leyton-Brown, & Stutzle, 2009). paper address
problem dynamically starting several instances local search algorithms
allocating resources instances based (potential) performance.
knowledge, solutions problem either based heuristics
assumption local optima search algorithms converge
extreme value distribution (see Section 2 below). paper, propose new multi-start
strategies mild conditions target function, attractive theoretical
practical properties: Supposing convergence rate local search algorithms
unknown constant, strategies continuously estimate potential performance
algorithm instance every phase allocate resources instances could
converge optimum particular range constant. selection mechanism
analogous DIRECT algorithm (Jones, Perttunen, & Stuckman, 1993; Finkel &
Kelley, 2004; Horn, 2006) optimizing Lipschitz-functions unknown constant,
preference given rectangles may contain global optimum. optimum
within rectangle estimated optimistic way, estimate depends
size rectangle. strategies use function describing convergence rate
local search algorithms similar way size rectangles used
DIRECT algorithm.
Since proposed multi-start strategies potential performance local search
algorithm continuously estimated currently best value target function
returned algorithm, method restricted work local search algorithms
return best known value target function step. case,
example, certain meta-learning problems, goal find good parameter
setting learning algorithm. search space parameter space learning
algorithm, one step local search methods means running learning algorithm
completely possibly large data set. hand, local search algorithm
sort gradient search optimizing error function training data,
value target function usually available case batch learning
(potentially cheap computations), gradient estimated
samples.
rest paper organized follows. Section 2 summarizes related research.
problem defined formally Section 3. new multi-start local search strategies
408

fiEfficient Multi-Start Strategies Local Search Algorithms

paper described analyzed Section 4: Section 4.1 deal selection
mechanism among fixed number instances local search algorithm, while,
addition, simple schedules starting new instances also considered Section 4.2,
natural extensions case finitely many local search algorithm instances.
section concludes discussion results Section 4.3. Simulation results
real synthetic data provided Section 5. Conclusions future work
described Section 6.

2. Related Work
problem allocating resources among several instances search algorithms
comfortably handled generalized version maximum K-armed bandit problem.
original version problem consists several rounds, round one
chooses one K arms, receives reward depending choice, goal
maximizing highest reward received several rounds. model easily used
problem considering local search algorithm instance arm: pulling
arm means taking one additional step corresponding algorithm, is, evaluating
target function point suggested algorithm, reward received
value target function sampled point. generic algorithm standard
maximum K-armed bandit problem, reward assumed independent
identical distribution, provided Adam (2001), so-called reservation price
instance introduced, gives maximum amount resources worth spend
instance: instance achieves reservation price, useless select again.
computation reservation price depends model algorithm
learnt specific constraints.
consider scenario several instances some, possibly randomized local
search algorithms run goal maximizing expected performance. instance run terminates. scenario natural assume
values returned instances (usually local optima target function) independent. Furthermore, since good search algorithms follow (usually heuristic)
procedures yield substantially better results pure random guessing, Cicirello
Smith (2004, 2005) suggested rewards (evaluated target function values)
search instances may viewed maximum many random variables (if instances run sufficiently long time), hence may modeled extreme value
distributions. Several algorithms based assumption, hence developed
maximum K-armed bandit problem returns following generalized extreme value
distributions: Cicirello Smith apply (somewhat heuristic) methods use
extreme-value-distribution assumption decision point meta-learning algorithm,
Streeter Smith (2006a) use model obtain upper confidence bounds
performance estimate type algorithms used try algorithms
best expected result. latter theoretically justified example natural
strategy probe algorithm instances while, estimate future performance
based results trial phase, use promising algorithm
time remaining. Streeter Smith (2006b) proposed distribution free approach
409

fiGyorgy & Kocsis

combines multi-armed bandit exploration strategy heuristic selection among
available arms.
standard maximum K-armed bandit problem rewards round
assumed independent, clearly case situation
algorithm instances run parallel reward evaluating target function
point improvement upon current maximum, since samples chosen local
search algorithm usually depend previous samples. Nevertheless, ideas lessons
learnt maximum K-armed bandit problems used case, well:
example, algorithm Threshold Ascent Streeter Smith (2006b) gives reasonably
good solutions case, principle probing instances using
promising time remaining also carries situation easily:
algorithms, first exploration exploitation phase, referred
sequel explore-and-exploit algorithms. class algorithms, simple rules
suggested Beck Freuder (2004) predict future performance algorithm,
Carchrae Beck (2004) employ Bayesian prediction.
Another related problem find fast algorithms among several ones solve
problem. precisely, several algorithm instances available produce
correct answer certain question run sufficiently long time. time needed
algorithm instance find answer assumed random quantity
independent identical distributions instances, goal combine
given algorithms minimize expected running time answer found.
distribution running time known, optimal non-adaptive time-allocation strategy1
perform sequence runs certain cut-off time depends distribution
(Luby, Sinclair, & Zuckerman, 1993). distribution unknown, particular running
time sequence chosen results expected total running time
logarithmic factor larger optimum achievable distribution known. note
strategy among provide schedule increases number
algorithm instances. set-up specialized problem: goal find
-optimal approximation optimum running time number steps
needed given search algorithm achieve approximation. Note
case running time algorithm instance providing -suboptimal solution
defined infinity, results Luby et al. remain valid -optimal solution
found positive probability. problem, Kautz, Horvitz, Ruan,
Gomes, Selman (2002) proposed allocation strategy based updating dynamically
belief run-time distribution. Concerning latter, Hoos Stutzle (1999)
found empirically run-time distributions approximately exponential certain (NPhard) problems, Ribeiro, Rosseti, Vallejos (2009) dealt comparison
different run-time distributions.
Finally, set time allocation strategies available optimization problem solved several times, one use standard multi-armed bandit framework
done Gagliolo Schmidhuber (2006, 2007, 2010).
Running several instances algorithm several algorithms parallel selecting
among algorithms intensively studied, example, area meta1. non-adaptive time-allocation strategy running time algorithm instance fixed advance,
is, measured performance algorithm instances effect schedule.

410

fiEfficient Multi-Start Strategies Local Search Algorithms

learning (Vilalta & Drissi, 2002) automatic algorithm configuration (Hutter et al., 2009).
underlying problem similar cases: automatic algorithm configuration
usually refers tuning search algorithms, meta-learning used subset
problems, tuning machine learning algorithms (the latter often allows specific use
data). main problem allocate time slices particular algorithms
aim maximizing best result returned. allocation may depend intermediate
performance algorithms. automatic algorithm configuration metalearning systems use various heuristics explore space algorithms parameters
(see, e.g., Hutter et al., 2009).
Finally, important note that, although multi-start local search strategies solve
global optimization problems, concentrate maximizing performance given
underlying family local optimization methods. Since choice latter major
effect achievable performance, compare results vast literature
global optimization.

3. Preliminaries
Assume wish maximize real valued function f d-dimensional unit hypercube
[0, 1]d , is, goal find maximizer x [0, 1]d f (x ) = f
f = max f (x)
x[0,1]d

denotes maximum f [0, 1]d . simplicity, assume f continuous
[0, 1]d .2 continuity f implies existence x , and, particular, f bounded.
Therefore, without loss generality, assume f non-negative.
form f known explicitly, search algorithms usually evaluate f several
locations return estimate x f based observations.
obvious trade-off number samples used (i.e., number points
target function f evaluated) quality estimate, performance
search strategy may measured accuracy achieves estimating f
constraint number samples used.
Given local search algorithm A, general strategy finding good approximation
optimum x run several instances initialized different starting points
approximate f maximum f value observed. concentrate local search
algorithms defined formally sequence possibly randomized sampling functions
sn : [0, 1]dn [0, 1]d , n = 1, 2, . . .: evaluates f locations X1 , X2 , . . . Xi+1 =
si (X1 , . . . , Xi ) 1, starting point X1 = s0 chosen uniformly random
[0, 1]d ; n observations returns estimate x maximum f , respectively,

bn = argmax f (Xk )
bn ).
X

f (X
1kn1

ties argmax function may broken arbitrarily, is, samples Xk
bn chosen them. avoid ambiguity
achieve maximum, X
2. results easily extended (arbitrary valued) bounded piecewise continuous functions
finitely many continuous components.

411

fiGyorgy & Kocsis

simplify notation, following, unless stated explicitly otherwise, adopt
convention use argmax denote maximizing sample smallest index,
results remain valid choice break ties.
simplicity, consider starting single local search algorithm different
random points, although results work extended allow varying
parameters (including situation running different local search algorithms,
parameter would choose actually employed search algorithm); well allow
dependence among initializations (that is, starting point parameters
local search instance may depend information previously obtained target
function).
clear starting points sampled uniformly [0, 1]d algorithm
bn ) converges
evaluated starting point strategy consistent, is, f (X
maximum f probability 1 number instances tends infinity (in
worst case perform random search known converge maximum almost
surely). hand, algorithm favorable properties possible
design multi-start strategies still keep random search based consistency,
provide much faster convergence optimum terms number evaluations
f.
bn ) bounded non-decreasing, converges (no matter
Since sequence f (X
random effects occur search). next lemma, proved Appendix A, shows
that, high probability, convergence cannot arbitrarily slow.
bn ) = f .3 P (E) > 0,
Lemma 1 f [0, 1]d , let E denote event limn f (X
bn ) f
then, 0 < < 1 event E E 1 P (E ) < f (X
uniformly almost everywhere E . words, exists non-negative, nonincreasing function g (n) limn g (n) = 0


fi
bt ) = f 1 .
b ) f (X
bn ) g (n) nfi lim f (X
P lim f (X
(1)




certain cases, g (n) = O(en ), shown Nesterov (2004) (gradient-based)
optimization convex functions, Gerencser Vago (2001) noise-free SPSA
convex functions, Kieffer (1982) k-means clustering (or Lloyds algorithm) one
dimension log-concave densities. results pertain simple situation
one local optimum global one, many results
extended general situations, observed exponential rate convergence
experiments functions many local maxima.
convergence property local search algorithms guaranteed Lemma 1
exploited next section derive efficient multi-start search strategies.

4. Multi-Start Search Strategies
Standard multi-start search strategies run instance seems converge
location hope beat currently best approximation f .
3. practice usually assume local search algorithms converge local optima, f may
assumed local optimum.

412

fiEfficient Multi-Start Strategies Local Search Algorithms

alternative way using multiple instances local search algorithms run algorithms
parallel, round decide algorithms take extra step. approach
may based estimating potential performance local search algorithm based
Lemma 1. Note g known, obvious way would run instance
possible performances become separated high probability sense
margin performance actually best second best algorithm
large actually best algorithm guaranteed best, long run,
high probability. could pick best instance run given
computational budget exhausted (this would simple adaptation explore-andexploit idea choosing best algorithm based trial phase Beck & Freuder,
2004; Carchrae & Beck, 2004).
practice, however, g usually known, certain problem classes local
search algorithms may known belong function class, example, g may
known (multiplicative) constant factor (here, example, constant may
depend certain characteristics f , maximum local steepness). Even
latter case, best instance still cannot selected high probability matter
large margin (as g may arbitrarily large). However, using ideas general
methodology Lipschitz optimization unknown constant (Jones et al., 1993),
get around problem estimate, certain optimistic way, potential
performance algorithm instance, round step promising
ones.
main idea resulting strategy summarized follows. Assume
K instances algorithm A, denoted A1 , . . . , AK . Let Xi,n , = 1, . . . , K denote
location f evaluated Ai nth time take step, Xi,1
starting point Ai . estimate location maximum algorithm Ai n
samples (steps)
bi,n = argmax f (Xi,t )
X
1tn

bi,n ).
maximum value function estimated fi,n = f (X
i, let fi = limn fi,n denote limiting estimate maximum f
provided Ai . Let g defined Lemma 1 largest values,
f = max fi .
i=1,...,K

Since f best achievable estimate maximum f given actual algorithms
A1 , . . . , AK , g gives high probability convergence rate algorithms provide
best estimate maximum long run (note assumption deals
limiting estimate usually local maximum separately, is, assumption
made algorithms whose limiting estimates less f ). Then, Ai evaluates f
ni,r points end rth round Ai converges best achievable estimate
f , Lemma 1 have, probability least 1 ,
fi fi,ni,r g (ni,r ),


fi,ni,r + g (ni,r )
413

(2)

fiGyorgy & Kocsis

optimistic estimate f . Ai suboptimal sense limn fi,n < f
estimate still optimistic rate convergence slower g ,
pessimistic rate convergence slower g . latter desirable sense
negatively biased estimate expected performance algorithm
want use (we waste samples suboptimal choices).
practice g usually known exactly, estimate (2) often cannot constructed. hand, g known constant factor construct
family estimates scales: Let g denote normalized version g
g (0) = 1 g (n)/g (n) constant n, construct family estimates
fi,ni,r + cg (ni,r )

(3)

c ranges positive reals. reasonable choose, round,
algorithms take another step provide largest estimate values c
(typically, algorithm gives largest estimate c = c interval
containing c algorithm provides largest estimate c I).
way get around fact know real scaling factor g ,
certainly use algorithms provide largest value (3) c = g (1)/g (1),
and, discussed later, waste many samples algorithms
maximize (3) values c. Using optimistic estimate (3) similar, spirit,
optimistic estimates standard upper confidence bound-type solution
multi-armed bandit problem (Auer, Cesa-Bianchi, & Fischer, 2002) well-known
search algorithm (Hart, Nilsson, & Raphael, 1968).
However, exact (local) convergence rate known, even constant factor,
many local search algorithms, even is, corresponding bounds usually
meaningful asymptotic regime, often practical interest. Therefore,
give freedom design algorithm, going use estimate
form
fi,ni,r + ch(ni,r )
(4)
where, similarly requirements g , h positive, monotone decreasing function
limn h(n) = 0. also assume, without loss generality, h(0) = 1.
actual form h based theoretical analysis resulting algorithms
heuristic considerations. Essentially use h functions converge zero
exponentially fast, agreement exponentially fast local convergence rates
examples given Lemma 1. optimal choice h, given, example, g ,
known, left future work.
4.1 Constant Number Instances
idea translated algorithm MetaMax(K) shown Figure 1.
consider case fixed number instances, goal perform
(almost) well best (in hindsight), using minimum number
br
evaluations f . Note slight abuse notation MetaMax(K) algorithm X
fr denote estimates algorithm r rounds (and r steps/samples).
first part step (a) MetaMax sweep positive c select local
search algorithms maximize estimate (4). easy see, Ai maximizes
414

fiEfficient Multi-Start Strategies Local Search Algorithms

MetaMax(K): multi-start strategy K algorithm
instances.
Parameters: K > 0 positive, monotone decreasing function h
limn h(n) = 0.
Initialization: = 1, . . . , K, take step algorithm Ai
once, let ni,0 = 1 fi,0 = f (Xi,1 ).
round r = 1, 2, . . .
(a) = 1, . . . , K select algorithm Ai exists c > 0
fi,ni,r1 + ch(ni,r1 ) > fj,nj,r1 + ch(nj,r1 )

(5)

j = 1, . . . , K (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).
several values selected step number
ni,r1 keep one selected uniformly random.
(b) Step selected Ai , update variables. is, set ni,r =
ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.
bi,n
selected Ai evaluate f (Xi,ni,r ) compute new estimates X
i,r
fi,ni,r .
(c) Let Ir = argmaxi=1,...,K fi,ni,r denote index algorithm
currently largest estimate f , estimate location
br = X
bIr ,n
maximum X
value fr = fIr ,nIr ,r .
Ir ,r
Figure 1: MetaMax(K) algorithm.
(4) particular c = u closed interval containing u Ai also
maximizes (4) c I. Therefore, round, strategy MetaMax(K) selects
local search algorithms Ai corresponding point (h(ni,r1 ), fi,ni,r1 )
corner upper convex hull set
Pr = {(h(nj,r1 ), fj,nj,r1 ) : j = 1, . . . , K} {(0, max fj,nj,r1 )}.
1jK

(6)

selection mechanism illustrated Figure 2.
avoid confusion, note random selection step (a) MetaMax(K) implies
algorithms exactly state, is, (ni,r1 , fi,ni,r1 ) = (nj,r1 , fj,nj,r1 )
i, j, one algorithm selected uniformly random (this pathological situation
may arise, e.g., beginning algorithm local search algorithms give
estimate f range step numbers). Apart case one
least used algorithms provides currently best estimate, happens surely
first round usually happen later (and includes previous pathological case),
guaranteed round use least two algorithms, one largest
415

fiGyorgy & Kocsis

0.7

0.6

f(x)

0.5

0.4

0.3

0.2

0.1

0
0.2

0.3

0.4

0.5

h(n)

0.6

0.7

0.8

0.9

Figure 2: Selecting algorithm instances MetaMax: points represent algorithm
instances, algorithms lie corners upper convex hull
(drawn blue lines) selected.

estimate fi,ni,r1 = fr1 (for small values c), one smallest step number
nj,r1 (for large values c). Thus, usually half total number function
calls f used optimal local search algorithm. observation gives practical lower bound (which valid apart pathological situation mentioned above)
proportion function calls f made optimal local search algorithms; surprisingly,
Theorem 6 shows lower bound achieved algorithm asymptotically.
randomization step (a) precludes using multiple instances
step number introduced speed algorithm certain pathological cases.
example, A1 converges correct estimate, algorithms A2 , . . . , AK
produce estimate round, independently samples, inferior
estimates A1 , use randomization, half calls compute f
made A1 , without randomization would drop 1/K
round would use algorithm. Furthermore, could take step algorithms
lie convex hull, similar pathological examples constructed
beneficial use algorithms corners. hand, almost never
happens practice three algorithms lie line, algorithms typically
never fall non-corner points convex hull.
remainder section analyze performance MetaMax(K)
algorithm. Proposition 2 shows algorithm consistent sense performance asymptotically achieves best algorithm instance number rounds
increases. understand algorithm better, Lemma 3 provides general sufficient condition algorithm instance advanced given round, while, based
result, Lemma 4 provides conditions ensure suboptimal algorithm instances
used round stepped many times (i.e., evaluated f
many points) before. Lemma 5 gives upper bound number algorithm
416

fiEfficient Multi-Start Strategies Local Search Algorithms

instances used round. results lemmas used show Theorems 6
8 Remark 9 optimal algorithm instances used (asymptotically) least
minimum frequency that, turn, yields asymptotic rate convergence
MetaMax(K) algorithm.
following proposition shows MetaMax(K) algorithm consistent
sense:
Proposition 2 MetaMax(K) algorithm consistent sense fr f
r,

n
f lim fi,n .
f lim fr = min
r

i=1,...,K

n

Proof proof follows trivially fact algorithm selected infinitely
often, is, limr ni,r = . see latter, show every K rounds
number steps taken least used algorithm, is, mini=1,...,K ni,r , guaranteed
increase one. is, k 0,
min ni,kK k.

i=1,...,K

(7)

described above, round select exactly one algorithms made
least number steps. Thus, K algorithms, minimum step number
per algorithm increase K rounds, completes proof.
2
MetaMax(K) algorithm efficient suboptimal algorithms step
often. next lemma provides sufficient conditions algorithm used
given round.
Lemma 3 algorithm instance Aj used round r + 1 MetaMax(K)
algorithm, algorithms Ai Ak fi,ni,r > fj,nj,r > fk,nk,r either
ni,r nj,r


h(nj,r )
h(nj,r )


fj,nj,r fi,ni,r 1
(8)
+ fk,nk,r
h(nk,r )
h(nk,r )
Proof round algorithms corners convex hull Pr+1 used,
easy see algorithm Aj used round r algorithms Ai
Ak fi,ni,r > fj,nj,r > fk,nk,r either ni,r nj,r
fi,ni,r fk,nk,r
fi,ni,r fj,nj,r

.
h(nj,r ) h(ni,r )
h(nk,r ) h(ni,r )

(9)

finish proof show (8) implies latter. Indeed, (9) equivalent
h(nk,r )(fi,ni,r fj,nj,r ) h(nj,r )(fi,ni,r fk,nk,r ) + h(ni,r )(fk,nk,r fj,nj,r ).
last term right hand side inequality negative assumptions,
inequality satisfied
h(nk,r )(fi,ni,r fj,nj,r ) h(nj,r )(fi,ni,r fk,nk,r )
417

fiGyorgy & Kocsis

equivalent (8).

2

lemma provides conditions using algorithm instances certain
round depend actual performance instances. next result gives similar
conditions, however, based best estimates (usually local optima) achievable
algorithms. Let fi = limr fi,ni,r asymptotic estimate algorithm Ai f ,
let f = max1iK fi denote best estimate achievable using algorithms A1 , . . . , AK .
Let {1, . . . , K} set optimal algorithms converge best estimate
f (for algorithms), let |O| denote cardinality (i.e., number
optimal algorithm instances). Note random variable depends actual
realizations possibly randomized search sequences algorithms. next lemma
shows j 6 O, Aj used round r used often far.
Lemma 4 Let

= f max fj
j6O

denote margin estimates best second best algorithms.
0 < u < random index R(u) > 0 j 6 O, Aj
used MetaMax(K) round r + 1 > R(u)
!!



f
j
min ni,r
1
nj,r h1 h
.
(10)
i=1,...,K
f u
Furthermore, let 0 < < 1, O, let g,i denote convergence rate algorithm
Ai guaranteed Lemma 1, let g (n) = maxiO g,i (n) n. P (R(u)
) 1 (where g 1 generalized inverse g ), suboptimal
Kg1 (u)|f1 , . . . , fK


algorithm Aj , j 6 O, used r > Kg1 (u) probability least 1 |O| given
.
limiting estimates f1 , . . . , fK
Proof Let O. Since limn fi,n = fi = f assumption (7) implies
(u)
limr ni,r = , almost surely finite random index Ri > 0
(u)

r > Ri f fi,n
u
i,r
f fr u.

(11)

Using Lemma 1 easily derive high probability upper bound R(u) . Since
r > Kg1 (u) = R , (7) implies ni,r g1 (u), Lemma 1 yields


fi
P fi fi,ni,r u r > R fi fi = f 1 .

follows probability least 1 |O| fi fi,ni,r u,
) |O| . Thus,
implies R(u) chosen P (R(u) > R |f1 , . . . , fK
prove lemma, enough show (10).
Clearly, (11), algorithm pick estimate one best algorithms
R(u) rounds. Let Ak algorithm least number steps taken end
418

fiEfficient Multi-Start Strategies Local Search Algorithms

round r, is, nk,r = mini ni,r . fk,nk,r fj,nj,r Aj used round r + 1.
Moreover, since Aj 6 O, fj,nj,r fj < fr case Aj used round r + 1
nj,r nIr ,r (recall nIr ,r number evaluations f initiated actually
best algorithm Ir ). Therefore, Lemma 3 implies Aj used r > R()
!
fj,nj,r fk,nk,r
h(nj,r ) h(nk,r ) 1
.
fr fk,n
k,r

clearly satisfied
h(nj,r ) h(min ni,r ) 1


fj
f u

!

(12)

0 < u < , since (11)
1

fj
fj,nj,r fk,nk,r
fj,nj,r
1
.
1
fr fk,nk,r
fr
f u

Applying inverse h sides (12) proves (10), and, hence, lemma.

2

result provides individual condition suboptimal algorithm
used round. hand, one optimal algorithms
stepped sufficiently many times, give cumulative upper bound number
suboptimal algorithms used round.
Lemma 5 Assume h decreases asymptotically least exponentially fast, is,
exist 0 < < 1 n > 0 h(n+1)
h(n) < n > n . Assume r large
enough ni,r > n i, let r = 1 maxi:fi,n

6=fr
i,r

fi,ni,r
fr

> 0.

r
ln
ln + 1 algorithms stepped round r + 1, x denotes smallest integer
least large x.

Proof Let i0 , i1 , . . . , im denote indices algorithms chosen round r + 1
fi0 ,r < fi1 ,r < < fim ,r = fr . Lemma 3 implies ni0 ,r < ni1 ,r < < nim ,r
fr fik ,r < (fr fik1 ,r )
k = 1, . . . , 1. Repeated application inequality implies
fr r fr fim1 ,r < (fr fim2 ,r ) < < m1 (fr fi0 ,r ) fr m1
yields

ln r
ln
assumed + 1 algorithms chosen round r + 1, fact finishes
proof.
2
m1<

419

fiGyorgy & Kocsis

Based Lemmas 4 5, next theorem shows local search algorithm
converges fast enough (exponentially problem dependent rate, faster exponential) half function calls evaluate f correspond optimal algorithm
instances.
Theorem 6 Assume performance algorithms Ai , = 1, . . . , K
same, is, |O| < K, suppose
(
)
fj
h(n + 1)
lim sup
.
(13)
< min 1
j6O
h(n)
n
f
asymptotically least half function
respond optimal algorithm. is,
P
ni,r
1
P lim inf PiO

K
r
2
i=1 ni,r

calls evaluate f MetaMax(K) cor!
fi
fi

fi f1 , . . . , fK
= 1.
fi

Furthermore, 0 < < 1 > 0 constant R(,) > 0
$P
%!
K
n
i=1 i,r
f fr g
(2 + )|O|

(14)

(15)

simultaneously r > R(,) ,
probability least 1 |O| given f1 , . . . , fK
(,)
g defined Lemma 4, threshold R
> 0 depends , , h, g1 ,
1
g also defined Lemma 4.

Proof show suboptimal Aj chosen large enough r nj,r > mink nk,r .
Lemma 4, sufficient prove that, large enough r,
!!
fj
1
(16)
min nk,r + 1 h
h(min nk,r ) 1
k
k
f u
0 < u < (recall r larger R(u) , almost surely finite
random index Lemma 4).
minimum (13) taken finite set, follows exists small
enough positive u <
(
)
fj
h(n + 1)
lim sup
,
(17)
min 1
j6O
h(n)
n
f u
clearly implies (16) limr mink nk,r = (7). fact finishes proof
(14), first part theorem.
Next prove (15). Let Nu > 0 threshold (17) holds n Nu .
Furthermore, Lemma 1 union bound, (1) holds local search algorithm
Ai g,i place g simultaneously probability least 1 |O|.
420

fiEfficient Multi-Start Strategies Local Search Algorithms

(7) slight modification Lemma 4 imply (16) holds simultaneously
.
r > K max{g1 (u), Nu } = R probability least 1 |O| given f1 , . . . , fK
Since
round two algorithms used, r > R + c
P
n
i,r
c+R
PiO
> 2c+KR
high probability. Since latter bounded 1/(2+)
K
n
i,r
i=1
PK
P
ni,r
c R (K2)/, iO ni,r i=1
r > R(,) = R +R (K2)/
2+

l P highmprobability. algorithm Ai , used least
K
i=1

ni,r
|O|(2+)

rounds, implying statement theorem via Lemma 1.

2

Remark 7 proof Theorem 6 based Lemma 4. proof based Lemma 5
also possible, since setting = minj6O (1 fj /f ) lemma, (13) implies that,
large enough r, r , round approximately length 2 lemma.
may happen although decay rate h exponential, quite fast
enough satisfy (13), optimal scenarios theorem hold.
case turns number algorithms converging local maximum
plays key role determining usage frequency optimal algorithms.
Theorem 8 Assume estimates provided algorithms A1 , . . . , AK converge
N > 1 distinct limit points, k0 = |O| algorithms converge f , k1 , k2 , . . . , kN 1
algorithms converge suboptimal limit points, respectively. Suppose furthermore
h decreases asymptotically least exponentially fast, is, 0 < < 1,
lim supn h(n+1)
h(n) < .
P lim inf
r

P

iO ni,r
PK
i=1 ni,r

!
fi
fi
kmax

fi f , . . . , fK = 1.

K k0 + kmax fi 1

kmax = max1iN 1 ki .
Furthermore, using definitions Lemma 4 0 < < 1 > 0
constant threshold R(,)
%!
$
PK
k
n
max
i=1 i,r
f fr cg
(K k0 + kmax + )|O|
simultaneously r > R(,) ,
probability least 1 |O| given f1 , . . . , fK
R(,) depends , .,f1 , . . . , sfK convergence rate algorithms4 .
given, fix random trajectories algorithms.
Proof Suppose f1 , . . . , fK
single suboptimal algorithm statement trivial kmax /(K k0 +kmax ) =
1/2 round least two algorithms used, one
suboptimal one. assume least two suboptimal algorithms.
Assume Aj Ak converge suboptimal local maxima (strictly less f ).
r large enough, optimal algorithm Ai better suboptimal ones,

4. Instead convergence rate algorithms, R(,) may defined dependent g .

421

fiGyorgy & Kocsis

is, Ai converges f fi,ni,r > fj,nj,r , fk,nk,r . Assume, without loss generality,
fj,nj,r fk,nk,r . nj,r nk,r clearly Aj chosen round r + 1. Assume
nj,r > nk,r . Since fj,nj,r fk,nk,r convergent sequences (as r ), large enough
r have, j,k < 1,
1

fj,nj,r fk,nk,r
> j,k tj,k


fi,n fk,n
i,r

(18)

k,r

tj,k = ln j,k / ln positive integer. Note Aj Ak converge
point, is, limr (fj,nj,r fk,nk,r ) = 0, second term left hand side
(18) converges 0, j,k chosen , implying tj,k = 1. Rearranging
inequality one obtains
(1 tj,k )fi,ni,r + tj,k fk,nk,r > fj,nj,r .

(19)

nj nk tj,k , conditions h fact nj,r nk,r tend
infinity r (recall (7)) imply that, large enough r, h(nj,r )/h(nk,r ) < tj,k . Since
fi,ni,r fk,nk,r large enough r, (19) obtain


h(nj,r )
h(nj,r )
tj,k
tj,k

fk,nk,r .
fi,ni,r +
fj,nj,r < (1 )fi,ni,r + fk,nk,r 1
h(nk,r )
h(nk,r )
Thus, Lemma 3, r large enough, Aj cannot used round r + 1 nj,r nk,r tj,k .
Since nj,r nk,r tend infinity, follows that, large enough r,
|nj,r nk,r | tj,k

(20)

two suboptimal algorithms Aj Ak . Note fact also implies
set suboptimal algorithms converging point, eventually one
used round (since corresponding thresholds tj,k = 1).
Clearly, (7) implies nj,r nk,r grow linearly r, since differences bounded (20), limr nj,r /nk,r = 1. Therefore, suboptimal algorithm
Aj , limn nj,r /r 1/kmax (this maximal rate using elements
largest group suboptimal algorithms converging local optimum). Finally,
optimal algorithm used round r, large enough r,
P
P
iO ni,r
iO ni,r
P
lim inf PK
= lim inf P
r
r
n
+
i,r
n
i6O ni,r
iO
i,r
i=1
kmax
r
lim
=
,
r
r r + (K k0 )
K k0 + kmax
kmax
used fact a/(a + b) increasing function a, b > 0. Since
,
inequality holds realizations trajectories A1 , . . . , AK , given f1 , . . . , fK
first statement theorem follows.
second statement follows similarly (15) Theorem 6. Since exact value
R(,) particular interest, derivation omitted.
2

422

fiEfficient Multi-Start Strategies Local Search Algorithms

Remark 9 main message theorem somewhat surprising observation
suboptimal algorithms slowed large group suboptimal algorithms
converging local optimum; rate suboptimal algorithms used bounded
size largest group.
4.2 Unbounded Number Instances
clear local search algorithms consistent (i.e., achieve
global optimum f ), then, despite favorable properties, MetaMax(K) strategy
inconsistent, too. However, increase number algorithms infinity
get consistency random search, still keeping reasonably fast convergence
rate MetaMax(K).
Clearly, one needs balance exploration exploitation, is,
control often introduce new algorithm. One solution let MetaMax
algorithm solve problem: MetaMax() algorithm, given Figure 3, extension MetaMax(K) able run infinitely many local search algorithm
instances. major issue new local search algorithms started
time time (this ensures algorithm converge global maximum f
since also performs random search): implemented modifying step (a)
MetaMax(K) algorithm new, randomly initialized local search algorithm introduced round (randomly selecting one algorithm uniformly infinitely
many possible algorithms used far). Obviously, skip initialization
step MetaMax(K) start algorithm 0 samples. better control
length round (i.e., exploration), round r allow use different
function h, denoted hr1 may depend value measured round r (this
suppressed notation). before, assume hr (0) = 1, hr (n) monotone decreasing n, limn hr (n) = 0 r. Typically make hr1 dependent
PKr1
total number steps (i.e., function calls evaluate f ) tr1 = i=1
ni,r1 made
algorithms round r, Kr1 number algorithm instances used
round r; note Kr1 = r 1 r, start exactly one new algorithm
round.
desired that, although number local search algorithms grows infinity,
number times best local search algorithm advanced MetaMax()
algorithm approaches infinity reasonably fast. Somewhat relaxing random initialization
condition, may imagine situation local search algorithms initialized
clever, deterministic way, first steps find better
value initial guesses. algorithms optimal (this may viewed result
clever initialization), may provide, example, identical estimates
0.5, 0.5, 1 first three steps. easy see algorithm stepped
exactly twice, thus convergence optimum (which would found third
step) achieved. Although random initialization search algorithms guarantees
consistency MetaMax() (see Proposition 10 below), robust behavior even
pathological cases preferred.
achieved slight modification algorithm: round local search
algorithm overtakes currently best algorithm, is, Ir 6= Ir1 , algorithm AIr
423

fiGyorgy & Kocsis

MetaMax(): multi-start strategy infinitely many
algorithm instances.
Parameters: {hr }, set positive, monotone decreasing functions
limn hr (n) = 0.
round r = 1, 2, . . .
(a) Initialize algorithm Ar setting nr,r1 = 0, fr,0 = 0.
(b) = 1, . . . , r select algorithm Ai exists c > 0
fi,ni,r1 + chr1 (ni,r1 ) > fj,nj,r1 + chr1 (nj,r1 )
j = 1, . . . , r (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).
several values selected step number
ni,r1 keep one selected uniformly random.
(c) Step selected Ai , update variables. is, set ni,r =
ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.
bi,n
selected Ai evaluate f (Xi,ni,r ) compute new estimates X
i,r
fi,ni,r .

(d) Let Ir = argmaxi=1,...,r fi,ni,r denote index algorithm
currently largest estimate f , estimate location
br = X
bIr ,n
maximum X
value fr = fIr ,nIr ,r .
Ir ,r
Figure 3: MetaMax() algorithm.

stepped several times used times AIr1 .5 resulting algorithm,
called MetaMax, given Figure 4. Note algorithms MetaMax()
MetaMax conceptually differ one place: step (c) extended step (c)
new algorithm. result, technical modification also appears step (d), and,
simplify presentation MetaMax algorithm, slight, insignificant modification
also introduced step (b), see discussion below.
modification MetaMax really significant practical examples
studied (see Section 5), number steps taken algorithm overtakes
currently best algorithm grows quickly also MetaMax() algorithm, since
MetaMax overtake usually introduces short rounds (close minimum length
two many cases) leading algorithm becomes also used one. goal
modification step (b) synchronize choice optimal algorithms
steps (b) (c). equally good solution would choose, case tie step
5. way achieve actually best algorithm dominates others terms accuracy
number calls made algorithms compute target function. type
dominance used Hutter et al. (2009) slightly different context.

424

fiEfficient Multi-Start Strategies Local Search Algorithms

MetaMax: multi-start strategy infinitely many
algorithm instances.
Parameters: {hr }, set positive, monotone decreasing functions
limn hr (n) = 0.
round r = 1, 2, . . .
(a) Initialize algorithm Ar setting nr,r1 = 0, fr,0 = 0.
(b) = 1, . . . , r select algorithm Ai exists c > 0
fi,ni,r1 + chr1 (ni,r1 ) > fj,nj,r1 + chr1 (nj,r1 )
j = 1, . . . , r (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).
several values selected step number
ni,r1 keep one smallest index.
(c) Step selected Ai , update variables. is, set ni,r =
ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.
bi,n
selected Ai evaluate f (Xi,ni,r ) compute new estimates X
i,r

fi,ni,r .

(c) Let Ir = argmaxi=1,...,r fi,ni,r denote index algorithm
currently largest estimate f (in case Ir unique, choose
one smallest number steps ni,r ). Ir 6= Ir1 , step
algorithm AIr (nIr1 ,r nIr ,r + 1) times set nIr ,r = nIr1 ,r + 1.
br = X
bIr ,n
(d) Estimate location maximum X

Ir ,r
value fr = fIr ,nIr ,r .
Figure 4: MetaMax algorithm.

(c), algorithm used current round. Also note that, result
modifications, currently best algorithm (with index Ir ) taken steps,
extra number steps taken step (c) indeed positive. important consequence
modifications that, round r, number steps taken local search
algorithm AIr , best end round, r 2r (see Theorem 15
below).
rest section devoted theoretical analysis MetaMax()
MetaMax, following lines analysis provided MetaMax(K). First, Proposition 10, shown algorithm consistent, is, solution found
algorithm actually converges f . Lemma 12 (a counterpart Lemma 4) shows
suboptimal algorithms make finitely many steps, Lemma 14 gives upper
bound length round. main theoretical results section apply
425

fiGyorgy & Kocsis

MetaMax algorithm: Theorem 15 gives lower bound number steps taken
actually best algorithm end given round, while, consequence, Theorem 16 shows rate convergence algorithm function total number
steps (i.e., function calls evaluate f ) used algorithm instances: turns
quadratically steps needed generic local search algorithm instance
converges optimum.
Since MetaMax() MetaMax strategies perform random search (the
number algorithms tends infinity length round finite), algorithms
consistent:
Proposition 10 strategies MetaMax() MetaMax consistent.
is,
lim fr = f
r

almost surely.
Proof Clearly, event fr converge f written
n

\
n
[


[
lim fr 6= f =
fr < f 1/n

r

(21)

n=1 R=1 r=R

continuity f implies that, n, X chosen uniformly [0, 1]d
qn P
= P(f (X) > f 1/n) > 0. Thus, round r, P(fr < f 1/n) (1 qn )r ,



r=1 P(fr < f 1/n) finite. Therefore, Borel-Cantelli lemma (see, e.g., Ash &
Doleans-Dade, 2000) implies
!
n
[

\

=0
P
fr < f 1/n
R=1 r=R

n. This, together (21) finishes proof,
P



lim fr 6= f

r








X

n=1

P

n
[
\

R=1 r=R

fr < f 1/n




!

= 0.
2

reminder section assume local search algorithms achieve
almost optimal value eventually converge optimum.
Assumption 11 Let F R denote set local maxima f , let = f
supfF ,f<f f. assume > 0 algorithm Ai fi,n > f
n, limn fi,n = f .
local search algorithms converge local optima (which reasonable assumption
practice), assumption usually satisfied: situation
hold pathological case f infinitely many local maxima set
maxima dense global maximum.
426

fiEfficient Multi-Start Strategies Local Search Algorithms

Assumption 11 prove, similarly Lemma 4, suboptimal algorithm selected limited number times increases h1
r . particular,
hr = h r large enough, suboptimal algorithm chosen finitely many
times.
Lemma 12 Suppose Assumption 11, let q = P(f (X) > f /2) X uniformly
distributed [0, 1]d . Then, MetaMax() MetaMax algorithms,
suboptimal algorithm Aj started round r +1 used round r +1, probability
least 1 (1 q)r ,



1
nj,r hr
.
2f
addition, hr (n) non-decreasing function r n,
lim sup
r

h1
r1

n
j,r



2f

<

almost surely.

(22)

particular, hr constant function, is, hr = h0 r, limr nj,r <
almost surely.
Remark 13 Note second
part lemma coulddrop
monotonicity
1
1


assumption hr replace hr1 2f max0r r1 hr 2f (22).
Proof Consider algorithm Aj used round r + 1. First note probability
least 1 (1 q)r , fr > f /2. Furthermore, newly introduced algorithm, Ar+1
used yet, nr+1,r = 0 fr+1,0 = 0. Thus, Lemma 3, Aj used


h(nj,r )


= fr (1 hr (nj,r )) .
fj,nj,r fr 1
hr (0)
Since equivalent
nj,r

h1
r

fj,nj,r
1
fr

h1
r

fj,nj,r
1
fr

!





h1
r



!

,


2f



fr fj,nj,r

fr (f )
(f /2) (f )
=
,
(23)

>

f /2
2f
fr
fr
first statement proof follows.
b denote first round optimal
prove second part, let R


algorithm Ai fi,ni,Rb > f /2. suboptimal algorithm Aj , first part
b
lemma implies that, r > R,










1
1
b
b
+ 1 = max R, hr1
+1
nj,r max R, max
h
0r r1 r
2f
2f
427

fiGyorgy & Kocsis

equality holds since h1
r (n) non-decreasing r. Thus




b
nj,r
R
1
lim sup max
, 1 +




lim sup



h1

r h1
r
h1
r1 2f
r1 2f
r1 2f




b
1
R
, 1 +



max



h1
h1
0

0

2f

(24)

2f

b finite, (24) also finite
used h1
non-decreasing r. Since R
r
probability 1.
2
simple modification Lemma 5 implies /2-optimal sample point
found limited number suboptimal algorithms chosen round.
Lemma 14 Consider algorithms MetaMax() MetaMax. Suppose Assumption 11
holds, assume f fR < /2 R > 0. anyround r > R, hr (n) = rn


0 < r < 1 n 0,

ln 2f
ln(1/r )

algorithms chosen

estimates fj f .

Proof proof follows Lemma 5 taking account suboptimal algorithm
Aj satisfies fj f least one optimal algorithm chosen round
r > R: Similarly (23), r defined Lemma 5 bounded r > /(2f ),

l
2f
ln
ln(1/r )

number suboptimal algorithms used round r bounded ln(1/
.
ln(1/
r)
r)
2
Finally derive convergence rate algorithm MetaMax. First bound
number steps taken currently best algorithm, terms number
rounds total number steps taken local search algorithms.
Theorem 15 Consider MetaMax algorithm. end round r number
steps taken currently best algorithm r 2r. is,
r nIr ,r < 2r.

(25)

Furthermore, number calls nIr ,r evaluate f currently
best algorithm AIr
Pr
bounded function total number times tr = i=1 ni,r target function f
evaluated local search instances

2tr + 7 1
nIr ,r
.
(26)
2
Proof first statement lemma simple, since round actually
best algorithm takes one step overtaking, one two steps
428

fiEfficient Multi-Start Strategies Local Search Algorithms

overtaking. Indeed, round r 2, overtaking, is, Ir = Ir1 ,
nIr ,r = nIr ,r1 + 1. Otherwise, Ir 6= Ir1 , nIr ,r = nIr1 ,r + 1, since
0 nIr1 ,r nIr1 ,r1 1,
1 nIr ,r nIr1 ,r1 2
situations. Since first round clearly algorithm used takes 1 step,
is, nI1 ,1 = 1, (25) follows.
prove second part, notice round r, nIr1 ,r1 + 1 algorithms
stepped step (c) algorithm used taken steps
currently best one. Also, step (c) extra samples used overtaking.
case overtaking, AIr advanced step (c), well AIr1 ,
nIr1 ,r1 + 1 extra steps taken AIr . Therefore,
tr tr1 + 2nIr1 ,r1 + 2.
Thus, since overtaking happens round 1, obtain
tr 1 +

r
X

2(nIs1 ,s1 + 1).

s=2

Then, (25)
tr 1 + 4

r
X
s=2

= 1 + 2(r + 2)(r 1) 1 + 2(nIr ,r + 2)(nIr ,r 1)

yields (26).

2

Note proof used crude estimate length usual round (without
overtaking) relative to, example, Lemma 14. This, however, affects result
constant factor long able bound number rounds number
extra steps taken overtaking happens, since effect overtakings
introduces quadratic dependence proof (26). Experimental results Section 5
show (see Figure 10) number algorithm instances (which turn number r
rounds) usual growth rate (tr / ln tr ), which, taken account, may sharpen
bound often best algorithm chosen.
Assumption 11, random search component MetaMax implies eventually optimal algorithm best. point convergence
rate optimal local search algorithms determine performance search,
number steps taken best local search algorithm bounded Theorem 15.
Theorem 16 Suppose Assumption 11 holds. almost surely finite random
index R rounds r > R, estimate fr MetaMax algorithm
total number steps tr taken local search algorithms end round r
satisfies


2t
+
7

1
r

f fr g
2
probability least 1 , g defined Lemma 1 global maximum f .
429

fiGyorgy & Kocsis

Remark 17 (i) value R bounded high probability using properties
uniform random search actual problem; would yield similar bounds
Theorems 6 8 MetaMax(K) algorithm. (ii) Note exploration-exploitation
trade-off MetaMax algorithm: value R potentially decreased introduce
new algorithms often, nIr ,r reduced time. (iii) Theorems 15 16
imply that, asymptotically, MetaMax algorithm needs quadratically function
evaluations local search algorithm
Psthat ensured converge optimum.
particular, f form f (x) =
i=1 fi (x)ISi (x) Si form partition
[0, 1]d , ISi denotes indicator function Si , fi belong nicely behaving
function class local search algorithm started Si converges maximum
fi Si (e.g., f piecewise concave function exponential convergence rate
SPSA algorithm, used sufficiently small step size), preserve
performance local search algorithm original function class price
asymptotically quadratic increase number function calls evaluate f (i.e.,
total number steps taken local search algorithm instances).
4.3 Discussion Results
sense theoretical results presented previous sections weak.
consistency result MetaMax(K) algorithm follows easily fact
local search algorithm used infinitely many times, consistency MetaMax()
MetaMax follows consistency random search. performance bounds
provided disadvantage asymptotic sense hold
possibly large number rounds (a weakness bounds minimum number
rounds obtained properties uniform random search/sampling particular
problem, neglecting attractive properties algorithms). fact, quite easy
construct scheduling strategies consistent asymptotically arbitrarily
large fraction function evaluations (even almost all) used optimal local search
algorithms: explore-and-exploit algorithms achieve goals number
function evaluations used known ahead use arbitrarily small fraction
evaluations target function f exploration. compare performance
algorithms explore-and-exploit algorithms Section 5. particular, match
performance guarantees MetaMax family, use algorithms spend half
time exploration half exploitation, exploration part
uniform allocation strategy used finite number local search algorithms,
schedule Luby et al. (1993) used infinitely many local search algorithms.
Although theoretical guarantees proved paper MetaMax family also hold
explore-and-exploit algorithms, experiments MetaMax family seems
behave superior compared algorithms, expected.
theoretical results also give sufficient guidance chose parameter
h hr (the time-varying version h considered MetaMax(K) algorithm
simplicity ease presentation). results require sufficiently fast
exponential decay h, problem dependent cannot determined advance.
sufficiently fast decay rate would ensure, example, MetaMax(K) algorithm
could always use stronger results Theorem 6 would never deal
430

fiEfficient Multi-Start Strategies Local Search Algorithms

case bound Theorem 8 holds. One may easily choose h
function decreases super-exponentially: would make asymptotic bounds work,
however, would slow exploration (in extreme case hr (n) 0, excluded
conditions, exploration would performed, algorithms would use
actually best local search algorithm). practice always found
appropriate chose hr decay exponentially. Furthermore, found even
effective gradually decrease decay rate enhance exploration time elapses (the
rationale behind approach assumption good algorithms
less converged while, may greater potential exploration
improve estimates). Finally, connection g h
investigated.
Keeping limitations theoretical results mind, still believe
theoretical analyses given provide important insight algorithms may guide
potential user practical applications, especially since properties MetaMax
family proved asymptotic regime (e.g., rounds quite short)
usually observed practice, well. Furthermore, think possible
improve analysis bound thresholds results become valid
reasonable values, would require different approach and, therefore, left
future work.

5. Experiments
variants MetaMax algorithm tested synthetic real examples. Since
negligible difference performance MetaMax() MetaMax,6
following present results MetaMax(K) MetaMax. First demonstrate performance algorithm optimizing synthetic function (using SPSA
local search algorithm). Next behavior algorithm tested standard data
sets. show MetaMax applied tuning parameters machine learning
algorithms: classification task solved neural network, parameters
training algorithm (back-propagation) fine-tuned MetaMax combined SPSA.
MetaMax also applied boost performance k-means clustering. end
section, compare results experiments theoretical bounds obtained
Section 4.2.
experiments, accordance simplifying assumptions introduced
Section 3, main difference individual runs particular local search
algorithm starting point. Obviously, general diversification techniques exist:
example, parameters local search algorithm could also vary instance
instance (including running instances different local search algorithms, parameter would select actually employed search algorithm), initialization (starting
point parametrization) new instance could also depend results delivered
6. example, relative difference average error eMetaMax() MetaMax()
eMetaMax MetaMax optimizing parameters multi-layer perceptron learning letter
data set (see Section 5.1 especially Figure 6, right details) 0.033 standard
deviation 0.06 (averaged
1000 experiments), relative difference defined
fi
fi
fieMetaMax() eMetaMax fi / max(eMetaMax() , eMetaMax ).

431

fiGyorgy & Kocsis

existing instances. Although MetaMax strategies could also applied
general scenarios, behavior better studied simpler scenario; hence,
experiments correspond setup.
5.1 Optimizing Parameters SPSA
section compare two versions MetaMax algorithm six multi-start
strategies, including three constant three variable number algorithm
instances. strategies run fixed time steps, is, target function
evaluated times, together local search instances (note several reference
strategies use parameter).
used SPSA (Simultaneous Perturbation Stochastic Approximation; Spall, 1992)
base local search algorithm cases. SPSA local search algorithm sampling
function uses gradient descent stochastic approximation derivative:
actual location Xt = (Xt,1 , . . . , Xt,d ), SPSA estimates lth partial derivative f
f (Xt + Bt ) f (Xt Bt )
,
ft,l (Xt,l ) =
2t Bt,l
Bt,l i.i.d. Bernoulli random variables components vector
Bt , uses sampling function st (Xt ) = Xt + ft (Xt ) choose next point
sampled, is,
Xt+1,l = Xt,l + ft,l (Xt,l )
l = 1, . . . , (t scalar parameters).
implementation algorithm followed guidelines provided
(Spall, 1998), gain sequence = a/(A + + 1) , perturbation size =
/(t + 1) , = 60, = 0.602 = 0.101. values vary
different experiments; chosen heuristically based experience similar
problems (this cause problem here, goal experiments
provide fast solutions global optimization problems hand demonstrate
behavior multi-start algorithms compared). addition two evaluations
required perturbed points, also evaluate function current point Xt .
starting point chosen randomly, function evaluated first point.
six reference algorithms MetaMax(K) MetaMax algorithms compared following:
Unif: algorithm selects constant number instances SPSA uniformly.
implementation instance = mod K selected time t, K denotes
number instances.
ThrAsc: Threshold Ascent algorithm Streeter Smith (2006b). algorithm begins selecting fixed number instances once. phase
time step ThrAsc selects best estimates produced far algorithm
instances Ai , = 1, . . . , K previous time steps, Ai counts
many estimates produced Ai . Denoting latter value Si,t , time
algorithm selects instance index = argmaxi U (Si,t /ni,t , ni,t ), ni,t
432

fiEfficient Multi-Start Strategies Local Search Algorithms

number times ith instance selected time t,
U (, n) = +

+

p
2n + 2
n

= ln(2T K/). parameters algorithm, experiments
best value appeared 100, set 0.01. note Threshold
Ascent developed maximum K-armed bandit problem; nevertheless,
provides sufficiently good performance setup test experiments.
Rand: random search algorithm. seen running sequence SPSA
algorithms instance used exactly one step, evaluation
random starting point SPSA algorithm.
Luby: algorithm based work Luby et al. (1993). method runs several
instances SPSA sequentially other, ith instance run ti steps,
ti defined

2k1 ,
= 2k 1
ti =
ti2k1 +1 ,
2k1 < 2k 1
definition produces schedule first 2k 1 algorithm instances
one run 2k1 steps, two 2k2 steps, four 2k3 steps, on.
EE-Unif: algorithm instance explore-and-exploit algorithms. first
/2 steps Unif algorithm used exploration, and, subsequently, exploration
phase, SPSA instance achieved highest value exploration phase
selected.
EE-Luby: algorithm similar EE-Unif, except Luby used exploration.
versions MetaMax algorithm tested. Motivated fact SPSA
known converge global optimum exponentially fast f satisfies restrictive
conditions (Gerencser & Vago, 2001), chose hr (n) decays exponentially fast.
control exploration far suboptimal algorithm instances, allowed hr (n)
time-varying function, is, changes tr , total number function calls
evaluate f (or equally, total number steps taken) algorithms far. Thus,
round r + 1 used


hr (n) = en/

tr

(27)

(note used time-varying version hr also case MetaMax(K)
latter easily extended situation, omitted simplify
presentation).
algorithms fixed number local search instances (MetaMax(K), Unif,
EE-Unif, ThrAsc), number instances K set 100 simulations,
choice provided reasonably good performance problems analyzed.
multi-start algorithms tested using two versions synthetic function,
tuning parameters learning algorithm two standard data sets.
433

fiGyorgy & Kocsis

synthetic function slightly modified7 version Griewank function (Griewank,
1981):



2xl X 4 2 x2l
cos
f (x) =
100
l
l=1
l=1
x = (x1 , . . . , xd ) xl constrained interval [1, 1]. show
results 2-dimensional 10-dimensional cases.
parameters SPSA = 0.05 = 0.1 2-dimensional case,
= 0.5 = 0.1 10-dimensional case. performance search algorithms
measured error defined difference maximum value
function (in case 1) best result obtained search algorithm given
number steps. results multi-start strategies two- 10dimensional test functions shown Figure 5. error curve averaged 10,000
runs, strategy run 100,000 steps (or iterations). One may observe
cases two versions MetaMax algorithm converge fastest. ThrAsc
better Unif, Luby seems fairly competitive two. two exploreand-exploit-type algorithms (EE-Unif EE-Luby) similar performance 2dimensional function, clearly better non-exploiting base algorithms,
10-dimensional function behavior somewhat pathological sense low
values performances best among algorithms, increasing ,
error actually increases respective base algorithms achieve smaller errors
values . random search seems option 2-dimensional function.
Similar results obtained dimensions 2 10. pathological behavior
explore-and-exploit algorithms start appear gradually starting 5-dimensional
function, pronounced 8 dimensions onwards. Limited experimental data
obtained higher dimensions 100 (averaged hundred runs) shows
superiority MetaMax preserved high-dimensional problems well.
reason pathological behavior explore-and-exploit strategies (i.e.,
error curves monotone decreasing number iterations) illustrated
follows. Assume two SPSA instances, one converging global optimum
another one converging suboptimal local optimum. Assume first
steps optimal algorithm gives better result, suboptimal algorithm takes
reaches local maximum, algorithms run even further, optimal
algorithm beats suboptimal one. exploration stopped first last
regime, explore-and-exploit algorithm choose first, optimal local search instance,
whose performance may get quite close global optimum exploitation phase
(even stopped first regime). exploration stopped middle regime,
suboptimal search instance selected exploitation, whose performance may
even get close global optimum. scenario, error exploitation
phase (i.e. end) lower small, increases higher values . Decrease
error increasing assured optimal instance converges
exploration phase past suboptimal local optima, results selecting optimal
local search instance exploitation. scenario error decrease fast
7. modification made order significant differences values function
global maximum local maxima.

434

fi10

10

1

1

0.1

0.1

average error

average error

Efficient Multi-Start Strategies Local Search Algorithms

0.01

0.001

0.0001

0.001

0.0001
Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

1e-06

0.01

1

Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

10

100

1000

10000

1e-06

100000

1

10

iteration

100

1000

10000

100000

iteration

Figure 5: average error multi-start strategies 2-dimensional (left)
10-dimensional (right) modified Griewank function. 99% confidence intervals
shown color corresponding curves. Note
intervals small.
1

0.1

0.01

0.01

average error

average error

0.1

0.001

0.0001
Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

1e-06

1

0.001

0.0001

Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

10

100

1000

10000

100000

iteration

1e-06

1

10

100

1000

10000

100000

iteration

Figure 6: average error multi-start strategies tuning parameters Multilayer Perceptron vehicle data set (left) letter data set (right).
99% confidence intervals also shown color corresponding
curves.

initially, increase may decrease till converges 0,
quite similar observe Figure 5, right. pathological behavior
becomes transparent many local search algorithms, length
exploitation phase scales number local search instances length
exploration instance kept fixed. Analyzing experimental data shows
complex versions scenario outlined occurred simulations
main cause observed pathological behavior (the non-monotonicity error
curves).
tuning parameters learning algorithm, used two standard data
sets UCI Machine Learning Repository (Asuncion & Newman, 2007): vehicle
435

fiGyorgy & Kocsis

letter, Multilayer Perceptron learning algorithm Weka (Witten & Frank, 2005)
(here back-propagation algorithm used training phase). Two parameters
tuned: learning rate momentum, range [0, 1]. size
hidden layer Multilayer Perceptron set 8, number epochs
100. parameters SPSA algorithm = 0.5 = 0.1,
10-dimensional Griewank function (as previous experiment, parameters
chosen based experience). rate correctly classified items test set
vehicle using Multilayer Perceptron varying values two parameters shown
Figure 7, highest rate 0.910112. Similarly, classification rate letter
shown Figure 8, highest rate 0.7505.
error rates optimized Multilayer Perceptron data sets vehicle
letter shown Figure 6, parameters learning algorithm tuned
multi-start strategies above. error cases difference
best classification rate obtained (0.910112 0.7505, respectively)
best classification rate obtained multi-start strategies given number steps.
results shown averaged 1,000 runs. observe MetaMax algorithm
(with increasing number algorithm instances) converged fastest average, three
strategies fixed number algorithm instances nearly identical results, Luby
(and explore-and-exploit variant) slightly worse these, random search
slowest, although performed nearly badly synthetic functions.
reason random search relatively better performance (relative
used SPSA) could twofold: (i) large parts error surface offer fairly small error,
(ii) error surface less smooth, therefore SPSA less successful using
gradient information. explore-and-exploit variants performed well vehicle data
set initially, performance worsened larger values (compared MetaMax,
algorithms extent). This, coupled observation Figure 5,
right would suggest explore-and-exploit variants competitive small values
, despite asymptotic guarantees.
summary, MetaMax algorithm (with increasing number algorithm instances) provided far best performance tests, usually requiring significantly
fewer steps find optimum algorithms. E.g., letter data set
MetaMax algorithm found global optimum runs 100,000 time steps.
conclude MetaMax converged faster multi-start strategies investigated four test cases, notable advantage difficult surfaces (at least
gradient-based optimization viewpoint) induced classification tasks.
5.2 k-Means Clustering
section consider problem partitioning set d-dimensional real vectors
xj Rd , j = 1, . . . , N clusters, cluster Si represented center (or
reconstruction) point ci Rd , = 1, . . . , N . cost function minimized sum
distances
PN(x,Pci ) data points corresponding centers, is, want
minimize i=1 xSi (x, ci ). two necessary conditions optimality (see, e.g.,
Linde, Buzo, & Gray, 1980; Gersho & Gray, 1992): = 1, . . . , N ,
Si = {x : (x, ci ) (x, cj ) j = 1, . . . , N }
436

(28)

fiEfficient Multi-Start Strategies Local Search Algorithms

Figure 7: Classification rate vehicle data set. rates plotted subtracting
0.911112 thus global optima scattered black spots
corresponding value equal 0.001.

Figure 8: Classification rate letter data set. rates plotted subtracting 0.7515 thus global optima scattered black spots
corresponding value equal 0.001.

(with ties broken arbitrarily)
ci = argmin
cRd

X

xSi

437

(x, c).

(29)

fiGyorgy & Kocsis

P

x

8

usual choice squared Euclidean distance, case ci = xS
|Si | . According necessary conditions, k-means algorithm (or Generalized-Lloyd
algorithm, see, e.g., Linde et al., 1980; Gersho & Gray, 1992) alternates partitioning data set according (28) centers fixed, recomputing
centers (29) partitioning kept fixed. easily seen cost
(or error) cannot increase steps, hence algorithm converges
local minimum cost function. practice, algorithm stops (or
insufficient) decrease cost function. However, k-means algorithm often trapped
local optimum, whose value influenced initial set centers. SPSA,
restarting k-means different initialization may result finding global optimum.
consider two initialization techniques: first, termed k-means, chooses centers
uniformly random data points; second, k-means++ (Arthur & Vassilvitskii,
2007) chooses initial center uniformly random data set, chooses
centers data points probability proportional distance
data point closest center already selected.

k-means algorithm usually terminates relatively small number steps,
thus multi-start strategies bounded number instances would run active local
search algorithms, therefore appear particularly attractive. However,
natural domain consider strategy starts new instance, previous
finished. strategy referred subsequently Serial. mentioned
considerations, test MetaMax, variant algorithms applicable
unbounded number instances.9 experiments SPSA, used hr (27).
Note theoretical results indicate k-means may converge exponential
rate (in particular, Kieffer, 1982 showed rate convergence exponential
random variables log-concave densities 1-dimension provided logarithm
density piecewise affine).
Two multi-start strategies, Serial MetaMax tested data set cloud
UCI Machine Learning Repository (Asuncion & Newman, 2007). data set
employed Arthur Vassilvitskii (2007) well. number clusters set
ten. performance multi-start strategies defined difference
smallest cost function obtained strategy given number steps smallest
cost seen experiments (5626.6357). results averaged 1,000 runs
plotted Figure 9. initialization methods MetaMax strategy converges
faster Serial strategy. note data set, k-means++
clever initialization procedure yields faster convergence standard k-means
uniform initialization, consistent results presented Arthur
Vassilvitskii (2007).

8. extension clustering random variables well-known straightforward, omitted
paper consider clustering finite data sets.
9. Note MetaMax algorithm practical modification local search
algorithm terminated chosen anymore. clearly improves performance
algorithm chosen anymore improvement observed.

438

fiEfficient Multi-Start Strategies Local Search Algorithms

100000

10000
1000
100

average error

average error

10000

1000

100

10
1
0.1
0.01
0.001

10

0.0001
1

Serial kmeans
MetaMax kmeans

1

10

100

1000

10000

100000

iteration

1e-05

Serial kmeans++
MetaMax kmeans++

1

10

100

1000

10000

100000

iteration

Figure 9: average error multi-start strategies k-means (left) kmeans++ (right). 99% confidence intervals shown color
corresponding curves.

5.3 Practical Considerations
experiments MetaMax algorithm presented above, observed
number algorithm instances r (shown Figure 10) grows rate (tr / ln tr ) (recall
tr total number function calls evaluate f , total number steps,
algorithm instances end round r). hand, derivation

theoretical bounds (see Theorem 15 Theorem 16) used bound r ( tr ).
contrast quadratic penalty suggested Theorem 16, plugging (tr / ln tr )
estimate r theorem would find logarithmic factor calls
evaluate f (total number steps) needed achieve performance search
algorithm started attraction region optimum.
Finally, perhaps main practical question concerning MetaMax family multistart algorithms decide use them. rule thumb, say
sufficiently large performance difference average run
local search algorithm best one. Clearly, single local search produces
acceptable result worth effort run several instances local search,
especially complicated schedule. many real problems often case
relatively easy get close optimum, may acceptable
applications, approaching optimum greater precision hard; latter
importance, MetaMax algorithm variants may useful. Last, one may
wonder computational costs algorithms. discussed before,
consider case evaluation target function expensive: clearly
case Griewank function, used demonstrate basic properties
algorithm, holds many optimization problems practice, including
experiments considered paper. problems function evaluation
indeed expensive (and depends available data), overhead introduced
MetaMax algorithms depends number rounds. MetaMax(K)
algorithm find upper convex hull set K points round;
worst case take long O(K 2 ) calculations, practice usually
439

fiGyorgy & Kocsis

number algorithm instances * ln(t)/t

1.8

Griewank 2D
Griewank 10D
vehicle
letter
K-MEANS
K-MEANS++
min
max

1.6
1.4
1.2
1
0.8
0.6
0.4
0.2

1

10

100

1000

10000

100000

iteration

Figure 10: Number algorithm instances (r) MetaMax. average number
instances shown six benchmarks: Griewank function (2- 10dimensional), parameter tuning Multilayer Perceptron (on vehicle
letter data set), clustering k-means k-means++.
maximum minimum number instances runs benchmarks
also shown. One notice larger values tr , 0.45tr / ln tr r
1.65tr / ln tr .

much cheaper, upper convex hull determined point corresponds
actually best estimate point corresponds least used algorithm,
requires O(K) computations, even less, special ordering tricks
introduced. Since target function f evaluated least twice round, average
O(K 2 ) computational overhead needed evaluation f worst
case, practically reduced O(K), even less. Similar considerations hold
MetaMax() MetaMax algorithms, resulting average O(r2 ) worst-case
overhead call f (in r rounds), closer O(r) even less practice.
examples considered (apart case Griewank function), amount
overhead negligible relative computational resources needed evaluate
f single point.

6. Conclusions
paper provided multi-start strategies local search algorithms. strategies
continuously estimate potential performance algorithm instance optimistic
way, supposing convergence rate local search algorithms unknown
constant, every phase resources allocated instances could converge
optimum particular range constant. Three versions algorithm
presented, one able follow performance best fixed number
local search algorithm instances, two that, gradually increasing number
local search algorithms, achieve global consistency. theoretical analysis asymptotic
440

fiEfficient Multi-Start Strategies Local Search Algorithms

behavior algorithms also given. Specifically, mild conditions
function maximized (e.g., set values local maxima dense
global maximum), best algorithm, MetaMax, preserves performance local
search algorithm original function class quadratic increase
number times target function needs evaluated (asymptotically). Simulations
demonstrate algorithms work quite well practice.
theoretical bound suggests target function evaluated
quadratic factor times achieve performance search algorithm started
attraction region optimum, experiments found logarithmic
penalty. clear whether difference result slightly conservative
(asymptotic) analysis choice experimental settings. Also, finite sample
analysis algorithm interest, experiments indicate MetaMax
algorithm provides good performance even relatively small number steps taken
local search algorithms, sense provides speed-up compared
approaches even number times target function evaluated (i.e., total
number steps taken algorithms together) relatively small. Finally,
future work needed clarify connection convergence rate optimal
algorithms (g ) function hr used exploration.

Acknowledgments
authors would like thank anonymous referees numerous insightful
constructive comments. research supported part Mobile Innovation
Center Hungary, National Development Agency Hungary Research
Technological Innovation Fund (KTIA-OTKA CNK 77782), PASCAL2 Network
Excellence (EC grant no. 216886). Parts paper presented ECML 2009
(Kocsis & Gyorgy, 2009).

Appendix A. Proof Lemma 1
bn ). Since Un 0 almost everywhere E, Egoroffs
Fix (0, 1) let Un = f f (X
theorem (see, e.g. Ash & Doleans-Dade, 2000) implies event E E
1 P (E ) < Un 0 uniformly almost everywhere E . second part
lemma follows definition uniform convergence.
2

References
Adam, K. (2001). Learning searching best alternative. Journal Economic
Theory, 101, 252280.
Arthur, D., & Vassilvitskii, S. (2007). k-means++: advantages careful seeding.
Proceedings 18th Annual ACM-SIAM Symposium Discrete Algorithms, pp.
10271035.
Ash, R. B., & Doleans-Dade, C. A. (2000). Probability & Measure Theory. Academic Press.
441

fiGyorgy & Kocsis

Asuncion, A., & Newman, D. J. (2007). UCI machine learning repository.
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite time analysis multiarmed
bandit problem. Machine Learning, 47 (2-3), 235256.
Bartz-Beielstein, T. (2006). Experimental Research Evolutionary Computation
New Experimentalism. Natural Computing Series. Springer, New York.
Battiti, R., Brunato, M., & Mascia, F. (2008). Reactive Search Intelligent Optimization,
Vol. 45 Operations research/Computer Science Interfaces. Springer Verlag.
Beck, C. J., & Freuder, E. C. (2004). Simple rules low-knowledge algorithm selection.
Regin, J. C., & Rueher, M. (Eds.), CPAIOR, Lecture Notes Computer Science
3011, pp. 5064. Springer.
Carchrae, T., & Beck, J. C. (2004). Low-knowledge algorithm control. Proceedings
Nineteenth National Conference Artificial Intelligence (AAAI), pp. 4954.
Cicirello, V. A., & Smith, S. F. (2004). Heuristic selection stochastic search optimization:
Modeling solution quality extreme value theory. Proceedings 10th
International Conference Principles Practice Constraint Programming, pp.
197211. Springer.
Cicirello, V. A., & Smith, S. F. (2005). max k-armed bandit: new model exploration
applied search heuristic selection. Proceedings Twentieth National
Conference Artificial Intelligence, pp. 13551361.
Finkel, D. E., & Kelley, C. T. (2004). Convergence analysis direct algorithm. Tech.
rep. CRSC-TR04-28, NCSU Mathematics Department.
Gagliolo, M., & Schmidhuber, J. (2006). Learning dynamic algorithm portfolios. Annals
Mathematics Artificial Intelligence, 47 (34), 295328. AI&MATH 2006 Special
Issue.
Gagliolo, M., & Schmidhuber, J. (2007). Learning restart strategies. Veloso, M. M. (Ed.),
IJCAI 2007 Twentieth International Joint Conference Artificial Intelligence,
vol. 1, pp. 792797. AAAI Press.
Gagliolo, M., & Schmidhuber, J. (2010). Algorithm selection bandit problem
unbounded losses. Blum, C., & Battiti, R. (Eds.), Learning Intelligent Optimization, Vol. 6073 Lecture Notes Computer Science, pp. 8296. Springer
Berlin/Heidelberg.
Gerencser, L., & Vago, Z. (2001). mathematics noise-free SPSA. Proceedings
IEEE Conference Decision Control, pp. 44004405.
Gersho, A., & Gray, R. M. (1992). Vector Quantization Signal Compression. Kluwer,
Boston.
Griewank, A. O. (1981). Generalized descent global optimization. Journal Optimization Theory Applications, 34, 1139.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. Systems Science Cybernetics, IEEE Transactions on,
4 (2), 100 107.
442

fiEfficient Multi-Start Strategies Local Search Algorithms

Hoos, H. H., & Stutzle, T. (1999). Towards characterisation behaviour stochastic
local search algorithms SAT. Artificial Intelligence, 112, 213232.
Horn, M. (2006). Optimal algorithms global optimization case unknown lipschitz
constant. Journal Complexity, 22 (1), 5070.
Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automatic
algorithm configuration framework. Journal Artificial Intelligence Research, 36 (1),
267306.
Jones, D. R., Perttunen, C. D., & Stuckman, B. E. (1993). Lipschitzian optimization without
lipschitz constant. Journal Optimization Theory Applications, 79 (1), 157
181.
Kautz, H., Horvitz, E., Ruan, Y., Gomes, C., & Selman, B. (2002). Dynamic restart policies. Proceedings Eighteenth National Conference Artificial Intelligence
(AAAI), pp. 674681.
Kieffer, J. C. (1982). Exponential rate convergence Lloyds method I. IEEE Trans.
Inform. Theory, IT-28, 205210.
Kocsis, L., & Gyorgy, A. (2009). Efficient multi-start strategies local search algorithms.
Buntine, W., Grobelnik, M., Mladenic, D., & Shawe-Taylor, J. (Eds.), Machine
Learning Knowledge Discovery Databases, Vol. 5781 Lecture Notes Computer Science, pp. 705720. Springer Berlin/Heidelberg.
Linde, Y., Buzo, A., & Gray, R. M. (1980). algorithm vector quantizer design. IEEE
Transactions Communications, COM-28, 8495.
Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup Las Vegas algorithms.
Information Processing Letters, 47, 173180.
Mart, R., Moreno-Vega, J., & Duarte, A. (2010). Advanced multi-start methods. Gendreau, M., & Potvin, J.-Y. (Eds.), Handbook Metaheuristics, 2nd edition (2 edition).
Springer.
Nesterov, Y. (2004). Introductory Lectures Convex Optimization: Basic Course.
Kluwer Academic Publishers.
Ribeiro, C., Rosseti, I., & Vallejos, R. (2009). use run time distributions evaluate
compare stochastic local search algorithms. Stutzle, T., Birattari, M., & Hoos,
H. (Eds.), Engineering Stochastic Local Search Algorithms. Designing, Implementing
Analyzing Effective Heuristic s, Vol. 5752 Lecture Notes Computer Science,
pp. 1630. Springer Berlin/Heidelberg.
Spall, J., Hill, S., & Stark, D. (2006). Theoretical framework comparing several stochastic
optimization approaches. Calafiore, G., & Dabbene, F. (Eds.), Probabilistic
Randomized Methods Design Uncertainty, chap. 3, pp. 99117. SpringerVerlag, London.
Spall, J. C. (1992). Multivariate stochastic approximation using simultaneous perturbation
gradient approximation. IEEE Transactions Automatic Control, 37, 332341.
Spall, J. C. (1998). Implementation simultaneous perturbation algorithm stochastic optimization. IEEE Transactions Aerospace Electronic Systems, 34, 817823.
443

fiGyorgy & Kocsis

Streeter, M. J., & Smith, S. F. (2006a). asymptotically optimal algorithm max
k-armed bandit problem. Proceedings, Twenty-First National Conference
Artificial Intelligence Eighteenth Innovative Applications Artificial Intelligence Conference, pp. 135142.
Streeter, M. J., & Smith, S. F. (2006b). simple distribution-free approach max
k-armed bandit problem. Principles Practice Constraint Programming CP 2006, 12th International Conference, CP 2006, Nantes, France, September 25-29,
2006, Proceedings, pp. 560574.
Vilalta, R., & Drissi, Y. (2002). perspective view survey meta-learning. Artificial
Intelligence Review, 18 (2), 7795.
Witten, I. H., & Frank, E. (2005). Data Mining: Practical Machine Learning Tools
Techniques (2nd edition). Morgan Kaufmann, San Francisco.
Zabinsky, Z. B., Bulger, D., & Khompatraporn, C. (2010). Stopping restarting strategy
stochastic sequential search global optimization. J. Global Optimization,
46 (2), 273286.

444

fiJournal Artificial Intelligence Research 41 (2011) 1-24

Submitted 10/2010; published 05/2011

Properties Bethe Free Energies Message Passing
Gaussian Models
Botond Cseke
Tom Heskes

b.cseke@science.ru.nl
t.heskes@science.ru.nl

Institute Computing Information Sciences
Faculty Science, Radboud University Nijmegen
Heyendaalseweg 135, 6525 AJ, Netherlands

Abstract
address problem computing approximate marginals Gaussian probabilistic
models using mean field fractional Bethe approximations. define Gaussian fractional Bethe free energy terms moment parameters approximate
marginals, derive lower upper bound fractional Bethe free energy
establish necessary condition lower bound bounded below. turns
condition identical pairwise normalizability condition, known
sufficient condition convergence message passing algorithm. show
stable fixed points Gaussian message passing algorithm local minima
Gaussian Bethe free energy. counterexample, disprove conjecture stating
unboundedness free energy implies divergence message passing
algorithm.

1. Introduction
One major tasks probabilistic inference calculating marginal posterior probabilities set variables given observations. case Gaussian models,
computational complexity computing marginals might scale cubically number
variables, models discrete variables often leads intractable computations.
Computations made faster tractable using approximate inference methods like
mean field approximation (e.g., Jaakkola, 2000) Bethe-type approximation (e.g.,
Yedidia, Freeman, & Weiss, 2000). methods developed discrete probabilistic
graphical models, applicable Gaussian models well. However,
important differences behavior discrete Gaussian cases. example,
discrete models error function Bethe approximationcalled Bethe free
energyis bounded (Heskes, 2004; Watanabe & Fukumizu, 2009), Gaussian
models might always case (Welling & Teh, 2001).
understanding properties Bethe free energy Gaussian models might
also help understand properties energy function conditional Gaussian
models. Conditional Gaussian hybrid graphical models, switching Kalman filters
(Zoeter & Heskes, 2005), combine discrete Gaussian variables. Approximate
inference models carried expectation propagation (e.g., Minka, 2004,
2005) viewed generalization Bethe approximation,
marginal consistency constraints approximate marginals replaced expectation
constraints (Heskes, Opper, Wiegerinck, Winther, & Zoeter, 2005). order understand
c
2011
AI Access Foundation. rights reserved.

fiCseke & Heskes

properties Bethe free energy hybrid models, good understanding two
special cases discrete Gaussian models needed. properties Bethe
free energy discrete models studied extensively last decade well
understood (Yedidia et al., 2000; Heskes, 2003; Wainwright, Jaakkola, & Willsky, 2003;
Watanabe & Fukumizu, 2009), properties Gaussian Bethe free energy
studied much less.
message passing algorithm well established method finding stationary
points Bethe free energy (Yedidia et al., 2000; Heskes, 2003). works locally
updating approximate marginals successfully applied discrete (e.g.,
Murphy, Weiss, & Jordan, 1999; Wainwright et al., 2003) Gaussian models (e.g., Weiss
& Freeman, 2001; Rusmevichientong & Roy, 2001; Malioutov, Johnson, & Willsky, 2006;
Johnson, Bickson, & Dolev, 2009; Nishiyama & Watanabe, 2009; Bickson, 2009). Gaussian
message passing simplest case free-energy based message passing algorithm
models continuous variables, therefore, important understand behavior.
Gaussian message passing many practical applications like distributed averaging
(Moallemi & Roy, 2006), peer-to-peer rating, linear detection, SVM regression (Bickson,
2009) generally problems involve solving large sparse linear systems
approximating marginal variances large sparse Gaussian systems typically encountered distributed computing settings. applications reader referred
work Bickson (2009) references therein.
Finding sufficient conditions convergence message passing Gaussian models
successfully addressed many authors. Using computation tree approach,
Weiss Freeman (2001) proved message passing converges whenever precision
matrixinverse covarianceof probability distribution diagonally dominant1 .
help analogy message passing walksum analysis, (Malioutov et al.,
2006) derived stronger condition pairwise normalizability2 . different approach
taken Welling Teh (2001), directly minimized Bethe free energy regard
parameters approximate marginals, conjecturing Gaussian message passing
converges free energy bounded below. experiments showed
message passing direct minimization either converge solution
fail converge. adopt similar approach, is, instead analyzing properties
Gaussian message passing algorithm using approaches like Weiss Freeman
Malioutov et al., choose study properties Gaussian Bethe free energy
stationary points. help us draw conclusions existence local
minima, possible stable fixed points message passing converge.
paper structured follows. Section 2 introduce Gaussian Markov random
fields message passing algorithm. Section 3 define Gaussian fractional
Bethe free energies parameterized moment parameters approximate marginals
derive boundedness conditions them. two sections based authors
earlier work (Cseke & Heskes, 2008). Section 4 analyze stability properties
Gaussian message passing algorithm and, using similar line argument Watanabe
P
1. matrix diagonally dominant |Aii | > j6=i |Aij | i.
2. Following work Malioutov et al. (2006), call Gaussian distribution pairwise normalizable

Q
factorized product normalizable pair factors, is, p(x1 , . . . , xn ) = ij ij (xi , xj )
ij normalizable.

2

fiBethe Free Energies Message Passing Gaussian Models

Fukumizu (2009), show stable fixed points indeed local minima Bethe
free energy. conclude paper experiments Sections 5 6 supporting
results implications.

2. Approximating Marginals Gaussian Models
probability density Gaussian random vector x Rn defined terms canonical
parameters h Q


1

p(x) exp h x x Qx ,
(1)
2
Q positive definite matrix. expectation covariance V x
given = Q1 h V = Q1 respectively. many real world applications
matrix Q sparse typically low density, is, number non-zero
elements Q scales number variables n.
probability density also defined terms undirected probabilistic
graphical model commonly known Gaussian Markov random field (GMRF). Since
interactions variables p pairwise, associate variables xi
nodes v V = {1, . . . , n} undirected graph G = (V, E), edges e E V V
graph stand non-zero off-diagonal elements Q. use j proxy
(i, j) E. using notation introduced above, density p (1) written
product

p(x)
ij (xi , xj )
(2)
ij

Gaussian functions ij (xi , xj ) (also called potentials) associated edges e = (i, j)
graph. h Q given define potentials
j
j


ij (xi , xj ) = exp {ij
hi xi + ij
hj xj ij
Qii x2i /2 ij
Qjj x2j /2 Qij xi xj } ,

P
P
j


ij ij = 1
ji ij = 1 partitioning h Q corresponding
factors. practice, however, factors ij might given problem hand
j computed summing parameters computing
h Q well ij
ij
partitioning respectively. Without loss generality, use Qii = 1, since
results paper easily re-formulated general Qs rescaling
variables (e.g., Malioutov et al., 2006).
numerical calculation marginals, done solving linear system
= Q1 h performing sparse Cholesky factorization LLT = Q followed solving Takahashi equations (Takahashi, Fagan, & Chin, 1973). alternative option
calculate marginal means approximate marginal variances run Gaussian message passing algorithm probabilistic graphical model associated
representation (2). Gaussian message passing algorithm Gaussian variant
message passing algorithm (Pearl, 1988), dynamical programming algorithm
introduced compute marginal densities discrete probabilistic models pairwise interactions tree-structured graphs G. However, turned running loops
graphs cycles, yields good approximations marginal distributions (Murphy
et al., 1999). Weiss Freeman (2001) showed Gaussian message passing
3

fiCseke & Heskes

Figure 1: illustration incoming outgoing messages adjacent nodes j.

algorithm converging, computes exact mean parameters m, thus also
used solving linear systems (e.g., Bickson, 2009). Message passing works updating
passing directed messages along edges graph G, which, case algorithm
converges, used compute (approximate) marginal probability distributions.
Gaussian discrete algorithms functional form exception
summation (discrete case) integration operators (Gaussian case). message
ij (xi ) updated according
Z

new
ij (xi ) = dxj ij (xi , xj )
jk (xj ) ,
(3)
kj\i

= {j : j i} denotes index set variables connected xi G. step
current approximations qij (xi ,j ) p(xi , xj ) computed according
qij (xi , xj ) ij (xi , xj )


li\j

il (xi )



jk (xj ) .

(4)

kj\i

update steps (9) iterated convergence. corresponding qij (xi , xj )s
yield final approximation p(xi , xj )s. common use damping, is,
1 new (x ) (0, 1]. practice, helps
replace new
ij (xi ) ij (xi )
ij
dampen possible periodic paths (3), keeps properties fixed points
unchanged. Figure 1 illustrates incoming outgoing messages nodes associated
variables xi xj . quite significant difference discrete Gaussian
message passing replacement sum operator integral operator.
finite sums always exist, integral (3) become infinite. problem
remedied technically canonical parameterization (see Section 4) keeps
algorithm running, lead non-normalizable approximate marginals qij , thus
(possible) break-down algorithm.
Message passing introduced Pearl (1988) heuristic algorithm (in discrete
models), however, Yedidia et al. (2000) showed also viewed algorithm
4

fiBethe Free Energies Message Passing Gaussian Models

finding stationary points so-called Bethe free energy, error function measuring
difference p specific family distributions detailed next
section. shown Heskes (2003) later different way Watanabe
Fukumizu (2009) stable fixed points (loopy) message passing algorithm local
minima corresponding Bethe free energy. paper show holds
Gaussian models well.
interest properties Gaussian Bethe free energy corresponding Gaussian message passing algorithm motivated mainly implications
general models inference algorithms like non-Gaussian models expectation propagation, respectively. reason, compare speed method
accuracy approximation mentioned exact linear algebraic methods.
mentioned introduction, approach take similar Welling
Teh (2001), is, study properties Gaussian Bethe free energy, parameterized
terms moment parameters approximate marginals. following
introduce mean field Bethe approximation Gaussian models. Readers familiar
subject continue Section 3.
2.1 Gaussian Bethe Free Energy
popular method approximate marginals approximating p distribution q
form makes marginals easy identify, example, factorizes treelike form. common quantity measure difference two probability
distributions Kullback-Leibler divergence [q || p]. often used characterize
quality approximation formulate computation approximate marginals
optimization problem


Z
q(x)

q (x) = argmin dx q(x) log
.
(5)
p(x)
qF
Here, F set distributions mentioned form. Since symmetric,
Kullback-Leibler divergence distance, [q || p] 0 proper q p,
[q || p] = 0 p = q, convex q p.
family F densities possessing form
Q makes marginals easy identify
family distributions factorize q(x) = k qk (xk ). words, problem (5)
approximate p distribution independent variables. approximation q
thisQtype called mean field approximation (e.g., Jaakkola, 2000). Defining FMF ({qk }) =
[ qk || p] writing right hand side (5) detail, one gets
Z
FMF ({qk }) =

dx



qk (xk ) log p(x) +

k

XZ

dxk qk (xk ) log qk (xk ).

k

Using parameterization qk (xk ) = N (xk |mk , vk ), = (m1 , . . . , mn )T v = (v1 , . . . , vn )T ,
reduces
1
1X
1X
FMF (m, v) = hT + mT Qm +
Qkk vk
log(vk ) + CMF ,
2
2
2
k

5

k

fiCseke & Heskes

Q
CMF irrelevant constant. Although [ k qk || p] might convex
(q1 , . . . , qn ), one easily check FMF convex variables v
minimum obtained = Q1 h vk = 1/Qkk . Since

1
1

1
Q kk = Qkk QTk,\k Q\k,\k
Q\k,k
,
one easily see mean field approximation underestimates variances. mean
field approximation computes solution means exact, variances
computed interactions variables, namely, matrix
Q diagonal, thus giving poor estimates variances.
order improve estimates variances, one choose approximating distributions q able capture dependencies variables p.
verified distribution dependencies form tree graph written
form
p(xi , xj )
p(x) =
p(xk ),
p(xi )p(xj )
ij

k

j run edges (i, j) tree k nodes 1, . . . , n.
Although cases undirected graph generated non-zero elements Q
tree, based tree intuition one construct q one two variable
marginals
qij (xi , xj )
q(x)
qk (xk )
(6)
qi (xi )qj (xj )
ij

k

andR constrain functions qij qk marginally
consistent normalize 1,
R
is, dxj qij (xi , xj ) = qi (xi ) j dxk qk (xk ) = 1 k. approximation
form (6) together constraints qij qk called Bethe approximation.
Let us denote family functions FB . choosing qij (xi , xj ) = qi (xi )qj (xj ) one
easily check FMF FB , thus FB non-empty. Assuming approximate
marginals correct q normalizes 1 substituting (6) (5), get
approximation KullbackLeibler divergence (5) called Bethe free energy.
Due factorization p, write Bethe free energy
XZ
FB ({qij , qk }) =
dxi,j qij (xi,j ) log ij (xi,j )
(7)
ij

+

XZ
ij



XZ
qij (xi,j )
dxi,j qij (xi,j ) log
+
dxk qk (xk ) log qk (xk ).
qi (xi )qj (xj )
k

One also define free energy Bethe approximation
Z
XZ
dx q (x) log q (x)
dxi,j q (xi,j ) log q (xi,j )
ij

+

X
k

6

Z
(1 nk )

dxk q (xk ) log q (xk )

fiBethe Free Energies Message Passing Gaussian Models

entropy (e.g., Yedidia et al., 2000) substitute marginals functions qij
qRk normalize one connected marginal consistency constraints
dxj qij (xi , xj ) = qi (xi ).
stationary conditions Lagrangian corresponding fractional Bethe
free energy (7) marginal consistency normalization constraints, one derive
iterative algorithm (3) corresponding Lagrange multipliers
consistency constraints (Yedidia et al., 2000). Similarly, approximate marginals
computed according (4). shown one-to-one correspondence
stationary points Bethe free energy (7) fixed points
message passing algorithm (3). Later, Section 4 link stable fixed points (3)
local minima (7).
2.2 Fractional Free Energies Message Passing Algorithm
mentioned introduction, case Gaussian models message passing algorithm
always converge. reason appears approximate marginals
may get indefinite negative definite covariance matrices. Welling Teh (2001) pointed
due unboundedness Bethe free energy.
Since FMF convex bounded Bethe free energy might unbounded,
seems plausible analyze fractional Bethe free energy
XZ
F ({qij , qk }) =
dxi,j qij (xi,j ) log ij (xi,j )
(8)
ij


XZ
X 1 Z
qij (xi,j )
+
dxi,j qij (xi,j ) log
+
dxk qk (xk ) log qk (xk ).
ij
qi (xi )qj (xj )
ij

k

introduced Wiegerinck Heskes (2003). Here, denotes set positive reals {ij }.
showed fractional Bethe free energy interpolates mean field
Bethe approximation. is, ij = 1 get Bethe free energy,
case ij tend 0, mutual information variables xi xj highly
penalized, therefore, (8) enforces solutions close mean field solution. also showed
fractional message passing algorithm derived (8) interpreted Pearls
message passing algorithm difference instead computing local marginals
like Pearls algorithmone computes local ij marginals.3 local ij marginals
correspond true local marginals ij = 1 local mean field approximations
ij = 0. resulting algorithm called fractional message passing algorithm
message updates defined
Z


new
(x
)
=
dxj ij (xi , xj )
jk (xj ) ji (xj )1 ,
(9)
ij
kj\i

approximate marginals computed according


qij (xi , xj ) ij (xi , xj )
il (xi ) ij (xi )1
jk (xj ) ji (xj )1 .
li\j

(10)

kj\i



Q
3. define marginals distribution p argmin{qk } p k qk , divergence
k
R

R
R
[p || q] = dxp(x) q(x)1 + dxp(x) + (1 ) dxq(x) /(1 ) (e.g., Minka, 2005).

7

fiCseke & Heskes

Power expectation propagation Minka (2004) approximate inference method
uses local approximations divergences. case Gaussian models power
expectation propagationwith fully factorized approximating distributionleads
message passing algorithm one derived (8) appropriate constraints.
Starting idea creating upper bound log partition function p
q exponential distributions, Wainwright et al. (2003) derived form (8)
ij chosen bound convex {qij , qk }.
Message passing works well practice, however, ways find local
minima fractional free energies like direct minimization w.r.t. parameterization approximate marginals qij qk (Welling & Teh, 2001). latter method
slower likely converge. following analyze Bethe free energy
expressed terms moment parameters approximate marginals qij . Later
Section 4 analyze stability conditions fractional message passing algorithm
expressing conditions term moment parameters approximate
marginals, show stable fixed points fractional Gaussian message passing
local minima fractional Bethe free energy.

3. Bounds Gaussian Bethe Free Energy
section analyze parametric form (8). show fractional Gaussian Bethe free energy non-increasing function . letting ij tend infinity, obtain lower bound free energies. turns condition
lower bound bounded pairwise normalizability
condition work Malioutov et al. (2006).
mentioned Section 2, without loss generality, work unit diagonal Q. define R matrix zeros diagonal Q = + R,
identity matrix. |R| matrix formed absolute values
Rs elements. use moment parameterization qij (xi,j ) = N (xi,j |mij , Vij )
, v ; v , v j ], v = v .
qk (xk ) = N (xk |mk , vk ), mij = (miij , mjij )T Vij = [vij
ij
ji ij
ij
ji
= mi v v = v k j k, embed
using mi

ij
ik
ik
R ij
R
marginalization ( dxj qij (xi , xj ) = qi (xi ) j) normalization ( dxj qj (xj ) = 1)
constraints parameterization. slight abuse notation matrix formed
diagonal elements vk off-diagonal elements vij denoted V (we take vij = 0
j), vector means = (m1 , . . . , mn )T vector variances
v = (v1 , . . . , vn )T . Substituting qij qk (8) one gets
1
1
F (m, V ) = hT + mT Qm + tr(QT V )
2
2 !
2
X
v
1
1
1X
ij

log 1

log (vk ) + C,
2
ij
vi vj
2
ij

(11)

k

C irrelevant constant. Note variables V independent, hence
minimizations F (m, V ) regard V carried independently.
8

fiBethe Free Energies Message Passing Gaussian Models

Property 1. F (m, V ) convex bounded (m, {vij }i6=j ) stationary point

= Q1 h
vij



p
1 + (2ij Rij )2 vi vj 1
= sign(Rij )
.
2ij |Rij |

(12)

Proof: Q positive definite definition, therefore, quadratic term convex
bounded. variables V independent minimum regard
achieved = Q1 h. One check second order derivative
F (m, V ) regard vij non-negative first order derivative one
2 v v . Since variables v independent, one conclude
solution vi vj vij
j
ij
F (m, V ) convex vij . independence V , follows F
convex (m, {vij }i6=j ).

2 , thus
Since Vij constrained covariance matrices, vi vj > vij
first logarithmic term (11) negative. consequence,

F1 (m, V ) F2 (m, V )



0 < 1 2 ,

1 2 taken element element. observation leads following
property.
Property 2. ij = , F non-increasing function .
F define constrained function
Using Property 1 substituting vij

1
1X
Fc (m, v) = hT + mT Qm +
vk
2
2
k
q

1X 1
1 + (2ij Rij )2 vi vj 1

2

ij ij
!
p
1 + (2ij Rij )2 vi vj 1
1 X 1

log 2
2
ij
(2ij Rij )2 vi vj
n(i,j)

1X

log(vk ) + C c ,
2

(13)

k

C c irrelevant constant. Property 2, follows choosing ij = ,
function (13) non-increasing function . makes sense take
verify whether get lower bound (13).
Lemma 1. v > 0, 0 1 1 2 1 following inequalities hold.


FMF (m, v) Fc1 (m, v) FB m, {vij
}, v


FB m, {vij
}, v Fc2 (m, v) . . .

1
. . . FMF (m, v)
v |R| v
2
Moreover, tight, is,


lim F m, {vij
()}, v = FMF (m, v)
0

9

fiCseke & Heskes





1

v |R| v.
lim F m, {vij
()}, v = FMF (m, v)
2
Proof: Since Bethe free energy specific case fractional Bethe free energy
()}, v) follow Property 2. Now, show
= 1, inequalities FB (m, {vij
upper lower bounds tight. function (1 + x2 )1/2 1 behaves 12 x2
neighborhood 0, therefore,


v 2 ()
log 1 ijvi vj
2 ()
vij
1

lim
lim vij
() = 0

lim
=
= 0,
0
0

vi vj 0


showing FMF (m, v) tight upper bound.
tends infinity,
p
1 + (2Rij )2 vi vj 1

= |Rij | vi vj
lim

2

1
log
lim


!
p
1 + (2Rij )2 vi vj 1
= 0,
(2Rij )2 vi vj

yielding tight lower bound


1

v |R| v.
lim F m, {vij
()}, v = FMF (m, v)

2



Let max (|R|) largest eigenvalue |R|. Analyzing boundedness lower
bound, arrive following theorem.
Theorem 1. fractional Bethe free energy (11) corresponding connected
Gaussian model, following statements hold
(1) max (|R|) < 1, F bounded > 0,
(2) max (|R|) > 1, F unbounded > 0,
P P 1
(3) max (|R|) = 1, F bounded
ij 2n.
ij

Proof: Since F interaction parameters V term
depending bounded due positive definiteness Q, simply
neglect term analyzing boundedness F . Let us write detail
lower bound fractional Bethe free energies form

1
v |R| v =
2

1
1
1 1
Q hT +
v (I |R|) v 1T log(v) + const.
2
2
2

FMF (m, v)

(14)

Statement (1): condition max (|R|) < 1 implies |R| positive definite. Now,
10

fiBethe Free Energies Message Passing Gaussian Models







log(x) x 1, thus 12 v (I |R|) v 1T log( v) 21 v (I |R|) v 1T v + n.
latter bounded follows (14) bounded
well. According Lemma 1, boundedness (14) implies fractional Bethe free
energies bounded below.
Statement (2): assumed Gaussian network connected undirected. According Perron-Frobenius theory non-negative matrices (e.g., Horn & Johnson,
2005), |R| simple maximal eigenvalue max (|R|) elements eigenvector umax corresponding positive. Let us take fractional Bethe free energy

analyze behavior v = tumax . large values
(1 + (2ij Rij )2 (uimax ujmax )2 t4 )1/2 ' 2ij |Rij |uimax ujmax t2 , therefore, sum second
third term (13) simplifies (1 max (|R|))t2 term dominates
logarithmic ones . result, limit independent choice ij
tends whenever max (|R|) > 1.
Statement (3): max (|R|) = 1, direction quadratic term

dominate v = tumax . Therefore, analyze P
behavior loga1
rithmic terms (13) . large ts behave ( ij ij
2n) log(t).
c
reason, boundedness F thus F depends condition
statement (3).

shown Malioutov et al. (2006) condition max (|R|) < 1 equivalent
condition pairwise normalizability. Therefore, pairwise normalizability
sufficient condition message passing algorithm converge, also necessary
condition fractional Gaussian Bethe free energies bounded. Using Lemma 1,
show suitably chosen > 0 always exists constrained
fractional free energy Fc possesses local minimum 0 < < (Property A2
Section Appendix).
Example case models adjacency matrix (non-zero entries R) corresponding Kregular graph4 equal interaction weights Rij = r, maximal eigenvalue |R| max (|R|) = Kr eigenvector corresponding eigenvalue 1.
(We define 1 vector elements equal 1.) model symmetric
verifying stationary point conditions, turns choice r
exists local minimum, also lies direction 1. One show
model pairwise normalizable (Kr > 1), critical r
p fractional
Bethe free energy possesses local minimum rc (K, ) = 1/2 (K )
valid r critical
p fractional Bethe free energies possesses local
minimum c (K, r) = 21 K(1 1 1/(Kr)2 ). results illustrated Figure 2.
(Note 2regular graphs, valid models pairwise normalizable possess
unique global minimum.)

Kregular graphs, convexity fractional Bethe free energy terms
{qij , qk } requires K, much stronger condition c (K, r). Thus, choose
sufficiently large Bethe free energy guaranteed unique global
minimum, minimum unbounded.

4. Kregular graph graph nodes connected K nodes.

11

fiCseke & Heskes

$

!"

$

)

!"

+0")12&3,)*.&456
+)D)1"7+834.59
+0!:;
+< VTUWff.fi
+0+

#

%&'(&)*+&&)&,&+-.&/

%&'(&)*+&&)&,&+-.&/

#

!"

834.5



!"

"

!"



!"

)

_0")12&3,)*.&456
_)D)7"8"!9!"":
_0!)1%&'(&6
_0_;

!"

_)0)')14<=&+)><?,56


!"

"

!"

)





!"



!"

"

!"


!

!"

!"



)



!"

!"



!"

"

!"


!

!"



!"

Figure 2: Visualizing critical parameters symmetric K-regular Gaussian model Rij = r.
Plots
left panel correspond constrained fractional Bethe free energies Fc

v = 1 8 node 4regular Gaussian model r=0.27 (Kr > 1) varying
.

Plots right panel correspond constrained Bethe free energies F1c v = 1
8 node 4regular Gaussian model varying r. Here, rvalid supremum
rs model valid, is, Q positive definite.

example disproves conjecture Welling Teh (2001), is, even
Bethe free energy bounded below, possess finite local minimum
message passing minimization algorithms converge.

4. Message Passing Algorithm Gaussian Models
section, turn attention towards properties message passing algorithm Gaussian models. Following similar line argument Watanabe Fukumizu
(2009) show stable fixed points message passing algorithm correspond local
minima Bethe free energy. use moment parameterization introduced
previous sections. way proceed following: (1) make linear expansion
message passing iteration fixed point, (2) express linear expansion terms
moment parameters corresponding fixed point finally (3) connect properties latter properties Hessian Bethe free energy using
matrix determinant lemma.
form equation (9) implies messages ij (xi ) univariate Gaussian
functions, thus express terms two scalar (canonical) parameters ij
ij log ij (xi ) = ij x2i /2 + ij xi + ijj , ij irrelevant constants.
expressed terms ij ij , damped message passing algorithm (9) translates
12

fiBethe Free Energies Message Passing Gaussian Models


j
hj +
ij


new
ij

=

(1 )ij +

P

jk + (1 )ji




kj\i

P
ij hi Rij

j

ij
+
jk + (1 )ji

(15)

kj\i



new
ij

=

1
X


j
2
2 Rij
ij
+
jk + (1 )ji
(1 )ij + ij



kj\i

(16)
, j , h R parameters Section 2.1, R = Q
ij

ij
ij
ij
ij
ij
assumption Qii = 1. approximate marginals qij (10) might normalizable,
message passing iteration (15) (16) stays well defined unless zero
denominator rhs. rarely happens practice. However,
common message passing converges intermediate steps
approximate marginals qij normalizable. often remedied choosing
appropriate damping parameter .
iteration (16) ij independent ij iteration (15) ij
linear ij . interesting see h = 0 neither constrained Bethe
free energy (13) message passing algorithm (16) depend sign Rij .
relevant compute meanswhen h 6= 0and signs correlations
(12). result, marginal variances computed either minimizing Bethe free
energy running message passing algorithm depend |R|, similarly
constrained fractional free energy Fc .

4.1 Stability Gaussian Message Passing Algorithm
following analyze stability message passing iteration fixed points,
is, stationary points Lagrangian corresponding constrained minimization Gaussian Bethe free energy. reiterate use G = (V, E) denote
graph corresponding Q, namely, V = {1, . . . , n} E = {(i, j) : Qij 6= 0}. vector R|E| , corresponding set messages {ij }ij , composed concatenation
ij ij followed ji (ij, ji) blocks follow lexicographic order w.r.t.
ij < j. vector consists variables ij follows similar structure .
j
define r, h, R|E| rij = rji = Rij , hij = hj ij = ij
. also define
|E| |E| matrix

1 j = k

1 kl = ji
Mij,kl ()

0 otherwise
encodes weighted edge adjacency corresponding G . number nonzero elements M(), scales roughly nnzeros (Q)2 /n, nnzeros (Q) denotes
number non-zeros Q. Since parallel message update given Equations (15)
(16) rewritten terms two matrix-vector multiplications element element
operations vectors, computational complexity update also scales roughly
nnzeros (Q)2 /n.
13

fiCseke & Heskes

notation, local linearization update equations (15) (16)
written
( new , new )
(, ) = (1 )I . . .
(, )






h+M()
1
diag r +M() M() diag r (+M())2 M()

,


+
1

0
diag 2 r 2 (+M())
M()
2

(17)

operations vectors element element. stability fixed point
( , ) depends union spectra

J ( , ) 1 diag r( + M() )1 M()


J ( , ) 1 diag 2 r 2 ( + M() )2 M().
important point stability properties depend R
independent h.
goal connect stability properties message passing algorithm
properties Bethe free energy. Therefore, express stability properties terms
moment parameters approximate marginals. leads normalizable approximate marginals qij (xi , xj ), use (10) identify local covariance
parameters Vij defined Section 3, without enforcing marginal matching
= v . correspondence given
constraints vij
ik
"


vij
vij

vij
j
vij


=

#1

1

=

"

j
vij
vij

vj v2
vij
ij
ij
P
+
il + (1 )ij
ij

vij

vij

#
(18)
Rij

li\j
j
ij

Rij

+

P

jk + (1 )ji



.

kj\i
, v j r
approximate local covariances vij fully determined vij
ij
ij
form (12). leaves us |E| moment parameters computed
, v = v j (v) =
message passing algorithm. Let v R|E| defined vij = vij
ji
ij
ij
v j v 2 ), v
vij /(vij
ij
ij computed according (12). checked
ij
mapping v continuous bijective. implies canonical
moment parameter transformation (18) written y(v) = + M(). Since
M() singular = K graph G K-regularsee Property A1
Section Appendix detailsfor rest cases, continuous,
bijective mapping moment parameters v canonical parameters
lead normalizable approximate marginals.
= v v
fixed point ( , ) moment matching, is, vij

ik
k, j i, therefore express stability properties terms moment parameters

14

fiBethe Free Energies Message Passing Gaussian Models

v = (vi , . . . , vn ). Using p
(18) defining diagonal matrix R|E||E|
diagonal elements Dij,ij = vi , get

, v)
v
(,
v
ij

j
= 1 diag q
M()


vi vj


DJ ( (v ))D 1

(19)


2





J ( (v ))D

2

=

1

diag

vij (, vi , vj )2
vi vj

!
M().

(20)


Let (A) denote
spectrum matrix A. Since DJ 1 = (J )

2 J 2 = (J ), sufficient analyze spectral properties right hand
sides equations (19) (20).
message passing algorithm asymptotically stable (v )
max { (J ( (v ))) , (J ( (v )))} < 1,

(21)

() denotes spectral radius. interesting see although functional
forms free energies message passing algorithms different Gaussian
discrete case, stability conditions similar forms. allow us use
results Watanabe Fukumizu (2009). next section, show
implications condition properties Hessian free energy.
4.2 Stable Fixed Points Local Minima
Hessian H[F ] Bethe free energy (11) depends moment parameters
vi , vj vij . Note now, vij unconstrained parameters. (|E|/2 + 2n)
(|E|/2 + 2n) matrix form


Q


0
H[F ](V ) =

0

diag
h 2

0 2

F
2 vij


h

F
vij vi ij,i

0

2 F
vij vi ij,i

h



2 F
vi vj i,j




,


use V denote collection parameters vi , = 1, . . . , n vij , j.
Since block corresponding partial differentials w.r.t. vij diagonal positive
elements, Hessian positive definite V Schur complement corresponding
15

fiCseke & Heskes

partial differentials w.r.t. vi positive definite V . latter given
X 2 F 2 F 1
2 F
v

Hii [F ](V ) =
vi vi
vij vi
vij
ij


1 1
1 X c4ij
=
1
+
,
4
2 vi2

1

c
ij
ij

1
2
2
F
F 2 F 2 F
v
Hij [F ](V ) =

vi vj
vij vi vij vj 2 vij
1 1 1 c2ij
=
,
2 vi vj 1 c4ij

use notation cij = vij / vi vj .
Now, would like connect condition (21) positive definiteness
matrix H v [F ](V ). following show stable fixed points (v ) Gaussian
message passing algorithm, satisfying (21), correspond local minima Gaussian free
energy F v vij (, vi , vj ).
According Watanabe Fukumizu (2009), arbitrary vector w R|E| one



det I|E| 1 diag (w) M() = det + 1 A(w)
(1 wij wji ),
(22)
ij


Aii (w) =

X
ij

wij wji
1 wij wji



Aij (w) =

wij
.
1 wij wji

(23)

proof application matrix determinant lemma reproduction
found Section Appendix. Equation (22) expresses determinant
|E||E| matrix determinant nn matrix.

Let c R|E| cij (V ) = vij / vi vj . substituting w = c(V )2 (23), find


det 1 diag c(V )2 M() = f (V ) det (H[F ](V )) ,
(24)
f (V ) positive function defined
f (V ) = 2n |E| |Q|1


k

vk2


2
2
vi vj vij
ij

2
vi vj + vij

2
vij
1
vi vj

!
.

V corresponding normalizable approximate marginals. Now, adapting theorem
Watanabe Fukumizu (2009)

following theorem.
Theorem 1 diag c(V )2 M() C \ R1 Hessian (Gaussian)
Bethe free energy H[F ] positive definite
V.
1
2
Proof: assumption
diag c(V ) M() C \ R1 implies
det 1 diag(c(V )2 M()) > 0. choosing Vij (t) = tvij [0, 1], find
2
c(V(t))2 = t2 c(V )2 , therefore, det 1 diag(c(V (t) )M()) > 0 [0, 1].
16

fiBethe Free Energies Message Passing Gaussian Models

implies det (H[F ](V (t))) > 0 [0, 1]. Since H[F ](V (0)) = > 0
eigenvalues H[F ](V (t)) change continuously w.r.t. [0, 1], results
H[F ](V (1)) > 0 V , thus satisfying condition theorem.



fixed point ( , ) stable
max{(J ( (v ))), (J ( (v )))} < 1.
1

2
implies diag(c(V ) )M() C \ R1 leads following property.

Property 3. Stable fixed points ( , ) damped Gaussian message passing algorithm (16) local minima Gaussian Bethe free energy Fc (13) v ( ).
shows boundedness F existence local minima case
unbounded F plays significant role convergence Gaussian message passing. illustrate Section 5. fractional message passing algorithm converges
converges set messages corresponds local minimum fractional free energy. also implies mean parameters local approximate
marginals exact (see Property 1. Section 3). Note observations Section 3
Property A2 Appendix together Property 3 imply always
range values fractional free energy possesses local minimum
fractional message passing converge.
4.3 Damping Fractional Parameters
local stability condition (21) independent damping parameter . Therefore,
alter local stability properties, makes iteration slower numerically stable, is, dampen possible periodic trajectories message
passing algorithm.
fractional parameter characterizes inference process seen
example previous sections, choosing smaller create local minima.
particular case h = 0, somewhat similar property message passing
updates well. Let R|E| set messages lead normalizable approximate
marginals. set characterized model parameters |R|, . reiterate
v j continuous bijective
elements v local variances vij
ij
|E|

mapping v R+ given y(v) = + M(), unless = K G
K-regular. allows us study q
stability properties terms moment parameters
, v j )/
v(). Let c(v, ) = [vij (, vij
ij

v j ] vector local correlations. using
vij
ij ij

Gershgorins theorem (Horn & Johnson, 2005) c(v, )2 c(v, ), find
eigenvalue 1 diag(c(v, ))M() 1 diag(c(v, ))2 M()


|| max 1 c(v, ) [(nj 1) + |1 |] .
i,j

h = 0, updates , rhs equation depends
1 c(v, )2 (see Equations (17) (20)) lim 1 c(v, )2 = 0, thus, small
0

values help achieve convergence. However, h 6= 0 term 1 c(v, )
dominating effects decreasing towards zero ambiguous.
17

fiCseke & Heskes

5. Experiments
implemented direct minimization fractional message passing analyzed
behavior different values max (|R|). reasons simplicity, set ij
equal. results small scale model summarized Figure 3. Note
good correspondence behavior fractional Bethe free energies
direction eigenvalue corresponding max (|R|) convergence Newton
method. Newton method started different initial points. experienced
max (|R|) > 1 setting initial value v0 = t2 u2max , algorithm
converge high values t. explained top plots Figure 3:
high values t, initial point might convergence region local
minimum. fractional message passing algorithm used two types initialization:
=
(1) max (|R|) < 1 set ij normalizable setting ij
= 1/n ,
|Rij |ujmax /max uimax (Malioutov et al., 2006), (2) max (|R|) 1, used ij

is, symmetric partitioning diagonal elements. set initial messages
approximate marginals normalizable first step iteration.
experienced behavior similar described Welling Teh (2001)
standard message passing, namely, fractional message passing direct minimization either
converge fail converge. experiments combination Theorem 1
show max (|R|) > 1, standard message passing best converges local
minimum Bethe free energy. standard message passing fails converge, one
decrease search stationary pointpreferably local minimumof
corresponding fractional free energy.
seen results right panels Figure 2, model
longer pairwise normalizable, local minimum unbounded global minimum
viewed natural continuation (bounded) global minimum pairwise
normalizable models. explains quality approximation local
minimum models pairwise normalizable still comparable
global minimum models pairwise normalizable.

6. Conclusions


seen, FMF FMF 21 v |R| v provide tight upper lower bounds
Gaussian fractional Bethe free energies. turns pairwise normalizability
sufficient condition message passing algorithm converge, also
necessary condition Gaussian fractional Bethe free energies bounded
below.
model pairwise normalizable, lower bound bounded, direct
minimization message passing converging. experiments converged
minimum. suggests pairwise normalizable case, fractional Bethe
free energies possess unique global minimum.
model pairwise normalizable, none fractional Bethe free energies
bounded below. However, always range values
fractional free energy possesses local minimum direct minimization
fractional message passing converge. Thus, decreasing towards zero, one gets
18

fiBethe Free Energies Message Passing Gaussian Models

&

!"

&

(

!"

)*+,(-.*/0
_(D(1"2"!3!""4
5*'6*(7_8!9
:;<*=(>;?,0

%

!"

%

!"

#

#

!"

!"

"

"

!"

!"



!"

(





"

!"

!"

!

#

!"
'

!"

$

!"

!"

Function value convergence

Function value convergence

6
5
4
3
2
1
0

"

!"

!

!"
'

#

$

!"

!"

2

0

10

10


7
6
5
4
3
2
1
0
1

2

10

Error variances convergence

Newton method
Message passing
1

10

0

10

1

10



8

7

1

(

!"

8

Error variances convergence

(

)*+,(-.*/0
_(D(1"2"!3!""4
5*'6*(7_8!9
:;<*=(>;?,0

2

10

0

10

0

10

10


2

Newton method
Message passing
1

10

0

10

1

2

10

0

10


10

2

10

2

10

10


2

Figure 3: top panels show constrained
fractional Bethe free energies Gaussian model

8 variables direction v = tumax , umax eigenvector corresponding max (|R|) max (|R|) = 0.9 (top-left) max (|R|) = 1.1 (top-right).
thick lines functions FMF (dashed), FB (dashed dotted) lower bound


FMF 12 v |R| v (continuous). thin lines constrained -fractional free
energies Fc [102 , 102 ]. Center panels show final function values
convergence Newton method. bottom panels
show || ||2 error approximation single node standard deviations = v. Missing values indicate
non-convergence.
19

fiCseke & Heskes

closer mean field energy finite local minimum appear (Property A2
Appendix). experienced suitable range s,s initial values
fractional Gaussian message passing made converge.
mentioned Section 2.1, ij correspond using local ij divergences applying power expectation propagation fully factorized approximating distribution.
Seeger (2008) reports expectation propagation converge, applying power
expectation propagation < 1 helps achieve convergence. case problem
addressed paper behavior explained observation small
make finite local minima likely occur thus prevents covariance matrices
becoming indefinite even non positive definite. Although common reason
using < 1 EP numerical robustness, also implies finding saddle point
-fractional EP free energy. might interesting investigate whether
reason convergence likely case Gaussian fractional message passing.
Wainwright et al. (2003) propose convexify Bethe free energy discrete models
choosing ij sufficiently large fractional Bethe free energy unique
global minimum. strategy appears fail Gaussian models. Convexification makes
possibly useful finite local minima disappear, leaving unbounded global minimum. case general hybrid models, use convexification still
unclear.
example Section 3 disproves conjecture work Welling Teh (2001):
even Bethe free energy bounded below, possess finite local
minimum message passing minimization algorithms converge.
shown stable fixed points Gaussian fractional message passing
algorithms local minima fractional Bethe free energy. Although existence
local minimum guarantee convergence message passing algorithm,
practice experienced existence local minimum implies convergence.
Based results, hypothesize pairwise normalizability hold,
Gaussian Bethe free energy Gaussian message passing algorithm ( = 1)
two types behavior:
(1) Gaussian Bethe free energy possesses unique finite local minimum
optimization methods converge starting from, say, mean field solution
vi = 1/Qii ; Gaussian message passing corresponding unique stable fixed
point, converge suitable starting point sufficient damping,
(2) finite local minimum exists, thus, optimization message
passing algorithm diverge.
using fractional free energy fractional message passing varying ,
one switch behaviors. Computing critical c (|R|) general |R|
remains open question. believe properties free energies K-regular
symmetric models (Section 3), critical values easily computed, give good
insight properties free energies general Gaussian models.
20

fiBethe Free Energies Message Passing Gaussian Models

Acknowledgments
would like thank Jason K. Johnson sharing ideas properties
message passing algorithm K-regular models. would also like thank anonymous
reviewers valuable comments earlier versions manuscript. research
reported paper supported VICI grant 639.023.604 Netherlands
Organization Scientific Research (NWO).

Appendix A. Properties Proofs
Lemma A1. (Watanabe & Fukumizu, 2009) graph G = (V, E), edge adjacency
matrix M() (defined Section 4.1), arbitrary vector w R|E| , one


det I|E| 1 diag (w) M() = det I|V | + 1 A(w)
(1 wij wji ),
ij


Aii (w) =

X
ij

wij wji
1 wij wji

Aij (w) =



wij
.
1 wij wji

Proof: reproduce proof somewhat simplified form. Let us define Uij, = eTj ,
Vij, = eTi ek k th unit vector Rn



Sij,ij Sij,ji
0 1
,
=
Sji,ij Sji,ji
1 0
M() = U V S. Let us define W R|E||E| diagonal matrix
wij,ij = wij . Using matrix determinant lemma reads

det 1 W U V

= det + W 1 W U V



= det 1 W U V (I + W S)1 det (I + W S)


= det 1 V (I + W S)1 W U det (I + W S).
(ij, ji) block (I + W S)1 W


1
1
wij
wij
1
0
1 wji wji wji

0
wji


=

1
1 wji wji



wij
wji wij

wij wji
wji



thus, define V (I + W S)1 W U
X wij wji
wij
Ai,i =
Ai,j =
.
1 wij wji
1 wij wji
ij

completes proof matrix determinant lemma (22) Section 4.2.

21



fiCseke & Heskes

Property A1. matrix M() = U V singular K-regular graphs
= K.
P
Proof: Let x R|E| =PM()x. yij = kj xjk xji . Let us fix j,
yij = 0 means kj xjk = xji i. hold graph
K-regular, = K xij equal xij = 0 pair indices ij.

Property A2. suitably chosen > 0, exists constrained
fractional free energy Fc possesses local minimum 0 < < .

Proof: Let us define vM
F = argminv FM F (v)


UM
F = {v : FM F (v) FM F (vM F ) + 2} .

form FM F implies always choose UM
F proper subset
n

n
positive quadrant R , words, UM F R+ . due properties FM F
(continuous convex, unique finite global minimum attained finite value),





domain UM
F closed, bounded, convex vM F UM F \ UM F , is, vM F

n
c

interior UM F . Since FM F F (v) continuous R+ , set UM F closed
bounded lim Fc (v) = FM F (v) (pointwise convergence) v Rn+ , follows Fc
0


c
converges uniformly UM
F 0. This, together monotonicity F w.r.t. ,
implies exists FM F (vM F ) < Fc (vM F ) < FM F (vM F ) 0 <
. Let us fix . known that, since U
< v UM
F
F closed bounded
) + 2

c
c
F continuous, F attains extrema UM F . Since FM F (v) = FM F (vM
F
)+
c

c

v UM F F (v) > FM F (v) v UM F follows F (v) > FM F (vM
F


c

).
v UM F . chosen FM F (vM F ) < F (vM F ) < FM F (vM
F
latter two conditions imply one extrema local minimum
.
interior UM

F

References
Bickson, D. (2009). Gaussian Belief Propagation: Theory Application. Ph.D. thesis,
Hebrew University Jerusalem.
Cseke, B., & Heskes, T. (2008). Bounds Bethe free energy Gaussian networks.
McAllester, D. A., & Myllymaki, P. (Eds.), UAI 2008, Proceedings 24th
Conference Uncertainty Artificial Intelligence, pp. 97104. AUAI Press.
Heskes, T. (2003). Stable fixed points loopy belief propagation minima Bethe
free energy. Becker, S., Thrun, S., & Obermayer, K. (Eds.), Advances Neural
Information Processing Systems 15, pp. 359366, Cambridge, MA. MIT Press.
Heskes, T., Opper, M., Wiegerinck, W., Winther, O., & Zoeter, O. (2005). Approximate
inference techniques expectation constraints. Journal Statistical Mechanics:
Theory Experiment, 2005, P11015.
Heskes, T. (2004). uniqueness loopy belief propagation fixed points. Neural
Computation, 16, 23792413.
Horn, R. A., & Johnson, C. (2005). Matrix Analysis. Cambridge University Press, Cambridge, UK.
22

fiBethe Free Energies Message Passing Gaussian Models

Jaakkola, T. (2000). Tutorial variational approximation methods. Opper, M., & Saad,
D. (Eds.), Advanced mean field methods: theory practice, pp. 129160, Cambridge,
MA. MIT Press.
Johnson, J. K., Bickson, D., & Dolev, D. (2009). Fixing convergence Gaussian belief
propagation. CoRR, abs/0901.4192.
Malioutov, D., Johnson, J., & Willsky, A. (2006). Walk-sums belief propagation
Gaussian graphical models. Journal Machine Learning Research, 7, 20312064.
Minka, T. P. (2004). Power EP. Tech. rep., Microsoft Research Ltd., Cambridge, UK,
MSR-TR-2004-149.
Minka, T. P. (2005). Divergence measures message passing. Tech. rep. MSR-TR-2005173, Microsoft Research Ltd., Cambridge, UK.
Moallemi, C., & Roy, B. V. (2006). Consensus propagation. Weiss, Y., Scholkopf, B., &
Platt, J. (Eds.), Advances Neural Information Processing Systems 18, pp. 899906.
MIT Press, Cambridge, MA.
Murphy, K., Weiss, Y., & Jordan, M. I. (1999). Loopy belief propagation approximate
inference: empirical study. Proceedings Fifteenth Conference Uncertainty Artificial Intelligence, Vol. 9, pp. 467475, San Francisco, USA. Morgan
Kaufman.
Nishiyama, Y., & Watanabe, S. (2009). Accuracy loopy belief propagation Gaussian
models. Neural Networks, 22 (4), 385 394.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufman Publishers, San Mateo, CA.
Rusmevichientong, P., & Roy, B. V. (2001). analysis belief propagation turbo
decoding graph Gaussian densities. IEEE Transactions Information Theory,
47, 745765.
Seeger, M. W. (2008). Bayesian inference optimal design sparse linear model.
Journal Machine Learning Research, 9, 759813.
Takahashi, K., Fagan, J., & Chin, M.-S. (1973). Formation sparse impedance matrix
application short circuit study. Proceedings 8th PICA Conference.
Wainwright, M., Jaakkola, T., & Willsky, A. (2003). Tree-reweighted belief propagation
algorithms approximate ML estimation via pseudo-moment matching. Bishop,
C., & Frey, B. (Eds.), Proceedings Ninth International Workshop Artificial
Intelligence Statistics. Society Artificial Intelligence Statistics.
Watanabe, Y., & Fukumizu, K. (2009). Graph zeta function Bethe free energy
loopy belief propagation. Bengio, Y., Schuurmans, D., Lafferty, J., Williams, C.
K. I., & Culotta, A. (Eds.), Advances Neural Information Processing Systems 22,
pp. 20172025. MIT Press.
Weiss, Y., & Freeman, W. T. (2001). Correctness belief propagation Gaussian graphical
models arbitrary topology. Neural Computation, 13 (10), 21732200.
23

fiCseke & Heskes

Welling, M., & Teh, Y. W. (2001). Belief optimization binary networks: stable alternative loopy belief propagation. Breese, J. S., & Koller, D. (Eds.), Proceedings
17th Conference Uncertainty Artificial Intelligence, pp. 554561. Morgan
Kaufmann Publishers.
Wiegerinck, W., & Heskes, T. (2003). Fractional belief propagation. Becker, S., Thrun,
S., & Obermayer, K. (Eds.), Advances Neural Information Processing Systems 15,
pp. 438445, Cambridge, MA. MIT Press.
Yedidia, J. S., Freeman, W. T., & Weiss, Y. (2000). Generalized belief propagation.
Advances Neural Information Processing Systems 12, pp. 689695, Cambridge, MA.
MIT Press.
Zoeter, O., & Heskes, T. (2005). Change point problems linear dynamical systems.
Journal Machine Learning Research, 6, 19992026.

24

fiJournal Artificial Intelligence Research 41 (2011) 527-551

Submitted 03/11; published 08/11

Controlling Complexity Part-of-Speech Induction
Joo V. Graa

JOAO . GRACA @ L 2 F. INESC - ID . PT

L2 F INESC-ID
Lisboa, Portugal

Kuzman Ganchev

KUZMAN @ GOOGLE . COM

Google Inc.
New York, NY, USA

Lusa Coheur

LUISA . COHEUR @ L 2 F. INESC - ID . PT

2

L F INESC-ID
Lisboa, Portugal

Fernando Pereira

PEREIRA @ GOOGLE . COM

Google Inc.
Mountain View, CA, USA

Ben Taskar

TASKAR @ CIS . UPENN . EDU

Computer & Information Science
University Pennsylvania

Abstract
consider problem fully unsupervised learning grammatical (part-of-speech) categories unlabeled text. standard maximum-likelihood hidden Markov model
task performs poorly, weak inductive bias large model capacity. address
problem refining model modifying learning objective control capacity via parametric non-parametric constraints. approach enforces word-category association sparsity,
adds morphological orthographic features, eliminates hard-to-estimate parameters rare
words. develop efficient learning algorithm much computationally intensive standard training. also provide open-source implementation algorithm.
experiments five diverse languages (Bulgarian, Danish, English, Portuguese, Spanish) achieve
significant improvements compared previous methods task.

1. Introduction
Part-of-speech (POS) categories elementary building blocks syntactic analysis text
play important role many natural-language-processing tasks, machine translation
information extraction. English handful languages fortunate enough
comprehensive POS-annotated corpora Penn Treebank (Marcus, Marcinkiewicz,
& Santorini, 1993), worlds languages extremely limited linguistic resources.
unrealistic expect annotation efforts catch explosion unlabeled electronic
text anytime soon. lack supervised data likely persist near future
investment required accurate linguistic annotation: took two years annotate 4,000 sentences
syntactic parse trees Chinese Treebank (Hwa, Resnik, Weinberg, Cabezas, & Kolak,
2005) four seven years annotate 50,000 sentences across range languages (Abeill,
2003).

c
2011
AI Access Foundation. rights reserved.

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

Supervised learning taggers POS-annotated training text well-studied task,
several methods achieving near-human tagging accuracy (Ratnaparkhi, 1996; Toutanova, Klein,
Manning, & Singer, 2003; Shen, Satta, & Joshi, 2007). However, POS induction one
access labeled corpus difficult task much room improvement.
recent literature, POS induction used refer two different tasks. first one,
addition raw text, given dictionary containing possible tags word
goal disambiguate tags particular word occurrence (Merialdo, 1994). second
task, given raw text, dictionary provided; goal cluster words
grammatical behavior. work, target latter, challenging, unsupervised POS
induction task.
Recent work task typically relies distributional morphological features, since words
grammatical function tend occur similar contexts common morphology (Brown, deSouza, Mercer, Pietra, & Lai, 1992; Schtze, 1995; Clark, 2003). However,
statistical regularities enough overcome several challenges. First, algorithm
decide many clusters use broad syntactic categories (for instance, whether distinguish
plural singular nouns). Second, category size distribution tends uneven. example, vast majority word types open class (nouns, verbs, adjectives), even among
open class categories, many nouns adjectives. runs contrary learning
biases commonly-used statistical models. common failure models clump several
rare categories together split common categories.
individual word types, third challenge arises ambiguity grammatical role
word sense. Many words take different POS tags different occurrences, depending
context occurrence (the word run either verb noun). approaches assume
(for computational statistical simplicity) word one tag, aggregating
local contexts distributional clustering (Schtze, 1995). one-tag-per-word
assumption clearly wrong, across many languages annotated corpora,
methods perform competitively methods assign different tags word
different contexts (Lamar, Maron, Johnson, & Bienenstock, 2010). partly due typical
statistical dominance one tags word, especially corpus includes single genre,
news. reason less restrictive models encode useful bias
words typically take small number tags.
approaches make one-tag-per-word assumption take form hidden
Markov model (HMM) hidden states represent word classes observations
word sequences (Brown et al., 1992; Johnson, 2007). Unfortunately, standard HMMs trained
maximize likelihood perform poorly, since learned hidden classes align well true
POS tags. Besides potential model estimation errors due non-convex optimization involved
training, pernicious problem. Typical maxima likelihood align well
maxima POS tag accuracy (Smith & Eisner, 2005; Graa, Ganchev, Pereira, & Taskar, 2009),
suggesting serious mismatch model data.
work, significantly reduce modeling mismatch combining three ideas:
standard HMM treats words atomic units, without using orthographic morphological information. information critical generalization many languages (Clark,
2003). address problem, reparameterize standard HMM replacing multinomial emission distributions maximum-entropy models (similar work Berg528

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

Kirkpatrick, Bouchard-Ct, DeNero, & Klein, 2010 Graa, 2010). allows use
orthographic morphological features emission model. Moreover, standard
HMM model large number parameters: number tags times number
word types. presents extremely rich model space capable fitting irrelevant correlations data. address problem dramatically reduce number parameters
model discarding features small support corpus, is, involving
rare words word parts.
HMM model allows high level ambiguity tags word. result,
maximizing marginal likelihood, common words typically tend associated every
tag non-trivial probability (Johnson, 2007). However, natural property POS
categories across many languages annotation standards word small
number allowed tags. address problem use posterior regularization (PR)
framework (Graa, Ganchev, & Taskar, 2007; Ganchev, Graa, Gillenwater, & Taskar, 2010)
constrain ambiguity word-tag associations via sparsity-inducing penalty
model posteriors (Graa et al., 2009).
show proposed extensions improves standard HMM performance,
moreover, gains nearly additive. improvements significant across different
metrics previously proposed task. instance, 1-Many metric, method attains
10.4% average improvement regular HMM. also compare proposed method
eleven previously proposed approaches. languages English metrics except 1-1,
method achieves best published results. Furthermore, method appears stable
across different testing scenarios always shows competitive results. Finally, show
induced tags used improve performance supervised POS tagging system
limited labeled data scenario. open-source software POS induction evaluation
available http://code.google.com/p/pr-toolkit/.
paper organized follows. Section 2 describes basic HMM POS induction
maximum-entropy extension. Section 3 describes standard EM sparsity-inducing estimation
method. Section 4 presents comprehensive survey previous fully unsupervised POS induction
methods. Section 5 provide detailed experimental evaluation method. Finally,
Section 6, summarize results suggest ideas future work.

2. Models
model experiments based first order HMM. denote sequence
words sentence boldface x sequence hidden states correspond partof-speech tags boldface y. sentence length l, thus l hidden state variables
yi {1, . . . , J}, 1 l J number possible POS tags, l observation variables
xi {1, . . . , V }, 1 l, V number word types. simplify notation, assume
every tag sequence prefixed conventional start tag y0 = start, allowing us write
p(y1 |y0 ) initial state probability HMM.
probability sentence x along particular hidden state sequence given by:
p(x, y) =

l


pt (yi | yi1 )po (xi | yi ),

i=1

529

(1)

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

po (xi | yi ) probability observing word xi given state yi (emission
probability), pt (yi | yi1 ) probability state yi , given previous hidden
state yi1 (transition probability).
2.1 Multinomial Emission Model
Standard HMMs use multinomial emission transition probabilities. is, generic word
xi tag yi , observation probability po (xi | yi ) transition probability pt (yi | yi1 )
multinomial distributions. experiments refer model simply HMM. model
large number parameters large number word types (see Table 1).
common convention follow lowercase words well map words occurring
corpus special token unk.
2.2 Maximum Entropy Emission Model
work, use simple modification HMM model discussed previous section:
represent conditional probability distributions maximum entropy (log-linear) models. Specifically, emission probability expressed as:
exp( f (x, y))
0
x0 exp( f (x , y))

po (x|y) = P

(2)

f (x, y) feature function, x ranges word types, model parameters.
refer model HMM+ME. addition word identity, features include orthographyand morphology-inspired cues presence capitalization, digits, common suffixes.
feature sets described Section 5. idea replacing multinomial models HMM
maximum entropy models new applied different domains (Chen,
2003), well POS induction (Berg-Kirkpatrick et al., 2010; Graa, 2010). key advantage
representation allows much tighter control expressiveness
model. many languages helpful exclude word identity features rare words order
constrain model force generalization across words similar features. Unlike mapping
rare words unk token multinomial setting, maxent model still captures
information word features. Moreover, reduce number
parameters even using lowercase word identities still keeping case information
using case feature. Table 1 shows number features used different corpora. Note
reduced feature set order magnitude fewer parameters multinomial model.

3. Learning
Section 5 describe experiments comparing HMM model model three
learning scenarios: maximum likelihood training using EM algorithm (Dempster, Laird, & Rubin, 1977) HMM HMM+ME, gradient-based likelihood optimization HMM+ME
model, PR sparsity constraints (Graa et al., 2009) HMM HMM+ME.
section describes three learning algorithms.
following, denote whole corpus, list sentences, X = (x1 , x2 , . . . , xN )
corresponding tag sequences = (y1 , y2 , . . . , yN ).

530

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

3.1 Maximum Likelihood EM
Standard HMM training seeks model parameters maximize log-likelihood observed
data:
X
p (X, Y)
(3)
Log-Likelihood: L() = log


X whole corpus. Since model assumes independence sentences ,
log

X

p (X, Y) =

N
X

log

X

(4)

yn

n=1



p (xn , yn ),

use corpus notation consistency Section 3.3. latent variables
Y, log-likelihood function HMM model convex model parameters,
model fitted using EM algorithm. EM maximizes L() via block-coordinate ascent lower
bound F (q, ) using auxiliary distribution latent variables q(Y) (Neal & Hinton, 1998).
Jensens inequality, define lower-bound F (q, ) as:
L() = log

X

q(Y)



p (X, Y) X
p (X, Y)

q(Y) log
= F (q, ).
q(Y)
q(Y)

(5)



rewrite F (q, ) as:
F (q, ) =

X

q(Y) log(p (X)p (Y|X))



X

q(Y) log q(Y)

(6)



q(Y)
q(Y) log
p (Y|X)

(7)

= L() KL(q(Y)||p (Y|X)).

(8)

= L()

X


Using interpretation, view EM performing coordinate ascent F (q, ). Starting
initial parameter estimate 0 , algorithm iterates two block-coordinate ascent steps
convergence criterion reached:
E : q t+1 = arg max F (q, ) = arg min KL(q(Y) k pt (Y | X))
q

(9)

q

: t+1 = arg max F (q t+1 , ) = arg max Eqt+1 [log p (X, Y)]


(10)



E-step corresponds maximizing Eq. 8 respect q M-step corresponds
maximizing Eq. 6 respect . EM algorithm guaranteed converge local
maximum L() mild conditions (Neal & Hinton, 1998). HMM POS tagger,
E-Step computes posteriors pt (y|x) latent variables (POS tags) given observed
variables (words) current parameters sentence. accomplished forwardbackward algorithm HMMs. EM algorithm together forward-backward algorithm
HMMs usually referred BaumWelch algorithm (Baum, Petrie, Soules, & Weiss,
1970).
step uses q t+1 (qnt+1 posteriors given sentence) fill values tags
estimate parameters t+1 . Since HMM model locally normalized features used
531

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

depend tag word identities particular position occur,
optimization decouples following way:
Eqt+1 [log p (X, Y)] =
=

N
X

Eqnt+1 [log

n=1
ln
N X
X

ln


n
pt (yin | yi1
)po (xni | yin )]

(11)

i=1
n
Eqnt+1 log pt (yin | yi1
) + Eqnt+1 log po (xni | yin )



(12)

n=1 i=1

multinomial emission model, optimization particularly easy simply involves
normalizing (expected) counts parameter. maximum-entropy emission model parameterized Equation 2, closed form solution need solve unconstrained
optimization problem. possible hidden tag value solve two problems: estimate emission probabilities po (x|y) estimate transition probabilities pt (y 0 |y),
gradient one given


Eqt+1 [log p (X, Y)]
= Eqt+1 f (X, Y) Ep (X0 |Y) [f (X0 , Y)] ,
(13)

similar gradient supervised models, except expectation
q t+1 (Y) instead observed Y. optimization done using L-BFGS Wolfes rule
line search (Nocedal & Wright, 1999).
3.2 Maximum Likelihood Direct Gradient
likelihood traditionally optimized EM, Berg-Kirkpatrick et al. (2010) find
HMM maximum entropy emission model, higher likelihood better accuracy
achieved gradient-based likelihood-optimization method. use L-BFGS
experiments. derivative likelihood is,
L()



1

1
X
log p (X) =
p (X) =
p (X, Y)

p (X)
p (X)

X 1
X p (X, Y)

=
p (X, Y) =
log p (X, Y)
p (X)
p (X)


X

=
p (Y|X) log p (X, Y),

=

(14)
(15)
(16)



exactly derivative M-Step. Equation 14 apply chain
rule take derivative log p (X), Equation 15 apply chain rule reverse
direction. biggest difference EM procedure direct gradient EM
fix counts E-Step optimize model using counts. directly
optimizing likelihood need recompute counts parameter setting,
expensive. Appendix gives detailed discussion methods.
3.3 Controlling Tag Ambiguity PR
One problem unsupervised HMM POS tagging maximum likelihood objective may
encourage tag distributions allow many different tags word given context.
532

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

10

6

Supervised
HMM
HMM+ME
HMM+Sp
HMM+ME+Sp

8
L1L

8
L1L

10

Supervised
HMM
HMM+ME
HMM+Sp
HMM+ME+Sp

4
2

6
4
2

0

0
0

1000 2000 3000 4000 5000 6000 7000 8000

0

200 400 600 800 1000 1200 1400 1600 1800

rank word L1L

rank word L1L

Figure 1: ambiguity measure (`1 /` ) word type two corpora supervised
model, EM training (HMM, HMM+ME), train ambiguity penalty
described Section 3.3 (HMM+Sp, HMM+ME+Sp). Left:En, Right:Pt.

find actual text linguist-designed tags, tags designed informative
words grammatical role. following paragraphs describe measure tag ambiguity
proposed Graa et al. (2009) attempt control. easier understand measure
hard tag assignments, start thene extend discussion distributions
tags.
Consider word stock. Intuitively, would like occurrences stock
tagged small subset possible tags (noun verb, case). hard assignment
tags entire corpus, Y, could count many different tags used occurrences
word stock.
instead single tagging corpus, distribution q(Y) assignments,
need generalize ambiguity measure. Instead asking particular tag ever used
word stock, would ask maximum probability particular tag
used word stock. instead counting number tags, would sum
probabilities.
motivation, Figure 1 shows distribution tag ambiguity across words two corpora.
see Figure 1, train using EM procedure described Section 3.1,
HMM models grossly overestimates tag ambiguity almost words. However
models trained using PR penalize tag ambiguity, models (HMM+Sp,
HMM+ME+Sp) achieve tag ambiguity closer truth.
formally, Graa et al. (2009) define measure terms constraint features (X, Y).
Constraint feature wvj (X, Y) takes value 1 j th occurrence word type w X assigned
tag v tag assignment Y. Consequently, probability j th occurrence word w
tag v label distribution q(Y) Eq [wvj (X, Y)]. ambiguity measurement
word type w becomes:
X
Ambiguity Penalty word type w:
max Eq(Y) [wvj (X, Y)] .
(17)
v

j

sum maxima also called `1 /` mixed norm. brevity use norm notation ||Eq [w ]||1/ . computational reasons, add penalty term based ambiguity model distribution p (Y|X), instead introduce auxiliary distribution q(Y)
533

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

must close p also must low ambiguity. modified objective becomes
X
||Eq [w (X, Y)]||1/ .
max L() KL(q(Y)||p (Y|X))
,q

(18)

w

Graa et al. (2009) optimize objective using algorithm similar EM. added complexity implementing algorithm lies computing Kullback-Leibler projection
modified E-Step. However, computation involves choosing distribution exponentially
many objects (label assignments). Luckily, Graa et al. (2009) show dual formulation
E-Step manageable. given by:
!
X
X
max log
p (Y|X) exp( (X, Y))
s. t.
wvj
(19)
0

j



vector dual parameters wvj , one wvj . projected distribution
given by: q(Y) p (Y|X) exp ( (X, Y)). Note p given HMM, q
sentence expressed
q(yn )




n
pt (yin | yi1
)qo (xni | yin ),

(20)

i=1

qo (xi |yi ) = po (xi |yi ) exp(xi yi j ) act modified (unnormalized) emission probabilities.
objective Equation 19 negative sum log probabilities sentences
q plus constant. compute running forward-backward corpus, similar
E-Step normal EM. gradient objective also computed using forwardbackward algorithm. Note objective Eq. 19 concave respect
optimized using variety methods. perform dual optimization projected gradient,
using fast simplex projection algorithm described Bertsekas, Homer, Logan, Patek
(1995). experiments found taking projected gradient steps enough,
performing optimization convergence helps results.

4. Related Work
POS tags place words classes share commonalities (classes of) words
cooccur with. Therefore, natural ask whether word clustering methods based word
context distributions might able recover word classification inherent POS tag set.
Several influential methods, notably mutual-information clustering (Brown et al., 1992),
used cluster words according immediately contiguous words distributed.
Although methods explicitly designed POS induction, resulting clusters capture syntactic information (see also Martin, Liermann, & Ney, 1998, different method
similar objective). Clark (2003) refined distributional clustering approach adding
morphological word frequency information, obtain clusters closely resemble POS
tags.
forms distributional clustering go beyond immediate neighbors word represent whole vector coocurrences target word within text window, compare
vectors using suitable metric, cosine similarity. However, wider-range similarities problems capturing local regularities. instance, adjective noun might
534

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

look similar noun tends used noun-noun compounds; similarly, two adjectives
different semantics selectional preferences might used different contexts. Moreover,
problem aggravated data sparsity. example, infrequent adjectives modify different nouns tend completely disjoint context vectors (but even frequent words like
might completely different context vectors, since articles used disjoint right
contexts). alleviate problems, Schtze (1995) used frequency cutoffs, singular-value decomposition co-occurrence matrices, approximate co-clustering two stages SVD,
clusters first stage used instead individual words provide vector representations second-stage clustering.
Lamar, Maron Johnson (2010) recently revised two-stage SVD model Schtze
(1995) achieve close state-of-the-art performance. revisions relatively small,
touch several important aspects model: singular vectors scaled singular values
preserve geometry original space; latent descriptors normalized unit length;
cluster centroids computed weighted average constituent vectors based word
frequency, rare common words treated differently centroids initialized
deterministic manner.
final class approaches include work paper uses sequence model,
HMM, represent probabilistic dependencies consecutive tags.
approaches, observation corresponds particular word hidden state corresponds
cluster. However, noted Clark (2003) Johnson (2007), using maximum likelihood
training models achieve good results: maximum likelihood training tends result
ambiguous distributions common words, contradiction rather sparse wordtag distribution. Several approaches proposed mitigate problem. Freitag (2004)
clusters frequent words using distributional approach co-clustering. cluster
remaining (infrequent) words, author trains second-order HMM emission probabilities frequent words fixed clusters found earlier emission probabilities
remaining words uniform.
Several studies propose using Bayesian inference improper Dirichlet prior favor
sparse model parameters hence indirectly reduce tag ambiguity (Johnson, 2007; Gao & Johnson, 2008; Goldwater & Griffiths, 2007). refined Moon, Erk, Baldridge
(2010) representing explicitly different ambiguity patterns function content words.
Lee, Haghighi, Barzilay (2010) take direct approach reducing tag ambiguity explicitly modeling set possible tags word type. model first generates tag
dictionary assigns mass one tag word type reflect lexicon sparsity. dictionary used constrain Dirichlet prior emission probabilities drawn
support word-tag pairs dictionary. token-level HMM using
emission parameters transition parameters draw symmetric Dirichlet prior used
tagging entire corpus. authors also show improvements using morphological features
creating dictionary. system achieves state-of-art results several languages.
noted common issue sparsity-inducing approaches sparsity
imposed parameter level, probability word given tag, desired sparsity
posterior level, probability tag given word. Graa et al. (2009) use PR framework
penalize ambiguous posteriors distributions words given tokens, achieves better results
Bayesian sparsifying Dirichlet priors.

535

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

recently, Berg-Kirkpatrick et al. (2010) Graa (2010) proposed replacing multinomial distributions HMM maximum entropy (ME) distributions. allows use features capture morphological information, achieve promising results. Berg-Kirkpatrick
et al. (2010) also find optimizing likelihood L-BFGS rather EM leads substantial improvements, show case beyond English.
also note briefly POS induction methods rely prior tag dictionary indicating
word type POS tags have. POS induction task then, word token
corpus, disambiguate possible POS tags, described Merialdo (1994). Unfortunately, availability large manually-constructed tag dictionary unrealistic much
later work tries reduce required dictionary size different ways, generalizing
small dictionary handful entries (Smith & Eisner, 2005; Haghighi & Klein, 2006;
Toutanova & Johnson, 2007; Goldwater & Griffiths, 2007). However, although approach greatly
simplifies problem words one tag and, furthermore, cluster-tag mappings predetermined, thus removing extra level ambiguity accuracy methods
still significantly behind supervised methods. address remaining ambiguity imposing
additional sparsity, Ravi Knight (2009) minimize number possible tag-tag transitions
HMM via integer program. Finally, Snyder, Naseem, Eisenstein, Barzilay (2008) jointly
train POS induction system parallel corpora several languages, exploiting fact
different languages present different ambiguities.

5. Experiments
section present encouraging results validating proposed method six different testing
scenarios according different metrics. highlights are:
maximum-entropy emission model Markov transition model trained ambiguity penalty improves regular HMM cases average improvement
10.4% (according 1-Many metric).
compared broad range recent POS induction systems, method produces
best results languages except English. Furthermore, method seems less sensitive
particular test conditions previous methods.
induced clusters useful features training supervised POS taggers, improving test
accuracy much clusters learned competing methods.
5.1 Corpora
experiments test several POS induction methods five languages help manually POS-tagged corpora languages. Table 1 summarizes characteristics test corpora:
Wall Street Journal portion Penn Treebank (Marcus et al., 1993) (we consider
17-tag version Smith & Eisner, 2005 (En17) 45-tag version (En45)); Bosque subset
Portuguese Floresta Sinta(c)tica Treebank (Afonso, Bick, Haber, & Santos, 2002) (Pt);
Bulgarian BulTreeBank (Simov et al., 2002) (Bg) (with 12 coarse tags); Spanish corpus Cast3LB treebank (Civit & Mart, 2004) (Es); Danish Dependency Treebank
(DDT) (Kromann, Matthias T., 2003) (Dk).

536

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

En
Pt
Bg
Es
Dk

1
Sentences
49208
9359
14187
3512
5620

2
Types
49206
29489
34928
16858
19400

3
LUnk
49.28%
37.83%
39.26%
37.73%
26.30%

4
Tokens
1173766
212545
214930
95028
65057

5
Tags
17 (45)
22
12
47
30

6
Avg. `1 /`
1.08 (1.11)
1.02
1.02
1.05
1.05

7
Total `1 /`
6523.6 (6746.2)
1144.6
3252.9
818.9
795.8

8
|w|1
54334
33293
38633
18962
21678

9
|w|2
7856
2114
2287
951
969

Table 1: Corpus statistics. third column shows percentage word types lower-casing
eliminating word types occurring once. sixth seventh columns show
information word ambiguity corpus average totality (corresponding penalty Equation 17). eighth ninth columns show number
parameters different feature sets, described Section 5.3.

5.2 Experimental Setup
compare work two kinds methods: induce single cluster word
type (type-level tagging), allow different tags different occurrences word type
(token-level tagging). type-level tagging, use two standard baselines, B ROWN C LARK,
described Brown et al. (1992)1 Clark (2003)2 . Following Headden, McClosky, Charniak (2008), trained C LARK system 5 10 hidden states letter HMM
ran 10 iterations; B ROWN system run according instructions accompanying
code. also ran recently proposed LDC system (Lamar, Maron, & Bienenstock, 2010)3 ,
configuration described paper PTB45 PTB17, PTB17 configuration
corpora. noted carry experiments SVD2
system (Lamar, Maron Johnson, 2010), since SVD2 superseded LDC according
authors.
token-level tagging, experimented feature-rich HMM presented BergKirkpatrick et al. (2010), trained using EM training (BK+EM) direct gradient (BK+DG),
using configuration provided authors4 . report results type-level HMM
(TLHMM) (Lee et al., 2010) applicable, since able run system. Moreover,
compared systems implementation various HMM-based approaches:
HMM multinomial emission probabilities (Section 2.1), HMM maximumentropy emission probabilities (Section 2.2) trained EM (HMM+ME), trained direct gradient (HMM+ME+DG), trained using PR ambiguity penalty, described Section 3.3
(HMM+Sp multinomial emissions, HMM+ME+Sp maximum-entropy emissions).
addition, also compared multinomial HMM sparsifying Dirichlet prior parameters (HMM+VB) trained using variational Bayes (Johnson, 2007).
Following standard practice, multinomial HMMs use morphological information, lowercase corpora replace unique words special unknown token,
improves multinomial HMM results decreasing number parameters eliminating
1.
2.
3.
4.

Implementation: http://www.cs.berkeley.edu/~pliang/software/brown-cluster-1.2.zip
Implementation: http://www.cs.rhul.ac.uk/home/alexc/pos2.tar.gz
Implementation provided Lamar, Maron Bienenstock (2010).
Implementation provided Berg-Kirkpatrick et al. (2010).

537

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

rare words (mostly nouns). Since maximum-entropy emission models access morphological features, preprocessing steps improve performance perform
case.
start EM, randomly initialize implementations HMM-based models
posteriors, obtained running E-step HMM model set random
parameters: close uniform random uniform jitter 0.01. means random
seed, initialization identical models.
EM variational Bayes training, train model 200 iterations, since found
typically models tend converge iteration 100. HMM+VB model fix
transition prior5 0.001 test emission prior equal 0.1 0.001, corresponding
best values reported Johnson (2007).
PR training, initialize 30 EM iterations run 170 iterations PR, following Graa et al. (2009). used results worked best English (En17) (Graa et al.,
2009), regularizing words occur least 10 times, = 32, use configuration scnenarios. setting specifically tuned test languages,
might optimal every language. Setting parameters unsupervised manner
difficult task address (Graa, 2010 discusses experiments different
values parameters).
obtain hard assignments using posterior decoding, position pick label
highest posterior probability, since showed small consistent improvements Viterbi
decoding. experiments required random initialization parameters report
average 5 random seeds.
experiments run using number true tags number clusters, results
obtained test set portion corpus. evaluate systems using four common metrics
POS induction: 1-Many mapping, 1-1 mapping (Haghighi & Klein, 2006), variation information (VI) (Meila, 2007), validity measure (V) (Rosenberg & Hirschberg, 2007). metrics
described detail Appendix B.
5.3 HMM+ME+Sp Performance
section compares gains using feature-rich representation ambiguity penalty, described Section 3.3. Experiments show feature-rich representation always improves performance, ambiguity penalty also always improves
performance. Then, see improvements two methods combine additively,
suggesting address independent aspects POS induction.
use two different feature sets: large feature set Berg-Kirkpatrick et al. (2010),
reduced feature set described Graa (2010). apply count-based feature selection identity suffix features. Specifically, add identity features words
occurring least 10 times suffix features words occurring least 20 times. also add
punctuation feature. follows, refer large feature set feature set 1 reduced
feature set 2. total number features model language given Table 1.
results experiments summarized Table 2.
Table 2 shows results 10 training methods across six corpora four evaluation metrics,
resulting 240 experimental conditions. simplify discussion, focus 1-Many metric
5. transition prior significantly affect results, report results different values.

538

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

1
2
3
4
5
6
7
8
9
10

1
2
3
4
5
6
7
8
9
10

HMM
HMM+Sp
HMM+ME1 Prior 1
HMM+ME1 Prior 10
HMM+ME2 Prior 1
HMM+ME2 Prior 10
HMM+ME+Sp1 Prior 1
HMM+ME+Sp1 Prior 10
HMM+ME+Sp2 Prior 1
HMM+ME+Sp2 Prior 10

En45
62.4
67.5
67.1
70.0
70.3
69.9
71.4
68.8
71.6
71.1

En17
65.6
70.3
72.2
69.2
71.8
71.0
71.7
71.1
72.5
72.0

1-Many
PT BG
64.9 58.9
71.2 65.0
72.3 61.1
66.8 58.2
73.9 62.4
74.1 63.9
75.1 63.0
71.6 62.2
73.4 60.9
76.9 67.1

DK
60.0
67.5
65.1
63.9
66.5
67.8
64.5
68.2
65.0
72.0

1-1
ES PTB45 PTB17 PT BG DK ES
60.2 42.5
43.5 42.2 40.6 37.4 30.6
69.0 46.1
52.5 47.7 46.3 40.0 35.3
71.8 45.0
51.1 46.3 46.1 42.6 40.8
66.2 48.4
45.6 40.8 41.7 41.1 35.1
72.9 45.1
49.8 46.8 46.7 45.0 42.6
73.4 47.3
51.2 48.8 48.8 44.7 37.1
72.8 49.4
52.5 46.6 46.7 43.1 41.1
69.3 45.1
52.1 48.0 49.7 42.0 38.5
72.1 52.5
53.9 45.5 49.5 43.0 38.6
75.2 46.7
48.5 49.6 53.4 48.7 40.8

HMM
HMM+Sp
HMM+ME1 Prior 1
HMM+ME1 Prior 10
HMM+ME2 Prior 1
HMM+ME2 Prior 10
HMM+ME+Sp1 Prior 1
HMM+ME+Sp1 Prior 10
HMM+ME+Sp2 Prior 1
HMM+ME+Sp2 Prior 10

En45
4.22
3.64
3.77
3.31
3.59
3.28
3.20
3.46
3.21
3.41

En17
3.75
3.20
3.11
3.38
3.12
3.24
3.09
3.15
3.04
3.25

VI
PT BG
3.90 4.04
3.27 3.49
3.21 3.46
3.66 3.83
3.05 3.46
3.12 3.44
3.00 3.38
3.15 3.43
3.16 3.37
2.86 3.12

DK
4.55
3.85
3.77
4.13
3.71
3.74
3.80
3.73
3.72
3.35

V
ES PTB45 PTB17 PT BG DK ES
4.89 .558
.479 .490 .383 .432 .474
3.85 .616
.549 .573 .467 .518 .581
3.56 .606
.564 .583 .460 .519 .608
4.11 .649
.530 .527 .406 .482 .553
3.46 .626
.559 .600 .460 .528 .617
3.58 .652
.546 .596 .471 .530 .610
3.49 .660
.560 .608 .478 .514 .617
3.76 .637
.557 .591 .470 .532 .589
3.46 .658
.567 .591 .473 .523 .616
3.34 .644
.541 .631 .519 .578 .636

Table 2: Results different HMMs. HMM HMM+Sp HMMs multinomial emission
functions trained using EM PR sparsity constraints, respectively. HMM+ME
HMM+ME+Spare HMMs maximum entropy emission model trained using EM
PR sparsity constraints. feature-rich models, superscript 1 represents large
feature set, superscript 2 represents reduced feature set. Prior 1 10 refers
regularization strength emission model. Table entries results averaged
5 runs. Bold indicates best system overall.

(top left tab Table 2), observe conclusions hold three evaluation
metrics also. Table 2 conclude following:
Adding penalty high word-tag ambiguity improves performance multinomial
HMM. multinomial HMM trained EM (line 1 Table 2) always worse
multinomial HMM trained PR ambiguity penalty, 6.5% average (line 2
Table 2).
feature-rich maximum entropy HMMs (lines 3-6 Table 2) almost always perform better
multinomial HMM. true feature sets regularization strengths
used, average increase 6.4%. exceptions possibly due suboptimal regularization.
Adding penalty high word-tag ambiguity maximum-entropy HMM improves performance. almost cases, comparing lines 3-6 lines 7-10 Table 2, sparsity
constraints improve performance (average improvement 1.6%). combined system al539

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

always outperforms multinomial HMM trained using ambiguity penalty
average improvement 1.6%. every corpus best performance achieved
model ambiguity penalty maximum-entropy emission probabilities.
every language except English 17 tags particular feature configuration, reducing feature set excluding rare features improves performance average 2.3% (lines
5-6 better lines 3-4 Table 2).
Regularizing maximum-entropy model important many features
word-tag ambiguity penalty. Lines 3-4 Table 2
maximum-entropy HMM many features, see tight parameter prior
almost always out-performs looser prior. contrast, looking lines 9-10 Table 2 see ambiguity penalty fewer features looser prior
almost always better tighter parameter prior. observed also Graa (2010).
encouraging see improvements using feature-rich model additive
effects penalizing tag-ambiguity. especially surprising since optimize strength tag-ambiguity penalty maximum-entropy emission HMM, rather
used value reported Graa et al. (2009) work multinomial emission HMM. Experiments reported Graa (2010) show tuning parameter improve performance.
Nevertheless, methods regularize objective different ways interaction
accounted for. would interesting use L1 regularization models, instead
L22 regularization together feature count cutoff. way model could learn features discard, instead requiring predefined parameter depends particular corpus
characteristics.
reported Berg-Kirkpatrick et al. (2010), way objective optimized
big impact overall results. However, due non-convex objective function
unclear optimization method works better why. briefly analyze question
Appendix leave open question future work.
5.4 Error Analysis
Figure 2 shows distribution true tags clusters HMM model (left)
HMM+ME+Sp model (right) En17 corpus. bar represents cluster, labeled tag
assigned performing 1-Many mapping. colors represent number words
corresponding true tag. reduce clutter, true tags never used label cluster
grouped Others.
observe models split common tags nouns several hidden states.
splitting accounts many errors models. using 5 states nouns instead
7, HMM+ME+Sp able use states adjectives. Another improvement comes
better grouping prepositions. example grouped punctuation HMM
HMM+ME+Sp correctly mapped prepositions. Although correct
behavior, actually hurts, since tagset special tag occurrences word
incorrectly assigned, resulting loss 2.2% accuracy. contrast, HMM state
mapped tag word comprises one fifth state. common
error made HMM+ME+Sp include word second noun induced tag
Figure 2 (Right). induced tag contains mostly capitalized nouns pronouns, often
540

fiPREP
DET

N
ADJ

RPUNC
POS

V
INPUNC

CONJ


EPUNC
Others

PREP
DET

N
ADJ

RPUNC
POS

V
INPUNC

CONJ


CONJ

ENDPUNC

V

INPUNC

V

V

ADJ

RPUNC

ADJ

N

ADJ

N

N

N

N

DET

PREP



ENDPUNC

CONJ

V

INPUNC

V

POS

N

ADJ

N

N

N

N

N

N

DET

PREP

C ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

EPUNC
Others

Figure 2: Induced tags HMM model (Left), HMM+ME+Sp model (Right)
En17 corpus. column represents hidden state, labeled 1-Many
mapping. Unused true tags grouped cluster named Others.

25000

25000

20000

20000

15000

15000

10000

10000

5000

5000

0

0
art
n
adj

prop
v-fin
prp

punc
num
adv

v-pcp
v-inf
conj-c

pron-pers
sumOthers

art
n
adj

prop
v-fin
prp

punc
num
adv

v-pcp
v-inf
conj-c

pron-pers
sumOthers

Figure 3: Induced tags HMM model (Left), HMM+ME+Sp model (Right)
Pt corpus. column represents hidden state, labeled 1-Many mapping.
Unused true tags grouped cluster named Others.

precede nouns induced tags. suspect capitalization feature cause
error.
better performance feature-based models Portuguese relative English may due
ability features better represent richer morphology Portuguese. Figure 3 shows
induced clusters Portuguese. HMM+ME+Sp model improves HMM tags
except adjectives. models trouble distinguishing nouns adjectives. reduced
accuracy adjectives HMM+ME+Sp explained mapping single cluster containing
adjectives adjectives HMM model nouns HMM+ME+Sp model.
Removing noun-adjective distinction, suggested Zhao Marcus (2009), would increase
performance models 6%. Another qualitative difference observed
HMM+ME+Sp model used single induced cluster proper nouns rather spreading
across different clusters.

541

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

5.5 State-of-the-Art Comparison
compare best POS induction system (based settings line 10 Table 2),
recent systems. Results summarized Table 3. previously done Table 2,
focus discussion 1-Many evaluation metric, results qualitatively
VI V metrics, 1-1 metric shows variance across languages.
1-Many
PT BG
69.6 63.2
66.0 62.3
67.1 57.0
69.2 61.1
64.9 58.9
61.5 51.5
63.2 53.5
71.2 65.0
72.3 64.3
72.5 56.1
74.5
72.0 76.9 67.1

DK
69.6
57.3
58.2
60.9
60.0
51.2
56.6
67.5
62.8
60.6
61.2
72.0

1-1
ES PTB45 PTB17 PT BG DK ES
69.7 53.3
56.6 43.8 47.9 44.3 41.2
67.6 52.3
43.1 47.3 50.3 37.5 37.4
70.1 52.3
44.2 48.1 45.2 37.5 40.0
67.9 48.6
50.0 42.6 50.1 35.2 38.8
60.2 42.5
43.5 42.2 40.6 37.4 30.6
45.5 48.1
50.3 51.4 42.0 42.7 35.9
55.9 44.1
51.4 45.1 38.3 38.1 34.4
69.0 46.1
52.5 47.7 46.3 40.0 35.3
72.0 48.3
54.4 45.5 50.6 41.5 37.2
73.7 54.5
47.9 42.9 38.8 41.5 40.4
68.9 50.9
64.1
52.1 58.3
75.2 46.7
48.5 49.6 53.4 48.7 40.8

VI
PT BG
3.34 3.30
3.38 3.30
3.28 3.60
3.50 3.51
3.90 4.04
3.65 3.90
3.97 4.07
3.27 3.49
3.19 3.30
3.29 3.89
2.86 3.12

DK
3.41
3.97
3.99
4.24
4.55
4.20
4.41
3.85
3.90
4.15
3.35

V
ES PTB45 PTB17 PT BG DK ES
3.40 .648
.559 .564 .473 .554 .613
3.76 .660
.498 .545 .475 .490 .588
3.55 .663
.499 .557 .424 .485 .610
4.00 .626
.585 .546 .450 .474 .569
4.89 .558
.479 .490 .383 .432 .474
4.40 .534
.500 .477 .368 .405 .402
4.69 .535
.501 .471 .368 .437 .474
3.85 .616
.549 .573 .467 .518 .581
4.15 .645
.568 .582 .479 .477 .596
3.56 .678
.534 .574 .392 .477 .611
3.34 .644
.541 .631 .519 .578 .636

1
2
3
4
5
6
7
8
9
10
11
12

En45
B ROWN
68.7
C LARK5
72.4
C LARK10
72.5
LDC
67.5
HMM
62.4
HMM+VB0.1
55.0
HMM+VB0.001
58.6
HMM+Sp
67.5
BK+EM
69.1
BK+DG
75.8
TLHMM
62.2
HMM+ME+Sp2 Prior 10 71.1

En17
68.7
63.5
63.2
74.7
65.6
67.2
67.7
70.3
72.1
67.9

1
2
3
4
5
6
7
8
9
10
12

En45
B ROWN
3.17
C LARK5
3.23
C LARK10
3.20
LDC
3.43
HMM
4.22
HMM+VB0.1
4.10
HMM+VB0.001
4.38
HMM+Sp
3.64
BK+EM
3.31
BK+DG
3.01
HMM+ME+Sp2 Prior 10 3.41

En17
3.07
3.45
3.46
3.00
3.75
3.52
3.55
3.20
3.04
3.21
3.25

Table 3: Comparing HMM+ME+Sp2 several POS induction systems. results
models random initialization run (systems: 2,3,5,6,7,8,9,10,12) represent
average 5 runs. See Section 5.5 details discussion.

Lines 1-3 Table 3 show clustering algorithms based information gain various metrics. B ROWN wins 5/6 times (in scenarios fewer clusters) C LARK system, despite
fact C LARK uses morphology. Comparing lines 1-3 Table 3 line 4, see
LDC system particularly strong En17 achieves state-of-the-art results, behaves
worse B ROWN system every corpus.
HMMs multinomial emissions (lines 5-8 Table 3), maximum likelihood training (HMM) parameter sparsity (HMM+VB) perform worse adding ambiguity penalty
(HMM+Sp). holds evaluation metrics, exception 1-1. confirms previous results Graa et al. (2009). Comparing models lines 5-8 lines 1-3, see

542

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

best HMM (HMM+Sp) performs comparably best clustering (B ROWN), one
model winning 3 languages remaining 3.
feature rich HMMs (BK+EM BK+DG) perform well, achieving results
better HMM+Sp 4 6 tests. Even though optimize objective, achieve
different results different corpora. explore training procedure detail Appendix A, comparing also implementation Berg-Kirkpatrick et al. (2010). brevity,
Table 3 contains results implementation Berg-Kirkpatrick et al. (2010).
implementation produces comparable, quite identical results.
Lines 11-12 Table 3 display two methods attempt control tag ambiguity
feature-rich representation capture morphological information. results TLHMM
taken Lee et al. (2010), report results En17 Bg corpora. Also,
able rerun experiments TLHMM, able compute
information-theoretic metrics. Consequently, comparison TLHMM slightly less complete
methods. TLHMM HMM+ME+Sp perform competitively better
systems. surprising since ability model morphological
regularity also penalizing high ambiguity. Comparing TLHMM HMM+ME+Sp, see
HMM+ME+Sp performs better 1-Many metric. contrast, TLHMM performs better
1-1. One possible explanation underlying model TLHMM Bayesian HMM
sparsifying Dirichlet priors. noted Graa et al. (2009), models trained way tend
cluster distribution closely resemble true POS distribution (some clusters lots
words words) favors 1-1 metric (a description particularity
1-1 metric discussed Appendix B).
summarize, non-English languages metrics except 1-1, HMM+ME+Sp
system performs better systems. English, BK+DG wins 45-tag corpus,
LDC wins 17-tag corpus. HMM+ME+Sp system fairly robust, performing well
corpora best several them, allow us conclude tuned
particular corpus evaluation metric.
performance HMM+ME+Sp tightly related performance underlying
HMM+ME system. Appendix present discussion performance different optimization methods HMM+ME. compare HMM+ME implementation BK+EM
BK+DG show significant differences performance. However,
clear results one better, performs better given situation.
mentioned Clark (2003), morphological information particularly useful rare words.
Table 4 compares different models accuracy words according frequency. compare clustering models based information gain without morphological information
(B ROWN,C LARK), distributional information-based model (LDC), feature rich HMM
tag ambiguity control (HMM+ME+Sp). expected see systems using morphology
better rare words. Moreover systems improve almost categories except
common words (words occurring 50 times). Comparing HMM+ME+Sp C LARK,
see even condition C LARK overall works better (En45), still performs worse
rare words HMM+ME+Sp.

543

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

1
5
10
50
> 50

B ROWN
50.07
61.76
64.32
67.13
68.94

C LARK
49.48
62.89
66.53
67.62
73.87

1
5
10
50
> 50

B ROWN
31.44
48.06
63.14
66.30
80.61

C LARK
44.53
53.30
64.33
67.52
74.68

1
5
10
50
> 50

B ROWN
41.04
61.75
72.10
64.44
86.43

C LARK
49.93
64.03
69.76
57.67
73.69

En45
LDC
50.65
58.70
61.78
64.28
68.04
PT
LDC
19.19
36.67
54.16
62.56
84.58
ES
LDC
38.75
51.94
61.69
56.74
81.94

HMM+ME+Sp2
70.12
72.12
70.59
70.80
71.49

B ROWN
29.42
43.38
50.94
59.16
72.14

C LARK
60.62
69.30
71.13
71.50
62.04

HMM+ME+Sp2
63.51
68.60
72.35
71.32
79.52

B ROWN
32.55
48.18
56.59
60.15
74.01

C LARK
52.25
65.00
69.51
68.95
61.89

HMM+ME+Sp2
68.65
72.05
73.35
59.94
82.11

B ROWN
37.71
49.54
58.90
60.42
82.82

C LARK
43.58
48.62
51.92
55.87
60.88

En17
LDC
53.39
64.03
67.35
68.02
77.14
BG
LDC
40.61
53.58
60.82
62.06
67.02
DK
LDC
35.65
40.17
47.96
46.12
77.91

HMM+ME+Sp2
75.79
76.50
74.29
75.31
71.40
HMM+ME+Sp2
68.17
73.54
71.53
68.59
65.89
HMM+ME+Sp2
64.41
66.98
65.21
61.83
73.26

Table 4: 1-Many accuracy word frequency different corpora.
5.6 Using Clusters
comparison different POS induction methods, experiment simple
semisupervised scheme use learned clusters features supervised POS tagger.
basic supervised model features HMM+ME model, except use
word identities suffixes regardless frequency. trained supervised model using
averaged perceptron number iterations chosen follows: split training set 20%
development 80% training pick number iterations optimize accuracy
development set. Finally, trained full training set using iterations report results
500 sentence test set.
augmented standard features learned hidden state current token,
unsupervised method (B ROWN,C LARK,LDC, HMM+ME+Sp). Figure 4 shows average
accuracy supervised model varied type unsupervised features. average
taken 10 random samples training set training set size. see Figure 4
using sem-supervised features models improves performance even
500 labeled sentences. Moreover, see HMM+ME+Sp either performs well better
models.

544

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

LDC
Brown
HMM+ME+Sp
Clark

100 200 300 400 500
# Training samples

LDC
Brown
HMM+ME+Sp
Clark

10
8
6
4
2
0

100 200 300 400 500
# Training samples

ES

LDC
Brown
HMM+ME+Sp
Clark

100 200 300 400 500
# Training samples

10
8
6
4
2
0

Improvement:

En17

10
8
6
4
2
0

Improvement:

BG

Improvement:

10
8
6
4
2
0

100 200 300 400 500
# Training samples

10
8
6
4
2
0

Improvement:

LDC
Brown
HMM+ME+Sp
Clark

Improvement:

En45

Improvement:

10
8
6
4
2
0

PT

LDC
Brown
HMM+ME+Sp
Clark

100 200 300 400 500
# Training samples

DK

LDC
Brown
HMM+ME+Sp
Clark

100 200 300 400 500
# Training samples

Figure 4: Error reduction using induced clusters features semi-supervised model
function labeled data size. Top Left: En45. Top Middle: En17. Top Right: PT.
Bottom Left: BG. Bottom Middle: ES. Bottom Right: DK.

6. Conclusion
work investigated task fully unsupervised POS induction five different languages.
identified proposed solutions three major problems simple hidden Markov model
used extensively task: i) treating words atomically, ignoring orthographic
morphological information addressed replacing multinomial word distributions
small maximum-entropy models; ii) excessive number parameters allows models
fit irrelevant correlations adressed discarding parameters small support
corpus; iii) training regime (maximum likelihood) allows high word ambiguity
addressed training using PR framework word ambiguity penalty. show
solutions improve model performance improvements additive. Comparing
regular HMM achieve impressive improvement 10.4% average.
also compared system main competing systems show approach
performs better every language except English. Moreover, approach performs well across
languages learning conditions, even hyperparameters tuned conditions.
induced clusters used features semi-supervised POS tagger trained small
amount supervised data, show significant improvements. Moreover, clusters induced
system always perform well better clusters produced systems.

545

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

Acknowledgments
Joo V. Graa supported fellowship Fundao para Cincia e Tecnologia (SFRH/
BD/ 27528/ 2006) FCT project CMU-PT/HuMach/0039/2008 FCT (INESC-ID multiannual funding) PIDDAC Program funds. Kuzman Ganchev partially supported
NSF ITR EIA 0205448. Ben Taskar partially supported DARPA CSSG 2009 Award
ONR 2010 Young Investigator Award. Lusa Coheur partially supported FCT (INESC-ID
multiannual funding) PIDDAC Program funds.

Appendix A. Unsupervised Optimization
Berg-Kirkpatrick et al. (2010) describe feature-rich HMM show training model
using direct gradient rather EM lead better results. However, report results
En45 corpus. Table 5 compares implementation training regimes (BK+EM,
BK+DG) different languages. Comparing two training regimes, see
clear winner. BK+EM wins 3 cases (Bg,En17,Dk) loses three.
also clear predict method suitable. follow discussion
6 authors propose difference arises algorithm starts fine-tune
weights rare features relative trains weights common features short
suffixes. case direct gradient training, start optimization, weights common
features change rapidly weight gradient proportional feature frequency.
training progresses, weight transferred rarer features. contrast, EM training,
optimization done completion M-Step, even first iterations EM
counts mostly random, rarer features get lot weight mass. prevents
model generalizing, optimization terminates local maximum closer starting
point. allow EM use common features longer tried small experiments
initially permissive stopping criteria M-step. EM iterations
permissive stopping criteria, require stricter stopping criteria. tended improve EM,
find principled method setting schedule convergence criteria M-step.
Furthermore, small experiments explain direct gradient better EM
languages worse others.
related study (Salakhutdinov et al., 2003) compares convergence rate EM direct
gradient training, identifies conditions EM achieves Newton-like behavior,
achieves first-order convergence. conditions based amount missing information,
case approximated number hidden states. Potentially, difference
also lead different local maxima, mainly due non-local nature line search procedure gradient based methods. fact, looking results, DG training seems work better
corpora higher number hidden states (En45, Es) work worse corpora
fewer hidden states (Bg,En17).
Also Table 5 compare implementation HMM+ME model implementation
Berg-Kirkpatrick et al. (2010), using conditions (regularization parameter, feature set,
convergence criteria, initialization) observe significant differences results. Communication
code-comparison revealed small implementation differences: use bias feature
not; random seed, parameters initialized differently theirs;
6. http://www.cs.berkeley.edu/~tberg/gradVsEM/main.html

546

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

En45
BK+EM 69.1
BK+DG 75.8
HMM+ME 67.1

1-Many
En17 Pt
Bg Dk Es
72.1 72.3 64.3 62.8 72.0
67.9 72.5 56.1 60.6 73.7
72.2 72.3 61.1 65.1 71.8

En45
48.3
54.5
45.0

1-1
En17 Pt
Bg Dk
Es
54.4 45.5 50.6 41.5 37.2
47.9 42.9 38.8 41.5 40.4
51.1 46.3 46.1 42.6 40.8

En45
BK+EM 3.31
BK+DG 3.01
HMM+ME 3.77

VI
En17 Pt
Bg Dk Es
3.04 3.19 3.30 3.90 4.15
3.21 3.29 3.89 4.15 3.56
3.11 3.21 3.46 3.77 3.56

En45
.645
.678
.606

V
En17 Pt
Bg Dk
Es
.568 .582 .479 .477 .596
.534 .574 .392 .477 .611
.564 .583 .460 .519 .608

Table 5: EM vs direct gradient Berg-Kirkpatrick et al. (2010) implementation compared
implementaion EM HMM maximum-entropy emission probabilities.
rows starting BK Berkeley implementation, rows starting
implementation.

different implementations optimization algorithm; different number iterations.
corpora differences result better performance implementation,
corpora implementation gets better results. leave details well better
understanding differences optimization procedure future work, since
main focus present paper.

Appendix B. Evaluation Metrics
compare performance different models one needs evaluate quality induced
clusters. Several evaluation metrics clustering proposed previous work. metrics
use evaluate divided two types (Reichart & Rappoport, 2009): mapping-based
information theoretic. Mapping based metrics require post-processing step map cluster
POS tag evaluate accuracy supervised POS tagging. Information-theoretic (IT)
metrics compare induced clusters directly true POS tags.
1-Many mapping 1-1 mapping (Haghighi & Klein, 2006) two widely-used mapping
metrics. 1-Many mapping, hidden state mapped tag cooccurs
most. means several hidden states mapped tag, tags might
used all. 1-1 mapping greedily assigns hidden state single tag. case
number tags hidden states same, give 1-1 correspondence. major
drawback latter mapping fails express information hidden states.
Typically, unsupervised models prefer explain frequent tags several hidden states,
combine rare tags. example Pt corpus 3 tags occur
corpus. Grouping together subdividing nouns still provides lot information
true tag assignments. However, would captured 1-1 mapping. metric
tends favor systems produce exponential distribution size induced cluster
independent clusters true quality, correlate well information theoretic
metrics (Graa et al., 2009). Nevertheless, 1-Many mapping also drawbacks, since
distinguish clusters based frequent tag. So, cluster split almost evenly

547

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

nouns adjectives, cluster number nouns, mixture
words different tags gives 1-Many accuracy.
information-theoretic measures use evaluation variation information (VI)
(Meila, 2007) validity-measure (V) (Rosenberg & Hirschberg, 2007). based
entropy conditional entropy tags induced clusters. VI desirable geometric properties metric convexly additive (Meila, 2007). However, range VI values
dataset-dependent (VI lies [0, 2 log N ] N number POS tags) allow
comparison across datasets different N . validity-measure (V) also entropy-based
measure always lies range [0, 1], satisfy geometric properties
VI. reported give high score large number clusters exist, even
low quality (Reichart & Rappoport, 2009). information-theoretic measures
proposed better handle different numbers clusters, instance NVI (Reichart & Rappoport,
2009). However, work testing conditions corpora number clusters problem exist. Christodoulopoulos, Goldwater, Steedman (2010)
present extensive comparison evaluation metrics. related work Maron, Lamar,
Bienenstock (2010) present another empirical study metrics conclude VI metric
produce results contradict true quality induced clustering, giving high
scores simple baseline systems, instance assigning label words.
also point several problems 1-1 metric explained previously. Since
metric comparison focus work compare methods using four metrics
described section.

References
Abeill, A. (2003). Treebanks: Building Using Parsed Corpora. Springer.
Afonso, S., Bick, E., Haber, R., & Santos, D. (2002). Floresta Sinta(c)tica: treebank Portuguese. Proc. LREC, pp. 16981703.
Baum, L., Petrie, T., Soules, G., & Weiss, N. (1970). maximization technique occurring
statistical analysis probabilistic functions Markov chains. Annals Mathematical
Statistics, 41(1), 164171.
Berg-Kirkpatrick, T., Bouchard-Ct, A., DeNero, J., & Klein, D. (2010). Painless unsupervised
learning features. Proc. NAACL.
Bertsekas, D., Homer, M., Logan, D., & Patek, S. (1995). Nonlinear programming. Athena Scientific.
Brown, P. F., deSouza, P. V., Mercer, R. L., Pietra, V. J. D., & Lai, J. C. (1992). Class-based n-gram
models natural language. Computational Linguistics, 18, 467479.
Chen, S. (2003). Conditional joint models grapheme-to-phoneme conversion. Proc.
ECSCT.
Christodoulopoulos, C., Goldwater, S., & Steedman, M. (2010). Two decades unsupervised POS
induction: far come?. Proc. EMNLP, Cambridge, MA.
Civit, M., & Mart, M. (2004). Building cast3lb: spanish treebank. Research Language &
Computation, 2(4), 549574.

548

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

Clark, A. (2003). Combining distributional morphological information part speech induction. Proc. EACL.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data via
EM algorithm. Journal Royal Statistical Society. Series B (Methodological), 39(1).
Freitag, D. (2004). Toward unsupervised whole-corpus tagging. Proc. COLING. Association
Computational Linguistics.
Ganchev, K., Graa, J., Gillenwater, J., & Taskar, B. (2010). Posterior regularization structured
latent variable models. Journal Machine Learning Research, 11, 20012049.
Gao, J., & Johnson, M. (2008). comparison Bayesian estimators unsupervised hidden
Markov model POS taggers. Proc. EMNLP, pp. 344352, Honolulu, Hawaii. ACL.
Goldwater, S., & Griffiths, T. (2007). fully Bayesian approach unsupervised part-of-speech
tagging. Proc. ACL, Vol. 45, p. 744.
Graa, J., Ganchev, K., Pereira, F., & Taskar, B. (2009). Parameter vs. posterior sparisty latent
variable models. Proc. NIPS.
Graa, J., Ganchev, K., & Taskar, B. (2007). Expectation maximization posterior constraints.
Proc. NIPS. MIT Press.
Graa, J. a. d. A. V. (2010). Posterior Regularization Framework: Learning Tractable Models
Intractable Constraints. Ph.D. thesis, Universidade Tcnica de Lisboa, Instituto Superior
Tcnico.
Haghighi, A., & Klein, D. (2006). Prototype-driven learning sequence models. Proc. HTLNAACL. ACL.
Headden, III, W. P., McClosky, D., & Charniak, E. (2008). Evaluating unsupervised part-of-speech
tagging grammar induction. Proc. COLING, pp. 329336.
Hwa, R., Resnik, P., Weinberg, A., Cabezas, C., & Kolak, O. (2005). Bootstrapping parsers via
syntactic projection across parallel texts. Special Issue Journal Natural Language
Engineering Parallel Texts, 11(3), 311325.
Johnson, M. (2007). doesnt EM find good HMM POS-taggers. Proc. EMNLP-CoNLL.
Kromann, Matthias T. (2003). Danish Dependency Treebank underlying linguistic
theory. Second Workshop Treebanks Linguistic Theories (TLT), pp. 217220, Vxj,
Sweden.
Lamar, M., Maron, Y., & Bienenstock, E. (2010). Latent-descriptor clustering unsupervised POS
induction. Proceedings 2010 Conference Empirical Methods Natural Language
Processing, pp. 799809, Cambridge, MA. Association Computational Linguistics.
Lamar, M., Maron, Y., Johnson, M., & Bienenstock, E. (2010). SVD clustering unsupervised POS tagging. Proceedings ACL 2010 Conference: Short Papers, pp. 215219,
Uppsala, Sweden. Association Computational Linguistics.
Lee, Y. K., Haghighi, A., & Barzilay, R. (2010). Simple type-level unsupervised POS tagging.
Proceedings 2010 Conference Empirical Methods Natural Language Processing,
pp. 853861, Cambridge, MA. Association Computational Linguistics.

549

fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR

Marcus, M., Marcinkiewicz, M., & Santorini, B. (1993). Building large annotated corpus
English: Penn Treebank. Computational linguistics, 19(2), 313330.
Maron, Y., Lamar, M., & Bienenstock, E. (2010). Evaluation criteria unsupervised POS induction. Tech. rep., Indiana University.
Martin, S., Liermann, J., & Ney, H. (1998). Algorithms bigram trigram word clustering.
Speech Communication, pp. 12531256.
Meila, M. (2007). Comparing clusteringsan information based distance. J. Multivar. Anal., 98(5),
873895.
Merialdo, B. (1994). Tagging English text probabilistic model. Computational linguistics,
20(2), 155171.
Moon, T., Erk, K., & Baldridge, J. (2010). Crouching Dirichlet, hidden Markov model: Unsupervised POS tagging context local tag generation. Proc. EMNLP, Cambridge, MA.
Neal, R. M., & Hinton, G. E. (1998). new view EM algorithm justifies incremental,
sparse variants. Jordan, M. I. (Ed.), Learning Graphical Models, pp. 355368.
Kluwer.
Nocedal, J., & Wright, S. J. (1999). Numerical optimization. Springer.
Ratnaparkhi, A. (1996). maximum entropy model part-of-speech tagging. Proc. EMNLP.
ACL.
Ravi, S., & Knight, K. (2009). Minimized models unsupervised part-of-speech tagging.
Proc. ACL.
Reichart, R., & Rappoport, A. (2009). NVI clustering evaluation measure. Proc. CONLL.
Rosenberg, A., & Hirschberg, J. (2007). V-measure: conditional entropy-based external cluster
evaluation measure. EMNLP-CoNLL, pp. 410420.
Salakhutdinov, R., Roweis, S., & Ghahramani, Z. (2003). Optimization EM expectationconjugate-gradient. Proc. ICML, Vol. 20.
Schtze, H. (1995). Distributional part-of-speech tagging. Proc. EACL, pp. 141148.
Shen, L., Satta, G., & Joshi, A. (2007). Guided learning bidirectional sequence classification.
Proc. ACL, Prague, Czech Republic.
Simov, K., Osenova, P., Slavcheva, M., Kolkovska, S., Balabanova, E., Doikoff, D., Ivanova, K.,
Simov, A., Simov, E., & Kouylekov, M. (2002). Building Linguistically Interpreted Corpus
Bulgarian: BulTreeBank. Proc. LREC.
Smith, N., & Eisner, J. (2005). Contrastive estimation: Training log-linear models unlabeled
data. Proc. ACL. ACL.
Snyder, B., Naseem, T., Eisenstein, J., & Barzilay, R. (2008). Unsupervised multilingual learning
POS tagging. Proceedings Conference Empirical Methods Natural Language
Processing, pp. 10411050. Association Computational Linguistics.
Toutanova, K., & Johnson, M. (2007). Bayesian LDA-based model semi-supervised part-ofspeech tagging. Proc. NIPS, 20.

550

fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION

Toutanova, K., Klein, D., Manning, C., & Singer, Y. (2003). Feature-rich part-of-speech tagging
cyclic dependency network. Proc. HLT-NAACL.
Zhao, Q., & Marcus, M. (2009). simple unsupervised learner POS disambiguation rules given
minimal lexicon. Proc. EMNLP.

551

fiJournal Artificial Intelligence Research 41 (2011) 297-327

Submitted 01/11; published 06/11

Stackelberg vs. Nash Security Games: Extended Investigation
Interchangeability, Equivalence, Uniqueness
Dmytro Korzhyk

DIMA @ CS . DUKE . EDU

Department Computer Science, Duke University
LSRC, Campus Box 90129, Durham, NC 27708, USA

Zhengyu Yin

ZHENGYUY @ USC . EDU

Computer Science Department, University Southern California
3737 Watt Way, Powell Hall Engg. 208, Los Angeles, CA 90089, USA

Christopher Kiekintveld

CDKIEKINTVELD @ UTEP. EDU

Department Computer Science, University Texas El Paso
500 W. University Ave., El Paso, TX 79968, USA

Vincent Conitzer

CONITZER @ CS . DUKE . EDU

Department Computer Science, Duke University
LSRC, Campus Box 90129, Durham, NC 27708, USA

Milind Tambe

TAMBE @ USC . EDU

Computer Science Department, University Southern California
3737 Watt Way, Powell Hall Engg. 410, Los Angeles, CA 90089, USA

Abstract
significant recent interest game-theoretic approaches security, much
recent research focused utilizing leader-follower Stackelberg game model. Among
major applications ARMOR program deployed LAX Airport IRIS program
use US Federal Air Marshals (FAMS). foundational assumption using Stackelberg
games security forces (leaders), acting first, commit randomized strategy;
adversaries (followers) choose best response surveillance randomized strategy.
Yet, many situations, leader may face uncertainty followers surveillance capability.
Previous work fails address leader compute strategy given uncertainty.
provide five contributions context general class security games. First,
show Nash equilibria security games interchangeable, thus alleviating equilibrium
selection problem. Second, natural restriction security games, Stackelberg strategy
also Nash equilibrium strategy; furthermore, solution unique class security
games ARMOR key exemplar. Third, faced follower attack
multiple targets, many properties longer hold. Fourth, show experimentally
(but all) games restriction hold, Stackelberg strategy still Nash
equilibrium strategy, longer true attacker attack multiple targets. Finally,
possible direction future research, propose extensive-form game model makes
defenders uncertainty attackers ability observe explicit.

1. Introduction
significant recent research interest game-theoretic approaches security airports, ports, transportation, shipping infrastructure (Pita et al., 2008; Pita, Jain, Ordonez,
Portway et al., 2009; Jain et al., 2010). Much work used Stackelberg game framec
2011
AI Access Foundation. rights reserved.

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

work model interactions security forces attackers compute strategies
security forces (Conitzer & Sandholm, 2006; Paruchuri et al., 2008; Kiekintveld et al., 2009;
Basilico, Gatti, & Amigoni, 2009; Letchford, Conitzer, & Munagala, 2009; Korzhyk, Conitzer,
& Parr, 2010). framework, defender (i.e., security forces) acts first committing
patrolling inspection strategy, attacker chooses attack observing
defenders choice. typical solution concept applied games Strong Stackelberg Equilibrium (SSE), assumes defender choose optimal mixed (randomized) strategy
based assumption attacker observe strategy choose optimal response.
leader-follower paradigm appears fit many real-world security situations.
Indeed, Stackelberg games heart two major deployed decision-support applications. first ARMOR security system, deployed Los Angeles International Airport
(LAX) (Pita et al., 2008; Jain et al., 2010). domain police able set checkpoints
roads leading particular terminals, assign canine units (bomb-sniffing dogs) patrol
terminals. Police resources domain homogeneous, significant scheduling constraints. second IRIS, similar application deployed Federal Air Marshals
Service (FAMS) (Tsai, Rathi, Kiekintveld, Ordonez, & Tambe, 2009; Jain et al., 2010). Armed
marshals assigned commercial flights deter defeat terrorist attacks. domain
complex constraints. particular, marshals assigned tours flights return
destination, tours given marshal available fly limited
marshals current location timing constraints. types scheduling resource constraints
consider work paper motivated necessary represent domain.
Additionally, security applications currently evaluation even
pipeline. example, Transportation Security Administration (TSA) testing evaluating GUARDS system potential national deployment (at 400 airports) GUARDS
also uses Stackelberg games TSA security resource allocation conducting security activities
aimed protection airport infrastructure (Pita, Bellamane et al., 2009). Another example
application development United States Coast Guard suggesting patrolling strategies protect ports ensure safety security passenger, cargo, vessel operations.
potential examples include protecting electric power grids, oil pipelines, subway systems
infrastructure (Brown, Carlyle, Salmeron, & Wood, 2005); well border security computer
network security.
However, legitimate concerns whether Stackelberg model appropriate
cases. situations attackers may choose act without acquiring costly information
security strategy, especially security measures difficult observe (e.g., undercover officers)
insiders unavailable. cases, simultaneous-move game model may better
reflection real situation. defender faces unclear choice strategy adopt:
recommendation Stackelberg model, simultaneous-move model, something
else entirely? general settings, equilibrium strategy fact differ models.
Consider normal-form game Table 1. row player ability commit, SSE
strategy play .5 b .5, best response column player play
d, gives row player expected utility 2.5.1 hand, players move
simultaneously Nash Equilibrium (NE) game row player play
column player c. seen noticing b strictly dominated row player.
1. games assumed follower indifferent, breaks tie leaders favor (otherwise,
optimal solution well defined).

298

fiS TACKELBERG VS . NASH ECURITY G AMES


b

c
1,1
0,0


3,0
2,1

Table 1: Example game Stackelberg Equilibrium Nash Equilibrium.
Previous work failed resolve defenders dilemma strategy select
attackers observation capability unclear.
paper, conduct theoretical experimental analysis leaders dilemma, focusing
security games (Kiekintveld et al., 2009). formally defined class not-necessarily-zerosum2 games motivated applications discussed earlier. make four primary contributions.
First, show Nash equilibria interchangeable security games, avoiding equilibrium
selection problems. Second, game satisfies SSAS (Subsets Schedules Schedules)
property, defenders set SSE strategies subset NE strategies. case, defender always playing best response using SSE regardless whether attacker observes
defenders strategy not. Third, provide counter-examples (partial) equivalence
two cases: (1) SSAS property hold defender schedules, (2)
attacker attack multiple targets simultaneously. cases, defenders SSE strategy may
part NE profile. Finally, experimental tests show fraction games
SSE strategy played part NE profile vanishingly small. However, attacker attack multiple targets, SSE strategy fails NE strategy relatively
large number games.
Section 2 contains formal definition security games considered paper. Section 3
contains theoretical results Nash Stackelberg equilibria security games,
consider main contributions paper. Section 4, show results
hold extension security games allows attacker attack multiple targets once.
Section 5 contains experimental results. initiate future research cases properties
Section 3 hold, present Section 6 extensive-form game model makes
defenders uncertainty attackers ability observe explicit. discuss additional related
work Section 7, conclude Section 8.

2. Definitions Notation
security game (Kiekintveld et al., 2009) two-player game defender attacker.
attacker may choose attack target set = {t1 , t2 , . . . , tn }. defender tries
prevent attacks covering targets using resources set R = {r1 , r2 , . . . , rK }. shown
Figure 1, Udc (ti ) defenders utility ti attacked ti covered defender
resource. ti covered, defender gets Udu (ti ). attackers utility denoted similarly
2. not-necessarily-zero-sumness games used counter-terrorism security resource allocation analysis
emphasized Bier (2007), Keeney (2007), Rosoff John (2009). focus preference elicitation
defenders attackers explicitly outline objectives different terrorist groups individuals often
different other, defenders attackers objectives exact opposites other.
instance, Bier (2007) notes attackers utility also depend factors may significant effect
defenders utility, cost mounting attack well propaganda value target
attacker.

299

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

Uac (ti ) Uau (ti ). use Ud (ti ) = Udc (ti ) Udu (ti ) denote difference defenders
covered uncovered utilities. Similarly, Ua (ti ) = Uau (ti ) Uac (ti ). key property
security games, assume Ud (ti ) > 0 Ua (ti ) > 0. words, adding resources cover
target helps defender hurts attacker.
Attacker

Defender
Udc(ti)

Uac(ti)

Ua(ti) > 0

Udu(ti)

Uau(ti)

Ud(ti) > 0
covered

Covered

Figure 1: Payoff structure security games.
Motivated FAMS similar domains, introduce resource scheduling constraints
defender. Resources may assigned schedules covering multiple targets, .
resource ri , subset Si schedules resource ri potentially cover. is,
ri cover Si . FAMS domain, flights targets air marshals resources.
Schedules capture idea air marshals fly tours, must return particular starting point.
Heterogeneous resources express additional timing location constraints limit tours
particular marshal assigned fly. important subset FAMS domain
modeled using fixed schedules size 2 (i.e., pair departing returning flights).
LAX domain also subclass security games defined here, schedules size 1
homogeneous resources.
security game described represented normal form game, follows.
attackers pure strategy space set targets. attackers mixed strategy = hai
vector ai represents probability attacking
QK ti . defenders pure strategy feasible
assignment resources schedules, i.e., hsi i=1 Si . Since covering target one resource
essentially covering positive number resources, defenders pure
strategy also represented coverage vector = hdi {0, 1}n di represents
whether ti covered not. example, h{t1 , t4 }, {t2 }i possible assignment,
corresponding coverage vector h1, 1, 0, 1i. However, coverage vectors feasible due
resource schedule constraints. denote set feasible coverage vectors {0, 1}n .
defenders mixed strategy C specifies probabilities playing D,
individual probability denoted
P Cd . Let c = hci vector coverage probabilities corresponding C, ci = dD di Cd marginal probability covering ti . example,
suppose defender two coverage vectors: d1 = h1, 1, 0i d2 = h0, 1, 1i. mixed
strategy C = h.5, .5i, corresponding vector coverage probabilities c = h.5, 1, .5i. Denote
mapping C c , c = (C).
strategy profile hC, ai played, defenders utility

Ud (C, a) =

n
X

ai (ci Udc (ti ) + (1 ci )Udu (ti )) ,

i=1

300

fiS TACKELBERG VS . NASH ECURITY G AMES

attackers utility
Ua (C, a) =

n
X

ai (ci Uac (ti ) + (1 ci )Uau (ti )) .

i=1

players move simultaneously, standard solution concept Nash equilibrium.
Definition 1. pair strategies hC, ai forms Nash Equilibrium (NE) satisfy following:
1. defender plays best-response:
Ud (C, a) Ud (C0 , a) C0 .
2. attacker plays best-response:
Ua (C, a) Ua (C, a0 ) a0 .
Stackelberg model, defender chooses mixed strategy first, attacker chooses
strategy observing defenders choice. attackers response function g(C) : C a.
case, standard solution concept Strong Stackelberg Equilibrium (Leitmann, 1978; von
Stengel & Zamir, 2010).
Definition 2. pair strategies hC, gi forms Strong Stackelberg Equilibrium (SSE) satisfy
following:
1. leader (defender) plays best-response:
Ud (C, g(C)) Ud (C0 , g(C0 )), C0 .
2. follower (attacker) plays best-response:
Ua (C, g(C)) Ua (C, g 0 (C)), C, g 0 .
3. follower breaks ties optimally leader:
Ud (C, g(C)) Ud (C, (C)), C, (C) set follower best-responses
C.
denote set mixed strategies defender played Nash Equilibrium
N E , corresponding set Strong Stackelberg Equilibrium SSE . defenders
SSE utility always least high defenders utility NE profile. holds
game, security games. follows following: SSE model, leader
least choose commit NE strategy. so, follower choose
among best responses one maximizes utility leader (due tie-breaking
assumption), whereas NE follower also choose best responses defender strategy (but necessarily ones maximize leaders utility). fact stronger
claim holds: leaders SSE utility least high correlated equilibrium. observations due von Stengel Zamir (2010) give much detailed discussion
points (including, implicitly, extent still holds without tie-breaking assumption).
basic model, assumed players utility functions common knowledge.
best approximation truth, useful reflect importance
assumption. SSE model, defender needs know attackers utility function order
compute SSE strategy, attacker need know defenders utility function;
301

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

needs best-respond know mixed strategy defender committed.3
hand, NE model, attacker observe defenders mixed strategy needs
know defenders utility function. Arguably, much harder justify practice,
may related SSE model used applications discussed earlier. goal
paper argue NE model, rather discuss relationship SSE
NE strategies defender. show Nash equilibria interchangeable security
games, suggesting NE strategies better properties security games
general. also show large class games, defenders SSE strategy guaranteed
NE strategy well, longer issue defender; attackers NE
strategy indeed depend defenders utility function, see affect
defenders NE strategy.
course, practice, defender generally know attackers utility function exactly. One way address make uncertainty explicit model game Bayesian
game (Harsanyi, 1968), known algorithms solving SSE strategies Bayesian games
(e.g., Paruchuri et al., 2008) practical small security games, depend
writing complete action space player, exponential size security games.
addition, even complete action space written out, problem NP-hard (Conitzer &
Sandholm, 2006) good approximation guarantee possible unless P=NP (Letchford et al.,
2009). recent paper Kiekintveld, Marecki, Tambe (2011) discusses approximation methods models. Another issue attacker assumed respond optimally,
may true practice; several models Stackelberg games imperfect follower
proposed Pita, Jain, Ordonez, Tambe et al. (2009). solution concepts also make
solution robust errors estimation attackers utility function. consider
Bayesian games imperfect attackers paper.

3. Equilibria Security Games
challenge us understand fundamental relationships SSE NE strategies security games. special case zero-sum security games, defenders utility
exact opposite attackers utility. finite two-person zero-sum games, known
different game theoretic solution concepts NE, minimax, maximin SSE give
answer. addition, Nash equilibrium strategies zero-sum games useful property
interchangeable: equilibrium strategy one player paired
players strategy equilibrium profile, result equilibrium, payoffs
players remain same.
Unfortunately, security games necessarily zero-sum (and zero-sum deployed
applications). Many properties zero-sum games hold security games. instance,
minimax strategy security game may maximin strategy. Consider example
Table 2, 3 targets one defender resource. defender three actions;
defenders actions cover one target time, leaving targets uncovered.
3. Technically, exactly true attacker needs break ties defenders favor. However,
attacker indifferent among multiple actions, defender generally modify strategy slightly make
attacker strictly prefer action optimal defender; point tiebreaking assumption merely
make optimal solution well defined. See also work von Stengel Zamir (2010) discussion
generic games particular.

302

fiS TACKELBERG VS . NASH ECURITY G AMES

three targets equally appealing attacker, defender varying utilities capturing
attacker different targets. defender, unique minimax strategy, h1/3, 1/3, 1/3i,
different unique maximin strategy, h6/11, 3/11, 2/11i.
t1
Def
Att

t2

t3

C

U

C

U

C

U

1
0

0
1

2
0

0
1

3
0

0
1

Table 2: Security game strategically zero-sum.
Strategically zero-sum games (Moulin & Vial, 1978) natural strict superset zerosum games desirable properties zero-sum games still hold. exactly
class games completely mixed Nash equilibrium improved upon. Moulin
Vial proved game (A, B) strategically zero-sum exist u > 0 v > 0
uA + vB = U + V , U matrix identical columns V matrix
identical rows (Moulin & Vial, 1978). Unfortunately, security games even strategically zerosum. game Table 2 counterexample, otherwise must exist u, v > 0
that,




1 0 0
0 1 1
u 0 2 0 + v 1 0 1
0 0 3
1 1 0




x z
= b b b + x z
c c c
x z
equations, + = + z = b + x = b + z = c + x = c + = v, implies
x = = z = b = c. also know + x = u, b + = 2u, c + z = 3u. However since
+ x = b + = c + z, u must 0, contradicts assumption u > 0.
Another concept worth mentioning unilaterally competitive games (Kats &
Thisse, 1992). game unilaterally competitive (or weakly unilaterally competitive), implies
player unilaterally changes action way increases utility, must
result (weak) decrease utility every players utility. hold security
games: example, attacker switches heavily defended sensitive target
undefended target little value defender, change may make players strictly
better off. example shown Table 3. attacker switches attacking t1 attacking
t2 , players utility increases.
Nevertheless, show rest section security games still important
properties. start establishing equivalence set defenders minimax strategies
set defenders NE strategies. Second, show Nash equilibria security games
interchangeable, resolving defenders equilibrium strategy selection problem simultaneousmove games. Third, show natural restriction schedules, SSE strategy
defender also minimax strategy hence NE strategy. resolves defenders dilemma
whether play according SSE NE uncertainty attackers ability
303

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

t1
Def
Att

t2

C

U

C

U

1
0

0
1

3
2

2
3

Table 3: security game unilaterally competitive (or weakly unilaterally competitive).

observe strategy: defender safely play SSE strategy, guaranteed
NE strategy well, moreover Nash equilibria interchangeable risk
choosing wrong equilibrium strategy. Finally, restricted class games (including
games LAX domain), find unique SSE/NE defender strategy
unique attacker NE strategy.
3.1 Equivalence NE Minimax
first prove defenders NE strategy also minimax strategy. every defenders
minimax strategy C construct strategy attacker hC, ai NE profile.
Definition 3. defenders mixed strategy C, define attackers best response utility
E(C) = maxni=1 Ua (C, ti ). Denote minimum attackers best response utilities
defenders strategies E = minC E(C). set defenders minimax strategies defined
as:
= {C|E(C) = E }.
define function f follows. attackers strategy target ti attacked
probability ai , f (a) = attackers strategy
Ud (ti )
Ua (ti )
Pn
> 0 normalizing constant i=1 ai = 1. intuition behind function f
defender prefers playing strategy C playing another strategy C0 security game
G attacker plays strategy defender also prefers playing C playing
C0 attacker plays f (a) corresponding zero-sum security game G, defined
Lemma 3.1 below. Also, supports attacker strategies f (a) same.
show Lemma 3.1, function f provides one-to-one mapping attackers NE strategies G
attackers NE strategies G, inverse function f 1 (a) = given following
equation.
1 Ua (ti )
ai = ai
(1)
Ud (ti )
ai = ai

Lemma 3.1. Consider security game G. Construct corresponding zero-sum security game G
defenders utilities re-defined follows.
Udc (t) = Uac (t)
Udu (t) = Uau (t)
hC, ai NE profile G hC, f (a)i NE profile G.
304

fiS TACKELBERG VS . NASH ECURITY G AMES

Proof. Note supports strategies = f (a) same, also attackers
utility function games G G. Thus best response C G
best response C G.
Denote utility defender gets profile hC, ai played game G UdG (C, a).
show C best response game G C best response G,
sufficient show equivalence following two inequalities.
UdG (C, a) UdG (C0 , a) 0
UdG (C, a) UdG (C0 , a) 0
prove equivalence starting first inequality transforming second
one. one hand, have,
UdG (C, a) UdG (C0 , a) =

n
X

ai (ci c0i )Ud (ti ).

i=1

Similarly, hand, have,
UdG (C, a) UdG (C0 , a) =

n
X

ai (ci c0i )Ua (ti ).

i=1

Given Equation (1) > 0, have,
UdG (C, a) UdG (C0 , a) 0
n
X

ai (ci c0i )Ud (ti ) 0



i=1
n
X

1 Ua (ti )
ai
(ci c0i )Ud (ti ) 0
Ud (ti )

i=1
n
X

1


ai (ci c0i )Ua (ti ) 0

i=1


1 G

Ud (C, a) UdG (C0 , a) 0

UdG (C, a) UdG (C0 , a) 0

Lemma 3.2. Suppose C defender NE strategy security game. E(C) = E , i.e.,
N E .
Proof. Suppose hC, ai NE profile security game G. According Lemma 3.1, hC, f (a)i
must NE profile corresponding zero-sum security game G. Since C NE strategy
zero-sum game G, must also minimax strategy G (Fudenberg & Tirole, 1991).
attackers utility function G G, thus C must also minimax strategy G,
E(C) = E .
305

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

Lemma 3.3. security game G, defenders strategy C E(C) = E NE
strategy, i.e., N E .
Proof. C minimax strategy G corresponding zero-sum game G. minimax
strategy also NE strategy zero-sum game (Fudenberg & Tirole, 1991). must
exist NE profile hC, ai G. Lemma 3.1, hC, f 1 (a)i NE profile G. Thus C
NE strategy G.
Theorem 3.4. security game, set defenders minimax strategies equal set
defenders NE strategies, i.e., = N E .
Proof. Lemma 3.2 shows every defenders NE strategy minimax strategy, Lemma 3.3
shows every defenders minimax strategy NE strategy. Thus sets defenders NE
minimax strategies must equal.
important emphasize defenders equilibrium strategies
G G, true attackers equilibrium strategies: attacker probabilities leave
defender indifferent across support G necessarily leave indifferent G.
reason function f (a) above.
3.2 Interchangeability Nash Equilibria
show Nash equilibria security games interchangeable. result indicates that,
case attacker cannot observe defenders mixed strategy, effectively
equilibrium selection problem: long player plays strategy equilibrium,
result guaranteed equilibrium. course, still resolve issue
clear whether attacker observe mixed strategy; return issue
Subsection 3.3.
Theorem 3.5. Suppose hC, ai hC0 , a0 two NE profiles security game G. hC, a0
hC0 , ai also NE profiles G.
Proof. Consider corresponding zero-sum game G. Lemma 3.1, hC, f (a)i hC0 , f (a0 )i
must NE profiles G. interchange property NE zero-sum games (Fudenberg & Tirole, 1991), hC, f (a0 )i hC0 , f (a)i must also NE profiles G. Applying Lemma 3.1
direction, get hC, a0 hC0 , ai must NE profiles G.
Theorem 3.5, defenders equilibrium selection problem simultaneous-move security
game resolved. reason given attackers NE strategy a, defender must get
utility responding NE strategy. Next, give insights expected utilities
NE profiles. first show attackers expected utility NE profiles, followed
example demonstrating defender may varying expected utilities corresponding
different attackers strategies.
Theorem 3.6. Suppose hC, ai NE profile security game. Then, Ua (C, a) = E .
Proof. Lemma 3.2, C minimax strategy E(C) = E . one hand,
Ua (C, a) =

n
X

ai Ua (C, ti )

i=1

n
X
i=1

306

ai E(C) = E .

fiS TACKELBERG VS . NASH ECURITY G AMES

hand, best response C, least good strategy
attacking arg maxt Ua (C, t) probability 1, is,
Ua (C, a) Ua (C, ) = E(C) = E .
Therefore know Ua (C, a) = E .
Unlike attacker gets utility NE profiles, defender may get varying
expected utilities depending attackers strategy selection. Consider game shown Table 4. defender choose cover one two targets time. defender NE
strategy cover t1 100% probability, making attacker indifferent attacking t1
t2 . One attacker NE strategy always attack t1 , gives defender expected utility
1. Another attackers NE strategy h2/3, 1/3i, given defender indifferent
defending t1 t2 . case, defenders utility decreases 2/3 captures
attacker lower probability.
t1
Def
Att

t2

C

U

C

U

1
1

0
2

2
0

0
1

Table 4: security game defenders expected utility varies different NE profiles.

3.3 SSE Strategies Also Minimax/NE Strategies
already shown set defenders NE strategies coincides minimax strategies. every defenders SSE strategy also minimax strategy, SSE strategies must also
NE strategies. defender safely commit SSE strategy; selection problem defender. Unfortunately, security game arbitrary scheduling constraints,
SSE strategy may part NE profile. example, consider game Table 5 4
targets {t1 , . . . , t4 }, 2 schedules s1 = {t1 , t2 }, s2 = {t3 , t4 }, single defender resource.
defender always prefers t1 attacked, t3 t4 never appealing attacker.
t1
Def
Att

t2

t3

t4

C

U

C

U

C

U

C

U

10
2

9
5

-2
3

-3
4

1
0

0
1

1
0

0
1

Table 5: schedule-constrained security game defenders SSE strategy NE
strategy.

unique SSE strategy defender, places much coverage probability
s1 possible without making t2 appealing attacker t1 . rest coverage
probability placed s2 . result s1 s2 covered probability 0.5.
307

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

contrast, simultaneous-move game, t3 t4 dominated attacker. Thus,
reason defender place resources targets never attacked, defenders unique
NE strategy covers s1 probability 1. is, defenders SSE strategy different
NE strategy. difference defenders payoffs cases also arbitrarily
large t1 always attacked SSE t2 always attacked NE.
example restricts defender protect t1 t2 together, makes impossible
defender put coverage t2 without making t1 less appealing. defender could
assign resources subset schedule, difficulty resolved. formally, assume
resource ri , subset schedule Si also possible schedule Si :
1 K : s0 Si s0 Si .

(2)

security game satisfies Equation (2), say SSAS property. natural many
security domains, since often possible cover fewer targets maximum number
resource could possible cover schedule. find property sufficient ensure
defenders SSE strategy must also NE strategy.
Lemma 3.7. Suppose C defender strategy security game satisfies SSAS property
c = (C) corresponding vector marginal probabilities. c0
0 c0i ci ti , must exist defender strategy C0 (C0 ) = c0 .
Proof. proof induction number ti c0i 6= ci , denoted (c, c0 ).
base case, c0i 6= ci , existence trivially holds (C) = c0 .
Suppose existence holds c, c0 (c, c0 ) = k, 0 k n 1. consider
c, c0 (c, c0 ) = k + 1. j, c0j 6= cj . Since c0j 0 c0j < cj ,
cj > 0. must nonempty set coverage vectors Dj cover tj receive positive
probability C. security game satisfies SSAS property, every Dj ,
valid covers targets except tj . defender strategy C, shifting
Cd (cj c0j )
probability every Dj corresponding , get defender strategy C
cj
ci = ci 6= j, ci = c0i = j. Hence (c , c0 ) = k, implying exists C0
(C0 ) = c0 induction assumption. induction, existence holds c, c0 .

Theorem 3.8. Suppose C defender SSE strategy security game satisfies SSAS
property. E(C) = E , i.e., SSE = N E .
Proof. proof contradiction. Suppose hC, gi SSE profile security game
satisfies SSAS property, E(C) > E . Let Ta = {ti |Ua (C, ti ) = E(C)} set targets
give attacker maximum utility given defender strategy C. definition SSE,

Ud (C, g(C)) = max Ud (C, ti ).
ti Ta

Consider defender mixed strategy C E(C ) = E . ti Ta , Ua (C , ti )
E . Consider vector c0 :



c E Ua (C , ti ) + ,
ti Ta ,
(3a)

Uau (ti ) Uac (ti )
c0i =

ci ,
ti
/ Ta ,
(3b)
308

fiS TACKELBERG VS . NASH ECURITY G AMES

infinitesimal positive number. Since E Ua (C , ti ) + > 0, c0i < ci
ti Ta . hand, since ti Ta ,
Ua (c0 , ti ) = E + < E(C) = Ua (C, ti ),
c0i > ci 0. ti , 0 c0i ci . Lemma 3.7, exists
defender strategy C0 corresponding c0 . attackers utility attacking target follows:

E + ,
ti Ta ,
(4a)
0
Ua (C , ti ) =


Ua (C , ti ) E ,
ti
/ Ta .
(4b)
Thus, attackers best responses C0 still Ta . ti Ta , since c0i > ci , must
case Ud (C, ti ) < Ud (C0 , ti ). definition attackers SSE response g, have,
Ud (C0 , g(C0 )) = max Ud (C0 , ti )
ti Ta

> max Ud (C, ti ) = Ud (C, g(C)).
ti Ta

follows defender better using C0 , contradicts assumption C SSE
strategy defender.
Theorem 3.4 3.8 together imply following corollary.
Corollary 3.9. security games SSAS property, defenders SSE strategy also
NE strategy.
answer original question posed paper: uncertainty
type game played, defender choose SSE strategy mixed strategy Nash
equilibrium combination two?4 domains satisfy SSAS property,
proven defender safely play SSE strategy, guaranteed Nash
equilibrium strategy well, moreover Nash equilibria interchangeable
risk choosing wrong equilibrium strategy.
Among motivating domains, LAX domain satisfies SSAS property since schedules
size 1. patrolling domains, patrolling port, also satisfy SSAS property.
domains, defender could thus commit SSE strategy, also known
NE strategy. defender retains ability commit, still playing best-response
attacker simultaneous-move setting (assuming attacker plays equilibrium strategy
matter one, due interchange property shown above). However, FAMS
domain naturally satisfy SSAS property marshals must fly complete tours.5
question selecting SSE vs. NE strategies case addressed experimentally Section 5.
4. course, one may agree that, cases common knowledge players move simultaneously,
playing NE strategy right thing practice. question heart game theory
far beyond scope paper resolve. paper, goal argue using NE strategies
simultaneous-move settings general; rather, assess robustness SSE strategies changes
information structure specific classes security games. purpose, NE seems like natural representative
solution concept simultaneous-move security games, especially light interchangeability properties
show.
5. principle, FAMs could fly civilians legs tour. However, would need able commit
acting civilians (i.e., intervening attempt hijack aircraft) attacker would need believe
FAM would intervene, difficult achieve practice.

309

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

3.4 Uniqueness Restricted Games
previous sections show SSE strategies NE strategies many cases. However,
may still multiple equilibria select (though difficulty alleviated interchange
property). prove even stronger uniqueness result important restricted class
security domains, includes LAX domain. particular, consider security games
defender homogeneous resources cover single target. SSAS property
trivially satisfied,
since schedules size 1. vector coverage probabilities c = hci
P
ni=1 ci K feasible strategy defender, represent defender
strategy marginal coverage probabilities. minor restriction attackers payoff matrix,
defender always unique minimax strategy also unique SSE NE strategy.
Furthermore, attacker also unique NE response strategy.
Theorem 3.10. security game homogeneous resources cover single target,
every target ti , Uac (ti ) 6= E , defender unique minimax, NE, SSE
strategy.
Proof. first show defender unique minimax strategy. Let = {t|Uau (t) E }.
Define c = hci

u

Ua (ti ) E ,
ti ,
(5a)
ci =
Uau (ti ) Uac (ti )

0,
ti
/ .
(5b)
Note E cannot less Uac (ti ) otherwise, regardless defenders strategy,
attacker could always get least Uac (ti ) > E attacking ti , contradicts fact
E attackers best response utility defenders minimax strategy. Since E Uac (ti )
assume E 6= Uac (ti ),
1 ci =

E Uac (ti )
> 0 ci < 1.
Uau (ti ) Uac (ti )

P
P
Next, prove ni=1 ci K. sake ofPcontradiction, suppose ni=1 ci < K. Let
n
0



> 0
c0 = hc0i i,
Pn ci0 = ci + . Since ci < 1 i=1 ci < K, find
0
ci < 1 i=1 ci < K. every target strictly higher coverage c0 c , hence
E(c0 ) < E(c ) = E , contradicts fact E minimum E(c).
Next, show c minimax strategy, c = c . P
definition minimax
n
. Hence, U (c, ) E c c . one hand
strategy, E(c)
=
E



i=1 ci K
Pn
Pn
hand i=1 ci i=1 ci K. Therefore must case ci = ci i. Hence,
c unique minimax strategy defender.
Furthermore, Theorem 3.4, c unique defenders NE strategy. Theorem 3.8 existence SSE (Basar & Olsder, 1995), c unique defenders
SSE strategy.
following example, show Theorem 3.10 work without condition
Uac (ti ) 6= E every ti . Consider security game 4 targets defender two
homogeneous resources, resource cover single target, players utility functions
defined Table 5. defender guarantee minimum attackers best-response utility
310

fiS TACKELBERG VS . NASH ECURITY G AMES

E = 3 covering t1 probability 2/3 covering t2 probability 1. Since
E = Uac (t2 ), Theorem 3.10 apply. defender prefers attack t1 , defender
must cover t1 probability exactly 2/3 SSE strategy. Thus defenders SSE strategies
coverage vectors (2/3, 1, 1/3, 0), (2/3, 1, 0, 1/3), convex combination two
vectors. According Theorem 3.8, SSE strategies also minimax/NE strategy,
defenders SSE, minimax, NE strategies unique example.
Theorem 3.11. security game homogeneous resources cover one target,
every target ti , Uac (ti ) 6= E Uau (ti ) 6= E , attacker unique NE strategy.
Proof. c proof Theorem 3.10. Given defenders unique NE
strategy c , attackers best response, ti attacked positive probability,
because,

E
ti
(6a)

Ua (c , ti ) =
u

Ua (ti ) < E
ti
/
(6b)
Suppose hc , ai forms NE profile.
X

ai = 1

(7)

ti

ti , know proof Theorem 3.10 ci < 1. addition,
Uau (t) 6= E , ci 6= 0. Thus 0 < ci < 1 ti . ti , tj ,
necessarily ai Ud (ti ) = aj Ud (tj ). Otherwise, assume ai Ud (ti ) > aj Ud (tj ). Consider
another defenders strategy c0 c0i = ci + < 1, c0j = cj > 0, c0k = ck k 6= i, j.
Ud (c0 , a) Ud (c , a) = ai Ud (ti ) aj Ud (tj ) > 0
Hence, c best response a, contradicts assumption hc , ai NE profile.
Therefore, exists > 0 that, ti , ai Ud (ti ) = . Substituting ai
/Ud (ti ) Equation (7),
= X
ti

1
1
Ud (ti )

explicitly write
ai =





,
Ud (ti )

0,

ti ,

(8a)

ti
/ .

(8b)

see, defined (8a) (8b) unique attacker NE strategy.
following example, show Theorem 3.11 work without condition
Uau (ti ) 6= E every ti . Consider game three targets defender one resource cover single target utilities defined Table 6. defender
guarantee minimum attackers best-response utility E = 2 covering targets t1 t2
311

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

probability 1/2 each. Since Uac (ti ) 6= E every ti , Theorem 3.10 applies, defenders
strategy coverage vector (.5, .5, 0) unique minimax/NE/SSE strategy. However, Theorem 3.11 apply Uau (t3 ) = E . attackers NE strategy indeed unique,
attacker strategies (.5, .5, 0) (1/3, 1/3, 1/3) (as well convex combination
strategies) valid NE best-responses.
t1
Def
Att

t2

t3

C

U

C

U

C

U

0
1

1
3

0
1

1
3

0
0

1
2

Table 6: example game defender unique minimax/NE/SSE strategy coverage vector (.5, .5, 0), attacker unique NE strategy. Two possible
attackers NE strategies (.5, .5, 0) (1/3, 1/3, 1/3).

implication Theorem 3.10 Theorem 3.11 certain conditions
simultaneous-move game, defender attacker unique NE strategy,
gives player unique expected utility result.

4. Multiple Attacker Resources
point assumed attacker attack exactly one target. extend
security game definition allow attacker use multiple resources attack multiple targets
simultaneously.
4.1 Model Description
keep model simple, assume homogeneous resources (for players) schedules
size 1. defender K < n resources assigned protect target,
attacker L < n resources used attack target. Attacking target
multiple resources equivalent attacking single resource. defenders pure strategy
coverage vector = hdi D, di {0, 1} represents whether ti P
covered not.
n
Similarly,

attackers
pure
strategy


attack
vector
q
=
hq


Q.



i=1 di = K
Pn
i=1 qi = L. pure strategies hd, qi played, attacker gets utility
Ua (d, q) =

n
X

qi (di Uac (ti ) + (1 di )Uau (ti ))

i=1

defenders utility given
Ud (d, q) =

n
X

qi (di Udc (ti ) + (1 di )Udu (ti ))

i=1

defenders mixed strategy vector C specifies probability playing
D. Similarly, attackers mixed strategy vector probabilities corresponding
312

fiS TACKELBERG VS . NASH ECURITY G AMES

q Q. defined Section 2, describe players mixed strategies pair vectors
hc, ai, ci probability target ti defended, ai probability ti
attacked.
4.2 Overview Results
games multiple attacker resources, defenders SSE strategy also NE strategy,
like single-attacker-resource case. example, suppose targets interchangeable
defender attacker. Then, defenders SSE strategy defend targets
equal probabilities, defenders utility attack least defended targets
maximized. attacker best-responds attacking targets equal probabilities,
resulting strategy profile NE. Thus defenders SSE strategy also NE strategy
case. Example 1 discusses case detail. observe defenders
SSE strategy example matter attacker 1 2 resources. use
observation construct sufficient condition defenders SSE strategy also
NE strategy security games multiple attacker resources (Proposition 4.2). modest
positive result, however, exhaustive sense explain cases
defenders SSE strategy also NE strategy. Example 2 describes game defenders
SSE strategy also NE strategy, condition Proposition 4.2 met.
games multiple attacker resources, defenders SSE strategy part
NE profile. following gives intuition happen. Suppose
target ti defender strongly hopes attacked (even Udc (ti ) negative),
given ti fact attacked, defending help defender much (Ud (ti ) =
Udc (ti ) Udu (ti ) small). SSE model, defender likely want devote defensive
resources ti , attacker observe want attack ti . However,
NE model, defenders strategy cannot influence attacker does, marginal utility
assigning defensive resources ti small; and, attacker multiple resources,
may well another target attacker also attack valuable defend,
defender send defensive resources instead. provide detailed descriptions games
defenders SSE strategy part NE profile Examples 3, 4, 5.
Since condition Proposition 4.2 implies defenders SSE NE strategies
change number attacker resources varies, provide exhaustive set example games
equality SSE NE strategies broken number different ways
(Examples 2, 3, 4, 5). set examples rules number ways Proposition 4.2
might generalized larger set games.
4.3 Detailed Proofs Examples
certain assumptions, SSE defender strategies still NE defender strategies model
multiple attacker resources. give simple sufficient condition hold. First,
need following lemma.
Lemma 4.1. Given security game G L L attacker resources, let G 1 game except
one attacker resource. Let hc, ai Nash equilibrium G 1 . Suppose target
ti , Lai 1. Then, hc, Lai Nash equilibrium G L .
313

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

Proof. Lai 1 ti , La fact feasible attacker strategy G L . left
prove hd, Lai fact equilibrium. attacker best-responding utility
attacking given target unchanged relative equilibrium G 1 . defender
best-responding utility defending schedule multiplied L relative
G 1 , still optimal defender defend schedules support c.
lemma immediately gives us following proposition:
Proposition 4.2. Given game G L L attacker resources SSAS holds, let G 1
game except one attacker resource. Suppose SSE strategy G L
G 1 . Let strategy attacker hd, ai Nash equilibrium G 1 (we know
exists Corollary 3.9). Lai 1 target ti , hd, Lai NE profile G L ,
means SSE NE strategy G L .
simple example Proposition 4.2 applies constructed follows.
Example 1. Suppose 3 targets, completely interchangeable players.
Suppose defender 1 resource. attacker 1 resource, defenders SSE strategy
= (1/3, 1/3, 1/3) attackers NE best-response = (1/3, 1/3, 1/3). attacker
2 resources, defenders SSE strategy still d. Since ti , 2ai 1, Proposition 4.2
applies, profile hd, 2ai NE profile.
denote defenders SSE strategy game L attacker resources cS,L denote
defenders NE strategy game cN ,L . Example 1, cN ,1 = cS,1 =
cS,2 = cN ,2 . Hence, conditions, defenders strategy always sameregardless
whether use SSE NE regardless whether attacker 1 2 resources.
show several examples games true, even though SSAS holds.
following cases, show example game SSAS holds relation
defenders equilibrium strategies specified case description. first case,
SSE strategy equal NE strategy L = 2, condition Proposition 4.2 met
SSE strategy L = 1 different SSE strategy L = 2, also
multiplying attackers NE strategy game L = 1 attacker resource 2 result
feasible attackers strategy (in game L = 2 attacker resources otherwise
same). last three cases, SSE strategy equal NE strategy L = 2.
cS,2 = cN ,2 6= cN ,1 = cS,1 (SSE vs. NE makes difference, L makes difference);
cN ,2 6= cS,2 = cS,1 = cN ,1 (NE L = 2 different cases);
cS,2 6= cN ,2 = cN ,1 = cS,1 (SSE L = 2 different cases);
cS,2 6= cN ,2 ; cS,2 6= cS,1 = cN ,1 ; cN ,2 6= cN ,1 = cS,1 (all cases different, except SSE
NE L = 1 implied Corollary 3.9).
easy see cases exhaustive, following. Corollary 3.9 necessitates cS,1 = cN ,1 (because want SSAS hold cS,L cN ,L strategy unique),
effectively three potentially different strategies, cN ,2 , cS,2 , cS,1 = cN ,1 .
either (as Example 1 Proposition 4.2), different (the last case),
exactly two (the first three cases).
314

fiS TACKELBERG VS . NASH ECURITY G AMES

give examples. examples, schedules size 1,
defender single resource.
Example 2 (cS,2 = cN ,2 6= cN ,1 = cS,1 ). Consider game shown Table 7. defender
1 resource. attacker 1 resource, target t1 attacked probability 1, hence
defended probability 1 well (whether SSE NE model). attacker
2 resources, targets attacked, target t2 defended Ud (t2 ) > Ud (t1 )
(whether SSE NE model).
t1
Def
Att

t2

C

U

C

U

0
2

1
3

0
0

2
1

Table 7: example game cS,2 = cN ,2 6= cN ,1 = cS,1 . single attacker resource,
attacker always attack t1 , defender defend t1 . two attacker
resources, attacker attack targets, case defender prefers
defend t2 .

Example 3 (cN ,2 6= cS,2 = cS,1 = cN ,1 ). Consider game shown Table 8. defender
1 resource. attacker 1 resource, follows Theorem 3.10 unique defender
minimax/NE/SSE strategy cS,1 = cN ,1 = (2/3, 1/6, 1/6).
t1
Def
Att

t2

t3

C

U

C

U

C

U

10
1

11
3

0
0

3
2

0
0

3
2

Table 8: example game cN ,2 6= cS,2 = cS,1 = cN ,1 . example corresponds
intuition given earlier. Target t1 sensitive target defender: defender suffers
large loss t1 attacked. However, t1 attacked, allocating defensive resources
benefit defender much, low marginal utility Ud (t1 ) = 1.
result, target t1 defended NE profile h(0, .5, .5), (1, .5, .5)i,
defended SSE profile h(1, 0, 0), (0, 1, 1)i.
suppose attacker 2 resources. SSE, defender wants primarily avoid
attack t1 (so t2 t3 attacked probability 1 each). constraint,
defender wants maximize total probability t2 t3 (they interchangeable
attacked, probability equally valuable either one). defender strategy (2/3, 1/6, 1/6)
unique optimal solution optimization problem.
However, straightforward verify following NE profile attacker 2
resources: h(0, .5, .5), (1, .5, .5)i. prove unique NE. First, show t1
315

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

defended probability 0 NE. one targets t2 , t3 must attacked
probability least .5. Thus, defender always incentive move probability
t1 target. follows t1 defended NE. Now, t1 defended, t1
attacked probability 1. remains effectively single-attacker-resource security game
t2 t3 clear unique equilibrium h(.5, .5), (.5, .5)i, thereby proving uniqueness.
Example 4 (cS,2 6= cN ,2 = cN ,1 = cS,1 ). Consider game shown Table 9. defender
1 resource. attacker 1 resource, defenders unique minimax/NE/SSE strategy
minimax strategy (1, 0, 0).
suppose attacker 2 resources. t1 must attacked probability 1.
Ud (t1 ) = 2 > 1 = Ud (t2 ) = Ud (t3 ), NE, implies defender must put full
probability 1 t1 . Hence, attacker attack t2 resource. So, unique NE
profile h(1, 0, 0), (1, 1, 0)i.
contrast, SSE, defenders primary goal avoid attack t2 , requires
putting probability least .5 t2 (so attacker prefers t3 t2 ). result t1
t3 attacked; defender prefers defend t1 remaining probability
Ud (t1 ) = 2 > 1 = Ud (t3 ). Hence, unique SSE profile h(.5, .5, 0), (1, 0, 1)i.
t1
Def
Att

t2

t3

C

U

C

U

C

U

0
5

2
6

9
2

10
4

0
1

1
3

Table 9: example game cS,2 6= cN ,2 = cN ,1 = cS,1 . t1 certainly attacked
attacker, hence valuable defend target NE
Ud (t1 ) = 2 > 1 = Ud (t2 ) = Ud (t3 ). However, SSE two attacker resources,
valuable defender use resource prevent attack t2
second attacker resource.

Example 5 (cS,2 6= cN ,2 ; cS,2 6= cS,1 = cN ,1 ; cN ,2 6= cN ,1 = cS,1 ). Consider game
Table 10. defender 1 resource. attacker 1 resource, follows Theorem 3.10
unique defender minimax/NE/SSE strategy cS,1 = cN ,1 = (1/6, 2/3, 1/6).
attacker 2 resources, SSE, defenders primary goal prevent t1
attacked. requires putting least much defender probability t1 t3 ,
result t2 t3 attacked. Given t2 t3 attacked, placing defender probability
t3 twice valuable placing t2 (Ud (t3 ) = 7, Ud (t2 ) = 3). Hence, even
though every unit probability placed t3 , also need place unit t1 (to keep t1
attacked), still uniquely optimal defender allocate probability mass
way. So, unique defender SSE strategy (.5, 0, .5).
However, straightforward verify following NE profile attacker
2 resources: h(0, 3/4, 1/4), (1, 7/10, 3/10)i. prove unique NE. First,
show t1 defended NE. least one t2 t3 must attacked
probability least .5, hence defender would better defending target instead.
316

fiS TACKELBERG VS . NASH ECURITY G AMES

t1
Def
Att

t2

t3

C

U

C

U

C

U

11
0

12
2

0
1

3
3

0
0

7
2

Table 10: example game cS,2 6= cN ,2 ; cS,2 6= cS,1 = cN ,1 ; cN ,2 6= cN ,1 = cS,1 . one
attacker resource, t1 t3 get small probability (regardless solution
concept). two attacker resources, unique NE, turns worthwhile
defend t1 even though always attacked, Ud (t1 ) low; contrast,
unique SSE, t1 defended relatively high probability prevent attack
it.

Next, show t1 attacked probability 1 NE. t3 positive defender probability,
(because t1 defended) t1 definitely attractive attack t3 , hence
attacked probability 1. hand, defender defends t2 , t1 t3
attacked probability 1. remains effectively single-attacker-resource security game
t2 t3 clear unique equilibrium h(3/4, 1/4), (7/10, 3/10)i, thereby proving uniqueness.

5. Experimental Results
theoretical results resolve leaders dilemma many interesting important classes
security games, seen, still cases SSE strategies distinct
NE strategies defender. One case schedules satisfy SSAS property,
another attacker multiple resources. section, conduct experiments
investigate two cases, offering evidence frequency SSE strategies
differ NE strategies across randomly generated games, variety parameter settings.
methodology follows. particular game instance, first compute SSE strategy C using DOBSS mixed-integer linear program (Pita et al., 2008). use linear
feasibility program determine whether SSE strategy part NE profile
attempting find appropriate attacker response strategy.
Aq [0, 1] q Q
X
Aq = 1

(9)
(10)

qQ

Aq = 0 Ua (q, C) < E(C)
X
Aq Ud (d, q) Z,

(11)
(12)

qQ

X

Aq Ud (d, q) = Z, Cd > 0

(13)

qQ

Q set attacker pure strategies, set targets one attacker resource. probability attacker plays q denoted Aq , must
0 1 (Constraint (9)). Constraint (10) forces probabilities sum 1. Constraint (11)
317

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

prevents attacker placing positive probabilities pure strategies give attacker
utility less best response utility E(C). constraints (12) (13), Z variable
represents maximum expected utility defender get among pure strategies given
attackers strategy A, Cd denotes probability playing C. two constraints require defenders strategy C best response attackers mixed strategy. Therefore,
feasible solution linear feasibility program, taken together Stackelberg strategy
C, constitutes Nash equilibrium. Conversely, hC, Ai Nash equilibrium, must satisfy
LP constraints.
experiment, varied:
number attacker resources,
number (homogeneous) defender resources,
size schedules resources cover,
number schedules.
parameter setting, generated 1000 games 10 targets. target t,
pair defender payoffs (Udc (t), Udu (t)) pair attacker payoffs (Uau (t), Uac (t)) drawn
uniformly random set {(x, y) Z2 : x [10, 10], [10, 10], x > y}.
game experiment, schedules size, except also always
empty scheduleassigning resource empty schedule corresponds resource
used. schedules randomly chosen set subsets targets size
specified corresponding parameter.
results experiments shown Figure 2. plots show percentage games
SSE strategy NE strategy, different numbers defender attacker
resources, different schedule sizes, different numbers schedules. case
single attacker resource schedules size 1, SSAS property holds, experimental results confirm theoretical result SSE strategy always NE strategy.
increase either number attacker resources schedule size, longer
theoretical result, indeed start see cases SSE strategy NE strategy.
Let us first consider effect increasing number attacker resources. see
number games defenders SSE strategy NE strategy increases significantly
number attacker resources increases, especially goes 1 2 (note different
scales y-axes). fact, 2 3 attacker resources, phenomenon many
cases SSE strategy NE strategy consistent across wide range values
parameters.6
Now, let us consider effect increasing schedule size. increase schedule
size (with single attacker resource), SSAS property longer holds include
subschedules schedules, find games SSE strategy
NE strategybut generally cases (< 6%) this. Also, generate random
schedules, number games SSE strategy NE strategy drops zero.
particularly encouraging domains like FAMS, schedule sizes relatively small (2
6. course, increase number attacker resources keeping number targets fixed, eventually,
every defender SSE strategy NE strategy again, simply number attacker resources
equal number targets, attacker one pure strategy available.

318

fiS TACKELBERG VS . NASH ECURITY G AMES

Figure 2: number games SSE strategy NE strategy, different
parameter settings. row corresponds different number attacker resources,
column different schedule size. number defender resources
x-axis, number schedules plotted separately. parameter setting,
1000 random games 10 targets generated. SSAS property holds
games schedule size 1 (shown column 1); SSAS hold games
schedule sizes 2 3 (columns 2 3).

cases), number possible schedules large relative number targets.
effect increasing number defender resources ambiguous. multiple
attacker resources, increasing schedule size sometimes increases sometimes decreases
number games SSE strategy NE strategy.
main message take away experimental results appears case
single attacker resource, SSE strategies usually also NE strategies even SSAS
hold, appears justify practice playing SSE strategy. hand,
multiple attacker resources, generally many cases SSE strategy
NE strategy. strongly poses question done case multiple
attacker resources (in settings clear whether attacker observe defenders
mixed strategy).
319

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

6. Uncertainty Attackers Ability Observe: Model Future
Research
far, security games attacker single resource, shown
SSAS property satisfied, Stackelberg strategy necessarily Nash equilibrium strategy (Section 3.3). This, combined fact that, shown, equilibria
games satisfy interchangeability property (Section 3.2), provides strong justification playing
Stackelberg strategy SSAS property satisfied. Also, experiments (Section 5) suggest even SSAS property satisfied, Stackelberg strategy usually Nash
equilibrium strategy. However, case consider security games attacker
multiple resources.
leaves question defender play games Stackelberg strategy necessarily Nash equilibrium strategy (which case many games multiple
attacker resources, also games single attacker resource SSAS satisfied), especially clear whether attacker observe defenders mixed strategy.
difficult question cuts heart normative foundations game theory,
addressing beyond scope paper. Nevertheless, given real-world implications
line research, believe important future research tackle problem. Rather
leave question completely open-ended, section propose model
may useful starting point future research. also provide result model
least leads sensible solutions SSAS games, which, among main results
paper, provide useful sanity check adopting model future research.
model propose section, defender uncertain whether attacker
observe mixed strategy defender commits. Specifically, game played
follows. First, defender commits mixed strategy. that, probability pobs , attacker observes defenders strategy; probability 1 pobs , observe defenders
mixed strategy. Figure 3 represents model larger extensive-form game.7 game, first
Nature decides whether attacker able observe defenders choice distribution.
Then, defender chooses distribution defender resource allocations (hence, defender
continuum possible moves; particular, important emphasize committing distribution allocations randomizing pure allocation
commit to, latter case observing attacker know realized allocation).
defender observe outcome Natures movehence, would make difference
Nature moved defender, Nature move first convenient drawing
discussing game tree. Finally, attacker moves (chooses one targets attack):
left side tree, knowing distribution defender committed,
right side tree, without knowing distribution.
Given extensive-form representation situation, natural approach solve
equilibrium larger game. possible apply standard algorithms solving extensiveform games directly game, tree infinite size due defender choice
distributions; nevertheless, one straightforward way addressing discretize space
7. point, risk confusion defender mixed strategies used phrase far,
defender strategies extensive-form game. rest section, avoid confusion, usually refer
former distributions allocationsbecause, technically, distribution allocations pure strategy
extensive-form game, defender mixed strategy extensive-form game would distribution
distributions.

320

fiS TACKELBERG VS . NASH ECURITY G AMES

Nature

Defender

observed
(pobs)

observed
(1-pobs)

(infinite
number
actions)

(infinite
number
actions)

Attacker

attacker moves knowledge
defender's distribution

attacker moves without knowledge
defender's distribution

Figure 3: Extensive form larger game defender uncertain attackers
ability observe.

distributions. important question, course, whether right thing play
equilibrium game. state simple propositions serve sanity checks
model. First, show pobs = 1, obtain Stackelberg model.
Proposition 6.1. pobs = 1, subgame-perfect equilibrium extensive-form game
corresponds SSE underlying security game.
Proof. guaranteed end left-hand side tree, attacker observes
distribution defender committed; subgame-perfect equilibrium, must
best-respond distribution. defender, turn, must choose distribution optimally
respect this. Hence, result corresponds SSE.
Next, show pobs = 0, obtain standard simultaneous-move model.
Proposition 6.2. pobs = 0, Nash equilibrium extensive-form game corresponds
Nash equilibrium underlying security game.
Proof. guaranteed end right-hand side tree, attacker observes
nothing distribution defender committed. Nash equilibrium
extensive-form game, defenders strategy leads probability distribution allocations.
attackers information set right-hand side tree, attacker place positive
probability actions best responses distribution allocations. Conversely,
defender put positive probability allocations best responses attackers
distribution actions. Hence, result Nash equilibrium underlying security game.

intermediate values pobs , sufficiently general settings, equilibrium extensiveform game may correspond neither SSE NE basic security game. However,
would hope security games Stackelberg strategy also Nash equilibrium
strategysuch SSAS security games discussed earlier paperthis strategy also corresponds equilibrium extensive-form game. next proposition shows indeed
case.
321

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

Proposition 6.3. underlying security game, Stackelberg strategy defender
also defenders strategy Nash equilibrium, strategy also defenders strategy subgame-perfect equilibrium extensive-form game.8
Proof. Suppose distribution allocations Stackelberg strategy
Nash equilibrium strategy underlying security game. Let best response
attacker plays corresponding SSE, let distribution attacker actions
hd , Nash equilibrium security game.
show construct subgame-perfect equilibrium extensive-form game. Let
defender commit distribution information set. attackers strategy
extensive form defined follows. left-hand side tree, attacker observes
defender committed , responds ; attacker observes defender
committed distribution allocations, responds best response
distribution. information set right-hand side tree, attacker plays .
straightforward check attacker best-responding defenders strategy every
one information sets. remains show defender best-responding
attackers strategy extensive-form game. defender commits distribution d0 ,
cannot help left side tree relative , Stackelberg strategy;
also cannot help right side tree, best response . follows
defender best-responding, hence identified subgame-perfect equilibrium
game.
proposition immediately applied SSAS games:
Corollary 6.4. security games satisfy SSAS property (and single attacker resource), Stackelberg strategy underlying security game, also defenders
strategy subgame-perfect equilibrium extensive-form game.
Proof. follows immediately Proposition 6.3 Corollary 3.9.
course, Proposition 6.3 also applies games SSAS hold Stackelberg
strategy still Nash equilibrium strategywhich case many games
experiments Section 5. general, course, SSAS property hold, Stackelberg
strategy may Nash equilibrium strategy underlying security game; so, defenders
strategies equilibria extensive-form game may correspond neither Stackelberg Nash
strategies underlying security game. case, method used
solve extensive-form game directlyfor example, discretizing space distributions
attacker applying standard algorithm solving equilibrium resulting
game. latter method scale well, leave design better algorithms
future research.

7. Additional Related Work
first sections paper, discussed recent uses game theory security domains,
formal model security games, model differs existing classes games
8. also hold stronger solution concepts subgame-perfect equilibrium.

322

fiS TACKELBERG VS . NASH ECURITY G AMES

strategically zero-sum unilaterally competitive games. discuss additional related work
section.
significant interest understanding interaction observability commitment general Stackelberg games. Bagwells early work (1995) questions value commitment
pure strategies given noisy observations followers, ensuing on-going debate illustrated leader retains advantage case commitment mixed strategies (van Damme
& Hurkens, 1997; Huck & Muller, 2000). Guth, Kirchsteiger, Ritzberger (1998) extend
observations n-player games. Maggi (1998) shows games private information,
leader advantage appears even pure strategies. also work value commitment leader observations costly (Morgan & Vardy, 2007).
Several examples applications Stackelberg games model terrorist attacks electric
power grids, subways, airports, critical infrastructure described Brown et al.
(2005) Sandler Arce M. (2003). Drake (1998) Pluchinsky (2005) studied different
aspects terrorist planning operations target selection. studies indicate terrorist
attacks planned certain level sophistication. addition, terrorist manual shows
significant amount information used plan attacks collected public sources (U.S.
Department Justice, 2001). Zhuang Bier (2010) studied reasons secrecy deception
defenders side. broader interest Stackelberg games indicated applications
areas, network routing scheduling (Korilis, Lazar, & Orda, 1997; Roughgarden, 2004).
contrast existing research, work focuses real-world security games, illustrating subset, equivalence, interchangeability, uniqueness properties non-existent
general Stackelberg games studied previously. course, results general nature date back
beginning game theory: von Neumanns minimax theorem (1928) implies two-player
zero-sum games, equilibria interchangeable optimal SSE strategy also minimax /
NE strategy. However, discussed earlier, security games studied generally
zero-sum games, captured general classes games strategically
zero-sum (Moulin & Vial, 1978) unilaterally competitive (Kats & Thisse, 1992) games.
Tennenholtz (2002) studies safety-level strategies. two players, safety-level (or maximin)
strategy player 1 mixed strategy maximizes expected utility player 1,
assumption player 2 acts minimize player 1s expected utility (rather maximize
utility). Tennenholtz shows conditions, utility guaranteed safety-level
strategy equal close utility obtained player 1 Nash equilibrium. may sound
reminiscent result Nash strategies coincide minimax strategies, fact results
quite different: particular, non-zero-sum games, maximin minimax strategies
identical. following example gives simple game result holds, safety-level
strategy result utility close equilibrium solution.
Example 6. Consider game shown Table 11. player 1 resource. game,
safety-level (maximin) strategy defender place resource target 2, thereby
guaranteeing utility least 2. However, attacker dominant strategy
attack target 1 (so defender actually plays safety-level strategy, expect utility
1). hand, minimax/Stackelberg/Nash solution, defend target 1
receive utility 0.
Kalai (2004) studies idea number players game grows, equilibria
become robust certain changes extensive form, players move
323

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

t1
Def
Att

t2

C

U

C

U

0
2

1
3

2
0

3
1

Table 11: example game defenders utility playing competitive safety
strategy close defenders Nash/Stackelberg equilibrium utility.

ones, learn others actions. high level reminiscent
results, sense also show class security games, particular choice
two structures game (one player committing mixed strategy first, players moving
time) affect defender play (though attackers strategy
affected). However, seem significant technical similarityour result relies
structure class security games number players becoming large
(after all, consider games two players).
Pita, Jain, Ordonez, Tambe et al. (2009) provide experimental results observability Stackelberg games: test variety defender strategies human players (attackers) choose
optimal attack provided limited observations defender strategies. Results
show superiority defenders strategy computed assuming human anchoring bias attributing probability distribution defenders actions. research complements
paper, provides new mathematical foundations. Testing insights research
experimental paradigm Pita, Jain, Ordonez, Tambe et al. (2009) expert players,
interesting topic future research.

8. Summary
paper focused general class defender-attacker Stackelberg games directly
inspired real-world security applications. paper confronts fundamental questions
defender compute mixed strategy. context, paper provides four key contributions. First, exploiting structure security games, paper shows Nash equilibria security games interchangeable, thus alleviating defenders equilibrium selection
problem simultaneous-move games. Second, resolving defenders dilemma, shows
SSAS restriction security games, Stackelberg strategy also Nash equilibrium
strategy; furthermore, strategy unique class security games ARMOR
key exemplar. Third, faced follower attack multiple targets, many
properties longer hold, providing key direction future research. Fourth, experimental
results emphasize positive properties security games fit SSAS property. practical
terms, contributions imply defenders applications ARMOR (Pita et al., 2008)
IRIS (Tsai et al., 2009) simply commit SSE strategies, thus helping resolve major
dilemma real-world security applications.
324

fiS TACKELBERG VS . NASH ECURITY G AMES

Acknowledgments
Dmytro Korzhyk Zhengyu Yin first authors paper. earlier conference version
paper published AAMAS-2010 (Yin, Korzhyk, Kiekintveld, Conitzer, & Tambe,
2010). major additions full version include (i) set new experiments analysis
results; (ii) new model addressing uncertainty attackers ability observe;
(iii) thorough treatment multiple attacker resources case; (iv) additional discussion
related research.
research supported United States Department Homeland Security
National Center Risk Economic Analysis Terrorism Events (CREATE) award
number 2010-ST-061-RE0001. Korzhyk Conitzer supported NSF IIS-0812113
CAREER-0953756, ARO 56698-CI, Alfred P. Sloan Research Fellowship. However,
opinions, findings, conclusions recommendations document authors
necessarily reflect views funding agencies. thank Ronald Parr many detailed comments discussions. also thank anonymous reviewers valuable suggestions.

References
Bagwell, K. (1995). Commitment observability games. Games Economic Behavior, 8,
271280.
Basar, T., & Olsder, G. J. (1995). Dynamic Noncooperative Game Theory (2nd edition). Academic
Press, San Diego, CA.
Basilico, N., Gatti, N., & Amigoni, F. (2009). Leader-follower strategies robotic patrolling
environments arbitrary topologies. Proceedings Eighth International Joint
Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 5764, Budapest,
Hungary.
Bier, V. M. (2007). Choosing protect. Risk Analysis, 27(3), 607620.
Brown, G., Carlyle, W. M., Salmeron, J., & Wood, K. (2005). Analyzing vulnerability critical
infrastructure attack planning defenses. INFORMS Tutorials Operations Research: Emerging Theory, Methods, Applications, pp. 102123. Institute Operations
Research Management Science, Hanover, MD.
Conitzer, V., & Sandholm, T. (2006). Computing optimal strategy commit to. Proceedings
ACM Conference Electronic Commerce (EC), pp. 8290, Ann Arbor, MI, USA.
Drake, C. J. M. (1998). Terrorists Target Selection. St. Martins Press, Inc.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Guth, W., Kirchsteiger, G., & Ritzberger, K. (1998). Imperfectly observable commitments nplayer games. Games Economic Behavior, 23(1), 5474.
Harsanyi, J. (19671968). Game incomplete information played Bayesian players. Management Science, 14, 159182; 320334; 486502.
Huck, S., & Muller, W. (2000). Perfect versus imperfect observabilityan experimental test
Bagwells result. Games Economic Behavior, 31(2), 174190.
325

fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE

Jain, M., Tsai, J., Pita, J., Kiekintveld, C., Rathi, S., Ordonez, F., & Tambe, M. (2010). Software
assistants randomized patrol planning LAX airport police Federal Air
Marshals Service. Interfaces, 40(4), 267290.
Kalai, E. (2004). Large robust games. Econometrica, 72(6), 16311665.
Kats, A., & Thisse, J. (1992). Unilaterally competitive games. International Journal Game
Theory, 21(3), 29199.
Keeney, R. (2007). Modeling values anti-terrorism analysis. Risk Analysis, 27, 585596.
Kiekintveld, C., Jain, M., Tsai, J., Pita, J., Ordonez, F., & Tambe, M. (2009). Computing optimal
randomized resource allocations massive security games. Proceedings Eighth
International Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS),
pp. 689696, Budapest, Hungary.
Kiekintveld, C., Marecki, J., & Tambe, M. (2011). Approximation methods infinite Bayesian
Stackelberg games: Modeling distributional uncertainty. Proceedings International
Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 10051012.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1997). Achieving network optima using Stackelberg routing
strategies. IEEE/ACM Transactions Networking, 5(1), 161173.
Korzhyk, D., Conitzer, V., & Parr, R. (2010). Complexity computing optimal Stackelberg strategies security resource allocation games. Proceedings National Conference
Artificial Intelligence (AAAI), pp. 805810, Atlanta, GA, USA.
Leitmann, G. (1978). generalized Stackelberg strategies. Optimization Theory Applications,
26(4), 637643.
Letchford, J., Conitzer, V., & Munagala, K. (2009). Learning approximating optimal strategy
commit to. Proceedings Second Symposium Algorithmic Game Theory (SAGT09), pp. 250262, Paphos, Cyprus.
Maggi, G. (1998). value commitment imperfect observability private information.
RAND Journal Economics, 30(4), 555574.
Morgan, J., & Vardy, F. (2007). value commitment contests tournaments observation costly. Games Economic Behavior, 60(2), 326338.
Moulin, H., & Vial, J.-P. (1978). Strategically zero-sum games: class games whose completely mixed equilibria cannot improved upon. International Journal Game Theory,
7(3-4), 201221.
Paruchuri, P., Pearce, J. P., Marecki, J., Tambe, M., Ordonez, F., & Kraus, S. (2008). Playing
games security: efficient exact algorithm solving Bayesian Stackelberg games.
Proceedings Seventh International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS), pp. 895902, Estoril, Portugal.
Pita, J., Bellamane, H., Jain, M., Kiekintveld, C., Tsai, J., Ordonez, F., & Tambe, M. (2009). Security
applications: Lessons real-world deployment. SIGECOM Issue 8.2.
Pita, J., Jain, M., Ordonez, F., Portway, C., Tambe, M., Western, C., Paruchuri, P., & Kraus, S.
(2009). Using game theory Los Angeles airport security. AI Magazine, 30(1), 4357.
326

fiS TACKELBERG VS . NASH ECURITY G AMES

Pita, J., Jain, M., Ordonez, F., Tambe, M., Kraus, S., & Magori-Cohen, R. (2009). Effective solutions real-world Stackelberg games: agents must deal human uncertainties.
Proceedings Eighth International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS), pp. 369376, Budapest, Hungary.
Pita, J., Jain, M., Western, C., Portway, C., Tambe, M., Ordonez, F., Kraus, S., & Parachuri, P.
(2008). Deployed ARMOR protection: application game-theoretic model security
Los Angeles International Airport. Proceedings 7th International Conference
Autonomous Agents Multiagent Systems (AAMAS 2008) Industry Applications
Track, pp. 125132, Estoril, Portugal.
Pluchinsky, D. A. (2005). Typology Anatomy Terrorist Operations, chap. 25. McGrawHill Homeland Security Book. McGraw-Hill.
Rosoff, H., & John, R. (2009). Decision analysis proxy rational terrorist. Quantitative risk analysis security applications workshop (QRASA) held conjunction
International Joint Conference AI, pp. 2532, Pasadena, CA, USA.
Roughgarden, T. (2004). Stackelberg scheduling strategies. SIAM Journal Computing, 33(2),
332350.
Sandler, T., & Arce M., D. G. (2003). Terrorism game theory. Simulation Gaming, 34(3),
319337.
Tennenholtz, M. (2002). Competitive safety analysis: Robust decision-making multi-agent systems. Journal Artificial Intelligence Research, 17, 363378.
Tsai, J., Rathi, S., Kiekintveld, C., Ordonez, F., & Tambe, M. (2009). IRIS - tool strategic
security allocation transportation networks. Eighth International Conference
Autonomous Agents Multiagent Systems - Industry Track, pp. 3744.
U.S. Department Justice (2001). Al Qaeda training manual. http://www.au.af.mil/au/
awc/awcgate/terrorism/alqaida_manual. Online release 7 December 2001.
van Damme, E., & Hurkens, S. (1997). Games imperfectly observable commitment. Games
Economic Behavior, 21(1-2), 282308.
von Neumann, J. (1928). Zur Theorie der Gesellschaftsspiele. Mathematische Annalen, 100, 295
320.
von Stengel, B., & Zamir, S. (2010). Leadership games convex strategy sets. Games
Economic Behavior, 69, 446457.
Yin, Z., Korzhyk, D., Kiekintveld, C., Conitzer, V., & Tambe, M. (2010). Stackelberg vs. Nash
security games: Interchangeability, equivalence, uniqueness. Proceedings Ninth
International Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS),
pp. 11391146, Toronto, Canada.
Zhuang, J., & Bier, V. M. (2010). Reasons secrecy deception homeland-security resource
allocation. Risk Analysis, 30(12), 17371743.

327

fiJournal Artificial Intelligence Research 41 (2011) 69-95

Submitted 10/10; published 05/11

Value Information Lattice: Exploiting Probabilistic
Independence Effective Feature Subset Acquisition
Mustafa Bilgic

mbilgic@iit.edu

Illinois Institute Technology
Chicago, IL 60616 USA

Lise Getoor

getoor@cs.umd.edu

University Maryland
College Park, MD 20742 USA

Abstract
address cost-sensitive feature acquisition problem, misclassifying instance costly expected misclassification cost reduced acquiring
values missing features. acquiring features costly well, objective acquire right set features sum feature acquisition
cost misclassification cost minimized. describe Value Information Lattice
(VOILA), optimal efficient feature subset acquisition framework. Unlike common
practice, acquire features greedily, VOILA reason subsets features.
VOILA efficiently searches space possible feature subsets discovering exploiting
conditional independence properties features reuses probabilistic inference computations speed process. empirical evaluation five
medical datasets, show greedy strategy often reluctant acquire features,
cannot forecast benefit acquiring multiple features combination.

1. Introduction
often need make decisions take appropriate actions complex uncertain
world. important subset decisions formulated classification problem,
instance described set features one finite categorical options
chosen based features. Examples include medical diagnosis patients
described lab tests diagnosis made disease state patient,
spam detection email described content email client needs
decide whether email spam.
Much research done learn effective efficient classifiers assuming
features describing entities fully given. Even though complete data
assumption might hold domains, practice features describe entities
often missing values. certain domains medical diagnosis decision
made based number features include laboratory test results, missing feature
values acquired cost performing related tests. cases, need
decide tests perform order. answer question, course,
depends important get correct classification decision. Put alternatively,
cost incorrect classification (e.g., misdiagnosis) determines much
willing spend expensive tests. Thus, need devise feature acquisition policy
determine tests perform order stop make
c
2011
AI Access Foundation. rights reserved.

fiBilgic & Getoor

final classification decision total incurred cost, feature acquisition cost
expected misclassification cost, minimized.
Devising optimal policy general requires considering possible permutations
features expected values. provide intuition, features might
useful acquired together, cost benefit acquiring features
depend features acquired values turned
be. devising optimal policy intractable general, previous work
greedy (Gaag & Wessels, 1993; Yang, Ling, Chai, & Pan, 2006), approximated value
information calculations (Heckerman, Horvitz, & Middleton, 1993), developed
heuristic feature scoring techniques (Nunez, 1991; Turney, 1995).
greedy approach, however, least two major limitations. First,
considers feature isolation, cannot accurately forecast value acquiring
multiple features together, causing produce sub-optimal policies. Second, greedy
strategy assumes features acquired sequentially value feature
observed acquiring next one. assumption, however, often
practical. example, doctors typically order batches measurements simultaneously
blood count, cholesterol level, etc., possibly order another batch
results arrive. two limitations greedy approach make necessary reason
sets features.
Reasoning sets features, hand, poses serious tractability challenges.
First all, number subsets exponential size feature set. Second,
judging value acquiring set features requires taking expectation
possible values features set, also exponential number
features. good news, however, need consider possible subsets
features practice; certain features render features useless, features
useful acquired together. example, X-Ray might render skin test
useless diagnosing tuberculosis. Similarly, chest pain alone might useful
differentiating cold heart disease; becomes useful combined
features, blood test.
article, describe data structure discovers exploits types
constraints (features render features useless features useful
acquired together) underlying probability distribution. propose Value
Information Lattice (VOILA) reduces space possible subsets exploiting
constraints features. Additionally, VOILA makes possible share value
information calculations different feature sets reduce computation time.
article builds upon earlier work (Bilgic & Getoor, 2007). contributions
article include:
introduce two additional techniques sharing computations different
subsets features. new techniques based information caching
utilizing paths underlying Bayesian network.
experiment asymmetric misclassification costs addition symmetric
costs. asymmetric setup reflects realistic case provides new insights.
addition feature acquisition costs defined Turney (1995), generate
experiment synthetic feature costs. synthetic feature costs capture
70

fiValue Information Lattice

complex feature acquisition costs allows leeway various acquisition
strategies differ.
remainder article organized follows. describe notation
problem formulation Section 2. describe reduce search space
share computations using VOILA Section 3. show experimental results Section 4,
discuss related work Section 5, discuss future work Section 6. conclude
Section 7.

2. Notation Problem Formulation
main task classify given instance missing feature values incur
minimum acquisition misclassification cost. Let instance described set
features X = {X1 , X2 , . . . , Xn } let random variable representing class.
assume joint probability distribution P (Y, X) given concern
feature acquisition inference (note conditional distribution P (Y |X)
appropriate, features assumed unobserved initially). purpose
article, assume given Bayesian network, joint probabilistic
model allows us efficiently answer conditional independence queries used.
notation, bold face letter represents set random variables non-bold face
letter represents single random variable. example X represents set features,
whereas Xi X represents feature X represents class variable. Additionally,
capital letter represents random variable, lowercase letter represents particular
value variable; applies individual variables sets variables.
example, represents variable, represents particular value take.
addition probabilistic model, also given cost models specify
feature acquisition costs misclassification costs. Formally, assume
feature acquisition cost function given subset features, S, set features
whose values known (evidence) E, returns non-negative real number C(S | e).
also assume misclassification cost model returns misclassification
cost cij incurred assigned yi correct assignment yj . cost
functions, model non-static feature acquisition costs; is, cost acquiring
feature Xi depend acquired far values
(e) well acquired conjunction feature (S \ {Xi }). Moreover,
misclassification cost model assume symmetric costs; different kids errors (false
positives negatives) different costs.
Figure 1 shows simple example configuration two features, X1 X2 ,
class variable . simple example, joint distribution P (X, ) represented
table, feature costs simple independent costs X1 X2 , misclassification cost symmetric types misclassifications cost correct
classification cost anything.
diagnostic policy decision tree node represents feature
branches nodes represent possible values features. path
policy, ps , represents ordered sequence feature values s. often use ps
represent ordered version s. Typically, order features set
important computing feature costs, cost feature depend values
71

fiBilgic & Getoor

Figure 1: Example configuration two features X1 X2 class variable .
table left right represent: joint probability distribution P (X1 , X2 , ),
feature costs, misclassification costs.

previously acquired features. order features irrelevant computing
probability P (s). example conditional policy using example configuration
Figure 1 given Figure 2.
policy two types costs: feature acquisition cost misclassification
cost. costs defined terms costs associated following paths
policy. first describe compute feature acquisition cost path
describe compute associated expected misclassification cost. Finally, show
compute expected total cost policy using total costs associated
path.
naive version, feature cost path ps sum costs
features appear path. However, practice, cost feature depend
features acquired far observed values acquired features.
example, performing treadmill test (asking patient run treadmill
measure heart beat, etc.) riskier ordered cholesterol test
result turned high, putting patient high risk heart disease. account
types costs, order features ps matters, total feature cost
path summation individual feature costs conditioned values
features precede features consideration:
F C(ps ) =

n
X

C(ps [j] | ps [1 : j])

j=1

ps [j] represents j th feature ps ps [1 : j] represents feature values 1
j ps .
reach end path, need make classification decision.
case, simply utilize Bayesian decision theory choose decision minimum
risk (i.e., misclassification cost). find decision using probabilistic model
72

fiValue Information Lattice

Figure 2: example conditional policy features X1 , X2 class variable .
non-leaf node represents feature acquisition, probability distribution
possible values, cost feature. path (e.g., X1 = T, X2 = )
acquisition cost expected misclassification cost. policy overall
expected total cost ETC, sum total costs path, weighted
probability following path.

compute probability distribution P (Y | ps ) choose value leads
minimum expected cost. Note order features values matter
case; P (Y | ps ) = P (Y | s). expected misclassification path, EM C(ps ),
73

fiBilgic & Getoor

computed follows:
EM C(ps ) = EM C(s) = min
yi

X

P (Y = yj | s) cij

(1)

yj

total cost incur following path policy simply sum feature
expected misclassification costs path:
C(ps ) = F C(ps ) + EM C(ps )
Finally, compute expected total cost policy using total costs
individual paths ps . path ps probability occurrence real world.
probability easily computed generative probability model assumed. simply P (s). expected total cost policy sum total
cost path, C(ps ), weighted probability following path, P (s):
ET C() =

X

P (s)T C(ps )

(2)

ps

objective feature acquisition inference is, given joint probabilistic
model cost models acquisition misclassification, find policy
minimum expected total cost. However, building optimal decision tree known
NP-complete (Hyafil & Rivest, 1976). Thus, research greedy choosing
best feature reduces misclassification costs lowest cost (e.g.,
Gaag & Wessels, 1993; Dittmer & Jensen, 1997) developed heuristic feature scoring
techniques (e.g., Nunez, 1991; Tan, 1990).
greedy strategy, path policy extended feature reduces
misclassification cost lowest cost. specifically, path
ps replaced new paths psx1 , psx2 , . . . , psxni x1i , x2i , . . . , xni values


Xi take Xi feature highest benefit. define benefit
feature Xi given path ps reduction total cost path path
expanded possible values Xi . formally,
Benef it(Xi | ps ) , C(ps )

n
X

P (xji | s)T C(psxj )


j=1

= F C(ps ) + EM C(s)

n
X



P (xji | s) F C(psxj ) + EM C(s xji )


j=1


= F C(ps )

n
X


P (xji | s)F C(psxj ) + EM C(s)


j=1

n
X

P (xji | s)EM C(s xji )

j=1

= C(Xi | s) + EM C(s)

P (xji | s)EM C(s xji )

j=1

= F C(ps ) (F C(ps ) + C(Xi | s)) + EM C(s)
n
X

n
X

P (xji | s)EM C(s xji )

j=1

74

fiValue Information Lattice

Note that, last two terms equivalent definition expected value information, EVI, (Howard, 1966):
EV I(Xi | s) = EM C(s)

n
X

P (xji | s)EM C(s xji )

(3)

j=1

Substituting EVI, definition benefit becomes intuitive:
Benef it(Xi | ps ) = Benef it(Xi | s) = EV I(Xi | s) C(Xi | s)

(4)

definition, greedy strategy iteratively finds feature highest
positive benefit (value cost difference), acquires it, stops acquisition
features positive benefit value.
also note straightforward define EVI Benefit set S0 features
like single feature. difference expectation needs
taken joint assignments, s0 , features set S0 .
EV I(S0 | s) = EM C(s)

X

P (s0 | s)EM C(s s0 )

(5)

s0

and,
Benef it(S0 | s) = EV I(S0 | s) C(S0 | s)

(6)

problems greedy strategy mentioned
P earlier. First,
short-sighted. exist sets X Benef it(S) >
Benef it(Xi ).
Xi

easier see, example, XOR function, = X1 XOR X2 , X1 X2
alone useful determinative together. Due relationship, greedy
policy guaranteed optimal. Moreover, greedy policy prematurely stop
acquisition single feature seems provide positive benefit.
second problem greedy strategy often need acquire set
features simultaneously. example, doctor orders set lab tests s/he sends
patient lab, blood count, cholesterol level, etc. rather ordering single test,
waiting result ordering next one. However, traditional greedy strategy
cannot handle reasoning sets features naturally.
would like able reason sets features two reasons.
objective article is, given existing potentially empty set already observed
features E observed values e, find set highest benefit:
L(X | e) , argmax Benef it(S | e)

(7)

SX\E

two problems formulation: first, number subsets X \ E
exponential size X \ E, second, set S, need take expectation
joint assignments features set. address two problems using
data structure describe next.
75

fiBilgic & Getoor

3. Value Information Lattice (VOILA)
VOILA makes reasoning sets features tractable reducing space possible
sets allowing sharing EVI computations different sets. section,
first explain reduce space explain techniques computation
sharing.
3.1 Reducing Space Possible Sets
domains, often complex interactions features
class label. Contrary Naive Bayes assumption, features often conditionally
independent given class label. features useless features
already acquired. example chest X-Ray typically determinative skin
test tuberculosis. Similarly, features useless alone unless accompanied
features. example, chest pain alone might due variety sicknesses;
accompanied high cholesterol, could indicate heart disease, whereas
combined fever, cold might probable. types interactions
features allow us reduce space candidate feature sets.
mentioned problem formulation, assumed already
joint probabilistic model features class variable, P (Y, X). find
two types feature interactions asking probabilistic independence queries using
P (Y, X). Specifically, assume given Bayesian network represents
P (Y, X). Bayesian network allow us find types interactions
standard d-separation algorithms.
Definition 1 set X \ E irreducible respect evidence e Xi S, Xi
conditionally independent given e \ {Xi }.
Given Bayesian network X , straightforward check irreducibility
d-separation (Pearl, 1988).
Proposition 1 Let S0 maximal irreducible subset respect e. Then, EV I(S |
e) = EV I(S0 | e).
Proof: Let S00 = \ S0 . S0 maximal irreducible set, S0 E d-separates S00 .
Otherwise, could make S0 larger including non-d-separated element(s) S00
S0 . Thus, P (Y | e, s) = P (Y | e, S0 , S00 ) = P (Y | e, S0 ). Substitution Equations
1 5 yields desired property.
Note assumption C(S0 | e) C(S | e) S0 S, suffices
consider irreducible sets find optimal solution objective function
Equation (7). VOILA data structure contains irreducible feature subsets
X, respect particular set evidence e. next define VOILA formally.
Definition 2 VOILA V directed acyclic graph node corresponding
possible irreducible set features, directed edge feature set
node corresponds direct (maximal) subset S. subset relationships
lattice defined directed paths V.
76

fiValue Information Lattice

(a)

(b)

Figure 3: (a) simple Bayesian network illustrating dependencies attributes
class variable. (b) VOILA corresponding network.

Figure 3(a) shows simple Bayesian network corresponding VOILA, respect
empty evidence set, shown Figure 3(b). Notice VOILA contains
irreducible subsets given Bayesian network; instance, VOILA contain
sets include X1 X2 X1 d-separates X2 . also observe
number irreducible subsets 9 contrast 24 = 16 possible subsets. Moreover,
note largest subset size 3 contrast 4. smaller feature sets sizes
dramatic effect value information calculations. fact, savings
make solving objective function optimally (Equation (7)) feasible practice.
3.2 Sharing EVI Calculations
Finding set highest Benefit (Equation 6) requires computing EV I(S)
(Equation 5). However, computing EV I(S) requires taking expectation possible
values features S. Moreover, searching best set among irreducible sets
requires us compute EVI irreducible sets. make computations tractable
practice, VOILA allows computation sharing nodes. article, describe
three possible ways sharing computations nodes VOILA.
77

fiBilgic & Getoor

3.2.1 Subset Relationships
VOILA exploits subset relationships different feature sets order avoid
computing EVI nodes. First all, directed path node S1 S2
VOILA, S1 S2 thus EV I(S1 | e) EV I(S2 | e)1 . assume
directed path Si Sj EV I(Si | e) = EV I(Sj | e). Then, nodes
path also EVI, thus need computation
subsets. algorithm makes use observation given Algorithm 1.
Algorithm 1: Efficient EVI computation using VOILA.
Input: VOILA V current evidence E
Output: VOILA updated correct EVI values
1 root node(s)
2
value EV I(S | e); ub(S) value; lb(S) value
3
ub(descendants(S)) value
4
5
6
7
8
9
10

leaf node(s)
value EV I(S | e); ub(S) value; lb(S) value
lb(ancestors(S)) value
node lb(S) 6= ub(S)
value EV I(S | e); ub(S) value; lb(S) value
lb(ancestors(S)) value
ub(descendants(S)) value

important point nodes VOILA irreducible sets. Unless
totally useless features change P (Y ) observed,
two distinct nodes EVI values exactly equal. However, statement
true context-specific independencies (independencies hold
certain assignments variables) underlying Bayesian network.
description implementation, used standard d-separation variable level; one
imagine going one step define irreducible sets variable
level d-separation context specific independencies.
order share computations different nodes lattice, keep lower
upper bounds EVI node. lower bound determined values
descendants node whereas upper bound determined values
ancestors. First, initialize bounds computing value information
boundary lattice, i.e., root node(s) leaf node(s) (lines 16) 2 . Then,
loop nodes whose upper bounds lower bounds equal (line 710),
computing values updating bounds ancestors descendants.
algorithm terminates upper bounds lower bounds nodes become
tight. order choose nodes line 7 number sets
value calculated minimum still open question. possible heuristic perform
1. superset always higher equivalent EVI (Equation (5)) subset.
2. need compute EVI root nodes; suffices compute node corresponds
Markov blanket . explained detail next section.

78

fiValue Information Lattice

binary search choose middle node path two nodes values
already calculated.
3.2.2 Information Pathways Underlying Bayesian Network
second mechanism VOILA uses share EVI computations edges
underlying Bayesian network. specifically make use following fact:
Proposition 2 S1 S2 , S1 d-separates S2 respect e,
EV I(S1 | e) EV I(S2 | e).
Proof: Consider S12 = S1 S2 . subset relationship, know EV I(S12 |
e) EV I(S1 | e) EV I(S12 | e) EV I(S2 | e).
EV I(S12 | e) = EM C(Y | e)

X

P (s12 | e)EM C(Y | e, s12 )

s12

= EM C(Y | e)

XX
s1

= EM C(Y | e)

XX
s1

= EM C(Y | e)

X

P (s1 , s2 | e)EM C(Y | e, s1 , s2 )

s2

P (s1 , s2 | e)EM C(Y | e, s1 )

s2

P (s1 | e)EM C(Y | e, s1 )

s1

= EV I(S1 | e)
EV I(S2 | e)
third line follows second fact S1 d-separates S2 thus
P (Y | s1 , s2 ) = P (Y | s1 ).
Corollary: Markov blanket , (i.e., parents, children, childrens
parents), set highest EVI search space, d-separates
remaining variables . Using corollary, need compute EVI
root nodes Algorithm 1; compute EVI root node corresponds
Markov blanket serves upper bound EVI remaining
root nodes.
relationships well exploited like exploited subset relationships
above. Instead using subset relationships, use subset independence relationships. One simple way make use Algorithm 1 without modification
add edges S1 S2 independence property holds. example S1 S2 according toy network Figure 3(a) would S1 = {X1 }
S2 = {X2 }. Thus, add directed edge X1 X2 VOILA Figure 3(b)
Algorithm 1 work fine.
3.2.3 Incremental Inference
third last mechanism VOILA uses computation sharing
caching probabilities nodes. candidate set V, need compute
EV I(S | e) requires computing P (S | e) EM C(Y | S, e). cache
79

fiBilgic & Getoor

conditional probabilities node V, compute
P (S | e), find one
P
supersets Si = {Xi } compute P (S | e) = xi P (S, Xi = xi | e).
Computing EM C(Y | S, e) requires computing P (Y | S, e). perform computation efficiently, cache state junction tree node VOILA. Then,
find subset, Sj , = Sj {Xj }. compute P (Y | S, e) integrating
extra evidence junction tree node Sj used compute P (Y | Sj , e).
3.3 Constructing VOILA
Efficient construction VOILA straightforward task. brute force approach
would enumerate possible subsets X \ E subset check whether
irreducible. However, brute force approach clearly impractical. number
nodes VOILA expected much fewer number possible subsets X\E,
smart sets consider inclusion V, construct
efficiently. is, instead generating possible candidates checking whether
irreducible not, try generate irreducible sets. first introduce
notion dependency constraint explain use dependency constraints
efficiently construct VOILA.
Definition 3 dependency constraint feature Xi respect E
constraint E ensures dependency Xi exists.
instance, running example, dependency constraint X2 X1 ;
words, order X2 relevant, X1 included E. Similarly,
dependency constraint X4 X3 , meaning X3 must included SE. Specifically,
dependency constraint feature Xi requires Xj path Xi
included E Xj part v-structure; Xj part v-structure,
either Xj one descendants must included E (we refer latter
constraints positivity constraints). algorithm uses ideas compute
dependency constraints feature given Algorithm 2.
Algorithm 2: Dependency constraint computation Xi .
Input: Xi ,
Output: Dependency constraint Xi , denoted DC(Xi )
1 DC(Xi ) false
2 undirected path pj Xi
3
DCj (Xi ) true
4
Xk path pj
5
Xk cause v-structure
6
DCj (Xi ) DCj (Xi ) Xk
7
else
8
DCj (Xi ) DCj (Xi ) (Xk Descendants(Xk ))
9

DC(Xi ) DC(Xi ) DCj (Xi )

80

fiValue Information Lattice

dependency constraints used check whether set irreducible
potentially irreducible. Intuitively, set potentially irreducible irreducible
possible make set irreducible adding features it. formally,
Definition 4 set X \ E potentially irreducible respect evidence e if,
irreducible exists non-empty set features S0 X \ {E S}
S0 irreducible.
Potential irreducibility possible due non-monotonic nature d-separation. is,
feature d-separated become dependent consider combination
features. example, running example, {X4 } irreducible, X4
d-separated , whereas {X3 , X4 } irreducible.
use dependency constraints check whether set irreducible potentially
irreducible. set irreducible dependency elements
exists, dependency constraint set conjunction dependency
constraints members. irreducibility checked setting elements
E true setting remaining elements X false evaluating
sets dependency constraint. running example, dependency constraint set
{X2 , X4 } X1 X3 . Assuming E = , set members {X2 , X4 } true,
set remaining features, X1 X3 , false, X1 X3 evaluates false thus
set irreducible. makes sense given evidence, X4 independent
, {X2 } useful feature set consider acquisition, {X2 , X4 } not.
Checking potential irreducibility similar. Set elements E true
like above. Then, set positivity constraints members true. Finally,
set everything else false. Using example above, check whether {X2 , X4 }
potentially irreducible, set X2 = true, X4 = true. Also set X3 = true
positivity constraint X4 . Set remaining features, X1 , false. Evaluating
constraint X1 X3 yields true, showing {X2 , X4 } potentially irreducible (while
irreducible).
Given definitions irreducibility potential irreducibility mechanisms
check properties notion dependency constraints, next describe
algorithm construct VOILA.
VOILA construction proceeds bottom fashion, beginning lowest level,
initially contains empty set constructs new irreducible feature sets
adding one feature time VOILA structure. Algorithm 3 gives details
algorithm. algorithm keeps track irreducible feature sets IS, set
potentially irreducible feature sets PS. done processing feature Xij ,
remove PS potentially irreducible set cannot become irreducible Xij
re-considered (line 11).
3.3.1 Analysis VOILA Construction Algorithm
construction algorithm inserts node VOILA corresponding set
irreducible (lines 6 7). Moreover, keeping track potentially irreducible sets
(lines 810), generate every possible irreducible set generated. Thus, VOILA
contains possible irreducible subsets X.
81

fiBilgic & Getoor

Algorithm 3: VOILA construction algorithm.
Input: Set features X class variable .
Output: VOILA data structure V, given E.
1 Pick ordering elements X = Xi1 , Xi2 , . . . , Xin
2 {}; PS
3 j = 1 n
4
PS
5
S0 Xij ; DC(S0 ) DC(S) DC(Xij )
6
S0 irreducible
7
{S0 }; Add node corresponding S0 V
8
else
9
S0 potentially irreducible
10
PS PS {S0 }
11
12
13
14
15
16
17

Remove PS sets longer potentially irreducible
max = size largest IS; = {S | |S| = l}
l = 0 max 1

S0 Ll+1
S0
Add edge S0 V

worst-case running time algorithm still exponential number
initially unobserved features, X \ E, number irreducible sets potentially
exponential. running time practice, though, depends structure
Bayesian network VOILA based upon ordering variables line 1.
example, Bayesian network naive Bayes, subsets irreducible (no
feature d-separates feature class variable); thus, search space cannot
reduced all. However, naive Bayes makes extremely strong assumptions
unlikely hold practice. fact, empirically show experiments section five
real-world datasets, features often conditionally independent given class variable;
complex interactions thus number irreducible
subsets substantially smaller number possible subsets.
loop line 4 iterates irreducible potentially irreducible sets
generated far, number potentially-irreducible sets generated
depends ordering chosen. good ordering processes features literals
positivity constraints features dependency constraints earlier. is,
undirected path Xi includes Xj v-structure, good ordering puts Xj
earlier ordering everything Xj Xi . instance, sample
Bayesian network Figure 3(a), consider X3 earlier X4 . refer
ordering perfect satisfies positivity constraints. perfect ordering used,
VOILA construction algorithm never generates potentially irreducible set. Unfortunately,
82

fiValue Information Lattice

always possible find perfect ordering. perfect ordering possible two
features positivity constraint literal dependency constraints.
case occurs loop two v-structures
(Note even though Bayesian network directed acyclic graph, still contain
loops, i.e., undirected cycles). perfect ordering possible four five real world
datasets used.
3.4 Using VOILA Feature-value Acquisition
VOILA makes searching space possible subsets tractable practice. Using
flexibility, possible devise several different acquisition policies. describe two
policies example policies section.
first acquisition policy aims capture practical setting one
feature acquired once. policy constructed using VOILA follows.
path ps policy (which initially empty) repeatedly extended acquiring
set S0 V best Benef it(S0 | s, e). policy construction ends path
extended, i.e., candidate sets non-positive Benefit values path .
second acquisition policy adds look-ahead capability greedy policy.
is, rather repeatedly extending path ps policy feature Xi
highest Benef it(Xi | s, e), add look-ahead capability, first find set S0 V
highest Benef it(S0 | s, e). Then, instead acquiring features S0
once, like policy, find feature Xi S0 highest
Benef it(Xi | s, e) acquire extend ps .

4. Experiments
experimented five real-world medical datasets Turney (1995) described
used paper. datasets Bupa Liver Disorders, Heart Disease, Hepatitis,
Pima Indians Diabetes, Thyroid Disease, available UCI Machine
Learning Repository (Frank & Asuncion, 2010). datasets varying number
features ranging five 20. Four five datasets binary labels, whereas
Thyroid dataset three labels.
dataset, first learned Bayesian Network provides joint
probability distribution P (Y, X) efficiently answers conditional independence queries
thorough d-separation (Pearl, 1988). built VOILA dataset using learned
Bayesian Network. first present statistics dataset, number features
number nodes VOILA, compare various acquisition policies.
4.1 Search Space Reduction
Table 1 shows aggregate statistics dataset, describing number features,
number possible subsets, number subsets VOILA, percent reduction
search space. table shows, number irreducible subsets substantially
fewer possible subsets. Thyroid Disease dataset, example, number
possible subsets million whereas number irreducible subsets fewer
83

fiBilgic & Getoor

Table 1: Aggregate statistics dataset. number irreducible subsets, i.e.,
number nodes VOILA, substantially fewer number possible
subsets.
Dataset
Bupa Liver Disorders
Pima Indians Diabetes
Heart Disease
Hepatitis
Thyroid Disease

Features

Subsets

Nodes VOILA

Reduction

5
8
13
19
20

32
256
8,192
524,288
1,048,576

26
139
990
18,132
28,806

19%
46%
88%
97%
97%

thirty thousand. enormous reduction search space makes searching
possible sets features tractable practice.
4.2 Expected Total Cost Comparisons
compared expected total costs (Equation 2) four different acquisition policies
dataset. policies follows:
Acquisition: policy acquire features; aims minimize
expected misclassification cost based prior probability distribution class
variable, P (Y ).
Markov Blanket: policy acquires every relevant feature, regardless misclassification costs. Market Blanket Bayesian network defined
parents, children, childrens parents (Pearl, 1988). Intuitively,
minimal set X (X \ S) | S.
Greedy: policy repeatedly expands path ps initially empty policy
acquiring feature Xi highest positive Benef it(Xi | s) (Equation
4). policy construction ends path extended feature
positive Benefit value.
Greedy-LA: policy adds look-ahead capability Greedy strategy.
policy repeatedly expands path ps initially empty policy first finding
set S0 highest positive Benef it(S0 | s) (Equation 6) acquiring
feature Xi S0 maximum Benef it(Xi | s) (Equation 4). policy
construction ends set positive Benefit value found path
policy.
feature costs dataset described detail Turney (1995). summary,
feature either independent cost, belong group features,
first feature group incurs additional cost. example, first feature
group blood measurements incurs overhead cost drawing blood patient.
feature costs based data Ontario Ministry Health (1992).
84

fiValue Information Lattice

Table 2: Example misclassification cost matrix (cij ) symmetric asymmetric misclassification costs. cij set way achieve prior expected misclassification
cost 1. symmetric cost case, choosing probable class leads
EM C = 1, whereas, asymmetric cost case, choosing either class
indifferent leads EMC 1.
Actual Class

Prior Probability

Pred. Class

Symm. Cost

Asymm. Cost

y1

P (y1 ) = 0.6510

y1
y2

0
2.866

0
2.866

y2

P (y2 ) = 0.3490

y1
y2

2.866
0

1.536
0

observed features assigned cost. example, four
five features Bupa Liver Disorders dataset, 13 19 features Hepatitis
dataset, six eight features Diabetes dataset, 16 20 features
Thyroid Disease dataset assigned cost. costs similar,
problem practically equivalent finding minimum size decision tree. provide
structure feature acquisition costs, also experimented randomly generated
feature group costs. feature, randomly generated cost 1 100,
group generated cost 100 200. repeated experiments
three different seeds dataset.
misclassification costs defined paper Turney (1995). One reason
could easier define feature costs, defining cost misclassification non-trivial. Instead, Turney tests different acquisition strategies using
various misclassification costs. follow similar technique slight modification.
compare acquisition policies symmetric (cij = cji ) asymmetric
misclassification costs. able judge misclassification cost structure affects
feature acquisition, unify presentation, compare different acquisition strategies
priori expected misclassification costs, defined Equation (1). Specifically, compare acquisition policies various priori EMC achieved
varying cij accordingly. show example misclassification table EMC value
1 Table 2. real feature cost case, varied EMC 0 2000,
varied 0 4000 synthetic feature cost case.
compare Greedy, Greedy-LA, Markov Blanket policies plotting
much cost policy saves respect Acquisition policy. X axis
plots, vary priori expected misclassification cost using methodology
described above. plot savings axis. dataset, plot four different
scenarios: cross product {symmetric, asymmetric} misclassification costs, {real,
synthetic} feature costs.
results Liver Disorders, Diabetes, Heart Disease, Hepatitis, Thyroid
Disease given Figures 4, 5, 6, 7, 8 respectively. figure, symmetric
misclassification cost scenarios given sub-figures (a) (c), whereas asymmetric
85

fiBilgic & Getoor

(a)

(b)

(c)

(d)

Figure 4: Expected Total Cost (ETC ) comparisons Bupa Liver Disorders dataset.
priori class distribution follows: P (Y ) = [0.4959, 0.5041].

misclassification cost scenarios presented (b) (d). Similarly, real feature cost
scenarios given (a) (b) synthetic feature cost scenarios presented
(c) (d). next summarize results.
found Greedy policy often prematurely stopped acquisition, performing
even worse Markov Blanket strategy. true datasets,
regardless feature misclassification cost structures. fact Greedy
strategy perform worse Markov Blanket strategy really troubling. first,
might seem rather unintuitive Greedy strategy perform worse Markov
Blanket strategy. Part reason features belong groups first
feature group incurs overhead cost. Greedy strategy feature
considered isolation, overhead costs outweigh single features benefit,
Greedy look ahead, reluctant commit acquiring
first feature group.
86

fiValue Information Lattice

(a)

(b)

(c)

(d)

Figure 5: Expected Total Cost (ETC ) comparisons Pima Indian Diabetes dataset.
priori class distribution follows: P (Y ) = [0.6510, 0.3490].

Greedy-LA strategy never performs worse strategy setting.
misclassification cost structure (symmetric asymmetric) considerable
effect policies behaved. differences symmetric asymmetric cases particularly evident datasets class distribution
imbalanced, Diabetes (Figure 5), Hepatitis (Figure 7), Thyroid
Disease (Figure 8) datasets. differences due misclassification cost structure
summarized follows:
class distribution imbalanced misclassification cost symmetric, acquiring information cannot change classification decisions
easily due class imbalance, thus features high EVI values.
hand, misclassification costs asymmetric, features tend
higher EVI values. Thus, Greedy Greedy-LA strategies start
acquiring features earlier X axis asymmetric cases compared
87

fiBilgic & Getoor

(a)

(b)

(c)

(d)

Figure 6: Expected Total Cost (ETC ) comparisons Heart Disease dataset. priori
class distribution follows: P (Y ) = [0.5444, 0.4556].

symmetric counterparts. example, Thyroid disease dataset
real feature costs, Greedy strategy starts acquisition EMC
greater 600 symmetric misclassification costs (Figure 8(a)) whereas
starts acquiring EMC reaches 100 asymmetric case (Figure 8(b)). synthetic feature costs, results dramatic; neither
Greedy Greedy-LA acquires features symmetric cost case (Figure 8(c)), whereas start acquisition EM C = 200 asymmetric
case (Figure 8(d)).
realm results, slope savings asymmetric case much higher compared symmetric case.
misclassification cost structure causes differences Greedy
Greedy-LA policies cases. Diabetes dataset Greedy policy performs worse misclassification costs symmetric (Figures 5(a)
88

fiValue Information Lattice

(a)

(b)

(c)

(d)

Figure 7: Expected Total Cost (ETC ) comparisons Hepatitis dataset. priori class
distribution follows: P (Y ) = [0.7908, 0.2092].

5(c)), whereas Hepatitis dataset, performs worse asymmetric
misclassification costs (Figures 7(b) 7(d)).
Greedy policy sometimes erratic, unpredictable, unreliable performance expected misclassification changes. possibly hits local minima, gets
later, hits local minima (Figures 6 8(d)).
finally present aggregate summary results Table 3. Table 3 shows
much Greedy policy Greedy-LA policy saves Markov Blanket policy.
results presented average saving various intervals, [0-500).
table also shows, Greedy-LA policy never loses compared Markov Blanket
policy, one would expect. Additionally, Greedy-LA policy wins Greedy
policy cases, never looses. Finally, Greedy policy prematurely stops
acquisition, negative savings respect Markov Blanket strategy.
89

fiBilgic & Getoor

(a)

(b)

(c)

(d)

Figure 8: Expected Total Cost (ETC ) comparisons Thyroid Disease dataset.
priori class distribution follows: P (Y ) = [0.0244, 0.0507, 0.9249].

5. Related Work
Decision theoretic value information calculations provide principled methodology
information gathering general (Howard, 1966; Lindley, 1956). Influence diagrams,
example, popular tools representing decisions utility functions (Howard &
Matheson, 1984). However, devising optimal acquisition policy (i.e., constructing optimal decision tree) intractable general, approaches feature
acquisition myopic (Dittmer & Jensen, 1997), greedily acquiring one feature
time. greedy approaches typically differ i) problem setup assume, ii)
way features scored, iii) classification model learned. review
existing work here, highlighting differences different techniques three
dimensions.
Gaag Wessels (1993) consider problem evidence gathering diagnosis
using Bayesian Network. setup, gather evidence (i.e., observe values
variables) hypothesis confirmed disconfirmed desired extent.
90

fiValue Information Lattice

Table 3: Savings Greedy (GR) Greedy-LA (LA) respect Markov Blanket
policy, averaged different intervals. entry bold worse
Greedy-LA, red worse Markov Blanket.

Liver
GR

LA

Diabetes
GR
LA

Heart
GR

LA

Hepatitis
GR
LA

Thyroid
GR
LA

Real Feature Costs & Symmetric Misclassification Costs
[0-500)
[500-1000)
[1000-1500)
[1500-2000]

6.77
-18.84
-42.12
-67.59

9.08
2.70
2.66
2.85

15.49
-18.28
-48.35
-81.43

24.27
17.06
17.35
17.34

240.59
121.31
79.07
-24.98

243.31
144.87
116.68
111.34

4.19
-6.06
-14.32
-23.40

5.86
3.90
3.90
3.85

28.07
13.90
13.41
13.41

28.07
13.90
13.41
13.41

5.84
2.57
2.57
2.57

17.7
1.56
1.56
1.56

17.7
1.56
1.56
1.56

231.93
106.54
96.39
88.14
79.88
71.63
68.67
63.66

298.01
277.70
257.40
237.09
216.79
196.48
176.18
153.84

298.01
277.70
257.40
237.09
216.79
196.48
176.18
153.84

276.32
213.60
162.52
113.82
65.12
28.72
0.78
-18.10

276.32
213.60
162.52
113.82
68.39
34.73
14.67
9.50

Real Feature Costs & Asymmetric Misclassification Costs
[0-500)
[500-1000)
[1000-1500)
[1500-2000]

7.33
-16.78
-38.26
-61.88

9.3
2.66
3.04
2.97

22.74
9.85
3.99
-2.54

23.84
13.31
11.7
13.7

245.79
131.36
46.20
-40.96

245.79
143.3
114.23
107.14

-9.55
-47.61
-84.79
-125.69

Synthetic Feature Costs & Symmetric Misclassification Costs
[0-500)
[500-1000)
[1000-1500)
[1500-2000)
[2000-2500)
[2500-3000)
[3000-3500)
[3500-4000]

307.39
160.95
60.30
31.86
10.43
-14.60
-39.64
-67.18

307.39
160.95
79.76
53.97
53.01
62.66
59.96
63.68

418.34
245.75
163.80
138.78
108.69
78.90
48.83
15.75

418.34
288.65
224.09
163.45
163.78
164.75
172.76
172.13

723.36
579.25
444.42
378.43
364.03
268.00
171.91
109.91

723.36
585.72
539.88
490.23
482.24
458.89
422.06
412.11

231.93
63.59
96.39
88.14
79.88
71.63
63.38
54.30

Synthetic Feature Costs & Asymmetric Misclassification Costs
[0-500)
[500-1000)
[1000-1500)
[1500-2000)
[2000-2500)
[2500-3000)
[3000-3500)
[3500-4000]

306.19
156.78
66.57
37.47
14.84
-9.19
-33.22
-59.66

306.19
156.78
79.79
60.62
55.70
58.85
59.33
63.13

441.29
341.28
260.09
201.19
161.24
144.24
132.84
126.43

441.29
341.28
261.21
204.31
164.17
151.22
139.54
136.51

728.57
599.02
505.80
420.56
320.32
211.26
248.73
206.06

728.57
603.12
517.37
519.29
512.75
500.75
400.16
389.32

219.04
88.34
-16.86
-54.31
-64.75
-101.93
-139.11
-180.01

219.04
91.53
49.39
61.90
61.90
61.90
61.90
61.90

propose acquisition algorithm greedily computes expected utility acquiring
feature chooses one highest utility. define utility absolute
value change probability distribution hypothesis tested.
recent work, Sent Gaag (2007) consider problem acquiring
single feature step. define subgoals cluster features subgoal.
subgoals clustering features provided domain experts. Then,
non-myopic case, pick cluster calculating expected values. However,
91

fiBilgic & Getoor

clusters big, calculating expected value cluster problematic;
thus, also provide semi-myopic algorithm pick cluster
best (myopic) feature.
Nunez (1991) introduces decision tree algorithm called EG2 sensitive
feature costs. Rather splitting decision tree feature high information
gain, EG2 chooses feature least information cost function, defined
ratio features cost discriminative efficiency. EG2 is, however, directly
optimized balance misclassification cost feature acquisition cost; rather
optimized 0/1 loss taking feature costs account. Similarly, Tan (1990)
modifies ID3 algorithm (Quinlan, 1986) account feature costs. Tan considers
domain robot needs sense, recognize, act, number features
large. robot act efficiently, needs trade-off accuracy efficiency.
Turney (1995) builds decision tree called ICET (standing Inexpensive Classification
Expensive Tests) using genetic search algorithm (Grefenstette, 1986) using
Nunezs (1991) criteria build C4.5 decision trees (Quinlan, 1993). Unlike Nunez, Turney
takes misclassification costs account (in addition feature costs) evaluate
given decision tree looks good decision tree using genetic search algorithms.
Yang et al. (2006) build cost-sensitive decision trees Naive Bayes classifiers
take feature costs misclassification costs account. Unlike Nunez (1991),
scores features based information gain cost ratio, Yang et al. score features based
expected reduction total cost (i.e., sum feature cost misclassification
cost) training data. so, take feature costs misclassification costs
account directly learning time.
Bayer-Zubek (2004) formulates feature acquisition problem Markov Decision
Process provides greedy systematic search algorithms develop diagnostic
policies. Bayer-Zubek takes feature cost misclassification costs account
automatically finds acquisition plan balances two costs. introduces
admissible heuristic AO* search describes regularization techniques reduce overfitting training data.
Saar-Tsechansky, Melville, Provost (2009) consider active feature acquisition
classifier induction. Specifically, given training data missing feature values, cost matrix defines cost acquiring feature value, describe
incremental algorithm select best feature acquire iteratively build
model expected high future performance. utility acquiring feature
estimated terms expected performance improvement per unit cost. two characteristics make work different previous work i) authors
assume fixed budget priori; rather build model incrementally, ii)
feature different cost instance.
Finally, Greiner, Grove, Roth (2002) analyze sample complexity dynamic
programming algorithms performs value iteration search best diagnostic
policies. analyze problem learning optimal policy, using variant
probably-approximately-correct (PAC) model. show learning achieved
efficiently active classifier allowed perform (at most) constant number
tests show learning optimal policy often intractable general
environments.
92

fiValue Information Lattice

6. Future Work
article, scratched surface incorporating constraints
features order reduce search space make reasoning sets tractable.
discovered two types constraints (features render features useless,
features useless without features) purely underlying probability
distribution. shown automatically discovered constraints helped reduce
search space dramatically. practice, possible discover additional types
constraints potentially used reduce search space (for e.g., ordering
constraints certain procedures always precede procedures). Constraints
also defined based observed feature values; example, treadmill test might
performed patients old age. Patients decline certain procedures medications.
Eliciting constraints domain experts utilizing reduce
search space promising future direction.
existing feature acquisition frameworks, including one, major
simplification happens practice; assumed acquiring values
features change class value values variables. However, practice,
feature value measurements side-effects, example, medical diagnosis
certain measurements non-invasive change status patient, others
might include medications affect outcome. Similarly, fault diagnosis
repair, purpose diagnose repair fault, actions
fact repair fault, essence changing class value. Taking extra side-effects
account make feature acquisition frameworks realistic.

7. Conclusion
typical approach feature acquisition greedy past primarily due
sheer size possible subsets features. described general technique
optimally prune search space exploiting conditional independence relationships
features class variable. empirically showed exploiting conditional independence relationships substantially reduce number possible subsets.
also introduced novel data structure called Value Information Lattice (VOILA)
efficiently reduce search space using conditional independence relationships also share probabilistic inference computations different subsets
features. using VOILA, able add full look-ahead capability greedy
acquisition policy, would practical otherwise. experimentally showed
five real-world medical datasets greedy strategy often stopped feature acquisition
prematurely, performing worse even policy acquires features.

Acknowledgments
thank reviewers helpful constructive feedback. material
based work supported National Science Foundation Grant No. 0746930.
93

fiBilgic & Getoor

References
Bayer-Zubek, V. (2004). Learning diagnostic policies examples systematic search.
Annual Conference Uncertainty Artificial Intelligence.
Bilgic, M., & Getoor, L. (2007). VOILA: Efficient feature-value acquisition classification.
AAAI Conference Artificial Intelligence, pp. 12251230.
Dittmer, S., & Jensen, F. (1997). Myopic value information influence diagrams.
Annual Conference Uncertainty Artificial Intelligence, pp. 142149.
Frank, A., & Asuncion, A. (2010). UCI machine learning repository..
Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic belief networks.
AISB Quarterly, pp. 2334.
Grefenstette, J. (1986). Optimization control parameters genetic algorithms. IEEE
Transactions Systems, Man Cybernetics, 16 (1), 122128.
Greiner, R., Grove, A. J., & Roth, D. (2002). Learning cost-sensitive active classifiers.
Artificial Intelligence, 139 (2), 137174.
Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computation value information. IEEE Transactions Pattern Analysis Machine
Intelligence, 15 (3), 292298.
Howard, R. A., & Matheson, J. E. (1984). Readings Principles Applications
Decision Analysis, chap. Influence Diagrams. Strategic Decision Group.
Howard, R. A. (1966). Information value theory. IEEE Transactions Systems Science
Cybernetics, 2 (1), 2226.
Hyafil, L., & Rivest, R. L. (1976). Constructing optimal binary decision trees NPComplete. Information Processing Letters, 5 (1), 1517.
Lindley, D. V. (1956). measure information provided experiment. Annals
Mathematical Statistics, 27, 9861005.
Nunez, M. (1991). use background knowledge decision tree induction. Machine
Learning, 6 (3), 231250.
Health, O. M. (1992). Schedule benefits: Physician services health insurance
act..
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann, San
Francisco.
Quinlan, J. R. (1986). Induction decision trees. Machine Learning, 1 (1), 81106.
Quinlan, J. R. (1993). C4.5: programs machine learning. Morgan Kaufmann Publishers
Inc., San Francisco, CA, USA.
Saar-Tsechansky, M., Melville, P., & Provost, F. (2009). Active feature-value acquisition.
Management Science, 55 (4), 664684.
Sent, D., & Gaag, L. C. (2007). Enhancing automated test selection probabilistic networks. Proceedings 11th conference Artificial Intelligence Medicine,
pp. 331335.
94

fiValue Information Lattice

Tan, M. (1990). CSL: cost-sensitive learning system sensing grasping objects.
IEEE International Conference Robotics Automation.
Turney, P. D. (1995). Cost-sensitive classification: Empirical evaluation hybrid genetic
decision tree induction algorithm. Journal Artificial Intelligence Research, 2, 369
409.
Yang, Q., Ling, C., Chai, X., & Pan, R. (2006). Test-cost sensitive classification data
missing values. IEEE Transactions Knowledge Data Engineering, 18 (5),
626638.

95

fiJournal Artificial Intelligence Research 41 (2011) 155-229

Submitted 01/11; published 06/11

Analyzing Search Topology Without Running Search:
Connection Causal Graphs h+
Jorg Hoffmann

joerg.hoffmann@inria.fr

INRIA
Nancy, France

Abstract
ignoring delete lists relaxation paramount importance satisficing
optimal planning. earlier work, observed optimal relaxation heuristic
h+ amazing qualities many classical planning benchmarks, particular pertaining
complete absence local minima. proofs hand-made, raising
question whether proofs lead automatically domain analysis techniques.
contrast earlier disappointing results analysis method exponential runtime
succeeds two extremely simple benchmark domains herein answer
question affirmative. establish connections causal graph structure
h+ topology. results low-order polynomial time analysis methods, implemented
tool call TorchLight. 12 domains absence local minima
proved, TorchLight gives strong success guarantees 8 domains. Empirically, analysis
exhibits strong performance 2 domains, plus 4 domains
local minima may exist rare. way, TorchLight distinguish easy domains
hard ones. summarizing structural reasons analysis failure, TorchLight also
provides diagnostic output indicating domain aspects may cause local minima.

1. Introduction
ignoring delete lists relaxation since decade, still is, paramount
importance effective satisficing planning (e.g., McDermott, 1999; Bonet & Geffner, 2001;
Hoffmann & Nebel, 2001a; Gerevini, Saetti, & Serina, 2003; Helmert, 2006; Richter &
Westphal, 2010). recently, heuristics making relaxation also shown
boost optimal planning (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009).
planners using relaxation approximate, variety ways, optimal relaxation
heuristic h+ NP-hard compute (Bylander, 1994). observed
earlier work (Hoffmann, 2005), h+ rather amazing qualities many classical
planning benchmarks. Figure 1 gives overview results.1
results divide domains classes along two dimensions. herein ignore horizontal dimension, pertaining dead ends, domain analysis already available:
easy-to-test powerful criteria implying task undirected/harmless known
(e.g., Hoffmann, 2005). vertical dimension divides domains three classes,
respect behavior exit distance, defined 1 distance state
strictly smaller h+ value. easiest bottom class, exist constant upper
1. omit ADL domains, add recent IPC benchmarks Elevators Transport (without
action costs), properties trivial prove based earlier results. Blocksworld-Arm
classical blocksworld, Blocksworld-NoArm variant allowing move B C directly.
c
2011
AI Access Foundation. rights reserved.

fiHoffmann

PipesworldTank
PipesworldNoTank
PSR

Rovers
OpticalTelegraph

Mystery
Mprime
Freecell
Airport

Hanoi [0]
BlocksworldNoArm [0]
Grid [0]
Transport [0]
bench ed <= c

local minima ed <= c

BlocksworldArm
Depots
Driverlog

Elevators [0,1]
Logistics [0,1]
Ferry [0,1]
Gripper [0,1]
undirected

Tyreworld [0,6]
Satellite [4,4]
Zenotravel [2,2]
MiconicSTRIPS [0,1]
Movie [0,1]
SimpleTsp [0,0]
harmless

DiningPhil. [31,31]

recognized

unrecognized

Figure 1: Overview h+ topology (Hoffmann, 2005).
bounds exit distance both, states local minima states benches (flat regions). figure, bounds given square brackets. example, Logistics,
bound local minima 0 meaning local minima exist bound
benches 1. middle class, bound exists local minima; bound
0 (no local minima all) domains shown. hardest top class, local
minima benches may take arbitrarily many steps escape.
proofs underlying Figure 1 hand-made. dealing unseen domains,
question arises whether design domain analysis methods leading proofs
automatically. potential uses analysis methods manifold; discuss
end paper. now, note addressing question formidable challenge.
trying automatically infer properties characterizing informativeness (or lack
thereof ) heuristic function. wish based static analysis, actually
running search. Formally characterizing informativeness heuristic function
is, cases, hardly possible even experienced researchers, explains perhaps
no-one far even attempted automatically. single exception,
best authors knowledge, analysis method mentioned side
authors earlier work (Hoffmann, 2005). analysis method builds exponentially
large tree structure summarizing ways relaxed plans may generate facts.
tree size, therewith analysis runtime, explodes quickly task size. Worse,
analysis succeeds Movie Simple-TSP arguably two simplistic planning
benchmarks existence.2
contrast, TorchLight tool developed herein low-order polynomial runtime
usually terminates split seconds. Distinguishing global (per task) local (per
state) analysis, proves global absence local minima Movie, Simple-TSP, Logistics,
Miconic-STRIPS. gives strong guarantee local analysis succeed every state
Ferry, Gripper, Elevators, Transport. Taking success rate fraction
states local analysis succeeds, TorchLight empirically exhibits strong performance
delivering high success rates also Zenotravel, Satellite, Tyreworld, Grid, Driverlog,
2. Simple-TSP encodes TSP fully connected graph uniform edge cost. domain
introduced Fox Long (1999) benchmark symmetry detection.

156

fiAnalyzing Search Topology Without Running Search

Rovers. Thus TorchLights success rates tend high easy domains Figure 1,
low hard ones, serving automatically distinguish two
groups.3 summarizing structural reasons analysis failure, TorchLight finally provides
diagnostic output indicating problematic aspects domain, i.e., operator effects
potentially cause local minima h+ .
key performance boost? Consider Logistics Blocksworld-Arm.
level PDDL domain descriptions, difference evident
delete effects, Blocksworld-Arm hurt Logistics dont?
trick move finite-domain variable representation (e.g., Jonsson &
Backstrom, 1998; Helmert, 2006, 2009) consider associated structures, notably
causal graph (e.g., Knoblock, 1994; Jonsson & Backstrom, 1995; Domshlak & Dinitz,
2001; Helmert, 2006) capturing precondition effect dependencies variables.
causal graph Blocksworld-Arm contains cycles. Logistics doesnt. Looking
this, surprisingly easy derive following basic result:
causal graph acyclic, every variable transition invertible,
local minima h+ .
result certainly interesting that, first time, establishes connection
causal graph structure h+ topology. However, result much
weak domain analysis considered benchmarks, applies Logistics. devise generalizations approximations yielding analysis results described
above. Aside significance domain analysis, techniques also interesting
respect research causal graphs. Whereas traditional methods (e.g., Jonsson &
Backstrom, 1995; Brafman & Domshlak, 2003; Jonsson, 2009; Gimenez & Jonsson, 2009a)
seek execution paths solving overall task, seek execution paths decreasing
value h+ . local analysis, enables us consider small fragments causal
graph, creating potential successfully analyze states tasks whose causal graphs
otherwise arbitrarily complex.
next section gives brief background planning finite-domain variables,
associated notions causal graphs definition h+ topology. Section 3 gives illustrative example explaining basic result, Section 4 provides
synopsis full technical results relating causal graphs h+ topology. Sections 5
6 present results detail, explaining first analyze state
provided given optimal relaxed plan input, thereafter providing
criteria causal graph structure implying analysis always succeed. evaluate domain analysis technique proving number domain-specific performance
guarantees Section 7, reporting large-scale experiment TorchLight Section 8. point related work within context appropriate, discuss details
Section 9. close paper discussion future work Section 10. improve
readability, main text omits many technical details outlines proofs.
full details including proofs Appendix A.
3. extent, particular result also achieved simpler means (limited search probing).
discuss along experiments Section 8.

157

fiHoffmann

2. Background
adopt terminology notation Helmert (2006), number modifications
suiting purposes. (finite-domain variable) planning task 4-tuple (X, sI , sG , O). X
finite set variables, x X associated finite domain Dx . partial
state X function subset Xs X, s(x) Dx x Xs ; state
Xs = X. initial state sI state. goal sG partial state. finite set
operators. pair = (preo , eff ) partial states, called precondition
effect. simple non-restricting sanity conditions, assume |Dx | > 1 x X,
preo (x) 6= eff (x) x Xpreo Xeff .
identify partial states sets variable-value pairs, often refer
facts. state space task directed graph whose vertices states
X, arc (s, s0 ) iff exists preo s, eff s0 , s(x) = s0 (x)
x X \ Xeff . plan path leading sI state sG s.
next define two basic structures analysis: domain transition graphs
causal graphs. former, diverge Helmerts definition (only)
introduce additional notations indicating operator responsible transition, well
side effects transition, i.e., variable values set executing
responsible operator. detail, let x X. domain transition graph DT Gx x
labeled directed graph vertex set Dx following arcs.
x Xpreo Xeff c := preo (x) c0 := eff (x), DT Gx contains arc (c, c0 ) labeled
responsible operator rop(c, c0 ) := o, conditions cond(c, c0 ) := preo \ {(x, c)},
side effects seff(c, c0 ) := eff \ {(x, c0 )}. x Xeff \ Xpreo
c0 := eff (x), every c Dx c 6= c0 , DT Gx contains arc (c, c0 ) labeled
rop(c, c0 ) := o, cond(c, c0 ) := preo , seff(c, c0 ) := eff \ {(x, c0 )}.
reader familiar causal graphs may wondered introduced notion
side effects, seeing causal graphs acyclic operators unary (affect
single variable). reason handle cases operators nonunary. variant causal graphs use still acyclic cases, indeed
happens benchmark domains, specifically Simple-TSP, Movie, MiconicSTRIPS, Satellite. define support graph SG directed graph vertex
set X, arc (x, y) iff DT Gy relevant transition (c, c0 )
x Xcond(c,c0 ) .
0
0
Here, transition (c, c ) variable x called relevant iff (x, c ) sG oO preo .
definition modifies commonly used one uses relevant transitions
only, introduce arcs variables co-occurring operator
effect (unless variables occur also precondition). Transitions side effects
handled separately analysis. Note irrelevant transitions occur naturally,
domains non-unary operators. example, unstacking block induces irrelevant
transition making arm non-empty, departing passenger Miconic-STRIPS makes
passenger not-boarded.4
Consider definition h+ . common Boolean-variable setting
PDDL, defined length shortest plan solving problem ignoring
4. remark relevant transitions correspond called requestable values
works, (e.g., Jonsson & Backstrom, 1998; Haslum, 2007). Fast Downwards implementation,
causal graph includes precondition-effect arcs, similarly support graph defined here.

158

fiAnalyzing Search Topology Without Running Search

delete lists, i.e., negative operator effects (Bylander, 1994; McDermott, 1999; Bonet
& Geffner, 2001). raises question h+ actually is, finite-domain variable
planning, delete lists. question easily answered. Ignoring
deletes essentially means act true remain true forever.
finite-domain variable setting, simply means over-write values
variables previously. knowledge, generalization first described
Helmert (2006). Consider directed graph + whose vertices sets s+ variable+
+
value pairs X, arc (s+
1 , s2 ) iff exists preo s1
+
+
+
s2 = s1 eff . state, relaxed plan path leading
s+ sG s+ . h+ (s) denote length shortest relaxed plan s,
h+ (s) = plan exists. easy see definition corresponds
common Boolean one: translate finite-domain variables Boolean ones
creating one Boolean variable is-(x, c)-true? every fact (x, c), standard h+
Boolean task identical h+ finite-domain variable task.
Bylander (1994) proved intractable compute h+ . Many state-of-the-art
planners approximate h+ , variety ways (e.g., McDermott, 1999; Bonet & Geffner,
2001; Hoffmann & Nebel, 2001a; Gerevini et al., 2003; Helmert, 2006; Richter, Helmert,
& Westphal, 2008; Richter & Westphal, 2010). popular approximation satisficing
planning gives guarantees quality relaxed plan returned
so-called relaxed plan heuristic first proposed FF system (Hoffmann & Nebel, 2001a),
approximates h+ terms length necessarily shortest relaxed plan.
relaxed plans computed low-order polynomial time using techniques inspired
Graphplan (Blum & Furst, 1997).
next introduce relevant notations pertaining search space topology h+ .
Let state 0 < h+ (s) < . exit state s0 reachable
S, h+ (s0 ) = h+ (s) exists neighbor s00 s0 h+ (s00 ) < h+ (s0 )
(and thus h+ (s00 ) < h+ (s)). exit distance ed(s) length shortest path
exit, ed(s) = exit exists. path called monotone iff exist
two consecutive states s1 s2 h+ (s1 ) < h+ (s2 ). say local
minimum exists monotone path exit.
topology definitions, adapted authors previous work (Hoffmann, 2005),
specific h+ sake simplicity (we herein consider heuristics
h+ ).5 States infinite heuristic value ignored correctly
identified, heuristic, dead ends (relaxed-plan based approximations like
FF identify cases). heuristic value 0 already reached
goal, case also safely ignored. Note force exit paths
monotone, i.e., also talk exit distances situations may
local minimum. necessary capture structure domains like Satellite
Zenotravel, local minima exist exit distance bounded. Also,
analysis methods guarantee upper bound length exit path only,
heuristic values path decrease monotonically.
5. remark original definitions significantly involved, e.g., defining local minima
based individual states based strongly connected sub-graphs state space. None
complications relevant results herein.

159

fiHoffmann

Finally, let us say words domain analysis. Generally speaking, domain analysis
aims automatically obtaining non-trivial information domain planning task.
analysis long tradition planning (e.g., Nebel, Dimopoulos, & Koehler, 1997;
Fox & Long, 1998; Gerevini & Schubert, 1998; Edelkamp & Helmert, 1999; Rintanen,
2000). often, information sought pertains reachability relevance properties,
i.e., entities combinations thereof reachable initial state/relevant
goal. notable exception work Long Fox (2000) automatically
recognizes certain generic types domains, like transportation. However, exists
prior work trying automatically infer topological properties heuristic function.
single exception aforementioned disappointing results reported (as aside)
authors previous work (Hoffmann, 2005). method builds structure called
fact generation tree, enumerating ways facts may support
non-redundant relaxed plan. conflict h+ exact solution distance.
Clearly, far strong property applicable reasonably complex domain.
considered benchmarks, property applies Simple-TSP. slightly
general property, also identified work, applies Movie well trivial Logistics
tasks 2 locations, 1 truck, 1 package.
worth noting analyzing topology h+ computationally hard:
Theorem 1. PSPACE-complete decide whether state space given
planning task contains local minimum, given integer K PSPACE-complete
decide whether states ed(s) K. Further, PSPACE-complete
decide whether given state local minimum, given integer K
PSPACE-complete decide whether ed(s) K.
results hardly surprising, stated anywhere yet. membership results Theorem 1 easy prove based guess-and-check arguments similar
given Bylander (1994), exploiting fact NPSPACE=PSPACE. hardness results still hold restricting input solvable tasks/states. proofs work
reducing plan existence, respectively bounded plan existence (with bound non-unary
representation). Given task whose plan existence wish decide, flatten h+
new operator always achieve goal fatal side effect. give
planner choice solving task, solving new alternative task. latter task designed local minimum exists/that exit distance exceeds bound
iff planner must choose alternative task, i.e., iff original task unsolvable/iff
cannot solved within given number steps. full proof Appendix A.1.
practice, computational hardness particularly challenging because,
applications domain analysis, willing run worst-case exponential search.
all, analysis actually solve problem. Consequently, present
research, restrict analysis methods low-order polynomial runtime.
reader noticed state-specific analysis problems Theorem 1.
distinguish global analysis per-task, local analysis per-state. precisely,
herein devise three kinds analyses:
(I) Guaranteed global analysis. Taking input planning task description,
analysis returns yes, state space contain local minima
exit distance state bounded d.
160

fiAnalyzing Search Topology Without Running Search

(II) Guaranteed local analysis. Taking input planning task description
state s, analysis returns yes, local minimum, exit
distance bounded d.
(III) Approximate local analysis. Taking input planning task description
state s, analysis returns yes, indicate local minimum,
exit distance bounded d. may wrong, i.e., analysis
guaranteed sound. Compared analysis (II), trades soundness
ability successfully analyze states.
Domain analysis traditionally considers global variant (I), even generalizing
variants looking PDDL domain file. global once-and-for-all analysis
also holy grail work, local analysis strong advantages. planning task
contain local minima one would expect typically case interesting
domains analysis (I) useless. simply answer no. contrast, local analysis
(II,III) may still detect individual states, sample randomly experiments,
local minima. percentage states, refer success rate,
deliver useful information matter structure planning task is. Note
also that, contrast PSPACE-hard problem low-order polynomial
analysis runtime necessarily implies analyses incomplete, local analyses
chance ameliorate averaging outcome set sample states.

3. Illustrative Example
basic connection identify causal graphs h+ topology precisely,
support graphs, domain transition graphs, h+ topology quite simple.
instructive understand first, delving full results. Figure 2 shows
fragments domain transition graphs (DTGs) three variables x0 , x1 , x2 .
DTG transitions assumed invertible, side effects.
t0

x0
g0
T2

T1

x1

L1

L2

L3

s1 R1

R2

R3

x2
c1

c2

s2

Figure 2: example illustrating basic result.
imaginative reader invited think x0 car whose battery currently
empty therefore requires help two people, x1 x2 , order push-start
it. people may, solve different parts task, required purposes too,
consider sub-problem achieving goal x0 = g0 . wish take
161

fiHoffmann

x0 transition t0 , two conditions c1 c2 . conditions currently
fulfilled. state hand, x1 s1 x2 s2 . must move different
state, s0 , x1 = c1 x2 = c2 . happen h+ along way?
Say optimal relaxed plan P + (s) moves x1 c1 along path marked T1 ,
moves x2 c2 along path marked T2 clearly, paths taken
P + (s). Key observation (1) similar phenomenon known transportation
benchmarks. moving x1 x2 , whichever state s0 in, long s0 remains
within boundaries values traversed T1 T2 , construct relaxed plan
P + (s0 ) s0 |P + (s0 )| |P + (s)|. Namely, obtain P + (s0 ), simply replace


respective move sequence
P + (s), = 1, 2, inverse
. example, say


0
got 1 = hR1, R2, R3i moving x1 c1 , indicated Figure 2. wlog
P + (s) form hR1, R2, R3i P . define P + (s0 ) := hL3, L2, L1i P . postfix P
relaxed plans same; end prefix, set values achieved x1 ,
namely s1 , c1 , two values between, also same. Thus P + (s0 ) relaxed

plan s0 .6 true general, i.e.,
1 necessarily applicable s0 , achieve,

+
0
within relaxed execution P (s ), set facts achieved
1 P + (s). Thus
h+ (s0 ) h+ (s) state s0 , including state s0 after.
Key observation (2) pertains leaf variable, x0 . Say x0 moves
sake, i.e., car position important goal. executing t0
s0 delete anything needed anywhere else. Thus remove rop(t0 )
relaxed plan P + (s0 ) s0 constructed per observation (1) obtain relaxed plan
state s1 results executing t0 s0 . Hence h+ (s1 ) < h+ (s). observation
(1), heuristic values along path s1 h+ (s). know least one
state s00 path heuristic value strictly smaller h+ (s): happens
latest s00 = s1 , may happen earlier case relaxed plan P + (s00 ) constructed
optimal (cf. Footnote 6). Let s00 earliest state h+ (s00 ) < h+ (s)
path, let s0 state preceding s00 . s0 exit s, path
exit monotone. Thus local minimum. exit distance, worst
case s00 = s1 s0 = s0 , ed(s) bounded length path s0 .
difficult imagine works also preconditions need
established recursively, long cyclic dependencies exist. third person may
needed first persuade x1 x2 , third person may need take bus, on.
length path s0 may grow exponentially x1 depends x3
move x1 may require several moves x3 , forth still able
construct P + (s0 ) inverting moves variables individually. Further, inverting
transitions may conditions, too, provided conditions required
original moves. example, above, inverting operator L1 may
arbitrary condition p condition also required R1 . conditions
required original moves (like p R1 ) established P + (s), thus
established P + (s0 ) time inverse moves (like L1 ).
6. Note P + (s0 ) may optimal relaxed plan s0 . P + (s) move x1 anything
attaining c1 , postfix P alone relaxed plan s0 : need insert
inverted prefix hL3, L2, L1i. cases like this, obtain exit state already path s0 ; get
back below.

162

fiAnalyzing Search Topology Without Running Search

Now, say support graph acyclic, transitions invertible
side effects. Given state s, unless already goal state, variable x0
moving sake necessarily exists. then, within optimal relaxed plan
s, situation exists, therefore monotone exit path, Q.E.D.
local minima h+ .
execution path construction discussed different known results
exploiting causal graph acyclicity notions connectedness invertibility domain
transition graphs (e.g., Jonsson & Backstrom, 1995; Williams & Nayak, 1997).
new connection h+ .
remark hand-made analysis h+ (Hoffmann, 2005) uses notion operators respected relaxation. operator respected relaxation iff,
whenever starts optimal plan s, also starts optimal relaxed plan s.
core property many hand-made proofs operators respected
relaxation. motivated speculation recognizing property automatically
could key domain analysis recognizing absence local minima h+ .
explore option herein, however note even basic result outlined
contains cases covered property. Even acyclic support graph invertible
transitions without side effects, examples operator respected
relaxation. give construction Example 1, Appendix A.4.

4. Synopsis Technical Results
technical results follows structured way similar proof argument
outlined previous section. results structured two parts, (A) (B).
(A), Section 5, identify circumstances deduce optimal
relaxed plan monotone exit path exists. (B), Section 6, devise support-graph
based sufficient criteria implying analysis (A) always succeed. Technique (B)
underlies TorchLights conservative analysis methods, i.e., guaranteed global analysis (I)
guaranteed local analysis (II) described end Section 2. feeding technique
(A) usual relaxed plans computed, e.g., FFs heuristic function, obtain
TorchLights approximate local analysis (III). analysis give guarantee,
(and because) FFs relaxed plans guaranteed optimal.
ease reading, give brief synopsis results obtained (A)
(B), provide analysis methods (I)(III). synopsis contains sufficient
information understand rest paper, reader may choose skip Sections 5
6, moving directly evaluation.
analysis method based particular kind sub-graph support graph.
Table 1 overviews these. role parts (A) (B) follows:
(A) Given optimal relaxed plan P + (s) state s, optimal rplan dependency graph
oDG+ sub-graph SG single leaf variable x0 transition t0
example (rop(t0 ) frequently referred o0 ). arc (x, x0 ) oDG+
P + (s) relies x0 achieve conditions t0 , P + (s) relies x moving x0 .
say oDG+ successful acyclic, involved transitions usable
exit path construction (e.g., harmful side effects), deletes t0
163

fiHoffmann

Name
Support graph

Symbol
SG

Analysis

Approximate
local analysis (III)
Theorem 2

Optimal rplan
dependency graph

oDG+

Local
dependency graph

lDG

Guaranteed
local analysis (II)
Theorem 3

Global
dependency graph

gDG

Guaranteed
global analysis (I)
Theorem 4

Leaves

Single leaf x0 s.t. applying
t0 affect
remainder P + (s)
Single leaf x0 XsG ,
s(x0 ) 6= sG (x0 ) x0
transitive SG successor
property
Single leaf x0 XsG

Arcs

(x, x0 ) x used
P + (s) support x0
obtaining cond(t0 )
(x, x0 )
s(x) 6= cond(t0 )(x);
(x, x0 ) x0 lDG
(x, x0 ) SG
(x, x0 ) x 6= x0 ;
(x, x0 ) x0 gDG
(x, x0 ) SG

Table 1: Overview different support graph sub-graphs underlying results.
either relevant P + (s) all, recovered inside P + (s). main
result, Theorem 2, states local minimum exists successful oDG+
s. also derives exit distance bound oDG+ . Approximating Theorem 2
applying relaxed plan computed FFs heuristic yields analysis (III).
(B) Given state s, local dependency graph lDG sub-graph SG single leaf
variable x0 , whose goal value yet unachieved, whose transitive successors
SG already attained goal values. setting, x0 moves
sake example. graph lDG simply includes SG predecessors x0 ,
single exception pertaining arcs (x, x0 ) x0 itself, inserted
corresponding condition t0 already satisfied s. say lDG successful
acyclic, involved transitions usable exit path construction, t0
relevant deletes. implies exists successful oDG+
contained lDG, thus Theorem 3, stating local minimum
giving corresponding exit distance bound. result underlies analysis (II).
global dependency graph gDG sub-graph SG identifies goal variable
x0 , includes SG predecessors x0 . successful defined
way lDGs. gDGs successful, Theorem 3 apply every state
lDG contained successful gDG. Thus Theorem 4, stating
state space contain local minima. exit distance bound
obtained maximizing gDGs. result underlies analysis (I).
understanding practical performance TorchLight, important note
(A) minimal result would suffice prove (B). cases identified
Theorem 2 much richer actually infer support graphs.
reason, analysis (III), sound due use potentially non-optimal relaxed
plans, able analyze much larger class states analysis (II). little detail,
difference two methods pertains (1) whether P + (s) relies values
x moving x0 , (2) whether deletes t0 recovered inside P + (s).
Neither (1) (2) visible support graph, rely details
form relaxed plan P + (s). example, consider Gripper domain. Notion (1)
important support graph contains arcs (carry-ball-b, free-gripper)
due dropping ball b (free-gripper, carry-ball-b) due picking ball b.
Thus, looking SG, seems carry-ball-b may support (free gripper
164

fiAnalyzing Search Topology Without Running Search

dropping ball want pick up). course, doesnt happen optimal
relaxed plan. Notion (2) important operators (picking ball)
harmful side effects (making gripper hand non-empty), side effects always
recovered inside relaxed plan (when dropping ball later on). remains future
work extend analyses (I,II) detect kinds phenomenona.

5. Analyzing Optimal Relaxed Plans
consider state optimal relaxed plan P + (s) s. describe circumstances
monotone exit path guaranteed exist, need number notations
pertaining properties transitions etc. introduce notations along way,
rather front, hope makes easier digest.
+
+
Given o0 P + (s), P<0
(s) P>0
(s) denote parts P + (s) front o0
+
behind o0 , respectively. P (s, x) denote sub-sequence P + (s) affecting
x. capture dependencies variables used P + (s) achieving
precondition o0 , follows:
Definition 1. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , let
P + (s) optimal relaxed plan s, let x0 X, let o0 P + (s) operator
taking relevant transition form t0 = (s(x0 ), c).
optimal rplan dependency graph P + (s), x0 o0 , optimal rplan dependency
graph P + (s) brief, graph oDG+ = (V, A) unique leaf vertex x0 ,
x V (x, x0 ) either: x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x 6= x0
0
+
(s) taking relevant transition x0 x Xpreo
V \ {x0 } exists P<0
preo (x) 6= s(x).
x V \ {x0 }, oDT G+
x denote sub-graph DT Gx includes
+
(s, x), relevant transitions using operator
values true point P<0
+
P<0 (s, x), least one relevant inverse relevant inverse exists.
+
(s, x) transitions original, inverse transitions induced.
refer P<0
transition t0 responsible operator o0 candidate reaching
exit state, like t0 Figure 2. oDG+ collects variables x connected variable x0
+
insofar P<0
(s) uses operator preconditioned x order move x0 .
variables need move, like x1 x2 Figure 2, obtain state s0 t0
taken. variable x, oDT G+
x captures domain transition graph fragment
+
P<0
(s) traverses within stay, like T1 T2 Figure 2.
+
Note need consider operators P>0
(s) behind o0 , simply
operators used order establish o0 precondition. paramount
importance practice. example Gripper situation mentioned above. o0 picks
+
ball b Gripper, P + (s) also contain behind o0 , i.e., P>0
(s)
0
0
+
operator dropping b. considered Definition 1, oDG would contain
mentioned cycle assuming o0 used making gripper hand free picking b.
TorchLights approximate local analysis, whenever consider operator o0 ,
build oDG+ re-order P + (s) moving operators behind o0 possible. minimizes
+
P<0
(s), oDG+ thus indeed contains necessary variables arcs.
165

fiHoffmann

circumstances t0 actually job? sufficient criterion
identify rather complex. provide overview criterion, next state definition. items definition explained below.
Definition 2. Let (X, sI , sG , O), s, P + (s), x0 , o0 , t0 , oDG+ = (V, A) Definition 1. say oDG+ successful following holds:
(1) oDG+ acyclic.
(2) either:
+
(a) oDG+ -relevant deletes t0 P>0
(s)-recoverable;
+
(b) s(x0 ) oDG -relevant, t0 replaceable side effect deletes;
(c) s(x0 ) oDG+ -relevant, t0 recoverable side effect deletes.

(3) x V \ {x0 }, oDT G+
x transitions either self-irrelevant deletes,
invertible/induced irrelevant side effect deletes side effects V \{x0 }.
already outlined, exit path construction works staying within ranges
oDT G+
x , x V \ {x0 }, reached state s0 transition t0
taken. make little precise, consider topological order xk , . . . , x1 V \ {x0 }
respect oDG+ order exists due Definition 2 condition (1). (If
cycles, moving variable may involve moving first place,
covered exit path construction.) consider, 0 k, d-abstracted
task. like original task except that, every transition one graphs
oDT G+
xi d, remove condition (xj , c) cond(t) j > d. exit
path construction understood induction d, proving existence


execution path
whose end t0 taken. construct
exclusively
,

x

V
\
{x
}.


base case,
operators responsible transitions oDT G+
0
x
0-abstracted task, t0 directly applicable. inductive case, constructed


suitable path
d-abstracted task, suitable path
d+1 + 1
abstracted task constructed follows. Assume operator
,


precondition (xd+1 , c) true current state. Then, d+1 ,
front simply insert path oDT G+
xd+1 ends c. Note that,
construction, (xd+1 , c) condition transition oDT G+
xi , < + 1.
+
+
taken P<0
(s, x), (xd+1 , c) must achieved P<0
(s) thus c node
+
oDT G+
xd+1 . induced transition inverting transition taken P<0 (s, x)
case unless inverse may introduce new outside conditions. thus need
exclude case, leading following definition invertibility:
Let = (c, c0 ) transition variable x. say invertible iff exists
transition (c0 , c) DT Gx cond(c0 , c) cond(c, c0 ).
transition invertible go back without introducing new conditions (e.g.,
driving trucks Logistics). subtle differences previous definitions invertible
operators, like authors (Hoffmann, 2005). allow new conditions even

actually established operator rop(t) responsible t. because,
,
necessarily execute executing inverse may got endpoint
via different path oDT G+
x . hand, definition also generous
166

fiAnalyzing Search Topology Without Running Search

common ones because, per se, care side effects inverse
transition may (side effects constrained separately stated Definition 2).
Consider Definition 2 condition (3). Apart constraints conditions induced


transitions, oDT G+
x transitions taken , must also make sure
harmful side effects. Obviously, case if, example Section 3,
transitions side effects all. However, easily generalize condition. Let
= (c, c0 ) transition variable x.
context set ctx(t) facts may deleted side effects t.
(y, d) seff(t), (y, cond(t)(y)) ctx(t) condition defined; else
Dy values 6= inserted.

say irrelevant side effect deletes iff ctx(t) (sG oO preo ) = .

say self-irrelevant side effect deletes iff ctx(t) (sG rop(t)6=oO preo ) =
.
say tShas self-irrelevant deletes iff self-irrelevant side effect deletes
(x, c) 6 sG rop(t)6=oO preo .
Irrelevant side effect deletes capture case side effect delete occurs goal
precondition operator. Self-irrelevant side effect deletes slightly
generous allow delete conditions needed responsible operator
rop(t) itself. Self-irrelevant deletes, finally, extend latter notion also ts delete.
nutshell, need postulate irrelevant side effect deletes transitions may
executed again, path. Examples irrelevant side effect deletes transitions
side effects all, move Simple-TSP, whose side effect, x0 =at,
deletes target locations not-visited. example operator selfirrelevant side effect deletes, irrelevant side effect deletes, departing passenger
Miconic-STRIPS, whose side effect, x0 =served, deletes boarded(passenger)
used purpose departure. fact, transition selfirrelevant deletes effect deletes not-served(passenger) obviously
irrelevant. Another example self-irrelevant deletes inflating spare wheel Tyreworld
wheel longer not-inflated.


Clearly, oDT G+
x transitions may using irrelevant side effect
deletes, then, far invalidating facts needed elsewhere concerned,
good side effects all. understand need require ts
side effect used move another variable x0 V \ {x0 }, recall that, states s0

visited
, construct relaxed plans P + (s0 ) |P + (s0 )| |P + (s)| inverting
transitions t. Now, say ts side effect used move another variable x0 V \ {x0 }.
may invert transitions separately (with different operators), thus
would |P + (s0 )| > |P + (s)|.
Regarding delete t, may important two reasons. First, deleted
fact may needed relaxed plan s0 . Second, x may traverse oDT G+
x several
times, thus may need traverse deleted value later on. covered
invertible, like earlier assumed transitions. Now, invertible?
constitute problem case self-irrelevant deletes: case,
167

fiHoffmann

deletes irrelevant except maybe responsible operator itself. Therefore,
obtain P + (s0 ), simply remove rop(t) relaxed plan constructed
predecessor state s00 . Thus |P + (s0 )| < |P + (s)| reached exit

need continue construction
. example, consider inflates spare wheel
W Tyreworld. deletes not-inflated(W), thus self-irrelevant deletes
(not-inflated(W) irrelevant goal operator). Say
state s00 relaxed plan P + (s00 ) constructed described. |P + (s00 )| |P + (s)|.
also rop(t) =inflate-W P + (s00 ), inflate-W P + (s),
inflate-W executed yet path, hence removed
relaxed plan. Applying inflate-W s00 , get state s0 identical s00 except W
inflated. Clearly, relaxed plan s0 longer needs apply inflate-W,
rest relaxed plan P + (s00 ) still works unchanged. Thus P + (s0 ) obtained
removing inflate-W P + (s00 ), yielding |P + (s0 )| < |P + (s)| desired.
Consider endpoint transition t0 responsible operator o0 . previously
demanded x0 moves sake, i.e., x0 goal value
important achieving goal. unnecessarily restrictive. example,
Miconic-STRIPS, board passenger h+ decreases remove
boarding operator relaxed plan. However, boarding means serving
passenger later on, variable x0 goal. Driverlog, driver may
goal needed drive vehicles, still t0 moving driver results
decreased h+ location moved away actually needed anymore. latter
example immediately leads definition capturing also first one: want
deletes t0 needed rest relaxed plan. remove o0
relaxed plan s0 , reached exit desired.
make precise, recall situation addressing. reached state s0
t0 = (s(x0 ), c) applied, yielding state s1 . relaxed plan P + (s0 )
s0 |P + (s0 )| |P + (s)|, P + (s0 ) constructed P + (s) replacing
+
(s) operators responsible induced oDT G+
operators P<0
x transitions
x V \ {x0 }. construct P1+ removing o0 P + (s0 ), need P1+
relaxed plan s1 . facts possibly needed P1+ ? safe approximation
union sG , precondition o0 6= P + (s), oDT G+
x values needed
7 Denote set R+ . values potentially deleted
induced oDT G+
transitions.
x
1
t0 contained C0 := {(x0 , s(x0 ))} ctx(t0 ). Thus R1+ C0 =
fine. Simple examples given already. Miconic-STRIPS,
delete o0 boarding passenger P not-boarded(P), contained
operator precondition goal thus intersection R1+ C0 = {notboarded(P)} empty. Driverlog, C0 = {at(D,A)} delete o0 moving driver
away location A. location irrelevant rest task,
at(D,A)6 R1+ thus, again, R1+ C0 = .

sharpen further. Consider set facts F0 := oP + (s) eff
<0

+
true relaxed execution P<0
(s). Say p 6 F0 . p needed

7. understand latter two items, note first operators preceding o0 P + (s), i.e., operators
+
P<0
(s), may still contained P1+ thus suffice include preconditions
+
+
operators P>0
(s). oDT G+
x values needed induced oDT Gx transitions, may needed
+
+
P1 P<0
(s).

168

fiAnalyzing Search Topology Without Running Search

P1+ relaxed plan s1 . see this, note first p needed part
+
+
P1+ pertaining P<0
(s). precisely, p cannot operator precondition P<0
(s)
+
condition would satisfied (relaxed) execution P (s). Also, p
cannot start value induced oDT G+
x transition because, definition,
+
values added operators P<0 (s). Now, part P1+ pertaining
+
+
P>0
(s)? Assume p either goal, operator precondition P>0
(s). Then,
+
+
since p 6 F0 P (s) relaxed plan, either o0 operator P>0 (s) must establish
+
p. o0 , effects true s1 anyway. P>0
(s), remains unchanged
+
P1 thus part covered, too. Altogether, thus suffices R1+ C0 F0 = .
example helps Satellite domain. Say o0 switches instrument I.
deletes calibration, i.e., calibrated(I) C0 . purpose switching
take images it, thus calibrated(I) R1+ C0 . However, instrument
may actually calibrated s. so, need switch
calibrated calibration operator requires power
thus calibrated(I) false relaxed execution P + (s), least o0 .
particular, calibrated(I)6 F0 thus R1+ C0 F0 = .
Even condition R1+ C0 F0 = still sharpened. Say exists


+
(s)
o0 guaranteed applicable
(possibly empty) sub-sequence
o0 P>0


+
start P1 , o0 re-achieves facts R1+ C0 F0 (both easy

define test). moving
o0 start P1+ job. say case
+
+
(s)-recoverable Definition 2 condition (2a).
oDG -relevant deletes t0 P>0
example, consider o0 picks ball b Gripper domain. operator deletes
fact p =free-gripper may needed remainder relaxed plan, thus

+
(s) necessarily contain sub-sequence
o0 moves
p R1+ C0 F0 . However, P>0


+
another room puts b again. re-order P1 put o0 right
start, re-achieving p. Similar patterns occur transportation domain capacity
constraints, generally domains renewable resources.
Finally, identified two simple alternative sufficient conditions t0
suitable, Definition 2 conditions (2b) (2c). sake brevity, sketch
here. require s(x0 ), i.e., start value t0 , contained R1+
defined above. say case s(x0 ) oDG+ -relevant. Note that, then,
R1+ C0 = unless t0 side effects. Side effects hurt t0 replaceable side
effect deletes, i.e., operator whose precondition may deleted replaced
alternative operator o0 applicable effect (this happens, e.g.,
Simple-TSP). Another possibility t0 recoverable side effect deletes:
exists operator o0 necessarily applicable directly execution t0 ,
recovers relevant side effect deletes. happens quite frequently, example Rovers
taking rock/soil sample fills store, free store simply
emptying anywhere. replace o0 o0 obtain relaxed plan P1+ s1 (and
thus h+ (s1 ) h+ (s)). apply o0 , yielding state s2 h+ (s2 ) < h+ (s)
obtain relaxed plan s2 removing o0 P1+ .
length exit path be? one move x0 . nonleaf variable x must provide new value every move variable x0
depending it, i.e., (x, x0 ) A. new value reached oDT G+
x
traversal. Denote maximum length traversal, i.e., diameter oDT G+
x,
169

fiHoffmann

8 Now, may diam(oDT G+ ) > diam(DT G ) oDT G+
diam(oDT G+
x
x ).
x
x
removes vertices also arcs. may short-cuts traversed P + (s).
certain circumstances safe take short-cuts, namely if:

(*) oDT G+
x transitions invertible/induced irrelevant side effect deletes
side effects V \ {x0 }, DT Gx transitions either irrelevant,
empty conditions irrelevant side effect deletes.
traversing short-cut condition, soon reach end shortcut, back region states s0 relaxed plan P + (s0 ) constructed
before. rest exit path construction remains unaffected. Thus,
denote V
P
subset V \ {x0 } (*) holds. define costd (oDG+ ) := xV costd (x),
costd (x) :=

1



P
0
diam(oDT G+
x)
x0 :(x,x0 )A cost (x )


min(diam(oDT G+ ), diam(DT G )) P
x

x

x = x0
x 6= x0 , x 6 V
x0 :(x,x0 )A cost

(x0 )

x 6= x0 , x V

Note costd (.) exponential depth graph. artifact
length estimation. easy construct examples exit distance exponential
parameter. because, hinted, variable may move several times
value required variables depending it. See Example 6 Appendix A.4
construction (following earlier construction Domshlak & Dinitz, 2001).
said, course costd (.) may over-estimate length shortest exit path.
assumes that, whenever variable x0 (x, x0 ) makes move, x must move
entire oDT G+ respectively DT G. conservative: (1) may
move x0 actually condition x; (2) even condition exists,
x may need less steps order reach it. One might able ameliorate (1) making
fine-grained distinctions part costd (x0 ) pertains moves conditioned
x. leave open future work. now, note over-estimation
exponential even due (2), i.e., costd (oDG+ ) may exponentially larger
length shortest exit path even if, (x, x0 ) A, moves x0 depend x.
shown simple variant Example 6; discuss Appendix A.4.
Exit paths using short-cuts described way may non-monotone. Example 5
Appendix A.4 contains construction showing this. intuitive understanding,
imagine line l0 , . . . , ln current task, achieve precondition another
operator, move l0 ln . Say locations line need visited,
relaxed plan, e.g. need load unload something locations.
Say shortcut via l0 needs visited. move l0 h+
increases made 1 step costly relaxed plan reach
locations l0 , . . . , ln . reason, costd (oDG+ ) upper bound length
shortest monotone exit path. also shown Example 5, construct
8. precisely, diam(.) diameter graph maximum distance vertex v vertex
v 0 exists path v v 0 .

170

fiAnalyzing Search Topology Without Running Search

situation shortest monotone exit path longer costd (oDG+ ).9 obtain
bound monotone exit paths, simply set V := definition costd .
Definition 2 condition (2a) (2b), exit distance bounded
costd (oDG+ ) 1 costd (oDG+ ) counts last step reducing h+ .
Definition 2 condition (2c), last step need 1 additional operator reduce
h+ , exit distance bounded costd (oDG+ ). Putting pieces together yields
main result section:
Theorem 2. Let (X, sI , sG , O), s, P + (s), oDG+ Definition 1. oDG+ successful, local minimum, ed(s) costd (oDG+ ). Definition 2
condition (2a) (2b), ed(s) costd (oDG+ ) 1.
full proof Appendix A.2. pointed earlier, approximate local analysis
(III) simply feed Theorem 2 relaxed plans returned FFs heuristic function
(Hoffmann & Nebel, 2001a). important note that, way, give
guarantees, i.e., Theorem 2 hold P + (s) optimal, even P + (s)
non-redundant parallel-optimal like computed FF. end exit
path may obtain relaxed plan shorter P + (s) shorter h+ (s).
nutshell, reason parallel-optimal relaxed plan generally, relaxed
plan minimizing number operators may take different decisions
sequentially-optimal relaxed plan, thus constructing exit path leading wrong
direction. Example 8 Appendix A.4 gives full construction proving this.
Feeding Theorem 2 non-optimal relaxed plans course also imprecise
direction, i.e., Theorem 2 may apply although apply optimal
relaxed plan. Thus good cases may go unrecognized. demonstrate simple
modification Example 8, explained example Appendix A.4. Importantly,
point Section 8, empirical results suggest weakness
tend occur practice, least far represented benchmarks.

6. Conservative Approximations
identify sufficient criteria guaranteeing prerequisites Theorem 2 hold
true. consider local case particular state given, global
case criterion implies prerequisites Theorem 2 every state task
hand. approximate optimal rplan dependency graphs follows:
Definition 3. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , let
x0 XsG , let t0 = (s(x0 ), c) relevant transition DT Gx0 o0 := rop(t0 ).
local dependency graph s, x0 , o0 , local dependency graph brief,
graph lDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:
x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x0 V \ {x0 } (x, x0 ) arc SG.
0
global dependency graph x0 o0 , global dependency graph brief,
graph gDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:
x0 = x0 x0 6= x Xpreo ; x0 V \ {x0 } (x, x0 ) arc SG
0

9. remark that, due mentioned sources over-estimation costd , constructing example
requires fairly awkward constructs appear likely occur practice.

171

fiHoffmann

optimal relaxed plan P + (s) contains o0 , oDG+ per Definition 1
sub-graph lDG gDG defined here. simply optimal rplan
dependency graph arcs (x, x0 ) contained support graph task.10
previously indicated, support graph may contain lot arcs actually necessary.
SG captures may ever support else, support else optimal
relaxed plan. Consider earlier point that, constructing oDG+ , take account
operators front o0 P + (s). information contained SG, thus
Gripper get aforementioned cycle dropping ball support free-gripper
picking ball.
reader waded cumbersome details previous section
delighted hear defining lDG respectively gDG successful
involve additional notation:
Definition 4. Let (X, sI , sG , O), s, x0 , t0 , o0 , G = lDG G = gDG
Definition 3. say G = (V, A) successful following hold:
(1) G acyclic.
(2) G = lDG sG (x0 ) 6= s(x0 ), exists transitive successor x0 x0
SG x0 XsG sG (x0 ) 6= s(x0 ).
(3) t0 either:
(a) self-irrelevant side effect deletes;
(b) replaceable side effect deletes;
(c) recoverable side effect deletes.
(4) x V \ {x0 }, DT Gx transitions either irrelevant, self-irrelevant
deletes, invertible irrelevant side effect deletes side effects
V \ {x0 }.
Consider first local dependency graphs G = lDG; discuss G = gDG below.
Assume optimal relaxed plan P + (s) contains o0 , thus oDG+
sub-graph lDG. condition (1) obviously implies Definition 2 condition (1).
Condition (4) implies Definition 2 condition (3) oDT G+
x contain
irrelevant transitions. Condition (2) implies (*) s(x0 ) oDG+ -relevant, i.e., s(x0 )
needed rest relaxed plan. simply un-achieved
goal depends x0 . (*), condition (3a) implies Definition 2 condition (2a),
R1+ C0 = , notation introduced previously. Conditions (3b) Definition 2
condition (2b), respectively (3c) Definition 2 condition (2c), equivalent given (*).
Regarding exit distance, know parts domain transition graphs
variables x V \ {x0 } traversed P + (s). obvious bound diam(oDT G+
x)
length maxPath(DT Gx ) longest non-redundant path graph (a path
visiting vertex once). Unfortunately, cannot compute maxPath(.) efficiently. Hamiltonian path (Garey & Johnson, 1979) exists graph G = (V, A) iff
10. gDG, note preo0 (x0 ), defined, = s(x0 ) thus x0 need recorded
predecessor.

172

fiAnalyzing Search Topology Without Running Search

maxPath(G) = |V | 1. Thus corresponding decision problem NP-hard. TorchLight over-approximates maxPath(G) simply |V | 1. However, sometimes use
diam(DT Gx ) instead maxPath(DT Gx ), namely certain x one
variables V used definition costd (oDG+ ). certain if:
(**) DT Gx transitions either irrelevant, invertible empty
conditions, irrelevant side effect deletes, side effects V \ {x0 }.
Note strictly stronger requirement Definition 4 condition (4). Clearly,
implies Definition 2 condition (3) well condition (*) SectionP5. Denote V
subset V \ {x0 } (**) holds. define costD (G) := xV costD (x),
costD (x) :=

1
x = x0



P

0
maxPath(DT Gx ) x0 :(x,x0 )A cost (x ) x 6= x0 , x 6 V


diam(DT G ) P
costD (x0 )
x 6= x , x V
x

0

x0 :(x,x0 )A

x0 must move attain goal every optimal relaxed plan must take
least one transition leaving s(x0 ). Thus, Theorem 2 above, that:
Theorem 3. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) <
. Say x0 X that, every o0 = rop(s(x0 ), c) DT Gx0 (s(x0 ), c)
relevant, lDGo0 successful local dependency graph. local minimum,
ed(s) maxo0 costD (lDGo0 ). If, every lDGo0 , Definition 4 condition (3a)
(3b), ed(s) maxo0 costD (lDGo0 ) 1.
Theorem 3 tool guaranteed local analysis (II). guaranteed global analysis
(I), simply look set global dependency graphs gDG, requiring
successful. particular, gDG acyclic, difficult deduce
non-goal state variable x0 fulfilling Definition 4 (2). x0 ,
apply Theorem 3 thus get:
Theorem 4. Let (X, sI , sG , O) planning task. Say global dependency graphs
gDG successful. contain local minima and, state
0 < h+ (s) < , ed(s) maxgDG costD (gDG). If, every gDG, Definition 4
condition (3a) (3b), ed(s) maxgDG costD (gDG) 1.
full proofs Theorems 3 4 Appendix A.3. SG acyclic
transitions invertible side effects, Theorem 4 applies, whereby
particular proved basic result. Vice versa, note that, Theorem 4 applies,
SG acyclic. far local minima concerned, one may thus reformulate Theorem 4
simpler terms relying notion successful dependency graphs. Apart
allowing also determine exit distance bound, present formulation already paves
way future research: gDG defined relative concrete variable x0 operator
o0 , may thus allow accurate analysis variables may actually
become important x0 o0 , optimal relaxed plan.
use diam(DT Gx ) instead maxPath(DT Gx ) costD (.), variables
V , rather significant effect quality bounds computed many
173

fiHoffmann

benchmarks. typical example transportation domain vehicle positions leaf
variables SG whose transitions side effects. variables qualify V . Using
maxPath(DT Gx ) instead, would obtain exceedingly large bounds even trivial road
maps. example, consider Logistics road map fully connected.
diam(DT Gx ) = 1 thus costD (.) delivers correct bound 1. Using maxPath(DT Gx )
instead get bound N 1, N total number locations DT Gx .
Note that, within scope Theorem 4, i.e., class planning tasks
Theorem 4 applies, plan existence tractable. Namely, exists plan task iff
exists relaxed plan initial state. because, starting optimal
relaxed plan, guaranteed able construct exit path; iterating argument
gets us goal. view, tractability weakness form global
analysis. analysis apply intractable classes tasks contain
local minima. Note classes exist, cf. Theorem 1. hand, plan
existence tractable known benchmark domains local minima absent,
practice appear major limitation. Also, note plan construction,
well optimal planning, still intractable within scope Theorem 4. Plan
construction intractable plans may exponentially long, cf. Example 6
Appendix A.4. optimal planning, consider Logistics Miconic-STRIPS.
see shortly (Proposition 1, next section) fully covered Theorem 4.
However, them, deciding bounded plan existence NP-hard (Helmert, 2003).
Interestingly, fact Theorem 2, therewith indirectly also Theorem 4, rely
optimal relaxed plans source intractability plan construction here. Theorem 4
applies, non-redundant relaxed plan P + successful oDG+ , enabling us
construct path state particular relaxed plan (although necessarily
optimal relaxed plan) shortened. Iterating argument gives us constructive
method obtaining plan, worst-case exponential behavior lies
length individual path segments. said, course plan constructed
way may highly non-optimal. Indeed, shown Example 7 Appendix A.4,
plan may exponentially longer optimal plan. Thus, even Theorem 4 applies
need optimality guarantee, running planner still makes sense.
discuss relation scope Theorem 4 known tractable classes
Section 9. basic fact one construct local minima even small examples
involving two variables complying basic result except either
support graph cyclic (Example 2, Appendix A.4), non-invertible transition
whose delete relevant (Example 3, Appendix A.4), transition
relevant side effect delete (Example 4, Appendix A.4). examples contained
many known tractable classes, thus underlining automatic analysis h+ topology
identification tractable classes different (although related) enterprises.

7. Benchmark Performance Guarantees
state guarantees analyses (I)(III) give benchmark domains.
underlying finite-domain variable formalizations straightforward, correspond
174

fiAnalyzing Search Topology Without Running Search

formulations found automatically Fast Downward. listed
Appendix A.5, also give proofs following two simple observations.11
four benchmark domains, guaranteed global analysis (I) always succeed :
Proposition 1. Let (X, sI , sG , O) planning task Logistics, Miconic-STRIPS,
Movie, Simple-TSP domain. Theorem 4 applies, bound delivered
1, 3, 1, 1 respectively.
follows trivially Proposition 1 guaranteed local analysis (II) succeeds
domains well. state one four listed domains, Theorem 3
applies s, bound delivered stated.
Note bounds Logistics Movie correct ones, i.e., tight.
Miconic-STRIPS, over-estimation actual bound (which 1, 3) arises
analysis realize boarding passenger used leaf
variable x0 . Simple-TSP, correct bound 0 (since h+ exact goal distance).
over-estimation arises because, every goal variable x0 =visited(location), gDG
includes also variable at, realizing value matter
location visited one.
transportation benchmarks involving capacity constraints, approximate local
analysis (III) always succeed, provided suitable optimal relaxed plans:
Proposition 2. Let (X, sI , sG , O) planning task Elevators, Ferry, Gripper,
Transport domain, let S. Ferry Gripper, every optimal relaxed plan
P + (s) exists oDG+ Theorem 2 applies, bound 1. Elevators
Transport, exists least one P + (s) oDG+ Theorem 2 applies,
bound 1 Elevators road map diameter Transport.
relevant deletes t0 , cases, due effects decreasing remaining vehicle capacity, like free-gripper Gripper domain. decrease capacity
always due load type operator, matched unload type operator
later inside relaxed plan. Thus deletes always recovered inside P + (s) (we
Definition 2 condition (2a)). Further, relaxed plans never use unload action
free capacity loading object, thus oDG+ cycle-free. Hence
oDG+ successful, Theorem 2 applies. Elevators Transport, Proposition 2
slightly weaker vehicle may capacity > 1, allowing forcing
relaxed plans use unloading operators recovering capacity actually present.
note similar patterns likely occur domain renewable resources,
recognized Definition 2 condition (2a) way.
Proposition 2 hold Theorems 3 4, i.e., lDGs gDGs. due
two deficiencies (cf. discussion end Section 4). First, SG contains cycles
unloading object order free capacity loading it. Second, Definition 2
condition (3a) restrictive Definition 2 condition (2a), postulating deletes
t0 entirely irrelevant. way removing deficiencies,
guaranteed analyses (I,II) would succeed four domains Proposition 2.
11. say found automatically Fast Downwards translator deterministic, i.e.,
may return different finite-domain variable encodings even run several times planning
task. encodings correspond domain formalizations. Elevators,
give full definition because, without action costs, merely variant Transport.

175

fiHoffmann

8. Experiments
report large-scale experiment TorchLight. fill details TorchLights implementation, describe simple alternative analysis technique based
search probing. explain experiments set-up, report runtime results different
stages TorchLight, describe TorchLights analysis results per-domain basis.
assess quality analysis terms predictive capability. finally summarize
outcome TorchLights diagnosis facility benchmarks.
8.1 TorchLight
TorchLight implemented C based FF.12 TorchLight currently handles STRIPS only,
i.e., ADL domains. uses Fast Downwards translator (Helmert, 2009) find finitedomain variables. Establishing correspondence variables (respectively
values) FFs internally used ground facts mostly straightforward.
details take care of; omit brevity.
parsing Fast Downwards variables, TorchLight creates data structures representing support graph domain transition graphs. enters phase refer
static analysis, determines fixed properties as, every transition t,
whether irrelevant, invertible, etc. next step guaranteed global analysis (I),
checking preconditions Theorem 4 enumerating global dependency graphs
testing whether successful. able report percentage successful gDGs,
stop first unsuccessful one.
local analysis techniques guaranteed local analysis (II) using Theorem 3
approximate local analysis (III) using Theorem 2 run set LS states comprising
initial state well number R sample states obtained random walks starting
sI . set LS identical analyses, run technique state
LS regardless outcome running respective technique is.
Given s, analysis (II) checks Theorem 3 constructing local dependency graph
every suitable variable x0 every transition t0 leaving s(x0 ). find non-successful
t0 , stop considering x0 . minimize exit distance bounds across different x0 .
Analysis (III) checks Theorem 2 relaxed plan P + (s) computed FFs heuristic
function. case relaxed plan exists s, analysis reports failure. Otherwise,
analysis proceeds operators o0 P + (s), start end, variables
x0 affected o0 . pair o0 , x0 build optimal rplan dependency graph oDG+
per Definition 1. skip variables x0 eff o0 (x0 ) actually used precondition
goal, rest P + (s). oDG+ successful, stop. (Relaxed plans big
large examples, continuing analysis exit bound minimization sometimes
costly.) mentioned Section 5, build oDG+ re-order P + (s) moving
operators behind o0 possible. paramount importance avoids including
unnecessary variables oDG+ . re-ordering process straightforward. starts
direct predecessor o0 , tests whether P + (s) still relaxed plan moving
directly behind o0 . yes, arrangement kept. iterate predecessor
o, forth. easy see that, way, oDG+ contain exactly variables
12. source code TorchLight online appendix paper. available download also
http://www.loria.fr/~hoffmanj/TorchLight.zip.

176

fiAnalyzing Search Topology Without Running Search

transitions used P + (s) achieve preo0 . Finally, check whether oDG+ +
relevant deletes t0 P>0
(s)-recoverable, use simple technique allowing recognize
situations failure due one operator avoided replacing alternative
operator. example, Transport o0 loading operator reducing capacity level k
k 1, P + (s) may still contain unloading operator relying level k. Thus level k
contained R1+ C0 , causing failure. However, unloading well
performed based capacity level k 1, removing difficulty. catch cases like
construction R1+ . Whenever find whose precondition overlaps C0 , test
whether replace similar operator.
local analyses return simple statistics, namely minimum, mean, maximal
exit distance bound found, well success rate, i.e., fraction sample states
guaranteed local analysis (II)/approximate local analysis (III) succeeded. Analysis
(III) success rates main focus, turn informative.
run R = 1, 10, 100, 1000 experiment. length random walk
chosen uniformly 0 5 hFF (sI ), i.e., 5 times FF heuristic value
initial state. play parameter 5. important, however,
parameter chosen small. domains many dead ends one may
things fatally wrong likely bad things happen
sufficiently large number random choices. Consequently, dead-end rate, i.e.,
fraction sample states relaxed plan exists, tends larger longer
random walks. Since analysis (III) fails states relaxed plan, exerts
important influence analysis (III) success rates. illustrate comparing
results sampled states results obtained using initial states only.
8.2 Search Probing
approximate analysis sample states, exists simple (and rather obvious) alternative TorchLights causal graph based technology. One use search determine
whether given sample state local minimum, exit distance is. Since
cannot compute h+ effectively, search-based analysis necessarily approximate.
straightforward method replace h+ relaxed-plan based approximation.
Herein, replace h+ hFF , i.e., FFs heuristic function. Precisely, given state
s, run single iteration FFs Enforced Hill-Climbing, i.e., breadth-first search
state better heuristic value. search, like FF does, use helpful actions
pruning avoid huge search spaces. Unlike FF, focus detection states
local minima, allow monotone paths (thus restricting search space states s0
hFF (s0 ) = hFF (s)). refer technique search probing, SP brief. also
experiment variant imposing 1 second runtime cut-off search. refer
limited search probing, SP1s brief. SP SP1s run set LS
states TorchLights local analyses (II,III).
turns out, empirically present benchmarks SP SP1s competitive TorchLights analysis (III). Since analysis main focus experiments,
relevant understand commonalities differences techniques.
far analysis quality guarantees concerned, 3 techniques analysis (III),
SP, SP1s similar properties: guarantees whatsoever. may report
177

fiHoffmann

success although local minimum (false positives), may fail although
local minimum (false negatives). cases, false positives due use
non-optimal relaxed plans (hFF instead h+ ). False negatives inherent analysis (III)
covers certain special cases; inherent SP1s due search
limit. SP false negatives due helpful actions pruning, however could
principle turned off; fundamental source false negatives non-optimal
relaxed plans. also responsible lack connections across techniques.
implication trivial one SP1s success state implies SP success
s. particular, analysis (III) correctly identifies local minimum,
imply SP well. causal graph analysis may less affected
irregularities hFF surface. happens, example, Transport domain
IPC 2008, resulting higher success rates analysis (III).
obvious important differences regarding runtime performance
danger false negatives. SP runtime worst-case exponential size
(grounded) input, whereas analysis (III) SP1s runtime low-order polynomial
size. SP, decreasing number R sample states merely reduces chance hitting
bad state (a sample state large flat region), whereas analysis (III) SP1s scale
linearly R. hand, analysis (III) SP1s buy efficiency
incompleteness, i.e., increased danger false negatives. Analysis (III) simply recognizes
special cases. SP1s effectively bounds lookahead depth, i.e., search depth
exit states detected.
indicated, SP SP1s turn competitive benchmarks. Large search
spaces rare SP. success rates SP SP1s similar, far predictive
capability concerned similarly informative analysis (III). Thus goodquality success rates obtained much simpler techniques TorchLight.13
notwithstanding, (a) TorchLight functions guaranteed analyses (I,II)
well diagnosis cannot simulated, (b) results benchmarks ever
pertain examples. TorchLights analysis (III) offers unlimited lookahead depth
low-order polynomial cost. appear matter much present benchmarks,
natural cases matter. get back below.
8.3 Experiments Set-Up
run experiments set 37 domains. include domains investigated
hand-made analysis h+ topology (Hoffmann, 2005), shown Figure 1,
include domains international planning competitions (IPC) IPC 2004.
remaining domains STRIPS (versions the) domains IPC 2006 IPC
2008, except IPC 2008 Cyber-Security omit due parsing difficulties.14 test
instances collected IPC collection(s) applicable (removing action cost
constructs IPC 2008 domains), randomly generated elsewhere. total,
test set contains 1160 instances.
13. particular, search probing appears rather useful technique, raising question
techniques yet used performance prediction purposes. Roberts Howe (2009),
example, use simple features only. get back conclusion.
14. instances large FFs parser standard configuration. tweaking bison allow
larger parse trees, obtained segmentation fault even smallest instance IPC 2008.

178

fiAnalyzing Search Topology Without Running Search

tool/phase
FD Translator
SG/DTG
Static Analysis
Analysis (I)
Sample States
Analysis (II)
Analysis (III)
TorchLight total
TorchLight (III)
TorchLight (III) FD
SP
SP total
SP1s
SP1s total
FF
LAMA

single-shot/R = 1
mean
max
6.12
690.59
0.14
6.91
0.25
31.42
0.40
53.29
0.01
0.53
0.00
0.18
0.02
1.31
6.92
727.63
6.52
724.54
0.40
33.95
0.06
58.02
0.07
58.03
0.01
1.08
0.01
1.48
268.20

185.05


R = 10
mean
max

0.08
0.01
0.03
7.04
6.64
0.49
0.23
0.32
0.07
0.15

4.81
1.11
2.46
736.98
732.98
40.50
138.54
138.59
4.46
9.27

R = 100
mean
max

0.76
0.10
0.23
8.00
7.51
1.37
5.47
6.23
0.66
1.42

50.35
9.56
20.09
807.70
795.16
103.67


56.18
106.53

R = 1000
mean
max

7.50
0.98
2.15
17.57
16.19
10.04
26.24
33.74
5.89
13.39

491.20
94.59
194.79
1510.74
1413.23
719.27


391.59
882.79

Table 2: Summary runtime data. Mean/max instances domains.
empty fields, respective tool/phase single-shot, i.e., depend R.
dash means time-out, 1800 seconds, inserted runtime respective instance mean computation. Rows FD Translator . . . Analysis
(III) time different stages TorchLight. TorchLight total overall runtime, TorchLight (III) run analyses (II) (III), TorchLight (III)
FD latter disregarding translation costs. SP determines success rate (fraction sample states deemed local minima) via search
probing, i.e., search around sample state; SP1s imposes 1 second time-out
searches. SP total SP1s total include time generating
sample states.
experiments run 1.8 GHZ CPU, 30 minute runtime 2 GB
memory cut-off. run 4 different planners/tools. Apart TorchLight (and SP/SP1s ),
include FF (Hoffmann & Nebel, 2001a), LAMA (Richter et al., 2008; Richter
& Westphal, 2010). purpose running planners assess extent
TorchLights output particular analysis (III) success rate predict planner success
failure. examine also plain planner, also run version FF uses
goal ordering techniques, runs Enforced Hill-Climbing, without resorting
best-first search fails. refer planner EHC follows.
8.4 Runtime
code currently optimized much readability speed. Still, TorchLight
fast. R = 100, bottleneck Fast Downwards translator. R = 1, 10, 100,
actual analysis takes much time translator 99.74%, 99.74%,
96.21% instances respectively. assess detail, consider Table 2
gives timing different stages TorchLight, planners/tools.
translation runtime sometimes hurts considerably, peak 690.59 seconds
costly instance Scanalyzer domain. rather exceptional, however.
second costly domain Blocksworld-NoArm, peak 138.33 seconds.
179

fiHoffmann

20 37 domains, costly instance translated less 10 seconds.
57.24% instances, Fast Downwards translator takes 1 second.
static analysis, peak behavior 31.42 seconds (also Scanalyzer) even
exceptional: 95.34% instances, static analysis takes 1 second. second
highest domain peak 7.88 seconds Pipesworld-Tankage. Similarly, analysis (I)
takes peak 53.29 seconds Blocksworld-NoArm 96.12% instances
completes 1 second. domain Blocksworld-NoArm
peak instance takes 10 seconds Airport, peak 41.71 seconds; next
highest domain peaks Pipesworld-Tankage (6.8), Scanalyzer (2.91), Logistics (1.89),
Woodworking (1.17). domains, analysis (I) always completes within second.
Turning focus local analyses, see even effective. particular, concentrate mostly approximate local analysis (III). see
R = 1000 offer advantages R 100 far information obtained
goes, mostly concentrate R 100. R = 1, 10, 100, analysis (III) completes 1 second 99.66%, 99.40%, 95.60% instances respectively.
R = 1000 still holds 76.55% instances. peak runtime 20.09 seconds
R = 100 occurs Scanalyzer. next highest domain peaks Blocksworld-NoArm
(9.23), Pipesworld-Tankage (4.24), Ferry(3.21), Logistics (2.99), Blocksworld-Arm (2.77),
Optical-Telegraph (1.97), Airport (1.41). 29 domains, analysis (III)
R = 100 always completes within second.
bottleneck local analysis generation sample states. costly
involves repeated computation applicable operators random
walks. R 100 peak 50.35 seconds Scanalyzer domain. However,
again, peak behavior exceptional. R = 1, 10, 100, sampling completes
within 1 second 100%, 98.28%, 87.41% instances respectively.
main competitor TorchLight analysis (III) success rates search probing, i.e.,
SP SP1s . Consider moment analysis methods themselves, i.e., row
Analysis (III) vs. rows SP SP1s Table 2. Compared SP1s , analysis (III)
consistently advantage (except maximum runtime R = 1), difference
dramatic. expected, given SP1s trades completeness small
fixed maximum runtime. Compared complete search SP, analysis (III) consistently
significant advantage. However, R 10 mean runtime SP tolerable,
even maximum runtime bad. Further, bad runtime behavior exceptional.
R = 1, 10, SP completes 1 second 99.83% 98.45% instances
respectively. 35 (R = 1) respectively 32 (R = 10) 37 domains even maximum
runtime 1 second. R = 100, SP two time-outs, Blocksworld-Arm.
R = 1000, 11 time-outs, Blocksworld-Arm, Blocksworld-NoArm, Freecell,
Pipesworld-NoTankage. R = 100, maximum runtime 10 seconds
7 domains; R = 1000, 12. However, R = 100, 1000, SP still completes
1 second 92.33% 71.98% instances respectively (compared 95.60%
76.55% analysis (III), cf. above).
Neither analysis (III) search probing stand-alone methods. former requires
TorchLight except analyses (I,II). latter requires sampling random states.
respective total data given rows TorchLight (III) SP total/ SP1s total
Table 2. picture changes dramatically favor SP especially SP1s .
180

fiAnalyzing Search Topology Without Running Search

noted, though, mostly due overhead translation finite-domain
variables. overhead artifact implementation. approach defined
finite-domain variables, benchmarks not, even though finite-domain
representation cases natural Boolean one. Further, many planners
(notably Fast Downward quickly growing set derivatives) use translation
anyway. runtimes without translation given row TorchLight (III) FD.
one would hope expect, analysis methods much faster actual planners. LAMA 112 time-outs test suite, FF 173.
8.5 Analyzing Domains
discuss actual analysis outcomes, per-domain basis. first consider
TorchLight, give details comparison analysis (III) success rates
obtained search probing. begin, words order regarding
comparison SP SP1s . R = 1, 10, 100, 1000, success rates identical
99.83%, 99.14%, 97.5%, 94.66% 1160 benchmark instances respectively; 99.83%,
99.14%, 99.31%, 98.97% instances, success rates differ 5%. Thus,
small runtime cut-off adversely affect success rates search probing (because
long searches rare). so, henceforth discuss data SP vs.
SP1s separately. compare TorchLights analysis (III) success rates SP only.
guarantees Proposition 1 confirmed, i.e., guaranteed global analysis (I) succeeds described Logistics, Miconic-STRIPS, Movie, Simple-TSP. never succeeds
domain, though. domains, fractions gDGs successful. Precisely, maximum fraction successful gDGs 97% Satellite, 50% Ferry, 33.33%
TPP, 22.22% Driverlog, 20% Depots, 13.33% Tyreworld, 12.5% BlocksworldArm. However, fraction 100% nothing proved, data may
best used give indication aspects domain good-natured.
Guaranteed local analysis (II) generally much applicable global analysis.
Thus concentrate approximate local analysis (III) exclusively.
Proposition 2 backed impressively. Even R = 1000, analysis (III) succeeds
every single sample state Ferry, Gripper, Elevators, Transport.15 indicates
strongly potentially sub-optimal relaxed plans result loss information
here. Indeed, analysis yields high success rates almost domains local minima
non-present limited. case domains, thus TorchLight
distinguish domains easy h+ topology hard ones. Consider Figure 3,
showing mean analysis (III) success rates per-domain R = 1. (The picture similar
R = 10, 100, 1000; cf. Table 3 below.)
domains whose h+ topology known shown separately right hand
side Figure 3. domains, see quite nicely harder domains tend
lower success rates. particular, easiest domains bottom class
100% success rates (95% case Zenotravel), whereas hardest domains
top right corner around 50% less. latter domains, extent
15. Historically, observation preceded Proposition 2, well h+ topology categorization Elevators Transport per Figure 1. is, hand-made analyses motivated observing
TorchLights analysis outcome.

181

fiHoffmann

PipesTank [40]
PipesNoTank [76]
PSR [50]

Rovers [100]
OptTele [7]

Mystery [39]
Mprime [49]
Freecell [55]
Airport [0]

Hanoi [0]
BlocksNoArm [57]
Grid [80]
Transport [+,100]
bench ed <= c

local minima ed <= c

BlocksArm [30]
Depots [82]
Driverlog [100]

Elevators [+,100]
Logistics [*,100]
Ferry [+,100]
Gripper [+,100]
undirected

Woodwork [13]
Trucks [0]
TPP [80]
Storage [93]
Sokoban [13]
Scanalyzer [30]

Tyreworld [100]
DinPhil [24]
Satellite [100]
Zenotravel [95]
MiconicSTR [*,100]
Movie [*,100]
SimpleTsp [*,100]
harmless

recognized

PegSol [0]
Pathways [10]
ParcPrinter [3]
Openstacks [0]
unrecognized

Figure 3: Overview TorchLight domain analysis results. *: guaranteed global analysis
(I) always succeeds. +: approximate local analysis (III) always succeeds
provided optimal relaxed plan. Numbers shown mean success rates per
domain, approximate local analysis (III) R = 1, i.e., sampling
single state per domain instance.
low success rates result recognition dead ends FFs heuristic function.
example, random sampling make random vehicle moves consuming fuel, like
Mystery Mprime, course chances end state fuel
scarce even relaxed plan exist anymore. pronounced
Airport, sample states infinite heuristic values. However, capabilities
analysis go far beyond counting states recognized dead ends. Blocksworld-Arm,
example, dead ends still success rate 30%, clearly
indicating domain difficult topology.
extent, based success rates even distinguish Pipesworld-Tankage
Pipesworld-NoTankage, Mprime Mystery (in Mprime, fuel transferred
locations). relatively high success rate Depots probably relates transportation aspects. Grid, 20% cases analysis strong enough recognize
reasons behind non-existence local minima; reasons quite complicated
(Hoffmann, 2003). Dining-Philosophers really favorable h+ topology.
rather excessive bound 31 due particular domain structure philosophers
behave strictly symmetrical ways (Hoffmann, 2005). Apart this, strong
outliers Driverlog, Rovers, Hanoi, Blocksworld-NoArm. problems hand-made analysis TorchLights. Driverlog Rovers, deep local
minima exist, awkward situations dont tend arise IPC instances. Thus hand-made analysis, worst-case nature, pessimistic
here. opposite happens Hanoi Blocksworld-NoArm, absence local
minima due rather idiosyncratic reasons. example, Hanoi reason h+
always equal number discs yet goal position relaxation, one
always accomplish remaining goals one-by-one, regardless constraints entailed
positioning. Hanoi Blocksworld-NoArm actually easy solve
182

fiAnalyzing Search Topology Without Running Search

domain
Airport
Blocks-Arm
Blocks-NoArm
Depots
Din-Phil
Driverlog
Elevators
Ferry
Freecell
Grid
Gripper
Hanoi
Logistics
Miconic
Movie
Mprime
Mystery
Opt-Tele
Pipes-NoTank
Pipes-Tank
PSR
Rovers
Satellite
Simple-TSP
Transport
Tyreworld
Zenotravel
Openstacks
Parc-Printer
Pathways
Peg-Sol
Scanalyzer
Sokoban
Storage
TPP
Trucks
Woodworking

sI
(III)
96.0
38.3
70.0
100
100
100
100
100
97.5
60.0
100
0.0
100
100
100
74.3
75.0
0
40.0
34.0
66.0
100
85
100
100
100
90
100
100
100
0
0
30.0
100
100
56.3
100

R=1
(III)
SP
0.0
0.0
30.0 93.3
56.7
100
81.8
100
24.1 27.6
100
100
100
100
100
100
55.0 60.0
80.0
100
100
100
0.0 33.3
100
100
100
100
100
100
48.6 74.3
39.3 42.9
7.1 14.3
76.0 98.0
40.0 92.0
50.0 62.0
100
100
100
100
100
100
100 93.3
100
100
95
100
0
4.4
3.3
6.7
10.0 10.0
0
10
30.0 96.7
13.3 33.3
93.3 96.7
80.0 80.0
0
0
13.3 13.3

R = 10
(III)
SP
2.0
2.0
28.2 94.5
57.2
100
85.9 99.1
22.8 23.1
97.5
100
100
100
100
100
57.4 62.8
74.0 92.0
100
100
11.1 44.4
100
100
100
100
100
100
61.1 76.3
37.1 43.9
1.4
2.9
75.4 97.4
50.6 90.0
57.6 69.8
100 99.5
98.5
100
100
100
100 93.0
95.6
100
94.5 99.5
14.8 21.3
8.0
8.3
6.0
6.0
13.3 22.7
33.0 99.7
20.3 38.3
89.0 96.3
68.0 67.0
2.5
3.1
14.3 14.3

R = 100
(III)
SP
2.8
2.9
26.9 91.7
55.9 99.9
86.3 99.7
22.8 22.9
97.4 99.9
100
100
100
100
57.9 63.5
69.0 93.8
100
100
10.2 41.9
100
100
100
100
100
100
64.3 79.0
37.6 45.6
0.9
1.4
75.2 97.4
49.4 88.1
58.3 71.1
100 99.8
98.4
100
100
100
100 94.8
96.3
100
95.8 98.4
17.7 22.0
6.3
7.2
5.4
5.4
13.1 22.3
33.5 97.9
19.1 38.2
89.8 96.8
65.4 63.8
1.9
2.9
15.3 15.4

(III)
2.9
26.5
56.2
86.2
22.0
97.9
100
100
58.0
69.5
100
10.6
100
100
100
64.1
36.3
1.1
75.1
48.7
57.0
100
98.0
100
100
95.5
95.4
16.6
6.0
4.6
12.6
33.9
18.5
89.3
65.5
1.4
15.3

R = 1000
SP
3.0
82.1
98.3
99.6
22.3
99.8
100
100
63.2
93.5
100
41.9
100
100
100
78.2
44.4
1.7
95.4
88.2
70.4
99.8
99.8
100
94.4
100
98.2
20.8
6.8
4.6
22.2
98.5
37.7
96.9
63.9
2.7
15.4

DE
97.0
0
0
0
77.2
0
0
0
35.4
0
0
0
0
0
0
7.2
46.8
98.3
0
8.7
0
0
0
0
0
0
0
79.1
93.0
95.3
75.2
0
54.2
0
34.5
97.3
84.6

Table 3: Mean success rates per domain. Upper part: domains whose h+ topology previously examined hand (Hoffmann, 2005) trivial examine based
results; lower part: IPC 2006/2008 domains case. Columns
sI show data analyzing initial state only, columns R = 1, 10, 100, 1000
analyzing respective number sample states. Columns (III) give data
approximate local analysis (III), columns SP give data search probing,
column DE gives dead-end rates R = 1000.
FF, sense, practical perspective, low success rates TorchLights
analysis (III) provide accurate picture.
Table 3 gives complete account per-domain averaged success rates data, including
domains, values R, rates obtained initial states, using SP instead
TorchLight. serves answer three questions:
(1) important sample random states, rather analyzing initial state?
(2) important sample many random states?
183

fiHoffmann

(3) competitive analysis (III) respect search-based analysis?
answer question (1) clear yes. importantly, pertains domains
dead ends, cf. brief discussion above. clear Table 3 that, domains,
analyzing sI results tendency optimistic. see this, consider entries
Airport, Dining-Philosophers, Freecell, Mystery, Openstacks, Parc-Printer, Pathways,
TPP, Trucks, Woodworking. domains dead ends, variety reasons.
dead ends occur frequently initial state level, occur frequently
random walks cf. column DE Table 3. (Interestingly, domains notably
two Pipesworlds opposite happens, i.e., success rates lower sI
sample states. clear us causes phenomenon.)
simply compare sI column R = 1000 column analysis (III),
find result lot different 10% 22 37 domains.
extent, difference initial states sample states may due
way benchmarks designed. Often, initial states every instance similar
certain ways (no package loaded yet, etc). hand, seems quite natural,
least offline problems, initial state different states deeper
state space (consider transportation problems card games, example).
answer question (2) clear no. example, compare R = 1
R = 1000 columns analysis (III). difference greater 10% 6
37 domains. peak difference Openstacks, 16.6% R = 1000 vs. 0%
R = 1. average difference domains 4.17%. Similarly, comparing R = 1
R = 1000 columns SP results 5 37 domains difference greater
10%, peak Openstacks, 20.8% R = 1000 vs. 4.4% R = 1.
average difference domains 3.7%.
answer question (3) bit complicated. Look columns analysis
(III) respectively SP R = 1000. number domains difference larger
10% 11 37, peak 64.6% difference Scanalyzer. one
hand, still means 26 37 domains analysis result get close
search (average difference 2.18%), without actually running search!
hand, happens 11 domains? these, success rate SP
higher TorchLight. surprising basically means TorchLights
analysis strong enough recognize states local minima.
Interestingly, weakness turn unexpected advantage. 11 domains
question, 8 domains Blocksworld-Arm, Depots, Mprime, Pipesworld-Tankage, PipesworldNoTankage, PSR, Scanalyzer, Sokoban contain deep local minima.16 Thus,
8 domains, would wish analysis return small success rates. TorchLight grants
wish much SP does. Consider happens using SP instead analysis
(III) Figure 3. Mystery, PSR, Sokoban, change dramatic. However,
Blocksworld-Arm marked average success rate 93 instead 30, putting almost
par very-simple-topology domains bottom class. Similarly, PipesworldTankage, Pipesworld-NoTankage, Scanalyzer put almost par these. Depots
16. Sokoban unrecognized dead-ends (in relaxation, blocks pushed across other)
therefore local minima. Scanalyzer, analyzing plants misplaces side effect, bringing
back start position, across large circle conveyor belts, may take arbitrarily many steps.
See Figure 3 6 domains.

184

fiAnalyzing Search Topology Without Running Search

actually receives 100, putting exactly par them. Thus SP analysis outcome
actually looks quite bit worse, 5 domains.
causes undesirably high success rates SP? authors best guess that,
many domains, chance randomly finding state local minimum low.
large-scale experiments measuring statistics search space surface FFs heuristic
function (Hoffmann, 2003), observed many sampled states local minima
themselves, contained valleys. Within valley, monotonically
decreasing path goal state. state may local minimum because,
because, one descend deeper valley. seems SP correctly identifies
valley states local minima, thus counting good many states actually
located difficult regions search space. weakness SP, success
rate search space feature.17 weakness manifest much
analysis (III)? analysis picky takes good states
qualify particular special cases. tend occur often difficult domains.
course, easy construct examples turning discussed strength real
weakness TorchLights analysis quality. seem happen lot
present benchmarks. Now, said that, present benchmarks arent well suited
bring theoretical advantage analysis (III) either. analysis offers unlimited
lookahead depth low-order polynomial cost. However, even R = 1000, 23 37
domains highest exit distance bound returned 0, i.e., every exit path identified consists
single operator. cases could handled much simpler variant analysis
(III), looking operators o0 directly applicable s, thus removing
entire machinery pertaining SG predecessors x0 . Still, machinery matter
cases quite natural. highest exit distance bound returned 10 Grid 7
Transport. generally, transportation domain non-trivial road-map,
easy construct relevant situations. example, say road map Transport forms N
cities, diameter least one vehicle, distances cities large
relative D. Then, typical state, around N vehicle moves considered helpful
FF: least 1 per city since local vehicles preferred relaxed plan.
successor states identical h+ package loaded/unloaded. typical
number steps required grow D. If, example, vehicle
outskirts packages city center, around D/2 steps required,
finding exit takes runtime around N D/2 . small values N already
render search probing either devoid information (if runtime cut-off small),
computationally infeasible (recall probing quick pre-process
actual planning). contrast, analysis (III) easily delivers correct success rate 100%.
8.6 Predicting Planner Performance
direct measure predictive quality success rates, conducted preliminary
experiments examining behavior primitive classifiers, runtime distributions
large vs. small success rates. consider first classifiers. predict, given
planning task, whether EHC/FF/LAMA succeed solving task, within given
17. Note cannot use valley rate instead, cheap domain analysis, since determining whether
lies valley implies finding plan thus solving task side effect.

185

fiHoffmann

time memory limits. classifiers answer yes iff success rate threshold
0, 10, . . . , 100. Obviously, this, need R > 1. consider follows
R = 10 R = 100 because, shown above, R = 1000 costly.
EHC, TorchLight analysis (III) SP deliver fairly good-quality predictions,
considering actual machine learning involved. prediction quality TorchLight good sometimes slightly better search. Whether use
R = 10 R = 100 make big difference. EHC solves 60.69% instances,
rate correct predictions trivial baseline classifier always answering yes.
R = 10, best rate correct predictions 71.90% TorchLight (with = 80)
70.17% SP (with = 90). R = 100, numbers 71.76% (T = 60)
71.16% (T = 100). Dead-end rate bad predictor. best prediction
baseline classifier = 0, second best classifier (T = 100) 36.79% correct.
Interestingly, major differences different sets domains.
domains previously analyzed hand (Hoffmann, 2005; Figure 1 without Elevators
Transport), best prediction 75.75% correct TorchLight = 70,
74.07% correct SP = 100, vs. baseline 63.81%. IPC 2006 domains,
numbers 57.98% 61.34% vs. baseline 55.46%, = 10 cases, i.e.,
best classifier close baseline. IPC 2008, hand, appears
exceptionally good-natured, numbers 79.52% (T = 60) 82.38% (T = 80) vs.
baseline 51.90%. clear us causes phenomena.18
summary, quality prediction always clearly baseline, around 10%
looking domains, even 30% looking IPC 2008 domains
only. comparison, using state-of-the-art classification techniques simple features, Roberts Howe (2009) get 69.47% correctness vs. baseline 74% (for saying no),
unseen testing domains FF. said that, setting considered
learning, actually distinguish learning data
testing data. Roberts Howes unseen testing domains IPC 2006 (in
different setting including also ADL test suites). set
domains 2006 (Figure 1 without Elevators Transport), get
best prediction = 70 TorchLight = 100 SP. setting ,
prediction correctness IPC 2006 suite 29.41% respectively 51.26% only, vs.
baseline 55.46%. hand, seems pertain IPC 2006 specifically.
IPC 2008, = 70 respectively = 100 good settings, giving 76.67% respectively
76.19% correctness vs. baseline 51.90%.
Importantly, Roberts Howe predicting performance EHC
FF, complex algorithm. FF LAMA, prediction quality
TorchLight SP rather bleak, using described primitive classifiers. cases,
best prediction correctness obtained always answering yes. best
said success rate still predicts much better dead-end rate. give
example data, R = 10 across domains FF, baseline 85.09% correct.
= 10, goes 77.50% TorchLight, 79.31% SP, 34.57% dead-end
rate. LAMA, baseline 90.26% correct, = 10 goes 81.81%
18. bad prediction quality IPC 2006 domains might related fact fully grounded,
potentially impeding ability Fast Downwards translator find useful finite-domain variables.

186

fiAnalyzing Search Topology Without Running Search

TorchLight, 83.97% SP, 29.91% dead-end rate. FF LAMA,
growing prediction quality decreases monotonically cases.
prediction quality much worse FF EHC,
main building block FF? Whereas EHC typically fails tasks whose h+ topology
favorable, FFs LAMAs complete search algorithms able solve many
cases, too. example, TorchLight success rates R = 10, EHC solves
34.07% tasks success rate 0, solves less 50% success rate 70%.
contrast, FF LAMA solve 74.18% respectively 76.92% tasks success rate
0, solve least 70% success rates.
Despite this, success rates far devoid information FF LAMA. Setting
threshold 10, . . . , 100, look distribution planner runtime instance
subset (A) success rate < , vs. instance subset (B) success rate .
Taking null hypothesis means two runtime distributions
same, run Students T-test unequal sample sizes determine confidence
null hypothesis rejected. is, determine confidence
distribution (B) lower mean distribution (A). Using TorchLights success rate
FF runtimes, R = 10 R = 100, 10 settings , get confidence
least 99.9%. difference means data, i.e., mean runtime
(A) minus mean runtime (B), tends grow . peaks 336 respectively 361
seconds R = 10 respectively R = 100; average difference values 239
respectively 240. Likewise, LAMA runtimes settings R yield confidence
99.9%, average differences 242 respectively 235. results SP comparable
LAMA. slightly worse FF, though. R = 10 confidence 99.9%
= 10, 20; confidence 95% values . difference peaks 241
seconds (vs. 336 TorchLight), average 150 seconds (vs. 239). R = 100,
thresholds = 30, 40, 50, 100 yield 99.9% confidence, average difference 160.
perhaps little surprisingly, simpler planner EHC runtime distributions behave differently. TorchLight success rates, get several cases
confidence < 95%, average differences around 80 seconds. SP, cases
get 99.9% confidence mean (B) larger (A). Again, reason
simple. many tasks unfavorable h+ topology, enforced hill-climbing quickly exhausts space states reachable FFs helpful actions. EHC gives solving
task, although consumed little runtime peculiar behavior one would
certainly expect planner trying competitive.
Summing up, success rates planning task feature provide good coverage
predictor EHC even without significant learning. FF LAMA, things
easy, however consideration runtime distributions clearly shows
feature highly informative. Exploiting informativeness predicting planner performance presumably requires combination features, actual machine learning
techniques, along lines Roberts Howe (2009). topic future research.
8.7 Diagnosis
Let us finally consider TorchLights diagnosis facility. idea behind facility
summarize reasons analysis failure. Testing sufficient criteria absence local
187

fiHoffmann

minima, diagnosis guaranteed identify domain features causing presence.
Still, least analysis using Theorem 2, diagnosis quite accurate.
current diagnosis facility merely first-shot implementation based reporting
pairs (operator o0 , variable x) caused oDG+ o0 successful. is,
report pair (o0 , x) o0 effect x, context fact (x, c) transition
t0 taken o0 contained R1+ C0 F0 , recoverable sub-sequence
+
P>0
(s). brief, record (o0 , x) o0 harmful effect x. perform test
whether main effect o0 , i.e., x0 , invertible; case record
x0 since problem appear side effects. avoid redundancies reporting,
record grounded operator o0 name action schema (load
instead load(package1 truck7)). Similarly, option record x name
predicate underlying fact (x, c). configuration, diagnosis comes
form action-name, predicate-name, direct match high-level PDDL
input files. measure parts diagnosis important,
associate pair count occurrences, weigh pairs frequency.
Zenotravel, diagnosis output always form fly, fuel-level zoom,
fuel-level, indicating correctly fuel consumption causing local
minima. Mprime Mystery, cause local minima same, however
diagnosis reliable specific structure domain, associating fuel
locations instead vehicles. sometimes causes diagnosis conclude
effect changing locations causing trouble. Concretely, R = 1000
Mystery, fuel consumption top-weighted diagnosis 17 28 tasks;
Mprime, happens 30 35 tasks. Satellite Rovers, diagnosis
always takes form switch-on, calibrated respectively take-image, calibrated, thus
reporting problem switching instrument, respectively taking image,
deletes calibration. precisely reason local minima exist here.19
Tyreworld, often diagnosis reports problem jacking hub results
longer jack (which needed elsewhere, too). actually
cause local minima (there none), indeed appears crucial aspect domain.
Similarly, Grid frequent diagnosis picking key results arm
longer empty again, actually cause local minima, critical resource
domain. Blocksworld-Arm, dominant diagnoses block longer
clear stack something top it, hand longer empty picking
block. Similarly, Freecell, dominant diagnoses send-to-free, cellspace
send-to-new-col, colspace.
One could make list much longer, however seems clear already
diagnosis facility, although yet primitive, potential identify interesting aspects
domain. Note making use one information sources
TorchLight. many things recorded, pertaining reasons
analysis failure, like support graph cycles etc, also reasons analysis success, like
successful gDGs x0 , o0 pairs yielding successful oDG+ s. appears promising try
improve diagnosis combining information sources. combination
19. Since analysis failure rare two domains, often diagnosis give output all.
R = 1000, output non-empty 10 instances Satellite 8 instances Rovers. R = 100
reduces 4 instances Satellite, single one Rovers.

188

fiAnalyzing Search Topology Without Running Search

domain analysis techniques, like landmarks invariants extraction, could also
useful. direction future work.20

9. Related Work
prior work aforementioned one author (Hoffmann, 2005)
trying automatically infer topological properties heuristic function. Thus work
relate strongly domain analysis techniques. closest relation
techniques relying causal graphs. follows discuss detail, along
connections arising context.
local analysis succeeds, construct path exit identified. this,
work relates work macro-actions (e.g., Botea, Muller, & Schaeffer, 2004; Vidal,
2004). distinguishing feature macro-action (would be) constructed
targeted analytical way, even giving guarantee, conservative case, make
progress towards goal. machinery behind analysis based causal graphs,
shares similarities known causal-graph based execution path generation methods
(e.g., Jonsson & Backstrom, 1995; Williams & Nayak, 1997; Brafman & Domshlak, 2003).
distinguishing feature focus h+ individual states rather
whole task. allows us consider small fragments otherwise arbitrarily complex
planning tasks look oDG+ instead SG. Note ability quite powerful
far applicability goes. seen Section 8, success rate (local)
approximate analysis therewith fraction states would able
generate macro-action non-zero almost benchmark domains. course,
broad applicability comes prize. traditional causal graph methods guarantee
reach goal, worst case macro-actions may lead h+ local minima. Still,
may interesting look whether other, traditional, causal-graph based methods
localized (or similar) manner well.
Global analysis, focus whole planning task thus whole causal
graph, even closely related research causal graphs based tractability analysis.
major difference tractability analysis h+ topology analysis, principle,
tractability absence local minima orthogonal properties general,
neither one implies other. Now, pointed end Section 6, global
analysis imply tractability (of plan existence). Vice versa, restrictions made
known tractable classes imply absence local minima? many cases, answer
question definite no; interesting questions open; single case
corresponding basic result answer yes.
Example 3 Appendix A.4 shows one construct local minimum 2
variables domain size 3, 1-arc SG, unary operators, strongly connected DTGs
single non-invertible transition. example (and various scaling extensions breaking
respective conditions) falls variety known tractable classes. example
20. particular, Fast Downwards translator always perfect detecting finite-domain variables
underlying benchmarks. example, Satellite often detect electricity available
exactly one instruments mounted satellite. lead pointless diagnosis output,
handled using simple notion predicates exchanged every operator.
things like principled manner, invariants analysis would useful.

189

fiHoffmann

tractable class F
n identified Domshlak Dinitz (2001), every transition
dependent variable depends variable. example Helmerts (2004,
2006) SAS+ -1 class strongly connected DTGs. example solved, i.e., reduced
empty task, Haslums (2007) simplification techniques (also, techniques
solve tasks Satellite domain, contain local minima). example
fork inverted fork causal graph, bounded domain size 1-dependent actions
(actions 1 prevail condition), thus qualifies tractable classes
identified Katz Domshlak (2008b). examples causal graph chain,
thus particular polytree bounded indegree, corresponding tractable class
identified Brafman Domshlak (2003) except that, there, variables restricted
binary (domain size 2). open question whether plan existence chain causal
graphs domain size 3 tractable; strongest known result NP-hard
domain size 5 (Gimenez & Jonsson, 2009b).21 Similarly, example fits prerequisites
stated Katz Domshlak (2008a) except binary variables only;
open question whether local minima exist tractable classes identified there.
Finally, example, suitable scaling extension, obviously qualifies two theorems
stated Chen Gimenez (2010). Theorem 3.1 (more precisely, first part
theorem) requires constant bound size connected components
undirected graph induced causal graph. first part Theorem 4.1
requires constant bound size strongly connected components causal
graph, pertains notion reversible tasks requiring always go back
initial state.
Next, consider line works restricting causal graph DTGs
task (Backstrom & Klein, 1991; Backstrom & Nebel, 1995; Jonsson & Backstrom, 1998).
simplest class identified here, contained classes, SAS+ -PUBS
fact achieved one operator (post-unique, P), operators unary
(U), variables binary (B), variables one value required
condition transition variable (single-valued, S). Now, Example 2
Appendix A.4 shows local minimum example U properties.
example two variables, x y, local minimum arises cyclic
dependency prevents attaining goal value dn via shortest path taken
optimal relaxed plan. remove two values domain y, remove
alternative way reaching dn ,22 example still contains local minimum
also P B properties. remark modified example unsolvable.
remains open question whether solvable SAS+ -PUBS tasks local minima exist;
generally, question open even larger SAS+ -PUS class, (yet larger)
SAS+ -IAO class identified Jonsson Backstrom (1998).
Another open question whether 3S class Jonsson Backstrom (1995)
contains local minima. class works binary variables only; requires unary operators
acyclic causal graphs, however allows facts splitting instead reversible.
p splitting then, intuitively, task decomposed three independent subtasks respect p; open question whether local minima constructed
21. Although, course, clear that, DTGs strongly connected case, deciding
plan existence tractable matter domain size is.
22. modification given detail example Appendix A.4.

190

fiAnalyzing Search Topology Without Running Search

satisfying property. Disallowing splitting option 3S, obtain single
positive case, known tractable class contain local minima.
class corresponds basic result acyclic causal graphs invertible transitions
except variables restricted binary. Williams Nayak (1997) mention
restrictions (but make formal claims regarding tractability) corresponding exactly
basic result except allow irreversible repair actions. latter actions
defined relative specialized formal framework control systems, spirit
similar term transitions self-irrelevant deletes herein.
Finally, easy see that, Bylanders (1994) three tractability criteria, two
allowing several effects imply absence local minima. third criterion,
restricting action effects single literal preconditions positive literals (but allowing
negative goals), leave open question whether local minima exist.
remark criterion apply benchmark aware of.
close section, certainly wish claim identification
tractable classes contribution work, note scope Theorem 4
tractable class, cf. covered known tractable classes.23
tractable cases identified Bylander (1994) obviously cover Logistics,
Miconic-STRIPS, Movie, Simple-TSP. Many causal graph based tractability results
require unary operators (Jonsson & Backstrom, 1995; Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Helmert, 2004, 2006; Katz & Domshlak, 2008a, 2008b; Jonsson,
2009; Gimenez & Jonsson, 2008, 2009a), cover Miconic-STRIPS, Movie,
Simple-TSP. work Chen Gimenez (2010), Theorem 4.1 requires reversibility given either Movie, Miconic-STRIPS, Simple-TSP,
Theorem 3.1 requires constant bound size connected components
undirected graph induced causal graph, given none Logistics, MiconicSTRIPS, Simple-TSP. known tractability results make different restrictions
DTGs (Backstrom & Klein, 1991; Backstrom & Nebel, 1995; Jonsson & Backstrom,
1998). Even general tractable class identified there, SAS+ -IAO, covers none
Miconic-STRIPS, Logistics, Simple-TSP (because vehicle variables acyclic
respect requestable values), neither cover Movie (because rewinding
movie neither unary irreplaceable: side effect un-setting counter,
breaking DTG counter two disjoint components).
far coverage benchmarks goes, strongest competitor Theorem 4
Haslums (2007) simplification techniques. iteratively remove variables
paths relevant attaining required conditions free, i.e., traversed using transitions neither conditions side effects. Haslums Theorem 1 states
removal done without jeopardizing solution existence, i.e., plan original
task reconstructed easily plan simplified task. particular,
task solved simplified completely, empty task plan constructed
polynomial time. Haslum combines basic technique number domain reformulation techniques, e.g., replacing action sequences macros certain conditions.
choice combination techniques apply fully automated, parts
23. true basic result, explained essentially covered works Jonsson
Backstrom (1995) Williams Nayak (1997). Formally, prerequisites imply (the
first part of) Theorem 4.1 work Chen Gimenez (2010), namely, postulated bound 1.

191

fiHoffmann

techniques fully described, making comparison Theorem 4 difficult.
Haslum reports techniques solve tasks Logistics, Miconic-STRIPS, Movie,
plus Gripper Satellite. Haslum experiment Simple-TSP. Theorem 1,
stated form, solve Simple-TSP, transitions root
variable side effects (with irrelevant deletes). Extending theorem cover
irrelevant deletes straightforward. subtle weakness Haslums Theorem 1 relative Theorem 4 pertains reaching required values externally caused
values. Haslum requires moves free, whereas, definition recoverable
side effect deletes, Theorem 4 allows recovering operators affect several variables
take precondition prevails effects o0 .

10. Conclusion
identified connection causal graphs h+ , devised tool allowing
analyze search space topology without actually running search. tool yet
automatic Hoffmann, analysis quality impressive even compared
unlimited search probing.
generic level, conclusion work that, sometimes, possible
automatically infer topological properties heuristic function. interesting question
future work whether also done heuristics h+ (cf. also
comments regarding causal graph research below). Methodologically, noteworthy
analysis based syntactic restrictions problem description, traditionally used identify tractable fragments (of planning computationally
hard problems). present work showcases similar techniques apply
analysis search spaces general problem solvers.
main open question whether global analysis tightly approximate scope
Theorem 2. indicated, good starting point appears trying include, gDG
operator o0 , variable dependencies induced operators may actually precede
o0 optimal relaxed plan. approach automatically recognizing operators could
possibly developed along lines Hoffmann Nebel (2001b), using simplified
version aforementioned fact generation tree analysis technique (Hoffmann, 2005).
Additionally, would great recognize situations harmful side effects o0
like making hand non-empty pick ball Gripper necessarily
recovered inside relaxed plan. Possibly, analysis could based variant
action landmarks (Hoffmann, Porteous, & Sebastia, 2004; Karpas & Domshlak, 2009).
Another interesting line research start results given individual states
local analysis, extract reasons success s, generalize reasons
determine generic property success guaranteed. Taken extreme,
might possible automatically identify domain sub-classes, i.e., particular combinations
initial state goal state, absence local minima proved.
work highlights two new aspects causal graph research. First, shows that,
certain situations, one localize causal graph analysis, consider causal
graph fragment relevant solving particular state. Second, one use causal graphs
constructing paths global goal, state value heuristic h
decreased. former enables analysis succeed tasks whose causal graphs
192

fiAnalyzing Search Topology Without Running Search

otherwise arbitrarily complex, thus potential greatly broaden scope
applicability. latter necessarily limited h+ simple example,
obvious similar constructions made trivial heuristic counting number
unsatisfied goals thus opens completely new avenue causal graph research.
Another possibility planner performance prediction, along lines Roberts
Howe (2009). experimental results indicate TorchLights problem features,
also search probing, highly informative. potential significantly
improve results Roberts Howe unseen domains currently use
simple features, like counts predicates action schemes, hardly capture domainindependent structure relevant planner performance. Like limited search probing (SP1s ),
TorchLight generates features without jeopardizing runtime, thus enabling automatic
planner configuration. Unlike search probing, may even work on-line search:
single relaxed plan already deliver interesting information. example, one might
make search less greedy choosing different search strategy, switching helpful
actions off, etc. depending outcome checking Theorem 2.
mentioned Section 9, direction worth trying use local analysis generating
macro-actions. domains high success rate, seems likely macro-actions
would lead goal search all. priori clear, though, whether
approach would significantly strengthen, least present benchmarks, existing
techniques executing (parts of) relaxed plan (e.g., Vidal, 2004).
One could use TorchLights diagnosis facility basis abstraction technique
deriving search guidance, much currently done relaxation/abstraction
techniques. diagnosis pin-point operator effects causing problems
search. remove enough harmful effects end task Theorem 4
applies, abstracted problem tractable. example, transportation domains,
process could abstract away fuel consumption. abstract much,
information provided may still outweigh effort abstract planning, i.e.,
using actual planner inside heuristic function. example, Grid abstract task
could problem variant allowing carry several keys once. One could also focus
construction different heuristics based ignoring deletes harmful effects.
Finally, interesting research line domain reformulation. well known,
domain formulation make huge difference planner performance. However,
difficult choose good formulation, given planner. black art even
reformulation done developer planner question. lack guidance
one main open problems identified Haslum (2007) automatic reformulation
approach. frequent question author asked non-expert users
model domain FF handle easily.
TorchLights diagnosis facility, pin-pointing problematic effects, might instrumental
addressing difficulties. case reformulation done computer,
one possibility use analysis outcome could produce macro-actions hiding
within operators harmful effects. Another possibility could precompose variable subsets touched harmful effects.
case reformulation done human user, sky limit.
name one example, local minima Satellite could removed allowing
switch instrument pointing direction instrument
193

fiHoffmann

calibrated. generally, note end-user PDDL modeling writing PDDL
non-expert user wanting solve problem using off-the-shelf planners quite
different PDDL modeling planning experts developing benchmarks.
example, expert models transportation benchmark fuel consumption,
may seem quite pointless TorchLight determine fuel consumption hurt
planner performance. Indeed may reason fuel consumption included
first place. contrast, end-user (a) information may come surprise,
(b) user may actually choose omit fuel consumption may yield
better point trade-off planner performance plan usability. Generally
speaking, approach could give user guidance designing natural hierarchy
increasingly detailed increasingly problematic domain formulations. could
help making planning technology accessible, thus contribute challenge
taken much seriously planning community.

Acknowledgments
would like thank anonymous reviewers both, article hand ICAPS
2011 short version, constructive comments. particular, one reviewers
proved completeness results Theorem 1, another reviewer suggested future
research line trying generalize reasons success local analysis.
thank Carmel Domshlak discussions, feedback early stages work contributing particular d-abstracted task construction proof Lemma 3
executive summary status quo causal graph research.
special thanks goes Carlos Areces Luciana Benotti, inspiring
work first place. long ago given problem. Carlos
Lucianas insistence finally made see connection causal graphs trying
convince analysis like impossible.

Appendix A. Technical Details Proofs
give full proofs and, needed, fill technical definitions. first
prove complexity result (Appendix A.1, Theorem 1), result pertaining
analysis optimal relaxed plans (Appendix A.2, Theorem 2), result pertaining
conservative approximations (Appendix A.3, Theorems 3 4). construct number
examples relevant kinds analysis (Appendix A.4), giving proofs
domain-specific performance guarantees (Appendix A.5, Propositions 1 2).
A.1 Computational Complexity
Theorem 1. PSPACE-complete decide whether state space given
planning task contains local minimum, given integer K PSPACE-complete
decide whether states ed(s) K. Further, PSPACE-complete
decide whether given state local minimum, given integer K
PSPACE-complete decide whether ed(s) K.
194

fiAnalyzing Search Topology Without Running Search

Proof. Throughout proof, since PSPACE closed complementation,
distinguish mentioned PSPACE-complete decision problems complements.
membership results easy prove. Note first that, given state s,
compute h+ (s) within polynomial space: generate potentially non-optimal relaxed plan,
length n, known methods; iteratively decrement n test value
whether relaxed plan length still exists; stop test answers no.
test bounded relaxed plan existence NP thus PSPACE. here,
prove membership results simple modifications guess-and-check argument
showing PLANSAT, problem deciding whether given planning task solvable,
NPSPACE hence PSPACE (Bylander, 1994). argument works
starting initial state, guessing actions, terminating successfully goal state
reached. Unsuccessful termination occurs guessed path longer trivial
upper bound B := xX |Dx | number different states. able check
condition polynomial space, path length maintained binary counter.
decide whether given state (not) local minimum, run guess-and-check
algorithm s, modified to: compute h+ encountered state; terminate unsuccessfully bound B exceeded h+ increases operator application;
terminate successfully h+ decreases operator application. decide whether
ed(s) K, use algorithm except bound B replaced bound K,
increases h+ permitted, success occurs h+ decreases h+ (s) h+ (s)1.
decide whether state space entire planning task contains local minima, whether
states state space ed(s) K, simply run Bylanders guess-and-check
algorithm way enumerating reachable states, individual state
run modified guess-and-check algorithms described. Clearly, algorithms
run non-deterministic polynomial space, shows part claim.
show PSPACE-hardness results. first consider problem deciding whether given state local minimum. proof works reducing
PLANSAT, known PSPACE-hard propositional STRIPS (Bylander,
1994), trivially follows PLANSAT PSPACE-hard also finitedomain variable planning tasks use herein.
Let (X, sI , sG , O) planning task whose solvability wish decide. design
modified task (X 0 , s0I , s0G , O0 ) starting (X, sI , sG , O) making following
modifications:
Add new variable ChooseT ask X 0 ,
s0I (ChooseT ask) = nil, s0G (ChooseT ask) undefined.

domain

{nil, org, alt},

role variable give planner choice whether solve
original task (X, sI , sG , O), whether solve alternative task custom-designed
proof.
Add new variable DistAlt X 0 , domain {0, 1}, s0I (DistAlt) = 1,
s0G (DistAlt) = 1.
variable simply serves control length solution alternative task.
solution length 1 plus number steps needed bring DistAlt
195

fiHoffmann

value 0 goal value. (Here, 1 step needed so; later
proof, increase distance.)
Add two new operators oOrg = ({(ChooseT ask, nil)}, {(ChooseT ask, org)})
oAlt = ({(ChooseT ask, nil)}, {(ChooseT ask, alt), (DistAlt, 0)}).
implements choice planning task. Note that, choose alternative
task, DistAlt set 0, thus forcing solution bridge distance.
contrast, original task, variable keeps residing goal value
already assigned s0I (DistAlt).
Add new operator oDistAlt = ({(ChooseT ask, alt), (DistAlt, 0)}, {(DistAlt, 1)}).
allows bridge distance intended solution alternative task.
Add new operator osG Alt = ({(ChooseT ask, alt), (DistAlt, 1)}, sG ).
allows us accomplish original goal, final step solving alternative task.
Add (ChooseT ask, org) new precondition original operators, i.e.,
taken O.
forces planner choose original task, executing operators.
Add new variable StillAlive X, domain {yes, no}, s0I (StillAlive) = yes,
sG (StillAlive) = yes. Add new operator osG Dead = (, sG {(StillAlive, no)}).
osG Dead operator allows us accomplish original goal single step,
matter task chosen solve, also new initial state s0I already.
However, operator also sets new variable StillAlive value no, whereas
goal value variable yes. value cannot re-achieved, thus
operator leads dead-end. function proof flatten value
h+ original task, s0I , constantly 1 unless goal state.
extreme flattening happen alternative task because, there,
distance variable DistAlt also needs handled.
summary, (X 0 , s0I , s0G , O0 ) designed setting:
X 0 := X {ChooseT ask, DistAlt, StillAlive}
s0I := sI {(ChooseT ask, nil), (DistAlt, 1), (StillAlive, yes)}
s0G := sG {(DistAlt, 1), (StillAlive, yes)}
O0 := {(pre {(ChooseT ask, org)}, eff) | (pre, eff) O} {oOrg , oAlt , oDistAlt , osG Alt ,
osG Dead }
consider new initial state s0I . exactly three successor states: sDead produced osG Dead , sOrg produced oOrg , sAlt produced oAlt . h+ (sDead ) =
sDead (StillAlive) = no. h+ (s0I ) = h+ (sOrg ) = 1 due relaxed
196

fiAnalyzing Search Topology Without Running Search

plan hosG Dead i. Finally, h+ (sAlt ) = 2 oAlt sets DistAlt variable 0
whereas goal 1. Thus shortest relaxed plan sAlt hoDistAlt , osG Alt i.
this, clearly follows s0I local minimum iff sOrg monotone
path state h+ (s) < h+ (sOrg ). Since h+ (sOrg ) = 1, latter equivalent
existence monotone path sOrg goal state, i.e., path goal state
h+ constantly 1. Since, states reachable sOrg , single-step sequence
hosG Dead relaxed plan, equivalent existence path sOrg goal
state. Clearly, latter equivalent solvability original task (X, sI , sG , O). Thus
s0I local minimum iff (X, sI , sG , O) solvable, shows part claim.
next prove PSPACE-hardness deciding whether given planning task
contains local minimum. follows easily above. Observe alternative
task contain local minima. described, h+ (sAlt ) = 2. apply
oDistAlt sAlt , obtain state sAltDist h+ (sAltDist ) = 1 relaxed
plan hosG Alt i. Applying osG Alt sAltDist yields goal state, thus sAlt sAltDist
better evaluated neighbors. states descending sAlt must produced
osG Dead thus h+ value . So, (X 0 , s0I , s0G , O0 ) contains local minimum iff
part state space descended sOrg does. Since states h+ value 1 unless
goal states, cf. above, latter equivalent unsolvability (X, sI , sG , O)
shows part claim.
Assume given integer K need decide individual state
whether ed(s) K. reduce Bounded-PLANSAT, problem deciding whether
given planning task solvable within given number steps. Bounded-PLANSAT
known PSPACE-complete bound given non-unary representation.
modify task (X 0 , s0I , s0G , O0 ) given above, way increases solution length
alternative task K. introduce binary counter using dlog2 (K 2)e new binary
variables Biti 0 sI . introduce operator bit, allowing set
bit 1 lower bits already 1, effect setting lower bits back
O. operator additional precondition (ChooseT ask, alt),
effect modifying bits. modify operator oDistAlt adding new
preconditions encoding counter position K 2. construction, clearly h+ (sAlt ) > 1,
distance goal sAlt K: plan count K 2, apply oDistAlt ,
apply osG Alt . Thus, shortest exit path sI via oAlt length K + 1. then,
above, ed(sI ) K iff (X, sI , sG , O) plan length K 1,
concludes part claim.
Finally, say need decide whether not, S, ed(s) K. Note
first sAlt successors necessarily exit distance K (the goal
reached many steps), exit distance sOrg successors
equal length shortest plan corresponding state (X, sI , sG , O).
latter length may, states (X, sI , sG , O), longer K even shortest
plan (X, sI , sG , O) (i.e., original initial state) length K. thus introduce
another binary counter, time counting K 1, conditioned (ChooseT ask, org),
new operator whose precondition demands new counter K 1
achieves goals. Then, clearly, sOrg descendants exit distance
K. Thus state may exit distance greater K s0I precisely,
197

fiHoffmann

ed(s0I ) = K + 1 iff new counter shortest plan sOrg , obviously
case iff (X, sI , sG , O) plan length K 1. concludes argument.
A.2 Analyzing Optimal Relaxed Plans
need fill notations. sake self-containedness section, first
re-state definitions given Section 5:
Definition 1. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , let
P + (s) optimal relaxed plan s, let x0 X, let o0 P + (s) operator taking
relevant transition form t0 = (s(x0 ), c).
optimal rplan dependency graph P + (s), x0 o0 , optimal rplan dependency
graph P + (s) brief, graph oDG+ = (V, A) unique leaf vertex x0 ,
x V (x, x0 ) either: x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x 6= x0
0
+
(s) taking relevant transition x0 x Xpreo
V \ {x0 } exists P<0
preo (x) 6= s(x).
x V \ {x0 }, oDT G+
x denote sub-graph DT Gx includes
+
(s, x), relevant transitions using operator
values true point P<0
+
P<0 (s, x), least one relevant inverse relevant inverse exists.
+
(s, x) transitions original, inverse transitions induced.
refer P<0
Definition 2. Let (X, sI , sG , O), s, P + (s), x0 , t0 , oDG+ = (V, A) Definition 1.
say oDG+ successful following holds:
(1) oDG+ acyclic.
(2) either:
+
(s)-recoverable;
(a) oDG+ -relevant deletes t0 P>0
+
(b) s(x0 ) oDG -relevant, t0 replaceable side effect deletes;
(c) s(x0 ) oDG+ -relevant, t0 recoverable side effect deletes.

(3) x V \ {x0 }, oDT G+
x transitions either self-irrelevant deletes,
invertible/induced irrelevant side effect deletes side effects V \{x0 }.
next define two general notions helpful state proofs.
prevail condition prevo operator results restricting preo
set variables Xpreo \ Xeff .
Let x X, let (c, c0 ) transition DT Gx , let (y, d) seff(c, c0 ) side
effect transition. context (y, d) (c, c0 ) ctx(c, c0 , y, d) :=
(
(y, prerop(c,c0 ) (y))
Xprerop(c,c0 )
{(y, d0 ) | d0 Dy , d0 6= d} 6 Xprerop(c,c0 )
context (c, c0 ) set ctx(c, c0 ) partial variable assignments that,
every (y, d) seff(c, c0 ), X (y, (y)) ctx(c, c0 , y, d). identify ctx(c, c0 )
set facts occur assignments.
198

fiAnalyzing Search Topology Without Running Search

Note definition ctx(c, c0 ) over-writes previous one Section 5,
sense also distinguish possible tuples context values,
rather collecting overall set. need fine-grained definition
precisely formulate Definition 2 condition (2c), i.e., conditions transition
recoverable side effect deletes. Namely, Definition 2 conditions (2b) (2c)
formalized follows:
transition (c, c0 ) replaceable side effect deletes iff ctx(c, c0 )sG = and, every
rop(c, c0 ) 6= preo ctx(c, c0 ) 6= exists o0 eff o0 = eff
preo0 prevrop(c,c0 ) eff rop(c,c0 ) .
transition (c, c0 ) recoverable side effect deletes iff following two conditions
hold:
Either (c, c0 ) irrelevant side effect deletes or, every ctx(c, c0 ),
exists recovering
operator preo prevrop(c,c0 ) eff rop(c,c0 ) eff ,
eff (sG rop(c,c0 )6=o0 preo0 ).
Every (y, d) seff(c, c0 ) goal appears operator precondition
possibly recovering operators.
t0 replaceable side effect deletes, upon execution remove o0
relaxed plan operator relying deleted facts replaced. t0
recoverable side effect deletes, then, due first clause definition, matter
state s0 apply t0 matter context holds s0
recovering operator applicable t0 re-achieves relevant facts. Due
second clause, delete facts relevant elsewhere relaxed plan (note
anything deleted must side effect t0 ).
Finally, formally define notion used Definition 2 condition (2a) oDG+ +
(s)-recoverable assume surroundings pertaining
relevant deletes t0 P>0
Theorem 2, i.e., (X, sI , sG , O) planning task, state, P + (s) optimal relaxed
plan s, oDG+ = (V, A) optimal rplan dependency graph leaf variable x0
transition t0 = (s(x0 ), c) responsible operator o0 . considering state s0
t0 executed, reaching state s1 , examining relaxed plan P1+ s1
+
constructed P + (s) removing o0 , replacing operators P<0
(s)
+
operators responsible induced oDT Gx transitions x V \ {x0 }.
C0 := {(x0 , s(x0 ))} ctx(t0 ) denote values potentially deleted t0 .
R1+ denote union sG , precondition P + (s) operator
o0 , precondition operator responsible operator
induced transition oDT G+
x , x V \ {x0 }. discussed Section 5,
super-set facts possibly needed P1+ .

F0 := oP + (s) eff denote set facts true relaxed execution
<0

+
P<0
(s) s. discussed Section 5, p 6 F0 p needed s1 P1+
relaxed plan.

199

fiHoffmann

S1 denote union of: (1) prevo0 eff o0 ; (2) set facts (x, c)
+
exists x Xeff either o0 P<0
(s) responsible
+
operator induced transition oDT Gx , x V \ {x0 }; (3) set F defined
F := {(x, c) | (x, c) F0 , x V \ {x0 }} Xeff o0 (V \ {x0 }) = , else F := . Here,
(1) (2) facts certain true s1 ; (3) set
facts able achieve start P1+ , appropriately re-ordering
operators.

+ (s), relaxed-plan macro-precondition

= ho1 , . . . , sub-sequence
P
Sn
i1


+
defined pre
:= i=1 (preoi \ j=1
eff oj ). relaxed-plan macro-effect


n




+
defined eff
:= i=1 eff oi . empty sets default empty


set. notions simply capture outside needs effects relaxed plan
sub-sequence.
+
+
(s)-recoverable iff P>0
(s) contains sub oDG+ -relevant deletes t0 P>0


+
+
+
sequence o0 pre



eff

C

F
.

first condition

R



1
0
0
1
o0
o0


ensures o0 applicable appropriate point within P1+ . second

o0 .
clause ensures facts relevant P1+ re-achieved

proceed exit path construction. follows, first consider
part path leading s0 , i.e., move non-leaf variables x V \{x0 }.
show construct relaxed plans P + (s0 ) states s0 visited path.
First, note assume P + (s) sorted according optimal rplan
dependency graph oDG+ = (V, A). Precisely, let xk , . . . , x1 topological ordering
V \ {x0 } according arcs A. Due construction (V, A) per Definition 1,
previous values never removed relaxed state space, re-order
+
+
(s, x1 ) P . is, perform moves
(s, xk ) P<0
P + (s) take form P<0
+
within oDT Gx front, order conforming A. henceforth assume,
wlog, P + (s) form.
+
Recall follows original oDT G+
x transitions taken P<0 (s),
whereas induced oDT G+
x transitions included inverse original tran

sition. path
p invertible transitions traversing hc0 , . . . , cn i, inverse path
p


traverses hcn , . . . , c0 replacing transition inverse. rop( p ) denote
operator sequence responsible path.
say state s0 invertible surroundings according oDG+ s0

reachable executing sequence
responsible operators invertible/induced
+
transitions oDT Gx x V \ {x0 }. adapted relaxed plan s0 , denoted
P + (ss0 ), constructed follows. Let xk , . . . , x1 topological ordering V \ {x0 }
according A, denote P + (s) = P + (s, xk ) P + (s, x1 ) P . Initialize P + (ss0 ) :=

P + (s). Then, xi V \ {x0 }, let
p path original invertible transitions

+
0
oDT Gxi leading s(xi ) (xi ) clearly, path must exist. Remove rop(
p )


+
0
+
0
P (ss ), insert rop( p ) start P (ss , xi ).
next show adapted relaxed plans indeed relaxed plans, restricting
conditions correspondence Definition 2 condition (3):
Lemma 1. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,
let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) optimal rplan
200

fiAnalyzing Search Topology Without Running Search

dependency graph P + (s) where, every x V \ {x0 }, invertible/induced oDT G+
x
transitions irrelevant side effect deletes side effects V \ {x0 }. Let s0
state invertible surroundings according oDG+ . P + (ss0 ) relaxed
plan s0 , |P + (ss0 )| |P + (s)|.
+
+
Proof. definition, know P + (s) takes form P<0
(s, xk ) P<0
(s, x1 ) P ,
+
+
+
0
0
0
P (ss ) takes form P<0 (s , xk ) P<0 (s , x1 ) P , xk , . . . , x0
topological ordering V , P operator sequence common both,
whose content important proof. simplicity, denote rest
proof P + (ss0 ) P + (s0 ), leave away < 0 subscripts.

Consider first (relaxed) execution P + (s, xk ) P + (s0 , xk ). Say
p
+ (s0 ), i.e., path original invertible
path oDT G+
considered


definition

P
xk


0
transitions oDT G+
xi leading s(xk ) (xk ). Clearly, ho1 , . . . , := rop( p )

sub-sequence P + (s, xk ). Say
p visits vertices s(xk ) = c0 , . . . , cn = s0 (xk ); denote
C := {c0 , . . . , cn }. Assume wlog P + (s, xk ) starts ho1 , . . . , note
re-order P + (s, xk ) (and relaxed plans general) way want long
violate operator preconditions. latter case because: ho1 , . . . ,
constitutes path oDT G+
xk ; operators depending value C

ordered occur later P + (s, xk ); because, since transitions
p side
effects V \{x0 }, construction (V, A) per Definition 1 operators ho1 , . . . ,
support way, P + (s), affecting variable xk .
Given above, wlog P + (s, xk ) form ho1 , . . . , P1 . construction,



+
P (s0 , xk ) form rop(
pS
) P1 =: h

n , . . . , o1 PS
1 . Consider endpoints
n
+
+
0
prefixes, i.e., s1 := i=1 eff oi s2 := 1i=n eff
oi . Clearly, since

transitions
p irrelevant side effect deletes, relevant part
contained s0 . then, far variables outside V \ {x0 , xk } concerned,
+
relevant part s+
1 contained s2 : relevant side effects ho1 , . . . , already
0
contained ; values C obviously true s+
2 ; induced transitions side


+

effects, increase fact set s2 . Further, sequence h
n , . . . , o1
applicable relaxation. see this, note first preconditions xk


satisfied definition, h

n , . . . , o1 constitutes path DT Gxk . side effects,
occur, harmful old values over-written relaxation.
preconditions variables, due invertibility outside conditions
oi contained oi subset ho1 , . . . , i. Hence, Definition 1
since xk incoming edges oDG+ , preconditions satisfied s.
also satisfied s0 (vk root oDG+ ) variables x
contained V hence s0 (x) = s(x) prerequisite note precondition facts
cannot deleted side effects whose deletes irrelevant prerequisite.
shown relevant part outcome relaxed execution
P + (s, xk ) contained outcome relaxed execution P + (s0 , xk ) s0 ,
variables outside V \ {x0 , xk }. iterate argument. Assume induction
hypothesis already shown relevant part outcome relaxed
execution P + (s, xk ) . . . P + (s, xi+1 ) contained outcome relaxed execution
P + (s0 , xk ) P + (s0 , xi+1 ) s0 , variables outside V \ {x0 , xk , . . . , xi+1 }.
consider P + (s, xi ) P + (s0 , xi ). thing changes respect xk
may preconditions variables xj true s; j >

201

fiHoffmann

preconditions must belong predecessors xi oDG+ Definition 1.
Since P + (s) = P + (s, xk ) P + (s, x1 ) P relaxed plan s, conditions
established relaxed execution P + (s, xk ) P + (s, xi+1 ) s. Given this,
induction hypothesis conditions clearly irrelevant established also
relaxed execution P + (s0 , xk ) P + (s0 , xi+1 ) s0 , concludes argument
inductive case. = 1, follows relevant part outcome relaxed
execution P + (s, xk ) P + (s, x1 ) contained (on variables) outcome
relaxed execution P + (s0 , xk ) P + (s0 , x1 ) s0 . this, claim follows trivially
P + (s) relaxed plan s, remainder P operator sequences
identical.
second part claim follows because, 6= j, original
transitions use xi respectively xj operators common. because,
argued above, relevant operators side effects V \ {x0 }. Since
operators affects variable xi , cannot affect variable V \ {x0 }. Thus,
inverse transition introduce via inverse operator, P + (s) contains separate
operator. this, obviously get |P + (ss0 )| |P + (s)|.
Lemma 1 captures second case Definition 2 condition (3), transitions
invertible/induced irrelevant side effect deletes side effects V \ {x0 }.
next lemma captures first case Definition 2 condition (3):
Lemma 2. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,
let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) optimal rplan
dependency graph P + (s) where, every x V \ {x0 }, invertible/induced oDT G+
x
transitions irrelevant side effect deletes side effects V \ {x0 }. Let s0
state invertible surroundings according oDG+ . Let s00 state reached
s0 P + (ss0 , x) operator constituting transition (c, c0 ) x V , s0 (x) = c,
self-irrelevant deletes. removing P + (ss0 ) yields relaxed plan
s00 .
Proof. Lemma 1, P + (ss0 ) relaxed plan s0 . Now, upon execution o, s00 ,
effects true, i.e., (x, c0 ) side effects (if present). hand,
obviously facts (z, e) true s0 s00 ctx(c, c0 ){(x, c)}. Since,
prerequisite, transition (c, c0 ) self-irrelevant deletes, facts ctx(c, c0 ){(x, c)}
either irrelevant rop(c, c0 )-only relevant, meaning goal occur
operator precondition than, possibly, itself. claim follows directly
that.
remark much easily formulated, general, version Lemma 2
could proved simply associating notion self-irrelevant deletes operators
rather transitions, postulating used P + (s). argument
corresponds part (A) proof Lemma 3 authors previous work (Hoffmann,
2005). state argument particular form since form
need below.
almost ready prove main lemma behind exit path construction.
need one last notation, capturing simpler form cost function costd (oDG+ )
202

fiAnalyzing Search Topology Without Running Search

considered Section 5. simpler function make use shortcut construction;Pthat construction introduced separately below. define
costd (oDG+ ) := xV costd (x), costd (x) :=
(
1
x = x0
P
+

0
diam(oDT Gx ) x0 :(x,x0 )A cost (x ) x 6= x0
Lemma 3. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,
let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) successful

optimal rplan dependency graph P + (s). exists operator sequence

that:

(I)
constitutes monotone path state s1 h+ (s) > h+ (s1 ).

(II) length
costd (oDG+ ) Definition 2 condition (2a)
(2b), costd (oDG+ ) + 1 Definition 2 condition (2c).
Proof. Let xk , . . . , x1 topological ordering V \{x0 } according arcs A. Consider
state s0 every x V \ {x0 } s0 (x) vertex oDT G+
x ,
every variable x outside V \ {x0 } s0 (x) = s(x) unless s(x) irrelevant. Say
preo0 s0 . Note first state s0 exists. definition, either
preo0 (x0 ) undefined preo0 (x0 ) = s(x0 ) = s0 (x0 ). (Note every variable
x outside V \ {x0 } s0 (x) = s(x) unless s(x) irrelevant covers also
case transition V \ {x0 } side effect x0 , whose delete must
prerequisite irrelevant thus either side effect x0 := s(x0 ) o0 actually
preconditioned x0 .) Definition 1 P + (s) relaxed plan s,
variable x Xpreo contained V unless preo0 (x) = s(x). reasons,
0
+
construction oDT G+
x , preo0 (x) vertex oDT Gx .
Now, consider state s1 results applying o0 s0 . first consider
situation s0 invertible surroundings according oDG+ ; opposite
case discussed below. apply Lemma 1 s0 , hence relaxed
+
(s, x), x
plan P + (ss0 ) s0 results replacing, P + (s), moves P<0
+
+
+
0
V \ {x0 }, inverses. particular, h (s) h (s0 ), P (ss0 , x ) = P + (s, x0 )
x0 6 V . relaxed plan s1 ? distinguish Definition 2 condition (2)
cases (a), (b), (c).

+
case (a), definition P>0
(s) contains sub-sequence
o0 pre+



o0
+
+
+
S1 eff
R1 C0 F0 . implies remove o0 P (s s0 )

o0
obtain relaxed plan P1+ s1 , thus getting h+ (s) > h+ (s1 ). precisely, construct

P1+ by: removing o0 P + (ss0 ); Xeff o0 (V \ {x0 }) 6= moving
o0 occur


+
+
start P1 ; Xeff o0 (V \ {x0 }) = moving o0 occur start P>0
(s)
+
(which unchanged P (ss0 )).

Observe first o0 P + (s s0 )
o0 sub-sequence P + (s s0 ) since
adaptation pertains exclusively operators precede o0 P + (s). Second, course
values established o0 true s1 .

Third,
o0 applicable (in relaxation) assigned point P1+ . see this,
consider first case Xeff o0 (V \ {x0 }) 6= . Then, definition S1 , pre+




0

203

fiHoffmann

contained (prevo0 eff o0 ) set facts (x, c) exists
+
x Xeff either o0 P<0
(s) responsible operator inverse
+
0
transition taken operator P<0
(s). facts true s1 .
obvious prevo0 eff o0 follows facts true
cannot affected operator path s1 . Consider case
Xeff o0 (V \ {x0 }) = . definition S1 , pre+
contained previous sets facts,


o0
plus {(x, c) | (x, c) F0 , x V \ {x0 }}. latter facts, far relevant, true

start
o0 P1+ . execution o0 affect execution
+
P (ss0 ), thus P1+ , point. then, argued Lemma 1,
outcome execution s0 contains, variables V \ {x0 },
+
relevant part outcome P<0
(s) is, relevant part F0 . Since o0
affect variables, true s1 , concludes point.
Finally, consider facts (z, e) true s0 s1 , may

needed P1+ behind
o0 , i.e., either goal precondition
operators. Observe that, since inverse operators performed transitions
variables V \ {x0 }, since include new outside preconditions,
(z, e) contained R1+ .24 Now, say first (z, e) F0 . Then, above,
(z, e) (ctx(s(x0 ), c){(x0 , s(x0 ))})F0 R1+ thus (z, e) eff +
prerequisite


o0
+
(s) else,
done. (z, e) 6 F0 ? Note that, then, (z, e) 6 preo P<0
+
precondition would true relaxed execution P (s) thus P + (s) would
+
(s), thus (z, e) needed
relaxed plan. Neither (z, e) added P<0
+
precondition inverse operator used P (s s0 ) operators
introduce new outside preconditions, course use own-preconditions previously
added operators affecting respective variable. Thus reason (z, e)
+
could needed P1+ either (z, e) sG (z, e) preo P>0
(s).
+
(z, e) sG certainly, since P (s) relaxed plan, achieved operator
P + (s). cannot = o0 since effect o0 true s1 , cannot
+
+
(s), thus contained P1+
(s) since (z, e) 6 F0 . Thus P>0
P<0
+
(s), arguments apply, i.e., must
done. (z, e) preo0 o0 P>0
+
0
P>0 (s), ordered , adds (z, e). concludes proof case (a).
Consider case (b), s(x0 ) 6 R1+ , transition (s(x0 ), c) replaceable
side effect deletes, i.e., ctx(s(x0 ), c) sG = and, every o0 6= preo
ctx(s(x0 ), c) 6= exists o0 eff o0 = eff preo0 prevo0 eff o0 .
obtain relaxed plan P1+ removing o0 P + (s s0 ), replacing
operators respective o0 needed. Precisely, say (z, e) true s0
s1 . z = x0 e = s(x0 ) needed P1+ construction. every z,
must (z, e) ctx(s(x0 ), c). (z, e) goal prerequisite. operator
P1+ (z, e) precondition, replace postulated operator o1
obviously applicable s1 effect. concludes case.
Consider last case (c), definition s(x0 ) 6 R1+ , transition (s(x0 ), c)
recoverable side effect deletes. Here, guarantee decrease h+ obtained s1
24. Note particular special case inverse transitions non-leaf variables x, may
precondition x added by, needed prerequisite of, operators P + (s, x).
preconditions preconditions may needed P + (ss0 ) thus P1+ ,
P + (s). reason include facts definition R1+ .

204

fiAnalyzing Search Topology Without Running Search

itself, successor state s2 s1 . Namely, let o0 operator recovering relevant
side effect deletes (s(x0 ), c). Precisely, let ctx(s(x0 ), c) s0 (such exists
definition ctx(s(x0 ), c)). Then,
let o0 operator preo0 (prevo0 eff o0 )
eff o0 , eff o0 (sG o0 6=o0 preo0 ) (such operator exists case (b)). Say
obtain P1+ replacing, P + (ss0 ), o0 o0 . P1+ relaxed plan
s1 . see this, note first o0 applicable s1 virtue preo0 (prevo0 eff o0 ).
Further, note values deleted o0 plus (x0 , s0 (x0 )). Since
s0 (x0 ) = s(x0 ), s(x0 ) 6 R1+ know s0 (x0 ) 6SR1+ thus delete
consequence. , virtue eff o0 (sG o0 6=o0 preo0 ) facts could
possibly relevant re-achieved o0 . Finally, values established o0 true
s1 .
Now, say obtain s2 applying o0 s1 . removing o0 P1+ yields relaxed
plan s2 . simply established effects true s2 , virtue
eff o0 facts deletes side-effects transition (s(x0 ), c). case (c),
relevant anything except possibly recovering operators. recovering
operator o0 removed P1+ . recovering
operators
could still contained P1+ , since eff eff o0 (sG o0 6=o0 preo0 ),
relevant facts could possibly achieve already true s2 thus remove
well. Hence, overall, h+ (s) > h+ (s2 ).
cases (a) (b) prove (I) constructing monotone path s1 , case (c)
true s2 . (Of course, also show (II), constructing path
specified length; ignore issue moment.) difficulty
constructing path achieving preconditions o0 . preconditions may
satisfied s, need reach state s0 satisfied. need
without ever increasing value h+ . Note that, decrease value h+ somewhere
along way, already reached exit monotone path, done. Thus
follows show upper bound h+ (s). Lemma 1, bounding
accomplished starting s, always taking oDT G+
x transitions variables
x V pertaining second case Definition 2 condition (3), i.e., transitions
invertible/induced irrelevant side effect deletes side effects V \ {x0 }.
follows will, brevity, refer transitions case2. Note that,
way, reach states invertible surroundings according oDG+ .

operator sequence
, Lemma 1 know h+ (s) h+ (s0 ) states
0
along way. Now, cannot reach s0 using sequence, i.e.,
0
would take non-case2 oDT G+
x transition (c, c ) variable x, state
s0 ? prerequisite know transition (c, c0 ) self-irrelevant deletes. apply
Lemma 2 because: s0 invertible surroundings according oDG+ ; since
following transition path, clearly s0 (x) = c, i.e., value relevant variable s0
start value last transition taking; construction, P + (ss0 ) changes
P + (s) case2 transitions, thus responsible operator rop(c, c0 ) (which
case2) guaranteed contained P + (ss0 ). Note rop(c, c0 ) cannot
used case2 transitions V \ {x0 } variable might taken
path s0 , prerequisite transitions side effects V \ {x0 },
contradiction constituting transition variable x hand. Thus know
h+ (s) > h+ (s0 ) already constructed desired monotone path exit
205

fiHoffmann



stop. Else, reach s0 sequence
, above,
ho0


(respectively ho0 , o0 i, case (c)) constitutes desired path.

remains show exactly construct operator sequence
. Consider
topological ordering V , xk , . . . , x1 . follows, consider depth indices k
0, say variable x V depth d, written depth(x) = d, iff x = xd .
characterizes d-abstracted planning task identical original planning
task except (and only) outside preconditions, oDT G+
x transitions
variables x depth(x) d, removed pertain values variables x0
depth(x0 ) > d. prove induction that:

(*) d-abstracted task, exists operator sequence
that:


(a) either (1)
ho0 execution path applicable s, (2)
execution path

0
applicable s, last transition (c, c ) variable x taken
relevant,
self-irrelevant deletes, responsible operator contained adapted relaxed
plan state s0 applied to, s0 (x) = c;

(b)
, except last step case (2) (a), uses case2 oDT G+
x transitions
variables x 1 depth(x) d;

(c) number operators
ho0 pertaining x V costd (x).

desired path
results setting := k. see this, note kabstracted planning task identical original planning task. claim follows
discussion above: (a) (b) together mean h+ decreases monotonically




+

P less dthan h (s) end. Given (c), length bounded
xV,depth(x)d cost (x). proves claim adding trivial observation that,
Definition 2 condition (2) case (c) discussed above, need add one
additional operator end path.

give proof (*). base case, = 0, trivial. set
0 empty.
construction (V, A) per Definition 1, construction 0-abstracted
task, outside preconditions o0 either true removed. (a)
(case (1)), (b), (c) obvious.

Inductive case, + 1. Exploiting induction hypothesis, let
operator




sequence per (*). turn requested sequence d+1 + 1abstracted planning task.
remainder proof, consider oDT G+
x , x V \ {x0 },
contain also irrelevant transitions, i.e., omit restriction Definition 1.
simplify argumentation show, oDT G+
x paths consider
contain irrelevant transitions, hence contained actual oDT G+
x per
Definition 1.

Let first operator
ho0 i. may applicable s, +
1-abstracted planning task. reason that, however, may precondition
removed d-abstracted planning task removed + 1abstracted planning task. construction, precondition must pertain xd+1 . Say
precondition (xd+1 , c). induction hypothesis, know contained
+
P<0
(s), responsible inverse transition operator. cases, since
inverse transitions introduce new outside preconditions, (xd+1 , c) precondition
206

fiAnalyzing Search Topology Without Running Search

+
operator P<0
(s). Thus c vertex oDT G+
xd+1 trivial (xd+1 , c) true
(which actually cannot case else would applicable
+ 1-abstracted planning task), (xd+1 , c) true follows P + (s)
relaxed plan must thus achieve (xd+1 , c) needed precondition.

+
Hence, P<0
(s, xd+1 ) must contain shortest path
q oDT G+
xd+1 s(xd+1 ) c.
transitions path irrelevant. see this, note first endpoint
operator precondition construction, thus last transition (c1 , c) irrelevant.
then, neither previous transition, (c2 , c1 ): was, (xd+1 , c1 ) would
+
operator precondition; then, rop(c1 , c) contained P<0
(s) construction

+
would also constitute transition (c2 , c) oDT Gxd+1 thus
q would


shortest path contradiction. Iterating argument, q contain irrelevant
transitions. Thus, since depth(xd+1 ) = + 1, Definition 1 (which includes nonsatisfied preconditions relevant transitions) construction + 1-abstracted

planning task, outside preconditions used rop(
q ) either true


removed. Hence execute rop( q ). either reached end
sequence, last transition taken oDT G+
xd+1 case2, hence
self-irrelevant deletes prerequisite. latter case, since following path
since discussed adapted relaxed plan exchanges operators pertaining
case2 transitions thus last one executed, clearly attained (a)

case (2) stop part rop(
q ) executed is, own, operator

sequence
d+1 desired. former case, reach state s0 s0 (xd+1 ) = c (and
nothing else relevance deleted, due non-existence relevant side-effect
deletes). s0 , applied, leading state s00 .

Let o0 second operator
ho i. Like above, o0 applicable s00 ,


0

reason may unsatisfied precondition form (xd+1 , c0 ). Like above,
+
(s), hence c0 vertex oDT G+
o0 inverse contained P<0
xd+1 . Likewise,
00
+
(xd+1 ) = c vertex oDT Gxd+1 . Now, yet used non-case2
transition oDT G+
xd+1 , else wouldnt get here. means still
invertible surroundings around s(xd+1 ) oDT G+
xd+1 . Clearly, implies
+
0
exists path oDT Gxd+1 c c (we could simply go back s(xd+1 ) move

c0 there). Taking shortest path
q , clearly path length bounded
+
diameter oDT Gxd+1 . path contain irrelevant transitions
endpoint c0 selected operator precondition, values
part shortest path oDT G+
xd+1 , thus argument given applies.

Thus outside preconditions used operators constituting
q either true
removed follows construction (V, A) per Definition 1
+
construction + 1-abstracted planning task operators P<0
(s), follows
inverses thereof inverse operators introduce new outside preconditions. Hence

execute
q s00 . either reached end path,
last transition taken case2, hence self-irrelevant deletes prerequisite.
Consider latter case. state s0 last transition reached
case2 transitions, since transition oDT G+
xd+1 case2, responsible
+
operator must contained P (s) adapted relaxed plan P + (ss0 )
s0 recall that, pointed above, since case2 transitions postulated
207

fiHoffmann

side effects V \{x0 }, responsible operator cannot used them. Further,
clearly since following path transitions, value xd+1 s0
start value transition. Hence attained (a) case (2) stop.
former case, reached state o0 applied (and nothing relevance
deleted, due postulated non-existence relevant side-effect deletes, case2

transitions). Iterating argument, get state last operator
ho0
applied, induction hypothesis reaching state s1 desired (a) case (1).
Properties (a) (b) clear construction. property (c), support

operator
ho0 i, clearly apply diam(oDT G+
xd+1 ) operators
pertaining xd+1 (or stop sequence earlier that). Note that,

operators
ho0 unsatisfied preconditions xd+1 above, pertains
variable x (xd+1 , x) A. consequence construction (V, A)
per Definition 1, fact inverse transitions introduce new outside

preconditions. Thus, comparison
ho0 i, overall execute
X
diam(oDT G+
k(x)
xd+1 )
x:(xd+1 ,x)A



additional operators
d+1 ho0 i, k(x) number operators
ho0
pertaining variable x. induction hypothesis, property (c) (*), k(x)
costd (x), x depth(x) < + 1, thus x (xd+1 , x) A. Hence
get, newly inserted steps affecting xd+1 , upper bound
X
diam(oDT G+
)

costd (x)
xd+1
x:(xd+1 ,x)A

identical costd (xd+1 ). concludes argument.
next note improve exit distance bound case insist
monotone exit paths:
Lemma 4. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,
let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) successful
optimal rplan dependency graph P + (s). Let V V \ {x0 } that, every x V ,
oDT G+
x transitions invertible/induced irrelevant side effect deletes
side effects V \{x0 }, DT Gx transitions either irrelevant, empty

conditions irrelevant side effect deletes. exists operator sequence

that:

(I)
constitutes path state s1 h+ (s) > h+ (s1 ).

(II) length
costd (oDG+ ) Definition 2 condition (2a)
(2b), costd (oDG+ ) + 1 Definition 2 condition (2c).
Proof. simple adaptation Lemma 3, adopt follows terminology proof lemma. thing changes bound imposed
exit path length sharper, insist path monotone.
level proof mechanics, happens that, whenever xd+1 V , choose
208

fiAnalyzing Search Topology Without Running Search


path
q achieve next open precondition operator already chosen participate


ho0 i, restrict paths within oDT G+
xd+1 , allow also
shortest path DT Gxd+1 . shortest path DT Gxd+1 value occurs

operator precondition,
q contains irrelevant transitions (same argument

proof Lemma 3). Further,
q executable prerequisite alternative
(non-oDT G+
)
transitions


outside conditions; original/induced transitions,
x
precondition achievement works exactly before. Note important property
open preconditions achieved xd+1 ever pertain values contained
oDT G+
xd+1 . trivial see induction alternative transitions
outside preconditions. Since prerequisite deletes alternative transitions
irrelevant, executing harm need minor extension Lemma 1,
allowing s0 identical state s00 invertible surroundings s, modulo
set irrelevant values hold s00 s; obvious extension
valid. extension, also obvious arguments pertaining s0 s1

remain valid. Finally, consider case
q involves non-case2 oDT G+
xd+1 transition.
state transition applied invertible surroundings s.
holds x 6 V construction remains same. holds
x V because, first, alternative transitions outside conditions, hence cause
higher-depth transitions inserted between, hence value lower-depth
+
variables x oDT G+
x ; second, prerequisite, oDT Gx contain non-case2
transitions, thus value x clearly reached case2 transitions.
Theorem 2. Let (X, sI , sG , O), s, P + (s), oDG+ Definition 1. oDG+ successful, local minimum, ed(s) costd (oDG+ ). Definition 2
condition (2a) (2b), ed(s) costd (oDG+ ) 1.
Proof. direct consequence Lemmas 3 4.
note prerequisites Lemma 4 could weakened allowing, x V ,
outside conditions already true s. extension obviously break
proof arguments. omitted make lemma prerequisite even
awkward already is.
indicated, exit path constructed Lemma 4 necessarily monotone. Example 5 Appendix A.4 contains construction showing this.
A.3 Conservative Approximations
sake self-containedness section, re-state definitions given Section 6:
Definition 3. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , let
x0 XsG , let t0 = (s(x0 ), c) relevant transition DT Gx0 o0 := rop(t0 ).
local dependency graph s, x0 , o0 , local dependency graph brief,
graph lDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:
x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x0 V \ {x0 } (x, x0 ) arc SG.
0

209

fiHoffmann

global dependency graph x0 o0 , global dependency graph brief,
graph gDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:
x0 = x0 x0 6= x Xpreo ; x0 V \ {x0 } (x, x0 ) arc SG.
0

Definition 4. Let (X, sI , sG , O), s, t0 , o0 , G = lDG G = gDG Definition 3.
say G = (V, A) successful following holds:
(1) G acyclic.
(2) G = lDG sG (x0 ) 6= s(x0 ), exists transitive successor x0 x0
SG x0 XsG sG (x0 ) 6= s(x0 ).
(3) t0 either:
(a) self-irrelevant side effect deletes;
(b) replaceable side effect deletes;
(c) recoverable side effect deletes.
(4) x V \ {x0 }, DT Gx transitions either irrelevant, self-irrelevant
deletes, invertible irrelevant side effect deletes side effects
V \ {x0 }.
Lemma 5. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) <
. Say x0 X and, every o0 = rop(s(x0 ), c) DT Gx0 t0 = (s(x0 ), c)
relevant, lDGo0 successful local dependency graph s, x0 , o0 . Then, least
one o0 , exist optimal relaxed plan P + (s) s, successful optimal rplan
dependency graph oDG+ P + (s), x0 , o0 , oDG+ sub-graph lDGo0 .
Proof. Observe first Definition 4 property (2) forces relaxed plan P + (s) move
x0 , i.e., P + (s, x0 ) non-empty. particular, P + (s, x0 ) takes path

DT Gx0 s(x0 ) sG (x0 ). Let
q shortest path taken P + (s, x0 ), let

o0 responsible operator first transition
q . Clearly, transition
form (s(x0 ), c), i.e., o0 one operators o0 claim. Lying shortest path
s(x0 ) sG (x0 ) sub-graph DT Gx0 taken P + (s, x0 ), transition (s(x0 ), c)
irrelevant. seen exactly argument given proof

Lemma 3 transitions paths
q constructed there, except endpoint
goal instead operator precondition.
Next, observe optimal P + (s) contains one operator x0 Xpreo
preo (x0 ) = s(x0 ). also follows Definition 4 property (2): x0 cannot become important non-achieved goal, i.e., P + (s) operator outside P + (s, x0 ) relies precondition x0 . see this, assume operator exist.
Then, since P + (s) optimal, exists reason inclusion o. Precisely,
must achieve least one fact needed terms Hoffmann Nebel
(2001b): fact either goal precondition another operator o0
behind P + (s). Iterating argument o0 (if necessary), obtain sequence
= o1 , (x1 , c1 ), o2 , (x2 , c2 ), . . . , , (xn , cn ) (xn , cn ) goal fact satisfied
oi achieves (xi , ci ) P + (s). Obviously, SG contains path x0 xn ,
xn XsG sG (xn ) 6= s(xn ), contradiction Definition 4 property (2). Thus
exist. argument, follows also every operator P + (s, x0 )
210

fiAnalyzing Search Topology Without Running Search

either side effect used elsewhere relaxed plan, precondition x0 .
Thus operators P + (s, x0 ) preconditioned x0 serve transform
s(x0 ) sG (x0 ). course, then, single one operators relies s(x0 )
else P + (s) optimal.
Say follows lDGo0 = (V, A). Denote (V 0 , A0 ) result backchaining
+
Definition 1 o0 P<0
(s). Definition 3 include variables arcs included
Definition 1. see this, note arcs (x, x0 ) included Definition 1 due
relevant transitions. Hence (V 0 , A0 ) sub-graph (V, A). particular, since (V, A)
acyclic, (V 0 , A0 ) acyclic well.
next observation that, assuming Definition 4 condition (2) holds true, Definition 4 condition (3a) implies Definition 2 condition (2a), Definition 4 condition (3b) implies
Definition 2 condition (2b), Definition 4 condition (3c) implies Definition 2 condition
(2c).
Consider first case (a) t0 self-irrelevant side effect deletes. show
+
R1 C0 = . Recall notations Appendix A.2 C0 = {(x0 , s(x0 ))} ctx(t0 ),
R1+ super-set set facts need relaxed plan removing o0 .
variables except x0 , clear fact intersection: facts
ctx(t0 ) irrelevant o0 -only relevant prerequisite, thus contained R1+ .
Hence, (x0 , s(x0 )) remains possible content R1+ C0 . show follows
(x0 , s(x0 )) 6 R1+ , thus (x0 , s(x0 )) 6 R1+ C0 latter intersection empty,
desired. Recall R1+ denotes union sG , precondition o0 6= P + (s),
precondition operator responsible operator induced
transition oDT G+
x , x V \ {x0 }. Definition 4 condition (2), (x0 , s(x0 )) 6 sG .
argued above, o0 operator P + (s) may preconditioned s(x0 )
thus precondition o0 6= P + (s). Lastly, say p precondition
responsible operator induced transition oDT G+
x , corresponding original
transition t. Then, since inverse transitions introduce new conditions,
+
(s). then, since
p cond(t) thus p prerop(t) where, definition, rop(t) P<0
+
o0 6= rop(t) P (s), (x0 , s(x0 )) 6 prerop(t) , implies p 6= (x0 , s(x0 )).
Thus (x0 , s(x0 )) 6 R1+ like needed show.
Consider case (b) t0 recoverable side effect deletes. show Definition 2
condition (2b) o0 = rop(t0 ), need prove s(x0 ) oDG+ -relevant,
i.e., s(x0 ) 6 R1+ . already shown above.
case (c), t0 replaceable side effect deletes. Again, show Definition 2 condition
(2c) t0 ), need prove s(x0 ) oDG+ -relevant.
Consider finally conditions imposed non-leaf variables x V \ {x0 }, i.e., Definition 4 condition (4) Definition 2 condition (3). Definition 4 condition (4),
DT Gx transitions every x V \ {x0 } either irrelevant, self-irrelevant deletes,
invertible irrelevant side effect deletes side effects V \ {x0 }.
DT Gx transitions irrelevant cannot oDT G+
x , thus 2nd 3rd case
+
0
true oDT Gx transitions every x V \ {x0 }. concludes argument.
Theorem 3. Let (X, sI , sG , O) planning task, let state 0 <
h+ (s) < . Say x0 X that, every o0 = rop(s(x0 ), c) DT Gx0
(s(x0 ), c) relevant, lDGo0 successful local dependency graph. local
211

fiHoffmann

minimum, ed(s) maxo0 costD (lDGo0 ). If, every lDGo0 , Definition 4
condition (3a) (3b), ed(s) maxo0 costD (lDGo0 ) 1.
Proof. Lemma 5, choice o0 = rop(s(x0 ), c) exists optimal relaxed
plan P + (s) successful optimal rplan dependency graph oDG+ = (V 0 , A0 ) P + (s),
oDG+ sub-graph lDGo0 unique leaf vertex x0 . apply
Lemma 3 obtain local minimum.
see part claim, let V defined Section 6, i.e., V subset
V \ {x0 } DT Gx transitions either irrelevant, invertible
empty conditions, irrelevant side effect deletes, side effects V \ {x0 }. Then,
DT Gx transition x V , satisfies restriction required Lemma 4
+
oDT G+
x transitions irrelevant, cannot oDT Gx , else invertible
irrelevant side effect deletes side effects V \ {x0 } restriction
required Lemma 4 transitions either irrelevant, empty conditions
irrelevant side effect deletes. hence apply Lemma 4 oDG+ , obtain (not
necessarily monotone) path exit, length bound costd (oDG+ ) (s(x0 ), c)
irrelevant side effect deletes replaceable side effect deletes, costd (oDG+ ) + 1
(s(x0 ), c) recoverable side effect deletes. thus suffices show costD (lDGo0 )
costd (oDG+ ). That, however, obvious V V 0 , costD (x) 0 x,
0
maxPath(DT Gx ) diam(oDT G+
x ) x V .
Theorem 4. Let (X, sI , sG , O) planning task. Say global dependency graphs
gDG successful. contain local minima and, state
0 < h+ (s) < , ed(s) maxgDG costD (gDG). If, every gDG, Definition 4
condition (3a) (3b), ed(s) maxgDG costD (gDG) 1.
Proof. Let state. need prove local minimum. h+ (s) = 0
h+ (s) = , nothing show. Else, assume variables X topologically
ordered according strongly connected components SG, let x0 X
uppermost variable x0 XsG sG (x0 ) 6= s(x0 ); obviously, x0 exists. Clearly,
chance x0 satisfy Definition 4 condition (2) exists transitive
successor x0 x0 SG x0 XsG sG (x0 ) 6= s(x0 ) exists x0
strongly connected SG component, x0 XsG (and sG (x0 ) 6= s(x0 )).
then, exists transition t0 DT Gx0 outside condition eventually leading,
backwards chaining SG, x0 . Let gDG0 global dependency graph x0
rop(t0 ) (such gDG0 exists x0 XsG ). Since Definition 3 includes transitive
SG-predecessors x0 pertaining conditions t0 , gDG0 includes x0 . then, since
x0 x0 lie strongly connected component, Definition 3 eventually reaches
x0 . Thus gDG0 contains cycle, contradiction prerequisite. follows
strongly connected SG component x0 contains x0 , thus Definition 4 condition
(2) holds true.
Now, say o0 responsible relevant transition form (s(x0 ), c) DT Gx0 .
exists local dependency graph lDG s, x0 , o0 lDG sub-graph
gDG. follows simple observation Definition 3 include, gDG,
variables arcs include lDG. (Note precondition o0
212

fiAnalyzing Search Topology Without Running Search

x0 , present, satisfied o0 = rop(s(x0 ), c), thus Definition 3
include x0 predecessor achieving o0 preconditions lDG.)
Obviously, given above, lDG successful. Since works choice notirrelevant (s(x0 ), c), apply Theorem 3. claim follows directly
fact costD (gDG) costD (lDG). latter obvious costD increases
monotonically adding additional variables.
A.4 Example Constructions
first example shows that, even within scope basic result, operators
necessarily respected relaxation, i.e., operator may start optimal real plan yet
occur optimal relaxed plan.
Example 1. Consider planning task Figure 4. Variables shown (in dark green)
left hand side respective DTG. Circles represent variable values, lines
represent DTG transitions. Transitions condition longer lines, condition
inscribed line (in blue). variable, dashed arrow indicates value
initial state sI . goal value defined, indicated circled value.
needed, refer operators responsible transition terms respective
variable followed indices start end value. example, operator moving
x c1 c2 referred x12. abbreviate states {(x, c), (y, d)} (c, d).
stick conventions throughout section.

x

d1

c1

c2

d3

c3

d7


d1

d2

d3

d7

Figure 4: Planning task underlying Example 1.
shown Figure 4, DTG x consists three vertices whose connection requires
conditions d1 d3 , alternatively d7 shortcut. domain line
length 6 requiring conditions.
Clearly, support graph planning task acyclic, transitions DTGs
side effects invertible. However, operator y34 (for example) respected
relaxation. see this, note first h+ (sI ) = 4: optimal relaxed plan
hy32, y21, x12, x23i relaxed plan ignores need move back d3 operator x23. hand, optimal (real) plan sI hy34, y45, y56, y67, x17i.
choose use y32 instead, like optimal relaxed plan does, end
sequence hy32, y21, x12, y12, y23, x23i 1 step longer. Hence, sI , y34 starts
optimal plan, start optimal relaxed plan.
213

fiHoffmann

next give three examples showing local minima arise simple situations generalizing basic result minimally. consider, order: cyclic support
graphs; non-invertible transitions; transitions side effects.
Example 2. Consider planning task Figure 5.

x
c1

d1

c2


d1

d2

dn1

dn

c1

Figure 5: Planning task underlying Example 2.
DTG x two vertices whose connection requires condition d1 .
domain line length n requiring conditions, shortcut d1
dn requires c1 condition. Clearly, transitions DTGs side effects
invertible. However, SG contains cycle x mutually
depend other. show mutual dependence causes initial state
sI = {(x, c1 ), (y, d1 )} local minimum, n 5. abbreviate, before, states
{(x, c), (y, d)} (c, d). h+ (sI ) = 2: optimal relaxed plan hx12, y1ni.
consider operators applicable sI = (c1 , d1 ):
Execute x12, leading s1 = (c2 , d1 ) h+ (s1 ) = 2 due hx21, y1ni. here,
new state reached via y12, giving s2 = (c2 , d2 ) h+ (s2 ) = 3 due
hy21, x21, y1ni. (Note n 2 3 prerequisite, relaxed plan composed
yi(i + 1) operators also 3 steps.) h+ (s2 ) > h+ (sI ) way
cannot reach exit monotone path.
Execute y12, leading s3 = (c1 , d2 ) h+ (s3 ) = 3 due hy21, x12, y1ni. (Note
n 2 3 prerequisite, relaxed plan moving ypp operators
4 steps.) Again, path monotone.
Execute y1n, leading s4 = (c1 , dn ) h+ (s4 ) = 2 due hyn1, x12i. here,
new state reached via yn(n1), giving s5 = (c1 , dn1 ) h+ (s5 ) = 3
due hy(n1)n, yn1, x12i. (Note n2 3 prerequisite, relaxed plan
moving d1 via dn2 , . . . , d2 3 + 2 steps.) Again, path monotone.
operators applicable sI , thus explored states reachable sI
monotone paths. None states exit, proving sI local minimum (as
s1 s4 ). is, fact, single state h+ (s) = 1, namely = (c2 , dn1 ).
Clearly, reaching sI takes n 1 steps: first apply x12, traverse d2 , . . . , dn2 .
exit distance sI n 3, thus distance unbounded.
214

fiAnalyzing Search Topology Without Running Search

Section 9, following modification Example 2 considered. set n := 2, i.e.,
domain reduced two values d1 , d2 ; remove line d2 , . . . , dn2 ,
i.e., move via previously short-cut. modified example falls
SAS+ -PUBS tractable class identified Backstrom Klein (1991), still
contains local minimum (the example unsolvable, though).
Example 3. Consider planning task Figure 6.

x
c1

d2

c2

d1

c3


d1

d2

dn

Figure 6: Planning task underlying Example 3. arrow d1 d2 indicates
respective DTG transition directed, i.e., exists transition d2
d1 .
DTG x three vertices whose connection requires (starting initial value
c1 ) first condition d2 , condition d1 . domain circle length n requiring
conditions, invertible except arc d1 d2 .
Clearly, support graph acyclic transitions DTGs side effects.
However, non-invertible arc d1 d2 causes initial state sI = (c1 , d1 )
local minimum n 3. easy see. h+ (sI ) = 3 due
optimal relaxed plan hy12, x12, x23i. Note relaxed plan
move back (y, d1 ) still true executing y12. Now, operators applicable
sI y12 y1n. latter, reaching state sn = (c1 , dn ), immediately increases
value h+ . because, n 3, y1n get closer d2 , moving
farther away d1 (both need achieved). shortest relaxed sn
hyn1, y12, x12, x23i. Alternatively, say apply y12 sI , reaching state s2 = (c1 , d2 ).
h+ (s2 ) = n + 1: need apply, relaxation, x12, n 1 steps complete
circle d2 back d1 , x23. Thus, n 3, s2 larger h+ value sI .
follows sI local minimum. nearest exit sI sn1 = (c2 , dn1 ): sn1
relaxed plan hy(n 1)n, yn1, x23i length 3, applying y(n 1)n get h+
value 2. Reaching sn1 sI takes 1 step moving x n 2 steps moving y.
exit distance sI n 1, thus distance unbounded.
Example 4. Consider planning task Figure 7.
DTG x consists two kinds transitions. First, line c1 , . . . , cn
transitions requiring conditions. Second, direct links, called short-cuts
follows, cn every ci , conditioned value d1 y. DTG contains
two vertices connected unconditionally. Moving d1 d2 side-effect
cn . (That side-effect responsible towards-cn direction short-cuts
DTG x.)
215

fiHoffmann

d1
d1

x
c1

c2

cn

cn


d1

d2

Figure 7: Planning task underlying Example 4. (red) inscription cn line
d1 d2 indicates transition d1 d2 side effect
cn .
support graph acyclic. arc goes x, due short-cuts
DTG x, due operator y12 effect x precondition y.
transitions invertible; particular short-cut both, direction towards
cn vice versa. However, side-effect y12 causes initial state sI = (c1 , d1 )
local minimum n 3.
h+ (sI ) = 1 due optimal relaxed plan hy12i. Note
relaxed plan care side effect y12, c1 still true afterward.
Now, apply operator sI leaves c1 , clearly increase h+ 1:
matter move make, relaxed plan must include y12 move back c1 .
available option sI apply y12. get state s1 = (cn , d2 ). There,
h+ (s1 ) = 2 well, relaxed plan needs re-achieve c1 . Since n 3,
via unconditional sequence cn , . . . , c1 takes 2 steps. alternative use
short-cut xn1 cn c1 ; involves applying y21 first place, giving us
relaxed plan length 2. Hence direct successors sI heuristic value > 1,
sI local minimum. Note also exit distance sI grows n. nearest
exit state goal reached single step. Clearly,
state (c2 , d2 ). shortest path state, sI , applies y12 moves along
unconditional line cn , . . . , c2 , taking 1 + (n 2) = n 1 steps.
next show exit path constructed using short-cuts, leading improved
bound costd instead costd , may non-monotone, improved bound may
indeed under-estimate length shortest monotone exit path.
Example 5. Consider planning task Figure 8.
example, optimal relaxed plan initial state moves z along
path e0 , . . . , e2n note values needed moving moves
d2k+2n , moves x c1 . gives total h+ (sI ) = 2n + (2k + 2n) + 1 = 4n + 2k + 1
steps.
operators applicable sI move z. move along line e0 , . . . , e2n ,
h+ remains constant: always need include moves back order achieve
goal z. reach e2n , move one step, need move z back,
etc. moves, state = d2k+2n , long z stays within
216

fiAnalyzing Search Topology Without Running Search

x
c0


d0

e 2n

d1

e0

e0

e 2n

d2

d2k+2n

c1

d2k

e1

d2k+1 e2

e 2n

d2k+2n

z
e0

e1

e 2n1

e 2n

e

Figure 8: Planning task underlying Example 5.
e0 , . . . , e2n , h+ remains constant. see this, observe first course suffices
relaxed plan reach once, z, values line, taking 2n moves wherever
line; moves before. Second, observe indeed moves
needed: wherever line d0 , . . . , d2k+2n , needs move d2k+2n order
suit x, needs move d0 suit goal. Every value e0 , . . . , e2n appears
condition least one moves. Thus, sI , nearest exit reached
way state = d2k+2n z = e2n : there, move x c1

decreases h+ 4n + 2k. length exit path
described, sI s,
obviously 2k (2n + 1) + 2n 2 = 4kn + 2k + 4n.
happens move z e0 ? Consider first sI . h+ increases
4n + 2k + 2: need reach values line e0 , . . . , e2n , e0 takes one

step more. argument applies state traversed
, because, argued,

state still need reach values line e0 , . . . , e2n . Thus

shortest monotone path exit.
optimal rplan dependency graph oDG+ sI entire SG, oDT G+
z
contains DT Gz except e0 . global dependency graph gDG entire SG.
Clearly, sI , next required value reach variable e2n , construction
proof Theorem 2 first try reach value. using short-cuts
accounted costd (.), exit path constructed move e2n via e0 rather via
line e0 , . . . , e2n , thus claimed exit path monotone.
Finally, consider bound returned costd (oDG+ ). Obviously, costd (oDG+ ) =
costD (gDG). obtain bound (1) + costd (oDG+ ) = (1) + 1[costd (x)] + 1 (2k +

2n)[costd (x) diam(oDT G+
)] + (2k + 2n) (n + 1)[cost (y) diam(DT Gz )]. Note
diam(DT Gz ) = n + 1 DT Gz circle 2n + 2 nodes. Overall,
(1)+costd (oDG+ ) = (2k+2n)(n+2) = 2kn+4k+2n2 +4n. sufficiently large k,
less 4kn+2k +4n, claimed. detail, 4kn+2k +4n > 2kn+4k +2n2 +4n
n2
iff 2kn 2k > 2n2 iff kn k > n2 iff k > n1
. holds, example, set n := 2
k := 5.
reader noticed Example 5 contrived. reason need
complicated unrealistic example costd , costd , contains two
sources over-estimation, cf. discussion Section 5. particular, every move non217

fiHoffmann

leaf variables supposed take whole oDT G+ /DT G diameter. show costd
general upper bound length monotone exit path, thus need presented
construction around k under-estimation considering diam(DT Gz ) instead
diam(oDT G+
z ) outweighs over-estimation. Importantly, constructing examples
short-cuts temporarily increase h+ (but costd nevertheless delivers upper bound
monotone exit path length) much easier. needs happen that, whatever
reason, variable z like here, currently required value (e2n Example 5)
reached oDT G+
z values along unnecessarily long path whose values needed
relaxed plan. happens quite naturally, e.g., transportation domains
vehicle needs load/unload objects along longer path.
demonstrate that, case analyses apply, exit distance may
exponential.
Example 6. Consider planning task Figure 9.

x0
c 10

x1
c 11

c 52

c 21

c 12

c 51

c 31

c 20

c 52

c 12

c 41

c 51

xn
c 1n

c 2n

c 3n

c 4n

c 5n

Figure 9: Planning task underlying Example 6.
DTG x0 two vertices whose connection conditioned c15 .
variables xi , five vertices line, alternatingly requiring last vertex ci+1

5
i+1
xi+1 first vertex c1 xi+1 . Clearly, optimal rplan dependency graph
oDG+ sI , global dependency graph gDG task full support
graph SG. acyclic, transitions invertible side effects, thus
analyses apply.
h+ (sI ) ed(sI )? relaxed plan, need move x0 c02 . Due
conditioning, variable extreme values left right hand side
required need 4 moves xi 1 n. Thus h+ (sI ) = 1 + 4n.
Now, consider state s(x0 ) = c01 . construct relaxed plan, obviously
still need 1 move x0 . also still need 4 moves variable. Consider x1 .
s(x1 ) = c11 need move c15 order able move x0 . s(x1 ) = c12
need move c15 order able move x0 , c11 goal,
forth. cases, four transitions must taken relaxed plan. Due
conditioning, recursively true variables. Thus, h+ (s) = 1 + 4n.
218

fiAnalyzing Search Topology Without Running Search

means nearest exit state s0 x0 value c01 x1 value c15 :
s0 , move x0 afterward, definitely, 4n steps suffice relaxed plan.
distance state s0 ? need move x1 four times. Lets denote d(x1 ) = 4.
move requires 4 moves x2 , d(x2 ) = 16. sequence moves x2 inverses
direction three times. points, x3 need move d(x3 ) = (d(x2 ) 3) 4.
Generalizing this, get d(xi+1 ) = [d(xi ) ( d(x4 ) 1)] 4 = 3d(xi ) + 4, growth
n exponential.
Obviously, Example 6 also shows plan length exponential cases
Theorem 4 applies. remark Example 6 similar example given
Domshlak Dinitz (2001). difference Domshlak Dinitzs example
uses different conditions transitions left/to right, enables
use smaller DTGs 3 nodes. setting, cannot use different conditions
need transitions invertible. causes loss exit path steps
situations next lower variable inverses direction thus relies
outside condition previous step. Indeed, DTGs size 3, loss
steps results polynomially bounded exit distance. recursive formula d(xi )
becomes d(xi+1 ) = [d(xi ) ( d(x2 ) 1)] 2 = d(xi ) + 2, resulting ed(sI ) = n2 + n.
hand, costd costD still remain exponential case,
consider loss incurred inversing
directions. Precisely, easy see
P
costd (oDG+ ) = costD (gDG) = 1 + ni=1 2i = 2n+1 1. proves bounds
over-estimate exponential amount.
next example shows exit path constructed (implicitly) analyses may
exponentially longer optimal plan task.
Example 7. Consider planning task Figure 10.

x0
c 10

c 51

c 20

c10

x1
c 11

c 52

c 21

0
c4n+1

c 12

c 31

c 52

c 12

c 41

xn
c 1n

c 2n

c 3n

c 4n

c 5n

Figure 10: Planning task underlying Example 7.
219

c 51

fiHoffmann

example, optimal relaxed plan initial state
Example 6, alternative route via c001 , . . . , c00(4n+1) takes 1 + 4n + 1 = 4n + 2 >
4n + 1 steps. Thus exit path constructed remains same, too, length exponential
n. However, length shortest plan 4n + 2.
Note Example 7 observed weakness guided wrong direction
caused weakness optimal relaxed planning, rather weakness
analysis. relaxation overlooks fact moving via x1 , . . . , xn incur high costs
due need repeatedly undo re-do conditions achieved beforehand. Note also
that, example too, get exponential over-estimation exit distance.
finally show feeding Theorem 2 non-optimal relaxed plans give
guarantees:
Example 8. Consider planning task Figure 11.

x
c1
g21

d2

c2

g2n+2

c

v1


d1

en

d2

g11

g21

g1n+2

g2n+2

v n+2

z
e1

e n1

en

Figure 11: Planning task underlying Example 8. arrow en1 en indicates
respective DTG transition directed, i.e., exists transition
en en1 .
two ways achieve goal c2 : either via moving z, moving
v1 , . . . , vn+2 . optimal relaxed plan chooses former option, giving h+ (sI ) = n+1.
soon n 3, however, parallel-optimal relaxed plan P + (sI ) chooses latter
option moving z results n + 1 sequential moves, whereas v1 , . . . , vn+2
moved parallel, giving parallel length 3.
Consider happens h+ either options. move z, h+ remains
constant need move z back goal. soon reach z = en ,
h+ = last transition uni-directional longer achieve
goal z. Thus exit path, particular monotone exit path, via
option.
Say move v1 , . . . , vn+2 instead. first move (whichever vi choose), h+
increases shortest option undo move go via z: takes
n + 2 steps whereas completing vi moves going via c0 takes (n + 1) + 2 = n + 3 steps.
220

fiAnalyzing Search Topology Without Running Search

Thus monotone exit path via option either, sI local minimum.
completing n + 2 moves vi moving x = c0 , h+ = (n + 2) + 1 due
shortest relaxed plan moves back vi moves x = c2 . reduce heuristic
value initial value h+ (sI ) = n + 1, need execute 2 steps.
state reached better evaluated neighbor, exit distance n + 5.
Consider effect feeding Theorem 2 parallel-optimal plan P + (sI ).
Clearly, optimal rplan dependency graph oDG+ constructed P + (sI ) consists x
vi variables, include z. Thus theorem applies,
wrongly concludes sI local minimum.
exit distance bound computed
P
(1

1)[costd (x) diam(DT Gvi )] = n + 2.
(1) + costd (oDG+ ) = (1) + 1[costd (x)] + n+2
i=1
less actual distance ed(sI ) = n + 5, thus result also wrong.
Say modify Example 8 making last transition z undirected, making
one vi transitions unidirectional right. v1 , . . . , vn+2 option leads
dead end, whereas y, z option succeeds. particular, Theorem 2 apply
oDG+ constructed parallel-optimal relaxed plan P + (sI ), thus example
using non-optimal relaxed plans results loss information.
A.5 Benchmark Performance Guarantees
give definitions 7 domains mentioned Propositions 1 2. domain,
explain respective property claimed holds true. domains,
assume static properties used PDDL capture unchanging things like
shape road network transportation domain. assume follows
static predicates removed prior analysis, i.e., prior testing
prerequisites Theorem 4.
Definition 5. Logistics domain set planning tasks = (V, O, sI , sG ) whose
components defined follows. V = P V P set package-location variables
p, Dp = L V L set representing possible locations, V set
vehicle-location variables v, Dv = Lv subset Lv L locations. contains
three types operators: move, load, unload, move(v, l1, l2) = ({v =
l1}, {v = l2}) l1 6= l2, load(v, l, p) = ({v = l, p = l}, {p = v}), unload(v, l, p) =
({v = l, p = v}, {p = l}). sI assigns arbitrary value variables, sG
assigns arbitrary value subset variables.
Every global dependency graph gDG Logistics either package p leaf
variable x0 , vehicle variable v leaf variable x0 . latter case gDG
consists x0 , arcs. former case, o0 preconditioned single vehicle
v only, leading single non-leaf variable v. cases, gDG acyclic, involved
transitions side effects, involved transitions invertible. Thus
apply Theorem 4. costD (gDG) = 1 + 1 1 packages costD (gDG) = 1
vehicles, thus overall obtain correct bound 1.
Definition 6. Miconic-STRIPS domain set planning tasks =
(V, O, sI , sG ) whose components defined follows. V = B {e}
|O| = |D| = |B| = |S| and: set passenger-origin variables o, = L L
221

fiHoffmann

set representing possible locations (floors); set passenger-destination
variables Dd = L; B set passenger-boarded variables b Db = {1, 0};
set passenger-served variables Ds = {1, 0}; e elevator-location variable
De = L. contains three types operators: move, board, depart,
move(l1, l2) = ({e = l1}, {e = l2}) l1 6= l2, board(l, i) = ({e = l, oi = l}, {bi = 1}),
depart(l, i) = ({e = l, di = l, bi = 1}, {bi = 0, si = 1}). sI assigns arbitrary locations
variables O, D, e, assigns 0 variables B S. sG assigns 1 variables
S.
Passenger-origin passenger-destination variables static, i.e., affected
operator. Thus common pre-processes remove variables, using
statically prune set operators reachable. assume follows
removal taken place.
Every global dependency graph gDG Miconic-STRIPS passenger-served variable
si leaf variable x0 . leads non-leaf variables bi e, arcs e
variables bi si . Clearly, gDG acyclic. transitions e
invertible side effects. transition (0, 1) bi (is invertible since
departing different condition e but) irrelevant own-delete bi = 0
occur anywhere goal preconditions side effects thus irrelevant
side effect deletes. transition (1, 0) bi (is invertible but) irrelevant bi = 0
doesnt occur anywhere. transition (0, 1) leaf variable si self-irrelevant side
effect deletes bi = 1 occurs precondition transitions responsible
operator rop(0, 1) = depart(ld , i). Hence apply Theorem 4. delivers bound
costD (gDG) 1 = 1 + 1[si ] + (1 1)[costD (si ) maxPath(DT Gbi )] + (2 1)[(costD (si ) +
costD (bi )) diam(DT Ge )] = 3.
Definition 7. Simple-TSP domain set planning tasks = (V, O, sI , sG )
whose components defined follows. V = {p} V where: p position variable,
Dp = L L set representing possible locations; V , |V | = |L|,
set location-visited variables v, Dv = {1, 0}. contains single type
operators: move(l1, l2) = ({p = l1}, {p = l2, vl2 = 1}) l1 6= l2. sI assigns arbitrary
value p assigns 0 variables V . sG assigns 1 variables V .
Every global dependency graph gDG Simple-TSP location-visited variable vi
leaf variable x0 . leads single non-leaf variable p. Clearly, gDG acyclic.
Every transition (0, 1) vi considered, induced o0 = move(l1, li), replaceable side
effect deletes. operator = move(l1, x) replaced equivalent operator
move(li, x) unless x = li. latter case, o0 = excluded
definition replaceable side effect deletes. Every transition (l1, l2) p clearly invertible;
irrelevant side effect delete vl2 = 0; side effect vl2
non-leaf variable gDG. Hence apply Theorem 4. delivers bound
costD (gDG) 1 = 1 + 1[vi ] + (1 1)[costD (vi ) diam(DT Gp )] = 1.
consider extended version Movie domain, sense that, whereas
original domain version considers fixed range snacks (and thus state space
constant across domain instances), allow scale number different snacks.25
25. original domain version allows scale number operators adding snack.
operators identical, removed trivial pre-processes.

222

fiAnalyzing Search Topology Without Running Search

Definition 8. Movie domain set planning tasks = (V, O, sI , sG )
whose components defined follows. V = {c0, c2, re} H. Here, c0 counterat-zero variable, Dc0 = {1, 0}; c2 counter-at-two-hours variable,
Dc2 = {1, 0}; movie-rewound variable, Dre = {1, 0}; H have-snack
variables h Dh = {1, 0}. contains four types operators: rewindTwo, rewindOther, resetCounter, getSnack, rewindT wo = ({c2 = 1}, {re = 1}),
rewindOther = ({c2 = 0}, {re = 1, c0 = 0}), resetCounter = (, {c0 = 1}),
getSnack(i) = (, {hi = 1}). sI assigns arbitrary value variables. sG assigns
re, c0, H variables 1.
Note that, depending value static variable c2, operator set
different: sI (c2) = 1 rewindOther removed, sI (c2) = 0 rewindT wo
removed. refer former case (a) latter case (b).
Every global dependency graph gDG consists single (leaf) variable. transitions
h variable side effects thus irrelevant side effect deletes.
transition (0, 1) c0 side effects thus irrelevant side effect deletes.
transition (1, 0) c0 irrelevant. case (a), transition (0, 1) side
effects thus irrelevant side effect deletes apply Theorem 4. case (b),
transition (0, 1) side effect c0 = 0. Observe (1) fact
irrelevant; (2) ctx(0, 1) {c0 = 1}, := resetCounter satisfies
= preo (prevrop(0,1) eff rop(0,1) ) = {re = 1, c0 = 0}, {c0
= 1} = eff = {c0 = 1},
{c0 = 1} = eff {(y, d) | (y, d) , (y, d) sG rop(c,c0 )6=o0 preo0 } = {c0 = 1}.
Thus transition recoverable side effect deletes, apply Theorem 4.
case (a), gDGs bound costD (gDG) 1 applies. Obviously, costD (gDG) = 1
thus obtain correct bound 0. case (b), bound costD (gDG) applies,
costD (gDG) = 1 obtain correct bound 1.
Definition 9. Ferry domain set planning tasks = (V, O, sI , sG ) whose
components defined follows. V = C {f, e} where: C set car-location
variables c, Dc = L {f } L set representing possible locations; f
ferry-location variable Df = L; e ferry-empty variable De = {1, 0}.
contains three types operators: sail, board, debark, sail(l1, l2) =
({f = l1}, {f = l2}) l1 6= l2, board(l, c) = ({f = l, c = l, e = 1}, {c = f, e = 0}),
debark(l, c) = ({f = l, c = f }, {c = l, e = 1}). sI assigns 1 variable e, assigns
arbitrary value variable f , assigns arbitrary value f variables
C. sG assigns arbitrary value 6= f (some subset ) variables C f .
Let arbitrary reachable state 0 < h+ (s) < , let P + (s)
arbitrary optimal relaxed plan s. always apply Theorem 2. show this,
distinguish three cases: (a) s(e) = 1, o0 = board(l, c) first board operator P + (s),
set x0 = c; (b) s(e) = 0, o0 = debark(l, c) first debark operator P + (s),
set x0 = c; (c) P + (s) contains board debark operator set o0
first operator, sail(l1, l2), P + (s), x0 = f . Obviously, exactly one cases
hold s. Let oDG+ = (V, A) sub-graph SG including x0 variables/arcs
included per Definition 1. Let t0 transition taken o0 .
case (a), obviously reorder P + (s) either board(l, c) first operator
P + (s), predecessors sail operators. oDG+ either (1) includes new
223

fiHoffmann

(non-leaf) variables all, (2) includes f . f , clearly transitions
invertible side effects. transition t0 effect (c, f ) deleting (c, l)
clearly needed rest P + (s). side effect e = 0 deleting e = 1.
latter fact may needed board operators P + (s). However, necessarily
P + (s) contains operator form debark(l0 , c), applicable board(l, c)
sequence moves P + (s) must contain l l0 ; debark(l0 , c) recovers e = 1.
+
Thus oDG+ -relevant deletes t0 P>0
(s)-recoverable. case (b), similarly
+
reorder P (s) either (1) debark(l, c) first operator P + (s), (2)
predecessors sail operators. transition t0 effect (c, l) deleting (c, f )
clearly needed rest P + (s); side effect e = 1 deleting e = 0
clearly needed rest P + (s). Thus, again, oDG+ -relevant deletes
+
+
t0 P>0
(s)-recoverable (the recovering sub-sequence P>0
(s) empty
+
recovery required). case (c), finally, oDG contains f , t0 side effects,
delete (f, l1) needed anymore (in fact, case l2 must goal
f , P + (s) contains single operator o0 ). Hence, cases, apply
Theorem 2. costd (oDG+ ) = 1 cases (a1), (b1), (c) get bound 0.
costd (oDG+ ) = 1 + diam(DT Gf ) = 2 cases (a2) (b2) get bound 1.
Definition 10. Gripper domain set planning tasks = (V, O, sI , sG )
whose components defined follows. V = {ro, f1 , f2 } B. Here, ro robotlocation variable, Dro = {L, R}; f1 , f2 gripper-free variables, Df1 = Df2 =
{1, 0}; B ball-location variables, Db = {L, R, 1, 2}. contains three types
operators: move, pickup, drop, move(l1, l2) = ({ro = l1}, {ro = l2})
l1 6= l2, pickup(g, b, l) = ({ro = l, b = l, fg = 1}, {b = g, fg = 0}), drop(g, b, l) = ({ro =
l, b = g}, {b = l, fg = 1}). sI assigns L ro, assigns 1 f1 f2 , assigns L
variables B. sG assigns R variables B.
Let arbitrary reachable state 0 < h+ (s) < , let P + (s)
arbitrary optimal relaxed plan s. always apply Theorem 2. distinguish
two cases: (a) exists b B s(b) = g g {1, 2}, o0 = drop(g, b, R),
set x0 = b; (b) exists b B s(b) = g g {1, 2}, o0 = pickup(g, b, L)
b B P + (s), set x0 = b. Obviously, exactly one cases
hold s. Let oDG+ = (V, A) sub-graph SG including x0 variables/arcs
included per Definition 1. Let t0 transition taken o0 .
case (a), obviously reorder P + (s) either drop(g, b, R) first
operator P + (s), predecessor move(L, R). oDG+ either (1) includes
new (non-leaf) variables all, (2) includes ro. ro, clearly transitions
invertible side effects. transition t0 effect (b, R) deleting
(b, g) clearly needed rest P + (s); side effect fg = 1 deleting
fg = 0 clearly needed rest P + (s). Thus oDG+ -relevant deletes
+
t0 P>0
(s)-recoverable. case (b), similarly reorder P + (s) either (1)
pickup(g, b, L) first operator P + (s), (2) predecessor move(R, L).
transition t0 effect (b, g) deleting (b, L) clearly needed rest
P + (s). side effect fg = 0 deleting fg = 1; latter fact may needed
pickup operators P + (s). However, necessarily P + (s) contains operators move(L, R)
drop(g, b, R), applicable board(l, c); drop(g, b, R) recovers fg = 1. Thus,
224

fiAnalyzing Search Topology Without Running Search

+
again, oDG+ -relevant deletes t0 P>0
(s)-recoverable. Hence, cases,

+
apply Theorem 2. cost (oDG ) = 1 cases (a1) (b1), get bound 0.
costd (oDG+ ) = 1 + diam(ro) = 2 cases (a2) (b2) get bound 1.

Definition 11. Transport domain set planning tasks = (V, O, sI , sG )
whose components defined follows. V = P V E C where: P set packagelocation variables p, Dp = L V E L set representing possible
locations; V E set vehicle-location variables v, Dv = L; C set
vehicle-capacity variables cv , Dcv = {0, . . . , K} K maximum capacity.
contains three types operators: drive, pickup, drop, where: drive(v, l1, l2) =
({v = l1}, {v = l2}) (l1, l2) R GR = (L, R) undirected graph roads
L; pickup(v, l, p, c) = ({v = l, p = l, cv = c}, {p = v, cv = c 1}), drop(v, l, p, c) =
({v = l, p = v, cv = c}, {p = l, cv = c + 1}). sI assigns arbitrary value L
variables P V E, assigns K variables C. sG assigns arbitrary value
L subset variables P V E.
Note use numbers addition/subtraction. are, course, part
planning language consider here. However, easily encoded (on
finite set number {0, . . . , K}) via static predicates. pre-processing, effect
resulting task isomorphic one obtained simple arithmetic above,
thus choose reduce notational clutter.
Let arbitrary reachable state 0 < h+ (s) < . exists
optimal relaxed plan P + (s) apply Theorem 2. distinguish three
cases: (a) exists p P s(p) = v v V E, o0 = drop(v, l, p, c)
s(cv ) = c P + (s), set x0 = p; (b) exists p P s(p) = v
v V E, o0 = pickup(v, l, p, K) p P P + (s), set x0 = p; (c) P + (s)
contains drop pickup operator set o0 first operator, drive(v, l1, l2),
P + (s), x0 = v. Obviously, choose P + (s) exactly one cases
hold (the choice P + (s) arbitrary (b) (c), (a) may exist optimal
relaxed plans s(cv ) 6= c). Let oDG+ = (V, A) sub-graph SG including x0
variables/arcs included per Definition 1. Let t0 transition taken o0 .
case (a), obviously reorder P + (s) either o0 = drop(v, l, p, c) first
operator P + (s), predecessors drive operators. oDG+ either (1) includes
new (non-leaf) variables all, (2) includes v. v, clearly transitions
invertible side effects. transition t0 effect (p, v) deleting
(p, l) clearly needed rest P + (s). side effect cv = c+1 deleting
cv = c. latter fact may needed operators P + (s), either taking form
drop(v, l0 , p0 , c) form pickup(v, l0 , p0 , c). Clearly, P + (s) contains operators
replace drop(v, l0 , p0 , c + 1) pickup(v, l0 , p0 , c + 1) respectively
value (cv , c + 1) true point (relaxed) execution. Thus
choose P + (s) P + (s)-relevant deletes t0 P + (s)-recoverable V \ {x0 }.
case (b), similarly reorder P + (s) either (1) o0 = pickup(v, l, p, K)
first operator P + (s), (2) predecessors drive operators. transition t0
effect (p, v) deleting (p, l) clearly needed rest P + (s).
side effect cv = K 1 deleting cv = K. latter fact may needed
operators P + (s), taking form pickup(v, l0 , p0 , K). However, necessarily P + (s)
225

fiHoffmann

contains operator form drop(v, l0 , p, c0 ). c0 6= K 1 replace
operator drop(v, l0 , p, K 1) since, clearly, value (cv , K 1) true
point (relaxed) execution. Now, drop(v, l0 , p, K 1) applicable pickup(v, l, p, K)
sequence drive operators P + (s) must contain l l0 ; drop(v, l0 , p, K 1)
recovers cv = K. Thus, again, choose P + (s) P + (s)-relevant deletes
t0 P + (s)-recoverable V \ {x0 }. case (c), finally, oDG+ contains v, t0
side effects, delete (v, l1) needed anymore. Hence, cases,
apply Theorem 2. costd (oDG+ ) = 1 cases (a1), (b1), (c) get bound
0. costd (oDG+ ) = 1 + min(diam(oDT G+
v ), diam(DT Gv )) cases (a2) (b2)
bound diameter road map GR .
ignoring action costs, Elevators domain IPC 2008 essentially variant
Transport. variant general (a) vehicle (each elevator) may
maximal capacity, (b) vehicle reach subset locations, i.e.,
vehicle individual road map. hand, Elevators restricted
Transport (c) vehicle road map fully connected (every reachable floor
navigated directly every reachable floor), (d) goals exist
packages (passengers, is), vehicles. Even ignoring restrictions (c) (d),
trivial see arguments given Transport still hold true. Therefore,
whenever reachable state 0 < h+ (s) < , exists optimal relaxed plan
P + (s) apply Theorem 2. before, bound diameter
road map. Due (c), diameter 1.

References
Backstrom, C., & Klein, I. (1991). Planning polynomial time: SAS-PUBS class.
Computational Intelligence, 7 (4).
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90 (1-2), 279298.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1
2), 533.
Botea, A., Muller, M., & Schaeffer, J. (2004). Using component abstraction automatic
generation macro-actions. Koenig et al. (Koenig, Zilberstein, & Koehler, 2004),
pp. 181190.
Brafman, R., & Domshlak, C. (2003). Structure complexity planning unary
operators. Journal Artificial Intelligence Research, 18, 315349.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69 (12), 165204.
Cesta, A., & Borrajo, D. (Eds.), ECP01 (2001). Recent Advances AI Planning. 6th
European Conference Planning (ECP01), Lecture Notes Artificial Intelligence,
Toledo, Spain. Springer-Verlag.
226

fiAnalyzing Search Topology Without Running Search

Chen, H., & Gimenez, O. (2010). Causal graphs structurally restricted planning. Journal Computer System Sciences, 76 (7), 579592.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent offline coordination: Structure complexity. Cesta & Borrajo (Cesta & Borrajo, 2001), pp. 3443.
Edelkamp, S., & Helmert, M. (1999). Exhibiting knowledge planning problems minimize state encoding length. Biundo, S., & Fox, M. (Eds.), Recent Advances AI
Planning. 5th European Conference Planning (ECP99), Lecture Notes Artificial
Intelligence, pp. 135147, Durham, UK. Springer-Verlag.
Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal
Artificial Intelligence Research, 9, 367421.
Fox, M., & Long, D. (1999). detection exploitation symmetry planning
problems. Pollack, M. (Ed.), Proceedings 16th International Joint Conference Artificial Intelligence (IJCAI99), pp. 956961, Stockholm, Sweden. Morgan
Kaufmann.
Garey, M. R., & Johnson, D. S. (1979). Computers IntractabilityA Guide
Theory NP-Completeness. Freeman, San Francisco, CA.
Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), ICAPS09 (2009). Proceedings
19th International Conference Automated Planning Scheduling (ICAPS9),
Thessaloniki, Greece. AAAI.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local search
temporal action graphs. Journal Artificial Intelligence Research, 20, 239290.
Gerevini, A., & Schubert, L. (1998). Inferring state-constraints domain independent
planning. Mostow, J., & Rich, C. (Eds.), Proceedings 15th National Conference American Association Artificial Intelligence (AAAI98), pp. 905912,
Madison, WI, USA. MIT Press.
Gimenez, O., & Jonsson, A. (2008). complexity planning problems simple
causal graphs. Journal Artificial Intelligence Research, 31, 319351.
Gimenez, O., & Jonsson, A. (2009a). influence k-dependence complexity
planning. Gerevini et al. (Gerevini, Howe, Cesta, & Refanidis, 2009), pp. 138145.
Gimenez, O., & Jonsson, A. (2009b). Planning chain causal graphs variables
domains size 5 NP-hard. Journal Artificial Intelligence Research, 34, 675706.
Haslum, P. (2007). Reducing accidental complexity planning problems. Veloso, M.
(Ed.), Proceedings 20th International Joint Conference Artificial Intelligence
(IJCAI07), pp. 18981903, Hyderabad, India. Morgan Kaufmann.
Helmert, M. (2003). Complexity results standard benchmark domains planning.
Artificial Intelligence, 143, 219262.
Helmert, M. (2004). planning heuristic based causal graph analysis.. Koenig et al.
(Koenig et al., 2004), pp. 161170.
Helmert, M. (2006). fast downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
227

fiHoffmann

Helmert, M. (2009). Concise finite-domain representations PDDL planning tasks. Artificial Intelligence, 173 (5-6), 503535.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats
difference anyway? Gerevini et al. (Gerevini et al., 2009), pp. 162169.
Hoffmann, J. (2003). Utilizing Problem Structure Planning: Local Search Approach,
Vol. 2854 Lecture Notes Artificial Intelligence. Springer-Verlag.
Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning
benchmarks. Journal Artificial Intelligence Research, 24, 685758.
Hoffmann, J., & Nebel, B. (2001a). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J., & Nebel, B. (2001b). RIFO revisited: Detecting relaxed irrelevance. Cesta
& Borrajo (Cesta & Borrajo, 2001), pp. 325336.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. Journal
Artificial Intelligence Research, 22, 215278.
Jonsson, A. (2009). role macros tractable planning. Journal Artificial Intelligence Research, 36, 471511.
Jonsson, P., & Backstrom, C. (1995). Incremental planning. European Workshop
Planning.
Jonsson, P., & Backstrom, C. (1998). State-variable planning structural restrictions:
Algorithms complexity. Artificial Intelligence, 100 (1-2), 125176.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C.
(Ed.), Proceedings 21st International Joint Conference Artificial Intelligence
(IJCAI09), pp. 17281733, Pasadena, CA, USA. Morgan Kaufmann.
Katz, M., & Domshlak, C. (2008a). New islands tractability cost-optimal planning.
Journal Artificial Intelligence Research, 32, 203288.
Katz, M., & Domshlak, C. (2008b). Structural patterns heuristics via fork decomposition.
Rintanen, J., Nebel, B., Beck, J. C., & Hansen, E. A. (Eds.), Proceedings
18th International Conference Automated Planning Scheduling (ICAPS08),
pp. 182189, Sydney, Australia. AAAI.
Knoblock, C. (1994). Automatically generating abstractions planning. Artificial Intelligence, 68 (2), 243302.
Koenig, S., Zilberstein, S., & Koehler, J. (Eds.), ICAPS04 (2004). Proceedings
14th International Conference Automated Planning Scheduling (ICAPS04),
Whistler, Canada. AAAI.
Long, D., & Fox, M. (2000). Automatic synthesis use generic types planning.
Chien, S., Kambhampati, R., & Knoblock, C. (Eds.), Proceedings 5th International Conference Artificial Intelligence Planning Systems (AIPS00), pp. 196205,
Breckenridge, CO. AAAI Press, Menlo Park.
McDermott, D. V. (1999). Using regression-match graphs control search planning.
Artificial Intelligence, 109 (1-2), 111159.
228

fiAnalyzing Search Topology Without Running Search

Nebel, B., Dimopoulos, Y., & Koehler, J. (1997). Ignoring irrelevant facts operators
plan generation. Steel, S., & Alami, R. (Eds.), Recent Advances AI Planning. 4th
European Conference Planning (ECP97), Vol. 1348 Lecture Notes Artificial
Intelligence, pp. 338350, Toulouse, France. Springer-Verlag.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. Fox, D., & Gomes,
C. (Eds.), Proceedings 23rd National Conference American Association
Artificial Intelligence (AAAI08), pp. 975982, Chicago, Illinois, USA. MIT Press.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime
planning landmarks. Journal Artificial Intelligence Research, 39, 127177.
Rintanen, J. (2000). iterative algorithm synthesizing invariants. Kautz, H. A.,
& Porter, B. (Eds.), Proceedings 17th National Conference American
Association Artificial Intelligence (AAAI00), pp. 806811, Austin, TX, USA.
MIT Press.
Roberts, M., & Howe, A. (2009). Learning planner performance. Artificial Intelligence,
173, 636561.
Vidal, V. (2004). lookahead strategy heuristic search planning. Koenig et al.
(Koenig et al., 2004), pp. 150160.
Williams, B. C., & Nayak, P. P. (1997). reactive planner model-based executive.
Pollack, M. (Ed.), Proceedings 15th International Joint Conference Artificial
Intelligence (IJCAI97), pp. 11781185, Nagoya, Japan. Morgan Kaufmann.

229

fiJournal Artificial Intelligence Research 41 (2011) 397-406

Submitted 05/11; published 07/11

Research Note
Policy Invariance Reward Transformations
General-Sum Stochastic Games
Xiaosong Lu
Howard M. Schwartz

LUXIAOS @ SCE . CARLETON . CA
SCHWARTZ @ SCE . CARLETON . CA

Department Systems Computer Engineering
Carleton University
1125 Colonel Drive, Ottawa, K1S 5B6 Canada

Sidney N. Givigi Jr.

IDNEY.G IVIGI @ RMC . CA

Department Electrical Computer Engineering
Royal Military College Canada
13 General Crerar Cres, Kingston, K7K 7B4 Canada

Abstract
extend potential-based shaping method Markov decision processes multi-player
general-sum stochastic games. prove Nash equilibria stochastic game remains
unchanged potential-based shaping applied environment. property policy
invariance provides possible way speeding convergence learning play stochastic
game.

1. Introduction
reinforcement learning, one may suffer temporal credit assignment problem (Sutton &
Barto, 1998) reward received sequence actions. delayed reward lead
difficulty distributing credit punishment action long sequence actions
cause algorithm learn slowly. example problem found
episodic tasks soccer game player given credit punishment
goal scored. number states soccer game large, take long time
player learn equilibrium policy.
Reward shaping technique improve learning performance reinforcement learner
introducing shaping rewards environment (Gullapalli & Barto, 1992; Mataric, 1994).
state space large, delayed reward slow learning dramatically.
speed learning, learner may apply shaping rewards environment supplement
delayed reward. way, reinforcement learning algorithm improve learning
performance combining "good" shaping reward function original delayed reward.
applications reward shaping found literature (Gullapalli & Barto, 1992;
Dorigo & Colombetti, 1994; Mataric, 1994; Randlv & Alstrm, 1998). Gullapalli Barto (1992)
demonstrated application shaping key-press task robot trained press keys
keyboard. Dorigo Colombetti (1994) applied shaping policies robot perform
predefined animate-like behavior. Mataric (1994) presented intermediate reinforcement function
group mobile robots learn foraging task. Randlv Alstrm (1998) combined reinforcement learning shaping make agent learn drive bicycle goal. theoretical
c
2011
AI Access Foundation. rights reserved.

fiL U , CHWARTZ , & G IVIGI

analysis reward shaping found literature (Ng, Harada, & Russell, 1999; Wiewiora,
2003; Asmuth, Littman, & Zinkov, 2008). Ng et al. (1999) presented potential-based shaping
reward guarantee policy invariance single agent Markov decision process
(MDP). Ng et al. proved optimal policy keeps unchanged adding potential-based
shaping reward MDP environment. Following Ng et al., Wiewiora (2003) showed effects potential-based shaping achieved particular initialization Q-values agents
using Q-learning. Asmuth et al. (2008) applied potential-based shaping reward model-based
reinforcement learning approach.
articles focus applications reward shaping single agent MDP.
applications reward shaping general-sum games, Babes, Munoz de Cote, Littman (2008)
introduced social shaping reward players learn equilibrium policies iterated
prisoners dilemma game. theoretical proof policy invariance reward
transformation. research, prove Nash equilibria potential-based shaping
reward transformation (Ng et al., 1999) also Nash equilibria original game
framework general-sum stochastic games. Note similar work Devlin Kudenko
(2011) published article review. Devlin Kudenko proved
sufficiency based proof technique introduced Asmuth et al. (2008), prove
sufficiency necessity using different proof technique article.

2. Framework Stochastic Games
Stochastic games first introduced Shapley (1953). stochastic game, players choose
joint action move one state another state based joint action choose.
section, framework stochastic games, introduce Markov decision processes, matrix
games stochastic games respectively.
2.1 Markov Decision Processes
Markov decision process tuple (S, A, T, , R) state space, action space,
: [0, 1] transition function, [0, 1] discount factor R : R
reward function. transition function denotes probability distribution next states
given current state action. reward function denotes received reward next state
given current action current state. Markov decision process following Markov
property: players next state reward depend players current state action.
players policy : defined probability distribution players actions given
state. optimal policy maximize players discounted future reward. MDP,
exists deterministic optimal policy player (Bertsekas, 1987).
Starting current state following optimal policy thereafter, get optimal
state-value function expected sum discounted rewards (Sutton & Barto, 1998)
)
(
V (s) = E




j rk+ j+1 |sk = s,

(1)

j=0

k current time step, rk+ j+1 received immediate reward time step k + j + 1,
[0, 1] discount factor, final time step. (1), task
infinite-horizon task task run infinite period. task episodic,
398

fiP OLICY NVARIANCE



R EWARD RANSFORMATIONS

defined terminal time episode terminated time step . call
state episode ends terminal state sT . terminal state, state-value function
always zero V (sT ) = 0 sT S. Given current state action a, following
optimal policy thereafter, define optimal action-value function (Sutton & Barto, 1998)
h



(2)
Q (s, a) = (s, a, ) R(s, a, ) + V (s )


(s, a, ) = Pr {sk+1 = |sk = s, ak = a} probability next state sk+1 =
given current state sk = action ak = time step k, R(s, a, ) = E{rk+1 |sk = s, ak = a,
sk+1 = } expected immediate reward received state given current state action
a. terminal state, action-value function always zero Q(sT , a) = 0 sT S.
2.2 Matrix Games
matrix game tuple (n, A1 , . . . , , R1 , . . . , Rn ) n number players, Ai (i = 1, . . . , n)
action set player Ri : A1 R payoff function player i.
matrix game game involving multiple players single state. player i(i = 1, . . . , n)
selects action action set Ai receives payoff. player payoff function Ri
determined players joint action joint action space A1 . two-player matrix
game, set matrix element containing payoff joint action pair.
payoff function Ri player i(i = 1, 2) becomes matrix. two players game
fully competitive, two-player zero-sum matrix game R1 = R2 .
matrix game, player tries maximize payoff based players strategy.
players strategy matrix game probability distribution players action set. evaluate players strategy, introduce following concept Nash equilibrium. Nash equilibrium
matrix game collection players policies (1 , , n )
Vi (1 , , , , n ) Vi (1 , , , , n ), , = 1, , n

(3)

Vi () expected payoff player given players current strategies
strategy player strategy space . words, Nash equilibrium collection
strategies players player better changing strategy given
players continue playing Nash equilibrium policies (Basar & Olsder, 1999). define
Qi (a1 , . . . , ) received payoff player given players joint action a1 , . . . , , (ai )
(i = 1, . . . , n) probability player choosing action a1 . Nash equilibrium defined
(3) becomes





Qi (a1 , . . . , )1 (a1 ) (ai ) n (an )

a1 ,...,an A1

Qi (a1 , . . . , )1 (a1 ) (ai ) n (an ), , = 1, , n

(4)

a1 ,...,an A1

(ai ) probability player choosing action ai player Nash equilibrium
strategy .
two-player matrix game called zero-sum game two players fully competitive.
way, R1 = R2 . zero-sum game unique Nash equilibrium sense
expected payoff. means that, although player may multiple Nash equilibrium
399

fiL U , CHWARTZ , & G IVIGI

strategies zero-sum game, value expected payoff Vi Nash equilibrium
strategies same. players game fully competitive summation
players payoffs zero, game called general-sum game. general-sum game,
Nash equilibrium longer unique game might multiple Nash equilibria. Unlike
deterministic optimal policy single player MDP, equilibrium strategies multiplayer matrix game may stochastic.
2.3 Stochastic Games
Markov decision process contains single player multiple states matrix game contains
multiple players single state. game one player multiple states,
define stochastic game (or Markov game) combination Markov decision processes
matrix games. stochastic game tuple (n, S, A1 , . . . , , T, , R1 , . . . , Rn ) n
number players, : A1 [0, 1] transition function, Ai (i = 1, . . . , n)
action set player i, [0, 1] discount factor Ri : A1 R
reward function player i. transition function stochastic game probability
distribution next states given current state joint action players. reward
function Ri (s, a1 , . . . , , ) denotes reward received player state taking joint
action (a1 , . . . , ) state s. Similar Markov decision processes, stochastic games also
Markov property. is, players next state reward depend current state
players current actions.
solve stochastic game, need find policy : Ai maximize player
discounted future reward discount factor . Similar matrix games, players policy
stochastic game probabilistic. example soccer game introduced Littman (Littman,
1994) agent offensive side must use probabilistic policy pass unknown
defender. literature, solution stochastic game described Nash equilibrium
strategies set associated state-specific matrix games (Bowling, 2003; Littman, 1994).
state-specific matrix games, define action-value function Qi (s, a1 , . . . , ) expected reward player players take joint action a1 , . . . , state follow
Nash equilibrium policies thereafter. value Qi (s, a1 , . . . , ) known states,
find player Nash equilibrium policy solving associated state-specific matrix game
(Bowling, 2003). Therefore, state s, matrix game find Nash
equilibrium strategies matrix game. Nash equilibrium policies game
collection Nash equilibrium strategies state-specific matrix game states.
2.4 Multi-Player General-Sum Stochastic Games
multi-player general-sum stochastic game, want find Nash equilibria game
know reward function transition function game. Nash equilibrium stochastic
game described tuple n policies (1 , . . . , n ) = 1, , n,
Vi (s, 1 , . . . , , . . . , n ) Vi (s, 1 , . . . , , . . . , n )

(5)

set policies available player Vi (s, 1 , . . . , n ) expected sum
discounted rewards player given current state players equilibrium policies.
simplify notation, use Vi (s) represent Vi (s, 1 , , n ) state-value function Nash
equilibrium policies. also define action-value function Q (s, a1 , , ) expected
400

fiP OLICY NVARIANCE



R EWARD RANSFORMATIONS

sum discounted rewards player given current state current joint action
players, following Nash equilibrium policies thereafter. get



Vi (s) =

Qi (s, a1 , , )1 (s, a1 ) n (s, ),

(6)

a1 , ,an A1

Qi (s, a1 , . . . , ) =

(s, a1 , . . . , , )






Ri (s, a1 , . . . , , ) + Vi (s ) ,

(7)

(s, ai ) PD(Ai ) probability distribution action ai player Nash equilibrium policy, (s, a1 , . . . , , ) = Pr {sk+1 = |sk = s, a1 , . . . , } probability next state
given current state joint action (a1 , . . . , ), Ri (s, a1 , . . . , , ) expected
immediate reward received state given current state joint action (a1 , . . . , ). Based
(6) (7), Nash equilibrium (5) rewritten



Qi (s, a1 , . . . , )1 (s, a1 ) (s, ai ) n (s, )

a1 ,...,an A1



Qi (s, a1 , . . . , )1 (s, a1 ) (s, ai ) n (s, ).

(8)

a1 ,...,an A1

3. Potential-Based Shaping General-Sum Stochastic Games
Ng et al. (1999) presented reward shaping method deal credit assignment problem
adding potential-based shaping reward environment. combination shaping
reward original reward may improve learning performance reinforcement learning
algorithm speed convergence optimal policy. theoretical studies potentialbased shaping methods appear published literature consider case single agent
MDP (Ng et al., 1999; Wiewiora, 2003; Asmuth et al., 2008). research, extend
potential-based shaping method Markov decision processes multi-player stochastic games.
prove Nash equilibria potential-based shaping reward transformation
Nash equilibria original game framework general-sum stochastic games.
define potential-based shaping reward Fi (s, ) player
Fi (s, ) = (s ) (s),

(9)

: R real-valued shaping function (sT ) = 0 terminal state sT .
define multi-player stochastic game tuple = (S, A1 , . . . , , T, , R1 , . . . , Rn ) set
states, A1 , . . . , players action sets, transition function, discount factor,
Ri (s, a1 , . . . , , )(i = 1, . . . , n) reward function player i. adding shaping reward
function Fi (s, ) reward function Ri (s, a1 , . . . , , ), define transformed multi-player
stochastic game tuple = (S, A1 , . . . , , T, , R1 , . . . , Rn ) Ri (i = 1, . . . , n) new
reward function given Ri (s, a1 , . . . , , ) = Fi (s, ) + Ri (s, a1 , . . . , , ). Inspired Ng et al.
(1999)s proof policy invariance MDP, prove policy invariance multi-player
general-sum stochastic game follows.
Theorem 1. Given n-player discounted stochastic game = (S, A1 , . . . , , T, , R1 , . . . , Rn ),
define transformed n-player discounted stochastic game = (S, A1 , . . . , , T, , R1 + F1 , . . . , Rn +
Fn ) Fi shaping reward function player i. call Fi potential-based shaping
function Fi form (9). Then, potential-based shaping function Fi necessary
sufficient condition guarantee Nash equilibrium policy invariance
401

fiL U , CHWARTZ , & G IVIGI

(Sufficiency) Fi (i = 1, . . . , n) potential-based shaping function, every Nash equilibrium policy also Nash equilibrium policy (and vice versa).
(Necessity) Fi (i = 1, . . . , n) potential-based shaping function, may exist
transition function reward function R Nash equilibrium policy
Nash equilibrium policy M.
Proof. (Proof Sufficiency)
Based (8), Nash equilibrium stochastic game represented set policies
= 1, . . . , n, Mi






QMi (s, a1 , . . . , )M
(s, a1 )
(s, ai )
(s, )
1

n

a1 ,...,an A1





(s, a1 ) Mi (s, ai )
(s, ).
QMi (s, a1 , . . . , )M
1
n

(10)

a1 ,...,an A1

subtract (s) sides (10) get



a1 ,...,an A1




QMi (s, a1 , . . . , )M
(s, a1 )
(s, ai )
(s, ) (s)
1

n





QMi (s, a1 , . . . , )M
(s, a1 ) Mi (s, ai )
(s, ) (s).
1
n

(11)

a1 ,...,an A1
(s, ) (s, ) (s, ) = 1, get
Since a1 ,...,an A1
1

n
Mi
Mn
1






(s, a1 )
(s, ai )
(s, )
[QMi (s, a1 , . . . , ) (s)]M
1

n

a1 ,...,an A1





[QMi (s, a1 , . . . , ) (s)]M
(s, a1 ) Mi (s, ai )
(s, ).
1
n

(12)

a1 ,...,an A1

define
QMi (s, a1 , . . . , ) = QMi (s, a1 , . . . , ) (s).

(13)

get



a1 ,...,an A1






QMi (s, a1 , . . . , )M
(s, a1 )
(s, ai )
(s, )
1

n

a1 ,...,an A1



(s, a1 ) Mi (s, ai )
(s, ).
QMi (s, a1 , . . . , )M
1
n

(14)

use algebraic manipulations rewrite action-value function Nash equilibrium (7) player stochastic game

QMi (s, a1 , . . . , ) (s) = (s, a1 , . . . , , ) RMi (s, a1 , . . . , , ) + VM (s )



+ (s ) (s ) (s).

(15)

Since (s, a1 , . . . , , ) = 1, equation becomes
QMi (s, a1 , . . . , ) (s) =

(s, a1 , . . . , , )





RMi (s, a1 , . . . , , )


+ (s ) (s) + VM (s ) (s ) .
402

(16)

fiP OLICY NVARIANCE



R EWARD RANSFORMATIONS

According (6), rewrite equation
QMi (s, a1 , . . . , ) (s) =



+

a1 ,...,an A1

=
+



a1 ,...,an A1

(s, a1 , . . . , , )





RMi (s, a1 , . . . , , ) + (s ) (s)







(s
,

)



(s
,

)

QMi (s , a1 , . . . , )M



(s
)

1

n
1


(s, a1 , . . . , , )



RMi (s, a1 , . . . , , ) + (s ) (s)






(s , a1 )
(s , ) .
QMi (s , a1 , . . . , ) (s )
1


(17)

Based definitions Fi (s, ) (9) QMi (s, a1 , . . . , ) (13), equation becomes
QMi (s, a1 , . . . , ) =
+



a1 ,...,an A1

(s, a1 , . . . , , )





RMi (s, a1 , . . . , , ) + Fi(s, )




QMi (s , a1 , . . . , )
(s , a1 )
(s , ) .
1


(18)

Since equations (14) (18) form equations (6)-(8), conclude
QMi (s, a1 , . . . , ) action-value function Nash equilibrium player stochastic game . Therefore, obtain
QMi (s, a1 , . . . , ) = QM (s, a1 , . . . , ) = QMi (s, a1 , . . . , ) (s).


(19)

state terminal state sT , QMi (sT , a1 , . . . , ) = QMi (sT , a1 , . . . , )
(sT ) = 0 0 = 0. Based (14) QMi (s, a1 , . . . , ) = QM (s, a1 , . . . , ), find

Nash equilibrium also Nash equilibrium . state-value function
Nash equilibrium stochastic game given
VM (s) = VM (s) (s).


(20)

(Proof Necessity)
Fi (i = 1, . . . , n) potential-based shaping function, Fi (s, ) 6= (s ) (s).
Similar Ng et al. (1999)s proof necessity, define = Fi (s, ) [ (s ) (s)].
build stochastic game giving following transition function player 1s reward
function RM1 ()
(s1 , a11 , a2 , . . . , , s3 ) = 1,
(s1 , a21 , a2 , . . . , , s2 ) = 1,
(s2 , a1 , . . . , , s3 ) = 1,
(s3 , a1 , . . . , , s3 ) = 1,

RM1 (s1 , a1 , . . . , , s3 ) = ,
2
RM1 (s1 , a1 , . . . , , s2 ) = 0,
RM1 (s2 , a1 , . . . , , s3 ) = 0,
RM1 (s3 , a1 , . . . , , s3 ) = 0,
403

(21)

fiL U , CHWARTZ , & G IVIGI

a11
S3

S1

a12
S2
Figure 1: possible states stochastic model proof necessity

ai (i = 1, . . . , n) represents possible action ai Ai player i, a11 a21 represent
player 1s action 1 action 2 respectively. Equation (s1 , a11 , a2 , . . . , , s3 ) = 1 (21) denotes
that, given current state s1 , player 1s action a11 lead next state s3 matter
joint action players take. Based transition function reward function,
get game model including states (s1 , s2 , s3 ) shown Figure 1. define 1 (si ) =
F1 (si , s3 )(i = 1, 2, 3). Based (6), (7), (19), (20) (21), obtain player 1s action-value
function state s1

,
2
QM1 (s1 , a21 , . . . ) = 0,

QM1 (s1 , a11 , . . . ) =


QM (s1 , a11 , . . . ) = F1 (s1 , s2 ) + F1 (s2 , s3 ) ,
1
2
QM (s1 , a21 , . . . ) = F1 (s1 , s2 ) + F1 (s2 , s3 ).
1

Nash equilibrium policy player 1 state s1


(s1 , a1 ) =

1

1
a1 > 0,


a21


,
(s1 , a1 ) =
1

otherwise

2
a1 > 0,


a11

.

(22)

otherwise

Therefore, case, Nash equilibrium policy player 1 state s1
Nash equilibrium policy .

analysis shows potential-based shaping reward form Fi (s, ) =
(s ) (s) guarantees Nash equilibrium policy invariance. question becomes
select shaping function (s) improve learning performance learner. Ng
et al. (1999) showed (s) = VM (s) good candidate improving players learning
404

fiP OLICY NVARIANCE



R EWARD RANSFORMATIONS

performance MDP. substitute (s) = VM (s) (18) get
QMi (s, a1 , . . . , ) = QM (s, a1 , . . . , )


=
+

(s, a1 , . . . , , )







RMi (s, a1 , . . . , , ) + Fi (s, )



RMi (s, a1 , . . . , , ) + Fi (s, )






QM (s , a1 , . . . , )

(s
,

)



(s
,

)
1

n
1



a1 ,...,an A1

=

(s, a1 , . . . , , )




+ (VM (s ) (s ))


= (s, a1 , . . . , , ) RMi (s, a1 , . . . , , ) + Fi (s, ) .

(23)



Equation (23) shows action-value function QM (s, a1 , . . . , ) state easily obtained

checking immediate reward RMi (s, a1 , . . . , , ) + Fi (s, ) player received state .
However, practical applications, information environment
(s, a1 , . . . , , ) Ri (s, a1 , . . . , , ). means cannot find shaping function (s)
(s) = VM (s) without knowing model environment. Therefore, goal
designing shaping function find (s) good approximation VM (s).

4. Conclusion
potential-based shaping method used deal temporal credit assignment problem
speed learning process MDPs. article, extend potential-based shaping
method general-sum stochastic games. prove proposed potential-based shaping reward applied general-sum stochastic game change original Nash equilibrium
game. analysis result article potential improve learning performance
players stochastic game.

References
Asmuth, J., Littman, M. L., & Zinkov, R. (2008). Potential-based shaping model-based reinforcement learning. Proceedings 23rd AAAI Conference Artificial Intelligence,
pp. 604609.
Babes, M., Munoz de Cote, E., & Littman, M. L. (2008). Social reward shaping prisoners
dilemma. Proceedings 7th International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS 2008), pp. 13891392.
Basar, T., & Olsder, G. J. (1999). Dynamic Noncooperative Game Theory. SIAM Series Classics
Applied Mathematics 2nd, London, U.K.
Bertsekas, D. P. (1987). Dynamic Programming: Deterministic Stochastic Models. PrenticeHall, Englewood Cliffs, NJ.
Bowling, M. (2003). Multiagent Learning Presence Agents Limitations. Ph.D. thesis,
School Computer Science, Carnegie Mellon University, Pittsburgh, PA.
405

fiL U , CHWARTZ , & G IVIGI

Devlin, S., & Kudenko, D. (2011). Theoretical considerations potential-based reward shaping
multi-agent systems.. Proceedings 10th International Conference Autonomous
Agents Multiagent Systems (AAMAS), Taipei, Taiwan.
Dorigo, M., & Colombetti, M. (1994). Robot shaping: developing autonomous agents
learning. Artificial Intelligence, 71, 321370.
Gullapalli, V., & Barto, A. (1992). Shaping method accelerating reinforcement learning.
Proceedings 1992 IEEE International Symposium Intelligent Control, pp. 554 559.
Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning.
Proceedings 11th International Conference Machine Learning, pp. 157163.
Mataric, M. J. (1994). Reward functions accelerated learning. Proceedings 11th
International Conference Machine Learning.
Ng, A. Y., Harada, D., & Russell, S. (1999). Policy invariance reward transformations: theory
application reward shaping. Proceedings 16th International Conference
Machine Learning, pp. 278287.
Randlv, J., & Alstrm, P. (1998). Learning drive bicycle using reinforcement learning
shaping. Proceedings 15th International Conference Machine Learning.
Shapley, L. S. (1953). Stochastic games. Proceedings National Academy Sciences,
Vol. 39, pp. 10951100.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, Massachusetts.
Wiewiora, E. (2003). Potential-based shaping Q-value initialization equivalent. Journal
Artificial Intelligence Research, 19, 205208.

406

fiJournal Artificial Intelligence Research 41 (2011) 267296

Submitted 11/10; published 06/11

Identical Similar: Fusing Retrieved Lists Based
Inter-Document Similarities
Anna Khudyak Kozorovitsky
Oren Kurland

annak@tx.technion.ac.il
kurland@ie.technion.ac.il

Faculty Industrial Engineering Management
Technion Israel Institute Technology

Abstract
Methods fusing document lists retrieved response query often utilize retrieval scores and/or ranks documents lists. present novel fusion
approach based using, addition, information induced inter-document
similarities. Specically, methods let similar documents dierent lists provide
relevance-status support other. use graph-based method model relevancestatus propagation documents. propagation governed inter-documentsimilarities retrieval scores documents lists. Empirical evaluation demonstrates eectiveness methods fusing TREC runs. performance
eective methods transcends eective fusion methods utilize retrieval scores ranks.

1. Introduction
ad hoc retrieval task nd documents pertaining information need
underlying given query. Naturally, considerable uncertainty retrieval process
e.g., accurately inferring actual information need is. Thus, researchers proposed utilize dierent information sources types address retrieval task (Croft,
2000b). example, utilizing multiple document representations (Katzer, McGill, Tessier,
Frakes, & Dasgupta, 1982), query representations (Saracevic & Kantor, 1988; Belkin, Cool,
Croft, & Callan, 1993), search techniques (Croft & Thompson, 1984; Fox & Shaw,
1994), proposed means improving retrieval eectiveness.
Many approaches mentioned depend ability eectively fuse several
retrieved lists produce single list results. Fusion might performed
single retrieval system (Croft & Thompson, 1984), upon results produced dierent
search systems (Fox & Shaw, 1994; Callan, Lu, & Croft, 1995; Dwork, Kumar, Naor, &
Sivakumar, 2001). Conceptually, fusion viewed integrating experts recommendations (Croft, 2000b), expert retrieval model used produce ranked list
results experts recommendation.
principle underlying many fusion methods documents highly
ranked many lists, i.e., highly recommended many experts,
ranked high nal result list (Fox & Shaw, 1994; Lee, 1997). eectiveness
approaches employ principle often depends overlap1 non-relevant
1. use term overlap refer number documents shared retrieved lists rather
reference content overlap.
c
2011
AI Access Foundation. rights reserved.

fiKhudyak Kozorovitsky & Kurland

documents lists much smaller relevant documents (Lee,
1997). However, several studies shown often case, specically,
many occasions (many) dierent relevant documents across lists
fused (Das-Gupta & Katzer, 1983; Griths, Luckhurst, & Willett, 1986; Chowdhury,
Frieder, Grossman, & McCabe, 2001; Soboro, Nicholas, & Cahan, 2001; Beitzel et al.,
2003).
propose novel approach fusion retrieved lists addresses, among others,
relevant-documents mismatch issue mentioned. principle guiding development
methods similar documents dierent lists, well
list provide relevance-status support other, potentially discuss
topics (Shou & Sanderson, 2002; Balinski & Danilowicz, 2005; Diaz, 2005; Kurland
& Lee, 2005; Meister, Kurland, & Kalmanovich, 2010). Specically, relevant documents
assumed similar following cluster hypothesis (van Rijsbergen, 1979),
provide support via inter-document similarities.
Inspired work re-ranking single retrieved list using inter-document similarities
within list (Balinski & Danilowicz, 2005; Diaz, 2005; Kurland & Lee, 2005), approach
uses graph-based method model relevance-status propagation documents
lists fused. propagation governed inter-document-similarities
retrieval scores documents lists. Specically, documents highly ranked
lists, similar documents highly ranked, rewarded.
inter-document-similarities utilized i.e., retrieval scores used
methods reduce standard fusion approaches.
Empirical evaluation shows methods highly eective fusing TREC runs
(Voorhees & Harman, 2005); is, lists document created response
queries search systems participated TREC. eective methods post
performance superior eective standard fusion methods utilize
retrieval scores. show ndings hold whether runs fused,
selected available runs per track (challenge) TREC, eective ones,
randomly selected. Using additional array experiments study eect
various factors performance approach.

2. Fusion Framework
Let q denote query document, respectively. assume documents
assigned unique IDs; write d1 d2 d1 d2 ID, i.e.,
[q;k]
[q;k]
document. assume document lists L1 , . . . , Lm , L1 , . . . , Lm short,
retrieved response q retrievals performed given corpus, respectively;
list contains k documents. write Li indicate member Li ,
def

use SLi (d) denote (positive) retrieval score Li ; 6 Li SLi (d) = 0.
document instance Lji document rank j list Li . simplify notation, often
def

use S(Lji ) denote retrieval score Lji (i.e., S(Lji ) = SLi (Lji )). methods
present consider similarity sim(d1 , d2 ) documents d1 d2 . methods
committed specic way computing inter-document similarities. example,
cosine measure vector-space representations documents used
268

fiFusing Retrieved Lists Based Inter-Document Similarities

previous work re-ranking single retrieved list (Diaz, 2005; Kurland & Lee, 2005).
Section 4.1 describe specic choice language-model-based inter-document
similarity measure used experiments following previous recommendations (Kurland &
Lee, 2010).
2.1 Fusion Essentials
goal produce single list results retrieved lists L1 , . . . , Lm . end,
opt detect documents highly recommended lists L1 , . . . , Lm ,
words, prestigious respect lists. Given virtue
lists created, is, response query, hypothesize prestige implies
relevance. key challenge formally dene quantify prestige.
Many current fusion approaches (implicitly) regard document prestigious
highly ranked many lists. CombSUM method (Fox & Shaw, 1994),
example, quanties prestige notion summing document retrieval scores2 :
def

PCombSU (d) =

X

SLi (d).

Li :dLi

emphasize even importance occurrence many lists, CombMNZ method
(Fox & Shaw, 1994; Lee, 1997), highly eective fusion approach (Montague &
Aslam, 2002), scales CombSUMs score number lists document member of:
def

PCombM N Z (d) = #{Li : Li }

X

SLi (d).

Li :dLi

potentially helpful source information utilized standard fusion methods
inter-document relationships. example, documents similar
provide support prestige potentially discuss topics. Indeed, work
re-ranking single retrieved list shown prestige induced inter-document similarities connected relevance (Kurland & Lee, 2005). multiple-lists setting
address here, information induced inter-document similarities across lists could
rich source helpful information well. case point, document member
single list, similar documents highly ranked many
lists could deemed prestigious. Furthermore, similarity-based prestige viewed
generalization prestige notion taken standard fusion methods, consider
documents similar document.

2.2 Similarity-Based Fusion
use graphs represent propagation prestige status documents; propagation based inter-document similarities retrieval scores. nodes graph
2. assume retrieval scores normalized inter-list compatibility; details normalization scheme employ experiments provided Section 4.1.

269

fiKhudyak Kozorovitsky & Kurland

represent either documents, document instances (appearances documents) retrieved lists. latter case, document represented several nodes,
corresponds appearance list, former case, node
corresponds dierent document.
development following graph-construction method prestige-induction
technique inspired work inducing prestige single retrieved list (Kurland & Lee,
2005). contrast work, however, would like exploit special characteristics
fusion setup. is, fact documents appear several retrieved
lists dierent retrieval scores might produced dierent retrieval methods.
Accordingly, fusion methods develop novel study.
Formally, given set documents (document instances) V , construct weighted
def

(directed) complete graph G = (V, V V, w t) edge-weight function w t:

w t(v1 v2 )

def

=

(

sim(v1 , v2 ) v2 N bhd(v1 ; ),
0
otherwise;

v1 , v2 V ; and, N bhd(v; ) elements v V {v : v v} yield highest
sim(v, v ) i.e., vs nearest neighbors V ; free parameter.3 Previous work
demonstrated merits using directed nearest-neighbor-based graphs, use here,
modeling prestige-status propagation setups wherein prestige implies relevance
information need (Kurland & Lee, 2005). (See Kurland, 2006 elaborated discussion.)
work inducing (i) journal prestige bibliometrics (Pinski & Narin, 1976), (ii)
Web-page prestige Web retrieval (Brin & Page, 1998), (iii) plain-text prestige reranking single list (Kurland & Lee, 2005), say node v G prestigious
extent receives prestige-status support prestigious nodes. quantify
def P


prestige notion using P (v; G) =
v V w t(v v)P (v ; G). However, recursive
equation necessarily solution.
address issue, dene smoothed version edge-weight function,
echoes PageRanks (Brin & Page, 1998) approach:
def

w t[] (v1 v2 ) = P

2 , q)
w t(v1 v2 )
sim(v
+ (1 ) P
;



sim(v , q)

v V w t(v1 v )

(1)

v V

q) vs estimated query similarity. (Below present
free parameter, sim(v,
def

various query-similarity measures.) resultant graph G[] = (V, V V, w t[] ).
Note node G[] receives prestige-status support extent partially controlled similarity document represents query. Nodes among
nearest-neighbors nodes get additional support. Moreover, w t[]
thought probability transition function, sum weights edges going
node 1; furthermore, every node outgoing edges nodes graph
(self loops included). Hence, G[] represents ergodic Markov chain unique stationary distribution exists (Golub & Van Loan, 1996). distribution, found
3. Note N bhd(v; ) contains nodes represent documents represented v.

270

fiFusing Retrieved Lists Based Inter-Document Similarities

Algorithm
SetUni
SetSum
SetMNZ
BagUni
BagSum
BagDupUni
BagDupMNZ

q)
sim(v,

V


{d : Li }

{d : Li }

{d : Li }
{Lji }i,j
{Lji }i,j
{Dup(Lji )}i,j
{Dup(Lji )}i,j

1

PCombSU (v)
PCombM N Z (v)
1
S(v)
1
S(v)

core(d)
P (d; G[] )
P (d; G[] )
P (d; G[] )
P
P (v; G[] )
PvV :vd
P (v; G[] )
PvV :vd
P (v; G[] )
PvV :vd
[]
vV :vd P (v; G )

Table 1: Similarity-based fusion methods; core(d) ds nal retrieval score.
L1
: d1
: d2
: d3

L11
L21
L31

L2
: d2
: d4
: d1

L12
L22
L32

Table 2: Example two retrieved lists fused.
using, example, Power method (Golub & Van Loan, 1996),
P unique solution
following prestige-induction equation constraint v V P (v ; G[] ) = 1:
def

P (v; G[] ) =

X

w t[] (v v)P (v ; G[] ).

(2)

v V

2.2.1 Methods
derive specic fusion methods, need specify graph G[] using prestige
induced Equation 2. specically, given lists L1 , . . . , Lm , dene
set nodes V represent documents (or document instances); and, devise
q)) used edge-weight function w t[]
query-similarity estimate (sim(v,
Equation 1. alternatives consider, represent ways utilizing
graph-based approach, resultant fusion methods, presented Table 1.
important note fusion method produces ranking documents wherein
document cannot one instance. facilitate discussion various
methods Table 1, refer example fusing two lists Table 2, L1
L2 , contains three documents.
rst group methods consider occurrences document multiple lists
utilizing inter-document similarities. Specically, V , set nodes, dened
def

set-union retrieved lists. example Table 2, V = {d1 , d2 , d3 , d4 }.
Thus, document represented graph single node. prestige value
node serves nal retrieval score document. SetUni method ignores
retrieval scores documents using uniform query-similarity estimate; hence,
inter-document similarity information utilized. SetSum SetMNZ methods,
hand, integrate also retrieval scores using CombSUM CombMNZ
prestige scores query-similarity estimates, respectively.
271

fiKhudyak Kozorovitsky & Kurland

SetSum SetMNZ methods are, fact, generalized forms CombSUM
CombMNZ, respectively. use edge-weight function w t[1] (i.e., set = 1 Equation 1), is, exploit inter-document-similarity information, SetSum
SetMNZ amount CombSUM CombMNZ, respectively; lower values result
emphasis put inter-document-similarities information. Furthermore, set-based
paradigm used incorporate generalize fusion method using
methods retrieval score query-similarity estimate. Then, setting = 1 amounts
using fusion methods retrieval scores. (See Appendix proof.)
contrast set-based methods, bag-based methods consider occurrences
document multiple lists utilizing inter-document similarity information. node
graph represents instance document list. Hence, set nodes (V )
graph could viewed bag-union retrieved lists. example
def

Table 2, V = {L11 , L21 , L31 , L12 , L22 , L32 }. nal retrieval score document set
sum prestige scores nodes represent i.e., correspond instances
lists. example, score d1 would sum scores nodes L11
L32 . also important note neighborhood set N bhd(v; ) node
v cannot contain nodes representing document represented v, contain
multiple instances dierent document. Thus, documents many instances tend
receive inter-document-similarity-based prestige-status support documents
fewer instances.
rst representative bag-based methods, BagUni, ignores retrieval scores
considers inter-document-similarities. Hence, BagUni diers SetUni
virtue rewarding documents multiple instances. addition exploiting interdocument similarities, BagSum method also uses retrieval score document
instance query-similarity estimate corresponding node. note CombSUM specic case BagSum = 1, case SetSum. (See Appendix
proof.) Furthermore, BagSum resembles SetSum uses controlling
balance using retrieval scores utilizing inter-document similarities. However, documents many instances get prestige-status support BagSum
SetSum due bag-based representation lists.
Naturally, then, opt create bag-based generalized version CombMNZ
method. end, document instance Lji corresponds document d,
dene new list Dup(Lji ). list contains n copies d, assigned arbitrary
def

dierent rank 1 n S(Lji ) retrieval score; n = #{Li : Li }
number original lists belongs to. set nodes V composed document
instances newly dened lists. example Table 2, get following
newly created lists:
def

La = Dup(L11 )
L1a : L11 d1
L2a : L11 d1

def

Lb = Dup(L32 )
L1b : L32 d1
L2b : L32 d1

def

Lc = Dup(L21 )
L1c : L21 d2
L2c : L21 d2

def

Ld = Dup(L12 )
L1d : L12 d2
L2d : L12 d2

def

Le = Dup(L31 )
L1e : L31 d3

def

Lf = Dup(L22 )
L1f : L22 d4

set nodes, V , {L1a , L2a , L1b , L2b , L1c , L2c , L1d , L2d , L1e , L1f }. Note, example,
d1 represented single node set-based representation, two nodes
bag-based representation, represented four nodes. generally,
272

fiFusing Retrieved Lists Based Inter-Document Similarities

number nodes document represented square number
appearances document lists.
BagDupUni method, then, uses uniform query-similarity estimate. Hence,
SetUni BagUni utilizes inter-document similarities; but, so, BagDupUni
rewards larger extent documents multiple instances due bag representation
duplicated instances. BagDupMNZ method integrates also retrieval-scores
information using retrieval score document instance new list querysimilarity estimate corresponding node. w t[1] (i.e., = 1), BagDupMNZ amounts
CombMNZ, case SetMNZ. (See Appendix proof.) Yet, BagDupMNZ
rewards larger extent documents multiple instances SetMNZ due
bag representation lists duplicated document instances.

3. Related Work
Fusion methods often use ranks documents lists, retrieval scores,
documents content (Fox & Shaw, 1994; Voorhees, Gupta, & Johnson-Laird, 1994; Lee,
1997; Vogt & Cottrell, 1999; Croft, 2000b; Dwork et al., 2001; Aslam & Montague, 2001;
Montague & Aslam, 2002; Lillis, Toolan, Collier, & Dunnion, 2006; Shokouhi, 2007).
example, Dwork et al. (2001), us, use Markov chains nd prestigious documents
lists. However, propagation relevance status governed information
regarding ranks documents lists. show Section 4.2 using
retrieval scores inter-document similarities guide relevance-status propagation
eective using alone. Also, note previous work fusion
demonstrated relative merits using retrieval scores rather rank information (Lee,
1997). Furthermore, stated Section 2.2.1, methods incorporate generalize
fusion methods rely scores/ranks using set-based graph representation.
used Section 2.2.1 CombSUM CombMNZ methods, based retrieval
scores, examples. CombSUM (non supervised) representative general family
linear combination techniques (Vogt & Cottrell, 1999), CombMNZ considered
highly eective approach therefore often serves baseline work fusion (Lee,
1997; Aslam & Montague, 2001; Montague & Aslam, 2002; Lillis et al., 2006; Shokouhi,
2007). Section 4.2 demonstrate performance merits approach respect
CombSUM CombMNZ, additional rank-based fusion methods.
several fusion methods utilize document-based features,
based document content, e.g., snippets (summaries) documents (Lawrence &
Giles, 1998; Craswell, Hawking, & Thistlewaite, 1999; Tsikrika & Lalmas, 2001; Beitzel,
Jensen, Frieder, Chowdhury, & Pass, 2005; Selvadurai, 2007). However, contrast
methods, inter-document similarities used approaches. Thus,
methods potentially incorporated fusion framework using set-based graph
representation. Furthermore, note methods potentially utilize document
snippets estimate inter-document similarities, rather use entire document content, content (quickly) accessible. Indeed, snippets used inducing
inter-document similarities cluster results Web search engines (Zamir & Etzioni,
1998).
273

fiKhudyak Kozorovitsky & Kurland

large body work re-ranking initially retrieved list using graphbased methods model inter-document similarities within list (e.g., Danilowicz &
Balinski, 2000; Balinski & Danilowicz, 2005; Diaz, 2005; Kurland & Lee, 2005, 2006; Zhang
et al., 2005; Yang, Ji, Zhou, Nie, & Xiao, 2006). mentioned Section 2, fusion
methods could conceptually viewed generalization approaches
(Danilowicz & Balinski, 2000; Diaz, 2005; Kurland & Lee, 2005); specically, methods
utilize retrieval scores inter-document-similarities modeling relevancestatus propagation within list (Danilowicz & Balinski, 2000; Diaz, 2005). similar
relevance-status propagation method also employed work sentence retrieval
question answering (Otterbacher, Erkan, & Radev, 2005).
Similarities document headlines used merging document lists
retrieved response query non-overlapping corpora (Shou & Sanderson, 2002).
Specically, document ranked sum similarities headline headlines documents. contrast approach, operates single corpus,
accordingly exploits information regarding multiple occurrences document
lists, retrieval scores integrated similarities; and, graph-based
approach use employed. Section 4.2 show using retrieval
scores single-corpus-based fusion setup explore highly important; specifically, integrating retrieval scores inter-document-similarities results much better
performance using inter-document similarities.
Similarities documents (potentially non-overlapping) dierent corpora
also used form document clusters (Xu & Croft, 1999; Crestani & Wu, 2006)
(potentially) improve results browsing (Crestani & Wu, 2006) improve collection
selection (Xu & Croft, 1999) search. contrast approach, fusion methods
based utilizing information induced inter-document similarities
proposed.
recent work re-ranking retrieved list using inter-document similarities
second retrieved list (Meister et al., 2010). idea documents highly
ranked original list, similar documents highly ranked second
list, rewarded. However, contrast fusion approaches, documents
members second list, rst list, cannot appear nal result list.
Furthermore, contrast approach, recursive denition prestige.
importantly, apparent way generalizing method fuse several lists,
contrast approach.
Methods utilizing inter-item textual similarities using variant PageRank
also used, example, cross-lingual retrieval (Diaz, 2008), prediction retrieval eectiveness (Diaz, 2007), text summarization clustering (Erkan
& Radev, 2004; Mihalcea & Tarau, 2004; Erkan, 2006). Specically, recent work
(Krikon, Kurland, & Bendersky, 2010) demonstrated merits integrating wholedocument-based inter-document similarities inter-passage-similarities re-ranking
single retrieved list; especially, using corpora containing long and/or topically heterogeneous documents. Incorporating inter-passage similarities methods future
venue intend explore.
274

fiFusing Retrieved Lists Based Inter-Document Similarities

4. Evaluation
next study eectiveness similarity-based fusion approach, dierent
factors aect performance.
4.1 Experimental Setup
follows describe setup used evaluation.
4.1.1 Measuring Inter-Document Similarities.
use previously proposed language-model-based similarity estimate shown
eective work re-ranking single retrieved list (Kurland & Lee, 2005, 2006, 2010).
[]
Let pd () denote unigram, Dirichlet-smoothed, language model induced document d, smoothing parameter (Zhai & Laerty, 2001). set = 1000
following previous recommendations (Zhai & Laerty, 2001). documents d1 d2
dene:
fifi



def
fifi []
[0]
sim(d1 , d2 ) = exp pd1 () fifi pd2 () ;

KL divergence. closer language models d1 d2 are, lower
KL divergence is, higher similarity estimate is.
4.1.2 Data, Evaluation Measures, Parameters.
evaluate performance fusion methods using TREC datasets (Voorhees &
Harman, 2005), also used previous work fusion (e.g., Lee, 1997;
Aslam & Montague, 2001; Montague & Aslam, 2002): ad hoc track trec3, web
tracks trec9 trec10, robust track trec12. Tokenization, Porter stemming,
stopword removal (using INQUERY list) applied documents using
Lemur toolkit4 , also used computing sim(d1 , d2 ).
Retrieval methods utilize inter-document similarities query context e.g.,
re-ranking single retrieved list using graph-based techniques known
eective employed relatively short lists (Willett, 1985; Diaz, 2005; Kurland & Lee,
2010). reason lists often contain documents exhibit high surface-level
query similarity. Hence, lists could thought providing eective query-based
corpus context. Similar arguments echoed work pseudo-feedback-based query
expansion (Xu & Croft, 1996; Lavrenko & Croft, 2001; Zhai & Laerty, 2002; Tao & Zhai,
2006). Furthermore, utilizing inter-document similarities short lists shown
highly eective improving precision top ranks (Kurland & Lee, 2005, 2006).5
Indeed, users Web search engines, example, often interested highly
ranked documents (a.k.a., rst page results). Given considerations mentioned,
take following design decisions respect evaluation measures focus
on, number lists fused, number documents list.
4. www.lemurproject.org
5. Improving precision top ranks often results improving MAP (mean average precision) virtue
way MAP defined. show Section 4.2.1 approach improves precision top
ranks MAP.

275

fiKhudyak Kozorovitsky & Kurland

focus precision top ranks, use precision top 5 10 documents
(p@5, p@10) main evaluation measures. determine statistically-signicant performance dierences, use two-tailed Wilcoxon test 95% condence level.
means that, average, result signicance test might erroneous one
every twenty tests. Thus, employ Bonferroni correction corpora per evaluation
measure (i.e., condence level 98.75% also used). Specically, results tables
present, statistical-signicance mark corresponds 95% condence level; and,
mark boldfaced corresponding performance dierence statistically signicant
Bonferroni correction employed (i.e., using 98.75% condence level).
use methods fuse three lists, corresponds top-k documents
submitted run within track; is, use actual result lists (runs) submitted
TRECs participants. main focus evaluation, (and including) Section
4.2.5, fusing three runs eective among submitted runs
track (both automatic manual); eectiveness measured MAP@k , is, mean
average non-interpolated precision cuto k, henceforth referred MAP (Voorhees
& Harman, 2005). three runs fused denoted, descending order MAP
performance, run1, run2, run3, respectively. Although MAP evaluation
measure focus albeit, present MAP performance numbers Section 4.2.1
practice ensures initial ranking lists fused relatively high
quality; is, terms recall relative positioning relevant documents. Yet,
lists fused could still sub-optimal respect precision top ranks. Thus,
use reference comparisons methods Optimal Runs (opt. run short)
per evaluation metric track; is, track, evaluation metric (p@5
p@10), report best (average queries per track) m-performance obtained
submitted run track. Note MAP performance run1 best track
virtue way run1 selected. However, run1 necessarily optimal
run respect p@5 p@10. addition, compare performance methods
CombSUM CombMNZ fusion techniques; recall methods,
rely solely retrieval scores, special cases methods. nutshell,
evaluate eectiveness fusion approach, fusion methods
serve reference comparisons, attaining high precision top ranks respect
(i) lists fused, (ii) best performing runs track respect
precision top ranks.
note fusing three (MAP) eective runs track constitute
real-life retrieval scenario quality lists fused known practice,
rather potentially predicted (Carmel & Yom-Tov, 2010). Yet, setup
suitable conservative evaluation methods, specically, studying ability
eectively fuse lists high quality. Nevertheless, Section 4.2.6 also present
performance methods fusing three runs randomly selected
runs track.
Experiments setting k, number documents list fused, values
{10, 20, 30, 40, 50, 75, 100} showed fusion methods compare
approach, specically CombMNZ (Fox & Shaw, 1994; Lee, 1997), often attain (near) optimal
precision-at-top-ranks performance k = 20. turns out, also case
eective fusion methods. Hence, experiments follow based using top
276

fiFusing Retrieved Lists Based Inter-Document Similarities

k = 20 documents run fused. Section 4.2.4 present eect k
performance.
main goal evaluation follow focus underlying principles
proposed fusion approach, potential eectiveness. would like thoroughly
compare dierent proposed methods utilizing inter-document similarities,
factors aect performance, rather engage excessive performance optimization. goals mind, start ameliorating eects free-parameter
values. setting values free parameters methods incorporate,
reference comparisons, optimize average p@5 performance
entire set queries track6 . Thus, note p@10 performance numbers
present necessarily optimal ones could attained. Yet, experimental setup realistic optimizing performance evaluation
metrics separately. Then, Sections 4.2.3 4.2.4 present eect performance
varying values free parameters methods. Furthermore, Section 4.2.5
present performance eective methods values free parameters
learned using cross-validation performed queries. value ancestry parameter
, incorporated methods, chosen {5, 10, 20, 30, 40, 50}. value
, controls reliance retrieval scores versus inter-document-similarities,
chosen {0.1, 0.2, . . . , 1}.
inter-list compatibility retrieval scores, normalize score document
list respect sum scores list; list negative retrieval scores,
usually due using logs, use exponent score normalization7 .
4.1.3 Efficiency Considerations.
number documents (document instances) graphs construct
hundreds8 . Hence, computing inter-document similarities incur signicant
computational overhead. Even entire document content quickly accessible,
document snippets, example, could used computing inter-document similarities.
(This future venue intend explore.) Similar eciency considerations made
work clustering results retrieved Web search engines (Zamir & Etzioni, 1998),
work re-ranking search results using clusters top-retrieved documents (Willett,
1985; Liu & Croft, 2004; Kurland & Lee, 2006). addition, note computing
prestige small graphs takes iterations Power method (Golub &
Van Loan, 1996).
4.2 Experimental Results
next present performance numbers fusion approach. Section 4.2.1
present main result performance best-performing models respect
reference comparisons. Then, Section 4.2.2 compare analyze
6. two parameter settings yield p@5, choose one minimizing p@10 provide
conservative estimates performance.
7. Normalizing retrieval scores respect maximum minimum scores list yields almost
exactly performance numbers report here.
8. Note three fused lists contains 20 documents, document instance duplicated,
all, three times.

277

fiKhudyak Kozorovitsky & Kurland

opt. run
run1
run2
run3
CombSUM
BagSum
CombMNZ
BagDupMNZ

trec3
p@5
p@10
76.0
72.2
74.4
72.2
72.8
67.6
76.0
71.2
80.8ab
74.6b
83.2oabc 78.8om
abc
80.8ab
74.6b
83.2ab 79.0om
abc

trec9
p@5
p@10
60.0
53.1
60.0
53.1
45.8o
38.8o
38.3o
34.6o
52.9bc 48.5bc
59.6m
48.1bc
bc
55.0bc 48.8bc
60.4m
47.9bc
bc

trec10
p@5
p@10
63.2
58.8
63.2
58.8
54.4
50.2
55.6
46.8o

71.2abc 61.0bc
71.2oabc 61.0bc
71.2oabc 61.0bc
72.0oabc 61.0bc

trec12
p@5
p@10
54.5
48.6
51.1
44.8
52.5
48.6
51.5
45.2o
53.7
49.2ac
55.4ac
49.2ac
53.9
49.2ac
56.6m
49.0ac
abc

Table 3: Main result table. performance two eective fusion methods,
BagSum BagDupMNZ; = 1, amount CombSUM CombMNZ,
respectively. best performance column boldfaced. Statisticallysignicant dierences opt. run, run1, run2, run3, marked o, a,
b, c, respectively. (Here after, mark statistically-signicant
dierences run1, run2 run3 avoid cluttering presentation,
convey additional insight.) Statistically-signicant dierences
BagSum CombSUM, BagDupMNZ CombMNZ, marked
m. values (, ) yield optimal average p@5 performance
BagSum (0.4, 5), (0.6, 40), (0, 5) (0.1, 5) trec3, trec9, trec10,
trec12, respectively; BagDupMNZ, (0.7, 5), (0.1, 20), (0.1, 5), (0.1, 20) yield
optimal average p@5 performance trec3, trec9, trec10, trec12, respectively.

performance proposed fusion methods. futher study merits using interdocument similarities Section 4.2.3. eect performance additional factors, e.g.,
number documents lists fused (k), presented Section 4.2.4. Section
4.2.5 presents performance numbers eective models values free
parameters learned using cross validation performed across queries. noted above,
(and including) Section 4.2.5, evaluation based fusing three eective
runs track. Section 4.2.6 evaluate performance methods fusing
runs randomly selected. Section 4.2.7 present analysis overlap
relevant non-relevant documents lists fused sheds light
reasons relative eectiveness approach respect standard
fusion.
4.2.1 Main Result
Table 3 presents main result. present performance numbers two
eective methods, namely, BagSum BagDupMNZ. (See Section 4.2.2 in-depth
analysis performance fusion methods.) Recall = 1 i.e.,
using inter-document-similarity information methods amount CombSUM
CombMNZ, respectively.
rst observation based Table 3 reference comparisons (track
evaluation measure) BagSum BagDupMNZ methods outperform often
278

fiFusing Retrieved Lists Based Inter-Document Similarities

substantial statistically-signicant degree three fused runs. Furthermore,
many cases, performance methods also superior opt. run. also
holds, example, p@5 BagDupMNZ trec12, track performance
runs fused (specically, run2 run3) quite opt. run.
trec9, methods performance several cases run1, also
opt. run respect p@5 p@10. However, performance dierences
statistically signicant. Also, note run1 far eective run2 run3;
hence, run2 run3 potentially relatively relevant documents contribute
addition run1. Nevertheless, performance methods trec9
substantially better two fused runs (run2 run3); and, terms
p@5 metric performance optimized performance trec9
BagSum BagDupMNZ statistically-signicantly better (for BagDupMNZ also
employing Bonferroni correction) special case, is, CombSUM
CombMNZ, respectively. fact p@5 performance CombSUM CombMNZ
much worse run1 trec9, case tracks, could
attributed fact number relevant documents shared among
three runs lowest observed respect considered tracks. (We present
analysis number relevant documents shared runs Section 4.2.7.)
scenario methods yield much merit using inter-document similarities,
evident p@5 performance improvements post CombSUM CombMNZ
trec9.
generally, see Table 3 majority relevant comparisons
methods performance superior special cases utilize interdocument similarities (CombSUM CombMNZ). p@5 improvements trec9,
example, noted above, substantial statistically signicant. Furthermore,
methods post statistically signicant improvements runs fused,
opt. run, CombSUM CombMNZ do. Thus, ndings attest merits
utilizing inter-document similarities fusion.
Analysis MAP Performance. Although focus evaluation present
precision top ranks, also interested general quality ranking
induced methods. Accordingly, present MAP performance BagSum
BagDupMNZ methods Table 4. avoid potential metric-divergence issues (Azzopardi,
Girolami, & van Rijsbergen, 2003; Morgan, Grei, & Henderson, 2004; Metzler & Croft,
2005), is, optimizing performance one retrieval metric presenting performance
numbers dierent retrieval metric, optimize performance methods
case respect MAP.
see Table 4 except trec9, methods outperform quite
cases, statistically signicantly fused runs, opt. run. (Recall run1
best MAP-performing run track; i.e., terms MAP, run1 opt. run.) Moreover,
methods consistently outperform corresponding special cases, CombSUM
CombMNZ.
Comparison Rank-Based Fusion Methods focus paper
fusion methods utilize retrieval scores, Table 5 compare performance
BagDupMNZ (one two best-performing methods) two fusion methods
279

fiKhudyak Kozorovitsky & Kurland

opt. run
run1
run2
run3
CombSUM
BagSum
CombMNZ
BagDupMNZ

trec3
MAP
10.4
10.4
9.6
9.5
10.9bc
11.4om
abc
10.9bc
11.5om
abc

trec9
MAP
28.2
28.2
18.4o
16.8o
24.9bc
26.6bc
25.5bc
27.0bc

trec10
MAP
30.7
30.7
27.7o
21.6o
37.2bc
37.3bc
37.2bc
38.4bc

trec12
MAP
28.8
28.8
28.4
28.1
30.3oa
30.5oa
30.3oa
30.5oa

Table 4: MAP performance numbers. best performance column boldfaced.
Statistically signicant dierences opt. run, run1, run2, run3, marked
o, a, b, c, respectively. Statistically signicant dierences
BagSum CombSUM, BagDupMNZ CombMNZ, marked
m.

round robin
Borda
BagDupMNZ

trec3
p@5 p@10
76.4
73.2
80.4
78.6
83.2 79.0rb

trec9
p@5 p@10
50.4
45.6
55.0
48.3
60.4rb 47.9

trec10
p@5 p@10
61.6
55.2
71.2
62.0
72.0r 61.0r

trec12
p@5 p@10
53.9
47.3
54.3
48.8
56.6 49.0

Table 5: Comparison rank-based fusion methods. Statistically-signicant dierences
BagDupMNZ round robin Borda marked r b,
respectively.

utilize ranks documents rather scores. rst simple round robin
approach wherein order runs used run1, run2 run3. second rank-based
fusion method Borda (Young, 1974), scored number documents
ranked higher lists:
def X
#{d Li : SLi (d ) <= SLi (d)}.
PBorda (d) =
Li

see Table 5 BagDupMNZ outperforms round robin
Borda methods reference comparisons. Many performance dierences (especially round robin) quite substantial also statistically signicant.
Upper Bound Analysis study potential approach completely neutralizing eects free-parameter values, present Table 6 upper bound analysis
p@5 performance BagDupMNZ. end, query use free-parameter
values BagDupMNZ yield optimized p@5 query. Recall performance
BagDupMNZ reported based free-parameter values set optimize average
280

fiFusing Retrieved Lists Based Inter-Document Similarities

OptRunPerQuery
opt. run
run1
CombMNZ
BagDupMNZ

trec3
91.6
76.0p
74.4p
80.8pa
89.6oam

trec9
79.6
60.0p
60.0p
55.0p
68.3po


trec10
84.4
63.2p
63.2p
71.2po

79.6po


trec12
84.8
54.5p
51.1p
53.9p
66.1po


Table 6: Upper bound analysis p@5 performance BagDupMNZ. Specically,
query use BagDupMNZ free-parameter values optimized p@5
query. reference comparison, query consider best p@5performing run (OptRunPerQuery). performance run1 (the best (MAP)
performing among three fused runs), opt. run (the run yields best
average p@5 per track), CombMNZ presented reference. p, o, a,
mark statistically signicant dierences OptRunPerQuery, opt. run,
run1, CombMNZ, respectively.

opt. run
run1
run2
run3
SetUni
SetSum
SetMNZ
BagUni
BagSum
BagDupUni
BagDupMNZ

trec3
p@5
p@10
76.0
72.2
74.4
72.2
72.8
67.6
76.0
71.2
79.2b
75.0b
82.8oabc 78.0oabc
82.0ab
77.2oabc
82.4ab
78.8oabc

83.2abc 78.8oabc
82.0ab
78.6oabc
83.2ab 79.0oabc

trec9
p@5
p@10
60.0
53.1
60.0
53.1
45.8o
38.8o
38.3o
34.6o

42.5a
39.2oa
59.2bc 49.2bc
61.3bc 49.2bc
59.2bc 47.9bc
59.6bc 48.1bc
57.5bc 48.1bc
60.4bc 47.9bc

trec10
p@5
p@10
63.2
58.8
63.2
58.8
54.4
50.2
55.6
46.8o
56.8
48.2oa

71.2abc 61.0bc
71.2oabc 61.0bc
70.8bc
61.2bc
71.2oabc 61.0bc
72.0oabc 60.4bc
72.0oabc 61.0bc

trec12
p@5
p@10
54.5
48.6
51.1
44.8
52.5
48.6
51.5
45.2o

47.3
41.5ob
55.4a
48.5ac
55.6ac
48.5ac
53.1
46.5
55.4ac
49.2ac
52.9
47.8
56.6abc 49.0ac

Table 7: Performance comparison proposed fusion methods. best result
column boldfaced. Statistically signicant dierences opt. run, run1, run2,
run3, marked o, a, b, c, respectively.

p@5 performance track. (The runs used fused here). reference
comparison, consider query run track yields best p@5
query (denoted OptRunPerQuery). also present performance opt. run
baseline, used above, run yields best average p@5 performance per
track. performance run1 (the (MAP) eective three fused runs)
CombMNZ presented reference well.
see Table 6 performance BagDupMNZ substantially (and statistically signicantly) better opt. run, run1 CombMNZ performance
dierences being, naturally, much higher Table 3. Thus, see using
inter-document similarities fusion yield substantial merits; and, optimizing
281

fiKhudyak Kozorovitsky & Kurland

free-parameter values approach per query yields better performance using
values queries, could expected. already noted, Section 4.2.5
study performance approach using cross-validation set free-parameter
values.
also see Table 6 except trec3, performance BagDupMNZ
much inferior (and statistically signicantly so) selecting best-performing
run per query (OptRunPerQuery). surprise performance run1
(the eective average among runs fused) also substantially (and
statistically signicantly) worse OptRunPerQuery; observation holds
opt. run, shows dierent runs eective dierent queries.
4.2.2 Performance Analysis Proposed Fusion Methods
Table 7 compare performance proposed fusion methods. rst observation using retrieval scores documents lists, top inter-documentsimilarity information, important. Indeed, methods sux Uni use
uniform query-similarity estimate, i.e., disregard retrieval scores documents
lists, post performance almost always worse counterparts
utilize retrieval scores inducing query similarity. (Compare SetUni SetSum
SetMNZ; BagUni BagSum; and, BagDupUni BagDupMNZ.) Furthermore,
utilizing retrieval scores results performance almost always better many
cases statistically signicant degree run2 run3; performance
also transcends run1 opt. run, except trec9.
also see Table 7 bag representation lists yields better performance, general, using set representation. (Compare, example, BagUni
SetUni, BagSum SetSum.) Recall bag representation document represented nodes corresponding instances lists, set
representation document represented single node. Hence, fact documents occurrences many fused lists draw prestige-status support
via inter-document-similarities documents fewer occurrences positive impact
performance.
Thus, surprise BagSum BagDupMNZ methods use bagrepresentation lists, utilize retrieval scores documents lists,
among eective fusion methods proposed.
4.2.3 Performance Impact Using Inter-Document-Similarities
parameter Equation 1 (Section 2) controls reliance retrieval scores versus inter-document similarity information. Setting = 1, i.e., using inter-documentsimilarity information, results XSum methods equivalent CombSUM,
XMNZ methods equivalent CombMNZ. Table 3 showed BagSum
outperforms CombSUM BagDupMNZ outperforms CombMNZ. turn
study performance XSum XMNZ methods respect special
cases, is, CombSUM CombMNZ, respectively.
see Table 8 majority relevant comparisons (track evaluation
metric), methods outperforms special case, several dierences
282

fiFusing Retrieved Lists Based Inter-Document Similarities

CombSUM
SetSum
BagSum

trec3
p@5 p@10
80.8
74.6
82.8 78.0m
83.2 78.8m

trec9
p@5
p@10
52.9
48.5

59.2
49.2

59.6
48.1

trec10
p@5 p@10
71.2 61.0
71.2 61.0
71.2 61.0

CombMNZ
SetMNZ
BagDupMNZ

80.8
82.0
83.2

55.0
61.3m
60.4m

71.2
71.2
72.0

74.6
77.2
79.0m

48.8
49.2
47.9

61.0
61.0
61.0

trec12
p@5
p@10
53.7
49.2
55.4
48.5
55.4
49.2
53.9
55.6
56.6m

49.2
48.5
49.0

Table 8: Comparison similarity-based fusion methods special cases, CombSUM CombMNZ. Best performance column boldfaced. Statistically
signicant dierence method special case marked m.

statistically signicant. therefore conclude inter-document-similarities
indeed helpful source information fusion.
study eect varying value p@5 performance one
two eective methods, BagDupMNZ, Figure 1. rst observation
except trec9, values , BagDupMNZ yields performance transcends
run1, eective among three fused runs; values
performance BagDupMNZ also better opt. run. Trec9 exception
BagDupMNZ outperforms run1, also opt. run, single value . Recall
trec9 performance run1 far better fused runs.
Another observation make based Figure 1 tracks 0.6
yields better performance attained using lower values . nding
demonstrates importance utilizing retrieval scores documents specied above.
= 1 inter-document-similarities used BagDupMNZ amounts CombMNZ.
also see many cases wherein {0.7, 0.8, 0.9} BagDupMNZ outperforms
CombMNZ; trec9 trec12 improvements quite substantial. ndings
echo specied regard merits utilizing inter-document-similarities
fusion. Finally, note performance merits attained using inter-document
similarities even emphasized runs fused randomly selected
available track (as show Section 4.2.6), rather best
(MAP) performing ones used here.
4.2.4 Analysis
Effect . similarity-based fusion methods incorporate two free parameters: ,
controls reliance retrieval scores versus inter-document-similarities; eect
studied above; and, , number nearest neighbors considered
node graphs use. Figure 2 analyze eect p@5 performance
BagDupMNZ.
see Figure 2 small values ( {5, 10, 20}) often yield better performance larger values. nding reported work utilizing nearest283

fiKhudyak Kozorovitsky & Kurland

trec3

trec9

84

61
60

82

59
58

78

p@5

p@5

80

76

57
56
55

74

54

opt. run
run1
CombMNZ
BagDupMNZ

72
70
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

opt. run
run1
CombMNZ
BagDupMNZ

53
52
0.9

1

0.1

0.2

0.3

0.4

0.5

0.6





trec10

trec12

0.7

0.8

0.9

1

0.9

1

74
56

72
70

54
p@5

p@5

68
66

52

64
50

62

opt. run
run1
CombMNZ
BagDupMNZ

60
58
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

opt. run
run1
CombMNZ
BagDupMNZ

48
0.9

1



0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8



Figure 1: Eect varying value (refer Equation 1 Section 2) p@5
performance BagDupMNZ; = 1 amounts CombMNZ. performance
opt. run, run1 CombMNZ depicted horizontal lines reference.
Note: gures scale.

neighbors-based graphs re-ranking single retrieved list (Diaz, 2005; Kurland & Lee,
2005). Furthermore, see small values yield performance transcends
run1 opt. run, except trec9. Another observation make based
Figure 2 corpora, values , BagDupMNZ outperforms
special case, CombMNZ.
Effect k. experimental design used insofar, presented
Section 4.1, based observation attaining high precision top ranks calls
fusion relatively short retrieved lists. Indeed, performance numbers presented
demonstrated eectiveness fusing lists 20 documents each. Figure 3 present
eect k (the number documents retrieved list) p@5 performance
BagDupMNZ CombMNZ.
284

fiFusing Retrieved Lists Based Inter-Document Similarities

trec3

trec9

84

61
60

82

59
58

78

p@5

p@5

80

76

57
56
55

74

54

opt. run
run1
CombMNZ
BagDupMNZ

72
70
5 10

20

30

40

50

75

opt. run
run1
CombMNZ
BagDupMNZ

53
52
100

5 10

20

30

40

50





trec10

trec12

75

100

74
56

72
70

54
p@5

p@5

68
66

52

64
50

62

opt. run
run1
CombMNZ
BagDupMNZ

60
58
5 10

20

30

40

50

75

opt. run
run1
CombMNZ
BagDupMNZ

48
100



5 10

20

30

40

50

75

100



Figure 2: Eect p@5 performance. performance opt. run, run1
CombMNZ depicted horizontal lines reference. Note: gures
scale

see Figure 3 almost values k performance BagDupMNZ
transcends CombMNZ. nding also holds respect opt. run, except
trec9 case. ndings attest merits utilizing inter-document
similarities fusion. Furthermore, small values k, specically k = 20 used
heretofore, often yield (near) optimal performance BagDupMNZ CombMNZ.
Thus, indeed see fusing short lists, specically, utilizing inter-document similarities, often leads eective precision-at-top-ranks performance.
4.2.5 Learning Free-Parameter Values
performance numbers presented insofar based free-parameter values yield
optimal average p@5 performance respect set queries track. experimental setup enabled us study potential performance approach,
carefully analyze dierent factors aect it.
285

fiKhudyak Kozorovitsky & Kurland

trec3

trec9

84

62

82

60
58

80
p@5

p@5

56
78
76

54
52
50

74
opt. run
run1
CombMNZ
BagDupMNZ

72
70
10

20

30

40

50

75

opt. run
run1
CombMNZ
BagDupMNZ

48
46
100

10

20

30

40

50

75

k

k

trec10

trec12

100

74
56

72
70

54
p@5

p@5

68
66

52

64
50

62

opt. run
run1
CombMNZ
BagDupMNZ

60
58
10

20

30

40

50

75

opt. run
run1
CombMNZ
BagDupMNZ

48
100

k

10

20

30

40

50

75

100

k

Figure 3: Eect varying k, number documents fused list (run), p@5
performance BagDupMNZ. performance opt. run, run1, CombMNZ
depicted reference. Note: gures scale.

Now, turn explore question whether eective values free parameters
methods, , generalize across queries; is, whether values
learned9 . end, employ leave-one-out cross validation procedure wherein
free parameters method set query values optimize average p@5
performance queries track. resultant performance numbers
best performing methods, BagSum BagDupMNZ, presented Table 9.
see Table 9 BagSum BagDupMNZ post better performance,
vast majority relevant comparisons (track evaluation measure), opt.
run, three runs fused; many performance improvements
statistically signicant.
9. Note analysis different studying effect free-parameter values
average performance presented above.

286

fiFusing Retrieved Lists Based Inter-Document Similarities

opt. run
run1
run2
run3
CombSUM
BagSum
CombMNZ
BagDupMNZ

trec3
p@5
p@10
76.0
72.2
74.4
72.2
72.8
67.6
76.0
71.2
80.8ab
74.6b
83.2oabc 78.8om
abc
80.8ab
74.6b
82.4ab
79.0om
abc

trec9
p@5
p@10
60.0
53.1
60.0
53.1
45.8o
38.8o
38.3o
34.6o
52.9bc 48.5bc
57.9bc 47.3bc
55.0bc 48.8bc
60.4m
47.9bc
bc

trec10
p@5
p@10
63.2
58.8
63.2
58.8
54.4
50.2
55.6
46.8o

71.2abc 61.0bc
67.6m
61.4bc
bc

71.2abc 61.0bc
70.8bc
60.4bc

trec12
p@5
p@10
54.5
48.6
51.1
44.8
52.5
48.6
51.5
45.2o
53.7
49.2ac
54.7a
49.2ac
53.9
49.2ac
56.6m
49.0ac
abc

Table 9: Performance numbers employing leave-one-out cross validation set freeparameter values. best performance column boldfaced. Statisticallysignicant dierences opt. run, run1, run2, run3, marked o,
a, b, c, respectively. Statistically signicant dierences BagSum
CombSUM, BagDupMNZ CombMNZ, marked m.

next compare methods special cases utilize inter-document
similarities. is, compare BagSum CombSUM BagDupMNZ
CombMNZ. respect p@5 metric performance optimized
learning phase methods outperform special cases tracks, except
trec10; improvements also statistically signicant (e.g., refer
BagDupMNZ versus CombMNZ trec9 trec12). Furthermore, note
cases CombSUM CombMNZ outperform methods p@10.
attribute nding metric divergence issue (Azzopardi et al., 2003; Morgan et al.,
2004; Metzler & Croft, 2005) optimizing performance learning phase respect
one metric (p@5 case), testing performance respect another
metric (p@10 case), albeit somewhat connected. Recall methods
incorporate two free parameters, CombSUM CombMNZ methods incorporate
free parameters. Additional examination Table 9 reveals methods post
statistically signicant improvements runs fused opt. run CombSUM
CombMNZ do.
all, results demonstrate eectiveness methods employing
cross validation set free-parameter values.
4.2.6 Fusing Randomly Selected Runs
Heretofore, evaluation approach based fusing (MAP) eective
runs track. turn study eectiveness best performing fusion
methods fusing randomly selected runs.
select 20 random triplets runs track. best performing run among
three denoted run1, second best denoted run2, worst among three
denoted run3. fuse three runs using either standard fusion methods,
CombSUM CombMNZ, methods generalize these, namely, BagSum
287

fiKhudyak Kozorovitsky & Kurland

run1
run2
run3
CombSUM
BagSum
CombMNZ
BagDupMNZ

trec3
p@5
p@10
68.9
57.4
57.4
55.4
42.3
41.4
65.6bc 61.3abc
76.1m
70.4m
bc
abc
65.7bc 61.3abc
75.7m
70.1m
bc
bc

trec9
p@5
p@10
22.1
19.6
16.2
14.7
10.9
10.2
19.6abc 17.6abc
22.0m
18.2m
abc
abc
20.0abc 17.5abc
21.3m
18.0m
abc
abc

trec10
p@5
p@10
32.7
28.5
28.5
24.9
18.3
16.0
32.4bc
28.3bc
36.6m
30.5m
abc
abc
33.6bc
28.7bc
36.5m
30.2m
abc
abc

trec12
p@5
p@10
46.0
39.9
39.9
34.4
27.4
23.2
44.4abc 37.7abc
47.8bc 40.6m
bc
44.4abc 37.7abc
46.6bc
40.4bc

Table 10: Fusing randomly selected runs. performance numbers represent averages
20 random samples triplets runs. best performance column
boldfaced. Statistically signicant dierences fusion method run1,
run2, run3, marked a, b, c, respectively. Statistically signicant dierences BagSum CombSUM, BagDupMNZ
CombMNZ, marked m.

BagDupMNZ, respectively. performance numbers presented Table 10 represent
averages 20 samples.10 free parameters BagSum BagDupMNZ
set values optimizing average p@5 performance queries track per triplet
runs. (The optimization procedure described Section 4.1 used.) Statistically
signicant dierences two methods determined based average (over 20
samples) performance per query.
rst observation based Table 10 methods highly eective fusing
randomly selected runs. almost reference comparisons (track evaluation measure),
outperform three fused runs; improvements substantial
statistically signicant. exception run1 trec9, outperforms
fusion methods.
also see Table 10 BagSum slightly eective BagDupMNZ.
However, fusing best-performing runs track, case above,
picture somewhat reversed. attribute nding relatively low overlap
relevant documents randomly selected runs. Specically, show
overlap much smaller best-performing runs. Thus, use information
regarding multiple appearances lists, quite emphasized BagDupMNZ,
signicant merit. Note also holds standard fusion methods. is,
superiority CombMNZ CombSUM former emphasizes appearances multiple
lists latter less substantial fusing best performing
runs.
Perhaps important observation make based Table 10
methods always eective standard fusion approaches, constitute special cases; is, compare BagSum CombSUM BagDupMNZ
10. note drop performance moving run1 run2 run3 highest trec9.
many runs trec9 low quality contain relevant documents
(Meister et al., 2010).

288

fiFusing Retrieved Lists Based Inter-Document Similarities

trec3

Best runs
Random runs

1
59.2
66.9

Rel
2
24.6
25.3

1
56.9
66.6

Rel
2
26.6
22.8

3
16.2
7.7

trec9

Non-Rel
1
2
3
81.1 14.5 4.3
84.9 12.9 2.2

1
61.4
78.6

Rel
2
25.3
24.4

1
32.6
48.5

Rel
2
24.6
27.8

trec10

Best runs
Random runs

3
16.5
10.6

3
13.3
6.3

1
79.4
78.6

Non-Rel
2
3
14.0 6.6
17.8 3.6

trec12

Non-Rel
1
2
3
77.4 16.0 6.6
79.6 14.9 5.5

3
42.8
23.6

1
51.9
68.0

Non-Rel
2
3
23.3 24.8
20.0 12.4

Table 11: percentage (non-) relevant documents (of appear least
one three runs fused) appear one (1), two (2) , three (3)
runs. number documents, k, considered run 20. three runs
either best (MAP) performing track, randomly selected;
latter case, percentages represent averages 20 random samples. Percentages
may sum 100 due rounding.

CombMNZ. Many performance dierences also statistically signicant. Furthermore, relevant comparisons, CombSUM CombMNZ outperformed
run1 best performing run among three fused reverse holds
methods. Thus, results support merits utilizing inter-document similarities
fusion.
4.2.7 Analysis (non-) Relevant Documents Overlap Lists
results presented show using inter-document-similarities highly eective
fusing randomly selected runs. fact, relative performance improvements
standard fusion methods utilize inter-document similarities larger
observed fusing best-performing runs. Furthermore, ndings
presented attested relative limited merit heavily emphasizing information
regarding multiple appearances documents randomly selected runs respect
case best-performing runs. Hence, turn analyze relevant
non-relevant document overlap runs using randomly-selected runs
using best-performing runs.
Table 11 present percentage (non-) relevant documents, appearing
least one three runs fused, appear one, two, three runs.
use top-20 documents run above. present percentages three
best-performing runs track three randomly selected runs; latter case,
report averages 20 samples triplets runs. cases, percentages averages
queries track.
rst observation based Table 11 tracks, majority relevant
documents appears one three runs. nding supports motivation
approach; is, using inter-document similarities transfer relevancestatus support dierent (similar) relevant documents across lists. also
289

fiKhudyak Kozorovitsky & Kurland

see nding holds non-relevant documents majority non-relevant
documents appears one three fused runs. note previous reports,
supporting certain extent cluster hypothesis, already shown majority
nearest neighbors relevant document similarity space tend relevant;
while, non-relevant document tend relevant non-relevant (Kurland,
2006). study performed upon documents retrieved response query
case here. Hence, relevant documents tend maintain prestige-status support
within set relevant documents, non-relevant documents tend spread support
among relevant non-relevant documents. Furthermore, percentage non-relevant
documents appears exactly one run larger relevant documents.
nding echoes used explain eectiveness standard fusion methods
emphasize appearance many lists i.e., overlap relevant documents
lists higher non-relevant documents (Lee, 1997).
also see Table 11 percentage relevant documents appear
one run much larger using randomly selected runs using bestperforming runs. words, relevant-document overlap across lists bestperforming-runs case higher randomly-selected runs case. nding
helps explain observations made above: (i) relative performance gains posted
methods respect standard fusion approaches, utilize interdocument similarities, larger randomly selected runs best performing
runs, (ii) heavily emphasizing document appearances multiple runs eective
random-runs case best-runs case.
explore ndings stated, present Figure 4 percentage
relevant documents appear one three runs function number
documents (k) run. evident Figure 4 best-performing runs case
percentages lower randomly-selected runs case, values k.
nding supports conclusion regard relative eectiveness
approach best-performing runs versus randomly-selected runs. Furthermore,
tracks, values k, least 40% relevant documents
runs fused appear one three runs. nding demonstrates
mismatch relevant-document sets runs scenario motivating
development fusion approach.

5. Conclusion Future Work
presented novel approach fusing document lists retrieved response
query. approach lets similar documents across (and within) lists provide relevance
status support other. use graph-based method model propagation
relevance status documents lists. propagation governed interdocument-similarities retrieval scores documents lists.
Empirical evaluation demonstrated eectiveness approach. showed
methods highly eective fusing TREC runs. nding holds whether runs
eective per TRECs track (challenge), randomly selected track.
also showed performance methods transcends eective standard
fusion methods utilize retrieval scores ranks documents.
290

fiFusing Retrieved Lists Based Inter-Document Similarities

trec3

trec9
100
% rel docs appear single run

% rel docs appear single run

100

80

60

40

20
best runs
random runs

0
10

20

30

40

50

75

80

60

40

20
best runs
random runs

0
100

10

20

30

40

50

k
trec10

100

trec12
100
% rel docs appear single run

100
% rel docs appear single run

75
k

80

60

40

20
best runs
random runs

0
10

20

30

40

50

75

80

60

40

20
best runs
random runs

0
100

k

10

20

30

40

50

75

100

k

Figure 4: percentage relevant documents (of appear least one
three runs fused) appear one runs function
number documents run (k). runs either best-performing
track, randomly selected; latter case, numbers represent averages
20 random samples.

One family proposed methods, namely, set-based family, incorporate
fusion method relies retrieval scores/ranks. specically, showed
inter-document-similarities utilized, set-based methods reduce
standard fusion method incorporate. used CombSUM CombMNZ
fusion methods examples instantiating set-based fusion approaches. Naturally then,
utilizing additional fusion methods rely retrieval scores/ranks future venue
intend explore.
Another venue intend explore eect approach diversity
results nal result list (Carbonell & Goldstein, 1998); and, exploring ways adapt
methods improve aspect coverage result list (Zhai, Cohen, & Laerty,
2003).
291

fiKhudyak Kozorovitsky & Kurland

Acknowledgments
thank reviewers helpful comments. also thank Malka Gorne
helpful comments. paper based upon work supported part Israel Science
Foundation grant no. 557/09, IBMs SUR award. opinions, ndings
conclusions recommendations expressed material authors
necessarily reect sponsoring institutions.

Appendix
Proposition 1. Let f fusion method based retrieval scores/ranks, e.g.,
CombSUM CombMNZ; f (d) score assigned f document appears
least one lists fused. Suppose use f (d) query-similarity estimate
q) def
set-based group methods, is, sim(d,
= f (d). Then, using w t[1] (i.e.,
setting = 1 Equation 1) results final retrieval score Table 1 (S core(d))
rank-equivalent f (d).
Proof. node v graph corresponds different document d, |V | incoming

q) f (d). Hence, weight unique
; sim(d,
edges weight P sim(d,q)
v V

,q)
sim(v

solution Equation 2, serves ds nal retrieval score, rank-equivalent
f (d).
Proposition 2. Using w t[1] BagSum algorithm amounts CombSUM algorithm.
Proof. node v graph corresponds document-instance Lji document d;
and, |V | incoming edges, weight

S(Lji )
.
v V sim(v ,q)

P

weight is, therefore,

prestige score P (Lji ; G[] ) v computed Equation 2 . denition, nal
P
retrieval score i,j:Lj P (Lji ; G[] ). score (following denitions

P
(d)
above) Li :dLi P Lid , rank-equivalent PCombSU (d).
v V

sim(v ,q)

Proposition 3. Using w t[1] BagDupMNZ algorithm amounts CombMNZ algorithm.

Proof. Let Lji document-instance document d. Following denitions Proposition 2, prestige value single copy Lji newly dened list

P

SLi (d)
,q) .
sim(v

v V

n = #{Li : Li } copies new list. Therefore, denition, nal
P
(d)
retrieval score n Li :dLi P Lid , rank equivalent PCombM N Z (d).
v V

sim(v ,q)

References
Aslam, J. A., & Montague, M. (2001). Models metasearch. Proceedings SIGIR,
pp. 276284.
Azzopardi, L., Girolami, M., & van Rijsbergen, K. (2003). Investigating relationship
language model preplexity IR precision-recall measures. Proceedings
SIGIR, pp. 369370. Poster.
292

fiFusing Retrieved Lists Based Inter-Document Similarities

Balinski, J., & Danilowicz, C. (2005). Re-ranking method based inter-document distances. Information Processing Management, 41 (4), 759775.
Beitzel, S. M., Jensen, E. C., Chowdhury, A., Frieder, O., Grossman, D. A., & Goharian,
N. (2003). Disproving fusion hypothesis: analysis data fusion via eective
information retrieval strategies. Proceedings SAC, pp. 823827.
Beitzel, S. M., Jensen, E. C., Frieder, O., Chowdhury, A., & Pass, G. (2005). Surrogate
scoring improved metasearch precision. Proceedings SIGIR, pp. 583584.
Belkin, N. J., Cool, C., Croft, W. B., & Callan, J. P. (1993). eect multiple query
representations information retrieval system performance. Proceedings SIGIR,
pp. 339346.
Brin, S., & Page, L. (1998). anatomy large-scale hypertextual web search engine.
Proceedings 7th International World Wide Web Conference, pp. 107117.
Callan, J. P., Lu, Z., & Croft, W. B. (1995). Searching distributed collections inference
networks. SIGIR, pp. 2128.
Carbonell, J. G., & Goldstein, J. (1998). use MMR, diversity-based reranking
reordering documents producing summaries. Proceedings SIGIR, pp. 335
336.
Carmel, D., & Yom-Tov, E. (2010). Estimating Query Difficulty Information Retrieval. Synthesis lectures information concepts, retrieval, services. Morgan &
Claypool.
Chowdhury, A., Frieder, O., Grossman, D. A., & McCabe, M. C. (2001). Analyses
multiple-evidence combinations retrieval strategies. Proceedings SIGIR, pp.
394395. poster.
Craswell, N., Hawking, D., & Thistlewaite, P. B. (1999). Merging results isolated
search engines. Proceedings Australian Database Conference, pp. 189200.
Crestani, F., & Wu, S. (2006). Testing cluster hypothesis distributed information
retrieval. Information Processing Management, 42 (5), 11371150.
Croft, W. B. (Ed.). (2000a). Advances Information Retrieval: Recent Research
Center Intelligent Information Retrieval. No. 7 Kluwer International Series
Information Retrieval. Kluwer.
Croft, W. B. (2000b). Combining approaches information retrieval. Croft (Croft,
2000a), chap. 1, pp. 136.
Croft, W. B., & Thompson, R. H. (1984). I3 R: new approach design document retrieval systems. Journal American Society Information Science
Technology, 38 (6), 389404.
Danilowicz, C., & Balinski, J. (2000). Document ranking based upon Markov chains. Information Processing Management, 41 (4), 759775.
Das-Gupta, P., & Katzer, J. (1983). study overlap among document representations.
Proceedgins SIGIR, pp. 106114.
293

fiKhudyak Kozorovitsky & Kurland

Diaz, F. (2005). Regularizing ad hoc retrieval scores. Proceedings Fourteenth
International Conference Information Knowledge Management (CIKM), pp.
672679.
Diaz, F. (2007). Performance prediction using spatial autocorrelation. Proceedings
SIGIR, pp. 583590.
Diaz, F. (2008). method transferring retrieval scores collections non
overlapping vocabularies. Proceedings SIGIR, pp. 805806. poster.
Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methods
Web. Proceedings World Wide Web Conference, pp. 613622, Hong
Kong.
Erkan, G. (2006). Language model based document clustering using random walks.
Proceedings HLT/NAACL.
Erkan, G., & Radev, D. R. (2004). LexRank: Graph-based lexical centrality salience
text summarization. Journal Artificial Intelligence Research, 22, 457479.
Fox, E. A., & Shaw, J. A. (1994). Combination multiple searches. Proceedings
TREC-2.
Golub, G. H., & Van Loan, C. F. (1996). Matrix Computations (Third edition). Johns
Hopkins University Press.
Griths, A., Luckhurst, H. C., & Willett, P. (1986). Using interdocument similarity information document retrieval systems. Journal American Society Information
Science (JASIS), 37 (1), 311. Reprinted Karen Sparck Jones Peter Willett,
eds., Readings Information Retrieval, Morgan Kaufmann, pp. 365373, 1997.
Katzer, J., McGill, M., Tessier, J., Frakes, W., & Dasgupta, P. (1982). study
overlap among document representations. Information Technology: Research Development, 1 (2), 261274.
Krikon, E., Kurland, O., & Bendersky, M. (2010). Utilizing inter-passage interdocument similarities re-ranking search results. ACM Transactions Information
Systems, 29 (1).
Kurland, O. (2006). Inter-document similarities, language models, ad hoc retrieval.
Ph.D. thesis, Cornell University.
Kurland, O., & Lee, L. (2005). PageRank without hyperlinks: Structural re-ranking using
links induced language models. Proceedings SIGIR, pp. 306313.
Kurland, O., & Lee, L. (2006). Respect authority! HITS without hyperlinks utilizing
cluster-based language models. Proceedings SIGIR, pp. 8390.
Kurland, O., & Lee, L. (2010). Pagerank without hyperlinks: Structural reranking using
links induced language models. ACM Transactions om Information Systems, 28 (4).
Lavrenko, V., & Croft, W. B. (2001). Relevance-based language models. Proceedings
SIGIR, pp. 120127.
Lawrence, S., & Giles, C. L. (1998). Inquirus, neci meta search engine. Proceedings
World Wide WEB conference, pp. 95105.
294

fiFusing Retrieved Lists Based Inter-Document Similarities

Lee, J. H. (1997). Analyses multiple evidence combination. Proceedings SIGIR, pp.
267276.
Lillis, D., Toolan, F., Collier, R. W., & Dunnion, J. (2006). Probfuse: probabilistic
approach data fusion. Proceedings SIGIR, pp. 139146.
Liu, X., & Croft, W. B. (2004). Cluster-based retrieval using language models. Proceedings
SIGIR, pp. 186193.
Meister, L., Kurland, O., & Kalmanovich, I. G. (2010). Re-ranking search results using
additional retrieved list. Information Retrieval, 1.
Metzler, D., & Croft, W. B. (2005). Markov random eld model term dependencies.
Proceedings SIGIR, pp. 472479.
Mihalcea, R., & Tarau, P. (2004). TextRank: Bringing order texts. Proceedings
EMNLP, pp. 404411. Poster.
Montague, M., & Aslam, J. A. (2002). Condorcet fusion improved retrieval. Proceedings CIKM, pp. 538548.
Morgan, W., Grei, W., & Henderson, J. (2004). Direct maximization average precision
hill-climbing, comparison maximum entropy approach. Tech. rep.
04-0367, MITRE Corporation.
Otterbacher, J., Erkan, G., & Radev, D. R. (2005). Using random walks question-focused
sentence retrieval. Proceedings Human Language Technology Conference
Conference Empirical Methods Natural Language Processing (HLT/EMNLP),
pp. 915922.
Pinski, G., & Narin, F. (1976). Citation inuence journal aggregates scientic publications: Theory, application literature physics. Information Processing
Management, 12, 297312.
Saracevic, T., & Kantor, P. (1988). study information seeking retrieving. iii.
searchers, searches, overlap. Journal American Society Information
Science, 39 (3), 197216.
Selvadurai, S. B. (2007). Implementing metasearch framework content-directed result
merging. Masters thesis, North Carolina State University.
Shokouhi, M. (2007). Segmentation search engine results eective data-fusion.
Proceedings ECIR, pp. 185197.
Shou, X. M., & Sanderson, M. (2002). Experiments data fusion using headline information. Proceedgins SIGIR, pp. 413414.
Soboro, I., Nicholas, C. K., & Cahan, P. (2001). Ranking retrieval systems without relevance judgments. Proceedings SIGIR, pp. 6673.
Tao, T., & Zhai, C. (2006). Regularized esitmation mixture models robust pseudorelevance feedback. Proceedings SIGIR, pp. 162169.
Tsikrika, T., & Lalmas, M. (2001). Merging techniques performing data fusion
web. Proceedings CIKM, pp. 127134.
van Rijsbergen, C. J. (1979). Information Retrieval (second edition). Butterworths.
295

fiKhudyak Kozorovitsky & Kurland

Vogt, C. C., & Cottrell, G. W. (1999). Fusion via linear combination scores. Information
Retrieval, 1 (3), 151173.
Voorhees, E. M., Gupta, N. K., & Johnson-Laird, B. (1994). collection fusion problem.
Proceedings TREC-3.
Voorhees, E. M., & Harman, D. K. (2005). TREC: Experiments evaluation information retrieval. MIT Press.
Willett, P. (1985). Query specic automatic document classication. International Forum
Information Documentation, 10 (2), 2832.
Xu, J., & Croft, W. B. (1996). Query expansion using local global document analysis.
Proceedings SIGIR, pp. 411.
Xu, J., & Croft, W. B. (1999). Cluster-based language models distributed retrieval.
Proceedings SIGIR, pp. 254261.
Yang, L., Ji, D., Zhou, G., Nie, Y., & Xiao, G. (2006). Document re-ranking using cluster
validation label propagation. Proceedings CIKM, pp. 690697.
Young, H. P. (1974). axiomatization Bordas rule. Journal Economic Theory, 9,
4352.
Zamir, O., & Etzioni, O. (1998). Web document clustering: feasibility demonstration.
Proceedings SIGIR, pp. 4654.
Zhai, C., Cohen, W. W., & Laerty, J. D. (2003). Beyond independent relevance: methods
evaluation metrics subtopic retrieval. Proceedings SIGIR, pp. 1017.
Zhai, C., & Laerty, J. (2002). Two-stage language models information retrieval.
Proceedings SIGIR, pp. 4956.
Zhai, C., & Laerty, J. D. (2001). study smoothing methods language models
applied ad hoc information retrieval. Proceedings SIGIR, pp. 334342.
Zhang, B., Li, H., Liu, Y., Ji, L., Xi, W., Fan, W., Chen, Z., & Ma, W.-Y. (2005). Improving
web search results using anity graph. Proceedings SIGIR, pp. 504511.

296

fiJournal Artificial Intelligence Research 41 (2011) 97-130

Submitted 10/10; published 05/11

Soft Constraints Difference Equality
Emmanuel Hebrard

hebrard@laas.fr

CNRS; LAAS
Universite de Toulouse
Toulouse, France

Daniel Marx

dmarx@cs.bme.hu

Humboldt-Universitat zu Berlin
Berlin, Germany

Barry OSullivan

b.osullivan@cs.ucc.ie

Cork Constraint Computation Centre
Department Computer Science, University College Cork
Cork, Ireland

Igor Razgon

ir45@mcs.le.ac.uk

Department Computer Science, University Leicester
Leicester, United Kingdom

Abstract
many combinatorial problems one may need model diversity similarity
sets assignments. example, one may wish maximise minimise number
distinct values solution. formulate problems type use soft variants
well known AllDifferent AllEqual constraints. present taxonomy six
soft global constraints, generated combining two latter ones two standard
cost functions, either maximised minimised. characterise complexity
achieving arc bounds consistency constraints, resolving cases
NP-hardness neither proven disproven. particular, explore depth
constraint ensuring least k pairs variables common value. show
achieving arc consistency NP-hard, however bounds consistency achieved
polynomial time dynamic programming. Moreover, show maximum
number pairs equal variables approximated factor 12 linear time
greedy algorithm. Finally, provide fixed parameter tractable algorithm respect
number values appearing two distinct domains. Interestingly,
taxonomy shows enforcing equality harder enforcing difference.

1. Introduction
Constraints reasoning equality difference within assignments set variables ubiquitous constraint programming. many settings, one needs enforce
given degree diversity similarity solution. example, university timetabling
problem want ensure courses taken particular student held
different times. Similarly, meeting scheduling want ensure participants
meeting scheduled meet time place. Sometimes, problem over-constrained, might wish maximise extent
constraints satisfied. Consider timetabling example: might wish

c
2011
AI Access Foundation. rights reserved.

fiHebrard, Marx, OSullivan & Razgon

maximise number courses scheduled different times students
preferences cannot met.
constraint programming setting requirements diversity similarity amongst
variables specified using global constraints. One commonly used global
constraints AllDifferent (Regin, 1994), enforces variables take pairwise different values. soft version AllDifferent constraint, named SoftAllDiff,
proposed Petit, Regin, Bessiere (2001). proposed two cost metrics
measuring degree satisfaction constraint, minimised
maximised: graph- variable-based cost. two cost metrics generic widely
used (e.g., van Hoeve, 2004). former counts number equalities, whilst latter counts number variables change order satisfy corresponding hard
constraint. wish enforce set variables take equal values,
use AllEqual, soft variant graph-based cost, SoftAllEqual constraint (Hebrard, OSullivan, & Razgon, 2008), soft variant variable-based
cost, AtMostNValue constraint (Beldiceanu, 2001).
considering two constraints (AllDifferent AllEqual), two
costs (graph-based variable-based) objectives (minimisation maximisation)
define eight algorithmic problems related constraints difference equality.
fact, graph-based costs AllDifferent AllEqual dual, six
distinct problems thus defined. structure class constraints illustrated
Figure 1. one, give complexity best known algorithm achieving ac bc. Three problems studied past: minimising cost
SoftAllDiff variable (Petit et al., 2001) graph-based cost (van Hoeve, 2004) polynomial whilst maximising variable-based cost SoftAllDiff NP-hard (Bessiere,
Hebrard, Hnich, Kiziltan, & Walsh, 2006) ac polynomial (Beldiceanu, 2001)
bc. fourth one, maximising variable-based cost SoftAllEqual constraint,
directly mapped known problem: Global Cardinality constraint.
paper,1 introduce two efficient algorithms achieving, respectively, Arc consistency (ac) Bounds consistency (bc) fifth case, minimising variable-based
cost SoftAllEqual. Moreover, computational complexity last remaining
case, maximising graph-based cost SoftAllDiff (or, equivalently, minimising
graph-based cost SoftAllEqual) still unknown. Informally, problem
maximise number pairs variables assigned common value. turns
challenging interesting problem, hard yet addressed several
ways. particular, show that:
Finding solution least k pairs equal variables NP-complete, hence
achieving ac corresponding constraint NP-hard.
domains contiguous, solved polynomial number steps
dynamic programming, hence achieving bc corresponding constraint
polynomial.
exists linear approximation factor

1
2

general case.

1. Part material presented paper based two conference publications (Hebrard et al.,
2008; Hebrard, Marx, OSullivan, & Razgon, 2009).

98

fiSoft Constraints Difference Equality

value appears domains two distinct variables,
problem solved general matching, thus defining another tractable class.
exists fixed parameter tractable algorithm problem parameter
k equal number values appear two distinct domains.
Moreover, show constraint defined setting lower bound graphbased cost SoftAllEqual used efficiently find set similar solutions
set problems, instance promote stability regularity. Similarly, dual constraint
(SoftAllDiff) used find set diverse solutions, instance sample set
configurations. Notice two applications motivated, part, choice
cost metrics.
remainder paper organised follows. Section 2 introduce necessary technical background. complete taxonomy constraints equality difference,
based results authors well original material presented Section 3. Then,
following sections, present new results allowing us close gaps
taxonomy. First, Section 4 present two efficient algorithm achieving ac bc
minimising variable-based cost SoftAllEqual. Second, Section 5 give
proof NP-hardness problem achieving ac maximising graph-based
cost SoftAllDiff. Third, Section 6 present polynomial algorithm achieve
bc constraint. Finally, remaining sections, explore algorithmic
properties preference cost. Section 7, show natural greedy algorithm
approximates maximum number equalities within factor 21 , complexity brought linear time. Next, Section 8, identify polynomial
class constraint. Then, Section 9, identify parameter based class
show SoftAllEqualG constraint fixed-parameter tractable respect
parameter. Finally, Section 10, show results obtained paper
applied sample solutions or, conversely, promote stability. particular,
describe two constructions using SoftAllDiffmin
SoftAllEqualmin
respectively.
G
G
Concluding remarks made Section 11.

2. Background
section present necessary background required reader introduce
notation use throughout paper.
2.1 Constraint Satisfaction
constraint satisfaction problem (CSP) triplet P = (X , D, C) X set
variables, mapping variables finite sets values C set constraints
specify allowed combinations values subsets variables. Without loss generality,
assume D(X) Z X X , denote min(X) max(X) minimum
maximum values D(X), respectively. assignment set variables X set
pairs |X | = |S| X X , exists (X, v) v D(X).
constraint C C arc consistent (ac) iff, variable scope C assigned
value, exists assignment variables C C satisfied.
satisfying assignment called domain support value. Similarly, call
99

fiHebrard, Marx, OSullivan & Razgon

range support assignment satisfying C, values, instead taken
domain variable (v D(X)), integer minimum
maximum domain following natural order Z (v [min(X), . . . , max(X)]) .
constraint C C range consistent (rc) iff every value every variable scope C
range support. constraint C C bounds consistent (bc) iff every variable X
scope C, min(X) max(X) range support. Given CSP P = (X , D, C),
shall use following notation throughout paper: n shall denote number
variables,
P i.e., n = |X |; shall denote number distinct unary
assignments, i.e.,
= XX |D(X)|; shall denote total set values, i.e., = XX D(X); finally,
shall denote total number distinct values, i.e., = ||.
2.2 Soft Global Constraints
Adding cost variable constraint represent degree violation common practice constraint programming. model introduced Petit, Regin,
Bessiere (2000). offers advantage unifying hard soft constraints since arc consistency, along types consistencies, applied constraints
extra effort. consequence, classical constraint solvers model over-constrained
problems way without modification. approach applied number
constraints, instance van Hoeve, Pesant, Rousseau (2006). Several cost
metrics explored AllDifferent constraint, well several others
(e.g., Beldiceanu & Petit, 2004). important, one uses unifying model,
cost metric chosen evaluated polynomial time given complete assignment
variables constrained. case two metrics considered
paper constraints AllDifferent AllEqual.
variable-based cost counts many variables need change order obtain
valid assignment hard constraint. viewed smallest Hamming distance
respect satisfying assignment. graph-based cost counts many times
component decomposition constraint violated. Typically components
correspond edges decomposition graph, e.g. AllDifferent constraint,
decomposition graph clique edge violated variables connected
edge share value. following example, still AllDifferent
constraint, shows two solutions involving four variables X1 , . . . , X4 domain {a, b}:
S1 = {(X1 , a), (X2 , b), (X3 , a), (X4 , b)}.
S2 = {(X1 , a), (X2 , b), (X3 , b), (X4 , b)}.
solutions, least two variables must change (e.g., X3 X4 ) obtain valid
solution. Therefore, variable-based cost 2 S1 S2 . However, S1 two
edges violated, (X1 , X3 ) (X2 , X4 ), whilst S2 , three edges violated, (X2 , X3 ),
(X2 , X4 ) (X3 , X4 ). Thus, graph-based cost S1 2 whereas 3 S2 .
2.3 Parameterised Complexity
shall use notion parameterised complexity Section 9. refer reader
Niedermeiers (2006) book comprehensive introduction. Given problem A,
100

fiSoft Constraints Difference Equality

parameterised version obtained specifying parameter problem getting
additional input non-negative integer k restricts value parameter.
resulting parameterised problem hA, ki fixed-parameter tractable (FPT) respect
k solved time f (k) nO(1) , f (k) function depending k.
size problem significantly larger parameter k, fixed-parameter
algorithm essentially polynomial behaviour. instance f (k) = 2k then, long
k bounded log n, problem solved polynomial time.

3. Taxonomy
section introduce taxonomy soft constraints based AllDifferent
AllEqual. consider eight algorithmic problems related constraints difference equality defined combining two constraints, two costs (graph-based
variable-based), two objectives (minimisation maximisation). fact,
graph-based costs AllDifferent AllEqual dual, six different problems
defined. Observe consider costs defined inequalities, rather
equalities. several reasons so. First, reasoning lower bound
upper bound cost variable yield two extremely different problems, hence
different algorithmic solutions. instance, shall see cases problem
tractable one direction, NP-hard direction. reasoning cost
equality, one often separate inference procedures relative lower bound, upper bound, intermediate values. Reasoning lower upper bounds sufficient
model equality although might hinder domain filtering intermediate values
cost forbidden. thus cover equalities restricted way, albeit arguably
reasonable practice. Indeed, dealing costs objectives, reasoning
inequalities bounds useful practice imposing (dis)equalities.
close last remaining cases: complexity achieving ac bc SoftAllEqualmin
V
Section 4, achieving ac SoftAllEqualmin

Section
5



achievG
ing bc SoftAllEqualmin
Section 6. Based results, Figure 1
G
completed (fourth fifth columns).
next six paragraphs correspond six columns Figure 1, is, twelve
elements taxonomy. them, briefly outline current state art,
using following assignment recurring example illustrate various costs:
S3 = {(X1 , a), (X2 , a), (X3 , a), (X4 , a), (X5 , b), (X6 , b), (X7 , c)}.
3.1 SoftAllDiff: Variable-based cost, Minimisation
Definition 1 (SoftAllDiffmin
V )
SoftAllDiffmin
V ({X1 , . . . , Xn }, N ) N n |{v | Xi = v}|.
cost minimise number variables need changed order
obtain solution satisfying AllDifferent constraint. instance, cost S3
4 since three four variables assigned well one variables assigned
b must change. objective function first studied Petit et al. (2001),

algorithm achieving ac O(n m) introduced. best knowledge,
101

fiHebrard, Marx, OSullivan & Razgon

AllEqual

AllDifferent
gra
p



min

x



ax

ax



x





le

min





var
iab

ph
gra

h

va



ble
ria

E



ft




fV






ax







fV


V
al
qu







V
al
qu
E


ft



G
al
qu ax
E
f G

ft llD

ft
ax


G
al
qu
E
f G

ft llD

ft

ax


ft



ft




O(n m) NP-hard O(nm) NP-hard O(nm) O(n m)
[1]
[2]
[4]
[5]
[6]
[8]

O(n m) O(n log n) O(nm) O(min( , n )nm)O(n log n)O(n log n)
2

[1]

[3]

[4]

2

[6]

[7]

[8]

Figure 1: Complexity optimising difference equality first row: ac, second row: bc.
Parameter n denotes number variables, sum domain sizes
number distinct values. References: [1] (Petit et al., 2001), [2] (Bessiere
et al., 2006), [3] (Beldiceanu, 2001), [4] (van Hoeve, 2004), [5] (Hebrard et al.,
2008), [6] (Hebrard et al., 2009), [7] (present paper), [8] (Quimper et al., 2004).

algorithm better time complexity special case bounds consistency
proposed constraint. Notice however Mehlhorn Thiels (2000) algorithm
achieves bc AllDifferent constraint O(n log n) time complexity.
question whether algorithm could adapted achieve bc SoftAllDiffmin
V
remains open.
3.2 SoftAllDiff: Variable-based cost, Maximisation
Definition 2 (SoftAllDiffmax
)
V
SoftAllDiffmax
({X1 , . . . , Xn }, N ) N n |{v | Xi = v}|.
V
cost maximised. words, want minimise number
distinct values assigned given set variables, since complement number
n exactly number variables modify order obtain solution satisfying
AllDifferent constraint. instance, cost S3 4 number distinct
values 7 4 = 3. constraint studied name AtMostNValue.
algorithm O(n log n) achieve bc proposed Beldiceanu (2001), proof
achieving ac NP-hard given Bessiere et al. (2006).

102

fiSoft Constraints Difference Equality

3.3 SoftAllDiff: Graph-based cost, Minimisation & SoftAllEqual:
Graph-based cost, Maximisation
Definition 3 (SoftAllDiffmin
SoftAllEqualmax
G
G )
SoftAllDiffmin
G ({X1 , . . . , Xn }, N ) N |{{i, j} | Xi = Xj & < j}|.
cost minimise number violated constraints decomposing
AllDifferent clique binary NotEqual constraints. instance, cost
S3 7 since four variables share value (six violations) two share value
b (one violation). Clearly, equivalent maximising number violated binary
Equal constraints decomposition
global AllEqual. Indeed, two costs

complementary n2 (on S3 : 7 + 14 = 21). algorithm O(nm)
achieving ac constraint introduced van Hoeve (2004). Again,
knowledge algorithm improving complexity special case bc.
3.4 SoftAllEqual: Graph-based cost, Minimisation & SoftAllDiff:
Graph-based cost Maximisation
SoftAllDiffmax
Definition 4 (SoftAllEqualmin
G )
G
SoftAllEqualmin
G ({X1 , . . . , Xn }, N ) N |{{i, j} | Xi 6= Xj & < j}|.
consider two complementary costs, however aim optimising
opposite way. Section 5 show achieving ac constraint NP-hard and,
Section 6 show that, domains contiguous intervals, computing optimal
cost done O(min(n2 , n3 )). consequence, bc achieved polynomial
time.
3.5 SoftAllEqual: Variable-based cost, Minimisation
Definition 5 (SoftAllEqualmin
V )
SoftAllEqualmin
V ({X1 , . . . , Xn }, N ) N n max(|{i | Xi = v}|).
v

cost minimise number variables need changed order
obtain solution satisfying AllEqual constraint. instance, cost S3 3 since
four variables already share value. equivalent maximising number
variables sharing given value. Therefore bound computed trivially counting
occurrences every value domains. However, pruning domains according
bound without degrading time complexity trivial. Section 4,
introduce two filtering algorithms, achieving ac rc complexity
counting values.
3.6 SoftAllEqual: Variable-based cost, Maximisation
Definition 6 (SoftAllEqualmax
)
V
({X1 , . . . , Xn }, N ) N n max(|{i | Xi = v}|).
SoftAllEqualmax
V
v

103

fiHebrard, Marx, OSullivan & Razgon

cost maximised. words want minimise
maximum cardinality value. instance, cost S3 3, is, complement
n maximum cardinality value (3 = 7 4). exactly equivalent
applying Global Cardinality constraint (considering upper bounds
cardinalities). Two algorithms, achieving ac bc constraint running

O( nm) O(n log n) respectively, introduced Quimper et al. (2004).

4. Complexity Arc Bounds Consistency SoftAllEqualmin
V
show achieve ac, rc bc SoftAllEqualmin
constraints (see
V
Definition 5). constraint satisfied n minus cardinality
set variables assigned single value less equal value cost
variable N . words, satisfied least k variables sharing value,
k = n max(N ). Therefore, simplicity sake, shall consider following
equivalent formulation, N lower bound complement n cost
(N 0 = n N ):
N 0 max(|{i | Xi = v}|).
v

shall see filter domain N 0 Xi need compute two properties:
1. upper bound k number occurrences amongst values.
2. set values actually appear k times.
Computing set values appear largest possible number variable domains
performed trivially O(m), counting number occurrences every value,
i.e., number variables whose domain contains v.
However, domains discrete intervals defined lower upper bounds,
done even efficiently. Given two integers b, b, say set
integers x, x b, interval denote byS[a, b]. rest section
shall assume overall set values values = XX D(X) interval [1, ].
Definition 7 (Occurrence function derivative) Given constraint network P =
(X , D, C), occurrence function occ mapping values N defined
follows:
occ(v) = |{X | X X & v doms(X)}|.
derivative occ, occ , maps value v difference value
occ(v 1) occ(v):
occ (0) = 0,
occ (v) = occ(v) occ(v 1).
give example occurrence function set variables interval domains
Figure 2.
Algorithm 1 computes occ1 , is, inverse occurrence function, maps
every element interval [1, n] set values appearing many times. runs
104

fiX6

5

X5

4

variables

variables

Soft Constraints Difference Equality

X4
X3

3
2

X2

1

X1

0
1

15

40

60

70

90

100

1

15

values

40

60

70

90

100

values

(a) Intervals

(b) Occurrence function

Figure 2: set intervals (a) corresponding occurrence function (b).
Algorithm 1: Computing inverse occurrence function.
Data: set variables: X
Result: occ1 : [1, n] 7 2
occ (v) ;
1 foreach X X
occ (min(X)) occ (min(X)) + 1;
occ (max(X) + 1) occ (max(X) + 1) 1;
2 x [1, n], occ1 (x) ;

x 0;
pop first element (v, a) occ ;
repeat
pop first element (w, b) occ ;
x x + occ (a);
occ1 (x) occ1 (x) [a, b 1];
b;
occ = ;

O(n log n) worst-case time complexity assume easy extract upper
bound (k N 0 ) set values appear k times occ1 .
idea behind algorithm, shall reuse throughout paper,
domains given discrete intervals one compute non-null values derivative
occ occurrence function occ O(n log n) time. procedure closely related
concept sweep algorithms (Beldiceanu & Carlsson, 2001) used, instance, implement
filtering algorithms Cumulative constraint. Instead scanning entire horizon,
one jump event next, assuming nothing changes two events.
case Cumulative constraint, events correspond start end points
domains. fact, possible compute lower bound,
complexity, using Petit, Regin, Bessieres (2002) Range-based Max-CSP Algorithm
(RMA)2 reformulation Max-CSP. Given set variables XS, add extra
variable Z whose domain union domains X : D(Z) = = XX D(X).
2. thank anonymous reviewer made observation.

105

fiHebrard, Marx, OSullivan & Razgon

link variables X binary equality constraints:
X X , Z = X.
one-to-one mapping solutions Max-CSP satisfying assignments SoftAllEqualmin
constraint (X , N ), value N corresponds
V
number violated constraints Max-CSP. lower bound number
violations computed RMA lower bound k N computed Algorithm 1 are,
therefore, same. Moreover procedures essentially equivalent, i.e., modulo
modelling step. Algorithm 1 seen particular case RMA: ordered set
intervals computed, subsequently associated violation cost. However,
use formalism, since notion occurrence function derivative important
used throughout paper.
first define simple data structure shall use compute represent
function occ . specific data structure required since indexing image occ (v)
value v would add factor (space therefore time) complexity. non-zero
values occ stored list pairs whose first element value v [1, . . . , ]
second element stands occ (v). list maintained increasing order pairs
first element. Given ordered list occ = [(v1 , o1 ), . . . , (vk , ok )], assignment operation
occ (vi ) oi therefore done O(log |occ |) steps follows:
1. rank r pair (vj , oj ) vj minimum vj vi computed
dichotomic search.
2. vi = vj , pair (vj , oj ) removed.
3. pair (vi , oi ) inserted rank r.
Moreover, one access element minimum (resp. maximum) first element
constant time since first (resp. last) list. Finally, value occ (vi ) oi
exists pair (vj , oj ) list, 0 otherwise. Computing value also
done logarithmic time.
derivative occ (v) computed Loop 1 Algorithm 1 using assignment
operator defined above. Observe D(X) = [a, b], X contributes two
values occ : increases occ (a) 1 decreases occ (b + 1) 1. every value w
X min(X) = w max(X) + 1 = w, occ (w) null.
words, define occ (v) value v, follows:
occ (v) = (|{i | min(Xi ) = v}| |{i | max(Xi ) = v 1}|).
Therefore, going every variable X X , compute non-null values
occ time O(n log n) using simple list structure described above.
Then, starting Line 2, compute occ1 going non-zero values v
derivative, i.e. occ (v) 6= 0, increasing order v. Recall use
ordered list, trivially done linear time. definition, occurrence function
constant interval defined two successive values. Since number non-zero
values occ bounded O(n), overall worst-case time complexity O(n log n).
use Figure 3 (a,c & d) illustrate execution Algorithm 1. First, six variables
106

fiX6

X6

X5

X5

variables

variables

Soft Constraints Difference Equality

X4
X3

X4
X3

X2

X2

X1

X1
1

15

40

60

70

90

100

1

values

=
=
=
=
=
=
=
=

+2
+2
2
+1
+1
1
1
2

40

60

70

90

100

values

(a) Intervals

occ (1)
occ (15)
occ (41)
occ (60)
occ (70)
occ (71)
occ (91)
occ (101)

15

(b) Pruning

occ1 (2)
occ1 (3)
occ1 (4)

=
=
=

{[1, 14] [41, 59] [91, 100]}
{[60, 69] [71, 90]}
{[15, 40] [70, 70]}

(d) Inverse occurrence function.

(c) Derivative occurrence function.

Figure 3: Execution Algorithm 1: set intervals (a). set intervals
inconsistent sub-intervals lower bound number equalities 4 (N
4) represented dashed lines (b). (c) (d) represent derivative,
inverse occurrence function initial set intervals, respectively.

domains represented Figure 3(a). Then, Figures 3(c) 3(d) show
derivative inverse, respectively, occurrence function.
Alternatively, < n log n, possible compute occ1 O(n + ) replacing
data structure used store occ simple array, indexed values [1, ]. Accessing
updating value occ thus done constant time.
show prune variables X respect bound without
degrading time complexity. According method used can, therefore, achieve
ac rc worst-case time complexity O(m) O(min(n + , n log n), respectively.
Theorem 1 Enforcing ac (resp. rc) SoftAllEqualmin
achieved O(m)
V
steps (resp. O(min(n + , n log n)).
Proof. suppose, without loss generality, current lower bound N 0 k.
first compute inverse occurrence function either counting values, considering
interval domains using Algorithm 1. define set values highest
number occurrences. Let number occurrences k , corresponding set
values V (i.e. occ1 (k ) = V ). three cases consider:
107

fiHebrard, Marx, OSullivan & Razgon

1. First, every value appears strictly fewer k domains (k < k)
constraint violated.
2. Second, least one value v appears domains least k + 1 variables
(k > k), build support every value w D(X). Let v V ,
assign variables X \ X v possible. resulting assignment
least k occurrences v, hence consistent. Consequently, since k > k, every
value consistent.
3. Otherwise, neither two cases hold, know value appears
k domains, least one appears k times. Recall V denotes
set values. case, pair (X, v) inconsistent
v 6 V & V D(X).
first suppose condition hold show build
support. v V clearly assign every possible variable v achieve
cost k. V 6 D(X), consider w w V w 6 D(X).
assigning every variable w possible achieve cost k matter
value assigned X.
suppose v 6 V & V D(X) holds show (X, v)
ac support. Indeed, X assigned v domains value
appears k domains more, since every value V one fewer occurrence,
hence back Case 1.
Computing set V values satisfying condition done easily
inverse occurrence function computed. one hand, function occ1
computed counting every value every domain, supports used
proofs domain supports, hence ac achieved. hand, domains
approximated bounds Algorithm 1 used instead, supports range
supports, hence rc achieved. Case 3, domain pruned set V
values whose number occurrences k, illustrated Figure 3 (b).
2
achieved O(min(n+, n log n)
Corollary 1 Enforcing bc SoftAllEqualmin
V
steps.
Proof. direct implication Theorem 1.

2

proof Theorem 1 yields domain filtering procedure. Algorithm 2 achieves either
ac rc depending version Algorithm 1 used Line 1 compute inverse
occurrence function. later function occ1 used Line 2, 3 4 to, respectively,
catch global inconsistency, prune upper bound N 0 prune domains
variables X .
Figure 3(b) illustrates pruning one achieve X provided lower
bound N 0 equal 4. Dashed lines represent inconsistent intervals. set V
values used Line 4 Algorithm 2 occ1 (4) = {[15, 40] [70, 70]}.

108

fiSoft Constraints Difference Equality

0
Algorithm 2: Propagation SoftAllEqualmin
V ({X1 , . . . , Xn }, N ).
1 occ1 Algorithm 1;

ub n;
occ1 (ub) =
ub ub 1;
2 min(N 0 ) > ub fail;

else
max(N 0 ) ub;
min(N 0 ) = max(N 0 )
V occ1 (min(N 0 ));
4
foreach X X V D(X) D(X) V ;

3

5. Complexity Arc Consistency SoftAllEqualmin
G
show achieving ac SoftAllEqualmin
NP-hard. order achieve
G
ac need compute arc consistent lower bound cost variable N constrained
follows:
N |{{i, j} | Xi 6= Xj & < j}|.
words, want find assignment variables X minimising number
pairwise disequalities, maximising number pairwise equalities. consider
corresponding decision problem (SoftAllEqualmin
G -decision), show
NP-hard reduction 3dMatching (Garey & Johnson, 1979).
Definition 8 (SoftAllEqualmin
G -decision)
Data: integer N , set X variables.
Question: exist mapping : X 7 X X , s[X] D(X)
|{{i, j} | s[Xi ] = s[Xj ] & 6= j}| N ?
Definition 9 (3dMatching)
Data: integer K, three disjoint sets X, Y, Z, X Z.
Question: exist |M | K m1 , m2 M, {1, 2, 3}, m1 [i] 6=
m2 [i]?
Theorem 2 (The Complexity SoftAllEqualmin
G ) Finding satisfying assignment
min
SoftAllEqualG constraint NP-complete even value appears
three domains.
Proof. problem SoftAllEqualmin
G -decision clearly NP: checking number
equalities assignment done O(n2 ) time.
use reduction 3dMatching show completeness. Let P = (X, Y, Z, T, K)
instance 3dMatching, where: K integer; X, Y, Z three disjoint sets
X Z = {x1 , . . . , xn }; = {t1 , . . . , tm } set triplets X Z.
build instance SoftAllEqualmin
follows:
G
1. Let n = |X| + |Y | + |Z|, build n variables {X1 , . . . , Xn }.
2. tl = hxi , xj , xk , l D(Xi ), l D(Xj ) l D(Xk ).
109

fiHebrard, Marx, OSullivan & Razgon

3. pair (i, j) 1 < j n, put value (|T | + (i 1) n + j)
D(Xi ) D(Xj ).
show exists matching P size K exists solution
b 3K+n
2 c equalities. refer matching P solution
matching solution throughout proof, respectively.
: show exists matching cardinality K exists solution
least b 3K+n
2 c equalities. Let matching cardinality K. build solution
follows. tl = hxi , xj , xk assign Xi , Xj Xk l (item 2 above).
Observe remain exactly n 3K unassigned variables process. pick
arbitrary pair unassigned variables assign common value (item 3
above), one variable left (if one variable left assign arbitrary
value). Therefore, solution obtained way exactly b 3K+n
2 c equalities, 3K
variables corresponding matching b n3K
c


remaining
variables.
2
: show cardinality maximal matching K, solution
b 3K+n
2 c equalities. Let solution. Furthermore, let L number
values appearing three times S. Observe set values corresponds
matching. Indeed, value l appears three domains D(Xi ), D(Xj ) D(Xk )
exists triplet tl = hxi , xj , xk (item 2 above). Since variable
assigned single value, values appearing three times solution form matching.
Moreover, since value appears three domains, values appear
twice. Hence number equalities less equal b 3L+n
2 c, L
size matching. follows matching cardinality greater
K, solution b 3K+n
2
2 c equalities.
Cohen, Cooper, Jeavons, Krokhin (2004) showed language soft binary
equality constraints NP-complete, three distinct values. one hand,
Theorem 2 applies specific class problems constraint network formed
soft binary constraints clique. hand, proof requires unbounded number values, two results therefore incomparable. However, shall
see Section 9 problem fixed parameter tractable respect number
values, hence polynomial bounded.

6. Complexity Bounds Consistency SoftAllEqualmin
G
section introduce efficient algorithm that, assuming domains discrete
intervals, computes maximum possible pairs equal values assignment.
therefore need solve optimisation version problem defined previous
section (Definition 8):
Definition 10 (SoftAllEqualmin
G -optimisation)
Data: set X variables.
Question: maximum integer K exists mapping : X 7
satisfying X X , s[X] D(X) |{{i, j} | s[Xi ] = s[Xj ] & 6= j}| = K?
algorithm introduce allows us close last remaining open complexity question
Figure 1: bc SoftAllEqualmin
constraint. improve reducing
G
time complexity thanks preprocessing step.
110

fiSoft Constraints Difference Equality

use terminology Section 4, refer set integers x
x b interval [a, b]. Let X set variables considered CSP
assume domains variables X sub-intervals [1, ]. denote
ME(X ) set assignments P variables X number pairs
equal values P maximum possible. subset X containing variables
whose domains subsets [a, b] denoted Xa,b . subset Xa,b including
variables containing given value c domains denoted Xa,b,c . Finally
number pairs equal values element ME(Xa,b ) denoted Ca,b (X )
Ca,b considered set variables clear context. notational convenience,
b < a, set Xa,b = Ca,b = 0. value C1, (X ) number equal pairs
values element ME(X ).
Theorem 3 C1, (X ) computed O((n + )2 ) steps.
Proof. problem solved dynamic programming approach: every a, b
1 b , compute Ca,b . main observation makes possible use
dynamic programming following: every P ME(Xa,b ) value c (a c b)
every variable X Xa,b,c assigned value c. see this, let value c value
assigned P maximum number variables. Suppose variable
X c D(X) assigned P different value, say c0 . Suppose c
c0 appear x variables, respectively. changing value X c0 c,
increase number equalities x (y 1) 1 (since x y), contradicting
optimality P .
Notice Xa,b \ Xa,b,c disjoint union Xa,c1 Xc+1,b (if c 1 <
c + 1 > b, corresponding set empty). two sets independent
sense value appear variables sets. Thus
assumed P ME(Xa,b ) restricted Xa,c1 Xc+1,b elements ME(Xa,c1 )
ME(Xc+1,b ), respectively. Taking consideration possible values c, get



|Xa,b,c |
Ca,b = max
+ Ca,c1 + Cc+1,b .
(1)
c,acb
2
first step Algorithm 3, compute |Xa,b,c | values a, b, c.
triple a, b, c, easy compute |Xa,b,c | time O(n), hence values
computed time O(n3 ). However, running time reduced O((n + )2 )
using idea Algorithm 1.
pair a, b, compute number
occurrences value c first computing derivative a,b . precisely, define
a,b (c) = |Xa,b,c | |Xa,b,c1 | compute a,b (c) every < c b (Algorithm 3, Line 1-2).
Thus going variables, compute a,b (c) values fixed a, b
c b time O(n) also compute |Xa,b,a | time
bound. possible compute values |Xa,b,c |, < c b time O() using
equality |Xa,b,c | = |Xa,b,c1 | + a,b (c) iteratively (Algorithm 3, Line 3).
second step algorithm, compute values Ca,b . compute

|
values increasing order b a. = b, Ca,b = |Xa,a,a
. Otherwise, values Ca,c1
2
Cc+1,b already available every c b, hence Ca,b determined time
O() using Eq. (1) (Algorithm 3, Line 4). Thus values Ca,b computed time
111

fiHebrard, Marx, OSullivan & Razgon

Algorithm 3: Computing maximum number equalities.
Data: set variables: X
Result: C1, (X )
1 a, b, c , a,b (c) |Xa,b,c | Ca,b 0;
foreach k [0, 1]
foreach [1, k]
b + k;
foreach X Xa,b
1
a,b (min(X)) a,b (min(X)) + 1;
2
a,b (max(X) + 1) a,b (max(X) + 1) 1;
3
4

foreach c [a, b]
|Xa,b,c | |Xa,b,c1 | + a,b (c);

|
+ Ca,c1 + Cc+1,b ));
Ca,b max(Ca,b , ( |Xa,b,c
2
return C1, ;

O(3 ), including C1, , value optimum solution problem. Using
standard techniques (storing Ca,b value c minimises (1)), third step
algorithm actually produce variable assignment obtains maximum value. 2
Ca,b
b=1
b=2
b=3
b=4

a=1
1
X1,2,1 + C2,2 = 3
X1,3,1 + C2,3 = 6
X1,4,1 + C2,4 = 16

a=2

a=3

a=4

0
0
X2,4,4 + C2,3 = 6

0
X3,4,4 + C3,3 = 3

1

X10
X9
X8

variables

X7
X6
X5
X4
X3
X2
X1
1

2

3

4

values

Figure 4: set intervals, corresponding dynamic programming Table (Ca,b ).
Algorithm 3 computes largest number equalities one achieve assigning
set variables interval domains. therefore used find optimal solution
either SoftAllDiffmax
SoftAllEqualmin
G
G . Notice latter one needs
take complement n2 order get value violation cost. Clearly,
follows achieving range bounds consistency two constraints done
112

fiSoft Constraints Difference Equality

polynomial time, since Algorithm 3 used oracle testing existence
range support. give example execution Algorithm 3 Figure 4. set
ten variables, X1 X10 represented. give table Ca,b pairs
a, b [1, ].
complexity reduced n. again, use occurrence
function, albeit slightly different way. intuition values intervals
values dominated other. occurrence function monotonically increasing,
means moving toward dominating values (they taken larger
set variables), conversely, monotonic decrease denotes dominated values. Notice
since considering discrete values, variations may apparent
occurrence function. instance, consider two variables X respective domains
[a, b] [b + 1, c] b c. occurrence function two variables
constant [a, c]. However, purpose, need distinguish true
monotonicity induced discrete nature problem. therefore consider
rational values defining occurrence function. example above,
introducing extra point b + 12 occurrence function, capture fact
fact monotonic [a, c].
Let X set variables interval domains [1, ]. Consider occurrence
function occ : Q 7 [0..n], Q Q set values form a/2 N,
min(Q) = 1 max(Q) = . Intuitively, value occ(a) number
variables whose domain interval encloses value a, formally:
Q, occ(a) = |{X | X X , min(X) max(X)}|.
function, along corresponding set intervals, depicted Figure 5.
crest function occ interval [a, b] Q c [a, b], occ
monotonically increasing [a, c] monotonically decreasing [c, b]. instance,
set intervals represented Figure 5, [1, 15] crest since monotonically increasing
[1, 12] monotonically decreasing [12, 15].
Let partition [1, ] set intervals every element
crest. instance, = {[1, 15], [16, 20], [21, 29], [30, 42]} partition set
intervals shown Figure 5. shall map element integer corresponding
rank natural order. denote RI (X ) reduction X partition I.
reduction many variables X (equation 2 below) domains replaced
set intervals overlap corresponding variable X (equation 3
below). Observe domains remain intervals reduction.
0 }.
{X10 , . . . , X|X
|

RI (X ) =
Xi0

RI (X ),

D(Xi0 )

= {I | & D(Xi ) 6= }.

(2)
(3)

instance, set intervals depicted Figure 5 reduced set shown
Figure 4, element mapped integer [1, 4].
Theorem 4 partition [1, ] every element crest occ,
ME(X ) = ME(RI (X )).
113

fiHebrard, Marx, OSullivan & Razgon

X10 [26,42]
X9 [10,26]
X8 [7,15]
X7 [18,32]
X6 [16,40]
X5 [9,19]
X4 [32,38]
X3 [1,13]
X2 [21,26]
X1 [30,40]
[1

15] [16

20] [21
values

29] [30

42]

Figure 5: intervals corresponding occ function.
Proof. First, show optimal solution ME(X ), produce solution
s0 ME(RI (X )) least many equalities s. Indeed, value a, consider
every variable X assigned value, is, s[X] = a. Let crest
containing a, definition D(X 0 ). Therefore assign variables
value I.
show opposite, is, given solution reduced problem, one build
solution original problem least many equalities. key observation
that, given crest [a, b], intervals overlapping [a, b] common value.
Indeed, suppose case, is, exists [c1 , d1 ] [c2 , d2 ]
overlapping [a, b] d1 < c2 . occ(d1 ) > occ(d1 + 21 ) similarly
occ(c2 12 ) < occ(c2 ). However, since d1 < c2 b, [a, b] would satisfy conditions
crest, hence contradiction. Therefore, given crest I, every variable
X 0 s0 [X 0 ] = I, assign X common value, hence obtaining many
equalities.
2
show transformation achieved O(n log n) steps.
use derivative occurrence function (occ ), however, defined Q rather [1, ]:
1
occ (v) (|{i | min(Xi ) = v}| |{i | max(Xi ) = v }|).
2
Moreover, compute O(n log n) steps shown Algorithm 4. first compute
non-null values occ looping variable X X (Line 1). use
114

fiSoft Constraints Difference Equality

data structure Algorithm 1, hence complexity step O(n log n). Next,
create partition crests going derivative identifying
inflection points. variable polarity (Line 3) used keep track evolution
function occ. decreasing phases denoted polarity = neg whilst increasing
phases correspond polarity = pos. know value v end crest interval
variable polarity switches neg pos. Clearly, number elements occ
bounded 2n. Recall list data structure sorted. Therefore, going
values occ (v) increasing order v done linear time, hence overall
O(n log n) worst-case time complexity.
Algorithm 4: Computing partition crests.
Data: set variables: X
Result:
occ ;
1 foreach X X
occ (min(X)) occ (min(X)) + 1;
occ (max(X) + 12 ) occ (max(X) + 12 ) 1;
;
min max 1;
2 occ 6=
3
polarity pos;
k = 1;
repeat
pick remove first element (a, k) occ ;
max round(a) 1;
polarity = pos & k < 0 polarity neg;
polarity = pos k < 0 ;
add [min, max] I;
min max + 1;
return

Therefore, replace every crest single value preprocessing stage
run Algorithm 3. Moreover, observe number crests bounded n, since
needs least one interval start one interval end. Thus obtain
following theorem, n stands number variables, number distinct
values, sum domain sizes.
Theorem 5 Enforcing rc SoftAllEqualmin
achieved O(min(2 , n2 )nm)
G
steps.
Proof. n one achieve range consistency iteratively calling Algorithm 3
assigning O(m) unit assignments ((X, v) X X , v D(X)).
resulting complexity O(n2 )m (see Theorem 3, term 3 absorbed n2 due
n).
Otherwise, > n, procedure used, applying reformulation
described Algorithm 4. complexity Algorithm 4 O(n log n), since
reformulation = O(n), resulting complexity O(n3 m).
2

115

fiHebrard, Marx, OSullivan & Razgon

7. Approximation Algorithm
completed taxonomy soft global constraints introduced Section 3. However, section rest paper refine analysis problem
maximising number pairs variables sharing value, is, SoftAllEqualmin
G optimisation (Definition 10).
Given solution set variable X , denote obj(s) number equalities
X .
obj(s) = |{{i, j} | s[Xi ] = s[X[j] & 6= j}|.
Furthermore, shall denote obj(s ) optimal solution number
equalities solution, respectively. first study natural greedy algorithm approximating maximum number equalities set variables (Algorithm 5).
algorithm picks value occurs largest number domains, assigns
many variables possible value (this achieved O(m)). recursively
repeats process resulting sub-problem variables assigned (at
O(n) times). show that, surprisingly, straightforward algorithm approximates
maximum number equalities factor 12 worst case. Moreover,
implemented run O(m) amortised time. use following data structures3 :
var : 7 2X maps every value v set variables whose domains contain v.
occ : 7 N maps every value v number variables whose domains contain v.
val : N 7 2 maps every integer [0..n] set values appearing exactly
domains.
data structures initialised Lines 1, 2 3 Algorithm 5, respectively. Then,
Algorithm 6 recursively chooses value largest number occurrences (Line 2),
makes corresponding assignments (Line 7) updating current state data
structures (Loop 3).
Algorithm 5: Computing lower bound maximum number equalities.
Data: set variables: X
Result: integer E obj(s )/2 E obj(s )

1 var(v) , v XX D(X);
foreach X X
foreach v D(X)
add X var(v);

2 occ(v) |var(v)|, v XX D(X);
3 val(k) , k [0..n];

foreach v XX D(X)
add v val(|var(v)|);
return AssignAndRecurse(var, val, occ, n);

Theorem 6 (Algorithm Correctness) Algorithm 5 approximates optimal satisfying
assignment SoftAllEqualG constraint within factor 21 - provided
data-structure representing domains respects assumptions - runs O(m).
3. describe structures lower level subsequent proof complexity.

116

fiSoft Constraints Difference Equality

Algorithm 6: procedure AssignAndRecurse Algorithm 5.

1

2
3
4
5
6
7

Data: mapping: var : 7 2X , mapping: val : N 7 2 , mapping: occ : 7 [0..n],
integer: k
val(k) = k k 1;
k 1
return 0;
else
pick remove v val(k);
foreach X var(v) v D(X)
foreach w 6= v D(X)
remove w val(occ(w));
occ(w) occ(w) 1;
add w val(occ(w));
assign X v;
return

k(k1)
+AssignAndRecurse(var, val, k);
2

Proof. first prove correctness approximation ratio, soundness
algorithm complexity algorithm.
Approximation Factor. proceed using induction number distinct values
current subproblem involving unassigned variables. Let solution computed
Algorithm 5 let optimal solution. denote P () proposition
values union domains X , obj(s) obj(s )/2. P (1)
implies every unassigned variable assigned unique value v. Algorithm 6
therefore chooses value assigns variables it. case obj(s) = obj(s ).
suppose P () holds
show P ( + 1) also holds. Let set
variables X problem | XX D(X)| = + 1 let v first value
chosen Algorithm 6. partition variables two subset Xv Xv depending
presence value v domains.
Xv = {X X | v D(X)} set variables whose domains contain v.
Xv = X \ Xv complementary set variables contain value v.
Using notations, partition equalities two subsets order count
them. first subset equalities involving least one variable Xv ,
second subset restricted variables Xv .
first compute bound number equalities one achieve X . Let
k = |Xv |, let sv optimal solution Xv let obj(sv ) number equalities
sv . variable X Xv , given value w D(X), k
variables X containing w. Indeed, v chosen maximising criterion belongs
domains exactly k variables. Therefore, k(k 1) equalities
involve least variable Xv , since one involved k 1 equalities,
k them. Consequently, set variables X , one achieve
k(k 1) + obj(sv ) equalities.
hand, Algorithm 6 assigns every variable Xv v therefore produces
k(k 1)/2 equalities involving least one variable Xv . Moreover, observe since v
belong domain Xv , number distinct values Xv .
117

fiHebrard, Marx, OSullivan & Razgon

induction hypothesis P () therefore used, hence know number
equalities achieved Algorithm 5 subset Xv least obj(sv )/2. Consequently,
set variables X , Algorithm 5 achieves least k(k 1)/2 + obj(sv )/2 equalities.
Since lower bound number equalities achieved greedy algorithm
half upper bound computed above, conclude P ( + 1) holds,
P ( + 1) also holds.
Correctness. show mappings occ val correctly updated call
Algorithm 6. domain variable X changes assigned value v
Line 7. case, occurrence every value w D(X) w 6= v decreased
one assigning X v. Indeed, every value w, occ(w) decremented
w removed val(occ(w) + 1) added val(occ(w)).
Complexity. show Algorithm 5 runs O(m) steps following assumptions:
values consecutive taken set {1, . . . , }.
Assigning variable value done constant time.
Checking membership value variables domain done constant time.
Notice first assumption hold, one rename values. However,
would require O( log ) time complexity sort them, well O(n) create
new set domains.
every 0 k n, use doubly linked list represent val(k). Moreover use
single array index + 1 elements store current position every value v
list appears (observe value appears exactly one list). add value v
val(k) simply append tail list set index previous length.
remove value v val(k), delete element position index[v] val(k).
total space complexity data-structure therefore O(). value v, set
variables var(k) implemented simple list, hence O(m) space complexity.
mapping occ(v) represented array one element per value, hence O() space
complexity.
Initialising three mappings done linear time since addition requires
constant time. step therefore achieved O(m) steps. Line 1 Algorithm 6,
k decremented n times total, hence Line 2 executed n times
total.
Observe value chosen Line 2. Moreover, total space
complexity var O(m). Therefore, total number steps Loop 3 O(m).
Last, observe pair variable/value (X, w) explored
Lines 4, 5 6. Indeed, since X assigned v Line 7, never pass condition
Line 3 since subsequent chosen values equal v. overall time complexity
thus O(m).
2
Theorem 7 (Tightness Approximation Ratio) approximation factor
Algorithm 5 tight.
118

1
2

fiSoft Constraints Difference Equality

Proof. Let {X1 , . . . , X4 } set four variables domains follows:
X1 {a}; X2 {b}; X3 {a, c}; X4 {b, c}.
Every value appears exactly two domains, hence Algorithm 5 choose value.
suppose value c chosen first. point value contribute
equality, hence Algorithm 5 returns 1. However, possible achieve two equalities
following solution: X1 = a, X3 = a, X2 = b, X4 = b.
2

8. Tractable Class
section explore connection SoftAllEqualmin
constraint
G
vertex matching. showed earlier general case linked 3dMatching.
show particular case value appears two domains
solving SoftAllEqualG constraint equivalent vertex matching problem
general graphs, therefore solved polynomial time algorithm. shall
use tractable class show SoftAllEqualG NP-hard unbounded
number values appear two domains.
Definition 11 (The VertexMatching Problem)
Data: integer K, undirected graph G = (V, E).
Question: exist E |M | K e1 , e2 , e1 e2
share vertex.
Theorem 8 (Tractable Class SoftAllEqualmin
G ) triplets variables X, Y, Z
X D(X) D(Y ) D(Z) = finding optimal satisfying assignment
SoftAllEqualmin
P .
G
Proof. order solve problem, build graph GX = (V, E) vertex
xi variable Xi X , is, V = {xi | Xi X }. pair {i, j}
D(Xi ) D(Xj ) 6= , create undirected edge {i, j}; let E = {{i, j} | 6=
j & D(Xi ) D(Xj ) 6= }.
first show exists matching cardinality K, exists solution
least K equalities. Let matching cardinality K GX , edge
e = (i, j) assign Xi Xj value v D(Xi ) D(Xj ) (by construction,
know exists value). Observe variable considered twice since
would mean two edges matching common vertex. obtained solution
therefore least |M | equalities.
show exists solution K equalities, exists
matching cardinality K. Let solution, let = {{i, j} | S[Xi ] = S[Xj ]}.
Observe matching GX . Indeed, suppose two edges sharing vertex
(say {i, j}, {j, k}) . follows S[Xi ] = S[Xj ] = S[Xk ], however
contradiction hypothesis. therefore compute solution maximising
number equalities computing maximal matching GX .
2
tractable class generalised restricting number occurrences values
domains variables. notion heavy values key result.
119

fiHebrard, Marx, OSullivan & Razgon

Definition 12 (Heavy Value) heavy value value occurs twice
domains variables problem.
Theorem 9 (Tractable Class Heavy Values) domain D(Xi ) variable Xi contains one heavy value finding optimal satisfying assignment
SoftAllEqualmin
P .
G
Proof. Consider two stage algorithm. first stage, explore every heavy value
w assign w every variable whose domain contains it. Notice variable
assigned twice. second stage, CSP created domains unassigned
variables consists values two occurrences, solve CSP
transforming matching problem suggested proof Theorem 8.
show exists optimal solution variable assigned
heavy value assigned value. Let optimal solution w heavy
value set variables cardinality t. suppose z <
assigned w . Consider solution s0 obtained assigning variables
w: add exactly t(t 1)/2 z(z 1)/2 equalities. However, potentially remove
z equalities since values w appear twice. therefore
obj(s0 ) obj(s ) t2 3t z 2 + 3z, non-negative 3 z < t. iteratively
applying transformation, obtain optimal solution variable
assigned heavy value assigned value. first stage algorithm
thus correct. second stage correct Theorem 8.
2

9. Parameterised Complexity
advance analysis complexity SoftAllEqualmin
constraint
G
introducing fixed-parameter tractable (FPT) algorithm respect number
values. result important shows complexity propagating
constraint grows polynomially number variables. may therefore possible
achieve ac reasonable computational cost even large set variables,
provided total number distinct values relatively small.
first show SoftAllEqualmin
G -optimisation problem FPT respect
number values . use tractable class introduced previous section
generalise result, showing problem FPT respect number
heavy values occurring domains containing two heavy values. begin
definition.
Definition 13 (Solution Total Order) solution induced total order
values
s[X] = v w v, w 6 D(X).
prove following key lemma.
Lemma 1 exists total order set values, solution
induced optimal.
120

fiSoft Constraints Difference Equality

Proof. Let optimal solution, v value, occ(s , v) number
variables assigned v . Moreover, let occ total order values
ranked decreasing number occurrences (occ(s , v)) ties broken arbitrarily.
show occ induces .
Consider, without loss generality, pair values v, w v occ w.
definition occ(s , v) occ(s , w). suppose hypothesis falsified
show leads contradiction. Suppose exists variable X
{v, w} D(X) [X] = w (that is, occ induce ). objective value
solution s0 s0 [X] = v s0 [Y ] = [Y ] 6= x given by: obj(s0 ) =
obj(s ) + occ(s , v) (occ(s , w) 1). Therefore, obj(s0 ) > obj(s ). However, optimal,
hence contradiction.
2
interesting consequence Lemma 1 searching space total orders
values enough compute optimal solution. Moreover, fixed-parameter tractability
SoftAllEqualmin
constraint follows easily lemma.
G
Theorem 10 (FPT number values) Finding optimal satisfying assignment
SoftAllEqualmin
constraint fixed-parameter tractable respect , number
G
values domains constrained variables.
Proof. Explore possible ! permutations values. permutation create
solution induced permutation. Compute cost solution. Return
solution highest cost. According Lemma 1, solution optimal. Creating
induced solution done selecting domain first value order.
Clearly, done O(m). Computing cost given solution done
computing number occurrences occ(w) summing occ(w) (occ(w) 1)/2
values w. Clearly, done O(m) well. Hence theorem follows. 2
also derive following corollary Lemma 1:
Corollary 2 number optimal solutions CSP SoftAllEqualG
!.
Proof. According Lemma 1, optimal solution induced order values
given problem. Clearly order induces exactly one solution. Thus number
optimal solution exceed number total orders !.
2
Corollary 2 shows number optimal solutions considered problem
depend number variables explored considering
possible orders values. believe fact interesting practical point
view essence means even enumerating optimal solutions scalable
respect number variables. Moreover, show SoftAllEqualmin
G
fixed-parameter tractable respect number conflicting values, defined
follows.
Definition 14 (Conflicting Value) value w given CSP conflicting value
heavy value domain D(X) contains w another
heavy value.

121

fiHebrard, Marx, OSullivan & Razgon

Theorem 11 (FPT number conflicting values) Let k number conflicting values CSP comprising one SoftAllEqualG constraint. CSP

solved time O(k! n), hence SoftAllEqualmin
fixed-parameter tractable
G
respect k.
Proof. Consider permutations conflicting values. permutation
perform following two steps. first step variable X two
conflicting values, remove conflicting values except one first
order among conflicting values D(X) according given permutation.
second stage obtain problem domain contains exactly one heavy value.
Solve problem polynomially algorithm provided proof Theorem 9.
Let solution obtained algorithm. show solution optimal.
Let p permutation values considered CSP solution
induced p highest possible cost. Lemma 1, optimal solution. Let p1
permutation conflicting values induced p let s1 solution
obtained algorithm respect p1 . definition s, obj(s) obj(s1 ).
show obj(s1 ) obj(s ) optimality immediately follows.
Observe X [X] = w w removed D(X)
first stage algorithm permutation p1 considered. Indeed, w
removed D(X) preceded p1 value v D(X). follows w
also preceded p v consequently (X) 6= w. Thus solution CSP
obtained result first stage. However s1 optimal solution CSP
Theorem 9 and, consequently, obj(s1 ) obj(s ) required.
Regarding runtime, observe execution algorithm consists k! running
algorithm finding largest bipartite matching given graph. graph
n vertices (corresponding variables). Moreover, edge associated value
two edges associated value (because matching applies
value two occurrences). follows graph edges.

According Micali Vazirani (1980), largest matching found O( n),
hence upper bound.
2
constraint
result shows complexity propagating SoftAllEqualmin
G
comes primarily number (conflicting) values, whereas factors,
number variables, little impact. Notice detecting conflicting values done
linear time (O(m)), first counting occurrences every value, flagging value
least two occurrences heavy finally flagging heavy values conflicting
every domain containing least two them.
Observe, moreover, exponential part algorithm based exploration
possible orders given set conflicting values. fact ordering relation
two values matters values belong domain variable.
words consider graph H values given CSP instance. Two values
b connected edge belong domain variable.
Instead considering possible orders given set values may consider
possible ways transforming given graph acyclic digraph. upper bound
number possible transformations 2E(H) E(H) number edges

122

fiSoft Constraints Difference Equality

H. sparse graphs bound much optimistic k!. example,
average degree vertex 4 number considered partial orders 22k = 4k .

10. Finding Set Similar Diverse Solutions
Problems similarity diversity wide range applications. Finding several
diverse solutions used sample solution space, instance product recommendation (Shimazu, 2001), case-based reasoning (Smyth & McClave, 2001; Aha & Watson,
2001) constraint elicitation (Bessiere, Coletta, Koriche, & OSullivan, 2005; Gama, Camacho, Brazdil, Jorge, & Torgo, 2005).
Conversely, similarity important problems periodic aspect. instance,
schedule timetable may need computed weekly basis, constraints might
change slightly week week. type problems regularity solutions,
is, similarity weeks solution, valuable property (Groer,
Golden, & Wasil, 2009).
Finally, finding similar solutions set variants problem useful
find solutions robust uncertainty. Suppose, example, solve
Travelling Salesman Problem (TSP), however, costs associated set k 1
links pairs cities uncertain variable time. would like find
optimal, near-optimal, route cost traversing link changes,
limited amount re-routing sufficient obtain another near-optimal solution.
purpose, one build similar structure pictured Figure 6 duplicating
TSP per uncertain link, last original formulation. duplicate,
cost corresponding link set expected upper bound. minimise
distance solutions, obtain solution good properties robustness:
cost associated ith link increases, solution ith duplicate valid
alternative avoiding link (if degrades solution quality much) whilst requiring
small amount re-routing.
therefore want find set k solutions either pairwise similar different
set k problems, distinct not. heuristic method introduced solve problem
finding k solutions constraint network, minimum (resp. maximum)
distance pairs solutions maximum (resp. minimum) Hebrard, Hnich,
OSullivan, Walsh (2005). Since reasoning maximum minimum distance NPhard (Frances & Litman, 1997), proposed use sum Hamming distances
instead. section, first formally define notion Hamming distance
variables solutions. Next, show constraints studied paper
help achieve ac rc polynomial time respectively maximising minimising
sum pairwise distances solutions set problem instances.
10.1 Hamming Distance:
Hamming distance instantiation two variables X defined
follows:

1 iff X 6=
h (X, ) =
0 otherwise

123

fiHebrard, Marx, OSullivan & Razgon

P1 : (X11 , X21 , X31 , . . . , Xn1 )
P2 : (X12 , X22 , X32 , . . . , Xn2 )
...
Pk : (X1k , X2k , X3k , . . . , Xnk )
Figure 6: problem P , duplicated k times.
Whereas Hamming distance two solutions si sj (over sets variables
{X1i , . . . , Xni } {X1j , . . . , Xnj }, respectively) defined as:
X
h (si , sj ) =
h (X`i , X`j )
1`n

Given problem P n variables {X1 , . . . , Xn }, duplicate P k times, identical
constraints seek set diverse solutions P , altered constraints model
expected scenarios seek set similar solutions variations P (see
Figure 6).
objective maximise minimise sum pairwise distances
(sub-)solutions duplicated problems:
X
h (si , sj )
(4)
1i<jk

10.2 Constraint Formulation:
first approaches problem relied heuristic methods (Hebrard et al., 2005;
Hentenryck, Coffrin, & Gutkovich, 2009), also shown problem P allows
it, knowledge compilation methods could efficiently solve problem (Hadzic, Holland, &
OSullivan, 2009).
show one achieve arc bound consistency maximising objective
function. Whilst arc consistency NP-hard minimisation, bounds consistency
achieved polynomial time minimisation maximisation. First, decompose
objective function described previously (Equation 4) using SoftAllEqualmin

G
SoftAllEqualmax
constraints

optimising,
respectively,
solution
similarity

diversity.
G
shall see achieving ac (resp. bc) decomposition equivalent
achieving ac (resp. bc) global constraint defined bounding objective.
Remember row Figure 6 represents duplicate original set variables
{X1 , . . . , Xn }. objective function defined sum Hamming distances
every pair rows. However, consider Figure 6 vertical slices.
column corresponds set duplicates {Xij | 1 j k} original original
variable Xi . One compute contribution set variables sum
Hamming distances pairs rows number pairwise disequalities
set: |{{j, k} | Xij 6= Xik & j < k}|. Notice precisely definition
cost minimise (resp. maximise) SoftAllEqualmin
(resp. SoftAllEqualmax
G
G ).
124

fiSoft Constraints Difference Equality

Therefore model objective function constraint networks shown Figure 7,
respectively minimisation maximisation. Notice that, simplify model, use
following, equivalent formulation SoftAllEqualmax
G , rather Definition 3:
SoftAllEqualmax
G ({X1 , . . . , Xn }, N ) N |{{i, j} | Xi 6= Xj & < j}|.

minimise
1 n
maximise
1 n

P

1in Ni subject
1
k
SoftAllEqualmin
G (Xi , . . . , Xi , Ni )

P

1in Ni subject
1
k
SoftAllEqualmax
G (Xi , . . . , Xi , Ni )

Figure 7: constraint network minimises (resp. maximises) sum distances
pairs solutions k vectors variables.

Second, notice constraint networks depicted Figure 7 two
constraints share one variable, Berge-cycle (Berge, 1970)
constraint hypergraph, is, sequence C1 , X1 , C2 , . . . , Xk , Ck+1 that:
X1 , . . . , Xk distinct variables,
C1 , . . . , Ck+1 distinct constraints,
k 2 C1 = Ck+1 ,
Xi scope Ci Ci+1 .
Indeed, SoftAllEqual constraints share variable, overlap
sum constraint limited single variable SoftAllEqual. constraint
hypergraph therefore Berge-acyclic, constraint networks shown
propagating ac sufficient filter globally inconsistent values (Janssen & Vilarem,
1988; Jegou, 1991).
Therefore, every constraint network ac (resp. rc), network
globally arc consistent (resp. globally range consistent). view two constraint
networks two global constraints, respectively CN div CN sim , set variables
{Xij | 1 n, 1 j k} variable N represent objective:
CN div ({Xij | 1 n, 1 j k}, N )
N

X

1
k
Ni & 1 n SoftAllEqualmax
G (Xi , . . . , Xi , Ni )

1in

CN sim ({Xij | 1 n, 1 j k}, N )
N

X

1
k
Ni & 1 n SoftAllEqualmin
G (Xi , . . . , Xi , Ni )

1in

125

fiHebrard, Marx, OSullivan & Razgon

P
Theorems 12 13 (where = 1in |D(Xi1 )| denotes sum domain sizes
one copy problem) follow from, respectively, (van Hoeve, 2004) Theorem 5:
Theorem 12 Enforcing ac CN div ({Xij | 1 n, 1 j k}, N ) achieved
O(k 2 m) steps.
Proof. Since constraint network equivalent CN div Berge-acyclic, know
ac iff every constraint decomposition ac. Moreover, describe filtering
algorithm requires bounded number calls propagator constraint
decomposition.
assume variables domain completely wiped process.
case, process would interrupted earlier (as soon inconsistency
detected achieving ac component).
introduce terminology:
property (1) denotes fact 1 n domains variables Xij
consistent upper bounds Ni ,
property (2) denotes fact 1 n domains variables Xij
consistent lower bounds Ni ,
P
property (3) denotes fact sum constraint (N
1in Ni ) bc (or
equivalently ac).
First, domain variable Xij 1 n 1 j k might changed,
well lower bound N . change upper bound N either results
immediate failure, bears consequences.
1. every [1..n], update upper bound variable Ni calling
procedure proposed van Hoeve (2004) find maximum possible number
disequalities. Hence property (1) holds.
2. achieve bc (equivalent ac case) sum constraint. Notice
upper bound N lower bounds Ni 1 n updated,
therefore property (1) (3) hold.
3. every [1..n], prune domains variables {Xij | 1 j k}
calling filtering procedure proposed van Hoeve (2004). Since domain
reduction trigger changes bounds Ni , know property
(1), (2) (3) hold, hence CN div ac.
P
first phase requires O( 1in k 2 |D(Xi1 )|), O(k 2 m) steps. second phase
requires O(n) steps. Finally, third phase, like first, requires O(k 2 m) steps. Hence
overall O(k 2 m) time complexity.
Theorem 13 Enforcing rc CN sim ({Xij | 1 n, 1 j k}, N ) achieved
O(k 4 m) steps.

126

fiSoft Constraints Difference Equality

Proof.
proof similar Theorem 12, swap upper lower
bounds, use procedure described Section 6 phase (1) (3).
3
first phase requires O(k
second phase requires O(n) steps. Finally,
P n) steps.
third phase requires O( 1in k 4 |D(Xi1 )|), O(k 4 m) steps. Hence overall
O(k 4 m) time complexity.

11. Conclusion
many applications concerned stating constraints similarity diversity amongst assignments variables. formulate problems use soft
variants well known AllDifferent AllEqual constraints. paper
considered global constraints AllDifferent AllEqual, optimisation
variants, SoftAllDiff SoftAllEqual, respectively. Furthermore, considered
two cost functions, based either Hamming distance satisfying assignment
number violations decomposition graph. shown constraint ensuring upper bound Hamming distance solution satisfying
AllEqual constraint propagated efficiently, arc bounds consistency.
shown that, one hand, deciding existence assignment minimising number violation decomposition graph AllEqual constraint
NP-complete, hence propagating arc consistency constraint ensuring property
NP-hard. hand, propagating bounds consistency constraint
done polynomial time. Moreover, shown problem fixed parameter
tractable number distinct values problem. work complements nicely
earlier results Cohen et al. (2004) showing language soft binary equality
constraints NP-complete, three distinct values domains.
paper shown problem remains NP-complete even graph soft binary
equality constraints forms clique, however, becomes polynomial number values
bounded.
paper therefore provides comprehensive complexity analysis achieving ac
bc important class soft constraints difference equality. Interestingly,
taxonomy shows enforcing equality harder enforcing difference.

Acknowledgments
Hebrard, OSullivan Razgon supported Science Foundation Ireland (Grant Number 05/IN/I886). Marx supported part ERC Advanced grant DMMCA,
Alexander von Humboldt Foundation, Hungarian National Research Fund (Grant
Number OTKA 67651).

References
Aha, D. W., & Watson, I. (Eds.). (2001). Case-Based Reasoning Research Development,
4th International Conference Case-Based Reasoning, ICCBR 2001, Vancouver,
BC, Canada, July 30 - August 2, 2001, Proceedings, Vol. 2080 Lecture Notes
Computer Science. Springer.

127

fiHebrard, Marx, OSullivan & Razgon

Beldiceanu, N., & Carlsson, M. (2001). Sweep Generic Pruning Technique Applied
Non-Overlapping Rectangles Constraint. Walsh, T. (Ed.), Proceedings 7th
International Conference Principles Practice Constraint Programming (CP01), Vol. 2239 Lecture Notes Computer Science, pp. 377391, Paphos, Cyprus.
Springer-Verlag.
Beldiceanu, N., & Petit, T. (2004). Cost evaluation soft global constraints. Regin, J.-C.,
& Rueher, M. (Eds.), Proceedings 6th International Conference Integration
AI Techniques Constraint Programming Combinatorial Optimization
Problems (CPAIOR-04), Vol. 3011 Lecture Notes Computer Science, pp. 8095,
Nice, France. Springer-Verlag.
Beldiceanu, N. (2001). Pruning Minimum Constraint Family Number
Distinct Values Constraint Family. Walsh, T. (Ed.), Proceedings 7th
International Conference Principles Practice Constraint Programming (CP01), Vol. 2239 Lecture Notes Computer Science, pp. 211224, Paphos, Cyprus.
Springer-Verlag.
Berge, C. (1970). Graphs Hypergraphs. Dunod.
Bessiere, C., Coletta, R., Koriche, F., & OSullivan, B. (2005). SAT-Based Version Space
Algorithm Acquiring Constraint Satisfaction Problems.. Gama et al. (Gama
et al., 2005), pp. 2334.
Bessiere, C., Hebrard, E., Hnich, B., Kiziltan, Z., & Walsh, T. (2006). Filtering algorithms
nvalue constraint. Constraints, 11 (4), 271293.
Cohen, D., Cooper, M., Jeavons, P., & Krokhin, A. (2004). maximal tractable class
soft constraints. Journal Artificial Intelligence Research, 22, 122.
Frances, M., & Litman, A. (1997). Covering Problems Codes. Theory Computing
Systems, 30, 113119.
Gama, J., Camacho, R., Brazdil, P., Jorge, A., & Torgo, L. (Eds.). (2005). Machine Learning: ECML 2005, 16th European Conference Machine Learning, Porto, Portugal, October 3-7, 2005, Proceedings, Vol. 3720 Lecture Notes Computer Science.
Springer.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-completeness. W.H. Freeman Company.
Groer, C., Golden, B., & Wasil, E. (2009). Consistent Vehicle Routing Problem.
Manufacturing & Service Operations Management, 11 (4), 630643.
Hadzic, T., Holland, A., & OSullivan, B. (2009). Reasoning Optimal Collections
Solutions. Gent, I. P. (Ed.), Proceedings 15th International Conference
Principles Practice Constraint Programming (CP-09), Vol. 5732 Lecture
Notes Computer Science, pp. 409423, Lisbon, Portugal. Springer-Verlag.
Hebrard, E., Hnich, B., OSullivan, B., & Walsh, T. (2005). Finding Diverse Similar
Solutions Constraint Programming. Veloso, M. M., & Kambhampati, S. (Eds.),
Proceedings 20th National Conference Artificial Intelligence Seventeenth Conference Innovative Applications Artificial Intelligence (AAAI-05 /
IAAI-05), pp. 372377, Pittsburgh, PE, USA. AAAI Press / MIT Press.
128

fiSoft Constraints Difference Equality

Hebrard, E., Marx, D., OSullivan, B., & Razgon, I. (2009). Constraints Difference
Equality: Complete Taxonomic Characterisation. Gent, I. P. (Ed.), Proceedings
15th International Conference Principles Practice Constraint Programming (CP-09), Lecture Notes Computer Science, pp. 424438, Lisbon, Portugal.
Springer-Verlag.
Hebrard, E., OSullivan, B., & Razgon, I. (2008). Soft Constraint Equality: Complexity
approximability. Stuckey, P. J. (Ed.), Proceedings 14th International
Conference Principles Practice Constraint Programming (CP-08), Lecture
Notes Computer Science, pp. 358371, Sydney, Australia. Springer-Verlag.
Hentenryck, P. V., Coffrin, C., & Gutkovich, B. (2009). Constraint-based local search
automatic generation architectural tests. Gent, I. P. (Ed.), Proceedings 15th
International Conference Principles Practice Constraint Programming (CP09), Vol. 5732 Lecture Notes Computer Science, pp. 787801, Lisbon, Portugal.
Springer-Verlag.
Janssen, P., & Vilarem, M.-C. (1988). Problemes de satisfaction de contraintes: techniques
de resolution et application la synthese de peptides. C.R.I.M. Research Report..
Jegou, P. (1991). Contribution letude des problemes de satisfaction de contraintes: algorithmes de propagation et de resolution. Propagation de contraintes dans les reseaux
dynamiques. Ph.D. thesis.
Mehlhorn, K., & Thiel, S. (2000). Faster Algorithms Bound-Consistency Sortedness Alldifferent Constraint. Dechter, R. (Ed.), Proceedings 6th International Conference Principles Practice Constraint Programming (CP-00),
Vol. 1894 Lecture Notes Computer Science, pp. 306319, Singapore. SpringerVerlag.
p
Micali, S., & Vazirani, V. V. (1980). o( (|v|)|e|) algorithm finding maximum matching general graphs. FOCS, pp. 1727.
Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.
Petit, T., Regin, J.-C., & Bessiere, C. (2000). Meta-constraints Violations
Constrained Problems. 12th IEEE International Conference Tools Artificial
Intelligence (ICTAI-00), pp. 358365.
Petit, T., Regin, J.-C., & Bessiere, C. (2001). Specific Filtering Algorithms OverConstrained Problems. Walsh, T. (Ed.), Proceedings 7th International Conference Principles Practice Constraint Programming (CP-01), Vol. 2239
Lecture Notes Computer Science, pp. 451463, Paphos, Cyprus. Springer-Verlag.
Petit, T., Regin, J.-C., & Bessiere, C. (2002). Range-Based Algorithm Max-CSP.
van Hentenryck, P. (Ed.), Proceedings 8th International Conference Principles Practice Constraint Programming (CP-02), Vol. 2470 Lecture Notes
Computer Science, pp. 113132, Ithaca, NY, USA. Springer-Verlag.
Quimper, C.-G., Lopez-Ortiz, A., van Beek, P., & Golynski, A. (2004). Improved Algorithms
Global Cardinality Constraint. Wallace, M. (Ed.), Proceedings 10th
International Conference Principles Practice Constraint Programming (CP-

129

fiHebrard, Marx, OSullivan & Razgon

04), Vol. 3258 Lecture Notes Computer Science, pp. 542556, Toronto, Canada.
Springer-Verlag.
Regin, J.-C. (1994). Filtering Algorithm Constraints Difference CSPs.
Hayes-Roth, B., & Korf, R. E. (Eds.), Proceedings 12th National Conference
Artificial Intelligence (AAAI-94), pp. 362367, Seattle, WA, USA. AAAI Press.
Shimazu, H. (2001). Expertclerk: Navigating Shoppers Buying Process Combination Asking Proposing. Nebel, B. (Ed.), Proceedings 17th International
Joint Conference Artificial Intelligence (IJCAI-01), pp. 14431450, Seattle, WA,
USA. Morgan Kaufmann.
Smyth, B., & McClave, P. (2001). Similarity vs. diversity.. Aha, & Watson (Aha &
Watson, 2001), pp. 347361.
van Hoeve, W.-J. (2004). hyper-arc consistency algorithm soft alldifferent constraint. Wallace, M. (Ed.), Proceedings 10th International Conference
Principles Practice Constraint Programming (CP-04), Vol. 3258 Lecture
Notes Computer Science, pp. 679689, Toronto, Canada. Springer-Verlag.
van Hoeve, W.-J., Pesant, G., & Rousseau, L.-M. (2006). Global Warming: Flow-Based
Soft Global Constraints. Journal Heuristics, 12 (4-5), 347373.

130

fiJournal Artificial Intelligence Research 41 (2011) pages 2567

Submitted 09/10; published 05/11

Determining Possible Necessary Winners
Common Voting Rules Given Partial Orders
Lirong Xia
Vincent Conitzer

lxia@cs.duke.edu
conitzer@cs.duke.edu

Department Computer Science, Duke University,
Durham, NC 27708, USA

Abstract
Usually voting rule requires agents give preferences linear orders. However,
cases impractical agent give linear order alternatives.
suggested let agents submit partial orders instead. Then, given voting rule,
profile partial orders, alternative (candidate) c, two important questions arise:
first, still possible c win, second, c guaranteed win?
possible winner necessary winner problems, respectively. two problems
divided two sub-problems: determining whether c unique winner (that
is, c winner), determining whether c co-winner (that is, c set
winners).
consider setting number alternatives unbounded votes
unweighted. completely characterize complexity possible/necessary winner
problems following common voting rules: class positional scoring rules (including
Borda), Copeland, maximin, Bucklin, ranked pairs, voting trees, plurality runoff.

1. Introduction
multiagent systems, often, agents must make joint decision spite fact
different preferences alternatives. example, agents may
decide joint plan allocation tasks/resources. general solution
problem agents vote alternatives. is, agent gives
ranking (linear order) alternatives; voting rule takes submitted
rankings input, based produces chosen alternative (the winner), set
chosen alternatives. design good voting rules studied centuries
social choice community. recently, computer scientists become interested
social choicemotivated part applications multiagent systems, also
applications. Hence, community interested computational social choice emerged.
traditional social choice, agents usually required give linear order
alternatives. However, especially multiagent systems applications, always
practical. one, sometimes, set alternatives large. example,
generally many possible joint plans allocations tasks/resources agent
give linear order them. settings, agents must use different voting language
represent preferences; example, use CP-nets (Boutilier, Brafman,
Domshlak, Hoos, & Poole, 2004; Lang, 2007; Xia, Lang, & Ying, 2007a, 2007b; Lang &
Xia, 2009). However, agent uses CP-net (or similar language) represent
preferences, generally gives us partial order alternatives. Another
c
2011
AI Access Foundation. rights reserved.

fiXia & Conitzer

issue always possible agent compare two alternatives (Pini, Rossi,
Venable, & Walsh, 2007). incomparabilities also result partial order.
paper, study setting agent, partial order corresponding agents preferences. study following two questions. (1)
case that, extension partial orders linear orders, alternative c wins?
(2) case that, extension partial orders linear orders, alternative c
wins? problems known possible winner necessary winner problems, respectively, introduced Konczak Lang (2005). Depending interpretation c
wins, possible/necessary winner problems divided two sub-problems:
one called possible/neccessary unique winner problem (here unique often omitted
causing confusion), c wins means c winner election; called possible/necessary co-winner problem, c wins means
c one winners. noted answer depends voting
rule used. Previous research also investigated setting uncertainty
voting rule; here, necessary (possible) winner alternative wins
(some) realization rule (Lang, Pini, Rossi, Venable, & Walsh, 2007). paper,
study setting; is, rule always fixed.
problems motivated observations impracticality
submitting linear orders, also relate preference elicitation manipulation.
preference elicitation, idea that, instead agent report preferences
once, ask simple queries preferences (e.g. prefer
b?), enough information determine winner. Preference elicitation found many applications multiagent systems, especially combinatorial auctions (for overviews, see Parkes, 2006; Sandholm & Boutilier, 2006) voting settings
well (Conitzer & Sandholm, 2002, 2005b; Conitzer, 2009). problem deciding
whether terminate preference elicitation declare winner exactly necessary winner problem. Manipulation said occur agent casts vote
correspond true preferences, order obtain result prefers.
GibbardSatterthwaite Theorem (Gibbard, 1973; Satterthwaite, 1975), reasonable voting rule, situations agent successfully manipulate rule.
prevent manipulation, one approach taken computational social
choice community study whether manipulation (or made) computationally
hard (Bartholdi, Tovey, & Trick, 1989a; Bartholdi & Orlin, 1991; Hemaspaandra & Hemaspaandra, 2007; Elkind & Lipmaa, 2005; Conitzer, Sandholm, & Lang, 2007; Faliszewski,
Hemaspaandra, & Schnoor, 2008; Zuckerman, Procaccia, & Rosenschein, 2009; Xia, Zuckerman, Procaccia, Conitzer, & Rosenschein, 2009; Faliszewski, Hemaspaandra, & Schnoor,
2010). fundamental questions studied Given votes,
coalition agents cast votes alternative c wins? (so-called constructive manipulation) Given votes, coalition agents cast votes
alternative c win? (so-called destructive manipulation). problems
correspond possible winner problem (the complement of) necessary winner
problem, respectively. precise, correspond restricted versions possible winner problem (the complement of) necessary winner problem
partial orders linear orders (the nonmanipulators votes) partial
orders empty (the manipulators votes). However, uncertainty parts
26

fiDetermining Possible Necessary Winners Given Partial Orders

nonmanipulators votes, parts manipulators votes already fixed (for
example due preference elicitation), correspond general versions
possible winner problem (the complement of) necessary winner problem.
Another related problem evaluation problem (Conitzer et al., 2007).
given probability distribution voters vote, asked probability
given alternative wins. shown anonymous voting rule,
number alternatives constant, polynomial-time algorithm
solves evaluation problem; number alternatives bounded
constant, problem becomes #P hard plurality, Borda, Copeland
rules (Hazon, Aumann, Kraus, & Wooldridge, 2008). complexity influencing
distribution voters votes multiple binary issues make given alternative
(a valuation issues) win also studied (Erdelyi, Fernau, Goldsmith,
Mattei, Raible, & Rothe, 2009). possible/necessary winner problems related
evaluation problem following way. every voter assigns positive probability
every one linear orders extend partial order, then, alternative c, c
possible winner probability c wins election positive; c
necessary winner probability c wins election 1. must
note reduction possible/necessary winner problem evaluation
problem general polynomial, partial order, possible
exponentially many linear orders extend it. example, partial
order empty, linear order extension it. However, paper,
prove results show possible/necessary winner problem hard even
number undetermined pairs partial order constant, fact
polynomially many linear orders extend it. Hence, hardness results also imply
(only NP-)hardness results evaluation problem.
variety different interpretations possible necessary winner
problems, surprising already significant studies problems. Two main settings studied (see Walsh, 2007 good survey). first
setting, number alternatives bounded, votes weighted. Here,
Borda, veto, Copeland, maximin, STV, plurality runoff rules, possible winner
problem NP-complete; STV plurality runoff rules, necessary winner
problem coNP-complete (Conitzer et al., 2007; Pini et al., 2007; Walsh, 2007). However,
many elections, votes unweighted (that is, agents vote counts same).
votes unweighted, number alternatives bounded, possible
necessary winner problems always solved polynomial time, assuming voting
rule executed polynomial time (Conitzer et al., 2007; Walsh, 2007). Hence,
setting studied votes unweighted number
alternatives bounded; setting study paper. setting, possible necessary winner problems known hard STV (Bartholdi
& Orlin, 1991; Pini et al., 2007; Walsh, 2007). Computing whether alternative
possible necessary Condorcet winner done polynomial time (Konczak & Lang,
2005). However, time conference version work (Xia & Conitzer, 2008),
common rules, prior results (except fact
27

fiXia & Conitzer

problems easy many rules partial order either linear order
empty, is, standard manipulation problem).1
1.1 Contributions
paper, characterize complexity possible necessary winner problems
important rulesspecifically, class positional scoring rules,
Copeland, maximin, Bucklin, ranked pairs, voting trees, plurality runoff.
show possible winner problems NP-complete rules except
possible unique winner problem respect plurality runoff. also show
necessary winner problems coNP-complete Copeland, ranked pairs, voting
trees; necessary co-winner problem coNP-complete plurality runoff.
remaining cases, present polynomial-time algorithms. results summarized
Table 1.

STV
Plurality
Veto
Pos. scoring
(incl. Borda, k-approval)

Copeland
Maximin
Bucklin
Ranked pairs
Voting trees
(incl. balanced trees)

Plu. w/ runoff

Possible Winner
NP-complete
(Bartholdi & Orlin, 1991)
P2
P3
NP-complete

4

NP-complete
NP-complete
NP-complete
NP-complete

4

NP-complete

4

4
4
4

NP-complete (unique winner)
P (co-winner)

Necessary Winner
coNP-complete
(Bartholdi & Orlin, 1991)
P2
P3
P
coNP-complete
P
P
coNP-complete

4

coNP-complete

4

4

P (unique winner)
coNP-complete (co-winner)

4

Table 1: Summary complexity possible/necessary winner problems respect
common voting rules. Unless otherwise mentioned, results depend
whether consider unique-winner co-winner version problem.

1. earlier paper (Konczak & Lang, 2005) studied problems positional scoring rules, claimed
problems polynomial-time solvable positional scoring rules; however, subtle
mistake proofs. show possible winner problem fact NP-complete
positional scoring rules. also give correct proof necessary winner problem indeed
polynomial-time solvable positional scoring rules.
2. Easy prove; also proved work Betzler Dorn (2010), follows bribery algorithm
Faliszewski (2008).
3. Easy prove, also proved work Betzler Dorn (2010).
4. Hardness results hold even number unknown pairs partial order
constant.

28

fiDetermining Possible Necessary Winners Given Partial Orders

paper significant extension conference version work (Xia &
Conitzer, 2008): extended version includes proofs, results voting trees,
plurality runoff, k-approval new. conference version also mention
plurality veto; results easy follow known results, explained
footnotes table.
1.2 Subsequent Work since Conference Version
Since conference version work, complexity possible winner problem
respect positional scoring rule fully characterized (Betzler & Dorn,
2010; Baumeister & Rothe, 2010). theorems Betzler Dorn (2010), possible
winner problem NP-complete respect Borda k-approval. Still, hardness
results directly imply hardness results obtained positional scoring rules
paperwe prove hardness results Borda k-approval hold even
number undetermined pairs vote 4.
Also, special case possible necessary winner problems new alternatives
join election voters preferences initial alternatives fully
revealed proposed studied work Chevaleyre, Lang, Maudet,
Monnot (2010). shown possible-winner-with-new-alternatives problem
NP-complete maximin, Copeland (Xia, Lang, & Monnot, 2011), k-approval
k 3 least 3 new alternatives (Chevaleyre, Lang, Maudet, Monnot, & Xia,
2010); problem P Bucklin (when k 3) (Xia, Lang, & Monnot, 2011), Borda,
k-approval (when k 2 two new alternatives) (Chevaleyre,
Lang, Maudet, Monnot, & Xia, 2010).
Meanwhile, number new results complexity unweighted coalitional
manipulation problem also obtained. Specifically, unweighted coalitional
manipulation problem shown NP-hard Copeland 0 1
(except = 12 ; results even hold two manipulators) (Faliszewski et al., 2008,
2010),5 maximin (two manipulators) ranked pairs (one manipulator) (Xia et al., 2009),
specific positional scoring rule (two manipulators) (Xia, Conitzer, & Procaccia, 2010).
mentioned before, unweighted coalitional manipulation problem special case
possible winner problem studied paper (where partial orders linear
orders others empty); result, NP-hardness results unweighted
coalitional manipulation problem also imply NP-hardness possible winner problem
rules. note NP-hardness results proved paper (except
possible unique winner problem plurality runoff) hold even partial
order, number pairs alternatives order unknown constant.
Therefore, subsequent research unweighted coalitional manipulation
completely imply NP-hardness results prove paper possible
winner problem Copeland, maximin, ranked pairs, positional scoring rules.
Elkind et al. (2009) showed possible winner problem also reduces swap
bribery problem, interested party pay voters swap adjacent alternatives
5. Faliszewksi et al. (2008) also study case weighted coalitional manipulation three alternatives
Copeland, show hard problem depends whether consider
unique-winner co-winner variant problem. study weighted votes paper.

29

fiXia & Conitzer

rankings, price swap two alternatives depends identity
alternatives identity voter. is, (with respect fixed voting rule)
computational complexity swap bribery problem least high
possible winner problem, terms polynomial-time reductions.
complexity possible winner problem also studied fixedparameter tractability perspective, parameters number alternatives,
number voters, number unknown pairs vote (Betzler, Hemmann, &
Niedermeier, 2009). Finally, counting version possible winner problem also
studied (Bachrach, Betzler, & Faliszewski, 2010).

2. Preliminaries
Let C = {c1 , . . . , cm } set alternatives (or candidates). linear order C
transitive, antisymmetric, total relation C. set linear orders C
denoted L(C). n-voter profile P C consists n linear orders C. is,
P = (V1 , . . . , Vn ), every n, Vi L(C). set profiles C denoted
P (C). remainder paper, denotes number alternatives n denotes
number voters.
voting rule r function set profiles C set (nonempty)
subsets C, is, r : P (C) 2C \ . following common voting rules.
1. (Positional) scoring rules: positional scoring rule defined scoring vector
~sm = (~sm (1), . . . , ~sm (m)) non-negative integers, ~sm (1) ~sm (m).
vote V L(C) c C, let s(V, c) = ~smP
(j), j rank
c V . profile P = (V1 , . . . , Vn ), let s(P, c) = ni=1 s(Vi , c). rule
select c C s(P, c) maximized. examples positional scoring rules
Borda, scoring vector (m 1, 2, . . . , 0), plurality,
scoring vector (1, 0, . . . , 0), veto, scoring vector (1, . . . , 1, 0),
k-approval (1 k 1), scoring vector (1, . . . , 1, 0, . . . , 0).
| {z }
k

paper, assume scoring vector computed polynomial time.
2. Copeland: two alternatives ci cj , simulate pairwise election
them, seeing many votes rank ci ahead cj , many rank cj
ahead ci . ci wins majority votes rank ci ahead cj . Then,
alternative receives one point win pairwise election. (Typically,
alternative also receives half point pairwise tie, matter
results.) winner alternative highest score.
3. Maximin (a.k.a. Simpson): Let NP (ci , cj ) denote number votes rank ci
ahead cj profile P . winner alternative c maximizes min{NP (c, c ) :
c C, c 6= c}.
4. Bucklin: alternative cs Bucklin score smallest number k
half votes rank c among top k alternatives. winner alternative
smallest Bucklin score. (Sometimes, ties broken number
30

fiDetermining Possible Necessary Winners Given Partial Orders

votes rank alternative among top k position, simplicity
consider tiebreaking rule here.)
5. Ranked pairs: rule first creates entire ranking alternatives. NP (ci , cj )
defined maximin rule. step, consider pair alternatives
ci , cj previously considered; specifically, choose remaining
pair highest NP (ci , cj ). fix order ci > cj , unless contradicts
previous orders fixed (that is, violates transitivity). continue
considered pairs alternatives (hence full ranking). alternative
top ranking wins.
6. Voting trees: voting tree binary tree leaves, leaf associated
alternative. round, pairwise election alternative
ci sibling cj : majority voters prefer ci cj , cj eliminated,
ci associated parent two nodes; similarly, majority
voters prefer cj ci , ci eliminated, cj associated parent
two nodes. alternative associated root tree (wins
rounds) wins. Balanced voting trees also known cup, knockout tournaments
single-elimination tournaments.
7. Plurality runoff: rule two steps. first step, alternatives except
two ranked top position times eliminated,
votes transfer second round, plurality rule (a.k.a. majority rule
case two alternatives) used select winner.
8. Single transferable vote (STV): election rounds. round, alternative gets minimal plurality score drops out, removed
votes (so votes alternative transfer another alternative next
round). last-remaining alternative winner.
Given profile P , pairwise score difference DP (c, c ) alternatives c c defined
follows.
DP (c, c ) = NP (c, c ) NP (c , c)
subscript P omitted risk confusion. linear order V
C, let DV denote pairwise score difference function profile consists
single vote V . is, DV = D{V } . follows definition D(c, c ) = D(c , c).
note although maximin, ranked pairs, voting trees based pairwise scores,
also computed pairwise score differences way,
profile P n votes, pair alternatives (c, c ), DP (c, c ) = 2NP (c, c ) n.
adopt parallel-universes tiebreaking (Conitzer, Rognlie, & Xia, 2009) define
winning alternatives rules multiple rounds (i.e., ranked pairs, voting
trees, plurality runoff, STV). is, alternative c winner
exists way break ties steps c winner. example,
alternative c winner voting tree, exists way break ties
pairwise elections voting process, c wins. partial order C reflexive,
transitive, antisymmetric relation C. say linear order V extends partial order
V .
31

fiXia & Conitzer

Definition 1 linear order V C extends partial order C every pair
alternatives c, c C, c c c V c .
Throughout paper use following notation. Let V denote linear order C;
let denote partial order C; let P denote profile linear orders; let Pposet denote
profile partial orders.

3. Possible/Necessary Winners
ready define possible (necessary) winners, first introduced
Konczak Lang (2005).
Definition 2 Given profile partial orders Pposet = (O1 , . . . , ) C, say
alternative c C is: (1) possible winner exists P = (V1 , . . . , Vn ) Vi
extends Oi , r(P ) = {c}; (2) necessary winner every P = (V1 , . . . , Vn )
Vi extends Oi , r(P ) = {c}; (3) possible co-winner exists P = (V1 , . . . , Vn )
Vi extends Oi , c r(P ); (4) necessary co-winner P = (V1 , . . . , Vn )
Vi extends Oi , c r(P ).
Example 1 Let three alternatives {c1 , c2 , c3 }. Three partial orders illustrated
Figure 1. Let Pposet = (O1 , O2 , O3 ). c1 possible (co-)winner Pposet respect
plurality, complete O1 adding c2 c3 , complete O2 adding c1 c2 ,
complete O3 adding c1 c2 c1 c3 ; then, c1 winner. However, c1
necessary (co-)winner, complete O1 adding c2 c3 , complete O2
adding c2 c1 , complete O3 adding c2 c1 c1 c3 ; then, c2 winner.
O1

c2

c1

O2

O3
c1

c3

c1
c3

c2

c2

c3

Figure 1: Partial orders.

However, let Pposet
= (O1 , O1 , O2 ), c1 (only) necessary winner,
c1 ranked first least two votes.

Now, define computational problems studied paper:
Definition 3 Define problem Possible Winner (PW) respect voting rule r be:
given profile Pposet partial orders alternative c, asked whether c
possible winner Pposet respect r.
Necessary Winner (NW), Possible co-Winner (PcW), Necessary co-Winner (NcW)
defined similarly.
natural first question problems related other. turns
(holding voting rule fixed) exists polynomial-time Turing reduction
NW PcW. is, PcW P, NW also P.
Proposition 1 voting rule r, computing PcW respect r P,
computing NW respect r also P .
32

fiDetermining Possible Necessary Winners Given Partial Orders

Proof. r never outputs , alternative c necessary unique winner respect
r every alternative (d 6= c), possible co-winner. Therefore,
polynomial-time algorithm solves PcW problem respect r,
solve NW problem, simply run algorithm every alternative (d 6= c).
6= c possible co-winner, output c necessary unique winner;
otherwise, output c necessary unique winner.
2
similar relationship PW NcW problems. true
alternative (d 6= c) possible unique winner, c necessary co-winner.
However, possible even alternative (d 6= c) possible unique winner, c
still necessary co-winner. example, let Pposet = (c2 c3 c1 , c3 c2 c1 ).
Pposet already composed linear orders, one extension (itself).
follows possible unique winner Pposet respect plurality, clearly
c1 necessary co-winner. generally, following proposition,
says pair different problems X, {PW, PcW, NW, NcW}, answer
cannot computed answers X alternatives, unless X =NW
=PcW. (This holds even rule plurality).
Proposition 2 Suppose 3. Let X, {P W, P cW, N W, N cW } (1) X6=Y
(2) X6=PcW Y6=NW. exist two profiles Pposet Pposet partial orders (with
|Pposet | = |Pposet |), (1) every alternative c, answers X respect
plurality Pposet Pposet , (2) exists alternative
answers respect plurality Pposet Pposet different.
Proof. proof construction. partial order C, let op(O) denote
set alternatives c exists least one extension c
top position. set C C, define OC arbitrary partial order
op(OC ) = C . simplicity, write Oc O{c } . example, = 3, let
Oc1 = O{c1 } = c1 c2 c3 , is, Oc1 linear order. another example, O{c1 ,c2 }
partial order obtained [c1 c2 c3 ] removing c1 c2 .
Let = c1 . next specify profiles Pposet Pposet following (exhaustive)
list cases (X, ).
(PW, NW) (PW, NcW). (1) Let Pposet composed 5 copies Oc1 . c1
necessary unique/co-winner. (2) Let Pposet = (Oc1 , Oc2 , Oc2 , O{c1 ,c3 } , O{c1 ,c3 } ). c1
unique winner one extension, {c1 , c2 } winners two extensions,
{c2 , c3 } winners one extension. Therefore, c1 necessary unique/cowinner. note c1 possible unique winner profiles.
(PW, PcW). (1) Let Pposet = (Oc1 , Oc2 ). {c1 , c2 } winners extension, means c1 possible co-winner. (2) Let Pposet = (Oc2 , Oc3 ).
{c2 , c3 } winners extension, means c1 possible
co-winner. note possible unique winner either profile.
(NcW, NW). (1) Let Pposet = (Oc1 , Oc1 ). c1 winner extension,
means c1 necessary unique winner. (2) Let Pposet = (Oc1 , O{c1 ,c2 } ).
c1 winner one extension, {c1 , c2 } winners
33

fiXia & Conitzer

extension, means c1 necessary unique winner. note c1
necessary co-winner profiles.
(PcW, PW) (PcW, NcW). (1) Let Pposet = (O{c1 ,c2 } , O{c1 ,c2 } ). c1 unique
winner one extension, c2 unique winner one extension, {c1 , c2 }
winners two extensions. Therefore, c1 possible unique winner (meanwhile, c1
necessary co-winner). (2) Let Pposet = (Oc1 , Oc2 ). {c1 , c2 } winners
extension, means c1 possible unique winner (meanwhile,
c1 necessary co-winner). note c1 c2 possible co-winners
profiles.
(NW, PW), (NW, PcW), (NcW, PW), (NcW, PcW). (1) Let Pposet = (O{c1 ,c2 } , O{c1 ,c2 } ).
c1 unique winner one extension, c2 unique winner one extension,
{c1 , c2 } winners two extensions. Therefore, c1 possible unique/cowinner. (2) Let Pposet = (O{c2 ,c3 } , O{c2 ,c3 } ). c2 unique winner one extension,
c3 unique winner one extension, {c2 , c3 } winners two extensions. Therefore, c1 possible unique/co-winner. note
necessary unique/co-winner either profile.
(NW, NcW). (1) Let Pposet = (Oc1 , Oc2 ). {c1 , c2 } winners extension, means c1 necessary co-winner. (2) Let Pposet = (Oc2 , O{c1 ,c2 } ).
{c1 , c2 } winners one extension, c2 unique winner
extension, means c1 necessary co-winner. note
necessary unique winner either profile.
2

4. Hardness Results
section, prove PW (PcW) NP-complete respect class positional
scoring rules, Copeland, maximin, Bucklin, ranked pairs, voting trees; NW (NcW)
coNP-complete respect Copeland, ranked pairs, voting trees; PW NPcomplete NcW coNP-complete respect plurality runoff. positional
scoring rules, show PW hard positional scoring rulesin fact,
plurality veto, PW easy; rather, give sufficient condition positional
scoring rule PW hard. notably, Borda satisfies condition. kapproval satisfy condition, provide distinct proof PW (PcW)
respect k-approval (k 2).6 Similarly voting trees, provide necessary
condition hardness results hold, notably, balanced voting trees
satisfy condition. results (except one PW respect plurality
runoff) hold even partial orders almost linear orders. is,
number undetermined pairs partial order bounded constant.
6. conference version paper (Xia & Conitzer, 2008), Betzler Dorn proved dichotomy
theorem possible winner problems respect positional scoring rules (Betzler & Dorn, 2010).
According theorem, PW respect k-approval (k 2) NP-complete. paper,
prove problem NP-complete, even number undetermined pairs vote
4.

34

fiDetermining Possible Necessary Winners Given Partial Orders

hardness results proved reductions exact 3-cover (X3C)
problem, except result k-approval, proved reduction 3-SAT.
X3C 3-SAT known NP-complete (Garey & Johnson, 1979). two problems
defined follows.
Definition 4 (X3C) given set V = {v1 , . . . , vq } collection = {S1 , . . . , St },
t, Si = {vl(i,1) , vl(i,2) , vl(i,3) } V, 1 l(i, 1), l(i, 2), l(i, 3) q.
asked whether cover elements V non-overlapping sets S.
Definition 5 (3-SAT) given formula conjunctive normal form: F = C1
. . . Ct binary variables x1 , . . . , xq , j t, Cj called clause.
j t, Cj = lj1 lj2 lj3 , {1, 2, 3}, lj called literal, exists
q either lj = xi lj = xi . asked whether exists valuation
variables F true.
proof, election instance construct arbitrary X3C (or 3-SAT)
instance consists two parts. first part set partial orders encode X3C
(or 3-SAT) instance.7 example, PW reductions X3C, first part
structured follows: order c win, alternative c needs
placed high position extensions partial orders least number
times. However, partial orders, set three alternatives
put c high position extension partial order, three
alternatives must ranked even higher positions (that is, c pushes three
alternatives extension). sets three alternatives must sometimes
pushed correspond sets three elements X3C instance. PW instance
set way X3C-element alternative pushed c two
different votes first part, c cannot win. Thus, sets alternatives
push must disjoint, instance set way need put c
high position often enough pushed-up 3-sets actually must constitute exact
cover. second part set linear orders (that is, second part, everything
determined) whose purpose is, informally stated, adjust scores alternatives
get properties described.
First introduce notation represent set pairwise comparisons
linear order.
Definition 6 set {a1 , . . . , al }, let O(a1 , . . . , al ) = {(ai , aj ) : < j}.
is, O(a1 , . . . , al ) set ordered pairs consistent linear order a1
. . . al . example, O(a, b, c) = {(a, b), (b, c), (a, c)}. following notation
frequently used proofs.
Definition 7 set partition A1 , . . . , Ak A, let O(A1 , . . . , Ak ) denote
arbitrary linear order consistent A1 A2 . . . Ak .
7. Typically, define partial orders first defining linear orders removing
pairwise ordering constraints.

35

fiXia & Conitzer

proofs make use notation use fact O(A1 , . . . , Ak ) consistent
A1 . . . Ak , order within Ai (i k) matter. example,
let = {a, b, c, d}, A1 = {a}, A2 = {b, c}, A3 = {d}. two linear orders
consistent A1 A2 A3 . b c c b d. O(A1 , A2 , A3 )
denote either them, e.g., O(A1 , A2 , A3 ) = b c d. Sometimes use
notation Others denote set objects mentioned context.
example, O(A1 , A2 , A3 ) = O(Others, A2 , A3 ) = O(A1 , Others, A3 ) = O(A1 , A2 , Others).
Usually, positional scoring rule defined fixed number alternatives (that is,
fixed). hold fixed, exist polynomial-time algorithms PW
NW (Walsh, 2007; Conitzer et al., 2007). However, positional scoring rules
defined number alternativesfor example, Borda, plurality, veto.
positional scoring rules, number alternatives bounded, indeed,
prove PW always easy respect rules. study complexity
social choice problems involve growing number alternatives, necessary
associate scoring vector every natural number alternatives. remainder
paper, positional scoring rule r consists sequence scoring vectors {~s1 , ~s2 , . . .}
N, ~si scoring vector alternatives. next theorem provides
sufficient condition positional scoring rule PW NP-complete. paper,
PW/PcW problems NP, NW/NcW problems coNP.
follows fact that, given extension partial orders linear orders,
compute winner(s) polynomial-time rules studied paper.
mind, prove hardness direction NP-completeness/coNP-completeness
proofs. exist rules computing winner(s) NP-hard, example,
Dodgsons rule (Bartholdi, Tovey, & Trick, 1989b; Hemaspaandra, Hemaspaandra, & Rothe,
1997) Youngs rule (Rothe, Spakowski, & Vogel, 2003), study rules
computing winners hard here.
Theorem 1 Let r positional scoring rule scoring vectors {~s1 , ~s2 , . . .}. Suppose
exists polynomial function f (x) x N, exist l k
x l f (x) k l 4, satisfy following conditions:
(1) ~sl (k) ~sl (k + 1) = ~sl (k + 1) ~sl (k + 2) = ~sl (k + 2) ~sl (k + 3) > 0,
(2) ~sl (k + 3) ~sl (k + 4) > 0,
Then, PW PcW NP-complete respect r, even number
undetermined pairs vote 4.
Proof. Given X3C instance V = {v1 , . . . , vq }, = {S1 , . . . , St }, let q + 3 l f (q + 3)
(where q number elements X3C instance) satisfy two conditions
assumption, let k l 4 satisfy ~sl (k) ~sl (k + 1) = ~sl (k + 1) ~sl (k + 2) =
~sl (k + 2) ~sl (k + 3) > 0, ~sl (k + 3) ~sl (k + 4) > 0. Let K1 = ~sl (k) ~sl (k + 1)
K2 = ~sl (k + 3) ~sl (k + 4). construct PW instance follows.
Alternatives: C = {c, w, d} V A, = {a1 , . . . , alq3 } auxiliary
alternatives.
First part (P1 ) profile: j t, choose arbitrary set Bj C\(Si {w, d})
36

fiDetermining Possible Necessary Winners Given Partial Orders

|Bj | = k 1. define partial order Oj follows.
Oj = O(Bj , w, Si , d, Others) \ [{w} (Sj {d})]
is, Oj partial order agrees Bj w Sj Others, except
pairwise relations (w, Sj ) (w, d) determined (and 4
undetermined relations). Let P1 = {O1 , . . . , Ot }.
Second part (P2 ) profile: first give properties need P2 satisfy;
show construct P2 polynomial time later proof. votes P2
linear orders. Let P1 = {O(Bj , w, Sj , d, Others) : j t}. is, P1 (|P1 | = t)
extension P1 (in fact, P1 set linear orders started obtain P1 ,
removing pairwise relations). P2 set linear orders
following holds Q = P1 P2 :
(1) every q, ~sl (Q, c) ~sl (Q, vi ) = 2K1 , ~sl (Q, w) ~sl (Q, c) =

q
3

(3K1 + K2 ) K2 .

(2) every q, scores vi w, c higher alternatives
extension P1 P2 .
(3) P2 size polynomial + q.
Suppose exists extension P1 P1 c winner P1 P2 .
q, vi ranked higher w P1 , otherwise total
score vi higher equal total score c. recall score
difference w c P1 P2 3q (3K1 + K2 ) K2 . Therefore, exists j
extension Oj , w ranked c, ranked alternative
Sj , must exist alternative V ranked w least two times
P1 , contradicts assumption c winner. follows order
total score w lower total score c, w ranked lower least
q

3 times. Let denote set subscripts votes P1 w ranked lower
d; then, SI = {Si : I} solution X3C instance.
Conversely, given solution X3C instance, let set indices Si
included X3C. Then, solution possible winner instance obtained
ranking ahead w exactly votes subscripts I. Therefore, c possible
winner exists solution X3C problem, means PW
PcW NP-complete respect positional scoring rules satisfy conditions
stated theorem.
possible co-winner, replace (1) following condition.
(1) every q, s(Q, c) s(Q, vi ) = K1 , s(Q, w) s(Q, c) = 3q (3K1 + K2 ).
Next, show construct profile P2 satisfies three conditions.
P2 consists following three parts.
first part, P2 . Let MV denote cyclic permutation among V {c, w}.
is, MV = c w v1 v2 . . . vq c. j N, e
V {c, w}, let MV0 (e) = e, MVj (e) = MV (MVj1 (e)). first part P2
P2 = MV (P1 ) MV2 (P1 ) . . . MVq+1 (P1 ). follows e, e V {c, w},
~sl (P1 P2 , e) = ~sl (P1 P2 , e ).
37

fiXia & Conitzer

second part, P2 . Choose arbitrary set B C\{d, w, c} |B| = k1,
arbitrary set C \ (B {d, w}) |A | = 3. define following
partial orders.
V1
V2
V3
V4

= O(B, d, w, c, Others),
= O(B, d, c, w, Others),
= O(B, d, , w, Others),
= O(B, , d, w, Others),

V1
V2
V3
V4

= O(B, c, w, d, Others)
= O(B, w, c, d, Others)
= O(B, w, , d, Others)
= O(B, , w, d, Others)

P2 defined follows.
P2 ={V1 , V2 , MV (V1 ), MV (V2 ), . . . , MVq+1 (V1 ), MVq+1 (V2 )}
q
{V3 , MV (V3 ), . . . , MVq+1 (V3 )} {V4 , MV (V4 ), . . . , MVq+1 (V4 )}
3
q
q
{V3 , MV (V3 ), . . . , MVq+1 (V3 )} represents copies {V3 , MV (V3 ), . . . , MVq+1 (V3 )}.
3
3
Putting P2 P2 together, condition (1) description P2 satisfied.
third part, P2 . P2 defined way P2 , total scores
pair alternatives V {c, w} same, total score alternative
V {c, w} significantly higher total score alternative {d}.
Let MO cyclic permutation among {d}. is, let MO = a1
a2 . . . alq3 d. Let V5 = O(V, c, w, Others). define third part P2
follows.
P2 = (|P1 P2 P2 | + 1) {MVi (MOj (V5 )) : q + 2, j l q 2}
note |P1 P2 P2 | + 1 polynomial + q. Therefore, size P2
polynomial + q.
2
Theorem 1 provides sufficient condition positional scoring rules PW PcW
NP-complete. applied prove NP-completeness PW PcW Borda,
following corollary shows.
Corollary 1 PW PcW NP-complete respect Borda, even number
undetermined pairs vote 4.
Proof. l N, scoring vector ~sl Borda (l 1, l 2, . . . , 0). let
f (x) = x, l = x, k = l 4, conditions Theorem 1 satisfied,
claim follows.
2
Theorem 1 apply k-approval. noted Table 1, possible
necessary winner problems respect plurality (1-approval) P. next show
fixed k N k 2, PW PcW respect k-approval NPcomplete.
Theorem 2 fixed natural number k 2, PW PcW NP-complete
respect k-approval, even number undetermined pairs vote
4.
38

fiDetermining Possible Necessary Winners Given Partial Orders

Proof. first prove NP-hardness PW respect 2-approval. Then, show
extend proof k N, k 2.
prove NP-hardness reduction 3-SAT. Given instance 3-SAT,
q variables x1 , . . . , xq formula F = C1 . . . Ct , construct
instance PW respect 2-approval follows. Without loss generality, assume
q + 2 (generally, fixed k N, assume q + k),
clause F , variable appears once.
Alternatives: C = {c} C X X1 X1 . . . Xq Xq D1 D1 . . . Dq Dq ,
C = {c1 , . . . , ct }, X = {x1 , . . . , xq , x1 , . . . , xq }, q,
Xi = {x1i , . . . , xti , x1i , . . . , xti }, Xi = {x1i , . . . , xti , x1i , . . . , xti };
Di = {d1i , . . . , dti }, Di = {d1i , . . . , dti }.
words, C represents set clauses F ; xi xi represent values
Boolean variable xi take; Xi (respectively, Xi ) represents set duplicates
xi (respectively, xi ); Di (respectively, Di ) represents set auxiliary alternatives
associated xi (respectively, xi ).
First part P1 profile: q, let Vi = O(c, xi , xi , Others).
Then, obtain Oi removing (xi , xi ) Vi . is, extension Oi ,
c must top position, one xi xi must second position
(and other, third). see later proof two extensions
Oi correspond two valuations variable xi , i.e., xi ranked
second position (while xi ranked third position) corresponds xi = f alse.
q, define following linear orders.
Vi1 = O(xi , d1i , x1i , x1i , Others)
2 j t, Vij = O(xij1 , dji , xji , xji , Others)
Then, obtain Oi1 Vi1 removing {xi , d1i } {x1i , x1i }; 2 j t,
obtain Oij Vij removing {xij1 , dji } {xji , xji }. define Vij, Oij,
similarly adding alternative explicitly written definition Vij
Oij , respectively (that is, alternatives Others). example,
Vi1, = O(xi , d1i , x1i , x1i , Others).
j t, let fj : X X1 X1 . . . Xq Xq mapping
x X, fj (x) obtained x adding j superscript
x. example, fj (x1 ) = xji fj (x2 ) = xj2 . j t, let Wj =
O(c, fj (lj1 ), fj (lj2 ), fj (lj3 ), Others). Then, obtain Qj Wj removing
{fj (lj1 ), fj (lj2 ), fj (lj3 )} {fj (lj1 ), fj (lj2 ), fj (lj3 )}
is, extension Qj , c must top position, one {fj (lj1 ), fj (lj2 ),
fj (lj3 )} must second position. see extensions Qj correspond Cj (the jth clause) satisfied valuation x1 , . . . , xq .
let P1 = {O1 , . . . , Oq } {Oij , Oij, : q, j t} {Qj : j t}.
39

fiXia & Conitzer

Second part P2 profile: profile P alternative c , let
s2 (P, c ) denote score c P , 2-approval. is, s2 (P, c ) number
times c ranked top two positions P . let P2 arbitrary
profile linear orders satisfies following conditions.
s2 (P2 , c) = 0.
every q every j t, s2 (P2 , xi ) = s2 (P2 , xi ) = s2 (P2 , xji ) =
s2 (P2 , xji ) = s2 (P2 , xji ) = s2 (P2 , xji ) = q + 2.
c mentioned above, s2 (P2 , c ) 1.
+ q 2, P2 well-defined |P2 | bounded polynomial q
(we try fit q + 2 copies {xi , xi , xji , xji , xji , xji : q, j t} top two
positions (q + 2)(2q + 4qt)/2 = q(q + 2)(2t + 1) votes). note number
undetermined pairs vote P1 P2 4.
Suppose feasible solution 3-SAT instance. Let g denote valuation
x1 , . . . , xq F satisfied. define extension P1 P2 follows.
every q, g(xi ) = true, define following extensions partial
orders P1 .
Let Vi extension Oi xi ranked second position.
Let Vi1 extension Oi1 xi d1i ranked top two
positions; let Vi1, extension Oi1, x1i x1i ranked
top two positions.
every 2 j t, let Vij extension Oij xij1 dji
ranked top two positions.
every 2 j t, let Vij, extension Oij, xji xji
ranked top two positions.
every q, g(xi ) = f alse, define following extensions (which
similar extensions case g(xi ) = true).
Let Vi extension Oi xi ranked second position.
Let Vi1, extension Oi1, xi d1i ranked top two
positions; let Vi1 extension Oi1 x1i x1i ranked top
two positions.
every 2 j t, let Vij, extension Oij, xij1 dji
ranked top two positions.
every 2 j t, let Vij extension Oij xji xji ranked
top two positions.
every j t, Cj satisfied xi = true (respectively, xi = f alse)
q, then, let Wj extension Qj xji (respectively, xji ) ranked
second position.
Let P = {V1 , . . . , Vq } {Vij , Vij, : q, j t} {W1 , . . . , Wt } P2 .
40

fiDetermining Possible Necessary Winners Given Partial Orders

checked P \ P2 , every alternative c (c 6= c) ranked two top
positions once. recall s2 (P2 , c ) q + 2 s2 (P , c) = q + t. Therefore,
c unique winner.
Next, show convert feasible solution PW feasible solution
3-SAT instance. Let P extension c unique winner. Let g
valuation q, g(xi ) = true extension Oi P ,
xi ranked second position. prove following claim show g,
clauses satisfied.
Claim 1 q, g(xi ) = true (respectively, g(xi ) = f alse), every j t,
xji xji (respectively, xji xji ) ranked top two positions extension
Oij, (respectively, Oij ) P .
Proof. q, prove claim induction j. prove case
g(xi ) = true; case g(xi ) = f alse proved similarly.
Suppose g(xi ) = true. definition, xi ranked second position extension Oi P . recall s2 (P2 , xi ) = q + 2 = s2 (P , c) 2. c
unique winner, xi ranked top two positions extension P1 \ {Oi }.
Specifically, xi ranked top two positions extension Oi1, . recall
xi d1i Oi1, . Therefore, d1i ranked top two positions
extension Oi1, (otherwise, xi would also ranked top two positions, immediately prevents c unique winner). also note xi , d1i , x1i , x1i
four alternatives ranked top two positions extension
Oi1, . follows extension Oi1, , x1i , x1i ranked top two positions.
means claim holds j = 1.
Suppose claim holds j j j . Following similar reasoning
case j = 1, prove claim holds j = j + 1. precisely,


induction hypothesis, xji ranked top two positions extension Oij , .


Therefore, xji ranked top two positions extension Oij +1, (otherwise

score xji least large score c, means c unique




winner). recall xji dji +1 Oij +1, . Therefore, dji +1 ranked


top two positions extension Oij +1, (otherwise xji must also ranked
top two positions, immediately prevents c unique winner). also




note xji , dji +1 , xji +1 , xji +1 four alternatives ranked


top two positions extension Oij +1, . follows extension Oij +1, ,


xji +1 xji +1 ranked top two positions. means claim holds
j = j + 1.
Therefore, claim holds every j t.
2
ready show g, clauses satisfied. Let j number
t. xji ranked second position extension Qj , must
g(xi ) = true. not, then, Claim 1, xji ranked top two positions
extension Oij , means xji ranked top two positions P \P2 least
twice: Oij , Qj . follows s2 (P , xji ) q+t2+2 q+t = s2 (P , c),
contradicts assumption c unique winner. Similarly, extension
41

fiXia & Conitzer

Qj , xji ranked second position, must g(xi ) = f alse. means
g, every clause Cj satisfied valuation variable corresponds
alternative ranked second position extension Qj . Hence, F
satisfied.
PcW, simply replace s2 (P2 , xi ) = s2 (P2 , xi ) = s2 (P2 , xji ) = s2 (P2 , xji ) =
s2 (P2 , xji ) = s2 (P2 , xji ) = q + 2 definition P2 s2 (P2 , xi ) = s2 (P2 , xi ) =
s2 (P2 , xji ) = s2 (P2 , xji ) = s2 (P2 , xji ) = s2 (P2 , xji ) = q + 1.
reduction k > 2 similar case k = 2. 3-SAT instance, let
P1 P2 profile partial orders defined case k = 2. k > 2, add
|P1 P2 | (k 2) new alternatives instance, partial order P1 P2 ,
let top k 2 positions occupied new alternatives, put remaining
new alternatives bottom positions, none new alternatives ranked
top k positions once. Let P1 P2 denote profiles partial orders
obtained way. follows c possible (co-)winner P1 P2 respect
k-approval c possible (co-)winner P1 P2 respect 2-approval.
2
Theorem 3 PW PcW NP-complete NW NcW coNP-complete
respect Copeland, even number undetermined pairs vote
8.
Proof. first prove PW NcW parts, one reduction X3C. Without loss
generality, always assume X3C instance, odd = q,
not, make following changes X3C instance.

2(t q) sets
> q, add 3(t q) dummy elements v1 , . . . , v3(tq)








S1 , S1 , . . . , Stq , Stq , q, Si = {v3i2 , v3i1 , v3i }.

q > t, add q copies S1 .
q = even, add three dummy elements v1 , v2 , v3 , three copies
S1 = {v1 , v2 , v3 }.
new X3C instance, = q, odd, size instance polynomial size
old one, new X3C instance feasible solution old one
has.
Given X3C instance V = {v1 , . . . , vq }, = {S1 , . . . , St }, q = odd,
construct PW instance follows.
Alternatives: {c, w, d} V B, = {a1 , . . . , at2 }, B = {b1 , . . . , b7t }.
First part P1 profile: Let cyclic permutation among B. is, =
b1 b2 . . . b7t b1 . Let VB = b1 b2 . . . b7t . t, obtain partial
order starting O((V \ Si ), d, Si , w, c, (VB ), A), removing ordering
relationships ({d} Si ) {w, c}.
Second part P2 profile:
2q
2q
+ 1 votes: + 1 2t
+ 1, vote
3
3

consistent w c V (VB ) A.



42

fiDetermining Possible Necessary Winners Given Partial Orders





2q
q
q
2 votes: 2t
+ 2 2t 1, vote
3
3
3
consistent w c V (VB ) A.
q
q
2 votes: 2t 2t 3, vote consistent
3
3
w c V (VB ) A.

2 votes: 2t 2 2t 1, vote consistent
c w V (VB ) A.
2 votes: 2t 2t + 1, vote consistent
c V w (VB ) A.




1
1
(5t 1) votes: 2t + 2 (9t + 1), vote
2
2
consistent w c (VB ) V d.
1
1
(5t 1) votes: (9t + 3) 7t, vote
2
2
consistent (VB ) V w c.

note number undetermined pairs vote 8.
Let P1 denote profile extends P1 vote Si ranked
higher w c, is, P1 = {O((V \ Si ), d, Si , w, c, B, A) : t}. make
following observations pairwise election:
w always defeats c, d, B, A, q, DP1 P2 (vi , w) = 3.
c always defeats V, B, always loses A, DP1 P2 (d, c) =

2q
1.
3

B always defeats d, V, A, due cyclic order profile, bj always defeats
bj+1 , . . . , bj+ 1 (7t1) , N, bi = bi+7t , always loses
2
alternatives B.
Therefore, P1 P2 , total number pairwise elections alternative is:
w wins |B| + |A| + 2 = 8t,
c wins |V| + |B| = q + 7t = 8t,
d, v V, wins 8t + q + 1 7t = + q + 1,
lose B,
b B wins 12 (|B| 1) + |A| + |V| + 1 = 12 (9t + 2q 3) pairwise elections.
recall X3C instance = q, means P1 P2 , winners
{w, c}. order c unique winner, possibility c win
q
pairwise election putting c least votes P1 . However,
3
put c ahead vote corresponding Si , v Si pairwise score difference
w v increases 2. Moreover, w v v V least twice
43

fiXia & Conitzer

extension P P1 , DP P2 (v, w) 1, means w defeats v pairwise
election. case, w would win 8m + 1 pairwise elections, means c cannot
unique winner. Therefore, c possible unique winner exists
q
extension P P1 c exactly votes P , corresponding Si
3
overlap, is, constitute exact cover V. means PW
solution X3C problem solution. PW NP-complete.
reduction, w would always co-winner c unique
winner, NcW coNP-complete. PcW NW, need slightly modify
reduction PW NcW: let |A| = 1 keep rest unchanged. Then, w
initially win 8t + 1 pairwise elections, c possible co-winner (w necessary
unique winner) exists feasible solution X3C instance.
2
Theorem 4 PW PcW NP-complete respect Bucklin, even number
undetermined pairs vote 16.
Proof.
First, give reduction X3C PW. Given X3C instance V =
{v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.
Alternatives: W V {c, w}, W = {w1 , . . . , wq+1 }, = {d1 , . . . , dq+1 }.
First part P1 profile: t, start O(w1 , . . . , wq+1 , Si , c, (V \
Si ), D), obtain partial order removing relations
{wq2 , wq1 , wq , wq+1 } (Si {c})
Second part P2 profile:
copies V c Others,
q
1 copies V w c Others,
3
q
+ 2 copies w1 Others.
3
note number undetermined pairs vote 16. Notice
2q
q
|P1 P2 | = 2t +
+ 1, w1 ranked within top q + 2 positions + + 2 votes
3
3
extension P1 P2 . Therefore, order c win, c wq2 must hold
q
least votes extension P1 . However, whenever put c ahead wq2 vote,
3
forcing alternatives Si corresponding vote ranked within top q
positions. v V ranked within top q positions least twice extension
q
P1 , overall ranked within top q positions least + + 1 votes,
3
means c unique winner.
exists feasible solution X3C problem, put c ahead wq2
votes corresponding solution, obtain extension P1 P1
q
c ranked within top q + 1 positions votes, v V, v ranked within
3
top q (and, fact, first q + 1) positions once. result, c unique winner
profile P1 P2 , alternative ranked within top q + 1 positions
44

fiDetermining Possible Necessary Winners Given Partial Orders

q
least + votes. Conversely, c unique winner profile P1 P2 ,
3
P1 corresponds feasible solution X3C problem. Therefore, PW respect
Bucklin NP-complete.
q
PcW, need modify reduction slightly, changing last + 1 votes
3
[D w1 Others] [d1 . . . dq w1 Others]. case, Bucklin score
w1 q + 1, means c best hope co-winner. result, PcW also
NP-complete.
2
prove hardness results maximin, ranked pairs, voting trees, present
two helpful lemmas. first show given pair alternatives c, c , exist two
linear orders increase D(c, c ) two keeping pairwise score differences
unchanged. lemma used previously (McGarvey, 1953; Conitzer & Sandholm,
2005a). use technique second (score-adjusting) part reductions
maximin, ranked pairs, voting trees.
Lemma 1 Given profile P pair different alternatives c, c , let remaining
alternatives {c1 , . . . , cm2 }. Let P profile consisting P plus following two
votes:
1. [c c c1 . . . cm2 ],
2. [cm2 . . . c1 c c ].
Then, DP (c, c ) = DP (c, c ) + 2, alternatives d, {d, } =
6 {c, c },
DP (d, ) = DP (d, ).
lemma tells us pairwise score differences changed almost arbitrarily.
constraint parity pairwise score differences remains same.
following lemma direct corollary.
Lemma 2 (The main theorem McGarvey, 1953) Given profile P skewsymmetric function F : C C Z (that is, F (c1 , c2 ) = F (c2 , c1 ) c1 , c2 ),
pairs alternatives c, c C, F (c, c ) DP (c, c ) even (or odd),
exists profile P
1. |P |

1P


(|F (c, c ) DP (c, c )| + 1),
2 c,c

2. DP P = F .
is, skew-symmetric function F pairs alternatives (c, c )
(with c 6= c ), F (c, c ) DP (c, c ) parity, change pairwise score
1P


differences DP F adding
(|F (c, c )DP (c, c )|+1) votes P .
2 c,c
Here, factor 12 comes fact pair alternatives c c , absolute
value difference F DP counted twice, i.e., |F (c, c ) DP (c, c )| =
|F (c , c) DP (c , c)|. fact, possible obtain even tighter bounds needed size
P (Erdos & Moser, 1964), purpose NP-hardness proofs
matter.
45

fiXia & Conitzer

ready prove hardness results maximin ranked pairs.
mentioned beginning section, hardness proofs section, profile
consists P1 P2 , P1 set partial orders used encode X3C instance,
P2 set linear orders used adjust scores alternatives. maximin,
ranked pairs, voting trees, P2 used adjust pairwise score differences.
explicitly give P2 reductions rules. Instead, present properties P2 ,
appeal Lemma 2 assert P2 exist, constructed polynomial
time.
Theorem 5 PW PcW NP-complete respect maximin, even number undetermined pairs vote 4.
Proof. first prove PW NP-complete. Given X3C instance V = {v1 , . . . , vq },
= {S1 , . . . , St }, construct PW instance follows.
Alternatives: V {c, w, w }.
First part P1 profile: t, start O(w, Si , c, (V \Si ), w ),
subsequently obtain partial order Oi removing relations {w} (Si {c}).
Second part P2 profile: according Lemma 2, P2 defined set
votes pairwise score differences {O(w, Si , c, (V \ Si ), w ) : t} P2
satisfy:
2q
2; q, D(w, vi ) = t+2; D(w , w) = D(v1 , w ) = t+4;
3
D(w , c) = 2.

(1) D(w, c) = t+

(2) pairwise scores defined (1), D(l, r) 1.
note number undetermined pairs vote 4.
Lemma 2 implies size P2 polynomial q + t.
note minimum pairwise score difference w D(w, w ) = 4;
minimum pairwise score difference w also 4 = D(w , v1 ).
Suppose exists profile P1 extending P1 c wins P1 P2 . c raised
q
higher w least one 1 votes P1 , then, D(c, w) t,
3
exists q D(vi , w) (the smallest pairwise score difference vi ),
means c unique winner vi performing least well. c ranked
q
higher w least + 1 votes P1 , still D(c, w ) = + 2,
3
exists q vi ranked higher w least two votes P1 , means
D(vi , w) + 2 (the smallest pairwise score difference vi ). follows
case, c unique winner vi performing least well. Therefore,
q
way c win decrease D(w, c) raising c higher w exactly votes
3
P1 . However, time decrease D(w, c) 2 due adding c w Oi P1 ,
v Si , D(w, v) also decreased two. D(w , c) = 2, decreasing D(w, c)
less 2 would raise minimum pairwise score difference c.
q, D(w, vi ) decreased 4 more, minimum pairwise score vj
46

fiDetermining Possible Necessary Winners Given Partial Orders

least + 2, means case c cannot unique winner. Therefore,
sets Si votes P1 c w cannot overlap. must least
q/3 votes, corresponding subsets Si constitute feasible solution X3C
instance.
Conversely, suppose X3C instance solution. Without loss generality, let
solution {S1 , . . . , Sq/3 }. define extension P1 P1 adding c w Oi
q/3, adding w Si > q/3. follows c unique winner
profile P1 P2 respect maximin rule. Therefore PW NP-complete.
PcW, need slightly modify reduction: replace condition
D(w, vi ) = + 2 D(w, vi ) = constructing P2 . Therefore PcW NP-complete. 2
Theorem 6 PW PcW NP-complete NW NcW coNP-complete
respect ranked pairs, even number undetermined pairs vote
8.
Proof. first prove NP-hardness PW NcW one reduction. Given X3C
instance V = {v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.
Alternatives: V {c, a, b, w}.
First part P1 profile: t, start O(a, c, Si , b, Others),
subsequently obtain partial order Oi removing relations ({a, c}(Si {b})).
Second part P2 profile: according Lemma 2, P2 defined set
votes pairwise score differences {O(a, c, Si , b, Others) : t} P2
satisfy:
1. q, D(c, b) = D(w, a) = D(w, vi ) = 3t +

2q
.
3

2q
2q
2q
, D(c, w) = +
2, D(vi , c) = +
6, D(b, a) = + 2.
3
3
3
3. D(l, r) = 0 cases.
2. D(a, c) = +

note number undetermined pairs vote 8.
Lemma 2 implies size P2 polynomial q + t.
note D(c, b), D(w, a), D(w, vi ) (for every q) much larger
remaining pairwise score differences extension P1 P2 . Therefore, c b, w a,
w vi (for every q) fixed first extension P1 P2 . follows
output (a linear order C) extension P1 P2 , must c b,
w a, w vi (for every q). note way c unique
2q
winner lock b c. is, D(b, a) must least + 2 + . However,
3
whenever let b extension Oi , forcing Si c. Let P1 extension
P1 c unique winner profile P1 P2 (or, equivalently,
w co-winner profile P1 P2 ). note exists q
2q
2q
6+4 = t+
2 = D(c, w),
vi c least two votes P1 , D(vi , c) +
3
3
means w co-winner (by locking vi c c w). Therefore, P1 ,
47

fiXia & Conitzer

q
must b exactly votes, q, vi c exactly one vote.
3
naturally corresponds solution X3C instance.
Conversely, suppose X3C instance solution. Without loss generality, let
solution {S1 , . . . , Sq/3 }. define extension P1 P1 adding b Oi
q/3, > q/3, letting extension Oi [a c Si b Others].
follows c unique winner profile (and hence, w co-winner).
Therefore, PW NP-complete NcW coNP-complete respect ranked pairs.
PcW NW, need slightly modify reduction letting
2q
D(b, a) = q, letting D(vi , c) = +
4.
2
3
Next, consider voting trees. voting tree defined fixed number
alternatives, study complexity possible/necessary winner problems
respect voting trees, need consider infinite sequence trees, one
natural number (representing number alternatives).8 Therefore, let voting tree
rule composed infinite sequence voting trees {T1 , T2 , . . .}, N,
Tm voting tree alternatives (that is, Tm binary tree leaf nodes,
leaf associated alternative).
N, voting tree Tm t-well-spread exist pairs leaves (c1 , a1 ), . . . ,
(ct , ), t, ci ai siblings. say leaf pair
rich leaf. voting tree balanced depths pair leaves differ
one, number leaves whose (unique) sibling leaf one.
Example 2 Two voting trees illustrated Figure 2. voting tree (a) 1-wellspread, c1 c2 rich leaves; voting tree (b) balanced 3-well-spread,
leaves except c5 rich leaves.

c4
c5

c3
c1

c2

c1

c2

c3

(a)

c4

c6

c7

(b)
Figure 2: Voting trees.

Theorem 7 voting tree rule = {T1 , T2 , . . .}, exists polynomial function
f (x) x N, exists l N x l f (x) Tl x-wellspread, PW PcW NP-complete, NW NcW coNP-complete
respect , even number undetermined pairs vote 16.
8. similar case positional scoring rules, technically defined specific
number alternatives.

48

fiDetermining Possible Necessary Winners Given Partial Orders

Proof. Let j2 , j3 , . . . index voting trees z N (z 2), Tjz
2(z + 1)-well-spread jz f (2(z + 1)). z, let c arbitrary rich leaf
Tj z .
first prove NP-hardness PW PcW single reduction. Given X3C
instance V = {v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.
Alternatives: Let C leaves Tjq , C = {c, d, w} V E,
= {a1 , . . . , aq }, E = {e1 , . . . , emq 2q3 }, mq number leaves Tjq .
Let tree {c, d}V rich leaves subtree whose root child
root Tjq (because Tjq 2(q + 1)-well-spread, always possible);
sibling c; common ancestor c w root; 1 q,
vi ai siblings. positions {c, d, w}V illustrated Figure 3. E
set alternatives Tjq . t, Si = {vl(i,1) , vl(i,2) , vl(i,3) },
let Ai = {al(i,1) , al(i,2) , al(i,3) }that is, Ai consists siblings elements
Si .

w

c



v1

a1

vq

aq

Figure 3: Positions alternatives Tjq .
First part P1 profile: t, start O(d, Ai , Si , c, Others),
subsequently obtain partial order Oi removing relations ({d} Ai )(Si {c}).
Second part P2 profile: according Lemma 2, P2 defined
set votes (linear orders) pairwise score differences profile
{O(d, Ai , Si , c, Others) : t} P2 satisfy:
(1) D(c, d) = 2q/3 + 1, D(c, w) = 2q + 1.
(2) q, D(ai , vi ) = 3, D(vi , c) = D(c, ai ) = 2q + 1.
(3) c C (with c 6= c), D(w, c ) = 2q + 1.
(4) pair i, q (with 6= ), D(vi , ai ) = 2q + 1.
(5) x C \ E, e E, D(x, e) = 2q + 1.
note number undetermined pairs vote 16.
Lemma 2 implies size P2 polynomial q + t.
49

fiXia & Conitzer

way c win beat first round, meet {v1 , . . . , vq }
later rounds, happen every vi beaten corresponding ai
first round. item (4), 6= , D(vi , ai ) = 2q + 1,
means q, vi wins first round, beaten w vj
j q subsequent rounds.In case winner must w. follows
extension P1 makes c win, c must ranked higher least q/3 times.
However, rank c higher extension Oi , extension
must Si Ai . order every ai defeat vi , every q, vi ranked
higher ai extension P1 . Therefore, exists profile P1
extending P1 c unique winner (or co-winner) P1 P2 , votes
P1 c make feasible solution X3C problem instance. Conversely,
feasible solution X3C problem instance, find P1 extending P1
c unique winner profile P1 P2 respect Tij . Therefore, PW PcW
NP-complete.
c unique winner, w always unique winner. Therefore,
NW NcW coNP-complete.
2
Theorem 7, immediately obtain following hardness results voting tree
rules composed balanced trees, setting f (x) = 4x (because exist integer
2x 2y 4x, balanced tree 2y alternatives least
x pairs siblings).
Corollary 2 PW PcW NP-complete NW NcW coNP-complete
respect voting tree rule composed balanced binary trees, even
number undetermined pairs vote 16.
Finally, following theorems complexity PW NcW respect
plurality runoff.
Theorem 8 PW NP-complete respect plurality runoff.
Proof. prove NP-hardness reduction X3C. Given X3C instance V =
{v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.
Alternatives: C = {c, d, e} SV E, SV = {s1 , . . . , st }
E = {e1 , . . . , e(q+4)2 (t+4)4 }.
First part P1 profile: P1 = P11 P12 , P11 P12 defined follows.
P11 : q, start linear order O(d, SV , c, Others), subsequently obtain partial order Oi removing ({d} SV ) {sj : vi Sj }.
is, remove minimum set constraints alternative
{sj : vi Sj } ranked top position least one extension Oi .
Let P11 = {Oi : q}.
P12 : j t, start linear order O(d, e, c, Others), subsequently obtain partial order Q1j removing ({d} {e}) (C {sj }). is,
extension Q1j , d, e, sj ranked top position.
let Q2j = Q1j , P12 = {Q1j : j t} {Q2j : j t}.
50

fiDetermining Possible Necessary Winners Given Partial Orders

Second part P2 profile: P2 = P21 P22 , P21 P22 defined
follows.
P21 : set q(t + 7/3) + 8 votes, c ranked top position q + 4
times, ranked top position q + 2 times, e ranked top position
q/3 + 2 times, j t, sj ranked top position q times.
matter remaining alternatives ranked P21 .
P22 : first obtain, according Lemma 2, profile P22 pairwise
score differences following profile:
{q copies O(d, SV , c, Others)} {2t copies O(d, e, c, Others)} P21 P22
satisfy following conditions.
1. D(d, c) = D(e, c) = 1;
2. j t, D(c, sj ) = 1.
Lemma 2, size P22 polynomial p + t. Next, obtain P22 P22
moving alternative E top position vote P22 ,
way vote P22 ranks different alternative top position. P22
well-defined, |E| |P22 |.
profile P , alternative c , let P luP (c ) denote plurality score c P ,
is, P luP (c ) number times c ranked top position P . subscript P omitted risk confusion. make following observations
profile {q copies O(d, SV , c, Others)} {2t copies O(d, e, c, Others)} P21 P22 :
D(d, c) = D(e, c) = 1, j t, D(c, sj ) = 1;
P lu(c) = q + 4, P lu(d) = 2t + 2q + 2, P lu(e) = q/3 + 2; j t, P lu(sj ) = q;
e E, P lu(e ) 1.
also note extension P1 P2 , P lu(c) = q + 4.
X3C instance solution Sj1 , . . . , Sjq/3 , construct solution
PW instance follows.
q, let Vi = [sjl (SV \ {sjl }) c Others], jl
ci Sjl ; note Vi extends Oi ;
l q/3, let Vj1l = Vj2l = [e c Others]; note Vj1l Vj2l extend
Q1jl Q2jl , respectively;
j (with j 6= jl l q/3), let Vj1 = Vj2 = [sj e c Others];
note Vj1 Vj2 extend Q1j Q2j , respectively;
then, use votes extend partial orders P1 : let P1 = {Vi :
q} {Vj1 , Vj2 : j t}.
51

fiXia & Conitzer

P1 P2 , P lu(c) = q + 4, P lu(d) = P lu(e) = q + 2; l q/3, P lu(sjl ) =
q + 3; j 6= jl (l = 1, . . . , q/3), P lu(sj ) = q + 2; e E, P lu(e ) 1.
Also, l q/3, D(c, sjl ) = 1. follows pairs enter
runoff (in parallel universe) (c, sj1 ), . . . , (c, sjq/3 ), c wins pairwise
elections. Therefore, c unique winner P1 P2 .
Next, show convert solution PW instance solution X3C
instance. Let P1 = P11 P12 extension P1 c unique winner
P1 P2 , P11 = {Vi : q} extends P11 , P12 = {Vj1 : j t} {Vj2 : j t}
extends P12 . make following sequence claims.
Claim 2 Neither e enter runoff, means pairs could
potentially still enter runoff (c, sj ), j t.
Proof. e entered runoff parallel universe, would defeat c
runoff (unless c even runoff, case c also win
parallel universe), contradicting c unique winner.
2
Claim 3 j t, P luP1 (sj ) 3.
Proof. hold, let j index maximizes P luP1 (sj ).
follows P luP12 (sj ) 1, P luP11 (sj ) 3. However, putting sj
top position partial order P12 , forcing D(c, sj ) reduced 2,
means sj defeats c pairwise election. Moreover, because, Claim 2, one
sj must enter runoff, sj maximum plurality score among
alternatives SV , sj must runoff one parallel universes. However, c
cannot win parallel universe, contradicts assumption c unique
winner.
2
Claim 4 P luP1 (d) = 0, P luP1 (e) 2q/3.
Proof. follows Claim 3 j t, P luP1 P2 (sj ) q + 3. Therefore,
Claim 2 must P luP1 P2 (d) q + 2 P luP1 P2 (e) q + 2. claim
follows.
2
Claim 5 j t, P luP12 (sj ) 1, P luP1 (sj ) 2.
Proof. P luP12 (sj ) 1 sj enters runoff parallel universe, c
cannot win parallel universe. sake contradiction, suppose P luP1 (sj ) 3.
Claim 3 Claim 2, sj enters runoff parallel universe, contradicts
assumption c unique winner.
2
Claim 6 Let X1 = {sj : P luP11 (sj ) > 0, P luP12 (sj ) = 0}, X2 = {sj : P luP11 (sj ) =
0, P luP12 (sj ) > 0}. X1 X2 = SV |X1 | = q/3.
52

fiDetermining Possible Necessary Winners Given Partial Orders

Proof. Let x1 = |X1 |, x2 = |X2 |, x3 = x1 x2 . Claim 5,
sj SV \ (X1 X2 ), P luP11 (sj ) = P luP12 (sj ) = 1. recall P11 ,
top-ranked alternative extension must either element SV ;
Q P12 , top-ranked alternative extension Q must d, e, element
SV . use observations obtain two inequalities.
First, order c unique winner, cannot top position vote
P11 . Therefore, q top positions P11 must taken alternatives SV .
Now, alternative X1 take three top positions; alternative
X2 takes none top positions definition; alternative SV \ (X1 X2 )
takes one top positions. follows 3x1 + x3 q.
Now, apply similar analysis P12 . order c unique winner, e
cannot top position 2q/3 votes P12 , leaving least 2t 2q/3
top positions filled. Now, alternative X1 takes none top positions;
alternative X2 take two top positions (Claim 5); alternative
SV \ (X1 X2 ) takes one top positions. follows 2x2 + x3 2t 2q/3.
substituting q second inequality q first inequality, obtain
2x1 + 2x2 + 53 x3 2t. recall x1 + x2 + x3 = t. Therefore, x3 = 0, x1 + x2 = t.
first inequality becomes x1 q/3 second inequality becomes x2 q/3.
follows x1 + x2 = x1 = q/3 x2 = q/3.
2
Based claims, construct solution X3C instance. Let
X1 = {sj1 , . . . , sjq/3 }. Claim 3, Claim 6, |P11 | = q, fact every top position
P11 must occupied one alternatives X1 , follows Sj1 , . . . , Sjq/3
solution X3C instance. Therefore, PW respect plurality runoff
NP-complete.
2
Theorem 9 NcW coNP-complete respect plurality runoff, even
number undetermined pairs vote 4.
Proof. prove coNP-hardness reduction X3C. Given X3C instance V =
{v1 , . . . , vq }, = {S1 , . . . , St }, construct NcW instance follows.
Alternatives: {c, d} V E, E = {e1 , . . . , et(q+2)3 }.
First part P1 profile: j t, start O(d, Sj , c, Others),
subsequently obtain partial order Oj removing orderings ({d} Sj ) {c}.
Second part P2 profile: P2 = P21 P22 , P21 P22 defined
follows.
P21 : set t(q + 1) + q/3 votes, c ranked top position + 1
times; ranked top position q/3 1 times; q, vi
ranked top position times.
P22 : first obtain, according Lemma 2, profile P22 pairwise
score differences {O(d, Sj , c, Others) : j t} P21 P22 satisfy following
conditions.
1. D(c, d) = 2t + 1;
53

fiXia & Conitzer

2. q, D(vi , c) = 3.
Lemma 2, size P22 polynomial + q. Next, obtain P22
P22 raising alternative E top position vote, way
vote P22 ranks different alternative top position.
recall profile P alternative c , P luP (c ) denotes number
times c ranked top position P . make following observations
{O(d, Sj , c, Others) : j t} P2 .
D(c, d) = 2t + 1, q, D(vi , c) = 3;
P lu(c) = + 1, P lu(d) = 1 + q/3; q, P lu(vi ) = t; e E,
P lu(e) 1.
follows observations extension P1 P2 , c must enter runoff;
also, extension, c defeats pairwise election. Let P1 P2 (where P1
extension P1 ) profile c co-winner. must
enter runoff, means P luP1 P2 (d) 1. follows c least q/3
votes P1 . However, ranking c partial order Oi , forcing c Si . Now,
pairs alternatives enter runoff (in parallel universes) (c, v1 ), . . . , (c, vq ).
Since c loses pairwise elections runoff (because, assumption, c
co-winner), must vj , c vj one vote P1 . Hence,
solution complement NcW instance naturally corresponds solution
X3C instance. Conversely, solution X3C instance corresponds solution
complement NcW instance. Therefore, NcW respect plurality runoff
coNP-complete.
2

5. Polynomial-time Algorithms Possible Necessary Winner
Problems
section present polynomial-time algorithms (1) NW NcW respect
positional scoring rules, maximin, Bucklin, (2) PcW NW respect
plurality runoff. recall PW NP-complete (Theorem 8) NcW coNPcomplete (Theorem 9), respect plurality runoff.
note positional scoring rules, maximin, Bucklin based type
scores, find extension partial orders linear orders
score c, denoted S(c), score another alternative w, c
(unique) winner profile, hence c necessary winner. Therefore,
following algorithms rules, check alternatives w 6= c, try make
S(c) S(w) low possible vote-by-vote basis (or equivalently, make S(w) S(c)
high possible). vote (partial order), two cases. first
case, c 6O w. case, need consider c w separately, raising w high
possible lowering c low possible. (This part algorithm already
considered Konczak & Lang, 2005.) following example, Example 3, illustrates
idea.

54

fiDetermining Possible Necessary Winners Given Partial Orders

Example 3 partial order illustrated Figure 4 (a). Let c = c2 w = c5 . Since
c2 6O c5 , raise c5 high possible lowering c2 low possible, shown
Figure 4 (b).
c5

c6

c2

c3

c1
c4

c1

c5

(a) partial order O.

c6

c2

c3

c4

(b) extension O.

Figure 4: partial order extension.
second case, c w. case complicated, follows
show minimize S(c) S(w) positional scoring rules, maximin, Bucklin.
plurality runoff, convert PcW maximum flow problem solve it; also
gives algorithm NW, simply checking whether alternative possible
co-winner (see Proposition 1).
section, input consists C = {c, c1 , . . . , cm1 }, c (the alternative
wish decide whether necessary (co-)winner), profile Pposet n partial
orders C, voting rule r.
first define notation used algorithms.
Definition 8 Given partial order alternative c, let UpO (c) = {c C : c c}
DownO (c) = {c C : c c }. Given another alternative w c w, let Os
c w block defined follows: BlockO (c, w) = {c C : c c w}.
is, UpO (c) set alternatives weakly preferred c (including c
itself), DownO (c) set alternatives c weakly preferred (including
c itself). c w, BlockO (c, w) set alternatives, including c w,
ranked c w. easy check partial order O,
pair alternatives c, w (with c w), BlockO (c, w) = DownO (c) UpO (w).
Example 4 Let partial order illustrated Figure 4 (a). UpO (c2 ) =
{c1 , c2 }, UpO (c4 ) = {c1 , c2 , c3 , c4 , c5 }, DownO (c2 ) = {c2 , c3 , c4 }, DownO (c4 ) = {c4 },
BlockO (c2 , c4 ) = {c2 , c3 , c4 }.
notion block useful following reason. algorithm, want
think extension partial orders w well possible, c
poorly possible. c w partial order O, cannot rank c
w; least makes sense alternatives possible.
alternatives block exactly ones need them; rank
alternatives outside block. Then, question position
block, slide block ranking.
ready present algorithms. note given partial order O,
computing UpO DownO sets takes polynomial time. Let ~sm denote scoring
vector positional scoring rule.
Algorithm 1 (Computing NW respect positional scoring rule)
55

fiXia & Conitzer

1. partial order Pposet alternative c, compute UpO (c)
DownO (c).
2. Repeat Steps 3ac w 6= c:
3a. Let S(w) = S(c) = 0.
3b. partial order Pposet ,
c 6O w, (following Example 3) lowest possible position c
+ 1 |DownO (c)|th position, highest possible position w
|UpO (w)|th position, add scores ~sm (|UpO (w)|) ~sm (m + 1
|DownO (c)|) S(w) S(c), respectively;
c w, highest slide Os c w block (as measured cs
position, top block) position |UpO (w) \ DownO (c)| + 1 (if
alternative ranked w partial order, place
c, unless partial order ranks c a), lowest (as measured ws
position, bottom block) position m|DownO (c)\UpO (w)|
(if alternative ranked c partial order, place
w, unless partial order ranks w). position
extremes also possible. find position minimizes score c
minus score w, add scores c w get positions
S(c) S(w), respectively.
3c. result S(w) S(c), output c necessary winner
(terminating algorithm).
4. Output c necessary winner (if reach point).
algorithm computing NcW obtained simply checking whether S(w) > S(c)
Step 4.
Proposition 3 Algorithm 1 checks whether c necessary winner Pposet
respect given positional scoring rule polynomial time.
Proof. equivalent check whether exists extension P Pposet
alternative w 6= c, s(P, w) s(P, c)that is, whether c necessary (unique)
winner. end, Pposet , maximize s(VO , w)s(VO , c) extensions
VO O.
recall m, ~sm (i) score alternative ranked
ith position. extension VO O, s(VO , w) ~sm (|UpO (w)|) (because w cannot
ranked higher |UpO (w)|th position) s(VO , c) ~sm (m + 1 |DownO (c)|)
(because c cannot ranked lower (m + 1 |DownO (c)|)th position).
two bounds achieved c 6O w: every C \ UpO (w), add w
O; every C \ DownO (c), add c O. obtain partial order
way, let VO (arbitrary) linear order extends . follows
s(VO , w) s(VO , c) = ~sm (|UpO (w)|) ~sm (m + 1 |DownO (c)|).
However, c w, may exist VO s(VO , w) = ~sm (|UpO (w)|)
s(VO , c) = ~sm (m + 1 |DownO (c)|) hold simultaneously. note VO
56

fiDetermining Possible Necessary Winners Given Partial Orders

maximizes s(VO , w) s(VO , c), alternatives c w must
BlockO (c, w). Therefore, C w c 6O d, must
VO c; C c 6O w, must w VO d.
follows s(VO , w) s(VO , c) maxl (~sm (l + |BlockO (c, w)| 1) ~sm (l)), l ranges
|UpO (w) \ DownO (c)| + 1 |DownO (c) \ UpO (w)|. Let VO extension
restricted C \ BlockO (c, w) UpO (w) \ DownO (c) ranked top
DownO (c) \ UpO (w) ranked bottom. C \ (UpO (w) DownO (c))
BlockO (c, w), must 6O 6O d. Therefore,
|UpO (w) \ DownO (c)| + 1 l |DownO (c) \ UpO (w)|, put BlockO (c, w)
(l 1)th position lth position VO , obtain linear order extends O.
proves correctness Step 3b, computes maxVO (s(VO , w) s(VO , c)).
follows algorithm correctly checks whether c necessary winner.
2
move maximin rule. note c necessary winner Pposet
respect maximin exists profile linear orders P extending
Pposet , two alternatives w w , alternatives d, NP (w, d) NP (c, w ).
recall NP (w, d) number votes P w d. Therefore, algorithm
considers pairs (w, w ), checks whether exists extension input
partial orders inequality holds alternatives d. perform check,
partial order, would like rank w ahead c, also rank w high
possible. However, two objectives may conflict: may case rank
c ahead w , rank w higher case rank w ahead c.
case, first place w ahead c, rank w high possible
additional constraint. works following reason. Let Pposet partial
order c 6O w w 6O c; let V arbitrary extension w V c
let V arbitrary extension c V w . C,
N{V } (w, d) N{V } (c, w ) 0 N{V } (w, d) N{V } (c, w ), means enforcing
w c always least good enforcing c w .
Algorithm 2 (Computing NW respect maximin)
1. partial order Pposet alternative c, compute UpO (c).
2. Repeat 3ac pairs w, w , c 6= w c 6= w .
3a. Let S(c, w ) = 0, alternative 6= w, let S(w, d) = 0.
3b. partial order Pposet ,
c 6O w , add w c raise w high possible;
6= w, if, resulting vote, w ahead (that is, 6 UpO (w)
c UpO (w), 6 UpO (w )), add 1 S(w, d).
c w , raise w high possible; add 1 S(c, w ); 6= w,
if, resulting vote, w ahead (that is, 6 UpO (w)), add 1
S(w, d).
3c. Check 6= w, S(w, d) S(c, w ); answer yes, output
c necessary winner (terminating algorithm).
4. Output c necessary winner.
57

fiXia & Conitzer

algorithm computing NcW respect maximin similar: modification
Step 3, check alternatives 6= w, S(w, d) > S(c, w ).
Proposition 4 Algorithm 2 checks whether c necessary winner Pposet
respect maximin polynomial time.
Proof. function S(x, y) computed algorithm number times x preferred
extension Pposet . partial order O, let VO extension computed
Step 3b. Let g(V, d) = NV (w, d) NV (c, w ). next prove 6= w
extension VO O, g(VO , d) g(VO , d). c 6O w c VO w , g(VO , d)
0 g(VO , d) (because NVO (c, w ) = 0 NVO (c, w ) = 1). c 6O w w VO c,
NVO (c, w ) = NVO (c, w ). note VO obtained raising w high possible
w c, means NVO (w, d) NVO (w, d). follows g(VO , d) g(VO , d).
Similarly, c w , also 6= w, NVO (w, d) NVO (w, d).
Therefore,Pfor extension P Pposet 6= w, S(w, d) S(c, w ) = NP (w, d)
NP (c, w ) OPposet g(VO , d), P profile computed Step 3b, inequality becomes equality. follows algorithm correct.
2
move Bucklin rule. note c necessary winner
Pposet respect Bucklin, exists extension P Pposet
alternative w, either ws Bucklin score 1, exists 2 k m,
w among top k n2 votes (meaning ws Bucklin score
k), c among top k 1 n2 votes (meaning cs Bucklin score
less k). Therefore, like Algorithm 1, algorithm Bucklin considers
alternative w, computes possible positions blocks BlockO (c, w), checks
k 1 whether condition made hold.
algorithm, c 6Oj w, High(j) highest position w reaches
extension Oj , Low(j) lowest position c reaches extension Oj .
c Oj w, High(j) highest position c given c w ranked close
possible, Low(j) lowest position c given c w ranked
close possible, Length(j) size BlockOj (c, w).
{c, w}, let S(i, d) denote minimum number times ranked
top positions, minimum taken optimal extensions Pposet (we
elaborate meaning optimality later). U (k) number partial orders
compute put block BlockOj (c, w) make c
necessary unique winner. is, U (k) number partial orders
exists extension c top k 1 positions w top k positions,
well another extension c top k 1 positions w
top k positions.
Algorithm 3 (Computing NW respect Bucklin)
1. partial order Pposet alternative c, compute UpO (c)
DownO (c).
2. Repeat Steps 3ad w 6= c:
3a. j n, let High(j) = Low(j) = Length(j) = 0. m, let
S(i, c) = S(i, w) = U (i) = 0.
58

fiDetermining Possible Necessary Winners Given Partial Orders

3b. partial order Oj Pposet ,
c 6Oj w, let Length(j) = 0, let High(j) = |UpOj (w)|, Low(j) =
+ 1 |DownOj (c)|;
c Oj w, let Length(j) = |BlockOj (c, w)|, High(j) = |UpOj (w) \
DownOj (c)| + 1, Low(j) = + 1 |DownOj (c)|.
3c. k m, j n,
Length(j) = 0, add 1 S(k, w) High(j) k, add 1 S(k 1, c)
Low(j) k 1;
Length(j) > 0, add 1 S(k, w) either Low(j) + Length(j) 1 k,
following two conditions hold: Low(j) k1 High(j)+Length(j)
1 k. Also, add 1 S(k1, c) Low(j) k1; add 1 U (k) Low(j) > k1
High(j) + Length(j) 1 k.
3d. S(1, w) + U (1) > n2 , exists 2 k S(k, w) > S(k 1, c),
S(k 1, c) n2 , S(k, w) + U (k) > n2 , output c necessary
winner (terminating algorithm).
4. Output c necessary winner.
algorithm computing NcW obtained making following changes Steps 3c
3d follows.
3c . k m, j n,
Length(j) = 0, add 1 S(k, w) High(j) k, add 1 S(k, c)
Low(j) k;
Length(j) > 0, add 1 S(k, w) either Low(j) + Length(j) 1 k,
following two conditions hold: Low(j) k High(j) + Length(j) 1
k. Also, add 1 S(k, c) Low(j) k; add 1 U (k) Low(j) k + 1
High(j) + Length(j) 1 k.
3d . exists 0 l U (1) S(1, w) + l > n2 S(1, c) + l, exists
2 k l U (k) S(k, w) + l > n2 S(k, c) + l, output c
necessary co-winner (terminating algorithm).
Proposition 5 Algorithm 3 checks whether c necessary winner Pposet
respect Bucklin polynomial time.
Proof. Similarly case positional scoring rules, Bucklin, c 6O w,
simply rank c low possible rank w high possible, independently.
hand, c w, without loss generality place alternatives
c w possible, question place c w block.
algorithm consider particular k, try make w among top k
half votes, c among top k 1 half votes.
particular vote c w, depending block placed, either (1) c among
top k 1 w among top k; or, (2) c among top k 1 w among
top k; or, (3) c among top k 1 w among top k. However,
59

fiXia & Conitzer

three possibilities may exist particular vote. algorithm never
choose (2) unless option, difficult case decision
must made (1) (3).
recall {c, w}, S(i, d) minimum number
times ranked within top positions, minimum taken extensions
Pposet consistent observations previous paragraph (specifically,
option (2) never chosen unless choice). U (k) number partial
orders exists extension c ranked within top k 1 positions
w ranked within top k positions, well extension c ranked
within top k 1 positions w ranked within top k positions (that is,
choice (1) (3)).
k m, j n, consider extend Oj .
c 6Oj w, positions c w already determined previous
observations (w ranked high possible c ranked low possible).
c Oj w High(j) k, c cannot ranked within top k 1 positions
w cannot ranked within top k positions; therefore, add 0 S(k 1, c)
S(k, w).
c Oj w, High(j) < k High(j) + Length(j) 1 > k, c ranked within
top k 1 positions, w cannot ranked within top k positions. two
sub-cases: (1) Low(j) k, rank c Low(j)th position, henceforth
add 0 S(k 1, c) S(k, w); (2) Low(j) < k, c inevitably ranked
within top k 1 positions, w cannot ranked within top k positions,
means add 1 S(k 1, c) 0 S(k, w).
final case c Oj w, High(j) < k High(j) + Length(j) 1 k. Again,
two subcases: (1) Low(j) < k, means c must ranked within
top k 1 positions. Therefore rank w top k positions, add 1
S(k 1, c) S(k, w); (2) Low(j) k, means three options
extension Oj , corresponding cases (1), (2), (3) discussed beginning
proof.
(1) cs position within top k 1 ws position within top k.
(2) cs position within top k 1 ws position within top k (which implies
Length(i) > 2).
(3) cs position within top k 1 ws position within top k.
already discussed, option (2) suboptimal. Therefore, add 0
S(k 1, c) S(k, w), add 1 U (k).
remaining decision many votes corresponding number
U (k) choose option (1) (as opposed option (3)). corresponds Step 3d
algorithm, checks whether exists way choosing number extensions
(but U (k)) choose (1) way c winner.
Therefore, algorithm correct.
2
60

fiDetermining Possible Necessary Winners Given Partial Orders

Finally, consider possible co-winner problem respect plurality runoff.
show problem solved polynomial time. this, also follows
necessary (unique) winner problem solved polynomial time (Proposition 1). contrast, already shown plurality runoff, possible
unique winner problem NP-complete (Theorem 8) necessary co-winner problem
coNP-complete (Theorem 9).
algorithm determining whether c possible co-winner based following
key observation: c possible co-winner Pposet respect plurality runoff
exists extension Pposet , denoted P , alternative 6= c,
two natural numbers l1 , l2 , (1) c preferred least half votes (linear
orders) P , (2) P luP (c) = l1 , P luP (d) = l2 , alternative c (c 6= c
c 6= d), P luP (c ) min{l1 , l2 }. is, c enter runoff (there could
pairs alternatives enter runoff parallel universe) c defeat
runoff.
1, let denote number partial orders Pposet
ci c. recall op(O) denote set alternatives c exists
least one extension c top position. Based observations
previous paragraph, consider possibilities l1 , l2 , (we use
denote possibilities index d), solve maximum flow problem instance
possibility.9 Specifically, every l1 , l2 n every 1 (with n/2),
define maximum flow problem Fl1 ,l2 ,i follows (illustrated Figure 5, = 1).
c

1

O1
1

1

c1

n/2 1

l1

c1
l2

1

c2
..
.



lmin

1

..
.

1

cm1





1



n l1 l2

lmin

Figure 5: maximum flow problem Fl1 ,l2 ,1 .
Vertices: s, O1 , . . . , , ci , c, c1 , . . . , cm1 , , t.
Edges: following five types edges.
Edges {O1 , . . . , }: every n, edge (s, Oi )
capacity 1.
9. original proof used minimum cost flow problem, one anonymous reviewers pointed
modify approach simpler maximum flow approach presented here, well two
papers (Gusfield & Martel, 2002; Russell & Walsh, 2009) maximum flow problems used
solve election problems, thank reviewer.

61

fiXia & Conitzer

Edges {O1 , . . . , } {ci , c, c1 , . . . , cm1 }:
every j n every C 6= ci , op(Oj ),
edge (Oj , d) capacity 1;
every j n, ci op(O) ci Oj c, edge (Oj , ci )
capacity 1;
j n, edge (Oj , ci ) capacity 1 ci op(O)
ci 6Oj c.
Edge ci ci : edge (ci , ci ) capacity n/2 .
Edges C \ {c, ci } : every c C \ {c, ci }, edge (c , )
capacity lmin = min{l1 , l2 }.
Edges {c, ci , } t:
edge (c, t) capacity l1 ;
edge (ci , t) capacity l2 ;
edge (t , t) capacity n l1 l2 .
Next, prove c possible co-winner Pposet respect plurality runoff
exist l1 , l2 n 1 Fl1 ,l2 ,i solution
value flow n.
parameters Fl1 ,l2 ,i integers, exists solution Fl1 ,l2 ,i ,
must also exists integer solution. First, show convert integer solution
Fl1 ,l2 ,i solution PcW problem respect plurality runoff. Let f
integer solution Fl1 ,l2 ,i , is, f : Vertices Vertices Z. construct
extension P = (V1 , . . . , Vn ) Pposet follows:
j n, f (Oj , ci ) = 1 let Vj extension Oj ci
ranked top position;
j n C \ {ci }, f (Oj , d) = 1 let Oj extension
Oj ranked top position, c ranked high possible.
value f n, plurality score c l1 plurality score ci
l2 , plurality score ci (i 6= ) lmin . Therefore, c ci enter
runoff together one parallel universe. Now, capacity constraint edge (ci , ci )
ensures c win runoff: reason rank ci first vote
could ranked c ahead ci , contribute 1 flow edge.
Moreover, capacity edge (ci , ci ) n/2 , means ci c
+ (n/2 ) n/2 votes P . Hence, c co-winner P .
Conversely, exists extension P P c co-winner P ,
exists ci parallel universe, {c, ci } enter runoff, c wins
runoff. Let l1 , l2 plurality scores c, ci , respectively. Then, extension
converted solution Fl1 ,l2 ,i (we omit details similar
details direction).
Therefore, following algorithm solves PcW respect plurality runoff.
Algorithm 4 (Computing PcW respect plurality runoff )
62

fiDetermining Possible Necessary Winners Given Partial Orders

1. Pposet , compute op(O) UpO (c). 1, let = |{O
Pposet : ci UpO (c)}|.
2. Repeat Steps 3ab 1 l1 , l2 n:
3a. Construct maximum flow problem Fl1 ,l2 ,i .
3b. Solve Fl1 ,l2 ,i FordFulkerson algorithm (Cormen, Leiserson, Rivest, &
Stein, 2001). maximum flow n, output c possible cowinner. Terminate algorithm.
4. Output c possible co-winner.
Proposition 6 Algorithm 4 checks whether c possible co-winner Pposet
respect plurality runoff polynomial time.
recall proof Proposition 1 c necessary unique winner
alternative possible co-winner. Therefore, naturally obtain algorithm
NW, simply using Algorithm 4 check alternative c possible
co-winner.
Proposition 7 Algorithm 4 used check whether c necessary unique
winner Pposet respect plurality runoff polynomial time.

6. Conclusion Future Work
considered following problem: given set alternatives, voting rule,
set partial orders, alternatives possible/necessary winners? is,
alternatives would win some/all extension partial orders? considered case
votes weighted number alternatives bounded. Table 1
introduction summarizes results. results hold whether alternative
must unique winner, merely co-winner, unless specifically mentioned.
paper, restriction partial orders. However, reason
partial orders preferences submitted CP-nets, introduces
additional structure partial orders; is, partial orders correspond
CP-net. Hence, positive results would still apply, immediately obvious
negative results would still apply.
Another approach approximate sets possible/necessary winners. precisely, asked output superset (respectively, subset) possible (respectively,
necessary) winners size output set within fixed ratio
number possible (respectively, necessary) winners. Pini et al. (2007) proved
inapproximability set possible/necessary winners single transferable vote
rule (STV) rule. conjecture similar inapproximability results hold
common voting rules studied paper (for possible/necessary winner
problems (co-)NP-complete).
63

fiXia & Conitzer

Acknowledgments
thank Nadja Betzler, Jerome Lang, Toby Walsh, anonymous reviewers AAAI-08
JAIR, participants Dagstuhl Seminar 07431: Computational Issues
Social Choice helpful discussions comments. Lirong Xia supported James
B. Duke Fellowship Vincent Conitzer supported Alfred P. Sloan Research Fellowship. work supported NSF award numbers IIS-0812113 CAREER
0953756.

References
Bachrach, Y., Betzler, N., & Faliszewski, P. (2010). Probabilistic possible winner determination. Proceedings National Conference Artificial Intelligence (AAAI),
pp. 697702, Atlanta, GA, USA.
Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social
Choice Welfare, 8 (4), 341354.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989a). computational difficulty manipulating election. Social Choice Welfare, 6 (3), 227241.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989b). Voting schemes
difficult tell election. Social Choice Welfare, 6, 157165.
Baumeister, D., & Rothe, J. (2010). Taking final step full dichotomy possible
winner problem pure scoring rules. Proceedings 19th European Conference
Artificial Intelligence (ECAI), pp. 10191020, Lisbon, Portugal.
Betzler, N., & Dorn, B. (2010). Towards dichotomy possible winner problem
elections based scoring rules. Journal Computer System Sciences, 76 (8),
812836.
Betzler, N., Hemmann, S., & Niedermeier, R. (2009). multivariate complexity analysis
determining possible winners given incomplete votes. Proceedings TwentyFirst International Joint Conference Artificial Intelligence (IJCAI), pp. 5358,
Pasadena, CA, USA.
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: tool
representing reasoning conditional ceteris paribus statements. Journal
Artificial Intelligence Research, 21, 135191.
Chevaleyre, Y., Lang, J., Maudet, N., & Monnot, J. (2010). Possible winners new candidates added: case scoring rules. Proceedings National Conference
Artificial Intelligence (AAAI), Atlanta, GA, USA.
Chevaleyre, Y., Lang, J., Maudet, N., Monnot, J., & Xia, L. (2010). New candidates
welcome! Possible winners respect addition new candidates. Technical
report, Cahiers du LAMSADE 302, Universite Paris-Dauphine.
Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. Journal
Artificial Intelligence Research, 35, 161191.
64

fiDetermining Possible Necessary Winners Given Partial Orders

Conitzer, V., Rognlie, M., & Xia, L. (2009). Preference functions score rankings
maximum likelihood estimation. Proceedings Twenty-First International
Joint Conference Artificial Intelligence (IJCAI), pp. 109115, Pasadena, CA, USA.
Conitzer, V., & Sandholm, T. (2002). Vote elicitation: Complexity strategy-proofness.
Proceedings National Conference Artificial Intelligence (AAAI), pp. 392
397, Edmonton, AB, Canada.
Conitzer, V., & Sandholm, T. (2005a). Common voting rules maximum likelihood estimators. Proceedings 21st Annual Conference Uncertainty Artificial
Intelligence (UAI), pp. 145152, Edinburgh, UK.
Conitzer, V., & Sandholm, T. (2005b). Communication complexity common voting rules.
Proceedings ACM Conference Electronic Commerce (EC), pp. 7887,
Vancouver, BC, Canada.
Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidates
hard manipulate?. Journal ACM, 54 (3), 133.
Cormen, T., Leiserson, C., Rivest, R., & Stein, C. (2001). Introduction Algorithms
(Second edition). MIT Press.
Elkind, E., Faliszewski, P., & Slinko, A. (2009). Swap bribery. Proceedings 2nd
International Symposium Algorithmic Game Theory.
Elkind, E., & Lipmaa, H. (2005). Hybrid voting protocols hardness manipulation.
Annual International Symposium Algorithms Computation (ISAAC), 3827
Lecture Notes Computer Science, pp. 206215, Sanya, Hainan, China.
Erdelyi, G., Fernau, H., Goldsmith, J., Mattei, N., Raible, D., & Rothe, J. (2009). complexity probabilistic lobbying. 1st International Conference Algorithmic
Decision Theory, pp. 8697, Venice, Italy.
Erdos, P., & Moser, L. (1964). representation directed graphs unions
orderings. Math. Inst. Hung. Acad. Sci., 9, 125132.
Faliszewski, P. (2008). Nonuniform bribery. Proceedings Seventh International
Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp.
15691572, Estoril, Portugal.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: ties matter.
Proceedings Seventh International Joint Conference Autonomous Agents
Multi-Agent Systems (AAMAS), pp. 983990, Estoril, Portugal.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2010). Manipulation copeland elections. Proceedings Nineth International Joint Conference Autonomous
Agents Multi-Agent Systems (AAMAS), pp. 367374, Toronto, Canada.
Garey, M., & Johnson, D. (1979). Computers Intractability. W. H. Freeman
Company.
Gibbard, A. (1973). Manipulation voting schemes: general result. Econometrica, 41,
587602.
Gusfield, D., & Martel, C. (2002). structure complexity sports elimination
numbers. Algorithmica, 32, 7386.
65

fiXia & Conitzer

Hazon, N., Aumann, Y., Kraus, S., & Wooldridge, M. (2008). Evaluation election outcomes uncertainty. Proceedings Seventh International Joint Conference
Autonomous Agents Multi-Agent Systems (AAMAS), pp. 959966, Estoril,
Portugal.
Hemaspaandra, E., & Hemaspaandra, L. A. (2007). Dichotomy voting systems. Journal
Computer System Sciences, 73 (1), 7383.
Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (1997). Exact analysis Dodgson
elections: Lewis Carrolls 1876 voting system complete parallel access NP.
Journal ACM, 44 (6), 806825.
Konczak, K., & Lang, J. (2005). Voting procedures incomplete preferences. Multidisciplinary Workshop Advances Preference Handling.
Lang, J. (2007). Vote aggregation combinatorial domains structured preferences. Proceedings Twentieth International Joint Conference Artificial
Intelligence (IJCAI), pp. 13661371, Hyderabad, India.
Lang, J., Pini, M. S., Rossi, F., Venable, K. B., & Walsh, T. (2007). Winner determination
sequential majority voting. Proceedings Twentieth International Joint
Conference Artificial Intelligence (IJCAI), pp. 13721377, Hyderabad, India.
Lang, J., & Xia, L. (2009). Sequential composition voting rules multi-issue domains.
Mathematical Social Sciences, 57 (3), 304324.
McGarvey, D. C. (1953). theorem construction voting paradoxes. Econometrica,
21 (4), 608610.
Parkes, D. (2006). Iterative combinatorial auctions. Cramton, P., Shoham, Y., & Steinberg, R. (Eds.), Combinatorial Auctions, chap. 2, pp. 4177. MIT Press.
Pini, M. S., Rossi, F., Venable, K. B., & Walsh, T. (2007). Incompleteness incomparability preference aggregation. Proceedings Twentieth International Joint
Conference Artificial Intelligence (IJCAI), pp. 14641469, Hyderabad, India.
Rothe, J., Spakowski, H., & Vogel, J. (2003). Exact complexity winner problem
Young elections. Theory Computing Systems, Vol. 36(4), pp. 375386. SpringerVerlag.
Russell, T., & Walsh, T. (2009). Manipulating tournaments cup round robin competitions. Proceedings First International Conference Algorithmic Decision
Theory (ADT), Lecture Notes Artificial Intelligence 5783, pp. 2637.
Sandholm, T., & Boutilier, C. (2006). Preference elicitation combinatorial auctions.
Cramton, P., Shoham, Y., & Steinberg, R. (Eds.), Combinatorial Auctions, chap. 10,
pp. 233263. MIT Press.
Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondence theorems voting procedures social welfare functions. Journal
Economic Theory, 10, 187217.
Walsh, T. (2007). Uncertainty preference elicitation aggregation. Proceedings
National Conference Artificial Intelligence (AAAI), pp. 38, Vancouver, BC,
Canada.
66

fiDetermining Possible Necessary Winners Given Partial Orders

Xia, L., Lang, J., & Monnot, J. (2011). Possible winners new alternatives join:
New results coming up!. apprea Proceedings Tenth International Joint
Conference Autonomous Agents Multi-Agent Systems (AAMAS).
Xia, L., & Conitzer, V. (2008). Determining possible necessary winners common voting rules given partial orders. Proceedings National Conference
Artificial Intelligence (AAAI), pp. 196201, Chicago, IL, USA.
Xia, L., Conitzer, V., & Procaccia, A. D. (2010). scheduling approach coalitional
manipulation. Proceedings ACM Conference Electronic Commerce (EC),
pp. 275284, Boston, MA, USA.
Xia, L., Lang, J., & Ying, M. (2007a). Sequential voting rules multiple elections paradoxes. Proceedings Eleventh Conference Theoretical Aspects Rationality
Knowledge (TARK), pp. 279288, Brussels, Belgium.
Xia, L., Lang, J., & Ying, M. (2007b). Strongly decomposable voting rules multiattribute
domains. Proceedings National Conference Artificial Intelligence (AAAI),
pp. 776781, Vancouver, BC, Canada.
Xia, L., Zuckerman, M., Procaccia, A. D., Conitzer, V., & Rosenschein, J. (2009). Complexity unweighted coalitional manipulation common voting rules.
Proceedings Twenty-First International Joint Conference Artificial Intelligence (IJCAI), pp. 348353, Pasadena, CA, USA.
Zuckerman, M., Procaccia, A. D., & Rosenschein, J. S. (2009). Algorithms coalitional
manipulation problem. Artificial Intelligence, 173 (2), 392412.

67

fi
