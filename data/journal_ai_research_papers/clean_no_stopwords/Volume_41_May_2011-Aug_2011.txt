Journal Artificial Intelligence Research 41 (2011) 445475Submitted 02/11; published 08/11Intertranslatability Argumentation SemanticsWolfgang DvorakStefan Woltrandvorak@dbai.tuwien.ac.atwoltran@dbai.tuwien.ac.atTechnische Universitat Wien,Institute Information Systems 184/2Favoritenstrasse 9-11, 1040 Vienna, AustriaAbstractTranslations different nonmonotonic formalisms always important topic field, particular understand knowledge-representation capabilitiesformalisms offer. provide investigation terms different semanticsproposed abstract argumentation frameworks, nonmonotonic yet simple formalismreceived increasing interest within last decade. Although propertiesdifferent semantics nowadays well understood, explicit results intertranslatability. provide translations wrt. different properties also givenovel complexity results underlie negative results.1. IntroductionStudies intertranslatability different approaches nonmonotonic reasoningalways considered important contribution field order understandexpressibility representation capacity various formalisms. intertranslatabilityunderstand function Tr maps theories one formalism anotherintended models theory source formalism certain relationintended models Tr (). Several desired properties translation functionsidentified, including polynomial (Tr () computed polynomial timewrt. size ) modular (roughly speaking, allows transform partstheory independently other). particular, relationship (variants of)default logic (Reiter, 1980) nonmonotonic modal logics, e.g. autoepistemic logic (Moore,1985), always received lot attention, (see, e.g., Denecker, Marek, & Truszczynski,2003; Konolige, 1988; Marek & Truszczynski, 1993). Perhaps notably, Gottlob (1995)showed modular translation default logic autoepistemic logic impossible.important contributions direction include translations default logiccircumscription (Imielinski, 1987), modal nonmonotonic logics logic programs (see,e.g., de Bruijn, Eiter, & Tompits, 2008 overview recent applications) workJanhunen (1999). Let us also refer recent work Pearce Uridia (2011),show translations aforementioned kind already known contextnon-classical logics related results date back work Godel.work, study translation functions within particular formalism nonmonotonic reasoning wrt. different semantics proposed formalism. areadefault logic, similar research undertaken, instance Liberatore (2007) Delgrande Schaub (2005). Likewise, work concerning relationship differentlogic programming semantics refer work Janhunen, Niemela, Seipel, Simons,c2011AI Access Foundation. rights reserved.fiDvorak & Woltran(2006) references therein. formalism focus paperDungs argumentation frameworks (Dung, 1995) received increasing interest withinlast decade. nutshell, argumentation frameworks (AFs, short) representabstract statements1 together relation denoting attacks them. Differentsemantics provide different ways solve inherent conflicts statements selecting acceptable subsets usually called extensions them. Several semanticsalready proposed Dung seminal paper (Dung, 1995), also alternativeapproaches play major role nowadays (see, e.g., Baroni, Dunne, & Giacomin, 2011; Baroni, Giacomin, & Guida, 2005; Caminada, 2006; Dung, Mancarella, & Toni, 2007; Verheij,1996). Compared nonmonotonic formalisms (which built top classicallogical syntax), argumentation frameworks much simpler formalism (in end,directed graphs). However, simplicity made attractive modeling toolseveral diverse areas, like formalizations legal reasoning (Bench-Capon & Dunne, 2005)multi-agent negotiation (Amgoud, Dimopoulos, & Moraitis, 2007).field argumentation, intertranslatability mainly studied connectiongeneralizations Dungs argumentation frameworks. generalization meanaugmentation simple frameworks concepts priorities additional relations arguments. context, translations used show proposedsemantics generalizations close relation corresponding semantics standard AFs. words, given generalized AF one interestedtranslating standard AFs preserving semantics. translationsdiscussed, instance, terms bipolar AFs (Cayrol & Lagasquie-Schiex, 2009), valuebased AFs (Bench-Capon & Atkinson, 2009), AFs recursive attacks (Baroni, Cerutti,Giacomin, & Guida, 2011), abstract dialectical frameworks (Brewka, Dunne, & Woltran,2011). recent exception intertranslatability within Dung AFs discussed,work Baumann Brewka (2010), consider enforce desired extension DungAFs adding new arguments switching semantics. slightly different perspective, also work Gabbay (2009) related, since investigates substitutionargumentation framework node another framework.focus exclusively standard argumentation frameworks followingmain objective: Given AF F argumentation semantics , find function Tr-extensions F certain correspondence -extensions Tr (F ).believe results important different points view.Firstly, consider advanced argumentation engine semantics , onewants evaluate AF F wrt. different semantics . Then, might good plantransform F way AF F evaluating F wrt. semantics allowseasy reconstruction -extensions F . required transformations efficiently computable, leads potentially successful approach implementingdistinguished algorithm -semantics scratch. Figure 1 illustrates idea.concept filter required case Tr (F ) introduces arguments (which thusmight appear -extensions Tr (F )) course translation making filter1. general, arguments considered simple statements contain number reasonslead conclusion (see, e.g., Besnard & Hunter, 2001; Caminada & Amgoud, 2007). However,purpose work, treat arguments atomic entities thus abstracting internalstructure.446fiOn Intertranslatability Argumentation SemanticsInput AF: FTranslationTr (F )Solver(Tr (F ))(F )FilterFigure 1: Solver semantics .ing new arguments necessary obtain desired original extensions. However,also consider translations back-translation necessary.second motivation work concerned meta(level) argumentation (see,e.g., Modgil & Bench-Capon, 2011; Villata, 2010) explained follows:meta-level Dung argumentation framework instantiated arguments makestatements arguments, interactions, evaluation object-level argumentation framework(Modgil & Bench-Capon, 2011). translations shall presentexactly fit picture sense model certain featuressemantics within another semantics , giving translation .concrete example, let complete semantics denote stable semantics(we provide formal details different semantics Section 2; sakeillustration details required). Then, transformation captureconcept admissibility (informally speaking, set arguments defend itself)implicitly present complete semantics suitable introduction new arguments,stable semantics perform type reasoning. words, translatability results different semantics AFs yield understanding certainproperties, specified implicitly within one semantics, made (syntactically)explicit within AF order make properties amenable another semantics.third important application work, consider situations differentsemantics argumentation dealt simultaneously. might casedifferent agents share views certain situation (modeled AFs)agents use different semantics reason frameworks. well, problemcombining frameworks constructed assumptionevaluated different semantics falls possible application area work.Finally, emphasize understanding translations efficiently performedwrt. different semantics complements picture expressibility argumentationsemantics. instance, exists efficient translation semantics semantics, translation direction, could understoodexpressible , although complexity analysis typical decision problems associatedAFs show difference . example consider semi-stablestage semantics. semantics credulous acceptance problem P2 -completeskeptical acceptance problem P2 -complete (Dvorak & Woltran, 2010).considering call efficient exact translations one map stage semantics semistable semantics vice versa. Thus semi-stable semantics expressiblestage semantics wrt. efficient exact translations. However argue notionexact translations may restrictive comparing expressibility argumentationsemantics.447fiDvorak & WoltranBeside aspects motivation, would like mention positive resultsintertranslations indicate certain form independence semantics argumentation.particular importance, mind argumentation community nowadays overwhelmed different proposals semantics. Thus understanding basicprinciples underlying different semantics crucial, believe results providedpaper contribute question.organization remainder paper main contributions follows:Section 2, introduce argumentation frameworks different semanticsdeal paper. also review known complexity results complement sense show known tractable problems P -hard;fact use impossibility results Section 5.Section 3 defines properties translations basically along lines Janhunen(1999). particular, consider desired properties efficiency (the translationcomputed logarithmic space wrt. given AF), modularity (the translationdone independently certain parts framework) faithfulness (thereclear correspondence extensions translated AForiginal AF). However, also consider additional features neededdeal argumentation semantics (for instance, admissible semanticsalways yields empty set one solution; thus filtering entire solutionnecessary).Section 4 contains main results, particular provide translationsDungs original semantics (admissible, preferred, stable, complete, grounded), stagesemantics (Verheij, 1996) semi-stable semantics (Caminada, 2006). analyzetranslations wrt. properties mentioned using minimal desiderataefficiency (a particular form of) faithfulness.already mentioned, Section 5 provides negative results, i.e. showcertain translations semantics possible. impossibilityresults make use typical complexity-theoretic assumptions; others genuine duedifferent properties compared semantics.Finally, Section 6 conclude paper summary discussionpresented results. well, outlook potential future work given there.2. Argumentation Frameworkssection introduce (abstract) argumentation frameworks (Dung, 1995) recallsemantics study paper (see also Baroni & Giacomin, 2009, overview).Moreover, highlight complement complexity results typical decision problemsassociated frameworks.Definition 1. argumentation framework (AF) pair F = (A, R) nonempty set arguments 2 R attack relation. given AF F = (A, R)2. technical reasons consider AFs 6= .448fiOn Intertranslatability Argumentation Semanticsuse AF denote set arguments RF denote attack relation R.pair (a, b) R means attacks b.sometimes use notation R b instead (a, b) R. A,also write R (resp. R S) case exists argument b S,b R (resp. R b). case ambiguity arises, use instead R .AF naturally represented directed graph. Semantics argumentationframeworks given via function assigns AF F = (A, R) set (F ) 2Aextensions. shall consider functions stb, adm, prf , com, grd , stg,sem stand stable, admissible, preferred, complete, grounded, stage,respectively, semi-stable semantics. giving actual definitions semantics,require formal concepts.Definition 2. Given AF F = (A, R), argument defended (in F ) setb A, b a, also b holds. Moreover, set A,+define range S, denoted SR, set {b | b}.continue definitions considered semantics. Observe common feature concept conflict-freeness, i.e. arguments extension allowedattack other.Definition 3. Let F = (A, R) AF. set conflict-free (in F ),a, b S, (a, b) R. conflict-free set S, holds+stb(F ), \ S, a, i.e. SR= A;adm(F ), defended S;prf (F ), adm(F ) adm(F ) S;com(F ), adm(F ) defended S, S;grd (F ), com(F ) com(F ) S;+stg(F ), conflict-free set F , TR+ SR;+sem(F ), adm(F ) adm(F ) TR+ SR.semantics , sets defined ones (F ).recall AF F ,stb(F ) sem(F ) prf (F ) com(F ) adm(F )holds, considered semantics except stable semantics, (F ) 6=holds. grounded semantics always yields exactly one extension. Moreover AFleast one stable extension stable, semi-stable, stage extensions coincide.Example 1. Consider AF F = (A, R), = {a, b, c, d, e} R = {(a, b), (c, b),(c, d), (d, c), (d, e), (e, e)}. graph representation F given follows.bc449efiDvorak & Woltranxxy zyz xxzFigure 2: Argumentation framework FT,z = { x, x z, z x}.stb(F ) = stg(F ) = sem(F ) = {{a, d}}. admissible sets Fcollection {}, {a}, {c}, {d}, {a, c}, {a, d}, thus prf (F ) = {{a, c},{a, d}}. Finallycomplete extensions F {a}, {a, c} {a, d}, {a} grounded extensionF .turn complexity reasoning AFs. end, define followingdecision problems semantics introduced Definition 3.Credulous Acceptance Cred : Given AF F = (A, R) argument A.contained (F )?Skeptical Acceptance Skept : Given AF F = (A, R) argument A.contained (F )?Verification extension Ver : Given AF F = (A, R) set argumentsA. (F )?Existence extension Exists : Given AF F = (A, R). (F ) 6= ?Existence nonempty extension Exists: Given AF F = (A, R). existset 6= (F )?giving overview known results, provide lower bounds which,best knowledge, established yet.Proposition 1. problems Credgrd = Skeptgrd = Skeptcom well Vergrd P-hard(under L-reductions, i.e. reductions using logarithmic space).Proof. use reduction P-hard problem decide, given propositional definiteHorn theory atom x, whether x true minimal model .Let, definite Horn theory = {rl : bl,1 bl,il hl | 1 l n} atoms Xatom z X, FT,z = (A, R) AF defined follows:= X {t}R = {(x, x), (t, x) | x X} {(z, t)}{(rl , hl ), (bl,j , rl ) | rl T, 1 j il )}fresh argument. See Figure 2 example. Clearly AF FT,zconstructed using logarithmic space size .450fiOn Intertranslatability Argumentation Semanticsfollowing show z minimal model iff groundedextension FT,z iff grd (FT,z ) = {T {t}}.First attend grounded extension E FT,z iff E = {T {t}}. Obviouslyif-direction holds. Thus let us assume E, x X attacked Ethus r defended E. Hence E = {T {t}}.remains show z minimal model iff grounded extensionE FT,z . recall definition characteristic function FF AF F , definedFF (S) = {x AF | x defended S}, grounded extension F leastfix-point FF . show only-if part, let us assume z minimal model. Thus exists finite sequence rules (rli )1ik , (i) rule rliatom bli ,s exists rule rlj , j < hlj = bli ,s (ii) hlk = z. Clearly rl1empty body thus corresponding argument attackers FT,z , i.e. rl1 E.claim i, 1 k, rli E holds well prove induction.end, assume claim holds < i, i.e. rlm E, thus E hlm< holds. Using (i) get argument rli , holdsE a. Hence rli E. particular rlk E (ii) E z. zargument attacking also E.show if-part, let us assume contained grounded extensions EFT,z . construction E z thus exists integer k, FFk () z< k : FFm () 6 z. claim 1 k x X holdsFFm () x x minimal model . proof inductionm. induction base consider FF (). construction FF () set argumentscorrespond rules empty body. arguments attacked FF ()head atoms rules, clearly minimal model. induction stepassume FFm1 () attacks arguments corresponding atoms minimal model.FFm1 () 6 z 6 FFm1 (). Let x X argument FFm () x,FFm1 () 6 z. exists ri hi = x ri FFm ().construction FT,z argument ri defended FFm1 () iff atombody ri attacked FFm1 (). Hence, assumption atom body ricontained minimal model . head hi ri minimal model. Hence, FFk () z, get z minimal model .Proposition 2. Verstg coNP-hard.Proof. prove assertion reducing (NP-hard) problem 3-SAT complementary problem Verstg . assume 3-CNF formula given set C clauses,clause set atoms negated atoms (denoted x). CNFvariables X, define AF F = (A, R)= X X C {s, t, b}R = {(x, x), (x, x) | x X} {(l, c) | l c, c C}{(c, t) | c C} {(s, y), (y, s) | \ {s, b}} {(t, b), (b, b)}X = {x | x X} s, t, b fresh arguments. See Figure 3 illustratingexample. show satisfiable iff {s} stage extension F . First letus assume satisfiable let satisfying assignment . set451fiDvorak & Woltranc1x1c2x2x1bc3x3x2x4x3x4Figure 3: AF F{c1 ,c2 ,c3 } c1 = {x1 , x2 , x3 }, c2 = {x2 , x3 , x4 }, c3 = {x1 , x2 , x4 }.E = {t} {x | x X, (x) = true} {x | x X, (x) = f alse} stable extension+F , i.e. ER= A, since {s}+R = \ {b}, {s} stage extension F .let us assume {s} stage extension. argumentation above, i.e.using {s}+R A, get F stable extension. seensatisfying assignment corresponds stable extension F . Thus concludeunsatisfiable.Together results literature (Coste-Marquis, Devred, & Marquis, 2005;Dimopoulos & Torres, 1996; Dung, 1995; Dunne & Bench-Capon, 2002; Dunne & Caminada, 2008; Dvorak & Woltran, 2010), obtain complexity-landscape abstractargumentation given Table 1.3. Properties Translationsfollows, understand translation Tr function maps AFs AFs.particular, seek translations, given semantics , , extensions (F )certain relation extensions (F ) AF F . start with, introduceadditional properties seem desirable translations. end, define,CredSkeptVerExistsExistsgrdP-cP-cP-ctrivialLstbNP-ccoNP-cLNP-cNP-cadmNP-ctrivialLtrivialNP-ccomNP-cP-cLtrivialNP-cprfNP-ccoNP-ctrivialNP-csemP2 -cP2 -cP2 -cP2 -cP2 -ccoNP-ctrivialNP-ccoNP-ctrivialLstgTable 1: Complexity abstract argumentation (C-c denotes completeness class C).452fiOn Intertranslatability Argumentation SemanticsAFs F = (A, R), F = (A , R ), union AFs F F = (A , R R ), inclusionF F iff jointly R R .Definition 4. translation Tr calledefficient every AF F , AF Tr (F ) computed using logarithmic spacewrt. |F |;covering every AF F , F Tr (F );embedding every AF F , AF ATr (F ) RF = RTr (F ) (AF AF );monotone AFs F, F , F F implies Tr (F ) Tr (F );modular AFs F, F , Tr (F ) Tr (F ) = Tr (F F ).translation reduce expressiveness semantic using expensivecomputation. Thus computational cost translation less computational cost semantic focus, i.e. less P. Thus using classlogarithmic space computable functions appropriate purposes. addition, onecould seek translations minimal wrt. certain parameters (for instance, numberadditional arguments attacks). However, decided design translationstowards aims, since would partly hide main intuitions underlying translations.property efficiency clearly motivated, let us spend wordsproperties. Covering holding ensures translation hide originalarguments conflicts. embedding, addition, ensures additional attacksoriginal arguments pretended. efficiency motivated expressiveness possibility reuse reasoning algorithms, properties coveringembedding motivated meta-argumentation scenario. Translationscovering embedding preserve arguments conflicts (meta)-argue about,assumption one usually mind context meta-argumentation. putwords, embedding translation, original framework meta-levelpart clearly separated translated framework.Monotonicity modularity crucial extending source AF translation.Let us first consider monotonicity. multi-agent scenarios may impossible oneagent withdraw already interchanged arguments attacks, agents mayagree forget arguments conflicts already know about; hence, re-translatingaugmented source AF respect already existing translation. let us considermodularity adding arguments/attacks huge AF. updatingtranslation suffices consider new arguments/attacks, instead wholesource AF, indeed computational value. field meta-argumentation,modular translations particular interesting compatible mergingAFs. Thus one interchange merge- translation-operations, i.e. makedifference one first merges two AFs translates union first translatesAFs merges translations. Moreover, easily checked modulartransformation also monotone.453fiDvorak & WoltranNext, give two properties refer semantics. note conceptfaithfulness follows definition used Janhunen (1999); exactness spiritbijective faithfulness wrt. equivalence used Liberatore (2007).Definition 5. semantics , call translation Trexact every AF F , (F ) = (Tr (F ));faithful every AF F , (F ) = {E AF | E (Tr (F ))}|(F )| = | (Tr (F ))|.However, due nature different semantics want consider, needless restricted notions. instance, consider translation stablesemantics, face fact AFs possess stable extension,semantics always yield least one extension. following definition takescare issue.Definition 6. semantics , , call translation Trweakly exact exists collection sets arguments,AF F , (F ) = (Tr (F )) \ S;weakly faithful exists collection sets arguments,AF F , (F ) = {E AF | E (Tr (F )) \ S} |(F )| = | (Tr (F )) \ S|.sometimes refer elements remainder sets. Note dependstranslation, input AF. Thus, definition,contains arguments never occur AFs subject translation. words,reserve certain arguments introduction weak translations.Finally, mention properties Definition 4 well exact, weaklyexact faithful transitive, i.e. two transformations satisfying one properties, also concatenation satisfies respective property. However, transitivityguaranteed weakly faithful.4. Translationssection, provide numerous faithful translations semantics introducedDefinition 3. minimal desiderata, want translations efficient, monotone,covering (see Definition 4). Thus, section speaking translationstacitly assume satisfy least three properties.4.1 Exact Translationsstart rather simple translation, show exact prf semadm com.Translation 1. translation Tr 1 defined Tr 1 (F ) = (A , R ),= AF AFR = RF {(a, ), (a , a), (a , ) | AF },AF = {a | AF }.454fiOn Intertranslatability Argumentation SemanticsbcebceFigure 4: Tr 1 (F ) AF F Example 1.words intuition behind translation (for illustration see Figure 4 depicts translation example AF Example 1): new argumentsAF self-attacking thus never appear extension resulting framework. However, attacks original argument (and attacks ), thus argumentdefended set E Tr 1 (F ) E. Consequently, Tr 1 (F )admissible set also complete one.Lemma 1. AF F set E arguments, following propositions equivalent:1. E adm(F )2. E adm(Tr 1 (F ))3. E com(Tr 1 (F ))Proof. arguments AF self-conflicting, every conflict-free set E Tr 1 (F ) satisfies E AF . Further, since Tr 1 embedding, E conflict-free F iff E conflict-freeTr 1 (F ). Moreover, since Tr 1 adds symmetric attacks arguments AF ,E defends arguments F iff E defends arguments Tr 1 (F ). Thus,adm(F ) = adm(Tr 1 (F )) (1)(2) follows. (2)(3), let arbitraryargument E A. Tr 1 (F ) argument attackedattacker (except itself) . Hence, A, E defends Ethus every admissible set Tr 1 (F ) also complete one. Finally, (2)(3) holds sincecom(F ) adm(F ) true AF F .Concerning Tr 1 observe another side effect. already mentionedargument attacking . Thus different preferred extensions Tr 1 (F ) incomparablerange (recall Definition 2), therefore preferred extension Tr 1 (F ) also semistable extension Tr 1 (F ).Lemma 2. AF F set E arguments, following propositions equivalent:1. E prf (F )2. E prf (Tr 1 (F ))3. E sem(Tr 1 (F ))Proof. (1)(2), sufficient show E adm(F ) iff E adm(Tr 1 (F )) holdsE. captured Lemma 1. (2)(3), let D, E prf (Tr 1 (F )) and,++towards contradiction, assume DR/ sem(Tr 1 (F )).ER , i.e.455fiDvorak & WoltranbcebceFigure 5: Tr 2 (F ) AF F Example 1.E preferred extensions, 6 E. Thus, exists argument \ E.+/ E + , contradiction + E + .construction Tr 1 (F ), get DRRRR(2)(3) follows fact sem(F ) prf (F ) AF F .Obviously Tr 1 embedding translation introduction new argumentattack Tr 1 depends one original argument also modular. Togetherresults Lemma 1 2 thus get first main result.Theorem 1. Tr 1 modular, embedding, exact translation prf semadm com.next translation, Tr 2 , concerned stage semi-stable semantics. addition Tr 1 , make attacks original AF symmetric (thus Tr 2embedding) add original attack (a, b) also attack (a, b ).Translation 2. translation Tr 2 defined Tr 2 (F ) = (A , R ),= AF AFR = RF {(b, a), (a, b ) | (a, b) RF }{(a, b) | AF , (b, b) RF }{(a, ), (a , ) | AF }symmetric attacks Tr 2 (F ) mirror fact mind orientationattacks considering conflict-freeness. words, exploit well knownproperty symmetric frameworks conflict-free admissible sets coincide. However,making attacks symmetric destroys original range extensions. Thus make usearguments AF sense that, given set E arguments, argument++contained ERLikewise, add attacks self iff contained ER .defeating arguments. technical reason require originalargument attacked maximal conflict-free non-empty set Tr 2 (F ) (see alsoproof forthcoming lemma). illustration refer Figure 5.Lemma 3. AF F set E arguments, following propositionsequivalent:1. E stg(F )2. E stg(Tr 2 (F ))3. E sem(Tr 2 (F ))456fiOn Intertranslatability Argumentation SemanticscbeFigure 6: Tr 3 (F ) AF F Example 1.Proof. First, mention every stage extension AF F also maximal (wrt.) conflict-free F . Let us consider case stg(F ).stg(F ) = {} equivalent to, AF also (a, a) RF . constructionTr 2 also (a, a) R therefore stg(Tr 2 (F )) = sem(Tr 2 (F )) = {}.Hence lemma holds AFs, remainder proof assume6 stg(F ).(1)(2), observe set E conflict-free F iff conflict-free++Tr 2 (F ). following use (ER) short hand {a | ER}.FF++(ERF ) ER , since (a, b) RF , (a, b ) R . Furthermore,+maximal conflict-free set E F (and thus Tr 2 (F )), holds AF ER.+show contradiction. end, let us assume AF 6 ER, i.e.+exists AF 6 ER. E 6= self-attacking arguments++R 6R E,contained ER , thus (a, a) 6 R . 6 ERE 6set E {a} conflict-free F E maximal E; contradiction. Hence,maximal conflict-free set E AF F , i.e. candidates stage extensions,++++holds ERmaximal (wrt. subset inclusion) iff ER= AF (ER ) thus ERFFmaximal.(2)(3), observe AF (a, a) 6 R defends Tr 2 (F )arguments AF self-conflicting. Thus, admissible conflict-free sets coincideTr 2 (F ). Consequently, stage semi-stable extensions Tr 2 (F ) coincide.definition translation Tr 2 covering, embedding. Moreover, selfattacking argument attacked arguments Tr 2 modular. Togetherlemma, thus obtain following result.Theorem 2. Tr 2 exact translation stg sem.next translations consider stable semantics source formalism. RecallAFs possess stable extension, holds semantics (also recallexcluded empty AFs considerations). Thus use weak translationsintroduced Definition 6. first translation weakly exact uses singleremainder set {t} (recall definition remainder sets given Definition 6).Translation 3. translation Tr 3 (F ) defined Tr 3 (F ) = (A , R )= AF {t}R = RF {(t, a), (a, t) | AF }457fiDvorak & Woltranintuition rather simple, see also Figure 6. fact, new argumentTr 3 (F ) encodes might exist stable extension F . Thus none(other) arguments Tr 3 (F ) accepted, whenever accepted. Since argumentguards exists least one stable extension Tr 3 (F ) (for AF F ), namely{t}, make use fact stable, semi-stable stage semantics thus coincideTr 3 (F ).Lemma 4. Let F = (A, R) AF E A. following statementsequivalent:1. E stb(F )2. E stb(Tr 3 (F ))3. E sem(Tr 3 (F ))4. E stg(Tr 3 (F ))E (Tr 3 (F )) {stb, sem, stg} either E = {t} 6 E holds.Proof. translation modify original AF F , i.e. Tr 3 embedding,E AF , E conflict-free F iff E conflict-free Tr 3 (F ).+(1)(2): E stb(F ) definition non-empty, conflict-free satisfies ER=F+RAF . construction also holds E thus ER = , i.e. E stb(Tr 3 (F )).(1)(2) consider E stb(Tr 3 (F )), E AF . definition E+conflict-free Tr 3 (F )) thus F ; moreover, ER= Tr 3 embedding also+ER= AF . Hence E stb(F ).(2)(3)(4), mention {t} stable extension Tr 3 (F ) AFF . Furthermore, know exists stable extension AF, stable,semi-stable stage extensions coincide.Finally argument conflict arguments extensionE E set {t}.Adding argument corresponding attacks source AF modular operation attacks added Tr 3 also embedding.Theorem 3. Tr 3 modular, embedding weakly exact stb , {sem, stg}.Proof. result follows Lemma 4, states sem(Tr 3 (F )) = stg(Tr 3 (F )) =stb(F ) {{t}}. Thus taking remainder set = {{t}}, Tr 3 weakly exact.continue different translation stable semantics.Translation 4. Tr 4 defined Tr 4 (F ) = (A , R )= AF AFR = RF {(b , a) | a, b AF }{(a , ), (a, ) | AF }{(a, b ) | (a, b) RF }.458fiOn Intertranslatability Argumentation SemanticsbcebceFigure 7: Tr 4 (F ) AF F Example 1.translation Tr 2 , new arguments AF used encode rangeextension sense attacked set E Tr 4 (F ) rangeE F . However, given fact AF attacks back original argumentsA, accept argument set E arguments rangeE. illustration running example, see Figure 7. Observe examplearguments , b , c , , e attacks arguments a, b, c, d, e.Lemma 5. Let F = (A, R) AF E E 6= . Then, followingstatements equivalent:1. E stb(F )2. E stb(Tr 4 (F ))3. E adm(Tr 4 (F ))4. E prf (Tr 4 (F ))5. E com(Tr 4 (F ))6. E sem(Tr 4 (F ))conflict-free set E Tr 4 (F ) holds E A.Proof. First, arguments self-attacking, conflict-free set ETr 4 (F ) holds E A. Since translation embedding, set E conflict-freeF iff conflict-free Tr 4 (F ). show (1)(2), let E stb(F ). Hence,\ E, E R a. claim argument \ E attacked ETr 4 (F ). distinguish two cases different arguments \ E:(i) \ E: construction Tr 4 (F ) preserves attacks R. Thus\ E satisfies E R a, obtain E R(ii) : case E E R , since (a, ) R case \ E,assumption E stb(F ), exists argument b E (b, a) R.construction (b, ) R thus E R .Together observations conflict-free sets, get E stb(Tr 4 (F )).Vice versa, show (1)(2) get, E stb(Tr 4 (F )), E R a, \ E,thus, particular, \ E. definition Tr 4 , also E R\ E. Thus E stb(F ) follows.459fiDvorak & Woltranshow (2)(3), let E nonempty admissible extension Tr 4 (F ) E.construction, := {b | (b, a) R } . E adm(Tr 4 (F )),E R . E either E E R a. Thus everyholds either E E R a; hence, E stb(Tr 4 (F )).remaining implications follow well-known relations semantics, i.e.stb(G) sem(G) prf (G) com(G) adm(G), AF G. Hence, particular, since Tr 4 (F ), stable extensions non-empty admissible sets coincide, claimfollows.Clearly Tr 4 embedding translation, new argument add attacksoriginal arguments, Tr 4 modular.Theorem 4. Tr 4 embedding weakly exact translation stb{adm, com, prf , sem}.Proof. Lemma 5, particular stb(F ) = (Tr 4 (F )) \ {}, AFF . Thus taking remainder set, obtain Tr 4 weakly exact involvedsemantics.Thus Tr 3 Tr 4 weakly exact translations stb sem,course different remainder sets. Due different properties two translationsdepends concrete application would better choice.4.2 Faithful Translationsfar, introduced exact weakly exact translations. presenttranslations relax semantical property, i.e. switch faithful translations.first example, consider translation stg sem faithful embedding,exact. contrast translation Tr 2 exact stg semembedding. see Section 5 impossible give translationembedding exact stg sem, thus one decide propertyimportant concrete application scenario.Translation 5. translation Tr 5 (F ) defined Tr 5 (F ) = (A , R )= AF AF AFR = RF {(a, a), (a, a) | AF }{(a, ), (a , ) | AF }{(a, b ) | (a, b) RF }Tr 2 (F ) arguments AF handle range original extensions.instead making original attacks symmetric (as Tr 2 ) add arguments AFencode argument extension (also compare Figures 5 8).fact, meta-arguments indicating extension usedfaithful translations presented subsection.Lemma 6. Let F = (A, R) AF, E E = E (A \ E). followingstatements equivalent:460fiOn Intertranslatability Argumentation SemanticsbcebcebceFigure 8: Tr 5 (F ) AF F Example 1.1. E stg(F )2. E stg(Tr 5 (F ))3. E sem(Tr 5 (F ))Moreover sem(Tr 5 (F )) exists set E = E (A \ E).Proof. First prove stg(Tr 5 (F )) form = E (A \ E).conflict-free AF = (each self-attacking){a, a} 6 E (as attacks vice versa). stage extension also-maximal conflict-free set either S. Henceexists E = E (A \ E).(1)(2): Let E stg(F ). easy see E conflict-free Tr 5 (F ).construction argument either E E holds mutualattacks a, hence (E )+R . Next observe. definitioniffEself-attacking thus (E )+RTr 5 (F ) argument attacked arguments b (b, a) R.+(E )+R iff either E exists b (b, a) R iff (E)R .+assumption E stage extension F thus (E)R -maximal. Usingobservation also (E )+R -maximal Tr 5 (F ) thereforeE stg(Tr 5 (F )).(1)(2): Let E stg(Tr 5 (F )). recall E form = E (A \ E),E A. easily checked E conflict-free F . observation++(E )+R iff (E)R fact (E )R -maximal Tr 5 (F ) get+also ER-maximal F . Hence, E stg(F ).(2)(3): Let us consider E stg(Tr 5 (F )). already observed, Edesired form AF AF either E E a. constructionargument b AF attack E . conclude stage extension defendsattackers, i.e. admissible set. Hence, stage semi-stable extensionsTr 5 (F ) coincide.lemma construction Tr 5 , following result immediate.Theorem 5. Tr 5 modular, embedding faithful translation stg sem.Next give faithful translation admissible semantics stable, semi-stablestage semantics.461fiDvorak & Woltranbcebce(a, b)(c, b)(d, c)(c, d)(d, e)(e, e)Figure 9: Tr 6 (F ) AF F Example 1.Translation 6. translation Tr 6 (F ) defined Tr 6 (F ) = (A , R )= AF AF RFR = RF {(a, a), (a, a) | AF }{(r, r) | r RF }{(a, r) | r = (y, a) RF }{(a, r) | r = (z, y) RF , (a, z) RF }main idea use additional arguments (a, b) represent attackrelations source framework order capture admissibility follows: (a, b)attacked extension E Tr 6 (F ) (a, b) critical wrt. correspondingextension E F , meaning either b/ E exists c E (c, b) RF , i.e.defended E. instance, consider argument (c, b) translationexample framework depicted Figure 9. Then, (1) b attacks (c, b) since bchosen (i.e. b chosen in), need defend b; (2) attacks (c, b) sincechosen in, defends b attacker c (recall (d, c) present sourceAF). Thus, long (c, b) attacked argument, b treated corrected termsadmissibility (wrt. attacker c). Note example b cannot defendeda, thus way get (a, b) range select b out.Lemma 7. Let F = (A, R) AF, E E = E (A \ E). followingstatements equivalent:1. E adm(F )2. E stb(Tr 6 (F ))3. E sem(Tr 6 (F ))4. E stg(Tr 6 (F ))Moreover E (Tr 6 (F )) ( {stb, sem, stg}) exists set EE = E (A \ E).Proof. (1)(2): Let E adm(F ). easy see E conflict-free Tr 6 (F )(E )+R . remains show argument r r R462fiOn Intertranslatability Argumentation Semanticsattacked E . Let (a, b) argument r. b/ E b E thus E R r.Otherwise, b E (thus b E ) and, assumption, E defends b F , i.e. (c, a) Rc E (thus c E ). construction, (c, r) R E R r.(1)(2): Let E stb(Tr 6 (F )). E conflict-free, thus R E = {a, a} 6 EA. construction, E conflict-free F . remains show E defendsarguments F . Let b \ E b R E. existsargument (b, a) Tr 6 (F ) attacked E. E/ E thusexists argument c E (c, b) R.(2)(3)(4): empty set always admissible always stableextension Tr 6 (F ). Hence, stable, semi-stable stage extensions coincide Tr 6 (F ),AF F .Observe construction Tr 6 drawing attacks {(a, r) | r = (z, y) RF , (a, z)RF } depends two attacks three arguments original framework. Hence Tr 6modular. Lemma 7 next result follows quite easily.Theorem 6. Translation Tr 6 embedding faithful adm ( {stb, sem, stg}).faithful translation complete stable semantics present next,extend given AF arguments represent whether argument attackedcorresponding extension not. add arguments ensure admissibilitycompleteness. entire translation thus slightly complicated; see also Figure 10depicts translated framework running example.Translation 7. translation Tr 7 (F ) defined Tr 7 (F ) = (A , R )= AF AF AF AF AF RFR = RF {(x, x) | x AF RF }{(a, a), (a, a), (a , ), (a, ) | AF }{(a, b ), (a , b ) | (a, b) RF }{(a, r ), (b , r ) | r = (b, a) RF }intuition behind arguments AF , AF , RF similar previous translations.argument AF indicates attacked extension E F , AFsays attacked E.Lemma 8. Let F = (A, R) AF, E E = E (A \ E) {a | E R a} {a |E 6R a}. following statements equivalent:1. E com(F )2. E stb(Tr 7 (F ))3. E sem(Tr 7 (F ))4. E stg(Tr 7 (F ))Moreover E (Tr 6 (F )) ( {stb, sem, stg}) exists set EE = E (A \ E) {a | E R a} {a | E 6R a}.463fiDvorak & Woltranbcebcebcebcebce(a, b)(c, b)(d, c)(c, d)(d, e)(e, e)Figure 10: Tr 7 (F ) AF F Example 1.Proof. show (1)(2), let E com(F ). construction E conflict-freeTr 7 (F ) (for x, E x R x R y). Moreover, definition E ,+verified (E )+R . Thus remains show (i) (E )R(ii) R (E )+R .(i) Let arbitrary argument F . E complete extensioneither E, thus E , exists attack (b, a) R E 6R b,thus b E . construction (b , ) R thus E R .(ii) Let r = (b, a) R arbitrary attack F . E admissible holds either/ E, thus E , E R b, thus b E . cases E R r.Putting things together, get R = (E )+Requivalent E stable extension Tr 7 (F ).show (1)(2), let E stb(Tr 7 (F )). First prove E desired form.E conflict-free -maximal clearly E (A A) = E \ EE A. Let arbitrary argument. E iff6 E . E stable 6 E iff exists attack (b, ) b E .construction Tr 7 (F ) equivalent b E therefore E R a. Thus Edesired form, remains show E complete. mentionedx, E : x R x R thus E conflict-free F . Thus remains show(i) E defends arguments F (ii) E contains argument defendedE F .(i) Let us assume exists argument E defended E. Thus existsr = (b, a) R, E 6 b. construction also/ E (as E)b 6 E (as E 6 b). Tr 7 (F ) self-attacking argument r attackedarguments a, b (and itself). Hence, contradiction E stableextension.464fiOn Intertranslatability Argumentation Semantics(ii) Let argument defended E. arguments b RE R b thus b E b/ E . Recall Tr 7 (F ) argumentself-attacking thus belong E attacked argumentsb a. E stable extension 6 E E E.(2) (3) (4): always exists complete extension know framework Tr 7 (F ) stable extension. stable, stage semi-stable extensionscoincide.Translation Tr 7 introduces huge number new arguments, despite introduction concrete argument attack depends single argument attack. HenceTr 7 modular. easily checked Tr 7 also embedding. Together Lemma 8thus state following result Tr 7 .Theorem 7. Tr 7 modular, embedding faithful translation com ({stb, sem, stg}).Finally present translation grounded semantics semanticsfocus, i.e. semantics except admissible semantics. main ideasimulate computation least fixed-point characteristic function FF (S) ={x AF | x defended S} AF F within target AF.Translation 8. translation Tr 8 (F ) defined Tr 8 (F ) = (A , R )= AF,1 AF,1 AF,l AF,lR = RF {(ai , bi ) | (a, b) R, [l]}{(ai , bi+1 ) | (a, b) R, [l 1]}AF = AF,l l = |A2F | .illustration, use slightly different example depicted Figure 11(a). Observe AF {a, c, d} grounded extension. translated frameworkgiven Figure 11(b).intuition behind arguments ai AF,i FFi (), intuition(i1)() 6 a. integer l upper bound numberai AF,i FFiterations need reach least fixed-point, i.e. grounded extension.Lemma 9. Let F = (A, R) AF E grounded extension Tr 8 (F ).E grounded extension F . Tr 8 (F ) grounded,stable, complete, preferred, semi-stable stage extensions coincide.Proof. recall definition characteristic function FF AF F , definedFF (S) = {x AF | x defended S}, grounded extension F leastfix-point FF . use shorthand F = Tr 8 (F ). One showarbitrary(i) ai E iff FFi ();(ii) ai E iff FFi1 () 6R a;465fiDvorak & Woltrancbea1b1c1d1e1a1b1c1d1e1a2b2c2d2e2a2b2c2d2e2a3b3c3d3e3bce(a) AF F(b) Tr 8 (F )Figure 11: example Tr 8 .(iii) AF,i (E )+R .(iv) AF,i (E )+R .prove structural induction. induction base show (ii) (iv)arguments a1 . a1 E attacked argument.coincides fact FF0 () = doesnt attack argument thus (ii)(iv) holds.two induction steps: (1) Showing (i) (iii) hold arbitrary n iff (ii)(iv) hold n; (2) showing (ii) (iv) hold arbitrary n iff (i) (iii)hold n 1.(1) assume (ii) (iv) hold . definition FF FFn ()iff b = {b | b a} attacked FFn1 (). Applying inductionhypothesis (ii) b obtain FFn () iff bi {bi | (b, a) R}attacked E . Further, construction Tr 8 (F ) attackersa, equivalent argument ai defended E . recallargument defended grounded extension indeed contained groundedextension. Hence, FFn () iff ai E (i) holds.show (iii) consider ai AF,i . ai E clearly ai (E )+R . Thus letus consider ai/ E . Then, observations, exists bibi ai E 6 bi . Using latter induction hypothesis (iv) obtainbi E . E ai , hence ai (E )+R obtain (iii).(2) let us assume (i) (iii) hold an1 . FFn1 ()iff exists b FFn1 () {b | (b, a) R }. induction hypothesis holds iff466fiOn Intertranslatability Argumentation Semanticsexists bi1 E (b, a) R. words exists bi1 Ebi1 R ai , implies ai 6 E . Moreover bi1 Ebi1 R ai , assumption (iii) E defends ai thusai E . Hence (ii) (iv) hold.Furthermore applying FF operator either add new argument setattack additional argument reach fixed-point. step makedecision least two arguments thus FFl () = grd (F ). combination (i),get al E iff grd (F ). Moreover (iii) (iv) holds E also stableextension thus grd (F ) = stb(F ) = com(F ) = prf (F ) = sem(F ) = stg(F ).Tr 8 integer value l depends size source AF, Tr 8 modular.However, verified computation translation requires logarithmicspace wrt. Tr 8 embedding (the original AF indeed contained resultingAF; see also bottom layer Figure 11(b)). final result concerning translations thusfollows immediately Lemma 9.Theorem 8. Tr 8 embedding faithful translation grd ( {stb, com,prf , stg, sem}).5. Negative Resultssection, present results fortifying several semantics existtranslation desired properties. first result, rather straight forward,relies fact grounded semantics unique-status semantics.Proposition 3. (weakly) faithful translation grd {sem,stg, prf , com, stb, adm}.Proof. instance consider AF F = ({a, b}, {(a, b), (b, a)}). {{a}, {b}}(F ) {sem, stg, prf , com, stb, adm} grounded semantics always proposesunique extension.observe general holds multiple status semanticsunique status semantics (weakly) faithful translation .results based complexity gaps different semantics (see Table 1)fact certain translations preserve decision problem. start casesimpossible find efficient faithful translations; even allow weaklyfaithful translations, cf. Definition 6. Afterwards, give negative results concerning(weakly) exact translations.following theorem concerns intertranslatability preferred, semi-stablestage semantics, i.e. semantics skeptical acceptance P2 -complete. underlying reason impossibility result complexity gap credulous acceptanceproblems.Theorem 9. efficient (weakly) faithful translation sem prf stg prfunless P2 = NP.467fiDvorak & WoltranProof. Let Tr efficient (weakly) faithful translation {sem, stg} prf .definition translation L-computable show next reduces Cred Credprf :Let F = (A, R) arbitrary AF, x argument. First let us assume xcredulously accepted wrt. . Hence, exists E (F ) x E. Trweakly faithful translation, E prf (Tr (F )), E = E. Thusx E , i.e. x credulously accepted wrt. preferred semantics Tr (F ).assume x credulously accepted Tr (F ) wrt. prf , i.e. x E Eprf (Tr (F )). x E conclude E remainder set Tr . Trweakly faithful translation E = E (F ), thus x credulouslyaccepted F wrt. . Thus, Tr L-reduction P2 -hard problem CredNP-easy problem Credprf .following theorem makes use complexity gaps skeptical acceptance.Theorem 10. efficient (weakly) faithful translation ,{sem, stg, prf } {com, stb, adm}, unless P2 = NP.Proof. Given efficient weakly faithful translation Tr remainder setSkept translated problem Skept , deciding whether argument-extension set S. Next show problem Skeptremains coNP. One disprove Skept , guessing set E A, 6 Everify E (F ) E 6 S. Ver P set fixed, i.e.depend input, NP-algorithm. Hence proving Skept coNP. ThusTr would L-reduction P2 -hard problem Skept coNP-easy problemSkept , implies P2 = NP.One might prefer (weakly) exact (weakly) faithful translations. seenSection 4, several translations exact faithful. casesinterested either finding exact translation evidence exact translationpossible. following theorems approve appropriate given(weakly) faithful translation Section 4, cannot exact translation.Theorem 11. (weakly) exact translation {adm, com}{stb, prf , sem, stg}.Proof. basically fact admissible resp. complete extensions may-relation; consider e.g. F = ({a, b}, {(a, b), (b, a)}) (F ) = {{a}, {b}, }. Let usassume exists (weakly) exact translation Tr . definition, (F ) ={{a}, {b}, } (Tr (F )), {a} contradicts {stb, prf , sem, stg}.Theorem 12. (weakly) exact translation com adm.Proof. observe every AF F holds adm(F ), AFs/ com(F ). Thus weakly exact translation Tr , collectionremainder sets, holds S. then, given AF F com(F ), e.g.F = ({a, b}, {(a, b), (b, a)}), conclude adm(Tr (F )) \ S, contradiction.Theorem 13. efficient (weakly) exact translation grd{stb, adm, com}, unless L = P.468fiOn Intertranslatability Argumentation Semanticsfhg1g2ecbFigure 12: Counterexample exact translations stg ( {sem, prf }).Proof. Let us, towards contradiction, assume exists efficient (weakly) exacttranslation Tr grd . given AF F = (A, R) set E holdsE grd (F ) iff E (Tr (F )). Thus Tr would L-reduction P-hard problemVer grd (see Proposition 1) Ver ( {stb, adm, com}) L.Section 4 presented two translations stg sem: Tr 2 exacttranslation, embedding, Tr 5 embedding faithful translation,exact. Let us also mention point Tr 2 translation presentedSection 4 embedding. Hence natural question occurs whethertranslation embedding exact stg sem possible. give negativeanswer question.Theorem 14. embedding (weakly) exact translation stg sem.Proof. Let us assume exists embedding (weakly) exact translation Trstg sem. Consider AF F = ({a, b}, {(a, a), (a, b)}) stg(F ) = {{b}}. Tr(weakly) exact translation {b} sem(Tr (F )) thus {b} adm(Tr (F )).(a, b) RTr (F ) (Tr (F ) embedding) thus {b} must attacka. (b, a) RTr (F ) contradiction Tr embeddingtranslation.Finally present impossibility result prf stg sem stg.Theorem 15. (weakly) exact translation stg ( {sem, prf }).Proof. Consider AF F = ({a, b, c, d, e, f, g1 , g2 , h}, {(g1 , g1 ), (g2 , g2 ), (a, b), (b, a), (c, d),(d, c), (a, g1 ), (b, e), (c, e), (d, g2 ), (e, f ), (f, h), (h, e)}) illustrated Figure 12.sem(F ) = {{b, d, f }, {a, c, f }, {a, d}} prf (F ) = sem(F ) {{b, c, f }}.prove weakly exact translation stg ( {sem, prf }),show exists AF F sem(F ) stg(F ). end, let us assumeF = (A , R ) AF {{b, d, f }, {a, c, f }, {a, d}} stg(F ). Using fact{b, d, f } conflict-free F obtain (d, f ), (f, d) 6 R similar using{a, c, f } conflict-free F get (a, f ), (f, a) 6 R . assumption {a, d} stg(F )thus {a, d} maximal conflict-free set F , observations set{a, d, f } also conflict-free F , contradiction.469fiDvorak & Woltrangrdadmstbcomprfsemstggrd id Tr 4 Tr 8 / - Tr 8 / - Tr 8 / Tr 8 / ?Tr 8 / ? Tr 8 / ?admidTr 6 / - Tr 1 Tr 4 Tr 6 / - Tr 6 / - Tr 6 / stbTr 4idTr 4Tr 4Tr 3 , Tr 4 Tr 3com Tr 4 Tr 7 / - Tr 7 / idTr 4 Tr 7 / - Tr 7 / - Tr 7 / prfidTr 1? /semid? /stgTr 2idTable 2: Results (weakly) faithful / exact translations.6. Conclusionwork, investigated intertranslations different semantics abstract argumentation. focused translations efficiently computable faithful (withrelaxations due certain differences implicit semantics). overview results given Table 2.3 entry row column read follows: statesshown (Section 5) efficient faithful (even weakly faithful) translationexists. entry refers translation (or concatenation translations),found efficient (weakly) exact translation . entry splittwo parts, e.g. Tr 8 / -, means found efficient (weakly) faithful translation,exact translation. ? indicates open problem. mentionconcatenated translations weakly faithful built weakly exacttranslation Tr 4 (which remainder set empty set) faithful translation(either Tr 6 , Tr 7 , Tr 8 ).Figure 13 illustrates intertranslatability results one glance. Here, solid arrowexpresses efficient faithful translation dotted arrow depictsmay exist translation, far neither found one argumentexistence. Furthermore, two semantics , pathproven (partly typical complexity theoretical assumptions)efficient faithful translation . consider relations semanticswrt. exactness rather faithfulness, overall picture changes; see Figure 14. Here,get detailed picture relations stable, admissible, completesemantics. One conclusion, draw pictures semi-stable semanticsexpressive one, since investigated semantics efficientlyembedded. Moreover, believe investigations complements recent resultscomparisons different semantics proposed argumentation frameworks.Let us point also mention that, instead considering different propertiestranslations, could also used slightly revised semantics. notion remaindersets (as given Definition 6) partly circumvented by, instance, using quasiadmissible semantics instead admissible semantics, quasi-admissible extensions3. One may notice Tr 5 appear table. Recall Tr 5 proposed alternativeTr 2 satisfying slightly different properties stg sem; see also discussion Theorem 14.470fiOn Intertranslatability Argumentation SemanticsAF non-empty admissible extensions (in case ones exist),empty set otherwise. Also obvious restricted properties translation are, less translations exist (compare Figures 13 14). Hence, observecertain trade-off translation criteria comparability semantics.alternative option obtain translations would exploit known relationsargumentation semantics logic-programming semantics (see, e.g., Dung, 1995;Wu, Caminada, & Gabbay, 2009) making use known translatability resultslatter. However, refrained approach here, since might blur minimalrequirements translations consideration. particular, pointmeta-argumentation, translations via logic-programming semantics might introduce newarguments technical reasons due logic-programming syntax,meaning level AFs.semi-stablepreferredstageadmissible, complete, stablegroundedFigure 13: Intertranslatability argumentation semantics wrt. weakly faithful translations.semi-stablepreferredstagestableadmissiblecompletegroundedFigure 14: Intertranslatability argumentation semantics wrt. weakly exact translations.471fiDvorak & Woltranfuture work, identify following tasks: First, want solve open slotsTable 2. Second, properties translations could interest. instance,one could even strengthen property exact (which defined termsextensions) requirement labelings (Caminada & Gabbay, 2009) sourcetarget framework coincide. Labelings provide additional information, particulararguments contained extension. Likewise, would interesting investigateintertranslatability general approach equational semantics argumentationframeworks (Gabbay, 2011). properties translations could given termsgraph properties. example, acyclic AFs remain acyclic translations,parameters tree-width remain unchanged. Requirements form alsotermed structural preservation (Janhunen et al., 2006). properties interestcomputational point view sense that, case source AF easyevaluate (because structure), advantage lost translation;recall Figure 1 suggested use translations rapid prototypingapproach compute extensions semantics via argumentation engine baseddifferent semantics. Finally, plan extend considerations importantsemantics like ideal semantics (Dung et al., 2007), cf2-semantics (which proposedamong others Baroni et al., 2005), resolution-based semantics (Baroni, Dunne, &Giacomin, 2011), among resolution-based grounded semantics particularinterest. well studying translations semantics generalizations Dung-styleAFs EAFs (Modgil, 2009) AFRAs (Baroni, Cerutti, et al., 2011) interestingsubject future work.Acknowledgmentswork supported Vienna Science Technology Fund (WWTF) grantICT08-028. preliminary version paper presented InternationalConference 30 Years Nonmonotonic Logic.authors grateful Christof Spanring suggesting counterexample usedproof Theorem 15. Moreover, authors want thank Tomi Janhunen wellanonymous referees 30 Years Nonmonotonic Logic symposiumJAIR valuable comments helped improve paper.ReferencesAmgoud, L., Dimopoulos, Y., & Moraitis, P. (2007). unified general frameworkargumentation-based negotiation. Durfee, E. H., Yokoo, M., Huhns, M. N., & Shehory, O. (Eds.), Proceedings 6th International Joint Conference AutonomousAgents Multiagent Systems (AAMAS 2007), pp. 963970. IFAAMAS.Baroni, P., Dunne, P. E., & Giacomin, M. (2011). resolution-based family abstractargumentation semantics grounded instance. Artif. Intell., 175 (3-4), 791813.Baroni, P., Cerutti, F., Giacomin, M., & Guida, G. (2011). AFRA: Argumentation framework recursive attacks. Int. J. Approx. Reasoning, 52 (1), 1937.472fiOn Intertranslatability Argumentation SemanticsBaroni, P., & Giacomin, M. (2009). Semantics abstract argument systems. Rahwan,I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp. 2544. Springer.Baroni, P., Giacomin, M., & Guida, G. (2005). SCC-recursiveness: general schemaargumentation semantics. Artif. Intell., 168 (1-2), 162210.Baumann, R., & Brewka, G. (2010). Expanding argumentation frameworks: Enforcingmonotonicity results. Baroni, P., Cerutti, F., Giacomin, M., & Simari, G. R. (Eds.),Proceedings 3rd Conference Computational Models Argument (COMMA2010), Vol. 216 Frontiers Artificial Intelligence Applications, pp. 7586. IOSPress.Bench-Capon, T. J. M., & Atkinson, K. (2009). Abstract argumentation values.Rahwan, I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp. 4564.Springer.Bench-Capon, T. J. M., & Dunne, P. E. (2005). Argumentation AI law: Editorsintroduction. Artif. Intell. Law, 13 (1), 18.Besnard, P., & Hunter, A. (2001). logic-based theory deductive arguments. Artif.Intell., 128, 203235.Brewka, G., Dunne, P. E., & Woltran, S. (2011). Relating semantics abstract dialectical frameworks standard AFs. Proceedings 22nd International JointConference Artificial Intelligence (IJCAI 2011), pp. 780785. AAAI Press.Caminada, M. (2006). Semi-stable semantics. Dunne, P. E., & Bench-Capon, T. J. M.(Eds.), Proceedings 1st Conference Computational Models Argument(COMMA 2006), Vol. 144 Frontiers Artificial Intelligence Applications, pp.121130. IOS Press.Caminada, M., & Amgoud, L. (2007). evaluation argumentation formalisms.Artif. Intell., 171 (5-6), 286310.Caminada, M., & Gabbay, D. (2009). logical account formal argumentation. StudiaLogica, 93 (2), 109145.Cayrol, C., & Lagasquie-Schiex, M. (2009). Bipolar abstract argumentation systems.Rahwan, I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp. 6584.Springer.Coste-Marquis, S., Devred, C., & Marquis, P. (2005). Symmetric argumentation frameworks. Godo, L. (Ed.), Proceedings 8th European Conference SymbolicQuantitative Approaches Reasoning Uncertainty (ECSQARU 2005), Vol.3571 Lecture Notes Computer Science, pp. 317328. Springer.de Bruijn, J., Eiter, T., & Tompits, H. (2008). Embedding approaches combining rulesontologies autoepistemic logic. Brewka, G., & Lang, J. (Eds.), Proceedings11th International Conference Principles Knowledge RepresentationReasoning (KR2008), pp. 485495. AAAI Press.Delgrande, J. P., & Schaub, T. (2005). Expressing default logic variants default logic. J.Log. Comput., 15 (5), 593621.473fiDvorak & WoltranDenecker, M., Marek, W., & Truszczynski, M. (2003). Uniform semantic treatmentdefault autoepistemic logics. Artif. Intell., 143 (1), 79122.Dimopoulos, Y., & Torres, A. (1996). Graph theoretical structures logic programsdefault theories. Theor. Comput. Sci., 170 (1-2), 209244.Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person games. Artif. Intell., 77 (2),321358.Dung, P. M., Mancarella, P., & Toni, F. (2007). Computing ideal sceptical argumentation.Artif. Intell., 171 (10-15), 642674.Dunne, P. E., & Bench-Capon, T. J. M. (2002). Coherence finite argument systems.Artif. Intell., 141 (1/2), 187203.Dunne, P. E., & Caminada, M. (2008). Computational complexity semi-stable semanticsabstract argumentation frameworks. Holldobler, S., Lutz, C., & Wansing, H.(Eds.), Proceedings 11th European Conference Logics Artificial Intelligence(JELIA 2008), Vol. 5293 Lecture Notes Computer Science, pp. 153165. Springer.Dvorak, W., & Woltran, S. (2010). Complexity semi-stable stage semantics argumentation frameworks. Inf. Process. Lett., 110 (11), 425430.Gabbay, D. M. (2009). Fibring argumentation frames. Studia Logica, 93 (2-3), 231295.Gabbay, D. M. (2011). Equational approach argumentation networks. Unpublished draft.Gottlob, G. (1995). Translating default logic standard autoepistemic logic. J. ACM,42 (4), 711740.Imielinski, T. (1987). Results translating defaults circumscription. Artif. Intell.,32 (1), 131146.Janhunen, T. (1999). intertranslatability non-monotonic logics. Ann. Math. Artif.Intell., 27 (1-4), 79128.Janhunen, T., Niemela, I., Seipel, D., Simons, P., & You, J.-H. (2006). Unfolding partialitydisjunctions stable model semantics. ACM Trans. Comput. Log., 7 (1), 137.Konolige, K. (1988). relation default autoepistemic logic. Artif. Intell.,35 (3), 343382.Liberatore, P. (2007).abs/0707.3781.Bijective faithful translations among default logics.CoRR,Marek, W., & Truszczynski, M. (1993). Nonmonotonic Logic: Context Dependent Reasoning.Springer.Modgil, S. (2009). Reasoning preferences argumentation frameworks. Artif. Intell.,173 (9-10), 901934.Modgil, S., & Bench-Capon, T. J. M. (2011). Metalevel argumentation. Accepted publication J. Log. Comput.. Available http://dx.doi.org/doi:10.1093/logcom/exq054.Moore, R. C. (1985). Semantical considerations nonmonotonic logic. Artif. Intell., 25,7594.474fiOn Intertranslatability Argumentation SemanticsPearce, D., & Uridia, L. (2011). Godel splitting translations. Submitted Draft.Preliminary Version presented International Conference 30 YearsNonmonotonic Logic.Reiter, R. (1980). logic default reasoning. Artif. Intell., 13 (12), 81132.Verheij, B. (1996). Two approaches dialectical argumentation: admissible sets argumentation stages. Meyer, J., & van der Gaag, L. (Eds.), Proceedings 8thDutch Conference Artificial Intelligence (NAIC96), pp. 357368.Villata, S. (2010). Meta-Argumentation Multiagent Systems: Coalition Formation, Merging Views, Subsumption Relation Dependence Networks. Ph.D. thesis, Universitadegli Studi di Torino.Wu, Y., Caminada, M., & Gabbay, D. M. (2009). Complete extensions argumentationcoincide 3-valued stable models logic programming. Studia Logica, 93 (2-3),383403.475fiJournal Artificial Intelligence Research 41 (2011) 131-154Submitted 11/10; published 5/11Redistribution Mechanisms AssignmentHeterogeneous ObjectsSujit GujarNaraharisujit@csa.iisc.ernet.inhari@csa.iisc.ernet.inDept Computer Science AutomationIndian Institute Science, Bangalore, 560012Abstractp heterogeneous objects assigned n competing agents (n > p)unit demand. required design Groves mechanism assignmentproblem satisfying weak budget balance, individual rationality, minimizing budgetimbalance. calls designing appropriate rebate function. objectsidentical, problem solved refer WCO mechanism. measureperformance mechanisms redistribution index. first prove impossibility theorem rules linear rebate functions non-zero redistribution indexheterogeneous object assignment. Motivated theorem, explore two approachesget around impossibility. first approach, show linear rebate functionsnon-zero redistribution index possible valuations objectscertain type relationship design mechanism linear rebate functionworst case optimal. second approach, show rebate functions nonzero efficiency possible linearity relaxed. extend rebate functionsWCO mechanism heterogeneous objects assignment conjecture worstcase optimal.1. IntroductionConsider p resources available n > p agents interested utilizingone them. desirable assign resources agents valuemost. Since classical Vickery-Clarke-Groves mechanisms (Vickrey, 1961; Clarke, 1971;Groves, 1973) attractive properties dominant strategy incentive compatibility(DSIC) allocative efficiency (AE), Groves mechanisms quite appealing usecontext. However, general, Groves mechanism need budget balanced.is, total transfer money system may zero. system leftsurplus deficit. Using Clarkes (1971) mechanism, ensure fairlyweak conditions, deficit money (that mechanism weakly budgetbalanced). case, system auctioneer left money.Often, surplus money really needed many social settings allocationsGovernment among departments, etc. Since strict budget balance cannot coexistDSIC AE (Green-Laffont theorem, see Green & Laffont, 1979), would likeredistribute surplus participants far possible, preserving DSIC AE.idea originally proposed Laffont (1979). total payment made mechanismredistribution referred rebate agents.c2011AI Access Foundation. rights reserved.fiGujar & Naraharipaper, consider following problem. n agents p heterogeneousobjects (n > p > 1). agent desires one object p objects. agentsvaluation objects independent valuations objects.Valuations different agents also mutually independent. goal designmechanism assignment p objects among n agents allocatively efficient,dominant strategy incentive compatible, maximizes rebate (which equivalentminimizing budget imbalance). addition, would like mechanism satisfyfeasibility individual rationality. Thus, seek design Groves mechanismassigning p heterogeneous objects among n agents satisfying:1. Feasibility (F) weak budget balance. is, total payment agentsless equal total received payment.2. Individual Rationality (IR), means agents utility participatingmechanism non-negative.3. Minimizes budget imbalance.call Groves mechanism redistributes Clarkes Payment Groves redistribution mechanism simply redistribution mechanism. Designing redistribution mechanism involves design appropriate rebate function. redistribution mechanism,rebate function agent linear function valuations remainingagents, refer mechanism linear redistribution mechanism (LRM). manysituations, design appropriate LRM reduces problem solving linear program.Due Green-Laffont theorem , cannot guarantee 100% redistribution typeprofiles. performance index redistribution mechanism would worst caseredistribution, is, fraction surplus guaranteed redistributedirrespective bid profiles. fraction referred redistribution indexrest paper. advantage worst case analysis that, requiredistributional information type sets agents. desirable rebatefunction deterministic anonymous. rebate function said anonymous twoagents bids get rebate. Also, valuation spaces identicalagents, without loss generality, restrict attention anonymousrebate functions. Thus, aim design anonymous, deterministic rebate functionmaximizes redistribution index satisfies feasibility individual rationality.work paper seeks non-trivially extend results Moulin (2009)Guo Conitzer (2009) independently designed Groves mechanism orderredistribute surplus objects identical (homogeneous objects case).mechanism deterministic, anonymous, maximum redistribution indexpossible Groves redistribution mechanisms. refer mechanism worstcase optimal (WCO) mechanism. WCO Mechanism linear redistribution mechanism. paper, concentrate designing linear redistribution mechanismheterogeneous objects case.132fiRedistribution Mechanisms1.1 Relevant Workimpossible achieve allocative efficiency, DSIC, strict budget balance simultaneously, compromise one properties. Faltings (2005) GuoConitzer (2008a) achieve budget balance compromising AE. interestedpreserving AE DSIC, settle non-zero surplus non-zero deficitmoney (budget imbalance) system. reduce budget imbalance, various rebatefunctions designed Bailey (1997), Cavallo (2006), Moulin (2009), GuoConitzer (2009). Moulin (2009) Guo Conitzer (2009) designed Groves redistribution mechanism assignment p homogeneous objects among n > p agents unitdemand. Guo Conitzer (2009) generalize work earlier paper (Guo & Conitzer,2007) multi-unit demand identical items. work Guo Conitzer (2008b),authors designed redistribution mechanism optimal expected sensehomogeneous objects setting. Thus, require distributional informationtype sets agents. Clippel co-authors (2009) use idea destroyingitems maximize agents utilities. preliminary version results presentedpaper appeared earlier papers (Gujar & Narahari, 2009, 2008).1.2 Contributions Outlineobjective paper design Groves redistribution mechanism assignmentheterogeneous objects unit demand. best knowledge, firstattempt design redistribution mechanism assignment heterogeneous objects.First, investigate question existence linear rebate function redistribution surplus assignment heterogeneous objects. result shows general,domain valuations agent Rp+ , impossible design linear rebatefunction, non-zero redistribution index, heterogeneous settings. However,relax assumption independence valuations different objects get linearrebate function non-zero redistribution index. Another way get around impossibility theorem relax linearity requirement rebate function. particular,contributions paper summarized follows.first prove impossibility existence linear rebate function non-zeroredistribution index heterogeneous settings, domain valuationsagent Rp+ valuations objects independent.objects heterogeneous values objects agentderived one single number, design Groves redistribution mechanismlinear, anonymous, deterministic, feasible, individually rational, efficient.addition, mechanism worst case optimal non-zero redistribution index.show existence non-linear rebate function non-zero redistribution index.propose mechanism, HETERO, extends Moulin/WCO mechanismheterogeneous settings. conjecture HETERO non-zero redistribution indexworst case optimal.133fiGujar & Naraharipaper organized follows. Section 2, introduce notation followedpaper describe relevant background work literature. also explainWCO mechanism there. Section 3, state prove impossibility result. deriveextension WCO mechanism heterogeneous objects single dimensionalprivate information Section 4. impossibility result rule possibilitynon-linear rebate functions strictly positive redistribution index. showredistribution mechanism, BAILEY-CAVALLO, Baileys mechanism (1997)applied settings consideration Section 5. design another non-linear rebatefunction, HETERO, actually matches Moulins rebate function objectsidentical. describe construction HETERO Section 5. carriedsimulations provide empirical evidence conjecture regarding HETERO.experimental setup results described Section 6. conclude paper Section7 provide directions future work. analysis, need orderingbids agents define Appendix A. proofs lemmaspaper presented Appendix B.2. Preliminaries Notationsection first define notation used paper preliminariesredistribution mechanisms.2.1 Model Notationnotation used summarized Table 1. context clear, uset, ti , ri , k, vi indicate t(b), ti (b), ri (b), k(b), vi (k(b)) respectively. paper,assume payment made agent form ti () Pri (), ti () agentpayment Clarke pivotal mechanism (1971). refer ti , total Clarkepayment surplus system.general, assume n agents p distinct objects. also assumeallocation rule satisfies allocative efficiency (AE) property.2.2 Important Definitionsprovide important definitions conceptual way.Definition 1 (DSIC) say mechanism Dominant Strategy Incentive Compatible(DSIC) best response agent report type truthfully, irrespectivetypes reported agents.Definition 2 (Allocative Efficiency) say mechanism allocatively efficient (AE)mechanism chooses, every given type profile, allocation objects amongagents sum valuations1 allocated agents maximized.Definition 3 (Redistribution Mechanism) refer Groves mechanism Grovesredistribution mechanism simply redistribution mechanism, allocates objects1. Sum valuations allocated agents allocation also referred total value valueallocation.134fiRedistribution MechanismsnNpjR+bibKk(b)k (b)(b)kivi (k(b))vti (b)t(b)tiri (b)eNumber agentsSet agents = {1, 2, . . . , n}Number objectsIndex agent, = 1, 2, . . . , nIndex object, j = 1, 2, . . . , pSet positive real numbersspace valuations agent i, = Rp+Bid submitted agent i, = (bi1 , bi2 , . . . , bip )(b1 , b2 , . . . , bn ), bid vectorset allocations p objects n agents,getting one objectallocation, k() K, corresponding bid profile ballocatively efficient allocation bid profile ballocatively efficient allocation bid profile bagent excluded systemValuation allocation k agent i,b bid profilePv : K R, valuation function, v(k(b)) = vi (k(b))Payment made agent Clarke pivotal mechanism,(b))bid profile b, ti (b) = vi (k (b)) v(k (b)) v(kiClarke payment,P is, total payment receivedagents, t(b) = ti (b)Clarke payment received absence agentRebate agent bid profile bPri (b)redistribution index mechanism, = inf b:t(b)6=0 t(b)Table 1: Notation: redistribution mechanismsagents allocatively efficient way redistributes Clarke surplus systemform rebates agents net payment made agent still followsGroves payment structure.Definition 4 (Linear Rebate Function) say rebates agent follow linearrebate function rebate linear combination bid vectors remainingagents. Moreover, redistribution mechanism uses linear rebate functionsagents, say mechanism linear redistribution mechanism.Definition 5 (Redistribution Index) redistribution index redistribution mechanism defined worst case fraction Clarkes surplus gets redistributedamong agents. is,Pri (b)e = infb:t(b)6=0 t(b)135fiGujar & Narahari2.3 Optimal Worst Case Redistribution Objects Identicalobjects identical, every agent value object, callvi . Without loss generality, assume, v1 v2 . . . vn . Clarkes pivotalmechanism, first p agents receive objects p agents payvp+1 . So, surplus system pvp+1 . situation, Moulin (2009) GuoConitzer (2009) independently designed redistribution mechanism.Guo Conitzer (2009) maximize worst case fraction total surplus getsredistributed. mechanism called WCO mechanism. Moulin (2009) minimizesratio budget imbalance value optimal allocation, valueallocatively efficient allocation. WCO mechanism coincides Moulins feasibleindividually rational mechanism. mechanisms work follows.receiving bids agents, bids sorted decreasing order. first p agentsreceive objects. agents Clarke payment calculated, say ti . Every agent pays,pi = ti ri , where, ri rebate function agent i.riW CO = cp+1 vp+2 + cp+2 vp+3 + . . . + cn1 vn= 1, . . . p + 1WCO= cp+1 vp+1 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vn = p + 2, . . . nri(1)where,(1)i+p1 (np)n1p1n1Xci =n 1 Pn1 n 1 j=ij=pjn1j;= p + 1, . . . , n 1(2)Suppose y1 y2 . . . yn1 bids (n 1) agents excluding agent i,equivalently rebate agent given by,riW CO =n1Xc j yj(3)j=p+1redistribution index mechanism e , e given by,n1pe = 1Pn1 n 1j=pjoptimal mechanism, since mechanism guaranteee fraction redistribution worst case.proceed present impossibility theorem state following theoremGuo Conitzer (2009) used design mechanism.Theorem 1 (Guo & Conitzer, 2009) x1 x2 . . . xn 0,a1 x1 + a2 x2 + . . . xn 0 iffjXi=1136ai 0 j = 1, 2 . . . , nfiRedistribution Mechanisms3. Impossibility Linear Rebate Function Non-Zero RedistributionIndexreviewed design redistribution mechanism homogeneous objects.seen WCO mechanism linear function types agents.explore general case. homogeneous case, bids real numbersarranged decreasing order. Clarke surplus linear function ordered bids.heterogeneous scenario, would case. bid bi belongs Rp+ ;hence, unique way defining order among bids. Moreover, Clarkesurplus linear function received bids heterogeneous case. So, cannotexpect linear/affine rebate function types work well type profiles.prove formally.first generalize theorem work Guo Conitzer (2009). contextGuo Conitzer stated proved theorem homogeneous setting.show result holds true heterogeneous objects case also. symbol <denotes order bids agents, defined A.2.Theorem 2 Groves redistribution mechanism, deterministic, anonymous rebatefunction f DSIC iff,ri = f (v1 , v2 , . . . , vi1 , vi+1 , . . . , vn ) N(4)where, v1 < v2 < . . . < vn .Proof:part: ri takes form given equation (4), rebate agentindependent valuation. allocation rule satisfies allocative efficiency.So, mechanism still Groves hence DSIC. rebate function defineddeterministic. two agents bids, then, per ordering definedAppendix, <, ranking. Suppose agents + 1bids. Thus vi < vi+1 vi+1 < vi . So, ri = f (v1 , v2 , . . . , vi1 , vi+1 , . . . , vn )ri+1 = f (v1 , v2 , . . . , vi , vi+2 , . . . , vn ). Since vi = vi+1 , ri = ri+1 . Thus rebatefunction anonymous.part: mechanism strategyproof, rebate functionagent independent bid. So, ri depend vi . So,deterministic rebate function, ri = fi (vi ). Now, desire anonymous rebatefunction. is, rebate independent identity agent. Thus,vi = vj , ri = rj . loss generality, say vi = vi+1 , vi =v(i+1) . So, ri = ri+1 implies, fi = fi+1 . Similarly fi+1 = fi+2 on. Thus,ri = f (vi ) N .state prove main result paper.Theorem 3 redistribution mechanism feasible individually rational,cannot exist linear rebate function simultaneously satisfies following properties:137fiGujar & NarahariDSICdeterministicanonymousnon-zero redistribution index.Proof : Assume contrary exists linear function, say f , satisfiesproperties. Let v1 < v2 < . . . < vn . according Theorem 2, agenti,ri = f (v1 , v2 , . . . , vi1 , vi+1 , . . . , vn )= (c0 , ep ) + (c1 , v1 ) + . . . + (cn1 , vn )where, ci = (ci1 , ci2 , . . . , cip ) Rp , ep = (1, 1, . . . , 1) Rp , (, ) denotes innerproduct two vectors Rp . Now, show worst case performance fzero. end, study structure f , step step.Observation 1: Consider type profile (v1 , v2 , . . . , vn ) v1 = v2 = . . . = vn = (0, 0, . . . , 0).type profile, total Clarke surplus zero ri = (c0 , ep ) N . Individualrationality implies,(c0 , ep ) 0(5)Feasibility implies total redistributed amount less surplus, is,Xri = n(c0 , ep ) 6 0(6)From, (5) (6), easy see that, (c0 , ep ) = 0.Observation 2: Consider type profile (v1 , v2 , . . . , vn ) v1 = (1, 0, 0, . . . , 0) v2 =. . . , vn = (0, 0, . . . , 0). type profile, r1 = 0 6= 1, ri = c11 0 individualrationality. type profile, seenstraight forward calculationsPClarke surplus zero. Thus, feasibility, ri = (n 1)c11 = 0. implies,c11 = 0.profile, considering v1 = (0, 1, 0, . . . , 0), get c12 = 0. Similarly, oneshow c13 = c14 = . . . = c1p = 0.Observation 3: Continuing lines with, v1 = v2 = . . . = vi = ep ,vi+1 = (1, 0 . . . , 0)(0, 1, 0 . . . , 0), . . . (0, . . . , 0, 1), get, ci+1 = (0, 0, . . . , 0) p 1. Thus,ri: p + 1(cp+1 , vp+2 ) + . . . + (cn1 , vn )(cp+1 , vp+1 ) + . . . + (ci1 , vi1 )=+(ci , vi+1 ) + . . . + (cn1 , vn ) : otherwise(7)Thus rebate function linear redistribution mechanism necessarilyform Equation (7). claim redistribution index mechanism138fiRedistribution Mechanismszero. individually rational redistribution mechanism, trivial lower boundredistribution index zero. prove linear redistribution mechanism,exists type profile, fraction Clarke surplus gets redistributedzero. Consider type profile:v1v2...= (2p 1, 2p 2, . . . , p + 1, p)= (2p 2, 2p 3, . . . , p, p 1)vp1 = (p + 1, p, . . . , 3, 2)vp = (p, p 1, . . . , 2, 1)vp+1 = vp+2 . . . = vn = (0, 0, . . . , 0).seen, straightforward calculations Clarke payments, that,type profile, agent 1 pays (p 1), agent 2 pays (p 2), . . . , agent (p 1) pays1 remaining agents pay 0. Thus, Clarke payment received non-zeroseen ri = 0 agents. Hence, redistribution index linearredistribution mechanism zero.theorem provides disappointing piece news. rules possibilitylinear redistribution mechanism heterogeneous settings non-zeroredistribution index. However, two ways get around it.1. domain types Theorem 3 holds is, = Rp+ , N . One idearestrict domain types. Section 4, design worst case optimal linearredistribution mechanism valuations agents heterogeneous objectscertain type relationship.2. Explore existence rebate function linear yields non-zeroredistribution index. explore Section 5.noted impossibility result holds true defining linearrebate functions Definition 4. result may hold types linearity.example, sort bid components (n 1) agents define rebate functionlinear combination (n 1)p elements. point, exploredlinear rebate functions.4. Redistribution Mechanism Heterogeneous ObjectsValuations Scaling Based RelationshipConsider scenario objects identical valuations objectsrelated derived single parameter. motivating example, considerwebsite people put ads free assume pslots available advertisements n agents interested displaying ads.Naturally, every agent higher preference higher slot. Another motivatingexample could be, university web site p slots display news139fiGujar & Naraharivarious departments. Define click rate slot number times adclicked, ad displayed slot, divided number impressions. Letclick rates slots 1 2 3 . . . p . Assume agentvalue click user, say vi . So, agents value j th slotj vi . Let us use phrase valuations scaling based relationship describevaluations. define formally below.Definition 6 say valuations agents scaling based relationshipexist positive real numbers 1 , 2 , 3 , . . . , p > 0 that, agent N , valuation object j, say j , form j = j vi , vi R+ private signalobserved agent i.Without loss generality, assume, 1 2 3 . . . p > 0. (For simplifyingequations, assume (n p) virtual objects, p+1 = p+2 = . . . =n = 0). immediately note homogeneous setting special case arises1 = 2 = 3 = . . . = p > 0setting, design Groves mechanism almost budget balancedoptimal worst case. mechanism similar Guo Conitzer (2009)proof uses line arguments.4.1 Proposed Mechanismuse linear rebate function. propose following mechanism:agents submit bids.bids sorted decreasing order.highest bidder allotted first object, second highest bidderallotted second object, on.Agent pay ti ri , ti Clarke payment ri rebate.ti =pX(j j+1 )vj+1j=iLet agent rebate be,ri = c0 + c1 v1 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vnci defined follows.mechanism required individually rational feasible.mechanism individually rational iff ri 0 N . is, N ,c0 + c1 v1 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vn 0.140fiRedistribution Mechanismsmechanism feasiblethePtotal redistributedpayment less equalPPsurplus. is, ri = ti ri 0, where,t=pXj(j j+1 )vj+1 .j=1setup, derive c0 , c1 , . . . , cn1 maximize fractionsurplus redistributed among agents.Step 1: First, claim c0 = c1 = 0. proved follows. Considertype profile, v1 = v2 = . . . = vn = 0.Pthis type profile, individual rationality impliesri = c0 0 = 0. feasibility, ri = nc0 = 0. is, c0 zero.Similarly, considering type profile v1 = 1, v2 = . . . = vn = 0, get c1 = 0.Step 2: Using c0 = c1 = 0,feasibility condition written as:)(n1X(j 1)(j1 j ) (j 1)cj1 (n j)cj vj (n 1)cn1 vn 0(8)j=2individual rationality condition writtenc2 v2 + . . . + ci1 vi1 + ci vi+1 + . . . + cn1 vn 0Step 3: say mechanisms redistribution index e, mean,is,n1Xj=2e(j 1)(j1 j ) + (j 1)cj1 + (n j)cj vj +(n 1)cn1 vn 0(9)Priet,(10)Step 4: Define 1 = 1 2 , = 2, . . . , n 1, let = i(i i+1 ) + i1 . Now,inequalities (8), (9), (10) satisfied values v1 v2 . . . vn 0.Theorem (1), need satisfy following set inequalities:Pji=2 ci 0 j = 2, . . . n 1e (n 2)c2 1Pi1 1ei1 n j=2 cj + (n i)ci i1 = 3, . . . , pPep n i1p = p + 1, . . . , n 1j=2 cj + (n i)cPn1ep n j=2 cj pNow, mechanism designer wishes design mechanism maximizes e subjectconstraints.PDefine xj = ji=2 ci j = 2, . . . , n 1. equivalent solving followinglinear program.141fiGujar & Naraharimaximize es.t.e1 (n 2)x2 1ei1 ixi1 + (n i)xi i1 = 3, . . . , pep ixi1 + (n i)xi p = p + 1, . . . , n 1ep nxn1 pxi 0 = 2, . . . , n 1(11)So, given n p, social planner solve optimization problemdetermine optimal values e, c2 , c3 , . . . , cn1 . would interest derive closedform solution problem.discussion summarized following theorem.Theorem 4 valuations agents scaling based relationship, pn > p + 1, linear redistribution mechanism obtained solving LP (11) worst caseoptimal among Groves redistribution mechanisms feasible, individually rational,deterministic, anonymous. mechanism example mechanismnon-zero redistribution index.Proof:worst case optimality mechanism proved following line argumentsGuo Conitzer (2009).per impossibility Theorem 3, linear redistribution mechanism general heterogeneous setting non-zero efficiency. However, objects scalingbased relationship, linear redistribution mechanism, obtained solving LP (11)non-zero efficiency least (n, p) instances. obtained actually solvingLP (for example, using MATLAB) various values n p. certainly provesthat, least n = 10, 12, 14, p = 2, 3, 4, . . . , 8 valuations scaling basedcorrelation, worst case optimal mechanism given LP (11) non-zero redistribution index. obtain upper bound redistribution index redistributionmechanism LP (11).Claim 1 e solution LP (11),Be min,BPPnn.B = i=2,4,6,... i1where, = i=1,3,5,... i1LP (11) writtenmaximize es.t.e xx0142fiRedistribution Mechanismsx = (x2 , x3 , . . . , xn1 ) R+ n2 = (1 , 2 , . . . , p , p , . . . , p ) R+ n1n20003n30004n40= ...............0n1 100nNow, = (y1 , y2 , . . . , yn1 ) Rn1 range iffnnnny1 +y3 + =y2 +y4 +2435(12)nnnNow,(M x)i{1, 2, 3, . . . , n 1}.i+1i+1i+1summing inequalities odd using (12), get e B summingeven get e B A. proves claim.everified using MATLAB n = 10, 12, 14 p= 2, 3,. . . 8, redistributionBindex proposed mechanism fact, e = min B,A .5. Non-linear Redistribution Mechanisms Heterogeneous Settingnote homogeneous objects case special case heterogeneousobjects case bidder submits bid objects. Thus, cannotexpect redistribution mechanism perform better homogeneous objects case.n p + 1, worst case redistribution zero homogeneous caseheterogeneous case (Guo & Conitzer, 2009; Moulin, 2009). So, assumen > p + 1. section, propose two redistribution mechanisms non-linear rebatefunctions. construct redistribution scheme applying mechanism proposedBailey (1997) heterogeneous settings. refer proposed mechanismheterogeneous objects BAILEY-CAVALLO redistribution mechanism. crucialnote non-zero redistribution index BAILEY-CAVALLO mechanismtrivially follow mechanism work Bailey. rewrite WCOmechanism extend rebate functions heterogeneous objects settings. callmechanism HETERO.mechanisms, namely BAILEY-CAVALLO HETERO, objectsassigned agents value most. Clarke payments collectedagents surplus redistributed among agents according rebate functionsdefined mechanism. Hence, Groves redistribution mechanisms henceDSIC.stated above, n (p + 1), redistribution index redistribution mechanism zero. case n > p + 1, redistribution index linearredistribution mechanism zero (Theorem 3). prove, n (2p + 1),143fiGujar & NarahariBAILEY-CAVALLO non-zero redistribution index. conjecture HETEROworst case optimal, mechanism better redistribution index HETERO. also conjecture HETEROs redistribution index WCO,non-zero n > (p + 1). Thus, n {p + 2, p + 3, . . . , 2p}, stillredistribution mechanism non-zero redistribution index proved.5.1 BAILEY-CAVALLO MechanismFirst, consider case p = 1. Let valuations agents object be,v1 v2 . . . vn . agent highest valuation receive object wouldpay second highest bid. Cavallo (2006) proposed rebate function as:r1 = r2 = n1 v3ri = n1 v2 > 2similar mechanism independently proposed Porter et al (2004). Motivatedscheme, propose scheme heterogeneous setting. Suppose agent excludedsystem. let ti Clarke surplus system (defined Table 1).Define,1ri B = ti N(13)nClarke surplus always positive, ri B 0 i. Thus, scheme satisfiesindividual rationality.P 1P Bn n1 = t. Thus,=ti (revenue monotonicity). So,ntrischeme feasible. (The revenue monotonicity follows factvaluations non-negative unit demand preferences. Gul Stacchetti (1999)showed unit demand preferences, VCG payments coinsidesmallest Walrasian prices turn would decrease addition agent.Thus addition agent cannot decrease total payments.)2show BAILEY-CAVALLO scheme non-zero redistribution indexn 2p + 1. First state two lemmas. proof given Appendix B.lemmas useful designing redistribution mechanisms heterogeneous settingswell analysis mechanisms. Lemma 2 used show redistribution indexBAILEY-CAVALLO mechanism non-zero. Lemma 1 used find allocativelyefficient outcome settings consideration. Lemma 1 also useful determiningClarke payments.Lemma 1 sort bids agents object, then:1. optimal allocation, allocatively efficient allocation, consistagents bids among p highest bids object.2. Consider optimal allocation k . p agents receiving objects koptimal allocation (ondropped, always exists allocation ki2. thank annonymous reviewer pointing reference.144fiRedistribution Mechanismsremaining n 1 agents) allocates objects remaining (p 1) agents., may howeverobjects (p 1) agents receive kiobjects allocated k .Lemma 2 2p agents involved deciding Clarke payment.Note: objects identical, bids (p + 1) agents involved determining Clarke payments.Now, show redistribution index BAILEY-CAVALLO mechanismnon-zero.Theorem 5 sufficient number agents (in particular, n > 2p),BAILEY-CAVALLO redistribution mechanism non-zero redistribution index.Proof: Lemma 2, shown 2p agents involveddetermining Clarke surplus. Thus, given type profile, (n 2p) agents,whom, ti = implies least n2pn redistributed.redistribution index mechanism least n2pn > 0.Note mechanism may worst case optimal. because,objects identical, WCO mechanism performs better worst case analysismechanism. So, suspect heterogeneous settings well,mechanism would optimal worst case analysis. next subsection, exploreanother rebate function, namely HETERO.5.2 HETERO: Redistribution Mechanism Heterogeneous Settingobjects identical, WCO mechanism given equation (3). givenovel interpretation it. Consider scenario one agent absentscene. Clarke payment received either pvp+1 pvp+2 depending uponagent absent. remove two agents, surplus pvp+1 pvp+2 pvp+3 , dependingupon two agents removed. Till (n p 1) agents removed, get non-zerosurplus. remove (n p) agents system, needmechanism assignment objects. So, consider cases remove kagents, where, 1 k < n p.let ti,k average payment received agent removed along kagents is, total (k + 1) agents removed comprising i. averagetaken possible selections k agents remaining (n 1) agents.rewrite WCO mechanism terms ti , ti,k . Observe that, ti , ti,k definedheterogeneous settings well. propose use rebate function defined as,riH= 1+k=np1Xk ti,k1(14)k=2k suitable weights assigned surplus generated total kagents removed system. using different k s, get different mechanisms.However, prefer choose k following.145fiGujar & Narahari5.2.1 Equivalence HETERO WCO Objects Identicaldesirable HETERO match WCO mechanism objectshomogeneous. choose Equation (14) way ensures that,objects identical, riH equation (14) equal riW CO equation (3)type profiles. Since rebate function remaining (n 1) bids, writeas, ri = f (x1 , x2 , . . . , xn1 ) x1 , x2 , . . . , xn1 bids without agent i,decreasing order. Note, case, bidder submitting bid bi R+ .Now, write, ti,k , riH , ri terms x1 , x2 , . . . , xn1 , as,p+lnp2lk1Xpk1li,k1=xp+1+ln1l=0k1riH=riW CO =k=np1Xk=1np1Xk ti,k1(15)cp+1+l xp+1+l(16)l=0where, ci , = p + 1, p + 2, . . . , n 1 given equation (2).Consider type profile (x1 = 1, x2 = 1, . . . , xp+1 = 1, xp+2 = 0, . . . , xn1 = 0).HETERO agree WCO, coefficients xp+1 equation (15) equation (16)same. consider type profile (x1 = 1, x2 = 1, . . . , xp+2 = 1, xp+3 =0, . . . , xn1 = 0). coefficients xp+1 equation (15) equation (16)same, coefficients xp+2 also equal equation (15) equation (16).Thus, coefficients xp+1 , xp+2 , . . . , xn1 equation (15) equation (16)agree.Let L = n p 1. Thus, = p + 1, . . . , n 1,i1ni1ni1XpkLkci =(17)n1k=0p+1+ksystem equations yields, = 1, 2, . . . , L,n1Li(i+1)XX(1)(L i)!p!i+j1n1=jl(n i)!j=0given by, =n1p1n1j(np)Pn1j=pl=p+i+j.146(18)fiRedistribution Mechanisms5.2.2 Properties HETEROHETERO mechanism matches WCO objects identical, HETERO mechanism satisfies individual rationality feasibility homogeneous case.two properties, however, remain shown heterogeneous case.Conjecture 1 HETERO mechanism satisfies individual rationality, feasibility, worstcase optimal, redistribution index WCO.5.2.3 Intuition Behind Individual Rationality HETEROshow agent i, riH 0 type profiles. convenience,i,j1 , j = 2, . . . , L.assume implicitly. So, say, riH = rP 1 = , j =Now, rebate given equation, r =j j j . show r 0.Note that, 1 2 . . . L 0. monotone absenceagentswould either decrease VCG payments payments remain same. So,Pji=1 0 j = 1 L, individual rationality would follow Theorem 1. observethat, general, true. important observation is, though decreasingpositive real numbers, related. example, show 1 > 0,2 > 0. experiments, describe next section, keep track 12 .observed ratio [0.5, 1]. Theorem 1 applicable, ratiovalue [0, 1].Thus, though alternately positive negative, relation among wouldmake r become negative within limits way total rebateagents less equal total Clarke payment. remains show individualrationality analytically general case. are, however, able showfollowing cases.1. Consider case p = 2. (i). n = 4, 1 = 14 . (ii). n = 5, 1 = 0.27273,2 = 0.18182. (iii). n = 6, 1 = 0.29487, 2 = 0.25641, 3 = 0.12821.2. Consider case p = 3. (i). n = 5, 1 = 15 . (ii). n = 6, 1 = 0.21875,2 = 0.15625. (iii). n = 7, 1 = 0.23810, 2 = 0.21429, 3 = 0.11905.Theorem 1, follows cases, proposed mechanism satisfies individual rationality.5.2.4 Feasibility Worst Case Optimality HETEROSimilarly, also believe that, adjust rebate functions optimally that, HETERO remains feasible worst case optimal redistribution indexWCO. Though analytical proof, provide empirical evidenceconjecture Section 6.6. Experimental Analysisperform experiments two sets. first set, consider bids real numbers.second set consider bidders submitting binary bids. use experimentsprovide empirical evidance Conjecture 1.147fiGujar & Narahari6.1 Empirical Evidence Individual Rationality HETEROSolving equations (18) challenging task. Though new mechanism extensionMoulin WCO mechanism, yet, able prove individual rationalityfeasibility HETERO analytically. therefore seek empirical evidence.6.1.1 Simulation 1consider various combinations n p. agent, object,valuation generated uniform random variable [0, 100]. run simulationsfollowing combinations n p.p = 2, n = 5, 6, . . . , 14, p = 3, n = 7, 8, . . . , 14 p = 4, n = 9, 10, . . . , 14.combination n p = 2, generated randomly 100,000 bid profiles evaluated mechanism. also kept track worst case performance mechanism100,000 bid profiles. mechanism feasible individually rational100,000 bid profiles. redistribution index mechanism upper boundedWCO mechanism. observed worst case performance100,000 random bid profiles WCO. strong indicationmechanism perform well general.6.1.2 Simulation 2: Bidders Binary ValuationSuppose bidder valuation object, either 0 1. 2np possiblebid profiles. ran experiment evaluate mechanism possible bid profilesagents binary valuations. considered p = 2 n = 5, 6, . . . , 12. foundmechanism feasible, individually rational, worst case performanceWCO mechanism. Note, indicated earlier, mechanism performbetter WCO mechanism worst case. mechanism performs equallywell WCO. Thus, though analytical proof elusive, binary valuation settings,p = 2 n = 5, 6, . . . , 12, mechanism worst case optimal.6.2 BAILEY-CAVALLO vs HETEROsubsection, compare worst case redistribution index BAILEY-CAVALLOworst case redistribution index HETERO varying number objects10 agents system. is, study worst case redistribution indexvarious p n = 10. worst case taken randomly generated 50K bid profiles.comparison depicted Figure 1. redistribution index WCO upper boundRedistribution Mechanism heterogeneous settings. However, simulationsexhaustive, worst case performance mechanisms could perhaps betterWCO. Exact worst case may worse WCO. However, simulations,never encountered situation HETERO worse WCO. seeFigure 1 BAILEY-CAVALLO mechanisms worst case performance betterHETERO, p = 3, 4, 5, 6, 7. worst case worst 50,000 randomly generatedbid profiles simulations.148fiRedistribution Mechanismsobservation made simulations time (70%),BAILEY-CAVALLO redistributes VCG surplus HETERO ever though worstcase performance worse HETERO.observations also lead question Cavallo (2008) raised contextdynamic redistribution mechanisms. really need highly sophisticated mechanism,worst case optimal, simple mechanism performs quite well general.10.9HETEROBAILEYCAVELLOWCO0.8redistribution index0.70.6n = 100.50.40.30.20.102345Number objects, (p)678Figure 1: Redistribution index vs number objects number agents = 107. Conclusionaddressed problem assigning p heterogeneous objects among n > p competingagents. valuations agents independent valuations object independent valuations objects, provedimpossibility existence linear redistribution mechanism non-zero redistributionindex (Theorem 3). explored two approaches get around impossibility.first approach, showed linear rebate functions non-zero redistribution index possible valuations objects scaling basedrelationship. settings, proposed strategyproof linear redistributionmechanism optimal worst case analysis, individually rational, feasible(Theorem 4).149fiGujar & Naraharisecond approach, relaxed linearity requirement. showed nonlinear rebate functions non-zero redistribution index possible applyingBAILEY-CAVALLO mechanism settings (Theorem 5).proposed mechanism, namely HETERO, general settings objectsheterogeneous private values agent objects independentother. mechanism deterministic, anonymous, DSIC. HETEROmechanism extends Moulin /WCO mechanism. Though analyticallyproved feasibility individual rationality, sufficient empirical evidenceconjecture mechanism feasible individually rational (Conjecture 1).would interesting see characterize situations linear redistribution mechanisms non-zero redistribution indices possible heterogeneoussettings.interesting research direction investigate individual rationality feasibilityproposed HETERO mechanism. Also, strongly believe mechanismworst case optimal. immediate future direction prove fact designmechanism worst case optimal.Another interesting problem explore characterize redistribution mechanismsworst case optimal heterogeneous settings.Acknowledgmentsfirst author would like acknowledge Infosys Technologies Ltd., awarding Infosysfellowship pursue Ph.D. authors would like thank Professor David Parkesuseful comments. authors would also like thank anonymous reviewers, whosefeedback helped lot improving paper.Appendix A. Ordering Agents Based Bid Profilesdefine ranking among agents. ranking used proving Theorem2 rebate function. theorem similar Cavallos theorem characterizationDSIC, deterministic, anonymous rebate functions homogeneous objects. wouldactually computing order among bidders. use order provingimpossibility linear rebate function desired properties.A.1 Properties Ranking Systemdefining ranking/ordering among agents, expect following propertieshold true:permutation objects corresponding permutation bid vector,(bi1 , bi2 ,. . . , bi p ) agent i, change ranking. is, rankingindependent order agents expected bid objects.Two bidders bid vectors rank.increasing bid objects, rank agent decrease.150fiRedistribution MechanismsA.2 Ranking among Agentscrucial step. First, find feasible allocations p objects amongn agents, agent receiving one object. Sort allocations, accordingvaluation allocation. Call list L. find ranking j, usesfollowing algorithm.1. Lij = L2. Delete allocations Lij contain j.3. Find first allocation Lij contains one agent j. Say k .(a) Suppose allocation contains value strictly greaterremaining allocations Lij containing j, say, j.(b) Suppose allocation contains j value strictly greaterremaining allocations Lij containing i, say, j i.4. step able decide ordering j, let = {kK|v(k) = v(k )}. Update Lij = Lij \ recur step (2) till EITHERallocation containing agent jordering j decided.5. steps give either j j i, say, j < j wellj < i.state properties ranking system <, explainexample. Let two items B, four bidders. is, p = 2, n = 4 letbids be: b1 = (4, 5), b2 = (2, 1), b3 = (1, 4), b4 = (1, 0).Now, allocation (A = 1, B = 3) highest valuation among allocations. So,agentagentagentagent1133agentagentagentagent2424Now, L13 defined procedure above, allocation (A = 2, B = 1) strictlyhigher value allocation agent 3 present. So,agent 1 agent 3.Thus,agent 1 agent 3 agent 2agent 1 agent 3 agent 4L24 , allocation (A = 2, B = 1) strictly higher value allocationagent 4 present. Thus, ranking agents is,agent 1 agent 3 agent 2 agent 4seen ranking defined above, satisfies following properties.151fiGujar & Narahari1. < defines total order set bids.2. < independent order objects.3. two bids same, equivalent order.4. increasing bid, agent decrease rank.agent < agent j, also say vi < vj .Appendix B. ProofsB.1 Proof Lemma 1Suppose optimal allocation contains agent whose bid winning object,say j, top p bids j th object. (p 1) winnersoptimal allocation. So, exists least one agent whose bid topp bids j th object win object. Thus, allocating j thobject, allocation higher valuation declared optimalallocation.Suppose agent receives object optimal allocation removedsystem. agent one bid top p bids object. So,agents bids top p bids, pth position. seenone agent optimal allocation pth positionobject wins. one agent optimal allocationpth position object win, improve allocation. Hence,removing i, one agent part newoptimal allocation.B.2 Proof Lemma 2argument follows.1. Sort bids agents object.2. optimal allocation consists agents bids p highest bidsobjects (Lemma 1).3. computing Clarke payment agent i, remove agent determineoptimal allocation. And, using bid, valuation optimal allocationwithout determine payment. done agent i.per Lemma 1, agent optimal allocation removed system,exists new optimal allocation consists least (p 1) agentsreceived objects original optimal allocation.152fiRedistribution Mechanisms4. p agents receiving objects determining paymentsinvolve removing one time, p agentsinfluence payment. Thus, 2p agents involved determiningClarke payment.ReferencesBailey, M. J. (1997). demand revealing process: distribute surplus. PublicChoice, 91 (2), 10726.Cavallo, R. (2006). Optimal decision-making minimal waste: strategyproof redistribution VCG payments. AAMAS 06: Proceedings Fifth International JointConference Autonomous Agents Multiagent Systems, pp. 882889, New York,NY, USA. ACM.Cavallo, R. (2008). Efficiency redistribution dynamic mechanism design. EC 08:Proceedings 9th ACM conference Electronic commerce, pp. 220229, NewYork, NY, USA. ACM.Clarke, E. (1971). Multi-part pricing public goods. Public Choice, 11, 1723.de Clippel, G., Naroditskiy, V., & Greenwald, A. (2009). Destroy save. EC 09:Proceedings tenth ACM conference Electronic commerce, pp. 207214, NewYork, NY, USA. ACM.Faltings, B. (2005). budget-balanced, incentive-compatible scheme social choice.Agent-Mediated Electronic Commerce, AMEC, pp. 3043. Springer.Green, J. R., & Laffont, J. J. (1979). Incentives Public Decision Making. North-HollandPublishing Company, Amsterdam.Groves, T. (1973). Incentives teams. Econometrica, 41, 617631.Gujar, S., & Narahari, Y. (2009). Redistribution mechanisms assignment heterogeneous objects. Formal Approaches Multi-Agent Systems, (FAMAS09), Vol. 494CEUR Workshop Proceedings. CEUR-WS.org.Gujar, S., & Narahari, Y. (2008). Redistribution VCG payments assignment heterogeneous objects. Papadimitriou, C. H., & Zhang, S. (Eds.), WINE, Vol. 5385Lecture Notes Computer Science, pp. 438445. Springer.Gul, F., & Stacchetti, E. (1999). Walrasian equilibrium gross substitutes. JournalEconomic Theory, 87 (1), 95124.Guo, M., & Conitzer, V. (2007). Worst-case optimal redistribution VCG payments.EC 07: Proceedings 8th ACM conference Electronic Commerce, pp. 3039,New York, NY, USA. ACM.Guo, M., & Conitzer, V. (2008a). Better redistribution inefficient allocation multiunit auctions unit demand. EC 08: Proceedings 9th ACM conferenceElectronic commerce, pp. 210219, New York, NY, USA. ACM.153fiGujar & NarahariGuo, M., & Conitzer, V. (2008b). Optimal-in-expectation redistribution mechanisms.AAMAS 08: Proceedings 7th international joint conference Autonomousagents multiagent systems, pp. 10471054, Richland, SC. International FoundationAutonomous Agents Multiagent Systems.Guo, M., & Conitzer, V. (2009). Worst-case optimal redistribution vcg paymentsmulti-unit auctions. Games Economic Behavior, 67 (1), 6998.Laffont, J., & Maskin, E. (1979). differential approach expected utility maximizingmechanisms. Laffont, J. J. (Ed.), Aggregation Revelation Preferences.Moulin, H. (2009). Almost budget-balanced VCG mechanisms assign multiple objects.Journal Economic Theory, 144, 96119.Porter, R., Shoham, Y., & Tennenholtz, M. (2004). Fair imposition. Journal EconomicTheory, 118 (2), 209228.Vickrey, W. (1961). Counterspeculation, auctions, competitive sealed tenders. JournalFinance, 16 (1), 837.154fiJournal Artificial Intelligence Research 41 (2011) 367395Submitted 03/2011; published 07/2011Opposite Smoothing: Language Model ApproachRanking Query-Specific Document ClustersOren KurlandEyal Krikonkurland@ie.technion.ac.ilkrikon@tx.technion.ac.ilFaculty Industrial Engineering ManagementTechnion Israel Institute TechnologyAbstractExploiting information induced (query-specific) clustering top-retrieved documents long proposed means improving precision top ranksreturned results. present novel language model approach ranking query-specicclusters presumed percentage relevant documents contain.previous cluster ranking approaches focus cluster whole, model utilizesalso information induced documents associated cluster. model substantially outperforms previous approaches identifying clusters containing high relevantdocument percentage. Furthermore, using model produce document ranking yieldsprecision-at-top-ranks performance consistently better initial ranking upon clustering performed. performance also favorably comparesstate-of-the-art pseudo-feedback-based retrieval method.1. IntroductionUsers search engines want see results pertaining queries highestranks returned document lists. However, attaining high precision top ranks stilldicult challenge search engines cope various (types of) queries(Buckley, 2004; Harman & Buckley, 2004).High precision top ranks also important applications rely searchintermediate step; example, question answering systems (Voorhees, 2002; CollinsThompson, Callan, Terra, & Clarke, 2004). systems provide answerusers query rather return list documents. Often, question answering systemsemploy search given document corpus using question hand query(Voorhees, 2002). Then, passages highest ranked documents analyzed extracting (compiling) answer question. Hence, important documentscontain question-pertaining information.cope fact search engine often return highest ranksresult list quite documents relevant users query, researchersproposed, among others, cluster-based result interfaces (Hearst & Pedersen, 1996; Leuski,2001). is, documents initially highest ranked clustered clusterssimilar documents. Then, user potentially exploit clustering informationquickly locate relevant documents initial result list. important questiondevising cluster-based result interfaces order present clustersusers (Leuski, 2001). order potentially reect presumed percentagerelevant documents clusters.c2011AI Access Foundation. rights reserved.fiKurland & KrikonClusters top-retrieved documents (a.k.a. query-specific clusters) also utilizedwithout user (or application uses search intermediate step) awareclustering performed. Indeed, researchers proposed using informationinduced clusters automatically re-rank initially retrieved list improve precision top ranks (Preece, 1973; Willett, 1985; Hearst & Pedersen, 1996; Liu &Croft, 2004; Kurland & Lee, 2006; Yang, Ji, Zhou, Nie, & Xiao, 2006; Liu & Croft, 2008).Much motivation employing clustering top-retrieved documents comes vanRijsbergens cluster hypothesis (van Rijsbergen, 1979), states closely associateddocuments tend relevant requests. Indeed, shown applyingvarious clustering techniques documents highly ranked initial searchproduces clusters contain high percentage relevant documents (Hearst& Pedersen, 1996; Tombros, Villa, & van Rijsbergen, 2002; Kurland, 2006; Liu & Croft,2006a). Moreover, positioning clusters constituent documents top ranksreturned results yields precision-at-top-ranks performance substantially better state-of-the-art document-based retrieval approaches (Hearst & Pedersen,1996; Tombros et al., 2002; Kurland, 2006).Thus, whether used creating eective result interfaces automatic re-rankingsearch results, whether utilized help serve users search engines applicationsrely search, query-specic clustering (i.e., clustering top-retrieved documents)result much merit. Yet, long standing challenge progress yieldsubstantial retrieval eectiveness improvements state-of-the-art retrieval approachesshow ability identify query-specic clusters contain high percentagedocuments relevant query.present novel language-model-based approach ranking query-specic clusterspresumed percentage relevant documents contain. key insightguides derivation cluster-ranking model documents stronglyassociated cluster serve proxies ranking it. Since documentsconsidered focused units clusters, serve, example, mediatorsestimating cluster-query match. Thus, previous approaches rankingvarious types clusters focus cluster whole unit (Jardine & van Rijsbergen,1971; Croft, 1980; Voorhees, 1985; Willett, 1985; Kurland & Lee, 2004; Liu & Croft,2004, 2006b), model integrates whole-cluster-based information induceddocuments associated cluster. Hence, conceptually take opposite approachcluster-based smoothing document language models recentlyproposed document ranking (Azzopardi, Girolami, & van Rijsbergen, 2004; Kurland &Lee, 2004; Liu & Croft, 2004; Tao, Wang, Mei, & Zhai, 2006; Wei & Croft, 2006);is, using cluster-based information enrich document representation purposedocument ranking.model integrates two types information induced clusters proxy(associated) documents. rst estimated similarity query. secondcentrality element (document cluster) respect reference set (documentsinitially-retrieved list clusters documents); centrality dened termstextual similarity central elements reference set (Kurland & Lee, 2005).Using either, both, types information described induced clusterwhole and/or proxy documents yields several novel cluster ranking criteria368fiA Language Model Approach Ranking Query-Specific Document ClustersLMRelevance modelOptimal clusterAP45.750.379.6TREC850.054.483.6WSJ53.658.881.5WT10G33.935.765.9Table 1: resultant p@5 performance nding optimal cluster comparisoninitial LM-based ranking upon clustering performed,optimized relevance model.integrated model. study relative contribution criteriaoverall eectiveness approach. Furthermore, show previously proposedcluster ranking methods, developed independently, derived explainedusing ranking framework.Empirical evaluation shows cluster ranking model consistently substantiallyoutperforms previously proposed methods identifying clusters contain high percentage relevant documents. Furthermore, positioning constituent documentscluster highly ranked model top list results yields precision-attop-ranks performance substantially better initial document rankingupon clustering performed. resultant performance also favorably comparesstate-of-the-art pseudo-feedback-based document retrieval method; and,approaches utilize inter-document similarities (e.g., using clusters) directly(re-)rank documents.2. Motivationrst start demonstrating performance merits ability eectively rankquery-specic clusters presumed percentage relevant documents contain.Suppose initial list documents retrieved responsequery using standard language model (LM) approach (Ponte & Croft, 1998; Laerty &Zhai, 2001). Suppose also clustering algorithm used cluster 50 highestranked documents, resultant clusters contain 5 documents each. (Specicdetails experimental setup provided Section 5.2.) dene optimal clusterone contains highest percentage relevant documents. positionconstituent documents cluster rst ranks document list returnedresponse query, resultant precision 5 (p@5) performance percentagerelevant documents cluster. contrast p@5 performanceinitial LM-based ranking. additional reference comparison use optimizedrelevance model, RM3, state-of-the-art pseudo-feedback-based query expansionapproach (Lavrenko & Croft, 2001; Abdul-Jaleel et al., 2004). performance numbersfour TREC corpora presented Table 1. (Details regarding corpora queriesused provided Section 5.2.)message rising Table 1 clear. able automatically identifyoptimal cluster, resultant performance would much betterinitial LM-based ranking upon clustering performed. Furthermore,369fiKurland & Krikonperformance also substantially better state-of-the-art retrieval approach.Similar conclusions echoed previous work using clusters top-retrieved documents (Hearst & Pedersen, 1996; Tombros et al., 2002; Crestani & Wu, 2006; Kurland,2006; Liu & Croft, 2006a; Kurland & Domshlak, 2008).3. Ranking FrameworkThroughout section assume following xed: query q, corpusN (henceforthdocuments D, initial list N documents Dinitinit )highest ranked search performed response q. assume Dinit clusteredset document clusters C l(Dinit ) = {c1 , . . . , cM } clustering algorithm1 .goal rank clusters C l(Dinit ) presumed percentage relevant documentscontain. follows use term cluster refer either setdocuments composed of, (language) model induced it. use py (x)denote language-model-based similarity (a document cluster) x (aquery cluster); describe language-model induction method Section 5.1.3.1 Cluster RankingSimilarly language model approach ranking documents (Ponte & Croft, 1998;Croft & Laerty, 2003), deference recent growing interest automaticallylabeling document clusters topic models (Geraci, Pellegrini, Maggini, & Sebastiani,2006; Treeratpituk & Callan, 2006; Mei, Shen, & Zhai, 2007), state problemranking clusters follows: estimate probability p(c|q) cluster c labeled(i.e., content described) terms q. hypothesize higherprobability is, higher percentage documents pertaining q c contains.Since q xed, use rank equivalencerankp(c|q) = p(q|c) p(c)rank clusters C l(Dinit ). Thus, c ranked combining probability p(q|c)q generated2 label c cs prior probability (p(c)) generating label.Indeed, prior work ranking various types clusters (Jardine & van Rijsbergen,1971; Croft, 1980; Willett, 1985; Voorhees, 1985; Kurland & Lee, 2004; Liu & Croft, 2004)implicitly uses uniform distribution p(c), estimates p(q|c) (in spirit) comparingrepresentation c whole unit q.Here, suggest incorporate document mediated approach estimating probability p(q|c) generating label q cluster c. Since documents consideredcoherent units clusters, might help generate informative/focusedlabels generated using representations clusters whole units.1. Clustering documents highly ranked search performed response query often termedquery-specific clustering (Willett, 1985). assume, however, clustering algorithmknowledge query hand.2. term generate convenient, assume clusters documents literally generatelabels, assume underlying generative theory presented Lavrenko Croft (2001)Lavrenko (2004), inter alia.370fiA Language Model Approach Ranking Query-Specific Document Clustersapproach conceptually opposite smoothing document representation (e.g., language model) cluster (Azzopardi et al., 2004; Kurland & Lee, 2004; Liu &Croft, 2004; Wei & Croft, 2006). follows use p(q|d) denote probabilityq generated label describing document ds content cf., language modeling approach ranking documents (Ponte & Croft, 1998; Croft & Laerty, 2003). Also,assume p(d) prior probability document generates labelprobability distribution documents corpus D.let all, only, documents corpus serve proxies label generationcluster C l(Dinit ). Consequently, assume p(d|c), probabilitychosen proxy c label generation, probability distribution deneddocuments D. Then, write using probability algebrarankp(c|q) = p(c)Xp(q|c, di )p(di |c).(1)diuse p(q|c) + (1 )p(q|di ), free parameter, estimate p(q|c, di )(Si, Jin, Callan, & Ogilvie, 2002; Kurland & Lee, 2004) Equation 1, applyingprobability algebra get following scoring principle3 clustersp(c)p(q|c) + (1 )Xp(q|di )p(c|di )p(di ).(2)diEquation 2 scores c mixture (i) probability q directly generated ccombined cs prior probability generating label, (ii) (average) probabilityq generated documents strongly associated c (as measuredp(c|di )) high prior probability p(di ) generating labels.next derive specic ranking algorithms Equation 2 making assumptionsestimation choices.3.2 Algorithmsrst make assumption, underlies (in spirit) pseudo-feedback-based retrieval models (Buckley, Salton, Allan, & Singhal, 1994; Xu & Croft, 1996; Lavrenko &Croft, 2003), probability generating q directly di (p(q|di )) quite smalldocuments di initially retrieved list Dinit ; hence, documentsrelatively little eect summation Equation 2. Furthermore, clustersC l(Dinit ) produced reasonable clustering algorithm, p(c|di ) clusterdocument association strength might assumed signicantly higher documentsDinit c documents Dinit c. Consequently,truncate summation Equation 2 allowing cs constituent documents serveproxies generating q. truncation alleviate computationalcost estimating Equation 2, also yield improved eectiveness show Section 5.3. addition, follow common practice language model framework (Croftrank3. shift notation terminology p(c|q) = score c echoes transition using(model) probabilities estimates probabilities.371fiKurland & Krikon& Laerty, 2003), specically, work utilizing cluster-based language models document retrieval (Liu & Croft, 2004; Kurland & Lee, 2004), use language-model estimatesconditional probabilities produce primary ranking principle:defcore(c) = p(c)pc (q) + (1 )Xpdi (q)pdi (c)p(di ).(3)di cNote using pd (c) p(c|d) means use probability generating label c(i.e., term-based representation c) document surrogate documentcluster association strength.remaining task estimate document cluster priors, p(d) p(c), respectively.3.2.1 Document cluster biasesFollowing common practice work language-model-based retrieval use uniform distribution document prior p(d) (Croft & Laerty, 2003), similarly assumeuniform distribution cluster prior p(c). practice would natural choice clusters want rank produced query-independent fashion.However, would like exploit fact clusters C l(Dinit ) composeddocuments initially retrieved list Dinit . case point, since Dinit retrievedresponse q, documents Dinit considered reecting Dinit content mightgood candidates generating label q (Kurland & Lee, 2005); similar argumentmade clusters C l(Dinit ) reect content. Therefore, instead using trueprior distributions, use biases represent centrality (Kurland & Lee, 2005)documents respect Dinit centrality clusters respect C l(Dinit ).4adopt recently proposed approach inducing document centrality basedmeasuring similarity document Dinit central documents Dinit (Kurland & Lee, 2005). quantify recursive centrality denition, compute PageRanks(Brin & Page, 1998) stationary distribution graph wherein vertices represent documents Dinit edge-weights represent inter-document language-model-based similaritiesdef(Kurland & Lee, 2005). set p(d) = Cent(d) Dinit 0 otherwise,Cent(d) ds PageRank score; hence, p(d) probability distribution entirecorpus D.defAnalogously, set p(c) = Cent(c) c C l(Dinit ), Cent(c) cs PageRankscore computed graph wherein vertices clusters C l(Dinit ) edge-weightsrepresent language-model-based inter-cluster similarities; therefore, p(c) probability distribution given set clusters C l(Dinit ). construction method documentcluster graphs follows constructing document-solely graphs (Kurland & Lee,2005), elaborated Appendix A.Using document cluster induced biases fully instantiate Equation 3derive ClustRanker, primary cluster ranking algorithm:4. biases true prior distributions, virtue Dinit created, is,response query. However, take care biases form valid probability distributionsshow later.372fiA Language Model Approach Ranking Query-Specific Document ClustersAlgorithmClustCentClustQueryGenClustCent ClustQueryGenDocCentDocQueryGenDocCent DocQueryGenClustCent DocCentClustQueryGen DocQueryGenClustRankerScoring function (S core(c))Cent(c)pc (q)Cent(c)pc (q)PpPdi c (c)Cent(di )Pdi c pdi (q)pdi (c)i)di c pdi (q)pdi (c)Cent(dPCent(c) + (1 P) di c pdi (c)Cent(di )pc (q) + (1 ) di c pdi (q)pdi (c)PCent(c)pc (q) + (1 ) di c pdi (q)pdi (c)Cent(di )Table 2: Summary methods ranking clusters.defcoreClustRanker (c) = Cent(c)pc (q) + (1 )Xpdi (q)pdi (c)Cent(di ).(4)di c3.2.2 Methods ranking clustersClustRanker algorithm ranks cluster c integrating several criteria: (i) ClustCentcs centrality (Cent(c)), (ii) ClustQueryGen possibility generate labelq directly c measured pc (q), (iii) DocCent centrality cs constituentdocuments (Cent(d)), (iv) DocQueryGen possibility generate q csconstituent documents measured pd (q). (Note latter two combinedcluster-document association strength, pd (c)).study eectiveness criteria (and combinations)ranking clusters, apply following manipulations ClustRanker algorithm:(i) setting 1 (0) cluster (documents) generate q, (ii) using uniformdistribution Cent(c) (over C l(Dinit )) and/or Cent(d) (over Dinit ) hence assumingclusters C l(Dinit ) and/or documents Dinit central extent; assumenumber clusters C l(Dinit ) number documents Dinit ,case clustering method employ Section 5; hence, documentuniform prior cluster uniform prior same; (iv) setting pc (q) (pd (q))constant value thereby assuming clusters C l(Dinit ) (documentsDinit ) probability directly generating q same. instance, setting 0pd (q) constant, rank c byPDocCent weighted-average centralityvalues constituent documents:di c pdi (c)Cent(di ). Table 2 presents resultantcluster ranking methods explore. ( indicates method utilizes two criteria.)3.3 Explaining Previous Methods Ranking ClustersClustRanker method, generally, Equation 3 based, usedhelp explain, derive, previously proposed methods ranking clusters.methods developed independently, part single framework,foundations described terms approach. following discussionuse uniform prior documents clusters, rank cluster c, using Equation 3,373fiKurland & KrikonPpc (q)+(1) di c pdi (q)pdi (c). Furthermore, recall framework committedlanguage models; i.e., px (y), language-model-based estimate p(y|x),replaced another estimate.Now, setting = 1, consequently considering cluster whole unit, yieldscommon cluster ranking method. is, ranking cluster based matchrepresentation whole unit query; cluster represented,example, using concatenation constituent documents (Kurland & Lee,2004; Liu & Croft, 2004) centroid-based representation constituent documentrepresentations (Voorhees, 1985; Leuski, 2001; Liu & Croft, 2008). ClustQueryGenmethod Table 2, also used previous work (Liu & Croft, 2004; Kurland& Lee, 2004; Liu & Croft, 2006b; Kurland & Lee, 2006), example approachlanguage modeling framework.hand, setting = 0 resultsP ranking c using constituent documentsrather using c whole unit:di c pdi (q)pdi (c). Several cluster ranking methodsproposed past literature ignore document-cluster association strength.practice amounts setting pdi (c) constant clusters documents.Assuming also clusters contain number documents, caseexperimental setup Section 5, rankc arithmetic mean query1 Pmatch values constituent documents, |c|di c pdi (q); |c| number documentsc. arithmetic mean bounded maxdi c pdi (q), usedprevious work ranking clusters (Leuski, 2001; Shanahan, Bennett, Evans, Hull,& Montgomery, 2003; Liu & Croft,qQ2008), geometric mean5|c|document-query match values,di c pdi (q) (Liu & Croft, 2008; Seo & Croft, 2010).Alternatively, minimal query-document match value, mindi c pdi (q), alsoutilized ranking clusters (Leuski, 2001; Liu & Croft, 2008), also constitutes lowerbound arithmetic mean.4. Related WorkQuery-specic clusters often used visualize results search help usersquickly detect relevant documents (Hearst & Pedersen, 1996; Leuski & Allan, 1998;Leuski, 2001; Palmer et al., 2001; Shanahan et al., 2003). Leuski (2001), example,orders (hard) clusters interactive retrieval system highest lowest querysimilarity exhibited constituent documents. showed Section 3.3ranking methods, others, used several reports using queryspecic clustering (Shanahan et al., 2003; Liu & Croft, 2006a), explained usingframework. Furthermore, Section 5.3 demonstrate merits ClustRankerrespect approaches.work uses information query-specic clusters smooth language modelsdocuments initial list improve document-query similarity estimate(Liu & Croft, 2004; Kurland, 2009). related vein, graph-based approaches reranking initial list, using document clusters, utilize inter-document similarity5. Liu Croft (2008) Seo Croft (2010) used geometric-mean-based language model representation clusters, rather geometric mean query-match values.374fiA Language Model Approach Ranking Query-Specific Document Clustersinformation also proposed (Diaz, 2005; Kurland & Lee, 2005, 2006; Yang et al., 2006).approaches potentially help improve performance ClustRankeralgorithm, provide higher quality document ranking begin with. Graph-basedapproaches modeling inter-item textual similarities, similar spirit methodsinducing document cluster centrality, also used text summarization, questionanswering, clustering (Erkan & Radev, 2004; Mihalcea, 2004; Mihalcea & Tarau, 2004;Otterbacher, Erkan, & Radev, 2005; Erkan, 2006a, 2006b).Ranking query-specic (and query-independent) clusters response query traditionally based comparing cluster representation query (Jardine& van Rijsbergen, 1971; Croft, 1980; Voorhees, 1985; Willett, 1985; Kurland & Lee, 2004;Liu & Croft, 2004, 2006b, 2006a). ClustQueryGen criterion, used workranking query-specic clusters language model framework (Liu & Croft, 2004;Kurland, 2009), language-model manifestation ranking approach. showeectiveness ClustQueryGen inferior ClustRanker Section 5.3.previous cluster-based document-ranking models (Kurland & Lee, 2004; Kurland,2009) viewed conceptual opposite ClustRanker method useclusters proxies ranking documents. However, models use query-similarityinformation ClustRanker integrates information centrality information.fact, show Section 5.3 centrality information often eective querysimilarity (generation) information ranking query-specic clusters; and, integration yields better performance using alone.Recently, researchers identied properties query-specic clusters contain high percentage relevant documents (Liu & Croft, 2006b; Kurland & Domshlak, 2008); among cluster-query similarity (ClustQueryGen) (Liu & Croft,2006b), query similarity clusters constituent documents (DocQueryGen) (Liu& Croft, 2006b; Kurland & Domshlak, 2008), dierences two (Liu &Croft, 2006b). properties utilized automatically deciding whether employcluster-based document-based retrieval response query (Liu & Croft, 2006b),ranking query-specic clusters (Kurland & Domshlak, 2008). latter approach(Kurland & Domshlak, 2008) relies rankings induced clusters models entirecorpus, contrast approach focuses context within initially retrievedlist. However, centrality-based methods Table 2 potentially incorporatedcluster-ranking framework (Kurland & Domshlak, 2008).work ranking query-specic clusters resembles utilizes clustercentrality information (Kurland & Lee, 2006); contrast approach, centralityinduced based cluster-document similarities. discuss approach compare Section 5.3.5. Evaluationnext evaluate eectiveness cluster ranking approach detecting query-specicclusters contain high percentage relevant documents.375fiKurland & Krikon5.1 Language-Model Inductionlanguage model induction, treat documents queries term sequences.several possible approaches representing clusters whole units (Voorhees,1985; Leuski, 2001; Liu & Croft, 2006b; Kurland & Domshlak, 2008), focusunderlying principles ranking framework. Therefore, adopt approachcommonly used work cluster-based retrieval (Kurland & Lee, 2004; Liu & Croft, 2004;Kurland & Lee, 2006; Liu & Croft, 2006a), represent cluster term sequenceresults concatenating constituent documents. order concatenationeect since dene unigram language models assume term independence.Dir[]use px() denote Dirichlet-smoothed unigram language model inducedterm sequence x (Zhai & Laerty, 2001); smoothing parameter. avoidlength bias underow issues assigning language-model probabilities long texts(Lavrenko et al., 2002; Kurland & Lee, 2005), case pd (c), adopt followingmeasure (Laerty & Zhai, 2001; Kurland & Lee, 2004, 2005, 2006), usedlanguage-model-based estimates experiments follow, unless otherwise specied(specically, relevance-model construction):fifideffifi Dir[]p();py (x) = exp pDir[0]()fifixx term sequences, Kullback-Leibler (KL) divergence. estimateempirically demonstrated eective settings wherein long texts assignedlanguage-model probabilities (Kurland & Lee, 2004, 2005, 2006).Although estimate described constitute probability distributioncase unigram language models previous work demonstrates meritsusing without normalization (Kurland & Lee, 2005, 2006).5.2 Experimental Setupconducted experiments following TREC corpora:corpusAPTREC8WSJWT10G# docs242,918528,155173,2521,692,096queries51-64, 66-150401-450151-200451-550disk(s)1-34-51-2WT10Gdata sets used previous work ranking query-specic clusters (Liu& Croft, 2004; Kurland & Lee, 2006; Liu & Croft, 2008) comparemethods. used titles TREC topics queries. applied tokenizationPorter stemming via Lemur toolkit (www.lemurproject.org), also usedlanguage model induction.set Dinit , list upon clustering performed, 50 highest rankedDir[]documents initial ranking induced entire corpus using pd(q) i.e.,standard language-model approach. initial ranking reasonable quality,set smoothing parameter, , value results optimized MAP (calculatedstandard 1000 cuto) performance. practice also facilitates comparison376fiA Language Model Approach Ranking Query-Specific Document Clustersprevious work cluster ranking (Kurland & Lee, 2006), employsapproach creating initial list 50 documents clustered. motivationusing relatively short initial list rises previous observations regarding eectivenessmethods utilize inter-document similarities among top-retrieved documents (Liu &Croft, 2004; Diaz, 2005; Kurland, 2006, 2009). documents highly ranked exhibithigh query similarity, hence, short retrieved lists could viewed providingconcise corpus context query longer lists. Similar considerations echoedwork pseudo-feedback-based query expansion, wherein top-retrieved documentsused forming new query model (Xu & Croft, 1996; Zhai & Laerty, 2001; Lavrenko &Croft, 2001; Tao & Zhai, 2006).produce set C l(Dinit ) query-specic clusters, use simple nearest-neighborsbased clustering approach known produce (some) clusters contain highpercentage relevant documents (Kurland, 2006; Liu & Croft, 2006a). Given Dinitdene cluster contains k 1 documents di Dinit (di 6= d) yieldhighest language-model similarity pdi (d). (We break ties document IDs.) highpercentages relevant documents optimal cluster presented Table 1clusters. generally, clustering approach shown eectivecluster-based retrieval (Griths, Luckhurst, & Willett, 1986; Kurland & Lee, 2004;Kurland, 2006; Liu & Croft, 2006b, 2006a; Tao et al., 2006), specically, respectusing hard clusters (Kurland, 2009).posed cluster ranking methods means increasing precisiontop ranks returned document list. Thus, evaluate cluster ranking methodpercentage relevant documents highest ranked cluster. use p@k denotepercentage relevant documents cluster size k (either 5 10),precision top k documents obtained clusters (k) constituent documentspositioned top ranks results. cluster ranking evaluation approachalso employed previous work ranking clusters (Kurland & Lee, 2006; Liu & Croft,2008) compare methods. determine statistically signicant dierencesp@k performance using Wilcoxons two-sided test condence level 95%.focus underlying principles approach potential eectiveness,specically, compare relative eectiveness contribution overallperformance dierent information types utilized methods, rst amelioratefree-parameter-values eects. end, set values free parameters incorporated methods optimize average (over queries per corpus) p@k performanceclusters size k. (Optimization based line search free-parameter valuesranges.) employ practice reference comparisons. is, independently optimize performance respect free-parameter values p@5 p@10.Then, Section 5.3.5 analyze eect free-parameter values eectivenessapproach. addition, Section 5.3.6 study performance approachfree-parameter values set using cross validation performed queries. value ,interpolation parameter ClustRanker algorithm, selected {0, 0.1, . . . , 1}.values (two) parameters controlling graph-construction methods (for inducing document cluster biases) chosen previously suggested ranges (Kurland& Lee, 2005). (See Appendix details graph construction.) value ,language model smoothing parameter, set 2000 following previous recommenda377fiKurland & Krikontions (Zhai & Laerty, 2001), except estimating pd (q) use value chosencreating Dinit maintain consistency initial ranking.important point computational overhead approach topinitial search signicant. Clustering top-retrieved documents (50case) performed quickly (Zamir & Etzioni, 1998); note frameworkcommitted specic clustering approach. Furthermore, computing PageRank scoresgraph 50 documents (clusters) induce document (cluster) centrality takesiterations Power method (Golub & Van Loan, 1996). Finally, notenumber documents corpus eect eciency approach,methods based clustering documents highly ranked initial search.5.3 Experimental Resultsfollows present analyze performance numbers cluster rankingapproach, study impact various factors eectiveness. Section 5.3.1study eectiveness ClustRanker means improving precision top ranks.end, use comparison initial ranking upon clustering performed,relevance models (Lavrenko & Croft, 2001). Then, Section 5.3.2 studyrelative performance eect various cluster ranking criteria integrated ClustRanker.compare eectiveness ClustRanker previously proposed methodscluster ranking Section 5.3.3. Section 5.3.4 compare performance ClustRanker document-based re-ranking approaches utilize inter-documentssimilarities various ways. Section 5.3.5 analyze performance sensitivityClustRanker respect free-parameter values. Finally, Section 5.3.6 analyzeperformance ClustRanker, contrast various reference comparisons,free-parameter values set using cross validation performed queries.5.3.1 Comparison Document-Based Retrievalrst question interested eectiveness (or lack thereof) ClustRankerimproving precision top ranks. Recall use ClustRanker rankclusters k ( {5, 10}) documents Dinit initially retrieved document list.described above, evaluate ClustRankers eectiveness percentage relevantdocuments cluster highly ranked. percentage p@k attainedclusters constituent documents positioned highest ranks nal result list.Table 3 compare performance ClustRanker initial ranking. Sinceinitial ranking created using standard language-model-based document retrievalperformed corpus pd (q) scoring function, document languagemodel smoothing parameter () optimized MAP, also consider optimized baselinesreference comparisons: ranking documents corpus pd (q) setoptimize (independently) p@5 p@10.see Table 3, ClustRanker posts performance substantially betterinitial ranking relevant comparisons (corpus evaluation measure). AP WT10G performance improvements also statistically signicant.Furthermore, ClustRanker almost always outperforms optimized baselines, oftensubstantial extent; several cases, improvements also statistically signicant.378fiA Language Model Approach Ranking Query-Specific Document Clustersinit. rank.opt. base.ClustRankerAPp@5 p@1045.743.246.543.752.7 50.6ioTREC8p@5 p@1050.045.651.246.457.6 50.6WSJp@5 p@1053.648.456.0 49.456.0 51.2WT10Gp@5 p@1033.928.034.128.239.8io 33.9ioTable 3: Comparison ClustRanker initial document ranking optimized baselines. Boldface marks best result column; mark statisticallysignicant dierences initial ranking, optimized baselines, respectively.init. rank.Rel ModelRel Model(Re-Rank)ClustRankerAPp@5 p@1045.743.250.348.6i51.1i 48.3i52.7i 50.6iTREC8p@5 p@1050.045.654.450.253.649.857.6 50.6WSJp@5 p@1053.648.458.4 53.2i58.8i 53.4i56.051.2WT10Gp@5 p@1033.928.035.729.936.330.139.8 33.9iTable 4: Comparison ClustRanker relevance model (RM3) used either rankentire corpus (Rel Model) re-rank initial list (Rel Model(Re-Rank)).Boldface marks best result column; marks statistically signicant difference initial ranking.Comparison Pseudo-Feedback-Based Retrieval ClustRanker algorithmhelps identify relevant documents Dinit exploiting clustering information. Pseudofeedback-based query expansion approaches, hand, dene query model basedDinit use (re-)ranking entire corpus (Buckley et al., 1994; Xu & Croft,1996). contrast two paradigms, use relevance model RM3 (Lavrenko & Croft,2001; Abdul-Jaleel et al., 2004; Diaz & Metzler, 2006), state-of-the-art pseudofeedback-based query expansion approach. use RM3 ranking entire corpusstandard, refer implementation Rel Model. Since ClustRankerthought means re-ranking initial list Dinit , also experiment using RM3re-ranking Dinit , rather entire corpus; Rel Model(Re-Rank) denotesimplementation. set values free parameters Rel Model Rel Model(ReRank) independently optimize p@5 p@10 performance. (See Appendix Bdetails regarding relevance model implementation.)see Table 4 ClustRanker outperforms relevance models AP,TREC8 WT10G; WSJ, relevance models outperform ClustRanker. performance dierences ClustRanker relevance models, however, statistically signicant. Nevertheless, results attest overall eectivenessapproach attaining high precision top ranks. later show, previous methodsranking clusters often yield performance comparable initialranking, much inferior relevance model.379fiKurland & Krikoninit. rank.p@545.7APp@1043.2TREC8p@5p@1050.045.6WSJp@5p@1053.648.4WT10Gp@5p@1033.928.0ClustCentClustQueryGenClustCent ClustQueryGen51.739.2i49.748.6i38.8i48.0i52.439.6i55.249.440.6i50.454.844.0i52.450.037.0i47.839.8i30.039.6i33.0i24.133.1iDocCentDocQueryGenDocCent DocQueryGen52.9i43.652.7i48.846.750.6i52.047.654.848.843.249.055.655.256.050.647.051.231.033.537.128.127.031.4ClustCent DocCentClustQueryGen DocQueryGen53.5i43.648.8i46.754.847.649.843.256.055.251.447.839.8i36.533.0i29.1ClustRanker52.7i50.6i57.650.656.051.239.8i33.9iTable 5: Comparison cluster ranking methods Table 2. Boldface marks bestresult column indicates statistically signicant dierenceinitial ranking.5.3.2 Deeper Inside ClustRankerturn analyze performance various cluster ranking criteria (methods)ClustRanker integrates study relative contribution overall eectiveness. (Refer back Table 2 specication dierent methods.) performancenumbers presented Table 5.rst interested comparison two types information utilizedranking, is, centrality query-similarity (generation). see Table 5almost relevant comparisons (corpus evaluation metric), using centrality information yields performance superior using query-similarity (generation)information. (Compare ClustCent ClustQueryGen, DocCent DocQueryGen,ClustCent DocCent ClustQueryGen DocQueryGen.) Specically, seecluster-query similarity (ClustQueryGen), main ranking criterion previouswork cluster ranking, yields performance much worse cluster centrality (ClustCent) cluster ranking criterion novel study. addition,note integrating centrality query-similarity (generation) information oftenyield performance better using alone, case DocCentDocQueryGen respect DocCent DocQueryGen.next turn examine relative eectiveness using cluster whole versususing constituent documents. using query-similarity (generation) information, see using documents cluster much eective usingcluster whole. (Compare DocQueryGen ClustQueryGen.) ndingattests merits using documents proxies ranking clusters underlyingidea approach. using centrality information, picture split across corpora:AP WSJ using documents cluster yields better performance usingwhole cluster, reverse holds TREC8 WT10G. (Compare DocCentClustCent.) Integrating whole-cluster-based document-based information resultsperformance corpora (much) better using less eectivetwo, sometimes even better eective two.380fiA Language Model Approach Ranking Query-Specific Document Clustersinit. rank.DinitdcAPp@5 p@1045.743.249.547.652.7 50.6iTREC8p@5 p@1050.045.654.049.857.6 50.6WSJp@5 p@1053.648.452.849.656.0 51.2WT10Gp@5 p@1033.928.039.6i 33.2i39.8i 33.9iTable 6: Performance numbers ClustRanker either documents Dinit serveproxies cluster c (denoted Dinit ), cs constituent documents serveproxies, original implementation (denoted c). Boldface marksbest result column; marks statistically signicant dierencesinitial ranking.surprise, then, ClustRanker method, integrates centralityinformation query-similarity (generation) information inducedcluster whole constituent documents, relevant comparisonseective cluster ranking method among presented Table 5.Documents Proxies Clusters ndings presented demonstratedmerits using documents proxies clusters. turn study eect performance documents selected proxies. derivation ClustRanker basedtruncating summation Equation 2 (Section 3) allow cs constituent documents serve proxies. examine variant ClustRanker wherein documentsinitial list Dinit serve cs proxies:Xdefcore(c) = Cent(c)pc (q) + (1 )pdi (q)pdi (c)Cent(di ).di Dinitseen Table 6, variant (represented row labeled Dinit )posts performance almost always better initial document rankingDinit derived. However, performance also consistently worseoriginal implementation ClustRanker (represented row labeled c)lets cs constituent documents serve proxies. Furthermore, variantClustRanker posts less statistically signicant improvements initial rankingoriginal implementation. (The performance dierences two variantsClustRanker, however, statistically signicant.) Thus, mentioned Section3, using clusters constituent documents proxies computationallyconvenient, also yields performance improvements.5.3.3 Comparison Past Approaches Ranking ClustersTable 7 compare performance ClustRanker previously proposedmethods ranking clusters. follows rst discuss methods,analyze performance patterns.previous approaches ranking (various types of) clusters compare cluster representation query (Jardine & van Rijsbergen, 1971; Croft, 1980; Kurland& Lee, 2004; Liu & Croft, 2004, 2006b). Specically, language model framework,381fiKurland & Krikonquery-specic clusters ranked probability assigned induced languagemodels query (Liu & Croft, 2004, 2006b; Kurland & Lee, 2006). Noteexactly ClustQueryGen method setup, ranks c pc (q).work using maximal (Leuski, 2001; Shanahan et al., 2003;Liu & Croft, 2008) minimal (Leuski, 2001; Liu & Croft, 2008) query-similarity valuesdocuments cluster ranking it. showed Section 3.3 approaches explained terms framework; specically, score cluster cmaxdi c pdi (q) mindi c pdi (q), respectively. However, methods originally proposed ranking hard clusters. clusters rank overlapping, rankingcriteria somewhat less appropriate result many ties cluster scores. Still,use methods baselines break ties arbitrarily also usedrecent work ranking nearest-neighbors-based clusters (Liu & Croft, 2008).6 Followingobservations regard merits representing clusters using geometric mean constituent documents representations (Liu & Croft, 2008; Seo & Croft,2010), also considergeometric mean query-similarity values documentsqQc ranking it; is, |c| di c pdi (q).7additional reference comparison consider, shown yield eectivecluster ranking performance, recently proposed (bipartite-)graph-based approach (Kurland & Lee, 2006). Documents Dinit vertices one side, clusters C l(Dinit )vertices side; edge connects document clusters ciyield highest language-model similarity pci (d), also serves weight functionedges. Then, Kleinbergs (1997) HITS (hubs authorities) algorithm rungraph, clusters ranked induced authority values. showncluster highest authority value tends contain high percentage relevantdocuments (Kurland & Lee, 2006). implementation, follow details providedKurland Lee (2006); specically, choose value {2, 4, 9, 19, 29, 39, 49}optimize p@k performance clusters size k.Table 7 presents comparison ClustRanker reference comparisonsdescribed. p@k (k {5, 10}) reported cluster ranking method percentagerelevant documents highest ranked cluster, wherein clusters contain k documentseach.see Table 7 ClustRanker outperforms reference comparisons almost cases. Many performance dierences also statistically signicant.Furthermore, ClustRanker cluster ranking method Table 7 consistentlyoutperforms initial ranking. Moreover, ClustRanker posts statistically signicantimprovements initial ranking cluster ranking methods do.6. noted above, previous work cluster-based retrieval demonstrated merits using overlappingnearest-neighbors-based clusters respect using hard clusters (Kurland, 2009). Indeed, recent workcluster ranking focused ranking nearest-neighbor-based clusters (Kurland & Lee,2006; Liu & Croft, 2006b, 2006a, 2008; Seo & Croft, 2010).7. note original proposals (Liu & Croft, 2008; Seo & Croft, 2010) geometric meanlanguage models used term level rather query-assigned score level use here.maintain consistency cluster-ranking methods explored, use geometric meanquery-assigned score level; and, hasten point geometric-mean-based languagemodel (Liu & Croft, 2008; Seo & Croft, 2010) could used instead standard language modelclusters ClustRanker reference comparisons potentially improve performance.382fiA Language Model Approach Ranking Query-Specific Document Clustersp@545.7APp@1043.2p@550.039.2i38.8i39.6i40.6i44.0i37.0i30.024.141.840.338.8i41.651.246.633.929.2SM (c) = mindi Dinit pdi (q)qQdefSGeoM ean (c) = |c| di c pdi (q)47.046.746.448.448.447.831.425.944.446.7i50.049.656.050.637.431.8iSHIT (c)49.547.250.846.653.649.026.7i23.9iSClustRanker (c)52.7icMg50.6icM57.6cMmh50.6cM56.0cm51.2c39.8icMmh33.9icMmhinit. rank.defSClustQueryGen (c) = pc (q)defSM ax (c) = maxdi Dinit pdi (q)defTREC8p@1045.6p@553.6WSJp@1048.4p@533.9WT10Gp@1028.0Table 7: Comparison ClustRanker previously proposed methods ranking clusters. (S stands cluster-scoring function.) Boldface marks best resultcolumn; marks statistically signicant dierence methodinitial ranking; c, M, m, g, h mark statistically signicant dierencesClustRanker ClustQueryGen, Max, Min, GeoMean HITS methods,respectively.APinit. rank.HITSClustCentDocCentClustCent DocCentp@545.749.551.752.9ih53.5ihp@1043.247.248.6i48.848.8iTREC8p@5 p@1050.045.650.846.652.449.452.048.854.8 49.8WSJp@5 p@1053.648.453.649.054.850.055.650.656.0 51.4WT10Gp@5p@1033.928.026.723.9i39.8ih 33.0ih31.0h28.1hih39.833.0ihTable 8: Comparison centrality-solely approaches ranking clusters HITSbased method (Kurland & Lee, 2006). Boldface marks best performancecolumn; h mark statistically signicant dierences initial rankingHITS method, respectively.Comparison HITS-Based Approach HITS-based method (Kurland & Lee, 2006) utilizes cluster centrality information induced cluster-documentgraph. ClustRanker method, hand, integrates centrality informationinduced document-solely cluster-solely graphs query-similarity (generation) information. Table 8 contrast resultant performance using dierentnotions centrality utilized two methods. present performancecentrality-solely-based methods ClustCent, DocCent, ClustCent DocCentHITS approach (Kurland & Lee, 2006).see Table 8 centrality-solely-based approaches outperformHITS-based method relevant comparisons. results attest eective utilization (a specic type of) centrality information framework.383fiKurland & Krikon5.3.4 Comparison Utilizing Inter-Document Similarities DirectlyRank DocumentsRanking clusters based presumed percentage relevant documents contain,ClustRanker, one approach utilizing inter-document similarities improvedocument-ranking eectiveness. Alternatively, inter-document similarities exploiteddirectly rank documents. example, re-ranking principle demonstratedeective rewarding documents initially highly ranked, highlysimilar many documents initial list (Balinski & Danilowicz, 2005; Diaz,2005; Kurland & Lee, 2005). Specically, using DocCent component ClustRanker,is, PageRank score document (Cent(d)) induced document-similaritygraph, scaling value pd (q) initial (query similarity) scoreshown eective re-ranking criterion (Kurland & Lee, 2005). usePR+QuerySim denote method.Another approach consider ranking documents using clusters formextended document representation. (In language model terms translates clusterbased smoothing.) Specically, use Interpolation algorithm (Kurland & Lee, 2004),shown highlyPeective re-ranking (Kurland, 2009). documentscored pd (q) + (1 ) cC l(Dinit) pc (q)pd (c); free parameter. is,document rewarded direct match query (pd (q)), criterionused creating initial ranking, query match clusters (pc (q))strongly associated (as measured pd (c)). words, Interpolationmodel backs document representation cluster-based representation.Interpolation model could conceptually viewed generalization methods usesingle cluster (Liu & Croft, 2004; Tao et al., 2006) topic model (Wei & Croft, 2006)smoothing document language model. Furthermore, note Interpolationuses clusters document proxies ranking documents, ClustRanker method usesdocuments cluster proxies ranking clusters.Table 9 compare performance ClustRanker PR+QuerySimInterpolation methods described. performance Interpolation independently optimized p@5 p@10 using clusters 5 10 documents, respectively,case ClustRanker; value chosen {0, 0.1, . . . , 0.9}. performance PR+QuerySim also independently optimized p@5 p@10, settinggraph degree parameter () 4 9 respectively, selecting value{2, 4, 9, 19, 29, 39, 49}. (Setting graph out-degree parameter value x amountsdocument transfer centrality support x documents; hence, usingvalues 4 9 amounts considering local neighborhoods 5 10 documentssimilarity space, respectively; conceptually reminiscent using clusters size 510 respectively. Refer Appendix details.)see Table 9 ClustRanker outperform PR+QuerySim Interpolationrelevant comparisons. (Several performance dierences formerstatistically signicant, latter not.) Specically, relativeperformance improvements WT10G quite substantial. (We hasten point out,however, Interpolation posts statistically signicant performance improvementsinitial ranking ClustRanker does.)384fiA Language Model Approach Ranking Query-Specific Document Clustersinit. rank.PR+QuerySimInterpolationClustRankerAPp@5 p@1045.743.249.549.5i51.3i 50.3i52.7ip 50.6iTREC8p@5 p@1050.045.656.0 51.0i55.6i 49.6i57.6 50.6WSJp@5 p@1053.648.457.250.456.852.456.051.2WT10Gp@5 p@1033.928.035.930.436.131.8i39.8ip 33.9ipTable 9: Comparison re-ranking methods utilize inter-document similaritiesdirectly rank documents. Boldface marks best result column. Statisticallysignicant dierences initial ranking PR+QuerySim markedp, respectively. statistically signicant dierencesClustRanker Interpolation.all, see ranking clusters done ClustRanker result (document)re-ranking performance least eective (and often eective)methods utilize inter-document similarities directly rank documents.5.3.5 Performance-Sensitivity Analysisnext turn analyze eect varying values free parameters ClustRanker incorporates performance. rst parameter, , controls reliancecluster whole unit versus constituent documents. (Refer back Equation 4Section 3 details.) Figure 1 depicts p@5 performance ClustRanker, clusters5 documents, function ; p@10 performance patterns ClustRankerclusters 10 documents similar, omitted avoid cluttering presentation.see Figure 1 AP, TREC8 WT10G, values resultperformance (much) better initial ranking; WSJ, 0.4 resultsperformance superior initial ranking. Furthermore, AP, TREC8,WT10G, = 0.4, strikes good balance using cluster wholeusing constituent documents, yields (near) optimal performance; WSJ, smaller values(specically, = 0), result weight put clusters constituentdocuments, eective. Thus, witness importance using clustersconstituent documents proxies ranking cluster.graph-based method used ClustRanker inducing document (and cluster)centrality depends two free parameters: (the number nearest neighbors consideredelement graph), (PageRanks damping factor); see Appendixdetails. noted above, document graph cluster graph constructedusing values two parameters. Figures 2 3 depict eectvalues , respectively, p@5 performance ClustRanker clusters 5documents.see Figure 2 values result performance (often much)better initial ranking. general, small values yield best performance. nding accordance reported previous work using385fiKurland & KrikonAPTREC8Effect p@5, corpus=APEffect p@5, corpus=TREC8545852565448p@5p@5504652445042ClustRankerinit. rank.4000.10.20.30.40.50.60.70.8ClustRankerinit. rank.480.9100.10.20.30.40.50.60.70.80.910.91WSJWT10GEffect p@5, corpus=WSJEffect p@5, corpus=WT10G584057563854p@5p@55553363452513250ClustRankerinit. rank.4900.10.20.30.40.50.60.70.8ClustRankerinit. rank.300.9100.10.20.30.40.50.60.70.8Figure 1: Eect varying p@5 performance ClustRanker.nearest-neighbor-based graphs ranking documents initially retrieved list usingdocument-solely graphs (Diaz, 2005; Kurland & Lee, 2005).Figure 3 shows almost every value , resultant performance ClustRankertranscends initial ranking; many cases, improvement quite substantial.5.3.6 Learning Free-Parameter ValuesHeretofore, studied performance ClustRanker, analyzed eectivenessinformation types utilizes, ameliorating free-parameter values eects.is, reported performance parameter values result optimized average p@kentire set queries per corpus. applied practice referencecomparisons considered, resulted comparing potential eectivenessapproach previously suggested ones. addition, studiedprevious section eect values free parameters incorporated ClustRanker(average) performance.turn study question whether eective values free parametersClustRanker generalize across queries; is, whether values learned.perform study, employ leave-one-out cross validation procedure. query,free parameters ClustRanker set values yield optimal average p@k386fiA Language Model Approach Ranking Query-Specific Document ClustersAPTREC8Effect p@5, corpus=APEffect p@5, corpus=TREC85458525650p@5p@5544852465044ClustRankerinit. rank.422 49192939ClustRankerinit. rank.48492 4919293949WSJWT10GEffect p@5, corpus=WSJEffect p@5, corpus=WT10G58425740563854p@5p@555533652513450ClustRankerinit. rank.492 49192939ClustRankerinit. rank.32492 4919293949Figure 2: Eect varying , one graph parameters (refer Appendix A),p@5 performance ClustRanker.queries corpus. Then, report resultant average p@kqueries per corpus. Thus, reported p@k numbers based learning performedp@k optimization metric.contrast performance ClustRanker reference comparisonsused above. Specically, document-based ranking baselines: (i) initial ranking, (ii)relevance model used rank entire corpus (Rel Model), (iii) relevance modelused re-rank initial list (Rel Model(Re-Rank)); and, cluster ranking methods: (i)defdefdefcoreClustQueryGen (c) = pc (q), (ii)S coreM ax (c) = maxdi Dinit pdi (q), (iii) coreM (c) =qQdefmindi Dinit pdi (q), (iv) coreGeoM ean (c) = |c| di c pdi (q), (v) coreHIT (c).reference comparisons incorporate free parameters Rel Model, Rel Model(Re-Rank),HITS employ leave-one-out cross validation set free-parameter valuesClustRanker. performance numbers methods presented Table10.rst observation based Table 10 ClustRanker outperforms initialranking relevant comparisons; improvements quite substantial.387fiKurland & KrikonAPTREC8Effect p@5, corpus=APEffect p@5, corpus=TREC85458525650p@5p@5544852465044420.050.1ClustRankerinit. rank.0.20.30.40.50.60.70.8480.050.10.90.95ClustRankerinit. rank.0.20.30.40.50.60.70.80.90.95WSJWT10GEffect p@5, corpus=WSJEffect p@5, corpus=WT10G58425740563854p@5p@555533652513450490.050.1ClustRankerinit. rank.0.20.30.40.50.60.70.8320.050.10.90.95ClustRankerinit. rank.0.20.30.40.50.60.70.80.90.95Figure 3: Eect varying , one graph parameters (refer Appendix A),p@5 performance ClustRanker.exception WSJ corpus, relevance models alsooutperform initial ranking terms p@5. Thus, seems query-variability issues,aect ability learn eective free-parameter values, quite eectperformance methods WSJ.also see Table 10 except WSJ, ClustRanker outperforms previously proposed cluster ranking methods almost relevant comparisons. Manyperformance improvements substantial statistically signicant.seen Table 10, ClustRanker method also outperformsrelevance models (Rel Model Rel Model(Re-Rank)) majority relevant comparisons (corpus evaluation measure). single case ClustRankeroutperformed statistically signicantly manner relevance models (p@10WSJ), WT10G ClustRanker posts statistically signicant improvements relevance models, performance dierences quite striking. Furthermore,observe contrast ClustRanker, previously proposed cluster ranking methods often post performance much worse many cases statistically signicantdegree relevance models. Somewhat exception ranking clusters388fiA Language Model Approach Ranking Query-Specific Document ClustersAPTREC8p@1045.6init. rank.p@545.7p@1043.2p@550.0Rel ModelRel Model(Re-Rank)49.951.1i48.4i45.850.850.450.249.852.052.039.2ir38.8ir39.6ir40.6ir41.8r40.3r38.8irdefSClustQueryGen (c) = pc (q)defSM ax (c) = maxdi Dinit pdi (q)defp@553.6WSJp@1048.4p@533.9WT10Gp@1028.030.4i36.329.227.844.0ir 37.0ir30.024.1r41.6r51.2r 46.6r33.929.248.4r 47.8r31.425.937.4r31.8i52.652.6SM (c) = mindi Dinit pdi (q)qQdefSGeoM ean (c) = |c| di c pdi (q)47.046.746.448.4r44.4r46.7i50.049.656.0r 50.6rSHIT (c)48.547.250.843.2r53.646.825.5i23.9rClustRanker52.3icM g48.3ic53.2c46.2c38.6rcM31.2cm56.8cM mh 49.4cMTable 10: Performance results using leave-one-out cross validation set freeparameter values. Boldface marks best performance per column. Statistically signicant dierences method initial ranking markedi. Statistically signicant dierences ClustRanker cluster rankingmethods, ClustQueryGen, Max, Min, GeoMean, HITS marked c,M, m, g, h, respectively. Statistically signicant dierences clusterranking method Rel Model Rel Model(Re-Rank) marked r, respectively.geometric mean constituent documents query-similarity values (GeoMean):WT10G WSJ performance better relevance models; however,TREC8 AP performance somewhat inferior relevance models.all, ndings presented attest ClustRanker, learning freeparameter values, (i) highly eective method obtaining high precision top ranks,(ii) much eective previously proposed methods ranking clusters.6. Conclusions Future Workpresented novel language model approach ranking query-specific clusters, is,clusters created documents highly ranked initial search performed responsequery. ranking clusters based presumed percentage relevant documents contain.cluster ranking model integrates information induced cluster wholeunit induced documents associated cluster. Two typesinformation exploited approach: similarity query centrality.latter reects similarity central items reference set, may documentsinitial list, clusters documents.Empirical evaluation showed using approach results precision-at-top-ranksperformance substantially better initial ranking upon clustering employed. Furthermore, performance often transcends state-of-the-artpseudo-feedback-based query expansion method, namely, relevance model. addition,showed approach substantially eective identifying clusters contain389fiKurland & Krikoning high percentage relevant documents previously proposed methods rankingclusters.future work intend explore additional characteristics document clustersmight attest percentage relevant documents contain; example, clusterdensity measured inter-document-similarities within cluster. Incorporatingcharacteristics framework principled way interesting challenge.Acknowledgmentsthank reviewers helpful comments. also thank Lillian Lee helpfulcomments work presented paper, discussions led ideas presentedhere; specically, cluster-centrality induction method fruit joint work LillianLee. paper based upon work supported part Israel Science Foundationgrant no. 557/09, National Science Foundation grant no. IIS-0329064,Googles faculty research award, IBMs SUR award. opinions, ndingsconclusions recommendations expressed material authorsnecessarily reect sponsoring institutions.Appendix A. Centrality Inductionbriey describe previously proposed graph-based approach inducing documentcentrality (Kurland & Lee, 2005), use inducing document cluster centrality.Let (either Dinit , initial list documents, C l(Dinit ), set clusters)set items, G = (S, S) complete directed graph dened S.weight w t(s1 s2 ) edge s1 s2 (s1 , s2 S) dened(ps2 (s1 ) s2 N bhd(s1 ; ),defw t(s1 s2 ) =0otherwise,N bhd(s1 ; ) set items {s1 } yield highest ps (s1 ). (Tiesbroken item ID.)use PageRank approach (Brin & Page, 1998) smooth edge-weight function:w t[] (s1 s2 ) = (1 )w t(s1 s2 )1;+ P|S|w t(s1 )free parameter.Thus, G edge-weight function w t[] constitutes ergodic Markov chain,stationary distribution exists. set Cent(s), centrality value s,stationary probability visiting s.Following previous work (Kurland & Lee, 2005), values chosen{2, 4, 9, 19, 29, 39, 49} {0.05, 0.1, . . . , 0.9, 0.95}, respectively, optimize p@kperformance given algorithm clusters size k. use parameter settingdocument-graph (S = Dinit ) cluster-graph (S = C l(Dinit )), therefore inducing document cluster centrality methods based two freeparameters.390fiA Language Model Approach Ranking Query-Specific Document ClustersAppendix B. Relevance Modelestimate standard relevance model, RM1, shown yield better performance RM2 relevance model (Lavrenko & Croft, 2003), employimplementation detailed Lavrenko Croft (2003). Let w denote term voJM []cabulary, {qi } set query terms, pd() denote Jelinek-Mercer smootheddocument language model smoothing parameter (Zhai & Laerty, 2001). RM1deneddefpRM 1 (w; ) =XdDinitJM [](w) PpdJM [](qi )pd.Q JM [](qi )dj DinitpdjQpractice, RM1 clipped setting pRM 1 (w; ) 0 termshighest pRM 1 (w; ) begin (Connell et al., 2004; Diaz & Metzler, 2006); normalization performed yield probability distribution, denotepRM 1 (; , ). improve performance, RM1 anchored original query via interpolation using free parameter (Abdul-Jaleel et al., 2004; Diaz & Metzler, 2006).results RM3 model:defpRM 3 (w; , , ) = pqM LE (w) + (1 )pRM 1 (w; , );pqM LE (w) maximum likelihood estimate term w respect q. Documentsfifififi Dir[]() .corpus ranked minus cross entropy CE pRM 3 (; , , ) fifi pdfree-parameter values chosen following ranges independently optimize p@5 p@10 performance: {0, 0.1, 0.3, . . . , 0.9}, {25, 50, 75, 100, 500,1000, 5000, ALL}, stands using terms corpus (i.e., clipping),{0, 0.1, 0.2, . . . , 0.9}; set 2000, cluster-based algorithms, followingprevious recommendations (Zhai & Laerty, 2001).ReferencesAbdul-Jaleel, N., Allan, J., Croft, W. B., Diaz, F., Larkey, L., Li, X., Smucker, M. D., &Wade, C. (2004). UMASS TREC 2004 novelty hard. ProceedingsThirteenth Text Retrieval Conference (TREC-13), pp. 715725.Azzopardi, L., Girolami, M., & van Rijsbergen, K. (2004). Topic based language modelsad hoc information retrieval. Proceedings International Conference NeuralNetworks IEEE International Conference Fuzzy Systems, pp. 32813286.Balinski, J., & Danilowicz, C. (2005). Re-ranking method based inter-document distances. Information Processing Management, 41 (4), 759775.Brin, S., & Page, L. (1998). anatomy large-scale hypertextual web search engine.Proceedings 7th International World Wide Web Conference, pp. 107117.Buckley, C. (2004). current IR engines fail. Proceedings SIGIR, pp. 584585.Poster.391fiKurland & KrikonBuckley, C., Salton, G., Allan, J., & Singhal, A. (1994). Automatic query expansion usingSMART: TREC3. Proceedings Third Text Retrieval Conference (TREC-3),pp. 6980.Collins-Thompson, K., Callan, J., Terra, E., & Clarke, C. L. (2004). eect documentretrieval quality factoid question answering performance. Proceedings SIGIR,pp. 574575. Poster.Connell, M., Feng, A., Kumaran, G., Raghavan, H., Shah, C., & Allan, J. (2004). UMassTDT 2004. TDT2004 System Description.Crestani, F., & Wu, S. (2006). Testing cluster hypothesis distributed informationretrieval. Information Processing Management, 42 (5), 11371150.Croft, W. B. (1980). model cluster searching based classication. InformationSystems, 5, 189195.Croft, W. B., & Laerty, J. (Eds.). (2003). Language Modeling Information Retrieval.No. 13 Information Retrieval Book Series. Kluwer.Diaz, F. (2005). Regularizing ad hoc retrieval scores. Proceedings FourteenthInternational Conference Information Knowledge Management (CIKM), pp.672679.Diaz, F., & Metzler, D. (2006). Improving estimation relevance models using largeexternal corpora. Proceedings SIGIR, pp. 154161.Erkan, G. (2006a). Language model based document clustering using random walks.Proceedings HLT/NAACL, pp. 479486.Erkan, G. (2006b). Using biased random walks focused summarization. ProceedingsDocument Understanding Conference (DUC).Erkan, G., & Radev, D. R. (2004). LexPageRank: Prestige multi-document text summarization. Proceedings EMNLP, pp. 365371. Poster.Geraci, F., Pellegrini, M., Maggini, M., & Sebastiani, F. (2006). Cluster generationcluster labeling Web snippets: fast accurate hierarchical solution. Proceedings 13th international conference string processing informationretrieval (SPIRE), pp. 2537.Golub, G. H., & Van Loan, C. F. (1996). Matrix Computations (Third edition). JohnsHopkins University Press.Griths, A., Luckhurst, H. C., & Willett, P. (1986). Using interdocument similarity information document retrieval systems. Journal American Society InformationScience (JASIS), 37 (1), 311. Reprinted Karen Sparck Jones Peter Willett,eds., Readings Information Retrieval, Morgan Kaufmann, pp. 365373, 1997.Harman, D., & Buckley, C. (2004). NRRC reliable information access (RIA) workshop.Proceedings SIGIR, pp. 528529. Poster.Hearst, M. A., & Pedersen, J. O. (1996). Reexamining cluster hypothesis: Scatter/Gather retrieval results. Proceedings SIGIR, pp. 7684.392fiA Language Model Approach Ranking Query-Specific Document ClustersJardine, N., & van Rijsbergen, C. J. (1971). use hierarchic clustering informationretrieval. Information Storage Retrieval, 7 (5), 217240.Kleinberg, J. (1997). Authoritative sources hyperlinked environment. Tech. rep. Research Report RJ 10076, IBM.Kurland, O. (2006). Inter-document similarities, language models, ad hoc retrieval.Ph.D. thesis, Cornell University.Kurland, O. (2009). Re-ranking search results using language models query-specicclusters. Journal Information Retrieval, 12 (4), 437460.Kurland, O., & Domshlak, C. (2008). rank-aggregation approach searching optimalquery-specic clusters. Proceedings SIGIR, pp. 547554.Kurland, O., & Lee, L. (2004). Corpus structure, language models, ad hoc informationretrieval. Proceedings SIGIR, pp. 194201.Kurland, O., & Lee, L. (2005). PageRank without hyperlinks: Structural re-ranking usinglinks induced language models. Proceedings SIGIR, pp. 306313.Kurland, O., & Lee, L. (2006). Respect authority! HITS without hyperlinks utilizingcluster-based language models. Proceedings SIGIR, pp. 8390.Laerty, J. D., & Zhai, C. (2001). Document language models, query models, riskminimization information retrieval. Proceedings SIGIR, pp. 111119.Lavrenko, V. (2004). Generative Theory Relevance. Ph.D. thesis, University Massachusetts Amherst.Lavrenko, V., Allan, J., DeGuzman, E., LaFlamme, D., Pollard, V., & Thomas, S. (2002).Relevance models topic detection tracking. Proceedings HumanLanguage Technology Conference (HLT), pp. 104110.Lavrenko, V., & Croft, W. B. (2001). Relevance-based language models. ProceedingsSIGIR, pp. 120127.Lavrenko, V., & Croft, W. B. (2003). Relevance models information retrieval. Croft,& Laerty (Croft & Laerty, 2003), pp. 1156.Leuski, A. (2001). Evaluating document clustering interactive information retrieval.Proceedings Tenth International Conference Information KnowledgeManagement (CIKM), pp. 3340.Leuski, A., & Allan, J. (1998). Evaluating visual navigation system digital library.Proceedings Second European conference research advanced technologydigital libraries (ECDL), pp. 535554.Liu, X., & Croft, W. B. (2004). Cluster-based retrieval using language models. ProceedingsSIGIR, pp. 186193.Liu, X., & Croft, W. B. (2006a). Experiments retrieval optimal clusters. Tech. rep. IR478, Center Intelligent Information Retrieval (CIIR), University Massachusetts.Liu, X., & Croft, W. B. (2006b). Representing clusters retrieval. ProceedingsSIGIR, pp. 671672. Poster.393fiKurland & KrikonLiu, X., & Croft, W. B. (2008). Evaluating text representations retrieval bestgroup documents. Proceedings ECIR, pp. 454462.Mei, Q., Shen, X., & Zhai, C. (2007). Automatic labeling multinomial topic models.Proceedings 13th ACM SIGKDD international conference, pp. 490499.Mihalcea, R. (2004). Graph-based ranking algorithms sentence extraction, appliedtext summarization. Companion Volume Proceedings 42nd AnnualMeeting Association Computational Linguistics, pp. 170173.Mihalcea, R., & Tarau, P. (2004). TextRank: Bringing order texts. ProceedingsEMNLP, pp. 404411. Poster.Otterbacher, J., Erkan, G., & Radev, D. R. (2005). Using random walks question-focusedsentence retrieval. Proceedings Human Language Technology ConferenceConference Empirical Methods Natural Language Processing (HLT/EMNLP),pp. 915922.Palmer, C. R., Pesenty, J., Veldes-Perez, R., Christel, M., Hauptmann, A. G., Ng, D., &Wactlar, H. D. (2001). Demonstration hierarchical document clustering digitallibrary retrieval results. Proceedings 1st ACM/IEEE-CS joint conferencedigital libraries, p. 451.Ponte, J. M., & Croft, W. B. (1998). language modeling approach information retrieval.Proceedings SIGIR, pp. 275281.Preece, S. E. (1973). Clustering output option. Proceedings American SocietyInformation Science, pp. 189190.Seo, J., & Croft, W. B. (2010). Geometric representations multiple documents.Proceedings SIGIR, pp. 251258.Shanahan, J. G., Bennett, J., Evans, D. A., Hull, D. A., & Montgomery, J. (2003). Clairvoyance Corporation experiments TREC 2003. High accuracy retrievaldocuments (HARD) track. Proceedings Twelfth Text Retrieval Conference(TREC-12), pp. 152160.Si, L., Jin, R., Callan, J., & Ogilvie, P. (2002). language modeling framework resourceselection results merging. Proceedings 11th International ConferenceInformation Knowledge Management (CIKM), pp. 391397.Tao, T., Wang, X., Mei, Q., & Zhai, C. (2006). Language model information retrievaldocument expansion. Proceedings HLT/NAACL, pp. 407414.Tao, T., & Zhai, C. (2006). Regularized esitmation mixture models robust pseudorelevance feedback. Proceedings SIGIR, pp. 162169.Tombros, A., Villa, R., & van Rijsbergen, C. (2002). eectiveness query-specic hierarchic clustering information retrieval. Information Processing Management,38 (4), 559582.Treeratpituk, P., & Callan, J. (2006). Automatically labeling hierarchical clusters.Proceedings sixth national conference digital government research, pp. 167176.394fiA Language Model Approach Ranking Query-Specific Document Clustersvan Rijsbergen, C. J. (1979). Information Retrieval (second edition). Butterworths.Voorhees, E. M. (1985). cluster hypothesis revisited. Proceedings SIGIR, pp.188196.Voorhees, E. M. (2002). Overview TREC 2002 question answering track.Eleventh Text Retrieval Conference TREC-11, pp. 115123.Wei, X., & Croft, W. B. (2006). LDA-based document models ad-hoc retrieval.Proceedings SIGIR, pp. 178185.Willett, P. (1985). Query specic automatic document classication. International ForumInformation Documentation, 10 (2), 2832.Xu, J., & Croft, W. B. (1996). Query expansion using local global document analysis.Proceedings SIGIR, pp. 411.Yang, L., Ji, D., Zhou, G., Nie, Y., & Xiao, G. (2006). Document re-ranking using clustervalidation label propagation. Proceedings CIKM, pp. 690697.Zamir, O., & Etzioni, O. (1998). Web document clustering: feasibility demonstration.Proceedings SIGIR, pp. 4654.Zhai, C., & Laerty, J. D. (2001). study smoothing methods language modelsapplied ad hoc information retrieval. Proceedings SIGIR, pp. 334342.395fiJournal Artificial Intelligence Research 41 (2011) 477526Submitted 11/10; published 08/11Probabilistic Framework Learning Kinematic ModelsArticulated ObjectsJurgen SturmCyrill StachnissWolfram Burgardsturm@informatik.uni-freiburg.destachnis@informatik.uni-freiburg.deburgard@informatik.uni-freiburg.deDepartment Computer Science,University Freiburg,Georges-Koehler-Allee 79, 79100 Freiburg, GermanyAbstractRobots operating domestic environments generally need interact articulatedobjects, doors, cabinets, dishwashers fridges. work, present novel,probabilistic framework modeling articulated objects kinematic graphs. Verticesgraph correspond object parts, edges model kinematicrelationship. particular, present set parametric non-parametric edge modelsrobustly estimated noisy pose observations. furthermoredescribe estimate kinematic structure use learned kinematicmodels pose prediction robotic manipulation tasks. finally presentlearned models generalized new previously unseen objects. variousexperiments using real robots different camera systems well simulation,show approach valid, accurate efficient. Further, demonstrateapproach broad set applications, particular emerging fields mobilemanipulation service robotics.1. IntroductionService robots operating domestic environments typically faced varietyobjects deal manipulate fulfill task.complicating factor many relevant objects articulated, doors,windows, also pieces furniture like cupboards, cabinets, larger objectsgarage doors, gates cars. Understanding spatial movements individual partsarticulated objects essential service robots allow plan relevant actionsdoor-opening trajectories assess whether actually successful.work, investigate problem learning kinematic models articulated objectsusing robotic manipulation tasks. illustrating example, consider Fig. 1mobile manipulation robot interacts various articulated objects kitchenenvironment, learns kinematic properties infers kinematic structure.problem formulated follows: Given sequence pose observationsobject parts, goal learn compact kinematic model describing whole articulated object. kinematic model define (i) connectivity parts,(ii) number degrees freedom object, (iii) kinematic functionarticulated object. result, obtain generative model usedrobot generating reasoning future unseen configurations.c2011AI Access Foundation. rights reserved.fiSturm, Stachniss, & BurgardrevoluteprismaticFigure 1: service robot learns kinematic models articulated objects kitchen environment.contribution paper novel approach enables real robot learnkinematic models articulated objects sensor data. models describekinematics object include part connectivity, degrees freedom objects,kinematic constraints. utilize models subsequently control motionmanipulator. Furthermore, show robot improve model learning exploitingpast experience. Finally, show framework generalized dealclosed-chain objects, i.e., objects contain kinematic loops.past, several researchers addressed problem handle doors drawers(Jain & Kemp, 2009a; Klingbeil, Saxena, & Ng, 2009; Meeussen et al., 2010; Wieland,Gonzalez-Aguirre, Vahrenkamp, Asfour, & Dillmann, 2009; McClung, Zheng, & Morrell,2010). approaches, however, either entirely model-free assume substantial knowledge model parameters. Whereas model-free approachesrelease designers providing a-priori model information, knowledge objects articulation properties supports state estimation, motion prediction,planning.478fiA Probabilistic Framework Learning Kinematic Models Articulated Objectsposeobservationsmodelfittingcandidatelink modelsstructureselectionkinematicgraphFigure 2: Schematic overview approach. robot observes articulated objectdifferent poses. uses observations generate set candidate models,selects kinematic structure maximizes posterior probability.previous work, introduced simpler version probabilistic frameworkmodeling articulated objects, presented estimators fitting link models, showedefficiently find kinematic structure kinematic trees (Sturm, Pradeep, Stachniss,Plagemann, Konolige, & Burgard, 2009). observations, used motion capture studiodata simulation. Further, used stereo camera system learning modelskitchen furniture (Sturm, Konolige, Stachniss, & Burgard, 2010). describedmanipulation robot learn kinematic models direct interaction articulatedobjects, improve time learning experience (Sturm, Jain, Stachniss,Kemp, & Burgard, 2010). work, present unified framework learning kinematic models articulated objects extended set experiments. contrastprevious work, generalize approach kinematic trees general kinematicgraph objects add strategy efficiently find locally optimal graph. this,becomes possible model articulated objects contain kinematic loops. Furthermore,finding effective number degrees freedom (DOFs) articulated object directlyfollows approach. general software framework implements presentedapproach available online1 BSD license, including source code, documentation,tutorials.paper organized follows. Section 2, introduce unified frameworkmodeling kinematics articulated objects. Section 3, present several extensionsincluding exploitation prior information, kinematic loops, estimationdegrees freedom. Section 4, describe different options perceive controlmotion articulated objects. analyze approach extensive set experimentssimulation real robots report results Section 5. Finally,conclude article discussion related work Section 6.2. Probabilistic Framework Articulated Objectsdefine articulated object consist multiple object parts onepassively actuated mechanical links them. links constrain motion parts. example, hinge door constrains door move arc,shaft drawer constrains drawer move line segment. simplestarticulated object consists two rigid parts one mechanical link. complex ob1. http://www.ros.org/wiki/articulation479fiSturm, Stachniss, & Burgardjects may consist several articulated parts, like door door handle, carseveral doors, windows, wheels.Fig. 2 gives high-level overview proposed system. robot observes posearticulated object manipulated. relative motion two parts,fits different candidate models describe different mechanical links. setcandidate link models, selects kinematic structure best explains observedmotion, i.e., kinematic structure maximizes posterior probability.2.1 Notationassume robot, external object, observes pose articulated objectconsisting p object parts. denote true pose object part {1, . . . , p}vector xi SE (3) representing 3D pose part (including position orientation),SE (3) = R3 SO(3) stands special Euclidean group. Further, referfull object pose (containing poses parts) vector x1:p = (x1 , . . . , xp )T .Two object parts j related relative transformation ij = xi xj .use referring motion composition operator inverse2 .denote kinematic link model two object parts j Mijassociated parameter vector ij Rkij , kij N0 denotes number parametersmodel describing link. kinematic graph G = (VG , EG ) consists setvertices VG = {1, . . . , p}, corresponding parts articulated object, setundirected edges EG VG VG describing kinematic link two object parts.edge (ij), corresponding kinematic link model Mij parameter vector ijassociated.kinematic link models consider (except trivial rigid link)latent variable qij Cij Rd ij describes configuration link. door,opening angle. Cij stands configuration space link. variabledij represents number DOFs mechanical link two parts.object articulated, robot observes object pose; denotenn-th pose observation object part yi . Correspondingly, denote n-th posen1 , . . . , yn ).observation parts y1:p sequence n pose observations Dy = (y1:p1:pnFurther, refer Dzij = (z1ij , . . . , zij ) sequence relative transformationszij = yi yj robot observed far edge (ij).Fig. 3a depicts graphical model simple articulated object consists twoobject parts. use so-called plate notation simplify notationgraphical model. Here, nodes inside rectangle (the plate) copied n times,i.e., time step object observed. time steps,articulated object takes particular configuration q12 defining together modelparameters noise-free relative transformation 12 noise-free poseobject parts x1 x2 . that, robot observes noisy poses y1 y2 ,infers virtual measurement z12 = y1 y2 . model learning,robot infers observations link model M12 link parameters 12 .2. E.g., poses x1 , x2 R44 represented homogeneous matrices, operators correspondmatrix multiplication x1 x2 = x1 x2 inverse multiplication x1 x2 = (x1 )1 x2 , respectively.480fiA Probabilistic Framework Learning Kinematic Models Articulated ObjectsM12 , 12qt12xt1qxt2x1x2x1x2M12 , 12t12y1ty2tM12 , 12zt121, . . . ,(a) Full graphical model(b) Reduced graphical model(c) Kinematic graphFigure 3: (a) Graphical model articulated object consisting two parts x1 x2 ,observed time steps. model M12 , 12 shared timesteps. (b) shows simplified version graphical model. (c) showscorresponding kinematic graph.reduced version graphical model depicted Fig. 3b. improve readability,leave nodes, i.e., node corresponding relative transformation 12observation nodes y1 , y2 , z12 . Instead, visualize dependency x1x2 direct link label corresponding model. Further, collapseconfiguration link single node corresponding configuration wholeobject. Finally, refer kinematic graph graph models connectivityobject parts, depicted Fig. 3c).2.2 Problem Definitionproblem consider find likely kinematic graph G givensequence pose observations Dy articulated object. Bayesian terms, meansaim finding kinematic graph G maximizes posterior probabilityobserving poses Dy articulated object, i.e.,G = arg max p(G | Dy ).(1)GHowever, finding global maximum posterior p(G | Dy ) difficult,highly non-convex function high-dimensional parameter space consisting discretewell continuous dimensions encode kinematic structure kinematicproperties, respectively.Therefore, section, consider simplified problem. restrict structurespace kinematic trees only, focus general problem Section 3. Kinematic481fiSturm, Stachniss, & Burgardtrees property individual edges independent other.result, estimate link parameters independently also independentkinematic structure. means learning local kinematic relationshipnobject parts j, relative transformations Dzij = (z1ij , . . . , zij )relevant estimating edge model. this, rephrase maximizationproblem (1) kinematic treesG = arg max p(G | Dz )(2)G= arg max p({(Mij , ij ) | (ij) EG } | Dz ).G= arg maxp(Mij , ij | Dzij ).G(3)(4)(ij)EGlatter transformation follows mutual independence edges kinematictrees.important insight work kinematic link models representingedges estimated independently actual structure kinematic tree.result, problem solved efficiently: first, estimate link modelspossibles edges (ij) VG VG :(Mij , ij ) = arg max p(Mij , ij | Dzij ).(5)Mij ,ijlink models independent independent whetheractually part kinematic structure EG . Second, given link models, estimatekinematic structure. two-step process also visualized Fig. 2.Solving (5) still two-step process (MacKay, 2003): first level inference,assume particular model (e.g., like revolute model) true, estimateparameters. applying Bayes rule, may writeij = arg max p(ij | Dzij , Mij )(6)ij= arg maxp(Dzij | ij , Mij ) p(ij | Mij )p(Dzij | Mij )ij.(7)term p(ij | Mij ) defines model-dependent prior parameter space,assume work uniform, thus may dropped. Further, ignorenormalizing constant p(Dzij | Mij ), influence choice parametervector. resultsij = arg max p(Dzij | ij , Mij ),(8)ijmeans fitting link model observations corresponds problemmaximizing data likelihood.482fiA Probabilistic Framework Learning Kinematic Models Articulated Objectssecond level inference, need compare probability different modelsgiven data select model highest posterior:ZMij = arg max p(Mij , ij | Dzij ) dij .(9)MijComputing exact posterior probability model general difficult, thereforeuse work Bayesian information criterion (BIC) selecting best modelaccording (9).result inference, obtain edge (ij) VG VG model Mijparameter vector ij , best describes motions Dzij observed twoparts. denote set possible link models= {(Mij , ij ) | (ij) VG VG }.(10)Given maximum-likelihood estimate links, efficiently estimatekinematic structure EG VG VG . this, aim finding subset,maximizes posterior probability resulting kinematic graph, i.e.,ZEG = arg max p(EG , | Dz ) dM.(11)EGsolve equation maximizing BIC possible structures EG , usingmaximum-likelihood estimate approximating integral.this, provide efficient way solve (2), first fitting models data,selecting best model link, finally estimating kinematic structurewhole articulated object. Section 2.3 Section 2.7, show solvemodel fitting problem (8) model selection problem (9) efficiently robustlynoisy observations. Section 2.8, show one efficiently solve (11),given link models. Section 3.2, show solution kinematic treesgeneralized general kinematic graphs, including kinematic structures containingloops.2.3 Observation Modelbeginning, consider simple objects consisting p = 2 rigid parts, dropij indices increase readability. consider case robot observedsequence n relative transformations Dz = (z1 , . . . , zn ) two adjacent rigidparts articulated object. assume presence Gaussian noisemeasurements zn zero mean covariance z R66 .Further, assume small fraction observations real outliers cannotexplained Gaussian noise assumption alone. outliers may resultpoor perception, bad data association, sensor failures hard modeledexplicitly. outliers related true value = x1 x2 all, assumecome uniform prior, i.e., assume constant likelihood p(zoutlier ) = const.One think latent variable v {0, 1} indicating whether observation483fiSturm, Stachniss, & Burgardinlier (v = 1) outlier (v = 0). Further, denote probability drawingoutlier, i.e., p(v = 0) = . full observation model becomes+ N (0, z ) v = 1z.(12)Uv = 0resulting data likelihood single observation z thus mixture Gaussianuniform distribution mixing constant :p(z | , ) = (1 )p(z | v = 1) + p(z | v = 0).(13)Note general neither true transformation outlier ratio directlyobservable, thus need estimated data. comparing modelsdifferent outlier ratios, assume global prior p() exp(w) wweighting constant, thereby favor models fewer outliers modelsoutliers. resulting data likelihood observation z given true value thusbecomes:p(z | ) = p(z | , )p().(14)2.4 Candidate Modelsconsidering set objects relevant service robot, one quickly realizesjoints many objects belong generic model classes. particular, revoluteprismatic joints used often, although objects composedmechanical linkages, example spherical joints, screws, two-bar links. Examplesrevolute joints include doors, door handles, windows. also includes doorsdishwashers, microwave ovens washing machines. Examples articulated objectsbelonging prismatic class include drawers, sliding doors, window blinds. However,also objects different mechanical linkages, garage doors twobar office lamps. motivates use set candidate models, well suiteddescribing kinematic properties particular class articulated links. candidateset consists parametrized non-parametrized models, particular, includes modelrevolute joints (Mrevolute ), prismatic joints (Mprismatic ), rigid transformations(Mrigid ). Additionally, may articulations correspond standardmotions, consider parameter-free model (MGP ). model joints usingcombination dimensionality reduction Gaussian process regression.framework, model class defines conditional probability distribution p( |q, M, ) p(q | , M, ) means forward kinematic function fM, (q) =1inverse kinematic function fM,(z) = q. means assume linkmodels deterministic, attribute noise measurement noise observationsobject parts, i.e., means observation model p( | z) defined Section 2.3.Since prior information nature connection tworigid parts, aim fit single model, instead aim fittingcandidate models observed data, select best model set.484fiA Probabilistic Framework Learning Kinematic Models Articulated Objectscandidate modelrigid modelprismatic modelrevolute modelGaussian process modelDOFs0111, . . . , 5parametersk69121 + + 6nTable 1: Overview different candidate models articulated links.2.5 Model Fitting using Maximum Likelihood Consensusestimating parameters above-mentioned models, need findparameter vector Rk maximizes data likelihood given model, i.e.,= arg max p(Dz | M, ).(15)presence noise outliers, finding right parameter vector minimizes (15)trivial, least squares estimation sensitive outliers thus sufficient givenobservation model. Therefore, use MLESAC (maximum likelihood consensus)algorithm introduced Torr Zisserman (2000). estimate initial kinematicparameters minimal set randomly drawn samples observation sequencerefine using non-linear optimization data likelihood.MLESAC procedure model works follows: First, generate guessparameter vector (15) minimal set samples Dz . guess,compute data likelihood whole observation sequence Dz productdatap(Dz | M, ) =np(zt | M, ).(16)t=1repeat sampling step fixed number iterations, finally select parameter vector maximizing (16). initial guess, apply non-linear optimizationdata likelihood refine parameter vector using Broyden-Fletcher-Goldfarb-Shanno(BFGS) optimization, quasi-Newton method function maximization.maximization data likelihood, MLESAC iteratively also estimates outlierratio , using Expectation Maximization algorithm.following, show link models (i) estimate parametervector minimal sample set observations, (ii) estimate transformation z givenconfiguration q, (iii) estimate configuration q given transformation z. briefoverview model candidates given Table 1.2.5.1 Rigid Modelparametrize rigid link fixed relative transformation two object parts.Thus, parameter vector k = 6 dimensions. sampling consensus step,draw single observation z training data Dz gives us initial guess485fiSturm, Stachniss, & Burgardparameter vector . parameter vector thus corresponds estimated fixedrelative transformation two parts. rigid transformation model,forward kinematics function equals parameter vector corresponds estimatedfixed relative transform two parts:fMrigid , (q) = .(17)rigid model zero DOFs (d = 0), inverse kinematic function needed.2.5.2 Prismatic ModelPrismatic joints move along single axis, thus one-dimensional configurationspace. prismatic model describes translation along vector unit length e R3relative fixed origin SE (3). results parameter vector = (a; e)k = 9 dimensions.estimating parameters, sample two observations training data.this, pick transformation first sample origin normalizedvector prismatic axis e.configuration q R encodes distance origin along directionmotion e. forward kinematics function prismatic model MprismaticfMprismatic , (q) = qe.(18)Let trans() function removes rotational components. inverse kinematicfunction becomes1fMprismatic , (z) =< e, trans(a z) >,(19)< , > refers dot product.2.5.3 Revolute Modelrevolute model describes motion revolute joint, i.e., one-dimensional motionalong circular arc. parametrize model center rotation c SE (3),rigid transformation r SE (3), center moving part. yields parametervector = (c; r) k = 12 dimensions.revolute model, sample three observations zi , zj zk trainingdata. First, estimate plane spanned three points; plane normalparallel rotation axis. Second, compute circle center intersectionperpendicular lines line segments three observations. Togetherrotation axis, gives us center rotation c. Finally, estimate rigidtransformation r circle first sample.forward kinematic function, obtain revolute linksfMrevolute , (q) = c RotZ (q) r,(20)RotZ (q) denotes rotation around Z-axis q. Thus, q R specifies anglerotation. estimating configuration revolute joint use11fMrevolute , (z) = RotZ ((z c) r),Rot1Z () gives rotation around Z-axis.486(21)fiA Probabilistic Framework Learning Kinematic Models Articulated Objects2.5.4 Gaussian Process ModelAlthough rigid transformations combination revolute prismatic joints mightseem first glance sufficient huge class kinematic objects, many realworld objects cannot described single shifting rotation axis. Examplesobjects include garage doors office table lamps, also furniture whose joints agedbecame loose.Therefore, provide additionally non-parametric model able describegeneral kinematic links. model based dimensionality reduction discovering latent manifold configuration space Gaussian process regressionlearning generative model. Consider manifold described observationsDz two rigid bodies. Depending number DOFs link, datasamples lie close d-dimensional manifold 1 6 non-linearlyembedded SE (3).many different dimensionality reduction techniques principal component analysis (PCA) linear manifolds, Isomap locally linear embedding (LLE)non-linear manifolds (Tenenbaum, de Silva, & Langford, 2000; Roweis & Saul, 2000).experiments, used PCA LLE dimensionality reduction. PCAadvantage robust noise near-linear manifolds, LLEgeneral also model strongly non-linear manifolds.general idea use dimensionality reduction technique obtain1inverse kinematics function fMGP : SE (3) R . result, assign configurationsobservations, i.e.,1fMGP (z) = q.(22)assignments observations configurations used learn forwardkinematics function fMGP , () observations. Except linear actuators, expectfunction strongly non-linear.flexible approach solving non-linear regression problems given noisy observations Gaussian processes (GPs). One main features Gaussian processframework observed data points explicitly included model. Therefore,parametric form fMGP : Rd SE (3) needs specified. Data points addedGP time, facilitates incremental online learning. model,aim learn GP fits dependencyfMGP (q) + = z(23)unknown forward model underlying articulated link consideration.assume homoscedastic noise, i.e., independent identically, normally distributed noiseterms N (0, z ). simplicity, train 12 independent Gaussian processesfree components homogeneous 4 4 transformation matrix. consequenceover-parametrization, predicted transformation matrices necessarily valid.practice, however, close valid transformation matrices,found using ortho-normalization via singular value decomposition. approach, usestandard choice covariance function, squared exponential. describes487fiSturm, Stachniss, & Burgardrelationship two configurations qi qj configuration space121k(qi , qj ) = f exp (qi qj ) (qi qj ) ,2(24)f2 signal variance, 1 = diag(l1 , . . . , ld ) diagonal matrixlength-scale parameters. results (1 + d)-dimensional hyper-parameter vector= (f2 , l1 , . . . , ld ). GPs data-driven, require training data making predictions. Therefore, count data samples parameters model,number parameters becomes k = (1 + d) + 6n, n = |Dz | numberobservations. refer interested reader text book Rasmussen Williams(2006) details GP regression.Note GP link model directly generalizes higher-dimensional configurationspaces, i.e., > 1: dimensionality reduction observations SE (3)configurations Rd , learn Gaussian process regression learnsmapping configuration space Rd back transformations SE (3). NoteGP model present similar GPLVM model introduced Lawrence(2005). contrast GPLVM, optimize latent configurations maximizingdata likelihood. would invalidate inverse kinematics function (22), limitsGPLVM model map latent space data space. approach,also infer configuration new relative transformations available training.2.6 Model Evaluationevaluate well single observation z explained model, evaluatep(z | M, ). configuration latent, i.e., directly observable robot,integrate possible values q, i.e.,Zp(z | M, ) = p(z | q, M, )p(q | M, ) dq.(25)assumption DOFs link independent other,configuration state q likely another (or equivalently, p(q | M, )uniformly distributed), may writep(q | M, ) n ,(26)n = |Dz | number observations far, thus number estimatedconfigurations d-dimensional configuration space. this, (25) simplifiedZp(z | M, ) n p(z | q, M, ) dq.(27)assume p(z | q, M, ) uni-modal distribution, approximationintegral evaluate estimated configuration q given observation z usinginverse kinematics function model consideration, i.e.,1q = fM,(z).488(28)fiA Probabilistic Framework Learning Kinematic Models Articulated Objectsusing forwardconfiguration, compute expected transformationkinematics function model,= fM, (q).(29)efficiently computeGiven observation z expected transformation ,data likelihood (27) using observation model (14)p(z | M, ) n p(z | ).(30)Note approximation integral based forward inverse kinematicsmodel corresponds projection noisy observations onto model. Finally,marginal data likelihood whole observation sequence becomesp(Dz | M, ) =p(z | M, ).(31)zDz2.7 Model Selectionfitted model candidates observation sequence Dz , need selectmodel explains data best. Bayesian model selection, meansneed compare posterior probability models given dataZp(Dz | M, )p( | M)p(M)p(M | Dz ) =d.(32)p(Dz )evaluation model posterior general difficult, approximatedefficiently based Bayesian information criterion (BIC) (Schwarz, 1978). denotek number parameters current model consideration, nnumber observations training data. Then, BIC definedBIC(M) = 2 log p(Dz | M, ) + k log n,(33)maximum likelihood parameter vector. Model selection reducesselecting model lowest BIC, i.e.,= arg min BIC(M).(34)refer interested reader work Bishop (2007) informationBIC.2.8 Finding Connectivityfar, ignored question connectivity described evaluate selectmodel single link two parts object only. section, extendapproach efficiently find kinematic trees articulated objects consisting multipleparts.adopt connectivity model Featherstone Orin (2008) modelingkinematic structure undirected graph G = (VG , EG ). nodes VG graph489fiSturm, Stachniss, & Burgardcorrespond poses individual object parts, edges EG correspondlinks parts. re-introduce ij-indices, i.e., use Dzijrefer observations link (ij), Dz refer observations wholearticulated object. Dz thus contains observations edges graph G, i.e.,Dz = {Dzij | (ij) EG }. previous section, established algorithm fitsselects given edge (ij) graph corresponding link model Mij parametervector ij . Given this, need select kinematic structure EG , i.e.,link models actually present articulated object consideration.moment, consider kinematic tree mechanisms, i.e., mechanismswithout kinematic loops. Now, consider fully connected graph p vertices, i.e., onevertex object part articulated object. set possible kinematic treesarticulated object given spanning trees graph. endeavorexplicitly computing, evaluating, reasoning kinematic trees, however,tractable practice.therefore seek find kinematic structure EG maximizes posteriorstated previously (11),EG = arg max p(EG | Dz )(35)EG= arg max p({(Mij , ij ) | (ij) EG } | Dz )(36)EG= arg maxEG= arg maxEGp(Mij , ij | Dz )(37)log p(Mij , ij | Dz ).(38)(ij)EGX(ij)EGNote independence assumption individual links kinematictrees, posterior kinematic model whole object (36) writtenproduct posteriors individual links (37). taking logarithm (38),structure selection problem takes form solved efficiently. key insightkinematic tree maximizes (38) corresponds problem selectingminimum spanning tree fully connected graph edge costs correspondingnegative log posterior,costij = log p(Mij , ij |Dzij ),(39)approximate BIC value. sum edge costs correspondsnegative log posterior kinematic tree, minimum spanning tree thus maximizes posterior (38). best kinematic structure found efficiently, i.e.,O(p2 log p) time, using example Prims Kruskals algorithm finding minimumspanning trees (Cormen, Leiserson, Rivest, & Stein, 2001).3. Framework Extensionsapproach described far enables robot learn kinematic models articulatedobjects scratch. following, consider three extensions. first extension490fiA Probabilistic Framework Learning Kinematic Models Articulated Objectsenables robot exploit priors learned previous interactions learning newmodels. Second, generalize framework general kinematic graphs, i.e., consideradditionally objects contain closed kinematic chains. Third, show estimatingnumber DOFs articulated objects follows directly approach.3.1 Learning Exploiting PriorsUsing approach described above, robot always starts learning model scratchobserves movements new articulated object. learning perspective,may seen unsatisfactory since articulated objects encountered man-madeenvironments belong different classes similar parameters. example,specific office kitchen, many cabinet doors open way, i.e.,radius rotation axis. Furthermore, countries size furniturestandardized. Thus, robot operating environments extended periodstime significantly boost performance learning priors space possiblearticulated object models.section describes approach learning priors articulated objectsmeans exploiting early possible manipulating previously unseenarticulated object. addition previous section, explicitly want transfer modelinformation contained already learned models newly seen articulated objects. keyidea identify small set representative models articulated objectsutilize prior information increase prediction accuracy handling newobjects.keep notation simple, consider case previously encounteredtwo articulated objects consisting two parts thus single link only. observedmotion given two observation sequences Dz,1 Dz,2 . question whethertrajectories described two distinct models M1 M2 jointmodel M1+2 . first case, split posterior two models mutuallyindependent, i.e.,p(M1 , M2 | Dz,1 , Dz,2 ) = p(M1 | Dz,1 )p(M2 | Dz,2 ).(40)latter case, trajectories explained single, joint model M1+2parameter vector 1+2 , estimated joint data Dz,1 Dz,2 . futurereference, denote corresponding posterior probabilityp(M1+2 | Dz,1 , Dz,2 ).(41)determine whether joint model better two separate models comparing posterior probabilities (40) (41), i.e, evaluatingp(M1+2 | Dz,1 , Dz,2 ) > p(M1 | Dz,1 )p(M2 | Dz,2 ).(42)expression efficiently evaluated using BIC follows. joint modellearned n = n1 + n2 data points, using k parameters, data likelihoodL = p(M1+2 | Dz,1 , Dz,2 ), two separate models learned n1 n2491fiSturm, Stachniss, & Burgardsamples, using k 1 k 2 parameters, data likelihoods L1 = p(Dz,1 | M1 )L2 = p(Dz,2 | M2 ), respectively. Accordingly, check whetherBIC(M1+2 | Dz,1 , Dz,2 ) < BIC(M1 | Dz,1 ) + BIC(M2 | Dz,2 )(43)i.e., whether2 log L + k log n < 2 log(L1 L2 ) + k 1 log n1 + k 2 log n2 .(44)Informally, merging two models one beneficial joint model explain dataequally well (i.e., L L1 L2 ), requiring single set parameters.two trajectories considered, one evaluate possible assignmentstrajectories models select assignment highest posterior.quickly becomes intractable due combinatorial explosion, use approximationconsider trajectories sequentially order robot observes them. checkwhether merging new trajectory one existing models leads higherposterior compared adding new model trajectory set previouslyencountered models.identified set models prior information, exploit knowledgemaking better predictions observing far unseen articulated object. Considersituation partial trajectory new object observed. exploitprior information, proceed exactly before. compute compare posteriorsaccording (44), treating newly observed data points new model respectivelymerging one w previously identified models evaluatingp(Mnew , M1 , . . . , Mw ) < max p(M1 , . . . , Mj+new , . . . , Mw ).j=1,...,w(45)newly observed data merged existing model, parameter vectorestimated much larger dataset Dz,j Dz,new instead Dz,new leads betterestimation. Note step carried observation new sequence.Thus, currently manipulated object ceases explained known models,method instantaneously creates new model. successful object manipulation,model serves additional prior information future.3.2 Closed Kinematic ChainsAlthough articulated objects connectivity kinematic trees, existmechanisms containing closed kinematic chains (Featherstone & Orin, 2008). intuitiveexample closed-loop system robot opens door manipulator.robot door described individually kinematic tree usingapproach, combined system robot, door floor creates kinematic loop.Another example humanoid robot multiple contact points, e.g., standingfeet, robot manipulates object two arms (Sentis, Park, & Khatib,2010). describe closed-loop systems, need extend approach.Recall finding kinematic structure Section 2.8, established correspondence finding graph maximizes posterior probability. that,needed compute data likelihood graph based edge constraints,492fiA Probabilistic Framework Learning Kinematic Models Articulated Objectseasy kinematic trees. case, links evaluated independently other.However, computing data likelihood kinematic graph based edge constraintsdifficult. results complex (joint) prediction posesobject parts involved kinematic loop. general, chained predictionsrelative transformations object parts lead globally consistent prediction, needed compute overall data likelihood case closed kinematicchains.problem, however, closely related loop-closing graph-based formulationsimultaneous localization mapping (SLAM) problem (Lu & Milios, 1997; Dellaert,2005; Frese, 2006; Grisetti, Stachniss, & Burgard, 2009). type problem, closedform solutions exist simple cases. popular solution general caseiterative optimization approaches deal underlying non-linear least squaresproblem.obtain consistent pose estimation whole graph, use optimizationengine HOG-Man Grisetti, Kummerle, Stachniss, Frese, Hertzberg (2010), originallydesigned solve SLAM problem. generate input graph HOG-Man,proceed follows. add vertex object part representing initial posex01 , . . . , x0n , estimate (arbitrary) spanning tree graph. Then,link model Mij graph G, add edge constrains relative transformation(in SLAM, correspondsx0i x0j expected transformationijobservation). optimization approach compute set new poses x1 , . . . , xnline constraints sense best prediction termssquared error obtained given links (in SLAM, correspondscorrected trajectory robot).pose observations yi , assume Gaussian noise zero mean covariance, i.e.,yi = xi +N (0, ).(46)(47)data likelihood single object part observed pose expectedpose x given kinematic graph G configuration q becomes11p(yi | G, q) exp (xi yi ) (xi yi ) .(48)2Using this, global data likelihood articulated object particular configurationcomputed product likelihoods individual object parts, i.e.,p(y1:p | G, q) =p(yi | G, q).(49)i1,...,pconfiguration q articulated object latent thus known, needintegrate possible configurations, i.e., calculateZp(y1:p | G) = p(y1:p | G, q)p(q | G)dq.(50)493fiSturm, Stachniss, & BurgardSimilar (25), approximate integral evaluating likely configuration q articulated object. assume configurations q uniformlydistributed, i.e., p(q | G) n , n number pose observationstotal number DOFs articulated object. data likelihood poseobservation y1:p becomesp(y1:p | G) n p(y1:p | G, q).(51)n1 , . . . , ) whole articulateddata likelihood observation sequence Dy = (y1:p1:pobjectp(Dy | G)n p(y1:p| G, qi )(52)i1,...,n= n nDp(y1:p| G, qi ).(53)i1,...,ndata likelihood used select best kinematic structure. Noteprinciple, possible graphs need evaluated super-exponentialnumber object parts, polynomial number template models. contrast,finding exact solution case kinematic trees polynomial complexityO(mp2 ). Obviously, massive set possible graph structures fully evaluatedsmall articulated objects template models.absence efficient exact solution, propose efficient approximationable find locally best graph initial guess using randomized searchstrategy polynomial time. idea given spanning tree initial solutionevaluate graphs neighborhood current structure, i.e., graphs whosetopology similar current one, e.g., adding removing one edge time.see experimental section, heuristic able find optimal (or nearoptimal) graph structure cases. Additionally, guaranteerandomized search strategy never gets worse initial solution, i.e., casespanning tree.3.3 Finding Number DOFscurrent configuration articulated object given stacked vectorindividual configurations articulated links, i.e.,q1q2qlinks = ..(54).qDlinks. question is, whether articulated object actually many DOFssum DOFs individual links might suggest. Clearly, case articulatedobject kinematic tree, DOFs objectP articulated object directly equalssum DOFs links links = (ij)EG ij links actuated494fiA Probabilistic Framework Learning Kinematic Models Articulated Objects(a)(b)Figure 4: Example open closed kinematic chain. Whereas open chain (a)three DOFs, closed chain (b) also single DOF.independently other. However, articulated objects containing loops, findingnumber DOFs articulated object trivial.example, consider object Fig. 4a consists four object partstotal three DOFs. contrast, object Fig. 4b consists four object parts,connected four revolute links form loop. four links singleDOF, therefore configuration vector defining configuration linksqlinks = (q1 , q2 , q3 , q4 ) R4 . Yet, overall system single DOF:first joint brought particular configuration, joints fixed well,result loop closure. means object configuration qobject Rsingle dimension, thus object configuration space one-dimensional manifoldembedded four-dimensional link configuration space.Finding mapping high-dimensional link configuration space RD linkslower-dimensional object configuration space RD object example achieved usingPCA linear manifolds, LLE ISOMAP non-linear manifolds. casePCA, results finding projection matrix P RD object links describing mappingqobject = P qlinks(55)Recall (53), number DOFs strong influence data likelihoodconfiguration, higher dimensional configuration space results lowerlikelihood single configuration. result, model fewer DOFs preferredmodel DOFs. time, additional parameters need estimateddimension reduction, parameters also model parameters thusneed considered model selection.Informally speaking, kinematic graph fewer DOFs explains data equallywell, higher data likelihood thus favored structure selectionstep. experimental section, see use accurately robustlyestimate DOFs various articulated objects.495fiSturm, Stachniss, & Burgard4. Perception Articulated Objectsestimating kinematic model articulated object, approach needs sequence1 , . . . , yn ) includes poses p partsn pose observations Dy = (y1:p1:pobject. experiments, used different sources acquiring pose observations:marker-based perception, described Section 4.1, domain-specific marker-less perception described Section 4.2, perception based internal forward kinematicmodel manipulator using joint encoders described Section 4.3.4.1 Marker-Based Perceptionobserving pose articulated object, used experiments three differentmarker-based systems, different noise outlier characteristics: motion capturestudio low noise outliers, ARToolkit markers relatively high noisefrequent outliers, OpenCVs checkerboard detector moderate noise occasionaloutliers.4.1.1 Motion Capturing Studioconducted first experiments PhaseSpace motion capture studio WillowGarage, collaboration Pradeep Konolige (Sturm et al., 2009). trackingsystem uses several high-speed cameras installed rig along ceiling, active LEDmarkers attached individual parts articulated object. dataPhaseSpace device virtually noise- outlier-free. noise PhaseSpace systemspecified y,pos < 0.005 y,orient < 1 .4.1.2 ARToolkit MarkersAdditionally, used passive marker-based system ARToolkit registering 3Dpose objects Fiala (2005). system advantage requiressingle camera, used without infrastructure. ARToolkit markersconsist black rectangle error-correcting code imprinted 6x6-grid insiderectangle distinguishing individual markers. found noisesystem strongly depends distance angle marker camera.marker size 0.08 distance 2 camera, typically obtainednoise values y,pos = 0.05 y,orient = 15 .4.1.3 Checkerboard MarkersOpenCVs checkerboard detector provides much higher pose accuracy. detectorsearches camera images strong black white corners sub-pixel accuracy (Bradski & Kaehler, 2008). system, typically obtained measurement noise aroundy,pos = 0.005 y,orient = 5 marker sizes 0.08 side length 2 distance camera. One distinguish different markers system usingcheckerboards varying numbers rows columns.496fiA Probabilistic Framework Learning Kinematic Models Articulated ObjectsFigure 5: Marker-less pose estimation using stereo camera. segmented plane,iteratively fit rectangle (left image). right two images show observedtracks cabinet drawer cabinet door.4.2 Marker-Less Pose Estimationcontrast using artificial markers, also possible estimate object pose directly,example, dense depth images acquired stereo camera system. recentlydeveloped system collaboration Konolige (Sturm et al., 2010). Usingmarker-less camera-based tracking system several advantages. First, relyartificial markers attached articulated objects, second, requireexpensive range scanners additional disadvantage poorly dealmoving objects, making inconvenient learning articulation models. However,recognize general registration arbitrary objects point clouds stillopen issue. Therefore, restrict fronts kitchen cabinets.solve general perception problem, provides useful working solution mobilemanipulation robots performing service tasks households. concrete scenario,perception articulated drawers doors kitchen environment requires accuratedetection rectangular objects depth image sequences.stereo processing system, obtain frame disparity imageR640480 , contains pixel (u, v) perceived disparity D(u, v) R.details camera system, particular choice suitable texture projectionpattern, refer interested reader recent work Konolige (2010). relationship 2D pixels disparity image 3D world points definedprojection matrices calibrated stereo camera, calculated single matrixmultiplication pixel coordinates disparity.apply RANSAC-based plane fitting algorithm segmenting dense depthimage planes. next step find rectangles segmented planes. startsampled candidate rectangle optimize pose size iteratively, minimizingobjective function evaluates accurately rectangle candidate matchespoints segmented plane. search converges, determine qualityfound rectangle evaluating pixel precision recall. example iterativepose fitting given left image Fig. 5: rectangle candidate started lowerleft door, iteratively converged correct pose size door.497fiSturm, Stachniss, & BurgardArticulated ObjectPositionEnd EffectorArm ControlCartesianEquilibriumPoint Generationy1:tModel FittingSelectionM,xCEPxt , JtModel PredictionFigure 6: Overall control structure (Sturm et al., 2010). robot uses trajectoryend effector estimate model articulated object. Subsequently,uses model generating next Cartesian equilibrium point.Finally, sequence depth images D1:n , detected rectangles need integrated set consistent tracks, one visible rectangle. result, obtain1 , . . . , yn ) use model estimation modelset pose sequences Dy = (y1:p1:pselection. middle right image Fig. 5 show tracks obtainedobserving drawer door kitchen cabinet. details approachrecently described Sturm et al. (2010).4.3 Perception using Joint Encoders Mobile Manipulation RobotNext visual observation articulated objects, mobile manipulation robot alsoestimate kinematic model physically interacts articulated object.evaluating joint encoders, robot compute pose gripper usingforward model manipulator. robot establishes firm contact handlecabinet door, position end-effector directly corresponds positiondoor handle. result, robot sense position handle well controlmoving manipulator.approach described section developed collaboration JainKemp Healthcare Robotics Lab Georgia Tech. robot useresearch statically stable mobile manipulator named Cody. consists two armsMEKA Robotics omni-directional mobile base Segway. end-effector,uses hook inspired prosthetic hooks human fingers, describeddetail recent work Jain Kemp (2009a). Furthermore, used PR2 robotWillow Garage additional experiments, using standard 1-DOF gripper twofingers, located lab.Fig. 6 shows block diagram approach. robot observes poseend effector Cartesian space, denoted SE (3). operating mechanism,robot records trajectory y1:t time sequence poses. partialtrajectory, continuously estimates kinematic model articulated object,robot uses turn predict continuation trajectory (Sturm et al., 2010).498fiA Probabilistic Framework Learning Kinematic Models Articulated Objectsactively operate articulated object robot, use trajectory controllerupdates Cartesian equilibrium point based estimated Jacobian kinematicmodel articulated object. controller uses kinematic model generateCartesian equilibrium point (CEP) trajectories fixed world frame, attached initiallocation handle. time step t, controller computes new equilibrium pointxCEPmechanismxCEP= xCEP+ vthook ,t1 + vt(56)vtmechanism vector intended operate mechanism, vthook vectorintended keep hook slipping handle. controller computesvtmechanism = L mechanismJtkJt k(57)vector length L mechanism = 0.01 along Jacobian learned kinematicfunction mechanism, i.e.,fiJt = fM, (q)fiq=qt .(58)vthook , use proportional controller tries maintain force 5 Nhook handle direction perpendicular Jt . controller uses forcemeasured wrist force-torque sensor robot. refer reader workJain Kemp (2009b) details implementation equilibrium point control,used coordinate motion mobile base compliant arm(Jain & Kemp, 2010).positional accuracy manipulator high, i.e., y,pos 0.01 m.However, using hook end-effector, robot cannot sense orientationhandle. manipulator mounted mobile base, robot move around,thus positional accuracy sensed position hook global coordinate system(and thus including localization errors base) reduces y,pos 0.05 m.5. Experimentssection, present results thorough evaluation aspects approach.First, show approach accurately robustly estimates kinematic modelstypical household objects using markers. Second, show also holds dataacquired marker-less pose estimation using active stereo camera system. Third,show approach also works data acquired different mobile manipulationrobots operating various pieces furniture domestic environments.5.1 Microwave Oven, Office Cabinet, Garage Doorfirst experiments, use pose observations three typical objects domesticenvironments: door microwave oven, drawers office cabinet, garagedoor. goal experiments show approach robustlyaccurately estimates link models, well correct kinematic structure whole499fiSturm, Stachniss, & Burgardarticulated object. addition, show range configuration spaceobtained model estimation.motion microwave oven cabinet tracked using motion capturestudio collaboration Pradeep Konolige (Sturm et al., 2009), garagedoor using checkerboard markers. object, recorded 200 data samplesmanually articulating object. evaluation, carry 10 runs. run,sampled n = 20 observations use fitting model parameters. usedremaining observations measuring prediction accuracy fitted model (10-foldscross-validation).5.1.1 Model Fittingquantitative results model fitting model selection given Table 2.seen table, revolute model well suited predicting openingmovement microwave door (error 0.001 m) prismatic model predictsaccurately motion drawer (error 0.0016 m), expectedresult. Note also revolute model also explain motion draweraccuracy 0.0017 m, estimating rotary joint large radius. notedflexible GP model provides roughly accuracy parametric modelsable robustly predict poses datasets (0.0020 door,0.0017 drawer). case simulated garage door, however, parametricmodels fail whereas GP model provides accurate estimates.reader might wonder GP model alone suffice, GP modelrepresent many different types kinematic models, including revolute prismaticones. However, even GP model fits data, best choice termsresulting posterior likelihoods. GP model cases overly complex,over-fit data hand. high complexity GP model penalizedBIC. contrast, specialized models smaller number free parameters,therefore robust noise outliers. Furthermore, require lessobservations converge. experiments illustrate system takes advantageexpert-designed parametric models appropriate keeping flexibilityalso learn accurate models unforeseen mechanical constructions.learned kinematic models also provide configuration range C articulatedobject. visualization purposes, sample configurations range,project object poses using learned forward function. Fig. 7, Fig. 8, Fig. 9illustrate learned configuration range door microwave oven, garagedoor, two drawers office cabinet, respectively.5.1.2 Model Structure Selectionfitting model candidates observed data, next goal select modelbest explains data, corresponds finding model maximizesposterior probability (or minimizes BIC score).right image Fig. 7 shows resulting graph microwave oven dataset,BIC score indicated edge. expected, revolute model selected,500fiA Probabilistic Framework Learning Kinematic Models Articulated ObjectsDatasetRigidModelPrismaticModelRevoluteModelGPModelMicrowave(z,pos. = 0.002 m,z,orient. = 2.0 )pos. error =orient. error ==0.308637.400.8910.104832.310.8160.00030.150.0000.00200.160.000Drawer(z,pos. = 0.002 m,z,orient. = 2.0 )pos. error =orient. error ==0.08222.060.8870.00161.360.0000.00181.600.0030.00171.090.000Garage Door(z,pos. = 0.050 m,z,orient. = 5.0 )pos. error =orient. error ==1.088714.920.7190.385610.790.2380.471310.340.4180.04500.930.021Table 2: Prediction errors estimated outlier ratios articulation models learnedmicrowave oven, office cabinet, real garage door.(a)microwave ovendoorx1x2rigidBIC(M12 ) =2568507.7prism.BIC(M12)=686885.1BIC(Mrev.12 ) =461.9BIC(MGP12 ) =165.8(b)Figure 7: Visualization kinematic model learned door microwave oven.(a) configuration range. (b) kinematic graph. numbers edges indicateBIC score corresponding model candidate.lowest BIC score. Correspondingly, right image Fig. 8 showsBIC scores edges garage door dataset, GP model gets selected.typical articulated object consisting multiple parts cabinet drawersdepicted Fig. 9. experiment, track poses cabinet (x1 ),two drawers (x2 x3 ). first 20 samples, opened closed lowerdrawer. Accordingly, prismatic joint model Mprism.selected (see top row images23Fig. 9). also upper drawer gets opened closed, rigid model Mrigid12prism.prism.prism.replaced prismatic model M12 , M23replaced M13 , resultingkinematic tree EG = {(1, 2), (1, 3)}. Note required articulate drawersone other. done illustration purposes.501fiSturm, Stachniss, & Burgardbuildinggarage doorx1x2rigidBIC(M12 ) =9893.4prism.BIC(M12)=5450.8BIC(Mrev.12 ) =5870.7BIC(MGP12 ) =620.2(a)(b)Figure 8: Visualization kinematic model learned garage door. (a) 10 uniformlysampled configurations. (b) kinematic graph.5.1.3 Multi-Dimensional Configuration Spacesillustrate approach also able find models higher-dimensional configuration spaces > 1, let robot monitor table moved floor.robot equipped monocular camera tracking Artoolkit marker attachedtable. experiment, table moved never turned, lifted, tiltedtherefore configuration space table two dimensions. Fig. 10 shows foursnapshots learning. Initially, table perfectly explained rigid objectroom (top left). Then, prismatic joint model best explains data since tablemoved one direction (top right). moving sideways, best model 1-DOFGaussian process model follows simple curved trajectory (bottom left). Finally,full planar movement explained 2-DOF Gaussian process model (bottom right),model movements lie 2D surfaces.5.1.4 Additional Examplesran similar experiments large set different articulated objects typicallyoccur domestic environments, including office cabinets, office doors, desk lamps, windows,kitchen cabinets, fridges dishwashers garage door. Four examples givenFig. 11. Videos (and other) experiments available homepagecorresponding author3 . videos show original movie well overlayinferred kinematic model. experiments, attached checkerboardsdifferent sizes movable parts, used consumer-grade video cameralow-cost laptop webcam acquiring image data. software also visualizeslearned articulation models 3D back-projects onto image allow easyvisual inspection. detected poses checkerboards visualized red/green/bluecoordinate axes systems, selected links indicated using coloredconnection. software also displays configuration range generating poses3. http://www.informatik.uni-freiburg.de/ sturm502fiA Probabilistic Framework Learning Kinematic Models Articulated Objectscabinetdrawer 1drawer 2x1x2x3rigidBIC(Mij ) =prism.BIC(Mij)=189.3997.2993.063.961.762.6BIC(Mrev. ) =41.858.159.3BIC(MGPij ) =277.2279.0278.4ij(a)(b)cabinetdrawer 1drawer 2x1x2x3rigidBIC(Mij ) =prism.793.72892.23660.1)=88.886.984.7BIC(Mrev. ) =84.984.482.4BIC(MGPij ) =331.6331.0331.8BIC(Mijij(c)(d)Figure 9: Incrementally estimating model two drawers cabinet. (a) Initially,lower drawer opened closed. (b) Corresponding kinematic graph. (c)drawers opened closed independently. (d) Corresponding kinematicgraph.estimated range. revolute joints, additionally indicates rotation axis using linesurrounding circle.visual inspection objects Fig. 11, one see accurate modelestimation works conjunction marker-based tracking: motion drawerscabinet well matched, rotation axes door hinge door handleestimated close true position. upper part garage door movesslider ceiling, lower part connected via revolute joint. resultingmotion clearly neither revolute prismatic, consequently approach selectsGP model. desk lamp consists two-bar links keep light housing alwaysupright (or, loosely speaking, rigid orientation), move positional domain alongcircle. link type well explained GP model. existenceobjects shows necessity supply domestic service robot general, nonparametric model deal wide variety different articulated objects.noted majority articulated objects domestic environments consistrevolute prismatic joints robustly estimated using parametrizedmodels. motivates approach enables robot fit parametric503fiSturm, Stachniss, & BurgardFigure 10: Learning model table moving ground plane. arrows indicaterecovered manifold configuration space.nonparametric models time compare terms posterior likelihoodsconsistent model selection framework.Another interesting object car, doors windows tree- chainlike elements. Fig. 12, observed motion drivers door window.first observations, approach estimates structure rigid, linksdoor window parallel car body. open windowhalf, approach attaches drivers window door, selects prismatic model.Surprisingly us, open window (and thus acquire observations),approach switches revolute model drivers window associated largeradius (r = 1.9 m). looking carefully data car, confirmwindow indeed moves circular path, due curved window glass. Finally,driver closes door, also revolute model link car bodydoor selected.504fiA Probabilistic Framework Learning Kinematic Models Articulated Objectsx1prismaticx2x1revoluteprismaticx2x3x3revolute(a) Office cabinet(b) Room doorx2GPx2x1x3GPGPx1(c) Garage door(d) Desk lampFigure 11: Visualization learned articulation models several domesticobjects. (a) cabinet two drawers, (b) room door including handle, (c)garage door, (d) desk lamp two-bar links.conclude results, approach able estimate kinematicparameters kinematic structure different household objects high accuracy, i.e.,prediction error learned models around 0.001 1 objects trackedmotion capture studio, around 0.003 3 checkerboard markers.accuracy, learned models well suited mobile manipulation tasks.5.2 Evaluation Marker-Less Model Estimationgoal next set experiments show kinematic models learnedcertain environments without requiring artificial markers. particular, focuskitchen environments rectangular cabinet fronts, employ pose detectordescribed previously (Sturm et al., 2010).505fiSturm, Stachniss, & Burgardx3x3rigidx1x1rigidprismaticrigidx2x2(a)(b)x3x3x1rigidrevolutex1revoluterevolutex2(c)x2(d)Figure 12: Snapshots learning process incrementally observing motioncar door window camera images. Due shape glassdrivers window actually moves circular arc radius r = 1.9 m. Imagestaken (a) 10, (b) 40, (c) 60, (d) 140 pose observations.first experiment carried motion capture studio, evaluated detectorfound detected cabinet drawer 75% imagesdistance 2.3 camera.evaluated robustness articulation model learner detailed logfilesdoor (0.395 0.58 m) drawer (0.395 0.125 m) typical kitchen interior.repeatedly opened closed objects approximately 1 distance robot;total, recorded 1,023 5,202 images. downsampled logs stochastically100 images, ran pose estimation, model estimation, structure selection 50times. outcome model selection process, accuracy selected modeldepicted Fig. 14 door dataset.506fiA Probabilistic Framework Learning Kinematic Models Articulated Objects(a)(b)Figure 13: Articulation model learned observing drawer (a) door (b).p(model)1rigidprismaticrevolute0.750.50.25error positionerror orientation0.050.040.030.020.010108642010203040number observations (door)50orientation error [deg]position error [m]060Figure 14: Evaluation articulation models learned cabinet door, averaged50 runs. plot top shows probability articulation model templates, plot bottom shows prediction error standard deviationlearned model.datasets, found roughly first 10 observations, mostly rigidmodel selected, substantial motion drawer door yet detected.observations added track, higher error (rigid) model507fiSturm, Stachniss, & BurgardFigure 15: Images showing robot Cody Georgia Tech operating five mechanismsusing approach described Section 4.3. objects (from left right):cabinet door opens right, cabinet door opens left,dishwasher, drawer, sliding cabinet door. Images courtesy JainKemp.predictions observations becomes. result, prismatic revolute modelsselected frequently. 30 observations, model selection convergedcases true model.models learned drawer datasets predictive accuracy approximately0.01 7 ; 0.01 3.5 door dataset. Although predictive accuracylearned models slightly lower comparison marker-based tracking systemsdue higher noise tracking system, learned models accuracyusable mobile manipulator operating objects.5.3 Operating Articulated Objects Mobile Manipulatorssection, show real robots utilize approach learn kinematicmodels objects active manipulation. Here, control arm done usingequilibrium point control described Section 4.3, result collaborationJain Kemp (Sturm et al., 2010). experiments conducted two differentplatforms, robot Cody PR2 robot.508fiA Probabilistic Framework Learning Kinematic Models Articulated Objects5.3.1 Task Performanceevaluated performance approach five different mechanisms using robotCody: cabinet door opens right, cabinet door opens left,dishwasher, drawer, sliding cabinet door. performed eight trials mechanism. robot started approximately 1 location handle. manuallyspecified grasp location selecting point 3D point cloud recorded robot,orientation hook end effector, initial pulling direction. taskrobot navigate mechanism operate it, learning articulationmodel using methods described Section 3.1. deemed trial successfulrobot navigated mechanism opened angle greater 60revolute mechanisms 0.3 prismatic mechanisms.Fig. 15 shows robot pulled open five mechanisms onerespective trials. robot successfully opened 3 rotary mechanisms 2124 trials 2 linear mechanisms 16 trials. robot able open doors70 , estimate radii average error 0.02 m. Further,robot pulled open drawer sliding cabinet repeatedly average 0.49 m.Overall robot successful 37 40 trials (92.5%).three failures due robot failing hook onto handle prior operatingmechanism, likely due odometry errors errors provided locationhandle. experiments, observe model learning causederrors. principle, however, hook could slip handle wrong modelestimated.5.3.2 Model Fitting Selection End-Effector TrajectoriesFig. 1 Fig. 16 show examples PR2 robot operating several articulated objectscommon domestic environments, i.e., fridge, drawer, dishwasher door, traydishwasher, valve heater. experiments, use feedback controldescribed Section 4.3 tele-operated manipulator manually. First, recordedset trajectories guiding manipulator operate various articulated objects.execution, played trajectories back using different implementation equilibriumpoint control available PR2 platform, recorded end-effector trajectoriesrobot. used trajectories subsequently learn kinematic models. Finally,visualized models superimposing images taken calibrated wide-anglecamera mounted head robot, see Fig. 16. experiments, approachalways selected correct model candidate. One easily verify visual inspectionapproach estimates kinematic properties (like rotation axis prismaticaxis) accurately.experiments show robots successfully learn accurate kinematic modelsarticulated objects end-effector trajectories using approach. PR2,achieved average predictive accuracy learned models 0.002 (in termsresidual error observed trajectory respect learned model),sufficient using models mobile manipulation tasks domestic settings.509fiSturm, Stachniss, & Burgardrevolute(a) Cabinet doorrevolute(b) Dishwasher doorprismatic(c) Dishwasher trayrevolute(d) Valve heaterFigure 16: PR2 robot learns kinematic models different pieces furnitureactuating using manipulator. Objects top bottom: fridge,cabinet door, drawer, dishwasher door, dishwasher tray, water tap, valveheater.510fi0.40.40.20.200-0.2-0.2-0.4-0.4-0.4-0.2x [m]0-0.4-0.2x [m]z [m][m]Probabilistic Framework Learning Kinematic Models Articulated Objects0Figure 17: plots show observed trajectories 5 recovered modelsminimizing overall BIC using approach. Trajectories assignedmodel depicted color.prediction error [m]without learned prior modelslearned prior models0.30.20.1000.10.20.30.40.50.60.70.8ratio observed trajectory vs. full trajectory0.91Figure 18: graph shows average prediction error (line) standard deviation(shaded area) learned model full trajectory without priorinformation.511fiSturm, Stachniss, & Burgard5.4 Improving Model Estimation Based Experienceexperiments described previous section, learned kinematic modelskitchen furniture independent other. using approach describedSection 3.1 data Cody, exploit correlation models differentobjects searching set model clusters maximize posterior probability.Fig. 17 shows result experiment. colors indicate clustertrajectories assigned to. approach correctly recognized robotoperated 5 different mechanisms assigned 37 different trajectories correctlycorresponding models.measured average prediction error without learning prior models (seeFig. 18), using leave-one-out cross-validation randomized ordering trajectories.found prior models reduce prediction error considerably, especiallynew trajectory partially observed. 30% 70% new trajectoryobserved, prediction error reduced factor three more. result,robot comes substantially accurate model early utilizeknowledge better control manipulator.Throughout experiments Cody, used fixed noise term z,pos = 0.05m.accounts inaccuracies observation end effector position, due variationshooking position, small errors kinematic forward model robot baselocalization. found repeated experiments range 0.02m z,pos0.20m, results similar previous results obtained z,pos = 0.05m.significantly smaller values z,pos models created, example due smallvariations grasping point inaccuracies. much larger values, observationsdifferent mechanisms clustered joint model. Thus, results insensitivemoderate variations observation noise z,pos .experiment illustrates approach enables mobile robot learnexperience exploit prior information manipulating new objects. experienceincreases prediction accuracy factor approximately three.5.5 Detecting Kinematic Loopsfinal set experiments, evaluated approach objects containing kinematicloops. goal experiments show approach estimate correctlykinematic connectivity, well correct number DOFs.purpose, used first four segments yardstick. resultsopen kinematic chain consisting three revolute joints (see top left image Fig. 19).object three DOFs, revolute joints independent other. secondexperiment, taped fifth segment yardstick together first one.creates kinematic loop, see top right image Fig. 19: resulting object consistsfour revolute joints single DOF. resulting mechanism effectivelysingle DOF. articulated objects manually, recorded object pose datasets|Dy | = 200 samples using checkerboard markers.second third row Fig. 19 visualize learned kinematic modelopen closed kinematic model, respectively, fourth row showskinematic structure learned model. figure, seen ap512fiA Probabilistic Framework Learning Kinematic Models Articulated Objectsproach correctly recognizes open kinematic chain consists three revolute linksrev.rev.(Mrev.12 , M23 , M34 ), three DOFs q = (q1 , q2 , q3 ) total. closed kinematicrev.rev.rev.chain, approach selects four revolute links (Mrev.12 , M23 , M34 , M14 ), correctlyinfers object exhibits single DOF q = (q1 ).also analyzed progression model selection training data incorporated. left plot Fig. 20 shows DOFs learned kinematic modelopen kinematic chain. Note opened yardstick segment segment, thereforenumber DOFs increases step-wise zero three. right plot shows estimated number DOFs closed kinematic chain: approach correctly estimatesnumber DOFs one already first observations.detail, analyzed evolution BIC scores runtimedifferent approaches closed kinematic chain Fig. 21. plot top showsevolution BIC scores possible kinematic structures. colorizedcurves corresponding spanning tree solution (solid red), heuristic search (dashedblue) global optimum (dotted green). spanning tree solution usestarting point heuristic search average 35.2% worse terms BICoptimal solution. contrast, BIC heuristic search 4.3% worse,equals optimal solution 57.5% cases. time complexity computingspanning tree independent number training samples, see bottom plot Fig. 21.contrast that, evaluation kinematic graphs requires kinematic structureconsideration evaluation whole object poses, thus linear numbertraining samples n. heuristic search evaluates kinematic graphs along tracestructure space. result, yardstick object p = 4 object parts,heuristic search requires average 82.6% less time full evaluation.conducted similar experiments objects containing kinematic loopsreduced DOFs. Two examples depicted first row Fig. 22: artificial objectconsisting four parts single revolute joint, common domestic step ladderconsisting two revolute joints single, shared DOF. cases, approachable correctly estimate kinematic parameters correct numberDOFs.experiments, shown approach able detect closedchains articulated objects, correctly estimates correct number DOFs. loopclosures (or reduced DOFs) reduce configuration space object significantly,valuable information mobile manipulator, example reasoning possibleconfigurations object.5.5.1 Evaluation Model Selection RobustnessFinally, investigated influence choice observation noise variable zmodel selection process artificial data. analysis, sampled noisy observationstrue = 0.05. resultingrevolute model true observation noise z,posobservation sequence, fitted candidate models, selected best model.repeated experiment 10 independent runs evaluated mean standarddeviation. number training samples n kept fixed, higher noiseassumption favors selection simpler models, vice versa. Fig. 23 illustrates513fiSturm, Stachniss, & Burgardx3revolutex1revoluterevolutex2x4revolutex2x1revoluteq1 q2 q3 . . .x1Mrev.12x4x2x3revoluterevolutex3q1 q2 q3 . . .x4x1Mrev.Mrev.2334Mrev.12x2x3x4Mrev.Mrev.Mrev.233414Figure 19: Open kinematic chain three DOFs (left column) closed kinematic chainsingle DOF (right column). First row: images objects. Secondthird row: learned kinematic models two different perspectives. Fourthrow: learned graphical model, showing connectivity DOFslearned kinematic model. selected kinematic model visualized boldedges, DOFs given boldly type-set configuration variables.514fiA Probabilistic Framework Learning Kinematic Models Articulated Objectsopen kinematic chainclosed kinematic chainDOFsDOFs4433221100501001500200050training samples n100150200training samples nFigure 20: Estimated number DOFs open closed kinematic chain object(see Fig. 19). Left: open kinematic chain. Right: closed kinematic chain.spanning treesearch heuristicglobal optimumBIC10,0000time [s]10,000200150100500020406080100120140160180200training samples nFigure 21: Top: BIC scores possible kinematic structures closed kinematicchain, depicted top right image Fig. 20. Bottom: Computationtimes function number training samples.515fiSturm, Stachniss, & Burgardx3x2rigidx1revolutex4rigidrevoluterevolutex2x3x1q1 q2 q3 . . .x1x2x3q1 q2 . . .x4x1x2x3rigidMrot.12Mrigid23 24Mrot.Mrot.1312Figure 22: articulated object consisting single revolute joint (left), stepladderconsisting two revolute joints (right).516fiA Probabilistic Framework Learning Kinematic Models Articulated Objects2,000BIC1,5001,0005000Gaussian process modelrevolute modelprismatic modelrigid modelselected model0.00010.0010.010.11.0observation noise z,positionFigure 23: BIC score function assumed observation noise. low noise assumption favors selection complex models, vice versa.dependency: n = 50 assumed noise level z,pos 0.02, GP modelselected. 0.02 z,pos 0.2, revolute model yields best trade-offmodel complexity data likelihood. 0.2 z,pos , rigid model best explainsobservations noise level magnitudes hides underlying model.experiment, demonstrated model selection procedure robustlarge intervals observation noise assumption, i.e., even though true observationtrue = 0.05, approach selected revolute model noisenoise set z,posassumption 0.02 z,pos 0.2, thus robust whole magnitude.also performed experiments synthetic data verify estimators robustnormally distributed noise MLESAC-based estimators additionallyrobust uniformly distributed outliers.5.6 Open-Source Availabilitysource code, documentation, code samples, tutorials fully available opensource, licensed BSD. also provide step-by-step guide repeat experiments using consumer-grade laptop webcam4 .6. Related Workpaper, combined several techniques come different fields, i.e.,system identification fitting kinematic models, information theory model comparisonstructure selection, computer vision estimating tracking objects, service roboticscontrol actually manipulating articulated objects mobile manipulators.4. http://www.ros.org/wiki/articulation517fiSturm, Stachniss, & Burgardfollowing, review related approaches, contrast approach, highlightcontributions.6.1 Kinematic Model FittingCalibrating kinematic models manipulation robots sensor data long historysystem identification. good overview existing techniques found workHollerbach, Khalil, Gautier (2008). He, Zhao, Yang, Yang (2010) recentlyanalyzed identifiability parameters serial-chain manipulators, proposedgeneric approach calibration. Pradeep, Konolige, Berger (2010) recently presentedsystem implementation sensor-actuator calibration complex service robot consistingtwo arms, laser scanner several cameras. works, kinematicmodel specified advance, typically expected initial parameter setavailable. taking multiple pose observations robot different configurations,error prediction observation computed, finally parametervector optimized using non-linear, iterative least-squares methods.case, neither kinematic model initial parameter set available,needs estimated observations alone. particular observationsdisturbed noise outliers, sample consensus methods proven providerobust estimates (Fischler & Bolles, 1981; Torr & Zisserman, 2000; Nister, 2005; Rusu,Marton, Blodow, Dolha, & Beetz, 2008). model estimators, use MLESACfirst described Torr Zisserman (2000) contrast least-squares fittingrobust reasonable amounts outliers training data.6.2 Kinematic Structure SelectionEstimating kinematic structure observations studied intensively before, however, without subsequently using models robotic manipulation (Taycher, Fisher,& Darrell, 2002; Kirk, OBrien, & Forsyth, 2004; Yan & Pollefeys, 2006; Ross, Tarlow, &Zemel, 2008; Pekelny & Gotsman, 2008). Taycher et al. (2002) address task estimating underlying topology observed articulated body. focus lies recoveringtopology object rather learning generative model. Also, comparedwork, approach handle links complex link models, e.g., multipleDOFs non-parametric models. Kirk et al. (2004) extract human skeletal topologies using 3D markers motion capture system, however assuming joints revolute.Yan Pollefeys (2006) present approach learning structure articulatedobject feature trajectories affine projections. researchers addressedproblem identifying different object parts image data. Ross et al. (2008) usemulti-body structure motion extract links image sequence fitarticulated model links using maximum likelihood learning.exist several approaches tracking articulated objects key motivationoften a-priori model assumed. Krainin, Henry, Ren, Fox (2010), example,described recently approach tracking articulated objects manipulator usingdepth camera texture projector. However, require geometric modelmanipulator. Kragic, Petersson, Christensen (2002) describe integrated navigationsystem mobile robots includes vision-based system detection door518fiA Probabilistic Framework Learning Kinematic Models Articulated Objectshandles enables robot successfully open doors. Anguelov, Koller, Parker,Thrun (2004) model doors line segments rotate around hinge. EM usedfind model parameters 2D range data images. Nieuwenhuisen, Stuckler,Behnke (2010) describe approach mobile robot increases localizationaccuracy learning positions doors.Although learning structure general Bayesian networks provenNP-complete (Chickering, 1996), many approximate methods proposedsolve structure search problem efficiently. methods include greedy search, iterated hill climbing, genetic algorithms ant colony optimization (Chickering, 2002; Daly& Shen, 2009). cases, size search space reduced significantlyevaluating number statistical independence tests (Margaritis & Thrun, 1999; Bromberg,Margaritis, & Honavar, 2009). paper, consider special Bayesian networks representing kinematic structures. allows us exploit mutual independence edgeskinematic trees efficiently recovering kinematic structure. closed kinematicchains, use greedy search heuristic similar work Chickering (2002).Estimating structure models requires trade data fit modelcomplexity. corresponds Bayesian model selection problem, describedMacKay (2003). approach problem work using Bayesian InformationCriterion (BIC) introduced Schwarz (1978). BIC provides method selectingalternate model hypotheses, based data likelihood model complexity.paper, use BIC select kinematic models individual linkswell multi-part articulated objects.6.3 Pose EstimationMany approaches estimating pose objects sensory data proposedpast, solving general problem still ongoing research effort. Marker-basedapproaches using active passive markers advantage easy useproviding full 3D pose information, require artificial markers attached uponobject parts interest. Early work area articulated object tracking presentedLowe (1991) assumption object model (and good initialization)known. Nieuwenhuisen et al. (2010) use 2D laser range finder detecting doorsoffice environment storing map. Tilting lasers line stripe systemsprovide dense 3D point clouds used localizing doors door handles,cannot deal moving objects (Rusu, Meeussen, Chitta, & Beetz, 2009; Quigley,Batra, Gould, Klingbeil, Le, Wellman, & Ng, 2009). Camera-based approaches providehigher frame rates. good survey state-of-the-art camera-based pose estimationtechniques found work Lepetit Fua (2005). context, workMurillo, Kosecka, Guerrero, Sagues (2008) Andreopoulos Tsotsos (2008)visual door detection pose estimation particular relevance. Stereo systemsemploy matching algorithms produce dense results provide 3D point clouds videoframe rates, suffer occasional dropouts areas low texture illumination(Konolige, 1997; Brox, Rosenhahn, Gall, & Cremers, 2010; Wedel, Rabe, Vaudrey, Brox,Franke, & Cremers, 2008). overcome active camera systems add texture519fiSturm, Stachniss, & Burgardscene using projector LED. Two examples systems describedKonolige (2010) Fox Ren (2010).work, use several different approaches estimating pose articulatedobject showing approach specific specific data source. particular,use marker-based pose estimation monocular camera, marker-less pose estimationstereo data, proprioceptive tracking using robots joint encoders.6.4 Operating Articulated ObjectsSeveral researchers addressed problem operating articulated objects roboticmanipulators. large number techniques focused handling doors drawers (Klingbeil et al., 2009; Kragic et al., 2002; Meeussen et al., 2010; Petrovskaya & Ng,2007; Parlitz, Hagele, Kleint, Seifertt, & Dautenhahn, 2008; Niemeyer & Slotine, 1997;Andreopoulos & Tsotsos, 2008; Rusu et al., 2009; Chitta, Cohen, & Likhachev, 2010).majority approaches, however, assumes implicit kinematic model articulated object. Meeussen et al. (2010) describe integrated navigation system mobilerobots including vision- laser-based detection doors door handles enablesrobot successfully open doors using compliant arm. Diankov, Srinivasa, Ferguson,Kuffner (2008) formulate door drawer operation kinematically constrainedplanning problem propose use caging grasps enlarge configuration space,demonstrate integrated system performing various fetch-and-carry tasks(Srinivasa, Ferguson, Helfrich, Berenson, Romea, Diankov, Gallagher, Hollinger, Kuffner,& Vandeweghe, 2010). Wieland et al. (2009) combine force visual feedback reduceinteraction forces opening kitchen cabinets drawers. contrast work,approaches make strong assumptions articulated objects, dealproblem inferring kinematic structure. Therefore, neither deal unknown objects, improve performance learning. Katz Brock (2008)enabled robot first interact planar kinematic object table ordervisually learn kinematic model, manipulate object using modelachieve goal state. contrast work, approach assumes planar objectslearns 2D models. Jain Kemp (2009b, 2010) recently presented approachenabled robot estimate radius location axis rotary joints moveplane parallel ground, opening novel doors drawers using equilibriumpoint control. Recently, combined (in collaboration Jain Kemp) modellearning approach equilibrium point controller (Sturm et al., 2010). enabledrobot operate larger class articulated objects, i.e., objects non-verticalrotation axes.7. Conclusionpaper, presented novel approach learning kinematic models articulatedobjects. approach infers connectivity rigid parts constitute objectincluding articulation models individual links. model links, approachconsiders both, parametrized well parameter-free representations. extensive studiessynthetic real data, evaluated behavior model estimation, modelselection, structure discovery. shown approach applicable520fiA Probabilistic Framework Learning Kinematic Models Articulated Objectswide range articulated objects, used conjunction varietydifferent sensor modalities. approach enables mobile manipulators operate unknownarticulated objects, learn models, improve time.Despite promising results presented paper, several open researchquestions remain future investigation. current approach, learn kinematic models static pose observations. would interesting include velocitiesaccelerations object body parts. would allow robot learn dynamicparameters well enable plan time-optimal motion trajectories. dynamicalmodel would enable robot accurately execute motions higher speeds. Furthermore,robot measure forces torques actuating object could additionallylearn friction damping profiles include information learned modelwell. robot could benefit information assess, example, whether doordrawer jammed.8. Acknowledgmentsauthors gratefully acknowledge help Advait Jain Charlie Kemp GeorgiaTech, particular collaboration joint development online model estimationcontrol approach described Section 4.3, evaluating approachmobile manipulation robot Cody described Section 5.3. Further, authors would likethank Vijay Pradeep Kurt Konolige Willow Garage inspired authorswork subject, contributed experiments motion capture devicereported Section 5.1. Additional thanks go Kurt Konolige joint developmentmarker-less perception algorithm stereo data outlined Section 4.2 wellevaluation presented Section 5.2. work partly supported EuropeanCommission grant agreement numbers FP7-248258-First-MM, FP7-260026-TAPAS,FP7-ICT-248873-RADHAR, DFG contract number SFB/TR-8.ReferencesAndreopoulos, A., & Tsotsos, J. K. (2008). Active vision door localization dooropening using playbot. Proc. Canadian Conf. Computer Robot Vision(CRV), pp. 310 Washington, DC, USA.Anguelov, D., Koller, D., Parker, E., & Thrun, S. (2004). Detecting modeling doorsmobile robots. Proc. IEEE Int. Conf. Robotics & Automation (ICRA),pp. 37773784.Bishop, C. (2007). Pattern Recognition Machine Learning (Information ScienceStatistics). Springer.Bradski, G., & Kaehler, A. (2008). Learning OpenCV: Computer Vision OpenCVLibrary. OReilly Media, Inc.Bromberg, F., Margaritis, D., & Honavar, V. (2009). Efficient markov network structurediscovery using independence tests. Journal Artificial Intelligence Research (JAIR),35.521fiSturm, Stachniss, & BurgardBrox, T., Rosenhahn, B., Gall, J., & Cremers, D. (2010). Combined region- motionbased 3D tracking rigid articulated objects. IEEE Transactions PatternAnalysis Machine Intelligence, 32(2), 402415.Chickering, D. M. (1996). Learning Bayesian networks NP-Complete. Fisher, D.,& Lenz, H. (Eds.), Learning Data: Artificial Intelligence Statistics V, pp.121130. Springer-Verlag.Chickering, D. M. (2002). Learning equivalence classes bayesian-network structures.Journal Machine Learning Research (JMLR), 2, 445498.Chitta, S., Cohen, B., & Likhachev, M. (2010). Planning autonomous door openingmobile manipulator. Proc. IEEE Int. Conf. Robotics & Automation(ICRA) Anchorage, AK, USA.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms. MIT Press.Daly, R., & Shen, Q. (2009). Learning bayesian network equivalence classes ant colonyoptimization. Journal Artificial Intelligence Research (JAIR), 35, 391447.Dellaert, F. (2005). Square Root SAM. Proc. Robotics: Science Systems (RSS),pp. 177184 Cambridge, MA, USA.Diankov, R., Srinivasa, S., Ferguson, D., & Kuffner, J. (2008). Manipulation planningcaging grasps. Proc. IEEE-RAS Intl. Conf. Humanoid Robots (Humanoids)Daejeon, Korea.Featherstone, R., & Orin, D. (2008). Dynamics. Siciliano, B., & Khatib, O. (Eds.),Handbook Robotics, pp. 3566. Springer, Secaucus, NJ, USA.Fiala, M. (2005). Artag, fiducial marker system using digital techniques. Proc.IEEE Conf. Computer Vision Pattern Recognition (CVPR).Fischler, M., & Bolles, R. (1981). Random sample consensus: paradigm model fittingapplication image analysis automated cartography. Commun. ACM., 24,381395.Fox, D., & Ren, X. (2010). Overview RGB-D cameras open research issues.Proceedings Workshop Advanced Reasoning Depth Cameras Robotics:Science Systems Conference (RSS) Zaragoza, Spain.Frese, U. (2006). Treemap: o(logn) algorithm indoor simultaneous localizationmapping. Autonomous Robots, 21 (2), 103122.Grisetti, G., Kummerle, R., Stachniss, C., Frese, U., & Hertzberg, C. (2010). Hierarchicaloptimization manifolds online 2D 3D mapping. Proc. IEEE Int.Conf. Robotics Automation (ICRA) Anchorage, AK, USA.Grisetti, G., Stachniss, C., & Burgard, W. (2009). Non-linear constraint network optimization efficient map learning. Trans. Intell. Transport. Sys., 10 (3), 428439.522fiA Probabilistic Framework Learning Kinematic Models Articulated ObjectsHe, R., Zhao, Y., Yang, S., & Yang, S. (2010). Kinematic-parameter identificationserial-robot calibration based poe formula. IEEE Transactions Robotics, 26 (3),411 423.Hollerbach, J., Khalil, W., & Gautier, M. (2008). Model identification. Siciliano, B., &Khatib, O. (Eds.), Handbook Robotics, pp. 321344. Springer, Secaucus, NJ, USA.Jain, A., & Kemp, C. (2009a). Behavior-based door opening equilibrium point control. Proc. RSS Workshop Mobile Manipulation Human EnvironmentsSeattle, WA, USA.Jain, A., & Kemp, C. (2009b). Pulling open novel doors drawers equilibrium pointcontrol. Proc. IEEE-RAS Intl. Conf. Humanoid Robots (Humanoids) Paris,France.Jain, A., & Kemp, C. (2010). Pulling open doors drawers: Coordinating omnidirectional base compliant arm equilibrium point control. Proc.IEEE Int. Conf. Robotics & Automation (ICRA) Anchorage, AK, USA.Katz, D., & Brock, O. (2008). Manipulating articulated objects interactive perception.Proc. Robotics: Science Systems (RSS), pp. 272277 Pasadena, CA, USA.Kirk, A., OBrien, J. F., & Forsyth, D. A. (2004). Skeletal parameter estimationoptical motion capture data. Proc. Int. Conf. Computer GraphicsInteractive Techniques (SIGGRAPH).Klingbeil, E., Saxena, A., & Ng, A. (2009). Learning open new doors. Proc.RSS Workshop Robot Manipulation Seattle, WA, USA.Konolige, K. (1997). Small vision systems: hardware implementation. Proc.Int. Symp. Robotics Research, pp. 111116.Konolige, K. (2010). Projected texture stereo. Proc. IEEE Int. Conf. Robotics& Automation (ICRA) Anchorage, AK, USA.Kragic, D., Petersson, L., & Christensen, H. (2002). Visually guided manipulation tasks.Robotics Autonomous Systems, 40 (2-3), 193 203.Krainin, M., Henry, P., Ren, X., & Fox, D. (2010). Manipulator object trackinghand model acquisition. Proc. IEEE Int. Conf. Robotics & Automation(ICRA) Anchorage, AK, USA.Lawrence, N. (2005). Probabilistic non-linear principal component analysis gaussianprocess latent variable models. J. Mach. Learn. Res., 6, 17831816.Lepetit, V., & Fua, P. (2005). Monocular model-based 3d tracking rigid objects. Foundations Trends Computer Graphics Vision, 1, 189.Lowe, D. (1991). Fitting parameterized three-dimensional models images. IEEE Transactions Pattern Analysis Machine Intelligence, 13, 441450.523fiSturm, Stachniss, & BurgardLu, F., & Milios, E. (1997). Globally consistent range scan alignment environmentmapping. Autonomous Robots, 4, 333349.MacKay, D. (2003). Information Theory, Inference, Learning Algorithms. CambridgeUniversity Press.Margaritis, D., & Thrun, S. (1999). Bayesian network induction via local neighborhoods.Proc. Conf. Neural Information Processing Systems (NIPS), pp. 505511.MIT Press.McClung, A., Zheng, Y., & Morrell, J. (2010). Contact feature extraction balancingmanipulation platform. Proc. IEEE Int. Conf. Robotics & Automation(ICRA).Meeussen, W., Wise, M., Glaser, S., Chitta, S., McGann, C., Patrick, M., Marder-Eppstein,E., Muja, M., Eruhimov, V., Foote, T., Hsu, J., Rusu, R., Marthi, B., Bradski, G.,Konolige, K., Gerkey, B., & Berger, E. (2010). Autonomous door opening pluggingpersonal robot. Proc. IEEE Int. Conf. Robotics & Automation(ICRA) Anchorage, AK, USA.Murillo, A. C., Kosecka, J., Guerrero, J. J., & Sagues, C. (2008). Visual door detectionintegrating appearance shape cues. Robotics Autonomous Systems, 56(6),pp. 512521.Niemeyer, G., & Slotine, J.-J. (1997). simple strategy opening unknown door.Proc. IEEE Int. Conf. Robotics & Automation (ICRA) Albuquerque, NM,USA.Nieuwenhuisen, M., Stuckler, J., & Behnke, S. (2010). Improving indoor navigationautonomous robots explicit representation doors. Proc. IEEEInt. Conf. Robotics & Automation (ICRA) Anchorage, AK, USA.Nister, D. (2005). Preemptive ransac live structure motion estimation. Mach. VisionAppl., 16 (5), 321329.Parlitz, C., Hagele, M., Kleint, P., Seifertt, J., & Dautenhahn, K. (2008). Care-o-bot 3- rationale human-robot interaction design. Proc. Int. SymposiumRobotics (ISR) Seoul, Korea.Pekelny, Y., & Gotsman, C. (2008). Articulated object reconstruction markerless motion capture depth video. Computer Graphics Forum, 27 (2), 399408.Petrovskaya, A., & Ng, A. (2007). Probabilistic mobile manipulation dynamic environments, application opening doors. Proc. Int. Conf. ArtificialIntelligence (IJCAI) Hyderabad, India.Pradeep, V., Konolige, K., & Berger, E. (2010). Calibrating multi-arm multi-sensor robot:bundle adjustment approach. Int. Symp. Experimental Robotics (ISER) NewDelhi, India.524fiA Probabilistic Framework Learning Kinematic Models Articulated ObjectsQuigley, M., Batra, S., Gould, S., Klingbeil, E., Le, Q., Wellman, A., & Ng, A. (2009).High-accuracy 3D sensing mobile manipulation: Improving object detectiondoor opening. Proc. IEEE Int. Conf. Robotics & Automation (ICRA)Kobe, Japan.Rasmussen, C., & Williams, C. (2006). Gaussian Processes Machine Learning.MIT Press, Cambridge, MA.Ross, D., Tarlow, D., & Zemel, R. (2008). Unsupervised learning skeletons motion.Proc. European Conf. Computer Vision (ECCV) Marseille, France.Roweis, S., & Saul, L. (2000). Nonlinear dimensionality reduction locally linear embedding. Science, 290 (5500), 23232326.Rusu, R. B., Meeussen, W., Chitta, S., & Beetz, M. (2009). Laser-based perception doorhandle identification. Proc. Int. Conf. Advanced Robotics (ICAR)Munich, Germany.Rusu, R. B., Marton, Z. C., Blodow, N., Dolha, M., & Beetz, M. (2008). Towards 3D pointcloud based object maps household environments. Robot. Auton. Syst., 56 (11),927941.Schwarz, G. (1978). Estimating dimension model. Annals Statistics, 6 (2).Sentis, L., Park, J., & Khatib, O. (2010). Compliant control multi-contact centermass behaviors humanoid robots. IEEE Trans. Robotics, 26 (3), 483501.Srinivasa, S., Ferguson, D., Helfrich, C., Berenson, D., Romea, A. C., Diankov, R., Gallagher, G., Hollinger, G., Kuffner, J., & Vandeweghe, J. M. (2010). HERB: homeexploring robotic butler. Autonomous Robots, 28 (1), 520.Sturm, J., Konolige, K., Stachniss, C., & Burgard, W. (2010). Vision-based detectionlearning articulation models cabinet doors drawers household environments.Proc. IEEE Int. Conf. Robotics & Automation (ICRA) Anchorage, AK,USA.Sturm, J., Pradeep, V., Stachniss, C., Plagemann, C., Konolige, K., & Burgard, W. (2009).Learning kinematic models articulated objects. Proc. Int. Joint Conf.Artificial Intelligence (IJCAI) Pasadena, CA, USA.Sturm, J., Jain, A., Stachniss, C., Kemp, C., & Burgard, W. (2010). Operating articulated objects based experience. Proc. IEEE International ConferenceIntelligent Robot Systems (IROS) Taipei, Taiwan.Taycher, L., Fisher, J., & Darrell, T. (2002). Recovering articulated model topologyobserved rigid motion. Proc. Conf. Neural Information Processing Systems(NIPS) Vancouver, Canada.Tenenbaum, J., de Silva, V., & Langford, J. (2000). global geometric frameworknonlinear dimensionality reduction.. Science, 290 (5500), 23192323.525fiSturm, Stachniss, & BurgardTorr, P. H. S., & Zisserman, A. (2000). Mlesac: new robust estimator applicationestimating image geometry. Computer Vision Image Understanding, 78, 2000.Wedel, A., Rabe, C., Vaudrey, T., Brox, T., Franke, U., & Cremers, D. (2008). Efficientdense scene flow sparse dense stereo data. Proc. European Conf.Computer Vision (ECCV) Marseille, France.Wieland, S., Gonzalez-Aguirre, D., Vahrenkamp, N., Asfour, T., & Dillmann, R. (2009).Combining force visual feedback physical interaction tasks humanoid robots.Proc. IEEE-RAS Intl. Conf. Humanoid Robots (Humanoids) Paris, France.Yan, J., & Pollefeys, M. (2006). Automatic kinematic chain building feature trajectories articulated objects. Proc. IEEE Conf. Computer VisionPattern Recognition (CVPR) Washington, DC, USA.526fiJournal Artificial Intelligence Research 41 (2011) 329-365Submitted 02/11; published 06/11Sequential Diagnosis AbstractionSajjad SiddiqiNational University Sciences Technology(NUST) Islamabad, Pakistansajjad.ahmed@seecs.edu.pkJinbo HuangNICTA Australian National UniversityCanberra, Australiajinbo.huang@nicta.com.auAbstractsystem behaves abnormally, sequential diagnosis takes sequence measurements system faults causing abnormality identified, goalreduce diagnostic cost, defined number measurements. proposemeasurement points, previous work employs heuristic based reducing entropycomputed set diagnoses. approach generally good performance termsdiagnostic cost, fail diagnose large systems set diagnoseslarge. Focusing smaller set probable diagnoses scales approach generallyleads increased average diagnostic costs. paper, propose new diagnosticframework employing four new techniques, scales much larger systems goodperformance terms diagnostic cost. First, propose new heuristic measurementpoint selection computed efficiently, without requiring set diagnoses,system modeled Bayesian network compiled logical form knownd-DNNF. Second, extend hierarchical diagnosis, technique based system abstraction previous work, handle probabilities applied sequentialdiagnosis allow larger systems diagnosed. Third, largest systemseven hierarchical diagnosis fails, propose novel method converts systemone smaller abstraction whose diagnoses form supersetoriginal system; new system diagnosed result mapped backoriginal system. Finally, propose novel cost estimation functionused choose abstraction system likely provide optimal averagecost. Experiments ISCAS-85 benchmark circuits indicate approach scalescircuits suite except one flat structure susceptible usefulabstraction.1. Introductionsystem behaves abnormally, task diagnosis identify reasonsabnormality. example, combinational circuit Figure 1, given inputsP Q R, output V 0, actually 1 due faults gates JB. Given system comprising set components, knowledge base modelingbehavior system, along (abnormal) observed values system variables,(consistency-based) diagnosis set components whose failure (assumingcomponents healthy) together observation logically consistentsystem model. example, {V }, {K}, {A}, {J, B} diagnoses givenc2011AI Access Foundation. rights reserved.fiSiddiqi & HuangBUFFER1P1Q11J1B11V1K0RFigure 1: faulty circuit.observation. general, number diagnoses exponential numbersystem components, one correspond set actual faults.paper, therefore, consider problem sequential diagnosis (de Kleer &Williams, 1987), sequence measurements system variables takenactual faults identified. goal reduce diagnostic cost, definednumber measurements. propose measurement points, state-of-the-art gde (generaldiagnosis engine) framework (de Kleer & Williams, 1987; de Kleer, Raiman, & Shirley, 1992;de Kleer, 2006) considers heuristic based reducing entropy set computeddiagnoses. approach generally good performance terms diagnostic cost,fail diagnose large systems set diagnoses large (de Kleer & Williams,1987; de Kleer et al., 1992; de Kleer, 2006). Focusing smaller set probable diagnosesscales approach generally leads increased average diagnostic costs (de Kleer,1992).propose new diagnostic framework employing four new techniques, scalesmuch larger systems good performance terms diagnostic cost. First, proposenew heuristic require computing entropy diagnoses. Instead considerentropies system variables measured well posterior probabilitiescomponent failures. idea select component highest posteriorprobability failure (Heckerman, Breese, & Rommelse, 1995) variablescomponent, measure one highest entropy. compute probabilities,exploit system structure joint probability distribution faultssystem variables represented compactly Bayesian network (Pearl, 1988),compiled deterministic decomposable negation normal form (d-DNNF) (Darwiche, 2001;Darwiche & Marquis, 2002). d-DNNF logical form exploit structure presentmany systems achieve compactness used compute probabilistic queriesefficiently. Specifically, required posterior probabilities exactly computedevaluating differentiating d-DNNF time linear d-DNNF size (Darwiche,2003).330fiSequential Diagnosis AbstractionSecond, extend hierarchical diagnosis, technique previous work (Siddiqi& Huang, 2007), handle probabilities applied sequential diagnosisallow larger systems diagnosed. Specifically, self-contained subsystems, called cones,treated single components diagnosed found faultytop-level diagnosis. significantly reduces number system components, allowinglarger systems compiled diagnosed. example, subcircuit dotted boxFigure 1 cone (with output {P, D} inputs) contains fault. First,cone A, whole, determined faulty. compiled separatelydiagnosed. previous work (Siddiqi & Huang, 2007) dealt taskcomputing diagnoses, involve measurements probabilities; presentpaper, present several extensions allow technique carry sequentialdiagnosis.Third, abstraction system still large compiled diagnosed,use novel structure based technique called cloning, systematically modifiesstructure given system C obtain new system C0 smaller abstractionwhose diagnoses form super-set original system; new systemdiagnosed result mapped back original system. idea selectsystem component G part cone hence cannot abstracted awayhierarchical diagnosis, create one clones G, distribute Gs parents (fromgraph point view) among clones, way G clones become partscones disappear abstraction. Repeated applications operationallow otherwise unmanageable system small enough abstraction diagnosissucceed.Finally, propose novel cost estimation function predict expecteddiagnostic cost given abstraction system used diagnosis. aimfind abstraction system likely give optimal average cost.purpose, use function various abstractions system differentabstractions obtained destroying different cones system (by destroyingcone mean overlook fact cone include componentsabstraction). abstraction lowest predicted cost used actualdiagnosis.Experiments ISCAS-85 benchmark circuits (Brglez & Fujiwara, 1985) indicatesolve first time nontrivial multiple-fault diagnostic cases benchmarks, good diagnostic costs, except one circuit flat structure susceptibleuseful abstraction, new cost estimation function often accurately predictabstraction likely give optimal average cost.2. Background Previous WorkSuppose system diagnosed formally modeled joint probability distribution P r(X H) set variables partitioned X H. Variables Xwhose values either observed measured, variables H health variables, one component describing health mode. joint probability distributionP r(X H) defines set system states.331fiSiddiqi & HuangDiagnosis starts initial (belief) stateI0 = P r(X H | Xo = xo )(1)values xo variables Xo X (we using boldface uppercase letters meansets vectors) given observation, wish reach goal state= P r(X H | Xo = xo , Xm = xm )(2)measuring values xm variables Xm X\Xo , |Xm | = n, one time,(the boldface 0 1 denote vectors 0s 1s):Hf H, P r(Hf = 0 | Xo = xo , Xm = xm ) = 1P r(Hf = 0, H\Hf = 1 | Xo = xo , Xm = xm ) > 0.is, goal state set components Hf known faulty certaintylogical inconsistency arises components assumed healthy.types goal conditions possible. example, health states componentsdetermined certainty, condition P r(H = 0 | Xo = xo , Xm = xm )0 1 H H (such goals possible reach strong fault models given,strong fault models explicit descriptions abnormal behavior, opposedweak fault models normal behavior known).Two special cases worth mentioning: (1) initial state I0 satisfies goalcondition Hf = observation normal diagnosis required. (2)initial state I0 satisfies goal condition Hf 6= , observationabnormal diagnosis already completed (assuming able checkprobabilities necessary); words, sequence length 0 solves problem.Following de Kleer Williams (1987) assume measurements unitcost. Hence objective reach goal state fewest measurements possible.classical gde framework, receiving abnormal observation Xo = xo , considersShannons entropy probability distribution set computed diagnoses,either set minimum-cardinality diagnoses set probable/leading diagnoses. proposes measure variable X whose value reduce entropy most,average. idea probability distribution diagnoses reflectsuncertainty actual faults, entropy captures amount uncertainty.measurement taken entropy updated updating posterior probabilitiesdiagnoses, potentially reducing 0.results reported de Kleer et al. (1992) involving single-fault cases ISCAS-85circuits indicate method leads measurement costs close optimalpolicies. However, major drawback impractical numberdiagnoses large (e.g., set minimum-cardinality diagnoses exponentiallylarge). Focusing smaller set probable diagnoses scales approach increaselikelihood irrelevant measurements generally leads increased average diagnosticcosts (de Kleer, 1992).on, shall use combinational circuits example type systemswish diagnose. approach, however, applies well types systems332fiSequential Diagnosis AbstractionP10P0.50.5P11110000okJ11001100okJ10J10101010okJ0.90.1J|P,okJ010.50.5100.50.5Figure 2: Bayesian network circuit Figure 1 (left). CPTs nodes P , J,okJ (right).long probabilistic model given defines behavior system. Sections 45 present new techniques introduced significantly enhancescalability sequential diagnosis. start, however, presenting following sectionsystem modeling compilation method underlies new diagnostic system.3. System Modeling Compilationorder define joint probability distribution P r(X H) system behavior,first assume prior probability failure P r(H = 0) given componentH H part input diagnosis task (de Kleer & Williams, 1987). example,small table two entries top-right Figure 2 gives prior probabilityfailure gate J 0.1.3.1 Conditional Probability TablesPrior fault probabilities alone define joint probability distribution P r(X H).addition, need specify component output related inputshealth mode. conditional probability table (CPT) component job.CPT shown bottom (right) Figure 2, example, defines behaviorgate J: entry gives probability output (J) particular value givenvalue input (P ) value health variable (okJ). case okJ = 1,probabilities always 0 1 behavior healthy gate deterministic.case okJ = 0 defines fault model gate, also part inputdiagnosis task. example, assume output values probability 0.5gate broken. simplicity assume gates two health modes333fiSiddiqi & Huang(i.e., health variable binary); encoding compilation described later,however, allows arbitrary number health modes.Given tables, joint probability distribution circuit behaviorobtained realizing gates circuit satisfy independence property, knownMarkov property: Given inputs health mode, output gate independentwire descendant gate (a wire X descendant gate Xreached following path output circuit direction towardscircuit outputs). means circuit effectively treated Bayesiannetwork straightforward way, node wire health variable,edge going input gate output, also healthvariable gate output. Figure 2 shows result translation circuitFigure 1.joint probability distribution encoded Bayesian network provides basiscomputing posterior probabilities may need proposing measurementpoints (by chain rule). However, provide efficient way so.Specifically, computing posterior P r(X = x | = y) given values variablesknown values involves summing variables X Y,complexity exponential number variables done naively.3.2 Propositional Modelingknown Bayesian network encoded logical formula compiledd-DNNF, which, successful, allows posterior probabilities variables computed efficiently (Darwiche, 2003). purposes sequential diagnosis, encodeBayesian network follows.Consider subcircuit dotted box Figure 1 example,modeled following formula:okJ (J P ), okA (A (J D)).Specifically, signal circuit translates propositional variable (A, D,P , J), gate, extra variable introduced model health (okA, okJ).formula health variables true remaining variablesconstrained model functionality gates. general, component X,okX NormalBehavior(X).Note formula fails encode half CPT entries, okJ = 0.order complete encoding CPT node J, introduce extra Boolean variableJ , write okJ (J J ). Finally, health variables (okA, okJ) associatedprobabilities respective gates healthy (0.9 experiments),-variable (J ) associated probability corresponding gate givingoutput 1 broken (0.5 experiments; thus assuming output faultygate probabilistically independent inputs).encoding circuit similar encoding Bayesian networks described Darwiche (2003) following way: According encoding Darwiche,every node Bayesian network every value indicator variable.Similarly every conditional probability network parameter variable.334fiSequential Diagnosis Abstractionencoding, variables wires analogous network indicators,encoding optimized single indicator values wire. Also,encoding exploits logical constraints generate network parameterszeros ones CPT. Finally, encoding node represents health variable optimized need single ok-variable servesindicator network parameter.components encoded described above, union (conjunction)formulas compiled d-DNNF. required probabilities exactly computedevaluating differentiating d-DNNF time linear size (Darwiche, 2003).Details compilation process discussed Darwiche (2004), computationprobabilities described Appendix A.present hierarchical diagnosis approach propose new measurementselection heuristic.4. Hierarchical Sequential Diagnosisoptimal solution sequential diagnosis would policy, is, plan measurements conditioned previous measurement outcomes, path plan leadsdiagnosis system (Heckerman et al., 1995). computing optimal policiesintractable general, follow approach heuristic measurement point selectionprevious work.start definition Shannons entropy , defined respectprobability distribution discrete random variable X ranging values x1 , x2 , . . . , xk .Formally:kX(X) =P r(X = xi ) log P r(X = xi ).(3)i=1Entropy measures amount uncertainty value random variable.maximal probabilities P r(X = xi ) equal, minimal oneprobabilities 1, corresponding nicely intuitive notion degree uncertainty.gde entropy computed probability distribution set computeddiagnoses (i.e., value random variable X ranges set diagnoses).mentioned earlier, entropy difficult compute number diagnoseslarge (de Kleer & Williams, 1987; de Kleer, 2006).4.1 Baseline ApproachAble compute probabilities efficiently exactly following successful d-DNNF compilation, propose new two-part heuristic circumvents limitation scalability.First, consider entropy candidate variable measured.4.1.1 Heuristic Based Entropy VariableSince wire X two values, entropy written as:(X) = (px log px + px log px )335(4)fiSiddiqi & Huangpx = P r(X = 1 | = y) px = P r(X = 0 | = y) posterior probabilitiesX values 1 0, respectively, given values wires whose valuesknown.(X) captures uncertainty value variable, also interpretexpected amount information gain provided measuring variable. Hencefirst idea consider selecting variable maximal entropy measurementstep.4.1.2 Improving Heuristic Accuracyidea alone, however, work well initial experiments. wouldconfirmed subsequent experiments, largely due fact (implicit) spacediagnoses generally large include large number unlikely diagnoses,tends compromise accuracy information gain provided entropy.experiments confirm explanation follows.d-DNNF compilation produced, used compute probabilities, prune d-DNNF graph models (satisfying variable assignments)corresponding diagnoses k broken components removed.1 setinitial k number actual faults experiments, observed significantreduction diagnostic cost resulted almost cases. improved performance apparently due fact pruning updates posterior probabilities variables,making accurate since many unlikely diagnoses eliminated.practice, however, number faults known beforehand choosingappropriate k pruning nontrivial (note k need exactlynumber actual faults pruning help). Interestingly, following heuristic,one actually use, appears achieve similar performance gainautomatic way: select component highest posterior probability failure(an idea Heckerman et al., 1995; see Section 8), variablescomponent, measure one highest entropy. heuristic requirepruning d-DNNF, appears improve diagnostic cost similarextent focusing measurement selection component likely broken(empirical results effect given discussed Section 7.1).4.1.3 Algorithmstart encoding system logical formula discussed Section 3,subset variables associated numbers representing prior fault probabilitiesprobabilities involved fault models components, compiledd-DNNF .overall sequential diagnosis process propose summarized Algorithm 1.inputs system C, d-DNNF compilation , set faults (which emptyused hierarchical approach), set known values variables,integer k specifying fault cardinality bound (this running model pruningexperiments described Section 4.1.2, required diagnosis using final1. complete pruning easy; however, approximation achieved time linear d-DNNFsize, variant minimization procedure described Darwiche (2001); see Appendix B.336fiSequential Diagnosis AbstractionAlgorithm 1 Probabilistic sequential diagnosisfunction psd(C, , D, y, k)inputs: {C: system}, {: d-DNNF}, {y: measurements}, {k: fault cardinality}, {D: ordered setknown faults}output: {pair< , >}1: Reduce ( , D, k |D| ) changed2: Given variables Y, Evaluate (, y) obtain P r(y)3: Differentiate () obtain P r(X = 1, y) variables X4: Deduce fault = {X : P r(okX = 1, y) = 0}5: changed && MeetsCriteria(,D,y)6:return < , >7: Measure variable X best given heuristic8: Add measured value x X y, go back line 1heuristic). reduce pruning models (line 1) fault cardinality boundk given, using function reduce(, D, k |D|). reduce accepts argumentscurrent DNNF , set known faults D, upper bound given kcardinality remaining faults, whereas returns pruned DNNF. Reduce excludesknown faults computing minimum cardinality , uses k |D|bound remaining faults (explained Appendix B). reduced firsttime psd called later time changed (i.e., component foundfaulty). evaluate (line 2) differentiate (line 3) (see Appendix A), selectmeasurement point take measurement (line 7), repeat process (line 8)stopping criteria met (line 5).stopping criteria line 5 given earlier Section 2 goal condition, i.e.,stop abnormal observation explained faulty components alreadyidentified assuming components healthy. faulty component X identifiedP r(okX = 1, y) = 0 values variables already known,mentioned earlier probabilities obtained variables simultaneouslyd-DNNF differentiation process. Finally, condition current set faultycomponents, health modes Hf , explains observation satisfied P r(Hf =0, H\Hf = 1, y) > 0, checked single evaluation original d-DNNF.algorithm returns actual faults together new set known values variables(line 6).4.2 Hierarchical Approachscale approach handle larger systems using idea abstraction-basedhierarchical diagnosis (Siddiqi & Huang, 2007). basic idea compilationsystem model d-DNNF efficient scalable numbersystem components reduced. achieved abstraction, subsystems,known cones, treated single components. example cone depictedFigure 1. objective use single health variable failure probabilityentire cone, hence significantly reducing size encoding difficultycompilation. cone identified faulty top-level diagnosis,compiled diagnosed, recursive fashion.337fiSiddiqi & Huanggive formal definition abstraction previous work:4.2.1 Abstraction SystemAbstraction based upon structural dominators (Kirkland & Mercer, 1987) system.component X dominates component , X called dominator , pathoutput system contains X. cone corresponds precisely setcomponents dominated component. cone may contain cones leadinghierarchy cones.system abstracted treating maximal cones black boxes (a maximalcone one either contained cone contained exactly one conewhole system). example, cone treated virtual gatetwo inputs {P, D} output A. abstraction system formally definedas:Definition 1 (Abstraction System). Given system C, let C0 = C C singleoutput; otherwise let C0 C augmented dummy component collecting outputsC. Let output C0 . abstraction AC system C setcomponents X C X dominated C0 component XO.example, AC = {A, B, D, K, V }. J 6 AC J cannot reach output withoutpassing A, dominator J.previous work (Siddiqi & Huang, 2007), dealt task computing minimum-cardinality diagnoses, involve probabilities measurementselection. context sequential diagnosis, several additional techniquesintroduced, particularly computation prior failure probabilities conesway measurement points selected, outlined below.4.2.2 Propositional Encodingstart discussion hierarchical encoding probabilistic reasoning,similar hierarchical encoding presented previous work (Siddiqi & Huang, 2007).Specifically, diagnosis abstraction AC given system C, health variablesassociated components AC \IC , gates {A, B, D, K, V }example (IC stands set inputs system C). Thus gate J Figure 1associated health variable, J wire internal cone rootedA. Consequently, nodes representing components AC \IC healthnodes associated corresponding Bayesian network. Hence node okJremoved Bayesian network Figure 2.addition, define failure cone outputs wrong value,introduce extra clauses model abnormal behavior cone. example,encoding given Section 3.2 cone Figure 1 (in dotted box) follows:J P, okA (A (J D)), okA (A 6 (J D))first part formula encodes normal behavior gate J (without healthvariable); next encodes normal behavior cone; last encodes338fiSequential Diagnosis Abstractioncone outputs wrong value fails. gates (that roots cones)abstraction AC encoded normally described Section 3.2.Note formulas components cone together encode single CPTwhole cone, provides conditional probability cones output givenhealth inputs cone, instead health inputs componentroot cone. example, encoding meant provide conditionalprobability given P , D, okA (instead J, D, okA), okA representshealth mode whole cone associated prior failure probability,initially unknown us computed cones (explained below).encoding whole system provides joint probability distribution variablesAC IC H, H = {okX | X AC \IC }.4.2.3 Prior Failure Probabilities Conescone treated single component, prior probability failure wholecomputed given prior probabilities components cones inside it.creating two copies h f cone, h models healthy behaviorcone (without health variables), f includes faulty behavior well (i.e.,full encoding described Section 3.2). outputs h f collectedXOR-gate X(when output XOR-gate X equals 1, inputs forceddifferent value). compute probability P r(X = 1) giving probabilityoutputs h f different. probability computed compilingencoding d-DNNF evaluating X = 1.Note procedure also abstraction-based hierarchical, performedbottom-up probabilities inner cones computed outerones. Also note performed per system pre-processing step.4.2.4 Measurement Point Selection Stopping Criteriaprinciple, heuristic select variables measurement stopping criteriabaseline approach; however, couple details worth mentioning.First, diagnosing abstraction given system (or cone) C, measurementcandidates restricted variables AC IC , ignoring internal variables maximalconesthose measured cone whole found faulty.Second, generally important full knowledge values cones inputsfinal diagnosis cone concluded. diagnosis cone concludedpartial knowledge inputs may include faults vital validityglobal diagnosis. reason diagnosis cone assumes unknowninputs take either value, reality values may become fixed variablesparts system measured, causing diagnosis certain cones becomeinvalid, possibly requiring affected cones diagnosed meetglobal stopping criteria (see line 17 Algorithm 2).avoid situation retaining effectiveness heuristic, modifymeasurement point selection follows diagnosing cone. selecting componenthighest probability failure, consider variables component plusinputs cone, measure one highest entropy. conclude339fiSiddiqi & HuangAlgorithm 2 Hierarchical probabilistic sequential diagnosisfunction hpsd(C, uC , k)inputs: {C : system},{uC : obs. across system} {k: fault cardinality}local variables: {B, D, : set components} {y, z, uG : set measurements} {i, k 0 : integer}output: {pair< , uC >}1: Compile2dDNNF (AC , uC )2: 0 , , uC3: < B, > psd (C, , B, y, k)4: {; < |B|; + +}5:G Element (B, i)6:G cone7:z Implications (, y)8:uG {x : x z, X IG OG }9:k 0 k |D| |B| + + 210:< T, uG > hpsd(DG IG , uG , k 0 )11:uG ,12:Evaluate (, y), Differentiate ( )13:else14:{G}15: z Implications (, y)16: uC uC {x : x z, X IC OC }17: MeetsCriteria (C, D, y)18:return < , uC >19: else20:goto line 3diagnosis cone values inputs become known (through measurementdeduction), except health components cone determinedwithout knowing inputs cone (it possible identify faulty component,strong fault models also healthy component, without knowing inputs).Note restriction measure inputs cone lead significantincrease cost compared cost baseline approach; especially numberinputs cone large. discussed detail Section 6.4.2.5 AlgorithmPseudocode hierarchical approach given Algorithm 2 recursive function.inputs system C, set known values uC variables inputs ICoutputs OC system, optional integer k specifying fault cardinalitybound purpose experimenting effect model pruning. startd-DNNF compilation abstraction given system (line 1) usefunction psd Algorithm 1 get diagnosis B abstraction (line 3), assumingmeasurement point selection stopping criteria Algorithm 1 modifiedaccording described Section 4.2.4. abstract diagnosis B usedget concrete diagnosis loop (lines 414). Specifically, component G Broot cone, added (line 14); otherwise cone G recursivelydiagnosed (line 10) result added (line 11). recursively diagnosing340fiSequential Diagnosis Abstractioncone G, subsystem contained G represented DG IG , DG setcomponents dominated G IG set inputs cone G.recursively diagnosing cone G, compute abnormal observation uGinputs output (IG {G}) cone G. values Gs inputs outputeither measured deduced current set measurements. valuevariable X implied x measurements P r(X = x, y) = 0,easy check differentiated y. function Implications(, y)(lines 7 15) implements operation, used compute partial abnormalobservation uG (line 8). fault cardinality bound k 0 cone G inferred (line 9),algorithm called recursively diagnose G, given uG k 0 .recursive call returns faults inside cone G together updatedobservation uG . observation uG may contain new measurement results regardingvariables IG {G}, added set measurements abstraction(line 11); measurement results obtained inside cone ignored due reasonsexplained Section 4.2.4. concrete diagnosis augmented faults foundinside cone (line 11), evaluated differentiated light newmeasurements (line 12).loop ends, variable uC updated known values inputsIC outputs OC system C (line 16). stopping criteria checkeddiagnosis (line 17) met function returns pair < D, uC > (line 18); otherwisemeasurements taken stopping criteria (line 17) met.Since contain faults inside cones, compilation cannot usedcheck stopping criteria (note change parameters functionMeetsCriteria line 17) probabilistic information regarding variables inside conesavailable . criteria checked follows instead: maintain depthlevel every component system. outputs system depth level 1rest components assigned depth levels based upon length shortestroute output system. example, Figure 1 gates B J depthlevel 3, depth level 2. Hence, B J deeper A. first propagatevalues inputs system, propagate fault effects componentsD, one one, flipping values abnormal ones propagating towardssystem outputs way deeper faults propagated first (Siddiqi & Huang,2007), check values system outputs obtained equalityobservation (y).4.2.6 ExampleSuppose diagnose abstraction circuit Figure 1, observationuC = {P = 1, Q = 1, R = 0, V = 1}, take sequence measurements = {D =1, K = 1, = 1}. concluded, abstract system model, given valuesP D, value 1 abnormal. algorithm concludes fault A. NoteQ = 1 = 1 suggests presence another fault besides A, triggeringmeasurement gate B, also found faulty. abstract diagnosis {A, B} meetsstopping criteria respect abstract circuit.341fiSiddiqi & Huang1P1Q11EJ1B111V1K0RFigure 3: faulty circuit faults B J.1P1J1E11B1Q1B'11V1K0RFigure 4: Creating clone B 0 B according D.enter diagnosis cone recursive call observation uA = {P =1, B = 1, = 1}. diagnosis cone immediately reveals cone Efaulty. Hence make recursive call order diagnose E observationuE = {P = 1, B = 1, E = 1}. unknown wire J measured gate J foundfaulty, explains observation outputs cones E well A, giveninputs P B. recursion terminates abstract diagnosis B = {A, B} generatesconcrete diagnosis = {J, B}, meets stopping criteria algorithmterminates.5. Component Cloningpreceding section, proposed abstraction-based approach sequential diagnosis, reduces complexity compilation diagnosis reducing numbersystem components diagnosed. take one step further, aiming handlesystems large remain intractable even abstraction, caselargest circuits ISCAS-85 benchmark suite.solution novel method systematically modifies structure systemreduce size abstraction. Specifically, select component G parents P (acomponent X parent component , child X, outputinput X) part cone hence cannot abstracted away hierarchical342fiSequential Diagnosis Abstractiondiagnosis, create clone G0 according parents P0 P senseG0 inherits children G feeds P0 G longer feeds P0 (seeFigures 3 4 example). idea create sufficient number clones GG clones become part cones hence abstracted away.Repeated applications operation allow otherwise unmanageable systemsmall enough abstraction compilation diagnosis succeed. hierarchicalalgorithm extended diagnose new system result mappedoriginal system. show solve almost benchmark circuits, usingapproach.go details new method, differentiate techniqueknown node splitting (Choi, Chavira, & Darwiche, 2007), used solve MPEqueries Bayesian network. Node splitting breaks enough number edgesnodes network MPE query resulting network becomes easysolve. broken edge replaced root variable uniform prior. resultingnetwork relaxation approximation original MPE solution,may computed compilation, gives upper bound MPE solutionoriginal network. depth-first branch bound search algorithm searchesoptimal solution using bounds prune search space. similar approach alsoused solve Weighted Max-SAT problems (Pipatsrisawat & Darwiche, 2007).version node splitting directly applicable present settingfollowing reasons. edges system broken redirected new root variables(primary inputs), resulting system represents different input-output functionoriginal system. abnormal observation original system may hencebecome normal one new system (if edges fault propagatesbroken), eliminating basis diagnosis. technique component cloning,also viewed version node splitting, introduces clones component insteadprimary inputs preserves input-output function system. Also, newsystem relaxation original diagnoses supersetoriginal.formally define component cloning:Definition 2 (Component Cloning). Let G component system C parentsP. say G cloned according parents P0 P system C resultssystem C0 follows:edges going G parents P0 removed.new component G0 functionally equivalent G added systemG0 shares inputs G feeds P0 .Figures 3 4 show example creating clone B 0 B according {D}results new circuit whose abstraction contains gates {A, D, K, V }, whereasabstraction original circuit contains also gate B.5.1 Choices Component Cloningtwo choices made component cloning: components clone,many clones create split parents?343fiSiddiqi & HuangSince goal cloning reduce abstraction size, clear wishclone components lie abstraction (i.e., within cones). Among these,cloning root cone cannot reduce abstraction size destroy existingcone reintroducing components inside cone abstraction.example, cloning according K Figure 4 produce circuit cloneabstracted away B 0 longer dominated hence reintroducedabstraction. Therefore, final candidates cloning precisely componentsabstract system roots cones. Note ordercandidates processed unimportant cloned produce equalreduction, namely reduction precisely 1 abstraction size, any.remains determine candidate many clones createconnect parents. understand final method, helps considernaive method simply creates |P| 1 clones (where P set parents)clone, well original, feed exactly one parent. way every parentcomponent becomes root cone component clonesabstracted away. Figure 3, example, B three parents {E, A, D}, naivemethod would create two clones B total three instances gate splitthree parents, would result abstraction Figure 4.trick number clones reduced knowing parentscomponent may lie cone single clone component accordingparents sufficient clone abstracted away. exampleFigure 3, again, parents E, B lie cone would suffice createsingle clone B according {E, A}, resulting same, efficient cloningFigure 4.formally, partition parents component G subsets P1 , P2 , . . . , Pqparents G lie cone placed subsetrest separate ones. create q 1 clones G according q 1subsets, resulting G clones abstracted away. process repeatedcandidate component abstraction size small enough reductionpossible.5.2 Diagnosis Component Cloningnew system functionally equivalent original smaller abstraction,equivalent original diagnostic purposes. new model allowscomponent clones fail independently other, relaxationoriginal model diagnoses new system form supersetoriginal. Specifically, diagnosis new system assigns health statecomponent clones components corresponds diagnosis originalsystem; diagnoses spurious ignored.core diagnosis process given Algorithm 2 continues applicable newsystem, two minor modifications necessary. First, spurious diagnoses(implicitly) filtered assuming health state clones (includingoriginal) component soon health state one known. Second,whenever measurement clone component proposed, actual measurement344fiSequential Diagnosis Abstractionc7552Number Cone Inputs605040302010005001000150020002500ConesFigure 5: Cones ISCAS-85 circuits.taken original component original system, obvious reasons (in words,new system used reasoning original measurements).principle, presence spurious diagnoses model potentially skewmeasurement point selection heuristic (at least early stages diagnosis,spurious diagnoses gradually filtered out). However, using smaller benchmarkscould diagnosed without cloning, conducted empirical analysisindicates, interestingly, overall diagnostic cost slightly affected.discuss detail Section 7.3.6. Diagnostic Cost Estimationaddress interesting issue stemming observation made conducting experiments (to detailed next section): system abstraction always beneficialcompilation, diagnostic cost always improve associated hierarchicaldiagnosis. one hand, hierarchical diagnosis approach help casesotherwise result high costs using baseline approach quickly finding faulty portionssystem, represented set faulty cones, directing sequential diagnosistake measurements inside cones, resulting useful measurements.hand, introduce overhead cases needlessly go hier345fiSiddiqi & Huangarchies locate actual faults, measure inputs cones involved, baselineversion find directly efficiently.overhead hierarchical approach quite high faults lie coneslarge number inputs. example, graphs Figure 5 show number inputs,represented dots, various cones ISCAS-85 circuits. Note conessmall number inputs; however, cones 30 inputs, especiallyc432 circuits beyond c1908, contribute increased diagnostic costseveral cases (such increase cost due cones also confirmed separate setexperiments using large set systematically generated combinational circuits, detailedAppendix C). avoid potential high cost diagnosis faults lie conelarge number inputs tempting destroy cone compilationfault directly found. However, due associated increaseabstraction size, destroying cones may cause increased costs cases couldpreviously solved efficiently, thus may show negative impact, overall.calls automatic mechanism predict effect destroying certain conesoverall diagnostic cost, subject section.propose novel cost estimation function predict average diagnostic costgiven abstraction system considered diagnosis, different abstractionsobtained destroying different cones system. Since cones destroyedautomatically, function used automatically propose abstraction system, used diagnosis, likely give optimal average cost. functionuses hierarchical structure given abstraction predict costtake account parameters may also contribute cost, probabilities. addition function limited single fault cases only. Therefore, expectedcost computed function indicative cannot always correct. However,experiments show function often quite useful proposing abstractionsystem likely give optimal cost (to discussed next section).estimate expected diagnostic cost assume composed two quantitiesnamely isolation cost abstraction cost, inversely proportionalother. isolation cost captures well given system abstraction isolatefaulty portions system. Therefore isolation cost minimum completeabstraction system used (i.e., cones considered) generally increasescones destroyed. abstraction cost captures overhead cost due introductioncones. Hence, abstraction cost minimum (zero) abstraction consideredgenerally increases cones introduced.define isolation cost diagnosis considering abstraction systemaverage cost required isolate single fault system using abstraction.Similarly, define abstraction cost diagnosis average overhead cost requireddiagnose single fault system using abstraction. expected averagecost diagnosis abstraction system considered diagnosis sumisolation abstraction costs abstraction. different cones destroyedgiven abstraction system expect changes values abstractionisolation costs, determine whether overall cost go (if changesuneven) stay constant (if changes even). idea obtain abstraction346fiSequential Diagnosis Abstractionsystem strike balance two quantities get overall optimal cost.discuss isolation abstraction costs estimated.noted experiments using baseline approach heuristicisolate single fault system cost average comparable log2number measurement points system, provided us basiscomputing isolation cost. hierarchical approach, fault lies inside coneone first estimate isolation cost diagnosing cone, separately, addisolation cost diagnosing abstract system get average isolation cost(single) faults lie cone. example, cones consideredcost isolating fault circuit Figure 3 log2 (6) = 2.58 (values P , Q, RV already known). However, cones considered cost isolating faultlies inside cone sum isolation cost abstract circuitisolation cost subcircuit inside cone A, log2 (4) + log2 (1) = 2. Similarly,get average isolation cost single faults system, using hierarchicalapproach, one add isolation cost diagnosing abstract system averageisolation costs diagnosing abstract components (where isolation costabstract component cone zero). Note isolation costdiagnosing cone computed taking abstraction cone.estimate abstraction cost diagnosis given abstraction first needestimate overhead cost involved individual component systemabstraction. estimate overhead cost a, possibly faulty, component onetake union inputs outputs cones component lies,number measurement points (approximately) constitutes required overheadcost component. component lie cone overhead costcomponent zero. example, circuit Figure 3 diagnosed usinghierarchical approach, find gate J faulty one must first find conefaulty cone E faulty gate J faulty. overheadcost gate J case 1 + 2 + 1 = 4 (i.e., measure wires A, B, E,J, assuming Q known). abstraction cost diagnosis given abstractionsystem average overhead costs system componentsabstraction.give formal definitions related cost estimation function. Let Pu (C)set measurement points system C whose values unknown,Pu (G) set inputs output abstract concrete component G whosevalues unknown. Let p number abstract components abstraction ACsystem C. Let Gi AC abstract component (either concrete component coneabstraction; concrete component abstraction regarded trivialcone containing component itself). Let DGi subsystem dominated GiAGi abstraction subsystem.isolation cost IC(C, AC ) abstraction AC system C considereddiagnosis sum log2 (|M Pu (AC )|) average isolation costs computed,similar manner, subsystems contained abstract components AC :347fiSiddiqi & Huang(Pplog2 (|M Pu (AC )|) + p1i=1 IC(DGi , AGi ), |M Pu (AC )| > 0IC(C, AC ) = 1 Ppotherwisei=1 IC(DGi , AGi )p(5)IC(DGi , AGi ) recursively computes isolation cost subsystem containedabstract component Gi , using Equation 5, taking abstraction AGi . Notecomputing IC(DGi , AGi ) assume inputs output Gi alreadymeasured. Thus Pu (DGi ) excludes inputs output cone Gi . Giconcretecomponent IC(DGi , AGi ) = 0. cones considered (AC = C)PpIC(DGi , AGi ) = 0 isolation cost simply equal log2 (|M Pu (C)|).i=1compute abstraction cost diagnosing system given abstractionfirst compute overhead costs diagnosing individual cones abstraction.multiply abstraction cost cone number components containedcone get total overhead cost components cone. Addingoverhead costs computed way cones abstraction dividingnumber total number concrete components whole system gives usaverage overhead cost per component, call abstraction cost. Formally: Letq cones AC . abstraction cost AC(C, AC ) abstraction ACsystem C considered diagnosis given as:AC(C, AC ) =q1 X|DGi | {M Pu (Gi ) + AC(DGi , AGi )} : Gi AC conen(6)i=1|DGi | number (concrete) components contained cone Gi , Pu (Gi )+AC(DGi , AGi ) recursively computes abstraction cost diagnosing cone Gi , usingEquation 6, taking abstraction AGi . abstraction cost Gi multiplied|DGi | effectively add cost measuring cone inputs output overhead costevery component inside cone. note computing AC(DGi , AGi )assume variables Pu (Gi ) already measured. Thus Pu (DGi )excludes inputs output cone Gi .Finally total expected cost EDC(C, AC ) diagnosing system C abstraction AC system considered diagnosis given as:EDC(C, AC ) = IC(C, AC ) + AC(C, AC ).(7)7. Experimental Resultssection provides empirical evaluation new diagnostic system, referredsda (sequential diagnosis abstraction), implements baseline, hierarchical,cloning-based approaches described Sections 4 5, cost estimation functiondescribed Section 6. experiments conducted cluster 32 computers consisting two types (comparable) CPUs, Intel Core Duo 2.4 GHz AMD Athlon 64X2 Dual Core Processor 4600+, 4 GB RAM running Linux. time limit 2348fiSequential Diagnosis Abstractionhours memory limit 1.5 GB imposed test case. d-DNNF compilation done using publicly available d-DNNF compiler c2d (Darwiche, 2004, 2005).CNF simplified compilation using given observation, allowed uscompile circuits, expense requiring fresh compilation per observation(see Algorithm 2, line 1).generated single- multiple-fault scenarios using ISCAS-85 benchmark circuits,scenario set gates assumed faulty. single-fault cases circuitsc1355 simulated equal prior probability faults generating n fault scenarioscircuit, n equals number gates circuit: scenario containsdifferent faulty gate. randomly generated 5 test cases (abnormal observations)n scenarios. multiple-fault scenarios would practicaldue large number combinations, circuit c1355 (respectively, largerc1355) simply generated 500 (respectively, 100) random scenarios givenfault cardinality random test case scenario.Thus test case faulty circuit gate gates give incorrectoutputs. inputs outputs circuit observed. values internal wirescomputed propagating inputs normal circuit towards outputs followedpropagating outputs assumed faulty gates one one deeper faultspropagated first. obtained values internal wires used simulateresults taking measurements. use P r(okX = 1) = 0.9 gates X circuit.Note cases, gates fail equal probability, conceivably hardersolve diagnoses tend less differentiable. Then, gate, two outputvalues given equal probability gate faulty. Again, tend makecases harder solve due high degree uncertainty. circuit faultcardinality, report cost (number measurements taken) time (includingcompilation time, CPU seconds) locate faults, averaged test cases solved.present experiments four subsections demonstrating effectivenessfour techniques proposed paper, namely new heuristic, hierarchical sequentialdiagnosis, component cloning, cost estimation function.7.1 Effectiveness Heuristicstart comparison baseline algorithm sda gde show sdaachieves similar diagnostic costs scales much larger circuits, hence illustratingeffectiveness new heuristic (along new way compute probabilities).7.1.1 Comparison gdecould obtain tutorial version gde (Forbus & de Kleer, 1993) comparison, downloadable http://www.qrg.northwestern.edu/BPS/readme.html. gde usesATCON, constraint language developed using LISP programming language, represent diagnostic problem cases. detailed account language given Forbusde Kleer (1993). Further, employs interactive user interface proposes measurement points respective costs lets user enter outcomes measurements.purpose comparison translated problem descriptions language accepted gde, also modified gde automatically read measurement outcomes349fiSiddiqi & Huangsize system1314151617gdesdagdesdagdesdagdesdagdesdasingle-faultcost time3.62.03.6 0.013.5 6.664.2 0.013.41113.9 0.013.33983.5 0.013.7 28763.8 0.01double-faultcost time3.81.813.40.013.315.12.90.013.5883.40.013.55563.30.014.641034.20.01triple-faultcost time4.01.92.8 0.013.0142.9 0.014.32993.7 0.013.25092.8 0.014.5 20674.2 0.01Table 1: Comparison gde.input problem description. also compiled LISP code machine dependentbinary code using native C compiler improve run-time performance.version gde, developed tutorial purposes, computes set minimal diagnoses instead probable diagnoses. makes comparison less informative. Nevertheless, able make reasonable comparison terms diagnostic cost setminimal diagnoses also serve large set probable diagnoses componentsequal prior probabilities. According de Kleer (1992) availability diagnosesaids heuristic accuracy, whereas focusing smaller set probable diagnosescomputationally efficient increase average diagnostic cost.version gde fact unable solve circuit ISCAS-85. enableuseful comparison, extracted set small subcircuits ISCAS-85 circuits:50 circuits size 13, 14, 15 16, 10 circuits size 17. circuit randomly generated 5 single-fault, 5 double-fault, 5 triple-fault scenarios, one testcase (input/output vector) fault scenario. comparison gde sda(baseline) benchmarks given Table 1 shows sda performs well gdeterms diagnostic cost.7.1.2 Larger Benchmarksevaluate performance sda larger ISCAS-85 circuits, conducted three sets experiments, time involving single, double, five faults, respectively. version gde available us unable handle circuits, orderprovide systematic reference point comparison implemented random strategy random order measurement points generated circuit usedtest cases. strategy also uses d-DNNF check whether stoppingcriteria met.Table 2 shows comparison random strategy sda using baselineapproach two different heuristics, one based entropies wires alone (ew)based also failure probabilities (fp). three systems ranset experiments without pruning d-DNNF (using known fault cardinalitydescribed Section 4.1.2), indicated third column table. testcases first four circuits could solved. circuits failure occurredcompilation phase, hence affected random strategy sda.350fiSequential Diagnosis Abstractioncircuit system pruningc432rand(160 gates)sda(ew)sda(fp)c499rand(202 gates)sda(ew)sda(fp)c880rand(383 gates)sda(ew)sda(fp)c1355rand(546 gates)sda(ew)sda(fp)yesyesyesyesyesyesyesyesyesyesyesyessingle-faultcost time92.3 20.74.5 11.442.0 16.63.7 11.16.7 11.74.3 11.0109.6 0.85.50.258.1 0.73.60.26.50.24.80.2221.0 1.95.40.226.8 0.34.00.210.8 0.25.60.2327.2 4.37.40.482.6 1.34.90.434.1 0.88.00.4double-faultcost time97.7 23.236.8 12.442.5 21.38.612.06.412.55.012.3120.6 1.220.10.254.00.53.70.24.30.23.00.2251.3 1.947.30.332.80.46.80.29.20.26.70.2365.7 5.759.01.091.21.55.50.414.80.59.40.6five-faultcost time117.8 26.599.7 17.268.4 25.533.8 12.89.4 13.09.1 12.6150.0 1.4104.9 0.795.8 0.835.7 0.37.2 0.27.1 0.2306.4 2.3205.7 1.379.0 0.730.5 0.415.8 0.314.0 0.3437.4 5.6328.6 3.5203.9 3.465.9 1.119.3 0.818.4 0.6Table 2: Effectiveness heuristic.clear diagnostic cost significantly lower heuristics sdarandom strategy whether pruning used. also interestingnote pruning significantly reduces diagnostic cost random sda-ewstrategies, much less effect sda-fp except cases (c1355 single-fault).Moreover, sda-fp generally dominates sda-ew, without pruning.may also observe (i) five-fault cases, sda-fp without pruning resultsmuch lower diagnostic cost sda-ew pruning; (ii) double-fault cases, twolargely comparable; (iii) single-faults cases, comparison reversed.indicates fault cardinality rises, combination failure probabilities wireentropies appears achieve effect similar pruning. sda-ew pruningperforms better sda-fp without pruning single-fault cases attributedfact cases pruning always exact hence likely result maximumbenefit.7.2 Effectiveness Abstractionreport, Table 3, results repeating experiments sda-fp usinghierarchical approach.notably, running time generally reduces cases ablehandle two circuits, namely c1908 c2670, solving 139 300 cases c1908 (25single-, 15 double-, 99 five-fault cases) 258 300 cases c2670 (100351fiSiddiqi & Huangcircuitpruningc432yesyesyesyesyesyes(64 cones)c499(90 cones)c880(177 cones)c1355(162 cones)c1908(374 cones)c2670(580 cones)single-faultcost time15.40.44.90.37.30.14.50.19.50.15.60.19.30.35.80.211.02223.021416.32136.5196double-faultcosttime15.80.510.40.45.80.13.90.110.20.17.60.18.20.26.30.217.15878.546319.217213.390five-faultcost time22.2 0.521.5 0.410.5 0.29.6 0.217.4 0.216.3 0.214.0 0.314.4 0.334.9 50532.4 38325.4 5824.3 45Table 3: Effectiveness abstraction.circuitc432c499c880c1355c1908c2670c3540c5315c6288c7552totalgates1602023835888011931669230724163512abstractionsize595877581601673533851456545cloningtime0.030.020.10.050.740.775.643.60.166.68totalclones2702402371104893580562abstraction sizecloning39585758701161652661456378Table 4: Results preprocessing step cloning.single-, 60 double-, 98 five-fault cases). failures occurredcompilation phase. Note observations cause sufficient simplificationtheory successfully compiled even abstraction. terms diagnosticcost, cases hierarchical approach comparable baseline approach.c432, baseline approach consistently performs better hierarchical faultcardinality, reverse true c1355. Note also pruning helps reducediagnostic cost various degrees baseline approach.discussed earlier, results confirm main advantage hierarchical approachlarger circuits solved. circuits also solved baselineapproach, hierarchical approach may help reduce diagnostic cost quickly findingfaulty portions circuit, represented set faulty cones, directingmeasurements inside them, result useful measurements (e.g. casec1355). hand, may suffer cases needlessly gohierarchies locate actual faults, baseline version find directlyefficiently (e.g. case c432). discussed Section 7.4.352fiSequential Diagnosis Abstractioncircuitc432c880single-faultcosttime7.210.311.20.2double-faultcosttime6.67.89.30.2five-faultcost time9.69.716.20.3Table 5: Effect component cloning diagnostic performance.circuitc432c880c1908c2670c3540c5315c7552single-faultcosttime15.20.18.80.113.62.813.54.527.83827.22.570.61056double-faultcosttime14.80.19.30.118.35.015.30.730.572.521.15.943.1129.0five-faultcosttime20.20.115.80.235.45.120.12.336.1108.624.46.6104.8 1108Table 6: Hierarchical sequential diagnosis component cloning (c499 c1355 omitted already easy diagnose cloning lead reducedabstraction).7.3 Effectiveness Component Cloningsubsection discuss experiments component cloning. show cloningsignificantly affect diagnostic cost allows us solve much larger circuits,particular, nearly circuits ISCAS-85 suite.Table 4 shows result pre-processing step cloning circuit.columns give name circuit, total number gates circuit, sizeabstraction circuit cloning, time spent cloning, total numberclones created circuit, abstraction size circuit obtained cloning.circuits except c499, c1355, c6288, significant reduction abstraction sizeachieved. c6288 appears extreme case large abstractionlacks hierarchy; gates abstractions c499 c1355 roots cones,affording opportunities reduction (note two circuits alreadysimple easy diagnose).start investigating effect component cloning diagnostic performance.isolate effect component cloning use baseline version sda (i.e., withoutabstraction), without pruning. Table 5 summarizes performance baseline sdacloning circuits c432 c880. Comparing results corresponding entries Table 2 shows overall diagnostic cost slightly affectedcloning. observed significant number cases proposed measurement sequence change cloning, cases changedinsubstantially. Moreover, number cases, although substantially differentsequence measurements proposed, actual diagnostic cost change much.Finally, note diagnosis time case c432 reduced cloning,ascribed general reduction complexity compilation due smallerabstraction.353fiSiddiqi & Huangcircuitc432c499c880c1355c1908c2670total max. cone abstraction measurementAC IC EDCcases inputssizepoints38393211.51 5.67 17.18001849425.22 6.05 11.21452454.87 6.11 10.9953464.64 6.14 10.84104972.11 6.72 8.801871800.00 7.50 7.5858263.77 5.32 9.01010574423.13 5.91 9.031701380.71 7.10 7.802021700.0 7.40 7.41657316.54 5.42 11.919151474485.75 6.02 11.710105794.22 6.72 10.961701442.70 7.48 10.104073810.0 8.57 8.5858263.59 6.34 9.92730598662.74 7.20 9.94114822.47 7.27 9.732662341.43 8.23 9.624263940.43 8.77 9.205465140.0 9.00 9.040704514.37 7.07 21.485929765112.85 7.15 20.028805512.70 7.23 19.927825712.62 7.27 19.8201381138.36 7.82 16.2181501257.79 7.92 15.755565217.84 6.40 24.298934585716.19 6.53 22.7331286415.63 6.68 22.32517811411.52 7.44 18.9casessolved800800800800800800101010101010101019151915191519151915273027302730273027302730859859859859859859989989989970single-faultcost time15.2 0.0611.0 0.111.0 0.110.7 0.18.80.37.37.37.30.17.70.19.40.16.40.18.70.18.50.18.00.18.60.110.8 0.29.30 0.112.55 0.212.39 0.222.5 0.333.5 0.434.0 0.418.7 2.617.8 5.818.3 5.918.2 5.917.7 15.017.7 47.519.2 0.719.1 0.818.6 0.816.1 79.0Table 7: Effectiveness diagnostic cost estimation.final set experimental results ISCAS-85 circuits, summarized Table 6,illustrates performance hierarchical sequential diagnosis component cloningscalable version sda. test cases circuits c1908 2670solved, largest circuits benchmark suite could handled: casesc5315, 164 300 cases c3540 (34 single-, 65 double-, 65 five-faultcases), 157 300 cases c7552 (60 single-, 26 double-, 71 fivefault cases) solved. terms diagnostic cost cloning generally resulted slightimprovement. terms time difference insignificant c432 c880,larger circuits (c1908 c2670) diagnosis cloning clearly ordermagnitude faster.7.4 Effectiveness Diagnostic Cost EstimationFinally, demonstrate effectiveness cost estimation function. showoften possible destroy different cones obtain different abstractions system354fiSequential Diagnosis Abstractionsuccessfully compiled, then, using cost estimation function, selectabstraction used diagnosis likely give optimal average cost.results also help explain cases hierarchical approach causes diagnostic costincrease compared baseline approach.experiments, use sda cloning include circuits c2670, considering single-fault test cases. include largest circuits analysiscircuits often could compiled cones destroyed; therefore possible obtain overall picture actual cost circuits. Testcases circuits c1355 used before, whereas circuits c1908c2670, time, use complete set cases done smaller circuits. Specifically, generate n fault scenarios circuit, n equals number gatescircuit: scenario contains different faulty gate. randomly generate1 test case n scenarios (in cases, could obtain test casereasonable time corresponding scenarios used).results experiments summarized Table 7. circuit first rowshows results cones considered subsequent rows show resultscones specified number inputs (in column 3)destroyed. value column 3 0 get trivial abstraction, conesdestroyed, equivalent using baseline approach. last twocolumns show (actual) average cost time diagnosing circuit using givenabstraction. columns labeled AC, IC, EDC show values obtained usingequations 6, 5, 7, respectively, given abstraction.results show often able destroy several cones still ablecompile circuit successfully. However, quite naturally, compilation time increasescones destroyed point circuits start fail compile,stop destroying cones. actual diagnostic cost different circuits show differenttrends time cones destroyed. example, c432 shows significantimprovement reverse true c1355. remaining circuits actual cost showssomewhat mixed trends; however, relative increase decrease costs generallyless significant.Comparison isolation abstraction costs (i.e., IC AC, respectively)various abstractions confirms time cones destroyed isolation costincreases abstraction cost decreases. potentially imbalanced changetwo costs determines whether cost might go conesdestroyed. example, case c432 abstraction cost drops rapidlyisolation cost increases cones destroyed, case c1355 twocosts change almost pace.Comparison predicted costs EDC actual costs shows c432,c499, c1908, c2670 predicted costs often quite close actual costs,demonstrates relative accuracy approach. result, circuitscost estimation function accurately predict abstraction likely giveoptimal cost. example, correctly suggests one use baseline approachc432. two circuits, c880 c1355, predicted actual costssignificantly different, cost estimation function fails give good predictions. c1355355fiSiddiqi & Huangseems special case actual diagnostic cost increases quite rapidlycones destroyed, reason interesting topic future work.8. Related Worket al. (1994) considered two kinds hierarchical models discussed automaticmethods constructing abstractions. first kind, components givendetailed model aggregated single components abstract model, everydiagnosis detailed model, refined diagnosis abstract model, guaranteedvalid. Thus need check validity detailed diagnoses afterwards.second kind, abstract model constructed always possibledetermine unique diagnosis every level hierarchy reasonable cost,measurements less costly make appear abstract modelcostly measurements appear detailed model. techniques automaticabstraction-based system observability discussed Torta Torasso (2003, 2008).papers provide alternative techniques automatic abstraction; however,address sequential diagnosis.idea testing likely failing component comes Heckerman et al. (1995),testing component considered unit operation componentstested decreasing order likelihood failure, computed assumingsingle fault (this assumption could compromise quality measurement sequencemultiple-fault cases authors pointed out). case, contrast, testingvariable component unit operation, calling complex heuristicorder minimize number tests; also, need assume single fault.work also goes scalability using several structure-based techniques: compilation,abstraction, component cloning.Chittaro & Ranon (2004) considered computation diagnoses using hierarchicalalgorithm. method takes hierarchical decomposition system input,sets components aggregated units, computes set diagnosesabstract level, refined hierarchically detailed level. Feldman &van Gemund (2006) developed hierarchical diagnosis algorithm tested reverseengineered ISCAS-85 circuits (Hansen, Yalcin, & Hayes, 1999) available highlevel form. idea decompose system hierarchies way minimizesharing variables them. done well engineered problemsformed hierarchies hand ISCAS-85 circuits. system representedhierarchical logical formula hierarchy represented traditional CNFformula. representation translated fully hierarchical DNF, fully flattenedDNF, partially flattened DNF dictated depth parameter, hierarchicalsearch algorithm employed find diagnoses. hierarchical aspect twoapproaches similar ours; however, require hierarchical decompositionsystem either given part input, obtained hand, approachsearches hierarchies automatically. Another major difference considercomputation diagnoses address problem sequential diagnosis.Based gde framework, de Kleer (2006) studied sensitivity diagnosticcost called -policy, policy quantifies posterior356fiSequential Diagnosis Abstractionprobabilities diagnoses estimated gde computes heuristic.case, probabilities diagnoses required all, probabilitiesrequired computed exactly evaluating differentiating d-DNNF.Nevertheless, algorithm sensitive initial probabilistic model givensensitivity analysis regard may lead interesting findings.Recently, Flesch, Lucas, & van der Weide (2007) proposed new framework integrateprobabilistic reasoning model-based diagnosis. framework based upon notionconflict measure, originated tool detection conflictsobservation given Bayesian network (Jensen, 2001). system modeledBayesian network diagnostic reasoning, possible use conflict measuredifferentiate diagnoses according degree consistency given setobservations. work, however, address problem sequential diagnosis,i.e., locating actual faults taking measurements.recently, Feldman, Provan, van Gemund (2009) proposed related methodreducing diagnostic uncertainty. work attempts identify actual faultsfewest individual measurements, heuristic aimed reducing numberdiagnoses fewest test vectors.9. Conclusionpresented new system sequential diagnosis, called sda, employs fournew structure-based techniques scale diagnosis larger systems. Specifically, usesheuristic measurement selection computed efficiently d-DNNFcompilation system. diagnose larger systems, automatically computes structural abstraction system performs diagnosis hierarchical fashion.employs structure-based technique reducing abstraction size system,scales diagnosis largest benchmark systems. Finally, automaticallyselect abstraction system likely give optimal average cost.Acknowledgmentsthank anonymous reviewers comments. NICTA funded AustralianGovernment represented Department Broadband, CommunicationsDigital Economy Australian Research Council ICT Centre Excellenceprogram. Part work appeared KR 2010 (Siddiqi & Huang, 2010); anotherpart work carried JulySeptember 2010 first authorvisiting NICTA.Appendix A. Computing Probabilities d-DNNFbriefly describe computation probabilities based d-DNNF compilationsBayesian networks. d-DNNF graph representation nested and/or expressionnegation appears next variables, children every and-node disjoint setsvariables (decomposability), children every or-node pairwise logically inconsistent357fiSiddiqi & Huang0.04750.047510.04750.95okA0.900.11110.95J00.050.05okAP0okJ0.50.10.05J J0.51J0.5okJ0.9Figure 6: d-DNNF compilation subcircuit (dotted) Figure 1 given observationP computation posterior probability J = 1.(determinism). example, Figure 6 shows d-DNNF compilation subcircuitdotted box Figure 1 observation P D.Given d-DNNF compilation, probability P r(E = e) instantiation e setvariables E obtained following linear-time procedure: (i) Set variables EBoolean constants according instantiation e, (ii) set literals (not E)true except numbers associated (negative literals associated1 minus corresponding numbers positive literals), (iii) evaluate dDNNF bottom-up treating true 1, false 0, remaining leaves associatednumbers, or-nodes additions, and-nodes multiplications. number rootP r(E = e). example, Figure 6 shows computation probability J = 1given observation P D. Thus e = {A = 1, P = 1, = 1, J = 1}. d-DNNF,set = 1, P = 1, = 1, J = 1, J = 0. rest literals given valuesassociated (discussed Section 3.2).Furthermore, second traversal d-DNNF, top down, effectivelydifferentiate d-DNNF updated probabilities computed everypossible change value variable (e.g., unknown known) (Darwiche, 2003).useful measurement point selection need update entropiescandidate measurement points.Appendix B. Cardinality-based Model Pruningpresent technique referred Section 4 used remove significantly large number (if all) diagnoses cardinality > k d-DNNF.value k must greater equal minimum-cardinality d-DNNFpruning occur. k equal minimum-cardinality d-DNNFdiagnoses cardinality > k removed using minimization procedure described358fiSequential Diagnosis AbstractionFigure 7: Pruning d-DNNF improve heuristic accuracy.Darwiche (2001). If, however, k greater minimum-cardinality d-DNNFneed similar modified minimization algorithm make sure removediagnoses cardinality k.complete pruning difficult achieve general, approximation possible.naive approach, one may remove every child l every or-node n minimumcardinality (mc) l greater k, sound never removediagnoses cardinality k may result little pruning many cases.increase amount pruning performed computing local value k(n) every node ngiven global k whole d-DNNF using top-down traversal d-DNNF:Every node n suggests value k(l) child l largest values acceptedfinal value k(l) (this essential avoid possibly removing diagnoses cardinalityk). pruning occur way k(n) often less globalk. k(n) computed every node, every child l every or-node nmc(l) > k(l) pruned.give pruning algorithm performs two pass traversald-DNNF. mc(n) updated upward traversal represents minimumcardinality diagnoses node n, whereas k(n) updated downwardtraversal represents upper bound fault-cardinality node usedprune branches emanating node whose mc(n) exceeds k(n).two passes procedure follows: Initialize mc(n) 0 k(n) -(least possible value) n. Traverse d-DNNF children visitedparents every leaf node, set mc(n) 1 n negated health variable 0otherwise; every or-node, set mc(n) minimum values mc children;every and-node set mc(n) sum values mc children. traversed-DNNF parents visited children set k(n) root nodevalue k; every or-node, remove every child p n mc(p) > k(n)every remaining child v set k(v) k(n) k(n) > k(v); every child p every and-node,let tp sum values mc children set k(p) value tptp > k(p).procedure conditions k(n) > k(v) tp > k(p) updating knode ensure safe value k set. example shown Figure 7.mc (left) k (right) values shown node. branches labeled , , ,359fiSiddiqi & HuangI1G1I2G2C1G3I3G5G4G6C2Figure 8: combinational circuit generated randomly set components consistinggates G1 , G2 , . . . , G6 cones C1 , C2 , processed order:G1 , C1 , G2 , G3 , G4 , C2 , G5 , G6 .N324048566472808896104112120128136144152totalgates104130156182208234260286312338364390416442468494averagedepth26.931.630.334.837.641.139.341.646.343.441.848.548.150.748.250.8approx.treewidth13161721242629323436394345485151abstractionsize263138455159667179829097104112116123totalclones3242696884108128158172177194218194243265272abstraction sizecloning17202428323841424849576165727078Table 8: Randomly generated combinational circuits (N, 25, 5).subgraphs associated hypothetical values mc. figure showsminimum-cardinality every node (mc) less equal bound (k) exceptbranch labeled , gets pruned accordingly.Appendix C. Randomly Generated Combinational Circuitssection use novel method systematically generate series combinationalcircuits structure size controlled. enables evaluationtechniques circuits ISCAS-85 benchmarks, helped us identifyfactors affect diagnostic cost, leading us cost estimation function givenSection 6. Specifically, observe circuits similar structure, diagnostic costgenerally increases circuit size, helped us devise notion isolation cost;360fiSequential Diagnosis Abstractioncircuit size held constant, diagnostic cost generally increases numbercones circuit, helped us devise notion abstraction cost.circuits generated composing set pre-formed building blocks. latterconsist gates cones. gates taken pool six gates types OR,NOR, AND, NAND, NOT, BUFFER, cones pool eight cones,10 gates extracted ISCAS-85 benchmark circuits.composition method inspired method generating random Bayesiannetworks described Marinescu, Kask, Dechter (2003). circuits generatedaccording formula (N, P, I), N number components (building blocks)use, P percentage cones components, maximum number inputsgate have. generate N components randomly pick (P/100) N cones (withrepetition) pool cones N (P/100) N gates (with repetition)pool gates place random order. number inputs gate setrandomly 2 I, except BUFFER gate oneinput.process component follows: Suppose components placedorder C1 , C2 , . . . , CN . Let Pi set components precede Ciorder. process component Ci connect every input Ci outputrandomly chosen component Pi two inputs Ci connectedcomponent. input Ci cannot connected (either Pi emptycomponents Pi used) treated primary input circuit.example, circuit Figure 8 randomly generated according formula(8, 25, 2), components shown boxes represent cones.varying parameters (N, P, I) obtain circuits varying size structure.First fix P = 25, = 5 vary N generate range circuits increasing size.N generate 10 circuits. circuits summarized Table 8. numberscolumns averaged circuits given size, rounded off. Generally,N increased see increase abstraction size well estimated treewidth,corresponding increase perceived difficulty circuit (e.g., notelargest circuit set smaller c1355, estimated treewidth c1355 muchlower, 25; actual compilation indeed harder former circuit).circuit randomly generate 10 single-fault, 10 double-fault, 10 five-fault scenariossingle test case scenario.results experiments circuits given Tables 9, 10, 11, usingbaseline, hierarchical, cloning techniques, respectively. results generallyconsistent obtained using ISCAS-85 circuits. baseline sda couldsolve circuit beyond (72, 25, 5). hierarchical sda solved circuits couldsolve circuit beyond (80, 25, 5). scalable version sda, componentcloning, solved much larger circuits, (168, 25, 5).Note general trend increase diagnostic cost increase N .consistent ones intuitive expectation diagnostic uncertainty would increasesystem size. Also note diagnostic cost often significantly higher hierarchicalapproach baseline approach. discussed earlier, attributedfact hierarchical approach often go hierarchies cones reachfaulty gate, baseline approach may able reach directly.361fiSiddiqi & Huangtotalsingle-faultdouble-faultfive-faultpruninggatessolved cost time solved cost time solved costtime32 104100 5.86 0.56100 6.34 0.571009.190.60yes100 4.81 0.54100 5.24 0.551008.220.5940 130100 5.82 4.31100 7.05 4.51100 11.53 5.09yes1004.54.16100 5.08 4.28100 10.35 4.9348 156100 6.58 32.43100 8.72 32.75100 11.19 34.87yes100 4.73 31.271005.9 31.141009.46 33.8456 182805.26 190.99806.9 192.698011.05 202.4yes803.58 185.32805.62 190.25808.325 197.0564 208505.58 532.82506.9 540.315013.94 581.11yes505.02 527.24504.72 525.02509.84 558.7972 234106.2 207.89109.5 230.721027.5 354.80yes106.2 207.49105.8 205.411011.4 248.20NTable 9: Baseline heuristic randomly generated circuits (N, 25, 5).totalsingle-faultdouble-faultfive-faultpruninggatessolved cost time solved cost time solved costtime32 104100 7.81 0.15100 8.78 0.16100 12.59 0.18yes100 3.42 0.15100 5.87 0.16100 11.88 0.1740 1301007.20.71100 8.19 0.72100 13.77 0.75yes100 3.07 0.70100 5.18 0.71100 12.94 0.7348 156100 7.03 4.10100 8.12 4.14100 12.78 4.26yes100 3.18 4.01100 4.96 4.02100 11.51 4.0856 182100 7.81 42.631009.1 43.58100 11.92 43.64yes100 2.98 41.60100 6.31 42.2310011.1 42.1964 208808.35 108.61809.11 107.968014.85 111.04yes803.31 107.05805.35 106.318013.56 107.7172 234307.56 120.59309.83 122.503012.66 123.81yes302.8 118.35305.53 118.573011.2 119.9380 260106.9 190.66109.2 193.581012.4 197.29yes102.8 188.95104.6 189.731010.5 190.07NTable 10: Hierarchical heuristic randomly generated circuits (N, 25, 5).also observe that, again, pruning leads general improvement diagnostic cost.improvement significant hierarchical approach, explainedfact effect pruning much greater abstract model, branchpruned correspond large part original system.perform another set experiments study impact hierarchycontrolled manner. time hold size circuits less constantvary percentage cones them. Specifically, generate large number randomcircuits P ranging 0 50, value P generated circuitscontain 120 gates average.experiments circuits summarized Table 12. Note P increasesestimated treewidth circuits decreases, would expected, actualcompilation time indeed also decreases. diagnostic cost, hand, increasessteadily P = 25 remains less flat afterwards. confirms potential362fiSequential Diagnosis AbstractionN324048566472808896104112120128136144152160168totalsingle-faultdouble-faultfive-faultgates solved costtime solved costtime solved costtime1041007.860.041008.780.05100 12.13 0.061301008.120.051009.60.06100 13.58 0.081561008.250.071009.340.0810012.60.101821009.030.1210010.40.13100 13.37 0.15208100 10.06 0.45100 10.73 0.46100 15.41 0.492341009.150.78100 11.38 0.80100 15.44 0.842601009.780.83100 11.38 0.8510015.50.892861009.560.78100 10.87 0.7910016.60.8431210010.41.85100 10.81 1.87100 17.87 1.97338100 10.03 4.23100 11.79 4.26100 16.95 4.34364100 10.44 29.20100 11.76 29.39100 17.62 29.93390100 10.36 39.8810013.6 40.15100 20.76 41.174169011.17 98.709013.73 99.089019.33 100.734429011.82 220.419013.76 221.638920.25 225.584688012.08 207.698015.05 207.688019.92 210.864944012.7 256.434014.72 257.54023.02 260.415204012.5 476.934014.15 479.334018.5 479.83546108.784.161010.1 84.441015.1 85.27Table 11: Component cloning randomly generated circuits (N, 25, 5).P051015202550totalsingle-faulttreewidthcircuitscost time1000325.78.8600236.70.9900217.50.51000187.70.11100178.00.11300159.20.1800128.60.06double-faultcosttime7.78.88.00.98.70.59.10.19.40.110.30.110.00.07five-faultcost time13.5 9.013.0 0.913.2 0.512.2 0.112.3 0.113.6 0.112.4 0.1Table 12: Component cloning randomly generated circuits (N ,P ,5).negative impact hierarchy diagnostic cost hypothesized: P increaseslikelihood fault occurring inside cone also increases thus average onetake measurements, many inputs cones, locate fault. diagnostic costincrease P = 25 consistent observation sincecircuit size fixed roughly 120 cone contributes 10 gates circuit,P increases point, gates lying outside cones hencelikelihood fault occurring cone less plateaued.ReferencesBrglez, F., & Fujiwara, H. (1985). neutral netlist 10 combinational benchmark circuits target translator Fortran. Proceedings IEEE InternationalSymposium Circuits Systems (ISCAS), pp. 695698.Chittaro, L., & Ranon, R. (2004). Hierarchical model-based diagnosis based structuralabstraction. Artificial Intelligence, 155 (1-2), 147182.363fiSiddiqi & HuangChoi, A., Chavira, M., & Darwiche, A. (2007). Node splitting: scheme generating upper bounds Bayesian networks. Proceedings 23rd ConferenceUncertainty Artificial Intelligence (UAI), pp. 5766.Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal ArtificialIntelligence Research, 17, 229264.Darwiche, A. (2001). Decomposable negation normal form. Journal ACM, 48 (4),608647.Darwiche, A. (2003). differential approach inference Bayesian networks. JournalACM, 50 (3), 280305.Darwiche, A. (2004). New advances compiling CNF decomposable negation normal form. Proceedings 16th European Conference Artificial Intelligence(ECAI), pp. 328332.Darwiche, A. (2005). c2d compiler user manual. Tech. rep. D-147, Computer ScienceDepartment, UCLA. http://reasoning.cs.ucla.edu/c2d/.de Kleer, J., & Williams, B. C. (1987). Diagnosing multiple faults. Artificial Intelligence,32 (1), 97130.de Kleer, J. (1992). Focusing probable diagnosis. Readings model-based diagnosis,pp. 131137. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.de Kleer, J. (2006). Improving probability estimates lower diagnostic costs. 17thInternational Workshop Principles Diagnosis (DX).de Kleer, J., Raiman, O., & Shirley, M. (1992). One step lookahead pretty good.Readings model-based diagnosis, pp. 138142. Morgan Kaufmann Publishers Inc.,San Francisco, CA, USA.Feldman, A., & van Gemund, A. (2006). two-step hierarchical algorithm modelbased diagnosis. Proceedings 21st AAAI Conference Artificial Intelligence(AAAI), pp. 827833.Feldman, A., Provan, G. M., & van Gemund, A. J. C. (2009). FRACTAL: Efficient faultisolation using active testing. Proceedings 21st International Joint ConferenceArtificial Intelligence (IJCAI), pp. 778784.Flesch, I., Lucas, P., & van der Weide, T. (2007). Conflict-based diagnosis: Adding uncertainty model-based diagnosis. Proceedings 20th International JointConference Artificial Intelligence (IJCAI), pp. 380385.Forbus, K. D., & de Kleer, J. (1993). Building problem solvers. MIT Press, Cambridge,MA, USA.Hansen, M. C., Yalcin, H., & Hayes, J. P. (1999). Unveiling ISCAS-85 benchmarks:case study reverse engineering. IEEE Design Test Computers, 16 (3), 7280.364fiSequential Diagnosis AbstractionHeckerman, D., Breese, J. S., & Rommelse, K. (1995). Decision-theoretic troubleshooting.Communications ACM, 38 (3), 4957.Jensen, F. V. (2001). Bayesian networks decision graphs. Springer-Verlag New York,Inc., Secaucus, NJ, USA.Kirkland, T., & Mercer, M. R. (1987). topological search algorithm ATPG.Proceedings 24th Conference Design Automation (DAC), pp. 502508.Marinescu, R., Kask, K., & Dechter, R. (2003). Systematic vs. non-systematic algorithmssolving MPE task. Proceedings 19th Conference UncertaintyArtificial Intelligence (UAI), pp. 394402.Out, D.-J., van Rikxoort, R., & Bakker, R. (1994). construction hierarchic models.Annals Mathematics Artificial Intelligence, 11 (1-4), 283296.Pearl, J. (1988). Probabilistic reasoning intelligent systems: Networks plausible inference. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.Pipatsrisawat, K., & Darwiche, A. (2007). Clone: Solving weighted Max-SAT reducedsearch space. Proceedings 20th Australian Joint Conference ArtificialIntelligence (AI), pp. 223233.Siddiqi, S., & Huang, J. (2007). Hierarchical diagnosis multiple faults. Proceedings20th International Joint Conference Artificial Intelligence (IJCAI), pp. 581586.Siddiqi, S., & Huang, J. (2010). New advances sequential diagnosis. ProceedingsTwelfth International Conference Principles Knowledge RepresentationReasoning (KR), pp. 1725.Torta, G., & Torasso, P. (2003). Automatic abstraction component-based diagnosis drivensystem observability. Proceedings 18th International Joint ConferenceArtificial Intelligence (IJCAI), pp. 394402.Torta, G., & Torasso, P. (2008). symbolic approach component abstraction modelbased diagnosis. 19th International Workshop Principles Diagnosis (DX).365fiJournal Artificial Intelligence Research 41 (2011) 231-266Submitted 11/2010; published 06/2011Probabilistic Relational PlanningFirst Order Decision DiagramsSaket Joshijoshi@eecs.oregonstate.eduSchool Electrical Engineering Computer ScienceOregon State UniversityCorvallis, 97331, USARoni Khardonroni@cs.tufts.eduDepartment Computer ScienceTufts UniversityMedford, MA, 02155, USAAbstractDynamic programming algorithms successfully applied propositional stochastic planning problems using compact representations, particular algebraic decisiondiagrams, capture domain dynamics value functions. Work symbolic dynamicprogramming lifted ideas first order logic using several representation schemes.Recent work introduced first order variant decision diagrams (FODD) developedvalue iteration algorithm representation. paper develops several improvementsFODD algorithm make approach practical. include, new reductionoperators decrease size representation, several speedup techniques,techniques value approximation. Incorporating these, paper presents planningsystem, FODD-Planner, solving relational stochastic planning problems. systemevaluated several domains, including problems recent international planningcompetition, shows competitive performance top ranking systems.first demonstration feasibility approach shows abstractioncompact representation promising approach stochastic planning.1. IntroductionPlanning uncertainty one core problems Artificial Intelligence.years research automated planning produced number planning formalismssystems. STRIPS planning system (Fikes & Nilsson, 1971) led generation automated planning research. produced number successful systems deterministicplanning using various paradigms like partial order planning (Penberthy & Weld, 1992),planning based planning graphs (Blum & Furst, 1997), planning satisfiability (Kautz& Selman, 1996) heuristic search (Bonet & Geffner, 2001). ideas later employed solving problem planning uncertainty (Blum & Langford, 1998; Weld,Anderson, & Smith, 1998; Majercik & Littman, 2003; Yoon, Fern, & Givan, 2007; TeichteilKoenigsbuch, Infantes, & Kuter, 2008). these, approaches using forward heuristic searchrelated planning graph (Blum & Furst, 1997) successful recentinternational planning competitions (Yoon et al., 2007; Teichteil-Koenigsbuch et al., 2008).Another approach probabilistic planning based Markov decision processes (MDPs).fact solutions MDPs generate policies rather action sequences particuc2011AI Access Foundation. rights reserved.fiJoshi & Khardonlarly attractive probabilistic planning, approach came known DecisionTheoretic Planning (Boutilier, Dean, & Hanks, 1999a). Classical solution techniquesMDPs, like value iteration (VI) (Bellman, 1957) policy iteration (PI) (Howard, 1960),based dynamic programming. early solutions, however, require enumerationstate space. Owing curse dimensionality (Bellman, 1957), even reasonablysmall problems, state space large. seen easily propositionally factored domains state defined N binary variables numberpossible states 2N .Several approaches developed handle propositionally factored domains(Boutilier, Dearden, & Goldszmidt, 1999b; Kearns & Koller, 1999; Guestrin, Koller, Parr, &Venkataraman, 2003b; Hoey, St-Aubin, Hu, & Boutilier, 1999). One successful,SPUDD (Hoey et al., 1999), demonstrated MDP represented using algebraic decision diagrams (ADDs) (Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi,1993), VI performed entirely using ADD representation thereby avoidingneed enumerate state space. Propositionally factored representations showimpressive speedup taking advantage propositional domain structure. However,benefit structure exists objects relations. Boutilier,Reiter, Price (2001) developed foundations provably optimal solutions relational problems provided Symbolic Dynamic Programming (SDP) algorithmcontext situation calculus. algorithm provided framework dynamic programming solutions Relational MDPs later employed several formalismssystems (Kersting, van Otterlo, & De Raedt, 2004; Holldobler, Karabaev, & Skvortsova,2006; Sanner & Boutilier, 2009; Wang, Joshi, & Khardon, 2008).advantage relational representation abstraction. One plan abstract level without grounding domain, potentially leading efficient algorithms.addition, solution abstract level optimal every instantiation domainreused multiple problems. However, approach raises difficult computational issues one must use theorem proving reason abstract level,problems optimal solutions abstract level infinite size. Following Boutilier et al. (2001) several abstract versions value iteration (VI) algorithmdeveloped using different representation schemes. example, approximatesolutions based linear function approximations developed successfully applied several problems international planning competitions (Sanner & Boutilier,2009).alternative representation motivated success algebraic decision diagramssolving propositional MDPs (Hoey et al., 1999; St-Aubin, Hoey, & Boutilier, 2000).Following work, relational variants decision diagrams defined usedVI algorithms (Wang et al., 2008; Sanner & Boutilier, 2009). Sanner Boutilier reportimplementation scale well yield exact solutions large problems.previous work (Wang et al., 2008) introduced First Order Decision Diagrams (FODD),developed algorithms reduction operators them. However, FODD representationrequires non-trivial operations reductions (to maintain small diagrams efficiency)leading difficulties implementation scaling.paper develops several algorithmic improvements extensions FODDbased solution make approach practical.232fiProbabilistic Planning FODDFirst, introduce new reduction operators, named R10 R11, decreasesize FODD representation. R10 makes global analysis FODD removesmany redundant portions diagram simultaneously. R11 works locally targetsparticular redundancy arises quite often two FODDs composedbinary operation; procedure used repeatedly VI algorithm. provesoundness reductions showing applied diagrams maintaincorrect value.Second, present novel FODD operation, sub-apart(A, B) identifies minimalconditions (in terms variables) one FODD dominates value anotherFODD B. new operation simultaneously expands applicability R7 reduction(Wang et al., 2008) cover situations simplifies test applicability,must implemented system. prove soundness operation showingapplied R7 diagrams maintain correct value.Third, present several techniques speed FODD-based planning algorithm.include sound simplification one steps algorithm additionseveral approximation techniques trade-off accuracy improvements run time.Fourth, extend system allow handle action costs universal goals.Incorporating ideas paper presents FODD-Planner, planning systemsolving relational stochastic planning problems using FODDs.Fifth, perform experimental evaluation FODD-Planner system severaldomains, including problems recent international planning competition (IPC).experiments demonstrate new reductions provide significant speedupalgorithm crucial practicality. importantly show FODDPlanner exhibits competitive performance top ranking systems IPC.knowledge first application pure relational VI algorithm without linearfunction approximation problems scale. results demonstrate abstractioncompact representation promising approach stochastic planning.rest paper organized follows. Section 2 gives short introductionrelational MDPs FODDs. Section 3 presents techniques speed FODDPlanner. section 4 introduce new operators removing redundancies FODDs.Section 5 describes FODD-Planner system Section 6 present resultsexperiments planning domains IPC. Section 7 provides additional discussionrelated work Section 8 concludes summary ideas future work.2. Preliminariessection gives overview Relational MDPs, First Order Decision DiagramsSymbolic Dynamic Programming algorithm.2.1 Relational Markov Decision ProcessesMarkov decision process (MDP) mathematical model interactionagent environment (Puterman, 1994). Formally MDP 5-tuple < S, A, T, R, >definingset fully observable states S.233fiJoshi & Khardonset actions available agent.state transition function defining probability P (s |s, a) getting statestate taking action a.reward function R(s, a) defining immediate reward achieved agentstate taking action a. simplify notation assume rewardindependent R(s, a) = R(s). However general case handledway.discount factor 0 1 captures relative value immediate actionsfuture actions.objective solving MDP generate policy maximizes agents total,expected, discounted, reward. Intuitively, expected utility value state equalreward obtained state plus discounted value state reachedbest action state. captured Bellman equation V (s) = axa [R(s)+ P (s |s, a)V (s )]. discount factor < 1 guarantees V (s) finite evenconsidering infinite number steps. episodic tasks planning providesincentive find short solutions. VI algorithm treats Bellman equationupdate rule V (s) axa [R(s) + P (s |s, a)V (s )], iteratively updates valueevery state convergence. optimal value function known, policygenerated assigning state action maximizes expected value.Relational MDP (RMDP) MDP world represented objectsrelations among them. RMDP specified1. set world predicates. literal, formed instantiating predicate usingobjects domain, either true false given state. example boxworld domain, world literals form box-in-city(box, city),box-on-truck(box, truck), truck-in-city(truck, city).2. set action predicates. action literal formed instantiating action predicate using objects domain defines concrete action. boxworld domain, actions form load-box-on-to-truck-in-city(box, truck, city), unload-box-from-truck-in-city(box, truck, city), drive-truck(truck, source.city, dest.city).3. state transition function provides abstract description probabilisticmove one state another. example, using STRIPS-like notation,transition defined action load-box-on-to-truck-in-city describedAction: load-box-on-to-truck-in-city(box, truck, city):Preconditions: box-in-city(box, city), truck-in-city(truck, city)Outcome 1: Probability 0.8 box-on-truck(box, truck), box-in-city(box, city)Outcome 2: Probability 0.2 nothing changes.preconditions action, box-in-city(box, city) truck-in-city(truck, city)satisfied, probability 0.8, action succeed generating effectbox-on-truck(box, truck) box-in-city(box, city). predicate instantiations remain unchanged. state remains unchanged probability 0.2.234fiProbabilistic Planning FODD4. abstract reward function describing conditions rewards obtained.example boxworld domain, reward function described boxcity,destination(box, city) box-in-city(box, city) constructed capture goaltransporting boxes source cities respective destination cities.Boutilier et al. (2001) developed SDP, first VI algorithm RMDPs.important theoretical result RMDPs finite horizon, SDP guaranteedproduce optimal value function independent domain size. Thus valuefunction applicable logistics problem 2 cities, 2 trucks 2 boxes, logisticsproblem 100 cities, 1000 trucks 2000 boxes, instance domain.One important ideas SDP represent stochastic actions deterministicalternatives natures control. helps separate regression deterministic actionalternatives probabilities action effects. separation necessarytransition functions represented relational schemas abstracting structurestates. basic outline relational value iteration algorithm follows:1. Regression: n step-to-go value function Vn regressed every deterministicvariant Aj (~x) every action A(~x) produce Regr(Vn , Aj (~x)). first iteration V0 assigned reward function. necessary correctnessalgorithm convenient starting point VI. Regr(Vn , Aj (~x)) describesconditions action alternative Aj (~x) causes state transitionabstract state description V n+1 .2. Add Action Variants: Q-functionA(~x)QVn= R [ j (prob(Aj (~x)) Regr(Vn , Aj (~x)))]action A(~x) generated. step different alternatives actioncombined. alternative Aj (~x) produces Regr(Vn , Aj (~x)) regressionstep. Regr(Vn , Aj (~x))s added weighted probabilityA(~x)Aj (~x). produces parametrized function QVn describes utilitystate taking concrete action A(~x).A(~x)3. Object Maximization: Maximize action parameters QVn producex), thus obtaining value achievable best groundQAVn action A(~instantiation A(~x).4. Maximize Actions: n + 1 step-to-go value function Vn+1 = maxA QAVn ,generated.description algorithm intermediate constructs (R, P , V etc.)represented compact form capture mapping states valuesprobabilities. operations Bellman update performed functionsmaintaining compact form. variant SDP developed previous work(Wang et al., 2008) employed First Order Decision Diagrams represent intermediateconstructs.235fiJoshi & Khardonp(x)q(y)q(y)1100(a)(b)Figure 1: Two example FODDs. diagrams paper, left going edgesrepresent branch taken predicate true right going edgesrepresent false branches.2.2 First Order Decision Diagramssection briefly reviews previous work FODDs use relational MDPs(Wang et al., 2008). use standard terminology First-Order logic (Lloyd, 1987).First Order Decision Diagram labeled directed acyclic graph, non-leafnode exactly 2 outgoing edges true false labels. non-leaf nodeslabeled atoms generated predetermined signature predicates, constantsenumerable set variables. Leaf nodes non-negative numeric values. signaturealso defines total order atoms, FODD ordered every parent smallerchild according order. Two examples FODDs given Figure 1;diagrams paper left going edges represent true branches rightedges false branches.Thus, FODD similar formula first order logic shares syntacticelements. meaning similarly defined relative interpretations symbols.interpretation defines domain objects, identifies constant object,specifies truth value predicate objects. context relationalMDPs, interpretation represents state world objects relationsamong them. Given FODD interpretation, valuation assigns variableFODD object interpretation. Following Groote Tveretina (2003),semantics FODDs defined follows. B FODD interpretation,valuation assigns domain element variable B fixes truthvalue every node atom B I. FODD B traversed orderreach leaf. value leaf denoted apB (I, ). apB (I) definedmax apB (I, ), i.e. aggregation apB (I, ) valuations . example,consider FODD Figure 1(a) interpretation objects a, btrue atoms p(a), q(b). valuations {x/a, y/a}, {x/a, y/b}, {x/b, y/a},{x/b, y/b}, produce values 0, 1, 0, 0 respectively. max aggregation semantics,apB (I) = max{0, 1, 0, 0} = 1. Thus, FODD equivalent formula x, y, p(x)q(y).236fiProbabilistic Planning FODDgeneral, max aggregation yields existential quantification leaves binary.using numerical values similarly capture value functions relational MDPs.Thus, every FODD binary leaves equivalent formula First-Order logic,variables existentially quantified. Conversely, every function free formula FirstOrder logic, variables existentially quantified, equivalent FODD representation.1 FODDs cannot capture universal quantification. Recently introducedgeneralized FODD based formalism capture arbitrary quantifiers (Joshi, Kersting,& Khardon, 2009); however expensive use computationally usedpaper.Akin ADDs, FODDs combined arithmetic operations, reducedorder remove redundancies. Intuitively, redundancies FODDs arise two differentways. first, observes edges never traversed valuation. Reduction operators redundancies called strong reduction operators. secondrequires subtle analysis: may parts FODD traversedvaluations max aggregation, valuations traverseparts never instrumental determining map. Operators redundanciescalled weak reductions operators. Strong reductions preserve apB (I, ) every valuation(thereby preserving apB (I)) weak reductions preserve apB (I) necessarilyapB (I, ) every . Groote Tveretina (2003) introduced four strong reduction operators (R1 R4). Wang et al. (2008) added strong reduction operator R5. alsointroduced notion weak reductions developed weak reduction operators (R6R9). Another subtlety arises RMDP domains may backgroundknowledge predicates domain. example, blocksworld, blockclear on(x, a) false values x. denote background knowledgeB allow reductions rely knowledge. Below, discuss operator R7detail relevance next section.use following notation. e edge node n node m, source(e)= n, target(e) = sibling(e) edge n. node n, symbolsnt nf denote true false edges n respectively. l(n) denotesatom associated node n. Node formulas (NF) edge formulas (EF) definedrecursively follows. node n labeled l(n) incoming edges e1 , . . . , ek , nodeformula NF(n) = (i EF(ei )). edge formula true outgoing edge nEF(nt ) = NF(n) l(n). edge formula false outgoing edge n EF(nf ) =NF(n) l(n). formulas, variables existentially quantified, captureconditions node edge reached. Similarly, B FODDp path root leaf B, path formula p, denoted PF(p)conjunction literals along p. variables p, denoted x~p . x~pexistentially quantified, satisfiability PF(p) interpretation necessarysufficient condition path p traversed valuation I.valuation, define P athB (I, ) = p. leaf reached path p denotedleaf (p). let PF(p)\Lit denote path formula path p literal Lit removed(if present) conjunction. B denotes background knowledge domain.1. seen translating formula f disjunctive normal form f = fi , representingevery conjunct fi FODD, calculating disjunction using apply procedure Wang et al.(2008).237fiJoshi & KhardonFigure 2: example R7 reduction.process algorithm, also reductions, need perform operations functions represented FODDs. Let B1 B2 two FODDs representingfunction states real values (B1 : , B2 : ). Let B functionS, B(S) = B1 (S) + B2 (S). Wang et al. (2008) provide algorithm calculatingFODD representation B. denote operation B = B1 B2 similarly use, etc. denote operations diagrams.R7 Reduction: Weak reductions arise two forms - edge redundancies node redundancies. Corresponding these, R7 reduction operator (Wang et al., 2008) twovariants - R7-replace (for removing redundant edges) R7-drop (for removing redundantnodes). edge redundant valuations going dominatedvaluations. Intuitively, given FODD B edges e1 e2 B, every valuationgoing edge e2 , always another valuation going e1 gives bettervalue, replace target(e2 ) 0 without affecting apB (I) interpretation I.Figure 2 shows example reduction. FODD left, consider valuationreaching 1 leaf traversing path p(x)p(y) interpretation I.generate another valuation (by substituting value value x) reaches1 leaf path p(x). Therefore, intuitively path p(x) p(y) redundantremoved diagram. R7-replace reduction formalizes notionnumber conditions certain combinations conditionssatisfied, edge reduction becomes applicable. example, following conditionsoccur together FODD, reduced replacing target edge e2 0 leaf.(P7.2) : B |= ~u, [[w,~ EF(e2 )] [~v , EF(e1 )]] ~u variables appeartarget(e1 ) target(e2 ), ~v variables appear EF(e1 ) ~u,w~ variables appear EF(e2 ) ~u.condition requires every valuation 1 reaches e2 valuation2 reaches e1 1 2 agree variables appear target(e1 )target(e2 ).(V7.3) : leaves = target(e1 ) target(e2 ) non-negative values, denoted0. case fixed valuation potentially reaching e1 e2 betterfollow e1 instead e2 .(S1) : path root leaf contains e1 e2 .238fiProbabilistic Planning FODDoperator R7-replace(e1 , e2 ) replaces target(e2 ) leaf valued 0. NoticeFODD Figure 2 satisfies conditions P7.2, V7.3, S1. (P7.2) sharedvariable z holds z, [[xy, p(x) p(y)] [x, p(x)]]. (V7.3) holdstarget(e1 ) = target(e2 ) 0. definitions Wang et al. (2008) showsafe perform R7-replace conditions P7.2, V7.3, S1 hold:Lemma 1 ((Wang et al., 2008)) Let B FODD, e1 e2 edges conditionsP7.2, V7.3, S1 hold, B result R7-replace(e1 , e2 ), interpretationMAPB (I) = MAPB (I).Similarly R7-drop formalizes conditions nodes dropped diagram. Several alternative conditions applicability R7 (R7-replace R7-drop)given Wang et al. (2008). provided set alternative conditions applicability R7 none dominates others, result effectively onecheck conditions reducing diagram. next section shows processapplying R7 simplified generalized.R7 captures fundamental intuition behind weak reductions hence widelyapplicable. Unfortunately also expensive run. practice R7-replace conditionstested pairs edges diagram. test requires theorem provingdisjunctive First-Order formulas.2.3 VI FODDsprevious work (Wang et al., 2008) showed capture reward functiondynamics domain using FODDs presented value iteration algorithm alonglines described last section. Reward value functions captured directlyusing FODDs. Domains dynamics captured FODDs describing probabilitiesaction variants prob(Aj (~a)), special FODDs, Truth Value Diagrams (TVD),capture deterministic effects action variant, similar successor state axiomsused Boutilier et al. (2001). every action variant Aj (~a) predicate schemap(~x) TVD (A(~a), p(~x)) FODD {0, 1} leaves. TVD gives truth valuep(~x) next state A(~a) performed current state. TVDstherefore capture action preconditions within FODD structure p(~x) potentialeffect formalism specifies truth value directly instead saying whetherchanges not. operations needed SDP algorithm (regression, plus,times, max) performed special algorithms combining FODDs. detailsrepresentations algorithms previously described (Wang et al., 2008)directly needed discussion paper thus omitted here.hand, direct application operations yield large FODDsredundant structure therefore, keep diagram size manageable, FODDsreduced every step algorithm. Efficient successful reductionskey procedure. reductions R1-R9 (Groote & Tveretina, 2003; Wang et al.,2008) provide first step towards efficient FODD system. However, coverpossible redundancies expensive apply practice. Therefore directimplementation sufficient yield effective stochastic planner.239fiJoshi & Khardonp(x)e1q(x)p(y)e210q(x)r(z)3q(x)01r(z)20Figure 3: FODD example showing applicability Sub-Apart.following sections present new reduction operations speedup techniques make VIFODDs practical.3. Speedup Techniquessection presents two techniques speed VI algorithm Wang et al. (2008)maintaining exact solution.3.1 Subtracting Apart - Improving Applicability R7applicability R7 increased certain branches variables standardizedapart way preserves evaluation FODD max aggregationsemantics. Consider FODD B Figure 3. Intuitively weak reduction applicablediagram following argument. Consider valuation = {x \ 1, \ 2,z \ 3} crossing edge e2 interpretation I. |= B p(1) p(2). Thereforemust valuation = {x \ 2, z \ 3} (and value y), crosses edge e1 .depending truth value |= B q(1) |= B q(2), fourpossibilities would reach crossing nodes target(e2 ) target(e1 )respectively. However, cases, apB (I, ) apB (I, ). Thereforeable replace target(e2 ) 0 leaf. similar argument shows alsoable drop node source(e2 ). Surprisingly, though, none R7 conditions applycase diagram cannot reduced. closer inspection findreason conditions (P7.2) (V7.3) restrictive. (V7.3)holds (P7.2) requires x, z,[[y, p(x) p(y)] [p(x)]] implying everyvaluation crossing edge e2 , another valuation crossing edge e1valuations agree value x z hold. However,argument above, dominate , two valuations need agree value x.observe rename variable x instances different sub-FODDs240fiProbabilistic Planning FODDrooted target(e1 ) target(e2 ) (i.e. standardized apart w.r.t. x) (P7.2)(V7.3) go diagram reduced. Notice typesimplification go must case B1 B2 0 already holds.variables standardize apart harder keep condition. developidea, introduce new FODD subtraction algorithm Sub-apart: Given diagrams B1B2 algorithm tries standardize apart many common variables possible,keeping condition B1 B2 0 true. algorithm returns 2-tuple {T, V },Boolean variable indicating whether combination produce diagramnegative leaves variables except ones V standardized apart.algorithm uses standard recursive template combining ADDs FODDs(Bahar et al., 1993; Wang et al., 2008) root node chosen root twodiagrams operation recursively performed corresponding sub-diagrams.addition roots two diagrams identical Sub-apart considers possibilitymaking different standardizing apart. Sub-apart uses recursive callscollect constraints specifying variables cannot standardized apart; setscombined returned calling procedure.Procedure 1 Sub-apart(A, B)1. B leaves,(a) B 0 return {true, {}} else return {f alse, {}}2. l(A) < l(B), let(a) {L, V1 } = Sub-apart(target(At ), B)(b) {R, V2 } = Sub-apart(target(Af ), B)Return {L R, V1 V2 }3. l(A) > l(B), let(a) {L, V1 } = Sub-apart(A, target(Bt ))(b) {R, V2 } = Sub-apart(A, target(Bf ))Return {L R, V1 V2 }4. l(A) = l(B), let V variables (or B). Let(a) {LL, V3 } = Sub-apart(target(At ), target(Bt ))(b) {RR, V4 } = Sub-apart(target(Af ), target(Bf ))(c) {LR, V5 } = Sub-apart(target(At ), target(Bf ))(d) {RL, V6 } = Sub-apart(target(Af ), target(Bt )(e) RR = f alse, return {f alse, V3 V4 }(f ) LR RL = f alse return {true, V V3 V4 }(g) Return {true, V3 V4 V5 V6 }241fiJoshi & Khardonnext theorem shows procedure correct. variables common B1B2 denoted ~u B w~ denotes combination diagram B1 B2subtract operation variables except ones w~ standardized apart. Let n1n2 roots nodes B1 B2 respectively.Theorem 1 Sub-apart(n1 , n2 ) = {true, ~v } implies B~v contains negative leavesSub-apart(n1 , n2 ) = {f alse, ~v } implies w~ w~ ~u B w~ contains negativeleaves.Proof: proof induction k, sum number nodes B1 B2 .base case k = 2, B1 B2 single leaf diagrams statementtrivially true. Assume statement true k consider casek = + 1. l(n1 ) < l(n2 ), resultant diagram combination subtraction,expect n1 root node n1t n2 n1f n2 left rightsub-FODDs respectively. Hence, Sub-apart algorithm recursively calls Sub-apart(n1t ,n2 ) Sub-apart(n1f , n2 ). Since sum number nodes diagramsrecursive calls always m, statement true recursive calls. Clearly,top level return true iff calls return true. addition, keep variablesV1 V2 (of step 2) original form (that is, standardized apart)branches new root n1 guaranteed positive leaves thereforetrue diagram rooted n1 . similar argument shows statement truel(n1 ) > l(n2 ).l(n1 ) = l(n2 ), inductive hypothesis, statement theoremtrue recursive calls. 2 choices. could either standardize apartvariables V l(n1 ) l(n2 ) keep identical. same, resultantdiagram combination subtraction expect n1 root node n1t n2tn1f n2f left right sub-FODDs respectively. top levelreturn true iff calls return true. set shared variables requires variablesl(n1 ) addition recursive calls order ensure l(n1 ) = l(n2 ).standardize apart l(n1 ) l(n2 ), fall back one cases n16= n2 except algorithm checks second level recursive calls n1t n2t ,n1t n2f , n1f n2t n1f n2f . top level algorithm return truefour calls return true return union sets variables returned fourcalls. four calls return true, algorithm still keep variables l(n1 )l(n2 ) identical return true conditions case met.theorem shows algorithm correct guarantee minimality.fact, smallest set variables w~ B w~ negative leaves may unique(Wang et al., 2008). One also show output Sub-apart may minimal.principle, one use greedy procedure standardizes apart one variable timearrives minimal set w.~ However, although Sub-apart produce minimalset, prefer greedy approach fast often generates small set w~practice. define new conditions applicability R7:(V7.3S) : Sub-apart(target(e1 ), target(e2 )) = {true, V1 }.(P7.2S) : B |= V1 , [[w,~ EF(e2 )] [~v , EF(e1 )]] ~v , w~ remaining variables (i.e. V1 ) EF(e1 ), EF(e2 ) respectively.242fiProbabilistic Planning FODD(P7.2S) guarantees whenever 2 running target(e2 ), always1 running target(e1 ) 1 2 agree V1 . (V7.3S) guaranteescondition, 1 provides better value 2 . Using exactly proof Lemma 1given Wang et al. (2008), show following:Lemma 2 Let B FODD, e1 e2 edges conditions P7.2S, V7.3S,S1 hold, B result R7-replace(e1 , e2 ), interpretationMAPB (I) = MAPB (I).Importantly, conditions (P7.2S) , (V7.3S) subsume previous conditions applicability safety R7-replace previously given (Wang et al., 2008). Therefore, instead testing multiple conditions sufficient test (P7.2S)(V7.3S) . similar argument one shows Sub-apart extends simplifies conditions R7-drop. Thus use Sub-apart simplifies conditionstested provides opportunities reductions. implementation,use new conditions Sub-apart whenever testing applicability R7-replaceR7-drop.3.2 Standardizing ApartRecall FODD-based VI algorithm must add functions represented FODDs (inSteps 2 4) take maximum functions represented FODDs (in Step4). Since individual functions independent functions state, variablesdifferent functions related one another. Therefore, adding maximizing,algorithm Wang et al. (2008) standardizes apart diagrams. is, variablesdiagrams given new names constrain other. hand,since different diagrams structurally related often introduces redundancies (inform renamed copies atoms) must removed reduction operators.However, reduction operators ideal avoiding step lead significantspeedup system. observe maximization (in Step 4) standardizingapart needed therefore avoided.Theorem 2 Let B1 B2 FODDs. Let B result combining B1 B2max operation B1 B2 standardized apart. is, s, MAPB (s) =max{MAPB1 (s), MAPB2 (s)}. Let B result combining B1 B2 maxoperation B1 B2 standardized apart. interpretations I, apB (I) =apB (I).Proof: theorem proved showing valuation maximizingdiagram completed valuation combined diagram givingvalue. Clearly apB (I) apB (I) since every substitution path exist Balso possible B. show direction holds well. Let ~uvariables common B1 B2 . Let u~1 variables B1 B2 u~2variables B2 B1 . definition, interpretation I,apB (I) = ax[M apB1 (I), apB2 (I)] = ax[M apB1 (I, 1 ), apB2 (I, 2 )]243fiJoshi & KhardonFigure 4: FODD example illustrating need DPO.valuations 1 ~uu~1 2 ~uu~2 . Without loss generality let us assumeapB1 (I, 1 ) = ax[M apB1 (I, 1 ), apB2 (I, 2 )]. construct valuation~uu~1 u~2 1 share values variables ~u u~1 . Obviously apB1 (I, )= apB1 (I, 1 ). Also, definition FODD combination, apB (I)apB1 (I, ) = apB (I).4. Additional Reduction Operatorssection introduce two new reduction operators improve efficiencyVI algorithm. following definitions important developing reductionsunderstand potential scope reducing diagrams.Definition 1 descending path ordering (DPO) ordered list pathsroot leaf FODD B, sorted descending order value leaf reachedpath. relative order paths reaching leaf set arbitrarily.Definition 2 B FODD, P DPO B, path pj P instrumentalrespect P iff1. interpretation valuation, , P athB (I, ) = pj ,2. valuations , P athB (I, ) = pk , k j.example Figure 4 shows DPO needed. paths p(x) p(y)p(x) p(z) imply other. Whenever valuation traversing onepaths always another valuation traversing other. Removing one pathdiagram would safe meaning map changed. cannot removepaths. Without externally imposed order paths, clear pathlabeled redundant. DPO exactly make reduction possible.clear outset best choose DPO maximally reducesize diagram. lexicographic ordering paths equal value makes easyimplementation may best. describe heuristic approach choosingDPOs next section context implementation FODD-Planner.244fiProbabilistic Planning FODD4.1 R10 Reductionpath FODD B dominated whenever valuation traverses it, alwaysanother valuation traversing another path reaching leaf greater equal value.paths edge e dominated, valuation crossing edgeever determine map max aggregation semantics. cases replacetarget(e) 0 leaf. basic intuition behind R10 operation.Although objective R7-replace, R10 faster computecases two advantages R7-replace. First, paths rankedvalue leaf reach, perform single ranking check dominatedpaths (and hence dominated edges). Hence, reduction operatorslocal, R10 global reduction. Second, theorem proving required R10 alwaysconjunctive formulas existentially quantified variables, decidablefunction free case (e.g., Khardon, 1999). gives speedup R7-replace.hand R10 must explicitly enumerate DPO therefore efficientFODD exponential number non-zero valued paths. case R7edge based procedure likely efficient.Consider example shown Figure 5. following list specifies DPOdiagram:1. p(y), p(z), p(x) 32. p(y), p(z), p(x), q(x) 33. p(y), p(x), q(x) 24. p(y), p(z), p(x), q(x) 2Notice relative order paths reaching leaf DPO definedranking shorter paths higher longer ones. requirement correctnessalgorithm good heuristic. According reduction procedure, edgespath 1 important cannot reduced. However, since 1 subsumes 2, 3 4,edges (those belonging paths 2, 3 4 appearingranked paths) reduced. Therefore reduction procedure replaces targetsedges ones path 1, value 0. Path 1 thus instrumental pathpaths 2, 3 4 not. process formalized following algorithm.Procedure 2 R10(B)1. Let E set edges B2. Let P = [p1 , p2 pn ] DPO B. Thus p1 path reaching highest leafpn path reaching lowest leaf.3. j = 1 n, following(a) Let Epj set edges pj(b) i, < j B |= (x~pj , PF(pj )) (x~pi , PF(pi )), set E =E E pj245fiJoshi & Khardonp(y)p(y)R10p(z)0p(x)q(x)2p(x)q(x)20p(z)000p(x)033Figure 5: FODD example illustrating R10 reduction.4. every edge e E, set target(e) = 0 Bexample Figure 5 none paths 2, 3 4 pass conditions step 3balgorithm. Therefore edges removed E assignedvalue 0 algorithm. R10 able identify one pass, one path(shown along curved indicator line) dominates paths. achievereduction, R7-replace takes 2-3 passes depending order application. Since everypass R7-replace check implication edge formulas every pair edges,expensive. hand, cases R10 applicableR7-replace is. example shown diagram Figure 6. diagrameasy see e2 reached e1 e1 always gives strictly better value.R10 cannot applied tests subsumption complete paths. casepath e2 implies disjunction two paths going e1 .next present proof correctness R10. Lemma 3 shows testinstrumental paths correct. Lemma 4 shows that, result, edges marked deletionend algorithm belong instrumental path. theorem usesfact argue correctness algorithm.Lemma 3 path pj P , pj instrumental i, < j B |= (x~pj ,PF(pj )) (x~pi , PF(pi )).Proof: pj instrumental definition, interpretation valuation,, P athB (I, ) = pj , valuations , < j P athB (I, ) = pi .words, |= [B (x~pj , PF(pj ))] 6|= [B (x~pi , PF(pi ))] < j.implies i, < j (B x~pj , PF(pj )) |= (B x~pi , PF(pi )). Hence i, < jB |= [(x~pj , PF(pj )) (x~pi , PF(pi ))].Lemma 4 E set edges left end R10 procedure e Einstrumental path goes e.246fiProbabilistic Planning FODDFigure 6: FODD example R7 applicable R10 not.Proof: Lemma 3 proves path pj instrumental, i, < j B |= [(x~pj ,PF(pj )) (x~pi , PF(pi ))]. Thus step 3b R10, path instrumental, edgesremoved E. Therefore e E end R10 procedure, cannotpj . Since pj constrained way argument above, e cannotinstrumental path.Theorem 3 Let B FODD. B = R10(B) interpretations I, apB (I) =apB (I).Proof: definition R10, difference B Bedges pointed sub-FODDs B, point 0 leaf B . edgesleft set E end R10 procedure. Therefore valuation crossingedges achieves value 0 B could achieved value Binterpretation. Valuations crossing edges achieve value BB. Therefore interpretation valuation , apB (I, ) apB (I, )hence apB (I) apB (I).Fix interpretation v = apB (I). Let valuation apB (I, )= v. one gives value v, choose one whose path pjleast index P . definition pj instrumental lemma 4, noneedges pj removed R10. Therefore apB (I, ) = v = apB (I). Finally,definition max aggregation semantics, apB (I) apB (I, ) thereforeapB (I) apB (I).R10 procedure similar reduction decision list rules ReBel (Kerstinget al., 2004). difference, however, R10 reduction procedure FODDstherefore uses individual rules subroutine gather informationredundant edges. Thus ReBel removes paths R10 removes edges affecting multiplepaths diagram. main potential disadvantage R10 representationReBel case number paths prohibitively large. case R7edge based reduction likely efficient. experiments showcase IPC domains tested. general case, meta-reduction heuristic tradingadvantages different operators would useful. discuss implementationexperimental results next sections.247fiJoshi & Khardon4.2 R11 ReductionConsider FODD B Figure 1(a). Clearly, background knowledge diagram cannot reduced. assume background knowledge B contains rulex, [q(x) p(x)]. case exists valuation reaches 1 leaf, mustanother valuation agrees values x y. dominatesvaluations max aggregation semantics. background knowledge rule implies, test root node redundant. However, cannot set left childroot 0 since entire diagram eliminated. Therefore R7 applicable,similarly none existing reductions applicable. Yet redundancies likegiven example arise often runs value iteration algorithm. happens naturally,without artificial background knowledge used example correspondingdiagrams large include text. main reason redundanciesstandardizing apart (which discussed above) introduces multiple renamed copiesatoms different diagrams. diagrams added, manyatoms redundant removed old operators. atoms may endparent-child relation weak implication child parent, similarexample given. introduce R11 reduction operator handle situations.R11 reduces FODD Figure 1(a) FODD Figure 1(b).Let B FODD, n node B, e edge e {nt , nf }, e = sibling(e)(so e = nt , e = nf vice versa), P set paths rootnon-zero leaf going edge e. reduction R11(B, n, e) drops node ndiagram B connects parents target(e). need two conditionsapplicability R11. first requires sibling zero valued leaf.Condition 1 target(e ) = 0.second requires valuations rerouted R11 traversing B ,valuations previously reached 0 leaf traverse path P ,dominated valuations giving value.Condition 2 p P , B |= [x~p , PF(p)\ne .lit ne .lit] [x~p , PF(p)].next theorem shows R11 sound. proof shows condition 2rerouted valuations add value diagram.Theorem 4 B = R11(B, n, e), conditions 1 2 hold, interpretations I,apB (I) = apB (I).Proof: Let interpretation let Z set valuations. divide Zthree disjoint sets depending path taken valuations B I. Z e -set valuations crossing edge e, Z e - set valuations crossing edge e Z- set valuations reaching node n. analyze behavior valuationssets I.Since structurally difference B B B node n bypassed, paths root leaf cross node n remain untouched.Therefore Z , apB (I, ) = apB (I, ).248fiProbabilistic Planning FODDSince, B parents node n connected target(e), valuations crossingedge e reaching target(e) B unaffected B will, therefore,produce map. Thus Z e , apB (I, ) = apB (I, ).Now, let denote node target(e) B. I, valuations Z e reach0 leaf B cross node B . Depending leaf reachedecrossing node m, set Z e divided 2 disjoint subsets. Zzeroeset valuations reaching 0 leaf Znonzero - set valuations reachinge , ap (I, ) = ap (I, ).non-zero leaf. Clearly ZzeroBBestructure B, every Znonzero, traverses p P , is, (PF(p)\ne .liten .lit) true I. Condition 2 states every , anothervaluation (PF(p)) true I, traverses path. However,every valuation must belong set Z e definition set Z e .edominated valuation Z e .words, B every valuation Znonzeroargument conclude B I, every valuation either producesmap B dominated valuation. max aggregationsemantics, therefore, apB (I) = apB (I).5. FODD-Plannersection discuss system FODD-Planner implements VI algorithmFODDs. FODD-Planner employs number approximation techniques yieldspeedup. system also implements extensions basic VI algorithmallow handle action costs universal goals. following sections describedetails.5.1 Value ApproximationReductions help keep diagrams small size removing redundanciestrue n step-to-go value function large, legal reductions cannot help.domains true value function unbounded. example tireworld domaininternational planning competition, goal always get vehicledestination city, one chain cities linked one another destination.chain length. Therefore value function represented usingstate abstraction, must unbounded. result SDP-like algorithms less effectivedomains dynamics lead transitive structure every iteration valueiteration increases size n step-to-go value function (Kersting et al., 2004; Sanner& Boutilier, 2009). cases value function infinite simply largemanipulate efficiently. happens resort approximation keeping muchstructure value function possible maintaining efficiency. One mustcareful tradeoff here. Without approximation runtime prohibitivemuch approximation causes loss structure value. next present three methodsget approximations act different levels algorithm.249fiJoshi & Khardon5.1.1 Standardizing Apart Action VariantsStandardizing apart diagrams action variants adding requiredcorrectness FODD based VI algorithm. is, standardize apart actionvariant diagrams adding them, value given states may lowertrue value (Wang et al., 2008). Intuitively, true since different paths valuefunction share atoms variables. Now, fixed action, best variable bindingcorresponding value different action variants may different. Thus, variablesforced variants, may rule viable combinations value.hand, value obtained standardize apart lower bound truevalue. every path diagram resulting standardizing apartpresent diagram resulting standardizing apart. Although value exact,standardizing apart leads compact diagrams, therefore usefulspeeding algorithm. call approximation method non-std-apart useheuristic speed computation. Although heuristic may cause loss structurerepresentation value function, observed practice gives significantspeedup maintaining relevant structure. approximation usedexperiments described below.5.1.2 Merging Leavesuse FODDs also allows us approximate value function simple controlled way. follow approximation techniques APRICODD (St-Aubin et al.,2000) used propositional problems. idea reduce sizediagram merging substructures similar values. One wayreduce precision leaf values. is, given precision value , join leaveswhose value within . This, turn, leads reduction diagram subpartsdiagram previously pointed different leaves, point leaf.granularity approximation, however, becomes extra parameter systemchosen carefully. Details provided experiments below.5.1.3 Domain DeterminizationPrevious work stochastic planning discovered domains one get goodperformance pretending domain deterministic re-planning unexpectedoutcomes reached (Yoon et al., 2007). use similar idea determinizedomain process policy generation. saves significant amount computationavoids typical increase size value function encountered step 2 VIalgorithm. Domains determinized many ways. choose perform determinization replacing every stochastic action probable deterministic alternative.done prior running VI. Although method determinizationsub-optimal many domains, makes sense domains probable outcome corresponds successful execution action (Little & Thibaux, 2007)case domains experimented with. Note determinization appliesprocess policy generation. generated policy deployed solve planningproblems, original stochastic environment. approximation usedexperiments described below.250fiProbabilistic Planning FODD5.2 Extensions VI AlgorithmFODD-Planner makes two additional extensions basic algorithm. allowshandling action costs, arbitrary conjunctive goals well universal goals.5.2.1 Handling Action Costsstandard way handle action costs replace R(s, a) R(s, a) Cost(s, a)VI algorithm. However, formalism using FODDs relies factleaves (and thus values) non-negative. avoid difficulty, note action costssupported long least one zero cost action. see recall VIalgorithm. appropriate place add action costs Object Maximizationstep. However, step followed maximizing action diagrams,least one action 0 cost (if create no-op action), resultant diagrammaximization never negative leaves. Therefore safely convert negative leavesmaximization step 0 thereby avoid conflict reduction procedures.5.2.2 Handling Universal GoalsFODDs max aggregation cannot represent universal quantifiers. Therefore VIalgorithm cannot handle universal goals abstract level (though see Joshi et al. (2009)formalism accept arbitrary quantifiers). concrete planning problemknown set objects instantiate universal goal get large conjunctivegoal. principle run VI policy generation large conjunctive goal.However, would mean cannot plan off-line get generic policy mustreplan problem instance scratch. follow alternative heuristicapproach previously introduced Sanner Boutilier (2009) use approximationtrue value function, results simple additive decomposition goalpredicates.Concretely, off-line planning plan separately generic versionpredicate. example transportation domain discussed plangeneric predicate box-in-city(box, city) well individual predicates.execution time, given concrete goal, approximate true value functionsum generic versions ground goal predicate. clearly exactcalculation work every case. hand, considerably extendsscope technique works well many situations.5.3 FODD-Planner Systemimplemented FODD-Planner system, plan execution routines evaluationroutines Yap Prolog 5.1.2. code domain encodings used experimentsreported next section available http://code.google.com/p/foddplanner/tag release11-JAIR2011.implementation uses simple theorem prover supports background knowledgeprocedure call state flooding. is, prove B |= X , X groundconjunction (represented Prolog list), flood X using rules backgroundknowledge using following simple steps convergence.251fiJoshi & Khardon1. Generate Z, set ground literals derived X rulesbackground knowledge.2. Set X = X Z.X converged test membership X. restrictedlanguage, reasoning problem decidable theorem prover complete.2overall algorithm SDP except operations performedFODDs reductions applied keep intermediate diagrams compact.experiments reported below, use previously mentioned reductions (R1 R11)except R7-replace. applied reductions iteratively reduction applicableFODD. correct order apply reductions sense reductionapplied give rise reductions. Heuristically chose orderhope get much diagram reduced soon possible. apply reductionsfollowing order. start applying R10 twice different DPO time. firstDPO generated breaking ties favor shorter paths. second generatedreversing order equal valued paths first DPO. R10 hope catch manyredundant edges early. R10 followed R7-drop remove redundant nodes connectededges removed R10. this, apply round strong reductions followedR9 remove redundant equality nodes. R9 followed another round strongreductions. sequence performed iteratively diagram stable.FODD-Planner strong reductions automatically applied every time two diagramscombined (using apply algorithm (Wang et al., 2008)) weak reductions appliedevery time two diagrams combined except regression block combination.chose apply R11 twice every iteration - regressionnext iteration. setting application reduction operators investigatedexperimentally discussed Section 6.1.handle complex goals use additive goal decomposition. generic goalatom g run system specified number iterations, last iterationperform step 4 algorithm. yields set functions, Qg,A , parameterizedaction generic goal implicitly represent policy. improve line executiontime using policy extract set paths Q functions perform logicalsimplification paths removing implied atoms directly applying equalitiespath formula. final form policy off-line planningphase. on-line phase, given concrete problem state goal identify potentialactions, action find top ranking rule concrete goal atom g.combined give total value action action highest valuechosen, breaking ties randomly unique.2. alternative list representation X would utilize Prolog database storeliterals X employ Prolog engine query . However, experience Yap,becomes expensive assert (and retract) literals X (from) Prolog database listrepresentation faster.252fiProbabilistic Planning FODD6. Experimental Resultsran experiments standard benchmark problem well probabilistic planningdomains international planning competitions (IPC) held 2004, 2006 2008.probabilistic track IPC provides domain descriptions PPDDL language(Younes, Littman, Weissman, & Asmuth, 2005). encoded TVDs probabilityreward functions domains translating PPDDL manually straightforwardmanner.3 experiments run Linux machine Intel Pentium processorrunning 3 GHz, 2 GB memory. Following IPC standards, timings, rewardsplan-lengths report averages 30 rounds. domain, constructedhand background knowledge restricting arguments predicates (e.g. boxone city time Bin(b, c1 ), Bin(b, c2 ) (c1 = c2 )). discussed above,useful process simplifying diagrams.6.1 Merits Reduction Operatorsfollowing subsections present main results showing performance solving planningproblems IPC. discussing first investigate illustrate meritsvarious reduction operators terms effect off-line planning time.experiments performed tireworld boxworld domains describeddetail below. section suffices consider domains typical casesmight address solving planning problems focus differencesreductions.first set experiments compare run time R7 R10 contextreductions. Since R10 R7 edge removal reductions R7-drop usedconjunction both, compare R10 R7-replace directly configurationsR9 R11. Except choice reductions used experimental setup exactlydetailed above. Figures 7 8 show time build policy varyingnumber iterations different settings weak reduction operators boxworldtireworld domains. figures clearly show superiority R10 R7-replace.combinations R7-replace prohibitively large run times 3 4 iterations.without R9 R11, R10 orders magnitude efficient R7-replace.reason future experiments used R10 instead R7-replace.experiments also demonstrate without new reduction operators presentedpaper FODD-Planner would slow run sufficient iterations VIalgorithm done following subsections yield good planning performance. Figure 8shows boxworld R11 hinders R7. appears case, applicationR11 limits applicability R7 causing larger diagrams thus slowingVI.Figures 9 10 show relative merits R9 R11 presence R10two domains. figures similar previous two plots except focusrelevant portion CPU time axis. Clearly R11 important reduction makes3. FODD formalism cannot capture PPDDL. particular since FODDs cannot represent universal quantification, cannot handle universal action preconditions. hand FODDshandle universal action effects. Wang (2007) provides algorithm detailed discussion translation PPDDL FODDs.253fiJoshi & KhardonTireworld: R7 vs. R10100000CPU Time (seconds)80000R10R10+R11R10+R9R10+R9+R11R7R7+R11R7+R9R7+R9+R11600004000020000001234# iterations5678Figure 7: comparison planning time taken various settings reduction operatorsvarying number iterations tireworld. Four settings R10 comparedfour settings R7. R7 variants complete 5 iterations withintime range graph therefore points plotted.Boxworld: R7 vs. R10R10R10+R11R10+R9R10+R9+R11R7R7+R11R7+R9R7+R9+R1140000CPU Time (seconds)30000200001000000123# iterations456Figure 8: comparison planning time taken various settings reduction operatorsvarying number iterations boxworld. Four settings R10 comparedfour settings R7. R7 variants complete 5 iterations withintime range graph therefore points plotted.planning efficient settings (just R10 R10+R9). R9 less effectivetireworld. boxworld, however presence R9 clearly improves planning efficiencysettings, best performance achieved setting using R10+R9+R11.addition, R9 targets removal equality nodes reduction directly.254fiProbabilistic Planning FODDTireworld: Merits R9 R1125000CPU Time (seconds)20000R10R10+R11R10+R9R10+R9+R1115000100005000001234# iterations5678Figure 9: comparison merits R9 R11 presence R10 tireworld.Boxworld: Merits R9 R113000025000CPU Time (seconds)20000R10R10+R11R10+R9R10+R9+R111500010000500000123# iterations456Figure 10: comparison merits R9 R11 presence R10 boxworld.Based results choose setting employ R10 along R9 R11remaining experiments.6.2 Logistics Benchmark Problemboxworld problem introduced Boutilier et al. (2001) usedstandard example exact solution methods relational MDPs. domain consistsboxes, cities trucks. objective get certain boxes certain cities loading,unloading driving. benchmark problem, goal existence boxParis. load unload actions probabilistic probability success unloaddepends whether raining not. domain, cities reachableother. result domain compact abstract optimal value function. Notechallenge domain concrete planning instances solve. Instead goal255fiJoshi & KhardonGPTPolicy Iterationpolicy language biasRe-Engg NMRDPPFODD-PlannerCoverage100%Time (ms)2220Reward57.6646.66%10%100%6046629083023127036-387.770.0Table 1: fileworld domain resultssolve off-line problem produce (abstract) optimal solution efficiently.domain description 3 predicates arity 2 3 actions 2 arguments.Like ReBel (Kersting et al., 2004) FOADD (Sanner & Boutilier, 2009) ablesolve MDP identify relevant partitions optimal value functionfact value function converges 10 iterations. FODD-Planner performed 10iterations 2 minutes.6.3 Fileworld Domaindomain part probabilistic track IPC-4 (2004) (information competitions accessible http://ipc.icaps-conference.org/). domain consistsfiles folders. Every file obtains random assignment folder execution timegoal place file assigned folder. cost 100 handle foldercost 1 place file folder. optimal policy domain first getassignments files folders handle folder once, placing filesassigned it. domain description 8 predicates arity 0 2 16 actions0 1 arguments.Results published one problem instance consisted thirty filesfive folders. Since goal conjunctive used additive goal decompositiondiscussed above. used off-line planning generic goal f iled(a) use policysolve number files. domain ideal abstract solversoptimal value function policy generic goal compact found quickly.FODD-Planner able achieve convergence within 4 iterations even withoutapproximation. Policy generation execution together took 4 minutes. 6systems competed track, results published 3 website citedabove. Table 1 compares performance FODD-Planner others. observerank ahead terms total reward coverage (both FODD-PlannerGPT achieve full coverage).6.4 Tireworld Domaindomain part probabilistic track IPC-5 (2006). domain consistsnetwork locations (or cities). vehicle starts one city moves city cityobjective reaching destination city. Moves made citiesdirectly connected road. addition, move, vehicle may lose tire40% probability. cities spare tire loaded onto vehicle.vehicle contains spare tire, flat tire changed 50% success probability.domain simple trivial owing possibility complex network topology256fiProbabilistic Planning FODDTireworld: Percentage Runs Solved vs. Problem Instance100Percentage Runs Solved806040FOALPFPGParagraphFF-ReplanFODDPlanner2000246810Problem Instance ID121416Figure 11: Coverage result tireworld experimentsTireworld: Average Running Time vs. Problem Instance1e+06Average Running Time (ms)FOALPFPGParagraphFF-Replan100000 FODDPlanner100001000100100246810121416Problem Instance IDFigure 12: Timing result tireworld experimentshigh probabilities failure. IPC description domain 5 predicatesarity 0 2 3 actions 0 2 arguments.Participants IPC-5 competed 15 problem instances domain varyingdegree difficulty. problem 1 16 locations progressively increased2 per problem 44 locations problem 15.limit off-line planning time restricted FODD-Planner 7 iterations withoutapproximation first 3 iterations non-std-apart approximationremaining iterations. policy generated 55 minutes; together onlineplanning time within competition time bound. performance FODD-Planner257fiJoshi & KhardonTireworld: Average # Actions Goal vs. Problem Instance12FOALPFPGParagraphFF-ReplanFODDPlannerAverage # Actions Goal10864200246810Problem Instance ID121416Figure 13: Plan length result tireworld experimentssystems competing probabilistic track IPC-5, data published,summarized Figures 11, 12, 13. figures indexed problem instanceshow comparison percentage runs planner able solve (coverage),average time per instance taken planner generate online solution,average number actions taken planner reach goal every instance.observe overall performance FODD-Planner competitive (andcases better than) systems. Runtimes generate online solutions highFODD-Planner comparable FOALP First-Orderplanner. hand, comparison systems, able achievehigh coverage short plans many problems.6.5 Value Approximation Merging LeavesAlthough tireworld domain solved within IPC time limit, one mightwish even faster execution. show next, heuristic merging leaves providestool, potentially trading quality coverage plan length faster planningexecution times. Table 2 shows average reduction planning time, coverageplanning length achieved approximation merging leaves used. highestreward obtained state 500. experimented reducing precision leavesvalues 50.0 150.0. results demonstrate, loss coverageplanning length, system gain terms execution time planning time.example, leaf precision 50.0 (10% total value) get 95.53% reductionplanning time (22 fold speedup) lose 15.29% coverage.44. Note measure plan length, average problems solved, good representationperformance coverage full. case, coverage goes dropping harderproblems longer solutions, plan length appear better, clearly indicationimproved performance.258fiProbabilistic Planning FODDPrecision5075100125150ReductionPlanning Time93.53%98.13%98.28%99.65%99.73%ReductionExecution Time88.3%95.21%95.21%95.48%95.61%ReductionCoverage15.29%15.29%15.29%31.76%31.76%ReductionPlan length14.54%6.23%6.23%-30.86%-30.86%Table 2: Percentage average reduction planning time, execution time, coverage planlength tireworld approximation merging leaves varying leaf precision values. example, first row table states reducingprecision leaves 50, 10% largest achievable rewardstate, planning time reduced 93.53% original value, averageexecution time reduced 88.3%, average coverage reduced 15.29%average plan length reduced 14.54%6.6 Boxworlddomain IPC 2008, world consists boxes, trucks, planes mapcities. objective get boxes source cities destination cities using trucksplanes. Boxes loaded unloaded trucks planes. Trucks (andplanes) driven (flown) one city another long direct road (orair route) source destination city. probabilistic action drive.drive works expected (transporting truck source city destinationcity) probability 0.8. Occasionally drive teleports truck wrong city. IPCdescription domain includes 11 predicates arity 2 6 actions 3 arguments.IPC posted 15 problems varying levels difficulty domain. problemsworld consisted 4 trucks 2 airplanes. problems 1 3 10 boxes5 cities. Problems 4 5 10 boxes 10 cities. Problems 6 7 10 boxes15 cities. Problems 8 9 15 boxes 10 cities. Problems 10, 11 12 15 boxes15 cities. Competition results show RFF (Teichteil-Koenigsbuch et al., 2008)system solved 15 problems. Neither RFF FODD-Plannercould solve problems 13 15; hence omit results those.limit off-line planning time determinized domain (making drive deterministic)restricted FODD-Planner 5 iterations. Since domain determinized,one alternative per action. Therefore non-std-apart approximationeffect here. policy generated 42.6 minutes. performance FODDPlanner RFF summarized Figures 14, 15, 16. figures show comparisonpercentage runs planner able solve (coverage), average rewardachieved per problem instance, average number actions taken plannerreach goal every instance.seen FODD-Planner lower coverage RFF. However, performance close RFF terms accumulated reward consistently better termsplan length even problems achieve full coverage.259fiJoshi & KhardonBoxworld: Percentage Runs Solved vs. Problem Instance100Percentage Runs Solved80FODDPlannerRFF604020002468Problem Instance ID1012Figure 14: Coverage results boxworld experimentsBoxworld: Average # Actions Goal vs. Problem Instance18001600Average # Actions Goal1400FODDPlannerRFF1200100080060040020000246810Problem Instance IDFigure 15: Plan length results boxworld experiments26012fiProbabilistic Planning FODDBoxworld: Average Reward vs. Problem Instance20001800FODDPlannerRFF1600Average Reward140012001000800600400200002468Problem Instance ID1012Figure 16: Average reward results boxworld experimentsdomain experienced long plan execution times (10 minutes per round hardproblems 15 seconds per round easier problems). points complexity instances could one reason failure planning systemsIPC strict time bound observed, failure RFF problems 13,14 15. Thus, although performance system promising, reducing online execution time crucial. shown above, domains technique merging leaveslead improvement cost reduction performance. Unfortunately,domain merging leaves provide advantage. tireworld,clear tradeoff quality coverage planning time. However switchabrupt gain significantly execution time one incurs significant loss coverage.Improving runtime online application policies important aspect futurework.7. Related Workintroduction briefly reviewed previous work MDPs, propositionally factored MDPsRMDPs focusing work directly related ideas used paper.several solution formalisms RMDPs combine dynamic programming ideas yield successful systems. include approaches combinedynamic programming linear function approximation (Sanner & Boutilier, 2009), forward search (Holldobler et al., 2006) machine learning (Fern, Yoon, & Givan, 2006;Gretton & Thiebaux, 2004). yielded strong implementations participatedplanning competitions. works directly use dynamic programming.instance Guestrin, Koller, Gearhart, Kanodia (2003a) present approach usingadditive value functions based object classes employ linear programming solveRMDP. Mausam Weld (2003) employ SPUDD (Hoey et al., 1999) solve groundinstances RMDP, generate training data solutions learn lifted value261fiJoshi & Khardonfunction training data using relational tree learner. Gardiol Kaelbling (2003)apply methods probabilistic planning solve RMDPs.closely related work preceded effort, Sanner Boutilier (2009)developed relational extension linear function approximation techniques factoredMDPs. value function represented weighted sum basis functions, denotingpartition state space. difference work factored MDPsbasis functions First-Order formulas thus value function valid domainsize (this fundamental advantage RMDP solvers ground MDPsolvers). develop methods automatic generation First-Order constraintslinear program automatic generation basis functions show promise solvingdomains IPC. work Sanner Boutilier thus extensionwork linear representations propositionally factored MDPs (e.g., Guestrin et al.,2003b) capture relational structure. similar view work FODD-Plannerrelational extension work ADD based solvers propositionally factored MDPs(Hoey et al., 1999). context interesting note Sanner Boutilier alsodeveloped relational extension ADDs call FOADDs. contrast FODDs,nodes FOADDs labeled closed First-Order formulas.5 Sanner Boutilierreport implementation able provide exact solutions simple problems,developed applied approach using linear function approximationcomplex problems. experiments use approximation demonstrateFODDs used solve problems least complexity currently employedIPC.Another important body work pursued Relational Reinforcement Learning(RRL) (Tadepalli, Givan, & Driessens, 2004) techniques reinforcement learningused learn construct value functions policies relational domains. RRLfollowed seminal work Dzeroski, De Raedt, Driessens (2001) whose algorithm involved generating state-value pairs state space exploration (biased favorstate-action pairs high estimated value) learning relational value function treecollected data. sense First-Order decision trees used Dzeroski et al.(2001) similar FODDs. However, important difference semanticsrepresentations strong implications computational properties.trees employ semantics based traversal single path, FODD semantics basedaggregating values generated traversal multiple paths. previously argued(Wang et al., 2008) FODD semantics much better suited dynamic programming solutions. several approaches RRL recent years showing niceperformance (for example, Driessens & Dzeroski, 2004; Kersting & De Raedt, 2004; Walker,5. discussed Sanner Boutilier (2009) hard characterize exact relationshipFOADDs FODDs terms representation computational properties. anonymous reviewerkindly provided following example shows cases FODDs might compactFOADDs. Consider domain n unary predicates A1 (), . . . , () capturing object propertiesconsider formula x, A1 (x) Xor A2 (x) Xor . . . Xor (x) n odd. formula requiresexists object odd number properties Ai () hold. Due restrictionuse connectives And, Not, FOADDs must rewrite formula way yieldsrepresentation (for example DNF form) whose size exponential number predicates.hand, one represent formula linear size FODD, similar representationparity functions propositional BDDs.262fiProbabilistic Planning FODDTorrey, Shavlik, & Maclin, 2007; Croonenborghs, Ramon, Blockeel, & Bruynooghe, 2007)although applied problems smaller scale ones IPC.excellent overview various solutions methods RMDPs provided van Otterlo(2008).8. Conclusion Future Workmain contribution paper introduction FODD-Planner, relationalplanning system based First Order Decision Diagrams. first planning systemuses lifted algebraic decision diagrams representation language successfullysolves planning problems international planning competition. FODD-Plannerprovides several improvements previous work FODDs (Wang et al., 2008). improvements include reduction operators R10, R11 Sub-apart operator, severalspeedup value approximation techniques. Taken together, improvements provide substantial speedup making approach practical. Therefore, results showabstraction compact representation promising approach stochastic planning.work raises many questions concerning foundations FODDs application solve RMDPs. first question reductions. set reductionsstill heuristic guarantee canonical form diagrams instrumentalefficiency propositional algorithms. Identifying complete sets reductionsoperators canonical forms interesting challenge. Identifying practically goodset operators trading complexity reduction power crucial applicability. recent work (Joshi, Kersting, & Khardon, 2010) developed practical variantsmodel-checking reductions (Joshi et al., 2009) demonstrating significant speedupsystem presented here. Another improvement may possible using FODD basedpolicy iteration algorithm (Wang & Khardon, 2007). may allow us avoid approximation infinite size value functions cases policy still compact. Anotherdirection use expressive GFODDs (Joshi et al., 2009) handle arbitrary quantification therefore applied widely. Finally work suggestspotential using FODDs underlying representation relational reinforcementlearning. Therefore, interesting develop learning algorithms FODDs.Acknowledgmentswork partly supported NSF grants IIS 0936687 IIS 0964457. Saket Joshiadditionally supported Computing Innovation Postdoctoral Fellowship.experiments reported paper performed Tufts Linux ResearchCluster supported Tufts UIT Research Computing. thank Kristian Kerstingvaluable input system insightful discussions.ReferencesBahar, R., Frohm, E., Gaona, C., Hachtel, G., Macii, E., Pardo, A., & Somenzi, F. (1993).Algebraic decision diagrams applications. IEEE /ACM ICCAD, pp.188191.263fiJoshi & KhardonBellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90(1-2), 279298.Blum, A., & Langford, J. (1998). Probabilistic planning graphplan framework.Proceedings Fifth European Conference Planning, pp. 812.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129,533.Boutilier, C., Dean, T., & Hanks, S. (1999a). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research, 11,194.Boutilier, C., Dearden, R., & Goldszmidt, M. (1999b). Stochastic dynamic programmingfactored representations. Artificial Intelligence, 121, 49107.Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming First-OrderMDPs. Proceedings International Joint Conference Artificial Intelligence,pp. 690700.Croonenborghs, T., Ramon, J., Blockeel, H., & Bruynooghe, M. (2007). Online learningexploiting relational models reinforcement learning. ProceedingsInternational Joint Conference Artificial Intelligence, pp. 726731.Driessens, K., & Dzeroski, S. (2004). Integrating guidance relational reinforcementlearning. Machine Learning, 57, 271304.Dzeroski, S., De Raedt, L., & Driessens, K. (2001). Relational reinforcement learning.Machine Learning, 43, 752.Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration policy languagebias. Journal Artificial Intelligence Research, 25(1), 75118.Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2(3-4), 189208.Gardiol, N., & Kaelbling, L. (2003). Envelope-based planning relational MDPs. Proceedings International Conference Neural Information Processing Systems,pp. 10401046.Gretton, C., & Thiebaux, S. (2004). Exploiting First-Order regression inductive policyselection. Proceedings Workshop Uncertainty Artificial Intelligence.Groote, J., & Tveretina, O. (2003). Binary decision diagrams First-Order predicatelogic. Journal Logic Algebraic Programming, 57, 122.Guestrin, C., Koller, D., Gearhart, C., & Kanodia, N. (2003a). Generalizing plans newenvironments relational MDPs. Proceedings International Joint ConferenceArtificial Intelligence, pp. 10031010.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003b). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research, 19, 399468.264fiProbabilistic Planning FODDHoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using decision diagrams. Proceedings Workshop Uncertainty ArtificialIntelligence, pp. 279288.Holldobler, S., Karabaev, E., & Skvortsova, O. (2006). FluCaP: heuristic search plannerFirst-Order MDPs. Journal Artificial Intelligence Research, 27, 419439.Howard, R. (1960). Dynamic Programming Markov Processes. MIT Press.Joshi, S., Kersting, K., & Khardon, R. (2009). Generalized First-Order decision diagramsFirst-Order Markov decision processes. Proceedings International JointConference Artificial Intelligence, pp. 19161921.Joshi, S., Kersting, K., & Khardon, R. (2010). Self-Taught decision theoretic planningFirst-Order decision diagrams. Proceedings International ConferenceAutomated Planning Scheduling, pp. 8996.Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic,stochastic search. Proceedings National Conference American Association Artificial Intelligence, pp. 11941201.Kearns, M., & Koller, D. (1999). Efficient reinforcement learning factored MDPs.Proceedings International Joint Conference Artificial Intelligence, pp. 740747.Kersting, K., & De Raedt, L. (2004). Logical Markov decision programs convergencelogical TD(). Proceedings Inductive Logic Programming, pp. 180197.Kersting, K., van Otterlo, M., & De Raedt, L. (2004). Bellman goes relational. ProceedingsInternational Conference Machine Learning, pp. 465472.Khardon, R. (1999). Learning function free Horn expressions. Machine Learning, 37 (3),249275.Little, I., & Thibaux, S. (2007). Probabilistic planning vs. replanning. ProceedingsICAPS Workshop IPC: Past, Present Future.Lloyd, J. (1987). Foundations Logic Programming. Springer Verlag. Second Edition.Majercik, S., & Littman, M. (2003). Contingent planning uncertainty via stochasticsatisfiability. Artificial Intelligence, 147 (1-2), 119162.Mausam, & Weld, D. (2003). Solving relational MDPs First-Order machine learning.Proceedings ICAPS Workshop Planning Uncertainty IncompleteInformation.Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order plannerADL. Principles Knowledge Representation Reasoning, pp. 103114.Puterman, M. L. (1994). Markov decision processes: Discrete stochastic dynamic programming. Wiley.Sanner, S., & Boutilier, C. (2009). Practical solution techniques First-Order MDPs.Artificial Intelligence, 173, 748788.265fiJoshi & KhardonSt-Aubin, R., Hoey, J., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. Proceedings International Conference NeuralInformation Processing Systems, pp. 10891095.Tadepalli, P., Givan, R., & Driessens, K. (2004). Relational reinforcement learning:overview. Proceedings International Conference Machine Learning 04Workshop Relational Reinforcement Learning.Teichteil-Koenigsbuch, F., Infantes, G., & Kuter, U. (2008). RFF: robust FF-based MDPplanning algorithm generating policies low probability failure. SixthIPC ICAPS.van Otterlo, M. (2008). logic Adaptive behavior: Knowledge representationalgorithms adaptive sequential decision making uncertainty First-Orderrelational domains. IOS Press.Walker, T., Torrey, L., Shavlik, J., & Maclin, R. (2007). Building relational world modelsreinforcement learning. Proceedings Inductive Logic Programming, pp. 280291.Wang, C. (2007). First-Order Markov decision processes. Ph.D. thesis, Tufts University.Wang, C., Joshi, S., & Khardon, R. (2008). First-Order decision diagrams relationalMDPs. Journal Artificial Intelligence Research, 31, 431472.Wang, C., & Khardon, R. (2007). Policy iteration relational MDPs. ProceedingsWorkshop Uncertainty Artificial Intelligence, pp. 408415.Weld, D., Anderson, C., & Smith, D. (1998). Extending graphplan handle uncertaintysensing actions. Proceedings National Conference Artificial Intelligence.Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning.Proceedings International Conference Automated Planning Scheduling,pp. 352359.Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic trackinternational planning competition. Journal Artificial Intelligence Research,24 (1), 851887.266fiJournal Artificial Intelligence Research 41 (2011) 407-444Submitted 02/11; published 07/11Efficient Multi-Start Strategies Local Search AlgorithmsAndras Gyorgygya@szit.bme.huMachine Learning Research GroupComputer Automation Research InstituteHungarian Academy Sciences1111 Budapest, HungaryLevente Kocsiskocsis@sztaki.huData Mining Web Search Research Group, Informatics LaboratoryComputer Automation Research InstituteHungarian Academy Sciences1111 Budapest, HungaryAbstractLocal search algorithms applied optimization problems often suffer gettingtrapped local optimum. common solution deficiency restartalgorithm progress observed. Alternatively, one start multiple instanceslocal search algorithm, allocate computational resources (in particular, processingtime) instances depending behavior. Hence, multi-start strategydecide (dynamically) allocate additional resources particular instancestart new instances. paper propose multi-start strategies motivatedworks multi-armed bandit problems Lipschitz optimization unknownconstant. strategies continuously estimate potential performance algorithminstance supposing convergence rate local search algorithm unknownconstant, every phase allocate resources instances could convergeoptimum particular range constant. Asymptotic bounds givenperformance strategies. particular, prove quadratic increasenumber times target function evaluated needed achieve performancelocal search algorithm started attraction region optimum. Experimentsprovided using SPSA (Simultaneous Perturbation Stochastic Approximation) kmeans local search algorithms, results indicate proposed strategies workwell practice, and, cases studied, need logarithmically evaluationstarget function opposed theoretically suggested quadratic increase.1. IntroductionLocal search algorithms applied optimization problems often suffer getting trappedlocal optimum. Moreover, local search algorithms guaranteed convergeglobal optimum conditions (such Simulated Annealing SimultaneousPerturbation Stochastic Approximation, SPSA, see, e.g., Spall, Hill, & Stark, 2006), usuallyconverge slow pace conditions satisfied. hand,algorithms employed aggressive settings, much faster convergence localoptima achievable, guarantee find global optimum. common soluc2011AI Access Foundation. rights reserved.fiGyorgy & Kocsistion escape local optimum restart algorithm progress observed(see e.g., Mart, Moreno-Vega, & Duarte, 2010; Zabinsky, Bulger, & Khompatraporn, 2010,references therein).Alternatively, one start multiple instances local search algorithm, allocatecomputational resources, particular, processing time, instances dependingbehavior. Instances started time, number instances may growtime depending allocation strategy. (see, e.g., Chapter 10 Battiti, Brunato, &Mascia, 2008 references therein). type problems computational costusually measured total number steps made search algorithm instances:often reflects situation evaluation target function optimizedexpensive, costs related determine algorithms use next negligiblecompared former (e.g., clearly case task tune parameterssystem whose performance tested via lengthy experiments, see, e.g., BartzBeielstein, 2006; Hutter, Hoos, Leyton-Brown, & Stutzle, 2009). paper addressproblem dynamically starting several instances local search algorithmsallocating resources instances based (potential) performance.knowledge, solutions problem either based heuristicsassumption local optima search algorithms convergeextreme value distribution (see Section 2 below). paper, propose new multi-startstrategies mild conditions target function, attractive theoreticalpractical properties: Supposing convergence rate local search algorithmsunknown constant, strategies continuously estimate potential performancealgorithm instance every phase allocate resources instances couldconverge optimum particular range constant. selection mechanismanalogous DIRECT algorithm (Jones, Perttunen, & Stuckman, 1993; Finkel &Kelley, 2004; Horn, 2006) optimizing Lipschitz-functions unknown constant,preference given rectangles may contain global optimum. optimumwithin rectangle estimated optimistic way, estimate dependssize rectangle. strategies use function describing convergence ratelocal search algorithms similar way size rectangles usedDIRECT algorithm.Since proposed multi-start strategies potential performance local searchalgorithm continuously estimated currently best value target functionreturned algorithm, method restricted work local search algorithmsreturn best known value target function step. case,example, certain meta-learning problems, goal find good parametersetting learning algorithm. search space parameter space learningalgorithm, one step local search methods means running learning algorithmcompletely possibly large data set. hand, local search algorithmsort gradient search optimizing error function training data,value target function usually available case batch learning(potentially cheap computations), gradient estimatedsamples.rest paper organized follows. Section 2 summarizes related research.problem defined formally Section 3. new multi-start local search strategies408fiEfficient Multi-Start Strategies Local Search Algorithmspaper described analyzed Section 4: Section 4.1 deal selectionmechanism among fixed number instances local search algorithm, while,addition, simple schedules starting new instances also considered Section 4.2,natural extensions case finitely many local search algorithm instances.section concludes discussion results Section 4.3. Simulation resultsreal synthetic data provided Section 5. Conclusions future workdescribed Section 6.2. Related Workproblem allocating resources among several instances search algorithmscomfortably handled generalized version maximum K-armed bandit problem.original version problem consists several rounds, round onechooses one K arms, receives reward depending choice, goalmaximizing highest reward received several rounds. model easily usedproblem considering local search algorithm instance arm: pullingarm means taking one additional step corresponding algorithm, is, evaluatingtarget function point suggested algorithm, reward receivedvalue target function sampled point. generic algorithm standardmaximum K-armed bandit problem, reward assumed independentidentical distribution, provided Adam (2001), so-called reservation priceinstance introduced, gives maximum amount resources worth spendinstance: instance achieves reservation price, useless select again.computation reservation price depends model algorithmlearnt specific constraints.consider scenario several instances some, possibly randomized localsearch algorithms run goal maximizing expected performance. instance run terminates. scenario natural assumevalues returned instances (usually local optima target function) independent. Furthermore, since good search algorithms follow (usually heuristic)procedures yield substantially better results pure random guessing, CicirelloSmith (2004, 2005) suggested rewards (evaluated target function values)search instances may viewed maximum many random variables (if instances run sufficiently long time), hence may modeled extreme valuedistributions. Several algorithms based assumption, hence developedmaximum K-armed bandit problem returns following generalized extreme valuedistributions: Cicirello Smith apply (somewhat heuristic) methods useextreme-value-distribution assumption decision point meta-learning algorithm,Streeter Smith (2006a) use model obtain upper confidence boundsperformance estimate type algorithms used try algorithmsbest expected result. latter theoretically justified example naturalstrategy probe algorithm instances while, estimate future performancebased results trial phase, use promising algorithmtime remaining. Streeter Smith (2006b) proposed distribution free approach409fiGyorgy & Kocsiscombines multi-armed bandit exploration strategy heuristic selection amongavailable arms.standard maximum K-armed bandit problem rewards roundassumed independent, clearly case situationalgorithm instances run parallel reward evaluating target functionpoint improvement upon current maximum, since samples chosen localsearch algorithm usually depend previous samples. Nevertheless, ideas lessonslearnt maximum K-armed bandit problems used case, well:example, algorithm Threshold Ascent Streeter Smith (2006b) gives reasonablygood solutions case, principle probing instances usingpromising time remaining also carries situation easily:algorithms, first exploration exploitation phase, referredsequel explore-and-exploit algorithms. class algorithms, simple rulessuggested Beck Freuder (2004) predict future performance algorithm,Carchrae Beck (2004) employ Bayesian prediction.Another related problem find fast algorithms among several ones solveproblem. precisely, several algorithm instances available producecorrect answer certain question run sufficiently long time. time neededalgorithm instance find answer assumed random quantityindependent identical distributions instances, goal combinegiven algorithms minimize expected running time answer found.distribution running time known, optimal non-adaptive time-allocation strategy1perform sequence runs certain cut-off time depends distribution(Luby, Sinclair, & Zuckerman, 1993). distribution unknown, particular runningtime sequence chosen results expected total running timelogarithmic factor larger optimum achievable distribution known. notestrategy among provide schedule increases numberalgorithm instances. set-up specialized problem: goal find-optimal approximation optimum running time number stepsneeded given search algorithm achieve approximation. Notecase running time algorithm instance providing -suboptimal solutiondefined infinity, results Luby et al. remain valid -optimal solutionfound positive probability. problem, Kautz, Horvitz, Ruan,Gomes, Selman (2002) proposed allocation strategy based updating dynamicallybelief run-time distribution. Concerning latter, Hoos Stutzle (1999)found empirically run-time distributions approximately exponential certain (NPhard) problems, Ribeiro, Rosseti, Vallejos (2009) dealt comparisondifferent run-time distributions.Finally, set time allocation strategies available optimization problem solved several times, one use standard multi-armed bandit frameworkdone Gagliolo Schmidhuber (2006, 2007, 2010).Running several instances algorithm several algorithms parallel selectingamong algorithms intensively studied, example, area meta1. non-adaptive time-allocation strategy running time algorithm instance fixed advance,is, measured performance algorithm instances effect schedule.410fiEfficient Multi-Start Strategies Local Search Algorithmslearning (Vilalta & Drissi, 2002) automatic algorithm configuration (Hutter et al., 2009).underlying problem similar cases: automatic algorithm configurationusually refers tuning search algorithms, meta-learning used subsetproblems, tuning machine learning algorithms (the latter often allows specific usedata). main problem allocate time slices particular algorithmsaim maximizing best result returned. allocation may depend intermediateperformance algorithms. automatic algorithm configuration metalearning systems use various heuristics explore space algorithms parameters(see, e.g., Hutter et al., 2009).Finally, important note that, although multi-start local search strategies solveglobal optimization problems, concentrate maximizing performance givenunderlying family local optimization methods. Since choice latter majoreffect achievable performance, compare results vast literatureglobal optimization.3. PreliminariesAssume wish maximize real valued function f d-dimensional unit hypercube[0, 1]d , is, goal find maximizer x [0, 1]d f (x ) = ff = max f (x)x[0,1]ddenotes maximum f [0, 1]d . simplicity, assume f continuous[0, 1]d .2 continuity f implies existence x , and, particular, f bounded.Therefore, without loss generality, assume f non-negative.form f known explicitly, search algorithms usually evaluate f severallocations return estimate x f based observations.obvious trade-off number samples used (i.e., number pointstarget function f evaluated) quality estimate, performancesearch strategy may measured accuracy achieves estimating fconstraint number samples used.Given local search algorithm A, general strategy finding good approximationoptimum x run several instances initialized different starting pointsapproximate f maximum f value observed. concentrate local searchalgorithms defined formally sequence possibly randomized sampling functionssn : [0, 1]dn [0, 1]d , n = 1, 2, . . .: evaluates f locations X1 , X2 , . . . Xi+1 =si (X1 , . . . , Xi ) 1, starting point X1 = s0 chosen uniformly random[0, 1]d ; n observations returns estimate x maximum f , respectively,bn = argmax f (Xk )bn ).Xf (X1kn1ties argmax function may broken arbitrarily, is, samples Xkbn chosen them. avoid ambiguityachieve maximum, X2. results easily extended (arbitrary valued) bounded piecewise continuous functionsfinitely many continuous components.411fiGyorgy & Kocsissimplify notation, following, unless stated explicitly otherwise, adoptconvention use argmax denote maximizing sample smallest index,results remain valid choice break ties.simplicity, consider starting single local search algorithm differentrandom points, although results work extended allow varyingparameters (including situation running different local search algorithms,parameter would choose actually employed search algorithm); well allowdependence among initializations (that is, starting point parameterslocal search instance may depend information previously obtained targetfunction).clear starting points sampled uniformly [0, 1]d algorithmbn ) convergesevaluated starting point strategy consistent, is, f (Xmaximum f probability 1 number instances tends infinity (inworst case perform random search known converge maximum almostsurely). hand, algorithm favorable properties possibledesign multi-start strategies still keep random search based consistency,provide much faster convergence optimum terms number evaluationsf.bn ) bounded non-decreasing, converges (no matterSince sequence f (Xrandom effects occur search). next lemma, proved Appendix A, showsthat, high probability, convergence cannot arbitrarily slow.bn ) = f .3 P (E) > 0,Lemma 1 f [0, 1]d , let E denote event limn f (Xbn ) fthen, 0 < < 1 event E E 1 P (E ) < f (Xuniformly almost everywhere E . words, exists non-negative, nonincreasing function g (n) limn g (n) = 0fibt ) = f 1 .b ) f (Xbn ) g (n) nfi lim f (XP lim f (X(1)certain cases, g (n) = O(en ), shown Nesterov (2004) (gradient-based)optimization convex functions, Gerencser Vago (2001) noise-free SPSAconvex functions, Kieffer (1982) k-means clustering (or Lloyds algorithm) onedimension log-concave densities. results pertain simple situationone local optimum global one, many resultsextended general situations, observed exponential rate convergenceexperiments functions many local maxima.convergence property local search algorithms guaranteed Lemma 1exploited next section derive efficient multi-start search strategies.4. Multi-Start Search StrategiesStandard multi-start search strategies run instance seems convergelocation hope beat currently best approximation f .3. practice usually assume local search algorithms converge local optima, f mayassumed local optimum.412fiEfficient Multi-Start Strategies Local Search Algorithmsalternative way using multiple instances local search algorithms run algorithmsparallel, round decide algorithms take extra step. approachmay based estimating potential performance local search algorithm basedLemma 1. Note g known, obvious way would run instancepossible performances become separated high probability sensemargin performance actually best second best algorithmlarge actually best algorithm guaranteed best, long run,high probability. could pick best instance run givencomputational budget exhausted (this would simple adaptation explore-andexploit idea choosing best algorithm based trial phase Beck & Freuder,2004; Carchrae & Beck, 2004).practice, however, g usually known, certain problem classes localsearch algorithms may known belong function class, example, g mayknown (multiplicative) constant factor (here, example, constant maydepend certain characteristics f , maximum local steepness). Evenlatter case, best instance still cannot selected high probability matterlarge margin (as g may arbitrarily large). However, using ideas generalmethodology Lipschitz optimization unknown constant (Jones et al., 1993),get around problem estimate, certain optimistic way, potentialperformance algorithm instance, round step promisingones.main idea resulting strategy summarized follows. AssumeK instances algorithm A, denoted A1 , . . . , AK . Let Xi,n , = 1, . . . , K denotelocation f evaluated Ai nth time take step, Xi,1starting point Ai . estimate location maximum algorithm Ai nsamples (steps)bi,n = argmax f (Xi,t )X1tnbi,n ).maximum value function estimated fi,n = f (Xi, let fi = limn fi,n denote limiting estimate maximum fprovided Ai . Let g defined Lemma 1 largest values,f = max fi .i=1,...,KSince f best achievable estimate maximum f given actual algorithmsA1 , . . . , AK , g gives high probability convergence rate algorithms providebest estimate maximum long run (note assumption dealslimiting estimate usually local maximum separately, is, assumptionmade algorithms whose limiting estimates less f ). Then, Ai evaluates fni,r points end rth round Ai converges best achievable estimatef , Lemma 1 have, probability least 1 ,fi fi,ni,r g (ni,r ),fi,ni,r + g (ni,r )413(2)fiGyorgy & Kocsisoptimistic estimate f . Ai suboptimal sense limn fi,n < festimate still optimistic rate convergence slower g ,pessimistic rate convergence slower g . latter desirable sensenegatively biased estimate expected performance algorithmwant use (we waste samples suboptimal choices).practice g usually known exactly, estimate (2) often cannot constructed. hand, g known constant factor constructfamily estimates scales: Let g denote normalized version gg (0) = 1 g (n)/g (n) constant n, construct family estimatesfi,ni,r + cg (ni,r )(3)c ranges positive reals. reasonable choose, round,algorithms take another step provide largest estimate values c(typically, algorithm gives largest estimate c = c intervalcontaining c algorithm provides largest estimate c I).way get around fact know real scaling factor g ,certainly use algorithms provide largest value (3) c = g (1)/g (1),and, discussed later, waste many samples algorithmsmaximize (3) values c. Using optimistic estimate (3) similar, spirit,optimistic estimates standard upper confidence bound-type solutionmulti-armed bandit problem (Auer, Cesa-Bianchi, & Fischer, 2002) well-knownsearch algorithm (Hart, Nilsson, & Raphael, 1968).However, exact (local) convergence rate known, even constant factor,many local search algorithms, even is, corresponding bounds usuallymeaningful asymptotic regime, often practical interest. Therefore,give freedom design algorithm, going use estimateformfi,ni,r + ch(ni,r )(4)where, similarly requirements g , h positive, monotone decreasing functionlimn h(n) = 0. also assume, without loss generality, h(0) = 1.actual form h based theoretical analysis resulting algorithmsheuristic considerations. Essentially use h functions converge zeroexponentially fast, agreement exponentially fast local convergence ratesexamples given Lemma 1. optimal choice h, given, example, g ,known, left future work.4.1 Constant Number Instancesidea translated algorithm MetaMax(K) shown Figure 1.consider case fixed number instances, goal perform(almost) well best (in hindsight), using minimum numberbrevaluations f . Note slight abuse notation MetaMax(K) algorithm Xfr denote estimates algorithm r rounds (and r steps/samples).first part step (a) MetaMax sweep positive c select localsearch algorithms maximize estimate (4). easy see, Ai maximizes414fiEfficient Multi-Start Strategies Local Search AlgorithmsMetaMax(K): multi-start strategy K algorithminstances.Parameters: K > 0 positive, monotone decreasing function hlimn h(n) = 0.Initialization: = 1, . . . , K, take step algorithm Aionce, let ni,0 = 1 fi,0 = f (Xi,1 ).round r = 1, 2, . . .(a) = 1, . . . , K select algorithm Ai exists c > 0fi,ni,r1 + ch(ni,r1 ) > fj,nj,r1 + ch(nj,r1 )(5)j = 1, . . . , K (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).several values selected step numberni,r1 keep one selected uniformly random.(b) Step selected Ai , update variables. is, set ni,r =ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.bi,nselected Ai evaluate f (Xi,ni,r ) compute new estimates Xi,rfi,ni,r .(c) Let Ir = argmaxi=1,...,K fi,ni,r denote index algorithmcurrently largest estimate f , estimate locationbr = XbIr ,nmaximum Xvalue fr = fIr ,nIr ,r .Ir ,rFigure 1: MetaMax(K) algorithm.(4) particular c = u closed interval containing u Ai alsomaximizes (4) c I. Therefore, round, strategy MetaMax(K) selectslocal search algorithms Ai corresponding point (h(ni,r1 ), fi,ni,r1 )corner upper convex hull setPr = {(h(nj,r1 ), fj,nj,r1 ) : j = 1, . . . , K} {(0, max fj,nj,r1 )}.1jK(6)selection mechanism illustrated Figure 2.avoid confusion, note random selection step (a) MetaMax(K) impliesalgorithms exactly state, is, (ni,r1 , fi,ni,r1 ) = (nj,r1 , fj,nj,r1 )i, j, one algorithm selected uniformly random (this pathological situationmay arise, e.g., beginning algorithm local search algorithms giveestimate f range step numbers). Apart case oneleast used algorithms provides currently best estimate, happens surelyfirst round usually happen later (and includes previous pathological case),guaranteed round use least two algorithms, one largest415fiGyorgy & Kocsis0.70.6f(x)0.50.40.30.20.100.20.30.40.5h(n)0.60.70.80.9Figure 2: Selecting algorithm instances MetaMax: points represent algorithminstances, algorithms lie corners upper convex hull(drawn blue lines) selected.estimate fi,ni,r1 = fr1 (for small values c), one smallest step numbernj,r1 (for large values c). Thus, usually half total number functioncalls f used optimal local search algorithm. observation gives practical lower bound (which valid apart pathological situation mentioned above)proportion function calls f made optimal local search algorithms; surprisingly,Theorem 6 shows lower bound achieved algorithm asymptotically.randomization step (a) precludes using multiple instancesstep number introduced speed algorithm certain pathological cases.example, A1 converges correct estimate, algorithms A2 , . . . , AKproduce estimate round, independently samples, inferiorestimates A1 , use randomization, half calls compute fmade A1 , without randomization would drop 1/Kround would use algorithm. Furthermore, could take step algorithmslie convex hull, similar pathological examples constructedbeneficial use algorithms corners. hand, almost neverhappens practice three algorithms lie line, algorithms typicallynever fall non-corner points convex hull.remainder section analyze performance MetaMax(K)algorithm. Proposition 2 shows algorithm consistent sense performance asymptotically achieves best algorithm instance number roundsincreases. understand algorithm better, Lemma 3 provides general sufficient condition algorithm instance advanced given round, while, basedresult, Lemma 4 provides conditions ensure suboptimal algorithm instancesused round stepped many times (i.e., evaluated fmany points) before. Lemma 5 gives upper bound number algorithm416fiEfficient Multi-Start Strategies Local Search Algorithmsinstances used round. results lemmas used show Theorems 68 Remark 9 optimal algorithm instances used (asymptotically) leastminimum frequency that, turn, yields asymptotic rate convergenceMetaMax(K) algorithm.following proposition shows MetaMax(K) algorithm consistentsense:Proposition 2 MetaMax(K) algorithm consistent sense fr fr,nf lim fi,n .f lim fr = minri=1,...,KnProof proof follows trivially fact algorithm selected infinitelyoften, is, limr ni,r = . see latter, show every K roundsnumber steps taken least used algorithm, is, mini=1,...,K ni,r , guaranteedincrease one. is, k 0,min ni,kK k.i=1,...,K(7)described above, round select exactly one algorithms madeleast number steps. Thus, K algorithms, minimum step numberper algorithm increase K rounds, completes proof.2MetaMax(K) algorithm efficient suboptimal algorithms stepoften. next lemma provides sufficient conditions algorithm usedgiven round.Lemma 3 algorithm instance Aj used round r + 1 MetaMax(K)algorithm, algorithms Ai Ak fi,ni,r > fj,nj,r > fk,nk,r eitherni,r nj,rh(nj,r )h(nj,r )fj,nj,r fi,ni,r 1(8)+ fk,nk,rh(nk,r )h(nk,r )Proof round algorithms corners convex hull Pr+1 used,easy see algorithm Aj used round r algorithms AiAk fi,ni,r > fj,nj,r > fk,nk,r either ni,r nj,rfi,ni,r fk,nk,rfi,ni,r fj,nj,r.h(nj,r ) h(ni,r )h(nk,r ) h(ni,r )(9)finish proof show (8) implies latter. Indeed, (9) equivalenth(nk,r )(fi,ni,r fj,nj,r ) h(nj,r )(fi,ni,r fk,nk,r ) + h(ni,r )(fk,nk,r fj,nj,r ).last term right hand side inequality negative assumptions,inequality satisfiedh(nk,r )(fi,ni,r fj,nj,r ) h(nj,r )(fi,ni,r fk,nk,r )417fiGyorgy & Kocsisequivalent (8).2lemma provides conditions using algorithm instances certainround depend actual performance instances. next result gives similarconditions, however, based best estimates (usually local optima) achievablealgorithms. Let fi = limr fi,ni,r asymptotic estimate algorithm Ai f ,let f = max1iK fi denote best estimate achievable using algorithms A1 , . . . , AK .Let {1, . . . , K} set optimal algorithms converge best estimatef (for algorithms), let |O| denote cardinality (i.e., numberoptimal algorithm instances). Note random variable depends actualrealizations possibly randomized search sequences algorithms. next lemmashows j 6 O, Aj used round r used often far.Lemma 4 Let= f max fjj6Odenote margin estimates best second best algorithms.0 < u < random index R(u) > 0 j 6 O, Ajused MetaMax(K) round r + 1 > R(u)!!fjmin ni,r1nj,r h1 h.(10)i=1,...,Kf uFurthermore, let 0 < < 1, O, let g,i denote convergence rate algorithmAi guaranteed Lemma 1, let g (n) = maxiO g,i (n) n. P (R(u)) 1 (where g 1 generalized inverse g ), suboptimalKg1 (u)|f1 , . . . , fKalgorithm Aj , j 6 O, used r > Kg1 (u) probability least 1 |O| given.limiting estimates f1 , . . . , fKProof Let O. Since limn fi,n = fi = f assumption (7) implies(u)limr ni,r = , almost surely finite random index Ri > 0(u)r > Ri f fi,nui,rf fr u.(11)Using Lemma 1 easily derive high probability upper bound R(u) . Sincer > Kg1 (u) = R , (7) implies ni,r g1 (u), Lemma 1 yieldsfiP fi fi,ni,r u r > R fi fi = f 1 .follows probability least 1 |O| fi fi,ni,r u,) |O| . Thus,implies R(u) chosen P (R(u) > R |f1 , . . . , fKprove lemma, enough show (10).Clearly, (11), algorithm pick estimate one best algorithmsR(u) rounds. Let Ak algorithm least number steps taken end418fiEfficient Multi-Start Strategies Local Search Algorithmsround r, is, nk,r = mini ni,r . fk,nk,r fj,nj,r Aj used round r + 1.Moreover, since Aj 6 O, fj,nj,r fj < fr case Aj used round r + 1nj,r nIr ,r (recall nIr ,r number evaluations f initiated actuallybest algorithm Ir ). Therefore, Lemma 3 implies Aj used r > R()!fj,nj,r fk,nk,rh(nj,r ) h(nk,r ) 1.fr fk,nk,rclearly satisfiedh(nj,r ) h(min ni,r ) 1fjf u!(12)0 < u < , since (11)1fjfj,nj,r fk,nk,rfj,nj,r1.1fr fk,nk,rfrf uApplying inverse h sides (12) proves (10), and, hence, lemma.2result provides individual condition suboptimal algorithmused round. hand, one optimal algorithmsstepped sufficiently many times, give cumulative upper bound numbersuboptimal algorithms used round.Lemma 5 Assume h decreases asymptotically least exponentially fast, is,exist 0 < < 1 n > 0 h(n+1)h(n) < n > n . Assume r largeenough ni,r > n i, let r = 1 maxi:fi,n6=fri,rfi,ni,rfr> 0.rlnln + 1 algorithms stepped round r + 1, x denotes smallest integerleast large x.Proof Let i0 , i1 , . . . , im denote indices algorithms chosen round r + 1fi0 ,r < fi1 ,r < < fim ,r = fr . Lemma 3 implies ni0 ,r < ni1 ,r < < nim ,rfr fik ,r < (fr fik1 ,r )k = 1, . . . , 1. Repeated application inequality impliesfr r fr fim1 ,r < (fr fim2 ,r ) < < m1 (fr fi0 ,r ) fr m1yieldsln rlnassumed + 1 algorithms chosen round r + 1, fact finishesproof.2m1<419fiGyorgy & KocsisBased Lemmas 4 5, next theorem shows local search algorithmconverges fast enough (exponentially problem dependent rate, faster exponential) half function calls evaluate f correspond optimal algorithminstances.Theorem 6 Assume performance algorithms Ai , = 1, . . . , Ksame, is, |O| < K, suppose()fjh(n + 1)lim sup.(13)< min 1j6Oh(n)nfasymptotically least half functionrespond optimal algorithm. is,Pni,r1P lim inf PiOKr2i=1 ni,rcalls evaluate f MetaMax(K) cor!fififi f1 , . . . , fK= 1.fiFurthermore, 0 < < 1 > 0 constant R(,) > 0$P%!Kni=1 i,rf fr g(2 + )|O|(14)(15)simultaneously r > R(,) ,probability least 1 |O| given f1 , . . . , fK(,)g defined Lemma 4, threshold R> 0 depends , , h, g1 ,1g also defined Lemma 4.Proof show suboptimal Aj chosen large enough r nj,r > mink nk,r .Lemma 4, sufficient prove that, large enough r,!!fj1(16)min nk,r + 1 hh(min nk,r ) 1kkf u0 < u < (recall r larger R(u) , almost surely finiterandom index Lemma 4).minimum (13) taken finite set, follows exists smallenough positive u <()fjh(n + 1)lim sup,(17)min 1j6Oh(n)nf uclearly implies (16) limr mink nk,r = (7). fact finishes proof(14), first part theorem.Next prove (15). Let Nu > 0 threshold (17) holds n Nu .Furthermore, Lemma 1 union bound, (1) holds local search algorithmAi g,i place g simultaneously probability least 1 |O|.420fiEfficient Multi-Start Strategies Local Search Algorithms(7) slight modification Lemma 4 imply (16) holds simultaneously.r > K max{g1 (u), Nu } = R probability least 1 |O| given f1 , . . . , fKSinceround two algorithms used, r > R + cPni,rc+RPiO> 2c+KRhigh probability. Since latter bounded 1/(2+)Kni,ri=1PKPni,rc R (K2)/, iO ni,r i=1r > R(,) = R +R (K2)/2+l P highmprobability. algorithm Ai , used leastKi=1ni,r|O|(2+)rounds, implying statement theorem via Lemma 1.2Remark 7 proof Theorem 6 based Lemma 4. proof based Lemma 5also possible, since setting = minj6O (1 fj /f ) lemma, (13) implies that,large enough r, r , round approximately length 2 lemma.may happen although decay rate h exponential, quite fastenough satisfy (13), optimal scenarios theorem hold.case turns number algorithms converging local maximumplays key role determining usage frequency optimal algorithms.Theorem 8 Assume estimates provided algorithms A1 , . . . , AK convergeN > 1 distinct limit points, k0 = |O| algorithms converge f , k1 , k2 , . . . , kN 1algorithms converge suboptimal limit points, respectively. Suppose furthermoreh decreases asymptotically least exponentially fast, is, 0 < < 1,lim supn h(n+1)h(n) < .P lim infrPiO ni,rPKi=1 ni,r!fifikmaxfi f , . . . , fK = 1.K k0 + kmax fi 1kmax = max1iN 1 ki .Furthermore, using definitions Lemma 4 0 < < 1 > 0constant threshold R(,)%!$PKknmaxi=1 i,rf fr cg(K k0 + kmax + )|O|simultaneously r > R(,) ,probability least 1 |O| given f1 , . . . , fKR(,) depends , .,f1 , . . . , sfK convergence rate algorithms4 .given, fix random trajectories algorithms.Proof Suppose f1 , . . . , fKsingle suboptimal algorithm statement trivial kmax /(K k0 +kmax ) =1/2 round least two algorithms used, onesuboptimal one. assume least two suboptimal algorithms.Assume Aj Ak converge suboptimal local maxima (strictly less f ).r large enough, optimal algorithm Ai better suboptimal ones,4. Instead convergence rate algorithms, R(,) may defined dependent g .421fiGyorgy & Kocsisis, Ai converges f fi,ni,r > fj,nj,r , fk,nk,r . Assume, without loss generality,fj,nj,r fk,nk,r . nj,r nk,r clearly Aj chosen round r + 1. Assumenj,r > nk,r . Since fj,nj,r fk,nk,r convergent sequences (as r ), large enoughr have, j,k < 1,1fj,nj,r fk,nk,r> j,k tj,kfi,n fk,ni,r(18)k,rtj,k = ln j,k / ln positive integer. Note Aj Ak convergepoint, is, limr (fj,nj,r fk,nk,r ) = 0, second term left hand side(18) converges 0, j,k chosen , implying tj,k = 1. Rearranginginequality one obtains(1 tj,k )fi,ni,r + tj,k fk,nk,r > fj,nj,r .(19)nj nk tj,k , conditions h fact nj,r nk,r tendinfinity r (recall (7)) imply that, large enough r, h(nj,r )/h(nk,r ) < tj,k . Sincefi,ni,r fk,nk,r large enough r, (19) obtainh(nj,r )h(nj,r )tj,ktj,kfk,nk,r .fi,ni,r +fj,nj,r < (1 )fi,ni,r + fk,nk,r 1h(nk,r )h(nk,r )Thus, Lemma 3, r large enough, Aj cannot used round r + 1 nj,r nk,r tj,k .Since nj,r nk,r tend infinity, follows that, large enough r,|nj,r nk,r | tj,k(20)two suboptimal algorithms Aj Ak . Note fact also impliesset suboptimal algorithms converging point, eventually oneused round (since corresponding thresholds tj,k = 1).Clearly, (7) implies nj,r nk,r grow linearly r, since differences bounded (20), limr nj,r /nk,r = 1. Therefore, suboptimal algorithmAj , limn nj,r /r 1/kmax (this maximal rate using elementslargest group suboptimal algorithms converging local optimum). Finally,optimal algorithm used round r, large enough r,PPiO ni,riO ni,rPlim inf PK= lim inf Prrn+i,rni6O ni,riOi,ri=1kmaxrlim=,rr r + (K k0 )K k0 + kmaxkmaxused fact a/(a + b) increasing function a, b > 0. Since,inequality holds realizations trajectories A1 , . . . , AK , given f1 , . . . , fKfirst statement theorem follows.second statement follows similarly (15) Theorem 6. Since exact valueR(,) particular interest, derivation omitted.2422fiEfficient Multi-Start Strategies Local Search AlgorithmsRemark 9 main message theorem somewhat surprising observationsuboptimal algorithms slowed large group suboptimal algorithmsconverging local optimum; rate suboptimal algorithms used boundedsize largest group.4.2 Unbounded Number Instancesclear local search algorithms consistent (i.e., achieveglobal optimum f ), then, despite favorable properties, MetaMax(K) strategyinconsistent, too. However, increase number algorithms infinityget consistency random search, still keeping reasonably fast convergencerate MetaMax(K).Clearly, one needs balance exploration exploitation, is,control often introduce new algorithm. One solution let MetaMaxalgorithm solve problem: MetaMax() algorithm, given Figure 3, extension MetaMax(K) able run infinitely many local search algorithminstances. major issue new local search algorithms startedtime time (this ensures algorithm converge global maximum fsince also performs random search): implemented modifying step (a)MetaMax(K) algorithm new, randomly initialized local search algorithm introduced round (randomly selecting one algorithm uniformly infinitelymany possible algorithms used far). Obviously, skip initializationstep MetaMax(K) start algorithm 0 samples. better controllength round (i.e., exploration), round r allow use differentfunction h, denoted hr1 may depend value measured round r (thissuppressed notation). before, assume hr (0) = 1, hr (n) monotone decreasing n, limn hr (n) = 0 r. Typically make hr1 dependentPKr1total number steps (i.e., function calls evaluate f ) tr1 = i=1ni,r1 madealgorithms round r, Kr1 number algorithm instances usedround r; note Kr1 = r 1 r, start exactly one new algorithmround.desired that, although number local search algorithms grows infinity,number times best local search algorithm advanced MetaMax()algorithm approaches infinity reasonably fast. Somewhat relaxing random initializationcondition, may imagine situation local search algorithms initializedclever, deterministic way, first steps find bettervalue initial guesses. algorithms optimal (this may viewed resultclever initialization), may provide, example, identical estimates0.5, 0.5, 1 first three steps. easy see algorithm steppedexactly twice, thus convergence optimum (which would found thirdstep) achieved. Although random initialization search algorithms guaranteesconsistency MetaMax() (see Proposition 10 below), robust behavior evenpathological cases preferred.achieved slight modification algorithm: round local searchalgorithm overtakes currently best algorithm, is, Ir 6= Ir1 , algorithm AIr423fiGyorgy & KocsisMetaMax(): multi-start strategy infinitely manyalgorithm instances.Parameters: {hr }, set positive, monotone decreasing functionslimn hr (n) = 0.round r = 1, 2, . . .(a) Initialize algorithm Ar setting nr,r1 = 0, fr,0 = 0.(b) = 1, . . . , r select algorithm Ai exists c > 0fi,ni,r1 + chr1 (ni,r1 ) > fj,nj,r1 + chr1 (nj,r1 )j = 1, . . . , r (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).several values selected step numberni,r1 keep one selected uniformly random.(c) Step selected Ai , update variables. is, set ni,r =ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.bi,nselected Ai evaluate f (Xi,ni,r ) compute new estimates Xi,rfi,ni,r .(d) Let Ir = argmaxi=1,...,r fi,ni,r denote index algorithmcurrently largest estimate f , estimate locationbr = XbIr ,nmaximum Xvalue fr = fIr ,nIr ,r .Ir ,rFigure 3: MetaMax() algorithm.stepped several times used times AIr1 .5 resulting algorithm,called MetaMax, given Figure 4. Note algorithms MetaMax()MetaMax conceptually differ one place: step (c) extended step (c)new algorithm. result, technical modification also appears step (d), and,simplify presentation MetaMax algorithm, slight, insignificant modificationalso introduced step (b), see discussion below.modification MetaMax really significant practical examplesstudied (see Section 5), number steps taken algorithm overtakescurrently best algorithm grows quickly also MetaMax() algorithm, sinceMetaMax overtake usually introduces short rounds (close minimum lengthtwo many cases) leading algorithm becomes also used one. goalmodification step (b) synchronize choice optimal algorithmssteps (b) (c). equally good solution would choose, case tie step5. way achieve actually best algorithm dominates others terms accuracynumber calls made algorithms compute target function. typedominance used Hutter et al. (2009) slightly different context.424fiEfficient Multi-Start Strategies Local Search AlgorithmsMetaMax: multi-start strategy infinitely manyalgorithm instances.Parameters: {hr }, set positive, monotone decreasing functionslimn hr (n) = 0.round r = 1, 2, . . .(a) Initialize algorithm Ar setting nr,r1 = 0, fr,0 = 0.(b) = 1, . . . , r select algorithm Ai exists c > 0fi,ni,r1 + chr1 (ni,r1 ) > fj,nj,r1 + chr1 (nj,r1 )j = 1, . . . , r (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).several values selected step numberni,r1 keep one smallest index.(c) Step selected Ai , update variables. is, set ni,r =ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.bi,nselected Ai evaluate f (Xi,ni,r ) compute new estimates Xi,rfi,ni,r .(c) Let Ir = argmaxi=1,...,r fi,ni,r denote index algorithmcurrently largest estimate f (in case Ir unique, chooseone smallest number steps ni,r ). Ir 6= Ir1 , stepalgorithm AIr (nIr1 ,r nIr ,r + 1) times set nIr ,r = nIr1 ,r + 1.br = XbIr ,n(d) Estimate location maximum XIr ,rvalue fr = fIr ,nIr ,r .Figure 4: MetaMax algorithm.(c), algorithm used current round. Also note that, resultmodifications, currently best algorithm (with index Ir ) taken steps,extra number steps taken step (c) indeed positive. important consequencemodifications that, round r, number steps taken local searchalgorithm AIr , best end round, r 2r (see Theorem 15below).rest section devoted theoretical analysis MetaMax()MetaMax, following lines analysis provided MetaMax(K). First, Proposition 10, shown algorithm consistent, is, solution foundalgorithm actually converges f . Lemma 12 (a counterpart Lemma 4) showssuboptimal algorithms make finitely many steps, Lemma 14 gives upperbound length round. main theoretical results section apply425fiGyorgy & KocsisMetaMax algorithm: Theorem 15 gives lower bound number steps takenactually best algorithm end given round, while, consequence, Theorem 16 shows rate convergence algorithm function total numbersteps (i.e., function calls evaluate f ) used algorithm instances: turnsquadratically steps needed generic local search algorithm instanceconverges optimum.Since MetaMax() MetaMax strategies perform random search (thenumber algorithms tends infinity length round finite), algorithmsconsistent:Proposition 10 strategies MetaMax() MetaMax consistent.is,lim fr = fralmost surely.Proof Clearly, event fr converge f writtenn\n[[lim fr 6= f =fr < f 1/nr(21)n=1 R=1 r=Rcontinuity f implies that, n, X chosen uniformly [0, 1]dqn P= P(f (X) > f 1/n) > 0. Thus, round r, P(fr < f 1/n) (1 qn )r ,r=1 P(fr < f 1/n) finite. Therefore, Borel-Cantelli lemma (see, e.g., Ash &Doleans-Dade, 2000) implies!n[\=0Pfr < f 1/nR=1 r=Rn. This, together (21) finishes proof,Plim fr 6= frXn=1Pn[\R=1 r=Rfr < f 1/n!= 0.2reminder section assume local search algorithms achievealmost optimal value eventually converge optimum.Assumption 11 Let F R denote set local maxima f , let = fsupfF ,f<f f. assume > 0 algorithm Ai fi,n > fn, limn fi,n = f .local search algorithms converge local optima (which reasonable assumptionpractice), assumption usually satisfied: situationhold pathological case f infinitely many local maxima setmaxima dense global maximum.426fiEfficient Multi-Start Strategies Local Search AlgorithmsAssumption 11 prove, similarly Lemma 4, suboptimal algorithm selected limited number times increases h1r . particular,hr = h r large enough, suboptimal algorithm chosen finitely manytimes.Lemma 12 Suppose Assumption 11, let q = P(f (X) > f /2) X uniformlydistributed [0, 1]d . Then, MetaMax() MetaMax algorithms,suboptimal algorithm Aj started round r +1 used round r +1, probabilityleast 1 (1 q)r ,1nj,r hr.2faddition, hr (n) non-decreasing function r n,lim suprh1r1nj,r2f<almost surely.(22)particular, hr constant function, is, hr = h0 r, limr nj,r <almost surely.Remark 13 Note secondpart lemma coulddropmonotonicity11assumption hr replace hr1 2f max0r r1 hr 2f (22).Proof Consider algorithm Aj used round r + 1. First note probabilityleast 1 (1 q)r , fr > f /2. Furthermore, newly introduced algorithm, Ar+1used yet, nr+1,r = 0 fr+1,0 = 0. Thus, Lemma 3, Aj usedh(nj,r )= fr (1 hr (nj,r )) .fj,nj,r fr 1hr (0)Since equivalentnj,rh1rfj,nj,r1frh1rfj,nj,r1fr!h1r!,2ffr fj,nj,rfr (f )(f /2) (f )=,(23)>f /22ffrfrfirst statement proof follows.b denote first round optimalprove second part, let Ralgorithm Ai fi,ni,Rb > f /2. suboptimal algorithm Aj , first partblemma implies that, r > R,11bb+ 1 = max R, hr1+1nj,r max R, maxh0r r1 r2f2f427fiGyorgy & Kocsisequality holds since h1r (n) non-decreasing r. Thusbnj,rR1lim sup max, 1 +lim suph1r h1rh1r1 2fr1 2fr1 2fb1R, 1 +maxh1h1002f(24)2fb finite, (24) also finiteused h1non-decreasing r. Since Rrprobability 1.2simple modification Lemma 5 implies /2-optimal sample pointfound limited number suboptimal algorithms chosen round.Lemma 14 Consider algorithms MetaMax() MetaMax. Suppose Assumption 11holds, assume f fR < /2 R > 0. anyround r > R, hr (n) = rn0 < r < 1 n 0,ln 2fln(1/r )algorithms chosenestimates fj f .Proof proof follows Lemma 5 taking account suboptimal algorithmAj satisfies fj f least one optimal algorithm chosen roundr > R: Similarly (23), r defined Lemma 5 bounded r > /(2f ),l2flnln(1/r )number suboptimal algorithms used round r bounded ln(1/.ln(1/r)r)2Finally derive convergence rate algorithm MetaMax. First boundnumber steps taken currently best algorithm, terms numberrounds total number steps taken local search algorithms.Theorem 15 Consider MetaMax algorithm. end round r numbersteps taken currently best algorithm r 2r. is,r nIr ,r < 2r.(25)Furthermore, number calls nIr ,r evaluate f currentlybest algorithm AIrPrbounded function total number times tr = i=1 ni,r target function fevaluated local search instances2tr + 7 1nIr ,r.(26)2Proof first statement lemma simple, since round actuallybest algorithm takes one step overtaking, one two steps428fiEfficient Multi-Start Strategies Local Search Algorithmsovertaking. Indeed, round r 2, overtaking, is, Ir = Ir1 ,nIr ,r = nIr ,r1 + 1. Otherwise, Ir 6= Ir1 , nIr ,r = nIr1 ,r + 1, since0 nIr1 ,r nIr1 ,r1 1,1 nIr ,r nIr1 ,r1 2situations. Since first round clearly algorithm used takes 1 step,is, nI1 ,1 = 1, (25) follows.prove second part, notice round r, nIr1 ,r1 + 1 algorithmsstepped step (c) algorithm used taken stepscurrently best one. Also, step (c) extra samples used overtaking.case overtaking, AIr advanced step (c), well AIr1 ,nIr1 ,r1 + 1 extra steps taken AIr . Therefore,tr tr1 + 2nIr1 ,r1 + 2.Thus, since overtaking happens round 1, obtaintr 1 +rX2(nIs1 ,s1 + 1).s=2Then, (25)tr 1 + 4rXs=2= 1 + 2(r + 2)(r 1) 1 + 2(nIr ,r + 2)(nIr ,r 1)yields (26).2Note proof used crude estimate length usual round (withoutovertaking) relative to, example, Lemma 14. This, however, affects resultconstant factor long able bound number rounds numberextra steps taken overtaking happens, since effect overtakingsintroduces quadratic dependence proof (26). Experimental results Section 5show (see Figure 10) number algorithm instances (which turn number rrounds) usual growth rate (tr / ln tr ), which, taken account, may sharpenbound often best algorithm chosen.Assumption 11, random search component MetaMax implies eventually optimal algorithm best. point convergencerate optimal local search algorithms determine performance search,number steps taken best local search algorithm bounded Theorem 15.Theorem 16 Suppose Assumption 11 holds. almost surely finite randomindex R rounds r > R, estimate fr MetaMax algorithmtotal number steps tr taken local search algorithms end round rsatisfies2t+71rf fr g2probability least 1 , g defined Lemma 1 global maximum f .429fiGyorgy & KocsisRemark 17 (i) value R bounded high probability using propertiesuniform random search actual problem; would yield similar boundsTheorems 6 8 MetaMax(K) algorithm. (ii) Note exploration-exploitationtrade-off MetaMax algorithm: value R potentially decreased introducenew algorithms often, nIr ,r reduced time. (iii) Theorems 15 16imply that, asymptotically, MetaMax algorithm needs quadratically functionevaluations local search algorithmPsthat ensured converge optimum.particular, f form f (x) =i=1 fi (x)ISi (x) Si form partition[0, 1]d , ISi denotes indicator function Si , fi belong nicely behavingfunction class local search algorithm started Si converges maximumfi Si (e.g., f piecewise concave function exponential convergence rateSPSA algorithm, used sufficiently small step size), preserveperformance local search algorithm original function class priceasymptotically quadratic increase number function calls evaluate f (i.e.,total number steps taken local search algorithm instances).4.3 Discussion Resultssense theoretical results presented previous sections weak.consistency result MetaMax(K) algorithm follows easily factlocal search algorithm used infinitely many times, consistency MetaMax()MetaMax follows consistency random search. performance boundsprovided disadvantage asymptotic sense holdpossibly large number rounds (a weakness bounds minimum numberrounds obtained properties uniform random search/sampling particularproblem, neglecting attractive properties algorithms). fact, quite easyconstruct scheduling strategies consistent asymptotically arbitrarilylarge fraction function evaluations (even almost all) used optimal local searchalgorithms: explore-and-exploit algorithms achieve goals numberfunction evaluations used known ahead use arbitrarily small fractionevaluations target function f exploration. compare performancealgorithms explore-and-exploit algorithms Section 5. particular, matchperformance guarantees MetaMax family, use algorithms spend halftime exploration half exploitation, exploration partuniform allocation strategy used finite number local search algorithms,schedule Luby et al. (1993) used infinitely many local search algorithms.Although theoretical guarantees proved paper MetaMax family also holdexplore-and-exploit algorithms, experiments MetaMax family seemsbehave superior compared algorithms, expected.theoretical results also give sufficient guidance chose parameterh hr (the time-varying version h considered MetaMax(K) algorithmsimplicity ease presentation). results require sufficiently fastexponential decay h, problem dependent cannot determined advance.sufficiently fast decay rate would ensure, example, MetaMax(K) algorithmcould always use stronger results Theorem 6 would never deal430fiEfficient Multi-Start Strategies Local Search Algorithmscase bound Theorem 8 holds. One may easily choose hfunction decreases super-exponentially: would make asymptotic bounds work,however, would slow exploration (in extreme case hr (n) 0, excludedconditions, exploration would performed, algorithms would useactually best local search algorithm). practice always foundappropriate chose hr decay exponentially. Furthermore, found eveneffective gradually decrease decay rate enhance exploration time elapses (therationale behind approach assumption good algorithmsless converged while, may greater potential explorationimprove estimates). Finally, connection g hinvestigated.Keeping limitations theoretical results mind, still believetheoretical analyses given provide important insight algorithms may guidepotential user practical applications, especially since properties MetaMaxfamily proved asymptotic regime (e.g., rounds quite short)usually observed practice, well. Furthermore, think possibleimprove analysis bound thresholds results become validreasonable values, would require different approach and, therefore, leftfuture work.5. Experimentsvariants MetaMax algorithm tested synthetic real examples. Sincenegligible difference performance MetaMax() MetaMax,6following present results MetaMax(K) MetaMax. First demonstrate performance algorithm optimizing synthetic function (using SPSAlocal search algorithm). Next behavior algorithm tested standard datasets. show MetaMax applied tuning parameters machine learningalgorithms: classification task solved neural network, parameterstraining algorithm (back-propagation) fine-tuned MetaMax combined SPSA.MetaMax also applied boost performance k-means clustering. endsection, compare results experiments theoretical bounds obtainedSection 4.2.experiments, accordance simplifying assumptions introducedSection 3, main difference individual runs particular local searchalgorithm starting point. Obviously, general diversification techniques exist:example, parameters local search algorithm could also vary instanceinstance (including running instances different local search algorithms, parameter would select actually employed search algorithm), initialization (startingpoint parametrization) new instance could also depend results delivered6. example, relative difference average error eMetaMax() MetaMax()eMetaMax MetaMax optimizing parameters multi-layer perceptron learning letterdata set (see Section 5.1 especially Figure 6, right details) 0.033 standarddeviation 0.06 (averaged1000 experiments), relative difference definedfififieMetaMax() eMetaMax fi / max(eMetaMax() , eMetaMax ).431fiGyorgy & Kocsisexisting instances. Although MetaMax strategies could also appliedgeneral scenarios, behavior better studied simpler scenario; hence,experiments correspond setup.5.1 Optimizing Parameters SPSAsection compare two versions MetaMax algorithm six multi-startstrategies, including three constant three variable number algorithminstances. strategies run fixed time steps, is, target functionevaluated times, together local search instances (note several referencestrategies use parameter).used SPSA (Simultaneous Perturbation Stochastic Approximation; Spall, 1992)base local search algorithm cases. SPSA local search algorithm samplingfunction uses gradient descent stochastic approximation derivative:actual location Xt = (Xt,1 , . . . , Xt,d ), SPSA estimates lth partial derivative ff (Xt + Bt ) f (Xt Bt ),ft,l (Xt,l ) =2t Bt,lBt,l i.i.d. Bernoulli random variables components vectorBt , uses sampling function st (Xt ) = Xt + ft (Xt ) choose next pointsampled, is,Xt+1,l = Xt,l + ft,l (Xt,l )l = 1, . . . , (t scalar parameters).implementation algorithm followed guidelines provided(Spall, 1998), gain sequence = a/(A + + 1) , perturbation size =/(t + 1) , = 60, = 0.602 = 0.101. values varydifferent experiments; chosen heuristically based experience similarproblems (this cause problem here, goal experimentsprovide fast solutions global optimization problems hand demonstratebehavior multi-start algorithms compared). addition two evaluationsrequired perturbed points, also evaluate function current point Xt .starting point chosen randomly, function evaluated first point.six reference algorithms MetaMax(K) MetaMax algorithms compared following:Unif: algorithm selects constant number instances SPSA uniformly.implementation instance = mod K selected time t, K denotesnumber instances.ThrAsc: Threshold Ascent algorithm Streeter Smith (2006b). algorithm begins selecting fixed number instances once. phasetime step ThrAsc selects best estimates produced far algorithminstances Ai , = 1, . . . , K previous time steps, Ai countsmany estimates produced Ai . Denoting latter value Si,t , timealgorithm selects instance index = argmaxi U (Si,t /ni,t , ni,t ), ni,t432fiEfficient Multi-Start Strategies Local Search Algorithmsnumber times ith instance selected time t,U (, n) = ++p2n + 2n= ln(2T K/). parameters algorithm, experimentsbest value appeared 100, set 0.01. note ThresholdAscent developed maximum K-armed bandit problem; nevertheless,provides sufficiently good performance setup test experiments.Rand: random search algorithm. seen running sequence SPSAalgorithms instance used exactly one step, evaluationrandom starting point SPSA algorithm.Luby: algorithm based work Luby et al. (1993). method runs severalinstances SPSA sequentially other, ith instance run ti steps,ti defined2k1 ,= 2k 1ti =ti2k1 +1 ,2k1 < 2k 1definition produces schedule first 2k 1 algorithm instancesone run 2k1 steps, two 2k2 steps, four 2k3 steps, on.EE-Unif: algorithm instance explore-and-exploit algorithms. first/2 steps Unif algorithm used exploration, and, subsequently, explorationphase, SPSA instance achieved highest value exploration phaseselected.EE-Luby: algorithm similar EE-Unif, except Luby used exploration.versions MetaMax algorithm tested. Motivated fact SPSAknown converge global optimum exponentially fast f satisfies restrictiveconditions (Gerencser & Vago, 2001), chose hr (n) decays exponentially fast.control exploration far suboptimal algorithm instances, allowed hr (n)time-varying function, is, changes tr , total number function callsevaluate f (or equally, total number steps taken) algorithms far. Thus,round r + 1 usedhr (n) = en/tr(27)(note used time-varying version hr also case MetaMax(K)latter easily extended situation, omitted simplifypresentation).algorithms fixed number local search instances (MetaMax(K), Unif,EE-Unif, ThrAsc), number instances K set 100 simulations,choice provided reasonably good performance problems analyzed.multi-start algorithms tested using two versions synthetic function,tuning parameters learning algorithm two standard data sets.433fiGyorgy & Kocsissynthetic function slightly modified7 version Griewank function (Griewank,1981):2xl X 4 2 x2lcosf (x) =100ll=1l=1x = (x1 , . . . , xd ) xl constrained interval [1, 1]. showresults 2-dimensional 10-dimensional cases.parameters SPSA = 0.05 = 0.1 2-dimensional case,= 0.5 = 0.1 10-dimensional case. performance search algorithmsmeasured error defined difference maximum valuefunction (in case 1) best result obtained search algorithm givennumber steps. results multi-start strategies two- 10dimensional test functions shown Figure 5. error curve averaged 10,000runs, strategy run 100,000 steps (or iterations). One may observecases two versions MetaMax algorithm converge fastest. ThrAscbetter Unif, Luby seems fairly competitive two. two exploreand-exploit-type algorithms (EE-Unif EE-Luby) similar performance 2dimensional function, clearly better non-exploiting base algorithms,10-dimensional function behavior somewhat pathological sense lowvalues performances best among algorithms, increasing ,error actually increases respective base algorithms achieve smaller errorsvalues . random search seems option 2-dimensional function.Similar results obtained dimensions 2 10. pathological behaviorexplore-and-exploit algorithms start appear gradually starting 5-dimensionalfunction, pronounced 8 dimensions onwards. Limited experimental dataobtained higher dimensions 100 (averaged hundred runs) showssuperiority MetaMax preserved high-dimensional problems well.reason pathological behavior explore-and-exploit strategies (i.e.,error curves monotone decreasing number iterations) illustratedfollows. Assume two SPSA instances, one converging global optimumanother one converging suboptimal local optimum. Assume firststeps optimal algorithm gives better result, suboptimal algorithm takesreaches local maximum, algorithms run even further, optimalalgorithm beats suboptimal one. exploration stopped first lastregime, explore-and-exploit algorithm choose first, optimal local search instance,whose performance may get quite close global optimum exploitation phase(even stopped first regime). exploration stopped middle regime,suboptimal search instance selected exploitation, whose performance mayeven get close global optimum. scenario, error exploitationphase (i.e. end) lower small, increases higher values . Decreaseerror increasing assured optimal instance convergesexploration phase past suboptimal local optima, results selecting optimallocal search instance exploitation. scenario error decrease fast7. modification made order significant differences values functionglobal maximum local maxima.434fi1010110.10.1average erroraverage errorEfficient Multi-Start Strategies Local Search Algorithms0.010.0010.00010.0010.0001RandLubyUnifThrAscEE-LubyEE-UnifMetaMax100MetaMax1e-051e-060.011RandLubyUnifThrAscEE-LubyEE-UnifMetaMax100MetaMax1e-05101001000100001e-06100000110iteration100100010000100000iterationFigure 5: average error multi-start strategies 2-dimensional (left)10-dimensional (right) modified Griewank function. 99% confidence intervalsshown color corresponding curves. Noteintervals small.10.10.010.01average erroraverage error0.10.0010.0001RandLubyUnifThrAscEE-LubyEE-UnifMetaMax100MetaMax1e-051e-0610.0010.0001RandLubyUnifThrAscEE-LubyEE-UnifMetaMax100MetaMax1e-0510100100010000100000iteration1e-06110100100010000100000iterationFigure 6: average error multi-start strategies tuning parameters Multilayer Perceptron vehicle data set (left) letter data set (right).99% confidence intervals also shown color correspondingcurves.initially, increase may decrease till converges 0,quite similar observe Figure 5, right. pathological behaviorbecomes transparent many local search algorithms, lengthexploitation phase scales number local search instances lengthexploration instance kept fixed. Analyzing experimental data showscomplex versions scenario outlined occurred simulationsmain cause observed pathological behavior (the non-monotonicity errorcurves).tuning parameters learning algorithm, used two standard datasets UCI Machine Learning Repository (Asuncion & Newman, 2007): vehicle435fiGyorgy & Kocsisletter, Multilayer Perceptron learning algorithm Weka (Witten & Frank, 2005)(here back-propagation algorithm used training phase). Two parameterstuned: learning rate momentum, range [0, 1]. sizehidden layer Multilayer Perceptron set 8, number epochs100. parameters SPSA algorithm = 0.5 = 0.1,10-dimensional Griewank function (as previous experiment, parameterschosen based experience). rate correctly classified items test setvehicle using Multilayer Perceptron varying values two parameters shownFigure 7, highest rate 0.910112. Similarly, classification rate lettershown Figure 8, highest rate 0.7505.error rates optimized Multilayer Perceptron data sets vehicleletter shown Figure 6, parameters learning algorithm tunedmulti-start strategies above. error cases differencebest classification rate obtained (0.910112 0.7505, respectively)best classification rate obtained multi-start strategies given number steps.results shown averaged 1,000 runs. observe MetaMax algorithm(with increasing number algorithm instances) converged fastest average, threestrategies fixed number algorithm instances nearly identical results, Luby(and explore-and-exploit variant) slightly worse these, random searchslowest, although performed nearly badly synthetic functions.reason random search relatively better performance (relativeused SPSA) could twofold: (i) large parts error surface offer fairly small error,(ii) error surface less smooth, therefore SPSA less successful usinggradient information. explore-and-exploit variants performed well vehicle dataset initially, performance worsened larger values (compared MetaMax,algorithms extent). This, coupled observation Figure 5,right would suggest explore-and-exploit variants competitive small values, despite asymptotic guarantees.summary, MetaMax algorithm (with increasing number algorithm instances) provided far best performance tests, usually requiring significantlyfewer steps find optimum algorithms. E.g., letter data setMetaMax algorithm found global optimum runs 100,000 time steps.conclude MetaMax converged faster multi-start strategies investigated four test cases, notable advantage difficult surfaces (at leastgradient-based optimization viewpoint) induced classification tasks.5.2 k-Means Clusteringsection consider problem partitioning set d-dimensional real vectorsxj Rd , j = 1, . . . , N clusters, cluster Si represented center (orreconstruction) point ci Rd , = 1, . . . , N . cost function minimized sumdistancesPN(x,Pci ) data points corresponding centers, is, wantminimize i=1 xSi (x, ci ). two necessary conditions optimality (see, e.g.,Linde, Buzo, & Gray, 1980; Gersho & Gray, 1992): = 1, . . . , N ,Si = {x : (x, ci ) (x, cj ) j = 1, . . . , N }436(28)fiEfficient Multi-Start Strategies Local Search AlgorithmsFigure 7: Classification rate vehicle data set. rates plotted subtracting0.911112 thus global optima scattered black spotscorresponding value equal 0.001.Figure 8: Classification rate letter data set. rates plotted subtracting 0.7515 thus global optima scattered black spotscorresponding value equal 0.001.(with ties broken arbitrarily)ci = argmincRdXxSi437(x, c).(29)fiGyorgy & KocsisPx8usual choice squared Euclidean distance, case ci = xS|Si | . According necessary conditions, k-means algorithm (or Generalized-Lloydalgorithm, see, e.g., Linde et al., 1980; Gersho & Gray, 1992) alternates partitioning data set according (28) centers fixed, recomputingcenters (29) partitioning kept fixed. easily seen cost(or error) cannot increase steps, hence algorithm convergeslocal minimum cost function. practice, algorithm stops (orinsufficient) decrease cost function. However, k-means algorithm often trappedlocal optimum, whose value influenced initial set centers. SPSA,restarting k-means different initialization may result finding global optimum.consider two initialization techniques: first, termed k-means, chooses centersuniformly random data points; second, k-means++ (Arthur & Vassilvitskii,2007) chooses initial center uniformly random data set, choosescenters data points probability proportional distancedata point closest center already selected.k-means algorithm usually terminates relatively small number steps,thus multi-start strategies bounded number instances would run active localsearch algorithms, therefore appear particularly attractive. However,natural domain consider strategy starts new instance, previousfinished. strategy referred subsequently Serial. mentionedconsiderations, test MetaMax, variant algorithms applicableunbounded number instances.9 experiments SPSA, used hr (27).Note theoretical results indicate k-means may converge exponentialrate (in particular, Kieffer, 1982 showed rate convergence exponentialrandom variables log-concave densities 1-dimension provided logarithmdensity piecewise affine).Two multi-start strategies, Serial MetaMax tested data set cloudUCI Machine Learning Repository (Asuncion & Newman, 2007). data setemployed Arthur Vassilvitskii (2007) well. number clusters setten. performance multi-start strategies defined differencesmallest cost function obtained strategy given number steps smallestcost seen experiments (5626.6357). results averaged 1,000 runsplotted Figure 9. initialization methods MetaMax strategy convergesfaster Serial strategy. note data set, k-means++clever initialization procedure yields faster convergence standard k-meansuniform initialization, consistent results presented ArthurVassilvitskii (2007).8. extension clustering random variables well-known straightforward, omittedpaper consider clustering finite data sets.9. Note MetaMax algorithm practical modification local searchalgorithm terminated chosen anymore. clearly improves performancealgorithm chosen anymore improvement observed.438fiEfficient Multi-Start Strategies Local Search Algorithms100000100001000100average erroraverage error1000010001001010.10.010.001100.00011Serial kmeansMetaMax kmeans110100100010000100000iteration1e-05Serial kmeans++MetaMax kmeans++110100100010000100000iterationFigure 9: average error multi-start strategies k-means (left) kmeans++ (right). 99% confidence intervals shown colorcorresponding curves.5.3 Practical Considerationsexperiments MetaMax algorithm presented above, observednumber algorithm instances r (shown Figure 10) grows rate (tr / ln tr ) (recalltr total number function calls evaluate f , total number steps,algorithm instances end round r). hand, derivationtheoretical bounds (see Theorem 15 Theorem 16) used bound r ( tr ).contrast quadratic penalty suggested Theorem 16, plugging (tr / ln tr )estimate r theorem would find logarithmic factor callsevaluate f (total number steps) needed achieve performance searchalgorithm started attraction region optimum.Finally, perhaps main practical question concerning MetaMax family multistart algorithms decide use them. rule thumb, saysufficiently large performance difference average runlocal search algorithm best one. Clearly, single local search producesacceptable result worth effort run several instances local search,especially complicated schedule. many real problems often caserelatively easy get close optimum, may acceptableapplications, approaching optimum greater precision hard; latterimportance, MetaMax algorithm variants may useful. Last, one maywonder computational costs algorithms. discussed before,consider case evaluation target function expensive: clearlycase Griewank function, used demonstrate basic propertiesalgorithm, holds many optimization problems practice, includingexperiments considered paper. problems function evaluationindeed expensive (and depends available data), overhead introducedMetaMax algorithms depends number rounds. MetaMax(K)algorithm find upper convex hull set K points round;worst case take long O(K 2 ) calculations, practice usually439fiGyorgy & Kocsisnumber algorithm instances * ln(t)/t1.8Griewank 2DGriewank 10DvehicleletterK-MEANSK-MEANS++minmax1.61.41.210.80.60.40.2110100100010000100000iterationFigure 10: Number algorithm instances (r) MetaMax. average numberinstances shown six benchmarks: Griewank function (2- 10dimensional), parameter tuning Multilayer Perceptron (on vehicleletter data set), clustering k-means k-means++.maximum minimum number instances runs benchmarksalso shown. One notice larger values tr , 0.45tr / ln tr r1.65tr / ln tr .much cheaper, upper convex hull determined point correspondsactually best estimate point corresponds least used algorithm,requires O(K) computations, even less, special ordering tricksintroduced. Since target function f evaluated least twice round, averageO(K 2 ) computational overhead needed evaluation f worstcase, practically reduced O(K), even less. Similar considerations holdMetaMax() MetaMax algorithms, resulting average O(r2 ) worst-caseoverhead call f (in r rounds), closer O(r) even less practice.examples considered (apart case Griewank function), amountoverhead negligible relative computational resources needed evaluatef single point.6. Conclusionspaper provided multi-start strategies local search algorithms. strategiescontinuously estimate potential performance algorithm instance optimisticway, supposing convergence rate local search algorithms unknownconstant, every phase resources allocated instances could convergeoptimum particular range constant. Three versions algorithmpresented, one able follow performance best fixed numberlocal search algorithm instances, two that, gradually increasing numberlocal search algorithms, achieve global consistency. theoretical analysis asymptotic440fiEfficient Multi-Start Strategies Local Search Algorithmsbehavior algorithms also given. Specifically, mild conditionsfunction maximized (e.g., set values local maxima denseglobal maximum), best algorithm, MetaMax, preserves performance localsearch algorithm original function class quadratic increasenumber times target function needs evaluated (asymptotically). Simulationsdemonstrate algorithms work quite well practice.theoretical bound suggests target function evaluatedquadratic factor times achieve performance search algorithm startedattraction region optimum, experiments found logarithmicpenalty. clear whether difference result slightly conservative(asymptotic) analysis choice experimental settings. Also, finite sampleanalysis algorithm interest, experiments indicate MetaMaxalgorithm provides good performance even relatively small number steps takenlocal search algorithms, sense provides speed-up comparedapproaches even number times target function evaluated (i.e., totalnumber steps taken algorithms together) relatively small. Finally,future work needed clarify connection convergence rate optimalalgorithms (g ) function hr used exploration.Acknowledgmentsauthors would like thank anonymous referees numerous insightfulconstructive comments. research supported part Mobile InnovationCenter Hungary, National Development Agency Hungary ResearchTechnological Innovation Fund (KTIA-OTKA CNK 77782), PASCAL2 NetworkExcellence (EC grant no. 216886). Parts paper presented ECML 2009(Kocsis & Gyorgy, 2009).Appendix A. Proof Lemma 1bn ). Since Un 0 almost everywhere E, EgoroffsFix (0, 1) let Un = f f (Xtheorem (see, e.g. Ash & Doleans-Dade, 2000) implies event E E1 P (E ) < Un 0 uniformly almost everywhere E . second partlemma follows definition uniform convergence.2ReferencesAdam, K. (2001). Learning searching best alternative. Journal EconomicTheory, 101, 252280.Arthur, D., & Vassilvitskii, S. (2007). k-means++: advantages careful seeding.Proceedings 18th Annual ACM-SIAM Symposium Discrete Algorithms, pp.10271035.Ash, R. B., & Doleans-Dade, C. A. (2000). Probability & Measure Theory. Academic Press.441fiGyorgy & KocsisAsuncion, A., & Newman, D. J. (2007). UCI machine learning repository.Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite time analysis multiarmedbandit problem. Machine Learning, 47 (2-3), 235256.Bartz-Beielstein, T. (2006). Experimental Research Evolutionary ComputationNew Experimentalism. Natural Computing Series. Springer, New York.Battiti, R., Brunato, M., & Mascia, F. (2008). Reactive Search Intelligent Optimization,Vol. 45 Operations research/Computer Science Interfaces. Springer Verlag.Beck, C. J., & Freuder, E. C. (2004). Simple rules low-knowledge algorithm selection.Regin, J. C., & Rueher, M. (Eds.), CPAIOR, Lecture Notes Computer Science3011, pp. 5064. Springer.Carchrae, T., & Beck, J. C. (2004). Low-knowledge algorithm control. ProceedingsNineteenth National Conference Artificial Intelligence (AAAI), pp. 4954.Cicirello, V. A., & Smith, S. F. (2004). Heuristic selection stochastic search optimization:Modeling solution quality extreme value theory. Proceedings 10thInternational Conference Principles Practice Constraint Programming, pp.197211. Springer.Cicirello, V. A., & Smith, S. F. (2005). max k-armed bandit: new model explorationapplied search heuristic selection. Proceedings Twentieth NationalConference Artificial Intelligence, pp. 13551361.Finkel, D. E., & Kelley, C. T. (2004). Convergence analysis direct algorithm. Tech.rep. CRSC-TR04-28, NCSU Mathematics Department.Gagliolo, M., & Schmidhuber, J. (2006). Learning dynamic algorithm portfolios. AnnalsMathematics Artificial Intelligence, 47 (34), 295328. AI&MATH 2006 SpecialIssue.Gagliolo, M., & Schmidhuber, J. (2007). Learning restart strategies. Veloso, M. M. (Ed.),IJCAI 2007 Twentieth International Joint Conference Artificial Intelligence,vol. 1, pp. 792797. AAAI Press.Gagliolo, M., & Schmidhuber, J. (2010). Algorithm selection bandit problemunbounded losses. Blum, C., & Battiti, R. (Eds.), Learning Intelligent Optimization, Vol. 6073 Lecture Notes Computer Science, pp. 8296. SpringerBerlin/Heidelberg.Gerencser, L., & Vago, Z. (2001). mathematics noise-free SPSA. ProceedingsIEEE Conference Decision Control, pp. 44004405.Gersho, A., & Gray, R. M. (1992). Vector Quantization Signal Compression. Kluwer,Boston.Griewank, A. O. (1981). Generalized descent global optimization. Journal Optimization Theory Applications, 34, 1139.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. Systems Science Cybernetics, IEEE Transactions on,4 (2), 100 107.442fiEfficient Multi-Start Strategies Local Search AlgorithmsHoos, H. H., & Stutzle, T. (1999). Towards characterisation behaviour stochasticlocal search algorithms SAT. Artificial Intelligence, 112, 213232.Horn, M. (2006). Optimal algorithms global optimization case unknown lipschitzconstant. Journal Complexity, 22 (1), 5070.Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automaticalgorithm configuration framework. Journal Artificial Intelligence Research, 36 (1),267306.Jones, D. R., Perttunen, C. D., & Stuckman, B. E. (1993). Lipschitzian optimization withoutlipschitz constant. Journal Optimization Theory Applications, 79 (1), 157181.Kautz, H., Horvitz, E., Ruan, Y., Gomes, C., & Selman, B. (2002). Dynamic restart policies. Proceedings Eighteenth National Conference Artificial Intelligence(AAAI), pp. 674681.Kieffer, J. C. (1982). Exponential rate convergence Lloyds method I. IEEE Trans.Inform. Theory, IT-28, 205210.Kocsis, L., & Gyorgy, A. (2009). Efficient multi-start strategies local search algorithms.Buntine, W., Grobelnik, M., Mladenic, D., & Shawe-Taylor, J. (Eds.), MachineLearning Knowledge Discovery Databases, Vol. 5781 Lecture Notes Computer Science, pp. 705720. Springer Berlin/Heidelberg.Linde, Y., Buzo, A., & Gray, R. M. (1980). algorithm vector quantizer design. IEEETransactions Communications, COM-28, 8495.Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup Las Vegas algorithms.Information Processing Letters, 47, 173180.Mart, R., Moreno-Vega, J., & Duarte, A. (2010). Advanced multi-start methods. Gendreau, M., & Potvin, J.-Y. (Eds.), Handbook Metaheuristics, 2nd edition (2 edition).Springer.Nesterov, Y. (2004). Introductory Lectures Convex Optimization: Basic Course.Kluwer Academic Publishers.Ribeiro, C., Rosseti, I., & Vallejos, R. (2009). use run time distributions evaluatecompare stochastic local search algorithms. Stutzle, T., Birattari, M., & Hoos,H. (Eds.), Engineering Stochastic Local Search Algorithms. Designing, ImplementingAnalyzing Effective Heuristic s, Vol. 5752 Lecture Notes Computer Science,pp. 1630. Springer Berlin/Heidelberg.Spall, J., Hill, S., & Stark, D. (2006). Theoretical framework comparing several stochasticoptimization approaches. Calafiore, G., & Dabbene, F. (Eds.), ProbabilisticRandomized Methods Design Uncertainty, chap. 3, pp. 99117. SpringerVerlag, London.Spall, J. C. (1992). Multivariate stochastic approximation using simultaneous perturbationgradient approximation. IEEE Transactions Automatic Control, 37, 332341.Spall, J. C. (1998). Implementation simultaneous perturbation algorithm stochastic optimization. IEEE Transactions Aerospace Electronic Systems, 34, 817823.443fiGyorgy & KocsisStreeter, M. J., & Smith, S. F. (2006a). asymptotically optimal algorithm maxk-armed bandit problem. Proceedings, Twenty-First National ConferenceArtificial Intelligence Eighteenth Innovative Applications Artificial Intelligence Conference, pp. 135142.Streeter, M. J., & Smith, S. F. (2006b). simple distribution-free approach maxk-armed bandit problem. Principles Practice Constraint Programming CP 2006, 12th International Conference, CP 2006, Nantes, France, September 25-29,2006, Proceedings, pp. 560574.Vilalta, R., & Drissi, Y. (2002). perspective view survey meta-learning. ArtificialIntelligence Review, 18 (2), 7795.Witten, I. H., & Frank, E. (2005). Data Mining: Practical Machine Learning ToolsTechniques (2nd edition). Morgan Kaufmann, San Francisco.Zabinsky, Z. B., Bulger, D., & Khompatraporn, C. (2010). Stopping restarting strategystochastic sequential search global optimization. J. Global Optimization,46 (2), 273286.444fiJournal Artificial Intelligence Research 41 (2011) 1-24Submitted 10/2010; published 05/2011Properties Bethe Free Energies Message PassingGaussian ModelsBotond CsekeTom Heskesb.cseke@science.ru.nlt.heskes@science.ru.nlInstitute Computing Information SciencesFaculty Science, Radboud University NijmegenHeyendaalseweg 135, 6525 AJ, NetherlandsAbstractaddress problem computing approximate marginals Gaussian probabilisticmodels using mean field fractional Bethe approximations. define Gaussian fractional Bethe free energy terms moment parameters approximatemarginals, derive lower upper bound fractional Bethe free energyestablish necessary condition lower bound bounded below. turnscondition identical pairwise normalizability condition, knownsufficient condition convergence message passing algorithm. showstable fixed points Gaussian message passing algorithm local minimaGaussian Bethe free energy. counterexample, disprove conjecture statingunboundedness free energy implies divergence message passingalgorithm.1. IntroductionOne major tasks probabilistic inference calculating marginal posterior probabilities set variables given observations. case Gaussian models,computational complexity computing marginals might scale cubically numbervariables, models discrete variables often leads intractable computations.Computations made faster tractable using approximate inference methods likemean field approximation (e.g., Jaakkola, 2000) Bethe-type approximation (e.g.,Yedidia, Freeman, & Weiss, 2000). methods developed discrete probabilisticgraphical models, applicable Gaussian models well. However,important differences behavior discrete Gaussian cases. example,discrete models error function Bethe approximationcalled Bethe freeenergyis bounded (Heskes, 2004; Watanabe & Fukumizu, 2009), Gaussianmodels might always case (Welling & Teh, 2001).understanding properties Bethe free energy Gaussian models mightalso help understand properties energy function conditional Gaussianmodels. Conditional Gaussian hybrid graphical models, switching Kalman filters(Zoeter & Heskes, 2005), combine discrete Gaussian variables. Approximateinference models carried expectation propagation (e.g., Minka, 2004,2005) viewed generalization Bethe approximation,marginal consistency constraints approximate marginals replaced expectationconstraints (Heskes, Opper, Wiegerinck, Winther, & Zoeter, 2005). order understandc2011AI Access Foundation. rights reserved.fiCseke & Heskesproperties Bethe free energy hybrid models, good understanding twospecial cases discrete Gaussian models needed. properties Bethefree energy discrete models studied extensively last decade wellunderstood (Yedidia et al., 2000; Heskes, 2003; Wainwright, Jaakkola, & Willsky, 2003;Watanabe & Fukumizu, 2009), properties Gaussian Bethe free energystudied much less.message passing algorithm well established method finding stationarypoints Bethe free energy (Yedidia et al., 2000; Heskes, 2003). works locallyupdating approximate marginals successfully applied discrete (e.g.,Murphy, Weiss, & Jordan, 1999; Wainwright et al., 2003) Gaussian models (e.g., Weiss& Freeman, 2001; Rusmevichientong & Roy, 2001; Malioutov, Johnson, & Willsky, 2006;Johnson, Bickson, & Dolev, 2009; Nishiyama & Watanabe, 2009; Bickson, 2009). Gaussianmessage passing simplest case free-energy based message passing algorithmmodels continuous variables, therefore, important understand behavior.Gaussian message passing many practical applications like distributed averaging(Moallemi & Roy, 2006), peer-to-peer rating, linear detection, SVM regression (Bickson,2009) generally problems involve solving large sparse linear systemsapproximating marginal variances large sparse Gaussian systems typically encountered distributed computing settings. applications reader referredwork Bickson (2009) references therein.Finding sufficient conditions convergence message passing Gaussian modelssuccessfully addressed many authors. Using computation tree approach,Weiss Freeman (2001) proved message passing converges whenever precisionmatrixinverse covarianceof probability distribution diagonally dominant1 .help analogy message passing walksum analysis, (Malioutov et al.,2006) derived stronger condition pairwise normalizability2 . different approachtaken Welling Teh (2001), directly minimized Bethe free energy regardparameters approximate marginals, conjecturing Gaussian message passingconverges free energy bounded below. experiments showedmessage passing direct minimization either converge solutionfail converge. adopt similar approach, is, instead analyzing propertiesGaussian message passing algorithm using approaches like Weiss FreemanMalioutov et al., choose study properties Gaussian Bethe free energystationary points. help us draw conclusions existence localminima, possible stable fixed points message passing converge.paper structured follows. Section 2 introduce Gaussian Markov randomfields message passing algorithm. Section 3 define Gaussian fractionalBethe free energies parameterized moment parameters approximate marginalsderive boundedness conditions them. two sections based authorsearlier work (Cseke & Heskes, 2008). Section 4 analyze stability propertiesGaussian message passing algorithm and, using similar line argument WatanabeP1. matrix diagonally dominant |Aii | > j6=i |Aij | i.2. Following work Malioutov et al. (2006), call Gaussian distribution pairwise normalizableQfactorized product normalizable pair factors, is, p(x1 , . . . , xn ) = ij ij (xi , xj )ij normalizable.2fiBethe Free Energies Message Passing Gaussian ModelsFukumizu (2009), show stable fixed points indeed local minima Bethefree energy. conclude paper experiments Sections 5 6 supportingresults implications.2. Approximating Marginals Gaussian Modelsprobability density Gaussian random vector x Rn defined terms canonicalparameters h Q1p(x) exp h x x Qx ,(1)2Q positive definite matrix. expectation covariance V xgiven = Q1 h V = Q1 respectively. many real world applicationsmatrix Q sparse typically low density, is, number non-zeroelements Q scales number variables n.probability density also defined terms undirected probabilisticgraphical model commonly known Gaussian Markov random field (GMRF). Sinceinteractions variables p pairwise, associate variables xinodes v V = {1, . . . , n} undirected graph G = (V, E), edges e E V Vgraph stand non-zero off-diagonal elements Q. use j proxy(i, j) E. using notation introduced above, density p (1) writtenproductp(x)ij (xi , xj )(2)ijGaussian functions ij (xi , xj ) (also called potentials) associated edges e = (i, j)graph. h Q given define potentialsjjij (xi , xj ) = exp {ijhi xi + ijhj xj ijQii x2i /2 ijQjj x2j /2 Qij xi xj } ,PPjij ij = 1ji ij = 1 partitioning h Q correspondingfactors. practice, however, factors ij might given problem handj computed summing parameters computingh Q well ijijpartitioning respectively. Without loss generality, use Qii = 1, sinceresults paper easily re-formulated general Qs rescalingvariables (e.g., Malioutov et al., 2006).numerical calculation marginals, done solving linear system= Q1 h performing sparse Cholesky factorization LLT = Q followed solving Takahashi equations (Takahashi, Fagan, & Chin, 1973). alternative optioncalculate marginal means approximate marginal variances run Gaussian message passing algorithm probabilistic graphical model associatedrepresentation (2). Gaussian message passing algorithm Gaussian variantmessage passing algorithm (Pearl, 1988), dynamical programming algorithmintroduced compute marginal densities discrete probabilistic models pairwise interactions tree-structured graphs G. However, turned running loopsgraphs cycles, yields good approximations marginal distributions (Murphyet al., 1999). Weiss Freeman (2001) showed Gaussian message passing3fiCseke & HeskesFigure 1: illustration incoming outgoing messages adjacent nodes j.algorithm converging, computes exact mean parameters m, thus alsoused solving linear systems (e.g., Bickson, 2009). Message passing works updatingpassing directed messages along edges graph G, which, case algorithmconverges, used compute (approximate) marginal probability distributions.Gaussian discrete algorithms functional form exceptionsummation (discrete case) integration operators (Gaussian case). messageij (xi ) updated accordingZnewij (xi ) = dxj ij (xi , xj )jk (xj ) ,(3)kj\i= {j : j i} denotes index set variables connected xi G. stepcurrent approximations qij (xi ,j ) p(xi , xj ) computed accordingqij (xi , xj ) ij (xi , xj )li\jil (xi )jk (xj ) .(4)kj\iupdate steps (9) iterated convergence. corresponding qij (xi , xj )syield final approximation p(xi , xj )s. common use damping, is,1 new (x ) (0, 1]. practice, helpsreplace newij (xi ) ij (xi )ijdampen possible periodic paths (3), keeps properties fixed pointsunchanged. Figure 1 illustrates incoming outgoing messages nodes associatedvariables xi xj . quite significant difference discrete Gaussianmessage passing replacement sum operator integral operator.finite sums always exist, integral (3) become infinite. problemremedied technically canonical parameterization (see Section 4) keepsalgorithm running, lead non-normalizable approximate marginals qij , thus(possible) break-down algorithm.Message passing introduced Pearl (1988) heuristic algorithm (in discretemodels), however, Yedidia et al. (2000) showed also viewed algorithm4fiBethe Free Energies Message Passing Gaussian Modelsfinding stationary points so-called Bethe free energy, error function measuringdifference p specific family distributions detailed nextsection. shown Heskes (2003) later different way WatanabeFukumizu (2009) stable fixed points (loopy) message passing algorithm localminima corresponding Bethe free energy. paper show holdsGaussian models well.interest properties Gaussian Bethe free energy corresponding Gaussian message passing algorithm motivated mainly implicationsgeneral models inference algorithms like non-Gaussian models expectation propagation, respectively. reason, compare speed methodaccuracy approximation mentioned exact linear algebraic methods.mentioned introduction, approach take similar WellingTeh (2001), is, study properties Gaussian Bethe free energy, parameterizedterms moment parameters approximate marginals. followingintroduce mean field Bethe approximation Gaussian models. Readers familiarsubject continue Section 3.2.1 Gaussian Bethe Free Energypopular method approximate marginals approximating p distribution qform makes marginals easy identify, example, factorizes treelike form. common quantity measure difference two probabilitydistributions Kullback-Leibler divergence [q || p]. often used characterizequality approximation formulate computation approximate marginalsoptimization problemZq(x)q (x) = argmin dx q(x) log.(5)p(x)qFHere, F set distributions mentioned form. Since symmetric,Kullback-Leibler divergence distance, [q || p] 0 proper q p,[q || p] = 0 p = q, convex q p.family F densities possessing formQ makes marginals easy identifyfamily distributions factorize q(x) = k qk (xk ). words, problem (5)approximate p distribution independent variables. approximation qthisQtype called mean field approximation (e.g., Jaakkola, 2000). Defining FMF ({qk }) =[ qk || p] writing right hand side (5) detail, one getsZFMF ({qk }) =dxqk (xk ) log p(x) +kXZdxk qk (xk ) log qk (xk ).kUsing parameterization qk (xk ) = N (xk |mk , vk ), = (m1 , . . . , mn )T v = (v1 , . . . , vn )T ,reduces11X1XFMF (m, v) = hT + mT Qm +Qkk vklog(vk ) + CMF ,222k5kfiCseke & HeskesQCMF irrelevant constant. Although [ k qk || p] might convex(q1 , . . . , qn ), one easily check FMF convex variables vminimum obtained = Q1 h vk = 1/Qkk . Since111Q kk = Qkk QTk,\k Q\k,\kQ\k,k,one easily see mean field approximation underestimates variances. meanfield approximation computes solution means exact, variancescomputed interactions variables, namely, matrixQ diagonal, thus giving poor estimates variances.order improve estimates variances, one choose approximating distributions q able capture dependencies variables p.verified distribution dependencies form tree graph writtenformp(xi , xj )p(x) =p(xk ),p(xi )p(xj )ijkj run edges (i, j) tree k nodes 1, . . . , n.Although cases undirected graph generated non-zero elements Qtree, based tree intuition one construct q one two variablemarginalsqij (xi , xj )q(x)qk (xk )(6)qi (xi )qj (xj )ijkandR constrain functions qij qk marginallyconsistent normalize 1,Ris, dxj qij (xi , xj ) = qi (xi ) j dxk qk (xk ) = 1 k. approximationform (6) together constraints qij qk called Bethe approximation.Let us denote family functions FB . choosing qij (xi , xj ) = qi (xi )qj (xj ) oneeasily check FMF FB , thus FB non-empty. Assuming approximatemarginals correct q normalizes 1 substituting (6) (5), getapproximation KullbackLeibler divergence (5) called Bethe free energy.Due factorization p, write Bethe free energyXZFB ({qij , qk }) =dxi,j qij (xi,j ) log ij (xi,j )(7)ij+XZijXZqij (xi,j )dxi,j qij (xi,j ) log+dxk qk (xk ) log qk (xk ).qi (xi )qj (xj )kOne also define free energy Bethe approximationZXZdx q (x) log q (x)dxi,j q (xi,j ) log q (xi,j )ij+Xk6Z(1 nk )dxk q (xk ) log q (xk )fiBethe Free Energies Message Passing Gaussian Modelsentropy (e.g., Yedidia et al., 2000) substitute marginals functions qijqRk normalize one connected marginal consistency constraintsdxj qij (xi , xj ) = qi (xi ).stationary conditions Lagrangian corresponding fractional Bethefree energy (7) marginal consistency normalization constraints, one deriveiterative algorithm (3) corresponding Lagrange multipliersconsistency constraints (Yedidia et al., 2000). Similarly, approximate marginalscomputed according (4). shown one-to-one correspondencestationary points Bethe free energy (7) fixed pointsmessage passing algorithm (3). Later, Section 4 link stable fixed points (3)local minima (7).2.2 Fractional Free Energies Message Passing Algorithmmentioned introduction, case Gaussian models message passing algorithmalways converge. reason appears approximate marginalsmay get indefinite negative definite covariance matrices. Welling Teh (2001) pointeddue unboundedness Bethe free energy.Since FMF convex bounded Bethe free energy might unbounded,seems plausible analyze fractional Bethe free energyXZF ({qij , qk }) =dxi,j qij (xi,j ) log ij (xi,j )(8)ijXZX 1 Zqij (xi,j )+dxi,j qij (xi,j ) log+dxk qk (xk ) log qk (xk ).ijqi (xi )qj (xj )ijkintroduced Wiegerinck Heskes (2003). Here, denotes set positive reals {ij }.showed fractional Bethe free energy interpolates mean fieldBethe approximation. is, ij = 1 get Bethe free energy,case ij tend 0, mutual information variables xi xj highlypenalized, therefore, (8) enforces solutions close mean field solution. also showedfractional message passing algorithm derived (8) interpreted Pearlsmessage passing algorithm difference instead computing local marginalslike Pearls algorithmone computes local ij marginals.3 local ij marginalscorrespond true local marginals ij = 1 local mean field approximationsij = 0. resulting algorithm called fractional message passing algorithmmessage updates definedZnew(x)=dxj ij (xi , xj )jk (xj ) ji (xj )1 ,(9)ijkj\iapproximate marginals computed accordingqij (xi , xj ) ij (xi , xj )il (xi ) ij (xi )1jk (xj ) ji (xj )1 .li\j(10)kj\iQ3. define marginals distribution p argmin{qk } p k qk , divergencekRRR[p || q] = dxp(x) q(x)1 + dxp(x) + (1 ) dxq(x) /(1 ) (e.g., Minka, 2005).7fiCseke & HeskesPower expectation propagation Minka (2004) approximate inference methoduses local approximations divergences. case Gaussian models powerexpectation propagationwith fully factorized approximating distributionleadsmessage passing algorithm one derived (8) appropriate constraints.Starting idea creating upper bound log partition function pq exponential distributions, Wainwright et al. (2003) derived form (8)ij chosen bound convex {qij , qk }.Message passing works well practice, however, ways find localminima fractional free energies like direct minimization w.r.t. parameterization approximate marginals qij qk (Welling & Teh, 2001). latter methodslower likely converge. following analyze Bethe free energyexpressed terms moment parameters approximate marginals qij . LaterSection 4 analyze stability conditions fractional message passing algorithmexpressing conditions term moment parameters approximatemarginals, show stable fixed points fractional Gaussian message passinglocal minima fractional Bethe free energy.3. Bounds Gaussian Bethe Free Energysection analyze parametric form (8). show fractional Gaussian Bethe free energy non-increasing function . letting ij tend infinity, obtain lower bound free energies. turns conditionlower bound bounded pairwise normalizabilitycondition work Malioutov et al. (2006).mentioned Section 2, without loss generality, work unit diagonal Q. define R matrix zeros diagonal Q = + R,identity matrix. |R| matrix formed absolute valuesRs elements. use moment parameterization qij (xi,j ) = N (xi,j |mij , Vij ), v ; v , v j ], v = v .qk (xk ) = N (xk |mk , vk ), mij = (miij , mjij )T Vij = [vijijji ijijji= mi v v = v k j k, embedusing miijikikR ijRmarginalization ( dxj qij (xi , xj ) = qi (xi ) j) normalization ( dxj qj (xj ) = 1)constraints parameterization. slight abuse notation matrix formeddiagonal elements vk off-diagonal elements vij denoted V (we take vij = 0j), vector means = (m1 , . . . , mn )T vector variancesv = (v1 , . . . , vn )T . Substituting qij qk (8) one gets11F (m, V ) = hT + mT Qm + tr(QT V )22 !2Xv111Xijlog 1log (vk ) + C,2ijvi vj2ij(11)kC irrelevant constant. Note variables V independent, henceminimizations F (m, V ) regard V carried independently.8fiBethe Free Energies Message Passing Gaussian ModelsProperty 1. F (m, V ) convex bounded (m, {vij }i6=j ) stationary point= Q1 hvijp1 + (2ij Rij )2 vi vj 1= sign(Rij ).2ij |Rij |(12)Proof: Q positive definite definition, therefore, quadratic term convexbounded. variables V independent minimum regardachieved = Q1 h. One check second order derivativeF (m, V ) regard vij non-negative first order derivative one2 v v . Since variables v independent, one concludesolution vi vj vijjijF (m, V ) convex vij . independence V , follows Fconvex (m, {vij }i6=j ).2 , thusSince Vij constrained covariance matrices, vi vj > vijfirst logarithmic term (11) negative. consequence,F1 (m, V ) F2 (m, V )0 < 1 2 ,1 2 taken element element. observation leads followingproperty.Property 2. ij = , F non-increasing function .F define constrained functionUsing Property 1 substituting vij11XFc (m, v) = hT + mT Qm +vk22kq1X 11 + (2ij Rij )2 vi vj 12ij ij!p1 + (2ij Rij )2 vi vj 11 X 1log 22ij(2ij Rij )2 vi vjn(i,j)1Xlog(vk ) + C c ,2(13)kC c irrelevant constant. Property 2, follows choosing ij = ,function (13) non-increasing function . makes sense takeverify whether get lower bound (13).Lemma 1. v > 0, 0 1 1 2 1 following inequalities hold.FMF (m, v) Fc1 (m, v) FB m, {vij}, vFB m, {vij}, v Fc2 (m, v) . . .1. . . FMF (m, v)v |R| v2Moreover, tight, is,lim F m, {vij()}, v = FMF (m, v)09fiCseke & Heskes1v |R| v.lim F m, {vij()}, v = FMF (m, v)2Proof: Since Bethe free energy specific case fractional Bethe free energy()}, v) follow Property 2. Now, show= 1, inequalities FB (m, {vijupper lower bounds tight. function (1 + x2 )1/2 1 behaves 12 x2neighborhood 0, therefore,v 2 ()log 1 ijvi vj2 ()vij1limlim vij() = 0lim== 0,00vi vj 0showing FMF (m, v) tight upper bound.tends infinity,p1 + (2Rij )2 vi vj 1= |Rij | vi vjlim21loglim!p1 + (2Rij )2 vi vj 1= 0,(2Rij )2 vi vjyielding tight lower bound1v |R| v.lim F m, {vij()}, v = FMF (m, v)2Let max (|R|) largest eigenvalue |R|. Analyzing boundedness lowerbound, arrive following theorem.Theorem 1. fractional Bethe free energy (11) corresponding connectedGaussian model, following statements hold(1) max (|R|) < 1, F bounded > 0,(2) max (|R|) > 1, F unbounded > 0,P P 1(3) max (|R|) = 1, F boundedij 2n.ijProof: Since F interaction parameters V termdepending bounded due positive definiteness Q, simplyneglect term analyzing boundedness F . Let us write detaillower bound fractional Bethe free energies form1v |R| v =2111 1Q hT +v (I |R|) v 1T log(v) + const.222FMF (m, v)(14)Statement (1): condition max (|R|) < 1 implies |R| positive definite. Now,10fiBethe Free Energies Message Passing Gaussian Modelslog(x) x 1, thus 12 v (I |R|) v 1T log( v) 21 v (I |R|) v 1T v + n.latter bounded follows (14) boundedwell. According Lemma 1, boundedness (14) implies fractional Bethe freeenergies bounded below.Statement (2): assumed Gaussian network connected undirected. According Perron-Frobenius theory non-negative matrices (e.g., Horn & Johnson,2005), |R| simple maximal eigenvalue max (|R|) elements eigenvector umax corresponding positive. Let us take fractional Bethe free energyanalyze behavior v = tumax . large values(1 + (2ij Rij )2 (uimax ujmax )2 t4 )1/2 ' 2ij |Rij |uimax ujmax t2 , therefore, sum secondthird term (13) simplifies (1 max (|R|))t2 term dominateslogarithmic ones . result, limit independent choice ijtends whenever max (|R|) > 1.Statement (3): max (|R|) = 1, direction quadratic termdominate v = tumax . Therefore, analyze Pbehavior loga1rithmic terms (13) . large ts behave ( ij ij2n) log(t).creason, boundedness F thus F depends conditionstatement (3).shown Malioutov et al. (2006) condition max (|R|) < 1 equivalentcondition pairwise normalizability. Therefore, pairwise normalizabilitysufficient condition message passing algorithm converge, also necessarycondition fractional Gaussian Bethe free energies bounded. Using Lemma 1,show suitably chosen > 0 always exists constrainedfractional free energy Fc possesses local minimum 0 < < (Property A2Section Appendix).Example case models adjacency matrix (non-zero entries R) corresponding Kregular graph4 equal interaction weights Rij = r, maximal eigenvalue |R| max (|R|) = Kr eigenvector corresponding eigenvalue 1.(We define 1 vector elements equal 1.) model symmetricverifying stationary point conditions, turns choice rexists local minimum, also lies direction 1. One showmodel pairwise normalizable (Kr > 1), critical rp fractionalBethe free energy possesses local minimum rc (K, ) = 1/2 (K )valid r criticalp fractional Bethe free energies possesses localminimum c (K, r) = 21 K(1 1 1/(Kr)2 ). results illustrated Figure 2.(Note 2regular graphs, valid models pairwise normalizable possessunique global minimum.)Kregular graphs, convexity fractional Bethe free energy terms{qij , qk } requires K, much stronger condition c (K, r). Thus, choosesufficiently large Bethe free energy guaranteed unique globalminimum, minimum unbounded.4. Kregular graph graph nodes connected K nodes.11fiCseke & Heskes$!"$)!"+0")12&3,)*.&456+)D)1"7+834.59+0!:;+< VTUWff.fi+0+#%&'(&)*+&&)&,&+-.&/%&'(&)*+&&)&,&+-.&/#!"834.5!""!"!")_0")12&3,)*.&456_)D)7"8"!9!"":_0!)1%&'(&6_0_;!"_)0)')14<=&+)><?,56!""!")!"!""!"!!"!")!"!"!""!"!!"!"Figure 2: Visualizing critical parameters symmetric K-regular Gaussian model Rij = r.Plotsleft panel correspond constrained fractional Bethe free energies Fcv = 1 8 node 4regular Gaussian model r=0.27 (Kr > 1) varying.Plots right panel correspond constrained Bethe free energies F1c v = 18 node 4regular Gaussian model varying r. Here, rvalid supremumrs model valid, is, Q positive definite.example disproves conjecture Welling Teh (2001), is, evenBethe free energy bounded below, possess finite local minimummessage passing minimization algorithms converge.4. Message Passing Algorithm Gaussian Modelssection, turn attention towards properties message passing algorithm Gaussian models. Following similar line argument Watanabe Fukumizu(2009) show stable fixed points message passing algorithm correspond localminima Bethe free energy. use moment parameterization introducedprevious sections. way proceed following: (1) make linear expansionmessage passing iteration fixed point, (2) express linear expansion termsmoment parameters corresponding fixed point finally (3) connect properties latter properties Hessian Bethe free energy usingmatrix determinant lemma.form equation (9) implies messages ij (xi ) univariate Gaussianfunctions, thus express terms two scalar (canonical) parameters ijij log ij (xi ) = ij x2i /2 + ij xi + ijj , ij irrelevant constants.expressed terms ij ij , damped message passing algorithm (9) translates12fiBethe Free Energies Message Passing Gaussian Modelsjhj +ijnewij=(1 )ij +Pjk + (1 )jikj\iPij hi Rijjij+jk + (1 )ji(15)kj\inewij=1Xj22 Rijij+jk + (1 )ji(1 )ij + ijkj\i(16), j , h R parameters Section 2.1, R = Qijijijijijijassumption Qii = 1. approximate marginals qij (10) might normalizable,message passing iteration (15) (16) stays well defined unless zerodenominator rhs. rarely happens practice. However,common message passing converges intermediate stepsapproximate marginals qij normalizable. often remedied choosingappropriate damping parameter .iteration (16) ij independent ij iteration (15) ijlinear ij . interesting see h = 0 neither constrained Bethefree energy (13) message passing algorithm (16) depend sign Rij .relevant compute meanswhen h 6= 0and signs correlations(12). result, marginal variances computed either minimizing Bethe freeenergy running message passing algorithm depend |R|, similarlyconstrained fractional free energy Fc .4.1 Stability Gaussian Message Passing Algorithmfollowing analyze stability message passing iteration fixed points,is, stationary points Lagrangian corresponding constrained minimization Gaussian Bethe free energy. reiterate use G = (V, E) denotegraph corresponding Q, namely, V = {1, . . . , n} E = {(i, j) : Qij 6= 0}. vector R|E| , corresponding set messages {ij }ij , composed concatenationij ij followed ji (ij, ji) blocks follow lexicographic order w.r.t.ij < j. vector consists variables ij follows similar structure .jdefine r, h, R|E| rij = rji = Rij , hij = hj ij = ij. also define|E| |E| matrix1 j = k1 kl = jiMij,kl ()0 otherwiseencodes weighted edge adjacency corresponding G . number nonzero elements M(), scales roughly nnzeros (Q)2 /n, nnzeros (Q) denotesnumber non-zeros Q. Since parallel message update given Equations (15)(16) rewritten terms two matrix-vector multiplications element elementoperations vectors, computational complexity update also scales roughlynnzeros (Q)2 /n.13fiCseke & Heskesnotation, local linearization update equations (15) (16)written( new , new )(, ) = (1 )I . . .(, )h+M()1diag r +M() M() diag r (+M())2 M(),+10diag 2 r 2 (+M())M()2(17)operations vectors element element. stability fixed point( , ) depends union spectraJ ( , ) 1 diag r( + M() )1 M()J ( , ) 1 diag 2 r 2 ( + M() )2 M().important point stability properties depend Rindependent h.goal connect stability properties message passing algorithmproperties Bethe free energy. Therefore, express stability properties termsmoment parameters approximate marginals. leads normalizable approximate marginals qij (xi , xj ), use (10) identify local covarianceparameters Vij defined Section 3, without enforcing marginal matching= v . correspondence givenconstraints vijik"vijvijvijjvij=#11="jvijvijvj v2vijijijP+il + (1 )ijijvijvij#(18)Rijli\jjijRij+Pjk + (1 )ji.kj\i, v j rapproximate local covariances vij fully determined vijijijform (12). leaves us |E| moment parameters computed, v = v j (v) =message passing algorithm. Let v R|E| defined vij = vijjiijijv j v 2 ), vvij /(vijijij computed according (12). checkedijmapping v continuous bijective. implies canonicalmoment parameter transformation (18) written y(v) = + M(). SinceM() singular = K graph G K-regularsee Property A1Section Appendix detailsfor rest cases, continuous,bijective mapping moment parameters v canonical parameterslead normalizable approximate marginals.= v vfixed point ( , ) moment matching, is, vijikk, j i, therefore express stability properties terms moment parameters14fiBethe Free Energies Message Passing Gaussian Modelsv = (vi , . . . , vn ). Using p(18) defining diagonal matrix R|E||E|diagonal elements Dij,ij = vi , get, v)v(,vijj= 1 diag qM()vi vjDJ ( (v ))D 1(19)2J ( (v ))D2=1diagvij (, vi , vj )2vi vj!M().(20)Let (A) denotespectrum matrix A. Since DJ 1 = (J )2 J 2 = (J ), sufficient analyze spectral properties right handsides equations (19) (20).message passing algorithm asymptotically stable (v )max { (J ( (v ))) , (J ( (v )))} < 1,(21)() denotes spectral radius. interesting see although functionalforms free energies message passing algorithms different Gaussiandiscrete case, stability conditions similar forms. allow us useresults Watanabe Fukumizu (2009). next section, showimplications condition properties Hessian free energy.4.2 Stable Fixed Points Local MinimaHessian H[F ] Bethe free energy (11) depends moment parametersvi , vj vij . Note now, vij unconstrained parameters. (|E|/2 + 2n)(|E|/2 + 2n) matrix formQ0H[F ](V ) =0diagh 20 2F2 vijhFvij vi ij,i02 Fvij vi ij,ih2 Fvi vj i,j,use V denote collection parameters vi , = 1, . . . , n vij , j.Since block corresponding partial differentials w.r.t. vij diagonal positiveelements, Hessian positive definite V Schur complement corresponding15fiCseke & Heskespartial differentials w.r.t. vi positive definite V . latter givenX 2 F 2 F 12 FvHii [F ](V ) =vi vivij vivijij1 11 X c4ij=1+,42 vi21cijij122FF 2 F 2 FvHij [F ](V ) =vi vjvij vi vij vj 2 vij1 1 1 c2ij=,2 vi vj 1 c4ijuse notation cij = vij / vi vj .Now, would like connect condition (21) positive definitenessmatrix H v [F ](V ). following show stable fixed points (v ) Gaussianmessage passing algorithm, satisfying (21), correspond local minima Gaussian freeenergy F v vij (, vi , vj ).According Watanabe Fukumizu (2009), arbitrary vector w R|E| onedet I|E| 1 diag (w) M() = det + 1 A(w)(1 wij wji ),(22)ijAii (w) =Xijwij wji1 wij wjiAij (w) =wij.1 wij wji(23)proof application matrix determinant lemma reproductionfound Section Appendix. Equation (22) expresses determinant|E||E| matrix determinant nn matrix.Let c R|E| cij (V ) = vij / vi vj . substituting w = c(V )2 (23), finddet 1 diag c(V )2 M() = f (V ) det (H[F ](V )) ,(24)f (V ) positive function definedf (V ) = 2n |E| |Q|1kvk222vi vj vijij2vi vj + vij2vij1vi vj!.V corresponding normalizable approximate marginals. Now, adapting theoremWatanabe Fukumizu (2009)following theorem.Theorem 1 diag c(V )2 M() C \ R1 Hessian (Gaussian)Bethe free energy H[F ] positive definiteV.12Proof: assumptiondiag c(V ) M() C \ R1 impliesdet 1 diag(c(V )2 M()) > 0. choosing Vij (t) = tvij [0, 1], find2c(V(t))2 = t2 c(V )2 , therefore, det 1 diag(c(V (t) )M()) > 0 [0, 1].16fiBethe Free Energies Message Passing Gaussian Modelsimplies det (H[F ](V (t))) > 0 [0, 1]. Since H[F ](V (0)) = > 0eigenvalues H[F ](V (t)) change continuously w.r.t. [0, 1], resultsH[F ](V (1)) > 0 V , thus satisfying condition theorem.fixed point ( , ) stablemax{(J ( (v ))), (J ( (v )))} < 1.12implies diag(c(V ) )M() C \ R1 leads following property.Property 3. Stable fixed points ( , ) damped Gaussian message passing algorithm (16) local minima Gaussian Bethe free energy Fc (13) v ( ).shows boundedness F existence local minima caseunbounded F plays significant role convergence Gaussian message passing. illustrate Section 5. fractional message passing algorithm convergesconverges set messages corresponds local minimum fractional free energy. also implies mean parameters local approximatemarginals exact (see Property 1. Section 3). Note observations Section 3Property A2 Appendix together Property 3 imply alwaysrange values fractional free energy possesses local minimumfractional message passing converge.4.3 Damping Fractional Parameterslocal stability condition (21) independent damping parameter . Therefore,alter local stability properties, makes iteration slower numerically stable, is, dampen possible periodic trajectories messagepassing algorithm.fractional parameter characterizes inference process seenexample previous sections, choosing smaller create local minima.particular case h = 0, somewhat similar property message passingupdates well. Let R|E| set messages lead normalizable approximatemarginals. set characterized model parameters |R|, . reiteratev j continuous bijectiveelements v local variances vijij|E|mapping v R+ given y(v) = + M(), unless = K GK-regular. allows us study qstability properties terms moment parameters, v j )/v(). Let c(v, ) = [vij (, vijijv j ] vector local correlations. usingvijij ijGershgorins theorem (Horn & Johnson, 2005) c(v, )2 c(v, ), findeigenvalue 1 diag(c(v, ))M() 1 diag(c(v, ))2 M()|| max 1 c(v, ) [(nj 1) + |1 |] .i,jh = 0, updates , rhs equation depends1 c(v, )2 (see Equations (17) (20)) lim 1 c(v, )2 = 0, thus, small0values help achieve convergence. However, h 6= 0 term 1 c(v, )dominating effects decreasing towards zero ambiguous.17fiCseke & Heskes5. Experimentsimplemented direct minimization fractional message passing analyzedbehavior different values max (|R|). reasons simplicity, set ijequal. results small scale model summarized Figure 3. Notegood correspondence behavior fractional Bethe free energiesdirection eigenvalue corresponding max (|R|) convergence Newtonmethod. Newton method started different initial points. experiencedmax (|R|) > 1 setting initial value v0 = t2 u2max , algorithmconverge high values t. explained top plots Figure 3:high values t, initial point might convergence region localminimum. fractional message passing algorithm used two types initialization:=(1) max (|R|) < 1 set ij normalizable setting ij= 1/n ,|Rij |ujmax /max uimax (Malioutov et al., 2006), (2) max (|R|) 1, used ijis, symmetric partitioning diagonal elements. set initial messagesapproximate marginals normalizable first step iteration.experienced behavior similar described Welling Teh (2001)standard message passing, namely, fractional message passing direct minimization eitherconverge fail converge. experiments combination Theorem 1show max (|R|) > 1, standard message passing best converges localminimum Bethe free energy. standard message passing fails converge, onedecrease search stationary pointpreferably local minimumofcorresponding fractional free energy.seen results right panels Figure 2, modellonger pairwise normalizable, local minimum unbounded global minimumviewed natural continuation (bounded) global minimum pairwisenormalizable models. explains quality approximation localminimum models pairwise normalizable still comparableglobal minimum models pairwise normalizable.6. Conclusionsseen, FMF FMF 21 v |R| v provide tight upper lower boundsGaussian fractional Bethe free energies. turns pairwise normalizabilitysufficient condition message passing algorithm converge, alsonecessary condition Gaussian fractional Bethe free energies boundedbelow.model pairwise normalizable, lower bound bounded, directminimization message passing converging. experiments convergedminimum. suggests pairwise normalizable case, fractional Bethefree energies possess unique global minimum.model pairwise normalizable, none fractional Bethe free energiesbounded below. However, always range valuesfractional free energy possesses local minimum direct minimizationfractional message passing converge. Thus, decreasing towards zero, one gets18fiBethe Free Energies Message Passing Gaussian Models&!"&(!")*+,(-.*/0_(D(1"2"!3!""45*'6*(7_8!9:;<*=(>;?,0%!"%!"##!"!"""!"!"!"("!"!"!#!"'!"$!"!"Function value convergenceFunction value convergence6543210"!"!!"'#$!"!"201010765432101210Error variances convergenceNewton methodMessage passing110010110871(!"8Error variances convergence()*+,(-.*/0_(D(1"2"!3!""45*'6*(7_8!9:;<*=(>;?,0210010010102Newton methodMessage passing110010121001010210210102Figure 3: top panels show constrainedfractional Bethe free energies Gaussian model8 variables direction v = tumax , umax eigenvector corresponding max (|R|) max (|R|) = 0.9 (top-left) max (|R|) = 1.1 (top-right).thick lines functions FMF (dashed), FB (dashed dotted) lower boundFMF 12 v |R| v (continuous). thin lines constrained -fractional freeenergies Fc [102 , 102 ]. Center panels show final function valuesconvergence Newton method. bottom panelsshow || ||2 error approximation single node standard deviations = v. Missing values indicatenon-convergence.19fiCseke & Heskescloser mean field energy finite local minimum appear (Property A2Appendix). experienced suitable range s,s initial valuesfractional Gaussian message passing made converge.mentioned Section 2.1, ij correspond using local ij divergences applying power expectation propagation fully factorized approximating distribution.Seeger (2008) reports expectation propagation converge, applying powerexpectation propagation < 1 helps achieve convergence. case problemaddressed paper behavior explained observation smallmake finite local minima likely occur thus prevents covariance matricesbecoming indefinite even non positive definite. Although common reasonusing < 1 EP numerical robustness, also implies finding saddle point-fractional EP free energy. might interesting investigate whetherreason convergence likely case Gaussian fractional message passing.Wainwright et al. (2003) propose convexify Bethe free energy discrete modelschoosing ij sufficiently large fractional Bethe free energy uniqueglobal minimum. strategy appears fail Gaussian models. Convexification makespossibly useful finite local minima disappear, leaving unbounded global minimum. case general hybrid models, use convexification stillunclear.example Section 3 disproves conjecture work Welling Teh (2001):even Bethe free energy bounded below, possess finite localminimum message passing minimization algorithms converge.shown stable fixed points Gaussian fractional message passingalgorithms local minima fractional Bethe free energy. Although existencelocal minimum guarantee convergence message passing algorithm,practice experienced existence local minimum implies convergence.Based results, hypothesize pairwise normalizability hold,Gaussian Bethe free energy Gaussian message passing algorithm ( = 1)two types behavior:(1) Gaussian Bethe free energy possesses unique finite local minimumoptimization methods converge starting from, say, mean field solutionvi = 1/Qii ; Gaussian message passing corresponding unique stable fixedpoint, converge suitable starting point sufficient damping,(2) finite local minimum exists, thus, optimization messagepassing algorithm diverge.using fractional free energy fractional message passing varying ,one switch behaviors. Computing critical c (|R|) general |R|remains open question. believe properties free energies K-regularsymmetric models (Section 3), critical values easily computed, give goodinsight properties free energies general Gaussian models.20fiBethe Free Energies Message Passing Gaussian ModelsAcknowledgmentswould like thank Jason K. Johnson sharing ideas propertiesmessage passing algorithm K-regular models. would also like thank anonymousreviewers valuable comments earlier versions manuscript. researchreported paper supported VICI grant 639.023.604 NetherlandsOrganization Scientific Research (NWO).Appendix A. Properties ProofsLemma A1. (Watanabe & Fukumizu, 2009) graph G = (V, E), edge adjacencymatrix M() (defined Section 4.1), arbitrary vector w R|E| , onedet I|E| 1 diag (w) M() = det I|V | + 1 A(w)(1 wij wji ),ijAii (w) =Xijwij wji1 wij wjiAij (w) =wij.1 wij wjiProof: reproduce proof somewhat simplified form. Let us define Uij, = eTj ,Vij, = eTi ek k th unit vector RnSij,ij Sij,ji0 1,=Sji,ij Sji,ji1 0M() = U V S. Let us define W R|E||E| diagonal matrixwij,ij = wij . Using matrix determinant lemma readsdet 1 W U V= det + W 1 W U V= det 1 W U V (I + W S)1 det (I + W S)= det 1 V (I + W S)1 W U det (I + W S).(ij, ji) block (I + W S)1 W11wijwij101 wji wji wji0wji=11 wji wjiwijwji wijwij wjiwjithus, define V (I + W S)1 W UX wij wjiwijAi,i =Ai,j =.1 wij wji1 wij wjiijcompletes proof matrix determinant lemma (22) Section 4.2.21fiCseke & HeskesProperty A1. matrix M() = U V singular K-regular graphs= K.PProof: Let x R|E| =PM()x. yij = kj xjk xji . Let us fix j,yij = 0 means kj xjk = xji i. hold graphK-regular, = K xij equal xij = 0 pair indices ij.Property A2. suitably chosen > 0, exists constrainedfractional free energy Fc possesses local minimum 0 < < .Proof: Let us define vMF = argminv FM F (v)UMF = {v : FM F (v) FM F (vM F ) + 2} .form FM F implies always choose UMF proper subsetnnpositive quadrant R , words, UM F R+ . due properties FM F(continuous convex, unique finite global minimum attained finite value),domain UMF closed, bounded, convex vM F UM F \ UM F , is, vM Fncinterior UM F . Since FM F F (v) continuous R+ , set UM F closedbounded lim Fc (v) = FM F (v) (pointwise convergence) v Rn+ , follows Fc0cconverges uniformly UMF 0. This, together monotonicity F w.r.t. ,implies exists FM F (vM F ) < Fc (vM F ) < FM F (vM F ) 0 <. Let us fix . known that, since U< v UMFF closed bounded) + 2ccF continuous, F attains extrema UM F . Since FM F (v) = FM F (vMF)+ccv UM F F (v) > FM F (v) v UM F follows F (v) > FM F (vMFc).v UM F . chosen FM F (vM F ) < F (vM F ) < FM F (vMFlatter two conditions imply one extrema local minimum.interior UMFReferencesBickson, D. (2009). Gaussian Belief Propagation: Theory Application. Ph.D. thesis,Hebrew University Jerusalem.Cseke, B., & Heskes, T. (2008). Bounds Bethe free energy Gaussian networks.McAllester, D. A., & Myllymaki, P. (Eds.), UAI 2008, Proceedings 24thConference Uncertainty Artificial Intelligence, pp. 97104. AUAI Press.Heskes, T. (2003). Stable fixed points loopy belief propagation minima Bethefree energy. Becker, S., Thrun, S., & Obermayer, K. (Eds.), Advances NeuralInformation Processing Systems 15, pp. 359366, Cambridge, MA. MIT Press.Heskes, T., Opper, M., Wiegerinck, W., Winther, O., & Zoeter, O. (2005). Approximateinference techniques expectation constraints. Journal Statistical Mechanics:Theory Experiment, 2005, P11015.Heskes, T. (2004). uniqueness loopy belief propagation fixed points. NeuralComputation, 16, 23792413.Horn, R. A., & Johnson, C. (2005). Matrix Analysis. Cambridge University Press, Cambridge, UK.22fiBethe Free Energies Message Passing Gaussian ModelsJaakkola, T. (2000). Tutorial variational approximation methods. Opper, M., & Saad,D. (Eds.), Advanced mean field methods: theory practice, pp. 129160, Cambridge,MA. MIT Press.Johnson, J. K., Bickson, D., & Dolev, D. (2009). Fixing convergence Gaussian beliefpropagation. CoRR, abs/0901.4192.Malioutov, D., Johnson, J., & Willsky, A. (2006). Walk-sums belief propagationGaussian graphical models. Journal Machine Learning Research, 7, 20312064.Minka, T. P. (2004). Power EP. Tech. rep., Microsoft Research Ltd., Cambridge, UK,MSR-TR-2004-149.Minka, T. P. (2005). Divergence measures message passing. Tech. rep. MSR-TR-2005173, Microsoft Research Ltd., Cambridge, UK.Moallemi, C., & Roy, B. V. (2006). Consensus propagation. Weiss, Y., Scholkopf, B., &Platt, J. (Eds.), Advances Neural Information Processing Systems 18, pp. 899906.MIT Press, Cambridge, MA.Murphy, K., Weiss, Y., & Jordan, M. I. (1999). Loopy belief propagation approximateinference: empirical study. Proceedings Fifteenth Conference Uncertainty Artificial Intelligence, Vol. 9, pp. 467475, San Francisco, USA. MorganKaufman.Nishiyama, Y., & Watanabe, S. (2009). Accuracy loopy belief propagation Gaussianmodels. Neural Networks, 22 (4), 385 394.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufman Publishers, San Mateo, CA.Rusmevichientong, P., & Roy, B. V. (2001). analysis belief propagation turbodecoding graph Gaussian densities. IEEE Transactions Information Theory,47, 745765.Seeger, M. W. (2008). Bayesian inference optimal design sparse linear model.Journal Machine Learning Research, 9, 759813.Takahashi, K., Fagan, J., & Chin, M.-S. (1973). Formation sparse impedance matrixapplication short circuit study. Proceedings 8th PICA Conference.Wainwright, M., Jaakkola, T., & Willsky, A. (2003). Tree-reweighted belief propagationalgorithms approximate ML estimation via pseudo-moment matching. Bishop,C., & Frey, B. (Eds.), Proceedings Ninth International Workshop ArtificialIntelligence Statistics. Society Artificial Intelligence Statistics.Watanabe, Y., & Fukumizu, K. (2009). Graph zeta function Bethe free energyloopy belief propagation. Bengio, Y., Schuurmans, D., Lafferty, J., Williams, C.K. I., & Culotta, A. (Eds.), Advances Neural Information Processing Systems 22,pp. 20172025. MIT Press.Weiss, Y., & Freeman, W. T. (2001). Correctness belief propagation Gaussian graphicalmodels arbitrary topology. Neural Computation, 13 (10), 21732200.23fiCseke & HeskesWelling, M., & Teh, Y. W. (2001). Belief optimization binary networks: stable alternative loopy belief propagation. Breese, J. S., & Koller, D. (Eds.), Proceedings17th Conference Uncertainty Artificial Intelligence, pp. 554561. MorganKaufmann Publishers.Wiegerinck, W., & Heskes, T. (2003). Fractional belief propagation. Becker, S., Thrun,S., & Obermayer, K. (Eds.), Advances Neural Information Processing Systems 15,pp. 438445, Cambridge, MA. MIT Press.Yedidia, J. S., Freeman, W. T., & Weiss, Y. (2000). Generalized belief propagation.Advances Neural Information Processing Systems 12, pp. 689695, Cambridge, MA.MIT Press.Zoeter, O., & Heskes, T. (2005). Change point problems linear dynamical systems.Journal Machine Learning Research, 6, 19992026.24fiJournal Artificial Intelligence Research 41 (2011) 527-551Submitted 03/11; published 08/11Controlling Complexity Part-of-Speech InductionJoo V. GraaJOAO . GRACA @ L 2 F. INESC - ID . PTL2 F INESC-IDLisboa, PortugalKuzman GanchevKUZMAN @ GOOGLE . COMGoogle Inc.New York, NY, USALusa CoheurLUISA . COHEUR @ L 2 F. INESC - ID . PT2L F INESC-IDLisboa, PortugalFernando PereiraPEREIRA @ GOOGLE . COMGoogle Inc.Mountain View, CA, USABen TaskarTASKAR @ CIS . UPENN . EDUComputer & Information ScienceUniversity PennsylvaniaAbstractconsider problem fully unsupervised learning grammatical (part-of-speech) categories unlabeled text. standard maximum-likelihood hidden Markov modeltask performs poorly, weak inductive bias large model capacity. addressproblem refining model modifying learning objective control capacity via parametric non-parametric constraints. approach enforces word-category association sparsity,adds morphological orthographic features, eliminates hard-to-estimate parameters rarewords. develop efficient learning algorithm much computationally intensive standard training. also provide open-source implementation algorithm.experiments five diverse languages (Bulgarian, Danish, English, Portuguese, Spanish) achievesignificant improvements compared previous methods task.1. IntroductionPart-of-speech (POS) categories elementary building blocks syntactic analysis textplay important role many natural-language-processing tasks, machine translationinformation extraction. English handful languages fortunate enoughcomprehensive POS-annotated corpora Penn Treebank (Marcus, Marcinkiewicz,& Santorini, 1993), worlds languages extremely limited linguistic resources.unrealistic expect annotation efforts catch explosion unlabeled electronictext anytime soon. lack supervised data likely persist near futureinvestment required accurate linguistic annotation: took two years annotate 4,000 sentencessyntactic parse trees Chinese Treebank (Hwa, Resnik, Weinberg, Cabezas, & Kolak,2005) four seven years annotate 50,000 sentences across range languages (Abeill,2003).c2011AI Access Foundation. rights reserved.fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARSupervised learning taggers POS-annotated training text well-studied task,several methods achieving near-human tagging accuracy (Ratnaparkhi, 1996; Toutanova, Klein,Manning, & Singer, 2003; Shen, Satta, & Joshi, 2007). However, POS induction oneaccess labeled corpus difficult task much room improvement.recent literature, POS induction used refer two different tasks. first one,addition raw text, given dictionary containing possible tags wordgoal disambiguate tags particular word occurrence (Merialdo, 1994). secondtask, given raw text, dictionary provided; goal cluster wordsgrammatical behavior. work, target latter, challenging, unsupervised POSinduction task.Recent work task typically relies distributional morphological features, since wordsgrammatical function tend occur similar contexts common morphology (Brown, deSouza, Mercer, Pietra, & Lai, 1992; Schtze, 1995; Clark, 2003). However,statistical regularities enough overcome several challenges. First, algorithmdecide many clusters use broad syntactic categories (for instance, whether distinguishplural singular nouns). Second, category size distribution tends uneven. example, vast majority word types open class (nouns, verbs, adjectives), even amongopen class categories, many nouns adjectives. runs contrary learningbiases commonly-used statistical models. common failure models clump severalrare categories together split common categories.individual word types, third challenge arises ambiguity grammatical roleword sense. Many words take different POS tags different occurrences, dependingcontext occurrence (the word run either verb noun). approaches assume(for computational statistical simplicity) word one tag, aggregatinglocal contexts distributional clustering (Schtze, 1995). one-tag-per-wordassumption clearly wrong, across many languages annotated corpora,methods perform competitively methods assign different tags worddifferent contexts (Lamar, Maron, Johnson, & Bienenstock, 2010). partly due typicalstatistical dominance one tags word, especially corpus includes single genre,news. reason less restrictive models encode useful biaswords typically take small number tags.approaches make one-tag-per-word assumption take form hiddenMarkov model (HMM) hidden states represent word classes observationsword sequences (Brown et al., 1992; Johnson, 2007). Unfortunately, standard HMMs trainedmaximize likelihood perform poorly, since learned hidden classes align well truePOS tags. Besides potential model estimation errors due non-convex optimization involvedtraining, pernicious problem. Typical maxima likelihood align wellmaxima POS tag accuracy (Smith & Eisner, 2005; Graa, Ganchev, Pereira, & Taskar, 2009),suggesting serious mismatch model data.work, significantly reduce modeling mismatch combining three ideas:standard HMM treats words atomic units, without using orthographic morphological information. information critical generalization many languages (Clark,2003). address problem, reparameterize standard HMM replacing multinomial emission distributions maximum-entropy models (similar work Berg528fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONKirkpatrick, Bouchard-Ct, DeNero, & Klein, 2010 Graa, 2010). allows useorthographic morphological features emission model. Moreover, standardHMM model large number parameters: number tags times numberword types. presents extremely rich model space capable fitting irrelevant correlations data. address problem dramatically reduce number parametersmodel discarding features small support corpus, is, involvingrare words word parts.HMM model allows high level ambiguity tags word. result,maximizing marginal likelihood, common words typically tend associated everytag non-trivial probability (Johnson, 2007). However, natural property POScategories across many languages annotation standards word smallnumber allowed tags. address problem use posterior regularization (PR)framework (Graa, Ganchev, & Taskar, 2007; Ganchev, Graa, Gillenwater, & Taskar, 2010)constrain ambiguity word-tag associations via sparsity-inducing penaltymodel posteriors (Graa et al., 2009).show proposed extensions improves standard HMM performance,moreover, gains nearly additive. improvements significant across differentmetrics previously proposed task. instance, 1-Many metric, method attains10.4% average improvement regular HMM. also compare proposed methodeleven previously proposed approaches. languages English metrics except 1-1,method achieves best published results. Furthermore, method appears stableacross different testing scenarios always shows competitive results. Finally, showinduced tags used improve performance supervised POS tagging systemlimited labeled data scenario. open-source software POS induction evaluationavailable http://code.google.com/p/pr-toolkit/.paper organized follows. Section 2 describes basic HMM POS inductionmaximum-entropy extension. Section 3 describes standard EM sparsity-inducing estimationmethod. Section 4 presents comprehensive survey previous fully unsupervised POS inductionmethods. Section 5 provide detailed experimental evaluation method. Finally,Section 6, summarize results suggest ideas future work.2. Modelsmodel experiments based first order HMM. denote sequencewords sentence boldface x sequence hidden states correspond partof-speech tags boldface y. sentence length l, thus l hidden state variablesyi {1, . . . , J}, 1 l J number possible POS tags, l observation variablesxi {1, . . . , V }, 1 l, V number word types. simplify notation, assumeevery tag sequence prefixed conventional start tag y0 = start, allowing us writep(y1 |y0 ) initial state probability HMM.probability sentence x along particular hidden state sequence given by:p(x, y) =lpt (yi | yi1 )po (xi | yi ),i=1529(1)fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARpo (xi | yi ) probability observing word xi given state yi (emissionprobability), pt (yi | yi1 ) probability state yi , given previous hiddenstate yi1 (transition probability).2.1 Multinomial Emission ModelStandard HMMs use multinomial emission transition probabilities. is, generic wordxi tag yi , observation probability po (xi | yi ) transition probability pt (yi | yi1 )multinomial distributions. experiments refer model simply HMM. modellarge number parameters large number word types (see Table 1).common convention follow lowercase words well map words occurringcorpus special token unk.2.2 Maximum Entropy Emission Modelwork, use simple modification HMM model discussed previous section:represent conditional probability distributions maximum entropy (log-linear) models. Specifically, emission probability expressed as:exp( f (x, y))0x0 exp( f (x , y))po (x|y) = P(2)f (x, y) feature function, x ranges word types, model parameters.refer model HMM+ME. addition word identity, features include orthographyand morphology-inspired cues presence capitalization, digits, common suffixes.feature sets described Section 5. idea replacing multinomial models HMMmaximum entropy models new applied different domains (Chen,2003), well POS induction (Berg-Kirkpatrick et al., 2010; Graa, 2010). key advantagerepresentation allows much tighter control expressivenessmodel. many languages helpful exclude word identity features rare words orderconstrain model force generalization across words similar features. Unlike mappingrare words unk token multinomial setting, maxent model still capturesinformation word features. Moreover, reduce numberparameters even using lowercase word identities still keeping case informationusing case feature. Table 1 shows number features used different corpora. Notereduced feature set order magnitude fewer parameters multinomial model.3. LearningSection 5 describe experiments comparing HMM model model threelearning scenarios: maximum likelihood training using EM algorithm (Dempster, Laird, & Rubin, 1977) HMM HMM+ME, gradient-based likelihood optimization HMM+MEmodel, PR sparsity constraints (Graa et al., 2009) HMM HMM+ME.section describes three learning algorithms.following, denote whole corpus, list sentences, X = (x1 , x2 , . . . , xN )corresponding tag sequences = (y1 , y2 , . . . , yN ).530fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION3.1 Maximum Likelihood EMStandard HMM training seeks model parameters maximize log-likelihood observeddata:Xp (X, Y)(3)Log-Likelihood: L() = logX whole corpus. Since model assumes independence sentences ,logXp (X, Y) =NXlogX(4)ynn=1p (xn , yn ),use corpus notation consistency Section 3.3. latent variablesY, log-likelihood function HMM model convex model parameters,model fitted using EM algorithm. EM maximizes L() via block-coordinate ascent lowerbound F (q, ) using auxiliary distribution latent variables q(Y) (Neal & Hinton, 1998).Jensens inequality, define lower-bound F (q, ) as:L() = logXq(Y)p (X, Y) Xp (X, Y)q(Y) log= F (q, ).q(Y)q(Y)(5)rewrite F (q, ) as:F (q, ) =Xq(Y) log(p (X)p (Y|X))Xq(Y) log q(Y)(6)q(Y)q(Y) logp (Y|X)(7)= L() KL(q(Y)||p (Y|X)).(8)= L()XUsing interpretation, view EM performing coordinate ascent F (q, ). Startinginitial parameter estimate 0 , algorithm iterates two block-coordinate ascent stepsconvergence criterion reached:E : q t+1 = arg max F (q, ) = arg min KL(q(Y) k pt (Y | X))q(9)q: t+1 = arg max F (q t+1 , ) = arg max Eqt+1 [log p (X, Y)](10)E-step corresponds maximizing Eq. 8 respect q M-step correspondsmaximizing Eq. 6 respect . EM algorithm guaranteed converge localmaximum L() mild conditions (Neal & Hinton, 1998). HMM POS tagger,E-Step computes posteriors pt (y|x) latent variables (POS tags) given observedvariables (words) current parameters sentence. accomplished forwardbackward algorithm HMMs. EM algorithm together forward-backward algorithmHMMs usually referred BaumWelch algorithm (Baum, Petrie, Soules, & Weiss,1970).step uses q t+1 (qnt+1 posteriors given sentence) fill values tagsestimate parameters t+1 . Since HMM model locally normalized features used531fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARdepend tag word identities particular position occur,optimization decouples following way:Eqt+1 [log p (X, Y)] ==NXEqnt+1 [logn=1lnN XXlnnpt (yin | yi1)po (xni | yin )](11)i=1nEqnt+1 log pt (yin | yi1) + Eqnt+1 log po (xni | yin )(12)n=1 i=1multinomial emission model, optimization particularly easy simply involvesnormalizing (expected) counts parameter. maximum-entropy emission model parameterized Equation 2, closed form solution need solve unconstrainedoptimization problem. possible hidden tag value solve two problems: estimate emission probabilities po (x|y) estimate transition probabilities pt (y 0 |y),gradient one givenEqt+1 [log p (X, Y)]= Eqt+1 f (X, Y) Ep (X0 |Y) [f (X0 , Y)] ,(13)similar gradient supervised models, except expectationq t+1 (Y) instead observed Y. optimization done using L-BFGS Wolfes ruleline search (Nocedal & Wright, 1999).3.2 Maximum Likelihood Direct Gradientlikelihood traditionally optimized EM, Berg-Kirkpatrick et al. (2010) findHMM maximum entropy emission model, higher likelihood better accuracyachieved gradient-based likelihood-optimization method. use L-BFGSexperiments. derivative likelihood is,L()11Xlog p (X) =p (X) =p (X, Y)p (X)p (X)X 1X p (X, Y)=p (X, Y) =log p (X, Y)p (X)p (X)X=p (Y|X) log p (X, Y),=(14)(15)(16)exactly derivative M-Step. Equation 14 apply chainrule take derivative log p (X), Equation 15 apply chain rule reversedirection. biggest difference EM procedure direct gradient EMfix counts E-Step optimize model using counts. directlyoptimizing likelihood need recompute counts parameter setting,expensive. Appendix gives detailed discussion methods.3.3 Controlling Tag Ambiguity PROne problem unsupervised HMM POS tagging maximum likelihood objective mayencourage tag distributions allow many different tags word given context.532fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION106SupervisedHMMHMM+MEHMM+SpHMM+ME+Sp8L1L8L1L10SupervisedHMMHMM+MEHMM+SpHMM+ME+Sp426420001000 2000 3000 4000 5000 6000 7000 80000200 400 600 800 1000 1200 1400 1600 1800rank word L1Lrank word L1LFigure 1: ambiguity measure (`1 /` ) word type two corpora supervisedmodel, EM training (HMM, HMM+ME), train ambiguity penaltydescribed Section 3.3 (HMM+Sp, HMM+ME+Sp). Left:En, Right:Pt.find actual text linguist-designed tags, tags designed informativewords grammatical role. following paragraphs describe measure tag ambiguityproposed Graa et al. (2009) attempt control. easier understand measurehard tag assignments, start thene extend discussion distributionstags.Consider word stock. Intuitively, would like occurrences stocktagged small subset possible tags (noun verb, case). hard assignmenttags entire corpus, Y, could count many different tags used occurrencesword stock.instead single tagging corpus, distribution q(Y) assignments,need generalize ambiguity measure. Instead asking particular tag ever usedword stock, would ask maximum probability particular tagused word stock. instead counting number tags, would sumprobabilities.motivation, Figure 1 shows distribution tag ambiguity across words two corpora.see Figure 1, train using EM procedure described Section 3.1,HMM models grossly overestimates tag ambiguity almost words. Howevermodels trained using PR penalize tag ambiguity, models (HMM+Sp,HMM+ME+Sp) achieve tag ambiguity closer truth.formally, Graa et al. (2009) define measure terms constraint features (X, Y).Constraint feature wvj (X, Y) takes value 1 j th occurrence word type w X assignedtag v tag assignment Y. Consequently, probability j th occurrence word wtag v label distribution q(Y) Eq [wvj (X, Y)]. ambiguity measurementword type w becomes:XAmbiguity Penalty word type w:max Eq(Y) [wvj (X, Y)] .(17)vjsum maxima also called `1 /` mixed norm. brevity use norm notation ||Eq [w ]||1/ . computational reasons, add penalty term based ambiguity model distribution p (Y|X), instead introduce auxiliary distribution q(Y)533fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARmust close p also must low ambiguity. modified objective becomesX||Eq [w (X, Y)]||1/ .max L() KL(q(Y)||p (Y|X)),q(18)wGraa et al. (2009) optimize objective using algorithm similar EM. added complexity implementing algorithm lies computing Kullback-Leibler projectionmodified E-Step. However, computation involves choosing distribution exponentiallymany objects (label assignments). Luckily, Graa et al. (2009) show dual formulationE-Step manageable. given by:!XXmax logp (Y|X) exp( (X, Y))s. t.wvj(19)0jvector dual parameters wvj , one wvj . projected distributiongiven by: q(Y) p (Y|X) exp ( (X, Y)). Note p given HMM, qsentence expressedq(yn )npt (yin | yi1)qo (xni | yin ),(20)i=1qo (xi |yi ) = po (xi |yi ) exp(xi yi j ) act modified (unnormalized) emission probabilities.objective Equation 19 negative sum log probabilities sentencesq plus constant. compute running forward-backward corpus, similarE-Step normal EM. gradient objective also computed using forwardbackward algorithm. Note objective Eq. 19 concave respectoptimized using variety methods. perform dual optimization projected gradient,using fast simplex projection algorithm described Bertsekas, Homer, Logan, Patek(1995). experiments found taking projected gradient steps enough,performing optimization convergence helps results.4. Related WorkPOS tags place words classes share commonalities (classes of) wordscooccur with. Therefore, natural ask whether word clustering methods based wordcontext distributions might able recover word classification inherent POS tag set.Several influential methods, notably mutual-information clustering (Brown et al., 1992),used cluster words according immediately contiguous words distributed.Although methods explicitly designed POS induction, resulting clusters capture syntactic information (see also Martin, Liermann, & Ney, 1998, different methodsimilar objective). Clark (2003) refined distributional clustering approach addingmorphological word frequency information, obtain clusters closely resemble POStags.forms distributional clustering go beyond immediate neighbors word represent whole vector coocurrences target word within text window, comparevectors using suitable metric, cosine similarity. However, wider-range similarities problems capturing local regularities. instance, adjective noun might534fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONlook similar noun tends used noun-noun compounds; similarly, two adjectivesdifferent semantics selectional preferences might used different contexts. Moreover,problem aggravated data sparsity. example, infrequent adjectives modify different nouns tend completely disjoint context vectors (but even frequent words likemight completely different context vectors, since articles used disjoint rightcontexts). alleviate problems, Schtze (1995) used frequency cutoffs, singular-value decomposition co-occurrence matrices, approximate co-clustering two stages SVD,clusters first stage used instead individual words provide vector representations second-stage clustering.Lamar, Maron Johnson (2010) recently revised two-stage SVD model Schtze(1995) achieve close state-of-the-art performance. revisions relatively small,touch several important aspects model: singular vectors scaled singular valuespreserve geometry original space; latent descriptors normalized unit length;cluster centroids computed weighted average constituent vectors based wordfrequency, rare common words treated differently centroids initializeddeterministic manner.final class approaches include work paper uses sequence model,HMM, represent probabilistic dependencies consecutive tags.approaches, observation corresponds particular word hidden state correspondscluster. However, noted Clark (2003) Johnson (2007), using maximum likelihoodtraining models achieve good results: maximum likelihood training tends resultambiguous distributions common words, contradiction rather sparse wordtag distribution. Several approaches proposed mitigate problem. Freitag (2004)clusters frequent words using distributional approach co-clustering. clusterremaining (infrequent) words, author trains second-order HMM emission probabilities frequent words fixed clusters found earlier emission probabilitiesremaining words uniform.Several studies propose using Bayesian inference improper Dirichlet prior favorsparse model parameters hence indirectly reduce tag ambiguity (Johnson, 2007; Gao & Johnson, 2008; Goldwater & Griffiths, 2007). refined Moon, Erk, Baldridge(2010) representing explicitly different ambiguity patterns function content words.Lee, Haghighi, Barzilay (2010) take direct approach reducing tag ambiguity explicitly modeling set possible tags word type. model first generates tagdictionary assigns mass one tag word type reflect lexicon sparsity. dictionary used constrain Dirichlet prior emission probabilities drawnsupport word-tag pairs dictionary. token-level HMM usingemission parameters transition parameters draw symmetric Dirichlet prior usedtagging entire corpus. authors also show improvements using morphological featurescreating dictionary. system achieves state-of-art results several languages.noted common issue sparsity-inducing approaches sparsityimposed parameter level, probability word given tag, desired sparsityposterior level, probability tag given word. Graa et al. (2009) use PR frameworkpenalize ambiguous posteriors distributions words given tokens, achieves better resultsBayesian sparsifying Dirichlet priors.535fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARrecently, Berg-Kirkpatrick et al. (2010) Graa (2010) proposed replacing multinomial distributions HMM maximum entropy (ME) distributions. allows use features capture morphological information, achieve promising results. Berg-Kirkpatricket al. (2010) also find optimizing likelihood L-BFGS rather EM leads substantial improvements, show case beyond English.also note briefly POS induction methods rely prior tag dictionary indicatingword type POS tags have. POS induction task then, word tokencorpus, disambiguate possible POS tags, described Merialdo (1994). Unfortunately, availability large manually-constructed tag dictionary unrealistic muchlater work tries reduce required dictionary size different ways, generalizingsmall dictionary handful entries (Smith & Eisner, 2005; Haghighi & Klein, 2006;Toutanova & Johnson, 2007; Goldwater & Griffiths, 2007). However, although approach greatlysimplifies problem words one tag and, furthermore, cluster-tag mappings predetermined, thus removing extra level ambiguity accuracy methodsstill significantly behind supervised methods. address remaining ambiguity imposingadditional sparsity, Ravi Knight (2009) minimize number possible tag-tag transitionsHMM via integer program. Finally, Snyder, Naseem, Eisenstein, Barzilay (2008) jointlytrain POS induction system parallel corpora several languages, exploiting factdifferent languages present different ambiguities.5. Experimentssection present encouraging results validating proposed method six different testingscenarios according different metrics. highlights are:maximum-entropy emission model Markov transition model trained ambiguity penalty improves regular HMM cases average improvement10.4% (according 1-Many metric).compared broad range recent POS induction systems, method producesbest results languages except English. Furthermore, method seems less sensitiveparticular test conditions previous methods.induced clusters useful features training supervised POS taggers, improving testaccuracy much clusters learned competing methods.5.1 Corporaexperiments test several POS induction methods five languages help manually POS-tagged corpora languages. Table 1 summarizes characteristics test corpora:Wall Street Journal portion Penn Treebank (Marcus et al., 1993) (we consider17-tag version Smith & Eisner, 2005 (En17) 45-tag version (En45)); Bosque subsetPortuguese Floresta Sinta(c)tica Treebank (Afonso, Bick, Haber, & Santos, 2002) (Pt);Bulgarian BulTreeBank (Simov et al., 2002) (Bg) (with 12 coarse tags); Spanish corpus Cast3LB treebank (Civit & Mart, 2004) (Es); Danish Dependency Treebank(DDT) (Kromann, Matthias T., 2003) (Dk).536fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONEnPtBgEsDk1Sentences49208935914187351256202Types49206294893492816858194003LUnk49.28%37.83%39.26%37.73%26.30%4Tokens117376621254521493095028650575Tags17 (45)221247306Avg. `1 /`1.08 (1.11)1.021.021.051.057Total `1 /`6523.6 (6746.2)1144.63252.9818.9795.88|w|154334332933863318962216789|w|2785621142287951969Table 1: Corpus statistics. third column shows percentage word types lower-casingeliminating word types occurring once. sixth seventh columns showinformation word ambiguity corpus average totality (corresponding penalty Equation 17). eighth ninth columns show numberparameters different feature sets, described Section 5.3.5.2 Experimental Setupcompare work two kinds methods: induce single cluster wordtype (type-level tagging), allow different tags different occurrences word type(token-level tagging). type-level tagging, use two standard baselines, B ROWN C LARK,described Brown et al. (1992)1 Clark (2003)2 . Following Headden, McClosky, Charniak (2008), trained C LARK system 5 10 hidden states letter HMMran 10 iterations; B ROWN system run according instructions accompanyingcode. also ran recently proposed LDC system (Lamar, Maron, & Bienenstock, 2010)3 ,configuration described paper PTB45 PTB17, PTB17 configurationcorpora. noted carry experiments SVD2system (Lamar, Maron Johnson, 2010), since SVD2 superseded LDC accordingauthors.token-level tagging, experimented feature-rich HMM presented BergKirkpatrick et al. (2010), trained using EM training (BK+EM) direct gradient (BK+DG),using configuration provided authors4 . report results type-level HMM(TLHMM) (Lee et al., 2010) applicable, since able run system. Moreover,compared systems implementation various HMM-based approaches:HMM multinomial emission probabilities (Section 2.1), HMM maximumentropy emission probabilities (Section 2.2) trained EM (HMM+ME), trained direct gradient (HMM+ME+DG), trained using PR ambiguity penalty, described Section 3.3(HMM+Sp multinomial emissions, HMM+ME+Sp maximum-entropy emissions).addition, also compared multinomial HMM sparsifying Dirichlet prior parameters (HMM+VB) trained using variational Bayes (Johnson, 2007).Following standard practice, multinomial HMMs use morphological information, lowercase corpora replace unique words special unknown token,improves multinomial HMM results decreasing number parameters eliminating1.2.3.4.Implementation: http://www.cs.berkeley.edu/~pliang/software/brown-cluster-1.2.zipImplementation: http://www.cs.rhul.ac.uk/home/alexc/pos2.tar.gzImplementation provided Lamar, Maron Bienenstock (2010).Implementation provided Berg-Kirkpatrick et al. (2010).537fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARrare words (mostly nouns). Since maximum-entropy emission models access morphological features, preprocessing steps improve performance performcase.start EM, randomly initialize implementations HMM-based modelsposteriors, obtained running E-step HMM model set randomparameters: close uniform random uniform jitter 0.01. means randomseed, initialization identical models.EM variational Bayes training, train model 200 iterations, since foundtypically models tend converge iteration 100. HMM+VB model fixtransition prior5 0.001 test emission prior equal 0.1 0.001, correspondingbest values reported Johnson (2007).PR training, initialize 30 EM iterations run 170 iterations PR, following Graa et al. (2009). used results worked best English (En17) (Graa et al.,2009), regularizing words occur least 10 times, = 32, use configuration scnenarios. setting specifically tuned test languages,might optimal every language. Setting parameters unsupervised mannerdifficult task address (Graa, 2010 discusses experiments differentvalues parameters).obtain hard assignments using posterior decoding, position pick labelhighest posterior probability, since showed small consistent improvements Viterbidecoding. experiments required random initialization parameters reportaverage 5 random seeds.experiments run using number true tags number clusters, resultsobtained test set portion corpus. evaluate systems using four common metricsPOS induction: 1-Many mapping, 1-1 mapping (Haghighi & Klein, 2006), variation information (VI) (Meila, 2007), validity measure (V) (Rosenberg & Hirschberg, 2007). metricsdescribed detail Appendix B.5.3 HMM+ME+Sp Performancesection compares gains using feature-rich representation ambiguity penalty, described Section 3.3. Experiments show feature-rich representation always improves performance, ambiguity penalty also always improvesperformance. Then, see improvements two methods combine additively,suggesting address independent aspects POS induction.use two different feature sets: large feature set Berg-Kirkpatrick et al. (2010),reduced feature set described Graa (2010). apply count-based feature selection identity suffix features. Specifically, add identity features wordsoccurring least 10 times suffix features words occurring least 20 times. also addpunctuation feature. follows, refer large feature set feature set 1 reducedfeature set 2. total number features model language given Table 1.results experiments summarized Table 2.Table 2 shows results 10 training methods across six corpora four evaluation metrics,resulting 240 experimental conditions. simplify discussion, focus 1-Many metric5. transition prior significantly affect results, report results different values.538fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTION1234567891012345678910HMMHMM+SpHMM+ME1 Prior 1HMM+ME1 Prior 10HMM+ME2 Prior 1HMM+ME2 Prior 10HMM+ME+Sp1 Prior 1HMM+ME+Sp1 Prior 10HMM+ME+Sp2 Prior 1HMM+ME+Sp2 Prior 10En4562.467.567.170.070.369.971.468.871.671.1En1765.670.372.269.271.871.071.771.172.572.01-ManyPT BG64.9 58.971.2 65.072.3 61.166.8 58.273.9 62.474.1 63.975.1 63.071.6 62.273.4 60.976.9 67.1DK60.067.565.163.966.567.864.568.265.072.01-1ES PTB45 PTB17 PT BG DK ES60.2 42.543.5 42.2 40.6 37.4 30.669.0 46.152.5 47.7 46.3 40.0 35.371.8 45.051.1 46.3 46.1 42.6 40.866.2 48.445.6 40.8 41.7 41.1 35.172.9 45.149.8 46.8 46.7 45.0 42.673.4 47.351.2 48.8 48.8 44.7 37.172.8 49.452.5 46.6 46.7 43.1 41.169.3 45.152.1 48.0 49.7 42.0 38.572.1 52.553.9 45.5 49.5 43.0 38.675.2 46.748.5 49.6 53.4 48.7 40.8HMMHMM+SpHMM+ME1 Prior 1HMM+ME1 Prior 10HMM+ME2 Prior 1HMM+ME2 Prior 10HMM+ME+Sp1 Prior 1HMM+ME+Sp1 Prior 10HMM+ME+Sp2 Prior 1HMM+ME+Sp2 Prior 10En454.223.643.773.313.593.283.203.463.213.41En173.753.203.113.383.123.243.093.153.043.25VIPT BG3.90 4.043.27 3.493.21 3.463.66 3.833.05 3.463.12 3.443.00 3.383.15 3.433.16 3.372.86 3.12DK4.553.853.774.133.713.743.803.733.723.35VES PTB45 PTB17 PT BG DK ES4.89 .558.479 .490 .383 .432 .4743.85 .616.549 .573 .467 .518 .5813.56 .606.564 .583 .460 .519 .6084.11 .649.530 .527 .406 .482 .5533.46 .626.559 .600 .460 .528 .6173.58 .652.546 .596 .471 .530 .6103.49 .660.560 .608 .478 .514 .6173.76 .637.557 .591 .470 .532 .5893.46 .658.567 .591 .473 .523 .6163.34 .644.541 .631 .519 .578 .636Table 2: Results different HMMs. HMM HMM+Sp HMMs multinomial emissionfunctions trained using EM PR sparsity constraints, respectively. HMM+MEHMM+ME+Spare HMMs maximum entropy emission model trained using EMPR sparsity constraints. feature-rich models, superscript 1 represents largefeature set, superscript 2 represents reduced feature set. Prior 1 10 refersregularization strength emission model. Table entries results averaged5 runs. Bold indicates best system overall.(top left tab Table 2), observe conclusions hold three evaluationmetrics also. Table 2 conclude following:Adding penalty high word-tag ambiguity improves performance multinomialHMM. multinomial HMM trained EM (line 1 Table 2) always worsemultinomial HMM trained PR ambiguity penalty, 6.5% average (line 2Table 2).feature-rich maximum entropy HMMs (lines 3-6 Table 2) almost always perform bettermultinomial HMM. true feature sets regularization strengthsused, average increase 6.4%. exceptions possibly due suboptimal regularization.Adding penalty high word-tag ambiguity maximum-entropy HMM improves performance. almost cases, comparing lines 3-6 lines 7-10 Table 2, sparsityconstraints improve performance (average improvement 1.6%). combined system al539fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARalways outperforms multinomial HMM trained using ambiguity penaltyaverage improvement 1.6%. every corpus best performance achievedmodel ambiguity penalty maximum-entropy emission probabilities.every language except English 17 tags particular feature configuration, reducing feature set excluding rare features improves performance average 2.3% (lines5-6 better lines 3-4 Table 2).Regularizing maximum-entropy model important many featuresword-tag ambiguity penalty. Lines 3-4 Table 2maximum-entropy HMM many features, see tight parameter prioralmost always out-performs looser prior. contrast, looking lines 9-10 Table 2 see ambiguity penalty fewer features looser prioralmost always better tighter parameter prior. observed also Graa (2010).encouraging see improvements using feature-rich model additiveeffects penalizing tag-ambiguity. especially surprising since optimize strength tag-ambiguity penalty maximum-entropy emission HMM, ratherused value reported Graa et al. (2009) work multinomial emission HMM. Experiments reported Graa (2010) show tuning parameter improve performance.Nevertheless, methods regularize objective different ways interactionaccounted for. would interesting use L1 regularization models, insteadL22 regularization together feature count cutoff. way model could learn features discard, instead requiring predefined parameter depends particular corpuscharacteristics.reported Berg-Kirkpatrick et al. (2010), way objective optimizedbig impact overall results. However, due non-convex objective functionunclear optimization method works better why. briefly analyze questionAppendix leave open question future work.5.4 Error AnalysisFigure 2 shows distribution true tags clusters HMM model (left)HMM+ME+Sp model (right) En17 corpus. bar represents cluster, labeled tagassigned performing 1-Many mapping. colors represent number wordscorresponding true tag. reduce clutter, true tags never used label clustergrouped Others.observe models split common tags nouns several hidden states.splitting accounts many errors models. using 5 states nouns instead7, HMM+ME+Sp able use states adjectives. Another improvement comesbetter grouping prepositions. example grouped punctuation HMMHMM+ME+Sp correctly mapped prepositions. Although correctbehavior, actually hurts, since tagset special tag occurrences wordincorrectly assigned, resulting loss 2.2% accuracy. contrast, HMM statemapped tag word comprises one fifth state. commonerror made HMM+ME+Sp include word second noun induced tagFigure 2 (Right). induced tag contains mostly capitalized nouns pronouns, often540fiPREPDETNADJRPUNCPOSVINPUNCCONJEPUNCOthersPREPDETNADJRPUNCPOSVINPUNCCONJCONJENDPUNCVINPUNCVVADJRPUNCADJNADJNNNNDETPREPENDPUNCCONJVINPUNCVPOSNADJNNNNNNDETPREPC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONEPUNCOthersFigure 2: Induced tags HMM model (Left), HMM+ME+Sp model (Right)En17 corpus. column represents hidden state, labeled 1-Manymapping. Unused true tags grouped cluster named Others.25000250002000020000150001500010000100005000500000artnadjpropv-finprppuncnumadvv-pcpv-infconj-cpron-perssumOthersartnadjpropv-finprppuncnumadvv-pcpv-infconj-cpron-perssumOthersFigure 3: Induced tags HMM model (Left), HMM+ME+Sp model (Right)Pt corpus. column represents hidden state, labeled 1-Many mapping.Unused true tags grouped cluster named Others.precede nouns induced tags. suspect capitalization feature causeerror.better performance feature-based models Portuguese relative English may dueability features better represent richer morphology Portuguese. Figure 3 showsinduced clusters Portuguese. HMM+ME+Sp model improves HMM tagsexcept adjectives. models trouble distinguishing nouns adjectives. reducedaccuracy adjectives HMM+ME+Sp explained mapping single cluster containingadjectives adjectives HMM model nouns HMM+ME+Sp model.Removing noun-adjective distinction, suggested Zhao Marcus (2009), would increaseperformance models 6%. Another qualitative difference observedHMM+ME+Sp model used single induced cluster proper nouns rather spreadingacross different clusters.541fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR5.5 State-of-the-Art Comparisoncompare best POS induction system (based settings line 10 Table 2),recent systems. Results summarized Table 3. previously done Table 2,focus discussion 1-Many evaluation metric, results qualitativelyVI V metrics, 1-1 metric shows variance across languages.1-ManyPT BG69.6 63.266.0 62.367.1 57.069.2 61.164.9 58.961.5 51.563.2 53.571.2 65.072.3 64.372.5 56.174.572.0 76.9 67.1DK69.657.358.260.960.051.256.667.562.860.661.272.01-1ES PTB45 PTB17 PT BG DK ES69.7 53.356.6 43.8 47.9 44.3 41.267.6 52.343.1 47.3 50.3 37.5 37.470.1 52.344.2 48.1 45.2 37.5 40.067.9 48.650.0 42.6 50.1 35.2 38.860.2 42.543.5 42.2 40.6 37.4 30.645.5 48.150.3 51.4 42.0 42.7 35.955.9 44.151.4 45.1 38.3 38.1 34.469.0 46.152.5 47.7 46.3 40.0 35.372.0 48.354.4 45.5 50.6 41.5 37.273.7 54.547.9 42.9 38.8 41.5 40.468.9 50.964.152.1 58.375.2 46.748.5 49.6 53.4 48.7 40.8VIPT BG3.34 3.303.38 3.303.28 3.603.50 3.513.90 4.043.65 3.903.97 4.073.27 3.493.19 3.303.29 3.892.86 3.12DK3.413.973.994.244.554.204.413.853.904.153.35VES PTB45 PTB17 PT BG DK ES3.40 .648.559 .564 .473 .554 .6133.76 .660.498 .545 .475 .490 .5883.55 .663.499 .557 .424 .485 .6104.00 .626.585 .546 .450 .474 .5694.89 .558.479 .490 .383 .432 .4744.40 .534.500 .477 .368 .405 .4024.69 .535.501 .471 .368 .437 .4743.85 .616.549 .573 .467 .518 .5814.15 .645.568 .582 .479 .477 .5963.56 .678.534 .574 .392 .477 .6113.34 .644.541 .631 .519 .578 .636123456789101112En45B ROWN68.7C LARK572.4C LARK1072.5LDC67.5HMM62.4HMM+VB0.155.0HMM+VB0.00158.6HMM+Sp67.5BK+EM69.1BK+DG75.8TLHMM62.2HMM+ME+Sp2 Prior 10 71.1En1768.763.563.274.765.667.267.770.372.167.91234567891012En45B ROWN3.17C LARK53.23C LARK103.20LDC3.43HMM4.22HMM+VB0.14.10HMM+VB0.0014.38HMM+Sp3.64BK+EM3.31BK+DG3.01HMM+ME+Sp2 Prior 10 3.41En173.073.453.463.003.753.523.553.203.043.213.25Table 3: Comparing HMM+ME+Sp2 several POS induction systems. resultsmodels random initialization run (systems: 2,3,5,6,7,8,9,10,12) representaverage 5 runs. See Section 5.5 details discussion.Lines 1-3 Table 3 show clustering algorithms based information gain various metrics. B ROWN wins 5/6 times (in scenarios fewer clusters) C LARK system, despitefact C LARK uses morphology. Comparing lines 1-3 Table 3 line 4, seeLDC system particularly strong En17 achieves state-of-the-art results, behavesworse B ROWN system every corpus.HMMs multinomial emissions (lines 5-8 Table 3), maximum likelihood training (HMM) parameter sparsity (HMM+VB) perform worse adding ambiguity penalty(HMM+Sp). holds evaluation metrics, exception 1-1. confirms previous results Graa et al. (2009). Comparing models lines 5-8 lines 1-3, see542fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONbest HMM (HMM+Sp) performs comparably best clustering (B ROWN), onemodel winning 3 languages remaining 3.feature rich HMMs (BK+EM BK+DG) perform well, achieving resultsbetter HMM+Sp 4 6 tests. Even though optimize objective, achievedifferent results different corpora. explore training procedure detail Appendix A, comparing also implementation Berg-Kirkpatrick et al. (2010). brevity,Table 3 contains results implementation Berg-Kirkpatrick et al. (2010).implementation produces comparable, quite identical results.Lines 11-12 Table 3 display two methods attempt control tag ambiguityfeature-rich representation capture morphological information. results TLHMMtaken Lee et al. (2010), report results En17 Bg corpora. Also,able rerun experiments TLHMM, able computeinformation-theoretic metrics. Consequently, comparison TLHMM slightly less completemethods. TLHMM HMM+ME+Sp perform competitively bettersystems. surprising since ability model morphologicalregularity also penalizing high ambiguity. Comparing TLHMM HMM+ME+Sp, seeHMM+ME+Sp performs better 1-Many metric. contrast, TLHMM performs better1-1. One possible explanation underlying model TLHMM Bayesian HMMsparsifying Dirichlet priors. noted Graa et al. (2009), models trained way tendcluster distribution closely resemble true POS distribution (some clusters lotswords words) favors 1-1 metric (a description particularity1-1 metric discussed Appendix B).summarize, non-English languages metrics except 1-1, HMM+ME+Spsystem performs better systems. English, BK+DG wins 45-tag corpus,LDC wins 17-tag corpus. HMM+ME+Sp system fairly robust, performing wellcorpora best several them, allow us conclude tunedparticular corpus evaluation metric.performance HMM+ME+Sp tightly related performance underlyingHMM+ME system. Appendix present discussion performance different optimization methods HMM+ME. compare HMM+ME implementation BK+EMBK+DG show significant differences performance. However,clear results one better, performs better given situation.mentioned Clark (2003), morphological information particularly useful rare words.Table 4 compares different models accuracy words according frequency. compare clustering models based information gain without morphological information(B ROWN,C LARK), distributional information-based model (LDC), feature rich HMMtag ambiguity control (HMM+ME+Sp). expected see systems using morphologybetter rare words. Moreover systems improve almost categories exceptcommon words (words occurring 50 times). Comparing HMM+ME+Sp C LARK,see even condition C LARK overall works better (En45), still performs worserare words HMM+ME+Sp.543fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKAR151050> 50B ROWN50.0761.7664.3267.1368.94C LARK49.4862.8966.5367.6273.87151050> 50B ROWN31.4448.0663.1466.3080.61C LARK44.5353.3064.3367.5274.68151050> 50B ROWN41.0461.7572.1064.4486.43C LARK49.9364.0369.7657.6773.69En45LDC50.6558.7061.7864.2868.04PTLDC19.1936.6754.1662.5684.58ESLDC38.7551.9461.6956.7481.94HMM+ME+Sp270.1272.1270.5970.8071.49B ROWN29.4243.3850.9459.1672.14C LARK60.6269.3071.1371.5062.04HMM+ME+Sp263.5168.6072.3571.3279.52B ROWN32.5548.1856.5960.1574.01C LARK52.2565.0069.5168.9561.89HMM+ME+Sp268.6572.0573.3559.9482.11B ROWN37.7149.5458.9060.4282.82C LARK43.5848.6251.9255.8760.88En17LDC53.3964.0367.3568.0277.14BGLDC40.6153.5860.8262.0667.02DKLDC35.6540.1747.9646.1277.91HMM+ME+Sp275.7976.5074.2975.3171.40HMM+ME+Sp268.1773.5471.5368.5965.89HMM+ME+Sp264.4166.9865.2161.8373.26Table 4: 1-Many accuracy word frequency different corpora.5.6 Using Clusterscomparison different POS induction methods, experiment simplesemisupervised scheme use learned clusters features supervised POS tagger.basic supervised model features HMM+ME model, except useword identities suffixes regardless frequency. trained supervised model usingaveraged perceptron number iterations chosen follows: split training set 20%development 80% training pick number iterations optimize accuracydevelopment set. Finally, trained full training set using iterations report results500 sentence test set.augmented standard features learned hidden state current token,unsupervised method (B ROWN,C LARK,LDC, HMM+ME+Sp). Figure 4 shows averageaccuracy supervised model varied type unsupervised features. averagetaken 10 random samples training set training set size. see Figure 4using sem-supervised features models improves performance even500 labeled sentences. Moreover, see HMM+ME+Sp either performs well bettermodels.544fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONLDCBrownHMM+ME+SpClark100 200 300 400 500# Training samplesLDCBrownHMM+ME+SpClark1086420100 200 300 400 500# Training samplesESLDCBrownHMM+ME+SpClark100 200 300 400 500# Training samples1086420Improvement:En171086420Improvement:BGImprovement:1086420100 200 300 400 500# Training samples1086420Improvement:LDCBrownHMM+ME+SpClarkImprovement:En45Improvement:1086420PTLDCBrownHMM+ME+SpClark100 200 300 400 500# Training samplesDKLDCBrownHMM+ME+SpClark100 200 300 400 500# Training samplesFigure 4: Error reduction using induced clusters features semi-supervised modelfunction labeled data size. Top Left: En45. Top Middle: En17. Top Right: PT.Bottom Left: BG. Bottom Middle: ES. Bottom Right: DK.6. Conclusionwork investigated task fully unsupervised POS induction five different languages.identified proposed solutions three major problems simple hidden Markov modelused extensively task: i) treating words atomically, ignoring orthographicmorphological information addressed replacing multinomial word distributionssmall maximum-entropy models; ii) excessive number parameters allows modelsfit irrelevant correlations adressed discarding parameters small supportcorpus; iii) training regime (maximum likelihood) allows high word ambiguityaddressed training using PR framework word ambiguity penalty. showsolutions improve model performance improvements additive. Comparingregular HMM achieve impressive improvement 10.4% average.also compared system main competing systems show approachperforms better every language except English. Moreover, approach performs well acrosslanguages learning conditions, even hyperparameters tuned conditions.induced clusters used features semi-supervised POS tagger trained smallamount supervised data, show significant improvements. Moreover, clusters inducedsystem always perform well better clusters produced systems.545fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARAcknowledgmentsJoo V. Graa supported fellowship Fundao para Cincia e Tecnologia (SFRH/BD/ 27528/ 2006) FCT project CMU-PT/HuMach/0039/2008 FCT (INESC-ID multiannual funding) PIDDAC Program funds. Kuzman Ganchev partially supportedNSF ITR EIA 0205448. Ben Taskar partially supported DARPA CSSG 2009 AwardONR 2010 Young Investigator Award. Lusa Coheur partially supported FCT (INESC-IDmultiannual funding) PIDDAC Program funds.Appendix A. Unsupervised OptimizationBerg-Kirkpatrick et al. (2010) describe feature-rich HMM show training modelusing direct gradient rather EM lead better results. However, report resultsEn45 corpus. Table 5 compares implementation training regimes (BK+EM,BK+DG) different languages. Comparing two training regimes, seeclear winner. BK+EM wins 3 cases (Bg,En17,Dk) loses three.also clear predict method suitable. follow discussion6 authors propose difference arises algorithm starts fine-tuneweights rare features relative trains weights common features shortsuffixes. case direct gradient training, start optimization, weights commonfeatures change rapidly weight gradient proportional feature frequency.training progresses, weight transferred rarer features. contrast, EM training,optimization done completion M-Step, even first iterations EMcounts mostly random, rarer features get lot weight mass. preventsmodel generalizing, optimization terminates local maximum closer startingpoint. allow EM use common features longer tried small experimentsinitially permissive stopping criteria M-step. EM iterationspermissive stopping criteria, require stricter stopping criteria. tended improve EM,find principled method setting schedule convergence criteria M-step.Furthermore, small experiments explain direct gradient better EMlanguages worse others.related study (Salakhutdinov et al., 2003) compares convergence rate EM directgradient training, identifies conditions EM achieves Newton-like behavior,achieves first-order convergence. conditions based amount missing information,case approximated number hidden states. Potentially, differencealso lead different local maxima, mainly due non-local nature line search procedure gradient based methods. fact, looking results, DG training seems work bettercorpora higher number hidden states (En45, Es) work worse corporafewer hidden states (Bg,En17).Also Table 5 compare implementation HMM+ME model implementationBerg-Kirkpatrick et al. (2010), using conditions (regularization parameter, feature set,convergence criteria, initialization) observe significant differences results. Communicationcode-comparison revealed small implementation differences: use bias featurenot; random seed, parameters initialized differently theirs;6. http://www.cs.berkeley.edu/~tberg/gradVsEM/main.html546fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONEn45BK+EM 69.1BK+DG 75.8HMM+ME 67.11-ManyEn17 PtBg Dk Es72.1 72.3 64.3 62.8 72.067.9 72.5 56.1 60.6 73.772.2 72.3 61.1 65.1 71.8En4548.354.545.01-1En17 PtBg DkEs54.4 45.5 50.6 41.5 37.247.9 42.9 38.8 41.5 40.451.1 46.3 46.1 42.6 40.8En45BK+EM 3.31BK+DG 3.01HMM+ME 3.77VIEn17 PtBg Dk Es3.04 3.19 3.30 3.90 4.153.21 3.29 3.89 4.15 3.563.11 3.21 3.46 3.77 3.56En45.645.678.606VEn17 PtBg DkEs.568 .582 .479 .477 .596.534 .574 .392 .477 .611.564 .583 .460 .519 .608Table 5: EM vs direct gradient Berg-Kirkpatrick et al. (2010) implementation comparedimplementaion EM HMM maximum-entropy emission probabilities.rows starting BK Berkeley implementation, rows startingimplementation.different implementations optimization algorithm; different number iterations.corpora differences result better performance implementation,corpora implementation gets better results. leave details well betterunderstanding differences optimization procedure future work, sincemain focus present paper.Appendix B. Evaluation Metricscompare performance different models one needs evaluate quality inducedclusters. Several evaluation metrics clustering proposed previous work. metricsuse evaluate divided two types (Reichart & Rappoport, 2009): mapping-basedinformation theoretic. Mapping based metrics require post-processing step map clusterPOS tag evaluate accuracy supervised POS tagging. Information-theoretic (IT)metrics compare induced clusters directly true POS tags.1-Many mapping 1-1 mapping (Haghighi & Klein, 2006) two widely-used mappingmetrics. 1-Many mapping, hidden state mapped tag cooccursmost. means several hidden states mapped tag, tags mightused all. 1-1 mapping greedily assigns hidden state single tag. casenumber tags hidden states same, give 1-1 correspondence. majordrawback latter mapping fails express information hidden states.Typically, unsupervised models prefer explain frequent tags several hidden states,combine rare tags. example Pt corpus 3 tags occurcorpus. Grouping together subdividing nouns still provides lot informationtrue tag assignments. However, would captured 1-1 mapping. metrictends favor systems produce exponential distribution size induced clusterindependent clusters true quality, correlate well information theoreticmetrics (Graa et al., 2009). Nevertheless, 1-Many mapping also drawbacks, sincedistinguish clusters based frequent tag. So, cluster split almost evenly547fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARnouns adjectives, cluster number nouns, mixturewords different tags gives 1-Many accuracy.information-theoretic measures use evaluation variation information (VI)(Meila, 2007) validity-measure (V) (Rosenberg & Hirschberg, 2007). basedentropy conditional entropy tags induced clusters. VI desirable geometric properties metric convexly additive (Meila, 2007). However, range VI valuesdataset-dependent (VI lies [0, 2 log N ] N number POS tags) allowcomparison across datasets different N . validity-measure (V) also entropy-basedmeasure always lies range [0, 1], satisfy geometric propertiesVI. reported give high score large number clusters exist, evenlow quality (Reichart & Rappoport, 2009). information-theoretic measuresproposed better handle different numbers clusters, instance NVI (Reichart & Rappoport,2009). However, work testing conditions corpora number clusters problem exist. Christodoulopoulos, Goldwater, Steedman (2010)present extensive comparison evaluation metrics. related work Maron, Lamar,Bienenstock (2010) present another empirical study metrics conclude VI metricproduce results contradict true quality induced clustering, giving highscores simple baseline systems, instance assigning label words.also point several problems 1-1 metric explained previously. Sincemetric comparison focus work compare methods using four metricsdescribed section.ReferencesAbeill, A. (2003). Treebanks: Building Using Parsed Corpora. Springer.Afonso, S., Bick, E., Haber, R., & Santos, D. (2002). Floresta Sinta(c)tica: treebank Portuguese. Proc. LREC, pp. 16981703.Baum, L., Petrie, T., Soules, G., & Weiss, N. (1970). maximization technique occurringstatistical analysis probabilistic functions Markov chains. Annals MathematicalStatistics, 41(1), 164171.Berg-Kirkpatrick, T., Bouchard-Ct, A., DeNero, J., & Klein, D. (2010). Painless unsupervisedlearning features. Proc. NAACL.Bertsekas, D., Homer, M., Logan, D., & Patek, S. (1995). Nonlinear programming. Athena Scientific.Brown, P. F., deSouza, P. V., Mercer, R. L., Pietra, V. J. D., & Lai, J. C. (1992). Class-based n-grammodels natural language. Computational Linguistics, 18, 467479.Chen, S. (2003). Conditional joint models grapheme-to-phoneme conversion. Proc.ECSCT.Christodoulopoulos, C., Goldwater, S., & Steedman, M. (2010). Two decades unsupervised POSinduction: far come?. Proc. EMNLP, Cambridge, MA.Civit, M., & Mart, M. (2004). Building cast3lb: spanish treebank. Research Language &Computation, 2(4), 549574.548fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONClark, A. (2003). Combining distributional morphological information part speech induction. Proc. EACL.Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data viaEM algorithm. Journal Royal Statistical Society. Series B (Methodological), 39(1).Freitag, D. (2004). Toward unsupervised whole-corpus tagging. Proc. COLING. AssociationComputational Linguistics.Ganchev, K., Graa, J., Gillenwater, J., & Taskar, B. (2010). Posterior regularization structuredlatent variable models. Journal Machine Learning Research, 11, 20012049.Gao, J., & Johnson, M. (2008). comparison Bayesian estimators unsupervised hiddenMarkov model POS taggers. Proc. EMNLP, pp. 344352, Honolulu, Hawaii. ACL.Goldwater, S., & Griffiths, T. (2007). fully Bayesian approach unsupervised part-of-speechtagging. Proc. ACL, Vol. 45, p. 744.Graa, J., Ganchev, K., Pereira, F., & Taskar, B. (2009). Parameter vs. posterior sparisty latentvariable models. Proc. NIPS.Graa, J., Ganchev, K., & Taskar, B. (2007). Expectation maximization posterior constraints.Proc. NIPS. MIT Press.Graa, J. a. d. A. V. (2010). Posterior Regularization Framework: Learning Tractable ModelsIntractable Constraints. Ph.D. thesis, Universidade Tcnica de Lisboa, Instituto SuperiorTcnico.Haghighi, A., & Klein, D. (2006). Prototype-driven learning sequence models. Proc. HTLNAACL. ACL.Headden, III, W. P., McClosky, D., & Charniak, E. (2008). Evaluating unsupervised part-of-speechtagging grammar induction. Proc. COLING, pp. 329336.Hwa, R., Resnik, P., Weinberg, A., Cabezas, C., & Kolak, O. (2005). Bootstrapping parsers viasyntactic projection across parallel texts. Special Issue Journal Natural LanguageEngineering Parallel Texts, 11(3), 311325.Johnson, M. (2007). doesnt EM find good HMM POS-taggers. Proc. EMNLP-CoNLL.Kromann, Matthias T. (2003). Danish Dependency Treebank underlying linguistictheory. Second Workshop Treebanks Linguistic Theories (TLT), pp. 217220, Vxj,Sweden.Lamar, M., Maron, Y., & Bienenstock, E. (2010). Latent-descriptor clustering unsupervised POSinduction. Proceedings 2010 Conference Empirical Methods Natural LanguageProcessing, pp. 799809, Cambridge, MA. Association Computational Linguistics.Lamar, M., Maron, Y., Johnson, M., & Bienenstock, E. (2010). SVD clustering unsupervised POS tagging. Proceedings ACL 2010 Conference: Short Papers, pp. 215219,Uppsala, Sweden. Association Computational Linguistics.Lee, Y. K., Haghighi, A., & Barzilay, R. (2010). Simple type-level unsupervised POS tagging.Proceedings 2010 Conference Empirical Methods Natural Language Processing,pp. 853861, Cambridge, MA. Association Computational Linguistics.549fiG RAA , G ANCHEV, C OHEUR , P EREIRA , & TASKARMarcus, M., Marcinkiewicz, M., & Santorini, B. (1993). Building large annotated corpusEnglish: Penn Treebank. Computational linguistics, 19(2), 313330.Maron, Y., Lamar, M., & Bienenstock, E. (2010). Evaluation criteria unsupervised POS induction. Tech. rep., Indiana University.Martin, S., Liermann, J., & Ney, H. (1998). Algorithms bigram trigram word clustering.Speech Communication, pp. 12531256.Meila, M. (2007). Comparing clusteringsan information based distance. J. Multivar. Anal., 98(5),873895.Merialdo, B. (1994). Tagging English text probabilistic model. Computational linguistics,20(2), 155171.Moon, T., Erk, K., & Baldridge, J. (2010). Crouching Dirichlet, hidden Markov model: Unsupervised POS tagging context local tag generation. Proc. EMNLP, Cambridge, MA.Neal, R. M., & Hinton, G. E. (1998). new view EM algorithm justifies incremental,sparse variants. Jordan, M. I. (Ed.), Learning Graphical Models, pp. 355368.Kluwer.Nocedal, J., & Wright, S. J. (1999). Numerical optimization. Springer.Ratnaparkhi, A. (1996). maximum entropy model part-of-speech tagging. Proc. EMNLP.ACL.Ravi, S., & Knight, K. (2009). Minimized models unsupervised part-of-speech tagging.Proc. ACL.Reichart, R., & Rappoport, A. (2009). NVI clustering evaluation measure. Proc. CONLL.Rosenberg, A., & Hirschberg, J. (2007). V-measure: conditional entropy-based external clusterevaluation measure. EMNLP-CoNLL, pp. 410420.Salakhutdinov, R., Roweis, S., & Ghahramani, Z. (2003). Optimization EM expectationconjugate-gradient. Proc. ICML, Vol. 20.Schtze, H. (1995). Distributional part-of-speech tagging. Proc. EACL, pp. 141148.Shen, L., Satta, G., & Joshi, A. (2007). Guided learning bidirectional sequence classification.Proc. ACL, Prague, Czech Republic.Simov, K., Osenova, P., Slavcheva, M., Kolkovska, S., Balabanova, E., Doikoff, D., Ivanova, K.,Simov, A., Simov, E., & Kouylekov, M. (2002). Building Linguistically Interpreted CorpusBulgarian: BulTreeBank. Proc. LREC.Smith, N., & Eisner, J. (2005). Contrastive estimation: Training log-linear models unlabeleddata. Proc. ACL. ACL.Snyder, B., Naseem, T., Eisenstein, J., & Barzilay, R. (2008). Unsupervised multilingual learningPOS tagging. Proceedings Conference Empirical Methods Natural LanguageProcessing, pp. 10411050. Association Computational Linguistics.Toutanova, K., & Johnson, M. (2007). Bayesian LDA-based model semi-supervised part-ofspeech tagging. Proc. NIPS, 20.550fiC ONTROLLING C OMPLEXITY PART- -S PEECH NDUCTIONToutanova, K., Klein, D., Manning, C., & Singer, Y. (2003). Feature-rich part-of-speech taggingcyclic dependency network. Proc. HLT-NAACL.Zhao, Q., & Marcus, M. (2009). simple unsupervised learner POS disambiguation rules givenminimal lexicon. Proc. EMNLP.551fiJournal Artificial Intelligence Research 41 (2011) 297-327Submitted 01/11; published 06/11Stackelberg vs. Nash Security Games: Extended InvestigationInterchangeability, Equivalence, UniquenessDmytro KorzhykDIMA @ CS . DUKE . EDUDepartment Computer Science, Duke UniversityLSRC, Campus Box 90129, Durham, NC 27708, USAZhengyu YinZHENGYUY @ USC . EDUComputer Science Department, University Southern California3737 Watt Way, Powell Hall Engg. 208, Los Angeles, CA 90089, USAChristopher KiekintveldCDKIEKINTVELD @ UTEP. EDUDepartment Computer Science, University Texas El Paso500 W. University Ave., El Paso, TX 79968, USAVincent ConitzerCONITZER @ CS . DUKE . EDUDepartment Computer Science, Duke UniversityLSRC, Campus Box 90129, Durham, NC 27708, USAMilind TambeTAMBE @ USC . EDUComputer Science Department, University Southern California3737 Watt Way, Powell Hall Engg. 410, Los Angeles, CA 90089, USAAbstractsignificant recent interest game-theoretic approaches security, muchrecent research focused utilizing leader-follower Stackelberg game model. Amongmajor applications ARMOR program deployed LAX Airport IRIS programuse US Federal Air Marshals (FAMS). foundational assumption using Stackelberggames security forces (leaders), acting first, commit randomized strategy;adversaries (followers) choose best response surveillance randomized strategy.Yet, many situations, leader may face uncertainty followers surveillance capability.Previous work fails address leader compute strategy given uncertainty.provide five contributions context general class security games. First,show Nash equilibria security games interchangeable, thus alleviating equilibriumselection problem. Second, natural restriction security games, Stackelberg strategyalso Nash equilibrium strategy; furthermore, solution unique class securitygames ARMOR key exemplar. Third, faced follower attackmultiple targets, many properties longer hold. Fourth, show experimentally(but all) games restriction hold, Stackelberg strategy still Nashequilibrium strategy, longer true attacker attack multiple targets. Finally,possible direction future research, propose extensive-form game model makesdefenders uncertainty attackers ability observe explicit.1. Introductionsignificant recent research interest game-theoretic approaches security airports, ports, transportation, shipping infrastructure (Pita et al., 2008; Pita, Jain, Ordonez,Portway et al., 2009; Jain et al., 2010). Much work used Stackelberg game framec2011AI Access Foundation. rights reserved.fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEwork model interactions security forces attackers compute strategiessecurity forces (Conitzer & Sandholm, 2006; Paruchuri et al., 2008; Kiekintveld et al., 2009;Basilico, Gatti, & Amigoni, 2009; Letchford, Conitzer, & Munagala, 2009; Korzhyk, Conitzer,& Parr, 2010). framework, defender (i.e., security forces) acts first committingpatrolling inspection strategy, attacker chooses attack observingdefenders choice. typical solution concept applied games Strong Stackelberg Equilibrium (SSE), assumes defender choose optimal mixed (randomized) strategybased assumption attacker observe strategy choose optimal response.leader-follower paradigm appears fit many real-world security situations.Indeed, Stackelberg games heart two major deployed decision-support applications. first ARMOR security system, deployed Los Angeles International Airport(LAX) (Pita et al., 2008; Jain et al., 2010). domain police able set checkpointsroads leading particular terminals, assign canine units (bomb-sniffing dogs) patrolterminals. Police resources domain homogeneous, significant scheduling constraints. second IRIS, similar application deployed Federal Air MarshalsService (FAMS) (Tsai, Rathi, Kiekintveld, Ordonez, & Tambe, 2009; Jain et al., 2010). Armedmarshals assigned commercial flights deter defeat terrorist attacks. domaincomplex constraints. particular, marshals assigned tours flights returndestination, tours given marshal available fly limitedmarshals current location timing constraints. types scheduling resource constraintsconsider work paper motivated necessary represent domain.Additionally, security applications currently evaluation evenpipeline. example, Transportation Security Administration (TSA) testing evaluating GUARDS system potential national deployment (at 400 airports) GUARDSalso uses Stackelberg games TSA security resource allocation conducting security activitiesaimed protection airport infrastructure (Pita, Bellamane et al., 2009). Another exampleapplication development United States Coast Guard suggesting patrolling strategies protect ports ensure safety security passenger, cargo, vessel operations.potential examples include protecting electric power grids, oil pipelines, subway systemsinfrastructure (Brown, Carlyle, Salmeron, & Wood, 2005); well border security computernetwork security.However, legitimate concerns whether Stackelberg model appropriatecases. situations attackers may choose act without acquiring costly informationsecurity strategy, especially security measures difficult observe (e.g., undercover officers)insiders unavailable. cases, simultaneous-move game model may betterreflection real situation. defender faces unclear choice strategy adopt:recommendation Stackelberg model, simultaneous-move model, somethingelse entirely? general settings, equilibrium strategy fact differ models.Consider normal-form game Table 1. row player ability commit, SSEstrategy play .5 b .5, best response column player playd, gives row player expected utility 2.5.1 hand, players movesimultaneously Nash Equilibrium (NE) game row player playcolumn player c. seen noticing b strictly dominated row player.1. games assumed follower indifferent, breaks tie leaders favor (otherwise,optimal solution well defined).298fiS TACKELBERG VS . NASH ECURITY G AMESbc1,10,03,02,1Table 1: Example game Stackelberg Equilibrium Nash Equilibrium.Previous work failed resolve defenders dilemma strategy selectattackers observation capability unclear.paper, conduct theoretical experimental analysis leaders dilemma, focusingsecurity games (Kiekintveld et al., 2009). formally defined class not-necessarily-zerosum2 games motivated applications discussed earlier. make four primary contributions.First, show Nash equilibria interchangeable security games, avoiding equilibriumselection problems. Second, game satisfies SSAS (Subsets Schedules Schedules)property, defenders set SSE strategies subset NE strategies. case, defender always playing best response using SSE regardless whether attacker observesdefenders strategy not. Third, provide counter-examples (partial) equivalencetwo cases: (1) SSAS property hold defender schedules, (2)attacker attack multiple targets simultaneously. cases, defenders SSE strategy maypart NE profile. Finally, experimental tests show fraction gamesSSE strategy played part NE profile vanishingly small. However, attacker attack multiple targets, SSE strategy fails NE strategy relativelylarge number games.Section 2 contains formal definition security games considered paper. Section 3contains theoretical results Nash Stackelberg equilibria security games,consider main contributions paper. Section 4, show resultshold extension security games allows attacker attack multiple targets once.Section 5 contains experimental results. initiate future research cases propertiesSection 3 hold, present Section 6 extensive-form game model makesdefenders uncertainty attackers ability observe explicit. discuss additional relatedwork Section 7, conclude Section 8.2. Definitions Notationsecurity game (Kiekintveld et al., 2009) two-player game defender attacker.attacker may choose attack target set = {t1 , t2 , . . . , tn }. defender triesprevent attacks covering targets using resources set R = {r1 , r2 , . . . , rK }. shownFigure 1, Udc (ti ) defenders utility ti attacked ti covered defenderresource. ti covered, defender gets Udu (ti ). attackers utility denoted similarly2. not-necessarily-zero-sumness games used counter-terrorism security resource allocation analysisemphasized Bier (2007), Keeney (2007), Rosoff John (2009). focus preference elicitationdefenders attackers explicitly outline objectives different terrorist groups individuals oftendifferent other, defenders attackers objectives exact opposites other.instance, Bier (2007) notes attackers utility also depend factors may significant effectdefenders utility, cost mounting attack well propaganda value targetattacker.299fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEUac (ti ) Uau (ti ). use Ud (ti ) = Udc (ti ) Udu (ti ) denote difference defenderscovered uncovered utilities. Similarly, Ua (ti ) = Uau (ti ) Uac (ti ). key propertysecurity games, assume Ud (ti ) > 0 Ua (ti ) > 0. words, adding resources covertarget helps defender hurts attacker.AttackerDefenderUdc(ti)Uac(ti)Ua(ti) > 0Udu(ti)Uau(ti)Ud(ti) > 0coveredCoveredFigure 1: Payoff structure security games.Motivated FAMS similar domains, introduce resource scheduling constraintsdefender. Resources may assigned schedules covering multiple targets, .resource ri , subset Si schedules resource ri potentially cover. is,ri cover Si . FAMS domain, flights targets air marshals resources.Schedules capture idea air marshals fly tours, must return particular starting point.Heterogeneous resources express additional timing location constraints limit toursparticular marshal assigned fly. important subset FAMS domainmodeled using fixed schedules size 2 (i.e., pair departing returning flights).LAX domain also subclass security games defined here, schedules size 1homogeneous resources.security game described represented normal form game, follows.attackers pure strategy space set targets. attackers mixed strategy = haivector ai represents probability attackingQK ti . defenders pure strategy feasibleassignment resources schedules, i.e., hsi i=1 Si . Since covering target one resourceessentially covering positive number resources, defenders purestrategy also represented coverage vector = hdi {0, 1}n di representswhether ti covered not. example, h{t1 , t4 }, {t2 }i possible assignment,corresponding coverage vector h1, 1, 0, 1i. However, coverage vectors feasible dueresource schedule constraints. denote set feasible coverage vectors {0, 1}n .defenders mixed strategy C specifies probabilities playing D,individual probability denotedP Cd . Let c = hci vector coverage probabilities corresponding C, ci = dD di Cd marginal probability covering ti . example,suppose defender two coverage vectors: d1 = h1, 1, 0i d2 = h0, 1, 1i. mixedstrategy C = h.5, .5i, corresponding vector coverage probabilities c = h.5, 1, .5i. Denotemapping C c , c = (C).strategy profile hC, ai played, defenders utilityUd (C, a) =nXai (ci Udc (ti ) + (1 ci )Udu (ti )) ,i=1300fiS TACKELBERG VS . NASH ECURITY G AMESattackers utilityUa (C, a) =nXai (ci Uac (ti ) + (1 ci )Uau (ti )) .i=1players move simultaneously, standard solution concept Nash equilibrium.Definition 1. pair strategies hC, ai forms Nash Equilibrium (NE) satisfy following:1. defender plays best-response:Ud (C, a) Ud (C0 , a) C0 .2. attacker plays best-response:Ua (C, a) Ua (C, a0 ) a0 .Stackelberg model, defender chooses mixed strategy first, attacker choosesstrategy observing defenders choice. attackers response function g(C) : C a.case, standard solution concept Strong Stackelberg Equilibrium (Leitmann, 1978; vonStengel & Zamir, 2010).Definition 2. pair strategies hC, gi forms Strong Stackelberg Equilibrium (SSE) satisfyfollowing:1. leader (defender) plays best-response:Ud (C, g(C)) Ud (C0 , g(C0 )), C0 .2. follower (attacker) plays best-response:Ua (C, g(C)) Ua (C, g 0 (C)), C, g 0 .3. follower breaks ties optimally leader:Ud (C, g(C)) Ud (C, (C)), C, (C) set follower best-responsesC.denote set mixed strategies defender played Nash EquilibriumN E , corresponding set Strong Stackelberg Equilibrium SSE . defendersSSE utility always least high defenders utility NE profile. holdsgame, security games. follows following: SSE model, leaderleast choose commit NE strategy. so, follower chooseamong best responses one maximizes utility leader (due tie-breakingassumption), whereas NE follower also choose best responses defender strategy (but necessarily ones maximize leaders utility). fact strongerclaim holds: leaders SSE utility least high correlated equilibrium. observations due von Stengel Zamir (2010) give much detailed discussionpoints (including, implicitly, extent still holds without tie-breaking assumption).basic model, assumed players utility functions common knowledge.best approximation truth, useful reflect importanceassumption. SSE model, defender needs know attackers utility function ordercompute SSE strategy, attacker need know defenders utility function;301fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEneeds best-respond know mixed strategy defender committed.3hand, NE model, attacker observe defenders mixed strategy needsknow defenders utility function. Arguably, much harder justify practice,may related SSE model used applications discussed earlier. goalpaper argue NE model, rather discuss relationship SSENE strategies defender. show Nash equilibria interchangeable securitygames, suggesting NE strategies better properties security gamesgeneral. also show large class games, defenders SSE strategy guaranteedNE strategy well, longer issue defender; attackers NEstrategy indeed depend defenders utility function, see affectdefenders NE strategy.course, practice, defender generally know attackers utility function exactly. One way address make uncertainty explicit model game Bayesiangame (Harsanyi, 1968), known algorithms solving SSE strategies Bayesian games(e.g., Paruchuri et al., 2008) practical small security games, dependwriting complete action space player, exponential size security games.addition, even complete action space written out, problem NP-hard (Conitzer &Sandholm, 2006) good approximation guarantee possible unless P=NP (Letchford et al.,2009). recent paper Kiekintveld, Marecki, Tambe (2011) discusses approximation methods models. Another issue attacker assumed respond optimally,may true practice; several models Stackelberg games imperfect followerproposed Pita, Jain, Ordonez, Tambe et al. (2009). solution concepts also makesolution robust errors estimation attackers utility function. considerBayesian games imperfect attackers paper.3. Equilibria Security Gameschallenge us understand fundamental relationships SSE NE strategies security games. special case zero-sum security games, defenders utilityexact opposite attackers utility. finite two-person zero-sum games, knowndifferent game theoretic solution concepts NE, minimax, maximin SSE giveanswer. addition, Nash equilibrium strategies zero-sum games useful propertyinterchangeable: equilibrium strategy one player pairedplayers strategy equilibrium profile, result equilibrium, payoffsplayers remain same.Unfortunately, security games necessarily zero-sum (and zero-sum deployedapplications). Many properties zero-sum games hold security games. instance,minimax strategy security game may maximin strategy. Consider exampleTable 2, 3 targets one defender resource. defender three actions;defenders actions cover one target time, leaving targets uncovered.3. Technically, exactly true attacker needs break ties defenders favor. However,attacker indifferent among multiple actions, defender generally modify strategy slightly makeattacker strictly prefer action optimal defender; point tiebreaking assumption merelymake optimal solution well defined. See also work von Stengel Zamir (2010) discussiongeneric games particular.302fiS TACKELBERG VS . NASH ECURITY G AMESthree targets equally appealing attacker, defender varying utilities capturingattacker different targets. defender, unique minimax strategy, h1/3, 1/3, 1/3i,different unique maximin strategy, h6/11, 3/11, 2/11i.t1DefAttt2t3CUCUCU100120013001Table 2: Security game strategically zero-sum.Strategically zero-sum games (Moulin & Vial, 1978) natural strict superset zerosum games desirable properties zero-sum games still hold. exactlyclass games completely mixed Nash equilibrium improved upon. MoulinVial proved game (A, B) strategically zero-sum exist u > 0 v > 0uA + vB = U + V , U matrix identical columns V matrixidentical rows (Moulin & Vial, 1978). Unfortunately, security games even strategically zerosum. game Table 2 counterexample, otherwise must exist u, v > 0that,1 0 00 1 1u 0 2 0 + v 1 0 10 0 31 1 0x z= b b b + x zc c cx zequations, + = + z = b + x = b + z = c + x = c + = v, impliesx = = z = b = c. also know + x = u, b + = 2u, c + z = 3u. However since+ x = b + = c + z, u must 0, contradicts assumption u > 0.Another concept worth mentioning unilaterally competitive games (Kats &Thisse, 1992). game unilaterally competitive (or weakly unilaterally competitive), impliesplayer unilaterally changes action way increases utility, mustresult (weak) decrease utility every players utility. hold securitygames: example, attacker switches heavily defended sensitive targetundefended target little value defender, change may make players strictlybetter off. example shown Table 3. attacker switches attacking t1 attackingt2 , players utility increases.Nevertheless, show rest section security games still importantproperties. start establishing equivalence set defenders minimax strategiesset defenders NE strategies. Second, show Nash equilibria security gamesinterchangeable, resolving defenders equilibrium strategy selection problem simultaneousmove games. Third, show natural restriction schedules, SSE strategydefender also minimax strategy hence NE strategy. resolves defenders dilemmawhether play according SSE NE uncertainty attackers ability303fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEt1DefAttt2CUCU10013223Table 3: security game unilaterally competitive (or weakly unilaterally competitive).observe strategy: defender safely play SSE strategy, guaranteedNE strategy well, moreover Nash equilibria interchangeable riskchoosing wrong equilibrium strategy. Finally, restricted class games (includinggames LAX domain), find unique SSE/NE defender strategyunique attacker NE strategy.3.1 Equivalence NE Minimaxfirst prove defenders NE strategy also minimax strategy. every defendersminimax strategy C construct strategy attacker hC, ai NE profile.Definition 3. defenders mixed strategy C, define attackers best response utilityE(C) = maxni=1 Ua (C, ti ). Denote minimum attackers best response utilitiesdefenders strategies E = minC E(C). set defenders minimax strategies definedas:= {C|E(C) = E }.define function f follows. attackers strategy target ti attackedprobability ai , f (a) = attackers strategyUd (ti )Ua (ti )Pn> 0 normalizing constant i=1 ai = 1. intuition behind function fdefender prefers playing strategy C playing another strategy C0 security gameG attacker plays strategy defender also prefers playing C playingC0 attacker plays f (a) corresponding zero-sum security game G, definedLemma 3.1 below. Also, supports attacker strategies f (a) same.show Lemma 3.1, function f provides one-to-one mapping attackers NE strategies Gattackers NE strategies G, inverse function f 1 (a) = given followingequation.1 Ua (ti )ai = ai(1)Ud (ti )ai = aiLemma 3.1. Consider security game G. Construct corresponding zero-sum security game Gdefenders utilities re-defined follows.Udc (t) = Uac (t)Udu (t) = Uau (t)hC, ai NE profile G hC, f (a)i NE profile G.304fiS TACKELBERG VS . NASH ECURITY G AMESProof. Note supports strategies = f (a) same, also attackersutility function games G G. Thus best response C Gbest response C G.Denote utility defender gets profile hC, ai played game G UdG (C, a).show C best response game G C best response G,sufficient show equivalence following two inequalities.UdG (C, a) UdG (C0 , a) 0UdG (C, a) UdG (C0 , a) 0prove equivalence starting first inequality transforming secondone. one hand, have,UdG (C, a) UdG (C0 , a) =nXai (ci c0i )Ud (ti ).i=1Similarly, hand, have,UdG (C, a) UdG (C0 , a) =nXai (ci c0i )Ua (ti ).i=1Given Equation (1) > 0, have,UdG (C, a) UdG (C0 , a) 0nXai (ci c0i )Ud (ti ) 0i=1nX1 Ua (ti )ai(ci c0i )Ud (ti ) 0Ud (ti )i=1nX1ai (ci c0i )Ua (ti ) 0i=11 GUd (C, a) UdG (C0 , a) 0UdG (C, a) UdG (C0 , a) 0Lemma 3.2. Suppose C defender NE strategy security game. E(C) = E , i.e.,N E .Proof. Suppose hC, ai NE profile security game G. According Lemma 3.1, hC, f (a)imust NE profile corresponding zero-sum security game G. Since C NE strategyzero-sum game G, must also minimax strategy G (Fudenberg & Tirole, 1991).attackers utility function G G, thus C must also minimax strategy G,E(C) = E .305fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBELemma 3.3. security game G, defenders strategy C E(C) = E NEstrategy, i.e., N E .Proof. C minimax strategy G corresponding zero-sum game G. minimaxstrategy also NE strategy zero-sum game (Fudenberg & Tirole, 1991). mustexist NE profile hC, ai G. Lemma 3.1, hC, f 1 (a)i NE profile G. Thus CNE strategy G.Theorem 3.4. security game, set defenders minimax strategies equal setdefenders NE strategies, i.e., = N E .Proof. Lemma 3.2 shows every defenders NE strategy minimax strategy, Lemma 3.3shows every defenders minimax strategy NE strategy. Thus sets defenders NEminimax strategies must equal.important emphasize defenders equilibrium strategiesG G, true attackers equilibrium strategies: attacker probabilities leavedefender indifferent across support G necessarily leave indifferent G.reason function f (a) above.3.2 Interchangeability Nash Equilibriashow Nash equilibria security games interchangeable. result indicates that,case attacker cannot observe defenders mixed strategy, effectivelyequilibrium selection problem: long player plays strategy equilibrium,result guaranteed equilibrium. course, still resolve issueclear whether attacker observe mixed strategy; return issueSubsection 3.3.Theorem 3.5. Suppose hC, ai hC0 , a0 two NE profiles security game G. hC, a0hC0 , ai also NE profiles G.Proof. Consider corresponding zero-sum game G. Lemma 3.1, hC, f (a)i hC0 , f (a0 )imust NE profiles G. interchange property NE zero-sum games (Fudenberg & Tirole, 1991), hC, f (a0 )i hC0 , f (a)i must also NE profiles G. Applying Lemma 3.1direction, get hC, a0 hC0 , ai must NE profiles G.Theorem 3.5, defenders equilibrium selection problem simultaneous-move securitygame resolved. reason given attackers NE strategy a, defender must getutility responding NE strategy. Next, give insights expected utilitiesNE profiles. first show attackers expected utility NE profiles, followedexample demonstrating defender may varying expected utilities correspondingdifferent attackers strategies.Theorem 3.6. Suppose hC, ai NE profile security game. Then, Ua (C, a) = E .Proof. Lemma 3.2, C minimax strategy E(C) = E . one hand,Ua (C, a) =nXai Ua (C, ti )i=1nXi=1306ai E(C) = E .fiS TACKELBERG VS . NASH ECURITY G AMEShand, best response C, least good strategyattacking arg maxt Ua (C, t) probability 1, is,Ua (C, a) Ua (C, ) = E(C) = E .Therefore know Ua (C, a) = E .Unlike attacker gets utility NE profiles, defender may get varyingexpected utilities depending attackers strategy selection. Consider game shown Table 4. defender choose cover one two targets time. defender NEstrategy cover t1 100% probability, making attacker indifferent attacking t1t2 . One attacker NE strategy always attack t1 , gives defender expected utility1. Another attackers NE strategy h2/3, 1/3i, given defender indifferentdefending t1 t2 . case, defenders utility decreases 2/3 capturesattacker lower probability.t1DefAttt2CUCU11022001Table 4: security game defenders expected utility varies different NE profiles.3.3 SSE Strategies Also Minimax/NE Strategiesalready shown set defenders NE strategies coincides minimax strategies. every defenders SSE strategy also minimax strategy, SSE strategies must alsoNE strategies. defender safely commit SSE strategy; selection problem defender. Unfortunately, security game arbitrary scheduling constraints,SSE strategy may part NE profile. example, consider game Table 5 4targets {t1 , . . . , t4 }, 2 schedules s1 = {t1 , t2 }, s2 = {t3 , t4 }, single defender resource.defender always prefers t1 attacked, t3 t4 never appealing attacker.t1DefAttt2t3t4CUCUCUCU10295-23-3410011001Table 5: schedule-constrained security game defenders SSE strategy NEstrategy.unique SSE strategy defender, places much coverage probabilitys1 possible without making t2 appealing attacker t1 . rest coverageprobability placed s2 . result s1 s2 covered probability 0.5.307fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEcontrast, simultaneous-move game, t3 t4 dominated attacker. Thus,reason defender place resources targets never attacked, defenders uniqueNE strategy covers s1 probability 1. is, defenders SSE strategy differentNE strategy. difference defenders payoffs cases also arbitrarilylarge t1 always attacked SSE t2 always attacked NE.example restricts defender protect t1 t2 together, makes impossibledefender put coverage t2 without making t1 less appealing. defender couldassign resources subset schedule, difficulty resolved. formally, assumeresource ri , subset schedule Si also possible schedule Si :1 K : s0 Si s0 Si .(2)security game satisfies Equation (2), say SSAS property. natural manysecurity domains, since often possible cover fewer targets maximum numberresource could possible cover schedule. find property sufficient ensuredefenders SSE strategy must also NE strategy.Lemma 3.7. Suppose C defender strategy security game satisfies SSAS propertyc = (C) corresponding vector marginal probabilities. c00 c0i ci ti , must exist defender strategy C0 (C0 ) = c0 .Proof. proof induction number ti c0i 6= ci , denoted (c, c0 ).base case, c0i 6= ci , existence trivially holds (C) = c0 .Suppose existence holds c, c0 (c, c0 ) = k, 0 k n 1. considerc, c0 (c, c0 ) = k + 1. j, c0j 6= cj . Since c0j 0 c0j < cj ,cj > 0. must nonempty set coverage vectors Dj cover tj receive positiveprobability C. security game satisfies SSAS property, every Dj ,valid covers targets except tj . defender strategy C, shiftingCd (cj c0j )probability every Dj corresponding , get defender strategy Ccjci = ci 6= j, ci = c0i = j. Hence (c , c0 ) = k, implying exists C0(C0 ) = c0 induction assumption. induction, existence holds c, c0 .Theorem 3.8. Suppose C defender SSE strategy security game satisfies SSASproperty. E(C) = E , i.e., SSE = N E .Proof. proof contradiction. Suppose hC, gi SSE profile security gamesatisfies SSAS property, E(C) > E . Let Ta = {ti |Ua (C, ti ) = E(C)} set targetsgive attacker maximum utility given defender strategy C. definition SSE,Ud (C, g(C)) = max Ud (C, ti ).ti TaConsider defender mixed strategy C E(C ) = E . ti Ta , Ua (C , ti )E . Consider vector c0 :c E Ua (C , ti ) + ,ti Ta ,(3a)Uau (ti ) Uac (ti )c0i =ci ,ti/ Ta ,(3b)308fiS TACKELBERG VS . NASH ECURITY G AMESinfinitesimal positive number. Since E Ua (C , ti ) + > 0, c0i < citi Ta . hand, since ti Ta ,Ua (c0 , ti ) = E + < E(C) = Ua (C, ti ),c0i > ci 0. ti , 0 c0i ci . Lemma 3.7, existsdefender strategy C0 corresponding c0 . attackers utility attacking target follows:E + ,ti Ta ,(4a)0Ua (C , ti ) =Ua (C , ti ) E ,ti/ Ta .(4b)Thus, attackers best responses C0 still Ta . ti Ta , since c0i > ci , mustcase Ud (C, ti ) < Ud (C0 , ti ). definition attackers SSE response g, have,Ud (C0 , g(C0 )) = max Ud (C0 , ti )ti Ta> max Ud (C, ti ) = Ud (C, g(C)).ti Tafollows defender better using C0 , contradicts assumption C SSEstrategy defender.Theorem 3.4 3.8 together imply following corollary.Corollary 3.9. security games SSAS property, defenders SSE strategy alsoNE strategy.answer original question posed paper: uncertaintytype game played, defender choose SSE strategy mixed strategy Nashequilibrium combination two?4 domains satisfy SSAS property,proven defender safely play SSE strategy, guaranteed Nashequilibrium strategy well, moreover Nash equilibria interchangeablerisk choosing wrong equilibrium strategy.Among motivating domains, LAX domain satisfies SSAS property since schedulessize 1. patrolling domains, patrolling port, also satisfy SSAS property.domains, defender could thus commit SSE strategy, also knownNE strategy. defender retains ability commit, still playing best-responseattacker simultaneous-move setting (assuming attacker plays equilibrium strategymatter one, due interchange property shown above). However, FAMSdomain naturally satisfy SSAS property marshals must fly complete tours.5question selecting SSE vs. NE strategies case addressed experimentally Section 5.4. course, one may agree that, cases common knowledge players move simultaneously,playing NE strategy right thing practice. question heart game theoryfar beyond scope paper resolve. paper, goal argue using NE strategiessimultaneous-move settings general; rather, assess robustness SSE strategies changesinformation structure specific classes security games. purpose, NE seems like natural representativesolution concept simultaneous-move security games, especially light interchangeability propertiesshow.5. principle, FAMs could fly civilians legs tour. However, would need able commitacting civilians (i.e., intervening attempt hijack aircraft) attacker would need believeFAM would intervene, difficult achieve practice.309fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE3.4 Uniqueness Restricted Gamesprevious sections show SSE strategies NE strategies many cases. However,may still multiple equilibria select (though difficulty alleviated interchangeproperty). prove even stronger uniqueness result important restricted classsecurity domains, includes LAX domain. particular, consider security gamesdefender homogeneous resources cover single target. SSAS propertytrivially satisfied,since schedules size 1. vector coverage probabilities c = hciPni=1 ci K feasible strategy defender, represent defenderstrategy marginal coverage probabilities. minor restriction attackers payoff matrix,defender always unique minimax strategy also unique SSE NE strategy.Furthermore, attacker also unique NE response strategy.Theorem 3.10. security game homogeneous resources cover single target,every target ti , Uac (ti ) 6= E , defender unique minimax, NE, SSEstrategy.Proof. first show defender unique minimax strategy. Let = {t|Uau (t) E }.Define c = hciuUa (ti ) E ,ti ,(5a)ci =Uau (ti ) Uac (ti )0,ti/ .(5b)Note E cannot less Uac (ti ) otherwise, regardless defenders strategy,attacker could always get least Uac (ti ) > E attacking ti , contradicts factE attackers best response utility defenders minimax strategy. Since E Uac (ti )assume E 6= Uac (ti ),1 ci =E Uac (ti )> 0 ci < 1.Uau (ti ) Uac (ti )PPNext, prove ni=1 ci K. sake ofPcontradiction, suppose ni=1 ci < K. Letn0> 0c0 = hc0i i,Pn ci0 = ci + . Since ci < 1 i=1 ci < K, find0ci < 1 i=1 ci < K. every target strictly higher coverage c0 c , henceE(c0 ) < E(c ) = E , contradicts fact E minimum E(c).Next, show c minimax strategy, c = c . Pdefinition minimaxn. Hence, U (c, ) E c c . one handstrategy, E(c)=Ei=1 ci KPnPnhand i=1 ci i=1 ci K. Therefore must case ci = ci i. Hence,c unique minimax strategy defender.Furthermore, Theorem 3.4, c unique defenders NE strategy. Theorem 3.8 existence SSE (Basar & Olsder, 1995), c unique defendersSSE strategy.following example, show Theorem 3.10 work without conditionUac (ti ) 6= E every ti . Consider security game 4 targets defender twohomogeneous resources, resource cover single target, players utility functionsdefined Table 5. defender guarantee minimum attackers best-response utility310fiS TACKELBERG VS . NASH ECURITY G AMESE = 3 covering t1 probability 2/3 covering t2 probability 1. SinceE = Uac (t2 ), Theorem 3.10 apply. defender prefers attack t1 , defendermust cover t1 probability exactly 2/3 SSE strategy. Thus defenders SSE strategiescoverage vectors (2/3, 1, 1/3, 0), (2/3, 1, 0, 1/3), convex combination twovectors. According Theorem 3.8, SSE strategies also minimax/NE strategy,defenders SSE, minimax, NE strategies unique example.Theorem 3.11. security game homogeneous resources cover one target,every target ti , Uac (ti ) 6= E Uau (ti ) 6= E , attacker unique NE strategy.Proof. c proof Theorem 3.10. Given defenders unique NEstrategy c , attackers best response, ti attacked positive probability,because,Eti(6a)Ua (c , ti ) =uUa (ti ) < Eti/(6b)Suppose hc , ai forms NE profile.Xai = 1(7)titi , know proof Theorem 3.10 ci < 1. addition,Uau (t) 6= E , ci 6= 0. Thus 0 < ci < 1 ti . ti , tj ,necessarily ai Ud (ti ) = aj Ud (tj ). Otherwise, assume ai Ud (ti ) > aj Ud (tj ). Consideranother defenders strategy c0 c0i = ci + < 1, c0j = cj > 0, c0k = ck k 6= i, j.Ud (c0 , a) Ud (c , a) = ai Ud (ti ) aj Ud (tj ) > 0Hence, c best response a, contradicts assumption hc , ai NE profile.Therefore, exists > 0 that, ti , ai Ud (ti ) = . Substituting ai/Ud (ti ) Equation (7),= Xti11Ud (ti )explicitly writeai =,Ud (ti )0,ti ,(8a)ti/ .(8b)see, defined (8a) (8b) unique attacker NE strategy.following example, show Theorem 3.11 work without conditionUau (ti ) 6= E every ti . Consider game three targets defender one resource cover single target utilities defined Table 6. defenderguarantee minimum attackers best-response utility E = 2 covering targets t1 t2311fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEprobability 1/2 each. Since Uac (ti ) 6= E every ti , Theorem 3.10 applies, defendersstrategy coverage vector (.5, .5, 0) unique minimax/NE/SSE strategy. However, Theorem 3.11 apply Uau (t3 ) = E . attackers NE strategy indeed unique,attacker strategies (.5, .5, 0) (1/3, 1/3, 1/3) (as well convex combinationstrategies) valid NE best-responses.t1DefAttt2t3CUCUCU011301130012Table 6: example game defender unique minimax/NE/SSE strategy coverage vector (.5, .5, 0), attacker unique NE strategy. Two possibleattackers NE strategies (.5, .5, 0) (1/3, 1/3, 1/3).implication Theorem 3.10 Theorem 3.11 certain conditionssimultaneous-move game, defender attacker unique NE strategy,gives player unique expected utility result.4. Multiple Attacker Resourcespoint assumed attacker attack exactly one target. extendsecurity game definition allow attacker use multiple resources attack multiple targetssimultaneously.4.1 Model Descriptionkeep model simple, assume homogeneous resources (for players) schedulessize 1. defender K < n resources assigned protect target,attacker L < n resources used attack target. Attacking targetmultiple resources equivalent attacking single resource. defenders pure strategycoverage vector = hdi D, di {0, 1} represents whether ti Pcovered not.nSimilarly,attackerspurestrategyattackvectorq=hqQ.i=1 di = KPni=1 qi = L. pure strategies hd, qi played, attacker gets utilityUa (d, q) =nXqi (di Uac (ti ) + (1 di )Uau (ti ))i=1defenders utility givenUd (d, q) =nXqi (di Udc (ti ) + (1 di )Udu (ti ))i=1defenders mixed strategy vector C specifies probability playingD. Similarly, attackers mixed strategy vector probabilities corresponding312fiS TACKELBERG VS . NASH ECURITY G AMESq Q. defined Section 2, describe players mixed strategies pair vectorshc, ai, ci probability target ti defended, ai probability tiattacked.4.2 Overview Resultsgames multiple attacker resources, defenders SSE strategy also NE strategy,like single-attacker-resource case. example, suppose targets interchangeabledefender attacker. Then, defenders SSE strategy defend targetsequal probabilities, defenders utility attack least defended targetsmaximized. attacker best-responds attacking targets equal probabilities,resulting strategy profile NE. Thus defenders SSE strategy also NE strategycase. Example 1 discusses case detail. observe defendersSSE strategy example matter attacker 1 2 resources. useobservation construct sufficient condition defenders SSE strategy alsoNE strategy security games multiple attacker resources (Proposition 4.2). modestpositive result, however, exhaustive sense explain casesdefenders SSE strategy also NE strategy. Example 2 describes game defendersSSE strategy also NE strategy, condition Proposition 4.2 met.games multiple attacker resources, defenders SSE strategy partNE profile. following gives intuition happen. Supposetarget ti defender strongly hopes attacked (even Udc (ti ) negative),given ti fact attacked, defending help defender much (Ud (ti ) =Udc (ti ) Udu (ti ) small). SSE model, defender likely want devote defensiveresources ti , attacker observe want attack ti . However,NE model, defenders strategy cannot influence attacker does, marginal utilityassigning defensive resources ti small; and, attacker multiple resources,may well another target attacker also attack valuable defend,defender send defensive resources instead. provide detailed descriptions gamesdefenders SSE strategy part NE profile Examples 3, 4, 5.Since condition Proposition 4.2 implies defenders SSE NE strategieschange number attacker resources varies, provide exhaustive set example gamesequality SSE NE strategies broken number different ways(Examples 2, 3, 4, 5). set examples rules number ways Proposition 4.2might generalized larger set games.4.3 Detailed Proofs Examplescertain assumptions, SSE defender strategies still NE defender strategies modelmultiple attacker resources. give simple sufficient condition hold. First,need following lemma.Lemma 4.1. Given security game G L L attacker resources, let G 1 game exceptone attacker resource. Let hc, ai Nash equilibrium G 1 . Suppose targetti , Lai 1. Then, hc, Lai Nash equilibrium G L .313fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEProof. Lai 1 ti , La fact feasible attacker strategy G L . leftprove hd, Lai fact equilibrium. attacker best-responding utilityattacking given target unchanged relative equilibrium G 1 . defenderbest-responding utility defending schedule multiplied L relativeG 1 , still optimal defender defend schedules support c.lemma immediately gives us following proposition:Proposition 4.2. Given game G L L attacker resources SSAS holds, let G 1game except one attacker resource. Suppose SSE strategy G LG 1 . Let strategy attacker hd, ai Nash equilibrium G 1 (we knowexists Corollary 3.9). Lai 1 target ti , hd, Lai NE profile G L ,means SSE NE strategy G L .simple example Proposition 4.2 applies constructed follows.Example 1. Suppose 3 targets, completely interchangeable players.Suppose defender 1 resource. attacker 1 resource, defenders SSE strategy= (1/3, 1/3, 1/3) attackers NE best-response = (1/3, 1/3, 1/3). attacker2 resources, defenders SSE strategy still d. Since ti , 2ai 1, Proposition 4.2applies, profile hd, 2ai NE profile.denote defenders SSE strategy game L attacker resources cS,L denotedefenders NE strategy game cN ,L . Example 1, cN ,1 = cS,1 =cS,2 = cN ,2 . Hence, conditions, defenders strategy always sameregardlesswhether use SSE NE regardless whether attacker 1 2 resources.show several examples games true, even though SSAS holds.following cases, show example game SSAS holds relationdefenders equilibrium strategies specified case description. first case,SSE strategy equal NE strategy L = 2, condition Proposition 4.2 metSSE strategy L = 1 different SSE strategy L = 2, alsomultiplying attackers NE strategy game L = 1 attacker resource 2 resultfeasible attackers strategy (in game L = 2 attacker resources otherwisesame). last three cases, SSE strategy equal NE strategy L = 2.cS,2 = cN ,2 6= cN ,1 = cS,1 (SSE vs. NE makes difference, L makes difference);cN ,2 6= cS,2 = cS,1 = cN ,1 (NE L = 2 different cases);cS,2 6= cN ,2 = cN ,1 = cS,1 (SSE L = 2 different cases);cS,2 6= cN ,2 ; cS,2 6= cS,1 = cN ,1 ; cN ,2 6= cN ,1 = cS,1 (all cases different, except SSENE L = 1 implied Corollary 3.9).easy see cases exhaustive, following. Corollary 3.9 necessitates cS,1 = cN ,1 (because want SSAS hold cS,L cN ,L strategy unique),effectively three potentially different strategies, cN ,2 , cS,2 , cS,1 = cN ,1 .either (as Example 1 Proposition 4.2), different (the last case),exactly two (the first three cases).314fiS TACKELBERG VS . NASH ECURITY G AMESgive examples. examples, schedules size 1,defender single resource.Example 2 (cS,2 = cN ,2 6= cN ,1 = cS,1 ). Consider game shown Table 7. defender1 resource. attacker 1 resource, target t1 attacked probability 1, hencedefended probability 1 well (whether SSE NE model). attacker2 resources, targets attacked, target t2 defended Ud (t2 ) > Ud (t1 )(whether SSE NE model).t1DefAttt2CUCU02130021Table 7: example game cS,2 = cN ,2 6= cN ,1 = cS,1 . single attacker resource,attacker always attack t1 , defender defend t1 . two attackerresources, attacker attack targets, case defender prefersdefend t2 .Example 3 (cN ,2 6= cS,2 = cS,1 = cN ,1 ). Consider game shown Table 8. defender1 resource. attacker 1 resource, follows Theorem 3.10 unique defenderminimax/NE/SSE strategy cS,1 = cN ,1 = (2/3, 1/6, 1/6).t1DefAttt2t3CUCUCU10111300320032Table 8: example game cN ,2 6= cS,2 = cS,1 = cN ,1 . example correspondsintuition given earlier. Target t1 sensitive target defender: defender sufferslarge loss t1 attacked. However, t1 attacked, allocating defensive resourcesbenefit defender much, low marginal utility Ud (t1 ) = 1.result, target t1 defended NE profile h(0, .5, .5), (1, .5, .5)i,defended SSE profile h(1, 0, 0), (0, 1, 1)i.suppose attacker 2 resources. SSE, defender wants primarily avoidattack t1 (so t2 t3 attacked probability 1 each). constraint,defender wants maximize total probability t2 t3 (they interchangeableattacked, probability equally valuable either one). defender strategy (2/3, 1/6, 1/6)unique optimal solution optimization problem.However, straightforward verify following NE profile attacker 2resources: h(0, .5, .5), (1, .5, .5)i. prove unique NE. First, show t1315fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEdefended probability 0 NE. one targets t2 , t3 must attackedprobability least .5. Thus, defender always incentive move probabilityt1 target. follows t1 defended NE. Now, t1 defended, t1attacked probability 1. remains effectively single-attacker-resource security gamet2 t3 clear unique equilibrium h(.5, .5), (.5, .5)i, thereby proving uniqueness.Example 4 (cS,2 6= cN ,2 = cN ,1 = cS,1 ). Consider game shown Table 9. defender1 resource. attacker 1 resource, defenders unique minimax/NE/SSE strategyminimax strategy (1, 0, 0).suppose attacker 2 resources. t1 must attacked probability 1.Ud (t1 ) = 2 > 1 = Ud (t2 ) = Ud (t3 ), NE, implies defender must put fullprobability 1 t1 . Hence, attacker attack t2 resource. So, unique NEprofile h(1, 0, 0), (1, 1, 0)i.contrast, SSE, defenders primary goal avoid attack t2 , requiresputting probability least .5 t2 (so attacker prefers t3 t2 ). result t1t3 attacked; defender prefers defend t1 remaining probabilityUd (t1 ) = 2 > 1 = Ud (t3 ). Hence, unique SSE profile h(.5, .5, 0), (1, 0, 1)i.t1DefAttt2t3CUCUCU0526921040113Table 9: example game cS,2 6= cN ,2 = cN ,1 = cS,1 . t1 certainly attackedattacker, hence valuable defend target NEUd (t1 ) = 2 > 1 = Ud (t2 ) = Ud (t3 ). However, SSE two attacker resources,valuable defender use resource prevent attack t2second attacker resource.Example 5 (cS,2 6= cN ,2 ; cS,2 6= cS,1 = cN ,1 ; cN ,2 6= cN ,1 = cS,1 ). Consider gameTable 10. defender 1 resource. attacker 1 resource, follows Theorem 3.10unique defender minimax/NE/SSE strategy cS,1 = cN ,1 = (1/6, 2/3, 1/6).attacker 2 resources, SSE, defenders primary goal prevent t1attacked. requires putting least much defender probability t1 t3 ,result t2 t3 attacked. Given t2 t3 attacked, placing defender probabilityt3 twice valuable placing t2 (Ud (t3 ) = 7, Ud (t2 ) = 3). Hence, eventhough every unit probability placed t3 , also need place unit t1 (to keep t1attacked), still uniquely optimal defender allocate probability massway. So, unique defender SSE strategy (.5, 0, .5).However, straightforward verify following NE profile attacker2 resources: h(0, 3/4, 1/4), (1, 7/10, 3/10)i. prove unique NE. First,show t1 defended NE. least one t2 t3 must attackedprobability least .5, hence defender would better defending target instead.316fiS TACKELBERG VS . NASH ECURITY G AMESt1DefAttt2t3CUCUCU11012201330072Table 10: example game cS,2 6= cN ,2 ; cS,2 6= cS,1 = cN ,1 ; cN ,2 6= cN ,1 = cS,1 . oneattacker resource, t1 t3 get small probability (regardless solutionconcept). two attacker resources, unique NE, turns worthwhiledefend t1 even though always attacked, Ud (t1 ) low; contrast,unique SSE, t1 defended relatively high probability prevent attackit.Next, show t1 attacked probability 1 NE. t3 positive defender probability,(because t1 defended) t1 definitely attractive attack t3 , henceattacked probability 1. hand, defender defends t2 , t1 t3attacked probability 1. remains effectively single-attacker-resource security gamet2 t3 clear unique equilibrium h(3/4, 1/4), (7/10, 3/10)i, thereby proving uniqueness.5. Experimental Resultstheoretical results resolve leaders dilemma many interesting important classessecurity games, seen, still cases SSE strategies distinctNE strategies defender. One case schedules satisfy SSAS property,another attacker multiple resources. section, conduct experimentsinvestigate two cases, offering evidence frequency SSE strategiesdiffer NE strategies across randomly generated games, variety parameter settings.methodology follows. particular game instance, first compute SSE strategy C using DOBSS mixed-integer linear program (Pita et al., 2008). use linearfeasibility program determine whether SSE strategy part NE profileattempting find appropriate attacker response strategy.Aq [0, 1] q QXAq = 1(9)(10)qQAq = 0 Ua (q, C) < E(C)XAq Ud (d, q) Z,(11)(12)qQXAq Ud (d, q) = Z, Cd > 0(13)qQQ set attacker pure strategies, set targets one attacker resource. probability attacker plays q denoted Aq , must0 1 (Constraint (9)). Constraint (10) forces probabilities sum 1. Constraint (11)317fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEprevents attacker placing positive probabilities pure strategies give attackerutility less best response utility E(C). constraints (12) (13), Z variablerepresents maximum expected utility defender get among pure strategies givenattackers strategy A, Cd denotes probability playing C. two constraints require defenders strategy C best response attackers mixed strategy. Therefore,feasible solution linear feasibility program, taken together Stackelberg strategyC, constitutes Nash equilibrium. Conversely, hC, Ai Nash equilibrium, must satisfyLP constraints.experiment, varied:number attacker resources,number (homogeneous) defender resources,size schedules resources cover,number schedules.parameter setting, generated 1000 games 10 targets. target t,pair defender payoffs (Udc (t), Udu (t)) pair attacker payoffs (Uau (t), Uac (t)) drawnuniformly random set {(x, y) Z2 : x [10, 10], [10, 10], x > y}.game experiment, schedules size, except also alwaysempty scheduleassigning resource empty schedule corresponds resourceused. schedules randomly chosen set subsets targets sizespecified corresponding parameter.results experiments shown Figure 2. plots show percentage gamesSSE strategy NE strategy, different numbers defender attackerresources, different schedule sizes, different numbers schedules. casesingle attacker resource schedules size 1, SSAS property holds, experimental results confirm theoretical result SSE strategy always NE strategy.increase either number attacker resources schedule size, longertheoretical result, indeed start see cases SSE strategy NE strategy.Let us first consider effect increasing number attacker resources. seenumber games defenders SSE strategy NE strategy increases significantlynumber attacker resources increases, especially goes 1 2 (note differentscales y-axes). fact, 2 3 attacker resources, phenomenon manycases SSE strategy NE strategy consistent across wide range valuesparameters.6Now, let us consider effect increasing schedule size. increase schedulesize (with single attacker resource), SSAS property longer holds includesubschedules schedules, find games SSE strategyNE strategybut generally cases (< 6%) this. Also, generate randomschedules, number games SSE strategy NE strategy drops zero.particularly encouraging domains like FAMS, schedule sizes relatively small (26. course, increase number attacker resources keeping number targets fixed, eventually,every defender SSE strategy NE strategy again, simply number attacker resourcesequal number targets, attacker one pure strategy available.318fiS TACKELBERG VS . NASH ECURITY G AMESFigure 2: number games SSE strategy NE strategy, differentparameter settings. row corresponds different number attacker resources,column different schedule size. number defender resourcesx-axis, number schedules plotted separately. parameter setting,1000 random games 10 targets generated. SSAS property holdsgames schedule size 1 (shown column 1); SSAS hold gamesschedule sizes 2 3 (columns 2 3).cases), number possible schedules large relative number targets.effect increasing number defender resources ambiguous. multipleattacker resources, increasing schedule size sometimes increases sometimes decreasesnumber games SSE strategy NE strategy.main message take away experimental results appears casesingle attacker resource, SSE strategies usually also NE strategies even SSAShold, appears justify practice playing SSE strategy. hand,multiple attacker resources, generally many cases SSE strategyNE strategy. strongly poses question done case multipleattacker resources (in settings clear whether attacker observe defendersmixed strategy).319fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBE6. Uncertainty Attackers Ability Observe: Model FutureResearchfar, security games attacker single resource, shownSSAS property satisfied, Stackelberg strategy necessarily Nash equilibrium strategy (Section 3.3). This, combined fact that, shown, equilibriagames satisfy interchangeability property (Section 3.2), provides strong justification playingStackelberg strategy SSAS property satisfied. Also, experiments (Section 5) suggest even SSAS property satisfied, Stackelberg strategy usually Nashequilibrium strategy. However, case consider security games attackermultiple resources.leaves question defender play games Stackelberg strategy necessarily Nash equilibrium strategy (which case many games multipleattacker resources, also games single attacker resource SSAS satisfied), especially clear whether attacker observe defenders mixed strategy.difficult question cuts heart normative foundations game theory,addressing beyond scope paper. Nevertheless, given real-world implicationsline research, believe important future research tackle problem. Ratherleave question completely open-ended, section propose modelmay useful starting point future research. also provide result modelleast leads sensible solutions SSAS games, which, among main resultspaper, provide useful sanity check adopting model future research.model propose section, defender uncertain whether attackerobserve mixed strategy defender commits. Specifically, game playedfollows. First, defender commits mixed strategy. that, probability pobs , attacker observes defenders strategy; probability 1 pobs , observe defendersmixed strategy. Figure 3 represents model larger extensive-form game.7 game, firstNature decides whether attacker able observe defenders choice distribution.Then, defender chooses distribution defender resource allocations (hence, defendercontinuum possible moves; particular, important emphasize committing distribution allocations randomizing pure allocationcommit to, latter case observing attacker know realized allocation).defender observe outcome Natures movehence, would make differenceNature moved defender, Nature move first convenient drawingdiscussing game tree. Finally, attacker moves (chooses one targets attack):left side tree, knowing distribution defender committed,right side tree, without knowing distribution.Given extensive-form representation situation, natural approach solveequilibrium larger game. possible apply standard algorithms solving extensiveform games directly game, tree infinite size due defender choicedistributions; nevertheless, one straightforward way addressing discretize space7. point, risk confusion defender mixed strategies used phrase far,defender strategies extensive-form game. rest section, avoid confusion, usually referformer distributions allocationsbecause, technically, distribution allocations pure strategyextensive-form game, defender mixed strategy extensive-form game would distributiondistributions.320fiS TACKELBERG VS . NASH ECURITY G AMESNatureDefenderobserved(pobs)observed(1-pobs)(infinitenumberactions)(infinitenumberactions)Attackerattacker moves knowledgedefender's distributionattacker moves without knowledgedefender's distributionFigure 3: Extensive form larger game defender uncertain attackersability observe.distributions. important question, course, whether right thing playequilibrium game. state simple propositions serve sanity checksmodel. First, show pobs = 1, obtain Stackelberg model.Proposition 6.1. pobs = 1, subgame-perfect equilibrium extensive-form gamecorresponds SSE underlying security game.Proof. guaranteed end left-hand side tree, attacker observesdistribution defender committed; subgame-perfect equilibrium, mustbest-respond distribution. defender, turn, must choose distribution optimallyrespect this. Hence, result corresponds SSE.Next, show pobs = 0, obtain standard simultaneous-move model.Proposition 6.2. pobs = 0, Nash equilibrium extensive-form game correspondsNash equilibrium underlying security game.Proof. guaranteed end right-hand side tree, attacker observesnothing distribution defender committed. Nash equilibriumextensive-form game, defenders strategy leads probability distribution allocations.attackers information set right-hand side tree, attacker place positiveprobability actions best responses distribution allocations. Conversely,defender put positive probability allocations best responses attackersdistribution actions. Hence, result Nash equilibrium underlying security game.intermediate values pobs , sufficiently general settings, equilibrium extensiveform game may correspond neither SSE NE basic security game. However,would hope security games Stackelberg strategy also Nash equilibriumstrategysuch SSAS security games discussed earlier paperthis strategy also corresponds equilibrium extensive-form game. next proposition shows indeedcase.321fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEProposition 6.3. underlying security game, Stackelberg strategy defenderalso defenders strategy Nash equilibrium, strategy also defenders strategy subgame-perfect equilibrium extensive-form game.8Proof. Suppose distribution allocations Stackelberg strategyNash equilibrium strategy underlying security game. Let best responseattacker plays corresponding SSE, let distribution attacker actionshd , Nash equilibrium security game.show construct subgame-perfect equilibrium extensive-form game. Letdefender commit distribution information set. attackers strategyextensive form defined follows. left-hand side tree, attacker observesdefender committed , responds ; attacker observes defendercommitted distribution allocations, responds best responsedistribution. information set right-hand side tree, attacker plays .straightforward check attacker best-responding defenders strategy everyone information sets. remains show defender best-respondingattackers strategy extensive-form game. defender commits distribution d0 ,cannot help left side tree relative , Stackelberg strategy;also cannot help right side tree, best response . followsdefender best-responding, hence identified subgame-perfect equilibriumgame.proposition immediately applied SSAS games:Corollary 6.4. security games satisfy SSAS property (and single attacker resource), Stackelberg strategy underlying security game, also defendersstrategy subgame-perfect equilibrium extensive-form game.Proof. follows immediately Proposition 6.3 Corollary 3.9.course, Proposition 6.3 also applies games SSAS hold Stackelbergstrategy still Nash equilibrium strategywhich case many gamesexperiments Section 5. general, course, SSAS property hold, Stackelbergstrategy may Nash equilibrium strategy underlying security game; so, defendersstrategies equilibria extensive-form game may correspond neither Stackelberg Nashstrategies underlying security game. case, method usedsolve extensive-form game directlyfor example, discretizing space distributionsattacker applying standard algorithm solving equilibrium resultinggame. latter method scale well, leave design better algorithmsfuture research.7. Additional Related Workfirst sections paper, discussed recent uses game theory security domains,formal model security games, model differs existing classes games8. also hold stronger solution concepts subgame-perfect equilibrium.322fiS TACKELBERG VS . NASH ECURITY G AMESstrategically zero-sum unilaterally competitive games. discuss additional related worksection.significant interest understanding interaction observability commitment general Stackelberg games. Bagwells early work (1995) questions value commitmentpure strategies given noisy observations followers, ensuing on-going debate illustrated leader retains advantage case commitment mixed strategies (van Damme& Hurkens, 1997; Huck & Muller, 2000). Guth, Kirchsteiger, Ritzberger (1998) extendobservations n-player games. Maggi (1998) shows games private information,leader advantage appears even pure strategies. also work value commitment leader observations costly (Morgan & Vardy, 2007).Several examples applications Stackelberg games model terrorist attacks electricpower grids, subways, airports, critical infrastructure described Brown et al.(2005) Sandler Arce M. (2003). Drake (1998) Pluchinsky (2005) studied differentaspects terrorist planning operations target selection. studies indicate terroristattacks planned certain level sophistication. addition, terrorist manual showssignificant amount information used plan attacks collected public sources (U.S.Department Justice, 2001). Zhuang Bier (2010) studied reasons secrecy deceptiondefenders side. broader interest Stackelberg games indicated applicationsareas, network routing scheduling (Korilis, Lazar, & Orda, 1997; Roughgarden, 2004).contrast existing research, work focuses real-world security games, illustrating subset, equivalence, interchangeability, uniqueness properties non-existentgeneral Stackelberg games studied previously. course, results general nature date backbeginning game theory: von Neumanns minimax theorem (1928) implies two-playerzero-sum games, equilibria interchangeable optimal SSE strategy also minimax /NE strategy. However, discussed earlier, security games studied generallyzero-sum games, captured general classes games strategicallyzero-sum (Moulin & Vial, 1978) unilaterally competitive (Kats & Thisse, 1992) games.Tennenholtz (2002) studies safety-level strategies. two players, safety-level (or maximin)strategy player 1 mixed strategy maximizes expected utility player 1,assumption player 2 acts minimize player 1s expected utility (rather maximizeutility). Tennenholtz shows conditions, utility guaranteed safety-levelstrategy equal close utility obtained player 1 Nash equilibrium. may soundreminiscent result Nash strategies coincide minimax strategies, fact resultsquite different: particular, non-zero-sum games, maximin minimax strategiesidentical. following example gives simple game result holds, safety-levelstrategy result utility close equilibrium solution.Example 6. Consider game shown Table 11. player 1 resource. game,safety-level (maximin) strategy defender place resource target 2, therebyguaranteeing utility least 2. However, attacker dominant strategyattack target 1 (so defender actually plays safety-level strategy, expect utility1). hand, minimax/Stackelberg/Nash solution, defend target 1receive utility 0.Kalai (2004) studies idea number players game grows, equilibriabecome robust certain changes extensive form, players move323fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEt1DefAttt2CUCU02132031Table 11: example game defenders utility playing competitive safetystrategy close defenders Nash/Stackelberg equilibrium utility.ones, learn others actions. high level reminiscentresults, sense also show class security games, particular choicetwo structures game (one player committing mixed strategy first, players movingtime) affect defender play (though attackers strategyaffected). However, seem significant technical similarityour result reliesstructure class security games number players becoming large(after all, consider games two players).Pita, Jain, Ordonez, Tambe et al. (2009) provide experimental results observability Stackelberg games: test variety defender strategies human players (attackers) chooseoptimal attack provided limited observations defender strategies. Resultsshow superiority defenders strategy computed assuming human anchoring bias attributing probability distribution defenders actions. research complementspaper, provides new mathematical foundations. Testing insights researchexperimental paradigm Pita, Jain, Ordonez, Tambe et al. (2009) expert players,interesting topic future research.8. Summarypaper focused general class defender-attacker Stackelberg games directlyinspired real-world security applications. paper confronts fundamental questionsdefender compute mixed strategy. context, paper provides four key contributions. First, exploiting structure security games, paper shows Nash equilibria security games interchangeable, thus alleviating defenders equilibrium selectionproblem simultaneous-move games. Second, resolving defenders dilemma, showsSSAS restriction security games, Stackelberg strategy also Nash equilibriumstrategy; furthermore, strategy unique class security games ARMORkey exemplar. Third, faced follower attack multiple targets, manyproperties longer hold, providing key direction future research. Fourth, experimentalresults emphasize positive properties security games fit SSAS property. practicalterms, contributions imply defenders applications ARMOR (Pita et al., 2008)IRIS (Tsai et al., 2009) simply commit SSE strategies, thus helping resolve majordilemma real-world security applications.324fiS TACKELBERG VS . NASH ECURITY G AMESAcknowledgmentsDmytro Korzhyk Zhengyu Yin first authors paper. earlier conference versionpaper published AAMAS-2010 (Yin, Korzhyk, Kiekintveld, Conitzer, & Tambe,2010). major additions full version include (i) set new experiments analysisresults; (ii) new model addressing uncertainty attackers ability observe;(iii) thorough treatment multiple attacker resources case; (iv) additional discussionrelated research.research supported United States Department Homeland SecurityNational Center Risk Economic Analysis Terrorism Events (CREATE) awardnumber 2010-ST-061-RE0001. Korzhyk Conitzer supported NSF IIS-0812113CAREER-0953756, ARO 56698-CI, Alfred P. Sloan Research Fellowship. However,opinions, findings, conclusions recommendations document authorsnecessarily reflect views funding agencies. thank Ronald Parr many detailed comments discussions. also thank anonymous reviewers valuable suggestions.ReferencesBagwell, K. (1995). Commitment observability games. Games Economic Behavior, 8,271280.Basar, T., & Olsder, G. J. (1995). Dynamic Noncooperative Game Theory (2nd edition). AcademicPress, San Diego, CA.Basilico, N., Gatti, N., & Amigoni, F. (2009). Leader-follower strategies robotic patrollingenvironments arbitrary topologies. Proceedings Eighth International JointConference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 5764, Budapest,Hungary.Bier, V. M. (2007). Choosing protect. Risk Analysis, 27(3), 607620.Brown, G., Carlyle, W. M., Salmeron, J., & Wood, K. (2005). Analyzing vulnerability criticalinfrastructure attack planning defenses. INFORMS Tutorials Operations Research: Emerging Theory, Methods, Applications, pp. 102123. Institute OperationsResearch Management Science, Hanover, MD.Conitzer, V., & Sandholm, T. (2006). Computing optimal strategy commit to. ProceedingsACM Conference Electronic Commerce (EC), pp. 8290, Ann Arbor, MI, USA.Drake, C. J. M. (1998). Terrorists Target Selection. St. Martins Press, Inc.Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.Guth, W., Kirchsteiger, G., & Ritzberger, K. (1998). Imperfectly observable commitments nplayer games. Games Economic Behavior, 23(1), 5474.Harsanyi, J. (19671968). Game incomplete information played Bayesian players. Management Science, 14, 159182; 320334; 486502.Huck, S., & Muller, W. (2000). Perfect versus imperfect observabilityan experimental testBagwells result. Games Economic Behavior, 31(2), 174190.325fiKORZHYK , , K IEKINTVELD , C ONITZER , & TAMBEJain, M., Tsai, J., Pita, J., Kiekintveld, C., Rathi, S., Ordonez, F., & Tambe, M. (2010). Softwareassistants randomized patrol planning LAX airport police Federal AirMarshals Service. Interfaces, 40(4), 267290.Kalai, E. (2004). Large robust games. Econometrica, 72(6), 16311665.Kats, A., & Thisse, J. (1992). Unilaterally competitive games. International Journal GameTheory, 21(3), 29199.Keeney, R. (2007). Modeling values anti-terrorism analysis. Risk Analysis, 27, 585596.Kiekintveld, C., Jain, M., Tsai, J., Pita, J., Ordonez, F., & Tambe, M. (2009). Computing optimalrandomized resource allocations massive security games. Proceedings EighthInternational Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS),pp. 689696, Budapest, Hungary.Kiekintveld, C., Marecki, J., & Tambe, M. (2011). Approximation methods infinite BayesianStackelberg games: Modeling distributional uncertainty. Proceedings InternationalConference Autonomous Agents Multiagent Systems (AAMAS), pp. 10051012.Korilis, Y. A., Lazar, A. A., & Orda, A. (1997). Achieving network optima using Stackelberg routingstrategies. IEEE/ACM Transactions Networking, 5(1), 161173.Korzhyk, D., Conitzer, V., & Parr, R. (2010). Complexity computing optimal Stackelberg strategies security resource allocation games. Proceedings National ConferenceArtificial Intelligence (AAAI), pp. 805810, Atlanta, GA, USA.Leitmann, G. (1978). generalized Stackelberg strategies. Optimization Theory Applications,26(4), 637643.Letchford, J., Conitzer, V., & Munagala, K. (2009). Learning approximating optimal strategycommit to. Proceedings Second Symposium Algorithmic Game Theory (SAGT09), pp. 250262, Paphos, Cyprus.Maggi, G. (1998). value commitment imperfect observability private information.RAND Journal Economics, 30(4), 555574.Morgan, J., & Vardy, F. (2007). value commitment contests tournaments observation costly. Games Economic Behavior, 60(2), 326338.Moulin, H., & Vial, J.-P. (1978). Strategically zero-sum games: class games whose completely mixed equilibria cannot improved upon. International Journal Game Theory,7(3-4), 201221.Paruchuri, P., Pearce, J. P., Marecki, J., Tambe, M., Ordonez, F., & Kraus, S. (2008). Playinggames security: efficient exact algorithm solving Bayesian Stackelberg games.Proceedings Seventh International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS), pp. 895902, Estoril, Portugal.Pita, J., Bellamane, H., Jain, M., Kiekintveld, C., Tsai, J., Ordonez, F., & Tambe, M. (2009). Securityapplications: Lessons real-world deployment. SIGECOM Issue 8.2.Pita, J., Jain, M., Ordonez, F., Portway, C., Tambe, M., Western, C., Paruchuri, P., & Kraus, S.(2009). Using game theory Los Angeles airport security. AI Magazine, 30(1), 4357.326fiS TACKELBERG VS . NASH ECURITY G AMESPita, J., Jain, M., Ordonez, F., Tambe, M., Kraus, S., & Magori-Cohen, R. (2009). Effective solutions real-world Stackelberg games: agents must deal human uncertainties.Proceedings Eighth International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS), pp. 369376, Budapest, Hungary.Pita, J., Jain, M., Western, C., Portway, C., Tambe, M., Ordonez, F., Kraus, S., & Parachuri, P.(2008). Deployed ARMOR protection: application game-theoretic model securityLos Angeles International Airport. Proceedings 7th International ConferenceAutonomous Agents Multiagent Systems (AAMAS 2008) Industry ApplicationsTrack, pp. 125132, Estoril, Portugal.Pluchinsky, D. A. (2005). Typology Anatomy Terrorist Operations, chap. 25. McGrawHill Homeland Security Book. McGraw-Hill.Rosoff, H., & John, R. (2009). Decision analysis proxy rational terrorist. Quantitative risk analysis security applications workshop (QRASA) held conjunctionInternational Joint Conference AI, pp. 2532, Pasadena, CA, USA.Roughgarden, T. (2004). Stackelberg scheduling strategies. SIAM Journal Computing, 33(2),332350.Sandler, T., & Arce M., D. G. (2003). Terrorism game theory. Simulation Gaming, 34(3),319337.Tennenholtz, M. (2002). Competitive safety analysis: Robust decision-making multi-agent systems. Journal Artificial Intelligence Research, 17, 363378.Tsai, J., Rathi, S., Kiekintveld, C., Ordonez, F., & Tambe, M. (2009). IRIS - tool strategicsecurity allocation transportation networks. Eighth International ConferenceAutonomous Agents Multiagent Systems - Industry Track, pp. 3744.U.S. Department Justice (2001). Al Qaeda training manual. http://www.au.af.mil/au/awc/awcgate/terrorism/alqaida_manual. Online release 7 December 2001.van Damme, E., & Hurkens, S. (1997). Games imperfectly observable commitment. GamesEconomic Behavior, 21(1-2), 282308.von Neumann, J. (1928). Zur Theorie der Gesellschaftsspiele. Mathematische Annalen, 100, 295320.von Stengel, B., & Zamir, S. (2010). Leadership games convex strategy sets. GamesEconomic Behavior, 69, 446457.Yin, Z., Korzhyk, D., Kiekintveld, C., Conitzer, V., & Tambe, M. (2010). Stackelberg vs. Nashsecurity games: Interchangeability, equivalence, uniqueness. Proceedings NinthInternational Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS),pp. 11391146, Toronto, Canada.Zhuang, J., & Bier, V. M. (2010). Reasons secrecy deception homeland-security resourceallocation. Risk Analysis, 30(12), 17371743.327fiJournal Artificial Intelligence Research 41 (2011) 69-95Submitted 10/10; published 05/11Value Information Lattice: Exploiting ProbabilisticIndependence Effective Feature Subset AcquisitionMustafa Bilgicmbilgic@iit.eduIllinois Institute TechnologyChicago, IL 60616 USALise Getoorgetoor@cs.umd.eduUniversity MarylandCollege Park, MD 20742 USAAbstractaddress cost-sensitive feature acquisition problem, misclassifying instance costly expected misclassification cost reduced acquiringvalues missing features. acquiring features costly well, objective acquire right set features sum feature acquisitioncost misclassification cost minimized. describe Value Information Lattice(VOILA), optimal efficient feature subset acquisition framework. Unlike commonpractice, acquire features greedily, VOILA reason subsets features.VOILA efficiently searches space possible feature subsets discovering exploitingconditional independence properties features reuses probabilistic inference computations speed process. empirical evaluation fivemedical datasets, show greedy strategy often reluctant acquire features,cannot forecast benefit acquiring multiple features combination.1. Introductionoften need make decisions take appropriate actions complex uncertainworld. important subset decisions formulated classification problem,instance described set features one finite categorical optionschosen based features. Examples include medical diagnosis patientsdescribed lab tests diagnosis made disease state patient,spam detection email described content email client needsdecide whether email spam.Much research done learn effective efficient classifiers assumingfeatures describing entities fully given. Even though complete dataassumption might hold domains, practice features describe entitiesoften missing values. certain domains medical diagnosis decisionmade based number features include laboratory test results, missing featurevalues acquired cost performing related tests. cases, needdecide tests perform order. answer question, course,depends important get correct classification decision. Put alternatively,cost incorrect classification (e.g., misdiagnosis) determines muchwilling spend expensive tests. Thus, need devise feature acquisition policydetermine tests perform order stop makec2011AI Access Foundation. rights reserved.fiBilgic & Getoorfinal classification decision total incurred cost, feature acquisition costexpected misclassification cost, minimized.Devising optimal policy general requires considering possible permutationsfeatures expected values. provide intuition, features mightuseful acquired together, cost benefit acquiring featuresdepend features acquired values turnedbe. devising optimal policy intractable general, previous workgreedy (Gaag & Wessels, 1993; Yang, Ling, Chai, & Pan, 2006), approximated valueinformation calculations (Heckerman, Horvitz, & Middleton, 1993), developedheuristic feature scoring techniques (Nunez, 1991; Turney, 1995).greedy approach, however, least two major limitations. First,considers feature isolation, cannot accurately forecast value acquiringmultiple features together, causing produce sub-optimal policies. Second, greedystrategy assumes features acquired sequentially value featureobserved acquiring next one. assumption, however, oftenpractical. example, doctors typically order batches measurements simultaneouslyblood count, cholesterol level, etc., possibly order another batchresults arrive. two limitations greedy approach make necessary reasonsets features.Reasoning sets features, hand, poses serious tractability challenges.First all, number subsets exponential size feature set. Second,judging value acquiring set features requires taking expectationpossible values features set, also exponential numberfeatures. good news, however, need consider possible subsetsfeatures practice; certain features render features useless, featuresuseful acquired together. example, X-Ray might render skin testuseless diagnosing tuberculosis. Similarly, chest pain alone might usefuldifferentiating cold heart disease; becomes useful combinedfeatures, blood test.article, describe data structure discovers exploits typesconstraints (features render features useless features usefulacquired together) underlying probability distribution. propose ValueInformation Lattice (VOILA) reduces space possible subsets exploitingconstraints features. Additionally, VOILA makes possible share valueinformation calculations different feature sets reduce computation time.article builds upon earlier work (Bilgic & Getoor, 2007). contributionsarticle include:introduce two additional techniques sharing computations differentsubsets features. new techniques based information cachingutilizing paths underlying Bayesian network.experiment asymmetric misclassification costs addition symmetriccosts. asymmetric setup reflects realistic case provides new insights.addition feature acquisition costs defined Turney (1995), generateexperiment synthetic feature costs. synthetic feature costs capture70fiValue Information Latticecomplex feature acquisition costs allows leeway various acquisitionstrategies differ.remainder article organized follows. describe notationproblem formulation Section 2. describe reduce search spaceshare computations using VOILA Section 3. show experimental results Section 4,discuss related work Section 5, discuss future work Section 6. concludeSection 7.2. Notation Problem Formulationmain task classify given instance missing feature values incurminimum acquisition misclassification cost. Let instance described setfeatures X = {X1 , X2 , . . . , Xn } let random variable representing class.assume joint probability distribution P (Y, X) given concernfeature acquisition inference (note conditional distribution P (Y |X)appropriate, features assumed unobserved initially). purposearticle, assume given Bayesian network, joint probabilisticmodel allows us efficiently answer conditional independence queries used.notation, bold face letter represents set random variables non-bold faceletter represents single random variable. example X represents set features,whereas Xi X represents feature X represents class variable. Additionally,capital letter represents random variable, lowercase letter represents particularvalue variable; applies individual variables sets variables.example, represents variable, represents particular value take.addition probabilistic model, also given cost models specifyfeature acquisition costs misclassification costs. Formally, assumefeature acquisition cost function given subset features, S, set featureswhose values known (evidence) E, returns non-negative real number C(S | e).also assume misclassification cost model returns misclassificationcost cij incurred assigned yi correct assignment yj . costfunctions, model non-static feature acquisition costs; is, cost acquiringfeature Xi depend acquired far values(e) well acquired conjunction feature (S \ {Xi }). Moreover,misclassification cost model assume symmetric costs; different kids errors (falsepositives negatives) different costs.Figure 1 shows simple example configuration two features, X1 X2 ,class variable . simple example, joint distribution P (X, ) representedtable, feature costs simple independent costs X1 X2 , misclassification cost symmetric types misclassifications cost correctclassification cost anything.diagnostic policy decision tree node represents featurebranches nodes represent possible values features. pathpolicy, ps , represents ordered sequence feature values s. often use psrepresent ordered version s. Typically, order features setimportant computing feature costs, cost feature depend values71fiBilgic & GetoorFigure 1: Example configuration two features X1 X2 class variable .table left right represent: joint probability distribution P (X1 , X2 , ),feature costs, misclassification costs.previously acquired features. order features irrelevant computingprobability P (s). example conditional policy using example configurationFigure 1 given Figure 2.policy two types costs: feature acquisition cost misclassificationcost. costs defined terms costs associated following pathspolicy. first describe compute feature acquisition cost pathdescribe compute associated expected misclassification cost. Finally, showcompute expected total cost policy using total costs associatedpath.naive version, feature cost path ps sum costsfeatures appear path. However, practice, cost feature dependfeatures acquired far observed values acquired features.example, performing treadmill test (asking patient run treadmillmeasure heart beat, etc.) riskier ordered cholesterol testresult turned high, putting patient high risk heart disease. accounttypes costs, order features ps matters, total feature costpath summation individual feature costs conditioned valuesfeatures precede features consideration:F C(ps ) =nXC(ps [j] | ps [1 : j])j=1ps [j] represents j th feature ps ps [1 : j] represents feature values 1j ps .reach end path, need make classification decision.case, simply utilize Bayesian decision theory choose decision minimumrisk (i.e., misclassification cost). find decision using probabilistic model72fiValue Information LatticeFigure 2: example conditional policy features X1 , X2 class variable .non-leaf node represents feature acquisition, probability distributionpossible values, cost feature. path (e.g., X1 = T, X2 = )acquisition cost expected misclassification cost. policy overallexpected total cost ETC, sum total costs path, weightedprobability following path.compute probability distribution P (Y | ps ) choose value leadsminimum expected cost. Note order features values mattercase; P (Y | ps ) = P (Y | s). expected misclassification path, EM C(ps ),73fiBilgic & Getoorcomputed follows:EM C(ps ) = EM C(s) = minyiXP (Y = yj | s) cij(1)yjtotal cost incur following path policy simply sum featureexpected misclassification costs path:C(ps ) = F C(ps ) + EM C(ps )Finally, compute expected total cost policy using total costsindividual paths ps . path ps probability occurrence real world.probability easily computed generative probability model assumed. simply P (s). expected total cost policy sum totalcost path, C(ps ), weighted probability following path, P (s):ET C() =XP (s)T C(ps )(2)psobjective feature acquisition inference is, given joint probabilisticmodel cost models acquisition misclassification, find policyminimum expected total cost. However, building optimal decision tree knownNP-complete (Hyafil & Rivest, 1976). Thus, research greedy choosingbest feature reduces misclassification costs lowest cost (e.g.,Gaag & Wessels, 1993; Dittmer & Jensen, 1997) developed heuristic feature scoringtechniques (e.g., Nunez, 1991; Tan, 1990).greedy strategy, path policy extended feature reducesmisclassification cost lowest cost. specifically, pathps replaced new paths psx1 , psx2 , . . . , psxni x1i , x2i , . . . , xni valuesXi take Xi feature highest benefit. define benefitfeature Xi given path ps reduction total cost path pathexpanded possible values Xi . formally,Benef it(Xi | ps ) , C(ps )nXP (xji | s)T C(psxj )j=1= F C(ps ) + EM C(s)nXP (xji | s) F C(psxj ) + EM C(s xji )j=1= F C(ps )nXP (xji | s)F C(psxj ) + EM C(s)j=1nXP (xji | s)EM C(s xji )j=1= C(Xi | s) + EM C(s)P (xji | s)EM C(s xji )j=1= F C(ps ) (F C(ps ) + C(Xi | s)) + EM C(s)nXnXP (xji | s)EM C(s xji )j=174fiValue Information LatticeNote that, last two terms equivalent definition expected value information, EVI, (Howard, 1966):EV I(Xi | s) = EM C(s)nXP (xji | s)EM C(s xji )(3)j=1Substituting EVI, definition benefit becomes intuitive:Benef it(Xi | ps ) = Benef it(Xi | s) = EV I(Xi | s) C(Xi | s)(4)definition, greedy strategy iteratively finds feature highestpositive benefit (value cost difference), acquires it, stops acquisitionfeatures positive benefit value.also note straightforward define EVI Benefit set S0 featureslike single feature. difference expectation needstaken joint assignments, s0 , features set S0 .EV I(S0 | s) = EM C(s)XP (s0 | s)EM C(s s0 )(5)s0and,Benef it(S0 | s) = EV I(S0 | s) C(S0 | s)(6)problems greedy strategy mentionedP earlier. First,short-sighted. exist sets X Benef it(S) >Benef it(Xi ).Xieasier see, example, XOR function, = X1 XOR X2 , X1 X2alone useful determinative together. Due relationship, greedypolicy guaranteed optimal. Moreover, greedy policy prematurely stopacquisition single feature seems provide positive benefit.second problem greedy strategy often need acquire setfeatures simultaneously. example, doctor orders set lab tests s/he sendspatient lab, blood count, cholesterol level, etc. rather ordering single test,waiting result ordering next one. However, traditional greedy strategycannot handle reasoning sets features naturally.would like able reason sets features two reasons.objective article is, given existing potentially empty set already observedfeatures E observed values e, find set highest benefit:L(X | e) , argmax Benef it(S | e)(7)SX\Etwo problems formulation: first, number subsets X \ Eexponential size X \ E, second, set S, need take expectationjoint assignments features set. address two problems usingdata structure describe next.75fiBilgic & Getoor3. Value Information Lattice (VOILA)VOILA makes reasoning sets features tractable reducing space possiblesets allowing sharing EVI computations different sets. section,first explain reduce space explain techniques computationsharing.3.1 Reducing Space Possible Setsdomains, often complex interactions featuresclass label. Contrary Naive Bayes assumption, features often conditionallyindependent given class label. features useless featuresalready acquired. example chest X-Ray typically determinative skintest tuberculosis. Similarly, features useless alone unless accompaniedfeatures. example, chest pain alone might due variety sicknesses;accompanied high cholesterol, could indicate heart disease, whereascombined fever, cold might probable. types interactionsfeatures allow us reduce space candidate feature sets.mentioned problem formulation, assumed alreadyjoint probabilistic model features class variable, P (Y, X). findtwo types feature interactions asking probabilistic independence queries usingP (Y, X). Specifically, assume given Bayesian network representsP (Y, X). Bayesian network allow us find types interactionsstandard d-separation algorithms.Definition 1 set X \ E irreducible respect evidence e Xi S, Xiconditionally independent given e \ {Xi }.Given Bayesian network X , straightforward check irreducibilityd-separation (Pearl, 1988).Proposition 1 Let S0 maximal irreducible subset respect e. Then, EV I(S |e) = EV I(S0 | e).Proof: Let S00 = \ S0 . S0 maximal irreducible set, S0 E d-separates S00 .Otherwise, could make S0 larger including non-d-separated element(s) S00S0 . Thus, P (Y | e, s) = P (Y | e, S0 , S00 ) = P (Y | e, S0 ). Substitution Equations1 5 yields desired property.Note assumption C(S0 | e) C(S | e) S0 S, sufficesconsider irreducible sets find optimal solution objective functionEquation (7). VOILA data structure contains irreducible feature subsetsX, respect particular set evidence e. next define VOILA formally.Definition 2 VOILA V directed acyclic graph node correspondingpossible irreducible set features, directed edge feature setnode corresponds direct (maximal) subset S. subset relationshipslattice defined directed paths V.76fiValue Information Lattice(a)(b)Figure 3: (a) simple Bayesian network illustrating dependencies attributesclass variable. (b) VOILA corresponding network.Figure 3(a) shows simple Bayesian network corresponding VOILA, respectempty evidence set, shown Figure 3(b). Notice VOILA containsirreducible subsets given Bayesian network; instance, VOILA containsets include X1 X2 X1 d-separates X2 . also observenumber irreducible subsets 9 contrast 24 = 16 possible subsets. Moreover,note largest subset size 3 contrast 4. smaller feature sets sizesdramatic effect value information calculations. fact, savingsmake solving objective function optimally (Equation (7)) feasible practice.3.2 Sharing EVI CalculationsFinding set highest Benefit (Equation 6) requires computing EV I(S)(Equation 5). However, computing EV I(S) requires taking expectation possiblevalues features S. Moreover, searching best set among irreducible setsrequires us compute EVI irreducible sets. make computations tractablepractice, VOILA allows computation sharing nodes. article, describethree possible ways sharing computations nodes VOILA.77fiBilgic & Getoor3.2.1 Subset RelationshipsVOILA exploits subset relationships different feature sets order avoidcomputing EVI nodes. First all, directed path node S1 S2VOILA, S1 S2 thus EV I(S1 | e) EV I(S2 | e)1 . assumedirected path Si Sj EV I(Si | e) = EV I(Sj | e). Then, nodespath also EVI, thus need computationsubsets. algorithm makes use observation given Algorithm 1.Algorithm 1: Efficient EVI computation using VOILA.Input: VOILA V current evidence EOutput: VOILA updated correct EVI values1 root node(s)2value EV I(S | e); ub(S) value; lb(S) value3ub(descendants(S)) value45678910leaf node(s)value EV I(S | e); ub(S) value; lb(S) valuelb(ancestors(S)) valuenode lb(S) 6= ub(S)value EV I(S | e); ub(S) value; lb(S) valuelb(ancestors(S)) valueub(descendants(S)) valueimportant point nodes VOILA irreducible sets. Unlesstotally useless features change P (Y ) observed,two distinct nodes EVI values exactly equal. However, statementtrue context-specific independencies (independencies holdcertain assignments variables) underlying Bayesian network.description implementation, used standard d-separation variable level; oneimagine going one step define irreducible sets variablelevel d-separation context specific independencies.order share computations different nodes lattice, keep lowerupper bounds EVI node. lower bound determined valuesdescendants node whereas upper bound determined valuesancestors. First, initialize bounds computing value informationboundary lattice, i.e., root node(s) leaf node(s) (lines 16) 2 . Then,loop nodes whose upper bounds lower bounds equal (line 710),computing values updating bounds ancestors descendants.algorithm terminates upper bounds lower bounds nodes becometight. order choose nodes line 7 number setsvalue calculated minimum still open question. possible heuristic perform1. superset always higher equivalent EVI (Equation (5)) subset.2. need compute EVI root nodes; suffices compute node correspondsMarkov blanket . explained detail next section.78fiValue Information Latticebinary search choose middle node path two nodes valuesalready calculated.3.2.2 Information Pathways Underlying Bayesian Networksecond mechanism VOILA uses share EVI computations edgesunderlying Bayesian network. specifically make use following fact:Proposition 2 S1 S2 , S1 d-separates S2 respect e,EV I(S1 | e) EV I(S2 | e).Proof: Consider S12 = S1 S2 . subset relationship, know EV I(S12 |e) EV I(S1 | e) EV I(S12 | e) EV I(S2 | e).EV I(S12 | e) = EM C(Y | e)XP (s12 | e)EM C(Y | e, s12 )s12= EM C(Y | e)XXs1= EM C(Y | e)XXs1= EM C(Y | e)XP (s1 , s2 | e)EM C(Y | e, s1 , s2 )s2P (s1 , s2 | e)EM C(Y | e, s1 )s2P (s1 | e)EM C(Y | e, s1 )s1= EV I(S1 | e)EV I(S2 | e)third line follows second fact S1 d-separates S2 thusP (Y | s1 , s2 ) = P (Y | s1 ).Corollary: Markov blanket , (i.e., parents, children, childrensparents), set highest EVI search space, d-separatesremaining variables . Using corollary, need compute EVIroot nodes Algorithm 1; compute EVI root node correspondsMarkov blanket serves upper bound EVI remainingroot nodes.relationships well exploited like exploited subset relationshipsabove. Instead using subset relationships, use subset independence relationships. One simple way make use Algorithm 1 without modificationadd edges S1 S2 independence property holds. example S1 S2 according toy network Figure 3(a) would S1 = {X1 }S2 = {X2 }. Thus, add directed edge X1 X2 VOILA Figure 3(b)Algorithm 1 work fine.3.2.3 Incremental Inferencethird last mechanism VOILA uses computation sharingcaching probabilities nodes. candidate set V, need computeEV I(S | e) requires computing P (S | e) EM C(Y | S, e). cache79fiBilgic & Getoorconditional probabilities node V, computeP (S | e), find onePsupersets Si = {Xi } compute P (S | e) = xi P (S, Xi = xi | e).Computing EM C(Y | S, e) requires computing P (Y | S, e). perform computation efficiently, cache state junction tree node VOILA. Then,find subset, Sj , = Sj {Xj }. compute P (Y | S, e) integratingextra evidence junction tree node Sj used compute P (Y | Sj , e).3.3 Constructing VOILAEfficient construction VOILA straightforward task. brute force approachwould enumerate possible subsets X \ E subset check whetherirreducible. However, brute force approach clearly impractical. numbernodes VOILA expected much fewer number possible subsets X\E,smart sets consider inclusion V, constructefficiently. is, instead generating possible candidates checking whetherirreducible not, try generate irreducible sets. first introducenotion dependency constraint explain use dependency constraintsefficiently construct VOILA.Definition 3 dependency constraint feature Xi respect Econstraint E ensures dependency Xi exists.instance, running example, dependency constraint X2 X1 ;words, order X2 relevant, X1 included E. Similarly,dependency constraint X4 X3 , meaning X3 must included SE. Specifically,dependency constraint feature Xi requires Xj path Xiincluded E Xj part v-structure; Xj part v-structure,either Xj one descendants must included E (we refer latterconstraints positivity constraints). algorithm uses ideas computedependency constraints feature given Algorithm 2.Algorithm 2: Dependency constraint computation Xi .Input: Xi ,Output: Dependency constraint Xi , denoted DC(Xi )1 DC(Xi ) false2 undirected path pj Xi3DCj (Xi ) true4Xk path pj5Xk cause v-structure6DCj (Xi ) DCj (Xi ) Xk7else8DCj (Xi ) DCj (Xi ) (Xk Descendants(Xk ))9DC(Xi ) DC(Xi ) DCj (Xi )80fiValue Information Latticedependency constraints used check whether set irreduciblepotentially irreducible. Intuitively, set potentially irreducible irreduciblepossible make set irreducible adding features it. formally,Definition 4 set X \ E potentially irreducible respect evidence e if,irreducible exists non-empty set features S0 X \ {E S}S0 irreducible.Potential irreducibility possible due non-monotonic nature d-separation. is,feature d-separated become dependent consider combinationfeatures. example, running example, {X4 } irreducible, X4d-separated , whereas {X3 , X4 } irreducible.use dependency constraints check whether set irreducible potentiallyirreducible. set irreducible dependency elementsexists, dependency constraint set conjunction dependencyconstraints members. irreducibility checked setting elementsE true setting remaining elements X false evaluatingsets dependency constraint. running example, dependency constraint set{X2 , X4 } X1 X3 . Assuming E = , set members {X2 , X4 } true,set remaining features, X1 X3 , false, X1 X3 evaluates false thusset irreducible. makes sense given evidence, X4 independent, {X2 } useful feature set consider acquisition, {X2 , X4 } not.Checking potential irreducibility similar. Set elements E truelike above. Then, set positivity constraints members true. Finally,set everything else false. Using example above, check whether {X2 , X4 }potentially irreducible, set X2 = true, X4 = true. Also set X3 = truepositivity constraint X4 . Set remaining features, X1 , false. Evaluatingconstraint X1 X3 yields true, showing {X2 , X4 } potentially irreducible (whileirreducible).Given definitions irreducibility potential irreducibility mechanismscheck properties notion dependency constraints, next describealgorithm construct VOILA.VOILA construction proceeds bottom fashion, beginning lowest level,initially contains empty set constructs new irreducible feature setsadding one feature time VOILA structure. Algorithm 3 gives detailsalgorithm. algorithm keeps track irreducible feature sets IS, setpotentially irreducible feature sets PS. done processing feature Xij ,remove PS potentially irreducible set cannot become irreducible Xijre-considered (line 11).3.3.1 Analysis VOILA Construction Algorithmconstruction algorithm inserts node VOILA corresponding setirreducible (lines 6 7). Moreover, keeping track potentially irreducible sets(lines 810), generate every possible irreducible set generated. Thus, VOILAcontains possible irreducible subsets X.81fiBilgic & GetoorAlgorithm 3: VOILA construction algorithm.Input: Set features X class variable .Output: VOILA data structure V, given E.1 Pick ordering elements X = Xi1 , Xi2 , . . . , Xin2 {}; PS3 j = 1 n4PS5S0 Xij ; DC(S0 ) DC(S) DC(Xij )6S0 irreducible7{S0 }; Add node corresponding S0 V8else9S0 potentially irreducible10PS PS {S0 }11121314151617Remove PS sets longer potentially irreduciblemax = size largest IS; = {S | |S| = l}l = 0 max 1S0 Ll+1S0Add edge S0 Vworst-case running time algorithm still exponential numberinitially unobserved features, X \ E, number irreducible sets potentiallyexponential. running time practice, though, depends structureBayesian network VOILA based upon ordering variables line 1.example, Bayesian network naive Bayes, subsets irreducible (nofeature d-separates feature class variable); thus, search space cannotreduced all. However, naive Bayes makes extremely strong assumptionsunlikely hold practice. fact, empirically show experiments section fivereal-world datasets, features often conditionally independent given class variable;complex interactions thus number irreduciblesubsets substantially smaller number possible subsets.loop line 4 iterates irreducible potentially irreducible setsgenerated far, number potentially-irreducible sets generateddepends ordering chosen. good ordering processes features literalspositivity constraints features dependency constraints earlier. is,undirected path Xi includes Xj v-structure, good ordering puts Xjearlier ordering everything Xj Xi . instance, sampleBayesian network Figure 3(a), consider X3 earlier X4 . referordering perfect satisfies positivity constraints. perfect ordering used,VOILA construction algorithm never generates potentially irreducible set. Unfortunately,82fiValue Information Latticealways possible find perfect ordering. perfect ordering possible twofeatures positivity constraint literal dependency constraints.case occurs loop two v-structures(Note even though Bayesian network directed acyclic graph, still containloops, i.e., undirected cycles). perfect ordering possible four five real worlddatasets used.3.4 Using VOILA Feature-value AcquisitionVOILA makes searching space possible subsets tractable practice. Usingflexibility, possible devise several different acquisition policies. describe twopolicies example policies section.first acquisition policy aims capture practical setting onefeature acquired once. policy constructed using VOILA follows.path ps policy (which initially empty) repeatedly extended acquiringset S0 V best Benef it(S0 | s, e). policy construction ends pathextended, i.e., candidate sets non-positive Benefit values path .second acquisition policy adds look-ahead capability greedy policy.is, rather repeatedly extending path ps policy feature Xihighest Benef it(Xi | s, e), add look-ahead capability, first find set S0 Vhighest Benef it(S0 | s, e). Then, instead acquiring features S0once, like policy, find feature Xi S0 highestBenef it(Xi | s, e) acquire extend ps .4. Experimentsexperimented five real-world medical datasets Turney (1995) describedused paper. datasets Bupa Liver Disorders, Heart Disease, Hepatitis,Pima Indians Diabetes, Thyroid Disease, available UCI MachineLearning Repository (Frank & Asuncion, 2010). datasets varying numberfeatures ranging five 20. Four five datasets binary labels, whereasThyroid dataset three labels.dataset, first learned Bayesian Network provides jointprobability distribution P (Y, X) efficiently answers conditional independence queriesthorough d-separation (Pearl, 1988). built VOILA dataset using learnedBayesian Network. first present statistics dataset, number featuresnumber nodes VOILA, compare various acquisition policies.4.1 Search Space ReductionTable 1 shows aggregate statistics dataset, describing number features,number possible subsets, number subsets VOILA, percent reductionsearch space. table shows, number irreducible subsets substantiallyfewer possible subsets. Thyroid Disease dataset, example, numberpossible subsets million whereas number irreducible subsets fewer83fiBilgic & GetoorTable 1: Aggregate statistics dataset. number irreducible subsets, i.e.,number nodes VOILA, substantially fewer number possiblesubsets.DatasetBupa Liver DisordersPima Indians DiabetesHeart DiseaseHepatitisThyroid DiseaseFeaturesSubsetsNodes VOILAReduction58131920322568,192524,2881,048,5762613999018,13228,80619%46%88%97%97%thirty thousand. enormous reduction search space makes searchingpossible sets features tractable practice.4.2 Expected Total Cost Comparisonscompared expected total costs (Equation 2) four different acquisition policiesdataset. policies follows:Acquisition: policy acquire features; aims minimizeexpected misclassification cost based prior probability distribution classvariable, P (Y ).Markov Blanket: policy acquires every relevant feature, regardless misclassification costs. Market Blanket Bayesian network definedparents, children, childrens parents (Pearl, 1988). Intuitively,minimal set X (X \ S) | S.Greedy: policy repeatedly expands path ps initially empty policyacquiring feature Xi highest positive Benef it(Xi | s) (Equation4). policy construction ends path extended featurepositive Benefit value.Greedy-LA: policy adds look-ahead capability Greedy strategy.policy repeatedly expands path ps initially empty policy first findingset S0 highest positive Benef it(S0 | s) (Equation 6) acquiringfeature Xi S0 maximum Benef it(Xi | s) (Equation 4). policyconstruction ends set positive Benefit value found pathpolicy.feature costs dataset described detail Turney (1995). summary,feature either independent cost, belong group features,first feature group incurs additional cost. example, first featuregroup blood measurements incurs overhead cost drawing blood patient.feature costs based data Ontario Ministry Health (1992).84fiValue Information LatticeTable 2: Example misclassification cost matrix (cij ) symmetric asymmetric misclassification costs. cij set way achieve prior expected misclassificationcost 1. symmetric cost case, choosing probable class leadsEM C = 1, whereas, asymmetric cost case, choosing either classindifferent leads EMC 1.Actual ClassPrior ProbabilityPred. ClassSymm. CostAsymm. Costy1P (y1 ) = 0.6510y1y202.86602.866y2P (y2 ) = 0.3490y1y22.86601.5360observed features assigned cost. example, fourfive features Bupa Liver Disorders dataset, 13 19 features Hepatitisdataset, six eight features Diabetes dataset, 16 20 featuresThyroid Disease dataset assigned cost. costs similar,problem practically equivalent finding minimum size decision tree. providestructure feature acquisition costs, also experimented randomly generatedfeature group costs. feature, randomly generated cost 1 100,group generated cost 100 200. repeated experimentsthree different seeds dataset.misclassification costs defined paper Turney (1995). One reasoncould easier define feature costs, defining cost misclassification non-trivial. Instead, Turney tests different acquisition strategies usingvarious misclassification costs. follow similar technique slight modification.compare acquisition policies symmetric (cij = cji ) asymmetricmisclassification costs. able judge misclassification cost structure affectsfeature acquisition, unify presentation, compare different acquisition strategiespriori expected misclassification costs, defined Equation (1). Specifically, compare acquisition policies various priori EMC achievedvarying cij accordingly. show example misclassification table EMC value1 Table 2. real feature cost case, varied EMC 0 2000,varied 0 4000 synthetic feature cost case.compare Greedy, Greedy-LA, Markov Blanket policies plottingmuch cost policy saves respect Acquisition policy. X axisplots, vary priori expected misclassification cost using methodologydescribed above. plot savings axis. dataset, plot four differentscenarios: cross product {symmetric, asymmetric} misclassification costs, {real,synthetic} feature costs.results Liver Disorders, Diabetes, Heart Disease, Hepatitis, ThyroidDisease given Figures 4, 5, 6, 7, 8 respectively. figure, symmetricmisclassification cost scenarios given sub-figures (a) (c), whereas asymmetric85fiBilgic & Getoor(a)(b)(c)(d)Figure 4: Expected Total Cost (ETC ) comparisons Bupa Liver Disorders dataset.priori class distribution follows: P (Y ) = [0.4959, 0.5041].misclassification cost scenarios presented (b) (d). Similarly, real feature costscenarios given (a) (b) synthetic feature cost scenarios presented(c) (d). next summarize results.found Greedy policy often prematurely stopped acquisition, performingeven worse Markov Blanket strategy. true datasets,regardless feature misclassification cost structures. fact Greedystrategy perform worse Markov Blanket strategy really troubling. first,might seem rather unintuitive Greedy strategy perform worse MarkovBlanket strategy. Part reason features belong groups firstfeature group incurs overhead cost. Greedy strategy featureconsidered isolation, overhead costs outweigh single features benefit,Greedy look ahead, reluctant commit acquiringfirst feature group.86fiValue Information Lattice(a)(b)(c)(d)Figure 5: Expected Total Cost (ETC ) comparisons Pima Indian Diabetes dataset.priori class distribution follows: P (Y ) = [0.6510, 0.3490].Greedy-LA strategy never performs worse strategy setting.misclassification cost structure (symmetric asymmetric) considerableeffect policies behaved. differences symmetric asymmetric cases particularly evident datasets class distributionimbalanced, Diabetes (Figure 5), Hepatitis (Figure 7), ThyroidDisease (Figure 8) datasets. differences due misclassification cost structuresummarized follows:class distribution imbalanced misclassification cost symmetric, acquiring information cannot change classification decisionseasily due class imbalance, thus features high EVI values.hand, misclassification costs asymmetric, features tendhigher EVI values. Thus, Greedy Greedy-LA strategies startacquiring features earlier X axis asymmetric cases compared87fiBilgic & Getoor(a)(b)(c)(d)Figure 6: Expected Total Cost (ETC ) comparisons Heart Disease dataset. prioriclass distribution follows: P (Y ) = [0.5444, 0.4556].symmetric counterparts. example, Thyroid disease datasetreal feature costs, Greedy strategy starts acquisition EMCgreater 600 symmetric misclassification costs (Figure 8(a)) whereasstarts acquiring EMC reaches 100 asymmetric case (Figure 8(b)). synthetic feature costs, results dramatic; neitherGreedy Greedy-LA acquires features symmetric cost case (Figure 8(c)), whereas start acquisition EM C = 200 asymmetriccase (Figure 8(d)).realm results, slope savings asymmetric case much higher compared symmetric case.misclassification cost structure causes differences GreedyGreedy-LA policies cases. Diabetes dataset Greedy policy performs worse misclassification costs symmetric (Figures 5(a)88fiValue Information Lattice(a)(b)(c)(d)Figure 7: Expected Total Cost (ETC ) comparisons Hepatitis dataset. priori classdistribution follows: P (Y ) = [0.7908, 0.2092].5(c)), whereas Hepatitis dataset, performs worse asymmetricmisclassification costs (Figures 7(b) 7(d)).Greedy policy sometimes erratic, unpredictable, unreliable performance expected misclassification changes. possibly hits local minima, getslater, hits local minima (Figures 6 8(d)).finally present aggregate summary results Table 3. Table 3 showsmuch Greedy policy Greedy-LA policy saves Markov Blanket policy.results presented average saving various intervals, [0-500).table also shows, Greedy-LA policy never loses compared Markov Blanketpolicy, one would expect. Additionally, Greedy-LA policy wins Greedypolicy cases, never looses. Finally, Greedy policy prematurely stopsacquisition, negative savings respect Markov Blanket strategy.89fiBilgic & Getoor(a)(b)(c)(d)Figure 8: Expected Total Cost (ETC ) comparisons Thyroid Disease dataset.priori class distribution follows: P (Y ) = [0.0244, 0.0507, 0.9249].5. Related WorkDecision theoretic value information calculations provide principled methodologyinformation gathering general (Howard, 1966; Lindley, 1956). Influence diagrams,example, popular tools representing decisions utility functions (Howard &Matheson, 1984). However, devising optimal acquisition policy (i.e., constructing optimal decision tree) intractable general, approaches featureacquisition myopic (Dittmer & Jensen, 1997), greedily acquiring one featuretime. greedy approaches typically differ i) problem setup assume, ii)way features scored, iii) classification model learned. reviewexisting work here, highlighting differences different techniques threedimensions.Gaag Wessels (1993) consider problem evidence gathering diagnosisusing Bayesian Network. setup, gather evidence (i.e., observe valuesvariables) hypothesis confirmed disconfirmed desired extent.90fiValue Information LatticeTable 3: Savings Greedy (GR) Greedy-LA (LA) respect Markov Blanketpolicy, averaged different intervals. entry bold worseGreedy-LA, red worse Markov Blanket.LiverGRLADiabetesGRLAHeartGRLAHepatitisGRLAThyroidGRLAReal Feature Costs & Symmetric Misclassification Costs[0-500)[500-1000)[1000-1500)[1500-2000]6.77-18.84-42.12-67.599.082.702.662.8515.49-18.28-48.35-81.4324.2717.0617.3517.34240.59121.3179.07-24.98243.31144.87116.68111.344.19-6.06-14.32-23.405.863.903.903.8528.0713.9013.4113.4128.0713.9013.4113.415.842.572.572.5717.71.561.561.5617.71.561.561.56231.93106.5496.3988.1479.8871.6368.6763.66298.01277.70257.40237.09216.79196.48176.18153.84298.01277.70257.40237.09216.79196.48176.18153.84276.32213.60162.52113.8265.1228.720.78-18.10276.32213.60162.52113.8268.3934.7314.679.50Real Feature Costs & Asymmetric Misclassification Costs[0-500)[500-1000)[1000-1500)[1500-2000]7.33-16.78-38.26-61.889.32.663.042.9722.749.853.99-2.5423.8413.3111.713.7245.79131.3646.20-40.96245.79143.3114.23107.14-9.55-47.61-84.79-125.69Synthetic Feature Costs & Symmetric Misclassification Costs[0-500)[500-1000)[1000-1500)[1500-2000)[2000-2500)[2500-3000)[3000-3500)[3500-4000]307.39160.9560.3031.8610.43-14.60-39.64-67.18307.39160.9579.7653.9753.0162.6659.9663.68418.34245.75163.80138.78108.6978.9048.8315.75418.34288.65224.09163.45163.78164.75172.76172.13723.36579.25444.42378.43364.03268.00171.91109.91723.36585.72539.88490.23482.24458.89422.06412.11231.9363.5996.3988.1479.8871.6363.3854.30Synthetic Feature Costs & Asymmetric Misclassification Costs[0-500)[500-1000)[1000-1500)[1500-2000)[2000-2500)[2500-3000)[3000-3500)[3500-4000]306.19156.7866.5737.4714.84-9.19-33.22-59.66306.19156.7879.7960.6255.7058.8559.3363.13441.29341.28260.09201.19161.24144.24132.84126.43441.29341.28261.21204.31164.17151.22139.54136.51728.57599.02505.80420.56320.32211.26248.73206.06728.57603.12517.37519.29512.75500.75400.16389.32219.0488.34-16.86-54.31-64.75-101.93-139.11-180.01219.0491.5349.3961.9061.9061.9061.9061.90propose acquisition algorithm greedily computes expected utility acquiringfeature chooses one highest utility. define utility absolutevalue change probability distribution hypothesis tested.recent work, Sent Gaag (2007) consider problem acquiringsingle feature step. define subgoals cluster features subgoal.subgoals clustering features provided domain experts. Then,non-myopic case, pick cluster calculating expected values. However,91fiBilgic & Getoorclusters big, calculating expected value cluster problematic;thus, also provide semi-myopic algorithm pick clusterbest (myopic) feature.Nunez (1991) introduces decision tree algorithm called EG2 sensitivefeature costs. Rather splitting decision tree feature high informationgain, EG2 chooses feature least information cost function, definedratio features cost discriminative efficiency. EG2 is, however, directlyoptimized balance misclassification cost feature acquisition cost; ratheroptimized 0/1 loss taking feature costs account. Similarly, Tan (1990)modifies ID3 algorithm (Quinlan, 1986) account feature costs. Tan considersdomain robot needs sense, recognize, act, number featureslarge. robot act efficiently, needs trade-off accuracy efficiency.Turney (1995) builds decision tree called ICET (standing Inexpensive ClassificationExpensive Tests) using genetic search algorithm (Grefenstette, 1986) usingNunezs (1991) criteria build C4.5 decision trees (Quinlan, 1993). Unlike Nunez, Turneytakes misclassification costs account (in addition feature costs) evaluategiven decision tree looks good decision tree using genetic search algorithms.Yang et al. (2006) build cost-sensitive decision trees Naive Bayes classifierstake feature costs misclassification costs account. Unlike Nunez (1991),scores features based information gain cost ratio, Yang et al. score features basedexpected reduction total cost (i.e., sum feature cost misclassificationcost) training data. so, take feature costs misclassification costsaccount directly learning time.Bayer-Zubek (2004) formulates feature acquisition problem Markov DecisionProcess provides greedy systematic search algorithms develop diagnosticpolicies. Bayer-Zubek takes feature cost misclassification costs accountautomatically finds acquisition plan balances two costs. introducesadmissible heuristic AO* search describes regularization techniques reduce overfitting training data.Saar-Tsechansky, Melville, Provost (2009) consider active feature acquisitionclassifier induction. Specifically, given training data missing feature values, cost matrix defines cost acquiring feature value, describeincremental algorithm select best feature acquire iteratively buildmodel expected high future performance. utility acquiring featureestimated terms expected performance improvement per unit cost. two characteristics make work different previous work i) authorsassume fixed budget priori; rather build model incrementally, ii)feature different cost instance.Finally, Greiner, Grove, Roth (2002) analyze sample complexity dynamicprogramming algorithms performs value iteration search best diagnosticpolicies. analyze problem learning optimal policy, using variantprobably-approximately-correct (PAC) model. show learning achievedefficiently active classifier allowed perform (at most) constant numbertests show learning optimal policy often intractable generalenvironments.92fiValue Information Lattice6. Future Workarticle, scratched surface incorporating constraintsfeatures order reduce search space make reasoning sets tractable.discovered two types constraints (features render features useless,features useless without features) purely underlying probabilitydistribution. shown automatically discovered constraints helped reducesearch space dramatically. practice, possible discover additional typesconstraints potentially used reduce search space (for e.g., orderingconstraints certain procedures always precede procedures). Constraintsalso defined based observed feature values; example, treadmill test mightperformed patients old age. Patients decline certain procedures medications.Eliciting constraints domain experts utilizing reducesearch space promising future direction.existing feature acquisition frameworks, including one, majorsimplification happens practice; assumed acquiring valuesfeatures change class value values variables. However, practice,feature value measurements side-effects, example, medical diagnosiscertain measurements non-invasive change status patient, othersmight include medications affect outcome. Similarly, fault diagnosisrepair, purpose diagnose repair fault, actionsfact repair fault, essence changing class value. Taking extra side-effectsaccount make feature acquisition frameworks realistic.7. Conclusiontypical approach feature acquisition greedy past primarily duesheer size possible subsets features. described general techniqueoptimally prune search space exploiting conditional independence relationshipsfeatures class variable. empirically showed exploiting conditional independence relationships substantially reduce number possible subsets.also introduced novel data structure called Value Information Lattice (VOILA)efficiently reduce search space using conditional independence relationships also share probabilistic inference computations different subsetsfeatures. using VOILA, able add full look-ahead capability greedyacquisition policy, would practical otherwise. experimentally showedfive real-world medical datasets greedy strategy often stopped feature acquisitionprematurely, performing worse even policy acquires features.Acknowledgmentsthank reviewers helpful constructive feedback. materialbased work supported National Science Foundation Grant No. 0746930.93fiBilgic & GetoorReferencesBayer-Zubek, V. (2004). Learning diagnostic policies examples systematic search.Annual Conference Uncertainty Artificial Intelligence.Bilgic, M., & Getoor, L. (2007). VOILA: Efficient feature-value acquisition classification.AAAI Conference Artificial Intelligence, pp. 12251230.Dittmer, S., & Jensen, F. (1997). Myopic value information influence diagrams.Annual Conference Uncertainty Artificial Intelligence, pp. 142149.Frank, A., & Asuncion, A. (2010). UCI machine learning repository..Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic belief networks.AISB Quarterly, pp. 2334.Grefenstette, J. (1986). Optimization control parameters genetic algorithms. IEEETransactions Systems, Man Cybernetics, 16 (1), 122128.Greiner, R., Grove, A. J., & Roth, D. (2002). Learning cost-sensitive active classifiers.Artificial Intelligence, 139 (2), 137174.Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computation value information. IEEE Transactions Pattern Analysis MachineIntelligence, 15 (3), 292298.Howard, R. A., & Matheson, J. E. (1984). Readings Principles ApplicationsDecision Analysis, chap. Influence Diagrams. Strategic Decision Group.Howard, R. A. (1966). Information value theory. IEEE Transactions Systems ScienceCybernetics, 2 (1), 2226.Hyafil, L., & Rivest, R. L. (1976). Constructing optimal binary decision trees NPComplete. Information Processing Letters, 5 (1), 1517.Lindley, D. V. (1956). measure information provided experiment. AnnalsMathematical Statistics, 27, 9861005.Nunez, M. (1991). use background knowledge decision tree induction. MachineLearning, 6 (3), 231250.Health, O. M. (1992). Schedule benefits: Physician services health insuranceact..Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann, SanFrancisco.Quinlan, J. R. (1986). Induction decision trees. Machine Learning, 1 (1), 81106.Quinlan, J. R. (1993). C4.5: programs machine learning. Morgan Kaufmann PublishersInc., San Francisco, CA, USA.Saar-Tsechansky, M., Melville, P., & Provost, F. (2009). Active feature-value acquisition.Management Science, 55 (4), 664684.Sent, D., & Gaag, L. C. (2007). Enhancing automated test selection probabilistic networks. Proceedings 11th conference Artificial Intelligence Medicine,pp. 331335.94fiValue Information LatticeTan, M. (1990). CSL: cost-sensitive learning system sensing grasping objects.IEEE International Conference Robotics Automation.Turney, P. D. (1995). Cost-sensitive classification: Empirical evaluation hybrid geneticdecision tree induction algorithm. Journal Artificial Intelligence Research, 2, 369409.Yang, Q., Ling, C., Chai, X., & Pan, R. (2006). Test-cost sensitive classification datamissing values. IEEE Transactions Knowledge Data Engineering, 18 (5),626638.95fiJournal Artificial Intelligence Research 41 (2011) 155-229Submitted 01/11; published 06/11Analyzing Search Topology Without Running Search:Connection Causal Graphs h+Jorg Hoffmannjoerg.hoffmann@inria.frINRIANancy, FranceAbstractignoring delete lists relaxation paramount importance satisficingoptimal planning. earlier work, observed optimal relaxation heuristich+ amazing qualities many classical planning benchmarks, particular pertainingcomplete absence local minima. proofs hand-made, raisingquestion whether proofs lead automatically domain analysis techniques.contrast earlier disappointing results analysis method exponential runtimesucceeds two extremely simple benchmark domains herein answerquestion affirmative. establish connections causal graph structureh+ topology. results low-order polynomial time analysis methods, implementedtool call TorchLight. 12 domains absence local minimaproved, TorchLight gives strong success guarantees 8 domains. Empirically, analysisexhibits strong performance 2 domains, plus 4 domainslocal minima may exist rare. way, TorchLight distinguish easy domainshard ones. summarizing structural reasons analysis failure, TorchLight alsoprovides diagnostic output indicating domain aspects may cause local minima.1. Introductionignoring delete lists relaxation since decade, still is, paramountimportance effective satisficing planning (e.g., McDermott, 1999; Bonet & Geffner, 2001;Hoffmann & Nebel, 2001a; Gerevini, Saetti, & Serina, 2003; Helmert, 2006; Richter &Westphal, 2010). recently, heuristics making relaxation also shownboost optimal planning (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009).planners using relaxation approximate, variety ways, optimal relaxationheuristic h+ NP-hard compute (Bylander, 1994). observedearlier work (Hoffmann, 2005), h+ rather amazing qualities many classicalplanning benchmarks. Figure 1 gives overview results.1results divide domains classes along two dimensions. herein ignore horizontal dimension, pertaining dead ends, domain analysis already available:easy-to-test powerful criteria implying task undirected/harmless known(e.g., Hoffmann, 2005). vertical dimension divides domains three classes,respect behavior exit distance, defined 1 distance statestrictly smaller h+ value. easiest bottom class, exist constant upper1. omit ADL domains, add recent IPC benchmarks Elevators Transport (withoutaction costs), properties trivial prove based earlier results. Blocksworld-Armclassical blocksworld, Blocksworld-NoArm variant allowing move B C directly.c2011AI Access Foundation. rights reserved.fiHoffmannPipesworldTankPipesworldNoTankPSRRoversOpticalTelegraphMysteryMprimeFreecellAirportHanoi [0]BlocksworldNoArm [0]Grid [0]Transport [0]bench ed <= clocal minima ed <= cBlocksworldArmDepotsDriverlogElevators [0,1]Logistics [0,1]Ferry [0,1]Gripper [0,1]undirectedTyreworld [0,6]Satellite [4,4]Zenotravel [2,2]MiconicSTRIPS [0,1]Movie [0,1]SimpleTsp [0,0]harmlessDiningPhil. [31,31]recognizedunrecognizedFigure 1: Overview h+ topology (Hoffmann, 2005).bounds exit distance both, states local minima states benches (flat regions). figure, bounds given square brackets. example, Logistics,bound local minima 0 meaning local minima exist boundbenches 1. middle class, bound exists local minima; bound0 (no local minima all) domains shown. hardest top class, localminima benches may take arbitrarily many steps escape.proofs underlying Figure 1 hand-made. dealing unseen domains,question arises whether design domain analysis methods leading proofsautomatically. potential uses analysis methods manifold; discussend paper. now, note addressing question formidable challenge.trying automatically infer properties characterizing informativeness (or lackthereof ) heuristic function. wish based static analysis, actuallyrunning search. Formally characterizing informativeness heuristic functionis, cases, hardly possible even experienced researchers, explains perhapsno-one far even attempted automatically. single exception,best authors knowledge, analysis method mentioned sideauthors earlier work (Hoffmann, 2005). analysis method builds exponentiallylarge tree structure summarizing ways relaxed plans may generate facts.tree size, therewith analysis runtime, explodes quickly task size. Worse,analysis succeeds Movie Simple-TSP arguably two simplistic planningbenchmarks existence.2contrast, TorchLight tool developed herein low-order polynomial runtimeusually terminates split seconds. Distinguishing global (per task) local (perstate) analysis, proves global absence local minima Movie, Simple-TSP, Logistics,Miconic-STRIPS. gives strong guarantee local analysis succeed every stateFerry, Gripper, Elevators, Transport. Taking success rate fractionstates local analysis succeeds, TorchLight empirically exhibits strong performancedelivering high success rates also Zenotravel, Satellite, Tyreworld, Grid, Driverlog,2. Simple-TSP encodes TSP fully connected graph uniform edge cost. domainintroduced Fox Long (1999) benchmark symmetry detection.156fiAnalyzing Search Topology Without Running SearchRovers. Thus TorchLights success rates tend high easy domains Figure 1,low hard ones, serving automatically distinguish twogroups.3 summarizing structural reasons analysis failure, TorchLight finally providesdiagnostic output indicating problematic aspects domain, i.e., operator effectspotentially cause local minima h+ .key performance boost? Consider Logistics Blocksworld-Arm.level PDDL domain descriptions, difference evidentdelete effects, Blocksworld-Arm hurt Logistics dont?trick move finite-domain variable representation (e.g., Jonsson &Backstrom, 1998; Helmert, 2006, 2009) consider associated structures, notablycausal graph (e.g., Knoblock, 1994; Jonsson & Backstrom, 1995; Domshlak & Dinitz,2001; Helmert, 2006) capturing precondition effect dependencies variables.causal graph Blocksworld-Arm contains cycles. Logistics doesnt. Lookingthis, surprisingly easy derive following basic result:causal graph acyclic, every variable transition invertible,local minima h+ .result certainly interesting that, first time, establishes connectioncausal graph structure h+ topology. However, result muchweak domain analysis considered benchmarks, applies Logistics. devise generalizations approximations yielding analysis results describedabove. Aside significance domain analysis, techniques also interestingrespect research causal graphs. Whereas traditional methods (e.g., Jonsson &Backstrom, 1995; Brafman & Domshlak, 2003; Jonsson, 2009; Gimenez & Jonsson, 2009a)seek execution paths solving overall task, seek execution paths decreasingvalue h+ . local analysis, enables us consider small fragments causalgraph, creating potential successfully analyze states tasks whose causal graphsotherwise arbitrarily complex.next section gives brief background planning finite-domain variables,associated notions causal graphs definition h+ topology. Section 3 gives illustrative example explaining basic result, Section 4 providessynopsis full technical results relating causal graphs h+ topology. Sections 56 present results detail, explaining first analyze stateprovided given optimal relaxed plan input, thereafter providingcriteria causal graph structure implying analysis always succeed. evaluate domain analysis technique proving number domain-specific performanceguarantees Section 7, reporting large-scale experiment TorchLight Section 8. point related work within context appropriate, discuss detailsSection 9. close paper discussion future work Section 10. improvereadability, main text omits many technical details outlines proofs.full details including proofs Appendix A.3. extent, particular result also achieved simpler means (limited search probing).discuss along experiments Section 8.157fiHoffmann2. Backgroundadopt terminology notation Helmert (2006), number modificationssuiting purposes. (finite-domain variable) planning task 4-tuple (X, sI , sG , O). Xfinite set variables, x X associated finite domain Dx . partialstate X function subset Xs X, s(x) Dx x Xs ; stateXs = X. initial state sI state. goal sG partial state. finite setoperators. pair = (preo , eff ) partial states, called preconditioneffect. simple non-restricting sanity conditions, assume |Dx | > 1 x X,preo (x) 6= eff (x) x Xpreo Xeff .identify partial states sets variable-value pairs, often referfacts. state space task directed graph whose vertices statesX, arc (s, s0 ) iff exists preo s, eff s0 , s(x) = s0 (x)x X \ Xeff . plan path leading sI state sG s.next define two basic structures analysis: domain transition graphscausal graphs. former, diverge Helmerts definition (only)introduce additional notations indicating operator responsible transition, wellside effects transition, i.e., variable values set executingresponsible operator. detail, let x X. domain transition graph DT Gx xlabeled directed graph vertex set Dx following arcs.x Xpreo Xeff c := preo (x) c0 := eff (x), DT Gx contains arc (c, c0 ) labeledresponsible operator rop(c, c0 ) := o, conditions cond(c, c0 ) := preo \ {(x, c)},side effects seff(c, c0 ) := eff \ {(x, c0 )}. x Xeff \ Xpreoc0 := eff (x), every c Dx c 6= c0 , DT Gx contains arc (c, c0 ) labeledrop(c, c0 ) := o, cond(c, c0 ) := preo , seff(c, c0 ) := eff \ {(x, c0 )}.reader familiar causal graphs may wondered introduced notionside effects, seeing causal graphs acyclic operators unary (affectsingle variable). reason handle cases operators nonunary. variant causal graphs use still acyclic cases, indeedhappens benchmark domains, specifically Simple-TSP, Movie, MiconicSTRIPS, Satellite. define support graph SG directed graph vertexset X, arc (x, y) iff DT Gy relevant transition (c, c0 )x Xcond(c,c0 ) .00Here, transition (c, c ) variable x called relevant iff (x, c ) sG oO preo .definition modifies commonly used one uses relevant transitionsonly, introduce arcs variables co-occurring operatoreffect (unless variables occur also precondition). Transitions side effectshandled separately analysis. Note irrelevant transitions occur naturally,domains non-unary operators. example, unstacking block induces irrelevanttransition making arm non-empty, departing passenger Miconic-STRIPS makespassenger not-boarded.4Consider definition h+ . common Boolean-variable settingPDDL, defined length shortest plan solving problem ignoring4. remark relevant transitions correspond called requestable valuesworks, (e.g., Jonsson & Backstrom, 1998; Haslum, 2007). Fast Downwards implementation,causal graph includes precondition-effect arcs, similarly support graph defined here.158fiAnalyzing Search Topology Without Running Searchdelete lists, i.e., negative operator effects (Bylander, 1994; McDermott, 1999; Bonet& Geffner, 2001). raises question h+ actually is, finite-domain variableplanning, delete lists. question easily answered. Ignoringdeletes essentially means act true remain true forever.finite-domain variable setting, simply means over-write valuesvariables previously. knowledge, generalization first describedHelmert (2006). Consider directed graph + whose vertices sets s+ variable++value pairs X, arc (s+1 , s2 ) iff exists preo s1+++s2 = s1 eff . state, relaxed plan path leadings+ sG s+ . h+ (s) denote length shortest relaxed plan s,h+ (s) = plan exists. easy see definition correspondscommon Boolean one: translate finite-domain variables Boolean onescreating one Boolean variable is-(x, c)-true? every fact (x, c), standard h+Boolean task identical h+ finite-domain variable task.Bylander (1994) proved intractable compute h+ . Many state-of-the-artplanners approximate h+ , variety ways (e.g., McDermott, 1999; Bonet & Geffner,2001; Hoffmann & Nebel, 2001a; Gerevini et al., 2003; Helmert, 2006; Richter, Helmert,& Westphal, 2008; Richter & Westphal, 2010). popular approximation satisficingplanning gives guarantees quality relaxed plan returnedso-called relaxed plan heuristic first proposed FF system (Hoffmann & Nebel, 2001a),approximates h+ terms length necessarily shortest relaxed plan.relaxed plans computed low-order polynomial time using techniques inspiredGraphplan (Blum & Furst, 1997).next introduce relevant notations pertaining search space topology h+ .Let state 0 < h+ (s) < . exit state s0 reachableS, h+ (s0 ) = h+ (s) exists neighbor s00 s0 h+ (s00 ) < h+ (s0 )(and thus h+ (s00 ) < h+ (s)). exit distance ed(s) length shortest pathexit, ed(s) = exit exists. path called monotone iff existtwo consecutive states s1 s2 h+ (s1 ) < h+ (s2 ). say localminimum exists monotone path exit.topology definitions, adapted authors previous work (Hoffmann, 2005),specific h+ sake simplicity (we herein consider heuristicsh+ ).5 States infinite heuristic value ignored correctlyidentified, heuristic, dead ends (relaxed-plan based approximations likeFF identify cases). heuristic value 0 already reachedgoal, case also safely ignored. Note force exit pathsmonotone, i.e., also talk exit distances situations maylocal minimum. necessary capture structure domains like SatelliteZenotravel, local minima exist exit distance bounded. Also,analysis methods guarantee upper bound length exit path only,heuristic values path decrease monotonically.5. remark original definitions significantly involved, e.g., defining local minimabased individual states based strongly connected sub-graphs state space. Nonecomplications relevant results herein.159fiHoffmannFinally, let us say words domain analysis. Generally speaking, domain analysisaims automatically obtaining non-trivial information domain planning task.analysis long tradition planning (e.g., Nebel, Dimopoulos, & Koehler, 1997;Fox & Long, 1998; Gerevini & Schubert, 1998; Edelkamp & Helmert, 1999; Rintanen,2000). often, information sought pertains reachability relevance properties,i.e., entities combinations thereof reachable initial state/relevantgoal. notable exception work Long Fox (2000) automaticallyrecognizes certain generic types domains, like transportation. However, existsprior work trying automatically infer topological properties heuristic function.single exception aforementioned disappointing results reported (as aside)authors previous work (Hoffmann, 2005). method builds structure calledfact generation tree, enumerating ways facts may supportnon-redundant relaxed plan. conflict h+ exact solution distance.Clearly, far strong property applicable reasonably complex domain.considered benchmarks, property applies Simple-TSP. slightlygeneral property, also identified work, applies Movie well trivial Logisticstasks 2 locations, 1 truck, 1 package.worth noting analyzing topology h+ computationally hard:Theorem 1. PSPACE-complete decide whether state space givenplanning task contains local minimum, given integer K PSPACE-completedecide whether states ed(s) K. Further, PSPACE-completedecide whether given state local minimum, given integer KPSPACE-complete decide whether ed(s) K.results hardly surprising, stated anywhere yet. membership results Theorem 1 easy prove based guess-and-check arguments similargiven Bylander (1994), exploiting fact NPSPACE=PSPACE. hardness results still hold restricting input solvable tasks/states. proofs workreducing plan existence, respectively bounded plan existence (with bound non-unaryrepresentation). Given task whose plan existence wish decide, flatten h+new operator always achieve goal fatal side effect. giveplanner choice solving task, solving new alternative task. latter task designed local minimum exists/that exit distance exceeds boundiff planner must choose alternative task, i.e., iff original task unsolvable/iffcannot solved within given number steps. full proof Appendix A.1.practice, computational hardness particularly challenging because,applications domain analysis, willing run worst-case exponential search.all, analysis actually solve problem. Consequently, presentresearch, restrict analysis methods low-order polynomial runtime.reader noticed state-specific analysis problems Theorem 1.distinguish global analysis per-task, local analysis per-state. precisely,herein devise three kinds analyses:(I) Guaranteed global analysis. Taking input planning task description,analysis returns yes, state space contain local minimaexit distance state bounded d.160fiAnalyzing Search Topology Without Running Search(II) Guaranteed local analysis. Taking input planning task descriptionstate s, analysis returns yes, local minimum, exitdistance bounded d.(III) Approximate local analysis. Taking input planning task descriptionstate s, analysis returns yes, indicate local minimum,exit distance bounded d. may wrong, i.e., analysisguaranteed sound. Compared analysis (II), trades soundnessability successfully analyze states.Domain analysis traditionally considers global variant (I), even generalizingvariants looking PDDL domain file. global once-and-for-all analysisalso holy grail work, local analysis strong advantages. planning taskcontain local minima one would expect typically case interestingdomains analysis (I) useless. simply answer no. contrast, local analysis(II,III) may still detect individual states, sample randomly experiments,local minima. percentage states, refer success rate,deliver useful information matter structure planning task is. Notealso that, contrast PSPACE-hard problem low-order polynomialanalysis runtime necessarily implies analyses incomplete, local analyseschance ameliorate averaging outcome set sample states.3. Illustrative Examplebasic connection identify causal graphs h+ topology precisely,support graphs, domain transition graphs, h+ topology quite simple.instructive understand first, delving full results. Figure 2 showsfragments domain transition graphs (DTGs) three variables x0 , x1 , x2 .DTG transitions assumed invertible, side effects.t0x0g0T2T1x1L1L2L3s1 R1R2R3x2c1c2s2Figure 2: example illustrating basic result.imaginative reader invited think x0 car whose battery currentlyempty therefore requires help two people, x1 x2 , order push-startit. people may, solve different parts task, required purposes too,consider sub-problem achieving goal x0 = g0 . wish take161fiHoffmannx0 transition t0 , two conditions c1 c2 . conditions currentlyfulfilled. state hand, x1 s1 x2 s2 . must move differentstate, s0 , x1 = c1 x2 = c2 . happen h+ along way?Say optimal relaxed plan P + (s) moves x1 c1 along path marked T1 ,moves x2 c2 along path marked T2 clearly, paths takenP + (s). Key observation (1) similar phenomenon known transportationbenchmarks. moving x1 x2 , whichever state s0 in, long s0 remainswithin boundaries values traversed T1 T2 , construct relaxed planP + (s0 ) s0 |P + (s0 )| |P + (s)|. Namely, obtain P + (s0 ), simply replacerespective move sequenceP + (s), = 1, 2, inverse. example, say0got 1 = hR1, R2, R3i moving x1 c1 , indicated Figure 2. wlogP + (s) form hR1, R2, R3i P . define P + (s0 ) := hL3, L2, L1i P . postfix Prelaxed plans same; end prefix, set values achieved x1 ,namely s1 , c1 , two values between, also same. Thus P + (s0 ) relaxedplan s0 .6 true general, i.e.,1 necessarily applicable s0 , achieve,+0within relaxed execution P (s ), set facts achieved1 P + (s). Thush+ (s0 ) h+ (s) state s0 , including state s0 after.Key observation (2) pertains leaf variable, x0 . Say x0 movessake, i.e., car position important goal. executing t0s0 delete anything needed anywhere else. Thus remove rop(t0 )relaxed plan P + (s0 ) s0 constructed per observation (1) obtain relaxed planstate s1 results executing t0 s0 . Hence h+ (s1 ) < h+ (s). observation(1), heuristic values along path s1 h+ (s). know least onestate s00 path heuristic value strictly smaller h+ (s): happenslatest s00 = s1 , may happen earlier case relaxed plan P + (s00 ) constructedoptimal (cf. Footnote 6). Let s00 earliest state h+ (s00 ) < h+ (s)path, let s0 state preceding s00 . s0 exit s, pathexit monotone. Thus local minimum. exit distance, worstcase s00 = s1 s0 = s0 , ed(s) bounded length path s0 .difficult imagine works also preconditions needestablished recursively, long cyclic dependencies exist. third person mayneeded first persuade x1 x2 , third person may need take bus, on.length path s0 may grow exponentially x1 depends x3move x1 may require several moves x3 , forth still ableconstruct P + (s0 ) inverting moves variables individually. Further, invertingtransitions may conditions, too, provided conditions requiredoriginal moves. example, above, inverting operator L1 mayarbitrary condition p condition also required R1 . conditionsrequired original moves (like p R1 ) established P + (s), thusestablished P + (s0 ) time inverse moves (like L1 ).6. Note P + (s0 ) may optimal relaxed plan s0 . P + (s) move x1 anythingattaining c1 , postfix P alone relaxed plan s0 : need insertinverted prefix hL3, L2, L1i. cases like this, obtain exit state already path s0 ; getback below.162fiAnalyzing Search Topology Without Running SearchNow, say support graph acyclic, transitions invertibleside effects. Given state s, unless already goal state, variable x0moving sake necessarily exists. then, within optimal relaxed plans, situation exists, therefore monotone exit path, Q.E.D.local minima h+ .execution path construction discussed different known resultsexploiting causal graph acyclicity notions connectedness invertibility domaintransition graphs (e.g., Jonsson & Backstrom, 1995; Williams & Nayak, 1997).new connection h+ .remark hand-made analysis h+ (Hoffmann, 2005) uses notion operators respected relaxation. operator respected relaxation iff,whenever starts optimal plan s, also starts optimal relaxed plan s.core property many hand-made proofs operators respectedrelaxation. motivated speculation recognizing property automaticallycould key domain analysis recognizing absence local minima h+ .explore option herein, however note even basic result outlinedcontains cases covered property. Even acyclic support graph invertibletransitions without side effects, examples operator respectedrelaxation. give construction Example 1, Appendix A.4.4. Synopsis Technical Resultstechnical results follows structured way similar proof argumentoutlined previous section. results structured two parts, (A) (B).(A), Section 5, identify circumstances deduce optimalrelaxed plan monotone exit path exists. (B), Section 6, devise support-graphbased sufficient criteria implying analysis (A) always succeed. Technique (B)underlies TorchLights conservative analysis methods, i.e., guaranteed global analysis (I)guaranteed local analysis (II) described end Section 2. feeding technique(A) usual relaxed plans computed, e.g., FFs heuristic function, obtainTorchLights approximate local analysis (III). analysis give guarantee,(and because) FFs relaxed plans guaranteed optimal.ease reading, give brief synopsis results obtained (A)(B), provide analysis methods (I)(III). synopsis contains sufficientinformation understand rest paper, reader may choose skip Sections 56, moving directly evaluation.analysis method based particular kind sub-graph support graph.Table 1 overviews these. role parts (A) (B) follows:(A) Given optimal relaxed plan P + (s) state s, optimal rplan dependency graphoDG+ sub-graph SG single leaf variable x0 transition t0example (rop(t0 ) frequently referred o0 ). arc (x, x0 ) oDG+P + (s) relies x0 achieve conditions t0 , P + (s) relies x moving x0 .say oDG+ successful acyclic, involved transitions usableexit path construction (e.g., harmful side effects), deletes t0163fiHoffmannNameSupport graphSymbolSGAnalysisApproximatelocal analysis (III)Theorem 2Optimal rplandependency graphoDG+Localdependency graphlDGGuaranteedlocal analysis (II)Theorem 3Globaldependency graphgDGGuaranteedglobal analysis (I)Theorem 4LeavesSingle leaf x0 s.t. applyingt0 affectremainder P + (s)Single leaf x0 XsG ,s(x0 ) 6= sG (x0 ) x0transitive SG successorpropertySingle leaf x0 XsGArcs(x, x0 ) x usedP + (s) support x0obtaining cond(t0 )(x, x0 )s(x) 6= cond(t0 )(x);(x, x0 ) x0 lDG(x, x0 ) SG(x, x0 ) x 6= x0 ;(x, x0 ) x0 gDG(x, x0 ) SGTable 1: Overview different support graph sub-graphs underlying results.either relevant P + (s) all, recovered inside P + (s). mainresult, Theorem 2, states local minimum exists successful oDG+s. also derives exit distance bound oDG+ . Approximating Theorem 2applying relaxed plan computed FFs heuristic yields analysis (III).(B) Given state s, local dependency graph lDG sub-graph SG single leafvariable x0 , whose goal value yet unachieved, whose transitive successorsSG already attained goal values. setting, x0 movessake example. graph lDG simply includes SG predecessors x0 ,single exception pertaining arcs (x, x0 ) x0 itself, insertedcorresponding condition t0 already satisfied s. say lDG successfulacyclic, involved transitions usable exit path construction, t0relevant deletes. implies exists successful oDG+contained lDG, thus Theorem 3, stating local minimumgiving corresponding exit distance bound. result underlies analysis (II).global dependency graph gDG sub-graph SG identifies goal variablex0 , includes SG predecessors x0 . successful definedway lDGs. gDGs successful, Theorem 3 apply every statelDG contained successful gDG. Thus Theorem 4, statingstate space contain local minima. exit distance boundobtained maximizing gDGs. result underlies analysis (I).understanding practical performance TorchLight, important note(A) minimal result would suffice prove (B). cases identifiedTheorem 2 much richer actually infer support graphs.reason, analysis (III), sound due use potentially non-optimal relaxedplans, able analyze much larger class states analysis (II). little detail,difference two methods pertains (1) whether P + (s) relies valuesx moving x0 , (2) whether deletes t0 recovered inside P + (s).Neither (1) (2) visible support graph, rely detailsform relaxed plan P + (s). example, consider Gripper domain. Notion (1)important support graph contains arcs (carry-ball-b, free-gripper)due dropping ball b (free-gripper, carry-ball-b) due picking ball b.Thus, looking SG, seems carry-ball-b may support (free gripper164fiAnalyzing Search Topology Without Running Searchdropping ball want pick up). course, doesnt happen optimalrelaxed plan. Notion (2) important operators (picking ball)harmful side effects (making gripper hand non-empty), side effects alwaysrecovered inside relaxed plan (when dropping ball later on). remains futurework extend analyses (I,II) detect kinds phenomenona.5. Analyzing Optimal Relaxed Plansconsider state optimal relaxed plan P + (s) s. describe circumstancesmonotone exit path guaranteed exist, need number notationspertaining properties transitions etc. introduce notations along way,rather front, hope makes easier digest.++Given o0 P + (s), P<0(s) P>0(s) denote parts P + (s) front o0+behind o0 , respectively. P (s, x) denote sub-sequence P + (s) affectingx. capture dependencies variables used P + (s) achievingprecondition o0 , follows:Definition 1. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , letP + (s) optimal relaxed plan s, let x0 X, let o0 P + (s) operatortaking relevant transition form t0 = (s(x0 ), c).optimal rplan dependency graph P + (s), x0 o0 , optimal rplan dependencygraph P + (s) brief, graph oDG+ = (V, A) unique leaf vertex x0 ,x V (x, x0 ) either: x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x 6= x00+(s) taking relevant transition x0 x XpreoV \ {x0 } exists P<0preo (x) 6= s(x).x V \ {x0 }, oDT G+x denote sub-graph DT Gx includes+(s, x), relevant transitions using operatorvalues true point P<0+P<0 (s, x), least one relevant inverse relevant inverse exists.+(s, x) transitions original, inverse transitions induced.refer P<0transition t0 responsible operator o0 candidate reachingexit state, like t0 Figure 2. oDG+ collects variables x connected variable x0+insofar P<0(s) uses operator preconditioned x order move x0 .variables need move, like x1 x2 Figure 2, obtain state s0 t0taken. variable x, oDT G+x captures domain transition graph fragment+P<0(s) traverses within stay, like T1 T2 Figure 2.+Note need consider operators P>0(s) behind o0 , simplyoperators used order establish o0 precondition. paramountimportance practice. example Gripper situation mentioned above. o0 picks+ball b Gripper, P + (s) also contain behind o0 , i.e., P>0(s)00+operator dropping b. considered Definition 1, oDG would containmentioned cycle assuming o0 used making gripper hand free picking b.TorchLights approximate local analysis, whenever consider operator o0 ,build oDG+ re-order P + (s) moving operators behind o0 possible. minimizes+P<0(s), oDG+ thus indeed contains necessary variables arcs.165fiHoffmanncircumstances t0 actually job? sufficient criterionidentify rather complex. provide overview criterion, next state definition. items definition explained below.Definition 2. Let (X, sI , sG , O), s, P + (s), x0 , o0 , t0 , oDG+ = (V, A) Definition 1. say oDG+ successful following holds:(1) oDG+ acyclic.(2) either:+(a) oDG+ -relevant deletes t0 P>0(s)-recoverable;+(b) s(x0 ) oDG -relevant, t0 replaceable side effect deletes;(c) s(x0 ) oDG+ -relevant, t0 recoverable side effect deletes.(3) x V \ {x0 }, oDT G+x transitions either self-irrelevant deletes,invertible/induced irrelevant side effect deletes side effects V \{x0 }.already outlined, exit path construction works staying within rangesoDT G+x , x V \ {x0 }, reached state s0 transition t0taken. make little precise, consider topological order xk , . . . , x1 V \ {x0 }respect oDG+ order exists due Definition 2 condition (1). (Ifcycles, moving variable may involve moving first place,covered exit path construction.) consider, 0 k, d-abstractedtask. like original task except that, every transition one graphsoDT G+xi d, remove condition (xj , c) cond(t) j > d. exitpath construction understood induction d, proving existenceexecution pathwhose end t0 taken. constructexclusively,xV\{x}.base case,operators responsible transitions oDT G+0x0-abstracted task, t0 directly applicable. inductive case, constructedsuitable pathd-abstracted task, suitable pathd+1 + 1abstracted task constructed follows. Assume operator,precondition (xd+1 , c) true current state. Then, d+1 ,front simply insert path oDT G+xd+1 ends c. Note that,construction, (xd+1 , c) condition transition oDT G+xi , < + 1.++taken P<0(s, x), (xd+1 , c) must achieved P<0(s) thus c node+oDT G+xd+1 . induced transition inverting transition taken P<0 (s, x)case unless inverse may introduce new outside conditions. thus needexclude case, leading following definition invertibility:Let = (c, c0 ) transition variable x. say invertible iff existstransition (c0 , c) DT Gx cond(c0 , c) cond(c, c0 ).transition invertible go back without introducing new conditions (e.g.,driving trucks Logistics). subtle differences previous definitions invertibleoperators, like authors (Hoffmann, 2005). allow new conditions evenactually established operator rop(t) responsible t. because,,necessarily execute executing inverse may got endpointvia different path oDT G+x . hand, definition also generous166fiAnalyzing Search Topology Without Running Searchcommon ones because, per se, care side effects inversetransition may (side effects constrained separately stated Definition 2).Consider Definition 2 condition (3). Apart constraints conditions inducedtransitions, oDT G+x transitions taken , must also make sureharmful side effects. Obviously, case if, example Section 3,transitions side effects all. However, easily generalize condition. Let= (c, c0 ) transition variable x.context set ctx(t) facts may deleted side effects t.(y, d) seff(t), (y, cond(t)(y)) ctx(t) condition defined; elseDy values 6= inserted.say irrelevant side effect deletes iff ctx(t) (sG oO preo ) = .say self-irrelevant side effect deletes iff ctx(t) (sG rop(t)6=oO preo ) =.say tShas self-irrelevant deletes iff self-irrelevant side effect deletes(x, c) 6 sG rop(t)6=oO preo .Irrelevant side effect deletes capture case side effect delete occurs goalprecondition operator. Self-irrelevant side effect deletes slightlygenerous allow delete conditions needed responsible operatorrop(t) itself. Self-irrelevant deletes, finally, extend latter notion also ts delete.nutshell, need postulate irrelevant side effect deletes transitions mayexecuted again, path. Examples irrelevant side effect deletes transitionsside effects all, move Simple-TSP, whose side effect, x0 =at,deletes target locations not-visited. example operator selfirrelevant side effect deletes, irrelevant side effect deletes, departing passengerMiconic-STRIPS, whose side effect, x0 =served, deletes boarded(passenger)used purpose departure. fact, transition selfirrelevant deletes effect deletes not-served(passenger) obviouslyirrelevant. Another example self-irrelevant deletes inflating spare wheel Tyreworldwheel longer not-inflated.Clearly, oDT G+x transitions may using irrelevant side effectdeletes, then, far invalidating facts needed elsewhere concerned,good side effects all. understand need require tsside effect used move another variable x0 V \ {x0 }, recall that, states s0visited, construct relaxed plans P + (s0 ) |P + (s0 )| |P + (s)| invertingtransitions t. Now, say ts side effect used move another variable x0 V \ {x0 }.may invert transitions separately (with different operators), thuswould |P + (s0 )| > |P + (s)|.Regarding delete t, may important two reasons. First, deletedfact may needed relaxed plan s0 . Second, x may traverse oDT G+x severaltimes, thus may need traverse deleted value later on. coveredinvertible, like earlier assumed transitions. Now, invertible?constitute problem case self-irrelevant deletes: case,167fiHoffmanndeletes irrelevant except maybe responsible operator itself. Therefore,obtain P + (s0 ), simply remove rop(t) relaxed plan constructedpredecessor state s00 . Thus |P + (s0 )| < |P + (s)| reached exitneed continue construction. example, consider inflates spare wheelW Tyreworld. deletes not-inflated(W), thus self-irrelevant deletes(not-inflated(W) irrelevant goal operator). Saystate s00 relaxed plan P + (s00 ) constructed described. |P + (s00 )| |P + (s)|.also rop(t) =inflate-W P + (s00 ), inflate-W P + (s),inflate-W executed yet path, hence removedrelaxed plan. Applying inflate-W s00 , get state s0 identical s00 except Winflated. Clearly, relaxed plan s0 longer needs apply inflate-W,rest relaxed plan P + (s00 ) still works unchanged. Thus P + (s0 ) obtainedremoving inflate-W P + (s00 ), yielding |P + (s0 )| < |P + (s)| desired.Consider endpoint transition t0 responsible operator o0 . previouslydemanded x0 moves sake, i.e., x0 goal valueimportant achieving goal. unnecessarily restrictive. example,Miconic-STRIPS, board passenger h+ decreases removeboarding operator relaxed plan. However, boarding means servingpassenger later on, variable x0 goal. Driverlog, driver maygoal needed drive vehicles, still t0 moving driver resultsdecreased h+ location moved away actually needed anymore. latterexample immediately leads definition capturing also first one: wantdeletes t0 needed rest relaxed plan. remove o0relaxed plan s0 , reached exit desired.make precise, recall situation addressing. reached state s0t0 = (s(x0 ), c) applied, yielding state s1 . relaxed plan P + (s0 )s0 |P + (s0 )| |P + (s)|, P + (s0 ) constructed P + (s) replacing+(s) operators responsible induced oDT G+operators P<0x transitionsx V \ {x0 }. construct P1+ removing o0 P + (s0 ), need P1+relaxed plan s1 . facts possibly needed P1+ ? safe approximationunion sG , precondition o0 6= P + (s), oDT G+x values needed7 Denote set R+ . values potentially deletedinduced oDT G+transitions.x1t0 contained C0 := {(x0 , s(x0 ))} ctx(t0 ). Thus R1+ C0 =fine. Simple examples given already. Miconic-STRIPS,delete o0 boarding passenger P not-boarded(P), containedoperator precondition goal thus intersection R1+ C0 = {notboarded(P)} empty. Driverlog, C0 = {at(D,A)} delete o0 moving driveraway location A. location irrelevant rest task,at(D,A)6 R1+ thus, again, R1+ C0 = .sharpen further. Consider set facts F0 := oP + (s) eff<0+true relaxed execution P<0(s). Say p 6 F0 . p needed7. understand latter two items, note first operators preceding o0 P + (s), i.e., operators+P<0(s), may still contained P1+ thus suffice include preconditions++operators P>0(s). oDT G+x values needed induced oDT Gx transitions, may needed++P1 P<0(s).168fiAnalyzing Search Topology Without Running SearchP1+ relaxed plan s1 . see this, note first p needed part++P1+ pertaining P<0(s). precisely, p cannot operator precondition P<0(s)+condition would satisfied (relaxed) execution P (s). Also, pcannot start value induced oDT G+x transition because, definition,+values added operators P<0 (s). Now, part P1+ pertaining++P>0(s)? Assume p either goal, operator precondition P>0(s). Then,++since p 6 F0 P (s) relaxed plan, either o0 operator P>0 (s) must establish+p. o0 , effects true s1 anyway. P>0(s), remains unchanged+P1 thus part covered, too. Altogether, thus suffices R1+ C0 F0 = .example helps Satellite domain. Say o0 switches instrument I.deletes calibration, i.e., calibrated(I) C0 . purpose switchingtake images it, thus calibrated(I) R1+ C0 . However, instrumentmay actually calibrated s. so, need switchcalibrated calibration operator requires powerthus calibrated(I) false relaxed execution P + (s), least o0 .particular, calibrated(I)6 F0 thus R1+ C0 F0 = .Even condition R1+ C0 F0 = still sharpened. Say exists+(s)o0 guaranteed applicable(possibly empty) sub-sequenceo0 P>0+start P1 , o0 re-achieves facts R1+ C0 F0 (both easydefine test). movingo0 start P1+ job. say case++(s)-recoverable Definition 2 condition (2a).oDG -relevant deletes t0 P>0example, consider o0 picks ball b Gripper domain. operator deletesfact p =free-gripper may needed remainder relaxed plan, thus+(s) necessarily contain sub-sequenceo0 movesp R1+ C0 F0 . However, P>0+another room puts b again. re-order P1 put o0 rightstart, re-achieving p. Similar patterns occur transportation domain capacityconstraints, generally domains renewable resources.Finally, identified two simple alternative sufficient conditions t0suitable, Definition 2 conditions (2b) (2c). sake brevity, sketchhere. require s(x0 ), i.e., start value t0 , contained R1+defined above. say case s(x0 ) oDG+ -relevant. Note that, then,R1+ C0 = unless t0 side effects. Side effects hurt t0 replaceable sideeffect deletes, i.e., operator whose precondition may deleted replacedalternative operator o0 applicable effect (this happens, e.g.,Simple-TSP). Another possibility t0 recoverable side effect deletes:exists operator o0 necessarily applicable directly execution t0 ,recovers relevant side effect deletes. happens quite frequently, example Roverstaking rock/soil sample fills store, free store simplyemptying anywhere. replace o0 o0 obtain relaxed plan P1+ s1 (andthus h+ (s1 ) h+ (s)). apply o0 , yielding state s2 h+ (s2 ) < h+ (s)obtain relaxed plan s2 removing o0 P1+ .length exit path be? one move x0 . nonleaf variable x must provide new value every move variable x0depending it, i.e., (x, x0 ) A. new value reached oDT G+xtraversal. Denote maximum length traversal, i.e., diameter oDT G+x,169fiHoffmann8 Now, may diam(oDT G+ ) > diam(DT G ) oDT G+diam(oDT G+xx ).xxremoves vertices also arcs. may short-cuts traversed P + (s).certain circumstances safe take short-cuts, namely if:(*) oDT G+x transitions invertible/induced irrelevant side effect deletesside effects V \ {x0 }, DT Gx transitions either irrelevant,empty conditions irrelevant side effect deletes.traversing short-cut condition, soon reach end shortcut, back region states s0 relaxed plan P + (s0 ) constructedbefore. rest exit path construction remains unaffected. Thus,denote VPsubset V \ {x0 } (*) holds. define costd (oDG+ ) := xV costd (x),costd (x) :=1P0diam(oDT G+x)x0 :(x,x0 )A cost (x )min(diam(oDT G+ ), diam(DT G )) Pxxx = x0x 6= x0 , x 6 Vx0 :(x,x0 )A cost(x0 )x 6= x0 , x VNote costd (.) exponential depth graph. artifactlength estimation. easy construct examples exit distance exponentialparameter. because, hinted, variable may move several timesvalue required variables depending it. See Example 6 Appendix A.4construction (following earlier construction Domshlak & Dinitz, 2001).said, course costd (.) may over-estimate length shortest exit path.assumes that, whenever variable x0 (x, x0 ) makes move, x must moveentire oDT G+ respectively DT G. conservative: (1) maymove x0 actually condition x; (2) even condition exists,x may need less steps order reach it. One might able ameliorate (1) makingfine-grained distinctions part costd (x0 ) pertains moves conditionedx. leave open future work. now, note over-estimationexponential even due (2), i.e., costd (oDG+ ) may exponentially largerlength shortest exit path even if, (x, x0 ) A, moves x0 depend x.shown simple variant Example 6; discuss Appendix A.4.Exit paths using short-cuts described way may non-monotone. Example 5Appendix A.4 contains construction showing this. intuitive understanding,imagine line l0 , . . . , ln current task, achieve precondition anotheroperator, move l0 ln . Say locations line need visited,relaxed plan, e.g. need load unload something locations.Say shortcut via l0 needs visited. move l0 h+increases made 1 step costly relaxed plan reachlocations l0 , . . . , ln . reason, costd (oDG+ ) upper bound lengthshortest monotone exit path. also shown Example 5, construct8. precisely, diam(.) diameter graph maximum distance vertex v vertexv 0 exists path v v 0 .170fiAnalyzing Search Topology Without Running Searchsituation shortest monotone exit path longer costd (oDG+ ).9 obtainbound monotone exit paths, simply set V := definition costd .Definition 2 condition (2a) (2b), exit distance boundedcostd (oDG+ ) 1 costd (oDG+ ) counts last step reducing h+ .Definition 2 condition (2c), last step need 1 additional operator reduceh+ , exit distance bounded costd (oDG+ ). Putting pieces together yieldsmain result section:Theorem 2. Let (X, sI , sG , O), s, P + (s), oDG+ Definition 1. oDG+ successful, local minimum, ed(s) costd (oDG+ ). Definition 2condition (2a) (2b), ed(s) costd (oDG+ ) 1.full proof Appendix A.2. pointed earlier, approximate local analysis(III) simply feed Theorem 2 relaxed plans returned FFs heuristic function(Hoffmann & Nebel, 2001a). important note that, way, giveguarantees, i.e., Theorem 2 hold P + (s) optimal, even P + (s)non-redundant parallel-optimal like computed FF. end exitpath may obtain relaxed plan shorter P + (s) shorter h+ (s).nutshell, reason parallel-optimal relaxed plan generally, relaxedplan minimizing number operators may take different decisionssequentially-optimal relaxed plan, thus constructing exit path leading wrongdirection. Example 8 Appendix A.4 gives full construction proving this.Feeding Theorem 2 non-optimal relaxed plans course also imprecisedirection, i.e., Theorem 2 may apply although apply optimalrelaxed plan. Thus good cases may go unrecognized. demonstrate simplemodification Example 8, explained example Appendix A.4. Importantly,point Section 8, empirical results suggest weaknesstend occur practice, least far represented benchmarks.6. Conservative Approximationsidentify sufficient criteria guaranteeing prerequisites Theorem 2 holdtrue. consider local case particular state given, globalcase criterion implies prerequisites Theorem 2 every state taskhand. approximate optimal rplan dependency graphs follows:Definition 3. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , letx0 XsG , let t0 = (s(x0 ), c) relevant transition DT Gx0 o0 := rop(t0 ).local dependency graph s, x0 , o0 , local dependency graph brief,graph lDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x0 V \ {x0 } (x, x0 ) arc SG.0global dependency graph x0 o0 , global dependency graph brief,graph gDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:x0 = x0 x0 6= x Xpreo ; x0 V \ {x0 } (x, x0 ) arc SG09. remark that, due mentioned sources over-estimation costd , constructing examplerequires fairly awkward constructs appear likely occur practice.171fiHoffmannoptimal relaxed plan P + (s) contains o0 , oDG+ per Definition 1sub-graph lDG gDG defined here. simply optimal rplandependency graph arcs (x, x0 ) contained support graph task.10previously indicated, support graph may contain lot arcs actually necessary.SG captures may ever support else, support else optimalrelaxed plan. Consider earlier point that, constructing oDG+ , take accountoperators front o0 P + (s). information contained SG, thusGripper get aforementioned cycle dropping ball support free-gripperpicking ball.reader waded cumbersome details previous sectiondelighted hear defining lDG respectively gDG successfulinvolve additional notation:Definition 4. Let (X, sI , sG , O), s, x0 , t0 , o0 , G = lDG G = gDGDefinition 3. say G = (V, A) successful following hold:(1) G acyclic.(2) G = lDG sG (x0 ) 6= s(x0 ), exists transitive successor x0 x0SG x0 XsG sG (x0 ) 6= s(x0 ).(3) t0 either:(a) self-irrelevant side effect deletes;(b) replaceable side effect deletes;(c) recoverable side effect deletes.(4) x V \ {x0 }, DT Gx transitions either irrelevant, self-irrelevantdeletes, invertible irrelevant side effect deletes side effectsV \ {x0 }.Consider first local dependency graphs G = lDG; discuss G = gDG below.Assume optimal relaxed plan P + (s) contains o0 , thus oDG+sub-graph lDG. condition (1) obviously implies Definition 2 condition (1).Condition (4) implies Definition 2 condition (3) oDT G+x containirrelevant transitions. Condition (2) implies (*) s(x0 ) oDG+ -relevant, i.e., s(x0 )needed rest relaxed plan. simply un-achievedgoal depends x0 . (*), condition (3a) implies Definition 2 condition (2a),R1+ C0 = , notation introduced previously. Conditions (3b) Definition 2condition (2b), respectively (3c) Definition 2 condition (2c), equivalent given (*).Regarding exit distance, know parts domain transition graphsvariables x V \ {x0 } traversed P + (s). obvious bound diam(oDT G+x)length maxPath(DT Gx ) longest non-redundant path graph (a pathvisiting vertex once). Unfortunately, cannot compute maxPath(.) efficiently. Hamiltonian path (Garey & Johnson, 1979) exists graph G = (V, A) iff10. gDG, note preo0 (x0 ), defined, = s(x0 ) thus x0 need recordedpredecessor.172fiAnalyzing Search Topology Without Running SearchmaxPath(G) = |V | 1. Thus corresponding decision problem NP-hard. TorchLight over-approximates maxPath(G) simply |V | 1. However, sometimes usediam(DT Gx ) instead maxPath(DT Gx ), namely certain x onevariables V used definition costd (oDG+ ). certain if:(**) DT Gx transitions either irrelevant, invertible emptyconditions, irrelevant side effect deletes, side effects V \ {x0 }.Note strictly stronger requirement Definition 4 condition (4). Clearly,implies Definition 2 condition (3) well condition (*) SectionP5. Denote Vsubset V \ {x0 } (**) holds. define costD (G) := xV costD (x),costD (x) :=1x = x0P0maxPath(DT Gx ) x0 :(x,x0 )A cost (x ) x 6= x0 , x 6 Vdiam(DT G ) PcostD (x0 )x 6= x , x Vx0x0 :(x,x0 )Ax0 must move attain goal every optimal relaxed plan must takeleast one transition leaving s(x0 ). Thus, Theorem 2 above, that:Theorem 3. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) <. Say x0 X that, every o0 = rop(s(x0 ), c) DT Gx0 (s(x0 ), c)relevant, lDGo0 successful local dependency graph. local minimum,ed(s) maxo0 costD (lDGo0 ). If, every lDGo0 , Definition 4 condition (3a)(3b), ed(s) maxo0 costD (lDGo0 ) 1.Theorem 3 tool guaranteed local analysis (II). guaranteed global analysis(I), simply look set global dependency graphs gDG, requiringsuccessful. particular, gDG acyclic, difficult deducenon-goal state variable x0 fulfilling Definition 4 (2). x0 ,apply Theorem 3 thus get:Theorem 4. Let (X, sI , sG , O) planning task. Say global dependency graphsgDG successful. contain local minima and, state0 < h+ (s) < , ed(s) maxgDG costD (gDG). If, every gDG, Definition 4condition (3a) (3b), ed(s) maxgDG costD (gDG) 1.full proofs Theorems 3 4 Appendix A.3. SG acyclictransitions invertible side effects, Theorem 4 applies, wherebyparticular proved basic result. Vice versa, note that, Theorem 4 applies,SG acyclic. far local minima concerned, one may thus reformulate Theorem 4simpler terms relying notion successful dependency graphs. Apartallowing also determine exit distance bound, present formulation already pavesway future research: gDG defined relative concrete variable x0 operatoro0 , may thus allow accurate analysis variables may actuallybecome important x0 o0 , optimal relaxed plan.use diam(DT Gx ) instead maxPath(DT Gx ) costD (.), variablesV , rather significant effect quality bounds computed many173fiHoffmannbenchmarks. typical example transportation domain vehicle positions leafvariables SG whose transitions side effects. variables qualify V . UsingmaxPath(DT Gx ) instead, would obtain exceedingly large bounds even trivial roadmaps. example, consider Logistics road map fully connected.diam(DT Gx ) = 1 thus costD (.) delivers correct bound 1. Using maxPath(DT Gx )instead get bound N 1, N total number locations DT Gx .Note that, within scope Theorem 4, i.e., class planning tasksTheorem 4 applies, plan existence tractable. Namely, exists plan task iffexists relaxed plan initial state. because, starting optimalrelaxed plan, guaranteed able construct exit path; iterating argumentgets us goal. view, tractability weakness form globalanalysis. analysis apply intractable classes tasks containlocal minima. Note classes exist, cf. Theorem 1. hand, planexistence tractable known benchmark domains local minima absent,practice appear major limitation. Also, note plan construction,well optimal planning, still intractable within scope Theorem 4. Planconstruction intractable plans may exponentially long, cf. Example 6Appendix A.4. optimal planning, consider Logistics Miconic-STRIPS.see shortly (Proposition 1, next section) fully covered Theorem 4.However, them, deciding bounded plan existence NP-hard (Helmert, 2003).Interestingly, fact Theorem 2, therewith indirectly also Theorem 4, relyoptimal relaxed plans source intractability plan construction here. Theorem 4applies, non-redundant relaxed plan P + successful oDG+ , enabling usconstruct path state particular relaxed plan (although necessarilyoptimal relaxed plan) shortened. Iterating argument gives us constructivemethod obtaining plan, worst-case exponential behavior lieslength individual path segments. said, course plan constructedway may highly non-optimal. Indeed, shown Example 7 Appendix A.4,plan may exponentially longer optimal plan. Thus, even Theorem 4 appliesneed optimality guarantee, running planner still makes sense.discuss relation scope Theorem 4 known tractable classesSection 9. basic fact one construct local minima even small examplesinvolving two variables complying basic result except eithersupport graph cyclic (Example 2, Appendix A.4), non-invertible transitionwhose delete relevant (Example 3, Appendix A.4), transitionrelevant side effect delete (Example 4, Appendix A.4). examples containedmany known tractable classes, thus underlining automatic analysis h+ topologyidentification tractable classes different (although related) enterprises.7. Benchmark Performance Guaranteesstate guarantees analyses (I)(III) give benchmark domains.underlying finite-domain variable formalizations straightforward, correspond174fiAnalyzing Search Topology Without Running Searchformulations found automatically Fast Downward. listedAppendix A.5, also give proofs following two simple observations.11four benchmark domains, guaranteed global analysis (I) always succeed :Proposition 1. Let (X, sI , sG , O) planning task Logistics, Miconic-STRIPS,Movie, Simple-TSP domain. Theorem 4 applies, bound delivered1, 3, 1, 1 respectively.follows trivially Proposition 1 guaranteed local analysis (II) succeedsdomains well. state one four listed domains, Theorem 3applies s, bound delivered stated.Note bounds Logistics Movie correct ones, i.e., tight.Miconic-STRIPS, over-estimation actual bound (which 1, 3) arisesanalysis realize boarding passenger used leafvariable x0 . Simple-TSP, correct bound 0 (since h+ exact goal distance).over-estimation arises because, every goal variable x0 =visited(location), gDGincludes also variable at, realizing value matterlocation visited one.transportation benchmarks involving capacity constraints, approximate localanalysis (III) always succeed, provided suitable optimal relaxed plans:Proposition 2. Let (X, sI , sG , O) planning task Elevators, Ferry, Gripper,Transport domain, let S. Ferry Gripper, every optimal relaxed planP + (s) exists oDG+ Theorem 2 applies, bound 1. ElevatorsTransport, exists least one P + (s) oDG+ Theorem 2 applies,bound 1 Elevators road map diameter Transport.relevant deletes t0 , cases, due effects decreasing remaining vehicle capacity, like free-gripper Gripper domain. decrease capacityalways due load type operator, matched unload type operatorlater inside relaxed plan. Thus deletes always recovered inside P + (s) (weDefinition 2 condition (2a)). Further, relaxed plans never use unload actionfree capacity loading object, thus oDG+ cycle-free. HenceoDG+ successful, Theorem 2 applies. Elevators Transport, Proposition 2slightly weaker vehicle may capacity > 1, allowing forcingrelaxed plans use unloading operators recovering capacity actually present.note similar patterns likely occur domain renewable resources,recognized Definition 2 condition (2a) way.Proposition 2 hold Theorems 3 4, i.e., lDGs gDGs. duetwo deficiencies (cf. discussion end Section 4). First, SG contains cyclesunloading object order free capacity loading it. Second, Definition 2condition (3a) restrictive Definition 2 condition (2a), postulating deletest0 entirely irrelevant. way removing deficiencies,guaranteed analyses (I,II) would succeed four domains Proposition 2.11. say found automatically Fast Downwards translator deterministic, i.e.,may return different finite-domain variable encodings even run several times planningtask. encodings correspond domain formalizations. Elevators,give full definition because, without action costs, merely variant Transport.175fiHoffmann8. Experimentsreport large-scale experiment TorchLight. fill details TorchLights implementation, describe simple alternative analysis technique basedsearch probing. explain experiments set-up, report runtime results differentstages TorchLight, describe TorchLights analysis results per-domain basis.assess quality analysis terms predictive capability. finally summarizeoutcome TorchLights diagnosis facility benchmarks.8.1 TorchLightTorchLight implemented C based FF.12 TorchLight currently handles STRIPS only,i.e., ADL domains. uses Fast Downwards translator (Helmert, 2009) find finitedomain variables. Establishing correspondence variables (respectivelyvalues) FFs internally used ground facts mostly straightforward.details take care of; omit brevity.parsing Fast Downwards variables, TorchLight creates data structures representing support graph domain transition graphs. enters phase referstatic analysis, determines fixed properties as, every transition t,whether irrelevant, invertible, etc. next step guaranteed global analysis (I),checking preconditions Theorem 4 enumerating global dependency graphstesting whether successful. able report percentage successful gDGs,stop first unsuccessful one.local analysis techniques guaranteed local analysis (II) using Theorem 3approximate local analysis (III) using Theorem 2 run set LS states comprisinginitial state well number R sample states obtained random walks startingsI . set LS identical analyses, run technique stateLS regardless outcome running respective technique is.Given s, analysis (II) checks Theorem 3 constructing local dependency graphevery suitable variable x0 every transition t0 leaving s(x0 ). find non-successfult0 , stop considering x0 . minimize exit distance bounds across different x0 .Analysis (III) checks Theorem 2 relaxed plan P + (s) computed FFs heuristicfunction. case relaxed plan exists s, analysis reports failure. Otherwise,analysis proceeds operators o0 P + (s), start end, variablesx0 affected o0 . pair o0 , x0 build optimal rplan dependency graph oDG+per Definition 1. skip variables x0 eff o0 (x0 ) actually used preconditiongoal, rest P + (s). oDG+ successful, stop. (Relaxed plans biglarge examples, continuing analysis exit bound minimization sometimescostly.) mentioned Section 5, build oDG+ re-order P + (s) movingoperators behind o0 possible. paramount importance avoids includingunnecessary variables oDG+ . re-ordering process straightforward. startsdirect predecessor o0 , tests whether P + (s) still relaxed plan movingdirectly behind o0 . yes, arrangement kept. iterate predecessoro, forth. easy see that, way, oDG+ contain exactly variables12. source code TorchLight online appendix paper. available download alsohttp://www.loria.fr/~hoffmanj/TorchLight.zip.176fiAnalyzing Search Topology Without Running Searchtransitions used P + (s) achieve preo0 . Finally, check whether oDG+ +relevant deletes t0 P>0(s)-recoverable, use simple technique allowing recognizesituations failure due one operator avoided replacing alternativeoperator. example, Transport o0 loading operator reducing capacity level kk 1, P + (s) may still contain unloading operator relying level k. Thus level kcontained R1+ C0 , causing failure. However, unloading wellperformed based capacity level k 1, removing difficulty. catch cases likeconstruction R1+ . Whenever find whose precondition overlaps C0 , testwhether replace similar operator.local analyses return simple statistics, namely minimum, mean, maximalexit distance bound found, well success rate, i.e., fraction sample statesguaranteed local analysis (II)/approximate local analysis (III) succeeded. Analysis(III) success rates main focus, turn informative.run R = 1, 10, 100, 1000 experiment. length random walkchosen uniformly 0 5 hFF (sI ), i.e., 5 times FF heuristic valueinitial state. play parameter 5. important, however,parameter chosen small. domains many dead ends one maythings fatally wrong likely bad things happensufficiently large number random choices. Consequently, dead-end rate, i.e.,fraction sample states relaxed plan exists, tends larger longerrandom walks. Since analysis (III) fails states relaxed plan, exertsimportant influence analysis (III) success rates. illustrate comparingresults sampled states results obtained using initial states only.8.2 Search Probingapproximate analysis sample states, exists simple (and rather obvious) alternative TorchLights causal graph based technology. One use search determinewhether given sample state local minimum, exit distance is. Sincecannot compute h+ effectively, search-based analysis necessarily approximate.straightforward method replace h+ relaxed-plan based approximation.Herein, replace h+ hFF , i.e., FFs heuristic function. Precisely, given states, run single iteration FFs Enforced Hill-Climbing, i.e., breadth-first searchstate better heuristic value. search, like FF does, use helpful actionspruning avoid huge search spaces. Unlike FF, focus detection stateslocal minima, allow monotone paths (thus restricting search space states s0hFF (s0 ) = hFF (s)). refer technique search probing, SP brief. alsoexperiment variant imposing 1 second runtime cut-off search. referlimited search probing, SP1s brief. SP SP1s run set LSstates TorchLights local analyses (II,III).turns out, empirically present benchmarks SP SP1s competitive TorchLights analysis (III). Since analysis main focus experiments,relevant understand commonalities differences techniques.far analysis quality guarantees concerned, 3 techniques analysis (III),SP, SP1s similar properties: guarantees whatsoever. may report177fiHoffmannsuccess although local minimum (false positives), may fail althoughlocal minimum (false negatives). cases, false positives due usenon-optimal relaxed plans (hFF instead h+ ). False negatives inherent analysis (III)covers certain special cases; inherent SP1s due searchlimit. SP false negatives due helpful actions pruning, however couldprinciple turned off; fundamental source false negatives non-optimalrelaxed plans. also responsible lack connections across techniques.implication trivial one SP1s success state implies SP successs. particular, analysis (III) correctly identifies local minimum,imply SP well. causal graph analysis may less affectedirregularities hFF surface. happens, example, Transport domainIPC 2008, resulting higher success rates analysis (III).obvious important differences regarding runtime performancedanger false negatives. SP runtime worst-case exponential size(grounded) input, whereas analysis (III) SP1s runtime low-order polynomialsize. SP, decreasing number R sample states merely reduces chance hittingbad state (a sample state large flat region), whereas analysis (III) SP1s scalelinearly R. hand, analysis (III) SP1s buy efficiencyincompleteness, i.e., increased danger false negatives. Analysis (III) simply recognizesspecial cases. SP1s effectively bounds lookahead depth, i.e., search depthexit states detected.indicated, SP SP1s turn competitive benchmarks. Large searchspaces rare SP. success rates SP SP1s similar, far predictivecapability concerned similarly informative analysis (III). Thus goodquality success rates obtained much simpler techniques TorchLight.13notwithstanding, (a) TorchLight functions guaranteed analyses (I,II)well diagnosis cannot simulated, (b) results benchmarks everpertain examples. TorchLights analysis (III) offers unlimited lookahead depthlow-order polynomial cost. appear matter much present benchmarks,natural cases matter. get back below.8.3 Experiments Set-Uprun experiments set 37 domains. include domains investigatedhand-made analysis h+ topology (Hoffmann, 2005), shown Figure 1,include domains international planning competitions (IPC) IPC 2004.remaining domains STRIPS (versions the) domains IPC 2006 IPC2008, except IPC 2008 Cyber-Security omit due parsing difficulties.14 testinstances collected IPC collection(s) applicable (removing action costconstructs IPC 2008 domains), randomly generated elsewhere. total,test set contains 1160 instances.13. particular, search probing appears rather useful technique, raising questiontechniques yet used performance prediction purposes. Roberts Howe (2009),example, use simple features only. get back conclusion.14. instances large FFs parser standard configuration. tweaking bison allowlarger parse trees, obtained segmentation fault even smallest instance IPC 2008.178fiAnalyzing Search Topology Without Running Searchtool/phaseFD TranslatorSG/DTGStatic AnalysisAnalysis (I)Sample StatesAnalysis (II)Analysis (III)TorchLight totalTorchLight (III)TorchLight (III) FDSPSP totalSP1sSP1s totalFFLAMAsingle-shot/R = 1meanmax6.12690.590.146.910.2531.420.4053.290.010.530.000.180.021.316.92727.636.52724.540.4033.950.0658.020.0758.030.011.080.011.48268.20185.05R = 10meanmax0.080.010.037.046.640.490.230.320.070.154.811.112.46736.98732.9840.50138.54138.594.469.27R = 100meanmax0.760.100.238.007.511.375.476.230.661.4250.359.5620.09807.70795.16103.6756.18106.53R = 1000meanmax7.500.982.1517.5716.1910.0426.2433.745.8913.39491.2094.59194.791510.741413.23719.27391.59882.79Table 2: Summary runtime data. Mean/max instances domains.empty fields, respective tool/phase single-shot, i.e., depend R.dash means time-out, 1800 seconds, inserted runtime respective instance mean computation. Rows FD Translator . . . Analysis(III) time different stages TorchLight. TorchLight total overall runtime, TorchLight (III) run analyses (II) (III), TorchLight (III)FD latter disregarding translation costs. SP determines success rate (fraction sample states deemed local minima) via searchprobing, i.e., search around sample state; SP1s imposes 1 second time-outsearches. SP total SP1s total include time generatingsample states.experiments run 1.8 GHZ CPU, 30 minute runtime 2 GBmemory cut-off. run 4 different planners/tools. Apart TorchLight (and SP/SP1s ),include FF (Hoffmann & Nebel, 2001a), LAMA (Richter et al., 2008; Richter& Westphal, 2010). purpose running planners assess extentTorchLights output particular analysis (III) success rate predict planner successfailure. examine also plain planner, also run version FF usesgoal ordering techniques, runs Enforced Hill-Climbing, without resortingbest-first search fails. refer planner EHC follows.8.4 Runtimecode currently optimized much readability speed. Still, TorchLightfast. R = 100, bottleneck Fast Downwards translator. R = 1, 10, 100,actual analysis takes much time translator 99.74%, 99.74%,96.21% instances respectively. assess detail, consider Table 2gives timing different stages TorchLight, planners/tools.translation runtime sometimes hurts considerably, peak 690.59 secondscostly instance Scanalyzer domain. rather exceptional, however.second costly domain Blocksworld-NoArm, peak 138.33 seconds.179fiHoffmann20 37 domains, costly instance translated less 10 seconds.57.24% instances, Fast Downwards translator takes 1 second.static analysis, peak behavior 31.42 seconds (also Scanalyzer) evenexceptional: 95.34% instances, static analysis takes 1 second. secondhighest domain peak 7.88 seconds Pipesworld-Tankage. Similarly, analysis (I)takes peak 53.29 seconds Blocksworld-NoArm 96.12% instancescompletes 1 second. domain Blocksworld-NoArmpeak instance takes 10 seconds Airport, peak 41.71 seconds; nexthighest domain peaks Pipesworld-Tankage (6.8), Scanalyzer (2.91), Logistics (1.89),Woodworking (1.17). domains, analysis (I) always completes within second.Turning focus local analyses, see even effective. particular, concentrate mostly approximate local analysis (III). seeR = 1000 offer advantages R 100 far information obtainedgoes, mostly concentrate R 100. R = 1, 10, 100, analysis (III) completes 1 second 99.66%, 99.40%, 95.60% instances respectively.R = 1000 still holds 76.55% instances. peak runtime 20.09 secondsR = 100 occurs Scanalyzer. next highest domain peaks Blocksworld-NoArm(9.23), Pipesworld-Tankage (4.24), Ferry(3.21), Logistics (2.99), Blocksworld-Arm (2.77),Optical-Telegraph (1.97), Airport (1.41). 29 domains, analysis (III)R = 100 always completes within second.bottleneck local analysis generation sample states. costlyinvolves repeated computation applicable operators randomwalks. R 100 peak 50.35 seconds Scanalyzer domain. However,again, peak behavior exceptional. R = 1, 10, 100, sampling completeswithin 1 second 100%, 98.28%, 87.41% instances respectively.main competitor TorchLight analysis (III) success rates search probing, i.e.,SP SP1s . Consider moment analysis methods themselves, i.e., rowAnalysis (III) vs. rows SP SP1s Table 2. Compared SP1s , analysis (III)consistently advantage (except maximum runtime R = 1), differencedramatic. expected, given SP1s trades completeness smallfixed maximum runtime. Compared complete search SP, analysis (III) consistentlysignificant advantage. However, R 10 mean runtime SP tolerable,even maximum runtime bad. Further, bad runtime behavior exceptional.R = 1, 10, SP completes 1 second 99.83% 98.45% instancesrespectively. 35 (R = 1) respectively 32 (R = 10) 37 domains even maximumruntime 1 second. R = 100, SP two time-outs, Blocksworld-Arm.R = 1000, 11 time-outs, Blocksworld-Arm, Blocksworld-NoArm, Freecell,Pipesworld-NoTankage. R = 100, maximum runtime 10 seconds7 domains; R = 1000, 12. However, R = 100, 1000, SP still completes1 second 92.33% 71.98% instances respectively (compared 95.60%76.55% analysis (III), cf. above).Neither analysis (III) search probing stand-alone methods. former requiresTorchLight except analyses (I,II). latter requires sampling random states.respective total data given rows TorchLight (III) SP total/ SP1s totalTable 2. picture changes dramatically favor SP especially SP1s .180fiAnalyzing Search Topology Without Running Searchnoted, though, mostly due overhead translation finite-domainvariables. overhead artifact implementation. approach definedfinite-domain variables, benchmarks not, even though finite-domainrepresentation cases natural Boolean one. Further, many planners(notably Fast Downward quickly growing set derivatives) use translationanyway. runtimes without translation given row TorchLight (III) FD.one would hope expect, analysis methods much faster actual planners. LAMA 112 time-outs test suite, FF 173.8.5 Analyzing Domainsdiscuss actual analysis outcomes, per-domain basis. first considerTorchLight, give details comparison analysis (III) success ratesobtained search probing. begin, words order regardingcomparison SP SP1s . R = 1, 10, 100, 1000, success rates identical99.83%, 99.14%, 97.5%, 94.66% 1160 benchmark instances respectively; 99.83%,99.14%, 99.31%, 98.97% instances, success rates differ 5%. Thus,small runtime cut-off adversely affect success rates search probing (becauselong searches rare). so, henceforth discuss data SP vs.SP1s separately. compare TorchLights analysis (III) success rates SP only.guarantees Proposition 1 confirmed, i.e., guaranteed global analysis (I) succeeds described Logistics, Miconic-STRIPS, Movie, Simple-TSP. never succeedsdomain, though. domains, fractions gDGs successful. Precisely, maximum fraction successful gDGs 97% Satellite, 50% Ferry, 33.33%TPP, 22.22% Driverlog, 20% Depots, 13.33% Tyreworld, 12.5% BlocksworldArm. However, fraction 100% nothing proved, data maybest used give indication aspects domain good-natured.Guaranteed local analysis (II) generally much applicable global analysis.Thus concentrate approximate local analysis (III) exclusively.Proposition 2 backed impressively. Even R = 1000, analysis (III) succeedsevery single sample state Ferry, Gripper, Elevators, Transport.15 indicatesstrongly potentially sub-optimal relaxed plans result loss informationhere. Indeed, analysis yields high success rates almost domains local minimanon-present limited. case domains, thus TorchLightdistinguish domains easy h+ topology hard ones. Consider Figure 3,showing mean analysis (III) success rates per-domain R = 1. (The picture similarR = 10, 100, 1000; cf. Table 3 below.)domains whose h+ topology known shown separately right handside Figure 3. domains, see quite nicely harder domains tendlower success rates. particular, easiest domains bottom class100% success rates (95% case Zenotravel), whereas hardest domainstop right corner around 50% less. latter domains, extent15. Historically, observation preceded Proposition 2, well h+ topology categorization Elevators Transport per Figure 1. is, hand-made analyses motivated observingTorchLights analysis outcome.181fiHoffmannPipesTank [40]PipesNoTank [76]PSR [50]Rovers [100]OptTele [7]Mystery [39]Mprime [49]Freecell [55]Airport [0]Hanoi [0]BlocksNoArm [57]Grid [80]Transport [+,100]bench ed <= clocal minima ed <= cBlocksArm [30]Depots [82]Driverlog [100]Elevators [+,100]Logistics [*,100]Ferry [+,100]Gripper [+,100]undirectedWoodwork [13]Trucks [0]TPP [80]Storage [93]Sokoban [13]Scanalyzer [30]Tyreworld [100]DinPhil [24]Satellite [100]Zenotravel [95]MiconicSTR [*,100]Movie [*,100]SimpleTsp [*,100]harmlessrecognizedPegSol [0]Pathways [10]ParcPrinter [3]Openstacks [0]unrecognizedFigure 3: Overview TorchLight domain analysis results. *: guaranteed global analysis(I) always succeeds. +: approximate local analysis (III) always succeedsprovided optimal relaxed plan. Numbers shown mean success rates perdomain, approximate local analysis (III) R = 1, i.e., samplingsingle state per domain instance.low success rates result recognition dead ends FFs heuristic function.example, random sampling make random vehicle moves consuming fuel, likeMystery Mprime, course chances end state fuelscarce even relaxed plan exist anymore. pronouncedAirport, sample states infinite heuristic values. However, capabilitiesanalysis go far beyond counting states recognized dead ends. Blocksworld-Arm,example, dead ends still success rate 30%, clearlyindicating domain difficult topology.extent, based success rates even distinguish Pipesworld-TankagePipesworld-NoTankage, Mprime Mystery (in Mprime, fuel transferredlocations). relatively high success rate Depots probably relates transportation aspects. Grid, 20% cases analysis strong enough recognizereasons behind non-existence local minima; reasons quite complicated(Hoffmann, 2003). Dining-Philosophers really favorable h+ topology.rather excessive bound 31 due particular domain structure philosophersbehave strictly symmetrical ways (Hoffmann, 2005). Apart this, strongoutliers Driverlog, Rovers, Hanoi, Blocksworld-NoArm. problems hand-made analysis TorchLights. Driverlog Rovers, deep localminima exist, awkward situations dont tend arise IPC instances. Thus hand-made analysis, worst-case nature, pessimistichere. opposite happens Hanoi Blocksworld-NoArm, absence localminima due rather idiosyncratic reasons. example, Hanoi reason h+always equal number discs yet goal position relaxation, onealways accomplish remaining goals one-by-one, regardless constraints entailedpositioning. Hanoi Blocksworld-NoArm actually easy solve182fiAnalyzing Search Topology Without Running SearchdomainAirportBlocks-ArmBlocks-NoArmDepotsDin-PhilDriverlogElevatorsFerryFreecellGridGripperHanoiLogisticsMiconicMovieMprimeMysteryOpt-TelePipes-NoTankPipes-TankPSRRoversSatelliteSimple-TSPTransportTyreworldZenotravelOpenstacksParc-PrinterPathwaysPeg-SolScanalyzerSokobanStorageTPPTrucksWoodworkingsI(III)96.038.370.010010010010010097.560.01000.010010010074.375.0040.034.066.010085100100100901001001000030.010010056.3100R=1(III)SP0.00.030.0 93.356.710081.810024.1 27.610010010010010010055.0 60.080.01001001000.0 33.310010010010010010048.6 74.339.3 42.97.1 14.376.0 98.040.0 92.050.0 62.0100100100100100100100 93.31001009510004.43.36.710.0 10.001030.0 96.713.3 33.393.3 96.780.0 80.00013.3 13.3R = 10(III)SP2.02.028.2 94.557.210085.9 99.122.8 23.197.510010010010010057.4 62.874.0 92.010010011.1 44.410010010010010010061.1 76.337.1 43.91.42.975.4 97.450.6 90.057.6 69.8100 99.598.5100100100100 93.095.610094.5 99.514.8 21.38.08.36.06.013.3 22.733.0 99.720.3 38.389.0 96.368.0 67.02.53.114.3 14.3R = 100(III)SP2.82.926.9 91.755.9 99.986.3 99.722.8 22.997.4 99.910010010010057.9 63.569.0 93.810010010.2 41.910010010010010010064.3 79.037.6 45.60.91.475.2 97.449.4 88.158.3 71.1100 99.898.4100100100100 94.896.310095.8 98.417.7 22.06.37.25.45.413.1 22.333.5 97.919.1 38.289.8 96.865.4 63.81.92.915.3 15.4(III)2.926.556.286.222.097.910010058.069.510010.610010010064.136.31.175.148.757.010098.010010095.595.416.66.04.612.633.918.589.365.51.415.3R = 1000SP3.082.198.399.622.399.810010063.293.510041.910010010078.244.41.795.488.270.499.899.810094.410098.220.86.84.622.298.537.796.963.92.715.4DE97.000077.200035.40000007.246.898.308.7000000079.193.095.375.2054.2034.597.384.6Table 3: Mean success rates per domain. Upper part: domains whose h+ topology previously examined hand (Hoffmann, 2005) trivial examine basedresults; lower part: IPC 2006/2008 domains case. ColumnssI show data analyzing initial state only, columns R = 1, 10, 100, 1000analyzing respective number sample states. Columns (III) give dataapproximate local analysis (III), columns SP give data search probing,column DE gives dead-end rates R = 1000.FF, sense, practical perspective, low success rates TorchLightsanalysis (III) provide accurate picture.Table 3 gives complete account per-domain averaged success rates data, includingdomains, values R, rates obtained initial states, using SP insteadTorchLight. serves answer three questions:(1) important sample random states, rather analyzing initial state?(2) important sample many random states?183fiHoffmann(3) competitive analysis (III) respect search-based analysis?answer question (1) clear yes. importantly, pertains domainsdead ends, cf. brief discussion above. clear Table 3 that, domains,analyzing sI results tendency optimistic. see this, consider entriesAirport, Dining-Philosophers, Freecell, Mystery, Openstacks, Parc-Printer, Pathways,TPP, Trucks, Woodworking. domains dead ends, variety reasons.dead ends occur frequently initial state level, occur frequentlyrandom walks cf. column DE Table 3. (Interestingly, domains notablytwo Pipesworlds opposite happens, i.e., success rates lower sIsample states. clear us causes phenomenon.)simply compare sI column R = 1000 column analysis (III),find result lot different 10% 22 37 domains.extent, difference initial states sample states may dueway benchmarks designed. Often, initial states every instance similarcertain ways (no package loaded yet, etc). hand, seems quite natural,least offline problems, initial state different states deeperstate space (consider transportation problems card games, example).answer question (2) clear no. example, compare R = 1R = 1000 columns analysis (III). difference greater 10% 637 domains. peak difference Openstacks, 16.6% R = 1000 vs. 0%R = 1. average difference domains 4.17%. Similarly, comparing R = 1R = 1000 columns SP results 5 37 domains difference greater10%, peak Openstacks, 20.8% R = 1000 vs. 4.4% R = 1.average difference domains 3.7%.answer question (3) bit complicated. Look columns analysis(III) respectively SP R = 1000. number domains difference larger10% 11 37, peak 64.6% difference Scanalyzer. onehand, still means 26 37 domains analysis result get closesearch (average difference 2.18%), without actually running search!hand, happens 11 domains? these, success rate SPhigher TorchLight. surprising basically means TorchLightsanalysis strong enough recognize states local minima.Interestingly, weakness turn unexpected advantage. 11 domainsquestion, 8 domains Blocksworld-Arm, Depots, Mprime, Pipesworld-Tankage, PipesworldNoTankage, PSR, Scanalyzer, Sokoban contain deep local minima.16 Thus,8 domains, would wish analysis return small success rates. TorchLight grantswish much SP does. Consider happens using SP instead analysis(III) Figure 3. Mystery, PSR, Sokoban, change dramatic. However,Blocksworld-Arm marked average success rate 93 instead 30, putting almostpar very-simple-topology domains bottom class. Similarly, PipesworldTankage, Pipesworld-NoTankage, Scanalyzer put almost par these. Depots16. Sokoban unrecognized dead-ends (in relaxation, blocks pushed across other)therefore local minima. Scanalyzer, analyzing plants misplaces side effect, bringingback start position, across large circle conveyor belts, may take arbitrarily many steps.See Figure 3 6 domains.184fiAnalyzing Search Topology Without Running Searchactually receives 100, putting exactly par them. Thus SP analysis outcomeactually looks quite bit worse, 5 domains.causes undesirably high success rates SP? authors best guess that,many domains, chance randomly finding state local minimum low.large-scale experiments measuring statistics search space surface FFs heuristicfunction (Hoffmann, 2003), observed many sampled states local minimathemselves, contained valleys. Within valley, monotonicallydecreasing path goal state. state may local minimum because,because, one descend deeper valley. seems SP correctly identifiesvalley states local minima, thus counting good many states actuallylocated difficult regions search space. weakness SP, successrate search space feature.17 weakness manifest muchanalysis (III)? analysis picky takes good statesqualify particular special cases. tend occur often difficult domains.course, easy construct examples turning discussed strength realweakness TorchLights analysis quality. seem happen lotpresent benchmarks. Now, said that, present benchmarks arent well suitedbring theoretical advantage analysis (III) either. analysis offers unlimitedlookahead depth low-order polynomial cost. However, even R = 1000, 23 37domains highest exit distance bound returned 0, i.e., every exit path identified consistssingle operator. cases could handled much simpler variant analysis(III), looking operators o0 directly applicable s, thus removingentire machinery pertaining SG predecessors x0 . Still, machinery mattercases quite natural. highest exit distance bound returned 10 Grid 7Transport. generally, transportation domain non-trivial road-map,easy construct relevant situations. example, say road map Transport forms Ncities, diameter least one vehicle, distances cities largerelative D. Then, typical state, around N vehicle moves considered helpfulFF: least 1 per city since local vehicles preferred relaxed plan.successor states identical h+ package loaded/unloaded. typicalnumber steps required grow D. If, example, vehicleoutskirts packages city center, around D/2 steps required,finding exit takes runtime around N D/2 . small values N alreadyrender search probing either devoid information (if runtime cut-off small),computationally infeasible (recall probing quick pre-processactual planning). contrast, analysis (III) easily delivers correct success rate 100%.8.6 Predicting Planner Performancedirect measure predictive quality success rates, conducted preliminaryexperiments examining behavior primitive classifiers, runtime distributionslarge vs. small success rates. consider first classifiers. predict, givenplanning task, whether EHC/FF/LAMA succeed solving task, within given17. Note cannot use valley rate instead, cheap domain analysis, since determining whetherlies valley implies finding plan thus solving task side effect.185fiHoffmanntime memory limits. classifiers answer yes iff success rate threshold0, 10, . . . , 100. Obviously, this, need R > 1. consider followsR = 10 R = 100 because, shown above, R = 1000 costly.EHC, TorchLight analysis (III) SP deliver fairly good-quality predictions,considering actual machine learning involved. prediction quality TorchLight good sometimes slightly better search. Whether useR = 10 R = 100 make big difference. EHC solves 60.69% instances,rate correct predictions trivial baseline classifier always answering yes.R = 10, best rate correct predictions 71.90% TorchLight (with = 80)70.17% SP (with = 90). R = 100, numbers 71.76% (T = 60)71.16% (T = 100). Dead-end rate bad predictor. best predictionbaseline classifier = 0, second best classifier (T = 100) 36.79% correct.Interestingly, major differences different sets domains.domains previously analyzed hand (Hoffmann, 2005; Figure 1 without ElevatorsTransport), best prediction 75.75% correct TorchLight = 70,74.07% correct SP = 100, vs. baseline 63.81%. IPC 2006 domains,numbers 57.98% 61.34% vs. baseline 55.46%, = 10 cases, i.e.,best classifier close baseline. IPC 2008, hand, appearsexceptionally good-natured, numbers 79.52% (T = 60) 82.38% (T = 80) vs.baseline 51.90%. clear us causes phenomena.18summary, quality prediction always clearly baseline, around 10%looking domains, even 30% looking IPC 2008 domainsonly. comparison, using state-of-the-art classification techniques simple features, Roberts Howe (2009) get 69.47% correctness vs. baseline 74% (for saying no),unseen testing domains FF. said that, setting consideredlearning, actually distinguish learning datatesting data. Roberts Howes unseen testing domains IPC 2006 (indifferent setting including also ADL test suites). setdomains 2006 (Figure 1 without Elevators Transport), getbest prediction = 70 TorchLight = 100 SP. setting ,prediction correctness IPC 2006 suite 29.41% respectively 51.26% only, vs.baseline 55.46%. hand, seems pertain IPC 2006 specifically.IPC 2008, = 70 respectively = 100 good settings, giving 76.67% respectively76.19% correctness vs. baseline 51.90%.Importantly, Roberts Howe predicting performance EHCFF, complex algorithm. FF LAMA, prediction qualityTorchLight SP rather bleak, using described primitive classifiers. cases,best prediction correctness obtained always answering yes. bestsaid success rate still predicts much better dead-end rate. giveexample data, R = 10 across domains FF, baseline 85.09% correct.= 10, goes 77.50% TorchLight, 79.31% SP, 34.57% dead-endrate. LAMA, baseline 90.26% correct, = 10 goes 81.81%18. bad prediction quality IPC 2006 domains might related fact fully grounded,potentially impeding ability Fast Downwards translator find useful finite-domain variables.186fiAnalyzing Search Topology Without Running SearchTorchLight, 83.97% SP, 29.91% dead-end rate. FF LAMA,growing prediction quality decreases monotonically cases.prediction quality much worse FF EHC,main building block FF? Whereas EHC typically fails tasks whose h+ topologyfavorable, FFs LAMAs complete search algorithms able solve manycases, too. example, TorchLight success rates R = 10, EHC solves34.07% tasks success rate 0, solves less 50% success rate 70%.contrast, FF LAMA solve 74.18% respectively 76.92% tasks success rate0, solve least 70% success rates.Despite this, success rates far devoid information FF LAMA. Settingthreshold 10, . . . , 100, look distribution planner runtime instancesubset (A) success rate < , vs. instance subset (B) success rate .Taking null hypothesis means two runtime distributionssame, run Students T-test unequal sample sizes determine confidencenull hypothesis rejected. is, determine confidencedistribution (B) lower mean distribution (A). Using TorchLights success rateFF runtimes, R = 10 R = 100, 10 settings , get confidenceleast 99.9%. difference means data, i.e., mean runtime(A) minus mean runtime (B), tends grow . peaks 336 respectively 361seconds R = 10 respectively R = 100; average difference values 239respectively 240. Likewise, LAMA runtimes settings R yield confidence99.9%, average differences 242 respectively 235. results SP comparableLAMA. slightly worse FF, though. R = 10 confidence 99.9%= 10, 20; confidence 95% values . difference peaks 241seconds (vs. 336 TorchLight), average 150 seconds (vs. 239). R = 100,thresholds = 30, 40, 50, 100 yield 99.9% confidence, average difference 160.perhaps little surprisingly, simpler planner EHC runtime distributions behave differently. TorchLight success rates, get several casesconfidence < 95%, average differences around 80 seconds. SP, casesget 99.9% confidence mean (B) larger (A). Again, reasonsimple. many tasks unfavorable h+ topology, enforced hill-climbing quickly exhausts space states reachable FFs helpful actions. EHC gives solvingtask, although consumed little runtime peculiar behavior one wouldcertainly expect planner trying competitive.Summing up, success rates planning task feature provide good coveragepredictor EHC even without significant learning. FF LAMA, thingseasy, however consideration runtime distributions clearly showsfeature highly informative. Exploiting informativeness predicting planner performance presumably requires combination features, actual machine learningtechniques, along lines Roberts Howe (2009). topic future research.8.7 DiagnosisLet us finally consider TorchLights diagnosis facility. idea behind facilitysummarize reasons analysis failure. Testing sufficient criteria absence local187fiHoffmannminima, diagnosis guaranteed identify domain features causing presence.Still, least analysis using Theorem 2, diagnosis quite accurate.current diagnosis facility merely first-shot implementation based reportingpairs (operator o0 , variable x) caused oDG+ o0 successful. is,report pair (o0 , x) o0 effect x, context fact (x, c) transitiont0 taken o0 contained R1+ C0 F0 , recoverable sub-sequence+P>0(s). brief, record (o0 , x) o0 harmful effect x. perform testwhether main effect o0 , i.e., x0 , invertible; case recordx0 since problem appear side effects. avoid redundancies reporting,record grounded operator o0 name action schema (loadinstead load(package1 truck7)). Similarly, option record x namepredicate underlying fact (x, c). configuration, diagnosis comesform action-name, predicate-name, direct match high-level PDDLinput files. measure parts diagnosis important,associate pair count occurrences, weigh pairs frequency.Zenotravel, diagnosis output always form fly, fuel-level zoom,fuel-level, indicating correctly fuel consumption causing localminima. Mprime Mystery, cause local minima same, howeverdiagnosis reliable specific structure domain, associating fuellocations instead vehicles. sometimes causes diagnosis concludeeffect changing locations causing trouble. Concretely, R = 1000Mystery, fuel consumption top-weighted diagnosis 17 28 tasks;Mprime, happens 30 35 tasks. Satellite Rovers, diagnosisalways takes form switch-on, calibrated respectively take-image, calibrated, thusreporting problem switching instrument, respectively taking image,deletes calibration. precisely reason local minima exist here.19Tyreworld, often diagnosis reports problem jacking hub resultslonger jack (which needed elsewhere, too). actuallycause local minima (there none), indeed appears crucial aspect domain.Similarly, Grid frequent diagnosis picking key results armlonger empty again, actually cause local minima, critical resourcedomain. Blocksworld-Arm, dominant diagnoses block longerclear stack something top it, hand longer empty pickingblock. Similarly, Freecell, dominant diagnoses send-to-free, cellspacesend-to-new-col, colspace.One could make list much longer, however seems clear alreadydiagnosis facility, although yet primitive, potential identify interesting aspectsdomain. Note making use one information sourcesTorchLight. many things recorded, pertaining reasonsanalysis failure, like support graph cycles etc, also reasons analysis success, likesuccessful gDGs x0 , o0 pairs yielding successful oDG+ s. appears promising tryimprove diagnosis combining information sources. combination19. Since analysis failure rare two domains, often diagnosis give output all.R = 1000, output non-empty 10 instances Satellite 8 instances Rovers. R = 100reduces 4 instances Satellite, single one Rovers.188fiAnalyzing Search Topology Without Running Searchdomain analysis techniques, like landmarks invariants extraction, could alsouseful. direction future work.209. Related Workprior work aforementioned one author (Hoffmann, 2005)trying automatically infer topological properties heuristic function. Thus workrelate strongly domain analysis techniques. closest relationtechniques relying causal graphs. follows discuss detail, alongconnections arising context.local analysis succeeds, construct path exit identified. this,work relates work macro-actions (e.g., Botea, Muller, & Schaeffer, 2004; Vidal,2004). distinguishing feature macro-action (would be) constructedtargeted analytical way, even giving guarantee, conservative case, makeprogress towards goal. machinery behind analysis based causal graphs,shares similarities known causal-graph based execution path generation methods(e.g., Jonsson & Backstrom, 1995; Williams & Nayak, 1997; Brafman & Domshlak, 2003).distinguishing feature focus h+ individual states ratherwhole task. allows us consider small fragments otherwise arbitrarily complexplanning tasks look oDG+ instead SG. Note ability quite powerfulfar applicability goes. seen Section 8, success rate (local)approximate analysis therewith fraction states would ablegenerate macro-action non-zero almost benchmark domains. course,broad applicability comes prize. traditional causal graph methods guaranteereach goal, worst case macro-actions may lead h+ local minima. Still,may interesting look whether other, traditional, causal-graph based methodslocalized (or similar) manner well.Global analysis, focus whole planning task thus whole causalgraph, even closely related research causal graphs based tractability analysis.major difference tractability analysis h+ topology analysis, principle,tractability absence local minima orthogonal properties general,neither one implies other. Now, pointed end Section 6, globalanalysis imply tractability (of plan existence). Vice versa, restrictions madeknown tractable classes imply absence local minima? many cases, answerquestion definite no; interesting questions open; single casecorresponding basic result answer yes.Example 3 Appendix A.4 shows one construct local minimum 2variables domain size 3, 1-arc SG, unary operators, strongly connected DTGssingle non-invertible transition. example (and various scaling extensions breakingrespective conditions) falls variety known tractable classes. example20. particular, Fast Downwards translator always perfect detecting finite-domain variablesunderlying benchmarks. example, Satellite often detect electricity availableexactly one instruments mounted satellite. lead pointless diagnosis output,handled using simple notion predicates exchanged every operator.things like principled manner, invariants analysis would useful.189fiHoffmanntractable class Fn identified Domshlak Dinitz (2001), every transitiondependent variable depends variable. example Helmerts (2004,2006) SAS+ -1 class strongly connected DTGs. example solved, i.e., reducedempty task, Haslums (2007) simplification techniques (also, techniquessolve tasks Satellite domain, contain local minima). examplefork inverted fork causal graph, bounded domain size 1-dependent actions(actions 1 prevail condition), thus qualifies tractable classesidentified Katz Domshlak (2008b). examples causal graph chain,thus particular polytree bounded indegree, corresponding tractable classidentified Brafman Domshlak (2003) except that, there, variables restrictedbinary (domain size 2). open question whether plan existence chain causalgraphs domain size 3 tractable; strongest known result NP-harddomain size 5 (Gimenez & Jonsson, 2009b).21 Similarly, example fits prerequisitesstated Katz Domshlak (2008a) except binary variables only;open question whether local minima exist tractable classes identified there.Finally, example, suitable scaling extension, obviously qualifies two theoremsstated Chen Gimenez (2010). Theorem 3.1 (more precisely, first parttheorem) requires constant bound size connected componentsundirected graph induced causal graph. first part Theorem 4.1requires constant bound size strongly connected components causalgraph, pertains notion reversible tasks requiring always go backinitial state.Next, consider line works restricting causal graph DTGstask (Backstrom & Klein, 1991; Backstrom & Nebel, 1995; Jonsson & Backstrom, 1998).simplest class identified here, contained classes, SAS+ -PUBSfact achieved one operator (post-unique, P), operators unary(U), variables binary (B), variables one value requiredcondition transition variable (single-valued, S). Now, Example 2Appendix A.4 shows local minimum example U properties.example two variables, x y, local minimum arises cyclicdependency prevents attaining goal value dn via shortest path takenoptimal relaxed plan. remove two values domain y, removealternative way reaching dn ,22 example still contains local minimumalso P B properties. remark modified example unsolvable.remains open question whether solvable SAS+ -PUBS tasks local minima exist;generally, question open even larger SAS+ -PUS class, (yet larger)SAS+ -IAO class identified Jonsson Backstrom (1998).Another open question whether 3S class Jonsson Backstrom (1995)contains local minima. class works binary variables only; requires unary operatorsacyclic causal graphs, however allows facts splitting instead reversible.p splitting then, intuitively, task decomposed three independent subtasks respect p; open question whether local minima constructed21. Although, course, clear that, DTGs strongly connected case, decidingplan existence tractable matter domain size is.22. modification given detail example Appendix A.4.190fiAnalyzing Search Topology Without Running Searchsatisfying property. Disallowing splitting option 3S, obtain singlepositive case, known tractable class contain local minima.class corresponds basic result acyclic causal graphs invertible transitionsexcept variables restricted binary. Williams Nayak (1997) mentionrestrictions (but make formal claims regarding tractability) corresponding exactlybasic result except allow irreversible repair actions. latter actionsdefined relative specialized formal framework control systems, spiritsimilar term transitions self-irrelevant deletes herein.Finally, easy see that, Bylanders (1994) three tractability criteria, twoallowing several effects imply absence local minima. third criterion,restricting action effects single literal preconditions positive literals (but allowingnegative goals), leave open question whether local minima exist.remark criterion apply benchmark aware of.close section, certainly wish claim identificationtractable classes contribution work, note scope Theorem 4tractable class, cf. covered known tractable classes.23tractable cases identified Bylander (1994) obviously cover Logistics,Miconic-STRIPS, Movie, Simple-TSP. Many causal graph based tractability resultsrequire unary operators (Jonsson & Backstrom, 1995; Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Helmert, 2004, 2006; Katz & Domshlak, 2008a, 2008b; Jonsson,2009; Gimenez & Jonsson, 2008, 2009a), cover Miconic-STRIPS, Movie,Simple-TSP. work Chen Gimenez (2010), Theorem 4.1 requires reversibility given either Movie, Miconic-STRIPS, Simple-TSP,Theorem 3.1 requires constant bound size connected componentsundirected graph induced causal graph, given none Logistics, MiconicSTRIPS, Simple-TSP. known tractability results make different restrictionsDTGs (Backstrom & Klein, 1991; Backstrom & Nebel, 1995; Jonsson & Backstrom,1998). Even general tractable class identified there, SAS+ -IAO, covers noneMiconic-STRIPS, Logistics, Simple-TSP (because vehicle variables acyclicrespect requestable values), neither cover Movie (because rewindingmovie neither unary irreplaceable: side effect un-setting counter,breaking DTG counter two disjoint components).far coverage benchmarks goes, strongest competitor Theorem 4Haslums (2007) simplification techniques. iteratively remove variablespaths relevant attaining required conditions free, i.e., traversed using transitions neither conditions side effects. Haslums Theorem 1 statesremoval done without jeopardizing solution existence, i.e., plan originaltask reconstructed easily plan simplified task. particular,task solved simplified completely, empty task plan constructedpolynomial time. Haslum combines basic technique number domain reformulation techniques, e.g., replacing action sequences macros certain conditions.choice combination techniques apply fully automated, parts23. true basic result, explained essentially covered works JonssonBackstrom (1995) Williams Nayak (1997). Formally, prerequisites imply (thefirst part of) Theorem 4.1 work Chen Gimenez (2010), namely, postulated bound 1.191fiHoffmanntechniques fully described, making comparison Theorem 4 difficult.Haslum reports techniques solve tasks Logistics, Miconic-STRIPS, Movie,plus Gripper Satellite. Haslum experiment Simple-TSP. Theorem 1,stated form, solve Simple-TSP, transitions rootvariable side effects (with irrelevant deletes). Extending theorem coverirrelevant deletes straightforward. subtle weakness Haslums Theorem 1 relative Theorem 4 pertains reaching required values externally causedvalues. Haslum requires moves free, whereas, definition recoverableside effect deletes, Theorem 4 allows recovering operators affect several variablestake precondition prevails effects o0 .10. Conclusionidentified connection causal graphs h+ , devised tool allowinganalyze search space topology without actually running search. tool yetautomatic Hoffmann, analysis quality impressive even comparedunlimited search probing.generic level, conclusion work that, sometimes, possibleautomatically infer topological properties heuristic function. interesting questionfuture work whether also done heuristics h+ (cf. alsocomments regarding causal graph research below). Methodologically, noteworthyanalysis based syntactic restrictions problem description, traditionally used identify tractable fragments (of planning computationallyhard problems). present work showcases similar techniques applyanalysis search spaces general problem solvers.main open question whether global analysis tightly approximate scopeTheorem 2. indicated, good starting point appears trying include, gDGoperator o0 , variable dependencies induced operators may actually precedeo0 optimal relaxed plan. approach automatically recognizing operators couldpossibly developed along lines Hoffmann Nebel (2001b), using simplifiedversion aforementioned fact generation tree analysis technique (Hoffmann, 2005).Additionally, would great recognize situations harmful side effects o0like making hand non-empty pick ball Gripper necessarilyrecovered inside relaxed plan. Possibly, analysis could based variantaction landmarks (Hoffmann, Porteous, & Sebastia, 2004; Karpas & Domshlak, 2009).Another interesting line research start results given individual stateslocal analysis, extract reasons success s, generalize reasonsdetermine generic property success guaranteed. Taken extreme,might possible automatically identify domain sub-classes, i.e., particular combinationsinitial state goal state, absence local minima proved.work highlights two new aspects causal graph research. First, shows that,certain situations, one localize causal graph analysis, consider causalgraph fragment relevant solving particular state. Second, one use causal graphsconstructing paths global goal, state value heuristic hdecreased. former enables analysis succeed tasks whose causal graphs192fiAnalyzing Search Topology Without Running Searchotherwise arbitrarily complex, thus potential greatly broaden scopeapplicability. latter necessarily limited h+ simple example,obvious similar constructions made trivial heuristic counting numberunsatisfied goals thus opens completely new avenue causal graph research.Another possibility planner performance prediction, along lines RobertsHowe (2009). experimental results indicate TorchLights problem features,also search probing, highly informative. potential significantlyimprove results Roberts Howe unseen domains currently usesimple features, like counts predicates action schemes, hardly capture domainindependent structure relevant planner performance. Like limited search probing (SP1s ),TorchLight generates features without jeopardizing runtime, thus enabling automaticplanner configuration. Unlike search probing, may even work on-line search:single relaxed plan already deliver interesting information. example, one mightmake search less greedy choosing different search strategy, switching helpfulactions off, etc. depending outcome checking Theorem 2.mentioned Section 9, direction worth trying use local analysis generatingmacro-actions. domains high success rate, seems likely macro-actionswould lead goal search all. priori clear, though, whetherapproach would significantly strengthen, least present benchmarks, existingtechniques executing (parts of) relaxed plan (e.g., Vidal, 2004).One could use TorchLights diagnosis facility basis abstraction techniquederiving search guidance, much currently done relaxation/abstractiontechniques. diagnosis pin-point operator effects causing problemssearch. remove enough harmful effects end task Theorem 4applies, abstracted problem tractable. example, transportation domains,process could abstract away fuel consumption. abstract much,information provided may still outweigh effort abstract planning, i.e.,using actual planner inside heuristic function. example, Grid abstract taskcould problem variant allowing carry several keys once. One could also focusconstruction different heuristics based ignoring deletes harmful effects.Finally, interesting research line domain reformulation. well known,domain formulation make huge difference planner performance. However,difficult choose good formulation, given planner. black art evenreformulation done developer planner question. lack guidanceone main open problems identified Haslum (2007) automatic reformulationapproach. frequent question author asked non-expert usersmodel domain FF handle easily.TorchLights diagnosis facility, pin-pointing problematic effects, might instrumentaladdressing difficulties. case reformulation done computer,one possibility use analysis outcome could produce macro-actions hidingwithin operators harmful effects. Another possibility could precompose variable subsets touched harmful effects.case reformulation done human user, sky limit.name one example, local minima Satellite could removed allowingswitch instrument pointing direction instrument193fiHoffmanncalibrated. generally, note end-user PDDL modeling writing PDDLnon-expert user wanting solve problem using off-the-shelf planners quitedifferent PDDL modeling planning experts developing benchmarks.example, expert models transportation benchmark fuel consumption,may seem quite pointless TorchLight determine fuel consumption hurtplanner performance. Indeed may reason fuel consumption includedfirst place. contrast, end-user (a) information may come surprise,(b) user may actually choose omit fuel consumption may yieldbetter point trade-off planner performance plan usability. Generallyspeaking, approach could give user guidance designing natural hierarchyincreasingly detailed increasingly problematic domain formulations. couldhelp making planning technology accessible, thus contribute challengetaken much seriously planning community.Acknowledgmentswould like thank anonymous reviewers both, article hand ICAPS2011 short version, constructive comments. particular, one reviewersproved completeness results Theorem 1, another reviewer suggested futureresearch line trying generalize reasons success local analysis.thank Carmel Domshlak discussions, feedback early stages work contributing particular d-abstracted task construction proof Lemma 3executive summary status quo causal graph research.special thanks goes Carlos Areces Luciana Benotti, inspiringwork first place. long ago given problem. CarlosLucianas insistence finally made see connection causal graphs tryingconvince analysis like impossible.Appendix A. Technical Details Proofsgive full proofs and, needed, fill technical definitions. firstprove complexity result (Appendix A.1, Theorem 1), result pertaininganalysis optimal relaxed plans (Appendix A.2, Theorem 2), result pertainingconservative approximations (Appendix A.3, Theorems 3 4). construct numberexamples relevant kinds analysis (Appendix A.4), giving proofsdomain-specific performance guarantees (Appendix A.5, Propositions 1 2).A.1 Computational ComplexityTheorem 1. PSPACE-complete decide whether state space givenplanning task contains local minimum, given integer K PSPACE-completedecide whether states ed(s) K. Further, PSPACE-completedecide whether given state local minimum, given integer KPSPACE-complete decide whether ed(s) K.194fiAnalyzing Search Topology Without Running SearchProof. Throughout proof, since PSPACE closed complementation,distinguish mentioned PSPACE-complete decision problems complements.membership results easy prove. Note first that, given state s,compute h+ (s) within polynomial space: generate potentially non-optimal relaxed plan,length n, known methods; iteratively decrement n test valuewhether relaxed plan length still exists; stop test answers no.test bounded relaxed plan existence NP thus PSPACE. here,prove membership results simple modifications guess-and-check argumentshowing PLANSAT, problem deciding whether given planning task solvable,NPSPACE hence PSPACE (Bylander, 1994). argument worksstarting initial state, guessing actions, terminating successfully goal statereached. Unsuccessful termination occurs guessed path longer trivialupper bound B := xX |Dx | number different states. able checkcondition polynomial space, path length maintained binary counter.decide whether given state (not) local minimum, run guess-and-checkalgorithm s, modified to: compute h+ encountered state; terminate unsuccessfully bound B exceeded h+ increases operator application;terminate successfully h+ decreases operator application. decide whethered(s) K, use algorithm except bound B replaced bound K,increases h+ permitted, success occurs h+ decreases h+ (s) h+ (s)1.decide whether state space entire planning task contains local minima, whetherstates state space ed(s) K, simply run Bylanders guess-and-checkalgorithm way enumerating reachable states, individual staterun modified guess-and-check algorithms described. Clearly, algorithmsrun non-deterministic polynomial space, shows part claim.show PSPACE-hardness results. first consider problem deciding whether given state local minimum. proof works reducingPLANSAT, known PSPACE-hard propositional STRIPS (Bylander,1994), trivially follows PLANSAT PSPACE-hard also finitedomain variable planning tasks use herein.Let (X, sI , sG , O) planning task whose solvability wish decide. designmodified task (X 0 , s0I , s0G , O0 ) starting (X, sI , sG , O) making followingmodifications:Add new variable ChooseT ask X 0 ,s0I (ChooseT ask) = nil, s0G (ChooseT ask) undefined.domain{nil, org, alt},role variable give planner choice whether solveoriginal task (X, sI , sG , O), whether solve alternative task custom-designedproof.Add new variable DistAlt X 0 , domain {0, 1}, s0I (DistAlt) = 1,s0G (DistAlt) = 1.variable simply serves control length solution alternative task.solution length 1 plus number steps needed bring DistAlt195fiHoffmannvalue 0 goal value. (Here, 1 step needed so; laterproof, increase distance.)Add two new operators oOrg = ({(ChooseT ask, nil)}, {(ChooseT ask, org)})oAlt = ({(ChooseT ask, nil)}, {(ChooseT ask, alt), (DistAlt, 0)}).implements choice planning task. Note that, choose alternativetask, DistAlt set 0, thus forcing solution bridge distance.contrast, original task, variable keeps residing goal valuealready assigned s0I (DistAlt).Add new operator oDistAlt = ({(ChooseT ask, alt), (DistAlt, 0)}, {(DistAlt, 1)}).allows bridge distance intended solution alternative task.Add new operator osG Alt = ({(ChooseT ask, alt), (DistAlt, 1)}, sG ).allows us accomplish original goal, final step solving alternative task.Add (ChooseT ask, org) new precondition original operators, i.e.,taken O.forces planner choose original task, executing operators.Add new variable StillAlive X, domain {yes, no}, s0I (StillAlive) = yes,sG (StillAlive) = yes. Add new operator osG Dead = (, sG {(StillAlive, no)}).osG Dead operator allows us accomplish original goal single step,matter task chosen solve, also new initial state s0I already.However, operator also sets new variable StillAlive value no, whereasgoal value variable yes. value cannot re-achieved, thusoperator leads dead-end. function proof flatten valueh+ original task, s0I , constantly 1 unless goal state.extreme flattening happen alternative task because, there,distance variable DistAlt also needs handled.summary, (X 0 , s0I , s0G , O0 ) designed setting:X 0 := X {ChooseT ask, DistAlt, StillAlive}s0I := sI {(ChooseT ask, nil), (DistAlt, 1), (StillAlive, yes)}s0G := sG {(DistAlt, 1), (StillAlive, yes)}O0 := {(pre {(ChooseT ask, org)}, eff) | (pre, eff) O} {oOrg , oAlt , oDistAlt , osG Alt ,osG Dead }consider new initial state s0I . exactly three successor states: sDead produced osG Dead , sOrg produced oOrg , sAlt produced oAlt . h+ (sDead ) =sDead (StillAlive) = no. h+ (s0I ) = h+ (sOrg ) = 1 due relaxed196fiAnalyzing Search Topology Without Running Searchplan hosG Dead i. Finally, h+ (sAlt ) = 2 oAlt sets DistAlt variable 0whereas goal 1. Thus shortest relaxed plan sAlt hoDistAlt , osG Alt i.this, clearly follows s0I local minimum iff sOrg monotonepath state h+ (s) < h+ (sOrg ). Since h+ (sOrg ) = 1, latter equivalentexistence monotone path sOrg goal state, i.e., path goal stateh+ constantly 1. Since, states reachable sOrg , single-step sequencehosG Dead relaxed plan, equivalent existence path sOrg goalstate. Clearly, latter equivalent solvability original task (X, sI , sG , O). Thuss0I local minimum iff (X, sI , sG , O) solvable, shows part claim.next prove PSPACE-hardness deciding whether given planning taskcontains local minimum. follows easily above. Observe alternativetask contain local minima. described, h+ (sAlt ) = 2. applyoDistAlt sAlt , obtain state sAltDist h+ (sAltDist ) = 1 relaxedplan hosG Alt i. Applying osG Alt sAltDist yields goal state, thus sAlt sAltDistbetter evaluated neighbors. states descending sAlt must producedosG Dead thus h+ value . So, (X 0 , s0I , s0G , O0 ) contains local minimum iffpart state space descended sOrg does. Since states h+ value 1 unlessgoal states, cf. above, latter equivalent unsolvability (X, sI , sG , O)shows part claim.Assume given integer K need decide individual statewhether ed(s) K. reduce Bounded-PLANSAT, problem deciding whethergiven planning task solvable within given number steps. Bounded-PLANSATknown PSPACE-complete bound given non-unary representation.modify task (X 0 , s0I , s0G , O0 ) given above, way increases solution lengthalternative task K. introduce binary counter using dlog2 (K 2)e new binaryvariables Biti 0 sI . introduce operator bit, allowing setbit 1 lower bits already 1, effect setting lower bits backO. operator additional precondition (ChooseT ask, alt),effect modifying bits. modify operator oDistAlt adding newpreconditions encoding counter position K 2. construction, clearly h+ (sAlt ) > 1,distance goal sAlt K: plan count K 2, apply oDistAlt ,apply osG Alt . Thus, shortest exit path sI via oAlt length K + 1. then,above, ed(sI ) K iff (X, sI , sG , O) plan length K 1,concludes part claim.Finally, say need decide whether not, S, ed(s) K. Notefirst sAlt successors necessarily exit distance K (the goalreached many steps), exit distance sOrg successorsequal length shortest plan corresponding state (X, sI , sG , O).latter length may, states (X, sI , sG , O), longer K even shortestplan (X, sI , sG , O) (i.e., original initial state) length K. thus introduceanother binary counter, time counting K 1, conditioned (ChooseT ask, org),new operator whose precondition demands new counter K 1achieves goals. Then, clearly, sOrg descendants exit distanceK. Thus state may exit distance greater K s0I precisely,197fiHoffmanned(s0I ) = K + 1 iff new counter shortest plan sOrg , obviouslycase iff (X, sI , sG , O) plan length K 1. concludes argument.A.2 Analyzing Optimal Relaxed Plansneed fill notations. sake self-containedness section, firstre-state definitions given Section 5:Definition 1. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , letP + (s) optimal relaxed plan s, let x0 X, let o0 P + (s) operator takingrelevant transition form t0 = (s(x0 ), c).optimal rplan dependency graph P + (s), x0 o0 , optimal rplan dependencygraph P + (s) brief, graph oDG+ = (V, A) unique leaf vertex x0 ,x V (x, x0 ) either: x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x 6= x00+(s) taking relevant transition x0 x XpreoV \ {x0 } exists P<0preo (x) 6= s(x).x V \ {x0 }, oDT G+x denote sub-graph DT Gx includes+(s, x), relevant transitions using operatorvalues true point P<0+P<0 (s, x), least one relevant inverse relevant inverse exists.+(s, x) transitions original, inverse transitions induced.refer P<0Definition 2. Let (X, sI , sG , O), s, P + (s), x0 , t0 , oDG+ = (V, A) Definition 1.say oDG+ successful following holds:(1) oDG+ acyclic.(2) either:+(s)-recoverable;(a) oDG+ -relevant deletes t0 P>0+(b) s(x0 ) oDG -relevant, t0 replaceable side effect deletes;(c) s(x0 ) oDG+ -relevant, t0 recoverable side effect deletes.(3) x V \ {x0 }, oDT G+x transitions either self-irrelevant deletes,invertible/induced irrelevant side effect deletes side effects V \{x0 }.next define two general notions helpful state proofs.prevail condition prevo operator results restricting preoset variables Xpreo \ Xeff .Let x X, let (c, c0 ) transition DT Gx , let (y, d) seff(c, c0 ) sideeffect transition. context (y, d) (c, c0 ) ctx(c, c0 , y, d) :=((y, prerop(c,c0 ) (y))Xprerop(c,c0 ){(y, d0 ) | d0 Dy , d0 6= d} 6 Xprerop(c,c0 )context (c, c0 ) set ctx(c, c0 ) partial variable assignments that,every (y, d) seff(c, c0 ), X (y, (y)) ctx(c, c0 , y, d). identify ctx(c, c0 )set facts occur assignments.198fiAnalyzing Search Topology Without Running SearchNote definition ctx(c, c0 ) over-writes previous one Section 5,sense also distinguish possible tuples context values,rather collecting overall set. need fine-grained definitionprecisely formulate Definition 2 condition (2c), i.e., conditions transitionrecoverable side effect deletes. Namely, Definition 2 conditions (2b) (2c)formalized follows:transition (c, c0 ) replaceable side effect deletes iff ctx(c, c0 )sG = and, everyrop(c, c0 ) 6= preo ctx(c, c0 ) 6= exists o0 eff o0 = effpreo0 prevrop(c,c0 ) eff rop(c,c0 ) .transition (c, c0 ) recoverable side effect deletes iff following two conditionshold:Either (c, c0 ) irrelevant side effect deletes or, every ctx(c, c0 ),exists recoveringoperator preo prevrop(c,c0 ) eff rop(c,c0 ) eff ,eff (sG rop(c,c0 )6=o0 preo0 ).Every (y, d) seff(c, c0 ) goal appears operator preconditionpossibly recovering operators.t0 replaceable side effect deletes, upon execution remove o0relaxed plan operator relying deleted facts replaced. t0recoverable side effect deletes, then, due first clause definition, matterstate s0 apply t0 matter context holds s0recovering operator applicable t0 re-achieves relevant facts. Duesecond clause, delete facts relevant elsewhere relaxed plan (noteanything deleted must side effect t0 ).Finally, formally define notion used Definition 2 condition (2a) oDG+ +(s)-recoverable assume surroundings pertainingrelevant deletes t0 P>0Theorem 2, i.e., (X, sI , sG , O) planning task, state, P + (s) optimal relaxedplan s, oDG+ = (V, A) optimal rplan dependency graph leaf variable x0transition t0 = (s(x0 ), c) responsible operator o0 . considering state s0t0 executed, reaching state s1 , examining relaxed plan P1+ s1+constructed P + (s) removing o0 , replacing operators P<0(s)+operators responsible induced oDT Gx transitions x V \ {x0 }.C0 := {(x0 , s(x0 ))} ctx(t0 ) denote values potentially deleted t0 .R1+ denote union sG , precondition P + (s) operatoro0 , precondition operator responsible operatorinduced transition oDT G+x , x V \ {x0 }. discussed Section 5,super-set facts possibly needed P1+ .F0 := oP + (s) eff denote set facts true relaxed execution<0+P<0(s) s. discussed Section 5, p 6 F0 p needed s1 P1+relaxed plan.199fiHoffmannS1 denote union of: (1) prevo0 eff o0 ; (2) set facts (x, c)+exists x Xeff either o0 P<0(s) responsible+operator induced transition oDT Gx , x V \ {x0 }; (3) set F definedF := {(x, c) | (x, c) F0 , x V \ {x0 }} Xeff o0 (V \ {x0 }) = , else F := . Here,(1) (2) facts certain true s1 ; (3) setfacts able achieve start P1+ , appropriately re-orderingoperators.+ (s), relaxed-plan macro-precondition= ho1 , . . . , sub-sequencePSni1+defined pre:= i=1 (preoi \ j=1eff oj ). relaxed-plan macro-effectn+defined eff:= i=1 eff oi . empty sets default emptyset. notions simply capture outside needs effects relaxed plansub-sequence.++(s)-recoverable iff P>0(s) contains sub oDG+ -relevant deletes t0 P>0+++sequence o0 preeffCF.first conditionR1001o0o0ensures o0 applicable appropriate point within P1+ . secondo0 .clause ensures facts relevant P1+ re-achievedproceed exit path construction. follows, first considerpart path leading s0 , i.e., move non-leaf variables x V \{x0 }.show construct relaxed plans P + (s0 ) states s0 visited path.First, note assume P + (s) sorted according optimal rplandependency graph oDG+ = (V, A). Precisely, let xk , . . . , x1 topological orderingV \ {x0 } according arcs A. Due construction (V, A) per Definition 1,previous values never removed relaxed state space, re-order++(s, x1 ) P . is, perform moves(s, xk ) P<0P + (s) take form P<0+within oDT Gx front, order conforming A. henceforth assume,wlog, P + (s) form.+Recall follows original oDT G+x transitions taken P<0 (s),whereas induced oDT G+x transitions included inverse original transition. pathp invertible transitions traversing hc0 , . . . , cn i, inverse pathptraverses hcn , . . . , c0 replacing transition inverse. rop( p ) denoteoperator sequence responsible path.say state s0 invertible surroundings according oDG+ s0reachable executing sequenceresponsible operators invertible/induced+transitions oDT Gx x V \ {x0 }. adapted relaxed plan s0 , denotedP + (ss0 ), constructed follows. Let xk , . . . , x1 topological ordering V \ {x0 }according A, denote P + (s) = P + (s, xk ) P + (s, x1 ) P . Initialize P + (ss0 ) :=P + (s). Then, xi V \ {x0 }, letp path original invertible transitions+0oDT Gxi leading s(xi ) (xi ) clearly, path must exist. Remove rop(p )+0+0P (ss ), insert rop( p ) start P (ss , xi ).next show adapted relaxed plans indeed relaxed plans, restrictingconditions correspondence Definition 2 condition (3):Lemma 1. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) optimal rplan200fiAnalyzing Search Topology Without Running Searchdependency graph P + (s) where, every x V \ {x0 }, invertible/induced oDT G+xtransitions irrelevant side effect deletes side effects V \ {x0 }. Let s0state invertible surroundings according oDG+ . P + (ss0 ) relaxedplan s0 , |P + (ss0 )| |P + (s)|.++Proof. definition, know P + (s) takes form P<0(s, xk ) P<0(s, x1 ) P ,+++000P (ss ) takes form P<0 (s , xk ) P<0 (s , x1 ) P , xk , . . . , x0topological ordering V , P operator sequence common both,whose content important proof. simplicity, denote restproof P + (ss0 ) P + (s0 ), leave away < 0 subscripts.Consider first (relaxed) execution P + (s, xk ) P + (s0 , xk ). Sayp+ (s0 ), i.e., path original invertiblepath oDT G+considereddefinitionPxk0transitions oDT G+xi leading s(xk ) (xk ). Clearly, ho1 , . . . , := rop( p )sub-sequence P + (s, xk ). Sayp visits vertices s(xk ) = c0 , . . . , cn = s0 (xk ); denoteC := {c0 , . . . , cn }. Assume wlog P + (s, xk ) starts ho1 , . . . , notere-order P + (s, xk ) (and relaxed plans general) way want longviolate operator preconditions. latter case because: ho1 , . . . ,constitutes path oDT G+xk ; operators depending value Cordered occur later P + (s, xk ); because, since transitionsp sideeffects V \{x0 }, construction (V, A) per Definition 1 operators ho1 , . . . ,support way, P + (s), affecting variable xk .Given above, wlog P + (s, xk ) form ho1 , . . . , P1 . construction,+P (s0 , xk ) form rop(pS) P1 =: hn , . . . , o1 PS1 . Consider endpointsn++0prefixes, i.e., s1 := i=1 eff oi s2 := 1i=n effoi . Clearly, sincetransitionsp irrelevant side effect deletes, relevant partcontained s0 . then, far variables outside V \ {x0 , xk } concerned,+relevant part s+1 contained s2 : relevant side effects ho1 , . . . , already0contained ; values C obviously true s+2 ; induced transitions side+effects, increase fact set s2 . Further, sequence hn , . . . , o1applicable relaxation. see this, note first preconditions xksatisfied definition, hn , . . . , o1 constitutes path DT Gxk . side effects,occur, harmful old values over-written relaxation.preconditions variables, due invertibility outside conditionsoi contained oi subset ho1 , . . . , i. Hence, Definition 1since xk incoming edges oDG+ , preconditions satisfied s.also satisfied s0 (vk root oDG+ ) variables xcontained V hence s0 (x) = s(x) prerequisite note precondition factscannot deleted side effects whose deletes irrelevant prerequisite.shown relevant part outcome relaxed executionP + (s, xk ) contained outcome relaxed execution P + (s0 , xk ) s0 ,variables outside V \ {x0 , xk }. iterate argument. Assume inductionhypothesis already shown relevant part outcome relaxedexecution P + (s, xk ) . . . P + (s, xi+1 ) contained outcome relaxed executionP + (s0 , xk ) P + (s0 , xi+1 ) s0 , variables outside V \ {x0 , xk , . . . , xi+1 }.consider P + (s, xi ) P + (s0 , xi ). thing changes respect xkmay preconditions variables xj true s; j >201fiHoffmannpreconditions must belong predecessors xi oDG+ Definition 1.Since P + (s) = P + (s, xk ) P + (s, x1 ) P relaxed plan s, conditionsestablished relaxed execution P + (s, xk ) P + (s, xi+1 ) s. Given this,induction hypothesis conditions clearly irrelevant established alsorelaxed execution P + (s0 , xk ) P + (s0 , xi+1 ) s0 , concludes argumentinductive case. = 1, follows relevant part outcome relaxedexecution P + (s, xk ) P + (s, x1 ) contained (on variables) outcomerelaxed execution P + (s0 , xk ) P + (s0 , x1 ) s0 . this, claim follows triviallyP + (s) relaxed plan s, remainder P operator sequencesidentical.second part claim follows because, 6= j, originaltransitions use xi respectively xj operators common. because,argued above, relevant operators side effects V \ {x0 }. Sinceoperators affects variable xi , cannot affect variable V \ {x0 }. Thus,inverse transition introduce via inverse operator, P + (s) contains separateoperator. this, obviously get |P + (ss0 )| |P + (s)|.Lemma 1 captures second case Definition 2 condition (3), transitionsinvertible/induced irrelevant side effect deletes side effects V \ {x0 }.next lemma captures first case Definition 2 condition (3):Lemma 2. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) optimal rplandependency graph P + (s) where, every x V \ {x0 }, invertible/induced oDT G+xtransitions irrelevant side effect deletes side effects V \ {x0 }. Let s0state invertible surroundings according oDG+ . Let s00 state reacheds0 P + (ss0 , x) operator constituting transition (c, c0 ) x V , s0 (x) = c,self-irrelevant deletes. removing P + (ss0 ) yields relaxed plans00 .Proof. Lemma 1, P + (ss0 ) relaxed plan s0 . Now, upon execution o, s00 ,effects true, i.e., (x, c0 ) side effects (if present). hand,obviously facts (z, e) true s0 s00 ctx(c, c0 ){(x, c)}. Since,prerequisite, transition (c, c0 ) self-irrelevant deletes, facts ctx(c, c0 ){(x, c)}either irrelevant rop(c, c0 )-only relevant, meaning goal occuroperator precondition than, possibly, itself. claim follows directlythat.remark much easily formulated, general, version Lemma 2could proved simply associating notion self-irrelevant deletes operatorsrather transitions, postulating used P + (s). argumentcorresponds part (A) proof Lemma 3 authors previous work (Hoffmann,2005). state argument particular form since formneed below.almost ready prove main lemma behind exit path construction.need one last notation, capturing simpler form cost function costd (oDG+ )202fiAnalyzing Search Topology Without Running Searchconsidered Section 5. simpler function make use shortcut construction;Pthat construction introduced separately below. definecostd (oDG+ ) := xV costd (x), costd (x) :=(1x = x0P+0diam(oDT Gx ) x0 :(x,x0 )A cost (x ) x 6= x0Lemma 3. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) successfuloptimal rplan dependency graph P + (s). exists operator sequencethat:(I)constitutes monotone path state s1 h+ (s) > h+ (s1 ).(II) lengthcostd (oDG+ ) Definition 2 condition (2a)(2b), costd (oDG+ ) + 1 Definition 2 condition (2c).Proof. Let xk , . . . , x1 topological ordering V \{x0 } according arcs A. Considerstate s0 every x V \ {x0 } s0 (x) vertex oDT G+x ,every variable x outside V \ {x0 } s0 (x) = s(x) unless s(x) irrelevant. Saypreo0 s0 . Note first state s0 exists. definition, eitherpreo0 (x0 ) undefined preo0 (x0 ) = s(x0 ) = s0 (x0 ). (Note every variablex outside V \ {x0 } s0 (x) = s(x) unless s(x) irrelevant covers alsocase transition V \ {x0 } side effect x0 , whose delete mustprerequisite irrelevant thus either side effect x0 := s(x0 ) o0 actuallypreconditioned x0 .) Definition 1 P + (s) relaxed plan s,variable x Xpreo contained V unless preo0 (x) = s(x). reasons,0+construction oDT G+x , preo0 (x) vertex oDT Gx .Now, consider state s1 results applying o0 s0 . first considersituation s0 invertible surroundings according oDG+ ; oppositecase discussed below. apply Lemma 1 s0 , hence relaxed+(s, x), xplan P + (ss0 ) s0 results replacing, P + (s), moves P<0+++0V \ {x0 }, inverses. particular, h (s) h (s0 ), P (ss0 , x ) = P + (s, x0 )x0 6 V . relaxed plan s1 ? distinguish Definition 2 condition (2)cases (a), (b), (c).+case (a), definition P>0(s) contains sub-sequenceo0 pre+o0+++S1 effR1 C0 F0 . implies remove o0 P (s s0 )o0obtain relaxed plan P1+ s1 , thus getting h+ (s) > h+ (s1 ). precisely, constructP1+ by: removing o0 P + (ss0 ); Xeff o0 (V \ {x0 }) 6= movingo0 occur++start P1 ; Xeff o0 (V \ {x0 }) = moving o0 occur start P>0(s)+(which unchanged P (ss0 )).Observe first o0 P + (s s0 )o0 sub-sequence P + (s s0 ) sinceadaptation pertains exclusively operators precede o0 P + (s). Second, coursevalues established o0 true s1 .Third,o0 applicable (in relaxation) assigned point P1+ . see this,consider first case Xeff o0 (V \ {x0 }) 6= . Then, definition S1 , pre+0203fiHoffmanncontained (prevo0 eff o0 ) set facts (x, c) exists+x Xeff either o0 P<0(s) responsible operator inverse+0transition taken operator P<0(s). facts true s1 .obvious prevo0 eff o0 follows facts truecannot affected operator path s1 . Consider caseXeff o0 (V \ {x0 }) = . definition S1 , pre+contained previous sets facts,o0plus {(x, c) | (x, c) F0 , x V \ {x0 }}. latter facts, far relevant, truestarto0 P1+ . execution o0 affect execution+P (ss0 ), thus P1+ , point. then, argued Lemma 1,outcome execution s0 contains, variables V \ {x0 },+relevant part outcome P<0(s) is, relevant part F0 . Since o0affect variables, true s1 , concludes point.Finally, consider facts (z, e) true s0 s1 , mayneeded P1+ behindo0 , i.e., either goal preconditionoperators. Observe that, since inverse operators performed transitionsvariables V \ {x0 }, since include new outside preconditions,(z, e) contained R1+ .24 Now, say first (z, e) F0 . Then, above,(z, e) (ctx(s(x0 ), c){(x0 , s(x0 ))})F0 R1+ thus (z, e) eff +prerequisiteo0+(s) else,done. (z, e) 6 F0 ? Note that, then, (z, e) 6 preo P<0+precondition would true relaxed execution P (s) thus P + (s) would+(s), thus (z, e) neededrelaxed plan. Neither (z, e) added P<0+precondition inverse operator used P (s s0 ) operatorsintroduce new outside preconditions, course use own-preconditions previouslyadded operators affecting respective variable. Thus reason (z, e)+could needed P1+ either (z, e) sG (z, e) preo P>0(s).+(z, e) sG certainly, since P (s) relaxed plan, achieved operatorP + (s). cannot = o0 since effect o0 true s1 , cannot++(s), thus contained P1+(s) since (z, e) 6 F0 . Thus P>0P<0+(s), arguments apply, i.e., mustdone. (z, e) preo0 o0 P>0+0P>0 (s), ordered , adds (z, e). concludes proof case (a).Consider case (b), s(x0 ) 6 R1+ , transition (s(x0 ), c) replaceableside effect deletes, i.e., ctx(s(x0 ), c) sG = and, every o0 6= preoctx(s(x0 ), c) 6= exists o0 eff o0 = eff preo0 prevo0 eff o0 .obtain relaxed plan P1+ removing o0 P + (s s0 ), replacingoperators respective o0 needed. Precisely, say (z, e) true s0s1 . z = x0 e = s(x0 ) needed P1+ construction. every z,must (z, e) ctx(s(x0 ), c). (z, e) goal prerequisite. operatorP1+ (z, e) precondition, replace postulated operator o1obviously applicable s1 effect. concludes case.Consider last case (c), definition s(x0 ) 6 R1+ , transition (s(x0 ), c)recoverable side effect deletes. Here, guarantee decrease h+ obtained s124. Note particular special case inverse transitions non-leaf variables x, mayprecondition x added by, needed prerequisite of, operators P + (s, x).preconditions preconditions may needed P + (ss0 ) thus P1+ ,P + (s). reason include facts definition R1+ .204fiAnalyzing Search Topology Without Running Searchitself, successor state s2 s1 . Namely, let o0 operator recovering relevantside effect deletes (s(x0 ), c). Precisely, let ctx(s(x0 ), c) s0 (such existsdefinition ctx(s(x0 ), c)). Then,let o0 operator preo0 (prevo0 eff o0 )eff o0 , eff o0 (sG o0 6=o0 preo0 ) (such operator exists case (b)). Sayobtain P1+ replacing, P + (ss0 ), o0 o0 . P1+ relaxed plans1 . see this, note first o0 applicable s1 virtue preo0 (prevo0 eff o0 ).Further, note values deleted o0 plus (x0 , s0 (x0 )). Sinces0 (x0 ) = s(x0 ), s(x0 ) 6 R1+ know s0 (x0 ) 6SR1+ thus deleteconsequence. , virtue eff o0 (sG o0 6=o0 preo0 ) facts couldpossibly relevant re-achieved o0 . Finally, values established o0 trues1 .Now, say obtain s2 applying o0 s1 . removing o0 P1+ yields relaxedplan s2 . simply established effects true s2 , virtueeff o0 facts deletes side-effects transition (s(x0 ), c). case (c),relevant anything except possibly recovering operators. recoveringoperator o0 removed P1+ . recoveringoperatorscould still contained P1+ , since eff eff o0 (sG o0 6=o0 preo0 ),relevant facts could possibly achieve already true s2 thus removewell. Hence, overall, h+ (s) > h+ (s2 ).cases (a) (b) prove (I) constructing monotone path s1 , case (c)true s2 . (Of course, also show (II), constructing pathspecified length; ignore issue moment.) difficultyconstructing path achieving preconditions o0 . preconditions maysatisfied s, need reach state s0 satisfied. needwithout ever increasing value h+ . Note that, decrease value h+ somewherealong way, already reached exit monotone path, done. Thusfollows show upper bound h+ (s). Lemma 1, boundingaccomplished starting s, always taking oDT G+x transitions variablesx V pertaining second case Definition 2 condition (3), i.e., transitionsinvertible/induced irrelevant side effect deletes side effects V \ {x0 }.follows will, brevity, refer transitions case2. Note that,way, reach states invertible surroundings according oDG+ .operator sequence, Lemma 1 know h+ (s) h+ (s0 ) states0along way. Now, cannot reach s0 using sequence, i.e.,0would take non-case2 oDT G+x transition (c, c ) variable x, states0 ? prerequisite know transition (c, c0 ) self-irrelevant deletes. applyLemma 2 because: s0 invertible surroundings according oDG+ ; sincefollowing transition path, clearly s0 (x) = c, i.e., value relevant variable s0start value last transition taking; construction, P + (ss0 ) changesP + (s) case2 transitions, thus responsible operator rop(c, c0 ) (whichcase2) guaranteed contained P + (ss0 ). Note rop(c, c0 ) cannotused case2 transitions V \ {x0 } variable might takenpath s0 , prerequisite transitions side effects V \ {x0 },contradiction constituting transition variable x hand. Thus knowh+ (s) > h+ (s0 ) already constructed desired monotone path exit205fiHoffmannstop. Else, reach s0 sequence, above,ho0(respectively ho0 , o0 i, case (c)) constitutes desired path.remains show exactly construct operator sequence. Considertopological ordering V , xk , . . . , x1 . follows, consider depth indices k0, say variable x V depth d, written depth(x) = d, iff x = xd .characterizes d-abstracted planning task identical original planningtask except (and only) outside preconditions, oDT G+x transitionsvariables x depth(x) d, removed pertain values variables x0depth(x0 ) > d. prove induction that:(*) d-abstracted task, exists operator sequencethat:(a) either (1)ho0 execution path applicable s, (2)execution path0applicable s, last transition (c, c ) variable x takenrelevant,self-irrelevant deletes, responsible operator contained adapted relaxedplan state s0 applied to, s0 (x) = c;(b), except last step case (2) (a), uses case2 oDT G+x transitionsvariables x 1 depth(x) d;(c) number operatorsho0 pertaining x V costd (x).desired pathresults setting := k. see this, note kabstracted planning task identical original planning task. claim followsdiscussion above: (a) (b) together mean h+ decreases monotonically+P less dthan h (s) end. Given (c), length boundedxV,depth(x)d cost (x). proves claim adding trivial observation that,Definition 2 condition (2) case (c) discussed above, need add oneadditional operator end path.give proof (*). base case, = 0, trivial. set0 empty.construction (V, A) per Definition 1, construction 0-abstractedtask, outside preconditions o0 either true removed. (a)(case (1)), (b), (c) obvious.Inductive case, + 1. Exploiting induction hypothesis, letoperatorsequence per (*). turn requested sequence d+1 + 1abstracted planning task.remainder proof, consider oDT G+x , x V \ {x0 },contain also irrelevant transitions, i.e., omit restriction Definition 1.simplify argumentation show, oDT G+x paths considercontain irrelevant transitions, hence contained actual oDT G+x perDefinition 1.Let first operatorho0 i. may applicable s, +1-abstracted planning task. reason that, however, may preconditionremoved d-abstracted planning task removed + 1abstracted planning task. construction, precondition must pertain xd+1 . Sayprecondition (xd+1 , c). induction hypothesis, know contained+P<0(s), responsible inverse transition operator. cases, sinceinverse transitions introduce new outside preconditions, (xd+1 , c) precondition206fiAnalyzing Search Topology Without Running Search+operator P<0(s). Thus c vertex oDT G+xd+1 trivial (xd+1 , c) true(which actually cannot case else would applicable+ 1-abstracted planning task), (xd+1 , c) true follows P + (s)relaxed plan must thus achieve (xd+1 , c) needed precondition.+Hence, P<0(s, xd+1 ) must contain shortest pathq oDT G+xd+1 s(xd+1 ) c.transitions path irrelevant. see this, note first endpointoperator precondition construction, thus last transition (c1 , c) irrelevant.then, neither previous transition, (c2 , c1 ): was, (xd+1 , c1 ) would+operator precondition; then, rop(c1 , c) contained P<0(s) construction+would also constitute transition (c2 , c) oDT Gxd+1 thusq wouldshortest path contradiction. Iterating argument, q contain irrelevanttransitions. Thus, since depth(xd+1 ) = + 1, Definition 1 (which includes nonsatisfied preconditions relevant transitions) construction + 1-abstractedplanning task, outside preconditions used rop(q ) either trueremoved. Hence execute rop( q ). either reached endsequence, last transition taken oDT G+xd+1 case2, henceself-irrelevant deletes prerequisite. latter case, since following pathsince discussed adapted relaxed plan exchanges operators pertainingcase2 transitions thus last one executed, clearly attained (a)case (2) stop part rop(q ) executed is, own, operatorsequenced+1 desired. former case, reach state s0 s0 (xd+1 ) = c (andnothing else relevance deleted, due non-existence relevant side-effectdeletes). s0 , applied, leading state s00 .Let o0 second operatorho i. Like above, o0 applicable s00 ,0reason may unsatisfied precondition form (xd+1 , c0 ). Like above,+(s), hence c0 vertex oDT G+o0 inverse contained P<0xd+1 . Likewise,00+(xd+1 ) = c vertex oDT Gxd+1 . Now, yet used non-case2transition oDT G+xd+1 , else wouldnt get here. means stillinvertible surroundings around s(xd+1 ) oDT G+xd+1 . Clearly, implies+0exists path oDT Gxd+1 c c (we could simply go back s(xd+1 ) movec0 there). Taking shortest pathq , clearly path length bounded+diameter oDT Gxd+1 . path contain irrelevant transitionsendpoint c0 selected operator precondition, valuespart shortest path oDT G+xd+1 , thus argument given applies.Thus outside preconditions used operators constitutingq either trueremoved follows construction (V, A) per Definition 1+construction + 1-abstracted planning task operators P<0(s), followsinverses thereof inverse operators introduce new outside preconditions. Henceexecuteq s00 . either reached end path,last transition taken case2, hence self-irrelevant deletes prerequisite.Consider latter case. state s0 last transition reachedcase2 transitions, since transition oDT G+xd+1 case2, responsible+operator must contained P (s) adapted relaxed plan P + (ss0 )s0 recall that, pointed above, since case2 transitions postulated207fiHoffmannside effects V \{x0 }, responsible operator cannot used them. Further,clearly since following path transitions, value xd+1 s0start value transition. Hence attained (a) case (2) stop.former case, reached state o0 applied (and nothing relevancedeleted, due postulated non-existence relevant side-effect deletes, case2transitions). Iterating argument, get state last operatorho0applied, induction hypothesis reaching state s1 desired (a) case (1).Properties (a) (b) clear construction. property (c), supportoperatorho0 i, clearly apply diam(oDT G+xd+1 ) operatorspertaining xd+1 (or stop sequence earlier that). Note that,operatorsho0 unsatisfied preconditions xd+1 above, pertainsvariable x (xd+1 , x) A. consequence construction (V, A)per Definition 1, fact inverse transitions introduce new outsidepreconditions. Thus, comparisonho0 i, overall executeXdiam(oDT G+k(x)xd+1 )x:(xd+1 ,x)Aadditional operatorsd+1 ho0 i, k(x) number operatorsho0pertaining variable x. induction hypothesis, property (c) (*), k(x)costd (x), x depth(x) < + 1, thus x (xd+1 , x) A. Henceget, newly inserted steps affecting xd+1 , upper boundXdiam(oDT G+)costd (x)xd+1x:(xd+1 ,x)Aidentical costd (xd+1 ). concludes argument.next note improve exit distance bound case insistmonotone exit paths:Lemma 4. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) < ,let P + (s) optimal relaxed plan s. Say oDG+ = (V, A) successfuloptimal rplan dependency graph P + (s). Let V V \ {x0 } that, every x V ,oDT G+x transitions invertible/induced irrelevant side effect deletesside effects V \{x0 }, DT Gx transitions either irrelevant, emptyconditions irrelevant side effect deletes. exists operator sequencethat:(I)constitutes path state s1 h+ (s) > h+ (s1 ).(II) lengthcostd (oDG+ ) Definition 2 condition (2a)(2b), costd (oDG+ ) + 1 Definition 2 condition (2c).Proof. simple adaptation Lemma 3, adopt follows terminology proof lemma. thing changes bound imposedexit path length sharper, insist path monotone.level proof mechanics, happens that, whenever xd+1 V , choose208fiAnalyzing Search Topology Without Running Searchpathq achieve next open precondition operator already chosen participateho0 i, restrict paths within oDT G+xd+1 , allow alsoshortest path DT Gxd+1 . shortest path DT Gxd+1 value occursoperator precondition,q contains irrelevant transitions (same argumentproof Lemma 3). Further,q executable prerequisite alternative(non-oDT G+)transitionsoutside conditions; original/induced transitions,xprecondition achievement works exactly before. Note important propertyopen preconditions achieved xd+1 ever pertain values containedoDT G+xd+1 . trivial see induction alternative transitionsoutside preconditions. Since prerequisite deletes alternative transitionsirrelevant, executing harm need minor extension Lemma 1,allowing s0 identical state s00 invertible surroundings s, moduloset irrelevant values hold s00 s; obvious extensionvalid. extension, also obvious arguments pertaining s0 s1remain valid. Finally, consider caseq involves non-case2 oDT G+xd+1 transition.state transition applied invertible surroundings s.holds x 6 V construction remains same. holdsx V because, first, alternative transitions outside conditions, hence causehigher-depth transitions inserted between, hence value lower-depth+variables x oDT G+x ; second, prerequisite, oDT Gx contain non-case2transitions, thus value x clearly reached case2 transitions.Theorem 2. Let (X, sI , sG , O), s, P + (s), oDG+ Definition 1. oDG+ successful, local minimum, ed(s) costd (oDG+ ). Definition 2condition (2a) (2b), ed(s) costd (oDG+ ) 1.Proof. direct consequence Lemmas 3 4.note prerequisites Lemma 4 could weakened allowing, x V ,outside conditions already true s. extension obviously breakproof arguments. omitted make lemma prerequisite evenawkward already is.indicated, exit path constructed Lemma 4 necessarily monotone. Example 5 Appendix A.4 contains construction showing this.A.3 Conservative Approximationssake self-containedness section, re-state definitions given Section 6:Definition 3. Let (X, sI , sG , O) planning task, let 0 < h+ (s) < , letx0 XsG , let t0 = (s(x0 ), c) relevant transition DT Gx0 o0 := rop(t0 ).local dependency graph s, x0 , o0 , local dependency graph brief,graph lDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:x0 = x0 , x Xpreo , preo0 (x) 6= s(x); x0 V \ {x0 } (x, x0 ) arc SG.0209fiHoffmannglobal dependency graph x0 o0 , global dependency graph brief,graph gDG = (V, A) unique leaf vertex x0 , x V (x, x0 ) either:x0 = x0 x0 6= x Xpreo ; x0 V \ {x0 } (x, x0 ) arc SG.0Definition 4. Let (X, sI , sG , O), s, t0 , o0 , G = lDG G = gDG Definition 3.say G = (V, A) successful following holds:(1) G acyclic.(2) G = lDG sG (x0 ) 6= s(x0 ), exists transitive successor x0 x0SG x0 XsG sG (x0 ) 6= s(x0 ).(3) t0 either:(a) self-irrelevant side effect deletes;(b) replaceable side effect deletes;(c) recoverable side effect deletes.(4) x V \ {x0 }, DT Gx transitions either irrelevant, self-irrelevantdeletes, invertible irrelevant side effect deletes side effectsV \ {x0 }.Lemma 5. Let (X, sI , sG , O) planning task, let state 0 < h+ (s) <. Say x0 X and, every o0 = rop(s(x0 ), c) DT Gx0 t0 = (s(x0 ), c)relevant, lDGo0 successful local dependency graph s, x0 , o0 . Then, leastone o0 , exist optimal relaxed plan P + (s) s, successful optimal rplandependency graph oDG+ P + (s), x0 , o0 , oDG+ sub-graph lDGo0 .Proof. Observe first Definition 4 property (2) forces relaxed plan P + (s) movex0 , i.e., P + (s, x0 ) non-empty. particular, P + (s, x0 ) takes pathDT Gx0 s(x0 ) sG (x0 ). Letq shortest path taken P + (s, x0 ), leto0 responsible operator first transitionq . Clearly, transitionform (s(x0 ), c), i.e., o0 one operators o0 claim. Lying shortest paths(x0 ) sG (x0 ) sub-graph DT Gx0 taken P + (s, x0 ), transition (s(x0 ), c)irrelevant. seen exactly argument given proofLemma 3 transitions pathsq constructed there, except endpointgoal instead operator precondition.Next, observe optimal P + (s) contains one operator x0 Xpreopreo (x0 ) = s(x0 ). also follows Definition 4 property (2): x0 cannot become important non-achieved goal, i.e., P + (s) operator outside P + (s, x0 ) relies precondition x0 . see this, assume operator exist.Then, since P + (s) optimal, exists reason inclusion o. Precisely,must achieve least one fact needed terms Hoffmann Nebel(2001b): fact either goal precondition another operator o0behind P + (s). Iterating argument o0 (if necessary), obtain sequence= o1 , (x1 , c1 ), o2 , (x2 , c2 ), . . . , , (xn , cn ) (xn , cn ) goal fact satisfiedoi achieves (xi , ci ) P + (s). Obviously, SG contains path x0 xn ,xn XsG sG (xn ) 6= s(xn ), contradiction Definition 4 property (2). Thusexist. argument, follows also every operator P + (s, x0 )210fiAnalyzing Search Topology Without Running Searcheither side effect used elsewhere relaxed plan, precondition x0 .Thus operators P + (s, x0 ) preconditioned x0 serve transforms(x0 ) sG (x0 ). course, then, single one operators relies s(x0 )else P + (s) optimal.Say follows lDGo0 = (V, A). Denote (V 0 , A0 ) result backchaining+Definition 1 o0 P<0(s). Definition 3 include variables arcs includedDefinition 1. see this, note arcs (x, x0 ) included Definition 1 duerelevant transitions. Hence (V 0 , A0 ) sub-graph (V, A). particular, since (V, A)acyclic, (V 0 , A0 ) acyclic well.next observation that, assuming Definition 4 condition (2) holds true, Definition 4 condition (3a) implies Definition 2 condition (2a), Definition 4 condition (3b) impliesDefinition 2 condition (2b), Definition 4 condition (3c) implies Definition 2 condition(2c).Consider first case (a) t0 self-irrelevant side effect deletes. show+R1 C0 = . Recall notations Appendix A.2 C0 = {(x0 , s(x0 ))} ctx(t0 ),R1+ super-set set facts need relaxed plan removing o0 .variables except x0 , clear fact intersection: factsctx(t0 ) irrelevant o0 -only relevant prerequisite, thus contained R1+ .Hence, (x0 , s(x0 )) remains possible content R1+ C0 . show follows(x0 , s(x0 )) 6 R1+ , thus (x0 , s(x0 )) 6 R1+ C0 latter intersection empty,desired. Recall R1+ denotes union sG , precondition o0 6= P + (s),precondition operator responsible operator inducedtransition oDT G+x , x V \ {x0 }. Definition 4 condition (2), (x0 , s(x0 )) 6 sG .argued above, o0 operator P + (s) may preconditioned s(x0 )thus precondition o0 6= P + (s). Lastly, say p preconditionresponsible operator induced transition oDT G+x , corresponding originaltransition t. Then, since inverse transitions introduce new conditions,+(s). then, sincep cond(t) thus p prerop(t) where, definition, rop(t) P<0+o0 6= rop(t) P (s), (x0 , s(x0 )) 6 prerop(t) , implies p 6= (x0 , s(x0 )).Thus (x0 , s(x0 )) 6 R1+ like needed show.Consider case (b) t0 recoverable side effect deletes. show Definition 2condition (2b) o0 = rop(t0 ), need prove s(x0 ) oDG+ -relevant,i.e., s(x0 ) 6 R1+ . already shown above.case (c), t0 replaceable side effect deletes. Again, show Definition 2 condition(2c) t0 ), need prove s(x0 ) oDG+ -relevant.Consider finally conditions imposed non-leaf variables x V \ {x0 }, i.e., Definition 4 condition (4) Definition 2 condition (3). Definition 4 condition (4),DT Gx transitions every x V \ {x0 } either irrelevant, self-irrelevant deletes,invertible irrelevant side effect deletes side effects V \ {x0 }.DT Gx transitions irrelevant cannot oDT G+x , thus 2nd 3rd case+0true oDT Gx transitions every x V \ {x0 }. concludes argument.Theorem 3. Let (X, sI , sG , O) planning task, let state 0 <h+ (s) < . Say x0 X that, every o0 = rop(s(x0 ), c) DT Gx0(s(x0 ), c) relevant, lDGo0 successful local dependency graph. local211fiHoffmannminimum, ed(s) maxo0 costD (lDGo0 ). If, every lDGo0 , Definition 4condition (3a) (3b), ed(s) maxo0 costD (lDGo0 ) 1.Proof. Lemma 5, choice o0 = rop(s(x0 ), c) exists optimal relaxedplan P + (s) successful optimal rplan dependency graph oDG+ = (V 0 , A0 ) P + (s),oDG+ sub-graph lDGo0 unique leaf vertex x0 . applyLemma 3 obtain local minimum.see part claim, let V defined Section 6, i.e., V subsetV \ {x0 } DT Gx transitions either irrelevant, invertibleempty conditions, irrelevant side effect deletes, side effects V \ {x0 }. Then,DT Gx transition x V , satisfies restriction required Lemma 4+oDT G+x transitions irrelevant, cannot oDT Gx , else invertibleirrelevant side effect deletes side effects V \ {x0 } restrictionrequired Lemma 4 transitions either irrelevant, empty conditionsirrelevant side effect deletes. hence apply Lemma 4 oDG+ , obtain (notnecessarily monotone) path exit, length bound costd (oDG+ ) (s(x0 ), c)irrelevant side effect deletes replaceable side effect deletes, costd (oDG+ ) + 1(s(x0 ), c) recoverable side effect deletes. thus suffices show costD (lDGo0 )costd (oDG+ ). That, however, obvious V V 0 , costD (x) 0 x,0maxPath(DT Gx ) diam(oDT G+x ) x V .Theorem 4. Let (X, sI , sG , O) planning task. Say global dependency graphsgDG successful. contain local minima and, state0 < h+ (s) < , ed(s) maxgDG costD (gDG). If, every gDG, Definition 4condition (3a) (3b), ed(s) maxgDG costD (gDG) 1.Proof. Let state. need prove local minimum. h+ (s) = 0h+ (s) = , nothing show. Else, assume variables X topologicallyordered according strongly connected components SG, let x0 Xuppermost variable x0 XsG sG (x0 ) 6= s(x0 ); obviously, x0 exists. Clearly,chance x0 satisfy Definition 4 condition (2) exists transitivesuccessor x0 x0 SG x0 XsG sG (x0 ) 6= s(x0 ) exists x0strongly connected SG component, x0 XsG (and sG (x0 ) 6= s(x0 )).then, exists transition t0 DT Gx0 outside condition eventually leading,backwards chaining SG, x0 . Let gDG0 global dependency graph x0rop(t0 ) (such gDG0 exists x0 XsG ). Since Definition 3 includes transitiveSG-predecessors x0 pertaining conditions t0 , gDG0 includes x0 . then, sincex0 x0 lie strongly connected component, Definition 3 eventually reachesx0 . Thus gDG0 contains cycle, contradiction prerequisite. followsstrongly connected SG component x0 contains x0 , thus Definition 4 condition(2) holds true.Now, say o0 responsible relevant transition form (s(x0 ), c) DT Gx0 .exists local dependency graph lDG s, x0 , o0 lDG sub-graphgDG. follows simple observation Definition 3 include, gDG,variables arcs include lDG. (Note precondition o0212fiAnalyzing Search Topology Without Running Searchx0 , present, satisfied o0 = rop(s(x0 ), c), thus Definition 3include x0 predecessor achieving o0 preconditions lDG.)Obviously, given above, lDG successful. Since works choice notirrelevant (s(x0 ), c), apply Theorem 3. claim follows directlyfact costD (gDG) costD (lDG). latter obvious costD increasesmonotonically adding additional variables.A.4 Example Constructionsfirst example shows that, even within scope basic result, operatorsnecessarily respected relaxation, i.e., operator may start optimal real plan yetoccur optimal relaxed plan.Example 1. Consider planning task Figure 4. Variables shown (in dark green)left hand side respective DTG. Circles represent variable values, linesrepresent DTG transitions. Transitions condition longer lines, conditioninscribed line (in blue). variable, dashed arrow indicates valueinitial state sI . goal value defined, indicated circled value.needed, refer operators responsible transition terms respectivevariable followed indices start end value. example, operator movingx c1 c2 referred x12. abbreviate states {(x, c), (y, d)} (c, d).stick conventions throughout section.xd1c1c2d3c3d7d1d2d3d7Figure 4: Planning task underlying Example 1.shown Figure 4, DTG x consists three vertices whose connection requiresconditions d1 d3 , alternatively d7 shortcut. domain linelength 6 requiring conditions.Clearly, support graph planning task acyclic, transitions DTGsside effects invertible. However, operator y34 (for example) respectedrelaxation. see this, note first h+ (sI ) = 4: optimal relaxed planhy32, y21, x12, x23i relaxed plan ignores need move back d3 operator x23. hand, optimal (real) plan sI hy34, y45, y56, y67, x17i.choose use y32 instead, like optimal relaxed plan does, endsequence hy32, y21, x12, y12, y23, x23i 1 step longer. Hence, sI , y34 startsoptimal plan, start optimal relaxed plan.213fiHoffmannnext give three examples showing local minima arise simple situations generalizing basic result minimally. consider, order: cyclic supportgraphs; non-invertible transitions; transitions side effects.Example 2. Consider planning task Figure 5.xc1d1c2d1d2dn1dnc1Figure 5: Planning task underlying Example 2.DTG x two vertices whose connection requires condition d1 .domain line length n requiring conditions, shortcut d1dn requires c1 condition. Clearly, transitions DTGs side effectsinvertible. However, SG contains cycle x mutuallydepend other. show mutual dependence causes initial statesI = {(x, c1 ), (y, d1 )} local minimum, n 5. abbreviate, before, states{(x, c), (y, d)} (c, d). h+ (sI ) = 2: optimal relaxed plan hx12, y1ni.consider operators applicable sI = (c1 , d1 ):Execute x12, leading s1 = (c2 , d1 ) h+ (s1 ) = 2 due hx21, y1ni. here,new state reached via y12, giving s2 = (c2 , d2 ) h+ (s2 ) = 3 duehy21, x21, y1ni. (Note n 2 3 prerequisite, relaxed plan composedyi(i + 1) operators also 3 steps.) h+ (s2 ) > h+ (sI ) waycannot reach exit monotone path.Execute y12, leading s3 = (c1 , d2 ) h+ (s3 ) = 3 due hy21, x12, y1ni. (Noten 2 3 prerequisite, relaxed plan moving ypp operators4 steps.) Again, path monotone.Execute y1n, leading s4 = (c1 , dn ) h+ (s4 ) = 2 due hyn1, x12i. here,new state reached via yn(n1), giving s5 = (c1 , dn1 ) h+ (s5 ) = 3due hy(n1)n, yn1, x12i. (Note n2 3 prerequisite, relaxed planmoving d1 via dn2 , . . . , d2 3 + 2 steps.) Again, path monotone.operators applicable sI , thus explored states reachable sImonotone paths. None states exit, proving sI local minimum (ass1 s4 ). is, fact, single state h+ (s) = 1, namely = (c2 , dn1 ).Clearly, reaching sI takes n 1 steps: first apply x12, traverse d2 , . . . , dn2 .exit distance sI n 3, thus distance unbounded.214fiAnalyzing Search Topology Without Running SearchSection 9, following modification Example 2 considered. set n := 2, i.e.,domain reduced two values d1 , d2 ; remove line d2 , . . . , dn2 ,i.e., move via previously short-cut. modified example fallsSAS+ -PUBS tractable class identified Backstrom Klein (1991), stillcontains local minimum (the example unsolvable, though).Example 3. Consider planning task Figure 6.xc1d2c2d1c3d1d2dnFigure 6: Planning task underlying Example 3. arrow d1 d2 indicatesrespective DTG transition directed, i.e., exists transition d2d1 .DTG x three vertices whose connection requires (starting initial valuec1 ) first condition d2 , condition d1 . domain circle length n requiringconditions, invertible except arc d1 d2 .Clearly, support graph acyclic transitions DTGs side effects.However, non-invertible arc d1 d2 causes initial state sI = (c1 , d1 )local minimum n 3. easy see. h+ (sI ) = 3 dueoptimal relaxed plan hy12, x12, x23i. Note relaxed planmove back (y, d1 ) still true executing y12. Now, operators applicablesI y12 y1n. latter, reaching state sn = (c1 , dn ), immediately increasesvalue h+ . because, n 3, y1n get closer d2 , movingfarther away d1 (both need achieved). shortest relaxed snhyn1, y12, x12, x23i. Alternatively, say apply y12 sI , reaching state s2 = (c1 , d2 ).h+ (s2 ) = n + 1: need apply, relaxation, x12, n 1 steps completecircle d2 back d1 , x23. Thus, n 3, s2 larger h+ value sI .follows sI local minimum. nearest exit sI sn1 = (c2 , dn1 ): sn1relaxed plan hy(n 1)n, yn1, x23i length 3, applying y(n 1)n get h+value 2. Reaching sn1 sI takes 1 step moving x n 2 steps moving y.exit distance sI n 1, thus distance unbounded.Example 4. Consider planning task Figure 7.DTG x consists two kinds transitions. First, line c1 , . . . , cntransitions requiring conditions. Second, direct links, called short-cutsfollows, cn every ci , conditioned value d1 y. DTG containstwo vertices connected unconditionally. Moving d1 d2 side-effectcn . (That side-effect responsible towards-cn direction short-cutsDTG x.)215fiHoffmannd1d1xc1c2cncnd1d2Figure 7: Planning task underlying Example 4. (red) inscription cn lined1 d2 indicates transition d1 d2 side effectcn .support graph acyclic. arc goes x, due short-cutsDTG x, due operator y12 effect x precondition y.transitions invertible; particular short-cut both, direction towardscn vice versa. However, side-effect y12 causes initial state sI = (c1 , d1 )local minimum n 3.h+ (sI ) = 1 due optimal relaxed plan hy12i. Noterelaxed plan care side effect y12, c1 still true afterward.Now, apply operator sI leaves c1 , clearly increase h+ 1:matter move make, relaxed plan must include y12 move back c1 .available option sI apply y12. get state s1 = (cn , d2 ). There,h+ (s1 ) = 2 well, relaxed plan needs re-achieve c1 . Since n 3,via unconditional sequence cn , . . . , c1 takes 2 steps. alternative useshort-cut xn1 cn c1 ; involves applying y21 first place, giving usrelaxed plan length 2. Hence direct successors sI heuristic value > 1,sI local minimum. Note also exit distance sI grows n. nearestexit state goal reached single step. Clearly,state (c2 , d2 ). shortest path state, sI , applies y12 moves alongunconditional line cn , . . . , c2 , taking 1 + (n 2) = n 1 steps.next show exit path constructed using short-cuts, leading improvedbound costd instead costd , may non-monotone, improved bound mayindeed under-estimate length shortest monotone exit path.Example 5. Consider planning task Figure 8.example, optimal relaxed plan initial state moves z alongpath e0 , . . . , e2n note values needed moving movesd2k+2n , moves x c1 . gives total h+ (sI ) = 2n + (2k + 2n) + 1 = 4n + 2k + 1steps.operators applicable sI move z. move along line e0 , . . . , e2n ,h+ remains constant: always need include moves back order achievegoal z. reach e2n , move one step, need move z back,etc. moves, state = d2k+2n , long z stays within216fiAnalyzing Search Topology Without Running Searchxc0d0e 2nd1e0e0e 2nd2d2k+2nc1d2ke1d2k+1 e2e 2nd2k+2nze0e1e 2n1e 2neFigure 8: Planning task underlying Example 5.e0 , . . . , e2n , h+ remains constant. see this, observe first course sufficesrelaxed plan reach once, z, values line, taking 2n moves whereverline; moves before. Second, observe indeed movesneeded: wherever line d0 , . . . , d2k+2n , needs move d2k+2n ordersuit x, needs move d0 suit goal. Every value e0 , . . . , e2n appearscondition least one moves. Thus, sI , nearest exit reachedway state = d2k+2n z = e2n : there, move x c1decreases h+ 4n + 2k. length exit pathdescribed, sI s,obviously 2k (2n + 1) + 2n 2 = 4kn + 2k + 4n.happens move z e0 ? Consider first sI . h+ increases4n + 2k + 2: need reach values line e0 , . . . , e2n , e0 takes onestep more. argument applies state traversed, because, argued,state still need reach values line e0 , . . . , e2n . Thusshortest monotone path exit.optimal rplan dependency graph oDG+ sI entire SG, oDT G+zcontains DT Gz except e0 . global dependency graph gDG entire SG.Clearly, sI , next required value reach variable e2n , constructionproof Theorem 2 first try reach value. using short-cutsaccounted costd (.), exit path constructed move e2n via e0 rather vialine e0 , . . . , e2n , thus claimed exit path monotone.Finally, consider bound returned costd (oDG+ ). Obviously, costd (oDG+ ) =costD (gDG). obtain bound (1) + costd (oDG+ ) = (1) + 1[costd (x)] + 1 (2k +2n)[costd (x) diam(oDT G+)] + (2k + 2n) (n + 1)[cost (y) diam(DT Gz )]. Notediam(DT Gz ) = n + 1 DT Gz circle 2n + 2 nodes. Overall,(1)+costd (oDG+ ) = (2k+2n)(n+2) = 2kn+4k+2n2 +4n. sufficiently large k,less 4kn+2k +4n, claimed. detail, 4kn+2k +4n > 2kn+4k +2n2 +4nn2iff 2kn 2k > 2n2 iff kn k > n2 iff k > n1. holds, example, set n := 2k := 5.reader noticed Example 5 contrived. reason needcomplicated unrealistic example costd , costd , contains twosources over-estimation, cf. discussion Section 5. particular, every move non217fiHoffmannleaf variables supposed take whole oDT G+ /DT G diameter. show costdgeneral upper bound length monotone exit path, thus need presentedconstruction around k under-estimation considering diam(DT Gz ) insteaddiam(oDT G+z ) outweighs over-estimation. Importantly, constructing examplesshort-cuts temporarily increase h+ (but costd nevertheless delivers upper boundmonotone exit path length) much easier. needs happen that, whateverreason, variable z like here, currently required value (e2n Example 5)reached oDT G+z values along unnecessarily long path whose values neededrelaxed plan. happens quite naturally, e.g., transportation domainsvehicle needs load/unload objects along longer path.demonstrate that, case analyses apply, exit distance mayexponential.Example 6. Consider planning task Figure 9.x0c 10x1c 11c 52c 21c 12c 51c 31c 20c 52c 12c 41c 51xnc 1nc 2nc 3nc 4nc 5nFigure 9: Planning task underlying Example 6.DTG x0 two vertices whose connection conditioned c15 .variables xi , five vertices line, alternatingly requiring last vertex ci+15i+1xi+1 first vertex c1 xi+1 . Clearly, optimal rplan dependency graphoDG+ sI , global dependency graph gDG task full supportgraph SG. acyclic, transitions invertible side effects, thusanalyses apply.h+ (sI ) ed(sI )? relaxed plan, need move x0 c02 . Dueconditioning, variable extreme values left right hand siderequired need 4 moves xi 1 n. Thus h+ (sI ) = 1 + 4n.Now, consider state s(x0 ) = c01 . construct relaxed plan, obviouslystill need 1 move x0 . also still need 4 moves variable. Consider x1 .s(x1 ) = c11 need move c15 order able move x0 . s(x1 ) = c12need move c15 order able move x0 , c11 goal,forth. cases, four transitions must taken relaxed plan. Dueconditioning, recursively true variables. Thus, h+ (s) = 1 + 4n.218fiAnalyzing Search Topology Without Running Searchmeans nearest exit state s0 x0 value c01 x1 value c15 :s0 , move x0 afterward, definitely, 4n steps suffice relaxed plan.distance state s0 ? need move x1 four times. Lets denote d(x1 ) = 4.move requires 4 moves x2 , d(x2 ) = 16. sequence moves x2 inversesdirection three times. points, x3 need move d(x3 ) = (d(x2 ) 3) 4.Generalizing this, get d(xi+1 ) = [d(xi ) ( d(x4 ) 1)] 4 = 3d(xi ) + 4, growthn exponential.Obviously, Example 6 also shows plan length exponential casesTheorem 4 applies. remark Example 6 similar example givenDomshlak Dinitz (2001). difference Domshlak Dinitzs exampleuses different conditions transitions left/to right, enablesuse smaller DTGs 3 nodes. setting, cannot use different conditionsneed transitions invertible. causes loss exit path stepssituations next lower variable inverses direction thus reliesoutside condition previous step. Indeed, DTGs size 3, losssteps results polynomially bounded exit distance. recursive formula d(xi )becomes d(xi+1 ) = [d(xi ) ( d(x2 ) 1)] 2 = d(xi ) + 2, resulting ed(sI ) = n2 + n.hand, costd costD still remain exponential case,consider loss incurred inversingdirections. Precisely, easy seePcostd (oDG+ ) = costD (gDG) = 1 + ni=1 2i = 2n+1 1. proves boundsover-estimate exponential amount.next example shows exit path constructed (implicitly) analyses mayexponentially longer optimal plan task.Example 7. Consider planning task Figure 10.x0c 10c 51c 20c10x1c 11c 52c 210c4n+1c 12c 31c 52c 12c 41xnc 1nc 2nc 3nc 4nc 5nFigure 10: Planning task underlying Example 7.219c 51fiHoffmannexample, optimal relaxed plan initial stateExample 6, alternative route via c001 , . . . , c00(4n+1) takes 1 + 4n + 1 = 4n + 2 >4n + 1 steps. Thus exit path constructed remains same, too, length exponentialn. However, length shortest plan 4n + 2.Note Example 7 observed weakness guided wrong directioncaused weakness optimal relaxed planning, rather weaknessanalysis. relaxation overlooks fact moving via x1 , . . . , xn incur high costsdue need repeatedly undo re-do conditions achieved beforehand. Note alsothat, example too, get exponential over-estimation exit distance.finally show feeding Theorem 2 non-optimal relaxed plans giveguarantees:Example 8. Consider planning task Figure 11.xc1g21d2c2g2n+2cv1d1end2g11g21g1n+2g2n+2v n+2ze1e n1enFigure 11: Planning task underlying Example 8. arrow en1 en indicatesrespective DTG transition directed, i.e., exists transitionen en1 .two ways achieve goal c2 : either via moving z, movingv1 , . . . , vn+2 . optimal relaxed plan chooses former option, giving h+ (sI ) = n+1.soon n 3, however, parallel-optimal relaxed plan P + (sI ) chooses latteroption moving z results n + 1 sequential moves, whereas v1 , . . . , vn+2moved parallel, giving parallel length 3.Consider happens h+ either options. move z, h+ remainsconstant need move z back goal. soon reach z = en ,h+ = last transition uni-directional longer achievegoal z. Thus exit path, particular monotone exit path, viaoption.Say move v1 , . . . , vn+2 instead. first move (whichever vi choose), h+increases shortest option undo move go via z: takesn + 2 steps whereas completing vi moves going via c0 takes (n + 1) + 2 = n + 3 steps.220fiAnalyzing Search Topology Without Running SearchThus monotone exit path via option either, sI local minimum.completing n + 2 moves vi moving x = c0 , h+ = (n + 2) + 1 dueshortest relaxed plan moves back vi moves x = c2 . reduce heuristicvalue initial value h+ (sI ) = n + 1, need execute 2 steps.state reached better evaluated neighbor, exit distance n + 5.Consider effect feeding Theorem 2 parallel-optimal plan P + (sI ).Clearly, optimal rplan dependency graph oDG+ constructed P + (sI ) consists xvi variables, include z. Thus theorem applies,wrongly concludes sI local minimum.exit distance bound computedP(11)[costd (x) diam(DT Gvi )] = n + 2.(1) + costd (oDG+ ) = (1) + 1[costd (x)] + n+2i=1less actual distance ed(sI ) = n + 5, thus result also wrong.Say modify Example 8 making last transition z undirected, makingone vi transitions unidirectional right. v1 , . . . , vn+2 option leadsdead end, whereas y, z option succeeds. particular, Theorem 2 applyoDG+ constructed parallel-optimal relaxed plan P + (sI ), thus exampleusing non-optimal relaxed plans results loss information.A.5 Benchmark Performance Guaranteesgive definitions 7 domains mentioned Propositions 1 2. domain,explain respective property claimed holds true. domains,assume static properties used PDDL capture unchanging things likeshape road network transportation domain. assume followsstatic predicates removed prior analysis, i.e., prior testingprerequisites Theorem 4.Definition 5. Logistics domain set planning tasks = (V, O, sI , sG ) whosecomponents defined follows. V = P V P set package-location variablesp, Dp = L V L set representing possible locations, V setvehicle-location variables v, Dv = Lv subset Lv L locations. containsthree types operators: move, load, unload, move(v, l1, l2) = ({v =l1}, {v = l2}) l1 6= l2, load(v, l, p) = ({v = l, p = l}, {p = v}), unload(v, l, p) =({v = l, p = v}, {p = l}). sI assigns arbitrary value variables, sGassigns arbitrary value subset variables.Every global dependency graph gDG Logistics either package p leafvariable x0 , vehicle variable v leaf variable x0 . latter case gDGconsists x0 , arcs. former case, o0 preconditioned single vehiclev only, leading single non-leaf variable v. cases, gDG acyclic, involvedtransitions side effects, involved transitions invertible. Thusapply Theorem 4. costD (gDG) = 1 + 1 1 packages costD (gDG) = 1vehicles, thus overall obtain correct bound 1.Definition 6. Miconic-STRIPS domain set planning tasks =(V, O, sI , sG ) whose components defined follows. V = B {e}|O| = |D| = |B| = |S| and: set passenger-origin variables o, = L L221fiHoffmannset representing possible locations (floors); set passenger-destinationvariables Dd = L; B set passenger-boarded variables b Db = {1, 0};set passenger-served variables Ds = {1, 0}; e elevator-location variableDe = L. contains three types operators: move, board, depart,move(l1, l2) = ({e = l1}, {e = l2}) l1 6= l2, board(l, i) = ({e = l, oi = l}, {bi = 1}),depart(l, i) = ({e = l, di = l, bi = 1}, {bi = 0, si = 1}). sI assigns arbitrary locationsvariables O, D, e, assigns 0 variables B S. sG assigns 1 variablesS.Passenger-origin passenger-destination variables static, i.e., affectedoperator. Thus common pre-processes remove variables, usingstatically prune set operators reachable. assume followsremoval taken place.Every global dependency graph gDG Miconic-STRIPS passenger-served variablesi leaf variable x0 . leads non-leaf variables bi e, arcs evariables bi si . Clearly, gDG acyclic. transitions einvertible side effects. transition (0, 1) bi (is invertible sincedeparting different condition e but) irrelevant own-delete bi = 0occur anywhere goal preconditions side effects thus irrelevantside effect deletes. transition (1, 0) bi (is invertible but) irrelevant bi = 0doesnt occur anywhere. transition (0, 1) leaf variable si self-irrelevant sideeffect deletes bi = 1 occurs precondition transitions responsibleoperator rop(0, 1) = depart(ld , i). Hence apply Theorem 4. delivers boundcostD (gDG) 1 = 1 + 1[si ] + (1 1)[costD (si ) maxPath(DT Gbi )] + (2 1)[(costD (si ) +costD (bi )) diam(DT Ge )] = 3.Definition 7. Simple-TSP domain set planning tasks = (V, O, sI , sG )whose components defined follows. V = {p} V where: p position variable,Dp = L L set representing possible locations; V , |V | = |L|,set location-visited variables v, Dv = {1, 0}. contains single typeoperators: move(l1, l2) = ({p = l1}, {p = l2, vl2 = 1}) l1 6= l2. sI assigns arbitraryvalue p assigns 0 variables V . sG assigns 1 variables V .Every global dependency graph gDG Simple-TSP location-visited variable vileaf variable x0 . leads single non-leaf variable p. Clearly, gDG acyclic.Every transition (0, 1) vi considered, induced o0 = move(l1, li), replaceable sideeffect deletes. operator = move(l1, x) replaced equivalent operatormove(li, x) unless x = li. latter case, o0 = excludeddefinition replaceable side effect deletes. Every transition (l1, l2) p clearly invertible;irrelevant side effect delete vl2 = 0; side effect vl2non-leaf variable gDG. Hence apply Theorem 4. delivers boundcostD (gDG) 1 = 1 + 1[vi ] + (1 1)[costD (vi ) diam(DT Gp )] = 1.consider extended version Movie domain, sense that, whereasoriginal domain version considers fixed range snacks (and thus state spaceconstant across domain instances), allow scale number different snacks.2525. original domain version allows scale number operators adding snack.operators identical, removed trivial pre-processes.222fiAnalyzing Search Topology Without Running SearchDefinition 8. Movie domain set planning tasks = (V, O, sI , sG )whose components defined follows. V = {c0, c2, re} H. Here, c0 counterat-zero variable, Dc0 = {1, 0}; c2 counter-at-two-hours variable,Dc2 = {1, 0}; movie-rewound variable, Dre = {1, 0}; H have-snackvariables h Dh = {1, 0}. contains four types operators: rewindTwo, rewindOther, resetCounter, getSnack, rewindT wo = ({c2 = 1}, {re = 1}),rewindOther = ({c2 = 0}, {re = 1, c0 = 0}), resetCounter = (, {c0 = 1}),getSnack(i) = (, {hi = 1}). sI assigns arbitrary value variables. sG assignsre, c0, H variables 1.Note that, depending value static variable c2, operator setdifferent: sI (c2) = 1 rewindOther removed, sI (c2) = 0 rewindT woremoved. refer former case (a) latter case (b).Every global dependency graph gDG consists single (leaf) variable. transitionsh variable side effects thus irrelevant side effect deletes.transition (0, 1) c0 side effects thus irrelevant side effect deletes.transition (1, 0) c0 irrelevant. case (a), transition (0, 1) sideeffects thus irrelevant side effect deletes apply Theorem 4. case (b),transition (0, 1) side effect c0 = 0. Observe (1) factirrelevant; (2) ctx(0, 1) {c0 = 1}, := resetCounter satisfies= preo (prevrop(0,1) eff rop(0,1) ) = {re = 1, c0 = 0}, {c0= 1} = eff = {c0 = 1},{c0 = 1} = eff {(y, d) | (y, d) , (y, d) sG rop(c,c0 )6=o0 preo0 } = {c0 = 1}.Thus transition recoverable side effect deletes, apply Theorem 4.case (a), gDGs bound costD (gDG) 1 applies. Obviously, costD (gDG) = 1thus obtain correct bound 0. case (b), bound costD (gDG) applies,costD (gDG) = 1 obtain correct bound 1.Definition 9. Ferry domain set planning tasks = (V, O, sI , sG ) whosecomponents defined follows. V = C {f, e} where: C set car-locationvariables c, Dc = L {f } L set representing possible locations; fferry-location variable Df = L; e ferry-empty variable De = {1, 0}.contains three types operators: sail, board, debark, sail(l1, l2) =({f = l1}, {f = l2}) l1 6= l2, board(l, c) = ({f = l, c = l, e = 1}, {c = f, e = 0}),debark(l, c) = ({f = l, c = f }, {c = l, e = 1}). sI assigns 1 variable e, assignsarbitrary value variable f , assigns arbitrary value f variablesC. sG assigns arbitrary value 6= f (some subset ) variables C f .Let arbitrary reachable state 0 < h+ (s) < , let P + (s)arbitrary optimal relaxed plan s. always apply Theorem 2. show this,distinguish three cases: (a) s(e) = 1, o0 = board(l, c) first board operator P + (s),set x0 = c; (b) s(e) = 0, o0 = debark(l, c) first debark operator P + (s),set x0 = c; (c) P + (s) contains board debark operator set o0first operator, sail(l1, l2), P + (s), x0 = f . Obviously, exactly one caseshold s. Let oDG+ = (V, A) sub-graph SG including x0 variables/arcsincluded per Definition 1. Let t0 transition taken o0 .case (a), obviously reorder P + (s) either board(l, c) first operatorP + (s), predecessors sail operators. oDG+ either (1) includes new223fiHoffmann(non-leaf) variables all, (2) includes f . f , clearly transitionsinvertible side effects. transition t0 effect (c, f ) deleting (c, l)clearly needed rest P + (s). side effect e = 0 deleting e = 1.latter fact may needed board operators P + (s). However, necessarilyP + (s) contains operator form debark(l0 , c), applicable board(l, c)sequence moves P + (s) must contain l l0 ; debark(l0 , c) recovers e = 1.+Thus oDG+ -relevant deletes t0 P>0(s)-recoverable. case (b), similarly+reorder P (s) either (1) debark(l, c) first operator P + (s), (2)predecessors sail operators. transition t0 effect (c, l) deleting (c, f )clearly needed rest P + (s); side effect e = 1 deleting e = 0clearly needed rest P + (s). Thus, again, oDG+ -relevant deletes++t0 P>0(s)-recoverable (the recovering sub-sequence P>0(s) empty+recovery required). case (c), finally, oDG contains f , t0 side effects,delete (f, l1) needed anymore (in fact, case l2 must goalf , P + (s) contains single operator o0 ). Hence, cases, applyTheorem 2. costd (oDG+ ) = 1 cases (a1), (b1), (c) get bound 0.costd (oDG+ ) = 1 + diam(DT Gf ) = 2 cases (a2) (b2) get bound 1.Definition 10. Gripper domain set planning tasks = (V, O, sI , sG )whose components defined follows. V = {ro, f1 , f2 } B. Here, ro robotlocation variable, Dro = {L, R}; f1 , f2 gripper-free variables, Df1 = Df2 ={1, 0}; B ball-location variables, Db = {L, R, 1, 2}. contains three typesoperators: move, pickup, drop, move(l1, l2) = ({ro = l1}, {ro = l2})l1 6= l2, pickup(g, b, l) = ({ro = l, b = l, fg = 1}, {b = g, fg = 0}), drop(g, b, l) = ({ro =l, b = g}, {b = l, fg = 1}). sI assigns L ro, assigns 1 f1 f2 , assigns Lvariables B. sG assigns R variables B.Let arbitrary reachable state 0 < h+ (s) < , let P + (s)arbitrary optimal relaxed plan s. always apply Theorem 2. distinguishtwo cases: (a) exists b B s(b) = g g {1, 2}, o0 = drop(g, b, R),set x0 = b; (b) exists b B s(b) = g g {1, 2}, o0 = pickup(g, b, L)b B P + (s), set x0 = b. Obviously, exactly one caseshold s. Let oDG+ = (V, A) sub-graph SG including x0 variables/arcsincluded per Definition 1. Let t0 transition taken o0 .case (a), obviously reorder P + (s) either drop(g, b, R) firstoperator P + (s), predecessor move(L, R). oDG+ either (1) includesnew (non-leaf) variables all, (2) includes ro. ro, clearly transitionsinvertible side effects. transition t0 effect (b, R) deleting(b, g) clearly needed rest P + (s); side effect fg = 1 deletingfg = 0 clearly needed rest P + (s). Thus oDG+ -relevant deletes+t0 P>0(s)-recoverable. case (b), similarly reorder P + (s) either (1)pickup(g, b, L) first operator P + (s), (2) predecessor move(R, L).transition t0 effect (b, g) deleting (b, L) clearly needed restP + (s). side effect fg = 0 deleting fg = 1; latter fact may neededpickup operators P + (s). However, necessarily P + (s) contains operators move(L, R)drop(g, b, R), applicable board(l, c); drop(g, b, R) recovers fg = 1. Thus,224fiAnalyzing Search Topology Without Running Search+again, oDG+ -relevant deletes t0 P>0(s)-recoverable. Hence, cases,+apply Theorem 2. cost (oDG ) = 1 cases (a1) (b1), get bound 0.costd (oDG+ ) = 1 + diam(ro) = 2 cases (a2) (b2) get bound 1.Definition 11. Transport domain set planning tasks = (V, O, sI , sG )whose components defined follows. V = P V E C where: P set packagelocation variables p, Dp = L V E L set representing possiblelocations; V E set vehicle-location variables v, Dv = L; C setvehicle-capacity variables cv , Dcv = {0, . . . , K} K maximum capacity.contains three types operators: drive, pickup, drop, where: drive(v, l1, l2) =({v = l1}, {v = l2}) (l1, l2) R GR = (L, R) undirected graph roadsL; pickup(v, l, p, c) = ({v = l, p = l, cv = c}, {p = v, cv = c 1}), drop(v, l, p, c) =({v = l, p = v, cv = c}, {p = l, cv = c + 1}). sI assigns arbitrary value Lvariables P V E, assigns K variables C. sG assigns arbitrary valueL subset variables P V E.Note use numbers addition/subtraction. are, course, partplanning language consider here. However, easily encoded (onfinite set number {0, . . . , K}) via static predicates. pre-processing, effectresulting task isomorphic one obtained simple arithmetic above,thus choose reduce notational clutter.Let arbitrary reachable state 0 < h+ (s) < . existsoptimal relaxed plan P + (s) apply Theorem 2. distinguish threecases: (a) exists p P s(p) = v v V E, o0 = drop(v, l, p, c)s(cv ) = c P + (s), set x0 = p; (b) exists p P s(p) = vv V E, o0 = pickup(v, l, p, K) p P P + (s), set x0 = p; (c) P + (s)contains drop pickup operator set o0 first operator, drive(v, l1, l2),P + (s), x0 = v. Obviously, choose P + (s) exactly one caseshold (the choice P + (s) arbitrary (b) (c), (a) may exist optimalrelaxed plans s(cv ) 6= c). Let oDG+ = (V, A) sub-graph SG including x0variables/arcs included per Definition 1. Let t0 transition taken o0 .case (a), obviously reorder P + (s) either o0 = drop(v, l, p, c) firstoperator P + (s), predecessors drive operators. oDG+ either (1) includesnew (non-leaf) variables all, (2) includes v. v, clearly transitionsinvertible side effects. transition t0 effect (p, v) deleting(p, l) clearly needed rest P + (s). side effect cv = c+1 deletingcv = c. latter fact may needed operators P + (s), either taking formdrop(v, l0 , p0 , c) form pickup(v, l0 , p0 , c). Clearly, P + (s) contains operatorsreplace drop(v, l0 , p0 , c + 1) pickup(v, l0 , p0 , c + 1) respectivelyvalue (cv , c + 1) true point (relaxed) execution. Thuschoose P + (s) P + (s)-relevant deletes t0 P + (s)-recoverable V \ {x0 }.case (b), similarly reorder P + (s) either (1) o0 = pickup(v, l, p, K)first operator P + (s), (2) predecessors drive operators. transition t0effect (p, v) deleting (p, l) clearly needed rest P + (s).side effect cv = K 1 deleting cv = K. latter fact may neededoperators P + (s), taking form pickup(v, l0 , p0 , K). However, necessarily P + (s)225fiHoffmanncontains operator form drop(v, l0 , p, c0 ). c0 6= K 1 replaceoperator drop(v, l0 , p, K 1) since, clearly, value (cv , K 1) truepoint (relaxed) execution. Now, drop(v, l0 , p, K 1) applicable pickup(v, l, p, K)sequence drive operators P + (s) must contain l l0 ; drop(v, l0 , p, K 1)recovers cv = K. Thus, again, choose P + (s) P + (s)-relevant deletest0 P + (s)-recoverable V \ {x0 }. case (c), finally, oDG+ contains v, t0side effects, delete (v, l1) needed anymore. Hence, cases,apply Theorem 2. costd (oDG+ ) = 1 cases (a1), (b1), (c) get bound0. costd (oDG+ ) = 1 + min(diam(oDT G+v ), diam(DT Gv )) cases (a2) (b2)bound diameter road map GR .ignoring action costs, Elevators domain IPC 2008 essentially variantTransport. variant general (a) vehicle (each elevator) maymaximal capacity, (b) vehicle reach subset locations, i.e.,vehicle individual road map. hand, Elevators restrictedTransport (c) vehicle road map fully connected (every reachable floornavigated directly every reachable floor), (d) goals existpackages (passengers, is), vehicles. Even ignoring restrictions (c) (d),trivial see arguments given Transport still hold true. Therefore,whenever reachable state 0 < h+ (s) < , exists optimal relaxed planP + (s) apply Theorem 2. before, bound diameterroad map. Due (c), diameter 1.ReferencesBackstrom, C., & Klein, I. (1991). Planning polynomial time: SAS-PUBS class.Computational Intelligence, 7 (4).Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. ComputationalIntelligence, 11 (4), 625655.Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90 (1-2), 279298.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (12), 533.Botea, A., Muller, M., & Schaeffer, J. (2004). Using component abstraction automaticgeneration macro-actions. Koenig et al. (Koenig, Zilberstein, & Koehler, 2004),pp. 181190.Brafman, R., & Domshlak, C. (2003). Structure complexity planning unaryoperators. Journal Artificial Intelligence Research, 18, 315349.Bylander, T. (1994). computational complexity propositional STRIPS planning.Artificial Intelligence, 69 (12), 165204.Cesta, A., & Borrajo, D. (Eds.), ECP01 (2001). Recent Advances AI Planning. 6thEuropean Conference Planning (ECP01), Lecture Notes Artificial Intelligence,Toledo, Spain. Springer-Verlag.226fiAnalyzing Search Topology Without Running SearchChen, H., & Gimenez, O. (2010). Causal graphs structurally restricted planning. Journal Computer System Sciences, 76 (7), 579592.Domshlak, C., & Dinitz, Y. (2001). Multi-agent offline coordination: Structure complexity. Cesta & Borrajo (Cesta & Borrajo, 2001), pp. 3443.Edelkamp, S., & Helmert, M. (1999). Exhibiting knowledge planning problems minimize state encoding length. Biundo, S., & Fox, M. (Eds.), Recent Advances AIPlanning. 5th European Conference Planning (ECP99), Lecture Notes ArtificialIntelligence, pp. 135147, Durham, UK. Springer-Verlag.Fox, M., & Long, D. (1998). automatic inference state invariants TIM. JournalArtificial Intelligence Research, 9, 367421.Fox, M., & Long, D. (1999). detection exploitation symmetry planningproblems. Pollack, M. (Ed.), Proceedings 16th International Joint Conference Artificial Intelligence (IJCAI99), pp. 956961, Stockholm, Sweden. MorganKaufmann.Garey, M. R., & Johnson, D. S. (1979). Computers IntractabilityA GuideTheory NP-Completeness. Freeman, San Francisco, CA.Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), ICAPS09 (2009). Proceedings19th International Conference Automated Planning Scheduling (ICAPS9),Thessaloniki, Greece. AAAI.Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local searchtemporal action graphs. Journal Artificial Intelligence Research, 20, 239290.Gerevini, A., & Schubert, L. (1998). Inferring state-constraints domain independentplanning. Mostow, J., & Rich, C. (Eds.), Proceedings 15th National Conference American Association Artificial Intelligence (AAAI98), pp. 905912,Madison, WI, USA. MIT Press.Gimenez, O., & Jonsson, A. (2008). complexity planning problems simplecausal graphs. Journal Artificial Intelligence Research, 31, 319351.Gimenez, O., & Jonsson, A. (2009a). influence k-dependence complexityplanning. Gerevini et al. (Gerevini, Howe, Cesta, & Refanidis, 2009), pp. 138145.Gimenez, O., & Jonsson, A. (2009b). Planning chain causal graphs variablesdomains size 5 NP-hard. Journal Artificial Intelligence Research, 34, 675706.Haslum, P. (2007). Reducing accidental complexity planning problems. Veloso, M.(Ed.), Proceedings 20th International Joint Conference Artificial Intelligence(IJCAI07), pp. 18981903, Hyderabad, India. Morgan Kaufmann.Helmert, M. (2003). Complexity results standard benchmark domains planning.Artificial Intelligence, 143, 219262.Helmert, M. (2004). planning heuristic based causal graph analysis.. Koenig et al.(Koenig et al., 2004), pp. 161170.Helmert, M. (2006). fast downward planning system. Journal Artificial IntelligenceResearch, 26, 191246.227fiHoffmannHelmert, M. (2009). Concise finite-domain representations PDDL planning tasks. Artificial Intelligence, 173 (5-6), 503535.Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whatsdifference anyway? Gerevini et al. (Gerevini et al., 2009), pp. 162169.Hoffmann, J. (2003). Utilizing Problem Structure Planning: Local Search Approach,Vol. 2854 Lecture Notes Artificial Intelligence. Springer-Verlag.Hoffmann, J. (2005). ignoring delete lists works: Local search topology planningbenchmarks. Journal Artificial Intelligence Research, 24, 685758.Hoffmann, J., & Nebel, B. (2001a). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J., & Nebel, B. (2001b). RIFO revisited: Detecting relaxed irrelevance. Cesta& Borrajo (Cesta & Borrajo, 2001), pp. 325336.Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. JournalArtificial Intelligence Research, 22, 215278.Jonsson, A. (2009). role macros tractable planning. Journal Artificial Intelligence Research, 36, 471511.Jonsson, P., & Backstrom, C. (1995). Incremental planning. European WorkshopPlanning.Jonsson, P., & Backstrom, C. (1998). State-variable planning structural restrictions:Algorithms complexity. Artificial Intelligence, 100 (1-2), 125176.Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C.(Ed.), Proceedings 21st International Joint Conference Artificial Intelligence(IJCAI09), pp. 17281733, Pasadena, CA, USA. Morgan Kaufmann.Katz, M., & Domshlak, C. (2008a). New islands tractability cost-optimal planning.Journal Artificial Intelligence Research, 32, 203288.Katz, M., & Domshlak, C. (2008b). Structural patterns heuristics via fork decomposition.Rintanen, J., Nebel, B., Beck, J. C., & Hansen, E. A. (Eds.), Proceedings18th International Conference Automated Planning Scheduling (ICAPS08),pp. 182189, Sydney, Australia. AAAI.Knoblock, C. (1994). Automatically generating abstractions planning. Artificial Intelligence, 68 (2), 243302.Koenig, S., Zilberstein, S., & Koehler, J. (Eds.), ICAPS04 (2004). Proceedings14th International Conference Automated Planning Scheduling (ICAPS04),Whistler, Canada. AAAI.Long, D., & Fox, M. (2000). Automatic synthesis use generic types planning.Chien, S., Kambhampati, R., & Knoblock, C. (Eds.), Proceedings 5th International Conference Artificial Intelligence Planning Systems (AIPS00), pp. 196205,Breckenridge, CO. AAAI Press, Menlo Park.McDermott, D. V. (1999). Using regression-match graphs control search planning.Artificial Intelligence, 109 (1-2), 111159.228fiAnalyzing Search Topology Without Running SearchNebel, B., Dimopoulos, Y., & Koehler, J. (1997). Ignoring irrelevant facts operatorsplan generation. Steel, S., & Alami, R. (Eds.), Recent Advances AI Planning. 4thEuropean Conference Planning (ECP97), Vol. 1348 Lecture Notes ArtificialIntelligence, pp. 338350, Toulouse, France. Springer-Verlag.Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. Fox, D., & Gomes,C. (Eds.), Proceedings 23rd National Conference American AssociationArtificial Intelligence (AAAI08), pp. 975982, Chicago, Illinois, USA. MIT Press.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytimeplanning landmarks. Journal Artificial Intelligence Research, 39, 127177.Rintanen, J. (2000). iterative algorithm synthesizing invariants. Kautz, H. A.,& Porter, B. (Eds.), Proceedings 17th National Conference AmericanAssociation Artificial Intelligence (AAAI00), pp. 806811, Austin, TX, USA.MIT Press.Roberts, M., & Howe, A. (2009). Learning planner performance. Artificial Intelligence,173, 636561.Vidal, V. (2004). lookahead strategy heuristic search planning. Koenig et al.(Koenig et al., 2004), pp. 150160.Williams, B. C., & Nayak, P. P. (1997). reactive planner model-based executive.Pollack, M. (Ed.), Proceedings 15th International Joint Conference ArtificialIntelligence (IJCAI97), pp. 11781185, Nagoya, Japan. Morgan Kaufmann.229fiJournal Artificial Intelligence Research 41 (2011) 397-406Submitted 05/11; published 07/11Research NotePolicy Invariance Reward TransformationsGeneral-Sum Stochastic GamesXiaosong LuHoward M. SchwartzLUXIAOS @ SCE . CARLETON . CASCHWARTZ @ SCE . CARLETON . CADepartment Systems Computer EngineeringCarleton University1125 Colonel Drive, Ottawa, K1S 5B6 CanadaSidney N. Givigi Jr.IDNEY.G IVIGI @ RMC . CADepartment Electrical Computer EngineeringRoyal Military College Canada13 General Crerar Cres, Kingston, K7K 7B4 CanadaAbstractextend potential-based shaping method Markov decision processes multi-playergeneral-sum stochastic games. prove Nash equilibria stochastic game remainsunchanged potential-based shaping applied environment. property policyinvariance provides possible way speeding convergence learning play stochasticgame.1. Introductionreinforcement learning, one may suffer temporal credit assignment problem (Sutton &Barto, 1998) reward received sequence actions. delayed reward leaddifficulty distributing credit punishment action long sequence actionscause algorithm learn slowly. example problem foundepisodic tasks soccer game player given credit punishmentgoal scored. number states soccer game large, take long timeplayer learn equilibrium policy.Reward shaping technique improve learning performance reinforcement learnerintroducing shaping rewards environment (Gullapalli & Barto, 1992; Mataric, 1994).state space large, delayed reward slow learning dramatically.speed learning, learner may apply shaping rewards environment supplementdelayed reward. way, reinforcement learning algorithm improve learningperformance combining "good" shaping reward function original delayed reward.applications reward shaping found literature (Gullapalli & Barto, 1992;Dorigo & Colombetti, 1994; Mataric, 1994; Randlv & Alstrm, 1998). Gullapalli Barto (1992)demonstrated application shaping key-press task robot trained press keyskeyboard. Dorigo Colombetti (1994) applied shaping policies robot performpredefined animate-like behavior. Mataric (1994) presented intermediate reinforcement functiongroup mobile robots learn foraging task. Randlv Alstrm (1998) combined reinforcement learning shaping make agent learn drive bicycle goal. theoreticalc2011AI Access Foundation. rights reserved.fiL U , CHWARTZ , & G IVIGIanalysis reward shaping found literature (Ng, Harada, & Russell, 1999; Wiewiora,2003; Asmuth, Littman, & Zinkov, 2008). Ng et al. (1999) presented potential-based shapingreward guarantee policy invariance single agent Markov decision process(MDP). Ng et al. proved optimal policy keeps unchanged adding potential-basedshaping reward MDP environment. Following Ng et al., Wiewiora (2003) showed effects potential-based shaping achieved particular initialization Q-values agentsusing Q-learning. Asmuth et al. (2008) applied potential-based shaping reward model-basedreinforcement learning approach.articles focus applications reward shaping single agent MDP.applications reward shaping general-sum games, Babes, Munoz de Cote, Littman (2008)introduced social shaping reward players learn equilibrium policies iteratedprisoners dilemma game. theoretical proof policy invariance rewardtransformation. research, prove Nash equilibria potential-based shapingreward transformation (Ng et al., 1999) also Nash equilibria original gameframework general-sum stochastic games. Note similar work Devlin Kudenko(2011) published article review. Devlin Kudenko provedsufficiency based proof technique introduced Asmuth et al. (2008), provesufficiency necessity using different proof technique article.2. Framework Stochastic GamesStochastic games first introduced Shapley (1953). stochastic game, players choosejoint action move one state another state based joint action choose.section, framework stochastic games, introduce Markov decision processes, matrixgames stochastic games respectively.2.1 Markov Decision ProcessesMarkov decision process tuple (S, A, T, , R) state space, action space,: [0, 1] transition function, [0, 1] discount factor R : Rreward function. transition function denotes probability distribution next statesgiven current state action. reward function denotes received reward next stategiven current action current state. Markov decision process following Markovproperty: players next state reward depend players current state action.players policy : defined probability distribution players actions givenstate. optimal policy maximize players discounted future reward. MDP,exists deterministic optimal policy player (Bertsekas, 1987).Starting current state following optimal policy thereafter, get optimalstate-value function expected sum discounted rewards (Sutton & Barto, 1998))(V (s) = Ej rk+ j+1 |sk = s,(1)j=0k current time step, rk+ j+1 received immediate reward time step k + j + 1,[0, 1] discount factor, final time step. (1), taskinfinite-horizon task task run infinite period. task episodic,398fiP OLICY NVARIANCER EWARD RANSFORMATIONSdefined terminal time episode terminated time step . callstate episode ends terminal state sT . terminal state, state-value functionalways zero V (sT ) = 0 sT S. Given current state action a, followingoptimal policy thereafter, define optimal action-value function (Sutton & Barto, 1998)h(2)Q (s, a) = (s, a, ) R(s, a, ) + V (s )(s, a, ) = Pr {sk+1 = |sk = s, ak = a} probability next state sk+1 =given current state sk = action ak = time step k, R(s, a, ) = E{rk+1 |sk = s, ak = a,sk+1 = } expected immediate reward received state given current state actiona. terminal state, action-value function always zero Q(sT , a) = 0 sT S.2.2 Matrix Gamesmatrix game tuple (n, A1 , . . . , , R1 , . . . , Rn ) n number players, Ai (i = 1, . . . , n)action set player Ri : A1 R payoff function player i.matrix game game involving multiple players single state. player i(i = 1, . . . , n)selects action action set Ai receives payoff. player payoff function Ridetermined players joint action joint action space A1 . two-player matrixgame, set matrix element containing payoff joint action pair.payoff function Ri player i(i = 1, 2) becomes matrix. two players gamefully competitive, two-player zero-sum matrix game R1 = R2 .matrix game, player tries maximize payoff based players strategy.players strategy matrix game probability distribution players action set. evaluate players strategy, introduce following concept Nash equilibrium. Nash equilibriummatrix game collection players policies (1 , , n )Vi (1 , , , , n ) Vi (1 , , , , n ), , = 1, , n(3)Vi () expected payoff player given players current strategiesstrategy player strategy space . words, Nash equilibrium collectionstrategies players player better changing strategy givenplayers continue playing Nash equilibrium policies (Basar & Olsder, 1999). defineQi (a1 , . . . , ) received payoff player given players joint action a1 , . . . , , (ai )(i = 1, . . . , n) probability player choosing action a1 . Nash equilibrium defined(3) becomesQi (a1 , . . . , )1 (a1 ) (ai ) n (an )a1 ,...,an A1Qi (a1 , . . . , )1 (a1 ) (ai ) n (an ), , = 1, , n(4)a1 ,...,an A1(ai ) probability player choosing action ai player Nash equilibriumstrategy .two-player matrix game called zero-sum game two players fully competitive.way, R1 = R2 . zero-sum game unique Nash equilibrium senseexpected payoff. means that, although player may multiple Nash equilibrium399fiL U , CHWARTZ , & G IVIGIstrategies zero-sum game, value expected payoff Vi Nash equilibriumstrategies same. players game fully competitive summationplayers payoffs zero, game called general-sum game. general-sum game,Nash equilibrium longer unique game might multiple Nash equilibria. Unlikedeterministic optimal policy single player MDP, equilibrium strategies multiplayer matrix game may stochastic.2.3 Stochastic GamesMarkov decision process contains single player multiple states matrix game containsmultiple players single state. game one player multiple states,define stochastic game (or Markov game) combination Markov decision processesmatrix games. stochastic game tuple (n, S, A1 , . . . , , T, , R1 , . . . , Rn ) nnumber players, : A1 [0, 1] transition function, Ai (i = 1, . . . , n)action set player i, [0, 1] discount factor Ri : A1 Rreward function player i. transition function stochastic game probabilitydistribution next states given current state joint action players. rewardfunction Ri (s, a1 , . . . , , ) denotes reward received player state taking jointaction (a1 , . . . , ) state s. Similar Markov decision processes, stochastic games alsoMarkov property. is, players next state reward depend current stateplayers current actions.solve stochastic game, need find policy : Ai maximize playerdiscounted future reward discount factor . Similar matrix games, players policystochastic game probabilistic. example soccer game introduced Littman (Littman,1994) agent offensive side must use probabilistic policy pass unknowndefender. literature, solution stochastic game described Nash equilibriumstrategies set associated state-specific matrix games (Bowling, 2003; Littman, 1994).state-specific matrix games, define action-value function Qi (s, a1 , . . . , ) expected reward player players take joint action a1 , . . . , state followNash equilibrium policies thereafter. value Qi (s, a1 , . . . , ) known states,find player Nash equilibrium policy solving associated state-specific matrix game(Bowling, 2003). Therefore, state s, matrix game find Nashequilibrium strategies matrix game. Nash equilibrium policies gamecollection Nash equilibrium strategies state-specific matrix game states.2.4 Multi-Player General-Sum Stochastic Gamesmulti-player general-sum stochastic game, want find Nash equilibria gameknow reward function transition function game. Nash equilibrium stochasticgame described tuple n policies (1 , . . . , n ) = 1, , n,Vi (s, 1 , . . . , , . . . , n ) Vi (s, 1 , . . . , , . . . , n )(5)set policies available player Vi (s, 1 , . . . , n ) expected sumdiscounted rewards player given current state players equilibrium policies.simplify notation, use Vi (s) represent Vi (s, 1 , , n ) state-value function Nashequilibrium policies. also define action-value function Q (s, a1 , , ) expected400fiP OLICY NVARIANCER EWARD RANSFORMATIONSsum discounted rewards player given current state current joint actionplayers, following Nash equilibrium policies thereafter. getVi (s) =Qi (s, a1 , , )1 (s, a1 ) n (s, ),(6)a1 , ,an A1Qi (s, a1 , . . . , ) =(s, a1 , . . . , , )Ri (s, a1 , . . . , , ) + Vi (s ) ,(7)(s, ai ) PD(Ai ) probability distribution action ai player Nash equilibrium policy, (s, a1 , . . . , , ) = Pr {sk+1 = |sk = s, a1 , . . . , } probability next stategiven current state joint action (a1 , . . . , ), Ri (s, a1 , . . . , , ) expectedimmediate reward received state given current state joint action (a1 , . . . , ). Based(6) (7), Nash equilibrium (5) rewrittenQi (s, a1 , . . . , )1 (s, a1 ) (s, ai ) n (s, )a1 ,...,an A1Qi (s, a1 , . . . , )1 (s, a1 ) (s, ai ) n (s, ).(8)a1 ,...,an A13. Potential-Based Shaping General-Sum Stochastic GamesNg et al. (1999) presented reward shaping method deal credit assignment problemadding potential-based shaping reward environment. combination shapingreward original reward may improve learning performance reinforcement learningalgorithm speed convergence optimal policy. theoretical studies potentialbased shaping methods appear published literature consider case single agentMDP (Ng et al., 1999; Wiewiora, 2003; Asmuth et al., 2008). research, extendpotential-based shaping method Markov decision processes multi-player stochastic games.prove Nash equilibria potential-based shaping reward transformationNash equilibria original game framework general-sum stochastic games.define potential-based shaping reward Fi (s, ) playerFi (s, ) = (s ) (s),(9): R real-valued shaping function (sT ) = 0 terminal state sT .define multi-player stochastic game tuple = (S, A1 , . . . , , T, , R1 , . . . , Rn ) setstates, A1 , . . . , players action sets, transition function, discount factor,Ri (s, a1 , . . . , , )(i = 1, . . . , n) reward function player i. adding shaping rewardfunction Fi (s, ) reward function Ri (s, a1 , . . . , , ), define transformed multi-playerstochastic game tuple = (S, A1 , . . . , , T, , R1 , . . . , Rn ) Ri (i = 1, . . . , n) newreward function given Ri (s, a1 , . . . , , ) = Fi (s, ) + Ri (s, a1 , . . . , , ). Inspired Ng et al.(1999)s proof policy invariance MDP, prove policy invariance multi-playergeneral-sum stochastic game follows.Theorem 1. Given n-player discounted stochastic game = (S, A1 , . . . , , T, , R1 , . . . , Rn ),define transformed n-player discounted stochastic game = (S, A1 , . . . , , T, , R1 + F1 , . . . , Rn +Fn ) Fi shaping reward function player i. call Fi potential-based shapingfunction Fi form (9). Then, potential-based shaping function Fi necessarysufficient condition guarantee Nash equilibrium policy invariance401fiL U , CHWARTZ , & G IVIGI(Sufficiency) Fi (i = 1, . . . , n) potential-based shaping function, every Nash equilibrium policy also Nash equilibrium policy (and vice versa).(Necessity) Fi (i = 1, . . . , n) potential-based shaping function, may existtransition function reward function R Nash equilibrium policyNash equilibrium policy M.Proof. (Proof Sufficiency)Based (8), Nash equilibrium stochastic game represented set policies= 1, . . . , n, MiQMi (s, a1 , . . . , )M(s, a1 )(s, ai )(s, )1na1 ,...,an A1(s, a1 ) Mi (s, ai )(s, ).QMi (s, a1 , . . . , )M1n(10)a1 ,...,an A1subtract (s) sides (10) geta1 ,...,an A1QMi (s, a1 , . . . , )M(s, a1 )(s, ai )(s, ) (s)1nQMi (s, a1 , . . . , )M(s, a1 ) Mi (s, ai )(s, ) (s).1n(11)a1 ,...,an A1(s, ) (s, ) (s, ) = 1, getSince a1 ,...,an A11nMiMn1(s, a1 )(s, ai )(s, )[QMi (s, a1 , . . . , ) (s)]M1na1 ,...,an A1[QMi (s, a1 , . . . , ) (s)]M(s, a1 ) Mi (s, ai )(s, ).1n(12)a1 ,...,an A1defineQMi (s, a1 , . . . , ) = QMi (s, a1 , . . . , ) (s).(13)geta1 ,...,an A1QMi (s, a1 , . . . , )M(s, a1 )(s, ai )(s, )1na1 ,...,an A1(s, a1 ) Mi (s, ai )(s, ).QMi (s, a1 , . . . , )M1n(14)use algebraic manipulations rewrite action-value function Nash equilibrium (7) player stochastic gameQMi (s, a1 , . . . , ) (s) = (s, a1 , . . . , , ) RMi (s, a1 , . . . , , ) + VM (s )+ (s ) (s ) (s).(15)Since (s, a1 , . . . , , ) = 1, equation becomesQMi (s, a1 , . . . , ) (s) =(s, a1 , . . . , , )RMi (s, a1 , . . . , , )+ (s ) (s) + VM (s ) (s ) .402(16)fiP OLICY NVARIANCER EWARD RANSFORMATIONSAccording (6), rewrite equationQMi (s, a1 , . . . , ) (s) =+a1 ,...,an A1=+a1 ,...,an A1(s, a1 , . . . , , )RMi (s, a1 , . . . , , ) + (s ) (s)(s,)(s,)QMi (s , a1 , . . . , )M(s)1n1(s, a1 , . . . , , )RMi (s, a1 , . . . , , ) + (s ) (s)(s , a1 )(s , ) .QMi (s , a1 , . . . , ) (s )1(17)Based definitions Fi (s, ) (9) QMi (s, a1 , . . . , ) (13), equation becomesQMi (s, a1 , . . . , ) =+a1 ,...,an A1(s, a1 , . . . , , )RMi (s, a1 , . . . , , ) + Fi(s, )QMi (s , a1 , . . . , )(s , a1 )(s , ) .1(18)Since equations (14) (18) form equations (6)-(8), concludeQMi (s, a1 , . . . , ) action-value function Nash equilibrium player stochastic game . Therefore, obtainQMi (s, a1 , . . . , ) = QM (s, a1 , . . . , ) = QMi (s, a1 , . . . , ) (s).(19)state terminal state sT , QMi (sT , a1 , . . . , ) = QMi (sT , a1 , . . . , )(sT ) = 0 0 = 0. Based (14) QMi (s, a1 , . . . , ) = QM (s, a1 , . . . , ), findNash equilibrium also Nash equilibrium . state-value functionNash equilibrium stochastic game givenVM (s) = VM (s) (s).(20)(Proof Necessity)Fi (i = 1, . . . , n) potential-based shaping function, Fi (s, ) 6= (s ) (s).Similar Ng et al. (1999)s proof necessity, define = Fi (s, ) [ (s ) (s)].build stochastic game giving following transition function player 1s rewardfunction RM1 ()(s1 , a11 , a2 , . . . , , s3 ) = 1,(s1 , a21 , a2 , . . . , , s2 ) = 1,(s2 , a1 , . . . , , s3 ) = 1,(s3 , a1 , . . . , , s3 ) = 1,RM1 (s1 , a1 , . . . , , s3 ) = ,2RM1 (s1 , a1 , . . . , , s2 ) = 0,RM1 (s2 , a1 , . . . , , s3 ) = 0,RM1 (s3 , a1 , . . . , , s3 ) = 0,403(21)fiL U , CHWARTZ , & G IVIGIa11S3S1a12S2Figure 1: possible states stochastic model proof necessityai (i = 1, . . . , n) represents possible action ai Ai player i, a11 a21 representplayer 1s action 1 action 2 respectively. Equation (s1 , a11 , a2 , . . . , , s3 ) = 1 (21) denotesthat, given current state s1 , player 1s action a11 lead next state s3 matterjoint action players take. Based transition function reward function,get game model including states (s1 , s2 , s3 ) shown Figure 1. define 1 (si ) =F1 (si , s3 )(i = 1, 2, 3). Based (6), (7), (19), (20) (21), obtain player 1s action-valuefunction state s1,2QM1 (s1 , a21 , . . . ) = 0,QM1 (s1 , a11 , . . . ) =QM (s1 , a11 , . . . ) = F1 (s1 , s2 ) + F1 (s2 , s3 ) ,12QM (s1 , a21 , . . . ) = F1 (s1 , s2 ) + F1 (s2 , s3 ).1Nash equilibrium policy player 1 state s1(s1 , a1 ) =11a1 > 0,a21,(s1 , a1 ) =1otherwise2a1 > 0,a11.(22)otherwiseTherefore, case, Nash equilibrium policy player 1 state s1Nash equilibrium policy .analysis shows potential-based shaping reward form Fi (s, ) =(s ) (s) guarantees Nash equilibrium policy invariance. question becomesselect shaping function (s) improve learning performance learner. Nget al. (1999) showed (s) = VM (s) good candidate improving players learning404fiP OLICY NVARIANCER EWARD RANSFORMATIONSperformance MDP. substitute (s) = VM (s) (18) getQMi (s, a1 , . . . , ) = QM (s, a1 , . . . , )=+(s, a1 , . . . , , )RMi (s, a1 , . . . , , ) + Fi (s, )RMi (s, a1 , . . . , , ) + Fi (s, )QM (s , a1 , . . . , )(s,)(s,)1n1a1 ,...,an A1=(s, a1 , . . . , , )+ (VM (s ) (s ))= (s, a1 , . . . , , ) RMi (s, a1 , . . . , , ) + Fi (s, ) .(23)Equation (23) shows action-value function QM (s, a1 , . . . , ) state easily obtainedchecking immediate reward RMi (s, a1 , . . . , , ) + Fi (s, ) player received state .However, practical applications, information environment(s, a1 , . . . , , ) Ri (s, a1 , . . . , , ). means cannot find shaping function (s)(s) = VM (s) without knowing model environment. Therefore, goaldesigning shaping function find (s) good approximation VM (s).4. Conclusionpotential-based shaping method used deal temporal credit assignment problemspeed learning process MDPs. article, extend potential-based shapingmethod general-sum stochastic games. prove proposed potential-based shaping reward applied general-sum stochastic game change original Nash equilibriumgame. analysis result article potential improve learning performanceplayers stochastic game.ReferencesAsmuth, J., Littman, M. L., & Zinkov, R. (2008). Potential-based shaping model-based reinforcement learning. Proceedings 23rd AAAI Conference Artificial Intelligence,pp. 604609.Babes, M., Munoz de Cote, E., & Littman, M. L. (2008). Social reward shaping prisonersdilemma. Proceedings 7th International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS 2008), pp. 13891392.Basar, T., & Olsder, G. J. (1999). Dynamic Noncooperative Game Theory. SIAM Series ClassicsApplied Mathematics 2nd, London, U.K.Bertsekas, D. P. (1987). Dynamic Programming: Deterministic Stochastic Models. PrenticeHall, Englewood Cliffs, NJ.Bowling, M. (2003). Multiagent Learning Presence Agents Limitations. Ph.D. thesis,School Computer Science, Carnegie Mellon University, Pittsburgh, PA.405fiL U , CHWARTZ , & G IVIGIDevlin, S., & Kudenko, D. (2011). Theoretical considerations potential-based reward shapingmulti-agent systems.. Proceedings 10th International Conference AutonomousAgents Multiagent Systems (AAMAS), Taipei, Taiwan.Dorigo, M., & Colombetti, M. (1994). Robot shaping: developing autonomous agentslearning. Artificial Intelligence, 71, 321370.Gullapalli, V., & Barto, A. (1992). Shaping method accelerating reinforcement learning.Proceedings 1992 IEEE International Symposium Intelligent Control, pp. 554 559.Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning.Proceedings 11th International Conference Machine Learning, pp. 157163.Mataric, M. J. (1994). Reward functions accelerated learning. Proceedings 11thInternational Conference Machine Learning.Ng, A. Y., Harada, D., & Russell, S. (1999). Policy invariance reward transformations: theoryapplication reward shaping. Proceedings 16th International ConferenceMachine Learning, pp. 278287.Randlv, J., & Alstrm, P. (1998). Learning drive bicycle using reinforcement learningshaping. Proceedings 15th International Conference Machine Learning.Shapley, L. S. (1953). Stochastic games. Proceedings National Academy Sciences,Vol. 39, pp. 10951100.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, Massachusetts.Wiewiora, E. (2003). Potential-based shaping Q-value initialization equivalent. JournalArtificial Intelligence Research, 19, 205208.406fiJournal Artificial Intelligence Research 41 (2011) 267296Submitted 11/10; published 06/11Identical Similar: Fusing Retrieved Lists BasedInter-Document SimilaritiesAnna Khudyak KozorovitskyOren Kurlandannak@tx.technion.ac.ilkurland@ie.technion.ac.ilFaculty Industrial Engineering ManagementTechnion Israel Institute TechnologyAbstractMethods fusing document lists retrieved response query often utilize retrieval scores and/or ranks documents lists. present novel fusionapproach based using, addition, information induced inter-documentsimilarities. Specically, methods let similar documents dierent lists providerelevance-status support other. use graph-based method model relevancestatus propagation documents. propagation governed inter-documentsimilarities retrieval scores documents lists. Empirical evaluation demonstrates eectiveness methods fusing TREC runs. performanceeective methods transcends eective fusion methods utilize retrieval scores ranks.1. Introductionad hoc retrieval task nd documents pertaining information needunderlying given query. Naturally, considerable uncertainty retrieval processe.g., accurately inferring actual information need is. Thus, researchers proposed utilize dierent information sources types address retrieval task (Croft,2000b). example, utilizing multiple document representations (Katzer, McGill, Tessier,Frakes, & Dasgupta, 1982), query representations (Saracevic & Kantor, 1988; Belkin, Cool,Croft, & Callan, 1993), search techniques (Croft & Thompson, 1984; Fox & Shaw,1994), proposed means improving retrieval eectiveness.Many approaches mentioned depend ability eectively fuse severalretrieved lists produce single list results. Fusion might performedsingle retrieval system (Croft & Thompson, 1984), upon results produced dierentsearch systems (Fox & Shaw, 1994; Callan, Lu, & Croft, 1995; Dwork, Kumar, Naor, &Sivakumar, 2001). Conceptually, fusion viewed integrating experts recommendations (Croft, 2000b), expert retrieval model used produce ranked listresults experts recommendation.principle underlying many fusion methods documents highlyranked many lists, i.e., highly recommended many experts,ranked high nal result list (Fox & Shaw, 1994; Lee, 1997). eectivenessapproaches employ principle often depends overlap1 non-relevant1. use term overlap refer number documents shared retrieved lists ratherreference content overlap.c2011AI Access Foundation. rights reserved.fiKhudyak Kozorovitsky & Kurlanddocuments lists much smaller relevant documents (Lee,1997). However, several studies shown often case, specically,many occasions (many) dierent relevant documents across listsfused (Das-Gupta & Katzer, 1983; Griths, Luckhurst, & Willett, 1986; Chowdhury,Frieder, Grossman, & McCabe, 2001; Soboro, Nicholas, & Cahan, 2001; Beitzel et al.,2003).propose novel approach fusion retrieved lists addresses, among others,relevant-documents mismatch issue mentioned. principle guiding developmentmethods similar documents dierent lists, welllist provide relevance-status support other, potentially discusstopics (Shou & Sanderson, 2002; Balinski & Danilowicz, 2005; Diaz, 2005; Kurland& Lee, 2005; Meister, Kurland, & Kalmanovich, 2010). Specically, relevant documentsassumed similar following cluster hypothesis (van Rijsbergen, 1979),provide support via inter-document similarities.Inspired work re-ranking single retrieved list using inter-document similaritieswithin list (Balinski & Danilowicz, 2005; Diaz, 2005; Kurland & Lee, 2005), approachuses graph-based method model relevance-status propagation documentslists fused. propagation governed inter-document-similaritiesretrieval scores documents lists. Specically, documents highly rankedlists, similar documents highly ranked, rewarded.inter-document-similarities utilized i.e., retrieval scores usedmethods reduce standard fusion approaches.Empirical evaluation shows methods highly eective fusing TREC runs(Voorhees & Harman, 2005); is, lists document created responsequeries search systems participated TREC. eective methods postperformance superior eective standard fusion methods utilizeretrieval scores. show ndings hold whether runs fused,selected available runs per track (challenge) TREC, eective ones,randomly selected. Using additional array experiments study eectvarious factors performance approach.2. Fusion FrameworkLet q denote query document, respectively. assume documentsassigned unique IDs; write d1 d2 d1 d2 ID, i.e.,[q;k][q;k]document. assume document lists L1 , . . . , Lm , L1 , . . . , Lm short,retrieved response q retrievals performed given corpus, respectively;list contains k documents. write Li indicate member Li ,defuse SLi (d) denote (positive) retrieval score Li ; 6 Li SLi (d) = 0.document instance Lji document rank j list Li . simplify notation, oftendefuse S(Lji ) denote retrieval score Lji (i.e., S(Lji ) = SLi (Lji )). methodspresent consider similarity sim(d1 , d2 ) documents d1 d2 . methodscommitted specic way computing inter-document similarities. example,cosine measure vector-space representations documents used268fiFusing Retrieved Lists Based Inter-Document Similaritiesprevious work re-ranking single retrieved list (Diaz, 2005; Kurland & Lee, 2005).Section 4.1 describe specic choice language-model-based inter-documentsimilarity measure used experiments following previous recommendations (Kurland &Lee, 2010).2.1 Fusion Essentialsgoal produce single list results retrieved lists L1 , . . . , Lm . end,opt detect documents highly recommended lists L1 , . . . , Lm ,words, prestigious respect lists. Given virtuelists created, is, response query, hypothesize prestige impliesrelevance. key challenge formally dene quantify prestige.Many current fusion approaches (implicitly) regard document prestigioushighly ranked many lists. CombSUM method (Fox & Shaw, 1994),example, quanties prestige notion summing document retrieval scores2 :defPCombSU (d) =XSLi (d).Li :dLiemphasize even importance occurrence many lists, CombMNZ method(Fox & Shaw, 1994; Lee, 1997), highly eective fusion approach (Montague &Aslam, 2002), scales CombSUMs score number lists document member of:defPCombM N Z (d) = #{Li : Li }XSLi (d).Li :dLipotentially helpful source information utilized standard fusion methodsinter-document relationships. example, documents similarprovide support prestige potentially discuss topics. Indeed, workre-ranking single retrieved list shown prestige induced inter-document similarities connected relevance (Kurland & Lee, 2005). multiple-lists settingaddress here, information induced inter-document similarities across lists couldrich source helpful information well. case point, document membersingle list, similar documents highly ranked manylists could deemed prestigious. Furthermore, similarity-based prestige viewedgeneralization prestige notion taken standard fusion methods, considerdocuments similar document.2.2 Similarity-Based Fusionuse graphs represent propagation prestige status documents; propagation based inter-document similarities retrieval scores. nodes graph2. assume retrieval scores normalized inter-list compatibility; details normalization scheme employ experiments provided Section 4.1.269fiKhudyak Kozorovitsky & Kurlandrepresent either documents, document instances (appearances documents) retrieved lists. latter case, document represented several nodes,corresponds appearance list, former case, nodecorresponds dierent document.development following graph-construction method prestige-inductiontechnique inspired work inducing prestige single retrieved list (Kurland & Lee,2005). contrast work, however, would like exploit special characteristicsfusion setup. is, fact documents appear several retrievedlists dierent retrieval scores might produced dierent retrieval methods.Accordingly, fusion methods develop novel study.Formally, given set documents (document instances) V , construct weighteddef(directed) complete graph G = (V, V V, w t) edge-weight function w t:w t(v1 v2 )def=(sim(v1 , v2 ) v2 N bhd(v1 ; ),0otherwise;v1 , v2 V ; and, N bhd(v; ) elements v V {v : v v} yield highestsim(v, v ) i.e., vs nearest neighbors V ; free parameter.3 Previous workdemonstrated merits using directed nearest-neighbor-based graphs, use here,modeling prestige-status propagation setups wherein prestige implies relevanceinformation need (Kurland & Lee, 2005). (See Kurland, 2006 elaborated discussion.)work inducing (i) journal prestige bibliometrics (Pinski & Narin, 1976), (ii)Web-page prestige Web retrieval (Brin & Page, 1998), (iii) plain-text prestige reranking single list (Kurland & Lee, 2005), say node v G prestigiousextent receives prestige-status support prestigious nodes. quantifydef Pprestige notion using P (v; G) =v V w t(v v)P (v ; G). However, recursiveequation necessarily solution.address issue, dene smoothed version edge-weight function,echoes PageRanks (Brin & Page, 1998) approach:defw t[] (v1 v2 ) = P2 , q)w t(v1 v2 )sim(v+ (1 ) P;sim(v , q)v V w t(v1 v )(1)v Vq) vs estimated query similarity. (Below presentfree parameter, sim(v,defvarious query-similarity measures.) resultant graph G[] = (V, V V, w t[] ).Note node G[] receives prestige-status support extent partially controlled similarity document represents query. Nodes amongnearest-neighbors nodes get additional support. Moreover, w t[]thought probability transition function, sum weights edges goingnode 1; furthermore, every node outgoing edges nodes graph(self loops included). Hence, G[] represents ergodic Markov chain unique stationary distribution exists (Golub & Van Loan, 1996). distribution, found3. Note N bhd(v; ) contains nodes represent documents represented v.270fiFusing Retrieved Lists Based Inter-Document SimilaritiesAlgorithmSetUniSetSumSetMNZBagUniBagSumBagDupUniBagDupMNZq)sim(v,V{d : Li }{d : Li }{d : Li }{Lji }i,j{Lji }i,j{Dup(Lji )}i,j{Dup(Lji )}i,j1PCombSU (v)PCombM N Z (v)1S(v)1S(v)core(d)P (d; G[] )P (d; G[] )P (d; G[] )PP (v; G[] )PvV :vdP (v; G[] )PvV :vdP (v; G[] )PvV :vd[]vV :vd P (v; G )Table 1: Similarity-based fusion methods; core(d) ds nal retrieval score.L1: d1: d2: d3L11L21L31L2: d2: d4: d1L12L22L32Table 2: Example two retrieved lists fused.using, example, Power method (Golub & Van Loan, 1996),P unique solutionfollowing prestige-induction equation constraint v V P (v ; G[] ) = 1:defP (v; G[] ) =Xw t[] (v v)P (v ; G[] ).(2)v V2.2.1 Methodsderive specic fusion methods, need specify graph G[] using prestigeinduced Equation 2. specically, given lists L1 , . . . , Lm , deneset nodes V represent documents (or document instances); and, deviseq)) used edge-weight function w t[]query-similarity estimate (sim(v,Equation 1. alternatives consider, represent ways utilizinggraph-based approach, resultant fusion methods, presented Table 1.important note fusion method produces ranking documents whereindocument cannot one instance. facilitate discussion variousmethods Table 1, refer example fusing two lists Table 2, L1L2 , contains three documents.rst group methods consider occurrences document multiple listsutilizing inter-document similarities. Specically, V , set nodes, deneddefset-union retrieved lists. example Table 2, V = {d1 , d2 , d3 , d4 }.Thus, document represented graph single node. prestige valuenode serves nal retrieval score document. SetUni method ignoresretrieval scores documents using uniform query-similarity estimate; hence,inter-document similarity information utilized. SetSum SetMNZ methods,hand, integrate also retrieval scores using CombSUM CombMNZprestige scores query-similarity estimates, respectively.271fiKhudyak Kozorovitsky & KurlandSetSum SetMNZ methods are, fact, generalized forms CombSUMCombMNZ, respectively. use edge-weight function w t[1] (i.e., set = 1 Equation 1), is, exploit inter-document-similarity information, SetSumSetMNZ amount CombSUM CombMNZ, respectively; lower values resultemphasis put inter-document-similarities information. Furthermore, set-basedparadigm used incorporate generalize fusion method usingmethods retrieval score query-similarity estimate. Then, setting = 1 amountsusing fusion methods retrieval scores. (See Appendix proof.)contrast set-based methods, bag-based methods consider occurrencesdocument multiple lists utilizing inter-document similarity information. nodegraph represents instance document list. Hence, set nodes (V )graph could viewed bag-union retrieved lists. exampledefTable 2, V = {L11 , L21 , L31 , L12 , L22 , L32 }. nal retrieval score document setsum prestige scores nodes represent i.e., correspond instanceslists. example, score d1 would sum scores nodes L11L32 . also important note neighborhood set N bhd(v; ) nodev cannot contain nodes representing document represented v, containmultiple instances dierent document. Thus, documents many instances tendreceive inter-document-similarity-based prestige-status support documentsfewer instances.rst representative bag-based methods, BagUni, ignores retrieval scoresconsiders inter-document-similarities. Hence, BagUni diers SetUnivirtue rewarding documents multiple instances. addition exploiting interdocument similarities, BagSum method also uses retrieval score documentinstance query-similarity estimate corresponding node. note CombSUM specic case BagSum = 1, case SetSum. (See Appendixproof.) Furthermore, BagSum resembles SetSum uses controllingbalance using retrieval scores utilizing inter-document similarities. However, documents many instances get prestige-status support BagSumSetSum due bag-based representation lists.Naturally, then, opt create bag-based generalized version CombMNZmethod. end, document instance Lji corresponds document d,dene new list Dup(Lji ). list contains n copies d, assigned arbitrarydefdierent rank 1 n S(Lji ) retrieval score; n = #{Li : Li }number original lists belongs to. set nodes V composed documentinstances newly dened lists. example Table 2, get followingnewly created lists:defLa = Dup(L11 )L1a : L11 d1L2a : L11 d1defLb = Dup(L32 )L1b : L32 d1L2b : L32 d1defLc = Dup(L21 )L1c : L21 d2L2c : L21 d2defLd = Dup(L12 )L1d : L12 d2L2d : L12 d2defLe = Dup(L31 )L1e : L31 d3defLf = Dup(L22 )L1f : L22 d4set nodes, V , {L1a , L2a , L1b , L2b , L1c , L2c , L1d , L2d , L1e , L1f }. Note, example,d1 represented single node set-based representation, two nodesbag-based representation, represented four nodes. generally,272fiFusing Retrieved Lists Based Inter-Document Similaritiesnumber nodes document represented square numberappearances document lists.BagDupUni method, then, uses uniform query-similarity estimate. Hence,SetUni BagUni utilizes inter-document similarities; but, so, BagDupUnirewards larger extent documents multiple instances due bag representationduplicated instances. BagDupMNZ method integrates also retrieval-scoresinformation using retrieval score document instance new list querysimilarity estimate corresponding node. w t[1] (i.e., = 1), BagDupMNZ amountsCombMNZ, case SetMNZ. (See Appendix proof.) Yet, BagDupMNZrewards larger extent documents multiple instances SetMNZ duebag representation lists duplicated document instances.3. Related WorkFusion methods often use ranks documents lists, retrieval scores,documents content (Fox & Shaw, 1994; Voorhees, Gupta, & Johnson-Laird, 1994; Lee,1997; Vogt & Cottrell, 1999; Croft, 2000b; Dwork et al., 2001; Aslam & Montague, 2001;Montague & Aslam, 2002; Lillis, Toolan, Collier, & Dunnion, 2006; Shokouhi, 2007).example, Dwork et al. (2001), us, use Markov chains nd prestigious documentslists. However, propagation relevance status governed informationregarding ranks documents lists. show Section 4.2 usingretrieval scores inter-document similarities guide relevance-status propagationeective using alone. Also, note previous work fusiondemonstrated relative merits using retrieval scores rather rank information (Lee,1997). Furthermore, stated Section 2.2.1, methods incorporate generalizefusion methods rely scores/ranks using set-based graph representation.used Section 2.2.1 CombSUM CombMNZ methods, based retrievalscores, examples. CombSUM (non supervised) representative general familylinear combination techniques (Vogt & Cottrell, 1999), CombMNZ consideredhighly eective approach therefore often serves baseline work fusion (Lee,1997; Aslam & Montague, 2001; Montague & Aslam, 2002; Lillis et al., 2006; Shokouhi,2007). Section 4.2 demonstrate performance merits approach respectCombSUM CombMNZ, additional rank-based fusion methods.several fusion methods utilize document-based features,based document content, e.g., snippets (summaries) documents (Lawrence &Giles, 1998; Craswell, Hawking, & Thistlewaite, 1999; Tsikrika & Lalmas, 2001; Beitzel,Jensen, Frieder, Chowdhury, & Pass, 2005; Selvadurai, 2007). However, contrastmethods, inter-document similarities used approaches. Thus,methods potentially incorporated fusion framework using set-based graphrepresentation. Furthermore, note methods potentially utilize documentsnippets estimate inter-document similarities, rather use entire document content, content (quickly) accessible. Indeed, snippets used inducinginter-document similarities cluster results Web search engines (Zamir & Etzioni,1998).273fiKhudyak Kozorovitsky & Kurlandlarge body work re-ranking initially retrieved list using graphbased methods model inter-document similarities within list (e.g., Danilowicz &Balinski, 2000; Balinski & Danilowicz, 2005; Diaz, 2005; Kurland & Lee, 2005, 2006; Zhanget al., 2005; Yang, Ji, Zhou, Nie, & Xiao, 2006). mentioned Section 2, fusionmethods could conceptually viewed generalization approaches(Danilowicz & Balinski, 2000; Diaz, 2005; Kurland & Lee, 2005); specically, methodsutilize retrieval scores inter-document-similarities modeling relevancestatus propagation within list (Danilowicz & Balinski, 2000; Diaz, 2005). similarrelevance-status propagation method also employed work sentence retrievalquestion answering (Otterbacher, Erkan, & Radev, 2005).Similarities document headlines used merging document listsretrieved response query non-overlapping corpora (Shou & Sanderson, 2002).Specically, document ranked sum similarities headline headlines documents. contrast approach, operates single corpus,accordingly exploits information regarding multiple occurrences documentlists, retrieval scores integrated similarities; and, graph-basedapproach use employed. Section 4.2 show using retrievalscores single-corpus-based fusion setup explore highly important; specifically, integrating retrieval scores inter-document-similarities results much betterperformance using inter-document similarities.Similarities documents (potentially non-overlapping) dierent corporaalso used form document clusters (Xu & Croft, 1999; Crestani & Wu, 2006)(potentially) improve results browsing (Crestani & Wu, 2006) improve collectionselection (Xu & Croft, 1999) search. contrast approach, fusion methodsbased utilizing information induced inter-document similaritiesproposed.recent work re-ranking retrieved list using inter-document similaritiessecond retrieved list (Meister et al., 2010). idea documents highlyranked original list, similar documents highly ranked secondlist, rewarded. However, contrast fusion approaches, documentsmembers second list, rst list, cannot appear nal result list.Furthermore, contrast approach, recursive denition prestige.importantly, apparent way generalizing method fuse several lists,contrast approach.Methods utilizing inter-item textual similarities using variant PageRankalso used, example, cross-lingual retrieval (Diaz, 2008), prediction retrieval eectiveness (Diaz, 2007), text summarization clustering (Erkan& Radev, 2004; Mihalcea & Tarau, 2004; Erkan, 2006). Specically, recent work(Krikon, Kurland, & Bendersky, 2010) demonstrated merits integrating wholedocument-based inter-document similarities inter-passage-similarities re-rankingsingle retrieved list; especially, using corpora containing long and/or topically heterogeneous documents. Incorporating inter-passage similarities methods futurevenue intend explore.274fiFusing Retrieved Lists Based Inter-Document Similarities4. Evaluationnext study eectiveness similarity-based fusion approach, dierentfactors aect performance.4.1 Experimental Setupfollows describe setup used evaluation.4.1.1 Measuring Inter-Document Similarities.use previously proposed language-model-based similarity estimate showneective work re-ranking single retrieved list (Kurland & Lee, 2005, 2006, 2010).[]Let pd () denote unigram, Dirichlet-smoothed, language model induced document d, smoothing parameter (Zhai & Laerty, 2001). set = 1000following previous recommendations (Zhai & Laerty, 2001). documents d1 d2dene:fifideffifi [][0]sim(d1 , d2 ) = exp pd1 () fifi pd2 () ;KL divergence. closer language models d1 d2 are, lowerKL divergence is, higher similarity estimate is.4.1.2 Data, Evaluation Measures, Parameters.evaluate performance fusion methods using TREC datasets (Voorhees &Harman, 2005), also used previous work fusion (e.g., Lee, 1997;Aslam & Montague, 2001; Montague & Aslam, 2002): ad hoc track trec3, webtracks trec9 trec10, robust track trec12. Tokenization, Porter stemming,stopword removal (using INQUERY list) applied documents usingLemur toolkit4 , also used computing sim(d1 , d2 ).Retrieval methods utilize inter-document similarities query context e.g.,re-ranking single retrieved list using graph-based techniques knowneective employed relatively short lists (Willett, 1985; Diaz, 2005; Kurland & Lee,2010). reason lists often contain documents exhibit high surface-levelquery similarity. Hence, lists could thought providing eective query-basedcorpus context. Similar arguments echoed work pseudo-feedback-based queryexpansion (Xu & Croft, 1996; Lavrenko & Croft, 2001; Zhai & Laerty, 2002; Tao & Zhai,2006). Furthermore, utilizing inter-document similarities short lists shownhighly eective improving precision top ranks (Kurland & Lee, 2005, 2006).5Indeed, users Web search engines, example, often interested highlyranked documents (a.k.a., rst page results). Given considerations mentioned,take following design decisions respect evaluation measures focuson, number lists fused, number documents list.4. www.lemurproject.org5. Improving precision top ranks often results improving MAP (mean average precision) virtueway MAP defined. show Section 4.2.1 approach improves precision topranks MAP.275fiKhudyak Kozorovitsky & Kurlandfocus precision top ranks, use precision top 5 10 documents(p@5, p@10) main evaluation measures. determine statistically-signicant performance dierences, use two-tailed Wilcoxon test 95% condence level.means that, average, result signicance test might erroneous oneevery twenty tests. Thus, employ Bonferroni correction corpora per evaluationmeasure (i.e., condence level 98.75% also used). Specically, results tablespresent, statistical-signicance mark corresponds 95% condence level; and,mark boldfaced corresponding performance dierence statistically signicantBonferroni correction employed (i.e., using 98.75% condence level).use methods fuse three lists, corresponds top-k documentssubmitted run within track; is, use actual result lists (runs) submittedTRECs participants. main focus evaluation, (and including) Section4.2.5, fusing three runs eective among submitted runstrack (both automatic manual); eectiveness measured MAP@k , is, meanaverage non-interpolated precision cuto k, henceforth referred MAP (Voorhees& Harman, 2005). three runs fused denoted, descending order MAPperformance, run1, run2, run3, respectively. Although MAP evaluationmeasure focus albeit, present MAP performance numbers Section 4.2.1practice ensures initial ranking lists fused relatively highquality; is, terms recall relative positioning relevant documents. Yet,lists fused could still sub-optimal respect precision top ranks. Thus,use reference comparisons methods Optimal Runs (opt. run short)per evaluation metric track; is, track, evaluation metric (p@5p@10), report best (average queries per track) m-performance obtainedsubmitted run track. Note MAP performance run1 best trackvirtue way run1 selected. However, run1 necessarily optimalrun respect p@5 p@10. addition, compare performance methodsCombSUM CombMNZ fusion techniques; recall methods,rely solely retrieval scores, special cases methods. nutshell,evaluate eectiveness fusion approach, fusion methodsserve reference comparisons, attaining high precision top ranks respect(i) lists fused, (ii) best performing runs track respectprecision top ranks.note fusing three (MAP) eective runs track constitutereal-life retrieval scenario quality lists fused known practice,rather potentially predicted (Carmel & Yom-Tov, 2010). Yet, setupsuitable conservative evaluation methods, specically, studying abilityeectively fuse lists high quality. Nevertheless, Section 4.2.6 also presentperformance methods fusing three runs randomly selectedruns track.Experiments setting k, number documents list fused, values{10, 20, 30, 40, 50, 75, 100} showed fusion methods compareapproach, specically CombMNZ (Fox & Shaw, 1994; Lee, 1997), often attain (near) optimalprecision-at-top-ranks performance k = 20. turns out, also caseeective fusion methods. Hence, experiments follow based using top276fiFusing Retrieved Lists Based Inter-Document Similaritiesk = 20 documents run fused. Section 4.2.4 present eect kperformance.main goal evaluation follow focus underlying principlesproposed fusion approach, potential eectiveness. would like thoroughlycompare dierent proposed methods utilizing inter-document similarities,factors aect performance, rather engage excessive performance optimization. goals mind, start ameliorating eects free-parametervalues. setting values free parameters methods incorporate,reference comparisons, optimize average p@5 performanceentire set queries track6 . Thus, note p@10 performance numberspresent necessarily optimal ones could attained. Yet, experimental setup realistic optimizing performance evaluationmetrics separately. Then, Sections 4.2.3 4.2.4 present eect performancevarying values free parameters methods. Furthermore, Section 4.2.5present performance eective methods values free parameterslearned using cross-validation performed queries. value ancestry parameter, incorporated methods, chosen {5, 10, 20, 30, 40, 50}. value, controls reliance retrieval scores versus inter-document-similarities,chosen {0.1, 0.2, . . . , 1}.inter-list compatibility retrieval scores, normalize score documentlist respect sum scores list; list negative retrieval scores,usually due using logs, use exponent score normalization7 .4.1.3 Efficiency Considerations.number documents (document instances) graphs constructhundreds8 . Hence, computing inter-document similarities incur signicantcomputational overhead. Even entire document content quickly accessible,document snippets, example, could used computing inter-document similarities.(This future venue intend explore.) Similar eciency considerations madework clustering results retrieved Web search engines (Zamir & Etzioni, 1998),work re-ranking search results using clusters top-retrieved documents (Willett,1985; Liu & Croft, 2004; Kurland & Lee, 2006). addition, note computingprestige small graphs takes iterations Power method (Golub &Van Loan, 1996).4.2 Experimental Resultsnext present performance numbers fusion approach. Section 4.2.1present main result performance best-performing models respectreference comparisons. Then, Section 4.2.2 compare analyze6. two parameter settings yield p@5, choose one minimizing p@10 provideconservative estimates performance.7. Normalizing retrieval scores respect maximum minimum scores list yields almostexactly performance numbers report here.8. Note three fused lists contains 20 documents, document instance duplicated,all, three times.277fiKhudyak Kozorovitsky & Kurlandopt. runrun1run2run3CombSUMBagSumCombMNZBagDupMNZtrec3p@5p@1076.072.274.472.272.867.676.071.280.8ab74.6b83.2oabc 78.8omabc80.8ab74.6b83.2ab 79.0omabctrec9p@5p@1060.053.160.053.145.8o38.8o38.3o34.6o52.9bc 48.5bc59.6m48.1bcbc55.0bc 48.8bc60.4m47.9bcbctrec10p@5p@1063.258.863.258.854.450.255.646.8o71.2abc 61.0bc71.2oabc 61.0bc71.2oabc 61.0bc72.0oabc 61.0bctrec12p@5p@1054.548.651.144.852.548.651.545.2o53.749.2ac55.4ac49.2ac53.949.2ac56.6m49.0acabcTable 3: Main result table. performance two eective fusion methods,BagSum BagDupMNZ; = 1, amount CombSUM CombMNZ,respectively. best performance column boldfaced. Statisticallysignicant dierences opt. run, run1, run2, run3, marked o, a,b, c, respectively. (Here after, mark statistically-signicantdierences run1, run2 run3 avoid cluttering presentation,convey additional insight.) Statistically-signicant dierencesBagSum CombSUM, BagDupMNZ CombMNZ, markedm. values (, ) yield optimal average p@5 performanceBagSum (0.4, 5), (0.6, 40), (0, 5) (0.1, 5) trec3, trec9, trec10,trec12, respectively; BagDupMNZ, (0.7, 5), (0.1, 20), (0.1, 5), (0.1, 20) yieldoptimal average p@5 performance trec3, trec9, trec10, trec12, respectively.performance proposed fusion methods. futher study merits using interdocument similarities Section 4.2.3. eect performance additional factors, e.g.,number documents lists fused (k), presented Section 4.2.4. Section4.2.5 presents performance numbers eective models values freeparameters learned using cross validation performed across queries. noted above,(and including) Section 4.2.5, evaluation based fusing three eectiveruns track. Section 4.2.6 evaluate performance methods fusingruns randomly selected. Section 4.2.7 present analysis overlaprelevant non-relevant documents lists fused sheds lightreasons relative eectiveness approach respect standardfusion.4.2.1 Main ResultTable 3 presents main result. present performance numbers twoeective methods, namely, BagSum BagDupMNZ. (See Section 4.2.2 in-depthanalysis performance fusion methods.) Recall = 1 i.e.,using inter-document-similarity information methods amount CombSUMCombMNZ, respectively.rst observation based Table 3 reference comparisons (trackevaluation measure) BagSum BagDupMNZ methods outperform often278fiFusing Retrieved Lists Based Inter-Document Similaritiessubstantial statistically-signicant degree three fused runs. Furthermore,many cases, performance methods also superior opt. run. alsoholds, example, p@5 BagDupMNZ trec12, track performanceruns fused (specically, run2 run3) quite opt. run.trec9, methods performance several cases run1, alsoopt. run respect p@5 p@10. However, performance dierencesstatistically signicant. Also, note run1 far eective run2 run3;hence, run2 run3 potentially relatively relevant documents contributeaddition run1. Nevertheless, performance methods trec9substantially better two fused runs (run2 run3); and, termsp@5 metric performance optimized performance trec9BagSum BagDupMNZ statistically-signicantly better (for BagDupMNZ alsoemploying Bonferroni correction) special case, is, CombSUMCombMNZ, respectively. fact p@5 performance CombSUM CombMNZmuch worse run1 trec9, case tracks, couldattributed fact number relevant documents shared amongthree runs lowest observed respect considered tracks. (We presentanalysis number relevant documents shared runs Section 4.2.7.)scenario methods yield much merit using inter-document similarities,evident p@5 performance improvements post CombSUM CombMNZtrec9.generally, see Table 3 majority relevant comparisonsmethods performance superior special cases utilize interdocument similarities (CombSUM CombMNZ). p@5 improvements trec9,example, noted above, substantial statistically signicant. Furthermore,methods post statistically signicant improvements runs fused,opt. run, CombSUM CombMNZ do. Thus, ndings attest meritsutilizing inter-document similarities fusion.Analysis MAP Performance. Although focus evaluation presentprecision top ranks, also interested general quality rankinginduced methods. Accordingly, present MAP performance BagSumBagDupMNZ methods Table 4. avoid potential metric-divergence issues (Azzopardi,Girolami, & van Rijsbergen, 2003; Morgan, Grei, & Henderson, 2004; Metzler & Croft,2005), is, optimizing performance one retrieval metric presenting performancenumbers dierent retrieval metric, optimize performance methodscase respect MAP.see Table 4 except trec9, methods outperform quitecases, statistically signicantly fused runs, opt. run. (Recall run1best MAP-performing run track; i.e., terms MAP, run1 opt. run.) Moreover,methods consistently outperform corresponding special cases, CombSUMCombMNZ.Comparison Rank-Based Fusion Methods focus paperfusion methods utilize retrieval scores, Table 5 compare performanceBagDupMNZ (one two best-performing methods) two fusion methods279fiKhudyak Kozorovitsky & Kurlandopt. runrun1run2run3CombSUMBagSumCombMNZBagDupMNZtrec3MAP10.410.49.69.510.9bc11.4omabc10.9bc11.5omabctrec9MAP28.228.218.4o16.8o24.9bc26.6bc25.5bc27.0bctrec10MAP30.730.727.7o21.6o37.2bc37.3bc37.2bc38.4bctrec12MAP28.828.828.428.130.3oa30.5oa30.3oa30.5oaTable 4: MAP performance numbers. best performance column boldfaced.Statistically signicant dierences opt. run, run1, run2, run3, markedo, a, b, c, respectively. Statistically signicant dierencesBagSum CombSUM, BagDupMNZ CombMNZ, markedm.round robinBordaBagDupMNZtrec3p@5 p@1076.473.280.478.683.2 79.0rbtrec9p@5 p@1050.445.655.048.360.4rb 47.9trec10p@5 p@1061.655.271.262.072.0r 61.0rtrec12p@5 p@1053.947.354.348.856.6 49.0Table 5: Comparison rank-based fusion methods. Statistically-signicant dierencesBagDupMNZ round robin Borda marked r b,respectively.utilize ranks documents rather scores. rst simple round robinapproach wherein order runs used run1, run2 run3. second rank-basedfusion method Borda (Young, 1974), scored number documentsranked higher lists:def X#{d Li : SLi (d ) <= SLi (d)}.PBorda (d) =Lisee Table 5 BagDupMNZ outperforms round robinBorda methods reference comparisons. Many performance dierences (especially round robin) quite substantial also statistically signicant.Upper Bound Analysis study potential approach completely neutralizing eects free-parameter values, present Table 6 upper bound analysisp@5 performance BagDupMNZ. end, query use free-parametervalues BagDupMNZ yield optimized p@5 query. Recall performanceBagDupMNZ reported based free-parameter values set optimize average280fiFusing Retrieved Lists Based Inter-Document SimilaritiesOptRunPerQueryopt. runrun1CombMNZBagDupMNZtrec391.676.0p74.4p80.8pa89.6oamtrec979.660.0p60.0p55.0p68.3potrec1084.463.2p63.2p71.2po79.6potrec1284.854.5p51.1p53.9p66.1poTable 6: Upper bound analysis p@5 performance BagDupMNZ. Specically,query use BagDupMNZ free-parameter values optimized p@5query. reference comparison, query consider best p@5performing run (OptRunPerQuery). performance run1 (the best (MAP)performing among three fused runs), opt. run (the run yields bestaverage p@5 per track), CombMNZ presented reference. p, o, a,mark statistically signicant dierences OptRunPerQuery, opt. run,run1, CombMNZ, respectively.opt. runrun1run2run3SetUniSetSumSetMNZBagUniBagSumBagDupUniBagDupMNZtrec3p@5p@1076.072.274.472.272.867.676.071.279.2b75.0b82.8oabc 78.0oabc82.0ab77.2oabc82.4ab78.8oabc83.2abc 78.8oabc82.0ab78.6oabc83.2ab 79.0oabctrec9p@5p@1060.053.160.053.145.8o38.8o38.3o34.6o42.5a39.2oa59.2bc 49.2bc61.3bc 49.2bc59.2bc 47.9bc59.6bc 48.1bc57.5bc 48.1bc60.4bc 47.9bctrec10p@5p@1063.258.863.258.854.450.255.646.8o56.848.2oa71.2abc 61.0bc71.2oabc 61.0bc70.8bc61.2bc71.2oabc 61.0bc72.0oabc 60.4bc72.0oabc 61.0bctrec12p@5p@1054.548.651.144.852.548.651.545.2o47.341.5ob55.4a48.5ac55.6ac48.5ac53.146.555.4ac49.2ac52.947.856.6abc 49.0acTable 7: Performance comparison proposed fusion methods. best resultcolumn boldfaced. Statistically signicant dierences opt. run, run1, run2,run3, marked o, a, b, c, respectively.p@5 performance track. (The runs used fused here). referencecomparison, consider query run track yields best p@5query (denoted OptRunPerQuery). also present performance opt. runbaseline, used above, run yields best average p@5 performance pertrack. performance run1 (the (MAP) eective three fused runs)CombMNZ presented reference well.see Table 6 performance BagDupMNZ substantially (and statistically signicantly) better opt. run, run1 CombMNZ performancedierences being, naturally, much higher Table 3. Thus, see usinginter-document similarities fusion yield substantial merits; and, optimizing281fiKhudyak Kozorovitsky & Kurlandfree-parameter values approach per query yields better performance usingvalues queries, could expected. already noted, Section 4.2.5study performance approach using cross-validation set free-parametervalues.also see Table 6 except trec3, performance BagDupMNZmuch inferior (and statistically signicantly so) selecting best-performingrun per query (OptRunPerQuery). surprise performance run1(the eective average among runs fused) also substantially (andstatistically signicantly) worse OptRunPerQuery; observation holdsopt. run, shows dierent runs eective dierent queries.4.2.2 Performance Analysis Proposed Fusion MethodsTable 7 compare performance proposed fusion methods. rst observation using retrieval scores documents lists, top inter-documentsimilarity information, important. Indeed, methods sux Uni useuniform query-similarity estimate, i.e., disregard retrieval scores documentslists, post performance almost always worse counterpartsutilize retrieval scores inducing query similarity. (Compare SetUni SetSumSetMNZ; BagUni BagSum; and, BagDupUni BagDupMNZ.) Furthermore,utilizing retrieval scores results performance almost always better manycases statistically signicant degree run2 run3; performancealso transcends run1 opt. run, except trec9.also see Table 7 bag representation lists yields better performance, general, using set representation. (Compare, example, BagUniSetUni, BagSum SetSum.) Recall bag representation document represented nodes corresponding instances lists, setrepresentation document represented single node. Hence, fact documents occurrences many fused lists draw prestige-status supportvia inter-document-similarities documents fewer occurrences positive impactperformance.Thus, surprise BagSum BagDupMNZ methods use bagrepresentation lists, utilize retrieval scores documents lists,among eective fusion methods proposed.4.2.3 Performance Impact Using Inter-Document-Similaritiesparameter Equation 1 (Section 2) controls reliance retrieval scores versus inter-document similarity information. Setting = 1, i.e., using inter-documentsimilarity information, results XSum methods equivalent CombSUM,XMNZ methods equivalent CombMNZ. Table 3 showed BagSumoutperforms CombSUM BagDupMNZ outperforms CombMNZ. turnstudy performance XSum XMNZ methods respect specialcases, is, CombSUM CombMNZ, respectively.see Table 8 majority relevant comparisons (track evaluationmetric), methods outperforms special case, several dierences282fiFusing Retrieved Lists Based Inter-Document SimilaritiesCombSUMSetSumBagSumtrec3p@5 p@1080.874.682.8 78.0m83.2 78.8mtrec9p@5p@1052.948.559.249.259.648.1trec10p@5 p@1071.2 61.071.2 61.071.2 61.0CombMNZSetMNZBagDupMNZ80.882.083.255.061.3m60.4m71.271.272.074.677.279.0m48.849.247.961.061.061.0trec12p@5p@1053.749.255.448.555.449.253.955.656.6m49.248.549.0Table 8: Comparison similarity-based fusion methods special cases, CombSUM CombMNZ. Best performance column boldfaced. Statisticallysignicant dierence method special case marked m.statistically signicant. therefore conclude inter-document-similaritiesindeed helpful source information fusion.study eect varying value p@5 performance onetwo eective methods, BagDupMNZ, Figure 1. rst observationexcept trec9, values , BagDupMNZ yields performance transcendsrun1, eective among three fused runs; valuesperformance BagDupMNZ also better opt. run. Trec9 exceptionBagDupMNZ outperforms run1, also opt. run, single value . Recalltrec9 performance run1 far better fused runs.Another observation make based Figure 1 tracks 0.6yields better performance attained using lower values . ndingdemonstrates importance utilizing retrieval scores documents specied above.= 1 inter-document-similarities used BagDupMNZ amounts CombMNZ.also see many cases wherein {0.7, 0.8, 0.9} BagDupMNZ outperformsCombMNZ; trec9 trec12 improvements quite substantial. ndingsecho specied regard merits utilizing inter-document-similaritiesfusion. Finally, note performance merits attained using inter-documentsimilarities even emphasized runs fused randomly selectedavailable track (as show Section 4.2.6), rather best(MAP) performing ones used here.4.2.4 AnalysisEffect . similarity-based fusion methods incorporate two free parameters: ,controls reliance retrieval scores versus inter-document-similarities; eectstudied above; and, , number nearest neighbors considerednode graphs use. Figure 2 analyze eect p@5 performanceBagDupMNZ.see Figure 2 small values ( {5, 10, 20}) often yield better performance larger values. nding reported work utilizing nearest283fiKhudyak Kozorovitsky & Kurlandtrec3trec984616082595878p@5p@580765756557454opt. runrun1CombMNZBagDupMNZ72700.10.20.30.40.50.60.70.8opt. runrun1CombMNZBagDupMNZ53520.910.10.20.30.40.50.6trec10trec120.70.80.910.917456727054p@5p@5686652645062opt. runrun1CombMNZBagDupMNZ60580.10.20.30.40.50.60.70.8opt. runrun1CombMNZBagDupMNZ480.910.10.20.30.40.50.60.70.8Figure 1: Eect varying value (refer Equation 1 Section 2) p@5performance BagDupMNZ; = 1 amounts CombMNZ. performanceopt. run, run1 CombMNZ depicted horizontal lines reference.Note: gures scale.neighbors-based graphs re-ranking single retrieved list (Diaz, 2005; Kurland & Lee,2005). Furthermore, see small values yield performance transcendsrun1 opt. run, except trec9. Another observation make basedFigure 2 corpora, values , BagDupMNZ outperformsspecial case, CombMNZ.Effect k. experimental design used insofar, presentedSection 4.1, based observation attaining high precision top ranks callsfusion relatively short retrieved lists. Indeed, performance numbers presenteddemonstrated eectiveness fusing lists 20 documents each. Figure 3 presenteect k (the number documents retrieved list) p@5 performanceBagDupMNZ CombMNZ.284fiFusing Retrieved Lists Based Inter-Document Similaritiestrec3trec984616082595878p@5p@580765756557454opt. runrun1CombMNZBagDupMNZ72705 102030405075opt. runrun1CombMNZBagDupMNZ53521005 1020304050trec10trec12751007456727054p@5p@5686652645062opt. runrun1CombMNZBagDupMNZ60585 102030405075opt. runrun1CombMNZBagDupMNZ481005 102030405075100Figure 2: Eect p@5 performance. performance opt. run, run1CombMNZ depicted horizontal lines reference. Note: guresscalesee Figure 3 almost values k performance BagDupMNZtranscends CombMNZ. nding also holds respect opt. run, excepttrec9 case. ndings attest merits utilizing inter-documentsimilarities fusion. Furthermore, small values k, specically k = 20 usedheretofore, often yield (near) optimal performance BagDupMNZ CombMNZ.Thus, indeed see fusing short lists, specically, utilizing inter-document similarities, often leads eective precision-at-top-ranks performance.4.2.5 Learning Free-Parameter Valuesperformance numbers presented insofar based free-parameter values yieldoptimal average p@5 performance respect set queries track. experimental setup enabled us study potential performance approach,carefully analyze dierent factors aect it.285fiKhudyak Kozorovitsky & Kurlandtrec3trec9846282605880p@5p@556787654525074opt. runrun1CombMNZBagDupMNZ7270102030405075opt. runrun1CombMNZBagDupMNZ4846100102030405075kktrec10trec121007456727054p@5p@5686652645062opt. runrun1CombMNZBagDupMNZ6058102030405075opt. runrun1CombMNZBagDupMNZ48100k102030405075100kFigure 3: Eect varying k, number documents fused list (run), p@5performance BagDupMNZ. performance opt. run, run1, CombMNZdepicted reference. Note: gures scale.Now, turn explore question whether eective values free parametersmethods, , generalize across queries; is, whether valueslearned9 . end, employ leave-one-out cross validation procedure whereinfree parameters method set query values optimize average p@5performance queries track. resultant performance numbersbest performing methods, BagSum BagDupMNZ, presented Table 9.see Table 9 BagSum BagDupMNZ post better performance,vast majority relevant comparisons (track evaluation measure), opt.run, three runs fused; many performance improvementsstatistically signicant.9. Note analysis different studying effect free-parameter valuesaverage performance presented above.286fiFusing Retrieved Lists Based Inter-Document Similaritiesopt. runrun1run2run3CombSUMBagSumCombMNZBagDupMNZtrec3p@5p@1076.072.274.472.272.867.676.071.280.8ab74.6b83.2oabc 78.8omabc80.8ab74.6b82.4ab79.0omabctrec9p@5p@1060.053.160.053.145.8o38.8o38.3o34.6o52.9bc 48.5bc57.9bc 47.3bc55.0bc 48.8bc60.4m47.9bcbctrec10p@5p@1063.258.863.258.854.450.255.646.8o71.2abc 61.0bc67.6m61.4bcbc71.2abc 61.0bc70.8bc60.4bctrec12p@5p@1054.548.651.144.852.548.651.545.2o53.749.2ac54.7a49.2ac53.949.2ac56.6m49.0acabcTable 9: Performance numbers employing leave-one-out cross validation set freeparameter values. best performance column boldfaced. Statisticallysignicant dierences opt. run, run1, run2, run3, marked o,a, b, c, respectively. Statistically signicant dierences BagSumCombSUM, BagDupMNZ CombMNZ, marked m.next compare methods special cases utilize inter-documentsimilarities. is, compare BagSum CombSUM BagDupMNZCombMNZ. respect p@5 metric performance optimizedlearning phase methods outperform special cases tracks, excepttrec10; improvements also statistically signicant (e.g., referBagDupMNZ versus CombMNZ trec9 trec12). Furthermore, notecases CombSUM CombMNZ outperform methods p@10.attribute nding metric divergence issue (Azzopardi et al., 2003; Morgan et al.,2004; Metzler & Croft, 2005) optimizing performance learning phase respectone metric (p@5 case), testing performance respect anothermetric (p@10 case), albeit somewhat connected. Recall methodsincorporate two free parameters, CombSUM CombMNZ methods incorporatefree parameters. Additional examination Table 9 reveals methods poststatistically signicant improvements runs fused opt. run CombSUMCombMNZ do.all, results demonstrate eectiveness methods employingcross validation set free-parameter values.4.2.6 Fusing Randomly Selected RunsHeretofore, evaluation approach based fusing (MAP) eectiveruns track. turn study eectiveness best performing fusionmethods fusing randomly selected runs.select 20 random triplets runs track. best performing run amongthree denoted run1, second best denoted run2, worst among threedenoted run3. fuse three runs using either standard fusion methods,CombSUM CombMNZ, methods generalize these, namely, BagSum287fiKhudyak Kozorovitsky & Kurlandrun1run2run3CombSUMBagSumCombMNZBagDupMNZtrec3p@5p@1068.957.457.455.442.341.465.6bc 61.3abc76.1m70.4mbcabc65.7bc 61.3abc75.7m70.1mbcbctrec9p@5p@1022.119.616.214.710.910.219.6abc 17.6abc22.0m18.2mabcabc20.0abc 17.5abc21.3m18.0mabcabctrec10p@5p@1032.728.528.524.918.316.032.4bc28.3bc36.6m30.5mabcabc33.6bc28.7bc36.5m30.2mabcabctrec12p@5p@1046.039.939.934.427.423.244.4abc 37.7abc47.8bc 40.6mbc44.4abc 37.7abc46.6bc40.4bcTable 10: Fusing randomly selected runs. performance numbers represent averages20 random samples triplets runs. best performance columnboldfaced. Statistically signicant dierences fusion method run1,run2, run3, marked a, b, c, respectively. Statistically signicant dierences BagSum CombSUM, BagDupMNZCombMNZ, marked m.BagDupMNZ, respectively. performance numbers presented Table 10 representaverages 20 samples.10 free parameters BagSum BagDupMNZset values optimizing average p@5 performance queries track per tripletruns. (The optimization procedure described Section 4.1 used.) Statisticallysignicant dierences two methods determined based average (over 20samples) performance per query.rst observation based Table 10 methods highly eective fusingrandomly selected runs. almost reference comparisons (track evaluation measure),outperform three fused runs; improvements substantialstatistically signicant. exception run1 trec9, outperformsfusion methods.also see Table 10 BagSum slightly eective BagDupMNZ.However, fusing best-performing runs track, case above,picture somewhat reversed. attribute nding relatively low overlaprelevant documents randomly selected runs. Specically, showoverlap much smaller best-performing runs. Thus, use informationregarding multiple appearances lists, quite emphasized BagDupMNZ,signicant merit. Note also holds standard fusion methods. is,superiority CombMNZ CombSUM former emphasizes appearances multiplelists latter less substantial fusing best performingruns.Perhaps important observation make based Table 10methods always eective standard fusion approaches, constitute special cases; is, compare BagSum CombSUM BagDupMNZ10. note drop performance moving run1 run2 run3 highest trec9.many runs trec9 low quality contain relevant documents(Meister et al., 2010).288fiFusing Retrieved Lists Based Inter-Document Similaritiestrec3Best runsRandom runs159.266.9Rel224.625.3156.966.6Rel226.622.8316.27.7trec9Non-Rel12381.1 14.5 4.384.9 12.9 2.2161.478.6Rel225.324.4132.648.5Rel224.627.8trec10Best runsRandom runs316.510.6313.36.3179.478.6Non-Rel2314.0 6.617.8 3.6trec12Non-Rel12377.4 16.0 6.679.6 14.9 5.5342.823.6151.968.0Non-Rel2323.3 24.820.0 12.4Table 11: percentage (non-) relevant documents (of appear leastone three runs fused) appear one (1), two (2) , three (3)runs. number documents, k, considered run 20. three runseither best (MAP) performing track, randomly selected;latter case, percentages represent averages 20 random samples. Percentagesmay sum 100 due rounding.CombMNZ. Many performance dierences also statistically signicant. Furthermore, relevant comparisons, CombSUM CombMNZ outperformedrun1 best performing run among three fused reverse holdsmethods. Thus, results support merits utilizing inter-document similaritiesfusion.4.2.7 Analysis (non-) Relevant Documents Overlap Listsresults presented show using inter-document-similarities highly eectivefusing randomly selected runs. fact, relative performance improvementsstandard fusion methods utilize inter-document similarities largerobserved fusing best-performing runs. Furthermore, ndingspresented attested relative limited merit heavily emphasizing informationregarding multiple appearances documents randomly selected runs respectcase best-performing runs. Hence, turn analyze relevantnon-relevant document overlap runs using randomly-selected runsusing best-performing runs.Table 11 present percentage (non-) relevant documents, appearingleast one three runs fused, appear one, two, three runs.use top-20 documents run above. present percentages threebest-performing runs track three randomly selected runs; latter case,report averages 20 samples triplets runs. cases, percentages averagesqueries track.rst observation based Table 11 tracks, majority relevantdocuments appears one three runs. nding supports motivationapproach; is, using inter-document similarities transfer relevancestatus support dierent (similar) relevant documents across lists. also289fiKhudyak Kozorovitsky & Kurlandsee nding holds non-relevant documents majority non-relevantdocuments appears one three fused runs. note previous reports,supporting certain extent cluster hypothesis, already shown majoritynearest neighbors relevant document similarity space tend relevant;while, non-relevant document tend relevant non-relevant (Kurland,2006). study performed upon documents retrieved response querycase here. Hence, relevant documents tend maintain prestige-status supportwithin set relevant documents, non-relevant documents tend spread supportamong relevant non-relevant documents. Furthermore, percentage non-relevantdocuments appears exactly one run larger relevant documents.nding echoes used explain eectiveness standard fusion methodsemphasize appearance many lists i.e., overlap relevant documentslists higher non-relevant documents (Lee, 1997).also see Table 11 percentage relevant documents appearone run much larger using randomly selected runs using bestperforming runs. words, relevant-document overlap across lists bestperforming-runs case higher randomly-selected runs case. ndinghelps explain observations made above: (i) relative performance gains postedmethods respect standard fusion approaches, utilize interdocument similarities, larger randomly selected runs best performingruns, (ii) heavily emphasizing document appearances multiple runs eectiverandom-runs case best-runs case.explore ndings stated, present Figure 4 percentagerelevant documents appear one three runs function numberdocuments (k) run. evident Figure 4 best-performing runs casepercentages lower randomly-selected runs case, values k.nding supports conclusion regard relative eectivenessapproach best-performing runs versus randomly-selected runs. Furthermore,tracks, values k, least 40% relevant documentsruns fused appear one three runs. nding demonstratesmismatch relevant-document sets runs scenario motivatingdevelopment fusion approach.5. Conclusion Future Workpresented novel approach fusing document lists retrieved responsequery. approach lets similar documents across (and within) lists provide relevancestatus support other. use graph-based method model propagationrelevance status documents lists. propagation governed interdocument-similarities retrieval scores documents lists.Empirical evaluation demonstrated eectiveness approach. showedmethods highly eective fusing TREC runs. nding holds whether runseective per TRECs track (challenge), randomly selected track.also showed performance methods transcends eective standardfusion methods utilize retrieval scores ranks documents.290fiFusing Retrieved Lists Based Inter-Document Similaritiestrec3trec9100% rel docs appear single run% rel docs appear single run10080604020best runsrandom runs010203040507580604020best runsrandom runs01001020304050ktrec10100trec12100% rel docs appear single run100% rel docs appear single run75k80604020best runsrandom runs010203040507580604020best runsrandom runs0100k102030405075100kFigure 4: percentage relevant documents (of appear least onethree runs fused) appear one runs functionnumber documents run (k). runs either best-performingtrack, randomly selected; latter case, numbers represent averages20 random samples.One family proposed methods, namely, set-based family, incorporatefusion method relies retrieval scores/ranks. specically, showedinter-document-similarities utilized, set-based methods reducestandard fusion method incorporate. used CombSUM CombMNZfusion methods examples instantiating set-based fusion approaches. Naturally then,utilizing additional fusion methods rely retrieval scores/ranks future venueintend explore.Another venue intend explore eect approach diversityresults nal result list (Carbonell & Goldstein, 1998); and, exploring ways adaptmethods improve aspect coverage result list (Zhai, Cohen, & Laerty,2003).291fiKhudyak Kozorovitsky & KurlandAcknowledgmentsthank reviewers helpful comments. also thank Malka Gornehelpful comments. paper based upon work supported part Israel ScienceFoundation grant no. 557/09, IBMs SUR award. opinions, ndingsconclusions recommendations expressed material authorsnecessarily reect sponsoring institutions.AppendixProposition 1. Let f fusion method based retrieval scores/ranks, e.g.,CombSUM CombMNZ; f (d) score assigned f document appearsleast one lists fused. Suppose use f (d) query-similarity estimateq) defset-based group methods, is, sim(d,= f (d). Then, using w t[1] (i.e.,setting = 1 Equation 1) results final retrieval score Table 1 (S core(d))rank-equivalent f (d).Proof. node v graph corresponds different document d, |V | incomingq) f (d). Hence, weight unique; sim(d,edges weight P sim(d,q)v V,q)sim(vsolution Equation 2, serves ds nal retrieval score, rank-equivalentf (d).Proposition 2. Using w t[1] BagSum algorithm amounts CombSUM algorithm.Proof. node v graph corresponds document-instance Lji document d;and, |V | incoming edges, weightS(Lji ).v V sim(v ,q)Pweight is, therefore,prestige score P (Lji ; G[] ) v computed Equation 2 . denition, nalPretrieval score i,j:Lj P (Lji ; G[] ). score (following denitionsP(d)above) Li :dLi P Lid , rank-equivalent PCombSU (d).v Vsim(v ,q)Proposition 3. Using w t[1] BagDupMNZ algorithm amounts CombMNZ algorithm.Proof. Let Lji document-instance document d. Following denitions Proposition 2, prestige value single copy Lji newly dened listPSLi (d),q) .sim(vv Vn = #{Li : Li } copies new list. Therefore, denition, nalP(d)retrieval score n Li :dLi P Lid , rank equivalent PCombM N Z (d).v Vsim(v ,q)ReferencesAslam, J. A., & Montague, M. (2001). Models metasearch. Proceedings SIGIR,pp. 276284.Azzopardi, L., Girolami, M., & van Rijsbergen, K. (2003). Investigating relationshiplanguage model preplexity IR precision-recall measures. ProceedingsSIGIR, pp. 369370. Poster.292fiFusing Retrieved Lists Based Inter-Document SimilaritiesBalinski, J., & Danilowicz, C. (2005). Re-ranking method based inter-document distances. Information Processing Management, 41 (4), 759775.Beitzel, S. M., Jensen, E. C., Chowdhury, A., Frieder, O., Grossman, D. A., & Goharian,N. (2003). Disproving fusion hypothesis: analysis data fusion via eectiveinformation retrieval strategies. Proceedings SAC, pp. 823827.Beitzel, S. M., Jensen, E. C., Frieder, O., Chowdhury, A., & Pass, G. (2005). Surrogatescoring improved metasearch precision. Proceedings SIGIR, pp. 583584.Belkin, N. J., Cool, C., Croft, W. B., & Callan, J. P. (1993). eect multiple queryrepresentations information retrieval system performance. Proceedings SIGIR,pp. 339346.Brin, S., & Page, L. (1998). anatomy large-scale hypertextual web search engine.Proceedings 7th International World Wide Web Conference, pp. 107117.Callan, J. P., Lu, Z., & Croft, W. B. (1995). Searching distributed collections inferencenetworks. SIGIR, pp. 2128.Carbonell, J. G., & Goldstein, J. (1998). use MMR, diversity-based rerankingreordering documents producing summaries. Proceedings SIGIR, pp. 335336.Carmel, D., & Yom-Tov, E. (2010). Estimating Query Difficulty Information Retrieval. Synthesis lectures information concepts, retrieval, services. Morgan &Claypool.Chowdhury, A., Frieder, O., Grossman, D. A., & McCabe, M. C. (2001). Analysesmultiple-evidence combinations retrieval strategies. Proceedings SIGIR, pp.394395. poster.Craswell, N., Hawking, D., & Thistlewaite, P. B. (1999). Merging results isolatedsearch engines. Proceedings Australian Database Conference, pp. 189200.Crestani, F., & Wu, S. (2006). Testing cluster hypothesis distributed informationretrieval. Information Processing Management, 42 (5), 11371150.Croft, W. B. (Ed.). (2000a). Advances Information Retrieval: Recent ResearchCenter Intelligent Information Retrieval. No. 7 Kluwer International SeriesInformation Retrieval. Kluwer.Croft, W. B. (2000b). Combining approaches information retrieval. Croft (Croft,2000a), chap. 1, pp. 136.Croft, W. B., & Thompson, R. H. (1984). I3 R: new approach design document retrieval systems. Journal American Society Information ScienceTechnology, 38 (6), 389404.Danilowicz, C., & Balinski, J. (2000). Document ranking based upon Markov chains. Information Processing Management, 41 (4), 759775.Das-Gupta, P., & Katzer, J. (1983). study overlap among document representations.Proceedgins SIGIR, pp. 106114.293fiKhudyak Kozorovitsky & KurlandDiaz, F. (2005). Regularizing ad hoc retrieval scores. Proceedings FourteenthInternational Conference Information Knowledge Management (CIKM), pp.672679.Diaz, F. (2007). Performance prediction using spatial autocorrelation. ProceedingsSIGIR, pp. 583590.Diaz, F. (2008). method transferring retrieval scores collections nonoverlapping vocabularies. Proceedings SIGIR, pp. 805806. poster.Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methodsWeb. Proceedings World Wide Web Conference, pp. 613622, HongKong.Erkan, G. (2006). Language model based document clustering using random walks.Proceedings HLT/NAACL.Erkan, G., & Radev, D. R. (2004). LexRank: Graph-based lexical centrality saliencetext summarization. Journal Artificial Intelligence Research, 22, 457479.Fox, E. A., & Shaw, J. A. (1994). Combination multiple searches. ProceedingsTREC-2.Golub, G. H., & Van Loan, C. F. (1996). Matrix Computations (Third edition). JohnsHopkins University Press.Griths, A., Luckhurst, H. C., & Willett, P. (1986). Using interdocument similarity information document retrieval systems. Journal American Society InformationScience (JASIS), 37 (1), 311. Reprinted Karen Sparck Jones Peter Willett,eds., Readings Information Retrieval, Morgan Kaufmann, pp. 365373, 1997.Katzer, J., McGill, M., Tessier, J., Frakes, W., & Dasgupta, P. (1982). studyoverlap among document representations. Information Technology: Research Development, 1 (2), 261274.Krikon, E., Kurland, O., & Bendersky, M. (2010). Utilizing inter-passage interdocument similarities re-ranking search results. ACM Transactions InformationSystems, 29 (1).Kurland, O. (2006). Inter-document similarities, language models, ad hoc retrieval.Ph.D. thesis, Cornell University.Kurland, O., & Lee, L. (2005). PageRank without hyperlinks: Structural re-ranking usinglinks induced language models. Proceedings SIGIR, pp. 306313.Kurland, O., & Lee, L. (2006). Respect authority! HITS without hyperlinks utilizingcluster-based language models. Proceedings SIGIR, pp. 8390.Kurland, O., & Lee, L. (2010). Pagerank without hyperlinks: Structural reranking usinglinks induced language models. ACM Transactions om Information Systems, 28 (4).Lavrenko, V., & Croft, W. B. (2001). Relevance-based language models. ProceedingsSIGIR, pp. 120127.Lawrence, S., & Giles, C. L. (1998). Inquirus, neci meta search engine. ProceedingsWorld Wide WEB conference, pp. 95105.294fiFusing Retrieved Lists Based Inter-Document SimilaritiesLee, J. H. (1997). Analyses multiple evidence combination. Proceedings SIGIR, pp.267276.Lillis, D., Toolan, F., Collier, R. W., & Dunnion, J. (2006). Probfuse: probabilisticapproach data fusion. Proceedings SIGIR, pp. 139146.Liu, X., & Croft, W. B. (2004). Cluster-based retrieval using language models. ProceedingsSIGIR, pp. 186193.Meister, L., Kurland, O., & Kalmanovich, I. G. (2010). Re-ranking search results usingadditional retrieved list. Information Retrieval, 1.Metzler, D., & Croft, W. B. (2005). Markov random eld model term dependencies.Proceedings SIGIR, pp. 472479.Mihalcea, R., & Tarau, P. (2004). TextRank: Bringing order texts. ProceedingsEMNLP, pp. 404411. Poster.Montague, M., & Aslam, J. A. (2002). Condorcet fusion improved retrieval. Proceedings CIKM, pp. 538548.Morgan, W., Grei, W., & Henderson, J. (2004). Direct maximization average precisionhill-climbing, comparison maximum entropy approach. Tech. rep.04-0367, MITRE Corporation.Otterbacher, J., Erkan, G., & Radev, D. R. (2005). Using random walks question-focusedsentence retrieval. Proceedings Human Language Technology ConferenceConference Empirical Methods Natural Language Processing (HLT/EMNLP),pp. 915922.Pinski, G., & Narin, F. (1976). Citation inuence journal aggregates scientic publications: Theory, application literature physics. Information ProcessingManagement, 12, 297312.Saracevic, T., & Kantor, P. (1988). study information seeking retrieving. iii.searchers, searches, overlap. Journal American Society InformationScience, 39 (3), 197216.Selvadurai, S. B. (2007). Implementing metasearch framework content-directed resultmerging. Masters thesis, North Carolina State University.Shokouhi, M. (2007). Segmentation search engine results eective data-fusion.Proceedings ECIR, pp. 185197.Shou, X. M., & Sanderson, M. (2002). Experiments data fusion using headline information. Proceedgins SIGIR, pp. 413414.Soboro, I., Nicholas, C. K., & Cahan, P. (2001). Ranking retrieval systems without relevance judgments. Proceedings SIGIR, pp. 6673.Tao, T., & Zhai, C. (2006). Regularized esitmation mixture models robust pseudorelevance feedback. Proceedings SIGIR, pp. 162169.Tsikrika, T., & Lalmas, M. (2001). Merging techniques performing data fusionweb. Proceedings CIKM, pp. 127134.van Rijsbergen, C. J. (1979). Information Retrieval (second edition). Butterworths.295fiKhudyak Kozorovitsky & KurlandVogt, C. C., & Cottrell, G. W. (1999). Fusion via linear combination scores. InformationRetrieval, 1 (3), 151173.Voorhees, E. M., Gupta, N. K., & Johnson-Laird, B. (1994). collection fusion problem.Proceedings TREC-3.Voorhees, E. M., & Harman, D. K. (2005). TREC: Experiments evaluation information retrieval. MIT Press.Willett, P. (1985). Query specic automatic document classication. International ForumInformation Documentation, 10 (2), 2832.Xu, J., & Croft, W. B. (1996). Query expansion using local global document analysis.Proceedings SIGIR, pp. 411.Xu, J., & Croft, W. B. (1999). Cluster-based language models distributed retrieval.Proceedings SIGIR, pp. 254261.Yang, L., Ji, D., Zhou, G., Nie, Y., & Xiao, G. (2006). Document re-ranking using clustervalidation label propagation. Proceedings CIKM, pp. 690697.Young, H. P. (1974). axiomatization Bordas rule. Journal Economic Theory, 9,4352.Zamir, O., & Etzioni, O. (1998). Web document clustering: feasibility demonstration.Proceedings SIGIR, pp. 4654.Zhai, C., Cohen, W. W., & Laerty, J. D. (2003). Beyond independent relevance: methodsevaluation metrics subtopic retrieval. Proceedings SIGIR, pp. 1017.Zhai, C., & Laerty, J. (2002). Two-stage language models information retrieval.Proceedings SIGIR, pp. 4956.Zhai, C., & Laerty, J. D. (2001). study smoothing methods language modelsapplied ad hoc information retrieval. Proceedings SIGIR, pp. 334342.Zhang, B., Li, H., Liu, Y., Ji, L., Xi, W., Fan, W., Chen, Z., & Ma, W.-Y. (2005). Improvingweb search results using anity graph. Proceedings SIGIR, pp. 504511.296fiJournal Artificial Intelligence Research 41 (2011) 97-130Submitted 10/10; published 05/11Soft Constraints Difference EqualityEmmanuel Hebrardhebrard@laas.frCNRS; LAASUniversite de ToulouseToulouse, FranceDaniel Marxdmarx@cs.bme.huHumboldt-Universitat zu BerlinBerlin, GermanyBarry OSullivanb.osullivan@cs.ucc.ieCork Constraint Computation CentreDepartment Computer Science, University College CorkCork, IrelandIgor Razgonir45@mcs.le.ac.ukDepartment Computer Science, University LeicesterLeicester, United KingdomAbstractmany combinatorial problems one may need model diversity similaritysets assignments. example, one may wish maximise minimise numberdistinct values solution. formulate problems type use soft variantswell known AllDifferent AllEqual constraints. present taxonomy sixsoft global constraints, generated combining two latter ones two standardcost functions, either maximised minimised. characterise complexityachieving arc bounds consistency constraints, resolving casesNP-hardness neither proven disproven. particular, explore depthconstraint ensuring least k pairs variables common value. showachieving arc consistency NP-hard, however bounds consistency achievedpolynomial time dynamic programming. Moreover, show maximumnumber pairs equal variables approximated factor 12 linear timegreedy algorithm. Finally, provide fixed parameter tractable algorithm respectnumber values appearing two distinct domains. Interestingly,taxonomy shows enforcing equality harder enforcing difference.1. IntroductionConstraints reasoning equality difference within assignments set variables ubiquitous constraint programming. many settings, one needs enforcegiven degree diversity similarity solution. example, university timetablingproblem want ensure courses taken particular student helddifferent times. Similarly, meeting scheduling want ensure participantsmeeting scheduled meet time place. Sometimes, problem over-constrained, might wish maximise extentconstraints satisfied. Consider timetabling example: might wishc2011AI Access Foundation. rights reserved.fiHebrard, Marx, OSullivan & Razgonmaximise number courses scheduled different times studentspreferences cannot met.constraint programming setting requirements diversity similarity amongstvariables specified using global constraints. One commonly used globalconstraints AllDifferent (Regin, 1994), enforces variables take pairwise different values. soft version AllDifferent constraint, named SoftAllDiff,proposed Petit, Regin, Bessiere (2001). proposed two cost metricsmeasuring degree satisfaction constraint, minimisedmaximised: graph- variable-based cost. two cost metrics generic widelyused (e.g., van Hoeve, 2004). former counts number equalities, whilst latter counts number variables change order satisfy corresponding hardconstraint. wish enforce set variables take equal values,use AllEqual, soft variant graph-based cost, SoftAllEqual constraint (Hebrard, OSullivan, & Razgon, 2008), soft variant variable-basedcost, AtMostNValue constraint (Beldiceanu, 2001).considering two constraints (AllDifferent AllEqual), twocosts (graph-based variable-based) objectives (minimisation maximisation)define eight algorithmic problems related constraints difference equality.fact, graph-based costs AllDifferent AllEqual dual, sixdistinct problems thus defined. structure class constraints illustratedFigure 1. one, give complexity best known algorithm achieving ac bc. Three problems studied past: minimising costSoftAllDiff variable (Petit et al., 2001) graph-based cost (van Hoeve, 2004) polynomial whilst maximising variable-based cost SoftAllDiff NP-hard (Bessiere,Hebrard, Hnich, Kiziltan, & Walsh, 2006) ac polynomial (Beldiceanu, 2001)bc. fourth one, maximising variable-based cost SoftAllEqual constraint,directly mapped known problem: Global Cardinality constraint.paper,1 introduce two efficient algorithms achieving, respectively, Arc consistency (ac) Bounds consistency (bc) fifth case, minimising variable-basedcost SoftAllEqual. Moreover, computational complexity last remainingcase, maximising graph-based cost SoftAllDiff (or, equivalently, minimisinggraph-based cost SoftAllEqual) still unknown. Informally, problemmaximise number pairs variables assigned common value. turnschallenging interesting problem, hard yet addressed severalways. particular, show that:Finding solution least k pairs equal variables NP-complete, henceachieving ac corresponding constraint NP-hard.domains contiguous, solved polynomial number stepsdynamic programming, hence achieving bc corresponding constraintpolynomial.exists linear approximation factor12general case.1. Part material presented paper based two conference publications (Hebrard et al.,2008; Hebrard, Marx, OSullivan, & Razgon, 2009).98fiSoft Constraints Difference Equalityvalue appears domains two distinct variables,problem solved general matching, thus defining another tractable class.exists fixed parameter tractable algorithm problem parameterk equal number values appear two distinct domains.Moreover, show constraint defined setting lower bound graphbased cost SoftAllEqual used efficiently find set similar solutionsset problems, instance promote stability regularity. Similarly, dual constraint(SoftAllDiff) used find set diverse solutions, instance sample setconfigurations. Notice two applications motivated, part, choicecost metrics.remainder paper organised follows. Section 2 introduce necessary technical background. complete taxonomy constraints equality difference,based results authors well original material presented Section 3. Then,following sections, present new results allowing us close gapstaxonomy. First, Section 4 present two efficient algorithm achieving ac bcminimising variable-based cost SoftAllEqual. Second, Section 5 giveproof NP-hardness problem achieving ac maximising graph-basedcost SoftAllDiff. Third, Section 6 present polynomial algorithm achievebc constraint. Finally, remaining sections, explore algorithmicproperties preference cost. Section 7, show natural greedy algorithmapproximates maximum number equalities within factor 21 , complexity brought linear time. Next, Section 8, identify polynomialclass constraint. Then, Section 9, identify parameter based classshow SoftAllEqualG constraint fixed-parameter tractable respectparameter. Finally, Section 10, show results obtained paperapplied sample solutions or, conversely, promote stability. particular,describe two constructions using SoftAllDiffminSoftAllEqualminrespectively.GGConcluding remarks made Section 11.2. Backgroundsection present necessary background required reader introducenotation use throughout paper.2.1 Constraint Satisfactionconstraint satisfaction problem (CSP) triplet P = (X , D, C) X setvariables, mapping variables finite sets values C set constraintsspecify allowed combinations values subsets variables. Without loss generality,assume D(X) Z X X , denote min(X) max(X) minimummaximum values D(X), respectively. assignment set variables X setpairs |X | = |S| X X , exists (X, v) v D(X).constraint C C arc consistent (ac) iff, variable scope C assignedvalue, exists assignment variables C C satisfied.satisfying assignment called domain support value. Similarly, call99fiHebrard, Marx, OSullivan & Razgonrange support assignment satisfying C, values, instead takendomain variable (v D(X)), integer minimummaximum domain following natural order Z (v [min(X), . . . , max(X)]) .constraint C C range consistent (rc) iff every value every variable scope Crange support. constraint C C bounds consistent (bc) iff every variable Xscope C, min(X) max(X) range support. Given CSP P = (X , D, C),shall use following notation throughout paper: n shall denote numbervariables,P i.e., n = |X |; shall denote number distinct unaryassignments, i.e.,= XX |D(X)|; shall denote total set values, i.e., = XX D(X); finally,shall denote total number distinct values, i.e., = ||.2.2 Soft Global ConstraintsAdding cost variable constraint represent degree violation common practice constraint programming. model introduced Petit, Regin,Bessiere (2000). offers advantage unifying hard soft constraints since arc consistency, along types consistencies, applied constraintsextra effort. consequence, classical constraint solvers model over-constrainedproblems way without modification. approach applied numberconstraints, instance van Hoeve, Pesant, Rousseau (2006). Several costmetrics explored AllDifferent constraint, well several others(e.g., Beldiceanu & Petit, 2004). important, one uses unifying model,cost metric chosen evaluated polynomial time given complete assignmentvariables constrained. case two metrics consideredpaper constraints AllDifferent AllEqual.variable-based cost counts many variables need change order obtainvalid assignment hard constraint. viewed smallest Hamming distancerespect satisfying assignment. graph-based cost counts many timescomponent decomposition constraint violated. Typically componentscorrespond edges decomposition graph, e.g. AllDifferent constraint,decomposition graph clique edge violated variables connectededge share value. following example, still AllDifferentconstraint, shows two solutions involving four variables X1 , . . . , X4 domain {a, b}:S1 = {(X1 , a), (X2 , b), (X3 , a), (X4 , b)}.S2 = {(X1 , a), (X2 , b), (X3 , b), (X4 , b)}.solutions, least two variables must change (e.g., X3 X4 ) obtain validsolution. Therefore, variable-based cost 2 S1 S2 . However, S1 twoedges violated, (X1 , X3 ) (X2 , X4 ), whilst S2 , three edges violated, (X2 , X3 ),(X2 , X4 ) (X3 , X4 ). Thus, graph-based cost S1 2 whereas 3 S2 .2.3 Parameterised Complexityshall use notion parameterised complexity Section 9. refer readerNiedermeiers (2006) book comprehensive introduction. Given problem A,100fiSoft Constraints Difference Equalityparameterised version obtained specifying parameter problem gettingadditional input non-negative integer k restricts value parameter.resulting parameterised problem hA, ki fixed-parameter tractable (FPT) respectk solved time f (k) nO(1) , f (k) function depending k.size problem significantly larger parameter k, fixed-parameteralgorithm essentially polynomial behaviour. instance f (k) = 2k then, longk bounded log n, problem solved polynomial time.3. Taxonomysection introduce taxonomy soft constraints based AllDifferentAllEqual. consider eight algorithmic problems related constraints difference equality defined combining two constraints, two costs (graph-basedvariable-based), two objectives (minimisation maximisation). fact,graph-based costs AllDifferent AllEqual dual, six different problemsdefined. Observe consider costs defined inequalities, ratherequalities. several reasons so. First, reasoning lower boundupper bound cost variable yield two extremely different problems, hencedifferent algorithmic solutions. instance, shall see cases problemtractable one direction, NP-hard direction. reasoning costequality, one often separate inference procedures relative lower bound, upper bound, intermediate values. Reasoning lower upper bounds sufficientmodel equality although might hinder domain filtering intermediate valuescost forbidden. thus cover equalities restricted way, albeit arguablyreasonable practice. Indeed, dealing costs objectives, reasoninginequalities bounds useful practice imposing (dis)equalities.close last remaining cases: complexity achieving ac bc SoftAllEqualminVSection 4, achieving ac SoftAllEqualminSection5achievGing bc SoftAllEqualminSection 6. Based results, Figure 1Gcompleted (fourth fifth columns).next six paragraphs correspond six columns Figure 1, is, twelveelements taxonomy. them, briefly outline current state art,using following assignment recurring example illustrate various costs:S3 = {(X1 , a), (X2 , a), (X3 , a), (X4 , a), (X5 , b), (X6 , b), (X7 , c)}.3.1 SoftAllDiff: Variable-based cost, MinimisationDefinition 1 (SoftAllDiffminV )SoftAllDiffminV ({X1 , . . . , Xn }, N ) N n |{v | Xi = v}|.cost minimise number variables need changed orderobtain solution satisfying AllDifferent constraint. instance, cost S34 since three four variables assigned well one variables assignedb must change. objective function first studied Petit et al. (2001),algorithm achieving ac O(n m) introduced. best knowledge,101fiHebrard, Marx, OSullivan & RazgonAllEqualAllDifferentgrapminxaxaxxleminvariabphgrahvableriaEftfVaxfVValquValquEftGalqu axEf Gft llDftaxGalquEf Gft llDftaxftftO(n m) NP-hard O(nm) NP-hard O(nm) O(n m)[1][2][4][5][6][8]O(n m) O(n log n) O(nm) O(min( , n )nm)O(n log n)O(n log n)2[1][3][4]2[6][7][8]Figure 1: Complexity optimising difference equality first row: ac, second row: bc.Parameter n denotes number variables, sum domain sizesnumber distinct values. References: [1] (Petit et al., 2001), [2] (Bessiereet al., 2006), [3] (Beldiceanu, 2001), [4] (van Hoeve, 2004), [5] (Hebrard et al.,2008), [6] (Hebrard et al., 2009), [7] (present paper), [8] (Quimper et al., 2004).algorithm better time complexity special case bounds consistencyproposed constraint. Notice however Mehlhorn Thiels (2000) algorithmachieves bc AllDifferent constraint O(n log n) time complexity.question whether algorithm could adapted achieve bc SoftAllDiffminVremains open.3.2 SoftAllDiff: Variable-based cost, MaximisationDefinition 2 (SoftAllDiffmax)VSoftAllDiffmax({X1 , . . . , Xn }, N ) N n |{v | Xi = v}|.Vcost maximised. words, want minimise numberdistinct values assigned given set variables, since complement numbern exactly number variables modify order obtain solution satisfyingAllDifferent constraint. instance, cost S3 4 number distinctvalues 7 4 = 3. constraint studied name AtMostNValue.algorithm O(n log n) achieve bc proposed Beldiceanu (2001), proofachieving ac NP-hard given Bessiere et al. (2006).102fiSoft Constraints Difference Equality3.3 SoftAllDiff: Graph-based cost, Minimisation & SoftAllEqual:Graph-based cost, MaximisationDefinition 3 (SoftAllDiffminSoftAllEqualmaxGG )SoftAllDiffminG ({X1 , . . . , Xn }, N ) N |{{i, j} | Xi = Xj & < j}|.cost minimise number violated constraints decomposingAllDifferent clique binary NotEqual constraints. instance, costS3 7 since four variables share value (six violations) two share valueb (one violation). Clearly, equivalent maximising number violated binaryEqual constraints decompositionglobal AllEqual. Indeed, two costscomplementary n2 (on S3 : 7 + 14 = 21). algorithm O(nm)achieving ac constraint introduced van Hoeve (2004). Again,knowledge algorithm improving complexity special case bc.3.4 SoftAllEqual: Graph-based cost, Minimisation & SoftAllDiff:Graph-based cost MaximisationSoftAllDiffmaxDefinition 4 (SoftAllEqualminG )GSoftAllEqualminG ({X1 , . . . , Xn }, N ) N |{{i, j} | Xi 6= Xj & < j}|.consider two complementary costs, however aim optimisingopposite way. Section 5 show achieving ac constraint NP-hard and,Section 6 show that, domains contiguous intervals, computing optimalcost done O(min(n2 , n3 )). consequence, bc achieved polynomialtime.3.5 SoftAllEqual: Variable-based cost, MinimisationDefinition 5 (SoftAllEqualminV )SoftAllEqualminV ({X1 , . . . , Xn }, N ) N n max(|{i | Xi = v}|).vcost minimise number variables need changed orderobtain solution satisfying AllEqual constraint. instance, cost S3 3 sincefour variables already share value. equivalent maximising numbervariables sharing given value. Therefore bound computed trivially countingoccurrences every value domains. However, pruning domains accordingbound without degrading time complexity trivial. Section 4,introduce two filtering algorithms, achieving ac rc complexitycounting values.3.6 SoftAllEqual: Variable-based cost, MaximisationDefinition 6 (SoftAllEqualmax)V({X1 , . . . , Xn }, N ) N n max(|{i | Xi = v}|).SoftAllEqualmaxVv103fiHebrard, Marx, OSullivan & Razgoncost maximised. words want minimisemaximum cardinality value. instance, cost S3 3, is, complementn maximum cardinality value (3 = 7 4). exactly equivalentapplying Global Cardinality constraint (considering upper boundscardinalities). Two algorithms, achieving ac bc constraint runningO( nm) O(n log n) respectively, introduced Quimper et al. (2004).4. Complexity Arc Bounds Consistency SoftAllEqualminVshow achieve ac, rc bc SoftAllEqualminconstraints (seeVDefinition 5). constraint satisfied n minus cardinalityset variables assigned single value less equal value costvariable N . words, satisfied least k variables sharing value,k = n max(N ). Therefore, simplicity sake, shall consider followingequivalent formulation, N lower bound complement n cost(N 0 = n N ):N 0 max(|{i | Xi = v}|).vshall see filter domain N 0 Xi need compute two properties:1. upper bound k number occurrences amongst values.2. set values actually appear k times.Computing set values appear largest possible number variable domainsperformed trivially O(m), counting number occurrences every value,i.e., number variables whose domain contains v.However, domains discrete intervals defined lower upper bounds,done even efficiently. Given two integers b, b, say setintegers x, x b, interval denote byS[a, b]. rest sectionshall assume overall set values values = XX D(X) interval [1, ].Definition 7 (Occurrence function derivative) Given constraint network P =(X , D, C), occurrence function occ mapping values N definedfollows:occ(v) = |{X | X X & v doms(X)}|.derivative occ, occ , maps value v difference valueocc(v 1) occ(v):occ (0) = 0,occ (v) = occ(v) occ(v 1).give example occurrence function set variables interval domainsFigure 2.Algorithm 1 computes occ1 , is, inverse occurrence function, mapsevery element interval [1, n] set values appearing many times. runs104fiX65X54variablesvariablesSoft Constraints Difference EqualityX4X332X21X1011540607090100115values40607090100values(a) Intervals(b) Occurrence functionFigure 2: set intervals (a) corresponding occurrence function (b).Algorithm 1: Computing inverse occurrence function.Data: set variables: XResult: occ1 : [1, n] 7 2occ (v) ;1 foreach X Xocc (min(X)) occ (min(X)) + 1;occ (max(X) + 1) occ (max(X) + 1) 1;2 x [1, n], occ1 (x) ;x 0;pop first element (v, a) occ ;repeatpop first element (w, b) occ ;x x + occ (a);occ1 (x) occ1 (x) [a, b 1];b;occ = ;O(n log n) worst-case time complexity assume easy extract upperbound (k N 0 ) set values appear k times occ1 .idea behind algorithm, shall reuse throughout paper,domains given discrete intervals one compute non-null values derivativeocc occurrence function occ O(n log n) time. procedure closely relatedconcept sweep algorithms (Beldiceanu & Carlsson, 2001) used, instance, implementfiltering algorithms Cumulative constraint. Instead scanning entire horizon,one jump event next, assuming nothing changes two events.case Cumulative constraint, events correspond start end pointsdomains. fact, possible compute lower bound,complexity, using Petit, Regin, Bessieres (2002) Range-based Max-CSP Algorithm(RMA)2 reformulation Max-CSP. Given set variables XS, add extravariable Z whose domain union domains X : D(Z) = = XX D(X).2. thank anonymous reviewer made observation.105fiHebrard, Marx, OSullivan & Razgonlink variables X binary equality constraints:X X , Z = X.one-to-one mapping solutions Max-CSP satisfying assignments SoftAllEqualminconstraint (X , N ), value N correspondsVnumber violated constraints Max-CSP. lower bound numberviolations computed RMA lower bound k N computed Algorithm 1 are,therefore, same. Moreover procedures essentially equivalent, i.e., modulomodelling step. Algorithm 1 seen particular case RMA: ordered setintervals computed, subsequently associated violation cost. However,use formalism, since notion occurrence function derivative importantused throughout paper.first define simple data structure shall use compute representfunction occ . specific data structure required since indexing image occ (v)value v would add factor (space therefore time) complexity. non-zerovalues occ stored list pairs whose first element value v [1, . . . , ]second element stands occ (v). list maintained increasing order pairsfirst element. Given ordered list occ = [(v1 , o1 ), . . . , (vk , ok )], assignment operationocc (vi ) oi therefore done O(log |occ |) steps follows:1. rank r pair (vj , oj ) vj minimum vj vi computeddichotomic search.2. vi = vj , pair (vj , oj ) removed.3. pair (vi , oi ) inserted rank r.Moreover, one access element minimum (resp. maximum) first elementconstant time since first (resp. last) list. Finally, value occ (vi ) oiexists pair (vj , oj ) list, 0 otherwise. Computing value alsodone logarithmic time.derivative occ (v) computed Loop 1 Algorithm 1 using assignmentoperator defined above. Observe D(X) = [a, b], X contributes twovalues occ : increases occ (a) 1 decreases occ (b + 1) 1. every value wX min(X) = w max(X) + 1 = w, occ (w) null.words, define occ (v) value v, follows:occ (v) = (|{i | min(Xi ) = v}| |{i | max(Xi ) = v 1}|).Therefore, going every variable X X , compute non-null valuesocc time O(n log n) using simple list structure described above.Then, starting Line 2, compute occ1 going non-zero values vderivative, i.e. occ (v) 6= 0, increasing order v. Recall useordered list, trivially done linear time. definition, occurrence functionconstant interval defined two successive values. Since number non-zerovalues occ bounded O(n), overall worst-case time complexity O(n log n).use Figure 3 (a,c & d) illustrate execution Algorithm 1. First, six variables106fiX6X6X5X5variablesvariablesSoft Constraints Difference EqualityX4X3X4X3X2X2X1X1115406070901001values========+2+22+1+111240607090100values(a) Intervalsocc (1)occ (15)occ (41)occ (60)occ (70)occ (71)occ (91)occ (101)15(b) Pruningocc1 (2)occ1 (3)occ1 (4)==={[1, 14] [41, 59] [91, 100]}{[60, 69] [71, 90]}{[15, 40] [70, 70]}(d) Inverse occurrence function.(c) Derivative occurrence function.Figure 3: Execution Algorithm 1: set intervals (a). set intervalsinconsistent sub-intervals lower bound number equalities 4 (N4) represented dashed lines (b). (c) (d) represent derivative,inverse occurrence function initial set intervals, respectively.domains represented Figure 3(a). Then, Figures 3(c) 3(d) showderivative inverse, respectively, occurrence function.Alternatively, < n log n, possible compute occ1 O(n + ) replacingdata structure used store occ simple array, indexed values [1, ]. Accessingupdating value occ thus done constant time.show prune variables X respect bound withoutdegrading time complexity. According method used can, therefore, achieveac rc worst-case time complexity O(m) O(min(n + , n log n), respectively.Theorem 1 Enforcing ac (resp. rc) SoftAllEqualminachieved O(m)Vsteps (resp. O(min(n + , n log n)).Proof. suppose, without loss generality, current lower bound N 0 k.first compute inverse occurrence function either counting values, consideringinterval domains using Algorithm 1. define set values highestnumber occurrences. Let number occurrences k , corresponding setvalues V (i.e. occ1 (k ) = V ). three cases consider:107fiHebrard, Marx, OSullivan & Razgon1. First, every value appears strictly fewer k domains (k < k)constraint violated.2. Second, least one value v appears domains least k + 1 variables(k > k), build support every value w D(X). Let v V ,assign variables X \ X v possible. resulting assignmentleast k occurrences v, hence consistent. Consequently, since k > k, everyvalue consistent.3. Otherwise, neither two cases hold, know value appearsk domains, least one appears k times. Recall V denotesset values. case, pair (X, v) inconsistentv 6 V & V D(X).first suppose condition hold show buildsupport. v V clearly assign every possible variable v achievecost k. V 6 D(X), consider w w V w 6 D(X).assigning every variable w possible achieve cost k mattervalue assigned X.suppose v 6 V & V D(X) holds show (X, v)ac support. Indeed, X assigned v domains valueappears k domains more, since every value V one fewer occurrence,hence back Case 1.Computing set V values satisfying condition done easilyinverse occurrence function computed. one hand, function occ1computed counting every value every domain, supports usedproofs domain supports, hence ac achieved. hand, domainsapproximated bounds Algorithm 1 used instead, supports rangesupports, hence rc achieved. Case 3, domain pruned set Vvalues whose number occurrences k, illustrated Figure 3 (b).2achieved O(min(n+, n log n)Corollary 1 Enforcing bc SoftAllEqualminVsteps.Proof. direct implication Theorem 1.2proof Theorem 1 yields domain filtering procedure. Algorithm 2 achieves eitherac rc depending version Algorithm 1 used Line 1 compute inverseoccurrence function. later function occ1 used Line 2, 3 4 to, respectively,catch global inconsistency, prune upper bound N 0 prune domainsvariables X .Figure 3(b) illustrates pruning one achieve X provided lowerbound N 0 equal 4. Dashed lines represent inconsistent intervals. set Vvalues used Line 4 Algorithm 2 occ1 (4) = {[15, 40] [70, 70]}.108fiSoft Constraints Difference Equality0Algorithm 2: Propagation SoftAllEqualminV ({X1 , . . . , Xn }, N ).1 occ1 Algorithm 1;ub n;occ1 (ub) =ub ub 1;2 min(N 0 ) > ub fail;elsemax(N 0 ) ub;min(N 0 ) = max(N 0 )V occ1 (min(N 0 ));4foreach X X V D(X) D(X) V ;35. Complexity Arc Consistency SoftAllEqualminGshow achieving ac SoftAllEqualminNP-hard. order achieveGac need compute arc consistent lower bound cost variable N constrainedfollows:N |{{i, j} | Xi 6= Xj & < j}|.words, want find assignment variables X minimising numberpairwise disequalities, maximising number pairwise equalities. considercorresponding decision problem (SoftAllEqualminG -decision), showNP-hard reduction 3dMatching (Garey & Johnson, 1979).Definition 8 (SoftAllEqualminG -decision)Data: integer N , set X variables.Question: exist mapping : X 7 X X , s[X] D(X)|{{i, j} | s[Xi ] = s[Xj ] & 6= j}| N ?Definition 9 (3dMatching)Data: integer K, three disjoint sets X, Y, Z, X Z.Question: exist |M | K m1 , m2 M, {1, 2, 3}, m1 [i] 6=m2 [i]?Theorem 2 (The Complexity SoftAllEqualminG ) Finding satisfying assignmentminSoftAllEqualG constraint NP-complete even value appearsthree domains.Proof. problem SoftAllEqualminG -decision clearly NP: checking numberequalities assignment done O(n2 ) time.use reduction 3dMatching show completeness. Let P = (X, Y, Z, T, K)instance 3dMatching, where: K integer; X, Y, Z three disjoint setsX Z = {x1 , . . . , xn }; = {t1 , . . . , tm } set triplets X Z.build instance SoftAllEqualminfollows:G1. Let n = |X| + |Y | + |Z|, build n variables {X1 , . . . , Xn }.2. tl = hxi , xj , xk , l D(Xi ), l D(Xj ) l D(Xk ).109fiHebrard, Marx, OSullivan & Razgon3. pair (i, j) 1 < j n, put value (|T | + (i 1) n + j)D(Xi ) D(Xj ).show exists matching P size K exists solutionb 3K+n2 c equalities. refer matching P solutionmatching solution throughout proof, respectively.: show exists matching cardinality K exists solutionleast b 3K+n2 c equalities. Let matching cardinality K. build solutionfollows. tl = hxi , xj , xk assign Xi , Xj Xk l (item 2 above).Observe remain exactly n 3K unassigned variables process. pickarbitrary pair unassigned variables assign common value (item 3above), one variable left (if one variable left assign arbitraryvalue). Therefore, solution obtained way exactly b 3K+n2 c equalities, 3Kvariables corresponding matching b n3Kcremainingvariables.2: show cardinality maximal matching K, solutionb 3K+n2 c equalities. Let solution. Furthermore, let L numbervalues appearing three times S. Observe set values correspondsmatching. Indeed, value l appears three domains D(Xi ), D(Xj ) D(Xk )exists triplet tl = hxi , xj , xk (item 2 above). Since variableassigned single value, values appearing three times solution form matching.Moreover, since value appears three domains, values appeartwice. Hence number equalities less equal b 3L+n2 c, Lsize matching. follows matching cardinality greaterK, solution b 3K+n22 c equalities.Cohen, Cooper, Jeavons, Krokhin (2004) showed language soft binaryequality constraints NP-complete, three distinct values. one hand,Theorem 2 applies specific class problems constraint network formedsoft binary constraints clique. hand, proof requires unbounded number values, two results therefore incomparable. However, shallsee Section 9 problem fixed parameter tractable respect numbervalues, hence polynomial bounded.6. Complexity Bounds Consistency SoftAllEqualminGsection introduce efficient algorithm that, assuming domains discreteintervals, computes maximum possible pairs equal values assignment.therefore need solve optimisation version problem defined previoussection (Definition 8):Definition 10 (SoftAllEqualminG -optimisation)Data: set X variables.Question: maximum integer K exists mapping : X 7satisfying X X , s[X] D(X) |{{i, j} | s[Xi ] = s[Xj ] & 6= j}| = K?algorithm introduce allows us close last remaining open complexity questionFigure 1: bc SoftAllEqualminconstraint. improve reducingGtime complexity thanks preprocessing step.110fiSoft Constraints Difference Equalityuse terminology Section 4, refer set integers xx b interval [a, b]. Let X set variables considered CSPassume domains variables X sub-intervals [1, ]. denoteME(X ) set assignments P variables X number pairsequal values P maximum possible. subset X containing variableswhose domains subsets [a, b] denoted Xa,b . subset Xa,b includingvariables containing given value c domains denoted Xa,b,c . Finallynumber pairs equal values element ME(Xa,b ) denoted Ca,b (X )Ca,b considered set variables clear context. notational convenience,b < a, set Xa,b = Ca,b = 0. value C1, (X ) number equal pairsvalues element ME(X ).Theorem 3 C1, (X ) computed O((n + )2 ) steps.Proof. problem solved dynamic programming approach: every a, b1 b , compute Ca,b . main observation makes possible usedynamic programming following: every P ME(Xa,b ) value c (a c b)every variable X Xa,b,c assigned value c. see this, let value c valueassigned P maximum number variables. Suppose variableX c D(X) assigned P different value, say c0 . Suppose cc0 appear x variables, respectively. changing value X c0 c,increase number equalities x (y 1) 1 (since x y), contradictingoptimality P .Notice Xa,b \ Xa,b,c disjoint union Xa,c1 Xc+1,b (if c 1 <c + 1 > b, corresponding set empty). two sets independentsense value appear variables sets. Thusassumed P ME(Xa,b ) restricted Xa,c1 Xc+1,b elements ME(Xa,c1 )ME(Xc+1,b ), respectively. Taking consideration possible values c, get|Xa,b,c |Ca,b = max+ Ca,c1 + Cc+1,b .(1)c,acb2first step Algorithm 3, compute |Xa,b,c | values a, b, c.triple a, b, c, easy compute |Xa,b,c | time O(n), hence valuescomputed time O(n3 ). However, running time reduced O((n + )2 )using idea Algorithm 1.pair a, b, compute numberoccurrences value c first computing derivative a,b . precisely, definea,b (c) = |Xa,b,c | |Xa,b,c1 | compute a,b (c) every < c b (Algorithm 3, Line 1-2).Thus going variables, compute a,b (c) values fixed a, bc b time O(n) also compute |Xa,b,a | timebound. possible compute values |Xa,b,c |, < c b time O() usingequality |Xa,b,c | = |Xa,b,c1 | + a,b (c) iteratively (Algorithm 3, Line 3).second step algorithm, compute values Ca,b . compute|values increasing order b a. = b, Ca,b = |Xa,a,a. Otherwise, values Ca,c12Cc+1,b already available every c b, hence Ca,b determined timeO() using Eq. (1) (Algorithm 3, Line 4). Thus values Ca,b computed time111fiHebrard, Marx, OSullivan & RazgonAlgorithm 3: Computing maximum number equalities.Data: set variables: XResult: C1, (X )1 a, b, c , a,b (c) |Xa,b,c | Ca,b 0;foreach k [0, 1]foreach [1, k]b + k;foreach X Xa,b1a,b (min(X)) a,b (min(X)) + 1;2a,b (max(X) + 1) a,b (max(X) + 1) 1;34foreach c [a, b]|Xa,b,c | |Xa,b,c1 | + a,b (c);|+ Ca,c1 + Cc+1,b ));Ca,b max(Ca,b , ( |Xa,b,c2return C1, ;O(3 ), including C1, , value optimum solution problem. Usingstandard techniques (storing Ca,b value c minimises (1)), third stepalgorithm actually produce variable assignment obtains maximum value. 2Ca,bb=1b=2b=3b=4a=11X1,2,1 + C2,2 = 3X1,3,1 + C2,3 = 6X1,4,1 + C2,4 = 16a=2a=3a=400X2,4,4 + C2,3 = 60X3,4,4 + C3,3 = 31X10X9X8variablesX7X6X5X4X3X2X11234valuesFigure 4: set intervals, corresponding dynamic programming Table (Ca,b ).Algorithm 3 computes largest number equalities one achieve assigningset variables interval domains. therefore used find optimal solutioneither SoftAllDiffmaxSoftAllEqualminGG . Notice latter one needstake complement n2 order get value violation cost. Clearly,follows achieving range bounds consistency two constraints done112fiSoft Constraints Difference Equalitypolynomial time, since Algorithm 3 used oracle testing existencerange support. give example execution Algorithm 3 Figure 4. setten variables, X1 X10 represented. give table Ca,b pairsa, b [1, ].complexity reduced n. again, use occurrencefunction, albeit slightly different way. intuition values intervalsvalues dominated other. occurrence function monotonically increasing,means moving toward dominating values (they taken largerset variables), conversely, monotonic decrease denotes dominated values. Noticesince considering discrete values, variations may apparentoccurrence function. instance, consider two variables X respective domains[a, b] [b + 1, c] b c. occurrence function two variablesconstant [a, c]. However, purpose, need distinguish truemonotonicity induced discrete nature problem. therefore considerrational values defining occurrence function. example above,introducing extra point b + 12 occurrence function, capture factfact monotonic [a, c].Let X set variables interval domains [1, ]. Consider occurrencefunction occ : Q 7 [0..n], Q Q set values form a/2 N,min(Q) = 1 max(Q) = . Intuitively, value occ(a) numbervariables whose domain interval encloses value a, formally:Q, occ(a) = |{X | X X , min(X) max(X)}|.function, along corresponding set intervals, depicted Figure 5.crest function occ interval [a, b] Q c [a, b], occmonotonically increasing [a, c] monotonically decreasing [c, b]. instance,set intervals represented Figure 5, [1, 15] crest since monotonically increasing[1, 12] monotonically decreasing [12, 15].Let partition [1, ] set intervals every elementcrest. instance, = {[1, 15], [16, 20], [21, 29], [30, 42]} partition setintervals shown Figure 5. shall map element integer correspondingrank natural order. denote RI (X ) reduction X partition I.reduction many variables X (equation 2 below) domains replacedset intervals overlap corresponding variable X (equation 3below). Observe domains remain intervals reduction.0 }.{X10 , . . . , X|X|RI (X ) =Xi0RI (X ),D(Xi0 )= {I | & D(Xi ) 6= }.(2)(3)instance, set intervals depicted Figure 5 reduced set shownFigure 4, element mapped integer [1, 4].Theorem 4 partition [1, ] every element crest occ,ME(X ) = ME(RI (X )).113fiHebrard, Marx, OSullivan & RazgonX10 [26,42]X9 [10,26]X8 [7,15]X7 [18,32]X6 [16,40]X5 [9,19]X4 [32,38]X3 [1,13]X2 [21,26]X1 [30,40][115] [1620] [21values29] [3042]Figure 5: intervals corresponding occ function.Proof. First, show optimal solution ME(X ), produce solutions0 ME(RI (X )) least many equalities s. Indeed, value a, considerevery variable X assigned value, is, s[X] = a. Let crestcontaining a, definition D(X 0 ). Therefore assign variablesvalue I.show opposite, is, given solution reduced problem, one buildsolution original problem least many equalities. key observationthat, given crest [a, b], intervals overlapping [a, b] common value.Indeed, suppose case, is, exists [c1 , d1 ] [c2 , d2 ]overlapping [a, b] d1 < c2 . occ(d1 ) > occ(d1 + 21 ) similarlyocc(c2 12 ) < occ(c2 ). However, since d1 < c2 b, [a, b] would satisfy conditionscrest, hence contradiction. Therefore, given crest I, every variableX 0 s0 [X 0 ] = I, assign X common value, hence obtaining manyequalities.2show transformation achieved O(n log n) steps.use derivative occurrence function (occ ), however, defined Q rather [1, ]:1occ (v) (|{i | min(Xi ) = v}| |{i | max(Xi ) = v }|).2Moreover, compute O(n log n) steps shown Algorithm 4. first computenon-null values occ looping variable X X (Line 1). use114fiSoft Constraints Difference Equalitydata structure Algorithm 1, hence complexity step O(n log n). Next,create partition crests going derivative identifyinginflection points. variable polarity (Line 3) used keep track evolutionfunction occ. decreasing phases denoted polarity = neg whilst increasingphases correspond polarity = pos. know value v end crest intervalvariable polarity switches neg pos. Clearly, number elements occbounded 2n. Recall list data structure sorted. Therefore, goingvalues occ (v) increasing order v done linear time, hence overallO(n log n) worst-case time complexity.Algorithm 4: Computing partition crests.Data: set variables: XResult:occ ;1 foreach X Xocc (min(X)) occ (min(X)) + 1;occ (max(X) + 12 ) occ (max(X) + 12 ) 1;;min max 1;2 occ 6=3polarity pos;k = 1;repeatpick remove first element (a, k) occ ;max round(a) 1;polarity = pos & k < 0 polarity neg;polarity = pos k < 0 ;add [min, max] I;min max + 1;returnTherefore, replace every crest single value preprocessing stagerun Algorithm 3. Moreover, observe number crests bounded n, sinceneeds least one interval start one interval end. Thus obtainfollowing theorem, n stands number variables, number distinctvalues, sum domain sizes.Theorem 5 Enforcing rc SoftAllEqualminachieved O(min(2 , n2 )nm)Gsteps.Proof. n one achieve range consistency iteratively calling Algorithm 3assigning O(m) unit assignments ((X, v) X X , v D(X)).resulting complexity O(n2 )m (see Theorem 3, term 3 absorbed n2 duen).Otherwise, > n, procedure used, applying reformulationdescribed Algorithm 4. complexity Algorithm 4 O(n log n), sincereformulation = O(n), resulting complexity O(n3 m).2115fiHebrard, Marx, OSullivan & Razgon7. Approximation Algorithmcompleted taxonomy soft global constraints introduced Section 3. However, section rest paper refine analysis problemmaximising number pairs variables sharing value, is, SoftAllEqualminG optimisation (Definition 10).Given solution set variable X , denote obj(s) number equalitiesX .obj(s) = |{{i, j} | s[Xi ] = s[X[j] & 6= j}|.Furthermore, shall denote obj(s ) optimal solution numberequalities solution, respectively. first study natural greedy algorithm approximating maximum number equalities set variables (Algorithm 5).algorithm picks value occurs largest number domains, assignsmany variables possible value (this achieved O(m)). recursivelyrepeats process resulting sub-problem variables assigned (atO(n) times). show that, surprisingly, straightforward algorithm approximatesmaximum number equalities factor 12 worst case. Moreover,implemented run O(m) amortised time. use following data structures3 :var : 7 2X maps every value v set variables whose domains contain v.occ : 7 N maps every value v number variables whose domains contain v.val : N 7 2 maps every integer [0..n] set values appearing exactlydomains.data structures initialised Lines 1, 2 3 Algorithm 5, respectively. Then,Algorithm 6 recursively chooses value largest number occurrences (Line 2),makes corresponding assignments (Line 7) updating current state datastructures (Loop 3).Algorithm 5: Computing lower bound maximum number equalities.Data: set variables: XResult: integer E obj(s )/2 E obj(s )1 var(v) , v XX D(X);foreach X Xforeach v D(X)add X var(v);2 occ(v) |var(v)|, v XX D(X);3 val(k) , k [0..n];foreach v XX D(X)add v val(|var(v)|);return AssignAndRecurse(var, val, occ, n);Theorem 6 (Algorithm Correctness) Algorithm 5 approximates optimal satisfyingassignment SoftAllEqualG constraint within factor 21 - provideddata-structure representing domains respects assumptions - runs O(m).3. describe structures lower level subsequent proof complexity.116fiSoft Constraints Difference EqualityAlgorithm 6: procedure AssignAndRecurse Algorithm 5.1234567Data: mapping: var : 7 2X , mapping: val : N 7 2 , mapping: occ : 7 [0..n],integer: kval(k) = k k 1;k 1return 0;elsepick remove v val(k);foreach X var(v) v D(X)foreach w 6= v D(X)remove w val(occ(w));occ(w) occ(w) 1;add w val(occ(w));assign X v;returnk(k1)+AssignAndRecurse(var, val, k);2Proof. first prove correctness approximation ratio, soundnessalgorithm complexity algorithm.Approximation Factor. proceed using induction number distinct valuescurrent subproblem involving unassigned variables. Let solution computedAlgorithm 5 let optimal solution. denote P () propositionvalues union domains X , obj(s) obj(s )/2. P (1)implies every unassigned variable assigned unique value v. Algorithm 6therefore chooses value assigns variables it. case obj(s) = obj(s ).suppose P () holdsshow P ( + 1) also holds. Let setvariables X problem | XX D(X)| = + 1 let v first valuechosen Algorithm 6. partition variables two subset Xv Xv dependingpresence value v domains.Xv = {X X | v D(X)} set variables whose domains contain v.Xv = X \ Xv complementary set variables contain value v.Using notations, partition equalities two subsets order countthem. first subset equalities involving least one variable Xv ,second subset restricted variables Xv .first compute bound number equalities one achieve X . Letk = |Xv |, let sv optimal solution Xv let obj(sv ) number equalitiessv . variable X Xv , given value w D(X), kvariables X containing w. Indeed, v chosen maximising criterion belongsdomains exactly k variables. Therefore, k(k 1) equalitiesinvolve least variable Xv , since one involved k 1 equalities,k them. Consequently, set variables X , one achievek(k 1) + obj(sv ) equalities.hand, Algorithm 6 assigns every variable Xv v therefore producesk(k 1)/2 equalities involving least one variable Xv . Moreover, observe since vbelong domain Xv , number distinct values Xv .117fiHebrard, Marx, OSullivan & Razgoninduction hypothesis P () therefore used, hence know numberequalities achieved Algorithm 5 subset Xv least obj(sv )/2. Consequently,set variables X , Algorithm 5 achieves least k(k 1)/2 + obj(sv )/2 equalities.Since lower bound number equalities achieved greedy algorithmhalf upper bound computed above, conclude P ( + 1) holds,P ( + 1) also holds.Correctness. show mappings occ val correctly updated callAlgorithm 6. domain variable X changes assigned value vLine 7. case, occurrence every value w D(X) w 6= v decreasedone assigning X v. Indeed, every value w, occ(w) decrementedw removed val(occ(w) + 1) added val(occ(w)).Complexity. show Algorithm 5 runs O(m) steps following assumptions:values consecutive taken set {1, . . . , }.Assigning variable value done constant time.Checking membership value variables domain done constant time.Notice first assumption hold, one rename values. However,would require O( log ) time complexity sort them, well O(n) createnew set domains.every 0 k n, use doubly linked list represent val(k). Moreover usesingle array index + 1 elements store current position every value vlist appears (observe value appears exactly one list). add value vval(k) simply append tail list set index previous length.remove value v val(k), delete element position index[v] val(k).total space complexity data-structure therefore O(). value v, setvariables var(k) implemented simple list, hence O(m) space complexity.mapping occ(v) represented array one element per value, hence O() spacecomplexity.Initialising three mappings done linear time since addition requiresconstant time. step therefore achieved O(m) steps. Line 1 Algorithm 6,k decremented n times total, hence Line 2 executed n timestotal.Observe value chosen Line 2. Moreover, total spacecomplexity var O(m). Therefore, total number steps Loop 3 O(m).Last, observe pair variable/value (X, w) exploredLines 4, 5 6. Indeed, since X assigned v Line 7, never pass conditionLine 3 since subsequent chosen values equal v. overall time complexitythus O(m).2Theorem 7 (Tightness Approximation Ratio) approximation factorAlgorithm 5 tight.11812fiSoft Constraints Difference EqualityProof. Let {X1 , . . . , X4 } set four variables domains follows:X1 {a}; X2 {b}; X3 {a, c}; X4 {b, c}.Every value appears exactly two domains, hence Algorithm 5 choose value.suppose value c chosen first. point value contributeequality, hence Algorithm 5 returns 1. However, possible achieve two equalitiesfollowing solution: X1 = a, X3 = a, X2 = b, X4 = b.28. Tractable Classsection explore connection SoftAllEqualminconstraintGvertex matching. showed earlier general case linked 3dMatching.show particular case value appears two domainssolving SoftAllEqualG constraint equivalent vertex matching problemgeneral graphs, therefore solved polynomial time algorithm. shalluse tractable class show SoftAllEqualG NP-hard unboundednumber values appear two domains.Definition 11 (The VertexMatching Problem)Data: integer K, undirected graph G = (V, E).Question: exist E |M | K e1 , e2 , e1 e2share vertex.Theorem 8 (Tractable Class SoftAllEqualminG ) triplets variables X, Y, ZX D(X) D(Y ) D(Z) = finding optimal satisfying assignmentSoftAllEqualminP .GProof. order solve problem, build graph GX = (V, E) vertexxi variable Xi X , is, V = {xi | Xi X }. pair {i, j}D(Xi ) D(Xj ) 6= , create undirected edge {i, j}; let E = {{i, j} | 6=j & D(Xi ) D(Xj ) 6= }.first show exists matching cardinality K, exists solutionleast K equalities. Let matching cardinality K GX , edgee = (i, j) assign Xi Xj value v D(Xi ) D(Xj ) (by construction,know exists value). Observe variable considered twice sincewould mean two edges matching common vertex. obtained solutiontherefore least |M | equalities.show exists solution K equalities, existsmatching cardinality K. Let solution, let = {{i, j} | S[Xi ] = S[Xj ]}.Observe matching GX . Indeed, suppose two edges sharing vertex(say {i, j}, {j, k}) . follows S[Xi ] = S[Xj ] = S[Xk ], howevercontradiction hypothesis. therefore compute solution maximisingnumber equalities computing maximal matching GX .2tractable class generalised restricting number occurrences valuesdomains variables. notion heavy values key result.119fiHebrard, Marx, OSullivan & RazgonDefinition 12 (Heavy Value) heavy value value occurs twicedomains variables problem.Theorem 9 (Tractable Class Heavy Values) domain D(Xi ) variable Xi contains one heavy value finding optimal satisfying assignmentSoftAllEqualminP .GProof. Consider two stage algorithm. first stage, explore every heavy valuew assign w every variable whose domain contains it. Notice variableassigned twice. second stage, CSP created domains unassignedvariables consists values two occurrences, solve CSPtransforming matching problem suggested proof Theorem 8.show exists optimal solution variable assignedheavy value assigned value. Let optimal solution w heavyvalue set variables cardinality t. suppose z <assigned w . Consider solution s0 obtained assigning variablesw: add exactly t(t 1)/2 z(z 1)/2 equalities. However, potentially removez equalities since values w appear twice. thereforeobj(s0 ) obj(s ) t2 3t z 2 + 3z, non-negative 3 z < t. iterativelyapplying transformation, obtain optimal solution variableassigned heavy value assigned value. first stage algorithmthus correct. second stage correct Theorem 8.29. Parameterised Complexityadvance analysis complexity SoftAllEqualminconstraintGintroducing fixed-parameter tractable (FPT) algorithm respect numbervalues. result important shows complexity propagatingconstraint grows polynomially number variables. may therefore possibleachieve ac reasonable computational cost even large set variables,provided total number distinct values relatively small.first show SoftAllEqualminG -optimisation problem FPT respectnumber values . use tractable class introduced previous sectiongeneralise result, showing problem FPT respect numberheavy values occurring domains containing two heavy values. begindefinition.Definition 13 (Solution Total Order) solution induced total ordervaluess[X] = v w v, w 6 D(X).prove following key lemma.Lemma 1 exists total order set values, solutioninduced optimal.120fiSoft Constraints Difference EqualityProof. Let optimal solution, v value, occ(s , v) numbervariables assigned v . Moreover, let occ total order valuesranked decreasing number occurrences (occ(s , v)) ties broken arbitrarily.show occ induces .Consider, without loss generality, pair values v, w v occ w.definition occ(s , v) occ(s , w). suppose hypothesis falsifiedshow leads contradiction. Suppose exists variable X{v, w} D(X) [X] = w (that is, occ induce ). objective valuesolution s0 s0 [X] = v s0 [Y ] = [Y ] 6= x given by: obj(s0 ) =obj(s ) + occ(s , v) (occ(s , w) 1). Therefore, obj(s0 ) > obj(s ). However, optimal,hence contradiction.2interesting consequence Lemma 1 searching space total ordersvalues enough compute optimal solution. Moreover, fixed-parameter tractabilitySoftAllEqualminconstraint follows easily lemma.GTheorem 10 (FPT number values) Finding optimal satisfying assignmentSoftAllEqualminconstraint fixed-parameter tractable respect , numberGvalues domains constrained variables.Proof. Explore possible ! permutations values. permutation createsolution induced permutation. Compute cost solution. Returnsolution highest cost. According Lemma 1, solution optimal. Creatinginduced solution done selecting domain first value order.Clearly, done O(m). Computing cost given solution donecomputing number occurrences occ(w) summing occ(w) (occ(w) 1)/2values w. Clearly, done O(m) well. Hence theorem follows. 2also derive following corollary Lemma 1:Corollary 2 number optimal solutions CSP SoftAllEqualG!.Proof. According Lemma 1, optimal solution induced order valuesgiven problem. Clearly order induces exactly one solution. Thus numberoptimal solution exceed number total orders !.2Corollary 2 shows number optimal solutions considered problemdepend number variables explored consideringpossible orders values. believe fact interesting practical pointview essence means even enumerating optimal solutions scalablerespect number variables. Moreover, show SoftAllEqualminGfixed-parameter tractable respect number conflicting values, definedfollows.Definition 14 (Conflicting Value) value w given CSP conflicting valueheavy value domain D(X) contains w anotherheavy value.121fiHebrard, Marx, OSullivan & RazgonTheorem 11 (FPT number conflicting values) Let k number conflicting values CSP comprising one SoftAllEqualG constraint. CSPsolved time O(k! n), hence SoftAllEqualminfixed-parameter tractableGrespect k.Proof. Consider permutations conflicting values. permutationperform following two steps. first step variable X twoconflicting values, remove conflicting values except one firstorder among conflicting values D(X) according given permutation.second stage obtain problem domain contains exactly one heavy value.Solve problem polynomially algorithm provided proof Theorem 9.Let solution obtained algorithm. show solution optimal.Let p permutation values considered CSP solutioninduced p highest possible cost. Lemma 1, optimal solution. Let p1permutation conflicting values induced p let s1 solutionobtained algorithm respect p1 . definition s, obj(s) obj(s1 ).show obj(s1 ) obj(s ) optimality immediately follows.Observe X [X] = w w removed D(X)first stage algorithm permutation p1 considered. Indeed, wremoved D(X) preceded p1 value v D(X). follows walso preceded p v consequently (X) 6= w. Thus solution CSPobtained result first stage. However s1 optimal solution CSPTheorem 9 and, consequently, obj(s1 ) obj(s ) required.Regarding runtime, observe execution algorithm consists k! runningalgorithm finding largest bipartite matching given graph. graphn vertices (corresponding variables). Moreover, edge associated valuetwo edges associated value (because matching appliesvalue two occurrences). follows graph edges.According Micali Vazirani (1980), largest matching found O( n),hence upper bound.2constraintresult shows complexity propagating SoftAllEqualminGcomes primarily number (conflicting) values, whereas factors,number variables, little impact. Notice detecting conflicting values donelinear time (O(m)), first counting occurrences every value, flagging valueleast two occurrences heavy finally flagging heavy values conflictingevery domain containing least two them.Observe, moreover, exponential part algorithm based explorationpossible orders given set conflicting values. fact ordering relationtwo values matters values belong domain variable.words consider graph H values given CSP instance. Two valuesb connected edge belong domain variable.Instead considering possible orders given set values may considerpossible ways transforming given graph acyclic digraph. upper boundnumber possible transformations 2E(H) E(H) number edges122fiSoft Constraints Difference EqualityH. sparse graphs bound much optimistic k!. example,average degree vertex 4 number considered partial orders 22k = 4k .10. Finding Set Similar Diverse SolutionsProblems similarity diversity wide range applications. Finding severaldiverse solutions used sample solution space, instance product recommendation (Shimazu, 2001), case-based reasoning (Smyth & McClave, 2001; Aha & Watson,2001) constraint elicitation (Bessiere, Coletta, Koriche, & OSullivan, 2005; Gama, Camacho, Brazdil, Jorge, & Torgo, 2005).Conversely, similarity important problems periodic aspect. instance,schedule timetable may need computed weekly basis, constraints mightchange slightly week week. type problems regularity solutions,is, similarity weeks solution, valuable property (Groer,Golden, & Wasil, 2009).Finally, finding similar solutions set variants problem usefulfind solutions robust uncertainty. Suppose, example, solveTravelling Salesman Problem (TSP), however, costs associated set k 1links pairs cities uncertain variable time. would like findoptimal, near-optimal, route cost traversing link changes,limited amount re-routing sufficient obtain another near-optimal solution.purpose, one build similar structure pictured Figure 6 duplicatingTSP per uncertain link, last original formulation. duplicate,cost corresponding link set expected upper bound. minimisedistance solutions, obtain solution good properties robustness:cost associated ith link increases, solution ith duplicate validalternative avoiding link (if degrades solution quality much) whilst requiringsmall amount re-routing.therefore want find set k solutions either pairwise similar differentset k problems, distinct not. heuristic method introduced solve problemfinding k solutions constraint network, minimum (resp. maximum)distance pairs solutions maximum (resp. minimum) Hebrard, Hnich,OSullivan, Walsh (2005). Since reasoning maximum minimum distance NPhard (Frances & Litman, 1997), proposed use sum Hamming distancesinstead. section, first formally define notion Hamming distancevariables solutions. Next, show constraints studied paperhelp achieve ac rc polynomial time respectively maximising minimisingsum pairwise distances solutions set problem instances.10.1 Hamming Distance:Hamming distance instantiation two variables X definedfollows:1 iff X 6=h (X, ) =0 otherwise123fiHebrard, Marx, OSullivan & RazgonP1 : (X11 , X21 , X31 , . . . , Xn1 )P2 : (X12 , X22 , X32 , . . . , Xn2 )...Pk : (X1k , X2k , X3k , . . . , Xnk )Figure 6: problem P , duplicated k times.Whereas Hamming distance two solutions si sj (over sets variables{X1i , . . . , Xni } {X1j , . . . , Xnj }, respectively) defined as:Xh (si , sj ) =h (X`i , X`j )1`nGiven problem P n variables {X1 , . . . , Xn }, duplicate P k times, identicalconstraints seek set diverse solutions P , altered constraints modelexpected scenarios seek set similar solutions variations P (seeFigure 6).objective maximise minimise sum pairwise distances(sub-)solutions duplicated problems:Xh (si , sj )(4)1i<jk10.2 Constraint Formulation:first approaches problem relied heuristic methods (Hebrard et al., 2005;Hentenryck, Coffrin, & Gutkovich, 2009), also shown problem P allowsit, knowledge compilation methods could efficiently solve problem (Hadzic, Holland, &OSullivan, 2009).show one achieve arc bound consistency maximising objectivefunction. Whilst arc consistency NP-hard minimisation, bounds consistencyachieved polynomial time minimisation maximisation. First, decomposeobjective function described previously (Equation 4) using SoftAllEqualminGSoftAllEqualmaxconstraintsoptimising,respectively,solutionsimilaritydiversity.Gshall see achieving ac (resp. bc) decomposition equivalentachieving ac (resp. bc) global constraint defined bounding objective.Remember row Figure 6 represents duplicate original set variables{X1 , . . . , Xn }. objective function defined sum Hamming distancesevery pair rows. However, consider Figure 6 vertical slices.column corresponds set duplicates {Xij | 1 j k} original originalvariable Xi . One compute contribution set variables sumHamming distances pairs rows number pairwise disequalitiesset: |{{j, k} | Xij 6= Xik & j < k}|. Notice precisely definitioncost minimise (resp. maximise) SoftAllEqualmin(resp. SoftAllEqualmaxGG ).124fiSoft Constraints Difference EqualityTherefore model objective function constraint networks shown Figure 7,respectively minimisation maximisation. Notice that, simplify model, usefollowing, equivalent formulation SoftAllEqualmaxG , rather Definition 3:SoftAllEqualmaxG ({X1 , . . . , Xn }, N ) N |{{i, j} | Xi 6= Xj & < j}|.minimise1 nmaximise1 nP1in Ni subject1kSoftAllEqualminG (Xi , . . . , Xi , Ni )P1in Ni subject1kSoftAllEqualmaxG (Xi , . . . , Xi , Ni )Figure 7: constraint network minimises (resp. maximises) sum distancespairs solutions k vectors variables.Second, notice constraint networks depicted Figure 7 twoconstraints share one variable, Berge-cycle (Berge, 1970)constraint hypergraph, is, sequence C1 , X1 , C2 , . . . , Xk , Ck+1 that:X1 , . . . , Xk distinct variables,C1 , . . . , Ck+1 distinct constraints,k 2 C1 = Ck+1 ,Xi scope Ci Ci+1 .Indeed, SoftAllEqual constraints share variable, overlapsum constraint limited single variable SoftAllEqual. constrainthypergraph therefore Berge-acyclic, constraint networks shownpropagating ac sufficient filter globally inconsistent values (Janssen & Vilarem,1988; Jegou, 1991).Therefore, every constraint network ac (resp. rc), networkglobally arc consistent (resp. globally range consistent). view two constraintnetworks two global constraints, respectively CN div CN sim , set variables{Xij | 1 n, 1 j k} variable N represent objective:CN div ({Xij | 1 n, 1 j k}, N )NX1kNi & 1 n SoftAllEqualmaxG (Xi , . . . , Xi , Ni )1inCN sim ({Xij | 1 n, 1 j k}, N )NX1kNi & 1 n SoftAllEqualminG (Xi , . . . , Xi , Ni )1in125fiHebrard, Marx, OSullivan & RazgonPTheorems 12 13 (where = 1in |D(Xi1 )| denotes sum domain sizesone copy problem) follow from, respectively, (van Hoeve, 2004) Theorem 5:Theorem 12 Enforcing ac CN div ({Xij | 1 n, 1 j k}, N ) achievedO(k 2 m) steps.Proof. Since constraint network equivalent CN div Berge-acyclic, knowac iff every constraint decomposition ac. Moreover, describe filteringalgorithm requires bounded number calls propagator constraintdecomposition.assume variables domain completely wiped process.case, process would interrupted earlier (as soon inconsistencydetected achieving ac component).introduce terminology:property (1) denotes fact 1 n domains variables Xijconsistent upper bounds Ni ,property (2) denotes fact 1 n domains variables Xijconsistent lower bounds Ni ,Pproperty (3) denotes fact sum constraint (N1in Ni ) bc (orequivalently ac).First, domain variable Xij 1 n 1 j k might changed,well lower bound N . change upper bound N either resultsimmediate failure, bears consequences.1. every [1..n], update upper bound variable Ni callingprocedure proposed van Hoeve (2004) find maximum possible numberdisequalities. Hence property (1) holds.2. achieve bc (equivalent ac case) sum constraint. Noticeupper bound N lower bounds Ni 1 n updated,therefore property (1) (3) hold.3. every [1..n], prune domains variables {Xij | 1 j k}calling filtering procedure proposed van Hoeve (2004). Since domainreduction trigger changes bounds Ni , know property(1), (2) (3) hold, hence CN div ac.Pfirst phase requires O( 1in k 2 |D(Xi1 )|), O(k 2 m) steps. second phaserequires O(n) steps. Finally, third phase, like first, requires O(k 2 m) steps. Henceoverall O(k 2 m) time complexity.Theorem 13 Enforcing rc CN sim ({Xij | 1 n, 1 j k}, N ) achievedO(k 4 m) steps.126fiSoft Constraints Difference EqualityProof.proof similar Theorem 12, swap upper lowerbounds, use procedure described Section 6 phase (1) (3).3first phase requires O(ksecond phase requires O(n) steps. Finally,P n) steps.third phase requires O( 1in k 4 |D(Xi1 )|), O(k 4 m) steps. Hence overallO(k 4 m) time complexity.11. Conclusionmany applications concerned stating constraints similarity diversity amongst assignments variables. formulate problems use softvariants well known AllDifferent AllEqual constraints. paperconsidered global constraints AllDifferent AllEqual, optimisationvariants, SoftAllDiff SoftAllEqual, respectively. Furthermore, consideredtwo cost functions, based either Hamming distance satisfying assignmentnumber violations decomposition graph. shown constraint ensuring upper bound Hamming distance solution satisfyingAllEqual constraint propagated efficiently, arc bounds consistency.shown that, one hand, deciding existence assignment minimising number violation decomposition graph AllEqual constraintNP-complete, hence propagating arc consistency constraint ensuring propertyNP-hard. hand, propagating bounds consistency constraintdone polynomial time. Moreover, shown problem fixed parametertractable number distinct values problem. work complements nicelyearlier results Cohen et al. (2004) showing language soft binary equalityconstraints NP-complete, three distinct values domains.paper shown problem remains NP-complete even graph soft binaryequality constraints forms clique, however, becomes polynomial number valuesbounded.paper therefore provides comprehensive complexity analysis achieving acbc important class soft constraints difference equality. Interestingly,taxonomy shows enforcing equality harder enforcing difference.AcknowledgmentsHebrard, OSullivan Razgon supported Science Foundation Ireland (Grant Number 05/IN/I886). Marx supported part ERC Advanced grant DMMCA,Alexander von Humboldt Foundation, Hungarian National Research Fund (GrantNumber OTKA 67651).ReferencesAha, D. W., & Watson, I. (Eds.). (2001). Case-Based Reasoning Research Development,4th International Conference Case-Based Reasoning, ICCBR 2001, Vancouver,BC, Canada, July 30 - August 2, 2001, Proceedings, Vol. 2080 Lecture NotesComputer Science. Springer.127fiHebrard, Marx, OSullivan & RazgonBeldiceanu, N., & Carlsson, M. (2001). Sweep Generic Pruning Technique AppliedNon-Overlapping Rectangles Constraint. Walsh, T. (Ed.), Proceedings 7thInternational Conference Principles Practice Constraint Programming (CP01), Vol. 2239 Lecture Notes Computer Science, pp. 377391, Paphos, Cyprus.Springer-Verlag.Beldiceanu, N., & Petit, T. (2004). Cost evaluation soft global constraints. Regin, J.-C.,& Rueher, M. (Eds.), Proceedings 6th International Conference IntegrationAI Techniques Constraint Programming Combinatorial OptimizationProblems (CPAIOR-04), Vol. 3011 Lecture Notes Computer Science, pp. 8095,Nice, France. Springer-Verlag.Beldiceanu, N. (2001). Pruning Minimum Constraint Family NumberDistinct Values Constraint Family. Walsh, T. (Ed.), Proceedings 7thInternational Conference Principles Practice Constraint Programming (CP01), Vol. 2239 Lecture Notes Computer Science, pp. 211224, Paphos, Cyprus.Springer-Verlag.Berge, C. (1970). Graphs Hypergraphs. Dunod.Bessiere, C., Coletta, R., Koriche, F., & OSullivan, B. (2005). SAT-Based Version SpaceAlgorithm Acquiring Constraint Satisfaction Problems.. Gama et al. (Gamaet al., 2005), pp. 2334.Bessiere, C., Hebrard, E., Hnich, B., Kiziltan, Z., & Walsh, T. (2006). Filtering algorithmsnvalue constraint. Constraints, 11 (4), 271293.Cohen, D., Cooper, M., Jeavons, P., & Krokhin, A. (2004). maximal tractable classsoft constraints. Journal Artificial Intelligence Research, 22, 122.Frances, M., & Litman, A. (1997). Covering Problems Codes. Theory ComputingSystems, 30, 113119.Gama, J., Camacho, R., Brazdil, P., Jorge, A., & Torgo, L. (Eds.). (2005). Machine Learning: ECML 2005, 16th European Conference Machine Learning, Porto, Portugal, October 3-7, 2005, Proceedings, Vol. 3720 Lecture Notes Computer Science.Springer.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-completeness. W.H. Freeman Company.Groer, C., Golden, B., & Wasil, E. (2009). Consistent Vehicle Routing Problem.Manufacturing & Service Operations Management, 11 (4), 630643.Hadzic, T., Holland, A., & OSullivan, B. (2009). Reasoning Optimal CollectionsSolutions. Gent, I. P. (Ed.), Proceedings 15th International ConferencePrinciples Practice Constraint Programming (CP-09), Vol. 5732 LectureNotes Computer Science, pp. 409423, Lisbon, Portugal. Springer-Verlag.Hebrard, E., Hnich, B., OSullivan, B., & Walsh, T. (2005). Finding Diverse SimilarSolutions Constraint Programming. Veloso, M. M., & Kambhampati, S. (Eds.),Proceedings 20th National Conference Artificial Intelligence Seventeenth Conference Innovative Applications Artificial Intelligence (AAAI-05 /IAAI-05), pp. 372377, Pittsburgh, PE, USA. AAAI Press / MIT Press.128fiSoft Constraints Difference EqualityHebrard, E., Marx, D., OSullivan, B., & Razgon, I. (2009). Constraints DifferenceEquality: Complete Taxonomic Characterisation. Gent, I. P. (Ed.), Proceedings15th International Conference Principles Practice Constraint Programming (CP-09), Lecture Notes Computer Science, pp. 424438, Lisbon, Portugal.Springer-Verlag.Hebrard, E., OSullivan, B., & Razgon, I. (2008). Soft Constraint Equality: Complexityapproximability. Stuckey, P. J. (Ed.), Proceedings 14th InternationalConference Principles Practice Constraint Programming (CP-08), LectureNotes Computer Science, pp. 358371, Sydney, Australia. Springer-Verlag.Hentenryck, P. V., Coffrin, C., & Gutkovich, B. (2009). Constraint-based local searchautomatic generation architectural tests. Gent, I. P. (Ed.), Proceedings 15thInternational Conference Principles Practice Constraint Programming (CP09), Vol. 5732 Lecture Notes Computer Science, pp. 787801, Lisbon, Portugal.Springer-Verlag.Janssen, P., & Vilarem, M.-C. (1988). Problemes de satisfaction de contraintes: techniquesde resolution et application la synthese de peptides. C.R.I.M. Research Report..Jegou, P. (1991). Contribution letude des problemes de satisfaction de contraintes: algorithmes de propagation et de resolution. Propagation de contraintes dans les reseauxdynamiques. Ph.D. thesis.Mehlhorn, K., & Thiel, S. (2000). Faster Algorithms Bound-Consistency Sortedness Alldifferent Constraint. Dechter, R. (Ed.), Proceedings 6th International Conference Principles Practice Constraint Programming (CP-00),Vol. 1894 Lecture Notes Computer Science, pp. 306319, Singapore. SpringerVerlag.pMicali, S., & Vazirani, V. V. (1980). o( (|v|)|e|) algorithm finding maximum matching general graphs. FOCS, pp. 1727.Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.Petit, T., Regin, J.-C., & Bessiere, C. (2000). Meta-constraints ViolationsConstrained Problems. 12th IEEE International Conference Tools ArtificialIntelligence (ICTAI-00), pp. 358365.Petit, T., Regin, J.-C., & Bessiere, C. (2001). Specific Filtering Algorithms OverConstrained Problems. Walsh, T. (Ed.), Proceedings 7th International Conference Principles Practice Constraint Programming (CP-01), Vol. 2239Lecture Notes Computer Science, pp. 451463, Paphos, Cyprus. Springer-Verlag.Petit, T., Regin, J.-C., & Bessiere, C. (2002). Range-Based Algorithm Max-CSP.van Hentenryck, P. (Ed.), Proceedings 8th International Conference Principles Practice Constraint Programming (CP-02), Vol. 2470 Lecture NotesComputer Science, pp. 113132, Ithaca, NY, USA. Springer-Verlag.Quimper, C.-G., Lopez-Ortiz, A., van Beek, P., & Golynski, A. (2004). Improved AlgorithmsGlobal Cardinality Constraint. Wallace, M. (Ed.), Proceedings 10thInternational Conference Principles Practice Constraint Programming (CP-129fiHebrard, Marx, OSullivan & Razgon04), Vol. 3258 Lecture Notes Computer Science, pp. 542556, Toronto, Canada.Springer-Verlag.Regin, J.-C. (1994). Filtering Algorithm Constraints Difference CSPs.Hayes-Roth, B., & Korf, R. E. (Eds.), Proceedings 12th National ConferenceArtificial Intelligence (AAAI-94), pp. 362367, Seattle, WA, USA. AAAI Press.Shimazu, H. (2001). Expertclerk: Navigating Shoppers Buying Process Combination Asking Proposing. Nebel, B. (Ed.), Proceedings 17th InternationalJoint Conference Artificial Intelligence (IJCAI-01), pp. 14431450, Seattle, WA,USA. Morgan Kaufmann.Smyth, B., & McClave, P. (2001). Similarity vs. diversity.. Aha, & Watson (Aha &Watson, 2001), pp. 347361.van Hoeve, W.-J. (2004). hyper-arc consistency algorithm soft alldifferent constraint. Wallace, M. (Ed.), Proceedings 10th International ConferencePrinciples Practice Constraint Programming (CP-04), Vol. 3258 LectureNotes Computer Science, pp. 679689, Toronto, Canada. Springer-Verlag.van Hoeve, W.-J., Pesant, G., & Rousseau, L.-M. (2006). Global Warming: Flow-BasedSoft Global Constraints. Journal Heuristics, 12 (4-5), 347373.130fiJournal Artificial Intelligence Research 41 (2011) pages 2567Submitted 09/10; published 05/11Determining Possible Necessary WinnersCommon Voting Rules Given Partial OrdersLirong XiaVincent Conitzerlxia@cs.duke.educonitzer@cs.duke.eduDepartment Computer Science, Duke University,Durham, NC 27708, USAAbstractUsually voting rule requires agents give preferences linear orders. However,cases impractical agent give linear order alternatives.suggested let agents submit partial orders instead. Then, given voting rule,profile partial orders, alternative (candidate) c, two important questions arise:first, still possible c win, second, c guaranteed win?possible winner necessary winner problems, respectively. two problemsdivided two sub-problems: determining whether c unique winner (thatis, c winner), determining whether c co-winner (that is, c setwinners).consider setting number alternatives unbounded votesunweighted. completely characterize complexity possible/necessary winnerproblems following common voting rules: class positional scoring rules (includingBorda), Copeland, maximin, Bucklin, ranked pairs, voting trees, plurality runoff.1. Introductionmultiagent systems, often, agents must make joint decision spite factdifferent preferences alternatives. example, agents maydecide joint plan allocation tasks/resources. general solutionproblem agents vote alternatives. is, agent givesranking (linear order) alternatives; voting rule takes submittedrankings input, based produces chosen alternative (the winner), setchosen alternatives. design good voting rules studied centuriessocial choice community. recently, computer scientists become interestedsocial choicemotivated part applications multiagent systems, alsoapplications. Hence, community interested computational social choice emerged.traditional social choice, agents usually required give linear orderalternatives. However, especially multiagent systems applications, alwayspractical. one, sometimes, set alternatives large. example,generally many possible joint plans allocations tasks/resources agentgive linear order them. settings, agents must use different voting languagerepresent preferences; example, use CP-nets (Boutilier, Brafman,Domshlak, Hoos, & Poole, 2004; Lang, 2007; Xia, Lang, & Ying, 2007a, 2007b; Lang &Xia, 2009). However, agent uses CP-net (or similar language) representpreferences, generally gives us partial order alternatives. Anotherc2011AI Access Foundation. rights reserved.fiXia & Conitzerissue always possible agent compare two alternatives (Pini, Rossi,Venable, & Walsh, 2007). incomparabilities also result partial order.paper, study setting agent, partial order corresponding agents preferences. study following two questions. (1)case that, extension partial orders linear orders, alternative c wins?(2) case that, extension partial orders linear orders, alternative cwins? problems known possible winner necessary winner problems, respectively, introduced Konczak Lang (2005). Depending interpretation cwins, possible/necessary winner problems divided two sub-problems:one called possible/neccessary unique winner problem (here unique often omittedcausing confusion), c wins means c winner election; called possible/necessary co-winner problem, c wins meansc one winners. noted answer depends votingrule used. Previous research also investigated setting uncertaintyvoting rule; here, necessary (possible) winner alternative wins(some) realization rule (Lang, Pini, Rossi, Venable, & Walsh, 2007). paper,study setting; is, rule always fixed.problems motivated observations impracticalitysubmitting linear orders, also relate preference elicitation manipulation.preference elicitation, idea that, instead agent report preferencesonce, ask simple queries preferences (e.g. preferb?), enough information determine winner. Preference elicitation found many applications multiagent systems, especially combinatorial auctions (for overviews, see Parkes, 2006; Sandholm & Boutilier, 2006) voting settingswell (Conitzer & Sandholm, 2002, 2005b; Conitzer, 2009). problem decidingwhether terminate preference elicitation declare winner exactly necessary winner problem. Manipulation said occur agent casts votecorrespond true preferences, order obtain result prefers.GibbardSatterthwaite Theorem (Gibbard, 1973; Satterthwaite, 1975), reasonable voting rule, situations agent successfully manipulate rule.prevent manipulation, one approach taken computational socialchoice community study whether manipulation (or made) computationallyhard (Bartholdi, Tovey, & Trick, 1989a; Bartholdi & Orlin, 1991; Hemaspaandra & Hemaspaandra, 2007; Elkind & Lipmaa, 2005; Conitzer, Sandholm, & Lang, 2007; Faliszewski,Hemaspaandra, & Schnoor, 2008; Zuckerman, Procaccia, & Rosenschein, 2009; Xia, Zuckerman, Procaccia, Conitzer, & Rosenschein, 2009; Faliszewski, Hemaspaandra, & Schnoor,2010). fundamental questions studied Given votes,coalition agents cast votes alternative c wins? (so-called constructive manipulation) Given votes, coalition agents cast votesalternative c win? (so-called destructive manipulation). problemscorrespond possible winner problem (the complement of) necessary winnerproblem, respectively. precise, correspond restricted versions possible winner problem (the complement of) necessary winner problempartial orders linear orders (the nonmanipulators votes) partialorders empty (the manipulators votes). However, uncertainty parts26fiDetermining Possible Necessary Winners Given Partial Ordersnonmanipulators votes, parts manipulators votes already fixed (forexample due preference elicitation), correspond general versionspossible winner problem (the complement of) necessary winner problem.Another related problem evaluation problem (Conitzer et al., 2007).given probability distribution voters vote, asked probabilitygiven alternative wins. shown anonymous voting rule,number alternatives constant, polynomial-time algorithmsolves evaluation problem; number alternatives boundedconstant, problem becomes #P hard plurality, Borda, Copelandrules (Hazon, Aumann, Kraus, & Wooldridge, 2008). complexity influencingdistribution voters votes multiple binary issues make given alternative(a valuation issues) win also studied (Erdelyi, Fernau, Goldsmith,Mattei, Raible, & Rothe, 2009). possible/necessary winner problems relatedevaluation problem following way. every voter assigns positive probabilityevery one linear orders extend partial order, then, alternative c, cpossible winner probability c wins election positive; cnecessary winner probability c wins election 1. mustnote reduction possible/necessary winner problem evaluationproblem general polynomial, partial order, possibleexponentially many linear orders extend it. example, partialorder empty, linear order extension it. However, paper,prove results show possible/necessary winner problem hard evennumber undetermined pairs partial order constant, factpolynomially many linear orders extend it. Hence, hardness results also imply(only NP-)hardness results evaluation problem.variety different interpretations possible necessary winnerproblems, surprising already significant studies problems. Two main settings studied (see Walsh, 2007 good survey). firstsetting, number alternatives bounded, votes weighted. Here,Borda, veto, Copeland, maximin, STV, plurality runoff rules, possible winnerproblem NP-complete; STV plurality runoff rules, necessary winnerproblem coNP-complete (Conitzer et al., 2007; Pini et al., 2007; Walsh, 2007). However,many elections, votes unweighted (that is, agents vote counts same).votes unweighted, number alternatives bounded, possiblenecessary winner problems always solved polynomial time, assuming votingrule executed polynomial time (Conitzer et al., 2007; Walsh, 2007). Hence,setting studied votes unweighted numberalternatives bounded; setting study paper. setting, possible necessary winner problems known hard STV (Bartholdi& Orlin, 1991; Pini et al., 2007; Walsh, 2007). Computing whether alternativepossible necessary Condorcet winner done polynomial time (Konczak & Lang,2005). However, time conference version work (Xia & Conitzer, 2008),common rules, prior results (except fact27fiXia & Conitzerproblems easy many rules partial order either linear orderempty, is, standard manipulation problem).11.1 Contributionspaper, characterize complexity possible necessary winner problemsimportant rulesspecifically, class positional scoring rules,Copeland, maximin, Bucklin, ranked pairs, voting trees, plurality runoff.show possible winner problems NP-complete rules exceptpossible unique winner problem respect plurality runoff. also shownecessary winner problems coNP-complete Copeland, ranked pairs, votingtrees; necessary co-winner problem coNP-complete plurality runoff.remaining cases, present polynomial-time algorithms. results summarizedTable 1.STVPluralityVetoPos. scoring(incl. Borda, k-approval)CopelandMaximinBucklinRanked pairsVoting trees(incl. balanced trees)Plu. w/ runoffPossible WinnerNP-complete(Bartholdi & Orlin, 1991)P2P3NP-complete4NP-completeNP-completeNP-completeNP-complete4NP-complete4444NP-complete (unique winner)P (co-winner)Necessary WinnercoNP-complete(Bartholdi & Orlin, 1991)P2P3PcoNP-completePPcoNP-complete4coNP-complete44P (unique winner)coNP-complete (co-winner)4Table 1: Summary complexity possible/necessary winner problems respectcommon voting rules. Unless otherwise mentioned, results dependwhether consider unique-winner co-winner version problem.1. earlier paper (Konczak & Lang, 2005) studied problems positional scoring rules, claimedproblems polynomial-time solvable positional scoring rules; however, subtlemistake proofs. show possible winner problem fact NP-completepositional scoring rules. also give correct proof necessary winner problem indeedpolynomial-time solvable positional scoring rules.2. Easy prove; also proved work Betzler Dorn (2010), follows bribery algorithmFaliszewski (2008).3. Easy prove, also proved work Betzler Dorn (2010).4. Hardness results hold even number unknown pairs partial orderconstant.28fiDetermining Possible Necessary Winners Given Partial Orderspaper significant extension conference version work (Xia &Conitzer, 2008): extended version includes proofs, results voting trees,plurality runoff, k-approval new. conference version also mentionplurality veto; results easy follow known results, explainedfootnotes table.1.2 Subsequent Work since Conference VersionSince conference version work, complexity possible winner problemrespect positional scoring rule fully characterized (Betzler & Dorn,2010; Baumeister & Rothe, 2010). theorems Betzler Dorn (2010), possiblewinner problem NP-complete respect Borda k-approval. Still, hardnessresults directly imply hardness results obtained positional scoring rulespaperwe prove hardness results Borda k-approval hold evennumber undetermined pairs vote 4.Also, special case possible necessary winner problems new alternativesjoin election voters preferences initial alternatives fullyrevealed proposed studied work Chevaleyre, Lang, Maudet,Monnot (2010). shown possible-winner-with-new-alternatives problemNP-complete maximin, Copeland (Xia, Lang, & Monnot, 2011), k-approvalk 3 least 3 new alternatives (Chevaleyre, Lang, Maudet, Monnot, & Xia,2010); problem P Bucklin (when k 3) (Xia, Lang, & Monnot, 2011), Borda,k-approval (when k 2 two new alternatives) (Chevaleyre,Lang, Maudet, Monnot, & Xia, 2010).Meanwhile, number new results complexity unweighted coalitionalmanipulation problem also obtained. Specifically, unweighted coalitionalmanipulation problem shown NP-hard Copeland 0 1(except = 12 ; results even hold two manipulators) (Faliszewski et al., 2008,2010),5 maximin (two manipulators) ranked pairs (one manipulator) (Xia et al., 2009),specific positional scoring rule (two manipulators) (Xia, Conitzer, & Procaccia, 2010).mentioned before, unweighted coalitional manipulation problem special casepossible winner problem studied paper (where partial orders linearorders others empty); result, NP-hardness results unweightedcoalitional manipulation problem also imply NP-hardness possible winner problemrules. note NP-hardness results proved paper (exceptpossible unique winner problem plurality runoff) hold even partialorder, number pairs alternatives order unknown constant.Therefore, subsequent research unweighted coalitional manipulationcompletely imply NP-hardness results prove paper possiblewinner problem Copeland, maximin, ranked pairs, positional scoring rules.Elkind et al. (2009) showed possible winner problem also reduces swapbribery problem, interested party pay voters swap adjacent alternatives5. Faliszewksi et al. (2008) also study case weighted coalitional manipulation three alternativesCopeland, show hard problem depends whether considerunique-winner co-winner variant problem. study weighted votes paper.29fiXia & Conitzerrankings, price swap two alternatives depends identityalternatives identity voter. is, (with respect fixed voting rule)computational complexity swap bribery problem least highpossible winner problem, terms polynomial-time reductions.complexity possible winner problem also studied fixedparameter tractability perspective, parameters number alternatives,number voters, number unknown pairs vote (Betzler, Hemmann, &Niedermeier, 2009). Finally, counting version possible winner problem alsostudied (Bachrach, Betzler, & Faliszewski, 2010).2. PreliminariesLet C = {c1 , . . . , cm } set alternatives (or candidates). linear order Ctransitive, antisymmetric, total relation C. set linear orders Cdenoted L(C). n-voter profile P C consists n linear orders C. is,P = (V1 , . . . , Vn ), every n, Vi L(C). set profiles C denotedP (C). remainder paper, denotes number alternatives n denotesnumber voters.voting rule r function set profiles C set (nonempty)subsets C, is, r : P (C) 2C \ . following common voting rules.1. (Positional) scoring rules: positional scoring rule defined scoring vector~sm = (~sm (1), . . . , ~sm (m)) non-negative integers, ~sm (1) ~sm (m).vote V L(C) c C, let s(V, c) = ~smP(j), j rankc V . profile P = (V1 , . . . , Vn ), let s(P, c) = ni=1 s(Vi , c). ruleselect c C s(P, c) maximized. examples positional scoring rulesBorda, scoring vector (m 1, 2, . . . , 0), plurality,scoring vector (1, 0, . . . , 0), veto, scoring vector (1, . . . , 1, 0),k-approval (1 k 1), scoring vector (1, . . . , 1, 0, . . . , 0).| {z }kpaper, assume scoring vector computed polynomial time.2. Copeland: two alternatives ci cj , simulate pairwise electionthem, seeing many votes rank ci ahead cj , many rank cjahead ci . ci wins majority votes rank ci ahead cj . Then,alternative receives one point win pairwise election. (Typically,alternative also receives half point pairwise tie, matterresults.) winner alternative highest score.3. Maximin (a.k.a. Simpson): Let NP (ci , cj ) denote number votes rank ciahead cj profile P . winner alternative c maximizes min{NP (c, c ) :c C, c 6= c}.4. Bucklin: alternative cs Bucklin score smallest number khalf votes rank c among top k alternatives. winner alternativesmallest Bucklin score. (Sometimes, ties broken number30fiDetermining Possible Necessary Winners Given Partial Ordersvotes rank alternative among top k position, simplicityconsider tiebreaking rule here.)5. Ranked pairs: rule first creates entire ranking alternatives. NP (ci , cj )defined maximin rule. step, consider pair alternativesci , cj previously considered; specifically, choose remainingpair highest NP (ci , cj ). fix order ci > cj , unless contradictsprevious orders fixed (that is, violates transitivity). continueconsidered pairs alternatives (hence full ranking). alternativetop ranking wins.6. Voting trees: voting tree binary tree leaves, leaf associatedalternative. round, pairwise election alternativeci sibling cj : majority voters prefer ci cj , cj eliminated,ci associated parent two nodes; similarly, majorityvoters prefer cj ci , ci eliminated, cj associated parenttwo nodes. alternative associated root tree (winsrounds) wins. Balanced voting trees also known cup, knockout tournamentssingle-elimination tournaments.7. Plurality runoff: rule two steps. first step, alternatives excepttwo ranked top position times eliminated,votes transfer second round, plurality rule (a.k.a. majority rulecase two alternatives) used select winner.8. Single transferable vote (STV): election rounds. round, alternative gets minimal plurality score drops out, removedvotes (so votes alternative transfer another alternative nextround). last-remaining alternative winner.Given profile P , pairwise score difference DP (c, c ) alternatives c c definedfollows.DP (c, c ) = NP (c, c ) NP (c , c)subscript P omitted risk confusion. linear order VC, let DV denote pairwise score difference function profile consistssingle vote V . is, DV = D{V } . follows definition D(c, c ) = D(c , c).note although maximin, ranked pairs, voting trees based pairwise scores,also computed pairwise score differences way,profile P n votes, pair alternatives (c, c ), DP (c, c ) = 2NP (c, c ) n.adopt parallel-universes tiebreaking (Conitzer, Rognlie, & Xia, 2009) definewinning alternatives rules multiple rounds (i.e., ranked pairs, votingtrees, plurality runoff, STV). is, alternative c winnerexists way break ties steps c winner. example,alternative c winner voting tree, exists way break tiespairwise elections voting process, c wins. partial order C reflexive,transitive, antisymmetric relation C. say linear order V extends partial orderV .31fiXia & ConitzerDefinition 1 linear order V C extends partial order C every pairalternatives c, c C, c c c V c .Throughout paper use following notation. Let V denote linear order C;let denote partial order C; let P denote profile linear orders; let Pposet denoteprofile partial orders.3. Possible/Necessary Winnersready define possible (necessary) winners, first introducedKonczak Lang (2005).Definition 2 Given profile partial orders Pposet = (O1 , . . . , ) C, sayalternative c C is: (1) possible winner exists P = (V1 , . . . , Vn ) Viextends Oi , r(P ) = {c}; (2) necessary winner every P = (V1 , . . . , Vn )Vi extends Oi , r(P ) = {c}; (3) possible co-winner exists P = (V1 , . . . , Vn )Vi extends Oi , c r(P ); (4) necessary co-winner P = (V1 , . . . , Vn )Vi extends Oi , c r(P ).Example 1 Let three alternatives {c1 , c2 , c3 }. Three partial orders illustratedFigure 1. Let Pposet = (O1 , O2 , O3 ). c1 possible (co-)winner Pposet respectplurality, complete O1 adding c2 c3 , complete O2 adding c1 c2 ,complete O3 adding c1 c2 c1 c3 ; then, c1 winner. However, c1necessary (co-)winner, complete O1 adding c2 c3 , complete O2adding c2 c1 , complete O3 adding c2 c1 c1 c3 ; then, c2 winner.O1c2c1O2O3c1c3c1c3c2c2c3Figure 1: Partial orders.However, let Pposet= (O1 , O1 , O2 ), c1 (only) necessary winner,c1 ranked first least two votes.Now, define computational problems studied paper:Definition 3 Define problem Possible Winner (PW) respect voting rule r be:given profile Pposet partial orders alternative c, asked whether cpossible winner Pposet respect r.Necessary Winner (NW), Possible co-Winner (PcW), Necessary co-Winner (NcW)defined similarly.natural first question problems related other. turns(holding voting rule fixed) exists polynomial-time Turing reductionNW PcW. is, PcW P, NW also P.Proposition 1 voting rule r, computing PcW respect r P,computing NW respect r also P .32fiDetermining Possible Necessary Winners Given Partial OrdersProof. r never outputs , alternative c necessary unique winner respectr every alternative (d 6= c), possible co-winner. Therefore,polynomial-time algorithm solves PcW problem respect r,solve NW problem, simply run algorithm every alternative (d 6= c).6= c possible co-winner, output c necessary unique winner;otherwise, output c necessary unique winner.2similar relationship PW NcW problems. truealternative (d 6= c) possible unique winner, c necessary co-winner.However, possible even alternative (d 6= c) possible unique winner, cstill necessary co-winner. example, let Pposet = (c2 c3 c1 , c3 c2 c1 ).Pposet already composed linear orders, one extension (itself).follows possible unique winner Pposet respect plurality, clearlyc1 necessary co-winner. generally, following proposition,says pair different problems X, {PW, PcW, NW, NcW}, answercannot computed answers X alternatives, unless X =NW=PcW. (This holds even rule plurality).Proposition 2 Suppose 3. Let X, {P W, P cW, N W, N cW } (1) X6=Y(2) X6=PcW Y6=NW. exist two profiles Pposet Pposet partial orders (with|Pposet | = |Pposet |), (1) every alternative c, answers X respectplurality Pposet Pposet , (2) exists alternativeanswers respect plurality Pposet Pposet different.Proof. proof construction. partial order C, let op(O) denoteset alternatives c exists least one extension ctop position. set C C, define OC arbitrary partial orderop(OC ) = C . simplicity, write Oc O{c } . example, = 3, letOc1 = O{c1 } = c1 c2 c3 , is, Oc1 linear order. another example, O{c1 ,c2 }partial order obtained [c1 c2 c3 ] removing c1 c2 .Let = c1 . next specify profiles Pposet Pposet following (exhaustive)list cases (X, ).(PW, NW) (PW, NcW). (1) Let Pposet composed 5 copies Oc1 . c1necessary unique/co-winner. (2) Let Pposet = (Oc1 , Oc2 , Oc2 , O{c1 ,c3 } , O{c1 ,c3 } ). c1unique winner one extension, {c1 , c2 } winners two extensions,{c2 , c3 } winners one extension. Therefore, c1 necessary unique/cowinner. note c1 possible unique winner profiles.(PW, PcW). (1) Let Pposet = (Oc1 , Oc2 ). {c1 , c2 } winners extension, means c1 possible co-winner. (2) Let Pposet = (Oc2 , Oc3 ).{c2 , c3 } winners extension, means c1 possibleco-winner. note possible unique winner either profile.(NcW, NW). (1) Let Pposet = (Oc1 , Oc1 ). c1 winner extension,means c1 necessary unique winner. (2) Let Pposet = (Oc1 , O{c1 ,c2 } ).c1 winner one extension, {c1 , c2 } winners33fiXia & Conitzerextension, means c1 necessary unique winner. note c1necessary co-winner profiles.(PcW, PW) (PcW, NcW). (1) Let Pposet = (O{c1 ,c2 } , O{c1 ,c2 } ). c1 uniquewinner one extension, c2 unique winner one extension, {c1 , c2 }winners two extensions. Therefore, c1 possible unique winner (meanwhile, c1necessary co-winner). (2) Let Pposet = (Oc1 , Oc2 ). {c1 , c2 } winnersextension, means c1 possible unique winner (meanwhile,c1 necessary co-winner). note c1 c2 possible co-winnersprofiles.(NW, PW), (NW, PcW), (NcW, PW), (NcW, PcW). (1) Let Pposet = (O{c1 ,c2 } , O{c1 ,c2 } ).c1 unique winner one extension, c2 unique winner one extension,{c1 , c2 } winners two extensions. Therefore, c1 possible unique/cowinner. (2) Let Pposet = (O{c2 ,c3 } , O{c2 ,c3 } ). c2 unique winner one extension,c3 unique winner one extension, {c2 , c3 } winners two extensions. Therefore, c1 possible unique/co-winner. notenecessary unique/co-winner either profile.(NW, NcW). (1) Let Pposet = (Oc1 , Oc2 ). {c1 , c2 } winners extension, means c1 necessary co-winner. (2) Let Pposet = (Oc2 , O{c1 ,c2 } ).{c1 , c2 } winners one extension, c2 unique winnerextension, means c1 necessary co-winner. notenecessary unique winner either profile.24. Hardness Resultssection, prove PW (PcW) NP-complete respect class positionalscoring rules, Copeland, maximin, Bucklin, ranked pairs, voting trees; NW (NcW)coNP-complete respect Copeland, ranked pairs, voting trees; PW NPcomplete NcW coNP-complete respect plurality runoff. positionalscoring rules, show PW hard positional scoring rulesin fact,plurality veto, PW easy; rather, give sufficient condition positionalscoring rule PW hard. notably, Borda satisfies condition. kapproval satisfy condition, provide distinct proof PW (PcW)respect k-approval (k 2).6 Similarly voting trees, provide necessarycondition hardness results hold, notably, balanced voting treessatisfy condition. results (except one PW respect pluralityrunoff) hold even partial orders almost linear orders. is,number undetermined pairs partial order bounded constant.6. conference version paper (Xia & Conitzer, 2008), Betzler Dorn proved dichotomytheorem possible winner problems respect positional scoring rules (Betzler & Dorn, 2010).According theorem, PW respect k-approval (k 2) NP-complete. paper,prove problem NP-complete, even number undetermined pairs vote4.34fiDetermining Possible Necessary Winners Given Partial Ordershardness results proved reductions exact 3-cover (X3C)problem, except result k-approval, proved reduction 3-SAT.X3C 3-SAT known NP-complete (Garey & Johnson, 1979). two problemsdefined follows.Definition 4 (X3C) given set V = {v1 , . . . , vq } collection = {S1 , . . . , St },t, Si = {vl(i,1) , vl(i,2) , vl(i,3) } V, 1 l(i, 1), l(i, 2), l(i, 3) q.asked whether cover elements V non-overlapping sets S.Definition 5 (3-SAT) given formula conjunctive normal form: F = C1. . . Ct binary variables x1 , . . . , xq , j t, Cj called clause.j t, Cj = lj1 lj2 lj3 , {1, 2, 3}, lj called literal, existsq either lj = xi lj = xi . asked whether exists valuationvariables F true.proof, election instance construct arbitrary X3C (or 3-SAT)instance consists two parts. first part set partial orders encode X3C(or 3-SAT) instance.7 example, PW reductions X3C, first partstructured follows: order c win, alternative c needsplaced high position extensions partial orders least numbertimes. However, partial orders, set three alternativesput c high position extension partial order, threealternatives must ranked even higher positions (that is, c pushes threealternatives extension). sets three alternatives must sometimespushed correspond sets three elements X3C instance. PW instanceset way X3C-element alternative pushed c twodifferent votes first part, c cannot win. Thus, sets alternativespush must disjoint, instance set way need put chigh position often enough pushed-up 3-sets actually must constitute exactcover. second part set linear orders (that is, second part, everythingdetermined) whose purpose is, informally stated, adjust scores alternativesget properties described.First introduce notation represent set pairwise comparisonslinear order.Definition 6 set {a1 , . . . , al }, let O(a1 , . . . , al ) = {(ai , aj ) : < j}.is, O(a1 , . . . , al ) set ordered pairs consistent linear order a1. . . al . example, O(a, b, c) = {(a, b), (b, c), (a, c)}. following notationfrequently used proofs.Definition 7 set partition A1 , . . . , Ak A, let O(A1 , . . . , Ak ) denotearbitrary linear order consistent A1 A2 . . . Ak .7. Typically, define partial orders first defining linear orders removingpairwise ordering constraints.35fiXia & Conitzerproofs make use notation use fact O(A1 , . . . , Ak ) consistentA1 . . . Ak , order within Ai (i k) matter. example,let = {a, b, c, d}, A1 = {a}, A2 = {b, c}, A3 = {d}. two linear ordersconsistent A1 A2 A3 . b c c b d. O(A1 , A2 , A3 )denote either them, e.g., O(A1 , A2 , A3 ) = b c d. Sometimes usenotation Others denote set objects mentioned context.example, O(A1 , A2 , A3 ) = O(Others, A2 , A3 ) = O(A1 , Others, A3 ) = O(A1 , A2 , Others).Usually, positional scoring rule defined fixed number alternatives (that is,fixed). hold fixed, exist polynomial-time algorithms PWNW (Walsh, 2007; Conitzer et al., 2007). However, positional scoring rulesdefined number alternativesfor example, Borda, plurality, veto.positional scoring rules, number alternatives bounded, indeed,prove PW always easy respect rules. study complexitysocial choice problems involve growing number alternatives, necessaryassociate scoring vector every natural number alternatives. remainderpaper, positional scoring rule r consists sequence scoring vectors {~s1 , ~s2 , . . .}N, ~si scoring vector alternatives. next theorem providessufficient condition positional scoring rule PW NP-complete. paper,PW/PcW problems NP, NW/NcW problems coNP.follows fact that, given extension partial orders linear orders,compute winner(s) polynomial-time rules studied paper.mind, prove hardness direction NP-completeness/coNP-completenessproofs. exist rules computing winner(s) NP-hard, example,Dodgsons rule (Bartholdi, Tovey, & Trick, 1989b; Hemaspaandra, Hemaspaandra, & Rothe,1997) Youngs rule (Rothe, Spakowski, & Vogel, 2003), study rulescomputing winners hard here.Theorem 1 Let r positional scoring rule scoring vectors {~s1 , ~s2 , . . .}. Supposeexists polynomial function f (x) x N, exist l kx l f (x) k l 4, satisfy following conditions:(1) ~sl (k) ~sl (k + 1) = ~sl (k + 1) ~sl (k + 2) = ~sl (k + 2) ~sl (k + 3) > 0,(2) ~sl (k + 3) ~sl (k + 4) > 0,Then, PW PcW NP-complete respect r, even numberundetermined pairs vote 4.Proof. Given X3C instance V = {v1 , . . . , vq }, = {S1 , . . . , St }, let q + 3 l f (q + 3)(where q number elements X3C instance) satisfy two conditionsassumption, let k l 4 satisfy ~sl (k) ~sl (k + 1) = ~sl (k + 1) ~sl (k + 2) =~sl (k + 2) ~sl (k + 3) > 0, ~sl (k + 3) ~sl (k + 4) > 0. Let K1 = ~sl (k) ~sl (k + 1)K2 = ~sl (k + 3) ~sl (k + 4). construct PW instance follows.Alternatives: C = {c, w, d} V A, = {a1 , . . . , alq3 } auxiliaryalternatives.First part (P1 ) profile: j t, choose arbitrary set Bj C\(Si {w, d})36fiDetermining Possible Necessary Winners Given Partial Orders|Bj | = k 1. define partial order Oj follows.Oj = O(Bj , w, Si , d, Others) \ [{w} (Sj {d})]is, Oj partial order agrees Bj w Sj Others, exceptpairwise relations (w, Sj ) (w, d) determined (and 4undetermined relations). Let P1 = {O1 , . . . , Ot }.Second part (P2 ) profile: first give properties need P2 satisfy;show construct P2 polynomial time later proof. votes P2linear orders. Let P1 = {O(Bj , w, Sj , d, Others) : j t}. is, P1 (|P1 | = t)extension P1 (in fact, P1 set linear orders started obtain P1 ,removing pairwise relations). P2 set linear ordersfollowing holds Q = P1 P2 :(1) every q, ~sl (Q, c) ~sl (Q, vi ) = 2K1 , ~sl (Q, w) ~sl (Q, c) =q3(3K1 + K2 ) K2 .(2) every q, scores vi w, c higher alternativesextension P1 P2 .(3) P2 size polynomial + q.Suppose exists extension P1 P1 c winner P1 P2 .q, vi ranked higher w P1 , otherwise totalscore vi higher equal total score c. recall scoredifference w c P1 P2 3q (3K1 + K2 ) K2 . Therefore, exists jextension Oj , w ranked c, ranked alternativeSj , must exist alternative V ranked w least two timesP1 , contradicts assumption c winner. follows ordertotal score w lower total score c, w ranked lower leastq3 times. Let denote set subscripts votes P1 w ranked lowerd; then, SI = {Si : I} solution X3C instance.Conversely, given solution X3C instance, let set indices Siincluded X3C. Then, solution possible winner instance obtainedranking ahead w exactly votes subscripts I. Therefore, c possiblewinner exists solution X3C problem, means PWPcW NP-complete respect positional scoring rules satisfy conditionsstated theorem.possible co-winner, replace (1) following condition.(1) every q, s(Q, c) s(Q, vi ) = K1 , s(Q, w) s(Q, c) = 3q (3K1 + K2 ).Next, show construct profile P2 satisfies three conditions.P2 consists following three parts.first part, P2 . Let MV denote cyclic permutation among V {c, w}.is, MV = c w v1 v2 . . . vq c. j N, eV {c, w}, let MV0 (e) = e, MVj (e) = MV (MVj1 (e)). first part P2P2 = MV (P1 ) MV2 (P1 ) . . . MVq+1 (P1 ). follows e, e V {c, w},~sl (P1 P2 , e) = ~sl (P1 P2 , e ).37fiXia & Conitzersecond part, P2 . Choose arbitrary set B C\{d, w, c} |B| = k1,arbitrary set C \ (B {d, w}) |A | = 3. define followingpartial orders.V1V2V3V4= O(B, d, w, c, Others),= O(B, d, c, w, Others),= O(B, d, , w, Others),= O(B, , d, w, Others),V1V2V3V4= O(B, c, w, d, Others)= O(B, w, c, d, Others)= O(B, w, , d, Others)= O(B, , w, d, Others)P2 defined follows.P2 ={V1 , V2 , MV (V1 ), MV (V2 ), . . . , MVq+1 (V1 ), MVq+1 (V2 )}q{V3 , MV (V3 ), . . . , MVq+1 (V3 )} {V4 , MV (V4 ), . . . , MVq+1 (V4 )}3qq{V3 , MV (V3 ), . . . , MVq+1 (V3 )} represents copies {V3 , MV (V3 ), . . . , MVq+1 (V3 )}.33Putting P2 P2 together, condition (1) description P2 satisfied.third part, P2 . P2 defined way P2 , total scorespair alternatives V {c, w} same, total score alternativeV {c, w} significantly higher total score alternative {d}.Let MO cyclic permutation among {d}. is, let MO = a1a2 . . . alq3 d. Let V5 = O(V, c, w, Others). define third part P2follows.P2 = (|P1 P2 P2 | + 1) {MVi (MOj (V5 )) : q + 2, j l q 2}note |P1 P2 P2 | + 1 polynomial + q. Therefore, size P2polynomial + q.2Theorem 1 provides sufficient condition positional scoring rules PW PcWNP-complete. applied prove NP-completeness PW PcW Borda,following corollary shows.Corollary 1 PW PcW NP-complete respect Borda, even numberundetermined pairs vote 4.Proof. l N, scoring vector ~sl Borda (l 1, l 2, . . . , 0). letf (x) = x, l = x, k = l 4, conditions Theorem 1 satisfied,claim follows.2Theorem 1 apply k-approval. noted Table 1, possiblenecessary winner problems respect plurality (1-approval) P. next showfixed k N k 2, PW PcW respect k-approval NPcomplete.Theorem 2 fixed natural number k 2, PW PcW NP-completerespect k-approval, even number undetermined pairs vote4.38fiDetermining Possible Necessary Winners Given Partial OrdersProof. first prove NP-hardness PW respect 2-approval. Then, showextend proof k N, k 2.prove NP-hardness reduction 3-SAT. Given instance 3-SAT,q variables x1 , . . . , xq formula F = C1 . . . Ct , constructinstance PW respect 2-approval follows. Without loss generality, assumeq + 2 (generally, fixed k N, assume q + k),clause F , variable appears once.Alternatives: C = {c} C X X1 X1 . . . Xq Xq D1 D1 . . . Dq Dq ,C = {c1 , . . . , ct }, X = {x1 , . . . , xq , x1 , . . . , xq }, q,Xi = {x1i , . . . , xti , x1i , . . . , xti }, Xi = {x1i , . . . , xti , x1i , . . . , xti };Di = {d1i , . . . , dti }, Di = {d1i , . . . , dti }.words, C represents set clauses F ; xi xi represent valuesBoolean variable xi take; Xi (respectively, Xi ) represents set duplicatesxi (respectively, xi ); Di (respectively, Di ) represents set auxiliary alternativesassociated xi (respectively, xi ).First part P1 profile: q, let Vi = O(c, xi , xi , Others).Then, obtain Oi removing (xi , xi ) Vi . is, extension Oi ,c must top position, one xi xi must second position(and other, third). see later proof two extensionsOi correspond two valuations variable xi , i.e., xi rankedsecond position (while xi ranked third position) corresponds xi = f alse.q, define following linear orders.Vi1 = O(xi , d1i , x1i , x1i , Others)2 j t, Vij = O(xij1 , dji , xji , xji , Others)Then, obtain Oi1 Vi1 removing {xi , d1i } {x1i , x1i }; 2 j t,obtain Oij Vij removing {xij1 , dji } {xji , xji }. define Vij, Oij,similarly adding alternative explicitly written definition VijOij , respectively (that is, alternatives Others). example,Vi1, = O(xi , d1i , x1i , x1i , Others).j t, let fj : X X1 X1 . . . Xq Xq mappingx X, fj (x) obtained x adding j superscriptx. example, fj (x1 ) = xji fj (x2 ) = xj2 . j t, let Wj =O(c, fj (lj1 ), fj (lj2 ), fj (lj3 ), Others). Then, obtain Qj Wj removing{fj (lj1 ), fj (lj2 ), fj (lj3 )} {fj (lj1 ), fj (lj2 ), fj (lj3 )}is, extension Qj , c must top position, one {fj (lj1 ), fj (lj2 ),fj (lj3 )} must second position. see extensions Qj correspond Cj (the jth clause) satisfied valuation x1 , . . . , xq .let P1 = {O1 , . . . , Oq } {Oij , Oij, : q, j t} {Qj : j t}.39fiXia & ConitzerSecond part P2 profile: profile P alternative c , lets2 (P, c ) denote score c P , 2-approval. is, s2 (P, c ) numbertimes c ranked top two positions P . let P2 arbitraryprofile linear orders satisfies following conditions.s2 (P2 , c) = 0.every q every j t, s2 (P2 , xi ) = s2 (P2 , xi ) = s2 (P2 , xji ) =s2 (P2 , xji ) = s2 (P2 , xji ) = s2 (P2 , xji ) = q + 2.c mentioned above, s2 (P2 , c ) 1.+ q 2, P2 well-defined |P2 | bounded polynomial q(we try fit q + 2 copies {xi , xi , xji , xji , xji , xji : q, j t} top twopositions (q + 2)(2q + 4qt)/2 = q(q + 2)(2t + 1) votes). note numberundetermined pairs vote P1 P2 4.Suppose feasible solution 3-SAT instance. Let g denote valuationx1 , . . . , xq F satisfied. define extension P1 P2 follows.every q, g(xi ) = true, define following extensions partialorders P1 .Let Vi extension Oi xi ranked second position.Let Vi1 extension Oi1 xi d1i ranked top twopositions; let Vi1, extension Oi1, x1i x1i rankedtop two positions.every 2 j t, let Vij extension Oij xij1 djiranked top two positions.every 2 j t, let Vij, extension Oij, xji xjiranked top two positions.every q, g(xi ) = f alse, define following extensions (whichsimilar extensions case g(xi ) = true).Let Vi extension Oi xi ranked second position.Let Vi1, extension Oi1, xi d1i ranked top twopositions; let Vi1 extension Oi1 x1i x1i ranked toptwo positions.every 2 j t, let Vij, extension Oij, xij1 djiranked top two positions.every 2 j t, let Vij extension Oij xji xji rankedtop two positions.every j t, Cj satisfied xi = true (respectively, xi = f alse)q, then, let Wj extension Qj xji (respectively, xji ) rankedsecond position.Let P = {V1 , . . . , Vq } {Vij , Vij, : q, j t} {W1 , . . . , Wt } P2 .40fiDetermining Possible Necessary Winners Given Partial Orderschecked P \ P2 , every alternative c (c 6= c) ranked two toppositions once. recall s2 (P2 , c ) q + 2 s2 (P , c) = q + t. Therefore,c unique winner.Next, show convert feasible solution PW feasible solution3-SAT instance. Let P extension c unique winner. Let gvaluation q, g(xi ) = true extension Oi P ,xi ranked second position. prove following claim show g,clauses satisfied.Claim 1 q, g(xi ) = true (respectively, g(xi ) = f alse), every j t,xji xji (respectively, xji xji ) ranked top two positions extensionOij, (respectively, Oij ) P .Proof. q, prove claim induction j. prove caseg(xi ) = true; case g(xi ) = f alse proved similarly.Suppose g(xi ) = true. definition, xi ranked second position extension Oi P . recall s2 (P2 , xi ) = q + 2 = s2 (P , c) 2. cunique winner, xi ranked top two positions extension P1 \ {Oi }.Specifically, xi ranked top two positions extension Oi1, . recallxi d1i Oi1, . Therefore, d1i ranked top two positionsextension Oi1, (otherwise, xi would also ranked top two positions, immediately prevents c unique winner). also note xi , d1i , x1i , x1ifour alternatives ranked top two positions extensionOi1, . follows extension Oi1, , x1i , x1i ranked top two positions.means claim holds j = 1.Suppose claim holds j j j . Following similar reasoningcase j = 1, prove claim holds j = j + 1. precisely,induction hypothesis, xji ranked top two positions extension Oij , .Therefore, xji ranked top two positions extension Oij +1, (otherwisescore xji least large score c, means c uniquewinner). recall xji dji +1 Oij +1, . Therefore, dji +1 rankedtop two positions extension Oij +1, (otherwise xji must also rankedtop two positions, immediately prevents c unique winner). alsonote xji , dji +1 , xji +1 , xji +1 four alternatives rankedtop two positions extension Oij +1, . follows extension Oij +1, ,xji +1 xji +1 ranked top two positions. means claim holdsj = j + 1.Therefore, claim holds every j t.2ready show g, clauses satisfied. Let j numbert. xji ranked second position extension Qj , mustg(xi ) = true. not, then, Claim 1, xji ranked top two positionsextension Oij , means xji ranked top two positions P \P2 leasttwice: Oij , Qj . follows s2 (P , xji ) q+t2+2 q+t = s2 (P , c),contradicts assumption c unique winner. Similarly, extension41fiXia & ConitzerQj , xji ranked second position, must g(xi ) = f alse. meansg, every clause Cj satisfied valuation variable correspondsalternative ranked second position extension Qj . Hence, Fsatisfied.PcW, simply replace s2 (P2 , xi ) = s2 (P2 , xi ) = s2 (P2 , xji ) = s2 (P2 , xji ) =s2 (P2 , xji ) = s2 (P2 , xji ) = q + 2 definition P2 s2 (P2 , xi ) = s2 (P2 , xi ) =s2 (P2 , xji ) = s2 (P2 , xji ) = s2 (P2 , xji ) = s2 (P2 , xji ) = q + 1.reduction k > 2 similar case k = 2. 3-SAT instance, letP1 P2 profile partial orders defined case k = 2. k > 2, add|P1 P2 | (k 2) new alternatives instance, partial order P1 P2 ,let top k 2 positions occupied new alternatives, put remainingnew alternatives bottom positions, none new alternatives rankedtop k positions once. Let P1 P2 denote profiles partial ordersobtained way. follows c possible (co-)winner P1 P2 respectk-approval c possible (co-)winner P1 P2 respect 2-approval.2Theorem 3 PW PcW NP-complete NW NcW coNP-completerespect Copeland, even number undetermined pairs vote8.Proof. first prove PW NcW parts, one reduction X3C. Without lossgenerality, always assume X3C instance, odd = q,not, make following changes X3C instance.2(t q) sets> q, add 3(t q) dummy elements v1 , . . . , v3(tq)S1 , S1 , . . . , Stq , Stq , q, Si = {v3i2 , v3i1 , v3i }.q > t, add q copies S1 .q = even, add three dummy elements v1 , v2 , v3 , three copiesS1 = {v1 , v2 , v3 }.new X3C instance, = q, odd, size instance polynomial sizeold one, new X3C instance feasible solution old onehas.Given X3C instance V = {v1 , . . . , vq }, = {S1 , . . . , St }, q = odd,construct PW instance follows.Alternatives: {c, w, d} V B, = {a1 , . . . , at2 }, B = {b1 , . . . , b7t }.First part P1 profile: Let cyclic permutation among B. is, =b1 b2 . . . b7t b1 . Let VB = b1 b2 . . . b7t . t, obtain partialorder starting O((V \ Si ), d, Si , w, c, (VB ), A), removing orderingrelationships ({d} Si ) {w, c}.Second part P2 profile:2q2q+ 1 votes: + 1 2t+ 1, vote33consistent w c V (VB ) A.42fiDetermining Possible Necessary Winners Given Partial Orders2qqq2 votes: 2t+ 2 2t 1, vote333consistent w c V (VB ) A.qq2 votes: 2t 2t 3, vote consistent33w c V (VB ) A.2 votes: 2t 2 2t 1, vote consistentc w V (VB ) A.2 votes: 2t 2t + 1, vote consistentc V w (VB ) A.11(5t 1) votes: 2t + 2 (9t + 1), vote22consistent w c (VB ) V d.11(5t 1) votes: (9t + 3) 7t, vote22consistent (VB ) V w c.note number undetermined pairs vote 8.Let P1 denote profile extends P1 vote Si rankedhigher w c, is, P1 = {O((V \ Si ), d, Si , w, c, B, A) : t}. makefollowing observations pairwise election:w always defeats c, d, B, A, q, DP1 P2 (vi , w) = 3.c always defeats V, B, always loses A, DP1 P2 (d, c) =2q1.3B always defeats d, V, A, due cyclic order profile, bj always defeatsbj+1 , . . . , bj+ 1 (7t1) , N, bi = bi+7t , always loses2alternatives B.Therefore, P1 P2 , total number pairwise elections alternative is:w wins |B| + |A| + 2 = 8t,c wins |V| + |B| = q + 7t = 8t,d, v V, wins 8t + q + 1 7t = + q + 1,lose B,b B wins 12 (|B| 1) + |A| + |V| + 1 = 12 (9t + 2q 3) pairwise elections.recall X3C instance = q, means P1 P2 , winners{w, c}. order c unique winner, possibility c winqpairwise election putting c least votes P1 . However,3put c ahead vote corresponding Si , v Si pairwise score differencew v increases 2. Moreover, w v v V least twice43fiXia & Conitzerextension P P1 , DP P2 (v, w) 1, means w defeats v pairwiseelection. case, w would win 8m + 1 pairwise elections, means c cannotunique winner. Therefore, c possible unique winner existsqextension P P1 c exactly votes P , corresponding Si3overlap, is, constitute exact cover V. means PWsolution X3C problem solution. PW NP-complete.reduction, w would always co-winner c uniquewinner, NcW coNP-complete. PcW NW, need slightly modifyreduction PW NcW: let |A| = 1 keep rest unchanged. Then, winitially win 8t + 1 pairwise elections, c possible co-winner (w necessaryunique winner) exists feasible solution X3C instance.2Theorem 4 PW PcW NP-complete respect Bucklin, even numberundetermined pairs vote 16.Proof.First, give reduction X3C PW. Given X3C instance V ={v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.Alternatives: W V {c, w}, W = {w1 , . . . , wq+1 }, = {d1 , . . . , dq+1 }.First part P1 profile: t, start O(w1 , . . . , wq+1 , Si , c, (V \Si ), D), obtain partial order removing relations{wq2 , wq1 , wq , wq+1 } (Si {c})Second part P2 profile:copies V c Others,q1 copies V w c Others,3q+ 2 copies w1 Others.3note number undetermined pairs vote 16. Notice2qq|P1 P2 | = 2t ++ 1, w1 ranked within top q + 2 positions + + 2 votes33extension P1 P2 . Therefore, order c win, c wq2 must holdqleast votes extension P1 . However, whenever put c ahead wq2 vote,3forcing alternatives Si corresponding vote ranked within top qpositions. v V ranked within top q positions least twice extensionqP1 , overall ranked within top q positions least + + 1 votes,3means c unique winner.exists feasible solution X3C problem, put c ahead wq2votes corresponding solution, obtain extension P1 P1qc ranked within top q + 1 positions votes, v V, v ranked within3top q (and, fact, first q + 1) positions once. result, c unique winnerprofile P1 P2 , alternative ranked within top q + 1 positions44fiDetermining Possible Necessary Winners Given Partial Ordersqleast + votes. Conversely, c unique winner profile P1 P2 ,3P1 corresponds feasible solution X3C problem. Therefore, PW respectBucklin NP-complete.qPcW, need modify reduction slightly, changing last + 1 votes3[D w1 Others] [d1 . . . dq w1 Others]. case, Bucklin scorew1 q + 1, means c best hope co-winner. result, PcW alsoNP-complete.2prove hardness results maximin, ranked pairs, voting trees, presenttwo helpful lemmas. first show given pair alternatives c, c , exist twolinear orders increase D(c, c ) two keeping pairwise score differencesunchanged. lemma used previously (McGarvey, 1953; Conitzer & Sandholm,2005a). use technique second (score-adjusting) part reductionsmaximin, ranked pairs, voting trees.Lemma 1 Given profile P pair different alternatives c, c , let remainingalternatives {c1 , . . . , cm2 }. Let P profile consisting P plus following twovotes:1. [c c c1 . . . cm2 ],2. [cm2 . . . c1 c c ].Then, DP (c, c ) = DP (c, c ) + 2, alternatives d, {d, } =6 {c, c },DP (d, ) = DP (d, ).lemma tells us pairwise score differences changed almost arbitrarily.constraint parity pairwise score differences remains same.following lemma direct corollary.Lemma 2 (The main theorem McGarvey, 1953) Given profile P skewsymmetric function F : C C Z (that is, F (c1 , c2 ) = F (c2 , c1 ) c1 , c2 ),pairs alternatives c, c C, F (c, c ) DP (c, c ) even (or odd),exists profile P1. |P |1P(|F (c, c ) DP (c, c )| + 1),2 c,c2. DP P = F .is, skew-symmetric function F pairs alternatives (c, c )(with c 6= c ), F (c, c ) DP (c, c ) parity, change pairwise score1Pdifferences DP F adding(|F (c, c )DP (c, c )|+1) votes P .2 c,cHere, factor 12 comes fact pair alternatives c c , absolutevalue difference F DP counted twice, i.e., |F (c, c ) DP (c, c )| =|F (c , c) DP (c , c)|. fact, possible obtain even tighter bounds needed sizeP (Erdos & Moser, 1964), purpose NP-hardness proofsmatter.45fiXia & Conitzerready prove hardness results maximin ranked pairs.mentioned beginning section, hardness proofs section, profileconsists P1 P2 , P1 set partial orders used encode X3C instance,P2 set linear orders used adjust scores alternatives. maximin,ranked pairs, voting trees, P2 used adjust pairwise score differences.explicitly give P2 reductions rules. Instead, present properties P2 ,appeal Lemma 2 assert P2 exist, constructed polynomialtime.Theorem 5 PW PcW NP-complete respect maximin, even number undetermined pairs vote 4.Proof. first prove PW NP-complete. Given X3C instance V = {v1 , . . . , vq },= {S1 , . . . , St }, construct PW instance follows.Alternatives: V {c, w, w }.First part P1 profile: t, start O(w, Si , c, (V \Si ), w ),subsequently obtain partial order Oi removing relations {w} (Si {c}).Second part P2 profile: according Lemma 2, P2 defined setvotes pairwise score differences {O(w, Si , c, (V \ Si ), w ) : t} P2satisfy:2q2; q, D(w, vi ) = t+2; D(w , w) = D(v1 , w ) = t+4;3D(w , c) = 2.(1) D(w, c) = t+(2) pairwise scores defined (1), D(l, r) 1.note number undetermined pairs vote 4.Lemma 2 implies size P2 polynomial q + t.note minimum pairwise score difference w D(w, w ) = 4;minimum pairwise score difference w also 4 = D(w , v1 ).Suppose exists profile P1 extending P1 c wins P1 P2 . c raisedqhigher w least one 1 votes P1 , then, D(c, w) t,3exists q D(vi , w) (the smallest pairwise score difference vi ),means c unique winner vi performing least well. c rankedqhigher w least + 1 votes P1 , still D(c, w ) = + 2,3exists q vi ranked higher w least two votes P1 , meansD(vi , w) + 2 (the smallest pairwise score difference vi ). followscase, c unique winner vi performing least well. Therefore,qway c win decrease D(w, c) raising c higher w exactly votes3P1 . However, time decrease D(w, c) 2 due adding c w Oi P1 ,v Si , D(w, v) also decreased two. D(w , c) = 2, decreasing D(w, c)less 2 would raise minimum pairwise score difference c.q, D(w, vi ) decreased 4 more, minimum pairwise score vj46fiDetermining Possible Necessary Winners Given Partial Ordersleast + 2, means case c cannot unique winner. Therefore,sets Si votes P1 c w cannot overlap. must leastq/3 votes, corresponding subsets Si constitute feasible solution X3Cinstance.Conversely, suppose X3C instance solution. Without loss generality, letsolution {S1 , . . . , Sq/3 }. define extension P1 P1 adding c w Oiq/3, adding w Si > q/3. follows c unique winnerprofile P1 P2 respect maximin rule. Therefore PW NP-complete.PcW, need slightly modify reduction: replace conditionD(w, vi ) = + 2 D(w, vi ) = constructing P2 . Therefore PcW NP-complete. 2Theorem 6 PW PcW NP-complete NW NcW coNP-completerespect ranked pairs, even number undetermined pairs vote8.Proof. first prove NP-hardness PW NcW one reduction. Given X3Cinstance V = {v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.Alternatives: V {c, a, b, w}.First part P1 profile: t, start O(a, c, Si , b, Others),subsequently obtain partial order Oi removing relations ({a, c}(Si {b})).Second part P2 profile: according Lemma 2, P2 defined setvotes pairwise score differences {O(a, c, Si , b, Others) : t} P2satisfy:1. q, D(c, b) = D(w, a) = D(w, vi ) = 3t +2q.32q2q2q, D(c, w) = +2, D(vi , c) = +6, D(b, a) = + 2.3333. D(l, r) = 0 cases.2. D(a, c) = +note number undetermined pairs vote 8.Lemma 2 implies size P2 polynomial q + t.note D(c, b), D(w, a), D(w, vi ) (for every q) much largerremaining pairwise score differences extension P1 P2 . Therefore, c b, w a,w vi (for every q) fixed first extension P1 P2 . followsoutput (a linear order C) extension P1 P2 , must c b,w a, w vi (for every q). note way c unique2qwinner lock b c. is, D(b, a) must least + 2 + . However,3whenever let b extension Oi , forcing Si c. Let P1 extensionP1 c unique winner profile P1 P2 (or, equivalently,w co-winner profile P1 P2 ). note exists q2q2q6+4 = t+2 = D(c, w),vi c least two votes P1 , D(vi , c) +33means w co-winner (by locking vi c c w). Therefore, P1 ,47fiXia & Conitzerqmust b exactly votes, q, vi c exactly one vote.3naturally corresponds solution X3C instance.Conversely, suppose X3C instance solution. Without loss generality, letsolution {S1 , . . . , Sq/3 }. define extension P1 P1 adding b Oiq/3, > q/3, letting extension Oi [a c Si b Others].follows c unique winner profile (and hence, w co-winner).Therefore, PW NP-complete NcW coNP-complete respect ranked pairs.PcW NW, need slightly modify reduction letting2qD(b, a) = q, letting D(vi , c) = +4.23Next, consider voting trees. voting tree defined fixed numberalternatives, study complexity possible/necessary winner problemsrespect voting trees, need consider infinite sequence trees, onenatural number (representing number alternatives).8 Therefore, let voting treerule composed infinite sequence voting trees {T1 , T2 , . . .}, N,Tm voting tree alternatives (that is, Tm binary tree leaf nodes,leaf associated alternative).N, voting tree Tm t-well-spread exist pairs leaves (c1 , a1 ), . . . ,(ct , ), t, ci ai siblings. say leaf pairrich leaf. voting tree balanced depths pair leaves differone, number leaves whose (unique) sibling leaf one.Example 2 Two voting trees illustrated Figure 2. voting tree (a) 1-wellspread, c1 c2 rich leaves; voting tree (b) balanced 3-well-spread,leaves except c5 rich leaves.c4c5c3c1c2c1c2c3(a)c4c6c7(b)Figure 2: Voting trees.Theorem 7 voting tree rule = {T1 , T2 , . . .}, exists polynomial functionf (x) x N, exists l N x l f (x) Tl x-wellspread, PW PcW NP-complete, NW NcW coNP-completerespect , even number undetermined pairs vote 16.8. similar case positional scoring rules, technically defined specificnumber alternatives.48fiDetermining Possible Necessary Winners Given Partial OrdersProof. Let j2 , j3 , . . . index voting trees z N (z 2), Tjz2(z + 1)-well-spread jz f (2(z + 1)). z, let c arbitrary rich leafTj z .first prove NP-hardness PW PcW single reduction. Given X3Cinstance V = {v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.Alternatives: Let C leaves Tjq , C = {c, d, w} V E,= {a1 , . . . , aq }, E = {e1 , . . . , emq 2q3 }, mq number leaves Tjq .Let tree {c, d}V rich leaves subtree whose root childroot Tjq (because Tjq 2(q + 1)-well-spread, always possible);sibling c; common ancestor c w root; 1 q,vi ai siblings. positions {c, d, w}V illustrated Figure 3. Eset alternatives Tjq . t, Si = {vl(i,1) , vl(i,2) , vl(i,3) },let Ai = {al(i,1) , al(i,2) , al(i,3) }that is, Ai consists siblings elementsSi .wcv1a1vqaqFigure 3: Positions alternatives Tjq .First part P1 profile: t, start O(d, Ai , Si , c, Others),subsequently obtain partial order Oi removing relations ({d} Ai )(Si {c}).Second part P2 profile: according Lemma 2, P2 definedset votes (linear orders) pairwise score differences profile{O(d, Ai , Si , c, Others) : t} P2 satisfy:(1) D(c, d) = 2q/3 + 1, D(c, w) = 2q + 1.(2) q, D(ai , vi ) = 3, D(vi , c) = D(c, ai ) = 2q + 1.(3) c C (with c 6= c), D(w, c ) = 2q + 1.(4) pair i, q (with 6= ), D(vi , ai ) = 2q + 1.(5) x C \ E, e E, D(x, e) = 2q + 1.note number undetermined pairs vote 16.Lemma 2 implies size P2 polynomial q + t.49fiXia & Conitzerway c win beat first round, meet {v1 , . . . , vq }later rounds, happen every vi beaten corresponding aifirst round. item (4), 6= , D(vi , ai ) = 2q + 1,means q, vi wins first round, beaten w vjj q subsequent rounds.In case winner must w. followsextension P1 makes c win, c must ranked higher least q/3 times.However, rank c higher extension Oi , extensionmust Si Ai . order every ai defeat vi , every q, vi rankedhigher ai extension P1 . Therefore, exists profile P1extending P1 c unique winner (or co-winner) P1 P2 , votesP1 c make feasible solution X3C problem instance. Conversely,feasible solution X3C problem instance, find P1 extending P1c unique winner profile P1 P2 respect Tij . Therefore, PW PcWNP-complete.c unique winner, w always unique winner. Therefore,NW NcW coNP-complete.2Theorem 7, immediately obtain following hardness results voting treerules composed balanced trees, setting f (x) = 4x (because exist integer2x 2y 4x, balanced tree 2y alternatives leastx pairs siblings).Corollary 2 PW PcW NP-complete NW NcW coNP-completerespect voting tree rule composed balanced binary trees, evennumber undetermined pairs vote 16.Finally, following theorems complexity PW NcW respectplurality runoff.Theorem 8 PW NP-complete respect plurality runoff.Proof. prove NP-hardness reduction X3C. Given X3C instance V ={v1 , . . . , vq }, = {S1 , . . . , St }, construct PW instance follows.Alternatives: C = {c, d, e} SV E, SV = {s1 , . . . , st }E = {e1 , . . . , e(q+4)2 (t+4)4 }.First part P1 profile: P1 = P11 P12 , P11 P12 defined follows.P11 : q, start linear order O(d, SV , c, Others), subsequently obtain partial order Oi removing ({d} SV ) {sj : vi Sj }.is, remove minimum set constraints alternative{sj : vi Sj } ranked top position least one extension Oi .Let P11 = {Oi : q}.P12 : j t, start linear order O(d, e, c, Others), subsequently obtain partial order Q1j removing ({d} {e}) (C {sj }). is,extension Q1j , d, e, sj ranked top position.let Q2j = Q1j , P12 = {Q1j : j t} {Q2j : j t}.50fiDetermining Possible Necessary Winners Given Partial OrdersSecond part P2 profile: P2 = P21 P22 , P21 P22 definedfollows.P21 : set q(t + 7/3) + 8 votes, c ranked top position q + 4times, ranked top position q + 2 times, e ranked top positionq/3 + 2 times, j t, sj ranked top position q times.matter remaining alternatives ranked P21 .P22 : first obtain, according Lemma 2, profile P22 pairwisescore differences following profile:{q copies O(d, SV , c, Others)} {2t copies O(d, e, c, Others)} P21 P22satisfy following conditions.1. D(d, c) = D(e, c) = 1;2. j t, D(c, sj ) = 1.Lemma 2, size P22 polynomial p + t. Next, obtain P22 P22moving alternative E top position vote P22 ,way vote P22 ranks different alternative top position. P22well-defined, |E| |P22 |.profile P , alternative c , let P luP (c ) denote plurality score c P ,is, P luP (c ) number times c ranked top position P . subscript P omitted risk confusion. make following observationsprofile {q copies O(d, SV , c, Others)} {2t copies O(d, e, c, Others)} P21 P22 :D(d, c) = D(e, c) = 1, j t, D(c, sj ) = 1;P lu(c) = q + 4, P lu(d) = 2t + 2q + 2, P lu(e) = q/3 + 2; j t, P lu(sj ) = q;e E, P lu(e ) 1.also note extension P1 P2 , P lu(c) = q + 4.X3C instance solution Sj1 , . . . , Sjq/3 , construct solutionPW instance follows.q, let Vi = [sjl (SV \ {sjl }) c Others], jlci Sjl ; note Vi extends Oi ;l q/3, let Vj1l = Vj2l = [e c Others]; note Vj1l Vj2l extendQ1jl Q2jl , respectively;j (with j 6= jl l q/3), let Vj1 = Vj2 = [sj e c Others];note Vj1 Vj2 extend Q1j Q2j , respectively;then, use votes extend partial orders P1 : let P1 = {Vi :q} {Vj1 , Vj2 : j t}.51fiXia & ConitzerP1 P2 , P lu(c) = q + 4, P lu(d) = P lu(e) = q + 2; l q/3, P lu(sjl ) =q + 3; j 6= jl (l = 1, . . . , q/3), P lu(sj ) = q + 2; e E, P lu(e ) 1.Also, l q/3, D(c, sjl ) = 1. follows pairs enterrunoff (in parallel universe) (c, sj1 ), . . . , (c, sjq/3 ), c wins pairwiseelections. Therefore, c unique winner P1 P2 .Next, show convert solution PW instance solution X3Cinstance. Let P1 = P11 P12 extension P1 c unique winnerP1 P2 , P11 = {Vi : q} extends P11 , P12 = {Vj1 : j t} {Vj2 : j t}extends P12 . make following sequence claims.Claim 2 Neither e enter runoff, means pairs couldpotentially still enter runoff (c, sj ), j t.Proof. e entered runoff parallel universe, would defeat crunoff (unless c even runoff, case c also winparallel universe), contradicting c unique winner.2Claim 3 j t, P luP1 (sj ) 3.Proof. hold, let j index maximizes P luP1 (sj ).follows P luP12 (sj ) 1, P luP11 (sj ) 3. However, putting sjtop position partial order P12 , forcing D(c, sj ) reduced 2,means sj defeats c pairwise election. Moreover, because, Claim 2, onesj must enter runoff, sj maximum plurality score amongalternatives SV , sj must runoff one parallel universes. However, ccannot win parallel universe, contradicts assumption c uniquewinner.2Claim 4 P luP1 (d) = 0, P luP1 (e) 2q/3.Proof. follows Claim 3 j t, P luP1 P2 (sj ) q + 3. Therefore,Claim 2 must P luP1 P2 (d) q + 2 P luP1 P2 (e) q + 2. claimfollows.2Claim 5 j t, P luP12 (sj ) 1, P luP1 (sj ) 2.Proof. P luP12 (sj ) 1 sj enters runoff parallel universe, ccannot win parallel universe. sake contradiction, suppose P luP1 (sj ) 3.Claim 3 Claim 2, sj enters runoff parallel universe, contradictsassumption c unique winner.2Claim 6 Let X1 = {sj : P luP11 (sj ) > 0, P luP12 (sj ) = 0}, X2 = {sj : P luP11 (sj ) =0, P luP12 (sj ) > 0}. X1 X2 = SV |X1 | = q/3.52fiDetermining Possible Necessary Winners Given Partial OrdersProof. Let x1 = |X1 |, x2 = |X2 |, x3 = x1 x2 . Claim 5,sj SV \ (X1 X2 ), P luP11 (sj ) = P luP12 (sj ) = 1. recall P11 ,top-ranked alternative extension must either element SV ;Q P12 , top-ranked alternative extension Q must d, e, elementSV . use observations obtain two inequalities.First, order c unique winner, cannot top position voteP11 . Therefore, q top positions P11 must taken alternatives SV .Now, alternative X1 take three top positions; alternativeX2 takes none top positions definition; alternative SV \ (X1 X2 )takes one top positions. follows 3x1 + x3 q.Now, apply similar analysis P12 . order c unique winner, ecannot top position 2q/3 votes P12 , leaving least 2t 2q/3top positions filled. Now, alternative X1 takes none top positions;alternative X2 take two top positions (Claim 5); alternativeSV \ (X1 X2 ) takes one top positions. follows 2x2 + x3 2t 2q/3.substituting q second inequality q first inequality, obtain2x1 + 2x2 + 53 x3 2t. recall x1 + x2 + x3 = t. Therefore, x3 = 0, x1 + x2 = t.first inequality becomes x1 q/3 second inequality becomes x2 q/3.follows x1 + x2 = x1 = q/3 x2 = q/3.2Based claims, construct solution X3C instance. LetX1 = {sj1 , . . . , sjq/3 }. Claim 3, Claim 6, |P11 | = q, fact every top positionP11 must occupied one alternatives X1 , follows Sj1 , . . . , Sjq/3solution X3C instance. Therefore, PW respect plurality runoffNP-complete.2Theorem 9 NcW coNP-complete respect plurality runoff, evennumber undetermined pairs vote 4.Proof. prove coNP-hardness reduction X3C. Given X3C instance V ={v1 , . . . , vq }, = {S1 , . . . , St }, construct NcW instance follows.Alternatives: {c, d} V E, E = {e1 , . . . , et(q+2)3 }.First part P1 profile: j t, start O(d, Sj , c, Others),subsequently obtain partial order Oj removing orderings ({d} Sj ) {c}.Second part P2 profile: P2 = P21 P22 , P21 P22 definedfollows.P21 : set t(q + 1) + q/3 votes, c ranked top position + 1times; ranked top position q/3 1 times; q, viranked top position times.P22 : first obtain, according Lemma 2, profile P22 pairwisescore differences {O(d, Sj , c, Others) : j t} P21 P22 satisfy followingconditions.1. D(c, d) = 2t + 1;53fiXia & Conitzer2. q, D(vi , c) = 3.Lemma 2, size P22 polynomial + q. Next, obtain P22P22 raising alternative E top position vote, wayvote P22 ranks different alternative top position.recall profile P alternative c , P luP (c ) denotes numbertimes c ranked top position P . make following observations{O(d, Sj , c, Others) : j t} P2 .D(c, d) = 2t + 1, q, D(vi , c) = 3;P lu(c) = + 1, P lu(d) = 1 + q/3; q, P lu(vi ) = t; e E,P lu(e) 1.follows observations extension P1 P2 , c must enter runoff;also, extension, c defeats pairwise election. Let P1 P2 (where P1extension P1 ) profile c co-winner. mustenter runoff, means P luP1 P2 (d) 1. follows c least q/3votes P1 . However, ranking c partial order Oi , forcing c Si . Now,pairs alternatives enter runoff (in parallel universes) (c, v1 ), . . . , (c, vq ).Since c loses pairwise elections runoff (because, assumption, cco-winner), must vj , c vj one vote P1 . Hence,solution complement NcW instance naturally corresponds solutionX3C instance. Conversely, solution X3C instance corresponds solutioncomplement NcW instance. Therefore, NcW respect plurality runoffcoNP-complete.25. Polynomial-time Algorithms Possible Necessary WinnerProblemssection present polynomial-time algorithms (1) NW NcW respectpositional scoring rules, maximin, Bucklin, (2) PcW NW respectplurality runoff. recall PW NP-complete (Theorem 8) NcW coNPcomplete (Theorem 9), respect plurality runoff.note positional scoring rules, maximin, Bucklin based typescores, find extension partial orders linear ordersscore c, denoted S(c), score another alternative w, c(unique) winner profile, hence c necessary winner. Therefore,following algorithms rules, check alternatives w 6= c, try makeS(c) S(w) low possible vote-by-vote basis (or equivalently, make S(w) S(c)high possible). vote (partial order), two cases. firstcase, c 6O w. case, need consider c w separately, raising w highpossible lowering c low possible. (This part algorithm alreadyconsidered Konczak & Lang, 2005.) following example, Example 3, illustratesidea.54fiDetermining Possible Necessary Winners Given Partial OrdersExample 3 partial order illustrated Figure 4 (a). Let c = c2 w = c5 . Sincec2 6O c5 , raise c5 high possible lowering c2 low possible, shownFigure 4 (b).c5c6c2c3c1c4c1c5(a) partial order O.c6c2c3c4(b) extension O.Figure 4: partial order extension.second case, c w. case complicated, followsshow minimize S(c) S(w) positional scoring rules, maximin, Bucklin.plurality runoff, convert PcW maximum flow problem solve it; alsogives algorithm NW, simply checking whether alternative possibleco-winner (see Proposition 1).section, input consists C = {c, c1 , . . . , cm1 }, c (the alternativewish decide whether necessary (co-)winner), profile Pposet n partialorders C, voting rule r.first define notation used algorithms.Definition 8 Given partial order alternative c, let UpO (c) = {c C : c c}DownO (c) = {c C : c c }. Given another alternative w c w, let Osc w block defined follows: BlockO (c, w) = {c C : c c w}.is, UpO (c) set alternatives weakly preferred c (including citself), DownO (c) set alternatives c weakly preferred (includingc itself). c w, BlockO (c, w) set alternatives, including c w,ranked c w. easy check partial order O,pair alternatives c, w (with c w), BlockO (c, w) = DownO (c) UpO (w).Example 4 Let partial order illustrated Figure 4 (a). UpO (c2 ) ={c1 , c2 }, UpO (c4 ) = {c1 , c2 , c3 , c4 , c5 }, DownO (c2 ) = {c2 , c3 , c4 }, DownO (c4 ) = {c4 },BlockO (c2 , c4 ) = {c2 , c3 , c4 }.notion block useful following reason. algorithm, wantthink extension partial orders w well possible, cpoorly possible. c w partial order O, cannot rank cw; least makes sense alternatives possible.alternatives block exactly ones need them; rankalternatives outside block. Then, question positionblock, slide block ranking.ready present algorithms. note given partial order O,computing UpO DownO sets takes polynomial time. Let ~sm denote scoringvector positional scoring rule.Algorithm 1 (Computing NW respect positional scoring rule)55fiXia & Conitzer1. partial order Pposet alternative c, compute UpO (c)DownO (c).2. Repeat Steps 3ac w 6= c:3a. Let S(w) = S(c) = 0.3b. partial order Pposet ,c 6O w, (following Example 3) lowest possible position c+ 1 |DownO (c)|th position, highest possible position w|UpO (w)|th position, add scores ~sm (|UpO (w)|) ~sm (m + 1|DownO (c)|) S(w) S(c), respectively;c w, highest slide Os c w block (as measured csposition, top block) position |UpO (w) \ DownO (c)| + 1 (ifalternative ranked w partial order, placec, unless partial order ranks c a), lowest (as measured wsposition, bottom block) position m|DownO (c)\UpO (w)|(if alternative ranked c partial order, placew, unless partial order ranks w). positionextremes also possible. find position minimizes score cminus score w, add scores c w get positionsS(c) S(w), respectively.3c. result S(w) S(c), output c necessary winner(terminating algorithm).4. Output c necessary winner (if reach point).algorithm computing NcW obtained simply checking whether S(w) > S(c)Step 4.Proposition 3 Algorithm 1 checks whether c necessary winner Pposetrespect given positional scoring rule polynomial time.Proof. equivalent check whether exists extension P Pposetalternative w 6= c, s(P, w) s(P, c)that is, whether c necessary (unique)winner. end, Pposet , maximize s(VO , w)s(VO , c) extensionsVO O.recall m, ~sm (i) score alternative rankedith position. extension VO O, s(VO , w) ~sm (|UpO (w)|) (because w cannotranked higher |UpO (w)|th position) s(VO , c) ~sm (m + 1 |DownO (c)|)(because c cannot ranked lower (m + 1 |DownO (c)|)th position).two bounds achieved c 6O w: every C \ UpO (w), add wO; every C \ DownO (c), add c O. obtain partial orderway, let VO (arbitrary) linear order extends . followss(VO , w) s(VO , c) = ~sm (|UpO (w)|) ~sm (m + 1 |DownO (c)|).However, c w, may exist VO s(VO , w) = ~sm (|UpO (w)|)s(VO , c) = ~sm (m + 1 |DownO (c)|) hold simultaneously. note VO56fiDetermining Possible Necessary Winners Given Partial Ordersmaximizes s(VO , w) s(VO , c), alternatives c w mustBlockO (c, w). Therefore, C w c 6O d, mustVO c; C c 6O w, must w VO d.follows s(VO , w) s(VO , c) maxl (~sm (l + |BlockO (c, w)| 1) ~sm (l)), l ranges|UpO (w) \ DownO (c)| + 1 |DownO (c) \ UpO (w)|. Let VO extensionrestricted C \ BlockO (c, w) UpO (w) \ DownO (c) ranked topDownO (c) \ UpO (w) ranked bottom. C \ (UpO (w) DownO (c))BlockO (c, w), must 6O 6O d. Therefore,|UpO (w) \ DownO (c)| + 1 l |DownO (c) \ UpO (w)|, put BlockO (c, w)(l 1)th position lth position VO , obtain linear order extends O.proves correctness Step 3b, computes maxVO (s(VO , w) s(VO , c)).follows algorithm correctly checks whether c necessary winner.2move maximin rule. note c necessary winner Pposetrespect maximin exists profile linear orders P extendingPposet , two alternatives w w , alternatives d, NP (w, d) NP (c, w ).recall NP (w, d) number votes P w d. Therefore, algorithmconsiders pairs (w, w ), checks whether exists extension inputpartial orders inequality holds alternatives d. perform check,partial order, would like rank w ahead c, also rank w highpossible. However, two objectives may conflict: may case rankc ahead w , rank w higher case rank w ahead c.case, first place w ahead c, rank w high possibleadditional constraint. works following reason. Let Pposet partialorder c 6O w w 6O c; let V arbitrary extension w V clet V arbitrary extension c V w . C,N{V } (w, d) N{V } (c, w ) 0 N{V } (w, d) N{V } (c, w ), means enforcingw c always least good enforcing c w .Algorithm 2 (Computing NW respect maximin)1. partial order Pposet alternative c, compute UpO (c).2. Repeat 3ac pairs w, w , c 6= w c 6= w .3a. Let S(c, w ) = 0, alternative 6= w, let S(w, d) = 0.3b. partial order Pposet ,c 6O w , add w c raise w high possible;6= w, if, resulting vote, w ahead (that is, 6 UpO (w)c UpO (w), 6 UpO (w )), add 1 S(w, d).c w , raise w high possible; add 1 S(c, w ); 6= w,if, resulting vote, w ahead (that is, 6 UpO (w)), add 1S(w, d).3c. Check 6= w, S(w, d) S(c, w ); answer yes, outputc necessary winner (terminating algorithm).4. Output c necessary winner.57fiXia & Conitzeralgorithm computing NcW respect maximin similar: modificationStep 3, check alternatives 6= w, S(w, d) > S(c, w ).Proposition 4 Algorithm 2 checks whether c necessary winner Pposetrespect maximin polynomial time.Proof. function S(x, y) computed algorithm number times x preferredextension Pposet . partial order O, let VO extension computedStep 3b. Let g(V, d) = NV (w, d) NV (c, w ). next prove 6= wextension VO O, g(VO , d) g(VO , d). c 6O w c VO w , g(VO , d)0 g(VO , d) (because NVO (c, w ) = 0 NVO (c, w ) = 1). c 6O w w VO c,NVO (c, w ) = NVO (c, w ). note VO obtained raising w high possiblew c, means NVO (w, d) NVO (w, d). follows g(VO , d) g(VO , d).Similarly, c w , also 6= w, NVO (w, d) NVO (w, d).Therefore,Pfor extension P Pposet 6= w, S(w, d) S(c, w ) = NP (w, d)NP (c, w ) OPposet g(VO , d), P profile computed Step 3b, inequality becomes equality. follows algorithm correct.2move Bucklin rule. note c necessary winnerPposet respect Bucklin, exists extension P Pposetalternative w, either ws Bucklin score 1, exists 2 k m,w among top k n2 votes (meaning ws Bucklin scorek), c among top k 1 n2 votes (meaning cs Bucklin scoreless k). Therefore, like Algorithm 1, algorithm Bucklin considersalternative w, computes possible positions blocks BlockO (c, w), checksk 1 whether condition made hold.algorithm, c 6Oj w, High(j) highest position w reachesextension Oj , Low(j) lowest position c reaches extension Oj .c Oj w, High(j) highest position c given c w ranked closepossible, Low(j) lowest position c given c w rankedclose possible, Length(j) size BlockOj (c, w).{c, w}, let S(i, d) denote minimum number times rankedtop positions, minimum taken optimal extensions Pposet (weelaborate meaning optimality later). U (k) number partial orderscompute put block BlockOj (c, w) make cnecessary unique winner. is, U (k) number partial ordersexists extension c top k 1 positions w top k positions,well another extension c top k 1 positions wtop k positions.Algorithm 3 (Computing NW respect Bucklin)1. partial order Pposet alternative c, compute UpO (c)DownO (c).2. Repeat Steps 3ad w 6= c:3a. j n, let High(j) = Low(j) = Length(j) = 0. m, letS(i, c) = S(i, w) = U (i) = 0.58fiDetermining Possible Necessary Winners Given Partial Orders3b. partial order Oj Pposet ,c 6Oj w, let Length(j) = 0, let High(j) = |UpOj (w)|, Low(j) =+ 1 |DownOj (c)|;c Oj w, let Length(j) = |BlockOj (c, w)|, High(j) = |UpOj (w) \DownOj (c)| + 1, Low(j) = + 1 |DownOj (c)|.3c. k m, j n,Length(j) = 0, add 1 S(k, w) High(j) k, add 1 S(k 1, c)Low(j) k 1;Length(j) > 0, add 1 S(k, w) either Low(j) + Length(j) 1 k,following two conditions hold: Low(j) k1 High(j)+Length(j)1 k. Also, add 1 S(k1, c) Low(j) k1; add 1 U (k) Low(j) > k1High(j) + Length(j) 1 k.3d. S(1, w) + U (1) > n2 , exists 2 k S(k, w) > S(k 1, c),S(k 1, c) n2 , S(k, w) + U (k) > n2 , output c necessarywinner (terminating algorithm).4. Output c necessary winner.algorithm computing NcW obtained making following changes Steps 3c3d follows.3c . k m, j n,Length(j) = 0, add 1 S(k, w) High(j) k, add 1 S(k, c)Low(j) k;Length(j) > 0, add 1 S(k, w) either Low(j) + Length(j) 1 k,following two conditions hold: Low(j) k High(j) + Length(j) 1k. Also, add 1 S(k, c) Low(j) k; add 1 U (k) Low(j) k + 1High(j) + Length(j) 1 k.3d . exists 0 l U (1) S(1, w) + l > n2 S(1, c) + l, exists2 k l U (k) S(k, w) + l > n2 S(k, c) + l, output cnecessary co-winner (terminating algorithm).Proposition 5 Algorithm 3 checks whether c necessary winner Pposetrespect Bucklin polynomial time.Proof. Similarly case positional scoring rules, Bucklin, c 6O w,simply rank c low possible rank w high possible, independently.hand, c w, without loss generality place alternativesc w possible, question place c w block.algorithm consider particular k, try make w among top khalf votes, c among top k 1 half votes.particular vote c w, depending block placed, either (1) c amongtop k 1 w among top k; or, (2) c among top k 1 w amongtop k; or, (3) c among top k 1 w among top k. However,59fiXia & Conitzerthree possibilities may exist particular vote. algorithm neverchoose (2) unless option, difficult case decisionmust made (1) (3).recall {c, w}, S(i, d) minimum numbertimes ranked within top positions, minimum taken extensionsPposet consistent observations previous paragraph (specifically,option (2) never chosen unless choice). U (k) number partialorders exists extension c ranked within top k 1 positionsw ranked within top k positions, well extension c rankedwithin top k 1 positions w ranked within top k positions (that is,choice (1) (3)).k m, j n, consider extend Oj .c 6Oj w, positions c w already determined previousobservations (w ranked high possible c ranked low possible).c Oj w High(j) k, c cannot ranked within top k 1 positionsw cannot ranked within top k positions; therefore, add 0 S(k 1, c)S(k, w).c Oj w, High(j) < k High(j) + Length(j) 1 > k, c ranked withintop k 1 positions, w cannot ranked within top k positions. twosub-cases: (1) Low(j) k, rank c Low(j)th position, henceforthadd 0 S(k 1, c) S(k, w); (2) Low(j) < k, c inevitably rankedwithin top k 1 positions, w cannot ranked within top k positions,means add 1 S(k 1, c) 0 S(k, w).final case c Oj w, High(j) < k High(j) + Length(j) 1 k. Again,two subcases: (1) Low(j) < k, means c must ranked withintop k 1 positions. Therefore rank w top k positions, add 1S(k 1, c) S(k, w); (2) Low(j) k, means three optionsextension Oj , corresponding cases (1), (2), (3) discussed beginningproof.(1) cs position within top k 1 ws position within top k.(2) cs position within top k 1 ws position within top k (which impliesLength(i) > 2).(3) cs position within top k 1 ws position within top k.already discussed, option (2) suboptimal. Therefore, add 0S(k 1, c) S(k, w), add 1 U (k).remaining decision many votes corresponding numberU (k) choose option (1) (as opposed option (3)). corresponds Step 3dalgorithm, checks whether exists way choosing number extensions(but U (k)) choose (1) way c winner.Therefore, algorithm correct.260fiDetermining Possible Necessary Winners Given Partial OrdersFinally, consider possible co-winner problem respect plurality runoff.show problem solved polynomial time. this, also followsnecessary (unique) winner problem solved polynomial time (Proposition 1). contrast, already shown plurality runoff, possibleunique winner problem NP-complete (Theorem 8) necessary co-winner problemcoNP-complete (Theorem 9).algorithm determining whether c possible co-winner based followingkey observation: c possible co-winner Pposet respect plurality runoffexists extension Pposet , denoted P , alternative 6= c,two natural numbers l1 , l2 , (1) c preferred least half votes (linearorders) P , (2) P luP (c) = l1 , P luP (d) = l2 , alternative c (c 6= cc 6= d), P luP (c ) min{l1 , l2 }. is, c enter runoff (there couldpairs alternatives enter runoff parallel universe) c defeatrunoff.1, let denote number partial orders Pposetci c. recall op(O) denote set alternatives c existsleast one extension c top position. Based observationsprevious paragraph, consider possibilities l1 , l2 , (we usedenote possibilities index d), solve maximum flow problem instancepossibility.9 Specifically, every l1 , l2 n every 1 (with n/2),define maximum flow problem Fl1 ,l2 ,i follows (illustrated Figure 5, = 1).c1O111c1n/2 1l1c1l21c2...lmin1...1cm11n l1 l2lminFigure 5: maximum flow problem Fl1 ,l2 ,1 .Vertices: s, O1 , . . . , , ci , c, c1 , . . . , cm1 , , t.Edges: following five types edges.Edges {O1 , . . . , }: every n, edge (s, Oi )capacity 1.9. original proof used minimum cost flow problem, one anonymous reviewers pointedmodify approach simpler maximum flow approach presented here, well twopapers (Gusfield & Martel, 2002; Russell & Walsh, 2009) maximum flow problems usedsolve election problems, thank reviewer.61fiXia & ConitzerEdges {O1 , . . . , } {ci , c, c1 , . . . , cm1 }:every j n every C 6= ci , op(Oj ),edge (Oj , d) capacity 1;every j n, ci op(O) ci Oj c, edge (Oj , ci )capacity 1;j n, edge (Oj , ci ) capacity 1 ci op(O)ci 6Oj c.Edge ci ci : edge (ci , ci ) capacity n/2 .Edges C \ {c, ci } : every c C \ {c, ci }, edge (c , )capacity lmin = min{l1 , l2 }.Edges {c, ci , } t:edge (c, t) capacity l1 ;edge (ci , t) capacity l2 ;edge (t , t) capacity n l1 l2 .Next, prove c possible co-winner Pposet respect plurality runoffexist l1 , l2 n 1 Fl1 ,l2 ,i solutionvalue flow n.parameters Fl1 ,l2 ,i integers, exists solution Fl1 ,l2 ,i ,must also exists integer solution. First, show convert integer solutionFl1 ,l2 ,i solution PcW problem respect plurality runoff. Let finteger solution Fl1 ,l2 ,i , is, f : Vertices Vertices Z. constructextension P = (V1 , . . . , Vn ) Pposet follows:j n, f (Oj , ci ) = 1 let Vj extension Oj ciranked top position;j n C \ {ci }, f (Oj , d) = 1 let Oj extensionOj ranked top position, c ranked high possible.value f n, plurality score c l1 plurality score cil2 , plurality score ci (i 6= ) lmin . Therefore, c ci enterrunoff together one parallel universe. Now, capacity constraint edge (ci , ci )ensures c win runoff: reason rank ci first votecould ranked c ahead ci , contribute 1 flow edge.Moreover, capacity edge (ci , ci ) n/2 , means ci c+ (n/2 ) n/2 votes P . Hence, c co-winner P .Conversely, exists extension P P c co-winner P ,exists ci parallel universe, {c, ci } enter runoff, c winsrunoff. Let l1 , l2 plurality scores c, ci , respectively. Then, extensionconverted solution Fl1 ,l2 ,i (we omit details similardetails direction).Therefore, following algorithm solves PcW respect plurality runoff.Algorithm 4 (Computing PcW respect plurality runoff )62fiDetermining Possible Necessary Winners Given Partial Orders1. Pposet , compute op(O) UpO (c). 1, let = |{OPposet : ci UpO (c)}|.2. Repeat Steps 3ab 1 l1 , l2 n:3a. Construct maximum flow problem Fl1 ,l2 ,i .3b. Solve Fl1 ,l2 ,i FordFulkerson algorithm (Cormen, Leiserson, Rivest, &Stein, 2001). maximum flow n, output c possible cowinner. Terminate algorithm.4. Output c possible co-winner.Proposition 6 Algorithm 4 checks whether c possible co-winner Pposetrespect plurality runoff polynomial time.recall proof Proposition 1 c necessary unique winneralternative possible co-winner. Therefore, naturally obtain algorithmNW, simply using Algorithm 4 check alternative c possibleco-winner.Proposition 7 Algorithm 4 used check whether c necessary uniquewinner Pposet respect plurality runoff polynomial time.6. Conclusion Future Workconsidered following problem: given set alternatives, voting rule,set partial orders, alternatives possible/necessary winners? is,alternatives would win some/all extension partial orders? considered casevotes weighted number alternatives bounded. Table 1introduction summarizes results. results hold whether alternativemust unique winner, merely co-winner, unless specifically mentioned.paper, restriction partial orders. However, reasonpartial orders preferences submitted CP-nets, introducesadditional structure partial orders; is, partial orders correspondCP-net. Hence, positive results would still apply, immediately obviousnegative results would still apply.Another approach approximate sets possible/necessary winners. precisely, asked output superset (respectively, subset) possible (respectively,necessary) winners size output set within fixed rationumber possible (respectively, necessary) winners. Pini et al. (2007) provedinapproximability set possible/necessary winners single transferable voterule (STV) rule. conjecture similar inapproximability results holdcommon voting rules studied paper (for possible/necessary winnerproblems (co-)NP-complete).63fiXia & ConitzerAcknowledgmentsthank Nadja Betzler, Jerome Lang, Toby Walsh, anonymous reviewers AAAI-08JAIR, participants Dagstuhl Seminar 07431: Computational IssuesSocial Choice helpful discussions comments. Lirong Xia supported JamesB. Duke Fellowship Vincent Conitzer supported Alfred P. Sloan Research Fellowship. work supported NSF award numbers IIS-0812113 CAREER0953756.ReferencesBachrach, Y., Betzler, N., & Faliszewski, P. (2010). Probabilistic possible winner determination. Proceedings National Conference Artificial Intelligence (AAAI),pp. 697702, Atlanta, GA, USA.Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. SocialChoice Welfare, 8 (4), 341354.Bartholdi, III, J., Tovey, C., & Trick, M. (1989a). computational difficulty manipulating election. Social Choice Welfare, 6 (3), 227241.Bartholdi, III, J., Tovey, C., & Trick, M. (1989b). Voting schemesdifficult tell election. Social Choice Welfare, 6, 157165.Baumeister, D., & Rothe, J. (2010). Taking final step full dichotomy possiblewinner problem pure scoring rules. Proceedings 19th European ConferenceArtificial Intelligence (ECAI), pp. 10191020, Lisbon, Portugal.Betzler, N., & Dorn, B. (2010). Towards dichotomy possible winner problemelections based scoring rules. Journal Computer System Sciences, 76 (8),812836.Betzler, N., Hemmann, S., & Niedermeier, R. (2009). multivariate complexity analysisdetermining possible winners given incomplete votes. Proceedings TwentyFirst International Joint Conference Artificial Intelligence (IJCAI), pp. 5358,Pasadena, CA, USA.Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: toolrepresenting reasoning conditional ceteris paribus statements. JournalArtificial Intelligence Research, 21, 135191.Chevaleyre, Y., Lang, J., Maudet, N., & Monnot, J. (2010). Possible winners new candidates added: case scoring rules. Proceedings National ConferenceArtificial Intelligence (AAAI), Atlanta, GA, USA.Chevaleyre, Y., Lang, J., Maudet, N., Monnot, J., & Xia, L. (2010). New candidateswelcome! Possible winners respect addition new candidates. Technicalreport, Cahiers du LAMSADE 302, Universite Paris-Dauphine.Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. JournalArtificial Intelligence Research, 35, 161191.64fiDetermining Possible Necessary Winners Given Partial OrdersConitzer, V., Rognlie, M., & Xia, L. (2009). Preference functions score rankingsmaximum likelihood estimation. Proceedings Twenty-First InternationalJoint Conference Artificial Intelligence (IJCAI), pp. 109115, Pasadena, CA, USA.Conitzer, V., & Sandholm, T. (2002). Vote elicitation: Complexity strategy-proofness.Proceedings National Conference Artificial Intelligence (AAAI), pp. 392397, Edmonton, AB, Canada.Conitzer, V., & Sandholm, T. (2005a). Common voting rules maximum likelihood estimators. Proceedings 21st Annual Conference Uncertainty ArtificialIntelligence (UAI), pp. 145152, Edinburgh, UK.Conitzer, V., & Sandholm, T. (2005b). Communication complexity common voting rules.Proceedings ACM Conference Electronic Commerce (EC), pp. 7887,Vancouver, BC, Canada.Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidateshard manipulate?. Journal ACM, 54 (3), 133.Cormen, T., Leiserson, C., Rivest, R., & Stein, C. (2001). Introduction Algorithms(Second edition). MIT Press.Elkind, E., Faliszewski, P., & Slinko, A. (2009). Swap bribery. Proceedings 2ndInternational Symposium Algorithmic Game Theory.Elkind, E., & Lipmaa, H. (2005). Hybrid voting protocols hardness manipulation.Annual International Symposium Algorithms Computation (ISAAC), 3827Lecture Notes Computer Science, pp. 206215, Sanya, Hainan, China.Erdelyi, G., Fernau, H., Goldsmith, J., Mattei, N., Raible, D., & Rothe, J. (2009). complexity probabilistic lobbying. 1st International Conference AlgorithmicDecision Theory, pp. 8697, Venice, Italy.Erdos, P., & Moser, L. (1964). representation directed graphs unionsorderings. Math. Inst. Hung. Acad. Sci., 9, 125132.Faliszewski, P. (2008). Nonuniform bribery. Proceedings Seventh InternationalJoint Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp.15691572, Estoril, Portugal.Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: ties matter.Proceedings Seventh International Joint Conference Autonomous AgentsMulti-Agent Systems (AAMAS), pp. 983990, Estoril, Portugal.Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2010). Manipulation copeland elections. Proceedings Nineth International Joint Conference AutonomousAgents Multi-Agent Systems (AAMAS), pp. 367374, Toronto, Canada.Garey, M., & Johnson, D. (1979). Computers Intractability. W. H. FreemanCompany.Gibbard, A. (1973). Manipulation voting schemes: general result. Econometrica, 41,587602.Gusfield, D., & Martel, C. (2002). structure complexity sports eliminationnumbers. Algorithmica, 32, 7386.65fiXia & ConitzerHazon, N., Aumann, Y., Kraus, S., & Wooldridge, M. (2008). Evaluation election outcomes uncertainty. Proceedings Seventh International Joint ConferenceAutonomous Agents Multi-Agent Systems (AAMAS), pp. 959966, Estoril,Portugal.Hemaspaandra, E., & Hemaspaandra, L. A. (2007). Dichotomy voting systems. JournalComputer System Sciences, 73 (1), 7383.Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (1997). Exact analysis Dodgsonelections: Lewis Carrolls 1876 voting system complete parallel access NP.Journal ACM, 44 (6), 806825.Konczak, K., & Lang, J. (2005). Voting procedures incomplete preferences. Multidisciplinary Workshop Advances Preference Handling.Lang, J. (2007). Vote aggregation combinatorial domains structured preferences. Proceedings Twentieth International Joint Conference ArtificialIntelligence (IJCAI), pp. 13661371, Hyderabad, India.Lang, J., Pini, M. S., Rossi, F., Venable, K. B., & Walsh, T. (2007). Winner determinationsequential majority voting. Proceedings Twentieth International JointConference Artificial Intelligence (IJCAI), pp. 13721377, Hyderabad, India.Lang, J., & Xia, L. (2009). Sequential composition voting rules multi-issue domains.Mathematical Social Sciences, 57 (3), 304324.McGarvey, D. C. (1953). theorem construction voting paradoxes. Econometrica,21 (4), 608610.Parkes, D. (2006). Iterative combinatorial auctions. Cramton, P., Shoham, Y., & Steinberg, R. (Eds.), Combinatorial Auctions, chap. 2, pp. 4177. MIT Press.Pini, M. S., Rossi, F., Venable, K. B., & Walsh, T. (2007). Incompleteness incomparability preference aggregation. Proceedings Twentieth International JointConference Artificial Intelligence (IJCAI), pp. 14641469, Hyderabad, India.Rothe, J., Spakowski, H., & Vogel, J. (2003). Exact complexity winner problemYoung elections. Theory Computing Systems, Vol. 36(4), pp. 375386. SpringerVerlag.Russell, T., & Walsh, T. (2009). Manipulating tournaments cup round robin competitions. Proceedings First International Conference Algorithmic DecisionTheory (ADT), Lecture Notes Artificial Intelligence 5783, pp. 2637.Sandholm, T., & Boutilier, C. (2006). Preference elicitation combinatorial auctions.Cramton, P., Shoham, Y., & Steinberg, R. (Eds.), Combinatorial Auctions, chap. 10,pp. 233263. MIT Press.Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondence theorems voting procedures social welfare functions. JournalEconomic Theory, 10, 187217.Walsh, T. (2007). Uncertainty preference elicitation aggregation. ProceedingsNational Conference Artificial Intelligence (AAAI), pp. 38, Vancouver, BC,Canada.66fiDetermining Possible Necessary Winners Given Partial OrdersXia, L., Lang, J., & Monnot, J. (2011). Possible winners new alternatives join:New results coming up!. apprea Proceedings Tenth International JointConference Autonomous Agents Multi-Agent Systems (AAMAS).Xia, L., & Conitzer, V. (2008). Determining possible necessary winners common voting rules given partial orders. Proceedings National ConferenceArtificial Intelligence (AAAI), pp. 196201, Chicago, IL, USA.Xia, L., Conitzer, V., & Procaccia, A. D. (2010). scheduling approach coalitionalmanipulation. Proceedings ACM Conference Electronic Commerce (EC),pp. 275284, Boston, MA, USA.Xia, L., Lang, J., & Ying, M. (2007a). Sequential voting rules multiple elections paradoxes. Proceedings Eleventh Conference Theoretical Aspects RationalityKnowledge (TARK), pp. 279288, Brussels, Belgium.Xia, L., Lang, J., & Ying, M. (2007b). Strongly decomposable voting rules multiattributedomains. Proceedings National Conference Artificial Intelligence (AAAI),pp. 776781, Vancouver, BC, Canada.Xia, L., Zuckerman, M., Procaccia, A. D., Conitzer, V., & Rosenschein, J. (2009). Complexity unweighted coalitional manipulation common voting rules.Proceedings Twenty-First International Joint Conference Artificial Intelligence (IJCAI), pp. 348353, Pasadena, CA, USA.Zuckerman, M., Procaccia, A. D., & Rosenschein, J. S. (2009). Algorithms coalitionalmanipulation problem. Artificial Intelligence, 173 (2), 392412.67fi