Journal Articial Intelligence Research 15 (2001) 163-187

Submitted 10/00; published 09/01

Analysis Reduced Error Pruning
elomaa@cs.helsinki.fi
matti.kaariainen@cs.helsinki.fi

Tapio Elomaa
Matti Kriinen
Department Computer Science
P. O. Box 26 (Teollisuuskatu 23)
FIN-00014 University Helsinki, Finland

Abstract

Top-down induction decision trees observed suer inadequate
functioning pruning phase. particular, known size resulting
tree grows linearly sample size, even though accuracy tree
improve. Reduced Error Pruning algorithm used representative
technique attempts explain problems decision tree learning.
paper present analyses Reduced Error Pruning three dierent settings.
First study basic algorithmic properties method, properties hold independent input decision tree pruning examples. examine situation
intuitively lead subtree consideration replaced leaf node,
one class label attribute values pruning examples independent
other. analysis conducted two dierent assumptions. general
analysis shows pruning probability node tting pure noise bounded
function decreases exponentially size tree grows. specic analysis
assume examples distributed uniformly tree. assumption lets
us approximate number subtrees pruned receive
pruning examples.
paper claries dierent variants Reduced Error Pruning algorithm,
brings new insight algorithmic properties, analyses algorithm less imposed
assumptions before, includes previously overlooked empty subtrees
analysis.
1. Introduction
Decision tree learning usually two-phase process (Breiman, Friedman, Olshen, & Stone,
1984; Quinlan, 1993).

training examples

First tree reecting given sample faithfully possible

constructed. noise prevails, accuracy tree perfect

used build tree. practice, however, data tends noisy,
may introduce contradicting examples training set.

overtted

necessarily obtained even training set.


Hence, 100% accuracy cannot

case, resulting decision tree

sample; addition general trends data, encodes

pruned

peculiarities particularities training data, makes poor predictor
class label future instances. second phase induction, decision tree

order reduce dependency training data. Pruning aims removing
tree parts likely due chance properties training set.
problems two-phased top-down induction decision trees well-known
extensively reported (Catlett, 1991; Oates & Jensen, 1997, 1998). size

c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiElomaa & Kriinen
tree grows linearly size training set, even though
accuracy gained increased tree complexity. Obviously, pruning intended
ght eect. Another defect observed data contains relevant attributes;
i.e., class labels examples independent attribute values. Clearly,
single-node tree predicting majority label examples result case,
since help obtained querying attribute values. practice, though, often
large decision trees built data.
Many alternative pruning schemes exist (Mingers, 1989a; Esposito, Malerba, & Semeraro, 1997; Frank, 2000).

pruning examples

dier, e.g., whether single pruned tree series

pruned trees produced, whether separate set

used, aspects

(classication error tree complexity) taken account pruning decisions,
aspects determined, whether single scan tree suces whether
iterative processing required.

basic pruning operation applied tree

replacement internal node together subtree rooted leaf.
Also elaborated tree restructuring operations used pruning techniques

majority leaf
pruning tree

(Quinlan, 1987, 1993). paper, pruning operation considered
replacement subtree
examples reaching it. Hence,

, i.e., leaf labeled majority class
subtree original tree

zero, one, internal nodes changed leaves.

Reduced Error Pruning

(subsequently

rep short) introduced Quinlan (1987)

context decision tree learning. subsequently adapted rule set learning
well (Pagallo & Haussler, 1990; Cohen, 1993).
practical decision tree pruning

overprunes

rep

rep one simplest pruning strategies.

seldom used, disadvantage

requiring separate set examples pruning. Moreover, considered aggressive
pruning strategy

decision tree, deleting relevant parts (Quinlan,

1987; Esposito et al., 1997). need pruning set often considered harmful
scarceness data. However, data mining context examples often
abundant setting part aside pruning purposes presents problem.
Despite shortcomings

rep

baseline method performance

pruning algorithms compared (Mingers, 1989a; Esposito, Malerba, & Semeraro, 1993;
Esposito et al., 1997).

presents good starting point understanding strengths

weaknesses two-phased decision tree learning oers insight decision tree
pruning.

rep advantage producing smallest pruning among

accurate respect pruning set. Recently, Oates Jensen (1999) analyzed

rep attempt explain decision tree pruning fails control growth

tree, even though data warrant increased size. approach
subject, try avoid restricting analysis unnecessary assumptions.

also

consider explanation unwarranted growth size decision tree.

rep three dierent settings. First, explore basic algorep, apply regardless distribution examples presented

paper analyze
rithmic properties

learning algorithm. Second, study, probabilistic setting, situation
attribute values independent classication example. Even though
pure noise tting situation expected arise whole pruning set considered,
encountered lower levels tree, relevant attributes already
exhausted. assume subtrees receive least one pruning example,

164

fiAn Analysis Reduced Error Pruning
none directly pruned due receiving examples. class value
also assigned random pruning examples. third analysis assumed
pruning example equal chance end one subtrees tree
pruned. rather theoretical setting lets us take account subtrees
receive examples. left without attention earlier analyses.
rest paper organized follows. next section discusses dierent
versions

rep

algorithm xes one analyzed subsequently. Section

3 review earlier analyses

rep.

Basic algorithmic properties

Section 4. Then, Section 5, carry probabilistic analysis
assumptions distribution examples.

rep examined
rep, without making

derive bound pruning

probability tree depends exponentially relation number pruning
examples size tree. Section 6 presents analysis, assumes
pruning examples distribute uniformly subtrees tree. assumption lets us
sharpen preceding analysis certain aspects. However, bounds Section 5 hold
certainty, Section 6 approximate results. related research
briey reviewed Section 7 and, nally, Section 8 present concluding remarks
study.

2. Reduced Error Pruning Algorithm

rep

never introduced algorithmically Quinlan (1987), source much

confusion. Even though

rep

considered appears simple, almost trivial,

algorithm pruning, many dierent algorithms go name.
consensus exists whether

rep bottom-up algorithm

iterative method. Neither

obvious whether training set pruning set used decide labels leaves
result pruning.

2.1 High-Level Control
Quinlan's (1987, p. 225226) original description

rep clearly specify pruning

algorithm leaves room interpretation. includes, e.g., following characterizations.
every non-leaf subtree







examine change misclassications

test set would occur



replaced best possible leaf.

new tree would give equal fewer number errors
subtree property,

replaced leaf.

contains

process continues

replacements would increase number errors test
set.
[...] nal tree accurate subtree original tree respect
test set smallest tree accuracy.
Quinlan (1987, p. 227) also later continues give following description.
method [pessimistic pruning] two advantages. much faster
either preceding methods [cost-complexity reduced error pruning]
since subtree examined once.

165

fiElomaa & Kriinen
one hand description requires nodes processed bottom-up manner,
since subtrees must checked property pruning node but,
hand, last quotation would indicate

rep

rep

iterative method.

take

following single-scan bottom-up control strategy like studies

(Oates & Jensen, 1997, 1998, 1999; Esposito et al., 1993, 1997; Kearns & Mansour, 1998).
Nodes pruned single bottom-up sweep decision tree, pruning node considered encountered.

nodes processed

postorder.
order node processing, tree candidate pruning cannot
contain subtree could still pruned without increasing tree's error.
Due ambiguity
1989a; Mitchell, 1997).

rep's denition, dierent version rep also lives (Mingers,

probably due Mingers' (1989) interpretation Quinlan's

ambiguous denition.
Nodes pruned iteratively, always choosing node whose removal
increases decision tree accuracy pruning set. process continues
pruning harmful.
However, algorithm appears incorrect. Esposito et al. (1993, 1997) shown
tree produced algorithm meet objective accurate
subtree respect pruning set.

Moreover, algorithm overlooks explicit

requirement checking whether subtree would lead reduction classication
error.
iterative algorithms could induced Quinlan's original description. However, explicit requirement checking whether subtree could pruned pruning supertree obeyed, versions

rep

reduce ecient

bottom-up algorithm.

2.2 Leaf Labeling
Another source confusion Quinlan's (1987) description

rep

clearly

specied choose labels leaves introduced tree

training

pruning. Oates Jensen (1999) interpreted intended algorithm would label
new leaves according majority class

pruning

examples, analyzed

version algorithm new leaves obtain labels majority
examples. Oates Jensen motivated choice empirical observation

practice little dierence choosing leaf labels either way.
However, choosing labels pruned leaves according majority pruning examples
set leaves dierent status original leaves, label
majority class training examples.

Example

Figure 1 shows decision tree pruned single leaf

training examples used label pruned leaves. negative leaf replaces root
tree makes two mistakes pruning examples, original tree makes three
mistakes.

tree illustrate important dierence using training

166

fiAn Analysis Reduced Error Pruning





+



+



+

0/1

0/1

2/0

2/0

Figure 1: (part a) decision tree. labels inside nodes denote majority classes
training examples arriving nodes. leaves numbers pruning
examples two classes also given.

x=y

means

x negative





positive instances reach leaf.

pruning examples label pruned leaves. Using training examples proceeding bottomup, observe neither subtree pruned, since left one replaced negative leaf
would make two mistakes instead original one mistake. Similarly, right subtree
replaced positive leaf would result increased number classication errors.
Nevertheless, root node even though subtrees pruned still
pruned.
pruning examples used label pruned leaves, node two non-trivial
subtrees cannot pruned unless subtrees collapsed leaves.

next

section prove this. tree Figure 1 subtrees would collapsed zeroerror leaves. However, case root node pruned.

possibility labeling leaf nodes would take training
pruning examples account deciding label pruned leaf.

Depending

relation numbers training pruning examples strategy resembles one
above-described approaches. Usually training examples numerous
pruning examples, thus dominate. practice impossible discern
labeling strategy using majority training examples.

2.3 Empty Subtrees
Since

rep

uses dierent sets examples construct prune decision tree,

possible parts tree receive examples pruning phase.
parts decision tree, naturally, replaced single leaf without changing
number classication errors tree makes pruning examples.
words, subtrees obtain pruning examples always pruned. Quinlan (1987)
already noted parts original tree correspond rarer special cases,
represented pruning set, may excised.

167

fiElomaa & Kriinen
DecisionTree REP( DecisionTree T, ExampleArray )
{ ( = 0 S.length-1 ) classify( T, S[i] );
return prune( ); }
void classify( DecisionTree T, Example e )
{ T.total++; ( e.label == 1 ) T.pos++;
// update node counters
( !leaf(T) )
( T.test(e) == 0 ) classify( T.left, e );
else classify( T.right, e ); }
int prune( DecisionTree ) // Output classification error pruning
{ ( leaf(T) )
( T.label == 1 ) return T.total - T.pos;
else return T.pos;
else
{ error = prune( T.left ) + prune( T.right );
( error < min( T.pos, T.total - T.pos ) )
return error;
else
{ replace leaf;
( T.pos > T.total - T.pos )
{ T.label = 1; return T.total - T.pos; }
else
{ T.label = 0; return T.pos; } } } }
Table 1:

rep

algorithm. algorithm rst classies pruning examples top-

pass using method
tree using method

prune.

classify

bottom-up pass prunes

Intuitively, clear best-founded strategy handling

empty subtrees

,

receive examples. one hand obtain support training
set, usually numerous pruning set but, hand, fact
pruning example corresponds parts tree would justify drawing
conclusion parts decision tree built chance properties training
data.

rep,

consistently preferring smaller prunings also otherwise, latter view

adopted.
problem empty subtrees connected problem
learning algorithms (Holte, Acker, & Porter, 1989).
number training examples.

small disjuncts

machine

small disjunct covers small

Collectively small disjuncts responsible

small number classication decisions, accumulate error whole
concept. Nevertheless, small disjuncts cannot eliminated altogether, without adversely
aecting disjuncts concept.

168

fiAn Analysis Reduced Error Pruning
2.4 Analyzed Pruning Algorithm
Let us briey reiterate details

rep algorithm analyzed subsequently.

al-

ready stated, control strategy algorithm single-sweep bottom-up processing.
First, top-down traversal drives pruning examples tree appropriate
leaves. counters nodes en route updated. Second, bottom-up traversal pruning operations indicated classication errors executed.

errors

determined basis node counter values. bottom-up traversal
node visited once. pruned leaves labeled majority pruning set
(see Table 1).

3. Previous Work
Pruning decision trees recently received lot analytical attention; existing pruning
methods analyzed (Esposito et al., 1993, 1997; Oates & Jensen, 1997, 1998,
1999) new analytically-founded pruning techniques developed (Helmbold &
Schapire, 1997; Pereira & Singer, 1999; Mansour, 1997; Kearns & Mansour, 1998).

Also

many empirical comparisons pruning appeared (Mingers, 1989a; Malerba, Esposito,
& Semeraro, 1996; Frank, 2000). section review earlier work concerns

rep

algorithm. related research considered Section 7.

Esposito et al. (1993) viewed
search process state space.

rep

algorithm, among pruning methods,

addition noting iterative version

rep

cannot produce optimal result required Quinlan (1987), also observed even
though
tree

rep linear-time algorithm size tree, respect height
rep requires exponential time worst case. subsequent comparative

analysis Esposito et al. (1997) sketched proof Quinlan's (1987) claim pruning
produced

rep

tree.
bias

smallest among accurate prunings given decision

rep briey examined Oates Jensen (1997, 1998).

observed

rL , best majority leaf could replace subtree depends
(the class distribution ) examples reach root N . words, tree
structure N decides error rL . Let rT denote error subtree
moment pruning sweep reaches N ; i.e., pruning may already
taken place . pruning operations performed led either rT decrease
initial situation stay unchanged. case, pruning taken place
potentially decreases rT , aect rL . Hence, probability rT < rL i.e.,
pruned increases pruning . error propagation bias
error,

inherent

rep.

Oates Jensen (1997, 1998) conjecture larger original

tree smaller pruning set, larger eect, large tree provides
pruning opportunities high variance small pruning set oers random
chances

rL rT .

Subsequently study eects exactly.

follow-up study Oates Jensen (1999) used

rep

vehicle explaining

problems observed pruning phase top-down induction decision
trees. analyzed

rep situation

decision node consideration ts

noise i.e., class examples independent value attribute tested
node hand built statistical model

169

rep

situation. indicates,

fiElomaa & Kriinen
consistently earlier considerations, even though probability pruning
node ts noise prior pruning beneath close 1, pruning occurs beneath
node reduces pruning probability close 0. particular, model shows even
one descendant node

N

depth

pruned, N

pruned (assuming

+1). consequence result increasing depth
leads exponential decrease node's pruning probability.
leaves depth

rst part Oates Jensen's (1999) analysis easy comprehend, significance uncertain, situation rise bottom-up pruning strategy.
statistical model based assumption number,

n, pruning instances

pass node consideration large, case independence assumptions prevailing errors committed node approximated normal
distribution. expected error original tree mean distribution, while,
pruned leaf, tree would misclassify proportion

n examples corresponds

minority class. Oates Jensen show latter number always less
mean standard distribution errors. Hence, probability pruning
0.5 approaches 1

n grows.

second part analysis, considering pruning probability node

N

pruning taken place beneath it, Oates Jensen assume proportion
positive examples descendant
assuming

N

N

depth

N .

setting,

also
pruned,

positive majority, descendants level

positive majority. directly follows descendants level

replaced positive leaf. Hence, function represented pruning identically
positive. majority leaf would replace
smaller pruning. Therefore,

N

also represents function

rep choose single leaf pruning.



N depth pruned,
N , subtrees maintained nodes

hand, one descendants
pruning tree rooted
level



pruned positive leaves, accurate majority leaf.

case tree pruned.
Oates Jensen (1999) also assume starting node level

proba-

bility routing example positive leaf same. following analyses try
rid unnecessary assumptions; results obtained without knowledge
example distribution.

4. Basic Properties

rep

going detailed probabilistic analysis
basic algorithmic properties.

rep

algorithm, examine

Throughout paper review binary case

simplicity. results, however, also apply many-valued attributes several classes.
processing control

rep

algorithm settled, actually

prove Quinlan's (1987) claim optimality pruning produced

rep.

Observe

following result holds true independent leaf labeling strategy.

Theorem 1 Applying rep set pruning examples, , decision tree produces
0 pruning smallest prunings minimal
error respect example set S.
170

fiAn Analysis Reduced Error Pruning
Proof prove claim induction size tree. Observe decision
full binary tree, 2L(T ) 1 nodes, L(T ) number leaves

tree

tree.

Base case

.

L(T ) = 1,



original tree



consists single leaf node.





possible pruning itself. Thus, is, trivially, also smallest among
accurate prunings

T.

Inductive hypothesis
Inductive step L(T ) = k

. claim holds

.

. Let

N

right subtree, respectively. Subtrees
pruning decision

N

L(T ) < k.

T1

left

must strictly less



root tree

T0



T1

prunings trees.

T00



T10 ,

k leaves.

inductive hypothesis,

smallest possible among accurate

(i): Accuracy
N



taken, bottom-up recursive control strategy

rep T0 T1 already processed algorithm.
subtrees pruning,

T0

. pruning decision node

N consists choosing whether collapse

tree rooted majority leaf, whether maintain whole

tree. alternatives make number errors,

N

collapsed

original accuracy respect pruning set retained. Otherwise,

rep

algorithm, pruning decision based resulting trees would make

. Hence, whichever choice made,
0 make smaller number errors respect .
00
Let us assume pruning makes even less errors respect
0
00
00
00
. must consist root N two subtrees T0 T1 ,
0
00
majority leaf cannot accurate . Since accurate pruning
0 , must either T000 accurate pruning T0 T00 T100
0
accurate pruning T1 T1 . inductive hypothesis possibilities
0
false. Therefore, accurate pruning .

less errors respect pruning set
resulting tree

(ii): Size
0


. see chosen alternative also small possible, rst assume

consists single leaf. tree smallest pruning

claim follows.

T00 T10 .

0
Otherwise, consists root node N

, case

two pruned subtrees

Since tree collapsed, tree must accurate

tree consisting single majority leaf. assume exists pruning



0 , smaller. majority leaf less accurate
0



, must consist root node N two subtrees T0 T1 . Then, either
T0 smaller pruning T0 T00 , accurate, T1 smaller pruning
T1 T10 , accurate. cases contradict inductive hypothesis. Hence,
0 smallest among accurate prunings .




accurate

Thus, case, claim follows

T.

2

consider next situation internal node tree, bottom-up
pruning sweep reaches node.

committed leaf labeling

majority pruning examples.

171

fiElomaa & Kriinen

internal node, prior pruning leaves children,
pruned rep non-trivial subtree bottom-up pruning sweep reaches
it.
Theorem 2
Proof

internal node

N

two possible cases non-trivial

subtrees; either subtrees non-trivial (non-leaf ) one trivial. Let us
review cases.
Let

rT

denote error (sub)tree



respect part pruning set

. rL denote misclassication rate majority leaf L
, chosen pruned.

reaches root
would replace

Case I: Let two subtrees

, T0 T1 , non-trivial.

Hence,

rT0 < rL0 rT1 < rL1 ,
T0 T1 , respectively,
pruned. rT = rT0 + rT1 , must rT < rL0 + rL1 .
T0 T1 majority class, also majority class .
rL = rL0 + rL1 , L majority leaf corresponding . Otherwise,
rL rL0 + rL1 . case, rL rL0 + rL1 . Combining fact
rT < rL0 + rL1 means rT < rL . Hence, pruned.

retained pruning sweep passed them. Thus,

L0



Case II: Let





L1

majority leaves would replace

one trivial subtree, produced pruning, one non-

T0 non-trivial L1
T1 pruning process. Then, rT0 < rL0 . Hence,
rT = rT0 + rL1 < rL0 + rL1 .
way Case I, deduce rL rL0 + rL1 . Therefore,
rT < rL retained pruned tree.

trivial subtree. assume, without loss generality,
majority leaf replaced



cannot pruned either case, pruning process stopped branch



containing
node

unless original leaf appears along path root

N

2

T.

original leaf, may pruned even subtree

non-trivial. Also

N

N

two trivial subtrees, may pruned. Whether pruning

takes place depends class distribution examples reaching

N

subtrees.

analysis Oates Jensen (1999) shown prerequisite pruning
node

N

tree descendants depth



pruned.

depth rst (original) leaf subtree rooted
result situation, corroborate nding
descendants depth

retained.

N

N.





apply

pruned one

Applying Theorem 2 recursively gives

result.

tree rooted node N retained rep one
descendants N depth pruned.
Corollary 3

avoid analysis restricted leaf globally closest root, need

fringe

able consider set leaves closest root branches tree. Let us
dene

decision tree contains node prior pruning leaf

172

fiAn Analysis Reduced Error Pruning

Figure 2: fringe (black gray nodes), interior (white nodes), safe nodes
(black ones) decision tree. triangles denote non-trivial subtrees.

child. Furthermore, node subtree rooted node belonging

interior

Safe nodes

fringe tree also fringe. nodes belonging fringe make
tree.

belong fringe tree,

parent interior tree (see Figure 2). fringe decision tree closed
downwards, safe nodes tree correspond leaves pruning it. Observe
also along path root safe node leaves. Therefore,
pruning process ever reaches safe node, Theorem 2 applies corresponding branch
on.
decision tree consideration pruned single majority leaf, safe
nodes also need turned leaves point, necessarily simultaneously.
pruning sweep continues safe nodes, question whether node
pruned settled solely basis whether nodes path root
majority class. pruning whole tree characterized below.
Let



tree pruned

set pruning examples, jS j = n.

assume,

without loss generality, least half pruning examples positive. Let
proportion positive examples

; p 0:5.





p

replaced majority

leaf, leaf would positive class label. assumptions prove
following.

tree pruned single leaf
subtrees rooted safe nodes pruned
least many positive negative pruning examples reach safe node .

Theorem 4

173

fiElomaa & Kriinen
Proof

begin show two conditions necessary pruning

show former condition fullled,
leaf. Second, prove neither
latter not.
hold,





T.

First,

cannot pruned single

pruned former condition holds,

Third, show suciency conditions; i.e., prove



pruned single leaf.



(i): Let us rst assume

safe node

denition safe node, parent
Therefore, Theorem 2,
neither root



P

P



N

N

pruned.

originally leaves children.

pruned.

easy see, inductively,

pruned.

(ii): Let us assume subtrees rooted safe nodes get pruned
one safe nodes



negative positive pruning examples

fall. Observe safe nodes cannot such. Let us consider pruning



leaves situated place safe nodes; leaves receive
examples original safe nodes.

safe nodes internal nodes,

rep

corresponding pruned leaves labeled majority pruning examples.
particular, safe nodes receive negative positive examples
replaced negative leaves. leaves labeled positive. pruning
original tree accurate majority leaf. Hence, Theorem 1,
prune



rep



single-leaf tree.

(iii): Let us assume subtrees rooted safe nodes



pruned

least many positive negative pruning examples reach safe node.
interior nodes must also majority positive pruning examples. Otherwise,

negative positive examples. Thus,
N majority negative examples. Carrying
induction way safe nodes shows node N exist .
Hence, interior prunings represent function (identically positive)
error respect . majority leaf unique,

interior node

N



least one children

smallest prunings will, Theorem 1, chosen.

2
5. Probabilistic Analysis

rep

Let us turn attention question prerequisites pruning decision
tree



single majority leaf are. Since, Theorem 1,

rep

produces pruning



accurate respect pruning set small
possible, show



reduce single leaf suces nd pruning

better prediction accuracy pruning examples majority leaf has.
following class example assumed independent attribute
values. Obviously, decision tree node assumption holds
examples arriving it, would like pruning algorithm turn majority leaf.
make assumptions decision tree. However, similar analysis
Oates Jensen (1999), obtained bounds tight, shortest path
root tree leaf short.

174

fiAn Analysis Reduced Error Pruning
5.1 Probability Theoretical Preliminaries
Let us recall basic probabilistic concepts results used subsequently.
denote probability event

p

X
X B (n; p),

(integer-valued) random variable
, denoted

E



PrfE g

EE .

binomially distributed parameters n
expectation

said

discrete

!

n k
Prf X = k g =
p (1 p)n k ; k = 0; 1; : : : ; n:
k


X B (n; p), expected
p value mean EX = = np, variance varX = np(1 p),
= np(1 p).

indicator variable

standard deviation


1. indicator variable


A1 ; : : : ;

discrete random variable takes values 0



used denote occurrence non-occurrence event.

Pn

independent events

X=

IA

PrfAi g = p IA1 ; : : : ; IA

n

respective

i=1
Bernoulli
p
density function fX : ! [0; 1]
X
fX (x) = Prf X = x g
cumulative
distribution
function
F
:

!
[0; 1]
X
P
indicator variables,

IA



called



binomially distributed parameters

random variable parameter



discrete random variable

.

n p.

.



dened

FX (y) = Prf X g = xy fX (x).
Let X B (n; p) random variable mean = np standard
p
= np(1 p). normalized random variable corresponding X



X



dened

X

Xe =





deviation

:

central limit theorem approximate cumulative distribution function

e
X



normal Gaussian distribution


n

FXe (y) = Pr Xe



(y):

cumulative distribution function bell curve density function e
Respectively, apply
able

X

normal approximation

FX (y) = Prf X g = FXe

x2 =2 =

FXe

p

2 .

corresponding random vari-





:



5.2 Bounding Pruning Probability Tree
Now, pruning set considered sample distribution class
attribute independent attributes.

assume class attribute

(p) distribution; i.e., class positive probability
p negative probability 1 p. assume p > 0:5.
distributed according Bernoulli

following analyze situation subtrees rooted safe nodes
already pruned leaves. bound pruning probability tree starting
initial conguration.

Since bottom-up pruning may already come

halt situation, following results actually give high probability
pruning. Hence, following upper bounds tight possible.

175

fiElomaa & Kriinen
consider pruning decision tree

rep

trial whose result decided set



pruning examples. Theorem 4 approximate probability tree
pruned majority leaf approximating probability

safe nodes get

positive majority negative majority. latter alternative probable
assumption

p > :5.

safe assume never happens.

consider sampling pruning examples two phases. First attribute values
assigned.

decides leaf example falls.

second phase

independently assign class label example.

Z (T ) = fz1 ; : : : ; zk g let number examples
pruning set jS j = n. number pruning examples falling safe node zi
Pk
denoted ni ;
i=1 ni = n. time assume ni > 0 i. number
positive examples falling safe node zi sum independent Bernoulli variables
and, thus, binomially distributed parameters ni p. Respectively, number
negative pruning examples safe node zi Xi B (ni ; 1
p). probability
majority negative examples safe node zi Prf Xi > ni =2 g. bound
Let safe nodes tree





probability using following inequality (Slud, 1977).

Lemma 5 (Slud's inequality)
m(1 q) h mq,

Let X B(m; q) random variable q 1=2.
!

h mq
:
Prf X h g 1 p
mq(1 q)
p > :5 random variable corresponding number negative examples
zi Xi B (ni; 1 p), rst condition Slud's inequality holds. Furthermore,
see condition m(1
q) h mq holds safe node zi substitute h = ni =2, = ni ,
q = 1
p obtain ni p ni=2 ni(1 p). Thus,
Since

safe node



Pr Xi >


ni

2

!

!

=2 ni(1 p)
= 1 p(p 1=2)ni :
1 nip
ni p(1 p)
ni p(1 p)

(1)

ni , number pruning instances reaching safe node zi , grows, standard

normal distribution term bound also grows. Hence, bound probability
majority pruning examples reaching

zi

negative smaller

pruning examples reach it. probability negative majority also reduces
growing probability positive class example,

p.

also reected

pruning probabilities whole tree.
roughly approximate probability
majority leaf follows. Theorem 4,
node








pruned single

pruned leaf safe

receives majority positive examples.





k

safe nodes

n pruning examples, according pigeon-hole principle least half safe
r = 2n=k examples. safe node zi ni r examples has,

nodes receive

Inequality 1, negative majority least probability

!

1 p(p 1=2)r :
rp(1 p)
176

fiAn Analysis Reduced Error Pruning
Observe Inequality 1 also holds

ni < r, becausepthe cumulative

distribution

increasing function. argument ni (p 1=2)= ni p(1 p) canpbe rewritten
p

ni cp , cp ispa positive constant depending value p. Since ( ni cp ) grows
ni grows, 1
( ni cp ) grows decreasing ni . Hence, lower bound Inequality
1 also applies values 0 < ni < r .

function

Thus, probability half safe nodes receive

r

examples

positive majority

p(p 1=2)r
rp(1 p)

!!k=2

:

(2)

upper bound probability whole tree



pruned single

leaf. distribution assumption made reach result

p > :5.

order obtain tighter bounds, one make assumptions shape tree
distribution examples.
bound Equation 2 depends size decision tree (reected

n

p





k),

number ( ) class distribution ( ) pruning examples. Keeping parameters
constant letting

k

grow reduces pruning probability exponentially. number

pruning examples grows proportion

r = 2n=k

stays constant,

pruning probability still falls exponentially. Class distribution pruning examples also
aects pruning probability smaller, closer

p value .5.

5.3 Implications Analysis
empirically observed size decision tree grows linearly
training set size, even trees pruned (Catlett, 1991; Oates & Jensen, 1997,
1998). analysis gives us possibility explain behavior. However, let us
rst prove correlation attribute values class label
example, size tree perfectly ts training data depends linearly
size sample.
setting simple be. one real-valued attribute
attribute

y, whose value independent



x.

before,



x class

two possible values,

0 1. tree built using binary splits numerical value range; i.e., propositions
type

x < r

assigned internal leaves tree.

analysis duplicate

instances occur probability 0.

Let training examples (x; y) drawn distribution, x uniformly distributed range [0; 1) obtains value 1, independent x, probability
p, value 0 probability 1 p. expected size decision tree ts
data linear size sample.
Theorem 6

= h(x1 ; y1 ); : : : ; (xt ; yt )i sample described distribution.
xi 6= xj , 6= j , probability complement event 0.
Let us, further, assume examples indexed x1 < x2 < : : : < xt .
Let Ai indicator variable event instances + 1 dierent class
labels; i.e., yi 6= yi+1 , 1 1. EAi = Prf Ai = 1 g = p(1 p)+(1 p)p = 2p(1 p),
Proof

Let

may assume

177

fiElomaa & Kriinen
yi = 1 probability p, time event yi+1 = 0
1 p, vice versa. number class alternations = Pti=11 Ai

event
probability

expectation

EA =
Let



1
X
i=1

EAi =

1
X
i=1

2p(1 p) = 2p(1 p)

1
X
i=1

1 = 2(t 1)p(1 p):

decision tree grown sample

continued training error 0. leaf

[a; b) [0; 1).



yi 6= yy+1 ,



xi



xi+1



S.

(3)

growing

corresponds half open interval

must fall dierent leaves

T,



. Thus, upper boundary b
xi falls must value less xi+1 .

otherwise one example falsely classied
interval corresponding leaf

Repetitively applying observation scanning examples left

must least one leaf x1 one leaf class alternation;
+ 1 leaves total. using Equation 3 see expected number leaves

right, see
i.e.,






EA + 1 = 2(t 1)p(1 p) + 1:
particular, linear size sample ; jS j = t.

2

theorem concerns zero training error trees built rst phase
decision tree induction. empirical observations Catlett (1991) Oates Jensen
(1997, 1998), however, concern decision trees pruned second phase
induction. come back topic pruned trees shortly.
Consider

rep used practice.

amount (classied) data available

application domain. Let total

examples available. part ff
1 ff reserved

data used tree growing remaining portion
separate pruning set;

0 < ff < 1.

Quite common practice use two thirds data

growing one third pruning nine tenths growing one tenth pruning
(ten-fold) cross-validation used. decision tree construction phase tree
tted

fft examples perfectly possible.

hypothesize previous result

holds noisy real-world data sets, empirical evidence would appear
case, number safe nodes also grows linearly number leaves,
tree grown contain



safe nodes,

> 0. Since pruning set size also
r = 2n=k stays constant setting.

linear fraction training set size, ratio

Hence, Equation 2, growing data set size forces pruning probability zero, even
quite fast, reduction probability exponential.

5.4 Limitations Analysis
Empty subtrees, receive pruning examples, left without attention
above; assumed

ni > 0



i.

Empty subtrees, however, decisively aect

analysis; automatically pruned away. Unfortunately, one cannot derive non-trivial
upper bound number empty subtrees. worst case pruning examples
routed safe node, leaves

k 1 empty safe nodes tree.

Subsequently

review case examples distributed uniformly safe nodes.
better approximations obtained.

178

fiAn Analysis Reduced Error Pruning
Even though assume pruning example positive higher probability
.5, guarantees majority examples positive.

However,

probability majority examples changes small, even negligible,
Cherno 's inequality (Cherno, 1952; Hagerup & Rb, 1990) number pruning

n, high p extremely close one half.
Prf X h g, used bound
probability Prf X > h g. continuity correction could used compensate this.
examples,

Slud's inequality bounds probability

practice, inexactness make dierence.
Even though would appear number safe nodes increases proportion leaves size training set grows, proved
result. Theorem 6 essentially uses leaf nodes, lend modication,
safe nodes could substituted place leaves.
relation number safe nodes leaves decision tree depends
shape tree. Hence, splitting criterion used tree growing decisively
aects relation. splitting criteria aim keeping produced split balanced
possible, others aim separating small class coherent subsets data (Quinlan,
1986; Mingers, 1989b). example, common entropy-based criteria bias
favors balanced splits (Breiman, 1996). Using balanced splitting criterion would seem
imply number safe nodes tree depends linearly number leaves
tree.

case reasoning would explain empirically observed linear

growth pruned decision trees.

6. Pruning Probability Uniform Distribution
assume


k

n

pruning examples equal probability end

safe nodes; i.e., pruning example falls safe node

zi

probability

1=k.

Contrary normal uniform distribution assumption analysis, analysis
best case. best distribution examples safe nodes would one pruning
example safe nodes except one, remaining pruning instances
would gather.

Nevertheless, uniformity lets us sharpen general approximation

using standard techniques.

n=k. Let us calculate
cn=k examples, c
event safe node zi receives

expected number examples falling safe node
expected number safe nodes receive

QPi indicator
k Q number safe nodes receive less
i=1
Pk

linearity expectation EQ =
i=1 EQi = kEQ1 ,
last equality follows fact Qi -s identically distributed.
Let Y1 number examples reaching safe node z1 . n examples reaches z1 probability 1=k independent examples, Y1 binomially
distributed parameters n 1=k . Clearly EQ1 = Prf Y1 cn=k g. approxiarbitrary positive constant. Let


cn=k examples.
cn=k examples.



Q=

mate last probability normal approximation, obtain

!
!


cn=k
n=k
(
c
1)
n=k
cn
pn 1=k (1 1=k) = pn=k(1 1=k) :
Pr Y1
k
179

fiElomaa & Kriinen
Hence, observation,

!

(c 1)n=k :
EQ = kEQ1 k p
n=k(1 1=k)


(4)

use Approximation 4 determine probability whole decision tree
pruned single leaf. Let

denote



P

random variable represent number

cn=k examples least one example.
R number empty safe nodes, P = Q R. Hence, EP = E(Q R) =

safe nodes

receive

EQ ER.

following result (Kamath, Motwani, Palem, & Spirakis, 1994; Motwani & Raghavan,
1995) lets us approximate number empty safe nodes

Theorem 7

bins.

n k.

Let Z number empty bins balls thrown randomly h


= EZ = h 1

> 0,

Prf jZ

1

h

j g 2 exp

m=h

!

2 (h 1=2)
:
h2 2

result expected number empty safe nodes approximately
number small

ke

n=k ;



k relatively small compared n.
EQ (Equation 4) using pre-

Substituting obtained approximation
vious result, get

(c 1)n=k
EP = EQ ER k p
n=k(1 1=k)

!

e

n=k

!

:

Applying Slud's inequality can, before, bound probability
majority class change safe node receives
Since

P

cn=k

pruning examples.

safe nodes class distribution examples within

independent, event majority class change safe node receives
least one

cn=k examples

upper bound

p(p :5)r
rp(1 p)


r = cn=k.

Replacing

P

!!P

;

(5)

expected value equation approxi-

mation pruning probability. approximation valid
expected value. consider deviation

P

P

deviate lot

expected value below.

upper bound pruning probability similar upper bound
obtained without assumptions distribution examples. However,
earlier constant 2 replaced new, controllable parameter
explicitly taken account.

c, empty subtrees

c chosen suitably, upper bound strict

one obtained general case.

180

fiAn Analysis Reduced Error Pruning

Upper bound pruning probability
0.5
0.25

1

0.5

0

0.9
0.8
0.7

0.5
1

Figure 3: eect parameters

p

0.6

1.5

c

0.5

p c upper bound pruning probability

tree 100 safe nodes 500 pruning examples used. curves
depicting 0.25 0.5 upper bounds also shown.

6.1 Illustration Upper Bound
Figure 3 plots upper bound pruning probability tree 100 safe nodes
500 pruning examples used. value parameter

c varies 0 2 p varies

0.5 1. observe surface corresponding upper bound stays
close 0 class distribution skewed parameter

c

small value. probability example positive class label

c approaches 0, upper bound climbs steeply. least
parameter c due inexactness approximation

hits value 0.75 value
part
extreme values.
probability

p

example positive class approaches 1, error

committed single positive leaf falls 0. Hence, accuracy non-trivial pruning
better, closer

p 1 beat majority leaf.

Intuitively, probability

pruning exists i.e., root node pruned drop zero

p increases.

bound reects intuition.

value parameter

c falls close 0, safe nodes taken account

upper bound receive pruning examples. number nodes

181

fiElomaa & Kriinen
small. hand,

c

increased, number nodes consideration

grows together upper limit number examples reaching single one
them. Thus, small large values
value

c somewhere

c

yield loose bounds. strictest bounds

middle, example around values 1.01.5.

bound Equation 5 argument cumulative distribution function
zero value

c small,

tends towards

time exponent decreases.

approaches 1/2, argument goes zero. hand, c
large value, approaches value 1 exponent P also increases.
value

6.2 Exactness Approximation
used expected value P analysis; EP = EQ
ER. probe
deviation P expected value. deviation R directly available
Theorem 7:



!

2 (k 1=2)
:
k2 E2 R

Prf jR ERj g 2 exp

Q similar result yet.

Lipschitz condition

section provide one.

Let us rst recapitulate denition

.

f : D1 Dm ! IR real-valued function arguments
f said satisfy Lipchitz condition
x1 2 D1 ; : : : ; xm 2 Dm , 2 f1; : : : ; mg, yi 2 Di ,
Denition

Let

possibly distinct domains. function

jf (x1 ; : : : ; xi 1 ; xi ; xi+1; : : : ; xm ) f (x1; : : : ; xi 1 ; yi; xi+1 ; : : : ; xm )j 1:

Hence, function satises Lipschitz condition arbitrary change value
one argument change value function 1.

martingales

following result (McDiarmid, 1989) holds functions satisfying Lipschitz condition. general results kind obtained using
(Motwani & Raghavan, 1995)).

(see e.g.,

Theorem 8 (McDiarmid) Let X1 ; : : : ; Xm independent random variables taking values
set V . Let f : V ! IR that, = 1; : : : ; m:

sup

x1 ;:::;xm ;yi 2V

jf (x1; : : : ; xi 1; xi ; xi+1; : : : ; xm ) f (x1; : : : ; xi 1 ; yi; xi+1 ; : : : ; xm )j ci :

> 0,
Prf jf (X1 ; : : : ; Xm ) Ef (X1 ; : : : ; Xm )j g 2 exp

2
P2

c2
i=1

!

:

Wi , = 1; : : : ; n, random variable Wi = j i-th example
directed safe node zj . uniform distribution assumption Wi -s independent.
values within set f1; : : : ; k g. Let us dene function f
f (w1 ; : : : ; wn ) number safe nodes receive r = cn=k examples,
i-th example directed safe node zw . is,
Let



f (w1 ; : : : ; wn ) = jf 2 f 1; : : : ; k g j jSi j r gj;
182

fiAn Analysis Reduced Error Pruning


Si set examples directed safe node zi ;
Si = f h 2 f 1; : : : ; n g j wh = g:
Q = f (W1 ; : : : ; Wn ).

Hence,

Moving one example one safe node another (chang-

ing value one argument
dition


f

Pn

wi ), change one safe node zi

jSij r, one less safe node fulll it, time.

fulll conThus, value

changes 1. Hence, function fullls Lipschitz condition. Therefore,

apply McDiarmid's inequality substituting

c2 = n:

i=1

ci = 1 observing

2
Prf jf (W1 ; : : : ; Wn ) Ef (W1 ; : : : ; Wn )j g 2e 2 =n ;
equally

2
Prf jQ EQj g 2e 2 =n :

Unfortunately, concentration bound tight. Nevertheless, combining
concentration bounds

Q R P

following deviation expected

value.

Since jP
EP j = jQ R E(Q R)j = jQ EQ + ER Rj jQ EQj + jR ERj,
jQ R E(Q R)j implies jQ EQj =2 jR ERj =2. Thus,
Prf jP EP j g = Prf jQ R E(Q R)j g




Pr jQ EQj 2 + Pr jR ERj 2

!

2
2n + 2 exp

2 exp

!

2 (k 1=2)
:
4(k2 E2 R)

7. Related Work
Traditional pruning algorithms like cost-complexity pruning (Breiman et al., 1984), pessimistic pruning (Quinlan, 1987), minimum error pruning (Niblett & Bratko, 1986; Cestnik
& Bratko, 1991), critical value pruning (Mingers, 1989a), error-based pruning (Quinlan,
1993) already covered extensively earlier work (Mingers, 1989a; Esposito
et al., 1997; Frank, 2000). Thus touch methods further. Instead,
review recent work pruning.

rep

produces optimal pruning given decision tree respect pruning

set. approaches producing optimal prunings also presented (Breiman
et al., 1984; Bohanec & Bratko, 1994; Oliver & Hand, 1995; Almuallim, 1996). However,
often optimality measured training set. possible maintain
initial accuracy, assuming noise present. Neither usually possible reduce
size decision tree without sacricing classication accuracy. example,
work Bohanec Bratko (1994) studied eciently nd optimal
pruning sense output decision tree smallest pruning satises
given accuracy requirement. somewhat improved algorithm problem
presented subsequently Almuallim (1996).

183

fiElomaa & Kriinen
high level control Kearns Mansour's (1998) pruning algorithm

cost-complexity

bottom-up sweep

rep.

However, pruning criterion method kind

condition (Breiman et al., 1984) takes observed classication

error (sub)tree complexity account.

Moreover, pruning scheme

pessimistic

require pruning set separate training set. Mansour's (1997)
Kearns Mansour's (1998) algorithms
(sub)tree training error.

: try bound true error

Since training error nature optimistic,

pruning criterion compensate pessimistic error approximation.
Consider yet another variant

rep, one

otherwise similar one analyzed

above, exception original leaves put special status,
relabeled majority pruning examples like internal nodes. version


rep

produces optimal pruning respect performance Kearns

Mansour's (1998) algorithm measured. pessimistic pruning produces decision tree
smaller produced

rep.

Kearns Mansour (1998) able prove algorithm strong performance guarantee. generalization error produced pruning bounded
best pruning given tree plus complexity penalty.
local sense

rep

pruning decisions

basic pruning operation replacing

subtree leaf used pruning algorithm.

8. Conclusion
paper

rep

algorithm analyzed three dierent settings.

First,

rep alone, without assuming anything input
setting possible prove rep fullls

studied algorithmic properties
decision tree pruning set.



intended task produces optimal pruning given tree. algorithm proceeds
prune nodes branch long subtrees internal node pruned
stops immediately even one subtree kept. Moreover, prunes interior node
descendants level



pruned. Furthermore,

rep

either halts

safe nodes reached prunes whole tree case safe nodes
majority class.
second setting tree consideration assumed noise; i.e.,
assumed class label pruning examples independent attribute
values. setting pruning probability tree could bound equation
depends exponentially size tree linearly number class
distribution pruning examples. Thus, analysis corroborates main nding
Oates Jensen (1999)

rep fails control growth decision tree extreme

case tree ts pure noise. Moreover, analysis opened possibility initially
explain learned decision tree grows linearly increasing data set. bound
pruning probability tree based bounding probability safe nodes
majority class. Surprisingly, essentially property, whose probability
try bound close 0, assumed hold probability 1 analysis Oates
Jensen (1999).


rep

may happen pruning examples directed given subtree.

subtrees taken account earlier analyses.

184

nal analysis

fiAn Analysis Reduced Error Pruning
included empty subtrees equation tree's pruning probability.

Taking empty

subtrees account gives realistic bound pruning probability tree.
Unfortunately, one cannot draw denite general conclusions two-phased topdown induction decision trees basis analyses
bias quite unique among pruning algorithms.

fact

rep algorithm,
rep penalize

size tree, rests classication error pruning examples makes
method sensitive small changes class distribution pruning set. decision
tree pruning algorithms also individual characteristics. Therefore, unied analysis
decision tree pruning may impossible.
version

rep,

one allowed relabel original leaves, well, used

performance objective Kearns Mansour's (1998) pruning algorithm.

Thus,

performance pruning algorithms use error size penalty related
use error estimation. version

rep

used Kearns Mansour

analysis based safe nodes applies leaves place safe nodes. Hence
algorithm derived bounds stricter.
leave detailed analysis important pruning algorithms future work.
investigation possible disclose dierences similarities
pruning algorithms.

Empirical examination managed reveal clear performance

dierences methods.

Also, relationship number safe nodes

leaves tree ought examined analytically empirically. particular, one
study whether number safe nodes increase linearly growing training set,
conjectured paper. Deeper understanding existing pruning algorithms may help
overcome problems associated pruning phase decision tree learning.

References

Intelligence 83

Almuallim, H. (1996). ecient algorithm optimal pruning decision trees.
,

Learning 15

, 347362.

Bohanec, M., & Bratko, I. (1994). Trading accuracy simplicity decision trees.
,

(3), 223250.

Regression Trees

Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. (1984).
. Wadsworth, Pacic Grove, CA.

tional Joint Conference Articial Intelligence

Machine

Classication

Machine Learning 24
Proceedings Twelfth Interna-

Breiman, L. (1996). properties splitting criteria.
Catlett, J. (1991). Overpruning large decision trees.

Articial

,

(1), 4147.

, pp. 764769, San Mateo, CA. Morgan

Kaufmann.

Machine LearningEWSL-91: Proceedings Fifth European Working
Lecture Notes Articial Intelligence

Cestnik, B., & Bratko, I. (1991). estimating probabilities tree pruning. Kodrato,

Session

Y. (Ed.),

, Vol. 482

, pp. 138150, Berlin, Hei-

delberg, New York. Springer-Verlag.

Annals Mathematical Statistics 23

Cherno, H. (1952). measure asymptotic eciency tests hypothesis based
sum observations.

,

185

(4), 493507.

fiElomaa & Kriinen

Proceedings Thirteenth International Joint Conference Articial

Cohen, W. W. (1993).

Intelligence

systems.

Ecient pruning methods separate-and-conquer rule learning

, pp. 988994, San Mateo, CA. Morgan Kaufmann.

Machine Learning: ECML-93, Proceedings
Lecture Notes Articial Intelligence

Esposito, F., Malerba, D., & Semeraro, G. (1993).

Sixth European Conference

state space. Brazdil, P. B. (Ed.),

Decision tree pruning search

, Vol. 667

, pp.

165184, Berlin, Heidelberg, New York. Springer-Verlag.

IEEE Transactions Pattern Analysis Machine Intelligence 19
Pruning Decision Trees Lists
Information Processing
Letters 33
Machine Learning 27
Proceedings Eleventh International Joint Conference Articial
Intelligence
Proceedings Thirty-Fifth Annual
IEEE Symposium Foundations Computer Science

Esposito, F., Malerba, D., & Semeraro, G. (1997). comparative analysis methods
pruning decision trees.
,

(5), 476491.

Frank, E. (2000).

. Ph.D. thesis, University Waikato,

Department Computer Science, Hamilton, New Zealand.

Hagerup, T., & Rb, C. (1990). guided tour Cherno bounds.
,

(6), 305308.

Helmbold, D. P., & Schapire, R. E. (1997). Predicting nearly well best pruning
decision tree.

,

(1), 5168.

Holte, R. C., Acker, L., & Porter, B. (1989).

Concept learning problem small

disjuncts.

, pp. 813818, San Mateo, CA. Morgan Kaufmann.

Kamath, A., Motwani, R., Palem, K., & Spirakis, P. (1994).

Tail bounds occupancy

satisability threshold conjecture.

, pp. 592603, Los Alamitos,

CA. IEEE Press.

Proceedings Fifteenth Inter-

Kearns, M., & Mansour, Y. (1998). fast, bottom-up decision tree pruning algorithm

national Conference Machine Learning

near-optimal generalization. Shavlik, J. (Ed.),

, pp. 269277, San Francisco, CA. Morgan

Kaufmann.

Learning

Malerba, D., Esposito, F., & Semeraro, G. (1996). comparison simplication

Data: AI Statistics V
Proceedings Fourteenth International Conference Machine Learning

methods decision-tree induction. Fisher, D., & Lenz, H.-J. (Eds.),

, pp. 365374, Berlin, Heidelberg, New York. Springer-Verlag.

Mansour, Y. (1997). Pessimistic decision tree pruning based tree size. Fisher, D. H.
(Ed.),

,

pp. 195201, San Francisco, CA. Morgan Kaufmann.

Surveys Combinatorics: Invited Papers 12th British Combinatorial Conference
Machine Learning 4
Machine Learning 3
Machine Learning

McDiarmid, C. J. H. (1989). method bounded dierences. Siemons, J. (Ed.),
, pp. 148188, Cambridge, U.K. Cambridge University Press.

Mingers, J. (1989a). empirical comparison pruning methods decision tree induction.
,

(2), 227243.

Mingers, J. (1989b). empirical comparison selection measures decision-tree induction.

Mitchell, T. M. (1997).

,

(4), 319342.

. McGraw-Hill, New York.

186

fiAn Analysis Reduced Error Pruning
Motwani, R., & Raghavan, P. (1995).
New York.

Randomized Algorithms

. Cambridge University Press,

Research Development Expert Systems III

Niblett, T., & Bratko, I. (1986). Learning decision rules noisy domains. Bramer, M. A.
(Ed.),

, pp. 2534, Cambridge, UK.

Cambridge University Press.

Proceedings Fourteenth International Conference

Oates, T., & Jensen, D. (1997). eects training set size decision tree complexity.

Machine Learning

Fisher, D. H. (Ed.),

, pp. 254261, San Francisco, CA. Morgan Kaufmann.

Oates, T., & Jensen, D. (1998). Large datasets lead overly complex models: expla-

Proceedings Fourth International Conference Knowledge Discovery Data
Mining
Proceedings Sixteenth National Conference Articial Intelligence
nation solution.

Agrawal, R., Stolorz, P., & Piatetsky-Shapiro, G. (Eds.),

, pp. 294298, Menlo Park, CA. AAAI Press.

Oates, T., & Jensen, D. (1999).

Toward theoretical understanding

decision tree pruning algorithms fail.

, pp. 372378, Menlo Park, CA/Cambridge, MA. AAAI

Press/MIT Press.

Proceedings Twelfth International Conference Machine
Machine

Oliver, J. J., & Hand, D. J. (1995). pruning averaging decision trees. Prieditis, A.,

Learning
Learning 5

& Russell, S. (Eds.),

, pp. 430437, San Francisco, CA. Morgan Kaufmann.

Pagallo, G., & Haussler, D. (1990). Boolean feature discovery empirical learning.
,

(1), 7199.

Machine Learning 36

Pereira, F., & Singer, Y. (1999). ecient extension mixture techniques prediction
decision trees.

,

(3), 183199.

Machine Learning 1
International Journal Man-Machine
C4.5: Programs Machine Learning
Annals Probability

Quinlan, J. R. (1986). Induction decision trees.

Studies 27

Quinlan, J. R. (1987).
,

,

, 81106.

Simplifying decision trees.

(3), 221248.

Quinlan, J. R. (1993).

.

Morgan Kaufmann, San

Slud, E. V. (1977). Distribution inequalities binomial law.

,

Mateo, CA.

5

(3), 404412.

187

fiJournal Artificial Intelligence Research 15 (2001) 351-381

Submitted 9/00; published 11/01

Experiments Infinite-Horizon, Policy-Gradient Estimation
Jonathan Baxter

JBAXTER @ WHIZBANG . COM

WhizBang! Labs.
4616 Henry Street Pittsburgh, PA 15213

Peter L. Bartlett

BARTLETT @ BARNHILLTECHNOLOGIES . COM

BIOwulf Technologies.
2030 Addison Street, Suite 102, Berkeley,CA 94704

Lex Weaver

L EX .W EAVER @ ANU . EDU . AU

Department Computer Science
Australian National University , Canberra 0200, Australia

Abstract
paper, present algorithms perform gradient ascent average reward partially observable Markov decision process (POMDP). algorithms based GPOMDP,
algorithm introduced companion paper (Baxter & Bartlett, 2001), computes biased
estimates performance gradient POMDPs. algorithms chief advantages
uses one free parameter fi 2 [0; 1), natural interpretation terms bias-variance
trade-off, requires knowledge underlying state, applied infinite state,
control observation spaces. show gradient estimates produced GPOMDP
used perform gradient ascent, traditional stochastic-gradient algorithm,
algorithm based conjugate-gradients utilizes gradient information bracket maxima
line searches. Experimental results presented illustrating theoretical results Baxter
Bartlett (2001) toy problem, practical aspects algorithms number
realistic problems.

1. Introduction
Function approximation necessary avoid curse dimensionality associated largescale dynamic programming reinforcement learning problems. dominant paradigm
use function approximate state (or state action) values. algorithms seek
minimize form error approximate value function true value function,
usually simulation (Sutton & Barto, 1998; Bertsekas & Tsitsiklis, 1996).
multitude empirical successes approach (for example, Samuel, 1959; Tesauro, 1992,
1994; Baxter, Tridgell, & Weaver, 2000; Zhang & Dietterich, 1995; Singh & Bertsekas, 1997),
weak theoretical guarantees performance policy generated approximate
value function. particular, guarantee policy improve approximate
value function trained; fact performance degrade even function class contains
approximate value function whose corresponding greedy policy optimal (see Baxter & Bartlett,
2001, Appendix A, simple two-state example).
alternative technique received increased attention recently policy-gradient
approach parameters stochastic policy adjusted direction gradient
performance criterion (typically either expected discounted reward average reward).

c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBAXTER

ET AL .

key problem compute performance gradient conditions partial observability
explicit model system available.
question addressed large body previous work (Barto, Sutton, & Anderson,
1983; Williams, 1992; Glynn, 1986; Cao & Chen, 1997; Cao & Wan, 1998; Fu & Hu, 1994;
Singh, Jaakkola, & Jordan, 1994, 1995; Marbach & Tsitsiklis, 1998; Marbach, 1998; Baird &
Moore, 1999; Rubinstein & Melamed, 1998; Kimura, Yamamura, & Kobayashi, 1995; Kimura,
Miyazaki, & Kobayashi, 1997). See introduction (Baxter & Bartlett, 2001) discussion
history policy-gradient approaches. existing algorithms rely existence
identifiable recurrent state order make updates gradient estimate, variance
algorithms governed recurrence time state. cases recurrence time
large (for instance state space large), situations partial observability
state cannot reliably identified, need seek alternatives require
access state.
Motivated considerations, Baxter Bartlett (2001, 2000) introduced analysed
GPOMDPan algorithm generating biased estimate gradient average reward
general Partially Observable Markov Decision Processes (POMDPs) controlled parameterized
stochastic policies. chief advantages GPOMDP requires single sample path
underlying Markov chain, uses one free parameter fi 2 ; , natural
interpretation terms bias-variance trade-off, requires knowledge underlying
state.
specifically, suppose 2 R K parameters controlling POMDP. example,
could parameters approximate neural-network value-function generates stochastic
policy form randomized look-ahead, could parameters approximate Q
function used stochastically select controls1 . Let denote average reward POMDP
parameter setting . GPOMDP computes approximation rfi r based single
continuous sample path underlying Markov chain. accuracy approximation
controlled parameter fi 2 ; , one show

[0 1)

()

[0 1)

()

()

r() = filim
r ():
!1 fi

trade-off preventing choosing fi arbitrarily close 1 variance GPOMDPs estimates rfi scale =
fi 2 . However, bright side, also shown bias
rfi (measured krfi
r k) proportional fi suitable mixing
time Markov chain underlying POMDP (Bartlett & Baxter, 2000a). Thus rapidly
mixing POMDPs (for small), estimates performance gradient acceptable
bias variance obtained.
Provided rfi sufficiently accurate approximation r fact, rfi need
within r small adjustments parameters direction rfi guarantee improvement average reward . case, gradient-based optimization algorithms
using rfi gradient estimate guaranteed improve average reward
step. Except case table-lookup, value-function based approaches reinforcement learning cannot make guarantee.
paper present conjugate-gradient ascent algorithm uses estimates rfi
provided GPOMDP. Critical successful operation algorithm novel line search

()

()

90
()

1 (1 )
() ()

()
()

(1

)

()

()

()
()

()

()

1. Stochastic policies strictly necessary framework, policy must differentiable sense
() exists.

r

352

fiP OLICY-G RADIENT E STIMATION

subroutine brackets maxima relying solely upon gradient estimates. largely avoids
problems associated finding maximum using noisy value estimates. Since parameters
updated accumulating sufficiently accurate estimates gradient direction, refer
approach off-line algorithm. approach essentially allows us take stochastic
gradient optimization problem treat non-stochastic optimization problem, thus enabling
use large body accumulated heuristics algorithmic improvements associated
methods. also present traditional, on-line stochastic gradient ascent algorithm
based GPOMDP updates parameters every time step. algorithm essentially
algorithm proposed (Kimura et al., 1997).
off-line on-line algorithms applied variety problems, beginning simple
3-state Markov decision process (MDP) controlled linear function true gradient
exactly computed. show rapid convergence gradient estimates rfi true
gradient, case large range values fi . simple system able
illustrate vividly bias/variance tradeoff associated selection fi . compare
performance off-line on-line approaches applied finding good policy MDP.
off-line algorithm reliably finds near-optimal policy less 100 iterations Markov
chain, order magnitude faster on-line approach. attributed
aggressive exploitation gradient information off-line method.
Next demonstrate effectiveness off-line algorithm training neural network
controller control puck two-dimensional world. task case reliably
navigate puck starting configuration arbitrary target location minimum
time, applying discrete forces x directions. Although on-line algorithm
tried problem, convergence considerably slower able reliably
find good local optimum.
third experiment, use off-line algorithm train controller call admission
queueing problem treated (Marbach, 1998). case near-optimal solutions found within
2000 iterations underlying queue, 1-2 orders magnitude faster experiments
reported (Marbach, 1998) on-line (stochastic-gradient) algorithms.
fourth final experiment, off-line algorithm used reliably train switched
neural-network controller two-dimensional variation classical mountain-car task (Sutton & Barto, 1998, Example 8.2).
rest paper organized follows. Section 2 introduce POMDPs controlled
stochastic policies, assumptions needed algorithms apply. GPOMDP described
Section 3. Section 4 describe off-line on-line gradient-ascent algorithms, including
gradient-based line-search subroutine. Experimental results presented Section 5.

()

2.

POMDPs Controlled Stochastic Policies

partially observable, Markov decision process (POMDP) consists state space , observation
space control space U . state 2 deterministic reward r . Although
results Baxter Bartlett (2001) guarantee convergence GPOMDP case
finite (but continuous U ), algorithm applied regardless nature
restrict cardinality , U .
Consider first case discrete , U . control u 2 U determines stochastic
matrix P u
pij u giving transition probability state state j (i; j 2 ).

()

( ) = [ ( )]

353

fiBAXTER

ET AL .

state 2 , observation 2 generated independently according probability distribution
observations . denote probability . randomized policy
simply function mapping observations probability distributions controls U .
is, observation 2 , distribution controls U . Denote probability
control u given observation u .
continuous ; U , pij u becomes kernel kij u giving probability density
transitions j , becomes probability density function density ,
becomes probability density function U u density u.
randomized policy corresponds Markov chain state transitions
generated first selecting observation state according distribution , selecting control U according distribution , finally generating transition state j
according probability pij U .
present dealing fixed POMDP. parameterize POMDP parameterize policies, becomes function ; set parameters 2 R K ,
well observation . Markov chain corresponding state transition matrix
P
pij given
pij EY (i) EU (;Y ) pij U :
(1)

()

=

()

()
()

()

()

()

()
()

()

()

( )

( )

( )

( ) = [ ( )]

( )=

( )

Note policies purely reactive memoryless choice action based
upon current observation. experiments described present paper use purely reactive
policies. Aberdeen Baxter (2001) extended GPOMDP techniques present
paper controllers internal state.
following technical assumptions required operation GPOMDP.
Assumption 1. derivatives,

exist, ratios

@u (; y)
;
@k

( ) fififi

fi
fi @u ;
fi
fi
@

k

fi

u (; y)
uniformly bounded B < 1, u 2 U , 2 , 2 R K

k

= 1; : : : ; K .

second part assumption needed ratio appears GPOMDP algorithm. allows zero-probability actions u ;
ru ; also zero, case
set =
. See Section 5 examples policies satisfying requirement.

( )=0

0 0=0

Assumption 2. magnitudes rewards,
states i.

( )

jr(i)j, uniformly bounded R < 1

deterministic rewards, condition represents restriction infinite state spaces.
However, results present paper apply bounded stochastic rewards, case r
expectation reward state i.

()

()

Assumption 3. P ; 2 R K , unique stationary distribution
satisfying balance equations:

()P () = ():
354

() = [1 (; : : : ; n()],

fiP OLICY-G RADIENT E STIMATION

Assumption 3 ensures that, parameters , Markov chain forms single recurrent class.
Since finite-state Markov chain always ends recurrent class, properties
class determine long-term average reward, assumption mainly convenience
include recurrence class quantifier theorems. Observe
episodic problems, minimization time goal state, may modeled way
satisfies Assumption 3 simply resetting agent upon reaching goal state back
initial starting distribution states. Examples described Section 5.
average reward simply expected reward stationary distribution :

()

()

() =

()

n
X
i=1

()r(i):

(2)

Assumption 3, also equal expected long-term average reward received starting state i:
fi

!

1 TX1 r(X )fififi X0 =
() = lim E

fi
!1

t=0

:

expectation sequences states X0 ; : : : ; XT 1 state transitions generated
P (note expectation independent starting state i).

()

3. GPOMDP Algorithm
(Algorithm 1) algorithm computing biased estimate
average reward r . satisfies

GPOMDP

()

gradient

lim = rfi ();

!1

rfi

() (fi 2 [0; 1)) approximation r() satisfying
r() = filim
r ();
!1 fi

(Baxter & Bartlett, 2001, Theorems 2, 5). Note GPOMDP relies upon single sample path
POMDP. Also, require knowledge transition probability matrix P ,
observation process ; requires knowledge randomized policy , particular
ability compute gradient probability chosen control divided probability
chosen control.
cannot set fi arbitrarily close GPOMDP, since variance estimate proportional =
fi 2 . However, bright side, also shown bias rfi
(measured krfi r k) proportional
fi suitable mixing time
Markov chain underlying POMDP (Bartlett & Baxter, 2000a). Assumption 3, regardless
initial starting state, distribution states converges stationary distribution
agent following policy ; . Standard Markov chain theory shows rate
convergence exponential, loosely speaking, mixing time time constant
exponential decay.

1 (1

)
()

()

1

()

(1 )

()
()

( )

355

fiBAXTER

ET AL .

(fi; T; ) ! RK

Algorithm 1 GPOMDP
1: Given:

fi 2 [0; 1).
> 0.
Parameters 2 RK .
Randomized policy (; ) satisfying Assumption 1.
POMDP rewards satisfying Assumption 2, controlled (; )
generates stochastic matrices P


2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

() satisfying Assumption 3.

Arbitrary (unknown) starting state X0 .

=0
=0

=0
1



Set z0
0
(z0 ; 0 2 RK ).



Observe Yt (generated according observation distribution Xt )
Generate control Ut according ; Yt
Observe r Xt+1 (where next state Xt+1 generated according pXt Xt+1

( )
rUt (; Yt )
Set zt+1 = fizt +
Ut (; Yt )
Set t+1 = + r (Xt+1 )zt+1
end
=T
return

(

)

( )

(Ut )).

Thus fi natural interpretation terms bias/variance trade-off: small values fi
give lower variance estimates , higher bias expectation may far
r , whereas values fi close yield small bias correspondingly larger variance.
Fortunately, problems mix rapidly (small ), fi small still yield reasonable
bias. bias/variance trade-off vividly illustrated experiments Section 5; see (Bartlett
& Baxter, 2000a) detailed theoretical discussion bias/variance question.

()





1

4. Stochastic Gradient Ascent Algorithms
section introduces two approaches exploiting gradient estimates produced GPOMDP:

1. off-line approach based traditional conjugate-gradient optimization techniques employing novel line-search mechanism cope noise GPOMDPs estimates,
2. on-line stochastic optimization approach uses core update GPOMDP (r
update parameters every iteration POMDP.
356

(Xt )zt )

fiP OLICY-G RADIENT E STIMATION

4.1 Off-line optimization average reward


()
()

()

biased noisy estimates gradient average reward r
controlled parameterized stochastic policies. straightforward algorithm finding
local maxima would compute current parameter settings ,
modify
. Provided close enough true gradient direction r ,
provided step-sizes suitably decreasing, standard stochastic optimization theory tells us
technique converge local maximum . However, given computation
requires many iterations POMDP guarantee suitably accurate gradient estimates
(that is, general needs large), would like aggressively exploit information
contained simply adjusting parameters small amount direction
.
two techniques making better use gradient information widely used
non-stochastic optimization: better choice search direction better choice step size. Better search directions found employing conjugate-gradient directions rather pure
gradient direction. Better step sizes usually obtained performing kind line-search
find local maximum search direction, use second order methods. Since
line-search techniques tend robust departures quadraticity optimization
surface, consider (however, see Baxter & Bartlett, 2001, Section 7.3,
discussion second-order derivatives may computed GPOMDP-like algorithm).
CONJPOMDP, described Algorithm 2, version Polak-Ribiere conjugate-gradient
algorithm (see, e.g. Fine, 1999, Section 5.5.2) designed operate using noisy (and
possibly) biased estimates gradient objective function (for example, estimates
provided GPOMDP). argument GRAD CONJPOMDP computes gradient estimate.
novel feature CONJPOMDP GSEARCH, linesearch subroutine uses gradient information find local maximum search direction. use gradient information ensures GSEARCH robust noise performance estimates. CONJPOMDP
GSEARCH applied stochastic optimization problem noisy (and possibly)
biased gradient estimates available.
argument s0 CONJPOMDP provides initial step-size GSEARCH. argument
provides stopping condition; kGRAD k2 falls , CONJPOMDP terminates.
GPOMDP generates
POMDPs

()
+()

()

()

()

()

()



()

4.2 GSEARCH algorithm
key successful operation CONJPOMDP linesearch algorithm GSEARCH (Algorithm 3). GSEARCH uses gradient information bracket maximum direction ,
quadratic interpolation jump maximum.
found use gradients bracket maximum far robust use function
values. illustrate so, Figure 1 plotted stylized view average reward
along search direction (labeled f figure), gradient direction
r (labeled grad(f )). two ways could search direction bracket
maximum direction (at case), one using function values
using gradient estimates:

()
()

()

0

( )

( )

1. Find three points 1 ; 2 ; 3 , lying direction , 1 < 2
3 < 2 . Assuming overshooting, know maximum must lie 1

( )

( )

357

fiBAXTER

Algorithm 2
1: Given:



(

CONJPOMDP GRAD

GRAD

ET AL .

; ; s0 ; )

: RK ! RK : (possibly noisy biased) estimate gradient objec-

tive function maximized.





2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

Starting parameters 2 R K (set maximum return).
Initial step size s0

> 0.

Gradient resolution .

g = h = GRAD()
kg k2

(
; ; h; s0 ; )
= GRAD()
= ( g) =kgk2
h = + h
h < 0
h=
end
g=
GSEARCH GRAD

end

3 use three points quadratic interpolation estimate location
maximum.

( )

0

( )

0

2. Find two points 1 2 r 1 > r 2 < , use
quadratic interpolation (which corresponds linear interpolation gradients) estimate
location maximum.
approaches equally satisfactory provided noise either function
estimates , gradient estimates r . However, estimates r
available simulation, necessarily noisy situation look
like Figure 2. case use gradients bracket maximum becomes desirable,
line-search technique based value estimates could choose peaks
plot f noise location maximum, occur nearly uniformly along x-axis,
whereas second technique based gradients would choose zero-crossings
noisy gradient plot, far closer true maximum2 . illustrated Figure 3.
Another view phenomenon regardless variance estimates ,
variance
1 2 approaches (the maximum possible) 1 approaches 2 . Thus,
reliably bracket maximum using noisy estimates need able reduce
variance estimates 1 2 close. case means running simulation

()

()

()

()

+

sign[ ( )

( )]

()

1

()

2. implicit assumption argument noise processes gradient value estimates
approximately magnitude. variance value estimates considerably smaller variance
gradient estimates would expect bracketing values superior. experiments found
gradient bracketing superior.

358

fiP OLICY-G RADIENT E STIMATION

2

f
grad(f)

1.5
1
0.5
0
-0.5
-1
-1.5
-2
-2.5
-1

-0.5

Figure 1: Stylized plot average reward
.

0

0.5

1

() gradient r() search direction

2.5

f + noise
grad(f) + noise

2
1.5
1
0.5
0
-0.5
-1
-1.5
-2
-2.5
-1

-0.5

0

0.5

1

Figure 2: Plot Figure 1 estimation noise added function gradient
curves.

estimates derived longer longer periods time. contrast, variance

r 1 (and r 2 ) independent distance 1 2 ,
particular grow two points approach one another.
One disadvantage using gradient estimates bracket possible detect extreme
overshooting maximum. However, avoided using value estimates sanity

sign ( )

sign ( )

359

fiBAXTER

ET AL .

1

0.5

0

-0.5
f
grad(f)

-1
-1

-0.5

0

0.5

1

Figure 3: Plot possible maximum locations would found line-search algorithm
based value estimates (f ), one based gradient estimates (grad(f )), curves
Figure 2. zero-crossings case possible locations. Note
gradient-based approach accurately localizes maximum.

check determine value dropped dramatically, suitably adjusting search
occurs.
Algorithm 3, lines 525 bracket maximum finding parameter setting
0
GRAD > , second parameter setting + 0 s+

GRAD + < . reason rather expressions provide robustness
errors estimates GRAD . also prevents algorithm stepping 1
local maximum direction . Note use used CONJPOMDP
determine terminate due small gradient (line 4 CONJPOMDP).
Provided signs gradients bracketing points + show maximum quadratic defined points lies them, line 27 jump maximum.
Otherwise algorithm simply jumps midpoint + .

( )

( )

()

= +

0

4.3 On-line optimization average reward:

= +

OLPOMDP

combined GSEARCH operates iteratively choosing uphill directions
searching local maximum chosen direction. GRAD argument CONJPOMDP
GPOMDP, optimization involve many iterations underlying POMDP parameter updates.
traditional stochastic optimization one typically uses algorithms update parameters
every iteration, rather accumulating gradient estimates many iterations. Algorithm 4,
OLPOMDP, presents adaptation GPOMDP form. See Bartlett Baxter (2000b)
proof OLPOMDP converges vicinity local maximum . Note OLPOMDP
similar algorithms proposed Kimura et al. (1995, 1997).

CONJPOMDP

()

360

fiP OLICY-G RADIENT E STIMATION

Algorithm 3
1: Given:



(

GSEARCH GRAD

GRAD

; 0 ; ; s0 ; )

: RK ! RK : (possibly noisy biased) estimate gradient objec-

tive function.






2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:

2 RK (set maximum return).
Search direction 2 RK GRAD(0 ) > 0.
Starting parameters 0
Initial step size s0

> 0.

= 0.

Inner product resolution >

= s0
= 0 +

= GRAD()
< 0

Step back bracket maximum:
repeat

s+ =
p+ =
= s=2
= 0 +

= GRAD()
>
=s
p =


else
Step forward bracket maximum:
18:
repeat
16:
17:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:

=s
p =
= 2s
= 0 +

= GRAD()
<
s+ =
p+ =
end
p > 0 p+ < 0
= p ps++ sp
else
= +2 s+
end
0 = 0 +
361

fiBAXTER

ET AL .

(fi; T; 0 ) ! RK .

Algorithm 4 OLPOMDP
1: Given:

fi 2 [0; 1).
> 0.
Initial parameter values 0 2 RK .


Randomized parameterized policies (; ): 2 RK satisfying Assumption 1.
POMDP rewards satisfying Assumption 2, controlled (; )

() satisfying Assumption 3.
Step sizes t; = 0; 1; : : : satisfying P = 1 P t2 < 1.
generates stochastic matrices P


2:
3:
4:
5:
6:
7:
8:

Arbitrary (unknown) starting state X0 .

=0
=0

Set z0
(z0 2 RK ).



Observe Yt (generated according Xt ).
Generate control Ut according ; Yt
Observe r Xt+1 (where next state Xt+1 generated according pXt Xt+1

1

( )
rUt (; Yt )
Set zt+1 = fizt +
Ut (; Yt )
Set t+1 = + r (Xt+1 )zt+1

( )
( )

(Ut ).

end
10: return
9:

5. Experiments
section present several sets experimental results. Throughout section,
refer CONJPOMDP mean CONJPOMDP GPOMDP GRAD argument.
first set experiments, consider system controller used select
actions 3-state Markov Decision Process (MDP). system able compute
true gradient exactly using matrix equation


r() = 0()rP () P () + e0 () 1 r;

()
()

()



()

(3)

P transition matrix underlying Markov chain controllers parameters
set , 0 stationary distribution corresponding P (written row vector), e 0
square matrix row stationary distribution, r (column) vector
rewards (see Baxter & Bartlett, 2001, Section 3, derivation (3)). Hence compare
estimates generated GPOMDP true gradient r , function number
iterations function discount parameter fi . also optimize performance
controller using on-line algorithm, OLPOMDP, off-line algorithm CONJPOMDP.
CONJPOMDP reliably converges near optimal policy around 100 iterations MDP,
on-line method requires approximately 1000 iterations. contrasted
362

()

fiP OLICY-G RADIENT E STIMATION

Origin
State



B
B
C
C

Destination State Probabilities
Action

a1
a2
a1
a2
a1
a2



B

C

0.0
0.0
0.8
0.2
0.0
0.0

0.8
0.2
0.0
0.0
0.8
0.2

0.2
0.8
0.2
0.8
0.2
0.8

Table 1: Transition probabilities three-state MDP

r(A) = 0
r(B ) = 0
r(C ) = 1

12 2 (A) = 6
1 (A) = 18
18
12
6
1 (B ) = 18 2 (B ) = 18
1 (C ) = 185 2 (C ) = 185

Table 2: Three-state rewards features.

TD(1)

training linear value-function system using
(Sutton, 1988), shown
converge value function whose one-step lookahead policy suboptimal (Weaver & Baxter,
1999).
second set experiments, consider simple puck-world problem small
puck must navigated around two-dimensional world applying thrust x directions.
train 1-hidden-layer neural-network controller puck using CONJPOMDP.
controller reliably converges near optimality.
third set experiments use CONJPOMDP optimize admission thresholds
call-admission problem considered (Marbach, 1998).
final set experiments use CONJPOMDP train switched neural-network controller two-dimensional variant mountain-car task (Sutton & Barto, 1998, Example
8.2).
experiments found convergence line-searches greatly improved
calls GPOMDP algorithm seeded random number sequence.
5.1 three-state MDP
section consider three-state MDP, state choice two actions

a1 a2 . Table 1 shows transition probabilities function states actions.
state x associated two-dimensional feature vector (x) = (1 (x); 2 (x)) reward r (x)

detailed Table 2. Clearly, optimal policy always select action leads
state C highest probability, Table 1 means always selecting action a2 .
rather odd choice feature vectors states ensures value function linear
features trained using
observing optimal policywill implement
suboptimal greedy one-step lookahead policy (see (Weaver & Baxter, 1999) proof). Thus,

TD(1)

363

fiBAXTER

ET AL .

TD(1)

contrast gradient based approach, system,
training linear value function
guaranteed produce worse policy starts observing optimal policy.
5.1.1 RAINING

CONTROLLER

goal learn stochastic controller system implements optimal (or nearoptimal) policy. Given parameter vector
1 ; 2 ; 3 ; 4 , generate policy follows.
state x, let

=(

)

s1 (x) := 1 1 (x) + 2 2 (x)
s2 (x) := 3 1 (x) + 4 2 (x):
probability choosing action a1 state x given

es1 (x)
a1 (x) = s1 (x) s2 (x) ;
e
+e
probability choosing action a2 given
es2 (x)
a2 (x) = s1 (x) s2 (x) = 1 a1 (x):
e
+e
r (x)
ratios aai(x) needed Algorithms 1 4 given by,

ra1 (x) = es2 (x) [ (x); (x); (x); (x)]
(4)
2
1
2
a1 (x)
es1 (x) + es2 (x) 1
ra2 (x) = es1 (x) [ (x); (x); (x); (x)]
(5)
1
2
1
2
a2 (x)
es1 (x) + es2 (x)
Since second two components r= always negative first two, shows
two parameters redundant case: could well set 3 = 1
4 = 2 .
5.1.2 G RADIENT

ESTIMATES

= [1 1 1 1]
[0 1)



parameter vector3
; ; ; , GPOMDP used generate estimates
rfi , various values fi 2 ; . measure progress towards true gradient
r, r calculated (3) value angle r
rk recorded. angles relative errors plotted Figures 4, 5
relative error kkr
k
6.
graphs illustrate typical trade-off GPOMDP algorithm: small values fi give
higher bias estimates, larger values fi give higher variance (the final bias
shown Figure 6 norm deviation small measure angular
deviation). bias introduced fi < small system. worst case,
fi
: , final gradient direction indistinguishable true direction relative
k
deviation krkr
.
k :

= 00





1

7 7%

3. initial values parameter vector chosen similar results. Note [1; 1; 1; 1] generates
suboptimal policy.

364

fiP OLICY-G RADIENT E STIMATION

160

beta=0.0

140

140

120

120
Angle (degrees)

Angle (degrees)

160

100
80
60
40
20

beta=0.4

100
80
60
40
20

0

0

-20

-20
1

10

100

1000 10000 100000 1e+06 1e+07

1

10

100

Markov Chain Iterations (T)
160

beta=0.8

140

140

120

120
Angle (degrees)

Angle (degrees)

160

1000 10000 100000 1e+06 1e+07

Markov Chain Iterations (T)

100
80
60
40
20

beta=0.95

100
80
60
40
20

0

0

-20

-20
1

10

100 1000 10000 100000 1e+06 1e+07
Markov Chain Iterations (T)

1

10

100 1000 10000 100000 1e+06 1e+07
Markov Chain Iterations (T)



Figure 4: Angle true gradient r estimate three-state Markov
chain, various values discount parameter fi . generated Algorithm 1.
Averaged 500 independent runs. Note higher variance large larger
values fi . Error bars one standard deviation.



5.1.3 RAINING

VIA CONJUGATE - GRADIENT ASCENT

GPOMDP GRAD argument used train parameters
controller described previous section. Following low bias observed experiments
previous section, argument fi GPOMDP set . small amount experimentation, arguments s0 CONJPOMDP set
:
respectively. None
values critical, although extremely large initial step-size (s0 ) considerably reduce
time required controller converge near-optimality.
tested performance CONJPOMDP range values argument
GPOMDP
. Since GSEARCH uses GPOMDP determine sign inner
product gradient search direction, need run GPOMDP many
iterations CONJPOMDP does. Thus, GSEARCH determined parameter GPOMDP
follows. Initially, (somewhat arbitrarily) value within GSEARCH set =
value used CONJPOMDP (or 1 value CONJPOMDP less 10). GSEARCH
called GPOMDP obtain estimate gradient direction. < (
desired search direction) doubled GSEARCH called generate new
estimate . procedure repeated > , doubled four times.

still negative end process, GSEARCH searched local maximum
direction , number iterations used CONJPOMDP doubled next
iteration (the conclusion direction generated overly noisy estimates
GPOMDP).
CONJPOMDP

0
100

0 0001

1 4096

1 10











365

0

0

fiBAXTER

3

beta=0.0

2.5

Relative Norm Difference

Relative Norm Difference

3

ET AL .

2
1.5
1
0.5

beta=0.4

2.5
2
1.5
1
0.5

0

0
1

10

100

1000 10000 100000 1e+06 1e+07

1

10

Markov Chain Iterations (T)

1000 10000 100000 1e+06 1e+07

4.5

beta=0.8

beta=0.95

4

3

Relative Norm Difference

Relative Norm Difference

3.5

100

Markov Chain Iterations (T)

2.5
2
1.5
1
0.5

3.5
3
2.5
2
1.5
1
0.5

0

0
1

10

100 1000 10000 100000 1e+06 1e+07
Markov Chain Iterations (T)

1

10

100 1000 10000 100000 1e+06 1e+07
Markov Chain Iterations (T)

k
Figure 5: plot krkr
three-state Markov chain, various values discount
k
parameter fi . generated Algorithm 1. Averaged 500 independent runs.
Note higher variance large larger values fi . Error bars one standard
deviation.



Relative Norm Difference

10

beta=0.0
beta=0.40
beta=0.80
beta=0.95

1

0.1

0.01

0.001
1

10

100 1000 10000 100000 1e+06 1e+07
Markov Chain Iterations (T)

k
Figure 6: Graph showing error estimate (as measured krkr
k ) various values
fi three-state Markov chain.

generated

Algorithm
1. Note

decrease final bias fi increases. axes log scales.




366

fiP OLICY-G RADIENT E STIMATION

CONJGRAD Final Reward

0.8
0.7
0.6
0.5
0.4
0.3
0.2
1

10
100
1000
Markov Chain Iterations (T)

10000

Figure 7: Performance 3-state Markov chain controller trained CONJPOMDP function total number iterations Markov chain. performance computed exactly stationary distribution induced controller. average
reward optimal policy : . Averaged 500 independent runs. error bars
computed dividing results two separate bins depending whether
mean, computing standard deviation within
bin.

08

()

Figure 7 shows average reward final controller produced CONJPOMDP,
function total number simulation steps underlying Markov chain. plots represent
average
independent runs CONJPOMDP. Note : average reward
optimal policy. parameters controller (uniformly) randomly initialized range
: ; : call CONJPOMDP. call CONJPOMDP, average reward
resulting controller computed exactly calculating stationary distribution
controller. Figure 7, optimality reliably achieved using approximately 100 iterations
Markov chain.

500

08

[ 0 1 0 1]

5.1.4 RAINING

- LINE OLPOMDP

=

controller also trained on-line using Algorithm 4 (OLPOMDP) fixed step-sizes c
c
: ; ; ; . Reducing step-sizes form c=t tried, caused intolerably
slow convergence. Figure 8 shows performance controller (measured exactly
previous section) function total number iterations Markov chain, different
values step-size c. graphs averages 100 runs, controllers weights
randomly initialized range
: ; : start run. figure, convergence
optimal order magnitude slower achieved CONJPOMDP, best
step-size c
: . Step-sizes much greater c
: failed reliably converge optimal
policy.

= 0 1 1 10 100

=

[ 0 1 0 1]

=10

= 10 0

367

fiBAXTER

ET AL .

0.8

0.8
0.79
0.78
Average Reward

Average Reward

0.75
0.7
0.65
0.6

0.77
0.76
0.75
0.74
0.73
0.72

0.55

0.71

c=0.1

0.5
10

100

1000

c=1

0.7
10000

10

100

10000

Markov Chain Iterations

0.8

0.9

0.7

0.8
Average Reward

Average Reward

Markov Chain Iterations

1000

0.6
0.5
0.4
0.3

0.7
0.6
0.5
0.4
0.3

c=10

0.2
10

100
1000
Markov Chain Iterations

c=100

0.2
10000

10

100
1000
Markov Chain Iterations

10000

Figure 8: Performance 3-state Markov chain controller function number iteration steps on-line algorithm, Algorithm 4, fixed step sizes : ; ; ,
.
Error bars computed Figure 7.

0 1 1 10

100

5.2 Puck World
section, experiments described CONJPOMDP OLPOMDP used
train 1-hidden-layer neural-network controllers navigate small puck around two-dimensional
world.
5.2.1 W ORLD
puck unit-radius, unit-mass disk constrained move plane region 100 units
square. puck internal dynamics (i.e rotation). Collisions regions boundaries
inelastic (tunable) coefficient restitution e (set : experiments reported
here). puck controlled applying 5 unit force either positive negative x
direction, 5 unit force either positive negative direction, giving four different
controls total. control could changed every = second, simulator operated
granularity =
second. puck also retarding force due air resistance
: speed2 . friction puck ground.
puck given reward decision point ( = second) equal
distance puck designated target point. encourage controller
learn navigate puck target independently starting state, puck state
reset every 30 (simulated) seconds random location random x velocities range
; , time target position set random location.
Note size state-space example essentially infinite, order
PRECISION PRECISION floating point precision machine (
bits). Thus,

09

0 005

1 10

1 100

1 10

[ 10 10]
2

64

368

fiP OLICY-G RADIENT E STIMATION

time visits recurrent state likely large. Also, puck cannot maximize
immediate reward leads significant overshooting target locations.
5.2.2

CONTROLLER

one-hidden-layer neural-network six input nodes, eight hidden nodes four output nodes
used generate probabilistic policy similar manner controller three-state
Markov chain example previous section. Four inputs set raw x
locations velocities puck current time-step, two differences
pucks x location targets x location respectively. location
inputs scaled lie
, velocity inputs scaled speed

units per second mapped value . hidden nodes computed
squashing
function, output nodes linear. hidden output node usual additional
offset parameter. four output nodes exponentiated normalized Markovchain example produce probability distribution four controls ( units thrust x
direction, units thrust direction). Controls selected random distribution.

1

10

1

1

tanh

5

5

5.2.3 C ONJUGATE

GRADIENT ASCENT

trained neural-network controller using CONJPOMDP gradient estimates generated
GPOMDP. experimentation chose fi
:
; ;
parameters CONJPOMDP supplied GPOMDP. GSEARCH used value fi scheme
discussed Section 5.1.3 determine number iterations call GPOMDP.
Due saturating nature neural-network hidden nodes (and exponentiated output
nodes), tendency network weights converge local minima infinity.
is, weights would grow rapidly early simulation, towards suboptimal
solution. Large weights tend imply small gradients thus network becomes stuck
suboptimal solutions. observed similar behaviour training neural networks
pattern classification problems. fix problem, subtracted small quadratic penalty term
kk2 performance estimates hence also small correction gradient
calculation4 .
used decreasing schedule quadratic penalty weight (arrived
experimentation). initialized : every tenth iteration CONJPOMDP,
performance improved less 10% value ten iterations ago, reduced
factor 10. schedule solved nearly local minima problems, expense slower
convergence controller.
plot average reward neural-network controller shown Figure 9, function
number iterations POMDP. graph average 100 independent runs,
parameters initialized randomly range
: ; : start run. four
bad runs shown Figure 10 omitted average gave misleadingly large
error bars.
Note optimal performance (within neural-network controller class) seems
around
problem, due fact puck target locations reset every
simulated seconds hence fixed fraction time puck must away

= 0 95

= 1 000 000

2

05

[ 0 1 0 1]

8

30

4. used technique capacity control pattern classification, technique goes name weight
decay. used condition optimization problem.

369

fiBAXTER

ET AL .

-5
-10
Average Reward

-15
-20
-25
-30
-35
-40
-45
-50
-55
0

3e+07

6e+07
9e+07
Iterations

1.2e+08

1.5e+08

Figure 9: Performance neural-network puck controller function number iterations puck world, trained using CONJPOMDP. Performance estimates
generated simulating ;
;
iterations. Averaged 100 independent runs
(excluding four bad runs Figure 10).

1 000 000

target. Figure 9 see final performance puck controller close optimal.
4 100 runs CONJPOMDP get stuck suboptimal local minimum. Three
cases caused overshooting GSEARCH (see Figure 10), could prevented
adding extra checks CONJPOMDP.
Figure 11 illustrates behaviour typical trained controller. purpose illustration, target location puck velocity randomized every 30 seconds, puck
location.
5.3 Call Admission Control
section report results experiments CONJPOMDP applied task
training controller call admission problem treated Marbach (1998, Chapter 7).
5.3.1 P ROBLEM
call admission control problem treated Marbach (1998, Chapter 7) models situation
telecommunications provider wishes sell bandwidth communications link
customers way maximize long-term average reward.
Specifically, problem queuing problem. three different types call,
call arrival rate ff , ff , ff , bandwidth demand b , b , b
average
holding time h , h , h . arrivals Poisson distributed holding times
exponentially distributed. link maximum bandwidth 10 units. call arrives
sufficient available bandwidth, service provider choose accept reject call
(if enough available bandwidth call always rejected). Upon accepting call

(1) (2) (3)

(1) (2) (3)

370

(1) (2) (3)

fiAverage Reward

P OLICY-G RADIENT E STIMATION

5
0
-5
-10
-15
-20
-25
-30
-35
-40
-45
-50
-55
0

5e+07 1e+08 1.5e+08 2e+08 2.5e+08 3e+08 3.5e+08
Iterations

Figure 10: Plots performance neural-network puck controller four runs (out
100) converged substantially suboptimal local minima.

target

Figure 11: Illustration behaviour typical trained puck controller.

type m, service provider receives reward r
maximize long-term average reward.

(m) units. goal service provider

parameters associated call type listed Table 3. settings,
optimal policy (found dynamic programming Marbach (1998)) always accept calls
type 2 3 (assuming sufficient available bandwidth) accept calls type 1 available
371

fiBAXTER

ET AL .

Call Type
Bandwidth Demand
Arrival Rate
Average Holding Time
Reward

b
ff
h
r

1
1

2
1

3
1

1

2

4

1:8 1:6 1:4
0:6 0:5 0:4

Table 3: Parameters call admission control problem.

bandwidth least 3. policy average reward
policy average reward5 : .

0 784

0:804, always accept

5.3.2 C ONTROLLER

=(

)

controller three parameters
1 ; 2 ; 3 , one type call. Upon arrival call
type m, controller chooses accept call probability
(

1
() = 1+exp(1:5(b

0

))

b

+ b(m) 10,

otherwise,

b currently used bandwidth. class controllers studied Marbach (1998).
5.3.3 C ONJUGATE

GRADIENT ASCENT

used train controller, GPOMDP generating gradient estimates range values fi . influence fi performance trained
controllers marginal, set fi
: gave lowest-variance estimates. used
value calls GPOMDP within CONJPOMDP within GSEARCH,
varied
;
. controller always started parameter
setting
; ; (as done Marbach (1998)). value initial policy : .
graph average reward final controller produced CONJPOMDP function
total number iterations queue shown Figure 12. performance :
reliably
achieved less
iterations queue.
Note optimal policy achievable controller class since incapable
implementing threshold policy always accept always reject policies.
Although provably optimal, parameter setting 1 : suitably large values 2
3 generates something close optimal policy within controller class, average
reward : . Figure 13 shows probability accepting call type policy
(with 2 3
), function available bandwidth.
controllers produced CONJPOMDP fi
: sufficiently large essentially
always accept controllers average reward : , within 2% optimum achievable
class. produce policies even nearer optimal policy performance, CONJPOMDP
must keep 1 close starting value , hence gradient estimate
1; 2; 3
CONJPOMDP

= 00

= (8 8 8)

10

10 000

0 691

0 784

2000

75

08
= = 15

=00
0 784

8

= ( )

5. discrepancy average rewards quoted Marbach (1998). probably due
discrepancy way state transitions counted, clear discussion (Marbach,
1998).

372

fiP OLICY-G RADIENT E STIMATION

CONJGRAD Final Reward

0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5

class optimal
beta=0.0

0.45
1000

10000
Total Queue Iterations

100000

Figure 12: Performance call admission controller trained CONJPOMDP function
total number iterations queue. performance computed simulating controller 100,000 iterations. average reward globally optimal
policy : , average reward optimal policy within class : ,
plateau performance CONJPOMDP : . graphs averages 100
independent runs.

0 804

08

0 784

1

Acceptance Probability

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
call type 1
call types 2 3

0.1
0
1

2

3

4
5
6
7
Available Bandwidth

8

9

10

Figure 13: Probability accepting call type call admission policy nearoptimal parameters 1
: ; 2
3
. Note calls type 2 3
essentially always accepted.

= 75

=

373

= 15

fiBAXTER

ET AL .

1

Normalized Delta

0.8
0.6
0.4
0.2
0
-0.2
Delta1
Delta2
Delta3

-0.4
-0.6
0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Beta



1

Figure 14: Plot three components call admission problem, function
discount parameter fi . parameters set
; ; . set ; ; .
Note 1 become negative (the correct sign) fi : .

= (8 8 8)



0 93

1 000 000

produced GPOMDP must relatively small first component. Figure 14 shows plot
normalized function fi ,
; ;
(sufficiently large ensure low variance
) starting parameter setting
; ; . figure, 1 starts high value
explains CONJPOMDP produces always accept controllers fi
: ,
become negative fi : , value variance even moderately large
relatively high.
plot performance CONJPOMDP fi
: fi
: shown Figure
15. Approximately half remaining 2% performance obtained setting fi
:,
fi
: sufficiently large choice gives remaining performance.
problem, huge difference gaining 98% optimal performance,
achieved fi
: less 2000 iterations queue, gaining 99% optimal
requires fi
: order 500,000 queue iterations. similar convergence rate
final approximation error latter case reported on-line algorithms Marbach
(1998, Chapter 7).





= 1 000 000
= (8 8 8)



0 93



= 09

= 0 95
= 00
= 09

= 0 95

=00

= 09

5.4 Mountainous Puck World
mountain-car task well-studied problem reinforcement learning literature (Sutton
& Barto, 1998, Example 8.2). shown Figure 16, task drive car top onedimensional hill. car powerful enough accelerate directly hill gravity,
successful controller must learn oscillate back forth builds enough speed
crest hill.
section describe variant mountain car problem based puck-world
example Section 5.2. reference Figure 17, problem task navigate puck
374

fiP OLICY-G RADIENT E STIMATION

0.805

0.802
CONJGRAD Final Reward

CONJGRAD Final Reward

0.8
0.8
0.795
0.79
0.785
0.78
0.775
100000

class optimal
beta=0.90
1e+06
Total Queue Iterations

0.798
0.796
0.794
0.792
0.79
0.788
0.786
0.784
class optimal
beta=0.95

0.782
0.78
1e+07

0

1e+07
2e+07
3e+07
Total Queue Iterations

4e+07

Figure 15: Performance call admission controller trained CONJPOMDP function
total number iterations queue. performance calculated
simulating controller 1,000,000 iterations. graphs averages 100
independent runs.

Figure 16: classical mountain-car task apply forward reverse thrust car get
crest hill. car starts bottom enough power
drive directly hill.

valley onto plateau northern end valley. mountain-car task,
puck sufficient power accelerate directly hill, learn oscillate
order climb valley. able reliably train near-optimal neuralnetwork controllers problem, using CONJPOMDP GSEARCH, GPOMDP
generating gradient estimates.
5.4.1 W ORLD
world dimensions, physics, puck dynamics controls identical flat puck world
described Section 5.2, except puck subject constant gravitational force
units, maximum allowed thrust units (instead ), height world varied

3

5

375

10

fiBAXTER

ET AL .

Figure 17: variant mountain-car problem task navigate puck valley
onto northern plateau. puck starts bottom valley
enough power drive directly hill.

follows:

8
<

height

3

15
(x; y) = :7:5 1 cos ( y2 50)
25

< 25 > 75
otherwise :


units thrust, unit mass puck accelerate directly valley.
Every 120 (simulated) seconds, puck initialized zero velocity bottom
valley, random x location. puck given reward valley
southern plateau, reward
s2 northern plateau, speed
puck. found speed penalty helped improve rate convergence neural
network controller.

100

5.4.2

CONTROLLER

experimentation found neural-network controller could reliably trained
navigate northern plateau, stay northern plateau there, difficult
combine controller (this surprising since two tasks quite distinct).
overcome problem, trained switched neural-network controller: puck used one
controller valley southern plateau, switched second neuralnetwork controller northern plateau. controllers one-hidden-layer neuralnetworks nine input nodes, five hidden nodes four output nodes. nine inputs
normalized (
; -valued) x, z puck locations, normalized x, z locations relative
center northern wall, x, z puck velocities. four outputs used
generate policy fashion controller Section 5.2.2.
approach requiring less prior knowledge would third controller stochastically selects base neural network controller function pucks location. master

[ 1 1]

376

fiP OLICY-G RADIENT E STIMATION

80

Average Reward

70
60
50
40
30
20
10
0
0

2e+07

4e+07
6e+07
Iterations

8e+07

1e+08

Figure 18: Performance neural-network puck controller function number iterations mountainous puck world, trained using CONJPOMDP. Performance
estimates generated simulating ;
;
iterations. Averaged 100
independent runs.

1 000 000

controller could parameterized parameters trained along base controllers.
5.4.3 C ONJUGATE

GRADIENT ASCENT

switched neural-network controller trained using scheme discussed Section 5.2.3, except time discount factor fi set : .
plot average reward neural-network controller shown Figure 18, function
number iterations POMDP. graph average 100 independent runs,
neural-network controller parameters initialized randomly range
: ; : start
run. case run failed converge near-optimal performance. figure
see pucks performance nearly optimal 40 million total iterations
puck world. Although figure may seem rather high, put perspective note
random neural-network controller takes 10,000 iterations reach northern plateau
standing start base valley. Thus, 40 million iterations equivalent 4,000
trips top random controller.
Note puck converges final average performance around 75, indicates
spending least 75% time northern plateau. Observation pucks final behaviour
shows behaves nearly optimally terms oscillating back forth get valley.

0 98

[ 0 1 0 1]

5.5 Choosing fi Running Time GPOMDP
One aspect experiments required measure tuning choice fi parameter running time used GPOMDP. Although selected trial error,
377

fiBAXTER

ET AL .

success recently scheme automatically choosing parameters follows.
training begins, GPOMDP run large number iterations whilst simultaneously
generating gradient estimates number different choices fi . done single
simulation simply maintaining separate eligibility trace zt value fi . Since bias
reduces increasing fi , largest fi gives reasonably low-variance gradient estimate
end long run selected reference fi (the variance estimated comparing gradient
estimates reasonably well-separated intervals towards end run). Furthermore, since
variance gradient estimate decreases fi decreases, gradient estimates values fi
smaller reference fi typically smaller variance reference fi . Hence,
reliably compare directions smaller fi direction given reference fi ,
choose smallest fi whose corresponding direction sufficiently close reference fi
direction. takesufficiently close mean within .
Note scheme works original run sufficiently long get low-variance
direction estimate right value fi . right value fi large fixed bound
run length made fail, problem algorithms automatically
choose fi .
suitable fi found, go back find point original long run
direction estimate corresponding value fi settled (again, measure
variance estimates sampling suitably large intervals, choose point
variance falls chosen value). time used running time GPOMDP
estimating gradient direction. Finally, running time used GPOMDP bracketing
maximum GSEARCH also automatically tuned starting initial fixed running
time fraction , continuing sign inner product estimates
produced GPOMDP search direction settles down. technique, sign
estimation time usually considerably smaller gradient direction estimation time.
Another useful heuristic re-estimate fi GPOMDPs running time whenever parameters change large amount, since large change lead significant changes
mixing time POMDP.

10 15

6. Conclusion
paper showed use performance gradient estimates generated GPOMDP algorithm (Baxter & Bartlett, 2001) optimize average reward parameterized POMDPs.
described traditional on-line stochastic gradient algorithm off-line approach
relied use GSEARCH, robust line-search algorithm uses gradient estimates, rather
value estimates, bracket maximum. off-line approach particular found perform well four quite distinct problems: optimizing controller three-state MDP, optimizing
neural-network controller navigating puck around two-dimensional world, optimizing
controller call admission problem, optimizing switched neural-network controller
variation classical mountain-car task. One reason superiority off-line approach
searching local maximum step makes much aggressive use
gradient information on-line algorithm.
three-state MDP call-admission problems able provide graphic illustrations bias variance gradient estimates rfi traded one another
varying fi (low variance, high bias) (high variance, low bias).

0

1

378

fiP OLICY-G RADIENT E STIMATION

Relatively little tuning required generate results. addition, controllers operated direct simple representations state, contrast complex representations
usually required value-function based approaches.
often case value-function methods converge much rapidly policygradient counterparts. due fact enforce constraints value-function.
mind interesting avenue research Actor-Critic algorithms (Barto et al.,
1983; Baird & Moore, 1999; Kimura & Kobayashi, 1998; Konda & Tsitsiklis, 2000; Sutton,
McAllester, Singh, & Mansour, 2000) one attempts combine fast convergence
value-functions theoretical guarantees policy-gradient approaches.
Despite success off-line approach experiments described here, on-line algorithm advantages settings. particular, applied multi-agent reinforcement
learning, gradient computations parameter updates performed distinct agents
without communication beyond global distribution reward signal. idea led
parameter optimization procedure spiking neural networks, successful preliminary
results network routing (Bartlett & Baxter, 1999; Tao, Baxter, & Weaver, 2001).
Acknowledgements
work supported Australian Research Council, benefited comments
several anonymous referees. research performed first second authors Research School Information Sciences Engineering, Australian National
University.

References
Aberdeen, D., & Baxter, J. (2001). Policy-gradient learning controllers internal state. Tech. rep.,
Australian National University.
Baird, L., & Moore, A. (1999). Gradient descent general reinforcement learning. Advances Neural
Information Processing Systems 11. MIT Press.
Bartlett, P. L., & Baxter, J. (1999). Hebbian synaptic modifications spiking neurons learn. Tech.
rep., Research School Information Sciences Engineering, Australian National University.
http://csl.anu.edu.au/bartlett/papers/BartlettBaxter-Nov99.ps.gz.
Bartlett, P. L., & Baxter, J. (2000a). Estimation approximation bounds gradient-based reinforcement
learning. Proceedings Thirteenth Annual Conference Computational Learning Theory,
pp. 133141.
Bartlett, P. L., & Baxter, J. (2000b). Stochastic optimization controlled partially observable markov decision processes. Proceedings 39th IEEE Conference Decision Control (CDC00).
Barto, A. G., Sutton, R. S., & Anderson, C. W. (1983). Neuronlike adaptive elements solve difficult
learning control problems. IEEE Transactions Systems, Man, Cybernetics, SMC-13, 834846.
Baxter, J., & Bartlett, P. L. (2000). Reinforcement learning POMDPs via direct gradient ascent.
Proceedings Seventeenth International Conference Machine Learning.
Baxter, J., & Bartlett, P. L. (2001). Infinite-horizon policy-gradient estimation. Journal Artificial Intelligence Research. appear.
Baxter, J., Tridgell, A., & Weaver, L. (2000). Learning play chess using temporal-differences. Machine
Learning, 40(3), 243263.
379

fiBAXTER

ET AL .

Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Cao, X.-R., & Chen, H.-F. (1997). Perturbation Realization, Potentials, Sensitivity Analysis Markov
Processes. IEEE Transactions Automatic Control, 42, 13821393.
Cao, X.-R., & Wan, Y.-W. (1998). Algorithms Sensitivity Analysis Markov Chains Potentials
Perturbation Realization. IEEE Transactions Control Systems Technology, 6, 482492.
Fine, T. L. (1999). Feedforward Neural Network Methodology. Springer, New York.
Fu, M. C., & Hu, J. (1994). Smooth Perturbation Derivative Estimation Markov Chains. Operations
Research Letters, 15, 241251.
Glynn, P. W. (1986). Stochastic approximation monte-carlo optimization. Proceedings 1986
Winter Simulation Conference, pp. 356365.
Kimura, H., & Kobayashi, S. (1998). analysis actor/critic algorithms using eligibility traces: Reinforcement learning imperfect value functions. Fifteenth International Conference Machine
Learning, pp. 278286.
Kimura, H., Miyazaki, K., & Kobayashi, S. (1997). Reinforcement learning POMDPs function
approximation. Fisher, D. H. (Ed.), Proceedings Fourteenth International Conference
Machine Learning (ICML97), pp. 152160.
Kimura, H., Yamamura, M., & Kobayashi, S. (1995). Reinforcement learning stochastic hill climbing
discounted reward. Proceedings Twelfth International Conference Machine Learning
(ICML95), pp. 295303.
Konda, V. R., & Tsitsiklis, J. N. (2000). Actor-Critic Algorithms. Neural Information Processing Systems
1999. MIT Press.
Marbach, P. (1998). Simulation-Based Methods Markov Decision Processes. Ph.D. thesis, Laboratory
Information Decision Systems, MIT.
Marbach, P., & Tsitsiklis, J. N. (1998). Simulation-Based Optimization Markov Reward Processes. Tech.
rep., MIT.
Rubinstein, R. Y., & Melamed, B. (1998). Modern Simulation Modeling. Wiley, New York.
Samuel, A. L. (1959). Studies Machine Learning Using Game Checkers. IBM Journal
Research Development, 3, 210229.
Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning Without State-Estimation Partially Observable
Markovian Decision Processes. Proceedings Eleventh International Conference Machine
Learning.
Singh, S., & Bertsekas, D. (1997). Reinforcement learning dynamic channel allocation cellular telephone systems. Advances Neural Information Processing Systems: Proceedings 1996
Conference, pp. 974980. MIT Press.
Singh, S., Jaakkola, T., & Jordan, M. (1995). Reinforcement learning soft state aggregation. Tesauro,
G., Touretzky, D., & Leen, T. (Eds.), Advances Neural Information Processing Systems, Vol. 7. MIT
Press, Cambridge, MA.
Sutton, R. (1988). Learning Predict Method Temporal Differences. Machine Learning, 3, 944.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press, Cambridge MA.
ISBN 0-262-19398-1.
Sutton, R. S., McAllester, D., Singh, S., & Mansour, Y. (2000). Policy Gradient Methods Reinforcement
Learning Function Approximation. Neural Information Processing Systems 1999. MIT Press.
380

fiP OLICY-G RADIENT E STIMATION

Tao, N., Baxter, J., & Weaver, L. (2001). multi-agent, policy-gradient approach network routing. Tech.
rep., Australian National University.
Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning, 8, 257278.
Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves master-level play. Neural
Computation, 6, 215219.
Weaver, L., & Baxter, J. (1999). Reinforcement learning state temporal differences. Tech. rep.,
Australian National University.
Williams, R. J. (1992). Simple Statistical Gradient-Following Algorithms Connectionist Reinforcement
Learning. Machine Learning, 8, 229256.
Zhang, W., & Dietterich, T. (1995). reinforcement learning approach job-shop scheduling. Proceedings Fourteenth International Joint Conference Artificial Intelligence, pp. 11141120.
Morgan Kaufmann.

381

fiJournal Artificial Intelligence Research 15 (2001) 319-350

Submitted 9/00; published 11/01

Infinite-Horizon Policy-Gradient Estimation
Jonathan Baxter

JBAXTER @ WHIZBANG . COM

WhizBang! Labs.
4616 Henry Street Pittsburgh, PA 15213

Peter L. Bartlett

BARTLETT @ BARNHILLTECHNOLOGIES . COM

BIOwulf Technologies.
2030 Addison Street, Suite 102, Berkeley, CA 94704

Abstract
Gradient-based approaches direct policy search reinforcement learning received
much recent attention means solve problems partial observability avoid
problems associated policy degradation value-function methods. paper introduce GPOMDP, simulation-based algorithm generating biased estimate gradient
average reward Partially Observable Markov Decision Processes (POMDPs) controlled
parameterized stochastic policies. similar algorithm proposed Kimura, Yamamura,
Kobayashi (1995). algorithms chief advantages requires storage twice
number policy parameters, uses one free parameter fi 2 [0; 1) (which natural interpretation
terms bias-variance trade-off), requires knowledge underlying state. prove
convergence GPOMDP, show correct choice parameter fi related
mixing time controlled POMDP. briefly describe extensions GPOMDP controlled
Markov chains, continuous state, observation control spaces, multiple-agents, higher-order
derivatives, version training stochastic policies internal states. companion paper
(Baxter, Bartlett, & Weaver, 2001) show gradient estimates generated GPOMDP
used traditional stochastic gradient algorithm conjugate-gradient procedure
find local optima average reward.

1. Introduction
Dynamic Programming method choice solving problems decision making
uncertainty (Bertsekas, 1995). However, application Dynamic Programming becomes problematic large infinite state-spaces, situations system dynamics unknown,
state partially observed. cases one looks approximate techniques
rely simulation, rather explicit model, parametric representations either valuefunction policy, rather exact representations.
Simulation-based methods rely parametric form value function tend go
name Reinforcement Learning, extensively studied Machine Learning
literature (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998). approach yielded
remarkable empirical successes number different domains, including learning play checkers (Samuel, 1959), backgammon (Tesauro, 1992, 1994), chess (Baxter, Tridgell, & Weaver,
2000), job-shop scheduling (Zhang & Dietterich, 1995) dynamic channel allocation (Singh &
Bertsekas, 1997).
Despite success, algorithms training approximate value functions suffer
theoretical flaw: performance greedy policy derived approximate valuefunction guaranteed improve iteration, fact worse old policy

c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBAXTER & BARTLETT

amount equal maximum approximation error states. happen even
parametric class contains value function whose corresponding greedy policy optimal.
illustrate concrete simple example Appendix A.
alternative approach circumvents problemthe approach pursue hereis
consider class stochastic policies parameterized 2 R K , compute gradient respect
average reward, improve policy adjusting parameters gradient
direction. Note policy could directly parameterized, could generated indirectly
value function. latter case value-function parameters parameters
policy, instead adjusted minimize error approximate true value
function, parameters adjusted directly improve performance policy generated
value function.
policy-gradient algorithms long history Operations Research, Statistics, Control Theory, Discrete Event Systems Machine Learning. describing contribution
present paper, seems appropriate introduce background material explaining approach. Readers already familiar material may want skip directly section 1.2,
contributions present paper described.
1.1 Brief History Policy-Gradient Algorithms
large-scale problems problems system dynamics unknown, performance
gradient computable closed form1 . Thus challenging aspect policy-gradient
approach find algorithm estimating gradient via simulation. Naively, gradient
calculated numerically adjusting parameter turn estimating effect performance via simulation (the so-called crude Monte-Carlo technique), prohibitively
inefficient problems. Somewhat surprisingly, mild regularity conditions, turns
full gradient estimated single simulation system. technique
called score function likelihood ratio method appears first proposed
sixties (Aleksandrov, Sysoyev, & Shemeneva, 1968; Rubinstein, 1969) computing performance
gradients i.i.d. (independently identically distributed) processes.
Specifically, suppose r X performance function depends random variable
X , q ; x probability X x, parameterized 2 RK . mild regularity
conditions, gradient respect expected performance,

( )

( )

may written

see this, rewrite (1) sum

=

() = Er(X );

(1)

r() = Er(X ) rqq(;(;XX)) :

(2)

() =

X

r() =

X

r(x)q(; x);

x
differentiate (one source requirement mild regularity conditions) obtain
x

r(x)rq(; x);

1. See equation (17) closed-form expression performance gradient.

320

fiP OLICY-G RADIENT E STIMATION

rewrite

X

r() =

r(x)

rq(; x) q(; x);

( )

q ; x
x
observe formula equivalent (2).
simulator available generate samples X distributed according q ; x ,
sequence X1 ; X2 ; : : : ; XN generated i.i.d. according q ; x gives unbiased estimate,

( )

( )
N
X
r^ () = N1 r(Xi) rqq(;(;XX)i) ;
(3)


^ () ! r() probability one. quantity
r ( ). law large numbers, r
rq(; X )=q(; X ) known likelihood ratio score function classical statistics.
performance function r (X ) also depends , r (X )rq (; X )=q (; X ) replaced
rr(; X ) + r(; X )rq(; X )=q(; X ) (2).
=1

1.1.1 U NBIASED E STIMATES
P ROCESSES



P ERFORMANCE G RADIENT



R EGENERATIVE

Extensions likelihood-ratio method regenerative processes (including Markov Decision
Processes MDPs) given Glynn (1986, 1990), Glynn LEcuyer (1995) Reiman
Weiss (1986, 1989), independently episodic Partially Observable Markov Decision
Processes (POMDPs) Williams (1992), introduced REINFORCE algorithm2 .
i.i.d. samples X previous section sequences states X0 ; : : : ; XT (of random length)
encountered visits designated recurrent state , sequences states
start state goal state. case rq ; X =q ; X written sum

(

) (

)

rq(; X ) = TX rpXtXt+1 () ;
1

q(; X )

()

t=0

pXt Xt+1 ()

(4)

pXt Xt+1 transition probability Xt Xt+1 given parameters . Equation (4)
admits recursive computation course regenerative cycle form z0
2 RK ,
state transition Xt ! Xt+1 ,

=0

zt+1 = zt +

( ) (
)

) (

)

rpXtXt+1 () ;
pXt Xt+1 ()

term r X rq ; X =q ; X estimate (3) form3
addition, r X0 ; : : : ; XT recursively computed

(

(5)

r(X0 ; : : : ; XT )zT . If,

r(X0 ; : : : ; Xt+1 ) = (r(X0 ; : : : ; Xt ); Xt+1 )
function , estimate r (X0 ; : : : ; XT )zT cycle computed using
storage K + 1 parameters (K zt 1 parameter update performance function
r). Hence, entire estimate (3) computed storage 2K + 1 real parameters,
follows.

2. thresholded version algorithms neuron-like elements described earlier Barto, Sutton, Anderson (1983).
3. vector zT known reinforcement learning eligibility trace. terminology used Barto et al.
(1983).

321

fiBAXTER & BARTLETT

Algorithm 1.1: Policy-Gradient Algorithm Regenerative Processes.
1. Set j

= 0, r = 0, z = 0, = 0 (z ; 2 RK ).
0

0

0

2. state transition Xt




3. j

0

! Xt

+1

0

:

episode finished (that is, Xt+1
j +1
j rt zt ,
j j ,
zt+1 ,
rt+1 .

= +
= +1
=0
=0
Otherwise, set

rp

= i), set



zt+1 = zt + pXXtXtXt+1() ;
t+1
rt+1 = (rt ; Xt+1 ).
( )

= N return N =N , otherwise goto 2.

Examples recursive
performance functions include sum scalar reward cycle,
P

r(X0 ; : : : ; XT ) = Tt=0 r(Xt ) r(i) scalar reward associated state (this corresponds ( ) average reward multiplied expected recurrence time E [T ]);

1
()

negative length cycle (which implemented assigning reward
state,
used task mimimize time taken get goal state, since
case
PT

E ); discounted reward start state, r X0 ; : : : ; XT
t=0 ff r Xt ,
ff 2 ; discount factor, on.
Williams (1992) pointed out, simplification possible case rT
r X0 ; : : : ; XT sum scalar rewards r Xt ; depending state possibly time
since starting state (such r Xt ; r Xt , r Xt ; fft r Xt above). case,
update single regenerative cycle may written

[ ]
[0 1)

(

(

)

(



=

TX1
t=0

pXt Xt+1 ()

"
X

s=0

( )

=

( )
)= ( ) (

rpXtXt+1 ()

()

)=

)=

r(Xs ; s) +


X
s=t+1

( )

#

r(Xs ; s) :

(

)

changes pXt Xt+1 influence rewards r Xs ; associated earlier
states (s t), able drop first term parentheses right-hand-side
write
TX1

rpXtXt+1 X
r X ;s :
(6)
p
s=t+1
t=0 Xt Xt+1

=

()
()

(

)

Although proof entirely trivial, intuition indeed shown correct.
Equation (6) allows even simpler recursive formula estimating performance gradient. Set z0
, introduce new variable
. before, set zt+1
zt
0
rpXtXt+1 =pXtXt+1 Xt+1 6 ,
zt+1
otherwise.
now, iteration, set t+1 r Xt ; zt
. =t estimate r . Since
updated every iteration, suggests away altogether simply update directly: t+1 r Xt ; zt , suitable step-sizes4 . Proving convergence

()

P

= =0
()

= +1
=
= ( ) +
= + ( )



=0
=0

=0



4. usual requirements convergence stochastic gradient algorithm > 0,
1 2 < .
t=0

1

322

=

()

P1t=0

=

+


1,

fiP OLICY-G RADIENT E STIMATION

algorithm straightforward normal stochastic gradient algorithms
updates r Xt zt gradient direction (in expectation), although sum updates
regenerative cycle are. Marbach Tsitsiklis (1998) provide convergence proof
know of, albeit slightly different update form t+1
r Xt ; zt ,
moving estimate expected performance, also updated on-line (this
update first suggested context POMDPs Jaakkola et al. (1995)).
Marbach Tsitsiklis (1998) also considered case -dependent rewards (recall discussion (3)), Baird Moore (1999) VAPS algorithm (Value Policy
Search). last paper contains interesting insight: suitable choices performance
function r X0 ; : : : ; XT ; , one combine policy-gradient search approximate value function methods. resulting algorithms viewed actor-critic techniques spirit Barto
et al. (1983); policy actor value function critic. primary motivation
reduce variance policy-gradient estimates. Experimental evidence phenomenon
presented number authors, including Barto et al. (1983), Kimura Kobayashi
(1998a), Baird Moore (1999). recent work subject includes Sutton
et al. (2000) Konda Tsitsiklis (2000). discuss use VAPS-style updates
Section 6.2.
far addressed question parameterized state-transition probabilities pXt Xt+1 arise. course, could simply generated parameterizing matrix
transition probabilities directly. Alternatively, case MDPs POMDPs, state transitions
typically generated feeding observation Yt depends stochastically state Xt
parameterized stochastic policy, selects control Ut random set available controls (approximate value-function based approaches generate controls stochastically
via form lookahead also fall category). distribution successor states
pXt Xt+1 Ut fixed function control. denote probability control ut given
parameters observation yt ut ; yt , discussion carries
rpXtXt+1 =pXtXt+1 replaced rUt ; Yt =Ut ; Yt . case, Algorithm 1.1 precisely Williams REINFORCE algorithm.
Algorithm 1.1 variants extended cover multiple agents (Peshkin
et al., 2000), policies internal state (Meuleau et al., 1999), importance sampling methods
(Meuleau et al., 2000). also refer reader work Rubinstein Shapiro (1993)
Rubinstein Melamed (1998) in-depth analysis application likelihood-ratio
method Discrete-Event Systems (DES), particular networks queues. Also worth mentioning
large literature Infinitesimal Perturbation Analysis (IPA), seeks similar goal estimating performance gradients, operates restrictive assumptions likelihoodratio approach; see, example, Ho Cao (1991).

( )

= + [(

^( )

(

) ^( )]

)

()

( )
()

(

()

1.1.2 B IASED E STIMATES



)
(

)

(

)

P ERFORMANCE G RADIENT

algorithms described previous section rely identifiable recurrent state , either
update gradient estimate, case on-line algorithm, zero eligibility trace
z . reliance recurrent state problematic two main reasons:
1. variance algorithms related recurrence time visits ,
typically grow state space grows. Furthermore, time visits depends
323

fiBAXTER & BARTLETT

parameters policy, states frequently visited initial value
parameters may become rare performance improves.
2. situations partial observability may difficult estimate underlying states,
therefore determine gradient estimate updated, eligibility trace
zeroed.
system available simulation, seems difficult (if impossible) obtain
unbiased estimates gradient direction without access recurrent state. Thus, solve 1
2, must look biased estimates. Two principle techniques introducing bias
proposed, may viewed artificial truncations eligibility trace z . first
method takes starting point formula5 eligibility trace time t:

zt =

1
X

rpXsXs+1 ()
pXs Xs+1 ()

s=0

simply truncates (fixed, random) number terms n looking backwards (Glynn,
1990; Rubinstein, 1991, 1992; Cao & Wan, 1998):

zt (n) :=

1
X
s=t n

rpXsXs+1 () :
pXs Xs+1 ()

(7)

(n) updated transition Xt ! Xt
rp
() rpXt nXt n+1 () ;
zt (n) = zt (n) + XtXt+1
pXt Xt+1 ()
pXt n Xt n+1 ()
case state-based rewards r (Xt ), estimated gradient direction steps

^rn() := 1 X zt (n)r(Xt ):
n+1 n
eligibility trace zt

+1

+1

(8)

(9)

=

Unless n exceeds maximum recurrence time (which infinite ergodic Markov chain),
rn biased estimate gradient direction, although n ! 1, bias approaches zero.
However variance rn diverges limit large n. illustrates natural trade-off
selection parameter n: large enough ensure bias acceptable (the
expectation rn least within true gradient direction), large
variance prohibitive. Experimental results Cao Wan (1998) illustrate nicely
bias/variance trade-off.
One potential difficulty method likelihood ratios rpXs Xs+1 =pXs Xs+1
must remembered previous n time steps, requiring storage Kn parameters. Thus,
obtain small bias, memory may grow without bound. alternative approach
requires fixed amount memory discount eligibility trace, rather truncating it:

^ ()

^ ()

^ ()

90

()

zt+1 (fi ) := fizt (fi ) +

rpXtXt+1 () ;
pXt Xt+1 ()

()

(10)

r

5. ease exposition, kept expression z terms likelihood ratios pXs Xs+1 ()=pXs Xs+1 ()
rely availability underlying state Xs . Xs available, pXs Xs+1 ()=pXs Xs+1 ()
replaced Us (; Ys )=Us (; Ys ).

r

r

324

fiP OLICY-G RADIENT E STIMATION

( )=0

z0 fi
fi
steps simply

2 [0; 1) discount factor.
r^fi () := T1

TX1
t=0

case estimated gradient direction

r(Xt )zt (fi ):

(11)

( ) ()
(( ) )

precisely estimate analyze present paper. similar estimate r Xt zt fi
replaced r Xt
b zt fi b reward baseline proposed Kimura et al. (1995,
1997) continuous control Kimura Kobayashi (1998b). fact use r Xt
b
place r Xt affect expectation estimates algorithm (although judicious choice reward baseline b reduce variance estimates). algorithm
presented Kimura et al. (1995) provides estimates expectation stationary distribution gradient discounted reward, show fact biased estimates
gradient expected discounted reward. arises stationary distribution
depends parameters. similar estimate (11) also proposed Marbach
Tsitsiklis (1998), time r Xt zt fi replaced r Xt
zt fi ,
estimate average reward, zt zeroed visits identifiable recurrent state.
final note, observe eligibility traces zt fi zt n defined (10) (8)
simply filtered versions sequence rpXt Xt+1 =pXt Xt+1 , first-order, infinite impulse
response filter case zt fi n-th order, finite impulse response filter case
zt n . raises question, addressed paper, whether interesting theory
optimal filtering policy-gradient estimators.

(( )
( )

) ()

( ) ()

( ( ) ^( )) ( )

()

()

()

()

^( )

()
()

1.2 Contribution
describe GPOMDP, general algorithm based upon (11) generating biased estimate
performance gradient r general POMDPs controlled parameterized stochastic policies.
denotes average reward policy parameters 2 RK . GPOMDP
rely access underlying recurrent state. Writing rfi expectation estimate produced GPOMDP, show
r , quantitatively
fi !1 rfi
rfi close true gradient provided = fi exceeds mixing time Markov chain
induced POMDP6 . truncated estimate above, trade-off preventing setting
fi arbitrarily close variance algorithms estimates increase fi approaches
. prove convergence probability 1 GPOMDP discrete continuous observation control spaces. present algorithms general parameterized Markov chains
POMDPs controlled parameterized stochastic policies.
several extensions GPOMDP investigated since first version
paper written. outline developments briefly Section 7.
companion paper show gradient estimates produced GPOMDP used
perform gradient ascent average reward (Baxter et al., 2001). describe
traditional stochastic gradient algorithms, conjugate-gradient algorithm utilizes gradient
estimates novel way perform line searches. Experimental results presented illustrat-

()

()

()
lim
( )= ( )
1 (1 )

()

1

1

()

6. mixing-time result paper applies Markov chains distinct eigenvalues. Better estimates
bias variance GPOMDP may found Bartlett Baxter (2001), general Markov chains
treated here, refined notions mixing time. Roughly speaking, variance GPOMDP
grows 1=(1 fi ), bias decreases function 1=(1 fi ).

325

fiBAXTER & BARTLETT

ing theoretical results present paper toy problem, practical aspects
algorithms number realistic problems.

2. Reinforcement Learning Problem
model reinforcement learning Markov decision process (MDP) finite state space
f ; : : : ; ng, stochastic matrix7 P pij giving probability transition state
state j . state associated reward8 r . matrix P belongs parameterized
class stochastic matrices, P
fP 2 RK g. Denote Markov chain corresponding
P . assume Markov chains rewards satisfy following assumptions:

= 1

()

=[ ]

()

:= ( ):

()

()

Assumption 1. P 2 P unique stationary distribution
satisfying balance equations

() := [(; 1); : : : ; (; n)]0

0 ()P () = 0 ()
(throughout 0 denotes transpose ).
Assumption 2. magnitudes rewards, jr (i)j, uniformly bounded R <
states i.

(12)

1

Assumption 1 ensures Markov chain forms single recurrent class parameters .
Since finite-state Markov chain always ends recurrent class, properties
class determine long-term average reward, assumption mainly convenience
include recurrence class quantifier theorems. However,
consider gradient-ascent algorithms Baxter et al. (2001), assumption becomes
restrictive since guarantees recurrence class cannot change parameters adjusted.
Ordinarily, discussion MDPs would complete without mention actions
available state space policies available learner. particular, parameters
would usually determine policy (either directly indirectly via value function), would
determine transition probabilities P . However, purposes care
dependence P arises, satisfies Assumption 1 (and differentiability
assumptions shall meet next section). Note also easy extend setup
case rewards also depend parameters transitions ! j .
equally straightforward extend algorithms results cases. See Section 6.1
illustration.
goal find 2 R K maximizing average reward:
fi
"
#
TX1
fi
fi

E
r Xt fi X0 ;
fi
!1
t=0
E denotes expectation sequences X0 ; X1 ; : : : ; transitions generated according P . Assumption 1, independent starting state equal
n
X

; r 0 r;
(13)
i=1

()

1

( ) := lim

()

=

()

( )=

r

( )

( ) ()= ( )

= [r(1); : : : ; r(n)]0 (Bertsekas, 1995).


P

7. stochastic matrix P = [pij ] pij 0 i; j n
j =1 pij = 1 i.
8. results present paper apply bounded stochastic rewards, case r(i) expectation
reward state i.

326

fiP OLICY-G RADIENT E STIMATION

3. Computing Gradient Average Reward

()

general MDPs little known average reward , hence finding optimum
problematic. However, section see general assumptions gradient
r exists, local optimization possible.
ensure existence suitable gradients (and boundedness certain random variables),
require parameterized class stochastic matrices satisfies following additional assumption.

()

()

Assumption 3. derivatives,

rP () :=
2 RK . ratios

exist



@pij ()
@k

i;j =1:::n;k=1:::K

2 fifi @p () fifi 3
ij
fi @k fi
4
5

pij ()

uniformly bounded B



i;j =1:::n;k=1:::K

< 1 2 RK .

second part assumption allows zero-probability transitions pij

() = 0

rpij () also zero, case set 0=0 = 0. One example ! j forbidden
transition, pij ( ) = 0 2 RK . Another example satisfying assumption
pij () =


= [

11

; : : : ; 1n ; : : : ; nn ] 2 Rn2

parameters P

@pij ()=@ij
pij ()
@pij ()=@kl
pij ()

Assuming moment r
dependencies,

eij
ij ;
j =1 e

Pn

=1
=

pij ();

(),



pkl ():

() exists (this justified shortly), then, suppressing
r = r0r;
(14)

since reward r depend . Note convention r paper takes
precedence operations, rg f
rg f . Equations like (14)
regarded shorthand notation K equations form

( ) ( ) = [ ( )] ( )

@()
@k

k

=





@(; 1)
@(; n)
;:::;
[r(1); : : : ; r(n)]0
@k
@k

= 1; : : : ; K . compute r, first differentiate balance equations (12) obtain
r0P + 0 rP = r0;
327

fiBAXTER & BARTLETT

hence

r0(I P ) = 0 rP:

(15)

system equations defined (15) under-constrained P invertible (the
balance equations show P left eigenvector zero eigenvalue). However, let e
denote n-dimensional column vector consisting s, e 0 n n matrix
stationary distribution 0 row. Since r 0 e r 0 e
r
, rewrite (15)

1

= ( ) = (1) = 0





r0 (P e0) = 0rP:
see inverse
write

[I (P
"

lim (I

e0 )]
A)

!1


X
t=0

1

exists, let matrix satisfying
#

= Tlim
!1



[

t=0

= Tlim
!1
= I:

Thus,

(I

"
X

A)

1

=

1
X
t=0

TX
+1



+1

t=1

limt!1 = 0.

#



:

] =

0

easy prove induction P e 0
P eP0
! 1
tconverges
1
0
0 . Hence, write
Assumption 1.
P e
exists equal 1
P
e
t=0

[

(

)]



r0 = 0rP P + e0
so9



r = 0rP P + e0





;

(16)

r:

(17)

1

1

MDPs sufficiently small number states, (17) could solved exactly yield precise
gradient direction. However, general, state space small enough exact solution
(17) possible, small enough derive optimal policy using policy iteration
table-lookup, would point pursuing gradient based approach first place10 .
Thus, problems practical interest, (17) intractable need find
way computing gradient. One approximate technique presented
next section.
9. argument leading (16) coupled fact () unique solution (12) used justify
existence . Specifically, run steps computing value ( + ) small
show expression (16) unique matrix satisfying ( + ) = () + () + O( 2 ).
10. Equation (17) may still useful POMDPs, since case tractable dynamic programming
algorithm.

r

r

r

328

kk

fiP OLICY-G RADIENT E STIMATION

4. Approximating Gradient Parameterized Markov Chains
section, show gradient split two components, one becomes
negligible discount factor fi approaches .
fi 2 ; , let Jfi
Jfi ; ; : : : ; Jfi ; n denote vector expected discounted
rewards state i:

[0 1)

( ) = [ ( 1)

Jfi (; i) := E

1

"

( )]

1
X
t=0

fitr

fi
fi
Xt fifi X0
fi

( )

#

=i

:

(18)

dependence obvious, write Jfi .

2 [0; 1),
r = (1 fi )r0 Jfi + fi0rP Jfi :

Proposition 1. 2 R K fi

(19)

Proof. Observe Jfi satisfies Bellman equations:

Jfi = r + fiP Jfi :

(20)

(Bertsekas, 1995). Hence,

r = r0r
= r0 [Jfi fiP Jfi ]
= r0Jfi fi r0Jfi + fi0 rP Jfi
= (1 fi )r0 Jfi + fi0rP Jfi :

(15)

shall see next section second term (19) estimated single sample path Markov chain. fact, Theorem 1 (Kimura et al., 1997) shows gradient
estimates algorithm presented paper converge
fi 0 rJfi . Bellman equations (20), equal
fi fi 0 rP Jfi 0 rJfi , implies
fi 0 rJfi fi0 rP Jfi .
Thus algorithm Kimura et al. (1997) also estimates second term expression
r given (19). important note 0rJfi 6 r 0 Jfi two quantities disagree
first term (19). arises stationary distribution depends
parameters. Hence, algorithm Kimura et al. (1997) estimate gradient expected discounted reward. fact, expected discounted reward simply =
fi times
average reward (Singh et al., 1994, Fact 7), gradient expected discounted reward
proportional gradient average reward.
following theorem shows first term (19) becomes negligible fi approaches .
Notice immediate Proposition 1, since Jfi become arbitrarily large
limit fi ! .

(1 ) (

+

(1

)

= [

]

)

()

(1 )

=

1 (1

()

)

1

1

Theorem 2. 2 RK ,

r = filim
r ;
! fi

(21)

rfi := 0 rP Jfi :

(22)

1



329

fiBAXTER & BARTLETT

Proof. Recalling equation (17) discussion preceeding it, 11

r = 0rP
rP e

1
X



e0 r:

Pt

t=0

(23)

= r(P e) = r(1) = 0 since P stochastic matrix, (23) rewritten
r = 0

"
1
X

#

rP P r:

t=0

(24)

2 [0; 1] discount factor consider expression

let fi

f (fi ) := 0

= lim
( )=

()

"
1
X

t=0

#

rP (fiP )t r

(25)

( )=

Clearly r
rfi .
fi !1 f fi . complete proof need show f fi




0
Since fiP
fi P ! fi e ! , invoke observation (16) write

0

1
X
t=0
P

particular, 1
t=0
(25) write12

(fiP )t = [I

(fiP )t converges, take rP back sum right-hand-side
f (fi ) = 0 rP



P1

t=0


fitP r

fiP ] 1 :

= Jfi . Thus f (fi ) = 0rP Jfi

"1
X

t=0

#

fitP

r:

(26)

= rfi .

1

Theorem 2 shows rfi good approximation gradient fi approaches ,
turns values fi close lead large variance estimates rfi
describe next section. However, following theorem shows
fi need
small, provided transition probability matrix P distinct eigenvalues, Markov
chain short mixing time. initial state, distribution states Markov chain
converges stationary distribution, provided assumption (Assumption 1) existence
uniqueness stationary distribution satisfied (see, example, Lancaster & Tismenetsky,
1985, Theorem 15.8.1, p. 552). spectral resolution theorem (Lancaster & Tismenetsky, 1985,
Theorem 9.5.1, p. 314) implies distribution converges stationarity exponential rate,
time constant convergence rate (the mixing time) depends eigenvalues
transition probability matrix. existence unique stationary distribution implies

1

1

()

11. Since e 0 r = e , (23) motivates different kind algorithm estimating based differential rewards
(Marbach & Tsitsiklis, 1998).
12. cannot back P sum right-hand-side (24) 1
P diverges (P e 0 ). reason
1 P P converges P becomes orthogonal P limit tof=0large t. Thus, view 1 P
t=0
t=0
sum two orthogonal components: infinite one direction e finite one direction e? .
1


finite component need estimate. Approximating 1
t=0 P t=0 (fiP ) way rendering
e-component finite hopefully altering e? -component much. substitutions
lead better approximations (in context, see final paragraph Section 1.1).

P

r

r

r

330

P

P

r

!

P

P

fiP OLICY-G RADIENT E STIMATION

1

1

largest magnitude eigenvalue multiplicity , corresponding left eigenvector
stationary distribution. sort eigenvalues decreasing order magnitude,
1 > j2 j > > js j n. turns j2 j determines mixing time
chain.
following theorem shows
fi small compared
j2j, gradient approximation described accurate. Since using estimate direction
update parameters, theorem compares directions gradient estimate.
theorem, 2 denotes spectral condition number nonsingular matrix A, defined
product spectral norms matrices 1 ,

1=

2

1

1

( )

2 (A) = kAk2 kA



1

k;
2

kAk = x max
kAxk;
kxk
2

:

=1

kxk denotes Euclidean norm vector x.

()

Theorem 3. Suppose transition probability matrix P satisfies Assumption 1 stationary distribution 0
1 ; : : : ; n , n distinct eigenvalues. Let
x1 x2 xn
matrix right eigenvectors P corresponding, order, eigenvalues
1 > j2 j
jn j. normalized inner product r fi rfi satisfies

=(

)

=(
1=

)


kr(p ; : : : ; p )k p
fi rfi
1 fi
n
1 rkr

=S
r0r
(27)
k
krk
1 fi j j ;
= diag( ; : : : ; n ).
Notice r 0 r expectation stationary distribution r (X ) .
well mixing time (via j j), bound theorem depends another parameter
Markov chain: spectral condition number = . Markov chain reversible (which
2

1 2

2

1

2

1

2

2

1 2

implies eigenvectors x1 ; : : : ; xn orthogonal), equal ratio maximum
minimum probability states stationary distribution. However, eigenvectors
need nearly orthogonal. fact, condition transition probability matrix
n distinct eigenvalues necessary; without it, condition number replaced
complicated expression involving spectral norms matrices form P .

(

)



Proof. existence n distinct eigenvalues implies P expressed 1 ,
1 ; : : : ; n (Lancaster & Tismenetsky, 1985, Theorem 4.10.2, p 153). follows
polynomial f , write f P
Sf 1 .
Now, Proposition 1 shows r fi rfi r 0
fi Jfi .

= diag(

)

( ) = ()
= (1 )
(1 fi )Jfi = (1 fi ) r + fiP r + fi P r +
= (1 fi ) + fiP + fi!P + r
1
X
= (1 fi )S
fi r
2

2

2

2

1

= (1

fi)

n
X
j =1

t=0

xj 0

331

j

1
X
t=0

(fij )

!



r;

fiBAXTER & BARTLETT

=(
=

)

1
y1 ; : : : ; yn 0 .
easy verify yi left eigenvector corresponding , choose
y1 x1 e. Thus write

=

(1

fi )Jfi = (1 fi )e0 r +

n
X

xj yj0

(1

!

fi )(fij )t r

t=0
j =2


n
X
fi
r
xj yj0
fi
j
j =2

= (1

fi )e +

= (1

fi )e + SMS 1 r;


1
1



1
= diag 0;
1



1
X

fi
1 fi :
;:::;
fi2
1 fin

follows Proposition 1

fi rfi
r (r r0(1
1 rkr
=
1
k
krk
0
= r r (1 fi )Jfi
2

2

fi )Jfi )

krk

r
r0 (1 fi )e + SMS r
=
krk
0
SMS r
= r rkr
k

r 0 SMS r

krk ;
p
0
Since r = r
0 = , apply Cauchy2

1

2

1

2

1

Cauchy-Schwartz inequality.
Schwartz inequality obtain

1 2

fi rfi
1 rkr

k





r



p

0





= SMS
1 2

1

krk

2



r

:

(28)

use spectral norms bound second factor numerator. clear definition
spectral norm product nonsingular matrices satisfies kAB k2 kAk2 kB k2 ,
spectral norm diagonal matrix given k
d1 ; : : : ; dn k2
jdi j. follows




= SMS
1 2

1

diag(
) = max


r = = SMS = = r




= = = r kM k

p
= r0r 1 1 fi jfi j :
1 2

1

1 2

1

2

2

1 2

1 2

1 2

1 2

2

1 2

2

Combining Equation (28) proves (27).
332

2

fiP OLICY-G RADIENT E STIMATION

5. Estimating Gradient Parameterized Markov Chains
Algorithm 1 introduces MCG (Markov Chain Gradient), algorithm estimating approximate gradient rfi single on-line sample path X0 ; X1 ; : : : Markov chain .
MCG requires K reals stored, K dimension parameter space: K
parameters eligibility trace zt , K parameters gradient estimate . Note
time steps average far r Xt zt ,

()

2





( )

TX
1
=
zt r(Xt ):
1



t=0

Algorithm 1 MCG (Markov Chain Gradient) algorithm
1: Given:




Parameter 2 R K .
Parameterized class stochastic matrices P
3 1.

= fP (): 2 RK g satisfying Assumptions

fi 2 [0; 1).
Arbitrary starting state X .
State sequence X ; X ; : : :
0

generated ( ) (i.e. Markov chain transition
()).
Reward sequence r(X ); r(X ); : : : satisfying Assumption 2.
Set z = 0 = 0 (z ; 2 RK ).
state Xt visited
rp
( )
zt = fizt + XtXt+1
pXt Xt+1 ()
= + [r(Xt )zt ]
probabilities P

0

1

0

2:
3:
4:
5:
6:

0

0

0

1

0

+1

+1

1
+1

+1

+1

+1

end

Theorem 4. Assumptions 1, 2 3, MCG algorithm starting initial state X0
generate sequence 0 ; 1 ; : : : ; ; : : : satisfying





lim = rfi

t!1

=

w.p.1:

(29)

()

Proof. Let fXt g fX0 ; X1 ; : : : g denote random process corresponding . X0
entire process stationary. proof easily generalized arbitrary initial distributions using fact Assumption 1, fXt g asymptotically stationary. fXt g
333

fiBAXTER & BARTLETT

stationary, write

0 rP Jfi =

X

=

X

=

X

i;j
i;j
i;j

(i)rpij ()Jfi (j )
(i)pij ()

rpij () J (j )
p () fi
ij

Pr(Xt = i)Pr(Xt = j jXt = i) rppij(()) E(J (t + 1)jXt = j );
+1

+1

ij

first probability respect stationary distribution

J (t + 1) =

( ( + 1)

)= (

1
X
s=t+1

fis



1

(30)

J (t + 1) process

r(Xs ):

)

fact E J
jXt+1 Jfi Xt+1 Xt+1 follows boundedness
magnitudes rewards (Assumption 2) Lebesgues dominated convergence theorem.
rewrite Equation (30)




X
rp ()
0 rP Jfi = E (Xt )j (Xt+1 ) ij J (t + 1) ;

pij ()

i;j



() denotes indicator function state i,
(
1 Xt = i;
(Xt ) :=
0 otherwise;

expectation respect stationary distribution. Xt chosen according
stationary distribution, process fXt g ergodic. Since process fZt g defined

Zt := (Xt )j (Xt+1 )

rpij () J (t + 1)
pij ()

obtained taking fixed
fXt g, fZt g also stationary ergodic (Breiman, 1966,
fi function
fi
fi rpij () fi
Proposition 6.31). Since fi pij () fi bounded Assumption 3, ergodic theorem
(almost surely):

0 rP Jfi

TX
1
rp ()
= Tlim
(Xt )j (Xt ) ij J (t + 1)
!1
pij ()
i;j
TX
rpXtXt+1 () J (t + 1)
1
= Tlim
!1
pXtXt+1 ()
"
TX
1
X
r
pXtXt+1 () X
1
= Tlim
fi r(Xs ) +
!1
pXtXt+1 ()

X

1

+1

=0

1

=0

1

1

=0

= +1

334

= +1

#

fis

1

r(Xs ) :

(31)

fiP OLICY-G RADIENT E STIMATION

Concentrating second term right-hand-side (31), observe that:
fi
fi TX1
fi
fi
fiT

1

t=0

rpXtXt+1 ()
pXt Xt+1 ()

1
X

fis

s=T +1
TX1 fifi

1


fi
fi

1

fi
fi
Xs fifi
fi

r(

)

pXt Xt+1 ()

t=0
1
BR TX1 X



= BR


1
X

rpXtXt+1 () fififi

t=0 s=T +1
TX1

fi

t=0

1

fis

fi



s=T +1

fis



1

jr(Xs)j

1

fi

1 fiT
= BRfi
(1 fi )2
! 0 ! 1;



jrp j
R B bounds magnitudes rewards pijij Assumptions 2
3. Hence,
TX1

rpXtXt+1 X
0 rP Jfi
(32)
fi 1 r Xs :
!1
p

X
X
t+1
t=0
s=t+1
Unrolling equation MCG algorithm shows equal

()
()

= lim 1



1 TX rpXtXt+1 () X
pXt Xt+1 ()
1

=0

hence

fis

( )



1

r(is );

= +1

! 0rP Jfi w.p.1 required.

6. Estimating Gradient Partially Observable Markov Decision Processes

()

Algorithm 1 applies parameterized class stochastic matrices P compute gradients rpij . section consider special case P arise
parameterized class randomized policies controlling partially observable Markov decision process (POMDP). partially observable qualification means assume policies
access observation process depends state, general may see state.
Specifically, assume N controls U
f ; : : : ; N g observations
f ; : : : ; g. u 2 U determines stochastic matrix P u depend
parameters . state 2 , observation 2 generated independently according
probability distribution observations . denote probability observation
. randomized policy simply function mapping observations 2 probability
distributions controls U . is, observation , distribution
controls U . Denote probability control u given observation u .
randomized policy observation distribution corresponds Markov
chain state transitions generated first selecting observation state according

()

= 1

1

()

()

=

()

()

()
()

()

335

()

fiBAXTER & BARTLETT

()

()

distribution , selecting control u according distribution , generating transition state j according probability pij u . parameterize chains
parameterize policies, becomes function ; set parameters 2 R K
well observation . Markov chain corresponding state transition matrix pij
given

()
( )

[ ( )]

pij () = EY (i) EU (;Y ) pij (U ):

Equation (33) implies

rpij () =

X

(33)

(i)pij (u)ru (; y):

u;y

(34)

Algorithm 2 introduces GPOMDP algorithm (for Gradient Partially Observable Markov
Decision Process), modified form Algorithm 1 updates zt based Ut ; Yt ,
rather pXt Xt+1 . Note Algorithm 2 require knowledge transition probability matrix P , observation process ; requires knowledge randomized
policy . GPOMDP essentially algorithm proposed Kimura et al. (1997) without
reward baseline.
algorithm GPOMDP assumes policy function current observation.
immediate algorithm works finite history observations. general,
optimal policy needs function entire observation history. GPOMDP extended
apply policies internal state (Aberdeen & Baxter, 2001).

(

()

)

Algorithm 2 GPOMDP algorithm.
1: Given:




Parameterized class randomized policies



(; ) : 2 RK



satisfying Assumption 4.

Partially observable Markov decision process controlled randomized
policies ; corresponds parameterized class Markov chains satisfying Assumption 1.

( )

fi 2 [0; 1).
Arbitrary (unknown) starting state X .
Observation sequence ; ; : : : generated POMDP controls U ; U ; : : :
0

0

1

0

(; Yt).

generated randomly according


2:
3:
4:
5:
6:

( ) ( )

Reward sequence r X0 ; r X1 ; : : : satisfying Assumption 2,
(hidden) sequence states Markov decision process.

=0

=0
= + (( ))
= + [ ( )

Set z0
0
(z0 ; 0 2 RK ).
observation Yt , control Ut , subsequent reward r
rUt ; Yt
zt+1 fizt
Ut ; Yt
1
t+1
t+1 r Xt+1 zt+1

end

]

336

(Xt )
+1

X0 ; X1 ; : : :

1



fiP OLICY-G RADIENT E STIMATION

convergence Algorithm 2 need replace Assumption 3 similar bound
gradient :
Assumption 4. derivatives,

exist u 2 U ,

@u (; y)
@k

2 2 RK . ratios
fi
2 fifi
@u (;y) fi 3
fi @
fi
k
4
5

u (; y)

uniformly bounded B

y=1:::M ;u=1:::N ;k=1:::K

< 1 2 RK .

Theorem 5. Assumptions 1, 2 4, Algorithm 2 starting initial state
generate sequence 0 ; 1 ; : : : ; ; : : : satisfying





lim = rfi

w.p.1:

t!1

X0



(35)

Proof. proof follows lines proof Theorem 4. case,

0 rP Jfi =

=
=
=

X

i;j

(i)rpij ()Jfi (j )

X

i;j;y;u
X

i;j;y;u
X

i;j;y;u

(i)pij (u)y (i)ru (; y)Jfi (j ) (34)
(i)pij (u)y (i)

ru (; y) (; y)J (j );
fi
(; y) u
u

EZt0;

expectation respect stationary distribution fXt g, process fZt0 g
defined
ru ; J ;
Zt0 Xt j Xt+1 u Ut Yt
u ;

:= ( ) (

) ( ) ( ) (( )) ( + 1)

Ut control process Yt observation process. result follows
arguments used proof Theorem 4.
6.1 Control dependent rewards

many circumstances rewards may depend controls u.
example, controls may consume energy others may wish add penalty
term reward function order conserve energy. simplest way deal
define state expected reward r

( )

r(i) = EY (i) EU (;Y ) r(U; i);
337

(36)

fiBAXTER & BARTLETT



redefine Jfi terms r:

Jfi (; i) :=

lim E

"

N !1

N
X
t=0

fi
fi
Xt fifi X0
fi

( )

fitr

#

=i

;

(37)

X0 ; X1 ; : : : . performance gradient becomes
r = r0r + 0rr;

expectation trajectories

approximated

rfi = 0 rP Jfi + rr ;








due fact Jfi satisfies Bellman equations (20) r replaced r .
GPOMDP take account dependence r controls, fifth line
replaced

1
= + + 1 r(Ut
+1



r
Ut+1 (; Yt )
; Xt ) zt +
:
(; )


+1

+1

+1

+1

Ut+1
t+1
straightforward extend proofs Theorems 2, 3 5 setting.

6.2 Parameter dependent rewards
possible modify GPOMDP rewards depend directly . case,
fifth line GPOMDP replaced

= + +1 1 [r(; Xt )zt + rr(; Xt ) t] :
+1

+1

+1

(38)

+1

( )

Again, convergence approximation theorems carry through, provided rr ; uniformly bounded. Parameter-dependent rewards considered Glynn (1990), Marbach
Tsitsiklis (1998), Baird Moore (1999). particular, Baird Moore (1999) showed
suitable choices r ; lead combination value policy search, VAPS.
example, J ; approximate value-function, setting13

( )

~( )

h

1
~
~
r(; Xt ; Xt ) =
2 r(Xt ) + ffJ (; Xt ) J (; Xt ) ;
r (Xt ) usual reward ff 2 [0; 1) discount factor, gives update seeks
2

1

1

minimize expected Bellman error
n
X
i=1

2

(; i) 4r(i) + ff

n
X
j =1

32

pij ()J~(; j ) J~(; i)5 :

(39)

~( )

effect minimizing Bellman error J ; , driving system
(via policy) states small Bellman error. motivation behind approach
understood one considers J zero Bellman error states. case greedy
policy derived J optimal, regardless actual policy parameterized,
expectation zt r ; Xt ; Xt 1 zero gradient computed GPOMDP.
kind update known actor-critic algorithm (Barto et al., 1983), policy playing
role actor, value function playing role critic.

(

~

13. use rewards r(; Xt ; Xt
analysis.

~

)

1 ) depend current previous

338

state substantially alter

fiP OLICY-G RADIENT E STIMATION

6.3 Extensions infinite state, observation, control spaces
convergence proof Algorithm 2 relied finite state (S ), observation (Y ) control (U )
spaces. However, clear modification Algorithm 2 applied immediately POMDPs countably uncountably infinite , countable U .
changes pij u becomes kernel p x; x0 ; u becomes density observations.
addition, appropriate interpretation r=, applied uncountable U . Specifically, U subset R N y; probability density function U u y;
density u. U subsets Euclidean space (but finite set), Theorem 5
extended show estimates produced algorithm converge almost surely rfi .
fact, prove general result implies case densities subsets R N
well finite case Theorem 5. allow U general spaces satisfying following
topological assumption. (For definitions see, example, (Dudley, 1989).)

()

(

)

()

( )

( )

Assumption 5. control space U associated topology separable, Hausdorff,
first-countable. corresponding Borel -algebra B generated topology,
-finite measure defined measurable space U ; B . say reference measure
U .
Similarly, observation space topology, Borel -algebra, reference measure
satisfying conditions.

(

)

case Theorem 5, U finite, associated reference measure
counting measure. U
RN RM , reference measure Lebesgue measure.
assume distributions ; absolutely continuous respect reference
measures, corresponding Radon-Nikodym derivatives (probability masses finite case,
densities Euclidean case) satisfy following assumption.

=

()

=

( )

( )

Assumption 6. every 2 2 R K , probability measure ; absolutely continuous respect reference measure U . every 2 , probability measure
absolutely continuous respect reference measure .
Let reference measure U . u 2 U , 2 , 2 R K , k 2 f ; : : : ; K g,
derivatives

@ d(; y)
(u)
@k

fi
fi @ du (;y)
fi @k

exist ratios

< 1.

1

fi

(u)fifi
du ;y
(u)
(

bounded B

()

)

assumptions, replace Algorithm 2 Radon-Nikodym derivative
respect reference measure U . case, following convergence
result. generalizes Theorem 5, also applies densities Euclidean space U .

Theorem 6. Suppose control space U observation space satisfy Assumption 5 let

reference measure control space U . Consider Algorithm 2
rUt (; Yt)
Ut (; Yt )
339

fiBAXTER & BARTLETT

replaced

r d;Yt (Ut ) :
(

)

( )

d(;Yt )
Ut

Assumptions 1, 2 6, algorithm, starting initial state
sequence 0 ; 1 ; : : : ; ; : : : satisfying





lim = rfi

t!1

X0

generate

w.p.1:

Proof. See Appendix B

7. New Results
Since first version paper, extended GPOMDP several new settings, also
proved new properties algorithm. section briefly outline results.
7.1 Multiple Agents

Instead single agent generating actions according (; ), suppose multiple agents
= 1; : : : ; na , parameter set distinct observation environment
yi , generate actions ui according policy ui (i ; yi ). agents receive reward signal r (Xt ) (they may cooperating solve task, example),

GPOMDP applied collective POMDP obtained concatenating
1 nobserva
1
na , u
tions, controls,
parameters

single
vectors


;
:
:
:
;

u ; : : : ; u ,


1 ; : : : ; na respectively. easy calculation shows gradient estimate generated
GPOMDP collective case precisely obtained applying GPOMDP


1
agent independently, concatenating results. is,
; : : : ; na ,
estimate produced GPOMDP applied agent i. leads on-line algorithm
agents adjust parameters independently without explicit communication,
yet collectively adjustments maximizing global average reward. similar observations context REINFORCE VAPS, see Peshkin et al. (2000). algorithm gives
biologically plausible synaptic weight-update rule applied networks spiking neurons
neurons regarded independent agents (Bartlett & Baxter, 1999), shown
promise network routing application (Tao, Baxter, & Weaver, 2001).

=

=

=

=






7.2 Policies internal states
far considered purely reactive memoryless policies chosen control
function current observation. GPOMDP easily extended cover case
policies depend finite histories observations Yt ; Yt 1 ; : : : ; Yt k , general, optimal
control POMDPs, policy must function entire observation history. Fortunately,
observation history may summarized form belief state (the current distribution
states), updated based upon current observation, knowledge
sufficient optimal behaviour (Smallwood & Sondik, 1973; Sondik, 1978). extension
GPOMDP policies parameterized internal belief states described Aberdeen Baxter
(2001), similar spirit extension VAPS REINFORCE described Meuleau et al.
(1999).
340

fiP OLICY-G RADIENT E STIMATION

7.3 Higher-Order Derivatives
generalized compute estimates second higher-order derivatives
average reward (assuming exist), still single sample Rpath underlying POMDP.
see second-order derivatives, observe
q ; x r x dx twicedifferentiable density q ; x performance measure r x ,

GPOMDP

()= ( )( )
()
Z
r () = r(x) rq(q;(;x)x) q(; x) dx

( )

2

2

r2 denotes matrix second derivatives (Hessian). verified

r q(; x) = r log q(; x) + [r log q(; x)]
q(; x)
2

2

2

(40)

log ( )

second term right-hand-side outer product r
q ; x
(that is, matrix entries @=@i
q ; x @=@j q ; x ). Taking x sequence
states X0 ; X1 ; : : : ; XT visits recurrent state parameterized Markov chain (recall
1p
Section 1.1.1), q ; X
t=0 Xt Xt+1 , combined (40) yields

log ( )
log ( )
)=
()

(

r q(; X ) = TX r pXtXt+1 ()
2

q(; X )

1

TX1

2

pXt Xt+1 ()

t=0

rpXtXt+1 () +
p
()
2

Xt Xt+1

t=0

"T 1
X

rpXtXt+1 ()

#2

pXtXt+1 ()

t=0

(the squared terms expression also outer products). expression derive
GPOMDP-like algorithm computing biased estimate Hessian r2 , involves
maintainingin addition usual eligibility trace zt second matrix trace updated follows:

()

Zt+1

= fiZt + rp pXtXt+1(())
2



Xt Xt+1

rpXtXt+1 () :
p
( )
2

Xt Xt+1

( ) +



time steps algorithm returns average far r Xt Zt zt2 second term
outer product. Computation higher-order derivatives could used second-order
gradient methods optimization policy parameters.
7.4 Bias Variance Bounds

()

()

Theorem 3 provides bound bias rfi relative r applies underlying Markov chain distinct eigenvalues. extended result arbitrary Markov chains
(Bartlett & Baxter, 2001). However, extra generality comes price, since latter bound involves number states chain, whereas Theorem 3 not. paper also supplies
proof variance GPOMDP scales =
fi 2 , providing formal justification
interpretation fi terms bias/variance trade-off.

1 (1

)

8. Conclusion
presented general algorithm (MCG) computing arbitrarily accurate approximations
gradient average reward parameterized Markov chain. chains transition
matrix distinct eigenvalues, accuracy approximation shown controlled
341

fiBAXTER & BARTLETT

size subdominant eigenvalue j2 j. showed algorithm could modified apply
partially observable Markov decision processes controlled parameterized stochastic policies,
discrete continuous control, observation state spaces (GPOMDP). finite
state case, proved convergence probability 1 algorithms.
briefly described extensions multi-agent problems, policies internal state, estimating
higher-order derivatives, generalizations bias result chains non-distinct eigenvalues,
new variance result. many avenues research. Continuous time results
follow extensions results presented here. MCG GPOMDP algorithms
applied countably uncountably infinite state spaces; convergence results also needed
cases.
companion paper (Baxter et al., 2001), present experimental results showing rapid
convergence estimates generated GPOMDP true gradient r . give on-line
variants algorithms present paper, also variants gradient ascent make use
estimates rfi . present experimental results showing effectiveness algorithms
variety problems, including three-state MDP, nonlinear physical control problem,
call-admission problem.
Acknowledgements
work supported Australian Research Council, benefited comments
several anonymous referees. research performed authors
Research School Information Sciences Engineering, Australian National University.

Appendix A. Simple Example Policy Degradation Value-Function Learning
Approximate value-function approaches reinforcement work minimizing form error
approximate value function true value function. long known
may necessarily lead improved policy performance new value function. include
appendix illustrates phenomenon occur simplest possible system,
two-state MDP, also provides geometric intuition phenomenon arises.
Consider two-state Markov decision process (MDP) Figure 1. two controls
u1 ; u2 corresponding transition probability matrices

P (u1 ) =

1
3
1
3

2

2
3
2
3



; P (u2 ) =

2

3
2
3

23

1
3
1
3



;

u1 always takes system state probability = , regardless starting state (and
therefore state probability = ), u2 opposite. Since state reward ,
state reward , optimal policy always select action u1 . policy
stationary distribution states 1 ; 2
= ; = , infinite-horizon discounted
value state
; discount value ff 2 ;

1

1

0

=1 2

13
[

Jff (i) = E

] = [1 3 2 3]
[0 1)

1
X

fft r

fi
fi
Xt fifi X0
fi

( )

=i

2

1

!

;

t=0
expectation state sequences X0 ; X1 ; X2 ; : : : state transitions generated according P u1 . Solving Bellmans equations: Jff r ffP u1 Jff , Jff
Jff ; Jff 0
2ff
2ff
r
r ; r 0 yields Jff
Jff
.
3(1 ff)
3(1 ff)

( )
= [ (1) (2)]

= + ( )
(2) = 1 +

(1) =

342

= [ (1) (2)]

fiP OLICY-G RADIENT E STIMATION

r(1) = 0

r(2) = 1

1

2

Figure 1: Two-state Markov Decsision Process

~

~( ) =

Now, suppose trying learn approximate value function J MDP, i.e. , J
w state ; scalar feature ( must dimensionality ensure
J really approximate). w 2 R parameter learnt. greedy policy obtained
J optimal, J must value state state . purposes illustration choose

;
, J
> J , w must negative.
Temporal Difference learning (or
) one popular techniques training
approximate value functions (Sutton & Barto, 1998). shown linear functions,
converges parameter w minimizing expected squared loss stationary
distribution (Tsitsikilis & Van-Roy, 1997):

()
=1 2
~
~
2
~(2) ~(1)
(1) = 2 (2) = 1
TD( )
TD(1)
~

w = argmin

w

1

1

2
X

i=1

[w(i) Jff (i)]2 :

(41)

Substituting previous expressions 1 ; 2 ; Jff optimal policy solving
3+ff
w , yields w
. Hence w > values ff 2 ; , wrong
9(1 ff)
sign. situation optimal policy implementable greedy policy based
approximate value function class (just choose w < ), yet
observing
optimal policy converge value function whose corresponding greedy policy implements
suboptimal policy.
geometrical illustration occurs shown Figure 2. figure, points
graph
represent
p
p values states. scales state 1 state 2 axes weighted
respectively. way, squared euclidean distance graph
two points J J corresponds expectation stationary distribution squared
difference values:

=

0

[0 1)

0

(1)

hp




TD(1)

(2)
~

(1)J (1);

p

(2)J (2)



hp

(1)J~(1); (2)J~(2)
p

2





2

= E J (X ) J~(X )

:

value function shaded region, corresponding greedy policy optimal, since
value functions rank state 2 state 1. bold line represents set realizable
approximate value functions w ; w
. solution (41) approximate value
function found projecting point corresponding true value function Jff ; Jff
onto
line. illustrated figure ff
= . projection suboptimal weighted
mean-squared distance value-function space take account policy boundary.

( (1)

(2))
=3 5

[( (1) (2)]

Appendix B. Proof Theorem 6
proof needs following topological lemma. definitions see, example, (Dudley, 1989,
pp. 2425).
343

fiBAXTER & BARTLETT

3

2

1

0

1

111111111111111
000000000000000
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
[J (1), J (2)]
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
[w * (1), w * (2)]
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
Legend
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
Optimal Policy:
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
Approximate
000000000000000
111111111111111
000000000000000
111111111111111
Value Function:
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
000000000000000
111111111111111
1

0

1

2

3

11
00
00
11
00
11
00
11

4

5

Figure 2: Plot value-function space two-state system. Note scale axis
weighted square root stationary probability corresponding state
optimal policy. solution found TD(1) simply projection true
value function onto set approximate value functions.

(

)

Lemma 7. Let X; topological space Hausdorff, separable, first-countable.
Let B Borel -algebra generated . measurable space X; B sequence
S1; S2 ; : : : B sets satisfies following conditions:

(

1. Si partition X (that is, X
empty intersection).

2. x 2 X , fxg 2 B

1
\

)

= SfS : 2 Sig two distinct elements Si

fS 2 Si : x 2 g = fxg:

i=1

=

Proof. Since X separable, countable dense subset
fx1 ; x2 ; : : :g. Since X firstcountable, xi aScountable neighbourhood base, Ni . Now, construct partitions
Si using countable set N 1
; ; : : :, define
i=1 Ni follows. Let S0 X and,

=

=

=1 2

Si = fS \ Ni : 2 Si g [ fS \ (X Ni) : 2 Si g :
1

1

344

fiP OLICY-G RADIENT E STIMATION

Clearly, Si measurable partition X . Since X Hausdorff, pair x; x0 distinct
points X , pair disjoint open sets A0 x 2 x0 2 A0 . Since
dense, pair s; s0 2 s0 2 A0 . Also, N contains neighbourhoods Ns
Ns0 Ns Ns0 A0 . Ns Ns0 disjoint. Thus, sufficiently large i, x
x0 fall distinct elements partition Si . Since true pair x; x0 , follows

1
\

fS 2 Si : x 2 g fxg:

i=1

reverse inclusion
trivial. measurability singletons fxg follows measuraS
bility Sx
fS 2 Si \ fxg g fact fxg X Sx .

:=

:

=

=

shall use Lemma 7 together following result show approximate
expectations certain random variables using single sample path Markov chain.

(

)

Lemma 8. Let X; B measurable space satisfying conditions Lemma 7, let S1 ; S2 ; : : :
suitable sequence partitions lemma. Let probability measure defined
space. Let f absolutely integrable function X . event , define

f (S ) =
x 2 X
almost x X ,

k

R

f :

(S )

= 1; 2; : : :, let Sk (x) unique element Sk containing x.
lim f (Sk (x)) = f (x):
k!1

Proof. Clearly, signed finite measure defined

(E ) =

Z

E

fd

absolutely continuous respect , Equation (42) defines
derivative respect . derivative also defined

(42)

f

Radon-Nikodym

(Sk (x))

(x) = klim
:
!1 (Sk (x))


See, example, (Shilov & Gurevich, 1966, Section 10.2). Radon-Nikodym Theorem (Dudley, 1989, Theorem 5.5.4, p. 134), two expressions equal a.e. ().
Proof. (Theorem 6.) definitions,

rfi = 0 rP Jfi

=

n X
n
X
i=1 j =1

(i)rpij ()Jfi (j ):

(43)

every , absolutely continuous respect reference measure , hence
j write
Z Z
d(; y)
pij () =
pij (u)
(u) d(u) (i)(y):

U
345

fiBAXTER & BARTLETT

Since depend
integral obtain

rpij () =

d(; y)=d absolutely integrable,

Z Z

U

pij (u) r

d(; y)
(u) d(u) (i)(y):


avoid cluttering notation, shall use denote distribution
denote distribution . notation,

()

rpij () =

differentiate

Z Z

U

pij

(; y) U ,



r
d:



Now, let probability measure U generated . write (43)

rfi =

X

i;j

(i)Jfi (j )

Z

YU

pij

r
d:



Using notation Lemma 8, define

pij (S ) =

R

pij ;

(S )

Z

1
r(S ) = (S ) rdd d;


measurable set

U . Notice that, given i, j , ,
pij (S ) = Pr(Xt+1 = j jXt = i; (y; u) 2 )
fi

!

fi
r
r(S ) = E dd fififi Xt = i; (Yt ; Ut ) 2 :


Let S1 ; S2 ; : : : sequence partitions U Lemma 7, let Sk
element Sk containing y; u . Using Lemma 8,

( )

Z

YU

pij

Z
r
=




lim pij (Sk (y; u)) r (Sk (y; u)) d(y; u)

YU k!1

= klim
!1

(y; u) denote

X Z

2Sk



pij (S ) r(S ) d;

346

fiP OLICY-G RADIENT E STIMATION

used Assumption 6 Lebesgue dominated convergence theorem interchange
integral limit. Hence,

rfi = klim
!1

= klim
!1

X X

i;j 2Sk

X

i;j;S

(i)(S )pij (S )Jfi (j )r(S )

Pr(Xt = i)Pr((Yt ; Ut ) 2 )Pr(Xt = j jXt = i; (Yt ; Ut ) 2 )
+1

fi

E (J (t + 1)jXt

+1

= klim
!1

X

i;j;S

"

fi
r
= j ) E dd fififi Xt = i; (Yt; Ut ) 2


!

#


E i(Xt )S (Yt; Ut )j (Xt )J (t + 1) rdd ;
+1



probabilities expectations respect stationary distribution Xt ,
distributions Yt ; Ut . Now, random process inside expectation asymptotically stationary
ergodic. ergodic theorem, (almost surely)

X TX
r
1
rfi = klim
lim
(Xt )S (Yt ; Ut )j (Xt )J (t + 1) dd :
!1 !1
1

+1

i;j;S t=0



easy see double limit also exists order reversed,
TX

X
r
1
rfi = Tlim
lim i(Xt )S (Yt ; Ut )j (Xt )J (t + 1) dd
!1
k!1
1

1
= Tlim
!1

t=0
TX1
t=0

+1

i;j;S

(;Yt )
r Ut
d(;Yt ) U



( ) J (t + 1):
( )

argument proof Theorem 4 shows tails

fi
fi
fi r d(;Yt ) U fi
fi
fi

fi
fi d(;Y
t)
fi
fi
U





J (t + 1) ignored

( )
( )
jr (Xt )j uniformly bounded. follows ! 0 rP Jfi w.p.1, required.
References
Aberdeen, D., & Baxter, J. (2001). Policy-gradient learning controllers internal state. Tech.
rep., Australian National University.
Aleksandrov, V. M., Sysoyev, V. I., & Shemeneva, V. V. (1968). Stochastic optimaization. Engineering Cybernetics, 5, 1116.
Baird, L., & Moore, A. (1999). Gradient descent general reinforcement learning. Advances
Neural Information Processing Systems 11. MIT Press.
347

fiBAXTER & BARTLETT

Bartlett, P. L., & Baxter, J. (1999). Hebbian synaptic modifications spiking neurons learn.
Tech. rep., Research School Information Sciences Engineering, Australian National
University. http://csl.anu.edu.au/bartlett/papers/BartlettBaxter-Nov99.ps.gz.
Bartlett, P. L., & Baxter, J. (2001). Estimation approximation bounds gradient-based reinforcement learning. Journal Computer Systems Sciences, 62. Invited Paper: Special
Issue COLT 2000.
Barto, A. G., Sutton, R. S., & Anderson, C. W. (1983). Neuronlike adaptive elements solve
difficult learning control problems. IEEE Transactions Systems, Man, Cybernetics,
SMC-13, 834846.
Baxter, J., Bartlett, P. L., & Weaver, L. (2001). Experiments infinite-horizon, policy-gradient
estimation. Journal Artificial Intelligence Research. appear.
Baxter, J., Tridgell, A., & Weaver, L. (2000). Learning play chess using temporal-differences.
Machine Learning, 40(3), 243263.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Bertsekas, D. P. (1995). Dynamic Programming Optimal Control, Vol II. Athena Scientific.
Breiman, L. (1966). Probability. Addison-Wesley.
Cao, X.-R., & Wan, Y.-W. (1998). Algorithms Sensitivity Analysis Markov Chains
Potentials Perturbation Realization. IEEE Transactions Control Systems Technology,
6, 482492.
Dudley, R. M. (1989). Real Analysis Probability. Wadsworth & Brooks/Cole, Belmont, California.
Glynn, P. W. (1986). Stochastic approximation monte-carlo optimization. Proceedings
1986 Winter Simulation Conference, pp. 356365.
Glynn, P. W. (1990). Likelihood ratio gradient estimation stochastic systems. Communications
ACM, 33, 7584.
Glynn, P. W., & LEcuyer, P. (1995). Likelihood ratio gradient estimation regenerative stochastic
recursions. Advances Applied Probability, 27, 4 (1995), 27, 10191053.
Ho, Y.-C., & Cao, X.-R. (1991). Perturbation Analysis Discrete Event Dynamic Systems. Kluwer
Academic, Boston.
Jaakkola, T., Singh, S. P., & Jordan, M. I. (1995). Reinforcement Learning Algorithm Partially
Observable Markov Decision Problems. Tesauro, G., Touretzky, D., & Leen, T. (Eds.),
Advances Neural Information Processing Systems, Vol. 7. MIT Press, Cambridge, MA.
Kimura, H., & Kobayashi, S. (1998a). analysis actor/critic algorithms using eligibility traces:
Reinforcement learning imperfect value functions. Fifteenth International Conference
Machine Learning, pp. 278286.
348

fiP OLICY-G RADIENT E STIMATION

Kimura, H., & Kobayashi, S. (1998b). Reinforcement learning continuous action using stochastic gradient ascent. Intelligent Autonomous Systems (IAS-5), pp. 288295.
Kimura, H., Miyazaki, K., & Kobayashi, S. (1997). Reinforcement learning POMDPs
function approximation. Fisher, D. H. (Ed.), Proceedings Fourteenth International
Conference Machine Learning (ICML97), pp. 152160.
Kimura, H., Yamamura, M., & Kobayashi, S. (1995). Reinforcement learning stochastic hill
climbing discounted reward. Proceedings Twelfth International Conference
Machine Learning (ICML95), pp. 295303.
Konda, V. R., & Tsitsiklis, J. N. (2000). Actor-Critic Algorithms. Neural Information Processing
Systems 1999. MIT Press.
Lancaster, P., & Tismenetsky, M. (1985). Theory Matrices. Academic Press, San Diego, CA.
Marbach, P., & Tsitsiklis, J. N. (1998). Simulation-Based Optimization Markov Reward Processes. Tech. rep., MIT.
Meuleau, N., Peshkin, L., Kaelbling, L. P., & Kim, K.-E. (2000). Off-policy policy search. Tech.
rep., MIT Artificical Intelligence Laboratory.
Meuleau, N., Peshkin, L., Kim, K.-E., & Kaelbling, L. P. (1999). Learning finite-state controllers
partially observable environments. Proceedings Fifteenth International Conference
Uncertainty Artificial Intelligence.
Peshkin, L., Kim, K.-E., Meuleau, N., & Kaelbling, L. P. (2000). Learning cooperate via policy
search. Proceedings Sixteenth International Conference Uncertainty Artificial
Intelligence.
Reiman, M. I., & Weiss, A. (1986). Sensitivity analysis via likelihood ratios. Proceedings
1986 Winter Simulation Conference.
Reiman, M. I., & Weiss, A. (1989). Sensitivity analysis simulations via likelihood ratios. Operations Research, 37.
Rubinstein, R. Y. (1969). Problems Monte Carlo Optimization. Ph.D. thesis.
Rubinstein, R. Y. (1991). optimize complex stochastic systems single sample path
score function method. Annals Operations Research, 27, 175211.
Rubinstein, R. Y. (1992). Decomposable score function estimators sensitivity analysis optimization queueing networks. Annals Operations Research, 39, 195229.
Rubinstein, R. Y., & Melamed, B. (1998). Modern Simulation Modeling. Wiley, New York.
Rubinstein, R. Y., & Shapiro, A. (1993). Discrete Event Systems. Wiley, New York.
Samuel, A. L. (1959). Studies Machine Learning Using Game Checkers. IBM
Journal Research Development, 3, 210229.
349

fiBAXTER & BARTLETT

Shilov, G. E., & Gurevich, B. L. (1966). Integral, Measure Derivative: Unified Approach.
Prentice-Hall, Englewood Cliffs, N.J.
Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning Without State-Estimation Partially
Observable Markovian Decision Processes. Proceedings Eleventh International
Conference Machine Learning.
Singh, S., & Bertsekas, D. (1997). Reinforcement learning dynamic channel allocation cellular telephone systems. Advances Neural Information Processing Systems: Proceedings
1996 Conference, pp. 974980. MIT Press.
Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observable Markov
decision processes finite horizon. Operations Research, 21, 10711098.
Sondik, E. J. (1978). optimal control partially observable Markov decision processes
infinite horizon: Discounted costs. Operations Research, 26.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge MA. ISBN 0-262-19398-1.
Sutton, R. S., McAllester, D., Singh, S., & Mansour, Y. (2000). Policy Gradient Methods
Reinforcement Learning Function Approximation. Neural Information Processing
Systems 1999. MIT Press.
Tao, N., Baxter, J., & Weaver, L. (2001). multi-agent, policy-gradient approach network
routing. Tech. rep., Australian National University.
Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning, 8, 257
278.
Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves master-level
play. Neural Computation, 6, 215219.
Tsitsikilis, J. N., & Van-Roy, B. (1997). Analysis Temporal Difference Learning Function Approximation. IEEE Transactions Automatic Control, 42(5), 674690.
Williams, R. J. (1992). Simple Statistical Gradient-Following Algorithms Connectionist Reinforcement Learning. Machine Learning, 8, 229256.
Zhang, W., & Dietterich, T. (1995). reinforcement learning approach job-shop scheduling.
Proceedings Fourteenth International Joint Conference Artificial Intelligence, pp.
11141120. Morgan Kaufmann.

350

fiJournal Artificial Intelligence Research 15 (2001) 207-261

Submitted 5/00; published 9/01

Planning Rewriting
Jose Luis Ambite
Craig A. Knoblock

ambite@isi.edu
knoblock@isi.edu

Information Sciences Institute Department Computer Science,
University Southern California,
4676 Admiralty Way, Marina del Rey, CA 90292, USA

Abstract
Domain-independent planning hard combinatorial problem. Taking account
plan quality makes task even difficult. article introduces Planning Rewriting (PbR), new paradigm efficient high-quality domain-independent planning. PbR
exploits declarative plan-rewriting rules efficient local search techniques transform
easy-to-generate, possibly suboptimal, initial plan high-quality plan. addition addressing issues planning efficiency plan quality, framework offers
new anytime planning algorithm. implemented planner applied
several existing domains. experimental results show PbR approach provides
significant savings planning effort generating high-quality plans.

1. Introduction

Planning process generating network actions, plan, achieves desired
goal initial state world. Many problems practical importance
cast planning problems. Instead crafting individual planner solve specific
problem, long line research focused constructing domain-independent planning
algorithms. Domain-independent planning accepts input, descriptions
initial state goal particular problem instance, also declarative domain
specification, is, set actions change properties state. Domainindependent planning makes development planning algorithms efficient, allows
software domain reuse, facilitates principled extension capabilities
planner. Unfortunately, domain-independent planning (like planning problems)
computationally hard (Bylander, 1994; Erol, Nau, & Subrahmanian, 1995; Backstrom
& Nebel, 1995). Given complexity limitations, previous work domainindependent planning focused finding solution plan without careful consideration
plan quality. Usually simple cost functions, length plan,
used. However, many practical problems plan quality crucial. paper
present new planning paradigm, Planning Rewriting (PbR), addresses
planning efficiency plan quality maintaining benefits domain independence.
framework fully implemented present empirical results several planning
domains.
c
2001
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiAmbite & Knoblock

1.1 Solution Approach
Two observations guided present work. first one two sources
complexity planning:
Satisfiability: difficulty finding solution planning problem (regardless
quality solution).
Optimization: difficulty finding optimal solution given cost metric.
given domain, facets may contribute differently complexity
planning. particular, many domains satisfiability problem
relatively easy complexity dominated optimization problem. example,
may many plans would solve problem, finding one efficient
practice, cost solution varies greatly, thus finding optimal one
computationally hard. refer domains optimization domains.
optimization domains great practical interest query optimization manufacturing
process planning.1
second observation planning problems great deal structure. Plans
type graph strong semantics, determined general properties
planning particular domain specification. structure
exploited improve efficiency planning process.
Prompted previous observations, developed novel approach efficient
planning optimization domains: Planning Rewriting (PbR). framework works
two phases:
1. Generate initial solution plan. Recall optimization domains efficient.
However, quality initial plan may far optimal.
2. Iteratively rewrite current solution plan improving quality using set declarative plan-rewriting rules, either acceptable solution found resource
limit reached.
motivation, consider optimization domains distributed query processing
manufacturing process planning.2 Distributed query processing (Yu & Chang, 1984) involves generating plan efficiently computes user query data resides
different nodes network. query plan composed data retrieval actions diverse
information sources operations data (such relational algebra:
join, selection, etc). systems use general-purpose planner solve problem
(Knoblock, 1996). domain easy construct initial plan (any parse
query suffices) transform using gradient-descent search reduce cost.
plan transformations exploit commutative associative properties (relational algebra) operators, facts group operators executed
together remote information source generally efficient so. Figure 1
1. Interestingly, one widely studied planning domains, Blocks World, also property.
2. domains analyzed Section 4. Graphical examples rewriting process appear Figure 30
query planning Figure 21 manufacturing process planning. reader may want consult
figures even details explained point.

208

fiPlanning Rewriting

shows sample transformations. Simple-join-swap transforms two join trees according commutative associative properties join operator. Remote-join-eval
executes join two subqueries remote source, source able so.
Simple-Join-Swap:
retrieve(Q1, Source1) 1 [retrieve(Q2, Source2) 1 retrieve(Q3, Source3)]
retrieve(Q2, Source2) 1 [retrieve(Q1, Source1) 1 retrieve(Q3, Source3)]
Remote-Join-Eval:
(retrieve(Q1, Source) 1 retrieve(Q2, Source)) capability(Source, join)
retrieve(Q1 1 Q2, Source)
Figure 1: Transformations Query Planning
manufacturing, problem find economical plan machining operations
implement desired features design. feature-based approach (Nau, Gupta,
& Regli, 1995), possible enumerate actions involved building piece
analyzing CAD model. difficult find ordering operations
setups optimize machining cost. However, similar query planning, possible
incrementally transform (possibly inefficient) initial plan. Often, order actions
affect design goal, quality plan, thus many actions commute.
Also, important minimize number setups fixing piece machine
rather time consuming operation. Interestingly, grouping machining operations
setup analogous evaluating subquery remote information source.
suggested examples, many problems combine characteristics traditional planning satisfiability quality optimization. domains
often exist natural transformations may used efficiently obtain high-quality plans
iterative rewriting. Planning Rewriting provides domain-independent framework
allows plan transformations conveniently specified declarative plan-rewriting
rules facilitates exploration efficient (local) search techniques.
1.2 Advantages Planning Rewriting
several advantages planning style PbR introduces. First, PbR
declarative domain-independent framework. facilitates specification planning
domains, evolution, principled extension planner new capabilities. Moreover, declarative rewriting rule language provides natural convenient
mechanism specify complex plan transformations.
Second, PbR accepts sophisticated quality measures operates complete
plans. previous planning approaches either addressed quality issues
simple quality measures, number steps plan, partial
plans available planning process. general, partial plan cannot offer
enough information evaluate complex cost metric and/or guide planning search
effectively.
209

fiAmbite & Knoblock

Third, PbR use local search methods remarkably successful scaling
large problems (Aarts & Lenstra, 1997).3 using local search techniques, high-quality
plans efficiently generated. Fourth, search occurs space solution plans,
generally much smaller space partial plans explored planners based
refinement search.
Fifth, framework yields anytime planning algorithm (Dean & Boddy, 1988).
planner always solution offer point computation (modulo initial
plan generation needs fast). clear advantage traditional planning
approaches, must run completion producing solution. Thus, system
allows possibility trading planning effort plan quality. example, query
planning quality plan execution time may make sense keep
planning cost current plan small enough, even cheaper one could
found. discussion concrete examples advantages given throughout
following sections.
1.3 Contributions
main contribution paper development Planning Rewriting, novel
domain-independent paradigm efficient high-quality planning. First, define language declarative plan-rewriting rules present algorithms domain-independent
plan rewriting. rewriting rules provide natural convenient mechanism specify complex plan transformations. techniques plan rewriting generalize traditional
graph rewriting. Graph rewriting rules need specify rule consequent complete
embedding replacement subplan. introduce novel class partially-specified
plan-rewriting rules relax restriction. taking advantage semantics
planning, embedding automatically computed. single partially-specified rule
concisely represent great number fully-specified rules. rules also easier
write understand fully-specified counterparts. Second, adapt local
search techniques, gradient descent, efficiently explore space plan rewritings optimize plan quality. Finally, demonstrate empirically usefulness
PbR approach several planning domains.
1.4 Outline
remainder paper structured follows. Section 2 provides background
planning, rewriting, local search, fields upon PbR builds. Section 3
presents basic framework Planning Rewriting domain-independent approach
local search. section describes detail plan rewriting declarative rewriting rule
language. Section 4 describes several application domains shows experimental results
comparing PbR planners. Section 5 reviews related work. Finally, Section 6
summarizes contributions paper discusses future work.
3. Although space rewritings explored complete search methods, application domains
analyzed search space large experience suggests local search
appropriate. However, extent complete search methods useful Planning Rewriting
framework remains open issue. paper focus local search.

210

fiPlanning Rewriting

2. Preliminaries: Planning, Rewriting, Local Search
framework Planning Rewriting arises confluence several areas research, namely, artificial intelligence planning algorithms, graph rewriting, local search
techniques. section give background areas explain
relate PbR.
2.1 AI Planning
assume reader familiar classical AI planning, section
highlight main concepts relate PbR framework. Weld (1994, 1999)
Russell & Norvig (1995) provide excellent introductions AI planning.
PbR follows classical AI planning representation actions transform state.
state set ground propositions understood conjunctive formula. PbR,
AI planners, follows Closed World Assumption, is, proposition explicitly
mentioned state assumed false, similarly negation failure semantics
logic programming. propositions state modified, asserted negated,
actions domain. actions domain specified operator schemas.
operator schema consists two logical formulas: precondition, defines
conditions operator may applied, postcondition, specifies
changes state effected operator. Propositions mentioned
postcondition assumed change application operator. type
representation initially introduced STRIPS system (Fikes & Nilsson, 1971).
language operators PbR Sage (Knoblock, 1995, 1994b),
extension UCPOP (Penberthy & Weld, 1992). operator description
language PbR accepts arbitrary function-free first-order formulas preconditions
operators, conditional universally quantified effects (but disjunctive effects).
addition, operators specify resources use. Sage PbR address unit
non-consumable resources. resources fully acquired operator
completion action released reused.
Figure 2 shows sample operator schema specification simple Blocks World
domain,4 representation accepted PbR. domain two actions: stack,
puts one block top another, unstack, places block table.5
state described two predicates: (on ?x ?y)6 denotes block ?x top
another block ?y (or Table), (clear ?x) denotes ?x block
block top it.
example complex operator process manufacturing domain shown
Figure 3. operator describes behavior punch, machine used
make holes parts. punch operation requires available clamp
machine orientation width hole appropriate using punch.
executing operation part desired hole also
4. illustrate basic concepts planning, use examples simple Blocks World domain.
reader find real-world application planning techniques, query planning, Section 4.4.
5. (stack ?x ?y ?z) read stack block ?x top block ?y ?z.
(unstack ?x ?y) read lift block ?x top block ?y put Table.
6. convention, variables preceded question mark symbol (?), ?x.

211

fiAmbite & Knoblock

(define (operator STACK)
:parameters (?X ?Y ?Z)
:precondition
(:and (on ?X ?Z) (clear ?X) (clear ?Y)
(:neq ?Y ?Z) (:neq ?X ?Z) (:neq ?X ?Y)
(:neq ?X Table) (:neq ?Y Table))
:effect (:and (on ?X ?Y) (:not (on ?X ?Z))
(clear ?Z) (:not (clear ?Y))))

(define (operator UNSTACK)
:parameters (?X ?Y)
:precondition
(:and (on ?X ?Y) (clear ?X) (:neq ?X ?Y)
(:neq ?X Table) (:neq ?Y Table))
:effect (:and (on ?X Table) (clear ?Y)
(:not (on ?X ?Y))))

Figure 2: Blocks World Operators
(define (operator PUNCH)
:parameters (?x ?width ?orientation)
:resources ((machine PUNCH) (is-object ?x))
:precondition (:and (is-object ?x)
(is-punchable ?x ?width ?orientation)
(has-clamp PUNCH))
:effect (:and (:forall (?surf) (:when (:neq ?surf ROUGH)
(:not (surface-condition ?x ?surf))))
(surface-condition ?x ROUGH)
(has-hole ?x ?width ?orientation)))

Figure 3: Manufacturing Operator
rough surface.7 Note specification resources slot. Declaring (machine PUNCH)
resource enforces operator use punch concurrently. Similarly,
declaring part, (is-object ?x), resource means one operation time
performed object. examples operator specifications appear
Figures 18, 19, 28.
plan PbR represented graph, spirit partial-order causal-link planners (POCL) UCPOP (Penberthy & Weld, 1992). nodes plan steps,
is, instantiated domain operators. edges specify temporal ordering relation among
steps imposed causal links ordering constraints. causal link record
proposition established plan. record contains proposition (sometimes also
called condition), producer step, consumer step. producer step
plan asserts proposition, is, proposition one effects. consumer
step needs proposition, is, proposition one preconditions.
causality, producer must precede consumer.
ordering constraints needed ensure plan consistent. arise
resolving operator threats resource conflicts. operator threat occurs
step negates condition causal link ordered producer
consumer steps causal link. prevent situation, makes plan inconsistent, POCL planners order threatening step either producer (demotion)
consumer (promotion) posting appropriate ordering constraints.
7. operator uses idiom combining universal quantification negated conditional effects enforce
attribute surface-condition part single-valued.

212

fiPlanning Rewriting

unit non-consumable resources considered, steps requiring resource
sequentially ordered, chain ordering constraints appear plan.
example plan Blocks World using graph representation given
Figure 4. plan transforms initial state consisting two towers: C A,
Table, B D, Table; final state consisting one tower: B, B C,
C D, Table. initial state represented step 0 preconditions
propositions initial state postconditions. Similarly, goal state
represented step goal postconditions goal formula precondition.
plan achieves goal using two unstack steps disassemble two initial towers
using three stack steps build desired tower. causal links shown
solid arrows ordering constraints dashed arrows. additional effects step
used causal links, sometimes called side effects, shown step
pointed thin dashed arrows. Negated propositions preceded . Note need
ordering link steps 2, stack(B C Table), 3, stack(A B Table).
step 3 could ordered concurrently step 2, would negate precondition
clear(B) step 2, making plan inconsistent. similar situation occurs steps
1 2 another ordering link introduced.

clear(B)

Causal Link
Ordering Constraint
Side Effect

on(A Table)
on(C A)

clear(A)

3 STACK(A B Table)

4 UNSTACK(C A)
on(C Table)

on(C A)
clear(C)
on(D Table)

on(A Table)
clear(B)

clear(C)

0
clear(B)

on(B Table)
on(A B)
clear(C)
2 STACK(B C Table)
on(B C)
on(C D)
1 STACK(C Table)
GOAL
clear(D)
on(C Table)
clear(D)


on(B D)

B

on(B Table)
5 UNSTACK(B D)
on(B D)
clear(B)

C

B

C







clear(C)
Initial State

Goal State

Figure 4: Sample Plan Blocks World Domain

2.2 Rewriting
Plan rewriting PbR related term graph rewriting. Term rewriting originated
context equational theories reduction normal forms effective way
perform deduction (Avenhaus & Madlener, 1990; Baader & Nipkow, 1998). rewrite
system specified set rules. rule corresponds preferred direction
equivalence theorem. main issue term rewriting systems convergence, is,
two arbitrary terms rewritten finite number steps unique normal form.
PbR two plans considered equivalent solutions problem,
213

fiAmbite & Knoblock

although may differ cost operators (that is, equivalent
respect satisfiability introduced above). However, interested using
rewriting rules prove equivalence. Instead, framework uses rewriting
rules explore space solution plans.
Graph rewriting, akin term rewriting, refers process replacing subgraph
given graph, conditions satisfied, another subgraph. Graph rewriting
found broad applications, high-level programming languages, database
data description query languages, etc. Schurr (1997) presents good survey.
main drawback general graph rewriting complexity. graph matching
reduced (sub)graph isomorphism problem NP-complete. Nevertheless,
restrictions graph rewriting performed efficiently (Dorr, 1995).
Planning Rewriting adapts general graph rewriting semantics partial-order
planning STRIPS-like operator representation. plan-rewriting rule PbR specifies
replacement, certain conditions, subplan another subplan. However,
formalism rule need specify completely detailed embedding
consequent graph rewriting systems. consistent embeddings rule consequent,
generation edges necessary, automatically computed according
semantics partial-order planning. algorithm ensures rewritten plans always
remain valid (Section 3.1.3). plan-rewriting rules intended explore space
solution plans reach high-quality plans.
2.3 Local Search Combinatorial Optimization
PbR inspired local search techniques used combinatorial optimization.
instance combinatorial optimization problem consists set feasible solutions
cost function solutions. problem consists finding solution optimal
cost among feasible solutions. Generally problems addressed computationally
intractable, thus approximation algorithms used. One class approximation
algorithms surprisingly successful spite simplicity local search
methods (Aarts & Lenstra, 1997; Papadimitriou & Steiglitz, 1982).
Local search based concept neighborhood. neighborhood solution
p set solutions sense close p, example
easily computed p share significant amount structure p.
neighborhood generating function may, may not, able generate optimal
solution. neighborhood function generate global optima, starting
initial feasible point, called exact (Papadimitriou & Steiglitz, 1982, page 10).
Local search seen walk directed graph whose vertices solutions
points whose arcs connect neighboring points. neighborhood generating function
determines properties graph. particular, graph disconnected,
neighborhood exact since exist feasible points would lead local optima
global optima. PbR points solution plans neighbors plan
plans generated application set declarative plan rewriting rules.
basic version local search iterative improvement. Iterative improvement starts
initial solution searches neighborhood solution lower cost solution. solution found, replaces current solution search continues.
214

fiPlanning Rewriting

Otherwise, algorithm returns locally optimal solution. Figure 5(a) shows graphical
depiction basic iterative improvement. several variations basic algorithm. First improvement generates neighborhood incrementally selects first
solution better cost current one. Best improvement generates complete
neighborhood selects best solution within neighborhood.

Neighborhood

Local Optima

Local Optima

(a) Basic Iterative Improvement

(b) Variable-Depth Search

Figure 5: Local Search
Basic iterative improvement obtains local optima, necessarily global optimum.
One way improve quality solution restart search several initial points choose best local optima reached them. advanced
algorithms, variable-depth search, simulated annealing tabu search, attempt
minimize probability stuck low-quality local optimum.
Variable-depth search based applying sequence steps opposed one
step iteration. Moreover, length sequence may change iteration
iteration. way system overcomes small cost increases eventually lead
strong cost reductions. Figure 5(b) shows graphical depiction variable-depth search.
Simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983) selects next point randomly. lower cost solution chosen, selected. solution higher cost
chosen, still selected probability. probability decreased algorithm progresses (analogously temperature physical annealing). function
governs behavior acceptance probability called cooling schedule.
proven simulated annealing converges asymptotically optimal solution. Unfortunately, convergence requires exponential time. So, practice, simulated annealing
used faster cooling schedules (not guaranteed converge optimal) thus
behaves like approximation algorithm.
Tabu search (Glover, 1989) also accept cost-increasing neighbors. next solution
randomly chosen legal neighbor even cost worse current solution.
neighbor legal limited-size tabu list. dynamically updated tabu list
prevents solution points considered period time. intuition
decide consider solution higher cost least lie
unexplored part space. mechanism forces exploration solution space
local minima.
Finally, stress appeal local search relies simplicity good
average-case behavior. could expected, number negative worst-case results. example, traveling salesman problem known exact neighborhoods,
215

fiAmbite & Knoblock

depend problem instance, must exponential size (Savage, Weiner,
& Bagchi, 1976). Moreover, improving move neighborhoods cannot found
polynomial time unless P = NP (Papadimitriou & Steiglitz, 1977). Nevertheless, best
approximation algorithm traveling salesman problem local search algorithm
(Johnson, 1990).

3. Planning Rewriting Local Search
Planning Rewriting viewed domain-independent framework local search.
PbR accepts arbitrary domain specifications, declarative plan-rewriting rules generate
neighborhood plan, arbitrary (local) search methods. Therefore, assuming
given combinatorial problem encoded planning problem, PbR take
input experiment different neighborhoods search methods.
describe main issues Planning Rewriting instantiation
local search idea typical combinatorial optimization algorithms:
Selection initial feasible point: PbR phase consists efficiently generating
initial solution plan.
Generation local neighborhood : PbR neighborhood plan set
plans obtained application set declarative plan-rewriting rules.
Cost function minimize: measure plan quality planner
optimizing. plan quality function range simple domain-independent
cost metric, number steps, complex domain-specific ones,
query evaluation cost total manufacturing time set parts.
Selection next point: PbR, consists deciding solution plan
consider next. choice determines global space explored
significant impact efficiency planning. variety local search strategies
used PbR, steepest descent, simulated annealing, etc. search
method yields best results may domain problem specific.
following subsections expand issues. First, discuss use
declarative rewriting rules generate local neighborhood plan, constitutes
main contribution paper. present syntax semantics rules,
plan-rewriting algorithm, formal properties complexity analysis plan rewriting,
rule taxonomy. Second, address selection next plan associated
search techniques plan optimization. Third, discuss measures plan quality.
Finally, describe approaches initial plan generation.
3.1 Local Neighborhood Generation: Plan-Rewriting Rules
neighborhood solution plan generated application set declarative
plan-rewriting rules. rules embody domain-specific knowledge transformations solution plan likely result higher-quality solutions. application
given rule may produce one several rewritten plans fail produce plan,
rewritten plans guaranteed valid solutions. First, describe syntax
216

fiPlanning Rewriting

semantics rules. Second, introduce two approaches rule specification. Third,
present rewriting algorithm, formal properties, complexity plan rewriting.
Finally, present taxonomy plan-rewriting rules.
3.1.1 Plan-Rewriting Rules: Syntax Semantics
First, introduce rule syntax semantics examples. Then, provide
formal description. plan-rewriting rule three components: (1) antecedent (:if
field) specifies subplan matched; (2) :replace field identifies subplan
going removed, subset steps links antecedent; (3) :with field
specifies replacement subplan. Figure 6 shows two rewriting rules Blocks World
domain introduced Figure 2. Intuitively, rule avoid-move-twice says that, whenever
possible, better stack block top another directly, rather first moving
table. situation occurs plans generated simple algorithm first
puts blocks table build desired towers, plan Figure 4.
rule avoid-undo says actions moving block table back
original position cancel could removed plan.
(define-rule :name avoid-move-twice
:if (:operators ((?n1 (unstack ?b1 ?b2))
(?n2 (stack ?b1 ?b3 Table)))
:links (?n1 (on ?b1 Table) ?n2)
:constraints ((possibly-adjacent ?n1 ?n2)
(:neq ?b2 ?b3)))
:replace (:operators (?n1 ?n2))
:with (:operators (?n3 (stack ?b1 ?b3 ?b2))))

(define-rule :name avoid-undo
:if (:operators
((?n1 (unstack ?b1 ?b2))
(?n2 (stack ?b1 ?b2 Table)))
:constraints
((possibly-adjacent ?n1 ?n2))
:replace (:operators (?n1 ?n2))
:with NIL))

Figure 6: Blocks World Rewriting Rules
rule manufacturing domain (Minton, 1988b) shown Figure 7.
domain additional rewriting rules described detail Section 4.1. rule states
plan includes two consecutive punching operations order make holes two
different objects, another machine, drill-press, also available, plan quality may
improved replacing one punch operations drill-press. domain
plan quality (parallel) time manufacture parts. rule helps parallelize
plan thus improve plan quality.
(define-rule :name punch-by-drill-press
:if (:operators ((?n1 (punch ?o1 ?width1 ?orientation1))
(?n2 (punch ?o2 ?width2 ?orientation2)))
:links (?n1 ?n2)
:constraints ((:neq ?o1 ?o2)
(possibly-adjacent ?n1 ?n2)))
:replace (:operators (?n1))
:with (:operators (?n3 (drill-press ?o1 ?width1 ?orientation1))))

Figure 7: Manufacturing Process Planning Rewriting Rule
217

fiAmbite & Knoblock

plan-rewriting rule syntax described BNF specification given Figure 8.
BNF generates rules follow template shown Figure 9. Next, describe
semantics three components rule (:if, :replace, :with fields) detail.
<rule> ::= (define-rule :name <name>
:if (<graph-spec-with-constraints>)
:replace (<graph-spec>)
:with (<graph-spec>))
<graph-spec-with-constraints> ::= {<graph-spec>}
{:constraints (<constraints>)}
<graph-spec> ::= {:operators (<nodes>)}
{:links (<edges>)} | NIL
<nodes> ::= <node> | <node> <nodes>
<edges> ::= <edge> | <edge> <edges>
<constraints> ::= <constraint> | <constraint> <constraints>
<node> ::= (<node-var> {<node-predicate>} {:resource})
<edge> ::= (<node-var> <node-var>) |
(<node-var> <edge-predicate> <node-var>) |
(<node-var> :threat <node-var>)
<constraint> ::= <interpreted-predicate> |
(:neq <pred-var> <pred-var>)
<node-var> <pred-var> = , {} = optional, | = alternative

Figure 8: BNF Rewriting Rules

(define-rule :name <rule-name>
:if (:operators ((<nv> <np> {:resource}) ...)
:links ((<nv> {<lp>|:threat} <nv>) ...)
:constraints (<ip> ...))
:replace (:operators (<nv> ...)
:links ((<nv> {<lp>|:threat} <nv>) ...))
:with (:operators ((<nv> <np> {:resource}) ...)
:links ((<nv> {<lp>} <nv>) ...)))
<nv> = node variable, <np> = node predicate, {} = optional
<lp> = causal link predicate, <ip> = interpreted predicate,

| = alternative

Figure 9: Rewriting Rule Template
antecedent, :if field, specifies subplan matched current
plan. graph structure subplan defined :operators :links fields.
:operators field specifies nodes (operators) graph :links field
specifies edges (causal ordering links). Finally, :constraints field specifies
set constraints operators links must satisfy.
:operators field consists list node variable node predicate pairs.
step number steps plan match given node predicate would
correspondingly bound node variable. node predicate interpreted
two ways: step action, resource used step. example, node
specification (?n2 (stack ?b1 ?b3 Table)) antecedent avoid-move-twice
Figure 6 shows node predicate denotes step action. node specification
collect tuples, composed step number ?n2 blocks ?b1 ?b3, obtained matching
steps whose action stack block ?b1 Table moved top
another block ?b3. node specification applied plan Figure 4 would result
218

fiPlanning Rewriting

three matches: (1 C D), (2 B C), (3 B), variables (?n2 ?b1 ?b3) respectively.
optional keyword :resource present, node predicate interpreted one
resources used plan step, opposed describing step action. example
rule matches resources operator given Figure 10, node
specification (?n1 (machine ?x) :resource) match steps use resource
type machine collect pairs step number ?n1 machine object ?x.
(define-rule :name resource-swap
:if (:operators ((?n1 (machine ?x) :resource)
(?n2 (machine ?x) :resource))
:links ((?n1 :threat ?n2)))
:replace (:links (?n1 ?n2))
:with (:links (?n2 ?n1)))

Figure 10: Resource-Swap Rewriting Rule
:links field consists list link specifications. language admits link
specifications three types. first type specified pair node variables.
example, (?n1 ?n2) Figure 7. specification matches temporal ordering link
plan, regardless imposed causal links resolution threats.
second type link specification matches causal links. Causal links specified
triples composed producer step node variable, edge predicate, consumer
step node variable. semantics causal link producer step asserts
effects predicate, turn needed preconditions consumer step.
example, link specification (?n1 (on ?b1 Table) ?n2) Figure 6 matches steps ?n1
put block ?b1 Table steps ?n2 subsequently pick block.
link specification applied plan Figure 4 would result matches: (4 C 1)
(5 B 2), variables (?n1 ?b1 ?n2).
third type link specification matches ordering links originating resolution
threats (coming either resource conflicts operator conflicts). links
selected using keyword :threat place condition. example,
resource-swap rule Figure 10 uses link specification (?n1 :threat ?n2) ensure
steps ordered involved threat situation matched.
helps identify critical steps reasons (i.e.
causal links) order, therefore rule may attempt reorder them.
useful plan quality depends degree parallelism plan
different ordering may help parallelize plan. Recall threats solved either
promotion demotion, reverse ordering may also produce valid plan,
often case conflict among resources rule Figure 10.
Interpreted predicates, built-in user-defined, specified :constraints
field. predicates implemented programmatically opposed obtained
matching components plan. built-in predicates currently implemented
inequality8 (:neq), comparison (< <= > >=), arithmetic (+ - * /) predicates.
user also add arbitrary predicates corresponding programmatic implementa8. Equality denoted sharing variables rule specification.

219

fiAmbite & Knoblock

tions. interpreted predicates may act filters previous variables introduce
new variables (and compute new values them). example, user-defined predicate
possibly-adjacent rules Figure 6 ensures steps consecutive
linearization plan.9 plan Figure 4 extension possibly-adjacent
predicate is: (0 4), (0 5), (4 5), (5 4), (4 1), (5 1), (1 2), (2 3), (3 Goal).
user easily add interpreted predicates including function definition
implements predicate. rule matching algorithm passes arguments calls
functions appropriate. current plan passed default first argument
interpreted predicates order provide context computation predicate
(but ignored). Figure 11 show skeleton (Lisp) implementation
possibly-adjacent less-than interpreted predicates.
(defun possibly-adjacent (plan node1 node2)
(not (necessarily-not-adjacent
node1
node2
;; accesses current plan
(plan-ordering plan)))

(defun less-than (plan n1 n2)
(declare (ignore plan))
(when (and (numberp n1) (numberp n2))
(if (< n1 n2)
(nil) ;; true
nil))) ;; false

Figure 11: Sample Implementation Interpreted Predicates
consequent composed :replace :with fields. :replace field
specifies subplan going removed plan, subset
steps links identified antecedent. step removed, links refer
step also removed. :with field specifies replacement subplan.
see Sections 3.1.2 3.1.3, replacement subplan need completely
specified. example, :with field avoid-move-twice rule Figure 6
specifies addition stack step step embedded plan.
links rest plan automatically computed rewriting process.
3.1.2 Plan-Rewriting Rules: Full versus Partial Specification
PbR gives user total flexibility defining rewriting rules. section describe two
approaches guaranteeing rewriting rule specification preserves plan correctness,
is, produces valid rewritten plan applied valid plan.
full-specification approach rule specifies steps links involved
rewriting. rule antecedent identifies anchoring points operators
consequent, embedding replacement subplan unambiguous results
valid plan. burden proving rule correct lies upon user automated
rule defining procedure (cf. Section 6). kind rules ones typically used
graph rewriting systems (Schurr, 1997).
partial-specification approach rule defines operators links constitute gist plan transformation, rule prescribe precise
9. interpreted predicate possibly-adjacent makes link expression antecedent avoid-move-twice redundant. Unstack puts block ?b1 table picked
stack operator, thus causal link (?n1 (on ?b1 Table) ?n2) already implied :operators
:constraints specification could removed rule specification.

220

fiPlanning Rewriting

embedding replacement subplan. burden producing valid plan lies upon
system. PbR takes advantage semantics domain-independent planning accept
relaxed rule specification, fill details, produce valid rewritten plan.
Moreover, user free specify rules may necessarily able compute
rewriting plan matches antecedent necessary condition
checked antecedent. is, partially-specified rule may overgeneral.
may seem undesirable, often rule may cover useful cases naturally
specified form. rule may fail rarely occurring plans, effort
defining matching complete specification may worthwhile. case,
plan-rewriting algorithm ensures application rewriting rule either generates
valid plan fails produce plan (Theorem 1, Section 3.1.3).
example two approaches rule specification, consider Figure 12
shows avoid-move-twice-full rule, fully-specified version avoid-move-twice
rule (of Figure 6, reprinted convenience). avoid-move-twice-full rule
complex less natural specify avoid-move-twice. But, importantly,
avoid-move-twice-full making commitments avoid-move-twice. particular, avoid-move-twice-full fixes producer (clear ?b1) ?n3 ?n4
?n7 also known valid candidate. general, several alternative producers
precondition replacement subplan, consequently many possible embeddings.
different fully-specified rule needed capture embedding. number rules
grows exponentially permutations embeddings enumerated. However,
using partial-specification approach express general plan transformation
single natural rule.
(define-rule :name avoid-move-twice-full
:if (:operators ((?n1 (unstack ?b1 ?b2))
(?n2 (stack ?b1 ?b3 Table)))
:links ((?n4 (clear ?b1) ?n1)
(?n5 (on ?b1 ?b2) ?n1)
(?n1 (clear ?b2) ?n6)
(?n1 (on ?b1 Table) ?n2)
(?n7 (clear ?b1) ?n2)
(?n8 (clear ?b3) ?n2)
(?n2 (on ?b1 ?b3) ?n9))
:constraints ((possibly-adjacent ?n1 ?n2)
(:neq ?b2 ?b3)))
:replace (:operators (?n1 ?n2))
:with (:operators ((?n3 (stack ?b1 ?b3 ?b2)))
:links ((?n4 (clear ?b1) ?n3)
(?n8 (clear ?b3) ?n3)
(?n5 (on ?b1 ?b2) ?n3)
(?n3 (on ?b1 ?b3) ?n9))))

(define-rule :name avoid-move-twice
:if (:operators
((?n1 (unstack ?b1 ?b2))
(?n2 (stack ?b1 ?b3 Table)))
:links (?n1 (on ?b1 Table) ?n2)
:constraints
((possibly-adjacent ?n1 ?n2)
(:neq ?b2 ?b3)))
:replace (:operators (?n1 ?n2))
:with (:operators
(?n3 (stack ?b1 ?b3 ?b2))))

Figure 12: Fully-specified versus Partially-specified Rewriting Rule
summary, main advantage full-specification rules rewriting
performed efficiently embedding consequent already specified.
disadvantages number rules represent generic plan transformation
may large resulting rules quite lengthy; problems may decrease
221

fiAmbite & Knoblock

performance match algorithm. Also, rule specification error prone written
user. Conversely, main advantage partial-specification rules single
rule represent complex plan transformation naturally concisely. rule
cover large number plan structures even may occasionally fail. Also, partial
specification rules much easier specify understand users system.
seen, PbR provides high degree flexibility defining plan-rewriting rules.
3.1.3 Plan-Rewriting Algorithm
section, first describe basic plan-rewriting algorithm PbR. Second,
prove algorithm sound discuss formal properties rewriting. Finally,
discuss family algorithms plan rewriting depending parameters
language defining plan operators, specification language rewriting rules,
requirements search method.
plan-rewriting algorithm shown Figure 13. algorithm takes two inputs:
valid plan P , rewriting rule R = (qm , pr , pc ) (qm antecedent query, pr
replaced subplan, pc replacement subplan). output valid rewritten
plan P 0 . matching antecedent rewriting rule (qm ) determines rule
applicable identifies steps links interest (line 1). matching seen
subgraph isomorphism antecedent subplan current plan (with
results filtered applying :constraints). However, take different approach.
PbR implements rule matching conjunctive query evaluation. implementation keeps
relational representation steps links current plan similar node
link specifications rewriting rules. example, database plan
Figure 4 contains one table unstack steps schema (?n1 ?b1 ?b2) tuples
(4 C A) (5 B D), another table causal links involving clear condition
schema (?n1 ?n2 ?b) tuples (0 1 C), (0 2 B), (0 2 C), (0 3 B), (0 4 C), (0 5 B), (4
3 A) (5 1 D), similar tables operator link types. match
process consists interpreting rule antecedent conjunctive query interpreted
predicates, executing query relational view plan structures.
running example, analyze application avoid-move-twice rule Figure 6
plan Figure 4. Matching rule antecedent identifies steps 1 4.
precisely, considering antecedent query, result single tuple (4 C 1 D)
variables (?n1 ?b1 ?b2 ?n2 ?b3).
choosing match work (line 3), algorithm instantiates subplan
specified :replace field (pr ) according match (line 4) removes
instantiated subplan pir original plan P (line 5). edges incoming
emanating nodes replaced subplan also removed. effects
replaced plan pir achieving remainder plan (P pir ), UsefulEffects pir ,
achieved replacement subplan (or steps P pir ). order
facilitate process, AddFlaws procedure records effects open conditions.10
10. POCL planners operate keeping track repairing flaws found partial plan. Open conditions, operator threats, resource threats collectively called flaws (Penberthy & Weld, 1992).
AddFlaws(F,P) adds set flaws F plan structure P .

222

fiPlanning Rewriting

procedure RewritePlan
Input: valid partial-order plan P
rewriting rule R = (qm , pr , pc ), V ariables(pr ) V ariables(qm )
Output: valid rewritten partial-order plan P 0 (or failure)
1. := atch(qm , P )
Match rule antecedent qm (:if field) P . result set substitutions
= {..., , ...} variables qm .
2. = return failure
3. Choose match
4. pir := pr
Instantiate subplan removed pr (the :replace field) according .
5. Pri := AddFlaws(UsefulEffects(pir ), P pir )
Remove instantiated subplan pir plan P add UsefulEffects pir
open conditions. resulting plan Pri incomplete.
6. pic := pc
Instantiate replacement subplan pc (the :with field) according .
7. Pci := AddF laws(P reconditions(pic ) F indT hreats(Pri pic ), Pri pic )
Add instantiated replacement subplan pic Pri . Find new threats open
conditions add flaws. Pci potentially incomplete, several flaws
need resolved.
8. P 0 := rP OP (Pci )
Complete plan using partial-order causal-link planning algorithm (restricted
step reuse, step addition) order resolve threats open conditions.
rP OP returns failure valid plan found.
9. Return P 0
Figure 13: Plan-Rewriting Algorithm
result partial plan Pri (line 5). Continuing example, Figure 14(a) shows
plan resulting removing steps 1 4 plan Figure 4.
Finally, algorithm embeds instantiated replacement subplan pic remainder original plan (lines 6-9). rule completely specified, algorithm simply
adds (already instantiated) replacement subplan plan, work
necessary. rule partially specified, algorithm computes embeddings
replacement subplan remainder original plan three stages. First,
algorithm adds instantiated steps links replacement plan pic (line 6)
current partial plan Pri (line 7). Figure 14(b) shows state example
pic , new stack step (6), incorporated plan. Note open conditions
(clear A) on(C D). Second, FindThreats procedure computes possible threats,
operator threats resource conflicts, occurring Pri pic partial plan (line 7);
example, threat situation clear(C) proposition step 6 2 Figure 14(b). threats preconditions replacement plan pic recorded
AddFlaws resulting partial plan Pci . Finally, algorithm completes plan using
rPOP, partial-order causal-link planning procedure restricted reuse steps (i.e.,
223

fiAmbite & Knoblock

step addition) (line 8). rPOP allows us support expressive operator language
flexibility computing one embeddings. one rewriting needed,
rPOP stops first valid plan. Otherwise, continues exhausting alternative ways satisfying open preconditions resolving conflicts, produces valid
rewritings. running example, one embedding possible resulting plan
Figure 14(c), new stack step (6) produces (clear A) on(C D),
preconditions satisfied, ordering (6 2) ensures plan valid.
rewriting algorithm Figure 13 sound sense produces valid plan
input valid plan, outputs failure input plan cannot rewritten using
given rule. Since elementary plan-rewriting step sound, sequence rewritings
performed PbRs optimization search also sound.
Lemma 1 (Soundness rPOP) Partial-order causal-link (POCL) planning without
step addition (rP OP ) sound.
Proof: POCL planning, precondition step plan achieved either
inserting new step snew reusing step sreuse already present current plan (the
steps effect unifies precondition). Forbidding step addition decreases
set available steps used satisfy precondition, step found
rPOP proceeds general POCL. Since, POCL completion partial-plan sound
(Penberthy & Weld, 1992), rP OP also sound. 2
Theorem 1 (Soundness Plan Rewriting) RewritePlan (Figure 13) produces
valid plan input P valid plan, outputs failure input plan cannot
rewritten using given rewriting rule R = (qm , pr , pc ).
Proof: Assume plan P solution planning problem goals G initial
state I. POCL planning, plan valid iff preconditions steps supported
causal links (the goals G preconditions goal step, initial state
conditions effects initial step), operator threatens causal link
(McAllester & Rosenblitt, 1991; Penberthy & Weld, 1992).
rule R match plan P , algorithm trivially returns failure (line 2). Assuming
match , removing P steps links specified pir (including
links causal ordering incoming outgoing steps pir ), open
conditions exist resulting plan Pri pir achieving (line 5).
Adding instantiated replacement subplan pic introduces open conditions
partial plan: preconditions steps pic (line 7). sources
open conditions algorithm.
Since plan P valid initially, (operator and/or resource) threats present
plan Pci (line 7) caused removal subplan pir (line 3) addition
subplan pic (line 7). threats may occur operators causal links Pri pic
regardless whether operator causal link initially Pri pic . threats
combined plan Pri pic effectively computed finding relative positions
steps comparing causal link steps may ordered
producer consumer condition causal link (FindThreats, line 7).
point, shown plan (Pci ) flaws (threats
open conditions) explicitly recorded (by AddFlaws lines 5 7). Since rP OP sound
(Lemma 1), conclude rP OP complete Pci output valid plan P 0 , output
failure flaws plan cannot repaired. 2
224

fiPlanning Rewriting

clear(B)

REMOVED SUBPLAN

on(A Table)
on(C A)

Causal Link
Ordering Constraint
Side Effect

clear(A)

4 UNSTACK(C A)
on(C A)
clear(C)
on(D Table)

on(A Table)
clear(B)

3 STACK(A B Table)
on(C Table)
2 STACK(B C Table)

clear(C)
1 STACK(C Table)

0

on(B Table)
on(A B)
clear(C)
on(B C)
on(C D)
GOAL

clear(D)
clear(B)

on(C Table)

clear(D)



on(B D)

B

on(B Table)
5 UNSTACK(B D)
on(B D)
clear(B)

C

B

C







clear(C)
Initial State

Goal State

(a) Application Rewriting Rule: Removing Subplan
clear(B)

Causal Link
Ordering Constraint
Open conditions

on(A Table)

clear(A)
clear(C)
on(D Table)
0

on(C A)
clear(B)

3 STACK(A B Table)
on(B Table)
on(A B)
clear(C)
on(B C)

2 STACK(B C Table)
clear(C)

clear(A)

on(C A)
clear(D)

on(B D)

on(A Table)
clear(B)

on(C D)

6 STACK(C A)

on(C D)
clear(D)
on(C A)

GOAL


clear(D)

B

on(B Table)
5 UNSTACK(B D)
on(B D)

clear(B)

C

B

C







clear(C)
Initial State

Goal State

(b) Application Rewriting Rule: Adding Replacement Subplan
on(A Table)
clear(B)

on(A Table)

3 STACK(A B Table)

clear(B)
clear(A)

on(D Table)
on(C A)

2 STACK(B C Table)

clear(C)

0

6 STACK(C A)
clear(B)

on(B Table)
on(A B)
clear(C)
on(B C)
on(C D)
GOAL

clear(D)
on(C A)

clear(D)

Causal Link
Ordering Constraint
Side Effect

on(B D)
on(B Table)
5 UNSTACK(B D)
on(B D)
clear(B)


B

C

B

C







clear(C)
Initial State

Goal State

(c) Rewritten Plan
Figure 14: Plan Rewriting: Applying rule avoid-move-twice Figure 6 plan Figure 4
225

fiAmbite & Knoblock

Corollary 1 (Soundness PbR Search) optimization search PbR sound.
Proof: induction. Assume initial valid plan single step rewriting search.
Theorem 1, output either valid rewritten plan failure. output failure,
search trivially sound. Assume valid plan Pn1 n 1 rewriting steps.
According Theorem 1, applying single rewriting rule plan Pn1 produces valid
plan Pn failure. Thus, arbitrary number rewritings produces valid plan (or
plan), PbRs search sound. 2
Although RewritePlan sound, may certainly produce plans
minimal number steps faced arbitrary rules. example, imagine
consequent rewriting rule specified two identical steps s1 s2 (both
effects e1 e2) flaws Pci exactly open conditions e1 e2.
Then, sound non step-minimal plan would using s1 satisfy e1 using s2
satisfy e2 (although step could satisfy open conditions). PbR
discard plan make restriction types acceptable cost
functions. cost function took robustness plan account,
plan steps may desirable.
cannot guarantee PbRs optimization search complete sense
optimal plan would found. PbR uses local search well known that, general,
local search cannot complete. Even PbR exhaustively explores space plan
rewritings induced given initial plan set rewriting rules, still cannot prove
solution plans reached. property initial plan generator,
set rewriting rules, semantics planning domain. rewriting rules PbR
play similar role traditional declarative search control completeness
search may traded efficiency. Perhaps using techniques inferring invariants
planning domain (Gerevini & Schubert, 1998; Fox & Long, 1998; Rintanen, 2000) proving
convergence term graph rewriting systems (Baader & Nipkow, 1998), conditions
completeness plan-rewriting search given planning domain could obtained.
design plan-rewriting algorithm depends several parameters: language
operators, language rewriting rules, choice full-specification partialspecification rewriting rules, need rewritings one rewriting required
search method.
language operators affects way initial rewritten plans
constructed. framework supports expressive operator definition language described
Section 2.1. provide support language using standard techniques causal
link establishment threat checking like Sage (Knoblock, 1995) UCPOP
(Penberthy & Weld, 1992).
language antecedents rewriting rules affects efficiency matching.
system implements conjunctive query language described Section 3.1.1.
However, system could easily accommodate expressive query language
rule antecedent, relationally complete language (i.e., conjunction, disjunction,
safe negation) (Abiteboul, Hull, & Vianu, 1995), recursive language datalog
stratified negation, without significantly increasing computational complexity
approach important way, discuss Section 3.1.4.
choice fully versus partially specified rewriting rules affects way
replacement plan embedded current plan. rule completely specified,
226

fiPlanning Rewriting

embedding already specified rule consequent, replacement subplan
simply added current plan. rule partially specified, algorithm
compute valid embeddings.
choice one versus rewritings affects antecedent matching
embedding rule consequent. rule matches computed either
time, bottom-up evaluation logic databases, one-at-a-time Prolog, depending whether search strategy requires one rewritings. rule fully-specified
one embedding per match possible. But, rule partially-specified multiple
embeddings may result single match. search strategy requires one rewriting, must also provide mechanism choosing rule applied, match
computed, embedding generated (rPOP stop first embedding
compute embeddings). implemented rewriting algorithm modular design
support different combinations choices.
3.1.4 Complexity Plan Rewriting
complexity plan rewriting PbR originates two sources: matching rule
antecedent plan, computing embeddings replacement plan.
order analyze complexity matching plan-rewriting rules, introduce following
database-theoretic definitions complexity (Abiteboul et al., 1995):
Data Complexity: complexity evaluating fixed query variable database inputs.
Expression Complexity: complexity evaluating, fixed database instance,
queries specifiable given query language.
Data complexity measures complexity respect size database.
Expression complexity measures complexity respect size queries
(taken given language). case, database steps links plan
queries antecedents plan-rewriting rules.
Formally, language rule antecedents described Section 3.1.1 conjunctive
queries interpreted predicates. worst-case combined data expression complexity conjunctive queries exponential (Abiteboul et al., 1995). is, size
query (rule antecedent) size database (plan) grow simultaneously,
little hope matching efficiently. Fortunately, relationally-complete languages data
complexity contained Logarithmic Space, is, turn, contained Polynomial Time
(Abiteboul et al., 1995). Thus conjunctive query language complexity.
encouraging result shows cost evaluating fixed query grows
slowly database size increases. PbR means matching antecedent
rules strongly affected size plans. Moreover, experience
useful rule antecedents large contain many constant labels (at least,
node edge predicate names) help reduce size intermediate results
improve efficiency matching. result also indicates could extend
language antecedent relationally complete without affecting significantly
performance system.11 Another possible extension use datalog stratified
negation, also polynomial time data complexity. Graph-theoretic properties
11. Figure 32 Section 6 proposes example rule relationally-complete antecedent using
appropriate syntax.

227

fiAmbite & Knoblock

plans could easily described datalog. example, possibly-adjacent interpreted predicate Figure 7 could described declaratively datalog program instead
piece code. summary, rule match moderately sized rules, even quite expressive
languages large plans, remains tractable made efficient using production
match (Forgy, 1982) query optimization techniques (Sellis, 1988).
second source complexity computing embeddings replacement plan
given consequent plan-rewriting rule. definition full-specification rules,
embedding completely specified rule itself. Thus, suffices simply remove
undesired subplan directly add replacement subplan. linear size
consequent.
partial-specification rules, computing embeddings replacement subplan
exponential size plan worst case. However, occurs
pathological cases. example, consider plan Figure 15(a) going
compute embeddings step x remainder plan order satisfy open
precondition g0. Step x preconditions two effects b g0. step
plan proposition b effect. Therefore, new step x conflicts every step
plan (1 n) ordered respect steps. Unfortunately,
exponential number orderings. effect, orderings imposed adding step
x correspond partitions set steps (1 n) two sets: one ordered
x one after. Figure 15(b) shows one possible orderings. subplan
embedding contained several steps contained similar conflicts problem would
compounded. Even deciding single embedding exists NP-hard. example,
add two additional effects g1 operator x, valid embedding.
worst case (solving first flaws induced conflicts proposition b)
explore exponential number positions step x plan, end
failure. Nevertheless, given quasi-decomposability useful planning domains expect
number conflicts relatively small. Also useful rewriting rules specify
replacement subplans small compared plan embedding into.
experience indicates plan rewriting partial-specification rules performed
efficiently shown results Section 4.
b

b

1

1

g1





b

g1
b

2

2

g2
g0
b



0

g

0

g2


b

x

g

g0

x

g0



n

gn

gn



b

n

(a) embedding

b

(b) One possible embedding

Figure 15: Exponential Embeddings

228

fiPlanning Rewriting

3.1.5 Taxonomy Plan-Rewriting Rules
order guide user defining plan-rewriting rules domain help designing
algorithms may automatically deduce rules domain specification (see
Section 6), helpful know kinds rules useful. identified
following general types transformation rules:
Reorder: rules based algebraic properties operators, commutative, associative distributive laws. example, commutative rule reorders
two operators need resource Figure 10, join-swap rule Figure 29
combines commutative associative properties relational algebra.
Collapse: rules replace subplan smaller subplan. example,
several operators replaced one, remote-join-eval rule Figure 29.
rule replaces two remote retrievals information source local join
operation single remote join operation, remote source capability
performing joins. example application rule query plan shown
Figure 30. examples Blocks World rules Figure 6 replace unstack
stack operators either equivalent single stack operator empty plan.
Expand: rules replace subplan bigger subplan. Although may
appear counter-intuitive initially, easy imagine situation expensive
operator replaced set operators cheaper whole. interesting
case operators already present plan synergistically reused. find rule type domains analyzed far, Backstrom
(1994a) presents framework adding actions improves quality plans.
quality metric plan execution time, similarly manufacturing domain Section 4.1. Figure 16 shows example planning domain adding actions improves
quality (from Backstrom, 1994a). example, removing link Bm C1
inserting new action shortens significantly time execute plan.
P

Rn1

R1

R0


C1

C1
R0

P

P

Q1

Qm

B1

Rn
Cn

P

Rn
Cn

P
Q1

Rn1

R1

R0


B1

Bm

Bm Qm

Qm1

Qm1

(a) Low Quality Plan

(b) High Quality Plan

Figure 16: Adding Actions Improve Quality
Parallelize: rules replace subplan equivalent alternative subplan
requires fewer ordering constraints. typical case redundant alternative resources operators use. example, rule punch-by-drill-press
Figure 7. Another example rule Figure 16 suggests could seen
combination expand parallelize types.
229

fiAmbite & Knoblock

3.2 Selection Next Plan: Search Strategies
Although space rewritings explored systematically, Planning Rewriting
framework better suited local search techniques typical combinatorial optimization algorithms. characteristics planning domain, initial plan generator,
rewriting rules determine local search method performs best. First, discuss
initial plan generator affects choice local search methods. Second, consider impact rewriting rules. Third, discuss role domain knowledge
search process. Finally, describe several local search methods work PbR.
important difference PbR traditional combinatorial algorithms
generation feasible solutions. Usually, combinatorial optimization problems exists
effective procedure generate feasible solutions (e.g., permutations schedule).
Thus, even local search graph disconnected, choosing appropriate initial
solution generator (e.g., random) could fall component graph contains
global optimum. PbR cannot assume powerful initial plan generators. Even
optimization domains, efficient initial plan generators, may
guarantees coverage solution space provide. Therefore, optimal plan
may reachable applying rewriting rules starting initial plans
available generator. Nevertheless, many domains initial plan generator
provides good sample solution space sufficient multiple-restart search methods
escape low-quality local minima provide high-quality solutions.
plan-rewriting rules define neighborhood function, may exact (cf.
Section 2.3) not. example, query planning domain define set
rules completely generate space solution plans (because properties
relational algebra). domains may hard prove exact set
rules. limitations initial plan generation plan-rewriting rules affect
possibility theoretically reaching global optimum. surprising since many
problems, regardless whether cast planning formalisms,
converging local search algorithms (e.g., Papadimitriou & Steiglitz, 1977). Nevertheless,
practice, good local optima still obtained many domains.
Many local search methods, first best improvement, simulated annealing,
tabu search, variable-depth search, applied straightforwardly PbR.
experiments Section 4 used first best improvement, performed
well. Next, describe details application two methods PbR.
Section 6, discuss ideas using variable-depth plan rewriting.
First improvement generates rewritings incrementally selects first plan
better cost current one. order implement method efficiently use
tuple-at-a-time evaluation rule antecedent, similarly behavior Prolog. Then,
rule instantiation, generate one embedding, test cost resulting plan,
better current plan, repeat. choice generating another
embedding rule instantiation, generate another instantiation rule,
generate match different rule.
Best improvement generates complete set rewritten plans selects best.
method requires computing matches embeddings match.
matches obtained evaluating rule antecedent set-at-a-time database
230

fiPlanning Rewriting

query. discussed Section 3.1.4 query evaluation quite efficient.
experience, computing plan embeddings usually expensive computing
rule matches.
Planning Rewriting choice initial plan generator, rewriting rules,
search methods intertwined. initial plan generator fixed, determines
shape plans would modified rewriting rules, according
neighborhood, appropriate search mechanism chosen. PbR
modular design facilitate experimentation different initial plan generators, sets
rewriting rules, search strategies.
3.3 Plan Quality
practical planning domains quality plans crucial. one
motivations Planning Rewriting approach. PbR user defines measure
plan quality appropriate application domain. quality metric could
range simple domain-independent cost metric, number steps,
complex domain-specific ones. example, query planning domain measure
plan quality usually estimation query execution cost based size
database relations, data manipulation operations involved answering query,
cost network transfer. decentralized environment, cost metric may involve
actual monetary costs information sources require payments. jobshop scheduling domain simple cost functions schedule length (that is,
parallel time finish pieces), sum times finish piece.
sophisticated manufacturing domain may include variety concerns cost,
reliability, precision operator/process, costs resources materials used
operators, utilization machines, etc. reader find detailed
examples quality metrics domains Sections 4.1 4.4.
significant advantage PbR complete plan available assess quality.
generative planners complete plan available search solution
completed, usually simple plan quality metrics, number steps,
used. work incorporate quality concerns generative planners (Estlin
& Mooney, 1997; Borrajo & Veloso, 1997; Perez, 1996). systems automatically
learn search control rules improve efficiency planning quality
resulting plans. PbR rewriting rules seen post facto optimization search
control. opposed guiding search generative planner towards high-quality
solutions based information available partial plans, PbR improves quality
complete solution plans without restriction types quality metrics. Moreover,
plan cost additive, plan refinement strategy impractical since may need
exhaustively explore search space find optimal plan. example nonadditive cost function appears UNIX planning domain (Etzioni & Weld, 1994)
plan transfer files two machines may cheaper files compressed
initially (and uncompressed arrival). is, plan includes compression
(and necessary uncompression) operations cost effective, plan refinement
search would naturally lead it. using complete plans, PbR accurately assess
arbitrary measures quality.
231

fiAmbite & Knoblock

3.4 Initial Plan Generation
Fast initial plan generation domain-specific nature. requires user specify
efficient mechanism compute initial solution plan. general, generating initial
plan may hard generating optimal plan. However, crucial intuition behind
planning algorithms practical problems quasi-decomposable (Simon, 1969),
is, interactions among parts problems limited. interactions
problem pervasive, 8-puzzle, operator-based representation algorithms classical planning little use. would behave search based
problem solver. Fortunately, many practical problems indeed quasi-decomposable.
intuition also suggests finding initial plan generators planning problems may
hard appears, system solve subproblems independently,
combine simplest way, example, concatenating solutions sequentially. Moreover, many circumstances problems may easily transformed
state minimizes interactions solving problem state much easier.
example, Blocks World state blocks table minimizes
interactions. simple design algorithm solves Blocks World problem
passing intermediate state. Using methods initial plan generator may
produce suboptimal initial plans reasonable planning cost.
ideas constructing initial plan generators embodied two general ways,
implemented system. first one bootstrap results
general purpose planning algorithm strong search control bias. second one
provide user convenient high-level facilities describe plan construction
algorithms programmatically.
3.4.1 Biased Generative Planners
variety ways control search generic planner. planners
accept search control rules, others accept heuristic functions, built-in search
control. present examples techniques.
general way efficiently constructing plans use domain-independent
generative planner accepts search control rules. example, Prodigy (Carbonell,
Knoblock, & Minton, 1991), UCPOP (Penberthy & Weld, 1992) Sage (Knoblock, 1995)
planners. setting type search providing strong bias means
search control rules, planner quickly generate valid, although possibly suboptimal,
initial plan. example, manufacturing domain (Minton, 1988a), analyzed
detail Section 4.1, depth-first search goal selection heuristic based abstraction
hierarchies (Knoblock, 1994a) quickly generates feasible plan, often quality
plan, defined time required manufacture objects, suboptimal.
TLPlan (Bacchus & Kabanza, 1995, 2000) efficient forward-chaining planner
uses search control expressed temporal logic. forward chaining complete
state available, much refined domain control knowledge specified.
preferred search strategy used TLPlan depth-first search, although finds plans
efficiently, plans may low quality. Note generative planner
explores partial sequences steps, cannot use sophisticated quality measures.
232

fiPlanning Rewriting

HSP (Bonet, Loerincs, & Geffner, 1997; Bonet & Geffner, 1999) forward search
planner performs variation heuristic search applied classical AI planning.
built-in heuristic function relaxed version planning problem: computes
number required steps reach goal disregarding negated effects operators.
metric computed efficiently. Despite simplicity heuristic
admissible, scales surprisingly well many domains. plans generated
according fixed heuristic function, planner cannot incorporate quality metric.
types planners quite efficient practice although often produce suboptimal plans. excellent candidates generate initial plans
subsequently optimized PbR.
3.4.2 Facilitating Algorithmic Plan Construction
many domains, simple domain-dependent approximation algorithms provide good
initial plans. example, query planning domain, system easily generate
initial query evaluation plans randomly (or greedily) parsing given query.
Blocks World also straightforward generate solution linear time using naive
algorithm: put blocks table build desired towers bottom up.
algorithm produces plans length worse twice optimal, makes
already good approximation algorithm. However, interest Blocks World
traditionally optimal solutions, NP-hard problem (Gupta & Nau, 1992).
system facilitates creation initial plans freeing user specifying detailed graph structure plan. user needs specify algorithm
produces sequence instantiated actions, is, action names ground
parameters action takes.12 example, (user-defined) naive algorithm
Blocks World domain described applied problem Figure 4 produces
sequence: unstack(C A), unstack(B D), stack(C Table), stack(B C Table),
stack(A B Table). Then, system automatically converts sequence actions
fully detailed partial-order plan using operator specification domain. resulting plan conforms internal data structures PbR uses. process includes
creating nodes fully detailed operators preconditions effects, adding
edges represent necessary causal links ordering constraints. Blocks
World example resulting plan Figure 4.
algorithm transforms user-defined sequence actions partial-order
plan presented Figure 17. algorithm first constructs causal structure plan
(lines 2 6) adds necessary ordering links avoid threats (lines 7 10).
user needs specify action names corresponding instantiated action
parameters. algorithm consults operator specification find preconditions
effects, instantiate them, construct causal links, check operator threats.
Operator threats always resolved favor ordering given user input
plan. reason input plan may overconstrained total order,
assumed valid. Therefore, processing step last first, orderings
indeed avoid threats included partial-order plan.
12. algorithm also accepts extra ordering constraints addition sequence available
initial plan generator.

233

fiAmbite & Knoblock

procedure TO2PO
Input: valid total-order plan (a1 , ..., )
Output: equivalent partial-order plan
1. := n 1
2.
p Preconditions(ai )
3.
choose k <
4.
1. p PositiveEffects(ak )
5.
2. 6 l k < l < p NegativeEffects(al )
6.
add order ak ai
7.
p NegativeEffects(ai )
8.
j := (i 1) 1
9.
p Preconditions(aj )
10.
add order aj ai
11. return ((a1 , ..., ), )
Figure 17: Algorithm Converting Total-order Partial-order Plans
algorithm extension greedy algorithm presented Veloso, Perez, & Carbonell (1990). algorithm explores non-deterministically producers proposition (line 3), opposed taking latest producer sequence algorithm.13
is, algorithm explored exhaustively, produces partially-ordered causal
structures consistent input sequence. generalization stems criticism
Backstrom (1994b) algorithm Veloso et al. (1990) desire able
produce alternative initial plans.
problem transforming sequence steps least constrained plan analyzed
Backstrom (1994b) several natural definitions optimality. definitions
least-constrained plan shortest parallel execution problem NP-hard. Backstrom
shows Velosos algorithm, although polynomial, conform natural definitions. algorithm greedy, suffer drawbacks
pointed Backstrom. Moreover, purposes need optimal initial plans.
space partial orders explored rewriting process.
Regardless method producing initial plans, generators provide multiple
plans preferable. different initial plans used conjunction multiple restart
search techniques order escape low-quality local minima.

4. Empirical Results
section show broad applicability Planning Rewriting analyzing four
domains different characteristics: process manufacturing domain (Minton, 1988b),
transportation logistics domain, Blocks World domain used examples
throughout paper, domain distributed query planning.
13. implement algorithm enough replace line 3 Figure 17 with:
find max k <

234

fiPlanning Rewriting

4.1 Manufacturing Process Planning
task manufacturing process planning domain find plan manufacture
set parts. implemented PbR translation domain specification (Minton,
1988b). domain contains variety machines, lathe, punch, spray painter,
welder, etc, total ten machining operations. operator specification shown
Figures 18 19. features part described set predicates,
temperature, painted, has-hole, etc. features changed operators.
predicates state, has-clamp, is-drillable, etc, set initial state
problem.
example behavior operator, consider polish operator Figure 18.
requires part manufacture cold polisher clamp secure
part machine. effect applying operator leave surface
part polished. attributes part, surface-condition, single-valued,
others, like has-hole, multivalued. Note drill-press punch
operators Figure 18 prevent several has-hole conditions asserted
part. interesting operators weld bolt. operators join two
parts particular orientation form new part. operations performed
separate parts joined.
measure plan cost schedule length, (parallel) time manufacture
parts. domain machining operations assumed take unit time.
machines objects (parts) modeled resources order enforce one
part placed machine time machine operate single
part time (except bolt weld operate two parts simultaneously).
already shown types rewriting rules domain Figures 7
10. set rules used experiments shown Figure 20. top
eight rules quite straightforward one becomes familiar domain. two
top rules explore space alternative orderings originated resource conflicts.
machine-swap rule allows system explore possible orderings operations
require machine. rule finds two consecutive operations machine
swaps order. Similarly, rule object-swap allows system explore
orderings operations object. two rules use interpreted predicate
adjacent-in-critical-path focus attention steps contribute cost
function. Adjacent-in-critical-path checks two steps consecutive along one
critical paths schedule. critical path sequence steps take longest
time accomplish. words, critical path one sequences steps
determine schedule length.
next six rules exchange operators equivalent respect achieving
effects. Rules IP-by-SP SP-by-IP propose exchange immersion-paint
spray-paint operators. examining operator definitions Figure 19,
readily noticed operators change value painted predicate. Similarly,
PU-by-DP DP-by-PU exchange drill-press punch operators, produce
has-hole predicate. Finally, roll-by-lathe lathe-by-roll exchange roll lathe
operators make parts cylindrical. focus search promising
235

fiAmbite & Knoblock

(define (operator POLISH)
:parameters (?x)
:resources ((machine POLISHER) (is-object ?x))
:precondition (:and (is-object ?x)
(temperature ?x COLD)
(has-clamp POLISHER))
:effect
(:and (:forall (?surf)
(:when (:neq ?surf POLISHED)
(:not (surface-condition ?x ?surf)))
(surface-condition ?x POLISHED)))

(define (operator GRIND)
:parameters (?x)
:resources ((machine GRINDER) (is-object ?x))
:precondition (is-object ?x)
:effect
(:and (:forall (?color)
(:not (painted ?x ?color)))
(:forall (?surf)
(:when (:neq ?surf SMOOTH)
(:not (surface-condition ?x ?surf))))
(surface-condition ?x SMOOTH)))

(define (operator LATHE)
:parameters (?x)
:resources ((machine LATHE) (is-object ?x))
:precondition (is-object ?x)
:effect
(:and (:forall (?color)
(:not (painted ?x ?color)))
(:forall (?shape)
(:when (:neq ?shape CYLINDRICAL)
(:not (shape ?x ?shape))))
(:forall (?surf)
(:when (:neq ?surf ROUGH)
(:not (surface-condition ?x ?surf))))
(surface-condition ?x ROUGH)
(shape ?x CYLINDRICAL)))

(define (operator ROLL)
:parameters (?x)
:resources ((machine ROLLER) (is-object ?x))
:precondition (is-object ?x)
:effect
(:and (:forall (?color)
(:not (painted ?x ?color)))
(:forall (?shape)
(:when (:neq ?shape CYLINDRICAL)
(:not (shape ?x ?shape))))
(:forall (?temp)
(:when (:neq ?temp HOT)
(:not (temperature ?x ?temp))))
(:forall (?surf)
(:not (surface-condition ?x ?surf)))
(:forall (?width ?orientation)
(:not (has-hole ?x ?width ?orientation)))
(temperature ?x HOT)
(shape ?x CYLINDRICAL)))

(define (operator DRILL-PRESS)
:parameters (?x ?width ?orientation)
:resources ((machine DRILL-PRESS)
(is-object ?x))
:precondition
(:and (is-object ?x)
(have-bit ?width)
(is-drillable ?x ?orientation))
:effect (has-hole ?x ?width ?orientation))

(define (operator PUNCH)
:parameters (?x ?width ?orientation)
:resources ((machine PUNCH) (is-object ?x))
:precondition
(:and (is-object ?x)
(has-clamp PUNCH)
(is-punchable ?x ?width ?orientation))
:effect
(:and (:forall (?surf)
(:when (:neq ?surf ROUGH)
(:not (surface-condition ?x ?surf))))
(surface-condition ?x ROUGH)
(has-hole ?x ?width ?orientation)))

Figure 18: Operators Manufacturing Process Planning (I)

exchanges rules match operators critical path (by means interpreted
predicate in-critical-path).
six bottom rules Figure 20 sophisticated. lathe+SP-by-SP rule
takes care undesirable effect simple depth-first search used initial plan
generator. domain, order spray paint part, part must regular shape.
cylindrical regular shape, therefore initial planner may decide make
part cylindrical lathing order paint it! However, may necessary
part may already regular shape (for example, could rectangular, also
regular shape). Thus, lathe+SP-by-SP substitutes pair spray-paint lathe
single spray-paint operation. supporting regular-shapes interpreted predicate
236

fiPlanning Rewriting

(define (operator IMMERSION-PAINT)
:parameters (?x ?color)
:resources ((machine IMMERSION-PAINTER)
(is-object ?x))
:precondition
(:and (is-object ?x)
(have-paint-for-immersion ?color))
:effect (painted ?x ?color))

(define (operator SPRAY-PAINT)
:parameters (?x ?color ?shape)
:resources ((machine SPRAY-PAINTER)
(is-object ?x))
:precondition (:and (is-object ?x)
(sprayable ?color)
(temperature ?x COLD)
(regular-shape ?shape)
(shape ?x ?shape)
(has-clamp SPRAY-PAINTER))
:effect (painted ?x ?color))

(define (operator BOLT)
(define (operator WELD)
:parameters (?x ?y ?new-obj ?orient ?width)
:parameters (?x ?y ?new-obj ?orient)
:resources ((machine BOLTER)
:resources ((machine WELDER)
(is-object ?x) (is-object ?y))
(is-object ?x) (is-object ?y))
:precondition
:precondition
(:and (is-object ?x) (is-object ?y)
(:and (is-object ?x) (is-object ?y)
(composite-object ?new-obj ?orient ?x ?y)
(composite-object ?new-obj ?orient ?x ?y)
(has-hole ?x ?width ?orient)
(can-be-welded ?x ?y ?orient))
(has-hole ?y ?width ?orient)
:effect (:and (temperature ?new-obj HOT)
(bolt-width ?width)
(joined ?x ?y ?orient)
(can-be-bolted ?x ?y ?orient))
(:not (is-object ?x))
:effect (:and (:not (is-object ?x))
(:not (is-object ?y))))
(:not (is-object ?y))
(joined ?x ?y ?orient)))

Figure 19: Operators Manufacturing Process Planning (II)

enumerates regular shapes. rules partially specified
guaranteed always produce rewriting. Nevertheless, often successful
producing plans lower cost.
remaining rules explore bolting two parts using bolts different size fewer operations may needed plan. developed rules analyzing differences
quality optimal plans rewritten plans. example, consider
both-providers-diff-bolt rule. rule states parts bolted already
compatible holes them, better reuse operators produced
holes. initial plan generator may drilled (or punched) holes whose purpose
bolt parts. However, goal problem may already require holes
performed parts joined. Reusing available holes produces economical plan. rules has-hole-x-diff-bolt-add-PU, has-hole-x-diff-bolt-add-DP,
has-hole-y-diff-bolt-add-PU, has-hole-y-diff-bolt-add-DP address cases
one holes reused, thus additional punch drill-press
operation needs added.
illustration rewriting process manufacturing domain, consider Figure 21. plan top figure result simple initial plan generator
solves part independently concatenates corresponding subplans. Although
plan generated efficiently, poor quality. requires six time-steps manufacture parts. figure shows application two rewriting rules, machine-swap
IP-by-SP, improve quality plan. operators matched rule antecedent shown italics. operators introduced rule consequent shown
bold. First, machine-swap rule reorders punching operations parts B.
237

fiAmbite & Knoblock

(define-rule :name machine-swap
:if (:operators ((?n1 (machine ?x) :resource)
(?n2 (machine ?x) :resource))
:links ((?n1 :threat ?n2))
:constraints
(adjacent-in-critical-path ?n1 ?n2))
:replace (:links (?n1 ?n2))
:with (:links (?n2 ?n1)))

(define-rule :name object-swap
:if (:operators ((?n1 (is-object ?x) :resource)
(?n2 (is-object ?x) :resource))
:links ((?n1 :threat ?n2))
:constraints
(adjacent-in-critical-path ?n1 ?n2))
:replace (:links (?n1 ?n2))
:with (:links (?n2 ?n1)))

(define-rule :name SP-by-IP
(define-rule :name IP-by-SP
:if (:operators (?n1 (spray-paint ?x ?c ?s))
:if (:operators (?n1 (immersion-paint ?x ?c))
:constraints ((in-critical-path ?n1)))
:constraints ((regular-shapes ?s)
:replace (:operators (?n1))
(in-critical-path ?n1)))
:with (:operators (?n2 (immersion-paint ?x ?c))))
:replace (:operators (?n1))
:with (:operators (?n2 (spray-paint ?x ?c ?s))))
(define-rule :name DP-by-PU
(define-rule :name PU-by-DP
:if (:operators ((?n1 (drill-press ?x ?w ?o)))
:if (:operators (?n1 (punch ?x ?w ?o))
:constraints ((in-critical-path ?n1)))
:constraints ((in-critical-path ?n1)))
:replace (:operators (?n1))
:replace (:operators (?n1))
:with (:operators (?n2 (punch ?x ?w ?o))))
:with (:operators (?n2 (drill-press ?x ?w ?o))))
(define-rule :name roll-by-lathe
:if (:operators ((?n1 (roll ?x)))
:constraints ((in-critical-path ?n1)))
:replace (:operators (?n1))
:with (:operators (?n2 (lathe ?x))))

(define-rule :name lathe-by-roll
:if (:operators ((?n1 (lathe ?x)))
:constraints ((in-critical-path ?n1)))
:replace (:operators (?n1))
:with (:operators (?n2 (roll ?x))))

(define-rule :name both-providers-diff-bolt
(define-rule :name lathe+SP-by-SP
:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1)))
:if (:operators
:links ((?n1 (has-hole ?x ?w1 ?o) ?n3)
((?n1 (lathe ?x))
(?n2 (has-hole ?y ?w1 ?o) ?n3)
(?n2 (spray-paint ?x ?color ?shape1)))
(?n4 (has-hole ?x ?w2 ?o) ?n5)
:constraints ((regular-shapes ?shape2)))
(?n6 (has-hole ?y ?w2 ?o) ?n7))
:replace (:operators (?n1 ?n2))
:constraints ((:neq ?w1 ?w2)))
:with (:operators
((?n3 (spray-paint ?x ?color ?shape2))))) :replace (:operators (?n1 ?n2 ?n3))
:with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2)))
:links ((?n4 (has-hole ?x ?w2 ?o) ?n8)
(?n6 (has-hole ?y ?w2 ?o) ?n8))))
(define-rule :name has-hole-x-diff-bolt-add-DP
(define-rule :name has-hole-x-diff-bolt-add-PU
:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1)))
:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1)))
:links ((?n1 (has-hole ?x ?w1 ?o) ?n3)
:links ((?n1 (has-hole ?x ?w1 ?o) ?n3)
(?n2 (has-hole ?y ?w1 ?o) ?n3)
(?n2 (has-hole ?y ?w1 ?o) ?n3)
(?n4 (has-hole ?x ?w2 ?o) ?n5))
(?n4 (has-hole ?x ?w2 ?o) ?n5))
:constraints ((:neq ?w1 ?w2)))
:constraints ((:neq ?w1 ?w2)))
:replace (:operators (?n1 ?n2 ?n3))
:replace (:operators (?n1 ?n2 ?n3))
:with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2))
:with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2))
(?n6 (drill-press ?y ?w2 ?o)))
(?n6 (punch ?y ?w2 ?o)))
:links ((?n4 (has-hole ?x ?w2 ?o) ?n8)
:links ((?n4 (has-hole ?x ?w2 ?o) ?n8)
(?n6 (has-hole ?y ?w2 ?o) ?n8))))
(?n6 (has-hole ?y ?w2 ?o) ?n8))))
(define-rule :name has-hole-y-diff-bolt-add-DP
(define-rule :name has-hole-y-diff-bolt-add-PU
:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1)))
:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1)))
:links ((?n1 (has-hole ?x ?w1 ?o) ?n3)
:links ((?n1 (has-hole ?x ?w1 ?o) ?n3)
(?n2 (has-hole ?y ?w1 ?o) ?n3)
(?n2 (has-hole ?y ?w1 ?o) ?n3)
(?n6 (has-hole ?y ?w2 ?o) ?n7))
(?n6 (has-hole ?y ?w2 ?o) ?n7))
:constraints ((:neq ?w1 ?w2)))
:constraints ((:neq ?w1 ?w2)))
:replace (:operators (?n1 ?n2 ?n3))
:replace (:operators (?n1 ?n2 ?n3))
:with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2))
:with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2))
(?n4 (drill-press ?x ?w2 ?o)))
(?n4 (punch ?x ?w2 ?o)))
:links ((?n4 (has-hole ?x ?w2 ?o) ?n8)
:links ((?n4 (has-hole ?x ?w2 ?o) ?n8)
(?n6 (has-hole ?y ?w2 ?o) ?n8))))
(?n6 (has-hole ?y ?w2 ?o) ?n8))))

Figure 20: Rewriting Rules Manufacturing Process Planning
238

fiPlanning Rewriting

Lathe

IPaint Red

Punch 2

Punch C 1

IPaint C Blue

Roll B

IPaint B Red

Reorder Parts Machine
Lathe

IPaint Red
Punch C 1

Cost: 6

Punch 2

Cost: 4

IPaint C Blue

IPaint B Red

Roll B

Immersion-Paint => Spray-Paint
Lathe
Roll B

IPaint Red

Punch 2

Punch C 1

IPaint C Blue

Cost: 3

Spray-Paint B Red

Figure 21: Rewriting Manufacturing Domain
breaks long critical path resulted simple concatenation respective
subplans. schedule length improves six four time-steps. Still, three parts
A, B, C use painting operation (immersion-paint). immersion-painter
process one piece time, three operations must done serially. Fortunately, domain another painting operation: spray-paint. IP-by-SP
rule takes advantage fact substitutes immersion-paint operation part B
spray-paint operation. parallelizes plan obtaining schedule length
three time-steps, optimal plan.
compare four planners (IPP, Initial, two configurations PbR):
IPP: one efficient domain-independent planners (Koehler, Nebel, Hoffman, & Dimopoulos, 1997) planning competition held Fourth International
Conference Artificial Intelligence Planning Systems (AIPS-98). IPP optimized reimplementation extension Graphplan (Blum & Furst, 1995, 1997). IPP produces
shortest parallel plans. manufacturing domain, exactly schedule length,
cost function optimizing.
Initial: initial plan generator uses divide-and-conquer heuristic order generate
plans fast possible. First, produces subplans part joined goals
independently. subplans generated Sage using depth-first search without
regard plan cost. Then, concatenates subsequences actions merges
using facilities Section 3.4.2.
PbR: present results two configurations PbR, refer PbR-100
PbR-300. configurations use first improvement gradient search strategy
random walk cost plateaus. rewriting rules used Figure 20.
problem PbR starts search plan generated Initial. two configurations
differ many total plateau plans allowed. PbR-100 allows considering
100 plans improve cost without terminating search. Similarly, PbR239

fiAmbite & Knoblock

300 allows 300 plateau plans. Note limit across plateaus encountered
search problem, plateau.
tested four systems 200 problems, machining 10 parts, ranging
5 50 goals. goals distributed randomly 10 parts. So, 50goal problems, average 5 goals per part. results shown Figure 22.
graphs data point average 20 problems given number goals.
10 provably unsolvable problems. Initial PbR solved 200 problems (or
proved unsolvable). IPP solved 65 problems total: problems 5 10 goals,
19 15 goals, 6 20 goals. IPP could solve problem 20 goals
1000 CPU seconds time limit.
Figure 22(a) shows average time solvable problems problem set
four planners. Figure 22(b) shows average schedule length problems solved
planners, is, 65 problems solved IPP 20 goals.
fastest planner Initial, produces plans cost twice optimal. IPP
produces optimal plans, cannot solve problems 20 goals. two
configurations PbR scale much better IPP solving problems producing good
quality plans. PbR-300 matches optimal cost IPP plans, except one problem
(the reason difference interesting explain below). faster PbR-100
also stays close optimal (less 2.5% average cost difference).
Figure 22(c) shows average schedule length problems solved
planners 50 goal range. PbR configurations scale gracefully across
range improving considerably cost plans generated Initial. additional
exploration PbR-300 allows improve plans even further. reason
difference PbR IPP 20-goal complexity level cost results
IPP 6 problems could solve, results PbR Initial
average 20 problems (as shown Figure 22(b), PbR matches cost
6 optimal plans produced IPP).
Figure 22(d) shows average number operators plans problems solved
three planners (up 20 goals). Figure 22(e) shows average number operators
plans problems solved planner across whole range 50 problems.
plans generated Initial use 2-3 additional operators. PbR IPP
produce plans require fewer steps. Interestingly, IPP sometimes produces plans
use operations PbR. IPP produces shortest parallel plan, one
minimum number steps. particular, observed IPP plans
suffer problem Initial. IPP would also lathe part order paint
it, opposed Initial would affect optimal schedule
length. Surprisingly, adding additional steps domain may improve schedule
length, albeit fairly rare situations. case problem IPP
produced better schedule PbR-300. could introduced rewriting rule
substituted immersion-paint operator lathe spray-paint operators
cases. However, rule low utility (in sense Minton, 1988b).
expands rewriting search space, adds cost match, random
search provides benefit rarely.
240

fiPlanning Rewriting

Average Planning Time (CPU Seconds)

1000
PbR-FI
Initial
IPP

100

10

1

0.1

0.01
0

10

20

30

40
50
60
70
Number Blocks

80

90

100

(a) Average Planning Time
40

Average Plan Cost (Schedule Length)

Average Plan Cost (Schedule Length)

9
PbR-300
PbR-100
Initial
IPP

8
7
6
5
4
3
2

(b)

6

8

10
12
14
Number Goals

16

18

30
25
20
15
10
5

20

5

Average Plan Cost
(Problems Solved All)

(c)

24

10

15

20
25
30
35
Number Goals

40

45

50

Average Plan Cost
(Problems Solved Each)

60

22

PbR-300
PbR-100
Initial
IPP

20

Average Number Plan Operators

Average Number Plan Operators

PbR-300
PbR-100
Initial
IPP

0
4

18
16
14
12
10
8
6
4

55
50
45
40
35

PbR-300
PbR-100
Initial
IPP

30
25
20
15
10
5

4

(d)

35

6

8

10
12
14
Number Goals

16

18

20

5

Number Plan Operators
(Problems Solved All)

(e)

10

15

20
25
30
35
Number Goals

Number Plan Operators
(Problems Solved Each)

Figure 22: Experimental Results: Manufacturing Process Planning

241

40

45

50

fiAmbite & Knoblock

experiment illustrates flexibility PbR specifying complex rules planning domain. results show benefits finding suboptimal initial plan quickly
efficiently transforming improve quality.
4.2 Logistics
task logistics domain transport several packages initial location
desired destinations. used version logistics-strips planning domain
AIPS98 planning competition restricted using trucks planes.14
domain shown Figure 23. package transported one location another
loading truck, driving truck destination, unloading truck.
truck load number packages. cost function (parallel) time deliver
packages (measured number operators critical path plan).
(define (operator LOAD-TRUCK)
:parameters (?obj ?truck ?loc)
:precondition
(:and (obj ?obj) (truck ?truck) (location ?loc)
(at ?truck ?loc) (at ?obj ?loc))
:effect (:and (:not (at ?obj ?loc))
(in ?obj ?truck)))

(define (operator UNLOAD-TRUCK)
:parameters (?obj ?truck ?loc)
:precondition
(:and (obj ?obj) (truck ?truck) (location ?loc)
(at ?truck ?loc) (in ?obj ?truck))
:effect (:and (:not (in ?obj ?truck))
(at ?obj ?loc)))

(define (operator DRIVE-TRUCK)
:parameters (?truck ?loc-from ?loc-to ?city)
:precondition (:and (truck ?truck) (location ?loc-from) (location ?loc-to) (city ?city)
(at ?truck ?loc-from) (in-city ?loc-from ?city) (in-city ?loc-to ?city))
:effect (:and (:not (at ?truck ?loc-from)) (at ?truck ?loc-to)))

Figure 23: Operators Logistics
compare three planners domain:
IPP:

IPP (Koehler et al., 1997) produces optimal plans domain.

Initial: initial plan generator picks distinguished location delivers packages
one one starting returning distinguished location. example, assume
truck t1 distinguished location l1, package p1 must delivered location
l2 location l3. plan would be: drive-truck(t1 l1 l2 c), load-truck(p1 t1 l2),
drive-truck(t1 l2 l3 c), unload-truck(p1 t1 l3), drive-truck(t1 l3 l1 c).
initial plan generator would keep producing circular trips remaining packages.
Although algorithm efficient produces plans low quality.
PbR: PbR starts plan produced Initial uses plan rewriting rules shown
Figure 24 optimize plan quality. loop rule states driving location
returning back immediately useless. fact operators must adjacent
important implies intervening load unload performed.
vein, triangle rule states better drive directly two
locations third point operation performed point.
14. logistics domain AIPS98, problems moving packages plane among different cities
truck among different locations city isomorphic, focused one better
analyze rewriting rules learned (Ambite, Knoblock, & Minton, 2000).

242

fiPlanning Rewriting

load-earlier rule captures situation package loaded truck
first time packages location visited. occurs initial planner
concerned trip another package. unload-later rule captures dual case.
PbR applies first improvement search strategy one run (no restarts).
(define-rule :name loop
:if (:operators
((?n1 (drive-truck ?t ?l1 ?l2 ?c))
(?n2 (drive-truck ?t ?l2 ?l1 ?c)))
:links ((?n1 ?n2))
:constraints
((adjacent-in-critical-path ?n1 ?n2)))
:replace (:operators (?n1 ?n2))
:with NIL)

(define-rule :name triangle
:if (:operators
((?n1 (drive-truck ?t ?l1 ?l2 ?c))
(?n2 (drive-truck ?t ?l2 ?l3 ?c)))
:links ((?n1 ?n2))
:constraints
((adjacent-in-critical-path ?n1 ?n2)))
:replace (:operators (?n1 ?n2))
:with (:operators
((?n3 (drive-truck ?t ?l1 ?l3 ?c)))))

(define-rule :name unload-later
(define-rule :name load-earlier
:if (:operators
:if (:operators
((?n1 (drive-truck ?t ?l1 ?l2 ?c))
((?n1 (drive-truck ?t ?l1 ?l2 ?c))
(?n2 (unload-truck ?p ?t ?l2))
(?n2 (drive-truck ?t ?l3 ?l2 ?c))
(?n3 (drive-truck ?t ?l3 ?l2 ?c)))
(?n3 (load-truck ?p ?t ?l2)))
:links ((?n1 ?n2))
:links ((?n2 ?n3))
:constraints
:constraints
((adjacent-in-critical-path ?n1 ?n2)
((adjacent-in-critical-path ?n2 ?n3)
(before ?n2 ?n3)))
(before ?n1 ?n2)))
:replace (:operators (?n2))
:replace (:operators (?n3))
:with (:operators ((?n4 (unload-truck ?p ?t ?l2)))
:with (:operators ((?n4 (load-truck ?p ?t ?l2)))
:links ((?n3 ?n4))))
:links ((?n1 ?n4))))

Figure 24: Logistics Rewriting Rules

250

PbR
Initial
IPP

1000

PbR
Initial
IPP

200

Average Plan Cost

Average Planning Time (CPU Seconds)

10000

100
10
1

150

100

50

0.1
0.01

0
0

5

10

15 20 25 30 35
Number Packages

40

45

50

0

(a) Average Planning Time

5

10

15

20
25
30
35
Number Packages

40

45

50

(b) Average Plan Cost

Figure 25: Experimental Results: Logistics, Scaling Number Packages
compared performance IPP, Initial, PbR set logistics problems
involving 50 packages. problem instance number packages,
locations, goals. single truck single city. performance results
shown Figure 25. graphs data point average 20 problems
given number packages. problems satisfiable. IPP could solve
243

fiAmbite & Knoblock

problems 7 packages (it also solved 10 20 8 packages, 1 20
9 packages, shown figure). Figure 25(a) shows average
planning time. Figure 25(b) shows average cost 50 packages range. results
similar previous experiment. Initial efficient highly suboptimal. PbR
able considerably improve cost plans approach optimal.
4.3 Blocks World
implemented classical Blocks World domain two operators Figure 2.
domain two actions: stack puts one block top another, and, unstack
places block table start new tower. Plan quality domain simply
number steps. Optimal planning domain NP-hard (Gupta & Nau, 1992).
However, trivial generate correct, suboptimal, plan linear time using
naive algorithm: put blocks table build desired towers bottom
up. compare three planners domain:
IPP: experiment used GAM goal ordering heuristic (Koehler, 1998; Koehler
& Hoffmann, 2000) tested Blocks World problems good scaling results.
Initial: planner programmatic implementation naive algorithm using
facilities introduced Section 3.4.2.
PbR: configuration PbR starts plan produced Initial uses
two plan-rewriting rules shown Figure 6 optimize plan quality. PbR applies first
improvement strategy one run (no restarts).
generated random Blocks World problems scaling number blocks. problem
set consists 25 random problems 3, 6, 9, 12, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100
blocks total 350 problems. problems may multiple towers initial
state goal state.
Figure 26(a) shows average planning time 25 problems block quantity.
IPP cannot solve problems 20 blocks within time limit 1000 CPU
seconds. problem solving behavior IPP interesting. IPP either solved given
problem fast timed out. example, able solve 11 25 20block problems 100 seconds, timed 1000 seconds remaining 14
problems. seems typical behavior complete search algorithms (Gomes,
Selman, & Kautz, 1998). local search PbR allows scale much better solve
problems.
Figure 26(b) shows average plan cost number blocks increases. PbR
improves considerably quality initial plans. optimal quality known
small problems, PbR approximates it, achieve (we ran Sage
problems less 9 blocks). larger plans know optimal cost. However,
Slaney & Thiebaux (1996) performed extensive experimental analysis Blocks World
planning using domain like ours. comparison among different approximation
algorithms found initial plan generator (unstack-stack) achieves empirically
quality around 1.22 optimal range problem sizes analyzed (Figure 7
Slaney & Thiebaux, 1996). value average initial plans divided 1.22 suggests
244

fiPlanning Rewriting

quality optimal plans. quality achieved PbR comparable value.
fact slightly better may due relatively small number problems
tested (25 per block size) skew random problem generator. Interestingly
plans found IPP actually low quality. due fact IPP produces
shortest parallel plans. means plans constructed fewest time
steps, IPP may introduce actions time step required.
summary, experiments previous sections show across variety
domains PbR scales large problems still producing high-quality plans.
180

Average Plan Cost (Number Operators)

Average Planning Time (CPU Seconds)

1000
PbR-FI
Initial
IPP

100

10

1

0.1

0.01
0

10

20

30

40
50
60
70
Number Blocks

80

90

PbR-FI
Initial
IPP
Initial/1.22

160
140
120
100
80
60
40
20
0

100

0

(a) Average Planning Time

10

20

30

40 50 60 70
Number Blocks

80

90

100

(b) Average Plan Cost

Figure 26: Experimental Results: Blocks World, Scaling Number Blocks

4.4 Query Planning
Query Planning problem considerable practical importance. central traditional
database mediator systems. section present results distributed query
planning highlight use PbR domain complex cost function. detailed
description query planning, including novel query processing algorithm mediators
based PbR, extensive experimental analysis appear (Ambite & Knoblock,
2000; Ambite, 1998).
Query planning involves generating plan efficiently computes user query
relevant information sources. plan composed data retrieval actions distributed information sources data manipulation operations, relational algebra: join, selection, union, etc. specification operators query
planning encoding information goals using first introduced
Knoblock (1996). sample information goal shown Figure 27. goal asks send
output device mediator names airports Tunisia. Two sample
operators shown Figure 28. retrieve operator executes query remote
information source transports data mediator, provided source
operation (source-available) source capable processing query
(source-acceptable-query). join operator takes two subqueries, available
locally mediator, combines using conditions produce joined
query.
245

fiAmbite & Knoblock

(available sims (retrieve (?ap_name)
(:and (airport ?aport)
(country-name ?aport "Tunisia")
(port-name ?aport ?ap_name))))

Figure 27: Sample Information Goal
(define (operator retrieve)
:parameters (?source ?query)
:resources ((processor ?source))
:precondition (:and (source-available ?source)
(source-acceptable-query ?query ?source))
:effect (available sims ?query))
(define (operator join)
:parameters (?join-conds ?query ?query-a ?query-b)
:precondition (:and (available sims ?query-a
(available sims ?query-b)
(join-query ?query ?join-conds ?query-a ?query-b))
:effect (available sims ?query))

Figure 28: Query Planning Operators
quality distributed query plan estimation execution cost,
function size intermediate results, cost performing data manipulation
operations, transmission network intermediate results
remote sources mediator. system estimates plan cost based statistics
obtained source relations, number tuples relation, number
distinct values attribute, maximum minimum values numeric
attributes (Silberschatz, Korth, & Sudarshan, 1997, chapter 12). sources accessed,
type ordering data processing operations critical plan cost.
rewriting rules derived properties distributed environment
relational algebra.15 first set rules rely fact that, distributed environment,
generally efficient execute group operations together remote information source transmit data network execute operations
local system. example consider Remote-Join-Eval rule Figure 29 (shown
PbR syntax, shown algebraically Figure 1). rule specifies
plan exist two retrieval operations remote database whose results
consequently joined remote source capable performing joins, system
rewrite plan one contains single retrieve operation pushes join
remote database.
second class rules derived commutative, associative, distributive
properties operators relational algebra. example, Join-Swap rule
Figure 29 (cf. Figure 1) specifies two consecutive joins operators reordered
allows planner explore space join trees. Since query planning
15. mediators, rules address resolution semantic heterogeneity also necessary. See
(Ambite & Knoblock, 2000; Ambite, 1998) details.

246

fiPlanning Rewriting

(define-rule :name remote-join-eval
(define-rule :name join-swap
:if (:operators
:if (:operators
((?n1 (retrieve ?query1 ?source))
((?n1 (join ?q1 ?jc1 ?sq1a ?sq1b))
(?n2 (retrieve ?query2 ?source))
(?n2 (join ?q2 ?jc2 ?sq2a ?sq2b)))
(?n3 (join ?query ?jc ?query1 ?query2)))
:links (?n2 ?n1)
:constraints
:constraints
((capability ?source join)))
(join-swappable
:replace (:operators (?n1 ?n2 ?n3))
?q1 ?jc1 ?sq1a ?sq1b
;;
:with (:operators
?q2 ?jc2 ?sq2a ?sq2b
;;
((?n4 (retrieve ?query ?source))))
?q3 ?jc3 ?sq3a ?sq3b
;;
?q4 ?jc4 ?sq4a ?sq4b))
;;
:replace (:operators (?n1 ?n2))
:with (:operators
((?n3 (join ?q3 ?jc3 ?sq3a ?sq3b))
(?n4 (join ?q4 ?jc4 ?sq4a ?sq4b)))
:links (?n4 ?n3)))

Figure 29: Query Planning Rewriting Rules
domain queries expressed complex terms (Knoblock, 1996), PbR rules use
interpreted predicates :constraints field manipulate query expressions.
example, join-swappable predicate checks queries two join operators
exchanged computes new subqueries.
Figure 30 shows example local search space query plan rewritings simple distributed domain describes company. figure shows alternative
query evaluation plans conjunctive query asks names employees,
salaries, projects working on. three relations requested query
(Employees, Payroll, Project) distributed among two databases (one companys headquarters HQ-db another branch Branch-db). Assume
leftmost plan initial plan. plan first retrieves Employee relation HQ-db
Project relation Branch-db, joins two tables employee name. Finally, plan retrieves Payroll relation HQ-db joins
ssn result previous join. Although valid plan, initial plan suboptimal. Applying join-swap rule initial plan generates two rewritings. One
involves cross-product, expensive operation, system, following gradient descent search strategy, prefers plan. system applies
remote-join-eval rule generates new rewritten plan evaluates join
employee project tables remotely headquarters database. final plan
much better quality.
compare planning efficiency plan quality four query planners:
Sage: original query planner (Knoblock, 1995, 1996) SIMS mediator,
performs best-first search heuristic commonly used query optimization
explores space left join trees. Sage refinement planner (Kambhampati,
Knoblock, & Yang, 1995) generates optimal left-tree query plans.
DP: implementation dynamic-programming bottom-up enumeration
query plans (Ono & Lohman, 1990) find optimal plan. Since distributed
domain subqueries execute parallel cost function reflects preference,
247

fiAmbite & Knoblock

a(name sal proj) :- Emp(name ssn) ^ Payroll(ssn sal) ^ Projects(name proj)

HQ-db
Emp(name ssn)
Payroll(ssn sal)

name ssn

Branch-db
Project(name proj)

Ret Emp
@ HQ-db
Ret Payroll Ret Project
@ HQ-db @ Branch-db

ssn

name

Ret Payroll
@ HQ-db

Join
Swap

name

Remote
Join
Eval
name

Ret Emp Ret Project
@ HQ-db @ Branch-db

ssn

Ret Project
@ Branch-db

Ret Emp Ret Payroll
@ HQ-db @ HQ-db

Ret Project
@Branch-db
Ret (Emp
@HQ-db

Payroll)

Figure 30: Rewriting Query Planning
DP algorithm considers bushy join trees. However, improve planning time, DP
applies heuristic avoiding cross-products join enumeration. Thus, rare
cases DP may produce optimal plan.
Initial: initial plan generator PbR. generates query plans according
random depth-first search parse query. non-random choice places
selections soon executed. fastest planner may produce
low quality plans.
PbR: used Remote-Join-Eval Join-Swap rules defined Figure 29.
two rules sufficient optimize queries test set. tested two gradientdescent search strategies PbR: first improvement four random restarts (PbR-FI),
steepest descent three random restarts (PbR-SD).
experiment compare behavior Sage, DP, Initial, PbR-FI, PbR-SD
distributed query planning domain size queries increases. generated
synthetic domain SIMS mediator defined set conjunctive queries involving
1 30 relations. queries one selection attribute table.
information source contains two relations perform remote operations. Therefore,
optimal plans involve pushing operations evaluated remotely sources.
results experiment shown Figure 31. Figure 31(a) shows planning
time, logarithmic scale, Sage, DP, Initial, PbR-FI, PbR-SD query size
grows. times PbR include generation random initial plans
rewriting. times Initial average initial plan construction across
restarts query. Sage able solve queries involving 6 relations, larger
248

fiPlanning Rewriting

queries cannot solved within search limit 200,000 partial-plan nodes. DP scales
better Sage, cannot solve queries 9 relations 1000 second time
limit. configurations PbR scale better Sage DP. first-improvement
search strategy PbR-FI faster steepest descent PbR-SD.
Figure 31(b) shows cost query plans five planners. cost Initial
average initial plans across restarts query. plan cost
estimate query execution cost. logarithmic scale used increasingly
larger absolute values plan costs conjunctive chain queries high
cost initial plans. PbR rewrites poor quality plans generated Initial
high-quality plans. PbR DP produce better plans Sage (in range
tractable Sage) experiment. happens searching larger
space bushy query trees take greater advantage parallel execution plans. PbR
produces plans quality comparable DP tractable range beyond range
PbR scales gracefully. two configurations PbR produce plans similar cost, though
PbR-FI needed less planning time PbR-SD. PbR-SD generates plans local
neighborhood order select cheapest one, PbR-FI generates portion
neighborhood since chooses first plan cheaper cost, PbR-FI faster
average. Figure 31 shows empirically domain locally optimal moves
steepest descent translate final solutions better cost produced
first-improvement strategy.

1000

1e+18
Sage
DP
Initial
PbR-FI
PbR-SD

100

1e+14
1e+12

10

Plan Cost

Planning Time (CPU seconds)

1e+16

1
Sage
DP
Initial
PbR-FI
PbR-SD

0.1

1e+10
1e+08
1e+06
10000
100

0.01

1
0

5

10

15
Query Size

20

25

30

0

(a) Planning Time

5

10

15
Query Size

20

25

30

(b) Plan Quality

Figure 31: Experimental Results: Distributed Query Planning

5. Related Work
section review previous work related Planning Rewriting framework.
First, discuss work disciplines upon PbR builds, namely, classical AI
planning, local search, graph rewriting. Then, discuss work related planrewriting algorithm.
249

fiAmbite & Knoblock

5.1 AI Planning
PbR designed find balance among requirements planning efficiency, high quality
plans, flexibility, extensibility. great amount work AI Planning focused
improving average-case efficiency given general cases computationally hard
(Erol et al., 1995). One possibility incorporate domain knowledge form search
control. recent example TLPlan (Bacchus & Kabanza, 1995, 2000), forward-search
planner shown remarkable scalability using control knowledge expressed temporal logic. systems automatically learn search control given planning domain
even specific problem instances. Minton (1988b) shows deduce search control rules
problem solver applying explanation-based learning problem-solving traces.
also discusses impact utility problem. utility problem, simply stated, says
(computational) benefits using additional knowledge must outweigh cost
applying it. PbR plan-rewriting rules also subject utility problem. quality
improvement obtained adding rewriting rules PbR-based planner may
worth performance degradation. Another approach automatically generating search
control analyzing statically operators (Etzioni, 1993) inferring invariants
planning domain (Gerevini & Schubert, 1998; Fox & Long, 1998; Rintanen, 2000). Abstraction provides yet another form search control. Knoblock (1994a) presents system
automatically learns abstraction hierarchies planning domain particular problem
instance order speed planning. plan-rewriting rules learned techniques
analogous used learn search control. Ambite, Knoblock, & Minton (2000) present
approach automatically learn plan-rewriting rules based comparing initial
optimal plans example problems. Alternatively, analyzing planning operators
combinations operators equivalent respect achievement
goals also lead automatic generation rewriting rules.
Local search algorithms also used improve planning efficiency although
somewhat indirect way. Planning reduced solving series propositional
satisfiability problems (Kautz & Selman, 1992). Thus, Kautz & Selman (1996) used
efficient satisfiability testing algorithm based local search solve SAT encodings
planning problem. approach proved efficient specialized planning
algorithms. believe power approach stems use local search.
PbR directly applies local search plan structures, opposed translating first
larger propositional representation.
Although approaches improve efficiency planning, specifically address plan quality, else consider simple cost metrics (such
number steps). systems learn search control addresses planning efficiency
plan quality (Estlin & Mooney, 1997; Borrajo & Veloso, 1997; Perez, 1996). However,
reported experimental results, PbR appears scalable. Moreover, PbR
provides anytime algorithm approaches must run completion.
5.2 Local Search
Local search long tradition combinatorial optimization (Aarts & Lenstra, 1997;
Papadimitriou & Steiglitz, 1982). Local improvement ideas found application many
250

fiPlanning Rewriting

domains. general work relevant PbR constraint satisfaction,
scheduling, satisfiability testing, heuristic search.
constraint satisfaction, local search techniques able solve problems
orders magnitude complex respective complete (backtracking) approaches.
Minton et al. (Minton, Johnston, Philips, & Laird, 1990; Minton, 1992) developed simple
repair heuristic, min-conflicts, could solve large constraint satisfaction scheduling
problems, scheduling operations Hubble Space Telescope. minconflicts heuristic selects variable value assignment minimizes number
constraints violated. heuristic used cost function gradient-descent
search also informed backtracking search.
satisfiability testing similar method, GSAT, introduced Selman, Levesque,
& Mitchell (1992). GSAT solves hard satisfiability problems using local search
repairs consist changing truth value randomly chosen variable. cost function
number clauses satisfied current truth assignment. approach scales
much better corresponding complete method (the Davis-Putnam procedure).
work scheduling rescheduling, Zweben, Daun, & Deale (1994) define set
general, fixed, repair methods, use simulated annealing search space
schedules. plans networks actions opposed metric-time totally-ordered
tasks. Also easily specify different rewriting rules (general specific) suit
domain, opposed fixed strategies.
work inspired approaches several differences. First, PbR
operates complex graph structures (partial-order plans) opposed variable assignments. Second, repairs declaratively specified may changed problem
domain, opposed general fixed repair strategies. Third, PbR accepts arbitrary measures quality, constraint violations min-conflicts, number
unsatisfied clauses GSAT. Finally, PbR searches space valid solution plans,
opposed space variable assignments may internally inconsistent.
Iterative repair ideas also used heuristic search. Ratner & Pohl (1986)
present two-phase approach similar PbR. first phase, find initial valid
sequence operators using approximation algorithm. second phase, perform
local search starting initial sequence. cost function plan length.
local neighborhood generated identifying segments current solution sequence
attempting optimize them. repair consists heuristic search initial
state beginning segment goal end segment. shorter
path found, original sequence replaced new shorter segment. significant
difference PbR state-space search, PbR planspace search. least-committed partial-order nature PbR allows optimize
plans ways cannot achieved optimizing linear subsequences.
5.3 Graph Rewriting
PbR builds ideas graph rewriting (Schurr, 1997). plan-rewriting rules
PbR extension traditional graph rewriting rules. taking advantage
semantics planning PbR introduces partially-specified plan-rewriting rules,
rules need specify completely detailed embedding consequent pure
251

fiAmbite & Knoblock

graph rewriting. Nevertheless, several techniques transfer graph
rewriting Planning Rewriting, particularly fully-specified rules. Dorr (1995)
defines abstract machine graph isomorphism studies set conditions
traditional graph rewriting performed efficiently. Perhaps similar abstract
machine plan rewriting defined. idea rule programs also appears
field implemented PROGRES system (Schurr, 1990, 1997).
5.4 Plan Rewriting
work closely related plan-rewriting algorithm plan merging (Foulser, Li, &
Yang, 1992). Foulser et al. provide formal analysis algorithms exploiting positive
interactions within plan across set plans. However, work considers
case set operators replaced one operator provides
effects rest plan consumes fewer preconditions. focus
optimal approximate algorithms type operator merging. Plan rewriting
PbR seen generalization operator merging subplan replace
another subplan. difference PbR concerned finding optimal merge
(rewritten plan) single pass optimization algorithm approach does.
PbR interested generating possible plan rewritings rewriting phase,
optimal one. optimization occurs (local) search progresses.
Case-based planning (e.g., Kambhampati, 1992; Veloso, 1994; Nebel & Koehler, 1995;
Hanks & Weld, 1995; Munoz-Avila, 1998) solves problem modifying previous solution.
two phases case-based planning. first one identifies plan library
similar current problem. second phase previous plan adapted
solve new problem. PbR modifies solution current problem,
need retrieval phase associated similarity metrics. Plan rewriting PbR
seen type adaptation solution problem alternate solution
problem. is, plan rewriting rule PbR identifies pair subplans (the
replaced replacement subplans) may interchangeable.
Veloso (1994) describes general approach case-based planning based derivational
analogy. approach works three steps. First, retrieval phase selects similar
plan library. Second, parts plan irrelevant current problem
removed. Finally, system searches completion plan selecting much
possible decisions old plan did. sense planning knowledge
encoded previous solution transferred generation new solution plan.
plan-rewriting algorithm partially-specified rules PbR seen strongly
constrained version approach. PbR subplan rule consequent fixes
steps added repair plan. could use technique respecting
previous choice points completing plan way ensuring
structure plan repair maintained. could useful
constrain number rewritten plans large rewriting rules.
Nebel Koehler (1995) present computational analysis case-based planning.
context show worst-case complexity plan modification better
plan generation point limitations reuse methods. related problem
PbR framework embedding replacement subplan partially specified rules.
252

fiPlanning Rewriting

explained Section 3.1.4 may pathological cases number
embeddings exponential size plan deciding embedding exists
NP-hard. However, often interested finding rewritings, example
following first improvement search strategy. experience average case behavior
seems much better presented Section 4.
Systematic algorithms case-based planning (such Hanks & Weld, 1995) invert
decisions done refinement planning find path solution similar old
problem new problem. rewriting rules PbR indicate transform
solution another solution plan based domain knowledge, opposed generic
inversion refinement operations. Plan rewriting PbR done constrained
way instead open search space partial plans. However, rules
PBR may search space rewritings non systematically. effect ameliorated
using local search.

6. Discussion Future Work
paper presented Planning Rewriting, new paradigm efficient high-quality
domain-independent planning. PbR adapts graph rewriting local search techniques
semantics domain-independent partial-order planning. basic idea PbR
consists transforming easy-to-generate, possibly suboptimal, initial plan
high-quality plan applying declarative plan-rewriting rules iterative repair style.
several important advantages PbR planning approach. First, PbR
declarative domain-independent framework, brings benefits reusability
extensibility. Second, addresses sophisticated plan quality measures, work
domain-independent planning addressed quality simple ways.
Third, PbR scalable uses efficient local search methods. Finally, PbR
anytime planning algorithm allows balancing planning effort plan quality order
maximize utility planning process.
Planning Rewriting provides domain-independent framework local search. PbR
accepts declarative domain specifications expressive operator language, declarative
plan-rewriting rules generate neighborhood plan, complex quality metrics, interchangeable initial plan generators, arbitrary (local) search methods.
Planning Rewriting well suited mixed-initiative planning. mixed-initiative
planning, user planner interact defining plan. example, user
specify available preferred actions moment, change quality criteria interest, etc. fact, domains approached mixed-initiative
planning. example, quality metric expensive evaluate,
geometric analysis manufacturing, user must guide planner towards good quality
plans way small number plans generated evaluated. Another example
plan quality metric multi-objective changes time. Several characteristics PbR support mixed-initiative planning. First, PbR offers complete plans,
user easily understand plan perform complex quality assessment. Second,
rewriting rule language convenient mechanism user propose modifications plans. Third, selecting rules apply order application
user guide planner.
253

fiAmbite & Knoblock

framework achieves balance domain knowledge, expressed plan-rewriting
rules, general local-search techniques proved useful many hard combinatorial problems. expect ideas push frontier solvable problems
many practical domains high quality plans anytime behavior needed.
planning style introduced PbR opens several areas future research.
great potential applying machine learning techniques PbR. important issue
generation plan-rewriting rules. Conceptually, plan-rewriting rules arise
chosen plan equivalence relation. valid plans achieve given goals finite
number steps, i.e. solution plans, (satisfiability) equivalent. rule arises
theorem states two subplans equivalent purposes achieving
goals, addition conditions indicate context rule
usefully applied. plan-rewriting rules generated automated procedures.
methods range static analysis domain operators analysis sample
equivalent plans achieve goals different costs. Note similarity
methods automatically infer search control domain invariants (Minton, 1988b;
Etzioni, 1993; Gerevini & Schubert, 1998; Fox & Long, 1998; Rintanen, 2000), also
need deal utility problem. Ambite, Knoblock, & Minton (2000) present
results learning plan rewriting rules based comparing initial optimal plans
sample problems.
Beyond learning rewriting rules, intend develop system automatically learn optimal planner configuration given planning domain problem
distribution manner analogous Mintons Multi-TAC system (Minton, 1996).
system would perform search configuration space PbR planner proposing
candidate sets rewriting rules different search methods. testing proposed
configuration training set simple problems, system would hill-climb
configuration space order arrive useful rewriting rules search strategies
given planning domain distribution problems.
many advanced techniques local search literature adapted
extended framework. particular, idea variable-depth rewriting leads
naturally creation rule programs, specify set rules applied
plan. already seen query planning could find transformations
better specified program simple rewriting rules. example, sequence
Join-Swap transformations may put two retrieve operators database together
query tree Remote-Join-Eval would collapse explicit join operator
two retrieves single retrieval remote join. Cherniack & Zdonik (1996, 1998)
present complex examples sort programs rewriting rules context
query optimizer object-oriented databases.
discussed Sections 3.1.3 3.1.4 language antecedent rewriting rules expressive conjunctive queries still remaining computationally efficient. example, Figure 32 shows rule manufacturing domain
Section 4.1 relationally-complete antecedent. rule matches subplan contains spray-paint operator, contain either punch drill-press operators
create holes diameter smaller 1 millimeter. case, rule replaces
spray-paint operator immersion-paint operator. rule would useful
situation painting immersion could clog small holes.
254

fiPlanning Rewriting

(define-rule :name SP-by-IP-no-small-holes
:if (:and (:operator ?n1 (spray-paint ?x ?c ?s))
(:not (:and (:or (:operator ?n2 (punch ?x ?w ?o))
(:operator ?n3 (drill-press ?x ?w ?o)))
(:less ?w 1mm))))
:replace (:operators (?n1))
:with (:operator ?n4 (immersion-paint ?x ?c)))

Figure 32: Rule Relationally-Complete Antecedent
Another area research interplay plan rewriting plan execution.
Sometimes best transformations plan may known portion
plan executed. information obtained run-time guide planner
select appropriate rewritings. example, query planning plans may contain
information gathering actions (Ashish, Knoblock, & Levy, 1997) depend run-time
conditions. yields form dynamic query optimization. Interleaved planning
execution also necessary order deal effectively unexpected situations
environment database network failures.
open area research relax framework accept incomplete plans
rewriting process. expands search space considerably benefits
PbR, anytime property, lost. domains shortest path
rewritings initial plan optimal may pass incomplete inconsistent
plans. idea could embodied planning style combines characteristics
generative planning Planning Rewriting. reminiscent plan critics
approach (Sacerdoti, 1975; Sussman, 1975). resulting plan-rewriting rules seen
declarative specifications plan critics. plan refinements partial order
planning (Kambhampati et al., 1995) Hierarchical Task Network Planning (Erol, Nau,
& Hendler, 1994) easily specified plan-rewriting rules.
Applying PbR domains surely provide new challenges possibility
discovering transferring general planning techniques one domain another.
hope local-search methods used PbR help planning techniques scale
large practical problems conversely domain-independent nature PbR
help analysis principled extension local search techniques.

Acknowledgments
paper extended version (Ambite & Knoblock, 1997).
research reported supported part Fulbright/Ministerio Educacion
Ciencia Spain scholarship, part Defense Advanced Research Projects Agency
(DARPA) Air Force Research Laboratory, Air Force Materiel Command, USAF,
agreement number F30602-00-1-0504, part National Science Foundation
grant number IRI-9313993, part Rome Laboratory Air Force Systems Command Defense Advanced Research Projects Agency (DARPA) contract numbers F30602-94-C-0210, F30602-97-2-0352, F30602-97-2-0238, F30602-98-2-0109, part
United States Air Force contract number F49620-98-1-0046, part
Integrated Media Systems Center, National Science Foundation Engineering Research
255

fiAmbite & Knoblock

Center, Cooperative Agreement No. EEC-9529152. U.S.Government authorized
reproduce distribute reports Governmental purposes notwithstanding copyright
annotation thereon. views conclusions contained herein authors
interpreted necessarily representing official policies endorsements,
either expressed implied, organizations person connected
them.

References
Aarts, E., & Lenstra, J. K. (1997). Local Search Combinatorial Optimization. John Wiley
Sons, Chichester, England.
Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison-Wesley.
Ambite, J. L. (1998). Planning Rewriting. Ph.D. thesis, University Southern California.
Ambite, J. L., & Knoblock, C. A. (1997). Planning rewriting: Efficiently generating
high-quality plans. Proceedings Fourteenth National Conference Artificial
Intelligence, pp. 706713 Providence, RI.
Ambite, J. L., & Knoblock, C. A. (2000). Flexible scalable cost-based query planning
mediators: transformational approach. Artificial Intelligence, 118 (1-2), 115161.
Ambite, J. L., Knoblock, C. A., & Minton, S. (2000). Learning plan rewriting rules.
Proceedings Fifth International Conference Artificial Intelligence Planning
Scheduling Systems Breckenridge, CO.
Ashish, N., Knoblock, C. A., & Levy, A. (1997). Information gathering plans sensing
actions. Steel, S., & Alami, R. (Eds.), Recent Advances AI Planning: 4th
European Conference Planning, ECP97. Springer-Verlag, New York.
Avenhaus, J., & Madlener, K. (1990). Term rewriting equational reasoning. Formal
Techniques Artificial Intelligence, pp. 143. Elsevier, North Holland.
Baader, F., & Nipkow, T. (1998). Term Rewriting That. Cambridge University
Press.
Bacchus, F., & Kabanza, F. (1995). Using temporal logic control search forward
chaining planner. Proceedings 3rd European Workshop Planning.
Bacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledge planning. Artificial Intelligence, 116 (12), 123191.
Backstrom, C. (1994a). Executing parallel plans faster adding actions. Cohn, A. G.
(Ed.), Proceedings Eleventh European Conference Artificial Intelligence, pp.
615619 Amsterdam, Netherlands. John Wiley Sons.
Backstrom, C. (1994b). Finding least constrained plans optimal parallel executions
harder thought. Backstrom, C., & Sandewell, E. (Eds.), Current Trends
AI Planning: Proceedings 2nd European Workshop Planning (EWSP-93),
pp. 4659 Vadstena, Sweeden. IOS Press (Amsterdam).
256

fiPlanning Rewriting

Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Blum, A. L., & Furst, M. L. (1995). Fast planning planning graph analysis.
Proceedings Fourteenth International Joint Conference Artificial Intelligence
Montreal, Canada.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90 (12), 281300.
Bonet, B., & Geffner, H. (1999). Planning heuristic search: New results. Proceedings
Fifth European Conference Planning (ECP-99) Durham, UK.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism planning. Proceedings Fourteenth National Conference Artificial
Intelligence, pp. 714719 Providence, RI.
Borrajo, D., & Veloso, M. (1997). Lazy incremental learning control knowledge
efficiently obtaining quality plans. AI Review, 11, 371405.
Bylander, T. (1994). computation complexity propositional strips. Artificial Intelligence, 69 (1-2), 165204.
Carbonell, J. G., Knoblock, C. A., & Minton, S. (1991). PRODIGY: integrated architecture planning learning. VanLehn, K. (Ed.), Architectures Intelligence,
pp. 241278. Lawrence Erlbaum, Hillsdale, NJ.
Cherniack, M., & Zdonik, S. B. (1996). Rule languages internal algebras rule-based
optimizers. SIGMOD Record (ACM Special Interest Group Management Data),
25 (2), 401412.
Cherniack, M., & Zdonik, S. B. (1998). Changing rules: Transformations rulebased optimizers. Proceedings ACM SIGMOD International Conference
Management Data, pp. 6172 Seattle, WA.
Dean, T., & Boddy, M. (1988). analysis time-dependent planning. Proceedings
Seventh National Conference Artificial Intelligence, pp. 4954 Saint Paul, MN.
Dorr, H. (1995). Efficient graph rewriting implementation, Vol. 922 Lecture Notes
Computer Science. Springer-Verlag Inc., New York, NY, USA.
Erol, K., Nau, D., & Hendler, J. (1994). UMCP: sound complete planning procedure
hierarchical task-network planning. Proceedings Second International
Conference Artificial Intelligence Planning Systems, pp. 249254 Chicago, IL.
Erol, K., Nau, D., & Subrahmanian, V. S. (1995). Decidability undecidability results
domain-independent planning. Artificial Intelligence, 76 (1-2), 7588.
Estlin, T. A., & Mooney, R. J. (1997). Learning improve efficiency quality
planning. Proceedings Fifteenth International Joint Conference Artificial
Intelligence, pp. 12271233 Nagoya, Japan.
257

fiAmbite & Knoblock

Etzioni, O. (1993). Acquiring search-control knowledge via static analysis. Artificial Intelligence, 62 (2), 255302.
Etzioni, O., & Weld, D. S. (1994). softbot-based interface Internet. Communications ACM, 37 (7).
Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach application
theorem proving problem solving. Artificial Intelligence, 2 (3/4), 189208.
Forgy, C. L. (1982). Rete: fast algorithm many pattern/many object pattern
match problem. Artificial Intelligence, 19, 1737.
Foulser, D. E., Li, M., & Yang, Q. (1992). Theory algorithms plan merging. Artificial
Intelligence, 57 (23), 143182.
Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal
Artificicial Intelligence Research, 9, 367421.
Gerevini, A., & Schubert, L. (1998). Inferring state constraints domain-independent
planning. Proceedings Fifteenth National Conference Artificial Intelligence, pp. 905912 Madison, WI.
Glover, F. (1989). Tabu searchPart I. ORSA Journal Computing, 1 (3), 190206.
Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial search
randomization. Proceedings Fifteenth National Conference Artificial Intelligence Madison, WI.
Gupta, N., & Nau, D. S. (1992). complexity blocks-world planning. Artificial
Intelligence, 56 (23), 223254.
Hanks, S., & Weld, D. S. (1995). domain-independent algorithm plan adaptation.
Journal Artificicial Intelligence Research, 2, 319360.
Johnson, D. S. (1990). Local optimization traveling salesman problem. Paterson,
M. S. (Ed.), Automata, Languages Programming: Proc. 17th International
Colloquium, pp. 446461. Springer, New York.
Kambhampati, S. (1992). validation-structure-based theory plan modification
reuse. Artificial Intelligence, 55 (2-3), 193258.
Kambhampati, S., Knoblock, C. A., & Yang, Q. (1995). Planning refinement search:
unified framework evaluating design tradeoffs partial order planning.
Artificial Intelligence, 76 (1-2), 167238.
Kautz, H., & Selman, B. (1992). Planning satisfiability. Neumann, B. (Ed.), Proceedings 10th European Conference Artificial Intelligence, pp. 359363 Vienna,
Austria. John Wiley & Sons.
258

fiPlanning Rewriting

Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic,
stochastic search. Proceedings Thirteenth National Conference Artificial
Intelligence, pp. 11941201 Portland, OR.
Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization simulated annealing.
Science, 220, 671680.
Knoblock, C. A. (1994a). Automatically generating abstractions planning. Artificial
Intelligence, 68 (2), 243302.
Knoblock, C. A. (1994b). Generating parallel execution plans partial-order planner. Proceedings Second International Conference Artificial Intelligence
Planning Systems Chicago, IL.
Knoblock, C. A. (1995). Planning, executing, sensing, replanning information gathering. Proceedings Fourteenth International Joint Conference Artificial
Intelligence Montreal, Canada.
Knoblock, C. A. (1996). Building planner information gathering: report
trenches. Proceedings Third International Conference Artificial Intelligence Planning Systems Edinburgh, Scotland.
Koehler, J. (1998). Solving complex planning tasks extraction subproblems.
Simmons, R., Veloso, M., & Smith, S. (Eds.), Proceedings Fourth International
Conference Artificial Intelligence Planning Systems, pp. 6269 Pittsburgh, PA.
Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings use
agenda-driven planning algorithm. Journal Artificial Intelligence Research,
12, 338386.
Koehler, J., Nebel, B., Hoffman, J., & Dimopoulos, Y. (1997). Extending planning graphs
ADL subset. Steel, S., & Alami, R. (Eds.), Proceedings Fourth European
Conference Planning (ECP-97): Recent Advances AI Planning, Vol. 1348
LNAI, pp. 273285 Berlin. Springer.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
Ninth National Conference Artificial Intelligence Anaheim, CA.
Minton, S. (1988a). Learning Effective Search Control Knowledge: Explanation-Based
Approach. Ph.D. thesis, Computer Science Department, Carnegie Mellon University.
Minton, S. (1988b). Learning Search Control Knowledge: Explanation-Based Approach.
Kluwer, Boston, MA.
Minton, S. (1992). Minimizing conflicts: heuristic repair method constraintsatisfaction scheduling problems. Artificial Intelligence, 58 (1-3), 161205.
Minton, S. (1996). Automatically configuring constraint satisfaction programs: case
study. Constraints, 1 (1), 743.
259

fiAmbite & Knoblock

Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1990). Solving large-scale constraint satisfaction scheduling problems using heuristic repair method. Proceedings Eighth National Conference Artificial Intelligence, pp. 1724 Boston,
MA.
Munoz-Avila, H. (1998). Integrating Twofold Case Retrieval Complete Decision Replay
CAPlan/CbC. Ph.D. thesis, University Kaiserslautern.
Nau, D. S., Gupta, S. K., & Regli, W. C. (1995). AI planning versus manufacturingoperation planning: case study. Proceedings Fourteenth International
Joint Conference Artificial Intelligence Montreal, Canada.
Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: theoretical
empirical analysis. Artificial Intelligence, 76 ((1-2)), 427454.
Ono, K., & Lohman, G. M. (1990). Measuring complexity join enumeration query
optimization. McLeod, D., Sacks-Davis, R., & Schek, H.-J. (Eds.), 16th International Conference Large Data Bases, pp. 314325 Brisbane, Queensland,
Australia. Morgan Kaufmann.
Papadimitriou, C. H., & Steiglitz, K. (1977). complexity local search
traveling salesman problem. SIAM, 6 (1), 7683.
Papadimitriou, C. H., & Steiglitz, K. (1982). Combinatorial Optimization: Algorithms
Complexity. Prentice Hall, Englewood Cliffs, NJ.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order planner
ADL. Third International Conference Principles Knowledge Representation
Reasoning, pp. 189197 Cambridge, MA.
Perez, M. A. (1996). Representing learning quality-improving search control knowledge.
Proceedings Thirteenth International Conference Machine Learning Bari,
Italy.
Ratner, D., & Pohl, I. (1986). Joint LPA*: Combination approximation search.
Proceedings Fifth National Conference Artificial Intelligence Philadelphia,
PA.
Rintanen, J. (2000). iterative algorithm synthesizing invariants. Proceedings
Seventeenth National Conference Artificial Intelligence Austin, TX.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall.
Sacerdoti, E. D. (1975). nonlinear nature plans. Proceedings Fourth
International Joint Conference Artificial Intelligence, pp. 206214 Tbilisi, Georgia,
USSR.
Savage, S., Weiner, P., & Bagchi, A. (1976). Neighborhood search algorithms guaranteeing optimal traveling salesman tours must inefficient. Journal Computer
System Sciences, 12 (1), 2535.
260

fiPlanning Rewriting

Schurr, A. (1990). Introduction PROGRES, attribute graph grammar based specification language. Nagl, M. (Ed.), Graph-Theoretic Concepts Computer Science,
Vol. 411 Lecture Notes Computer Science, pp. 151165.
Schurr, A. (1997). Programmed graph replacement systems. Rozenberg, G. (Ed.),
Handbook Graph Grammars: Foundations, Vol. 1, pp. 479546. World Scientific,
Singapore.
Sellis, T. K. (1988). Multiple-query optimization. ACM Transactions Database Systems,
13 (1), 2352.
Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiability
problems. Proceedings Tenth National Conference Artificial Intelligence
(AAAI-92), pp. 440446 San Jose, California. AAAI Press.
Silberschatz, A., Korth, H. F., & Sudarshan, S. (1997). Database System Concepts (Third
edition). McGraw-Hill.
Simon, H. (1969). sciences artificial. MIT Press.
Slaney, J., & Thiebaux, S. (1996). Linear time near-optimal planning blocks world.
Proceedings Thirteenth National Conference Artificial Intelligence
Eighth Innovative Applications Artificial Intelligence Conference, pp. 12081214
Menlo Park. AAAI Press / MIT Press.
Sussman, G. J. (1975). Computer Model Skill Acquisition. American Elsevier, New
York.
Veloso, M. (1994). Planning Learning Analogical Reasoning. Springer Verlag.
Veloso, M. M., Perez, M. A., & Carbonell, J. G. (1990). Nonlinear planning parallel
resource allocation. Proceedings Workshop Innovative Approaches
Planning, Scheduling Control, pp. 207212 San Diego, CA.
Weld, D. S. (1994). introduction least commitment planning. AI Magazine, 15 (4).
Weld, D. S. (1999). Recent advances AI planning. AI Magazine, 20 (2).
Yu, C., & Chang, C. (1984). Distributed query processing. ACM Computing Surveys, 16 (4),
399433.
Zweben, M., Daun, B., & Deale, M. (1994). Scheduling rescheduling iterative
repair. Intelligent Scheduling, pp. 241255. Morgan Kaufman, San Mateo, CA.

261

fiJournal Artificial Intelligence Research 15 (2001) 391-454

Submitted 6/18; published 12/01

Parameter Learning Logic Programs
Symbolic-statistical Modeling

Taisuke Sato
Yoshitaka Kameya

sato@mi.cs.titech.ac.jp
kame@mi.cs.titech.ac.jp

Dept. Computer Science, Graduate School Information
Science Engineering, Tokyo Institute Technology
2-12-1 Ookayama Meguro-ku Tokyo Japan 152-8552

Abstract

propose logical/mathematical framework statistical parameter learning parameterized logic programs, i.e. definite clause programs containing probabilistic facts
parameterized distribution. extends traditional least Herbrand model semantics
logic programming distribution semantics , possible world semantics probability
distribution unconditionally applicable arbitrary logic programs including ones
HMMs, PCFGs Bayesian networks.
also propose new EM algorithm, graphical EM algorithm, runs
class parameterized logic programs representing sequential decision processes
decision exclusive independent. runs new data structure called support graph
describing logical relationship observations explanations, learns
parameters computing inside outside probability generalized logic programs.
complexity analysis shows combined OLDT search explanations observations, graphical EM algorithm, despite generality,
time complexity existing EM algorithms, i.e. Baum-Welch algorithm HMMs,
Inside-Outside algorithm PCFGs, one singly connected Bayesian networks
developed independently research field. Learning experiments
PCFGs using two corpora moderate size indicate graphical EM algorithm
significantly outperform Inside-Outside algorithm.
1. Introduction

Parameter learning common various fields neural networks reinforcement learning statistics. used tune systems best performance, classifiers
statistical models. Unlike numerical systems described mathematical formulas however, symbolic systems, typically programs, seem amenable kind
parameter learning. Actually little literature parameter learning programs.
paper attempt incorporate parameter learning computer programs.
reason twofold. Theoretically wish add ability learning computer
programs, authors believe necessary step toward building intelligent systems.
Practically broadens class probability distributions, beyond traditionally used numerical ones, available modeling complex phenomena gene inheritance,
consumer behavior, natural language processing on.
c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiSato & Kameya

type learning consider statistical parameter learning applied logic
programs.1 assume facts (unit clauses) program probabilistically true
parameterized distribution.2 clauses, non-unit definite clauses, always
true encode laws \if one pair blood type genes b, one's
blood type AB". call logic programs type parameterized logic program
use statistical modeling ground atoms3 provable program represent
observations \one's blood type AB" parameters program
inferred performing ML (maximum likelihood) estimation observed atoms.
probabilistic first-order framework sketched termed statistical abduction
(Sato & Kameya, 2000) amalgamation statistical inference abduction
probabilistic facts play role abducible s, i.e. primitive hypotheses.4 Statistical
abduction powerful subsumes diverse symbolic-statistical frameworks
HMMs (hidden Markov models, Rabiner, 1989), PCFGs (probabilistic context free
grammars, Wetherell, 1980; Manning & Schutze, 1999) (discrete) Bayesian networks
(Pearl, 1988; Castillo, Gutierrez, & Hadi, 1997) gives us freedom using arbitrarily
complex logic programs modeling.5
semantic basis statistical abduction distribution semantics introduced Sato
(1995). defines parameterized distribution, actually probability measure, set
possible truth assignments ground atoms enables us derive new EM algorithm6
ML estimation called graphical EM algorithm (Kameya & Sato, 2000).
Parameter learning statistical abduction done two phases, search EM learning. Given parameterized logic program observations, first phase searches
explanations observations. Redundancy first phase eliminated tabulating
partial explanations using OLDT search (Tamaki & Sato, 1986; Warren, 1992; Sagonas, T.,
& Warren, 1994; Ramakrishnan, Rao, Sagonas, Swift, & Warren, 1995; Shen, Yuan, You, &
Zhou, 2001). returns support graph compact representation discovered
explanations. second phase, run graphical EM algorithm support graph
1. paper, logic programs mean definite clause programs. definite clause program set definite
clauses. definite clause clause form L1 ; : : : ; Ln (0 n) A; L1 ; : : : ; Ln atoms.
called head, L1 ; : : : ; Ln body. variables universally quantified. reads L1
1 1 1 Ln hold, holds. case n = 0, clause called unit clause. general clause
one whose body may contain negated atoms. program including general clauses sometimes called
general program (Lloyd, 1984; Doets, 1994).
2. Throughout paper, familiarity readability, somewhat loosely use \distribution"
synonym \probability measure".
3. logic programming, adjective \ground" means variables contained.
4. Abduction means inference best explanation set observations. Logically, formalized
search explanation E E; KB ` G G atom representing observation, KB
knowledge base E conjunction atoms chosen abducible s, i.e. class formulas allowed
primitive hypotheses (Kakas, Kowalski, & Toni, 1992; Flach & Kakas, 2000). E must consistent
KB.
5. Existing symbolic-statistical modeling frameworks restrictions limitations various types compared arbitrary logic programs (see Section 7 details). example, Bayesian networks
allow recursion. HMMs PCFGs, stochastic grammars, allow recursion lack variables data
structures. Recursive logic programs allowed Ngo Haddawy's (1997) framework
assume domains finite function symbols seem prohibited.
6. \EM algorithm" stands class iterative algorithms ML estimation incomplete data
(McLachlan & Krishnan, 1997).
392

fiParameter Learning Logic Programs Symbolic-statistical Modeling

learn parameters distribution associated program. Redundancy
second phase removed introduction inside outside probability logic
programs computed support graph.
graphical EM algorithm accomplished, combined OLDT search
explanations, time complexity specialized ones, e.g. Baum-Welch
algorithm HMMs (Rabiner, 1989) Inside-Outside algorithm PCFGs (Baker,
1979), despite generality. surprising that, conducted learning experiments PCFGs using real corpora, outperformed Inside-Outside algorithm
orders magnitudes terms time one iteration update parameters. experimental results enhance prospect symbolic-statistical modeling parameterized
logic programs even complex systems stochastic grammars whose modeling
dicult simply lack appropriate modeling tool sheer
complexities. contributions paper therefore
distribution semantics parameterized logic programs unifies existing symbolicstatistical frameworks,
graphical EM algorithm (combined tabulated search), general yet ecient
EM algorithm runs support graphs
prospect suggested learning experiments modeling learning complex
symbolic-statistical phenomena.
rest paper organized follows. preliminaries Section 2, probability space parameterized logic programs constructed Section 3 mathematical
basis subsequent sections. propose new EM algorithm, graphical
EM algorithm, parameterized logic programs Section 4. Complexity analysis
graphical EM algorithm presented Section 5 HMMs, PCFGs, pseudo PCSGs
sc-BNs.7 Section 6 contains experimental results parameter learning PCFGs
graphical EM algorithm using real corpora demonstrate eciency graphical
EM algorithm. state related work Section 7, followed conclusion Section 8.
reader assumed familiar basics logic programming (Lloyd, 1984; Doets,
1994), probability theory (Chow & Teicher, 1997), Bayesian networks (Pearl, 1988; Castillo
et al., 1997) stochastic grammars (Rabiner, 1989; Manning & Schutze, 1999).
2. Preliminaries

Since subject intersects logic programming EM learning quite different
nature, separate preliminaries.

2.1 Logic Programming OLDT

logic programming, program DB set definite clauses8 execution search
SLD refutation given goal G. top-down interpreter recursively selects
7. Pseudo PCSGs (probabilistic context sensitive grammars) context-sensitive extension PCFGs
proposed Charniak Carroll (1994). sc-BN shorthand singly connected Bayesian network
(Pearl, 1988).
8. deal general logic programs paper.
393

fiSato & Kameya

next goal unfolds (Tamaki & Sato, 1984) subgoals using nondeterministically
chosen clause. computed result SLD refutation, i.e. solution, answer
substitution (variable binding) DB ` G.9 Usually one
refutation G, search space refutations described SLD tree
may infinite depending program goal (Lloyd, 1984; Doets, 1994).
often not, applications require solutions. natural language processing
instance, parser must able find possible parse trees given sentence
every one syntactically correct. Similarly statistical abduction, need
examine explanations determine likely one. solutions obtained
searching entire SLD tree, choice search strategy. Prolog,
standard logic programming language, backtracking used search solutions
conjunction fixed search order goals (textually left-to-right) clauses
(textually top-to-bottom) due ease simplicity implementation.
problem backtracking forgets everything previous
choice point, hence quite likely prove goal again, resulting
exponential search time. One answer avoid problem store computed results
reuse whenever necessary. OLDT instance memoizing scheme (Tamaki
& Sato, 1986; Warren, 1992; Sagonas et al., 1994; Ramakrishnan et al., 1995; Shen et al.,
2001). Reuse proved subgoals OLDT search often drastically reduces search time
solutions, especially refutations top goal include many common subrefutations. Take example logic program coding HMM. given string s,
exist exponentially many transition paths output s. OLDT search applied
program however takes time linear length find unlike
exponential time Prolog's backtracking search.
OLDT statistical abduction? viewpoint statistical abduction, reuse proved subgoals, equivalently, structure sharing sub-refutations
top-goal G brings structure sharing explanations G, addition
reduction search time mentioned above, thereby producing highly compact representation explanations G.

2.2 EM Learning

Parameterized distributions multinomial distribution normal distribution provide convenient modeling devices statistics. Suppose random sample x1; : : : ; xT
size random variable X drawn distribution P (X = x j ) parameterized
unknown , observed. value determined ML estimation MLE
(maximum likelihood estimate) , i.e. maximizer likelihood 1iT P (xi j ).
Things get much dicult data incomplete. Think probabilistic
relationship non-observable cause X observable effect one
diseases symptoms medicine assume uniquely determine
cause X . incomplete sense carry enough information
completely determine X . Let P (X = x; = j ) parameterized joint distribution
X . task perform ML estimation condition X
Q

9. solution ambiguously mean answer substitution proved atom G,
one gives other.
394

fiParameter Learning Logic Programs Symbolic-statistical Modeling

non-observable observable. Let y1 ; : : : ; yT random sample size drawn
marginal distribution P (Y = j ) = x P (X = x; = j ). MLE
obtained maximizing likelihood 1iT P (yi j ) function .
mathematical formulation looks alike cases, latter, ML estimation
incomplete data, far complicated direct maximization practically impossible
many cases. People therefore looked indirect approaches tackle problem
ML estimation incomplete data EM algorithm standard
solution (Dempster, Laird, & Rubin, 1977; McLachlan & Krishnan, 1997). iterative
algorithm applicable wide class parameterized distributions including multinomial
distribution normal distribution MLE computation replaced
iteration two easier, tractable steps. n-th iteration, first calculates value
Q function introduced using current parameter value (n) (E-step)10 :
P

Q

Q( j (n)) def
=

X

x

P (x j y; (n) ) ln P (x; j ):

(1)

Next, maximizes Q( j (n)) function updates (n) (M-step):
(n+1) = argmax Q( j (n) ):
(2)
Since old value (n) updated value (n+1) necessarily coincide, E-steps
M-steps iterated convergence, (log) likelihood assured
increase monotonically (McLachlan & Krishnan, 1997).
Although EM algorithm merely performs local maximization, used variety
settings due simplicity relatively good performance. One must notice however
EM algorithm class name, taking different form depending distributions
applications. development concrete EM algorithm Baum-Welch
algorithm HMMs (Rabiner, 1989) Inside-Outside algorithm PCFGs (Baker,
1979) requires individual effort case.
10. Q function related ML estimation follows. assume one data, , observed.
Jensen's inequality (Chow & Teicher, 1997) concavity ln function, follows
X

P (x j y; (n) ) ln P (x j y; ) 0

x

X

P (x j y; (n) ) ln P (x j y; (n) ) 0

x

hence
Q( j (n) ) 0 Q((n) j (n) )
X
X
=
P (x j y; (n) ) ln P (x j y; ) 0
P (x j y; (n) ) ln P (x j y; (n) ) + ln P (y j ) 0 ln P (y j (n) )
x

ln P (y j ) 0 ln P (y j (n) ):

x

Consequently,
Q( j (n) ) Q((n) j (n) ) ) ln p(y j ) ln p(y j (n) ) ) p(y j ) p(y j (n) ):
395

fiSato & Kameya
3. Distribution Semantics

section, introduce parameterized logic programs define declarative semantics. basic idea follows. start set F probabilistic facts (atoms)
set R non-unit definite clauses. Sampling F determines set F 0 true
atoms, least Herbrand model F 0 [ R determines truth value every atom
DB = F [ R. Hence every atom considered random variable, taking 1
(true) 0 (false). follows, formalize process construct underlying
probability space denotation DB.

3.1 Basic Distribution PF

Let DB = F [R definite clause program first-order language L countably many
variables, function symbols predicate symbols F set unit clauses (facts)
R set non-unit clauses (rules). sequel, unless otherwise stated, consider
simplicity DB set ground instances clauses DB, assume
F R consist countably infinite ground clauses (the finite case similarly treated).
construct probability space DB two steps. First introduce probability
space Herbrand interpretations11 F i.e. truth assignments ground atoms
F . Next extend probability space Herbrand interpretations
ground atoms L using least model semantics (Lloyd, 1984; Doets, 1994).
Let A1 ; A2 ; : : : fixed enumeration atoms F . regard infinite vector ! =
hx1; x2; : : :i 0s 1s Herbrand interpretation F way = 1; 2; : : :
Ai true (resp. false) xi = 1 (resp. xi = 0). isomorphism, set
possible Herbrand interpretations F coincides Cartesian product:
1
def

F = f0; 1gi:


i=1

construct probability measure PF sample space
F 12 collection
finite joint distributions PF(n)(A1 = x1; : : : ; = xn) (n = 1; 2; : : : ; xi 2 f0; 1g; 1 n)

0 PF(n)(A1 = x1 ; : : : ; = xn) 1
(n)
(3)
x ;:::;x PF (A1 = x1 ; : : : ; = xn ) = 1
(
n+1)
(
n)
PF (A1 = x1 ; : : : ; An+1 = xn+1 ) = PF (A1 = x1 ; : : : ; = xn ):
x
last equation called compatibility condition. proved (Chow & Teicher,
1997) compatibility condition exists probability space (
F ; F ; PF )
PF probability measure F , minimal algebra containing open sets
F ,
n,
PF (A1 = x1 ; : : : ; = xn ) = PF(n) (A1 = x1 ; : : : ; = xn ):
8
>
>
<
>
>
:

P

P

1

n

n+1

11. Herbrand interpretation interprets function symbol uniquely function ground terms
assigns truth values ground atoms. Since interpretation function symbols common
Herbrand interpretations, given L, one-to-one correspondence truth assignments
ground atoms L. distinguish them.
12. regard
F topological space product topology f0; 1g equipped
discrete topology.
396

fiParameter Learning Logic Programs Symbolic-statistical Modeling

call PF basic distribution
.13
(
n)
choice PF free long compatibility condition met. want
interpretations equiprobable, set PF(n)(A1 = x1; : : : ; = xn) = 1=2n
every hx1; : : : ; xn i. resulting PF uniform distribution
F like one
unit interval [0; 1]. If, hand, stipulate interpretation except
!0 = hc1 ; c2; : : :i possible, put, n,
PF(n) (A1 = x1 ; : : : ; = xn ) = 10 ifo.w. 8i xi = ci (1 n)
PF places probability mass !0 gives probability 0 rest.
Define parameterized logic program definite clause program14 DB = F [ R
F set unit clauses, R set non-unit clauses clause head R
unifiable unit clause F parameterized basic distribution PF associated
F . parameterized PF obtained collection parameterized joint distributions
satisfying compatibility condition. Generally, complex PF(n)'s are,
exible PF is, cost tractability. choice parameterized finite distributions
made Sato (1995) simple:
PF(2n) (ON 1 = x1; 2 = x2 ; : : : ; 2n = x2n j 1 ; : : : ; n)
n
= Pbs (ON 2i01 = x2i01; 2i = x2i j i)
i=1

Pbs (ON 2i01 = x2i01 ; 2i = x2i j )
0 x2i01 = x2i
=
x2i01 = 1; x2i = 0
(4)
1 0 x2i01 = 0; x2i = 1:
Pbs (ON 2i01 = x2i01 ; 2i = x2i j ) (1 n) represents probabilistic binary switch,
i.e. Bernoulli trial, using two exclusive atoms 2i01 2i way either
one true trial never both. parameter specifying probability
switch on. resulting PF probability measure infinite product
independent binary outcomes. might look simple expressive enough Bayesian
networks, Markov chains HMMs (Sato, 1995; Sato & Kameya, 1997).
(



8
>
<
>
:

3.2 Extending PF PDB

subsection, extend PF probability measure PDB possible world
L, i.e. set possible truth assignments ground atoms L least
13. naming PF , despite probability measure, partly ects observation behaves
like infinite joint distribution PF (A1 = x1 ; A2 = x2 ; : : :) infinite random vector hA1 ; A2 ; : : :i
PF(n) (A1 = x1 ; : : : ; = xn ) (n = 1; 2; : : :) marginal distributions. Another reason
intuitiveness. considerations apply PDB defined next subsection well.
14. clauses necessarily ground.
397

fiSato & Kameya

Herbrand model (Lloyd, 1984; Doets, 1994). proceeding however, need couple
notations. atom A, define Ax
Ax = x = 1
Ax = :A x = 0:
Next take Herbrand interpretation 2
F F . makes atoms F true
others false. Let F set atoms made true . imagine definite clause
program DB0 = R [ F least Herbrand model MDB0 (Lloyd, 1984; Doets, 1994).
MDB0 characterized least fixed point mapping TDB0 (1)
B1 ; : : : ; Bk 2 DB0 (0 k)
TDB0 (I ) def
=
fB1 ; : : : ; Bk g
set ground atoms.15 equivalently, inductively defined
I0 = ;
In+1 = TDB0 (In )
MDB0 =
:
(

(

fi
fi
fi
fi
fi

)

[

n

Taking account fact MDB0 function 2
F , henceforth employ
functional notation MDB ( ) denote MDB0 .
Turning back, let A1 ; A2 ; : : : enumeration, ground atoms L.16
Form
DB , similarly
F , Cartesian product denumerably many f0; 1g's identify set possible Herbrand interpretations ground atoms A1 ; A2 ; : : :
L, i.e. possible world L. extend PF probability
measure PDB
DB
(
n)
follows. Introduce series finite joint distributions PDB (A1 = x1 ; : : : ; = xn )
n = 1; 2; : : :
[Ax1 ^ 1 1 1 ^ Axn ]F def
= f 2
F j MDB ( ) j= Ax1 ^ 1 11 ^ Axn g
def
(n) (A = x ; : : : ; = x ) = P ([Ax ^ 11 1 ^ Ax ] ):
PDB
1
1
n
n
F
n F
1
1

n

1

1

n

n

(n) 's satisfy
Note set [Ax1 ^ 1 1 1 ^ Axn ]F PF -measurable definition, PDB
compatibility condition
(n+1) (A = x ; : : : ; = x ) = P (n) (A = x ; : : : ; = x ):
PDB
1
1
n+1
n+1
1
n
n
DB 1
1

n

X

xn+1

Hence exists probability measure PDB
DB extension PF

PDB (A1 = x1 ; : : : ; = xn ) = PF (A1 = x1 ; : : : ; = xn )
15. defines, mutually, Herbrand interpretation ground atom true 2 .
Herbrand model program Herbrand interpretation makes every ground instance every
clause program true.
16. Note enumeration enumerates ground atoms F well.
398

fiParameter Learning Logic Programs Symbolic-statistical Modeling

finite atoms A1; : : : ; F every binary vector hx1 ; : : : ; xni (xi 2 f0; 1g; 1
n). Define denotation program DB = F [ R w.r.t. PF PDB . denotational semantics parameterized logic programs defined called distribution
semantics. remarked before, regard PDB kind infinite joint distribution
PDB (A1 = x1 ; A2 = x2 ; : : :). Mathematical properties PDB listed Appendix
semantics proved extension standard least model semantics
logic programming possible world semantics probability measure.

3.3 Programs Distributions

Distribution semantics views parameterized logic programs expressing distributions. Traditionally distributions expressed using mathematical formulas use
programs (discrete) distributions gives us far freedom exibility mathematical formulas construction distributions recursion arbitrary composition. particular program contain infinitely many random variables
probabilistic atoms recursion, hence describe stochastic processes
potentially involve infinitely many random variables Markov chains derivations
PCFGs (Manning & Schutze, 1999).17
Programs also enable us procedurally express complicated constraints distributions
\the sum occurrences alphabets b output string HMM must
multiple three". feature, procedural expression arbitrarily complex (discrete)
distributions, seems quite helpful symbolic-statistical modeling.
Finally, providing mathematically sound semantics parameterized logic programs
one thing, implementing distribution semantics tractable way another.
next section, investigate conditions parameterized logic programs make
probability computation tractable, thereby making usable means large scale
symbolic-statistical modeling.
4. Graphical EM Algorithm

According preceding section, parameterized logic program DB = F [ R
first-order language L parameterized basic distribution PF (1 j ) Herbrand
interpretations ground atoms F specifies parameterized distribution PDB (1 j )
Herbrand interpretations L. section, develop, step step, ecient EM
algorithm parameter learning parameterized logic programs interpreting PDB
distribution observable non-observable events. new EM algorithm
termed graphical EM algorithm. applicable arbitrary logic programs satisfying
certain conditions described later provided basic distribution direct product
multi-ary random switches, slight complication binary ones introduced
Section 3.1.
section on, assume DB consists usual definite clauses containing
(universally quantified) variables. Definitions changes relating assumption
17. infinite derivation occur PCFGs. Take simple PCFG fp : ! a; q : ! SS g
start symbol, terminal symbol, p + q = 1 p; q > 0. PCFG, rewritten either
probability p SS probability q . probability occurrence infinite derivation
calculated max f0; 1 0 (p=q)g non-zero q > p (Chi & Geman, 1998).
399

fiSato & Kameya

listed below. predicate p, introduce iff (p), iff definition p
iff(p) def
= 8x (p(x) $ 9y1(x = t1 ^ W1 ) _ 1 11 _ 9yn (x = tn ^ Wn )) :
x vector new variables length equal arity p, p(ti) Wi (1
n; 0 n), enumeration clauses p DB, yi , vector variables occurring
p(ti) Wi. define comp(R) follows.
head(R) def
= fB j B ground instance clause head appearing Rg
iff (R) def
= fiff (p) j p appears clause head Rg
Eq def
= ff (x) = f (y) ! x = j f function symbolg
[ ff (x) 6= g(y) j f g different function symbolsg
[ ft 6= x j term properly containing xg
comp(R) def
= iff (R) [ Eq
Eq , Clark's equational theory (Clark, 1978), deductively simulates unification. Likewise
comp(R) first-order theory deductively simulates SLD refutation help
Eq replacing clause head atom clause body (Lloyd, 1984; Doets, 1994).
introduce definitions frequently used. Let B atom.
explanation B w.r.t. DB = F [ R conjunction S; R ` B,
set comprised conjuncts, F holds proper subset satisfies this.
set explanations B called support set B designated DB (B).18

4.1 Motivating Example

First all, review distribution semantics concrete example. Consider following
program DBb = Fb [ Rb Figure 1 modeling one's blood type determined blood
type genes probabilistically inherited parents.19
first four clauses Rb state blood type determined genotype, i.e. pair
blood type genes a, b o. instance, btype('A'):- (gtype(a,a) ; gtype(a,o) ;
gtype(o,a)) says one's blood type (her) genotype ha; ai, ha; oi ho; ai.
propositional rules.
Succeeding clauses state general rules terms logical variables. fifth clause
says regardless values X Y, event gtype(X,Y) (one's genotype
hX; Yi) caused two events, gene(father,X) (inheriting gene X father)
gene(mother,Y) (inheriting gene mother). gene(P,G):- msw(gene,P,G)
clause connecting rules Rb probabilistic facts Fb. tells us gene G
inherited parent P choice represented msw(gene,P,G)20 made.

18. definition support set differs one used Sato (1995) Kameya Sato (2000).
19. implicitly emphasize procedural reading logic programs, Prolog conventions employed
(Sterling & Shapiro, 1986). Thus, ; stands \or", , \and" :- \implied by" respectively. Strings
beginning capital letter (universally quantified) variables, quoted ones 'A'
constants. underscore anonymous variable.
20. msw abbreviation \multi-ary random switch" msw(1; 1; 1) expresses probabilistic choice
finite alternatives. framework statistical abduction, msw atoms abducibles
explanations constructed conjunction.
400

fiParameter Learning Logic Programs Symbolic-statistical Modeling

8
>
>
>
>
>
>
>
<

btype('A')
btype('B')
btype('O')
btype('AB')
gtype(X,Y)
gene(P,G)

::::::-

(gtype(a,a) ; gtype(a,o) ; gtype(o,a)).
(gtype(b,b) ; gtype(b,o) ; gtype(o,b)).
gtype(o,o).
(gtype(a,b) ; gtype(b,a)).
gene(father,X), gene(mother,Y).
msw(gene,P,G).

Rb

=

Fb

= fmsw(gene,father,a); msw(gene,father,b); msw(gene,father,o);

>
>
>
>
>
>
>
:

msw(gene,mother,a); msw(gene,mother,b); msw(gene,mother,o)g

Figure 1: ABO blood type program DBb
genetic knowledge choice G chance made fa; b; og expressed
specifying joint distribution Fb follows.
PF (msw(gene,t,a) = x; msw(gene,t,b) = y; msw(gene,t,o) = z j ; b ; ) def
= axby oz
x; y; z 2 f0; 1g, x + + z = 1, a; b; 2 [0; 1], + b + = 1 either
father mother. Thus probability inheriting gene parent. Statistical
independence choice gene, father mother, expressed
putting
PF ( msw(gene,father,a) = x; msw(gene,father,b) = y; msw(gene,father,o) = z;
msw(gene,mother,a) = x0; msw(gene,mother,b) = 0; msw(gene,mother,o) = z 0
j ; b ; )
= PF (x; y; z j a; b; o)PF (x0; y0 ; z0 j a; b ; o):
setting, atoms representing observation obs(DBb ) = fbtype('A'); btype('B');
btype('O'); btype('AB')g. observe one them, say btype('A'), infer possible
explanation , i.e. minimal conjunction abducibles msw(gene,1,1)
S; Rb ` btype('A').
obtained applying special SLD refutation procedure goal btype('A')
preserves msw atoms resolved upon refutation. Three explanations found.
S1 = msw(gene,father,a) ^ msw(gene,mother,a)
S2 = msw(gene,father,a) ^ msw(gene,mother,o)
S3 = msw(gene,father,o) ^ msw(gene,mother,a)
DB (btype(a)), support set btype(a), fS1 ; S2 ; S3g. probability
explanation respectively computed PF (S1) = a2 PF (S2 ) = PF (S3) = ao.
Proposition A.2 Appendix A, follows PDB (btype('A')) = PDB (S1 _ S2 _ S3) =
PF (S1 _ S2 _ S3 )
PDB (btype('A') j ; b ; ) = PF (S1 ) + PF (S2 ) + PF (S3 )
= a2 + 2ao:
b

b

b

b

b

b

b

b

b

b

b

b

b

401

b

b

fiSato & Kameya

used fact S1, S2 S3 mutually exclusive choice gene
exclusive. Parameters, i.e. a, b determined ML estimation performed
random sample fbtype('A'); btype('O'); btype('AB')g btype follows.
ha ; b ; oi = argmaxh ; ; PDB (btype('A'))PDB (btype('O'))PDB (btype('AB'))
= argmaxh ; ; (a2 + 2ao)o2 ab
program contains neither function symbol recursion though semantics
allows them. Later see example containing both, program HMM (Rabiner
& Juang, 1993).


b



b

b

b

b

4.2 Four Simplifying Conditions

Figure 1 simple probability computation easy. generally
case. Since primary interest learning, especially ecient parameter learning parameterized logic programs, hereafter concentrate identifying property program
makes probability computation easy like DBb, thereby makes ecient parameter learning
possible.
answer question precisely, let us formulate whole modeling process. Suppose
exist symbolic-statistical phenomena gene inheritance hope
construct probabilistic computational model. first specify target predicate p
whose ground atom p(s) represents observation phenomena. explain
empirical distribution p, write parameterized logic program DB = F [ R
basic distribution PF parameter reproduce observable patterns
p(s). Finally, observing random sample p(s1); : : : ; p(sT ) ground atoms p,
adjust ML estimation, i.e. maximizing likelihood L() = Tt=1 PDB (p(st) j )
PDB (p(1) j ) approximates closely empirically observed distribution p
possible.
first sight, formulation looks right, reality not. Suppose two events
p(s) p(s0 ) (s 6= s0) observed. put L() = PDB (p(s) j )PDB (p(s0) j ).
cannot likelihood simply distribution semantics, p(s) p(s0 )
two different random variables, two realizations random variable.
quick remedy note case blood type program DBb obs(DBb) =
fbtype('A'); btype('B'); btype('O'); btype('AB')g observable atoms, one
true observation, atom true, others must false.
words, atoms collectively behave single random variable distribution
PDB whose values obs(DBb ).
Keeping mind, introduce following condition. Let obs(DB) ( head(R))
set ground atoms represent observable events. call observable atom s.
DBb

Q

b

Uniqueness condition:
0
PDB (G ^ G ) = 0

G 6= G0 2 obs(DB),

402

P

G2obs(DB) PDB

(G) = 1.

fiParameter Learning Logic Programs Symbolic-statistical Modeling

uniqueness condition enables us introduce new random variable Yo representing
observation. Fix enumeration G1 ; G2 ; : : : observable atoms obs(DB) define
Yo by21
(! ) = k

iff ! j= Gk ! 2
DB (k 1):
(5)
Let Gk T; Gk ; : : : ; Gk 2 obs(DB) random sample size . L() = Tt=1 PDB (Gk j
) = t=1 PDB (Yo = kt j ) qualifies likelihood function w.r.t. Yo .
second condition concerns reduction probability computation addition.
Take blood type exmaple. computation PDB (btype('A')) decomposed
summation explanations support set mutualy exclusive.
introduce
Q

Q1

2





b

Exclusiveness condition:

every G 2 obs(DB) support set DB (G), PDB (S ^ 0) = 0 6=
0 2 DB (G).
Using exclusiveness condition (and Proposition A.2 Appendix A),
PDB (G) =
PF (S ):
X

S2

DB

(G)

modeling point view, means single event, single observation,
G, may several (or even infinite) explanations DB (G), one DB (G) allowed
true observation.
introduce 9DB , i.e. set explanations relevant obs(DB)
9DB def
=
DB (G)
[

G2obs(DB)

fix enumeration S1; S2 ; : : : explanations 9DB . follows Proposition A.2,
uniqueness condition exclusiveness condition
PDB (Si ^ Sj ) = 0 6= j

PDB (S ) =
PDB (S )
X

29DB

X

X

G2obs(DB) 2

(G)
PDB (G)
DB

=
G2obs(DB)
= 1:
able introduce uniqueness condition exclusiveness condition
yet another random variable Xe, representing explanation G, defined
Xe (!) = k iff ! j= Sk ! 2
DB :
(6)
third condition concerns termination.

21.

X

G2obs(DB) PDB (G) = 1 guarantees measure f ! j ! j= Gk k ( 1)g one,
! satisfying Gk 's. case, put Yo (!) = 0. values set measure
zero affect part discussion follows. also applies definition Xe (6).
P

403

fiSato & Kameya

Finite support condition:

every G 2 obs(DB) DB (G) finite.
PDB (G) computed support set DB (G) = fS1 ; : : : ; Sm g (0 m),
help exclusiveness condition, finite summation mi=1 PF (Si). condition
prevents infinite summation hardly computable.
fourth condition simplifies probability computation multiplication. Recall
explanation G 2 obs(DB) conjunction a1 ^ 1 11 ^ abducibles
fa1; : : : ; amg F (1 m). order reduce computation PF (S ) = PF (a1 ^11 1^ am)
multiplication PF (a1) 1 11 PF (am ), assume
P

Distribution condition:

F set Fmsw ground atoms parameterized distribution Pmsw specified below.

atom msw(i,n,v) intended simulate multi-ary random switch whose name
whose outcome v trial n. generalization primitive probabilistic events
coin tossing dice rolling.
1. Fmsw consists probabilistic atoms msw(i,n,v). arguments i, n v ground
terms called switch name, trial-id value (of switch i), respectively.
assume finite set Vi ground terms called value set associated
i, v 2 Vi holds.
2. Write Vi fv1 ; v2 ; : : : ; vmg (m = jVi j). Then, one ground atoms f msw(i,n,v1),
msw(i,n,v2 ), . .. , msw(i,n,vm )g becomes exclusively true (takes value 1)
trial. i, parameter i;v 2 [0; 1] v2V i;v = 1 associated. i;v
probability msw(i,1,v) true (v 2 Vi).
3. ground terms i, i0 , n, n0, v 2 Vi v0 2 Vi0 , random variable msw(i,n,v)
independent msw(i0 ,n0 ,v0 ) n 6= n0 6= i0 .
words, introduce family parameterized finite distributions P(i;n)
P(i;n)(msw(i,n,v1 ) = x1 ; : : : ; msw(i,n,vm ) = xm j i;v ; : : : ; i;v )
x
x
mk=1 xk = 1
def
= 0i;v 1 11 i;v o.w.
(7)
P



(

1

1

1




P



= jVij, xk 2 f0; 1g (1 k m), define Pmsw infinite product
Pmsw def
= P(i;n) :


i;n

condition, compute Pmsw(S ), probability explanation S,
product parameters. Suppose msw(ij ,n,v) msw(ij0 ,n0,v0) different conjuncts
explanation = msw(i1 ,n1,v1 ) ^ 11 1^ msw(ik ,nk ,vk ). either j 6= j 0 n 6= n0 holds,
independent construction. Else j = j 0 n = n0 v 6= v 0,
independent Pmsw(S ) = 0 construction. result, whichever condition may hold,
Pmsw (S ) computed parameters.
404

fiParameter Learning Logic Programs Symbolic-statistical Modeling

4.3 Modeling Principle

point, introduced four conditions, uniqueness condition, exclusiveness condition, finite support condition distribution condition, simplify
probability computation. last one easy satisfy. adopt Fmsw together
Pmsw . So, on, always assume Fmsw parameterized distribution Pmsw
introduced previous subsection. Unfortunately rest satisfied automatically. According modeling experiences however, mildly dicult satisfy
uniqueness condition exclusiveness condition long obey following
modeling principle.
Modeling principle: DB = Fmsw [ R describes sequential decision process
(modulo auxiliary computations) uniquely produces observable atom
G 2 obs(DB) decision expressed msw atom.22
Translated programming level, says must take care writing program sample F 0 Pmsw, must uniquely exist goal G (G 2 obs(DB))
successful refutation DB0 = F 0 [ R. confirm principle
blood type program DBb = Fb [ Rb. describes process gene inheritance,
arbitrary sample Fb0 Pmsw, say Fb0 = fmsw(gene,father,a); msw(gene,mother,o)g,
exists unique goal, btype('A') case, successful SLD refutation
Fb0 [ Rb.
idea behind principle decision process always produces result (an
observable atom), different decision processes must differ msw thereby entailing
mutually exclusive observable atoms. uniqueness condition exclusiveness
condition automatically satisfied.
Satisfying finite support condition dicult virtually equivalent
writing program DB solution search G (G 2 obs(DB)) always terminates. Apparently general solution problem, far specific models
HMMs, PCFGs Bayesian networks concerned, met. programs
models satisfy finite support condition (and conditions well).

4.4 Four Conditions Revisited

subsection, discuss relax four simplifying conditions introduced Subsection 4.2 purpose exible modeling. first examine uniqueness condition
considering crucial role adaptation EM algorithm semantics.
uniqueness condition guarantees exists (many-to-one) mapping
explanations observations EM algorithm applicable (Dempster et al., 1977).
possible, however, relax uniqueness condition justifying application
EM algorithm. assume MAR (missing random) condition introduced
Rubin (1976) statistical condition complete data (explanation) becomes incomplete data (observation), customarily assumed implicitly explicitly
statistics (see Appendix B). assuming MAR condition, apply EM
22. Decisions made process finite subset Fmsw .
405

fiSato & Kameya

algorithm non-exclusive observations P (O) 1 uniqueness
condition seemingly destroyed.
Let us see MAR condition action simple example. Imagine walk along
road front lawn. occasionally observe state \the road dry
lawn wet". Assume lawn watered sprinkler running probabilistically.
program DBrl = Rrl [ Frl Figure 2 describes sequential process outputs
observation observed(road(x),lawn(y)) (\the road x lawn y")
x; 2 fwet; dryg.
Rrl = { observed(road(X),lawn(Y)):P

Frl

=

msw(rain,once,A),
( = yes, X = wet, = wet
; = no, msw(sprinkler,once,B),
( B = on, X = dry, = wet
; B = off, X = dry, = dry ) ). }
{ msw(rain,once,yes), msw(rain,once,no),
msw(sprinkler,once,on), msw(sprinkler,once,off) }

Figure 2: DBrl
basic distribution Frl specified like PF (1) Subsection 4.1, omit it.
msw(rain,once,A) program determines whether rains (A = yes) (A = no),
whereas msw(sprinkler,once,B) determines whether sprinkler works fine (B = on)
(B = off). Since sampled values = (a 2 fyes; nog) B = b
(b 2 fon; offg), uniquely exists observation observed(road(x),lawn(y)) (x; 2
fwet; dryg), many-to-one mapping : (a; b) = hx; yi. words,
apply EM algorithm observations observed(road(x),lawn(y)) (x; 2
fwet; dryg). would happen observe exclusively either state road
lawn? Logically, means observe 9y observed(road(x),lawn(y))
9x observed(road(x),lawn(y)). Apparently uniqueness condition met,
9y observed(road(wet),lawn(y)) 9x observed(road(x),lawn(wet)) compatible
(they true rains). Despite non-exclusiveness observations, still
apply EM algorithm MAR condition, case translates
observe either lawn road randomly regardless state.
brie check conditions. Basically relaxed cost
increased computation. Without exclusiveness condition instance, would need
additional process transforming support set DB (G) goal G set exclusive
explanations. instance, G explanations fmsw(a,n,v); msw(b,m,w)g,
transform fmsw(a,n,v); :msw(a,n,v) ^ msw(b,m,w)g on.23 Clearly,
transformation exponential number msw atoms eciency concern leads
assuming exclusiveness condition.
finite support condition practice equivalent condition SLD tree
G finite. relaxing condition might induce infinite computation.
b

23. :msw(a,n,v ) transformed disjunction exclusive msw atoms like
406

W

6

0
2 msw(a,n,v ).

v 0 =v;v 0 Va

fiParameter Learning Logic Programs Symbolic-statistical Modeling

Relaxing distribution condition accepting probability distributions
serve expand horizon applicability parameterized logic programs.
particular introduction parameterized joint distributions P (v1; : : : ; vk ) like Boltzmann distributions switches msw1 ; : : : ; mswk v1; : : : ; vk values switches,
makes correlated. distributions facilitate writing parameterized logic programs
complicated decision processes decisions independent interdependent. Obviously, hand, increase learning time, whether added
exibility distributions deserves increased learning time yet seen.
Pmsw

4.5 Naive Approach EM Learning

subsection, derive concrete EM algorithm parameterized logic programs
DB = Fmsw [ R assuming satisfy uniqueness condition, exclusiveness
condition finite support condition.
start, introduce Yo, random variable representing observations according
(5) based fixed enumeration observable atoms obs(DB). also introduce
another random variable Xe representing explanations according (6) based
fixed enumeration explanations 9DB . understanding Xe non-observable
Yo observable, joint distribution PDB (Xe = x; Yo = j )
denotes relevant parameters. immediate, following (1) (2) Section 2,
derive concrete EM algorithm Q function defined Q( j 0 ) def
= x PDB (x j
y; 0) ln PDB (x; j ) whose input random sample observable atoms whose output
MLE .
following, sake readability, substitute observable atom G (G 2
obs(DB)) Yo = write PDB (G j ) instead PDB (Yo = j ). Likewise
substitute explanation (S 2 9DB ) Xe = x write PDB (S; G j ) instead
PDB (Xe = x; Yo = j ). follows uniqueness condition
0
62 DB (G)
PDB (S; G j ) =
Pmsw (S j ) 2 DB (G):
need yet another notation here. explanation S, define count msw(i,n,v)

i;v (S ) def
= jf n j msw(i,n,v) 2 gj :
done preparations now. Suppose make observations G = G1 ; : : : ; GT
Gt 2 obs(DB) (1 ). Put
def
= fi j msw(i,n,v) 2 2 DB (Gt); 1 g
def
= fi;v j msw(i,n,v) 2 2 DB (Gt); 1 g:
set switch names appear explanation one Gt 's denotes
parameters associated switches. finite due finite support condition.
P

(

407

fiSato & Kameya

Various probabilities Q function computed using Proposition A.2
Appendix together assumptions follows.
PDB (Gt j ) = PDB
=
Pmsw (S j )
(8)
DB (Gt )
fi
fi
fi

_

Pmsw (S j )

=

Q( j 0 ) def
=

=

(i; v; ) def
=



t=1 S29DB
i2I;v2Vi

X
t=1

X

S2

i;v (S )
i;v

i2I;v2Vi

X
X

X



DB

(Gt )

PDB (S j Gt ; 0 ) ln PDB (S; Gt j )

(i; v; 0 )ln i;v

1

PDB (Gt j ) 2

X

i2I;v2Vi

X

DB

(Gt )

!
(i; v; 0 )
0
(i; v; ) ln P
0 0
v0 2Vi (i; v ; )

(9)

Pmsw (S j )i;v (S )

used Jensen's inequality obtain (9). Note PDB (Gt j )01 S2 (G )
Pmsw (S j )i;v (S ) expected count msw(i,1,v) SLD refutation Gt. Speaking
likelihood function L() = Tt=1 PDB (Gt j ), already shown Subsection 2.2
(footnote) Q( j 0 ) Q(0 j 0 ) implies L() L(0 ). Hence (9), reach
procedure learn-naive( ,G) finds MLE parameters. array
variable [i; v] stores (i; v; ) current .
P

DB



Q

DB

1:
2:
3:
4:
5:
6:

procedure

learn-naive(DB; G )

begin

Initialize appropriate values " small positive number ;
(0) := t=1 ln PDB (Gt j );
% Compute log-likelihood.
P

repeat
foreach

2 I; v 2 Vi

[i; v ] :=


X

1

PDB (Gt j ) 2
foreach 2 I; v 2 Vi
[i; v]
i;v := P
0;
0
v 2Vi [i; v ]
:= +P1;
(m) := Tt=1 ln PDB (Gt j )
(m) 0 (m01) < "

7:
8:
9:
10:
11:
12: end

t=1

X

DB

(Gt )

Pmsw (S j )i;v (S );

% Update parameters.
% Compute log-likelihood again.
% Terminate converged.

EM algorithm simple correctly calculates MLE , calculation PDB (Gt j ) [i; v](Line 3, 6 10) may suffer combinatorial explosion
explanations. is, j DB (Gt)j often grows exponentially complexity model.
instance, j DB (Gt)j HMM N states O(N L), exponential length L
input/output string. Nonetheless, suppressing explosion realize ecient computation polynomial order possible, suitable conditions, avoiding multiple
computations subgoal see next.
408

fiParameter Learning Logic Programs Symbolic-statistical Modeling

4.6 Inside Probability Outside Probability Logic Programs

subsection, generalize notion inside probability outside probability
(Baker, 1979; Lari & Young, 1990) logic programs. Major computations learn-naive( ,G)
two terms Line 6, PDB (Gt j ) S2 (G ) Pmsw(S j )i;v (S). Computational redundancy lurks naive computation terms. show example.
Suppose propositional program DBp = Fp [ Rp Fp = fa; b; c; d; mg
DB

P

DB

8
>
>
>
>
>
<

Rp = >
>
>
>
>
:

f
f
g
g
h



a^g
b^g
c
d^h
m:

(10)

f observable atom. assume a, b, c, independent also
fa; bg fc; dg pair-wise exclusive. support set f calculated
DB (f) = fa ^ c; ^ ^ m; b ^ c; b ^ ^ g:
Hence, light (8), may compute PDB (f)
PDB (f) = PF (a ^ c) + PF (a ^ ^ m) + PF (b ^ c) + PF (b ^ ^ m):
(11)
computation requires 6 multiplications (because PF (a ^ c) = PF (a)PF (c) etc.)
3 additions. hand, possible compute PDB (f) much eciently
factoring common computations. Let ground atom. Define inside probability
fi (A)
fi (A) def
= PDB (A j ):24
(12)
applying Theorem A.1 Appendix
comp(Rp) ` f $ (a ^ g) _ (b ^ g); g $ c _ (d ^ h); h $
(13)
unconditionally holds semantics, using independent exclusiveness assumption made Fp, following equations inside probability
derived.
fi (f) = fi (a)fi (g) + fi (b)fi (g)
fi (g) = fi (c) + fi (d)fi (h)
(14)
fi (h) = fi (m)
PDB (f)(= fi (f)) obtained solving (14) fi (f), 3 multiplications
2 additions required.
quite straightforward generalize (14) proceeding, look program
DBq = fmg [ fg:-m ^ m; g:-mg g observable atom msw atom.
g $ (m ^ m) _ semantics, compute P (g) = P (m)P (m) + P (m)
clearly wrong ignores fact clause bodies g, i.e. m^m mutually
exclusive, atoms clause body m^m independent (here P (1) = PDB (1)).
Similarly, set = b = c = = m, equation (14) totally incorrect.
p

p

p

p

p

p

p

p

p

p

p

8
>
<
>
:

p

q

24. Note fact F , fi (A) = Pmsw (A j ).

409

fiSato & Kameya

therefore add, temporarily subsection, two assumptions top exclusiveness condition finite support condition equations like (14) become
mathematically correct. first assumption \clause" bodies mutually exclusive i.e. two clauses B W B W 0 , PDB (W ^ W 0 j ) = 0,
second assumption body atoms independent, i.e. B1 ^ 1 1 1 ^ Bk rule,
PDB (B1 ^ 11 1 ^ Bk j ) = PDB (B1 j ) 11 1 PDB (Bk j ) holds.
Please note \clause" used subsection special meaning. intended
mean G G goal tabled explanation G obtained OLDT search
explained next subsection.25 words, additional
conditions imposed source program result OLDT search.
clauses auxiliary computations need satisfy them.
suppose clauses occur DB like



B1;1 ^ 1 1 1 ^ B1;i1

11 1

BL;1 ^ 11 1 ^ BL;iL

Bh;j (1 h L; 1 j ih) atom. Theorem A.1 Appendix
assumptions ensure


fi (A) = fi (B1;j ) + 1 11 + fi (BL;j ):
(15)
1


L


j =1

j =1

(15) suggests fi (Gt) considered function fi (A) equations
inside probabilities hierarchically organized way fi(Gt) belongs top
layer fi(A) appearing left hand side refers fi (B)'s belong
lower layers. refer condition acyclic support condition. acyclic
support condition, equations form (15) unique solution, computation
PDB (G j ) via inside probabilities allows us take advantage reusing intermediate
results stored fi (A), thereby contributing faster computation PDB (Gt j ).
Next tackle intricate problem, computation S2 (G ) Pmsw(S j
)i;v (S ). Since sum equals n msw(i,n,v )2S 2 (G ) Pmsw (S j ), concentrate
computation
(Gt; m) def
=
Pmsw (S j )
P

P

DB

P

DB





X

( )

m2S 2 DB Gt

= msw(i,n,v). First note explanation contains like = a1 ^1 11^
ah ^ m, fi (S ) = fi (a1 ) 1 1 1 fi (ah)fi (m). (Gt ; m) expressed
(Gt; m) = ff(Gt ; m)fi (m)

(16)
ff(Gt; m) = @@fi(G(m;)m) ff(Gt; m) depend fi (m). Generalizing observation arbitrary ground atoms, introduce outside probability ground atom
w.r.t. Gt
(Gt)
ff(Gt; A) def
= @fi
@fi (A)


25. logical relationship (13) corresponds (20) f, g h table atoms.
410

fiParameter Learning Logic Programs Symbolic-statistical Modeling

assuming conditions inside probability. view (16), problem computing (Gt; m) reduced computing ff(Gt; m), recursively computable
follows. Suppose occurs ground program DB like
B1
BK

^ W1;1 ; 11 1 ; B1

11 1

^ WK;1 ; 11 1 ; BK

^ W1;i1
^ WK;iK :

fi (Gt) function fi (B1 ); : : : ; fi(BK ) assumption, chain rule derivatives
leads
@fi (Gt )
@fi (A ^ WK;i )
@fi (Gt ) @fi (A ^ W1;1 )
+
11
1
+
ff(Gt ; A) =
@fi (B1 )
@fi (A)
@fi (BK )
@fi (A)
hence to26
ff(Gt; Gt ) = 1
(17)


ff(Gt ; A) = ff(Gt ; B1 ) fi (W1;j ) + 11 1 + ff(Gt ; BK ) fi (WK;j ):
(18)












K

1
X

K
X

j =1

j =1

Therefore inside probabilities already computed, outside probabilities
recursively computed top (17) using (18) downward along program layers.
case DBp f chosen atoms, compute
ff(f; f) = 1
ff(f; g) = fi (a) + fi (b)
(19)
ff(f; h) = ff(f; g)fi (d)
ff(f; m) = ff(f; h):
(19), desired sum (f; m) calculated
(f; m) = ff(f; m)fi (m) = (fi (a) + fi (b))fi (d)fi (m)
requires two multiplications one addition compared four multiplications
one addition naive computation.
Gains obtained computing inside outside probability may small case,
problem size grows, become enormous, compensate enough additional restrictions imposed result OLDT search.
8
>
>
>
<
>
>
>
:

4.7 OLDT Search

compute inside outside probability recursively like (15) (17) (18), need
programming level tabulation mechanism structure-sharing partial explanations
26. independence assumption body atoms, Wh;j (1 h K; 1 j ih )
independent. Therefore
@fi (A ^ Wh;j ) = @fi (A)fi (Wh;j ) = fi (W ):
h;j
@fi(A)
@fi (A)
411

fiSato & Kameya

subgoals. henceforth deal programs DB set table(DB) table
predicate declared advance. ground atom containing table predicate called
table atom. purpose table atoms store support sets eliminate
need recomputation, so, construct hierarchically organized explanations
made table atoms msw atoms.
Let DB = Fmsw [ R parameterized logic program satisfies finite support
condition uniqueness condition. Also let G1 ; G2; : : : ; GT random sample
observable atoms obs(DB). make following additional assumptions.

Assumptions:

(1 ), exists finite set f1t; : : : ; Kt g table atoms associated
(0 k K ; 1 j )
conjunctions Sk;j

k


e

comp(R)





` Gt $ S0t;1 _ 1 1 1 _ S0t;m
^ 1t $ S1t;1 _ 11 1 _ S1t;m ^ 1 11 ^ Kt $ SKt ;1 _ 11 1 _ SKt ;mKt
e



e

e

0

e





e

1

e

(20)




(0 k K ; 1 j ) is, set, subset F
Sk;j

msw [ fk+1 ; : : : ; K g
k
(acyclic support condition). convention, put 0 = Gt call respectively
def
(k 0) t-explanation
DB
= f0 ; 1t; : : : ; Kt g set table atoms Gt Sk;j
kt .27 set t-explanations k denoted DB (kt ) consider
DB (1) function table atoms.
^ St ) =
t-explanations mutually exclusive, i.e. k (0 k Kt ), PDB (Sk;j
k;j 0
0 (1 j 6= j 0 mk ) (t0exclusiveness condition).
(0 k K ; 1 j ) conjunction independent atoms (independent
Sk;j

k
condition).28
assumptions aimed ecient probability computation. Namely, acyclic
support condition makes dynamic programming possible, t-exclusiveness condition reduces PDB (A _ B) PDB (A)+ PDB (B) independent condition reduces PDB (A ^ B )
PDB (A)PDB (B). one point concerning eciency however. Note
29 imcomputation dynamic programming proceeds following partial order DB
posed acyclic support condition access table atoms much simplified
respecting said partial
linearly ordered. therefore topologically sort DB

order call linearized DB satisfying three assumptions (the acyclic support condition, t-exclusiveness condition independent condition) hierarchical system
= h ; ; : : : ; ( = G ) assuming
t-explanations Gt . write DB
0

DB (1)
0 1
K
30
implicitly given. hierarchical system t-explanations Gt successfully built
e



e



e

e

e

e

e



e

27. Prefix \t-" abbreviation \tabled-".
28. independence mentioned concerns positive propositions. B1 ; B2 2 head(DB), say
B1 B2 independent PDB (B1 ^ B2 j ) = PDB (B1 j )PDB (B2 j ) .
29. precedes j top-down execution w.r.t. DB invokes j directly indirectly.
30. holds precedes j < j .
412

fiParameter Learning Logic Programs Symbolic-statistical Modeling

source program, equations inside probability outside probability
(14) (19) automatically derived solved time proportional size
equations. plays central role approach ecient EM learning.
One way obtain t-explanations use OLDT search (Tamaki & Sato, 1986;
Warren, 1992), complete refutation method logic programs. OLDT search,
goal G called first time, set entry G solution table store
answer substitutions G there. call instance G0 G occurs later, stop
solving G0 instead try retrieve answer substitution G stored solution table
unifying G0 G. record remaining answer substitutions G, prepare
lookup table G0 hold pointer them.
self-containedness, look details OLDT search using sample program
DBh = Fh [Rh Figure 431 depicts HMM32 Figure 3. HMM two states
fs0; s1g. state transition, probabilistically chooses next destination fs0; s1g
a,b
s1

s0

a,b

a,b

a,b

Figure 3: Two state HMM
Fh

Rh

=

=

8
<
:
8
>
>
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
>
>
:

f1: values(init, [s0,s1]).
f2: values(out(_),[a,b]).
f3: values(tr(_), [s0,s1]).

h1: hmm(Cs):msw(init,once,Si),
hmm(1,Si,Cs).
h2: hmm(T,S,[C|Cs]):- T=<3,
msw(out(S),T,C),
msw(tr(S),T,NextS),
T1 T+1,
hmm(T1,NextS,Cs).
h3: hmm(T,_,[]):- T>3.

%
%
%
%
%
%
%
%
%

generate string (chars) Cs,
Set initial state Si,
Enter loop clock = 1.
Loop:
Output C state S.
Transit NextS.
Put clock ahead.
Continue loop (recursion).
Finish loop clock > 3.

Figure 4: Two state HMM program DBh
31. f1, f2, f3, h1, h2 h3 temporary marks, part program.
32. HMM defines probability distribution strings given set alphabets, works
stochastic string generator (Rabiner & Juang, 1993) output string sample
defined distribution.
413

fiSato & Kameya

also alphabet fa; bg emit. Note specify fact set Fh associated distribution compactly, introduce new notation values(i,[v1,...,vm]).
declares Fh contains msw atoms form msw(i,n,v) (v 2 fv1 ; : : : ; vmg) whose distribution P(i;n) given (7) Subsection 4.2. example, (f3), values(tr( ),[s0,s1])
introduces msw(tr(t),n,v) atoms program ground term,
v 2 fs0; s1g ground term n, distribution
x
P(tr(t);n) (msw(tr(t),n,s0) = x; msw(tr(t),n,s1) = j i;s0 ; i;s1) = i;s
0 i;s1
= tr(t), x; 2 f0; 1g x + = 1.
program runs like Prolog program. non-ground top-goal hmm(S), functions stochastic string generator returning list alphabets [a,b,a]
variable follows. top-goal calls clause (h1) (h1) selects initial state executing subgoal msw(init,once,Si)33 returns Si initial state probabilistically
chosen fs0, s1g. second clause (h2) called (h1) ground ground
T. makes probabilistic choice output alphabet C asking msw(out(S),T,C)
determines NextS, next state, asking msw(tr(S),T,NextS). (h3)
stop transition. simplicity, length output strings fixed three. way
execution termed sampling execution corresponds random sampling
PDB . top-goal ground like hmm([a,b,a]), works acceptor, i.e.
returning success (yes) failure (no).
explanations hmm([a,b,a]) sought for, keep msw atoms resolved upon
refutation conjunction (explanation), repeat process backtracking refutation found. need t-explanations however, backtracking must
abandoned sharing partial explanations t-explanations, purpose
t-explanations itself, becomes impossible. therefore instead use OLDT search
h

t1:
t2:
t3:
t4:
t4':
:
t7:
t8:
t9:

top_hmm(Cs,Ans):- tab_hmm(Cs,Ans,[]).
tab_hmm(Cs,[hmm(Cs)|X],X):- hmm(Cs,_,[]).
tab_hmm(T,S,Cs,[hmm(T,S,Cs)|X],X):- hmm(T,S,Cs,_,[]).
e_msw(init,T,s0,[msw(init,T,s0)|X],X).
e_msw(init,T,s1,[msw(init,T,s1)|X],X).
hmm(Cs,X0,X1):- e_msw(init,once,Si,X0,X2), tab_hmm(1,Si,Cs,X2,X1).
hmm(T,S,[C|Cs],X0,X1):T=<3, e_msw(out(S),T,C,X0,X2), e_msw(tr(S),T,NextS,X2,X3),
T1 T+1, tab_hmm(T1,NextS,Cs,X3,X1).
hmm(T,S,[],X,X):- T>3.

Figure 5: Translated program DBh
33. msw(i,n,V) called ground ground n, V, logical variable, behaves like random variable.
instantiated term v probability i;v selected value set Vi declared values
atom. If, hand, V ground term v called, procedural semantics msw(i,n,v)
equal msw(i,n,V) ^ V = v.
414

fiParameter Learning Logic Programs Symbolic-statistical Modeling

t-explanation search. case HMM program example, build hierarchical
system t-explanations hmm([a,b,a]) OLDT search, first declare hmm=1
hmm=3 table predicate.34 t-explanation conjunction hmm=1 atoms, hmm=3
atoms msw atoms. translate program another logic program, analogously translation definite clause grammars (DCGs) Prolog (Sterling & Shapiro,
1986). add two arguments (which forms D-list) predicate purpose
accumulating msw atoms table atoms conjuncts t-explanation. translation
applied DBh yields program Figure 5.
translated program, clause (t1) corresponds top-goal hmm(l)
input string l, t-explanation table atom hmm(l) returned Ans. (t2)
(t3) auxiliary clauses add callee's D-list table atom form hmm(l)
hmm(t,s,l) respectively (t: time step, s: state). general, p=n table predicate
original program, p=(n + 2) becomes table predicate translated program
auxiliary predicate tab p=(n +2) inserted signal OLDT interpreter check
solution table p=n, i.e. check already exist t-explanations p=n. Likewise
clauses (t4) (t4') pair corresponding (f1) insert msw(init,T,1)
callee's D-list = once. Clauses (t7), (t8) (t9) respectively correspond (h1),
(h2) (h3).
hmm([a,b,a]):[hmm([a,b,a])]
[ [msw(init,once,s0), hmm(1,s0,[a,b,a])],
[msw(init,once,s1), hmm(1,s1,[a,b,a])] ]
hmm(1,s0,[a,b,a]):[hmm(1,s0,[a,b,a])]
[ [msw(out(s0),1,a), msw(tr(s0),1,q0), hmm(2,s0,[b,a])],
[msw(out(s0),1,a), msw(tr(s0),1,s1), hmm(2,s1,[b,a])] ]
hmm(1,s1,[a,b,a]):[hmm(1,s1,[a,b,a])]
[ [msw(out(s1),1,a), msw(tr(s1),1,s0), hmm(2,s0,[b,a])],
[msw(out(s1),1,a), msw(tr(s1),1,s1), hmm(2,s1,[b,a])] ]
hmm(2,s0,[b,a]):[hmm(2,s0,[b,a])]
[ [msw(out(s0),2,b), msw(tr(s0),2,s0), hmm(3,s0,[a])],
[msw(out(s0),2,b), msw(tr(s0),2,s1), hmm(3,s1,[a])] ]
hmm(2,s1,[b,a]):[hmm(2,s1,[b,a])]
[ [msw(out(s1),2,b), msw(tr(s1),2,s0), hmm(3,s0,[a])],
[msw(out(s1),2,b), msw(tr(s1),2,s1), hmm(3,s1,[a])] ]
hmm(3,s0,[a]):[hmm(3,s0,[a])]
[ [msw(out(s0),3,a), msw(tr(s0),3,s0), hmm(4,s0,[])],
[msw(out(s0),3,a), msw(tr(s0),3,s1), hmm(4,s1,[])] ]
hmm(3,s1,[a]):[hmm(3,s1,[a])]
[ [msw(out(s1),3,a), msw(tr(s1),3,s0), hmm(4,s0,[])],
[msw(out(s1),3,a), msw(tr(s1),3,s1), hmm(4,s1,[])] ]
hmm(4,s0,[]):[hmm(4,s0,[])]
[[]]
hmm(4,s1,[]):[hmm(4,s1,[])]
[[]]

Figure 6: Solution table
34. general, p=n means predicate p arity n. although hmm=1 hmm=3 share predicate name
hmm, different predicates.
415

fiSato & Kameya

translation, apply OLDT search top hmm([a,b,a],Ans) noting (i) added D-list uence OLDT procedure, (ii) associate
solution table atom solution table list t-explanations. resulting
solution table shown Figure 6. first row reads call hmm([a,b,a]) occurred entered solution table solution, hmm([a,b,a]) (no variable binding generated), two t-explanations, msw(init,once,s0) ^ hmm(1,s0,[a,b,a])
msw(init,once,s1) ^ hmm(1,s1,[a,b,a]). remaining task topological sorting table atoms stored solution table respecting acyclic support condition.
done using depth-first search (trace) t-explanations top-goal
example. Thus obtain hierarchical system t-explanations hmm([a,b,a]).

4.8 Support Graphs

Looking back, need compute inside outside probability hierarchical system
t-explanations, essentially boolean combination primitive events (msw atoms)
compound events (table atoms) intuitively representable
graph. reason, help visualizing learning algorithm, introduce new
data-structure termed support graphs, though new EM algorithm next subsection
described solely hierarchical system t-explanations.
illustrated Figure 7 (a), support graph Gt graphical representation
= h ; ; : : : ; ( = G ) G (20).
hierarchical system t-explanations DB


0 1
0
K
consists totally ordered disconnected subgraphs, labeled
(0 k K ). subgraph labeled comprises two
corresponding table atom kt DB

k
special nodes (the start node end node) explanation graphs, corresponding


t-explanation Sk;j
DB (k ) (1 j mk ).
linear graph node labeled either
explanation graph Sk;j
. called table node switch
table atom switch msw(1,1,1) Sk;j
node respectively. Figure 7 (b) support graph hmm([a,b,a]) obtained
solution table Figure 6. table node labeled refers subgraph labeled ,
data-sharing achieved distinct table nodes referring subgraph.


e

e

e

e

4.9 Graphical EM Algorithm

describe ecient EM learning algorithm termed graphical EM algorithm
(Figure 8) introduced Kameya Sato (2000), runs support graphs. Suppose
random sample G = G1; : : : ; GT observable atoms. Also suppose support
graphs Gt (1 ), i.e. hierarchical systems t-explanations satisfying acyclic
support condition, t-exclusiveness condition independent condition,
successfully constructed parameterized logic program DB satisfying uniqueness
condition finite support condition.
graphical EM algorithm refines learn-naive( ,G ) introducing two subroutines,
get-inside-probs(
, G ) compute inside probabilities get-expectations(
, G ) compute outside probabilities. called main routine learn-gEM( ,G ).
learning, prepare four arrays support graph Gt G :
P [t; ] inside probability , i.e. fi ( ) = PDB ( j ) (see (12))
DB

DB

DB

DB

416

fiParameter Learning Logic Programs Symbolic-statistical Modeling
k

(a)

explanation graph

msw

Gt:
start

k

msw

end

msw

msw

msw

:
k :
start

end
msw

msw

:

(b)
msw(init,once,s0)

hmm(1,s0,[a,b,a])

hmm([a,b,a]):

start

end

msw(init,once,s1)

msw(out(s0),1,a)

hmm(1,s1,[a,b,a])

msw(tr(s0),1,s0)

hmm(2,s0,[b,a])

hmm(1,s0,[a,b,a]):

end

start

msw(out(s0),1,a)

msw(tr(s0),1,s1)

hmm(2,s1,[b,a])

msw(out(s1),1,a)

msw(tr(s1),1,s0)

hmm(2,s0,[b,a])

hmm(1,s1,[a,b,a]):

end

start

msw(out(s1),1,a)

msw(tr(s1),1,s1)

hmm(2,s1,[b,a])

Figure 7: support graph (a) general form, (b) Gt = hmm([a,b,a]) HMM
program DBh. double-circled node refers table node.
Q[t; ] outside probability w.r.t. Gt , i.e. ff(Gt; ) (see (17) (18))
R[t; ; ] explanation probability (2 DB (kt )), i.e. PDB (S j )
e

e

417

e

e

fiSato & Kameya
1: procedure learn-gEM (DB; G )
2: begin
3: Select initial
4:
5:
6:
7:
8:
9:

1: procedure get-inside-probs (DB; G )
2: begin
3: := 1 begin
4:
Let 0t = Gt;
5:
k := Kt downto 0 begin
6:
P [t; kt ] := 0;
7:
foreach Se 2 eDB (kt ) begin
8:
Let Se = fA1 ; A2 ; : : : ; AjSejg;
9:
R[t; kt ; Se] := 1;
10:
l := 1 jSej
11:
Al = msw(i,1,v )
12:
R[t; kt ; Se] 3 = i;v
13:
else R[t; kt ; Se] 3 = P [t; Al ];
14:
P [t; kt ]+= R[t; kt ; Se]
15:
end /* foreach Se */
16:
end /* k */
17: end /* */
18: end.

parameters;

get-inside-probs
(DB; G);
P
(0) := Tt=1 ln P [t; Gt ];
repeat

get-expectations (DB; G );
2 I; v 2 Vi
[i; vP
] :=
[t; i; v]=P [t; G ];

t=1
foreach 2 I; v P
2 Vi
i;v := [i; v]= v0 2Vi [i; v0 ];
get-inside-probs (DB; G );
:= +
1;
P
(m) := Tt=1 ln P [t; Gt ]
(m) 0 (m01) < "
foreach

10:
11:
12:
13:
14:
15:
16: end.

1: procedure get-expectations (DB; G ) begin
2: := 1 begin
3:
foreach 2 I; v 2 Vi [t; i; v] := 0;
4:
Let 0t = Gt; Q[t; 0t] := 1:0;
5:
k := 1 Kt Q[t; kt ] := 0;
6:
k := 0 Kt
7:
foreach Se 2 eDB (kt ) begin
8:
Let Se = fA1 ; A2 ; : : : ; AjSejg;
9:
l := 1 jSej
10:
Al = msw(i,1,v ) [t; i; v] += Q[t; kt ] 1 R[t; kt ; Se]
11:
else Q[t; Al ] += Q[t; kt ] 1 R[t; kt ; Se]=P [t; Al ]
12:
end /* foreach Se */
13: end /* */
14: end.

Figure 8: graphical EM algorithm.
[t; i; v] expected count msw(i,1,v), i.e.

P

S2

DB

(Gt) Pmsw (S j )i;v (S )

call procedure learn-gEM( ,G) Figure 8. main routine learn-gEM( ,G) initially computes inside probabilities (Line 4) enters loop get-expectations( ,G )
called first compute expected count [t; i; v] msw(i,1,v) parameters updated (Line 11). Inside probabilities renewed using updated parameters
entering next loop (Line 12).
DB

DB

DB

418

fiParameter Learning Logic Programs Symbolic-statistical Modeling

subroutine get-inside-probs( ,G ) computes inside probability fi ( ) = PDB ( j )
(and stores P [t; ]) table atom bottom layer topmost layer 0 =
Gt (Line 4) hierarchical system t-explanations Gt (see (20) Subsection 4.6).
takes t-explanation DB (kt ) one one (Line 7), decomposes conjuncts
multiplies inside probabilities either known (Line 12) already computed
(Line 13).
subroutine get-expectations( ,G ) computes outside probabilities following
recursive definitions (17) (18) Subsection 4.6 stores outside probability
ff(Gt; ) table atom Q[t; ]. first sets outside probability top-goal
0 = Gt 1:0 (Line 4) computes rest outside probabilities (Line 6) going
layers t-explanation Gt described (20) Subsection 4.6. (Line 10) adds
Q[t; kt ] 1 R[t; kt ; ] = ff(Gt ; kt ) 1 fi(S ) [t; i; v], expected count msw(i,1,v),
contribution msw(i,1,v) kt [t; i; v]. (Line 11) increments outside
probability Q[t; Al ] = ff(Gt; Al ) Al according equation (18). Notice Q[t; kt ]
already computed R[t; kt ; S]=P [t; Al ] = fi(W ) = Al ^ W . shown
Subsection 4.5, learn-naive( ,G ) MLE procedure, hence following theorem holds.
Theorem 4.1 Let DB parameterized logic program, G = G1; : : : ; GT ranDB

e

e

e

DB

e

e

e

e

e

DB

dom sample observable atoms. Suppose five conditions (uniqueness, finite support
(Subsection 4.2), acyclic support, t-exclusiveness independence (Subsection 4.7))
met. ThenQlearn-gEM (DB; G ) finds MLE 3 (locally) maximizes likelihood
L(G j ) = Tt=1 PDB (Gt j ).

(Proof) Sketch.35 Since main routine learn-gEM( ,G ) learn-naive( ,G)
except computation [i; v] = Tt=1 [t; i; v], show [t; i; v] = S2 (G ) Pmsw(S j
)i;v (S ) (= n msw(i,n,v )2S2 (G ) Pmsw (S j )). However,
DB

P

P

DB

P

DB

[t; i; v]

DB

P

=

X

X

0kKt





X

n msw(i,n,v )2Se2 e ( )
DB k

ff(Gt ; kt )fi (Se)

(see (Line 10) get-expectations(DB; G))
= ff(Gt; msw(i,n,v))fi(msw(i,n,v))
n
= (Gt; msw(i,n,v)) (see equation (16))
n
=
Pmsw (S j ):
Q.E.D.
X

X

X

X

n msw(i,n,v )2S2

DB

(Gt )

used fact contains msw(i,n,v) like = S0 ^ msw(i,n,v), fi(S) =
fi (S 0 )fi (msw(i,n,v )) holds, hence
ff(Gt ; kt )fi (S ) = ff(Gt ; kt )fi (S 0 )fi (msw(i,n,v ))
= (contribution msw(i,n,v) kt ff(Gt; msw(i,n,v)))fi (msw(i,n,v)):
e

e

e

e

e

e

e

e

35. formal proof given Kameya (2000). proved common parameters , [i; v]
learn-naive(DB,G ) coincides [i; v] learn-gEM(DB,G ). So, parameters updated
values. Hence, starting initial values, parameters converge
values.
419

fiSato & Kameya

five conditions applicability graphical EM algorithm may look hard
satisfy once. Fortunately, modeling principle Section 4.3 still stands,
due care modeling, likely lead us program meets them. Actually,
see next section, programs standard symbolic-statistical frameworks
Bayesian networks, HMMs PCFGs satisfy five conditions.
5. Complexity

section, analyze time complexity graphical EM algorithm applied
various symbolic-statistical frameworks including HMMs, PCFGs, pseudo PCSGs
Bayesian networks. results show graphical EM algorithm competitive
specialized EM algorithms developed independently research field.

5.1 Basic Property

Since EM algorithm iterative algorithm since unable predict
converges, measure time complexity time taken one iteration. therefore
estimate time per iteration repeat loop learn-gEM (DB; G) (G = G1 ; : : : ; GT ).
observe one iteration, support graph Gt (1 ) scanned twice,
get-inside-probs (DB; G ) get-expectations (DB; G). scan, addition
performed t-explanations, multiplication (possibly division) performed
msw atoms table atoms each. time spent Gt per iteration
graphical EM algorithm linear size support graph, i.e. number nodes
support graph Gt. Put
1tDB def
=
DB ( )
e

[

e


2DB

num def
= 1max
j1e j
tT DB
maxsize def
=
max
jSej:

e
e
1tT;S 21DB
set table atoms G , hence 1t set t-explanations
Recall DB

DB
appearing right hand side (20) Subsection 4.7. num maximum number
t-explanations support graph Gt's maxsize maximum size texplanation Gt's respectively. following obvious.
e

Proposition 5.1 time complexity graphical EM algorithm per iteration linear

total size support graphs, (nummaxsize ) notation, coincides
space complexity graphical EM algorithm runs support graphs.

rather general result, compare graphical EM algorithm
EM algorithms, must remember input graphical EM algorithm
support graphs (one observed atom) actual total learning time
OLDT time + (the number iterations) 2O(nummaxsizeT )
420

fiParameter Learning Logic Programs Symbolic-statistical Modeling

\OLDT time" denotes time construct support graphs G . sum
time OLDT search time topological sorting table atoms,
latter part former order-wise,36 represent \OLDT time" time OLDT
search. Also observe total size support graphs exceed time OLDT
search G order-wise.
evaluate OLDT time specific class models HMMs, need know
time table operations. Observe OLDT search paper special
sense table atoms always ground called resolution solved
goals. Accordingly solution table used
check goal G already entry solution table, i.e. called
before,
add new searched t-explanation G list discovered t-explanations
G's entry.
time complexity operations equal table access depends
program implementation solution table.37 first suppose
programs carefully written way arguments table atoms used indecies table access integers. Actually programs used subsequent complexity
analysis (DBh Subsection 4.7, DBg DBg0 Subsection 5.3, DBG Subsection 5.5)
satisfy satisfy condition replacing non-integer terms appropriate integers. also suppose solution table implemented using array table
access done O(1) time.38
follows, present detailed analysis time complexity graphical
EM algorithm applied HMMs, PCFGs, pseudo PCSGs Bayesian networks, assuming
O(1) time access solution table. remark way space complexity
total size solution tables (support graphs).


5.2 HMMs

standard EM algorithm HMMs Baum-Welch algorithm (Rabiner, 1989; Rabiner & Juang, 1993). example HMM shown Figure 3 Subsection 4.7.39 Given
observations w1 ; : : : ; wT output string length L, computes (N 2 LT ) time
iteration forward probability fftm(q) = P (ot1 ot2 1 11 otm01; q j ) backward
probability fimt (q) = P (otm otm+1 1 1 1 otL j q; ) state q 2 Q, time step (1 L)
string wt = ot1 ot2 11 1 otL (1 ), Q set states N number
states. factor N 2 comes fact every state N possible destinations

36. Think OLDT search top-goal Gt . searches msw atoms table atoms create solution table, auxiliary computations. Therefore time complexity never less
O(jthe number msw atoms table atoms support graph Gt j), coincides
time need topologically sort table atoms solution table depth-first search 0 = Gt .
37. Sagonas et al. (1994) Ramakrishnan et al. (1995) discuss implementation OLDT.
38. arrays available, may able use balanced trees, giving O(log n) access time n
number data solution table, may able use hashing, giving average (1) time
access certain condition (Cormen, Leiserson, & Rivest, 1990).
39. treat \state-emission HMMs" emit symbol depending state. Another type,
\arc-emission HMMs" emitted symbol depends transition arc, treated similarly.
421

fiSato & Kameya

compute forward backward probability every destination every
state. computing ffmt (q)'s fimt (q)'s, parameters updated. So, total
computation time iteration Baum-Welch algorithm estimated O(N 2LT )
(Rabiner & Juang, 1993; Manning & Schutze, 1999).
compare result graphical EM algorithm, use HMM program
DBh Figure 4 appropriate modifications L, length string, Q,
state set, declarations Fh output alphabets. string w = o1o2 11 1 oL,
hmm(n,q ,[om ; om+1 ; : : : ; oL ]) DBh reads HMM state q 2 Q time n
output [om ,om+1 ,...,oL] reaches final state. declaring hmm=1
hmm=3 table predicate translation (see Figure 5), apply OLDT search goal
top hmm([o1,...,oL ],Ans) w.r.t. translated program obtain t-explanations
hmm([o1,...,oL]). complexity argument however, translated program
DBh same, talk terms DBh sake simplicity. search,
fix search strategy multi-stage depth-first strategy (Tamaki & Sato, 1986).
assume solution table accessible O(1) time.40 Since length list
third argument hmm=3 decreases one recursion, finitely
many choices state transition output alphabet, search terminates, leaving
finitely many t-explanations solution table like Figure 6 satisfy acyclic support condition respectively. Also sampling execution hmm(L) w.r.t. DBh nothing
sequential decision process decisions made msw atoms exclusive,
independent generate unique string, means DBh satisfies t-exclusiveness
condition, independence condition uniqueness condition respectively. So,
graphical EM algorithm applicable set hierarchical systems t-explanations
hmm(wt ) (1 ) produced OLDT search observations w1 ; : : : ; wT output
string. Put wt = ot1 ot2 1 11 otL. follows

DB
= fhmm(m,q,[otm ,...,otL]) j 1 L + 1; q 2 Qg [ fhmm([ot1,...,otL])g
h

DBh

(

(

msw(out(q),m,om ); msw(tr(q),m,q 0);
hmm(m + 1,q0 ,[otm+1 ,...,otL ])

fi
fi
fi
fi
fi

)

) =
(1 L)
top-goal hmm([ot1 ,...,otL]), O(NL) calling patterns hmm=3
call causes N calls hmm=3, implying occur O(NL 1 N ) = O(N 2L)
calls hmm=3. Since call computed due tabling mechanism,
num = O(N 2 L). Also maxsize = 3. Applying Proposition 5.1, reach
e

hmm(m,q ,[otm ,...,otL ])

q0 2 Q

Proposition 5.2 Suppose strings length L. Also suppose
table operation
2

OLDT search done (1) time. OLDT time DBh O(N LT ) graphical
EM algorithm takes O(N 2 LT ) time per iteration N number states.

O(N 2LT ) time complexity Baum-Welch algorithm.
algorithm runs eciently Baum-Welch algorithm.41

graphical EM

40. O(1) possible translated program DBh Section 4.7, identify goal pattern
hmm(1,1,1,1,1) first two arguments constants (integers).
41. Besides, Baum-Welch algorithm graphical EM algorithm whose input support graphs
generated DBh update parameters value initial values same.
422

fiParameter Learning Logic Programs Symbolic-statistical Modeling

way, Viterbi algorithm (Rabiner, 1989; Rabiner & Juang, 1993) provides
HMMs ecient way finding likely transition path given input/output
string. similar algorithm parameterized logic programs determines
likely explanation given goal derived. runs time linear size
support graph, thereby O(N 2 L) case HMMs, complexity Viterbi
algorithm (Sato & Kameya, 2000).

5.3 PCFGs

compare graphical EM algorithm Inside-Outside algorithm (Baker,
1979; Lari & Young, 1990). Inside-Outside algorithm well-known EM algorithm
PCFGs (Wetherell, 1980; Manning & Schutze, 1999).42 takes grammar Chomsky
normal form. Given N nonterminals, production rule grammar takes form
! j; k (1 i; j; k N ) (nonterminals named numbers 1 N 1
starting symbol) form ! w 1 N w terminal. iteration,
computes inside probability outside probability every partial parse tree
given sentence update parameters production rules. Time complexity
measured time per iteration, described N , number nonterminals,
L, number terminals sentence. O(N 3 L3T ) observed sentences (Lari
& Young, 1990).
compare graphical EM algorithm Inside-Outside algorithm, start
propositional program DBg = Fg [ Rg representing largest grammar
containing possible rules ! j; k N nonterminals nonterminal 1 starting
symbol, i.e. sentence.
Fg
Rg

d,d0],[j ,k]) j 1 i; j; k N; d; d0 numbersg
= fmsw([if,[msw(
i,d,w ) j 1 N; number; w terminalg

=

8
>
<
>
:



q(i,d0,d2 ) :- msw(i,[d0,d2 ],[j ,k ]),
q(j ,d0,d1 ),
q(k ,d1 ,d2).
n

q(i,d,d +1) :- msw(i,d,wd+1 ).

fi
fi
fi

fi
fi
fi
fi
fi
fi
fi

1 i; j; k N;
0 d0 < d1 < d2 L

1 N; 0 L 0 1

9
>
=
>
;



Figure 9: PCFG program DBg
DB g artificial parsing program whose sole purpose measure size
OLDT tree43 created OLDT interpreter parses sentence w1 w2 1 11 wL.
42. PCFG (probabilistic context free grammar) backbone CFG probabilities (parameters) assigned production rule. nonterminal
n production rules fA ! ffi j 1 ng,
P
probability pi assigned ! ffi (1 n) ni=1 pi = 1. probability sentence
sum probabilities (leftmost) derivation s. latter product probabilities
rules used derivation.
43. precise, OLDT structure, case, tree DBg contains constants
(Datalog program) never occurs need creating new root node.
423

fiSato & Kameya
(1)

Td

q(1,d,L)
2 j N

2 k N
q(1,d,d+1),
q(1,d+1,L)

q(1,d+1,L)
(1)

[Note] q
1

2 k N

q(1,d,d+1),
q(k,d+1,L)

q(j,d,d+1),
q(1,d+1,L)

q(j,d,d+1),
q(k,d+1,L)

q(k,d+1,L)

q(1,d+1,L)

q(k,d+1,L)

(k)

Td+1
q(i,d,d) already appears
d+1 L, 1
d-d L-d-2

Td+1

d+2 e L-1
1 j N

2 k N
q(j,d,e),
q(1,e,L)

q(j,d,e),
q(k,e,L)

d+2 e e
1 N,
1 j N,

q(i,d,e),
q(j,e,e),
q(1,e,L)

Td

q(k,e,L)

N

q

N

q(j,e,e),
q(1,e,L)
q(1,e,L)

...
p(i)

p(1) p(2) p(N)

Figure 10: OLDT tree query

q(1,d,L)

input sentence w1 w2 11 1 wL embedded program separately msw(i,d,wd+1)
(0 L0 1) second clauses Rg (this treatment affect complexity argument). q(i,d0,d1) reads i-th nonterminal spans position d0 position d1,
i.e. substring wd +1 1 11 wd . first clauses q(i,d0 ,d2 ) :- msw(1,1,1), q(j ,d0 ,d1),
q(k,d1 ,d2) supposed textually ordered according lexicographic order
tuples hi; j; k; d0 ; d2 ; d1i. parser, top-goal set q(1,0,L).44 asks
parser parse whole sentence w1 w2 1 1 1 wL syntactic category \1" (sentence).
make exhaustive search query OLDT search.45 before, multistage depth-first search strategy O(1) time access solution table assumed.
time complexity OLDT search measured number nodes
OLDT tree. Let Td(k) OLDT tree q(k,d,L). Figure 10 illustrates Td(1)
(0 L 0 3) msw atoms omitted. seen, tree many similar
subtrees, put together (see Note Figure 10). Due depth-first strategy,
Td(1) recursive structure contains Td(1)
+1 subtree. Nodes whose leftmost atom
underlined solution nodes, i.e. solve leftmost atoms first time
entire refutation process. underlined atoms already computed subtrees
left.46 check solution table entries (= already
0

1

44. L Prolog variable constant denoting sentence length.
45. q table predicate.
0 00
0
46. inductively proved Td(1)
+1 contains every computed q(i,d ,d ) (0 L 0 3; + 1 <
d00 L; 1 N; d00 0 d0 L 0 0 2).
424

fiParameter Learning Logic Programs Symbolic-statistical Modeling

computed) O(1) time. Since clauses ground, execution generates
single child node.
(1)
(k)
enumerate h(1)
, number nodes Td Td+1 (1 k N ).
(k)
3
2 47
Figure 10, see h(1)
= O(N (L 0 d) ). Let hd (2 k N ) number nodes
k)
Td(+1
contained Td(1)+1. estimated O(N 2 (L 0 0 2)). Consequently, number
(k)
N
3
2
nodes newly created Td(1) h(1)
+ k=2 hd = (N (L 0 d) ). result,
L
0
3
3
3
48
total time OLDT search computed d=0 hd = O(N L ) also size
support graph.
consider non-propositional parsing program DBg0 = Fg0 [ Rg0 Figure 11
whose ground instances constitute propositional program DBg . DBg0 probabilistic
variant DCG program (Pereira & Warren, 1980) q'/1, q'/6 between/3
declared table predicate. Semantically DBg0 specifies probability distribution
atoms form fq'(l) j l list terminalsg.
P

P

Fg0

Rg0

t,[sj ,sk ]) j 1 i; j; k N; numberg
= fmsw([sfi,msw(
si ,t,w) j 1 N; number; w terminalg

=

8
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
:

q'(S) :- length(S,D), q'(s1 ,0,D,0, ,S-[]).
q'(I,D0,D2,C0,C2,L0-L2) :- between(D0,D1,D2),
msw(I,C0,[J,K]),
q'(J,D0,D1,s(C0),C1,L0-L1),
q'(K,D1,D2,s(C1),C2,L1-L2).
q'(I,D,s(D),C0,s(C0),[W|X]-X) :- msw(I,C0,W).

Figure 11: Probabilistic DCG like program DBg0
top-goal parse sentence = [w1; : : : ; wL] q'([w1; : : : ; wL]). invokes
q'(s1 ,0,D,0, ,[w1 ,: : :,wL ]-[]) measuring length input sentence
calling length=2. 49 50 general, q'(i,d0,d2 ,c0 ,c2 ,l0-l2) works identically q(i,d0 ,d2 )
three arguments, c0 , c2 l0-l2, added. c0 supplies unique trial-id msws
used body, c2 latest trial-id current computation, l0 -l2 D-list holding
substring d0 d2 . Since added arguments affect shape

47. focus subtree Td0 . j , i0 j 0 range 1 N , fif(e; e0 ) j + 2 e0 < e L 0 1 gfi =
O((L 0 d)2 ). Hence, number nodes Td0 O(N 3 (L 0 d)2 ). number nodes Td(1)
(1)
0
neither Td(1)
= (N 3 (L 0 d)2 ).
+1 Td negligible, therefore hd
(1)
(1)
48. number nodes TL01 TL02 negligible.
49. make program simple possible, assume integer n represented ground term
fi

(n)
z }| {

fi

s(1 1 1s (0)1 1 1). also assume D0 D2 ground, goal between(D0, D1, D2)
returns integer D1 time proportional jD1 0 D0j.
50. omit obvious program length(l,sn ) computes length sn list l O(jlj) time.

sn =

def

425

fiSato & Kameya

search tree Figure 10 extra computation caused length=2 O(L)
one insertion between(D0,D1,D2) O(NL3) respectively,51 OLDT time remains
O(N 3 L3), hence size support graph.
apply graphical EM algorithm correctly, need confirm five conditions
applicability. rather apparent however OLDT refutation topgoal form q'([w1 ,: : :,wL]) w.r.t. DBg0 terminates, leaves support graph
satisfying finite support condition acyclic support condition. t-exclusiveness
condition independent condition also hold refutation process faithfully
simulates leftmost stochastic derivation w1 11 1 wL choice production
rule made msw(si ,sc,[sj ,sk ]) exclusive independent (trial-ids different
different choices).
remains uniqueness condition. confirm it, let us consider another program DBg00 , modification DBg0 first goal length(S,D) body
first clause first goal between(D0,D1,D2) second clause Rg0 moved
last position bodies respectively. DBg00 DBg0 logically equivalent,
semantically equivalent well viewpoint distribution semantics. think
sampling execution OLDT interpreter top-goal q'(S) w.r.t. DBg00
variable, using multi-stage depth-first search strategy. easy see first
execution never fails, second OLDT refutation terminates, sentence
[w1 ; : : : ; wL ] returned S, third conversely, set msw atoms resolved upon
refutation uniquely determines output sentence [w1 ; : : : ; wL].52 Hence,
sampling execution guaranteed always terminate, every sampling PF 00 (= PF 0 )
uniquely generates sentence, observable atom, uniqueness condition satisfied
DBg00 , hence DBg0 .
sampling execution guaranteed always terminate? words,
grammar generate finite sentences? Giving general answer seems
dicult, known parameter values PCFG obtained learning
finite sentences, stochastic derivation PCFG terminates probability
one (Chi & Geman, 1998). summary, assuming appropriate parameter values,
say parameterized logic program DBg0 largest PCFG N nonterminal
symbols satisfies applicability conditions, OLDT time sentence length
L O(N 3 L3)53 also size support graph. Proposition 5.1,
conclude
g

g

Proposition 5.3 Let DB a0 parameterized logic program representing PCFG N

nonterminals form DBg Figure 11, G = G1 ; G2 ; : : : ; GT sampled atoms
representing sentences length L. suppose table operation OLDT search done
O(1) time. OLDT search G one iteration learn-gEM respectively
done O(N 3 L3T ) time.

51.

between(D0,D1,D2)

called O(N (L 0 d)2 ) times Td(1) . called

0 O(N (L 0 d)2 ) = O(NL3 )

PL 3
d=0

times .
52. trial-ids used refutation record rule used step derivation
w1 1 1 1 wL .
53. DBg , represent integers ground terms made 0 s(1) keep program short.
use integers instead ground terms however, first three arguments q'(1,1,1,1,1,1) enough
check whether goal previously called not, check done O(1) time.
(1)
0

0

426

fiParameter Learning Logic Programs Symbolic-statistical Modeling
(N 3 L 3 )

also time complexity Inside-Outside algorithm per iteration
(Lari & Young, 1990), hence algorithm ecient Inside-Outside algorithm.

5.4 Pseudo PCSGs

PCFGs improved making choices context-sensitive, one attempts
pseudo PCSGs (pseudo probabilistic context sensitive grammars) rule chosen probabilistically depending nonterminal expanded parent
nonterminal (Charniak & Carroll, 1994).
pseudo PCSG easily programmed. add one extra-argument, N, representing
parent node, predicate q'(I,D0,D2,C0,C2,L0-L2) Figure 11 replace
msw(I,C0,[J,K]) msw([N,I],C0,[J,K]). Since (leftmost) derivation sentence
pseudo PCSG still sequential decision process described modified program,
graphical EM algorithm applied support graphs generated modified
program observed sentences correctly performs ML estimation parameters
pseudo PCSG.
pseudo PCSG thought PCFG rules form [n; i] ! [i; j ][i; k]
(1 n; i; j; k N ) n parent nonterminal i, arguments previous
subsection carried minor changes. therefore (details omitted)

Proposition 5.4 Let DB parameterized logic program pseudo PCSG N

nonterminals shown above, G = G1; G2 ; : : : ; GT observed atoms representing
sampled sentences length L. Suppose table operation OLDT search done
O(1) time. OLDT search G iteration learn-gEM completed
O(N 4 L3T ) time.

5.5 Bayesian Networks

relationship cause C effect E often probabilistic one diseases symptoms, mathematically captured conditional
probability P (E = e j C = c) effect e given cause c. wish know however
inverse, i.e. probability candidate cause c given evidence e, i.e. P (C = c j E = e)
calculated Bayes' theorem P (E = e j C = c)P (C = c)= c0 P (E = e j C =
c0)P (C = c0 ). Bayesian networks representational/computational framework fits
best type probabilistic inference (Pearl, 1988; Castillo et al., 1997).
Bayesian network graphical representation joint distribution P (X1 = x1 ; : : : ;
XN = xN ) finitely many random variables X1 ; : : : ; XN . graph dag (directed
acyclic graph) ones Figure 12, node random variable.54
graph, conditional probability table (CPT) representing P (Xi = xi j 5i = ui)
(1 N ) associated node Xi 5i represents Xi's parent nodes ui
values. Xi parent, i.e. topmost node graph, table
marginal distribution P (Xi = xi). whole joint distribution defined product
P

54. deal discrete cases.
427

fiSato & Kameya



B





C

B

C

E



F

E

( G 1 ) Singly-connected

F

( G 2 ) Multiply-connected

Figure 12: Bayesian networks
conditional distributions:
P (X1 = x1 ; : : : ; XN

= xN )55 =

N

i=1

P (Xi = xi j 5i = ui ):

(21)

Thus graph G1 Figure 12 defines
PG (a; b; c; d; e; f ) = PG (a)PG (b)PG (c j a)PG (d j a; b)PG (e j d)PG (f j d)
a, b, c, d, e f values corresponding random variables A, B, C , D, E
F , respectively.56 mentioned before, one basic tasks Bayesian networks
compute marginal probabilities. example, marginal distribution PG (c; d)
computed either (22) (23) below.
PG (c; d) =
PG (a)PG (b)PG (c j a)PG (d j a; b)PG (e j d)P (f j d)
(22)
1

1

1

1

1

1

1

1

X

1

a;b;e;f

1

1

1

1

0

=

X
@

a;b

1

10

PG1 (a)PG1 (b)PG1 (c j a)PG1 (d j a; b)A @

1
X

e;f

PG1 (e j d)PG1 (f j d)A (23)

(23) clearly ecient (22). Observe graph like G2
Figure 12, would way factorize computations like (23) use (22) requiring
exponentially many operations. problem computing marginal probabilities
NP-hard general, factorization (23) assured graph singly
connected like G1 , i.e. loop viewed undirected graph. case,
computation possible O(jV j) time V set vertices graph (Pearl,
1988). Otherwise, graph called multiply-connected, might need exponential time
compute marginal probabilities. sequel, show following.
discrete Bayesian network G defining distribution PG (x1 ; : : : ; xN ),
parameterized logic program DBG predicate bn(1) PDB (bn(x1,: : :,xN ))
= PG(x1 ; : : : ; xN ).
G

55. Thanks acyclicity graph, without losing generality, may assume Xi ancestor
node Xj , < j holds.
56. notational simplicity, shall omit random variables confusion arises.
428

fiParameter Learning Logic Programs Symbolic-statistical Modeling

arbitrary factorizations order compute marginal distribution,

exists tabled program accomplishes computation specified way.
graph singly connected evidence e given, exists tabled
program DBG OLDT time bn(e) O(jV j), hence time
complexity per iteration graphical EM algorithm O(jV j) well.
Let G Bayesian network defining joint distribution PG(x1 ; : : : ; xN ) fPG (Xi =
xi j 5i = ui ) j 1 N; xi 2 val(Xi ); ui 2 val(5i )g conditional probabilities
associated G val(Xi) set Xi's possible values val(5i) denotes
set possible values parent nodes 5i random vector, respectively.
construct parameterized logic program defines distribution PG (x1 ; : : : ; xN ).
program DBG = FG [ RG shown Figure 13.


FG

= f msw(par(i,ui),once,xi) j 1 N; ui 2 val(5i); xi 2 val(Xi) g

RG

= f bn(X1 ,: : :,XN ):-

5i),once,Xi). g

VN

i=1 msw(par(i,

Figure 13: Bayesian network program DBG
FG comprised msw atoms form msw(par(i,ui ),once,xi ) whose probability
exactly conditional probability PG (Xi = xi j 5i = ui). Xi parents, ui
empty list []. RG singleton, containing one clause whose body conjunction
msw atoms corresponds product conditional probabilities. Note
intentionally identify random variables X1 ; : : : ; XN logical variables X1 ; : : : ; XN
convenience.

Proposition 5.5 DBG denotes distributions G.

(Proof) Let hx1 ; : : : ; xN realization random vector hX1; : : : ; XN i. holds
construction
PDBG (bn(x1 ,: : :,xN ))

=

N

h=1
N


Pmsw (msw(par(i,ui ),once,xi ))

=
PG (Xi = xi j 5i = ui )
h=1
= PG (x1 ; : : : ; xN ):
Q:E:D:
case G1 Figure 12, program becomes57
bn(A,B,C,D,E,F)

:-

msw(par('A',[]),once,A),
msw(par('C',[A]),once,C),
msw(par('E',[D]),once,E),

57. 0 A0 ; 0 B0 ; : : : Prolog constants used place integers.
429

msw(par('B',[]),once,B),
msw(par('D',[A,B]),once,D),
msw(par('F',[D]),once,F).

fiSato & Kameya

left-to-right sampling execution gives sample realization random vector
h A; B; C; D; E; F i. marginal distribution computed bn(x1 ,: : :,xN ) adding new
clause DBG. example, compute PG (c; d), add bn(C,D):- bn(A,B,C,D,E,F)
DBG (let result DB0G ) compute PDB0 (bn(c,d)) equal
PG (c; d)
PDB0 (bn(c,d)) = PDB (9 a; b; e; f bn(a,b,c,d,e,f ))
=
PDB (bn(a,b,c,d,e,f ))
a;b;e;f
= PG (c; d):
Regrettably computation corresponds (22), factorization (23). Ecient
probability computation using factorization made possible carrying summations
proper order.
next sketch example carry specified summations specified
order introducing new clauses. Suppose joint distribution P (x; y; z; w) =
1 (x; )2 (y; z; w)3(x; z; w) 1(x; ), 2(y; z; w) 3 (x; z; w) respectively
computed atoms p1 (X,Y), p2 (Y,Z,W) p3 (X,Z,W). Suppose also hope
compute sum
P (x) = 1(x; )
2 (y; z; w )3 (x; z; w)
1

1

1

G1

1

G1

X

G1

G1

1

X

X



z;w

!

first eliminate z; w y. Corresponding elimination, introduce
two new predicates, q(X,Y) compute 4 (x; y) = z;w 2 (y; z; w)3 (x; z; w) p(X)
compute P (x) = 1 (x; y)4(x; y) follows.
P

P

p(X)
q(X,Y)

::-

p1(X,Y), q(X,Y).
p2(Y,Z,W), p3 (X,Z,W).

Note clause body q=2 contains Z W (existentially quantified) local variables
clause head q(X,Y) contains variables shared atoms. view
correspondence 9, easy confirm program realizes
required computation. also easy see generalizing example, though
prove here, exists parameterized logic program carries given
summations given order arbitrary Bayesian network, particular
able simulate (variable elimination, Zhang & Poole, 1996; D'Ambrosio, 1999)
approach.
Ecient computation marginal distributions always possible
well-known class Bayesian networks, singly connected Bayesian networks,
exists ecient algorithm compute marginal distributions message passing (Pearl,
1988; Castillo et al., 1997). show graph singly connected,
construct ecient tabled Bayesian network program DBG assigning table predicate
node. avoid complications, explain construction procedure informally
concentrate case one interested variable. Let G singly
P



430

fiParameter Learning Logic Programs Symbolic-statistical Modeling

connected graph. First pick node U whose probability PG (u) seek.
construct tree G root node U G, letting nodes dangling U .
Figure 14 shows G1 transformed tree select node B root node.
B





E

F

C


Transformed graph G1

Figure 14: Transforming G1 tree
examine node G one one. add node X graph
corresponding clause DBG whose purpose visit nodes connected X except
one calls X . Suppose started root node U1 Figure 15 evidence
u given, generated clause (24). proceed inner node X (U1 calls
X ). original graph G, X parent nodes fU1 ; U2; U3g child nodes fV1 ; V2 g. U3
topmost node G.


U1
X
U2

V2
U3

V1

Tree G

Figure 15: General situation
node X Figure 15, add clause (25). called parent node
U1 U1 ground, first generate possible values U2 calling val U2 (U2),
call call X U2 (U2 ) visit nodes connected X U2 . U3 similary
treated. visiting nodes G connecting X parent nodes U2
U3 (nodes connected U1 already visited), value random variable X
determined sampling msw atom jointly indexed 'X' values U1 , U2
431

fiSato & Kameya
U3 . visit X 's children, V1 V2 . topmost node U3 original graph,
add clause (26).
tbn(U1 ) :- msw(par('U1 ',[]),once,U1 ), call
call

U1 X (U1 ).

U1 X (U1 ) :- val U2 (U2), call X U2 (U2 ),
val U3 (U3), call X U3 (U3 ),
msw(par('X',[U1 ,U2 ,U3 ]),once,X),
call X V1 (X), call X V2(X).

(24)

(25)

(26)
Let DBG final program containing clauses like (24), (25) (26). Apparently
DBG constructed time linear number nodes network. Also
note successive unfolding (Tamaki & Sato, 1984) atoms form call ...(1)
clause bodies starts (24) yields program DB0G similar one
Figure 13 contains msw atoms call ...(1)'s. DBG DB0G define
distribution,58 proved Proposition 5.5 PG (u) = PDB0 (bn(u)) =
PDB (tbn(u)) holds (details omitted). way, Figure 15 assume construction
starts topmost node U1 evidence u given, necessary.
Suppose change start inner node X. case, replace clause (24)
call X U1(U1 ) :- msw(par('U1',[]),once,U1 ) like (26). time
replace head clause (25) tbn() add goal call X U1 (u) body
on. changed program DB00G , rather straightforward prove
PDB00 (tbn()) = PG(u) holds. true construction tabled program
DBG shown crude lot room optimization, suces
show parameterized logic program singly connected Bayesian network runs
O(jV j) time V set nodes.
estimate time complexity OLDT search w.r.t. DBG , declare tbn every
predicate form call ...(1) table predicate verify five conditions
applicability graphical EM algorithm (details omitted). estimate time
complexity OLDT search goal tbn(u) w.r.t. DBG .59 notice calls occur
according pre-order scan (parents { node { children) tree G , calls
call X (1) occur val(Y ) times. call call X (1) invokes calls rest
nodes, X 's parents X 's children graph G except caller node, diffrent
set variable instantiations, second call on, every call refers solutions
stored solution table O(1) time. Thus, number added computation steps
call

X U3(U3 ) :- msw(par('U3 ',[]),once,U3 ).







G

G



G






58. Since distribution semantics based least model semantics, unfold/fold transformation (Tamaki & Sato, 1984) preserves least Herbrand model transformed program, unfold/fold
transformation applied parameterized logic programs preserves denotation transformed
program.
59. DBG transformed OLDT interpreter collect msw atoms like case HMM
program.
432

fiParameter Learning Logic Programs Symbolic-statistical Modeling

OLDT search X bounded above, constant O(val(U 1)val(U 2)val(U 3)val(X ))
case Figure 15. result OLDT time proportional number nodes
original graph G (and size support graph) provided number
edges connecting node, values random variable bounded
above.

Proposition 5.6 Let G singly connected Bayesian network defining distribution PG ,

V set nodes, DBG tabled program derived above. Suppose number
edges connecting node, values random variable bounded
constant. Also suppose table access done O(1) time. Then, OLDT time
computing PG(u) observed value u random variable U means DBG
O(jV j) time per iteration required graphical EM algorithm.
observations, time complexity O(jV jT ).

O(jV j) time complexity required compute marignal distribution singly
connected Bayesian network standard algorithm (Pearl, 1988; Castillo et al., 1997),
also EM algorithm using it. therefore conclude graphical
EM algorithm ecient specialzed EM algorithm singly connected Bayesian
networks.60 must also quickly add graphical EM algorithm applicable
arbitrary Bayesian networks,61 Proposition 5.6 says explosion
support graph avoided appropriate programming case singly connected
Bayesian networks.
summarize, graphical EM algorithm, single generic EM algorithm, proved
time complexity specialized EM algorithms, i.e. Baum-Welch algorithm
HMMs, Inside-Outside algorithm PCFGs, one singly connected
Bayesian networks developed independently research field.
Table 1 summarizes time complexity EM learning using OLDT search
graphical EM algorithm case one observation. first column, \sc-BNs"
represents singly connected Bayesian networks. second column shows program use.
DBh HMM proram Subsection 4.7, DBg0 PCFG program Subsection 5.3
DBG transformed Bayesian network program Subsection 5.5, respectively. OLDT time
third column time OLDT search complete search t-explanations.
gEM fourth column time one iteration taken graphical EM algorithm
update parameters. use N , , L V respectively number states
HMM, number nonterminals PCFG, length input string
number nodes Bayesian network. last column standard (specialized) EM
algorithm model.


60. marginal distribution PG one variable required, construct similar
tabled program computes marginal probabilities still O(jV j) time adding extra-arguments
convey evidence embedding evidnece program.
61. check five conditions DBG Figure 13. uniqueness condition obvious sampling
always uniquely generates sampled value random variable. finite support condition
satisfied finite number random variables values. acyclic support
condition immediate acyclicity Bayesian networks. t-exclusiveness condition
independent condition easy verify.
433

fiSato & Kameya

Model
Program
HMMs
DBh
PCFGs
DBg0
DBG
sc-BNs
user model


OLDT time
(N 2L)
(M 3 L 3 )
O(jV j)
O(jOLDT treej)

gEM
Specialized EM
2
O(N L)
Baum-Welch
3
3
(M L )
Inside-Outside
O(jV j)
(Castillo et al., 1997)
(jsupport graphj)

Table 1: Time complexity EM learning OLDT search graphical EM algorithm

5.6 Modeling Language PRISM

developing symbolic-statistical modeling laguage PRISM since 1995 (URL
= http://mi.cs.titech.ac.jp/prism/) implementation distribution semantics
(Sato, 1995; Sato & Kameya, 1997; Sato, 1998). language intented modeling
complex symbolic-statistical phenomena discourse interpretation natural language
processing gene inheritance interacting social rules. programming language,
looks like extension Prolog new built-in predicates including msw predicate
special predicates manipulating msw atoms parameters.
PRISM program comprised three parts, one directives, one modeling
one utilities. directive part contains declarations values, telling system
msw atoms used execution. modeling part set non-unit definite
clauses define distribution (denotation) program using msw atoms.
last part, utility part, arbitary Prolog program refers predicates defined
modeling part. use utility part learn built-in predicate carry
EM learning observed atoms.
PRISM provides three modes execution. sampling execution correponds
random sampling drawn distribution defined modeling part. second
one computes probability given atom. third one returns support set
given goal. execution modes available built-in predicates.
must report however implementation graphical EM algorithm
simpified OLDT search mechanism way, completed yet.
currently, Prolog search learn-naive(DB; G) Section 4 available EM learning though realized, partially, structrure sharing explanations implemention
learn-naive(DB; G ). Putting computational eciecy aside however, problem
expressing learning HMMs, PCFGs, pseudo PCSGs, Bayesian networks
probailistic models current version. learning experiments next section
used parser substitute OLDT interpreter, independently implemented
graphical EM algorithm.
6. Learning Experiments

complexity analysis graphical EM algorithm popular symbolic-probabilistic
models previous section, look actual behavior graphical EM algorithm
real data section. conducted learning experiments PCFGs using two
434

fiParameter Learning Logic Programs Symbolic-statistical Modeling

corpora contrasting characters, compared performance graphical
EM algorithm Inside-Outside algorithm terms time per iteration
(= time updating parameters). results indicate graphical EM algorithm
outperform Inside-Outside algorithm orders magnigude. Detalis reported
Sato, Kameya, Abe, Shirai (2001). proceeding, review Inside-Outside
algorithm completeness.

6.1 Inside-Outside Algorithm

Inside-Outside algorithm proposed Baker (1979) generalization
Baum-Welch algorithm PCFGs. algorithm designed estimate parameters
CFG grammar Chomsky normal form containing rules expressed numbers like ! j; k
(1 i; j; k N N nonterminals, 1 starting symbol). Suppose input
sentence w1 ; : : : ; wL given.
iteration, first computes bottom manner
3
inside probabilities3 e(s; t; i) = P (i ) ws; : : : ; wt) computes outside probabilities
f (s; t; i) = P (S )
w1 ; : : : ; ws01 wt+1 ; : : : ; wL ) top-down manner every s,
(1 L; 1 N ). computing probabilities, parameters
updated using them, process iterates predetermined criterion
convergence likelihood input sentence achieved. Although Baker
give analysis Inside-Outside algorithm, Lari Young (1990) showed
takes O(N 3 L3 ) time one iteration Lafferty (1993) proved EM algorithm.
true Inside-Outside algorithm recognized standard EM
algortihm training PCFGs, notoriously slow. Although much literature
explicitly stating time required Inside-Outside algorithm (Carroll & Rooth, 1998;
Beil, Carroll, Prescher, Riezler, & Rooth, 1999), Beil et al. (1999) reported example
trained PCFG 5,508 rules corpus 450,526 German subordinate clauses whose average ambiguity 9,202 trees/clause using four machines (167MHz
Sun UltraSPARC22 296MHz Sun UltraSPARC-II22), took 2.5 hours complete
one iteration. discuss later Inside-Outside algorithm slow.

6.2 Learning Experiments Using Two Corpora

report parameter learning existing PCFGs using two corpora moderate size
compare graphical EM algorithm Inside-Outside algorithm terms
time per iteration. mentioned before, support graphs, input garphical EM
algorithm, generated parser, i.e. MSLR parser.62 measurements made
296MHz Sun UltraSPARC-II 2GB memory Solaris 2.6 threshold
increase log likelihood input sentences set 1006 stopping criterion
EM algorithms.
experiments, used ATR corpus EDR corpus (each converted POS
(part speech)-tagged corpus). similar size (about 10,000) contrasting
characters, sentence length ambiguity grammars. first experiment
employed ATR corpus Japanese-English corpus (we used Japanese part)
developed ATR (Uratani, Takezawa, Matsuo, & Morita, 1994). contains 10,995 short
62. MSLR parser Tomita (Generalized LR) parser developed Tanaka-Tokunaga Laboratory Tokyo
Institute Technology (Tanaka, Takezawa, & Etoh, 1997).
435

fiSato & Kameya

conversational sentences, whose minimum length, average length maximum length
respectively 2, 9.97 49. skeleton PCFG, employed context free grammar
Gatr comprising 860 rules (172 nonterminals 441 terminals) manually developed
ATR corpus (Tanaka et al., 1997) yields 958 parses/sentence.
Inside-Outside algorithm accepts CFG Chomsky normal form,
converted Gatr Chomsky normal form G3atr . G3atr contains 2,105 rules (196 nonterminals 441 terminals). divided corpus subgroups similar length
like (L = 1; 2); (L = 3; 4); : : : ; (L = 25; 26), containing randomly chosen 100 sentences.
preparations, compare length graphical EM algorithm applied
Gatr G3atr Inside-Outside algorithm applied G3atr terms time per
iteration running convergence.
(sec)

(sec)

(sec)

60
I-O
50

0.7

0.04

0.6

0.035

0.5

40

0.4

0.03

I-O
gEM (original)
gEM (Chomsky NF)

0.025
0.02

30
0.3
20

0.015

0.2

10

0.01

0.1

0.005

5

10

15

20

25

L

L

L
0

gEM (original)
gEM (Chomsky NF)

0

5

10

15

20

25

0

5

10 15 20 25

Figure 16: Time per iteration : I-O vs. gEM (ATR)
Curves Figure 16 show learning results x-axis length L input
sentence y-axis average time taken EM algorithm one iteration update
parameters contained support graphs generated chosen 100 sentences
(other parameters grammar change). left graph, Inside-Outside
algorithm plots cubic curve labeled \I-O". omitted curve drawn graphical
EM algorithm drew x-axis. middle graph magnifies left graph. curve
labeled \gEM (original)" plotted graphical EM algorithm applied original
grammar Gatr whereas one labeled \gEM (Chomsky NF)" used G3atr. length 10,
average sentence length, measured whichever grammar employed, graphical
EM algorithm runs several hundreds times faster (845 times faster case Gatr
720 times faster case G3atr) Inside-Outside algorithm per iteration.
right graph shows (almost) linear dependency updating time graphical EM
algorithm within measuared sentence length.
Although difference anticipated learning speed, speed gap
Inside-Outside algorithm graphical EM algorithm unexpectedly large.
conceivable reason ATR corpus contains short sentences Gatr
436

fiParameter Learning Logic Programs Symbolic-statistical Modeling

much ambiguous parse trees sparse generated support graphs small,
affects favorably perforamnce graphical EM algorithm.
therefore conducted experiment another corpus contains much
longer sentences using ambiguous grammar generates dense parse trees.
used EDR Japanese corpus (Japan EDR, 1995) containing 220,000 Japanese news article
sentences. however process re-annotation, part (randomly
sampled 9,900 sentences) recently made available labeled corpus. Compared
ATR corpus, sentences much longer (the average length 9,900 sentences 20,
minimum length 5, maximum length 63) CFG grammar Gedr (2,687 rules,
converted Chomsky normal form grammar G3edr containing 12,798 rules) developed
ambiguous (to keep coverage rate), 3:0 2 108 parses/sentence length
20 6:7 2 1019 parses/sentence length 38.
(sec)

5000

(sec)

(sec)
3

10

6000
I-O

8

I-O
gEM (original)

2.5

gEM (original)

2

4000

6
1.5

3000

4
1

2000

2

1000
0

L
5 10 15 20 25 30 35 40

0

0.5

L
5 10 15 20 25 30 35 40

0

L
5 10 15 20 25 30 35 40

Figure 17: Time per iteration : I-O vs. gEM (EDR)
Figure 17 shows obtained curves experiments EDR corpus (the graphical EM algorithm applied Gedr vs. Inside-Outside algorithm applied G3edr)
condition ATR corpus, i.e. plotting average time per iteration process 100
sentences designated length, except plotted time Inside-Outside algorithm average 20 iterations whereas graphical EM algorithm
average 100 iterations. clear middle graph, time again, graphical
EM algorithm runs orders magnitude faster Inside-Outside algorithm. average sentence length 20, former takes 0.255 second whereas latter takes 339 seconds,
giving speed ratio 1,300 1. sentence length 38, former takes 2.541 seconds
latter takes 4,774 seconds, giving speed ratio 1,878 1. Thus speed ratio even
widens compared ATR corpus. explained mixed effects O(L3 ),
time complexity Inside-Outside algorithm, moderate increase total size
support graphs w.r.t. L. Notice right graph shows total size support
graphs grows sentence length L time per iteration graphical EM algorithm
linear total size support graphs.

437

fiSato & Kameya

Since implemented Inside-Outside algorithm faithfully Baker (1979), Lari
Young (1990), much room improvement. Actually Kita gave refined InsideOutside algorithm (Kita, 1999). also implementation Mark Johnson
Inside-Outside algorithm down-loadable http://www.cog.brown.edu/%7Emj/.
use implementations may lead different conclusions. therefore conducted
learning experiments entire ATR corpus using two implementations
measured updating time per iteration (Sato et al., 2001). turned implementations run twice fast naive implementation take 630 seconds per
iteration graphical EM algorithm takes 0.661 second per iteration, still
orders magnitude faster former two. Regrettably similar comparison using
entire EDR corpus available moment abandoned due memory ow
parsing construction support graphs.
Learning experiments far compared time per iteration ignore extra time
search (parsing) required graphical EM algorithm. question naturally arises
w.r.t. comparison terms total learning time. Assuming 100 iterations learning
ATR corpus however, estimated even considering parsing time, graphical
EM algorithm combined MSLR parser runs orders magnitude faster three
implementations (ours, Kita's Johnson's) Inside-Outside algorithm (Sato et al.,
2001). course estimation directly apply graphical EM algorithm
combined OLDT search, OLDT interpreter take time parser
much time needed depends implementaiton OLDT search.63
Conversely, however, may able take rough indication far approach,
graphical EM algorithm combined OLDT search via support graphs, go
domain EM learning PCFGs.

6.3 Examing Performance Gap

previous subsection, compared performance graphical EM algorithm
Inside-Outside algorithm PCFGs given, using two corpora three
implementations Inside-Outside algorithm. experiments, graphical EM
algorithm considerably outperformed Inside-Outside algorithm despite fact
time complexity. look causes performance
gap.
Simply put, Inside-Outside algorithm slow (primarily) lacks parsing.
Even backbone CFG grammar explicitly given, take advantage
constraints imposed grammar. see it, might help review inside
probability e(s; t; A), i.e. P(nonterminal spans s-th word t-th word) (s t),
calculated Inside-Outside algorithm given grammar.
e(s; t; A) =

r=
t01
X

P(A ! BC )e(s; r; B)e(r + 1; t; C )
s.t. A!BC grammar r=s
P(A ! BC ) probability associated production rule ! BC . Note
fixed triplet (s; t; A), usual term P(A ! BC )e(s; r; B )e(r +1; t; C ) non-zero
X

B;C

63. cannnot answer question right implementation OLDT search completed.
438

fiParameter Learning Logic Programs Symbolic-statistical Modeling

relatively small number (B; C; r)'s determined successful parses
rest combinations always give 0 term. Nonetheless Inside-Outside algorithm
attempts compute term every iteration possible combinations B, C
r repeated every possible (s; t; A), resulting lot redundancy.
kind redundancy occurs computation outside probability Inside-Outside
algorithm.
graphical EM algorithm free redundancy runs parse trees (a
parse forest) represented support graph.64 must added, hand,
superiority learning speed graphical EM algorithm realized cost space
complexity Inside-Outside algorithm merely requires O(NL2 ) space
array store probabilities, graphical EM algorithm needs O(N 3 L3 ) space store
support graph N number nonterminals L sentence length.
trade-off understandable one notices graphical EM algorithm applied
PCFG considered partial evaluation Inside-Outside algorithm
grammar (and introduction appropriate data structure output).
Finally remark use parsing preprocess EM learning PCFGs
unique graphical EM algorithm (Fujisaki, Jelinek, Cocke, Black, & Nishino, 1989;
Stolcke, 1995). approaches however still seem contain redundancies compared
graphical EM algorithm. instance Stolcke (1995) uses Earley chart compute
inside outside probability, parses implicitly reconstructed iteration
dynamically combining completed items.
7. Related Work Discussion

7.1 Related Work

work presented paper crossroads logic programming probability
theory, considering enormous body work done fields, incompleteness
unavoidable reviewing related work. said that, look various attempts
made integrate probability computational logic logic programming.65 reviewing, one immediately notice two types usage probability. One type,
constraint approach, emphasizes role probability constraints necessarily seek unique probability distribution logical formulas. type,
distribution approach, explicitly defines unique distribution model theoretical means
proof theoretical means, compute various probabilities propositions.
typical constraint approach seen early work probabilistic logic Nilsson
(1986). central problem, \probabilistic entailment problem", compute upper
lower bound probability P() target sentence way bounds
compatible given knowledge base containing logical sentences (not necessarily
logic programs) annotated probability. probabilities work constraints
64. emphasize difference Inside-Outside algorithm graphical EM algorithm
solely computational eciency, converge parameter values starting
initial values. Linguistic evaluations estimated parameters graphical EM algorithm
also reported Sato et al. (2001).
65. omit literature leaning strongly toward logic. logic(s) concerning uncertainty, see overview
Kyburg (1994).
439

fiSato & Kameya

possible range P(). used linear programming technique solve problem
inevitably delimits applicability approach finite domains.
Later Lukasiewicz (1999) investigated computational complexity probabilistic
entailment problem slightly different setting. knowledge base comprises statements
form (H j G)[u1 ; u2 ] representing u1 P(H j G) u2 . showed inferring
\tight" u1 ; u2 NP-hard general, proposed tractable class knowledge base called
conditional constraint trees.
uential work Nilsson, Frish Haddawy (1994) introduced deductive system probabilistic logic remedies \drawbacks" Nilsson's approach,
computational intractability lack proof system. system deduces
probability range proposition rules probabilistic inferences unconditional
conditional probabilities. instance, one rules infers P (ff j ) 2 [0 y]
P (ff _ fi j ) 2 [x ] ff,fi propositional variables [x y] (x ) designates
probability range.
Turning logic programming, probabilistic logic programming formalized Ng
Subrahmanian (1992) Dekhtyar Subrahmanian (1997) also constraint approach. program set annotated clauses form : F1 : 1; : : : ; Fn : n
atom, Fi (1 n) basic formula, i.e. conjunction disjunction
atoms, j (0 j n) sub-interval [0; 1] indicating probability range. query
9 (F1 : 1 ; : : : ; Fn : n) answered extension SLD refutation. formalization,
assumed language contains finite number constant predicate
symbols, function symbol allowed.
similar framework proposed Lakshmanan Sadri (1994) syntactic restrictions (finitely many constant predicate symbols function
symbols)
different uncertainty setting. used annotated clauses form c B1 ; : : : ; Bn
Bi (1 n) atoms c = h[ff; fi ]; [ ; ]i, confidence level, represents
belief interval [ff; fi ] (0 ff fi 1) doubt interval [ ; ] (0 1),
expert clause.
seen above, defining unique probability distribution secondary concern
constraint approach. sharp contrast Bayesian networks whole
discipline rests ability networks define unique probability distribution
(Pearl, 1988; Castillo et al., 1997). Researchers Bayesian networks seeking
way mixing Bayesian networks logical representation increase inherently
propositional expressive power.
Breese (1992) used logic programs automatically build Bayesian network
query. Breese's approach, program union definite clause program set
conditional dependencies form P(P j Q1 ^ 1 11 ^ Qn ) P Qi atoms.
Given query, Bayesian network constructed dynamically connects query
relevant atoms program, turn defines local distribution connected
atoms. Logical variables appear atoms function symbol allowed.
Ngo Haddawy (1997) extended Breese's approach incorporating mechanism
ecting context. used clause form P(A0 j A1 ; : : : ; ) = ff L1 ; : : : ; Lk ,
Ai's called p-atoms (probabilistic atoms) whereas Lj 's context atoms disjoint
p-atoms, computed another general logic program (satisfying certain restric440

fiParameter Learning Logic Programs Symbolic-statistical Modeling

tions). Given query, set evidence context atoms, relevant ground p-atoms
identified resolving context atoms away SLDNF resolution, local Bayesian network built calculate probability query. proved soundness
completeness query evaluation procedure condition programs
acyclic66 domains finite.
Instead defining local distribution query, Poole (1993) defined global distribution \probabilistic Horn abduction". program consists definite clauses
disjoint declarations form disjoint([h1 :p1,...,hn:pn]) specifies probability distribution hypotheses (abducibles) fh1; : : : ; hn g. assigned probabilities
ground atoms help theory logic programming, furthermore proved
Bayesian networks representable framework. Unlike previous approaches,
language contains function symbols, acyclicity condition imposed programs
semantics definable seems severe restriction. Also, probabilities
defined quantified formulas.
Bacchus et al. (1996) used much powerful first-order probabilistic language
clauses annotated probabilities. language allows statistically quantified term
k (x)j(x) kx denote ratio individuals finite domain satisfying (x) ^
(x) satisfying (x). Assuming every world (interpretation language)
equally likely, define probability sentence ' given knowledge
('^KB)

base KB limit limN !1 ##worlds
worlds (KB) #worldsN () number
possible worlds containing N individuals satisfying , parameters used judging
approximations. Although limit necessarily exist domain must finite,
showed method cope diculties arising \direct inference"
default reasoning.
linguistic vein, Muggleton (1996, others) formulated SLPs (stochastic
logic programs) procedurally, extension PCFGs probabilistic logic programs.
So, clause C , must range-restricted,67 annotated probability p like
p : C . probability goal G product ps appearing refutation
modification subgoal g invoke n clauses, pi : Ci (1 n)
refutation step, probability choosing k-th clause normalized pk = ni=1 pi.
recently, Cussens (1999, 2001) enriched SLPs introducing special class
log-linear models SLD refutations w.r.t. given goal. example considers
possible SLD refutations general goal s(X ) defines probability P(R)
refutation R P(R) = Z 01 exp( (R; i)). number associated
clause Ci (R; i) feature, i.e. number occurrences Ci R. Z
normalizing constant. Then, probability assigned s(a) sum probabilities
refutation s(a).



N

N



P

P

66. condition says every ground atom must assigned unique integer n(A) n(A) >
n(B1 ); : : : ; n(Bn ) holds ground instance clause form B1 ; : : : ; Bn .
condition, program includes p(X ) q(X; ), cannot write recursive clauses q
q (X; [H jY ]) q(X; ).
67. syntactic property variables appearing head also appear body clause. unit
clause must ground.
441

fiSato & Kameya

7.2 Limitations Potential Problems

Approaches described far less similar limitations potential problems.
Descriptive power confined finite domains common limitation, due
use linear programming technique (Nilsson, 1986), due syntactic
restrictions allowing infinitely many constant, function predicate symbols (Ng
& Subrahmanian, 1992; Lakshmanan & Sadri, 1994). Bayesian networks
limitation well (only finite number random variables representable).68 Also
various semantic/syntactic restrictions logic programs. instance acyclicity
condition imposed Poole (1993) Ngo Haddawy (1997) prevents unconditional
use clauses local variables, range-restrictedness imposed Muggleton
(1996) Cussens (1999) excludes programs usual membership Prolog program.
another type problem, possibility assigning con icting probabilities
logically equivalent formulas. SLPs, P(A) P(A ^ A) necessarily coincide
^ may different refutations (Muggleton, 1996; Cussens, 1999, 2001).
Consequently SLPs, would trouble naively interpret P(A) probability
A's true. Also assigning probabilities arbitrary quantified formulas seems
scope approaches SLPs.
Last least, big problem common approach using probabilities:
numbers come from? Generally speaking, use n binary random variables
model, determine 2n probabilities completely specify joint distribution,
fulfilling requirement reliable numbers quickly becomes impossible n grows.
situation even worse unobservable variables model
possible causes disease. Apparently parameter learning observed data natural
solution problem, parameter learning logic programs well studied.
Distribution semantics proposed Sato (1995) attempt solve problems
along line global distribution approach. defines distribution (probability
measure) possible interpretations ground atoms arbitrary logic program
first order language assigns consistent probabilities closed formulas. Also
distribution semantics enabled us derive EM algorithm parameter learning
logic programs first time. naive algorithm however, dealing large
problems dicult exponentially many explanations observation
like HMMs. believe eciency problem solved large extent
graphical EM algorithm presented paper.

7.3 EM Learning

Since EM learning one central issues paper, separately mention work
related EM learning symbolic frameworks. Koller Pfeffer (1997) used
approach KBMC (knowledge-based model construction) EM learning estimate parameters labeling clauses. express probabilistic dependencies among events definite clauses annotated probabilities, similarly Ngo Haddawy's (1997) approach,
locally build Bayesian network relevant context evidence well
68. However, RPMs (recursive probability models) proposed Pfeffer Koller (2000) extension
Bayesian networks allow infinitely many random variables. organized attributes
classes probability measure attribute values introduced.
442

fiParameter Learning Logic Programs Symbolic-statistical Modeling

query. Parameters learned applying constructed network specialized EM
algorithm Bayesian networks (Castillo et al., 1997).
Dealing PCFG statically constructed Bayesian network proposed Pynadath Wellman (1998), possible combine EM algorithm method
estimate parameters PCFG. Unfortunately, constructed network singly
connected, time complexity probability computation potentially exponential
length input sentence.
Closely related EM learning parameter learning log-linear models. Riezler (1998) proposed IM algorithm approach probabilistic constraint programming. IM algorithm general parameter estimation algorithm incomplete data
log-linear models whose probability function P(x) takes form P(x) =
Z 01 exp( ni=1 (x)) p0 (x) (1 ; : : : ; n ) parameters estimated, (x)
i-th feature observed object x Z normalizing constant. Since feature
function x, log-linear model highly exible includes distribution
Pmsw special case Z = 1. price pay however; computational cost
Z . requires summation exponentially many terms. avoid cost exact
computation, approximate computation Monte Carlo method possible. Whichever
one may choose however, learning time increases compared EM algorithm Z = 1.
FAM (failure-adjusted maximization) algorithm proposed Cussens (2001)
EM algorithm applicable pure normalized SLPs may fail. deals special
class log-linear models ecient IM algorithm. statistical
framework FAM rather different distribution semantics, comparison
graphical EM algorithm seems dicult.
slightly tangential EM learning, Koller et al. (1997) developed functional
modeling language defining probability distribution symbolic structures
showed \cashing" computed results leads ecient probability computation
singly connected Bayesian networks PCFGs. cashing corresponds computation inside probability Inside-Outside algorithm computation outside
probability untouched.
P

7.4 Future Directions

Parameterized logic programs expected useful modeling tool complex symbolicstatistical phenomena. tried various types modeling, besides stochastic grammars Bayesian networks, modeling gene inheritance Kariera tribe
(White, 1963) rules bi-lateral cross-cousin marriage four clans interact
rules genetic inheritance (Sato, 1998). model quite interdisciplinary,
exibility combining msw atoms means definite clauses greatly facilitated
modeling process.
Although satisfying five conditions Section 4
uniqueness condition (roughly, one cause yields one effect)
finite support condition (there finite number explanations one observation)
acyclic support condition (explanations must cyclic)
443

fiSato & Kameya

t-exclusiveness condition (explanations must mutually exclusive)
independence condition (events explanation must independent)

applicability graphical EM algorithm seems daunting, modeling experiences far tell us modeling principle Section 4 effectively guides us successful
modeling. return, obtain declarative model described compactly high level
language whose parameters eciently learnable graphical EM algorithm shown
preceding section.
One future directions however relax applicability conditions,
especially uniqueness condition prohibits generative model failure
generating multiple observable events. Although pointed Section 4.4 MAR
condition Appendix B adapted semantics replace uniqueness condition
validates use graphical EM algorithm even complete data uniquely
determine observed data like case \partially bracketed corpora" (Pereira &
Schabes, 1992), feel need research topic. Also investigating
role acyclicity condition seems theoretically interesting acyclicity often
related learning logic programs (Arimura, 1997; Reddy & Tadepalli, 1998).
paper scratched surface individual research fields HMMs,
PCFGs Bayesian networks. Therefore, remains much done clarifying
experiences research field ected framework parameterized logic
programs. example, need clarify relationship symbolic approaches
Bayesian networks SPI (Li, Z. & D'Ambrosio, B., 1994) approach.
Also unclear compiled approach using junction tree algorithm Bayesian
networks incorporated approach. Aside exact methods, approximate
methods probability computation specialized parameterized logic programs must also
developed.
also direction improving learning ability introducing priors instead ML
estimation cope data sparseness. introduction basic distributions make
probabilistic switches correlated seems worth trying near future. also important
take advantage logical nature approach handle uncertainty. example,
already shown Sato (2001) learn parameters negative examples
\the grass wet" treatment negative examples parameterized
logic programs still infancy.
Concerning developing complex statistical models based \programs distributions" scheme, stochastic natural language processing exploits semantic information
seems promising. instance, unification-based grammars HPSGs (Abney, 1997)
may good target beyond PCFGs use feature structures logically describable, ambiguity feature values seems expressible probability
distribution.
Also building mathematical basis logic programs continuous random variables
challenging research topic.

444

fiParameter Learning Logic Programs Symbolic-statistical Modeling
8. Conclusion

proposed logical/mathematical framework statistical parameter learning
parameterized logic programs, i.e. definite clause programs containing probabilistic facts
parameterized probability distribution. extends traditional least Herbrand
model semantics logic programming distribution semantics , possible world semantics
probability distribution possible worlds (Herbrand interpretations)
unconditionally applicable arbitrary logic programs including ones HMMs, PCFGs
Bayesian networks.
also presented new EM algorithm, graphical EM algorithm Section 4,
learns statistical parameters observations class parameterized logic programs representing sequential decision process decision exclusive
independent. works support graph s, new data structure specifying logical relationship observed goal explanations, estimates parameters computing
inside outside probability generalized logic programs.
complexity analysis Section 5 showed OLDT search, complete tabled
refutation method logic programs, employed support graph construction
table access done O(1) time, graphical EM algorithm, despite generality,
time complexity existing EM algorithms, i.e. Baum-Welch algorithm
HMMs, Inside-Outside algorithm PCFGs one singly connected Bayesian
networks developed independently research field. addition,
pseudo probabilistic context sensitive grammars N nonterminals, showed
graphical EM algorithm runs time O(N 4 L3) sentence length L.
compare actual performance graphical EM algorithm InsideOutside algorithm, conducted learning experiments PCFGs Section 6 using two
real corpora contrasting characters. One ATR corpus containing short sentences
grammar much ambiguous (958 parses/sentence), EDR
corpus containing long sentences grammar rather ambiguous (3:0 2 108
average sentence length 20). cases, graphical EM algorithm outperformed
Inside-Outside algorithm orders magnitude terms time per iteration,
suggests effectiveness approach EM learning graphical EM algorithm.
Since semantics limited finite domains finitely many random variables
applicable logic programs arbitrary complexity, graphical EM algorithm
expected give general yet ecient method parameter learning models complex
symbolic-statistical phenomena governed rules probabilities.
Acknowledgments

authors wish thank three anonymous referees comments suggestions.
Special thanks go Takashi Mori Shigeru Abe stimulating discussions learning
experiments, also Tanaka-Tokunaga Laboratory kindly allowing use
MSLR parser linguistic data.

445

fiSato & Kameya
Appendix A. Properties

PDB

appendix, list properties PDB defined parameterized logic program
DB = F [ R countable first-order language L.69 First all, PDB assigns consistent
probabilities70 every closed formula L
PDB () def
= PDB (f! 2
DB j ! j= g)
guaranteeing continuity sense
limn!1 PDB ((t1 ) ^ 1 11 ^ (tn)) = PDB (8x(x))
limn!1 PDB ((t1 ) _ 1 11 _ (tn)) = PDB (9x(x))
t1 ; t2 ; : : : enumeration ground terms L.
next proposition, Proposition A.1, relates PDB Herbrand model. prove
it, need terminology. factor closed formula prenex disjunctive normal
form Q1 1 1 1 QnM Qi (1 n) either existential quantification universal
quantification matrix. length quantifications n called rank
factor. Define 8 set formulas made factors, conjunctions disjunctions.
Associate formula 8 multi-set r() ranks
;
factor quantification
r () =
fng
factor rank n
r(1) ] r (2 ) = 1 _ 2 = 1 ^ 2:
] stands union two multi-sets. instance f1; 2; 3g]f2; 3; 4g = f1; 2; 2; 3; 3; 4g.
use multi-set ordering proof Proposition A.1 usual induction
complexity formulas work.
Lemma A.1 Let boolean formula made ground atoms L. PDB() =
PF (f 2
F j MDB ( ) j= g).
(Proof) prove lemma conjunction atoms form D1x ^
1 11 ^ Dnx (xi 2 f0; 1g; 1 n).
PDB (D1x ^ 1 11 ^ Dnx ) = PDB (f! 2
DB j ! j= D1x ^ 11 1 ^ Dnx g)
= PDB (D1 = x1 ; : : : ; Dn = xn)
= PF (f 2
F j MDB ( ) j= D1x ^ 1 11 ^ Dnx g) Q.E.D.
8
>
<
>
:

1

n

1

n

n

1

1

n

Proposition A.1 Let closed formula L. PDB() = PF (f 2
F j MDB( ) j= g).
69. definitions
F , PF , MDB ( ),
DB , PDB others used below, see Section 3.
70. consistent, mean probabilities assigned logical formulas respect laws probability
0 P (A) 1, P (:A) = 1 0 P (A) P (A _ B ) = P (A) + P (B ) 0 P (A ^ B ).
446

fiParameter Learning Logic Programs Symbolic-statistical Modeling

(Proof) Recall closed formula equivalent prenex disjunctive normal form
belongs 8. prove proposition formulas 8 using induction
multi-set ordering fr() j 2 8g. r() = ;, quantification.
proposition correct Lemma A.1. Suppose otherwise. Write = G[Q1 Q2 11 1 Qn F ]
Q1 Q2 1 11 QnF indicates single occurrence factor G.71 assume Q1 = 9x
(Q1 = 8x similarly treated). also assume bound variables renamed avoid
name clash. G[9xQ2 11 1 Qn F ] equivalent 9xG[Q2 1 11 QnF ] light validity
(9xA) ^ B = 9x(A ^ B) (9xA) _ B = 9x(A _ B) B contains free x.
PDB () = PDB (G[Q1 Q2 1 11 QnF ])
= PDB (9xG[ Q2 11 1 Qn F [x]])
= klim
P (G[ Q2 11 1 Qn F [t1 ]] _ 1 11 _ G[Q2 11 1 Qn F [tk ]])
!1 DB
= klim
P (G[ Q2 11 1 Qn F [t1 ] _ 1 11 _ Q2 11 1 Qn F [tk ]])
!1 DB
= klim
P (f 2
F j MDB ( ) j= G[ Q2 1 11 QnF [t1] _ 11 1 _ Q2 1 11 QnF [tk ] ]g)
!1 F
(by induction hypothesis)
= PF (f 2
F j MDB ( ) j= 9xG[Q2 1 11 QnF [x]]g)
= PF (f 2
F j MDB ( ) j= g)
Q.E.D.
next prove theorem iff definition introduced Section 4. Distribution
semantics considers program DB = F [ R set infinitely many ground definite
clauses F set facts (with probability measure PF ) R set rules,
clause head R appears F . Put
head(R) def
= fB j B appears R clause headg:
B 2 head(R), let B Wi (i = 1; 2; : : :) enumeration clauses B R.
Define iff (B), iff (if-and-only-if) form rules B DB72
iff (B) def
= B $ W1 _ W2 _ 1 1 1
Since MDB ( ) least Herbrand model, following obvious.
Lemma A.2 B head(R) 2
F , MDB( ) j= iff (B).
Theorem A.1 iff (B). states general level, sides iff
definition p(x) $ 9y1 (x = t1 ^ W1 ) _ 1 11 _ 9yn (x = tn ^ Wn) p(1) coincide random
variables whenever x instantiated ground term.
Theorem A.1 Let iff (B ) = B $ W1 _ W2 _11 1 iff form rules B 2 head(R).
PDB (iff (B )) = 1 PDB (B ) = PDB (W1 _ W2 _ 1 11).
71. expression E , E [ ] means may occur specified positions E . 1 _ 2 E [ 1 _ 2 ]
indicates single occurrence 1 _ 2 positive boolean formula E , E [ 1 _ 2 ] = E [ 1 ] _ E [ 2 ] holds.
72. definition different usual one (Lloyd, 1984; Doets, 1994) talking ground
level. W1 _ W2 _ 1 1 1 true one disjuncts true.
447

fiSato & Kameya

(Proof)

PDB (iff (B ))

=

PDB (f! 2
DB j ! j= B ^ (W1 _ W2 _ 11 1)g)
+PDB (f! 2
DB j ! j= :B ^ :(W1 _ W2 _ 1 11)g)

= klim
P (f! 2
DB j ! j= B ^
!1 DB

k
_

i=1

Wi g)

+ klim
P (f! 2
DB j ! j= :B ^ :
!1 DB
= klim
P (f 2
F j MDB ( ) j= B ^
!1 F

k
_
i=1

k
_
i=1

Wi g)

Wi g)
k
_

+ klim
P (f 2
F j MDB ( ) j= :B ^ : Wi g)
!1 F
i=1
(Lemma A.1)
= PF (f 2
F j MDB ( ) j= iff (B)g)
= PF (
F ) (Lemma A.2)
= 1
follows PDB (iff (B)) = 1
PDB (B ) = PDB (B ^ iff(B )) = PDB (W1 _ W2 _ 1 1 1):
Q.E.D.
prove proposition useful probability computation. Let DB (B )
support set atom B introduced Section 4 (it set explanations B).
sequel, B ground atom. Write DB (B) = fS1 ; S2; : : :g DB (B) = S1 _S2 _1 1173
Define set 3B
3B def
= f! 2
DB j ! j= B $ DB (B)g:
Proposition A.2 every B 2 head(R), PDB(3B ) = 1 PDB (B) = PDB( DB (B)).
(Proof) first prove PDB (3B ) = 1 proof exactly parallels Theorem A.1
except W1 _ W2 _ 1 1 1 replaced S1 _ S2 _ 11 1 using fact B $ S1 _ S2 _ 11 1
true every least Herbrand model form MDB ( ). PDB (3B ) = 1,

PDB (B ) = PDB (B ^ (B $
DB (B )))
= PDB ( DB (B)):
Q.E.D.
Finally, show distribution semantics probabilistic extension traditional
least Herbrand model semantics logic programming proving Theorem A.2. says
probability mass distributed exclusively possible least Herbrand models.
Define 3 set least Herbrand models generated fixing R varying subset
F program DB = F [ R. symbols,
W

_

W

_

_

W

73. set K = fE1 ; E2 ; : : :g formulas, K denotes (-n infinite) disjunction E1 _ E2 _ 1 1 1
448

fiParameter Learning Logic Programs Symbolic-statistical Modeling

3 def
= f! 2
DB j ! = MDB () 2
F g:
Note 3 merely subset
DB , cannot conclude PDB (3) = 1 priori,
next theorem, Theorem A.2, states PDB (3) = 1, i.e. distribution semantics distributes
probability mass exclusively 3, i.e. possible least Herbrand models.
prove theorem, need preparations. Recalling atoms outside head(R)[
F chance proved DB, introduce
30 def
= f! 2
DB j ! j= :D every ground atom 62 head(R) [ F g:
Herbrand interpretation ! 2
DB , !jF (2
F ) restriction ! atoms
F .
Lemma A.3 Let ! 2
DB Herbrand
interpretation.
0
! = MDB ( ) 2
F iff ! 2 3 ! j= B $ DB (B ) every B 2 head(R).
(Proof) Only-if part immediate property least Herbrand model.
if-part, suppose ! satisfies right hand side. show ! = MDB (!jF ). !
MDB (! jF ) coincide w.r.t. atoms head(R), enough prove also give
truth values atoms head(R). Take B 2 head(R) write DB (B) =
S1 _ S2 _ 1 11 Suppose ! j= B $ S1 _ S2 _ 11 1 ! j= B , ! j= Sj j ,
thereby !jF j= Sj , hence MDB (!jF ) j= Sj , implies MDB (!jF ) j= B. Otherwise
! j= :B . ! j= :Sj every j . follows MDB (! jF ) j= :B . Since B arbitrary,
conclude ! MDB (!jF ) agree truth values assigned atoms head(R)
well.
Q.E.D.
W

W

Theorem A.2 PDB(3) = 1.

(Proof) Lemma A.3,
3 = f! 2
DB j ! = MDB ( ) 2
F g
= 30 \
3B :
\

B2head(R)

PDB (3B ) = 1 Proposition A.2. prove PDB (30 ) = 1, let D1; D2 ; : : : enumeration
atoms belonging head(R) [ F . provable DB = F [ R,
hence false every least Herbrand model MDB ( ) ( 2
F ).
PDB (30 )

= mlim
!1 PDB (f! 2
DB j ! j= :D1 ^ 11 1 ^ :Dm g)
= mlim
!1 PF (f 2
F j MDB ( ) j= :D1 ^ 1 1 1 ^ :Dm g)
= PF (
F ) = 1:
Since countable conjunction measurable sets probability measure one also
probability measure one, follows PDB (3B ) = 1 every B 2 head(R) PDB (30) =
1 PDB (3) = 1.
Q.E.D.
449

fiSato & Kameya
Appendix B. MAR (missing random) Condition

original formulation EM algorithm Dempster et al. (1977), assumed
exists many-to-one mapping = (x) complete data x incomplete
(observed) data y. case parsing, x parse tree input sentence x
uniquely determines y. paper, uniqueness condition ensures existence
many-to-one mapping explanations observations. however sometimes face
situation many-to-one mapping complete data incomplete
data nonetheless wish apply EM algorithm.
dilemma solved introduction missing-data mechanism
makes complete data incomplete. missing-data mechanism, m, distribution
g (m j x) parameterized , observed data, described = (x). says
x becomes incomplete m. correspondence x , i.e. fhx; j 9m(y =
(x))g naturally becomes many-to-many.
Rubin (1976) derived two conditions g (data missing random data
observed random) collectively called MAR (missing random) condition, showed
assume missing-data mechanism behind observations satisfies MAR
condition, may estimate parameters distribution x simply applying
EM algorithm y, observed data.
adapt MAR condition parameterized logic programs follows. keep
generative model satisfying uniqueness condition outputs goals G parse
trees. extend model additionally inserting missing-data mechanism
G observation like = (G) assume satisfies MAR
condition. extended model many-to-many correspondence explanations observations, generates non-exclusive observations P (O ^ O0 ) > 0
(O 6= O0 ), causes P (O) 1 P (O) = G:9m O= (G) PDB (G). Thanks
MAR condition however, still allowed apply EM algorithm nonexclusive observations. Put differently, even uniqueness condition seemingly
destroyed, EM algorithm applicable (imaginarily) assuming missing-data
mechanism satisfying MAR condition.
P

P



References

Abney, S. (1997). Stochastic attribute-value grammars. Computational Linguistics, 23 (4),
597{618.
Arimura, H. (1997). Learning acyclic first-order horn sentences entailment.
Proceedings Eighth International Workshop Algorithmic Learning Theory.
Ohmsha/Springer-Verlag.
Bacchus, F., Grove, A., Halpern, J., & Koller, D. (1996). statistical knowledge bases
degrees belief. Artificial Intelligence, 87, 75{143.
Baker, J. K. (1979). Trainable grammars speech recognition. Proceedings Spring
Conference Acoustical Society America, pp. 547{550.

450

fiParameter Learning Logic Programs Symbolic-statistical Modeling

Beil, F., Carroll, G., Prescher, D., Riezler, S., & Rooth, M. (1999). Inside-Outside estimation
lexicalized PCFG German. Proceedings 37th Annual Meeting
Association Computational Linguistics (ACL'99), pp. 269{276.
Breese, J. S. (1992). Construction belief decision networks. Computational Intelligence, 8 (4), 624{647.
Carroll, G., & Rooth, M. (1998). Valence induction head-lexicalized PCFG. Proceedings 3rd Conference Empirical Methods Natural Language Processing
(EMNLP 3).
Castillo, E., Gutierrez, J. M., & Hadi, A. S. (1997). Expert Systems Probabilistic
Network Models. Springer-Verlag.
Charniak, E., & Carroll, G. (1994). Context-sensitive statistics improved grammatical language models. Proceedings 12th National Conference Artificial
Intelligence (AAAI'94), pp. 728{733.
Chi, Z., & Geman, S. (1998). Estimation probabilistic context-free grammars. Computational Linguistics, 24 (2), 299{305.
Chow, Y., & Teicher, H. (1997). Probability Theory (3rd ed.). Springer.
Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic
Databases, pp. 293{322. Plenum Press.
Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT Press.
Cussens, J. (1999). Loglinear models first-order probabilistic reasoning. Proceedings
15th Conference Uncertainty Artificial Intelligence (UAI'99), pp. 126{133.
Cussens, J. (2001). Parameter estimation stochastic logic programs. Machine Learning,
44 (3), 245{271.
D'Ambrosio, B. (1999). Inference Bayesian networks. AI Magazine, summer, 21{36.
Dekhtyar, A., & Subrahmanian, V. S. (1997). Hybrid probabilistic programs. Proceedings
14th International Conference Logic Programming (ICLP'97), pp. 391{405.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incomplete
data via EM algorithm. Royal Statistical Society, B39 (1), 1{38.
Doets, K. (1994). Logic Logic Programming. MIT Press.
Flach, P., & Kakas, A. (Eds.). (2000). Abduction Induction { Essays Relation
Integration. Kluwer Academic Publishers.
Frish, A., & Haddawy, P. (1994). Anytime deduction probabilistic logic. Journal
Artificial Intelligence, 69, 93{122.
Fujisaki, T., Jelinek, F., Cocke, J., Black, E., & Nishino, T. (1989). probabilistic parsing
method sentence disambiguation. Proceedings 1st International Workshop
Parsing Technologies, pp. 85{94.
Japan EDR, L. (1995). EDR electronic dictionary technical guide (2nd edition). Technical
report, Japan Electronic Dictionary Research Institute, Ltd.
451

fiSato & Kameya

Kakas, A. C., Kowalski, R. A., & Toni, F. (1992). Abductive logic programming. Journal
Logic Computation, 2 (6), 719{770.
Kameya, Y. (2000). Learning Representation Symbolic-Statistical Knowledge (in
Japanese). Ph. D. dissertation, Tokyo Institute Technology.
Kameya, Y., & Sato, T. (2000). Ecient EM learning parameterized logic programs.
Proceedings 1st Conference Computational Logic (CL2000), Vol. 1861
Lecture Notes Artificial Intelligence, pp. 269{294. Springer.
Kita, K. (1999). Probabilistic Language Models (in Japanese). Tokyo Daigaku Syuppan-kai.
Koller, D., McAllester, D., & Pfeffer, A. (1997). Effective Bayesian inference stochastic programs. Proceedings 15th National Conference Artificial Intelligence
(AAAI'97), pp. 740{747.
Koller, D., & Pfeffer, A. (1997). Learning probabilities noisy first-order rules. Proceedings 15th International Joint Conference Artificial Intelligence (IJCAI'97),
pp. 1316{1321.
Kyburg, H. (1994). Uncertainty logics. Gabbay, D., Hogger, C., & Robinson, J. (Eds.),
Handbook Logics Artificial Intelligence Logic Programming, pp. 397{438.
Oxford Science Publications.
Lafferty, J. (1993). derivation Inside-Outside Algorithm EM algorithm.
Technical report, IBM T.J.Watson Research Center.
Lakshmanan, L. V. S., & Sadri, F. (1994). Probabilistic deductive databases. Proceedings
1994 International Symposium Logic Programming (ILPS'94), pp. 254{268.
Lari, K., & Young, S. J. (1990). estimation stochastic context-free grammars using
Inside-Outside algorithm. Computer Speech Language, 4, 35{56.
Li, Z., & D'Ambrosio, B. (1994). Ecient inference Bayes networks combinatorial
optimization problem. International Journal Approximate Reasoning, 11, 55{81.
Lloyd, J. W. (1984). Foundations Logic Programming. Springer-Verlag.
Lukasiewicz, T. (1999). Probabilistic deduction conditional constraints basic
events. Journal Artificial Intelligence Research, 10, 199{241.
Manning, C. D., & Schutze, H. (1999). Foundations Statistical Natural Language Processing. MIT Press.
McLachlan, G. J., & Krishnan, T. (1997). EM Algorithm Extensions. Wiley
Interscience.
Muggleton, S. (1996). Stochastic logic programs. de Raedt, L. (Ed.), Advances
Inductive Logic Programming, pp. 254{264. IOS Press.
Ng, R., & Subrahmanian, V. S. (1992). Probabilistic logic programming. Information
Computation, 101, 150{201.
Ngo, L., & Haddawy, P. (1997). Answering queries context-sensitive probabilistic
knowledge bases. Theoretical Computer Science, 171, 147{177.
Nilsson, N. J. (1986). Probabilistic logic. Artificial Intelligence, 28, 71{87.
452

fiParameter Learning Logic Programs Symbolic-statistical Modeling

Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.
Pereira, F. C. N., & Schabes, Y. (1992). Inside-Outside reestimation partially bracketed
corpora. Proceedings 30th Annual Meeting Association Computational Linguistics (ACL'92), pp. 128{135.
Pereira, F. C. N., & Warren, D. H. D. (1980). Definite clause grammars language analysis
| survey formalism comparison augmented transition networks.
Artificial Intelligence, 13, 231{278.
Pfeffer, A., & Koller, D. (2000). Semantics inference recursive probability models.
Proceedings Seventh National Conference Artificial Intelligence (AAAI'00),
pp. 538{544.
Poole, D. (1993). Probabilistic Horn abduction Bayesian networks. Artificial Intelligence, 64 (1), 81{129.
Pynadath, D. V., & Wellman, M. P. (1998). Generalized queries probabilistic context-free
grammars. IEEE Transaction Pattern Analysis Machine Intelligence, 20 (1),
65{77.
Rabiner, L. R. (1989). tutorial hidden markov models selected applications
speech recognition. Proceedings IEEE, 77 (2), 257{286.
Rabiner, L. R., & Juang, B. (1993). Foundations Speech Recognition. Prentice-Hall.
Ramakrishnan, I., Rao, P., Sagonas, K., Swift, T., & Warren, D. (1995). Ecient tabling
mechanisms logic programs. Proceedings 12th International Conference
Logic Programming (ICLP'95), pp. 687{711. MIT Press.
Reddy, C., & Tadepalli, P. (1998). Learning first-order acyclic horn programs entailment. Proceedings 15th International Conference Machine Learning;
(and Proceedings 8th International Conference Inductive Logic Programming). Morgan Kaufmann.
Riezler, S. (1998). Probabilistic Constraint Logic Programming. Ph.D. thesis, Universitat
Tubingen.
Rubin, D. (1976). Inference missing data. Biometrika, 63 (3), 581{592.
Sagonas, K., T., S., & Warren, D. (1994). XSB ecient deductive database engine.
Proceedings 1994 ACM SIGMOD International Conference Management
Data, pp. 442{453.
Sato, T. (1995). statistical learning method logic programs distribution semantics.
Proceedings 12th International Conference Logic Programming (ICLP'95),
pp. 715{729.
Sato, T. (1998). Modeling scientific theories PRISM programs. Proceedings ECAI'98
Workshop Machine Discovery, pp. 37{45.
Sato, T. (2001). Minimum likelihood estimation negative examples statistical abduction. Proceedings IJCAI-01 workshop Abductive Reasoning, pp. 41{47.
Sato, T., & Kameya, Y. (1997). PRISM: language symbolic-statistical modeling.
Proceedings 15th International Joint Conference Artificial Intelligence
(IJCAI'97), pp. 1330{1335.
453

fiSato & Kameya

Sato, T., & Kameya, Y. (2000). Viterbi-like algorithm EM learning statistical
abduction. Proceedings UAI2000 Workshop Fusion Domain Knowledge
Data Decision Support.
Sato, T., Kameya, Y., Abe, S., & Shirai, K. (2001). Fast EM learning family PCFGs.
Titech technical report (Dept. CS) TR01-0006, Tokyo Institute Technology.
Shen, Y., Yuan, L., You, J., & Zhou, N. (2001). Linear tabulated resolution based Prolog
control strategy. Theory Practice Logic Programming, 1 (1), 71{103.
Sterling, L., & Shapiro, E. (1986). Art Prolog. MIT Press.
Stolcke, A. (1995). ecient probabilistic context-free parsing algorithm computes
prefix probabilities. Computational Linguistics, 21 (2), 165{201.
Tamaki, H., & Sato, T. (1984). Unfold/fold transformation logic programs. Proceedings
2nd International Conference Logic Programming (ICLP'84), Lecture Notes
Computer Science, pp. 127{138. Springer.
Tamaki, H., & Sato, T. (1986). OLD resolution tabulation. Proceedings 3rd
International Conference Logic Programming (ICLP'86), Vol. 225 Lecture Notes
Computer Science, pp. 84{98. Springer.
Tanaka, H., Takezawa, T., & Etoh, J. (1997). Japanese grammar speech recognition
considering MSLR method. Proceedings meeting SIG-SLP (Spoken
Language Processing), 97-SLP-15-25, pp. 145{150. Information Processing Society
Japan. Japanese.
Uratani, N., Takezawa, T., Matsuo, H., & Morita, C. (1994). ATR integrated speech
language database. Technical report TR-IT-0056, ATR Interpreting Telecommunications Research Laboratories. Japanese.
Warren, D. S. (1992). Memoing logic programs. Communications ACM, 35 (3),
93{111.
Wetherell, C. S. (1980). Probabilistic languages: review open questions. Computing Surveys, 12 (4), 361{379.
White, H. C. (1963). Anatomy Kinship. Prentice-Hall.
Zhang, N., & Poole, D. (1996). Exploiting causal independence Bayesian network inference. Journal Artificial Intelligence Research, 5, 301{328.

454

fiJournal Artificial Intelligence Research 15 (2001) 1-30

Submitted 11/00; published 7/01

Goal Recognition Goal Graph Analysis
j.hong@ulst.ac.uk

Jun Hong
School Information Software Engineering
University Ulster Jordanstown
Newtownabbey, Co. Antrim BT37 0QB, UK

Abstract
present novel approach goal recognition based two-stage paradigm graph
construction analysis. First, graph structure called Goal Graph constructed
represent observed actions, state world, achieved goals well
various connections nodes consecutive time steps. Then, Goal Graph
analysed time step recognise partially fully achieved goals
consistent actions observed far. Goal Graph analysis also reveals valid
plans recognised goals part goals.
approach goal recognition need plan library. suer
problems acquisition hand-coding large plan libraries, neither
problems searching plan space exponential size. describe two algorithms
Goal Graph construction analysis paradigm. algorithms
provably sound, polynomial-time, polynomial-space. number goals recognised
algorithms usually small sequence observed actions
processed. Thus sequence observed actions well explained recognised goals
little ambiguity. evaluated algorithms UNIX domain,
excellent performance achieved terms accuracy, eciency, scalability.

1. Introduction
Plan recognition involves inferring intentions agent set observations.
typical approach plan recognition uses explicit representation possible plans
goals, often called plan library, conducts type reasoning basis set
observations identify plans goals plan library, could caused
observations.
Plan recognition useful many areas, including discourse analysis natural language question-answering systems, story understanding, intelligent user interfaces,
multi-agent coordination. Much early research plan recognition done natural language question-answering systems (Allen & Perrault, 1980; Allen, 1983; Sidner,
1985; Litman & Allen, 1987; Carberry, 1988; Pollack, 1990; Grosz & Sidner, 1990).
systems, plan recognition used support intelligent response generation;
understand sentence fragments, ellipsis indirect speech acts; track speakers ow
discourse; deal correctness completeness discrepancies
knowledge users systems.
Plan recognition enhance user interfaces. recognition users goals
plans interaction interface facilitates intelligent user help (Carver, Lesser,
& McCue, 1984; Hu & Lesser, 1988; Goodman & Litman, 1992; Bauer & Paul, 1993;
Lesh & Etzioni, 1995). Plan recognition enables interface assist user task
c
2001
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHong

completion, error detection recovery (Wilensky & et al., 1988). interface
watching users shoulder infer goals plans. decide
help assistance user needs.
story understanding (Schank & Abelson, 1977; Wilensky, 1983; Charniak & Goldman,
1993), useful recognise goals plans characters described
actions order understand characters doing. multi-agent coordination,
ecient eective coordination among multiple agents requires modelling agents
goals plans (Huber, Durfee, & Wellman, 1994; Huber & Durfee, 1995).
Given set observations, plan recognition systems (Allen & Perrault, 1980;
Carberry, 1986; Litman & Allen, 1987; Kautz, 1987; Pollack, 1990)) search space
possible plan hypotheses candidate plans goals account observations.
form search space given domain, kind plan library required.
instance, Kautzs event hierarchy (Kautz, 1987), plan decompositions required
describe low-level actions make complex actions. Despite obvious advantage
expressive richness, use plan library limitations. First, able deal
new plans whose types appear plan library. Second, acquiring handcoding plan library large complex domain presents tedious impractical task.
Third, domains, knowledge plans might readily available.
attempts (Mooney, 1990; Forbes, Huang, Kanazawa, & Russell, 1995; Lesh &
Etzioni, 1996; Albrecht, Zukerman, & Nicholson, 1998; Bauer, 1998) recently
made apply machine learning techniques automated acquisition coding plan
libraries. Even leaving aside plan library consideration, searching plan space
can, however, exponentially expensive number possible plan hypotheses
exponential number actions (Kautz, 1987). plan recognition systems
developed domains peoples behaviour characterized fewer
100 plans goals (Lesh & Etzioni, 1996).
paper, focus goal recognition, special case plan recognition.
introduce novel approach goal recognition, graph construction analysis
used paradigm. approach signicantly diers plan recognition systems.
First, approach need plan library. Instead dene constitutes valid
plan goal. need consider observed actions organised plans.
Hence problems associated acquisition hand-coding
plan library large complex domain well availability planning knowledge
domain. plan recognition systems cannot recognise new plans whose types
appear plan library. Without using plan library, approach suer
limitation. Second, instead immediately searching plan plan space
plan recognition systems, approach explicitly constructs graph structure,
called Goal Graph, analysed recognise goals plans. approach
therefore problems searching plan space exponential size. Third,
approach recognises partially fully achieved goals consistent
actions observed far. number recognised goals usually small
sequence observed actions processed. Thus sequence observed actions
well explained recognised goals little ambiguity.
emphasised approach goal recognition, purpose recognising partially fully achieved goals explain past actions rather predicting
2

fiGoal Recognition Goal Graph Analysis

future actions. particularly useful problem areas story understanding,
software advisory systems, database query optimisation, customer data mining.
problem areas several specic characteristics. First, actions either described observed. Second, likely users intended goal partially
fully achieved actions. Third, recognising intended goal aims explaining past actions rather predicting future actions. Finally, distinguishing partially
fully achieved goals others greatly reduces ambiguity involved recognising
intended goal.
story understanding, actions characters described story. Recognising goals plans account described actions enables better understanding
characters doing. software advisory systems, user
observed issue sequence operations software application, system rst
recognise task user performed. system decide whether user
performed task suboptimal way, advice given user
better perform task. database query optimisation, user conducted sequence data retrieval manipulation operations, recognising underlying
query lead advice query optimisation query executed
optimal way. customer data mining, individual customers shopping goals
recognised logged customer on-line shopping data. also form basis
performing customer data mining tasks.
algorithms Goal Graph construction analysis provably sound,
polynomial-time, polynomial-space. empirical results UNIX domain show
algorithms perform well terms accuracy, eciency, scalability. also
show algorithms scaled applied domains tens
thousands possible goals plans. Though algorithm Goal Graph analysis
complete, recognised every goal intended successfully achieved
subject UNIX data set used evaluation. Since new graph-based
approach goal recognition fundamentally dierent existing methods plan
recognition, provides alternative methods new perspective plan
recognition problem.
rest paper organised follows. First, give overview novel
approach goal recognition. Section 3, discuss domain representation.
Section 4 dene Goal Graphs, valid plans, consistent goals. Section 5 present
goal recognition algorithms together analysis algorithms. Section 6
discuss empirical results. summarise paper discuss limitations future
work last section.

2. Novel Approach Goal Recognition
section, describe basic assumptions make goal recognition problem
outline approach. discuss previous work planning Planning Graphs
graph-based approach goal recognition. briey describe empirical results
favour approach.
3

fiHong

2.1 Basic Assumptions
start example UNIX domain. observe user types two
commands, cd papers ls, one another, able infer user
wants nd le subdirectory directory, papers, two reasons. First, goal
fully achieved. Second, relevant commands consistent way
sense rst command satises one preconditions second command
second command achieves recognised goal. recognised goal might
intermediate goal user. users intended goal might one le related
goals, instance, deleting le directory. Since commands
part plans almost le related goals, impossible us uniquely identify
users intended goal current time step. Yet goal nding le directory
well explains commands. user next types command, rm oldpaper.tex,
infer users goal delete le, oldpaper.tex, directory, papers,
goal fully achieved relevant commands observed
far consistent way sense rst command satises one preconditions
second third commands, second command satises one preconditions
third command, third command achieves recognised goal.
example highlights way new approach goal recognition works. make
following assumptions goal recognition problem. First, set actions
observed consecutive time steps.1 Second, initial state world immediately
set actions observed known.2 Third, domain knowledge
actions goals, is, know preconditions eects every observed action,
every possible goal explicitly specied set goal descriptions.
Given assumptions, action observed time step, want infer
goals partially fully achieved time step whether
achieved goals relevant strict majority actions observed far consistent
way sense actions organised plan structure goal
part it.
2.2 Goal Recognition Goal Graph
propose use graph structure, called Goal Graph, new approach goal
recognition. view goal recognition problem process graph construction
analysis. Goal Graph, action nodes represent actions observed consecutive time
steps; proposition nodes represent state world consecutive time steps,
changed initial state subsequent states observed actions; goal
nodes represent goals partially fully achieved consecutive time steps.
Edges Goal Graph explicitly represent relations actions propositions
well relations propositions goals. Based explicit relations
constructed Goal Graph, causal links either two actions action goal
recognised. recognised causal links, decided whether fully
partially achieved goal time step relevant strict majority observed
1. observed actions partially ordered sense one action observed
time step temporal ordering constraint actions.
2. approach however reasons state world subsequent time steps.

4

fiGoal Recognition Goal Graph Analysis

actions far consistent way sense relevant actions organised
plan structure goal part it. approach, extraneous, redundant,
partially ordered actions plans handled.
attempt use graph construction analysis paradigm goal recognition
spirit inuenced Blum Fursts eorts planning Planning Graphs (Blum
& Furst, 1997). introduced new graph-based approach planning STRIPS
domains, graph structure called Planning Graph rst constructed explicitly
rather searching immediately plan standard planning methods. Many useful
constraints inherent planning problem made explicitly available Planning
Graph reduce amount search needed. Planning Graph analysed
generate possible plans.
Goal-Graph-based approach goal recognition seen counterpart
planning Planning Graph. Though graph structures used approaches,
composed dierent kinds nodes edges. time step, Planning Graph
represents possible propositions either added actions previous time step
brought forward maintenance actions previous time step, possible
actions whose preconditions satised propositions time step.
hand, Goal Graph, time step, represents propositions either added
actions observed previous time step brought forward maintenance actions
previous time step, actions observed time step. addition, Goal
Graph, time step, also represents possible goals, either fully partially achieved
time step, Planning Graph represent goal all. Accordingly,
Planning Graph represents relations actions propositions, Goal
Graph also represents relations propositions goals.
analysis Planning Graph aims search possible subgraphs
Planning Graph, form valid plans given goal. hand,
analysis Goal Graph aims search every possible partially fully goal
exists subgraph Goal Graph, consisting strict majority observed
actions. subgraph forms valid plan goal part shows
strict majority observed actions relevant goal consistent way.
domain representation planning Planning Graph
goal recognition Goal Graph. regard, previous eorts handling
expressive representation languages (Gazen & Knoblock, 1997; Anderson, Smith, & Weld,
1998; Koehler, Nebel, Homann, & Dimopoulos, 1997) still useful goal recognition.
languages allow use disjunctive preconditions, conditional eects, universally
quantied preconditions (goal descriptions) eects action goal representation.
ADL-like domain representation actually based work, allows use
conditional eects, universally quantied eects, existentially universally quantied
preconditions goal descriptions action goal representation.
Goal-Graph-based approach extends Lesh Etzionis previous work
use graph representation actions goals goal recognition problem (Lesh &
Etzioni, 1995). used graph representation, called consistency graph, goal
recognition problem. consistency graph consists action goal nodes representing
possible actions goals, edges representing possible connections nodes
5

fiHong

graph. Initially, action goal nodes fully connected consistency
graph, inconsistent goals repeatedly pruned consistency graph.
number major dierences Lesh Etzionis approach ours.
First, two dierent graph representations used. Apart action goal nodes,
consistency graph nodes representing propositions model
state world changed observed actions. Therefore, consistency graph
explicitly reveal causal links actions goals. Neither system
know whether goal partially fully achieved observed actions. Goal
Graph consists action, goal, proposition nodes. explicitly reveals causal links
actions goals, hence system knows observed actions composed
valid plans recognised goals part goals. systems also knows whether
goal partially fully achieved observed actions.
Second, goal consistency dened dierently. Lesh Etzionis approach, goal
consistent exists plan includes observed actions achieves
goal. approach, goal consistent partially fully achieved
observed actions relevant strict majority observed actions. Also, two
dierent recognition processes used. approach pruning process used
prune inconsistent goals consistency graph. pruning process guarantees
goals pruned consistency graph inconsistent goals. However, number
consistent goals, still remaining consistency graph pruning, usually large. Thus
ambiguity intended goal remains issue addressed. approach instead
uses graph analysis process directly recognise consistent goals fully
partially achieved goals. number consistent goals recognised Goal Graph
usually small. Third, approach requires every observed action relevant
goal, strict majority observed actions required relevant
goal approach.
developed two algorithms, GoalGraphConstructor GoalGraphAnalyser,
based two-stage paradigm Goal Graph construction analysis. GoalGraphConstructor algorithm takes set actions observed dierent time
steps constructs Goal Graph. GoalGraphAnalyser algorithm analyses constructed Goal Graph recognise consistent goals valid plans. prove
algorithms sound, polynomial-time, polynomial-space.
algorithms implemented Prolog tested UNIX domain
desktop Pentium III processor 600 MHz. used set data, collected
UNIX domain University Washington, domain representation 35 action
schemata 249 goal schemata. entire UNIX data set, average took
CPU seconds update Goal Graph observed action processed, usually
small number consistent goals remained sequence actions
observed. test cases intended goals successfully achieved
subjects, intended goals among remaining goals recognised
complete sequences actions observed. test scalability algorithms,
tested series spaces approximate 104 , 2 104 , 105 candidate goals
respectively UNIX domain, approximate linear time performance
achieved. empirical results show algorithms scaled applied
domains tens thousands possible goals plans.
6

fiGoal Recognition Goal Graph Analysis

3. Domain Representation
use ADL-like representation (Pednault, 1989), including actions conditional
universally quantied eects, existentially well universally quantied preconditions
goal descriptions. approach goal recognition, goal recognition problem
consists
set action schemata specifying primitive actions.
nite, dynamic universe typed objects objects either added
deleted action.
set propositions called Initial Conditions.
set goal schemata specifying possible goals.
set actions observed consecutive time steps.3
solution goal recognition problem consists set partially fully achieved
goals consistent set observed actions together valid plans
consisting observed actions recognised goals part them.
goal schema consists set goal descriptions (GDs) dened
following EBNF denitions.
<GD>
<GD>
<GD>
<GD>
<GD>
<GD>
<GD>
<GD>
<GD>

::=
::=
::=
::=
::=
::=
::=
::=
::=

<term>
(not <term>)
(neg <term>)
(and <GD>*)
(imply <GD> <GD>)
(exist <term> <GD>)
(forall <term> <GD>)
(eq <argument> <argument>)
(neq <argument> <argument>)

action schema consists set preconditions set eects. set
preconditions dened goal descriptions. set eects dened
following EBNF denitions.
<effect>
<effect>
<effect>
<effect>
<effect>

::=
::=
::=
::=
::=

<term>
(neg <term>)
(and <effect>*)
(when <GD> <effect>)
(forall <term> <effect>)

3. say observed action, mean action observed successfully executed.
ignore invalid actions. UNIX domain, instance, invalid actions issued
commands UNIX failed execute responded error messages.

7

fiHong

two sets EBNF denitions, <term> atomic expression form:
<term> ::= (<predicate-name> <argument>*)
<argument> ::= <constant-name>
<argument> ::= <variable-name>
use eq neq specify equality inequality constraints. two negation
connectives: neg not. use (neg A) specically mean truth value
made explicitly known false action. use (not A) mean truth value
known false either explicitly implicitly. latter kind representation
used necessary represent truth value explicitly known
false long known false. closed world assumption therefore
implemented follows. initial state world, explicitly represent
propositions known true Initial Conditions. proposition explicitly
represented state world implicitly known false. Actions however may
add propositions explicitly known false state world. proposition
become explicitly known false made explicitly known
false action. important represent propositions explicitly known
false, want explicitly represent eects actions causal links
either two actions action goal established.
goal action schemata parameterised typed variables represented
terms object type predicates. goal ground instance goal schema.
action ground instance action schema. set goal descriptions goal must
satised state world goal fully achieved.
goal descriptions satised instead, goal partially achieved. Positive literals
goal descriptions represent propositions true state world. Negative literals
goal descriptions represent propositions known false state world.
use imply specify dependency constraints goal descriptions. goal description GD2
implied another goal description GD1 , GD2 satised GD1 satised
GD1 satised without GD2 satised. goal description existentially
universally quantied dynamic universe objects.
set preconditions must satised state world action
executed. set preconditions syntax semantics
set goal descriptions. set eects taken state world
action executed. Positive literals eects represent propositions true state
world action executed. propositions added state
world. Negative literals eects represent propositions longer true state
world action executed. propositions deleted state
world, negations propositions added state world,
representing propositions explicitly known false state world
action executed. Furthermore, conditional eect consists antecedent
consequent, antecedent set preconditions consequent set
eects. eects consequent taken preconditions
antecedent satised state world action executed. eect
action schema universally quantied dynamic universe objects.
8

fiGoal Recognition Goal Graph Analysis

use simple example domain extended Pednaults famous example (Pednault,
1988). involves transportation two physical objects, dictionary, chequebook,
home oce using briefcase. assume one physical object
carried briefcase time. extended briefcase domain consists
special physical object: briefcase.
Two physical objects: dictionary chequebook.
Two locations: home oce.
Three action schemata:
Moving briefcase one location another,
Putting physical object briefcase,
Taking physical object briefcase.
Three goal schemata:
Moving physical object one location another,
Keeping physical object location,
Keeping physical object briefcase.
action goal schemata example domain shown Figure 1.
used throughout paper.
actual implementation goal recognition algorithms, universally quantied
preconditions eects, conditional eects action schemata eliminated;
equivalent schemata created. use particular approach call dynamic expansion.
Dynamic expansion involves two steps. rst step, universally quantied preconditions
eects action schema dynamically compiled corresponding Herbrand
bases, taking account universe objects current time step. universally
quantied preconditions eects dynamically compiled assume
universe objects dynamically changed. assumption needed
domain like UNIX shell system destruction creation objects required.
assumption dynamic universe objects, object universe,
object type must declared time step immediately action
executed. object initial universe objects, type must declared
Initial Conditions. object either added deleted universe objects
action time step, eect either stating proposition new object
negating proposition existing object.
instance, suppose time step immediately instance action
schema mov-b shown Figure 1 executed, universe objects consists three physical
objects: B, C, D. Action schema mov-b dynamically compiled action schema
mov-b-1 follows.
9

fiHong

(:action mov-b
:paras (?l ?m - loc)
:pre (and (neq ?l ?m)(at B ?l))
:eff (and (at B ?m) (neg (at B ?l))
(forall (?z - physob)
(when (in ?z)
(and (at ?z ?m)
(neg (at ?z ?l)))))) )
(:action put-in
:paras (?x - physob ?l loc)
:pre (and (neq ?x B)(at ?x ?l)(at B ?l))
(forall (?z - physob)
(not (in ?z))))
:eff (in ?x) )
(:action take-out
:paras (?x - physob)
:pre (in ?x)
:eff (neg (in ?x)) )
(:goal move-object
:paras (?x - physob ?l ?m - loc)
:goal-des (and (neq ?l ?m)
(neq ?x B)
(imply (neg (at ?x ?l))
(at ?x ?m))) )
(:goal keep-object-at
:paras (?x - physob ?l - loc)
:goal-des (and (neq ?x B)
(imply (at ?x ?l)
(not (in ?x)))) )
(:goal keep-object-in
:paras (?x - physob)
:goal-des (in ?x) )
Figure 1: action goal schemata extended briefcase domain

10

fiGoal Recognition Goal Graph Analysis

(:action mov-b-1
:paras (?l ?m - loc)
:pre (and (neq ?l ?m) (at B ?l))
:eff (and (at B ?m) (neg (at B ?l))
(when (in B)
(and (at B ?m)
(neg (at B ?l))))
(when (in C)
(and (at C ?m)
(neg (at C ?l))))
(when (in D)
(and (at ?m)
(neg (at ?l))))) )
second step, conditional eects mov-b-1 eliminated. Assume
that, time step, following propositions true: (at B H), (at C H), (at H),
(in D). conditional eects mov-b-1, whose antecedents satised
time step, removed. therefore action schema mov-b-2.
(:action mov-b-2
:paras (?l ?m - loc)
:pre (and (neq ?l ?m) (at B ?l))
:eff (and (at B ?m) (neg (at B ?l))
(when (in D)
(and (at ?m)
(neg (at ?l))))) )
antecedent remaining conditional eect mov-b-2 already satised
time step moved existing preconditions. nally action schema
mov-b-3 current time step. Action schema mov-b-3 equivalent original
action schema mov-b current time step. mov-b-3 actually used
action schema, Moving briefcase one location another, time step.
(:action mov-b-3
:paras (?l ?m - loc)
:pre (and (neq ?l ?m) (at B ?l)
(in D))
:eff (and (at B ?m) (neg (at B ?l))
(at ?m) (neg (at ?l))))
universally quantied goal descriptions goal schema treated
way universally quantied preconditions action schema.

4. Goal Graphs, Valid Plans Consistent Goals
section, rst describe structure Goal Graph. dene
mean say set observed actions forms valid plan achieving goal given
11

fiHong

mov-b H

put-in H

mov-b H

Actions

B
H

B H
B

B H

B

B

B H

C H

H

H



C H

C H

H
C H




keep-object-at H

keep-object-at H

keep-object-at C H

keep-object-at C H
keep-object-in D*

Propositions

move-object H O*

keep-object-at C H

Goals

keep-object-at C H
keep-object-in
keep-object-at

Level 1

Level 2

Level 3

Level 4

Figure 2: Goal Graph example extended briefcase domain
Initial Conditions. nally dene mean say goal consistent
set observed actions.
4.1 Goal Graphs
Goal Graph represents actions observed, propositions true explicitly known
false, fully partially achieved goals consecutive time steps. Goal Graph
also explicitly represents connections propositions, actions, goals graph.
Goal Graph directed, levelled graph. levels alternate proposition
levels containing proposition nodes (each labelled proposition negation proposition), representing state world consecutive time steps; goal levels containing
goal nodes (each labelled goal), representing goals fully partially achieved consecutive time steps; action levels containing action nodes (each labelled action),
representing actions observed consecutive time steps. levels Goal Graph start
proposition level time step 1, consisting one node proposition true
Initial Conditions. end goal level last time step, consisting
node goals either fully partially achieved actions observed far.
levels are: propositions true time step 1, goals achieved time step 1, actions
observed time step 1; propositions true explicitly known false time step 2,
goals achieved time step 2, actions observed time step 2; propositions true explicitly
known false time step 3, goals achieved time step 3, forth.
goal nodes goal-level connected description edges goal descriptions proposition-level i. action nodes action-level connected precondition
edges preconditions proposition-level i, eect edges eects
proposition-level + 1. proposition nodes proposition-level connected via
persistence edges corresponding proposition nodes proposition-level + 1,
truth values aected actions action-level i. persistence edges
represent eects maintenance actions simply bring forward proposition nodes
proposition-level i, aected actions action-level i, proposition-level + 1.
example shown Figure 2, three actions observed three consecutive time steps: (mov-b H), (put-in H), (mov-b H O). Initial Conditions
12

fiGoal Recognition Goal Graph Analysis

consist of: (at B O), (at H), (at C H). Action goal nodes top
bottom parts graph respectively. proposition nodes middle part
graph. edges connecting proposition nodes action node level
precondition edges. edges connecting action node one level propositions
subsequent level eect edges. edges connecting proposition nodes goal
nodes level description edges. edges connecting proposition nodes
one level proposition nodes subsequent level persistence edges. goal nodes
bold represent consistent goals, among goal nodes italics represent partially
achieved goals, others represent fully achieved goals. edges bold show
causal link paths. goal nodes asterisk represent recognised goals.
4.2 Valid Plans
dene mean say set observed actions forms valid plan
goal, given Initial Conditions.
Definition 1 (Causal Link) Let ai aj two observed actions time steps j
respectively, < j. exists causal link ai aj , written ai aj ,
one eects ai satises one preconditions aj .
instance, example shown Figure 2, exists causal link actions
(mov-b H) time step 1 (put-in H) time step 2, since one eects
rst action, (at B H), satised one preconditions second action.
goal treated action goal descriptions preconditions
empty set eects. Therefore, causal links also established observed actions
goals.
instance, example shown Figure 2, exists causal link action
(mov-b H O) time step 3 goal (move-object H O) time step 4, since one
eects action, (at O), satised one goal descriptions goal.
valid plan goal dened basis temporal ordering constraints
causal links set observed actions. valid plan P goal g, given Initial
Conditions, represented 3-tuple, < A, O, L >, set observed actions,
set temporal ordering constraints A, L set causal links A.
Definition 2 (Valid Plan) Let g goal, P =< A, O, L >, set
observed actions, set temporal ordering constraints, {ai < aj }, A, L
set causal links, {ai aj }, A. Let Initial Conditions. P valid plan
g, given I,
1. actions executed order consistent O;
2. goal g fully achieved actions executed order
consistent O.
instance, example shown Figure 2, given Initial Conditions, = {(at
B O), (at H), (at C H)}, P = ({a1 = (mov-b H), a2 = (put-in H), a3 = (mov-b
H O)}, {a1 < a2 , a2 < a3 }, {a1 a2 , a1 a3 , a2 a3 }) valid plan goal g =
(move-object H O).
13

fiHong

4.3 Consistent Goals
dene mean say goal consistent set observed
actions. set observed actions represented 2-tuple, < A, >,
set observed actions set temporal ordering constraints, {ai < aj }, A.4
Definition 3 (Relevant Action) Given goal g set observed actions, < A, >,
action said relevant g context < A, >,
1. exists causal link, g;
2. exists causal link, b, b relevant g < b consistent
O.
Definition 4 (Consistent Goal) goal g consistent set observed actions,
< A, >, strict majority relevant g context
< A, >.
Proposition 1 (Valid Plan Consistent Goal) Let < A, > set observed
actions, Initial Conditions < A, >, g goal consistent < A, >.
exists set causal links, L = {ai aj }, given I, P =< A, O, L >
valid plan either g g fully achieved time step < A, >
observed achieved part g g partially achieved time step
< A, > observed.
Proof. g fully achieved time step set actions observed,
directly follows Denitions 3 4 exists set causal links, L = {ai aj },
A. follows Denition 2 given I, P =< A, O, L > valid plan g.
g partially achieved time step set actions observed,
let g achieved part g. g fully achieved time step set
actions observed, directly follows Denitions 2, 3 4 exists
set causal links, L = {ai aj }, given I, P =< A, O, L > valid plan
g. 2
instance, example shown Figure 2, < A, > = < {a1 = (mov-b
H), a2 = (put-in H), a3 = (mov-b H O)}, {a1 < a2 , a2 < a3 } >, g = (move-object
H O) fully achieved goal time step < A, > observed. According
Denition 3 4, g consistent < A, > exist causal links, a3 g
a3 g, a2 a3 a2 a3 , a1 a3 a1 a3 , a1 a2
a1 a2 . Let Initial Conditions < A, >, L = {a1 a2 , a1 a3 ,
a2 a3 }, according Proposition 1, P =< A, O, L > valid plan g. Furthermore,
causal link, a3 g, explains purpose a3 .
summary, according Denition 4 Proposition 1, say goal consistent
set observed actions, mean strict majority observed actions
relevant goal set observed actions forms valid plan goal
achieved part it.
4. assume actions observed consecutive time steps one action observed
time step.

14

fiGoal Recognition Goal Graph Analysis

5. Goal Recognition Algorithms
describe goal recognition algorithms. goal recognition algorithms run
two-stage cycle time step. rst stage, GoalGraphConstructor algorithm
takes actions observed time step tries extend Goal Graph. second
stage, GoalGraphAnalyser algorithm analyses constructed Goal Graph recognise
fully partially achieved goals, consistent actions observed far,
valid plans goals part them. two-stage cycle continues
action observed next time step.
5.1 Constructing Goal Graph
use 4-tuple < P, AO , GR , E > represent Goal Graph, P set proposition nodes, AO set action nodes, GR set goal nodes, E set edges.
proposition node represented prop(p, i), p positive negative ground literal,
time step. action node represented action(a, i), observed action
time step. goal node represented goal(g, i), g goal
time step. precondition edge represented precondition-edge(prop(p, i), action(a, i)),
eect edge represented eect-edge(action(a, i), prop(p, + 1)), description edge
represented description-edge(prop(p, i), goal(g, i)), persistence edge represented
persistence-edge(prop(p, 1), prop(p, i)).
GoalGraphConstructor algorithm consists two algorithms: goal expansion
algorithm action expansion algorithm. GoalGraphConstructor algorithm starts
Goal Graph, < P, {}, {}, {} >, consists proposition-level 1 nodes
representing Initial Conditions.
Given Goal Graph ending proposition-level i, goal expansion algorithm rst
extends Goal Graph goal-level i, nodes representing goals fully partially
achieved time step i. algorithm goes every possible ground instance goal
schemata. every goal instance, rst gets set goal descriptions. eliminates
universally quantied goal descriptions dynamic expansion get equivalent
set goal descriptions. goal node added onto goal-level represent achieved
goal, least one goal descriptions satised proposition-level i.
decided whether goal fully partially achieved, based whether
goal descriptions satised respectively proposition-level i. Meanwhile,
node proposition-level satises goal description, description edge connecting
proposition node goal node added onto Goal Graph. Figure 3 shows
goal expansion algorithm. algorithm takes Goal Graph < P, AO , GR , E > ending
proposition-level i, time step i, set goal schemata G input. returns
updated Goal Graph ending goal-level goal expansion.
actions observed time step i, action expansion algorithm extends Goal Graph ending goal-level i, action-level i, nodes representing
observed actions. time, algorithm also extends Goal Graph
proposition-level + 1, nodes representing propositions true explicitly known
false actions observed.
every action observed time step i, algorithm rst instantiates action schema
observed action get precondition set eect set. eliminates
15

fiHong

Goal-Expansion(< P, AO , GR , E >, i, G)
1. every Gk G
every instance g Gk
a. Get set goal descriptions Sg .
b. Get equivalent set Sg , Sg .
c. every pg Sg , pg = not(pg ),
prop(neg(pg ), i) P ,
Add description-edge(prop(neg(pg), i), goal(g, i)) E.
d. every pg Sg , pg = not(pg ),
prop(pg , i) P ,
Add description-edge(prop(pg, i), goal(g, i)) E.
e. one goal descriptions g satised,
Add goal(g, i) GR .
2. Return < P, AO , GR , E >.
Figure 3: goal expansion algorithm

universally quantied preconditions eects, well conditional eects,
dynamic expansion get equivalent precondition eect sets. Meanwhile, node
proposition-level satises precondition action, precondition edge, connecting
proposition node action node, added onto Goal Graph. every eect
action, action expansion algorithm simply adds proposition node representing
eect proposition-level + 1. eect edge action node proposition
node also added onto Goal Graph.
expansion, every proposition node proposition-level brought
forward proposition-level + 1 maintenance action, truth value
changed action observed time step (and added onto Goal Graph
action observed time step i).5 Persistence edges, connecting corresponding
proposition nodes two proposition levels, added onto Goal Graph.
Figure 4 shows action expansion algorithm. algorithm takes Goal Graph
< P, AO , GR , E > ending goal-level i, set actions observed time step i, Ai ,
time step i, set action schemata input. returns updated Goal Graph
ending proposition-level + 1 action expansion. expansion Goal
Graph proposition-level proposition-level + 1 simulates eects executing
actions observed time step i.
otherwise action observed time step i, GoalGraphConstructor algorithm nishes nodes goal-level i, representing possible goals either fully
partially achieved actions observed.

5. goal recognition algorithms allow redundant actions.

16

fiGoal Recognition Goal Graph Analysis

Action-Expansion(< P, AO , GR, E >, Ai , i, A)
1. every ai Ai
a. Add action(ai, i) AO .
b. Instantiate action schema ai get precondition set
SP , eect set SE .
c. Get equivalent sets SP SE , SP SE .
d. every pp SP , pp = not(pp ),
prop(neg(pp, i) P ,
Add precondition-edge(prop(neg(pp, i), action(ai, i)) E.
e. every pp SP , pp = not(pp ),
prop(pp, i) P ,
Add precondition-edge(prop(pp, i), action(ai, i)) E.
f. every pe SE
i. Add prop(pe, + 1) P .
ii. Add eect-edge(action(ai, prop(pe, + 1)) E.
2. every prop(p, i) P
prop(p, + 1)
/ P ,
prop(p, + 1)
/ P , Add prop(p, + 1) P ;
Add persistence-edge(prop(p, i), prop(p, + 1)) E.
3. Return < P, AO , GR , E >.
Figure 4: action expansion algorithm
Theorem 1 (Polynomial Size Time) Consider goal recognition problem
observed actions time steps, nite number objects time step, p propositions
Initial Conditions, goal schemata constant number parameters.
Let l1 largest number eects action schema, l2 largest number
goal descriptions goal schema. Let n largest number objects time
steps. Then, size Goal Graph + 1 levels created GoalGraphConstructor
algorithm, time needed create graph, polynomial n, m, p, l1 , l2 , s.
Proof. maximum number nodes proposition level O(p + l1 s). Let k
largest number parameters goal schema. Since goal schema
instantiated nk distinct ways, maximum numbers nodes edges
goal level O(mnk ) O(l2 mnk ) respectively. obvious time needed
create nodes edges level polynomial number nodes edges
level. 2
Theorem 2 GoalGraphConstructor algorithm sound: goal adds Goal
Graph time step one either fully partially achieved time step state
world. algorithm complete: goal either fully partially achieved
observed actions time step 1, algorithm add Goal Graph
time step i, assumption possible goals restricted categories
goal schemata.
17

fiHong

Proof (soundness). Proposition-level 1 Goal Graph consists Initial
Conditions, representing state world time step 1 action
observed. Goal Graph extended proposition-level 1 proposition-level i,
adding eects actions observed time step i1, bringing forward
proposition nodes aected actions proposition-level
1 proposition-level i. Therefore, proposition-level Goal Graph represents
state world time step i, changed Initial Conditions
actions observed time steps 1, ..., 1.
goal added Goal Graph time step algorithm fully partially
achieved goal proposition-level Goal Graph. Therefore, goal fully
partially achieved state world time step i.
Proof (completeness). Suppose goal either fully partially achieved
actions observed time steps 1, ..., 1. goal either fully partially achieved
proposition-level Goal Graph. Since goal-level Goal Graph consists
possible instances goal schemata, fully partially achieved
proposition-level Goal Graph, goal instance goal schema, one
fully partially achieved goal instances proposition-level i. algorithm
therefore add goal goal-level Goal Graph. 2
5.2 Recognising Consistent Goals Valid Plans
GoalGraphAnalyser algorithm analyses constructed Goal Graph recognise consistent goals valid plans. assume strict majority observed actions
relevant goal intended agent context agents actions. Therefore,
goal intended agent consistent set observed actions, goal
may intended goal consistent set observed actions. order
decide whether goal consistent set observed actions, is, whether
relevant strict majority observed actions, need recognise causal links
either two observed actions observed action goal. dene
two particular types paths, call causal link paths, constructed Goal Graph.
prove Theorems 3 4 causal links recognised identifying causal link
paths.
Definition 5 Given Goal Graph, let ai action observed time step gj
goal fully partially achieved time step j, < j. path connects ai gj
via eect edge, zero persistence edges, description edge, called causal
link path ai gj .
Theorem 3 Given Goal Graph, exists causal link, ai gj , action ai
time step goal gj time step j, < j, ai connected gj via causal
link path.
Proof. According Denition 5, causal link path ai gj consists
eect edge, zero persistence edges, description edge. eect edge
path connects ai proposition node proposition-level + 1, representing one
eects ai . j = + 1, persistence-edge path proposition
18

fiGoal Recognition Goal Graph Analysis

node connected gj description edge. j > + 1, proposition node
brought forward proposition-level j via j i1 persistence-edges j i1 maintenance
actions, brought-forward proposition node proposition-level j connected gj
description edge. either case, one eects ai satised one goal
descriptions gj . Since goal treated action goal descriptions
preconditions empty set eects, according Denition 1, exists causal
link ai gj . 2
Definition 6 Given Goal Graph, let ai aj two actions observed time steps
j respectively, < j. path connects ai aj via eect edge, zero
persistence edges, precondition-edge, called causal link path ai
aj .
Theorem 4 Given Goal Graph, exist causal link, ai aj , action ai
time step action aj time step j, < j, ai connected aj via
causal link path.
proof Theorem 4 similar Theorem 3. details proof omitted.
Given constructed Goal Graph < P, AO , GR , E > levels, GoalGraphAnalyser
algorithm shown Figure 5 recognises every consistent goal goals goal-level t,
deciding whether strict majority observed actions relevant it.
done rst nding relevant actions observed actions, connected
goal causal link paths. already-known relevant actions, algorithm
tries nd relevant actions observed actions, connected
causal link paths. continues relevant action found. consistent
goal recognised valid plan goal part represented 3-tuple,
< gt, < AO , O, La >, Lg >, gt goal, La set causal links observed
actions, Lg set causal links observed actions goal.
< AO , O, La > represents valid plan gt part it, Lg explains
purposes observed actions.
Proposition 2 GoalGraphAnalyser algorithm sound: goal g recognises
time step consistent observed actions far, plan organises g
part g valid.
Proof. GoalGraphAnalyser algorithm recognises goal g time step t,
strict majority observed actions connected g, either directly causal link
path indirectly chain causal link paths. observed action connected
g directly causal link path, according Theorem 3 Denition 3, exists
causal link observed action g, observed action relevant
g. observed action connected g indirectly chain causal link paths,
according Theorem 3, Theorem 4, Denition 3, chain causal links
observed action g, observed action relevant g. Since strict
majority observed actions relevant g, according Denition 4, g consistent
set observed actions. Furthermore, according Proposition 1, plan
GoalGraphAnalyser algorithm organises g part g, < AO , O, La >, valid plan.2
19

fiHong

GoalGraphAnalyser(< P, AO , GR , E >, t)
1. every gt GR goal-level
a. AO {}, {}, Lg {}, La {}.
b. every ai AO connected gt causal link path
Add ai gt Lg ;
Add ai AO ;
Add ai A.
c. = {} ai AO , ai AO ,
Get ordering constraints, O, AO ;
Add < gt , < AO , O, La >, Lg > GoalPlan.
d. = {},
Remove action aj A;
every ai AO connected aj causal link path
Add ai aj La ;
/ AO , Add ai AO , ai A;
ai
Go 1c.
2. Return GoalPlan.
Figure 5: GoalGraphAnalyser algorithm

example shown Figure 2, goal nodes bold represent three consistent
goals, among goal node italics represents partially achieved goal,
two represent two fully achieved goals. edges bold show causal link paths.

Theorem 5 (Polynomial Space Time) Consider t-level Goal Graph. Let l1
number fully partially achieved goals time step t, m1 largest number
goal descriptions goals, l2 number observed actions, m2
largest number preconditions actions. space size possible
causal link paths, connect goals observed actions connect observed
actions observed actions, time needed recognise consistent goals,
polynomial l1 , l2 , m1 , m2 .

Proof. Persistence edges branch Goal Graph. goals
goal-level t, maximum number paths searched observed actions,
connected goal causal link paths hence relevant it, O(m1 ).
relevant actions goal, maximum number paths searched observed
actions, connected relevant action causal link paths hence also
relevant goal, O(m2 ). maximum l1 goals goal-level
l2 relevant actions goals. space size possible causal link paths
O(l1 (m1 + l2 m2 )). time needed recognise consistent goals polynomial
space size. 2
20

fiGoal Recognition Goal Graph Analysis

5.3 Goal Redundancy
GoalGraphAnalyser algorithm recognises fully partially achieved goals time step,
consistent actions observed far. Among consistent goals, fully
achieved goals better explain actions observed far. instance, example shown
Figure 2, two consistent goals recognised GoalGraphAnalyser algorithm time
step 4: (move-object H O) fully achieved (keep-object-at O) partially
achieved. two consistent goals, fully achieved goal better explains
observed actions far. If, instance, another action (take-out D) observed next
time step, (keep-object-at O) becomes fully achieved remains consistent
observed actions. time step, best explains observed actions. partially
achieved goal, consistent observed actions far, remain consistent
actions observed future becomes fully achieved. choosing
fully achieved goal making partially achieved goal redundant rule
possibility partially achieved goal remaining consistent becoming fully achieved
future. Based principle, make partially achieved consistent goal
time step redundant, satised goal descriptions implied satised goal
descriptions another fully partially achieved consistent goal.
Definition 7 partially achieved consistent goal time step redundant, set
satised goal descriptions either subset goal descriptions fully achieved consistent goal proper subset satised goal descriptions another partially achieved
consistent goal time step.
instance, time step 4 set satised goal descriptions (keep-object-at
O) subset goal descriptions (move-object H O). partial achievement
(keep-object-at O) implied full achievement (move-object H
O). (keep-object-at O) made redundant (move-object H O) time step
4.
fully achieved consistent goal time step, however, made redundant
goal descriptions implied goal descriptions another fully achieved consistent
goal time step.
Definition 8 fully achieved consistent goal time step redundant, set
goal descriptions subset goal descriptions another fully achieved consistent goal
time step.
5.4 Consistent Goals
redundant goals removed set consistent goals time
step, might still one consistent goal set. case,
numbers observed actions relevant remaining consistent goals
compared. remaining goals maximum number relevant actions
chosen consistent goals time step.
Definition 9 Given set consistent goals time step, consistent goal set
consistent goal set, maximum number relevant actions among
consistent goals set.
21

fiHong

instance, example shown Figure 2, another action (take-out D)
observed time step 4, (move-object H O) (keep-object-at O) consistent goals time step 5, neither redundant. (keep-object-at O)
relevant observed actions, (move-object H O) relevant
four observed actions. According Denition 9, (keep-object-at O)
consistent goal time step 5.
example shown Figure 2, goal nodes asterisk represent consistent
goals eventually remaining two processes removing redundant goals selecting
consistent goals.

6. Experimental Results
implemented goal recognition algorithms Prolog tested terms
accuracy, eciency, scalability desktop Pentium III processor 600 MHz.
tested algorithms set data UNIX domain collected University
Washington. collect data, subjects given goals described English rst
tried achieve goal executing UNIX commands. commands
issued UNIX subject responses UNIX commands
recorded data set. commands issued subject valid
could executed UNIX. responses UNIX invalid commands
actually error messages. goals subjects tried achieve,
indicated success failure regard achievement goal.
14 goals UNIX data set, goals tried 5 subjects
average. shown Table 1, goals classied four types. rst type
goals locating le properties, extension, size,
contents, ownership, date, word count, compression. second type goals
locating machine properties, load logged-in users.
third type goals locating printer properties,
print jobs paper. fourth type goals compressing large
les directory. fourth type goals, universally quantied goal descriptions
needed corresponding goal schemata. addition, also two compound
goals, G3 G9 , conjunctions two goals second type.
test algorithms, sequences UNIX commands, recorded data set,
taken observed actions consecutive time steps. took valid commands,
successfully executed UNIX, ltered invalid commands,
UNIX failed execute responded error messages. created 35 action
schemata set commonly used UNIX commands, including executed
subjects. also created 249 goal schemata, including 129 le-search goal schemata (for
goals locating le properties), 15 non-le-search goal schemata (for goals
locating machine printer properties goals compressing
large les directory) 105 goal schemata paired non-le-search goals.
14 goals UNIX data set instances goal schemata. rst
tested algorithms respect accuracy eciency, is, number goals
remaining sequence observed actions processed, average time
22

fiGoal Recognition Goal Graph Analysis

G1
G2
G3
G4
G5
G6
G7
G8
G9
G10
G11
G12
G13
G14

Find le named core.
Find le contains motivating whose name ends .tex.
Find machine low (< 1.0) load;
determine Oren Etzioni logged machine named chum.
Compress large (> 10,000 bytes) les Testgrounds subdirectory tree.
Compress les directory named backups [Dont use *].
Find large le (> 100,000 bytes) hasnt changed month.
Find le contains less 20 words.
Find laser printer Sieg Hall active print job.
Find Sun fourth oor low (< 1.0) load;
determine Dan Weld active machine named chum.
Find printer paper.
Find le named oldpaper neal/Testgrounds subdirectory.
Find le length 4 neal/Testgrounds subdirectory.
See Dan Weld logged chum.
Find machine Dan Weld logged into.

Table 1: 14 goals UNIX data set collected University Washington
taken construct Goal Graph, analyse constructed Goal Graph, run
cycle Goal Graph construction analysis, action observed time step.
Table 2 gives summary empirical results showing accuracy algorithms.
rst column shows goals subject tried achieve. achieved goals
goals fully partially achieved last observed action processed.
consistent goals fully partially achieved goals consistent
sequence observed actions.6 remaining goals goals remained
redundant goals removed consistent goals selected.
last column shows whether given goal among remaining goals.
shown Table 2, algorithms successfully recognised 13 14 given goals.
failed recognise one given goal, G10 , simply sequence commands
executed subject actually failed achieve goal. terms UNIX data set,
goal recognition occurs algorithms return single, consistent goal. occurred
G2 , G4 , G7 , G8 , G9 , G13 , G14 . G1 , G3 , G6 , G11 , G12 , one goal
recognised, including goal given subject. G1 , G6 , G11 , G12 ,
algorithms recognised subject tried nd one les properties
directory know le was. instance, G1 , intended
goal nd le named core. subject successfully found le named core
directory, other, executing command, ls, list les directory. Since
les, greenmouse, paper.tex, action.ps.Z, directory,
6. experiments UNIX data set, goal, two third observed actions
relevant, recognised consistent goal. threshold number relevant actions
dependent application domain though strict majority actions must relevant.
threshold high, algorithms might fail recognise intended goal. hand,
low, set recognised goals might large provide much value great ambiguity
intended goal.

23

fiHong

goal
G1
G2
G3
G4
G5
G6
G7
G8
G9
G10
G11
G12
G13
G14

achieved
goals
15
26
14
56
46
107
85
6
22
9
12
60
1
8

consistent
goals
15
6
4
18
33
47
4
4
5
0
12
44
1
2

remaining
goals
4
1
2
1
6
4
1
1
1
0
2
6
1
1

given goal
recognised















Table 2: Empirical results UNIX domain showing accuracy algorithms

les also listed command, algorithms recognised four
goals, nding le named core, nding le named greenmouse, nding le named
paper extension tex, nding le named action extension ps
also compressed. G3 , algorithms recognised subject tried nd one
users machine know was. good human
observer could simply could tell observed actions le
user subject trying nd. recognised goals generalised single,
consistent goal nding le directory nding user using machine,
variables allowed recognised goals.
G5 , algorithms recognised 6 consistent goals. Among goals, goals
nd les properties compression extension
directory named backups. Another goal gunzip les directory
named backups. human observer could probably better recognising goal
gunzipping les directory named backups, accounted better
gunzip command observed. unlikely subject gunzipped
les directory order nd le gunzip compression.
Among goals tested, G1 , G2 , G3 , G4 originally tested Lesh
Etzioni (1995). empirical results show signicant improvement accuracy
goal recogniser implemented terms remaining goals. algorithms
4, 1, 2, 1 remaining goals G1 , G2 , G3 , G4 respectively, goal
recogniser 155, 37, 1, 15 remaining goals G1 , G2 , G3 , G4 respectively,
last observed action processed. Furthermore, 4 2 remaining goals
algorithms G1 G3 generalised two single goals. results
show algorithms perform extremely well regard accuracy.
24

fiGoal Recognition Goal Graph Analysis

goal
G1
G2
G3
G4
G5
G6
G7
G8
G9
G10
G11
G12
G13
G14

length
observation
2.25
16
3.0
20.5
9
8.78
9.11
3.5
12
15
7
17
1
2

construction
time
0.535
0.382
0.021
1.036
0.426
12.185
16.473
0.014
0.034
0.018
0.051
0.821
0.010
0.013

analysis
time
0.013
0.102
0.009
3.609
0.565
4.143
8.581
0.002
0.050
0.007
0.020
0.774
0.001
0.004

time
per cycle
0.547
0.484
0.030
4.645
0.991
16.329
25.054
0.017
0.084
0.025
0.071
1.595
0.011
0.017

Table 3: Empirical results UNIX domain showing eciency algorithms

worth noting Lesh Etzionis algorithm converges last observed
action processed. algorithm works towards goal prediction, algorithms emphasise explanation observed actions, recognising fully partially
achieved goals consistent actions. algorithm quickly prune
inconsistent goals get converged set hypothesised goals, though number
hypothesised goals set sometimes large. next step work might
assign probabilities hypothesised goals dierentiate single goal
others, exists one intended goal. hand, less desirable
goals recognised algorithms dierentiated accuracy
algorithms usually high. algorithms, however, cannot recognise goal
fully partially achieved.
Table 3 gives summary empirical results showing eciency algorithms.
length observation average number observed actions executed
subjects achieve given goal. construction time average time took
construct Goal Graph time step. analysis time average time took
analyse constructed Goal Graph time step. time per cycle average
time took go two-stage cycle Goal Graph construction analysis,
observed action processed time step, including constructing Goal
Graph, recognising consistent goals, removing redundant goals, selecting
consistent goals. shown Table 3, average time step, took 2.287 CPU seconds
construct Goal Graph, 1.277 CPU seconds analyse Goal Graph, 3.564
CPU seconds process observed action. Since algorithms written
less ecient Prolog run desktop Pentium III processor 600 MHz,
eciency could achieved. construction time, analysis time, time per cycle could
25

fiHong

Average CPU Seconds

250
200

C-Time

150

A-Time
100

P-Time

50
0
10080

19790

29665

39540

49415

59290

69165

81015

90890 100765

Number Goals

Figure 6: Empirical results UNIX domain showing scalability algorithms

reduced well CPU second, algorithms coded ecient
programming language run faster machine.
Compared empirical results eciency goal recogniser implemented
Lesh Etzioni (1995), average, took 0.547, 0.484, 0.030, 4.645 CPU seconds
process observed action algorithms G1 , G2 , G3 , G4 respectively,
1.616, 1.643, 0.648, 1.610 CPU seconds taken goal recogniser process
observed action goals. average time process observed action
roughly around 1.4 CPU seconds desktop Pentium III processor
600 MHz algorithms coded Prolog SPARC 10 goal recogniser
coded Lisp. Given two dierent programming languages machines used
implementation two dierent systems, comparison hardly meaningful.
however apparent use ecient programming languages machines
signicantly speed algorithms.
also tested scalability goal recognition algorithms UNIX domain.
tested eciency algorithms aected number possible goals,
turn aected number objects universe objects. created
series spaces approximate 104 , 2 104 , 3 104 , 105 possible goals respectively
based data recorded G7 UNIX data set.7 this, changed
les directories le hierarchy, well properties les, original
data set G7 , increase decrease number objects universe objects,
keeping les directories related intended goal properties
related les unchanged. sense part Initial Conditions
intended goal remained same, rest Initial Conditions changed create
7. number goal schemata remains unchanged.

26

fiGoal Recognition Goal Graph Analysis

appropriate number candidate goals. change le hierarchy reected
change complexity le hierarchy.
original sequences commands recorded data set used experiments, conjunction dierent sets Initial Conditions, creation
dierent spaces candidate goals. Figure 6 shows average CPU time taken
time step construct analyse Goal Graph (shown C-Time A-Time respectively Figure 6), process observed action whole (shown P-Time
Figure 6) approximately linear number candidate goals.

7. Conclusion Future Work
paper, presented new approach goal recognition graph structure
called Goal Graph constructed analysed goal recognition. described two
algorithms constructing analysing Goal Graph. algorithms recognise partially
fully achieved goals consistent observed actions, reveal valid plans
recognised goals part them. algorithms need plan library.
allow redundant, extraneous, partially ordered actions. sound, polynomialtime, polynomial-space.
empirical experiments show algorithms recognise goals great accuracy.
computationally ecient. scaled applied domains
tens thousands goals plans. Even though one goal recognition
algorithms, GoalGraphAnalyser algorithm, complete, recognised
intended goals UNIX data set successfully achieved subjects.
limitation goal recognition algorithms sometimes one goal
recognised, though number recognised goals usually small. algorithms
cannot tell goal probable one one intended goal.
instance, G5 UNIX data set, algorithms recognised 6 goals. Even though
intended goal, gunzipping les directory called backups, among goals,
probably likely one compared others, algorithms could
dierentiate others. Sometimes algorithms recognise unique goal
implies intended goal cannot make specic. instance, G7 UNIX
data set, algorithms recognised unique goal, nding le, index.tex, word
count extension. Even though achievement goal implied achievement
intended goal, nding le contains less 20 words, algorithms could
specic. problems due incomplete information
observed actions. G7 , observed actions indication likelihood
recognised goals intended goal. subject actually achieved G7
knew word count less 20 words knowing word count le,
observed action directly used achieve this.
Several attempts (Carberry, 1990; Charniak & Goldman, 1993; Huber et al., 1994;
Forbes et al., 1995; Pynadath & Wellman, 1995; Bauer, 1995; Albrecht et al., 1998)
made incorporate uncertainty representation reasoning techniques plan
recognition handling uncertain incomplete information, single plan
distinguished set candidate plans. However, systems rely heavily
availability planning knowledge certain extent use plan libraries. future
27

fiHong

work, intend investigate possibility incorporating uncertainty representation
reasoning mechanisms Goal-Graph-based approach goal recognition,
unique, specic goal recognised one intended goal,
good features Goal-Graph-based approach kept.
future work, also intend explore extent Goal Graph representation used probabilistic goal recognition. particular, consider problem
settings eects actions probabilistic objective goal recognition
recognise consistent goals highest probability achievement.
Another area future work recognise goals even partially
fully achieved actions observed far. regard, current goal recognition
algorithms used recognise goals sequence actions large data
set achieve. sequence actions data set recognised goals
used acquire probabilistic model goal prediction machine learning method.
probabilistic model takes actions observed far predicts possible goals even
partially fully achieved.

Acknowledgments
paper revised extended version paper appeared Proceedings
AAAI-2000 (Hong, 2000). author wishes thank Neal Lesh providing UNIX
data set, anonymous referees insights constructive criticisms,
helped improve paper signicantly.

References
Albrecht, D. W., Zukerman, I., & Nicholson, A. E. (1998). Bayesian model keyhole
plan recognition adventure game. User Modeling User-Adapted Interaction,
8 (1-2), 547.
Allen, J. F. (1983). Recognizing intentions natural language utterances. Brady, M.,
& Berwick, B. (Eds.), Computational Models Discourse, pp. 107166. MIT Press,
Cambridge, MA.
Allen, J. F., & Perrault, C. R. (1980). Analyzing intention utterances. Articial Intelligence, 15, 143178.
Anderson, C., Smith, D. E., & Weld, D. (1998). Conditional eects Graphplan.
Proceedings 4th International Conference AI Planning Systems, pp. 4453.
Bauer, M. (1995). Dempster-Shafer approach modeling agent preferences plan recognition. User Modeling User-Adapted Interaction, 5 (3-4), 317348.
Bauer, M. (1998). Acquisition abstract plan descriptions plan recognition. Proceedings AAAI-98, pp. 936941.
Bauer, M., & Paul, G. (1993). Logic-based plan recognition intelligent help systems.
Backstrom, C., & Sandewall, E. (Eds.), Current Trends AI Planning, pp. 6073.
IOS Press.
28

fiGoal Recognition Goal Graph Analysis

Blum, A. L., & Furst, M. L. (1997). Fast planning Planning Graph analysis.
Articial Intelligence, 90, 281300.
Carberry, S. (1986). User models: problem disparity. Proceedings 11th
International Conference Computational Linguistics, pp. 2934.
Carberry, S. (1988). Modeling users plans goals. Computational Linguistics, 14 (3),
2337.
Carberry, S. (1990). Incorporating default inferences plan recognition. Proceedings
AAAI-90, pp. 471478.
Carver, N. F., Lesser, V. R., & McCue, D. L. (1984). Focusing plan recognition.
Proceedings AAAI-84, pp. 4248.
Charniak, E., & Goldman, R. P. (1993). Bayesian model plan recognition. Articial
Intelligence, 64, 5379.
Forbes, J., Huang, T., Kanazawa, K., & Russell, S. (1995). BATmobile: Towards
Bayesian automated taxi. Proceedings IJCAI-95, pp. 18781885.
Gazen, B., & Knoblock, C. (1997). Combining expressivity UCPOP eciency
Graphplan. Proceedings 4th European Conference Planning, pp. 221
233.
Goodman, B. A., & Litman, D. J. (1992). interaction plan recognition
intelligent interfaces. User Modeling User-Adapted Interaction, 2, 83115.
Grosz, B. J., & Sidner, C. L. (1990). Plans discourse. P. R. Cohen, J. M., & Pollack,
M. E. (Eds.), Intentions Communication, pp. 417444. MIT Press, Cambridge, MA.
Hong, J. (2000). Goal Graph construction analysis paradigm plan recognition.
Proceedings AAAI-2000, pp. 774779.
Huber, M. J., & Durfee, E. H. (1995). Deciding commit action
observation-based coordination. Proceedings First International Conference
Multi-Agent Systems, pp. 163170.
Huber, M. J., Durfee, E. H., & Wellman, M. P. (1994). automated mapping plans
plan recognition. Proceedings 10th Conference Uncertainty Articial
Intelligence, pp. 344351.
Hu, K., & Lesser, V. (1988). plan-based intelligent assistant supports software
development process. Proceedings ACM SIGSOFT/SIGPLAN Software Engineering Symposium Practical Software Development Environments, pp. 97106.
Kautz, H. A. (1987). Formal Theory Plan Recognition. PhD Thesis, University
Rochester.
Koehler, J., Nebel, B., Homann, J., & Dimopoulos, Y. (1997). Extending planning graphs
ADL subset. Proceedings 4th European Conference Planning, pp.
273285.
Lesh, N., & Etzioni, O. (1995). sound fast goal recognizer. Proceedings IJCAI95, pp. 17041710.
29

fiHong

Lesh, N., & Etzioni, O. (1996). Scaling goal recognition. Proceedings 5th
International Conference Principles Knowledge Representation Reasoning,
pp. 178189.
Litman, D. J., & Allen, J. F. (1987). plan recognition model sub-dialogues conversation. Cognitive Science, 11 (2), 163200.
Mooney, R. J. (1990). Learning plan schemata observation: Explanation-based learning
plan recognition. Cognitive Science, 14 (4), 483509.
Pednault, E. P. D. (1988). Synthesizing plans contain actions context-dependent
eects. Computational Intelligence, 4 (4), 356372.
Pednault, E. P. D. (1989). ADL: Exploring middle ground STRIPS
Situation Calculus. Proceedings 1st International Conference Knowledge
Representation Reasoning, pp. 324332.
Pollack, M. E. (1990). Plans complex mental attitudes. Cohen, P. R., Morgan,
J., & Pollack, M. E. (Eds.), Intentions Communication, pp. 77101. MIT Press,
Cambridge, MA.
Pynadath, D. V., & Wellman, M. P. (1995). Accounting context plan recognition,
application trac monitoring. Proceedings 11th Conference Uncertainty
Articial Intelligence, pp. 472481.
Schank, R., & Abelson, R. (1977). Scripts, Plans, Goals, Understanding. Erlbaum.
Sidner, C. L. (1985). Plan parsing intended response recognition discourse. Computational Intelligence, 1 (1), 110.
Wilensky, R. (1983). Planning Understanding. Addison-Wesley Publishing Company,
Reading, MA.
Wilensky, R., & et al. (1988). Berkeley unix consultant project. Computational Linguistics, 14 (4), 3584.

30

fiJournal Artificial Intelligence Research 15 (2001) 289-318

Submitted 3/01; published 10/01

Ecient Methods Qualitative Spatial Reasoning
renz@dbai.tuwien.ac.at

Jochen Renz
Institut f
ur Informationssysteme, Technische Universit
Wien
Favoritenstr.9, A-1040 Wien, Austria

nebel@informatik.uni-freiburg.de

Bernhard Nebel
Institut f
ur Informatik, Albert-Ludwigs-Universit

Flughafen 17, D-79110 Freiburg, Germany

Abstract

theoretical properties qualitative spatial reasoning RCC-8 framework
analyzed extensively. However, empirical investigation made yet.
experiments show adaption algorithms used qualitative temporal
reasoning solve large RCC-8 instances, even phase transition region
{ provided one uses maximal tractable subsets RCC-8 identified
us. particular, demonstrate orthogonal combination heuristic methods
successful solving almost apparently hard instances phase transition region
certain size reasonable time.
1. Introduction

Representing qualitative spatial information reasoning information
important subproblem many applications, natural language understanding, document interpretation, geographical information systems. RCC-8 calculus (Randell,
Cui, & Cohn, 1992b) well suited representing topological relationships spatial
regions. Inference full calculus is, however, NP-hard (Grigni, Papadias, & Papadimitriou, 1995; Renz & Nebel, 1999). means unlikely large
instances solved reasonable time, result rule possibility
solve instances certain size reasonable time. Recently, maximal tractable
subsets RCC-8 identified (Renz & Nebel, 1999; Renz, 1999) used
speed backtracking search general NP-complete reasoning problem reducing
search space considerably.
paper address several questions emerge previous theoretical results
RCC-8 (Renz & Nebel, 1999; Renz, 1999): size possible solve
instances reasonable time? heuristic best? really much ecient
use maximal tractable subsets solving instances NP-complete consistency
problem theoretical savings given smaller branching factors indicate
effect out-balanced forward-checking power interleaved path-consistency
computations? case similar temporal problems (pointisable vs. ORD-Horn
relations) (Nebel, 1997). possible combine different heuristics way
instances solved reasonable time heuristic alone?
treat questions randomly generating instances solving using
different heuristics. so, particularly interested hardest randomly
c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiRenz & Nebel

generated instances leads question phase-transitions (Cheeseman, Kanefsky,
& Taylor, 1991): parameter randomly generating instances consistency
problem RCC-8 results phase-transition behavior? so, case
hardest instances mainly located phase-transition region instances
contained phase-transition region easily solvable? order generate instances
harder higher probability, generate two different kinds instances.
one hand generated instances contain constraints RCC-8 relations,
hand generated instances contain constraints relations
contained maximal tractable subsets. expect instances
harder average former instances.
algorithmic techniques use solving randomly generated instances
borrowed similar work qualitative temporal reasoning (Nebel, 1997; van Beek &
Manchak, 1996; Ladkin & Reinefeld, 1992). Additionally, make use fragments
RCC-8, named Hb 8, Q8 , C8, permit polynomial-time inferences (Renz & Nebel,
1999; Renz, 1999). backtracking algorithm, used solve reasoning
problem full RCC-8, decompose every disjunctive relation relations one
tractable subsets instead decomposing base relations. reduces
average branching factor backtracking tree 4.0 base relations
1.4375 Hb 8, 1.523 C8, 1.516 Q8 . Although theoretical savings
cannot observed experiments, using maximal tractable subsets instead
base relations leads significant performance improvements.
paper structured follows. Section 2, give brief sketch RCC-8
calculus algorithms used solving instances RCC-8. Section 3 describe
procedure randomly generating instances, different heuristics apply solving
instances, measure quality heuristics. Section 4 evaluate
different path-consistency algorithms order find ecient one used
forward-checking backtracking search. Section 5 observe phase-transition
behavior randomly generated instances show instances phasetransition region harder solve instances. Section 6 report
outcome running different heuristics solving instances identify several
hard instances mainly located phase-transition region. Section 7 try
solve hard instances orthogonally combining different heuristics. turns
effective leads ecient solution strategy. Finally, Section 8
evaluate strategy trying solve large instances.1
2. Region Connection Calculus RCC-8

Region Connection Calculus (RCC) first-order language representation
reasoning topological relationships extended spatial regions (Randell et al.,
1992b). Spatial regions RCC non-empty regular subsets topological space
internally connected, i.e., spatial region may consist different
disconnected pieces. Different relationships spatial regions defined based
one dyadic relation, connected relation C( ) true topological closures
spatial regions share common point.
a; b



b

1. programs available online appendix.

290

fiEfficient Methods Qualitative Spatial Reasoning

fi fi


fi
fi


fi fi






fi
fi





X

X





DC(X; Y)

X





X

TPP(X; Y) TPP 1 (X; Y)

EC(X; Y)

X

X



PO(X; Y)

X





X

NTPP(X; Y) NTPP 1 (X; Y)

EQ(X; Y)

Figure 1: Two-dimensional examples eight base relations RCC-8
Region Connection Calculus RCC-8 constraint language formed eight
jointly exhaustive pairwise disjoint base relations DC, EC, PO, EQ, TPP, NTPP, TPP 1 ,
NTPP 1 definable RCC-theory possible unions base relations|
giving total number 28 = 256 different relations. base relations meaning
DisConnected, Externally Connected, Partial Overlap, EQual, Tangential Proper Part,
Non-Tangential Proper Part, converses. Examples relations shown
Figure 1. Constraints written form
variables spatial
regions RCC-8 relation. write union base relations f g.
union base relations, universal relation, written fg. Apart union
([), operations relations defined, namely, converse ( ), intersection (\),
composition (). formal definitions operations are:
xRy

x;

R

R;

^

8
8
8
8

x;
x;
x;
x;

:
:
:
:

( [ )
( \ )

x R



x R



xR

^

( )

x R





$
$
$
$ 9

_
^
,
:(

xRy

xS

xRy

xS

yRx
z

xRz

,
,

^

)

zSy :

composition base relations computed semantics relations
usually provided composition table (Randell, Cohn, & Cui, 1992a; Bennett, 1994).
RCC-8 composition table corresponds given extensional definition composition
universal region permitted (Bennett, 1997). Based table, compositions
disjunctive relations easily computed. following, Sb denotes closure
set RCC-8 relations composition, intersection, converse.
finite set RCC-8 constraints describing topological relationships different
regions represented matrix , entry represents RCC-8
relation holding region region . Without loss generality, = fEQg
=
assumed. fundamental reasoning problem (named RSAT)
framework deciding consistency set spatial formulas , i.e., whether
spatial configuration relations regions described .
interesting reasoning problem reduced polynomial time (Golumbic
& Shamir, 1993). Unfortunately, RSAT NP-complete (Renz & Nebel, 1999), i.e.,
unlikely polynomial algorithm deciding consistency. However,
shown Nebel's (1995) paper subsets RCC-8 consistency
n

n



Mji

n



j

^

Mij

291

Mij

Mii

fiRenz & Nebel

problem (written RSAT(S)) decided polynomial time.2 particular set
eight base relations B shown tractable. follows Bb consisting
32 relations also tractable. even larger tractable subset containing base relations
Hb 8 (Renz & Nebel, 1999), contains 148 256 RCC-8 relations. set
also shown maximal respect tractability, i.e., RCC-8 relation
added, consistency problem becomes NP-complete. Renz (1999) made complete
analysis tractability RSAT identifying maximal tractable subsets contain
base relations, altogether three subsets Hb 8, Q8 (160 relations), C8 (158 relations).
NP 8 set relations result NP-completeness combined
set base relations. contains following 76 relations contained
one Hb 8 Q8 C8 (Renz, 1999):
NP 8 = f j fPOg 6 (fNTPPg fTPPg )
(fNTPP 1g fTPP 1g )g
[ ffEC NTPP EQg fDC EC NTPP EQg
fEC NTPP 1 EQg fDC EC NTPP 1 EQgg
maximal tractable subsets contain following relations (Renz, 1999):
Hb 8 = (RCC-8 n NP 8 ) n f j (fEQ NTPPg fTPPg 6 )
(fEQ NTPP 1 g fTPP 1g 6 )g
C8 = (RCC-8 n NP 8 ) n f j fECg fPOg 6
\ fTPP NTPP TPP 1 NTPP 1 EQg =6 ;g
Q8 = (RCC-8 n NP 8 ) n f j fEQg fPOg 6
\ fTPP NTPP TPP 1 NTPP 1 g 6= ;g
;

;

R

R

R

R

R

;

;

;

;

;

;

;

;

;

;

;

;

;

R

R

R

;

;

R

R

;

R

;

;

:

R

R

R

R

;

;

R

R

R

;

R

;

relations Q8 contained one Hb 8 C8, i.e., Hb 8 [ C8 = RCC-8 n NP 8 .
Although Hb 8 smallest three maximal tractable subsets, best decomposes
RCC-8 relations: decomposing RCC-8 relation
sub-relations one
maximal tractable subsets, i.e., = 1 [ [ , one needs average 1.4375 Hb 8 relations,
1.516 Q8 relations, 1.523 C8 relations decomposing RCC-8 relations. Renz (2000)
gives detailed enumeration relations three sets.
R

R



:::

Si

Sk

2.1 Path-Consistency Algorithm

area qualitative temporal reasoning based Allen's interval calculus (Allen,
1983), path-consistency algorithm (Montanari, 1974; Mackworth, 1977; Mackworth &
Freuder, 1985) used approximate consistency realize forward-checking
(Haralick & Elliot, 1980) backtracking algorithm.
path-consistency algorithm checks consistency triples relations
eliminates relations impossible. done iteratively performing following
operation
\
Mij

Mij

Mik

Mkj

2. Strictly speaking, applies systems regions require regularity.

292

fiEfficient Methods Qualitative Spatial Reasoning

Algorithm: Path-consistency
Input: set binary constraints variables x1 ; x2 ; : : : ; x

n



represented matrix .
path-consistent set equivalent ; fail, set
exist.
n

Output:

n



1. := f( ) ( ) j 1

6= 6= g;
( indicates -th variable . Analogously )
2. 6= ;
3. select delete path ( ) ;
4. revise( )
5.

= ; return fail
6.
else := [ f(
) ( ) j 1 6= 6= g.
Q

i; j; k ;

k; i; j



i; j; k

n; < j; k

i; k

j



j

k

Q

p; r; q

Q

p; r; q

Mpq

Q

Q

p; q; ;

s; p; q



n;

p;

q

Function: revise(i; k; j )
Input: three labels i, k j indicating variables x ; x ; x
Output: true, revised; false otherwise.
Side effects: revised using operations \


j

k

ij

ij

ji

constraints involving , , .
xi

xk

xj

1. oldM := ;
2.
:= \ ( );
3. (oldM = ) return false;
4.
:= ;
5. return true.
Mij

Mij

Mij

Mj

Mij

Mik

Mkj

Mij

^

Figure 2: Path-consistency algorithm.
triples regions
fixed point reached.
= ; pair
, know inconsistent, otherwise path-consistent. Computing
done ( 3) time (see Figure 2). achieved using queue triples
regions relations recomputed (Mackworth & Freuder, 1985). Pathconsistency imply consistency. instance, following set spatial constraints
path-consistent consistent:
i; j; k

i; j



ij







n

lHH - l
HHH
l? HHHj- l?

X

DC _ TPP

Z

TPP _ TPP 1
EC _ TPP
EC _ TPP

EQ _ NTPP



EC _ NTPP

W

hand, consistency imply path-consistency, since path-consistency
form consistency (in logical sense), form disjunctive non-redundancy.
Nevertheless, path-consistency enforced consistent set constraints ap293

fiRenz & Nebel

Algorithm: Consistency
Input: set RCC-8 constraints variables x1 ; x2 ; : : : ; x

subset RCC-8 contains base relations
Decide sound complete decision
procedure.
Output: true, iff consistent.
1. Path-Consistency()
2. contains empty relation return false
3. else choose unprocessed constraint

split 1
2 1 [ [ =
4. constraint split return Decide()
5. refinements (1 )
6.
replace


7.
Consistency() return true

n

xi Rxj

R

; : : : ; Sk

Sl

xi Rxj

l



:::

Sk

R

k

xi Sl xj

Figure 3: Backtracking algorithm deciding consistency.
plying path-consistency algorithm. relations Hb 8, Q8 , C8 used, however,
path-consistency algorithm sucient deciding consistency, i.e., path-consistency
decides RSAT(Hb 8), RSAT(Q8 ), RSAT(C8 ), (Renz & Nebel, 1999; Renz, 1999).
2.2 Backtracking Algorithm

order solve instance RSAT, explore corresponding search space
using sort backtracking. experiments, used backtracking algorithm
employed solving qualitative temporal reasoning problems (Nebel, 1997), based
algorithm proposed Ladkin Reinefeld (1992). algorithm (see Figure 3)
necessary subset RCC-8 consistency decided using
sound complete (and preferably polynomial) decision procedure Decide. contains
base relations, thenS relation 2 RCC-8 decomposed sub-relations
2 =
. size particular decomposition minimal number
sub-relations used decompose . backtracking algorithm successively
selects constraints , backtracks sub-relations constraints according
decomposition decides sub-instances contain constraints using
Decide.
(optional) procedure Path-consistency line 1 used forward-checking
restricts remaining search space. Nebel (1997) showed restriction
effect soundness completeness algorithm. enforcing path-consistency
sucient deciding RSAT(S), Decide() line 5 necessary. Instead possible
always return true there.
eciency backtracking algorithm depends several factors. One is,
course, size search space explored. common way measuring
R

Si

R



Si

Si

R

294

fiEfficient Methods Qualitative Spatial Reasoning

size search space average branching factor search space, i.e.,
average number branches node search space (a node recursive 2call
) 2,
Consistency). average size search space computed (
2
(
) 2 number constraints split variables
given. backtracking algorithm described Figure 3 branching factor depends
average number relations split set relation split.
less splits average better, i.e., expected eciency
backtracking algorithm depends split set branching factor. Another factor
search space explored. backtracking algorithm Figure 3 offers two
possibilities applying heuristics. One line 3 next unprocessed constraint
chosen, line 5 next refinement chosen. two
choices uence search space path search space.
b

b

n

n =

n

n =

n

3. Test Instances, Heuristics, Measurement

previous work empirical evaluation algorithms reasoning RCC-8
benchmark problems known. Therefore randomly generated test instances
given number regions , average label-size , average degree
constraint graph. Further, used two different sets relations generating test
instances, set RCC-8 relations set hard RCC-8 relations NP 8, i.e.,
76 relations contained maximal tractable subsets Hb 8, C8 ,
Q8 . Based sets relations, used two models generate instances, denoted
( ) ( ). former model uses relations generate instances,
latter relations NP 8. instances generated follows:
1. constraint graph nodes average degree node generated.
accomplished selecting 2 ( 1) 2 possible edges using
uniform distribution.
2. edge th th node, set = universal
relation.
3. Otherwise non-universal relation selected according parameter
average size relations selected edges . accomplished selecting
one base relations uniform distribution remaining 7 relations
one probability ( 1) 7.3 results allowed relation (i.e., relation
NP 8 ( ), RCC-8 relation ( )), assign relation
edge. Otherwise repeat process.
reason also generating instances using relations NP 8 assume
instances dicult solve since every relation split
backtracking search, even use maximal tractable subclass split set.
generated instances average label size = 4 0, since case relations equally
distributed.
n

n; d; l

l



H n; d; l

n



nd=



n n

j

=

Mij

Mji

l

l

l

=

H n; d; l

n; d; l

l

:

3. method could result assignment universal constraint selected link, thereby changing
degree node. However, since probability getting universal relation low,
ignore following.

295

fiRenz & Nebel

way generating random instances similar way random CSP instances finite domains usually generated (Gent, MacIntyre, Prosser, Smith, &
Walsh, 2001). Achlioptas et al. (1997) found standard models generating
random CSP instances finite domains lead trivially awed instances ! 1,
i.e., instances become locally inconsistent without propagate constraints. Since
using CSP instances infinite domains, Achlioptas et al.'s result necessarily hold random instances. We, therefore, analyze following whether
instances also trivially awed ! 1. order obtain CSP finite domain, first transform constraint graph dual graph
( 1) 2 edges
constraint graph corresponds node
dual graph. Moreover, variables constraint graph corresponds
1 edges dual graph, i.e., dual graph contains ( 1) edges ( 1) 2
nodes. dual graph, node corresponds variable eight-valued domain
= fDC EC PO TPP TPP 1 NTPP NTPP 1 EQg. Ternary constraints variables imposed composition table, i.e., composition rules


must hold connected
dual graph ( =
triples nodes
n
). 3 = ( 1)( 2) 6 connected triples dual graph.


n(n 1)=2
overall number triples dual graph
.
2 unary constraints
3

domain variables given, i.e., nd=3 2 triples dual graph
nodes restricted unary constraints. Therefore, expected number
connected triples unary constraints given computed
!
!
2
3 3
!
=
( 1) 2
3
! 1, expected number triples 1 tends 3 6. instances generated
according model ( ), probability unary constraints
assigned triple lead local inconsistency 0 0036% (only 58,989
2553 = 16 581 375 possible assignments inconsistent). Since one locally inconsistent
triple makes whole instance inconsistent, interested average degree
expected number locally inconsistent triples equal one. model
( ) occurs value = 11 90, 1 = 0 5 = 9 44. = 100,
expected number locally inconsistent triples one = 13 98, 100 = 0 5
= 11 10. model ( ), none possible assignments triples leads
local inconsistency, i.e., triples randomly generated instances ( )
model locally consistent.4 analysis shows contrary Achlioptas et
al. found randomly generated CSP instances finite domains, model ( ),
model ( ) small suffer trivial local inconsistencies.
n

n

n n

=

Mij

n

n

n n

;

;

;

;

;

;

n n

;

Mij

Mik

Mij ; Mik ; Mkj

i; j

n n

=

n

Mkj

^

Mij

Mj

=

nd=

Mij

n
CT

E

n

nd=

n

:

EC

n n

n

=

EC

=

n; d; l

;

;

;



n
E


n; d; l



:

E



:







:

:

:

n

E



:

H n; d; l

H n; d; l

H n; d; l

n; d; l



4. similar result CSPs finite domains restricting constraint type, e.g.,
\not-equal" constraints graph-coloring used, possible ensure problems cannot
trivially awed.

296

fiEfficient Methods Qualitative Spatial Reasoning

solve randomly generated instances using backtracking algorithm described
previous section. search space backtracking performed depends
split set, i.e., set sub-relations allowed decompositions. Choosing
right split-set uences search noticeably uences average branching factor
search space. choose five different split sets, three maximal tractable subsets
Hb 8 Q8 C8, set base relations B closure set Bb consists
38 relations. sets following branching factors B: 4.0, B:b 2.50 ,Hb 8: 1.438,
C8: 1.523, Q8 : 1.516. is, course, worst case measure interleaved pathconsistency computations reduce branching factor considerably (Ladkin & Reinefeld,
1997).
Apart choice split set heuristics uence eciency search. general best search strategy proceed constraint
constraining relation (line 3 Figure 3) least constraining choice
sub-relation (line 5 Figure 3). investigated two different aspects choosing
next constraint processed (Nebel, 1997).
static/dynamic: Constraints processed according heuristic evaluation
constrainedness determined statically backtracking starts dynamically search.
local/global: evaluation constrainedness based local heuristic weight
criterion global heuristic criterion (van Beek & Manchak, 1996).
gives us four possibilities combine five different split sets, i.e.,
total number 20 different heuristics. evaluation constrainedness well
relations decomposed relations different split sets depends restrictiveness
relations, heuristic criterion (van Beek & Manchak, 1996). Restrictiveness
relation measure relation restricts neighborhood. instance,
universal relation given constraint network restrict neighboring relations
all, result composition relation universal relation universal
relation. identity relation, contrast, restricts neighborhood lot. every triple
variables one relation identity relation, two relations must equal.
Therefore, universal relation usually least restricting relation, identity
relation usually restricting relation. Restrictiveness relations represented
weight range 1 16 assigned every relation, 1 value
16 value least restricting relation. discuss following section
detail restrictiveness weight relation determined.
Given weights assigned every relation, compute decompositions estimate
constrainedness follows. split set RCC-8 relation compute
smallest decomposition sub-relations S, i.e., decomposition requires least number sub-relations S. one possibility, choose
decomposition least restricting sub-relations. line 5 backtracking algorithm (see Figure 3), least restricting sub-relation decomposition processed
first. local strategy, constrainedness constraint determined size
decomposition (which different every split set) weight. choose
constraint smallest decomposition larger one and,
;

;

R

R

297

fiRenz & Nebel

one constraint, one smallest weight. reason choosing relation
smallest decomposition expected forward-checking refines relations larger decomposition relations smaller decomposition. reduces
backtracking effort. global strategy, constrainedness constraint

determined adding weights neighboring relations



weight . idea behind strategy refining relation
restricted neighborhood, inconsistency detected faster refining
relation less restricted neighborhood.
order evaluate quality different heuristics, measured run-time used
solving instances well number visited nodes search space. Comparing
different approaches run-time often reliable depends several
factors implementation algorithms, used hardware, current
load used machine makes results sometimes reproducible. reason,
ran run-time experiments machine, Sun Ultra 1 128 MB
main memory. Nevertheless, suggest use run-time results mainly qualitatively
comparing different heuristics getting rough idea order magnitude
instances solved.
contrast this, number visited nodes solving instance particular
heuristic always every machine. allows comparing path
search space taken single heuristics judge heuristic makes better
choices average. However, take account time needed make
choice single node. Computing local constrainedness constraint certainly
faster computing global constrainedness. Similarly, computing constrainedness
statically faster computing dynamically. Furthermore, larger instances
require time nodes smaller instances, computing path-consistency
computing constrainedness. Taking running-time number visited nodes
together gives good indications quality heuristics.
choice make evaluating measurements aggregate
measurements single instances total picture. possibilities use
either average different percentiles median, i.e., 50% percentile.
% percentile value 0
100 obtained sorting measurements increasing
order picking measurement % element, i.e., % values less
value. Suppose instances low value (e.g. running time)
instances large value. average might larger values
almost instances, case median better indication distribution
values. case 99% percentile, instance, gives good indication
value hardest among \normal" instances. chosen use average
value measurements well distributed use 50% 99% percentile
exceptional values distribution measurements.
xRy

S;

R



xS z

zT

R

< <





4. Empirical Evaluation Path-Consistency Algorithm

Since eciency backtracking algorithm depends eciency underlying
path-consistency algorithm, first compare different implementations pathconsistency algorithm. previous empirical investigations (van Beek & Manchak, 1996)
298

fiEfficient Methods Qualitative Spatial Reasoning

reasoning Allen's interval relations (Allen, 1983), different methods computing
composition two relations evaluated. mainly full composition
table interval relations contains 213 213 = 67108864 entries, large
time stored main memory. setting, simply use composition
table specifies compositions RCC-8 relations, 256 256 table
consuming approximately 128 KB main memory. means composition
two arbitrary relations done simple table lookup.
Van Beek Manchak (1996) also studied effect weighting relations
queue according restrictiveness process restricting relation first.
Restrictiveness measured base relation successively composing base
relation every possible label, summing cardinalities, i.e., number base
relations contained result composition, suitably scaling result.
reason restricting relation restricts relations
average therefore decreases probability processed again.
Restrictiveness complex relation approximated summing restrictiveness
involved base relations. Van Beek Manchak (1996) found method
weighting triples queue much ecient randomly picking arbitrary
triple. relatively small number RCC-8 relations, computed exact
restrictiveness composing relation every relation summing
cardinalities resulting compositions. scaled result weights 1 (the
restricting relation) 16 (the least restricting relations).
gives us three different implementations path-consistency algorithm. One
entries queue weighted, one approximated restrictiveness
done van Beek Manchak, one exact restrictiveness.5 order compare
implementations, randomly generated instances 50 1,000 regions.
value average degree ranging 8.0 stepping 0.5 11.0 generated
10 different instances. Figure 4 displays average CPU time different methods
applying path-consistency algorithm generated instances.
seen positive effect using weighted queue much greater problem
temporal problem (about 10 faster using ordinary queue without
weights compared 2 faster (van Beek & Manchak, 1996)). Determining
weights every relation using exact restrictiveness much advantage
approximating restrictiveness using approach van Beek Manchak (1996),
however. experiments always used \exact weights" method
determining restrictiveness amounts one table lookup.
mentioned previous section, one way measuring quality heuristics
count number visited nodes backtrack search. backtracking
algorithm, path-consistency enforced every visited node. Note adequate
multiply average running-time enforcing path-consistency instance
particular size number visited nodes order obtain approximation
required running time instance. average running-time enforcing pathconsistency given Figure 4 holds possible paths entered
queue beginning computation (see line 1 Figure 2). paths
5. weighted versions select path (i; k; j ) queue Q line 3 algorithm Figure 2
according weights different paths Q computed specified above.

299

fiRenz & Nebel

Average CPU time PCA using different queue methods A(n,d,4.0)
1000
100

"exact" weights
"approx." weights
weights

CPU time (sec)

10
1
0.1
0.01
0.001
100

200

300

400

500
600
nodes

700

800

900

1000

Figure 4: Comparing performance path-consistency algorithm using different
methods weighting queue (70 instances/data point, = 8 0 11 0)


:

:

checked algorithm. path-consistency computation
backtracking search different, however. There, paths involving currently
changed constraint entered queue, since paths might result changes
constraint graph. much faster full computation path-consistency
done beginning backtrack search.
5. Phase-Transition RCC-8

randomly generating problem instances usually problem-dependent parameter determines solubility instances. one parameter range instances
underconstrained therefore soluble high probability. another range,
problems overconstrained soluble low probability.
ranges phase-transition region probability solubility changes abruptly
high low values (Cheeseman et al., 1991). order study quality
different heuristics algorithms randomly generated instances NP-complete
problem, important aware phase-transition behavior problem.
instances contained phase-transition region often
easily solvable algorithms heuristics are, thus, useful
comparing quality. Conversely, hard instances better suited comparing
quality algorithms heuristics usually found phase-transition region.
section identify phase-transition region randomly generated instances
RSAT problem, instances using RCC-8 relations instances using
relations NP 8. Similarly empirical analysis qualitative temporal reasoning
problems (Nebel, 1997), turns phase-transition depends strongly
average degree nodes constraint graph. relations allowed, phased

300

fiEfficient Methods Qualitative Spatial Reasoning

Probability satisfiability A(n,d,4.0)

Median CPU time A(n,d,4.0)
CPU time(s)

Probability (%)
100

0.6
0.5
0.4
0.3
0.2
0.1
0

50
100
80
60
4 6
8 10
12 14
average degree
16 18

40

nodes

100
80
60

4 6
8 10
12 14
average degree
16 18

20

40

nodes

20

Figure 5: Probability satisfiability median CPU time (
Hb 8/static/global heuristic (500 instances per data point)

n; d;

4 0) using
:

transition around = 8 = 10 depending instance size (see Figure 5).
result theoretical analysis occurrence trivial aws (see Section 3),
expected larger instance sizes phase-transition behavior overlaid
mainly determined expected number locally inconsistent triples also depends
average degree . Thus, although seems phase-transition shifts towards
larger values instance size increases, phase-transition asymptotically
= 9 44, theoretical value ! 1 (see Section 3). Instances pathconsistent solved fast one application path-consistency algorithm
without need backtracking. looking median CPU times given
Figure 5, one notices sharp decline median CPU times phase
transition. indicates values average degree higher
phase-transition occurs, least 50% instances path-consistent.
using \hard" relations, i.e., relations NP 8, phase-transition appears
higher values , namely, = 10 = 15 (see Figure 6). median
runtime shows, instances much harder phase-transition former
case. previous case, even strongly, seems phase-transition
shifts towards larger values instance size increases, also phasetransition region narrows.
order evaluate quality path-consistency method approximation
consistency, counted number instances inconsistent path-consistent
(see Figure 7), i.e., instances approximation path-consistency algorithm consistency wrong. First all, one notes instances close
phase transition region. general case, i.e., constraints RCC-8 relations
employed, low percentage instances path-consistent inconsistent.
Therefore, figure looks erratic. data points would required order
obtain smooth curve. However, important observations made
figure, namely, path-consistency gives excellent approximation consistency even
instances large size. Except instances phase-transition region,
almost instances path-consistent also consistent. picture changes










:

n









301

fiRenz & Nebel

Probability satisfiability H(n,d,4.0)

Median CPU time H(n,d,4.0)

Probability (%)

CPU time(s)

100

2
1.5

50

1
80
60
40

6 8
10 12
14 16
average degree
18 20

80

0.5

60

0

nodes

6 8
10 12
14 16
average degree
18 20

20

40

nodes

20

Figure 6: Probability satisfiability median CPU time (
Hb 8/static/global heuristic (500 instances per data point)

H n; d;

Percentage points incorrect PCA answers A(n,d,4.0)

4 0) using
:

Percentage points incorrect PCA answers H(n,d,4.0)

PC-Failures (%)
PC-Failures (%)
0.6
0.5

80
70
60
50
40
30
20
10
0

0.4
0.3
0.2

100

0.1

80
60

0
4

40

6

8 10
12 14
average degree
16 18

nodes

80
60
40

6

8 10
12 14
16 18
average degree
20

20

nodes

20

Figure 7: Percentage points incorrect answers path-consistency algorithm
( 4 0) ( 4 0)
n; d;

:

H n; d;

:

looking ( 4 0) case. almost instances phase-transition
region many instances mostly insoluble region path-consistent, though
consistent.
following evaluation different heuristics randomly generate instances average degree = 2 = 18 ( 4 0) case
= 4 = 20 ( 4 0) case. covers large area around
phase-transition. expect instances phase-transition region ( 4 0)
particularly hard makes interesting comparing quality
different heuristics.
H n; d;

:







H n; d;



n; d;

:

:

H n; d;

:

6. Empirical Evaluation Heuristics

section compare different heuristics running randomly
generated instances. instances ( 4 0) ran 20 different heuristics
n; d;

302

:

fiEfficient Methods Qualitative Spatial Reasoning

Number hard instances A(n,d,4.0)

Number hard instances H(n,d,4.0)

#Hard Instances

#Hard Instances

10
9
8
7
6
5
4
3
2
1
0

450
400
350
300
250
200
150
100
50
0

100
80
60

4 6
8 10
12 14
16 18
average degree
20

40

nodes

80
60
40

6 8
10 12
14 16
average degree
18 20

20

nodes

20

Figure 8: Number instances using 10,000 visited nodes heuristic
( 4 0) ( 4 0)
n; d;

:

H n; d;

:

(static/dynamic local/global combined five split sets B Bb Hb 8 C8 Q8 )
randomly generated instances size = 10 = 100. instances
( 4 0) restricted instances = 80 regions larger
ones appeared dicult.
first experiments found instances solved fast
less 1,000 visited nodes search space using one maximal tractable
subsets splitting. However, instances turned extremely hard, could
solved within limit 2 million visited nodes, 1.5 hours CPU
time. Therefore, ran programs maximal number 10,000 visited nodes
stored instances least one different heuristics used
10,000 visited nodes experiments (see next section). call instances
hard instances. distribution hard instances shown Figure 8. turned
heuristics using B split set heuristics using dynamic
global evaluation constrainedness many instances hard
combinations heuristics. We, therefore, include Figure 8 hard instances
B/dynamic/global heuristic ( 4 0) hard instances heuristics
b dynamic/global heuristic ( 4 0).
using B split set B/
Figure 8 shows, almost hard instances phase-transition region.
( 4 0) 500 instances per data point hard ( 4 0)
almost instances phase-transition hard. Altogether 788 hard instances
( 4 0) (out total number 759,000 generated instances) 75,081 hard
instances ( 4 0) (out total number 594,000 generated instances). Table 1
shows number hard instances heuristic except excluded
mentioned above. heuristics using Hb 8 split set solve instances
heuristics using split sets. Using C8 Q8 split set seem
improvement using B.b Among different ways computing constrainedness, static
global appears effective combination using one maximal
tractable subsets split set. split sets, dynamic local also seems
;

n

H n; d;

;

;

;

n

:

n

n; d;

:

H n; d;

n; d;

:

n; d;

:

:

H n; d;

H n; d;

:

303

:

fiRenz & Nebel

Heuristics

Hb8 /sta/loc
Hb8 /sta/glo
Hb8 /dyn/loc
Hb8 /dyn/glo
C8 /sta/loc
C8 /sta/glo
C8 /dyn/loc
C8 /dyn/glo
Q8 /sta/loc
Q8 /sta/glo
Q8 /dyn/loc
Q8 /dyn/glo
Bb/sta/loc
Bb/sta/glo
Bb/dyn/loc
Bb/dyn/glo
B/sta/loc
B/sta/glo
B/dyn/loc
B/dyn/glo
total

(

n; d;

4:0)

64
42
52
100
81
58
78
108
81
54
74
104
68
89
70
162
163
222
209
(303)
788

(
4:0)
21; 129
10; 826
9; 967
24; 038
28; 830
15; 457
32; 926
41; 565
24; 189
13; 189
13; 727
29; 448
23; 711
13; 831
29; 790
{
{
{
{
{
75; 081

H n; d;

H

(80; 14:0; 4:0)
331
227
217
345
373
277
412
428
346
239
255
368
344
249
379
{
{
{
{
{
486

Table 1: Number hard instances heuristic
effective combination combining dynamic global cases worst choice
respect number solved instances.
Figure 9 compare 50% 99% percentiles different heuristics
( 4 0). give average run times since ran heuristics
10,000 visited nodes reduces real average run time values. data point
average values = 8 = 10. took average different degrees
order cover whole phase-transition region = 8 instances
size = 10 = 10 instances size = 100. different combinations
computing constrainedness, ordering run times different split
sets: B Bb C8 Hb 8 Q8 . run times using static/local, static/global, dynamic/local
computing constrainedness almost combined split set
longer split sets using dynamic/global (about 3 times longer
using Bb split set 1.5 times longer using split sets).
99% percentile run times 1.5 times longer 50% percentile run
times. Thus, even harder among \normal" instances solved easily, i.e., apart
hard instances, instances solved eciently within size range
analyzed. erratic behavior median curves results aggregation
effect observed Figure 5, namely, median elements
phase-transition inconsistent easily solvable.
n; d;

:







n



>

;

n

;

304

fiEfficient Methods Qualitative Spatial Reasoning

Median CPU time using STATIC,LOCAL A(n,d,4.0)

99%-Percentile CPU time using STATIC,LOCAL A(n,d,4.0)

0.6

0.6
B-split
B^-split
C-split
H^8-split
Q-split

0.4
0.3
0.2
0.1

20

30

40

50
60
nodes

70

80

90

0.2

100

10

Median CPU time using STATIC,GLOBAL A(n,d,4.0)

20

30

40

50
60
nodes

70

80

90

100

99%-Percentile CPU time using STATIC,GLOBAL A(n,d,4.0)

0.6

0.6
B-split
B^-split
C-split
H^8-split
Q-split

0.4

B-split
B^-split
C-split
H^8-split
Q-split

0.5
CPU time (sec)

0.5
CPU time (sec)

0.3

0
10

0.3
0.2
0.1

0.4
0.3
0.2
0.1

0

0
10

20

30

40

50
60
nodes

70

80

90

100

10

Median CPU time using DYNAMIC,LOCAL A(n,d,4.0)

20

30

40

50
60
nodes

70

80

90

100

99%-Percentile CPU time using DYNAMIC,LOCAL A(n,d,4.0)

0.6

0.6
B-split
B^-split
C-split
H^8-split
Q-split

0.4

B-split
B^-split
C-split
H^8-split
Q-split

0.5
CPU time (sec)

0.5
CPU time (sec)

0.4

0.1

0

0.3
0.2
0.1

0.4
0.3
0.2
0.1

0

0
10

20

30

40

50
60
nodes

70

80

90

100

10

Median CPU time using DYNAMIC,GLOBAL A(n,d,4.0)

20

30

40

50
60
nodes

70

80

90

100

99%-Percentile CPU time using DYNAMIC,GLOBAL A(n,d,4.0)

0.6

0.6
B-split
B^-split
C-split
H^8-split
Q-split

0.4

B-split
B^-split
C-split
H^8-split
Q-split

0.5
CPU time (sec)

0.5
CPU time (sec)

B-split
B^-split
C-split
H^8-split
Q-split

0.5
CPU time (sec)

CPU time (sec)

0.5

0.3
0.2
0.1

0.4
0.3
0.2
0.1

0

0
10

20

30

40

50
60
nodes

70

80

90

100

10

20

30

40

50
60
nodes

70

80

90

100

Figure 9: Percentile 50% 99% CPU time different heuristics solving
( 4 0) ( = 8 0 = 10 0, 2,500 instances per data point)
n; d;

:



:



:

305

fiRenz & Nebel

runtime studies ( 4 0) noticed many hard instances
40 (see Figure 8), = 80 almost instances phase-transition region
hard (see last column Table 1). Also, Table 1 shows, number hard instances
varies lot different heuristics. Therefore, possible compare percentile
running times different heuristics 40. = 80 = 14 (see last column
Table 1), instance, 50% 99% percentile element C8/dynamic/global
heuristic element no.36 element no.72, element no.141 element no.280
Hb 8/dynamic/local heuristic (out 500 sorted elements), respectively.
reason show results size = 40 (see Figure 10). Again,
took average different degrees = 10 = 15 order cover whole
phase-transition region. order run times different combinations
computing constrainedness: B Bb C8 Q8 Hb 8, Hb 8 cases fastest.
( 4 0) instances, run times dynamic/global much longer
combinations. 99% percentile run times static/global combination
Hb 8 Q8 dynamic/local combination faster
combinations. Although median CPU times ( 4 0)
40, percentile 99% CPU times much longer. already shown Figure 7
8, evidence hard instances phase-transition
region ( 4 0).
H n; d;

n >

:

n

n >

n



n



;

n; d;



;

:

n; d;

:

n <

H n; d;

:

7. Orthogonal Combination Heuristics

previous section studied quality different heuristics solving randomly
generated RSAT instances. found several instances mainly located
phase-transition region could solved heuristics within limit 10,000
visited nodes search space. Since different heuristics different search space
(depending split set) use different path search space (determined
different possibilities computing constrainedness), possible instances
hard heuristics easily solvable heuristics. Nebel (1997) observed
running different heuristics parallel solve instances particular hard set
temporal reasoning instances proposed van Beek Manchak (1996) single
heuristic alone solve, using altogether number visited nodes
heuristic alone. open question Nebel's investigation (Nebel, 1997) whether
also case hard instances phase-transition region.
section evaluate power \orthogonally combining" different heuristics
solving RSAT instances, i.e., running different heuristics instance parallel
one heuristics solves instance. different ways simulating
parallel processing single processor machine. One use time slicing
different heuristics, another run heuristics fixed random order
certain number nodes search space visited unsuccessful try next
heuristic (cf. Huberman, Lukose, & Hogg, 1997). possibility chosen
parameters (e.g., order heuristics run number visited
nodes spent heuristic) determines eciency single processor
simulation orthogonal combination. order find best parameters, ran
heuristics using 10,000 visited nodes heuristic set hard instances
306

fiEfficient Methods Qualitative Spatial Reasoning

Median CPU time using STATIC,LOCAL H(n,d,4.0)

99%-Percentile CPU time using STATIC,LOCAL H(n,d,4.0)

0.045

5
B-split
C-split
B^-split
Q-split
H^8-split

CPU time (sec)

0.035
0.03

B-split
C-split
B^-split
Q-split
H^8-split

4
CPU time (sec)

0.04

0.025
0.02
0.015
0.01

3

2

1

0.005
0

0
10

15

20

25
nodes

30

35

40

10

Median CPU time using STATIC,GLOBAL H(n,d,4.0)

20

25
nodes

30

35

40

99%-Percentile CPU time using STATIC,GLOBAL H(n,d,4.0)

0.045

5
B-split
C-split
B^-split
Q-split
H^8-split

0.035
0.03

B-split
C-split
B^-split
Q-split
H^8-split

4
CPU time (sec)

0.04
CPU time (sec)

15

0.025
0.02
0.015
0.01

3

2

1

0.005
0

0
10

15

20

25
nodes

30

35

40

10

Median CPU time using DYNAMIC,LOCAL H(n,d,4.0)

20

25
nodes

30

35

40

99%-Percentile CPU time using DYNAMIC,LOCAL H(n,d,4.0)

0.045

5
B-split
C-split
B^-split
Q-split
H^8-split

0.035
0.03

B-split
C-split
B^-split
Q-split
H^8-split

4
CPU time (sec)

0.04
CPU time (sec)

15

0.025
0.02
0.015
0.01

3

2

1

0.005
0

0
10

15

20

25
nodes

30

35

40

10

Median CPU time using DYNAMIC,GLOBAL H(n,d,4.0)

20

25
nodes

30

35

40

99%-Percentile CPU time using DYNAMIC,GLOBAL H(n,d,4.0)

0.045

5
B-split
C-split
B^-split
Q-split
H^8-split

0.035
0.03

B-split
C-split
B^-split
Q-split
H^8-split

4
CPU time (sec)

0.04
CPU time (sec)

15

0.025
0.02
0.015
0.01

3

2

1

0.005
0

0
10

15

20

25
nodes

30

35

40

10

15

20

25
nodes

30

35

40

Figure 10: Percentile 50% 99% CPU time different heuristics solving
( 4 0) ( = 10 0 = 15 0, 5,500 instances per data point)
H n; d;

:



:



:

307

fiRenz & Nebel

A(n; d; 4:0)
Heuristics Solved Instances 1. Response
91:88%
19:80%
Hb8 /sta/loc
Hb8 /sta/glo
94:67%
12:56%
Hb8 /dyn/loc
93:40%
24:37%
Hb8 /dyn/glo
87:31%
13:58%
C8 /sta/loc
89:72%
6:35%
C8 /sta/glo
92:64%
5:20%
C8 /dyn/loc
90:10%
5:96%
C8 /dyn/glo
86:63%
6:60%
Q8 /sta/loc
89:72%
9:77%
Q8 /sta/glo
93:15%
12:06%
Q8 /dyn/loc
90:61%
10:15%
Q8 /dyn/glo
86:80%
12:82%
91:37%
1:40%
Bb/sta/loc
bB/sta/glo
88:71%
1:27%
Bb/dyn/loc
91:12%
0:89%
Bb/dyn/glo
79:44%
0:89%
B/sta/loc
79:31%
0:51%
B/sta/glo
71:83%
0:25%
B/dyn/loc
73:48%
0:51%
B/dyn/glo
{
0:13%
combined
99:87%

H (n; d; 4:0)
Solved Instances 1. Response
71:86%
6:92%
85:58%
14:26%
86:73%
22:28%
67:98%
15:00%
61:60%
1:47%
79:41%
5:04%
56:15%
2:26%
44:64%
2:40%
67:78%
1:63%
82:43%
3:61%
81:72%
1:83%
60:78%
4:61%
68:42%
1:84%
81:58%
5:22%
60:32%
2:56%
{
1:83%
{
1:67%
{
1:13%
{
0:42%
{
0:49%
96:48%

Table 2: Percentage solved hard instances heuristic percentage first response orthogonally running heuristics. Note sometimes different
heuristics equally fast. Therefore sum 100%.

identified previous section (those instances least one heuristic required
10,000 visited nodes) compared behavior. Since ran heuristics
instances already experiments previous section, evaluate
outcomes. led surprising result ( 4 0) instances, namely,
788 hard instances except single one solved least one heuristics
using less 10,000 visited nodes. Table 2 list percentage hard instances
could solved different heuristics percentage first response
running heuristics parallel (i.e., heuristic required smallest
number visited nodes solving instance). turns heuristics using Hb 8
split set solve instances heuristics, also
often fastest finding solution. Although heuristics using two
maximal tractable subsets Q8 C8 split set solve significantly instances
heuristics using B,b much faster finding solution. Despite solving
least number instances, heuristics using B split set cases
fastest producing solution.
n; d;

308

:

fiEfficient Methods Qualitative Spatial Reasoning

First Response Solving Hard Instances A(n,d,4.0)

First Response Solving Hard Instances H(n,d,4.0)

20
700
Number solved instances

Number solved instances

inconsistent
consistent
15

10

5

inconsistent
consistent

600
500
400
300
200
100

0

0
1

10
100
1000
Minimal number visited nodes

10000

1

10
100
1000
Minimal number visited nodes

10000

Figure 11: Fastest solution hard instances running heuristics parallel
comparing minimal number visited nodes heuristics
hard instances, found five (which inconsistent) required
150 visited nodes. particularly remarkable instances
phase-transition region NP-hard problem, i.e., instances usually
considered dicult ones. note 15% (120) 788 (pathconsistent) instances inconsistent, much higher usual (cf. Figure 7).
Interestingly, inconsistent instances solved faster consistent
instances. point, noted combining heuristics orthogonally
similar randomized search techniques restarts (Selman, Levesque, & Mitchell, 1992).
However, contrast randomized search, method also determine whether
instance inconsistent. Figure 11 chart number hard instances solved
smallest number visited nodes respect solubility. Due low number
hard instances ( 4 0), figure left looks bit ugly one least
approximate behavior curves comparing second figure
right curve ( 4 0) (see below). oscillating behavior
inconsistent instances (more instances solved odd even number
visited nodes) might due sizes instances|we generated instances
even number nodes only. dicult instance ( = 56 = 10) solved
b static/global heuristic using 91,000 visited nodes
inconsistent B/
heuristics using one maximal tractable subsets split set failed solve even
allowed visit 20,000,000 nodes search space.
examination set 75,081 hard instances ( 4 0). 2,640
instances could solved 20 different heuristics using 10,000 visited
nodes each. distribution shown Figure 12(a). Similar hard instances
( 4 0), heuristics using Hb 8 split set successful ones
solving hard instances ( 4 0), shown Table 2. solved
hard instances heuristics produced fastest response
50% hard instances. significant difference using C8 Q8 Bb
split set, neither number solved instances percentage first
response. Like previous case, computing constrainedness using static/global
dynamic/local heuristics resulted successful paths search space
n; d;

:

H n; d;

:

n

;d

H n; d;

n; d;

:

:

H n; d;

:

;

309

;

fiRenz & Nebel

First Response Solving Hard Instances H(n,d,4.0)
Number hard instances H(n,d,4.0) using orthogonal combination
inconsistent
consistent

#Hard Instances
100
80
60
40
20
0

80
60
40

6 8
10 12
14 16
average degree
18 20

nodes

Number solved instances

100

80

60

40

20

20
0
20000

40000
60000
80000
Number visited nodes

100000

(a)
(b)
Figure 12: Hard instances using orthogonal combination heuristic ( 4 0),
(a) shows distribution, (b) shows fastest solution using
100,000 visited nodes per heuristic
H n; d;

:

instances solved within 10,000 visited nodes combinations.
average produced faster solutions combinations.
observations ( 4 0) made charting fastest solutions
hard instances ( 4 0) (see Figure 11). 29% (21,307) solved
instances inconsistent. were, again, solved faster consistent
instances. 75% hard instances solved 150 visited nodes.
90% solved 1,300 visited nodes. Since Hb 8/dynamic/local heuristic
alone solves 86% instances, seems dicult combine different heuristics
way hard instances solved using 10,000 visited
nodes altogether. However, orthogonally combining two best performing heuristics
(Hb 8 /dynamic/local Hb 8/static/global) allowing maximal number 5,000
visitable nodes, solve 92% (69,056) hard instances.
tried solve 2,640 hard instances ( 4 0) solvable using
orthogonal combination heuristics 10,000 visited nodes using maximal
number 100,000 visited nodes. 471 instances still solvable,
75% solved instances inconsistent. fastest response solved instances
charted Figure 12(b). successful heuristics giving fastest response
Hb 8 /dynamic/local (42.5%) Hb 8/static/global (26.6%). three heuristics using
static/global computation constrainedness combined using Q8 C8 Bb split
set gave fastest response 15.9% solved instances Bb strategy
far best among three (9.4%).
n; d;

H n; d;

:

:

H n; d;

:

;

;

8. Combining Heuristics Solving Large Instances

previous section found combining different heuristics orthogonally solve
instances using amount visited nodes heuristic alone solve.
section use results order identify size randomly generated instances
310

fiEfficient Methods Qualitative Spatial Reasoning

almost them, especially phase-transition region, still
solved acceptable time. Since many instances ( 4 0) already dicult
size = 80 (see Figure 12), restrict analysis instances ( 4 0)
study randomly generated instances size = 100 nodes.
instances large size allowing maximal number 10,000 visited nodes
search space much obtaining acceptable runtime. 10,000 visited nodes
instances size = 100 corresponds runtime 10 seconds Sun Ultra1,
larger instances gets much slower. Therefore, restrict maximal number
visited nodes order achieve acceptable runtime. Given multi-processor machine,
different heuristics run orthogonally different processors using maximal
number visited nodes each. orthogonal combination different heuristics
simulated single-processor machine, maximal number nodes divided
number used heuristics obtain available number visitable nodes
heuristic. Thus, different heuristics use, less visitable nodes available
heuristic. Therefore, order achieve best performance, find
combination heuristics solves instances within given number visitable
nodes. chosen heuristics solve many instances alone, also
complement well, i.e., instances cannot solved one heuristic
solvable heuristic.
started finding optimal combination heuristics set 788 hard
instances ( 4 0). empirical evaluation given Section 6 know
many visited nodes heuristic needs order solve 788 hard instances.
Therefore, computed number solved instances 220 possible combinations
heuristics using increasing maximal number visitable nodes heuristics
together. Since tried find combination solves instances,
computed quite fast. results given Table 3. show
good performance obtained maximal number 600 visited nodes.
case four heuristics involved, i.e., 150 visitable nodes spent four
heuristics. Since combination heuristics (Hb 8/static/global, Hb 8 /dynamic/local,
b static/local) also best 1,000 visitable nodes, choose
C8/dynamic/local, B/
combination analysis. choose order processed
b static/local according
1. Hb 8/dynamic/local, 2. Hb 8 /static/global, 3. C8/dynamic/local, 4. B/
first response behavior given Table 2. Note although two heuristics
b static/local show particularly good performance
C8/dynamic/local B/
running alone (see Table 2), seem best complement two heuristics.
find next maximal number visitable nodes spend
heuristics. ran best performing heuristic (Hb 8/dynamic/local) instances
phase-transition region varying sizes. turned almost consistent
instances number visited nodes required solving slightly less twice
size instances inconsistent instances also path-consistent and,
thus, solvable one visited node. Therefore, ran four heuristics
following allowing 2 visited nodes each, size instance, i.e., together
allow 8 visitable nodes. randomly generated test instances according
( 4 0) model size = 110 regions size = 500 regions
step 10 regions 100 instances size average degree ranging
H n; d;

:

n

n; d;

n

n

n; d;

:

n

n

n

n; d;

:

n

n

311

:

fiRenz & Nebel

Max Nodes Solved Instances
100
516
200
705
300
759
400
769
500
774
600
778
700
780
800
783
900
784
1100
785
1300
786
3900
787

Combination Heuristics
Hb 8-d-l
Hb 8-s-g
Hb 8-s-g, Hb 8-d-l
Hb 8-s-g, C8 -d-l
Hb 8-s-g, Hb 8-d-l, C8 -d-l
b
Hb 8-s-g, Hb 8-d-l, C8 -d-l, B-s-l
b
b
b
H8-s-g, H8-d-l, C8 -d-l, B-s-l
b
Hb 8-s-g, Hb 8-d-l, C8 -d-l, B-s-l
b
b
b
H8-s-g, H8-d-l, C8 -d-l, B-s-l
b B-s-g
b
Hb 8-s-g, Hb 8-d-l, C8 -d-l, B-s-l,
b B-s-g
b
Hb 8-s-g, Hb 8-d-l, B-s-l,
b
b
b
H8-s-g, H8-d-l, B-d-l

Table 3: Best performance combining different heuristics solving 787 solvable hard
instances ( 4 0) fixed maximal number visited nodes
n; d;

:

Probability satisfiability A(n,d,4.0)

Probability (%)

Average number visited nodes A(n,d,4.0)

Visited nodes

100

1000
900
800
700
600
500
400
300
200
100

50

4 6
8 10
12 14
average degree
16 18

500
450
400
350
300
250 nodes
200
150

4 6
8 10
12 14
average degree
16 18

500
450
400
350
300
250 nodes
200
150

Figure 13: Probability satisfiability ( 4 0) (100 instances per data point)
average number visited nodes path-consistent instances using
orthogonal combination four selected heuristics
n; d;

:

= 2 0 = 18 0 step 0.5, total number 132,000 instances. Since solving
large instances using backtracking requires lot memory, solved instances
Sun Ultra60 1GB main memory.
generated instances display phase-transition behavior continues one
given Figure 5. phase-transition ranges = 10 0 = 110 = 10 5
= 500 (see Figure 13). Apart 112 instances, instances generated solvable orthogonal combination four heuristics (Hb 8 /static/global,
b static/local) spending less 2n visited nodes
Hb 8/dynamic/local, C8/dynamic/local, B/


:



:



n

312

:

n



:

fiEfficient Methods Qualitative Spatial Reasoning

Percentile 70% CPU time using orthogonal combination A(n,d,4.0)

Percentile 99% CPU time using orthogonal combination A(n,d,4.0)
CPU time (s)

CPU time (s)
100
25
20
15
10
5
0

80
60

4 6
8 10
12 14
average degree
16 18

40

500
450
400
350
300
250 nodes
200
150

20
0
4 6
8 10
12 14
average degree
16 18

500
450
400
350
300
250 nodes
200
150

Figure 14: Percentile 70% 99% CPU time orthogonal combination four different heuristics solving large randomly generated instances ( 4 0)
n; d;

:

each. Figure 13 give average number visited nodes path-consistent
instances. seen test instances average number visited nodes
linear size instances. percentile 70% CPU time instances
phase-transition size = 500 regions 20 seconds, percentile 99% CPU
time 90 seconds. size = 400 regions, percentile 99% CPU time
less minute (see Figure 14).
131,240 test instances already solved Hb 8/static/global heuristic,
71 instances Hb 8/dynamic/local heuristic required 577 instances
C8/dynamic/local heuristic produced solution. None 112 instances
b static/local heuristic.
solved one three heuristics solved B/
tried solve instances using heuristics, using maximal number 2
visited nodes each. best performing among heuristics C8/dynamic/global
heuristic solved 87 112 instances followed C8 /static/global heuristic (83)
Q8 /dynamic/global heuristic (63). 7 instances solved heuristic
within maximal number 2 visited nodes.
n

n

n

n

9. Discussion

empirically studied behavior solving randomly generated RSAT instances using
different backtracking heuristics make use maximal tractable subsets
identified previous work. generated instances according two different models
\general model" allows 256 RCC-8 relations used \hard
model" allows relations contained maximal tractable
subsets. theoretical analysis two models showed model model
small average degree nodes constraint graph suffer trivial
local inconsistencies case similar generation procedures CSPs finite
domains (Achlioptas et al., 1997). turned randomly generated instances
models show phase-transition behavior depends strongly average
degree instances. instances outside phase-transition region


H

H



313

fiRenz & Nebel

solved eciently heuristics, instances phase-transition region
extremely hard. instances general model, path-consistent instances
also consistent. Conversely, path-consistency bad approximation consistency
instances hard model. instances also much harder solve instances
general model.
comparing different heuristics, found heuristics using one
maximal tractable subsets split set much faster deciding consistency
RSAT instances theoretical advantage given reduced average branching factor
resulting exponentially smaller size search space indicates.
using path-consistency forward checking method considerably reduces search space
cases. Nevertheless, using one maximal tractable subsets split set,
particular Hb 8, still leads much faster solution solves instances reasonable
time heuristics. Although two maximal tractable subsets Q8 C8
contain relations Hb 8 , average branching factor lower, i.e., using
Hb 8 one decompose relations (256 148 = 108) using two
sets (96 98 relations, respectively), Hb 8 splits relations better
two sets. relations decomposed two Hb 8 sub-relations, many
relations must decomposed three C8 sub-relations three Q8 sub-relations.
explains superior performance heuristics involving Hb 8 decomposition.
Among instances generated, stored could solved
heuristics within maximum number 10,000 visited nodes search space order
find different heuristics perform hard instances. found almost
hard instances located phase-transition region many
hard instances hard model general model. orthogonally combined
heuristics ran hard instances. turned successful. Apart
one instance, hard instances general model could solved,
low number visited nodes. hard instances hard model much
dicult: many could solved heuristics. Nevertheless,
many instances solved orthogonally combining heuristics
heuristic alone. Again, solved using low number visited nodes.
Based observations orthogonally combining different heuristics, tried
identify combination heuristics successful eciently solving many
instances used combination solving large instances. turned
best combination involves heuristics use maximal tractable subsets decomposition. combination able solve almost randomly generated
instances phase-transition region general model size = 500 regions
eciently. seems impossible considering enormous size
search space, average 1039323 instances size = 500 using Hb 8
split set.
results show despite NP-hardness, able solve almost randomly generated RSAT instances general model eciently. neither due
low number different RCC-8 relations (instances generated according hard model
hard phase-transition region) generation procedure random
instances lead trivially awed instances asymptotically. mainly due
maximal tractable subsets cover large fraction RCC-8 lead
n

n

314

fiEfficient Methods Qualitative Spatial Reasoning

extremely low branching factors. Since different maximal tractable subsets,
allow choosing many different backtracking heuristics increases
eciency: instances solved easily one heuristic, instances
heuristics. Heuristics involving maximal tractable subclasses showed best behavior
instances solved faster tractable subsets used. full classification tractable subsets gives possibility generating hard instances high
probability. Many randomly generated instances phase-transition region
hard using relations contained tractable subsets
consist = 60 regions. next step developing ecient reasoning
methods RCC-8 find methods also successful solving hard
instances hard model.
n

results empirical evaluation reasoning RCC-8 suggest analyzing
computational properties reasoning problem identifying tractable subclasses
problem excellent way achieving ecient reasoning mechanisms. particular
maximal tractable subclasses used develop ecient methods solving
full problem since average branching factor lowest. Using refinement
method developed Renz's (1999) paper, tractable subclasses set relations forming
relation algebra identified almost automatically. method makes easy
develop ecient algorithms. indication empirical evaluation
much effective (even especially hard instances phase-transition
region) orthogonally combine different heuristics try get final epsilon
single heuristic. answers question raised Nebel (1997) whether orthogonal
combination heuristics also useful phase-transition region. experiments
lead much better results even simulating orthogonal combination different
heuristics single processor machine spending altogether resources
one heuristic alone. contrast method time slicing different
heuristics, started new heuristic previous heuristic failed certain
number visited nodes search space. order ran heuristics
depended performance well complemented other,
successful heuristics used first. similar using algorithm portfolios proposed
Huberman et al. (1997). heuristics perform better combination
successful one matter empirical evaluation depends particular
problem. Heuristics depending maximal tractable subclasses, however, lead
best performance.
CSPs finite domains many theoretical results localizing
phase-transition behavior predicting hard instances located. contrast this, basically theoretical results CSPs infinite domains
used spatial temporal reasoning. initial theoretical analysis shows, theoretical results CSPs finite domains necessarily extend CSPs infinite
domains. would interesting develop general theory CSPs
infinite domains, possibly similar Williams Hogg's \Deep Structure" (Williams &
Hogg, 1994) Gent et al.'s \Kappa" theory (Gent, MacIntyre, Prosser, & Walsh, 1996).
315

fiRenz & Nebel
Acknowledgments

would like thank Ronny Fehling assistance developing programs, Malte
Helmert proof reading paper, three anonymous reviewers
helpful comments.
research supported DFG part project fast-qual-space,
part DFG special research effort \Spatial Cognition". first author
partially supported Marie Curie Fellowship European Community programme
\Improving Human Potential" contract number HPMF-CT-2000-00667. preliminary version paper appeared Proceedings 13th European Conference
Artificial Intelligence (Renz & Nebel, 1998).
References

Achlioptas, D., Kirousis, L., Kranakis, E., Krizanc, D., Molloy, M., & Stamatiou, Y. (1997).
Random constraint satisfaction: accurate picture. 3rd Conference
Principles Practice Constraint Programming (CP'97), Vol. 1330 LNCS, pp.
107{120. Springer-Verlag.
Allen, J. F. (1983). Maintaining knowledge temporal intervals. Communications
ACM, 26 (11), 832{843.
Bennett, B. (1994). Spatial reasoning propositional logic. Doyle, J., Sandewall,
E., & Torasso, P. (Eds.), Principles Knowledge Representation Reasoning:
Proceedings 4th International Conference, pp. 51{62, Bonn, Germany. Morgan
Kaufmann.
Bennett, B. (1997). Logical Representations Automated Reasoning Spatial Relationships. Ph.D. thesis, School Computer Studies, University Leeds.
Cheeseman, P., Kanefsky, B., & Taylor, W. M. (1991). really hard problems are.
Proceedings 12th International Joint Conference Artificial Intelligence,
pp. 331{337, Sydney, Australia. Morgan Kaufmann.
Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraint
satisfaction: Flaws structure. CONSTRAINTS, 6 (4), 345{372.
Gent, I., MacIntyre, E., Prosser, P., & Walsh, T. (1996). constrainedness search.
Proceedings 13th National Conference AI (AAAI'96), pp. 246{252.
Golumbic, M. C., & Shamir, R. (1993). Complexity algorithms reasoning time:
graph-theoretic approach. Journal Association Computing Machinery,
40 (5), 1128{1133.
Grigni, M., Papadias, D., & Papadimitriou, C. (1995). Topological inference. Proceedings
14th International Joint Conference Artificial Intelligence, pp. 901{906,
Montreal, Canada.
316

fiEfficient Methods Qualitative Spatial Reasoning

Haralick, R. M., & Elliot, G. L. (1980). Increasing tree search eciency constraint
satisfaction problems. Artificial Intelligence, 14, 263{313.
Huberman, B., Lukose, R., & Hogg, T. (1997). economics approach hard computational problems. Science, 275, 51{54.
Ladkin, P. B., & Reinefeld, A. (1992). Effective solution qualitative interval constraint
problems. Artificial Intelligence, 57 (1), 105{124.
Ladkin, P. B., & Reinefeld, A. (1997). Fast algebraic methods interval constraint problems. Annals Mathematics Artificial Intelligence, 19 (3,4).
Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8,
99{118.
Mackworth, A. K., & Freuder, E. C. (1985). complexity polynomial network
consistency algorithms constraint satisfaction problems. Artificial Intelligence, 25,
65{73.
Montanari, U. (1974). Networks constraints: fundamental properties applications
picture processing. Information Science, 7, 95{132.
Nebel, B. (1995). Computational properties qualitative spatial reasoning: First results.
Wachsmuth, I., Rollinger, C.-R., & Brauer, W. (Eds.), KI-95: Advances Artificial
Intelligence, Vol. 981 Lecture Notes Artificial Intelligence, pp. 233{244, Bielefeld,
Germany. Springer-Verlag.
Nebel, B. (1997). Solving hard qualitative temporal reasoning problems: Evaluating
eciency using ORD-Horn class. CONSTRAINTS, 3 (1), 175{190.
Randell, D. A., Cohn, A. G., & Cui, Z. (1992a). Computing transitivity tables: challenge
automated theorem provers. Proceedings 11th CADE. Springer-Verlag.
Randell, D. A., Cui, Z., & Cohn, A. G. (1992b). spatial logic based regions
connection. Nebel, B., Swartout, W., & Rich, C. (Eds.), Principles Knowledge
Representation Reasoning: Proceedings 3rd International Conference, pp.
165{176, Cambridge, MA. Morgan Kaufmann.
Renz, J. (1999). Maximal tractable fragments Region Connection Calculus: complete analysis. Proceedings 16th International Joint Conference Artificial
Intelligence, pp. 448{454, Stockholm, Sweden.
Renz, J. (2000). Qualitative Spatial Reasoning Topological Information. Ph.D. thesis,
Institut fur Informatik, Albert-Ludwigs-Universitat Freiburg.
Renz, J., & Nebel, B. (1998). Ecient methods qualitative spatial reasoning. Proceedings 13th European Conference Artificial Intelligence, pp. 562{566, Amsterdam, Netherlands. Wiley.
317

fiRenz & Nebel

Renz, J., & Nebel, B. (1999). complexity qualitative spatial reasoning: maximal
tractable fragment Region Connection Calculus. Artificial Intelligence, 108 (12), 69{123.
Selman, B., Levesque, H. J., & Mitchell, D. (1992). new method solving hard satisfiability problems. Proceedings 10th National Conference American
Association Artificial Intelligence, pp. 440{446, San Jose, CA. MIT Press.
van Beek, P., & Manchak, D. W. (1996). design experimental analysis algorithms
temporal reasoning. Journal Artificial Intelligence Research, 4, 1{18.
Williams, C. P., & Hogg, T. (1994). Exploiting deep structure constraint problems.
Artificial Intelligence, 70, 73{117.

318

fi
ff fi


"!$#%'&)(**#+ ,#.-/#0#1

>

2345'67(08**9:4
!6;*<8*=#

?A@CBEDGFH?AIJLKM?ONQPSRSJUTWVRYXZ@[T]\^?A_'`@aIb_'I@aT]TcRCVedf?gI`?AVihj?'NkcRaX]lST

mHnQoprq]s touwvHn]qyxxqz{n|qpr}Q}]q

~~y]~y0 ~Q yy )

a.$EQr'yG3$3)3 e$GrrG
{)rHG)GY$3)3
gr0
C{rEQ )
rG3
'A]qyxGnQo)}]qyprxGno

30Qy G7 g | yG 3

a.$A^ {)Q C'3G3S'r){3)r
ar =A|{)3)$)rr0
)rr

Ar ]
' 7=WQ AAS GH{ G= $E U)=
=7;A ";3]'' H rr/r$ ";Ga3S0=a);=3
' S= Ur A=r;" QS3GH rG
$ "rGr) = Hr {=H Yr 0= UrS]
{ = ]G)HU=)=|{U' U {=^A]{ 0H
0"rGQ{QrS {=$ ]]$=g Q w;A = r
={QUUQ3Gr3'G={=YGSG' e=' $ 0H
=a=r

ff
fiA
!"#$&%('#)* ,+.-/0 )&21430576 698 : ;9)<$>=0@?BA9C#D E9F$0)130576 6 Gff )&HC9'F%0)I.;#9D#) C9E7J
K0FL)&0C9)&07$MF$'N#O'FPC9)&'N9 #$KRQS'#T90UBVWE#X#$&%('#)* )&@T9)&K$TBFK#KKXDN)> C9E#
+ZYH[,\L!G%,E#'7,#'#T9()&0C9)&>0 $) #T9'NQ^]F )& #W%,E#,$!E#W_9*7W)&0C9)&07$"K07;#MF97`a;#0#K0U
VWE#"F>'NKF$'Nb9$&%0PD#) C9Ec$ME#'N)&P7#TdC9)<'N9 #$&S0)&]7"Fe7PDN7 $ff$'#' 7f'#)gE9 #T9#D
;9#K0)&$Mh_7$&X_i)&0Fffjf U@VWE#O#$k%'N)>* P )<l#K0)&0h#D m_#DX;#Tn_oT9]70)&@ )&0FH)&'NQ
QFD PC9)<'NK>_#Dp+Z[HD ' $!91q305 5 r Gs$'tQST9K0F/T9FDN#' >+2A9E7%u?wvH$ME#0)&0135 5930GU
VxE#d;#>!.;##c'F($ME#>d#$&%'N)*7L)&SE#0]Np'Ny' ]##D@$ME#tC9)&'N#0Qz'F7f0)&0#K US[
)&D ON;9QS90){'F,FD 'N)&$ME9QdlE9] t0pT9] 'NCT|$'@!}tK07$pK'NQC9;#$O$ME#*FE#'N'#T~7J
FK$ 17 QbC# #K_;#T9PC9)>;9#_#D9F>TtQS$ME#'#T9,+2 F0);#j"14305 576 G1'N)/$ME#,'N;9#T9TtK'##T9$>'#7J
#DtQS$ME#'#Tm+.W'N)<]N$= 19A9;#0)QS'##T9$014?'#'NC90)1305 6 57Gff$K U"x'F%] 0) $ME#PFD 'N)<$!E9QS, )&H'F%
+Z 0#>0q1H'##D41N?B F0);#j"1q305 5 7G%,E#0O C9C#Tt$>'PT90#K'N9#K$>T!"#$&%('#)* F+2WMGU
n )<D #$&%'N)*7P9FK$FD 'N)<$!E9QS )&O_7$M)hK$M # 1"FS$ME#R)<;#)&@M;9QbQS#Dp'F] 0)S p7J
C9'##0 $Fn_7)&D t#;9QS90)L'hE#T9T90n$MF$>0US[C9' >_# C9C9)<'NFKE$>'$MFK*7b$ME#lC9)&'N#0Q
$'p)&'#)&$S$'Xo7)*F'F]RWE9FnX'N7$@W )&'R9F>T~QS$ME#'#T9_*h\L9#tA97QC#_#DB+2\{0Q |?
\L0Qb q1g35 6F48qW0hf1ff35 5 GUHVWE#P C9C9)&'NhKENT9lFKK0;9)>F$)&M;#$P9;#$HP#$M)&0QS>'F%^
K'N7] 0)&D 0#K U
E (**=#|fiyfi96 Q 6 $0 ff] 3ff5' ff4
!fi

G!3Z6F

fi

y)

{yy

@$ME#LC9 C90)x%L%W2'NK0;#H'NO$ME#SQS0 7J4TX$ME#'N)&@9'#))&'F%TO.)&'#Q $MF$>>$K0FgQSKE9 7J
K0U"VWE#H $!;#$>'#@90E##T$ME#>uQS$!E#'NT9$ME9F$(S#'#T9,W)&F$] O#0#$] P$>'lC9 )&$>K0;# )
$$>_#D7L'F"$ME#S] F;#c'F"$P#DNEN'N)&01/9;#$P)F$ME#0)xT90C90#T9c'Ny$ME#)LQS0 7J]FF;#0UlVxE#c'N7J
0)&]FF$'Ny0FT9L$'tbQC#t #TX'F2$0] 0)&FKK0;9)h$lC9)&'#KT4;9)&08"+fP '#)&T4 q1q\PE9 E9)7Q #21
N 7*N*F'7_1?A97;#f1/305 5 GUgVxE#H$KE9#;#cNT9u7O$QF$L'hg$ME#PQS0 #x'Fe$!E#P;9#_#>$M 7$jJ
F$T@#'#T9, #T@F' >$QF$H'F$ME#PC9 )&$>$>'#S;9#K$'NqU"VWE#PQbFtFQw'Fg$!E#WC9 C0)W$'
$M;#T9@C' %0)I;#gQS077J 4Ty$KE9#9;#ST4;#P$'-s!*0X+&30576 G1# #T C9C#@$W$'O(x0U
-s!.*S#$>_hpC9)&'NC' TE#W$ME#'#)&tO$ME#LK'# $#$'FffMC#OD F01 E#0#KP
$ W C9C#K0F$'N
$'@ ' $=0Q 9ypFKE#_#t+."XMG+Z[,K*7 1qx_7$'Nq1q? A#&<#'F%W!* 21ff305 67 GL$M)hD#E $&2'N)&%W )<TU(V '
T9] 'NCpQd0 7J 4Tp$ME#'N)&{f'N)HWL'#$!E#l#S'F( X01q$LcQC9'N)<$M 7$,$ME9h$,%S$P;9CX
) QS%'N)*Hb%,E#KEO9'7$MES$ME#H#$k%'N)>* /K0 ,$!;#T9TU "'7$ME X" #TtW K0 ,0bF
T9j0)&0 $")<0F=0h$'N#"'Ffiff!\P) C9E#K0F4Qd'NT9 t+2\{XMGUbA#K$'NSH%(W)&]#%|$ME#T9 a#$'N#"'F
X( #Ttx(F MC9KFqK0F>"'F\LX( #Tdf'N)>Ql;#F$>W$ME#,F>'NKF$>TtC9)&'N9 #$&T9$M)&9;#$'N
F, ' $=0Qb 9\{_9#xT9>$M)&9;#$'NqU
vL;9)LQbFp)&M;#$S )&SRA#K$'N
9UlIX$ME#P>K$'Np-ff!*0 l C9C9)&'#FKEyPT90)<]7Tp)&'NQz
] 7)&F$'N9FqC90)&MCK$] U:q
$ ~T90#'7$,$!E#,C9 )&$$'Nd;9#K$'Nth'#K_h$T%W$MEb$ME#, ' $=0Q79
T9$M)&9;#$'NqU VWE#@] )<_h$'N9F,C0)&MC9K$>]7K'N))<MC9'N#T9b$'X_7$M)&'#T4;#K#D|N$!)y] )& #@ #T
T90)&]#_#DdK'N ]7;9#K$'N@'he$ME#>L] )& #PFW y;9C9C90)H9'N;9#Ty'NO$ME#S#DNF$] L' DN7)&$ME9Q
'FcU"VDNE7$0##D'F$ME#W9'N;9#T@0FT9W$>'lPQd_#QS=0F$>'#C9)&'N#0Qw2'N)s%,E#KEO$!F$'N9 )&$&SK'N7J
T9$'N#l7)&l' $MEX#KM )< #TXM;7}tK0 $H2'N)xD 'N9FffQS#Ql;9QUP[W$H$ME#c$MF$'N97)&C9' 7$L$ME#
9'#;9#TRF$$Mh_#TUyVWE#K'N7] y.;9#K$>'#|QS0 $>'##Tm 'F] SK'NQC9;#$MF$>'#9Fi_7$M)hK$M # U
2$LP C9C9)<' #QF$TX #TX$ME#P>$MF$'N9 )<$&@K'N#T9$'N#L'h"$ME#P C9C9)&'FNQh$L;9#K$'NX#T9c$ME#
QS0 7J 4T ;9F$>'##0UR-s!*0 C9C9)&'NFKEnC9)&'F]NT9ty#$0Qh$Kt%Wp'F,$!)FK$M #R7C9C9)&'FNjJ
QF$>_#DX$ME#S;9#K$'N $'T9)&T 'N)&T90)&S'FLFKK0;9)FKn$ME9)&'N;#D#ERV/N'N)c0)&0
U p@ME#'F% $ME9F$
$ME#S C9C9)&'FNQh$'NO'N#$MF#TX A9 ;# $,F2U ,7C9C9)&'NFKE@H$ME#LM QSPh,$ME9h$('he$ME#
a)&$W'#)&T90)
C9C9)&'F#QF$'N_X-s!*0 P C9C9)&'NhKEqUHVWE#P#$0#'Ny'F(-s!*0 P C9C9)&'NhKEOP#' $HT9)&K$0
U p
C9)&'NC' @X#% hK$] F$'N7J#T90C0#T90#$tKE#0QS@9FTn'NnVg#'#)P>0)&dQd$ME#'NT9S$'XFKE#]7
$ME#0U"I@A#K$'NOSC0)&QS07$W'NbMQF#$&%'N)*7"%0)&HK'N#T4;#K$TUVWE#HC0)&QS0 $>,ME#'F%
$ME9F$$ME#c'N#$MF#TX C9C9)&'FNQh$'N#, )&L9;#$lh$$M)FK$>]7 U

g " !#%$

j


&#%'e

$ME#yK$'N %>$M #MEBo.)7QS%'N)*n %,E#KEB' $ME X #TB(x@K0 9X$!;#T9TU
#T9T|9'7$MEX"XP #Tn(xLK0 p0XFLT9j0)&07$P$&CL'F\{X01q$ME#ST9j 0)<0#K_#Dy
$ME#LK'N9#K$>]#$& #T@$ME#L0#0)<D O.;9#K$>'#;#T@@K'#QC9;#$#Dt$!E#PC9)&'N9 #$k U
Ip$!E#C9 C0)c%(b%WW)&>$M)&K$P'N;9)<] S$'#9 )&i] F;#T~;9#$0(
U p$ME#;#ST9 a#X\{
$'@9cK'N#$#D@'F()4NTp#;9QS90)x'F"$'#KE9h$Kl;9#$0+
U * FKEy;9#$PE9Fu7F>'NKF$TX#9 )&
) #T9'#Q]F )& #
,.-/ r 023 1t+Z'N
) /N3 0
3L23 1 Gfi
U *"FKE@>$MF$5
7
4, 68/9, # 0:, ( 0
;<;
;0,>=1l'hsO\L E9FL
F>'NKF$7
ff>0#0)&D b.;9#K$'N? X19%,E#KE@L;#T$'ST9 a#c$ME#l ' $=0Q79OYL>$M)&9;#$'N> @

A+" 4, GB6DC2EF
H G JILK
& +

+&30G

VWE#@T90#'NQd_9h$'N)NMff1/K0FT~$ME#@C9 )&$$'Ni;9#K$'Nq1 $ME##'N)QbF=0h$'Ni.hK$'N)LT9a#T

56PO H G C EF H G JILK ;
& +

Q
R

fi

\ X"E90]7;9#$K0FT7ffME#T9T90? 419 #T ff>]N# t;9#$0U"VxE#W$MF$>(]7K$'N)i
{
4, K0 9H$ME#'N;#D#E $
4
4
41;
'Feh,9#DOT9]#T9TX_7$'S$ME#PC9F)'h +2E#T9T90;9#$MGW7#T +f]N#l;9#$MG19'N) 4, 6 / 4 0 N
YP;9)&#Dn'NC90)h$'N~C9E9F> 1]N#p;9#$> )&@K QCT1W$ME9F$S 4 6 4 1'N) 4, 6 /N4 0 4 1?;"VWE#
T9$M)&9;#$'NXF>'NKF$>T@%W$ME@$ME#PE#T9T90X;9#$xf'N)$ME#LK QC9TXC9E9Fc

A+ ff4
4 Gfi6 C E F fi+ H G 4 G K
H G K L;#TO2'N)Nff 720))&#D O$ME#L] F;#H'F"E#T9T90X;9#$0U
%,E#0)& fi0+ 4 GB6 G G
E
F
C

G
BE#0 HM;9#$>$!;#$T%W$ME
= = =


@+ g4, G 6 W
3 r; , , 3 ,
& +

+2 G

& +



Q# Q#




#

+ G

#TF'L$ME#W)&>$M)&K$'N 6 0FffQC9'7T'Nc$ME#%DNE $>g$ME#%4*N#'F%,S "'##$MF#TU
Ic$ME#(C9 C0)/%(%Wa )<$M)&K $ff'N;9)&>]7"$'LHMC9KF KFff'F(xff%W$MES$!E#"2' 'F%W#DP0#0)&D
;9#K$'N
=




4, B683

@+ ffG

"





#

/9,





_e+!

G" +<3

3 ,



G9+&3 #
3 ff+$



G>G1

+ZNG

%,E#0)&% 6 &E # #
,
0 #T%'HPS;9#K$'Ny)&'NQO!;9#$)( 'F"$ME#l)<0Fg#T90#' $>T
7+
*L1$'S$ME#P7$0)&] h (+2r030G1 2U U 1

@

,(.-/*/0

+.r0030G

;

p y%WPhM;9QSy$ME9F$1' 9FN$>K.;9#K$>'#qU VxE#0)&F'n$ME#)<$M)&K$'N 'N|%DNE7$
; A#DNQS' TB #T #'7> J'N)O#$&%'N)*7t )&y$k%'p!;#KE MC9KFP#$&%'N)*7+2x0F21
6 r91j325476
6 33
)&MC9K$>]7 UWI@DNQd'
305 57 G1#%W$MEhK$] F$'N.;9#K$>'##98"+!:4GB6 <;>=&?A@ #TB +!:4GBw
#$&%'N)*7E:K0 b9, 7)&0F4#;9QS90)17%,E#L#'7> J'N) :W)&$!)&KC $DE C T$'Pu#'N7Jk#D#F$] 8#$ME#
#

#

K'N#$!)F $HL07f'#)&KT7@2'N)&K#DO$ME#P%DNE7$u7#To#F>L$'t9#'N7Jk#D#F$] UFa)&'#QE#0)&S'N
%,E#0#] 0)x%P)&!20)$'WH$W%'N;#T9L%x$!E)&!20)&0#KP$>'+fNGU
F 'N)x_720)&0#KO$ME#SK0);#KF"$!E#_#D7L$'9]FF;9F$TR7)&
EfiH #T cUlVWE# a)&>$L$>0Q )&;#)&
M;9QQd_#DS $>0)QSff%,E#L$ME#W#N$ $0)Q)&9;#)&M;9QQS#DS = $0)>QS,+Z%,E#0)&H~ $ME#,#;9Ql0)
'FgE#T9T90;9#$W #T@ $ME#,$>' $MF4#;9QS90) 'Fg;9#$MGU"VxE#,9C9)&'N# 2'N)"C97)&$$'Nd.;9#K$'N#
)&SQS )cp9F$M;9)<d' $MEXX$!E#lK QbC9T| #Tp$ME#;9#K QCTmC9E9F> UVWE#'N#XT9j 0)<0#K
L$ME9F$H$!E#lK QbC9TpC9E9FS$ME#SM;9QQbF$'N@L'F] 0)HE#T9T90p;9#$01q%,E#X$ME#S;9#K_7QC9T
C9E9FH$W' ]70)"Fq$ME#L;9#$>0U"VWE#;#$ME9)&'N;#DNE#'#;#$($!E#u)&0QbF#_#DOC9 C90) %,%x$!F*S'N#t 'N;#$
] h_;9h$#D ;
[H,QS07$'N#TX 9'F] cK'NQC9;#$#%
)&9;#)&P O9C9'N#07$F/M;9QQh$'N@'NC0)F$'NqUVWE#;#
9FK$SK0FK0;#_h$'N 'F b_7$M)hK$M # URA9 QbC##D|9FT~QS$!E#'NT9'h 0)SXC9'7#%Wp'N;#$0U
;#$@$ME#pQS$ME#'#T9 )&yK'NQC9;#$Mh$'N9F ]70)&|C0#] Uw[u#' $!E#0)@F$0)9F$] y$'n'N'N*
2'N)OT9$0)QS#$K~ C9C9)<'NFKE#01L9FTB'N QS077J 4T^$ME#'N)< hFT9] '#K0F$TB +2-/$>0)&'N ?
[L#T90)&'Nq1/305 6 8A97;#$uhfU 1305 5 G8L7C9C90XI
? H'#T4)&DN;#= 1ff30575 6 GU"VxE#PQS$ME#'#T9uC9)&'#C9' TX
+2-/$0)<'NP? [u#T90)&>'Nq1430576 98 L C9C0tJ
? H'#T4)&DN;#= 1q305 5 67Gg )<7C9C#K0 #L$'P X01F%,E#LA9 ;#
$LF2U +&305 K5 G GT9] 'NCTR>KE#0QSS%,E#KEXE9Fu0p C9C#Tp$'@9' $!EWP7#T X0U,VWE###$
K$'N%Wg9cT9] ' $T@$'-s!*0 ,QS$ME#'#TB
U pc $0#T@$>'$M;#T9O$014;9#T90)&$! #T@$,)&F$'N#
%W$MEN$#DO$ME#'N)&,7#T C9C#@$W$'tx0U

QML

fi

y)

ff

! $ "ff

]





{yy


&#%'

HK07$ L C9C0 #T H'#T4)&DN;#=N+&35 5 6 GS7$M)&'#T4;#KT1W$'i$ME##0;9)h,#$&%('#)*pK'#QQS;9#$& 1

C9'F%0)I;#u7C9C9)&'FNQF$>'# Qd$ME#'NT T4;#p$'|-ff!*09U $ME#@K$'N %%xPC9)&>0 $-s!*0
QS$ME#'#TppOT9j0)&07$L% 1q'@$!E9F$L$LK0 p9bN$0#T9Ti$'W0U p%xF'@T90QS'N#$!)F$ 1
F$0)$ME#,K$>'#@$ME9F$W-s!*0 uQd$ME#'NT@LQS'N)&LD70#0)Fq$ME9 @A# @ C9C9)&'#FKEqU


fi ff )qWxGn

YLa#lb#%B0#0)&D b.;9#K$>'#

+ 4 0!G 6"$#&% 3
@

=





#

,

+2 G

2+ A##KP$!E#LT90C90#T90#KS'Fg]F )&'N;#x.;9#K$'N#x'N 4, 1'%B #T 4 x;#$L'N7]#'#;#019@%,E9h$"2' 'F%W
%@%W,#' $tQS07$'Nn$ME#>Fc.;9#K$'N9hu )<DN;9QS07$0U @T9'$!E#O'X$ME9F$S$ME#@T90C0#T90#K
'Ny' $ME#0)H]F )& #P!;#KEph(
R7#T 4 >$M #T9L'N;#$PQS'#)&SK07)& U GRVxE#K'N))&!C9'N#T9#DC97)&$$'N
;9#K$'N #TC9)<'N9 #$&yT9>$M)&9;#$'NX )& @

. 6



HG C E F

) * 6 C E F






+$G G
+ G

L$M)<0F$ F#$0)9F]F )& #0UVWE#,E#C#P;#W@#$0#T9#Dt$!E#P C9C9)&'NFKEO$'ST90)&] SQS0 7J
p
4T~$ME#'#)&2'N)S W0U vL ;9) C9C9)&'NhKEnT9j0)&S)&'NQ $ME9F$b'Fd+2L C9C0~? H'#T4)&DN;#= 1c305 5 6 G1
%,E#KE@T90 $> 4 %W$ME 19$ME#P#FH] 7)& #L_y m1#c;9h$'Np+ GU
VxE#dQd' $] F$>'#@2'N)H9 )&#D #DX_+R7#T 4 7#T T9 # #DX$ME# ' ]7L;9#K$'N#PlhW2' ' %x0U
ZP$!E#@0#0)&D i.;9#K$'N t'FL$ME#@#0 )b2'N)Q@1 , 1"$ME#0 $ME#@K'N))<MC9'N#T9#D~C9)&'#9 #$&
T9$M)&9;#$'N OFK$'N)&F21P+Z'huK'N;9)<'N#@K07~;#X' $ME#0)l.;9#K$'N#7#T~$H$ME#C9)&'#9 #$&
T9$M)&9;#$'NiK0 X9d.FK$>'N)&FG1q #TpK'NQC9;#$!F$'N#LK0 X9bT9'N#S$M)FK$M7# UcVWE#tC9 )7QS$0),
K0 c9$ME#'N;#DNE7$/'FaFff,E#'NQd' $'NC7uC97) QS$0) $ME9F$/MQS'#' $ME#P9)&#D ffc$ME#$M);#"0#0)<D H.;9#K$>'#
$>'C#K$!;9)&F(
iL#K0)&0hTy.)&'#Q r9ULV 'tD7$,$ME#S'N)<D7_9hg0#0)&D7@;9#K$'N.)&'#Q %S#T
$'>$

6B,r -+2 -/N3 0! 0/.0.1.321 04 63
+26 G
F4'#)K'N7] 0#0 $,Qb #C9;#_h$'Nq1q$Wu;#!;#$'bT9 a#P$ME#H;9#K$'Nq1

4 0 6&3@

(+ !G

%,E#0)&

"


98

5 676, : ; 6=<
<



5

+25 G

+&30r G

A##K 5 4 1 $ME#HQS0 S] K$>'N)1F(C9E7N>K0h@QS'N)&WQS07#_#Dh.;# $ME9 4 1 $ C9C9)&'NC9)<_h$W$'LK'N#>T90)
$,F )&P #T@$M)&0h$ 4 FH9#DtT90C0#T90 $H'N 5 4 UeV 'SFK$!F$LM;#KE@S$M)&0h$MQS07$"$ME#H2' ' %x_#D
F!;9QC#$'NOuQbFT9 U

Q1>

fi



rs]ypxou;o o)x3}

4 U





/
Qxo Qsj



F4'N)S0hKE 4NT

54

7#T ff1u+<30r GcK0 ~p;9#9;#~'7]7T~2'N)

: $ 6fiff + 5 4 0 GcT90#' $>$ME#X ]70)&'h+&30r GU B
E#0 $ME#7] 0)&y;9#K$'N @;#T1(
$M)7#&f'#)QS$'c;9#K$'N@'F 5 4 7#T B@

40 G G G
+&3 30G
VWE#;#

+ 5 4 !0 G 6&3_ " K 5
+&30 G

%,E#0)& ,K'N#>T90)<T$'tlc;9#K$'N'F 5 4 1j #T ffUex' $L$!E9F$


< 6 < ( < ff 6 3 < " 5 " < 5 < ff 6
+&3
G
5<
5




< < 5


<
< <
VWE#p)&F$'N#!E#_C 9$&%0 4 #T 5 4 1,Qd'N)&C9)<K> 9;9F$'N#R+&3r G1L+&3
G1W7#T~$ME#X ]70)&$&J
#$&|FM;9QC#$>'#q1P%(*##'F%,X #TpPK0FT|$ME#:qD 0#T4)<V/) #&2'N)QbF$'N|+$H'#K*20)1
305 7 GUL07$M)F$>'@$ME#L$M) #&2'N)QbF$'N@L$ME#I ] 0)<$#$&RF!;9QC#$'NqUPVWE#S]FFT9$&p'F$ME#
F!;9QC#$'N@F$ %63LWQC'N)&$M7 $2'N)$!E#L$KE9#9;#,T9K0;#>TX_$ME#PC9 C0)U
In$ME#79'F] @%E9] QFT9;#@'hu$ME#.hK$l$!E9F$ GG O$ME#@ ]70)&'h GG U~W0#Ky$ME#
B
6 r,- 2>14)&9;#)&0QS07$uQS07$'N#Ty_n+26 G $M)7#F$W$'

< 6 B
6 r -+2
+&3NG
5<
0 )& 1 %,E#0O$ME#HK'N#$M)h_7$WH07f'N)<KT #T yHK0 ))<T@$>'3 1#%LD $ 6&
3 _c U
VxE#p ] 0)<'N 'F+&30r7G7$M)FK$! #p2'N) 6 r91H%,E#KE Q *Fy$yQC9' >#|$>'|%,)&$
40 6

+ 5 !G J(@+ !GM

$ & *

+

nFD 09)FKOC9)<'Ni2'N
) ff| #T|E#0#K\UffV 'K)&K0;9Qc] 07$S$ME#tC9)&'N#0Q@1"7p C9C9)&'F#_QbF$
T9K0)&C#$'NO'he\B,9;#$,7t;##D$ME#xFK$"$ME9h$"$ME#H ] 0)<'NO'F(+&30r Gs(9;#$L$M)>FDNE $<f'N)<%7)&T
F$ 6Br914 #T@9C9 #T9#D + 5 4 0!G" )<'N;9#T 6 r;##DV/N'N)xA#0)&0U
[x$ %6Br91

) * 6 3 C "

#T@9;9F$'Nn+&30r G9K'#QS

JH



C

+&30 G





C3E"

C
VWE#L7] 0)&'N'Fe$!E#H9;9F$'NOK0 y9PK07))&T@'N;#$W9C#K$X$''##$MF 6




+ 5 4 !0 r G 6 5 5 "B+&3 3 5 G9+&33 5 G
5 6


#



E

#T



[H>'419$ME#LT9$M)<_9;#$>'#n+&30 G K0 y9L9C9)&TXF,c;9#K$'N@'h


) * 6 5 H +&33 5

Q!



G
#

E H

5 4 19OFK$'N)&F

2'N)Q
+&3MG G

fi

y)

{yy

VWE#L$M)>;9#K0F$TV/N'N) 0)<L C9C9)&'F#QF$'NO'F

+ 5 !G


40 6






40



< <

+ 5 Mr G>"
Q#





+&3
G



* *

Lc;9#K$'Ny'F 5 4 #T ff147#T@K0 P]#%TpF,7@X$MEO'N)&T90)x C9C9)&'FNQh$'N@'F"\U :q$
;##'F% K'##T90)S$ME#@)&;#)&0Qd0 $OQS0 $>'##T|_B+.6 GUXA#$$#D .6 3t>$M)FDNE7$&2'N)&%W )&TX$'
QC#0QS07$0U(VxE#l)&9;#)&0QS07$01 6Br1 2'N)Wh f1K0 l C9C9)&'F#QF$O07f'N)<KT;##D+&3NGF


6 < < 6Br -+2
<5
<5

+&306 G

VWE#H9;9F$'N#(7)&,;#TO$'P>$(;9Cb$ME#4#T@C9' 7$"9;9F$'N#0U"x0#K!2'N)&$MEb%W%W )<!f0)s$ME#0Q
FW$!E#PQS0 7J 4TX;9F$>'##0U
VxE#W20F#$&y'Fg$ME#HKE#0QSLHOK'NQC9;#$#D$!E#PC9 )&$FqT90)&] h$] W'F"\^%W$MEO)&MC9K$
$' pF(
$ 6rU,y$ME#PC9 C0)H%P%W")&$M)<K$H'N;9)&>]7L$'
6 ;aVxE#l)&] 7 $L9C9)&'N#
+2-s!*01305 6 8E9F$>$MFKE9 )&#NS?H0)&$ME#21g35 5 5 9G )&

<
<

(





8
< 7
6
6 :

< * *
= M6 +$ 3 6 8 G+, 3 5 G 8
:(
8 8
ff
6&3 6M+!P3 6 G ( :
ff "
+&33 5 G
5
#



* *

(

+&305 G
+2 r G

*ff9C9)&>'##Sf'#)S' $ME#0)cT90)&] h$] tK07|F'R9@T90)<]7T~~y$M)>FDNE $<f'N)<%7)&Tp%W U F4'#)l
$ME#cT90)&] F$>]7u )<L$M)FK$M7# U F4'N)WxWK'NQC9;#$>_#DO$ME#c$0)QSxHC9)&'N#0QF$K 1q #T>''N#
/f'#)&KTS$',Q *h";9)&$ME#0)/ C9C9)&'F#QF$'N#0U/W%~7C9C9)&'FNQF$>'#P>KE#0QS/$ME9F$/%(E9] T9]#>T
%WePT9K0;#>TF$0)U
V 'W]FF;9F$"$!E#"9;9 $>$>ff)&9;#)&TL2'N)q0 )##DL'N#E9F$'xK'NQC9;#$
fi Uff:q$/;#gK'N#>T90)

$ME#H;9#K$'N
e+ 4 fi
G 6&3 + 5 4 003
G 6


%,E#0)& 5 4 ,#'S'N#D 0)W{)&,]7K$'N)199;#$$W(K'##T90)&T$'PL;9#K$'NO'F 4 ] 0O p+&3NGU
x' $L$ME9F$

+ 5 4 030G 5



<

x#Do+&3NG %(LD7$

<





6 <
<





6&3 <

<





"

< &
6 3 < + 5 4 030G
<
<



< <
< 5 <

V E#X)&DNE $OE9 #T~T9yO $!)FK$M # 1W9;#$OK0 |9X C9C9)&'F#_QbF$T ;#>_#D
W
F$
T90)&] h$] u)<;#)&Ty2'N) 07)##D@K0 O$ME#;#,9cK'NQC9;#$T7@$ME#P C9C9)&'F#QF$'N>@

%,E#0)&

5 4

< &
6 3 < + 5 4 030G 3 < + 5 4 0030G
<
<
<

,S>' ;#$'N@'Fff$ME#PQS077J4TX9;9F$'N#01/+&306 GU

Q

6

3 U VWE#

fi






]q



]qyq

q q]s ]p&Qq]s

;p/qz{nq]s

3
fiff



qWxGn

A9 ;#$HF2U +&305 5KG GC#'##0)&T$ME#S C9C#K0F$'Ny'F"QS0 7J4T$ME#'#)&t$>'tW0U @$!E#HM;9#K$>'#
%@%W,ME#'F% $ME9F$b$ME#) C9C9)&'NhKEnK0 |0 F(a)&$b'N)&T90) C9C9)<' #QF$'Nn'h{-s!*0
QS$ME#'#TU"V '$M7#ME$ME#,%PC9)&>0 $,b#%B] )<_h$'N9F/T90)&] F$'N'F"-ff!.* ,Qd$ME#'NTU



]q



fi|qyq

)qeq]s |p&

;p0qz{n

q]s3

fiff



i$ME#SK$'Nn%t)&]#%A9 ;#$lF2U c%'N)* UVWE#RFT9'#C#$l@]F )&F$'N9h7C9C9)&'NFKE>@L2'N)Q
;9#K$'N+Z%W$ME{N$!)W]F )& #MGs%,E#KES"x' %0)/9'N;9#Tdf'N) #TSKE#'#' $ME#] )<_7# 'LF
$'PQhNQS=H$ME#;9#K$'NqUff[L C9C9)&'F#_QbF$T9$M)&9;#$'Nq19+ 4, 0 5 4 G1F"KE#' 0S%x$!EPC9 )> QS$0)
] K$'#) 5 4 URVWE#C97) QS$0) 5 4 1"$M;9#T|>'p$ME9F
$ 9+ 4, 0 5 4 GctFbK'7FC9' >#X$' ) + ff4, GUp[H
Qd0FM;9)&'hK' >0#t9$&%0X$&%'@T9$M)&9;#$'N#tL;#9FK*R: _#0)bT9$M #KOd;#>TU2$c
T9 a#Tp
9+ 4, 0 5 4 G
X
+ ?0 )
G 6 9+ 4, 0 5 4 G9
+2930G
) + ff4, G
VWE#

54

HG

WKE#' 0@>'$ME9F$X+?0 ) GsLQS#QS=TU9+

4, 0 5 4 GB6

9+


BE#0 )

=



4, 0 5 4 GWKE#'70@$'LFK$'N)&F2192U U

H5 +&3 3 5 G E H



#

+2 G

#

W$!E#l ' $=0Q 9OT9$!)&9;#$'Ny$ME#PL;#_9hK*y:q#0){T9$M #Kc$M *F$ME#H2'N)Q
+


%,E#0)&

8
6
@+ 4 G & +
G
%
3

+2 G

F+ 5 4 G



=









3 5 G9+&33 5 GG
+2FNG
5

x#Dt$ME#HFK$W$!E9F$ + ?0 ) G rS%LD $,c' %0)W'N;9#T'#@ @
P3
+2 G
LQS#QS=T~%W$MEp)<MC9K$S$' 5 4 $'yD $P n;9C9C90)S9'#;9#TR'N 3@ c
U@VWE#t]7K$'N) 5 4






+ 5 4 GB6

0 ) G 6 ff"







"

#

+ 5

"B+&3

!

"!

#

#

T9$0)Qd_#Tp7t>' ]N#DO$ME#Hf'7'F%W#DO$W'Fff;9h$'N#0U

<

6

Br



<5

+2G G

VxE#'N;#DNEO$ME#L C9C9)&'FNQh$'NO,%g*##' %HO_y$!F$$K0FC9E7NKH$>0)F$M;9)&@+2-ff )&2135 6 6 G
F L$ME#O9F] Qd0 7J4TR$ME#'#)& 1gA9 ;# $PF2U C9C#K0h$'Np'h($ME#S$ME#'N)&y$'Wcd#% #T
$>0)&$#D41"E#0#KO%t%xW)&!20)L$ME#@ ' ]7t C9C9)&'NhKEphP$ME#@A# p C9C9)&8 'NhKEqU@[ '#'N*pF$@+2FNG
ME#'F%W $ME9F$$ME#W C9C9)&'NFKEOE9FK'NQC9;#$MF$>'#9F920F#8$&@'N#O%,E#0+
6
K0 tLC9)<T@F
c;9#K$'NO'F 5 4 U F 'N)W01$ME#LK0FK0;#F$'N@'h 6 @+ /4, G x_7$M)hK$M # 14]70O%,E#0$
c.FK$>'N)&F2U
A9 ;#$LF2U M;#D $9C#' $#DFK$]FF$'N7JT90C90#T907$LK'N7] #$&C9)&'#C90)&$H$'T9] 'NC.;9)<$ME#0)
C9C9)&'F#QF$'N#@$
' U VWE#;#@'N#pE9F@$'n$MF'N)$ME#pA# C9C9)<'NFKEn2'N)O] )<'#;#FK$] F$>'#

Q

&%

fi

y)

{yy

;9#K$'N#0Uc[up7C9C9)&'FNQF$>'#q1 :!: 1 LT9] 'NC9T|*F0C##D$&%'t$!E#_#D7L_iQS#T @t+&30Gx$L
K' c0#'N;#DNEO$' #84 #TR+. G$Wud$M)FKC $M7#H;9#K$'N'F 5 4 UffVWE#0R+2KG G L C9C9)&'F#QF$T7

<

#

*s] 0S%,E#0 5 4

:!:



<5

6

+2 G

C Br

KE#' >0$'SQS#QS= 1 $!E#,9;9F$kb_p+. G/,F$$!F#Tjs #TO'N#j )
FK$'N)&F2UffVWE#ff2' 'F%Wff)&'NQ^$ME# FK$ff$ME9F$X+?0 ) G6BrHje7#Tl'##Sj ) 6 #1# #TS$ME#FK$ff$ME9F$
KE#' >0S$'lWFK$'#)&F2UeVxEN;#A# C9C9)&'NFKES9FT9;9h$W2'N)/'N#$!F#_#D b )#$M) )<K' >
C9C9)&'F#QF$'Nb$'P
P172'N)"cD 0#0)>F4T9$M)<_9;#$>'#q1 ) UffvL#L%WS'F' ]70)&K'NQS#DS$ME#T4)%,9FK*41
L$'O$M)&0F$L!QFe#;9QS90)H'F] )<_7#chK$ #TX C9C9)&'FNQh$S$ME#l)&>$08q+ZN 7*N*F'7_O?
'N)<T4 q1g35 5 598qA9 ;#ff? 'N)<T4 q1ff305 5 G7GU(Iy$ME#PC9 C90)H%P>$M;#T9-ff!*0 P7C9C9)&'NFKE@%,E#KEX;#
V/0#'N)/0)& $'LD ] ,H#$0QbF$K%c'F 9;#T9#Dt )#$M)7)&SK' H C9C9)&'FNQh$'NS$'L
cU
b$ME#HM;9#K$'Nb%,%x)&T90)&] L-ff!*0 Qd$ME#'NTb)&'NQ {] )<_h$'N9FC90)&!C9K$] 147#TtME#'F%
$ME9F$WA# 7C9C9)&'NFKELSMCK_hgK0F>L'Fs-s!.* L C9C9)&'NFKEqU


q$WxGn

SqpGoqyxo

Cyp& ;yzGxo |

s|q

y$ME#LK$>'#@%l)&T90)<]7d-s!.* PQS$ME#'#Ty.)<'NQb] )&F$>'#9FeC0)&MCK$] UPVWE#c_#9;9F$&
N' 3@T90)&] TXy$ME#lC9)<'NK1a #Ty$ME#S$M #ME9QS07$L'FffK'N7] N$&@'F"$ME#S C9C9)&'F#_QbF$'N
;9#K$'N%x$!Et)&!C9K$W$'c$ME#W]F )&F$'N9Fq]F )& #, )&H#% K'# $M)<_9;#$>'##,QFT9WO$ME#WC9 C0)U
Fa;9)<$ME#0)QS'N)< 10%"F'WT90Qd'N#$M)h$ff$ME9F$$!E#"A# P C9C9)&'NhKEHffMC9KF9K0hff'F4-ff!.* ffQS$ME#'#TU
[HWA#K$>'# 9U c$ 9S)&0F/C9 ) QS$>0)"$!E9F$W$M *hW] F;#x.)<'NQ rS$'3 U :q$,;#HT9 a#
$ yT90C90#T907$PC9 )&$$'N@ #TyT9$M)&9;#$'N;9#K$'Nq1

*
CGH E F H G JILK
* H G JILK
) * 6DC E F *

* 6



+2 6 G

& +

& +

x' $L$ME9F$
#

6P^ #T ) 6 )
#

UeI $!)&'NT4;#K#D O#$0)9h )<0F] K$'#)

* 6
%,E#0)&

+2 5 G



HG

*ff
fi ;


CE

JH



^ HD ] 0@7o+$G7GU W#DO 0#0> L#9;9F$& 1
* 6 ) * C E H

CE

H
8

6 C EC C E C 19%LD $


+ r G

!

!

CE

HG
V/ * #DO' DN )&$ME9QdW'N@9'7$MEOT9,'hx+30G1#%,'N#$!F

3 5
' * |' .
!

4 19$u;#,)<%,)&$t+2 67G(h

+930G
+ G

x' $L$ME9F$x$ME#l)&DNE7$,E9 #TyT9c.;9#K$'Nu#' $!E#_#D@9;#$N3 (+ 4 0!GFWT9a#TXR+.5 GU".$,LF'
%'N)&$MEy#' $#D@$ME9F$L$!E#dQd' $] F$>'#@2'N)HT9a##DX$ME# ( ;9#K$'NXK'NQSPQS;#KEXQS'N)&S9F$M;9)F
E#0)& U

Q

fi

4

f g$ME#L7] 0)&$#$&XFM;9QC#$>'#@E#' T9W$ME#0O%LK0 O;#
T90C0#T90 $H'N 5 4 G #T)&%H)&$t+ GF

3@ *

54

F$ME#L#T90C0#T90 $L] K$>'N)L+Z%W$ME

40

+ G

+ 5 !G

%,E#0)& PFHT9a#Tn_|+&3730GULVWE#LD ] PO] 7)&F$'N9F fff$>'-s!*0 PQS$ME#'#T @H$M)&0F$ 5 4 F
#$0)9F]F )& #S] K$'N)x #TKE#'N'7L$,$'OQS#_Qd= U2$WK0 y9{ .;9)&$!E#0),C9)&'F] T@$!E9F$ L
K'N7] @;9#K$'Ny 5 4 ULV '@S$ME#LT9 a#$ME#SW>_7X'F F 6 ;qYLj0)&07$F$'N

'F,+&30r G %W$ME@)<MC9K$H$' 5 4 1N#T9
6cv
+ FNG
%,E#0)&

8
98
8
v 6 6 , , 3 6 ,
6,
+ G

#DbK' ]F )& #KtQbF$M)&q
1 PC9' $] b0QST9 a#$
U *ff9;9F$'N|+ F#GW0#M;9)<L$ME9F$L9' $Mff
E
#T )&P#'#7J#DN;# )UW0#K ,C' $] ST9 a#$PQC###D@$ME9F$ HK'N7] qU
[HST9K0;#T _ A#K$'N7
9U 1g$!E#@T9 }OK0;#$&|n ]70)&$#D +&30r7GH2'N
) 6 rX)&0QbF#t #Tn
' ] Tp7@$ME#lV/N'N)x0)&P C9C9)<'NFKEFHT9K0;#Tpy$ME9F$HK$'NqULf"%(S;#S$ME#+
a)<$,'#)&T90)
C9C9)&'F#QF$'NO$ME#PA#7 C9C9)&'NFKEbH'N#$Mh_#T
U F4'#)
6371N%PE9]
# + 5 !G

40 6

%,E#0)&

40 6

+ 5 Mr G

.hK$ fi
#



=



+ 5

Q#



5

'F] 0)&$Qh$$ME# ;9#K$'N

3@' *

8
6

: ff
%

40

+ 5 !r G "
"^+&3

40

+ 5 G

3 5



G_+<33

+G G

5



;

GG

40 ;

+ G

fi # + 5 !G

V @
' $ME#+.F'@+2E9F$$MhKE9 )<NNO?H0)&$!E#f1 305 5 57 GGH#' $S$ME9F$H;9h$'N~+ 7GWK0 iF'
9c $0)>C9)&$T$0)QS'Fff$ME#LT9] 0)&D 0#K$k%0O$ME#c$&%('cT9$M)&9;#$'N#01 ) * 7#T ) * 1 $ME9h$(
X+ ) *


[H>'#' $>_#Db$ME9F$

0 ) * GB6


GH

) *

) * 6 _ *
)*



" +5

40


) * )) * * 6 * " fi # + 5 4 0!G
HG

X+ ) * 0 ) * GB6 ) * _ ) * 6 fi # + 5 4 0!G 3 + 5 4 0

)*
HG
X+ )


*

0 ) * GB6

+ 6 G
G

+ 5 G





G

+ZNr G

#T;##DO$ME#LFK$$ME9F$x$ME#LT9] 0)&D 0#K LF%#,#'N7Jk#DNh$] t+ G H'N#$MF#TU
[x$ %63
# + 5 4 0030G 6 + 5 4 G
+Z430G
%,E#0)& #W$ME#H'N#&K$] H;9#K$'NO'N#$MF#T7A#7t C9C9)&'NhKEq8#t+2hNGUgx' $H$ME9F$WF$ %63 1
+ 7G">$M #ME#L$ME#P#9;9F$k|+2 G @$!E#lA# C9C9)<'NFKEqU"2$H,$ME#;#WK0 )&y$M #ME#TX$ME9F$

Q
Q

fi

y)

{yy

A# C9C9)<'NFKEOL a)&>$,'N)<T90)W C9C9)&'F#_QbF$'N@$>'t-ff!*0 L C9C9)&'#FKEqU#KT907$MFp(7)90)H #T
] 7@T9P: 7)P+&305 575 G"F'@)&T90)&] Ty$ME#PA# @ C9C9)&'NhKE@7;#>_#D@SK0;9QS;# 7$,9C9 #'NqU
x#D+ 6 G14+ 5 G1q+ZNr G1 th$>0)9F$W72'N)Qh$'ND7'NQS$M)&KHT90)&] F$>'#'Fff-ff!.* WQS$ME#'#T
K0 c9K'N#$M)>;#K$TUffVWE#] )&F$>'#9FNT90)<]FF$'NSC9)&07$TE#0)&WF'LE#C#ff_d$M #ME##DP9*
%W$MEy' $ME#0)L)< a#0QS0 $>L*F@V [u-B7#T#0 )c)&MC9'##K'N))<K$'NqU F 'N)HOT9$MFTpT9K0;#'N
'Fff$ME#,C9'7_7$L)&!20)$'+2E9F$>$MFKE9 )&#NP?H0)&$!E#f1q r r7r91q305 5 5 9GU



Wq]s' fi

;p0o qyxo Qs$

]pv+

!*0 Qd$ME#'NT T9K0;#T
$ME#@K$'Nq1WQS077J4T $ME#'#)&p2'N)xt @T9] 'NCTB;##Dm-s

#
|$ME#XC9)&]#'#;#tK$>'##0U/F 'N)x0FKE., t7`a;#0#KT 7 &E # , " 1%,E#KE K0
9O]#%T|F+
4T90UXVWE#@QS0 7J4T~ C9C9)&'F#QF$'NX$!E# 0pM;# D7D $L $M E9h$P$ME#@
C9)&'N97#$K
4T9,QtP)&0C#FKT b$ME#)WQS0 b] F;#01$ME9F$" &E # # 5 " ;H0C##DO$ME#_@Qd_#T1
-ff!*0 QS$ME#'#T FT4 C#$>T $>'|T9] 'NCBQS0 7J 4T^KE#0QS @2'N)O( x0UIBA#K$'NP
9Ujp%
M;#D D7$( b C9C9)&'FNQh$'NQS$ME#'#TO%,E#KEbK0 u;#TO$'cK'NQC9;#$,hq$ME#x;9 7$$W)&9;#_)<T
2'N)LQC#0QS07$#DR-ff!*0 d7C9C9)&'NFKEqU@vL;9)P C9C9)&'#FKEoS9;#$tD70#0)F(7#TRT9'#l#' $cT90C90#T
'NO$ME#{f'#)Q 'F"FK$] h$'NO;9#K$'Nq
U F4'N)'7$ME#0)WFK$]FF$'N@#T90C0#T90 $S C9C9)&'NFKE#,)&D# )&T9#D
$ME#S C9C#K0h$'Ny'FsQd0 7J 4T$!E#'N)&O$'(xH+2H2$019W'h.Q79q14? V/)&MCq135 5 5989H0 )#L?
A9 ;#21q305 5 67GUgA##KH2'N)"!(#$&%'N)*{'NC90)h$'N
% $"$>'t3 17%(H%WqT4)&'N$
C % )&'NQ h.;9)<$ME#0)
9;9F$'N#0U





' Qs q$WxGn

z{n]vq

-ff!*0 lQS$ME#'#T1ffFlC9)<0 $>TpRA#K$'Ni41 #' $cT9)&K$R;#!;#ff2'N)Px01gK0 ;#O'FW$ME#
$!)FK$M #$&R'FH$ME#C97)&$FT90)&] F$>]7tF$$.6 r9UXV'X'F] 0)&K'NQd$ME#tC9)&'N#0Q@1 %t!;#D $
nQS$ME#'#T 9hT~'N V/N'N)S>0)&@C9 #>'#qU VWE#@p] 0)<|D 0#0)F,Qd$ME#'NTB #T #' $
T90C90#T907$H'NO$ME#PFK$]FF$'Nb;9#K$'NqU(VxE#HQS$ME#'#T@09 #,K0FK0;#F$'N'FeF$!E#P#KM )&
$0)Qd,)&9;#_)<T@2'N) N$0#T9#D-s!*0 ,QS$ME#'#T@2'N)WU
: $,;#WT9 a##%B0#0)&D7;9#K$'N

fi0 4, 0 5 4 0 4 GB6&3

ff + fi
@

%,E#0)&Pr
fi

=






3 1

#



+ figGB6 E

&

#T



#
#



6 E

&

ff + fi
A##KfipW$!E#,QC'N)&$M 7$WC9 ) Qd$0)1
#' $Mh$'N9FqK;9QS#0UWx' $L$ME9h$

B683

ff +2r G




=


#

/9,



3 ,

_e+ + figGG>"^+&3








/2,

_e+

, 3 5 G"



fi(+


#
#



5 "







G9+&3 #
3 ff+ + figGG1




;

0 4, 0 5 4 0 4 G %Wg9P)&!20))&T@$>'dh




G" +<3


3 ,

+ZN G



G9+&3 #
3 ff+



G

1

ff + figG 'F$'] '


fi

ff +&3G+6
#T
T9a#

;>pt;#@V/N'N){0)& C9C9)&'FNQh$'NX'F
B6

ff + fi/G

ff +2r7G "


ff #1 $ME#0%LK0 O%,)&$
Z ff C9C9)&'FNQh$

6



:q$,;#L#'F% T9a#l$!E#Hf' 'F%W#D;9#K$'N

+fiB0 fi

0 5 4 G 6 3_






< <

#



ff +&30G


ff
fi
*


fi



ff + figGL%W$MEi)&MC9K$S$' fi"U@:q$;#


+Z NG


CG E F JH "



+Z G

;

ff +&30G

*



;

ff ;





5

+ZN G

5 4 0 fifi0 e1%,E#KE@ )&H'N#$MF#T7 ] 0)<$#Dl$!E#W2' ' %x_#D
+Z G G
5 6 , ) * -

V E# )&,hM;9QSTO$'9H;9#K$'N#'F
W
9;9F$'N#
@

HG

%,E#0)&


C E F * ff ; H H
GCE F

)* 6

*

ff ;

+Z G



ff ff _n+ZN G %L'N#$Mh_
)<0C#_hK_#D w



+fiB0 fifi0 5 4 GB683@




CG E F
*



H

ff ;

5

" K

+ZN6 G

ff 7 ff ;Nd]N% 'F(+Z NG/'##WK0 SK'N#>T90)
%,E#0)&x$ME#WT9a#$'NO'F 5 4 'N#$!F#Tt )&0C#FK#D ^

F, @ C9C9)<' #QF$'NO$>' ;4VWE#H'N#0)&]FF$'NM;#D $>7@ C9C9)&'FNQh$'NO$' U
fi+ B0 5 4 B
G 6 3+ 03 0 5 4 G 3+ 03 0 5 4 G
+ZN5 G

VWE#0$ME#PQS0 7J4TX;9h$'N#WK0 y9L$Mh$TF




6 < 6 <
<5
<



5


<

#






< 5



6Br
#

+2 r G

VWE#P)&9;#)&TX$0)QSW#T9TX@$ME#PV/N'N)C9 #>'#@'F yK0 @9S C9C9)&'F#_QbF$T7

4 0 6
6 <

+2r003

+ 5 !r G

<
<







* *

<






0 5 4 GB6



* *



+2r03


<

<

#



0 54 G





* *



#

VWE#S#D7D $,FT9]F 7$MFD Ly%'N)*7_#Db%W$ME )F$ME#0)$ME9 H$ME9F$W$!E#lC9 )&$>_hT90)&] F$>]7,'F
%W$ME@)&MCK$,$' F$ %6Br #T
fi 63LK0 @P9C9)&TXF;9#K$'N#,'h 5 4 ; iPT9a#

40 6

ff + 5 !G

+ 5 4 M0 r G>"





#




<
<








* *


+2930G
#

fi

y)

{yy

D#E $H'Fg$ME#S 9'F] HT9K0;#'Ny'N#cK0 OK'N#T90)

ff



+2 G


#TE#0#KS$ME#PQS077J4TX9;9F$'N#WK07@9P>$MF$TF


ff
6 < < < 6Br
<5
<5
<5

+2 G

V 'T9] 'NCnO2ff2'N)L$!E#t C9C9)&'F#_QbF$'N#P$;#PK'##T90)P$!E#K0FO%,E#0)&
'N)&T90)K0F UEHK0h/$ME9F$WF$, 6Br1N$!E#LT9>$M)&9;#$'Ny,D ] 0y



) fi * 6 5 H +&33 5



8

G

&#

8

6

371$ME#Na)<$

E H ;
)+



ff




3
ff +2r G

<
7
6
6


"
+2FNG



:




:

*



fi

<
<
:

$ME#,$>0)QSK0 O9LK'NQC9;#$>TFWL;9#K$'NO'F 5 4 U"VWE#L C9C9)&'#C9)&F$L9C9)&'N#,7)&,T90)<]7T


<



*

#

676 ff

+&3G

#

*

[H
| C9C90#T9 LU/[,$ME# ' ]7t$0)>QSSK0 |9;#T|nK'NQbC9;#$#DR | C9C9)&'F#QF$'Ni$'
x#Do+230G %(L'##$MF
ff
#

+ 5 4 0!G

6

+5

VWE#;#,;##Dp+2 G %PE9]

40

6

8

!r G>"
ff +2r G



# +fiG

3
"

Q#

:


<
<

ff
fi
* : ff


ff #

<5

+2G G

6

+2 G
r

VWE#4#TC' $H;9h$'N#,$!EN;#W'##$MF#T )&


5 6

3

8 fi fi 6
ff +.r G

8

:




"


#

3

< <

ff
fi
* :



U

+2 G

ff # +fiG

VWE#PQS077J4TX9;9F$'N#L )&L'N#$!F#T ;##D+. G $'D $

<

#

+2 6 G

x' $@$ME9F$S$ME#@>KE#0QSX)&M;#$#Di.)&'#Q 6S3 C9C9)&'NhKEnK0 |h>'R9y'N#$MF#T|)&'NQ X!FT9T9
C9'7_7$t C9C9)<'NFKEq1+.(E9h$$MFKE9 )&#N@? H0)&$ME#21H305 5 57 GU [K'N7;#'N|QSDNE7$ )&)&D# )&T9#D
$ME#c_7$0)C9)<$MF$'N'F VWE#c] )<_h$'N9F/T90)&] F$'NXQSDNE7$H$0QC#$W'N#c$'@9] $ME9F$x#K
n;9C9C90)'N;9#T|$7
' 3@
c1(7#T
n C9C9)&'FNQh$'Nn$' 1ff$ME#0
tF'p
;9C9C90)L'N;9#TULA9;#KEX )<DN;9QS07$, )&S#' $HK'N))&K$0UW.$,LT9j}tK0;#$L$'O$M #MEy%,E#$ME#0) K0
9bK'N#T90)&TRFL X;9C9C90){'N)x'F%0)L9'#;9#TXf'#),OD ] 0
#T tULIy.hK$,] 02'N
)
6 91


'N#LK0 yF$WQS' $xM ( 4 # 1 +.(E9h$$MFKE9 )&#NS?H0)&$ME#21/305 5 5 9G1 2'N)SD 0#0)>F ;
i(7$0)C9)&$ F"HK' , C9C9)<' #QF$'Nc$' F"x;9#K$'NS'h 5 4 ; f$ME#W C9C9)&'FNQh$'N#
)&@K' >0#'N;#DNEn$!E#0|$ME#@DN)>FT90 $
Ql;#>$tF'R%, C9C9)&'F#_QbF$T~7 %,E#KE


;#$QF$@0FT9H$'+&36 GU/[ >_Qd )x $>0)C9)&$MF$>'# C9C#,$>' ff ;


R



fi

[ C9C#K0F$'Ni'F,-ff!.* SQS$ME#'#Tp$' 7X$'#KE9F>$Kl>N$>0Q@12U Udf'N)L7 O1)&l'#X$ME#
L
] hT9$&~'FL$ME#y_7] 0)&$>_#$& hM;9QC#$'Nn%HE#KE T90C90#T9@'Nn$!E#K'N7] 0)&D 0#Ky'FL$ME#Vg#'N)
0)&9C9 #'Ni'F 4
ffU@X'N)&O_QbC9'N)&$! $>i$ME#)>FT9;#l'h,K'N7] 0)&D 0#K BpE9FS$'Mh$&f
BB3t+2-s!.*91g35 6 GUff.$,H$e O'#C90y;#>$'N@%,E#$!E#0)$ME#l)>FT9;#,'FffK'N7] 0)&D 0#K{f'#)$ME#
0#0)&D b;9#K$'N@T9K0)<_TX_|+Z#G"'#)"n+Z G MF$> 4,$ME#WK'##T9$>'#qU

ff



&'Rfiff

H

fi 4






{$ME#g>K$'NL%(7C9C#L$!E#"] 7)&'N;#e7C9C9)&'FNQF$>'#LKE#0QS/T9] 'NC9TSL$ME#C9)&]#'#;#gK$>'#
$'n$&%('nT9j0)&0 $yKF@'F#$k%'N)>* 01W97QS $!E#>D#QS' #$&%'N)*nT9a#T 7~$ME#XDNQd'
FK$]FF$'Ni;9#K$'N| 8"!+ :4N
G 6 #<;>=&# ?A@ 1"7#T|$ME##' 7J'N)#$&%'N)*XT9a#T p$!E#FK$] F$>'#
;9#K$'N B$+ :4
G 6z
3 3
01: r ;aIX$ME#lC9 C0)L%S%W()&$!)&K$P'N;9)&>]7L$'@$ME9)&T9j0)&07$
2
C
C
E
C9C9)&'F#QF$'N KE#0QdE90]##D|$ME#'##kK$>]7;9#K$'N# ff ## 0 ff #( 0 ff (0( ;2$O@_7$0)&>$#D~$'
K'NQC97)&L$ME#P C9C9)&'F#QF$'N#2'N)>D#QS' T4FgxuFxT90)&] TR+.A9 ;#$,F2U1 305 5 G G %W$MEO$!E#'
'N#$Mh_#TpE#0)& ULvxWC9 )&$K0;# )H $>0)&$L ff #( ;qVWE#+
4#TRC9'7_7$H;9F$>'##P)&M;#$#D@)&'NQ $ME#
'N#&K$] H;9#K$'N7)&


5 6







6&3Wr; 8 +



8 fi

3 8"+
G+&3 #



=

"



;
#

/+ 5 3

3 8 +
GGW+&3 R



GG "


8"+



G>G E








#




#

(


5

1


3 5

+<3

+2 5 G


G>"



3
+&3 R
(





5 G

+$G r G

Z 4 2$ME#0 6wr;q[LC9C9)&'FNQF$>'#@2'N)HDNQd' T4F"WPFLT90)<]7Tp~+2A9 ;#ff$PF2U1ff35 5G G
9E FW$!E#Hf' 'F%W#D4#TC' $H9;9F$'N


5 6


8 fi




"

=



;Q#

/+ 5 3 G






"



1




+$G930G

%,E#0)&PhDNF 6Br@19j 4/
2>8F<;#>$W_*h+$G r7G1 ,h>'T90C90#T907$L'N 5 1!>63 0/.0./.0 3 3 U
VxE#9C9)&>'# #@2'N) +.)&!f0)O$>'mA9 ;#L$XF2U1P35 5Gof'N)O9FK$@9C9)&'N#!G@'N'#*|] 0)&
T9j0)&0 $ )&'N"
Q ;9.$Qb0,$>gC' #P$!E9F$(#;9QS0)&K0F@$ME#tQ9H] 0)&bK'7 U"bFK$
$ME#cQS_7)&$ky@$M)>;#K$M;9)&L|+2 5 G #T|$+ G930G L%'N)&$MEO#' $#D41q #T9C90)<_Qd0 $Mhe)&!;#$>,ME#'F%
$ME9F$HF )F, C9C9)&'F#QF$'N'Fe
^D7'NW$!E#t#TXK' S)&M;#$0U2$HuC' #S$ME9F$$ME##

#T 8"+ GWC#0O$ME#cM QSP)&'7 U vL#PK0 @)&!20)$'X+2A9 ;#? '#)&T4 q130575 5 Gsf'#)(dT9>K0;#'Ny'N
$ME#LC9' 7$0U"2$xLQh$$0) 'F/.;#$M;9)<L$M;#T9O$' ]7$DNF$L$!E#P 9'F] P)&F$>'##ME#C#L_T9$MF2U

$ fi ff&%

;ypo sxq



(' x/

V 'R$>$$ME#7C9C9)&'FNQF$>'#|KE#0QSOT9] 'NC9T A#K$'N5
91(#;9QS0)&K0FH9C90)&QS07$@%0)&
K'N#T4;#K$TUffA9Qh9x$k%'N)>* q%0)&ffKE#' 0L>'W$ME9F$pK07P9 K'NQC9;#$TS L9FK$0#;9QS0)h$'NqU
F4'#)lh$ME#@9C90)<_Qd0 $b$ME##$&%'N)*o$'NC9'7'7D p%WF+
4#T~$>'
)i
)#G98 4DN;9)<3 UpVxE#
KE#' KP'Fg$!E#P#$k%'N)>*S09 #u;#H$'SK'NQC97)&L$ME#P)&M;#$x%W$MEO$ME#' L'hsA9 ;#q$,hfUZ+&305 5 G7GUgV '
K'NQC97)&$ME#tC0)I2'N)Q #Kb'FW'N;9)LQS$ME#'#T9P%W$MEi$ME#)PQd$ME#'NTn%)&0C90F$>TR$ME#bC0)&QS0 $
ML

fi

y)

@

{yy

+2#
)@ )+G G %W$MEO$>'NCOT9'F%,tC9)<'NC9FDNF$>'#'F"9!20U(VxE#PFK$] F$>'#
.;9#K$>'#@%WFKE#'70O$'tP'N#L'FffDNQS'7TX #T#' 7J'N)U

FffDN;9)&3 HVWE9)&H070)W

K'N#T4;#K$TO c$ME#0Q 2'N)/DNQd' Tdx0U30r0!r r rW#$&%'N)*7%0)&D 0#0)F$>Td7l)> #T9'NQSPKE#'#' #D
%DNE $L]FF;#P 3L3003 UHVWE#9' $>$'NQ _ 0)L;9#$1'N)x$ME#S]N#;9#$L'F0FKEX#$&%'N)*O%WF
#$M 7$F$Ti$'@=0)&'4UVW E#b*FE#'#'NT1 c1%WFLK'NQbC9;#$TR79FK$P0#;9QS0)F$>'#X'Fh $ME#
$Mh$,X$!E#dE#DNE#0){$&%('O 0)&0UPVxE#t C9C9)&'F#_QbF$P]FF;#'F+3@ %h,K'NQbC9;#$TR7 ff 8
5 4 SK'NQbC9;#$TR7>' ]N#DX$ME#N 4#TmC' $S9;9F$'N#c'N#$MF#Ti.)&'#Q +2 GUOVWE#D '#'#T4#P'F
C9C9)&'F#QF$'NOKE#0QSc%h($>$T7t$ME#{f'7'F%W#D@QS0FM;9)&


ff
6&3 ~
3 3

pHQC#0QS0 $>T C9C9)&'F#_QbF$'NbKE#0Qd

ff

+$G G

1 ff #( 1 ff (( U H] 7$HC9)&>'N#, )&H%'N)*FT
'N;#$O[uC9C0#T9,U F 'N)"SC9)&'NC0)K'NQC97)&'Nb%(LF')&!JQC#0QS07$T$!E#uA# OQS$ME#'#TU"VWE#
'#'NT4#>"'Fg C9C9)&'F#QF$'Nc2'N)/$ME#HA# SKE#0QdW(]FF;9F$T@ SM;9#>$$M;#$#D ff 17$+ G7 Gff
: :
19QS0 $>'##Tt@A#K$'N%9Uj9U3 12'N)ff!C9K 4KHf'#)QS;#_{+2A9 ;#q$(F2U1q30575 G GU/VWE#u)<M;#$

)&OC9)&C 07$TRi$ME#bf'N)>Q 'F,E#$' D#) QSc_ FffDN;9)&@ #T FffDN;9)& %
U ptF'p)&0C0F$Tn$ME#
9C90)&QS07$P%W$MEo%(DNE7$P #Tn#_hP$M7* #D@] h_;#S9$&%0yJk@ #TR1q$ME#)&M;#$l7)&FDNF
C9)&07$TOO$ME#2'N)Q'h E#$>' DN) Qd"%
FffDN;9)<, #%
FffDN;9)<u9UffVWE# a#T9#D , )<WM;9QQ7)&=T
@$ME#H2'N)Q 'FsQd0 #W$M 9;#F$>T@_yVg7#O3 U
F 'N)L!QF"%DNE7$ ff #( #Tn$ME#@A# p C9C9)&'NFKEiME#'F% K' @)&M;#$01s%,E#KEi%WFP9C9K$TU
;#$P$ME#SQC9)&'F] 0Qd0 $SFKE#] Tn X$ME# ff (( >KE#0QSbS)&0Q )>*0 # 1/$PDN] @QS0 o] F;#'F
r ; r7r 5O%,E#KEnK'NQC9 )&SM;9#>$M 7$Fn%hDNF#$S$ME#@QS0 n] h_;#@'hur; r937
3 5@)&0C'N)&$T|
ME#'NCi$dhfU UVWE#pM;#D7D $L$ME#@;#O'F,QSN$M;9)<tT9$M)<_9;#$>'##%,E#KE|)<;#)&S $!)&'NT4;#K$>'#
'FffN$!)]F )&F$'N9hg]F )& #08QS'N)<L$ME9 p3r rS#$M)S]F )&F$'N9F/] 7)& #l )&P#T9Ty2'N)H
K'NQC'N#07$uQS#$M;9)& UWVWE#L)&M;#$L@!;9#$M 7$F#K0)&0F>ly$ME#cK'NQC9;#$MF$>'#OK' $0UWvL$ME#
' $ME#0)E9 #T@$!E#LN$M)>LK'NQC9;#$!F$'N9FqK' $ 2'N) ff (( ' ]70) ff #( WQ7)&D 9F2U"VWE#,Q7*F$ME# ff ((
KE#0QSPK'#QC9;#$MF$'N9hF$>$M)FK$] H'F] 0) $ME#lQd#$M;9)&LT9$!)&9;#$'NqU
V 'S$M;#T9$!E#P)&'N9;#$M#>('hg$ME#HKE#0QdW$ME#H%(DNE7$WK0hx%(0)<,#K0)&0F>TUff[,x$ME#,%DNE7$
K0F%0)&O#K0)&0FT T9DN)FT4h$'Nn%WFl#' $>KT |FW$ME#bf'N;9)SQS$!E#'NT90U|VWE#@C9'7_7$$'p
#' $TbWF $ME#W$ME9)&LQS$ME#'#T9(7C9C90 ) $'PuQS'#)&,)&'N9;#>$"$ME9 d$ME#,A# C9C9)&'#FKEqUff;#$(;9#*F
$ME#MQh#%DNE $>gK0F> ff (( T9Tt#' $ffC90)I2'N)Q %f17$ff"HC9'#'N)ff C9C9)<' #QF$'Nuf'#) )&D7(%DNE7$0U
VWE#P$u)<M;#$, )&L'##$MF#T7 ff #( KE#0QS U
YP;9)<_#D@$!E#lK'#;9)&S'F(9C90)<_Qd0 $Mh$'NX$L%WFW2'N;9#TX$ME9F$1 f'N)x'NQdd#$&%'N)*7H%W$MEy_7)&D
%DNE $>01/$ME#
4#T|C9' 7$l9;9F$'N#bK'N ]70)&D Tp$'X i'N)&T90)P 4#TmC' $8"%,E#@' ]##Dp$ME#
4#TC9'7_7$W9;9F$'N# 5 4 ' KF$L9$&%0O$k%'S] K$'#)& 5 4 # #T 5 4 ( U"V 'S' ] L$ME#LC9)&'N#0Q %
##

1>

fi

6

ff

#0#

ff

(0(

ff

8

MQF%DNE7$ 3L3 03

Jkr9U rFNrh
r9U r93
r9U r r7 5
r9U r93

#(

,



6

8

)&D7P%DNE $> 3W0!

Jkr9U rF7Nr
r9U r7 93
Jkr9U rF#G
r9U r75 G


V/ #t3
@ X0 'F f'#)W) #T9'NQdyD 0#0)F$>TDNQS'7Tp#$&%'N)*70UP3r0Mr r7rl#$&%'N)*7W%0)&S) 7J
T9'NQdiK$Tm7XKE#'#' #DX$ME#%DNE7$L)&'NQz$!E#)7#D 3L3 003 UVWE#OC0)&QS0 $
%WFW)&0C0F$T7OKE#'#' #DO$ME#L%D#E $.)&'#Qc_7)&D 0)W)7#D 3W0!




4000

4500

3500

4000

3500
3000
3000
2500
2500
2000
2000
1500
1500
1000
1000

500

0
0.12

500

0.1

0.08

@

0.06

0.04

0.02

0

0.02

0.04

0.06

0.08

0

0

0.01

0.02

0.03

0.04

0.05

0.06

0.07

0.08

3 0

FffDN;9)&P HW$>' DN) Qd2'N) ff # #TA# PKE#0QS2'N) MQF9%DNE7$01F$M *7#DL] F;# _ L3 03 1 2'N)
DNQS' Tt#$&%'N)*70U/VWE#WC#'7$"'NS$!E#(!2$"ME#'F%~E#$'7DN) QS/2'N) 2'N)/$ME#W>KE#0QS ff ##
#T ff #( VxE#lT9T@#' $"E9] , 7P'F] 0)<_7C#( #T$!E#lK0 )<bME#'F%|$ME#WQC9)&'F] 0QS07$0U
ff ## 1qD ] S@QS0 y'F"JkrU rFNrb%,E# ff #( ] P@QS0 X'hr9U r30 9ULVWE#tC#' $c'Ny$ME#

;



)&DNE7$(!E#' %xW$ME#PE#$' D#) Qw2'N) $ME#lA#7tKE#0QS U"VxE#PQS0 @WD7]707r9Ujr930 9 U

F T4 C#$>Tp$ME#S2' ' %x_#Dy$M)h$D US[HP'#'NXFP$!E#' KF$'N#S%0)&T9$K$Ti%(b$'NC9CTp$ME#
4#TC9'7_7$H;9F$>'##014 #T)&>$M )&$T@$W%x$!ES#% C' $ 54 U"VWE#L#% C9'7_7$H%hWKE#'70@
0 )<KE##DF'N#D@$ME#c_#O9$&%0 5 4 # #T 5 4 ( 14%,E#KEXDN] P@QS#QS;9Qz] F;#'h ULvL#K$ME#
%WFT9'N#PK'# ] 0)<D 0#KL$'t O'#)&T90)L
3 4#TC' $W'#KK0;9))&TU
H;9QS0)&K0F/9C90)&QS07$H%(0)<lF'OK'N#T4;#K$Ty2'N)W#' 7J'N)H#$k%'N)>* 0U F4'N)$!E#l C9C9)&'F#QJ
$'NS>KE#0QS $'L%'N)*{%( $ ME#'N;#T@9, #H$'P C9C9)&'F#QF$ 'F] 0)ffL)7#D W'Fq] F;#0U"VxE#
QS' $>]FF$Ty$ME#LC0)&QS07$LT9K0)&9TR' %cU(x' 7J'N),#$&%'N)*701#%,E#' >P$'NC' ' O,D ] 0y
FffDN;9)&X3O%(0)<)7#T9'NQSpD 0#0)h$T~ iKE#'#' #DX%D#E $ #T|#Ft)> #T9'NQSi.)&'#Q rX #T
r9U 79
U F4'N)H0FKEX#$&%('#)*O
w%h,K'NQbC9;#$Tyf'N)Lhff$!E#d' $$'#Q 0)H$Mh$0UPvL;#$L'FWFff$ME#
$Mh$01F$&%'L$MF$ff%0)&xKE#' >0SM;#KE$ME9h$ff_
(QF#QS=T #TtQS#QS=T)<MC9K$] UVWE#
9'7$$'NQz 0)H%WFL#$M 7$F$Ti%W$MEX0FKEy'FW$ME#SKE#' >0X$&%('O$Mh$01 #TR7C9C9)&'FNQF$>'##P$'
$ME#@*FE#'N'#TB%0)&@$ME#0nK'NQbC9;#$TU|VWE#t9C90)&QS07$O%hd)<0C90F$Tn2'N)@3r 0Mr r7rOM;#KE #$&J
%'N)*70U [,DNh_
P;#TFLOQS0FM;9)&c'FffD 'N'#T4#L'F" C9C9)&'F#QF$'Nq
U FffD#;9)&9
GO #
ME#'F%
$ME#OK'N))&!C9'N#T9#DRE#$'7DN) QSU p@)&0C0F$T|$ME#OC0)&QS07$Sf'#)lT9j 0)<0 $%DNE7$) #D 1
r ;j 0Mr ;j6 U FffDN;9)&S6@ #Tp5OME#'F% $ME#O)&] 7$lE#$'7DN) QSUPVWE#E#$' DN)> QSL )&SM;9QQ7)&=T
] F;#H'F $M 9;#F$Ty_O$! #l9Uff$ME#,K0hL$, C9C907)&W$ME9F$ ff (( W#T9TobC9'#'N)
7QS07O
C9C9)&'F#QF$'NqU ff #( FQS' $,h%W#(D#0]7,$ME#S9$H)&M;#$HME#'F%W#D$ME9F$] 0f'N)x#' J'#)WFK!J






!

fi

y)

{yy

4500

4000

3500

3000

2500

2000

1500

1000

500

0
2

0

2

4

6

8

10

12

14

16
3

FffDN;9)&

x 10

@HW$>' DN) Q

F'
2'N) ff (( C9C#TO$'LDNQS' T@#$&%('#)*H%W$MESMQbF9%(DNE7$0UffVWE#HQS0
'N#$MF#T@Lr9U r r 759Ugx' $L$ME9h$ WK0FTp730r @$!E# 4DN;9)&




7000

7000

6000

6000

5000

5000

4000

4000

3000

3000

2000

2000

1000

1000

8000

7000

6000

5000

4000

3000

2000

0
0.8

0.6

0.4

@

0.2

0

0.2

0.4

0.6

0.8

1

1.2

0
0.5

1000

0

0.5

1

1.5

2

0

2.5

0

0.5

1

3 0
;

1.5

FffDN;9)&L HW$>' DN) Qdqf'#)$ME# ff # #TA# P>KE#0QS/2'N) )&D %(DNE7$01F$! * #DL]FF;#ff_ W
f'#)DNQS' TX#$k%'N)>* 0U VWE#lE#$'7DN) Q '#@$ME#c!2$HME#'F%W f'N) ff ## KE#0QSSE90]##D
SQS0 b'F Wr rF Nr1F'N#PF$$ME#LK07$0) x2'N) ff #( >KE#0QSPE9]##DtSQS0 O'Fer r 9371
#T@'N#PF$x$ME#P)&DNE7$WW2'N)A# OKE#0Qd 1aE9]#_#DOQS0 O'F"r r75 G 9U

3 ;

ff

#0#

ff

(0(

ff



;

#(

A9Qh %(DNE7$
r ;0!r;

K0h K0F
r9Ujr C r93
Jkr9UjrG93
r9Ujr 6
r9U r3 3
r9U N
r9U 7 r

_7)&D P%DNE7$
r ; 0Mr ; 6

K0F K0F
Jkr9U30C G
JkrU r 5
r9U r 7
r9U r930
r9U r 57r
r9U 93 3

V/ #l@X0 'F 2'N)W) #T9'#QS@D 0#0)F$TX#' 7J'N),#$&%'N)*70UH30r0!r r rS#$&%('#)* %0)&S) 7J
T9'NQdbK$T7SKE#'#' #Dc$ME#,%DNE7$/)&'NQ$!E#,) #D r;0!r; U F4'N)s0FKE#$&%('#)*
$ME#y]N#p$!F$%W$ME QF#Ql;9Q
#T QS#_QS;9Q %(0 )<@T907$ 4TUVWE#
]###'#T9L'F0FKEi#$k%'N)>*Oc$ME#0y#$M 7$F$Tp%x$!EX$ME#ST90 $ 4Tn$MF$>01 #T
$ME#HK'N))<MC9'N#T9#DS'
H C9C9)&'FNQh$Tt7] )<'#;#(>KE#0QSUeVxE#,9C90)&QS07$W%WF
)&0C0F$TX OKE#'#' #DO$ME#L%DNE $>.)<'NQ ST9j 0)<0 $,)> #D r ;j 0Mr ;j6






2

2.5

fi

5000

4500

4000

3500

3000

2500

2000

1500

1000

500

0
0.5

@

0

0.5

E#'F%W
f'#) ff
DNQS' T@%W$ME )&D L%DNE7$

FffDN;9)&P HVWE#E#$>' DN) Q



1

((

1.5

2

2.5

1HE9]N#D~|QS0 'F W
3 r; rFNGU VWE#p#$&%'N)*i

3500
4000

10000

3000

9000

3500

8000

2500

3000
7000

2500

2000

6000

2000

1500

5000

4000

1500

1000
3000

1000
2000

500
500

0

0

1

2

3

4

5

6

7

0

3

x 10

@

1000

0

0.05

0.1

0.15

0.2

0
5

0.25



0

5

10

15

20

25

30

35

FffDN;9)& G HW$>' DN) Qd2'N)b]N#|$MF$>%W$MEBQbFNQS;9Q ' c1xf'#)t#' 7J'N)y#$k%'N)>* O%W$ME
%D#E $b$M *7_#Dn] h_;#O r Mr UnVWE#E#$>' DN) Q 'N|$ME#y!f$OME#'F%W
f'#) ff ##
KE#0QS 1ffF$P$ME#OK07$0) ff #( >KE#0QS @ #Tn$ME9F$SF$P$ME#@)&DNE7$ ff (( UVxE#tKE#0QS ff ##
DN] LQS0 O'F"r9U r7r93 1 ff #( DN] ubQS0 @'her9U r 76l7#T ff (( DN] LQS07O'FsrU N

0 ;



6000

4000

9000

8000

3500

5000
7000
3000

4000

6000

2500

5000
3000

2000

4000
1500

2000

3000

1000

2000
1000

500

0
0.14

1000

0.12

FffDN;9)&

0.1

0.08

0.06

0.04

0
0.05

0.02

0

0.05

0.1

0.15

0.2

0.25

0

0.3

0

0.5

1

1.5

2

@HW$>' DN) QdOf'N)O]##|$MF$X%W$ME^QS#QS;9Q ' P1uf'N)y#' 7J'N)#$&%'N)*7@%Wff $ME
%D#E $b$M *7_#Dn] h_;#O rM0 r; UnVWE#E#$>' DN) Q 'N|$ME#y!f$OME#'F%W
f'#)
KE#0QS 1ffF$P$ME#OK07$0) ff >KE#0QS @ #Tn$ME9F$SF$P$ME#@)&DNE7$ ff UVxE#tKE#0QS ff
DN] LQS0 O'F/Jkr9U rKG93 1 ff DN] PQS0 O'her9U r9373u7#T ff DN] LQS07O'FsrU r


#(

((

#(

(0(

&%

##
##

2.5

3

3.5

fi

y)

3000

2500

{yy

3500

3500

3000

3000

2500

2500

2000

2000

1500

1500

1000

1000

500

500

2000

1500

1000

500

0
0.26

0.24

0.22

@

0.2

0.18

0.16

0.14

0.12

0.1

0.08

0

0

0.02

0.04

0.06

0.08

0.1

0.12



0.14

0.16

0
0.02

0.04

0.06

0.08

0.1

0.12

0.14

FffDN;9)&P6 HW$>' DN) Qd2'N)b]N#|$MF$>%W$MEBQbFNQS;9Q ' c1xf'#)t#' 7J'N)y#$k%'N)>* O%W$ME
%D#E $S$M7* #Dp]FF;#t r !r 6 UXVWE#E#$' DN)> Q 'Nn$ME#@!f$OME#'F%W
2'N) ff ##
ff
ff

KE#0QS 1ffF$P$ME#OK07$0) #( >KE#0QS@ #Tn$ME9F$SF$P$ME#@)&DNE7$ (( UVxE#tKE#0QS ff ##
DN] LQS0 O'F/Jkr9U39G 1 ff #( DN] PQS0 O'her9U r 7l7#T ff (0( DN] LQS07O'FsrU r 5

; 0 ;

2500



2500

4000

3500

2000

2000
3000

2500

1500

1500

2000

1000

1000

1500

1000

500

500
500

0
0.09

0.08

0.07

@

0.06

0.05

0.04

0.03

0.02

0.01

0

0.01

0
0.01

0

0.01

0.02

0.03

0.04



0.05

0
0.2

0

0.2

0.4

FffDN;9)&P5 HW$>' DN) QdOf'N)O]##|$MF$X%W$ME^QS#QS;9Q ' P1uf'N)y#' 7J'N)#$&%'N)*7@%W$ME
%D#E $S$M7* #Dp]FF;#t r !r 6 UXVWE#E#$' DN)> Q 'Nn$ME#@!f$OME#'F%W
2'N) ff ##
KE#0QS 1ffF$P$ME#OK07$0) ff #( >KE#0QS @ #Tn$ME9F$SF$P$ME#@)&DNE7$ ff (( UVxE#tKE#0QS ff ##
DN] LQS0 O'F/Jkr9U r7 591 ff #( DN] PQS0 O'her9U r93l7#T ff (0( DN] LQS07O'FsrU 930

; 0 ;





0.6

0.8

1

fi

-5

-9

-6
-10

-7
-11
-8
-12
-9

-13
-10

-11

-14
M=1,C=1

M=1,C=2

M=2,C=2

SJJ

M=1,C=1

M=1,C=2

M=2,C=1

@

FffDN;9)&30r WVWE#,C#' $"'#S$ME#W!2$"ME#'F%W"V/);#W' Dc*FE#'#'NTyT9]#T9T7S$ME#,#;9QS90)ff'h C9F$$>0)#
f'N) ff ## 1 ff #( 1 ff (0( #TA#7tKE#0QSL2$0) $M)F##D'NODNQd' T#$&%'N)*708#$ME#PC#' $

'N$!E#P)&DNE $ME#'F%W $ME#H$M);#L' DS_*hE#'#'NTXT9]#T9TX b$ME#PN;9QS0)"'heC9F$$0)>#"2'N)
#' J'#),#$&%'N)*7

$] h$'NS;9#K$'NO$($!E#u$0U/[,D#F$ME#'N;#T9LQS07$'N#T@$ME9F$sf'#)ff'NQdW'F$ME#L#$k%'N)>*
$ME# 4NT@C9'7_7$;9h$'N#K'N ]70)&D T$'S S'N)<T90)"4NT@C9'7_7$01#$ME#,E#0;9)<>$KLT9K0)&9TX9!2'N)&
%WFW;#T$>'' ] L$ME#LC9)&'N#0Q@U
vx$ME#H$ME9)&xKE#0Qd ff #( ($!E#,QS' $)&'N9;#$ #TtF'cNT9,)&0h'N9 #tFKK0;9)>F$,)&!;#$>0U
2$'N;#$MC0)If'#)QST'N#t7 ff (( _b$ME#HK0FW'hgDNQS' T@#$&%('#)* ff%x$!E'F%~%DNE7$0B
U *"QC#)&K0F
]#T90#KO$ME#;#,!;#D $L$!E9F$,$!E#lKE#' K'F(O>KE#0QSSP#' $L$!)FDNE7$&f'#)&%W )&T #TXT90C90#T9c'N
$ME#PFK$>]FF$'N.;9#K$'Ny #Th>'tC9 ) Qd$0) ] F;#0U
V 'X$M;#T9p$!E#t0 )##DnK0 C9 #$t'FH$ME#@] )<'#;#l>KE#0QSOC9)&'NC9'7T|%t$'#'N*X;9C|y$'F
C9)&'N#0Q !;#D $Tn Rx $>'Np$F2U +<305 5 GH7] ' ]#_#Dn#_97)&RQhD 0UXVWE#@#_97)&RQhD
)&@'hu=X
)np %,E#KE 0FKE|QFD @K'##$O'Fu$ME#0)b] 0)&$>K0h,'N)bE#'N)&='N7$MFW9 )&O%W$ME
9;9FeC9)<'N9 #$& 1 %W$MEy0FKEy'#K0F$'NX'F"$!E#d97)W'#KK0;9C#TR%W$MEyC9)&'N9 #$&'hr; ;pS$'#'N*
X
3 )o6 )R3 G@#$k%'N)>*@ #TX$M)&Tp$'O0 )X$P;##D' $MEy$ME#SDNQS'7Tn #Tp#' J'#)LFK$] F$>'#
;9#K$'N#0UH;9Ql0)L'FWC9F$$0)>#P;#Tp%WFP r r7r914%HE#O$ME#t#;9QS90)H'F0C9'#KE#c%hP r r9USVWE#
9C90)&QS07$S%hP)&0C90F$>Tp2'N)S30rT9 0)&07$l#$&%'N)*70U F 'N)L0FKEp#$&%'N)*$M);#*FE#'N'#T~%WF
K'NQC9;#$>Td7P9FK$/0N;9Qd0)F$'NqUffVWE#WA# SQS$ME#'#Tl#T9Tt'F%0)*FE#'N'#T9_bFQS' $ffF9$ME#
K0FU"2$$ME#;#, C9C0 )&$ME9F$$ME#L$ME9)<PC9)&'NC9'7T@KE#0QS,E9] Ll$$0)0 )>#_#D@C90)kf'N)>Q #K
$ME9 O$!E#PA# 7C9C9)&'NFKEqU"VWE#P)&!;#$>u )<LM;9QQ )<=Ty 4DN;9)&3r9U
g G9fiAGF
$ME#,>K$'N@%LM;9QQb )&=L$ME#PK'# $M)<_9;#$>'##,'Fff$ME#LC9 C90)1 #TT907$jf@M;#x2'N) ;#$M;9)&
)&07)&KEqUXVWE#@QFnK'N7$M)&9;#$'N#S'F,$!E#C9 C0) )&@C9)&07$Tn|A#K$'N79UXnA#K$'N7
-ff!*0 tQS$ME#'#TR7$M)&'#T4;#KT1()<!JT90)&] T|)&'NQ n] )<_h$'N9FWC90)&!C9K$] X #Tm7C9C#T $'
WU~-ff!*0 @ C9C9)&'#FKEnD7]7tX#$0Qh$K@%p'h{9;#T9#D | )>#$!) )&|K' 7C9C9)&'FNjJ
QF$>'#n$.
' 3@
; W'F%] 0)c$tME#'#;#TB#' $T $ME9F$$!E#@! '#)&$t#T9T $'p]FF;9F$E#DNE#0)
'N)&T90) $0)>QS_#K0)<0FH%W$MEO$ME#H'N)&T90) #TQSDNE7$,9L]70OC'N#0 $>_hqf'#)(7t )>#$!) )&tK' >
C9C9)&'F#QF$'NqU


Q



fi

y)

{yy

V E#@] )&F$>'#9FWT90)&] h$'N|$! #!E#t$ME9h$tA# R C9C9)<'NFKEn@yMC9KFHK0F@'h{-s!*0
x
C9C9)&'#FKEq1 $ME#;#t>0)&]N#D|FtX9*|%x$!E|$ME#yN$#D|$ME#'#)& U VxE#OT90)&] h$'N C9)&'NK>tT9'#
#' $PQ7*Fl 7F!;9QC#$'N#l)<DN )&T9#DO$ME#S$M);#K$M;9)<l'h(0#0)&D .;9#K$>'#7#ToE#0#Kb$cPF'
C9C#K0 #$'WU(VWE#L]FFT9$&y'Fs-s!.* LQS$ME#'#T@HM;9#&K$W$'b$ME#PK'N#T9$'Nq1 $ME9F$W)hT9_;#
'FgK'# ] 0)<D 0#KPME#'#;#TPDN)<0F$0) $ME9 X3 8#PA#K$>'# 9Uff2$xH$g O'#C90O9;#$'N@%HE#$ME#0)
'N#LK0 yC9)&'F] H$ME9F$WM;#KEOK'N#T9$'NXE#' T9xf'N) $ME#SB0#0)&D7;9#K$'NqU
[LC9C#K0F$'Nn'Fu-s!.* S$ME#'N)&X$'XWSt#' $c$M)FDNE7$&2'N)&%W )&T1q$)&9;#)&K'NQC9;#$!F$'N
'Fff'NQSS] 0)FD %,E#KEX )&P#' $W$!)FK$M # U pPC9)<0 $>TodKE#0QdPy%,E#KE$ME#l^0#0)&D
;9#K$'NyP7C9C9)&'FNQF$>To7OVg#'#)W0)<1q%,E#KEXD7]7ub$M)FK$! #d7C9C9)&'FNQF$>'#@$'O$ME#
$0)Qd)&;#)&T 2'N)@-ff!*0 XQS$ME#'#TU " )&'N;#X C9C9)&'FNQh$'N KE#0QS@T90C90#T9#DB'# $ME#
T9DN)&X'FP$!E#V/0#'N)b0)&@C97#'N )&T90)<]7TU H#*Fp$ME#X C9C9)&'NFKE|+2A9 ;#H$@F2U1
305 K5 G G1$!E#tKE#0QSST9K0;#T~E#0)< )<tQC#0)hP$ME#pT9'p#' $c $M)<'NT4;#K@#$M)] )&F$>'#9F
] 7)& #08 K'NQbC9 )&"9;9F$'N#+2 5 G7#T$+ G93GUq[u#'7$ME#0)C9'7$] WFMC9K$/'F9$ME# C9C9)&'FNQh$'N#
$ME9F$"$!E#t )&HD 0#0)Fq #T@#' $(FK$>]#$&S.;9#K$>'#OT90C90#T907$084E#0#KL$ME#t7)&, C9C#K0 #P$'S
9)&'NhTKFH'F"(x0UWvx"K'N;9)<L2'N)HSD ] 0hK$] F$'N;9#K$'Ny$uQSDNE7$L9lC' #$'bK'NQS
;9Cb%W$MES$MF'N)IJkQbFT9u7C9C9)&'FNQF$>'##"%,E#KE@ )&,$$0)ff$!E9 S$ME#HKE#0QS"T9K0;#>TE#0)& U";#$
0QC#)&K0FH] F;9F$>'#|'NnMQbFWK0F#$&%'N)*7l!E#' % $ME9h$$ME#@9;9F$&n'FP C9C9)&'FNQh$'N#S
9$>$0)$ME9 O$!E#' L'N#$Mh_#T.)<'NQ ' $ME#0) ]F )&F$'N9F/QS$ME#'#T90U
VxE#ffK'NQC9;#$MF$>'#9F QC#K$k 19)&'#9;#$M#ff #TLD 0#0)h$&lQb *Fff$ME# KE#0QSg]70)&uh$$M)FK!J
$] U H72'N)&$M;99F$>b$ME#'N)&$K0FqDN;97) 7$W)&DN )&T9#DS$ME#L]FFT9$&@'FeV/N'N) 0)<xC9 #>'#
fiX )&,Qd>#D4U(VxE# 7#' $ME#0)ff'#C90b>M;#,%HE#KEO#T9($>'l9LFT9T4)&>Ttb$ME#,#0 )e.;#$!;9)& U
2$L%'N;#TR $>0)&$#D$>'@E#' %$!E#KE#0QSPC90)kf'N)>Qz'Np)&0F/%'N)&TpT4F$!F$0
U p )&
C9)&07$9C#'N)&#DS$ME#, C9C#K0 #$&t'F$ME#>,QS$ME#'#T9"'Nd$ME#,E9 #T#J%,)<$>$0T9D $T4F$!Jk9F U

















p@ )&bN$M)<0QSpDN)F$>!.;#ff$'y$ME#O] )&'N;# #'# 9QS'N;#S)&!f0)<01/%,E#' 9C9;#$b%(07$l'N#D
%WlOQC9)&'F]##D$ME#PC9 C0)UBp
L )&LF'S$ME9 9*h.;#q$'SYP)cUN UL7C9C90O2'N) E#xM;#D $>'##0U

F M!
ff >! #%'
d$ME#"K$'Nd%(WC9)&>0 $ff9C9)& 8 'N#sf'#)/$ME#ffLa )&$ff'#)&T90)ff C9C9)&'F#_QbF$'N?P
QS$M E#'#T7$M)&'#T4;#KT
~A#K$'N59 U V'nK'NQC9;#$ 6 1 $ME#] 0)FD #DR

$
7

F
*
0

|

F
'

]
0

c
)

$
#
E


.
=
5 H +<3 3 5 G H 1 %T9a #,L) #T9'#Q^] )& #fiff 6 %,E#0)& 6 FKO$>'N)&FT9 +$M, )& 93 ;#$5 'NG U
&

&E
E
C
x' %

= H
98
6ff 6 C 5 +&3 3 5 G E H
+$G G
H 8 &
8


< 6ff 7
6 6
+$GFNG


#



g

G



Q

r







c



e

#

#

#

#

#

6ff

98

< *

#




&
#

0
E
6 / C E + 5 " C E +&33 5 G 1
& #
8
6 6 r




+$G G
+$GG G

fi

6




8
(

6 E


#

&

3 5 G



#

+$G G

5 +&3
(

YLj0)&0 $>_h$'N@'F ff n+ZN G #T@$M7* #Dt] 0)hD ,%x$!E@$ME#HFK$'N)<_haT9$!)&9;#$'NyNT9

<

ff
fi
*


%,E#0)&





+5

<







0 GB6 5 <

=







0 1G 6

+ 54

#

e+


<



6 3



G"B+&33

5



G

<





<

8



+$G 6 G

3

g+<3




ff+

GG

+$G 5 G

VWE# a)&$L$>0)Q # $0)>QP))<]F 7$l90hK0 ;#'FP+$GG GUPX'#;9)H_QbC#0Qd0 $Mh$'N#
;#T19$H9C9)&'N

(

+5





0 BG 6 / 3



5

ff+



G

33
+&3 3#ff+

(

3



5



GG

VWE#;#,7o+$GKG G %(PE9]

ff
#

6


=


3


5 _

=

#






5

3 5





5 )ff+
#

=

3



#

+5


#







33 5
,1 q
+
33 ff+ G

3
G



+ r G
G

+930G


3 5

Gg+&3


3 5

G>"^+&3





$0)Q

(

6Br

"B+&3





/ ff+ 5

G( "

*





3

(

1A2+

ff
< fi
<









0 1G 6




G


3

G9+&3

8



e+

G


+ G

6

ff
FffN 8 T|C9'7_7$S;9h$'N# )&'N#$!F#Tm7pC9;#$$#D zr91g #T|F'X#' $#D$ME#@C9'7_7$S$ME9F$

6 Br9U

6


5 6

8 fi





33

e+



G
"
+
e
G

# $



=



;
#

ff+$

5 3



ff+$

3

G0+&3

ff+$


G



GG

2+$

G"



](



<

<5

=




#







8

0 1G 6


+ G

eff $ #%'
3



+5



)!MQ'
e
ff
fi

o$ME#PK$'Ny%tC9)&>0 $H2'N)QS;#Fcf'#) ff 1 f'N)( 6z3 0M0 630Mb$ME9F$L%WFL;#TX2'N)H$ME#
9C90)&QS07$HT9K0)&9TXA#K$'N4U



ff

##




6


=


#



+ 5

5










3 5

"B+<3





G9g+<3

3 5

G



GG

3



=





#



+ 5 ff+



G " +&3

3 5



G+&3 #
3 ff+



GG

+FNG

fi

y)

ff

6

#(

=







3

#




"





5



3
#

ff+



5



ff+

5



3 5

" +<3





8



=

+ 5




G

(

{yy



3 5 G>G3

+&3 3 5 G

G9+&3

3 +&33


ff+

3G 3 3 33e+ 5 G




5 +&33 5 G ;







G>G

+

=


#

6
G



f+



(



+ 5 )ff+



G



3 5

G>"^+&3

3

G9+&3

e+



GG

(

8
(

+ G

%,E#0)&6 ( 6 E # # (
.$,POQF$$>0)W'F"T 9$!Fg$'@C#;#D@X$ME#l7C9C9)&'NC9)&F$c;9#K$'N#H2'N),bMCK 4KO#$k%'N)>*41 _*h
$ME#LDNQd' T'N)W#'7> J'N)U(A##KS$W,$'#'K0;9QS90)<'NQSL%LT9'@#' $,C9)&07$W9C#K$X$ME#c$0)QS
)&9;#)&T@2'N) ff (( 1#f'#)"SD 0#0)>FFK$] F$>'#b.;9#K$'NqU #$0hT@%(LC9)&07$W$ME#H9C9)&'N#,;#>T
2'N)$ME#LDNQd' #T#' 7J'N).;9#K$>'##0U
F 'N)A#DNQS' T#$&%'N)*


ff

6

((

ff

=


E
3pr;

#(

3
6

ff

#(

+<33

5



#





F 'N)#' 7J'N)W#$&%'N)*
((



#




5

G

3pr;



=


fi

E

#


(

5 +&3






>
; #


<
+
3
G
0
+
5 5
5
& # Q
#

; ;>


+5
8 +
G "


; # Q
; #

E

"

ff




#

3

3

5

3 5G

3


8"+



3



+5





<+ 3
ff+

G0+ 5

3

3

8"+

+5


3 5
G


(

G



8"+

"

GG


5

3

3

3

3

5





3 5

+&3

G

G>G





5

+<3

3 5



3

G

G


+G G

C G

|3G9' Da+&3 "

# & #

>
; #
5 |3G0+ 5 ~30G

"
5 +&3 5 0G + ff

+
G
+ G
ff
& # #

;>
;>
5 |03 G"B+ 5 |30G' Da+&3 "

fi
+ff
+ G
ff+ G
; # Q
; #

E



8"+

ff+




GG"

3

3

C

G








5 +&33 5 G+ G

I@9' $!EO$ME#,9C9)&>'##d+KG G" #TR+ G $xKE#' >0O$'9P$ME#0)2/'N) 6a1#%,E#KE#] 0)xx'F%0)8
F'$!E#PFK$] F$>'#O;9#K$'Nq1919R+ G )ff+$:4GB63 3
;
C
E
C
VxE#L] K$'N) 5 4 WT9$0)QS#Tp7t'7]##D4#TC' $H9;9F$'N#W'N#$!F#T7t$>$#D
ff
< 6Br;
<5

VWE#LDN)>FT90 $L)&9;#)&T@2'N) 0 )##D@W] F;9F$>To7 ff F$W$ME#4#TC' $0U


:R



fi

! 4






[HK*7 1YU1x $'#q1g\U 1a?A#&#'F%WM*721gVLUff+&305 67 GUL[w07)##DFD 'N)<$!E9Qz2'N),' $=0Q 9iQJ
KE##0
U ff
fi ff 01 F13? aM3 G 5U
[HD ' $M1N U9|Ug+&305 57r GUgVxE#L$M);#K$M;9)<L'Fs9 H#$k%'N)>* 2'N)]#!;9Fg)&K' D##$>'#qU
fiff ff
fi
!"
fi #$&%'"
fi%%()* 01 +9U
)0)1HYU1(? ] T9R:7 )1,-/UP+&35 5 5 GU " )<_h$'N9FLK0;9QS;# $yC97#'N 2'N)7$M)FK$! #
T9>$M)&9;#$'N#0U-,.&/* %0 '1
fi #$ff%2'"2
fi%ff%3)* 54$7689;:N1=<?>719 #N 9U

E9F$$MhKE9 )<NN1 LU1N?^H0)&$ME#214AqU9AqUq+&305 5 57 GU 077J4T@$!E#'N)&S2'N)ff>$'NKE9F$>KHK'N9#K$'N#$
#$k%'N)>* 0UqV KEqU9)&0CqU#kIA#K!JkWA#[xJk5 5Jkr 91YL0C9 )&$MQS07$"'h 'NQC9;#$0)A#K0#Kl #Tb[u;#$'#QJ
$'Nq14#T9 y#$>$!;#$P'F"A#K0#K U

E9F$$MhKE9 )<NN1NLU1 ?H0)&$ME#21AqU4AqUg+&35 5 5 9GUff-s!*0 uQd0 7J4T$ME#'N)<)&'NQd] )&F$>'#9F
]N%,C' $0UA9;99QS$$Ty$' * *fi* Vg)> #0U#'N@x0;9)Fgx$&%('#)* U
E9F$$MhKE9 )<NN1{U14? H0)&$ME#21qAqUaAqUff+2 r r7r GU72'N)QF$>'#OD 'NQS$M)< #TC#!*0 LQS0 7J4T
$ME#'N)& U@, A0B:*6ADC0EF
ff:.AHGIJA 1KKe+ G13
7r a3
309U

ME#'NCq1 |U0{U1 : 0%H)&0#K 1 PU 10N7 *N*h' 91 VLU1F?| '#)&T4 q1F|U >U+<305 5 GU0[LC9C9)&'FNQh$#DPC9' $>0)&'N)
T9>$M)&9;#$'N#SR!P#$&%('#)* P;#>_#DpQS#$M;9)&0U@Ip '#)&T4 q1|U/U1/H0 )#01/|Uq4U1ff?
A#' _14AqUg+ *sT90U GL1 5M & ;6ON/P&%'" ';QR
fi&SBH9;668ffR6;
fiQ6T<?> U9pIVBC9)&0U
\L0Qb q19AqU19? \L0Qb q1#YU +<305 6FNGUA#$'NKE9F$>KP)<_hF$>'#q1 9#,T9$!)&9;#$'Nq1 #Ty$ME#P9
)&$'N)>F$'N@'h"_QbFD 0UR'VUUUXWP&L6;
fiffL6T&FB$
fi
fi"F2%(6;Y6T MZE[7:*2R'"2
fi%ff%3Y\
*2"J1 ]F"1 93 h43 U



Hf$1ff|U1ffW'FQ 9q1 HLU1? Vg)&!Cq1 lUW+&35 5 5 GUXX'#T9_#T90C0#T90 $Qd0 7J4T~$ME#'N)<RF
'#K0FgQd$ME#'NTf'#)W C9C9)&'F#_QbF$LC9)&'NC9FDNh$'NO'Fff_72'N)QbF$'NqU-N1
fi^_`CQ-aJ/
fi
fiffbff
N1/*9%68
fiQT6J1 <c> dP<"eh145 a30r U
x_7$'Nq1L\bU *xU1WYPN q1W-/U1Fa)& 1HHU1,? x0F211HLUP+&30575 GU^VWE#X%7*F0C^FD 'N)&$ME9Q
;9#M;9C90)&]#Tp#0;9)Fg#$&%'N)*70U@J 012f*]?g 13730 6a373MG93 U

2'N)

x'N)&]#$>= 1 *xU/4U1ffA9;#0)QS'N#T9$1"PU 4U1ff? '#'NC90)1e\bU(+&35 6 5 GU@ 'N;9#T9T|K'N#T9$'N##D @ Fff#_#
_720)&0#K2'N) T9K'N#W;9#T90)/K0 )&KW)&'#;9)&K0U9F@ ';92"Hh
fi2
fi5ffT
fi #@\
ff%'
fi%ff%(i2"?CB$9""M&&6_ 'I
ff:*# ';
ff:T"& ';92"UMX'N;97$MF H%c1N[N@0[H'7KF$'N
f'N) x[u>U
N 7*N*F'7_1gVLU1/?7'N)&T4 q1/|UUW+&30575 5 GU " )<_h$'N9F(C9)<'N9 #>$K7f0)<0#K #TR$!E#Qb)IJT9$
T4F$M 9F> U,L/"2%= '
fi #Hff%2'"
fi%%()*2"54H;6;"&P7:N1=<?> 147593 79U

0#0q1qLU1#H'N#D419[SU19? F0);#j"1 PU+&35 5 GU '#K*7#DtD 9#HM QC##D@]70)& )&D PC9)<'N9J
#$KL9C90)&$ #$0QS0U !
'"2
fi
fiff2%,L/"2% &'Ij1/QRFQ-aJ/
fi-J
fi/Mff;6U4A9C9KF
>M;#P'N
H0F p'N)<Ty[uC9C#K0F$'N#L'h ,#K0)<$MF H0h'N##D4U

'N)<T4 q1#mU#U1#\PE9 E9)> Q #21MffU17N *#*F' 91#AqUNVLU1#? A97;#f19:ffU+&35 5 GU [L7$M)&'#T4;#K$'N$>'P] 7)&jJ
F$'N9FgQd$ME#'NT9x2'N)WD#) C9E#K0FffQS'NT90UHy 'N)<T4 q14|U4>Ue+ *ffTU G1lkl ff!mGI9a2:*%
QDM%)6U
L

fi

y)

{yy

L C9C0q1gcUq4U1q? H'#T4)&DN;#= 1FWUqHU"+&305 5 67GUL"'7$>=0Q 9XQFKE##0 )##D;##DXQS0 4T
$ME#'N)&t7#T@#0 )H)&MC'N#LK'N)>)&K$'NqUff 'N)&T4 q1#|U9U19H0 )>#019|U#4U19?A#' 91aAqU#[SU
+ *ffT90UjGL1 M& 2"76 ON/9%'" '8QR
fiffOB$9;668ffR68
fiQT6T<?> UoIVBC9)&U
H0 )#1W|U1"? A9 ;#21L:ffUL+&305 5 67GUB: )&D7T9]#_h$'NBQS$ME#'#T9O2'N)t7C9C9)&'FNQF$>C9)&'N97#$K
_720)&0#KO%W$MEp)h$L'F(K'# ] 0)<D 0#K UtIhB$9"Mff&6T '
ff:*';/"
fi2
ff:m ';9 D&
2""
fiff
fiRff "
fi #$&% '
fi%ff%(i2"UF'#)&DN OL ;7Q 9qU

F0);#j"1 cUg+&30575 6 GUEHT4;#K$'NX'FffK'NQC9;#$Mh$'N9FK'NQbC##$&9 y#$&%('#)* >$ME9)&'N;#DNE
)&0QS'F] F9'h %0 *cT90C0#T90#K0U"
fi2
fi& MT
fi #$ff% '"
fi%%()*2"?CBHP"M&6
'T
ff:*SW
ff:S& ';92"U A9 @pF$' 1[ @#X'N)&DN7tL ;7Q 9qU
: ;9)<$>=0q1 AqU10?~A9C#D E9F$0)1 YU +&305 676 GUF:q'NK0h K'NQC9;#$Mh$'N#%W$MEcC9)&'N9 #$"'NHDN)> C9E#K0F
$M);#K$M;9)<l #Tp$!E#_)S C9C#K0F$'Nn$>'9C90)&$S#$0QSUS,L/"2%&'
ff:* 4H?%_
fi
fiY68
fiff"&%
J
fi1 ?> 130 F U
x0F21HLU+<305 5 GU '#9#K$'N#$g0 )>#_#DL'ha9! #$&%'N)*70U?
fi #Hff%'
fi%ff%(i2"1]F1 3a3 306U

J
fi
fiY68
fiff%%3MFW:*FUg[HT9T9'N7J p> 1HT9%('#'#TK$& 14[SU
-/0 )&21/4U+&305 6 67GU!B$9 V ;ff%( 6;
fiff 4H"?6;2&Sh'
fi%ff%(i2
68
fiQT6UX'N)<DN XL ;7Q 9q1ffA9
-ff )&214\bUg+&30576 6 GU

oh$'41N[lU

-/$0)&>'Nq19LU14?^[L#T90)&'Nq1 4U H{Ue+&35 6 GU [ QS0 4 TX$ME#'N)&O0 )##D@FD 'N)&$ME9Qw2'N)W#0;9)>F
#$k%'N)>* 0U-Q-aJ%(ff
R6;
fiQ61=<F145 5 30r9305U
-ff!*091/VLU"+&30576 GUL'N7] 0)&D70#KlK'##T9$>'#X'F($!E#l$! Cy;9F$>'#yf'#)W$ME#b_a#$!Jk)> #D Tn>_#D
F,QS'#T92H
U , AB:6A2DC0EF
ff:.AHGIJA =1 <fig!+ G G1305 93 a305 69U





H'#K*20)1H{U4VLUg+&35 GU-2 ff
&%36; 6+ a)&$xT9$>'#9GU"-")<_#K$>'N;9#] 0)&>$&C9)&>0U

A9 ;#21N:sU1 ? 'N)<T4 q1F|U U4+&30575G GU?*ff9C#'7$>_#DS$M)>FK$M #M;9#$M)>;#K$M;9)&"S7$M)FK$! ##$&%'N)*70U
nV'N;9)<$=0* 1sYUgAqU1/X' =0)1/|UgLU 1e?zHFQS'41/|U*xUW+*ffT90UjG1 5M ;6 ffhN1/*9%
'" ';QD&
fiOBHP"76"6;ffJ68
fiQ6Tg U9pVBC9)<0U
A9 ;#21W:ffU1 ? 'N)<T4 q1|Ue>Uu+<305 5 5 GUR[x$$M)FK$>'N)LT999 QSK@n2T#f'#)&%W )&T~#$&%'N)*70U
Q-aJ/
fi
fi&4U"IC9)&U

N1/*9%

A9 ;#21:ffU"SU1ff# *#*F' 91VLU1ff? '#)&T4 q1ff|UffU,+<305 5G GUX0 4T~$!E#'N)&X2'N)cDNQS' 9!
#$k%'N)>* 0U ,.&/* % '
fi #$ff%2'"2
fi%ff%3)* 54$7689;:N1L+91 G93 GU
A9E7%( 1F|U[lU 1 ? vH$!E#0)&,+&305 530GUN- )&'N9 #$KHT9_hDN#' ";##DlL)<!f'N)>Ql;#F$>'#P'h4$ME#_7$0)#$<J
3 F9Q)*N#'F%WT9D S9F UHEF
ff:.A0'" '8&"Q AlE[M*A10K> U

!>

fiJournal Artificial Intelligence Research 15 (2001) 189-206

Submitted 2/01; published 9/01

ATTac-2000: Adaptive Autonomous Bidding Agent
Peter Stone
Michael L. Littman

pstone@research.att.com
mlittman@research.att.com

AT&T Labs Research, 180 Park Avenue
Florham Park, NJ 07932 USA

Satinder Singh
Michael Kearns

satinder.baveja@syntekcapital.com
michael.kearns@syntekcapital.com

Syntek Capital, 423 West 55th Street
New York, NY 10019 USA

Abstract

First Trading Agent Competition (TAC) held June 22nd July 8th,
2000. TAC designed create benchmark problem complex domain emarketplaces motivate researchers apply unique approaches common task.
article describes ATTac-2000, first-place finisher TAC. ATTac-2000 uses principled bidding strategy includes several elements adaptivity . addition success
competition, isolated empirical results presented indicating robustness
effectiveness ATTac-2000's adaptive strategy.

1. Introduction
first Trading Agent Competition (TAC) held June 22nd July 8th, 2000, organized group researchers developers led Michael Wellman University
Michigan Peter Wurman North Carolina State University (Wellman, Wurman,
O'Malley, Bangera, Lin, Reeves, & Walsh, 2001). goals included providing benchmark problem complex rapidly advancing domain e-marketplaces (Eisenberg,
2000) motivating researchers apply unique approaches common task. key
feature TAC required autonomous bidding agents buy sell multiple
interacting goods auctions different types.
Another key feature TAC participating agents competed
preliminary round many practice games leading finals. Thus, developers
changed strategies response others' agents sort escalating arms race.
Leading competition day, wide variety scenarios possible. successful
agent needed able perform well possible circumstances.
article describes ATTac-2000, first-place finisher TAC. ATTac-2000 uses
principled bidding strategy, includes several elements adaptivity . addition
success competition, isolated empirical results presented indicating robustness
effectiveness ATTac-2000's adaptive strategy.
remainder article organized follows. Section 2 presents details
TAC domain. Section 3 introduces ATTac-2000, including mechanisms behind
adaptivity. Section 4 describes competition results results controlled
experiments testing ATTac-2000's adaptive components. Section 5 compares ATTac-2000
c 2001


AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiStone, Littman, Singh, & Kearns

TAC participants. Section 6 presents possible directions future
research concludes.

2. TAC

TAC game instance pits 8 autonomous bidding agents one another. TAC
agent simulated travel agent 8 clients, would like travel TACtown Boston back common 5-day period. client characterized
random set preferences possible arrival departure dates; hotel rooms
(The Grand Hotel Le Fleabag Inn); entertainment tickets (symphony, theater,
baseball). obtain utility client, agent must construct travel package
client purchasing airline tickets TACtown securing hotel reservations;
possible obtain additional utility providing entertainment tickets well. TAC
agent's score game instance difference sum clients' utilities
packages receive agent's total expenditure.
TAC agents buy ights, hotel rooms entertainment tickets different types
auctions. TAC server, running University Michigan, maintains markets
sends price quotes agents. agents connect Internet send bids
server update markets accordingly execute transactions.
game instance lasts 15 minutes includes total 28 auctions 3 different
types.

Flights (8 auctions): separate auction type airline ticket: ights
Boston (in ights) days 1{4 ights Boston (out ights) days 2{5.
unlimited supply airline tickets, ask price periodically increases
decreases randomly $0 $10. cases, tickets priced $150
$600. server receives bid ask price, transaction
cleared immediately ask price. resale airline tickets allowed.

Hotel Rooms (8): two different types hotel rooms|the Boston Grand Hotel

(BGH) Le Fleabag Inn (LFI)|each 16 rooms available days 1{4.
rooms sold 16th-price ascending (English) auction, meaning
8 types hotel rooms, 16 highest bidders get rooms 16th highest
price. example, 15 bids BGH day 2 $300, 2 bids $150,
number lower bids, rooms sold $150 15 high bidders plus one
$150 bidders (earliest received bid). ask price current 16th-highest
bid. Thus, agents knowledge of, example, current highest bid. New
bids must higher current ask price. bid withdrawal resale
allowed. Transactions clear auction closes. prevent agents
waiting end game bid hotel rooms, hotel auctions close
unspecified period (roughly one minute) inactivity (no new bids received).

Entertainment Tickets (12): Baseball, symphony, theater tickets sold
days 1{4 continuous double auctions. Here, agents buy sell tickets,
transactions clearing immediately one agent places buy bid price least
high another agent's sell price. Unlike auction types
190

fiATTac-2000: Adaptive Autonomous Bidding Agent

goods sold centralized stock, agent starts random endowment
entertainment tickets. prices sent agents bid-ask spreads, i.e.,
highest current bid price lowest current ask price (due immediate clears, ask
price always greater bid price). bid beats current bid (ask)
price arrives, sale price standing bid (ask) price, opposed arriving
ask (bid) price. case, bid withdrawal ticket resale permitted.
addition unpredictable market prices, sources variability game instance game instance client profiles assigned agents random initial
allotment entertainment tickets. TAC agent 8 clients randomly assigned
travel preferences. Clients parameters ideal arrival day, IAD (1{4); ideal departure day, IDD (2{5); grand hotel value, GHV ($50{$150); entertainment values, EV
($0{$200) type entertainment ticket.
utility obtained client determined travel package given
combination preferences. obtain non-zero utility, client must assigned
feasible travel package consisting arrival day AD corresponding ight,
departure day DD corresponding ight, hotel rooms type (BGH
LFI) day AD < DD. one entertainment ticket
assigned day AD < DD, client given one
entertainment ticket type. Given feasible package, client's utility defined
1000 , travelPenalty + hotelBonus + funBonus

travelPenalty = 100(jAD , IAD j + jDD , IDD j)
hotelBonus = GHV client GBH, 0 otherwise.
funBonus = sum relevant EV's entertainment ticket type assigned
client.
TAC agent's final score simply sum clients' utilities minus agent's
expenditures. Throughout game instance, must decide bids place
28 auctions. end game, must submit final allocation purchased
goods clients.
client preferences, allocations, resulting utilities one particular game
TAC finals (Game 3070 TAC server) shown Tables 1 2.
full details design mechanisms TAC server, see Wellman et al. (2001).

3.

ATTac-2000
ATTac-2000 finished first Trading Agent Competition using principled bidding
strategy, included several elements adaptivity . adaptivity gave ATTac-2000
exibility cope wide variety possible scenarios competition.
section, describe ATTac-2000's bidding strategy, method determining best
allocation goods clients, three forms adaptivity. ATTac-2000's high-level
strategy summarized Table 3.
191

fiStone, Littman, Singh, & Kearns

Client
1
2
3
4
5
6
7
8

IAD
Day 2
Day 1
Day 4
Day 1
Day 1
Day 2
Day 1
Day 1

IDD GHV BEV
Day 5 73 175
Day 3 125 113
Day 5 73 157
Day 2 102 50
Day 3 75
12
Day 4 86 197
Day 5 90
56
Day 3 50
79

SEV TEV
34
24
124 57
12 177
67
49
135 110
8
59
197 162
92 136

Table 1: ATTac-2000's client preferences game 3070. BEV, SEV, TEV EVs
baseball, symphony, theater respectively.

Client
1
2
3
4
5
6
7
8

AD
Day 2
Day 1
Day 3
Day 1
Day 1
Day 2
Day 1
Day 1

DD
Day 5
Day 2
Day 5
Day 2
Day 2
Day 3
Day 5
Day 2

Hotel Ent'ment Utility
LFI
B4
1175
BGH
B1
1138
LFI
T3, B4
1234
BGH
None
1102
BGH
S1
1110
BGH
B2
1183
LFI S2, B3, T4 1415
BGH
T1
1086

Table 2: ATTac-2000's client allocations utilities game 3070. Client 1's \B4"
\Ent'ment" indicates baseball day 4.

3.1 Bidding Strategy

TAC defined simple enough low barrier entry, yet complex
enough prevent tractable solution via direct game-theoretic analysis. Given
optimal solution attainable, use principled approach takes advantage
details TAC scenario. general, ATTac-2000 aims robust parameter
space defined TAC well conceivable opponent strategies.
every bidding opportunity, ATTac-2000 begins computing profitable
allocation goods clients (which shall denote G ), given goods currently
owned current prices hotels ights. (See Section 3.3 caveat.)
purposes computation, ATTac-2000 allocates, consider buying selling,
entertainment tickets. cases, G computed using integer linear programming,
described Section 3.2.
ATTac-2000's high-level bidding strategy based following two observations:
192

fiATTac-2000: Adaptive Autonomous Bidding Agent

1. auctions open:
Obtain updated market prices.
Compute G: profitable allocation goods given current holdings
prices.
Bid 1 2 different modes
Passive: bid keep options open
Active: end, bid aggressively packages
2. Allocate:
Compute G closed auctions allocate purchased goods clients.
Table 3: overview ATTac-2000's high-level strategy.
1. Since airline prices periodically increase decrease equal probability, expected change price airline auction $0. Indeed, shown
airline auction considered isolation, waiting end game
purchase tickets optimal strategy (except rare case price reaches
lowest allowed value).
2. Since hotel prices monotonically increasing, game proceeds, hotel prices
approach eventual closing prices.
Therefore, ATTac-2000 aims delay purchases, particularly airline
purchases, late game. ATTac-2000's high-level bidding strategy based
premise best delay \committing" current G long possible.
Although continually reevaluates G, therefore never technically committed
anything, markets rarely advantageous change client's travel
package would mean wasting airline ticket expensive hotel room (thus requiring
additional ones purchased).
ATTac-2000 accomplishes delay commitment bidding two different modes:
passive active. passive mode, lasts game, designed keep
many options open possible. passive mode, ATTac-2000 computes average
time takes compute place bids, Tb (Tb average time takes go
one iteration loop step 1 Table 3). found Tb ranged 10
seconds well minute, primarily dependent upon server's load. Call
time left game Tl . Tl 2 Tb , ATTac-2000 switches active mode,
buys airline tickets required current G places high bids
required hotel rooms. Note ATTac-2000 expects run 2 bidding iterations
active mode. fact, 1 iteration necessary, huge cost failing
complete iteration end game. Planning 2 active iterations leaves
room error.
Based current G , current mode, Tl, ATTac-2000 bids ights, hotel
rooms, entertainment tickets.
193

fiStone, Littman, Singh, & Kearns

3.1.1 Flights

passive mode, ATTac-2000 bid airline auctions. active mode,
ATTac-2000 buys currently unowned airline tickets needed current G.
cases, means bids airline tickets first bidding opportunity
active mode. However, face drastically changing (hotel entertainment
ticket) prices, G could change suciently necessitate purchasing additional ights, instead simply using ones already purchased.
3.1.2 Hotels

passive mode, ATTac-2000 bids hotel auctions either try win hotels
cheaply auction close early, try prevent hotel auctions closing
early. might advantageous prevent hotel auction closing rooms
currently desired order keep open option switching hotel future
market prices warrant it.
hotel room type (such \Grand Hotel, night 3"), let Hi number
rooms type needed G . Based current price i, Pi , ATTac-2000 tries
acquire n rooms

8
>>
< max(8Hi; 4)
n = > max(H ; 2)
>: max(Hi; 1)


Pi = 0 (only true outset game)
Pi 10
Pi 20
Pi 50:

ATTac-2000's outstanding bids would already win n rooms auction close
current price, ATTac-2000 nothing: auction close prematurely,
ATTac-2000 wins n rooms cheaply, competitors lose opportunity get
rooms type later game. Otherwise, ATTac-2000 bids n rooms $1
current ask price. formula computing n selected risk wasting
$40{$50 per room type benefit maintaining exibility later game.
exact parameters chosen ad-hoc fashion without detailed experimentation.
intuition ATTac-2000's performance sensitive exact values.
active mode, ATTac-2000 bids hotel rooms based marginal value within
allocation G . Let V (G ) value G (the income clients, minus cost
yet-to-be-acquired goods). Let G0c optimal allocation client c fail get
hotel rooms. Note G0c might differ G distribution entertainment
tickets well ights hotels client c. ATTac-2000 bids hotel rooms
assigned client c G price V (G ) , V (G0c ). Since point ights
sunk cost, price tends $1000.
Notice ATTac-2000 bids full marginal utility hotel room required
client's travel package. alternative would divide marginal utility
number rooms package, would eliminated risk spending
hotels itinerary worth. hand, failing win single hotel
room enough invalidate entire itinerary. ATTac-2000 bids full marginal utility
maximize chance valid itineraries obtained clients. combinatorial
194

fiATTac-2000: Adaptive Autonomous Bidding Agent

auction, bidder would able place bid conjunction desired rooms
would therefore need choose two alternatives.
3.1.3 Entertainment Tickets

ATTac-2000's bidding strategy entertainment tickets hypothesizes

ticket, opponent buy (sell) price remains constant course single game
(but may vary game game). avoid underbidding (overbidding)
price, ATTac-2000 gradually decreases (increases) bid course game.
initial bids always optimistic possible, end game, ATTac-2000
willing settle deals minimally profitable. addition, strategy serves
hedge ATTac-2000's early uncertainty final allocation goods clients.
every bidding iteration, ATTac-2000 places buy bid type entertainment
ticket, sell bid type entertainment ticket currently owns. cases,
prices depend amount time left game (Tl), becoming less aggressive
time goes (see Figure 1).
Buy value

200

}$50
Bid Price ($)

Owned, unallocated
sell value

}$20

100
Owned,allocated
sell value
$30

0

5

10

Game Time (min.)

15

Figure 1: ATTac-2000's bidding strategy entertainment tickets. black circles indicate calculated values tickets ATTac-2000. lines indicate bid
prices corresponding values. example, solid line (which increases
time) corresponds buy price relative buy value. Correspondence text lines indicated similar line types boxes
surrounding text.
owned entertainment ticket E , E assigned G, let V (E ) value
E client assigned G (\owned, allocated sell value" Figure 1).
ATTac-2000 offers sell E min(200; V (E ) + ) decreases linearly 100
20 based Tl.1 current bid price greater resulting sell price,
ATTac-2000 raises sell price 1 cent lower current bid price order get
high price possible.
E owned assigned G (because clients either unavailable night
already scheduled type entertainment G ), let V (E ) maximum value
1. Recall $200 maximum possible value E client TAC parameters.

195

fiStone, Littman, Singh, & Kearns

E clients, i.e. greatest possible value E given client profiles (\owned,
unallocated sell value" Figure 1). ATTac-2000 offers sell E max(50; V (E ) , )
increases linearly 0 50 based Tl . again, ATTac-2000 raises price
meet existing bid price greater target price. strategy ects
increasing likelihood game progresses G close final client
allocation, thus currently unused tickets needed end.
active mode, ATTac-2000 assumes G final offers sell unneeded tickets
$30 order obtain least value (represented discrete point
bottom right Figure 1). $30, ATTac-2000 would rather waste ticket
allow competitor make large profit.
Finally, ATTac-2000 bids buy type entertainment ticket E (including
also offering sell) based increased value would derived owning
E . Let G0E optimal allocation would result E owned (\buy value"
Figure 1). Note G 0E could different ight hotel assignments G
make effective use E . Then, ATTac-2000 offers buy E V (G0E ) , V (G) , ,
decreases linearly 100 20 based Tl.
parameters described section chosen arbitrarily without detailed
experimentation. intuition that, unless opponents know explicitly exploit
values, ATTac-2000's performance sensitive them.

3.2 Allocation Strategy
evident Section 3.1, ATTac-2000 relies heavily computing current
profitable allocation goods clients, G . Since G changes prices change, ATTac-2000
needs recompute every bidding opportunity. using integer linear programming
approach, ATTac-2000 able compute optimal final allocations every game instance
tournament finals|one 2 entrants so.2
TAC participants used form greedy strategy allocation (Greenwald
& Stone, 2001). computationally feasible quickly determine maximum utility
achievable client 1 given set purchased goods, move client 2 remaining
goods, etc. However, greedy strategy lead suboptimal solutions. example,
consider 2 clients B identical travel days IAD IDD well identical
entertainment values EV , A's GHV = $50 B 's GHV = $150. agent
exactly one type hotel room day, optimal assignment clearly
assign BGH client B . However, client A's utility optimized first,
assigned BGH, leaving B stay LFI. agent's resulting score would 100 less
could been.
improvement basic greedy strategy, implemented heuristic approach
implements greedy strategy 100 random client orderings chooses
profitable resulting allocation. Empirically, resulting allocation often optimal,
never far optimal. addition, always quick compute. set seven
games tournament, greedy allocator run approximately 600
times produced allocations averaged 99.5% optimal value.
2. computed Shou-de Lin TAC organizing team.

196

fiATTac-2000: Adaptive Autonomous Bidding Agent

competition drew near, however, became clear every point would count.
therefore implemented allocation strategy guaranteed find optimal
allocation goods.3 integer linear programming approach used ATTac-2000 works
defining set variables, constraints variables, objective function.
assignment variables represents allocation clients constraints
ensure allocation legal. objective function encodes fact seek
allocation maximum value (utility minus cost).
following notation needed describe integer linear program. formal notation included completeness; equivalent English description follows equation.
symbol c client (1 8). symbol f feasible travel package,
consists of: arrival day AD(f ) (1 4); departure day DD(f ) (2 5),
choice hotel H (f ) (BGH LFI). 20 travel packages. Symbol e
entertainment ticket, consists of: day event D(e) (1 4),
type event (e) (baseball b, symphony s, theater t). 12 different
entertainment tickets. Symbol r resource (AD, DD, BGH, LFI).
Using notation, 272 variables are: P (c; f ), indicates whether client c
allocated feasible travel package f (160 variables); E (c; e), indicates whether client
c allocated entertainment ticket e (96 variables); and, Br (d) number copies
resource r would like buy day (16 variables).
also several constants define problem: (d) number tickets
resource r currently owned day d, pr (d) current price resource r day d,
(c; f ) utility customer c travel package f , uE (c; e) utility customer
c entertainment ticket e.
Given notation, objective maximize utility minus cost

X
c;f

(c; f )P (c; f ) +

,
,

X
d2f2;3;4;5g

X
c;e

uE (c; e)E (c; e)

pDD (d)BDD(d)

X

d2f1;2;3;4g;r2fBGH;LFI;ADg

pr (d)Br (d)

subject following 188 constraints:
c, Pf P (c; f ) 1: client gets one travel package (8 constraints).
2 f1; 2; 3; 4g,

X X

c f jAD(f )=d

P (c; f ) oAD (d) + BAD (d);

2 f1; 2; 3; 4g h 2 fBGH; LFIg,

X

X

P (c; f ) oh (d) + Bh (d);
c f jH (f )=h & AD(f )d<DD(f )
3. general allocation problem NP-complete, equivalent set-packing problem (Garey &
Johnson, 1979). Exhaustive search computationally intractable even 8 clients.
197

fiStone, Littman, Singh, & Kearns

2 f2; 3; 4; 5g,

X X
c f jDD(f )=d

P (c; f ) oDD (d) + BDD (d) :

demand resources selected travel packages must exceed sum
owned bought resources (16 constraints).

e, Pc E (c; e) oE (e): total quantity entertainment ticket allocated
exceed owned (12 constraints).

c e, Pf jAD(f )D(e)<DD(f ) P (c; f ) E (c; e): entertainment ticket

used day arrival departure day selected travel
package (96 constraints).

c 2 f1; 2; 3; 4g, PejD(e)=d E (c; e) 1: client use one
entertainment ticket per day (32 constraints).

c 2 fb; s; tg, PejT (e)=y E (c; e) 1: client use type
entertainment ticket (24 constraints).

variables integers.
solution resulting integer linear program value-maximizing allocation
owned resources customers along list resources need purchased.
Using linear programming package \LPsolve", ATTac-2000 usually able find
globally optimal solution one second 650 MHz Pentium II.
Note means possible formulation allocation.
Greenwald, Boyan, Kirby, Reiter (2001) studied variant found performed
extremely well collection large, random allocation problems.
approach guaranteed find optimal allocation, usually
quickly. However, since integer linear programming NP-complete problem, inputs
lead significantly longer solution times. sample 32 games taken shortly
finals, allocator called 1866 times. 93% cases, optimization took
second less. Less 1% took 6 seconds. However, 3 longest running times
minute came game. ATTac-2000 used strategy
integer linear program takes 6 seconds solve, above-mentioned
greedy strategy random client orderings used fall-back strategy rest
game. fall-back strategy needed tournament finals.

3.3 Adaptivity

TAC game instance, information available agents ask prices|
individual bids visible. game, transaction-by-transaction data available,
lack within-game information precluded competitors using detailed models
opponent strategies decision making. ATTac-2000 instead adapts behavior on-line
three different ways: adaptable timing bidding modes; adaptable allocation strategy;
adaptable hotel bidding.
198

fiATTac-2000: Adaptive Autonomous Bidding Agent

3.3.1 Timing Bidding Modes

ATTac-2000 decides switch passive active bidding mode based

observed server latency Tb current game instance (see Section 3.1).
3.3.2 Allocation

ATTac-2000 adapts allocation strategy based amount time takes

integer linear programming approach determine optimal allocations current game
instance (see Section 3.2).
3.3.3 Hotel Bidding

Perhaps significantly, ATTac-2000 predicts closing prices hotel auctions based
closing prices previous games. Hotel bidding TAC particularly challenging
due extreme volatility prices near end game. stated Section 3.1.2,
end game ATTac-2000 bids marginal utility desired hotel room,
often excess $1000.
preliminary competition, agents bid marginal utilities hotel
rooms. did, however, generally dominated competitors; agents
high-bidders, bidding $1000, always winning hotels bid, paying far
less bids. observed dominant strategy preliminary rounds,
agents, including ATTac-2000, adopted high-bidding strategy actual
competition. result many negative scores, prices skyrocketed last moments
game 16 high bids given room.
Section 3.1, stated ATTac-2000 computes G based current prices
hotel rooms. prices eventually become high, ATTac-2000 would either
end paying high price hotel rooms else fail get travel packages
clients. alternative avoid counting obtaining contentious
hotel rooms.
Since strategies changing last minute finals, way
identify priori hotels would contentious whether hotel prices would
actually skyrocket tournament. Therefore, ATTac-2000 divided 8 hotel rooms
4 equivalence classes, exploiting symmetries game (hotel rooms days 1
4 equally demand rooms days 2 3), assigned priors
expected closing prices rooms, adjusted priors based observed
closing prices tournament.
expected, Grand Hotel days 2 3 turned contentious
finals. Le Fleabag Inn days also fairly contentious. Whenever
actual price hotel less predicted closing price, ATTac-2000 used
predicted hotel closing price computing allocation values.
One additional method predicting whether hotel prices would skyrocket given
game notice participants whether tended highbidders past games (see Figure 2). Although information available via
server's API, game's participants always published beforehand TAC web page.
automatically downloading information web (a practice whose ethicality
questioned competition), matching precompiled database
199

fiStone, Littman, Singh, & Kearns

agents high-bidders past, ATTac-2000 would use predicted hotel closing
prices games 3 high-bidders involved: games fewer high-bidders,
prices hotel rooms almost never skyrocketed4 . turned out, one ATTac2000's games semi-finals, games finals, involved several high-bidders,
thus triggering use predicted hotel closing prices.
RiskPro grand day 2 recent

aster grand day 2

250

1400

Aster: Grand Day 2

1200

Bid Price ($)

200

Bid Price ($)

1200

RiskPro: Grand Day 2

200
150

100
100

1000

800
800

600

400
400

50
200

0
0

0

100

200

300

5

400

500

600

10

Game Time (min.)

700

800

0
0

900

15

0

100

200

5

300

400

500

10

600

Game Time (min.)

700

800

900

15

Figure 2: Graphs two different agents' bidding patterns many games. line
represents one game's worth bidding single auction. Left: RiskPro never
bids $250 games plotted. Right: Aster consistently bids $1000
rooms.
Empirical testing (Section 4) indicates strategy extremely beneficial situations hotel prices indeed escalate, lead significantly degraded
performance not.

4. Results

TAC consisted preliminary round ran course week involved
roughly 80 games 22 participants. top 12 finishers invited
semi-finals finals Boston, July 8th. Since agents conditions
constantly changing, since 13 games played agent semi-finals
finals, competition provide controlled testing environment.
section, describe ATTac-2000's success tournament, also present empirical
results controlled tests demonstrate effectiveness robustness ATTac-2000's
adaptive strategy.

4.1 Competition

ATTac-2000's scores 88 preliminary-round games ranged ,3000 4500
(mean 2700, std. dev. 1600). good score game instance 3000 4000 range.
noticed many bad scores (12 less 1000 seven less 0).
4. 2 high-bidders, way price escalate would bid combined
total 16 rooms hotel type. could happen clients stay
hotel night, unlikely scenario given TAC parameters.

200

fiATTac-2000: Adaptive Autonomous Bidding Agent

largely result ATTac-2000 yet imbued adaptive timing
bidding modes. preliminary round, ATTac-2000 shifted passive active
bidding mode 50 seconds left game instance. 50 seconds usually plenty
time allow least 2 iterations ATTac-2000's bidding loop,
occasions network server lags would take 50
seconds obtain updated market prices submit bids. case, ATTac-2000 would
either fail buy airline tickets, worse still, would buy airline tickets get
final hotel bids time. Noticing server lag tended consistent within
game instance (perhaps due trac patterns generated participating agents),
introduced adaptive timing bidding modes described Section 3.3.
change, ATTac-2000 always able complete least one, usually two, bidding
loops active bidding phase.
adaptive allocation strategy never came play finals, ATTac-2000
able optimally solve allocation problems came finals
quickly using integer linear programming method.
However, adaptive hotel bidding play big role. ATTac-2000 performed well
best teams early TAC games hotel prices (surprisingly) stayed low,
out-performed competitors final games tournament hotel
prices suddenly rose high levels. Indeed, last 2 games, popular hotels
closed $400. ATTac-2000 steered clear hotel rooms effectively
closest competitors.
Table 4 shows scores 8 TAC finalists (Wellman et al., 2001). ATTac-2000's
consistency (std. dev. 443 opposed 1600 preliminaries) apparent: avoided
disastrous games, presumably due large part adaptivity regarding timing
hotel bidding.
Rank
1
2
3
4
5
6
7
8

Team

Avg. Score Std. Dev.
ATTac-2000 3398
443
RoxyBot
3283
545
aster
3068
493
umbctac1 3051
1123
ALTA
2198
1328
rajatish 1873
1657
RiskPro
1570
1607
T1
1167
1593

Institution
AT&T Labs { Research
Brown University, NASA Ames Research
STAR Lab, InterTrust Technologies
University Maryland Baltimore County
Artificial Life, Inc.
University Tulsa
Royal Inst. Technology, Stockholm University
Swedish Inst. Computer Science, Industilogik

Table 4: scores 8 TAC finalists semi-finals finals (13 games).

4.2 Controlled Testing

order evaluate ATTac-2000's adaptive hotel bidding strategy controlled manner,
ran several game instances ATTac-2000 playing two variants itself:
201

fiStone, Littman, Singh, & Kearns

1. High-bidder always computed G based current hotel prices (as opposed
using priors averages past closing prices).
2. Low-bidder always computed G variant 1, also bid hotel rooms
$50 current ask price (as opposed marginal utility, tended
$1000).
extremes, ATTac-2000 7 high-bidders playing, least one hotel price
skyrockets every game since agents bid high hotel rooms.
hand, ATTac-2000 7 low-bidders playing, hotel prices never skyrocket since
agents ATTac-2000 bid close ask price. goal measure whether ATTac2000 could perform well extreme scenarios well various intermediate ones.
Table 5 summarizes results.
#high agent 2
7 (14)
,
6 (87)
,
5 (84)
,
4 (48)
,
3 (21)
,
2 (282)
,

agent 3 agent 4 agent 5 agent 6 agent 7 agent 8

9526 |||||||||||||,!
10679 ||||||||||,!
1389
10310 |||||||,!
, 2650
10005 ||||,!
,|||| 4015
5067 ,!
,||||||| 3639
209
,|||||||||| 2710

Table 5: difference ATTac-2000's score score
seven agents averaged games controlled experiment. differences
statistically significant 0:001 level, except one marked italics.
row corresponds different number high-bidders (excluding ATTac2000 itself). first column presents number high-bidders well
number experiments ran scenario (in parentheses). column
labeled \agent i" shows much better ATTac-2000 average agent i.
Scores stair-step line high-bidders (variant 1) scores
line low-bidders (variant 2). Results identical agents averaged
obtain single average score difference type agent row.
cases, ATTac-2000 beats agents.
row Table 5 corresponds different number high-bidders game;
example, row labeled 4 high-bidders corresponds ATTac-2000 playing
4 copies variant 1 3 copies variant 2. Results identical agents averaged
obtain single average score difference type agent row. first
column, also show parentheses number games played results
row|each row ects different number runs. cases, ran enough game instances
achieve statistically significant results. However, cases ran instances
turned required. column labeled agent shows difference
ATTac-2000's score score agent averaged games. scenarios,
202

fiATTac-2000: Adaptive Autonomous Bidding Agent

differences positive, showing ATTac-2000 outscored agents average.5
Statistical significance computed paired T-tests; results significant
0:001 level except one marked italics. mentioned before, number
high-bidders greater equal 3, expect price contentious hotels rise,
scenarios ATTac-2000 significantly outperforms agents.
large score differences appearing top rows Table 5 mainly due fact
agents get large, negative scores since end buying many expensive hotel
rooms.
experiments, ATTac-2000 always uses adaptive hotel price expectations, even
2 high-bidders. last row, number high-bidders 2,
little bidding hotel prices expected case, get statistical
significance relative two high-bidders (agent 2 agent 3), since strategies
nearly identical ATTac-2000's case. get high statistical significance relative
agents (copies variant 2), however. Thus, ATTac-2000's adaptivity
hotel prices seems help lot hotel prices skyrocket seem
prevent ATTac-2000 winning average don't.
results Table 5 provide strong evidence ATTac-2000's ability adapt robustly
varying number competing agents bid hotel prices near end game.
Note ATTac-2000 designed perform well itself. 8 copies ATTac2000 play repeatedly, favor hotel rooms thus
consistently get large negative scores. would interesting determine whether
exists strategy harmful ATTac beneficial adversary.

5. Related Work
Although good deal research auction theory, especially perspective auction mechanisms (Klemperer, 1999), studies autonomous bidding agents
interactions relatively recent. TAC one example. FM97.6 another auction test-bed, based fishmarket auctions (Rodriguez-Aguilar, Martin,
Noriega, Garcia, & Sierra, 2001). Automatic bidding agents also created
domain (Gimenez-Funes, Godo, Rodriguez-Aguiolar, & Garcia-Calves, 1998).
number studies agents bidding single good multiple auctions (Ito,
Fukuta, Shintani, & Sycara, 2000; Anthony, Hall, Dang, & Jennings, ; Preist, Bartolini, &
Phillips, 2001). Outside of, related to, auction scenario, automatic shopping
pricing agents internet commerce studied within simplified model (Greenwald & Kephart, 1999).
Twenty-two agents 6 countries entered TAC, 12 qualified compete
semi-finals finals Boston. designs agents motivated
wide variety research interests including machine learning, artificial life, experimental
economics, real-time systems, choice theory (Greenwald & Stone, 2001).
approach motivated research interests multiagent learning (Littman,
1994; Stone, 2000; Singh, Kearns, & Mansour, 2000). Based problem description,
expected find several learning opportunities domain. noted above, detailed
5. general, ATTac-2000's average score decreased increasing numbers high-bidders, games
became volatile.

203

fiStone, Littman, Singh, & Kearns

opponent modeling precluded system dynamics. Nonetheless, ATTac-2000's
adaptivity one keys success, particularly avoiding skyrocketing hotels.
2nd 3rd place agents used different strategy prepare possibility
skyrocketing hotels. Rather avoiding popular hotels entirely tracking closing
prices across game instances, discouraged agents bidding many
particular hotel room, thus spreading demand across rooms (Greenwald &
Stone, 2001). strategy safer limit (i.e., continues work even
everyone uses it), greater potential cost agent event hotel prices
skyrocket, since agent still distribute demand less desirable rooms.
hand, ATTac-2000 would notice prices skyrocketing thus
bid optimal travel packages given current prices.

6. Conclusion Future Work

TAC-2000 first autonomous bidding agent competition. successful event, minor improvements would increase interest multiagent learning
perspective.

Currently, incentive buy airline tickets end game.

price ights tend increase, supply limited, agents would
balance advantage keeping options open savings committing
travel packages earlier6 .

information structure TAC setup impossible observe

bidding patterns individual agents games. Nonetheless, strategic
behavior individual agents often profoundly affected market dynamics|particularly
hotel auctions. seems would beneficial able directly observe
behavior individual agent. information available regarding
bidding behavior agents game (such agents could infer
clients' preferences, therefore market supply, demand, prices), TAC agents
would potentially able learn predict market behavior game proceeds.

without modifications, hope able participate future TACs,
goal adding additional adaptive elements ATTac-2000.
Another direction future research apply lessons learned TAC real
simultaneous interacting auctions. straightforward write bidding agents participate on-line auctions single good value client fixed ahead time:
agent bid slightly ask price auction closes price exceeds
value. However, values multiple goods interact, case TAC,
agent deployment nearly straightforward.
One real application Federal Communications Commission's auctioning
radio spectrum (Weber, 1997; Cramton, 1997). Especially companies trying
achieve national coverage, values different licenses interact complex ways.
Perhaps autonomous bidding agents able affect bidding strategies future
6. change adopted specification TAC-01.

204

fiATTac-2000: Adaptive Autonomous Bidding Agent

auctions. Indeed, related research begun path creating straightforward bidding agents realistic FCC Auction Simulator (Csirik, Littman, Singh, &
Stone, 2001).
obvious application, extended version ATTac-2000 could potentially
become useful real travel agents, end users wish create travel
packages.

Acknowledgements
would like thank TAC team University Michigan, including Michael Wellman, Peter Wurman, Kevin O'Malley, Daniel Reeves, William Walsh, constructing
TAC server responding promptly cordially many requests conducting research reported here. would also thank anonymous reviewers
helpful comments suggestions.

References

Anthony, P., Hall, W., Dang, V. D., & Jennings, N. R. Autonomous agents participating
multiple on-line auctions..
Cramton, P. C. (1997). FCC spectrum auctions: early assessment. Journal
Economics Management Strategy, 6 (3), 431{495.
Csirik, J. A., Littman, M. L., Singh, S., & Stone, P. (2001). FAucS: FCC spectrum auction simulator autonomous bidding agents. Proceedings Second International Workshop Electronic Commerce. appear. Available
http://www.research.att.com/~pstone/papers.html.
Eisenberg, A. (2000). online auctions future, it'll bot vs. bot vs. bot. New
York Times. August 17th.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide
Theory NP-completeness. Freeman, San Francisco, CA.
Gimenez-Funes, E., Godo, L., Rodriguez-Aguiolar, J. A., & Garcia-Calves, P. (1998). Designing bidding strategies trading agents electronic auctions. Proceedings
Third International Conference Multi-Agent Systems, pp. 136{143.
Greenwald, A., Boyan, J., Kirby, R. M., & Reiter, J. (2001). Bidding algorithms simultaneous auctions. Proceedings Third ACM Conference E-Commerce, p.
appear.
Greenwald, A., & Kephart, J. O. (1999). Shopbots pricebots. Proceedings
Sixteenth International Joint Conference Artificial Intelligence, pp. 506{511.
Greenwald, A., & Stone, P. (2001). Autonomous bidding agents trading agent competition. IEEE Internet Computing, 5 (2), 52{60.
205

fiStone, Littman, Singh, & Kearns

Ito, T., Fukuta, N., Shintani, T., & Sycara, K. (2000). Biddingbot: multiagent support
system cooperative bidding multiple auctions. Proceedings Fourth
International Conference MultiAgent Systems, pp. 399{400.
Klemperer, P. (1999). Auction theory: guide literature. Journal Economic
Surveys, 13 (3), 227{86.
Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning. Proceedings Eleventh International Conference Machine Learning,
pp. 157{163 San Mateo, CA. Morgan Kaufman.
Preist, C., Bartolini, C., & Phillips, I. (2001). Algorithm design agents participate multiple simultaneous auctions. Agent Mediated Electronic Commerce III
(LNAI), pp. 139{154. Springer-Verlag, Berlin.
Rodriguez-Aguilar, J. A., Martin, F. J., Noriega, P., Garcia, P., & Sierra, C. (2001). Towards
test-bed trading agents electronic auction markets. AI Communications.
press. Available http://sinera.iiia.csic.es/~pablo/pncve.html.
Singh, S., Kearns, M., & Mansour, Y. (2000). Nash convergence gradient dynamics
general sum games. Proceedings Sixteenth Conference Uncertainty
Artificial Intelligence (UAI), pp. 541{548.
Stone, P. (2000). Layered Learning Multiagent Systems: Winning Approach Robotic
Soccer. MIT Press.
Weber, R. J. (1997). Making less: Strategic demand reduction FCC
spectrum auctions. Journal Economics Management Strategy, 6 (3), 529{548.
Wellman, M. P., Wurman, P. R., O'Malley, K., Bangera, R., Lin, S.-d., Reeves, D., & Walsh,
W. E. (2001). trading agent competition. IEEE Internet Computing, 5 (2), 43{51.

206

fiJournal Artificial Intelligence Research 15 (2001) 383-389

Submitted 6/01; published 11/01

Research Note

Finding Path Harder Finding Tree

Christopher Meek

meek@microsoft.com

Microsoft Research,
Redmond, WA 98052-6399 USA

Abstract

consider problem learning optimal path graphical model data show
problem NP-hard maximum likelihood minimum description length
approaches Bayesian approach. hardness result holds despite fact
problem restriction polynomially solvable problem finding optimal tree
graphical model.
1. Introduction

problem learning graphical models received much attention within Artificial Intelligence community. Graphical models used represent approximate joint
distributions sets variables graphical structure graphical model represents dependencies among set variables. goal learning graphical model
learn graphical structure parameters approximate joint distribution data. note, present negative hardness result learning optimal
path graphical models.
Path graphical models interesting class graphical models respect learning. due fact that, many situations, restricting attention class path
models justified basis physical constraints temporal relationships among
variables. One example problem identifying relative positions loci
segment DNA (e.g., Boehnke, Lange & Cox, 1991). addition, one might interested
obtaining total order set variables purposes visualization
(e.g., & Hellerstein, 1999).
main positive results hardness learning graphical models learning
tree graphical models. presented maximum likelihood (ML) criterion
(Edmonds, 1967; Chow & Liu, 1968) adapted Bayesian criterion Heckerman,
Geiger, & Chickering (1995). Two NP-hardness results learning graphical models
appeared literature. NP-hardness finding optimal Bayesian
network structure in-degree greater equal two using Bayesian optimality
criterion (Chickering, 1996) problem finding ML optimal polytree (Dasgupta,
1999).
note, present proof hardness finding optimal path graphical
models maximum likelihood (ML) criterion, minimum description length (MDL)
criterion, Bayesian scoring criterion. Unlike ML hardness result Dasgupta,
provide explicit construction polynomial sized data set reduction and, unlike
Bayesian hardness result Chickering (1996), use common \uninformative" prior.

c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiMeek

2. Optimal Graphical Models

One primary goals learning graphical model obtain approximate joint
distribution set variables data. note, focus directed graphical
models set discrete variables fX1 ; : : : ; X g. One component directed graphical
model directed graphical structure describes dependencies variables.
directed graphical model represents family distributions factor according
graphical structure G directed graphical model, specifically,
n

P (X1 ; : : : ; X ) =
G

n

P (X jpa
n

=1



G

(X ))




pa (X ) denotes possibly empty set parents vertex X graph G.
subscript G omitted clear context. common methods guiding
choice distribution family distributions maximum likelihood estimation
Bayesian estimation. Given graphical structure set cases variables
(also prior distribution distributions case Bayesian approach),
methods provide approximate joint distribution. details graphical models
estimation see Heckerman (1998).
leaves open question one choose appropriate graphical structure. remainder section, present maximum likelihood (ML) criterion,
minimum discrimination length (MDL) criterion, Bayesian criterion evaluating
directed graphical models given set cases D. value variable X denoted
x value set variables pa(X ) denoted pa(x ). number cases
X = x pa(X ) = pa(x ) denoted N (x ; pa(x )) total number
cases denoted N .
One important property common scoring criteria scores factor according graphical structure model. is, score graph G data
set written sum local scores variables
G





















Score(G; D) =





X LocalScore(X ; pa(X )):






local score variable X function counts X pa(X )
data set number possible assignments variables X pa(X ). Thus
structure graphical model determines particular variables counts
needed computation local score variable.
log maximum likelihood scoring criterion graphical model


Score

ML

X LocalScore

(G; D) =

ML









(X ; pa(X ))






LocalScore

ML

(X ; pa(X )) = N H (X jpa(X ))










(1)

H (X jpa(X )) empirical conditional entropy X given parents,
equal
N (x ; pa(x )) N (x ; pa(x ))
log
:
N
N (pa(x ))
( )






X













Xi ;pa Xi

384

fiFinding Path Harder Finding Tree

One practical shortcoming ML score comparing two models graphical
structure G G0 G contains proper subset edges G0 ML score
never favor G. Thus, using ML score choose among models without restricting
class graphical structures, fully connected structure guaranteed maximal
score. problematic due potential poor generalization error using
resulting approximation. problem often called overfitting. using principle
best restrict class alternative structures consideration suitable
manner.
minimum description length score viewed penalized version ML
score

Score

DL

(G; D) = Score

log N

(G; D)

X LocalScore
ML

=

2

DL

(G; D)



LocalScore

DL

(X ; pa(X )) =




#(pa(X )) (#(X )
2

LocalScore



ML

P



1) log N

(2)

= (#(pa(X )) (#(X ) 1)) #(Y ) used denote number possible
distinct assignments set variables number assignments empty
set variables #(;) = 1. penalty term leads parsimonious models, thus,
alleviating overfitting problem described above.
Finally, Bayesian score requires prior alternative models and, model,
prior distributions. commonly used family priors directed graphical models described Cooper & Herskovits (1992). approach, one assumes uniform
prior alternative graphs, P (G) / 1, \uninformative" prior distributions.
assumptions lead following scoring function;




Score



Bayes

(G; D) = log P (DjG) + log P (G)
/
LocalScore
(X ; pa(X ))

X

Bayes







LocalScore

Bayes

(X ; pa(X )) =


log





(

pa xi

(#(X ) 1)!
(#(
X
)
1) + N (pa(x )))!
)






N (x ; pa(x ))!




(3)

xi

Although apparent MDL score, Bayesian score also built-in
tendency parsimony alleviates problems overfitting. hardness results
presented extended variety alternative types priors including
BDe prior empty prior model (see Heckerman et al. 1995).
problem finding optimal directed graphical model given class structures G data problem finding structure G 2 G maximizes Score(G; D).
385

fiMeek

3. NP-Hardness Finding Optimal Paths

section, consider problem finding optimal directed graphical model
class structures restricted paths. directed graphical structure
path one vertex in-degree zero vertices in-degree one.
show problem finding optimal path directed graphical model NP-hard
commonly used scoring functions described Section 2. demonstrate hardness
finding optimal paths problem needs formulated decision problem.
decision problem version finding optimal path directed graphical model follows
optimal path (OP) decision problem: path graphical model
score greater equal k data set D?
section prove following theorem.
Theorem 1 optimal path problem NP-Hard maximum likelihood score,
minimum description length score Bayesian score.

prove this, reduce Hamiltonian Path (HP) decision problem OP decision
problem.
Hamiltonian path (HP) decision problem: Hamiltonian path
undirected graph G?
Hamiltonian path undirected graph G non-repeating sequence vertices
vertex G occurs path pair adjacent vertices
sequence edge G. Let undirected graph G = hV; E vertex set
V = fX1 ; : : : ; X g edge set E .
HP decision problem NP-complete. Loosely speaking, means HP
decision problem computationally dicult variety problems known
algorithm exists runs time polynomial function size input.
Theorem 1 indicates OP decision problem least dicult NP-complete
problem. information HP decision problem NP-completeness see
Garey & Johnson (1979).
reduce HP decision problem G OP decision problem constructing
set cases following properties;
n

#(X ) = #(X )


(i)

j

LocalScore(X ; ;) = LocalScore(X ; ;) =

(ii)

LocalScore(X ; fX g) 2 fff; fi g

(iii)





j

ff<fi

j

LocalScore(X ; fX g) = LocalScore(X ; fX g)

(iv)

LocalScore(X ; fX g) = fi iff fX ; X

(v)

j







j



386

j

j

g2E

fiFinding Path Harder Finding Tree

data set, problem existence Hamiltonian path equivalent
existence path graphical model score equal k = + (jV j 1) fi
jV j = n number vertices undirected graph G. Thus, reduce
HP problem OP problem one needs eciently construct polynomial sized data
set properties. words, construction, general HP decision
problem transformed OP decision problem. size input
OP problem polynomial function size input HP problem,
one find algorithm solve OP problem polynomial time NP-complete
problems solved polynomial time.
construct data set graph G assuming variable ternary satisfy
condition (i). pair vertices X X (i < j ) edge G,
add following 8 cases every variable X (k 6= i; j ) zero.


j

k

X1 : : : X
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0



1

X X +1 : : : X
1
0:::0
1
0:::0
1
0:::0
1
0:::0
2
0:::0
2
0:::0
2
0:::0
2
0:::0




j

1

X

j

1
1
1
2
1
2
2
2

X +1 : : : X
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
j

n

pair vertices X X (i < j ) edge G, add
following 8 cases.


j

X1 : : : X
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0



1

X X +1 : : : X
1
0:::0
1
0:::0
1
0:::0
1
0:::0
2
0:::0
2
0:::0
2
0:::0
2
0:::0




j

1

X

j

1
1
2
2
1
1
2
2

X +1 : : : X
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
0:::0
j

n

set cases constructed described above, pairwise counts pair variables
X X connected edge G


j

X



X

j

0
1
2
0 4(n2 5n + 6) 4(n 2) 4(n 2)
1
4(n 2)
3
1
4(n 2)
1
3
2
387

fiMeek

pairwise counts pair variables X X connected edge G


j

X



X

j

0
1
2
0 4(n2 5n + 6) 4(n 2) 4(n 2)
1
4(n 2)
2
2
2
4(n 2)
2
2

Condition (ii) satisfied marginal counts variable identical.
two types pairwise count tables, thus, two values given type
pairwise LocalScore. using two pairwise count tables Equations 1, 2, 3,
one easily verify local scores two tables satisfy condition (iii). follows
symmetry two types pairwise tables condition (ii) condition (iv)
satisfied. follows construction condition (v) satisfied. Furthermore,
set cases eciently constructed size polynomially bounded
size graph G proving result.
4. Conclusion

note, show problem finding optimal path graphical models NPhard variety common learning approaches. negative result learning optimal
path graphical models stands contrast positive result learning tree graphical
models. hardness result highlights one potential source hardness. is,
one make easy problem dicult choosing inappropriate subclass models.
Perhaps, carefully choosing broader class models tree graphical models one
identify interesting classes graphical models problem finding optimal
model tractable.
Another interesting class graphical models described note class
undirected graphical models (e.g., Lauritzen, 1996). methods learning undirected
graphical models closely related methods described Section 2. fact,
case undirected path models, scoring formulas described Section 2 identical
common approaches. Therefore, NP-hardness result directed path
models presented note also applies problem learning undirected path models.
Finally, important note good heuristics exist problem finding
weighted Hamiltonian paths (Karp & Held, 1971). heuristics used identify
good quality path models rely fact optimal tree model easily
found score least large path model.
References

Boehnke, M., Lange, K., & Cox, D. (1991). Statistical methods multipoint radiation
hybrid mapping. American Journal Human Genetics, 49, 1174{1188.
Chickering, D. (1996). Learning Bayesian networks NP-complete. Fisher, D., & Lenz,
H. (Eds.), Learning Data, pp. 121{130. Springer-Verlag.
Chow, C., & Liu, C. (1968). Approximating discrete probability distributions dependence trees. IEEE Transactions Information Theory, 14, 462{467.
388

fiFinding Path Harder Finding Tree

Cooper, G., & Herskovits, E. (1992). Bayesian method induction probabilistic
networks data. Machine Learning, 9, 309{347.
Dasgupta, S. (1999). Learning polytrees. Proceedings Fifteenth Conference
Uncertainty Artificial Intelligence, Stockholm, Sweden, pp. 134{141. Morgan Kaufmann.
Edmonds, J. (1967). Optimum branching. J. Res. NBS, 71B, 233{240.
Garey, M., & Johnson, D. (1979). Computers intractability: guide theory
NP-completeness. W.H. Freeman, New York.
Heckerman, D. (1998). tutorial learning Bayesian networks. Jordan, M. (Ed.),
Learning Graphical Models, pp. 301{354. Kluwer Academic Publishers.
Heckerman, D., Geiger, D., & Chickering, D. (1995). Learning Bayesian networks:
combination knowledge statistical data. Machine Learning, 20, 197{243.
Karp, R., & Held, M. (1971). traveling-salesman problem minimum spanning trees:
Part ii. Mathematical Programming, 1, 6{25.
Lauritzen, S. (1996). Graphical Models. Oxford University Press.
Ma, S., & Hellerstein, J. (1999). Ordering categorical data improve visualization.
Proceedings IEEE Symposium Information Visualization, pp. 15{17.

389

fi
ff
fi
! #"$ %
'&)( *,+.-//!(102-34657-8:9

;<=>? @A4:B
/!(CED= %&@F( /:B
/!(

GIHKJMLONQPSRAPST:HKUVRXWZY[LOLV\]H)R_^#`aPSHbYcUVRXLO`VH)\]RedgfihHFW<NQPST:HKU
TUkjQLVRXUOT:hS`mlnT:RXW:HFoFNVfih

prq2s]t#uwvAxKq2vy{z|q$}
K''?{:ffE_.::<:

{
A,6E
,
':]

~,2{~i{{F2ff

xKq}ffyprq$} s#uwffVq$}y

7w7SF{<$

K''?{:ffE_.::<:

{
A,6E
,
':]

ZA]w
?Ew?6<16?OE617?17ff'
1E1!:<66
F<:1EE
{ff1!{?w6E
6<11F1!6<

ff6X
:<XE?76E1
X11:16<:)E1!:<)E6EE<
!
:<QEF6Qff< i. 1.7612.1
.E
166676E1$SX1.76E1$)1.F1!1$KE11c1<X1
6_716ff6.766E11g._ !.6
1
E6?EQ176<i !iEOE6<:!11Q :_?1O?.
1)
66F1Q6 1! <K1ffw6K<6K1<E1!11.E61
O61)1Q:1
Q.E<<AK66 AK<K<1<
6
:6F1F1? 1
ESE1!:<66ff<6<QQ16w1< :)6<
1
,
E<7A6KE
1! 1$E

7!1E
E








fiff






ff

w
!


"$#&%')(+*-,.%/,1023*
465+7189*
#:8;2<*
#&0=*->71(+0@?A*
237B%-CD7189E-0%,10%-2F*->G,10210%,.C.(H8;#:I$%715+,.%-4KJ%-#+L
5)%L-0NMG,1*O
CD0212186#+LAPQIRJSMUTWV
XY(+0ZCD*
?'),10(+0#&218;*
#=*->[%-#&%')(+*-,W%$862%-#8;?'\*-,171%-#]7S'&,.*^CD021286#@%-#]_=I$JM`23_a23730?cb
_-0d7R8;7Y8;2Z%-?*
#+LA71(&0e73*
5+L
(+0237<'&,1*-f)490?2Z8;#cCD*
?')5+71%718;*
#&%-4g4;8;#&L
5&8;23718;Cd2U%-#&hiI$JMV)"$CdCD*-,.h&86#+L73*
j 89,.237kPmln-oalTWp
qFrtsWu)v^w-xmsy=z{r}|z{~DWwax.~yez{~sH|dzW$dwxAsfizr]s-rsdx3dzs-1|Hx3ddx3drtW.w-r&
!s-z{r&zr]kddDxADzQ~NwmA|z{~Ds-Adz
&s-Qz{r^izrdwxWAs-Qzwr+yRxms-v+DxAv^sr.dz{r]i9.-z.swx
utv^wr[QzQWs{~.vawxdx!w~DwAdr)QzQw-xNDrtQzQz!~Az{rHvaA.u+.!s-Qzwrvas-va@x1D
Dzdx/wm/v+c|z{~D.w-^xW~dz{WsD;!wH|z{~DsfiDx1Dzs-iva/x3ddx3drtWisrt|yevadx3fiDy
|]dDxNz{r\Nva=z|Dr)QzQQw3kvaDrtQzQ

X (&0,10d>{0d,.0#&CD073*%-#H0#]71897_P0-VL+V9b%'&,1*
#&*
5&#tTR8;2BL-0#+0d,W%-4;49_Cd%-46490hH%-#}srtsu)v^wxb71(+00#]71897_

73*R(&8;C.(71(+0%-#&%'t(+*-,k,10d>0d,.2=8;2k89712x3ddx3dr)Qb%-#&h71(&0'&,10dEa89*
5&2e,10d>{0d,.0#&CD073*71(+0/21%-?A00#]71897_
8;2$71(+0A%-#&%'t(+*-,2sr).W1|]Dr)QV+*-,k86#&2371%-#&CD0-bg8;#:71(+02371%730?A0#7}awvr
ks-/srsWu
ut;@mFGs~
var]
xW[Wb)71(+0e'&,1*
#&*
5&#va@8;271(+0k%-#)%')(+*-,<%-#&h71(&0k#+*
5&#+wvrH8;2Z71(&0e%-#730CD0h+0#]7dV
"$#%-#&%')(+*-,.86CY'&,1*-ft490?Cd%-#f\0Fh+021CD,.89f\0h/%-2U4;_^8;#&L=23*
?0dR(+0d,10$f[0d70d0#71(+0F,1021*
4;5+7189*
#%-#&h
71(+0FL-0#+0d,.%718;*
#*->%-#&%')(+*-,W%ab^71(&0$>*-,.?0d,730d,.?f\08;#&Lk71(+0Fh&8;21%f)f&,10dEa8;%718;#+Le*->S71(+0F,10d>0d,10#&CD0B%-#&h






U

G



6 fi

-//!(] w %% !@6X
@ :
]
!fi>i
w=! %&% &:%2% : @

fi

i{9 ] DA2

2{~i{

71(+0c4;%73730d,Af\08;#&L71(+0c%f&f),10dE^86%718;#+L:>{*-,.?*->$71(+0,10d>0d,10#&CD0c73*%-#0#]71897_-VXY()8;2k't%'[0d,N>*^Cd5)2302
0D+Cd4;5&2189E-04;_*
#`71(+0,.023*
4;5+7189*
#*->Y%-#&%')(+*-,.%%-#&h#&*-7k*
#71(&089,kL-0#+0d,W%7189*
#Vi"$#&%')(+*-,.%Cd%-#f\0
Cd4;%-212.8)0h8;#}?A%-#_h&89[0d,10#]7A%_a2dbYh+0d'\0#&h&86#+LH5+'\*
#71(+0i')%,.718;Cd5&4;%,CD,W89730d,.8;%*
#+0:C.(+*^*
2302/73*
0?')4;*_-VY0dL
%,Wh&8;#+L71(&0i0490?0#]771(&%7Cd%,1,.8;02A*
5+7A71(&0,10d>0d,10#&CD0P71(+0%-#&%'t(+*-,TWbZ>*-,0D+%-?NO
')490-btCd490%,$h)8;23718;#&CD718;*
#&2Z21(+*
5&46hf[0=?A%-h+0ef\0d7U0d0#:'&,1*
#+*
?8;#&%-4%-#&%')(&*-,.%abt%-h30CD7189E%-4%-#&%'t(+*-,.%ab
h+0Dt#)89730Ah+021CD,.8;'&7189*
#&2db*
#+0DO%-#&%')(+*-,W%ab215&,1>%-CD0DOCD*
5)#7@%-#&%')(+*-,.%abE-0d,1f)%-49O!')(+,.%-230A%-#)%')(+*-,.%abK%-#&h
718;?0/%-#&htfi*-,N49*^Cd%718;*
#,10d>0d,10#&CD02dVcXY()8;2B')%'\0d,e>*^Cd5)2302k*
#71(+0,.023*
4;5+7189*
#*->U'),1*
#+*
?A8;#)%-4%-#&h
%-h30CD7189E%-4g%-#&%')(+*-,W%aV (
7/8;2A<8;h+049_%L-,10d0h71(&%771(+0'&,1*aCD0212*->B,1021*
49E^86#+L%-#&%')(+*-,W%8;##&%715&,.%-4Y4;%-#+L
5)%L-0730Da712
?A%_if\0@215&'&'\*-,1730hif^_%/E%,.8;0d7_i*->G2173,.%730dL
8902F71(&%7$0?')49*fi_h&8\0d,10#]7<a8;#&h&2<*->a#+*<4;0h+L-0-VB_
h&8\0d,10#]7<a8;#&h&2Y*->^#+*fi<490h+L-0=0N?0%-#71(+0kE%,.89*
5)2<23*
5+,WCD02<*->G86#+>{*-,W?A%7189*
#i5&2.5&%-4;49_0?')49*fi_-0h
>*-,%-#&%')(+*-,.%F,.023*
4;5+7189*
#gb
8;#&Cd4;5&h)8;#+L<?*-,.')(+*
49*-L
8;Cd%-4a%L-,10d0?A0#7dba23_a#71%-CD718;CY')%,.%-4;490468;21?cb230?A%-#]718;C
8;#+>*-,.?A%718;*
#b+h&8;21CD*
5+,W230B2373,.5&CD715+,.0-b+73*-')8;Cd%-4a#+*R490h+L-0-b)%-#&h23**
#V
I$%715+,.%-44;%-#+L
5&%L-0/'&,1*aCD021218;#+LPQI$JMTWbS%-#&hgb23'\0Cd8[Cd%-4;49_-b%-#&%'t(+*-,.%c,1021*
4;5+7189*
#b5&2302=?A%-#_
,1023*
5&,.CD02<%-#&h23*
5+,.CD02<*->8;#+>*-,.?A%7189*
#>*-,$7U*,10%-23*
#)2dpFPmlTY#]5)?0d,1*
5&2<,1023*
5+,.CD02R%,10=%E%-864;%f)490
73*71(&0=21Cd890#]718tC=CD*
?A?@5&#&897_t[%-#&h`P
T<(]5)?A%-#&2Y0?A')49*_c?A%-#]_i23*
5+,WCD02<*->8;#&>{*-,.?%7189*
#i8;#c*-,Wh+0d,
73*A,1021*
49E-0kh&8\0d,10#]7Y4;8;#+L
5)8;23718;C<')(+0#+*
?0#)%aV
0Y'),10230#]7K%-#%-49L-*-,.8971(&?71(&%7CD*^*-,.h&86#&%7302h&8\0d,10#]7>*-,.?A2K*->[a#+*<4;0h+L-0f]_@h&8;23718;#&L
5&8;21(&86#+L
f\0d7U0d0#4;8;#+L
5&8623718;C@^#&*<490h&L-0:PQCD*
#&2373,W%-8;#712@%-#&h`'&,10d>0d,10#&CD02WTe%-#&hh)8;%-49*-L
5+0DO2373,W5&CD715+,10Aa#+*fi<4O
0h+L-0PQ%-#&%'t(+*-,.8;C@%-CdCD0212189ft8;4;897_23')%-CD0fiTWV@XY(+0%-49L-*-,.8971()?86h+0#7189)02$71(+0#+*
5&#:')(+,.%-210=73*c<()8;C.(%
71(&89,WhaO!'\0d,.23*
#'\0d,.21*
#&%-4G*-,h+0?A*
#&2373,.%7189E-0'&,.*
#+*
5&#`*-,N%-hm0CD7189E%-4%-#&%')(+*-, - ,10d>0d,.2N8;#%^')%-#aO
8;21(h&86%-49*-L
5+0-V 0ACd%-4;471(&862$%-4;L-*-,.8971(&?"$<F8YPQ%-#&%')(+*-,W%/,.023*
4;5+7189*
#8;#h&86%-49*-L
5+02WTWVk"$<F8K%-2
8;?'t490?0#]730hc8;#cM,1*
4;*-L+V
#^0CD7189*
#f\049*ebU0'&,10230#]7N,104;%730hU*-,1*
#%-#&%'t(+*-,.%:,1023*
4;5&7189*
#`86#h)8;%-49*-L
5+02dV #
^0CD7189*
#^bU0215+L-L-0217=%-#%-#)#+*-71%7189*
#2.C.(+0?0>{*-,kCd%')715+,.8;#+La')%-#&8;21(h&86%-49*-L
5+0A2373,.5)CD715+,10-V #
^0CD7189*
#N+b
%-#%-CdCD02.2189f)8;46897_e23't%-CD0Uft%-230hN*
#@71(&8;2K%-#&#+*-71%7189*
#2.C.(+0?0Z8;2Kh+0D[#+0hV #A^0CD7189*
#A^b-U0
'&,10210#7R71(+0@%-4;L-*-,.8971(&?"RR$8!V<K8;#&%-4;49_-b[%-#0Da'\0d,.8;?0#]71%-421715&h+_*->71(+0@%-49L-*-,.8971(&?8;2<'&,10230#]730h
8;#^0CD718;*
#^V
K) {



[ U



i-

G g


+*-,G%-#)%')(+*-,.%F,1021*
4;5+7189*
#N8;#Nh&8;%-4;*-L
5+02db
%F'&,1*
4689>{0d,W%7189*
#k*->[?0d71(+*ah&2Kf)%-230hN*
#h&8;%-49*-L
5+02373,.5)CD715+,10
PQh&8;2.CD*
5+,.230DO!*-,.8;0#730h/%'&'&,1*
%-CW(+02WTG(&%E-0$f\0d0#h+0dE-049*-'\0hV"$?*
#+L@71(+0230-b^0$21(+*
5&46hA4;89-0Y73*@023'\0DO
Cd8;%-4;4;_N%-C.^#&*<490h&L-0$71(&0<U*-,1A*->S$,1*
21NPmln
-]bgln-oalTWb&8;#<(&8;CW(A71(+0F8;#a[5+0#&CD0Y*->gh&86%-49*-L
5+0R2173,.5&CO
715+,108;#H%-#)%')(+*-,.%,1023*
465+7189*
#8;215&23718)0hgVN$,1*
21-2B*-,.>*^Cd5)2302B23'\0Cd8tCd%-4;4;_i*
#71%-23]O!*-,.890#]730h
h&8;%-4;*-L
5+02dV$71(&0d,k23715&h&8;02db215&CW(%-2k71(+*
230A')5&f)4;8;21(&0hf^_$,1*
23:$s-Pmln-o-^bln-n-
TWb'&,10230#]7k%
CD0#]730d,.8;#+L>,.%-?0dU*-,1%-2%?*^h&0473*0Da')4;%-8;#71(+0CD*
(+0d,10#&CD0i*->B49*aCd%-4Yh&8621CD*
5+,.230i210dL
?0#712/8;#
<(&86C.(71(+021'[0%-0d,2e>*^Cd5&2F*->Z%73730#]7189*
#8;2F,104;%730hH73*,10d>0d,1,.8;#+L0Da'&,10212.89*
#&2dVXY(&862B?*^h&04(&%-2
%-C.()890dE-0hc215&CdCD02121>5&4),10215&4;7128;#%-#&%')(&*-,.%k,.023*
4;5+7189*
#/8;#?*
#+*
49*-L
5+02b]f)5&7U*
5&4;h,10]5)89,10RCD0d,.71%-8;#
?*ah&8tCd%718;*
#&2$73*if\0N2.5&CdCD02123>Q5&4;49_%'&')4;890h:73*ih&86%-49*-L
5+02dV"$49*
#+L71(+*
230468;#+02dbU_],.*
#%-#&h^730#]7
&NY1Yfi3.UmDm=g!A!ZW[m!WWgWfiW-mmWY!N.-31!3 ZQff
! fi
fifiRBW WW!! 3 i3.
-k! 3/!AW!fi
R

d!/ c!fi= W Wm$[=. .!3
WfiW

fiA m!WW Wfi.U
=
!A "fi ..$g!Y![W
#$&%U Z!3(
'fiW
fi Zfi )% *,+-#/.0#13254!%ff+6%87ff9-#$%;:=<1
?>

fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

Pmln-n-o
T(&%E-0h&0dE-049*-'\0hk0Da730#&2189*
#)2*->+71(+0CD0#]730d,.8;#+LF?0d71(+*ahk>*-,K%'&')4;8;Cd%718;*
#e73*Fh&8;%-49*-L
5+02VSXY(+0d_
CD*
#&Cd4;5)h+0B71(&%7<CD0#]730d,.8;#+LA862Y%-2YCD*
#&218623730#7R8;#ch&8;%-49*-L
5&02Y%-2Y897Y8;2<8;#c?*
#+*
49*-L
5&02dV
IR0dE-0d,171(+04902.2dbS%-CdCD*-,.h)8;#+Lc73*^73,.5&f[0N%-#&h j %-(&#}Pmln-n-n
TWb71(+0ACD,.5&Cd86%-4K'[*
86#7F*->U71(+0ACD0#730d,W8;#+L
?*ah+048;2e71(+0Cd%-#&h&86h&%7304;8;217dV$,1*
23dFsPmln-n-
T=2371%730/71(&%7k71(&862e4;8;237B?A%_Hf\0*-,.h+0d,10h5)218;#+L
h&8\0d,10#]7=>Q%-CD73*-,.2dbf)5+7@71(+0d_*
#)49_5&230c8;#&>{*-,.?%7189*
#`%f\*
5+7@L-,.%-?A?%718;Cd%-4,1*
4902dV j *U0dE-0d,bZ897N8;2
h&;8 KCd5&497F73*h+0Dt#&0AL-,.%-?A?A%7186Cd%-4,1*
4902k8;#H>,10d0DO!*-,WhaO!*-,.h+0d,k46%-#+L
5&%L-02@4;89-0/$0d,.?%-#*-,@^'t%-#&8;21(
<8971(&*
5+7Z5&218;#+L230?%-#718;Ck8;#+>*-,.?A%7189*
#V 4
F#71(+0*-71(+0d,@()%-#&hb*-,1Cd%,.,.890h*
5&7kf^G
_ LGC1-0d,.7N%-#)h^73,.5&f[0:Pmln-n-n
Te*

# LG#&L
4;8;21(h&0d71%-8;4;2
%?0d71(+*ah>{*-,,.023*
49Ea8;#+L'),1*
#+*
?A8;#)%-4%-#&%'t(+*-,.%8;#h&8;%-49*-L
5&02=R8971(`%'),10Cd8;2189*
#`*->$-^V N %-#&h
%,10Cd%-4;4,W%730i*->F-o^V NVXY(&8;2N?0d71(+*ah8;2Nf)%-210h*
#71(+0ih&8;2173,.89f)5+718;*
#*->Fh&8;%-49*-L
5+0c%-CD712/%-2A%-#
%-49730d,.#)%7189E-0e73*A71(+0eCD0#]730d,.8;#&L?0d71(+*ahV
&5&,171(+0d,.?*-,.0-Pb O:%,1?7 R Q #&0dDOU%,WCD*dGs9Pmln-n-n
T0?')(&%-218;d0R71(+0B8;?A'[*-,.71%-#&CD0<*->h&8;21CD*
5+,W230DO!73*-')8;C
a#+*<4;0h+L-0k%-2<%CD*
?')490?0#]71%,1_c?0d71(+*ahi>*-,<%-#&%'t(+*-,.%,1021*
4;5+7189*
#i86#ch&8;%-49*-L
5+02<8;#c<(&86C.(c215&CW(
a#+*<4;0h+L-0e8;2Y#+0CD02.21%,1_>{*-,R49*
#+LOh&8;2171%-#&CD0e%-#&%')(+*-,W%N,1023*
4;5+718;*
#V
SK




G ]{


TMU
G g

ff




w

+*-,N215&CdCD02121>5&4G%-#&%')(+*-,.%i,1023*
4;5+718;*
#8;#h&86%-49*-L
5+02dbS0%-21215&?071(&%7k897k862e021230#]718;%-4G73*8;h+0#]7189>_
h&8;%-4;*-L
5+0R2373,W5&CD715+,10-VXY(+0d,.0d>{*-,10-b^U0R'&,.*-'[*
210R%-#%-#&#+*-71%7189*
#21CW(+0?0$>{*-,Y^')%-#)8;21(h)8;%-49*-L
5+02G71(&%7
8;2Rf)%-230h:*
#U*-,1Cd%,1,.8;0h*
5+7Ff^_:F%-4;46%,.h+*HPmln-n-
TWb<(+*%'&')468902Y71(+0N71(+0d*-,W8902$')5+7<>*-,1%,.h:f]_
a%-C.^2NdsPmln
fi]T<CD*
#&CD0d,.#&8;#&LPQCD*
#E-0d,.2.%7189*
#&%-4{TZ715+,.#aO!71%a8;#+L+V
0i5&210%-#%-#&#&*-71%7189*
#21C.(&0?0cf)%-230h*
#71(+023071(+0d*-,W8902N>{*-,71(&,10d0c?A%-8;#`,10%-23*
#&2dV`8;,.237db
%-2B897F8;2F%L-0#+0d,.%-4K%'&'&,.*
%-C.(H73*ch&8;%-4;*-L
5+0@?A*^h+0468;#+L+b\897B8;2F%'&')4;8;Cd%ft490e73*i%-4;47_^'\02F*->h&86%-49*-L
5+02db
8;#&Cd465&h&8;#+L:f\*-71(71%-23]O!*-,.890#]730h%-#)h}8;#+>*-,.?A%718;*
#aO!,10d73,.890dE%-4O!*-,.8;0#730hh)8;%-49*-L
5+02dW
V VU*
#&230^5+0#]7149_-b
71(+0N5&230=*->G215&CW(%?*ah+04S%-2F%/f)%-218;2<>{*-,Bh+0dE-04;*-')8;#+L/*
5+,$%-#)%')(+*-,$,1023*
4;5+718;*
#i'&,1*aCD0h&5+,.0=%-4;49*fi<2
5&2B73*:%'&')49_71(+0A'&,.*^CD0h&5&,1073*%-#]_:7_]'\0A*->Zh+*
?%-8;#bg71(^5&2e*\0d,.8;#&Li%-#%-h+E%-#71%L-0*E-0d,@'&,1*aCD0DO
h&5+,.02kf)%-210h*
#h&8;2.CD*
5+,.230?*^h&04;2k23'\0Cd8[CA73*')%,1718;Cd5)4;%,=h+*
?%-8;#&2dVH^0CD*
#&hb71(&862=%-#&#&*-71%7189*
#
21CW(+0?0eCd%-#f\0R0%-2.8;49_%'&'t4;890hA73*A%-5&73*
?A%718;CF'&,1*aCD0212302U<8;71(+*
5+7?0d71%-4;8;#+L
5)8;23718;CRCD*
#&218;h+0d,W%7189*
#&2dV
"$4971(+*
5+L
(8;#*
5+,ZU*-,171(+0B%-#&#+*-71%7189*
#c71%-21/(&%-2f\0d0#'\0d,1>*-,.?0hf]_(&%-#&hba>*-,Yh&8;%-49*-L
5&0DO!f)%-230h
%'&')468;Cd%7189*
#&286#<(&8;CW(A*
5+,'&,1*aCD0h&5+,10Y?89L
(7f\0Y0?kf\0h&h&0hP0-VL+V9b&8;#Ah&86%-49*-L
5+0<?A%-#)%L-0?0#723_a2mO
730?A2WTWb%-#&#&*-71%7189*
#71%-21^2F?@5&237<f\0='[0d,.>{*-,.?A0hi%-5+73*
?A%718;Cd%-4649_-VRK8;#&%-4649_-b&U0=%-#730h:73*f)%-230=*
5+,
*R#'&,.*^CD0h&5&,10Y*
#23715&h&8902*->71(+0R8;#+t5+0#&CD0Y*->gh)8;%-49*-L
5+0<2173,.5&CD715+,10<*
#/%-#&%'t(+*-,.%e,.023*
4;5+7189*
#A71(&%7
U0d,10kCd%,1,.8;0h*
5+7Yf^_+*`Pmln-o
-TWbtR(+*
230k%'&'),1*
%-C.(b&86#715+,.#b&8;2ft%-230hc*
#i71()%7Y*->+%-C1a2@dsV
"$CdCD*-,.h&8;#&L73*c71(&0230N71(+0d*-,.8902db71(+0Nf)%-218;C@5&#&897$*->CD*
#]E-0d,.21%718;*
#8;2$71(+0Awdbg<(&86C.(8;#+>*-,.?A2
71(+0i4;8623730#+0d,%f\*
5+7A%-#%-CD7189*
#bU,10^5+0237db^5+023718;*
#bG0d71CX
V O*E-02/%,10Cd%,1,.8;0h*
5+7Nf]_?0%-#&2*->
+Dx3srt~WZV Y:"R#)hc5+73730d,.%-#&CD02R%,103*
8;#+0h73*-L-0d71(+0d,$73*Af\0CD*
?0Qaxr+~WV
a86#&CD0N*
5+,B*-,.:%-2eh+*
#&0A5&218;#+L23'\*--0#h&86%-49*-L
5+02F71(&%7e(&%-hf\0d0#H73,W%-#&21CD,.89f\0hb\715+,W#&2B%,10
%-#&#+*-71%730h8;#71(+0B730D^712<%-#&h5+73730d,.%-#&CD02Y%,.0eh+04;8;?A8;730hf^_71(+0e5)230F*->')5&#)CD715&%7189*
#?A%,1a2*-,Zf]_
71(+0@0#&h&2<*->715+,.#&2V<Y0%-h&86#+L/%')5&#&CD715&%718;*
#?A%,.PV9\b [
b ]9bSV9V9V T%-4;49*fi<2R5)2Y73*,10CD*-L
#&89d0@71(+0@0#&h
*->%-#i5+73730d,.%-#)CD0-VGXY(+0230k71%-23^2<h+*#+*-7Y%\0CD7<71(+0=%-#&%')(+*-,.%O!,.023*
4;5+7189*
#'),1*^CD02.2dV
^-._Y1! mW\!B `afi! Ab
! fi;\W?fi6WfiZ WmW ?Qm0\!Z?Q0\!W
3c-G!mm1D!me!<R 16 U! B-m!!edfg6fi D6k
W !mZ
0dfg6fi m!W !mZ
0]
B3WUW
fi!-!.)Y
16D
!m \
h W8Y
! !mgW!U\.i6fi Wm!Q! g!!1!3
j lk?2m2=%"+-n$&opZ
% k<fi W K WWd!<Yd!mGkqfi!fi{ .
fi]
W!WW r, m3.Ut

!fi ."

fi!1!sY16 fi !fimm.!K!mmt 3d uZ
3g+

-mD
!fi
v .mm
?>fiff

fi

i{9 ] DA2

2{~i{

"$2Y%,102.5&497db+U0e'&,1*-'\*
230F71(+0e>*
4;49*fi<8;#+L%-#&#&*-71%7189*
#i21CW(+0?0e>*-,<h&8;%-4;*-L
5+0e2373,.5&CD715&,10-p
68 28;h+0#]718)0h`f]_%HC.(&%-#+L-0c*->F23'\0%-0d,A8;#71(+0ih&86%-49*-L
5+0-U0%-C.(}CW(&%-#+L-0c*->F23'\0%-0d,
'),10215+'&'\*
2302<%/#+0d715+,.#gVRF#i71(&862<'\*
8;#]7db)U0=?A%-0N%h&8;23718;#)CD7189*
#cf\0d7U0d0#:7U*h&89[0d,10#]7
a8;#&h)2*->S715+,W#&2dp

w t}ffsyx wbz

{

{

" # su}!|{usy{s t#}ffsWx0} w z 8;2*
#+0R71()%7U%-h&h)28;#&>{*-,.?%7189*
#73*N71(+0Fh&8;%-49*-L
5+0-VGa5)C.(
$
715&,.#&2ACD*
#&217189715+730i<()%78;2Cd%-4;490hvaAutxz{Asx~~D wm.w-r&dx.~ds-QzQw-r&V^'\0%-0d,.2
5)23071(+089,c8;#]730d,1E-0#718;*
#&273*'&,1*Ea8;h+08;#+>*-,.?A%718;*
#71()%7>Q%-Cd8;4;8;71%730271(+0'&,1*-L-,10212*->
71(&073*-'t8;C*->$CD*
#E-0d,W21%7189*
#V #]730d,1E-0#718;*
#&2?A%_`f\0 'sq$=|{u)~Xx0} wc!z <(+0#71(+0d_
>*-,.?@5&4;%7308;#]E^8971%718;*
#&2db,10^5&89,10?0#]712dbZ*\0d,.2dbY,.0d'[*-,.712dbZ0d71CV9bR*-, }uq$y{s~x0} wz
R(+0#71(+0d_%-#&23U0d,Z*-,Y0dE%-465&%730e71(+0F'&,10dEa89*
5&2Z21'[0%-0d, Q2Y8;#]730d,1E-0#718;*
#VK8;#&%-4;49_-ba71(+0d_
Cd%-#c%-4623*=f\0 z|= u) su}!|{usy{s~x0} w J z b^<(&8;CW(/862%@,10%-CD7189*
#71()%7f\0dL
8;#&2U%-2Z%
,.023'\*
#&230@73*c71(+0N'&,10dEa89*
5&2F23'\0%-0d,2B8;#]730d,1E-0#]7189*
#b%-#&h:0#&h)2$%-2k%-#H8;#73,.*^h&5)CD7189*
#*->
#&0d8;#+>*-,.?A%7189*
#gV
" ys's]t#'s t#}ffsx w z ,10d'),10230#]712B%-#H0?'&7_715+,W#bg<(&86C.(8;2B^5&89730N7_^')8;Cd%-4*->
%4;8;23730#+0d,BR(+*
230A%-8;? 862B71(+0>*-,.?A%-4,1086#+>{*-,WCD0?0#7e%-#)hH,.%718tCd%718;*
#H*->71(+0ACd%-237k*->
CD*
#]E-0d,.21%718;*
#&%-4g,1*
4;02dVUa5&CW(c8;#]730d,1E-0#718;*
#&2<4;%-C.86#+>{*-,W?A%7189*
#V

x z PQ%-4;21*}Cd%-4;490h ur #q2s2u T8;2i%210]5+0#)CD0*->=715&,.#&2c(+0%-h+0hf]_ %-#
86#&89718;%7189*
#`8;#]730d,1E-0#718;*
#715+,W# P X Tk%-#&h0#)h+0hf^_%,10%-CD7189*
#8;#]730d,1E-0#]7189*
#715+,.# P X TWV
X<(&8;2>{*-,W? *->=%-#&%')(&*-,.%ab$86#R(&8;C.( 71(+0H,.0d>{0d,10#)CD0%')'[0%,W2<8971(&8;# %-# %-h1%-CD0#&CD_ ')%-89,b
%')'[0%,W2Z73*Af\0BE-0d,1_CD*
?A?*
#86#ch&8;%-49*-L
5+02=PQ+*\bSln-o
-TWV



)q$usq2}x

VXY(+073*-'t8;C?@5&237gf\0%<4;0Da8;Cd%-489730? 71(&%78;2,10d>0d,1,10hB73*R>{,.0]5+0#]7149_-V"RCdCD*-,.h)8;#+L
73*Y*aC.()% Pmln-n-o
TWb$>{*
5&,>0%715+,102%,1071%-0# 8;#]73*`%-CdCD*
5)#7c8;#}71(+02304;0CD7189*
#}*->B71(&0f\0237
Cd%-#)h&8;h&%730>*-,e%ch&8;21CD*
5&,.230N73*-')8;CpF>,10]5&0#&CD_-bg0dE-0#h&862373,.89f)5&7189*
#b)'\*
218;7189*
#:*->G),W237F73*--0#b
%-#)h@210?A%-#7186C%-h+0^5&%-CD_-V"()89L
(&49_F>,10]5&0#70490?0#]7S71()%7*aCdCd5+,.2K8;#]730#&218;E-049_e8;#@%<')%-2.21%L-0
*->71(&0Rh&8;%-4;*-L
5+0Yf)5+7Uh+*^02G#+*-7U%'&'\0%,>*-,49*
#&L=2373,10d71CW(+028;2G#&*-74;89-04;_=73*@f\0<%eL-*^*^hC.(&*
8;CD0
>*-,h&8;21CD*
5&,.23073*-'t8;CV #`71(+0c21%-?0U%_-bG#+08971(+0d,N8;2@%-#0490?0#]7@R(+*
230/),.237@%'&'\0%,.%-#&CD0
*aCdCd5+,.2$%4;*
#+LA%_i>,1*
? 71(&0kf\0dL
8;#&#&86#+LN71(+0kf\0237<CW(+*
8;CD0-q
V O*-,10d*fiE-0d,b230?A%-#]718;Ck%-h+0^5&%-CD_
?@5&237<f[0BCD*
#&2.8;h+0d,10h>*-,<71(+0eCd%-#)h&8;h&%730-b)%-#)hc897Y?=5)237Zf\0e%-2123021230hf]_71(+0k%-#)#+*-71%73*-,V

w x wb xc} z

%-230h`*
#71(&0%f\*E-0DO?0#]7189*
#+0h2373,.5)CD715+,10-b71(+0#b71(+0>*
4;49*fi<8;#+Lc71%L
2@%,10/CD*
#)218;h+0d,10h#+0CO
02121%,._i>{*-,Bh&86%-49*-L
5+0=2173,.5&CD715+,10N%-#&#+*-71%718;*
#p } w b } w b w b x b\%-#&h wb xc} VtXY(&0@"$M %-#&h
XRFM V71%L
2G<864;4^f[0Y5)230h73*=h&0Dt#+0Z71(+0<%-#)%')(+*-,.8;CZ%-CdCD02.2189f)8;46897_N23')%-CD0-b^%-#&hA71(+0<,10?A%-8;#&86#+LF71%L
2
<8;464
f\0Z5&230h@73*B*-f&71%-8;#@71(+0Z%-h1%-CD0#&CD_@')%-89,.2dVXY(+0 X 71%L+b],10d'&,10230#]718;#+LF?A8a0hN8;#]730d,1E-0#718;*
#&2db
8;2B#+*-7B8;#)Cd4;5&h+0h:218;#&CD0?A89^0hH8;#]730d,1E-0#]7189*
#&2BCd%-#Hf\0%-#&#+*-71%730h%-2 X ')4;5)2 X VNXY(&8;2$71%-238;2
h+*
#+0e86#71(+0k%-#&#+*-71%718;*
#c')(&%-230-V
"$#N0Da%-?A')490*->t%-#%-#&#&*-71%730hAh&8;%-49*-L
5&0<8;71(=71%L
2G8;2'&,10230#]730h8;#NK89L
5+,10BlV #@71(+0Zh&86%-49*-L
5+0-b
71(+08;h+0#]718)0d,P!BMUT8;#&h&8;Cd%730271(+0U715+,.#e*->t%Y,.%-8;4;U%_eCD*
?')%-#]_e0?')49*fi_-0d0-b%-#&hk71(+0U86h+0#7189)0d,U-P B&T
8;#&h)8;Cd%730271(+0kCd4;8;0#7d2Z715&,.#V
F#&0*->+71(+0?A*
237S8;?A'[*-,.71%-#7%-h&E%-#]71%L-02K*->a71(&8;2%-#)#+*-71%7189*
#@21C.(+0?A08;2S89712CD*
?'t%7189f)8;4;8;7_$<8971(
?*
237*->+71(+0h&8;%-49*-L
5&0DO%-#&#+*-71%7189*
#@21C.(&0?02S5)230h=86#kh&8;%-4;*-L
5+0G23_a23730?A2dVKIR*-718;CD0-b->{*-,8;#)2371%-#&CD0-b71(&%7
71(+0%-h3%-CD0#&CD_H't%-89,.2B21(+*fi71(+0A2.%-?0/2373,W5&CD715+,10A%-2k71(+0.w-r&dx.~ds-QzQw-rtss%'&')46890h73*i71%-23]O
*-,.890#]730hAh&86%-49*-L
5+02h+0Dt#&0h8;#N71(+0<h&86%-49*-L
5+0Z2373,.5&CD715&,10Zf]b
_ V%,.4;0d7371%/dKs9tPmln-n
-TW
V O*-,10d*fiE-0d,b^*
5+,
?>i>

fi@ 2~,7



2 AK$)B



!P8
!Pp
8

P

! "J

!

P

-

!P"J
!P-

)

! "J
P,

! 8
!

p

!P-

!P"J
!P-
"J





2B2{EDX<{$7

G
F





7BEHK.{JI22

0;?
6/iZ

J



$CA

! "J
!

-

a/", _!()?!)i!
6a;_Zi// ai/!ZP
&)?i
3 :S<!
&
-!Z &
e?& ! 05ie" &
?a upimis?ms
eg ?
-0?Z/Zrui&Ji/3iZc/?Z0a 3_i=3a0!Z
iaa
i;((_p 0;(& q! _pi;!!
5i gZ 0 //_ c3i s?i3a/=
?upi\b p?m!!
5i gi3c& /8
b pimi!6i; =qc s(ffa &)u0a?;pc p
cff&
- /8/!=_ i(Z&//?i3a)i"a/ "
ii&g
i! p (& eiZ qq,g,
6/!a!\?i3a !gi P,3ca
q?8?! p cff& ffi5p!?m!a
-Zu0 0si&/ffii&0 = )a

5i
c !u r
/
:#w!
c !u pau
?ceg,
=-&ip0&Z Zcagm

5i 8
!!q6&& 66sq, i6
=? /i ff8/i ff?0)(i?a
,; ??
6/?i&ig
q(i ?qc66)ppZ!r
p0bZZg/ii!3_!

nWh\.m$W g fi3Yg!f j


8;L
5+,10AlpffLa%-?'t490F*->K%-#%-#&#+*-71%730hh)8;%-49*-L
5+0B>,1*
?
wxut^~fiffWrdw &x3drRDxW~Dwr
?>

fi

i{9 ] DA2

2{~i{

21CW(+0?0R862G%-4;23*@CD*
?')%7189ft490Y<8971(A71(+*
230$71(&%7%,10Rf)%-230h/*
#5+73730d,W%-#&CD0R>Q5&#&CD718;*
#&2db215)C.(%-2G71(+0R*
#+0
h+0Dt#&0h8;#A<e
" OHaJf^_N"$4;490#/%-#&h V*-,10@Pmln-n
-TWVUYe
" OHaJ8;#&h)8;Cd%7302G(+*fi 5&73730d,.%-#&CD02%,10<,.04;%730h
73*71(+0Nh&8;21CD*
5+,W230kf^_?0%-#&2$*->SDwxGsx3|ksrt|:1s
dfiGsx3|wwfizr]@^r[Qzwr+~WVeX<(+0@86#730d,1'),10d71%7189*
#
*->71(+0230e>Q5&#&CD7189*
#)2f)5&8;4;h)2G71(+0e%-h3%-CD0#&CD_]O!')%-89,R2373,.5&CD715+,.0-V86#&%-4;49_-ba*
5+,Y73*-'t8;CB2373,.5&CD715&,10B0Da()89f)89712
71(+0F21%-?0F>0%715+,102%-271(+0NQxmsr&~Ds
QzQwrH2373,W5&CD715+,10R*-
> V%,.4;0d7371%Gs9a*-,71(+0!s~.N9ddgh+0Dt#+0h/f]_
"$4;490#c%-#&E
h V*-,10-V
]

gZ#
ffU fi,
%-230h5+'\*
#i71(+0N%f\*E-0DO?0#]7189*
#+0hH%-#)#+*-71%7189*
#b%-#%-#&%')(+*-,W8;Ck%-CdCD0212.89f)8;4;8;7_c23')%-CD0N8;2R'&,1*-'\*
230h
>*-,=^')%-#&8;2.(8;#:*-,.h&0d,B73*i,1023*
49E-0%-#&%'t(+*-,.2B8;#:71(+0>*-,.?*->U'[0d,W23*
#&%-4'&,1*
#+*
5)#&2dbh+0?*
#&2173,.%7189E-0
'&,1*
#&*
5&#&2db+%-#&hi%-hm0CD7189E%-4g%-#&%'t(+*-,.2dV






u)~E}ff/ys

"$CdCD*-,.h&8;#+L73*+* Pmln-o
-TWb71(+0At,.237e?0#]7189*
#*->Z%,10d>{0d,.0#7@8;#%i230^5+0#&CD0/*->ZCD*
#730Da712N8;2e'\0d,3O
>*-,.?0h<8971(%>Q5&4;4K#+*
5&#:')(&,.%-230-VN"<>730d,e71(&%7dbSf]_:5&218;#+L%-#%-#&%'t(+*-,B71(+0A23'\0%-0d,eh&8;21')4;%_a2F%-#
5&#&h&0d,.2371%-#&h&86#+L71(&%7@210]5+0#)CD0/(&%-2@#+*-7kf\0d0#`Cd49*
230hh+*<#gV 0%-21210d,17k71(&%7@7U*h&8\0d,10#7=230DO
^5+0#&CD02=L-0#+0d,.%730?*
237e*->Z71(+0%-#&%')(+*-,W2e73*f\0A>*
5&#&h8;#h&8;%-4;*-L
5+02dpk71(&0/%-h1%-CD0#&CD_H')%-89,@%-#&h
71(+0N73*-')8;C@21CD*-'\0-VeXY(+0@>*-,.?0d,FL-0#+0d,.%7302B,.0d>{0d,10#)CD02F73*%-#]_4;*^Cd%-4K#+*
5&#')(+,W%-230-b%-#&h:71(+04;%73730d,
L-0#+0d,.%7302R,10d>0d,10#&CD02Z73*/71(+0e?A%-8;#73*-'t8;CB*->71(+0kh&8;%-4;*-L
5+0-V
%-230h*
#i71(&8;2b+0e'),1*-'\*
230B71(&%7Y71(+0=%-#&%')(+*-,.86CB%-CdCD0212189f)864;897_23')%-CD0e>*-,R%-#]_L
89E-0#%-#)%')(+*-,
?A%_f\0eh+0D[#+0hc%-2Z71(+0k210d7Y*->#&*
5&#c')(+,W%-230271%-0#>,1*
?cp
{

71(&0k%-h1%-CD0#&CD_')%-89,YCD*
#]71%-8;#&8;#+L71(&0k%-#&%')(+*-,b+')4;5&2
{

71(&0k%-h1%-CD0#&CD_')%-89,Z'&,10CD0h)8;#+LN71(+0k%-h1%-CD0#&CD_')%-89,YCD*
#]71%-8;#&86#+L71(+0k%-#&%'t(+*-,b+')4;5)2
{

%-#]_c%-h1%-CD0#&CD_')%-89,Y8;#&Cd465&h&8;#+L=71(+0k%-h1%-CD0#&CD_')%-89,YCD*
#]71%-8;#&86#+L71(+0k%-#&%'t(+*-,b+')4;5)2
{

71(&0k#+*
5&#')(&,.%-230B,10d'&,.0230#7186#+LN71(+0k?A%-8;#73*-'t8;CF*->K71(+0kh&8;%-4;*-L
5+0-V




q2t y{z|qy uuwys


}yiy ~q2v

^ 0dE-0d,.%-4*-,.^2$%f\*
5+7<%-5+73*
?A%7186Ce73*-')8;C=h+0d730CD7189*
#:(&%E-0@f\0d0#c')5+ft4;8;21(+0h! Y0d_a#&%,ePmln-n-n
TWb#"*
5aO
?A%-#&2FPmln-nalTU*-, j 0%,.237ePmln-n]T$! V # O%,17?R Q #+0dDO%,.CD*ds9Pmln-n-n
TU%-#%-5+73*
?%718;C$73*-')8;C$h+0d730CO
7189*
#i%-4;L-*-,.8971(&? %-2R%'&')4;890h73*%-#)%')(+*-,.%N,1021*
4;5+7189*
#c8;2Y'&,10230#]730hV
XY()8;2Z%-49L-*-,.8971()? 230490CD712<#&*
5&#')(+,.%-2102ePQIRMTU*^CdCd5&,1,.8;#+LNf\0d>*-,10e%-#i%-#&%')(&*-,VXY(+0230eI$MG2R%,10
8;#&Cd465&h+0hB8;#e%R4;8;23771(&%7S8;271(+0#eU089L
(]730h
V LG%-C.(@718;?A071(+0I$M:%'&'\0%,.28;#=%<#+0d`715+,.#P>,10^5+0#&CD_&TWb
89712UU089L
(7Y862U86#&CD,10%-230hba%-#&h0%-CW(c718;?0F71(+0BI$Mh+*^02U#&*-7%')'[0%,Y86#/%N#+0d 715+,W#PQ86#+>{,.0]5+0#)CD_+TWb
89712UU089L
(7Z8;2h+0CD,.0%-230hVG"$CdCD*-,.h&8;#&L=73*71(&862U%-4;L-*-,.8971(&?cb^71(+0Bh&8;%-4;*-L
5+0R73*-'t8;CF?A%_/f[0Fh+0d730d,.?8;#+0h
f^_:89712B2.%-4;890#&CD0-bg8V0-V9bf]_h+0d730d,.?A86#&8;#+L/71(+0AIRM<8971(:71(+0A(+0%E^8;0237B08;L
(7PQ(&8;L
(>{,10^5+0#&CD_:8;#H%
21(+*-,.7<h&8;2371%-#)CD0fiT*aCdCd5+,1,.8;#&Lf[0d>*-,10@%-#%-#&%')(&*-,V #*-,.h+0d,<73**-f&71%-8;#71(&8;2Y86#+>{*-,W?A%7189*
#PU089L
(]7WTWb
71(+0k%-4;L-*-,.8971(&? 5&2102Z71(+0B>*
4;49*R8;#+LN7U*/CD*^0 K/Cd890#]712dp
{

&%
{



pGCD*]0KCd890#7<*->>,10^5+0#&CD_

pGCD*^0K/Cd890#]7Y*->K8;#+>,10^5+0#&CD_
?>

fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

V % 8;#)CD,10%-2302B71(+0A2.%-4;890#&CD0N*->%c,10d>0d,1,.8;#+L0Da'&,1021218;*
#<(+0#71(+00#]71897_H%'&'\0%,.2B86#71(+0ACd5+,1,10#]7
;8 #]730d,1E-0#]7189*
#c715+,.#gVV h&0CD,10%-2302Y71(&0e21%-4;890#&CD0B*->0Da'&,1021218;*
#&271(&%7<%'&'\0%,10hc86#'&,10dEa89*
5&2Z8;#]730d,3O
E-0#]7189*
#c715+,.#)2f)5+7Y#+*-7Y8;#71(&0eCd5+,1,10#]7Z*
#+0-b)8;#)h&8;Cd%718;#+LN%A49*
2.2*->K86?'\*-,171%-#&CD0-VU*-71(CD*^0K/Cd890#]712
*-f^E^89*
5)2149_i%\0CD7B71(+021%-4;890#&CD0@*->G0Da'&,102.2189*
#&2$8;#,10D)0CD718;#+L71(+089,F>,10^5+0#&CD_%-#&h:71(+08;,$h&862371%-#&CD0
>,1*
?71(&0RCd5+,1,.0#78;#]730d,1E-0#718;*
#715+,W#A<(+0d,.0<71(+0$%-#&%')(+*-,(&%-2f[0d0#/>*
5&#&hVKXY(+0R0D^'&,.0212189*
#<8971(
71(+0(&89L
(+0237@21%-4;890#)CD0A<8;4;4f[071(+0?A*
237k>Q%E-*-,10hCd%-#)h&8;h&%730%-#730CD0h+0#]7N*
#71(&0<(+*
4;0/4;8;217k%-#&h
71(+0d,10d>*-,10e71(&0e?*
237Y,104;0dE%-#]7Y73*-')8;CF>*-,Y71(+0=Cd5+,1,10#]7Y8;#]730d,1E-0#718;*
#c715+,.#V
XY()8;2%-5+73*
?A%718;CY73*-')8;CZh+0d730CD7189*
#/?0d71(+*ahA(&%-271(&0Z>{*
4;4;*<8;#&LF%-h&E%-#]71%L-0<*fiE-0d,*-71(+0d,?0d71(+*ah&2dp
897Fh+*^02$#&*-7R*-f&71%-86#:%218;#&L
490k73*-')86Cb[ft5+7R,W%71(+0d,B%/4;86237<*->73*-')8;C@Cd%-#&h&8;h&%7302$*-,.h&0d,10hf^_21%-46890#&CD0-V
XY(&%78;2U8;?'\*-,171%-#]7>*-,*
5+,%-#&%')(+*-,.%=,1023*
465+7189*
#23_^21730?f\0Cd%-5&210-ba8;>g71(+0F(&89L
(+0237mO!,W%-#+-0hCd%-#&h&8O
h&%730Fh+*^02#+*-7U>Q5&4t4;4^71(+0$,10490dE%-#]7UCD*
#&2173,.%-8;#]712db]71(&0#71(+0$#+0Da7U(&8;L
(+0237GCd%-#&h)8;h&%730FCd%-#f\0<73021730hV
h V VGX<(+0230
#&89718;%-4649_-b]E%-4;5+02Y*->l '5&#&89712Z%-#&hHlk5&#&897dba,1023'\0CD7189E-04;_-b&0d,.0k%-212189L
#&0h73* V % %-#&C
E%-4;5+02ZU0d,10k%,1,W89E-0hc%7Y0Da'[0d,W8;?0#]71%-4;49_-baf)5+7Z>Q5+,171(+0d,Y21715&h+_CD*
5&4;hc490%-hc73*/?*-,10e'&,.0Cd8;230FE%-465+02dV


! *)
1 G g
[U ?
#71(&8;2A210CD7189*
#b71(+0%-#&%'t(+*-,.%H,1021*
4;5+7189*
#%-49L-*-,W8971(&? f)%-210h*
#%`CD*
#&2373,.%-8;#]7%-#&h'&,10d>0d,10#&CD0
%'&'&,.*
%-C.(862'&,10230#]730hV
(K

+,

Qys~E}q{s!~Oq2s

}u.- uw}us#ur~qg~q2s

qg#}y2q$a



q{sqg#y2}q}u)~Eyvty{s

"$CdCD*-,.h&8;#+L/73*/F%-(&490f %-/ C1Pmln-nalTWb71(+0d,10@%,10=%7$'&,10210#7R7U*/f)%-2.8;Ce%'&'&,.*
%-C.(+02F8;#i%-#)%')(+*-,.%,102mO
*
4;5+718;*
#p=PmlT<71(+0N73,.%-h&89718;*
#&%-4S%')'&,1*
%-C.(gb<(&8;CW(L-0#+0d,W%-4;49_h+0d'\0#&h)2<5+'\*
#:4;8;#+L
5&8623718;CBa#+*R490h+L-0-b
%-#&h P
T=71(+0ch&8;2.CD*
5+,.230DO!*-,.8;0#730h%'&'&,1*
%-CW(b86#<()8;C.(`71(+0,10230%,.CW(+0d,73,.8902@73*?*ah+04UCD*
?')490D
h&8;2.CD*
5+,.230B2373,.5)CD715+,102Y%-#&hi71(+0#i5&2302Y71(+0230k2373,W5&CD715+,10273*A,.023*
49E-0k%-#&%'t(+*-,.%aV
"$?*
#+L`71(+073,.%-h)897189*
#&%-4Z%'&'),1*
%-C.(+02bY71(+0iU*-,1*-
> O8;73-*E Pmln-n-o
TWb$U%-46h+<8;#Pmln-n
-TWb$%-#&h
+0d,1, %-Q #&h+0dAds9Pmln-n-n
TU%,10R%-4;4)f)%-230h*
#/%@CD*
?kft8;#&%7189*
#*->g4;8;#+L
5&8623718;CU^#&*<490h&L-0@PQ490D+8;Cd%-4b^?*-,3O
')(+*
4;*-L
8;Cd%-4b23_a#]71%-CD718;Cb%-#)htfi*-,=230?%-#718;CTF>{*-,=71(+0A,1023*
465+7189*
#*->Z%-#&%')(+*-,W%aVXY(+0230A%')'&,1*
%-C.(&02
%'&')4;_:4;86#+L
5&8;237186C=a#+*fi<490h+L-0-b8;#H71(&0%_*->YCD*
#&2173,.%-8;#]712k%-#&h'&,10d>0d,10#&CD02dbK>*
4;49*R8;#+Lc71(+0/*-,1
*-
> V%,1f\*
#+0464%-#&hU,1*fi<#Pmln-o-o
TR%-#&h<8;CW(%-#&hJ5+'\0d,.&*_Pmln-o-o
TWbg8;#cR(&8;C.(215&C.(:23_a23730?A2$%,10
'&,1*-'\*
230hc%-2R%N730C.(&#)8;]5&0e>{*-,RCD*
?kf)86#&8;#+L230dE-0d,.%-48;#+>*-,.?A%7189*
#c23*
5&,.CD02dV
XY(&0230/%'&'),1*
%-C.(+02%,.0/f)%-210hb8;#715)897189E-049_-b*
#71(&0/>*
4;49*fi<8;#+Li71(&,10d021730d')2dpPmlTkh+0Dt#&8;#&L%-#
%-#&%')(&*-,.8;CF%-CdCD0212189ft8;4;897_/23')%-CD0-bKP
T%'&')4;_^8;#&L@CD*
#&2173,.%-8;#]712db)%-#&hP
TZ%'&')49_a8;#+L@'&,10d>0d,10#&CD02dV
"CD*
#&2373,.%-86#7<%-#)h'&,10d>0d,10#&CD0k23_a23730? ?@5&237Yh&0Dt#+0-b+*
#c71(+0B*
#&0k(&%-#&hba71(+0=%-#&%')(+*-,.86C$%-CdCD023O
2189ft8;4;897_=23')%-CD0-VXY(&%7862db]897U?=5)237G*-f&71%-86#/%@4;8;237G<8971(%-464&71(+0$'\*
212189f)4;0YCd%-#&h&8;h&%730$%-#730CD0h&0#712dVZF#
71(+0F*-71(+0d,Y(&%-#)hba71(+0B23_^21730? ?=5&217U%-4;21*Nh&0Dt#+0$71(+0B730D^7Z230dL
?A0#712Y86#/R(&8;C.(/71(+0e%-#]730CD0h+0#]7<Cd%-#
f\0B>{*
5)#&hVXY(&862Z23730d'(&%-2R%L-,10%7R86?'\*-,171%-#&CD0F>{*-,R71(+0e,10?%-8;#&8;#+LN23730d')2R8;#71(+0e'),1*^CD02.2Zf\0Cd%-5&230
%h+0Dt#&89718;*
#c*->71(+0@%-#&%')(+*-,.86Ck%-CdCD021218;f)8;4;897_c23')%-CD0@71(&%7$862<73*^*#)%,1,1*,10215)49712<8;#71(+0=0DaCd4;5)2189*
#
*->E%-4;8;h%-#730CD0h+0#]712dVkJS89-0d<8;210-b[%h+0Dt#&8;7189*
#i*->71(&0@%-#&%'t(+*-,.8;C=%-CdCD0212189f)864;897_i21')%-CD0N71(&%7$862<73*^*
f&,1*
%-h,10215&4971286#4;%,1L-0Cd%-#)h&8;h&%730i4;8623712dbGR8971(%CD*-,1,1021'[*
#)h&8;#+LH8;#&CD,.0%-230i8;#71(+0i4689-04;8;(+*^*ah`*->
0d,1,1*
#&0d*
5&2N%-#&%')(+*-,.%:,1021*
4;5+7189*
#V $215&%-4;4;_-b%-#&%')(+*-,.%:,1021*
4;5+7189*
#23_a23730?A2Nf)%-230h*
#4;86#+L
5&8;237186C
a#+*<4;0h+L-0/PQ+0d,1, %-Q #&h+0d@0d7<%-4V9bSln-n-n
TRh+0D[#+0e%-#%-CdCD0212.89f)8;4;8;7_23')%-CD0=5)218;#+Lcr'&,10dEa89*
5&2<230#730#)CD02
73*A71(+0=%-#&%')(+*-,b+R(+0d,10r8;2E%,W8;%f)490e%-CdCD*-,.h)8;#+L73*A71(+0k^8;#)h/*->K71(+0e%-#)%')(+*-,.%aV
F#)CD0Y71(+0<4;86237K*->['\*
212.89f)490Cd%-#&h&8;h)%7302G8;2h+0D[#+0hb230dE-0d,W%-4)CD*
#&2373,W%-8;#712%,10<%'&'t4;890h8;#N*-,.h&0d,73*
,10?*fiE-0A8;#&CD*
?'t%7189f)490@%-#730CD0h+0#]712dVNXY(+0CD*
#&2373,W%-8;#7B23_a23730? CD*
#&2.8;23712$*->CD*
#&h)897189*
#&2$71(&%7B?@5&237
f\0@?A0d7db\%-#)h:Cd%-#)h&8;h&%7302$71(&%7Bh+*#+*-7$>5&49t4;471(+0210NCD*
#)h&897189*
#&2R<8;464g#+*-7Ff\0=CD*
#&2186h+0d,10h'[*
2.2189f)490
?>

fi

i{9 ] DA2

2{~i{

%-#]730CD0h+0#712Y>{*-,U71(+0F%-#&%')(+*-,VJ0Da86Cd%-4b^?A*-,1')(+*
49*-L
86Cd%-4b]23_a#]71%-CD718;Cd%-4b+%-#&h230?A%-#]718;CF8;#+>*-,.?A%7189*
#
%,10e73,W%-h&897189*
#&%-4649_5&230h73*/h+0Dt#+0B71(+0=CD*
#&2373,.%-8;#]712dV
K8;#&%-4649_-bY%>{730d,c,.0?*Ea8;#+L8;#&CD*
?A')%7189f)490Cd%-#&h&8;h&%7302bR89>B71(+0,10?%-8;#&8;#+L`4;8;237CD*
#71%-8;#)2c?*-,10
71(&%-#*
#+0B%-#]730CD0h+0#]7db&'&,10d>0d,10#&CD02Z%,10B%'&'t4;890h8;#*-,.h+0d,73*AC.(+*^*
230e%N218;#&L
490R%-#]730CD0h+0#]7dV #71(&8;2
Cd%-230-b+5&#&4689-0Y71(&%7U*->gCD*
#&2373,.%-86#712db^'&,10d>0d,10#&CD02U%,10F%-2123*aCd8;%730h<8971(/4;89-04;8;(&*]*ah49*U0d,71(&%-#:l '1',NV
V%-#&h)8;h&%7302B>Q5&4t464;8;#+L%i'&,10d>0d,10#&CD0-b71(&0#bS(&%E-0/%cL-,.0%730d,@4;8;-04;8;(+*^*^h*->f\08;#+L71(+0%-#]730CD0h+0#]7
71(&%-#71(+*
230#+*-7R>5&49t4;4;8;#&LN8;7dVRXY(+0='&,10d>0d,10#&CD0@23_^21730??@5&237$f\0=h+02.89L
#+0hif\0%,.86#+L8;#:?A8;#&hi71(&%7
*
#&49_*
#+0ACd%-#&h&86h&%730?=5&217B,10?A%-8;#%7B71(+00#&hgV@XY()8;2Rt#&%-4KCd%-#&h&8;h)%730<8;4;4Sf\0@'),1*-'\*
230h%-2B71(+0
%-#]730CD0h+0#7>*-,@71(+0%-#)%')(+*-,VJg0D+8;Cd%-4b?*-,1't(+*
49*-L
8;Cd%-4b23_a#]71%-CD718;Cb%-#&h230?A%-#]718;C8;#+>*-,.?A%7189*
#
%,10k5)215&%-4;49_/5&230hc8;#c*-,Wh+0d,Z73*/h+0D[#+0F71(+0e'&,10d>0d,10#&CD0e21_^23730?iV
XY(&0$U*-,1a2Z*-
> O8973-*fiEPmln-n-o
TZ%-#&hi&0d,1, %-Q #&h+0d/s9Pmln-n-n
TY21(&* 71(&%7<%-#)%')(+*-,.%@,1023*
465+7189*
#
23_a23730?A2cft%-230h *
#CD*
#&2173,.%-8;#]712i%-#&h '&,10d>0d,10#&CD02Cd%-# _^8;04;h 215&CdCD02121>5&4$,102.5&49712<(+0# %')')4;890h
73*`#&*
#aOh&8;%-49*-L
5&0i730D^712V j *fi0dE-0d,bR71(+0230*-,1a24;%-C1%-h+0^5&%730:'&,1*-'\*
21%-4;2A>{*-,/71(+0%-#&%'t(+*-,.8;C
%-CdCD021218;f)8;4;897_23')%-CD0-V&5&,171(+0d,.?*-,.0-bY71(+0230:%'&'&,1*
%-CW(+024;%-C1}CD*
#)218;23730#&CD_86#71(+073,10%71?0#]7*->
*-71(+0d,R^8;#)h&2U*->730Da712db&>*-,Y0D+%-?')490-bth&8;%-49*-L
5+02V
+,

x 32

w uq2s#qg#y2}q}ur~y{v't ysIq2v/2y2}ff!z



z

#i71(&8;2R230CD7189*
#bt71(+0=86#715&8;7189E-0k%-49L-*-,.8;71(&? >*-,R%-#&%'t(+*-,.%A,.023*
4;5+7189*
#8;#23'\*--0#h&8;%-49*-L
5+0=23_^21730?A2
PQ"$<F8{TN8;2N'),10230#]730hV}"$<F8Z*-'\0d,.%7302AR8971(23_a#71%-CD718;C8;#+>*-,.?A%7189*
#'&,.*Ea8;h+0hf^_`71(+0PRMM
')%,17186%-4K')%,.230d,/PQ&0d,1, %-Q #&h+0d-bKMK%-49*
?A%,5
b 4 O*-,10#+*+bln-n-o
TWViP $MGM 8;2Ff)%-230hH*
#%c')%,1718;%-4K,.0d'&,10DO
230#]71%7189*
#*->2149*-7R5)#&8tCd%7189*
#iL-,.%-?A?A%,F%-#&%-49_a218;2kPQ&0d,1, %-Q #&h+0d@0d7F%-4V9bSln-n-n
TWV$XY(&8;2<')%,1718;%-4,.0d'&,10DO
230#]71%7189*
#HL
89E-02k23*
?0*->U71(+0A5+73730d,.%-#&CD0/CD*
#&237189715+0#]712db2.5&C.(H%-2eI$MG2bMGM2dbgE-0d,1f)%-4CW(]5)#+^2b%-#&h
')%,17186%-4t8;#&>{*-,.?%7189*
#/%f\*
5+7215+f\*-,.h)8;#&%730hCd46%-5&2302dVXY(^5&2dba"$<F8\CD*
?kf)86#+02U7U*@a8;#&h)2G*->ga#+*fi<4O
0h+L-0Y%f\*
5+7h&8;%-4;*-L
5+02dpPmlTK468;#+L
5&8;21718;Ca#+*<4;0h+L-0-b
215&CW(%-2490D+8;Cd%-4b-?*-,1')(&*
49*-L
8;Cd%-4b-%-#&h23_a#]71%-CD718;C
a#+*<4;0h+L-0-g%-#&hP
TR^#&*<490h&L-0N%f\*
5+7$71(+0h&8;%-4;*-L
5+0-2F2373,.5&CD715+,.0@897121049>b[<(&86C.(:8;2$f)%-230h:*
#71(+0
%-#&#+*-71%718;*
#*->Y%-h1%-CD0#&CD_'t%-89,.2 * %-#&h^#&*<490h&L-0/%f\*
5+7e71(+0/73*-')8;C*->Z71(+0/h&86%-49*-L
5+0PQ?A%-#^5&%-4;4;_
%-#&#+*-71%730h[TWVK89L
5+,10kA21(+*R2Z71(+0e%-#&%')(&*-,.%,1023*
465+7189*
#'&,1*aCD0h&5+,10-V
"$<F8g8;2Yf)%-230hb&8;#]715&89718;E-049_-ba*
#c71(+0e>*
4;49*fi<8;#+LN71(+,10d0e21730d')2dp
lV$Ff&71%-8;#c%-4;4'\*
212.89f)490F%-#730CD0h&0#712R>{,.*
? h&8;%-49*-L
5&0F2173,.5&CD715+,10e%-#)hc73*-')8;CB%-2<>{*
4;4;*<2dp
PQ%T71%-071(+*
210UI$MG2S71(&%7S%,.0U8;#)Cd4;5&h+0hB8;#k71(+02.%-?0U%-h3%-CD0#&CD_k')%-89,UPQ"$MUT%-2S71(+0%-#&%'t(+*-,b
%-#)h
Pf[T/71%-0H71(&*
230HIRM2/71()%7%,.086#&Cd4;5&h+0h}8;#}71(&0:'),10dE^8;*
5&2/"$M73*71(&%7cCD*
#71%-86#&8;#+L71(+0
%-#)%')(+*-,b&%-#&h
PQCT71%-0B71(&*
230BIRM271(&%7Z%,10B8;#&Cd4;5&h&0h8;#/71(+0F?*
237,10CD0#]7Y5&#&Cd49*
230h"$MCD*
#71%-86#&8;#+L@71(+0
"$M CD*
#71%-8;#)8;#+L71(+0e%-#&%'t(+*-,b&%-#&h
PQhtT/71%-0=71(+0e73*-')86CF*->71(&0eh&8;%-49*-L
5+0
^V<F8;2.Cd%,.hi8;#&CD*
?A')%7189f)490B%-#]730CD0h+0#]712<f^_%')')49_a8;#+LN4;8;#+L
5&8623718;C$CD*
#&2373,.%-8;#]712db&%-2<>{*
4;4;*<2dp
PQ%T>*-,Y'&,.*
#+*
?A8;#&%-4\%-#&%'t(+*-,.%ap
6h\$B
QWm /.!<.R WWefi!
WRWfiWk!mfi!c uW3/!fi$\.6/
fffi."
%"2n*87#Q9 ;:=< j> )
NgN!= mQ!.G_
.6

.fiWFgAW-m.!! <@_Z
=
fi . fimS!
!g!fi$BWQ WmfiRW3
?d

fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

@BA1CEDGFH?IBAJFLKBMJNBO?PGQJRSOGTVUXWZY[P\UXWBWJNE]B]
P1FG^_WBTWB@B`EOGKba_^cEFedGfJdGgBcEC?AhW
P1FG^_WBW1Nea_dGfEdgBcEC?Ai?DjdEDBDGFJkBk1ilminEi=^Boek=gEdEDFep?AJC=qrW
P1FG^sP.SN?Rtasd_nEik^tP\U[WBWJNu]jCp_d1nBnvTB@ukwUxdGf1^JFEDFH1FGf1^tDGdGfJHuiH1d?^JFJk1]
pA1C=qrWBWJN
yJCGArFBdJD=ctTB@zifrPuSN?RZY{dGgBgEnGorDGCGfk=^BAJduif.kjCpjqC?AgcEC1nC?|.iDGd1n
d?|AJFBF=qFf1^vlEF?^?}EFBFGfhT@rdGf1HeWTBWB@B`EOKh^JC_Cl1^JduiftPuSN?R~
FGf1H_p1CGA
yJCGArFBdJD=ctTB@zifrPuSN?R~mY&dgBgunGoDGCGf.k^BAJduifkCpkofB^JdED^i?DbDGCGfJHui=^iCGf.k
lEFG^}EFBFGfbTB@rdfJHtWTBWB@B`EOKb^JCtCGl1^JduiftP.SN?RJ
FGf1H_p1CGA
yJCGArd1nnbT@ifsP.SNGRJ\Y&dGgBgEnGo_nEif1|?Imik^i?DjdGfJHeH.ikDGCGI1A.kFtk^BAI.D^I1AJdBn
g1A1Fp1F?AJFfDGFEkUift^cEFtC?A1H1FGAeH1FEkBDA.ilEFHsifk^1FGgshlEFBnCG}z]
IBfB^iGnP.SN?RJ5fia~
FGf1H_p1CGA
KJFG^I1AftP.SN?RJ
FGf1Heg1A1CEDGFH?IBAJF

K89L
5+,10k^pG"$#&%')(&*-,.%N,1023*
4;5&7189*
#'&,1*aCD0h&5+,10
8VYh)8;21Cd%,.h71(+*
210k%-#730CD0h&0#712R71(&%7<h+*/#+*-7Y%L-,10d0=86#L-0#&h+0d,b&#^5&?=f[0d,b&%-#&h'\0d,.23*
#
8;8!Vh)8;21Cd%,.h:71(+0A%-#]730CD0h+0#]712e71(&%7e%,10A#&*
#aOCD*O!,10d>0d,10#7=%-CdCD*-,.h&8;#+L73*c71(+0N>*
4;49*fi<8;#+L
,W5&490-p
" '&,1*
#+*
5)#M8;2N#+*
#aOCD*O!,10d>0d,10#]718;%-4<8971(%PQ#+*
#aO!,10Dt0Da89E-0*-,A#+*
#+O!,10Cd89'&,1*aCd%-4{T
#&*
5&#c')(+,W%-230BI8;>S%-#]_*->71(+0e>*
4;49*fi<8;#+LCD*
#&h)897189*
#&2 3 (+*
4;hgp
{ M}%-#&hcI %,.0e8;#71(+0e21%-?0e5+73730d,W%-#&CD0e%-#&hcCd4;%-5&210-b&%-#&hcM%-#&hcI?*ah&89>_A71(+0
(&0%-hc*->K71(+0e21%-?0kI$M
{ M%-#&hI%,10A8;#:71(+021%-?A0A5+73730d,.%-#&CD0A%-#&hCd4;%-5)230-bg%-#&hHMh+*^02F#+*-7e?*ah&89>_
71(&0e(+0%-hi*->K%-#_cI$M
Pf[T/>*-,<%-h30CD7189E-0@%-#&%')(+*-,.%ap
8VYh)8;21Cd%,.h71(+*
210k%-#730CD0h&0#712R71(&%7<h+*/#+*-7Y%L-,10d0=86#L-0#&h+0d,
8;8!Vh)8;21Cd%,.h71(&*
230%-#]730CD0h+0#]712/R(+*
230(+0%-h#+*
5&#862A#+*-7A*->F71(+0:490Da86Cd%-4YCd%730dL-*-,1_
OEOHF

V<
^V >G?*-,.0=71(&%-#*
#+0N%-#730CD0h&0#7e8;2$490d>7db[t49730d,$71(+0=,.0?A%-8;#&8;#&LA%-#730CD0h+0#]712Bf^_%'&')4;_^8;#&LA71(+0
>*
4;49*fi<8;#+LNU089L
(]730hi'&,10d>0d,10#&CD02p
PQ%T>*-,Y'&,.*
#+*
?A8;#&%-4\%-#&%'t(+*-,.%ap
8VY%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k21%-?0k"$M}%-2<71(+0e%-#&%')(&*-,=P08;L
(7 -

#fi6m_YZY.1D6fi!K31!.!mQ!!t.!\!-m,d.
W6 .!mm.9Q;:^ >
.3$<!mS!mQ!!<!fi!fi6m6fi !"
!fimKm!g
]
WfiF
3WQ9 :: j=>
[Kfi!W-
mfi!fi
Wffdfg6fi fi!Wcifi6m;fi !
!Y.fi!3(
. ]q\h fimZmfi!fi1!YWfi3=!R!fi
QidW!Gi
.6Y
.!efi!1 fi3d
$!fi.! W+.!3\
h B.!U
J. !3.KZ
-.fim 3WfiG[fiufiW

d!!
.6Y
.!$RS!-W!W9
?

fi

i{9 ] DA2

2{~i{

8;8!V%-#]730CD0h+0#]712i71(&%7i%,.086#71(&0:'),10dE^8;*
5&2/"$M 73*71(&%7cCD*
#]71%-8;#&8;#&L`71(+0%-#)%')(+*-,
PU089L
(]fi
7 B 'T
8;868VU%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k?*
237Y,.0CD0#7<5)#&Cd49*
230hc"$MPU089L
(]7 B'T
89EtVY%-#]730CD0h+0#]712F8;#71(+0B73*-')8;C/P089L
(]
7 l

EtVY%-#]730CD0h+0#]712K71(&%7S%')'[0%,S<8971(k71(+0E-0d,1f@*->+71(+0%-#)%')(+*-,S?A*-,1071(&%-#=*
#&CD0$PU089L
(]7


E^8VY%-#]730CD0h+0#]712B71(&%7F%,10N8;#71(&0@21%-?A0='\*
2189718;*
#c<8971(,10d>0d,10#&CD0@73*/71(+0@E-0d,1fH%-2$71(+0
%-#)%')(+*-,=Pf\0d>*-,10B*-,R%>730d,TDPU089L
(
7

E^8;8!V%-#]730CD0h+0#]712Y71(&%7Y%,.0e8;#71(&0e21%-?0F'\*
21897189*
#/<8971(,10d>0d,10#&CD0B73*N71(+0e5+73730d,W%-#&CD0e%-2
71(&0k%-#&%')(+*-,@P089L
(]
7

E^8;868V71(&0e#+0%,10237Z%-#]730CD0h+0#7<73*71(+0B%-#&%')(+*-,kPQ5&210h<(+0#?*-,10F71(&%-#*
#+0BCd%-#&h)8;h&%730
*-f)71%-8;#&2Z71(+0=(&89L
(+0237E%-4;5+0fiT
Pf[T/>*-,<%-h30CD7189E%-4%-#&%'t(+*-,.%ap
8VY%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k21%-?0k"$M}%-2<71(+0e%-#&%')(&*-,=P08;L
(
7 -

8;8!V%-#]730CD0h+0#]712i71(&%7i%,.086#71(&0:'),10dE^8;*
5&2/"$M 73*71(&%7cCD*
#]71%-8;#&8;#&L`71(+0%-#)%')(+*-,
PU089L
(]fi
7 l 'T
8;868VU%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k?*
237Y,.0CD0#7<5)#&Cd49*
230hc"$MPU089L
(]
7 l 'T
89EtVY%-#]730CD0h+0#]712F8;#71(+0B73*-')8;C/P089L
(]
7 -

EtVY%-#]730CD0h+0#]71271(&%721(&%,.071(+021%-?0a8;#&hF*->a?*ah&8)0d,W2P0-VL+V9b'),10d'\*
21897189*
#&%-4')(&,.%-2302db
%-hm0CD7189E-02bt%-#&hc23**
#tTBPU089L
(fi
7

E^8VY%-#]730CD0h+0#]712F<8971(c0D+%-CD7149_c71(+0=21%-?0=?A*^h&89)0d,.2eP0-VL+V9b\71(+0=2.%-?0k%-h30CD7189E-0,10h
PU089L
(]fi
7

E^8;8!V%-#]730CD0h+0#]712$71(&%7<%L-,10d0k86#c#]5&?=f\0d,kP08;L
(
7

E^8;868V71(&0e#+0%,10237Z%-#]730CD0h+0#7<73*71(+0B%-#&%')(+*-,kPQ5&210h<(+0#?*-,10F71(&%-#*
#+0BCd%-#&h)8;h&%730
*-f)71%-8;#&2Z71(+0=(&89L
(+0237E%-4;5+0fiT
XY(&0230'&,10d>0d,10#&CD02NU0d,10ch+0dE-049*-'\0h%-2A%:,10215&497@*-><71(&00?A')89,.8;Cd%-4U23715&h&_0D^'t4;%-8;#+0h8;#71(+0
>*
4;49*R8;#+L230CD7189*
#V
Tt

#71(&8;2F230CD7189*
#bS%-#0D^'\0d,.8;?A0#71%-4K23715&h&_*->U71(+0%-49L-*-,.8971(&? 862R'),10230#]730hb8;#&Cd465&h&8;#+L/%ch+0d0d'h+0DO
21CD,.8;'&7189*
#B*->+71(+0G0D^'\0d,.8;?A0#712dbCD*-,1'\*-,.%R%-#&he73*^*
4;25)230hb%-2U04;4%-2%<21715&h+_B%f\*
5+7g71(+0U8;?'\*-,171%-#&CD0
*->K71(+0e%-#&%')(&*-,.8;CB%-CdCD021218;f)8;4;897_/23't%-CD0-V
K{

\

Qy{}!y2}q\y]y{v/~1?q2s

u)~E}ff=#y{sIy-)ur\iu}ff'z

usi~

#c*-,.h+0d,Y73*0dE%-4;5)%730e71(+0e%-#&%')(&*-,.%,1023*
465+7189*
#c%-49L-*-,.8;71(&?'&,1*-'\*
230hc8;#71()8;2Z')%'\0d,ba71(+0eL-0#&0d,.%-4
'&,1*aCD0212Z*
5&714;8;#+0h8;#iK89L
5&,10eNU%-2<>{*
4649*U0hV
F%71%/>{*-,Y71(&0e0dE%-465&%7189*
#cU0d,10e71%-0#>{,.*
? 71(+L
0 wxut^
~ ffWrDw &x1Dr RDxW~Dwr)bt%ACD*-,1't5&2Z*->B '
73,.%-#&2.CD,.89f\0h23'\*--0#`^')%-#&8621(h&8;%-49*-L
5+02e'&,1*Ea8;h+0h:f^_71(+0A%-215+,.h+0AMG,1*30CD7/PQ%-215+,.h+0/M,1*30CD7db
ln-n-o
TWVGXY(&0230Yh&8;%-49*-L
5&02%,10YCD*
#E-0d,W21%7189*
#&2Gf[0d70d0#%B,.%-8;49%_@CD*
?')%-#]_N0?')49*fi_-0d0Y%-#&hA%BCd4;890#]7dV
XY(+0U73,.%-#&2.CD,.89'&73*-,K5&230h@8;#=71(+0U%-215&,.h+0M,1*30CD7K'&,1*Ea8;h+02S715+,.#@%-#&h@23'\0%-0d,?A%,1a5+'gVF5+7*->\B '
h&8;%-4;*-L
5+02dbgJ 'cU0d,10A2304;0CD730h>*-,e71(+073,.%-8;#)8;#+LP73,.%-8;#&86#+LcCD*-,1')5&2WT$%-#)h71(+0A,10?A%-86#&8;#+LliU0d,10
?

fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

X x $
xu
x= $x
$XxxxXXx$
X x $



x $
X G
G
8X$ ?X$
G

x=
x$
xXX$x$
xXx$X$
Xx$
$$

x
x $


XBx x;xX
X=[==X
G 8
u $

8;L
5+,10k^pG&5)4;4\0dE%-465&%7189*
#c'&,.*^CD0212
,10230d,.E-0h>{*-,71(+0Rt#&%-4t0dE%-465&%7189*
#HP730237YCD*-,1')5)2WTWVXY(+0230BB'h&8;%-49*-L
5&02UCD*
#]71%-8;#i='&,1*
#&*
?A8;#&%-4
%-#&%')(&*-,.2Y%-#&hi-
A%-hm0CD718;E%-4g%-#)%')(+*-,.2dV
0(&%-hH7U*%-8;?A2e8;#H5)218;#+Lc71(+073,.%-8;#&8;#&LCD*-,.')5&2dp/PmlTB73*i023718;?%73071(+086?'\*-,171%-#&CD0*->71(+0
2373,.5)CD715+,.%-4%-#&%')(+*-,W8;C%-CdCD0212.89f)8;4;8;7_23't%-CD0-b%-#&h P
T=73*Hh+0Dt#+0%-#%-h+0^5&%730i230d7N*->RCD*
#)2373,.%-8;#]712
%-#&h'&,.0d>{0d,10#)CD02P0D^'\0d,.86?0#71
2 'abGlb^b%-#&h
TWVAXY(+0730217kCD*-,1')5&2F%-2B,10210d,1E-0hH73*i*-f&71%-86#H71(+0
t#&%-4\0dE%-4;5&%718;*
#V
#%-h)h&897189*
#bt71(+0@0#7189,.0@CD*-,1't5&2<%-2F?A%-#^5&%-4;49_i%-#&#&*-71%730hR8971(7*ch&89[0d,10#]7<L-*
%-462dp=PmlT<73*
8;h+0#]7189>_F>5+,.71(+0d,Sh&8621CD*
5+,.2302373,.5&CD715+,W%-4
'&,1*-'\0d,1718;02215&CW(=%-2%-h1%-CD0#&CD_e')%-8;,.2%-#&h=73*-')8;Cd2b%-#)hP
Tg73*
8;h+0#]7189>_R%-#&%'t(+*-,.2g%-#&hk%-#730CD0h+0#]712dV"$4971(+*
5+L
(BU0G%-#&#&*-71%730he71(+0GCD*-,.')5&2g?A%-#^5&%-4;4;_-b71(+0d,10%,.0G%7
'&,10210#7K23*
?0%-5+73*
?A%718;C23_a23730?A2>*-,K'[0d,.>{*-,.?8;#+L<%-h1%-CD0#&CD_e't%-89,S71%L-L
86#+LAP71(+0U%-215&,.h+0M,1*30CD7
PQ%-215+,.h&0UMG,1*m0CD7dbtln-n-o
TWb>*-,0D+%-?')4;0fiTWb
%-2K04;4^%-2K>*-,K%-5&73*
?A%718;CU73*-')8;C71%L-L
8;#+LPQ<0d_^#&%,b&ln-n-n

*-,Z%-5+73*
?A%718;CF73*-'t8;C<0Da73,.%-CD7189*
#PQ210d0$71(&0F?A0d71(+*^h>*-,Z%-#&%')(+*-,.%=,1023*
465+7189*
#h+021CD,.89f\0h/8;#a0CD7189*
#
]TWV
XY(&0%-#&#+*-71%7189*
#*->eCD*
#]E-0d,.21%7189*
#&%-4$2373,.5)CD715+,10i%-2/Cd%,.,.890h*
5&7/%-2h&021CD,.89f\0h8;#71(+0#+0Da7
')%,.%L-,W%')(V"R#8;?A'[*-,.71%-#7%-23'\0CD7*->Rh)8;%-49*-L
5+0c2373,.5)CD715+,10c%-#&#+*-71%7189*
#}8;2@71(+0c73,.%-8;#&86#+L't(&%-230-b
<(&86C.(c%-21215&,102Z,104;86%f)8;4;897_A%-?*
#+L%-#)#+*-71%73*-,.2dV
XY(&0%-#&#+*-71%7189*
#')(&%-230%-2k%-CdCD*
?A')4;8;21(&0h%-2e>*
4;49*fi<2dp/PmlTB7U*%-#&#+*-71%73*-,W2kU0d,102304;0CD730hb
P
T<%-#%L-,10d0?A0#7 9 %-2<,10%-CW(+0h:f\0d7U0d0#71(&0k7U*%-#&#+*-71%73*-,.2F<8;71(c,10dL
%,.h:73*71(&0@%-#&#&*-71%7189*
#
21CW(+0?0R5)218;#+Le%B73,W%-8;#&8;#+LeCD*-,.')5&2dbtP
T71(+0R%-#)#+*-71%7189*
#A%-271(+0#Cd%,1,W890h*
5+7f^_f\*-71(A%-#&#+*-71%73*-,W2
8;#N')%,W%-4;4904^*E-0d,U71(+0Z730237GCD*-,.')5&2db%-#)hiP]TK%B,104;86%f)8;4;897_e23715&h+_=U%-2Cd%,1,.890hN*
5&7*
#71(+0<%-#&#&*-71%7189*
#
6P V%,.4;0d7371%/dKs9\ln-n
-TWVGXY(+0Z,10468;%f)8;4;8;7_e23715&h&_@5&210h71(+0B-sWu
uasR2371%718;237186CZ71(&%7G?0%-2.5+,10271(+0R
% K/#aO
<h\.!mZdg-Wfigg1SDYZm\!UmDR!..!WggfiF .3R!!Km.!fim
?d

fi

i{9 ] DA2

2{~i{

897_f\0d70d0#71(+0=%-#)#+*-71%7189*
#&2<*->71(+0e7U*%-#&#+*-71%73*-,.2Rf]_c?A%a8;#+LB35&h&L
?0#712R%f\*
5+7<Cd%730dL-*-,.8902V
+*-,$CD*
?')5+718;#&L71(+0NsWuuasHPdT2171%718;23718;Cb)210d0@a890dL-04g%-#)h V%-237304;4;%-#`Pmln-o-o
TWV 8
U0Cd%-5&230Z715&,.#&2%,10Z?A%,1-0hh&5+,W8;#+LY71(+073,.%-#)21CD,.89'&718;*
#k')()%-230-b-71(+0Z%-#&#+*-71%73*-,?0d,.049_kCd4;%-212.8)02
715+,.#)2=%-CdCD*-,.h)8;#+L:73*:71(&0/715+,W#7_]'\02h+021CD,W89f\0h8;#^0CD7189*
#%-#&h71(+0#,104;%7302@0%-C.(8;#)89718;%7189E-0
8;#]730d,1E-0#]7189*
e
# 1 73*89712F,.0%-CD7189*
#8;#]730d,1E-0#]7189*
e
# J bg71(+0d,10df^_h+0Dt#&8;#&L%-h3%-CD0#&CD_:')%-89,W2dVa8;#&CD0
71(&8;271%-212.8;?')49_,10]5)89,102ZCd4;%-212.8tCd%7189*
#b&8;7Y8;20%-218;49_?0%-215+,.0hi5&218;#&L@71(&0sWuuas2371%718;237186CV
VU*
#)Cd5+,1,10#]7149_-bg73*-')86Cd2B0d,.08;h+0#]718)0hVXY()8;2$71%-23U%-2=%-4;23*i218;?A')490-bg218;#)CD071(+0ACD*-,1')5&2k5&230h
>*-,G71(+0230R0D^'\0d,.86?0#712G8;2*-,1L
%-#&8;d0h8;#]73*=21(&*-,17h&8;%-49*-L
5&02G%-#&h0%-CW(h&8;%-49*-L
5+0Y()%-2*
#&49_N*
#+0R?A%-8;#
73*-')8;C$*-,Y71(&0?0-b&%-#&hc218;#)CD0$71(&0230e%,10e8;#]73,1*ah&5&CD0hCd490%,.49_/f]_?0%-#&2*->71(+0eCd4;890#]7d2Z8;#]730d,1E-0#]7189*
#
%7e71(+0f\0dL
8;#)#&8;#+L*->0%-CW(h&86%-49*-L
5+0-V"R2=%,10215&4;7db0h&0d730CD730h#+*ih&8621CD,10d')%-#&Cd8;02Ff[0d70d0#`%-#aO
#+*-71%73*-,.2e<8971(,10dL
%,.h73*c71(+0N73*-')8;CN8;h&0#718[Cd%7189*
#VeXY(+0d,.0d>{*-,10-b71(&0d,10NU%-2B#+*c#+0d0h:73*i?0%-2.5+,10
71(&8;271%-215)218;#+LN71(+0-sWu
uas=2371%718;21718;CV
"$CdCD*-,.h&8;#&L=73
* V%,.4;0d7371%cGs9;b+%/?0%-215&,10?0#]7Uf\0d70d0
# ' -oN%-#&
h ' Bo 'N%-4;49*fi<25&2U73*?A%-0
'\*
21897189E-0cCD*
#&Cd465&2189*
#&2b%-#&h8;
> 8;2NL-,.0%730d,/71(&%-
# ' Bo 'abZ0i(&%E-073*-71%-4<,104;8;%f)864;897_f[0d70d0#}71(+0
,10215)49712*->K71(+0e%-#&#+*-71%73*-,.2V
#71(+*
230iCd%-2102A<(+0d,.0i%Hh&8;21CD,10d't%-#&CD_%-2A>*
5&#&hf\0d7U0d0#71(+0i%-#)#+*-71%73*-,.2db71(+0c>*
4;49*fi<8;#+L
CD,.89730d,W89*
#c%-2R%'&'t4;890hp0%-CW(h&8;%-49*-L
5+0kU%-2$%-212189L
#&0hi%?A%-86#%-#&#+*-71%73*-,$<(+*
210=%-#&#+*-71%718;*
#%-2
CD*
#&2186h+0d,10hh&0Dt#&897189E-0@8;#i71(&0=0dE-0#]7F71(&%7R71(&0d,10=U0d,10Nh&8;21CD,.0d')%-#&Cd8902Zf\0d70d0#71(+0=7U*c%-CdCD*
5&#712V
#*-,Wh+0d,R73*cL
5)%,.%-#730d0Nf)%-46%-#&CD0-b0%-C.(H%-#&#&*-71%73*-,eU%-2$71(+0?A%-86#%-#&#&*-71%73*-,e>{*-,F0D+%-CD7149_:B ',N*->
71(+0kh)8;%-49*-L
5+02dV
F#)CD0<f\*-71(A%-#&#+*-71%73*-,W2U()%-hNt#&8;2.(+0hN71(+0R%-#)#+*-71%7189*
#b^71(+0Y,10468;%f)8;4;8;7_=21715&h+_@U%-2UCd%,1,.890hA*
5+7db
<8971(%:,10215)4971%-#7-sWu
uas?0%-215&,10?0#]7@*-fi
> z' nalV 0c71(&0d,10d>{*-,.0iCD*
#&218;h+0d,N71(+0c%-#&#&*-71%7189*
#
*-f&71%-8;#&0hc>{*-,<71(+0B0dE%-465&%7189*
#c73*Af\0B73*-71%-4;4;_,.04;8;%f)490-V
a86#&CD071(+0c%-#&#+*-71%730h730Da712U*
5&4;hf\0'&,1*aCD021230hf^_%-#%-#&%'t(+*-,.%:,1023*
4;5&7189*
#23_^21730?cbGU0
h+0dE-049*-'\0hi%-#:&
O:J71%L-L
8;#+L/>{*-,W?A%7dV
$0#&0d,.%-4;49_-b+71(&862R&
O:J?A%,.^5+'cR8;4;4\(&%E-0k71(+0e>*
4;49*R8;#+LN>{*-,W?cp


fiff Ju.E.u1E.

Ju.E.u1E.E.E,JmuJ.E.ZEEmZ.u;

XY(^5&2db+71(&0B>{*
4;4;*<8;#&LN#&*-71%7189*
#&2<%,.0e5&230hi8;#0%-CW(Cd%-210-p
XS*-')8;Cp
{

#ffE ffV1#.

J

"$h1%-CD0#&CD_')%-89,.2p
{

"!#


E

$%&" m&ff
wJm



R(+0d,10 8;2%-#A8;h+0#]718tCd%718;*
##]5&?=f\0d,5&230hN73*k%,.,.%-#+L-0Y71(+0R%-h3%-CD0#)CD_@'t%-89,.28;#230^5+0#]718;%-4
*-,Wh+0d,
{

#]730d,1E-0#718;*
#i715+,.#)2dp

'uZ)(;+*..,Em&-
ZG "
. ff" ""

fifi!W&!
.6Y.!@-Wfi!..!=fi!dmGm-
!k=Gfi. 3e!m-W! 09 /F123 1 fi
1!m!&45
4 56/F.731 fi .!m98 f+WY.0:4544 >




?D

fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

R(+0d,10kX "BMffL ?A%_cf[0 A*-, PQY0%-CD718;*
#*-, #)89718;%7189E-0fiT%-#)h:aMLG"<;(LG 8;2Y71(+0=8;#&h&8O
Cd%73*-,$>*-,Y71(+0k23'\0%-0d,YR(+*
230B715+,.#897Z8;2
{

V*
#718;#^5&8;#&L@715&,.#&2dp

=*..,Em&-
ZG> ff? @ff? m""
" Em
E

XY(&0B>{*-,.?%7<8;20Da0?')4;8t0h86#c8;L
5+,10B+V

CB
AED JZFB
CFHMGJIL@N?K IL?K,K B KsPNaPOQNILKFRSK"B

AED PB HGJILiK KB
CFM @NIL,K sK PaN POQN ILK KB





AED C PFB M@NILKrKePNaPOQNILKaCRSKB


AED P@B B
AED CFM@NILKrKePNaPOQNILKaKB

AED P@B B
AED

0;?
6/iZ
5
i! " (ffa siZ !eeg,
6/!a!ii3a 0 gi P,c3g

ui-i! p (& ff?;,!p!?m!a
-Zu0& 00qi!/ffa!?i3& !
= )a
0
5i 8

( !u r
6/aip&\!Z

5

K89L
5+,10B+pL+%-?')490F*->G&O:J%-#&#&*-71%7189*
#
" 20Da')4;%-86#+0h%f\*E-0-b@8;#%-h&h)897189*
# 73*71(&8;22173,.5&CD715+,.%-4k%-#&#+*-71%7189*
#b=71(+0`CD*-,.')5&2i%-2:%-4;23*
$
%-#&%')(&*-,.8;Cd%-4;49_%-#&#+*-71%730h f^_?A%,1a8;#+L5+'}71(&0:%-#&%'t(+*-,.8;Cc,.04;%7189*
#&2/f\0d7U0d0# %-464Y'&,1*
#&*
?A8;#&%-4
%-#&h`%-hm0CD718;E%-4%-#)%')(+*-,.2=%-#&hH71(+089,@CD*-,1,10CD7@%-#730CD0h+0#]712dV #H*-,.h+0d,=73*L
5&%,W%-#730d071(+0A,102.5&49712db
71(&8;2%-#)#+*-71%7189*
#%-2'\0d,1>*-,.?0hNf^_=7*kh)8[0d,.0#7%-#&#+*-71%73*-,W2G8;#N')%,W%-4;4904a%-#&h%B,10468;%f)8;4;8;7_e23715&h&_
*->71(+0$215+f)230^5+0#]7G%-#&#+*-71%718;*
#/%-271(+0#/Cd%,.,.890hA*
5&7dVB#&CD0R%L
%-8;#gb]71(+0$%-#&#+*-71%7189*
#%-2G73,.0%730h
%-2%Cd4;%-212189tCd%7189*
#71%-23[bCD*
#&218623718;#+L*->R230490CD7186#+L71(+0c%'&'&,1*-'&,W8;%730/04;0?0#71286#71(+0cCd%-#&h)8;h&%730
4;8;217PU0A0237186?A%730h%-#%E-0d,.%L-0*->^V '\*
212.89f)490N%-#730CD0h&0#712@'\0d,e%-#&%')(+*-,e%>730d,=%')')49_a8;#+LCD*
#aO
2373,.%-86#712WTWV XY(+0i,.04;8;%f)8;46897_23715)h+_`*->F71(+0?A%-#]5)%-4<%-#&%')(&*-,.8;C%-#&#+*-71%7189*
#,10215)49730h8;#%-sWu
uas
?0%-215&,10?0#]7Y*-5
> w'
]V
#%-h&h&89718;*
#b71(+0ZCD*-,1')5&2K%-2K71%L-L-0h5&2.8;#+L$71(+0ZMUe=71%L-L-0d,730CW(&#&8;^5+0Zh+021CD,W89f\0h=f^_=M4;%F%-#&h
M,W890d73*Pmln-n-o
TWV=+,1*
?71(&8;2btU0N*-f&71%-8;#+0h:?*-,1')(&*
49*-L
8;Cd%-4%-#&h490Da86Cd%-4S8;#&>{*-,.?%7189*
#VRX<(+0@CD*-,.')5&2
%-2G71(+0#')%,.230h5&218;#+LB71(&0$P $MGM`')%,1718;%-4+'t%,.230d,G'),1*-'\*
230hf^l
_ O:%,1?7 R Q #&0dDOU%,WCD*cKs-Pmln-n-o
TG8;#
*-,.h+0d,73*N*-f&71%-8;#23_a#]71%-CD718;CF8;#+>*-,.?A%7189*
#VK8;#&%-4649_-b71(+0F'&,.*-'[*
210h/%-#&%'t(+*-,.%=,1023*
4;5+718;*
#/%-49L-*-,W8971(&?
%-2<%'&')46890hV
?ff

fi

K

1E


<:1

^

ff

>fi >
fi

{E
E ?! 6

i{9 ] DA2

2{~i{



6ff

>


ET

U

:!

fi
ff fi


WV

WXUJUZYL[ \




W -
E1.<:<611:6w1<_\ fiff
1E`_ <:1a_g fi K

?]

1?6


ff


nWh\Kd!mm3dg
R$!fiK!ZWQWmfiFWSW!K.fiW
\h Kd!mm3dg
R$!fiKfi!mfiQ Wm R.g!U!fiKfimd.fiU!fiWfiW
\h Kd!mm3dg
R$!fi WR.SdW!!W .mfi$WmU!fiWfiW
7W\
h Kd!mm3dg
R$!fi!fi

! WW
% \h Kd!mm3dg
Rmgfi!

b

X%f)490AlpUa73,.5&CD715+,.%-4%-#)%')(+*-,.8;CF%-CdCD0212.89f)8;4;8;7_/21')%-CD0e,10215)49712
^0dE-0d,W%-4g23715&h&8;020d,10k71(+0#cCd%,1,.890hi*
5+7Y8;#*-,.h+0d,<73*A8;h+0#]7189>{_/71(+0e8;?'\*-,171%-#)CD0B*->h+0D[#&8;#+LN%-#
-% h+0^5&%730A%-#&%')(&*-,.8;CN%-CdCD0212189ft8;4;897_23')%-CD0%-#&h*->Uh+0Dt#&8;#&L%CD*
#&2373,W%-8;#7e%-#)h'&,10d>0d,10#&CD023_a23730?
f)%-230h*
#:71(&8;2$23')%-CD0-V #71(+0230N23715&h)8902db)U0NCD*
?')%,10h:71(+0@*
5+73')5+7R*->71(+0N%-#&%')(+*-,W%A,1023*
465+7189*
#
23_a23730? R8971(71(+0e?A%-#^5&%-4g%-#&#&*-71%7189*
#i%-#&hcL-0#&0d,.%730h210dE-0d,.%-4g2371%718;21718;Cd%-4g,102.5&49712dV
\

ac

}Eziy2}q2s#uy-Xuq2sq #y2}ffq$ur~?~ 'v'

~?q$u

#*-,.h+0d,=73*:2.(+*71(+0/8;?A'[*-,.71%-#&CD0A*->Yh+0Dt#)8;#+Li%-#%-h&0]5&%730%-#&%')(&*-,.8;CA%-CdCD0212.89f)8;4;8;7_23')%-CD0-b%
23715&h&_*-><71(+0c49*aCd%7189*
#*->R71(+0c%-#730CD0h+0#]7A*->R0%-C.('&,.*
#+*
?A8;#&%-4U%-#&h%-h30CD7189E%-4Z%-#&%')(+*-,.%:%-2
h+*
#+0e5)218;#+LN71(+0e73,W%-8;#&8;#+LNCD*-,1')5)2dVXY(+0B,102.5&49712Z%,10eL
8;E-0#i8;#iX%f)490AlVed
"$2Cd%-#Nf\0210d0#8;#@71(+071%f)490-bn-^V n N *->t71(+0Z%-#730CD0h&0#712G0d,10Y4;*^Cd%730h8;#@71(+0'&,.*-'[*
210h@2173,.5&CO
715+,.%-4K%-#&%'t(+*-,.8;C@%-CdCD0212189ft8;4;897_i23')%-CD0-V 7B8;2$023718;?A%730h71(&%7F71(+0N,10?%-8;#&8;#+L%-#730CD0h&0#712P+V;il NT
%,10i49*aCd%730h8;#71(+0c215+f)73*-')8;Cd2@*->R71(&0h)8;%-49*-L
5+02dV ( / #*-,.h&0d,@73*86#&CD*-,1'\*-,.%73071(+0230c,10?%-8;#&8;#+L
%-#]730CD0h+0#712@8;#]73*71(+0A%-#&%')(+*-,W8;CN%-CdCD0212189f)864;897_23')%-CD0-b*
#&0A?A89L
(]7$0?A')49*_%c2373,.%730dL-_71(&%7e5)2302
71(+0 -1tvv~i#q$u PQ8V0-V9ba%-4;4&71(+0$#+*
5&#')(+,.%-2302G>{,.*
?71(+0Rf\0dL
8;#&#&8;#&L$*->71(&0Rh&8;%-4;*-L
5+0<73*=71(+0$%-#)%')(+*-,
?A89L
(]7f\0F5)230htTWV j *U0dE-0d,bt%-2Z21(&*<#c8;#X%f)490e^b+*
5+,Z'&,.*-'[*
2.%-4t>*-,Z71(+0e%-#&%'t(+*-,.8;C$%-CdCD0212189ft8;4;897_
23')%-CD0PQ(+0d,10%>730d,F,10d>{0d,.,10hi73*%-2 ~E}t#t#}q2v TWbt,10h)5&CD02Y71(+0@%E-0d,.%L-0A#^5&?=f\0d,Y*->Cd%-#&h&8;h)%7302<'\0d,
%-#&%')(&*-,Pf\0d>*-,10%')')49_a8;#+LCD*
#&2173,.%-8;#]712WTB73*l 'aV fiH>,1*
? 71(+0+V;lDH71()%7@U*
5&4;hf\0/*-f&71%-86#+0h`8;>
71(+0 -1tv'v(~?q$u %')'&,1*
%-C.(U0d,10%-h+*-'&730hV #`*-71(+0d,.2@U*-,.h&2db5&2.8;#+Li71(+0 -1tv'vc~i#q$u %'&'&,1*
%-CW(
U*
5&4;h:8;#&CD,10%-230@71(+0#^5&?kf\0d,$*->G'\*
21218;f)490kCd%-#&h)8;h&%7302$f]_%/>Q%-CD73*-,B*->G71(&,10d0-b\71(+0d,10df^_L-,10%7149_:8;#aO
CD,10%-2186#+Lf[*-71(71(+0,10^5&89,.0h`CD*
?'t5+71%7189*
#&%-40D\*-,17%-#&h71(+0'\*
212189ft8;4;897_*->$230490CD718;#+LH8;#)CD*-,1,10CD7
%-#]730CD0h+0#712V<I<*-7186CD0-bt73*^*+bt71()%7<71(+0230=0D^'\0d,.86?0#712Y0d,10='\0d,1>{*-,W?0hc*E-0d,B%ACD*
46490CD7189*
#*->K2.(+*-,17
h&8;%-4;*-L
5+02iPQ%,1*
5&#&h--*-,Wh&2N'\0d,Ah&8;%-49*-L
5+0fiTWVXY(&0230c'&,1*-f)4;0?A2N<8;4;4f\00dE-0#}?*-,10i%-Cd5&7308;#
49*
#+L-0d,Rh&8;%-49*-L
5+02V
$71(&0d,k,10230%,WC.(+0d,.2@(&%E-0'&,1*-'\*
230h5&218;#+Li%i<8;#&h+*fi <8971(%&a0h#^5&?kf\0d,e*->Z230#]730#&CD02=73*
h+0Dt#&0G71(+0U%-#&%')(+*-,.86CG%-CdCD021218;f)8;4;897_B23')%-CD0-VXY(&8;2g7_^'[0U*->&%'&'&,.*
%-C.(N?A89L
(]7f\0Cd%-46490h=%)f 'sy f y~Eususu)~ %'&'),1*
%-C.(V&*-,0Da%-?A')490-b+0d,., %-Q #&h+0d@s-[Pmln-n-n
TK'&,.*-'[*
210Y5&218;#+L$71(+0Z71(+,.0d0Z'&,10dEa89*
5&2
230#]730#&CD02R73*h+0Dt#+0B71(&0k%-CdCD0212189ft8;4;897_/23')%-CD0k>{*-,R'&,1*
#+*
5&#)2Z%-#&hc71(+0B>*
5+,Y'&,.0dE^89*
5)2Z230#730#)CD02<>*-,
%-h30CD7189E%-4+%-#&%')(+*-,.%F8;#A^'t%-#&8;21(VS+*-ff
, LG#&L
4;8;21(b ;e%-?A0d_
%-?A%APmln-n
-TK'&,.*-'[*
2102S71(&0Y21%-?0Z23')%-CD0Z>*-,
71(+0U'&,1*
#+*
?8;#&%-4V j *U0dE-0d,b]71(+0d,108;2S#&*$2373,W5&CD715+,.%-435)23718tCd%7189*
#k>{*-,K71(+0210h&0Dt#&897189*
#)2dVg+0d,1, %-Q #)h+0d
: d.!mS!.\!fiSQ!Z
^!WfiW!K.mmmfi R.mS\WfiW31!3RWfifi!Wfi!fifiJ
!!fi.!fi
!Y
1!S..K!mfi!RQQ!
t1!
!
!Y
WfiW.!099 9
!gm.!mW ! >
< !fi fi [Z
3$dA
f !.gfiW!fiY
WR!W+

!fifi .
fifffi
figmd!fi
fi!m\!fi `3

24

?>

fi@ 2~,7



2 AK$)B

"$#&%')(&*-,.8;CF%-CdCD0212189ft8;4;897_/23')%-CD0
XS*-71%-4gCd%-#&h)8;h&%7302
VZ%-#&h&8;h&%7302'\0d,Y%-#&%'t(+*-,
MG,1*-'\*-,17189*
#



$CA

2B2{EDX<{$7

a73,.5&CD715+,.%-4
lb '
-
l 'aV fi

l'1',N

&5)4;423')%-CD0
^b -oB'
+V;lD
aloN

G
F





7BEHK.{JI22

8;#&h+*fi*->5+73730d,.%-#&CD02
lb -n-
l^V '

l-N

X%f)490k^pV%-#&h&8;h)%730273*f\0F'&,1*aCD021230hc>*-,Y0%-C.(:%-#&%')(&*-,.8;CF%-CdCD0212189ft8;4;897_/23')%-CD0
dSs%-#&g
h ;e%-?0d_
%-?A%$'\0d,1>*-,.?0h@230dE-0d,.%-4a0?'t89,.8;Cd%-4]23715&h&8902S73*B21(+*fi71(&0U*-')718;?A%-4^23')%-CD0>{*-,K0%-CW(
0Da'[0d,W8;?0#]7dVSX%f)490GZf\049*fi21(+*fi<2g71(&0,10215&4;712*->+%<23715&h&_R<()8;C.(BU0'\0d,1>*-,.?0he5)218;#+L71(+0& wx!u[]~
ffWrdw-Qx1D
r RDxW~Dwr&b+71(&0BL-*
%-4\*-><(&86C.(U%-273*Ah&0Dt#+0F%-#c%-#&%')(+*-,.86CR%-CdCD0212.89f)8;4;8;7_23't%-CD0$ft%-230h*
#
h% f 'sy f y-_~Eusuws#u)~ 71(&%7ZCd%-#71(+0#f\0$%-h)%'&730h73*h&8;%-49*-L
5+02Uf^_?0%-#&2*->Si% f sy f yl '@5+73730d,.%-#)CD02
tEuw}q2s#u)~ V"$2G71(+0$71%f)490$21(+*fi<2db\l-lR5+73730d,W%-#&CD02U>{*-,'&,1*
#&*
?A8;#&%-4&%-#)%')(+*-,.%=%-#&h
>*-,N%-hm0CD7189E%-4Z%-#&%')(&*-,.%%,10c#+0d0h+0h8;#`*-,.h+0d,73*HCD*E-0d,/71(+0c21%-?0c#]5)?kf\0d,@*->R%-#]730CD0h+0#712/%-2
%-2YCD*E-0d,10h5&218;#&L=71(+0B2373,W5&CD715+,.%-4%-#&%'t(+*-,.8;C$%-CdCD0212189ft8;4;897_23')%-CD0P<()8;C.(%-2Yh+0Dt#&0h/ft%-230h*
#
%-h1%-CD0#&CD_'t%-89,.2k%-#)h71(+073*-')8;CTWVa86#&CD071(+0%-#&%')(&*-,.8;C21')%-CD05)218;#+L:%<86#&h+**-><5+73730d,.%-#)CD02
8;2B#+*-7Bft%-230hH*
#%-#]_'),.8;#&Cd89't490-btft5+7F,.%71(+0d,e*
#H0?A')89,.8;Cd%-4K23715)h&8902dbg897e?%_:E%,1_:>,1*
? *
#+0730Da7
73*%-#+*-71(&0d,%-#&h71(+0d,10d>*-,10i8;286#&%-h+0^5&%730-
V O*-,10d*fiE-0d,bZ71(+0i2373,W5&CD715+,.%-4%-#&%')(&*-,.8;C%-CdCD0212189ft8;4;897_
23')%-CD0eCd%-#CD*E-0d,$*
#&49_71(&*
230eCd%-2302Y71()%7Z,10d>{0d,<73*IRM2Z8;#]73,1*^h)5&CD0h%7Y71(+0B*
5+71230d7<*->S71(+0eh)8;%-49*-L
5+0
P73*-')8;Cd2TWb)#+*-7Y71(+*
210e<8971(c%N<86#&h+* *->230#]730#&CD02W5&73730d,.%-#&CD02F%'&'&,1*
%-CW(V
#HCD*
#&Cd4;5&2.89*
#bg897FU*
5&4;h%'&'\0%,B71(&%7e71(+0 ~}t#t#}q{v %-#)%')(+*-,.8;CN%-CdCD0212.89f)8;4;8;7_23't%-CD0A8;2F73*
f\0B'&,10d>0d,1,10hb+%7<4;0%-237Y>*-,<%-#&%')(+*-,W%N,1023*
4;5+718;*
#c8;#ch&8;%-49*-L
5&02dV

j

esy

f

y-FtEuw}q2su

`kxmw q$rtsu)v^wxl ~
+dxmsr[WN!w[
"R#)%')(+*-,2Y5&73730d,.%-#&CD0
O.l


O!



Oo

O.l'
O.l-l
O.l
O.l
O.lD

p

&' ,.*
#+*
?A8;#&%-4
%-#&%')(+*-,W%
%-#730CD0h+0#]712

]V
+V;l
'aV

-]V'
'aV
B
o-^V
o-o^V
nalV
nalV
n-^V;l
n-^V
N

mn



n-o^V
n-o^V
l'1'aV'

N%-hm0CD7189E%-4

%-#&%')(+*-,W%
%-#730CD0h+0#]712
lo^V
-+V
-^V
-^V

]V n
^lV'
^V
^V
oalV
oalV

\

n+V
n
]V
n
]V
l'1'aV'

XS%f)4;0k^pffLG?'t89,.8;Cd%-4\23715&h&_/*->K%-#&%')(+*-,W8;CB%-CdCD0212189ft8;4;897_/23')%-CD0Bft%-230hi*
#i%A<8;#&h+*fi *->K5&73730d,.%-#&CD02
?G

fi

$230hc'&,10d>0d,10#&CD02

L^'\0d,.8;?A0#7

I<*+V




p

{
{

{

{

{

{

{

{

{

{

{

{

{

l

'

r



{

q
L^'\0d,.8;?A0#7
I<*+V
l



l

'

l

i{9 ] DA2

2{~i{

MG,1*
#+*
?A8;#)%-4%-#&%')(+*-,.%
n
{



{

{

{

l'

l-l

l

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

p


M,10Cd8;2.89*
#

"$h30CD7189E%-4%-#&%')(+*-,.%


{

{
{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{

{
{

N

-n^V'
-^V
^V
oalV
N

-^V
-^V
o^V n
oalV

nWf+!
! mK[md!3sYWZd
+f !
! mK[m d!3sY
W Z


b

XS%ft490B+pffLa'\0d,.8;?0#]7Z215&?A?%,1_

ts

\

Qys~E}q{sq{s

#}u.- uw}usuE~Eu

"$2B>{*-,k71(+08;?'\*-,171%-#)CD0@*->Zh+0D[#&8;#+L%-#%-h+0^5&%730/CD*
#)2373,.%-8;#]7e%-#&hH'&,.0d>{0d,10#)CD0A230d7ef)%-230h*
#h&8O
%-49*-L
5+02373,.5)CD715+,10/5)218;#+L71(+0/%-CdCD0212.89f)8;4;8;7_23')%-CD0h+0Dt#&0h8;#^0CD7189*
#`+bU0/f\0dL
8;#f]_%-h&*-'&718;#+L
71(+0CD*
#&2373,.%-8;#]7k%-#&h'&,10d>0d,10#&CD0210d7=h+0dE-049*-'\0hf]_H+0d,1, %-Q #&h+0d$s-ZPmln-n-n
T=%-#&h`h+021CD,.89f\0hf\0DO
49*fi 8;#a0CD7189*
#^V+V@X<(&8;2$CD*
#&2373,.%-8;#]7B%-#&h:'&,10d>0d,10#&CD0230d7e(&%-2Ff\0d0#21(+*fi<#:73*cf\0@%-h+0^5&%730>*-,
'&,1*
#&*
?A8;#&%-4%-#&h%-hm0CD718;E%-4Y%-#)%')(+*-,.%86##+*
#aOh&8;%-4;*-L
5+0ih&8;21CD*
5&,.230-V}XS*71(&8;2210d7dbY8;#+>*-,.?A%7189*
#
%f\*
5+7=h)8;%-49*-L
5+02173,.5&CD715+,10<8;4;4Kf\0%'&'t4;890h8;#*-,.h+0d,@73*71%-0c%-h+E%-#71%L-0*->Y89712@8;#at5+0#)CD0-VIR*-7
*
#&49_8;2Zh&8;%-4;*-L
5+0e2373,.5&CD715&,10e5&230h73*h&0Dt#+0F71(+0e%-#&%')(&*-,.8;CB%-CdCD021218;f)8;4;897_/23't%-CD0-b&f)5+7Z897Y8;2Z5)230h73*
h+0Dt#&0B'&,10d>0d,10#&CD02Y%-2ZU04;4V
+*-,=71(&8;2e21715&h+_-b230dE-0d,W%-40Da'[0d,W8;?0#]712B0d,.0Cd%,1,.890h*
5&7k5&218;#&L71(&0A73,.%-8;#&86#+LcCD*-,1')5&2dVAX<(+0230
0Da'[0d,W8;?0#]712@86#E-*
49E-0hCW(&%-#+L-02A86#`71(&0CD*
#)2373,.%-8;#]7A%-#&h'&,10d>0d,10#&CD0c230d7A8;#*-,.h&0d,@73*h&0Dt#+071(+0
CD*
#a)L
5&,.%7189*
# (( 71(&%7YU*
5&4;h(&%E-0e*-')718;?=5)? '&,10Cd8;2.89*
#VKY0215&4;712Y%,10k215)?A?A%,.89d0h8;#XS%f)4;0B+V

uvxwvzy|{~}C}CQfi9FFFJ)J

XY(+0d,.0%,107U*:h&89[0d,10#]7=%')'&,1*
%-C.(&02k73*?A%-#&%L
8;#&L71(+0/'&,10d>0d,10#&CD0/210d7db*-,Wh+0d,10h?%-#&%L-0?0#]7
%-#&hU089L
(730hc?%-#&%L-0?0#]7dV$,.h&0d,10h?A%-#&%L-0?0#]7Y8;2Uf)%-230h*
#ch&8;2.Cd%,.h&8;#+L=71(+*
230B%-#]730CD0h+0#712
71(&%7Kh+*R#&*-7>Q5&4t4;4-%<'&,10d>0d,10#&CD0U89>a71(+0d,10862%-#]_kCd%-#&h&8;h)%730G71(&%7S>5&49t4;4;2897dV 089L
(]730h@?%-#&%L-0?0#]7
8;2f)%-230h*
#%-21218;L
#&8;#+L@%=U089L
(]773*@0%-CW('&,10d>0d,10#&CD0B%-#&h/71(+0#c230490CD7186#+L=71(&0$Cd%-#&h)8;h&%730F<8971(/71(+0
?A%+8;?@5&?E%-465+0-V
+*-,G71(+02300D^'\0d,.86?0#712b-71(+0Z23_^21730? U%-273,W%-8;#+0hN23*B%-2K73*B*-f&71%-8;#@71(+0Zf\0237K230d7*->)'),10d>{0d,.0#&CD02dV
a5+ft230]5&0#7149_-b[U0N%')')4;890hf[*-71(:*->71(+0@%')'&,1*
%-C.(&02F73*'),10d>{0d,.0#&CD0?A%-#&%L-0?0#]7B73**-f&71%-8;#:71(+0
f\0237A,102.5&497N<8971(71(&0i73,.%-8;#&86#+LHCD*-,1')5&2dV F#&CD0iU0i*-f&71%-86#+0h71(+0f[0217A230d7*->F'&,10d>0d,10#&CD02/%-#&h
Jh\!6 o6#$2ki+-n2x#$AS3B!!<fi `!GK
[Q.!KB!
! mmS!.YDF!fi
QQ! fi3e
.SUmfi!!Qm
+!Kfi-!Z .
fi!dmmm
?d

fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

89712f\0237?A%-#&%L-0?0#]7dbRU00dE%-465&%730h 71(+0H23_^21730? R8971(}71(&0:730217CD*-,.')5&28;#*-,.h+0d,73**-f)71%-8;#
8;#&h&0d'[0#)h+0#7U,10215)49712dV
^*+ba>*-,0D^'\0d,.8;?A0#71
2 'ablba%-#)h^ba*-,.h&0d,10h?A%-#&%L-0?0#]7U%-2Z%'&'t4;890hA73*N*-f&71%-86#71(+0Ff\0237U230d7
*->Y'&,.0d>{0d,10#)CD02dVXY(&0#b86#0Da'[0d,W8;?0#]7@^bU0%'&'t4;890hHU089L
(]730h?%-#&%L-0?0#]7@73*8;?'),1*E-071(+0
,10215)49712Z8;#71(+0e73,W%-8;#&8;#+LNCD*-,1')5)2dV



\

2x c

\iuw}'z|uws

?

qg~Euv's#u z

's{t=~E'sZ-1y2}ffz

qys

ys#v=

0 f\0dL
%-#<8;71(71(+0iCD*
#&2373,.%-86#7A%-#&h'),10d>{0d,.0#&CD0i230d75&210hf]_+0d,1, %-Q #)h+0dd=sFPmln-n-n
TWV XY(&8;2

%-49L-*-,.8;71(&? 8;2f)%-230h*
#468;#+L
5&8;21718;C8;#+>*-,.?A%7189*
#*
#)49_-bY%-#&h}8;712,102.5&49712A(&%E-0f[0d0#215&CdCD02121>5&4649_
73023730hN*fiE-0d,G%F#+*
#aOh&8;%-4;*-L
5+0UCD*-,.')5&2<8971(@%$,10215&497186#+L<'&,.0Cd8;2189*
#k*->[o- N >*-,'&,1*
#+*
?A86#&%-4%-#&%'t(+*-,.%
,1023*
465+7189*
#PU0k(&%E-0@#+*A8;#+>*-,.?A%718;*
#c%f[*
5&7Z71(+0B'&,10Cd8;2.89*
#>{*-,R%-hm0CD718;E%-4g%-#)%')(+*-,.%TWV
XY(&0@8;#)89718;%-4gCD*
#atL
5+,.%7189*
#:8;#&Cd4;5)h+0hc71(+0@>{*
4649*<86#+LCD*
#&2373,W%-8;#7F%-#&h:'&,10d>0d,10#&CD0N230d7F%-#&h:h+0D&O
#&89718;*
#*->%-#&%'t(+*-,.8;CB%-CdCD0212.89f)8;4;8;7_/21')%-CD0-V

uvHCvzyhFFQJ}C`F@fifi?`aafiFfi

+ *-,'&,1*
#+*
?A86#&%-4]%-#)%')(+*-,.%F,1021*
4;5+7189*
#b-71(&0Y%-#&%')(+*-,.86C%-CdCD0212.89f)8;4;8;7_=21')%-CD0YCD*
#&218;21730h*->t71(&0Z71(+,10d0
'&,10dEa89*
5&2G715+,.#&2G73*N71(+0R%-#&%'t(+*-,V+*-,Y%-h30CD7189E%-4t%-#&%'t(+*-,.%ab^71(+0$21')%-CD0$CD*
#)218;23730h/*->g71(+0R'&,10dEa89*
5&2
>*
5+,Y715+,.#)2dV

uvHCv0JQS@}CFaJC

#c71(+0eCd%-210k*->'&,1*
#+*
?A86#&%-4\%-#&%')(+*-,.%ab)71(+0kCD*
#&2373,W%-8;#712<8;#&Cd4;5&h&0hp

{

lV<?A*-,1')(+*
49*-L
86Cd%-4%L-,10d0?0#]7dpYh&8;2.Cd%,.hi71(+0@%-#730CD0h&0#712F<()8;C.(%,10=8;#)CD*
?')%7189f)4;0e?*-,3O
't(+*
49*-L
8;Cd%-4;4;_:PL-0#&h+0d,b)#]5)?kf\0d,b+%-#&hc'\0d,.21*
#tT
^V<21_^#]71%-CD718;CCD*
#]730Da7dpNh)8;21Cd%,.hH71(&0%-#730CD0h&0#712@<(&86C.(%,10/#+*
#aOCD*O!,10d>0d,10#]7@%-CdCD*-,.h)8;#+L
73*/J%'&')86#c%-#&hcJg0%-212@Pmln-n]T
#c71(+0eCd%-210k*->K%-hm0CD718;E%-4S%-#&%')(+*-,.%ab+71(&0kCD*
#&2373,.%-86#712Y86#&Cd4;5&h+0hgp
{

lV<?A*-,1')(+*
49*-L
86Cd%-4%L-,10d0?0#]7dpYh&8;2.Cd%,.hi71(+0@%-#730CD0h&0#712F<()8;C.(%,10=8;#)CD*
?')%7189f)4;0e?*-,3O
't(+*
49*-L
8;Cd%-4;4;_:PL-0#&h+0d,DT
^V<MG,1*-'\0d,3O#+*
5&#+O!')(+,.%-230F0D+Cd4;5&218;*
#p0D+Cd4;5&h+0e#+*
5)#c')(+,.%-2102Y(&%Ea8;#+L/%'&,1*-'\0d,<#+*
5)# ( - %-2
(&0%-h

uvHCvxw{~}C}CQfifi
{

#c71(+0eCd%-210k*->'&,1*
#+*
?A86#&%-4\%-#&%')(+*-,.%ab)71(+0e'&,10d>0d,10#&CD02<%,10B>{*-,p
l V<Cd%-#)h&8;h&%7302Y86#71(+0k21%-?0k715+,.#c%-2Y71()%7Y*->S71(&0k%-#&%')(+*-,
^V<Cd%-#)h&8;h&%7302Y86#71(+0e'&,10dEa89*
5&2715&,.#
^V<Cd%-#)h&8;h&%730B'&,.*-'[0d,Y#&*
5&#&2*-,R86#&h+0Dt#&8;730$I$MG2

Jf+!-\fifi.!Wgfi. qZfiZ`3_<Wm!Dmmh\iW<Wm1!-\fi!$.3W
.!
fiWg DmR3 fi 1!mW d!mmmfi d!g
&W m!.a Wfi.!m
?d

fi

i{9 ] DA2

2{~i{

+V=P>*-,<'\0d,.21*
#&%-4\'&,1*
#+*
5)#&2WTCd%-#&h&8;h)%730B'&,1*-'\0d,Y#+*
5&#&2
^V<Cd%-#)h&8;h&%7302S71(&%7S()%E-0f\0d0#e,10d'\0%730h@?*-,10G71()%-#k*
#&CD0BP,10d'\0%730h=>{*-,.?2%-#&h=,10d'\0%730h
?A0#7189*
#)2WT
^V<Cd%-#)h&8;h&%7302<71(&%7R(&%E-0=%'&'\0%,10h?*-,10e71()%-#i*
#&CD0@8;#cCD*
#&2373,.5)CD7189*
#i<8;71(c71(+0eE-0d,1f:8;#
CD*
#)2373,.5&CD7189*
#i<8971(71(+0k%-#)%')(+*-,
]V<Cd%-#)h&8;h&%730286#=71(&0Y21%-?0Z'\*
21897189*
#N%-271(&0Y%-#&%')(+*-,<8;71(N,10d>{0d,.0#&CD0Z73*B71(+0ZE-0d,1fPf\0d>*-,10
*-,$%>{730d,DT
o^V<Cd%-#)h&8;h&%7302Y86#71(+0k21%-?0k'[*
2.897189*
#<8971(,10d>0d,10#&CD0k73*A71(+0k5+73730d,W%-#&CD0k%-2Y71(&0e%-#&%')(+*-,
n^V<Cd%-#)h&8;h&%7302Y#&*-7<8;#cCd89,.Cd5)?A2371%-#]718;%-4%-h15&#&CD712
l'aV<Cd%-#)h&8;h&%7302Y?A*
237Y,10d'\0%730hi8;#i71(+0B730D^7
l-lV<Cd%-#)h&8;h&%7302=?*
237k*->730#%')'[0%,W8;#+Li8;#CD*
#)2373,.5&CD7189*
#<8971(H71(&0AE-0d,1f`86#CD*
#&2373,.5)CD7189*
#
R8971(71(+0k%-#&%'t(+*-,
l^VY71(&0kCd49*
230237RCd%-#&h&8;h&%730B73*71(+0k%-#&%')(&*-,
{

#c71(+0eCd%-210k*->K%-hm0CD718;E%-4S%-#&%')(+*-,.%ab+71(&0e'&,10d>0d,10#&CD02Y%,.0e>{*-,p
l V<Cd%-#)h&8;h&%7302Y86#71(+0k21%-?0k715+,.#c%-2Y71()%7Y*->S71(&0k%-#&%')(+*-,
^V<Cd%-#)h&8;h&%7302Y86#71(+0e'&,10dEa89*
5&2715&,.#
^V<Cd%-#)h&8;h&%7302K21(&%,W8;#+L<71(&02.%-?0a8;#&h=*->)?*ah&8t0d,%-271(+0Z%-#&%')(&*-,P0-VL+V9b^%R'),10d'\*
21897189*
#&%-4
't(+,.%-230fiT
+V<Cd%-#)h&8;h&%7302e2.(&%,.8;#+L71(+0A2.%-?0?*ah&8)0d,B%-2B71(&0A%-#&%')(+*-,/P0-VL+V9b71(+0A21%-?A0%-h30CD7189E-0-p
,.*3%a&,.0htT
^V<Cd%-#)h&8;h&%7302Y%L-,.0d08;#+L8;#c#^5&?=f\0d,
^V<Cd%-#)h&8;h&%7302Y?A*
237Y*->730#i,10d'\0%730hi8;#71(&0e730D^7
]V<Cd%-#)h&8;h&%7302=%'&'\0%,.8;#+Li?*
217k*->730#8;#CD*
#)2373,.5&CD7189*
#<8971(H71(&0AE-0d,1f`86#CD*
#&2373,.5)CD7189*
#
R8971(71(+0k%-#&%'t(+*-,
o^VY71(&0kCd49*
230237RCd%-#&h&8;h&%730B73*71(+0k%-#&%')(&*-,

uvHCvHh`?zF

F89E-0#71(&8;2R),.237BCD*
#atL
5+,.%7189*
#bS%-#0dE%-4;5)%7189*
#U%-2kCd%,1,.890h*
5+7BR(&8;C.(,.0215&49730h8;#H%'&,.0Cd8;2189*
#
*->-n^V',N>{*-,Z'&,.*
#+*
?A8;#&%-4t%-#&%')(+*-,W%=,.023*
4;5+7189*
#%-#&hc-^V &N >*-,Y%-h30CD7189E%-4[%-#)%')(+*-,.%@,1023*
465+7189*
#V
IR0d0h&490212N73*H21%_-b71(+0210,.0215&49712N%,10E-0d,1_49* >*-,N'&,1*
#+*
?A86#&%-4%-#)%')(+*-,.%%-#&h0Da73,10?049_`'[*^*-,
>*-,R%-h30CD7189E%-4%-#&%')(&*-,.%aV #i0dE%-4;5&%7186#+L71(+0k0d,.,1*-,.2db&U0=CD*
#)Cd4;5&h+0hc71()%7Y71(+0=h&0Dt#+0hi%-#&%'t(+*-,.8;C
%-CdCD021218;f)8;4;897_23't%-CD0%-2e73*^*CD*
#&2373,.%-86#+0h%-#&hH73*^*%,.f)8973,.%,.8649_h+0Dt#&0hV 7=218;?')4;_h&8;23,.0dL
%,.h+0h
71(+0e,.04;%7189*
#&21()89'cf\0d7U0d0#%-#&%')(&*-,.%A%-#&hh&8;%-49*-L
5+0e2173,.5&CD715+,10-_
V VU*
#&230^5+0#]7149_-b&U0k'&,.*-'[*
210hc71(+0
>*
4;49*R8;#+LC.(&%-#&L-02Y>*-,Y71(+0k230CD*
#)hc0D^'\0d,.86?0#7dV



\ +

\iuw}'z|uws







q2vy {t#u

~}fftt}uZs - y{}z|qys

y{sv=

+*-,R71(&8;20Da'[0d,W8;?0#]7db^71(&0eh+0Dt#&89718;*
#/*->71(+0e%-#&%'t(+*-,.8;CF%-CdCD021218;f)8;4;897_23')%-CD0kU%-2YCW(&%-#+L-0h73*A0?NO
')49*fi_B8;#+>*-,.?A%7189*
#B'),1*Ea8;h+0hBf^_B71(+0Uh&8;%-49*-L
5+02373,.5&CD715+,.0-b%-2215+L-L-023730h=f^_(O%,17?R Q #+0dDO%,.CD*NPmln-n-n
TWV
#e%-h&h&89718;*
#b71(+0G'&,10d>0d,10#&CD02%\0CD730h@f]_F71(&862,10dEa8;230heh+0D[#&897189*
#F*->+%-#&%')(&*-,.8;C%-CdCD0212.89f)8;4;8;7_R21')%-CD0
U0d,10k?*ah&8)0h%-2<04;4!V


fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

uv0fivzyhFFQJ}C`F@fifi?`aafiFfi

XY(+0$%-h1%-CD0#&CD_')%-89,U%-#&h71(&0<73*-')8;C<*->71(+0Rh)8;%-49*-L
5+0R0d,10$5&230h/8;#A*-,.h&0d,73*@h+0Dt#+0R71(+0R%-#&%'t(+*-,.8;C
%-CdCD021218;f)8;4;897_A23')%-CD0-
V VU*
#)CD,10d73049_-ba0Bh+0D[#+0h/%-#%-#&%'t(+*-,.8;CR%-CdCD0212189f)864;897_A21')%-CD0Rf^_?0%-#)2*->S71(+0
%-h1%-CD0#&CD_')%-89,N*-><71(+0i%-#)%')(+*-,b71(&0'),10dE^8;*
5&2N%-h3%-CD0#)CD_`')%-8;,@73*H71(&0%-h3%-CD0#&CD_')%-89,N*->$71(+0
%-#&%')(&*-,bG%-h1%-CD0#&CD_')%-89,.2NCD*
#]71%-8;#&8;#+L:71(+0i%-h1%-CD0#&CD_')%-89,@*->R71(&0%-#)%')(+*-,bG%-#)hbt#&%-4649_-b71(+0
?A%-8;#73*-'t8;CB*->71(+0kh&8;%-4;*-L
5+0AP>{*-,R'&,1*
#+*
?A86#&%-4\%-2Z0464g%-2Y%-h30CD7189E%-4g%-#&%')(+*-,W%TWV

uv0fiv0{~}C}CQfifi

+*-, La'[0d,W8;?0#]7lbU0c,.0?*E-0h}71(+0c'&,1*
#+*
?8;#&%-4%-#&%')(+*-,W%'&,10d>0d,10#&CD02h+021CD,W89f\0h%f\*fiE-08;#
89730?A2=71(+,1*
5+L
(:l-lF%-#&h/71(+0$%-hm0CD7189E%-4\%-#&%')(+*-,W%e'&,10d>0d,10#&CD02h+02.CD,.89f\0h8;#/89730?A2Zk71(+,1*
5+L
(c]V
"$4;23*+ba'&,10d>0d,10#&CD02FlF%-#&hc@%f[*fiE-0F0d,10F,10d't4;%-CD0hf]_/71(+0R>*
4;49*fi<8;#+L=>{*
5&,#&0d '),10d>{0d,.0#&CD02dVXY(^5&2db
f\*-71(c>*-,Y'&,1*
#+*
?8;#&%-4\%-#&hi%-h30CD7189E%-4g%-#&%')(&*-,.%ab+71(+0e'&,.0d>{0d,10#)CD02Y%,10e>*-,p
{

lVCd%-#&h&8;h&%7302<8;#71(+0k21%-?A0k%-h1%-CD0#&CD_')%-89,Y%-2Y71()%7Y*->S71(&0k%-#&%')(+*-,
{

^VCd%-#&h&8;h&%7302<8;#71(+0e'&,.0dE^89*
5)2Z%-h3%-CD0#)CD_'t%-89,Z73*A71(+0k%-#)%')(+*-,

oG
V Cd%-#&h&86h&%7302Y8;#c%-#]_c%-h3%-CD0#)CD_'t%-89,YCD*
#71%-86#&8;#+L71(+0=%-h3%-CD0#)CD_'t%-89,Z*->S71(&0k%-#&%')(+*-,
{

pDVCd%-#&h&8;h&%7302Y71(&%7<%,10e8;#i71(+0B73*-')8;C
{

XY()8;2YC.()%-#+L-0=%-2F?A%-h+0k86#i*-,.h+0d,R73*/730217R71(+0@23_a23730?c2R'[0d,.>{*-,.?%-#&CD0e<(+0#4;8;#+L
5)8;23718;CF8;#+>*-,3O
?A%7189*
#8;2R,10?*fiE-0h%-#&h:*
#&49_ih&8;%-4;*-L
5+0=2373,W5&CD715+,10@8;#+>*-,.?A%7189*
#8;2R5)230hP'),10d>{0d,.0#&CD02Nl=71(&,1*
5+L
(
p.TWV #*-,Wh+0d,A73*HL
5&%,.%-#]730d0%H2.8;#+L
490/t#&%-4Z23*
465+7189*
#b*
#)49_`4;86#+L
5&8;237186CA'&,10d>0d,10#&CD0c89730? l^b>*-,
'&,1*
#&*
?A8;#&%-4\%-#&%')(&*-,.%ab)%-#&hc89730?o^b&>{*-,$%-h30CD7189E%-4%-#&%')(+*-,.%iP71(&0kCd49*
230237RCd%-#&h&8;h&%730fiTWb+,.0?A%-8;#V

uv0fivxwh`?zF

"R>{730d,86#&Cd4;5&h&86#+Li8;#+>*-,.?A%7189*
#%f\*
5+7h&8;%-4;*-L
5+0c2373,.5&CD715+,.0%-#)h`,.0?*Ea8;#+LH71(+0c4;86#+L
5&8;237186C'&,10d>0d,3O
0#&CD02dbF'&,.0Cd8;2189*
# ,.%7302c,.*
230H73*-^V N >*-,i'&,.*
#+*
?A8;#&%-4$%-#&%')(&*-,.%,1023*
4;5&7189*
# %-#&h-^V >*-,
%-h30CD7189E%-4[%-#)%')(+*-,.%=,1023*
4;5&7189*
#V"CD*
#&2.8;h+0d,.%f)4;0<8;#&CD,10%-210F862GL
%-8;#&0h86#71(+0F,1021*
4;5+7189*
#/*->%-h30CO
7189E%-4%-#&%'t(+*-,.%Af^_i218;?A')49_C.(&%-#+L
86#+L71(+0@h+0Dt#&8;7189*
#*->71(+0@%-CdCD0212189f)864;897_c23't%-CD0-V<XY(&%7$8;2<h&5&0e73*
71(+0e>Q%-CD7Y71(&%7R%-hm0CD718;E%-4g%-#)%')(+*-,.%#+0d0h%A4;%,1L-0d,<21')%-CD0e71(&%-#c71()%7<5&230hi86
# La'[0d,W8;?0#]7 'aV
5+7K71(+0230,102.5&49712K%,10Z23718;4;4]49*%-#)h@h&0?*
#&2373,.%73071(&%7h)8;%-49*-L
5+02373,.5&CD715&,10U86#+>{*-,W?A%7189*
#@%-49*
#+0
8;2e#&*-7=21P5 KCd890#7dVXY(^5&2dbS%i71(&89,.hH0Da'\0d,.8;?0#]7B%-2kCd%,1,.8;0h*
5+7k5)218;#+Lcf\*-71(h&86%-49*-L
5+0A2373,.5)CD715+,10
%-#&h4;8;#&L
5&8;23718;C86#+>{*-,W?A%7189*
#V^0dE-0d,.%-4E%,.8;%7189*
#)2=8;#`71(+0'&,10d>0d,10#&CD023_a23730? 0d,.086#E-023718;L
%730h
8;#&h&0d'[0#)h+0#714;_-V



\

x f

\iuw}'z|uws
y2}
u}ur



's{t/~'s - y2}ffz|qy{s

z|q2sq 2uz

v't~bq2vy{t#uC~E}t#t#}u
usOy-q}uu-1u}uws#u)~ z

's - y2}ffz|qy{s

+*
4;4;*<8;#&L+b+71(+0e'&,10d>0d,10#&CD02<5&230hc8;#71(&862Z0D^'\0d,.86?0#7Z%-#&hi71(+089,15&23718tCd%718;*
#c%,10k21(+*fi<#V

uvxuvzy|{~}C}CQfifi

#=71()8;20Da'\0d,.8;?0#]7db0),.2175&210h=%$'&,10d>0d,10#&CD0230d7K71(&%78;#&Cd465&h+0he%-4;4]71(+0Z4;8;#&L
5&8;23718;C%-#)h@h)8;%-49*-L
5+0
2373,.5)CD715+,10c'&,10d>0d,10#&CD02/h+021CD,.8;f[0h%f\*fiE-0-V X<(+0#bGE%,.89*
5)2A%-49730d,.#&%718;E-02U0d,105&210h8;#*-,.h&0d,A73*



fi

i{9 ] DA2

2{~i{

*-f&71%-8;#:%-#:*-'&718;?A%-4SCD*
#a)L
5+,W%7189*
#VF"R2$%,.0215&497db[71(+0@>{*
4;4;*<8;#&LA'&,10d>0d,10#&CD02$U0d,10@%,.,.89E-0h:%7R>*-,
71(+0B[#&%-4CD*
#a)L
5+,W%7189*
#p
{ &*-,<'&,1*
#&*
?A8;#&%-4\%-#&%')(&*-,.%ab&71(+0e'),10d>{0d,.0#&CD02Y%,10B>*-,p
h)8;%-49*-L
5+0e2373,W5&CD715+,10B'&,.0d>{0d,10#)CD02dpYlB71(+,1*
5&L
(p
468;#+L
5&8;21718;C<'),10d>{0d,.0#&CD02dpG^b[]bto^bt%-#&hl
{ &*-,R%-h30CD7189E%-4g%-#&%')(+*-,W%ab&71(+0e'&,.0d>{0d,10#)CD02Y%,10e>*-,p
h)8;%-49*-L
5+0e2373,W5&CD715+,10B'&,.0d>{0d,10#)CD02dpYlB71(+,1*
5&L
(p
468;#+L
5&8;21718;C<'),10d>{0d,.0#&CD02dpG^b&+bt^bt%-#&ho
XY()8;2Ut#&%-4230d7<*->CD*
#&2173,.%-8;#]712<%-#&h'&,.0d>{0d,10#)CD02<8;271(+0k*
#+0B71(&%7<8;2Y'&,10230#]730hi8;#^0CD718;*
#^V ^V

uvxuv0h`?zF>JF5QS@0z@zF

7Y21(+*
5&4;hf\0B#+*-730hc71(&%7R8;#+>*-,.?A%7189*
#%f\*
5+7,10d'\0%730hiCd%-#&h&86h&%7302x!>*-,Z0Da%-?A')490-b+71(+0B'&,.*
#+*
?NO
8;#&%-4\%-#&%'t(+*-,.%N'&,10d>0d,10#&CD02Y^bSl 'ab&%-#&hl-lb+*-,Y71(+0e%-hm0CD7189E%-4%-#&%')(&*-,.%N'&,10d>0d,10#&CD02YN%-#&h: ! 8;2
5&215)%-4;49_i8;#&210d,1730h86#73*71(+0N'&,10d>0d,10#&CD023_a23730? 8;#:*-,.h&0d,$73*i%-CW(&890dE-0a#+*R490h+L-0%f\*
5+7F71(+0?A%-8;#
0#]7189718902Y*->71(&0=h&8;%-4;*-L
5+0-V j *fi0dE-0d,b8;#71(&8;2Z0Da'\0d,.8;?0#]7db)8;#&>{*-,.?%7189*
#i%f\*
5+7<71(&0=?A%-8;#i73*-')8;Ce*->
71(+0Uh&8;%-49*-L
5+0(&%-2f\0d0#=8;#&Cd4;5&h&0he%-#&hk21*R8;#+>*-,.?A%718;*
#e%f\*
5+7,10d'\0%730h@Cd%-#&h&8;h)%7302S8;2S5&#&#+0CD02.21%,1_-V
XY(+*
210B'&,10d>0d,10#&CD02ZU0d,10e71(+0d,.0d>{*-,10k,10?*E-0hgbt8;?'),1*Ea8;#+L@71(+0e,102.5&49712dV
&5&,171(+0d,.?*-,.0-b^U0B>*
5&#&h/71(&%7Z'&,1*
#+*
?8;#&%-4)%-#)%')(+*-,.%@'&,10d>0d,10#&CD02Y@%-#&hN>*-,Z'&,1*-'\0d,U#&*
5&#&2
Cd%-5&230h0d,.,1*-,.2dVXY()8;2862f\0Cd%-5&210F86#71(+0Bh+*
?%-8;#*->71(+0F0Da'[0d,W8;?0#]771(+0d,.0F862U%-#0D+%L-L-0d,.%730h5&230
*->g')46%-CD0R#&%-?02<(+0d,.0<71(+0230$'&,10d>0d,10#&CD028;#)CD*-,1,10CD7149_%'&')4;_-VKU_A,.0?*Ea8;#+L=71(+0?cbaf\0d73730d,,102.5&49712
U0d,10e*-f&71%-8;#&0hV
K8;#&%-4649_-b218;#&CD0N71(+0A5&210d>5&46#+0212$*->'),10d>{0d,.0#&CD0AnHPQCd%-#&h&8;h&%7302e71(&%7e%,10A#+*-7e8;#Cd89,WCd5&?A2371%-#]718;%-4
%-h15&#&CD7WT(&%-2#+0dE-0d,Zf\0d0#k35)23718)0h/'&,1*-'\0d,.49_-b^89773*]*N%-2*
?A8973730hV"R>730d,Z,10?*E%-4b+71(+0F'&,.0Cd8;2189*
#
>*-,Y'&,1*
#+*
?8;#&%-4\%-#&%')(+*-,W%2371%_-0h71(+0k21%-?A0-V
XY(^5&2dbK(&%E^8;#&LCD*
#&2186h+0d,10h%-464'\*
212189ft490A%'&')4;86Cd%7189*
#&2B>*-,=*-,Wh+0d,10h`'&,10d>0d,10#&CD0/?%-#&%L-0?0#]7db
%-#&hcL
8;E-0#i71(&%7R71(&8;2Ut#&%-4230d7Y*->K'&,10d>0d,10#&CD02<,10d'&,10230#]730hi71(&0k?A8;#&86?=5&?230d7<*->'),10d>{0d,.0#&CD02db&U0
CD*
#&2186h+0d,10h897A73*f[0c71(&0i*-'&718;?A%-4<230d7dV 071(+0#%'&')46890h71(&8;2*-'&7186?A%-4Y230d7A*->F'&,.0d>{0d,10#)CD0273*
71(+0$73,.%-8;#&86#+LkCD*-,1')5)2db]*-f)71%-8;#&8;#+L@%k'),10Cd8;2189*
#*->^V N>*-,U'),1*
#+*
?A8;#)%-4&%-#&%')(+*-,W%k,1021*
4;5+7189*
#%-#&h
o^V n N >{*-,<%-hm0CD7189E%-4g%-#&%'t(+*-,.%aV

`

\

x

f



\iuw}'z|uws
' s{t/~'s - y2}ffz|qy{s v't~bq2vy{t#uC~E}t#t#}u

uw/
urIz 2
q s#qg{uwz|uwsOy-q}u.- uw}us#ur~ z

f

's - y2}ffz|qy{s

+*
4;4;*<8;#&L+b+71(+0e'&,10d>0d,10#&CD02<5&230hc8;#71(&862Z0D^'\0d,.86?0#7Z%-#&hi71(+089,15&23718tCd%718;*
#c%,10k21(+*fi<#V

uv0fivzy|{~}C}CQfifi

#71(&8;2Rt#&%-4K0Da'\0d,.8;?0#]7db71(+0N'&,10d>0d,10#&CD0A230d7B*-f)71%-8;#+0hH8;#:71(+0'&,.0dE^89*
5)2R0Da'\0d,.8;?0#]7FU%-2k5&230h
PQ8;#&Cd465&h&8;#+L=71(+0k?A86#&8;?@5&?210d7Y*->S'),10d>{0d,.0#&CD02Y71(&%7ZU0kCD*
#&2.8;h+0d,10h73*Af\0B71(+0k*-'&718;?A%-4CD*
#atL
5+,.%O
7189*
#tTWVX<(+0#b+230dE-0d,.%-4%-49730d,W#&%7189E-02ZU0d,10e5&230h8;#*-,.h&0d,U73**-f)71%-8;#c%-#*-'&718;?A%-4['&,.0d>{0d,10#)CD0$U089L
(]7
%-21218;L
#&?0#]7dVX%f)4902:%-#&h:21(+*71(+0'&,.0d>{0d,10#)CD0/U089L
(]7N%-2.2189L
#&?0#]712@>{*-,N'&,.*
#+*
?A8;#&%-4%-#&h
%-h30CD7189E%-4g%-#&%')(+*-,W%ab&,1023'\0CD7189E-049_-V
XY()8;2Ut#&%-4230d7<*->CD*
#&2173,.%-8;#]712<%-#&h'&,.0d>{0d,10#)CD02Y%-2Z'&,10230#]730h86#^0CD7189*
#^V ^V
fi

fi@ 2~,7

MG,10d>VIR*+V
l






p




l



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

$021CD,.8;'&7189*
#
"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k21%-?A0e"RM %-2Z71(+0k%-#)%')(+*-,
"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0e'&,.0dE^89*
5)2U"$M73*A71(&%7
CD*
#]71%-8;#&8;#&L71(+0e%-#&%')(+*-,
"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k?*
217Z,10CD0#7$5&#&Cd49*
210hc"RM
"$#730CD0h&0#712$8;#71(+0e73*-'t8;C
"$#730CD0h&0#712R71(&%7<%'&'\0%,YR8971(71(+0eE-0d,1f*->S71(+0=%-#&%')(+*-,<?A*-,10
71(&%-#i*
#&CD0
"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k21%-?A0B'[*
2.897189*
#<8971(,.0d>{0d,10#)CD0
73*A71(&0eE-0d,1f%-2<71(+0e%-#&%')(+*-,@Pf[0d>*-,10B*-,$%>{730d,T
"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k21%-?A0B'[*
2.897189*
#<8971(,.0d>{0d,10#)CD0
73*A71(&0k5+73730d,.%-#&CD0=%-2Y71(+0e%-#&%'t(+*-,
XY(&0e#+0%,10237<%-#]730CD0h+0#]7<73*A71(&0k%-#&%')(+*-,

089L
(]7
-
B'

B'
l



"L

X%f)490k^pGMG,10d>0d,10#&CD0BU089L
(7R%-212189L
#&?A0#7Z>*-,<'&,.*
#+*
?A8;#&%-4\%-#&%'t(+*-,.%

MG,10d>VI<*+V
l






p






$021CD,.8;'&7189*
#
"$#730CD0h&0#712$71(&%7<%,.0e8;#71(+0k21%-?A0k"RM%-2Y71(+0e%-#)%')(+*-,
"$#730CD0h&0#712$71(&%7<%,.0e8;#71(+0e'&,.0dE^89*
5)2Z"RM}73*A71(&%7
CD*
#]71%-8;#&8;#&L71(+0k%-#&%')(&*-,
"$#730CD0h&0#712$71(&%7<%,.0e8;#71(+0k?*
217Y,10CD0#]7<5&#&Cd49*
210hc"RM
"$#730CD0h&0#712F8;#71(+0B73*-'t8;C
"$#730CD0h&0#712$71(&%7<2.(&%,10B71(+0e21%-?A0e^86#&h*->?A*^h&89)0d,.2
"$#730CD0h&0#712$<8971(0D+%-CD7149_71(+0e21%-?A0k?*ah&8)0d,.2
"$#730CD0h&0#712$71(&%7<%L-,.0d0k8;#c#^5&?kf\0d,
XY(&0e#+0%,10237<%-#]730CD0h+0#]7R73*71(+0e%-#&%')(+*-,

X%f)490k^pGMG,10d>0d,10#&CD0eU089L
(]7<%-212189L
#)?0#7Z>*-,<%-h30CD7189E%-4g%-#&%')(&*-,.%



089L
(7
-
l'

l'

-



"L

fi

i{9 ] DA2

2{~i{

uv0fiv0h`?zF>JF5QS@0z@zF

#`*-,Wh+0d,N73*:*-f)71%-8;#71(+0*-'&718;?A%-4U'&,10d>0d,10#&CD0U089L
(7%-212.89L
#&?0#]7dbU0'\0d,1>*-,.?0h230dE-0d,.%-473021712
<8971(71(+073,.%-86#&8;#+L:CD*-,1')5&2dV`XY(]5)2db%>{730d,A4;*]*-a8;#+L%7A%-4;4U71(+0'\*
212189f)864;89718902B%-#&hL
8;E-0#`71()%771(&8;2
%-2i71(+0210d7i*->N'&,10d>0d,10#&CD02i(&%E^86#+L71(+0f\0237c,102.5&49712db$0`CD*
#&218;h+0d,.0h897c73*f\0H71(+0*-')718;?A%-4
CD*
#a)L
5&,.%7189*
#V 8;71(`71()8;2=CD*
#+)L
5+,.%7189*
#gb0*-f&71%-8;#+0h%'&,10Cd8;2.89*
#*->$Bo 'aV N >{*-,N'&,1*
#&*
?A8;#&%-4
%-#&%')(&*-,.%N,1023*
4;5&7189*
#c%-#&hn-^V;il N >{*-,R%-hm0CD718;E%-4g%-#)%')(+*-,.%N,1021*
4;5+7189*
#V
\

n

's#q2v,u,|q2v't#qy{s

x
u)~y{}!t~ z

$218;#+L71(+0Nt#)%-4S'),10d>{0d,.0#&CD0A230d7eh+0Dt#&0hH8;# La'[0d,W8;?0#]7Fc%-#)h71(+0'&,1*-'\*
230hCD*
#&2373,W%-8;#7e210d7dbS%
f)4;86#&hN0dE%-465&%7189*
#/U%-2UCd%,1,.890h*
5+7U*E-0d,71(+0<0#]7189,10R730237CD*-,1')5&2dVXY()8;20dE%-4;5&%7189*
#/U%-2'\0d,1>*-,.?0h
8;#&h&0d'[0#)h+0#7N*->$71(+0i73,.%-86#&8;#+L'&,1*aCD0212/23*%-2A73*L
5&%,.%-#]730d071(&%7/71(+0i73,.%-8;#)8;#+L*
5)4;h(&%E-0:#+*
8;#a[5+0#&CD0F*E-0d,R71(+0Bt#&%-4\'\0d,.CD0#]71%L-02dV
"$2B%,10215&4;7db[U0*-f&71%-8;#&0hH%/'),10Cd8;2189*
#:*->oalV N>*-,B'&,1*
#+*
?A86#&%-4S%-#)%')(+*-,.%,1023*
465+7189*
#%-#&h
oalV N >{*-,<%-hm0CD7189E%-4g%-#&%'t(+*-,.%N,1023*
465+7189*
#V



,!

#71()8;2<'t%'[0d,$U0N()%E-0'&,10210#730h%-#%-49L-*-,.8971()? >*-,e8;h+0#]7189>_^8;#&LA71(+0N#+*
5&#')(+,.%-230N%-#]730CD0h+0#712
*->'&,1*
#&*
5&#&2%-#&h%-h30CD7189E%-4)%-#&%')(&*-,.286#/^')%-#&8621(Ah&8;%-4;*-L
5+02dVKXY(&8;2%-49L-*-,.8971(&?0D^'t49*
89712h&89[0d,10#]7
a8;#&h&2F*->Y8;#&>{*-,.?%7189*
#pe4;8;#&L
5&8;23718;C@a#+*R490h+L-0-bKh&8;21CD*
5+,W230fih&8;%-49*-L
5&0N2173,.5&CD715+,10/8;#+>*-,.?A%7189*
#b%-#&h
h&8;2.CD*
5+,.230Y73*-'t8;C<a#+*fi<490h+L-0-V 7U862f)%-230h*
#%=210d7*->CD*
#)2373,.%-8;#]712%-#&h'),10d>{0d,.0#&CD02GR(&8;C.(h+0d'\0#&h
*
#i%-4;4%E%-8;4;%f)490Fa#+*R490h+L-0k8;#*-,Wh+0d,Y73*A,1021*
49E-0e%-#&%')(+*-,W%aV
#A%-h&h&8;7189*
#b-%eh+0Dt#)897189*
#@*->\71(+0Y%-#&%')(+*-,W8;C%-CdCD0212189f)864;897_@23')%-CD0Yft%-230h*
#Ah&8621CD*
5+,.230fih)8;%-49*-L
5+0
2373,.5)CD715+,10A8;#+>*-,.?A%718;*
#HU%-2k'&,10230#]730hV 0(&%E-0/21(&*<#H71(&08;?'\*-,171%-#&CD0*->71(&862e%-CdCD0212189ft8;4;897_
23')%-CD0e86#%-#)%')(+*-,.%@,1023*
465+7189*
#ba8;#CD*
#73,W%-237Z73*A%-49L-*-,.8971()?A2U71(&%7Yh+*#+*-7,1049_/*
#c%-#_215&C.(c21')%-CD0-V
Y02.5&49712Z21(+*fi71(&%7$n-^V n N*->K71(+0e%-#]730CD0h+0#712$U0d,10k49*aCd%730hi8;#71(&0e'&,1*-'\*
230hc23't%-CD0-V
K8;#&%-4649_-bU0/h+02.CD,.89f\0h%210d7=*->Z0Da'\0d,.8;?0#]712eCD*
#&CD0d,.#)8;#+L71()8;2e%-49L-*-,.8;71(&? %-#&h`%-CdCD0212189ft8;4;897_
23')%-CD05&218;#&L%CD*-,1')5&2k*->ZB ':h&8;%-49*-L
5&02dVXY(+0/%-49L-*-,.8971(&? U%-2=8;?')490?A0#730h5)218;#+LcM,.*
49*-L+V #
*
5+,t#&%-4)0D^'\0d,.8;?A0#7db^%e'&,10Cd862189*
#A*->oalV N%-2U%-C.(&890dE-0h>*-,'),1*
#+*
?A8;#)%-4&%-#&%')(+*-,W%e,1023*
465+7189*
#
%-#&hi%A'&,10Cd8;218;*
#/*->oalV N U%-2R%-C.(&890dE-0h>{*-,R%-hm0CD718;E%-4g%-#)%')(+*-,.%,.023*
4;5+7189*
#gV
"$2F%/73*^*
4>{*-,F,1021*
49E^86#+LA'&,1*
#&*
?A8;#&%-4S%-#&h%-hm0CD718;E%-4%-#&%')(+*-,W%>*-,k^')%-#&8;2.(h&8;%-4;*-L
5+02db[71(&8;2
23_a23730?Cd%-#f\0k5&210h8;#215+'&'\*-,17Z*->E%,.89*
5&2<IRJSM71%-21^2db\8;#&Cd465&h&8;#+LN?A%-CW(&8;#+0=73,.%-#&214;%718;*
#b)8;#+>*-,3O
?A%7189*
#i0D^73,.%-CD718;*
#b&,10d73,.8;0dE%-4g86#+>{*-,W?A%7189*
#ba*-,<^5+0237189*
#+O%-#&23U0d,.8;#+L+V
V5&,1,10#]7149_-b\71(+0A%-5+71(+*-,.2B%,.0*-,1a8;#+L*
#H8;#&CD*-,.'[*-,W%718;#+L230?A%-#]718;C8;#+>*-,.?A%7189*
#:8;#]73*71(+0A%-4O
L-*-,.8971()?cV



)





XY(+0A%-5&71(+*-,.2B<8621(73*71(&%-#&:I$%7189Ea8;h&%-hMG,.890d73*+bS&0d,1,.%-#M4;%ab%-#&h"R#]73*
#&89* O*
4;8;#)%>{*-,k()%Ea8;#+L
CD*
#]73,.89f)5+730h71(+089,=71%L-L-0d,JS8;h&8;
% O*-,10#+*>{*-,N(+0d,=(&049'&>Q5&4K,10dEa8;2189*
#&2e*->Z71(+0/8;h&0%-2e'&,10210#730h8;#
71(&8;2')%'\0d,e%-#)h R%>%0
4 O:5 #+ *--
b O:%a8;?8;4;8;%-#+*a%-89DOIR*]0h&%abF"$#73*
#&8;*&0d,1, %-Q #&h+0d-bF%-#&
h
0J2 5&Q 2
M0d,.%-4\>*-,U71(&089,ZCD*
4;4;%f\*-,.%7189*
#8;#'\0d,1>*-,.?A8;#+Lk71(+0F0D^'\0d,.8;?A0#712dV 0e%,10e%-4623*=L-,W%730d>5&4\73*A210dE-0d,.%-4
%-#+*
#]_^?A*
5&2,10dEa890dU0d,.2*->\71(+0B+waxWrts-[wmZq$xQz zQs ffWr)D z9]drtW~
<~d.sx3DvF>{*-,G(&049'&>Q5&4aCD*
?A?0#]712
*
#c0%,.46890d,<h+,.%>712*->K71(+0e')%'\0d,V


fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

XY()8;2B,10230%,WC.((&%-2ef\0d0#215+'&'\*-,1730hf]_71(+0VU*
?A8;2.8?*
Q # #730d,.?8;#&8;23730d,W8;%-4h+0 V8;0#&Cd8;%c_XS0CO
#+*
49*-LgR Q %=P6V V "BXRT[*->&71(+0Z^')%-#&8621(FL-*E-0d,.#)?0#7db]5&#&h+0d,g'),1*m0CD7K#^5&?kf\0d,.2X VYn
O['

^lO V '
fiO['+l'

%-#&h j Fln-n-ofiO['1'
-o^V
gUm )
"$4;490#b+V9b4VU*-,10-bgO`VSPmln-n
-TWVU$,.%>7Z*->Y"sOaJGp)F8;%-49*-LA%-CD7<?%,1^5&'i8;#c230dE-0d,.%-4g46%_-0d,.2dVX0CW(V
,.0d'gV9b)XY(+
0 O:5&497189't%,17_F8;21CD*
5+,.210=$,1*
5+'ggV $#&89E-0d,W21897_*->KY*aC.(+023730d,btY*aC.(&023730d,b Ba"=V
%-215+,.h&0YM,1*30CD7$Pmln-n-o
TWV-u+wr)!sr[.w^~WZ-u+W1DvkzQs-w1
)9)~dzrKz@zQ1|@wAszr+~V\V V "BX
PQX VZn-ofiO!-fi V '

TW
V $<r
J | ~2""J"fi5@ ".fi?#&
$ ! ! V

%-4;h+<86#b<$VePmln-n
-TWV V*-L
"qV$p j 89L
( '&,10Cd8;218;*
# CD*-,.0d>{0d,10#)CD0H<8971( 4;8;?A8;730ha#+*<4;0h+L-0%-#&h
468;#+L
5&8;21718;CY,1021*
5+,.CD02dV #jx3wWW1|zr]-~@wm$q{ FGq Fw-x.fi~.v^wWuw-rSu+dxms
QzQwr[sCks
!w-x.~
zj
r x3s
Qz.s- P
ZwD^~DKq$r[sWu)v^wx3sYD~Dw+QzQw-r&bt')'gV&-oO:%-h+,.8;hP!a')%-8;#tTWV
U_],.*
#b)@V9b,4^730#7db\"=VSPmln-n-o
TWV<"'&,104;86?A8;#&%,1_A?A*^h+04g*->CD0#730d,.86#+L8;#ih)8;%-49*-L+V #vZxmwW..|zr]~
w3v+
v}q$r&r)+s-~
`.dQzr]wm:v+qB~.~dwdzs-Qzwrdwz
x wRut+!s-Qzwrts<
z{r^-az6~DQzQd~sr[|
{v ffWr)dxWr[s-QzQw-rts wrDx1Dr[W=w_r wRut+!s-Qzwrts Kzr]-az{~QzD~= WZff2{q Fl "Dfib^'&'gV
lD] tlD]- O*
#]73,10%-46P V%-#)%-h&%TWV


#
)
W

2l "

V%,.4;0d7371%ab+
V9b+0d7Y%-4VPmln-n
-TWVGX<(+0F,104;8;%f)864;897_N*->K%h&8;%-49*-L
5&0$2373,W5&CD715+,10BCD*ah&8;#+L21CW(+0?0-V wRut+!s
Qzwrts-K
zr]
^z{~QzD~b K PmlTWbl^ -^V
F%-(&49f %-/ C.tbSIkVPmln-nalTWVY
utx3D~ddr)!s-Qzwr+~wmk z{~D.w-^xW~dd= w.-r&zQQz{-srt|s wRut+!s-QzQw-rtsKqB~!u&1~V
V%,1f\*
#+0464b &V9b54U,1*<#gbeVZPmln-o-o
TWV"$#&%')(&*-,.%i,1021*
4;5+7189*
#p%:?=5)49718O2373,.%730dL-_`%'&'&,1*
%-CW(V
ZxmwW..|zr]~wm
vrffWr)dxWrts
QzQwr[s& w-rddx3drtWwr wRut+!s-Qzwrts z{r]
az6~DQzQd~`
ff
Dfibt'&'gV&n- tl'+l@U5)h&%'\0237kP j 5)#+L-,1_&TWV

M(V@V71(+021862db$0d')%,.71?0#7S*-> U
V *
?')5+730d,S%-#&h #+>{*-,W?A%7189*
#=aCd8;0#&CD0-bfiJS8;#+\*-/ ')8;#+L_$#&89E-0d,.218;7_-b
JS8;#+\ *-/ ')8;#+L+b)^U0h+0#V

LGC.-0d,17dbO`V9b54^73,.5+f\0-bOVPmln-n-n
TWV:F8;%-49*-L
5&0/%-CD712db23_a#&CW(+,1*
#&8;2.8;#+Lc5&#&89712k%-#&h`%-#)%')(+*-,.%c,.023*O
465+7189*
#V #v
x3w.1|-z{r]-~w3Bq$@~DDx3|
wxW~Wv^wWuw-rva \dAsr)QzD~Ns-rt|
x3s

QzQd~wm
kzs9w1-)q

F"R?23730d,.h&%-? P j *
4;4;%-#)htTWV



< CW~gFl "





+0d,1,%-Q #&h+0d-b
"=V9bMK%-49*
?A%,bO`V9bE4 O*-,10#&*+b
JV&Pmln-n-o
TWV)"$#&%')(+*-,.%R,1023*
465+7189*
#k86#=5&#&,102373,.8;CD730h=730Da712
R8971(')%,.718;%-4')%,.2.8;#+L+V #rx3wWW1|zr]~cwm/v+vq$r)r&&sWdQzr]HwmvaqF~W~DwzQs
QzQwr
dwL
x w-<u[a!s
QzQwr[s
z{r^-az6~DQzQd~srt| v
v ffWr)dxWr[s-QzQw-rts
w-rddx3drtWw-r w-<u[a!s
QzQwr[s
z{r^-az6~DQzQd~ W ff2!{q Fl Db+'&'gV&-o- ^-nall O*
#]73,10%-4U6P V%-#&%-h&%TWV
+0d,1,%-Q #&h+0d-bF"kV9bBMK%-49*
?A%,bO`V9bfi4 O*-,10#+*+bBJVePmln-n-n
TWV "$# 0?')89,.86Cd%-4R%'&'),1*
%-C.( 73*^'t%-#&8;21(
%-#)%')(+*-,.%,.023*
4;5+7189*
#gP
V
Dv]z{r[ &xms-r+~W9s-Qzwr&b P]TWbKlnal^al^V

+*[b$VZPmln-o
-TWVkz{~D.w-^xW~dtQx+Qax3srt|q$rtsWutv^wx3s
cxzdr srt|`.wr)DxW~Ds
QzQwr[sLr^-z6~WvV
VZ%-?kf&,W8;h+L-0=^715&h)89028;#cJ8;#&L
5&8;23718;Cd2
V V%-?=f&,.86h+L-(
0 R#)89E-0d,.21897_/MG,10212dbJVZ%-?kf&,W8;h+L-0-V

F%-4;46%,.h+*+b-$VaPmln-n-
TWVtq$rgs z{~Wz{~ wr&dx.~ds
dzwrts-&x3s-|s- Qz.sN|d"<1Wu[!wxVVU*
490CdCd8?*
Q #Aa86#&%')218;2V
Lh&8;Cd89*
#&0_
2 L')8;21730?0-bt[VJV9b%-4;0#&Cd8;%aV
fiff

fi

i{9 ] DA2

2{~i{

$,1*
21-bK$VPmln
--TWVXY(+0,10d'&,10230#]71%7189*
#%-#&h5)230A*->Z>*^Cd5&2=8;#%23_^21730? >*-,=5&#)h+0d,.2371%-#&h)8;#+Lch&8O
%-4;*-L
2dV # ZxmwW..|zr]~ewmL
kGz &
v ffWrtDxrts-Qzwrts[aw-z{r) wrddx3drtWkwr/q$xDQz zQs-.ffWr)Dz^Drt
ffW,
g
q ffl " fib)'&'gV)
V%-?kf),.8;h+L-0-b O:"-P Ba"BTWV
$,1*
21-bgRVPmln-oalTWVk+*aCd5&2186#+L%-#)hh+02.CD,.89'&7189*
#8;#:#&%715+,.%-44;%-#+L
5&%L-0Nh&8;%-4;*-L
5+02dV #;DDrt~wm
kz{~DWwax.~ Srt|]DxW~!srt|-z{r]
V V%-?=f&,.86h+L-(0 R#)89E-0d,.21897_/MG,10212db V%-?=f&,.86h+L-0-V
$,1*
21-b\$V9bJ
*
21(&8b["kV9b4 08;#&2373086#b\VPmln-o-
TWVkMG,1*Ea8;h&8;#&L%/5)#&8)0h%-CdCD*
5&#7F*->Gh&0Dt#&89730@#+*
5&#
't(+,.%-23028;#h&8;21CD*
5&,.230-V # ZxmwW..|zr]~ewmRv+ ~Dq$r&r&&s.Qz{r^wmRva<qF~W~DwzQs-Qzwredwx
w-<u[a!s
QzQwr[sJ
Kzr]-az{~QzD~Wb+')'gV+- ^B' V%-?=f&,.86h+L-0-bgO" P-Ba"BTWV
$,1*
21-bG$V9bE-*
21()8b"kV9b4 086#&237308;#bG[VZPmln-n-
TWV V0#730d,.86#+L+p" >,.%-?0dU*-,1>*-,?*ah+04;8;#+L71(+0
4;*^Cd%-4gCD*
(&0d,10#&CD0e*->h&8;2.CD*
5+,.230-V wRut+!s-QzwrtsJz{r]
az6~DQzQd~Wb P
TWb\B'
^--^V

j 0%,.237db_OV$Pmln-n]TWV O:5&497189O!')%,.%L-,.%')(210dL
?0#71%718;*
#*->F0D^'\*
218;73*-,1_`730Da7dV #Zxmw..|z{r^~:wm
rt|q$r&r&&sfi `.Qz{r]wmevaFqB~.~dwdzs-QzwrNDwx w-<u[a!s
QzQwr[sCz{r^-az6~DQzQd~Wba'&'gV&ntlJS%-2
V,.5&CD02db&IR0d O0Da86CD*+V
j 89,.237dbt@VPmln-oalTWVZq$r[sWu)v^wx3szr=s-Qax3ssr]-&s^Sr[|DxW~!sr[|z{r^-Va'&,.8;#+L-0d,1O0d,.4;%L+b&U0d,.4;8;#gV

;e%-?0d_
%-?%abaO`V]Pmln-n
-TWV^Y0CD*-L
#&8986#+LY,10d>0d,10#]718;%-4
4;8;#&^2dp\"$#e8;#+>*-,.?A%7189*
#F0Da73,.%-CD7189*
#='\0d,.23'\0CD7189E-0-V
q F wxW~Wv^wWuwrS u+dxms-Qzwrts-gk s!wxW~kzrZxms
QzQWs yZ wd]~D
#jx3w.1|-z{r]-~@wmRq{ FG
qFrtsWu)v^w-xms<
~Dw- +Qzwr&b['&'gVa^ -O:%-h+,.86hP!^')%-8;#tTWV
J%')')8;#b+[V9b4J0%-212db j VPmln-n]TWV"R#%-49L-*-,W8971(&?>{*-,'&,1*
#&*
?A8;#&%-4t%-#&%')(+*-,.%=,1023*
465+7189*
#V wRuta
!s
QzQwr[sC z{r^-az6~DQzQd~Wb P]TWb--^-alV
O:%,17?R Q #+0dDO%,.CD*+bgMVPmln-n-n
TWVF"$49L-*-,.8;71?*/h+0=,1023*
4;5)Cd8?*
Q #h+0N4;%/%-#u%Q >{*-,W%'&,.*
#+*
?A8;#&%-4g0#h&8i%-Q 49*-L-*
2dV
ZxmwW~dsNzdr)!wi|d dr]-&s =s-Qaxmsb
b[ ^o-^V

@



7



?

h





O:%,17?R Q #+0dDO%,.CD*+bgMVPB'1'+lTWV YD~Dw&dz wr wRut+!s
zQwr[sG|@9sq$r s3Dwx3sdr ez s9w1w~= U~DQxW&d
Qax3s|D kz6~ddaxW~Dwj
wrtwz{Nz!Dr)!w Kzr] ~Qz.wVM(V@V^71(&0218;2db$#&89E-0d,.2186h&%-h/h&0$"$4;8;Cd%-#]730-b



"$4;8;Cd%-#]730-b[^'t%-8;#V

LE

O:%,17?R Q #+0dDO%,.CD*+baMV9b.4

%-49*
?A%,b,OV[PB'1'1'TWVgY023*
4;5)Cd8?*
Q #h+0<4;%B%-#q%Q >{*-,.%ap02373,.5)CD715+,.%eh+04+h)8?%-Q 49*-L-*
K
_cCD*
#+*aCd8;?A8;0#73*A4;86#+L,5\/ R Q 237186CD*+V Zxmw~dsNzdr)!wi|d@dr]-&s7ks
Q^x3sb b&]S^-^V

O:%,17?R Q #+0dDO%,.CD*+b&MV9ba0d7U%-4!V\Pmln-n-o
TWVK"R#)%-4;89%-h+*-,U')%,.Cd8;%-4\P$MGMYV #VU*^04;(+*+b
Wff r)d z9]drtdzsq$xDQz zQs- b+'&'V)--n ^&l=JS8;23f\*
#PQM*-,1715+L
%-4{TWV





j VP-LGhV TWbx3w1
x3D~.~Dw

O:%,17?R Q #+0dDO%,.CD*+bMV9b0d7B%-4VPmln-n-n
TWVcLE%-4;5&%718;*
#*->'&,1*
#+*
5&#,1023*
4;5&7189*
#%-4;L-*-,.8971(&?>{*-,k^'t%-#&8;21(
h)8;%-49*-L
5+02dV #vZ
xmwW..|zr]~Awm=v+ )dr[ dzQseu+dx=z &
xms
!sDr)!wq$+!wAs-Qz.wi|d{; z{r^-)
3^ q
fib+')'gV)-- ^-- 0#&8;CD0P 71%-49_+TWV

@W <l "



:



O:8973-*E[bSkVGPmln-n-o
TWVY*-f)5)237B'&,1*
#+*
5)#,.023*
4;5+7189*
#:<8;71(H4;8;?A89730ha#+*<4;0h+L-0-V #tZxmw..|z{r^~wm
v+ vq$r&r&&s `.dQzr]:wmvaNqF~W~DwzQs
QzQwrdwxj
wRut+!s-Qzwrts Kzr]
^z{~QzD~Asrt|
v
Wff rtDxrts-Qzwrts
wrDx1Dr[WBwrt
w-<u[a!s
QzQwr[s Kzr]-az{~QzD~k
ff !q{
dfib
'&'Vo--n


*
#]73,10%-4UP6
V %-#&%-h&%TWV



Q



i>

P
W 2 Fl





fi@ 2~,7



2 AK$)B

$CA



2B2{EDX<{$7

G
F





7BEHK.{JI22

MG46%ab[UV9b\4MG,.890d73*+b\IkVPmln-n-o
TWV(R2.8;#+LAL-,.%-??A%718;Cd%-4K8;#+>0d,10#&CD0@?0d71(+*ah&2<>*-,F%-5+73*
?A%718;C=')%,17mO!*->{O
21'[0d0CW(71%L-L
8;#+L+V
# ZxmwW..|zr]~wm
kGzx.~D ffWr)dxWrts
QzQwr[s wrDx1Dr[W:w
r gsr]
&s]
YD
~dwaxm~@s-rt
| &s-Qzwr` Q l D=$,W%-#&%-h&%iP!^')%-86#tTWV
Y086#&(&%,17dbXBVZPmln-o-
TWVq$rtsu)v^wx3s`s-rt|\ds-r)QzQ3ffWr)Dxutx1d!s-Qzwr&V U
V ,1*^*
? j 04;?cbJ*
#&h+*
#%-#&h
a_^h&#&0d_-V

Y0d_a#&%,b+VV$VYPmln-n-n
TWV a71%718;23718;Cd%-4Z?*ah+04;2@>*-,A73*-')8;C230dL
?A0#71%7189*
#gV #Zxmw..|z{r^~wm v
qFr&r&&s `.Qz{r]wmRvaRqF~W~DwzQs
QzQwr=Dw-x wRut+!s-QzwrtsKzr]-az{~QzD~kq Fl "fib^'&'gV^-

- O%,._^4;%-#)h-P Fa"BTWV
<86C.(b\L<V9b\4JS5+'\0d,.+*fi_-b[VPmln-o-o
TWV"R#&%'t(+*-,.%%,.C.()89730CD715+,10>*-,e%-#&%')(+*-,W%/,.023*
4;5+7189*
#gV #tZxmw
..|z{r^~/wmg
\..wr[s
| w-rddx3drtWwrqu
utz.
| ks-Qax3s sr]-&s^&
x3wWD~.~Wzr]Q9
q <Zl "dfib
')'gVglo ^/"$5&23718;#gb&X0D+%-2=-P Ba"BTWV
Y*aC.()%abO`VPmln-n-o
TWViq wx!u[]~$s~1|tQ&|wm@q$r[sWu)v^wx3szrkzs9w1-)~Azrr]
z{~.vsrt|<wxW
Q

&D~ddVMG(V@V&71(+02.8;2dbg$#&89E-0d,.218;7_*->Ga5)21230D\b&+5&21230D\Vg9;AV
a%-C.^2db j V9b++C.(+0dL
49*KbPLYV9b4|
0D[0d,.21*
#b+NV\Pmln
fi]TWVK" 12 8;?'t49023723_a23730?A%718;Cd2U>*-,71(&0<*-,1L
%-#&8;%7189*
#
*->K715+,W#71%^8;#&L>{*-,$CD*
#E-0d,.2.%7189*
#VLsr]-&s^DbQ P ]TWb-n-a-^V
a890dL-04!b][V9bE4 V%-237304;46%-#b+V&Pmln-o-o
TWVFkwr-uasx3sdQxzQt!s-Qz{~QzD~gdwxYva~Fvaszwx3s[zdrtWD~kP#&h
0h)897189*
#tTWVO:C$,.%ZO j 864;4V
^73,.5&f[0-bO`V9bZ4 j %-(&#b=VGPmln-n-n
TWV@)5&#&CD7189*
#&%-4KCD0#]730d,.8;#+L+pe$,1*
5)#&h&8;#+L,10d>{0d,.0#718;%-4KCD*
(+0d,.0#&CD0A8;#
86#+>{*-,W?A%7189*
#c2373,.5)CD715+,10-V wRut+!s-QzwrtsJz{r]
az6~DQzQd~Wb P
TWb\B'
n^-+V
"*
5&?A%-#)2db@VaPmln-nalTWV+"#&0d73*^*
4>*-,h)8;21CD*
5+,.210G%-#&%-49_a218;2dpgX<(+0GE-*aCd%f)5&4;%,._F?%-#&%L-0?0#]7'),1*t490-V

sr]
+s]Db P]TWbg-ao-n^V



fiJournal Artificial Intelligence Research 15 (2001) 115-161

Submitted 4/01; published 8/01

GRT Planning System: Backward Heuristic Construction
Forward State-Space Planning
YREFANID@CSD.AUTH.GR
VLAHAVAS@CSD.AUTH.GR

Ioannis Refanidis
Ioannis Vlahavas
Aristotle University
Dept. Informatics
54006 Thessaloniki, Greece
Abstract

paper presents GRT, domain-independent heuristic planning system STRIPS worlds.
GRT solves problems two phases. pre-processing phase, estimates distance
fact goals problem, backward direction. Then, search phase,
estimates used order estimate distance intermediate state
goals, guiding search process forward direction best-first basis. paper
presents benefits adoption opposite directions preprocessing
search phases, discusses difficulties arise pre-processing phase introduces
techniques cope them. Moreover, presents several methods improving efficiency
heuristic, enriching representation reducing size problem. Finally,
method overcoming local optimal states, based domain axioms, proposed. According it,
difficult problems decomposed easier sub-problems solved sequentially.
performance results various domains, including recent planning competitions,
show GRT among fastest planners.

1. Introduction
far, planning problems considered special kind particularly difficult search
problems (Newell & Simon, 1972) many algorithms decomposition, abstraction, least
commitment etc. proposed cope them. early 90's, researchers arguing
plan-space planning efficient state-space planning (Barrett & Weld, 1994;
McAllester & Rosenblitt, 1991; Minton, Bresina & Drummond, 1994; Penberthy & Weld, 1992).
mid 90's, new algorithms appeared achieved even better performance transforming
planning problems either graph solving problems (Blum & Furst, 1995, 1997)
satisfiability ones (Kautz & Selman, 1992, 1996, 1998). However, shown simple
search strategies use domain-dependent heuristics solve large problems (Gupta &
Nau, 1992; Korf & Taylor, 1996; Pearl, 1983; Slaney & Thiebaux, 1996).
recent years, part planning community turned towards heuristic planning, adopting
known search strategies developing powerful domain-independent heuristics achieve
significant performance. first planner UNPOP (McDermott 1996, 1999) followed
ASP (Bonet, Loerings & Geffner, 1997), HSP (Bonet & Geffner, 1998), HSPr (Bonet & Geffner,
1999), GRT (Refanidis & Vlahavas, 1999b), FF (Hoffmann & Nebel, 2000) ALTALT (Nigenda,
Nguyen & Kambhampati, 2000). domain independent heuristic planners search solutions
either state-space regression space. use variations relatively
simple idea guide: estimate distance two states, based estimates
distances fact problem one two states.
2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiREFANIDIS & VLAHAVAS

planners primarily classified based forward backward direction,
heuristic constructed state-space traversed. distinguish following
three categories:




Forward heuristic construction, forward search (ASP, HSP, FF).
Forward heuristic construction, backward search (HSPr, ALTALT).
Backward heuristic construction, forward search (UNPOP, GRT).

Generally, forward direction seems advantageous backward one,
constructing heuristic searching, backward direction case
incomplete goal states, problems invalid states unreachable facts usually arise.
However, using forward direction tasks requires reconstructing heuristic function
visited state, spending way significant portion processing time, using
opposite directions tasks allows constructing heuristic once, pre-processing phase.
paper presents GRT planning system. domain independent heuristic
planner constructs heuristic once, backward direction pre-processing phase.
UNPOP, although uses directions, reconstructs heuristic scratch visited
state. GRT, pre-processing phase estimates distance fact goals
problem. search phase, estimates used order estimate distance
visited state goals, guiding search process forward direction
best-first basis. Constructing heuristic offers ability evaluate states
quickly, traversing state-space forward direction allows planner avoid invalid
states arise regression space.
paper substantially extends previous work (Refanidis & Vlahavas, 1999b, 1999c, 2000a
2000b), presents proves fundamental theory planner, along many
new techniques developed it, extensively tests contribution technique overall
performance provides thorough comparison planning systems.
rest paper organized follows: Section 2 presents data structures main
algorithms planner. Section 3 discusses difficulties incomplete goal states cause
backward direction construction heuristic presents methods cope them.
methods also applied identify enrich poor domain representations.
Two approaches reduce problem's size presented Section 4. first one deals
identification elimination irrelevant objects second one concerns adoption
numerical representation resources.
Section 5 deals problem local optimal states proposes method cope
them. Specifically, XOR-constraints introduced used order decompose difficult
problems easier sub-problems solved sequentially. Section 6 presents
operation GRT, Section 7 presents related work Section 8 presents performance results,
show GRT among fastest domain-independent planners. Finally, Section 9
concludes paper poses future directions.

2. GRT Heuristic
STRIPS (Fikes & Nilsson, 1971), action represented three sets facts:
precondition list Pre(a), add-list Add(a) delete-list Del(a), Del(a) Pre(a).
state defined finite set facts. action applicable state if:
Pre(a)
state resulting application action state defined as:
116

(1)

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

S' = res(S,a) = \ Del(a) Add(a)

(2)

Inductively define state resulting application sequence actions (a1,
a2, ..., aN) state as:
S' = res(S, (a1, a2, ..., aN)) = res( res(S, (a1, a2, ..., aN-1)), aN)

(3)

requirement action ai applicable state res(S, (a1, a2, ..., ai-1)),
i=1, 2, ..., N. formalization used henceforth, set problem constants assumed
finite function symbols used, set actions finite.
planning problem P triplet P=(O, Initial, Goals), set ground actions,
Initial initial state Goals set facts. task find sequence actions a1, a2,
..., applied initial state, state resulting application
superset Goals. sequences actions called Plans. plan applied
initial state called valid plan. valid plan achieves Goals called solution
planning problem. planning problem may several solutions. latter case
problem described unsolvable.
next sub-section gives brief presentation ASP heuristic, motivation
helps understand following concepts, whereas subsequent sub-sections present
GRT heuristic detail.
2.1

ASP Heuristic

ASP heuristic, action fact p Add(a), rule Cp formed,
C=Pre(a). Assuming set rules, said fact p reachable state p
rule C p fact q C reachable S.
So, function g(p,S) defined, inductively assigns number fact p,
estimate number steps needed achieve p S, i.e. distance p S.
specifically, g(p,S) set 0 every fact p S, g(p,S) set i+1, 0, fact p
rule C p exists, g (r , ) = . Thus:

def

g ( p, ) =

{

rC

0,

p

i+1,

Cp,

g (r, ) =
rC

,

(4)

p reachable

case one rules Cp fact p, rule minimum
cost chosen. Note fact p initially achieved rule C1p, may re-achieved,
later, another rule C2p smaller cost. preconditions
second rule achieved time first rule applied. task applying
rules continues rule achieve fact smaller cost exists. distances
computed way unique.
set facts P, distance defined as:
def

g ( P, ) = g ( p , )
pP

(5)

ASP planner uses g(P,S) estimate distances intermediate state
Goals. So, ASP heuristic function defined as:

117

fiREFANIDIS & VLAHAVAS

def

H

( ) = g (Goals , )
ASP

(6)

ASP heuristic take account delete lists actions. simplified
problem created ignoring delete lists referred relaxed problem
corresponding actions referred relaxed actions. complexity constructing
HASP(S) linear, respect number ground actions number ground facts.
2.2

Backward Heuristic Construction

Instead estimating distance fact current state forward direction,
ASP does, GRT estimates distance fact goals backward direction.
task performed once, pre-processing phase. search phase, estimates
used estimate distance intermediate state goals. backward
forward estimation distance two states often results different values, since
heuristic precise. However, two directions result estimates equal quality average.
estimates distances fact goals stored table, records
indexed facts. call table Greedy Regression Table (by
acronym GRT comes from), since estimates obtained greedy regression
goals.
order construct heuristic backwards, actions problem inverted. Let
action S' two states, applicable S' = res(S,a).
inverted action a' action applicable S', = res(S', a'). inverted action
defined original action follows:
Pre(a')=Add(a) Pre(a) \ Del(a)
Del(a')=Add(a)
Add(a')=Del(a)

(7)

inverted ground actions applied goals, assigning progressively ground
fact p estimate distance goals, way similar ASP. Applying inverted actions
goals presupposes goals form complete state. Section 2 assumed
always case, whereas Section 3 case incomplete goal states treated.
2.3

Related Facts

order obtain precise estimates, GRT heuristic tries track interactions arise
estimating distances fact goals. word 'interaction' mean
achieving fact may affect achieving facts positively negatively. order track
interactions notion related facts introduced.
Definition 1 (Related facts). fact q related another fact p, achieving p causes fact q
achieved well.
use notation q

%

rel

p denote q related p. set facts related

specific fact p denoted rel(p), i.e.:

rel ( p ) = {q : q %rel p}

(8)

set related facts set facts P defined union related facts P-facts:
118

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

rel ( P ) =

rel ( p)

(9)

pP

Proposition 1. inverted action achieving fact p, related facts p defined as:
rel(p) = Pre(a) rel(Pre(a)) Add(a) \ Del(a)

(10)

Proof: Formula 10 inductive, since defines related facts fact p based related
facts preconditions action achieving fact. Thus, prove induction.
formula holds goal facts, suppose hypothetical inverted action
without preconditions achieving them. So, goal facts related other. Then, suppose
Formula 10 holds preconditions inverted action a. enough prove
holds also facts action adds. Let p fact. facts hold
application action, related facts p, hold
application, i.e. preconditions action together related facts, plus facts
action achieves, minus facts action deletes, exactly Formula 10 states.
According Formula 10, facts achieved action related facts.
Moreover, fact least related itself.
single path achieve specific fact, related facts would defined
unique way. However, rare situation. Thus, many actions achieve fact,
many paths achieve preconditions actions; therefore, extremely large
number possible combinations. Storing, fact, related facts possible ways
achieving it, requires huge amounts time space. efficiency reasons decided
store one set related facts fact, set corresponds shortest path
achieves fact, according heuristic.
Proposition 2. relation
Proof: relation

%

rel

%

rel

reflexive, neither symmetric, transitive.

reflexive, since fact related itself. relation

symmetric, since fact q, pre-requisite achieve p, q
achieving p delete q) p

%

rel

%

rel

%

rel

p may hold (if action

q may hold, since q may achieved

% transitive, since relations q % p p %
cannot conclude q % r holds, since possible action achieving r delete q.

p. Finally, relation



rel

rel

rel

rel

r


fact p, dist(p) denotes estimated distance goals. Next, present axioms
concerning distances facts.
Axiom 1. cost achieving set facts {p1, p2, ..., pN} simultaneously, cannot lower
maximum individual distances.
N

dist({p1, p2, ..., pN})

max (dist(pi))
i=1

(11)

Axiom 2. inverted action achieves fact p, distance p equal cost
simultaneously achieving a's preconditions plus one.
dist(p)=dist({p1,p2, ...})+1, pi Pre(a)
119

(12)

fiREFANIDIS & VLAHAVAS

Proposition 3. q

%

rel

p true two facts q p, dist(q)dist(p).

Proof: prove Proposition 3 induction. Proposition 3 holds Goals, since
goal facts zero distances related other. Suppose Proposition 3 holds
set currently achieved facts Facts. suffices prove action a,
Pre(a)Facts, Proposition 3 holds set FactsAdd(a).
Suppose fact pAdd(a) achieved, re-achieved smaller
cost. another fact q FactsAdd(a), q rel p, either q also

%

achieved hence dist(q)=dist(p), q precondition then, according Axiom2,
dist(q)<dist(p), finally q related fact a's precondition, say q' dist(q')<dist(p)
(Axiom 2) dist(q)dist(q') (Proposition 3 holds Facts), dist(q)<dist(p).
Let us suppose another fact q, p rel q. q achieved a,

%

dist(p)=dist(q). q achieved a, q previously achieved
another action, q Facts. case, p would also previously achieved another
action, re-achieved a, also p Facts. Since Proposition 3 holds Facts,
distOLD(p)dist(q), distOLD(p) previous distance p. new distance p smaller
previous distance, dist(p)<distOLD(p), dist(p)<dist(q). Therefore, Proposition 3 holds
every case.
Corollary 1. q

%

Corollary 2. q

%

rel

rel

p p

%

rel

p p

q, dist(p)=dist(q).

%

rel

q, q achieved p.

two corollaries follow directly Proposition 3. Concerning Corollary 2,
expression 'has achieved before' means pre-processing phase, distances
goals estimated progressively, dist(q) computed dist(p). case
fact re-achieved smaller distance, consider last time.
Corollary 3. sequence facts p1, p2, ..., pN, N>2, pi
without pi+1

%

rel

pi also holding, impossible pN

%

rel

%

rel

pi+1, i=1,2,...,N-1, hold,

p1.

Corollary 3 follows directly Corollary's 2 time ordering relation.
Proposition 4. Facts related achieved action.
Proof: Let p q two facts related other, i.e. q

%

rel

p p

%

rel

q. Let a1 action

achieves p a2 action achieves q, pAdd(a1) qAdd(a2). prove
a1a2. Suppose a1a2. Since q rel p, q may add effect a1, precondition a1,

%

related fact a1's precondition. However, according Corollary 1, dist(p)=dist(q). Thus, q
cannot anything else add effect a1, case dist(q) < dist(p) would hold.
way prove pAdd(a2). Thus, {p,q}Add(a1)Add(a2). However,
case, first action applied computing distances would achieve facts. So, facts
achieved action.

120

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

related facts play critical role estimating cost achieving set facts
simultaneously. GRT groups related facts sums maximum individual cost group.
example, q rel p, p rel r q rel r hold three facts q, p r, three facts

%

%

%

grouped together contribute total cost maximum cost, dist(r).
However, q rel r hold (since relation
transitive), p r
rel

%

%

grouped together, q included group. case, q belongs another
group, contributes separately total cost.
aggregation process performed function AGGREGATE, described below.
function takes set facts {p1, p2, ...., pN} input, together distances dist(pi)
lists related facts rel(pi), estimates cost achieving simultaneously.
function used pre-processing phase, order estimate application cost
inverted actions, search phase, order estimate distance intermediate state
goals.
Function AGGREGATE
Input: set facts {p1, p2, ..., pN }, distances dist(pi) lists related facts rel(pi).
Output: estimate cost achieving facts simultaneously.
1. Set M1 = {p1, p2, ..., pN }. Set Cost = 0.
2. (M1 ) do:
a) Let M2 set facts pi M1 included list
related facts another fact pj M1, without pj also
included list related facts. formally:

M2 = { pi: pi M1, pj M1, pi rel(pj) pj rel(pi) }
b) Let M3 set facts M1 included M2,
included least one lists related facts
elements M2.

M3 = { pi: pi M1 \ M2, pj M2, pi rel(pj) }
c) Divide M2 disjoint groups facts related
other. group add common cost facts Cost.
d) Set M1 = M1 \ (M2M3).
3. Return Cost

AGGREGATE function illustrated blocks-world problem Figure 1. Part
Greedy Regression Table problem shown Table 1. simplicity, fact p
consider related facts zero distances (i.e. Goals) fact p itself.
simplification affect estimated distances.




c

b

b

c

Initial State

Goal State

Figure 1: 3-blocks problem.
121

fiREFANIDIS & VLAHAVAS

Let us compute distance initial goal state. initial state consists
following set facts:
( (on table) (clear a) (on b table) (on c b) (clear c) )1
results Table 1, initial state facts related (on c b), whereas (on c b)
related fact. Thus, first iteration AGGREGATION loop, M2 set ((on c
b)) (step 2a) M3 set ((on table) (clear a) (on b table) (clear c)) (step 2b). So, Cost
becomes equal distance (on c b), i.e. 3 (step 2c) M1 becomes empty. second
iteration performed value 3, actual distance initial goal
state, returned.
Fact

Distance
goals

Related facts

(on c table)

0

()

(on b c)

0

()

(on b)

0

()

(clear a)

0

()

(on table)

1

( (clear b) )

(clear B)

1

( (on table) )

(on b table)

2

( (on table) (clear a) (clear b) (clear c) )

(clear c)

2

( (on table) (clear a) (clear b) (on b table) )

(on c b)

3

( (on table) (clear a) (on b table) (clear c) )

...

...

...

Table 1: Part Greedy Regression Table 3-blocks problem.
Corollary 3 ensures set M2 (step 2a function AGGREGATE) never empty.
Proposition 4 ensures M2 always partitioned groups facts achieved
action (step 2c). number iterations function AGGREGATE performs
bounded initial size M1, however usually single iteration performed.
2.4

Pre-Processing Algorithm

estimation distance fact Goals computation lists
related facts facts problem performed following algorithm:

1

representation facts, actions states adopt PDDL (Planning Domain Definition Language) syntax
throughout paper. manual PDDL language found URL
http://www.cs.yale.edu/pub/mcdermott/software/pddl.tar.gz

122

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

Pre-Processing Algorithm
Input:
action predicate definitions domain objects problem.
Output:
distance estimate goals dist(p) related facts rel(p)
ground fact p problem.
1. Let Actions set inverted ground actions given
problem. Actions, set dist()=+.
2. Let Agenda list inverted actions. Set Agenda=.
3. Let Facts set problem's ground facts. f
Facts set dist(f)= +.
4. f Goals set dist(f)=0 rel(f)=Goals.
5. action Actions, AGGREGATE(Pre())<+,
dist()=AGGREGATE(Pre())+1 add end Agenda.

set

6. Agenda do:
a) Extract first action Agenda, say .
b) every fact f Add(), dist(f)>dist(), then:
- dist(f)=dist()
- rel(f) = Pre() rel(Pre()) Add()\Del()
- every action b Actions, f Pre(b),
AGGREGATE(Pre(b))+1<dist(b), dist(b)=AGGREGATE(Pre(b))+1
push action b end Agenda.

Agenda works FIFO basis. action re-inserted Agenda cost
becomes smaller. Thus, fact achieved several times, time smaller cost.
cost applying Pre-Processing Algorithm polynomial number problem ground
facts ground actions.
Proposition 5. Pre-Processing Algorithm preserves Axiom 2.
Proof: step 6b, cost applying action set equal cost achieving
simultaneously preconditions action plus one. cost assigned add effects
action, except lower costs already assigned them. Thus, Axiom 2 preserved.


Proposition 6. Function AGGREGATE preserves Axiom 1.
Proof: prove Proposition 6 induction. Axiom 1 holds Goals, zero
distances related other. Besides, Propositions 3 4
Corollaries 1, 2 3 hold also them. Suppose next Axiom 1 induced
Propositions Corollaries hold currently achieved facts Facts. suffices prove
action a, Pre(a) Facts, Axiom 1 holds new set achieved facts
Facts'=Facts Add(a).
Consider set facts P Facts'. prove function AGGREGATE preserves Axiom 1,
regard randomly selected set P. Let p fact maximum distance among
facts P. According definition AGGREGATE function, suffices prove p
another fact equal distance included M2.
123

fiREFANIDIS & VLAHAVAS

p P\Add(a), every fact qP\Add(a), p

%

rel

q, dist(q)dist(p)

(according Proposition 3, holds Facts) finally dist(q)=dist(p), p
maximum distance among facts P (the rationale used case
sequence facts q1, q2, ..., qN, p rel q1 qi rel qi+1, i=1, 2, ..., N-1). q Add(a)
p

%

%

rel

%

q, p would precondition a, related fact precondition a. However,

case would possible p

%

rel

q, distance q would greater cost

p (according Axiom 2, holds preconditions action a)
contradiction hypothesis p maximum distance among facts P.
Let us consider case p Add(a). p firstly achieved, facts
q, p rel q hold, certainly achieved re-achieved add effects action

%

a, application cost. p re-achieved smaller cost,
impossible hold p rel q another fact q P\Add(a). Actually, hypothetical case

%

would dist(q)distOLD(p), since Proposition 3 holds q previous distance p,
distOLD(p)>distNEW(p), dist(q)>distNEW(p), contradiction hypothesis p
maximum distance among facts P. Therefore, case, p another fact equal
cost included M2 cost achieving simultaneously facts P equal higher
maximum distance.
close section mentioning two types facts, static facts dynamic
facts, found problem. first type concerns facts neither added
deleted action, second concerns rest facts. GRT classifies automatically
facts, analyzing action schemas domain. procedures presented Section 2,
i.e. distance estimates related facts, concern dynamic facts.

3. Detecting Enhancing Incomplete States
Backward heuristic construction induces problem: problems goals
constitute complete state description, possible apply inverted actions them.
example, commonly used logistics problems, packages moved
several locations via trucks planes, goals determine final locations trucks
planes. source problem GRT heuristic constructed using stricter
usual regression, i.e. uses actions, add effects non-deleted preconditions
(i.e. preconditions corresponding inverted actions) included within goals
(in usual regression, actions least one add effect within goals used). way
GRT succeeds obtaining precise estimates avoiding unreachable facts.
solution adopted GRT confront problem incomplete goal states enhance
goals new facts, contradiction existing ones. example, since
goals 'logistics.a' problem (Veloso, 1992) determine final locations two
planes, supposed one planes could three airports. So,
ground facts:
(at plane1 pgh_air) (at plane1 bos_air) (at plane1 la_air)
(at plane2 pgh_air) (at plane2 bos_air) (at plane2 la_air)
added new goal state, called henceforth enhanced goal state.
noted enhanced goal state used pre-processing phase,
construction heuristic. search phase, attention paid reach original
124

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

goals. way, completeness never lost, even case wrong facts
selected enhance Goals. However, selecting wrong facts may significantly affect
efficiency heuristic function.
Two issues arise trying enhance goals: first one detect candidate
new goal facts second one use. Sections 3.1 3.2 examine
issues, Section 3.3 similar technique used identifying enriching poor domain
representations.
3.1

Detecting Missing Goal Facts

Regarding identification candidate facts enhance goals, two automatic
approaches. first one consists forward GRAPHPLAN-like (Blum & Furst, 1999) prepreprocessing phase computes binary mutual exclusion relations (or simply "mutex"
relations) among facts problem. number optimizations approach
presented (Refanidis & Vlahavas, 1999c), based primarily monotonic behavior
mutual exclusion relations (Long & Fox, 1999; Smith & Weld, 1999) secondly fact
necessary construct complete planning graph, since used extracting
plan. computation mutual exclusion relations, facts mutually
exclusive goal fact considered candidates enhancement goals.
advantage extra information needed, apart usual STRIPS domain
representation. Moreover, mutual exclusion relations easily recognized human
expert detected way. Finally, approach also exploited coarse-grained
reachability analysis problem's facts. disadvantages approach time
consuming detect mutual exclusion relations higher order two.
second approach use domain specific knowledge form axioms. example,
axiom state truck plane always located place. So, goals
determine truck is, deduce set candidate goal facts using axiom.
advantage approach time needed deduce candidate facts negligible,
comparison time needed rest planning process. Moreover, complicated
relations simple binary mutual exclusion ones encoded. disadvantage extra
labor required domain encoding. However, several methods automatic discovery
domain axioms proposed, e.g. DISCOPLAN system (Gerevini & Schubert, 1998)
work Fox Long automated inference invariants (Fox & Long, 2000),
future plans adopt method GRT.
GRT planner uses first approach detect missing goal facts. Thus, overhead
total solution time imposed extra pre-processing work. contribution work
total problem solving time varies less 10% domains like blocks-world,
20% domains like logistics. ratio depends difficulty domain, i.e.
much time consumed search phase. Logistics problems easier blocks-world
problems, domain overhead severe. future, intend adopt
automatic method detecting domain axioms, order avoid overhead.
3.2

Enhancing Goals

GRT supports three methods selecting among candidate new goal facts:




Select candidate facts.
Use initial state facts.
Favor promising facts.

125

fiREFANIDIS & VLAHAVAS

first method considers found facts goal facts assigns zero distances them.
cases, enhanced goal state obtained way valid state, since new facts
may mutually exclusive (but original goals). advantage
approach heuristic construction fast, since many facts achieved
beginning large number actions become initially applicable. disadvantage
obtained heuristic less informative, since small differences obtained
estimates. So, best-first strategy tends towards breadth-first, visits states, consumes
time, generally produces better plans two methods.
second method enhances goals candidate facts also included
initial state, whereas facts mutually exclusive selected ones, rejected.
advantage method, compared first one, results greater differences
facts' distances, therefore faster search phase. hand, preference
initial state facts risk, - even worse - cannot included within
goals, search process may become disoriented, leading longer plans. method
suitable problems, objects' properties unnecessary solve problem
left undetermined goals.
third method tries combine advantages two. contrast them,
enhancement goals performed single step, prior construction heuristic,
method adds facts goals progressively, parallel heuristic construction.
Actually, facts added goals case Agenda (Section 2.4) becomes empty.
case, candidate facts progressively assigned zero distances, new inverted action
satisfies preconditions. time fact selected, candidate facts mutually
exclusive selected one rejected set candidate facts.
method favors facts combined already achieved facts, order make
inverted action applicable. following four rules applied decreasing preference:





facts combined original goals selected first.
Then, facts combined already achieved facts selected.
Next, facts included initial state selected.
Finally, remaining candidate facts selected randomly.

Generally, method results best solving speed and, many cases, produces equal
even better plans first two methods. However, especially terms plan quality,
many exceptions depending specific problem. difficult create problems
methods presented performs best. default method GRT planner
first one, method used AIPS-00 competition2.
Note domains, like blocks-world, freecell elevator AIPS-00 competition,
gripper movie domains AIPS-98 competition3, goals complete
near-complete state descriptions; therefore method used domains affect
neither solution time solution quality. domains, mystery (AIPS-98),
impossible predict, without solving planning problem, candidate facts could
actually goal facts, case acceptable method goal completion first
one.

2
3

official WEB page AIPS-00 competition found URL http://www.cs.toronto.edu/aips2000/.
official WEB page AIPS-98 competition found URL
ftp://ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html

126

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

3.3

Domain Enrichment

section, present approach adopted GRT planner, order deal poor
domain descriptions. word 'poor' refer domains negative facts implicitly
present initial state actions' preconditions. GRT faced problem twice,
movie elevator domains.
order explain problem, let us consider elevator domain, one elevator,
several floors several passengers. passenger located initial floor wants
move her/his destination floor. domain described four action schemas, (board Floor
Passenger) (depart Floor Passenger) boarding leaving elevator (up Floor1
Floor2) (down Floor1 Floor2) moving elevator.
action schema (board Floor Passenger) defined following PDDL formula:
(:action board
:parameters (?f ?p)
:precondition (and (floor ?f) (passenger ?p)
(lift-at ?f) (origin ?p ?f))
:effect (boarded ?p))
dynamic predicate definition action schema board boarded, add effect
denoting passenger boarded elevator. precondition requiring
passenger boarded. problem definition twofold. Firstly, action
applied several times passenger plan, i.e. passenger may board
elevator although she/he already boarded. Secondly, specifically GRT, stated
explicitly passengers initially boarded. Actually, initial state contains static facts
only, removed successive states. However, GRT takes account dynamic
facts order estimate distances. result initial state subsequent
states assigned zero distances Goals best-first strategy behaves breadthfirst one.
needed definition new predicate, say not_boarded. Facts predicate
added initial state, denoting passenger initially boarded,
action schema board changed accordingly.
GRT performs domain enrichment run-time. identification situation
performed way similar identification incomplete goal states. case, G RT
looks dynamic facts problem mutually exclusive initial state fact.
case facts, negations identified facts defined run-time added
initial state. Furthermore, negations added preconditions lists delete lists
actions achieve identified facts.
elevator domain case board depart actions boarded
served predicates. not_boarded not_served predicates defined run-time, initial
state enhanced facts determining passenger neither boarded served yet
actions board depart transformed accordingly. example, action schema board
transformed following definition:
(:action board
:parameters (?f ?p)
:precondition (and (floor ?f) (passenger ?p)(lift-at ?f)
(origin ?p ?f) (not_boarded ?p))
:effect (and (not (not_boarded ?p))(boarded ?p))

127

fiREFANIDIS & VLAHAVAS

similar situation arises movie domain. domain, goal enough snacks
watch movie. several action schemas form:
(:action get-chips
:parameters (?x)
:precondition (and (chips ?x))
:effect (and (have-chips)))
action schema static fact (chips ?x) precondition produces dynamic fact
(have-chips). action applied several times, however enough achieve goal
chips. difficulty domain initial state implicitly declares
chips (and dips pops etc), specific dynamic fact make clear.
Therefore, case domain enrichment process takes place, GRT assigns initial state zero
distance goals. domain enrichment feature, GRT detects facts like
have-chips, have-dips etc mutually exclusive initial state, defines
negations (not_have-chips, not_have-dips etc.), adds initial state transforms
actions accordingly.
domains, without domain enrichment feature GRT planner could
solve easiest problems. However, feature able tackle
problems efficiently.
Adding negative predicates preconditions actions may lead loss completeness,
since actions may able applied states, otherwise could. order
prevent completeness, GRT treats new preconditions conditional preconditions, i.e.
necessary application action state, however, present
current state removed successor one.

4. Reducing Size Problems
section, two methods reduce size problem, i.e. number ground facts
actions, presented. first method refers identification elimination objects,
certainly part solution. second method concerns adoption
numerical representation resources, instead problematic atom-based representation
numbers used domains like mystery freecell. Reducing size problem
reduces effort needed solve it, especially pre-processing phase, distances
facts problem computed.
4.1

Eliminating Irrelevant Objects

many domains, objects irrelevant solution. typical examples
found transportation domains, like logistics, mystery elevator,
packages initially found destinations specific destination determined.
So, objects, together facts actions containing them, removed
problem description, without losing completeness.
GRT developed method detects removes irrelevant objects. method
concerns pure STRIPS domains without negation preconditions actions goal
formula; however, easily extended cover cases. objects identified
pre-processing phase using following two rules:
object irrelevant solution specific planning problem, if:

128

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING




appear goal fact, unless fact also included initial state,
action containing object preconditions, unless object also contained
action's effects.

conditions strict, ensure detected object certainly
irrelevant, maintain completeness problem solving process.
Proposition 7. object satisfying rules safely removed problem
description, without sacrificing completeness.
Proof: Suppose object obj identified, two rules hold.
show obj necessary achieve goal fact, contain obj. Let us
assume fact g Goals, contain obj. Suppose action
achieves g, precondition containing obj. case, second rule violated, since
action including obj preconditions, without obj appearing effect. So, fact g
achieved actions without preconditions containing obj. Thus, regress goals
using actions achieving g, established subgoals contain obj. However, way
reject actions including obj preconditions achieve new established subgoals.
So, obj necessary achieve goal subgoal problem. Moreover, goal
fact containing obj, achieved; even one, already present initial
state. Therefore, obj safely removed problem.
application rules elimination irrelevant objects done
progressively. Let us consider enhanced logistics domain, added colors. Specifically,
define dynamic predicate (painted ?object ?color) denoting color package, static
predicate (color ?color) declaring available colors, action schema (paint ?object
?old_color ?new_color) painting package. Let us assume goal state
determine colors packages. case, colors irrelevant objects safely
removed, together facts actions include colors.
Suppose also brushes used perform paint operation. two
new action schemas, (get ?brush) (leave ?brush) predicate (have ?brush),
effect get action precondition enhanced action (paint ?package ?color ?brush).
case, brushes also irrelevant eliminated. However, since action paint
needs brushes effects containing (i.e. (painted ?package ?color) ), brushes
removed, due second rule. However, removing color objects, paint
actions removed; thus, brushes violate second rule remaining actions
safely removed.
disadvantage approach elimination irrelevant objects
remove objects eventually appear plan, better (i.e. shorter) plans
using them. example, logistics domain, suppose three cities, city1, city2
city3 package transferred one location city1 another location city2.
case, city3, together locations truck, necessary solve planning
problem, since package transferred directly city1 city2, without going via city3.
However, easy identify irrelevance city3. Actually, plans transport
packages city1 city2 via city3. decide remove city3 objects
problem representation, take risk sacrificing completeness, since problem may
become unsolvable. Deciding safely, without loss completeness, city3 objects
removed, hard solving original problem.
129

fiREFANIDIS & VLAHAVAS

approaches elimination irrelevant redundant information, order achieve
better performance, proposed Nebel, Dimopoulos & Koehler (1997), Scholz (1999)
Haslum & Jonsson (2000). work Nebel, Dimopoulos & Koehler concerns ignoring
irrelevant facts actions (not objects), based heuristics approximate plan
backchaining goals without taking account conflicts. Although approach
powerful, terms elimination, one presented section, solution
preserving. Furthermore, may time-consuming, since demands construction
initial approximate plan.
Scholz introduces action constraints, i.e. patterns action sequences applied
states produce overall effects. Action constraints used pruning
purposes state-space planners, reducing size search space levels
partial-order planners (Minton, Bresina & Drummond, 1994), without losing completeness.
work Scholz actually re-investigation sleep sets actions originally
presented Godefroid & Kabanza (1991) also examined us, name
prohibited actions, earlier version GRT (1999a). experience authors
detecting pruning redundant actions sequences time consuming, effective
approach employ closed list visited states, paying however cost terms memory.
latter approach adopted GRT planning system. However Scholz considers action
sequences length two, makes approach fast enough less effective closed list
visited states structure.
Haslum Jonsson compute reduced set actions problem, ignoring actions
equivalently replaced sequences actions. approach solution preserving,
adopted STRIPS planner pre-instantiates actions problem,
results, planners, considerable speed-up also longer plans.
4.2

Numerical Representation Resources

section, present enhanced STRIPS formalism, resources represented
numbers, instead atoms. work motivated mystery domain, suitable
domain resources. Moreover, easily extended cover domains
reasoning numbers required.
GRT supports explicit representation resources natural format, i.e.
numerical format. According this, resources distinguished types objects
separately declared using following statement:
(:resources R1 R2 ... RN )
Ri various resources. Furthermore, declarations following form added
initial state description :
(amount R1 V1) (amount R2 V2) ... (amount RN VN)
denoting initial quantity resource. Moreover, allowed resources participate
relations atomic facts. Finally, action definitions enhanced, declare explicitly
consumed resources.
example, consider mystery domain, comprises cities, connected via
edges, packages transferred initial locations destinations
trucks. beginning, city amount fuel. truck travel city
c1 adjacent city c2, c1 must least one unit fuel. journey, fuel c1
decreased one.

130

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

original domain representation, different fuel quantities represented relations
form4:
(fuel fuel0) (fuel fuel1) (fuel fuel2)etc.
orderings quantities represented relations follows:
(adjacent_fuel fuel0 fuel1) (adjacent_fuel fuel1 fuel2) etc.
initial amount resources city as:
(city_fuel city1 fuel3) etc.
Finally, actions consume resources, e.g. moving truck, following form:
(:action move
:parameters (?tr ?c1 ?c2 ?f1 ?f2)
:precondition (and (truck ?tr) (city ?c1) (city ?c2)
(adjacent_cities ?c1 ?c2) (fuel ?f1) (fuel ?f2) (at ?tr ?c1)
(adjacent_fuel ?f1 ?f2) (city_fuels ?c1 ?f2))
:effect (and (not (at ?tr ?c1)) (not (city_fuel ?c1 ?f2))
(at ?tr ?c2) (city_fuel ?c1 ?f1)))
order idea resources represented GRT, let us consider STRIPSMYSTY-X-1 problem mystery domain. problem 6 cities, 6 resource objects
declared:
(:resources r1 r2 r3 r4 r5 r6)
resources related corresponding cities:
(city_fuel city1 r1) (city_fuel city2 r1) ... (city_fuel city6 r6)
Propositions added initial state, denoting initial availability resource:
(amount r1 1) (amount r2 2) ... (amount r6 3)
Finally, action move defined way separates resource requirements
precondition effect lists:
(:action move
:parameters (?tr ?c1 ?c2 ?f)
:precondition (and (truck ?tr) (city ?c1) (city ?c2) (at ?tr ?c1)
(adjacent_cities ?c1 ?c2) (city_fuel ?c1 ?f))
:effect (and (not (at ?tr ?c1)) (at ?tr ?c2))
:resources (amount ?f 1))
Table 2 shows number ground facts ground actions first five problems
mystery distribution, two alternative resource representations. clear table,
numerical representation resources important reduction number
ground facts, considerable case ground actions. even
important size problem atom-based representation grow illimitably,
levels resource availability added, whereas numerical representation size
problem remains constant.

4

AIPS-98 competition, different predicate object names used; however, paper
translated meaningful ones simplicity.

131

fiREFANIDIS & VLAHAVAS

Atom representation
ground facts
ground actions

Problem
strips-mysty-x-1
strips-mysty-x-2
strips-mysty-x-3
strips-mysty-x-4
strips-mysty-x-5

101
359
277
178
299

Numerical Representation
ground facts
ground actions

150
3596
1676
210
2325

56
310
230
144
269

48
1200
816
168
1032

Table 2: Size problem (number ground facts actions)
two alternative resource representations.

5.

Using XOR Constraints avoid Local Optimal States

section, tackle problem local optimal states. Firstly, illustrate problem,
introduce XOR-constraints finally present exploited GRT order
avoid local optima.
5.1

Local Optimal States

search phase, GRT always selects expand promising state, according
heuristic. various facts problem independent even GRT always managed
track interactions related facts, strategy would optimal. However,
always case times search led local optimal states. Therefore, planner
temporarily backtrack less promising states, selecting promising ones.
Figure 2 presents example situation:

2
1
0

Initial state
K
R
0

1

Goal state
2
1
0

2

K

0

1

R
2

Figure 2: 3x3 grid problem.
problem refers grid-like domain (McDermott, 1999), K key R robot.
robot proceed adjacent positions. valid actions get leave key
move robot. Table 3 shows part Greedy Regression Table problem Figure 2.
According Table, distance initial goal state 10. two
applicable initial state actions, moving R n1_0 moving R n0_1. moving R
n1_0 resulting state distance goals equal 9, whereas moving R n0_1
resulting state distance goals equal 11. planner decides move R
n1_0 subsequently n2_0. However, obvious optimal first movements
moving robot n0_1, next n0_2, getting key etc.

132

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

Fact

Distance
Goals

Related Facts

(at R n2_0)
(at K n2_2)
(at R n1_0)
(at R n0_0)
(at R n0_1)
(at R n2_1)
(at R n2_2)
(in R K)
(at R n1_2)
(at K n1_2)
(at R n0_2)
(at K n0_2)

0
0
1
2
3
1
2
3
3
7
4
8

()
()
()
()
()
()
()
( (at R n2_2) )
()
( (at R n1_2) )
()
( (at R n0_2) )

Table 3: Part Greedy Regression Table 3x3 grid problem.
Initially planner select optimal action, since leads state greater
distance goals, according heuristic. order decide move robot towards
key, planner go valid plans, backtrack move robot
worse states (this requires planner maintains closed list visited states
revisit them). difficult problems, number states planner visit
following optimal direction, extremely large. main reason GRT, like many
heuristic planners, handle grid-like domains efficiently.
3x3 grid problem Figure 2, ideal planner detect that, order move
key n0_2 n2_2, necessary robot gets key, fact (at R n0_2)
achieved fact (at R n2_0). However, planner know facts (at R
n0_0), (at R n2_0) (at R n0_2) related way, domain definition
provide piece information. Therefore, necessary provide planner information
relations hold facts problem.
5.2

Defining XOR-constraints

order avoid local optimal states, provide GRT knowledge relations facts,
exactly one facts hold state. call relations XOR-constraints.
Definition 2 (XOR-constraint). XOR-constraint relation ground facts.
relation valid state, exactly one participating facts holds state.
general form XOR-constraint schema following:
((xor f1 f2 ...) c1 c2 ...)
fi facts cannot co-appear state ci static facts provide
supplementary conditions type constraints, relations objects, etc.
XOR-constraints formalized almost domain. example, logistics domain
could define following XOR-constraints:
( (xor ( ?Truck * ) ) ( truck ?Truck ) )
( (xor ( ?Plane * ) ) ( plane ?Plane ) )
( (xor ( ?Package * ) (in ?Package * ) ) ( package ?Package ))

133

fiREFANIDIS & VLAHAVAS

Question marks (?) precede named variables, whereas asterisks (*) denote no-named ones.
definitions mean every instantiation named variables appear XORconstraint valid instantiations no-named variables, according predicate
definitions, exactly one ground fact hold valid complete state. XORconstraints schemas general definitions grounded several ways, according
different ways named variables instantiated.
cases, possible XOR-constraints incorporate relations.
example, logistics domain predicate (out ?Package) defined, means
package loaded either truck plane, relevant constraint written:
( ( xor ( ( ( ?Package * ) ( ?Package ) ) ( ?Package * ) ) ( package ?Package ) )
Note facts may appear XOR-constraint, others may appear
one. Henceforth, refer facts appear least one XOR-constraint XORconstrained facts.
requirement current version GRT XOR-constraints included
domain definition. However, could computed analytically, based mutual exclusion
relations facts problem, since mutually exclusive facts cannot appear
simultaneously valid state. However, providing manually allows form
guidance, since domain engineer leave them, since would lead pointless
decompositions.
notion XOR-constraints new planning. Gerevini Schubert (1998) proposed
method automatic inference state constraints action definitions initial
state. Single valuedness constraints sv constraints closest XOR-constraints. sv
constraints concern instantiations predicate, XOR-constraints relations
ground facts different predicates. However, recent work (2000a, 2000b),
extended work also infer XOR-constraints.
object oriented domain specification formalism introduced McCluskey & Porteous
(1997) similar XOR-constraints. According this, states defined collections
facts collections objects, object internal status. So, XOR-constraints
implicitly defined requirement object attributes single valued.
5.3

Decomposing Problems Sub-problems using XOR-constraints

section illustrate GRT exploits XOR-constraints within pre-processing phase,
order avoid local optimal states. Specifically, using GRT manages establish new ordered
subgoals achieved achieving original goals. subgoals grouped
ordered intermediate states, thus original difficult problem decomposed sequence
easier subproblems solved sequentially.
present steps problem decomposition process example Figure
3, 4x4 grid problem two keys (K1 K2) two robots (R1 R2).
Initial State
K2
R2

3
2
1
0
0

R1
1

2

3
2
1
0

K1
3

Goal State
R2 K2
K1
R1
0

1

Figure 3: 4x4 grid problem.
134

2

3

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

Goal facts
(at R1 n0_0)
distance=0
-

(at R1 n1_0)
distance=1

(at R1 n1_1)
distance=2

(at R1 n2_0)
distance=2

(at R1 n3_0)
distance=3

(move R1 n1_0 n0_0)

(move R1 n1_1 n1_0)

(move R1 n2_0 n1_0)

(move R1 n3_0 n2_0)

(at K1 n1_1)
distance=0
-

(at R2 n0_3)
distance=0
-

(holding R1 K1)
distance=3

(at K1 n3_0)
distance=7

(leave R1 K1 n1_1)

(at R2 n2_2)
distance=3

(get R1 K1 n3_0)

(move R2 n2_2 n2_3)

(at R2 n1_3)
distance=1

(at R2 n2_3)
distance=2

(move R2 n1_3 n0_3)

(move R1 n2_3 n1_3)

(at R2 n3_3)
distance=3
(move R2 n3_3 n2_3)

(at K2 n1_3)
distance=0
-

(holding R2 K2)
distance=2

(at K2 n3_3)
distance=6

(leave R2 K2 n1_3)

(get R2 K2 n3_3)

Figure 4: Part Greedy Regression Graph 4x4 Grid problem.
domain following XOR-constraints defined:
( ( xor ( ?Robot * ) ) ( robot ?Robot ) )
( ( xor ( ?Key * ) ( holding ?Key ) ) ( key ?Key ) )
definitions four ground instantiations, one Robot one Key.
Henceforth notation XOROBJ refer ground XOR-constraint concerning object OBJ.
first information extracted pairs facts, one initial state one
goals, belong ground XOR-constraint. problem Figure 3
following pairs identified:
XORR1: (at R1 n1_0)
XORR2: (at R2 n2_2)
XORK1: (at K1 n3_0)
XORK2: (at K2 n3_3)

-

(at R1 n0_0)
(at R2 n0_3)
(at K1 n1_1)
(at K2 n1_3)

original GRT planner store information inverted actions, achieved
various facts heuristic construction phase. However, order exploit XORconstraints, information stored. storing actions, table structure used
GRT heuristic transformed directed acyclic graph. call structure Greedy
Regression Graph simply GRG.
nodes graph labeled facts problem. node retains also
estimated distance fact goals corresponding related facts. retains also
name inverted action achieved fact. arcs point node originate
nodes preconditions inverted action achieved node's fact. Figure 4 shows
part GRG structure 4x4 grid problem (the related facts omitted).
Based GRG, every ground XOR-constraint, sequence actions able
transform initial state fact corresponding goal state fact derived. interested
actions change XOR-constraint's facts actions provide auxiliary
preconditions. problem Figure 3, actions' sequences shown Table 4:

135

fiREFANIDIS & VLAHAVAS

Initial state

Intermediate goals

Goal state

XORR1

(at R1 n1_0)

(at R1 n3_0)

(at R1 n1_1)

(at R1 n0_0)

XORR2

(at R2 n2_2)

(at R2 n3_3)

(at R2 n1_3)

(at R2 n0_3)

XORK1

(at K1 n3_0)

(holding R1 K1)

(at K1 n1_1)

XORK2

(at K2 n3_3)

(holding R2 K2)

(at K2 n1_3)

Figure 5: ordering graph 4x4 grid problem.
XOR
constraints

Initial State
Facts

Goal State
Facts

XORR1
XORR2

(at R1 n1_0)
(at R2 n2_2)

(at R1 n0_0)
(at R2 n0_3)

XORK1
XORK1

(at K1 n3_0)
(at K2 n3_3)

(at K1 n1_1)
(at K2 n1_3)

Sequences actions
(move R1 n1_0 n0_0)
(move R2 n2_2 n2_3) (move R2 n2_3 n1_3)
(move R2 n1_3 n0_3)
(get R1 K1 n3_0) (leave R1 K1 n1_1)
(get R2 K2 n3_3) (leave R2 K2 n1_3)

Table 4: Sequences actions transform initial state facts
corresponding goal facts.
Checking preconditions actions, find facts members foreign
XOR-constraints. facts subgoals temporarily established,
achieving original goals, forward search phase. Table 4, actions (get R1 K1 n3_0)
(leave R1 K1 n1_1) XORK1 sequence (at R1 n3_0) (at R1 n1_1)
preconditions respectively, members XORR1 relation. Similarly, actions (get
R2 K2 n3_3) (leave R2 K2 n1_3) XORK2 sequence (at R2 n3_3) (at R2 n1_3)
preconditions respectively, members XORR2 relation.
two types subgoals. XOR-constrained facts either:
(I)
(II)

preconditions ground action foreign XOR sequence,
add-effects action, XOR sequence, foreign precondition.

identified subgoals, construct graph, conjoining new subgoals arcs
denote ordering constraints, using following rules:
1. subgoals ordered initial state fact goal fact (if any).
2. Subgoals type (II) members XOR-constraint ordered according
ordering actions.
3. Subgoals type (I) ordered together corresponding subgoals type (II),
resulted action.
4. specific XOR-constraint, subgoals type (I) ordered subgoals type (II).

136

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

call resulted graph ordering graph problem, since denotes order
subgoals achieved. Figure 5 shows ordering graph problem
Figure 3. Lines arcs denote ordering constraints. Double-lines without arcs denote two
facts ordered together.
Proposition 8. ordering graph acyclic graph.
Proof sketch: proof based way facts achieved PreProcessing Algorithm (Section 2.4). Actually, facts achieved specific time order (in case
fact re-achieved smaller cost, consider last time
achieved). define ordering relation < facts, denoting fact achieved
another Pre-Processing Algorithm. Similarly define relation.
Ordering relations subgoals originate two ways. Firstly, subgoals type (II)
XOR-constraint ordered explicitly other, according time
achieved (in Figure 5 ordering relations denoted non-dashed lines arcs).
Secondly, subgoal type (I) ordered least time
previous one corresponding type (II) subgoal (in Figure 5 ordering relations denoted
dashed lines arcs). Using equivalences, transform ordering graph
equivalent time-ordering graph. Since time-ordering relation cannot include cycles,
happens ordering graph.
ordering graph makes possible construct intermediate, possibly incomplete, states,
achieved sequentially. Starting initial state, GRT attempts insert one
subgoal XOR-constraint intermediate state. fact must following
properties:




inserted previous intermediate state,
ordered fact XOR-constraint yet inserted
previous intermediate state, finally
ordered together fact another XOR-constraint cannot inserted
current intermediate state.

case one facts properties single XORconstraint, selection among done arbitrarily. Finally, case fact
properties exists XOR-constraint, intermediate state left incomplete.
Corollary 4. always possible construct intermediate states.
Corollary 4 follows Proposition 8. Since ordering graph directed acyclic graph,
always possible find least one subgoal included next intermediate state.
number subgoals upper bound number intermediate states
constructed.
ordering graph Figure 5, following intermediate states extracted:
Intermediate state 1: ( (at R1 n3_0) (at R2 n3_3) (in K1 R1) (in K2 R2) )
Intermediate state 2: ( (at R1 n1_1) (at R2 n1_3) (at K1 n1_1) (at K2 n1_3) )
Intermediate state 3: ( (at R1 n0_0) (at R2 n0_3) (at K1n1_1) (at K2 n1_3) )
last state goal state.
construction intermediate states, planner solve three sub-problems,
easier original one; thus, overall time solve shorter time
137

fiREFANIDIS & VLAHAVAS

needed solve original problem. Note, however, decomposition may lead loss
completeness. domains deadlock exists, solutions may pruned. domains
deadlocks exist, decomposition may produce unsolvable sub-problems. order
maintain completeness, algorithm backtrack possible inverted actions
could achieve facts Pre-Processing Algorithm, even large application costs.
However, due combinatorial explosion problem, approach adopted GRT.
usual situation case sub-problems need decomposition. situation
arises two cases. first two objects need achieve goals,
case grid domain, keys robot, second case sequential
interaction three objects. cases, ordering graph initial problem
encodes one aspect interaction, ordering graphs sub-problems encode
aspects. However, order avoid infinite decompositions, cutoff level defined.

6. GRT Operation
GRT implemented C++5. operation consists several stages, shown
Figure 6a.
Domain file
Problem file

Parsing

Facts
Actions
computation

Mutex
computation

Domain
enrichment

Problem
processing

Plan

(a) GRT operation stages
Problem processing
Irrelevant
objects
elimination

Goals
completion

Heuristic
construction

Problem
decomposition

State-space
search

Partial
solution
merging

(b) problem processing stage

Figure 6: overall operation GRT planning system.
first stage domain problem files parsed initial data structures
constructed. second stage consists computing facts actions problem.
facts stored tree structure, indexed predicates objects allows
fast access, actions stored linked list. Moreover, multiple pointers connect
fact actions, fact appears. computation facts actions
performed incrementally, repeatedly applying following steps:

fact reached, create new actions include fact others already reached,
preconditions.

action created, add add effects tree structure.
process starts initial state facts continues facts actions
reached. approach time efficient succeeds generating many unreachable facts
actions. example, logistics domain, facts denoting truck located city
5

GRT available on-line http://www.csd.auth.gr/~lpis/GRT/main.html.

138

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

different initial location, corresponding actions, created. Note
stage, normal inverted actions computed; former used mutex
computation stage, latter used heuristic construction stage. However, preinstantiated actions used state-space search, applicable actions
state computed progressively instantiating action schemas, using constraint satisfaction
techniques (forward checking intelligent backtracking).
stages follow computation mutual exclusion relations, enrichment
domain, problem processing. latter stage consists several sub-stages,
shown Figure 6b, important ones construction heuristic
state-space search. Note refer pre-processing phase GRT, mean stages
precede state-space search.
case XOR-constraints provided, GRT attempts decompose current
problem sub-problems. attempt successful, problem processing stage executed
recursively sub-problem, otherwise current problem solved. Finally, case
decompositions, partial solutions merged overall solution returned.

7. Related Work
section briefly presents domain independent heuristic state-space planning systems,
emphasizing similarities differences GRT, terms way construct
heuristic direction traverse state-space. omit certain pieces related
work concern specific pre-processing techniques implemented GRT, example
elimination irrelevant objects, since already presented previous sections.
recent evolvement domain independent heuristic planning started work
Drew McDermott (1996, 1999) UNPOP (UN-Partial Order Planner, UN- stands non-).
McDermott's planner restricted pure STRIPS representations, supporting
expressive language ADL (Pednault, 1989). planner proceeds forward state-space.
Distance estimates states based so-called regression graph, built
goals using non fully-instantiated actions. UNPOP consider subgoals interactions
reconstructs regression graph scratch intermediate state. Although planner
competitive enough, compared subsequent heuristic planners, faster one
time appearance. However, note UNPOP developed LISP, whereas
heuristic planners highly optimized C C++ programs.
Although UNPOP first domain independent heuristic planner, area pushed
forward ASP (Action Selection Planner, Bonet, Loerings & Geffner, 1997) HSP
(Heuristic Search Planner, Bonet & Geffner, 1998) planners. attractive feature
planners simple way heuristic constructed, presented Section 2.1. ASP used bestfirst strategy limited agenda, H SP uses hill-climbing one limited plateau search
restarts (an in-depth presentation state-space search algorithms given Zhang, 1999).
ASP HSP reconstruct heuristic scratch intermediate state.
variation, called HSPr (r stands regression), constructs heuristic (Bonet &
Geffner, 1999). approach resembles GRT, although HSPr constructs heuristic forward
searches backwards. approaches problem incomplete goal states, however arises
different phases planning process. GRT faces problem pre-processing phase,
enhancing goals, described Section 3. HSPr, problem arises search
phase, form invalid states regression state space. cope problem, HSPr
computes mutual exclusion relations checks state regression state space

139

fiREFANIDIS & VLAHAVAS

possible violation relations. disadvantage approach considerably
time consuming GRT approach, since HSPr check visited state.
variation HSP, named HSP-2, changed hill-climbing strategy best-first one, thus
preserving completeness producing better plans (Bonet & Geffner, 2001). Moreover, HSP-2
uses weighted A* algorithm (WA*) (Pearl, 1983) form f(S)=g(S)+Wh(S),
intermediate state, g(S) accumulated cost initial state, h(S) estimated cost
reach Goals W parameter. W=0, search algorithm behaves breadth-first
one, W=1 behaves typical A* W behaves best-first. h(S)
function, HSP-2 supports several heuristic functions, apart one presented Section 2.1.
Recently, two new planners, FF ALTALT, appeared, use GRAPHPLAN-based
approach estimate distances intermediate states goals. ALTALT (A Little
This, Little That) regression planner based HSPr, faces problems
invalid states HSPr (Nigenda, Nguyen & Kambhampati, 2000). ALTALT creates planning graph
pre-processing phase uses several techniques extract heuristic estimates distances
intermediate states initial state. example, one returns level
planning graph, facts intermediate state appear, without mutual
exclusion relation them.
FF (Fast Forward) forward heuristic planner (Hoffmann & Nebel, 2001). order
estimate distance intermediate state goals, FF creates planning graph
state goals, using relaxed actions. Since delete effects, mutual
exclusion relations planning graph. graph, FF extracts relaxed plan, length
distance estimate. Note that, since mutual exclusion relations,
backtracking occurs extraction relaxed plan, thus extraction accomplished
fast enough. FF heuristic resembles GRT one, aim obtaining under-estimates,
adopt different approaches. relaxations FF performs stronger, since
completely ignores delete effects. FF estimates usually smaller GRT's ones
times underestimates, whereas GRT not-rarely produces overestimates.
FF adopts variation hill-climbing strategy, called enforced hill climbing, according
which, planner always seeks move state closer goals, according heuristic. FF
achieves performing bounded breadth-first search current state, maximum
depth defined user; improving state direct successor
current state. improving state found, new actions added end
current plan hill-climbing search continues new state. case
bounded breadth-first search find improving state, FF restarts search initial
state adopting best-first search strategy.
FF exhibited distinguishable performance AIPS-00 planning competition. One
features FF resulting good performance compute applicable actions
intermediate state. Actually, FF gives priority first level actions relaxed plan.
action produces better state found, applied next state processed.
Moreover, times, new relaxed plan constructed, since suffices
remove lastly applied action beginning previous relaxed plan. So, FF succeeds
reducing drastically cost processing intermediate state, paying however cost
loosing completeness.
bottleneck occurs determining applicable actions intermediate state
also identified Vrakas et al. (1999, 2000). work, process finding
applying applicable actions parallelized, resulting almost linear speedup.
Parallelizing process finding applicable actions, instead ignoring them, FF

140

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

does, presents advantage preserving completeness; however, cost parallel
machine required.
close reference heuristic state-space planners STAN planning system
(Fox & Long, 1998; Long & Fox, 1999). STAN heuristic state-space planner, least
basic architecture, graph-based planner, uses several pre-processing techniques
extracting useful domain information exploited efficient graph construction
solution extraction. However, AIPS-00 competition hybrid architecture used (Long &
Fox, 2000; Fox & Long, 2001), heuristic state-space planning module employed
solve specific identified sub-problems. Thus STAN succeeded improving performance,
especially cases transportation domains.
Concerning problem decomposition, work done goal ordering (Cheng & Irani,
1989; Drummond & Currie, 1989). Recently similar approach proposed Koehler
(1998) extended Koehler Hoffmann (2000). approach automatically
derives ordering relation goal facts, used planner search
increasing sets subgoals. advantage approach extra information needed,
except usual domain definition, disadvantage, respect XOR-constraints
approach, goal facts taken account intermediate states
constructed. approach adopted FF planning system.

8. Performance Results
section, present performance results several domains, taken literature
two planning competitions. First, investigate several techniques GRT
contribute overall performance compare GRT planners.
measurements follow taken SUN Enterprise 3000 machine running
167MHz, 256 MB main memory operating system Solaris 2.5.1. experiments
set 5 minutes time limit experiments planners6.
8.1

Measuring Effectiveness Related Facts

order measure contribution related facts overall performance GRT,
tested planner, without related facts, problems various domains. results
(solution length time) presented Figure 7 (a-f).




/HQJWK




7LPH



























:LWKRXW 5HODWHG
:LWK 5HODWHG



:LWKRXW 5HODWHG
:LWK 5HODWHG





























(a) Logistics problems (the goals enhanced promising facts selection method)

6

URL http://www.csd.auth.gr/~lpis/GRT/JAIR/OnlineAppendix1.html
found executable files planners took part comparison, source code GRT, detailed
results (in MS-Excel format), original data files, problem description files script files planner.

141

fiREFANIDIS & VLAHAVAS





/HQJWK



:LWKRXW 5HODWHG
:LWK 5HODWHG



7LPH














:LWKRXW 5HODWHG
:LWK 5HODWHG





































(b) Blocks-world problems 4 action schemas (push, pop, pick-up, put-down)


:LWKRXW 5HODWHG
:LWK 5HODWHG

/HQJWK





















7LPH

:LWKRXW 5HODWHG
:LWK 5HODWHG














































(c) Blocks-world problems 3 action schemas (several cases move)




/HQJWK






:LWKRXW 5HODWHG
:LWK 5HODWHG



7LPH





:LWKRXW 5HODWHG
:LWK 5HODWHG













































(d) FreeCell Problems




/HQJWK












:LWKRXW 5HODWHG
:LWK 5HODWHG
























7LPH

:LWKRXW 5HODWHG
:LWK 5HODWHG






























(e) Elevator problems


/HQJWK





:LWKRXW 5HODWHG
:LWK 5HODWHG



7LPH
:LWKRXW 5HODWHG
:LWK 5HODWHG




























(f) Puzzle problems

Figure 7: Solution length time (in msecs) without use related facts
problems several domains.

142



fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

classify domains three groups. first group includes domains
use related facts clearly improves solution length time. group comprises
logistics domain (6a), blocks-world, 3-action schemas representation (move actions)
used (6c), puzzle domain (6f). domains, many cases GRT
without related facts solve problems, related facts did. Moreover,
cases versions solved problem, version related facts faster
came shorter plan.
second group includes domains use related facts affect
effectiveness planning process. group comprises elevator domain, along
gripper, movie mystery ones. domains, usually single way achieve
goals, versions produce identical plans. However, due processing overhead,
imposed computation related facts, version related facts slightly slower
version without them.
Finally, third group includes domains apparent predominance
two versions. freecell domain blocks-world domain, 4-action schemas
representation used (push, pop, pick-up, put-down), fall class. domains two
versions equal performance, problems one version surpasses
vice-versa.
conclusion drawn measurements effectiveness related facts
depends domain. suitable domains several ways achieve
goals, logistics blocks-world.
Additionally, efficiency depends way domain codified. typical example
blocks-world domain 4- 3-action schemas representations. problem 4action schemas representation pushing stacking block anywhere always
fact precondition, i.e. block held arm. consequence neither
related facts, distances computed correctly. However problem related
facts, common problem domain independent heuristic planning, results last
planning competition. hand, 3-action schemas representation used,
paths achieve facts domain better tracked, larger problems solved
contribution related facts significant. believe, finally, also freecell domain
representation inefficiency, however yet tried construct alternative one.
8.2

Using Several Methods Enhance Goals

order measure effectiveness three proposed methods enhance goals, ran
GRT using logistics problems AIPS-00 competition. selected domain,
since domains competition goal state either complete, near complete,
difference among three methods. Figure 8 shows solution length time
easiest logistics problems.
regard solution length, first method, considers candidate facts goal
facts, always came better plans. mentioned Section 3.2, method produces
small differences among estimated distances, search process tends breadth-first.
However, cases, third method found plans equal quality. regard
solution time, last two methods work faster, since produce greater differences
distances.
Section 3.3 also presented method enriching domain representation. already
mentioned, motivated need treat domains like movie elevator.
present comparative performance results domain enrichment method pure
GRT planner domains, since without technique impossible GRT solve
143

fiREFANIDIS & VLAHAVAS

problems. However, would interesting test efficiency method heuristic
state space planners.




/HQJWK

7LPH










$OO
,QLWLDO
*UHHG\

$OO
,QLWLDO
*UHHG\









































Figure 8: Results logistics problems using different methods complete goals.
= Consider candidate facts goal facts.
Initial = Select initial state facts.
Greedy = Favor promising facts.

8.3

Reducing Size Problem

work detecting eliminating irrelevant objects motivated need
simplify sub-problems resulting decomposition problem, using XORconstraints. Performance results case presented Section 8.4. section presents
indicative results concerning effectiveness technique colored logistics domain
mentioned Section 4.1. purpose enhanced first group logistics
problems AIPS-00 competition required predicates actions added
propositions defining original color package initial states. Figure 9 presents
time needed solve problems, without irrelevant objects elimination technique.
results experimental data, improvement solution time 20%.
Note cases plans found; however, would probably
case domains.
order measure efficiency numerical representation resources, ran GRT
original mystery domain modified domain, resources represented
numbers. Figure 10 presents time needed solve problems cases GRT.
Note experiments solvable mystery problems taken account.
results Figure 10, GRT significantly faster, numerical representation used.
improvement 65% average. solution length, cases
found again.
techniques evaluated section gain speedup mainly pre-processing
phase, since distances significantly smaller number facts estimated.
search phase, also speedup, less important. Actually, number applicable
actions state two alternative representations resources, since
equivalent. Moreover, detection applicable actions atom-based representation
takes time, due effective constraint-satisfaction techniques GRT uses
instantiating action schemata. Concerning elimination irrelevant objects, without
technique, applicable actions state, however usually selected,

144

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

since lead improving state. However, time spent detection
actions may negligible.
significance two techniques lies overall time needed solve problems
remains same, case irrelevant objects used, exactly same,
case resource levels used. case irrelevant objects,
detected (in negligible cost) eliminated subsequent stages (Figure 6). However,
overhead imposed stages precede irrelevant objects elimination stage,
objects eliminated.
case resource levels, lead generation new ground facts
actions, pre-processing stages consume exactly time. state-space
search, also executed time, case neither initial
availability resources, consumption actions, finally constraints
changed. case, dealing different planning problem,
may harder solve.


7LPH



(OLPLQDWLQJ LUUHOHYDQW REMHFWV
8VLQJ DOO REMHFWV
















Figure 9: Time (in msecs) needed solve colored logistics problems,
without irrelevant object elimination technique.

$WRP EDVHG UHSUHVHQWDWLRQ
1XPHULFDO UHSUHVHQWDWLRQ



7LPH


























Figure 10: Time (in msecs) needed solve solvable mystery problems,
original atom-based number-based representation resources used.
8.4

XOR Constraints

tested efficiency XOR-constraints based decomposition two domains: simplified
mystery domain, resources removed, grid domain AIPS-98
competition. use logistics domain experiments, since logistics problems

145

fiREFANIDIS & VLAHAVAS

difficult original GRT small profit solving easier sub-problems
compensated extra pre-processing cost sub-problem.
removed resources original mystery domain otherwise would
probable obtain unsolvable subproblems. noted Section 5, decomposing
problem may lead loss completeness, thus technique unsuitable domains
deadlocks may arise, original mystery one. Note removing resources, mystery
problems become solvable.
XOR-constraints defined simplified mystery domain
following:
( ( xor ( ?Truck * ) ) (truck ?Truck ))
( ( xor ( ?Package * ) (in ?Package * ) ) ( package ?Package ) )
grid domain following ones:
( ( xor ( at-robot * ) ) )
( ( xor ( locked ?Place ) ( open ?Place ) ) ( place ?Place ) )
( ( xor ( ?Key * ) ( holding ?Key ) ) ( key ?Key ) )
Note grid domain XOR-constraint denoting arm either empty,
robot holds key defined, since would lead pointless decompositions.
domains, ran GRT without problem decomposition technique.
Additionally, order demonstrate contribution irrelevant objects elimination
technique solving sub-problems, conducted experiments case simplified
mystery domain. consider case grid domain, irrelevant objects
detected there. Figure 11 presents results.


1R ;25V

/HQJWK



;25V

7LPH

;25V1R HOLP LQDWLRQ














1R ;25V





















;25V
;25V1R HOLP LQDWLRQ

















(a) Simplified Mystery


/HQJWK



7LP H







ZLWKRXW ;256

ZLWKRXW ;256
ZLWK ;256





ZLWK ;256


















(b) Grid Domain

Figure 11: Solution time (in msecs) length without
XOR-constraints based problem decomposition technique.
146





fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

simplified mystery domain, GRT without problem decomposition technique
generally produced shorter plans, expected. hand, use XOR-constraints
accelerated problem decomposition process, especially case difficult problems. Actually,
consider seven difficult problems, improvement achieved
decomposition 60% average. Note however that, irrelevant objects elimination
technique used, improvement. difficult problems
acceleration, since, case logistics problems, small profit faster solution
easier sub-problems compensated cost repeating pre-processing phase
one them.
grid domain difficult one AIPS-98 competition. contestants
managed solve first problem. GRT without XOR-constraints could solve first
problem, too. hand, XOR-constraints based decomposition, GRT able
solve first four problems time limit 5 minutes, fifth problem ran
memory. worth noting domain produces multiple levels decompositions. Figure 12
presents levels strips-grid-y-2 problem.
far know, planner cope grid problems effectively FF.
ran FF five grid problems solved first four, within time limit 5 minutes,
following results (length/time): 14/230, 39/840, 40/7810 45/3280, considerably
better compared performance GRT.
Main problem

Sub-problem 1

Sub-problem 2

Sub-problem 3.1

Sub-problem 3.1.1

Sub-problem 3.1.1.1

Sub-problem 3.1.2

Sub-problem 3.1.1.2

Sub-problem 3

Sub-problem 3.2

Sub-problem 3.3

Sub-problem 4.1

Sub-problem 3.1.3

Sub-problem 4

Sub-problem 4.2

Sub-problem 4.3

Sub-problem 3.1.1.3

Figure 12: Decomposition strips-grid-y-2 problem using XOR-constraints.

8.5

Best-First Hill-Climbing Strategies

Recently equipped GRT planner two new features: second optional search strategy,
well known hill-climbing, closed-list visited states, order avoid revisiting them.
GRT adopts enforced hill-climbing strategy, originally presented Hoffmann & Nebel
(2001), according which, intermediate state limited breadth first search
performed, improving state reached. improving state cannot found, GRT
restarts search initial state typical best-first strategy.
Moreover, hill-climbing strategy enhanced fast action selection mechanism.
presented Section 5.3, GRT estimates distances problem's
facts goals pre-processing phase, stores GRG structure action
achieved fact. So, order find improving successor state quickly, hill-climbing
search strategy first attempts apply actions achieved current state's facts.
147

fiREFANIDIS & VLAHAVAS

improving successor state found, remaining actions processed, thus avoiding
compute applicable current state actions. Note however guaranteed
actions always applied current state. case improving state
found, remaining applicable current state actions taken account.
Figure 13 presents comparative performance results logistics elevator problems, using
search strategies. logistics problems, promising facts selection method
enhancing goals used. results experimental data, logistics
problems use hill-climbing strategy, significant reduction
solution time 52%. cost increment 3% length plans.
elevator problems, also reduction solution time 29%, whereas
produced plans identical.




/HQJWK

7LP H











+LOO &OLP ELQJ



+LOO &OLP ELQJ

%HV W )LUV W

%HV W )LUV W












































(a) Logistics domain




/HQJWK

7LP H











+LOO&OLP ELQJ



+LOO&OLP ELQJ



%HV W )LUV W

%HV W )LUV W
























































(b) Elevator domain

Figure 13: Comparative results (solution length time) hill-climbing
best-first strategies.
tested efficiency fast action selection mechanism, also running GRT
hill-climbing strategy without mechanism logistics elevator problems.
Concerning logistics problems, speedup 47%, increment solution
length 3% average again. Concerning elevator problems, speedup 28%, whereas
produced plans identical. conclusion additional measurements
speedup primarily due hill-climbing strategy secondly due fast action
selection mechanism. contribution mechanism depends domain
important logistics less elevator. inefficiency elevator domain means
actions selected mechanism usually lead improving state
applicable, applicable actions computed.
Results domains, like blocks-world freecell, presented, since
domains hill-climbing usually fails find plan GRT restarts best-first basis. However,
148

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

domains closed-list states proved invaluable, improving drastically
performance GRT. example, freecell domain without closed list visited
states, GRT planner AIPS-00 planning competition succeeded solving problems
6 cards per suit, data structure solve difficult ones (13
cards per suit). Note efficient implementation closed-list visited states hashtable data structure adopted.
8.6

Comparison Planners

section, present comparative results GRT planner planners.
decided use HSP-2 (Bonet & Geffner, 2001), FF (Hoffman & Nebel, 2001), STAN (Long & Fox,
2000; Fox & Long, 2000, 2001) ALTALT (Nigenda, Nguyen & Kambhampati, 2000)7.
planners took part domain independent track AIPS-00 planning competition.
selected planners HSP-2 STAN state-ofthe-art planning systems, FF
awarded outstanding performance last competition ALTALT new
promising domain-independent state-space heuristic planner.
aim experiments overall view performance evaluated
systems. Performing pair wise comparisons specific optimization techniques
possible, since techniques implemented top different systems. Moreover, kind
comparisons scope paper, focuses use specific directions
constructing heuristic traversing space states, area domain-independent
heuristic state-space planning, evaluation numerous pre-processing
optimization techniques. However, cases identify contribution specific
feature performance planner, comment this.
order fair comparisons, used exactly problem domain description
files planners. So, GRT ran without XOR-constraints numerical representation
resources. Moreover, although irrelevant object elimination technique integral feature
GRT, contribution domains, since irrelevant objects. believe
absence irrelevant objects domains mean technique limited
applicability, indication real domains testing purposes used
future, since planning tasks real-life full irrelevant objects. Finally, domain
enrichment technique proved valuable elevator domain only. However, technique,
well goal enhancement one, seen optimization technique, way
overcome problems arise backward direction heuristic construction.
tested planners several domains taken planning competitions
literature, workstation within 5 minutes time limit. results presented
following.
8.6.1

LOGISTICS

logistics domain used test suite AIPS-00 competition. results shown
Figure 14. domain GRT, well FF STAN, performed well, solving problems.
HSP ALTALT failed solve large problems within time-limit. general, best plans
found STAN, uses special domain-dependent heuristics problems identified
7

STAN available http://www.dur.ac.uk/~dcs0www/research/stanstuff/stanpage.html
FF available http://www.informatik.uni-freiburg.de/~hoffmann/ff.html
HSP-2 available http://www.ldc.usb.ve/~hector/
ALTALT available http://rakaposhi.eas.asu.edu/altweb/altalt.html

149

fiREFANIDIS & VLAHAVAS

transportation problems. Best solution times achieved FF STAN small problems
GRT large ones.



/HQJWK

7LPH











))

))

*5 7

*57



+ 63


+ 63



$OW$OW

$OW$OW

67$1

67$1




































Figure 14: Solution length time (msecs) logistics problems AIPS-00 competition.
logistics problems Figure 14 incomplete goal states. GRT ran
promising facts goals-completion method hill-climbing strategy. However,
incompleteness goal state advantage planners construct heuristic
forward direction. Motivated remark, forced planners solve logistics problems
complete goal states, requiring trucks planes return initial location.
results shown Figure 15.




/HQJWK

7LPH

+ 63





*57
$OW$OW



67$1




))



+ 63



*5 7


$OW$OW


67$1



))



































Figure 15: Solution length time (msecs) logistics problems complete goal states.
new logistics problems, GRT, STAN HSP-2 exhibited stable performance, solving
problems time. GRT, means goal completion mechanism behaves
well, least domain. FF failed solve large problems. Finally, ALTALT solved
150

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

problems regression mechanism encounter invalid states. Note
that, although goal state complete case, GRT treated problems usual,
attempting enhance goals.
8.6.2

BLOCKS-WORLD

blocks-world problems AIPS-00 competition four-actions representation used, i.e.
actions push, pop, stack unstack. representation unsuitable GRT,
explained Section 7.1. So, GRT solve blocks-world problems. Figure 16
presents results planners blocks-world problems.
shown Figure 16, FF exhibits best performance, solving majority problems
producing better plans planners. superiority FF domain due
technique called Added Goal Deletion, according goal facts ordered achieved
progressive manner (Hoffmann & Nebel, 2001; Koehler Hoffmann, 2000). technique
especially suited blocks-world domain 4-action schemas representation. However,
technique always succeeds produce good orderings reason FF
fails solve easiest problems, solved planners.
remaining planners, HSP-2 succeeded solving problems 18 blocks
one problem 24 blocks, GRT ALTALT solved problems 14 blocks STAN
12 blocks. Moreover, GRT produced plans low quality.




/HQJWK

7LPH

))



*5 7
+ 63





67$1


$OW$OW






))



*5 7


+ 63



67$1



$OW$OW















































Figure 16: Solution length time (msecs) blocks-world problems
using 4-action schemas domain representation.
order demonstrate influence domain representation efficiency GRT,
ran planners problems using alternative 3-action schemas domain
representation. results shown Figure 17.
performance GRT significantly improved, solving problems 33 blocks
producing better plans planners. Moreover, exception smallest
problems, GRT faster planners, FF. latter solved less large problems,

151

fiREFANIDIS & VLAHAVAS

solved smallest ones. HSP-2 solved problems 19 blocks, ALTALT
STAN stopped 14 blocks.




7LPH

/HQJWK











))

))
*57


*57

+ 63

+ 63


$OW$OW



67$1

$OW$OW
67$1
















































Figure 17: Solution length time (msecs) blocks-world problems
using 3-action schemas domain representation.
8.6.3

FREECELL

Freecell famous card game taken MS-Windows 98 distribution. domain
initially introduced AIPS-00 competition proved one difficult domains.
Figure 18 presents performance results domain. Note ALTALT could solve
problems also case competition.
freecell domain, planners succeeded solve difficult problems
GRT FF. Actually, planners solved problems 12 13 cards per suit.
HSP-2 solved problems 6 cards per suit STAN 3 cards per suit. Regarding
solution quality, GRT produced better plans FF. Regarding solution time, FF faster
small problems, whereas big ones two planners equal performance.
8.6.4

ELEVATOR

elevator (or miconic-10) domain presented Section 3.3. least pure STRIPS
version, relatively easy domain. So, planners found plans equal quality (with
exception HSP-2, produced slightly lengthy plans). However, planners
different performance terms solution time.
Specifically, FF fastest, followed STAN, GRT, HSP-2 finally ALTALT.
domain favors FF, relaxed plan produced heuristic mechanism initial
state actually solution, since original actions domain contain delete lists.
STAN identifies domain transportation domain uses suitable techniques solve
problem. Finally, GRT faster HSP-2 ALTALT, since GRT constructs heuristic faster
HSP-2. results presented Figure 19.
152

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING





/HQJWK

7LPH












))
*57



+63
67$1

))




*57
+63
67$1














































Figure 18: Solution length time (msecs) freecell domain.

7LPH

$OW$OW


+63

*57


67$1

))





































Figure 19: Solution time (in msecs) elevator domain.
8.6.5

GRIPPER

gripper domain introduced AIPS-98 planning competition. domain concerns
robot two grippers must transport set balls one room another. AIPS-98
competition, HSP managed solve 20 problems. Figure 20 presents results
domain.
153

fiREFANIDIS & VLAHAVAS





/HQJWK

7LPH










*57

*57



))

))





+ 63



+ 63

$OW$OW

$OW$OW

67$1

67$1
































Figure 20: Solution length time (msecs) gripper domain.
Regarding solution length, five planners divided two groups: GRT,
ALTALT STAN produced identical plans higher quality, FF HSP-2 produced
identical plans lower quality. Regarding solution time, GRT fastest planner problems
apart easiest, followed closely STAN, next comes FF, next ALTALT last
HSP-2. Note domain STAN takes advantage symmetry analysis, identifies
set balls two grippers symmetric objects (Fox Long, 1999).
8.6.6

HANOI

ran planners 6 hanoi problems, taken Bonet Geffner (2001). six problems
three eight disks respectively. Figure 21 presents results.




/HQJWK
*57



$OW$OW

$OW$OW



))



))

+ 63



7LPH

*57

+ 63



67$1

67$1































Figure 21: Solution length time (msecs) hanoi domain.
Regarding solution length, planners found identical plans, exception
last two problems, GRT found worse plans. Regarding solution time, FF faster,
came GRT HSP-2, ALTALT last came STAN.

154

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

8.6.7

PUZZLE

ran planners four 8-puzzle problems two 15-puzzle ones, taken Bonet
Geffner (2001). Two four 8-puzzle hard optimal solution involves 31 actions,
maximum plan length domain. 15-puzzle problems medium difficulty. Figure
22 presents results.



+ 63



+ 63
$OW$OW
))

/HQJWK

*57
67$1

*57




7LPH



$OW$OW
67$1





))


































Figure 22: Solution length time (msecs) puzzle domain.
STAN solved 8-puzzle instances, produced best plans. planners
solved problems, presented variations quality plans, FF
planning system producing worst plans cases. Regarding solution time, FF
fastest easier problems GRT difficult ones, followed HSP-2 ALTALT.
STAN slowest planner domain.

9. Conclusion Future Work
paper presented GRT planning system, heuristic state-space planner,
constructs heuristic domain-independent way. fundamental difference GRT
heuristic state-space planners GRT constructs heuristic once, pre-processing
phase backward direction, using regression goals. GRT attempts track
positive negative interactions occur problem facts trying achieve
them, order produce better estimates.
GRT employs several new techniques improve efficiency. automated
identification incomplete goal states, identification enrichment inadequate domain
representations, elimination irrelevant objects adoption numerical representation
resources. Finally, knowledge-based method uses domain axioms form XORconstraints, order decompose difficult problems easier sub-problems
solved sequentially, adopted.
paper presented extensive comparative results large number domains.
comparisons, besides GRT, four powerful domain independent planners took part.
results showed planner clearly outperforms others.
Concerning solution time, domains GRT FF fastest planners.
explanation behind observation lies planners construct heuristic either
(in case GRT), times (in case FF). example, elevator domain,
delete effects exist FF constructs relaxed planning graph once,
extremely fast. contrary, gripper puzzle domains, FF needs
155

fiREFANIDIS & VLAHAVAS

reconstruct relaxed planning graphs, efficiency decreases drastically respect
GRT's one.
HSP-2 faster planners domain, always outperformed FF.
expected, since two planners use forward direction construction
heuristics traversing state-space, however FF constructs heuristic less times
HSP-2. impression FF heuristic also informative accurate
one HSP-2. Concerning ALTALT, although constructs heuristic once, manage
faster others domain (we believe) due problems arise
backward direction traverses state-space. So, indication case
opposite directions used heuristic construction search phase, GRT,
ALTALT HSPr do, preferable use backward direction heuristic construction
forward direction search phase. problems arise
constructing heuristic backwards may confronted easily problems arise
traversing state-space backwards.
Domain analysis techniques, occur pre-processing phase, also play important role.
STAN, primarily based techniques, many variations performance.
transportation domains, like logistics elevator ones, STAN exploits specialized
heuristics, among fastest planners. gripper domain, STAN exploits
symmetry analysis, performance also excellent. domains, example
freecell blocks, competitive due GRAPHPLAN basic architecture,
considered fast technology more.
FF also employed domain analysis technique concerning goal ordering, played
important role blocks problems. would interesting see adaptation
impact technique planners well. far know, HSP-2 ALTALT
using domain analysis technique. GRT exploited domain enrichment technique
elevator domain, however technique integral part heuristic mechanism, order
overcome problems arise backward heuristic construction.
interesting observation concerns performance GRT bigger problems
logistics, freecell, gripper puzzle domains, GRT exhibited better performance
smaller problems domains, compared planners. believe due
fact GRT constructs heuristic once, repeated construction heuristics
planners inhibitory factor bigger problems.
conclusions drawn ignore significant factor, specific implementation,
i.e. approaches adopted various planners "trivial" tasks, computation
ground facts actions problem computation applicable actions given
state, optimization code course potential "bugs". example, order find
applicable actions state, GRT uses constraint satisfaction techniques progressively instantiate
action schemas state, whereas planners exploit connectivity graphs
facts problem pre-instantiated actions. experiments GRT
shown significant portion processing time spent determination
applicable actions state. reason developed parallel version GRT,
named PGRT (Vrakas et. al., 1999; 2000), makes use observation
proved efficient domains. However, future plans develop connectivity
graph also GRT compare existent approach.
Differences due code optimization potential "bugs" cannot easily detected,
believe planners, oldest newest ones well-optimized
programs. future would like see theoretical comparisons computational

156

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

complexities various techniques algorithms, apart experimental evaluation
usually adopted.
Concerning plan length, GRT produced better plans planners freecell
domain, gripper domain (along planners), many blocks problems 3action schemas representation used logistics problems. STAN exhibited best
behavior domains believe due GRAPHPLAN basic architecture,
always produces optimal parallel plans and, many cases, sequential plans also. FF behaved
well logistics blocks problems, 4-action schemas representation (in latter
case probably due goal ordering technique), however produced lengthy plans
domains, freecell, gripper puzzle ones.
HSP-2 produced longer plans GRT many domains, example logistics,
freecell gripper domains blocks one, 3-actions representation used.
observation means domains related facts employed GRT heuristic
proved valuable forward repeated reconstruction HSP-2 heuristic. Finally,
ALTALT distinguished quality plans domain.
general impression experiments specific domains favor
specific planners. So, important investigate reasons that. currently
working exploring internal characteristics domain, classifying
general categories share common features, associate features specific heuristic
search techniques. first attempt domain classification also found (Hoffmann,
2001).
alternative view problem concerns way domain encoded.
planner domain may alter performance different representation adopted.
faced problem blocks-world, 4- 3-actions schemas domain
representations, performance GRT varies significantly, performance
planners also altered. also faced problem elevator movie domains,
motivation development domain enrichment technique. conviction
domain-independent planning strongly domain-representation dependent.
Concerning GRT, plan extend handle expressive domains, supporting
features PDDL language (types, quantifications, negations, disjunctions, etc).
time working extension GRT, ability take account multiple
criteria (i.e. solution time, resources, safety, profit etc.). also interested incorporating
domain analysis techniques, developed STAN DISCOPLAN, order take
advantage specialized methods handling specific types problems sub-problems. Finally,
investigate possibility utility combining domain independent planning
techniques domain dependent ones, without loosing generality planning system.

Acknowledgments
authors would like thank Thomas Eiter, editor charge paper,
anonymous reviewers helpful comments. would like also thank Dimitris Vrakas
careful reading suggestions final version paper. Finally, would like thank
researchers planning community making planners available,
specifically Blai Bonet, Hector Geffner, Joerg Hoffman, Bernhard Nebel, Derek Long, Maria Fox,
Romeo Sanchez Nigenda, XuanLong Nguyen Subbarao Kambhampati.

157

fiREFANIDIS & VLAHAVAS

References
Barrett, A. & Weld, D. S. (1994). Partial order planning: Evaluating possible efficiency gains.
Artificial Intelligence, 67, 71-112
Biundo, S. & Fox, M. (2000). Recent advances AI planning. 5th European Conference
Planning (ECP-99). Durham, UK, Springer-Verlag.
Blum, A. & Furst, M. (1997). Fast planning planning graph analysis. Proceedings
IJCAI-95.
Blum, A. & Furst, M. (1995). Fast planning planning graph analysis. Artificial
Intelligence, 90, 281-300.
Bonet, B. & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1-2), pp.
5-33.
Bonet, B. & Geffner, H. (1999). Heuristic planning: New results. (Biundo & Fox, 1999).
Bonet, B. & Geffner, H. (1998). HSP: Heuristic search planner. Entry 4th International
Conference Artificial Intelligence Planning Systems (AIPS) Planning Competition.
Pittsburgh, 1998.
Bonet, B., Loerincs, G. & Geffner, H. (1997). robust fast action selection mechanism
planning. Proceedings AAAI-97.
Cheng, J. & Irani, K. B. (1989). Ordering problem subgoals. Proceedings IJCAI-89.
Drummond, M. & Currie, K. (1989). Goal ordering partially ordered plans. Proceedings
IJCAI-89.
Fikes, R. E. & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189-208.
Fox, M. & Long, D. (2001). Hybrid STAN: Identifying managing combinatorial optimization
sub-problems planning. Proceedings IJCAI-2001.
Fox, M. & Long, D. (2000). Using automatically inferred invariants graph construction
search. Proceedings AIPS-2000.
Fox, M. & Long, D. (1999). detection exploitation symmetry planning problems.
Proceedings IJCAI-99.
Fox, M. & Long, D. (1998). automatic inference state invariants TIM. Journal
Artificial Intelligence Research, 9, 367-421.
Gerevini, A. & Schubert, L. (2000b). Discovering state constraints DISCOPLAN: new
results. Proceedings AAAI-00.
158

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

Gerevini, A. & Schubert, L. (2000a). Extending types state constraints discovered
DISCOPLAN. Proceedings AIPS-00 Workshop Analysing Exploiting
Domain Knowledge Efficient Planning.
Gerevini, A. & Schubert, L. (1998). Inferring state constraints domain-independent planning.
Proceedings AAAI-98.
Godefroid, P. & Kabanza, F. (1991). efficient reactive planner synthesizing reactive plans.
Proceedings AAAI-91.
Gupta, N. & Nau, D.S. (1992). complexity blocks world planning. Artificial Intelligence
56 (2-3), 223-254.
Haslum, P. & Jonsson, P. (2000). Planning reduced operator sets. Proceedings AIPS2000.
Hoffmann, J. & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence 14, 253-302.
Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis.
Proceedings IJCAI-2001.
Kautz, H. & Selman, B. (1998). BLACKBOX: new approach application theorem
proving problem solving. AIPS-98 Workshop Planning Combinatorial Search.
Kautz, H. & Selman, B. (1996). Pushing envelope: Planning, propositional logic stochastic
search. Proceedings AAAI-96.
Kautz, H. & Selman, B. (1992). Planning satisfiability. Proceedings ECAI-92.
Koehler, J. (1998). Solving complex planning tasks extraction subproblems.
Proceedings 4th Intl. Conf. Artificial Intelligence Planning Systems (AIPS-98).
Koehler, J. & Hoffmann, J. (2000). reasonable forced goals orderings use
agenda-driven planning algorithm. Journal Artificial Intelligence Research, 12, 339-386.
Korf, R. & Taylor, L. (1996). Finding optimal solutions twenty-four puzzle. Proceedings
AAAI-96.
Long, D. & Fox, M. (2000). Automatic synthesis use generic types planning.
Proceedings 5th Intl. Conf. AI Planning Scheduling Systems (AIPS-00).
Long, D. & Fox, M. (1999). Efficient implementation plan graph STAN. Journal
Artificial Intelligence Research, 10, 87-115.
McAllester, D. & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings AAAI91.
McCluskey, T.L. & Porteous, J.M. (1997). Engineering compiling planning domain models
promote validity efficiency. Artificial Intelligence, 95, 1-65.
159

fiREFANIDIS & VLAHAVAS

McDermott, D. (1999). Using regression-match graphs control search planning. Artificial
Intelligence, 109 (1-2), 111-159.
McDermott, D. (1996). heuristic estimator means-ends analysis planning. Proceedings
3rd International Conference Artificial Intelligence Planning Systems (AIPS-96).
Minton, S., Bresina, J. & Drummond, M. (1994). Total-order partial-order planning:
comparative analysis. Journal Artificial Intelligence Research, 2, 227-261.
Nebel, B., Dimopoulos, Y. & Koehler, J. (1997). Ignoring irrelevant facts operators plan
generation. Proceedings 4th European Conference Planning (ECP-97).
Newell, A. & Simon, H. (1972). Human problem solving. Englewood Cliffs, NJ. Prentice-Hall.
Nigenda R.S., Nguyen, X. & Kambhampati, S. (2000). AltAlt: Combining advantages
graphplan heuristic state search. Technical Report, Arizona State University.
Pearl, J. (1983). Heuristics. Morgan Kaufmann.
Pednault, E. (1989). ADL: Exploring middle ground STRIPS situation
calculus. Proceedings KR-89.
Penberthy, J. & Weld, D. (1992). UCPOP: sound complete, partial order planner ADL.
Proceedings KR-92.
Refanidis, I. & Vlahavas, I. (2000b). Heuristic planning resources. Proceedings ECAI2000.
Refanidis, I. & Vlahavas, I. (2000a). Exploiting state constraints heuristic state-space planning.
Proceedings 5th Intl. Conf. Artificial Intelligence Planning Scheduling
Systems (AIPS-00).
Refanidis, I. & Vlahavas, I. (1999c). determining completing incomplete states STRIPS
Domains. Proceedings IEEE Intl. Conf. Information, Intelligence Systems.
Refanidis, I. & Vlahavas, I. (1999b). GRT: domain independent heuristic STRIPS worlds
based greedy regression tables. (Biundo & Fox, 1999).
Refanidis, I. & Vlahavas, I. (1999a). SSPOP: state-space partial-order planner. Proceedings
3rd World Multiconference Systemics, Cybernetics Informatics.
Scholz, U. (1999). Action constraints planning. (Biundo & Fox, 1999).
Slaney, J. & Thiebaux, S. (1996). Linear-time near-optimal planning blocks world.
Proceedings AAAI-96.
Smith, D. & Weld, D. (1999). Temporal graphplan mutual exclusion reasoning.
Proceedings IJCAI-99.

160

fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING

Veloso, M. (1992). Learning analogical reasoning general problem solving. Ph.D. thesis,
Department Computer Science, Carnegie Mellon University.
Vrakas, D., Refanidis, I. & Vlahavas, I. (2000). operator distribution method parallel
planning. AAAI-2000 Workshop Parallel Distributed Search Reasoning.
Vrakas, D., Refanidis, I., Milcent, F. & Vlahavas, I. (1999). parallelizing greedy regression
tables. Proceedings 18th Workshop UK Planning Scheduling SIG.
Zhang, W. (1999). State-space search: Algorithms, complexity, extensions applications.
Springer.

161

fi
