Journal Articial Intelligence Research 15 (2001) 163-187Submitted 10/00; published 09/01Analysis Reduced Error Pruningelomaa@cs.helsinki.fimatti.kaariainen@cs.helsinki.fiTapio ElomaaMatti KriinenDepartment Computer ScienceP. O. Box 26 (Teollisuuskatu 23)FIN-00014 University Helsinki, FinlandAbstractTop-down induction decision trees observed suer inadequatefunctioning pruning phase. particular, known size resultingtree grows linearly sample size, even though accuracy treeimprove. Reduced Error Pruning algorithm used representativetechnique attempts explain problems decision tree learning.paper present analyses Reduced Error Pruning three dierent settings.First study basic algorithmic properties method, properties hold independent input decision tree pruning examples. examine situationintuitively lead subtree consideration replaced leaf node,one class label attribute values pruning examples independentother. analysis conducted two dierent assumptions. generalanalysis shows pruning probability node tting pure noise boundedfunction decreases exponentially size tree grows. specic analysisassume examples distributed uniformly tree. assumption letsus approximate number subtrees pruned receivepruning examples.paper claries dierent variants Reduced Error Pruning algorithm,brings new insight algorithmic properties, analyses algorithm less imposedassumptions before, includes previously overlooked empty subtreesanalysis.1. IntroductionDecision tree learning usually two-phase process (Breiman, Friedman, Olshen, & Stone,1984; Quinlan, 1993).training examplesFirst tree reecting given sample faithfully possibleconstructed. noise prevails, accuracy tree perfectused build tree. practice, however, data tends noisy,may introduce contradicting examples training set.overttednecessarily obtained even training set.Hence, 100% accuracy cannotcase, resulting decision treesample; addition general trends data, encodesprunedpeculiarities particularities training data, makes poor predictorclass label future instances. second phase induction, decision treeorder reduce dependency training data. Pruning aims removingtree parts likely due chance properties training set.problems two-phased top-down induction decision trees well-knownextensively reported (Catlett, 1991; Oates & Jensen, 1997, 1998). sizec 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiElomaa & Kriinentree grows linearly size training set, even thoughaccuracy gained increased tree complexity. Obviously, pruning intendedght eect. Another defect observed data contains relevant attributes;i.e., class labels examples independent attribute values. Clearly,single-node tree predicting majority label examples result case,since help obtained querying attribute values. practice, though, oftenlarge decision trees built data.Many alternative pruning schemes exist (Mingers, 1989a; Esposito, Malerba, & Semeraro, 1997; Frank, 2000).pruning examplesdier, e.g., whether single pruned tree seriespruned trees produced, whether separate setused, aspects(classication error tree complexity) taken account pruning decisions,aspects determined, whether single scan tree suces whetheriterative processing required.basic pruning operation applied treereplacement internal node together subtree rooted leaf.Also elaborated tree restructuring operations used pruning techniquesmajority leafpruning tree(Quinlan, 1987, 1993). paper, pruning operation consideredreplacement subtreeexamples reaching it. Hence,, i.e., leaf labeled majority classsubtree original treezero, one, internal nodes changed leaves.Reduced Error Pruning(subsequentlyrep short) introduced Quinlan (1987)context decision tree learning. subsequently adapted rule set learningwell (Pagallo & Haussler, 1990; Cohen, 1993).practical decision tree pruningoverprunesreprep one simplest pruning strategies.seldom used, disadvantagerequiring separate set examples pruning. Moreover, considered aggressivepruning strategydecision tree, deleting relevant parts (Quinlan,1987; Esposito et al., 1997). need pruning set often considered harmfulscarceness data. However, data mining context examples oftenabundant setting part aside pruning purposes presents problem.Despite shortcomingsrepbaseline method performancepruning algorithms compared (Mingers, 1989a; Esposito, Malerba, & Semeraro, 1993;Esposito et al., 1997).presents good starting point understanding strengthsweaknesses two-phased decision tree learning oers insight decision treepruning.rep advantage producing smallest pruning amongaccurate respect pruning set. Recently, Oates Jensen (1999) analyzedrep attempt explain decision tree pruning fails control growthtree, even though data warrant increased size. approachsubject, try avoid restricting analysis unnecessary assumptions.alsoconsider explanation unwarranted growth size decision tree.rep three dierent settings. First, explore basic algorep, apply regardless distribution examples presentedpaper analyzerithmic propertieslearning algorithm. Second, study, probabilistic setting, situationattribute values independent classication example. Even thoughpure noise tting situation expected arise whole pruning set considered,encountered lower levels tree, relevant attributes alreadyexhausted. assume subtrees receive least one pruning example,164fiAn Analysis Reduced Error Pruningnone directly pruned due receiving examples. class valuealso assigned random pruning examples. third analysis assumedpruning example equal chance end one subtrees treepruned. rather theoretical setting lets us take account subtreesreceive examples. left without attention earlier analyses.rest paper organized follows. next section discusses dierentversionsrepalgorithm xes one analyzed subsequently. Section3 review earlier analysesrep.Basic algorithmic propertiesSection 4. Then, Section 5, carry probabilistic analysisassumptions distribution examples.rep examinedrep, without makingderive bound pruningprobability tree depends exponentially relation number pruningexamples size tree. Section 6 presents analysis, assumespruning examples distribute uniformly subtrees tree. assumption lets ussharpen preceding analysis certain aspects. However, bounds Section 5 holdcertainty, Section 6 approximate results. related researchbriey reviewed Section 7 and, nally, Section 8 present concluding remarksstudy.2. Reduced Error Pruning Algorithmrepnever introduced algorithmically Quinlan (1987), source muchconfusion. Even thoughrepconsidered appears simple, almost trivial,algorithm pruning, many dierent algorithms go name.consensus exists whetherrep bottom-up algorithmiterative method. Neitherobvious whether training set pruning set used decide labels leavesresult pruning.2.1 High-Level ControlQuinlan's (1987, p. 225226) original descriptionrep clearly specify pruningalgorithm leaves room interpretation. includes, e.g., following characterizations.every non-leaf subtreeexamine change misclassicationstest set would occurreplaced best possible leaf.new tree would give equal fewer number errorssubtree property,replaced leaf.containsprocess continuesreplacements would increase number errors testset.[...] nal tree accurate subtree original tree respecttest set smallest tree accuracy.Quinlan (1987, p. 227) also later continues give following description.method [pessimistic pruning] two advantages. much fastereither preceding methods [cost-complexity reduced error pruning]since subtree examined once.165fiElomaa & Kriinenone hand description requires nodes processed bottom-up manner,since subtrees must checked property pruning node but,hand, last quotation would indicatereprepiterative method.takefollowing single-scan bottom-up control strategy like studies(Oates & Jensen, 1997, 1998, 1999; Esposito et al., 1993, 1997; Kearns & Mansour, 1998).Nodes pruned single bottom-up sweep decision tree, pruning node considered encountered.nodes processedpostorder.order node processing, tree candidate pruning cannotcontain subtree could still pruned without increasing tree's error.Due ambiguity1989a; Mitchell, 1997).rep's denition, dierent version rep also lives (Mingers,probably due Mingers' (1989) interpretation Quinlan'sambiguous denition.Nodes pruned iteratively, always choosing node whose removalincreases decision tree accuracy pruning set. process continuespruning harmful.However, algorithm appears incorrect. Esposito et al. (1993, 1997) showntree produced algorithm meet objective accuratesubtree respect pruning set.Moreover, algorithm overlooks explicitrequirement checking whether subtree would lead reduction classicationerror.iterative algorithms could induced Quinlan's original description. However, explicit requirement checking whether subtree could pruned pruning supertree obeyed, versionsrepreduce ecientbottom-up algorithm.2.2 Leaf LabelingAnother source confusion Quinlan's (1987) descriptionrepclearlyspecied choose labels leaves introduced treetrainingpruning. Oates Jensen (1999) interpreted intended algorithm would labelnew leaves according majority classpruningexamples, analyzedversion algorithm new leaves obtain labels majorityexamples. Oates Jensen motivated choice empirical observationpractice little dierence choosing leaf labels either way.However, choosing labels pruned leaves according majority pruning examplesset leaves dierent status original leaves, labelmajority class training examples.ExampleFigure 1 shows decision tree pruned single leaftraining examples used label pruned leaves. negative leaf replaces roottree makes two mistakes pruning examples, original tree makes threemistakes.tree illustrate important dierence using training166fiAn Analysis Reduced Error Pruning+++0/10/12/02/0Figure 1: (part a) decision tree. labels inside nodes denote majority classestraining examples arriving nodes. leaves numbers pruningexamples two classes also given.x=ymeansx negativepositive instances reach leaf.pruning examples label pruned leaves. Using training examples proceeding bottomup, observe neither subtree pruned, since left one replaced negative leafwould make two mistakes instead original one mistake. Similarly, right subtreereplaced positive leaf would result increased number classication errors.Nevertheless, root node even though subtrees pruned stillpruned.pruning examples used label pruned leaves, node two non-trivialsubtrees cannot pruned unless subtrees collapsed leaves.nextsection prove this. tree Figure 1 subtrees would collapsed zeroerror leaves. However, case root node pruned.possibility labeling leaf nodes would take trainingpruning examples account deciding label pruned leaf.Dependingrelation numbers training pruning examples strategy resembles oneabove-described approaches. Usually training examples numerouspruning examples, thus dominate. practice impossible discernlabeling strategy using majority training examples.2.3 Empty SubtreesSincerepuses dierent sets examples construct prune decision tree,possible parts tree receive examples pruning phase.parts decision tree, naturally, replaced single leaf without changingnumber classication errors tree makes pruning examples.words, subtrees obtain pruning examples always pruned. Quinlan (1987)already noted parts original tree correspond rarer special cases,represented pruning set, may excised.167fiElomaa & KriinenDecisionTree REP( DecisionTree T, ExampleArray ){ ( = 0 S.length-1 ) classify( T, S[i] );return prune( ); }void classify( DecisionTree T, Example e ){ T.total++; ( e.label == 1 ) T.pos++;// update node counters( !leaf(T) )( T.test(e) == 0 ) classify( T.left, e );else classify( T.right, e ); }int prune( DecisionTree ) // Output classification error pruning{ ( leaf(T) )( T.label == 1 ) return T.total - T.pos;else return T.pos;else{ error = prune( T.left ) + prune( T.right );( error < min( T.pos, T.total - T.pos ) )return error;else{ replace leaf;( T.pos > T.total - T.pos ){ T.label = 1; return T.total - T.pos; }else{ T.label = 0; return T.pos; } } } }Table 1:repalgorithm. algorithm rst classies pruning examples top-pass using methodtree using methodprune.classifybottom-up pass prunesIntuitively, clear best-founded strategy handlingempty subtrees,receive examples. one hand obtain support trainingset, usually numerous pruning set but, hand, factpruning example corresponds parts tree would justify drawingconclusion parts decision tree built chance properties trainingdata.rep,consistently preferring smaller prunings also otherwise, latter viewadopted.problem empty subtrees connected problemlearning algorithms (Holte, Acker, & Porter, 1989).number training examples.small disjunctsmachinesmall disjunct covers smallCollectively small disjuncts responsiblesmall number classication decisions, accumulate error wholeconcept. Nevertheless, small disjuncts cannot eliminated altogether, without adverselyaecting disjuncts concept.168fiAn Analysis Reduced Error Pruning2.4 Analyzed Pruning AlgorithmLet us briey reiterate detailsrep algorithm analyzed subsequently.al-ready stated, control strategy algorithm single-sweep bottom-up processing.First, top-down traversal drives pruning examples tree appropriateleaves. counters nodes en route updated. Second, bottom-up traversal pruning operations indicated classication errors executed.errorsdetermined basis node counter values. bottom-up traversalnode visited once. pruned leaves labeled majority pruning set(see Table 1).3. Previous WorkPruning decision trees recently received lot analytical attention; existing pruningmethods analyzed (Esposito et al., 1993, 1997; Oates & Jensen, 1997, 1998,1999) new analytically-founded pruning techniques developed (Helmbold &Schapire, 1997; Pereira & Singer, 1999; Mansour, 1997; Kearns & Mansour, 1998).Alsomany empirical comparisons pruning appeared (Mingers, 1989a; Malerba, Esposito,& Semeraro, 1996; Frank, 2000). section review earlier work concernsrepalgorithm. related research considered Section 7.Esposito et al. (1993) viewedsearch process state space.repalgorithm, among pruning methods,addition noting iterative versionrepcannot produce optimal result required Quinlan (1987), also observed eventhoughtreerep linear-time algorithm size tree, respect heightrep requires exponential time worst case. subsequent comparativeanalysis Esposito et al. (1997) sketched proof Quinlan's (1987) claim pruningproducedreptree.biassmallest among accurate prunings given decisionrep briey examined Oates Jensen (1997, 1998).observedrL , best majority leaf could replace subtree depends(the class distribution ) examples reach root N . words, treestructure N decides error rL . Let rT denote error subtreemoment pruning sweep reaches N ; i.e., pruning may alreadytaken place . pruning operations performed led either rT decreaseinitial situation stay unchanged. case, pruning taken placepotentially decreases rT , aect rL . Hence, probability rT < rL i.e.,pruned increases pruning . error propagation biaserror,inherentrep.Oates Jensen (1997, 1998) conjecture larger originaltree smaller pruning set, larger eect, large tree providespruning opportunities high variance small pruning set oers randomchancesrL rT .Subsequently study eects exactly.follow-up study Oates Jensen (1999) usedrepvehicle explainingproblems observed pruning phase top-down induction decisiontrees. analyzedrep situationdecision node consideration tsnoise i.e., class examples independent value attribute testednode hand built statistical model169repsituation. indicates,fiElomaa & Kriinenconsistently earlier considerations, even though probability pruningnode ts noise prior pruning beneath close 1, pruning occurs beneathnode reduces pruning probability close 0. particular, model shows evenone descendant nodeNdepthpruned, Npruned (assuming+1). consequence result increasing depthleads exponential decrease node's pruning probability.leaves depthrst part Oates Jensen's (1999) analysis easy comprehend, significance uncertain, situation rise bottom-up pruning strategy.statistical model based assumption number,n, pruning instancespass node consideration large, case independence assumptions prevailing errors committed node approximated normaldistribution. expected error original tree mean distribution, while,pruned leaf, tree would misclassify proportionn examples correspondsminority class. Oates Jensen show latter number always lessmean standard distribution errors. Hence, probability pruning0.5 approaches 1n grows.second part analysis, considering pruning probability nodeNpruning taken place beneath it, Oates Jensen assume proportionpositive examples descendantassumingNNdepthN .setting,alsopruned,positive majority, descendants levelpositive majority. directly follows descendants levelreplaced positive leaf. Hence, function represented pruning identicallypositive. majority leaf would replacesmaller pruning. Therefore,Nalso represents functionrep choose single leaf pruning.N depth pruned,N , subtrees maintained nodeshand, one descendantspruning tree rootedlevelpruned positive leaves, accurate majority leaf.case tree pruned.Oates Jensen (1999) also assume starting node levelproba-bility routing example positive leaf same. following analyses tryrid unnecessary assumptions; results obtained without knowledgeexample distribution.4. Basic Propertiesrepgoing detailed probabilistic analysisbasic algorithmic properties.repalgorithm, examineThroughout paper review binary casesimplicity. results, however, also apply many-valued attributes several classes.processing controlrepalgorithm settled, actuallyprove Quinlan's (1987) claim optimality pruning producedrep.Observefollowing result holds true independent leaf labeling strategy.Theorem 1 Applying rep set pruning examples, , decision tree produces0 pruning smallest prunings minimalerror respect example set S.170fiAn Analysis Reduced Error PruningProof prove claim induction size tree. Observe decisionfull binary tree, 2L(T ) 1 nodes, L(T ) number leavestreetree.Base case.L(T ) = 1,original treeconsists single leaf node.possible pruning itself. Thus, is, trivially, also smallest amongaccurate pruningsT.Inductive hypothesisInductive step L(T ) = k. claim holds.. LetNright subtree, respectively. Subtreespruning decisionNL(T ) < k.T1leftmust strictly lessroot treeT0T1prunings trees.T00T10 ,k leaves.inductive hypothesis,smallest possible among accurate(i): AccuracyNtaken, bottom-up recursive control strategyrep T0 T1 already processed algorithm.subtrees pruning,T0. pruning decision nodeN consists choosing whether collapsetree rooted majority leaf, whether maintain wholetree. alternatives make number errors,Ncollapsedoriginal accuracy respect pruning set retained. Otherwise,repalgorithm, pruning decision based resulting trees would make. Hence, whichever choice made,0 make smaller number errors respect .00Let us assume pruning makes even less errors respect0000000. must consist root N two subtrees T0 T1 ,000majority leaf cannot accurate . Since accurate pruning0 , must either T000 accurate pruning T0 T00 T1000accurate pruning T1 T1 . inductive hypothesis possibilities0false. Therefore, accurate pruning .less errors respect pruning setresulting tree(ii): Size0. see chosen alternative also small possible, rst assumeconsists single leaf. tree smallest pruningclaim follows.T00 T10 .0Otherwise, consists root node N, casetwo pruned subtreesSince tree collapsed, tree must accuratetree consisting single majority leaf. assume exists pruning0 , smaller. majority leaf less accurate0, must consist root node N two subtrees T0 T1 . Then, eitherT0 smaller pruning T0 T00 , accurate, T1 smaller pruningT1 T10 , accurate. cases contradict inductive hypothesis. Hence,0 smallest among accurate prunings .accurateThus, case, claim followsT.2consider next situation internal node tree, bottom-uppruning sweep reaches node.committed leaf labelingmajority pruning examples.171fiElomaa & Kriineninternal node, prior pruning leaves children,pruned rep non-trivial subtree bottom-up pruning sweep reachesit.Theorem 2Proofinternal nodeNtwo possible cases non-trivialsubtrees; either subtrees non-trivial (non-leaf ) one trivial. Let usreview cases.LetrTdenote error (sub)treerespect part pruning set. rL denote misclassication rate majority leaf L, chosen pruned.reaches rootwould replaceCase I: Let two subtrees, T0 T1 , non-trivial.Hence,rT0 < rL0 rT1 < rL1 ,T0 T1 , respectively,pruned. rT = rT0 + rT1 , must rT < rL0 + rL1 .T0 T1 majority class, also majority class .rL = rL0 + rL1 , L majority leaf corresponding . Otherwise,rL rL0 + rL1 . case, rL rL0 + rL1 . Combining factrT < rL0 + rL1 means rT < rL . Hence, pruned.retained pruning sweep passed them. Thus,L0Case II: LetL1majority leaves would replaceone trivial subtree, produced pruning, one non-T0 non-trivial L1T1 pruning process. Then, rT0 < rL0 . Hence,rT = rT0 + rL1 < rL0 + rL1 .way Case I, deduce rL rL0 + rL1 . Therefore,rT < rL retained pruned tree.trivial subtree. assume, without loss generality,majority leaf replacedcannot pruned either case, pruning process stopped branchcontainingnodeunless original leaf appears along path rootN2T.original leaf, may pruned even subtreenon-trivial. AlsoNNtwo trivial subtrees, may pruned. Whether pruningtakes place depends class distribution examples reachingNsubtrees.analysis Oates Jensen (1999) shown prerequisite pruningnodeNtree descendants depthpruned.depth rst (original) leaf subtree rootedresult situation, corroborate ndingdescendants depthretained.NN.applypruned oneApplying Theorem 2 recursively givesresult.tree rooted node N retained rep onedescendants N depth pruned.Corollary 3avoid analysis restricted leaf globally closest root, needfringeable consider set leaves closest root branches tree. Let usdenedecision tree contains node prior pruning leaf172fiAn Analysis Reduced Error PruningFigure 2: fringe (black gray nodes), interior (white nodes), safe nodes(black ones) decision tree. triangles denote non-trivial subtrees.child. Furthermore, node subtree rooted node belonginginteriorSafe nodesfringe tree also fringe. nodes belonging fringe maketree.belong fringe tree,parent interior tree (see Figure 2). fringe decision tree closeddownwards, safe nodes tree correspond leaves pruning it. Observealso along path root safe node leaves. Therefore,pruning process ever reaches safe node, Theorem 2 applies corresponding branchon.decision tree consideration pruned single majority leaf, safenodes also need turned leaves point, necessarily simultaneously.pruning sweep continues safe nodes, question whether nodepruned settled solely basis whether nodes path rootmajority class. pruning whole tree characterized below.Lettree prunedset pruning examples, jS j = n.assume,without loss generality, least half pruning examples positive. Letproportion positive examples; p 0:5.preplaced majorityleaf, leaf would positive class label. assumptions provefollowing.tree pruned single leafsubtrees rooted safe nodes prunedleast many positive negative pruning examples reach safe node .Theorem 4173fiElomaa & KriinenProofbegin show two conditions necessary pruningshow former condition fullled,leaf. Second, prove neitherlatter not.hold,T.First,cannot pruned singlepruned former condition holds,Third, show suciency conditions; i.e., provepruned single leaf.(i): Let us rst assumesafe nodedenition safe node, parentTherefore, Theorem 2,neither rootPPNNpruned.originally leaves children.pruned.easy see, inductively,pruned.(ii): Let us assume subtrees rooted safe nodes get prunedone safe nodesnegative positive pruning examplesfall. Observe safe nodes cannot such. Let us consider pruningleaves situated place safe nodes; leaves receiveexamples original safe nodes.safe nodes internal nodes,repcorresponding pruned leaves labeled majority pruning examples.particular, safe nodes receive negative positive examplesreplaced negative leaves. leaves labeled positive. pruningoriginal tree accurate majority leaf. Hence, Theorem 1,prunerepsingle-leaf tree.(iii): Let us assume subtrees rooted safe nodesprunedleast many positive negative pruning examples reach safe node.interior nodes must also majority positive pruning examples. Otherwise,negative positive examples. Thus,N majority negative examples. Carryinginduction way safe nodes shows node N exist .Hence, interior prunings represent function (identically positive)error respect . majority leaf unique,interior nodeNleast one childrensmallest prunings will, Theorem 1, chosen.25. Probabilistic AnalysisrepLet us turn attention question prerequisites pruning decisiontreesingle majority leaf are. Since, Theorem 1,repproduces pruningaccurate respect pruning set smallpossible, showreduce single leaf suces nd pruningbetter prediction accuracy pruning examples majority leaf has.following class example assumed independent attributevalues. Obviously, decision tree node assumption holdsexamples arriving it, would like pruning algorithm turn majority leaf.make assumptions decision tree. However, similar analysisOates Jensen (1999), obtained bounds tight, shortest pathroot tree leaf short.174fiAn Analysis Reduced Error Pruning5.1 Probability Theoretical PreliminariesLet us recall basic probabilistic concepts results used subsequently.denote probability eventpXX B (n; p),(integer-valued) random variable, denotedEPrfE gEE .binomially distributed parameters nexpectationsaiddiscrete!n kPrf X = k g =p (1 p)n k ; k = 0; 1; : : : ; n:kX B (n; p), expectedp value mean EX = = np, variance varX = np(1 p),= np(1 p).indicator variablestandard deviation1. indicator variableA1 ; : : : ;discrete random variable takes values 0used denote occurrence non-occurrence event.Pnindependent eventsX=IAPrfAi g = p IA1 ; : : : ; IAnrespectivei=1Bernoullipdensity function fX : ! [0; 1]XfX (x) = Prf X = x gcumulativedistributionfunctionF:![0; 1]XPindicator variables,IAcalledbinomially distributed parametersrandom variable parameterdiscrete random variable.n p..denedFX (y) = Prf X g = xy fX (x).Let X B (n; p) random variable mean = np standardp= np(1 p). normalized random variable corresponding XXdenedXXe =deviation:central limit theorem approximate cumulative distribution functioneXnormal Gaussian distributionnFXe (y) = Pr Xe(y):cumulative distribution function bell curve density function eRespectively, applyableXnormal approximationFX (y) = Prf X g = FXex2 =2 =FXep2 .corresponding random vari-:5.2 Bounding Pruning Probability TreeNow, pruning set considered sample distribution classattribute independent attributes.assume class attribute(p) distribution; i.e., class positive probabilityp negative probability 1 p. assume p > 0:5.distributed according Bernoullifollowing analyze situation subtrees rooted safe nodesalready pruned leaves. bound pruning probability tree startinginitial conguration.Since bottom-up pruning may already comehalt situation, following results actually give high probabilitypruning. Hence, following upper bounds tight possible.175fiElomaa & Kriinenconsider pruning decision treereptrial whose result decided setpruning examples. Theorem 4 approximate probability treepruned majority leaf approximating probabilitysafe nodes getpositive majority negative majority. latter alternative probableassumptionp > :5.safe assume never happens.consider sampling pruning examples two phases. First attribute valuesassigned.decides leaf example falls.second phaseindependently assign class label example.Z (T ) = fz1 ; : : : ; zk g let number examplespruning set jS j = n. number pruning examples falling safe node ziPkdenoted ni ;i=1 ni = n. time assume ni > 0 i. numberpositive examples falling safe node zi sum independent Bernoulli variablesand, thus, binomially distributed parameters ni p. Respectively, numbernegative pruning examples safe node zi Xi B (ni ; 1p). probabilitymajority negative examples safe node zi Prf Xi > ni =2 g. boundLet safe nodes treeprobability using following inequality (Slud, 1977).Lemma 5 (Slud's inequality)m(1 q) h mq,Let X B(m; q) random variable q 1=2.!h mq:Prf X h g 1 pmq(1 q)p > :5 random variable corresponding number negative exampleszi Xi B (ni; 1 p), rst condition Slud's inequality holds. Furthermore,see condition m(1q) h mq holds safe node zi substitute h = ni =2, = ni ,q = 1p obtain ni p ni=2 ni(1 p). Thus,Sincesafe nodePr Xi >ni2!!=2 ni(1 p)= 1 p(p 1=2)ni :1 nipni p(1 p)ni p(1 p)(1)ni , number pruning instances reaching safe node zi , grows, standardnormal distribution term bound also grows. Hence, bound probabilitymajority pruning examples reachingzinegative smallerpruning examples reach it. probability negative majority also reducesgrowing probability positive class example,p.also reectedpruning probabilities whole tree.roughly approximate probabilitymajority leaf follows. Theorem 4,nodepruned singlepruned leaf safereceives majority positive examples.ksafe nodesn pruning examples, according pigeon-hole principle least half safer = 2n=k examples. safe node zi ni r examples has,nodes receiveInequality 1, negative majority least probability!1 p(p 1=2)r :rp(1 p)176fiAn Analysis Reduced Error PruningObserve Inequality 1 also holdsni < r, becausepthe cumulativedistributionincreasing function. argument ni (p 1=2)= ni p(1 p) canpbe rewrittenpni cp , cp ispa positive constant depending value p. Since ( ni cp ) growsni grows, 1( ni cp ) grows decreasing ni . Hence, lower bound Inequality1 also applies values 0 < ni < r .functionThus, probability half safe nodes receiverexamplespositive majorityp(p 1=2)rrp(1 p)!!k=2:(2)upper bound probability whole treepruned singleleaf. distribution assumption made reach resultp > :5.order obtain tighter bounds, one make assumptions shape treedistribution examples.bound Equation 2 depends size decision tree (reectednpk),number ( ) class distribution ( ) pruning examples. Keeping parametersconstant lettingkgrow reduces pruning probability exponentially. numberpruning examples grows proportionr = 2n=kstays constant,pruning probability still falls exponentially. Class distribution pruning examples alsoaects pruning probability smaller, closerp value .5.5.3 Implications Analysisempirically observed size decision tree grows linearlytraining set size, even trees pruned (Catlett, 1991; Oates & Jensen, 1997,1998). analysis gives us possibility explain behavior. However, let usrst prove correlation attribute values class labelexample, size tree perfectly ts training data depends linearlysize sample.setting simple be. one real-valued attributeattributey, whose value independentx.before,x classtwo possible values,0 1. tree built using binary splits numerical value range; i.e., propositionstypex < rassigned internal leaves tree.analysis duplicateinstances occur probability 0.Let training examples (x; y) drawn distribution, x uniformly distributed range [0; 1) obtains value 1, independent x, probabilityp, value 0 probability 1 p. expected size decision tree tsdata linear size sample.Theorem 6= h(x1 ; y1 ); : : : ; (xt ; yt )i sample described distribution.xi 6= xj , 6= j , probability complement event 0.Let us, further, assume examples indexed x1 < x2 < : : : < xt .Let Ai indicator variable event instances + 1 dierent classlabels; i.e., yi 6= yi+1 , 1 1. EAi = Prf Ai = 1 g = p(1 p)+(1 p)p = 2p(1 p),ProofLetmay assume177fiElomaa & Kriinenyi = 1 probability p, time event yi+1 = 01 p, vice versa. number class alternations = Pti=11 AieventprobabilityexpectationEA =Let1Xi=1EAi =1Xi=12p(1 p) = 2p(1 p)1Xi=11 = 2(t 1)p(1 p):decision tree grown samplecontinued training error 0. leaf[a; b) [0; 1).yi 6= yy+1 ,xixi+1S.(3)growingcorresponds half open intervalmust fall dierent leavesT,. Thus, upper boundary bxi falls must value less xi+1 .otherwise one example falsely classiedinterval corresponding leafRepetitively applying observation scanning examples leftmust least one leaf x1 one leaf class alternation;+ 1 leaves total. using Equation 3 see expected number leavesright, seei.e.,EA + 1 = 2(t 1)p(1 p) + 1:particular, linear size sample ; jS j = t.2theorem concerns zero training error trees built rst phasedecision tree induction. empirical observations Catlett (1991) Oates Jensen(1997, 1998), however, concern decision trees pruned second phaseinduction. come back topic pruned trees shortly.Considerrep used practice.amount (classied) data availableapplication domain. Let totalexamples available. part ff1 ff reserveddata used tree growing remaining portionseparate pruning set;0 < ff < 1.Quite common practice use two thirds datagrowing one third pruning nine tenths growing one tenth pruning(ten-fold) cross-validation used. decision tree construction phase treettedfft examples perfectly possible.hypothesize previous resultholds noisy real-world data sets, empirical evidence would appearcase, number safe nodes also grows linearly number leaves,tree grown containsafe nodes,> 0. Since pruning set size alsor = 2n=k stays constant setting.linear fraction training set size, ratioHence, Equation 2, growing data set size forces pruning probability zero, evenquite fast, reduction probability exponential.5.4 Limitations AnalysisEmpty subtrees, receive pruning examples, left without attentionabove; assumedni > 0i.Empty subtrees, however, decisively aectanalysis; automatically pruned away. Unfortunately, one cannot derive non-trivialupper bound number empty subtrees. worst case pruning examplesrouted safe node, leavesk 1 empty safe nodes tree.Subsequentlyreview case examples distributed uniformly safe nodes.better approximations obtained.178fiAn Analysis Reduced Error PruningEven though assume pruning example positive higher probability.5, guarantees majority examples positive.However,probability majority examples changes small, even negligible,Cherno 's inequality (Cherno, 1952; Hagerup & Rb, 1990) number pruningn, high p extremely close one half.Prf X h g, used boundprobability Prf X > h g. continuity correction could used compensate this.examples,Slud's inequality bounds probabilitypractice, inexactness make dierence.Even though would appear number safe nodes increases proportion leaves size training set grows, provedresult. Theorem 6 essentially uses leaf nodes, lend modication,safe nodes could substituted place leaves.relation number safe nodes leaves decision tree dependsshape tree. Hence, splitting criterion used tree growing decisivelyaects relation. splitting criteria aim keeping produced split balancedpossible, others aim separating small class coherent subsets data (Quinlan,1986; Mingers, 1989b). example, common entropy-based criteria biasfavors balanced splits (Breiman, 1996). Using balanced splitting criterion would seemimply number safe nodes tree depends linearly number leavestree.case reasoning would explain empirically observed lineargrowth pruned decision trees.6. Pruning Probability Uniform Distributionassumeknpruning examples equal probability endsafe nodes; i.e., pruning example falls safe nodeziprobability1=k.Contrary normal uniform distribution assumption analysis, analysisbest case. best distribution examples safe nodes would one pruningexample safe nodes except one, remaining pruning instanceswould gather.Nevertheless, uniformity lets us sharpen general approximationusing standard techniques.n=k. Let us calculatecn=k examples, cevent safe node zi receivesexpected number examples falling safe nodeexpected number safe nodes receiveQPi indicatork Q number safe nodes receive lessi=1Pklinearity expectation EQ =i=1 EQi = kEQ1 ,last equality follows fact Qi -s identically distributed.Let Y1 number examples reaching safe node z1 . n examples reaches z1 probability 1=k independent examples, Y1 binomiallydistributed parameters n 1=k . Clearly EQ1 = Prf Y1 cn=k g. approxiarbitrary positive constant. Letcn=k examples.cn=k examples.Q=mate last probability normal approximation, obtain!!cn=kn=k(c1)n=kcnpn 1=k (1 1=k) = pn=k(1 1=k) :Pr Y1k179fiElomaa & KriinenHence, observation,!(c 1)n=k :EQ = kEQ1 k pn=k(1 1=k)(4)use Approximation 4 determine probability whole decision treepruned single leaf. LetdenotePrandom variable represent numbercn=k examples least one example.R number empty safe nodes, P = Q R. Hence, EP = E(Q R) =safe nodesreceiveEQ ER.following result (Kamath, Motwani, Palem, & Spirakis, 1994; Motwani & Raghavan,1995) lets us approximate number empty safe nodesTheorem 7bins.n k.Let Z number empty bins balls thrown randomly h= EZ = h 1> 0,Prf jZ1hj g 2 expm=h!2 (h 1=2):h2 2result expected number empty safe nodes approximatelynumber smallken=k ;k relatively small compared n.EQ (Equation 4) using pre-Substituting obtained approximationvious result, get(c 1)n=kEP = EQ ER k pn=k(1 1=k)!en=k!:Applying Slud's inequality can, before, bound probabilitymajority class change safe node receivesSincePcn=kpruning examples.safe nodes class distribution examples withinindependent, event majority class change safe node receivesleast onecn=k examplesupper boundp(p :5)rrp(1 p)r = cn=k.ReplacingP!!P;(5)expected value equation approxi-mation pruning probability. approximation validexpected value. consider deviationPPdeviate lotexpected value below.upper bound pruning probability similar upper boundobtained without assumptions distribution examples. However,earlier constant 2 replaced new, controllable parameterexplicitly taken account.c, empty subtreesc chosen suitably, upper bound strictone obtained general case.180fiAn Analysis Reduced Error PruningUpper bound pruning probability0.50.2510.500.90.80.70.51Figure 3: eect parametersp0.61.5c0.5p c upper bound pruning probabilitytree 100 safe nodes 500 pruning examples used. curvesdepicting 0.25 0.5 upper bounds also shown.6.1 Illustration Upper BoundFigure 3 plots upper bound pruning probability tree 100 safe nodes500 pruning examples used. value parameterc varies 0 2 p varies0.5 1. observe surface corresponding upper bound staysclose 0 class distribution skewed parametercsmall value. probability example positive class labelc approaches 0, upper bound climbs steeply. leastparameter c due inexactness approximationhits value 0.75 valuepartextreme values.probabilitypexample positive class approaches 1, errorcommitted single positive leaf falls 0. Hence, accuracy non-trivial pruningbetter, closerp 1 beat majority leaf.Intuitively, probabilitypruning exists i.e., root node pruned drop zerop increases.bound reects intuition.value parameterc falls close 0, safe nodes taken accountupper bound receive pruning examples. number nodes181fiElomaa & Kriinensmall. hand,cincreased, number nodes considerationgrows together upper limit number examples reaching single onethem. Thus, small large valuesvaluec somewherecyield loose bounds. strictest boundsmiddle, example around values 1.01.5.bound Equation 5 argument cumulative distribution functionzero valuec small,tends towardstime exponent decreases.approaches 1/2, argument goes zero. hand, clarge value, approaches value 1 exponent P also increases.value6.2 Exactness Approximationused expected value P analysis; EP = EQER. probedeviation P expected value. deviation R directly availableTheorem 7:!2 (k 1=2):k2 E2 RPrf jR ERj g 2 expQ similar result yet.Lipschitz conditionsection provide one.Let us rst recapitulate denition.f : D1 Dm ! IR real-valued function argumentsf said satisfy Lipchitz conditionx1 2 D1 ; : : : ; xm 2 Dm , 2 f1; : : : ; mg, yi 2 Di ,DenitionLetpossibly distinct domains. functionjf (x1 ; : : : ; xi 1 ; xi ; xi+1; : : : ; xm ) f (x1; : : : ; xi 1 ; yi; xi+1 ; : : : ; xm )j 1:Hence, function satises Lipschitz condition arbitrary change valueone argument change value function 1.martingalesfollowing result (McDiarmid, 1989) holds functions satisfying Lipschitz condition. general results kind obtained using(Motwani & Raghavan, 1995)).(see e.g.,Theorem 8 (McDiarmid) Let X1 ; : : : ; Xm independent random variables taking valuesset V . Let f : V ! IR that, = 1; : : : ; m:supx1 ;:::;xm ;yi 2Vjf (x1; : : : ; xi 1; xi ; xi+1; : : : ; xm ) f (x1; : : : ; xi 1 ; yi; xi+1 ; : : : ; xm )j ci :> 0,Prf jf (X1 ; : : : ; Xm ) Ef (X1 ; : : : ; Xm )j g 2 exp2P2c2i=1!:Wi , = 1; : : : ; n, random variable Wi = j i-th exampledirected safe node zj . uniform distribution assumption Wi -s independent.values within set f1; : : : ; k g. Let us dene function ff (w1 ; : : : ; wn ) number safe nodes receive r = cn=k examples,i-th example directed safe node zw . is,Letf (w1 ; : : : ; wn ) = jf 2 f 1; : : : ; k g j jSi j r gj;182fiAn Analysis Reduced Error PruningSi set examples directed safe node zi ;Si = f h 2 f 1; : : : ; n g j wh = g:Q = f (W1 ; : : : ; Wn ).Hence,Moving one example one safe node another (chang-ing value one argumentditionfPnwi ), change one safe node zijSij r, one less safe node fulll it, time.fulll conThus, valuechanges 1. Hence, function fullls Lipschitz condition. Therefore,apply McDiarmid's inequality substitutingc2 = n:i=1ci = 1 observing2Prf jf (W1 ; : : : ; Wn ) Ef (W1 ; : : : ; Wn )j g 2e 2 =n ;equally2Prf jQ EQj g 2e 2 =n :Unfortunately, concentration bound tight. Nevertheless, combiningconcentration boundsQ R Pfollowing deviation expectedvalue.Since jPEP j = jQ R E(Q R)j = jQ EQ + ER Rj jQ EQj + jR ERj,jQ R E(Q R)j implies jQ EQj =2 jR ERj =2. Thus,Prf jP EP j g = Prf jQ R E(Q R)j gPr jQ EQj 2 + Pr jR ERj 2!22n + 2 exp2 exp!2 (k 1=2):4(k2 E2 R)7. Related WorkTraditional pruning algorithms like cost-complexity pruning (Breiman et al., 1984), pessimistic pruning (Quinlan, 1987), minimum error pruning (Niblett & Bratko, 1986; Cestnik& Bratko, 1991), critical value pruning (Mingers, 1989a), error-based pruning (Quinlan,1993) already covered extensively earlier work (Mingers, 1989a; Espositoet al., 1997; Frank, 2000). Thus touch methods further. Instead,review recent work pruning.repproduces optimal pruning given decision tree respect pruningset. approaches producing optimal prunings also presented (Breimanet al., 1984; Bohanec & Bratko, 1994; Oliver & Hand, 1995; Almuallim, 1996). However,often optimality measured training set. possible maintaininitial accuracy, assuming noise present. Neither usually possible reducesize decision tree without sacricing classication accuracy. example,work Bohanec Bratko (1994) studied eciently nd optimalpruning sense output decision tree smallest pruning satisesgiven accuracy requirement. somewhat improved algorithm problempresented subsequently Almuallim (1996).183fiElomaa & Kriinenhigh level control Kearns Mansour's (1998) pruning algorithmcost-complexitybottom-up sweeprep.However, pruning criterion method kindcondition (Breiman et al., 1984) takes observed classicationerror (sub)tree complexity account.Moreover, pruning schemepessimisticrequire pruning set separate training set. Mansour's (1997)Kearns Mansour's (1998) algorithms(sub)tree training error.: try bound true errorSince training error nature optimistic,pruning criterion compensate pessimistic error approximation.Consider yet another variantrep, oneotherwise similar one analyzedabove, exception original leaves put special status,relabeled majority pruning examples like internal nodes. versionrepproduces optimal pruning respect performance KearnsMansour's (1998) algorithm measured. pessimistic pruning produces decision treesmaller producedrep.Kearns Mansour (1998) able prove algorithm strong performance guarantee. generalization error produced pruning boundedbest pruning given tree plus complexity penalty.local sensereppruning decisionsbasic pruning operation replacingsubtree leaf used pruning algorithm.8. Conclusionpaperrepalgorithm analyzed three dierent settings.First,rep alone, without assuming anything inputsetting possible prove rep fulllsstudied algorithmic propertiesdecision tree pruning set.intended task produces optimal pruning given tree. algorithm proceedsprune nodes branch long subtrees internal node prunedstops immediately even one subtree kept. Moreover, prunes interior nodedescendants levelpruned. Furthermore,repeither haltssafe nodes reached prunes whole tree case safe nodesmajority class.second setting tree consideration assumed noise; i.e.,assumed class label pruning examples independent attributevalues. setting pruning probability tree could bound equationdepends exponentially size tree linearly number classdistribution pruning examples. Thus, analysis corroborates main ndingOates Jensen (1999)rep fails control growth decision tree extremecase tree ts pure noise. Moreover, analysis opened possibility initiallyexplain learned decision tree grows linearly increasing data set. boundpruning probability tree based bounding probability safe nodesmajority class. Surprisingly, essentially property, whose probabilitytry bound close 0, assumed hold probability 1 analysis OatesJensen (1999).repmay happen pruning examples directed given subtree.subtrees taken account earlier analyses.184nal analysisfiAn Analysis Reduced Error Pruningincluded empty subtrees equation tree's pruning probability.Taking emptysubtrees account gives realistic bound pruning probability tree.Unfortunately, one cannot draw denite general conclusions two-phased topdown induction decision trees basis analysesbias quite unique among pruning algorithms.factrep algorithm,rep penalizesize tree, rests classication error pruning examples makesmethod sensitive small changes class distribution pruning set. decisiontree pruning algorithms also individual characteristics. Therefore, unied analysisdecision tree pruning may impossible.versionrep,one allowed relabel original leaves, well, usedperformance objective Kearns Mansour's (1998) pruning algorithm.Thus,performance pruning algorithms use error size penalty relateduse error estimation. versionrepused Kearns Mansouranalysis based safe nodes applies leaves place safe nodes. Hencealgorithm derived bounds stricter.leave detailed analysis important pruning algorithms future work.investigation possible disclose dierences similaritiespruning algorithms.Empirical examination managed reveal clear performancedierences methods.Also, relationship number safe nodesleaves tree ought examined analytically empirically. particular, onestudy whether number safe nodes increase linearly growing training set,conjectured paper. Deeper understanding existing pruning algorithms may helpovercome problems associated pruning phase decision tree learning.ReferencesIntelligence 83Almuallim, H. (1996). ecient algorithm optimal pruning decision trees.,Learning 15, 347362.Bohanec, M., & Bratko, I. (1994). Trading accuracy simplicity decision trees.,(3), 223250.Regression TreesBreiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. (1984).. Wadsworth, Pacic Grove, CA.tional Joint Conference Articial IntelligenceMachineClassicationMachine Learning 24Proceedings Twelfth Interna-Breiman, L. (1996). properties splitting criteria.Catlett, J. (1991). Overpruning large decision trees.Articial,(1), 4147., pp. 764769, San Mateo, CA. MorganKaufmann.Machine LearningEWSL-91: Proceedings Fifth European WorkingLecture Notes Articial IntelligenceCestnik, B., & Bratko, I. (1991). estimating probabilities tree pruning. Kodrato,SessionY. (Ed.),, Vol. 482, pp. 138150, Berlin, Hei-delberg, New York. Springer-Verlag.Annals Mathematical Statistics 23Cherno, H. (1952). measure asymptotic eciency tests hypothesis basedsum observations.,185(4), 493507.fiElomaa & KriinenProceedings Thirteenth International Joint Conference ArticialCohen, W. W. (1993).Intelligencesystems.Ecient pruning methods separate-and-conquer rule learning, pp. 988994, San Mateo, CA. Morgan Kaufmann.Machine Learning: ECML-93, ProceedingsLecture Notes Articial IntelligenceEsposito, F., Malerba, D., & Semeraro, G. (1993).Sixth European Conferencestate space. Brazdil, P. B. (Ed.),Decision tree pruning search, Vol. 667, pp.165184, Berlin, Heidelberg, New York. Springer-Verlag.IEEE Transactions Pattern Analysis Machine Intelligence 19Pruning Decision Trees ListsInformation ProcessingLetters 33Machine Learning 27Proceedings Eleventh International Joint Conference ArticialIntelligenceProceedings Thirty-Fifth AnnualIEEE Symposium Foundations Computer ScienceEsposito, F., Malerba, D., & Semeraro, G. (1997). comparative analysis methodspruning decision trees.,(5), 476491.Frank, E. (2000).. Ph.D. thesis, University Waikato,Department Computer Science, Hamilton, New Zealand.Hagerup, T., & Rb, C. (1990). guided tour Cherno bounds.,(6), 305308.Helmbold, D. P., & Schapire, R. E. (1997). Predicting nearly well best pruningdecision tree.,(1), 5168.Holte, R. C., Acker, L., & Porter, B. (1989).Concept learning problem smalldisjuncts., pp. 813818, San Mateo, CA. Morgan Kaufmann.Kamath, A., Motwani, R., Palem, K., & Spirakis, P. (1994).Tail bounds occupancysatisability threshold conjecture., pp. 592603, Los Alamitos,CA. IEEE Press.Proceedings Fifteenth Inter-Kearns, M., & Mansour, Y. (1998). fast, bottom-up decision tree pruning algorithmnational Conference Machine Learningnear-optimal generalization. Shavlik, J. (Ed.),, pp. 269277, San Francisco, CA. MorganKaufmann.LearningMalerba, D., Esposito, F., & Semeraro, G. (1996). comparison simplicationData: AI Statistics VProceedings Fourteenth International Conference Machine Learningmethods decision-tree induction. Fisher, D., & Lenz, H.-J. (Eds.),, pp. 365374, Berlin, Heidelberg, New York. Springer-Verlag.Mansour, Y. (1997). Pessimistic decision tree pruning based tree size. Fisher, D. H.(Ed.),,pp. 195201, San Francisco, CA. Morgan Kaufmann.Surveys Combinatorics: Invited Papers 12th British Combinatorial ConferenceMachine Learning 4Machine Learning 3Machine LearningMcDiarmid, C. J. H. (1989). method bounded dierences. Siemons, J. (Ed.),, pp. 148188, Cambridge, U.K. Cambridge University Press.Mingers, J. (1989a). empirical comparison pruning methods decision tree induction.,(2), 227243.Mingers, J. (1989b). empirical comparison selection measures decision-tree induction.Mitchell, T. M. (1997).,(4), 319342.. McGraw-Hill, New York.186fiAn Analysis Reduced Error PruningMotwani, R., & Raghavan, P. (1995).New York.Randomized Algorithms. Cambridge University Press,Research Development Expert Systems IIINiblett, T., & Bratko, I. (1986). Learning decision rules noisy domains. Bramer, M. A.(Ed.),, pp. 2534, Cambridge, UK.Cambridge University Press.Proceedings Fourteenth International ConferenceOates, T., & Jensen, D. (1997). eects training set size decision tree complexity.Machine LearningFisher, D. H. (Ed.),, pp. 254261, San Francisco, CA. Morgan Kaufmann.Oates, T., & Jensen, D. (1998). Large datasets lead overly complex models: expla-Proceedings Fourth International Conference Knowledge Discovery DataMiningProceedings Sixteenth National Conference Articial Intelligencenation solution.Agrawal, R., Stolorz, P., & Piatetsky-Shapiro, G. (Eds.),, pp. 294298, Menlo Park, CA. AAAI Press.Oates, T., & Jensen, D. (1999).Toward theoretical understandingdecision tree pruning algorithms fail., pp. 372378, Menlo Park, CA/Cambridge, MA. AAAIPress/MIT Press.Proceedings Twelfth International Conference MachineMachineOliver, J. J., & Hand, D. J. (1995). pruning averaging decision trees. Prieditis, A.,LearningLearning 5& Russell, S. (Eds.),, pp. 430437, San Francisco, CA. Morgan Kaufmann.Pagallo, G., & Haussler, D. (1990). Boolean feature discovery empirical learning.,(1), 7199.Machine Learning 36Pereira, F., & Singer, Y. (1999). ecient extension mixture techniques predictiondecision trees.,(3), 183199.Machine Learning 1International Journal Man-MachineC4.5: Programs Machine LearningAnnals ProbabilityQuinlan, J. R. (1986). Induction decision trees.Studies 27Quinlan, J. R. (1987).,,, 81106.Simplifying decision trees.(3), 221248.Quinlan, J. R. (1993)..Morgan Kaufmann, SanSlud, E. V. (1977). Distribution inequalities binomial law.,Mateo, CA.5(3), 404412.187fiJournal Artificial Intelligence Research 15 (2001) 351-381Submitted 9/00; published 11/01Experiments Infinite-Horizon, Policy-Gradient EstimationJonathan BaxterJBAXTER @ WHIZBANG . COMWhizBang! Labs.4616 Henry Street Pittsburgh, PA 15213Peter L. BartlettBARTLETT @ BARNHILLTECHNOLOGIES . COMBIOwulf Technologies.2030 Addison Street, Suite 102, Berkeley,CA 94704Lex WeaverL EX .W EAVER @ ANU . EDU . AUDepartment Computer ScienceAustralian National University , Canberra 0200, AustraliaAbstractpaper, present algorithms perform gradient ascent average reward partially observable Markov decision process (POMDP). algorithms based GPOMDP,algorithm introduced companion paper (Baxter & Bartlett, 2001), computes biasedestimates performance gradient POMDPs. algorithms chief advantagesuses one free parameter fi 2 [0; 1), natural interpretation terms bias-variancetrade-off, requires knowledge underlying state, applied infinite state,control observation spaces. show gradient estimates produced GPOMDPused perform gradient ascent, traditional stochastic-gradient algorithm,algorithm based conjugate-gradients utilizes gradient information bracket maximaline searches. Experimental results presented illustrating theoretical results BaxterBartlett (2001) toy problem, practical aspects algorithms numberrealistic problems.1. IntroductionFunction approximation necessary avoid curse dimensionality associated largescale dynamic programming reinforcement learning problems. dominant paradigmuse function approximate state (or state action) values. algorithms seekminimize form error approximate value function true value function,usually simulation (Sutton & Barto, 1998; Bertsekas & Tsitsiklis, 1996).multitude empirical successes approach (for example, Samuel, 1959; Tesauro, 1992,1994; Baxter, Tridgell, & Weaver, 2000; Zhang & Dietterich, 1995; Singh & Bertsekas, 1997),weak theoretical guarantees performance policy generated approximatevalue function. particular, guarantee policy improve approximatevalue function trained; fact performance degrade even function class containsapproximate value function whose corresponding greedy policy optimal (see Baxter & Bartlett,2001, Appendix A, simple two-state example).alternative technique received increased attention recently policy-gradientapproach parameters stochastic policy adjusted direction gradientperformance criterion (typically either expected discounted reward average reward).c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBAXTERET AL .key problem compute performance gradient conditions partial observabilityexplicit model system available.question addressed large body previous work (Barto, Sutton, & Anderson,1983; Williams, 1992; Glynn, 1986; Cao & Chen, 1997; Cao & Wan, 1998; Fu & Hu, 1994;Singh, Jaakkola, & Jordan, 1994, 1995; Marbach & Tsitsiklis, 1998; Marbach, 1998; Baird &Moore, 1999; Rubinstein & Melamed, 1998; Kimura, Yamamura, & Kobayashi, 1995; Kimura,Miyazaki, & Kobayashi, 1997). See introduction (Baxter & Bartlett, 2001) discussionhistory policy-gradient approaches. existing algorithms rely existenceidentifiable recurrent state order make updates gradient estimate, variancealgorithms governed recurrence time state. cases recurrence timelarge (for instance state space large), situations partial observabilitystate cannot reliably identified, need seek alternatives requireaccess state.Motivated considerations, Baxter Bartlett (2001, 2000) introduced analysedGPOMDPan algorithm generating biased estimate gradient average rewardgeneral Partially Observable Markov Decision Processes (POMDPs) controlled parameterizedstochastic policies. chief advantages GPOMDP requires single sample pathunderlying Markov chain, uses one free parameter fi 2 ; , naturalinterpretation terms bias-variance trade-off, requires knowledge underlyingstate.specifically, suppose 2 R K parameters controlling POMDP. example,could parameters approximate neural-network value-function generates stochasticpolicy form randomized look-ahead, could parameters approximate Qfunction used stochastically select controls1 . Let denote average reward POMDPparameter setting . GPOMDP computes approximation rfi r based singlecontinuous sample path underlying Markov chain. accuracy approximationcontrolled parameter fi 2 ; , one show[0 1)()[0 1)()()r() = filimr ():!1 fitrade-off preventing choosing fi arbitrarily close 1 variance GPOMDPs estimates rfi scale =fi 2 . However, bright side, also shown biasrfi (measured krfir k) proportional fi suitable mixingtime Markov chain underlying POMDP (Bartlett & Baxter, 2000a). Thus rapidlymixing POMDPs (for small), estimates performance gradient acceptablebias variance obtained.Provided rfi sufficiently accurate approximation r fact, rfi needwithin r small adjustments parameters direction rfi guarantee improvement average reward . case, gradient-based optimization algorithmsusing rfi gradient estimate guaranteed improve average rewardstep. Except case table-lookup, value-function based approaches reinforcement learning cannot make guarantee.paper present conjugate-gradient ascent algorithm uses estimates rfiprovided GPOMDP. Critical successful operation algorithm novel line search()()90()1 (1 )() ()()()(1)()()()()()()1. Stochastic policies strictly necessary framework, policy must differentiable sense() exists.r352fiP OLICY-G RADIENT E STIMATIONsubroutine brackets maxima relying solely upon gradient estimates. largely avoidsproblems associated finding maximum using noisy value estimates. Since parametersupdated accumulating sufficiently accurate estimates gradient direction, referapproach off-line algorithm. approach essentially allows us take stochasticgradient optimization problem treat non-stochastic optimization problem, thus enablinguse large body accumulated heuristics algorithmic improvements associatedmethods. also present traditional, on-line stochastic gradient ascent algorithmbased GPOMDP updates parameters every time step. algorithm essentiallyalgorithm proposed (Kimura et al., 1997).off-line on-line algorithms applied variety problems, beginning simple3-state Markov decision process (MDP) controlled linear function true gradientexactly computed. show rapid convergence gradient estimates rfi truegradient, case large range values fi . simple system ableillustrate vividly bias/variance tradeoff associated selection fi . compareperformance off-line on-line approaches applied finding good policy MDP.off-line algorithm reliably finds near-optimal policy less 100 iterations Markovchain, order magnitude faster on-line approach. attributedaggressive exploitation gradient information off-line method.Next demonstrate effectiveness off-line algorithm training neural networkcontroller control puck two-dimensional world. task case reliablynavigate puck starting configuration arbitrary target location minimumtime, applying discrete forces x directions. Although on-line algorithmtried problem, convergence considerably slower able reliablyfind good local optimum.third experiment, use off-line algorithm train controller call admissionqueueing problem treated (Marbach, 1998). case near-optimal solutions found within2000 iterations underlying queue, 1-2 orders magnitude faster experimentsreported (Marbach, 1998) on-line (stochastic-gradient) algorithms.fourth final experiment, off-line algorithm used reliably train switchedneural-network controller two-dimensional variation classical mountain-car task (Sutton & Barto, 1998, Example 8.2).rest paper organized follows. Section 2 introduce POMDPs controlledstochastic policies, assumptions needed algorithms apply. GPOMDP describedSection 3. Section 4 describe off-line on-line gradient-ascent algorithms, includinggradient-based line-search subroutine. Experimental results presented Section 5.()2.POMDPs Controlled Stochastic Policiespartially observable, Markov decision process (POMDP) consists state space , observationspace control space U . state 2 deterministic reward r . Althoughresults Baxter Bartlett (2001) guarantee convergence GPOMDP casefinite (but continuous U ), algorithm applied regardless naturerestrict cardinality , U .Consider first case discrete , U . control u 2 U determines stochasticmatrix P upij u giving transition probability state state j (i; j 2 ).()( ) = [ ( )]353fiBAXTERET AL .state 2 , observation 2 generated independently according probability distributionobservations . denote probability . randomized policysimply function mapping observations probability distributions controls U .is, observation 2 , distribution controls U . Denote probabilitycontrol u given observation u .continuous ; U , pij u becomes kernel kij u giving probability densitytransitions j , becomes probability density function density ,becomes probability density function U u density u.randomized policy corresponds Markov chain state transitionsgenerated first selecting observation state according distribution , selecting control U according distribution , finally generating transition state jaccording probability pij U .present dealing fixed POMDP. parameterize POMDP parameterize policies, becomes function ; set parameters 2 R K ,well observation . Markov chain corresponding state transition matrixPpij givenpij EY (i) EU (;Y ) pij U :(1)()=()()()()()()()()()()( )( )( )( ) = [ ( )]( )=( )Note policies purely reactive memoryless choice action basedupon current observation. experiments described present paper use purely reactivepolicies. Aberdeen Baxter (2001) extended GPOMDP techniques presentpaper controllers internal state.following technical assumptions required operation GPOMDP.Assumption 1. derivatives,exist, ratios@u (; y);@k( ) fififififi @u ;fifi@kfiu (; y)uniformly bounded B < 1, u 2 U , 2 , 2 R Kk= 1; : : : ; K .second part assumption needed ratio appears GPOMDP algorithm. allows zero-probability actions u ;ru ; also zero, caseset =. See Section 5 examples policies satisfying requirement.( )=00 0=0Assumption 2. magnitudes rewards,states i.( )jr(i)j, uniformly bounded R < 1deterministic rewards, condition represents restriction infinite state spaces.However, results present paper apply bounded stochastic rewards, case rexpectation reward state i.()()Assumption 3. P ; 2 R K , unique stationary distributionsatisfying balance equations:()P () = ():354() = [1 (; : : : ; n()],fiP OLICY-G RADIENT E STIMATIONAssumption 3 ensures that, parameters , Markov chain forms single recurrent class.Since finite-state Markov chain always ends recurrent class, propertiesclass determine long-term average reward, assumption mainly convenienceinclude recurrence class quantifier theorems. Observeepisodic problems, minimization time goal state, may modeled waysatisfies Assumption 3 simply resetting agent upon reaching goal state backinitial starting distribution states. Examples described Section 5.average reward simply expected reward stationary distribution :()()() =()nXi=1()r(i):(2)Assumption 3, also equal expected long-term average reward received starting state i:fi!1 TX1 r(X )fififi X0 =() = lim Efi!1t=0:expectation sequences states X0 ; : : : ; XT 1 state transitions generatedP (note expectation independent starting state i).()3. GPOMDP Algorithm(Algorithm 1) algorithm computing biased estimateaverage reward r . satisfiesGPOMDP()gradientlim = rfi ();!1rfi() (fi 2 [0; 1)) approximation r() satisfyingr() = filimr ();!1 fi(Baxter & Bartlett, 2001, Theorems 2, 5). Note GPOMDP relies upon single sample pathPOMDP. Also, require knowledge transition probability matrix P ,observation process ; requires knowledge randomized policy , particularability compute gradient probability chosen control divided probabilitychosen control.cannot set fi arbitrarily close GPOMDP, since variance estimate proportional =fi 2 . However, bright side, also shown bias rfi(measured krfi r k) proportionalfi suitable mixing timeMarkov chain underlying POMDP (Bartlett & Baxter, 2000a). Assumption 3, regardlessinitial starting state, distribution states converges stationary distributionagent following policy ; . Standard Markov chain theory shows rateconvergence exponential, loosely speaking, mixing time time constantexponential decay.1 (1)()()1()(1 )()()( )355fiBAXTERET AL .(fi; T; ) ! RKAlgorithm 1 GPOMDP1: Given:fi 2 [0; 1).> 0.Parameters 2 RK .Randomized policy (; ) satisfying Assumption 1.POMDP rewards satisfying Assumption 2, controlled (; )generates stochastic matrices P2:3:4:5:6:7:8:9:10:11:() satisfying Assumption 3.Arbitrary (unknown) starting state X0 .=0=0=01Set z00(z0 ; 0 2 RK ).Observe Yt (generated according observation distribution Xt )Generate control Ut according ; YtObserve r Xt+1 (where next state Xt+1 generated according pXt Xt+1( )rUt (; Yt )Set zt+1 = fizt +Ut (; Yt )Set t+1 = + r (Xt+1 )zt+1end=Treturn()( )(Ut )).Thus fi natural interpretation terms bias/variance trade-off: small values figive lower variance estimates , higher bias expectation may farr , whereas values fi close yield small bias correspondingly larger variance.Fortunately, problems mix rapidly (small ), fi small still yield reasonablebias. bias/variance trade-off vividly illustrated experiments Section 5; see (Bartlett& Baxter, 2000a) detailed theoretical discussion bias/variance question.()14. Stochastic Gradient Ascent Algorithmssection introduces two approaches exploiting gradient estimates produced GPOMDP:1. off-line approach based traditional conjugate-gradient optimization techniques employing novel line-search mechanism cope noise GPOMDPs estimates,2. on-line stochastic optimization approach uses core update GPOMDP (rupdate parameters every iteration POMDP.356(Xt )zt )fiP OLICY-G RADIENT E STIMATION4.1 Off-line optimization average reward()()()biased noisy estimates gradient average reward rcontrolled parameterized stochastic policies. straightforward algorithm findinglocal maxima would compute current parameter settings ,modify. Provided close enough true gradient direction r ,provided step-sizes suitably decreasing, standard stochastic optimization theory tells ustechnique converge local maximum . However, given computationrequires many iterations POMDP guarantee suitably accurate gradient estimates(that is, general needs large), would like aggressively exploit informationcontained simply adjusting parameters small amount direction.two techniques making better use gradient information widely usednon-stochastic optimization: better choice search direction better choice step size. Better search directions found employing conjugate-gradient directions rather puregradient direction. Better step sizes usually obtained performing kind line-searchfind local maximum search direction, use second order methods. Sinceline-search techniques tend robust departures quadraticity optimizationsurface, consider (however, see Baxter & Bartlett, 2001, Section 7.3,discussion second-order derivatives may computed GPOMDP-like algorithm).CONJPOMDP, described Algorithm 2, version Polak-Ribiere conjugate-gradientalgorithm (see, e.g. Fine, 1999, Section 5.5.2) designed operate using noisy (andpossibly) biased estimates gradient objective function (for example, estimatesprovided GPOMDP). argument GRAD CONJPOMDP computes gradient estimate.novel feature CONJPOMDP GSEARCH, linesearch subroutine uses gradient information find local maximum search direction. use gradient information ensures GSEARCH robust noise performance estimates. CONJPOMDPGSEARCH applied stochastic optimization problem noisy (and possibly)biased gradient estimates available.argument s0 CONJPOMDP provides initial step-size GSEARCH. argumentprovides stopping condition; kGRAD k2 falls , CONJPOMDP terminates.GPOMDP generatesPOMDPs()+()()()()()()()4.2 GSEARCH algorithmkey successful operation CONJPOMDP linesearch algorithm GSEARCH (Algorithm 3). GSEARCH uses gradient information bracket maximum direction ,quadratic interpolation jump maximum.found use gradients bracket maximum far robust use functionvalues. illustrate so, Figure 1 plotted stylized view average rewardalong search direction (labeled f figure), gradient directionr (labeled grad(f )). two ways could search direction bracketmaximum direction (at case), one using function valuesusing gradient estimates:()()()0( )( )1. Find three points 1 ; 2 ; 3 , lying direction , 1 < 23 < 2 . Assuming overshooting, know maximum must lie 1( )( )357fiBAXTERAlgorithm 21: Given:(CONJPOMDP GRADGRADET AL .; ; s0 ; ): RK ! RK : (possibly noisy biased) estimate gradient objec-tive function maximized.2:3:4:5:6:7:8:9:10:11:12:Starting parameters 2 R K (set maximum return).Initial step size s0> 0.Gradient resolution .g = h = GRAD()kg k2(; ; h; s0 ; )= GRAD()= ( g) =kgk2h = + hh < 0h=endg=GSEARCH GRADend3 use three points quadratic interpolation estimate locationmaximum.( )0( )02. Find two points 1 2 r 1 > r 2 < , usequadratic interpolation (which corresponds linear interpolation gradients) estimatelocation maximum.approaches equally satisfactory provided noise either functionestimates , gradient estimates r . However, estimates ravailable simulation, necessarily noisy situation looklike Figure 2. case use gradients bracket maximum becomes desirable,line-search technique based value estimates could choose peaksplot f noise location maximum, occur nearly uniformly along x-axis,whereas second technique based gradients would choose zero-crossingsnoisy gradient plot, far closer true maximum2 . illustrated Figure 3.Another view phenomenon regardless variance estimates ,variance1 2 approaches (the maximum possible) 1 approaches 2 . Thus,reliably bracket maximum using noisy estimates need able reducevariance estimates 1 2 close. case means running simulation()()()()+sign[ ( )( )]()1()2. implicit assumption argument noise processes gradient value estimatesapproximately magnitude. variance value estimates considerably smaller variancegradient estimates would expect bracketing values superior. experiments foundgradient bracketing superior.358fiP OLICY-G RADIENT E STIMATION2fgrad(f)1.510.50-0.5-1-1.5-2-2.5-1-0.5Figure 1: Stylized plot average reward.00.51() gradient r() search direction2.5f + noisegrad(f) + noise21.510.50-0.5-1-1.5-2-2.5-1-0.500.51Figure 2: Plot Figure 1 estimation noise added function gradientcurves.estimates derived longer longer periods time. contrast, variancer 1 (and r 2 ) independent distance 1 2 ,particular grow two points approach one another.One disadvantage using gradient estimates bracket possible detect extremeovershooting maximum. However, avoided using value estimates sanitysign ( )sign ( )359fiBAXTERET AL .10.50-0.5fgrad(f)-1-1-0.500.51Figure 3: Plot possible maximum locations would found line-search algorithmbased value estimates (f ), one based gradient estimates (grad(f )), curvesFigure 2. zero-crossings case possible locations. Notegradient-based approach accurately localizes maximum.check determine value dropped dramatically, suitably adjusting searchoccurs.Algorithm 3, lines 525 bracket maximum finding parameter setting0GRAD > , second parameter setting + 0 s+GRAD + < . reason rather expressions provide robustnesserrors estimates GRAD . also prevents algorithm stepping 1local maximum direction . Note use used CONJPOMDPdetermine terminate due small gradient (line 4 CONJPOMDP).Provided signs gradients bracketing points + show maximum quadratic defined points lies them, line 27 jump maximum.Otherwise algorithm simply jumps midpoint + .( )( )()= +04.3 On-line optimization average reward:= +OLPOMDPcombined GSEARCH operates iteratively choosing uphill directionssearching local maximum chosen direction. GRAD argument CONJPOMDPGPOMDP, optimization involve many iterations underlying POMDP parameter updates.traditional stochastic optimization one typically uses algorithms update parametersevery iteration, rather accumulating gradient estimates many iterations. Algorithm 4,OLPOMDP, presents adaptation GPOMDP form. See Bartlett Baxter (2000b)proof OLPOMDP converges vicinity local maximum . Note OLPOMDPsimilar algorithms proposed Kimura et al. (1995, 1997).CONJPOMDP()360fiP OLICY-G RADIENT E STIMATIONAlgorithm 31: Given:(GSEARCH GRADGRAD; 0 ; ; s0 ; ): RK ! RK : (possibly noisy biased) estimate gradient objec-tive function.2:3:4:5:6:7:8:9:10:11:12:13:14:15:2 RK (set maximum return).Search direction 2 RK GRAD(0 ) > 0.Starting parameters 0Initial step size s0> 0.= 0.Inner product resolution >= s0= 0 += GRAD()< 0Step back bracket maximum:repeats+ =p+ == s=2= 0 += GRAD()>=sp =elseStep forward bracket maximum:18:repeat16:17:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:=sp == 2s= 0 += GRAD()<s+ =p+ =endp > 0 p+ < 0= p ps++ spelse= +2 s+end0 = 0 +361fiBAXTERET AL .(fi; T; 0 ) ! RK .Algorithm 4 OLPOMDP1: Given:fi 2 [0; 1).> 0.Initial parameter values 0 2 RK .Randomized parameterized policies (; ): 2 RK satisfying Assumption 1.POMDP rewards satisfying Assumption 2, controlled (; )() satisfying Assumption 3.Step sizes t; = 0; 1; : : : satisfying P = 1 P t2 < 1.generates stochastic matrices P2:3:4:5:6:7:8:Arbitrary (unknown) starting state X0 .=0=0Set z0(z0 2 RK ).Observe Yt (generated according Xt ).Generate control Ut according ; YtObserve r Xt+1 (where next state Xt+1 generated according pXt Xt+11( )rUt (; Yt )Set zt+1 = fizt +Ut (; Yt )Set t+1 = + r (Xt+1 )zt+1( )( )(Ut ).end10: return9:5. Experimentssection present several sets experimental results. Throughout section,refer CONJPOMDP mean CONJPOMDP GPOMDP GRAD argument.first set experiments, consider system controller used selectactions 3-state Markov Decision Process (MDP). system able computetrue gradient exactly using matrix equationr() = 0()rP () P () + e0 () 1 r;()()()()(3)P transition matrix underlying Markov chain controllers parametersset , 0 stationary distribution corresponding P (written row vector), e 0square matrix row stationary distribution, r (column) vectorrewards (see Baxter & Bartlett, 2001, Section 3, derivation (3)). Hence compareestimates generated GPOMDP true gradient r , function numberiterations function discount parameter fi . also optimize performancecontroller using on-line algorithm, OLPOMDP, off-line algorithm CONJPOMDP.CONJPOMDP reliably converges near optimal policy around 100 iterations MDP,on-line method requires approximately 1000 iterations. contrasted362()fiP OLICY-G RADIENT E STIMATIONOriginStateBBCCDestination State ProbabilitiesActiona1a2a1a2a1a2BC0.00.00.80.20.00.00.80.20.00.00.80.20.20.80.20.80.20.8Table 1: Transition probabilities three-state MDPr(A) = 0r(B ) = 0r(C ) = 112 2 (A) = 61 (A) = 18181261 (B ) = 18 2 (B ) = 181 (C ) = 185 2 (C ) = 185Table 2: Three-state rewards features.TD(1)training linear value-function system using(Sutton, 1988), shownconverge value function whose one-step lookahead policy suboptimal (Weaver & Baxter,1999).second set experiments, consider simple puck-world problem smallpuck must navigated around two-dimensional world applying thrust x directions.train 1-hidden-layer neural-network controller puck using CONJPOMDP.controller reliably converges near optimality.third set experiments use CONJPOMDP optimize admission thresholdscall-admission problem considered (Marbach, 1998).final set experiments use CONJPOMDP train switched neural-network controller two-dimensional variant mountain-car task (Sutton & Barto, 1998, Example8.2).experiments found convergence line-searches greatly improvedcalls GPOMDP algorithm seeded random number sequence.5.1 three-state MDPsection consider three-state MDP, state choice two actionsa1 a2 . Table 1 shows transition probabilities function states actions.state x associated two-dimensional feature vector (x) = (1 (x); 2 (x)) reward r (x)detailed Table 2. Clearly, optimal policy always select action leadsstate C highest probability, Table 1 means always selecting action a2 .rather odd choice feature vectors states ensures value function linearfeatures trained usingobserving optimal policywill implementsuboptimal greedy one-step lookahead policy (see (Weaver & Baxter, 1999) proof). Thus,TD(1)363fiBAXTERET AL .TD(1)contrast gradient based approach, system,training linear value functionguaranteed produce worse policy starts observing optimal policy.5.1.1 RAININGCONTROLLERgoal learn stochastic controller system implements optimal (or nearoptimal) policy. Given parameter vector1 ; 2 ; 3 ; 4 , generate policy follows.state x, let=()s1 (x) := 1 1 (x) + 2 2 (x)s2 (x) := 3 1 (x) + 4 2 (x):probability choosing action a1 state x givenes1 (x)a1 (x) = s1 (x) s2 (x) ;e+eprobability choosing action a2 givenes2 (x)a2 (x) = s1 (x) s2 (x) = 1 a1 (x):e+er (x)ratios aai(x) needed Algorithms 1 4 given by,ra1 (x) = es2 (x) [ (x); (x); (x); (x)](4)212a1 (x)es1 (x) + es2 (x) 1ra2 (x) = es1 (x) [ (x); (x); (x); (x)](5)1212a2 (x)es1 (x) + es2 (x)Since second two components r= always negative first two, showstwo parameters redundant case: could well set 3 = 14 = 2 .5.1.2 G RADIENTESTIMATES= [1 1 1 1][0 1)parameter vector3; ; ; , GPOMDP used generate estimatesrfi , various values fi 2 ; . measure progress towards true gradientr, r calculated (3) value angle rrk recorded. angles relative errors plotted Figures 4, 5relative error kkrk6.graphs illustrate typical trade-off GPOMDP algorithm: small values fi givehigher bias estimates, larger values fi give higher variance (the final biasshown Figure 6 norm deviation small measure angulardeviation). bias introduced fi < small system. worst case,fi: , final gradient direction indistinguishable true direction relativekdeviation krkr.k := 0017 7%3. initial values parameter vector chosen similar results. Note [1; 1; 1; 1] generatessuboptimal policy.364fiP OLICY-G RADIENT E STIMATION160beta=0.0140140120120Angle (degrees)Angle (degrees)16010080604020beta=0.41008060402000-20-201101001000 10000 100000 1e+06 1e+07110100Markov Chain Iterations (T)160beta=0.8140140120120Angle (degrees)Angle (degrees)1601000 10000 100000 1e+06 1e+07Markov Chain Iterations (T)10080604020beta=0.951008060402000-20-20110100 1000 10000 100000 1e+06 1e+07Markov Chain Iterations (T)110100 1000 10000 100000 1e+06 1e+07Markov Chain Iterations (T)Figure 4: Angle true gradient r estimate three-state Markovchain, various values discount parameter fi . generated Algorithm 1.Averaged 500 independent runs. Note higher variance large largervalues fi . Error bars one standard deviation.5.1.3 RAININGVIA CONJUGATE - GRADIENT ASCENTGPOMDP GRAD argument used train parameterscontroller described previous section. Following low bias observed experimentsprevious section, argument fi GPOMDP set . small amount experimentation, arguments s0 CONJPOMDP set:respectively. Nonevalues critical, although extremely large initial step-size (s0 ) considerably reducetime required controller converge near-optimality.tested performance CONJPOMDP range values argumentGPOMDP. Since GSEARCH uses GPOMDP determine sign innerproduct gradient search direction, need run GPOMDP manyiterations CONJPOMDP does. Thus, GSEARCH determined parameter GPOMDPfollows. Initially, (somewhat arbitrarily) value within GSEARCH set =value used CONJPOMDP (or 1 value CONJPOMDP less 10). GSEARCHcalled GPOMDP obtain estimate gradient direction. < (desired search direction) doubled GSEARCH called generate newestimate . procedure repeated > , doubled four times.still negative end process, GSEARCH searched local maximumdirection , number iterations used CONJPOMDP doubled nextiteration (the conclusion direction generated overly noisy estimatesGPOMDP).CONJPOMDP01000 00011 40961 1036500fiBAXTER3beta=0.02.5Relative Norm DifferenceRelative Norm Difference3ET AL .21.510.5beta=0.42.521.510.5001101001000 10000 100000 1e+06 1e+07110Markov Chain Iterations (T)1000 10000 100000 1e+06 1e+074.5beta=0.8beta=0.9543Relative Norm DifferenceRelative Norm Difference3.5100Markov Chain Iterations (T)2.521.510.53.532.521.510.500110100 1000 10000 100000 1e+06 1e+07Markov Chain Iterations (T)110100 1000 10000 100000 1e+06 1e+07Markov Chain Iterations (T)kFigure 5: plot krkrthree-state Markov chain, various values discountkparameter fi . generated Algorithm 1. Averaged 500 independent runs.Note higher variance large larger values fi . Error bars one standarddeviation.Relative Norm Difference10beta=0.0beta=0.40beta=0.80beta=0.9510.10.010.001110100 1000 10000 100000 1e+06 1e+07Markov Chain Iterations (T)kFigure 6: Graph showing error estimate (as measured krkrk ) various valuesfi three-state Markov chain.generatedAlgorithm1. Notedecrease final bias fi increases. axes log scales.366fiP OLICY-G RADIENT E STIMATIONCONJGRAD Final Reward0.80.70.60.50.40.30.21101001000Markov Chain Iterations (T)10000Figure 7: Performance 3-state Markov chain controller trained CONJPOMDP function total number iterations Markov chain. performance computed exactly stationary distribution induced controller. averagereward optimal policy : . Averaged 500 independent runs. error barscomputed dividing results two separate bins depending whethermean, computing standard deviation withinbin.08()Figure 7 shows average reward final controller produced CONJPOMDP,function total number simulation steps underlying Markov chain. plots representaverageindependent runs CONJPOMDP. Note : average rewardoptimal policy. parameters controller (uniformly) randomly initialized range: ; : call CONJPOMDP. call CONJPOMDP, average rewardresulting controller computed exactly calculating stationary distributioncontroller. Figure 7, optimality reliably achieved using approximately 100 iterationsMarkov chain.50008[ 0 1 0 1]5.1.4 RAINING- LINE OLPOMDP=controller also trained on-line using Algorithm 4 (OLPOMDP) fixed step-sizes cc: ; ; ; . Reducing step-sizes form c=t tried, caused intolerablyslow convergence. Figure 8 shows performance controller (measured exactlyprevious section) function total number iterations Markov chain, differentvalues step-size c. graphs averages 100 runs, controllers weightsrandomly initialized range: ; : start run. figure, convergenceoptimal order magnitude slower achieved CONJPOMDP, beststep-size c: . Step-sizes much greater c: failed reliably converge optimalpolicy.= 0 1 1 10 100=[ 0 1 0 1]=10= 10 0367fiBAXTERET AL .0.80.80.790.78Average RewardAverage Reward0.750.70.650.60.770.760.750.740.730.720.550.71c=0.10.5101001000c=10.7100001010010000Markov Chain Iterations0.80.90.70.8Average RewardAverage RewardMarkov Chain Iterations10000.60.50.40.30.70.60.50.40.3c=100.2101001000Markov Chain Iterationsc=1000.210000101001000Markov Chain Iterations10000Figure 8: Performance 3-state Markov chain controller function number iteration steps on-line algorithm, Algorithm 4, fixed step sizes : ; ; ,.Error bars computed Figure 7.0 1 1 101005.2 Puck Worldsection, experiments described CONJPOMDP OLPOMDP usedtrain 1-hidden-layer neural-network controllers navigate small puck around two-dimensionalworld.5.2.1 W ORLDpuck unit-radius, unit-mass disk constrained move plane region 100 unitssquare. puck internal dynamics (i.e rotation). Collisions regions boundariesinelastic (tunable) coefficient restitution e (set : experiments reportedhere). puck controlled applying 5 unit force either positive negative xdirection, 5 unit force either positive negative direction, giving four differentcontrols total. control could changed every = second, simulator operatedgranularity =second. puck also retarding force due air resistance: speed2 . friction puck ground.puck given reward decision point ( = second) equaldistance puck designated target point. encourage controllerlearn navigate puck target independently starting state, puck statereset every 30 (simulated) seconds random location random x velocities range; , time target position set random location.Note size state-space example essentially infinite, orderPRECISION PRECISION floating point precision machine (bits). Thus,090 0051 101 1001 10[ 10 10]264368fiP OLICY-G RADIENT E STIMATIONtime visits recurrent state likely large. Also, puck cannot maximizeimmediate reward leads significant overshooting target locations.5.2.2CONTROLLERone-hidden-layer neural-network six input nodes, eight hidden nodes four output nodesused generate probabilistic policy similar manner controller three-stateMarkov chain example previous section. Four inputs set raw xlocations velocities puck current time-step, two differencespucks x location targets x location respectively. locationinputs scaled lie, velocity inputs scaled speedunits per second mapped value . hidden nodes computedsquashingfunction, output nodes linear. hidden output node usual additionaloffset parameter. four output nodes exponentiated normalized Markovchain example produce probability distribution four controls ( units thrust xdirection, units thrust direction). Controls selected random distribution.11011tanh555.2.3 C ONJUGATEGRADIENT ASCENTtrained neural-network controller using CONJPOMDP gradient estimates generatedGPOMDP. experimentation chose fi:; ;parameters CONJPOMDP supplied GPOMDP. GSEARCH used value fi schemediscussed Section 5.1.3 determine number iterations call GPOMDP.Due saturating nature neural-network hidden nodes (and exponentiated outputnodes), tendency network weights converge local minima infinity.is, weights would grow rapidly early simulation, towards suboptimalsolution. Large weights tend imply small gradients thus network becomes stucksuboptimal solutions. observed similar behaviour training neural networkspattern classification problems. fix problem, subtracted small quadratic penalty termkk2 performance estimates hence also small correction gradientcalculation4 .used decreasing schedule quadratic penalty weight (arrivedexperimentation). initialized : every tenth iteration CONJPOMDP,performance improved less 10% value ten iterations ago, reducedfactor 10. schedule solved nearly local minima problems, expense slowerconvergence controller.plot average reward neural-network controller shown Figure 9, functionnumber iterations POMDP. graph average 100 independent runs,parameters initialized randomly range: ; : start run. fourbad runs shown Figure 10 omitted average gave misleadingly largeerror bars.Note optimal performance (within neural-network controller class) seemsaroundproblem, due fact puck target locations reset everysimulated seconds hence fixed fraction time puck must away= 0 95= 1 000 000205[ 0 1 0 1]8304. used technique capacity control pattern classification, technique goes name weightdecay. used condition optimization problem.369fiBAXTERET AL .-5-10Average Reward-15-20-25-30-35-40-45-50-5503e+076e+079e+07Iterations1.2e+081.5e+08Figure 9: Performance neural-network puck controller function number iterations puck world, trained using CONJPOMDP. Performance estimatesgenerated simulating ;;iterations. Averaged 100 independent runs(excluding four bad runs Figure 10).1 000 000target. Figure 9 see final performance puck controller close optimal.4 100 runs CONJPOMDP get stuck suboptimal local minimum. Threecases caused overshooting GSEARCH (see Figure 10), could preventedadding extra checks CONJPOMDP.Figure 11 illustrates behaviour typical trained controller. purpose illustration, target location puck velocity randomized every 30 seconds, pucklocation.5.3 Call Admission Controlsection report results experiments CONJPOMDP applied tasktraining controller call admission problem treated Marbach (1998, Chapter 7).5.3.1 P ROBLEMcall admission control problem treated Marbach (1998, Chapter 7) models situationtelecommunications provider wishes sell bandwidth communications linkcustomers way maximize long-term average reward.Specifically, problem queuing problem. three different types call,call arrival rate ff , ff , ff , bandwidth demand b , b , baverageholding time h , h , h . arrivals Poisson distributed holding timesexponentially distributed. link maximum bandwidth 10 units. call arrivessufficient available bandwidth, service provider choose accept reject call(if enough available bandwidth call always rejected). Upon accepting call(1) (2) (3)(1) (2) (3)370(1) (2) (3)fiAverage RewardP OLICY-G RADIENT E STIMATION50-5-10-15-20-25-30-35-40-45-50-5505e+07 1e+08 1.5e+08 2e+08 2.5e+08 3e+08 3.5e+08IterationsFigure 10: Plots performance neural-network puck controller four runs (out100) converged substantially suboptimal local minima.targetFigure 11: Illustration behaviour typical trained puck controller.type m, service provider receives reward rmaximize long-term average reward.(m) units. goal service providerparameters associated call type listed Table 3. settings,optimal policy (found dynamic programming Marbach (1998)) always accept callstype 2 3 (assuming sufficient available bandwidth) accept calls type 1 available371fiBAXTERET AL .Call TypeBandwidth DemandArrival RateAverage Holding TimeRewardbffhr1121311241:8 1:6 1:40:6 0:5 0:4Table 3: Parameters call admission control problem.bandwidth least 3. policy average rewardpolicy average reward5 : .0 7840:804, always accept5.3.2 C ONTROLLER=()controller three parameters1 ; 2 ; 3 , one type call. Upon arrival calltype m, controller chooses accept call probability(1() = 1+exp(1:5(b0))b+ b(m) 10,otherwise,b currently used bandwidth. class controllers studied Marbach (1998).5.3.3 C ONJUGATEGRADIENT ASCENTused train controller, GPOMDP generating gradient estimates range values fi . influence fi performance trainedcontrollers marginal, set fi: gave lowest-variance estimates. usedvalue calls GPOMDP within CONJPOMDP within GSEARCH,varied;. controller always started parametersetting; ; (as done Marbach (1998)). value initial policy : .graph average reward final controller produced CONJPOMDP functiontotal number iterations queue shown Figure 12. performance :reliablyachieved lessiterations queue.Note optimal policy achievable controller class since incapableimplementing threshold policy always accept always reject policies.Although provably optimal, parameter setting 1 : suitably large values 23 generates something close optimal policy within controller class, averagereward : . Figure 13 shows probability accepting call type policy(with 2 3), function available bandwidth.controllers produced CONJPOMDP fi: sufficiently large essentiallyalways accept controllers average reward : , within 2% optimum achievableclass. produce policies even nearer optimal policy performance, CONJPOMDPmust keep 1 close starting value , hence gradient estimate1; 2; 3CONJPOMDP= 00= (8 8 8)1010 0000 6910 78420007508= = 15=000 7848= ( )5. discrepancy average rewards quoted Marbach (1998). probably duediscrepancy way state transitions counted, clear discussion (Marbach,1998).372fiP OLICY-G RADIENT E STIMATIONCONJGRAD Final Reward0.850.80.750.70.650.60.550.5class optimalbeta=0.00.45100010000Total Queue Iterations100000Figure 12: Performance call admission controller trained CONJPOMDP functiontotal number iterations queue. performance computed simulating controller 100,000 iterations. average reward globally optimalpolicy : , average reward optimal policy within class : ,plateau performance CONJPOMDP : . graphs averages 100independent runs.0 804080 7841Acceptance Probability0.90.80.70.60.50.40.30.2call type 1call types 2 30.101234567Available Bandwidth8910Figure 13: Probability accepting call type call admission policy nearoptimal parameters 1: ; 23. Note calls type 2 3essentially always accepted.= 75=373= 15fiBAXTERET AL .1Normalized Delta0.80.60.40.20-0.2Delta1Delta2Delta3-0.4-0.600.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9Beta1Figure 14: Plot three components call admission problem, functiondiscount parameter fi . parameters set; ; . set ; ; .Note 1 become negative (the correct sign) fi : .= (8 8 8)0 931 000 000produced GPOMDP must relatively small first component. Figure 14 shows plotnormalized function fi ,; ;(sufficiently large ensure low variance) starting parameter setting; ; . figure, 1 starts high valueexplains CONJPOMDP produces always accept controllers fi: ,become negative fi : , value variance even moderately largerelatively high.plot performance CONJPOMDP fi: fi: shown Figure15. Approximately half remaining 2% performance obtained setting fi:,fi: sufficiently large choice gives remaining performance.problem, huge difference gaining 98% optimal performance,achieved fi: less 2000 iterations queue, gaining 99% optimalrequires fi: order 500,000 queue iterations. similar convergence ratefinal approximation error latter case reported on-line algorithms Marbach(1998, Chapter 7).= 1 000 000= (8 8 8)0 93= 09= 0 95= 00= 09= 0 95=00= 095.4 Mountainous Puck Worldmountain-car task well-studied problem reinforcement learning literature (Sutton& Barto, 1998, Example 8.2). shown Figure 16, task drive car top onedimensional hill. car powerful enough accelerate directly hill gravity,successful controller must learn oscillate back forth builds enough speedcrest hill.section describe variant mountain car problem based puck-worldexample Section 5.2. reference Figure 17, problem task navigate puck374fiP OLICY-G RADIENT E STIMATION0.8050.802CONJGRAD Final RewardCONJGRAD Final Reward0.80.80.7950.790.7850.780.775100000class optimalbeta=0.901e+06Total Queue Iterations0.7980.7960.7940.7920.790.7880.7860.784class optimalbeta=0.950.7820.781e+0701e+072e+073e+07Total Queue Iterations4e+07Figure 15: Performance call admission controller trained CONJPOMDP functiontotal number iterations queue. performance calculatedsimulating controller 1,000,000 iterations. graphs averages 100independent runs.Figure 16: classical mountain-car task apply forward reverse thrust car getcrest hill. car starts bottom enough powerdrive directly hill.valley onto plateau northern end valley. mountain-car task,puck sufficient power accelerate directly hill, learn oscillateorder climb valley. able reliably train near-optimal neuralnetwork controllers problem, using CONJPOMDP GSEARCH, GPOMDPgenerating gradient estimates.5.4.1 W ORLDworld dimensions, physics, puck dynamics controls identical flat puck worlddescribed Section 5.2, except puck subject constant gravitational forceunits, maximum allowed thrust units (instead ), height world varied3537510fiBAXTERET AL .Figure 17: variant mountain-car problem task navigate puck valleyonto northern plateau. puck starts bottom valleyenough power drive directly hill.follows:8<height315(x; y) = :7:5 1 cos ( y2 50)25< 25 > 75otherwise :units thrust, unit mass puck accelerate directly valley.Every 120 (simulated) seconds, puck initialized zero velocity bottomvalley, random x location. puck given reward valleysouthern plateau, rewards2 northern plateau, speedpuck. found speed penalty helped improve rate convergence neuralnetwork controller.1005.4.2CONTROLLERexperimentation found neural-network controller could reliably trainednavigate northern plateau, stay northern plateau there, difficultcombine controller (this surprising since two tasks quite distinct).overcome problem, trained switched neural-network controller: puck used onecontroller valley southern plateau, switched second neuralnetwork controller northern plateau. controllers one-hidden-layer neuralnetworks nine input nodes, five hidden nodes four output nodes. nine inputsnormalized (; -valued) x, z puck locations, normalized x, z locations relativecenter northern wall, x, z puck velocities. four outputs usedgenerate policy fashion controller Section 5.2.2.approach requiring less prior knowledge would third controller stochastically selects base neural network controller function pucks location. master[ 1 1]376fiP OLICY-G RADIENT E STIMATION80Average Reward70605040302010002e+074e+076e+07Iterations8e+071e+08Figure 18: Performance neural-network puck controller function number iterations mountainous puck world, trained using CONJPOMDP. Performanceestimates generated simulating ;;iterations. Averaged 100independent runs.1 000 000controller could parameterized parameters trained along base controllers.5.4.3 C ONJUGATEGRADIENT ASCENTswitched neural-network controller trained using scheme discussed Section 5.2.3, except time discount factor fi set : .plot average reward neural-network controller shown Figure 18, functionnumber iterations POMDP. graph average 100 independent runs,neural-network controller parameters initialized randomly range: ; : startrun. case run failed converge near-optimal performance. figuresee pucks performance nearly optimal 40 million total iterationspuck world. Although figure may seem rather high, put perspective noterandom neural-network controller takes 10,000 iterations reach northern plateaustanding start base valley. Thus, 40 million iterations equivalent 4,000trips top random controller.Note puck converges final average performance around 75, indicatesspending least 75% time northern plateau. Observation pucks final behaviourshows behaves nearly optimally terms oscillating back forth get valley.0 98[ 0 1 0 1]5.5 Choosing fi Running Time GPOMDPOne aspect experiments required measure tuning choice fi parameter running time used GPOMDP. Although selected trial error,377fiBAXTERET AL .success recently scheme automatically choosing parameters follows.training begins, GPOMDP run large number iterations whilst simultaneouslygenerating gradient estimates number different choices fi . done singlesimulation simply maintaining separate eligibility trace zt value fi . Since biasreduces increasing fi , largest fi gives reasonably low-variance gradient estimateend long run selected reference fi (the variance estimated comparing gradientestimates reasonably well-separated intervals towards end run). Furthermore, sincevariance gradient estimate decreases fi decreases, gradient estimates values fismaller reference fi typically smaller variance reference fi . Hence,reliably compare directions smaller fi direction given reference fi ,choose smallest fi whose corresponding direction sufficiently close reference fidirection. takesufficiently close mean within .Note scheme works original run sufficiently long get low-variancedirection estimate right value fi . right value fi large fixed boundrun length made fail, problem algorithms automaticallychoose fi .suitable fi found, go back find point original long rundirection estimate corresponding value fi settled (again, measurevariance estimates sampling suitably large intervals, choose pointvariance falls chosen value). time used running time GPOMDPestimating gradient direction. Finally, running time used GPOMDP bracketingmaximum GSEARCH also automatically tuned starting initial fixed runningtime fraction , continuing sign inner product estimatesproduced GPOMDP search direction settles down. technique, signestimation time usually considerably smaller gradient direction estimation time.Another useful heuristic re-estimate fi GPOMDPs running time whenever parameters change large amount, since large change lead significant changesmixing time POMDP.10 156. Conclusionpaper showed use performance gradient estimates generated GPOMDP algorithm (Baxter & Bartlett, 2001) optimize average reward parameterized POMDPs.described traditional on-line stochastic gradient algorithm off-line approachrelied use GSEARCH, robust line-search algorithm uses gradient estimates, rathervalue estimates, bracket maximum. off-line approach particular found perform well four quite distinct problems: optimizing controller three-state MDP, optimizingneural-network controller navigating puck around two-dimensional world, optimizingcontroller call admission problem, optimizing switched neural-network controllervariation classical mountain-car task. One reason superiority off-line approachsearching local maximum step makes much aggressive usegradient information on-line algorithm.three-state MDP call-admission problems able provide graphic illustrations bias variance gradient estimates rfi traded one anothervarying fi (low variance, high bias) (high variance, low bias).01378fiP OLICY-G RADIENT E STIMATIONRelatively little tuning required generate results. addition, controllers operated direct simple representations state, contrast complex representationsusually required value-function based approaches.often case value-function methods converge much rapidly policygradient counterparts. due fact enforce constraints value-function.mind interesting avenue research Actor-Critic algorithms (Barto et al.,1983; Baird & Moore, 1999; Kimura & Kobayashi, 1998; Konda & Tsitsiklis, 2000; Sutton,McAllester, Singh, & Mansour, 2000) one attempts combine fast convergencevalue-functions theoretical guarantees policy-gradient approaches.Despite success off-line approach experiments described here, on-line algorithm advantages settings. particular, applied multi-agent reinforcementlearning, gradient computations parameter updates performed distinct agentswithout communication beyond global distribution reward signal. idea ledparameter optimization procedure spiking neural networks, successful preliminaryresults network routing (Bartlett & Baxter, 1999; Tao, Baxter, & Weaver, 2001).Acknowledgementswork supported Australian Research Council, benefited commentsseveral anonymous referees. research performed first second authors Research School Information Sciences Engineering, Australian NationalUniversity.ReferencesAberdeen, D., & Baxter, J. (2001). Policy-gradient learning controllers internal state. Tech. rep.,Australian National University.Baird, L., & Moore, A. (1999). Gradient descent general reinforcement learning. Advances NeuralInformation Processing Systems 11. MIT Press.Bartlett, P. L., & Baxter, J. (1999). Hebbian synaptic modifications spiking neurons learn. Tech.rep., Research School Information Sciences Engineering, Australian National University.http://csl.anu.edu.au/bartlett/papers/BartlettBaxter-Nov99.ps.gz.Bartlett, P. L., & Baxter, J. (2000a). Estimation approximation bounds gradient-based reinforcementlearning. Proceedings Thirteenth Annual Conference Computational Learning Theory,pp. 133141.Bartlett, P. L., & Baxter, J. (2000b). Stochastic optimization controlled partially observable markov decision processes. Proceedings 39th IEEE Conference Decision Control (CDC00).Barto, A. G., Sutton, R. S., & Anderson, C. W. (1983). Neuronlike adaptive elements solve difficultlearning control problems. IEEE Transactions Systems, Man, Cybernetics, SMC-13, 834846.Baxter, J., & Bartlett, P. L. (2000). Reinforcement learning POMDPs via direct gradient ascent.Proceedings Seventeenth International Conference Machine Learning.Baxter, J., & Bartlett, P. L. (2001). Infinite-horizon policy-gradient estimation. Journal Artificial Intelligence Research. appear.Baxter, J., Tridgell, A., & Weaver, L. (2000). Learning play chess using temporal-differences. MachineLearning, 40(3), 243263.379fiBAXTERET AL .Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.Cao, X.-R., & Chen, H.-F. (1997). Perturbation Realization, Potentials, Sensitivity Analysis MarkovProcesses. IEEE Transactions Automatic Control, 42, 13821393.Cao, X.-R., & Wan, Y.-W. (1998). Algorithms Sensitivity Analysis Markov Chains PotentialsPerturbation Realization. IEEE Transactions Control Systems Technology, 6, 482492.Fine, T. L. (1999). Feedforward Neural Network Methodology. Springer, New York.Fu, M. C., & Hu, J. (1994). Smooth Perturbation Derivative Estimation Markov Chains. OperationsResearch Letters, 15, 241251.Glynn, P. W. (1986). Stochastic approximation monte-carlo optimization. Proceedings 1986Winter Simulation Conference, pp. 356365.Kimura, H., & Kobayashi, S. (1998). analysis actor/critic algorithms using eligibility traces: Reinforcement learning imperfect value functions. Fifteenth International Conference MachineLearning, pp. 278286.Kimura, H., Miyazaki, K., & Kobayashi, S. (1997). Reinforcement learning POMDPs functionapproximation. Fisher, D. H. (Ed.), Proceedings Fourteenth International ConferenceMachine Learning (ICML97), pp. 152160.Kimura, H., Yamamura, M., & Kobayashi, S. (1995). Reinforcement learning stochastic hill climbingdiscounted reward. Proceedings Twelfth International Conference Machine Learning(ICML95), pp. 295303.Konda, V. R., & Tsitsiklis, J. N. (2000). Actor-Critic Algorithms. Neural Information Processing Systems1999. MIT Press.Marbach, P. (1998). Simulation-Based Methods Markov Decision Processes. Ph.D. thesis, LaboratoryInformation Decision Systems, MIT.Marbach, P., & Tsitsiklis, J. N. (1998). Simulation-Based Optimization Markov Reward Processes. Tech.rep., MIT.Rubinstein, R. Y., & Melamed, B. (1998). Modern Simulation Modeling. Wiley, New York.Samuel, A. L. (1959). Studies Machine Learning Using Game Checkers. IBM JournalResearch Development, 3, 210229.Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning Without State-Estimation Partially ObservableMarkovian Decision Processes. Proceedings Eleventh International Conference MachineLearning.Singh, S., & Bertsekas, D. (1997). Reinforcement learning dynamic channel allocation cellular telephone systems. Advances Neural Information Processing Systems: Proceedings 1996Conference, pp. 974980. MIT Press.Singh, S., Jaakkola, T., & Jordan, M. (1995). Reinforcement learning soft state aggregation. Tesauro,G., Touretzky, D., & Leen, T. (Eds.), Advances Neural Information Processing Systems, Vol. 7. MITPress, Cambridge, MA.Sutton, R. (1988). Learning Predict Method Temporal Differences. Machine Learning, 3, 944.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press, Cambridge MA.ISBN 0-262-19398-1.Sutton, R. S., McAllester, D., Singh, S., & Mansour, Y. (2000). Policy Gradient Methods ReinforcementLearning Function Approximation. Neural Information Processing Systems 1999. MIT Press.380fiP OLICY-G RADIENT E STIMATIONTao, N., Baxter, J., & Weaver, L. (2001). multi-agent, policy-gradient approach network routing. Tech.rep., Australian National University.Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning, 8, 257278.Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves master-level play. NeuralComputation, 6, 215219.Weaver, L., & Baxter, J. (1999). Reinforcement learning state temporal differences. Tech. rep.,Australian National University.Williams, R. J. (1992). Simple Statistical Gradient-Following Algorithms Connectionist ReinforcementLearning. Machine Learning, 8, 229256.Zhang, W., & Dietterich, T. (1995). reinforcement learning approach job-shop scheduling. Proceedings Fourteenth International Joint Conference Artificial Intelligence, pp. 11141120.Morgan Kaufmann.381fiJournal Artificial Intelligence Research 15 (2001) 319-350Submitted 9/00; published 11/01Infinite-Horizon Policy-Gradient EstimationJonathan BaxterJBAXTER @ WHIZBANG . COMWhizBang! Labs.4616 Henry Street Pittsburgh, PA 15213Peter L. BartlettBARTLETT @ BARNHILLTECHNOLOGIES . COMBIOwulf Technologies.2030 Addison Street, Suite 102, Berkeley, CA 94704AbstractGradient-based approaches direct policy search reinforcement learning receivedmuch recent attention means solve problems partial observability avoidproblems associated policy degradation value-function methods. paper introduce GPOMDP, simulation-based algorithm generating biased estimate gradientaverage reward Partially Observable Markov Decision Processes (POMDPs) controlledparameterized stochastic policies. similar algorithm proposed Kimura, Yamamura,Kobayashi (1995). algorithms chief advantages requires storage twicenumber policy parameters, uses one free parameter fi 2 [0; 1) (which natural interpretationterms bias-variance trade-off), requires knowledge underlying state. proveconvergence GPOMDP, show correct choice parameter fi relatedmixing time controlled POMDP. briefly describe extensions GPOMDP controlledMarkov chains, continuous state, observation control spaces, multiple-agents, higher-orderderivatives, version training stochastic policies internal states. companion paper(Baxter, Bartlett, & Weaver, 2001) show gradient estimates generated GPOMDPused traditional stochastic gradient algorithm conjugate-gradient procedurefind local optima average reward.1. IntroductionDynamic Programming method choice solving problems decision makinguncertainty (Bertsekas, 1995). However, application Dynamic Programming becomes problematic large infinite state-spaces, situations system dynamics unknown,state partially observed. cases one looks approximate techniquesrely simulation, rather explicit model, parametric representations either valuefunction policy, rather exact representations.Simulation-based methods rely parametric form value function tend goname Reinforcement Learning, extensively studied Machine Learningliterature (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998). approach yieldedremarkable empirical successes number different domains, including learning play checkers (Samuel, 1959), backgammon (Tesauro, 1992, 1994), chess (Baxter, Tridgell, & Weaver,2000), job-shop scheduling (Zhang & Dietterich, 1995) dynamic channel allocation (Singh &Bertsekas, 1997).Despite success, algorithms training approximate value functions suffertheoretical flaw: performance greedy policy derived approximate valuefunction guaranteed improve iteration, fact worse old policyc 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBAXTER & BARTLETTamount equal maximum approximation error states. happen evenparametric class contains value function whose corresponding greedy policy optimal.illustrate concrete simple example Appendix A.alternative approach circumvents problemthe approach pursue hereisconsider class stochastic policies parameterized 2 R K , compute gradient respectaverage reward, improve policy adjusting parameters gradientdirection. Note policy could directly parameterized, could generated indirectlyvalue function. latter case value-function parameters parameterspolicy, instead adjusted minimize error approximate true valuefunction, parameters adjusted directly improve performance policy generatedvalue function.policy-gradient algorithms long history Operations Research, Statistics, Control Theory, Discrete Event Systems Machine Learning. describing contributionpresent paper, seems appropriate introduce background material explaining approach. Readers already familiar material may want skip directly section 1.2,contributions present paper described.1.1 Brief History Policy-Gradient Algorithmslarge-scale problems problems system dynamics unknown, performancegradient computable closed form1 . Thus challenging aspect policy-gradientapproach find algorithm estimating gradient via simulation. Naively, gradientcalculated numerically adjusting parameter turn estimating effect performance via simulation (the so-called crude Monte-Carlo technique), prohibitivelyinefficient problems. Somewhat surprisingly, mild regularity conditions, turnsfull gradient estimated single simulation system. techniquecalled score function likelihood ratio method appears first proposedsixties (Aleksandrov, Sysoyev, & Shemeneva, 1968; Rubinstein, 1969) computing performancegradients i.i.d. (independently identically distributed) processes.Specifically, suppose r X performance function depends random variableX , q ; x probability X x, parameterized 2 RK . mild regularityconditions, gradient respect expected performance,( )( )may writtensee this, rewrite (1) sum=() = Er(X );(1)r() = Er(X ) rqq(;(;XX)) :(2)() =Xr() =Xr(x)q(; x);xdifferentiate (one source requirement mild regularity conditions) obtainxr(x)rq(; x);1. See equation (17) closed-form expression performance gradient.320fiP OLICY-G RADIENT E STIMATIONrewriteXr() =r(x)rq(; x) q(; x);( )q ; xxobserve formula equivalent (2).simulator available generate samples X distributed according q ; x ,sequence X1 ; X2 ; : : : ; XN generated i.i.d. according q ; x gives unbiased estimate,( )( )NXr^ () = N1 r(Xi) rqq(;(;XX)i) ;(3)^ () ! r() probability one. quantityr ( ). law large numbers, rrq(; X )=q(; X ) known likelihood ratio score function classical statistics.performance function r (X ) also depends , r (X )rq (; X )=q (; X ) replacedrr(; X ) + r(; X )rq(; X )=q(; X ) (2).=11.1.1 U NBIASED E STIMATESP ROCESSESP ERFORMANCE G RADIENTR EGENERATIVEExtensions likelihood-ratio method regenerative processes (including Markov DecisionProcesses MDPs) given Glynn (1986, 1990), Glynn LEcuyer (1995) ReimanWeiss (1986, 1989), independently episodic Partially Observable Markov DecisionProcesses (POMDPs) Williams (1992), introduced REINFORCE algorithm2 .i.i.d. samples X previous section sequences states X0 ; : : : ; XT (of random length)encountered visits designated recurrent state , sequences statesstart state goal state. case rq ; X =q ; X written sum() ()rq(; X ) = TX rpXtXt+1 () ;1q(; X )()t=0pXt Xt+1 ()(4)pXt Xt+1 transition probability Xt Xt+1 given parameters . Equation (4)admits recursive computation course regenerative cycle form z02 RK ,state transition Xt ! Xt+1 ,=0zt+1 = zt +( ) ()) ()rpXtXt+1 () ;pXt Xt+1 ()term r X rq ; X =q ; X estimate (3) form3addition, r X0 ; : : : ; XT recursively computed((5)r(X0 ; : : : ; XT )zT . If,r(X0 ; : : : ; Xt+1 ) = (r(X0 ; : : : ; Xt ); Xt+1 )function , estimate r (X0 ; : : : ; XT )zT cycle computed usingstorage K + 1 parameters (K zt 1 parameter update performance functionr). Hence, entire estimate (3) computed storage 2K + 1 real parameters,follows.2. thresholded version algorithms neuron-like elements described earlier Barto, Sutton, Anderson (1983).3. vector zT known reinforcement learning eligibility trace. terminology used Barto et al.(1983).321fiBAXTER & BARTLETTAlgorithm 1.1: Policy-Gradient Algorithm Regenerative Processes.1. Set j= 0, r = 0, z = 0, = 0 (z ; 2 RK ).0002. state transition Xt3. j0! Xt+10:episode finished (that is, Xt+1j +1j rt zt ,j j ,zt+1 ,rt+1 .= += +1=0=0Otherwise, setrp= i), setzt+1 = zt + pXXtXtXt+1() ;t+1rt+1 = (rt ; Xt+1 ).( )= N return N =N , otherwise goto 2.Examples recursiveperformance functions include sum scalar reward cycle,Pr(X0 ; : : : ; XT ) = Tt=0 r(Xt ) r(i) scalar reward associated state (this corresponds ( ) average reward multiplied expected recurrence time E [T ]);1()negative length cycle (which implemented assigning rewardstate,used task mimimize time taken get goal state, sincecasePTE ); discounted reward start state, r X0 ; : : : ; XTt=0 ff r Xt ,ff 2 ; discount factor, on.Williams (1992) pointed out, simplification possible case rTr X0 ; : : : ; XT sum scalar rewards r Xt ; depending state possibly timesince starting state (such r Xt ; r Xt , r Xt ; fft r Xt above). case,update single regenerative cycle may written[ ][0 1)(()(=TX1t=0pXt Xt+1 ()"Xs=0( )=( ))= ( ) (rpXtXt+1 ()())=)=r(Xs ; s) +Xs=t+1( )#r(Xs ; s) :()changes pXt Xt+1 influence rewards r Xs ; associated earlierstates (s t), able drop first term parentheses right-hand-sidewriteTX1rpXtXt+1 Xr X ;s :(6)ps=t+1t=0 Xt Xt+1=()()()Although proof entirely trivial, intuition indeed shown correct.Equation (6) allows even simpler recursive formula estimating performance gradient. Set z0, introduce new variable. before, set zt+1zt0rpXtXt+1 =pXtXt+1 Xt+1 6 ,zt+1otherwise.now, iteration, set t+1 r Xt ; zt. =t estimate r . Sinceupdated every iteration, suggests away altogether simply update directly: t+1 r Xt ; zt , suitable step-sizes4 . Proving convergence()P= =0()= +1== ( ) += + ( )=0=0=04. usual requirements convergence stochastic gradient algorithm > 0,1 2 < .t=01322=()P1t=0=+1,fiP OLICY-G RADIENT E STIMATIONalgorithm straightforward normal stochastic gradient algorithmsupdates r Xt zt gradient direction (in expectation), although sum updatesregenerative cycle are. Marbach Tsitsiklis (1998) provide convergence proofknow of, albeit slightly different update form t+1r Xt ; zt ,moving estimate expected performance, also updated on-line (thisupdate first suggested context POMDPs Jaakkola et al. (1995)).Marbach Tsitsiklis (1998) also considered case -dependent rewards (recall discussion (3)), Baird Moore (1999) VAPS algorithm (Value PolicySearch). last paper contains interesting insight: suitable choices performancefunction r X0 ; : : : ; XT ; , one combine policy-gradient search approximate value function methods. resulting algorithms viewed actor-critic techniques spirit Bartoet al. (1983); policy actor value function critic. primary motivationreduce variance policy-gradient estimates. Experimental evidence phenomenonpresented number authors, including Barto et al. (1983), Kimura Kobayashi(1998a), Baird Moore (1999). recent work subject includes Suttonet al. (2000) Konda Tsitsiklis (2000). discuss use VAPS-style updatesSection 6.2.far addressed question parameterized state-transition probabilities pXt Xt+1 arise. course, could simply generated parameterizing matrixtransition probabilities directly. Alternatively, case MDPs POMDPs, state transitionstypically generated feeding observation Yt depends stochastically state Xtparameterized stochastic policy, selects control Ut random set available controls (approximate value-function based approaches generate controls stochasticallyvia form lookahead also fall category). distribution successor statespXt Xt+1 Ut fixed function control. denote probability control ut givenparameters observation yt ut ; yt , discussion carriesrpXtXt+1 =pXtXt+1 replaced rUt ; Yt =Ut ; Yt . case, Algorithm 1.1 precisely Williams REINFORCE algorithm.Algorithm 1.1 variants extended cover multiple agents (Peshkinet al., 2000), policies internal state (Meuleau et al., 1999), importance sampling methods(Meuleau et al., 2000). also refer reader work Rubinstein Shapiro (1993)Rubinstein Melamed (1998) in-depth analysis application likelihood-ratiomethod Discrete-Event Systems (DES), particular networks queues. Also worth mentioninglarge literature Infinitesimal Perturbation Analysis (IPA), seeks similar goal estimating performance gradients, operates restrictive assumptions likelihoodratio approach; see, example, Ho Cao (1991).( )= + [(^( )() ^( )])()( )()(()1.1.2 B IASED E STIMATES)()()P ERFORMANCE G RADIENTalgorithms described previous section rely identifiable recurrent state , eitherupdate gradient estimate, case on-line algorithm, zero eligibility tracez . reliance recurrent state problematic two main reasons:1. variance algorithms related recurrence time visits ,typically grow state space grows. Furthermore, time visits depends323fiBAXTER & BARTLETTparameters policy, states frequently visited initial valueparameters may become rare performance improves.2. situations partial observability may difficult estimate underlying states,therefore determine gradient estimate updated, eligibility tracezeroed.system available simulation, seems difficult (if impossible) obtainunbiased estimates gradient direction without access recurrent state. Thus, solve 12, must look biased estimates. Two principle techniques introducing biasproposed, may viewed artificial truncations eligibility trace z . firstmethod takes starting point formula5 eligibility trace time t:zt =1XrpXsXs+1 ()pXs Xs+1 ()s=0simply truncates (fixed, random) number terms n looking backwards (Glynn,1990; Rubinstein, 1991, 1992; Cao & Wan, 1998):zt (n) :=1Xs=t nrpXsXs+1 () :pXs Xs+1 ()(7)(n) updated transition Xt ! Xtrp() rpXt nXt n+1 () ;zt (n) = zt (n) + XtXt+1pXt Xt+1 ()pXt n Xt n+1 ()case state-based rewards r (Xt ), estimated gradient direction steps^rn() := 1 X zt (n)r(Xt ):n+1 neligibility trace zt+1+1(8)(9)=Unless n exceeds maximum recurrence time (which infinite ergodic Markov chain),rn biased estimate gradient direction, although n ! 1, bias approaches zero.However variance rn diverges limit large n. illustrates natural trade-offselection parameter n: large enough ensure bias acceptable (theexpectation rn least within true gradient direction), largevariance prohibitive. Experimental results Cao Wan (1998) illustrate nicelybias/variance trade-off.One potential difficulty method likelihood ratios rpXs Xs+1 =pXs Xs+1must remembered previous n time steps, requiring storage Kn parameters. Thus,obtain small bias, memory may grow without bound. alternative approachrequires fixed amount memory discount eligibility trace, rather truncating it:^ ()^ ()^ ()90()zt+1 (fi ) := fizt (fi ) +rpXtXt+1 () ;pXt Xt+1 ()()(10)r5. ease exposition, kept expression z terms likelihood ratios pXs Xs+1 ()=pXs Xs+1 ()rely availability underlying state Xs . Xs available, pXs Xs+1 ()=pXs Xs+1 ()replaced Us (; Ys )=Us (; Ys ).rr324fiP OLICY-G RADIENT E STIMATION( )=0z0 fifisteps simply2 [0; 1) discount factor.r^fi () := T1TX1t=0case estimated gradient directionr(Xt )zt (fi ):(11)( ) ()(( ) )precisely estimate analyze present paper. similar estimate r Xt zt fireplaced r Xtb zt fi b reward baseline proposed Kimura et al. (1995,1997) continuous control Kimura Kobayashi (1998b). fact use r Xtbplace r Xt affect expectation estimates algorithm (although judicious choice reward baseline b reduce variance estimates). algorithmpresented Kimura et al. (1995) provides estimates expectation stationary distribution gradient discounted reward, show fact biased estimatesgradient expected discounted reward. arises stationary distributiondepends parameters. similar estimate (11) also proposed MarbachTsitsiklis (1998), time r Xt zt fi replaced r Xtzt fi ,estimate average reward, zt zeroed visits identifiable recurrent state.final note, observe eligibility traces zt fi zt n defined (10) (8)simply filtered versions sequence rpXt Xt+1 =pXt Xt+1 , first-order, infinite impulseresponse filter case zt fi n-th order, finite impulse response filter casezt n . raises question, addressed paper, whether interesting theoryoptimal filtering policy-gradient estimators.(( )( )) ()( ) ()( ( ) ^( )) ( )()()()()^( )()()1.2 Contributiondescribe GPOMDP, general algorithm based upon (11) generating biased estimateperformance gradient r general POMDPs controlled parameterized stochastic policies.denotes average reward policy parameters 2 RK . GPOMDPrely access underlying recurrent state. Writing rfi expectation estimate produced GPOMDP, showr , quantitativelyfi !1 rfirfi close true gradient provided = fi exceeds mixing time Markov chaininduced POMDP6 . truncated estimate above, trade-off preventing settingfi arbitrarily close variance algorithms estimates increase fi approaches. prove convergence probability 1 GPOMDP discrete continuous observation control spaces. present algorithms general parameterized Markov chainsPOMDPs controlled parameterized stochastic policies.several extensions GPOMDP investigated since first versionpaper written. outline developments briefly Section 7.companion paper show gradient estimates produced GPOMDP usedperform gradient ascent average reward (Baxter et al., 2001). describetraditional stochastic gradient algorithms, conjugate-gradient algorithm utilizes gradientestimates novel way perform line searches. Experimental results presented illustrat-()()()lim( )= ( )1 (1 )()11()6. mixing-time result paper applies Markov chains distinct eigenvalues. Better estimatesbias variance GPOMDP may found Bartlett Baxter (2001), general Markov chainstreated here, refined notions mixing time. Roughly speaking, variance GPOMDPgrows 1=(1 fi ), bias decreases function 1=(1 fi ).325fiBAXTER & BARTLETTing theoretical results present paper toy problem, practical aspectsalgorithms number realistic problems.2. Reinforcement Learning Problemmodel reinforcement learning Markov decision process (MDP) finite state spacef ; : : : ; ng, stochastic matrix7 P pij giving probability transition statestate j . state associated reward8 r . matrix P belongs parameterizedclass stochastic matrices, PfP 2 RK g. Denote Markov chain correspondingP . assume Markov chains rewards satisfy following assumptions:= 1()=[ ]():= ( ):()()Assumption 1. P 2 P unique stationary distributionsatisfying balance equations() := [(; 1); : : : ; (; n)]00 ()P () = 0 ()(throughout 0 denotes transpose ).Assumption 2. magnitudes rewards, jr (i)j, uniformly bounded R <states i.(12)1Assumption 1 ensures Markov chain forms single recurrent class parameters .Since finite-state Markov chain always ends recurrent class, propertiesclass determine long-term average reward, assumption mainly convenienceinclude recurrence class quantifier theorems. However,consider gradient-ascent algorithms Baxter et al. (2001), assumption becomesrestrictive since guarantees recurrence class cannot change parameters adjusted.Ordinarily, discussion MDPs would complete without mention actionsavailable state space policies available learner. particular, parameterswould usually determine policy (either directly indirectly via value function), woulddetermine transition probabilities P . However, purposes caredependence P arises, satisfies Assumption 1 (and differentiabilityassumptions shall meet next section). Note also easy extend setupcase rewards also depend parameters transitions ! j .equally straightforward extend algorithms results cases. See Section 6.1illustration.goal find 2 R K maximizing average reward:fi"#TX1fifiEr Xt fi X0 ;fi!1t=0E denotes expectation sequences X0 ; X1 ; : : : ; transitions generated according P . Assumption 1, independent starting state equalnX; r 0 r;(13)i=1()1( ) := lim()=()( )=r( )( ) ()= ( )= [r(1); : : : ; r(n)]0 (Bertsekas, 1995).P7. stochastic matrix P = [pij ] pij 0 i; j nj =1 pij = 1 i.8. results present paper apply bounded stochastic rewards, case r(i) expectationreward state i.326fiP OLICY-G RADIENT E STIMATION3. Computing Gradient Average Reward()general MDPs little known average reward , hence finding optimumproblematic. However, section see general assumptions gradientr exists, local optimization possible.ensure existence suitable gradients (and boundedness certain random variables),require parameterized class stochastic matrices satisfies following additional assumption.()()Assumption 3. derivatives,rP () :=2 RK . ratiosexist@pij ()@ki;j =1:::n;k=1:::K2 fifi @p () fifi 3ijfi @k fi45pij ()uniformly bounded Bi;j =1:::n;k=1:::K< 1 2 RK .second part assumption allows zero-probability transitions pij() = 0rpij () also zero, case set 0=0 = 0. One example ! j forbiddentransition, pij ( ) = 0 2 RK . Another example satisfying assumptionpij () == [11; : : : ; 1n ; : : : ; nn ] 2 Rn2parameters P@pij ()=@ijpij ()@pij ()=@klpij ()Assuming moment rdependencies,eijij ;j =1 ePn=1=pij ();(),pkl ():() exists (this justified shortly), then, suppressingr = r0r;(14)since reward r depend . Note convention r paper takesprecedence operations, rg frg f . Equations like (14)regarded shorthand notation K equations form( ) ( ) = [ ( )] ( )@()@kk=@(; 1)@(; n);:::;[r(1); : : : ; r(n)]0@k@k= 1; : : : ; K . compute r, first differentiate balance equations (12) obtainr0P + 0 rP = r0;327fiBAXTER & BARTLETThencer0(I P ) = 0 rP:(15)system equations defined (15) under-constrained P invertible (thebalance equations show P left eigenvector zero eigenvalue). However, let edenote n-dimensional column vector consisting s, e 0 n n matrixstationary distribution 0 row. Since r 0 e r 0 er, rewrite (15)1= ( ) = (1) = 0r0 (P e0) = 0rP:see inversewrite[I (P"lim (Ie0 )]A)!1Xt=01exists, let matrix satisfying#= Tlim!1[t=0= Tlim!1= I:Thus,(I"XA)1=1Xt=0TX+1+1t=1limt!1 = 0.#:] =0easy prove induction P e 0P eP0! 1tconverges100 . Hence, writeAssumption 1.P eexists equal 1Pet=0[()]r0 = 0rP P + e0so9r = 0rP P + e0;(16)r:(17)11MDPs sufficiently small number states, (17) could solved exactly yield precisegradient direction. However, general, state space small enough exact solution(17) possible, small enough derive optimal policy using policy iterationtable-lookup, would point pursuing gradient based approach first place10 .Thus, problems practical interest, (17) intractable need findway computing gradient. One approximate technique presentednext section.9. argument leading (16) coupled fact () unique solution (12) used justifyexistence . Specifically, run steps computing value ( + ) smallshow expression (16) unique matrix satisfying ( + ) = () + () + O( 2 ).10. Equation (17) may still useful POMDPs, since case tractable dynamic programmingalgorithm.rrr328kkfiP OLICY-G RADIENT E STIMATION4. Approximating Gradient Parameterized Markov Chainssection, show gradient split two components, one becomesnegligible discount factor fi approaches .fi 2 ; , let JfiJfi ; ; : : : ; Jfi ; n denote vector expected discountedrewards state i:[0 1)( ) = [ ( 1)Jfi (; i) := E1"( )]1Xt=0fitrfifiXt fifi X0fi( )#=i:(18)dependence obvious, write Jfi .2 [0; 1),r = (1 fi )r0 Jfi + fi0rP Jfi :Proposition 1. 2 R K fi(19)Proof. Observe Jfi satisfies Bellman equations:Jfi = r + fiP Jfi :(20)(Bertsekas, 1995). Hence,r = r0r= r0 [Jfi fiP Jfi ]= r0Jfi fi r0Jfi + fi0 rP Jfi= (1 fi )r0 Jfi + fi0rP Jfi :(15)shall see next section second term (19) estimated single sample path Markov chain. fact, Theorem 1 (Kimura et al., 1997) shows gradientestimates algorithm presented paper convergefi 0 rJfi . Bellman equations (20), equalfi fi 0 rP Jfi 0 rJfi , impliesfi 0 rJfi fi0 rP Jfi .Thus algorithm Kimura et al. (1997) also estimates second term expressionr given (19). important note 0rJfi 6 r 0 Jfi two quantities disagreefirst term (19). arises stationary distribution dependsparameters. Hence, algorithm Kimura et al. (1997) estimate gradient expected discounted reward. fact, expected discounted reward simply =fi timesaverage reward (Singh et al., 1994, Fact 7), gradient expected discounted rewardproportional gradient average reward.following theorem shows first term (19) becomes negligible fi approaches .Notice immediate Proposition 1, since Jfi become arbitrarily largelimit fi ! .(1 ) (+(1)= [])()(1 )=1 (1())11Theorem 2. 2 RK ,r = filimr ;! fi(21)rfi := 0 rP Jfi :(22)1329fiBAXTER & BARTLETTProof. Recalling equation (17) discussion preceeding it, 11r = 0rPrP e1Xe0 r:Ptt=0(23)= r(P e) = r(1) = 0 since P stochastic matrix, (23) rewrittenr = 0"1X#rP P r:t=0(24)2 [0; 1] discount factor consider expressionlet fif (fi ) := 0= lim( )=()"1Xt=0#rP (fiP )t r(25)( )=Clearly rrfi .fi !1 f fi . complete proof need show f fi0Since fiPfi P ! fi e ! , invoke observation (16) write01Xt=0Pparticular, 1t=0(25) write12(fiP )t = [I(fiP )t converges, take rP back sum right-hand-sidef (fi ) = 0 rPP1t=0fitP rfiP ] 1 := Jfi . Thus f (fi ) = 0rP Jfi"1Xt=0#fitPr:(26)= rfi .1Theorem 2 shows rfi good approximation gradient fi approaches ,turns values fi close lead large variance estimates rfidescribe next section. However, following theorem showsfi needsmall, provided transition probability matrix P distinct eigenvalues, Markovchain short mixing time. initial state, distribution states Markov chainconverges stationary distribution, provided assumption (Assumption 1) existenceuniqueness stationary distribution satisfied (see, example, Lancaster & Tismenetsky,1985, Theorem 15.8.1, p. 552). spectral resolution theorem (Lancaster & Tismenetsky, 1985,Theorem 9.5.1, p. 314) implies distribution converges stationarity exponential rate,time constant convergence rate (the mixing time) depends eigenvaluestransition probability matrix. existence unique stationary distribution implies11()11. Since e 0 r = e , (23) motivates different kind algorithm estimating based differential rewards(Marbach & Tsitsiklis, 1998).12. cannot back P sum right-hand-side (24) 1P diverges (P e 0 ). reason1 P P converges P becomes orthogonal P limit tof=0large t. Thus, view 1 Pt=0t=0sum two orthogonal components: infinite one direction e finite one direction e? .1finite component need estimate. Approximating 1t=0 P t=0 (fiP ) way renderinge-component finite hopefully altering e? -component much. substitutionslead better approximations (in context, see final paragraph Section 1.1).Prrr330PPr!PPfiP OLICY-G RADIENT E STIMATION11largest magnitude eigenvalue multiplicity , corresponding left eigenvectorstationary distribution. sort eigenvalues decreasing order magnitude,1 > j2 j > > js j n. turns j2 j determines mixing timechain.following theorem showsfi small comparedj2j, gradient approximation described accurate. Since using estimate directionupdate parameters, theorem compares directions gradient estimate.theorem, 2 denotes spectral condition number nonsingular matrix A, definedproduct spectral norms matrices 1 ,1=211( )2 (A) = kAk2 kA1k;2kAk = x maxkAxk;kxk2:=1kxk denotes Euclidean norm vector x.()Theorem 3. Suppose transition probability matrix P satisfies Assumption 1 stationary distribution 01 ; : : : ; n , n distinct eigenvalues. Letx1 x2 xnmatrix right eigenvectors P corresponding, order, eigenvalues1 > j2 jjn j. normalized inner product r fi rfi satisfies=()=(1=)kr(p ; : : : ; p )k pfi rfi1 fin1 rkr=Sr0r(27)kkrk1 fi j j ;= diag( ; : : : ; n ).Notice r 0 r expectation stationary distribution r (X ) .well mixing time (via j j), bound theorem depends another parameterMarkov chain: spectral condition number = . Markov chain reversible (which21 22121221 2implies eigenvectors x1 ; : : : ; xn orthogonal), equal ratio maximumminimum probability states stationary distribution. However, eigenvectorsneed nearly orthogonal. fact, condition transition probability matrixn distinct eigenvalues necessary; without it, condition number replacedcomplicated expression involving spectral norms matrices form P .()Proof. existence n distinct eigenvalues implies P expressed 1 ,1 ; : : : ; n (Lancaster & Tismenetsky, 1985, Theorem 4.10.2, p 153). followspolynomial f , write f PSf 1 .Now, Proposition 1 shows r fi rfi r 0fi Jfi .= diag()( ) = ()= (1 )(1 fi )Jfi = (1 fi ) r + fiP r + fi P r += (1 fi ) + fiP + fi!P + r1X= (1 fi )Sfi r22221= (1fi)nXj =1t=0xj 0331j1Xt=0(fij )!r;fiBAXTER & BARTLETT=(=)1y1 ; : : : ; yn 0 .easy verify yi left eigenvector corresponding , choosey1 x1 e. Thus write=(1fi )Jfi = (1 fi )e0 r +nXxj yj0(1!fi )(fij )t rt=0j =2nXfirxj yj0fijj =2= (1fi )e += (1fi )e + SMS 1 r;111= diag 0;11Xfi1 fi :;:::;fi21 finfollows Proposition 1fi rfir (r r0(11 rkr=1kkrk0= r r (1 fi )Jfi22fi )Jfi )krkrr0 (1 fi )e + SMS r=krk0SMS r= r rkrkr 0 SMS rkrk ;p0Since r = r0 = , apply Cauchy212121Cauchy-Schwartz inequality.Schwartz inequality obtain1 2fi rfi1 rkrkrp0= SMS1 21krk2r:(28)use spectral norms bound second factor numerator. clear definitionspectral norm product nonsingular matrices satisfies kAB k2 kAk2 kB k2 ,spectral norm diagonal matrix given kd1 ; : : : ; dn k2jdi j. follows= SMS1 21diag() = maxr = = SMS = = r= = = r kM kp= r0r 1 1 fi jfi j :1 211 21221 21 21 21 221 22Combining Equation (28) proves (27).3322fiP OLICY-G RADIENT E STIMATION5. Estimating Gradient Parameterized Markov ChainsAlgorithm 1 introduces MCG (Markov Chain Gradient), algorithm estimating approximate gradient rfi single on-line sample path X0 ; X1 ; : : : Markov chain .MCG requires K reals stored, K dimension parameter space: Kparameters eligibility trace zt , K parameters gradient estimate . Notetime steps average far r Xt zt ,()2( )TX1=zt r(Xt ):1t=0Algorithm 1 MCG (Markov Chain Gradient) algorithm1: Given:Parameter 2 R K .Parameterized class stochastic matrices P3 1.= fP (): 2 RK g satisfying Assumptionsfi 2 [0; 1).Arbitrary starting state X .State sequence X ; X ; : : :0generated ( ) (i.e. Markov chain transition()).Reward sequence r(X ); r(X ); : : : satisfying Assumption 2.Set z = 0 = 0 (z ; 2 RK ).state Xt visitedrp( )zt = fizt + XtXt+1pXt Xt+1 ()= + [r(Xt )zt ]probabilities P0102:3:4:5:6:00010+1+11+1+1+1+1endTheorem 4. Assumptions 1, 2 3, MCG algorithm starting initial state X0generate sequence 0 ; 1 ; : : : ; ; : : : satisfyinglim = rfit!1=w.p.1:(29)()Proof. Let fXt g fX0 ; X1 ; : : : g denote random process corresponding . X0entire process stationary. proof easily generalized arbitrary initial distributions using fact Assumption 1, fXt g asymptotically stationary. fXt g333fiBAXTER & BARTLETTstationary, write0 rP Jfi =X=X=Xi;ji;ji;j(i)rpij ()Jfi (j )(i)pij ()rpij () J (j )p () fiijPr(Xt = i)Pr(Xt = j jXt = i) rppij(()) E(J (t + 1)jXt = j );+1+1ijfirst probability respect stationary distributionJ (t + 1) =( ( + 1))= (1Xs=t+1fis1(30)J (t + 1) processr(Xs ):)fact E JjXt+1 Jfi Xt+1 Xt+1 follows boundednessmagnitudes rewards (Assumption 2) Lebesgues dominated convergence theorem.rewrite Equation (30)Xrp ()0 rP Jfi = E (Xt )j (Xt+1 ) ij J (t + 1) ;pij ()i;j() denotes indicator function state i,(1 Xt = i;(Xt ) :=0 otherwise;expectation respect stationary distribution. Xt chosen accordingstationary distribution, process fXt g ergodic. Since process fZt g definedZt := (Xt )j (Xt+1 )rpij () J (t + 1)pij ()obtained taking fixedfXt g, fZt g also stationary ergodic (Breiman, 1966,fi functionfifi rpij () fiProposition 6.31). Since fi pij () fi bounded Assumption 3, ergodic theorem(almost surely):0 rP JfiTX1rp ()= Tlim(Xt )j (Xt ) ij J (t + 1)!1pij ()i;jTXrpXtXt+1 () J (t + 1)1= Tlim!1pXtXt+1 ()"TX1XrpXtXt+1 () X1= Tlimfi r(Xs ) +!1pXtXt+1 ()X1+1=01=011=0= +1334= +1#fis1r(Xs ) :(31)fiP OLICY-G RADIENT E STIMATIONConcentrating second term right-hand-side (31), observe that:fifi TX1fififiT1t=0rpXtXt+1 ()pXt Xt+1 ()1Xfiss=T +1TX1 fifi1fifi1fifiXs fififir()pXt Xt+1 ()t=01BR TX1 X= BR1XrpXtXt+1 () fififit=0 s=T +1TX1fit=01fisfis=T +1fis1jr(Xs)j1fi1 fiT= BRfi(1 fi )2! 0 ! 1;jrp jR B bounds magnitudes rewards pijij Assumptions 23. Hence,TX1rpXtXt+1 X0 rP Jfi(32)fi 1 r Xs :!1pXXt+1t=0s=t+1Unrolling equation MCG algorithm shows equal()()= lim 11 TX rpXtXt+1 () XpXt Xt+1 ()1=0hencefis( )1r(is );= +1! 0rP Jfi w.p.1 required.6. Estimating Gradient Partially Observable Markov Decision Processes()Algorithm 1 applies parameterized class stochastic matrices P compute gradients rpij . section consider special case P ariseparameterized class randomized policies controlling partially observable Markov decision process (POMDP). partially observable qualification means assume policiesaccess observation process depends state, general may see state.Specifically, assume N controls Uf ; : : : ; N g observationsf ; : : : ; g. u 2 U determines stochastic matrix P u dependparameters . state 2 , observation 2 generated independently accordingprobability distribution observations . denote probability observation. randomized policy simply function mapping observations 2 probabilitydistributions controls U . is, observation , distributioncontrols U . Denote probability control u given observation u .randomized policy observation distribution corresponds Markovchain state transitions generated first selecting observation state according()= 11()()=()()()()()335()fiBAXTER & BARTLETT()()distribution , selecting control u according distribution , generating transition state j according probability pij u . parameterize chainsparameterize policies, becomes function ; set parameters 2 R Kwell observation . Markov chain corresponding state transition matrix pijgiven()( )[ ( )]pij () = EY (i) EU (;Y ) pij (U ):Equation (33) impliesrpij () =X(33)(i)pij (u)ru (; y):u;y(34)Algorithm 2 introduces GPOMDP algorithm (for Gradient Partially Observable MarkovDecision Process), modified form Algorithm 1 updates zt based Ut ; Yt ,rather pXt Xt+1 . Note Algorithm 2 require knowledge transition probability matrix P , observation process ; requires knowledge randomizedpolicy . GPOMDP essentially algorithm proposed Kimura et al. (1997) withoutreward baseline.algorithm GPOMDP assumes policy function current observation.immediate algorithm works finite history observations. general,optimal policy needs function entire observation history. GPOMDP extendedapply policies internal state (Aberdeen & Baxter, 2001).(())Algorithm 2 GPOMDP algorithm.1: Given:Parameterized class randomized policies(; ) : 2 RKsatisfying Assumption 4.Partially observable Markov decision process controlled randomizedpolicies ; corresponds parameterized class Markov chains satisfying Assumption 1.( )fi 2 [0; 1).Arbitrary (unknown) starting state X .Observation sequence ; ; : : : generated POMDP controls U ; U ; : : :0010(; Yt).generated randomly according2:3:4:5:6:( ) ( )Reward sequence r X0 ; r X1 ; : : : satisfying Assumption 2,(hidden) sequence states Markov decision process.=0=0= + (( ))= + [ ( )Set z00(z0 ; 0 2 RK ).observation Yt , control Ut , subsequent reward rrUt ; Ytzt+1 fiztUt ; Yt1t+1t+1 r Xt+1 zt+1end]336(Xt )+1X0 ; X1 ; : : :1fiP OLICY-G RADIENT E STIMATIONconvergence Algorithm 2 need replace Assumption 3 similar boundgradient :Assumption 4. derivatives,exist u 2 U ,@u (; y)@k2 2 RK . ratiosfi2 fifi@u (;y) fi 3fi @fik45u (; y)uniformly bounded By=1:::M ;u=1:::N ;k=1:::K< 1 2 RK .Theorem 5. Assumptions 1, 2 4, Algorithm 2 starting initial stategenerate sequence 0 ; 1 ; : : : ; ; : : : satisfyinglim = rfiw.p.1:t!1X0(35)Proof. proof follows lines proof Theorem 4. case,0 rP Jfi ====Xi;j(i)rpij ()Jfi (j )Xi;j;y;uXi;j;y;uXi;j;y;u(i)pij (u)y (i)ru (; y)Jfi (j ) (34)(i)pij (u)y (i)ru (; y) (; y)J (j );fi(; y) uuEZt0;expectation respect stationary distribution fXt g, process fZt0 gdefinedru ; J ;Zt0 Xt j Xt+1 u Ut Ytu ;:= ( ) () ( ) ( ) (( )) ( + 1)Ut control process Yt observation process. result followsarguments used proof Theorem 4.6.1 Control dependent rewardsmany circumstances rewards may depend controls u.example, controls may consume energy others may wish add penaltyterm reward function order conserve energy. simplest way dealdefine state expected reward r( )r(i) = EY (i) EU (;Y ) r(U; i);337(36)fiBAXTER & BARTLETTredefine Jfi terms r:Jfi (; i) :=lim E"N !1NXt=0fifiXt fifi X0fi( )fitr#=i;(37)X0 ; X1 ; : : : . performance gradient becomesr = r0r + 0rr;expectation trajectoriesapproximatedrfi = 0 rP Jfi + rr ;due fact Jfi satisfies Bellman equations (20) r replaced r .GPOMDP take account dependence r controls, fifth linereplaced1= + + 1 r(Ut+1rUt+1 (; Yt ); Xt ) zt +:(; )+1+1+1+1Ut+1t+1straightforward extend proofs Theorems 2, 3 5 setting.6.2 Parameter dependent rewardspossible modify GPOMDP rewards depend directly . case,fifth line GPOMDP replaced= + +1 1 [r(; Xt )zt + rr(; Xt ) t] :+1+1+1(38)+1( )Again, convergence approximation theorems carry through, provided rr ; uniformly bounded. Parameter-dependent rewards considered Glynn (1990), MarbachTsitsiklis (1998), Baird Moore (1999). particular, Baird Moore (1999) showedsuitable choices r ; lead combination value policy search, VAPS.example, J ; approximate value-function, setting13( )~( )h1~~r(; Xt ; Xt ) =2 r(Xt ) + ffJ (; Xt ) J (; Xt ) ;r (Xt ) usual reward ff 2 [0; 1) discount factor, gives update seeks211minimize expected Bellman errornXi=12(; i) 4r(i) + ffnXj =132pij ()J~(; j ) J~(; i)5 :(39)~( )effect minimizing Bellman error J ; , driving system(via policy) states small Bellman error. motivation behind approachunderstood one considers J zero Bellman error states. case greedypolicy derived J optimal, regardless actual policy parameterized,expectation zt r ; Xt ; Xt 1 zero gradient computed GPOMDP.kind update known actor-critic algorithm (Barto et al., 1983), policy playingrole actor, value function playing role critic.(~13. use rewards r(; Xt ; Xtanalysis.~)1 ) depend current previous338state substantially alterfiP OLICY-G RADIENT E STIMATION6.3 Extensions infinite state, observation, control spacesconvergence proof Algorithm 2 relied finite state (S ), observation (Y ) control (U )spaces. However, clear modification Algorithm 2 applied immediately POMDPs countably uncountably infinite , countable U .changes pij u becomes kernel p x; x0 ; u becomes density observations.addition, appropriate interpretation r=, applied uncountable U . Specifically, U subset R N y; probability density function U u y;density u. U subsets Euclidean space (but finite set), Theorem 5extended show estimates produced algorithm converge almost surely rfi .fact, prove general result implies case densities subsets R Nwell finite case Theorem 5. allow U general spaces satisfying followingtopological assumption. (For definitions see, example, (Dudley, 1989).)()()()( )( )Assumption 5. control space U associated topology separable, Hausdorff,first-countable. corresponding Borel -algebra B generated topology,-finite measure defined measurable space U ; B . say reference measureU .Similarly, observation space topology, Borel -algebra, reference measuresatisfying conditions.()case Theorem 5, U finite, associated reference measurecounting measure. URN RM , reference measure Lebesgue measure.assume distributions ; absolutely continuous respect referencemeasures, corresponding Radon-Nikodym derivatives (probability masses finite case,densities Euclidean case) satisfy following assumption.=()=( )( )Assumption 6. every 2 2 R K , probability measure ; absolutely continuous respect reference measure U . every 2 , probability measureabsolutely continuous respect reference measure .Let reference measure U . u 2 U , 2 , 2 R K , k 2 f ; : : : ; K g,derivatives@ d(; y)(u)@kfifi @ du (;y)fi @kexist ratios< 1.1fi(u)fifidu ;y(u)(bounded B())assumptions, replace Algorithm 2 Radon-Nikodym derivativerespect reference measure U . case, following convergenceresult. generalizes Theorem 5, also applies densities Euclidean space U .Theorem 6. Suppose control space U observation space satisfy Assumption 5 letreference measure control space U . Consider Algorithm 2rUt (; Yt)Ut (; Yt )339fiBAXTER & BARTLETTreplacedr d;Yt (Ut ) :()( )d(;Yt )UtAssumptions 1, 2 6, algorithm, starting initial statesequence 0 ; 1 ; : : : ; ; : : : satisfyinglim = rfit!1X0generatew.p.1:Proof. See Appendix B7. New ResultsSince first version paper, extended GPOMDP several new settings, alsoproved new properties algorithm. section briefly outline results.7.1 Multiple AgentsInstead single agent generating actions according (; ), suppose multiple agents= 1; : : : ; na , parameter set distinct observation environmentyi , generate actions ui according policy ui (i ; yi ). agents receive reward signal r (Xt ) (they may cooperating solve task, example),GPOMDP applied collective POMDP obtained concatenating1 nobserva1na , utions, controls,parameterssinglevectors;:::;u ; : : : ; u ,1 ; : : : ; na respectively. easy calculation shows gradient estimate generatedGPOMDP collective case precisely obtained applying GPOMDP1agent independently, concatenating results. is,; : : : ; na ,estimate produced GPOMDP applied agent i. leads on-line algorithmagents adjust parameters independently without explicit communication,yet collectively adjustments maximizing global average reward. similar observations context REINFORCE VAPS, see Peshkin et al. (2000). algorithm givesbiologically plausible synaptic weight-update rule applied networks spiking neuronsneurons regarded independent agents (Bartlett & Baxter, 1999), shownpromise network routing application (Tao, Baxter, & Weaver, 2001).====7.2 Policies internal statesfar considered purely reactive memoryless policies chosen controlfunction current observation. GPOMDP easily extended cover casepolicies depend finite histories observations Yt ; Yt 1 ; : : : ; Yt k , general, optimalcontrol POMDPs, policy must function entire observation history. Fortunately,observation history may summarized form belief state (the current distributionstates), updated based upon current observation, knowledgesufficient optimal behaviour (Smallwood & Sondik, 1973; Sondik, 1978). extensionGPOMDP policies parameterized internal belief states described Aberdeen Baxter(2001), similar spirit extension VAPS REINFORCE described Meuleau et al.(1999).340fiP OLICY-G RADIENT E STIMATION7.3 Higher-Order Derivativesgeneralized compute estimates second higher-order derivativesaverage reward (assuming exist), still single sample Rpath underlying POMDP.see second-order derivatives, observeq ; x r x dx twicedifferentiable density q ; x performance measure r x ,GPOMDP()= ( )( )()Zr () = r(x) rq(q;(;x)x) q(; x) dx( )22r2 denotes matrix second derivatives (Hessian). verifiedr q(; x) = r log q(; x) + [r log q(; x)]q(; x)222(40)log ( )second term right-hand-side outer product rq ; x(that is, matrix entries @=@iq ; x @=@j q ; x ). Taking x sequencestates X0 ; X1 ; : : : ; XT visits recurrent state parameterized Markov chain (recall1pSection 1.1.1), q ; Xt=0 Xt Xt+1 , combined (40) yieldslog ( )log ( ))=()(r q(; X ) = TX r pXtXt+1 ()2q(; X )1TX12pXt Xt+1 ()t=0rpXtXt+1 () +p()2Xt Xt+1t=0"T 1XrpXtXt+1 ()#2pXtXt+1 ()t=0(the squared terms expression also outer products). expression deriveGPOMDP-like algorithm computing biased estimate Hessian r2 , involvesmaintainingin addition usual eligibility trace zt second matrix trace updated follows:()Zt+1= fiZt + rp pXtXt+1(())2Xt Xt+1rpXtXt+1 () :p( )2Xt Xt+1( ) +time steps algorithm returns average far r Xt Zt zt2 second termouter product. Computation higher-order derivatives could used second-ordergradient methods optimization policy parameters.7.4 Bias Variance Bounds()()Theorem 3 provides bound bias rfi relative r applies underlying Markov chain distinct eigenvalues. extended result arbitrary Markov chains(Bartlett & Baxter, 2001). However, extra generality comes price, since latter bound involves number states chain, whereas Theorem 3 not. paper also suppliesproof variance GPOMDP scales =fi 2 , providing formal justificationinterpretation fi terms bias/variance trade-off.1 (1)8. Conclusionpresented general algorithm (MCG) computing arbitrarily accurate approximationsgradient average reward parameterized Markov chain. chains transitionmatrix distinct eigenvalues, accuracy approximation shown controlled341fiBAXTER & BARTLETTsize subdominant eigenvalue j2 j. showed algorithm could modified applypartially observable Markov decision processes controlled parameterized stochastic policies,discrete continuous control, observation state spaces (GPOMDP). finitestate case, proved convergence probability 1 algorithms.briefly described extensions multi-agent problems, policies internal state, estimatinghigher-order derivatives, generalizations bias result chains non-distinct eigenvalues,new variance result. many avenues research. Continuous time resultsfollow extensions results presented here. MCG GPOMDP algorithmsapplied countably uncountably infinite state spaces; convergence results also neededcases.companion paper (Baxter et al., 2001), present experimental results showing rapidconvergence estimates generated GPOMDP true gradient r . give on-linevariants algorithms present paper, also variants gradient ascent make useestimates rfi . present experimental results showing effectiveness algorithmsvariety problems, including three-state MDP, nonlinear physical control problem,call-admission problem.Acknowledgementswork supported Australian Research Council, benefited commentsseveral anonymous referees. research performed authorsResearch School Information Sciences Engineering, Australian National University.Appendix A. Simple Example Policy Degradation Value-Function LearningApproximate value-function approaches reinforcement work minimizing form errorapproximate value function true value function. long knownmay necessarily lead improved policy performance new value function. includeappendix illustrates phenomenon occur simplest possible system,two-state MDP, also provides geometric intuition phenomenon arises.Consider two-state Markov decision process (MDP) Figure 1. two controlsu1 ; u2 corresponding transition probability matricesP (u1 ) =131322323; P (u2 ) =2323231313;u1 always takes system state probability = , regardless starting state (andtherefore state probability = ), u2 opposite. Since state reward ,state reward , optimal policy always select action u1 . policystationary distribution states 1 ; 2= ; = , infinite-horizon discountedvalue state; discount value ff 2 ;110=1 213[Jff (i) = E] = [1 3 2 3][0 1)1Xfft rfifiXt fifi X0fi( )=i21!;t=0expectation state sequences X0 ; X1 ; X2 ; : : : state transitions generated according P u1 . Solving Bellmans equations: Jff r ffP u1 Jff , JffJff ; Jff 02ff2ffrr ; r 0 yields JffJff.3(1 ff)3(1 ff)( )= [ (1) (2)]= + ( )(2) = 1 +(1) =342= [ (1) (2)]fiP OLICY-G RADIENT E STIMATIONr(1) = 0r(2) = 112Figure 1: Two-state Markov Decsision Process~~( ) =Now, suppose trying learn approximate value function J MDP, i.e. , Jw state ; scalar feature ( must dimensionality ensureJ really approximate). w 2 R parameter learnt. greedy policy obtainedJ optimal, J must value state state . purposes illustration choose;, J> J , w must negative.Temporal Difference learning (or) one popular techniques trainingapproximate value functions (Sutton & Barto, 1998). shown linear functions,converges parameter w minimizing expected squared loss stationarydistribution (Tsitsikilis & Van-Roy, 1997):()=1 2~~2~(2) ~(1)(1) = 2 (2) = 1TD( )TD(1)~w = argminw112Xi=1[w(i) Jff (i)]2 :(41)Substituting previous expressions 1 ; 2 ; Jff optimal policy solving3+ffw , yields w. Hence w > values ff 2 ; , wrong9(1 ff)sign. situation optimal policy implementable greedy policy basedapproximate value function class (just choose w < ), yetobservingoptimal policy converge value function whose corresponding greedy policy implementssuboptimal policy.geometrical illustration occurs shown Figure 2. figure, pointsgraphrepresentpp values states. scales state 1 state 2 axes weightedrespectively. way, squared euclidean distance graphtwo points J J corresponds expectation stationary distribution squareddifference values:=0[0 1)0(1)hpTD(1)(2)~(1)J (1);p(2)J (2)hp(1)J~(1); (2)J~(2)p22= E J (X ) J~(X ):value function shaded region, corresponding greedy policy optimal, sincevalue functions rank state 2 state 1. bold line represents set realizableapproximate value functions w ; w. solution (41) approximate valuefunction found projecting point corresponding true value function Jff ; Jffontoline. illustrated figure ff= . projection suboptimal weightedmean-squared distance value-function space take account policy boundary.( (1)(2))=3 5[( (1) (2)]Appendix B. Proof Theorem 6proof needs following topological lemma. definitions see, example, (Dudley, 1989,pp. 2425).343fiBAXTER & BARTLETT32101111111111111111000000000000000000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111[J (1), J (2)]000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111[w * (1), w * (2)]000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111Legend000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111Optimal Policy:000000000000000111111111111111000000000000000111111111111111000000000000000111111111111111Approximate000000000000000111111111111111000000000000000111111111111111Value Function:00000000000000011111111111111100000000000000011111111111111100000000000000011111111111111100000000000000011111111111111100000000000000011111111111111100000000000000011111111111111110123110000110011001145Figure 2: Plot value-function space two-state system. Note scale axisweighted square root stationary probability corresponding stateoptimal policy. solution found TD(1) simply projection truevalue function onto set approximate value functions.()Lemma 7. Let X; topological space Hausdorff, separable, first-countable.Let B Borel -algebra generated . measurable space X; B sequenceS1; S2 ; : : : B sets satisfies following conditions:(1. Si partition X (that is, Xempty intersection).2. x 2 X , fxg 2 B1\)= SfS : 2 Sig two distinct elements SifS 2 Si : x 2 g = fxg:i=1=Proof. Since X separable, countable dense subsetfx1 ; x2 ; : : :g. Since X firstcountable, xi aScountable neighbourhood base, Ni . Now, construct partitionsSi using countable set N 1; ; : : :, definei=1 Ni follows. Let S0 X and,===1 2Si = fS \ Ni : 2 Si g [ fS \ (X Ni) : 2 Si g :11344fiP OLICY-G RADIENT E STIMATIONClearly, Si measurable partition X . Since X Hausdorff, pair x; x0 distinctpoints X , pair disjoint open sets A0 x 2 x0 2 A0 . Sincedense, pair s; s0 2 s0 2 A0 . Also, N contains neighbourhoods NsNs0 Ns Ns0 A0 . Ns Ns0 disjoint. Thus, sufficiently large i, xx0 fall distinct elements partition Si . Since true pair x; x0 , follows1\fS 2 Si : x 2 g fxg:i=1reverse inclusiontrivial. measurability singletons fxg follows measuraSbility SxfS 2 Si \ fxg g fact fxg X Sx .:=:==shall use Lemma 7 together following result show approximateexpectations certain random variables using single sample path Markov chain.()Lemma 8. Let X; B measurable space satisfying conditions Lemma 7, let S1 ; S2 ; : : :suitable sequence partitions lemma. Let probability measure definedspace. Let f absolutely integrable function X . event , definef (S ) =x 2 Xalmost x X ,kRf :(S )= 1; 2; : : :, let Sk (x) unique element Sk containing x.lim f (Sk (x)) = f (x):k!1Proof. Clearly, signed finite measure defined(E ) =ZEfdabsolutely continuous respect , Equation (42) definesderivative respect . derivative also defined(42)fRadon-Nikodym(Sk (x))(x) = klim:!1 (Sk (x))See, example, (Shilov & Gurevich, 1966, Section 10.2). Radon-Nikodym Theorem (Dudley, 1989, Theorem 5.5.4, p. 134), two expressions equal a.e. ().Proof. (Theorem 6.) definitions,rfi = 0 rP Jfi=n XnXi=1 j =1(i)rpij ()Jfi (j ):(43)every , absolutely continuous respect reference measure , hencej writeZ Zd(; y)pij () =pij (u)(u) d(u) (i)(y):U345fiBAXTER & BARTLETTSince dependintegral obtainrpij () =d(; y)=d absolutely integrable,Z ZUpij (u) rd(; y)(u) d(u) (i)(y):avoid cluttering notation, shall use denote distributiondenote distribution . notation,()rpij () =differentiateZ ZUpij(; y) U ,rd:Now, let probability measure U generated . write (43)rfi =Xi;j(i)Jfi (j )ZYUpijrd:Using notation Lemma 8, definepij (S ) =Rpij ;(S )Z1r(S ) = (S ) rdd d;measurable setU . Notice that, given i, j , ,pij (S ) = Pr(Xt+1 = j jXt = i; (y; u) 2 )fi!firr(S ) = E dd fififi Xt = i; (Yt ; Ut ) 2 :Let S1 ; S2 ; : : : sequence partitions U Lemma 7, let Skelement Sk containing y; u . Using Lemma 8,( )ZYUpijZr=lim pij (Sk (y; u)) r (Sk (y; u)) d(y; u)YU k!1= klim!1(y; u) denoteX Z2Skpij (S ) r(S ) d;346fiP OLICY-G RADIENT E STIMATIONused Assumption 6 Lebesgue dominated convergence theorem interchangeintegral limit. Hence,rfi = klim!1= klim!1X Xi;j 2SkXi;j;S(i)(S )pij (S )Jfi (j )r(S )Pr(Xt = i)Pr((Yt ; Ut ) 2 )Pr(Xt = j jXt = i; (Yt ; Ut ) 2 )+1fiE (J (t + 1)jXt+1= klim!1Xi;j;S"fir= j ) E dd fififi Xt = i; (Yt; Ut ) 2!#E i(Xt )S (Yt; Ut )j (Xt )J (t + 1) rdd ;+1probabilities expectations respect stationary distribution Xt ,distributions Yt ; Ut . Now, random process inside expectation asymptotically stationaryergodic. ergodic theorem, (almost surely)X TXr1rfi = klimlim(Xt )S (Yt ; Ut )j (Xt )J (t + 1) dd :!1 !11+1i;j;S t=0easy see double limit also exists order reversed,TXXr1rfi = Tlimlim i(Xt )S (Yt ; Ut )j (Xt )J (t + 1) dd!1k!111= Tlim!1t=0TX1t=0+1i;j;S(;Yt )r Utd(;Yt ) U( ) J (t + 1):( )argument proof Theorem 4 shows tailsfififi r d(;Yt ) U fififififi d(;Yt)fifiUJ (t + 1) ignored( )( )jr (Xt )j uniformly bounded. follows ! 0 rP Jfi w.p.1, required.ReferencesAberdeen, D., & Baxter, J. (2001). Policy-gradient learning controllers internal state. Tech.rep., Australian National University.Aleksandrov, V. M., Sysoyev, V. I., & Shemeneva, V. V. (1968). Stochastic optimaization. Engineering Cybernetics, 5, 1116.Baird, L., & Moore, A. (1999). Gradient descent general reinforcement learning. AdvancesNeural Information Processing Systems 11. MIT Press.347fiBAXTER & BARTLETTBartlett, P. L., & Baxter, J. (1999). Hebbian synaptic modifications spiking neurons learn.Tech. rep., Research School Information Sciences Engineering, Australian NationalUniversity. http://csl.anu.edu.au/bartlett/papers/BartlettBaxter-Nov99.ps.gz.Bartlett, P. L., & Baxter, J. (2001). Estimation approximation bounds gradient-based reinforcement learning. Journal Computer Systems Sciences, 62. Invited Paper: SpecialIssue COLT 2000.Barto, A. G., Sutton, R. S., & Anderson, C. W. (1983). Neuronlike adaptive elements solvedifficult learning control problems. IEEE Transactions Systems, Man, Cybernetics,SMC-13, 834846.Baxter, J., Bartlett, P. L., & Weaver, L. (2001). Experiments infinite-horizon, policy-gradientestimation. Journal Artificial Intelligence Research. appear.Baxter, J., Tridgell, A., & Weaver, L. (2000). Learning play chess using temporal-differences.Machine Learning, 40(3), 243263.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.Bertsekas, D. P. (1995). Dynamic Programming Optimal Control, Vol II. Athena Scientific.Breiman, L. (1966). Probability. Addison-Wesley.Cao, X.-R., & Wan, Y.-W. (1998). Algorithms Sensitivity Analysis Markov ChainsPotentials Perturbation Realization. IEEE Transactions Control Systems Technology,6, 482492.Dudley, R. M. (1989). Real Analysis Probability. Wadsworth & Brooks/Cole, Belmont, California.Glynn, P. W. (1986). Stochastic approximation monte-carlo optimization. Proceedings1986 Winter Simulation Conference, pp. 356365.Glynn, P. W. (1990). Likelihood ratio gradient estimation stochastic systems. CommunicationsACM, 33, 7584.Glynn, P. W., & LEcuyer, P. (1995). Likelihood ratio gradient estimation regenerative stochasticrecursions. Advances Applied Probability, 27, 4 (1995), 27, 10191053.Ho, Y.-C., & Cao, X.-R. (1991). Perturbation Analysis Discrete Event Dynamic Systems. KluwerAcademic, Boston.Jaakkola, T., Singh, S. P., & Jordan, M. I. (1995). Reinforcement Learning Algorithm PartiallyObservable Markov Decision Problems. Tesauro, G., Touretzky, D., & Leen, T. (Eds.),Advances Neural Information Processing Systems, Vol. 7. MIT Press, Cambridge, MA.Kimura, H., & Kobayashi, S. (1998a). analysis actor/critic algorithms using eligibility traces:Reinforcement learning imperfect value functions. Fifteenth International ConferenceMachine Learning, pp. 278286.348fiP OLICY-G RADIENT E STIMATIONKimura, H., & Kobayashi, S. (1998b). Reinforcement learning continuous action using stochastic gradient ascent. Intelligent Autonomous Systems (IAS-5), pp. 288295.Kimura, H., Miyazaki, K., & Kobayashi, S. (1997). Reinforcement learning POMDPsfunction approximation. Fisher, D. H. (Ed.), Proceedings Fourteenth InternationalConference Machine Learning (ICML97), pp. 152160.Kimura, H., Yamamura, M., & Kobayashi, S. (1995). Reinforcement learning stochastic hillclimbing discounted reward. Proceedings Twelfth International ConferenceMachine Learning (ICML95), pp. 295303.Konda, V. R., & Tsitsiklis, J. N. (2000). Actor-Critic Algorithms. Neural Information ProcessingSystems 1999. MIT Press.Lancaster, P., & Tismenetsky, M. (1985). Theory Matrices. Academic Press, San Diego, CA.Marbach, P., & Tsitsiklis, J. N. (1998). Simulation-Based Optimization Markov Reward Processes. Tech. rep., MIT.Meuleau, N., Peshkin, L., Kaelbling, L. P., & Kim, K.-E. (2000). Off-policy policy search. Tech.rep., MIT Artificical Intelligence Laboratory.Meuleau, N., Peshkin, L., Kim, K.-E., & Kaelbling, L. P. (1999). Learning finite-state controllerspartially observable environments. Proceedings Fifteenth International ConferenceUncertainty Artificial Intelligence.Peshkin, L., Kim, K.-E., Meuleau, N., & Kaelbling, L. P. (2000). Learning cooperate via policysearch. Proceedings Sixteenth International Conference Uncertainty ArtificialIntelligence.Reiman, M. I., & Weiss, A. (1986). Sensitivity analysis via likelihood ratios. Proceedings1986 Winter Simulation Conference.Reiman, M. I., & Weiss, A. (1989). Sensitivity analysis simulations via likelihood ratios. Operations Research, 37.Rubinstein, R. Y. (1969). Problems Monte Carlo Optimization. Ph.D. thesis.Rubinstein, R. Y. (1991). optimize complex stochastic systems single sample pathscore function method. Annals Operations Research, 27, 175211.Rubinstein, R. Y. (1992). Decomposable score function estimators sensitivity analysis optimization queueing networks. Annals Operations Research, 39, 195229.Rubinstein, R. Y., & Melamed, B. (1998). Modern Simulation Modeling. Wiley, New York.Rubinstein, R. Y., & Shapiro, A. (1993). Discrete Event Systems. Wiley, New York.Samuel, A. L. (1959). Studies Machine Learning Using Game Checkers. IBMJournal Research Development, 3, 210229.349fiBAXTER & BARTLETTShilov, G. E., & Gurevich, B. L. (1966). Integral, Measure Derivative: Unified Approach.Prentice-Hall, Englewood Cliffs, N.J.Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning Without State-Estimation PartiallyObservable Markovian Decision Processes. Proceedings Eleventh InternationalConference Machine Learning.Singh, S., & Bertsekas, D. (1997). Reinforcement learning dynamic channel allocation cellular telephone systems. Advances Neural Information Processing Systems: Proceedings1996 Conference, pp. 974980. MIT Press.Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observable Markovdecision processes finite horizon. Operations Research, 21, 10711098.Sondik, E. J. (1978). optimal control partially observable Markov decision processesinfinite horizon: Discounted costs. Operations Research, 26.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge MA. ISBN 0-262-19398-1.Sutton, R. S., McAllester, D., Singh, S., & Mansour, Y. (2000). Policy Gradient MethodsReinforcement Learning Function Approximation. Neural Information ProcessingSystems 1999. MIT Press.Tao, N., Baxter, J., & Weaver, L. (2001). multi-agent, policy-gradient approach networkrouting. Tech. rep., Australian National University.Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning, 8, 257278.Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves master-levelplay. Neural Computation, 6, 215219.Tsitsikilis, J. N., & Van-Roy, B. (1997). Analysis Temporal Difference Learning Function Approximation. IEEE Transactions Automatic Control, 42(5), 674690.Williams, R. J. (1992). Simple Statistical Gradient-Following Algorithms Connectionist Reinforcement Learning. Machine Learning, 8, 229256.Zhang, W., & Dietterich, T. (1995). reinforcement learning approach job-shop scheduling.Proceedings Fourteenth International Joint Conference Artificial Intelligence, pp.11141120. Morgan Kaufmann.350fiJournal Artificial Intelligence Research 15 (2001) 207-261Submitted 5/00; published 9/01Planning RewritingJose Luis AmbiteCraig A. Knoblockambite@isi.eduknoblock@isi.eduInformation Sciences Institute Department Computer Science,University Southern California,4676 Admiralty Way, Marina del Rey, CA 90292, USAAbstractDomain-independent planning hard combinatorial problem. Taking accountplan quality makes task even difficult. article introduces Planning Rewriting (PbR), new paradigm efficient high-quality domain-independent planning. PbRexploits declarative plan-rewriting rules efficient local search techniques transformeasy-to-generate, possibly suboptimal, initial plan high-quality plan. addition addressing issues planning efficiency plan quality, framework offersnew anytime planning algorithm. implemented planner appliedseveral existing domains. experimental results show PbR approach providessignificant savings planning effort generating high-quality plans.1. IntroductionPlanning process generating network actions, plan, achieves desiredgoal initial state world. Many problems practical importancecast planning problems. Instead crafting individual planner solve specificproblem, long line research focused constructing domain-independent planningalgorithms. Domain-independent planning accepts input, descriptionsinitial state goal particular problem instance, also declarative domainspecification, is, set actions change properties state. Domainindependent planning makes development planning algorithms efficient, allowssoftware domain reuse, facilitates principled extension capabilitiesplanner. Unfortunately, domain-independent planning (like planning problems)computationally hard (Bylander, 1994; Erol, Nau, & Subrahmanian, 1995; Backstrom& Nebel, 1995). Given complexity limitations, previous work domainindependent planning focused finding solution plan without careful considerationplan quality. Usually simple cost functions, length plan,used. However, many practical problems plan quality crucial. paperpresent new planning paradigm, Planning Rewriting (PbR), addressesplanning efficiency plan quality maintaining benefits domain independence.framework fully implemented present empirical results several planningdomains.c2001AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiAmbite & Knoblock1.1 Solution ApproachTwo observations guided present work. first one two sourcescomplexity planning:Satisfiability: difficulty finding solution planning problem (regardlessquality solution).Optimization: difficulty finding optimal solution given cost metric.given domain, facets may contribute differently complexityplanning. particular, many domains satisfiability problemrelatively easy complexity dominated optimization problem. example,may many plans would solve problem, finding one efficientpractice, cost solution varies greatly, thus finding optimal onecomputationally hard. refer domains optimization domains.optimization domains great practical interest query optimization manufacturingprocess planning.1second observation planning problems great deal structure. Planstype graph strong semantics, determined general propertiesplanning particular domain specification. structureexploited improve efficiency planning process.Prompted previous observations, developed novel approach efficientplanning optimization domains: Planning Rewriting (PbR). framework workstwo phases:1. Generate initial solution plan. Recall optimization domains efficient.However, quality initial plan may far optimal.2. Iteratively rewrite current solution plan improving quality using set declarative plan-rewriting rules, either acceptable solution found resourcelimit reached.motivation, consider optimization domains distributed query processingmanufacturing process planning.2 Distributed query processing (Yu & Chang, 1984) involves generating plan efficiently computes user query data residesdifferent nodes network. query plan composed data retrieval actions diverseinformation sources operations data (such relational algebra:join, selection, etc). systems use general-purpose planner solve problem(Knoblock, 1996). domain easy construct initial plan (any parsequery suffices) transform using gradient-descent search reduce cost.plan transformations exploit commutative associative properties (relational algebra) operators, facts group operators executedtogether remote information source generally efficient so. Figure 11. Interestingly, one widely studied planning domains, Blocks World, also property.2. domains analyzed Section 4. Graphical examples rewriting process appear Figure 30query planning Figure 21 manufacturing process planning. reader may want consultfigures even details explained point.208fiPlanning Rewritingshows sample transformations. Simple-join-swap transforms two join trees according commutative associative properties join operator. Remote-join-evalexecutes join two subqueries remote source, source able so.Simple-Join-Swap:retrieve(Q1, Source1) 1 [retrieve(Q2, Source2) 1 retrieve(Q3, Source3)]retrieve(Q2, Source2) 1 [retrieve(Q1, Source1) 1 retrieve(Q3, Source3)]Remote-Join-Eval:(retrieve(Q1, Source) 1 retrieve(Q2, Source)) capability(Source, join)retrieve(Q1 1 Q2, Source)Figure 1: Transformations Query Planningmanufacturing, problem find economical plan machining operationsimplement desired features design. feature-based approach (Nau, Gupta,& Regli, 1995), possible enumerate actions involved building pieceanalyzing CAD model. difficult find ordering operationssetups optimize machining cost. However, similar query planning, possibleincrementally transform (possibly inefficient) initial plan. Often, order actionsaffect design goal, quality plan, thus many actions commute.Also, important minimize number setups fixing piece machinerather time consuming operation. Interestingly, grouping machining operationssetup analogous evaluating subquery remote information source.suggested examples, many problems combine characteristics traditional planning satisfiability quality optimization. domainsoften exist natural transformations may used efficiently obtain high-quality plansiterative rewriting. Planning Rewriting provides domain-independent frameworkallows plan transformations conveniently specified declarative plan-rewritingrules facilitates exploration efficient (local) search techniques.1.2 Advantages Planning Rewritingseveral advantages planning style PbR introduces. First, PbRdeclarative domain-independent framework. facilitates specification planningdomains, evolution, principled extension planner new capabilities. Moreover, declarative rewriting rule language provides natural convenientmechanism specify complex plan transformations.Second, PbR accepts sophisticated quality measures operates completeplans. previous planning approaches either addressed quality issuessimple quality measures, number steps plan, partialplans available planning process. general, partial plan cannot offerenough information evaluate complex cost metric and/or guide planning searcheffectively.209fiAmbite & KnoblockThird, PbR use local search methods remarkably successful scalinglarge problems (Aarts & Lenstra, 1997).3 using local search techniques, high-qualityplans efficiently generated. Fourth, search occurs space solution plans,generally much smaller space partial plans explored planners basedrefinement search.Fifth, framework yields anytime planning algorithm (Dean & Boddy, 1988).planner always solution offer point computation (modulo initialplan generation needs fast). clear advantage traditional planningapproaches, must run completion producing solution. Thus, systemallows possibility trading planning effort plan quality. example, queryplanning quality plan execution time may make sense keepplanning cost current plan small enough, even cheaper one couldfound. discussion concrete examples advantages given throughoutfollowing sections.1.3 Contributionsmain contribution paper development Planning Rewriting, noveldomain-independent paradigm efficient high-quality planning. First, define language declarative plan-rewriting rules present algorithms domain-independentplan rewriting. rewriting rules provide natural convenient mechanism specify complex plan transformations. techniques plan rewriting generalize traditionalgraph rewriting. Graph rewriting rules need specify rule consequent completeembedding replacement subplan. introduce novel class partially-specifiedplan-rewriting rules relax restriction. taking advantage semanticsplanning, embedding automatically computed. single partially-specified ruleconcisely represent great number fully-specified rules. rules also easierwrite understand fully-specified counterparts. Second, adapt localsearch techniques, gradient descent, efficiently explore space plan rewritings optimize plan quality. Finally, demonstrate empirically usefulnessPbR approach several planning domains.1.4 Outlineremainder paper structured follows. Section 2 provides backgroundplanning, rewriting, local search, fields upon PbR builds. Section 3presents basic framework Planning Rewriting domain-independent approachlocal search. section describes detail plan rewriting declarative rewriting rulelanguage. Section 4 describes several application domains shows experimental resultscomparing PbR planners. Section 5 reviews related work. Finally, Section 6summarizes contributions paper discusses future work.3. Although space rewritings explored complete search methods, application domainsanalyzed search space large experience suggests local searchappropriate. However, extent complete search methods useful Planning Rewritingframework remains open issue. paper focus local search.210fiPlanning Rewriting2. Preliminaries: Planning, Rewriting, Local Searchframework Planning Rewriting arises confluence several areas research, namely, artificial intelligence planning algorithms, graph rewriting, local searchtechniques. section give background areas explainrelate PbR.2.1 AI Planningassume reader familiar classical AI planning, sectionhighlight main concepts relate PbR framework. Weld (1994, 1999)Russell & Norvig (1995) provide excellent introductions AI planning.PbR follows classical AI planning representation actions transform state.state set ground propositions understood conjunctive formula. PbR,AI planners, follows Closed World Assumption, is, proposition explicitlymentioned state assumed false, similarly negation failure semanticslogic programming. propositions state modified, asserted negated,actions domain. actions domain specified operator schemas.operator schema consists two logical formulas: precondition, definesconditions operator may applied, postcondition, specifieschanges state effected operator. Propositions mentionedpostcondition assumed change application operator. typerepresentation initially introduced STRIPS system (Fikes & Nilsson, 1971).language operators PbR Sage (Knoblock, 1995, 1994b),extension UCPOP (Penberthy & Weld, 1992). operator descriptionlanguage PbR accepts arbitrary function-free first-order formulas preconditionsoperators, conditional universally quantified effects (but disjunctive effects).addition, operators specify resources use. Sage PbR address unitnon-consumable resources. resources fully acquired operatorcompletion action released reused.Figure 2 shows sample operator schema specification simple Blocks Worlddomain,4 representation accepted PbR. domain two actions: stack,puts one block top another, unstack, places block table.5state described two predicates: (on ?x ?y)6 denotes block ?x topanother block ?y (or Table), (clear ?x) denotes ?x blockblock top it.example complex operator process manufacturing domain shownFigure 3. operator describes behavior punch, machine usedmake holes parts. punch operation requires available clampmachine orientation width hole appropriate using punch.executing operation part desired hole also4. illustrate basic concepts planning, use examples simple Blocks World domain.reader find real-world application planning techniques, query planning, Section 4.4.5. (stack ?x ?y ?z) read stack block ?x top block ?y ?z.(unstack ?x ?y) read lift block ?x top block ?y put Table.6. convention, variables preceded question mark symbol (?), ?x.211fiAmbite & Knoblock(define (operator STACK):parameters (?X ?Y ?Z):precondition(:and (on ?X ?Z) (clear ?X) (clear ?Y)(:neq ?Y ?Z) (:neq ?X ?Z) (:neq ?X ?Y)(:neq ?X Table) (:neq ?Y Table)):effect (:and (on ?X ?Y) (:not (on ?X ?Z))(clear ?Z) (:not (clear ?Y))))(define (operator UNSTACK):parameters (?X ?Y):precondition(:and (on ?X ?Y) (clear ?X) (:neq ?X ?Y)(:neq ?X Table) (:neq ?Y Table)):effect (:and (on ?X Table) (clear ?Y)(:not (on ?X ?Y))))Figure 2: Blocks World Operators(define (operator PUNCH):parameters (?x ?width ?orientation):resources ((machine PUNCH) (is-object ?x)):precondition (:and (is-object ?x)(is-punchable ?x ?width ?orientation)(has-clamp PUNCH)):effect (:and (:forall (?surf) (:when (:neq ?surf ROUGH)(:not (surface-condition ?x ?surf))))(surface-condition ?x ROUGH)(has-hole ?x ?width ?orientation)))Figure 3: Manufacturing Operatorrough surface.7 Note specification resources slot. Declaring (machine PUNCH)resource enforces operator use punch concurrently. Similarly,declaring part, (is-object ?x), resource means one operation timeperformed object. examples operator specifications appearFigures 18, 19, 28.plan PbR represented graph, spirit partial-order causal-link planners (POCL) UCPOP (Penberthy & Weld, 1992). nodes plan steps,is, instantiated domain operators. edges specify temporal ordering relation amongsteps imposed causal links ordering constraints. causal link recordproposition established plan. record contains proposition (sometimes alsocalled condition), producer step, consumer step. producer stepplan asserts proposition, is, proposition one effects. consumerstep needs proposition, is, proposition one preconditions.causality, producer must precede consumer.ordering constraints needed ensure plan consistent. ariseresolving operator threats resource conflicts. operator threat occursstep negates condition causal link ordered producerconsumer steps causal link. prevent situation, makes plan inconsistent, POCL planners order threatening step either producer (demotion)consumer (promotion) posting appropriate ordering constraints.7. operator uses idiom combining universal quantification negated conditional effects enforceattribute surface-condition part single-valued.212fiPlanning Rewritingunit non-consumable resources considered, steps requiring resourcesequentially ordered, chain ordering constraints appear plan.example plan Blocks World using graph representation givenFigure 4. plan transforms initial state consisting two towers: C A,Table, B D, Table; final state consisting one tower: B, B C,C D, Table. initial state represented step 0 preconditionspropositions initial state postconditions. Similarly, goal staterepresented step goal postconditions goal formula precondition.plan achieves goal using two unstack steps disassemble two initial towersusing three stack steps build desired tower. causal links shownsolid arrows ordering constraints dashed arrows. additional effects stepused causal links, sometimes called side effects, shown steppointed thin dashed arrows. Negated propositions preceded . Note needordering link steps 2, stack(B C Table), 3, stack(A B Table).step 3 could ordered concurrently step 2, would negate preconditionclear(B) step 2, making plan inconsistent. similar situation occurs steps1 2 another ordering link introduced.clear(B)Causal LinkOrdering ConstraintSide Effecton(A Table)on(C A)clear(A)3 STACK(A B Table)4 UNSTACK(C A)on(C Table)on(C A)clear(C)on(D Table)on(A Table)clear(B)clear(C)0clear(B)on(B Table)on(A B)clear(C)2 STACK(B C Table)on(B C)on(C D)1 STACK(C Table)GOALclear(D)on(C Table)clear(D)on(B D)Bon(B Table)5 UNSTACK(B D)on(B D)clear(B)CBCclear(C)Initial StateGoal StateFigure 4: Sample Plan Blocks World Domain2.2 RewritingPlan rewriting PbR related term graph rewriting. Term rewriting originatedcontext equational theories reduction normal forms effective wayperform deduction (Avenhaus & Madlener, 1990; Baader & Nipkow, 1998). rewritesystem specified set rules. rule corresponds preferred directionequivalence theorem. main issue term rewriting systems convergence, is,two arbitrary terms rewritten finite number steps unique normal form.PbR two plans considered equivalent solutions problem,213fiAmbite & Knoblockalthough may differ cost operators (that is, equivalentrespect satisfiability introduced above). However, interested usingrewriting rules prove equivalence. Instead, framework uses rewritingrules explore space solution plans.Graph rewriting, akin term rewriting, refers process replacing subgraphgiven graph, conditions satisfied, another subgraph. Graph rewritingfound broad applications, high-level programming languages, databasedata description query languages, etc. Schurr (1997) presents good survey.main drawback general graph rewriting complexity. graph matchingreduced (sub)graph isomorphism problem NP-complete. Nevertheless,restrictions graph rewriting performed efficiently (Dorr, 1995).Planning Rewriting adapts general graph rewriting semantics partial-orderplanning STRIPS-like operator representation. plan-rewriting rule PbR specifiesreplacement, certain conditions, subplan another subplan. However,formalism rule need specify completely detailed embeddingconsequent graph rewriting systems. consistent embeddings rule consequent,generation edges necessary, automatically computed accordingsemantics partial-order planning. algorithm ensures rewritten plans alwaysremain valid (Section 3.1.3). plan-rewriting rules intended explore spacesolution plans reach high-quality plans.2.3 Local Search Combinatorial OptimizationPbR inspired local search techniques used combinatorial optimization.instance combinatorial optimization problem consists set feasible solutionscost function solutions. problem consists finding solution optimalcost among feasible solutions. Generally problems addressed computationallyintractable, thus approximation algorithms used. One class approximationalgorithms surprisingly successful spite simplicity local searchmethods (Aarts & Lenstra, 1997; Papadimitriou & Steiglitz, 1982).Local search based concept neighborhood. neighborhood solutionp set solutions sense close p, exampleeasily computed p share significant amount structure p.neighborhood generating function may, may not, able generate optimalsolution. neighborhood function generate global optima, startinginitial feasible point, called exact (Papadimitriou & Steiglitz, 1982, page 10).Local search seen walk directed graph whose vertices solutionspoints whose arcs connect neighboring points. neighborhood generating functiondetermines properties graph. particular, graph disconnected,neighborhood exact since exist feasible points would lead local optimaglobal optima. PbR points solution plans neighbors planplans generated application set declarative plan rewriting rules.basic version local search iterative improvement. Iterative improvement startsinitial solution searches neighborhood solution lower cost solution. solution found, replaces current solution search continues.214fiPlanning RewritingOtherwise, algorithm returns locally optimal solution. Figure 5(a) shows graphicaldepiction basic iterative improvement. several variations basic algorithm. First improvement generates neighborhood incrementally selects firstsolution better cost current one. Best improvement generates completeneighborhood selects best solution within neighborhood.NeighborhoodLocal OptimaLocal Optima(a) Basic Iterative Improvement(b) Variable-Depth SearchFigure 5: Local SearchBasic iterative improvement obtains local optima, necessarily global optimum.One way improve quality solution restart search several initial points choose best local optima reached them. advancedalgorithms, variable-depth search, simulated annealing tabu search, attemptminimize probability stuck low-quality local optimum.Variable-depth search based applying sequence steps opposed onestep iteration. Moreover, length sequence may change iterationiteration. way system overcomes small cost increases eventually leadstrong cost reductions. Figure 5(b) shows graphical depiction variable-depth search.Simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983) selects next point randomly. lower cost solution chosen, selected. solution higher costchosen, still selected probability. probability decreased algorithm progresses (analogously temperature physical annealing). functiongoverns behavior acceptance probability called cooling schedule.proven simulated annealing converges asymptotically optimal solution. Unfortunately, convergence requires exponential time. So, practice, simulated annealingused faster cooling schedules (not guaranteed converge optimal) thusbehaves like approximation algorithm.Tabu search (Glover, 1989) also accept cost-increasing neighbors. next solutionrandomly chosen legal neighbor even cost worse current solution.neighbor legal limited-size tabu list. dynamically updated tabu listprevents solution points considered period time. intuitiondecide consider solution higher cost least lieunexplored part space. mechanism forces exploration solution spacelocal minima.Finally, stress appeal local search relies simplicity goodaverage-case behavior. could expected, number negative worst-case results. example, traveling salesman problem known exact neighborhoods,215fiAmbite & Knoblockdepend problem instance, must exponential size (Savage, Weiner,& Bagchi, 1976). Moreover, improving move neighborhoods cannot foundpolynomial time unless P = NP (Papadimitriou & Steiglitz, 1977). Nevertheless, bestapproximation algorithm traveling salesman problem local search algorithm(Johnson, 1990).3. Planning Rewriting Local SearchPlanning Rewriting viewed domain-independent framework local search.PbR accepts arbitrary domain specifications, declarative plan-rewriting rules generateneighborhood plan, arbitrary (local) search methods. Therefore, assuminggiven combinatorial problem encoded planning problem, PbR takeinput experiment different neighborhoods search methods.describe main issues Planning Rewriting instantiationlocal search idea typical combinatorial optimization algorithms:Selection initial feasible point: PbR phase consists efficiently generatinginitial solution plan.Generation local neighborhood : PbR neighborhood plan setplans obtained application set declarative plan-rewriting rules.Cost function minimize: measure plan quality planneroptimizing. plan quality function range simple domain-independentcost metric, number steps, complex domain-specific ones,query evaluation cost total manufacturing time set parts.Selection next point: PbR, consists deciding solution planconsider next. choice determines global space exploredsignificant impact efficiency planning. variety local search strategiesused PbR, steepest descent, simulated annealing, etc. searchmethod yields best results may domain problem specific.following subsections expand issues. First, discuss usedeclarative rewriting rules generate local neighborhood plan, constitutesmain contribution paper. present syntax semantics rules,plan-rewriting algorithm, formal properties complexity analysis plan rewriting,rule taxonomy. Second, address selection next plan associatedsearch techniques plan optimization. Third, discuss measures plan quality.Finally, describe approaches initial plan generation.3.1 Local Neighborhood Generation: Plan-Rewriting Rulesneighborhood solution plan generated application set declarativeplan-rewriting rules. rules embody domain-specific knowledge transformations solution plan likely result higher-quality solutions. applicationgiven rule may produce one several rewritten plans fail produce plan,rewritten plans guaranteed valid solutions. First, describe syntax216fiPlanning Rewritingsemantics rules. Second, introduce two approaches rule specification. Third,present rewriting algorithm, formal properties, complexity plan rewriting.Finally, present taxonomy plan-rewriting rules.3.1.1 Plan-Rewriting Rules: Syntax SemanticsFirst, introduce rule syntax semantics examples. Then, provideformal description. plan-rewriting rule three components: (1) antecedent (:iffield) specifies subplan matched; (2) :replace field identifies subplangoing removed, subset steps links antecedent; (3) :with fieldspecifies replacement subplan. Figure 6 shows two rewriting rules Blocks Worlddomain introduced Figure 2. Intuitively, rule avoid-move-twice says that, wheneverpossible, better stack block top another directly, rather first movingtable. situation occurs plans generated simple algorithm firstputs blocks table build desired towers, plan Figure 4.rule avoid-undo says actions moving block table backoriginal position cancel could removed plan.(define-rule :name avoid-move-twice:if (:operators ((?n1 (unstack ?b1 ?b2))(?n2 (stack ?b1 ?b3 Table))):links (?n1 (on ?b1 Table) ?n2):constraints ((possibly-adjacent ?n1 ?n2)(:neq ?b2 ?b3))):replace (:operators (?n1 ?n2)):with (:operators (?n3 (stack ?b1 ?b3 ?b2))))(define-rule :name avoid-undo:if (:operators((?n1 (unstack ?b1 ?b2))(?n2 (stack ?b1 ?b2 Table))):constraints((possibly-adjacent ?n1 ?n2)):replace (:operators (?n1 ?n2)):with NIL))Figure 6: Blocks World Rewriting Rulesrule manufacturing domain (Minton, 1988b) shown Figure 7.domain additional rewriting rules described detail Section 4.1. rule statesplan includes two consecutive punching operations order make holes twodifferent objects, another machine, drill-press, also available, plan quality mayimproved replacing one punch operations drill-press. domainplan quality (parallel) time manufacture parts. rule helps parallelizeplan thus improve plan quality.(define-rule :name punch-by-drill-press:if (:operators ((?n1 (punch ?o1 ?width1 ?orientation1))(?n2 (punch ?o2 ?width2 ?orientation2))):links (?n1 ?n2):constraints ((:neq ?o1 ?o2)(possibly-adjacent ?n1 ?n2))):replace (:operators (?n1)):with (:operators (?n3 (drill-press ?o1 ?width1 ?orientation1))))Figure 7: Manufacturing Process Planning Rewriting Rule217fiAmbite & Knoblockplan-rewriting rule syntax described BNF specification given Figure 8.BNF generates rules follow template shown Figure 9. Next, describesemantics three components rule (:if, :replace, :with fields) detail.<rule> ::= (define-rule :name <name>:if (<graph-spec-with-constraints>):replace (<graph-spec>):with (<graph-spec>))<graph-spec-with-constraints> ::= {<graph-spec>}{:constraints (<constraints>)}<graph-spec> ::= {:operators (<nodes>)}{:links (<edges>)} | NIL<nodes> ::= <node> | <node> <nodes><edges> ::= <edge> | <edge> <edges><constraints> ::= <constraint> | <constraint> <constraints><node> ::= (<node-var> {<node-predicate>} {:resource})<edge> ::= (<node-var> <node-var>) |(<node-var> <edge-predicate> <node-var>) |(<node-var> :threat <node-var>)<constraint> ::= <interpreted-predicate> |(:neq <pred-var> <pred-var>)<node-var> <pred-var> = , {} = optional, | = alternativeFigure 8: BNF Rewriting Rules(define-rule :name <rule-name>:if (:operators ((<nv> <np> {:resource}) ...):links ((<nv> {<lp>|:threat} <nv>) ...):constraints (<ip> ...)):replace (:operators (<nv> ...):links ((<nv> {<lp>|:threat} <nv>) ...)):with (:operators ((<nv> <np> {:resource}) ...):links ((<nv> {<lp>} <nv>) ...)))<nv> = node variable, <np> = node predicate, {} = optional<lp> = causal link predicate, <ip> = interpreted predicate,| = alternativeFigure 9: Rewriting Rule Templateantecedent, :if field, specifies subplan matched currentplan. graph structure subplan defined :operators :links fields.:operators field specifies nodes (operators) graph :links fieldspecifies edges (causal ordering links). Finally, :constraints field specifiesset constraints operators links must satisfy.:operators field consists list node variable node predicate pairs.step number steps plan match given node predicate wouldcorrespondingly bound node variable. node predicate interpretedtwo ways: step action, resource used step. example, nodespecification (?n2 (stack ?b1 ?b3 Table)) antecedent avoid-move-twiceFigure 6 shows node predicate denotes step action. node specificationcollect tuples, composed step number ?n2 blocks ?b1 ?b3, obtained matchingsteps whose action stack block ?b1 Table moved topanother block ?b3. node specification applied plan Figure 4 would result218fiPlanning Rewritingthree matches: (1 C D), (2 B C), (3 B), variables (?n2 ?b1 ?b3) respectively.optional keyword :resource present, node predicate interpreted oneresources used plan step, opposed describing step action. examplerule matches resources operator given Figure 10, nodespecification (?n1 (machine ?x) :resource) match steps use resourcetype machine collect pairs step number ?n1 machine object ?x.(define-rule :name resource-swap:if (:operators ((?n1 (machine ?x) :resource)(?n2 (machine ?x) :resource)):links ((?n1 :threat ?n2))):replace (:links (?n1 ?n2)):with (:links (?n2 ?n1)))Figure 10: Resource-Swap Rewriting Rule:links field consists list link specifications. language admits linkspecifications three types. first type specified pair node variables.example, (?n1 ?n2) Figure 7. specification matches temporal ordering linkplan, regardless imposed causal links resolution threats.second type link specification matches causal links. Causal links specifiedtriples composed producer step node variable, edge predicate, consumerstep node variable. semantics causal link producer step assertseffects predicate, turn needed preconditions consumer step.example, link specification (?n1 (on ?b1 Table) ?n2) Figure 6 matches steps ?n1put block ?b1 Table steps ?n2 subsequently pick block.link specification applied plan Figure 4 would result matches: (4 C 1)(5 B 2), variables (?n1 ?b1 ?n2).third type link specification matches ordering links originating resolutionthreats (coming either resource conflicts operator conflicts). linksselected using keyword :threat place condition. example,resource-swap rule Figure 10 uses link specification (?n1 :threat ?n2) ensuresteps ordered involved threat situation matched.helps identify critical steps reasons (i.e.causal links) order, therefore rule may attempt reorder them.useful plan quality depends degree parallelism plandifferent ordering may help parallelize plan. Recall threats solved eitherpromotion demotion, reverse ordering may also produce valid plan,often case conflict among resources rule Figure 10.Interpreted predicates, built-in user-defined, specified :constraintsfield. predicates implemented programmatically opposed obtainedmatching components plan. built-in predicates currently implementedinequality8 (:neq), comparison (< <= > >=), arithmetic (+ - * /) predicates.user also add arbitrary predicates corresponding programmatic implementa8. Equality denoted sharing variables rule specification.219fiAmbite & Knoblocktions. interpreted predicates may act filters previous variables introducenew variables (and compute new values them). example, user-defined predicatepossibly-adjacent rules Figure 6 ensures steps consecutivelinearization plan.9 plan Figure 4 extension possibly-adjacentpredicate is: (0 4), (0 5), (4 5), (5 4), (4 1), (5 1), (1 2), (2 3), (3 Goal).user easily add interpreted predicates including function definitionimplements predicate. rule matching algorithm passes arguments callsfunctions appropriate. current plan passed default first argumentinterpreted predicates order provide context computation predicate(but ignored). Figure 11 show skeleton (Lisp) implementationpossibly-adjacent less-than interpreted predicates.(defun possibly-adjacent (plan node1 node2)(not (necessarily-not-adjacentnode1node2;; accesses current plan(plan-ordering plan)))(defun less-than (plan n1 n2)(declare (ignore plan))(when (and (numberp n1) (numberp n2))(if (< n1 n2)(nil) ;; truenil))) ;; falseFigure 11: Sample Implementation Interpreted Predicatesconsequent composed :replace :with fields. :replace fieldspecifies subplan going removed plan, subsetsteps links identified antecedent. step removed, links referstep also removed. :with field specifies replacement subplan.see Sections 3.1.2 3.1.3, replacement subplan need completelyspecified. example, :with field avoid-move-twice rule Figure 6specifies addition stack step step embedded plan.links rest plan automatically computed rewriting process.3.1.2 Plan-Rewriting Rules: Full versus Partial SpecificationPbR gives user total flexibility defining rewriting rules. section describe twoapproaches guaranteeing rewriting rule specification preserves plan correctness,is, produces valid rewritten plan applied valid plan.full-specification approach rule specifies steps links involvedrewriting. rule antecedent identifies anchoring points operatorsconsequent, embedding replacement subplan unambiguous resultsvalid plan. burden proving rule correct lies upon user automatedrule defining procedure (cf. Section 6). kind rules ones typically usedgraph rewriting systems (Schurr, 1997).partial-specification approach rule defines operators links constitute gist plan transformation, rule prescribe precise9. interpreted predicate possibly-adjacent makes link expression antecedent avoid-move-twice redundant. Unstack puts block ?b1 table pickedstack operator, thus causal link (?n1 (on ?b1 Table) ?n2) already implied :operators:constraints specification could removed rule specification.220fiPlanning Rewritingembedding replacement subplan. burden producing valid plan lies uponsystem. PbR takes advantage semantics domain-independent planning acceptrelaxed rule specification, fill details, produce valid rewritten plan.Moreover, user free specify rules may necessarily able computerewriting plan matches antecedent necessary conditionchecked antecedent. is, partially-specified rule may overgeneral.may seem undesirable, often rule may cover useful cases naturallyspecified form. rule may fail rarely occurring plans, effortdefining matching complete specification may worthwhile. case,plan-rewriting algorithm ensures application rewriting rule either generatesvalid plan fails produce plan (Theorem 1, Section 3.1.3).example two approaches rule specification, consider Figure 12shows avoid-move-twice-full rule, fully-specified version avoid-move-twicerule (of Figure 6, reprinted convenience). avoid-move-twice-full rulecomplex less natural specify avoid-move-twice. But, importantly,avoid-move-twice-full making commitments avoid-move-twice. particular, avoid-move-twice-full fixes producer (clear ?b1) ?n3 ?n4?n7 also known valid candidate. general, several alternative producersprecondition replacement subplan, consequently many possible embeddings.different fully-specified rule needed capture embedding. number rulesgrows exponentially permutations embeddings enumerated. However,using partial-specification approach express general plan transformationsingle natural rule.(define-rule :name avoid-move-twice-full:if (:operators ((?n1 (unstack ?b1 ?b2))(?n2 (stack ?b1 ?b3 Table))):links ((?n4 (clear ?b1) ?n1)(?n5 (on ?b1 ?b2) ?n1)(?n1 (clear ?b2) ?n6)(?n1 (on ?b1 Table) ?n2)(?n7 (clear ?b1) ?n2)(?n8 (clear ?b3) ?n2)(?n2 (on ?b1 ?b3) ?n9)):constraints ((possibly-adjacent ?n1 ?n2)(:neq ?b2 ?b3))):replace (:operators (?n1 ?n2)):with (:operators ((?n3 (stack ?b1 ?b3 ?b2))):links ((?n4 (clear ?b1) ?n3)(?n8 (clear ?b3) ?n3)(?n5 (on ?b1 ?b2) ?n3)(?n3 (on ?b1 ?b3) ?n9))))(define-rule :name avoid-move-twice:if (:operators((?n1 (unstack ?b1 ?b2))(?n2 (stack ?b1 ?b3 Table))):links (?n1 (on ?b1 Table) ?n2):constraints((possibly-adjacent ?n1 ?n2)(:neq ?b2 ?b3))):replace (:operators (?n1 ?n2)):with (:operators(?n3 (stack ?b1 ?b3 ?b2))))Figure 12: Fully-specified versus Partially-specified Rewriting Rulesummary, main advantage full-specification rules rewritingperformed efficiently embedding consequent already specified.disadvantages number rules represent generic plan transformationmay large resulting rules quite lengthy; problems may decrease221fiAmbite & Knoblockperformance match algorithm. Also, rule specification error prone writtenuser. Conversely, main advantage partial-specification rules singlerule represent complex plan transformation naturally concisely. rulecover large number plan structures even may occasionally fail. Also, partialspecification rules much easier specify understand users system.seen, PbR provides high degree flexibility defining plan-rewriting rules.3.1.3 Plan-Rewriting Algorithmsection, first describe basic plan-rewriting algorithm PbR. Second,prove algorithm sound discuss formal properties rewriting. Finally,discuss family algorithms plan rewriting depending parameterslanguage defining plan operators, specification language rewriting rules,requirements search method.plan-rewriting algorithm shown Figure 13. algorithm takes two inputs:valid plan P , rewriting rule R = (qm , pr , pc ) (qm antecedent query, prreplaced subplan, pc replacement subplan). output valid rewrittenplan P 0 . matching antecedent rewriting rule (qm ) determines ruleapplicable identifies steps links interest (line 1). matching seensubgraph isomorphism antecedent subplan current plan (withresults filtered applying :constraints). However, take different approach.PbR implements rule matching conjunctive query evaluation. implementation keepsrelational representation steps links current plan similar nodelink specifications rewriting rules. example, database planFigure 4 contains one table unstack steps schema (?n1 ?b1 ?b2) tuples(4 C A) (5 B D), another table causal links involving clear conditionschema (?n1 ?n2 ?b) tuples (0 1 C), (0 2 B), (0 2 C), (0 3 B), (0 4 C), (0 5 B), (43 A) (5 1 D), similar tables operator link types. matchprocess consists interpreting rule antecedent conjunctive query interpretedpredicates, executing query relational view plan structures.running example, analyze application avoid-move-twice rule Figure 6plan Figure 4. Matching rule antecedent identifies steps 1 4.precisely, considering antecedent query, result single tuple (4 C 1 D)variables (?n1 ?b1 ?b2 ?n2 ?b3).choosing match work (line 3), algorithm instantiates subplanspecified :replace field (pr ) according match (line 4) removesinstantiated subplan pir original plan P (line 5). edges incomingemanating nodes replaced subplan also removed. effectsreplaced plan pir achieving remainder plan (P pir ), UsefulEffects pir ,achieved replacement subplan (or steps P pir ). orderfacilitate process, AddFlaws procedure records effects open conditions.1010. POCL planners operate keeping track repairing flaws found partial plan. Open conditions, operator threats, resource threats collectively called flaws (Penberthy & Weld, 1992).AddFlaws(F,P) adds set flaws F plan structure P .222fiPlanning Rewritingprocedure RewritePlanInput: valid partial-order plan Prewriting rule R = (qm , pr , pc ), V ariables(pr ) V ariables(qm )Output: valid rewritten partial-order plan P 0 (or failure)1. := atch(qm , P )Match rule antecedent qm (:if field) P . result set substitutions= {..., , ...} variables qm .2. = return failure3. Choose match4. pir := prInstantiate subplan removed pr (the :replace field) according .5. Pri := AddFlaws(UsefulEffects(pir ), P pir )Remove instantiated subplan pir plan P add UsefulEffects piropen conditions. resulting plan Pri incomplete.6. pic := pcInstantiate replacement subplan pc (the :with field) according .7. Pci := AddF laws(P reconditions(pic ) F indT hreats(Pri pic ), Pri pic )Add instantiated replacement subplan pic Pri . Find new threats openconditions add flaws. Pci potentially incomplete, several flawsneed resolved.8. P 0 := rP OP (Pci )Complete plan using partial-order causal-link planning algorithm (restrictedstep reuse, step addition) order resolve threats open conditions.rP OP returns failure valid plan found.9. Return P 0Figure 13: Plan-Rewriting Algorithmresult partial plan Pri (line 5). Continuing example, Figure 14(a) showsplan resulting removing steps 1 4 plan Figure 4.Finally, algorithm embeds instantiated replacement subplan pic remainder original plan (lines 6-9). rule completely specified, algorithm simplyadds (already instantiated) replacement subplan plan, worknecessary. rule partially specified, algorithm computes embeddingsreplacement subplan remainder original plan three stages. First,algorithm adds instantiated steps links replacement plan pic (line 6)current partial plan Pri (line 7). Figure 14(b) shows state examplepic , new stack step (6), incorporated plan. Note open conditions(clear A) on(C D). Second, FindThreats procedure computes possible threats,operator threats resource conflicts, occurring Pri pic partial plan (line 7);example, threat situation clear(C) proposition step 6 2 Figure 14(b). threats preconditions replacement plan pic recordedAddFlaws resulting partial plan Pci . Finally, algorithm completes plan usingrPOP, partial-order causal-link planning procedure restricted reuse steps (i.e.,223fiAmbite & Knoblockstep addition) (line 8). rPOP allows us support expressive operator languageflexibility computing one embeddings. one rewriting needed,rPOP stops first valid plan. Otherwise, continues exhausting alternative ways satisfying open preconditions resolving conflicts, produces validrewritings. running example, one embedding possible resulting planFigure 14(c), new stack step (6) produces (clear A) on(C D),preconditions satisfied, ordering (6 2) ensures plan valid.rewriting algorithm Figure 13 sound sense produces valid planinput valid plan, outputs failure input plan cannot rewritten usinggiven rule. Since elementary plan-rewriting step sound, sequence rewritingsperformed PbRs optimization search also sound.Lemma 1 (Soundness rPOP) Partial-order causal-link (POCL) planning withoutstep addition (rP OP ) sound.Proof: POCL planning, precondition step plan achieved eitherinserting new step snew reusing step sreuse already present current plan (thesteps effect unifies precondition). Forbidding step addition decreasesset available steps used satisfy precondition, step foundrPOP proceeds general POCL. Since, POCL completion partial-plan sound(Penberthy & Weld, 1992), rP OP also sound. 2Theorem 1 (Soundness Plan Rewriting) RewritePlan (Figure 13) producesvalid plan input P valid plan, outputs failure input plan cannotrewritten using given rewriting rule R = (qm , pr , pc ).Proof: Assume plan P solution planning problem goals G initialstate I. POCL planning, plan valid iff preconditions steps supportedcausal links (the goals G preconditions goal step, initial stateconditions effects initial step), operator threatens causal link(McAllester & Rosenblitt, 1991; Penberthy & Weld, 1992).rule R match plan P , algorithm trivially returns failure (line 2). Assumingmatch , removing P steps links specified pir (includinglinks causal ordering incoming outgoing steps pir ), openconditions exist resulting plan Pri pir achieving (line 5).Adding instantiated replacement subplan pic introduces open conditionspartial plan: preconditions steps pic (line 7). sourcesopen conditions algorithm.Since plan P valid initially, (operator and/or resource) threats presentplan Pci (line 7) caused removal subplan pir (line 3) additionsubplan pic (line 7). threats may occur operators causal links Pri picregardless whether operator causal link initially Pri pic . threatscombined plan Pri pic effectively computed finding relative positionssteps comparing causal link steps may orderedproducer consumer condition causal link (FindThreats, line 7).point, shown plan (Pci ) flaws (threatsopen conditions) explicitly recorded (by AddFlaws lines 5 7). Since rP OP sound(Lemma 1), conclude rP OP complete Pci output valid plan P 0 , outputfailure flaws plan cannot repaired. 2224fiPlanning Rewritingclear(B)REMOVED SUBPLANon(A Table)on(C A)Causal LinkOrdering ConstraintSide Effectclear(A)4 UNSTACK(C A)on(C A)clear(C)on(D Table)on(A Table)clear(B)3 STACK(A B Table)on(C Table)2 STACK(B C Table)clear(C)1 STACK(C Table)0on(B Table)on(A B)clear(C)on(B C)on(C D)GOALclear(D)clear(B)on(C Table)clear(D)on(B D)Bon(B Table)5 UNSTACK(B D)on(B D)clear(B)CBCclear(C)Initial StateGoal State(a) Application Rewriting Rule: Removing Subplanclear(B)Causal LinkOrdering ConstraintOpen conditionson(A Table)clear(A)clear(C)on(D Table)0on(C A)clear(B)3 STACK(A B Table)on(B Table)on(A B)clear(C)on(B C)2 STACK(B C Table)clear(C)clear(A)on(C A)clear(D)on(B D)on(A Table)clear(B)on(C D)6 STACK(C A)on(C D)clear(D)on(C A)GOALclear(D)Bon(B Table)5 UNSTACK(B D)on(B D)clear(B)CBCclear(C)Initial StateGoal State(b) Application Rewriting Rule: Adding Replacement Subplanon(A Table)clear(B)on(A Table)3 STACK(A B Table)clear(B)clear(A)on(D Table)on(C A)2 STACK(B C Table)clear(C)06 STACK(C A)clear(B)on(B Table)on(A B)clear(C)on(B C)on(C D)GOALclear(D)on(C A)clear(D)Causal LinkOrdering ConstraintSide Effecton(B D)on(B Table)5 UNSTACK(B D)on(B D)clear(B)BCBCclear(C)Initial StateGoal State(c) Rewritten PlanFigure 14: Plan Rewriting: Applying rule avoid-move-twice Figure 6 plan Figure 4225fiAmbite & KnoblockCorollary 1 (Soundness PbR Search) optimization search PbR sound.Proof: induction. Assume initial valid plan single step rewriting search.Theorem 1, output either valid rewritten plan failure. output failure,search trivially sound. Assume valid plan Pn1 n 1 rewriting steps.According Theorem 1, applying single rewriting rule plan Pn1 produces validplan Pn failure. Thus, arbitrary number rewritings produces valid plan (orplan), PbRs search sound. 2Although RewritePlan sound, may certainly produce plansminimal number steps faced arbitrary rules. example, imagineconsequent rewriting rule specified two identical steps s1 s2 (botheffects e1 e2) flaws Pci exactly open conditions e1 e2.Then, sound non step-minimal plan would using s1 satisfy e1 using s2satisfy e2 (although step could satisfy open conditions). PbRdiscard plan make restriction types acceptable costfunctions. cost function took robustness plan account,plan steps may desirable.cannot guarantee PbRs optimization search complete senseoptimal plan would found. PbR uses local search well known that, general,local search cannot complete. Even PbR exhaustively explores space planrewritings induced given initial plan set rewriting rules, still cannot provesolution plans reached. property initial plan generator,set rewriting rules, semantics planning domain. rewriting rules PbRplay similar role traditional declarative search control completenesssearch may traded efficiency. Perhaps using techniques inferring invariantsplanning domain (Gerevini & Schubert, 1998; Fox & Long, 1998; Rintanen, 2000) provingconvergence term graph rewriting systems (Baader & Nipkow, 1998), conditionscompleteness plan-rewriting search given planning domain could obtained.design plan-rewriting algorithm depends several parameters: languageoperators, language rewriting rules, choice full-specification partialspecification rewriting rules, need rewritings one rewriting requiredsearch method.language operators affects way initial rewritten plansconstructed. framework supports expressive operator definition language describedSection 2.1. provide support language using standard techniques causallink establishment threat checking like Sage (Knoblock, 1995) UCPOP(Penberthy & Weld, 1992).language antecedents rewriting rules affects efficiency matching.system implements conjunctive query language described Section 3.1.1.However, system could easily accommodate expressive query languagerule antecedent, relationally complete language (i.e., conjunction, disjunction,safe negation) (Abiteboul, Hull, & Vianu, 1995), recursive language datalogstratified negation, without significantly increasing computational complexityapproach important way, discuss Section 3.1.4.choice fully versus partially specified rewriting rules affects wayreplacement plan embedded current plan. rule completely specified,226fiPlanning Rewritingembedding already specified rule consequent, replacement subplansimply added current plan. rule partially specified, algorithmcompute valid embeddings.choice one versus rewritings affects antecedent matchingembedding rule consequent. rule matches computed eithertime, bottom-up evaluation logic databases, one-at-a-time Prolog, depending whether search strategy requires one rewritings. rule fully-specifiedone embedding per match possible. But, rule partially-specified multipleembeddings may result single match. search strategy requires one rewriting, must also provide mechanism choosing rule applied, matchcomputed, embedding generated (rPOP stop first embeddingcompute embeddings). implemented rewriting algorithm modular designsupport different combinations choices.3.1.4 Complexity Plan Rewritingcomplexity plan rewriting PbR originates two sources: matching ruleantecedent plan, computing embeddings replacement plan.order analyze complexity matching plan-rewriting rules, introduce followingdatabase-theoretic definitions complexity (Abiteboul et al., 1995):Data Complexity: complexity evaluating fixed query variable database inputs.Expression Complexity: complexity evaluating, fixed database instance,queries specifiable given query language.Data complexity measures complexity respect size database.Expression complexity measures complexity respect size queries(taken given language). case, database steps links planqueries antecedents plan-rewriting rules.Formally, language rule antecedents described Section 3.1.1 conjunctivequeries interpreted predicates. worst-case combined data expression complexity conjunctive queries exponential (Abiteboul et al., 1995). is, sizequery (rule antecedent) size database (plan) grow simultaneously,little hope matching efficiently. Fortunately, relationally-complete languages datacomplexity contained Logarithmic Space, is, turn, contained Polynomial Time(Abiteboul et al., 1995). Thus conjunctive query language complexity.encouraging result shows cost evaluating fixed query growsslowly database size increases. PbR means matching antecedentrules strongly affected size plans. Moreover, experienceuseful rule antecedents large contain many constant labels (at least,node edge predicate names) help reduce size intermediate resultsimprove efficiency matching. result also indicates could extendlanguage antecedent relationally complete without affecting significantlyperformance system.11 Another possible extension use datalog stratifiednegation, also polynomial time data complexity. Graph-theoretic properties11. Figure 32 Section 6 proposes example rule relationally-complete antecedent usingappropriate syntax.227fiAmbite & Knoblockplans could easily described datalog. example, possibly-adjacent interpreted predicate Figure 7 could described declaratively datalog program insteadpiece code. summary, rule match moderately sized rules, even quite expressivelanguages large plans, remains tractable made efficient using productionmatch (Forgy, 1982) query optimization techniques (Sellis, 1988).second source complexity computing embeddings replacement plangiven consequent plan-rewriting rule. definition full-specification rules,embedding completely specified rule itself. Thus, suffices simply removeundesired subplan directly add replacement subplan. linear sizeconsequent.partial-specification rules, computing embeddings replacement subplanexponential size plan worst case. However, occurspathological cases. example, consider plan Figure 15(a) goingcompute embeddings step x remainder plan order satisfy openprecondition g0. Step x preconditions two effects b g0. stepplan proposition b effect. Therefore, new step x conflicts every stepplan (1 n) ordered respect steps. Unfortunately,exponential number orderings. effect, orderings imposed adding stepx correspond partitions set steps (1 n) two sets: one orderedx one after. Figure 15(b) shows one possible orderings. subplanembedding contained several steps contained similar conflicts problem wouldcompounded. Even deciding single embedding exists NP-hard. example,add two additional effects g1 operator x, valid embedding.worst case (solving first flaws induced conflicts proposition b)explore exponential number positions step x plan, endfailure. Nevertheless, given quasi-decomposability useful planning domains expectnumber conflicts relatively small. Also useful rewriting rules specifyreplacement subplans small compared plan embedding into.experience indicates plan rewriting partial-specification rules performedefficiently shown results Section 4.bb11g1bg1b22g2g0b0g0g2bxgg0xg0ngngnbn(a) embeddingb(b) One possible embeddingFigure 15: Exponential Embeddings228fiPlanning Rewriting3.1.5 Taxonomy Plan-Rewriting Rulesorder guide user defining plan-rewriting rules domain help designingalgorithms may automatically deduce rules domain specification (seeSection 6), helpful know kinds rules useful. identifiedfollowing general types transformation rules:Reorder: rules based algebraic properties operators, commutative, associative distributive laws. example, commutative rule reorderstwo operators need resource Figure 10, join-swap rule Figure 29combines commutative associative properties relational algebra.Collapse: rules replace subplan smaller subplan. example,several operators replaced one, remote-join-eval rule Figure 29.rule replaces two remote retrievals information source local joinoperation single remote join operation, remote source capabilityperforming joins. example application rule query plan shownFigure 30. examples Blocks World rules Figure 6 replace unstackstack operators either equivalent single stack operator empty plan.Expand: rules replace subplan bigger subplan. Although mayappear counter-intuitive initially, easy imagine situation expensiveoperator replaced set operators cheaper whole. interestingcase operators already present plan synergistically reused. find rule type domains analyzed far, Backstrom(1994a) presents framework adding actions improves quality plans.quality metric plan execution time, similarly manufacturing domain Section 4.1. Figure 16 shows example planning domain adding actions improvesquality (from Backstrom, 1994a). example, removing link Bm C1inserting new action shortens significantly time execute plan.PRn1R1R0C1C1R0PPQ1QmB1RnCnPRnCnPQ1Rn1R1R0B1BmBm QmQm1Qm1(a) Low Quality Plan(b) High Quality PlanFigure 16: Adding Actions Improve QualityParallelize: rules replace subplan equivalent alternative subplanrequires fewer ordering constraints. typical case redundant alternative resources operators use. example, rule punch-by-drill-pressFigure 7. Another example rule Figure 16 suggests could seencombination expand parallelize types.229fiAmbite & Knoblock3.2 Selection Next Plan: Search StrategiesAlthough space rewritings explored systematically, Planning Rewritingframework better suited local search techniques typical combinatorial optimization algorithms. characteristics planning domain, initial plan generator,rewriting rules determine local search method performs best. First, discussinitial plan generator affects choice local search methods. Second, consider impact rewriting rules. Third, discuss role domain knowledgesearch process. Finally, describe several local search methods work PbR.important difference PbR traditional combinatorial algorithmsgeneration feasible solutions. Usually, combinatorial optimization problems existseffective procedure generate feasible solutions (e.g., permutations schedule).Thus, even local search graph disconnected, choosing appropriate initialsolution generator (e.g., random) could fall component graph containsglobal optimum. PbR cannot assume powerful initial plan generators. Evenoptimization domains, efficient initial plan generators, mayguarantees coverage solution space provide. Therefore, optimal planmay reachable applying rewriting rules starting initial plansavailable generator. Nevertheless, many domains initial plan generatorprovides good sample solution space sufficient multiple-restart search methodsescape low-quality local minima provide high-quality solutions.plan-rewriting rules define neighborhood function, may exact (cf.Section 2.3) not. example, query planning domain define setrules completely generate space solution plans (because propertiesrelational algebra). domains may hard prove exact setrules. limitations initial plan generation plan-rewriting rules affectpossibility theoretically reaching global optimum. surprising since manyproblems, regardless whether cast planning formalisms,converging local search algorithms (e.g., Papadimitriou & Steiglitz, 1977). Nevertheless,practice, good local optima still obtained many domains.Many local search methods, first best improvement, simulated annealing,tabu search, variable-depth search, applied straightforwardly PbR.experiments Section 4 used first best improvement, performedwell. Next, describe details application two methods PbR.Section 6, discuss ideas using variable-depth plan rewriting.First improvement generates rewritings incrementally selects first planbetter cost current one. order implement method efficiently usetuple-at-a-time evaluation rule antecedent, similarly behavior Prolog. Then,rule instantiation, generate one embedding, test cost resulting plan,better current plan, repeat. choice generating anotherembedding rule instantiation, generate another instantiation rule,generate match different rule.Best improvement generates complete set rewritten plans selects best.method requires computing matches embeddings match.matches obtained evaluating rule antecedent set-at-a-time database230fiPlanning Rewritingquery. discussed Section 3.1.4 query evaluation quite efficient.experience, computing plan embeddings usually expensive computingrule matches.Planning Rewriting choice initial plan generator, rewriting rules,search methods intertwined. initial plan generator fixed, determinesshape plans would modified rewriting rules, accordingneighborhood, appropriate search mechanism chosen. PbRmodular design facilitate experimentation different initial plan generators, setsrewriting rules, search strategies.3.3 Plan Qualitypractical planning domains quality plans crucial. onemotivations Planning Rewriting approach. PbR user defines measureplan quality appropriate application domain. quality metric couldrange simple domain-independent cost metric, number steps,complex domain-specific ones. example, query planning domain measureplan quality usually estimation query execution cost based sizedatabase relations, data manipulation operations involved answering query,cost network transfer. decentralized environment, cost metric may involveactual monetary costs information sources require payments. jobshop scheduling domain simple cost functions schedule length (that is,parallel time finish pieces), sum times finish piece.sophisticated manufacturing domain may include variety concerns cost,reliability, precision operator/process, costs resources materials usedoperators, utilization machines, etc. reader find detailedexamples quality metrics domains Sections 4.1 4.4.significant advantage PbR complete plan available assess quality.generative planners complete plan available search solutioncompleted, usually simple plan quality metrics, number steps,used. work incorporate quality concerns generative planners (Estlin& Mooney, 1997; Borrajo & Veloso, 1997; Perez, 1996). systems automaticallylearn search control rules improve efficiency planning qualityresulting plans. PbR rewriting rules seen post facto optimization searchcontrol. opposed guiding search generative planner towards high-qualitysolutions based information available partial plans, PbR improves qualitycomplete solution plans without restriction types quality metrics. Moreover,plan cost additive, plan refinement strategy impractical since may needexhaustively explore search space find optimal plan. example nonadditive cost function appears UNIX planning domain (Etzioni & Weld, 1994)plan transfer files two machines may cheaper files compressedinitially (and uncompressed arrival). is, plan includes compression(and necessary uncompression) operations cost effective, plan refinementsearch would naturally lead it. using complete plans, PbR accurately assessarbitrary measures quality.231fiAmbite & Knoblock3.4 Initial Plan GenerationFast initial plan generation domain-specific nature. requires user specifyefficient mechanism compute initial solution plan. general, generating initialplan may hard generating optimal plan. However, crucial intuition behindplanning algorithms practical problems quasi-decomposable (Simon, 1969),is, interactions among parts problems limited. interactionsproblem pervasive, 8-puzzle, operator-based representation algorithms classical planning little use. would behave search basedproblem solver. Fortunately, many practical problems indeed quasi-decomposable.intuition also suggests finding initial plan generators planning problems mayhard appears, system solve subproblems independently,combine simplest way, example, concatenating solutions sequentially. Moreover, many circumstances problems may easily transformedstate minimizes interactions solving problem state much easier.example, Blocks World state blocks table minimizesinteractions. simple design algorithm solves Blocks World problempassing intermediate state. Using methods initial plan generator mayproduce suboptimal initial plans reasonable planning cost.ideas constructing initial plan generators embodied two general ways,implemented system. first one bootstrap resultsgeneral purpose planning algorithm strong search control bias. second oneprovide user convenient high-level facilities describe plan constructionalgorithms programmatically.3.4.1 Biased Generative Plannersvariety ways control search generic planner. plannersaccept search control rules, others accept heuristic functions, built-in searchcontrol. present examples techniques.general way efficiently constructing plans use domain-independentgenerative planner accepts search control rules. example, Prodigy (Carbonell,Knoblock, & Minton, 1991), UCPOP (Penberthy & Weld, 1992) Sage (Knoblock, 1995)planners. setting type search providing strong bias meanssearch control rules, planner quickly generate valid, although possibly suboptimal,initial plan. example, manufacturing domain (Minton, 1988a), analyzeddetail Section 4.1, depth-first search goal selection heuristic based abstractionhierarchies (Knoblock, 1994a) quickly generates feasible plan, often qualityplan, defined time required manufacture objects, suboptimal.TLPlan (Bacchus & Kabanza, 1995, 2000) efficient forward-chaining planneruses search control expressed temporal logic. forward chaining completestate available, much refined domain control knowledge specified.preferred search strategy used TLPlan depth-first search, although finds plansefficiently, plans may low quality. Note generative plannerexplores partial sequences steps, cannot use sophisticated quality measures.232fiPlanning RewritingHSP (Bonet, Loerincs, & Geffner, 1997; Bonet & Geffner, 1999) forward searchplanner performs variation heuristic search applied classical AI planning.built-in heuristic function relaxed version planning problem: computesnumber required steps reach goal disregarding negated effects operators.metric computed efficiently. Despite simplicity heuristicadmissible, scales surprisingly well many domains. plans generatedaccording fixed heuristic function, planner cannot incorporate quality metric.types planners quite efficient practice although often produce suboptimal plans. excellent candidates generate initial planssubsequently optimized PbR.3.4.2 Facilitating Algorithmic Plan Constructionmany domains, simple domain-dependent approximation algorithms provide goodinitial plans. example, query planning domain, system easily generateinitial query evaluation plans randomly (or greedily) parsing given query.Blocks World also straightforward generate solution linear time using naivealgorithm: put blocks table build desired towers bottom up.algorithm produces plans length worse twice optimal, makesalready good approximation algorithm. However, interest Blocks Worldtraditionally optimal solutions, NP-hard problem (Gupta & Nau, 1992).system facilitates creation initial plans freeing user specifying detailed graph structure plan. user needs specify algorithmproduces sequence instantiated actions, is, action names groundparameters action takes.12 example, (user-defined) naive algorithmBlocks World domain described applied problem Figure 4 producessequence: unstack(C A), unstack(B D), stack(C Table), stack(B C Table),stack(A B Table). Then, system automatically converts sequence actionsfully detailed partial-order plan using operator specification domain. resulting plan conforms internal data structures PbR uses. process includescreating nodes fully detailed operators preconditions effects, addingedges represent necessary causal links ordering constraints. BlocksWorld example resulting plan Figure 4.algorithm transforms user-defined sequence actions partial-orderplan presented Figure 17. algorithm first constructs causal structure plan(lines 2 6) adds necessary ordering links avoid threats (lines 7 10).user needs specify action names corresponding instantiated actionparameters. algorithm consults operator specification find preconditionseffects, instantiate them, construct causal links, check operator threats.Operator threats always resolved favor ordering given user inputplan. reason input plan may overconstrained total order,assumed valid. Therefore, processing step last first, orderingsindeed avoid threats included partial-order plan.12. algorithm also accepts extra ordering constraints addition sequence availableinitial plan generator.233fiAmbite & Knoblockprocedure TO2POInput: valid total-order plan (a1 , ..., )Output: equivalent partial-order plan1. := n 12.p Preconditions(ai )3.choose k <4.1. p PositiveEffects(ak )5.2. 6 l k < l < p NegativeEffects(al )6.add order ak ai7.p NegativeEffects(ai )8.j := (i 1) 19.p Preconditions(aj )10.add order aj ai11. return ((a1 , ..., ), )Figure 17: Algorithm Converting Total-order Partial-order Plansalgorithm extension greedy algorithm presented Veloso, Perez, & Carbonell (1990). algorithm explores non-deterministically producers proposition (line 3), opposed taking latest producer sequence algorithm.13is, algorithm explored exhaustively, produces partially-ordered causalstructures consistent input sequence. generalization stems criticismBackstrom (1994b) algorithm Veloso et al. (1990) desire ableproduce alternative initial plans.problem transforming sequence steps least constrained plan analyzedBackstrom (1994b) several natural definitions optimality. definitionsleast-constrained plan shortest parallel execution problem NP-hard. Backstromshows Velosos algorithm, although polynomial, conform natural definitions. algorithm greedy, suffer drawbackspointed Backstrom. Moreover, purposes need optimal initial plans.space partial orders explored rewriting process.Regardless method producing initial plans, generators provide multipleplans preferable. different initial plans used conjunction multiple restartsearch techniques order escape low-quality local minima.4. Empirical Resultssection show broad applicability Planning Rewriting analyzing fourdomains different characteristics: process manufacturing domain (Minton, 1988b),transportation logistics domain, Blocks World domain used examplesthroughout paper, domain distributed query planning.13. implement algorithm enough replace line 3 Figure 17 with:find max k <234fiPlanning Rewriting4.1 Manufacturing Process Planningtask manufacturing process planning domain find plan manufactureset parts. implemented PbR translation domain specification (Minton,1988b). domain contains variety machines, lathe, punch, spray painter,welder, etc, total ten machining operations. operator specification shownFigures 18 19. features part described set predicates,temperature, painted, has-hole, etc. features changed operators.predicates state, has-clamp, is-drillable, etc, set initial stateproblem.example behavior operator, consider polish operator Figure 18.requires part manufacture cold polisher clamp securepart machine. effect applying operator leave surfacepart polished. attributes part, surface-condition, single-valued,others, like has-hole, multivalued. Note drill-press punchoperators Figure 18 prevent several has-hole conditions assertedpart. interesting operators weld bolt. operators join twoparts particular orientation form new part. operations performedseparate parts joined.measure plan cost schedule length, (parallel) time manufactureparts. domain machining operations assumed take unit time.machines objects (parts) modeled resources order enforce onepart placed machine time machine operate singlepart time (except bolt weld operate two parts simultaneously).already shown types rewriting rules domain Figures 710. set rules used experiments shown Figure 20. topeight rules quite straightforward one becomes familiar domain. twotop rules explore space alternative orderings originated resource conflicts.machine-swap rule allows system explore possible orderings operationsrequire machine. rule finds two consecutive operations machineswaps order. Similarly, rule object-swap allows system exploreorderings operations object. two rules use interpreted predicateadjacent-in-critical-path focus attention steps contribute costfunction. Adjacent-in-critical-path checks two steps consecutive along onecritical paths schedule. critical path sequence steps take longesttime accomplish. words, critical path one sequences stepsdetermine schedule length.next six rules exchange operators equivalent respect achievingeffects. Rules IP-by-SP SP-by-IP propose exchange immersion-paintspray-paint operators. examining operator definitions Figure 19,readily noticed operators change value painted predicate. Similarly,PU-by-DP DP-by-PU exchange drill-press punch operators, producehas-hole predicate. Finally, roll-by-lathe lathe-by-roll exchange roll latheoperators make parts cylindrical. focus search promising235fiAmbite & Knoblock(define (operator POLISH):parameters (?x):resources ((machine POLISHER) (is-object ?x)):precondition (:and (is-object ?x)(temperature ?x COLD)(has-clamp POLISHER)):effect(:and (:forall (?surf)(:when (:neq ?surf POLISHED)(:not (surface-condition ?x ?surf)))(surface-condition ?x POLISHED)))(define (operator GRIND):parameters (?x):resources ((machine GRINDER) (is-object ?x)):precondition (is-object ?x):effect(:and (:forall (?color)(:not (painted ?x ?color)))(:forall (?surf)(:when (:neq ?surf SMOOTH)(:not (surface-condition ?x ?surf))))(surface-condition ?x SMOOTH)))(define (operator LATHE):parameters (?x):resources ((machine LATHE) (is-object ?x)):precondition (is-object ?x):effect(:and (:forall (?color)(:not (painted ?x ?color)))(:forall (?shape)(:when (:neq ?shape CYLINDRICAL)(:not (shape ?x ?shape))))(:forall (?surf)(:when (:neq ?surf ROUGH)(:not (surface-condition ?x ?surf))))(surface-condition ?x ROUGH)(shape ?x CYLINDRICAL)))(define (operator ROLL):parameters (?x):resources ((machine ROLLER) (is-object ?x)):precondition (is-object ?x):effect(:and (:forall (?color)(:not (painted ?x ?color)))(:forall (?shape)(:when (:neq ?shape CYLINDRICAL)(:not (shape ?x ?shape))))(:forall (?temp)(:when (:neq ?temp HOT)(:not (temperature ?x ?temp))))(:forall (?surf)(:not (surface-condition ?x ?surf)))(:forall (?width ?orientation)(:not (has-hole ?x ?width ?orientation)))(temperature ?x HOT)(shape ?x CYLINDRICAL)))(define (operator DRILL-PRESS):parameters (?x ?width ?orientation):resources ((machine DRILL-PRESS)(is-object ?x)):precondition(:and (is-object ?x)(have-bit ?width)(is-drillable ?x ?orientation)):effect (has-hole ?x ?width ?orientation))(define (operator PUNCH):parameters (?x ?width ?orientation):resources ((machine PUNCH) (is-object ?x)):precondition(:and (is-object ?x)(has-clamp PUNCH)(is-punchable ?x ?width ?orientation)):effect(:and (:forall (?surf)(:when (:neq ?surf ROUGH)(:not (surface-condition ?x ?surf))))(surface-condition ?x ROUGH)(has-hole ?x ?width ?orientation)))Figure 18: Operators Manufacturing Process Planning (I)exchanges rules match operators critical path (by means interpretedpredicate in-critical-path).six bottom rules Figure 20 sophisticated. lathe+SP-by-SP ruletakes care undesirable effect simple depth-first search used initial plangenerator. domain, order spray paint part, part must regular shape.cylindrical regular shape, therefore initial planner may decide makepart cylindrical lathing order paint it! However, may necessarypart may already regular shape (for example, could rectangular, alsoregular shape). Thus, lathe+SP-by-SP substitutes pair spray-paint lathesingle spray-paint operation. supporting regular-shapes interpreted predicate236fiPlanning Rewriting(define (operator IMMERSION-PAINT):parameters (?x ?color):resources ((machine IMMERSION-PAINTER)(is-object ?x)):precondition(:and (is-object ?x)(have-paint-for-immersion ?color)):effect (painted ?x ?color))(define (operator SPRAY-PAINT):parameters (?x ?color ?shape):resources ((machine SPRAY-PAINTER)(is-object ?x)):precondition (:and (is-object ?x)(sprayable ?color)(temperature ?x COLD)(regular-shape ?shape)(shape ?x ?shape)(has-clamp SPRAY-PAINTER)):effect (painted ?x ?color))(define (operator BOLT)(define (operator WELD):parameters (?x ?y ?new-obj ?orient ?width):parameters (?x ?y ?new-obj ?orient):resources ((machine BOLTER):resources ((machine WELDER)(is-object ?x) (is-object ?y))(is-object ?x) (is-object ?y)):precondition:precondition(:and (is-object ?x) (is-object ?y)(:and (is-object ?x) (is-object ?y)(composite-object ?new-obj ?orient ?x ?y)(composite-object ?new-obj ?orient ?x ?y)(has-hole ?x ?width ?orient)(can-be-welded ?x ?y ?orient))(has-hole ?y ?width ?orient):effect (:and (temperature ?new-obj HOT)(bolt-width ?width)(joined ?x ?y ?orient)(can-be-bolted ?x ?y ?orient))(:not (is-object ?x)):effect (:and (:not (is-object ?x))(:not (is-object ?y))))(:not (is-object ?y))(joined ?x ?y ?orient)))Figure 19: Operators Manufacturing Process Planning (II)enumerates regular shapes. rules partially specifiedguaranteed always produce rewriting. Nevertheless, often successfulproducing plans lower cost.remaining rules explore bolting two parts using bolts different size fewer operations may needed plan. developed rules analyzing differencesquality optimal plans rewritten plans. example, considerboth-providers-diff-bolt rule. rule states parts bolted alreadycompatible holes them, better reuse operators producedholes. initial plan generator may drilled (or punched) holes whose purposebolt parts. However, goal problem may already require holesperformed parts joined. Reusing available holes produces economical plan. rules has-hole-x-diff-bolt-add-PU, has-hole-x-diff-bolt-add-DP,has-hole-y-diff-bolt-add-PU, has-hole-y-diff-bolt-add-DP address casesone holes reused, thus additional punch drill-pressoperation needs added.illustration rewriting process manufacturing domain, consider Figure 21. plan top figure result simple initial plan generatorsolves part independently concatenates corresponding subplans. Althoughplan generated efficiently, poor quality. requires six time-steps manufacture parts. figure shows application two rewriting rules, machine-swapIP-by-SP, improve quality plan. operators matched rule antecedent shown italics. operators introduced rule consequent shownbold. First, machine-swap rule reorders punching operations parts B.237fiAmbite & Knoblock(define-rule :name machine-swap:if (:operators ((?n1 (machine ?x) :resource)(?n2 (machine ?x) :resource)):links ((?n1 :threat ?n2)):constraints(adjacent-in-critical-path ?n1 ?n2)):replace (:links (?n1 ?n2)):with (:links (?n2 ?n1)))(define-rule :name object-swap:if (:operators ((?n1 (is-object ?x) :resource)(?n2 (is-object ?x) :resource)):links ((?n1 :threat ?n2)):constraints(adjacent-in-critical-path ?n1 ?n2)):replace (:links (?n1 ?n2)):with (:links (?n2 ?n1)))(define-rule :name SP-by-IP(define-rule :name IP-by-SP:if (:operators (?n1 (spray-paint ?x ?c ?s)):if (:operators (?n1 (immersion-paint ?x ?c)):constraints ((in-critical-path ?n1))):constraints ((regular-shapes ?s):replace (:operators (?n1))(in-critical-path ?n1))):with (:operators (?n2 (immersion-paint ?x ?c)))):replace (:operators (?n1)):with (:operators (?n2 (spray-paint ?x ?c ?s))))(define-rule :name DP-by-PU(define-rule :name PU-by-DP:if (:operators ((?n1 (drill-press ?x ?w ?o))):if (:operators (?n1 (punch ?x ?w ?o)):constraints ((in-critical-path ?n1))):constraints ((in-critical-path ?n1))):replace (:operators (?n1)):replace (:operators (?n1)):with (:operators (?n2 (punch ?x ?w ?o)))):with (:operators (?n2 (drill-press ?x ?w ?o))))(define-rule :name roll-by-lathe:if (:operators ((?n1 (roll ?x))):constraints ((in-critical-path ?n1))):replace (:operators (?n1)):with (:operators (?n2 (lathe ?x))))(define-rule :name lathe-by-roll:if (:operators ((?n1 (lathe ?x))):constraints ((in-critical-path ?n1))):replace (:operators (?n1)):with (:operators (?n2 (roll ?x))))(define-rule :name both-providers-diff-bolt(define-rule :name lathe+SP-by-SP:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1))):if (:operators:links ((?n1 (has-hole ?x ?w1 ?o) ?n3)((?n1 (lathe ?x))(?n2 (has-hole ?y ?w1 ?o) ?n3)(?n2 (spray-paint ?x ?color ?shape1)))(?n4 (has-hole ?x ?w2 ?o) ?n5):constraints ((regular-shapes ?shape2)))(?n6 (has-hole ?y ?w2 ?o) ?n7)):replace (:operators (?n1 ?n2)):constraints ((:neq ?w1 ?w2))):with (:operators((?n3 (spray-paint ?x ?color ?shape2))))) :replace (:operators (?n1 ?n2 ?n3)):with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2))):links ((?n4 (has-hole ?x ?w2 ?o) ?n8)(?n6 (has-hole ?y ?w2 ?o) ?n8))))(define-rule :name has-hole-x-diff-bolt-add-DP(define-rule :name has-hole-x-diff-bolt-add-PU:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1))):if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1))):links ((?n1 (has-hole ?x ?w1 ?o) ?n3):links ((?n1 (has-hole ?x ?w1 ?o) ?n3)(?n2 (has-hole ?y ?w1 ?o) ?n3)(?n2 (has-hole ?y ?w1 ?o) ?n3)(?n4 (has-hole ?x ?w2 ?o) ?n5))(?n4 (has-hole ?x ?w2 ?o) ?n5)):constraints ((:neq ?w1 ?w2))):constraints ((:neq ?w1 ?w2))):replace (:operators (?n1 ?n2 ?n3)):replace (:operators (?n1 ?n2 ?n3)):with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2)):with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2))(?n6 (drill-press ?y ?w2 ?o)))(?n6 (punch ?y ?w2 ?o))):links ((?n4 (has-hole ?x ?w2 ?o) ?n8):links ((?n4 (has-hole ?x ?w2 ?o) ?n8)(?n6 (has-hole ?y ?w2 ?o) ?n8))))(?n6 (has-hole ?y ?w2 ?o) ?n8))))(define-rule :name has-hole-y-diff-bolt-add-DP(define-rule :name has-hole-y-diff-bolt-add-PU:if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1))):if (:operators ((?n3 (bolt ?x ?y ?z ?o ?w1))):links ((?n1 (has-hole ?x ?w1 ?o) ?n3):links ((?n1 (has-hole ?x ?w1 ?o) ?n3)(?n2 (has-hole ?y ?w1 ?o) ?n3)(?n2 (has-hole ?y ?w1 ?o) ?n3)(?n6 (has-hole ?y ?w2 ?o) ?n7))(?n6 (has-hole ?y ?w2 ?o) ?n7)):constraints ((:neq ?w1 ?w2))):constraints ((:neq ?w1 ?w2))):replace (:operators (?n1 ?n2 ?n3)):replace (:operators (?n1 ?n2 ?n3)):with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2)):with (:operators ((?n8 (bolt ?x ?y ?z ?o ?w2))(?n4 (drill-press ?x ?w2 ?o)))(?n4 (punch ?x ?w2 ?o))):links ((?n4 (has-hole ?x ?w2 ?o) ?n8):links ((?n4 (has-hole ?x ?w2 ?o) ?n8)(?n6 (has-hole ?y ?w2 ?o) ?n8))))(?n6 (has-hole ?y ?w2 ?o) ?n8))))Figure 20: Rewriting Rules Manufacturing Process Planning238fiPlanning RewritingLatheIPaint RedPunch 2Punch C 1IPaint C BlueRoll BIPaint B RedReorder Parts MachineLatheIPaint RedPunch C 1Cost: 6Punch 2Cost: 4IPaint C BlueIPaint B RedRoll BImmersion-Paint => Spray-PaintLatheRoll BIPaint RedPunch 2Punch C 1IPaint C BlueCost: 3Spray-Paint B RedFigure 21: Rewriting Manufacturing Domainbreaks long critical path resulted simple concatenation respectivesubplans. schedule length improves six four time-steps. Still, three partsA, B, C use painting operation (immersion-paint). immersion-painterprocess one piece time, three operations must done serially. Fortunately, domain another painting operation: spray-paint. IP-by-SPrule takes advantage fact substitutes immersion-paint operation part Bspray-paint operation. parallelizes plan obtaining schedule lengththree time-steps, optimal plan.compare four planners (IPP, Initial, two configurations PbR):IPP: one efficient domain-independent planners (Koehler, Nebel, Hoffman, & Dimopoulos, 1997) planning competition held Fourth InternationalConference Artificial Intelligence Planning Systems (AIPS-98). IPP optimized reimplementation extension Graphplan (Blum & Furst, 1995, 1997). IPP producesshortest parallel plans. manufacturing domain, exactly schedule length,cost function optimizing.Initial: initial plan generator uses divide-and-conquer heuristic order generateplans fast possible. First, produces subplans part joined goalsindependently. subplans generated Sage using depth-first search withoutregard plan cost. Then, concatenates subsequences actions mergesusing facilities Section 3.4.2.PbR: present results two configurations PbR, refer PbR-100PbR-300. configurations use first improvement gradient search strategyrandom walk cost plateaus. rewriting rules used Figure 20.problem PbR starts search plan generated Initial. two configurationsdiffer many total plateau plans allowed. PbR-100 allows considering100 plans improve cost without terminating search. Similarly, PbR239fiAmbite & Knoblock300 allows 300 plateau plans. Note limit across plateaus encounteredsearch problem, plateau.tested four systems 200 problems, machining 10 parts, ranging5 50 goals. goals distributed randomly 10 parts. So, 50goal problems, average 5 goals per part. results shown Figure 22.graphs data point average 20 problems given number goals.10 provably unsolvable problems. Initial PbR solved 200 problems (orproved unsolvable). IPP solved 65 problems total: problems 5 10 goals,19 15 goals, 6 20 goals. IPP could solve problem 20 goals1000 CPU seconds time limit.Figure 22(a) shows average time solvable problems problem setfour planners. Figure 22(b) shows average schedule length problems solvedplanners, is, 65 problems solved IPP 20 goals.fastest planner Initial, produces plans cost twice optimal. IPPproduces optimal plans, cannot solve problems 20 goals. twoconfigurations PbR scale much better IPP solving problems producing goodquality plans. PbR-300 matches optimal cost IPP plans, except one problem(the reason difference interesting explain below). faster PbR-100also stays close optimal (less 2.5% average cost difference).Figure 22(c) shows average schedule length problems solvedplanners 50 goal range. PbR configurations scale gracefully acrossrange improving considerably cost plans generated Initial. additionalexploration PbR-300 allows improve plans even further. reasondifference PbR IPP 20-goal complexity level cost resultsIPP 6 problems could solve, results PbR Initialaverage 20 problems (as shown Figure 22(b), PbR matches cost6 optimal plans produced IPP).Figure 22(d) shows average number operators plans problems solvedthree planners (up 20 goals). Figure 22(e) shows average number operatorsplans problems solved planner across whole range 50 problems.plans generated Initial use 2-3 additional operators. PbR IPPproduce plans require fewer steps. Interestingly, IPP sometimes produces plansuse operations PbR. IPP produces shortest parallel plan, oneminimum number steps. particular, observed IPP planssuffer problem Initial. IPP would also lathe part order paintit, opposed Initial would affect optimal schedulelength. Surprisingly, adding additional steps domain may improve schedulelength, albeit fairly rare situations. case problem IPPproduced better schedule PbR-300. could introduced rewriting rulesubstituted immersion-paint operator lathe spray-paint operatorscases. However, rule low utility (in sense Minton, 1988b).expands rewriting search space, adds cost match, randomsearch provides benefit rarely.240fiPlanning RewritingAverage Planning Time (CPU Seconds)1000PbR-FIInitialIPP1001010.10.01010203040506070Number Blocks8090100(a) Average Planning Time40Average Plan Cost (Schedule Length)Average Plan Cost (Schedule Length)9PbR-300PbR-100InitialIPP8765432(b)68101214Number Goals161830252015105205Average Plan Cost(Problems Solved All)(c)24101520253035Number Goals404550Average Plan Cost(Problems Solved Each)6022PbR-300PbR-100InitialIPP20Average Number Plan OperatorsAverage Number Plan OperatorsPbR-300PbR-100InitialIPP0418161412108645550454035PbR-300PbR-100InitialIPP302520151054(d)3568101214Number Goals1618205Number Plan Operators(Problems Solved All)(e)101520253035Number GoalsNumber Plan Operators(Problems Solved Each)Figure 22: Experimental Results: Manufacturing Process Planning241404550fiAmbite & Knoblockexperiment illustrates flexibility PbR specifying complex rules planning domain. results show benefits finding suboptimal initial plan quicklyefficiently transforming improve quality.4.2 Logisticstask logistics domain transport several packages initial locationdesired destinations. used version logistics-strips planning domainAIPS98 planning competition restricted using trucks planes.14domain shown Figure 23. package transported one location anotherloading truck, driving truck destination, unloading truck.truck load number packages. cost function (parallel) time deliverpackages (measured number operators critical path plan).(define (operator LOAD-TRUCK):parameters (?obj ?truck ?loc):precondition(:and (obj ?obj) (truck ?truck) (location ?loc)(at ?truck ?loc) (at ?obj ?loc)):effect (:and (:not (at ?obj ?loc))(in ?obj ?truck)))(define (operator UNLOAD-TRUCK):parameters (?obj ?truck ?loc):precondition(:and (obj ?obj) (truck ?truck) (location ?loc)(at ?truck ?loc) (in ?obj ?truck)):effect (:and (:not (in ?obj ?truck))(at ?obj ?loc)))(define (operator DRIVE-TRUCK):parameters (?truck ?loc-from ?loc-to ?city):precondition (:and (truck ?truck) (location ?loc-from) (location ?loc-to) (city ?city)(at ?truck ?loc-from) (in-city ?loc-from ?city) (in-city ?loc-to ?city)):effect (:and (:not (at ?truck ?loc-from)) (at ?truck ?loc-to)))Figure 23: Operators Logisticscompare three planners domain:IPP:IPP (Koehler et al., 1997) produces optimal plans domain.Initial: initial plan generator picks distinguished location delivers packagesone one starting returning distinguished location. example, assumetruck t1 distinguished location l1, package p1 must delivered locationl2 location l3. plan would be: drive-truck(t1 l1 l2 c), load-truck(p1 t1 l2),drive-truck(t1 l2 l3 c), unload-truck(p1 t1 l3), drive-truck(t1 l3 l1 c).initial plan generator would keep producing circular trips remaining packages.Although algorithm efficient produces plans low quality.PbR: PbR starts plan produced Initial uses plan rewriting rules shownFigure 24 optimize plan quality. loop rule states driving locationreturning back immediately useless. fact operators must adjacentimportant implies intervening load unload performed.vein, triangle rule states better drive directly twolocations third point operation performed point.14. logistics domain AIPS98, problems moving packages plane among different citiestruck among different locations city isomorphic, focused one betteranalyze rewriting rules learned (Ambite, Knoblock, & Minton, 2000).242fiPlanning Rewritingload-earlier rule captures situation package loaded truckfirst time packages location visited. occurs initial plannerconcerned trip another package. unload-later rule captures dual case.PbR applies first improvement search strategy one run (no restarts).(define-rule :name loop:if (:operators((?n1 (drive-truck ?t ?l1 ?l2 ?c))(?n2 (drive-truck ?t ?l2 ?l1 ?c))):links ((?n1 ?n2)):constraints((adjacent-in-critical-path ?n1 ?n2))):replace (:operators (?n1 ?n2)):with NIL)(define-rule :name triangle:if (:operators((?n1 (drive-truck ?t ?l1 ?l2 ?c))(?n2 (drive-truck ?t ?l2 ?l3 ?c))):links ((?n1 ?n2)):constraints((adjacent-in-critical-path ?n1 ?n2))):replace (:operators (?n1 ?n2)):with (:operators((?n3 (drive-truck ?t ?l1 ?l3 ?c)))))(define-rule :name unload-later(define-rule :name load-earlier:if (:operators:if (:operators((?n1 (drive-truck ?t ?l1 ?l2 ?c))((?n1 (drive-truck ?t ?l1 ?l2 ?c))(?n2 (unload-truck ?p ?t ?l2))(?n2 (drive-truck ?t ?l3 ?l2 ?c))(?n3 (drive-truck ?t ?l3 ?l2 ?c)))(?n3 (load-truck ?p ?t ?l2))):links ((?n1 ?n2)):links ((?n2 ?n3)):constraints:constraints((adjacent-in-critical-path ?n1 ?n2)((adjacent-in-critical-path ?n2 ?n3)(before ?n2 ?n3)))(before ?n1 ?n2))):replace (:operators (?n2)):replace (:operators (?n3)):with (:operators ((?n4 (unload-truck ?p ?t ?l2))):with (:operators ((?n4 (load-truck ?p ?t ?l2))):links ((?n3 ?n4)))):links ((?n1 ?n4))))Figure 24: Logistics Rewriting Rules250PbRInitialIPP1000PbRInitialIPP200Average Plan CostAverage Planning Time (CPU Seconds)10000100101150100500.10.010051015 20 25 30 35Number Packages4045500(a) Average Planning Time5101520253035Number Packages404550(b) Average Plan CostFigure 25: Experimental Results: Logistics, Scaling Number Packagescompared performance IPP, Initial, PbR set logistics problemsinvolving 50 packages. problem instance number packages,locations, goals. single truck single city. performance resultsshown Figure 25. graphs data point average 20 problemsgiven number packages. problems satisfiable. IPP could solve243fiAmbite & Knoblockproblems 7 packages (it also solved 10 20 8 packages, 1 209 packages, shown figure). Figure 25(a) shows averageplanning time. Figure 25(b) shows average cost 50 packages range. resultssimilar previous experiment. Initial efficient highly suboptimal. PbRable considerably improve cost plans approach optimal.4.3 Blocks Worldimplemented classical Blocks World domain two operators Figure 2.domain two actions: stack puts one block top another, and, unstackplaces block table start new tower. Plan quality domain simplynumber steps. Optimal planning domain NP-hard (Gupta & Nau, 1992).However, trivial generate correct, suboptimal, plan linear time usingnaive algorithm: put blocks table build desired towers bottomup. compare three planners domain:IPP: experiment used GAM goal ordering heuristic (Koehler, 1998; Koehler& Hoffmann, 2000) tested Blocks World problems good scaling results.Initial: planner programmatic implementation naive algorithm usingfacilities introduced Section 3.4.2.PbR: configuration PbR starts plan produced Initial usestwo plan-rewriting rules shown Figure 6 optimize plan quality. PbR applies firstimprovement strategy one run (no restarts).generated random Blocks World problems scaling number blocks. problemset consists 25 random problems 3, 6, 9, 12, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100blocks total 350 problems. problems may multiple towers initialstate goal state.Figure 26(a) shows average planning time 25 problems block quantity.IPP cannot solve problems 20 blocks within time limit 1000 CPUseconds. problem solving behavior IPP interesting. IPP either solved givenproblem fast timed out. example, able solve 11 25 20block problems 100 seconds, timed 1000 seconds remaining 14problems. seems typical behavior complete search algorithms (Gomes,Selman, & Kautz, 1998). local search PbR allows scale much better solveproblems.Figure 26(b) shows average plan cost number blocks increases. PbRimproves considerably quality initial plans. optimal quality knownsmall problems, PbR approximates it, achieve (we ran Sageproblems less 9 blocks). larger plans know optimal cost. However,Slaney & Thiebaux (1996) performed extensive experimental analysis Blocks Worldplanning using domain like ours. comparison among different approximationalgorithms found initial plan generator (unstack-stack) achieves empiricallyquality around 1.22 optimal range problem sizes analyzed (Figure 7Slaney & Thiebaux, 1996). value average initial plans divided 1.22 suggests244fiPlanning Rewritingquality optimal plans. quality achieved PbR comparable value.fact slightly better may due relatively small number problemstested (25 per block size) skew random problem generator. Interestinglyplans found IPP actually low quality. due fact IPP producesshortest parallel plans. means plans constructed fewest timesteps, IPP may introduce actions time step required.summary, experiments previous sections show across varietydomains PbR scales large problems still producing high-quality plans.180Average Plan Cost (Number Operators)Average Planning Time (CPU Seconds)1000PbR-FIInitialIPP1001010.10.01010203040506070Number Blocks8090PbR-FIInitialIPPInitial/1.221601401201008060402001000(a) Average Planning Time10203040 50 60 70Number Blocks8090100(b) Average Plan CostFigure 26: Experimental Results: Blocks World, Scaling Number Blocks4.4 Query PlanningQuery Planning problem considerable practical importance. central traditionaldatabase mediator systems. section present results distributed queryplanning highlight use PbR domain complex cost function. detaileddescription query planning, including novel query processing algorithm mediatorsbased PbR, extensive experimental analysis appear (Ambite & Knoblock,2000; Ambite, 1998).Query planning involves generating plan efficiently computes user queryrelevant information sources. plan composed data retrieval actions distributed information sources data manipulation operations, relational algebra: join, selection, union, etc. specification operators queryplanning encoding information goals using first introducedKnoblock (1996). sample information goal shown Figure 27. goal asks sendoutput device mediator names airports Tunisia. Two sampleoperators shown Figure 28. retrieve operator executes query remoteinformation source transports data mediator, provided sourceoperation (source-available) source capable processing query(source-acceptable-query). join operator takes two subqueries, availablelocally mediator, combines using conditions produce joinedquery.245fiAmbite & Knoblock(available sims (retrieve (?ap_name)(:and (airport ?aport)(country-name ?aport "Tunisia")(port-name ?aport ?ap_name))))Figure 27: Sample Information Goal(define (operator retrieve):parameters (?source ?query):resources ((processor ?source)):precondition (:and (source-available ?source)(source-acceptable-query ?query ?source)):effect (available sims ?query))(define (operator join):parameters (?join-conds ?query ?query-a ?query-b):precondition (:and (available sims ?query-a(available sims ?query-b)(join-query ?query ?join-conds ?query-a ?query-b)):effect (available sims ?query))Figure 28: Query Planning Operatorsquality distributed query plan estimation execution cost,function size intermediate results, cost performing data manipulationoperations, transmission network intermediate resultsremote sources mediator. system estimates plan cost based statisticsobtained source relations, number tuples relation, numberdistinct values attribute, maximum minimum values numericattributes (Silberschatz, Korth, & Sudarshan, 1997, chapter 12). sources accessed,type ordering data processing operations critical plan cost.rewriting rules derived properties distributed environmentrelational algebra.15 first set rules rely fact that, distributed environment,generally efficient execute group operations together remote information source transmit data network execute operationslocal system. example consider Remote-Join-Eval rule Figure 29 (shownPbR syntax, shown algebraically Figure 1). rule specifiesplan exist two retrieval operations remote database whose resultsconsequently joined remote source capable performing joins, systemrewrite plan one contains single retrieve operation pushes joinremote database.second class rules derived commutative, associative, distributiveproperties operators relational algebra. example, Join-Swap ruleFigure 29 (cf. Figure 1) specifies two consecutive joins operators reorderedallows planner explore space join trees. Since query planning15. mediators, rules address resolution semantic heterogeneity also necessary. See(Ambite & Knoblock, 2000; Ambite, 1998) details.246fiPlanning Rewriting(define-rule :name remote-join-eval(define-rule :name join-swap:if (:operators:if (:operators((?n1 (retrieve ?query1 ?source))((?n1 (join ?q1 ?jc1 ?sq1a ?sq1b))(?n2 (retrieve ?query2 ?source))(?n2 (join ?q2 ?jc2 ?sq2a ?sq2b)))(?n3 (join ?query ?jc ?query1 ?query2))):links (?n2 ?n1):constraints:constraints((capability ?source join)))(join-swappable:replace (:operators (?n1 ?n2 ?n3))?q1 ?jc1 ?sq1a ?sq1b;;:with (:operators?q2 ?jc2 ?sq2a ?sq2b;;((?n4 (retrieve ?query ?source))))?q3 ?jc3 ?sq3a ?sq3b;;?q4 ?jc4 ?sq4a ?sq4b));;:replace (:operators (?n1 ?n2)):with (:operators((?n3 (join ?q3 ?jc3 ?sq3a ?sq3b))(?n4 (join ?q4 ?jc4 ?sq4a ?sq4b))):links (?n4 ?n3)))Figure 29: Query Planning Rewriting Rulesdomain queries expressed complex terms (Knoblock, 1996), PbR rules useinterpreted predicates :constraints field manipulate query expressions.example, join-swappable predicate checks queries two join operatorsexchanged computes new subqueries.Figure 30 shows example local search space query plan rewritings simple distributed domain describes company. figure shows alternativequery evaluation plans conjunctive query asks names employees,salaries, projects working on. three relations requested query(Employees, Payroll, Project) distributed among two databases (one companys headquarters HQ-db another branch Branch-db). Assumeleftmost plan initial plan. plan first retrieves Employee relation HQ-dbProject relation Branch-db, joins two tables employee name. Finally, plan retrieves Payroll relation HQ-db joinsssn result previous join. Although valid plan, initial plan suboptimal. Applying join-swap rule initial plan generates two rewritings. Oneinvolves cross-product, expensive operation, system, following gradient descent search strategy, prefers plan. system appliesremote-join-eval rule generates new rewritten plan evaluates joinemployee project tables remotely headquarters database. final planmuch better quality.compare planning efficiency plan quality four query planners:Sage: original query planner (Knoblock, 1995, 1996) SIMS mediator,performs best-first search heuristic commonly used query optimizationexplores space left join trees. Sage refinement planner (Kambhampati,Knoblock, & Yang, 1995) generates optimal left-tree query plans.DP: implementation dynamic-programming bottom-up enumerationquery plans (Ono & Lohman, 1990) find optimal plan. Since distributeddomain subqueries execute parallel cost function reflects preference,247fiAmbite & Knoblocka(name sal proj) :- Emp(name ssn) ^ Payroll(ssn sal) ^ Projects(name proj)HQ-dbEmp(name ssn)Payroll(ssn sal)name ssnBranch-dbProject(name proj)Ret Emp@ HQ-dbRet Payroll Ret Project@ HQ-db @ Branch-dbssnnameRet Payroll@ HQ-dbJoinSwapnameRemoteJoinEvalnameRet Emp Ret Project@ HQ-db @ Branch-dbssnRet Project@ Branch-dbRet Emp Ret Payroll@ HQ-db @ HQ-dbRet Project@Branch-dbRet (Emp@HQ-dbPayroll)Figure 30: Rewriting Query PlanningDP algorithm considers bushy join trees. However, improve planning time, DPapplies heuristic avoiding cross-products join enumeration. Thus, rarecases DP may produce optimal plan.Initial: initial plan generator PbR. generates query plans accordingrandom depth-first search parse query. non-random choice placesselections soon executed. fastest planner may producelow quality plans.PbR: used Remote-Join-Eval Join-Swap rules defined Figure 29.two rules sufficient optimize queries test set. tested two gradientdescent search strategies PbR: first improvement four random restarts (PbR-FI),steepest descent three random restarts (PbR-SD).experiment compare behavior Sage, DP, Initial, PbR-FI, PbR-SDdistributed query planning domain size queries increases. generatedsynthetic domain SIMS mediator defined set conjunctive queries involving1 30 relations. queries one selection attribute table.information source contains two relations perform remote operations. Therefore,optimal plans involve pushing operations evaluated remotely sources.results experiment shown Figure 31. Figure 31(a) shows planningtime, logarithmic scale, Sage, DP, Initial, PbR-FI, PbR-SD query sizegrows. times PbR include generation random initial plansrewriting. times Initial average initial plan construction acrossrestarts query. Sage able solve queries involving 6 relations, larger248fiPlanning Rewritingqueries cannot solved within search limit 200,000 partial-plan nodes. DP scalesbetter Sage, cannot solve queries 9 relations 1000 second timelimit. configurations PbR scale better Sage DP. first-improvementsearch strategy PbR-FI faster steepest descent PbR-SD.Figure 31(b) shows cost query plans five planners. cost Initialaverage initial plans across restarts query. plan costestimate query execution cost. logarithmic scale used increasinglylarger absolute values plan costs conjunctive chain queries highcost initial plans. PbR rewrites poor quality plans generated Initialhigh-quality plans. PbR DP produce better plans Sage (in rangetractable Sage) experiment. happens searching largerspace bushy query trees take greater advantage parallel execution plans. PbRproduces plans quality comparable DP tractable range beyond rangePbR scales gracefully. two configurations PbR produce plans similar cost, thoughPbR-FI needed less planning time PbR-SD. PbR-SD generates plans localneighborhood order select cheapest one, PbR-FI generates portionneighborhood since chooses first plan cheaper cost, PbR-FI fasteraverage. Figure 31 shows empirically domain locally optimal movessteepest descent translate final solutions better cost producedfirst-improvement strategy.10001e+18SageDPInitialPbR-FIPbR-SD1001e+141e+1210Plan CostPlanning Time (CPU seconds)1e+161SageDPInitialPbR-FIPbR-SD0.11e+101e+081e+06100001000.011051015Query Size2025300(a) Planning Time51015Query Size202530(b) Plan QualityFigure 31: Experimental Results: Distributed Query Planning5. Related Worksection review previous work related Planning Rewriting framework.First, discuss work disciplines upon PbR builds, namely, classical AIplanning, local search, graph rewriting. Then, discuss work related planrewriting algorithm.249fiAmbite & Knoblock5.1 AI PlanningPbR designed find balance among requirements planning efficiency, high qualityplans, flexibility, extensibility. great amount work AI Planning focusedimproving average-case efficiency given general cases computationally hard(Erol et al., 1995). One possibility incorporate domain knowledge form searchcontrol. recent example TLPlan (Bacchus & Kabanza, 1995, 2000), forward-searchplanner shown remarkable scalability using control knowledge expressed temporal logic. systems automatically learn search control given planning domaineven specific problem instances. Minton (1988b) shows deduce search control rulesproblem solver applying explanation-based learning problem-solving traces.also discusses impact utility problem. utility problem, simply stated, says(computational) benefits using additional knowledge must outweigh costapplying it. PbR plan-rewriting rules also subject utility problem. qualityimprovement obtained adding rewriting rules PbR-based planner mayworth performance degradation. Another approach automatically generating searchcontrol analyzing statically operators (Etzioni, 1993) inferring invariantsplanning domain (Gerevini & Schubert, 1998; Fox & Long, 1998; Rintanen, 2000). Abstraction provides yet another form search control. Knoblock (1994a) presents systemautomatically learns abstraction hierarchies planning domain particular probleminstance order speed planning. plan-rewriting rules learned techniquesanalogous used learn search control. Ambite, Knoblock, & Minton (2000) presentapproach automatically learn plan-rewriting rules based comparing initialoptimal plans example problems. Alternatively, analyzing planning operatorscombinations operators equivalent respect achievementgoals also lead automatic generation rewriting rules.Local search algorithms also used improve planning efficiency althoughsomewhat indirect way. Planning reduced solving series propositionalsatisfiability problems (Kautz & Selman, 1992). Thus, Kautz & Selman (1996) usedefficient satisfiability testing algorithm based local search solve SAT encodingsplanning problem. approach proved efficient specialized planningalgorithms. believe power approach stems use local search.PbR directly applies local search plan structures, opposed translating firstlarger propositional representation.Although approaches improve efficiency planning, specifically address plan quality, else consider simple cost metrics (suchnumber steps). systems learn search control addresses planning efficiencyplan quality (Estlin & Mooney, 1997; Borrajo & Veloso, 1997; Perez, 1996). However,reported experimental results, PbR appears scalable. Moreover, PbRprovides anytime algorithm approaches must run completion.5.2 Local SearchLocal search long tradition combinatorial optimization (Aarts & Lenstra, 1997;Papadimitriou & Steiglitz, 1982). Local improvement ideas found application many250fiPlanning Rewritingdomains. general work relevant PbR constraint satisfaction,scheduling, satisfiability testing, heuristic search.constraint satisfaction, local search techniques able solve problemsorders magnitude complex respective complete (backtracking) approaches.Minton et al. (Minton, Johnston, Philips, & Laird, 1990; Minton, 1992) developed simplerepair heuristic, min-conflicts, could solve large constraint satisfaction schedulingproblems, scheduling operations Hubble Space Telescope. minconflicts heuristic selects variable value assignment minimizes numberconstraints violated. heuristic used cost function gradient-descentsearch also informed backtracking search.satisfiability testing similar method, GSAT, introduced Selman, Levesque,& Mitchell (1992). GSAT solves hard satisfiability problems using local searchrepairs consist changing truth value randomly chosen variable. cost functionnumber clauses satisfied current truth assignment. approach scalesmuch better corresponding complete method (the Davis-Putnam procedure).work scheduling rescheduling, Zweben, Daun, & Deale (1994) define setgeneral, fixed, repair methods, use simulated annealing search spaceschedules. plans networks actions opposed metric-time totally-orderedtasks. Also easily specify different rewriting rules (general specific) suitdomain, opposed fixed strategies.work inspired approaches several differences. First, PbRoperates complex graph structures (partial-order plans) opposed variable assignments. Second, repairs declaratively specified may changed problemdomain, opposed general fixed repair strategies. Third, PbR accepts arbitrary measures quality, constraint violations min-conflicts, numberunsatisfied clauses GSAT. Finally, PbR searches space valid solution plans,opposed space variable assignments may internally inconsistent.Iterative repair ideas also used heuristic search. Ratner & Pohl (1986)present two-phase approach similar PbR. first phase, find initial validsequence operators using approximation algorithm. second phase, performlocal search starting initial sequence. cost function plan length.local neighborhood generated identifying segments current solution sequenceattempting optimize them. repair consists heuristic search initialstate beginning segment goal end segment. shorterpath found, original sequence replaced new shorter segment. significantdifference PbR state-space search, PbR planspace search. least-committed partial-order nature PbR allows optimizeplans ways cannot achieved optimizing linear subsequences.5.3 Graph RewritingPbR builds ideas graph rewriting (Schurr, 1997). plan-rewriting rulesPbR extension traditional graph rewriting rules. taking advantagesemantics planning PbR introduces partially-specified plan-rewriting rules,rules need specify completely detailed embedding consequent pure251fiAmbite & Knoblockgraph rewriting. Nevertheless, several techniques transfer graphrewriting Planning Rewriting, particularly fully-specified rules. Dorr (1995)defines abstract machine graph isomorphism studies set conditionstraditional graph rewriting performed efficiently. Perhaps similar abstractmachine plan rewriting defined. idea rule programs also appearsfield implemented PROGRES system (Schurr, 1990, 1997).5.4 Plan Rewritingwork closely related plan-rewriting algorithm plan merging (Foulser, Li, &Yang, 1992). Foulser et al. provide formal analysis algorithms exploiting positiveinteractions within plan across set plans. However, work considerscase set operators replaced one operator provideseffects rest plan consumes fewer preconditions. focusoptimal approximate algorithms type operator merging. Plan rewritingPbR seen generalization operator merging subplan replaceanother subplan. difference PbR concerned finding optimal merge(rewritten plan) single pass optimization algorithm approach does.PbR interested generating possible plan rewritings rewriting phase,optimal one. optimization occurs (local) search progresses.Case-based planning (e.g., Kambhampati, 1992; Veloso, 1994; Nebel & Koehler, 1995;Hanks & Weld, 1995; Munoz-Avila, 1998) solves problem modifying previous solution.two phases case-based planning. first one identifies plan librarysimilar current problem. second phase previous plan adaptedsolve new problem. PbR modifies solution current problem,need retrieval phase associated similarity metrics. Plan rewriting PbRseen type adaptation solution problem alternate solutionproblem. is, plan rewriting rule PbR identifies pair subplans (thereplaced replacement subplans) may interchangeable.Veloso (1994) describes general approach case-based planning based derivationalanalogy. approach works three steps. First, retrieval phase selects similarplan library. Second, parts plan irrelevant current problemremoved. Finally, system searches completion plan selecting muchpossible decisions old plan did. sense planning knowledgeencoded previous solution transferred generation new solution plan.plan-rewriting algorithm partially-specified rules PbR seen stronglyconstrained version approach. PbR subplan rule consequent fixessteps added repair plan. could use technique respectingprevious choice points completing plan way ensuringstructure plan repair maintained. could usefulconstrain number rewritten plans large rewriting rules.Nebel Koehler (1995) present computational analysis case-based planning.context show worst-case complexity plan modification betterplan generation point limitations reuse methods. related problemPbR framework embedding replacement subplan partially specified rules.252fiPlanning Rewritingexplained Section 3.1.4 may pathological cases numberembeddings exponential size plan deciding embedding existsNP-hard. However, often interested finding rewritings, examplefollowing first improvement search strategy. experience average case behaviorseems much better presented Section 4.Systematic algorithms case-based planning (such Hanks & Weld, 1995) invertdecisions done refinement planning find path solution similar oldproblem new problem. rewriting rules PbR indicate transformsolution another solution plan based domain knowledge, opposed genericinversion refinement operations. Plan rewriting PbR done constrainedway instead open search space partial plans. However, rulesPBR may search space rewritings non systematically. effect amelioratedusing local search.6. Discussion Future Workpaper presented Planning Rewriting, new paradigm efficient high-qualitydomain-independent planning. PbR adapts graph rewriting local search techniquessemantics domain-independent partial-order planning. basic idea PbRconsists transforming easy-to-generate, possibly suboptimal, initial planhigh-quality plan applying declarative plan-rewriting rules iterative repair style.several important advantages PbR planning approach. First, PbRdeclarative domain-independent framework, brings benefits reusabilityextensibility. Second, addresses sophisticated plan quality measures, workdomain-independent planning addressed quality simple ways.Third, PbR scalable uses efficient local search methods. Finally, PbRanytime planning algorithm allows balancing planning effort plan quality ordermaximize utility planning process.Planning Rewriting provides domain-independent framework local search. PbRaccepts declarative domain specifications expressive operator language, declarativeplan-rewriting rules generate neighborhood plan, complex quality metrics, interchangeable initial plan generators, arbitrary (local) search methods.Planning Rewriting well suited mixed-initiative planning. mixed-initiativeplanning, user planner interact defining plan. example, userspecify available preferred actions moment, change quality criteria interest, etc. fact, domains approached mixed-initiativeplanning. example, quality metric expensive evaluate,geometric analysis manufacturing, user must guide planner towards good qualityplans way small number plans generated evaluated. Another exampleplan quality metric multi-objective changes time. Several characteristics PbR support mixed-initiative planning. First, PbR offers complete plans,user easily understand plan perform complex quality assessment. Second,rewriting rule language convenient mechanism user propose modifications plans. Third, selecting rules apply order applicationuser guide planner.253fiAmbite & Knoblockframework achieves balance domain knowledge, expressed plan-rewritingrules, general local-search techniques proved useful many hard combinatorial problems. expect ideas push frontier solvable problemsmany practical domains high quality plans anytime behavior needed.planning style introduced PbR opens several areas future research.great potential applying machine learning techniques PbR. important issuegeneration plan-rewriting rules. Conceptually, plan-rewriting rules arisechosen plan equivalence relation. valid plans achieve given goals finitenumber steps, i.e. solution plans, (satisfiability) equivalent. rule arisestheorem states two subplans equivalent purposes achievinggoals, addition conditions indicate context ruleusefully applied. plan-rewriting rules generated automated procedures.methods range static analysis domain operators analysis sampleequivalent plans achieve goals different costs. Note similaritymethods automatically infer search control domain invariants (Minton, 1988b;Etzioni, 1993; Gerevini & Schubert, 1998; Fox & Long, 1998; Rintanen, 2000), alsoneed deal utility problem. Ambite, Knoblock, & Minton (2000) presentresults learning plan rewriting rules based comparing initial optimal planssample problems.Beyond learning rewriting rules, intend develop system automatically learn optimal planner configuration given planning domain problemdistribution manner analogous Mintons Multi-TAC system (Minton, 1996).system would perform search configuration space PbR planner proposingcandidate sets rewriting rules different search methods. testing proposedconfiguration training set simple problems, system would hill-climbconfiguration space order arrive useful rewriting rules search strategiesgiven planning domain distribution problems.many advanced techniques local search literature adaptedextended framework. particular, idea variable-depth rewriting leadsnaturally creation rule programs, specify set rules appliedplan. already seen query planning could find transformationsbetter specified program simple rewriting rules. example, sequenceJoin-Swap transformations may put two retrieve operators database togetherquery tree Remote-Join-Eval would collapse explicit join operatortwo retrieves single retrieval remote join. Cherniack & Zdonik (1996, 1998)present complex examples sort programs rewriting rules contextquery optimizer object-oriented databases.discussed Sections 3.1.3 3.1.4 language antecedent rewriting rules expressive conjunctive queries still remaining computationally efficient. example, Figure 32 shows rule manufacturing domainSection 4.1 relationally-complete antecedent. rule matches subplan contains spray-paint operator, contain either punch drill-press operatorscreate holes diameter smaller 1 millimeter. case, rule replacesspray-paint operator immersion-paint operator. rule would usefulsituation painting immersion could clog small holes.254fiPlanning Rewriting(define-rule :name SP-by-IP-no-small-holes:if (:and (:operator ?n1 (spray-paint ?x ?c ?s))(:not (:and (:or (:operator ?n2 (punch ?x ?w ?o))(:operator ?n3 (drill-press ?x ?w ?o)))(:less ?w 1mm)))):replace (:operators (?n1)):with (:operator ?n4 (immersion-paint ?x ?c)))Figure 32: Rule Relationally-Complete AntecedentAnother area research interplay plan rewriting plan execution.Sometimes best transformations plan may known portionplan executed. information obtained run-time guide plannerselect appropriate rewritings. example, query planning plans may containinformation gathering actions (Ashish, Knoblock, & Levy, 1997) depend run-timeconditions. yields form dynamic query optimization. Interleaved planningexecution also necessary order deal effectively unexpected situationsenvironment database network failures.open area research relax framework accept incomplete plansrewriting process. expands search space considerably benefitsPbR, anytime property, lost. domains shortest pathrewritings initial plan optimal may pass incomplete inconsistentplans. idea could embodied planning style combines characteristicsgenerative planning Planning Rewriting. reminiscent plan criticsapproach (Sacerdoti, 1975; Sussman, 1975). resulting plan-rewriting rules seendeclarative specifications plan critics. plan refinements partial orderplanning (Kambhampati et al., 1995) Hierarchical Task Network Planning (Erol, Nau,& Hendler, 1994) easily specified plan-rewriting rules.Applying PbR domains surely provide new challenges possibilitydiscovering transferring general planning techniques one domain another.hope local-search methods used PbR help planning techniques scalelarge practical problems conversely domain-independent nature PbRhelp analysis principled extension local search techniques.Acknowledgmentspaper extended version (Ambite & Knoblock, 1997).research reported supported part Fulbright/Ministerio EducacionCiencia Spain scholarship, part Defense Advanced Research Projects Agency(DARPA) Air Force Research Laboratory, Air Force Materiel Command, USAF,agreement number F30602-00-1-0504, part National Science Foundationgrant number IRI-9313993, part Rome Laboratory Air Force Systems Command Defense Advanced Research Projects Agency (DARPA) contract numbers F30602-94-C-0210, F30602-97-2-0352, F30602-97-2-0238, F30602-98-2-0109, partUnited States Air Force contract number F49620-98-1-0046, partIntegrated Media Systems Center, National Science Foundation Engineering Research255fiAmbite & KnoblockCenter, Cooperative Agreement No. EEC-9529152. U.S.Government authorizedreproduce distribute reports Governmental purposes notwithstanding copyrightannotation thereon. views conclusions contained herein authorsinterpreted necessarily representing official policies endorsements,either expressed implied, organizations person connectedthem.ReferencesAarts, E., & Lenstra, J. K. (1997). Local Search Combinatorial Optimization. John WileySons, Chichester, England.Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison-Wesley.Ambite, J. L. (1998). Planning Rewriting. Ph.D. thesis, University Southern California.Ambite, J. L., & Knoblock, C. A. (1997). Planning rewriting: Efficiently generatinghigh-quality plans. Proceedings Fourteenth National Conference ArtificialIntelligence, pp. 706713 Providence, RI.Ambite, J. L., & Knoblock, C. A. (2000). Flexible scalable cost-based query planningmediators: transformational approach. Artificial Intelligence, 118 (1-2), 115161.Ambite, J. L., Knoblock, C. A., & Minton, S. (2000). Learning plan rewriting rules.Proceedings Fifth International Conference Artificial Intelligence PlanningScheduling Systems Breckenridge, CO.Ashish, N., Knoblock, C. A., & Levy, A. (1997). Information gathering plans sensingactions. Steel, S., & Alami, R. (Eds.), Recent Advances AI Planning: 4thEuropean Conference Planning, ECP97. Springer-Verlag, New York.Avenhaus, J., & Madlener, K. (1990). Term rewriting equational reasoning. FormalTechniques Artificial Intelligence, pp. 143. Elsevier, North Holland.Baader, F., & Nipkow, T. (1998). Term Rewriting That. Cambridge UniversityPress.Bacchus, F., & Kabanza, F. (1995). Using temporal logic control search forwardchaining planner. Proceedings 3rd European Workshop Planning.Bacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledge planning. Artificial Intelligence, 116 (12), 123191.Backstrom, C. (1994a). Executing parallel plans faster adding actions. Cohn, A. G.(Ed.), Proceedings Eleventh European Conference Artificial Intelligence, pp.615619 Amsterdam, Netherlands. John Wiley Sons.Backstrom, C. (1994b). Finding least constrained plans optimal parallel executionsharder thought. Backstrom, C., & Sandewell, E. (Eds.), Current TrendsAI Planning: Proceedings 2nd European Workshop Planning (EWSP-93),pp. 4659 Vadstena, Sweeden. IOS Press (Amsterdam).256fiPlanning RewritingBackstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. ComputationalIntelligence, 11 (4), 625655.Blum, A. L., & Furst, M. L. (1995). Fast planning planning graph analysis.Proceedings Fourteenth International Joint Conference Artificial IntelligenceMontreal, Canada.Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90 (12), 281300.Bonet, B., & Geffner, H. (1999). Planning heuristic search: New results. ProceedingsFifth European Conference Planning (ECP-99) Durham, UK.Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism planning. Proceedings Fourteenth National Conference ArtificialIntelligence, pp. 714719 Providence, RI.Borrajo, D., & Veloso, M. (1997). Lazy incremental learning control knowledgeefficiently obtaining quality plans. AI Review, 11, 371405.Bylander, T. (1994). computation complexity propositional strips. Artificial Intelligence, 69 (1-2), 165204.Carbonell, J. G., Knoblock, C. A., & Minton, S. (1991). PRODIGY: integrated architecture planning learning. VanLehn, K. (Ed.), Architectures Intelligence,pp. 241278. Lawrence Erlbaum, Hillsdale, NJ.Cherniack, M., & Zdonik, S. B. (1996). Rule languages internal algebras rule-basedoptimizers. SIGMOD Record (ACM Special Interest Group Management Data),25 (2), 401412.Cherniack, M., & Zdonik, S. B. (1998). Changing rules: Transformations rulebased optimizers. Proceedings ACM SIGMOD International ConferenceManagement Data, pp. 6172 Seattle, WA.Dean, T., & Boddy, M. (1988). analysis time-dependent planning. ProceedingsSeventh National Conference Artificial Intelligence, pp. 4954 Saint Paul, MN.Dorr, H. (1995). Efficient graph rewriting implementation, Vol. 922 Lecture NotesComputer Science. Springer-Verlag Inc., New York, NY, USA.Erol, K., Nau, D., & Hendler, J. (1994). UMCP: sound complete planning procedurehierarchical task-network planning. Proceedings Second InternationalConference Artificial Intelligence Planning Systems, pp. 249254 Chicago, IL.Erol, K., Nau, D., & Subrahmanian, V. S. (1995). Decidability undecidability resultsdomain-independent planning. Artificial Intelligence, 76 (1-2), 7588.Estlin, T. A., & Mooney, R. J. (1997). Learning improve efficiency qualityplanning. Proceedings Fifteenth International Joint Conference ArtificialIntelligence, pp. 12271233 Nagoya, Japan.257fiAmbite & KnoblockEtzioni, O. (1993). Acquiring search-control knowledge via static analysis. Artificial Intelligence, 62 (2), 255302.Etzioni, O., & Weld, D. S. (1994). softbot-based interface Internet. Communications ACM, 37 (7).Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach applicationtheorem proving problem solving. Artificial Intelligence, 2 (3/4), 189208.Forgy, C. L. (1982). Rete: fast algorithm many pattern/many object patternmatch problem. Artificial Intelligence, 19, 1737.Foulser, D. E., Li, M., & Yang, Q. (1992). Theory algorithms plan merging. ArtificialIntelligence, 57 (23), 143182.Fox, M., & Long, D. (1998). automatic inference state invariants TIM. JournalArtificicial Intelligence Research, 9, 367421.Gerevini, A., & Schubert, L. (1998). Inferring state constraints domain-independentplanning. Proceedings Fifteenth National Conference Artificial Intelligence, pp. 905912 Madison, WI.Glover, F. (1989). Tabu searchPart I. ORSA Journal Computing, 1 (3), 190206.Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial searchrandomization. Proceedings Fifteenth National Conference Artificial Intelligence Madison, WI.Gupta, N., & Nau, D. S. (1992). complexity blocks-world planning. ArtificialIntelligence, 56 (23), 223254.Hanks, S., & Weld, D. S. (1995). domain-independent algorithm plan adaptation.Journal Artificicial Intelligence Research, 2, 319360.Johnson, D. S. (1990). Local optimization traveling salesman problem. Paterson,M. S. (Ed.), Automata, Languages Programming: Proc. 17th InternationalColloquium, pp. 446461. Springer, New York.Kambhampati, S. (1992). validation-structure-based theory plan modificationreuse. Artificial Intelligence, 55 (2-3), 193258.Kambhampati, S., Knoblock, C. A., & Yang, Q. (1995). Planning refinement search:unified framework evaluating design tradeoffs partial order planning.Artificial Intelligence, 76 (1-2), 167238.Kautz, H., & Selman, B. (1992). Planning satisfiability. Neumann, B. (Ed.), Proceedings 10th European Conference Artificial Intelligence, pp. 359363 Vienna,Austria. John Wiley & Sons.258fiPlanning RewritingKautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic,stochastic search. Proceedings Thirteenth National Conference ArtificialIntelligence, pp. 11941201 Portland, OR.Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization simulated annealing.Science, 220, 671680.Knoblock, C. A. (1994a). Automatically generating abstractions planning. ArtificialIntelligence, 68 (2), 243302.Knoblock, C. A. (1994b). Generating parallel execution plans partial-order planner. Proceedings Second International Conference Artificial IntelligencePlanning Systems Chicago, IL.Knoblock, C. A. (1995). Planning, executing, sensing, replanning information gathering. Proceedings Fourteenth International Joint Conference ArtificialIntelligence Montreal, Canada.Knoblock, C. A. (1996). Building planner information gathering: reporttrenches. Proceedings Third International Conference Artificial Intelligence Planning Systems Edinburgh, Scotland.Koehler, J. (1998). Solving complex planning tasks extraction subproblems.Simmons, R., Veloso, M., & Smith, S. (Eds.), Proceedings Fourth InternationalConference Artificial Intelligence Planning Systems, pp. 6269 Pittsburgh, PA.Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings useagenda-driven planning algorithm. Journal Artificial Intelligence Research,12, 338386.Koehler, J., Nebel, B., Hoffman, J., & Dimopoulos, Y. (1997). Extending planning graphsADL subset. Steel, S., & Alami, R. (Eds.), Proceedings Fourth EuropeanConference Planning (ECP-97): Recent Advances AI Planning, Vol. 1348LNAI, pp. 273285 Berlin. Springer.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsNinth National Conference Artificial Intelligence Anaheim, CA.Minton, S. (1988a). Learning Effective Search Control Knowledge: Explanation-BasedApproach. Ph.D. thesis, Computer Science Department, Carnegie Mellon University.Minton, S. (1988b). Learning Search Control Knowledge: Explanation-Based Approach.Kluwer, Boston, MA.Minton, S. (1992). Minimizing conflicts: heuristic repair method constraintsatisfaction scheduling problems. Artificial Intelligence, 58 (1-3), 161205.Minton, S. (1996). Automatically configuring constraint satisfaction programs: casestudy. Constraints, 1 (1), 743.259fiAmbite & KnoblockMinton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1990). Solving large-scale constraint satisfaction scheduling problems using heuristic repair method. Proceedings Eighth National Conference Artificial Intelligence, pp. 1724 Boston,MA.Munoz-Avila, H. (1998). Integrating Twofold Case Retrieval Complete Decision ReplayCAPlan/CbC. Ph.D. thesis, University Kaiserslautern.Nau, D. S., Gupta, S. K., & Regli, W. C. (1995). AI planning versus manufacturingoperation planning: case study. Proceedings Fourteenth InternationalJoint Conference Artificial Intelligence Montreal, Canada.Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: theoreticalempirical analysis. Artificial Intelligence, 76 ((1-2)), 427454.Ono, K., & Lohman, G. M. (1990). Measuring complexity join enumeration queryoptimization. McLeod, D., Sacks-Davis, R., & Schek, H.-J. (Eds.), 16th International Conference Large Data Bases, pp. 314325 Brisbane, Queensland,Australia. Morgan Kaufmann.Papadimitriou, C. H., & Steiglitz, K. (1977). complexity local searchtraveling salesman problem. SIAM, 6 (1), 7683.Papadimitriou, C. H., & Steiglitz, K. (1982). Combinatorial Optimization: AlgorithmsComplexity. Prentice Hall, Englewood Cliffs, NJ.Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order plannerADL. Third International Conference Principles Knowledge RepresentationReasoning, pp. 189197 Cambridge, MA.Perez, M. A. (1996). Representing learning quality-improving search control knowledge.Proceedings Thirteenth International Conference Machine Learning Bari,Italy.Ratner, D., & Pohl, I. (1986). Joint LPA*: Combination approximation search.Proceedings Fifth National Conference Artificial Intelligence Philadelphia,PA.Rintanen, J. (2000). iterative algorithm synthesizing invariants. ProceedingsSeventeenth National Conference Artificial Intelligence Austin, TX.Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall.Sacerdoti, E. D. (1975). nonlinear nature plans. Proceedings FourthInternational Joint Conference Artificial Intelligence, pp. 206214 Tbilisi, Georgia,USSR.Savage, S., Weiner, P., & Bagchi, A. (1976). Neighborhood search algorithms guaranteeing optimal traveling salesman tours must inefficient. Journal ComputerSystem Sciences, 12 (1), 2535.260fiPlanning RewritingSchurr, A. (1990). Introduction PROGRES, attribute graph grammar based specification language. Nagl, M. (Ed.), Graph-Theoretic Concepts Computer Science,Vol. 411 Lecture Notes Computer Science, pp. 151165.Schurr, A. (1997). Programmed graph replacement systems. Rozenberg, G. (Ed.),Handbook Graph Grammars: Foundations, Vol. 1, pp. 479546. World Scientific,Singapore.Sellis, T. K. (1988). Multiple-query optimization. ACM Transactions Database Systems,13 (1), 2352.Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiabilityproblems. Proceedings Tenth National Conference Artificial Intelligence(AAAI-92), pp. 440446 San Jose, California. AAAI Press.Silberschatz, A., Korth, H. F., & Sudarshan, S. (1997). Database System Concepts (Thirdedition). McGraw-Hill.Simon, H. (1969). sciences artificial. MIT Press.Slaney, J., & Thiebaux, S. (1996). Linear time near-optimal planning blocks world.Proceedings Thirteenth National Conference Artificial IntelligenceEighth Innovative Applications Artificial Intelligence Conference, pp. 12081214Menlo Park. AAAI Press / MIT Press.Sussman, G. J. (1975). Computer Model Skill Acquisition. American Elsevier, NewYork.Veloso, M. (1994). Planning Learning Analogical Reasoning. Springer Verlag.Veloso, M. M., Perez, M. A., & Carbonell, J. G. (1990). Nonlinear planning parallelresource allocation. Proceedings Workshop Innovative ApproachesPlanning, Scheduling Control, pp. 207212 San Diego, CA.Weld, D. S. (1994). introduction least commitment planning. AI Magazine, 15 (4).Weld, D. S. (1999). Recent advances AI planning. AI Magazine, 20 (2).Yu, C., & Chang, C. (1984). Distributed query processing. ACM Computing Surveys, 16 (4),399433.Zweben, M., Daun, B., & Deale, M. (1994). Scheduling rescheduling iterativerepair. Intelligent Scheduling, pp. 241255. Morgan Kaufman, San Mateo, CA.261fiJournal Artificial Intelligence Research 15 (2001) 391-454Submitted 6/18; published 12/01Parameter Learning Logic ProgramsSymbolic-statistical ModelingTaisuke SatoYoshitaka Kameyasato@mi.cs.titech.ac.jpkame@mi.cs.titech.ac.jpDept. Computer Science, Graduate School InformationScience Engineering, Tokyo Institute Technology2-12-1 Ookayama Meguro-ku Tokyo Japan 152-8552Abstractpropose logical/mathematical framework statistical parameter learning parameterized logic programs, i.e. definite clause programs containing probabilistic factsparameterized distribution. extends traditional least Herbrand model semanticslogic programming distribution semantics , possible world semantics probabilitydistribution unconditionally applicable arbitrary logic programs including onesHMMs, PCFGs Bayesian networks.also propose new EM algorithm, graphical EM algorithm, runsclass parameterized logic programs representing sequential decision processesdecision exclusive independent. runs new data structure called support graphdescribing logical relationship observations explanations, learnsparameters computing inside outside probability generalized logic programs.complexity analysis shows combined OLDT search explanations observations, graphical EM algorithm, despite generality,time complexity existing EM algorithms, i.e. Baum-Welch algorithm HMMs,Inside-Outside algorithm PCFGs, one singly connected Bayesian networksdeveloped independently research field. Learning experimentsPCFGs using two corpora moderate size indicate graphical EM algorithmsignificantly outperform Inside-Outside algorithm.1. IntroductionParameter learning common various fields neural networks reinforcement learning statistics. used tune systems best performance, classifiersstatistical models. Unlike numerical systems described mathematical formulas however, symbolic systems, typically programs, seem amenable kindparameter learning. Actually little literature parameter learning programs.paper attempt incorporate parameter learning computer programs.reason twofold. Theoretically wish add ability learning computerprograms, authors believe necessary step toward building intelligent systems.Practically broadens class probability distributions, beyond traditionally used numerical ones, available modeling complex phenomena gene inheritance,consumer behavior, natural language processing on.c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiSato & Kameyatype learning consider statistical parameter learning applied logicprograms.1 assume facts (unit clauses) program probabilistically trueparameterized distribution.2 clauses, non-unit definite clauses, alwaystrue encode laws \if one pair blood type genes b, one'sblood type AB". call logic programs type parameterized logic programuse statistical modeling ground atoms3 provable program representobservations \one's blood type AB" parameters programinferred performing ML (maximum likelihood) estimation observed atoms.probabilistic first-order framework sketched termed statistical abduction(Sato & Kameya, 2000) amalgamation statistical inference abductionprobabilistic facts play role abducible s, i.e. primitive hypotheses.4 Statisticalabduction powerful subsumes diverse symbolic-statistical frameworksHMMs (hidden Markov models, Rabiner, 1989), PCFGs (probabilistic context freegrammars, Wetherell, 1980; Manning & Schutze, 1999) (discrete) Bayesian networks(Pearl, 1988; Castillo, Gutierrez, & Hadi, 1997) gives us freedom using arbitrarilycomplex logic programs modeling.5semantic basis statistical abduction distribution semantics introduced Sato(1995). defines parameterized distribution, actually probability measure, setpossible truth assignments ground atoms enables us derive new EM algorithm6ML estimation called graphical EM algorithm (Kameya & Sato, 2000).Parameter learning statistical abduction done two phases, search EM learning. Given parameterized logic program observations, first phase searchesexplanations observations. Redundancy first phase eliminated tabulatingpartial explanations using OLDT search (Tamaki & Sato, 1986; Warren, 1992; Sagonas, T.,& Warren, 1994; Ramakrishnan, Rao, Sagonas, Swift, & Warren, 1995; Shen, Yuan, You, &Zhou, 2001). returns support graph compact representation discoveredexplanations. second phase, run graphical EM algorithm support graph1. paper, logic programs mean definite clause programs. definite clause program set definiteclauses. definite clause clause form L1 ; : : : ; Ln (0 n) A; L1 ; : : : ; Ln atoms.called head, L1 ; : : : ; Ln body. variables universally quantified. reads L11 1 1 Ln hold, holds. case n = 0, clause called unit clause. general clauseone whose body may contain negated atoms. program including general clauses sometimes calledgeneral program (Lloyd, 1984; Doets, 1994).2. Throughout paper, familiarity readability, somewhat loosely use \distribution"synonym \probability measure".3. logic programming, adjective \ground" means variables contained.4. Abduction means inference best explanation set observations. Logically, formalizedsearch explanation E E; KB ` G G atom representing observation, KBknowledge base E conjunction atoms chosen abducible s, i.e. class formulas allowedprimitive hypotheses (Kakas, Kowalski, & Toni, 1992; Flach & Kakas, 2000). E must consistentKB.5. Existing symbolic-statistical modeling frameworks restrictions limitations various types compared arbitrary logic programs (see Section 7 details). example, Bayesian networksallow recursion. HMMs PCFGs, stochastic grammars, allow recursion lack variables datastructures. Recursive logic programs allowed Ngo Haddawy's (1997) frameworkassume domains finite function symbols seem prohibited.6. \EM algorithm" stands class iterative algorithms ML estimation incomplete data(McLachlan & Krishnan, 1997).392fiParameter Learning Logic Programs Symbolic-statistical Modelinglearn parameters distribution associated program. Redundancysecond phase removed introduction inside outside probability logicprograms computed support graph.graphical EM algorithm accomplished, combined OLDT searchexplanations, time complexity specialized ones, e.g. Baum-Welchalgorithm HMMs (Rabiner, 1989) Inside-Outside algorithm PCFGs (Baker,1979), despite generality. surprising that, conducted learning experiments PCFGs using real corpora, outperformed Inside-Outside algorithmorders magnitudes terms time one iteration update parameters. experimental results enhance prospect symbolic-statistical modeling parameterizedlogic programs even complex systems stochastic grammars whose modelingdicult simply lack appropriate modeling tool sheercomplexities. contributions paper thereforedistribution semantics parameterized logic programs unifies existing symbolicstatistical frameworks,graphical EM algorithm (combined tabulated search), general yet ecientEM algorithm runs support graphsprospect suggested learning experiments modeling learning complexsymbolic-statistical phenomena.rest paper organized follows. preliminaries Section 2, probability space parameterized logic programs constructed Section 3 mathematicalbasis subsequent sections. propose new EM algorithm, graphicalEM algorithm, parameterized logic programs Section 4. Complexity analysisgraphical EM algorithm presented Section 5 HMMs, PCFGs, pseudo PCSGssc-BNs.7 Section 6 contains experimental results parameter learning PCFGsgraphical EM algorithm using real corpora demonstrate eciency graphicalEM algorithm. state related work Section 7, followed conclusion Section 8.reader assumed familiar basics logic programming (Lloyd, 1984; Doets,1994), probability theory (Chow & Teicher, 1997), Bayesian networks (Pearl, 1988; Castilloet al., 1997) stochastic grammars (Rabiner, 1989; Manning & Schutze, 1999).2. PreliminariesSince subject intersects logic programming EM learning quite differentnature, separate preliminaries.2.1 Logic Programming OLDTlogic programming, program DB set definite clauses8 execution searchSLD refutation given goal G. top-down interpreter recursively selects7. Pseudo PCSGs (probabilistic context sensitive grammars) context-sensitive extension PCFGsproposed Charniak Carroll (1994). sc-BN shorthand singly connected Bayesian network(Pearl, 1988).8. deal general logic programs paper.393fiSato & Kameyanext goal unfolds (Tamaki & Sato, 1984) subgoals using nondeterministicallychosen clause. computed result SLD refutation, i.e. solution, answersubstitution (variable binding) DB ` G.9 Usually onerefutation G, search space refutations described SLD treemay infinite depending program goal (Lloyd, 1984; Doets, 1994).often not, applications require solutions. natural language processinginstance, parser must able find possible parse trees given sentenceevery one syntactically correct. Similarly statistical abduction, needexamine explanations determine likely one. solutions obtainedsearching entire SLD tree, choice search strategy. Prolog,standard logic programming language, backtracking used search solutionsconjunction fixed search order goals (textually left-to-right) clauses(textually top-to-bottom) due ease simplicity implementation.problem backtracking forgets everything previouschoice point, hence quite likely prove goal again, resultingexponential search time. One answer avoid problem store computed resultsreuse whenever necessary. OLDT instance memoizing scheme (Tamaki& Sato, 1986; Warren, 1992; Sagonas et al., 1994; Ramakrishnan et al., 1995; Shen et al.,2001). Reuse proved subgoals OLDT search often drastically reduces search timesolutions, especially refutations top goal include many common subrefutations. Take example logic program coding HMM. given string s,exist exponentially many transition paths output s. OLDT search appliedprogram however takes time linear length find unlikeexponential time Prolog's backtracking search.OLDT statistical abduction? viewpoint statistical abduction, reuse proved subgoals, equivalently, structure sharing sub-refutationstop-goal G brings structure sharing explanations G, additionreduction search time mentioned above, thereby producing highly compact representation explanations G.2.2 EM LearningParameterized distributions multinomial distribution normal distribution provide convenient modeling devices statistics. Suppose random sample x1; : : : ; xTsize random variable X drawn distribution P (X = x j ) parameterizedunknown , observed. value determined ML estimation MLE(maximum likelihood estimate) , i.e. maximizer likelihood 1iT P (xi j ).Things get much dicult data incomplete. Think probabilisticrelationship non-observable cause X observable effect onediseases symptoms medicine assume uniquely determinecause X . incomplete sense carry enough informationcompletely determine X . Let P (X = x; = j ) parameterized joint distributionX . task perform ML estimation condition XQ9. solution ambiguously mean answer substitution proved atom G,one gives other.394fiParameter Learning Logic Programs Symbolic-statistical Modelingnon-observable observable. Let y1 ; : : : ; yT random sample size drawnmarginal distribution P (Y = j ) = x P (X = x; = j ). MLEobtained maximizing likelihood 1iT P (yi j ) function .mathematical formulation looks alike cases, latter, ML estimationincomplete data, far complicated direct maximization practically impossiblemany cases. People therefore looked indirect approaches tackle problemML estimation incomplete data EM algorithm standardsolution (Dempster, Laird, & Rubin, 1977; McLachlan & Krishnan, 1997). iterativealgorithm applicable wide class parameterized distributions including multinomialdistribution normal distribution MLE computation replacediteration two easier, tractable steps. n-th iteration, first calculates valueQ function introduced using current parameter value (n) (E-step)10 :PQQ( j (n)) def=XxP (x j y; (n) ) ln P (x; j ):(1)Next, maximizes Q( j (n)) function updates (n) (M-step):(n+1) = argmax Q( j (n) ):(2)Since old value (n) updated value (n+1) necessarily coincide, E-stepsM-steps iterated convergence, (log) likelihood assuredincrease monotonically (McLachlan & Krishnan, 1997).Although EM algorithm merely performs local maximization, used varietysettings due simplicity relatively good performance. One must notice howeverEM algorithm class name, taking different form depending distributionsapplications. development concrete EM algorithm Baum-Welchalgorithm HMMs (Rabiner, 1989) Inside-Outside algorithm PCFGs (Baker,1979) requires individual effort case.10. Q function related ML estimation follows. assume one data, , observed.Jensen's inequality (Chow & Teicher, 1997) concavity ln function, followsXP (x j y; (n) ) ln P (x j y; ) 0xXP (x j y; (n) ) ln P (x j y; (n) ) 0xhenceQ( j (n) ) 0 Q((n) j (n) )XX=P (x j y; (n) ) ln P (x j y; ) 0P (x j y; (n) ) ln P (x j y; (n) ) + ln P (y j ) 0 ln P (y j (n) )xln P (y j ) 0 ln P (y j (n) ):xConsequently,Q( j (n) ) Q((n) j (n) ) ) ln p(y j ) ln p(y j (n) ) ) p(y j ) p(y j (n) ):395fiSato & Kameya3. Distribution Semanticssection, introduce parameterized logic programs define declarative semantics. basic idea follows. start set F probabilistic facts (atoms)set R non-unit definite clauses. Sampling F determines set F 0 trueatoms, least Herbrand model F 0 [ R determines truth value every atomDB = F [ R. Hence every atom considered random variable, taking 1(true) 0 (false). follows, formalize process construct underlyingprobability space denotation DB.3.1 Basic Distribution PFLet DB = F [R definite clause program first-order language L countably manyvariables, function symbols predicate symbols F set unit clauses (facts)R set non-unit clauses (rules). sequel, unless otherwise stated, considersimplicity DB set ground instances clauses DB, assumeF R consist countably infinite ground clauses (the finite case similarly treated).construct probability space DB two steps. First introduce probabilityspace Herbrand interpretations11 F i.e. truth assignments ground atomsF . Next extend probability space Herbrand interpretationsground atoms L using least model semantics (Lloyd, 1984; Doets, 1994).Let A1 ; A2 ; : : : fixed enumeration atoms F . regard infinite vector ! =hx1; x2; : : :i 0s 1s Herbrand interpretation F way = 1; 2; : : :Ai true (resp. false) xi = 1 (resp. xi = 0). isomorphism, setpossible Herbrand interpretations F coincides Cartesian product:1defF = f0; 1gi:i=1construct probability measure PF sample spaceF 12 collectionfinite joint distributions PF(n)(A1 = x1; : : : ; = xn) (n = 1; 2; : : : ; xi 2 f0; 1g; 1 n)0 PF(n)(A1 = x1 ; : : : ; = xn) 1(n)(3)x ;:::;x PF (A1 = x1 ; : : : ; = xn ) = 1(n+1)(n)PF (A1 = x1 ; : : : ; An+1 = xn+1 ) = PF (A1 = x1 ; : : : ; = xn ):xlast equation called compatibility condition. proved (Chow & Teicher,1997) compatibility condition exists probability space (F ; F ; PF )PF probability measure F , minimal algebra containing open setsF ,n,PF (A1 = x1 ; : : : ; = xn ) = PF(n) (A1 = x1 ; : : : ; = xn ):8>><>>:PP1nn+111. Herbrand interpretation interprets function symbol uniquely function ground termsassigns truth values ground atoms. Since interpretation function symbols commonHerbrand interpretations, given L, one-to-one correspondence truth assignmentsground atoms L. distinguish them.12. regardF topological space product topology f0; 1g equippeddiscrete topology.396fiParameter Learning Logic Programs Symbolic-statistical Modelingcall PF basic distribution.13(n)choice PF free long compatibility condition met. wantinterpretations equiprobable, set PF(n)(A1 = x1; : : : ; = xn) = 1=2nevery hx1; : : : ; xn i. resulting PF uniform distributionF like oneunit interval [0; 1]. If, hand, stipulate interpretation except!0 = hc1 ; c2; : : :i possible, put, n,PF(n) (A1 = x1 ; : : : ; = xn ) = 10 ifo.w. 8i xi = ci (1 n)PF places probability mass !0 gives probability 0 rest.Define parameterized logic program definite clause program14 DB = F [ RF set unit clauses, R set non-unit clauses clause head Runifiable unit clause F parameterized basic distribution PF associatedF . parameterized PF obtained collection parameterized joint distributionssatisfying compatibility condition. Generally, complex PF(n)'s are,exible PF is, cost tractability. choice parameterized finite distributionsmade Sato (1995) simple:PF(2n) (ON 1 = x1; 2 = x2 ; : : : ; 2n = x2n j 1 ; : : : ; n)n= Pbs (ON 2i01 = x2i01; 2i = x2i j i)i=1Pbs (ON 2i01 = x2i01 ; 2i = x2i j )0 x2i01 = x2i=x2i01 = 1; x2i = 0(4)1 0 x2i01 = 0; x2i = 1:Pbs (ON 2i01 = x2i01 ; 2i = x2i j ) (1 n) represents probabilistic binary switch,i.e. Bernoulli trial, using two exclusive atoms 2i01 2i way eitherone true trial never both. parameter specifying probabilityswitch on. resulting PF probability measure infinite productindependent binary outcomes. might look simple expressive enough Bayesiannetworks, Markov chains HMMs (Sato, 1995; Sato & Kameya, 1997).(8><>:3.2 Extending PF PDBsubsection, extend PF probability measure PDB possible worldL, i.e. set possible truth assignments ground atoms L least13. naming PF , despite probability measure, partly ects observation behaveslike infinite joint distribution PF (A1 = x1 ; A2 = x2 ; : : :) infinite random vector hA1 ; A2 ; : : :iPF(n) (A1 = x1 ; : : : ; = xn ) (n = 1; 2; : : :) marginal distributions. Another reasonintuitiveness. considerations apply PDB defined next subsection well.14. clauses necessarily ground.397fiSato & KameyaHerbrand model (Lloyd, 1984; Doets, 1994). proceeding however, need couplenotations. atom A, define AxAx = x = 1Ax = :A x = 0:Next take Herbrand interpretation 2F F . makes atoms F trueothers false. Let F set atoms made true . imagine definite clauseprogram DB0 = R [ F least Herbrand model MDB0 (Lloyd, 1984; Doets, 1994).MDB0 characterized least fixed point mapping TDB0 (1)B1 ; : : : ; Bk 2 DB0 (0 k)TDB0 (I ) def=fB1 ; : : : ; Bk gset ground atoms.15 equivalently, inductively definedI0 = ;In+1 = TDB0 (In )MDB0 =:((fififififi)[nTaking account fact MDB0 function 2F , henceforth employfunctional notation MDB ( ) denote MDB0 .Turning back, let A1 ; A2 ; : : : enumeration, ground atoms L.16FormDB , similarlyF , Cartesian product denumerably many f0; 1g's identify set possible Herbrand interpretations ground atoms A1 ; A2 ; : : :L, i.e. possible world L. extend PF probabilitymeasure PDBDB(n)follows. Introduce series finite joint distributions PDB (A1 = x1 ; : : : ; = xn )n = 1; 2; : : :[Ax1 ^ 1 1 1 ^ Axn ]F def= f 2F j MDB ( ) j= Ax1 ^ 1 11 ^ Axn gdef(n) (A = x ; : : : ; = x ) = P ([Ax ^ 11 1 ^ Ax ] ):PDB11nnFn F11n11nn(n) 's satisfyNote set [Ax1 ^ 1 1 1 ^ Axn ]F PF -measurable definition, PDBcompatibility condition(n+1) (A = x ; : : : ; = x ) = P (n) (A = x ; : : : ; = x ):PDB11n+1n+11nnDB 11nXxn+1Hence exists probability measure PDBDB extension PFPDB (A1 = x1 ; : : : ; = xn ) = PF (A1 = x1 ; : : : ; = xn )15. defines, mutually, Herbrand interpretation ground atom true 2 .Herbrand model program Herbrand interpretation makes every ground instance everyclause program true.16. Note enumeration enumerates ground atoms F well.398fiParameter Learning Logic Programs Symbolic-statistical Modelingfinite atoms A1; : : : ; F every binary vector hx1 ; : : : ; xni (xi 2 f0; 1g; 1n). Define denotation program DB = F [ R w.r.t. PF PDB . denotational semantics parameterized logic programs defined called distributionsemantics. remarked before, regard PDB kind infinite joint distributionPDB (A1 = x1 ; A2 = x2 ; : : :). Mathematical properties PDB listed Appendixsemantics proved extension standard least model semanticslogic programming possible world semantics probability measure.3.3 Programs DistributionsDistribution semantics views parameterized logic programs expressing distributions. Traditionally distributions expressed using mathematical formulas useprograms (discrete) distributions gives us far freedom exibility mathematical formulas construction distributions recursion arbitrary composition. particular program contain infinitely many random variablesprobabilistic atoms recursion, hence describe stochastic processespotentially involve infinitely many random variables Markov chains derivationsPCFGs (Manning & Schutze, 1999).17Programs also enable us procedurally express complicated constraints distributions\the sum occurrences alphabets b output string HMM mustmultiple three". feature, procedural expression arbitrarily complex (discrete)distributions, seems quite helpful symbolic-statistical modeling.Finally, providing mathematically sound semantics parameterized logic programsone thing, implementing distribution semantics tractable way another.next section, investigate conditions parameterized logic programs makeprobability computation tractable, thereby making usable means large scalesymbolic-statistical modeling.4. Graphical EM AlgorithmAccording preceding section, parameterized logic program DB = F [ Rfirst-order language L parameterized basic distribution PF (1 j ) Herbrandinterpretations ground atoms F specifies parameterized distribution PDB (1 j )Herbrand interpretations L. section, develop, step step, ecient EMalgorithm parameter learning parameterized logic programs interpreting PDBdistribution observable non-observable events. new EM algorithmtermed graphical EM algorithm. applicable arbitrary logic programs satisfyingcertain conditions described later provided basic distribution direct productmulti-ary random switches, slight complication binary ones introducedSection 3.1.section on, assume DB consists usual definite clauses containing(universally quantified) variables. Definitions changes relating assumption17. infinite derivation occur PCFGs. Take simple PCFG fp : ! a; q : ! SS gstart symbol, terminal symbol, p + q = 1 p; q > 0. PCFG, rewritten eitherprobability p SS probability q . probability occurrence infinite derivationcalculated max f0; 1 0 (p=q)g non-zero q > p (Chi & Geman, 1998).399fiSato & Kameyalisted below. predicate p, introduce iff (p), iff definition piff(p) def= 8x (p(x) $ 9y1(x = t1 ^ W1 ) _ 1 11 _ 9yn (x = tn ^ Wn )) :x vector new variables length equal arity p, p(ti) Wi (1n; 0 n), enumeration clauses p DB, yi , vector variables occurringp(ti) Wi. define comp(R) follows.head(R) def= fB j B ground instance clause head appearing Rgiff (R) def= fiff (p) j p appears clause head RgEq def= ff (x) = f (y) ! x = j f function symbolg[ ff (x) 6= g(y) j f g different function symbolsg[ ft 6= x j term properly containing xgcomp(R) def= iff (R) [ EqEq , Clark's equational theory (Clark, 1978), deductively simulates unification. Likewisecomp(R) first-order theory deductively simulates SLD refutation helpEq replacing clause head atom clause body (Lloyd, 1984; Doets, 1994).introduce definitions frequently used. Let B atom.explanation B w.r.t. DB = F [ R conjunction S; R ` B,set comprised conjuncts, F holds proper subset satisfies this.set explanations B called support set B designated DB (B).184.1 Motivating ExampleFirst all, review distribution semantics concrete example. Consider followingprogram DBb = Fb [ Rb Figure 1 modeling one's blood type determined bloodtype genes probabilistically inherited parents.19first four clauses Rb state blood type determined genotype, i.e. pairblood type genes a, b o. instance, btype('A'):- (gtype(a,a) ; gtype(a,o) ;gtype(o,a)) says one's blood type (her) genotype ha; ai, ha; oi ho; ai.propositional rules.Succeeding clauses state general rules terms logical variables. fifth clausesays regardless values X Y, event gtype(X,Y) (one's genotypehX; Yi) caused two events, gene(father,X) (inheriting gene X father)gene(mother,Y) (inheriting gene mother). gene(P,G):- msw(gene,P,G)clause connecting rules Rb probabilistic facts Fb. tells us gene Ginherited parent P choice represented msw(gene,P,G)20 made.18. definition support set differs one used Sato (1995) Kameya Sato (2000).19. implicitly emphasize procedural reading logic programs, Prolog conventions employed(Sterling & Shapiro, 1986). Thus, ; stands \or", , \and" :- \implied by" respectively. Stringsbeginning capital letter (universally quantified) variables, quoted ones 'A'constants. underscore anonymous variable.20. msw abbreviation \multi-ary random switch" msw(1; 1; 1) expresses probabilistic choicefinite alternatives. framework statistical abduction, msw atoms abduciblesexplanations constructed conjunction.400fiParameter Learning Logic Programs Symbolic-statistical Modeling8>>>>>>><btype('A')btype('B')btype('O')btype('AB')gtype(X,Y)gene(P,G)::::::-(gtype(a,a) ; gtype(a,o) ; gtype(o,a)).(gtype(b,b) ; gtype(b,o) ; gtype(o,b)).gtype(o,o).(gtype(a,b) ; gtype(b,a)).gene(father,X), gene(mother,Y).msw(gene,P,G).Rb=Fb= fmsw(gene,father,a); msw(gene,father,b); msw(gene,father,o);>>>>>>>:msw(gene,mother,a); msw(gene,mother,b); msw(gene,mother,o)gFigure 1: ABO blood type program DBbgenetic knowledge choice G chance made fa; b; og expressedspecifying joint distribution Fb follows.PF (msw(gene,t,a) = x; msw(gene,t,b) = y; msw(gene,t,o) = z j ; b ; ) def= axby ozx; y; z 2 f0; 1g, x + + z = 1, a; b; 2 [0; 1], + b + = 1 eitherfather mother. Thus probability inheriting gene parent. Statisticalindependence choice gene, father mother, expressedputtingPF ( msw(gene,father,a) = x; msw(gene,father,b) = y; msw(gene,father,o) = z;msw(gene,mother,a) = x0; msw(gene,mother,b) = 0; msw(gene,mother,o) = z 0j ; b ; )= PF (x; y; z j a; b; o)PF (x0; y0 ; z0 j a; b ; o):setting, atoms representing observation obs(DBb ) = fbtype('A'); btype('B');btype('O'); btype('AB')g. observe one them, say btype('A'), infer possibleexplanation , i.e. minimal conjunction abducibles msw(gene,1,1)S; Rb ` btype('A').obtained applying special SLD refutation procedure goal btype('A')preserves msw atoms resolved upon refutation. Three explanations found.S1 = msw(gene,father,a) ^ msw(gene,mother,a)S2 = msw(gene,father,a) ^ msw(gene,mother,o)S3 = msw(gene,father,o) ^ msw(gene,mother,a)DB (btype(a)), support set btype(a), fS1 ; S2 ; S3g. probabilityexplanation respectively computed PF (S1) = a2 PF (S2 ) = PF (S3) = ao.Proposition A.2 Appendix A, follows PDB (btype('A')) = PDB (S1 _ S2 _ S3) =PF (S1 _ S2 _ S3 )PDB (btype('A') j ; b ; ) = PF (S1 ) + PF (S2 ) + PF (S3 )= a2 + 2ao:bbbbbbbbbbbbb401bbfiSato & Kameyaused fact S1, S2 S3 mutually exclusive choice geneexclusive. Parameters, i.e. a, b determined ML estimation performedrandom sample fbtype('A'); btype('O'); btype('AB')g btype follows.ha ; b ; oi = argmaxh ; ; PDB (btype('A'))PDB (btype('O'))PDB (btype('AB'))= argmaxh ; ; (a2 + 2ao)o2 abprogram contains neither function symbol recursion though semanticsallows them. Later see example containing both, program HMM (Rabiner& Juang, 1993).bbbbb4.2 Four Simplifying ConditionsFigure 1 simple probability computation easy. generallycase. Since primary interest learning, especially ecient parameter learning parameterized logic programs, hereafter concentrate identifying property programmakes probability computation easy like DBb, thereby makes ecient parameter learningpossible.answer question precisely, let us formulate whole modeling process. Supposeexist symbolic-statistical phenomena gene inheritance hopeconstruct probabilistic computational model. first specify target predicate pwhose ground atom p(s) represents observation phenomena. explainempirical distribution p, write parameterized logic program DB = F [ Rbasic distribution PF parameter reproduce observable patternsp(s). Finally, observing random sample p(s1); : : : ; p(sT ) ground atoms p,adjust ML estimation, i.e. maximizing likelihood L() = Tt=1 PDB (p(st) j )PDB (p(1) j ) approximates closely empirically observed distribution ppossible.first sight, formulation looks right, reality not. Suppose two eventsp(s) p(s0 ) (s 6= s0) observed. put L() = PDB (p(s) j )PDB (p(s0) j ).cannot likelihood simply distribution semantics, p(s) p(s0 )two different random variables, two realizations random variable.quick remedy note case blood type program DBb obs(DBb) =fbtype('A'); btype('B'); btype('O'); btype('AB')g observable atoms, onetrue observation, atom true, others must false.words, atoms collectively behave single random variable distributionPDB whose values obs(DBb ).Keeping mind, introduce following condition. Let obs(DB) ( head(R))set ground atoms represent observable events. call observable atom s.DBbQbUniqueness condition:0PDB (G ^ G ) = 0G 6= G0 2 obs(DB),402PG2obs(DB) PDB(G) = 1.fiParameter Learning Logic Programs Symbolic-statistical Modelinguniqueness condition enables us introduce new random variable Yo representingobservation. Fix enumeration G1 ; G2 ; : : : observable atoms obs(DB) defineYo by21(! ) = kiff ! j= Gk ! 2DB (k 1):(5)Let Gk T; Gk ; : : : ; Gk 2 obs(DB) random sample size . L() = Tt=1 PDB (Gk j) = t=1 PDB (Yo = kt j ) qualifies likelihood function w.r.t. Yo .second condition concerns reduction probability computation addition.Take blood type exmaple. computation PDB (btype('A')) decomposedsummation explanations support set mutualy exclusive.introduceQQ12bExclusiveness condition:every G 2 obs(DB) support set DB (G), PDB (S ^ 0) = 0 6=0 2 DB (G).Using exclusiveness condition (and Proposition A.2 Appendix A),PDB (G) =PF (S ):XS2DB(G)modeling point view, means single event, single observation,G, may several (or even infinite) explanations DB (G), one DB (G) allowedtrue observation.introduce 9DB , i.e. set explanations relevant obs(DB)9DB def=DB (G)[G2obs(DB)fix enumeration S1; S2 ; : : : explanations 9DB . follows Proposition A.2,uniqueness condition exclusiveness conditionPDB (Si ^ Sj ) = 0 6= jPDB (S ) =PDB (S )X29DBXXG2obs(DB) 2(G)PDB (G)DB=G2obs(DB)= 1:able introduce uniqueness condition exclusiveness conditionyet another random variable Xe, representing explanation G, definedXe (!) = k iff ! j= Sk ! 2DB :(6)third condition concerns termination.21.XG2obs(DB) PDB (G) = 1 guarantees measure f ! j ! j= Gk k ( 1)g one,! satisfying Gk 's. case, put Yo (!) = 0. values set measurezero affect part discussion follows. also applies definition Xe (6).P403fiSato & KameyaFinite support condition:every G 2 obs(DB) DB (G) finite.PDB (G) computed support set DB (G) = fS1 ; : : : ; Sm g (0 m),help exclusiveness condition, finite summation mi=1 PF (Si). conditionprevents infinite summation hardly computable.fourth condition simplifies probability computation multiplication. Recallexplanation G 2 obs(DB) conjunction a1 ^ 1 11 ^ abduciblesfa1; : : : ; amg F (1 m). order reduce computation PF (S ) = PF (a1 ^11 1^ am)multiplication PF (a1) 1 11 PF (am ), assumePDistribution condition:F set Fmsw ground atoms parameterized distribution Pmsw specified below.atom msw(i,n,v) intended simulate multi-ary random switch whose namewhose outcome v trial n. generalization primitive probabilistic eventscoin tossing dice rolling.1. Fmsw consists probabilistic atoms msw(i,n,v). arguments i, n v groundterms called switch name, trial-id value (of switch i), respectively.assume finite set Vi ground terms called value set associatedi, v 2 Vi holds.2. Write Vi fv1 ; v2 ; : : : ; vmg (m = jVi j). Then, one ground atoms f msw(i,n,v1),msw(i,n,v2 ), . .. , msw(i,n,vm )g becomes exclusively true (takes value 1)trial. i, parameter i;v 2 [0; 1] v2V i;v = 1 associated. i;vprobability msw(i,1,v) true (v 2 Vi).3. ground terms i, i0 , n, n0, v 2 Vi v0 2 Vi0 , random variable msw(i,n,v)independent msw(i0 ,n0 ,v0 ) n 6= n0 6= i0 .words, introduce family parameterized finite distributions P(i;n)P(i;n)(msw(i,n,v1 ) = x1 ; : : : ; msw(i,n,vm ) = xm j i;v ; : : : ; i;v )xxmk=1 xk = 1def= 0i;v 1 11 i;v o.w.(7)P(111P= jVij, xk 2 f0; 1g (1 k m), define Pmsw infinite productPmsw def= P(i;n) :i;ncondition, compute Pmsw(S ), probability explanation S,product parameters. Suppose msw(ij ,n,v) msw(ij0 ,n0,v0) different conjunctsexplanation = msw(i1 ,n1,v1 ) ^ 11 1^ msw(ik ,nk ,vk ). either j 6= j 0 n 6= n0 holds,independent construction. Else j = j 0 n = n0 v 6= v 0,independent Pmsw(S ) = 0 construction. result, whichever condition may hold,Pmsw (S ) computed parameters.404fiParameter Learning Logic Programs Symbolic-statistical Modeling4.3 Modeling Principlepoint, introduced four conditions, uniqueness condition, exclusiveness condition, finite support condition distribution condition, simplifyprobability computation. last one easy satisfy. adopt Fmsw togetherPmsw . So, on, always assume Fmsw parameterized distribution Pmswintroduced previous subsection. Unfortunately rest satisfied automatically. According modeling experiences however, mildly dicult satisfyuniqueness condition exclusiveness condition long obey followingmodeling principle.Modeling principle: DB = Fmsw [ R describes sequential decision process(modulo auxiliary computations) uniquely produces observable atomG 2 obs(DB) decision expressed msw atom.22Translated programming level, says must take care writing program sample F 0 Pmsw, must uniquely exist goal G (G 2 obs(DB))successful refutation DB0 = F 0 [ R. confirm principleblood type program DBb = Fb [ Rb. describes process gene inheritance,arbitrary sample Fb0 Pmsw, say Fb0 = fmsw(gene,father,a); msw(gene,mother,o)g,exists unique goal, btype('A') case, successful SLD refutationFb0 [ Rb.idea behind principle decision process always produces result (anobservable atom), different decision processes must differ msw thereby entailingmutually exclusive observable atoms. uniqueness condition exclusivenesscondition automatically satisfied.Satisfying finite support condition dicult virtually equivalentwriting program DB solution search G (G 2 obs(DB)) always terminates. Apparently general solution problem, far specific modelsHMMs, PCFGs Bayesian networks concerned, met. programsmodels satisfy finite support condition (and conditions well).4.4 Four Conditions Revisitedsubsection, discuss relax four simplifying conditions introduced Subsection 4.2 purpose exible modeling. first examine uniqueness conditionconsidering crucial role adaptation EM algorithm semantics.uniqueness condition guarantees exists (many-to-one) mappingexplanations observations EM algorithm applicable (Dempster et al., 1977).possible, however, relax uniqueness condition justifying applicationEM algorithm. assume MAR (missing random) condition introducedRubin (1976) statistical condition complete data (explanation) becomes incomplete data (observation), customarily assumed implicitly explicitlystatistics (see Appendix B). assuming MAR condition, apply EM22. Decisions made process finite subset Fmsw .405fiSato & Kameyaalgorithm non-exclusive observations P (O) 1 uniquenesscondition seemingly destroyed.Let us see MAR condition action simple example. Imagine walk alongroad front lawn. occasionally observe state \the road drylawn wet". Assume lawn watered sprinkler running probabilistically.program DBrl = Rrl [ Frl Figure 2 describes sequential process outputsobservation observed(road(x),lawn(y)) (\the road x lawn y")x; 2 fwet; dryg.Rrl = { observed(road(X),lawn(Y)):PFrl=msw(rain,once,A),( = yes, X = wet, = wet; = no, msw(sprinkler,once,B),( B = on, X = dry, = wet; B = off, X = dry, = dry ) ). }{ msw(rain,once,yes), msw(rain,once,no),msw(sprinkler,once,on), msw(sprinkler,once,off) }Figure 2: DBrlbasic distribution Frl specified like PF (1) Subsection 4.1, omit it.msw(rain,once,A) program determines whether rains (A = yes) (A = no),whereas msw(sprinkler,once,B) determines whether sprinkler works fine (B = on)(B = off). Since sampled values = (a 2 fyes; nog) B = b(b 2 fon; offg), uniquely exists observation observed(road(x),lawn(y)) (x; 2fwet; dryg), many-to-one mapping : (a; b) = hx; yi. words,apply EM algorithm observations observed(road(x),lawn(y)) (x; 2fwet; dryg). would happen observe exclusively either state roadlawn? Logically, means observe 9y observed(road(x),lawn(y))9x observed(road(x),lawn(y)). Apparently uniqueness condition met,9y observed(road(wet),lawn(y)) 9x observed(road(x),lawn(wet)) compatible(they true rains). Despite non-exclusiveness observations, stillapply EM algorithm MAR condition, case translatesobserve either lawn road randomly regardless state.brie check conditions. Basically relaxed costincreased computation. Without exclusiveness condition instance, would needadditional process transforming support set DB (G) goal G set exclusiveexplanations. instance, G explanations fmsw(a,n,v); msw(b,m,w)g,transform fmsw(a,n,v); :msw(a,n,v) ^ msw(b,m,w)g on.23 Clearly,transformation exponential number msw atoms eciency concern leadsassuming exclusiveness condition.finite support condition practice equivalent condition SLD treeG finite. relaxing condition might induce infinite computation.b23. :msw(a,n,v ) transformed disjunction exclusive msw atoms like406W602 msw(a,n,v ).v 0 =v;v 0 VafiParameter Learning Logic Programs Symbolic-statistical ModelingRelaxing distribution condition accepting probability distributionsserve expand horizon applicability parameterized logic programs.particular introduction parameterized joint distributions P (v1; : : : ; vk ) like Boltzmann distributions switches msw1 ; : : : ; mswk v1; : : : ; vk values switches,makes correlated. distributions facilitate writing parameterized logic programscomplicated decision processes decisions independent interdependent. Obviously, hand, increase learning time, whether addedexibility distributions deserves increased learning time yet seen.Pmsw4.5 Naive Approach EM Learningsubsection, derive concrete EM algorithm parameterized logic programsDB = Fmsw [ R assuming satisfy uniqueness condition, exclusivenesscondition finite support condition.start, introduce Yo, random variable representing observations according(5) based fixed enumeration observable atoms obs(DB). also introduceanother random variable Xe representing explanations according (6) basedfixed enumeration explanations 9DB . understanding Xe non-observableYo observable, joint distribution PDB (Xe = x; Yo = j )denotes relevant parameters. immediate, following (1) (2) Section 2,derive concrete EM algorithm Q function defined Q( j 0 ) def= x PDB (x jy; 0) ln PDB (x; j ) whose input random sample observable atoms whose outputMLE .following, sake readability, substitute observable atom G (G 2obs(DB)) Yo = write PDB (G j ) instead PDB (Yo = j ). Likewisesubstitute explanation (S 2 9DB ) Xe = x write PDB (S; G j ) insteadPDB (Xe = x; Yo = j ). follows uniqueness condition062 DB (G)PDB (S; G j ) =Pmsw (S j ) 2 DB (G):need yet another notation here. explanation S, define count msw(i,n,v)i;v (S ) def= jf n j msw(i,n,v) 2 gj :done preparations now. Suppose make observations G = G1 ; : : : ; GTGt 2 obs(DB) (1 ). Putdef= fi j msw(i,n,v) 2 2 DB (Gt); 1 gdef= fi;v j msw(i,n,v) 2 2 DB (Gt); 1 g:set switch names appear explanation one Gt 's denotesparameters associated switches. finite due finite support condition.P(407fiSato & KameyaVarious probabilities Q function computed using Proposition A.2Appendix together assumptions follows.PDB (Gt j ) = PDB=Pmsw (S j )(8)DB (Gt )fififi_Pmsw (S j )=Q( j 0 ) def==(i; v; ) def=t=1 S29DBi2I;v2ViXt=1XS2i;v (S )i;vi2I;v2ViXXXDB(Gt )PDB (S j Gt ; 0 ) ln PDB (S; Gt j )(i; v; 0 )ln i;v1PDB (Gt j ) 2Xi2I;v2ViXDB(Gt )!(i; v; 0 )0(i; v; ) ln P0 0v0 2Vi (i; v ; )(9)Pmsw (S j )i;v (S )used Jensen's inequality obtain (9). Note PDB (Gt j )01 S2 (G )Pmsw (S j )i;v (S ) expected count msw(i,1,v) SLD refutation Gt. Speakinglikelihood function L() = Tt=1 PDB (Gt j ), already shown Subsection 2.2(footnote) Q( j 0 ) Q(0 j 0 ) implies L() L(0 ). Hence (9), reachprocedure learn-naive( ,G) finds MLE parameters. arrayvariable [i; v] stores (i; v; ) current .PDBQDB1:2:3:4:5:6:procedurelearn-naive(DB; G )beginInitialize appropriate values " small positive number ;(0) := t=1 ln PDB (Gt j );% Compute log-likelihood.Prepeatforeach2 I; v 2 Vi[i; v ] :=X1PDB (Gt j ) 2foreach 2 I; v 2 Vi[i; v]i;v := P0;0v 2Vi [i; v ]:= +P1;(m) := Tt=1 ln PDB (Gt j )(m) 0 (m01) < "7:8:9:10:11:12: endt=1XDB(Gt )Pmsw (S j )i;v (S );% Update parameters.% Compute log-likelihood again.% Terminate converged.EM algorithm simple correctly calculates MLE , calculation PDB (Gt j ) [i; v](Line 3, 6 10) may suffer combinatorial explosionexplanations. is, j DB (Gt)j often grows exponentially complexity model.instance, j DB (Gt)j HMM N states O(N L), exponential length Linput/output string. Nonetheless, suppressing explosion realize ecient computation polynomial order possible, suitable conditions, avoiding multiplecomputations subgoal see next.408fiParameter Learning Logic Programs Symbolic-statistical Modeling4.6 Inside Probability Outside Probability Logic Programssubsection, generalize notion inside probability outside probability(Baker, 1979; Lari & Young, 1990) logic programs. Major computations learn-naive( ,G)two terms Line 6, PDB (Gt j ) S2 (G ) Pmsw(S j )i;v (S). Computational redundancy lurks naive computation terms. show example.Suppose propositional program DBp = Fp [ Rp Fp = fa; b; c; d; mgDBPDB8>>>>><Rp = >>>>>:ffggha^gb^gcd^hm:(10)f observable atom. assume a, b, c, independent alsofa; bg fc; dg pair-wise exclusive. support set f calculatedDB (f) = fa ^ c; ^ ^ m; b ^ c; b ^ ^ g:Hence, light (8), may compute PDB (f)PDB (f) = PF (a ^ c) + PF (a ^ ^ m) + PF (b ^ c) + PF (b ^ ^ m):(11)computation requires 6 multiplications (because PF (a ^ c) = PF (a)PF (c) etc.)3 additions. hand, possible compute PDB (f) much ecientlyfactoring common computations. Let ground atom. Define inside probabilityfi (A)fi (A) def= PDB (A j ):24(12)applying Theorem A.1 Appendixcomp(Rp) ` f $ (a ^ g) _ (b ^ g); g $ c _ (d ^ h); h $(13)unconditionally holds semantics, using independent exclusiveness assumption made Fp, following equations inside probabilityderived.fi (f) = fi (a)fi (g) + fi (b)fi (g)fi (g) = fi (c) + fi (d)fi (h)(14)fi (h) = fi (m)PDB (f)(= fi (f)) obtained solving (14) fi (f), 3 multiplications2 additions required.quite straightforward generalize (14) proceeding, look programDBq = fmg [ fg:-m ^ m; g:-mg g observable atom msw atom.g $ (m ^ m) _ semantics, compute P (g) = P (m)P (m) + P (m)clearly wrong ignores fact clause bodies g, i.e. m^m mutuallyexclusive, atoms clause body m^m independent (here P (1) = PDB (1)).Similarly, set = b = c = = m, equation (14) totally incorrect.ppppppppppp8><>:pq24. Note fact F , fi (A) = Pmsw (A j ).409fiSato & Kameyatherefore add, temporarily subsection, two assumptions top exclusiveness condition finite support condition equations like (14) becomemathematically correct. first assumption \clause" bodies mutually exclusive i.e. two clauses B W B W 0 , PDB (W ^ W 0 j ) = 0,second assumption body atoms independent, i.e. B1 ^ 1 1 1 ^ Bk rule,PDB (B1 ^ 11 1 ^ Bk j ) = PDB (B1 j ) 11 1 PDB (Bk j ) holds.Please note \clause" used subsection special meaning. intendedmean G G goal tabled explanation G obtained OLDT searchexplained next subsection.25 words, additionalconditions imposed source program result OLDT search.clauses auxiliary computations need satisfy them.suppose clauses occur DB likeB1;1 ^ 1 1 1 ^ B1;i111 1BL;1 ^ 11 1 ^ BL;iLBh;j (1 h L; 1 j ih) atom. Theorem A.1 Appendixassumptions ensurefi (A) = fi (B1;j ) + 1 11 + fi (BL;j ):(15)1Lj =1j =1(15) suggests fi (Gt) considered function fi (A) equationsinside probabilities hierarchically organized way fi(Gt) belongs toplayer fi(A) appearing left hand side refers fi (B)'s belonglower layers. refer condition acyclic support condition. acyclicsupport condition, equations form (15) unique solution, computationPDB (G j ) via inside probabilities allows us take advantage reusing intermediateresults stored fi (A), thereby contributing faster computation PDB (Gt j ).Next tackle intricate problem, computation S2 (G ) Pmsw(S j)i;v (S ). Since sum equals n msw(i,n,v )2S 2 (G ) Pmsw (S j ), concentratecomputation(Gt; m) def=Pmsw (S j )PPDBPDBX( )m2S 2 DB Gt= msw(i,n,v). First note explanation contains like = a1 ^1 11^ah ^ m, fi (S ) = fi (a1 ) 1 1 1 fi (ah)fi (m). (Gt ; m) expressed(Gt; m) = ff(Gt ; m)fi (m)(16)ff(Gt; m) = @@fi(G(m;)m) ff(Gt; m) depend fi (m). Generalizing observation arbitrary ground atoms, introduce outside probability ground atomw.r.t. Gt(Gt)ff(Gt; A) def= @fi@fi (A)25. logical relationship (13) corresponds (20) f, g h table atoms.410fiParameter Learning Logic Programs Symbolic-statistical Modelingassuming conditions inside probability. view (16), problem computing (Gt; m) reduced computing ff(Gt; m), recursively computablefollows. Suppose occurs ground program DB likeB1BK^ W1;1 ; 11 1 ; B111 1^ WK;1 ; 11 1 ; BK^ W1;i1^ WK;iK :fi (Gt) function fi (B1 ); : : : ; fi(BK ) assumption, chain rule derivativesleads@fi (Gt )@fi (A ^ WK;i )@fi (Gt ) @fi (A ^ W1;1 )+111+ff(Gt ; A) =@fi (B1 )@fi (A)@fi (BK )@fi (A)hence to26ff(Gt; Gt ) = 1(17)ff(Gt ; A) = ff(Gt ; B1 ) fi (W1;j ) + 11 1 + ff(Gt ; BK ) fi (WK;j ):(18)K1XKXj =1j =1Therefore inside probabilities already computed, outside probabilitiesrecursively computed top (17) using (18) downward along program layers.case DBp f chosen atoms, computeff(f; f) = 1ff(f; g) = fi (a) + fi (b)(19)ff(f; h) = ff(f; g)fi (d)ff(f; m) = ff(f; h):(19), desired sum (f; m) calculated(f; m) = ff(f; m)fi (m) = (fi (a) + fi (b))fi (d)fi (m)requires two multiplications one addition compared four multiplicationsone addition naive computation.Gains obtained computing inside outside probability may small case,problem size grows, become enormous, compensate enough additional restrictions imposed result OLDT search.8>>><>>>:4.7 OLDT Searchcompute inside outside probability recursively like (15) (17) (18), needprogramming level tabulation mechanism structure-sharing partial explanations26. independence assumption body atoms, Wh;j (1 h K; 1 j ih )independent. Therefore@fi (A ^ Wh;j ) = @fi (A)fi (Wh;j ) = fi (W ):h;j@fi(A)@fi (A)411fiSato & Kameyasubgoals. henceforth deal programs DB set table(DB) tablepredicate declared advance. ground atom containing table predicate calledtable atom. purpose table atoms store support sets eliminateneed recomputation, so, construct hierarchically organized explanationsmade table atoms msw atoms.Let DB = Fmsw [ R parameterized logic program satisfies finite supportcondition uniqueness condition. Also let G1 ; G2; : : : ; GT random sampleobservable atoms obs(DB). make following additional assumptions.Assumptions:(1 ), exists finite set f1t; : : : ; Kt g table atoms associated(0 k K ; 1 j )conjunctions Sk;jkecomp(R)` Gt $ S0t;1 _ 1 1 1 _ S0t;m^ 1t $ S1t;1 _ 11 1 _ S1t;m ^ 1 11 ^ Kt $ SKt ;1 _ 11 1 _ SKt ;mKteee0ee1e(20)(0 k K ; 1 j ) is, set, subset FSk;jmsw [ fk+1 ; : : : ; K gk(acyclic support condition). convention, put 0 = Gt call respectivelydef(k 0) t-explanationDB= f0 ; 1t; : : : ; Kt g set table atoms Gt Sk;jkt .27 set t-explanations k denoted DB (kt ) considerDB (1) function table atoms.^ St ) =t-explanations mutually exclusive, i.e. k (0 k Kt ), PDB (Sk;jk;j 00 (1 j 6= j 0 mk ) (t0exclusiveness condition).(0 k K ; 1 j ) conjunction independent atoms (independentSk;jkcondition).28assumptions aimed ecient probability computation. Namely, acyclicsupport condition makes dynamic programming possible, t-exclusiveness condition reduces PDB (A _ B) PDB (A)+ PDB (B) independent condition reduces PDB (A ^ B )PDB (A)PDB (B). one point concerning eciency however. Note29 imcomputation dynamic programming proceeds following partial order DBposed acyclic support condition access table atoms much simplifiedrespecting said partiallinearly ordered. therefore topologically sort DBorder call linearized DB satisfying three assumptions (the acyclic support condition, t-exclusiveness condition independent condition) hierarchical system= h ; ; : : : ; ( = G ) assumingt-explanations Gt . write DB0DB (1)0 1K30implicitly given. hierarchical system t-explanations Gt successfully builteeeeeeee27. Prefix \t-" abbreviation \tabled-".28. independence mentioned concerns positive propositions. B1 ; B2 2 head(DB), sayB1 B2 independent PDB (B1 ^ B2 j ) = PDB (B1 j )PDB (B2 j ) .29. precedes j top-down execution w.r.t. DB invokes j directly indirectly.30. holds precedes j < j .412fiParameter Learning Logic Programs Symbolic-statistical Modelingsource program, equations inside probability outside probability(14) (19) automatically derived solved time proportional sizeequations. plays central role approach ecient EM learning.One way obtain t-explanations use OLDT search (Tamaki & Sato, 1986;Warren, 1992), complete refutation method logic programs. OLDT search,goal G called first time, set entry G solution table storeanswer substitutions G there. call instance G0 G occurs later, stopsolving G0 instead try retrieve answer substitution G stored solution tableunifying G0 G. record remaining answer substitutions G, preparelookup table G0 hold pointer them.self-containedness, look details OLDT search using sample programDBh = Fh [Rh Figure 431 depicts HMM32 Figure 3. HMM two statesfs0; s1g. state transition, probabilistically chooses next destination fs0; s1ga,bs1s0a,ba,ba,bFigure 3: Two state HMMFhRh==8<:8>>>>>>>>>>>>>><>>>>>>>>>>>>>>:f1: values(init, [s0,s1]).f2: values(out(_),[a,b]).f3: values(tr(_), [s0,s1]).h1: hmm(Cs):msw(init,once,Si),hmm(1,Si,Cs).h2: hmm(T,S,[C|Cs]):- T=<3,msw(out(S),T,C),msw(tr(S),T,NextS),T1 T+1,hmm(T1,NextS,Cs).h3: hmm(T,_,[]):- T>3.%%%%%%%%%generate string (chars) Cs,Set initial state Si,Enter loop clock = 1.Loop:Output C state S.Transit NextS.Put clock ahead.Continue loop (recursion).Finish loop clock > 3.Figure 4: Two state HMM program DBh31. f1, f2, f3, h1, h2 h3 temporary marks, part program.32. HMM defines probability distribution strings given set alphabets, worksstochastic string generator (Rabiner & Juang, 1993) output string sampledefined distribution.413fiSato & Kameyaalso alphabet fa; bg emit. Note specify fact set Fh associated distribution compactly, introduce new notation values(i,[v1,...,vm]).declares Fh contains msw atoms form msw(i,n,v) (v 2 fv1 ; : : : ; vmg) whose distribution P(i;n) given (7) Subsection 4.2. example, (f3), values(tr( ),[s0,s1])introduces msw(tr(t),n,v) atoms program ground term,v 2 fs0; s1g ground term n, distributionxP(tr(t);n) (msw(tr(t),n,s0) = x; msw(tr(t),n,s1) = j i;s0 ; i;s1) = i;s0 i;s1= tr(t), x; 2 f0; 1g x + = 1.program runs like Prolog program. non-ground top-goal hmm(S), functions stochastic string generator returning list alphabets [a,b,a]variable follows. top-goal calls clause (h1) (h1) selects initial state executing subgoal msw(init,once,Si)33 returns Si initial state probabilisticallychosen fs0, s1g. second clause (h2) called (h1) ground groundT. makes probabilistic choice output alphabet C asking msw(out(S),T,C)determines NextS, next state, asking msw(tr(S),T,NextS). (h3)stop transition. simplicity, length output strings fixed three. wayexecution termed sampling execution corresponds random samplingPDB . top-goal ground like hmm([a,b,a]), works acceptor, i.e.returning success (yes) failure (no).explanations hmm([a,b,a]) sought for, keep msw atoms resolved uponrefutation conjunction (explanation), repeat process backtracking refutation found. need t-explanations however, backtracking mustabandoned sharing partial explanations t-explanations, purposet-explanations itself, becomes impossible. therefore instead use OLDT searchht1:t2:t3:t4:t4'::t7:t8:t9:top_hmm(Cs,Ans):- tab_hmm(Cs,Ans,[]).tab_hmm(Cs,[hmm(Cs)|X],X):- hmm(Cs,_,[]).tab_hmm(T,S,Cs,[hmm(T,S,Cs)|X],X):- hmm(T,S,Cs,_,[]).e_msw(init,T,s0,[msw(init,T,s0)|X],X).e_msw(init,T,s1,[msw(init,T,s1)|X],X).hmm(Cs,X0,X1):- e_msw(init,once,Si,X0,X2), tab_hmm(1,Si,Cs,X2,X1).hmm(T,S,[C|Cs],X0,X1):T=<3, e_msw(out(S),T,C,X0,X2), e_msw(tr(S),T,NextS,X2,X3),T1 T+1, tab_hmm(T1,NextS,Cs,X3,X1).hmm(T,S,[],X,X):- T>3.Figure 5: Translated program DBh33. msw(i,n,V) called ground ground n, V, logical variable, behaves like random variable.instantiated term v probability i;v selected value set Vi declared valuesatom. If, hand, V ground term v called, procedural semantics msw(i,n,v)equal msw(i,n,V) ^ V = v.414fiParameter Learning Logic Programs Symbolic-statistical Modelingt-explanation search. case HMM program example, build hierarchicalsystem t-explanations hmm([a,b,a]) OLDT search, first declare hmm=1hmm=3 table predicate.34 t-explanation conjunction hmm=1 atoms, hmm=3atoms msw atoms. translate program another logic program, analogously translation definite clause grammars (DCGs) Prolog (Sterling & Shapiro,1986). add two arguments (which forms D-list) predicate purposeaccumulating msw atoms table atoms conjuncts t-explanation. translationapplied DBh yields program Figure 5.translated program, clause (t1) corresponds top-goal hmm(l)input string l, t-explanation table atom hmm(l) returned Ans. (t2)(t3) auxiliary clauses add callee's D-list table atom form hmm(l)hmm(t,s,l) respectively (t: time step, s: state). general, p=n table predicateoriginal program, p=(n + 2) becomes table predicate translated programauxiliary predicate tab p=(n +2) inserted signal OLDT interpreter checksolution table p=n, i.e. check already exist t-explanations p=n. Likewiseclauses (t4) (t4') pair corresponding (f1) insert msw(init,T,1)callee's D-list = once. Clauses (t7), (t8) (t9) respectively correspond (h1),(h2) (h3).hmm([a,b,a]):[hmm([a,b,a])][ [msw(init,once,s0), hmm(1,s0,[a,b,a])],[msw(init,once,s1), hmm(1,s1,[a,b,a])] ]hmm(1,s0,[a,b,a]):[hmm(1,s0,[a,b,a])][ [msw(out(s0),1,a), msw(tr(s0),1,q0), hmm(2,s0,[b,a])],[msw(out(s0),1,a), msw(tr(s0),1,s1), hmm(2,s1,[b,a])] ]hmm(1,s1,[a,b,a]):[hmm(1,s1,[a,b,a])][ [msw(out(s1),1,a), msw(tr(s1),1,s0), hmm(2,s0,[b,a])],[msw(out(s1),1,a), msw(tr(s1),1,s1), hmm(2,s1,[b,a])] ]hmm(2,s0,[b,a]):[hmm(2,s0,[b,a])][ [msw(out(s0),2,b), msw(tr(s0),2,s0), hmm(3,s0,[a])],[msw(out(s0),2,b), msw(tr(s0),2,s1), hmm(3,s1,[a])] ]hmm(2,s1,[b,a]):[hmm(2,s1,[b,a])][ [msw(out(s1),2,b), msw(tr(s1),2,s0), hmm(3,s0,[a])],[msw(out(s1),2,b), msw(tr(s1),2,s1), hmm(3,s1,[a])] ]hmm(3,s0,[a]):[hmm(3,s0,[a])][ [msw(out(s0),3,a), msw(tr(s0),3,s0), hmm(4,s0,[])],[msw(out(s0),3,a), msw(tr(s0),3,s1), hmm(4,s1,[])] ]hmm(3,s1,[a]):[hmm(3,s1,[a])][ [msw(out(s1),3,a), msw(tr(s1),3,s0), hmm(4,s0,[])],[msw(out(s1),3,a), msw(tr(s1),3,s1), hmm(4,s1,[])] ]hmm(4,s0,[]):[hmm(4,s0,[])][[]]hmm(4,s1,[]):[hmm(4,s1,[])][[]]Figure 6: Solution table34. general, p=n means predicate p arity n. although hmm=1 hmm=3 share predicate namehmm, different predicates.415fiSato & Kameyatranslation, apply OLDT search top hmm([a,b,a],Ans) noting (i) added D-list uence OLDT procedure, (ii) associatesolution table atom solution table list t-explanations. resultingsolution table shown Figure 6. first row reads call hmm([a,b,a]) occurred entered solution table solution, hmm([a,b,a]) (no variable binding generated), two t-explanations, msw(init,once,s0) ^ hmm(1,s0,[a,b,a])msw(init,once,s1) ^ hmm(1,s1,[a,b,a]). remaining task topological sorting table atoms stored solution table respecting acyclic support condition.done using depth-first search (trace) t-explanations top-goalexample. Thus obtain hierarchical system t-explanations hmm([a,b,a]).4.8 Support GraphsLooking back, need compute inside outside probability hierarchical systemt-explanations, essentially boolean combination primitive events (msw atoms)compound events (table atoms) intuitively representablegraph. reason, help visualizing learning algorithm, introduce newdata-structure termed support graphs, though new EM algorithm next subsectiondescribed solely hierarchical system t-explanations.illustrated Figure 7 (a), support graph Gt graphical representation= h ; ; : : : ; ( = G ) G (20).hierarchical system t-explanations DB0 10Kconsists totally ordered disconnected subgraphs, labeled(0 k K ). subgraph labeled comprises twocorresponding table atom kt DBkspecial nodes (the start node end node) explanation graphs, correspondingt-explanation Sk;jDB (k ) (1 j mk ).linear graph node labeled eitherexplanation graph Sk;j. called table node switchtable atom switch msw(1,1,1) Sk;jnode respectively. Figure 7 (b) support graph hmm([a,b,a]) obtainedsolution table Figure 6. table node labeled refers subgraph labeled ,data-sharing achieved distinct table nodes referring subgraph.eeee4.9 Graphical EM Algorithmdescribe ecient EM learning algorithm termed graphical EM algorithm(Figure 8) introduced Kameya Sato (2000), runs support graphs. Supposerandom sample G = G1; : : : ; GT observable atoms. Also suppose supportgraphs Gt (1 ), i.e. hierarchical systems t-explanations satisfying acyclicsupport condition, t-exclusiveness condition independent condition,successfully constructed parameterized logic program DB satisfying uniquenesscondition finite support condition.graphical EM algorithm refines learn-naive( ,G ) introducing two subroutines,get-inside-probs(, G ) compute inside probabilities get-expectations(, G ) compute outside probabilities. called main routine learn-gEM( ,G ).learning, prepare four arrays support graph Gt G :P [t; ] inside probability , i.e. fi ( ) = PDB ( j ) (see (12))DBDBDBDB416fiParameter Learning Logic Programs Symbolic-statistical Modelingk(a)explanation graphmswGt:startkmswendmswmswmsw:k :startendmswmsw:(b)msw(init,once,s0)hmm(1,s0,[a,b,a])hmm([a,b,a]):startendmsw(init,once,s1)msw(out(s0),1,a)hmm(1,s1,[a,b,a])msw(tr(s0),1,s0)hmm(2,s0,[b,a])hmm(1,s0,[a,b,a]):endstartmsw(out(s0),1,a)msw(tr(s0),1,s1)hmm(2,s1,[b,a])msw(out(s1),1,a)msw(tr(s1),1,s0)hmm(2,s0,[b,a])hmm(1,s1,[a,b,a]):endstartmsw(out(s1),1,a)msw(tr(s1),1,s1)hmm(2,s1,[b,a])Figure 7: support graph (a) general form, (b) Gt = hmm([a,b,a]) HMMprogram DBh. double-circled node refers table node.Q[t; ] outside probability w.r.t. Gt , i.e. ff(Gt; ) (see (17) (18))R[t; ; ] explanation probability (2 DB (kt )), i.e. PDB (S j )ee417eefiSato & Kameya1: procedure learn-gEM (DB; G )2: begin3: Select initial4:5:6:7:8:9:1: procedure get-inside-probs (DB; G )2: begin3: := 1 begin4:Let 0t = Gt;5:k := Kt downto 0 begin6:P [t; kt ] := 0;7:foreach Se 2 eDB (kt ) begin8:Let Se = fA1 ; A2 ; : : : ; AjSejg;9:R[t; kt ; Se] := 1;10:l := 1 jSej11:Al = msw(i,1,v )12:R[t; kt ; Se] 3 = i;v13:else R[t; kt ; Se] 3 = P [t; Al ];14:P [t; kt ]+= R[t; kt ; Se]15:end /* foreach Se */16:end /* k */17: end /* */18: end.parameters;get-inside-probs(DB; G);P(0) := Tt=1 ln P [t; Gt ];repeatget-expectations (DB; G );2 I; v 2 Vi[i; vP] :=[t; i; v]=P [t; G ];t=1foreach 2 I; v P2 Vii;v := [i; v]= v0 2Vi [i; v0 ];get-inside-probs (DB; G );:= +1;P(m) := Tt=1 ln P [t; Gt ](m) 0 (m01) < "foreach10:11:12:13:14:15:16: end.1: procedure get-expectations (DB; G ) begin2: := 1 begin3:foreach 2 I; v 2 Vi [t; i; v] := 0;4:Let 0t = Gt; Q[t; 0t] := 1:0;5:k := 1 Kt Q[t; kt ] := 0;6:k := 0 Kt7:foreach Se 2 eDB (kt ) begin8:Let Se = fA1 ; A2 ; : : : ; AjSejg;9:l := 1 jSej10:Al = msw(i,1,v ) [t; i; v] += Q[t; kt ] 1 R[t; kt ; Se]11:else Q[t; Al ] += Q[t; kt ] 1 R[t; kt ; Se]=P [t; Al ]12:end /* foreach Se */13: end /* */14: end.Figure 8: graphical EM algorithm.[t; i; v] expected count msw(i,1,v), i.e.PS2DB(Gt) Pmsw (S j )i;v (S )call procedure learn-gEM( ,G) Figure 8. main routine learn-gEM( ,G) initially computes inside probabilities (Line 4) enters loop get-expectations( ,G )called first compute expected count [t; i; v] msw(i,1,v) parameters updated (Line 11). Inside probabilities renewed using updated parametersentering next loop (Line 12).DBDBDB418fiParameter Learning Logic Programs Symbolic-statistical Modelingsubroutine get-inside-probs( ,G ) computes inside probability fi ( ) = PDB ( j )(and stores P [t; ]) table atom bottom layer topmost layer 0 =Gt (Line 4) hierarchical system t-explanations Gt (see (20) Subsection 4.6).takes t-explanation DB (kt ) one one (Line 7), decomposes conjunctsmultiplies inside probabilities either known (Line 12) already computed(Line 13).subroutine get-expectations( ,G ) computes outside probabilities followingrecursive definitions (17) (18) Subsection 4.6 stores outside probabilityff(Gt; ) table atom Q[t; ]. first sets outside probability top-goal0 = Gt 1:0 (Line 4) computes rest outside probabilities (Line 6) goinglayers t-explanation Gt described (20) Subsection 4.6. (Line 10) addsQ[t; kt ] 1 R[t; kt ; ] = ff(Gt ; kt ) 1 fi(S ) [t; i; v], expected count msw(i,1,v),contribution msw(i,1,v) kt [t; i; v]. (Line 11) increments outsideprobability Q[t; Al ] = ff(Gt; Al ) Al according equation (18). Notice Q[t; kt ]already computed R[t; kt ; S]=P [t; Al ] = fi(W ) = Al ^ W . shownSubsection 4.5, learn-naive( ,G ) MLE procedure, hence following theorem holds.Theorem 4.1 Let DB parameterized logic program, G = G1; : : : ; GT ranDBeeeDBeeeeeDBdom sample observable atoms. Suppose five conditions (uniqueness, finite support(Subsection 4.2), acyclic support, t-exclusiveness independence (Subsection 4.7))met. ThenQlearn-gEM (DB; G ) finds MLE 3 (locally) maximizes likelihoodL(G j ) = Tt=1 PDB (Gt j ).(Proof) Sketch.35 Since main routine learn-gEM( ,G ) learn-naive( ,G)except computation [i; v] = Tt=1 [t; i; v], show [t; i; v] = S2 (G ) Pmsw(S j)i;v (S ) (= n msw(i,n,v )2S2 (G ) Pmsw (S j )). However,DBPPDBPDB[t; i; v]DBP=XX0kKtXn msw(i,n,v )2Se2 e ( )DB kff(Gt ; kt )fi (Se)(see (Line 10) get-expectations(DB; G))= ff(Gt; msw(i,n,v))fi(msw(i,n,v))n= (Gt; msw(i,n,v)) (see equation (16))n=Pmsw (S j ):Q.E.D.XXXXn msw(i,n,v )2S2DB(Gt )used fact contains msw(i,n,v) like = S0 ^ msw(i,n,v), fi(S) =fi (S 0 )fi (msw(i,n,v )) holds, henceff(Gt ; kt )fi (S ) = ff(Gt ; kt )fi (S 0 )fi (msw(i,n,v ))= (contribution msw(i,n,v) kt ff(Gt; msw(i,n,v)))fi (msw(i,n,v)):eeeeeeee35. formal proof given Kameya (2000). proved common parameters , [i; v]learn-naive(DB,G ) coincides [i; v] learn-gEM(DB,G ). So, parameters updatedvalues. Hence, starting initial values, parameters convergevalues.419fiSato & Kameyafive conditions applicability graphical EM algorithm may look hardsatisfy once. Fortunately, modeling principle Section 4.3 still stands,due care modeling, likely lead us program meets them. Actually,see next section, programs standard symbolic-statistical frameworksBayesian networks, HMMs PCFGs satisfy five conditions.5. Complexitysection, analyze time complexity graphical EM algorithm appliedvarious symbolic-statistical frameworks including HMMs, PCFGs, pseudo PCSGsBayesian networks. results show graphical EM algorithm competitivespecialized EM algorithms developed independently research field.5.1 Basic PropertySince EM algorithm iterative algorithm since unable predictconverges, measure time complexity time taken one iteration. thereforeestimate time per iteration repeat loop learn-gEM (DB; G) (G = G1 ; : : : ; GT ).observe one iteration, support graph Gt (1 ) scanned twice,get-inside-probs (DB; G ) get-expectations (DB; G). scan, additionperformed t-explanations, multiplication (possibly division) performedmsw atoms table atoms each. time spent Gt per iterationgraphical EM algorithm linear size support graph, i.e. number nodessupport graph Gt. Put1tDB def=DB ( )e[e2DBnum def= 1maxj1e jtT DBmaxsize def=maxjSej:ee1tT;S 21DBset table atoms G , hence 1t set t-explanationsRecall DBDBappearing right hand side (20) Subsection 4.7. num maximum numbert-explanations support graph Gt's maxsize maximum size texplanation Gt's respectively. following obvious.eProposition 5.1 time complexity graphical EM algorithm per iteration lineartotal size support graphs, (nummaxsize ) notation, coincidesspace complexity graphical EM algorithm runs support graphs.rather general result, compare graphical EM algorithmEM algorithms, must remember input graphical EM algorithmsupport graphs (one observed atom) actual total learning timeOLDT time + (the number iterations) 2O(nummaxsizeT )420fiParameter Learning Logic Programs Symbolic-statistical Modeling\OLDT time" denotes time construct support graphs G . sumtime OLDT search time topological sorting table atoms,latter part former order-wise,36 represent \OLDT time" time OLDTsearch. Also observe total size support graphs exceed time OLDTsearch G order-wise.evaluate OLDT time specific class models HMMs, need knowtime table operations. Observe OLDT search paper specialsense table atoms always ground called resolution solvedgoals. Accordingly solution table usedcheck goal G already entry solution table, i.e. calledbefore,add new searched t-explanation G list discovered t-explanationsG's entry.time complexity operations equal table access dependsprogram implementation solution table.37 first supposeprograms carefully written way arguments table atoms used indecies table access integers. Actually programs used subsequent complexityanalysis (DBh Subsection 4.7, DBg DBg0 Subsection 5.3, DBG Subsection 5.5)satisfy satisfy condition replacing non-integer terms appropriate integers. also suppose solution table implemented using array tableaccess done O(1) time.38follows, present detailed analysis time complexity graphicalEM algorithm applied HMMs, PCFGs, pseudo PCSGs Bayesian networks, assumingO(1) time access solution table. remark way space complexitytotal size solution tables (support graphs).5.2 HMMsstandard EM algorithm HMMs Baum-Welch algorithm (Rabiner, 1989; Rabiner & Juang, 1993). example HMM shown Figure 3 Subsection 4.7.39 Givenobservations w1 ; : : : ; wT output string length L, computes (N 2 LT ) timeiteration forward probability fftm(q) = P (ot1 ot2 1 11 otm01; q j ) backwardprobability fimt (q) = P (otm otm+1 1 1 1 otL j q; ) state q 2 Q, time step (1 L)string wt = ot1 ot2 11 1 otL (1 ), Q set states N numberstates. factor N 2 comes fact every state N possible destinations36. Think OLDT search top-goal Gt . searches msw atoms table atoms create solution table, auxiliary computations. Therefore time complexity never lessO(jthe number msw atoms table atoms support graph Gt j), coincidestime need topologically sort table atoms solution table depth-first search 0 = Gt .37. Sagonas et al. (1994) Ramakrishnan et al. (1995) discuss implementation OLDT.38. arrays available, may able use balanced trees, giving O(log n) access time nnumber data solution table, may able use hashing, giving average (1) timeaccess certain condition (Cormen, Leiserson, & Rivest, 1990).39. treat \state-emission HMMs" emit symbol depending state. Another type,\arc-emission HMMs" emitted symbol depends transition arc, treated similarly.421fiSato & Kameyacompute forward backward probability every destination everystate. computing ffmt (q)'s fimt (q)'s, parameters updated. So, totalcomputation time iteration Baum-Welch algorithm estimated O(N 2LT )(Rabiner & Juang, 1993; Manning & Schutze, 1999).compare result graphical EM algorithm, use HMM programDBh Figure 4 appropriate modifications L, length string, Q,state set, declarations Fh output alphabets. string w = o1o2 11 1 oL,hmm(n,q ,[om ; om+1 ; : : : ; oL ]) DBh reads HMM state q 2 Q time noutput [om ,om+1 ,...,oL] reaches final state. declaring hmm=1hmm=3 table predicate translation (see Figure 5), apply OLDT search goaltop hmm([o1,...,oL ],Ans) w.r.t. translated program obtain t-explanationshmm([o1,...,oL]). complexity argument however, translated programDBh same, talk terms DBh sake simplicity. search,fix search strategy multi-stage depth-first strategy (Tamaki & Sato, 1986).assume solution table accessible O(1) time.40 Since length listthird argument hmm=3 decreases one recursion, finitelymany choices state transition output alphabet, search terminates, leavingfinitely many t-explanations solution table like Figure 6 satisfy acyclic support condition respectively. Also sampling execution hmm(L) w.r.t. DBh nothingsequential decision process decisions made msw atoms exclusive,independent generate unique string, means DBh satisfies t-exclusivenesscondition, independence condition uniqueness condition respectively. So,graphical EM algorithm applicable set hierarchical systems t-explanationshmm(wt ) (1 ) produced OLDT search observations w1 ; : : : ; wT outputstring. Put wt = ot1 ot2 1 11 otL. followsDB= fhmm(m,q,[otm ,...,otL]) j 1 L + 1; q 2 Qg [ fhmm([ot1,...,otL])ghDBh((msw(out(q),m,om ); msw(tr(q),m,q 0);hmm(m + 1,q0 ,[otm+1 ,...,otL ])fififififi)) =(1 L)top-goal hmm([ot1 ,...,otL]), O(NL) calling patterns hmm=3call causes N calls hmm=3, implying occur O(NL 1 N ) = O(N 2L)calls hmm=3. Since call computed due tabling mechanism,num = O(N 2 L). Also maxsize = 3. Applying Proposition 5.1, reachehmm(m,q ,[otm ,...,otL ])q0 2 QProposition 5.2 Suppose strings length L. Also supposetable operation2OLDT search done (1) time. OLDT time DBh O(N LT ) graphicalEM algorithm takes O(N 2 LT ) time per iteration N number states.O(N 2LT ) time complexity Baum-Welch algorithm.algorithm runs eciently Baum-Welch algorithm.41graphical EM40. O(1) possible translated program DBh Section 4.7, identify goal patternhmm(1,1,1,1,1) first two arguments constants (integers).41. Besides, Baum-Welch algorithm graphical EM algorithm whose input support graphsgenerated DBh update parameters value initial values same.422fiParameter Learning Logic Programs Symbolic-statistical Modelingway, Viterbi algorithm (Rabiner, 1989; Rabiner & Juang, 1993) providesHMMs ecient way finding likely transition path given input/outputstring. similar algorithm parameterized logic programs determineslikely explanation given goal derived. runs time linear sizesupport graph, thereby O(N 2 L) case HMMs, complexity Viterbialgorithm (Sato & Kameya, 2000).5.3 PCFGscompare graphical EM algorithm Inside-Outside algorithm (Baker,1979; Lari & Young, 1990). Inside-Outside algorithm well-known EM algorithmPCFGs (Wetherell, 1980; Manning & Schutze, 1999).42 takes grammar Chomskynormal form. Given N nonterminals, production rule grammar takes form! j; k (1 i; j; k N ) (nonterminals named numbers 1 N 1starting symbol) form ! w 1 N w terminal. iteration,computes inside probability outside probability every partial parse treegiven sentence update parameters production rules. Time complexitymeasured time per iteration, described N , number nonterminals,L, number terminals sentence. O(N 3 L3T ) observed sentences (Lari& Young, 1990).compare graphical EM algorithm Inside-Outside algorithm, startpropositional program DBg = Fg [ Rg representing largest grammarcontaining possible rules ! j; k N nonterminals nonterminal 1 startingsymbol, i.e. sentence.FgRgd,d0],[j ,k]) j 1 i; j; k N; d; d0 numbersg= fmsw([if,[msw(i,d,w ) j 1 N; number; w terminalg=8><>:q(i,d0,d2 ) :- msw(i,[d0,d2 ],[j ,k ]),q(j ,d0,d1 ),q(k ,d1 ,d2).nq(i,d,d +1) :- msw(i,d,wd+1 ).fifififififififififi1 i; j; k N;0 d0 < d1 < d2 L1 N; 0 L 0 19>=>;Figure 9: PCFG program DBgDB g artificial parsing program whose sole purpose measure sizeOLDT tree43 created OLDT interpreter parses sentence w1 w2 1 11 wL.42. PCFG (probabilistic context free grammar) backbone CFG probabilities (parameters) assigned production rule. nonterminaln production rules fA ! ffi j 1 ng,Pprobability pi assigned ! ffi (1 n) ni=1 pi = 1. probability sentencesum probabilities (leftmost) derivation s. latter product probabilitiesrules used derivation.43. precise, OLDT structure, case, tree DBg contains constants(Datalog program) never occurs need creating new root node.423fiSato & Kameya(1)Tdq(1,d,L)2 j N2 k Nq(1,d,d+1),q(1,d+1,L)q(1,d+1,L)(1)[Note] q12 k Nq(1,d,d+1),q(k,d+1,L)q(j,d,d+1),q(1,d+1,L)q(j,d,d+1),q(k,d+1,L)q(k,d+1,L)q(1,d+1,L)q(k,d+1,L)(k)Td+1q(i,d,d) already appearsd+1 L, 1d-d L-d-2Td+1d+2 e L-11 j N2 k Nq(j,d,e),q(1,e,L)q(j,d,e),q(k,e,L)d+2 e e1 N,1 j N,q(i,d,e),q(j,e,e),q(1,e,L)Tdq(k,e,L)NqNq(j,e,e),q(1,e,L)q(1,e,L)...p(i)p(1) p(2) p(N)Figure 10: OLDT tree queryq(1,d,L)input sentence w1 w2 11 1 wL embedded program separately msw(i,d,wd+1)(0 L0 1) second clauses Rg (this treatment affect complexity argument). q(i,d0,d1) reads i-th nonterminal spans position d0 position d1,i.e. substring wd +1 1 11 wd . first clauses q(i,d0 ,d2 ) :- msw(1,1,1), q(j ,d0 ,d1),q(k,d1 ,d2) supposed textually ordered according lexicographic ordertuples hi; j; k; d0 ; d2 ; d1i. parser, top-goal set q(1,0,L).44 asksparser parse whole sentence w1 w2 1 1 1 wL syntactic category \1" (sentence).make exhaustive search query OLDT search.45 before, multistage depth-first search strategy O(1) time access solution table assumed.time complexity OLDT search measured number nodesOLDT tree. Let Td(k) OLDT tree q(k,d,L). Figure 10 illustrates Td(1)(0 L 0 3) msw atoms omitted. seen, tree many similarsubtrees, put together (see Note Figure 10). Due depth-first strategy,Td(1) recursive structure contains Td(1)+1 subtree. Nodes whose leftmost atomunderlined solution nodes, i.e. solve leftmost atoms first timeentire refutation process. underlined atoms already computed subtreesleft.46 check solution table entries (= already0144. L Prolog variable constant denoting sentence length.45. q table predicate.0 00046. inductively proved Td(1)+1 contains every computed q(i,d ,d ) (0 L 0 3; + 1 <d00 L; 1 N; d00 0 d0 L 0 0 2).424fiParameter Learning Logic Programs Symbolic-statistical Modelingcomputed) O(1) time. Since clauses ground, execution generatessingle child node.(1)(k)enumerate h(1), number nodes Td Td+1 (1 k N ).(k)32 47Figure 10, see h(1)= O(N (L 0 d) ). Let hd (2 k N ) number nodesk)Td(+1contained Td(1)+1. estimated O(N 2 (L 0 0 2)). Consequently, number(k)N32nodes newly created Td(1) h(1)+ k=2 hd = (N (L 0 d) ). result,L033348total time OLDT search computed d=0 hd = O(N L ) also sizesupport graph.consider non-propositional parsing program DBg0 = Fg0 [ Rg0 Figure 11whose ground instances constitute propositional program DBg . DBg0 probabilisticvariant DCG program (Pereira & Warren, 1980) q'/1, q'/6 between/3declared table predicate. Semantically DBg0 specifies probability distributionatoms form fq'(l) j l list terminalsg.PPFg0Rg0t,[sj ,sk ]) j 1 i; j; k N; numberg= fmsw([sfi,msw(si ,t,w) j 1 N; number; w terminalg=8>>>>>>>>>>>><>>>>>>>>>>>>:q'(S) :- length(S,D), q'(s1 ,0,D,0, ,S-[]).q'(I,D0,D2,C0,C2,L0-L2) :- between(D0,D1,D2),msw(I,C0,[J,K]),q'(J,D0,D1,s(C0),C1,L0-L1),q'(K,D1,D2,s(C1),C2,L1-L2).q'(I,D,s(D),C0,s(C0),[W|X]-X) :- msw(I,C0,W).Figure 11: Probabilistic DCG like program DBg0top-goal parse sentence = [w1; : : : ; wL] q'([w1; : : : ; wL]). invokesq'(s1 ,0,D,0, ,[w1 ,: : :,wL ]-[]) measuring length input sentencecalling length=2. 49 50 general, q'(i,d0,d2 ,c0 ,c2 ,l0-l2) works identically q(i,d0 ,d2 )three arguments, c0 , c2 l0-l2, added. c0 supplies unique trial-id mswsused body, c2 latest trial-id current computation, l0 -l2 D-list holdingsubstring d0 d2 . Since added arguments affect shape47. focus subtree Td0 . j , i0 j 0 range 1 N , fif(e; e0 ) j + 2 e0 < e L 0 1 gfi =O((L 0 d)2 ). Hence, number nodes Td0 O(N 3 (L 0 d)2 ). number nodes Td(1)(1)0neither Td(1)= (N 3 (L 0 d)2 ).+1 Td negligible, therefore hd(1)(1)48. number nodes TL01 TL02 negligible.49. make program simple possible, assume integer n represented ground termfi(n)z }| {fis(1 1 1s (0)1 1 1). also assume D0 D2 ground, goal between(D0, D1, D2)returns integer D1 time proportional jD1 0 D0j.50. omit obvious program length(l,sn ) computes length sn list l O(jlj) time.sn =def425fiSato & Kameyasearch tree Figure 10 extra computation caused length=2 O(L)one insertion between(D0,D1,D2) O(NL3) respectively,51 OLDT time remainsO(N 3 L3), hence size support graph.apply graphical EM algorithm correctly, need confirm five conditionsapplicability. rather apparent however OLDT refutation topgoal form q'([w1 ,: : :,wL]) w.r.t. DBg0 terminates, leaves support graphsatisfying finite support condition acyclic support condition. t-exclusivenesscondition independent condition also hold refutation process faithfullysimulates leftmost stochastic derivation w1 11 1 wL choice productionrule made msw(si ,sc,[sj ,sk ]) exclusive independent (trial-ids differentdifferent choices).remains uniqueness condition. confirm it, let us consider another program DBg00 , modification DBg0 first goal length(S,D) bodyfirst clause first goal between(D0,D1,D2) second clause Rg0 movedlast position bodies respectively. DBg00 DBg0 logically equivalent,semantically equivalent well viewpoint distribution semantics. thinksampling execution OLDT interpreter top-goal q'(S) w.r.t. DBg00variable, using multi-stage depth-first search strategy. easy see firstexecution never fails, second OLDT refutation terminates, sentence[w1 ; : : : ; wL ] returned S, third conversely, set msw atoms resolved uponrefutation uniquely determines output sentence [w1 ; : : : ; wL].52 Hence,sampling execution guaranteed always terminate, every sampling PF 00 (= PF 0 )uniquely generates sentence, observable atom, uniqueness condition satisfiedDBg00 , hence DBg0 .sampling execution guaranteed always terminate? words,grammar generate finite sentences? Giving general answer seemsdicult, known parameter values PCFG obtained learningfinite sentences, stochastic derivation PCFG terminates probabilityone (Chi & Geman, 1998). summary, assuming appropriate parameter values,say parameterized logic program DBg0 largest PCFG N nonterminalsymbols satisfies applicability conditions, OLDT time sentence lengthL O(N 3 L3)53 also size support graph. Proposition 5.1,concludeggProposition 5.3 Let DB a0 parameterized logic program representing PCFG Nnonterminals form DBg Figure 11, G = G1 ; G2 ; : : : ; GT sampled atomsrepresenting sentences length L. suppose table operation OLDT search doneO(1) time. OLDT search G one iteration learn-gEM respectivelydone O(N 3 L3T ) time.51.between(D0,D1,D2)called O(N (L 0 d)2 ) times Td(1) . called0 O(N (L 0 d)2 ) = O(NL3 )PL 3d=0times .52. trial-ids used refutation record rule used step derivationw1 1 1 1 wL .53. DBg , represent integers ground terms made 0 s(1) keep program short.use integers instead ground terms however, first three arguments q'(1,1,1,1,1,1) enoughcheck whether goal previously called not, check done O(1) time.(1)00426fiParameter Learning Logic Programs Symbolic-statistical Modeling(N 3 L 3 )also time complexity Inside-Outside algorithm per iteration(Lari & Young, 1990), hence algorithm ecient Inside-Outside algorithm.5.4 Pseudo PCSGsPCFGs improved making choices context-sensitive, one attemptspseudo PCSGs (pseudo probabilistic context sensitive grammars) rule chosen probabilistically depending nonterminal expanded parentnonterminal (Charniak & Carroll, 1994).pseudo PCSG easily programmed. add one extra-argument, N, representingparent node, predicate q'(I,D0,D2,C0,C2,L0-L2) Figure 11 replacemsw(I,C0,[J,K]) msw([N,I],C0,[J,K]). Since (leftmost) derivation sentencepseudo PCSG still sequential decision process described modified program,graphical EM algorithm applied support graphs generated modifiedprogram observed sentences correctly performs ML estimation parameterspseudo PCSG.pseudo PCSG thought PCFG rules form [n; i] ! [i; j ][i; k](1 n; i; j; k N ) n parent nonterminal i, arguments previoussubsection carried minor changes. therefore (details omitted)Proposition 5.4 Let DB parameterized logic program pseudo PCSG Nnonterminals shown above, G = G1; G2 ; : : : ; GT observed atoms representingsampled sentences length L. Suppose table operation OLDT search doneO(1) time. OLDT search G iteration learn-gEM completedO(N 4 L3T ) time.5.5 Bayesian Networksrelationship cause C effect E often probabilistic one diseases symptoms, mathematically captured conditionalprobability P (E = e j C = c) effect e given cause c. wish know howeverinverse, i.e. probability candidate cause c given evidence e, i.e. P (C = c j E = e)calculated Bayes' theorem P (E = e j C = c)P (C = c)= c0 P (E = e j C =c0)P (C = c0 ). Bayesian networks representational/computational framework fitsbest type probabilistic inference (Pearl, 1988; Castillo et al., 1997).Bayesian network graphical representation joint distribution P (X1 = x1 ; : : : ;XN = xN ) finitely many random variables X1 ; : : : ; XN . graph dag (directedacyclic graph) ones Figure 12, node random variable.54graph, conditional probability table (CPT) representing P (Xi = xi j 5i = ui)(1 N ) associated node Xi 5i represents Xi's parent nodes uivalues. Xi parent, i.e. topmost node graph, tablemarginal distribution P (Xi = xi). whole joint distribution defined productP54. deal discrete cases.427fiSato & KameyaBCBCEFE( G 1 ) Singly-connectedF( G 2 ) Multiply-connectedFigure 12: Bayesian networksconditional distributions:P (X1 = x1 ; : : : ; XN= xN )55 =Ni=1P (Xi = xi j 5i = ui ):(21)Thus graph G1 Figure 12 definesPG (a; b; c; d; e; f ) = PG (a)PG (b)PG (c j a)PG (d j a; b)PG (e j d)PG (f j d)a, b, c, d, e f values corresponding random variables A, B, C , D, EF , respectively.56 mentioned before, one basic tasks Bayesian networkscompute marginal probabilities. example, marginal distribution PG (c; d)computed either (22) (23) below.PG (c; d) =PG (a)PG (b)PG (c j a)PG (d j a; b)PG (e j d)P (f j d)(22)11111111X1a;b;e;f11110=X@a;b110PG1 (a)PG1 (b)PG1 (c j a)PG1 (d j a; b)A @1Xe;fPG1 (e j d)PG1 (f j d)A (23)(23) clearly ecient (22). Observe graph like G2Figure 12, would way factorize computations like (23) use (22) requiringexponentially many operations. problem computing marginal probabilitiesNP-hard general, factorization (23) assured graph singlyconnected like G1 , i.e. loop viewed undirected graph. case,computation possible O(jV j) time V set vertices graph (Pearl,1988). Otherwise, graph called multiply-connected, might need exponential timecompute marginal probabilities. sequel, show following.discrete Bayesian network G defining distribution PG (x1 ; : : : ; xN ),parameterized logic program DBG predicate bn(1) PDB (bn(x1,: : :,xN ))= PG(x1 ; : : : ; xN ).G55. Thanks acyclicity graph, without losing generality, may assume Xi ancestornode Xj , < j holds.56. notational simplicity, shall omit random variables confusion arises.428fiParameter Learning Logic Programs Symbolic-statistical Modelingarbitrary factorizations order compute marginal distribution,exists tabled program accomplishes computation specified way.graph singly connected evidence e given, exists tabledprogram DBG OLDT time bn(e) O(jV j), hence timecomplexity per iteration graphical EM algorithm O(jV j) well.Let G Bayesian network defining joint distribution PG(x1 ; : : : ; xN ) fPG (Xi =xi j 5i = ui ) j 1 N; xi 2 val(Xi ); ui 2 val(5i )g conditional probabilitiesassociated G val(Xi) set Xi's possible values val(5i) denotesset possible values parent nodes 5i random vector, respectively.construct parameterized logic program defines distribution PG (x1 ; : : : ; xN ).program DBG = FG [ RG shown Figure 13.FG= f msw(par(i,ui),once,xi) j 1 N; ui 2 val(5i); xi 2 val(Xi) gRG= f bn(X1 ,: : :,XN ):-5i),once,Xi). gVNi=1 msw(par(i,Figure 13: Bayesian network program DBGFG comprised msw atoms form msw(par(i,ui ),once,xi ) whose probabilityexactly conditional probability PG (Xi = xi j 5i = ui). Xi parents, uiempty list []. RG singleton, containing one clause whose body conjunctionmsw atoms corresponds product conditional probabilities. Noteintentionally identify random variables X1 ; : : : ; XN logical variables X1 ; : : : ; XNconvenience.Proposition 5.5 DBG denotes distributions G.(Proof) Let hx1 ; : : : ; xN realization random vector hX1; : : : ; XN i. holdsconstructionPDBG (bn(x1 ,: : :,xN ))=Nh=1NPmsw (msw(par(i,ui ),once,xi ))=PG (Xi = xi j 5i = ui )h=1= PG (x1 ; : : : ; xN ):Q:E:D:case G1 Figure 12, program becomes57bn(A,B,C,D,E,F):-msw(par('A',[]),once,A),msw(par('C',[A]),once,C),msw(par('E',[D]),once,E),57. 0 A0 ; 0 B0 ; : : : Prolog constants used place integers.429msw(par('B',[]),once,B),msw(par('D',[A,B]),once,D),msw(par('F',[D]),once,F).fiSato & Kameyaleft-to-right sampling execution gives sample realization random vectorh A; B; C; D; E; F i. marginal distribution computed bn(x1 ,: : :,xN ) adding newclause DBG. example, compute PG (c; d), add bn(C,D):- bn(A,B,C,D,E,F)DBG (let result DB0G ) compute PDB0 (bn(c,d)) equalPG (c; d)PDB0 (bn(c,d)) = PDB (9 a; b; e; f bn(a,b,c,d,e,f ))=PDB (bn(a,b,c,d,e,f ))a;b;e;f= PG (c; d):Regrettably computation corresponds (22), factorization (23). Ecientprobability computation using factorization made possible carrying summationsproper order.next sketch example carry specified summations specifiedorder introducing new clauses. Suppose joint distribution P (x; y; z; w) =1 (x; )2 (y; z; w)3(x; z; w) 1(x; ), 2(y; z; w) 3 (x; z; w) respectivelycomputed atoms p1 (X,Y), p2 (Y,Z,W) p3 (X,Z,W). Suppose also hopecompute sumP (x) = 1(x; )2 (y; z; w )3 (x; z; w)111G11G1XG1G11XXz;w!first eliminate z; w y. Corresponding elimination, introducetwo new predicates, q(X,Y) compute 4 (x; y) = z;w 2 (y; z; w)3 (x; z; w) p(X)compute P (x) = 1 (x; y)4(x; y) follows.PPp(X)q(X,Y)::-p1(X,Y), q(X,Y).p2(Y,Z,W), p3 (X,Z,W).Note clause body q=2 contains Z W (existentially quantified) local variablesclause head q(X,Y) contains variables shared atoms. viewcorrespondence 9, easy confirm program realizesrequired computation. also easy see generalizing example, thoughprove here, exists parameterized logic program carries givensummations given order arbitrary Bayesian network, particularable simulate (variable elimination, Zhang & Poole, 1996; D'Ambrosio, 1999)approach.Ecient computation marginal distributions always possiblewell-known class Bayesian networks, singly connected Bayesian networks,exists ecient algorithm compute marginal distributions message passing (Pearl,1988; Castillo et al., 1997). show graph singly connected,construct ecient tabled Bayesian network program DBG assigning table predicatenode. avoid complications, explain construction procedure informallyconcentrate case one interested variable. Let G singlyP430fiParameter Learning Logic Programs Symbolic-statistical Modelingconnected graph. First pick node U whose probability PG (u) seek.construct tree G root node U G, letting nodes dangling U .Figure 14 shows G1 transformed tree select node B root node.BEFCTransformed graph G1Figure 14: Transforming G1 treeexamine node G one one. add node X graphcorresponding clause DBG whose purpose visit nodes connected X exceptone calls X . Suppose started root node U1 Figure 15 evidenceu given, generated clause (24). proceed inner node X (U1 callsX ). original graph G, X parent nodes fU1 ; U2; U3g child nodes fV1 ; V2 g. U3topmost node G.U1XU2V2U3V1Tree GFigure 15: General situationnode X Figure 15, add clause (25). called parent nodeU1 U1 ground, first generate possible values U2 calling val U2 (U2),call call X U2 (U2 ) visit nodes connected X U2 . U3 similarytreated. visiting nodes G connecting X parent nodes U2U3 (nodes connected U1 already visited), value random variable Xdetermined sampling msw atom jointly indexed 'X' values U1 , U2431fiSato & KameyaU3 . visit X 's children, V1 V2 . topmost node U3 original graph,add clause (26).tbn(U1 ) :- msw(par('U1 ',[]),once,U1 ), callcallU1 X (U1 ).U1 X (U1 ) :- val U2 (U2), call X U2 (U2 ),val U3 (U3), call X U3 (U3 ),msw(par('X',[U1 ,U2 ,U3 ]),once,X),call X V1 (X), call X V2(X).(24)(25)(26)Let DBG final program containing clauses like (24), (25) (26). ApparentlyDBG constructed time linear number nodes network. Alsonote successive unfolding (Tamaki & Sato, 1984) atoms form call ...(1)clause bodies starts (24) yields program DB0G similar oneFigure 13 contains msw atoms call ...(1)'s. DBG DB0G definedistribution,58 proved Proposition 5.5 PG (u) = PDB0 (bn(u)) =PDB (tbn(u)) holds (details omitted). way, Figure 15 assume constructionstarts topmost node U1 evidence u given, necessary.Suppose change start inner node X. case, replace clause (24)call X U1(U1 ) :- msw(par('U1',[]),once,U1 ) like (26). timereplace head clause (25) tbn() add goal call X U1 (u) bodyon. changed program DB00G , rather straightforward provePDB00 (tbn()) = PG(u) holds. true construction tabled programDBG shown crude lot room optimization, sucesshow parameterized logic program singly connected Bayesian network runsO(jV j) time V set nodes.estimate time complexity OLDT search w.r.t. DBG , declare tbn everypredicate form call ...(1) table predicate verify five conditionsapplicability graphical EM algorithm (details omitted). estimate timecomplexity OLDT search goal tbn(u) w.r.t. DBG .59 notice calls occuraccording pre-order scan (parents { node { children) tree G , callscall X (1) occur val(Y ) times. call call X (1) invokes calls restnodes, X 's parents X 's children graph G except caller node, diffrentset variable instantiations, second call on, every call refers solutionsstored solution table O(1) time. Thus, number added computation stepscallX U3(U3 ) :- msw(par('U3 ',[]),once,U3 ).GGG58. Since distribution semantics based least model semantics, unfold/fold transformation (Tamaki & Sato, 1984) preserves least Herbrand model transformed program, unfold/foldtransformation applied parameterized logic programs preserves denotation transformedprogram.59. DBG transformed OLDT interpreter collect msw atoms like case HMMprogram.432fiParameter Learning Logic Programs Symbolic-statistical ModelingOLDT search X bounded above, constant O(val(U 1)val(U 2)val(U 3)val(X ))case Figure 15. result OLDT time proportional number nodesoriginal graph G (and size support graph) provided numberedges connecting node, values random variable boundedabove.Proposition 5.6 Let G singly connected Bayesian network defining distribution PG ,V set nodes, DBG tabled program derived above. Suppose numberedges connecting node, values random variable boundedconstant. Also suppose table access done O(1) time. Then, OLDT timecomputing PG(u) observed value u random variable U means DBGO(jV j) time per iteration required graphical EM algorithm.observations, time complexity O(jV jT ).O(jV j) time complexity required compute marignal distribution singlyconnected Bayesian network standard algorithm (Pearl, 1988; Castillo et al., 1997),also EM algorithm using it. therefore conclude graphicalEM algorithm ecient specialzed EM algorithm singly connected Bayesiannetworks.60 must also quickly add graphical EM algorithm applicablearbitrary Bayesian networks,61 Proposition 5.6 says explosionsupport graph avoided appropriate programming case singly connectedBayesian networks.summarize, graphical EM algorithm, single generic EM algorithm, provedtime complexity specialized EM algorithms, i.e. Baum-Welch algorithmHMMs, Inside-Outside algorithm PCFGs, one singly connectedBayesian networks developed independently research field.Table 1 summarizes time complexity EM learning using OLDT searchgraphical EM algorithm case one observation. first column, \sc-BNs"represents singly connected Bayesian networks. second column shows program use.DBh HMM proram Subsection 4.7, DBg0 PCFG program Subsection 5.3DBG transformed Bayesian network program Subsection 5.5, respectively. OLDT timethird column time OLDT search complete search t-explanations.gEM fourth column time one iteration taken graphical EM algorithmupdate parameters. use N , , L V respectively number statesHMM, number nonterminals PCFG, length input stringnumber nodes Bayesian network. last column standard (specialized) EMalgorithm model.60. marginal distribution PG one variable required, construct similartabled program computes marginal probabilities still O(jV j) time adding extra-argumentsconvey evidence embedding evidnece program.61. check five conditions DBG Figure 13. uniqueness condition obvious samplingalways uniquely generates sampled value random variable. finite support conditionsatisfied finite number random variables values. acyclic supportcondition immediate acyclicity Bayesian networks. t-exclusiveness conditionindependent condition easy verify.433fiSato & KameyaModelProgramHMMsDBhPCFGsDBg0DBGsc-BNsuser modelOLDT time(N 2L)(M 3 L 3 )O(jV j)O(jOLDT treej)gEMSpecialized EM2O(N L)Baum-Welch33(M L )Inside-OutsideO(jV j)(Castillo et al., 1997)(jsupport graphj)Table 1: Time complexity EM learning OLDT search graphical EM algorithm5.6 Modeling Language PRISMdeveloping symbolic-statistical modeling laguage PRISM since 1995 (URL= http://mi.cs.titech.ac.jp/prism/) implementation distribution semantics(Sato, 1995; Sato & Kameya, 1997; Sato, 1998). language intented modelingcomplex symbolic-statistical phenomena discourse interpretation natural languageprocessing gene inheritance interacting social rules. programming language,looks like extension Prolog new built-in predicates including msw predicatespecial predicates manipulating msw atoms parameters.PRISM program comprised three parts, one directives, one modelingone utilities. directive part contains declarations values, telling systemmsw atoms used execution. modeling part set non-unit definiteclauses define distribution (denotation) program using msw atoms.last part, utility part, arbitary Prolog program refers predicates definedmodeling part. use utility part learn built-in predicate carryEM learning observed atoms.PRISM provides three modes execution. sampling execution correpondsrandom sampling drawn distribution defined modeling part. secondone computes probability given atom. third one returns support setgiven goal. execution modes available built-in predicates.must report however implementation graphical EM algorithmsimpified OLDT search mechanism way, completed yet.currently, Prolog search learn-naive(DB; G) Section 4 available EM learning though realized, partially, structrure sharing explanations implementionlearn-naive(DB; G ). Putting computational eciecy aside however, problemexpressing learning HMMs, PCFGs, pseudo PCSGs, Bayesian networksprobailistic models current version. learning experiments next sectionused parser substitute OLDT interpreter, independently implementedgraphical EM algorithm.6. Learning Experimentscomplexity analysis graphical EM algorithm popular symbolic-probabilisticmodels previous section, look actual behavior graphical EM algorithmreal data section. conducted learning experiments PCFGs using two434fiParameter Learning Logic Programs Symbolic-statistical Modelingcorpora contrasting characters, compared performance graphicalEM algorithm Inside-Outside algorithm terms time per iteration(= time updating parameters). results indicate graphical EM algorithmoutperform Inside-Outside algorithm orders magnigude. Detalis reportedSato, Kameya, Abe, Shirai (2001). proceeding, review Inside-Outsidealgorithm completeness.6.1 Inside-Outside AlgorithmInside-Outside algorithm proposed Baker (1979) generalizationBaum-Welch algorithm PCFGs. algorithm designed estimate parametersCFG grammar Chomsky normal form containing rules expressed numbers like ! j; k(1 i; j; k N N nonterminals, 1 starting symbol). Suppose inputsentence w1 ; : : : ; wL given.iteration, first computes bottom manner3inside probabilities3 e(s; t; i) = P (i ) ws; : : : ; wt) computes outside probabilitiesf (s; t; i) = P (S )w1 ; : : : ; ws01 wt+1 ; : : : ; wL ) top-down manner every s,(1 L; 1 N ). computing probabilities, parametersupdated using them, process iterates predetermined criterionconvergence likelihood input sentence achieved. Although Bakergive analysis Inside-Outside algorithm, Lari Young (1990) showedtakes O(N 3 L3 ) time one iteration Lafferty (1993) proved EM algorithm.true Inside-Outside algorithm recognized standard EMalgortihm training PCFGs, notoriously slow. Although much literatureexplicitly stating time required Inside-Outside algorithm (Carroll & Rooth, 1998;Beil, Carroll, Prescher, Riezler, & Rooth, 1999), Beil et al. (1999) reported exampletrained PCFG 5,508 rules corpus 450,526 German subordinate clauses whose average ambiguity 9,202 trees/clause using four machines (167MHzSun UltraSPARC22 296MHz Sun UltraSPARC-II22), took 2.5 hours completeone iteration. discuss later Inside-Outside algorithm slow.6.2 Learning Experiments Using Two Corporareport parameter learning existing PCFGs using two corpora moderate sizecompare graphical EM algorithm Inside-Outside algorithm termstime per iteration. mentioned before, support graphs, input garphical EMalgorithm, generated parser, i.e. MSLR parser.62 measurements made296MHz Sun UltraSPARC-II 2GB memory Solaris 2.6 thresholdincrease log likelihood input sentences set 1006 stopping criterionEM algorithms.experiments, used ATR corpus EDR corpus (each converted POS(part speech)-tagged corpus). similar size (about 10,000) contrastingcharacters, sentence length ambiguity grammars. first experimentemployed ATR corpus Japanese-English corpus (we used Japanese part)developed ATR (Uratani, Takezawa, Matsuo, & Morita, 1994). contains 10,995 short62. MSLR parser Tomita (Generalized LR) parser developed Tanaka-Tokunaga Laboratory TokyoInstitute Technology (Tanaka, Takezawa, & Etoh, 1997).435fiSato & Kameyaconversational sentences, whose minimum length, average length maximum lengthrespectively 2, 9.97 49. skeleton PCFG, employed context free grammarGatr comprising 860 rules (172 nonterminals 441 terminals) manually developedATR corpus (Tanaka et al., 1997) yields 958 parses/sentence.Inside-Outside algorithm accepts CFG Chomsky normal form,converted Gatr Chomsky normal form G3atr . G3atr contains 2,105 rules (196 nonterminals 441 terminals). divided corpus subgroups similar lengthlike (L = 1; 2); (L = 3; 4); : : : ; (L = 25; 26), containing randomly chosen 100 sentences.preparations, compare length graphical EM algorithm appliedGatr G3atr Inside-Outside algorithm applied G3atr terms time periteration running convergence.(sec)(sec)(sec)60I-O500.70.040.60.0350.5400.40.03I-OgEM (original)gEM (Chomsky NF)0.0250.02300.3200.0150.2100.010.10.005510152025LLL0gEM (original)gEM (Chomsky NF)05101520250510 15 20 25Figure 16: Time per iteration : I-O vs. gEM (ATR)Curves Figure 16 show learning results x-axis length L inputsentence y-axis average time taken EM algorithm one iteration updateparameters contained support graphs generated chosen 100 sentences(other parameters grammar change). left graph, Inside-Outsidealgorithm plots cubic curve labeled \I-O". omitted curve drawn graphicalEM algorithm drew x-axis. middle graph magnifies left graph. curvelabeled \gEM (original)" plotted graphical EM algorithm applied originalgrammar Gatr whereas one labeled \gEM (Chomsky NF)" used G3atr. length 10,average sentence length, measured whichever grammar employed, graphicalEM algorithm runs several hundreds times faster (845 times faster case Gatr720 times faster case G3atr) Inside-Outside algorithm per iteration.right graph shows (almost) linear dependency updating time graphical EMalgorithm within measuared sentence length.Although difference anticipated learning speed, speed gapInside-Outside algorithm graphical EM algorithm unexpectedly large.conceivable reason ATR corpus contains short sentences Gatr436fiParameter Learning Logic Programs Symbolic-statistical Modelingmuch ambiguous parse trees sparse generated support graphs small,affects favorably perforamnce graphical EM algorithm.therefore conducted experiment another corpus contains muchlonger sentences using ambiguous grammar generates dense parse trees.used EDR Japanese corpus (Japan EDR, 1995) containing 220,000 Japanese news articlesentences. however process re-annotation, part (randomlysampled 9,900 sentences) recently made available labeled corpus. ComparedATR corpus, sentences much longer (the average length 9,900 sentences 20,minimum length 5, maximum length 63) CFG grammar Gedr (2,687 rules,converted Chomsky normal form grammar G3edr containing 12,798 rules) developedambiguous (to keep coverage rate), 3:0 2 108 parses/sentence length20 6:7 2 1019 parses/sentence length 38.(sec)5000(sec)(sec)3106000I-O8I-OgEM (original)2.5gEM (original)2400061.53000412000210000L5 10 15 20 25 30 35 4000.5L5 10 15 20 25 30 35 400L5 10 15 20 25 30 35 40Figure 17: Time per iteration : I-O vs. gEM (EDR)Figure 17 shows obtained curves experiments EDR corpus (the graphical EM algorithm applied Gedr vs. Inside-Outside algorithm applied G3edr)condition ATR corpus, i.e. plotting average time per iteration process 100sentences designated length, except plotted time Inside-Outside algorithm average 20 iterations whereas graphical EM algorithmaverage 100 iterations. clear middle graph, time again, graphicalEM algorithm runs orders magnitude faster Inside-Outside algorithm. average sentence length 20, former takes 0.255 second whereas latter takes 339 seconds,giving speed ratio 1,300 1. sentence length 38, former takes 2.541 secondslatter takes 4,774 seconds, giving speed ratio 1,878 1. Thus speed ratio evenwidens compared ATR corpus. explained mixed effects O(L3 ),time complexity Inside-Outside algorithm, moderate increase total sizesupport graphs w.r.t. L. Notice right graph shows total size supportgraphs grows sentence length L time per iteration graphical EM algorithmlinear total size support graphs.437fiSato & KameyaSince implemented Inside-Outside algorithm faithfully Baker (1979), LariYoung (1990), much room improvement. Actually Kita gave refined InsideOutside algorithm (Kita, 1999). also implementation Mark JohnsonInside-Outside algorithm down-loadable http://www.cog.brown.edu/%7Emj/.use implementations may lead different conclusions. therefore conductedlearning experiments entire ATR corpus using two implementationsmeasured updating time per iteration (Sato et al., 2001). turned implementations run twice fast naive implementation take 630 seconds periteration graphical EM algorithm takes 0.661 second per iteration, stillorders magnitude faster former two. Regrettably similar comparison usingentire EDR corpus available moment abandoned due memory owparsing construction support graphs.Learning experiments far compared time per iteration ignore extra timesearch (parsing) required graphical EM algorithm. question naturally arisesw.r.t. comparison terms total learning time. Assuming 100 iterations learningATR corpus however, estimated even considering parsing time, graphicalEM algorithm combined MSLR parser runs orders magnitude faster threeimplementations (ours, Kita's Johnson's) Inside-Outside algorithm (Sato et al.,2001). course estimation directly apply graphical EM algorithmcombined OLDT search, OLDT interpreter take time parsermuch time needed depends implementaiton OLDT search.63Conversely, however, may able take rough indication far approach,graphical EM algorithm combined OLDT search via support graphs, godomain EM learning PCFGs.6.3 Examing Performance Gapprevious subsection, compared performance graphical EM algorithmInside-Outside algorithm PCFGs given, using two corpora threeimplementations Inside-Outside algorithm. experiments, graphical EMalgorithm considerably outperformed Inside-Outside algorithm despite facttime complexity. look causes performancegap.Simply put, Inside-Outside algorithm slow (primarily) lacks parsing.Even backbone CFG grammar explicitly given, take advantageconstraints imposed grammar. see it, might help review insideprobability e(s; t; A), i.e. P(nonterminal spans s-th word t-th word) (s t),calculated Inside-Outside algorithm given grammar.e(s; t; A) =r=t01XP(A ! BC )e(s; r; B)e(r + 1; t; C )s.t. A!BC grammar r=sP(A ! BC ) probability associated production rule ! BC . Notefixed triplet (s; t; A), usual term P(A ! BC )e(s; r; B )e(r +1; t; C ) non-zeroXB;C63. cannnot answer question right implementation OLDT search completed.438fiParameter Learning Logic Programs Symbolic-statistical Modelingrelatively small number (B; C; r)'s determined successful parsesrest combinations always give 0 term. Nonetheless Inside-Outside algorithmattempts compute term every iteration possible combinations B, Cr repeated every possible (s; t; A), resulting lot redundancy.kind redundancy occurs computation outside probability Inside-Outsidealgorithm.graphical EM algorithm free redundancy runs parse trees (aparse forest) represented support graph.64 must added, hand,superiority learning speed graphical EM algorithm realized cost spacecomplexity Inside-Outside algorithm merely requires O(NL2 ) spacearray store probabilities, graphical EM algorithm needs O(N 3 L3 ) space storesupport graph N number nonterminals L sentence length.trade-off understandable one notices graphical EM algorithm appliedPCFG considered partial evaluation Inside-Outside algorithmgrammar (and introduction appropriate data structure output).Finally remark use parsing preprocess EM learning PCFGsunique graphical EM algorithm (Fujisaki, Jelinek, Cocke, Black, & Nishino, 1989;Stolcke, 1995). approaches however still seem contain redundancies comparedgraphical EM algorithm. instance Stolcke (1995) uses Earley chart computeinside outside probability, parses implicitly reconstructed iterationdynamically combining completed items.7. Related Work Discussion7.1 Related Workwork presented paper crossroads logic programming probabilitytheory, considering enormous body work done fields, incompletenessunavoidable reviewing related work. said that, look various attemptsmade integrate probability computational logic logic programming.65 reviewing, one immediately notice two types usage probability. One type,constraint approach, emphasizes role probability constraints necessarily seek unique probability distribution logical formulas. type,distribution approach, explicitly defines unique distribution model theoretical meansproof theoretical means, compute various probabilities propositions.typical constraint approach seen early work probabilistic logic Nilsson(1986). central problem, \probabilistic entailment problem", compute upperlower bound probability P() target sentence way boundscompatible given knowledge base containing logical sentences (not necessarilylogic programs) annotated probability. probabilities work constraints64. emphasize difference Inside-Outside algorithm graphical EM algorithmsolely computational eciency, converge parameter values startinginitial values. Linguistic evaluations estimated parameters graphical EM algorithmalso reported Sato et al. (2001).65. omit literature leaning strongly toward logic. logic(s) concerning uncertainty, see overviewKyburg (1994).439fiSato & Kameyapossible range P(). used linear programming technique solve probleminevitably delimits applicability approach finite domains.Later Lukasiewicz (1999) investigated computational complexity probabilisticentailment problem slightly different setting. knowledge base comprises statementsform (H j G)[u1 ; u2 ] representing u1 P(H j G) u2 . showed inferring\tight" u1 ; u2 NP-hard general, proposed tractable class knowledge base calledconditional constraint trees.uential work Nilsson, Frish Haddawy (1994) introduced deductive system probabilistic logic remedies \drawbacks" Nilsson's approach,computational intractability lack proof system. system deducesprobability range proposition rules probabilistic inferences unconditionalconditional probabilities. instance, one rules infers P (ff j ) 2 [0 y]P (ff _ fi j ) 2 [x ] ff,fi propositional variables [x y] (x ) designatesprobability range.Turning logic programming, probabilistic logic programming formalized NgSubrahmanian (1992) Dekhtyar Subrahmanian (1997) also constraint approach. program set annotated clauses form : F1 : 1; : : : ; Fn : natom, Fi (1 n) basic formula, i.e. conjunction disjunctionatoms, j (0 j n) sub-interval [0; 1] indicating probability range. query9 (F1 : 1 ; : : : ; Fn : n) answered extension SLD refutation. formalization,assumed language contains finite number constant predicatesymbols, function symbol allowed.similar framework proposed Lakshmanan Sadri (1994) syntactic restrictions (finitely many constant predicate symbols functionsymbols)different uncertainty setting. used annotated clauses form c B1 ; : : : ; BnBi (1 n) atoms c = h[ff; fi ]; [ ; ]i, confidence level, representsbelief interval [ff; fi ] (0 ff fi 1) doubt interval [ ; ] (0 1),expert clause.seen above, defining unique probability distribution secondary concernconstraint approach. sharp contrast Bayesian networks wholediscipline rests ability networks define unique probability distribution(Pearl, 1988; Castillo et al., 1997). Researchers Bayesian networks seekingway mixing Bayesian networks logical representation increase inherentlypropositional expressive power.Breese (1992) used logic programs automatically build Bayesian networkquery. Breese's approach, program union definite clause program setconditional dependencies form P(P j Q1 ^ 1 11 ^ Qn ) P Qi atoms.Given query, Bayesian network constructed dynamically connects queryrelevant atoms program, turn defines local distribution connectedatoms. Logical variables appear atoms function symbol allowed.Ngo Haddawy (1997) extended Breese's approach incorporating mechanismecting context. used clause form P(A0 j A1 ; : : : ; ) = ff L1 ; : : : ; Lk ,Ai's called p-atoms (probabilistic atoms) whereas Lj 's context atoms disjointp-atoms, computed another general logic program (satisfying certain restric440fiParameter Learning Logic Programs Symbolic-statistical Modelingtions). Given query, set evidence context atoms, relevant ground p-atomsidentified resolving context atoms away SLDNF resolution, local Bayesian network built calculate probability query. proved soundnesscompleteness query evaluation procedure condition programsacyclic66 domains finite.Instead defining local distribution query, Poole (1993) defined global distribution \probabilistic Horn abduction". program consists definite clausesdisjoint declarations form disjoint([h1 :p1,...,hn:pn]) specifies probability distribution hypotheses (abducibles) fh1; : : : ; hn g. assigned probabilitiesground atoms help theory logic programming, furthermore provedBayesian networks representable framework. Unlike previous approaches,language contains function symbols, acyclicity condition imposed programssemantics definable seems severe restriction. Also, probabilitiesdefined quantified formulas.Bacchus et al. (1996) used much powerful first-order probabilistic languageclauses annotated probabilities. language allows statistically quantified termk (x)j(x) kx denote ratio individuals finite domain satisfying (x) ^(x) satisfying (x). Assuming every world (interpretation language)equally likely, define probability sentence ' given knowledge('^KB)base KB limit limN !1 ##worldsworlds (KB) #worldsN () numberpossible worlds containing N individuals satisfying , parameters used judgingapproximations. Although limit necessarily exist domain must finite,showed method cope diculties arising \direct inference"default reasoning.linguistic vein, Muggleton (1996, others) formulated SLPs (stochasticlogic programs) procedurally, extension PCFGs probabilistic logic programs.So, clause C , must range-restricted,67 annotated probability p likep : C . probability goal G product ps appearing refutationmodification subgoal g invoke n clauses, pi : Ci (1 n)refutation step, probability choosing k-th clause normalized pk = ni=1 pi.recently, Cussens (1999, 2001) enriched SLPs introducing special classlog-linear models SLD refutations w.r.t. given goal. example considerspossible SLD refutations general goal s(X ) defines probability P(R)refutation R P(R) = Z 01 exp( (R; i)). number associatedclause Ci (R; i) feature, i.e. number occurrences Ci R. Znormalizing constant. Then, probability assigned s(a) sum probabilitiesrefutation s(a).NNPP66. condition says every ground atom must assigned unique integer n(A) n(A) >n(B1 ); : : : ; n(Bn ) holds ground instance clause form B1 ; : : : ; Bn .condition, program includes p(X ) q(X; ), cannot write recursive clauses qq (X; [H jY ]) q(X; ).67. syntactic property variables appearing head also appear body clause. unitclause must ground.441fiSato & Kameya7.2 Limitations Potential ProblemsApproaches described far less similar limitations potential problems.Descriptive power confined finite domains common limitation, dueuse linear programming technique (Nilsson, 1986), due syntacticrestrictions allowing infinitely many constant, function predicate symbols (Ng& Subrahmanian, 1992; Lakshmanan & Sadri, 1994). Bayesian networkslimitation well (only finite number random variables representable).68 Alsovarious semantic/syntactic restrictions logic programs. instance acyclicitycondition imposed Poole (1993) Ngo Haddawy (1997) prevents unconditionaluse clauses local variables, range-restrictedness imposed Muggleton(1996) Cussens (1999) excludes programs usual membership Prolog program.another type problem, possibility assigning con icting probabilitieslogically equivalent formulas. SLPs, P(A) P(A ^ A) necessarily coincide^ may different refutations (Muggleton, 1996; Cussens, 1999, 2001).Consequently SLPs, would trouble naively interpret P(A) probabilityA's true. Also assigning probabilities arbitrary quantified formulas seemsscope approaches SLPs.Last least, big problem common approach using probabilities:numbers come from? Generally speaking, use n binary random variablesmodel, determine 2n probabilities completely specify joint distribution,fulfilling requirement reliable numbers quickly becomes impossible n grows.situation even worse unobservable variables modelpossible causes disease. Apparently parameter learning observed data naturalsolution problem, parameter learning logic programs well studied.Distribution semantics proposed Sato (1995) attempt solve problemsalong line global distribution approach. defines distribution (probabilitymeasure) possible interpretations ground atoms arbitrary logic programfirst order language assigns consistent probabilities closed formulas. Alsodistribution semantics enabled us derive EM algorithm parameter learninglogic programs first time. naive algorithm however, dealing largeproblems dicult exponentially many explanations observationlike HMMs. believe eciency problem solved large extentgraphical EM algorithm presented paper.7.3 EM LearningSince EM learning one central issues paper, separately mention workrelated EM learning symbolic frameworks. Koller Pfeffer (1997) usedapproach KBMC (knowledge-based model construction) EM learning estimate parameters labeling clauses. express probabilistic dependencies among events definite clauses annotated probabilities, similarly Ngo Haddawy's (1997) approach,locally build Bayesian network relevant context evidence well68. However, RPMs (recursive probability models) proposed Pfeffer Koller (2000) extensionBayesian networks allow infinitely many random variables. organized attributesclasses probability measure attribute values introduced.442fiParameter Learning Logic Programs Symbolic-statistical Modelingquery. Parameters learned applying constructed network specialized EMalgorithm Bayesian networks (Castillo et al., 1997).Dealing PCFG statically constructed Bayesian network proposed Pynadath Wellman (1998), possible combine EM algorithm methodestimate parameters PCFG. Unfortunately, constructed network singlyconnected, time complexity probability computation potentially exponentiallength input sentence.Closely related EM learning parameter learning log-linear models. Riezler (1998) proposed IM algorithm approach probabilistic constraint programming. IM algorithm general parameter estimation algorithm incomplete datalog-linear models whose probability function P(x) takes form P(x) =Z 01 exp( ni=1 (x)) p0 (x) (1 ; : : : ; n ) parameters estimated, (x)i-th feature observed object x Z normalizing constant. Since featurefunction x, log-linear model highly exible includes distributionPmsw special case Z = 1. price pay however; computational costZ . requires summation exponentially many terms. avoid cost exactcomputation, approximate computation Monte Carlo method possible. Whicheverone may choose however, learning time increases compared EM algorithm Z = 1.FAM (failure-adjusted maximization) algorithm proposed Cussens (2001)EM algorithm applicable pure normalized SLPs may fail. deals specialclass log-linear models ecient IM algorithm. statisticalframework FAM rather different distribution semantics, comparisongraphical EM algorithm seems dicult.slightly tangential EM learning, Koller et al. (1997) developed functionalmodeling language defining probability distribution symbolic structuresshowed \cashing" computed results leads ecient probability computationsingly connected Bayesian networks PCFGs. cashing corresponds computation inside probability Inside-Outside algorithm computation outsideprobability untouched.P7.4 Future DirectionsParameterized logic programs expected useful modeling tool complex symbolicstatistical phenomena. tried various types modeling, besides stochastic grammars Bayesian networks, modeling gene inheritance Kariera tribe(White, 1963) rules bi-lateral cross-cousin marriage four clans interactrules genetic inheritance (Sato, 1998). model quite interdisciplinary,exibility combining msw atoms means definite clauses greatly facilitatedmodeling process.Although satisfying five conditions Section 4uniqueness condition (roughly, one cause yields one effect)finite support condition (there finite number explanations one observation)acyclic support condition (explanations must cyclic)443fiSato & Kameyat-exclusiveness condition (explanations must mutually exclusive)independence condition (events explanation must independent)applicability graphical EM algorithm seems daunting, modeling experiences far tell us modeling principle Section 4 effectively guides us successfulmodeling. return, obtain declarative model described compactly high levellanguage whose parameters eciently learnable graphical EM algorithm shownpreceding section.One future directions however relax applicability conditions,especially uniqueness condition prohibits generative model failuregenerating multiple observable events. Although pointed Section 4.4 MARcondition Appendix B adapted semantics replace uniqueness conditionvalidates use graphical EM algorithm even complete data uniquelydetermine observed data like case \partially bracketed corpora" (Pereira &Schabes, 1992), feel need research topic. Also investigatingrole acyclicity condition seems theoretically interesting acyclicity oftenrelated learning logic programs (Arimura, 1997; Reddy & Tadepalli, 1998).paper scratched surface individual research fields HMMs,PCFGs Bayesian networks. Therefore, remains much done clarifyingexperiences research field ected framework parameterized logicprograms. example, need clarify relationship symbolic approachesBayesian networks SPI (Li, Z. & D'Ambrosio, B., 1994) approach.Also unclear compiled approach using junction tree algorithm Bayesiannetworks incorporated approach. Aside exact methods, approximatemethods probability computation specialized parameterized logic programs must alsodeveloped.also direction improving learning ability introducing priors instead MLestimation cope data sparseness. introduction basic distributions makeprobabilistic switches correlated seems worth trying near future. also importanttake advantage logical nature approach handle uncertainty. example,already shown Sato (2001) learn parameters negative examples\the grass wet" treatment negative examples parameterizedlogic programs still infancy.Concerning developing complex statistical models based \programs distributions" scheme, stochastic natural language processing exploits semantic informationseems promising. instance, unification-based grammars HPSGs (Abney, 1997)may good target beyond PCFGs use feature structures logically describable, ambiguity feature values seems expressible probabilitydistribution.Also building mathematical basis logic programs continuous random variableschallenging research topic.444fiParameter Learning Logic Programs Symbolic-statistical Modeling8. Conclusionproposed logical/mathematical framework statistical parameter learningparameterized logic programs, i.e. definite clause programs containing probabilistic factsparameterized probability distribution. extends traditional least Herbrandmodel semantics logic programming distribution semantics , possible world semanticsprobability distribution possible worlds (Herbrand interpretations)unconditionally applicable arbitrary logic programs including ones HMMs, PCFGsBayesian networks.also presented new EM algorithm, graphical EM algorithm Section 4,learns statistical parameters observations class parameterized logic programs representing sequential decision process decision exclusiveindependent. works support graph s, new data structure specifying logical relationship observed goal explanations, estimates parameters computinginside outside probability generalized logic programs.complexity analysis Section 5 showed OLDT search, complete tabledrefutation method logic programs, employed support graph constructiontable access done O(1) time, graphical EM algorithm, despite generality,time complexity existing EM algorithms, i.e. Baum-Welch algorithmHMMs, Inside-Outside algorithm PCFGs one singly connected Bayesiannetworks developed independently research field. addition,pseudo probabilistic context sensitive grammars N nonterminals, showedgraphical EM algorithm runs time O(N 4 L3) sentence length L.compare actual performance graphical EM algorithm InsideOutside algorithm, conducted learning experiments PCFGs Section 6 using tworeal corpora contrasting characters. One ATR corpus containing short sentencesgrammar much ambiguous (958 parses/sentence), EDRcorpus containing long sentences grammar rather ambiguous (3:0 2 108average sentence length 20). cases, graphical EM algorithm outperformedInside-Outside algorithm orders magnitude terms time per iteration,suggests effectiveness approach EM learning graphical EM algorithm.Since semantics limited finite domains finitely many random variablesapplicable logic programs arbitrary complexity, graphical EM algorithmexpected give general yet ecient method parameter learning models complexsymbolic-statistical phenomena governed rules probabilities.Acknowledgmentsauthors wish thank three anonymous referees comments suggestions.Special thanks go Takashi Mori Shigeru Abe stimulating discussions learningexperiments, also Tanaka-Tokunaga Laboratory kindly allowing useMSLR parser linguistic data.445fiSato & KameyaAppendix A. PropertiesPDBappendix, list properties PDB defined parameterized logic programDB = F [ R countable first-order language L.69 First all, PDB assigns consistentprobabilities70 every closed formula LPDB () def= PDB (f! 2DB j ! j= g)guaranteeing continuity senselimn!1 PDB ((t1 ) ^ 1 11 ^ (tn)) = PDB (8x(x))limn!1 PDB ((t1 ) _ 1 11 _ (tn)) = PDB (9x(x))t1 ; t2 ; : : : enumeration ground terms L.next proposition, Proposition A.1, relates PDB Herbrand model. proveit, need terminology. factor closed formula prenex disjunctive normalform Q1 1 1 1 QnM Qi (1 n) either existential quantification universalquantification matrix. length quantifications n called rankfactor. Define 8 set formulas made factors, conjunctions disjunctions.Associate formula 8 multi-set r() ranks;factor quantificationr () =fngfactor rank nr(1) ] r (2 ) = 1 _ 2 = 1 ^ 2:] stands union two multi-sets. instance f1; 2; 3g]f2; 3; 4g = f1; 2; 2; 3; 3; 4g.use multi-set ordering proof Proposition A.1 usual inductioncomplexity formulas work.Lemma A.1 Let boolean formula made ground atoms L. PDB() =PF (f 2F j MDB ( ) j= g).(Proof) prove lemma conjunction atoms form D1x ^1 11 ^ Dnx (xi 2 f0; 1g; 1 n).PDB (D1x ^ 1 11 ^ Dnx ) = PDB (f! 2DB j ! j= D1x ^ 11 1 ^ Dnx g)= PDB (D1 = x1 ; : : : ; Dn = xn)= PF (f 2F j MDB ( ) j= D1x ^ 1 11 ^ Dnx g) Q.E.D.8><>:1n1nn11nProposition A.1 Let closed formula L. PDB() = PF (f 2F j MDB( ) j= g).69. definitionsF , PF , MDB ( ),DB , PDB others used below, see Section 3.70. consistent, mean probabilities assigned logical formulas respect laws probability0 P (A) 1, P (:A) = 1 0 P (A) P (A _ B ) = P (A) + P (B ) 0 P (A ^ B ).446fiParameter Learning Logic Programs Symbolic-statistical Modeling(Proof) Recall closed formula equivalent prenex disjunctive normal formbelongs 8. prove proposition formulas 8 using inductionmulti-set ordering fr() j 2 8g. r() = ;, quantification.proposition correct Lemma A.1. Suppose otherwise. Write = G[Q1 Q2 11 1 Qn F ]Q1 Q2 1 11 QnF indicates single occurrence factor G.71 assume Q1 = 9x(Q1 = 8x similarly treated). also assume bound variables renamed avoidname clash. G[9xQ2 11 1 Qn F ] equivalent 9xG[Q2 1 11 QnF ] light validity(9xA) ^ B = 9x(A ^ B) (9xA) _ B = 9x(A _ B) B contains free x.PDB () = PDB (G[Q1 Q2 1 11 QnF ])= PDB (9xG[ Q2 11 1 Qn F [x]])= klimP (G[ Q2 11 1 Qn F [t1 ]] _ 1 11 _ G[Q2 11 1 Qn F [tk ]])!1 DB= klimP (G[ Q2 11 1 Qn F [t1 ] _ 1 11 _ Q2 11 1 Qn F [tk ]])!1 DB= klimP (f 2F j MDB ( ) j= G[ Q2 1 11 QnF [t1] _ 11 1 _ Q2 1 11 QnF [tk ] ]g)!1 F(by induction hypothesis)= PF (f 2F j MDB ( ) j= 9xG[Q2 1 11 QnF [x]]g)= PF (f 2F j MDB ( ) j= g)Q.E.D.next prove theorem iff definition introduced Section 4. Distributionsemantics considers program DB = F [ R set infinitely many ground definiteclauses F set facts (with probability measure PF ) R set rules,clause head R appears F . Puthead(R) def= fB j B appears R clause headg:B 2 head(R), let B Wi (i = 1; 2; : : :) enumeration clauses B R.Define iff (B), iff (if-and-only-if) form rules B DB72iff (B) def= B $ W1 _ W2 _ 1 1 1Since MDB ( ) least Herbrand model, following obvious.Lemma A.2 B head(R) 2F , MDB( ) j= iff (B).Theorem A.1 iff (B). states general level, sides iffdefinition p(x) $ 9y1 (x = t1 ^ W1 ) _ 1 11 _ 9yn (x = tn ^ Wn) p(1) coincide randomvariables whenever x instantiated ground term.Theorem A.1 Let iff (B ) = B $ W1 _ W2 _11 1 iff form rules B 2 head(R).PDB (iff (B )) = 1 PDB (B ) = PDB (W1 _ W2 _ 1 11).71. expression E , E [ ] means may occur specified positions E . 1 _ 2 E [ 1 _ 2 ]indicates single occurrence 1 _ 2 positive boolean formula E , E [ 1 _ 2 ] = E [ 1 ] _ E [ 2 ] holds.72. definition different usual one (Lloyd, 1984; Doets, 1994) talking groundlevel. W1 _ W2 _ 1 1 1 true one disjuncts true.447fiSato & Kameya(Proof)PDB (iff (B ))=PDB (f! 2DB j ! j= B ^ (W1 _ W2 _ 11 1)g)+PDB (f! 2DB j ! j= :B ^ :(W1 _ W2 _ 1 11)g)= klimP (f! 2DB j ! j= B ^!1 DBk_i=1Wi g)+ klimP (f! 2DB j ! j= :B ^ :!1 DB= klimP (f 2F j MDB ( ) j= B ^!1 Fk_i=1k_i=1Wi g)Wi g)k_+ klimP (f 2F j MDB ( ) j= :B ^ : Wi g)!1 Fi=1(Lemma A.1)= PF (f 2F j MDB ( ) j= iff (B)g)= PF (F ) (Lemma A.2)= 1follows PDB (iff (B)) = 1PDB (B ) = PDB (B ^ iff(B )) = PDB (W1 _ W2 _ 1 1 1):Q.E.D.prove proposition useful probability computation. Let DB (B )support set atom B introduced Section 4 (it set explanations B).sequel, B ground atom. Write DB (B) = fS1 ; S2; : : :g DB (B) = S1 _S2 _1 1173Define set 3B3B def= f! 2DB j ! j= B $ DB (B)g:Proposition A.2 every B 2 head(R), PDB(3B ) = 1 PDB (B) = PDB( DB (B)).(Proof) first prove PDB (3B ) = 1 proof exactly parallels Theorem A.1except W1 _ W2 _ 1 1 1 replaced S1 _ S2 _ 11 1 using fact B $ S1 _ S2 _ 11 1true every least Herbrand model form MDB ( ). PDB (3B ) = 1,PDB (B ) = PDB (B ^ (B $DB (B )))= PDB ( DB (B)):Q.E.D.Finally, show distribution semantics probabilistic extension traditionalleast Herbrand model semantics logic programming proving Theorem A.2. saysprobability mass distributed exclusively possible least Herbrand models.Define 3 set least Herbrand models generated fixing R varying subsetF program DB = F [ R. symbols,W_W__W73. set K = fE1 ; E2 ; : : :g formulas, K denotes (-n infinite) disjunction E1 _ E2 _ 1 1 1448fiParameter Learning Logic Programs Symbolic-statistical Modeling3 def= f! 2DB j ! = MDB () 2F g:Note 3 merely subsetDB , cannot conclude PDB (3) = 1 priori,next theorem, Theorem A.2, states PDB (3) = 1, i.e. distribution semantics distributesprobability mass exclusively 3, i.e. possible least Herbrand models.prove theorem, need preparations. Recalling atoms outside head(R)[F chance proved DB, introduce30 def= f! 2DB j ! j= :D every ground atom 62 head(R) [ F g:Herbrand interpretation ! 2DB , !jF (2F ) restriction ! atomsF .Lemma A.3 Let ! 2DB Herbrandinterpretation.0! = MDB ( ) 2F iff ! 2 3 ! j= B $ DB (B ) every B 2 head(R).(Proof) Only-if part immediate property least Herbrand model.if-part, suppose ! satisfies right hand side. show ! = MDB (!jF ). !MDB (! jF ) coincide w.r.t. atoms head(R), enough prove also givetruth values atoms head(R). Take B 2 head(R) write DB (B) =S1 _ S2 _ 1 11 Suppose ! j= B $ S1 _ S2 _ 11 1 ! j= B , ! j= Sj j ,thereby !jF j= Sj , hence MDB (!jF ) j= Sj , implies MDB (!jF ) j= B. Otherwise! j= :B . ! j= :Sj every j . follows MDB (! jF ) j= :B . Since B arbitrary,conclude ! MDB (!jF ) agree truth values assigned atoms head(R)well.Q.E.D.WWTheorem A.2 PDB(3) = 1.(Proof) Lemma A.3,3 = f! 2DB j ! = MDB ( ) 2F g= 30 \3B :\B2head(R)PDB (3B ) = 1 Proposition A.2. prove PDB (30 ) = 1, let D1; D2 ; : : : enumerationatoms belonging head(R) [ F . provable DB = F [ R,hence false every least Herbrand model MDB ( ) ( 2F ).PDB (30 )= mlim!1 PDB (f! 2DB j ! j= :D1 ^ 11 1 ^ :Dm g)= mlim!1 PF (f 2F j MDB ( ) j= :D1 ^ 1 1 1 ^ :Dm g)= PF (F ) = 1:Since countable conjunction measurable sets probability measure one alsoprobability measure one, follows PDB (3B ) = 1 every B 2 head(R) PDB (30) =1 PDB (3) = 1.Q.E.D.449fiSato & KameyaAppendix B. MAR (missing random) Conditionoriginal formulation EM algorithm Dempster et al. (1977), assumedexists many-to-one mapping = (x) complete data x incomplete(observed) data y. case parsing, x parse tree input sentence xuniquely determines y. paper, uniqueness condition ensures existencemany-to-one mapping explanations observations. however sometimes facesituation many-to-one mapping complete data incompletedata nonetheless wish apply EM algorithm.dilemma solved introduction missing-data mechanismmakes complete data incomplete. missing-data mechanism, m, distributiong (m j x) parameterized , observed data, described = (x). saysx becomes incomplete m. correspondence x , i.e. fhx; j 9m(y =(x))g naturally becomes many-to-many.Rubin (1976) derived two conditions g (data missing random dataobserved random) collectively called MAR (missing random) condition, showedassume missing-data mechanism behind observations satisfies MARcondition, may estimate parameters distribution x simply applyingEM algorithm y, observed data.adapt MAR condition parameterized logic programs follows. keepgenerative model satisfying uniqueness condition outputs goals G parsetrees. extend model additionally inserting missing-data mechanismG observation like = (G) assume satisfies MARcondition. extended model many-to-many correspondence explanations observations, generates non-exclusive observations P (O ^ O0 ) > 0(O 6= O0 ), causes P (O) 1 P (O) = G:9m O= (G) PDB (G). ThanksMAR condition however, still allowed apply EM algorithm nonexclusive observations. Put differently, even uniqueness condition seeminglydestroyed, EM algorithm applicable (imaginarily) assuming missing-datamechanism satisfying MAR condition.PPReferencesAbney, S. (1997). Stochastic attribute-value grammars. Computational Linguistics, 23 (4),597{618.Arimura, H. (1997). Learning acyclic first-order horn sentences entailment.Proceedings Eighth International Workshop Algorithmic Learning Theory.Ohmsha/Springer-Verlag.Bacchus, F., Grove, A., Halpern, J., & Koller, D. (1996). statistical knowledge basesdegrees belief. Artificial Intelligence, 87, 75{143.Baker, J. K. (1979). Trainable grammars speech recognition. Proceedings SpringConference Acoustical Society America, pp. 547{550.450fiParameter Learning Logic Programs Symbolic-statistical ModelingBeil, F., Carroll, G., Prescher, D., Riezler, S., & Rooth, M. (1999). Inside-Outside estimationlexicalized PCFG German. Proceedings 37th Annual MeetingAssociation Computational Linguistics (ACL'99), pp. 269{276.Breese, J. S. (1992). Construction belief decision networks. Computational Intelligence, 8 (4), 624{647.Carroll, G., & Rooth, M. (1998). Valence induction head-lexicalized PCFG. Proceedings 3rd Conference Empirical Methods Natural Language Processing(EMNLP 3).Castillo, E., Gutierrez, J. M., & Hadi, A. S. (1997). Expert Systems ProbabilisticNetwork Models. Springer-Verlag.Charniak, E., & Carroll, G. (1994). Context-sensitive statistics improved grammatical language models. Proceedings 12th National Conference ArtificialIntelligence (AAAI'94), pp. 728{733.Chi, Z., & Geman, S. (1998). Estimation probabilistic context-free grammars. Computational Linguistics, 24 (2), 299{305.Chow, Y., & Teicher, H. (1997). Probability Theory (3rd ed.). Springer.Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), LogicDatabases, pp. 293{322. Plenum Press.Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT Press.Cussens, J. (1999). Loglinear models first-order probabilistic reasoning. Proceedings15th Conference Uncertainty Artificial Intelligence (UAI'99), pp. 126{133.Cussens, J. (2001). Parameter estimation stochastic logic programs. Machine Learning,44 (3), 245{271.D'Ambrosio, B. (1999). Inference Bayesian networks. AI Magazine, summer, 21{36.Dekhtyar, A., & Subrahmanian, V. S. (1997). Hybrid probabilistic programs. Proceedings14th International Conference Logic Programming (ICLP'97), pp. 391{405.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incompletedata via EM algorithm. Royal Statistical Society, B39 (1), 1{38.Doets, K. (1994). Logic Logic Programming. MIT Press.Flach, P., & Kakas, A. (Eds.). (2000). Abduction Induction { Essays RelationIntegration. Kluwer Academic Publishers.Frish, A., & Haddawy, P. (1994). Anytime deduction probabilistic logic. JournalArtificial Intelligence, 69, 93{122.Fujisaki, T., Jelinek, F., Cocke, J., Black, E., & Nishino, T. (1989). probabilistic parsingmethod sentence disambiguation. Proceedings 1st International WorkshopParsing Technologies, pp. 85{94.Japan EDR, L. (1995). EDR electronic dictionary technical guide (2nd edition). Technicalreport, Japan Electronic Dictionary Research Institute, Ltd.451fiSato & KameyaKakas, A. C., Kowalski, R. A., & Toni, F. (1992). Abductive logic programming. JournalLogic Computation, 2 (6), 719{770.Kameya, Y. (2000). Learning Representation Symbolic-Statistical Knowledge (inJapanese). Ph. D. dissertation, Tokyo Institute Technology.Kameya, Y., & Sato, T. (2000). Ecient EM learning parameterized logic programs.Proceedings 1st Conference Computational Logic (CL2000), Vol. 1861Lecture Notes Artificial Intelligence, pp. 269{294. Springer.Kita, K. (1999). Probabilistic Language Models (in Japanese). Tokyo Daigaku Syuppan-kai.Koller, D., McAllester, D., & Pfeffer, A. (1997). Effective Bayesian inference stochastic programs. Proceedings 15th National Conference Artificial Intelligence(AAAI'97), pp. 740{747.Koller, D., & Pfeffer, A. (1997). Learning probabilities noisy first-order rules. Proceedings 15th International Joint Conference Artificial Intelligence (IJCAI'97),pp. 1316{1321.Kyburg, H. (1994). Uncertainty logics. Gabbay, D., Hogger, C., & Robinson, J. (Eds.),Handbook Logics Artificial Intelligence Logic Programming, pp. 397{438.Oxford Science Publications.Lafferty, J. (1993). derivation Inside-Outside Algorithm EM algorithm.Technical report, IBM T.J.Watson Research Center.Lakshmanan, L. V. S., & Sadri, F. (1994). Probabilistic deductive databases. Proceedings1994 International Symposium Logic Programming (ILPS'94), pp. 254{268.Lari, K., & Young, S. J. (1990). estimation stochastic context-free grammars usingInside-Outside algorithm. Computer Speech Language, 4, 35{56.Li, Z., & D'Ambrosio, B. (1994). Ecient inference Bayes networks combinatorialoptimization problem. International Journal Approximate Reasoning, 11, 55{81.Lloyd, J. W. (1984). Foundations Logic Programming. Springer-Verlag.Lukasiewicz, T. (1999). Probabilistic deduction conditional constraints basicevents. Journal Artificial Intelligence Research, 10, 199{241.Manning, C. D., & Schutze, H. (1999). Foundations Statistical Natural Language Processing. MIT Press.McLachlan, G. J., & Krishnan, T. (1997). EM Algorithm Extensions. WileyInterscience.Muggleton, S. (1996). Stochastic logic programs. de Raedt, L. (Ed.), AdvancesInductive Logic Programming, pp. 254{264. IOS Press.Ng, R., & Subrahmanian, V. S. (1992). Probabilistic logic programming. InformationComputation, 101, 150{201.Ngo, L., & Haddawy, P. (1997). Answering queries context-sensitive probabilisticknowledge bases. Theoretical Computer Science, 171, 147{177.Nilsson, N. J. (1986). Probabilistic logic. Artificial Intelligence, 28, 71{87.452fiParameter Learning Logic Programs Symbolic-statistical ModelingPearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.Pereira, F. C. N., & Schabes, Y. (1992). Inside-Outside reestimation partially bracketedcorpora. Proceedings 30th Annual Meeting Association Computational Linguistics (ACL'92), pp. 128{135.Pereira, F. C. N., & Warren, D. H. D. (1980). Definite clause grammars language analysis| survey formalism comparison augmented transition networks.Artificial Intelligence, 13, 231{278.Pfeffer, A., & Koller, D. (2000). Semantics inference recursive probability models.Proceedings Seventh National Conference Artificial Intelligence (AAAI'00),pp. 538{544.Poole, D. (1993). Probabilistic Horn abduction Bayesian networks. Artificial Intelligence, 64 (1), 81{129.Pynadath, D. V., & Wellman, M. P. (1998). Generalized queries probabilistic context-freegrammars. IEEE Transaction Pattern Analysis Machine Intelligence, 20 (1),65{77.Rabiner, L. R. (1989). tutorial hidden markov models selected applicationsspeech recognition. Proceedings IEEE, 77 (2), 257{286.Rabiner, L. R., & Juang, B. (1993). Foundations Speech Recognition. Prentice-Hall.Ramakrishnan, I., Rao, P., Sagonas, K., Swift, T., & Warren, D. (1995). Ecient tablingmechanisms logic programs. Proceedings 12th International ConferenceLogic Programming (ICLP'95), pp. 687{711. MIT Press.Reddy, C., & Tadepalli, P. (1998). Learning first-order acyclic horn programs entailment. Proceedings 15th International Conference Machine Learning;(and Proceedings 8th International Conference Inductive Logic Programming). Morgan Kaufmann.Riezler, S. (1998). Probabilistic Constraint Logic Programming. Ph.D. thesis, UniversitatTubingen.Rubin, D. (1976). Inference missing data. Biometrika, 63 (3), 581{592.Sagonas, K., T., S., & Warren, D. (1994). XSB ecient deductive database engine.Proceedings 1994 ACM SIGMOD International Conference ManagementData, pp. 442{453.Sato, T. (1995). statistical learning method logic programs distribution semantics.Proceedings 12th International Conference Logic Programming (ICLP'95),pp. 715{729.Sato, T. (1998). Modeling scientific theories PRISM programs. Proceedings ECAI'98Workshop Machine Discovery, pp. 37{45.Sato, T. (2001). Minimum likelihood estimation negative examples statistical abduction. Proceedings IJCAI-01 workshop Abductive Reasoning, pp. 41{47.Sato, T., & Kameya, Y. (1997). PRISM: language symbolic-statistical modeling.Proceedings 15th International Joint Conference Artificial Intelligence(IJCAI'97), pp. 1330{1335.453fiSato & KameyaSato, T., & Kameya, Y. (2000). Viterbi-like algorithm EM learning statisticalabduction. Proceedings UAI2000 Workshop Fusion Domain KnowledgeData Decision Support.Sato, T., Kameya, Y., Abe, S., & Shirai, K. (2001). Fast EM learning family PCFGs.Titech technical report (Dept. CS) TR01-0006, Tokyo Institute Technology.Shen, Y., Yuan, L., You, J., & Zhou, N. (2001). Linear tabulated resolution based Prologcontrol strategy. Theory Practice Logic Programming, 1 (1), 71{103.Sterling, L., & Shapiro, E. (1986). Art Prolog. MIT Press.Stolcke, A. (1995). ecient probabilistic context-free parsing algorithm computesprefix probabilities. Computational Linguistics, 21 (2), 165{201.Tamaki, H., & Sato, T. (1984). Unfold/fold transformation logic programs. Proceedings2nd International Conference Logic Programming (ICLP'84), Lecture NotesComputer Science, pp. 127{138. Springer.Tamaki, H., & Sato, T. (1986). OLD resolution tabulation. Proceedings 3rdInternational Conference Logic Programming (ICLP'86), Vol. 225 Lecture NotesComputer Science, pp. 84{98. Springer.Tanaka, H., Takezawa, T., & Etoh, J. (1997). Japanese grammar speech recognitionconsidering MSLR method. Proceedings meeting SIG-SLP (SpokenLanguage Processing), 97-SLP-15-25, pp. 145{150. Information Processing SocietyJapan. Japanese.Uratani, N., Takezawa, T., Matsuo, H., & Morita, C. (1994). ATR integrated speechlanguage database. Technical report TR-IT-0056, ATR Interpreting Telecommunications Research Laboratories. Japanese.Warren, D. S. (1992). Memoing logic programs. Communications ACM, 35 (3),93{111.Wetherell, C. S. (1980). Probabilistic languages: review open questions. Computing Surveys, 12 (4), 361{379.White, H. C. (1963). Anatomy Kinship. Prentice-Hall.Zhang, N., & Poole, D. (1996). Exploiting causal independence Bayesian network inference. Journal Artificial Intelligence Research, 5, 301{328.454fiJournal Artificial Intelligence Research 15 (2001) 1-30Submitted 11/00; published 7/01Goal Recognition Goal Graph Analysisj.hong@ulst.ac.ukJun HongSchool Information Software EngineeringUniversity Ulster JordanstownNewtownabbey, Co. Antrim BT37 0QB, UKAbstractpresent novel approach goal recognition based two-stage paradigm graphconstruction analysis. First, graph structure called Goal Graph constructedrepresent observed actions, state world, achieved goals wellvarious connections nodes consecutive time steps. Then, Goal Graphanalysed time step recognise partially fully achieved goalsconsistent actions observed far. Goal Graph analysis also reveals validplans recognised goals part goals.approach goal recognition need plan library. suerproblems acquisition hand-coding large plan libraries, neitherproblems searching plan space exponential size. describe two algorithmsGoal Graph construction analysis paradigm. algorithmsprovably sound, polynomial-time, polynomial-space. number goals recognisedalgorithms usually small sequence observed actionsprocessed. Thus sequence observed actions well explained recognised goalslittle ambiguity. evaluated algorithms UNIX domain,excellent performance achieved terms accuracy, eciency, scalability.1. IntroductionPlan recognition involves inferring intentions agent set observations.typical approach plan recognition uses explicit representation possible plansgoals, often called plan library, conducts type reasoning basis setobservations identify plans goals plan library, could causedobservations.Plan recognition useful many areas, including discourse analysis natural language question-answering systems, story understanding, intelligent user interfaces,multi-agent coordination. Much early research plan recognition done natural language question-answering systems (Allen & Perrault, 1980; Allen, 1983; Sidner,1985; Litman & Allen, 1987; Carberry, 1988; Pollack, 1990; Grosz & Sidner, 1990).systems, plan recognition used support intelligent response generation;understand sentence fragments, ellipsis indirect speech acts; track speakers owdiscourse; deal correctness completeness discrepanciesknowledge users systems.Plan recognition enhance user interfaces. recognition users goalsplans interaction interface facilitates intelligent user help (Carver, Lesser,& McCue, 1984; Hu & Lesser, 1988; Goodman & Litman, 1992; Bauer & Paul, 1993;Lesh & Etzioni, 1995). Plan recognition enables interface assist user taskc2001AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHongcompletion, error detection recovery (Wilensky & et al., 1988). interfacewatching users shoulder infer goals plans. decidehelp assistance user needs.story understanding (Schank & Abelson, 1977; Wilensky, 1983; Charniak & Goldman,1993), useful recognise goals plans characters describedactions order understand characters doing. multi-agent coordination,ecient eective coordination among multiple agents requires modelling agentsgoals plans (Huber, Durfee, & Wellman, 1994; Huber & Durfee, 1995).Given set observations, plan recognition systems (Allen & Perrault, 1980;Carberry, 1986; Litman & Allen, 1987; Kautz, 1987; Pollack, 1990)) search spacepossible plan hypotheses candidate plans goals account observations.form search space given domain, kind plan library required.instance, Kautzs event hierarchy (Kautz, 1987), plan decompositions requireddescribe low-level actions make complex actions. Despite obvious advantageexpressive richness, use plan library limitations. First, able dealnew plans whose types appear plan library. Second, acquiring handcoding plan library large complex domain presents tedious impractical task.Third, domains, knowledge plans might readily available.attempts (Mooney, 1990; Forbes, Huang, Kanazawa, & Russell, 1995; Lesh &Etzioni, 1996; Albrecht, Zukerman, & Nicholson, 1998; Bauer, 1998) recentlymade apply machine learning techniques automated acquisition coding planlibraries. Even leaving aside plan library consideration, searching plan spacecan, however, exponentially expensive number possible plan hypothesesexponential number actions (Kautz, 1987). plan recognition systemsdeveloped domains peoples behaviour characterized fewer100 plans goals (Lesh & Etzioni, 1996).paper, focus goal recognition, special case plan recognition.introduce novel approach goal recognition, graph construction analysisused paradigm. approach signicantly diers plan recognition systems.First, approach need plan library. Instead dene constitutes validplan goal. need consider observed actions organised plans.Hence problems associated acquisition hand-codingplan library large complex domain well availability planning knowledgedomain. plan recognition systems cannot recognise new plans whose typesappear plan library. Without using plan library, approach suerlimitation. Second, instead immediately searching plan plan spaceplan recognition systems, approach explicitly constructs graph structure,called Goal Graph, analysed recognise goals plans. approachtherefore problems searching plan space exponential size. Third,approach recognises partially fully achieved goals consistentactions observed far. number recognised goals usually smallsequence observed actions processed. Thus sequence observed actionswell explained recognised goals little ambiguity.emphasised approach goal recognition, purpose recognising partially fully achieved goals explain past actions rather predicting2fiGoal Recognition Goal Graph Analysisfuture actions. particularly useful problem areas story understanding,software advisory systems, database query optimisation, customer data mining.problem areas several specic characteristics. First, actions either described observed. Second, likely users intended goal partiallyfully achieved actions. Third, recognising intended goal aims explaining past actions rather predicting future actions. Finally, distinguishing partiallyfully achieved goals others greatly reduces ambiguity involved recognisingintended goal.story understanding, actions characters described story. Recognising goals plans account described actions enables better understandingcharacters doing. software advisory systems, userobserved issue sequence operations software application, system rstrecognise task user performed. system decide whether userperformed task suboptimal way, advice given userbetter perform task. database query optimisation, user conducted sequence data retrieval manipulation operations, recognising underlyingquery lead advice query optimisation query executedoptimal way. customer data mining, individual customers shopping goalsrecognised logged customer on-line shopping data. also form basisperforming customer data mining tasks.algorithms Goal Graph construction analysis provably sound,polynomial-time, polynomial-space. empirical results UNIX domain showalgorithms perform well terms accuracy, eciency, scalability. alsoshow algorithms scaled applied domains tensthousands possible goals plans. Though algorithm Goal Graph analysiscomplete, recognised every goal intended successfully achievedsubject UNIX data set used evaluation. Since new graph-basedapproach goal recognition fundamentally dierent existing methods planrecognition, provides alternative methods new perspective planrecognition problem.rest paper organised follows. First, give overview novelapproach goal recognition. Section 3, discuss domain representation.Section 4 dene Goal Graphs, valid plans, consistent goals. Section 5 presentgoal recognition algorithms together analysis algorithms. Section 6discuss empirical results. summarise paper discuss limitations futurework last section.2. Novel Approach Goal Recognitionsection, describe basic assumptions make goal recognition problemoutline approach. discuss previous work planning Planning Graphsgraph-based approach goal recognition. briey describe empirical resultsfavour approach.3fiHong2.1 Basic Assumptionsstart example UNIX domain. observe user types twocommands, cd papers ls, one another, able infer userwants nd le subdirectory directory, papers, two reasons. First, goalfully achieved. Second, relevant commands consistent waysense rst command satises one preconditions second commandsecond command achieves recognised goal. recognised goal mightintermediate goal user. users intended goal might one le relatedgoals, instance, deleting le directory. Since commandspart plans almost le related goals, impossible us uniquely identifyusers intended goal current time step. Yet goal nding le directorywell explains commands. user next types command, rm oldpaper.tex,infer users goal delete le, oldpaper.tex, directory, papers,goal fully achieved relevant commands observedfar consistent way sense rst command satises one preconditionssecond third commands, second command satises one preconditionsthird command, third command achieves recognised goal.example highlights way new approach goal recognition works. makefollowing assumptions goal recognition problem. First, set actionsobserved consecutive time steps.1 Second, initial state world immediatelyset actions observed known.2 Third, domain knowledgeactions goals, is, know preconditions eects every observed action,every possible goal explicitly specied set goal descriptions.Given assumptions, action observed time step, want infergoals partially fully achieved time step whetherachieved goals relevant strict majority actions observed far consistentway sense actions organised plan structure goalpart it.2.2 Goal Recognition Goal Graphpropose use graph structure, called Goal Graph, new approach goalrecognition. view goal recognition problem process graph constructionanalysis. Goal Graph, action nodes represent actions observed consecutive timesteps; proposition nodes represent state world consecutive time steps,changed initial state subsequent states observed actions; goalnodes represent goals partially fully achieved consecutive time steps.Edges Goal Graph explicitly represent relations actions propositionswell relations propositions goals. Based explicit relationsconstructed Goal Graph, causal links either two actions action goalrecognised. recognised causal links, decided whether fullypartially achieved goal time step relevant strict majority observed1. observed actions partially ordered sense one action observedtime step temporal ordering constraint actions.2. approach however reasons state world subsequent time steps.4fiGoal Recognition Goal Graph Analysisactions far consistent way sense relevant actions organisedplan structure goal part it. approach, extraneous, redundant,partially ordered actions plans handled.attempt use graph construction analysis paradigm goal recognitionspirit inuenced Blum Fursts eorts planning Planning Graphs (Blum& Furst, 1997). introduced new graph-based approach planning STRIPSdomains, graph structure called Planning Graph rst constructed explicitlyrather searching immediately plan standard planning methods. Many usefulconstraints inherent planning problem made explicitly available PlanningGraph reduce amount search needed. Planning Graph analysedgenerate possible plans.Goal-Graph-based approach goal recognition seen counterpartplanning Planning Graph. Though graph structures used approaches,composed dierent kinds nodes edges. time step, Planning Graphrepresents possible propositions either added actions previous time stepbrought forward maintenance actions previous time step, possibleactions whose preconditions satised propositions time step.hand, Goal Graph, time step, represents propositions either addedactions observed previous time step brought forward maintenance actionsprevious time step, actions observed time step. addition, GoalGraph, time step, also represents possible goals, either fully partially achievedtime step, Planning Graph represent goal all. Accordingly,Planning Graph represents relations actions propositions, GoalGraph also represents relations propositions goals.analysis Planning Graph aims search possible subgraphsPlanning Graph, form valid plans given goal. hand,analysis Goal Graph aims search every possible partially fully goalexists subgraph Goal Graph, consisting strict majority observedactions. subgraph forms valid plan goal part showsstrict majority observed actions relevant goal consistent way.domain representation planning Planning Graphgoal recognition Goal Graph. regard, previous eorts handlingexpressive representation languages (Gazen & Knoblock, 1997; Anderson, Smith, & Weld,1998; Koehler, Nebel, Homann, & Dimopoulos, 1997) still useful goal recognition.languages allow use disjunctive preconditions, conditional eects, universallyquantied preconditions (goal descriptions) eects action goal representation.ADL-like domain representation actually based work, allows useconditional eects, universally quantied eects, existentially universally quantiedpreconditions goal descriptions action goal representation.Goal-Graph-based approach extends Lesh Etzionis previous workuse graph representation actions goals goal recognition problem (Lesh &Etzioni, 1995). used graph representation, called consistency graph, goalrecognition problem. consistency graph consists action goal nodes representingpossible actions goals, edges representing possible connections nodes5fiHonggraph. Initially, action goal nodes fully connected consistencygraph, inconsistent goals repeatedly pruned consistency graph.number major dierences Lesh Etzionis approach ours.First, two dierent graph representations used. Apart action goal nodes,consistency graph nodes representing propositions modelstate world changed observed actions. Therefore, consistency graphexplicitly reveal causal links actions goals. Neither systemknow whether goal partially fully achieved observed actions. GoalGraph consists action, goal, proposition nodes. explicitly reveals causal linksactions goals, hence system knows observed actions composedvalid plans recognised goals part goals. systems also knows whethergoal partially fully achieved observed actions.Second, goal consistency dened dierently. Lesh Etzionis approach, goalconsistent exists plan includes observed actions achievesgoal. approach, goal consistent partially fully achievedobserved actions relevant strict majority observed actions. Also, twodierent recognition processes used. approach pruning process usedprune inconsistent goals consistency graph. pruning process guaranteesgoals pruned consistency graph inconsistent goals. However, numberconsistent goals, still remaining consistency graph pruning, usually large. Thusambiguity intended goal remains issue addressed. approach insteaduses graph analysis process directly recognise consistent goals fullypartially achieved goals. number consistent goals recognised Goal Graphusually small. Third, approach requires every observed action relevantgoal, strict majority observed actions required relevantgoal approach.developed two algorithms, GoalGraphConstructor GoalGraphAnalyser,based two-stage paradigm Goal Graph construction analysis. GoalGraphConstructor algorithm takes set actions observed dierent timesteps constructs Goal Graph. GoalGraphAnalyser algorithm analyses constructed Goal Graph recognise consistent goals valid plans. provealgorithms sound, polynomial-time, polynomial-space.algorithms implemented Prolog tested UNIX domaindesktop Pentium III processor 600 MHz. used set data, collectedUNIX domain University Washington, domain representation 35 actionschemata 249 goal schemata. entire UNIX data set, average tookCPU seconds update Goal Graph observed action processed, usuallysmall number consistent goals remained sequence actionsobserved. test cases intended goals successfully achievedsubjects, intended goals among remaining goals recognisedcomplete sequences actions observed. test scalability algorithms,tested series spaces approximate 104 , 2 104 , 105 candidate goalsrespectively UNIX domain, approximate linear time performanceachieved. empirical results show algorithms scaled applieddomains tens thousands possible goals plans.6fiGoal Recognition Goal Graph Analysis3. Domain Representationuse ADL-like representation (Pednault, 1989), including actions conditionaluniversally quantied eects, existentially well universally quantied preconditionsgoal descriptions. approach goal recognition, goal recognition problemconsistsset action schemata specifying primitive actions.nite, dynamic universe typed objects objects either addeddeleted action.set propositions called Initial Conditions.set goal schemata specifying possible goals.set actions observed consecutive time steps.3solution goal recognition problem consists set partially fully achievedgoals consistent set observed actions together valid plansconsisting observed actions recognised goals part them.goal schema consists set goal descriptions (GDs) denedfollowing EBNF denitions.<GD><GD><GD><GD><GD><GD><GD><GD><GD>::=::=::=::=::=::=::=::=::=<term>(not <term>)(neg <term>)(and <GD>*)(imply <GD> <GD>)(exist <term> <GD>)(forall <term> <GD>)(eq <argument> <argument>)(neq <argument> <argument>)action schema consists set preconditions set eects. setpreconditions dened goal descriptions. set eects denedfollowing EBNF denitions.<effect><effect><effect><effect><effect>::=::=::=::=::=<term>(neg <term>)(and <effect>*)(when <GD> <effect>)(forall <term> <effect>)3. say observed action, mean action observed successfully executed.ignore invalid actions. UNIX domain, instance, invalid actions issuedcommands UNIX failed execute responded error messages.7fiHongtwo sets EBNF denitions, <term> atomic expression form:<term> ::= (<predicate-name> <argument>*)<argument> ::= <constant-name><argument> ::= <variable-name>use eq neq specify equality inequality constraints. two negationconnectives: neg not. use (neg A) specically mean truth valuemade explicitly known false action. use (not A) mean truth valueknown false either explicitly implicitly. latter kind representationused necessary represent truth value explicitly knownfalse long known false. closed world assumption thereforeimplemented follows. initial state world, explicitly representpropositions known true Initial Conditions. proposition explicitlyrepresented state world implicitly known false. Actions however mayadd propositions explicitly known false state world. propositionbecome explicitly known false made explicitly knownfalse action. important represent propositions explicitly knownfalse, want explicitly represent eects actions causal linkseither two actions action goal established.goal action schemata parameterised typed variables representedterms object type predicates. goal ground instance goal schema.action ground instance action schema. set goal descriptions goal mustsatised state world goal fully achieved.goal descriptions satised instead, goal partially achieved. Positive literalsgoal descriptions represent propositions true state world. Negative literalsgoal descriptions represent propositions known false state world.use imply specify dependency constraints goal descriptions. goal description GD2implied another goal description GD1 , GD2 satised GD1 satisedGD1 satised without GD2 satised. goal description existentiallyuniversally quantied dynamic universe objects.set preconditions must satised state world actionexecuted. set preconditions syntax semanticsset goal descriptions. set eects taken state worldaction executed. Positive literals eects represent propositions true stateworld action executed. propositions added stateworld. Negative literals eects represent propositions longer true stateworld action executed. propositions deleted stateworld, negations propositions added state world,representing propositions explicitly known false state worldaction executed. Furthermore, conditional eect consists antecedentconsequent, antecedent set preconditions consequent seteects. eects consequent taken preconditionsantecedent satised state world action executed. eectaction schema universally quantied dynamic universe objects.8fiGoal Recognition Goal Graph Analysisuse simple example domain extended Pednaults famous example (Pednault,1988). involves transportation two physical objects, dictionary, chequebook,home oce using briefcase. assume one physical objectcarried briefcase time. extended briefcase domain consistsspecial physical object: briefcase.Two physical objects: dictionary chequebook.Two locations: home oce.Three action schemata:Moving briefcase one location another,Putting physical object briefcase,Taking physical object briefcase.Three goal schemata:Moving physical object one location another,Keeping physical object location,Keeping physical object briefcase.action goal schemata example domain shown Figure 1.used throughout paper.actual implementation goal recognition algorithms, universally quantiedpreconditions eects, conditional eects action schemata eliminated;equivalent schemata created. use particular approach call dynamic expansion.Dynamic expansion involves two steps. rst step, universally quantied preconditionseects action schema dynamically compiled corresponding Herbrandbases, taking account universe objects current time step. universallyquantied preconditions eects dynamically compiled assumeuniverse objects dynamically changed. assumption neededdomain like UNIX shell system destruction creation objects required.assumption dynamic universe objects, object universe,object type must declared time step immediately actionexecuted. object initial universe objects, type must declaredInitial Conditions. object either added deleted universe objectsaction time step, eect either stating proposition new objectnegating proposition existing object.instance, suppose time step immediately instance actionschema mov-b shown Figure 1 executed, universe objects consists three physicalobjects: B, C, D. Action schema mov-b dynamically compiled action schemamov-b-1 follows.9fiHong(:action mov-b:paras (?l ?m - loc):pre (and (neq ?l ?m)(at B ?l)):eff (and (at B ?m) (neg (at B ?l))(forall (?z - physob)(when (in ?z)(and (at ?z ?m)(neg (at ?z ?l)))))) )(:action put-in:paras (?x - physob ?l loc):pre (and (neq ?x B)(at ?x ?l)(at B ?l))(forall (?z - physob)(not (in ?z)))):eff (in ?x) )(:action take-out:paras (?x - physob):pre (in ?x):eff (neg (in ?x)) )(:goal move-object:paras (?x - physob ?l ?m - loc):goal-des (and (neq ?l ?m)(neq ?x B)(imply (neg (at ?x ?l))(at ?x ?m))) )(:goal keep-object-at:paras (?x - physob ?l - loc):goal-des (and (neq ?x B)(imply (at ?x ?l)(not (in ?x)))) )(:goal keep-object-in:paras (?x - physob):goal-des (in ?x) )Figure 1: action goal schemata extended briefcase domain10fiGoal Recognition Goal Graph Analysis(:action mov-b-1:paras (?l ?m - loc):pre (and (neq ?l ?m) (at B ?l)):eff (and (at B ?m) (neg (at B ?l))(when (in B)(and (at B ?m)(neg (at B ?l))))(when (in C)(and (at C ?m)(neg (at C ?l))))(when (in D)(and (at ?m)(neg (at ?l))))) )second step, conditional eects mov-b-1 eliminated. Assumethat, time step, following propositions true: (at B H), (at C H), (at H),(in D). conditional eects mov-b-1, whose antecedents satisedtime step, removed. therefore action schema mov-b-2.(:action mov-b-2:paras (?l ?m - loc):pre (and (neq ?l ?m) (at B ?l)):eff (and (at B ?m) (neg (at B ?l))(when (in D)(and (at ?m)(neg (at ?l))))) )antecedent remaining conditional eect mov-b-2 already satisedtime step moved existing preconditions. nally action schemamov-b-3 current time step. Action schema mov-b-3 equivalent originalaction schema mov-b current time step. mov-b-3 actually usedaction schema, Moving briefcase one location another, time step.(:action mov-b-3:paras (?l ?m - loc):pre (and (neq ?l ?m) (at B ?l)(in D)):eff (and (at B ?m) (neg (at B ?l))(at ?m) (neg (at ?l))))universally quantied goal descriptions goal schema treatedway universally quantied preconditions action schema.4. Goal Graphs, Valid Plans Consistent Goalssection, rst describe structure Goal Graph. denemean say set observed actions forms valid plan achieving goal given11fiHongmov-b Hput-in Hmov-b HActionsBHB HBB HBBB HC HHHC HC HHC Hkeep-object-at Hkeep-object-at Hkeep-object-at C Hkeep-object-at C Hkeep-object-in D*Propositionsmove-object H O*keep-object-at C HGoalskeep-object-at C Hkeep-object-inkeep-object-atLevel 1Level 2Level 3Level 4Figure 2: Goal Graph example extended briefcase domainInitial Conditions. nally dene mean say goal consistentset observed actions.4.1 Goal GraphsGoal Graph represents actions observed, propositions true explicitly knownfalse, fully partially achieved goals consecutive time steps. Goal Graphalso explicitly represents connections propositions, actions, goals graph.Goal Graph directed, levelled graph. levels alternate propositionlevels containing proposition nodes (each labelled proposition negation proposition), representing state world consecutive time steps; goal levels containinggoal nodes (each labelled goal), representing goals fully partially achieved consecutive time steps; action levels containing action nodes (each labelled action),representing actions observed consecutive time steps. levels Goal Graph startproposition level time step 1, consisting one node proposition trueInitial Conditions. end goal level last time step, consistingnode goals either fully partially achieved actions observed far.levels are: propositions true time step 1, goals achieved time step 1, actionsobserved time step 1; propositions true explicitly known false time step 2,goals achieved time step 2, actions observed time step 2; propositions true explicitlyknown false time step 3, goals achieved time step 3, forth.goal nodes goal-level connected description edges goal descriptions proposition-level i. action nodes action-level connected preconditionedges preconditions proposition-level i, eect edges eectsproposition-level + 1. proposition nodes proposition-level connected viapersistence edges corresponding proposition nodes proposition-level + 1,truth values aected actions action-level i. persistence edgesrepresent eects maintenance actions simply bring forward proposition nodesproposition-level i, aected actions action-level i, proposition-level + 1.example shown Figure 2, three actions observed three consecutive time steps: (mov-b H), (put-in H), (mov-b H O). Initial Conditions12fiGoal Recognition Goal Graph Analysisconsist of: (at B O), (at H), (at C H). Action goal nodes topbottom parts graph respectively. proposition nodes middle partgraph. edges connecting proposition nodes action node levelprecondition edges. edges connecting action node one level propositionssubsequent level eect edges. edges connecting proposition nodes goalnodes level description edges. edges connecting proposition nodesone level proposition nodes subsequent level persistence edges. goal nodesbold represent consistent goals, among goal nodes italics represent partiallyachieved goals, others represent fully achieved goals. edges bold showcausal link paths. goal nodes asterisk represent recognised goals.4.2 Valid Plansdene mean say set observed actions forms valid plangoal, given Initial Conditions.Definition 1 (Causal Link) Let ai aj two observed actions time steps jrespectively, < j. exists causal link ai aj , written ai aj ,one eects ai satises one preconditions aj .instance, example shown Figure 2, exists causal link actions(mov-b H) time step 1 (put-in H) time step 2, since one eectsrst action, (at B H), satised one preconditions second action.goal treated action goal descriptions preconditionsempty set eects. Therefore, causal links also established observed actionsgoals.instance, example shown Figure 2, exists causal link action(mov-b H O) time step 3 goal (move-object H O) time step 4, since oneeects action, (at O), satised one goal descriptions goal.valid plan goal dened basis temporal ordering constraintscausal links set observed actions. valid plan P goal g, given InitialConditions, represented 3-tuple, < A, O, L >, set observed actions,set temporal ordering constraints A, L set causal links A.Definition 2 (Valid Plan) Let g goal, P =< A, O, L >, setobserved actions, set temporal ordering constraints, {ai < aj }, A, Lset causal links, {ai aj }, A. Let Initial Conditions. P valid plang, given I,1. actions executed order consistent O;2. goal g fully achieved actions executed orderconsistent O.instance, example shown Figure 2, given Initial Conditions, = {(atB O), (at H), (at C H)}, P = ({a1 = (mov-b H), a2 = (put-in H), a3 = (mov-bH O)}, {a1 < a2 , a2 < a3 }, {a1 a2 , a1 a3 , a2 a3 }) valid plan goal g =(move-object H O).13fiHong4.3 Consistent Goalsdene mean say goal consistent set observedactions. set observed actions represented 2-tuple, < A, >,set observed actions set temporal ordering constraints, {ai < aj }, A.4Definition 3 (Relevant Action) Given goal g set observed actions, < A, >,action said relevant g context < A, >,1. exists causal link, g;2. exists causal link, b, b relevant g < b consistentO.Definition 4 (Consistent Goal) goal g consistent set observed actions,< A, >, strict majority relevant g context< A, >.Proposition 1 (Valid Plan Consistent Goal) Let < A, > set observedactions, Initial Conditions < A, >, g goal consistent < A, >.exists set causal links, L = {ai aj }, given I, P =< A, O, L >valid plan either g g fully achieved time step < A, >observed achieved part g g partially achieved time step< A, > observed.Proof. g fully achieved time step set actions observed,directly follows Denitions 3 4 exists set causal links, L = {ai aj },A. follows Denition 2 given I, P =< A, O, L > valid plan g.g partially achieved time step set actions observed,let g achieved part g. g fully achieved time step setactions observed, directly follows Denitions 2, 3 4 existsset causal links, L = {ai aj }, given I, P =< A, O, L > valid plang. 2instance, example shown Figure 2, < A, > = < {a1 = (mov-bH), a2 = (put-in H), a3 = (mov-b H O)}, {a1 < a2 , a2 < a3 } >, g = (move-objectH O) fully achieved goal time step < A, > observed. AccordingDenition 3 4, g consistent < A, > exist causal links, a3 ga3 g, a2 a3 a2 a3 , a1 a3 a1 a3 , a1 a2a1 a2 . Let Initial Conditions < A, >, L = {a1 a2 , a1 a3 ,a2 a3 }, according Proposition 1, P =< A, O, L > valid plan g. Furthermore,causal link, a3 g, explains purpose a3 .summary, according Denition 4 Proposition 1, say goal consistentset observed actions, mean strict majority observed actionsrelevant goal set observed actions forms valid plan goalachieved part it.4. assume actions observed consecutive time steps one action observedtime step.14fiGoal Recognition Goal Graph Analysis5. Goal Recognition Algorithmsdescribe goal recognition algorithms. goal recognition algorithms runtwo-stage cycle time step. rst stage, GoalGraphConstructor algorithmtakes actions observed time step tries extend Goal Graph. secondstage, GoalGraphAnalyser algorithm analyses constructed Goal Graph recognisefully partially achieved goals, consistent actions observed far,valid plans goals part them. two-stage cycle continuesaction observed next time step.5.1 Constructing Goal Graphuse 4-tuple < P, AO , GR , E > represent Goal Graph, P set proposition nodes, AO set action nodes, GR set goal nodes, E set edges.proposition node represented prop(p, i), p positive negative ground literal,time step. action node represented action(a, i), observed actiontime step. goal node represented goal(g, i), g goaltime step. precondition edge represented precondition-edge(prop(p, i), action(a, i)),eect edge represented eect-edge(action(a, i), prop(p, + 1)), description edgerepresented description-edge(prop(p, i), goal(g, i)), persistence edge representedpersistence-edge(prop(p, 1), prop(p, i)).GoalGraphConstructor algorithm consists two algorithms: goal expansionalgorithm action expansion algorithm. GoalGraphConstructor algorithm startsGoal Graph, < P, {}, {}, {} >, consists proposition-level 1 nodesrepresenting Initial Conditions.Given Goal Graph ending proposition-level i, goal expansion algorithm rstextends Goal Graph goal-level i, nodes representing goals fully partiallyachieved time step i. algorithm goes every possible ground instance goalschemata. every goal instance, rst gets set goal descriptions. eliminatesuniversally quantied goal descriptions dynamic expansion get equivalentset goal descriptions. goal node added onto goal-level represent achievedgoal, least one goal descriptions satised proposition-level i.decided whether goal fully partially achieved, based whethergoal descriptions satised respectively proposition-level i. Meanwhile,node proposition-level satises goal description, description edge connectingproposition node goal node added onto Goal Graph. Figure 3 showsgoal expansion algorithm. algorithm takes Goal Graph < P, AO , GR , E > endingproposition-level i, time step i, set goal schemata G input. returnsupdated Goal Graph ending goal-level goal expansion.actions observed time step i, action expansion algorithm extends Goal Graph ending goal-level i, action-level i, nodes representingobserved actions. time, algorithm also extends Goal Graphproposition-level + 1, nodes representing propositions true explicitly knownfalse actions observed.every action observed time step i, algorithm rst instantiates action schemaobserved action get precondition set eect set. eliminates15fiHongGoal-Expansion(< P, AO , GR , E >, i, G)1. every Gk Gevery instance g Gka. Get set goal descriptions Sg .b. Get equivalent set Sg , Sg .c. every pg Sg , pg = not(pg ),prop(neg(pg ), i) P ,Add description-edge(prop(neg(pg), i), goal(g, i)) E.d. every pg Sg , pg = not(pg ),prop(pg , i) P ,Add description-edge(prop(pg, i), goal(g, i)) E.e. one goal descriptions g satised,Add goal(g, i) GR .2. Return < P, AO , GR , E >.Figure 3: goal expansion algorithmuniversally quantied preconditions eects, well conditional eects,dynamic expansion get equivalent precondition eect sets. Meanwhile, nodeproposition-level satises precondition action, precondition edge, connectingproposition node action node, added onto Goal Graph. every eectaction, action expansion algorithm simply adds proposition node representingeect proposition-level + 1. eect edge action node propositionnode also added onto Goal Graph.expansion, every proposition node proposition-level broughtforward proposition-level + 1 maintenance action, truth valuechanged action observed time step (and added onto Goal Graphaction observed time step i).5 Persistence edges, connecting correspondingproposition nodes two proposition levels, added onto Goal Graph.Figure 4 shows action expansion algorithm. algorithm takes Goal Graph< P, AO , GR , E > ending goal-level i, set actions observed time step i, Ai ,time step i, set action schemata input. returns updated Goal Graphending proposition-level + 1 action expansion. expansion GoalGraph proposition-level proposition-level + 1 simulates eects executingactions observed time step i.otherwise action observed time step i, GoalGraphConstructor algorithm nishes nodes goal-level i, representing possible goals either fullypartially achieved actions observed.5. goal recognition algorithms allow redundant actions.16fiGoal Recognition Goal Graph AnalysisAction-Expansion(< P, AO , GR, E >, Ai , i, A)1. every ai Aia. Add action(ai, i) AO .b. Instantiate action schema ai get precondition setSP , eect set SE .c. Get equivalent sets SP SE , SP SE .d. every pp SP , pp = not(pp ),prop(neg(pp, i) P ,Add precondition-edge(prop(neg(pp, i), action(ai, i)) E.e. every pp SP , pp = not(pp ),prop(pp, i) P ,Add precondition-edge(prop(pp, i), action(ai, i)) E.f. every pe SEi. Add prop(pe, + 1) P .ii. Add eect-edge(action(ai, prop(pe, + 1)) E.2. every prop(p, i) Pprop(p, + 1)/ P ,prop(p, + 1)/ P , Add prop(p, + 1) P ;Add persistence-edge(prop(p, i), prop(p, + 1)) E.3. Return < P, AO , GR , E >.Figure 4: action expansion algorithmTheorem 1 (Polynomial Size Time) Consider goal recognition problemobserved actions time steps, nite number objects time step, p propositionsInitial Conditions, goal schemata constant number parameters.Let l1 largest number eects action schema, l2 largest numbergoal descriptions goal schema. Let n largest number objects timesteps. Then, size Goal Graph + 1 levels created GoalGraphConstructoralgorithm, time needed create graph, polynomial n, m, p, l1 , l2 , s.Proof. maximum number nodes proposition level O(p + l1 s). Let klargest number parameters goal schema. Since goal schemainstantiated nk distinct ways, maximum numbers nodes edgesgoal level O(mnk ) O(l2 mnk ) respectively. obvious time neededcreate nodes edges level polynomial number nodes edgeslevel. 2Theorem 2 GoalGraphConstructor algorithm sound: goal adds GoalGraph time step one either fully partially achieved time step stateworld. algorithm complete: goal either fully partially achievedobserved actions time step 1, algorithm add Goal Graphtime step i, assumption possible goals restricted categoriesgoal schemata.17fiHongProof (soundness). Proposition-level 1 Goal Graph consists InitialConditions, representing state world time step 1 actionobserved. Goal Graph extended proposition-level 1 proposition-level i,adding eects actions observed time step i1, bringing forwardproposition nodes aected actions proposition-level1 proposition-level i. Therefore, proposition-level Goal Graph representsstate world time step i, changed Initial Conditionsactions observed time steps 1, ..., 1.goal added Goal Graph time step algorithm fully partiallyachieved goal proposition-level Goal Graph. Therefore, goal fullypartially achieved state world time step i.Proof (completeness). Suppose goal either fully partially achievedactions observed time steps 1, ..., 1. goal either fully partially achievedproposition-level Goal Graph. Since goal-level Goal Graph consistspossible instances goal schemata, fully partially achievedproposition-level Goal Graph, goal instance goal schema, onefully partially achieved goal instances proposition-level i. algorithmtherefore add goal goal-level Goal Graph. 25.2 Recognising Consistent Goals Valid PlansGoalGraphAnalyser algorithm analyses constructed Goal Graph recognise consistent goals valid plans. assume strict majority observed actionsrelevant goal intended agent context agents actions. Therefore,goal intended agent consistent set observed actions, goalmay intended goal consistent set observed actions. orderdecide whether goal consistent set observed actions, is, whetherrelevant strict majority observed actions, need recognise causal linkseither two observed actions observed action goal. denetwo particular types paths, call causal link paths, constructed Goal Graph.prove Theorems 3 4 causal links recognised identifying causal linkpaths.Definition 5 Given Goal Graph, let ai action observed time step gjgoal fully partially achieved time step j, < j. path connects ai gjvia eect edge, zero persistence edges, description edge, called causallink path ai gj .Theorem 3 Given Goal Graph, exists causal link, ai gj , action aitime step goal gj time step j, < j, ai connected gj via causallink path.Proof. According Denition 5, causal link path ai gj consistseect edge, zero persistence edges, description edge. eect edgepath connects ai proposition node proposition-level + 1, representing oneeects ai . j = + 1, persistence-edge path proposition18fiGoal Recognition Goal Graph Analysisnode connected gj description edge. j > + 1, proposition nodebrought forward proposition-level j via j i1 persistence-edges j i1 maintenanceactions, brought-forward proposition node proposition-level j connected gjdescription edge. either case, one eects ai satised one goaldescriptions gj . Since goal treated action goal descriptionspreconditions empty set eects, according Denition 1, exists causallink ai gj . 2Definition 6 Given Goal Graph, let ai aj two actions observed time stepsj respectively, < j. path connects ai aj via eect edge, zeropersistence edges, precondition-edge, called causal link path aiaj .Theorem 4 Given Goal Graph, exist causal link, ai aj , action aitime step action aj time step j, < j, ai connected aj viacausal link path.proof Theorem 4 similar Theorem 3. details proof omitted.Given constructed Goal Graph < P, AO , GR , E > levels, GoalGraphAnalyseralgorithm shown Figure 5 recognises every consistent goal goals goal-level t,deciding whether strict majority observed actions relevant it.done rst nding relevant actions observed actions, connectedgoal causal link paths. already-known relevant actions, algorithmtries nd relevant actions observed actions, connectedcausal link paths. continues relevant action found. consistentgoal recognised valid plan goal part represented 3-tuple,< gt, < AO , O, La >, Lg >, gt goal, La set causal links observedactions, Lg set causal links observed actions goal.< AO , O, La > represents valid plan gt part it, Lg explainspurposes observed actions.Proposition 2 GoalGraphAnalyser algorithm sound: goal g recognisestime step consistent observed actions far, plan organises gpart g valid.Proof. GoalGraphAnalyser algorithm recognises goal g time step t,strict majority observed actions connected g, either directly causal linkpath indirectly chain causal link paths. observed action connectedg directly causal link path, according Theorem 3 Denition 3, existscausal link observed action g, observed action relevantg. observed action connected g indirectly chain causal link paths,according Theorem 3, Theorem 4, Denition 3, chain causal linksobserved action g, observed action relevant g. Since strictmajority observed actions relevant g, according Denition 4, g consistentset observed actions. Furthermore, according Proposition 1, planGoalGraphAnalyser algorithm organises g part g, < AO , O, La >, valid plan.219fiHongGoalGraphAnalyser(< P, AO , GR , E >, t)1. every gt GR goal-levela. AO {}, {}, Lg {}, La {}.b. every ai AO connected gt causal link pathAdd ai gt Lg ;Add ai AO ;Add ai A.c. = {} ai AO , ai AO ,Get ordering constraints, O, AO ;Add < gt , < AO , O, La >, Lg > GoalPlan.d. = {},Remove action aj A;every ai AO connected aj causal link pathAdd ai aj La ;/ AO , Add ai AO , ai A;aiGo 1c.2. Return GoalPlan.Figure 5: GoalGraphAnalyser algorithmexample shown Figure 2, goal nodes bold represent three consistentgoals, among goal node italics represents partially achieved goal,two represent two fully achieved goals. edges bold show causal link paths.Theorem 5 (Polynomial Space Time) Consider t-level Goal Graph. Let l1number fully partially achieved goals time step t, m1 largest numbergoal descriptions goals, l2 number observed actions, m2largest number preconditions actions. space size possiblecausal link paths, connect goals observed actions connect observedactions observed actions, time needed recognise consistent goals,polynomial l1 , l2 , m1 , m2 .Proof. Persistence edges branch Goal Graph. goalsgoal-level t, maximum number paths searched observed actions,connected goal causal link paths hence relevant it, O(m1 ).relevant actions goal, maximum number paths searched observedactions, connected relevant action causal link paths hence alsorelevant goal, O(m2 ). maximum l1 goals goal-levell2 relevant actions goals. space size possible causal link pathsO(l1 (m1 + l2 m2 )). time needed recognise consistent goals polynomialspace size. 220fiGoal Recognition Goal Graph Analysis5.3 Goal RedundancyGoalGraphAnalyser algorithm recognises fully partially achieved goals time step,consistent actions observed far. Among consistent goals, fullyachieved goals better explain actions observed far. instance, example shownFigure 2, two consistent goals recognised GoalGraphAnalyser algorithm timestep 4: (move-object H O) fully achieved (keep-object-at O) partiallyachieved. two consistent goals, fully achieved goal better explainsobserved actions far. If, instance, another action (take-out D) observed nexttime step, (keep-object-at O) becomes fully achieved remains consistentobserved actions. time step, best explains observed actions. partiallyachieved goal, consistent observed actions far, remain consistentactions observed future becomes fully achieved. choosingfully achieved goal making partially achieved goal redundant rulepossibility partially achieved goal remaining consistent becoming fully achievedfuture. Based principle, make partially achieved consistent goaltime step redundant, satised goal descriptions implied satised goaldescriptions another fully partially achieved consistent goal.Definition 7 partially achieved consistent goal time step redundant, setsatised goal descriptions either subset goal descriptions fully achieved consistent goal proper subset satised goal descriptions another partially achievedconsistent goal time step.instance, time step 4 set satised goal descriptions (keep-object-atO) subset goal descriptions (move-object H O). partial achievement(keep-object-at O) implied full achievement (move-object HO). (keep-object-at O) made redundant (move-object H O) time step4.fully achieved consistent goal time step, however, made redundantgoal descriptions implied goal descriptions another fully achieved consistentgoal time step.Definition 8 fully achieved consistent goal time step redundant, setgoal descriptions subset goal descriptions another fully achieved consistent goaltime step.5.4 Consistent Goalsredundant goals removed set consistent goals timestep, might still one consistent goal set. case,numbers observed actions relevant remaining consistent goalscompared. remaining goals maximum number relevant actionschosen consistent goals time step.Definition 9 Given set consistent goals time step, consistent goal setconsistent goal set, maximum number relevant actions amongconsistent goals set.21fiHonginstance, example shown Figure 2, another action (take-out D)observed time step 4, (move-object H O) (keep-object-at O) consistent goals time step 5, neither redundant. (keep-object-at O)relevant observed actions, (move-object H O) relevantfour observed actions. According Denition 9, (keep-object-at O)consistent goal time step 5.example shown Figure 2, goal nodes asterisk represent consistentgoals eventually remaining two processes removing redundant goals selectingconsistent goals.6. Experimental Resultsimplemented goal recognition algorithms Prolog tested termsaccuracy, eciency, scalability desktop Pentium III processor 600 MHz.tested algorithms set data UNIX domain collected UniversityWashington. collect data, subjects given goals described English rsttried achieve goal executing UNIX commands. commandsissued UNIX subject responses UNIX commandsrecorded data set. commands issued subject validcould executed UNIX. responses UNIX invalid commandsactually error messages. goals subjects tried achieve,indicated success failure regard achievement goal.14 goals UNIX data set, goals tried 5 subjectsaverage. shown Table 1, goals classied four types. rst typegoals locating le properties, extension, size,contents, ownership, date, word count, compression. second type goalslocating machine properties, load logged-in users.third type goals locating printer properties,print jobs paper. fourth type goals compressing largeles directory. fourth type goals, universally quantied goal descriptionsneeded corresponding goal schemata. addition, also two compoundgoals, G3 G9 , conjunctions two goals second type.test algorithms, sequences UNIX commands, recorded data set,taken observed actions consecutive time steps. took valid commands,successfully executed UNIX, ltered invalid commands,UNIX failed execute responded error messages. created 35 actionschemata set commonly used UNIX commands, including executedsubjects. also created 249 goal schemata, including 129 le-search goal schemata (forgoals locating le properties), 15 non-le-search goal schemata (for goalslocating machine printer properties goals compressinglarge les directory) 105 goal schemata paired non-le-search goals.14 goals UNIX data set instances goal schemata. rsttested algorithms respect accuracy eciency, is, number goalsremaining sequence observed actions processed, average time22fiGoal Recognition Goal Graph AnalysisG1G2G3G4G5G6G7G8G9G10G11G12G13G14Find le named core.Find le contains motivating whose name ends .tex.Find machine low (< 1.0) load;determine Oren Etzioni logged machine named chum.Compress large (> 10,000 bytes) les Testgrounds subdirectory tree.Compress les directory named backups [Dont use *].Find large le (> 100,000 bytes) hasnt changed month.Find le contains less 20 words.Find laser printer Sieg Hall active print job.Find Sun fourth oor low (< 1.0) load;determine Dan Weld active machine named chum.Find printer paper.Find le named oldpaper neal/Testgrounds subdirectory.Find le length 4 neal/Testgrounds subdirectory.See Dan Weld logged chum.Find machine Dan Weld logged into.Table 1: 14 goals UNIX data set collected University Washingtontaken construct Goal Graph, analyse constructed Goal Graph, runcycle Goal Graph construction analysis, action observed time step.Table 2 gives summary empirical results showing accuracy algorithms.rst column shows goals subject tried achieve. achieved goalsgoals fully partially achieved last observed action processed.consistent goals fully partially achieved goals consistentsequence observed actions.6 remaining goals goals remainedredundant goals removed consistent goals selected.last column shows whether given goal among remaining goals.shown Table 2, algorithms successfully recognised 13 14 given goals.failed recognise one given goal, G10 , simply sequence commandsexecuted subject actually failed achieve goal. terms UNIX data set,goal recognition occurs algorithms return single, consistent goal. occurredG2 , G4 , G7 , G8 , G9 , G13 , G14 . G1 , G3 , G6 , G11 , G12 , one goalrecognised, including goal given subject. G1 , G6 , G11 , G12 ,algorithms recognised subject tried nd one les propertiesdirectory know le was. instance, G1 , intendedgoal nd le named core. subject successfully found le named coredirectory, other, executing command, ls, list les directory. Sinceles, greenmouse, paper.tex, action.ps.Z, directory,6. experiments UNIX data set, goal, two third observed actionsrelevant, recognised consistent goal. threshold number relevant actionsdependent application domain though strict majority actions must relevant.threshold high, algorithms might fail recognise intended goal. hand,low, set recognised goals might large provide much value great ambiguityintended goal.23fiHonggoalG1G2G3G4G5G6G7G8G9G10G11G12G13G14achievedgoals1526145646107856229126018consistentgoals15641833474450124412remaininggoals41216411102611given goalrecognisedTable 2: Empirical results UNIX domain showing accuracy algorithmsles also listed command, algorithms recognised fourgoals, nding le named core, nding le named greenmouse, nding le namedpaper extension tex, nding le named action extension psalso compressed. G3 , algorithms recognised subject tried nd oneusers machine know was. good humanobserver could simply could tell observed actions leuser subject trying nd. recognised goals generalised single,consistent goal nding le directory nding user using machine,variables allowed recognised goals.G5 , algorithms recognised 6 consistent goals. Among goals, goalsnd les properties compression extensiondirectory named backups. Another goal gunzip les directorynamed backups. human observer could probably better recognising goalgunzipping les directory named backups, accounted bettergunzip command observed. unlikely subject gunzippedles directory order nd le gunzip compression.Among goals tested, G1 , G2 , G3 , G4 originally tested LeshEtzioni (1995). empirical results show signicant improvement accuracygoal recogniser implemented terms remaining goals. algorithms4, 1, 2, 1 remaining goals G1 , G2 , G3 , G4 respectively, goalrecogniser 155, 37, 1, 15 remaining goals G1 , G2 , G3 , G4 respectively,last observed action processed. Furthermore, 4 2 remaining goalsalgorithms G1 G3 generalised two single goals. resultsshow algorithms perform extremely well regard accuracy.24fiGoal Recognition Goal Graph AnalysisgoalG1G2G3G4G5G6G7G8G9G10G11G12G13G14lengthobservation2.25163.020.598.789.113.5121571712constructiontime0.5350.3820.0211.0360.42612.18516.4730.0140.0340.0180.0510.8210.0100.013analysistime0.0130.1020.0093.6090.5654.1438.5810.0020.0500.0070.0200.7740.0010.004timeper cycle0.5470.4840.0304.6450.99116.32925.0540.0170.0840.0250.0711.5950.0110.017Table 3: Empirical results UNIX domain showing eciency algorithmsworth noting Lesh Etzionis algorithm converges last observedaction processed. algorithm works towards goal prediction, algorithms emphasise explanation observed actions, recognising fully partiallyachieved goals consistent actions. algorithm quickly pruneinconsistent goals get converged set hypothesised goals, though numberhypothesised goals set sometimes large. next step work mightassign probabilities hypothesised goals dierentiate single goalothers, exists one intended goal. hand, less desirablegoals recognised algorithms dierentiated accuracyalgorithms usually high. algorithms, however, cannot recognise goalfully partially achieved.Table 3 gives summary empirical results showing eciency algorithms.length observation average number observed actions executedsubjects achieve given goal. construction time average time tookconstruct Goal Graph time step. analysis time average time tookanalyse constructed Goal Graph time step. time per cycle averagetime took go two-stage cycle Goal Graph construction analysis,observed action processed time step, including constructing GoalGraph, recognising consistent goals, removing redundant goals, selectingconsistent goals. shown Table 3, average time step, took 2.287 CPU secondsconstruct Goal Graph, 1.277 CPU seconds analyse Goal Graph, 3.564CPU seconds process observed action. Since algorithms writtenless ecient Prolog run desktop Pentium III processor 600 MHz,eciency could achieved. construction time, analysis time, time per cycle could25fiHongAverage CPU Seconds250200C-Time150A-Time100P-Time500100801979029665395404941559290691658101590890 100765Number GoalsFigure 6: Empirical results UNIX domain showing scalability algorithmsreduced well CPU second, algorithms coded ecientprogramming language run faster machine.Compared empirical results eciency goal recogniser implementedLesh Etzioni (1995), average, took 0.547, 0.484, 0.030, 4.645 CPU secondsprocess observed action algorithms G1 , G2 , G3 , G4 respectively,1.616, 1.643, 0.648, 1.610 CPU seconds taken goal recogniser processobserved action goals. average time process observed actionroughly around 1.4 CPU seconds desktop Pentium III processor600 MHz algorithms coded Prolog SPARC 10 goal recognisercoded Lisp. Given two dierent programming languages machines usedimplementation two dierent systems, comparison hardly meaningful.however apparent use ecient programming languages machinessignicantly speed algorithms.also tested scalability goal recognition algorithms UNIX domain.tested eciency algorithms aected number possible goals,turn aected number objects universe objects. createdseries spaces approximate 104 , 2 104 , 3 104 , 105 possible goals respectivelybased data recorded G7 UNIX data set.7 this, changedles directories le hierarchy, well properties les, originaldata set G7 , increase decrease number objects universe objects,keeping les directories related intended goal propertiesrelated les unchanged. sense part Initial Conditionsintended goal remained same, rest Initial Conditions changed create7. number goal schemata remains unchanged.26fiGoal Recognition Goal Graph Analysisappropriate number candidate goals. change le hierarchy reectedchange complexity le hierarchy.original sequences commands recorded data set used experiments, conjunction dierent sets Initial Conditions, creationdierent spaces candidate goals. Figure 6 shows average CPU time takentime step construct analyse Goal Graph (shown C-Time A-Time respectively Figure 6), process observed action whole (shown P-TimeFigure 6) approximately linear number candidate goals.7. Conclusion Future Workpaper, presented new approach goal recognition graph structurecalled Goal Graph constructed analysed goal recognition. described twoalgorithms constructing analysing Goal Graph. algorithms recognise partiallyfully achieved goals consistent observed actions, reveal valid plansrecognised goals part them. algorithms need plan library.allow redundant, extraneous, partially ordered actions. sound, polynomialtime, polynomial-space.empirical experiments show algorithms recognise goals great accuracy.computationally ecient. scaled applied domainstens thousands goals plans. Even though one goal recognitionalgorithms, GoalGraphAnalyser algorithm, complete, recognisedintended goals UNIX data set successfully achieved subjects.limitation goal recognition algorithms sometimes one goalrecognised, though number recognised goals usually small. algorithmscannot tell goal probable one one intended goal.instance, G5 UNIX data set, algorithms recognised 6 goals. Even thoughintended goal, gunzipping les directory called backups, among goals,probably likely one compared others, algorithms coulddierentiate others. Sometimes algorithms recognise unique goalimplies intended goal cannot make specic. instance, G7 UNIXdata set, algorithms recognised unique goal, nding le, index.tex, wordcount extension. Even though achievement goal implied achievementintended goal, nding le contains less 20 words, algorithms couldspecic. problems due incomplete informationobserved actions. G7 , observed actions indication likelihoodrecognised goals intended goal. subject actually achieved G7knew word count less 20 words knowing word count le,observed action directly used achieve this.Several attempts (Carberry, 1990; Charniak & Goldman, 1993; Huber et al., 1994;Forbes et al., 1995; Pynadath & Wellman, 1995; Bauer, 1995; Albrecht et al., 1998)made incorporate uncertainty representation reasoning techniques planrecognition handling uncertain incomplete information, single plandistinguished set candidate plans. However, systems rely heavilyavailability planning knowledge certain extent use plan libraries. future27fiHongwork, intend investigate possibility incorporating uncertainty representationreasoning mechanisms Goal-Graph-based approach goal recognition,unique, specic goal recognised one intended goal,good features Goal-Graph-based approach kept.future work, also intend explore extent Goal Graph representation used probabilistic goal recognition. particular, consider problemsettings eects actions probabilistic objective goal recognitionrecognise consistent goals highest probability achievement.Another area future work recognise goals even partiallyfully achieved actions observed far. regard, current goal recognitionalgorithms used recognise goals sequence actions large dataset achieve. sequence actions data set recognised goalsused acquire probabilistic model goal prediction machine learning method.probabilistic model takes actions observed far predicts possible goals evenpartially fully achieved.Acknowledgmentspaper revised extended version paper appeared ProceedingsAAAI-2000 (Hong, 2000). author wishes thank Neal Lesh providing UNIXdata set, anonymous referees insights constructive criticisms,helped improve paper signicantly.ReferencesAlbrecht, D. W., Zukerman, I., & Nicholson, A. E. (1998). Bayesian model keyholeplan recognition adventure game. User Modeling User-Adapted Interaction,8 (1-2), 547.Allen, J. F. (1983). Recognizing intentions natural language utterances. Brady, M.,& Berwick, B. (Eds.), Computational Models Discourse, pp. 107166. MIT Press,Cambridge, MA.Allen, J. F., & Perrault, C. R. (1980). Analyzing intention utterances. Articial Intelligence, 15, 143178.Anderson, C., Smith, D. E., & Weld, D. (1998). Conditional eects Graphplan.Proceedings 4th International Conference AI Planning Systems, pp. 4453.Bauer, M. (1995). Dempster-Shafer approach modeling agent preferences plan recognition. User Modeling User-Adapted Interaction, 5 (3-4), 317348.Bauer, M. (1998). Acquisition abstract plan descriptions plan recognition. Proceedings AAAI-98, pp. 936941.Bauer, M., & Paul, G. (1993). Logic-based plan recognition intelligent help systems.Backstrom, C., & Sandewall, E. (Eds.), Current Trends AI Planning, pp. 6073.IOS Press.28fiGoal Recognition Goal Graph AnalysisBlum, A. L., & Furst, M. L. (1997). Fast planning Planning Graph analysis.Articial Intelligence, 90, 281300.Carberry, S. (1986). User models: problem disparity. Proceedings 11thInternational Conference Computational Linguistics, pp. 2934.Carberry, S. (1988). Modeling users plans goals. Computational Linguistics, 14 (3),2337.Carberry, S. (1990). Incorporating default inferences plan recognition. ProceedingsAAAI-90, pp. 471478.Carver, N. F., Lesser, V. R., & McCue, D. L. (1984). Focusing plan recognition.Proceedings AAAI-84, pp. 4248.Charniak, E., & Goldman, R. P. (1993). Bayesian model plan recognition. ArticialIntelligence, 64, 5379.Forbes, J., Huang, T., Kanazawa, K., & Russell, S. (1995). BATmobile: TowardsBayesian automated taxi. Proceedings IJCAI-95, pp. 18781885.Gazen, B., & Knoblock, C. (1997). Combining expressivity UCPOP eciencyGraphplan. Proceedings 4th European Conference Planning, pp. 221233.Goodman, B. A., & Litman, D. J. (1992). interaction plan recognitionintelligent interfaces. User Modeling User-Adapted Interaction, 2, 83115.Grosz, B. J., & Sidner, C. L. (1990). Plans discourse. P. R. Cohen, J. M., & Pollack,M. E. (Eds.), Intentions Communication, pp. 417444. MIT Press, Cambridge, MA.Hong, J. (2000). Goal Graph construction analysis paradigm plan recognition.Proceedings AAAI-2000, pp. 774779.Huber, M. J., & Durfee, E. H. (1995). Deciding commit actionobservation-based coordination. Proceedings First International ConferenceMulti-Agent Systems, pp. 163170.Huber, M. J., Durfee, E. H., & Wellman, M. P. (1994). automated mapping plansplan recognition. Proceedings 10th Conference Uncertainty ArticialIntelligence, pp. 344351.Hu, K., & Lesser, V. (1988). plan-based intelligent assistant supports softwaredevelopment process. Proceedings ACM SIGSOFT/SIGPLAN Software Engineering Symposium Practical Software Development Environments, pp. 97106.Kautz, H. A. (1987). Formal Theory Plan Recognition. PhD Thesis, UniversityRochester.Koehler, J., Nebel, B., Homann, J., & Dimopoulos, Y. (1997). Extending planning graphsADL subset. Proceedings 4th European Conference Planning, pp.273285.Lesh, N., & Etzioni, O. (1995). sound fast goal recognizer. Proceedings IJCAI95, pp. 17041710.29fiHongLesh, N., & Etzioni, O. (1996). Scaling goal recognition. Proceedings 5thInternational Conference Principles Knowledge Representation Reasoning,pp. 178189.Litman, D. J., & Allen, J. F. (1987). plan recognition model sub-dialogues conversation. Cognitive Science, 11 (2), 163200.Mooney, R. J. (1990). Learning plan schemata observation: Explanation-based learningplan recognition. Cognitive Science, 14 (4), 483509.Pednault, E. P. D. (1988). Synthesizing plans contain actions context-dependenteects. Computational Intelligence, 4 (4), 356372.Pednault, E. P. D. (1989). ADL: Exploring middle ground STRIPSSituation Calculus. Proceedings 1st International Conference KnowledgeRepresentation Reasoning, pp. 324332.Pollack, M. E. (1990). Plans complex mental attitudes. Cohen, P. R., Morgan,J., & Pollack, M. E. (Eds.), Intentions Communication, pp. 77101. MIT Press,Cambridge, MA.Pynadath, D. V., & Wellman, M. P. (1995). Accounting context plan recognition,application trac monitoring. Proceedings 11th Conference UncertaintyArticial Intelligence, pp. 472481.Schank, R., & Abelson, R. (1977). Scripts, Plans, Goals, Understanding. Erlbaum.Sidner, C. L. (1985). Plan parsing intended response recognition discourse. Computational Intelligence, 1 (1), 110.Wilensky, R. (1983). Planning Understanding. Addison-Wesley Publishing Company,Reading, MA.Wilensky, R., & et al. (1988). Berkeley unix consultant project. Computational Linguistics, 14 (4), 3584.30fiJournal Artificial Intelligence Research 15 (2001) 289-318Submitted 3/01; published 10/01Ecient Methods Qualitative Spatial Reasoningrenz@dbai.tuwien.ac.atJochen RenzInstitut fur Informationssysteme, Technische UniversitWienFavoritenstr.9, A-1040 Wien, Austrianebel@informatik.uni-freiburg.deBernhard NebelInstitut fur Informatik, Albert-Ludwigs-UniversitFlughafen 17, D-79110 Freiburg, GermanyAbstracttheoretical properties qualitative spatial reasoning RCC-8 frameworkanalyzed extensively. However, empirical investigation made yet.experiments show adaption algorithms used qualitative temporalreasoning solve large RCC-8 instances, even phase transition region{ provided one uses maximal tractable subsets RCC-8 identifiedus. particular, demonstrate orthogonal combination heuristic methodssuccessful solving almost apparently hard instances phase transition regioncertain size reasonable time.1. IntroductionRepresenting qualitative spatial information reasoning informationimportant subproblem many applications, natural language understanding, document interpretation, geographical information systems. RCC-8 calculus (Randell,Cui, & Cohn, 1992b) well suited representing topological relationships spatialregions. Inference full calculus is, however, NP-hard (Grigni, Papadias, & Papadimitriou, 1995; Renz & Nebel, 1999). means unlikely largeinstances solved reasonable time, result rule possibilitysolve instances certain size reasonable time. Recently, maximal tractablesubsets RCC-8 identified (Renz & Nebel, 1999; Renz, 1999) usedspeed backtracking search general NP-complete reasoning problem reducingsearch space considerably.paper address several questions emerge previous theoretical resultsRCC-8 (Renz & Nebel, 1999; Renz, 1999): size possible solveinstances reasonable time? heuristic best? really much ecientuse maximal tractable subsets solving instances NP-complete consistencyproblem theoretical savings given smaller branching factors indicateeffect out-balanced forward-checking power interleaved path-consistencycomputations? case similar temporal problems (pointisable vs. ORD-Hornrelations) (Nebel, 1997). possible combine different heuristics wayinstances solved reasonable time heuristic alone?treat questions randomly generating instances solving usingdifferent heuristics. so, particularly interested hardest randomlyc 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiRenz & Nebelgenerated instances leads question phase-transitions (Cheeseman, Kanefsky,& Taylor, 1991): parameter randomly generating instances consistencyproblem RCC-8 results phase-transition behavior? so, casehardest instances mainly located phase-transition region instancescontained phase-transition region easily solvable? order generate instancesharder higher probability, generate two different kinds instances.one hand generated instances contain constraints RCC-8 relations,hand generated instances contain constraints relationscontained maximal tractable subsets. expect instancesharder average former instances.algorithmic techniques use solving randomly generated instancesborrowed similar work qualitative temporal reasoning (Nebel, 1997; van Beek &Manchak, 1996; Ladkin & Reinefeld, 1992). Additionally, make use fragmentsRCC-8, named Hb 8, Q8 , C8, permit polynomial-time inferences (Renz & Nebel,1999; Renz, 1999). backtracking algorithm, used solve reasoningproblem full RCC-8, decompose every disjunctive relation relations onetractable subsets instead decomposing base relations. reducesaverage branching factor backtracking tree 4.0 base relations1.4375 Hb 8, 1.523 C8, 1.516 Q8 . Although theoretical savingscannot observed experiments, using maximal tractable subsets insteadbase relations leads significant performance improvements.paper structured follows. Section 2, give brief sketch RCC-8calculus algorithms used solving instances RCC-8. Section 3 describeprocedure randomly generating instances, different heuristics apply solvinginstances, measure quality heuristics. Section 4 evaluatedifferent path-consistency algorithms order find ecient one usedforward-checking backtracking search. Section 5 observe phase-transitionbehavior randomly generated instances show instances phasetransition region harder solve instances. Section 6 reportoutcome running different heuristics solving instances identify severalhard instances mainly located phase-transition region. Section 7 trysolve hard instances orthogonally combining different heuristics. turnseffective leads ecient solution strategy. Finally, Section 8evaluate strategy trying solve large instances.12. Region Connection Calculus RCC-8Region Connection Calculus (RCC) first-order language representationreasoning topological relationships extended spatial regions (Randell et al.,1992b). Spatial regions RCC non-empty regular subsets topological spaceinternally connected, i.e., spatial region may consist differentdisconnected pieces. Different relationships spatial regions defined basedone dyadic relation, connected relation C( ) true topological closuresspatial regions share common point.a; bb1. programs available online appendix.290fiEfficient Methods Qualitative Spatial Reasoningfi fifififi fififiXXDC(X; Y)XXTPP(X; Y) TPP 1 (X; Y)EC(X; Y)XXPO(X; Y)XXNTPP(X; Y) NTPP 1 (X; Y)EQ(X; Y)Figure 1: Two-dimensional examples eight base relations RCC-8Region Connection Calculus RCC-8 constraint language formed eightjointly exhaustive pairwise disjoint base relations DC, EC, PO, EQ, TPP, NTPP, TPP 1 ,NTPP 1 definable RCC-theory possible unions base relations|giving total number 28 = 256 different relations. base relations meaningDisConnected, Externally Connected, Partial Overlap, EQual, Tangential Proper Part,Non-Tangential Proper Part, converses. Examples relations shownFigure 1. Constraints written formvariables spatialregions RCC-8 relation. write union base relations f g.union base relations, universal relation, written fg. Apart union([), operations relations defined, namely, converse ( ), intersection (\),composition (). formal definitions operations are:xRyx;RR;^8888x;x;x;x;::::( [ )( \ )x Rx RxR^( )x R$$$$ 9_^,:(xRyxSxRyxSyRxzxRz,,^)zSy :composition base relations computed semantics relationsusually provided composition table (Randell, Cohn, & Cui, 1992a; Bennett, 1994).RCC-8 composition table corresponds given extensional definition compositionuniversal region permitted (Bennett, 1997). Based table, compositionsdisjunctive relations easily computed. following, Sb denotes closureset RCC-8 relations composition, intersection, converse.finite set RCC-8 constraints describing topological relationships differentregions represented matrix , entry represents RCC-8relation holding region region . Without loss generality, = fEQg=assumed. fundamental reasoning problem (named RSAT)framework deciding consistency set spatial formulas , i.e., whetherspatial configuration relations regions described .interesting reasoning problem reduced polynomial time (Golumbic& Shamir, 1993). Unfortunately, RSAT NP-complete (Renz & Nebel, 1999), i.e.,unlikely polynomial algorithm deciding consistency. However,shown Nebel's (1995) paper subsets RCC-8 consistencynnMjinj^Mij291MijMiifiRenz & Nebelproblem (written RSAT(S)) decided polynomial time.2 particular seteight base relations B shown tractable. follows Bb consisting32 relations also tractable. even larger tractable subset containing base relationsHb 8 (Renz & Nebel, 1999), contains 148 256 RCC-8 relations. setalso shown maximal respect tractability, i.e., RCC-8 relationadded, consistency problem becomes NP-complete. Renz (1999) made completeanalysis tractability RSAT identifying maximal tractable subsets containbase relations, altogether three subsets Hb 8, Q8 (160 relations), C8 (158 relations).NP 8 set relations result NP-completeness combinedset base relations. contains following 76 relations containedone Hb 8 Q8 C8 (Renz, 1999):NP 8 = f j fPOg 6 (fNTPPg fTPPg )(fNTPP 1g fTPP 1g )g[ ffEC NTPP EQg fDC EC NTPP EQgfEC NTPP 1 EQg fDC EC NTPP 1 EQggmaximal tractable subsets contain following relations (Renz, 1999):Hb 8 = (RCC-8 n NP 8 ) n f j (fEQ NTPPg fTPPg 6 )(fEQ NTPP 1 g fTPP 1g 6 )gC8 = (RCC-8 n NP 8 ) n f j fECg fPOg 6\ fTPP NTPP TPP 1 NTPP 1 EQg =6 ;gQ8 = (RCC-8 n NP 8 ) n f j fEQg fPOg 6\ fTPP NTPP TPP 1 NTPP 1 g 6= ;g;;RRRRR;;;;;;;;;;;;;RRR;;RR;R;;:RRRR;;RRR;R;relations Q8 contained one Hb 8 C8, i.e., Hb 8 [ C8 = RCC-8 n NP 8 .Although Hb 8 smallest three maximal tractable subsets, best decomposesRCC-8 relations: decomposing RCC-8 relationsub-relations onemaximal tractable subsets, i.e., = 1 [ [ , one needs average 1.4375 Hb 8 relations,1.516 Q8 relations, 1.523 C8 relations decomposing RCC-8 relations. Renz (2000)gives detailed enumeration relations three sets.RR:::SiSk2.1 Path-Consistency Algorithmarea qualitative temporal reasoning based Allen's interval calculus (Allen,1983), path-consistency algorithm (Montanari, 1974; Mackworth, 1977; Mackworth &Freuder, 1985) used approximate consistency realize forward-checking(Haralick & Elliot, 1980) backtracking algorithm.path-consistency algorithm checks consistency triples relationseliminates relations impossible. done iteratively performing followingoperation\MijMijMikMkj2. Strictly speaking, applies systems regions require regularity.292fiEfficient Methods Qualitative Spatial ReasoningAlgorithm: Path-consistencyInput: set binary constraints variables x1 ; x2 ; : : : ; xnrepresented matrix .path-consistent set equivalent ; fail, setexist.nOutput:n1. := f( ) ( ) j 16= 6= g;( indicates -th variable . Analogously )2. 6= ;3. select delete path ( ) ;4. revise( )5.= ; return fail6.else := [ f() ( ) j 1 6= 6= g.Qi; j; k ;k; i; ji; j; kn; < j; ki; kjjkQp; r; qQp; r; qMpqQQp; q; ;s; p; qn;p;qFunction: revise(i; k; j )Input: three labels i, k j indicating variables x ; x ; xOutput: true, revised; false otherwise.Side effects: revised using operations \jkijijjiconstraints involving , , .xixkxj1. oldM := ;2.:= \ ( );3. (oldM = ) return false;4.:= ;5. return true.MijMijMijMjMijMikMkjMij^Figure 2: Path-consistency algorithm.triples regionsfixed point reached.= ; pair, know inconsistent, otherwise path-consistent. Computingdone ( 3) time (see Figure 2). achieved using queue triplesregions relations recomputed (Mackworth & Freuder, 1985). Pathconsistency imply consistency. instance, following set spatial constraintspath-consistent consistent:i; j; ki; jijnlHH - lHHHl? HHHj- l?XDC _ TPPZTPP _ TPP 1EC _ TPPEC _ TPPEQ _ NTPPEC _ NTPPWhand, consistency imply path-consistency, since path-consistencyform consistency (in logical sense), form disjunctive non-redundancy.Nevertheless, path-consistency enforced consistent set constraints ap293fiRenz & NebelAlgorithm: ConsistencyInput: set RCC-8 constraints variables x1 ; x2 ; : : : ; xsubset RCC-8 contains base relationsDecide sound complete decisionprocedure.Output: true, iff consistent.1. Path-Consistency()2. contains empty relation return false3. else choose unprocessed constraintsplit 12 1 [ [ =4. constraint split return Decide()5. refinements (1 )6.replace7.Consistency() return truenxi RxjR; : : : ; SkSlxi Rxjl:::SkRkxi Sl xjFigure 3: Backtracking algorithm deciding consistency.plying path-consistency algorithm. relations Hb 8, Q8 , C8 used, however,path-consistency algorithm sucient deciding consistency, i.e., path-consistencydecides RSAT(Hb 8), RSAT(Q8 ), RSAT(C8 ), (Renz & Nebel, 1999; Renz, 1999).2.2 Backtracking Algorithmorder solve instance RSAT, explore corresponding search spaceusing sort backtracking. experiments, used backtracking algorithmemployed solving qualitative temporal reasoning problems (Nebel, 1997), basedalgorithm proposed Ladkin Reinefeld (1992). algorithm (see Figure 3)necessary subset RCC-8 consistency decided usingsound complete (and preferably polynomial) decision procedure Decide. containsbase relations, thenS relation 2 RCC-8 decomposed sub-relations2 =. size particular decomposition minimal numbersub-relations used decompose . backtracking algorithm successivelyselects constraints , backtracks sub-relations constraints accordingdecomposition decides sub-instances contain constraints usingDecide.(optional) procedure Path-consistency line 1 used forward-checkingrestricts remaining search space. Nebel (1997) showed restrictioneffect soundness completeness algorithm. enforcing path-consistencysucient deciding RSAT(S), Decide() line 5 necessary. Instead possiblealways return true there.eciency backtracking algorithm depends several factors. One is,course, size search space explored. common way measuringRSiRSiSiR294fiEfficient Methods Qualitative Spatial Reasoningsize search space average branching factor search space, i.e.,average number branches node search space (a node recursive 2call) 2,Consistency). average size search space computed (2() 2 number constraints split variablesgiven. backtracking algorithm described Figure 3 branching factor dependsaverage number relations split set relation split.less splits average better, i.e., expected eciencybacktracking algorithm depends split set branching factor. Another factorsearch space explored. backtracking algorithm Figure 3 offers twopossibilities applying heuristics. One line 3 next unprocessed constraintchosen, line 5 next refinement chosen. twochoices uence search space path search space.bbnn =nn =n3. Test Instances, Heuristics, Measurementprevious work empirical evaluation algorithms reasoning RCC-8benchmark problems known. Therefore randomly generated test instancesgiven number regions , average label-size , average degreeconstraint graph. Further, used two different sets relations generating testinstances, set RCC-8 relations set hard RCC-8 relations NP 8, i.e.,76 relations contained maximal tractable subsets Hb 8, C8 ,Q8 . Based sets relations, used two models generate instances, denoted( ) ( ). former model uses relations generate instances,latter relations NP 8. instances generated follows:1. constraint graph nodes average degree node generated.accomplished selecting 2 ( 1) 2 possible edges usinguniform distribution.2. edge th th node, set = universalrelation.3. Otherwise non-universal relation selected according parameteraverage size relations selected edges . accomplished selectingone base relations uniform distribution remaining 7 relationsone probability ( 1) 7.3 results allowed relation (i.e., relationNP 8 ( ), RCC-8 relation ( )), assign relationedge. Otherwise repeat process.reason also generating instances using relations NP 8 assumeinstances dicult solve since every relation splitbacktracking search, even use maximal tractable subclass split set.generated instances average label size = 4 0, since case relations equallydistributed.nn; d; llH n; d; lnnd=n nj=MijMjilll=H n; d; ln; d; ll:3. method could result assignment universal constraint selected link, thereby changingdegree node. However, since probability getting universal relation low,ignore following.295fiRenz & Nebelway generating random instances similar way random CSP instances finite domains usually generated (Gent, MacIntyre, Prosser, Smith, &Walsh, 2001). Achlioptas et al. (1997) found standard models generatingrandom CSP instances finite domains lead trivially awed instances ! 1,i.e., instances become locally inconsistent without propagate constraints. Sinceusing CSP instances infinite domains, Achlioptas et al.'s result necessarily hold random instances. We, therefore, analyze following whetherinstances also trivially awed ! 1. order obtain CSP finite domain, first transform constraint graph dual graph( 1) 2 edgesconstraint graph corresponds nodedual graph. Moreover, variables constraint graph corresponds1 edges dual graph, i.e., dual graph contains ( 1) edges ( 1) 2nodes. dual graph, node corresponds variable eight-valued domain= fDC EC PO TPP TPP 1 NTPP NTPP 1 EQg. Ternary constraints variables imposed composition table, i.e., composition rulesmust hold connecteddual graph ( =triples nodesn). 3 = ( 1)( 2) 6 connected triples dual graph.n(n 1)=2overall number triples dual graph.2 unary constraints3domain variables given, i.e., nd=3 2 triples dual graphnodes restricted unary constraints. Therefore, expected numberconnected triples unary constraints given computed!!23 3!=( 1) 23! 1, expected number triples 1 tends 3 6. instances generatedaccording model ( ), probability unary constraintsassigned triple lead local inconsistency 0 0036% (only 58,9892553 = 16 581 375 possible assignments inconsistent). Since one locally inconsistenttriple makes whole instance inconsistent, interested average degreeexpected number locally inconsistent triples equal one. model( ) occurs value = 11 90, 1 = 0 5 = 9 44. = 100,expected number locally inconsistent triples one = 13 98, 100 = 0 5= 11 10. model ( ), none possible assignments triples leadslocal inconsistency, i.e., triples randomly generated instances ( )model locally consistent.4 analysis shows contrary Achlioptas etal. found randomly generated CSP instances finite domains, model ( ),model ( ) small suffer trivial local inconsistencies.nnn n=Mijnnn n;;;;;;n n;MijMikMij ; Mik ; Mkji; jn n=nMkj^MijMj=nd=MijnCTEnnd=n:ECn nn=EC=n; d; l;;;nEn; d; l:E::::nE:H n; d; lH n; d; lH n; d; ln; d; l4. similar result CSPs finite domains restricting constraint type, e.g.,\not-equal" constraints graph-coloring used, possible ensure problems cannottrivially awed.296fiEfficient Methods Qualitative Spatial Reasoningsolve randomly generated instances using backtracking algorithm describedprevious section. search space backtracking performed dependssplit set, i.e., set sub-relations allowed decompositions. Choosingright split-set uences search noticeably uences average branching factorsearch space. choose five different split sets, three maximal tractable subsetsHb 8 Q8 C8, set base relations B closure set Bb consists38 relations. sets following branching factors B: 4.0, B:b 2.50 ,Hb 8: 1.438,C8: 1.523, Q8 : 1.516. is, course, worst case measure interleaved pathconsistency computations reduce branching factor considerably (Ladkin & Reinefeld,1997).Apart choice split set heuristics uence eciency search. general best search strategy proceed constraintconstraining relation (line 3 Figure 3) least constraining choicesub-relation (line 5 Figure 3). investigated two different aspects choosingnext constraint processed (Nebel, 1997).static/dynamic: Constraints processed according heuristic evaluationconstrainedness determined statically backtracking starts dynamically search.local/global: evaluation constrainedness based local heuristic weightcriterion global heuristic criterion (van Beek & Manchak, 1996).gives us four possibilities combine five different split sets, i.e.,total number 20 different heuristics. evaluation constrainedness wellrelations decomposed relations different split sets depends restrictivenessrelations, heuristic criterion (van Beek & Manchak, 1996). Restrictivenessrelation measure relation restricts neighborhood. instance,universal relation given constraint network restrict neighboring relationsall, result composition relation universal relation universalrelation. identity relation, contrast, restricts neighborhood lot. every triplevariables one relation identity relation, two relations must equal.Therefore, universal relation usually least restricting relation, identityrelation usually restricting relation. Restrictiveness relations representedweight range 1 16 assigned every relation, 1 value16 value least restricting relation. discuss following sectiondetail restrictiveness weight relation determined.Given weights assigned every relation, compute decompositions estimateconstrainedness follows. split set RCC-8 relation computesmallest decomposition sub-relations S, i.e., decomposition requires least number sub-relations S. one possibility, choosedecomposition least restricting sub-relations. line 5 backtracking algorithm (see Figure 3), least restricting sub-relation decomposition processedfirst. local strategy, constrainedness constraint determined sizedecomposition (which different every split set) weight. chooseconstraint smallest decomposition larger one and,;;RR297fiRenz & Nebelone constraint, one smallest weight. reason choosing relationsmallest decomposition expected forward-checking refines relations larger decomposition relations smaller decomposition. reducesbacktracking effort. global strategy, constrainedness constraintdetermined adding weights neighboring relationsweight . idea behind strategy refining relationrestricted neighborhood, inconsistency detected faster refiningrelation less restricted neighborhood.order evaluate quality different heuristics, measured run-time usedsolving instances well number visited nodes search space. Comparingdifferent approaches run-time often reliable depends severalfactors implementation algorithms, used hardware, currentload used machine makes results sometimes reproducible. reason,ran run-time experiments machine, Sun Ultra 1 128 MBmain memory. Nevertheless, suggest use run-time results mainly qualitativelycomparing different heuristics getting rough idea order magnitudeinstances solved.contrast this, number visited nodes solving instance particularheuristic always every machine. allows comparing pathsearch space taken single heuristics judge heuristic makes betterchoices average. However, take account time needed makechoice single node. Computing local constrainedness constraint certainlyfaster computing global constrainedness. Similarly, computing constrainednessstatically faster computing dynamically. Furthermore, larger instancesrequire time nodes smaller instances, computing path-consistencycomputing constrainedness. Taking running-time number visited nodestogether gives good indications quality heuristics.choice make evaluating measurements aggregatemeasurements single instances total picture. possibilities useeither average different percentiles median, i.e., 50% percentile.% percentile value 0100 obtained sorting measurements increasingorder picking measurement % element, i.e., % values lessvalue. Suppose instances low value (e.g. running time)instances large value. average might larger valuesalmost instances, case median better indication distributionvalues. case 99% percentile, instance, gives good indicationvalue hardest among \normal" instances. chosen use averagevalue measurements well distributed use 50% 99% percentileexceptional values distribution measurements.xRyS;RxS zzTR< <4. Empirical Evaluation Path-Consistency AlgorithmSince eciency backtracking algorithm depends eciency underlyingpath-consistency algorithm, first compare different implementations pathconsistency algorithm. previous empirical investigations (van Beek & Manchak, 1996)298fiEfficient Methods Qualitative Spatial Reasoningreasoning Allen's interval relations (Allen, 1983), different methods computingcomposition two relations evaluated. mainly full compositiontable interval relations contains 213 213 = 67108864 entries, largetime stored main memory. setting, simply use compositiontable specifies compositions RCC-8 relations, 256 256 tableconsuming approximately 128 KB main memory. means compositiontwo arbitrary relations done simple table lookup.Van Beek Manchak (1996) also studied effect weighting relationsqueue according restrictiveness process restricting relation first.Restrictiveness measured base relation successively composing baserelation every possible label, summing cardinalities, i.e., number baserelations contained result composition, suitably scaling result.reason restricting relation restricts relationsaverage therefore decreases probability processed again.Restrictiveness complex relation approximated summing restrictivenessinvolved base relations. Van Beek Manchak (1996) found methodweighting triples queue much ecient randomly picking arbitrarytriple. relatively small number RCC-8 relations, computed exactrestrictiveness composing relation every relation summingcardinalities resulting compositions. scaled result weights 1 (therestricting relation) 16 (the least restricting relations).gives us three different implementations path-consistency algorithm. Oneentries queue weighted, one approximated restrictivenessdone van Beek Manchak, one exact restrictiveness.5 order compareimplementations, randomly generated instances 50 1,000 regions.value average degree ranging 8.0 stepping 0.5 11.0 generated10 different instances. Figure 4 displays average CPU time different methodsapplying path-consistency algorithm generated instances.seen positive effect using weighted queue much greater problemtemporal problem (about 10 faster using ordinary queue withoutweights compared 2 faster (van Beek & Manchak, 1996)). Determiningweights every relation using exact restrictiveness much advantageapproximating restrictiveness using approach van Beek Manchak (1996),however. experiments always used \exact weights" methoddetermining restrictiveness amounts one table lookup.mentioned previous section, one way measuring quality heuristicscount number visited nodes backtrack search. backtrackingalgorithm, path-consistency enforced every visited node. Note adequatemultiply average running-time enforcing path-consistency instanceparticular size number visited nodes order obtain approximationrequired running time instance. average running-time enforcing pathconsistency given Figure 4 holds possible paths enteredqueue beginning computation (see line 1 Figure 2). paths5. weighted versions select path (i; k; j ) queue Q line 3 algorithm Figure 2according weights different paths Q computed specified above.299fiRenz & NebelAverage CPU time PCA using different queue methods A(n,d,4.0)1000100"exact" weights"approx." weightsweightsCPU time (sec)1010.10.010.001100200300400500600nodes7008009001000Figure 4: Comparing performance path-consistency algorithm using differentmethods weighting queue (70 instances/data point, = 8 0 11 0)::checked algorithm. path-consistency computationbacktracking search different, however. There, paths involving currentlychanged constraint entered queue, since paths might result changesconstraint graph. much faster full computation path-consistencydone beginning backtrack search.5. Phase-Transition RCC-8randomly generating problem instances usually problem-dependent parameter determines solubility instances. one parameter range instancesunderconstrained therefore soluble high probability. another range,problems overconstrained soluble low probability.ranges phase-transition region probability solubility changes abruptlyhigh low values (Cheeseman et al., 1991). order study qualitydifferent heuristics algorithms randomly generated instances NP-completeproblem, important aware phase-transition behavior problem.instances contained phase-transition region ofteneasily solvable algorithms heuristics are, thus, usefulcomparing quality. Conversely, hard instances better suited comparingquality algorithms heuristics usually found phase-transition region.section identify phase-transition region randomly generated instancesRSAT problem, instances using RCC-8 relations instances usingrelations NP 8. Similarly empirical analysis qualitative temporal reasoningproblems (Nebel, 1997), turns phase-transition depends stronglyaverage degree nodes constraint graph. relations allowed, phased300fiEfficient Methods Qualitative Spatial ReasoningProbability satisfiability A(n,d,4.0)Median CPU time A(n,d,4.0)CPU time(s)Probability (%)1000.60.50.40.30.20.105010080604 68 1012 14average degree16 1840nodes10080604 68 1012 14average degree16 182040nodes20Figure 5: Probability satisfiability median CPU time (Hb 8/static/global heuristic (500 instances per data point)n; d;4 0) using:transition around = 8 = 10 depending instance size (see Figure 5).result theoretical analysis occurrence trivial aws (see Section 3),expected larger instance sizes phase-transition behavior overlaidmainly determined expected number locally inconsistent triples also dependsaverage degree . Thus, although seems phase-transition shifts towardslarger values instance size increases, phase-transition asymptotically= 9 44, theoretical value ! 1 (see Section 3). Instances pathconsistent solved fast one application path-consistency algorithmwithout need backtracking. looking median CPU times givenFigure 5, one notices sharp decline median CPU times phasetransition. indicates values average degree higherphase-transition occurs, least 50% instances path-consistent.using \hard" relations, i.e., relations NP 8, phase-transition appearshigher values , namely, = 10 = 15 (see Figure 6). medianruntime shows, instances much harder phase-transition formercase. previous case, even strongly, seems phase-transitionshifts towards larger values instance size increases, also phasetransition region narrows.order evaluate quality path-consistency method approximationconsistency, counted number instances inconsistent path-consistent(see Figure 7), i.e., instances approximation path-consistency algorithm consistency wrong. First all, one notes instances closephase transition region. general case, i.e., constraints RCC-8 relationsemployed, low percentage instances path-consistent inconsistent.Therefore, figure looks erratic. data points would required orderobtain smooth curve. However, important observations madefigure, namely, path-consistency gives excellent approximation consistency eveninstances large size. Except instances phase-transition region,almost instances path-consistent also consistent. picture changes:n301fiRenz & NebelProbability satisfiability H(n,d,4.0)Median CPU time H(n,d,4.0)Probability (%)CPU time(s)10021.55018060406 810 1214 16average degree18 20800.5600nodes6 810 1214 16average degree18 202040nodes20Figure 6: Probability satisfiability median CPU time (Hb 8/static/global heuristic (500 instances per data point)H n; d;Percentage points incorrect PCA answers A(n,d,4.0)4 0) using:Percentage points incorrect PCA answers H(n,d,4.0)PC-Failures (%)PC-Failures (%)0.60.5807060504030201000.40.30.21000.18060044068 1012 14average degree16 18nodes80604068 1012 1416 18average degree2020nodes20Figure 7: Percentage points incorrect answers path-consistency algorithm( 4 0) ( 4 0)n; d;:H n; d;:looking ( 4 0) case. almost instances phase-transitionregion many instances mostly insoluble region path-consistent, thoughconsistent.following evaluation different heuristics randomly generate instances average degree = 2 = 18 ( 4 0) case= 4 = 20 ( 4 0) case. covers large area aroundphase-transition. expect instances phase-transition region ( 4 0)particularly hard makes interesting comparing qualitydifferent heuristics.H n; d;:H n; d;n; d;::H n; d;:6. Empirical Evaluation Heuristicssection compare different heuristics running randomlygenerated instances. instances ( 4 0) ran 20 different heuristicsn; d;302:fiEfficient Methods Qualitative Spatial ReasoningNumber hard instances A(n,d,4.0)Number hard instances H(n,d,4.0)#Hard Instances#Hard Instances10987654321045040035030025020015010050010080604 68 1012 1416 18average degree2040nodes8060406 810 1214 16average degree18 2020nodes20Figure 8: Number instances using 10,000 visited nodes heuristic( 4 0) ( 4 0)n; d;:H n; d;:(static/dynamic local/global combined five split sets B Bb Hb 8 C8 Q8 )randomly generated instances size = 10 = 100. instances( 4 0) restricted instances = 80 regions largerones appeared dicult.first experiments found instances solved fastless 1,000 visited nodes search space using one maximal tractablesubsets splitting. However, instances turned extremely hard, couldsolved within limit 2 million visited nodes, 1.5 hours CPUtime. Therefore, ran programs maximal number 10,000 visited nodesstored instances least one different heuristics used10,000 visited nodes experiments (see next section). call instanceshard instances. distribution hard instances shown Figure 8. turnedheuristics using B split set heuristics using dynamicglobal evaluation constrainedness many instances hardcombinations heuristics. We, therefore, include Figure 8 hard instancesB/dynamic/global heuristic ( 4 0) hard instances heuristicsb dynamic/global heuristic ( 4 0).using B split set B/Figure 8 shows, almost hard instances phase-transition region.( 4 0) 500 instances per data point hard ( 4 0)almost instances phase-transition hard. Altogether 788 hard instances( 4 0) (out total number 759,000 generated instances) 75,081 hardinstances ( 4 0) (out total number 594,000 generated instances). Table 1shows number hard instances heuristic except excludedmentioned above. heuristics using Hb 8 split set solve instancesheuristics using split sets. Using C8 Q8 split set seemimprovement using B.b Among different ways computing constrainedness, staticglobal appears effective combination using one maximaltractable subsets split set. split sets, dynamic local also seems;nH n; d;;;;n:nn; d;:H n; d;n; d;:n; d;::H n; d;H n; d;:303:fiRenz & NebelHeuristicsHb8 /sta/locHb8 /sta/gloHb8 /dyn/locHb8 /dyn/gloC8 /sta/locC8 /sta/gloC8 /dyn/locC8 /dyn/gloQ8 /sta/locQ8 /sta/gloQ8 /dyn/locQ8 /dyn/gloBb/sta/locBb/sta/gloBb/dyn/locBb/dyn/gloB/sta/locB/sta/gloB/dyn/locB/dyn/glototal(n; d;4:0)644252100815878108815474104688970162163222209(303)788(4:0)21; 12910; 8269; 96724; 03828; 83015; 45732; 92641; 56524; 18913; 18913; 72729; 44823; 71113; 83129; 790{{{{{75; 081H n; d;H(80; 14:0; 4:0)331227217345373277412428346239255368344249379{{{{{486Table 1: Number hard instances heuristiceffective combination combining dynamic global cases worst choicerespect number solved instances.Figure 9 compare 50% 99% percentiles different heuristics( 4 0). give average run times since ran heuristics10,000 visited nodes reduces real average run time values. data pointaverage values = 8 = 10. took average different degreesorder cover whole phase-transition region = 8 instancessize = 10 = 10 instances size = 100. different combinationscomputing constrainedness, ordering run times different splitsets: B Bb C8 Hb 8 Q8 . run times using static/local, static/global, dynamic/localcomputing constrainedness almost combined split setlonger split sets using dynamic/global (about 3 times longerusing Bb split set 1.5 times longer using split sets).99% percentile run times 1.5 times longer 50% percentile runtimes. Thus, even harder among \normal" instances solved easily, i.e., aparthard instances, instances solved eciently within size rangeanalyzed. erratic behavior median curves results aggregationeffect observed Figure 5, namely, median elementsphase-transition inconsistent easily solvable.n; d;:n>;n;304fiEfficient Methods Qualitative Spatial ReasoningMedian CPU time using STATIC,LOCAL A(n,d,4.0)99%-Percentile CPU time using STATIC,LOCAL A(n,d,4.0)0.60.6B-splitB^-splitC-splitH^8-splitQ-split0.40.30.20.12030405060nodes7080900.210010Median CPU time using STATIC,GLOBAL A(n,d,4.0)2030405060nodes70809010099%-Percentile CPU time using STATIC,GLOBAL A(n,d,4.0)0.60.6B-splitB^-splitC-splitH^8-splitQ-split0.4B-splitB^-splitC-splitH^8-splitQ-split0.5CPU time (sec)0.5CPU time (sec)0.30100.30.20.10.40.30.20.100102030405060nodes70809010010Median CPU time using DYNAMIC,LOCAL A(n,d,4.0)2030405060nodes70809010099%-Percentile CPU time using DYNAMIC,LOCAL A(n,d,4.0)0.60.6B-splitB^-splitC-splitH^8-splitQ-split0.4B-splitB^-splitC-splitH^8-splitQ-split0.5CPU time (sec)0.5CPU time (sec)0.40.100.30.20.10.40.30.20.100102030405060nodes70809010010Median CPU time using DYNAMIC,GLOBAL A(n,d,4.0)2030405060nodes70809010099%-Percentile CPU time using DYNAMIC,GLOBAL A(n,d,4.0)0.60.6B-splitB^-splitC-splitH^8-splitQ-split0.4B-splitB^-splitC-splitH^8-splitQ-split0.5CPU time (sec)0.5CPU time (sec)B-splitB^-splitC-splitH^8-splitQ-split0.5CPU time (sec)CPU time (sec)0.50.30.20.10.40.30.20.100102030405060nodes708090100102030405060nodes708090100Figure 9: Percentile 50% 99% CPU time different heuristics solving( 4 0) ( = 8 0 = 10 0, 2,500 instances per data point)n; d;:::305fiRenz & Nebelruntime studies ( 4 0) noticed many hard instances40 (see Figure 8), = 80 almost instances phase-transition regionhard (see last column Table 1). Also, Table 1 shows, number hard instancesvaries lot different heuristics. Therefore, possible compare percentilerunning times different heuristics 40. = 80 = 14 (see last columnTable 1), instance, 50% 99% percentile element C8/dynamic/globalheuristic element no.36 element no.72, element no.141 element no.280Hb 8/dynamic/local heuristic (out 500 sorted elements), respectively.reason show results size = 40 (see Figure 10). Again,took average different degrees = 10 = 15 order cover wholephase-transition region. order run times different combinationscomputing constrainedness: B Bb C8 Q8 Hb 8, Hb 8 cases fastest.( 4 0) instances, run times dynamic/global much longercombinations. 99% percentile run times static/global combinationHb 8 Q8 dynamic/local combination fastercombinations. Although median CPU times ( 4 0)40, percentile 99% CPU times much longer. already shown Figure 78, evidence hard instances phase-transitionregion ( 4 0).H n; d;n >:nn >nn;n; d;;:n; d;:n <H n; d;:7. Orthogonal Combination Heuristicsprevious section studied quality different heuristics solving randomlygenerated RSAT instances. found several instances mainly locatedphase-transition region could solved heuristics within limit 10,000visited nodes search space. Since different heuristics different search space(depending split set) use different path search space (determineddifferent possibilities computing constrainedness), possible instanceshard heuristics easily solvable heuristics. Nebel (1997) observedrunning different heuristics parallel solve instances particular hard settemporal reasoning instances proposed van Beek Manchak (1996) singleheuristic alone solve, using altogether number visited nodesheuristic alone. open question Nebel's investigation (Nebel, 1997) whetheralso case hard instances phase-transition region.section evaluate power \orthogonally combining" different heuristicssolving RSAT instances, i.e., running different heuristics instance parallelone heuristics solves instance. different ways simulatingparallel processing single processor machine. One use time slicingdifferent heuristics, another run heuristics fixed random ordercertain number nodes search space visited unsuccessful try nextheuristic (cf. Huberman, Lukose, & Hogg, 1997). possibility chosenparameters (e.g., order heuristics run number visitednodes spent heuristic) determines eciency single processorsimulation orthogonal combination. order find best parameters, ranheuristics using 10,000 visited nodes heuristic set hard instances306fiEfficient Methods Qualitative Spatial ReasoningMedian CPU time using STATIC,LOCAL H(n,d,4.0)99%-Percentile CPU time using STATIC,LOCAL H(n,d,4.0)0.0455B-splitC-splitB^-splitQ-splitH^8-splitCPU time (sec)0.0350.03B-splitC-splitB^-splitQ-splitH^8-split4CPU time (sec)0.040.0250.020.0150.013210.0050010152025nodes30354010Median CPU time using STATIC,GLOBAL H(n,d,4.0)2025nodes30354099%-Percentile CPU time using STATIC,GLOBAL H(n,d,4.0)0.0455B-splitC-splitB^-splitQ-splitH^8-split0.0350.03B-splitC-splitB^-splitQ-splitH^8-split4CPU time (sec)0.04CPU time (sec)150.0250.020.0150.013210.0050010152025nodes30354010Median CPU time using DYNAMIC,LOCAL H(n,d,4.0)2025nodes30354099%-Percentile CPU time using DYNAMIC,LOCAL H(n,d,4.0)0.0455B-splitC-splitB^-splitQ-splitH^8-split0.0350.03B-splitC-splitB^-splitQ-splitH^8-split4CPU time (sec)0.04CPU time (sec)150.0250.020.0150.013210.0050010152025nodes30354010Median CPU time using DYNAMIC,GLOBAL H(n,d,4.0)2025nodes30354099%-Percentile CPU time using DYNAMIC,GLOBAL H(n,d,4.0)0.0455B-splitC-splitB^-splitQ-splitH^8-split0.0350.03B-splitC-splitB^-splitQ-splitH^8-split4CPU time (sec)0.04CPU time (sec)150.0250.020.0150.013210.0050010152025nodes30354010152025nodes303540Figure 10: Percentile 50% 99% CPU time different heuristics solving( 4 0) ( = 10 0 = 15 0, 5,500 instances per data point)H n; d;:::307fiRenz & NebelA(n; d; 4:0)Heuristics Solved Instances 1. Response91:88%19:80%Hb8 /sta/locHb8 /sta/glo94:67%12:56%Hb8 /dyn/loc93:40%24:37%Hb8 /dyn/glo87:31%13:58%C8 /sta/loc89:72%6:35%C8 /sta/glo92:64%5:20%C8 /dyn/loc90:10%5:96%C8 /dyn/glo86:63%6:60%Q8 /sta/loc89:72%9:77%Q8 /sta/glo93:15%12:06%Q8 /dyn/loc90:61%10:15%Q8 /dyn/glo86:80%12:82%91:37%1:40%Bb/sta/locbB/sta/glo88:71%1:27%Bb/dyn/loc91:12%0:89%Bb/dyn/glo79:44%0:89%B/sta/loc79:31%0:51%B/sta/glo71:83%0:25%B/dyn/loc73:48%0:51%B/dyn/glo{0:13%combined99:87%H (n; d; 4:0)Solved Instances 1. Response71:86%6:92%85:58%14:26%86:73%22:28%67:98%15:00%61:60%1:47%79:41%5:04%56:15%2:26%44:64%2:40%67:78%1:63%82:43%3:61%81:72%1:83%60:78%4:61%68:42%1:84%81:58%5:22%60:32%2:56%{1:83%{1:67%{1:13%{0:42%{0:49%96:48%Table 2: Percentage solved hard instances heuristic percentage first response orthogonally running heuristics. Note sometimes differentheuristics equally fast. Therefore sum 100%.identified previous section (those instances least one heuristic required10,000 visited nodes) compared behavior. Since ran heuristicsinstances already experiments previous section, evaluateoutcomes. led surprising result ( 4 0) instances, namely,788 hard instances except single one solved least one heuristicsusing less 10,000 visited nodes. Table 2 list percentage hard instancescould solved different heuristics percentage first responserunning heuristics parallel (i.e., heuristic required smallestnumber visited nodes solving instance). turns heuristics using Hb 8split set solve instances heuristics, alsooften fastest finding solution. Although heuristics using twomaximal tractable subsets Q8 C8 split set solve significantly instancesheuristics using B,b much faster finding solution. Despite solvingleast number instances, heuristics using B split set casesfastest producing solution.n; d;308:fiEfficient Methods Qualitative Spatial ReasoningFirst Response Solving Hard Instances A(n,d,4.0)First Response Solving Hard Instances H(n,d,4.0)20700Number solved instancesNumber solved instancesinconsistentconsistent15105inconsistentconsistent600500400300200100001101001000Minimal number visited nodes100001101001000Minimal number visited nodes10000Figure 11: Fastest solution hard instances running heuristics parallelcomparing minimal number visited nodes heuristicshard instances, found five (which inconsistent) required150 visited nodes. particularly remarkable instancesphase-transition region NP-hard problem, i.e., instances usuallyconsidered dicult ones. note 15% (120) 788 (pathconsistent) instances inconsistent, much higher usual (cf. Figure 7).Interestingly, inconsistent instances solved faster consistentinstances. point, noted combining heuristics orthogonallysimilar randomized search techniques restarts (Selman, Levesque, & Mitchell, 1992).However, contrast randomized search, method also determine whetherinstance inconsistent. Figure 11 chart number hard instances solvedsmallest number visited nodes respect solubility. Due low numberhard instances ( 4 0), figure left looks bit ugly one leastapproximate behavior curves comparing second figureright curve ( 4 0) (see below). oscillating behaviorinconsistent instances (more instances solved odd even numbervisited nodes) might due sizes instances|we generated instanceseven number nodes only. dicult instance ( = 56 = 10) solvedb static/global heuristic using 91,000 visited nodesinconsistent B/heuristics using one maximal tractable subsets split set failed solve evenallowed visit 20,000,000 nodes search space.examination set 75,081 hard instances ( 4 0). 2,640instances could solved 20 different heuristics using 10,000 visitednodes each. distribution shown Figure 12(a). Similar hard instances( 4 0), heuristics using Hb 8 split set successful onessolving hard instances ( 4 0), shown Table 2. solvedhard instances heuristics produced fastest response50% hard instances. significant difference using C8 Q8 Bbsplit set, neither number solved instances percentage firstresponse. Like previous case, computing constrainedness using static/globaldynamic/local heuristics resulted successful paths search spacen; d;:H n; d;:n;dH n; d;n; d;::H n; d;:;309;fiRenz & NebelFirst Response Solving Hard Instances H(n,d,4.0)Number hard instances H(n,d,4.0) using orthogonal combinationinconsistentconsistent#Hard Instances1008060402008060406 810 1214 16average degree18 20nodesNumber solved instances1008060402020020000400006000080000Number visited nodes100000(a)(b)Figure 12: Hard instances using orthogonal combination heuristic ( 4 0),(a) shows distribution, (b) shows fastest solution using100,000 visited nodes per heuristicH n; d;:instances solved within 10,000 visited nodes combinations.average produced faster solutions combinations.observations ( 4 0) made charting fastest solutionshard instances ( 4 0) (see Figure 11). 29% (21,307) solvedinstances inconsistent. were, again, solved faster consistentinstances. 75% hard instances solved 150 visited nodes.90% solved 1,300 visited nodes. Since Hb 8/dynamic/local heuristicalone solves 86% instances, seems dicult combine different heuristicsway hard instances solved using 10,000 visitednodes altogether. However, orthogonally combining two best performing heuristics(Hb 8 /dynamic/local Hb 8/static/global) allowing maximal number 5,000visitable nodes, solve 92% (69,056) hard instances.tried solve 2,640 hard instances ( 4 0) solvable usingorthogonal combination heuristics 10,000 visited nodes using maximalnumber 100,000 visited nodes. 471 instances still solvable,75% solved instances inconsistent. fastest response solved instancescharted Figure 12(b). successful heuristics giving fastest responseHb 8 /dynamic/local (42.5%) Hb 8/static/global (26.6%). three heuristics usingstatic/global computation constrainedness combined using Q8 C8 Bb splitset gave fastest response 15.9% solved instances Bb strategyfar best among three (9.4%).n; d;H n; d;::H n; d;:;;8. Combining Heuristics Solving Large Instancesprevious section found combining different heuristics orthogonally solveinstances using amount visited nodes heuristic alone solve.section use results order identify size randomly generated instances310fiEfficient Methods Qualitative Spatial Reasoningalmost them, especially phase-transition region, stillsolved acceptable time. Since many instances ( 4 0) already dicultsize = 80 (see Figure 12), restrict analysis instances ( 4 0)study randomly generated instances size = 100 nodes.instances large size allowing maximal number 10,000 visited nodessearch space much obtaining acceptable runtime. 10,000 visited nodesinstances size = 100 corresponds runtime 10 seconds Sun Ultra1,larger instances gets much slower. Therefore, restrict maximal numbervisited nodes order achieve acceptable runtime. Given multi-processor machine,different heuristics run orthogonally different processors using maximalnumber visited nodes each. orthogonal combination different heuristicssimulated single-processor machine, maximal number nodes dividednumber used heuristics obtain available number visitable nodesheuristic. Thus, different heuristics use, less visitable nodes availableheuristic. Therefore, order achieve best performance, findcombination heuristics solves instances within given number visitablenodes. chosen heuristics solve many instances alone, alsocomplement well, i.e., instances cannot solved one heuristicsolvable heuristic.started finding optimal combination heuristics set 788 hardinstances ( 4 0). empirical evaluation given Section 6 knowmany visited nodes heuristic needs order solve 788 hard instances.Therefore, computed number solved instances 220 possible combinationsheuristics using increasing maximal number visitable nodes heuristicstogether. Since tried find combination solves instances,computed quite fast. results given Table 3. showgood performance obtained maximal number 600 visited nodes.case four heuristics involved, i.e., 150 visitable nodes spent fourheuristics. Since combination heuristics (Hb 8/static/global, Hb 8 /dynamic/local,b static/local) also best 1,000 visitable nodes, chooseC8/dynamic/local, B/combination analysis. choose order processedb static/local according1. Hb 8/dynamic/local, 2. Hb 8 /static/global, 3. C8/dynamic/local, 4. B/first response behavior given Table 2. Note although two heuristicsb static/local show particularly good performanceC8/dynamic/local B/running alone (see Table 2), seem best complement two heuristics.find next maximal number visitable nodes spendheuristics. ran best performing heuristic (Hb 8/dynamic/local) instancesphase-transition region varying sizes. turned almost consistentinstances number visited nodes required solving slightly less twicesize instances inconsistent instances also path-consistent and,thus, solvable one visited node. Therefore, ran four heuristicsfollowing allowing 2 visited nodes each, size instance, i.e., togetherallow 8 visitable nodes. randomly generated test instances according( 4 0) model size = 110 regions size = 500 regionsstep 10 regions 100 instances size average degree rangingH n; d;:nn; d;nnn; d;:nnnn; d;:nn311:fiRenz & NebelMax Nodes Solved Instances100516200705300759400769500774600778700780800783900784110078513007863900787Combination HeuristicsHb 8-d-lHb 8-s-gHb 8-s-g, Hb 8-d-lHb 8-s-g, C8 -d-lHb 8-s-g, Hb 8-d-l, C8 -d-lbHb 8-s-g, Hb 8-d-l, C8 -d-l, B-s-lbbbH8-s-g, H8-d-l, C8 -d-l, B-s-lbHb 8-s-g, Hb 8-d-l, C8 -d-l, B-s-lbbbH8-s-g, H8-d-l, C8 -d-l, B-s-lb B-s-gbHb 8-s-g, Hb 8-d-l, C8 -d-l, B-s-l,b B-s-gbHb 8-s-g, Hb 8-d-l, B-s-l,bbbH8-s-g, H8-d-l, B-d-lTable 3: Best performance combining different heuristics solving 787 solvable hardinstances ( 4 0) fixed maximal number visited nodesn; d;:Probability satisfiability A(n,d,4.0)Probability (%)Average number visited nodes A(n,d,4.0)Visited nodes1001000900800700600500400300200100504 68 1012 14average degree16 18500450400350300250 nodes2001504 68 1012 14average degree16 18500450400350300250 nodes200150Figure 13: Probability satisfiability ( 4 0) (100 instances per data point)average number visited nodes path-consistent instances usingorthogonal combination four selected heuristicsn; d;:= 2 0 = 18 0 step 0.5, total number 132,000 instances. Since solvinglarge instances using backtracking requires lot memory, solved instancesSun Ultra60 1GB main memory.generated instances display phase-transition behavior continues onegiven Figure 5. phase-transition ranges = 10 0 = 110 = 10 5= 500 (see Figure 13). Apart 112 instances, instances generated solvable orthogonal combination four heuristics (Hb 8 /static/global,b static/local) spending less 2n visited nodesHb 8/dynamic/local, C8/dynamic/local, B/::n312:n:fiEfficient Methods Qualitative Spatial ReasoningPercentile 70% CPU time using orthogonal combination A(n,d,4.0)Percentile 99% CPU time using orthogonal combination A(n,d,4.0)CPU time (s)CPU time (s)100252015105080604 68 1012 14average degree16 1840500450400350300250 nodes2001502004 68 1012 14average degree16 18500450400350300250 nodes200150Figure 14: Percentile 70% 99% CPU time orthogonal combination four different heuristics solving large randomly generated instances ( 4 0)n; d;:each. Figure 13 give average number visited nodes path-consistentinstances. seen test instances average number visited nodeslinear size instances. percentile 70% CPU time instancesphase-transition size = 500 regions 20 seconds, percentile 99% CPUtime 90 seconds. size = 400 regions, percentile 99% CPU timeless minute (see Figure 14).131,240 test instances already solved Hb 8/static/global heuristic,71 instances Hb 8/dynamic/local heuristic required 577 instancesC8/dynamic/local heuristic produced solution. None 112 instancesb static/local heuristic.solved one three heuristics solved B/tried solve instances using heuristics, using maximal number 2visited nodes each. best performing among heuristics C8/dynamic/globalheuristic solved 87 112 instances followed C8 /static/global heuristic (83)Q8 /dynamic/global heuristic (63). 7 instances solved heuristicwithin maximal number 2 visited nodes.nnnn9. Discussionempirically studied behavior solving randomly generated RSAT instances usingdifferent backtracking heuristics make use maximal tractable subsetsidentified previous work. generated instances according two different models\general model" allows 256 RCC-8 relations used \hardmodel" allows relations contained maximal tractablesubsets. theoretical analysis two models showed model modelsmall average degree nodes constraint graph suffer triviallocal inconsistencies case similar generation procedures CSPs finitedomains (Achlioptas et al., 1997). turned randomly generated instancesmodels show phase-transition behavior depends strongly averagedegree instances. instances outside phase-transition regionHH313fiRenz & Nebelsolved eciently heuristics, instances phase-transition regionextremely hard. instances general model, path-consistent instancesalso consistent. Conversely, path-consistency bad approximation consistencyinstances hard model. instances also much harder solve instancesgeneral model.comparing different heuristics, found heuristics using onemaximal tractable subsets split set much faster deciding consistencyRSAT instances theoretical advantage given reduced average branching factorresulting exponentially smaller size search space indicates.using path-consistency forward checking method considerably reduces search spacecases. Nevertheless, using one maximal tractable subsets split set,particular Hb 8, still leads much faster solution solves instances reasonabletime heuristics. Although two maximal tractable subsets Q8 C8contain relations Hb 8 , average branching factor lower, i.e., usingHb 8 one decompose relations (256 148 = 108) using twosets (96 98 relations, respectively), Hb 8 splits relations bettertwo sets. relations decomposed two Hb 8 sub-relations, manyrelations must decomposed three C8 sub-relations three Q8 sub-relations.explains superior performance heuristics involving Hb 8 decomposition.Among instances generated, stored could solvedheuristics within maximum number 10,000 visited nodes search space orderfind different heuristics perform hard instances. found almosthard instances located phase-transition region manyhard instances hard model general model. orthogonally combinedheuristics ran hard instances. turned successful. Apartone instance, hard instances general model could solved,low number visited nodes. hard instances hard model muchdicult: many could solved heuristics. Nevertheless,many instances solved orthogonally combining heuristicsheuristic alone. Again, solved using low number visited nodes.Based observations orthogonally combining different heuristics, triedidentify combination heuristics successful eciently solving manyinstances used combination solving large instances. turnedbest combination involves heuristics use maximal tractable subsets decomposition. combination able solve almost randomly generatedinstances phase-transition region general model size = 500 regionseciently. seems impossible considering enormous sizesearch space, average 1039323 instances size = 500 using Hb 8split set.results show despite NP-hardness, able solve almost randomly generated RSAT instances general model eciently. neither duelow number different RCC-8 relations (instances generated according hard modelhard phase-transition region) generation procedure randominstances lead trivially awed instances asymptotically. mainly duemaximal tractable subsets cover large fraction RCC-8 leadnn314fiEfficient Methods Qualitative Spatial Reasoningextremely low branching factors. Since different maximal tractable subsets,allow choosing many different backtracking heuristics increaseseciency: instances solved easily one heuristic, instancesheuristics. Heuristics involving maximal tractable subclasses showed best behaviorinstances solved faster tractable subsets used. full classification tractable subsets gives possibility generating hard instances highprobability. Many randomly generated instances phase-transition regionhard using relations contained tractable subsetsconsist = 60 regions. next step developing ecient reasoningmethods RCC-8 find methods also successful solving hardinstances hard model.nresults empirical evaluation reasoning RCC-8 suggest analyzingcomputational properties reasoning problem identifying tractable subclassesproblem excellent way achieving ecient reasoning mechanisms. particularmaximal tractable subclasses used develop ecient methods solvingfull problem since average branching factor lowest. Using refinementmethod developed Renz's (1999) paper, tractable subclasses set relations formingrelation algebra identified almost automatically. method makes easydevelop ecient algorithms. indication empirical evaluationmuch effective (even especially hard instances phase-transitionregion) orthogonally combine different heuristics try get final epsilonsingle heuristic. answers question raised Nebel (1997) whether orthogonalcombination heuristics also useful phase-transition region. experimentslead much better results even simulating orthogonal combination differentheuristics single processor machine spending altogether resourcesone heuristic alone. contrast method time slicing differentheuristics, started new heuristic previous heuristic failed certainnumber visited nodes search space. order ran heuristicsdepended performance well complemented other,successful heuristics used first. similar using algorithm portfolios proposedHuberman et al. (1997). heuristics perform better combinationsuccessful one matter empirical evaluation depends particularproblem. Heuristics depending maximal tractable subclasses, however, leadbest performance.CSPs finite domains many theoretical results localizingphase-transition behavior predicting hard instances located. contrast this, basically theoretical results CSPs infinite domainsused spatial temporal reasoning. initial theoretical analysis shows, theoretical results CSPs finite domains necessarily extend CSPs infinitedomains. would interesting develop general theory CSPsinfinite domains, possibly similar Williams Hogg's \Deep Structure" (Williams &Hogg, 1994) Gent et al.'s \Kappa" theory (Gent, MacIntyre, Prosser, & Walsh, 1996).315fiRenz & NebelAcknowledgmentswould like thank Ronny Fehling assistance developing programs, MalteHelmert proof reading paper, three anonymous reviewershelpful comments.research supported DFG part project fast-qual-space,part DFG special research effort \Spatial Cognition". first authorpartially supported Marie Curie Fellowship European Community programme\Improving Human Potential" contract number HPMF-CT-2000-00667. preliminary version paper appeared Proceedings 13th European ConferenceArtificial Intelligence (Renz & Nebel, 1998).ReferencesAchlioptas, D., Kirousis, L., Kranakis, E., Krizanc, D., Molloy, M., & Stamatiou, Y. (1997).Random constraint satisfaction: accurate picture. 3rd ConferencePrinciples Practice Constraint Programming (CP'97), Vol. 1330 LNCS, pp.107{120. Springer-Verlag.Allen, J. F. (1983). Maintaining knowledge temporal intervals. CommunicationsACM, 26 (11), 832{843.Bennett, B. (1994). Spatial reasoning propositional logic. Doyle, J., Sandewall,E., & Torasso, P. (Eds.), Principles Knowledge Representation Reasoning:Proceedings 4th International Conference, pp. 51{62, Bonn, Germany. MorganKaufmann.Bennett, B. (1997). Logical Representations Automated Reasoning Spatial Relationships. Ph.D. thesis, School Computer Studies, University Leeds.Cheeseman, P., Kanefsky, B., & Taylor, W. M. (1991). really hard problems are.Proceedings 12th International Joint Conference Artificial Intelligence,pp. 331{337, Sydney, Australia. Morgan Kaufmann.Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraintsatisfaction: Flaws structure. CONSTRAINTS, 6 (4), 345{372.Gent, I., MacIntyre, E., Prosser, P., & Walsh, T. (1996). constrainedness search.Proceedings 13th National Conference AI (AAAI'96), pp. 246{252.Golumbic, M. C., & Shamir, R. (1993). Complexity algorithms reasoning time:graph-theoretic approach. Journal Association Computing Machinery,40 (5), 1128{1133.Grigni, M., Papadias, D., & Papadimitriou, C. (1995). Topological inference. Proceedings14th International Joint Conference Artificial Intelligence, pp. 901{906,Montreal, Canada.316fiEfficient Methods Qualitative Spatial ReasoningHaralick, R. M., & Elliot, G. L. (1980). Increasing tree search eciency constraintsatisfaction problems. Artificial Intelligence, 14, 263{313.Huberman, B., Lukose, R., & Hogg, T. (1997). economics approach hard computational problems. Science, 275, 51{54.Ladkin, P. B., & Reinefeld, A. (1992). Effective solution qualitative interval constraintproblems. Artificial Intelligence, 57 (1), 105{124.Ladkin, P. B., & Reinefeld, A. (1997). Fast algebraic methods interval constraint problems. Annals Mathematics Artificial Intelligence, 19 (3,4).Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8,99{118.Mackworth, A. K., & Freuder, E. C. (1985). complexity polynomial networkconsistency algorithms constraint satisfaction problems. Artificial Intelligence, 25,65{73.Montanari, U. (1974). Networks constraints: fundamental properties applicationspicture processing. Information Science, 7, 95{132.Nebel, B. (1995). Computational properties qualitative spatial reasoning: First results.Wachsmuth, I., Rollinger, C.-R., & Brauer, W. (Eds.), KI-95: Advances ArtificialIntelligence, Vol. 981 Lecture Notes Artificial Intelligence, pp. 233{244, Bielefeld,Germany. Springer-Verlag.Nebel, B. (1997). Solving hard qualitative temporal reasoning problems: Evaluatingeciency using ORD-Horn class. CONSTRAINTS, 3 (1), 175{190.Randell, D. A., Cohn, A. G., & Cui, Z. (1992a). Computing transitivity tables: challengeautomated theorem provers. Proceedings 11th CADE. Springer-Verlag.Randell, D. A., Cui, Z., & Cohn, A. G. (1992b). spatial logic based regionsconnection. Nebel, B., Swartout, W., & Rich, C. (Eds.), Principles KnowledgeRepresentation Reasoning: Proceedings 3rd International Conference, pp.165{176, Cambridge, MA. Morgan Kaufmann.Renz, J. (1999). Maximal tractable fragments Region Connection Calculus: complete analysis. Proceedings 16th International Joint Conference ArtificialIntelligence, pp. 448{454, Stockholm, Sweden.Renz, J. (2000). Qualitative Spatial Reasoning Topological Information. Ph.D. thesis,Institut fur Informatik, Albert-Ludwigs-Universitat Freiburg.Renz, J., & Nebel, B. (1998). Ecient methods qualitative spatial reasoning. Proceedings 13th European Conference Artificial Intelligence, pp. 562{566, Amsterdam, Netherlands. Wiley.317fiRenz & NebelRenz, J., & Nebel, B. (1999). complexity qualitative spatial reasoning: maximaltractable fragment Region Connection Calculus. Artificial Intelligence, 108 (12), 69{123.Selman, B., Levesque, H. J., & Mitchell, D. (1992). new method solving hard satisfiability problems. Proceedings 10th National Conference AmericanAssociation Artificial Intelligence, pp. 440{446, San Jose, CA. MIT Press.van Beek, P., & Manchak, D. W. (1996). design experimental analysis algorithmstemporal reasoning. Journal Artificial Intelligence Research, 4, 1{18.Williams, C. P., & Hogg, T. (1994). Exploiting deep structure constraint problems.Artificial Intelligence, 70, 73{117.318fiff fi"!$#%'&)(**#+ ,#.-/#0#1>2345'67(08**9:4!6;*<8*=#?A@CBEDGFH?AIJLKM?ONQPSRSJUTWVRYXZ@[T]\^?A_'`@aIb_'I@aT]TcRCVedf?gI`?AVihj?'NkcRaX]lSTmHnQoprq]s touwvHn]qyxxqz{n|qpr}Q}]q~~y]~y0 ~Q yy )a.$EQr'yG3$3)3 e$GrrG{)rHG)GY$3)3gr0C{rEQ )rG3'A]qyxGnQo)}]qyprxGno30Qy G7 g | yG 3a.$A^ {)Q C'3G3S'r){3)rar =A|{)3)$)rr0)rrAr ]' 7=WQ AAS GH{ G= $E U)==7;A ";3]'' H rr/r$ ";Ga3S0=a);=3' S= Ur A=r;" QS3GH rG$ "rGr) = Hr {=H Yr 0= UrS]{ = ]G)HU=)=|{U' U {=^A]{ 0H0"rGQ{QrS {=$ ]]$=g Q w;A = r={QUUQ3Gr3'G={=YGSG' e=' $ 0H=a=rfffiA!"#$&%('#)* ,+.-/0 )&21430576 698 : ;9)<$>=0@?BA9C#D E9F$0)130576 6 Gff )&HC9'F%0)I.;#9D#) C9E7JK0FL)&0C9)&07$MF$'N#O'FPC9)&'N9 #$KRQS'#T90UBVWE#X#$&%('#)* )&@T9)&K$TBFK#KKXDN)> C9E#+ZYH[,\L!G%,E#'7,#'#T9()&0C9)&>0 $) #T9'NQ^]F )& #W%,E#,$!E#W_9*7W)&0C9)&07$"K07;#MF97`a;#0#K0UVWE#"F>'NKF$'Nb9$&%0PD#) C9Ec$ME#'N)&P7#TdC9)<'N9 #$&S0)&]7"Fe7PDN7 $ff$'#' 7f'#)gE9 #T9#D;9#K0)&$Mh_7$&X_i)&0Fffjf U@VWE#O#$k%'N)>* P )<l#K0)&0h#D m_#DX;#Tn_oT9]70)&@ )&0FH)&'NQQFD PC9)<'NK>_#Dp+Z[HD ' $!91q305 5 r Gs$'tQST9K0F/T9FDN#' >+2A9E7%u?wvH$ME#0)&0135 5930GUVxE#d;#>!.;##c'F($ME#>d#$&%'N)*7L)&SE#0]Np'Ny' ]##D@$ME#tC9)&'N#0Qz'F7f0)&0#K US[)&D ON;9QS90){'F,FD 'N)&$ME9QdlE9] t0pT9] 'NCT|$'@!}tK07$pK'NQC9;#$O$ME#*FE#'N'#T~7JFK$ 17 QbC# #K_;#T9PC9)>;9#_#D9F>TtQS$ME#'#T9,+2 F0);#j"14305 576 G1'N)/$ME#,'N;9#T9TtK'##T9$>'#7J#DtQS$ME#'#Tm+.W'N)<]N$= 19A9;#0)QS'##T9$014?'#'NC90)1305 6 57Gff$K U"x'F%] 0) $ME#PFD 'N)<$!E9QS, )&H'F%+Z 0#>0q1H'##D41N?B F0);#j"1q305 5 7G%,E#0O C9C#Tt$>'PT90#K'N9#K$>T!"#$&%('#)* F+2WMGUn )<D #$&%'N)*7P9FK$FD 'N)<$!E9QS )&O_7$M)hK$M # 1"FS$ME#R)<;#)&@M;9QbQS#Dp'F] 0)S p7JC9'##0 $Fn_7)&D t#;9QS90)L'hE#T9T90n$MF$>0US[C9' >_# C9C9)<'NFKE$>'$MFK*7b$ME#lC9)&'N#0Q$'p)&'#)&$S$'Xo7)*F'F]RWE9FnX'N7$@W )&'R9F>T~QS$ME#'#T9_*h\L9#tA97QC#_#DB+2\{0Q |?\L0Qb q1g35 6F48qW0hf1ff35 5 GUHVWE#P C9C9)&'NhKENT9lFKK0;9)>F$)&M;#$P9;#$HP#$M)&0QS>'F%^K'N7] 0)&D 0#K UE (**=#|fiyfi96 Q 6 $0 ff] 3ff5' ff4!fiG!3Z6Ffiy){yy@$ME#LC9 C90)x%L%W2'NK0;#H'NO$ME#SQS0 7J4TX$ME#'N)&@9'#))&'F%TO.)&'#Q $MF$>>$K0FgQSKE9 7JK0U"VWE#H $!;#$>'#@90E##T$ME#>uQS$!E#'NT9$ME9F$(S#'#T9,W)&F$] O#0#$] P$>'lC9 )&$>K0;# )$$>_#D7L'F"$ME#S] F;#c'F"$P#DNEN'N)&01/9;#$P)F$ME#0)xT90C90#T9c'Ny$ME#)LQS0 7J]FF;#0UlVxE#c'N7J0)&]FF$'Ny0FT9L$'tbQC#t #TX'F2$0] 0)&FKK0;9)h$lC9)&'#KT4;9)&08"+fP '#)&T4 q1q\PE9 E9)7Q #21N 7*N*F'7_1?A97;#f1/305 5 GUgVxE#H$KE9#;#cNT9u7O$QF$L'hg$ME#PQS0 #x'Fe$!E#P;9#_#>$M 7$jJF$T@#'#T9, #T@F' >$QF$H'F$ME#PC9 )&$>$>'#S;9#K$'NqU"VWE#PQbFtFQw'Fg$!E#WC9 C0)W$'$M;#T9@C' %0)I;#gQS077J 4Ty$KE9#9;#ST4;#P$'-s!*0X+&30576 G1# #T C9C#@$W$'O(x0U-s!.*S#$>_hpC9)&'NC' TE#W$ME#'#)&tO$ME#LK'# $#$'FffMC#OD F01 E#0#KP$ W C9C#K0F$'N$'@ ' $=0Q 9ypFKE#_#t+."XMG+Z[,K*7 1qx_7$'Nq1q? A#&<#'F%W!* 21ff305 67 GL$M)hD#E $&2'N)&%W )<TU(V 'T9] 'NCpQd0 7J 4Tp$ME#'N)&{f'N)HWL'#$!E#l#S'F( X01q$LcQC9'N)<$M 7$,$ME9h$,%S$P;9CX) QS%'N)*Hb%,E#KEO9'7$MES$ME#H#$k%'N)>* /K0 ,$!;#T9TU "'7$ME X" #TtW K0 ,0bFT9j0)&0 $")<0F=0h$'N#"'Ffiff!\P) C9E#K0F4Qd'NT9 t+2\{XMGUbA#K$'NSH%(W)&]#%|$ME#T9 a#$'N#"'FX( #Ttx(F MC9KFqK0F>"'F\LX( #Tdf'N)>Ql;#F$>W$ME#,F>'NKF$>TtC9)&'N9 #$&T9$M)&9;#$'NF, ' $=0Qb 9\{_9#xT9>$M)&9;#$'NqUvL;9)LQbFp)&M;#$S )&SRA#K$'N9UlIX$ME#P>K$'Np-ff!*0 l C9C9)&'#FKEyPT90)<]7Tp)&'NQz] 7)&F$'N9FqC90)&MCK$] U:q$ ~T90#'7$,$!E#,C9 )&$$'Nd;9#K$'Nth'#K_h$T%W$MEb$ME#, ' $=0Q79T9$M)&9;#$'NqU VWE#@] )<_h$'N9F,C0)&MC9K$>]7K'N))<MC9'N#T9b$'X_7$M)&'#T4;#K#D|N$!)y] )& #@ #TT90)&]#_#DdK'N ]7;9#K$'N@'he$ME#>L] )& #PFW y;9C9C90)H9'N;9#Ty'NO$ME#S#DNF$] L' DN7)&$ME9Q'FcU"VDNE7$0##D'F$ME#W9'N;9#T@0FT9W$>'lPQd_#QS=0F$>'#C9)&'N#0Qw2'N)s%,E#KEO$!F$'N9 )&$&SK'N7JT9$'N#l7)&l' $MEX#KM )< #TXM;7}tK0 $H2'N)xD 'N9FffQS#Ql;9QUP[W$H$ME#c$MF$'N97)&C9' 7$L$ME#9'#;9#TRF$$Mh_#TUyVWE#K'N7] y.;9#K$>'#|QS0 $>'##Tm 'F] SK'NQC9;#$MF$>'#9Fi_7$M)hK$M # U2$LP C9C9)<' #QF$TX #TX$ME#P>$MF$'N9 )<$&@K'N#T9$'N#L'h"$ME#P C9C9)&'FNQh$L;9#K$'NX#T9c$ME#QS0 7J 4T ;9F$>'##0UR-s!*0 C9C9)&'NFKEnC9)&'F]NT9ty#$0Qh$Kt%Wp'F,$!)FK$M #R7C9C9)&'FNjJQF$>_#DX$ME#S;9#K$'N $'T9)&T 'N)&T90)&S'FLFKK0;9)FKn$ME9)&'N;#D#ERV/N'N)c0)&0U p@ME#'F% $ME9F$$ME#S C9C9)&'FNQh$'NO'N#$MF#TX A9 ;# $,F2U ,7C9C9)&'NFKE@H$ME#LM QSPh,$ME9h$('he$ME#a)&$W'#)&T90)C9C9)&'F#QF$'N_X-s!*0 P C9C9)&'NhKEqUHVWE#P#$0#'Ny'F(-s!*0 P C9C9)&'NhKEOP#' $HT9)&K$0U pC9)&'NC' @X#% hK$] F$'N7J#T90C0#T90#$tKE#0QS@9FTn'NnVg#'#)P>0)&dQd$ME#'NT9S$'XFKE#]7$ME#0U"I@A#K$'NOSC0)&QS07$W'NbMQF#$&%'N)*7"%0)&HK'N#T4;#K$TUVWE#HC0)&QS0 $>,ME#'F%$ME9F$$ME#c'N#$MF#TX C9C9)&'FNQh$'N#, )&L9;#$lh$$M)FK$>]7 Ug " !#%$j&#%'e$ME#yK$'N %>$M #MEBo.)7QS%'N)*n %,E#KEB' $ME X #TB(x@K0 9X$!;#T9TU#T9T|9'7$MEX"XP #Tn(xLK0 p0XFLT9j0)&07$P$&CL'F\{X01q$ME#ST9j 0)<0#K_#Dy$ME#LK'N9#K$>]#$& #T@$ME#L0#0)<D O.;9#K$>'#;#T@@K'#QC9;#$#Dt$!E#PC9)&'N9 #$k UIp$!E#C9 C0)c%(b%WW)&>$M)&K$P'N;9)<] S$'#9 )&i] F;#T~;9#$0(U p$ME#;#ST9 a#X\{$'@9cK'N#$#D@'F()4NTp#;9QS90)x'F"$'#KE9h$Kl;9#$0+U * FKEy;9#$PE9Fu7F>'NKF$TX#9 )&) #T9'#Q]F )& #,.-/ r 023 1t+Z'N) /N3 03L23 1 GfiU *"FKE@>$MF$574, 68/9, # 0:, ( 0;<;;0,>=1l'hsO\L E9FLF>'NKF$7ff>0#0)&D b.;9#K$'N? X19%,E#KE@L;#T$'ST9 a#c$ME#l ' $=0Q79OYL>$M)&9;#$'N> @A+" 4, GB6DC2EFH G JILK& ++&30GVWE#@T90#'NQd_9h$'N)NMff1/K0FT~$ME#@C9 )&$$'Ni;9#K$'Nq1 $ME##'N)QbF=0h$'Ni.hK$'N)LT9a#T56PO H G C EF H G JILK ;& +QRfi\ X"E90]7;9#$K0FT7ffME#T9T90? 419 #T ff>]N# t;9#$0U"VxE#W$MF$>(]7K$'N)i{4, K0 9H$ME#'N;#D#E $4441;'Feh,9#DOT9]#T9TX_7$'S$ME#PC9F)'h +2E#T9T90;9#$MGW7#T +f]N#l;9#$MG19'N) 4, 6 / 4 0 NYP;9)&#Dn'NC90)h$'N~C9E9F> 1]N#p;9#$> )&@K QCT1W$ME9F$S 4 6 4 1'N) 4, 6 /N4 0 4 1?;"VWE#T9$M)&9;#$'NXF>'NKF$>T@%W$ME@$ME#PE#T9T90X;9#$xf'N)$ME#LK QC9TXC9E9FcA+ ff44 Gfi6 C E F fi+ H G 4 G KH G K L;#TO2'N)Nff 720))&#D O$ME#L] F;#H'F"E#T9T90X;9#$0U%,E#0)& fi0+ 4 GB6 G GEFCGBE#0 HM;9#$>$!;#$T%W$ME= = =@+ g4, G 6 W3 r; , , 3 ,& ++2 G& +Q# Q##+ G#TF'L$ME#W)&>$M)&K$'N 6 0FffQC9'7T'Nc$ME#%DNE $>g$ME#%4*N#'F%,S "'##$MF#TUIc$ME#(C9 C0)/%(%Wa )<$M)&K $ff'N;9)&>]7"$'LHMC9KF KFff'F(xff%W$MES$!E#"2' 'F%W#DP0#0)&D;9#K$'N=4, B683@+ ffG"#/9,_e+!G" +<33 ,G9+&3 #3 ff+$G>G1+ZNG%,E#0)&% 6 &E # #,0 #T%'HPS;9#K$'Ny)&'NQO!;9#$)( 'F"$ME#l)<0Fg#T90#' $>T7+*L1$'S$ME#P7$0)&] h (+2r030G1 2U U 1@,(.-/*/0+.r0030G;p y%WPhM;9QSy$ME9F$1' 9FN$>K.;9#K$>'#qU VxE#0)&F'n$ME#)<$M)&K$'N 'N|%DNE7$; A#DNQS' TB #T #'7> J'N)O#$&%'N)*7t )&y$k%'p!;#KE MC9KFP#$&%'N)*7+2x0F216 r91j3254766 33)&MC9K$>]7 UWI@DNQd'305 57 G1#%W$MEhK$] F$'N.;9#K$>'##98"+!:4GB6 <;>=&?A@ #TB +!:4GBw#$&%'N)*7E:K0 b9, 7)&0F4#;9QS90)17%,E#L#'7> J'N) :W)&$!)&KC $DE C T$'Pu#'N7Jk#D#F$] 8#$ME###K'N#$!)F $HL07f'#)&KT7@2'N)&K#DO$ME#P%DNE7$u7#To#F>L$'t9#'N7Jk#D#F$] UFa)&'#QE#0)&S'N%,E#0#] 0)x%P)&!20)$'WH$W%'N;#T9L%x$!E)&!20)&0#KP$>'+fNGUF 'N)x_720)&0#KO$ME#SK0);#KF"$!E#_#D7L$'9]FF;9F$TR7)&EfiH #T cUlVWE# a)&>$L$>0Q )&;#)&M;9QQd_#DS $>0)QSff%,E#L$ME#W#N$ $0)Q)&9;#)&M;9QQS#DS = $0)>QS,+Z%,E#0)&H~ $ME#,#;9Ql0)'FgE#T9T90;9#$W #T@ $ME#,$>' $MF4#;9QS90) 'Fg;9#$MGU"VxE#,9C9)&'N# 2'N)"C97)&$$'Nd.;9#K$'N#)&SQS )cp9F$M;9)<d' $MEXX$!E#lK QbC9T| #Tp$ME#;9#K QCTmC9E9F> UVWE#'N#XT9j 0)<0#KL$ME9F$H$!E#lK QbC9TpC9E9FS$ME#SM;9QQbF$'N@L'F] 0)HE#T9T90p;9#$01q%,E#X$ME#S;9#K_7QC9TC9E9FH$W' ]70)"Fq$ME#L;9#$>0U"VWE#;#$ME9)&'N;#DNE#'#;#$($!E#u)&0QbF#_#DOC9 C90) %,%x$!F*S'N#t 'N;#$] h_;9h$#D ;[H,QS07$'N#TX 9'F] cK'NQC9;#$#%)&9;#)&P O9C9'N#07$F/M;9QQh$'N@'NC0)F$'NqUVWE#;#9FK$SK0FK0;#_h$'N 'F b_7$M)hK$M # URA9 QbC##D|9FT~QS$!E#'NT9'h 0)SXC9'7#%Wp'N;#$0U;#$@$ME#pQS$ME#'#T9 )&yK'NQC9;#$Mh$'N9F ]70)&|C0#] Uw[u#' $!E#0)@F$0)9F$] y$'n'N'N*2'N)OT9$0)QS#$K~ C9C9)<'NFKE#01L9FTB'N QS077J 4T^$ME#'N)< hFT9] '#K0F$TB +2-/$>0)&'N ?[L#T90)&'Nq1/305 6 8A97;#$uhfU 1305 5 G8L7C9C90XI? H'#T4)&DN;#= 1ff30575 6 GU"VxE#PQS$ME#'#T9uC9)&'#C9' TX+2-/$0)<'NP? [u#T90)&>'Nq1430576 98 L C9C0tJ? H'#T4)&DN;#= 1q305 5 67Gg )<7C9C#K0 #L$'P X01F%,E#LA9 ;#$LF2U +&305 K5 G GT9] 'NCTR>KE#0QSS%,E#KEXE9Fu0p C9C#Tp$'@9' $!EWP7#T X0U,VWE###$K$'N%Wg9cT9] ' $T@$'-s!*0 ,QS$ME#'#TBU pc $0#T@$>'$M;#T9O$014;9#T90)&$! #T@$,)&F$'N#%W$MEN$#DO$ME#'N)&,7#T C9C#@$W$'tx0UQMLfiy)ff! $ "ff]{yy&#%'HK07$ L C9C0 #T H'#T4)&DN;#=N+&35 5 6 GS7$M)&'#T4;#KT1W$'i$ME##0;9)h,#$&%('#)*pK'#QQS;9#$& 1C9'F%0)I;#u7C9C9)&'FNQF$>'# Qd$ME#'NT T4;#p$'|-ff!*09U $ME#@K$'N %%xPC9)&>0 $-s!*0QS$ME#'#TppOT9j0)&07$L% 1q'@$!E9F$L$LK0 p9bN$0#T9Ti$'W0U p%xF'@T90QS'N#$!)F$ 1F$0)$ME#,K$>'#@$ME9F$W-s!*0 uQd$ME#'NT@LQS'N)&LD70#0)Fq$ME9 @A# @ C9C9)&'#FKEqUfi ff )qWxGnYLa#lb#%B0#0)&D b.;9#K$>'#+ 4 0!G 6"$#&% 3@=#,+2 G2+ A##KP$!E#LT90C90#T90#KS'Fg]F )&'N;#x.;9#K$'N#x'N 4, 1'%B #T 4 x;#$L'N7]#'#;#019@%,E9h$"2' 'F%W%@%W,#' $tQS07$'Nn$ME#>Fc.;9#K$'N9hu )<DN;9QS07$0U @T9'$!E#O'X$ME9F$S$ME#@T90C0#T90#K'Ny' $ME#0)H]F )& #P!;#KEph(R7#T 4 >$M #T9L'N;#$PQS'#)&SK07)& U GRVxE#K'N))&!C9'N#T9#DC97)&$$'N;9#K$'N #TC9)<'N9 #$&yT9>$M)&9;#$'NX )& @. 6HG C E F) * 6 C E F+$G G+ GL$M)<0F$ F#$0)9F]F )& #0UVWE#,E#C#P;#W@#$0#T9#Dt$!E#P C9C9)&'NFKEO$'ST90)&] SQS0 7Jp4T~$ME#'#)&2'N)S W0U vL ;9) C9C9)&'NhKEnT9j0)&S)&'NQ $ME9F$b'Fd+2L C9C0~? H'#T4)&DN;#= 1c305 5 6 G1%,E#KE@T90 $> 4 %W$ME 19$ME#P#FH] 7)& #L_y m1#c;9h$'Np+ GUVxE#dQd' $] F$>'#@2'N)H9 )&#D #DX_+R7#T 4 7#T T9 # #DX$ME# ' ]7L;9#K$'N#PlhW2' ' %x0UZP$!E#@0#0)&D i.;9#K$'N t'FL$ME#@#0 )b2'N)Q@1 , 1"$ME#0 $ME#@K'N))<MC9'N#T9#D~C9)&'#9 #$&T9$M)&9;#$'N OFK$'N)&F21P+Z'huK'N;9)<'N#@K07~;#X' $ME#0)l.;9#K$'N#7#T~$H$ME#C9)&'#9 #$&T9$M)&9;#$'NiK0 X9d.FK$>'N)&FG1q #TpK'NQC9;#$!F$'N#LK0 X9bT9'N#S$M)FK$M7# UcVWE#tC9 )7QS$0),K0 c9$ME#'N;#DNE7$/'FaFff,E#'NQd' $'NC7uC97) QS$0) $ME9F$/MQS'#' $ME#P9)&#D ffc$ME#$M);#"0#0)<D H.;9#K$>'#$>'C#K$!;9)&F(iL#K0)&0hTy.)&'#Q r9ULV 'tD7$,$ME#S'N)<D7_9hg0#0)&D7@;9#K$'N.)&'#Q %S#T$'>$6B,r -+2 -/N3 0! 0/.0.1.321 04 63+26 GF4'#)K'N7] 0#0 $,Qb #C9;#_h$'Nq1q$Wu;#!;#$'bT9 a#P$ME#H;9#K$'Nq14 0 6&3@(+ !G%,E#0)&"985 676, : ; 6=<<5+25 G+&30r GA##K 5 4 1 $ME#HQS0 S] K$>'N)1F(C9E7N>K0h@QS'N)&WQS07#_#Dh.;# $ME9 4 1 $ C9C9)&'NC9)<_h$W$'LK'N#>T90)$,F )&P #T@$M)&0h$ 4 FH9#DtT90C0#T90 $H'N 5 4 UeV 'SFK$!F$LM;#KE@S$M)&0h$MQS07$"$ME#H2' ' %x_#DF!;9QC#$'NOuQbFT9 UQ1>firs]ypxou;o o)x3}4 U/Qxo QsjF4'N)S0hKE 4NT547#T ff1u+<30r GcK0 ~p;9#9;#~'7]7T~2'N): $ 6fiff + 5 4 0 GcT90#' $>$ME#X ]70)&'h+&30r GU BE#0 $ME#7] 0)&y;9#K$'N @;#T1($M)7#&f'#)QS$'c;9#K$'N@'F 5 4 7#T B@40 G G G+&3 30GVWE#;#+ 5 4 !0 G 6&3_ " K 5+&30 G%,E#0)& ,K'N#>T90)<T$'tlc;9#K$'N'F 5 4 1j #T ffUex' $L$!E9F$< 6 < ( < ff 6 3 < " 5 " < 5 < ff 6+&3G5<5< < 5<< <VWE#p)&F$'N#!E#_C 9$&%0 4 #T 5 4 1,Qd'N)&C9)<K> 9;9F$'N#R+&3r G1L+&3G1W7#T~$ME#X ]70)&$&J#$&|FM;9QC#$>'#q1P%(*##'F%,X #TpPK0FT|$ME#:qD 0#T4)<V/) #&2'N)QbF$'N|+$H'#K*20)1305 7 GUL07$M)F$>'@$ME#L$M) #&2'N)QbF$'N@L$ME#I ] 0)<$#$&RF!;9QC#$'NqUPVWE#S]FFT9$&p'F$ME#F!;9QC#$'N@F$ %63LWQC'N)&$M7 $2'N)$!E#L$KE9#9;#,T9K0;#>TX_$ME#PC9 C0)UIn$ME#79'F] @%E9] QFT9;#@'hu$ME#.hK$l$!E9F$ GG O$ME#@ ]70)&'h GG U~W0#Ky$ME#B6 r,- 2>14)&9;#)&0QS07$uQS07$'N#Ty_n+26 G $M)7#F$W$'< 6 B6 r -+2+&3NG5<0 )& 1 %,E#0O$ME#HK'N#$M)h_7$WH07f'N)<KT #T yHK0 ))<T@$>'3 1#%LD $ 6&3 _c UVxE#p ] 0)<'N 'F+&30r7G7$M)FK$! #p2'N) 6 r91H%,E#KE Q *Fy$yQC9' >#|$>'|%,)&$40 6+ 5 !G J(@+ !GM$ & *+nFD 09)FKOC9)<'Ni2'N) ff| #T|E#0#K\UffV 'K)&K0;9Qc] 07$S$ME#tC9)&'N#0Q@1"7p C9C9)&'F#_QbF$T9K0)&C#$'NO'he\B,9;#$,7t;##D$ME#xFK$"$ME9h$"$ME#H ] 0)<'NO'F(+&30r Gs(9;#$L$M)>FDNE $<f'N)<%7)&TF$ 6Br914 #T@9C9 #T9#D + 5 4 0!G" )<'N;9#T 6 r;##DV/N'N)xA#0)&0U[x$ %6Br91) * 6 3 C "#T@9;9F$'Nn+&30r G9K'#QSJHC+&30 GC3E"CVWE#L7] 0)&'N'Fe$!E#H9;9F$'NOK0 y9PK07))&T@'N;#$W9C#K$X$''##$MF 6+ 5 4 !0 r G 6 5 5 "B+&3 3 5 G9+&33 5 G5 6#E#T[H>'419$ME#LT9$M)<_9;#$>'#n+&30 G K0 y9L9C9)&TXF,c;9#K$'N@'h) * 6 5 H +&33 5Q!G#E H5 4 19OFK$'N)&F2'N)Q+&3MG Gfiy){yyVWE#L$M)>;9#K0F$TV/N'N) 0)<L C9C9)&'F#QF$'NO'F+ 5 !G40 640< <+ 5 Mr G>"Q#+&3G* *Lc;9#K$'Ny'F 5 4 #T ff147#T@K0 P]#%TpF,7@X$MEO'N)&T90)x C9C9)&'FNQh$'N@'F"\U :q$;##'F% K'##T90)S$ME#@)&;#)&0Qd0 $OQS0 $>'##T|_B+.6 GUXA#$$#D .6 3t>$M)FDNE7$&2'N)&%W )&TX$'QC#0QS07$0U(VxE#l)&9;#)&0QS07$01 6Br1 2'N)Wh f1K0 l C9C9)&'F#QF$O07f'N)<KT;##D+&3NGF6 < < 6Br -+2<5<5+&306 GVWE#H9;9F$'N#(7)&,;#TO$'P>$(;9Cb$ME#4#T@C9' 7$"9;9F$'N#0U"x0#K!2'N)&$MEb%W%W )<!f0)s$ME#0QFW$!E#PQS0 7J 4TX;9F$>'##0UVxE#W20F#$&y'Fg$ME#HKE#0QSLHOK'NQC9;#$#D$!E#PC9 )&$FqT90)&] h$] W'F"\^%W$MEO)&MC9K$$' pF($ 6rU,y$ME#PC9 C0)H%P%W")&$M)<K$H'N;9)&>]7L$'6 ;aVxE#l)&] 7 $L9C9)&'N#+2-s!*01305 6 8E9F$>$MFKE9 )&#NS?H0)&$ME#21g35 5 5 9G )&<<(8< 766 :< * *= M6 +$ 3 6 8 G+, 3 5 G 8:(8 8ff6&3 6M+!P3 6 G ( :ff "+&33 5 G5#* *(+&305 G+2 r G*ff9C9)&>'##Sf'#)S' $ME#0)cT90)&] h$] tK07|F'R9@T90)<]7T~~y$M)>FDNE $<f'N)<%7)&Tp%W U F4'#)l$ME#cT90)&] F$>]7u )<L$M)FK$M7# U F4'N)WxWK'NQC9;#$>_#DO$ME#c$0)QSxHC9)&'N#0QF$K 1q #T>''N#/f'#)&KTS$',Q *h";9)&$ME#0)/ C9C9)&'F#QF$'N#0U/W%~7C9C9)&'FNQF$>'#P>KE#0QS/$ME9F$/%(E9] T9]#>T%WePT9K0;#>TF$0)UV 'W]FF;9F$"$!E#"9;9 $>$>ff)&9;#)&TL2'N)q0 )##DL'N#E9F$'xK'NQC9;#$fi Uff:q$/;#gK'N#>T90)$ME#H;9#K$'Ne+ 4 fiG 6&3 + 5 4 003G 6%,E#0)& 5 4 ,#'S'N#D 0)W{)&,]7K$'N)199;#$$W(K'##T90)&T$'PL;9#K$'NO'F 4 ] 0O p+&3NGUx' $L$ME9F$+ 5 4 030G 5<x#Do+&3NG %(LD7$<6 <<6&3 <<"< &6 3 < + 5 4 030G<<< << 5 <V E#X)&DNE $OE9 #T~T9yO $!)FK$M # 1W9;#$OK0 |9X C9C9)&'F#_QbF$T ;#>_#DWF$T90)&] h$] u)<;#)&Ty2'N) 07)##D@K0 O$ME#;#,9cK'NQC9;#$T7@$ME#P C9C9)&'F#QF$'N>@%,E#0)&5 4< &6 3 < + 5 4 030G 3 < + 5 4 0030G<<<,S>' ;#$'N@'Fff$ME#PQS077J4TX9;9F$'N#01/+&306 GUQ63 U VWE#fi]q]qyqq q]s ]p&Qq]s;p/qz{nq]s3fiffqWxGnA9 ;#$HF2U +&305 5KG GC#'##0)&T$ME#S C9C#K0F$'Ny'F"QS0 7J4T$ME#'#)&t$>'tW0U @$!E#HM;9#K$>'#%@%W,ME#'F% $ME9F$b$ME#) C9C9)&'NhKEnK0 |0 F(a)&$b'N)&T90) C9C9)<' #QF$'Nn'h{-s!*0QS$ME#'#TU"V '$M7#ME$ME#,%PC9)&>0 $,b#%B] )<_h$'N9F/T90)&] F$'N'F"-ff!.* ,Qd$ME#'NTU]qfi|qyq)qeq]s |p&;p0qz{nq]s3fiffi$ME#SK$'Nn%t)&]#%A9 ;#$lF2U c%'N)* UVWE#RFT9'#C#$l@]F )&F$'N9h7C9C9)&'NFKE>@L2'N)Q;9#K$'N+Z%W$ME{N$!)W]F )& #MGs%,E#KES"x' %0)/9'N;9#Tdf'N) #TSKE#'#' $ME#] )<_7# 'LF$'PQhNQS=H$ME#;9#K$'NqUff[L C9C9)&'F#_QbF$T9$M)&9;#$'Nq19+ 4, 0 5 4 G1F"KE#' 0S%x$!EPC9 )> QS$0)] K$'#) 5 4 URVWE#C97) QS$0) 5 4 1"$M;9#T|>'p$ME9F$ 9+ 4, 0 5 4 GctFbK'7FC9' >#X$' ) + ff4, GUp[HQd0FM;9)&'hK' >0#t9$&%0X$&%'@T9$M)&9;#$'N#tL;#9FK*R: _#0)bT9$M #KOd;#>TU2$cT9 a#Tp9+ 4, 0 5 4 GX+ ?0 )G 6 9+ 4, 0 5 4 G9+2930G) + ff4, GVWE#54HGWKE#' 0@>'$ME9F$X+?0 ) GsLQS#QS=TU9+4, 0 5 4 GB69+BE#0 )=4, 0 5 4 GWKE#'70@$'LFK$'N)&F2192U UH5 +&3 3 5 G E H#+2 G#W$!E#l ' $=0Q 9OT9$!)&9;#$'Ny$ME#PL;#_9hK*y:q#0){T9$M #Kc$M *F$ME#H2'N)Q+%,E#0)&86@+ 4 G & +G%3+2 GF+ 5 4 G=3 5 G9+&33 5 GG+2FNG5x#Dt$ME#HFK$W$!E9F$ + ?0 ) G rS%LD $,c' %0)W'N;9#T'#@ @P3+2 GLQS#QS=T~%W$MEp)<MC9K$S$' 5 4 $'yD $P n;9C9C90)S9'#;9#TR'N 3@ cU@VWE#t]7K$'N) 5 4+ 5 4 GB60 ) G 6 ff""#+ 5"B+&3!"!##T9$0)Qd_#Tp7t>' ]N#DO$ME#Hf'7'F%W#DO$W'Fff;9h$'N#0U<6Br<5+2G GVxE#'N;#DNEO$ME#L C9C9)&'FNQh$'NO,%g*##' %HO_y$!F$$K0FC9E7NKH$>0)F$M;9)&@+2-ff )&2135 6 6 GF L$ME#O9F] Qd0 7J4TR$ME#'#)& 1gA9 ;# $PF2U C9C#K0h$'Np'h($ME#S$ME#'N)&y$'Wcd#% #T$>0)&$#D41"E#0#KO%t%xW)&!20)L$ME#@ ' ]7t C9C9)&'NhKEphP$ME#@A# p C9C9)&8 'NhKEqU@[ '#'N*pF$@+2FNGME#'F%W $ME9F$$ME#W C9C9)&'NFKEOE9FK'NQC9;#$MF$>'#9F920F#8$&@'N#O%,E#0+6K0 tLC9)<T@Fc;9#K$'NO'F 5 4 U F 'N)W01$ME#LK0FK0;#F$'N@'h 6 @+ /4, G x_7$M)hK$M # 14]70O%,E#0$c.FK$>'N)&F2UA9 ;#$LF2U M;#D $9C#' $#DFK$]FF$'N7JT90C90#T907$LK'N7] #$&C9)&'#C90)&$H$'T9] 'NC.;9)<$ME#0)C9C9)&'F#QF$'N#@$' U VWE#;#@'N#pE9F@$'n$MF'N)$ME#pA# C9C9)<'NFKEn2'N)O] )<'#;#FK$] F$>'#Q&%fiy){yy;9#K$'N#0Uc[up7C9C9)&'FNQF$>'#q1 :!: 1 LT9] 'NC9T|*F0C##D$&%'t$!E#_#D7L_iQS#T @t+&30Gx$LK' c0#'N;#DNEO$' #84 #TR+. G$Wud$M)FKC $M7#H;9#K$'N'F 5 4 UffVWE#0R+2KG G L C9C9)&'F#QF$T7<#*s] 0S%,E#0 5 4:!:<56+2 GC BrKE#' >0$'SQS#QS= 1 $!E#,9;9F$kb_p+. G/,F$$!F#Tjs #TO'N#j )FK$'N)&F2UffVWE#ff2' 'F%Wff)&'NQ^$ME# FK$ff$ME9F$X+?0 ) G6BrHje7#Tl'##Sj ) 6 #1# #TS$ME#FK$ff$ME9F$KE#' >0S$'lWFK$'#)&F2UeVxEN;#A# C9C9)&'NFKES9FT9;9h$W2'N)/'N#$!F#_#D b )#$M) )<K' >C9C9)&'F#QF$'Nb$'PP172'N)"cD 0#0)>F4T9$M)<_9;#$>'#q1 ) UffvL#L%WS'F' ]70)&K'NQS#DS$ME#T4)%,9FK*41L$'O$M)&0F$L!QFe#;9QS90)H'F] )<_7#chK$ #TX C9C9)&'FNQh$S$ME#l)&>$08q+ZN 7*N*F'7_O?'N)<T4 q1g35 5 598qA9 ;#ff? 'N)<T4 q1ff305 5 G7GU(Iy$ME#PC9 C90)H%P>$M;#T9-ff!*0 P7C9C9)&'NFKE@%,E#KEX;#V/0#'N)/0)& $'LD ] ,H#$0QbF$K%c'F 9;#T9#Dt )#$M)7)&SK' H C9C9)&'FNQh$'NS$'LcUb$ME#HM;9#K$'Nb%,%x)&T90)&] L-ff!*0 Qd$ME#'NTb)&'NQ {] )<_h$'N9FC90)&!C9K$] 147#TtME#'F%$ME9F$WA# 7C9C9)&'NFKELSMCK_hgK0F>L'Fs-s!.* L C9C9)&'NFKEqUq$WxGnSqpGoqyxoCyp& ;yzGxo |s|qy$ME#LK$>'#@%l)&T90)<]7d-s!.* PQS$ME#'#Ty.)<'NQb] )&F$>'#9FeC0)&MCK$] UPVWE#c_#9;9F$&N' 3@T90)&] TXy$ME#lC9)<'NK1a #Ty$ME#S$M #ME9QS07$L'FffK'N7] N$&@'F"$ME#S C9C9)&'F#_QbF$'N;9#K$'N%x$!Et)&!C9K$W$'c$ME#W]F )&F$'N9Fq]F )& #, )&H#% K'# $M)<_9;#$>'##,QFT9WO$ME#WC9 C0)UFa;9)<$ME#0)QS'N)< 10%"F'WT90Qd'N#$M)h$ff$ME9F$$!E#"A# P C9C9)&'NhKEHffMC9KF9K0hff'F4-ff!.* ffQS$ME#'#TU[HWA#K$>'# 9U c$ 9S)&0F/C9 ) QS$>0)"$!E9F$W$M *hW] F;#x.)<'NQ rS$'3 U :q$,;#HT9 a#$ yT90C90#T907$PC9 )&$$'N@ #TyT9$M)&9;#$'N;9#K$'Nq1*CGH E F H G JILK* H G JILK) * 6DC E F ** 6+2 6 G& +& +x' $L$ME9F$#6P^ #T ) 6 )#UeI $!)&'NT4;#K#D O#$0)9h )<0F] K$'#)* 6%,E#0)&+2 5 GHG*fffi ;CEJH^ HD ] 0@7o+$G7GU W#DO 0#0> L#9;9F$& 1* 6 ) * C E HCEH86 C EC C E C 19%LD $+ r G!!CEHGV/ * #DO' DN )&$ME9QdW'N@9'7$MEOT9,'hx+30G1#%,'N#$!F3 5' * |' .!4 19$u;#,)<%,)&$t+2 67G(h+930G+ Gx' $L$ME9F$x$ME#l)&DNE7$,E9 #TyT9c.;9#K$'Nu#' $!E#_#D@9;#$N3 (+ 4 0!GFWT9a#TXR+.5 GU".$,LF'%'N)&$MEy#' $#D@$ME9F$L$!E#dQd' $] F$>'#@2'N)HT9a##DX$ME# ( ;9#K$'NXK'NQSPQS;#KEXQS'N)&S9F$M;9)FE#0)& UQfi4f g$ME#L7] 0)&$#$&XFM;9QC#$>'#@E#' T9W$ME#0O%LK0 O;#T90C0#T90 $H'N 5 4 G #T)&%H)&$t+ GF3@ *54F$ME#L#T90C0#T90 $L] K$>'N)L+Z%W$ME40+ G+ 5 !G%,E#0)& PFHT9a#Tn_|+&3730GULVWE#LD ] PO] 7)&F$'N9F fff$>'-s!*0 PQS$ME#'#T @H$M)&0F$ 5 4 F#$0)9F]F )& #S] K$'N)x #TKE#'N'7L$,$'OQS#_Qd= U2$WK0 y9{ .;9)&$!E#0),C9)&'F] T@$!E9F$ LK'N7] @;9#K$'Ny 5 4 ULV '@S$ME#LT9 a#$ME#SW>_7X'F F 6 ;qYLj0)&07$F$'N'F,+&30r G %W$ME@)<MC9K$H$' 5 4 1N#T96cv+ FNG%,E#0)&8988v 6 6 , , 3 6 ,6,+ G#DbK' ]F )& #KtQbF$M)&q1 PC9' $] b0QST9 a#$U *ff9;9F$'N|+ F#GW0#M;9)<L$ME9F$L9' $MffE#T )&P#'#7J#DN;# )UW0#K ,C' $] ST9 a#$PQC###D@$ME9F$ HK'N7] qU[HST9K0;#T _ A#K$'N79U 1g$!E#@T9 }OK0;#$&|n ]70)&$#D +&30r7GH2'N) 6 rX)&0QbF#t #Tn' ] Tp7@$ME#lV/N'N)x0)&P C9C9)<'NFKEFHT9K0;#Tpy$ME9F$HK$'NqULf"%(S;#S$ME#+a)<$,'#)&T90)C9C9)&'F#QF$'NO$ME#PA#7 C9C9)&'NFKEbH'N#$Mh_#TU F4'#)6371N%PE9]# + 5 !G40 6%,E#0)&40 6+ 5 Mr G.hK$ fi#=+ 5Q#5'F] 0)&$Qh$$ME# ;9#K$'N3@' *86: ff%40+ 5 !r G ""^+&340+ 5 G3 5G_+<33+G G5;GG40 ;+ Gfi # + 5 !GV @' $ME#+.F'@+2E9F$$MhKE9 )<NNO?H0)&$!E#f1 305 5 57 GGH#' $S$ME9F$H;9h$'N~+ 7GWK0 iF'9c $0)>C9)&$T$0)QS'Fff$ME#LT9] 0)&D 0#K$k%0O$ME#c$&%('cT9$M)&9;#$'N#01 ) * 7#T ) * 1 $ME9h$(X+ ) *[H>'#' $>_#Db$ME9F$0 ) * GB6GH) *) * 6 _ *)*" +540) * )) * * 6 * " fi # + 5 4 0!GHGX+ ) * 0 ) * GB6 ) * _ ) * 6 fi # + 5 4 0!G 3 + 5 4 0)*HGX+ )*0 ) * GB6+ 6 GG+ 5 GG+ZNr G#T;##DO$ME#LFK$$ME9F$x$ME#LT9] 0)&D 0#K LF%#,#'N7Jk#DNh$] t+ G H'N#$MF#TU[x$ %63# + 5 4 0030G 6 + 5 4 G+Z430G%,E#0)& #W$ME#H'N#&K$] H;9#K$'NO'N#$MF#T7A#7t C9C9)&'NhKEq8#t+2hNGUgx' $H$ME9F$WF$ %63 1+ 7G">$M #ME#L$ME#P#9;9F$k|+2 G @$!E#lA# C9C9)<'NFKEqU"2$H,$ME#;#WK0 )&y$M #ME#TX$ME9F$QQfiy){yyA# C9C9)<'NFKEOL a)&>$,'N)<T90)W C9C9)&'F#_QbF$'N@$>'t-ff!*0 L C9C9)&'#FKEqU#KT907$MFp(7)90)H #T] 7@T9P: 7)P+&305 575 G"F'@)&T90)&] Ty$ME#PA# @ C9C9)&'NhKE@7;#>_#D@SK0;9QS;# 7$,9C9 #'NqUx#D+ 6 G14+ 5 G1q+ZNr G1 th$>0)9F$W72'N)Qh$'ND7'NQS$M)&KHT90)&] F$>'#'Fff-ff!.* WQS$ME#'#TK0 c9K'N#$M)>;#K$TUffVWE#] )&F$>'#9FNT90)<]FF$'NSC9)&07$TE#0)&WF'LE#C#ff_d$M #ME##DP9*%W$MEy' $ME#0)L)< a#0QS0 $>L*F@V [u-B7#T#0 )c)&MC9'##K'N))<K$'NqU F 'N)HOT9$MFTpT9K0;#'N'Fff$ME#,C9'7_7$L)&!20)$'+2E9F$>$MFKE9 )&#NP?H0)&$!E#f1q r r7r91q305 5 5 9GUWq]s' fi;p0o qyxo Qs$]pv+!*0 Qd$ME#'NT T9K0;#T$ME#@K$'Nq1WQS077J4T $ME#'#)&p2'N)xt @T9] 'NCTB;##Dm-s#|$ME#XC9)&]#'#;#tK$>'##0U/F 'N)x0FKE., t7`a;#0#KT 7 &E # , " 1%,E#KE K09O]#%T|F+4T90UXVWE#@QS0 7J4T~ C9C9)&'F#QF$'NX$!E# 0pM;# D7D $L $M E9h$P$ME#@C9)&'N97#$K4T9,QtP)&0C#FKT b$ME#)WQS0 b] F;#01$ME9F$" &E # # 5 " ;H0C##DO$ME#_@Qd_#T1-ff!*0 QS$ME#'#T FT4 C#$>T $>'|T9] 'NCBQS0 7J 4T^KE#0QS @2'N)O( x0UIBA#K$'NP9Ujp%M;#D D7$( b C9C9)&'FNQh$'NQS$ME#'#TO%,E#KEbK0 u;#TO$'cK'NQC9;#$,hq$ME#x;9 7$$W)&9;#_)<T2'N)LQC#0QS07$#DR-ff!*0 d7C9C9)&'NFKEqU@vL;9)P C9C9)&'#FKEoS9;#$tD70#0)F(7#TRT9'#l#' $cT90C90#T'NO$ME#{f'#)Q 'F"FK$] h$'NO;9#K$'NqU F4'N)'7$ME#0)WFK$]FF$'N@#T90C0#T90 $S C9C9)&'NFKE#,)&D# )&T9#D$ME#S C9C#K0h$'Ny'FsQd0 7J 4T$!E#'N)&O$'(xH+2H2$019W'h.Q79q14? V/)&MCq135 5 5989H0 )#L?A9 ;#21q305 5 67GUgA##KH2'N)"!(#$&%'N)*{'NC90)h$'N% $"$>'t3 17%(H%WqT4)&'N$C % )&'NQ h.;9)<$ME#0)9;9F$'N#0U' Qs q$WxGnz{n]vq-ff!*0 lQS$ME#'#T1ffFlC9)<0 $>TpRA#K$'Ni41 #' $cT9)&K$R;#!;#ff2'N)Px01gK0 ;#O'FW$ME#$!)FK$M #$&R'FH$ME#C97)&$FT90)&] F$>]7tF$$.6 r9UXV'X'F] 0)&K'NQd$ME#tC9)&'N#0Q@1 %t!;#D $nQS$ME#'#T 9hT~'N V/N'N)S>0)&@C9 #>'#qU VWE#@p] 0)<|D 0#0)F,Qd$ME#'NTB #T #' $T90C90#T907$H'NO$ME#PFK$]FF$'Nb;9#K$'NqU(VxE#HQS$ME#'#T@09 #,K0FK0;#F$'N'FeF$!E#P#KM )&$0)Qd,)&9;#_)<T@2'N) N$0#T9#D-s!*0 ,QS$ME#'#T@2'N)WU: $,;#WT9 a##%B0#0)&D7;9#K$'Nfi0 4, 0 5 4 0 4 GB6&3ff + fi@%,E#0)&Prfi=3 1#+ figGB6 E&#T##6 E&ff + fiA##KfipW$!E#,QC'N)&$M 7$WC9 ) Qd$0)1#' $Mh$'N9FqK;9QS#0UWx' $L$ME9h$B683ff +2r G=#/9,3 ,_e+ + figGG>"^+&3/2,_e+, 3 5 G"fi(+##5 "G9+&3 #3 ff+ + figGG1;0 4, 0 5 4 0 4 G %Wg9P)&!20))&T@$>'dhG" +<33 ,+ZN GG9+&3 #3 ff+G1ff + figG 'F$'] 'fiff +&3G+6#TT9a#;>pt;#@V/N'N){0)& C9C9)&'FNQh$'NX'FB6ff + fi/Gff +2r7G "ff #1 $ME#0%LK0 O%,)&$Z ff C9C9)&'FNQh$6:q$,;#L#'F% T9a#l$!E#Hf' 'F%W#D;9#K$'N+fiB0 fi0 5 4 G 6 3_< <#ff +&30Gfffi*fiff + figGL%W$MEi)&MC9K$S$' fi"U@:q$;#+Z NGCG E F JH "+Z G;ff +&30G*;ff ;5+ZN G5 4 0 fifi0 e1%,E#KE@ )&H'N#$MF#T7 ] 0)<$#Dl$!E#W2' ' %x_#D+Z G G5 6 , ) * -V E# )&,hM;9QSTO$'9H;9#K$'N#'FW9;9F$'N#@HG%,E#0)&C E F * ff ; H HGCE F)* 6*ff ;+Z Gff ff _n+ZN G %L'N#$Mh_)<0C#_hK_#D w+fiB0 fifi0 5 4 GB683@CG E F*Hff ;5" K+ZN6 Gff 7 ff ;Nd]N% 'F(+Z NG/'##WK0 SK'N#>T90)%,E#0)&x$ME#WT9a#$'NO'F 5 4 'N#$!F#Tt )&0C#FK#D ^F, @ C9C9)<' #QF$'NO$>' ;4VWE#H'N#0)&]FF$'NM;#D $>7@ C9C9)&'FNQh$'NO$' Ufi+ B0 5 4 BG 6 3+ 03 0 5 4 G 3+ 03 0 5 4 G+ZN5 GVWE#0$ME#PQS0 7J4TX;9h$'N#WK0 y9L$Mh$TF6 < 6 <<5<5<#< 56Br#+2 r GVWE#P)&9;#)&TX$0)QSW#T9TX@$ME#PV/N'N)C9 #>'#@'F yK0 @9S C9C9)&'F#_QbF$T74 0 66 <+2r003+ 5 !r G<<* *<0 5 4 GB6* *+2r03<<#0 54 G* *#VWE#S#D7D $,FT9]F 7$MFD Ly%'N)*7_#Db%W$ME )F$ME#0)$ME9 H$ME9F$W$!E#lC9 )&$>_hT90)&] F$>]7,'F%W$ME@)&MCK$,$' F$ %6Br #Tfi 63LK0 @P9C9)&TXF;9#K$'N#,'h 5 4 ; iPT9a#40 6ff + 5 !G+ 5 4 M0 r G>"#<<* *+2930G#fiy){yyD#E $H'Fg$ME#S 9'F] HT9K0;#'Ny'N#cK0 OK'N#T90)ff+2 G#TE#0#KS$ME#PQS077J4TX9;9F$'N#WK07@9P>$MF$TFff6 < < < 6Br<5<5<5+2 GV 'T9] 'NCnO2ff2'N)L$!E#t C9C9)&'F#_QbF$'N#P$;#PK'##T90)P$!E#K0FO%,E#0)&'N)&T90)K0F UEHK0h/$ME9F$WF$, 6Br1N$!E#LT9>$M)&9;#$'Ny,D ] 0y) fi * 6 5 H +&33 58G&#86371$ME#Na)<$E H ;)+ff3ff +2r G<766"+2FNG::*fi<<:$ME#,$>0)QSK0 O9LK'NQC9;#$>TFWL;9#K$'NO'F 5 4 U"VWE#L C9C9)&'#C9)&F$L9C9)&'N#,7)&,T90)<]7T<*#676 ff+&3G#*[H| C9C90#T9 LU/[,$ME# ' ]7t$0)>QSSK0 |9;#T|nK'NQbC9;#$#DR | C9C9)&'F#QF$'Ni$'x#Do+230G %(L'##$MFff#+ 5 4 0!G6+5VWE#;#,;##Dp+2 G %PE9]4068!r G>"ff +2r G# +fiG3"Q#:<<fffi* : ffff #<5+2G G6+2 GrVWE#4#TC' $H;9h$'N#,$!EN;#W'##$MF#T )&5 638 fi fi 6ff +.r G8:"#3< <fffi* :U+2 Gff # +fiGVWE#PQS077J4TX9;9F$'N#L )&L'N#$!F#T ;##D+. G $'D $<#+2 6 Gx' $@$ME9F$S$ME#@>KE#0QSX)&M;#$#Di.)&'#Q 6S3 C9C9)&'NhKEnK0 |h>'R9y'N#$MF#T|)&'NQ X!FT9T9C9'7_7$t C9C9)<'NFKEq1+.(E9h$$MFKE9 )&#N@? H0)&$ME#21H305 5 57 GU [K'N7;#'N|QSDNE7$ )&)&D# )&T9#D$ME#c_7$0)C9)<$MF$'N'F VWE#c] )<_h$'N9F/T90)&] F$'NXQSDNE7$H$0QC#$W'N#c$'@9] $ME9F$x#Kn;9C9C90)'N;9#T|$7' 3@c1(7#Tn C9C9)&'FNQh$'Nn$' 1ff$ME#0tF'p;9C9C90)L'N;9#TULA9;#KEX )<DN;9QS07$, )&S#' $HK'N))&K$0UW.$,LT9j}tK0;#$L$'O$M #MEy%,E#$ME#0) K09bK'N#T90)&TRFL X;9C9C90){'N)x'F%0)L9'#;9#TXf'#),OD ] 0#T tULIy.hK$,] 02'N)6 91'N#LK0 yF$WQS' $xM ( 4 # 1 +.(E9h$$MFKE9 )&#NS?H0)&$ME#21/305 5 5 9G1 2'N)SD 0#0)>F ;i(7$0)C9)&$ F"HK' , C9C9)<' #QF$'Nc$' F"x;9#K$'NS'h 5 4 ; f$ME#W C9C9)&'FNQh$'N#)&@K' >0#'N;#DNEn$!E#0|$ME#@DN)>FT90 $Ql;#>$tF'R%, C9C9)&'F#_QbF$T~7 %,E#KE;#$QF$@0FT9H$'+&36 GU/[ >_Qd )x $>0)C9)&$MF$>'# C9C#,$>' ff ;Rfi[ C9C#K0F$'Ni'F,-ff!.* SQS$ME#'#Tp$' 7X$'#KE9F>$Kl>N$>0Q@12U Udf'N)L7 O1)&l'#X$ME#L] hT9$&~'FL$ME#y_7] 0)&$>_#$& hM;9QC#$'Nn%HE#KE T90C90#T9@'Nn$!E#K'N7] 0)&D 0#Ky'FL$ME#Vg#'N)0)&9C9 #'Ni'F 4ffU@X'N)&O_QbC9'N)&$! $>i$ME#)>FT9;#l'h,K'N7] 0)&D 0#K BpE9FS$'Mh$&fBB3t+2-s!.*91g35 6 GUff.$,H$e O'#C90y;#>$'N@%,E#$!E#0)$ME#l)>FT9;#,'FffK'N7] 0)&D 0#K{f'#)$ME#0#0)&D b;9#K$'N@T9K0)<_TX_|+Z#G"'#)"n+Z G MF$> 4,$ME#WK'##T9$>'#qUff&'RfiffHfi 4{$ME#g>K$'NL%(7C9C#L$!E#"] 7)&'N;#e7C9C9)&'FNQF$>'#LKE#0QS/T9] 'NC9TSL$ME#C9)&]#'#;#gK$>'#$'n$&%('nT9j0)&0 $yKF@'F#$k%'N)>* 01W97QS $!E#>D#QS' #$&%'N)*nT9a#T 7~$ME#XDNQd'FK$]FF$'Ni;9#K$'N| 8"!+ :4NG 6 #<;>=&# ?A@ 1"7#T|$ME##' 7J'N)#$&%'N)*XT9a#T p$!E#FK$] F$>'#;9#K$'N B$+ :4G 6z3 301: r ;aIX$ME#lC9 C0)L%S%W()&$!)&K$P'N;9)&>]7L$'@$ME9)&T9j0)&07$2CCEC9C9)&'F#QF$'N KE#0QdE90]##D|$ME#'##kK$>]7;9#K$'N# ff ## 0 ff #( 0 ff (0( ;2$O@_7$0)&>$#D~$'K'NQC97)&L$ME#P C9C9)&'F#QF$'N#2'N)>D#QS' T4FgxuFxT90)&] TR+.A9 ;#$,F2U1 305 5 G G %W$MEO$!E#''N#$Mh_#TpE#0)& ULvxWC9 )&$K0;# )H $>0)&$L ff #( ;qVWE#+4#TRC9'7_7$H;9F$>'##P)&M;#$#D@)&'NQ $ME#'N#&K$] H;9#K$'N7)&5 66&3Wr; 8 +8 fi3 8"+G+&3 #=";#/+ 5 33 8 +GGW+&3 RGG "8"+G>G E##(513 5+<3+2 5 GG>"3+&3 R(5 G+$G r GZ 4 2$ME#0 6wr;q[LC9C9)&'FNQF$>'#@2'N)HDNQd' T4F"WPFLT90)<]7Tp~+2A9 ;#ff$PF2U1ff35 5G G9E FW$!E#Hf' 'F%W#D4#TC' $H9;9F$'N5 68 fi"=;Q#/+ 5 3 G"1+$G930G%,E#0)&PhDNF 6Br@19j 4/2>8F<;#>$W_*h+$G r7G1 ,h>'T90C90#T907$L'N 5 1!>63 0/.0./.0 3 3 UVxE#9C9)&>'# #@2'N) +.)&!f0)O$>'mA9 ;#L$XF2U1P35 5Gof'N)O9FK$@9C9)&'N#!G@'N'#*|] 0)&T9j0)&0 $ )&'N"Q ;9.$Qb0,$>gC' #P$!E9F$(#;9QS0)&K0F@$ME#tQ9H] 0)&bK'7 U"bFK$$ME#cQS_7)&$ky@$M)>;#K$M;9)&L|+2 5 G #T|$+ G930G L%'N)&$MEO#' $#D41q #T9C90)<_Qd0 $Mhe)&!;#$>,ME#'F%$ME9F$HF )F, C9C9)&'F#QF$'N'Fe^D7'NW$!E#t#TXK' S)&M;#$0U2$HuC' #S$ME9F$$ME###T 8"+ GWC#0O$ME#cM QSP)&'7 U vL#PK0 @)&!20)$'X+2A9 ;#? '#)&T4 q130575 5 Gsf'#)(dT9>K0;#'Ny'N$ME#LC9' 7$0U"2$xLQh$$0) 'F/.;#$M;9)<L$M;#T9O$' ]7$DNF$L$!E#P 9'F] P)&F$>'##ME#C#L_T9$MF2U$ fi ff&%;ypo sxq(' x/V 'R$>$$ME#7C9C9)&'FNQF$>'#|KE#0QSOT9] 'NC9T A#K$'N591(#;9QS0)&K0FH9C90)&QS07$@%0)&K'N#T4;#K$TUffA9Qh9x$k%'N)>* q%0)&ffKE#' 0L>'W$ME9F$pK07P9 K'NQC9;#$TS L9FK$0#;9QS0)h$'NqUF4'#)lh$ME#@9C90)<_Qd0 $b$ME##$&%'N)*o$'NC9'7'7D p%WF+4#T~$>')i)#G98 4DN;9)<3 UpVxE#KE#' KP'Fg$!E#P#$k%'N)>*S09 #u;#H$'SK'NQC97)&L$ME#P)&M;#$x%W$MEO$ME#' L'hsA9 ;#q$,hfUZ+&305 5 G7GUgV 'K'NQC97)&$ME#tC0)I2'N)Q #Kb'FW'N;9)LQS$ME#'#T9P%W$MEi$ME#)PQd$ME#'NTn%)&0C90F$>TR$ME#bC0)&QS0 $MLfiy)@{yy+2#)@ )+G G %W$MEO$>'NCOT9'F%,tC9)<'NC9FDNF$>'#'F"9!20U(VxE#PFK$] F$>'#.;9#K$>'#@%WFKE#'70O$'tP'N#L'FffDNQS'7TX #T#' 7J'N)UFffDN;9)&3 HVWE9)&H070)WK'N#T4;#K$TO c$ME#0Q 2'N)/DNQd' Tdx0U30r0!r r rW#$&%'N)*7%0)&D 0#0)F$>Td7l)> #T9'NQSPKE#'#' #D%DNE $L]FF;#P 3L3003 UHVWE#9' $>$'NQ _ 0)L;9#$1'N)x$ME#S]N#;9#$L'F0FKEX#$&%'N)*O%WF#$M 7$F$Ti$'@=0)&'4UVW E#b*FE#'#'NT1 c1%WFLK'NQbC9;#$TR79FK$P0#;9QS0)F$>'#X'Fh $ME#$Mh$,X$!E#dE#DNE#0){$&%('O 0)&0UPVxE#t C9C9)&'F#_QbF$P]FF;#'F+3@ %h,K'NQbC9;#$TR7 ff 85 4 SK'NQbC9;#$TR7>' ]N#DX$ME#N 4#TmC' $S9;9F$'N#c'N#$MF#Ti.)&'#Q +2 GUOVWE#D '#'#T4#P'FC9C9)&'F#QF$'NOKE#0QSc%h($>$T7t$ME#{f'7'F%W#D@QS0FM;9)&ff6&3 ~3 3pHQC#0QS0 $>T C9C9)&'F#_QbF$'NbKE#0Qdff+$G G1 ff #( 1 ff (( U H] 7$HC9)&>'N#, )&H%'N)*FT'N;#$O[uC9C0#T9,U F 'N)"SC9)&'NC0)K'NQC97)&'Nb%(LF')&!JQC#0QS07$T$!E#uA# OQS$ME#'#TU"VWE#'#'NT4#>"'Fg C9C9)&'F#QF$'Nc2'N)/$ME#HA# SKE#0QdW(]FF;9F$T@ SM;9#>$$M;#$#D ff 17$+ G7 Gff: :19QS0 $>'##Tt@A#K$'N%9Uj9U3 12'N)ff!C9K 4KHf'#)QS;#_{+2A9 ;#q$(F2U1q30575 G GU/VWE#u)<M;#$)&OC9)&C 07$TRi$ME#bf'N)>Q 'F,E#$' D#) QSc_ FffDN;9)&@ #T FffDN;9)& %U ptF'p)&0C0F$Tn$ME#9C90)&QS07$P%W$MEo%(DNE7$P #Tn#_hP$M7* #D@] h_;#S9$&%0yJk@ #TR1q$ME#)&M;#$l7)&FDNFC9)&07$TOO$ME#2'N)Q'h E#$>' DN) Qd"%FffDN;9)<, #%FffDN;9)<u9UffVWE# a#T9#D , )<WM;9QQ7)&=T@$ME#H2'N)Q 'FsQd0 #W$M 9;#F$>T@_yVg7#O3 UF 'N)L!QF"%DNE7$ ff #( #Tn$ME#@A# p C9C9)&'NFKEiME#'F% K' @)&M;#$01s%,E#KEi%WFP9C9K$TU;#$P$ME#SQC9)&'F] 0Qd0 $SFKE#] Tn X$ME# ff (( >KE#0QSbS)&0Q )>*0 # 1/$PDN] @QS0 o] F;#'Fr ; r7r 5O%,E#KEnK'NQC9 )&SM;9#>$M 7$Fn%hDNF#$S$ME#@QS0 n] h_;#@'hur; r9373 5@)&0C'N)&$T|ME#'NCi$dhfU UVWE#pM;#D7D $L$ME#@;#O'F,QSN$M;9)<tT9$M)<_9;#$>'##%,E#KE|)<;#)&S $!)&'NT4;#K$>'#'FffN$!)]F )&F$'N9hg]F )& #08QS'N)<L$ME9 p3r rS#$M)S]F )&F$'N9F/] 7)& #l )&P#T9Ty2'N)HK'NQC'N#07$uQS#$M;9)& UWVWE#L)&M;#$L@!;9#$M 7$F#K0)&0F>ly$ME#cK'NQC9;#$MF$>'#OK' $0UWvL$ME#' $ME#0)E9 #T@$!E#LN$M)>LK'NQC9;#$!F$'N9FqK' $ 2'N) ff (( ' ]70) ff #( WQ7)&D 9F2U"VWE#,Q7*F$ME# ff ((KE#0QSPK'#QC9;#$MF$'N9hF$>$M)FK$] H'F] 0) $ME#lQd#$M;9)&LT9$!)&9;#$'NqUV 'S$M;#T9$!E#P)&'N9;#$M#>('hg$ME#HKE#0QdW$ME#H%(DNE7$WK0hx%(0)<,#K0)&0F>TUff[,x$ME#,%DNE7$K0F%0)&O#K0)&0FT T9DN)FT4h$'Nn%WFl#' $>KT |FW$ME#bf'N;9)SQS$!E#'NT90U|VWE#@C9'7_7$$'p#' $TbWF $ME#W$ME9)&LQS$ME#'#T9(7C9C90 ) $'PuQS'#)&,)&'N9;#>$"$ME9 d$ME#,A# C9C9)&'#FKEqUff;#$(;9#*F$ME#MQh#%DNE $>gK0F> ff (( T9Tt#' $ffC90)I2'N)Q %f17$ff"HC9'#'N)ff C9C9)<' #QF$'Nuf'#) )&D7(%DNE7$0UVWE#P$u)<M;#$, )&L'##$MF#T7 ff #( KE#0QS UYP;9)<_#D@$!E#lK'#;9)&S'F(9C90)<_Qd0 $Mh$'NX$L%WFW2'N;9#TX$ME9F$1 f'N)x'NQdd#$&%'N)*7H%W$MEy_7)&D%DNE $>01/$ME#4#T|C9' 7$l9;9F$'N#bK'N ]70)&D Tp$'X i'N)&T90)P 4#TmC' $8"%,E#@' ]##Dp$ME#4#TC9'7_7$W9;9F$'N# 5 4 ' KF$L9$&%0O$k%'S] K$'#)& 5 4 # #T 5 4 ( U"V 'S' ] L$ME#LC9)&'N#0Q %##1>fi6ff#0#ff(0(ff8MQF%DNE7$ 3L3 03Jkr9U rFNrhr9U r93r9U r r7 5r9U r93#(,68)&D7P%DNE $> 3W0!Jkr9U rF7Nrr9U r7 93Jkr9U rF#Gr9U r75 GV/ #t3@ X0 'F f'#)W) #T9'NQdyD 0#0)F$>TDNQS'7Tp#$&%'N)*70UP3r0Mr r7rl#$&%'N)*7W%0)&S) 7JT9'NQdiK$Tm7XKE#'#' #DX$ME#%DNE7$L)&'NQz$!E#)7#D 3L3 003 UVWE#OC0)&QS0 $%WFW)&0C0F$T7OKE#'#' #DO$ME#L%D#E $.)&'#Qc_7)&D 0)W)7#D 3W0!40004500350040003500300030002500250020002000150015001000100050000.125000.10.08@0.060.040.0200.020.040.060.08000.010.020.030.040.050.060.070.083 0FffDN;9)&P HW$>' DN) Qd2'N) ff # #TA# PKE#0QS2'N) MQF9%DNE7$01F$M *7#DL] F;# _ L3 03 1 2'N)DNQS' Tt#$&%'N)*70U/VWE#WC#'7$"'NS$!E#(!2$"ME#'F%~E#$'7DN) QS/2'N) 2'N)/$ME#W>KE#0QS ff ###T ff #( VxE#lT9T@#' $"E9] , 7P'F] 0)<_7C#( #T$!E#lK0 )<bME#'F%|$ME#WQC9)&'F] 0QS07$0Uff ## 1qD ] S@QS0 y'F"JkrU rFNrb%,E# ff #( ] P@QS0 X'hr9U r30 9ULVWE#tC#' $c'Ny$ME#;)&DNE7$(!E#' %xW$ME#PE#$' D#) Qw2'N) $ME#lA#7tKE#0QS U"VxE#PQS0 @WD7]707r9Ujr930 9 UF T4 C#$>Tp$ME#S2' ' %x_#Dy$M)h$D US[HP'#'NXFP$!E#' KF$'N#S%0)&T9$K$Ti%(b$'NC9CTp$ME#4#TC9'7_7$H;9F$>'##014 #T)&>$M )&$T@$W%x$!ES#% C' $ 54 U"VWE#L#% C9'7_7$H%hWKE#'70@0 )<KE##DF'N#D@$ME#c_#O9$&%0 5 4 # #T 5 4 ( 14%,E#KEXDN] P@QS#QS;9Qz] F;#'h ULvL#K$ME#%WFT9'N#PK'# ] 0)<D 0#KL$'t O'#)&T90)L3 4#TC' $W'#KK0;9))&TUH;9QS0)&K0F/9C90)&QS07$H%(0)<lF'OK'N#T4;#K$Ty2'N)W#' 7J'N)H#$k%'N)>* 0U F4'N)$!E#l C9C9)&'F#QJ$'NS>KE#0QS $'L%'N)*{%( $ ME#'N;#T@9, #H$'P C9C9)&'F#QF$ 'F] 0)ffL)7#D W'Fq] F;#0U"VxE#QS' $>]FF$Ty$ME#LC0)&QS07$LT9K0)&9TR' %cU(x' 7J'N),#$&%'N)*701#%,E#' >P$'NC' ' O,D ] 0yFffDN;9)&X3O%(0)<)7#T9'NQSpD 0#0)h$T~ iKE#'#' #DX%D#E $ #T|#Ft)> #T9'NQSi.)&'#Q rX #Tr9U 79U F4'N)H0FKEX#$&%('#)*Ow%h,K'NQbC9;#$Tyf'N)Lhff$!E#d' $$'#Q 0)H$Mh$0UPvL;#$L'FWFff$ME#$Mh$01F$&%'L$MF$ff%0)&xKE#' >0SM;#KE$ME9h$ff_(QF#QS=T #TtQS#QS=T)<MC9K$] UVWE#9'7$$'NQz 0)H%WFL#$M 7$F$Ti%W$MEX0FKEy'FW$ME#SKE#' >0X$&%('O$Mh$01 #TR7C9C9)&'FNQF$>'##P$'$ME#@*FE#'N'#TB%0)&@$ME#0nK'NQbC9;#$TU|VWE#t9C90)&QS07$O%hd)<0C90F$Tn2'N)@3r 0Mr r7rOM;#KE #$&J%'N)*70U [,DNh_P;#TFLOQS0FM;9)&c'FffD 'N'#T4#L'F" C9C9)&'F#QF$'NqU FffD#;9)&9GO #ME#'F%$ME#OK'N))&!C9'N#T9#DRE#$'7DN) QSU p@)&0C0F$T|$ME#OC0)&QS07$Sf'#)lT9j 0)<0 $%DNE7$) #D 1r ;j 0Mr ;j6 U FffDN;9)&S6@ #Tp5OME#'F% $ME#O)&] 7$lE#$'7DN) QSUPVWE#E#$' DN)> QSL )&SM;9QQ7)&=T] F;#H'F $M 9;#F$Ty_O$! #l9Uff$ME#,K0hL$, C9C907)&W$ME9F$ ff (( W#T9TobC9'#'N)7QS07OC9C9)&'F#QF$'NqU ff #( FQS' $,h%W#(D#0]7,$ME#S9$H)&M;#$HME#'F%W#D$ME9F$] 0f'N)x#' J'#)WFK!J!fiy){yy450040003500300025002000150010005000202468101214163FffDN;9)&x 10@HW$>' DN) QF'2'N) ff (( C9C#TO$'LDNQS' T@#$&%('#)*H%W$MESMQbF9%(DNE7$0UffVWE#HQS0'N#$MF#T@Lr9U r r 759Ugx' $L$ME9h$ WK0FTp730r @$!E# 4DN;9)&70007000600060005000500040004000300030002000200010001000800070006000500040003000200000.80.60.4@0.200.20.40.60.811.200.5100000.511.5202.500.513 0;1.5FffDN;9)&L HW$>' DN) Qdqf'#)$ME# ff # #TA# P>KE#0QS/2'N) )&D %(DNE7$01F$! * #DL]FF;#ff_ Wf'#)DNQS' TX#$k%'N)>* 0U VWE#lE#$'7DN) Q '#@$ME#c!2$HME#'F%W f'N) ff ## KE#0QSSE90]##DSQS0 b'F Wr rF Nr1F'N#PF$$ME#LK07$0) x2'N) ff #( >KE#0QSPE9]##DtSQS0 O'Fer r 9371#T@'N#PF$x$ME#P)&DNE7$WW2'N)A# OKE#0Qd 1aE9]#_#DOQS0 O'F"r r75 G 9U3 ;ff#0#ff(0(ff;#(A9Qh %(DNE7$r ;0!r;K0h K0Fr9Ujr C r93Jkr9UjrG93r9Ujr 6r9U r3 3r9U Nr9U 7 r_7)&D P%DNE7$r ; 0Mr ; 6K0F K0FJkr9U30C GJkrU r 5r9U r 7r9U r930r9U r 57rr9U 93 3V/ #l@X0 'F 2'N)W) #T9'#QS@D 0#0)F$TX#' 7J'N),#$&%'N)*70UH30r0!r r rS#$&%('#)* %0)&S) 7JT9'NQdbK$T7SKE#'#' #Dc$ME#,%DNE7$/)&'NQ$!E#,) #D r;0!r; U F4'N)s0FKE#$&%('#)*$ME#y]N#p$!F$%W$ME QF#Ql;9Q#T QS#_QS;9Q %(0 )<@T907$ 4TUVWE#]###'#T9L'F0FKEi#$k%'N)>*Oc$ME#0y#$M 7$F$Tp%x$!EX$ME#ST90 $ 4Tn$MF$>01 #T$ME#HK'N))<MC9'N#T9#DS'H C9C9)&'FNQh$Tt7] )<'#;#(>KE#0QSUeVxE#,9C90)&QS07$W%WF)&0C0F$TX OKE#'#' #DO$ME#L%DNE $>.)<'NQ ST9j 0)<0 $,)> #D r ;j 0Mr ;j622.5fi50004500400035003000250020001500100050000.5@00.5E#'F%Wf'#) ffDNQS' T@%W$ME )&D L%DNE7$FffDN;9)&P HVWE#E#$>' DN) Q1((1.522.51HE9]N#D~|QS0 'F W3 r; rFNGU VWE#p#$&%'N)*i3500400010000300090003500800025003000700025002000600020001500500040001500100030001000200050050000123456703x 10@100000.050.10.150.2050.2505101520253035FffDN;9)& G HW$>' DN) Qd2'N)b]N#|$MF$>%W$MEBQbFNQS;9Q ' c1xf'#)t#' 7J'N)y#$k%'N)>* O%W$ME%D#E $b$M *7_#Dn] h_;#O r Mr UnVWE#E#$>' DN) Q 'N|$ME#y!f$OME#'F%Wf'#) ff ##KE#0QS 1ffF$P$ME#OK07$0) ff #( >KE#0QS @ #Tn$ME9F$SF$P$ME#@)&DNE7$ ff (( UVxE#tKE#0QS ff ##DN] LQS0 O'F"r9U r7r93 1 ff #( DN] ubQS0 @'her9U r 76l7#T ff (( DN] LQS07O'FsrU N0 ;60004000900080003500500070003000400060002500500030002000400015002000300010002000100050000.1410000.12FffDN;9)&0.10.080.060.0400.050.0200.050.10.150.20.2500.300.511.52@HW$>' DN) QdOf'N)O]##|$MF$X%W$ME^QS#QS;9Q ' P1uf'N)y#' 7J'N)#$&%'N)*7@%Wff $ME%D#E $b$M *7_#Dn] h_;#O rM0 r; UnVWE#E#$>' DN) Q 'N|$ME#y!f$OME#'F%Wf'#)KE#0QS 1ffF$P$ME#OK07$0) ff >KE#0QS @ #Tn$ME9F$SF$P$ME#@)&DNE7$ ff UVxE#tKE#0QS ffDN] LQS0 O'F/Jkr9U rKG93 1 ff DN] PQS0 O'her9U r9373u7#T ff DN] LQS07O'FsrU r#(((#((0(&%####2.533.5fiy)30002500{yy35003500300030002500250020002000150015001000100050050020001500100050000.260.240.22@0.20.180.160.140.120.10.08000.020.040.060.080.10.120.140.1600.020.040.060.080.10.120.14FffDN;9)&P6 HW$>' DN) Qd2'N)b]N#|$MF$>%W$MEBQbFNQS;9Q ' c1xf'#)t#' 7J'N)y#$k%'N)>* O%W$ME%D#E $S$M7* #Dp]FF;#t r !r 6 UXVWE#E#$' DN)> Q 'Nn$ME#@!f$OME#'F%W2'N) ff ##ffffKE#0QS 1ffF$P$ME#OK07$0) #( >KE#0QS@ #Tn$ME9F$SF$P$ME#@)&DNE7$ (( UVxE#tKE#0QS ff ##DN] LQS0 O'F/Jkr9U39G 1 ff #( DN] PQS0 O'her9U r 7l7#T ff (0( DN] LQS07O'FsrU r 5; 0 ;25002500400035002000200030002500150015002000100010001500100050050050000.090.080.07@0.060.050.040.030.020.0100.0100.0100.010.020.030.040.0500.200.20.4FffDN;9)&P5 HW$>' DN) QdOf'N)O]##|$MF$X%W$ME^QS#QS;9Q ' P1uf'N)y#' 7J'N)#$&%'N)*7@%W$ME%D#E $S$M7* #Dp]FF;#t r !r 6 UXVWE#E#$' DN)> Q 'Nn$ME#@!f$OME#'F%W2'N) ff ##KE#0QS 1ffF$P$ME#OK07$0) ff #( >KE#0QS @ #Tn$ME9F$SF$P$ME#@)&DNE7$ ff (( UVxE#tKE#0QS ff ##DN] LQS0 O'F/Jkr9U r7 591 ff #( DN] PQS0 O'her9U r93l7#T ff (0( DN] LQS07O'FsrU 930; 0 ;0.60.81fi-5-9-6-10-7-11-8-12-9-13-10-11-14M=1,C=1M=1,C=2M=2,C=2SJJM=1,C=1M=1,C=2M=2,C=1@FffDN;9)&30r WVWE#,C#' $"'#S$ME#W!2$"ME#'F%W"V/);#W' Dc*FE#'#'NTyT9]#T9T7S$ME#,#;9QS90)ff'h C9F$$>0)#f'N) ff ## 1 ff #( 1 ff (0( #TA#7tKE#0QSL2$0) $M)F##D'NODNQd' T#$&%'N)*708#$ME#PC#' $'N$!E#P)&DNE $ME#'F%W $ME#H$M);#L' DS_*hE#'#'NTXT9]#T9TX b$ME#PN;9QS0)"'heC9F$$0)>#"2'N)#' J'#),#$&%'N)*7$] h$'NS;9#K$'NO$($!E#u$0U/[,D#F$ME#'N;#T9LQS07$'N#T@$ME9F$sf'#)ff'NQdW'F$ME#L#$k%'N)>*$ME# 4NT@C9'7_7$;9h$'N#K'N ]70)&D T$'S S'N)<T90)"4NT@C9'7_7$01#$ME#,E#0;9)<>$KLT9K0)&9TX9!2'N)&%WFW;#T$>'' ] L$ME#LC9)&'N#0Q@Uvx$ME#H$ME9)&xKE#0Qd ff #( ($!E#,QS' $)&'N9;#$ #TtF'cNT9,)&0h'N9 #tFKK0;9)>F$,)&!;#$>0U2$'N;#$MC0)If'#)QST'N#t7 ff (( _b$ME#HK0FW'hgDNQS' T@#$&%('#)* ff%x$!E'F%~%DNE7$0BU *"QC#)&K0F]#T90#KO$ME#;#,!;#D $L$!E9F$,$!E#lKE#' K'F(O>KE#0QSSP#' $L$!)FDNE7$&f'#)&%W )&T #TXT90C90#T9c'N$ME#PFK$>]FF$'N.;9#K$'Ny #Th>'tC9 ) Qd$0) ] F;#0UV 'X$M;#T9p$!E#t0 )##DnK0 C9 #$t'FH$ME#@] )<'#;#l>KE#0QSOC9)&'NC9'7T|%t$'#'N*X;9C|y$'FC9)&'N#0Q !;#D $Tn Rx $>'Np$F2U +<305 5 GH7] ' ]#_#Dn#_97)&RQhD 0UXVWE#@#_97)&RQhD)&@'hu=X)np %,E#KE 0FKE|QFD @K'##$O'Fu$ME#0)b] 0)&$>K0h,'N)bE#'N)&='N7$MFW9 )&O%W$ME9;9FeC9)<'N9 #$& 1 %W$MEy0FKEy'#K0F$'NX'F"$!E#d97)W'#KK0;9C#TR%W$MEyC9)&'N9 #$&'hr; ;pS$'#'N*X3 )o6 )R3 G@#$k%'N)>*@ #TX$M)&Tp$'O0 )X$P;##D' $MEy$ME#SDNQS'7Tn #Tp#' J'#)LFK$] F$>'#;9#K$'N#0UH;9Ql0)L'FWC9F$$0)>#P;#Tp%WFP r r7r914%HE#O$ME#t#;9QS90)H'F0C9'#KE#c%hP r r9USVWE#9C90)&QS07$S%hP)&0C90F$>Tp2'N)S30rT9 0)&07$l#$&%'N)*70U F 'N)L0FKEp#$&%'N)*$M);#*FE#'N'#T~%WFK'NQC9;#$>Td7P9FK$/0N;9Qd0)F$'NqUffVWE#WA# SQS$ME#'#Tl#T9Tt'F%0)*FE#'N'#T9_bFQS' $ffF9$ME#K0FU"2$$ME#;#, C9C0 )&$ME9F$$ME#L$ME9)<PC9)&'NC9'7T@KE#0QS,E9] Ll$$0)0 )>#_#D@C90)kf'N)>Q #K$ME9 O$!E#PA# 7C9C9)&'NFKEqU"VWE#P)&!;#$>u )<LM;9QQ )<=Ty 4DN;9)&3r9Ug G9fiAGF$ME#,>K$'N@%LM;9QQb )&=L$ME#PK'# $M)<_9;#$>'##,'Fff$ME#LC9 C90)1 #TT907$jf@M;#x2'N) ;#$M;9)&)&07)&KEqUXVWE#@QFnK'N7$M)&9;#$'N#S'F,$!E#C9 C0) )&@C9)&07$Tn|A#K$'N79UXnA#K$'N7-ff!*0 tQS$ME#'#TR7$M)&'#T4;#KT1()<!JT90)&] T|)&'NQ n] )<_h$'N9FWC90)&!C9K$] X #Tm7C9C#T $'WU~-ff!*0 @ C9C9)&'#FKEnD7]7tX#$0Qh$K@%p'h{9;#T9#D | )>#$!) )&|K' 7C9C9)&'FNjJQF$>'#n$.' 3@; W'F%] 0)c$tME#'#;#TB#' $T $ME9F$$!E#@! '#)&$t#T9T $'p]FF;9F$E#DNE#0)'N)&T90) $0)>QS_#K0)<0FH%W$MEO$ME#H'N)&T90) #TQSDNE7$,9L]70OC'N#0 $>_hqf'#)(7t )>#$!) )&tK' >C9C9)&'F#QF$'NqUQfiy){yyV E#@] )&F$>'#9FWT90)&] h$'N|$! #!E#t$ME9h$tA# R C9C9)<'NFKEn@yMC9KFHK0F@'h{-s!*0xC9C9)&'#FKEq1 $ME#;#t>0)&]N#D|FtX9*|%x$!E|$ME#yN$#D|$ME#'#)& U VxE#OT90)&] h$'N C9)&'NK>tT9'##' $PQ7*Fl 7F!;9QC#$'N#l)<DN )&T9#DO$ME#S$M);#K$M;9)<l'h(0#0)&D .;9#K$>'#7#ToE#0#Kb$cPF'C9C#K0 #$'WU(VWE#L]FFT9$&y'Fs-s!.* LQS$ME#'#T@HM;9#&K$W$'b$ME#PK'N#T9$'Nq1 $ME9F$W)hT9_;#'FgK'# ] 0)<D 0#KPME#'#;#TPDN)<0F$0) $ME9 X3 8#PA#K$>'# 9Uff2$xH$g O'#C90O9;#$'N@%HE#$ME#0)'N#LK0 yC9)&'F] H$ME9F$WM;#KEOK'N#T9$'NXE#' T9xf'N) $ME#SB0#0)&D7;9#K$'NqU[LC9C#K0F$'Nn'Fu-s!.* S$ME#'N)&X$'XWSt#' $c$M)FDNE7$&2'N)&%W )&T1q$)&9;#)&K'NQC9;#$!F$'N'Fff'NQSS] 0)FD %,E#KEX )&P#' $W$!)FK$M # U pPC9)<0 $>TodKE#0QdPy%,E#KE$ME#l^0#0)&D;9#K$'NyP7C9C9)&'FNQF$>To7OVg#'#)W0)<1q%,E#KEXD7]7ub$M)FK$! #d7C9C9)&'FNQF$>'#@$'O$ME#$0)Qd)&;#)&T 2'N)@-ff!*0 XQS$ME#'#TU " )&'N;#X C9C9)&'FNQh$'N KE#0QS@T90C90#T9#DB'# $ME#T9DN)&X'FP$!E#V/0#'N)b0)&@C97#'N )&T90)<]7TU H#*Fp$ME#X C9C9)&'NFKE|+2A9 ;#H$@F2U1305 K5 G G1$!E#tKE#0QSST9K0;#T~E#0)< )<tQC#0)hP$ME#pT9'p#' $c $M)<'NT4;#K@#$M)] )&F$>'#9F] 7)& #08 K'NQbC9 )&"9;9F$'N#+2 5 G7#T$+ G93GUq[u#'7$ME#0)C9'7$] WFMC9K$/'F9$ME# C9C9)&'FNQh$'N#$ME9F$"$!E#t )&HD 0#0)Fq #T@#' $(FK$>]#$&S.;9#K$>'#OT90C90#T907$084E#0#KL$ME#t7)&, C9C#K0 #P$'S9)&'NhTKFH'F"(x0UWvx"K'N;9)<L2'N)HSD ] 0hK$] F$'N;9#K$'Ny$uQSDNE7$L9lC' #$'bK'NQS;9Cb%W$MES$MF'N)IJkQbFT9u7C9C9)&'FNQF$>'##"%,E#KE@ )&,$$0)ff$!E9 S$ME#HKE#0QS"T9K0;#>TE#0)& U";#$0QC#)&K0FH] F;9F$>'#|'NnMQbFWK0F#$&%'N)*7l!E#' % $ME9h$$ME#@9;9F$&n'FP C9C9)&'FNQh$'N#S9$>$0)$ME9 O$!E#' L'N#$Mh_#T.)<'NQ ' $ME#0) ]F )&F$'N9F/QS$ME#'#T90UVxE#ffK'NQC9;#$MF$>'#9F QC#K$k 19)&'#9;#$M#ff #TLD 0#0)h$&lQb *Fff$ME# KE#0QSg]70)&uh$$M)FK!J$] U H72'N)&$M;99F$>b$ME#'N)&$K0FqDN;97) 7$W)&DN )&T9#DS$ME#L]FFT9$&@'FeV/N'N) 0)<xC9 #>'#fiX )&,Qd>#D4U(VxE# 7#' $ME#0)ff'#C90b>M;#,%HE#KEO#T9($>'l9LFT9T4)&>Ttb$ME#,#0 )e.;#$!;9)& U2$L%'N;#TR $>0)&$#D$>'@E#' %$!E#KE#0QSPC90)kf'N)>Qz'Np)&0F/%'N)&TpT4F$!F$0U p )&C9)&07$9C#'N)&#DS$ME#, C9C#K0 #$&t'F$ME#>,QS$ME#'#T9"'Nd$ME#,E9 #T#J%,)<$>$0T9D $T4F$!Jk9F Up@ )&bN$M)<0QSpDN)F$>!.;#ff$'y$ME#O] )&'N;# #'# 9QS'N;#S)&!f0)<01/%,E#' 9C9;#$b%(07$l'N#D%WlOQC9)&'F]##D$ME#PC9 C0)UBpL )&LF'S$ME9 9*h.;#q$'SYP)cUN UL7C9C90O2'N) E#xM;#D $>'##0UF M!ff >! #%'d$ME#"K$'Nd%(WC9)&>0 $ff9C9)& 8 'N#sf'#)/$ME#ffLa )&$ff'#)&T90)ff C9C9)&'F#_QbF$'N?PQS$M E#'#T7$M)&'#T4;#KT~A#K$'N59 U V'nK'NQC9;#$ 6 1 $ME#] 0)FD #DR$7F*0|F']0c)$#E.=5 H +<3 3 5 G H 1 %T9a #,L) #T9'#Q^] )& #fiff 6 %,E#0)& 6 FKO$>'N)&FT9 +$M, )& 93 ;#$5 'NG U&&EECx' %= H986ff 6 C 5 +&3 3 5 G E H+$G GH 8 &8< 6ff 76 6+$GFNG#gGQrce#####6ff98< *#&#0E6 / C E + 5 " C E +&33 5 G 1& #86 6 r+$G G+$GG Gfi68(6 E#&3 5 G#+$G G5 +&3(YLj0)&0 $>_h$'N@'F ff n+ZN G #T@$M7* #Dt] 0)hD ,%x$!E@$ME#HFK$'N)<_haT9$!)&9;#$'NyNT9<fffi*%,E#0)&+5<0 GB6 5 <=0 1G 6+ 54#e+<6 3G"B+&335G<<8+$G 6 G3g+<3ff+GG+$G 5 GVWE# a)&$L$>0)Q # $0)>QP))<]F 7$l90hK0 ;#'FP+$GG GUPX'#;9)H_QbC#0Qd0 $Mh$'N#;#T19$H9C9)&'N(+50 BG 6 / 35ff+G33+&3 3#ff+(35GGVWE#;#,7o+$GKG G %(PE9]ff#6=35 _=#53 55 )ff+#=3#+5#33 5,1 q+33 ff+ G3G+ r GG+930G3 5Gg+&33 5G>"^+&3$0)Q(6Br"B+&3/ ff+ 5G( "*3(1A2+ff< fi<0 1G 6G3G9+&38e+G+ G6ffFffN 8 T|C9'7_7$S;9h$'N# )&'N#$!F#Tm7pC9;#$$#D zr91g #T|F'X#' $#D$ME#@C9'7_7$S$ME9F$6 Br9U65 68 fi33e+G"+eG# $=;#ff+$5 3ff+$3G0+&3ff+$GGG2+$G"](<<5=#80 1G 6+ Geff $ #%'3+5)!MQ'efffio$ME#PK$'Ny%tC9)&>0 $H2'N)QS;#Fcf'#) ff 1 f'N)( 6z3 0M0 630Mb$ME9F$L%WFL;#TX2'N)H$ME#9C90)&QS07$HT9K0)&9TXA#K$'N4Uff##6=#+ 553 5"B+<3G9g+<33 5GGG3=#+ 5 ff+G " +&33 5G+&3 #3 ff+GG+FNGfiy)ff6#(=3#"53#ff+5ff+53 5" +<38=+ 5G({yy3 5 G>G3+&3 3 5 GG9+&33 +&33ff+3G 3 3 33e+ 5 G5 +&33 5 G ;G>G+=#6Gf+(+ 5 )ff+G3 5G>"^+&33G9+&3e+GG(8(+ G%,E#0)&6 ( 6 E # # (.$,POQF$$>0)W'F"T 9$!Fg$'@C#;#D@X$ME#l7C9C9)&'NC9)&F$c;9#K$'N#H2'N),bMCK 4KO#$k%'N)>*41 _*h$ME#LDNQd' T'N)W#'7> J'N)U(A##KS$W,$'#'K0;9QS90)<'NQSL%LT9'@#' $,C9)&07$W9C#K$X$ME#c$0)QS)&9;#)&T@2'N) ff (( 1#f'#)"SD 0#0)>FFK$] F$>'#b.;9#K$'NqU #$0hT@%(LC9)&07$W$ME#H9C9)&'N#,;#>T2'N)$ME#LDNQd' #T#' 7J'N).;9#K$>'##0UF 'N)A#DNQS' T#$&%'N)*ff6((ff=E3pr;#(36ff#(+<335#F 'N)#' 7J'N)W#$&%'N)*((#5G3pr;=fiE#(5 +&3>; #<+3G0+5 55& # Q#; ;>+58 +G "; # Q; #E"ff#3353 5G38"+3+5<+ 3ff+G0+ 5338"++53 5G(G8"+"GG5333353 5+&3GG>G5+<33 53GG+G GC G|3G9' Da+&3 "# & #>; #5 |3G0+ 5 ~30G"5 +&3 5 0G + ff+G+ Gff& # #;>;>5 |03 G"B+ 5 |30G' Da+&3 "fi+ff+ Gff+ G; # Q; #E8"+ff+GG"33CG5 +&33 5 G+ GI@9' $!EO$ME#,9C9)&>'##d+KG G" #TR+ G $xKE#' >0O$'9P$ME#0)2/'N) 6a1#%,E#KE#] 0)xx'F%0)8F'$!E#PFK$] F$>'#O;9#K$'Nq1919R+ G )ff+$:4GB63 3;CECVxE#L] K$'N) 5 4 WT9$0)QS#Tp7t'7]##D4#TC' $H9;9F$'N#W'N#$!F#T7t$>$#Dff< 6Br;<5VWE#LDN)>FT90 $L)&9;#)&T@2'N) 0 )##D@W] F;9F$>To7 ff F$W$ME#4#TC' $0U:Rfi! 4[HK*7 1YU1x $'#q1g\U 1a?A#&#'F%WM*721gVLUff+&305 67 GUL[w07)##DFD 'N)<$!E9Qz2'N),' $=0Q 9iQJKE##0U fffi ff 01 F13? aM3 G 5U[HD ' $M1N U9|Ug+&305 57r GUgVxE#L$M);#K$M;9)<L'Fs9 H#$k%'N)>* 2'N)]#!;9Fg)&K' D##$>'#qUfiff fffi!"fi #$&%'"fi%%()* 01 +9U)0)1HYU1(? ] T9R:7 )1,-/UP+&35 5 5 GU " )<_h$'N9FLK0;9QS;# $yC97#'N 2'N)7$M)FK$! #T9>$M)&9;#$'N#0U-,.&/* %0 '1fi #$ff%2'"2fi%ff%3)* 54$7689;:N1=<?>719 #N 9UE9F$$MhKE9 )<NN1 LU1N?^H0)&$ME#214AqU9AqUq+&305 5 57 GU 077J4T@$!E#'N)&S2'N)ff>$'NKE9F$>KHK'N9#K$'N#$#$k%'N)>* 0UqV KEqU9)&0CqU#kIA#K!JkWA#[xJk5 5Jkr 91YL0C9 )&$MQS07$"'h 'NQC9;#$0)A#K0#Kl #Tb[u;#$'#QJ$'Nq14#T9 y#$>$!;#$P'F"A#K0#K UE9F$$MhKE9 )<NN1NLU1 ?H0)&$ME#21AqU4AqUg+&35 5 5 9GUff-s!*0 uQd0 7J4T$ME#'N)<)&'NQd] )&F$>'#9F]N%,C' $0UA9;99QS$$Ty$' * *fi* Vg)> #0U#'N@x0;9)Fgx$&%('#)* UE9F$$MhKE9 )<NN1{U14? H0)&$ME#21qAqUaAqUff+2 r r7r GU72'N)QF$>'#OD 'NQS$M)< #TC#!*0 LQS0 7J4T$ME#'N)& U@, A0B:*6ADC0EFff:.AHGIJA 1KKe+ G137r a3309UME#'NCq1 |U0{U1 : 0%H)&0#K 1 PU 10N7 *N*h' 91 VLU1F?| '#)&T4 q1F|U >U+<305 5 GU0[LC9C9)&'FNQh$#DPC9' $>0)&'N)T9>$M)&9;#$'N#SR!P#$&%('#)* P;#>_#DpQS#$M;9)&0U@Ip '#)&T4 q1|U/U1/H0 )#01/|Uq4U1ff?A#' _14AqUg+ *sT90U GL1 5M & ;6ON/P&%'" ';QRfi&SBH9;668ffR6;fiQ6T<?> U9pIVBC9)&0U\L0Qb q19AqU19? \L0Qb q1#YU +<305 6FNGUA#$'NKE9F$>KP)<_hF$>'#q1 9#,T9$!)&9;#$'Nq1 #Ty$ME#P9)&$'N)>F$'N@'h"_QbFD 0UR'VUUUXWP&L6;fiffL6T&FB$fifi"F2%(6;Y6T MZE[7:*2R'"2fi%ff%3Y\*2"J1 ]F"1 93 h43 UHf$1ff|U1ffW'FQ 9q1 HLU1? Vg)&!Cq1 lUW+&35 5 5 GUXX'#T9_#T90C0#T90 $Qd0 7J4T~$ME#'N)<RF'#K0FgQd$ME#'NTf'#)W C9C9)&'F#_QbF$LC9)&'NC9FDNh$'NO'Fff_72'N)QbF$'NqU-N1fi^_`CQ-aJ/fififfbffN1/*9%68fiQT6J1 <c> dP<"eh145 a30r Ux_7$'Nq1L\bU *xU1WYPN q1W-/U1Fa)& 1HHU1,? x0F211HLUP+&30575 GU^VWE#X%7*F0C^FD 'N)&$ME9Q;9#M;9C90)&]#Tp#0;9)Fg#$&%'N)*70U@J 012f*]?g 13730 6a373MG93 U2'N)x'N)&]#$>= 1 *xU/4U1ffA9;#0)QS'N#T9$1"PU 4U1ff? '#'NC90)1e\bU(+&35 6 5 GU@ 'N;9#T9T|K'N#T9$'N##D @ Fff#_#_720)&0#K2'N) T9K'N#W;9#T90)/K0 )&KW)&'#;9)&K0U9F@ ';92"Hhfi2fi5ffTfi #@\ff%'fi%ff%(i2"?CB$9""M&&6_ 'Iff:*# ';ff:T"& ';92"UMX'N;97$MF H%c1N[N@0[H'7KF$'Nf'N) x[u>UN 7*N*F'7_1gVLU1/?7'N)&T4 q1/|UUW+&30575 5 GU " )<_h$'N9F(C9)<'N9 #>$K7f0)<0#K #TR$!E#Qb)IJT9$T4F$M 9F> U,L/"2%= 'fi #Hff%2'"fi%%()*2"54H;6;"&P7:N1=<?> 147593 79U0#0q1qLU1#H'N#D419[SU19? F0);#j"1 PU+&35 5 GU '#K*7#DtD 9#HM QC##D@]70)& )&D PC9)<'N9J#$KL9C90)&$ #$0QS0U !'"2fififf2%,L/"2% &'Ij1/QRFQ-aJ/fi-Jfi/Mff;6U4A9C9KF>M;#P'NH0F p'N)<Ty[uC9C#K0F$'N#L'h ,#K0)<$MF H0h'N##D4U'N)<T4 q1#mU#U1#\PE9 E9)> Q #21MffU17N *#*F' 91#AqUNVLU1#? A97;#f19:ffU+&35 5 GU [L7$M)&'#T4;#K$'N$>'P] 7)&jJF$'N9FgQd$ME#'NT9x2'N)WD#) C9E#K0FffQS'NT90UHy 'N)<T4 q14|U4>Ue+ *ffTU G1lkl ff!mGI9a2:*%QDM%)6ULfiy){yyL C9C0q1gcUq4U1q? H'#T4)&DN;#= 1FWUqHU"+&305 5 67GUL"'7$>=0Q 9XQFKE##0 )##D;##DXQS0 4T$ME#'N)&t7#T@#0 )H)&MC'N#LK'N)>)&K$'NqUff 'N)&T4 q1#|U9U19H0 )>#019|U#4U19?A#' 91aAqU#[SU+ *ffT90UjGL1 M& 2"76 ON/9%'" '8QRfiffOB$9;668ffR68fiQT6T<?> UoIVBC9)&UH0 )#1W|U1"? A9 ;#21L:ffUL+&305 5 67GUB: )&D7T9]#_h$'NBQS$ME#'#T9O2'N)t7C9C9)&'FNQF$>C9)&'N97#$K_720)&0#KO%W$MEp)h$L'F(K'# ] 0)<D 0#K UtIhB$9"Mff&6T 'ff:*';/"fi2ff:m ';9 D&2""fifffiRff "fi #$&% 'fi%ff%(i2"UF'#)&DN OL ;7Q 9qUF0);#j"1 cUg+&30575 6 GUEHT4;#K$'NX'FffK'NQC9;#$Mh$'N9FK'NQbC##$&9 y#$&%('#)* >$ME9)&'N;#DNE)&0QS'F] F9'h %0 *cT90C0#T90#K0U"fi2fi& MTfi #$ff% '"fi%%()*2"?CBHP"M&6'Tff:*SWff:S& ';92"U A9 @pF$' 1[ @#X'N)&DN7tL ;7Q 9qU: ;9)<$>=0q1 AqU10?~A9C#D E9F$0)1 YU +&305 676 GUF:q'NK0h K'NQC9;#$Mh$'N#%W$MEcC9)&'N9 #$"'NHDN)> C9E#K0F$M);#K$M;9)<l #Tp$!E#_)S C9C#K0F$'Nn$>'9C90)&$S#$0QSUS,L/"2%&'ff:* 4H?%_fifiY68fiff"&%Jfi1 ?> 130 F Ux0F21HLU+<305 5 GU '#9#K$'N#$g0 )>#_#DL'ha9! #$&%'N)*70U?fi #Hff%'fi%ff%(i2"1]F1 3a3 306UJfifiY68fiff%%3MFW:*FUg[HT9T9'N7J p> 1HT9%('#'#TK$& 14[SU-/0 )&21/4U+&305 6 67GU!B$9 V ;ff%( 6;fiff 4H"?6;2&Sh'fi%ff%(i268fiQT6UX'N)<DN XL ;7Q 9q1ffA9-ff )&214\bUg+&30576 6 GUoh$'41N[lU-/$0)&>'Nq19LU14?^[L#T90)&'Nq1 4U H{Ue+&35 6 GU [ QS0 4 TX$ME#'N)&O0 )##D@FD 'N)&$ME9Qw2'N)W#0;9)>F#$k%'N)>* 0U-Q-aJ%(ffR6;fiQ61=<F145 5 30r9305U-ff!*091/VLU"+&30576 GUL'N7] 0)&D70#KlK'##T9$>'#X'F($!E#l$! Cy;9F$>'#yf'#)W$ME#b_a#$!Jk)> #D Tn>_#DF,QS'#T92HU , AB:6A2DC0EFff:.AHGIJA =1 <fig!+ G G1305 93 a305 69UH'#K*20)1H{U4VLUg+&35 GU-2 ff&%36; 6+ a)&$xT9$>'#9GU"-")<_#K$>'N;9#] 0)&>$&C9)&>0UA9 ;#21N:sU1 ? 'N)<T4 q1F|U U4+&30575G GU?*ff9C#'7$>_#DS$M)>FK$M #M;9#$M)>;#K$M;9)&"S7$M)FK$! ##$&%'N)*70UnV'N;9)<$=0* 1sYUgAqU1/X' =0)1/|UgLU 1e?zHFQS'41/|U*xUW+*ffT90UjG1 5M ;6 ffhN1/*9%'" ';QD&fiOBHP"76"6;ffJ68fiQ6Tg U9pVBC9)<0UA9 ;#21W:ffU1 ? 'N)<T4 q1|Ue>Uu+<305 5 5 GUR[x$$M)FK$>'N)LT999 QSK@n2T#f'#)&%W )&T~#$&%'N)*70UQ-aJ/fifi&4U"IC9)&UN1/*9%A9 ;#21:ffU"SU1ff# *#*F' 91VLU1ff? '#)&T4 q1ff|UffU,+<305 5G GUX0 4T~$!E#'N)&X2'N)cDNQS' 9!#$k%'N)>* 0U ,.&/* % 'fi #$ff%2'"2fi%ff%3)* 54$7689;:N1L+91 G93 GUA9E7%( 1F|U[lU 1 ? vH$!E#0)&,+&305 530GUN- )&'N9 #$KHT9_hDN#' ";##DlL)<!f'N)>Ql;#F$>'#P'h4$ME#_7$0)#$<J3 F9Q)*N#'F%WT9D S9F UHEFff:.A0'" '8&"Q AlE[M*A10K> U!>fiJournal Artificial Intelligence Research 15 (2001) 189-206Submitted 2/01; published 9/01ATTac-2000: Adaptive Autonomous Bidding AgentPeter StoneMichael L. Littmanpstone@research.att.commlittman@research.att.comAT&T Labs Research, 180 Park AvenueFlorham Park, NJ 07932 USASatinder SinghMichael Kearnssatinder.baveja@syntekcapital.commichael.kearns@syntekcapital.comSyntek Capital, 423 West 55th StreetNew York, NY 10019 USAAbstractFirst Trading Agent Competition (TAC) held June 22nd July 8th,2000. TAC designed create benchmark problem complex domain emarketplaces motivate researchers apply unique approaches common task.article describes ATTac-2000, first-place finisher TAC. ATTac-2000 uses principled bidding strategy includes several elements adaptivity . addition successcompetition, isolated empirical results presented indicating robustnesseffectiveness ATTac-2000's adaptive strategy.1. Introductionfirst Trading Agent Competition (TAC) held June 22nd July 8th, 2000, organized group researchers developers led Michael Wellman UniversityMichigan Peter Wurman North Carolina State University (Wellman, Wurman,O'Malley, Bangera, Lin, Reeves, & Walsh, 2001). goals included providing benchmark problem complex rapidly advancing domain e-marketplaces (Eisenberg,2000) motivating researchers apply unique approaches common task. keyfeature TAC required autonomous bidding agents buy sell multipleinteracting goods auctions different types.Another key feature TAC participating agents competedpreliminary round many practice games leading finals. Thus, developerschanged strategies response others' agents sort escalating arms race.Leading competition day, wide variety scenarios possible. successfulagent needed able perform well possible circumstances.article describes ATTac-2000, first-place finisher TAC. ATTac-2000 usesprincipled bidding strategy, includes several elements adaptivity . additionsuccess competition, isolated empirical results presented indicating robustnesseffectiveness ATTac-2000's adaptive strategy.remainder article organized follows. Section 2 presents detailsTAC domain. Section 3 introduces ATTac-2000, including mechanisms behindadaptivity. Section 4 describes competition results results controlledexperiments testing ATTac-2000's adaptive components. Section 5 compares ATTac-2000c 2001AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiStone, Littman, Singh, & KearnsTAC participants. Section 6 presents possible directions futureresearch concludes.2. TACTAC game instance pits 8 autonomous bidding agents one another. TACagent simulated travel agent 8 clients, would like travel TACtown Boston back common 5-day period. client characterizedrandom set preferences possible arrival departure dates; hotel rooms(The Grand Hotel Le Fleabag Inn); entertainment tickets (symphony, theater,baseball). obtain utility client, agent must construct travel packageclient purchasing airline tickets TACtown securing hotel reservations;possible obtain additional utility providing entertainment tickets well. TACagent's score game instance difference sum clients' utilitiespackages receive agent's total expenditure.TAC agents buy ights, hotel rooms entertainment tickets different typesauctions. TAC server, running University Michigan, maintains marketssends price quotes agents. agents connect Internet send bidsserver update markets accordingly execute transactions.game instance lasts 15 minutes includes total 28 auctions 3 differenttypes.Flights (8 auctions): separate auction type airline ticket: ightsBoston (in ights) days 1{4 ights Boston (out ights) days 2{5.unlimited supply airline tickets, ask price periodically increasesdecreases randomly $0 $10. cases, tickets priced $150$600. server receives bid ask price, transactioncleared immediately ask price. resale airline tickets allowed.Hotel Rooms (8): two different types hotel rooms|the Boston Grand Hotel(BGH) Le Fleabag Inn (LFI)|each 16 rooms available days 1{4.rooms sold 16th-price ascending (English) auction, meaning8 types hotel rooms, 16 highest bidders get rooms 16th highestprice. example, 15 bids BGH day 2 $300, 2 bids $150,number lower bids, rooms sold $150 15 high bidders plus one$150 bidders (earliest received bid). ask price current 16th-highestbid. Thus, agents knowledge of, example, current highest bid. Newbids must higher current ask price. bid withdrawal resaleallowed. Transactions clear auction closes. prevent agentswaiting end game bid hotel rooms, hotel auctions closeunspecified period (roughly one minute) inactivity (no new bids received).Entertainment Tickets (12): Baseball, symphony, theater tickets solddays 1{4 continuous double auctions. Here, agents buy sell tickets,transactions clearing immediately one agent places buy bid price leasthigh another agent's sell price. Unlike auction types190fiATTac-2000: Adaptive Autonomous Bidding Agentgoods sold centralized stock, agent starts random endowmententertainment tickets. prices sent agents bid-ask spreads, i.e.,highest current bid price lowest current ask price (due immediate clears, askprice always greater bid price). bid beats current bid (ask)price arrives, sale price standing bid (ask) price, opposed arrivingask (bid) price. case, bid withdrawal ticket resale permitted.addition unpredictable market prices, sources variability game instance game instance client profiles assigned agents random initialallotment entertainment tickets. TAC agent 8 clients randomly assignedtravel preferences. Clients parameters ideal arrival day, IAD (1{4); ideal departure day, IDD (2{5); grand hotel value, GHV ($50{$150); entertainment values, EV($0{$200) type entertainment ticket.utility obtained client determined travel package givencombination preferences. obtain non-zero utility, client must assignedfeasible travel package consisting arrival day AD corresponding ight,departure day DD corresponding ight, hotel rooms type (BGHLFI) day AD < DD. one entertainment ticketassigned day AD < DD, client given oneentertainment ticket type. Given feasible package, client's utility defined1000 , travelPenalty + hotelBonus + funBonustravelPenalty = 100(jAD , IAD j + jDD , IDD j)hotelBonus = GHV client GBH, 0 otherwise.funBonus = sum relevant EV's entertainment ticket type assignedclient.TAC agent's final score simply sum clients' utilities minus agent'sexpenditures. Throughout game instance, must decide bids place28 auctions. end game, must submit final allocation purchasedgoods clients.client preferences, allocations, resulting utilities one particular gameTAC finals (Game 3070 TAC server) shown Tables 1 2.full details design mechanisms TAC server, see Wellman et al. (2001).3.ATTac-2000ATTac-2000 finished first Trading Agent Competition using principled biddingstrategy, included several elements adaptivity . adaptivity gave ATTac-2000exibility cope wide variety possible scenarios competition.section, describe ATTac-2000's bidding strategy, method determining bestallocation goods clients, three forms adaptivity. ATTac-2000's high-levelstrategy summarized Table 3.191fiStone, Littman, Singh, & KearnsClient12345678IADDay 2Day 1Day 4Day 1Day 1Day 2Day 1Day 1IDD GHV BEVDay 5 73 175Day 3 125 113Day 5 73 157Day 2 102 50Day 3 7512Day 4 86 197Day 5 9056Day 3 5079SEV TEV3424124 5712 1776749135 110859197 16292 136Table 1: ATTac-2000's client preferences game 3070. BEV, SEV, TEV EVsbaseball, symphony, theater respectively.Client12345678ADDay 2Day 1Day 3Day 1Day 1Day 2Day 1Day 1DDDay 5Day 2Day 5Day 2Day 2Day 3Day 5Day 2Hotel Ent'ment UtilityLFIB41175BGHB11138LFIT3, B41234BGHNone1102BGHS11110BGHB21183LFI S2, B3, T4 1415BGHT11086Table 2: ATTac-2000's client allocations utilities game 3070. Client 1's \B4"\Ent'ment" indicates baseball day 4.3.1 Bidding StrategyTAC defined simple enough low barrier entry, yet complexenough prevent tractable solution via direct game-theoretic analysis. Givenoptimal solution attainable, use principled approach takes advantagedetails TAC scenario. general, ATTac-2000 aims robust parameterspace defined TAC well conceivable opponent strategies.every bidding opportunity, ATTac-2000 begins computing profitableallocation goods clients (which shall denote G ), given goods currentlyowned current prices hotels ights. (See Section 3.3 caveat.)purposes computation, ATTac-2000 allocates, consider buying selling,entertainment tickets. cases, G computed using integer linear programming,described Section 3.2.ATTac-2000's high-level bidding strategy based following two observations:192fiATTac-2000: Adaptive Autonomous Bidding Agent1. auctions open:Obtain updated market prices.Compute G: profitable allocation goods given current holdingsprices.Bid 1 2 different modesPassive: bid keep options openActive: end, bid aggressively packages2. Allocate:Compute G closed auctions allocate purchased goods clients.Table 3: overview ATTac-2000's high-level strategy.1. Since airline prices periodically increase decrease equal probability, expected change price airline auction $0. Indeed, shownairline auction considered isolation, waiting end gamepurchase tickets optimal strategy (except rare case price reacheslowest allowed value).2. Since hotel prices monotonically increasing, game proceeds, hotel pricesapproach eventual closing prices.Therefore, ATTac-2000 aims delay purchases, particularly airlinepurchases, late game. ATTac-2000's high-level bidding strategy basedpremise best delay \committing" current G long possible.Although continually reevaluates G, therefore never technically committedanything, markets rarely advantageous change client's travelpackage would mean wasting airline ticket expensive hotel room (thus requiringadditional ones purchased).ATTac-2000 accomplishes delay commitment bidding two different modes:passive active. passive mode, lasts game, designed keepmany options open possible. passive mode, ATTac-2000 computes averagetime takes compute place bids, Tb (Tb average time takes goone iteration loop step 1 Table 3). found Tb ranged 10seconds well minute, primarily dependent upon server's load. Calltime left game Tl . Tl 2 Tb , ATTac-2000 switches active mode,buys airline tickets required current G places high bidsrequired hotel rooms. Note ATTac-2000 expects run 2 bidding iterationsactive mode. fact, 1 iteration necessary, huge cost failingcomplete iteration end game. Planning 2 active iterations leavesroom error.Based current G , current mode, Tl, ATTac-2000 bids ights, hotelrooms, entertainment tickets.193fiStone, Littman, Singh, & Kearns3.1.1 Flightspassive mode, ATTac-2000 bid airline auctions. active mode,ATTac-2000 buys currently unowned airline tickets needed current G.cases, means bids airline tickets first bidding opportunityactive mode. However, face drastically changing (hotel entertainmentticket) prices, G could change suciently necessitate purchasing additional ights, instead simply using ones already purchased.3.1.2 Hotelspassive mode, ATTac-2000 bids hotel auctions either try win hotelscheaply auction close early, try prevent hotel auctions closingearly. might advantageous prevent hotel auction closing roomscurrently desired order keep open option switching hotel futuremarket prices warrant it.hotel room type (such \Grand Hotel, night 3"), let Hi numberrooms type needed G . Based current price i, Pi , ATTac-2000 triesacquire n rooms8>>< max(8Hi; 4)n = > max(H ; 2)>: max(Hi; 1)Pi = 0 (only true outset game)Pi 10Pi 20Pi 50:ATTac-2000's outstanding bids would already win n rooms auction closecurrent price, ATTac-2000 nothing: auction close prematurely,ATTac-2000 wins n rooms cheaply, competitors lose opportunity getrooms type later game. Otherwise, ATTac-2000 bids n rooms $1current ask price. formula computing n selected risk wasting$40{$50 per room type benefit maintaining exibility later game.exact parameters chosen ad-hoc fashion without detailed experimentation.intuition ATTac-2000's performance sensitive exact values.active mode, ATTac-2000 bids hotel rooms based marginal value withinallocation G . Let V (G ) value G (the income clients, minus costyet-to-be-acquired goods). Let G0c optimal allocation client c fail gethotel rooms. Note G0c might differ G distribution entertainmenttickets well ights hotels client c. ATTac-2000 bids hotel roomsassigned client c G price V (G ) , V (G0c ). Since point ightssunk cost, price tends $1000.Notice ATTac-2000 bids full marginal utility hotel room requiredclient's travel package. alternative would divide marginal utilitynumber rooms package, would eliminated risk spendinghotels itinerary worth. hand, failing win single hotelroom enough invalidate entire itinerary. ATTac-2000 bids full marginal utilitymaximize chance valid itineraries obtained clients. combinatorial194fiATTac-2000: Adaptive Autonomous Bidding Agentauction, bidder would able place bid conjunction desired roomswould therefore need choose two alternatives.3.1.3 Entertainment TicketsATTac-2000's bidding strategy entertainment tickets hypothesizesticket, opponent buy (sell) price remains constant course single game(but may vary game game). avoid underbidding (overbidding)price, ATTac-2000 gradually decreases (increases) bid course game.initial bids always optimistic possible, end game, ATTac-2000willing settle deals minimally profitable. addition, strategy serveshedge ATTac-2000's early uncertainty final allocation goods clients.every bidding iteration, ATTac-2000 places buy bid type entertainmentticket, sell bid type entertainment ticket currently owns. cases,prices depend amount time left game (Tl), becoming less aggressivetime goes (see Figure 1).Buy value200}$50Bid Price ($)Owned, unallocatedsell value}$20100Owned,allocatedsell value$300510Game Time (min.)15Figure 1: ATTac-2000's bidding strategy entertainment tickets. black circles indicate calculated values tickets ATTac-2000. lines indicate bidprices corresponding values. example, solid line (which increasestime) corresponds buy price relative buy value. Correspondence text lines indicated similar line types boxessurrounding text.owned entertainment ticket E , E assigned G, let V (E ) valueE client assigned G (\owned, allocated sell value" Figure 1).ATTac-2000 offers sell E min(200; V (E ) + ) decreases linearly 10020 based Tl.1 current bid price greater resulting sell price,ATTac-2000 raises sell price 1 cent lower current bid price order gethigh price possible.E owned assigned G (because clients either unavailable nightalready scheduled type entertainment G ), let V (E ) maximum value1. Recall $200 maximum possible value E client TAC parameters.195fiStone, Littman, Singh, & KearnsE clients, i.e. greatest possible value E given client profiles (\owned,unallocated sell value" Figure 1). ATTac-2000 offers sell E max(50; V (E ) , )increases linearly 0 50 based Tl . again, ATTac-2000 raises pricemeet existing bid price greater target price. strategy ectsincreasing likelihood game progresses G close final clientallocation, thus currently unused tickets needed end.active mode, ATTac-2000 assumes G final offers sell unneeded tickets$30 order obtain least value (represented discrete pointbottom right Figure 1). $30, ATTac-2000 would rather waste ticketallow competitor make large profit.Finally, ATTac-2000 bids buy type entertainment ticket E (includingalso offering sell) based increased value would derived owningE . Let G0E optimal allocation would result E owned (\buy value"Figure 1). Note G 0E could different ight hotel assignments Gmake effective use E . Then, ATTac-2000 offers buy E V (G0E ) , V (G) , ,decreases linearly 100 20 based Tl.parameters described section chosen arbitrarily without detailedexperimentation. intuition that, unless opponents know explicitly exploitvalues, ATTac-2000's performance sensitive them.3.2 Allocation Strategyevident Section 3.1, ATTac-2000 relies heavily computing currentprofitable allocation goods clients, G . Since G changes prices change, ATTac-2000needs recompute every bidding opportunity. using integer linear programmingapproach, ATTac-2000 able compute optimal final allocations every game instancetournament finals|one 2 entrants so.2TAC participants used form greedy strategy allocation (Greenwald& Stone, 2001). computationally feasible quickly determine maximum utilityachievable client 1 given set purchased goods, move client 2 remaininggoods, etc. However, greedy strategy lead suboptimal solutions. example,consider 2 clients B identical travel days IAD IDD well identicalentertainment values EV , A's GHV = $50 B 's GHV = $150. agentexactly one type hotel room day, optimal assignment clearlyassign BGH client B . However, client A's utility optimized first,assigned BGH, leaving B stay LFI. agent's resulting score would 100 lesscould been.improvement basic greedy strategy, implemented heuristic approachimplements greedy strategy 100 random client orderings choosesprofitable resulting allocation. Empirically, resulting allocation often optimal,never far optimal. addition, always quick compute. set sevengames tournament, greedy allocator run approximately 600times produced allocations averaged 99.5% optimal value.2. computed Shou-de Lin TAC organizing team.196fiATTac-2000: Adaptive Autonomous Bidding Agentcompetition drew near, however, became clear every point would count.therefore implemented allocation strategy guaranteed find optimalallocation goods.3 integer linear programming approach used ATTac-2000 worksdefining set variables, constraints variables, objective function.assignment variables represents allocation clients constraintsensure allocation legal. objective function encodes fact seekallocation maximum value (utility minus cost).following notation needed describe integer linear program. formal notation included completeness; equivalent English description follows equation.symbol c client (1 8). symbol f feasible travel package,consists of: arrival day AD(f ) (1 4); departure day DD(f ) (2 5),choice hotel H (f ) (BGH LFI). 20 travel packages. Symbol eentertainment ticket, consists of: day event D(e) (1 4),type event (e) (baseball b, symphony s, theater t). 12 differententertainment tickets. Symbol r resource (AD, DD, BGH, LFI).Using notation, 272 variables are: P (c; f ), indicates whether client callocated feasible travel package f (160 variables); E (c; e), indicates whether clientc allocated entertainment ticket e (96 variables); and, Br (d) number copiesresource r would like buy day (16 variables).also several constants define problem: (d) number ticketsresource r currently owned day d, pr (d) current price resource r day d,(c; f ) utility customer c travel package f , uE (c; e) utility customerc entertainment ticket e.Given notation, objective maximize utility minus costXc;f(c; f )P (c; f ) +,,Xd2f2;3;4;5gXc;euE (c; e)E (c; e)pDD (d)BDD(d)Xd2f1;2;3;4g;r2fBGH;LFI;ADgpr (d)Br (d)subject following 188 constraints:c, Pf P (c; f ) 1: client gets one travel package (8 constraints).2 f1; 2; 3; 4g,X Xc f jAD(f )=dP (c; f ) oAD (d) + BAD (d);2 f1; 2; 3; 4g h 2 fBGH; LFIg,XXP (c; f ) oh (d) + Bh (d);c f jH (f )=h & AD(f )d<DD(f )3. general allocation problem NP-complete, equivalent set-packing problem (Garey &Johnson, 1979). Exhaustive search computationally intractable even 8 clients.197fiStone, Littman, Singh, & Kearns2 f2; 3; 4; 5g,X Xc f jDD(f )=dP (c; f ) oDD (d) + BDD (d) :demand resources selected travel packages must exceed sumowned bought resources (16 constraints).e, Pc E (c; e) oE (e): total quantity entertainment ticket allocatedexceed owned (12 constraints).c e, Pf jAD(f )D(e)<DD(f ) P (c; f ) E (c; e): entertainment ticketused day arrival departure day selected travelpackage (96 constraints).c 2 f1; 2; 3; 4g, PejD(e)=d E (c; e) 1: client use oneentertainment ticket per day (32 constraints).c 2 fb; s; tg, PejT (e)=y E (c; e) 1: client use typeentertainment ticket (24 constraints).variables integers.solution resulting integer linear program value-maximizing allocationowned resources customers along list resources need purchased.Using linear programming package \LPsolve", ATTac-2000 usually able findglobally optimal solution one second 650 MHz Pentium II.Note means possible formulation allocation.Greenwald, Boyan, Kirby, Reiter (2001) studied variant found performedextremely well collection large, random allocation problems.approach guaranteed find optimal allocation, usuallyquickly. However, since integer linear programming NP-complete problem, inputslead significantly longer solution times. sample 32 games taken shortlyfinals, allocator called 1866 times. 93% cases, optimization tooksecond less. Less 1% took 6 seconds. However, 3 longest running timesminute came game. ATTac-2000 used strategyinteger linear program takes 6 seconds solve, above-mentionedgreedy strategy random client orderings used fall-back strategy restgame. fall-back strategy needed tournament finals.3.3 AdaptivityTAC game instance, information available agents ask prices|individual bids visible. game, transaction-by-transaction data available,lack within-game information precluded competitors using detailed modelsopponent strategies decision making. ATTac-2000 instead adapts behavior on-linethree different ways: adaptable timing bidding modes; adaptable allocation strategy;adaptable hotel bidding.198fiATTac-2000: Adaptive Autonomous Bidding Agent3.3.1 Timing Bidding ModesATTac-2000 decides switch passive active bidding mode basedobserved server latency Tb current game instance (see Section 3.1).3.3.2 AllocationATTac-2000 adapts allocation strategy based amount time takesinteger linear programming approach determine optimal allocations current gameinstance (see Section 3.2).3.3.3 Hotel BiddingPerhaps significantly, ATTac-2000 predicts closing prices hotel auctions basedclosing prices previous games. Hotel bidding TAC particularly challengingdue extreme volatility prices near end game. stated Section 3.1.2,end game ATTac-2000 bids marginal utility desired hotel room,often excess $1000.preliminary competition, agents bid marginal utilities hotelrooms. did, however, generally dominated competitors; agentshigh-bidders, bidding $1000, always winning hotels bid, paying farless bids. observed dominant strategy preliminary rounds,agents, including ATTac-2000, adopted high-bidding strategy actualcompetition. result many negative scores, prices skyrocketed last momentsgame 16 high bids given room.Section 3.1, stated ATTac-2000 computes G based current priceshotel rooms. prices eventually become high, ATTac-2000 would eitherend paying high price hotel rooms else fail get travel packagesclients. alternative avoid counting obtaining contentioushotel rooms.Since strategies changing last minute finals, wayidentify priori hotels would contentious whether hotel prices wouldactually skyrocket tournament. Therefore, ATTac-2000 divided 8 hotel rooms4 equivalence classes, exploiting symmetries game (hotel rooms days 14 equally demand rooms days 2 3), assigned priorsexpected closing prices rooms, adjusted priors based observedclosing prices tournament.expected, Grand Hotel days 2 3 turned contentiousfinals. Le Fleabag Inn days also fairly contentious. Wheneveractual price hotel less predicted closing price, ATTac-2000 usedpredicted hotel closing price computing allocation values.One additional method predicting whether hotel prices would skyrocket givengame notice participants whether tended highbidders past games (see Figure 2). Although information available viaserver's API, game's participants always published beforehand TAC web page.automatically downloading information web (a practice whose ethicalityquestioned competition), matching precompiled database199fiStone, Littman, Singh, & Kearnsagents high-bidders past, ATTac-2000 would use predicted hotel closingprices games 3 high-bidders involved: games fewer high-bidders,prices hotel rooms almost never skyrocketed4 . turned out, one ATTac2000's games semi-finals, games finals, involved several high-bidders,thus triggering use predicted hotel closing prices.RiskPro grand day 2 recentaster grand day 22501400Aster: Grand Day 21200Bid Price ($)200Bid Price ($)1200RiskPro: Grand Day 2200150100100100080080060040040050200000100200300540050060010Game Time (min.)70080000900150100200530040050010600Game Time (min.)70080090015Figure 2: Graphs two different agents' bidding patterns many games. linerepresents one game's worth bidding single auction. Left: RiskPro neverbids $250 games plotted. Right: Aster consistently bids $1000rooms.Empirical testing (Section 4) indicates strategy extremely beneficial situations hotel prices indeed escalate, lead significantly degradedperformance not.4. ResultsTAC consisted preliminary round ran course week involvedroughly 80 games 22 participants. top 12 finishers invitedsemi-finals finals Boston, July 8th. Since agents conditionsconstantly changing, since 13 games played agent semi-finalsfinals, competition provide controlled testing environment.section, describe ATTac-2000's success tournament, also present empiricalresults controlled tests demonstrate effectiveness robustness ATTac-2000'sadaptive strategy.4.1 CompetitionATTac-2000's scores 88 preliminary-round games ranged ,3000 4500(mean 2700, std. dev. 1600). good score game instance 3000 4000 range.noticed many bad scores (12 less 1000 seven less 0).4. 2 high-bidders, way price escalate would bid combinedtotal 16 rooms hotel type. could happen clients stayhotel night, unlikely scenario given TAC parameters.200fiATTac-2000: Adaptive Autonomous Bidding Agentlargely result ATTac-2000 yet imbued adaptive timingbidding modes. preliminary round, ATTac-2000 shifted passive activebidding mode 50 seconds left game instance. 50 seconds usually plentytime allow least 2 iterations ATTac-2000's bidding loop,occasions network server lags would take 50seconds obtain updated market prices submit bids. case, ATTac-2000 wouldeither fail buy airline tickets, worse still, would buy airline tickets getfinal hotel bids time. Noticing server lag tended consistent withingame instance (perhaps due trac patterns generated participating agents),introduced adaptive timing bidding modes described Section 3.3.change, ATTac-2000 always able complete least one, usually two, biddingloops active bidding phase.adaptive allocation strategy never came play finals, ATTac-2000able optimally solve allocation problems came finalsquickly using integer linear programming method.However, adaptive hotel bidding play big role. ATTac-2000 performed wellbest teams early TAC games hotel prices (surprisingly) stayed low,out-performed competitors final games tournament hotelprices suddenly rose high levels. Indeed, last 2 games, popular hotelsclosed $400. ATTac-2000 steered clear hotel rooms effectivelyclosest competitors.Table 4 shows scores 8 TAC finalists (Wellman et al., 2001). ATTac-2000'sconsistency (std. dev. 443 opposed 1600 preliminaries) apparent: avoideddisastrous games, presumably due large part adaptivity regarding timinghotel bidding.Rank12345678TeamAvg. Score Std. Dev.ATTac-2000 3398443RoxyBot3283545aster3068493umbctac1 30511123ALTA21981328rajatish 18731657RiskPro15701607T111671593InstitutionAT&T Labs { ResearchBrown University, NASA Ames ResearchSTAR Lab, InterTrust TechnologiesUniversity Maryland Baltimore CountyArtificial Life, Inc.University TulsaRoyal Inst. Technology, Stockholm UniversitySwedish Inst. Computer Science, IndustilogikTable 4: scores 8 TAC finalists semi-finals finals (13 games).4.2 Controlled Testingorder evaluate ATTac-2000's adaptive hotel bidding strategy controlled manner,ran several game instances ATTac-2000 playing two variants itself:201fiStone, Littman, Singh, & Kearns1. High-bidder always computed G based current hotel prices (as opposedusing priors averages past closing prices).2. Low-bidder always computed G variant 1, also bid hotel rooms$50 current ask price (as opposed marginal utility, tended$1000).extremes, ATTac-2000 7 high-bidders playing, least one hotel priceskyrockets every game since agents bid high hotel rooms.hand, ATTac-2000 7 low-bidders playing, hotel prices never skyrocket sinceagents ATTac-2000 bid close ask price. goal measure whether ATTac2000 could perform well extreme scenarios well various intermediate ones.Table 5 summarizes results.#high agent 27 (14),6 (87),5 (84),4 (48),3 (21),2 (282),agent 3 agent 4 agent 5 agent 6 agent 7 agent 89526 |||||||||||||,!10679 ||||||||||,!138910310 |||||||,!, 265010005 ||||,!,|||| 40155067 ,!,||||||| 3639209,|||||||||| 2710Table 5: difference ATTac-2000's score scoreseven agents averaged games controlled experiment. differencesstatistically significant 0:001 level, except one marked italics.row corresponds different number high-bidders (excluding ATTac2000 itself). first column presents number high-bidders wellnumber experiments ran scenario (in parentheses). columnlabeled \agent i" shows much better ATTac-2000 average agent i.Scores stair-step line high-bidders (variant 1) scoresline low-bidders (variant 2). Results identical agents averagedobtain single average score difference type agent row.cases, ATTac-2000 beats agents.row Table 5 corresponds different number high-bidders game;example, row labeled 4 high-bidders corresponds ATTac-2000 playing4 copies variant 1 3 copies variant 2. Results identical agents averagedobtain single average score difference type agent row. firstcolumn, also show parentheses number games played resultsrow|each row ects different number runs. cases, ran enough game instancesachieve statistically significant results. However, cases ran instancesturned required. column labeled agent shows differenceATTac-2000's score score agent averaged games. scenarios,202fiATTac-2000: Adaptive Autonomous Bidding Agentdifferences positive, showing ATTac-2000 outscored agents average.5Statistical significance computed paired T-tests; results significant0:001 level except one marked italics. mentioned before, numberhigh-bidders greater equal 3, expect price contentious hotels rise,scenarios ATTac-2000 significantly outperforms agents.large score differences appearing top rows Table 5 mainly due factagents get large, negative scores since end buying many expensive hotelrooms.experiments, ATTac-2000 always uses adaptive hotel price expectations, even2 high-bidders. last row, number high-bidders 2,little bidding hotel prices expected case, get statisticalsignificance relative two high-bidders (agent 2 agent 3), since strategiesnearly identical ATTac-2000's case. get high statistical significance relativeagents (copies variant 2), however. Thus, ATTac-2000's adaptivityhotel prices seems help lot hotel prices skyrocket seemprevent ATTac-2000 winning average don't.results Table 5 provide strong evidence ATTac-2000's ability adapt robustlyvarying number competing agents bid hotel prices near end game.Note ATTac-2000 designed perform well itself. 8 copies ATTac2000 play repeatedly, favor hotel rooms thusconsistently get large negative scores. would interesting determine whetherexists strategy harmful ATTac beneficial adversary.5. Related WorkAlthough good deal research auction theory, especially perspective auction mechanisms (Klemperer, 1999), studies autonomous bidding agentsinteractions relatively recent. TAC one example. FM97.6 another auction test-bed, based fishmarket auctions (Rodriguez-Aguilar, Martin,Noriega, Garcia, & Sierra, 2001). Automatic bidding agents also createddomain (Gimenez-Funes, Godo, Rodriguez-Aguiolar, & Garcia-Calves, 1998).number studies agents bidding single good multiple auctions (Ito,Fukuta, Shintani, & Sycara, 2000; Anthony, Hall, Dang, & Jennings, ; Preist, Bartolini, &Phillips, 2001). Outside of, related to, auction scenario, automatic shoppingpricing agents internet commerce studied within simplified model (Greenwald & Kephart, 1999).Twenty-two agents 6 countries entered TAC, 12 qualified competesemi-finals finals Boston. designs agents motivatedwide variety research interests including machine learning, artificial life, experimentaleconomics, real-time systems, choice theory (Greenwald & Stone, 2001).approach motivated research interests multiagent learning (Littman,1994; Stone, 2000; Singh, Kearns, & Mansour, 2000). Based problem description,expected find several learning opportunities domain. noted above, detailed5. general, ATTac-2000's average score decreased increasing numbers high-bidders, gamesbecame volatile.203fiStone, Littman, Singh, & Kearnsopponent modeling precluded system dynamics. Nonetheless, ATTac-2000'sadaptivity one keys success, particularly avoiding skyrocketing hotels.2nd 3rd place agents used different strategy prepare possibilityskyrocketing hotels. Rather avoiding popular hotels entirely tracking closingprices across game instances, discouraged agents bidding manyparticular hotel room, thus spreading demand across rooms (Greenwald &Stone, 2001). strategy safer limit (i.e., continues work eveneveryone uses it), greater potential cost agent event hotel pricesskyrocket, since agent still distribute demand less desirable rooms.hand, ATTac-2000 would notice prices skyrocketing thusbid optimal travel packages given current prices.6. Conclusion Future WorkTAC-2000 first autonomous bidding agent competition. successful event, minor improvements would increase interest multiagent learningperspective.Currently, incentive buy airline tickets end game.price ights tend increase, supply limited, agents wouldbalance advantage keeping options open savings committingtravel packages earlier6 .information structure TAC setup impossible observebidding patterns individual agents games. Nonetheless, strategicbehavior individual agents often profoundly affected market dynamics|particularlyhotel auctions. seems would beneficial able directly observebehavior individual agent. information available regardingbidding behavior agents game (such agents could inferclients' preferences, therefore market supply, demand, prices), TAC agentswould potentially able learn predict market behavior game proceeds.without modifications, hope able participate future TACs,goal adding additional adaptive elements ATTac-2000.Another direction future research apply lessons learned TAC realsimultaneous interacting auctions. straightforward write bidding agents participate on-line auctions single good value client fixed ahead time:agent bid slightly ask price auction closes price exceedsvalue. However, values multiple goods interact, case TAC,agent deployment nearly straightforward.One real application Federal Communications Commission's auctioningradio spectrum (Weber, 1997; Cramton, 1997). Especially companies tryingachieve national coverage, values different licenses interact complex ways.Perhaps autonomous bidding agents able affect bidding strategies future6. change adopted specification TAC-01.204fiATTac-2000: Adaptive Autonomous Bidding Agentauctions. Indeed, related research begun path creating straightforward bidding agents realistic FCC Auction Simulator (Csirik, Littman, Singh, &Stone, 2001).obvious application, extended version ATTac-2000 could potentiallybecome useful real travel agents, end users wish create travelpackages.Acknowledgementswould like thank TAC team University Michigan, including Michael Wellman, Peter Wurman, Kevin O'Malley, Daniel Reeves, William Walsh, constructingTAC server responding promptly cordially many requests conducting research reported here. would also thank anonymous reviewershelpful comments suggestions.ReferencesAnthony, P., Hall, W., Dang, V. D., & Jennings, N. R. Autonomous agents participatingmultiple on-line auctions..Cramton, P. C. (1997). FCC spectrum auctions: early assessment. JournalEconomics Management Strategy, 6 (3), 431{495.Csirik, J. A., Littman, M. L., Singh, S., & Stone, P. (2001). FAucS: FCC spectrum auction simulator autonomous bidding agents. Proceedings Second International Workshop Electronic Commerce. appear. Availablehttp://www.research.att.com/~pstone/papers.html.Eisenberg, A. (2000). online auctions future, it'll bot vs. bot vs. bot. NewYork Times. August 17th.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: GuideTheory NP-completeness. Freeman, San Francisco, CA.Gimenez-Funes, E., Godo, L., Rodriguez-Aguiolar, J. A., & Garcia-Calves, P. (1998). Designing bidding strategies trading agents electronic auctions. ProceedingsThird International Conference Multi-Agent Systems, pp. 136{143.Greenwald, A., Boyan, J., Kirby, R. M., & Reiter, J. (2001). Bidding algorithms simultaneous auctions. Proceedings Third ACM Conference E-Commerce, p.appear.Greenwald, A., & Kephart, J. O. (1999). Shopbots pricebots. ProceedingsSixteenth International Joint Conference Artificial Intelligence, pp. 506{511.Greenwald, A., & Stone, P. (2001). Autonomous bidding agents trading agent competition. IEEE Internet Computing, 5 (2), 52{60.205fiStone, Littman, Singh, & KearnsIto, T., Fukuta, N., Shintani, T., & Sycara, K. (2000). Biddingbot: multiagent supportsystem cooperative bidding multiple auctions. Proceedings FourthInternational Conference MultiAgent Systems, pp. 399{400.Klemperer, P. (1999). Auction theory: guide literature. Journal EconomicSurveys, 13 (3), 227{86.Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning. Proceedings Eleventh International Conference Machine Learning,pp. 157{163 San Mateo, CA. Morgan Kaufman.Preist, C., Bartolini, C., & Phillips, I. (2001). Algorithm design agents participate multiple simultaneous auctions. Agent Mediated Electronic Commerce III(LNAI), pp. 139{154. Springer-Verlag, Berlin.Rodriguez-Aguilar, J. A., Martin, F. J., Noriega, P., Garcia, P., & Sierra, C. (2001). Towardstest-bed trading agents electronic auction markets. AI Communications.press. Available http://sinera.iiia.csic.es/~pablo/pncve.html.Singh, S., Kearns, M., & Mansour, Y. (2000). Nash convergence gradient dynamicsgeneral sum games. Proceedings Sixteenth Conference UncertaintyArtificial Intelligence (UAI), pp. 541{548.Stone, P. (2000). Layered Learning Multiagent Systems: Winning Approach RoboticSoccer. MIT Press.Weber, R. J. (1997). Making less: Strategic demand reduction FCCspectrum auctions. Journal Economics Management Strategy, 6 (3), 529{548.Wellman, M. P., Wurman, P. R., O'Malley, K., Bangera, R., Lin, S.-d., Reeves, D., & Walsh,W. E. (2001). trading agent competition. IEEE Internet Computing, 5 (2), 43{51.206fiJournal Artificial Intelligence Research 15 (2001) 383-389Submitted 6/01; published 11/01Research NoteFinding Path Harder Finding TreeChristopher Meekmeek@microsoft.comMicrosoft Research,Redmond, WA 98052-6399 USAAbstractconsider problem learning optimal path graphical model data showproblem NP-hard maximum likelihood minimum description lengthapproaches Bayesian approach. hardness result holds despite factproblem restriction polynomially solvable problem finding optimal treegraphical model.1. Introductionproblem learning graphical models received much attention within Artificial Intelligence community. Graphical models used represent approximate jointdistributions sets variables graphical structure graphical model represents dependencies among set variables. goal learning graphical modellearn graphical structure parameters approximate joint distribution data. note, present negative hardness result learning optimalpath graphical models.Path graphical models interesting class graphical models respect learning. due fact that, many situations, restricting attention class pathmodels justified basis physical constraints temporal relationships amongvariables. One example problem identifying relative positions locisegment DNA (e.g., Boehnke, Lange & Cox, 1991). addition, one might interestedobtaining total order set variables purposes visualization(e.g., & Hellerstein, 1999).main positive results hardness learning graphical models learningtree graphical models. presented maximum likelihood (ML) criterion(Edmonds, 1967; Chow & Liu, 1968) adapted Bayesian criterion Heckerman,Geiger, & Chickering (1995). Two NP-hardness results learning graphical modelsappeared literature. NP-hardness finding optimal Bayesiannetwork structure in-degree greater equal two using Bayesian optimalitycriterion (Chickering, 1996) problem finding ML optimal polytree (Dasgupta,1999).note, present proof hardness finding optimal path graphicalmodels maximum likelihood (ML) criterion, minimum description length (MDL)criterion, Bayesian scoring criterion. Unlike ML hardness result Dasgupta,provide explicit construction polynomial sized data set reduction and, unlikeBayesian hardness result Chickering (1996), use common \uninformative" prior.c 2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiMeek2. Optimal Graphical ModelsOne primary goals learning graphical model obtain approximate jointdistribution set variables data. note, focus directed graphicalmodels set discrete variables fX1 ; : : : ; X g. One component directed graphicalmodel directed graphical structure describes dependencies variables.directed graphical model represents family distributions factor accordinggraphical structure G directed graphical model, specifically,nP (X1 ; : : : ; X ) =GnP (X jpan=1G(X ))pa (X ) denotes possibly empty set parents vertex X graph G.subscript G omitted clear context. common methods guidingchoice distribution family distributions maximum likelihood estimationBayesian estimation. Given graphical structure set cases variables(also prior distribution distributions case Bayesian approach),methods provide approximate joint distribution. details graphical modelsestimation see Heckerman (1998).leaves open question one choose appropriate graphical structure. remainder section, present maximum likelihood (ML) criterion,minimum discrimination length (MDL) criterion, Bayesian criterion evaluatingdirected graphical models given set cases D. value variable X denotedx value set variables pa(X ) denoted pa(x ). number casesX = x pa(X ) = pa(x ) denoted N (x ; pa(x )) total numbercases denoted N .One important property common scoring criteria scores factor according graphical structure model. is, score graph G dataset written sum local scores variablesGScore(G; D) =X LocalScore(X ; pa(X )):local score variable X function counts X pa(X )data set number possible assignments variables X pa(X ). Thusstructure graphical model determines particular variables countsneeded computation local score variable.log maximum likelihood scoring criterion graphical modelScoreMLX LocalScore(G; D) =ML(X ; pa(X ))LocalScoreML(X ; pa(X )) = N H (X jpa(X ))(1)H (X jpa(X )) empirical conditional entropy X given parents,equalN (x ; pa(x )) N (x ; pa(x ))log:NN (pa(x ))( )XXi ;pa Xi384fiFinding Path Harder Finding TreeOne practical shortcoming ML score comparing two models graphicalstructure G G0 G contains proper subset edges G0 ML scorenever favor G. Thus, using ML score choose among models without restrictingclass graphical structures, fully connected structure guaranteed maximalscore. problematic due potential poor generalization error usingresulting approximation. problem often called overfitting. using principlebest restrict class alternative structures consideration suitablemanner.minimum description length score viewed penalized version MLscoreScoreDL(G; D) = Scorelog N(G; D)X LocalScoreML=2DL(G; D)LocalScoreDL(X ; pa(X )) =#(pa(X )) (#(X )2LocalScoreMLP1) log N(2)= (#(pa(X )) (#(X ) 1)) #(Y ) used denote number possibledistinct assignments set variables number assignments emptyset variables #(;) = 1. penalty term leads parsimonious models, thus,alleviating overfitting problem described above.Finally, Bayesian score requires prior alternative models and, model,prior distributions. commonly used family priors directed graphical models described Cooper & Herskovits (1992). approach, one assumes uniformprior alternative graphs, P (G) / 1, \uninformative" prior distributions.assumptions lead following scoring function;ScoreBayes(G; D) = log P (DjG) + log P (G)/LocalScore(X ; pa(X ))XBayesLocalScoreBayes(X ; pa(X )) =log(pa xi(#(X ) 1)!(#(X)1) + N (pa(x )))!)N (x ; pa(x ))!(3)xiAlthough apparent MDL score, Bayesian score also built-intendency parsimony alleviates problems overfitting. hardness resultspresented extended variety alternative types priors includingBDe prior empty prior model (see Heckerman et al. 1995).problem finding optimal directed graphical model given class structures G data problem finding structure G 2 G maximizes Score(G; D).385fiMeek3. NP-Hardness Finding Optimal Pathssection, consider problem finding optimal directed graphical modelclass structures restricted paths. directed graphical structurepath one vertex in-degree zero vertices in-degree one.show problem finding optimal path directed graphical model NP-hardcommonly used scoring functions described Section 2. demonstrate hardnessfinding optimal paths problem needs formulated decision problem.decision problem version finding optimal path directed graphical model followsoptimal path (OP) decision problem: path graphical modelscore greater equal k data set D?section prove following theorem.Theorem 1 optimal path problem NP-Hard maximum likelihood score,minimum description length score Bayesian score.prove this, reduce Hamiltonian Path (HP) decision problem OP decisionproblem.Hamiltonian path (HP) decision problem: Hamiltonian pathundirected graph G?Hamiltonian path undirected graph G non-repeating sequence verticesvertex G occurs path pair adjacent verticessequence edge G. Let undirected graph G = hV; E vertex setV = fX1 ; : : : ; X g edge set E .HP decision problem NP-complete. Loosely speaking, means HPdecision problem computationally dicult variety problems knownalgorithm exists runs time polynomial function size input.Theorem 1 indicates OP decision problem least dicult NP-completeproblem. information HP decision problem NP-completeness seeGarey & Johnson (1979).reduce HP decision problem G OP decision problem constructingset cases following properties;n#(X ) = #(X )(i)jLocalScore(X ; ;) = LocalScore(X ; ;) =(ii)LocalScore(X ; fX g) 2 fff; fi g(iii)jff<fijLocalScore(X ; fX g) = LocalScore(X ; fX g)(iv)LocalScore(X ; fX g) = fi iff fX ; X(v)jj386jjg2EfiFinding Path Harder Finding Treedata set, problem existence Hamiltonian path equivalentexistence path graphical model score equal k = + (jV j 1) fijV j = n number vertices undirected graph G. Thus, reduceHP problem OP problem one needs eciently construct polynomial sized dataset properties. words, construction, general HP decisionproblem transformed OP decision problem. size inputOP problem polynomial function size input HP problem,one find algorithm solve OP problem polynomial time NP-completeproblems solved polynomial time.construct data set graph G assuming variable ternary satisfycondition (i). pair vertices X X (i < j ) edge G,add following 8 cases every variable X (k 6= i; j ) zero.jkX1 : : : X0:::00:::00:::00:::00:::00:::00:::00:::01X X +1 : : : X10:::010:::010:::010:::020:::020:::020:::020:::0j1Xj11121222X +1 : : : X0:::00:::00:::00:::00:::00:::00:::00:::0jnpair vertices X X (i < j ) edge G, addfollowing 8 cases.jX1 : : : X0:::00:::00:::00:::00:::00:::00:::00:::01X X +1 : : : X10:::010:::010:::010:::020:::020:::020:::020:::0j1Xj11221122X +1 : : : X0:::00:::00:::00:::00:::00:::00:::00:::0jnset cases constructed described above, pairwise counts pair variablesX X connected edge GjXXj0120 4(n2 5n + 6) 4(n 2) 4(n 2)14(n 2)314(n 2)132387fiMeekpairwise counts pair variables X X connected edge GjXXj0120 4(n2 5n + 6) 4(n 2) 4(n 2)14(n 2)2224(n 2)22Condition (ii) satisfied marginal counts variable identical.two types pairwise count tables, thus, two values given typepairwise LocalScore. using two pairwise count tables Equations 1, 2, 3,one easily verify local scores two tables satisfy condition (iii). followssymmetry two types pairwise tables condition (ii) condition (iv)satisfied. follows construction condition (v) satisfied. Furthermore,set cases eciently constructed size polynomially boundedsize graph G proving result.4. Conclusionnote, show problem finding optimal path graphical models NPhard variety common learning approaches. negative result learning optimalpath graphical models stands contrast positive result learning tree graphicalmodels. hardness result highlights one potential source hardness. is,one make easy problem dicult choosing inappropriate subclass models.Perhaps, carefully choosing broader class models tree graphical models oneidentify interesting classes graphical models problem finding optimalmodel tractable.Another interesting class graphical models described note classundirected graphical models (e.g., Lauritzen, 1996). methods learning undirectedgraphical models closely related methods described Section 2. fact,case undirected path models, scoring formulas described Section 2 identicalcommon approaches. Therefore, NP-hardness result directed pathmodels presented note also applies problem learning undirected path models.Finally, important note good heuristics exist problem findingweighted Hamiltonian paths (Karp & Held, 1971). heuristics used identifygood quality path models rely fact optimal tree model easilyfound score least large path model.ReferencesBoehnke, M., Lange, K., & Cox, D. (1991). Statistical methods multipoint radiationhybrid mapping. American Journal Human Genetics, 49, 1174{1188.Chickering, D. (1996). Learning Bayesian networks NP-complete. Fisher, D., & Lenz,H. (Eds.), Learning Data, pp. 121{130. Springer-Verlag.Chow, C., & Liu, C. (1968). Approximating discrete probability distributions dependence trees. IEEE Transactions Information Theory, 14, 462{467.388fiFinding Path Harder Finding TreeCooper, G., & Herskovits, E. (1992). Bayesian method induction probabilisticnetworks data. Machine Learning, 9, 309{347.Dasgupta, S. (1999). Learning polytrees. Proceedings Fifteenth ConferenceUncertainty Artificial Intelligence, Stockholm, Sweden, pp. 134{141. Morgan Kaufmann.Edmonds, J. (1967). Optimum branching. J. Res. NBS, 71B, 233{240.Garey, M., & Johnson, D. (1979). Computers intractability: guide theoryNP-completeness. W.H. Freeman, New York.Heckerman, D. (1998). tutorial learning Bayesian networks. Jordan, M. (Ed.),Learning Graphical Models, pp. 301{354. Kluwer Academic Publishers.Heckerman, D., Geiger, D., & Chickering, D. (1995). Learning Bayesian networks:combination knowledge statistical data. Machine Learning, 20, 197{243.Karp, R., & Held, M. (1971). traveling-salesman problem minimum spanning trees:Part ii. Mathematical Programming, 1, 6{25.Lauritzen, S. (1996). Graphical Models. Oxford University Press.Ma, S., & Hellerstein, J. (1999). Ordering categorical data improve visualization.Proceedings IEEE Symposium Information Visualization, pp. 15{17.389fifffi! #"$ %'&)( *,+.-//!(102-34657-8:9;<=>? @A4:B/!(CED= %&@F( /:B/!(GIHKJMLONQPSRAPST:HKUVRXWZY[LOLV\]H)R_^#`aPSHbYcUVRXLO`VH)\]RedgfihHFW<NQPST:HKUTUkjQLVRXUOT:hS`mlnT:RXW:HFoFNVfihprq2s]t#uwvAxKq2vy{z|q$}K''?{:ffE_.::<:{A,6E,':]~,2{~i{{F2ffxKq}ffyprq$} s#uwffVq$}y7w7SF{<$K''?{:ffE_.::<:{A,6E,':]ZA]w?Ew?6<16?OE617?17ff'1E1!:<66F<:1EE{ff1!{?w6E6<11F1!6<ff6X:<XE?76E1X11:16<:)E1!:<)E6EE<!:<QEF6Qff< i. 1.7612.1.E166676E1$SX1.76E1$)1.F1!1$KE11c1<X16_716ff6.766E11g._ !.61E6?EQ176<i !iEOE6<:!11Q :_?1O?.1)66F1Q6 1! <K1ffw6K<6K1<E1!11.E61O61)1Q:1Q.E<<AK66 AK<K<1<6:6F1F1? 1ESE1!:<66ff<6<QQ16w1< :)6<1,E<7A6KE1! 1$E7!1EEfiffffw!"$#&%')(+*-,.%/,1023*465+7189*#:8;2<*#&0=*->71(+0@?A*237B%-CD7189E-0%,10%-2F*->G,10210%,.C.(H8;#:I$%715+,.%-4KJ%-#+L5)%L-0NMG,1*OCD0212186#+LAPQIRJSMUTWVXY(+0ZCD*?'),10(+0#&218;*#=*->[%-#&%')(+*-,W%$862%-#8;?'\*-,171%-#]7S'&,.*^CD021286#@%-#]_=I$JM`23_a23730?cb_-0d7R8;7Y8;2Z%-?*#+LA71(&0e73*5+L(+0237<'&,1*-f)490?2Z8;#cCD*?')5+71%718;*#&%-4g4;8;#&L5&8;23718;Cd2U%-#&hiI$JMV)"$CdCD*-,.h&86#+L73*j 89,.237kPmln-oalTWpqFrtsWu)v^w-xmsy=z{r}|z{~DWwax.~yez{~sH|dzW$dwxAsfizr]s-rsdx3dzs-1|Hx3ddx3drtW.w-r&!s-z{r&zr]kddDxADzQ~NwmA|z{~Ds-Adz&s-Qz{r^izrdwxWAs-Qzwr+yRxms-v+DxAv^sr.dz{r]i9.-z.swxutv^wr[QzQWs{~.vawxdx!w~DwAdr)QzQw-xNDrtQzQz!~Az{rHvaA.u+.!s-Qzwrvas-va@x1DDzdx/wm/v+c|z{~D.w-^xW~dz{WsD;!wH|z{~DsfiDx1Dzs-iva/x3ddx3drtWisrt|yevadx3fiDy|]dDxNz{r\Nva=z|Dr)QzQQw3kvaDrtQzQX (&0,10d>{0d,.0#&CD073*%-#H0#]71897_P0-VL+V9b%'&,1*#&*5&#tTR8;2BL-0#+0d,W%-4;49_Cd%-46490hH%-#}srtsu)v^wxb71(+00#]71897_73*R(&8;C.(71(+0%-#&%'t(+*-,k,10d>0d,.2=8;2k89712x3ddx3dr)Qb%-#&h71(&0'&,10dEa89*5&2e,10d>{0d,.0#&CD073*71(+0/21%-?A00#]71897_8;2$71(+0A%-#&%'t(+*-,2sr).W1|]Dr)QV+*-,k86#&2371%-#&CD0-bg8;#:71(+02371%730?A0#7}awvrks-/srsWuut;@mFGs~var]xW[Wb)71(+0e'&,1*#&*5&#va@8;271(+0k%-#)%')(+*-,<%-#&h71(&0k#+*5&#+wvrH8;2Z71(&0e%-#730CD0h+0#]7dV"$#%-#&%')(+*-,.86CY'&,1*-ft490?Cd%-#f\0Fh+021CD,.89f\0h/%-2U4;_^8;#&L=23*?0dR(+0d,10$f[0d70d0#71(+0F,1021*4;5+7189*#%-#&h71(+0FL-0#+0d,.%718;*#*->%-#&%')(+*-,W%ab^71(&0$>*-,.?0d,730d,.?f\08;#&Lk71(+0Fh&8;21%f)f&,10dEa8;%718;#+Le*->S71(+0F,10d>0d,10#&CD0B%-#&hUG6 fi-//!(] w %% !@6X@ :]!fi>iw=! %&% &:%2% : @fii{9 ] DA22{~i{71(+0c4;%73730d,Af\08;#&L71(+0c%f&f),10dE^86%718;#+L:>{*-,.?*->$71(+0,10d>0d,10#&CD0c73*%-#0#]71897_-VXY()8;2k't%'[0d,N>*^Cd5)23020D+Cd4;5&2189E-04;_*#`71(+0,.023*4;5+7189*#*->Y%-#&%')(+*-,.%%-#&h#&*-7k*#71(&089,kL-0#+0d,W%7189*#Vi"$#&%')(+*-,.%Cd%-#f\0Cd4;%-212.8)0h8;#}?A%-#_h&89[0d,10#]7A%_a2dbYh+0d'\0#&h&86#+LH5+'\*#71(+0i')%,.718;Cd5&4;%,CD,W89730d,.8;%*#+0:C.(+*^*2302/73*0?')4;*_-VY0dL%,Wh&8;#+L71(&0i0490?0#]771(&%7Cd%,1,.8;02A*5+7A71(&0,10d>0d,10#&CD0P71(+0%-#&%'t(+*-,TWbZ>*-,0D+%-?NO')490-btCd490%,$h)8;23718;#&CD718;*#&2Z21(+*5&46hf[0=?A%-h+0ef\0d7U0d0#:'&,1*#+*?8;#&%-4%-#&%')(&*-,.%abt%-h30CD7189E%-4%-#&%'t(+*-,.%abh+0Dt#)89730Ah+021CD,.8;'&7189*#&2db*#+0DO%-#&%')(+*-,W%ab215&,1>%-CD0DOCD*5)#7@%-#&%')(+*-,.%abE-0d,1f)%-49O!')(+,.%-230A%-#)%')(+*-,.%abK%-#&h718;?0/%-#&htfi*-,N49*^Cd%718;*#,10d>0d,10#&CD02dVcXY()8;2B')%'\0d,e>*^Cd5)2302k*#71(+0,.023*4;5+7189*#*->U'),1*#+*?A8;#)%-4%-#&h%-h30CD7189E%-4g%-#&%')(+*-,W%aV (7/8;2A<8;h+049_%L-,10d0h71(&%771(+0'&,1*aCD0212*->B,1021*49E^86#+L%-#&%')(+*-,W%8;##&%715&,.%-4Y4;%-#+L5)%L-0730Da712?A%_if\0@215&'&'\*-,1730hif^_%/E%,.8;0d7_i*->G2173,.%730dL8902F71(&%7$0?')49*fi_h&8\0d,10#]7<a8;#&h&2<*->a#+*<4;0h+L-0-VB_h&8\0d,10#]7<a8;#&h&2Y*->^#+*fi<490h+L-0=0N?0%-#71(+0kE%,.89*5)2<23*5+,WCD02<*->G86#+>{*-,W?A%7189*#i5&2.5&%-4;49_0?')49*fi_-0h>*-,%-#&%')(+*-,.%F,.023*4;5+7189*#gb8;#&Cd4;5&h)8;#+L<?*-,.')(+*49*-L8;Cd%-4a%L-,10d0?A0#7dba23_a#71%-CD718;CY')%,.%-4;490468;21?cb230?A%-#]718;C8;#+>*-,.?A%718;*#b+h&8;21CD*5+,W230B2373,.5&CD715+,.0-b+73*-')8;Cd%-4a#+*R490h+L-0-b)%-#&h23**#VI$%715+,.%-44;%-#+L5&%L-0/'&,1*aCD021218;#+LPQI$JMTWbS%-#&hgb23'\0Cd8[Cd%-4;49_-b%-#&%'t(+*-,.%c,1021*4;5+7189*#b5&2302=?A%-#_,1023*5&,.CD02<%-#&h23*5+,.CD02<*->8;#+>*-,.?A%7189*#>*-,$7U*,10%-23*#)2dpFPmlTY#]5)?0d,1*5&2<,1023*5+,.CD02R%,10=%E%-864;%f)49073*71(&0=21Cd890#]718tC=CD*?A?@5&#&897_t[%-#&h`PT<(]5)?A%-#&2Y0?A')49*_c?A%-#]_i23*5+,WCD02<*->8;#&>{*-,.?%7189*#i8;#c*-,Wh+0d,73*A,1021*49E-0kh&8\0d,10#]7Y4;8;#+L5)8;23718;C<')(+0#+*?0#)%aV0Y'),10230#]7K%-#%-49L-*-,.8971(&?71(&%7CD*^*-,.h&86#&%7302h&8\0d,10#]7>*-,.?A2K*->[a#+*<4;0h+L-0f]_@h&8;23718;#&L5&8;21(&86#+Lf\0d7U0d0#4;8;#+L5&8623718;C@^#&*<490h&L-0:PQCD*#&2373,W%-8;#712@%-#&h`'&,10d>0d,10#&CD02WTe%-#&hh)8;%-49*-L5+0DO2373,W5&CD715+,10Aa#+*fi<4O0h+L-0PQ%-#&%'t(+*-,.8;C@%-CdCD0212189ft8;4;897_23')%-CD0fiTWV@XY(+0%-49L-*-,.8971()?86h+0#7189)02$71(+0#+*5&#:')(+,.%-210=73*c<()8;C.(%71(&89,WhaO!'\0d,.23*#'\0d,.21*#&%-4G*-,h+0?A*#&2373,.%7189E-0'&,.*#+*5&#`*-,N%-hm0CD7189E%-4%-#&%')(+*-, - ,10d>0d,.2N8;#%^')%-#aO8;21(h&86%-49*-L5+0-V 0ACd%-4;471(&862$%-4;L-*-,.8971(&?"$<F8YPQ%-#&%')(+*-,W%/,.023*4;5+7189*#8;#h&86%-49*-L5+02WTWVk"$<F8K%-28;?'t490?0#]730hc8;#cM,1*4;*-L+V#^0CD7189*#f\049*ebU0'&,10230#]7N,104;%730hU*-,1*#%-#&%'t(+*-,.%:,1023*4;5&7189*#`86#h)8;%-49*-L5+02dV #^0CD7189*#^bU0215+L-L-0217=%-#%-#)#+*-71%7189*#2.C.(+0?0>{*-,kCd%')715+,.8;#+La')%-#&8;21(h&86%-49*-L5+0A2373,.5)CD715+,10-V #^0CD7189*#N+b%-#%-CdCD02.2189f)8;46897_e23't%-CD0Uft%-230hN*#@71(&8;2K%-#&#+*-71%7189*#2.C.(+0?0Z8;2Kh+0D[#+0hV #A^0CD7189*#A^b-U0'&,10210#7R71(+0@%-4;L-*-,.8971(&?"RR$8!V<K8;#&%-4;49_-b[%-#0Da'\0d,.8;?0#]71%-421715&h+_*->71(+0@%-49L-*-,.8971(&?8;2<'&,10230#]730h8;#^0CD718;*#^VK) {[ Ui-G g+*-,G%-#)%')(+*-,.%F,1021*4;5+7189*#N8;#Nh&8;%-4;*-L5+02db%F'&,1*4689>{0d,W%7189*#k*->[?0d71(+*ah&2Kf)%-230hN*#h&8;%-49*-L5+02373,.5)CD715+,10PQh&8;2.CD*5+,.230DO!*-,.8;0#730h/%'&'&,1*%-CW(+02WTG(&%E-0$f\0d0#h+0dE-049*-'\0hV"$?*#+L@71(+0230-b^0$21(+*5&46hA4;89-0Y73*@023'\0DOCd8;%-4;4;_N%-C.^#&*<490h&L-0$71(&0<U*-,1A*->S$,1*21NPmln-]bgln-oalTWb&8;#<(&8;CW(A71(+0F8;#a[5+0#&CD0Y*->gh&86%-49*-L5+0R2173,.5&CO715+,108;#H%-#)%')(+*-,.%,1023*465+7189*#8;215&23718)0hgVN$,1*21-2B*-,.>*^Cd5)2302B23'\0Cd8tCd%-4;4;_i*#71%-23]O!*-,.890#]730hh&8;%-4;*-L5+02dV$71(&0d,k23715&h&8;02db215&CW(%-2k71(+*230A')5&f)4;8;21(&0hf^_$,1*23:$s-Pmln-o-^bln-n-TWb'&,10230#]7k%CD0#]730d,.8;#+L>,.%-?0dU*-,1%-2%?*^h&0473*0Da')4;%-8;#71(+0CD*(+0d,10#&CD0i*->B49*aCd%-4Yh&8621CD*5+,.230i210dL?0#712/8;#<(&86C.(71(+021'[0%-0d,2e>*^Cd5&2F*->Z%73730#]7189*#8;2F,104;%730hH73*,10d>0d,1,.8;#+L0Da'&,10212.89*#&2dVXY(&862B?*^h&04(&%-2%-C.()890dE-0hc215&CdCD02121>5&4),10215&4;7128;#%-#&%')(&*-,.%k,.023*4;5+7189*#/8;#?*#+*49*-L5+02b]f)5&7U*5&4;h,10]5)89,10RCD0d,.71%-8;#?*ah&8tCd%718;*#&2$73*if\0N2.5&CdCD02123>Q5&4;49_%'&')4;890h:73*ih&86%-49*-L5+02dV"$49*#+L71(+*230468;#+02dbU_],.*#%-#&h^730#]7&NY1Yfi3.UmDm=g!A!ZW[m!WWgWfiW-mmWY!N.-31!3 ZQff! fififiRBW WW!! 3 i3.-k! 3/!AW!fiRd!/ c!fi= W Wm$[=. .!3WfiWfiA m!WW Wfi.U=!A "fi ..$g!Y![W#$&%U Z!3('fiWfi Zfi )% *,+-#/.0#13254!%ff+6%87ff9-#$%;:=<1?>fi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22Pmln-n-oT(&%E-0h&0dE-049*-'\0hk0Da730#&2189*#)2*->+71(+0CD0#]730d,.8;#+LF?0d71(+*ahk>*-,K%'&')4;8;Cd%718;*#e73*Fh&8;%-49*-L5+02VSXY(+0d_CD*#&Cd4;5)h+0B71(&%7<CD0#]730d,.8;#+LA862Y%-2YCD*#&218623730#7R8;#ch&8;%-49*-L5&02Y%-2Y897Y8;2<8;#c?*#+*49*-L5&02dVIR0dE-0d,171(+04902.2dbS%-CdCD*-,.h)8;#+Lc73*^73,.5&f[0N%-#&h j %-(&#}Pmln-n-nTWb71(+0ACD,.5&Cd86%-4K'[*86#7F*->U71(+0ACD0#730d,W8;#+L?*ah+048;2e71(+0Cd%-#&h&86h&%7304;8;217dV$,1*23dFsPmln-n-T=2371%730/71(&%7k71(&862e4;8;237B?A%_Hf\0*-,.h+0d,10h5)218;#+Lh&8\0d,10#]7=>Q%-CD73*-,.2dbf)5+7@71(+0d_*#)49_5&230c8;#&>{*-,.?%7189*#`%f\*5+7@L-,.%-?A?%718;Cd%-4,1*4902dV j *U0dE-0d,bZ897N8;2h&;8 KCd5&497F73*h+0Dt#&0AL-,.%-?A?A%7186Cd%-4,1*4902k8;#H>,10d0DO!*-,WhaO!*-,.h+0d,k46%-#+L5&%L-02@4;89-0/$0d,.?%-#*-,@^'t%-#&8;21(<8971(&*5+7Z5&218;#+L230?%-#718;Ck8;#+>*-,.?A%7189*#V 4F#71(+0*-71(+0d,@()%-#&hb*-,1Cd%,.,.890h*5&7kf^G_ LGC1-0d,.7N%-#)h^73,.5&f[0:Pmln-n-nTe*# LG#&L4;8;21(h&0d71%-8;4;2%?0d71(+*ah>{*-,,.023*49Ea8;#+L'),1*#+*?A8;#)%-4%-#&%'t(+*-,.%8;#h&8;%-49*-L5&02=R8971(`%'),10Cd8;2189*#`*->$-^V N %-#&h%,10Cd%-4;4,W%730i*->F-o^V NVXY(&8;2N?0d71(+*ah8;2Nf)%-210h*#71(+0ih&8;2173,.89f)5+718;*#*->Fh&8;%-49*-L5+0c%-CD712/%-2A%-#%-49730d,.#)%7189E-0e73*A71(+0eCD0#]730d,.8;#&L?0d71(+*ahV&5&,171(+0d,.?*-,.0-Pb O:%,1?7 R Q #&0dDOU%,WCD*dGs9Pmln-n-nT0?')(&%-218;d0R71(+0B8;?A'[*-,.71%-#&CD0<*->h&8;21CD*5+,W230DO!73*-')8;Ca#+*<4;0h+L-0k%-2<%CD*?')490?0#]71%,1_c?0d71(+*ahi>*-,<%-#&%'t(+*-,.%,1021*4;5+7189*#i86#ch&8;%-49*-L5+02<8;#c<(&86C.(c215&CW(a#+*<4;0h+L-0e8;2Y#+0CD02.21%,1_>{*-,R49*#+LOh&8;2171%-#&CD0e%-#&%')(+*-,W%N,1023*4;5+718;*#VSKG ]{TMUG gffw+*-,N215&CdCD02121>5&4G%-#&%')(+*-,.%i,1023*4;5+718;*#8;#h&86%-49*-L5+02dbS0%-21215&?071(&%7k897k862e021230#]718;%-4G73*8;h+0#]7189>_h&8;%-4;*-L5+0R2373,W5&CD715+,10-VXY(+0d,.0d>{*-,10-b^U0R'&,.*-'[*210R%-#%-#&#+*-71%7189*#21CW(+0?0$>{*-,Y^')%-#)8;21(h)8;%-49*-L5+02G71(&%78;2Rf)%-230h:*#U*-,1Cd%,1,.8;0h*5+7Ff^_:F%-4;46%,.h+*HPmln-n-TWb<(+*%'&')468902Y71(+0N71(+0d*-,W8902$')5+7<>*-,1%,.h:f]_a%-C.^2NdsPmlnfi]T<CD*#&CD0d,.#&8;#&LPQCD*#E-0d,.2.%7189*#&%-4{TZ715+,.#aO!71%a8;#+L+V0i5&210%-#%-#&#&*-71%7189*#21C.(&0?0cf)%-230h*#71(+023071(+0d*-,W8902N>{*-,71(&,10d0c?A%-8;#`,10%-23*#&2dV`8;,.237db%-2B897F8;2F%L-0#+0d,.%-4K%'&'&,.*%-C.(H73*ch&8;%-4;*-L5+0@?A*^h+0468;#+L+b\897B8;2F%'&')4;8;Cd%ft490e73*i%-4;47_^'\02F*->h&86%-49*-L5+02db8;#&Cd465&h&8;#+L:f\*-71(71%-23]O!*-,.890#]730h%-#)h}8;#+>*-,.?A%718;*#aO!,10d73,.890dE%-4O!*-,.8;0#730hh)8;%-49*-L5+02dWV VU*#&230^5+0#]7149_-b71(+0N5&230=*->G215&CW(%?*ah+04S%-2F%/f)%-218;2<>{*-,Bh+0dE-04;*-')8;#+L/*5+,$%-#)%')(+*-,$,1023*4;5+718;*#i'&,1*aCD0h&5+,.0=%-4;49*fi<25&2B73*:%'&')49_71(+0A'&,.*^CD0h&5&,1073*%-#]_:7_]'\0A*->Zh+*?%-8;#bg71(^5&2e*\0d,.8;#&Li%-#%-h+E%-#71%L-0*E-0d,@'&,1*aCD0DOh&5+,.02kf)%-210h*#h&8;2.CD*5+,.230?*^h&04;2k23'\0Cd8[CA73*')%,1718;Cd5)4;%,=h+*?%-8;#&2dVH^0CD*#&hb71(&862=%-#&#&*-71%7189*#21CW(+0?0eCd%-#f\0R0%-2.8;49_%'&'t4;890hA73*A%-5&73*?A%718;CF'&,1*aCD0212302U<8;71(+*5+7?0d71%-4;8;#+L5)8;23718;CRCD*#&218;h+0d,W%7189*#&2dV"$4971(+*5+L(8;#*5+,ZU*-,171(+0B%-#&#+*-71%7189*#c71%-21/(&%-2f\0d0#'\0d,1>*-,.?0hf]_(&%-#&hba>*-,Yh&8;%-49*-L5&0DO!f)%-230h%'&')468;Cd%7189*#&286#<(&8;CW(A*5+,'&,1*aCD0h&5+,10Y?89L(7f\0Y0?kf\0h&h&0hP0-VL+V9b&8;#Ah&86%-49*-L5+0<?A%-#)%L-0?0#723_a2mO730?A2WTWb%-#&#&*-71%7189*#71%-21^2F?@5&237<f\0='[0d,.>{*-,.?A0hi%-5+73*?A%718;Cd%-4649_-VRK8;#&%-4649_-b&U0=%-#730h:73*f)%-230=*5+,*R#'&,.*^CD0h&5&,10Y*#23715&h&8902*->71(+0R8;#+t5+0#&CD0Y*->gh)8;%-49*-L5+0<2173,.5&CD715+,10<*#/%-#&%'t(+*-,.%e,.023*4;5+7189*#A71(&%7U0d,10kCd%,1,.8;0h*5+7Yf^_+*`Pmln-o-TWbtR(+*230k%'&'),1*%-C.(b&86#715+,.#b&8;2ft%-230hc*#i71()%7Y*->+%-C1a2@dsV"$CdCD*-,.h&8;#&L73*c71(&0230N71(+0d*-,.8902db71(+0Nf)%-218;C@5&#&897$*->CD*#]E-0d,.21%718;*#8;2$71(+0Awdbg<(&86C.(8;#+>*-,.?A271(+0i4;8623730#+0d,%f\*5+7A%-#%-CD7189*#bU,10^5+0237db^5+023718;*#bG0d71CXV O*E-02/%,10Cd%,1,.8;0h*5+7Nf]_?0%-#&2*->+Dx3srt~WZV Y:"R#)hc5+73730d,.%-#&CD02R%,103*8;#+0h73*-L-0d71(+0d,$73*Af\0CD*?0Qaxr+~WVa86#&CD0N*5+,B*-,.:%-2eh+*#&0A5&218;#+L23'\*--0#h&86%-49*-L5+02F71(&%7e(&%-hf\0d0#H73,W%-#&21CD,.89f\0hb\715+,W#&2B%,10%-#&#+*-71%730h8;#71(+0B730D^712<%-#&h5+73730d,.%-#&CD02Y%,.0eh+04;8;?A8;730hf^_71(+0e5)230F*->')5&#)CD715&%7189*#?A%,1a2*-,Zf]_71(+0@0#&h&2<*->715+,.#&2V<Y0%-h&86#+L/%')5&#&CD715&%718;*#?A%,.PV9\b [b ]9bSV9V9V T%-4;49*fi<2R5)2Y73*,10CD*-L#&89d0@71(+0@0#&h*->%-#i5+73730d,.%-#)CD0-VGXY(+0230k71%-23^2<h+*#+*-7Y%\0CD7<71(+0=%-#&%')(+*-,.%O!,.023*4;5+7189*#'),1*^CD02.2dV^-._Y1! mW\!B `afi! Ab! fi;\W?fi6WfiZ WmW ?Qm0\!Z?Q0\!W3c-G!mm1D!me!<R 16 U! B-m!!edfg6fi D6kW !mZ0dfg6fi m!W !mZ0]B3WUWfi!-!.)Y16D!m \h W8Y! !mgW!U\.i6fi Wm!Q! g!!1!3j lk?2m2=%"+-n$&opZ% k<fi W K WWd!<Yd!mGkqfi!fi{ .fi]W!WW r, m3.Ut!fi ."fi!1!sY16 fi !fimm.!K!mmt 3d uZ3g+-mD!fiv .mm?>fifffii{9 ] DA22{~i{"$2Y%,102.5&497db+U0e'&,1*-'\*230F71(+0e>*4;49*fi<8;#+L%-#&#&*-71%7189*#i21CW(+0?0e>*-,<h&8;%-4;*-L5+0e2373,.5&CD715&,10-p68 28;h+0#]718)0h`f]_%HC.(&%-#+L-0c*->F23'\0%-0d,A8;#71(+0ih&86%-49*-L5+0-U0%-C.(}CW(&%-#+L-0c*->F23'\0%-0d,'),10215+'&'\*2302<%/#+0d715+,.#gVRF#i71(&862<'\*8;#]7db)U0=?A%-0N%h&8;23718;#)CD7189*#cf\0d7U0d0#:7U*h&89[0d,10#]7a8;#&h)2*->S715+,W#&2dpw t}ffsyx wbz{{" # su}!|{usy{s t#}ffsWx0} w z 8;2*#+0R71()%7U%-h&h)28;#&>{*-,.?%7189*#73*N71(+0Fh&8;%-49*-L5+0-VGa5)C.($715&,.#&2ACD*#&217189715+730i<()%78;2Cd%-4;490hvaAutxz{Asx~~D wm.w-r&dx.~ds-QzQw-r&V^'\0%-0d,.25)23071(+089,c8;#]730d,1E-0#718;*#&273*'&,1*Ea8;h+08;#+>*-,.?A%718;*#71()%7>Q%-Cd8;4;8;71%730271(+0'&,1*-L-,10212*->71(&073*-'t8;C*->$CD*#E-0d,W21%7189*#V #]730d,1E-0#718;*#&2?A%_`f\0 'sq$=|{u)~Xx0} wc!z <(+0#71(+0d_>*-,.?@5&4;%7308;#]E^8971%718;*#&2db,10^5&89,10?0#]712dbZ*\0d,.2dbY,.0d'[*-,.712dbZ0d71CV9bR*-, }uq$y{s~x0} wzR(+0#71(+0d_%-#&23U0d,Z*-,Y0dE%-465&%730e71(+0F'&,10dEa89*5&2Z21'[0%-0d, Q2Y8;#]730d,1E-0#718;*#VK8;#&%-4;49_-ba71(+0d_Cd%-#c%-4623*=f\0 z|= u) su}!|{usy{s~x0} w J z b^<(&8;CW(/862%@,10%-CD7189*#71()%7f\0dL8;#&2U%-2Z%,.023'\*#&230@73*c71(+0N'&,10dEa89*5&2F23'\0%-0d,2B8;#]730d,1E-0#]7189*#b%-#&h:0#&h)2$%-2k%-#H8;#73,.*^h&5)CD7189*#*->#&0d8;#+>*-,.?A%7189*#gV" ys's]t#'s t#}ffsx w z ,10d'),10230#]712B%-#H0?'&7_715+,W#bg<(&86C.(8;2B^5&89730N7_^')8;Cd%-4*->%4;8;23730#+0d,BR(+*230A%-8;? 862B71(+0>*-,.?A%-4,1086#+>{*-,WCD0?0#7e%-#)hH,.%718tCd%718;*#H*->71(+0ACd%-237k*->CD*#]E-0d,.21%718;*#&%-4g,1*4;02dVUa5&CW(c8;#]730d,1E-0#718;*#&2<4;%-C.86#+>{*-,W?A%7189*#Vx z PQ%-4;21*}Cd%-4;490h ur #q2s2u T8;2i%210]5+0#)CD0*->=715&,.#&2c(+0%-h+0hf]_ %-#86#&89718;%7189*#`8;#]730d,1E-0#718;*#715+,W# P X Tk%-#&h0#)h+0hf^_%,10%-CD7189*#8;#]730d,1E-0#]7189*#715+,.# P X TWVX<(&8;2>{*-,W? *->=%-#&%')(&*-,.%ab$86#R(&8;C.( 71(+0H,.0d>{0d,10#)CD0%')'[0%,W2<8971(&8;# %-# %-h1%-CD0#&CD_ ')%-89,b%')'[0%,W2Z73*Af\0BE-0d,1_CD*?A?*#86#ch&8;%-49*-L5+02=PQ+*\bSln-o-TWV)q$usq2}xVXY(+073*-'t8;C?@5&237gf\0%<4;0Da8;Cd%-489730? 71(&%78;2,10d>0d,1,10hB73*R>{,.0]5+0#]7149_-V"RCdCD*-,.h)8;#+L73*Y*aC.()% Pmln-n-oTWb$>{*5&,>0%715+,102%,1071%-0# 8;#]73*`%-CdCD*5)#7c8;#}71(+02304;0CD7189*#}*->B71(&0f\0237Cd%-#)h&8;h&%730>*-,e%ch&8;21CD*5&,.230N73*-')8;CpF>,10]5&0#&CD_-bg0dE-0#h&862373,.89f)5&7189*#b)'\*218;7189*#:*->G),W237F73*--0#b%-#)h@210?A%-#7186C%-h+0^5&%-CD_-V"()89L(&49_F>,10]5&0#70490?0#]7S71()%7*aCdCd5+,.2K8;#]730#&218;E-049_e8;#@%<')%-2.21%L-0*->71(&0Rh&8;%-4;*-L5+0Yf)5+7Uh+*^02G#+*-7U%'&'\0%,>*-,49*#&L=2373,10d71CW(+028;2G#&*-74;89-04;_=73*@f\0<%eL-*^*^hC.(&*8;CD0>*-,h&8;21CD*5&,.23073*-'t8;CV #`71(+0c21%-?0U%_-bG#+08971(+0d,N8;2@%-#0490?0#]7@R(+*230/),.237@%'&'\0%,.%-#&CD0*aCdCd5+,.2$%4;*#+LA%_i>,1*? 71(&0kf\0dL8;#&#&86#+LN71(+0kf\0237<CW(+*8;CD0-qV O*-,10d*fiE-0d,b230?A%-#]718;Ck%-h+0^5&%-CD_?@5&237<f[0BCD*#&2.8;h+0d,10h>*-,<71(+0eCd%-#)h&8;h&%730-b)%-#)hc897Y?=5)237Zf\0e%-2123021230hf]_71(+0k%-#)#+*-71%73*-,Vw x wb xc} z%-230h`*#71(&0%f\*E-0DO?0#]7189*#+0h2373,.5)CD715+,10-b71(+0#b71(+0>*4;49*fi<8;#+Lc71%L2@%,10/CD*#)218;h+0d,10h#+0CO02121%,._i>{*-,Bh&86%-49*-L5+0=2173,.5&CD715+,10N%-#&#+*-71%718;*#p } w b } w b w b x b\%-#&h wb xc} VtXY(&0@"$M %-#&hXRFM V71%L2G<864;4^f[0Y5)230h73*=h&0Dt#+0Z71(+0<%-#)%')(+*-,.8;CZ%-CdCD02.2189f)8;46897_N23')%-CD0-b^%-#&hA71(+0<,10?A%-8;#&86#+LF71%L2<8;464f\0Z5&230h@73*B*-f&71%-8;#@71(+0Z%-h1%-CD0#&CD_@')%-89,.2dVXY(+0 X 71%L+b],10d'&,10230#]718;#+LF?A8a0hN8;#]730d,1E-0#718;*#&2db8;2B#+*-7B8;#)Cd4;5&h+0h:218;#&CD0?A89^0hH8;#]730d,1E-0#]7189*#&2BCd%-#Hf\0%-#&#+*-71%730h%-2 X ')4;5)2 X VNXY(&8;2$71%-238;2h+*#+0e86#71(+0k%-#&#+*-71%718;*#c')(&%-230-V"$#N0Da%-?A')490*->t%-#%-#&#&*-71%730hAh&8;%-49*-L5&0<8;71(=71%L2G8;2'&,10230#]730h8;#NK89L5+,10BlV #@71(+0Zh&86%-49*-L5+0-b71(+08;h+0#]718)0d,P!BMUT8;#&h&8;Cd%730271(+0U715+,.#e*->t%Y,.%-8;4;U%_eCD*?')%-#]_e0?')49*fi_-0d0-b%-#&hk71(+0U86h+0#7189)0d,U-P B&T8;#&h)8;Cd%730271(+0kCd4;8;0#7d2Z715&,.#VF#&0*->+71(+0?A*237S8;?A'[*-,.71%-#7%-h&E%-#]71%L-02K*->a71(&8;2%-#)#+*-71%7189*#@21C.(+0?A08;2S89712CD*?'t%7189f)8;4;8;7_$<8971(?*237*->+71(+0h&8;%-49*-L5&0DO%-#&#+*-71%7189*#@21C.(&0?02S5)230h=86#kh&8;%-4;*-L5+0G23_a23730?A2dVKIR*-718;CD0-b->{*-,8;#)2371%-#&CD0-b71(&%771(+0%-h3%-CD0#&CD_H't%-89,.2B21(+*fi71(+0A2.%-?0/2373,W5&CD715+,10A%-2k71(+0.w-r&dx.~ds-QzQw-rtss%'&')46890h73*i71%-23]O*-,.890#]730hAh&86%-49*-L5+02h+0Dt#&0h8;#N71(+0<h&86%-49*-L5+0Z2373,.5&CD715&,10Zf]b_ V%,.4;0d7371%/dKs9tPmln-n-TWV O*-,10d*fiE-0d,b^*5+,?>i>fi@ 2~,72 AK$)B!P8!Pp8P! "J!P-!P"J!P-)! "JP,! 8!p!P-!P"J!P-"J2B2{EDX<{$7GF7BEHK.{JI220;?6/iZJ$CA! "J!-a/", _!()?!)i!6a;_Zi// ai/!ZP&)?i3 :S<!&-!Z &e?& ! 05ie" &?a upimis?mseg ?-0?Z/Zrui&Ji/3iZc/?Z0a 3_i=3a0!Ziaai;((_p 0;(& q! _pi;!!5i gZ 0 //_ c3i s?i3a/=?upi\b p?m!!5i gi3c& /8b pimi!6i; =qc s(ffa &)u0a?;pc pcff&- /8/!=_ i(Z&//?i3a)i"a/ "ii&gi! p (& eiZ qq,g,6/!a!\?i3a !gi P,3caq?8?! p cff& ffi5p!?m!a-Zu0 0si&/ffii&0 = )a5ic !u r/:#w!c !u pau?ceg,=-&ip0&Z Zcagm5i 8!!q6&& 66sq, i6=? /i ff8/i ff?0)(i?a,; ??6/?i&igq(i ?qc66)ppZ!rp0bZZg/ii!3_!nWh\.m$W g fi3Yg!f j8;L5+,10AlpffLa%-?'t490F*->K%-#%-#&#+*-71%730hh)8;%-49*-L5+0B>,1*?wxut^~fiffWrdw &x3drRDxW~Dwr?>fii{9 ] DA22{~i{21CW(+0?0R862G%-4;23*@CD*?')%7189ft490Y<8971(A71(+*230$71(&%7%,10Rf)%-230h/*#5+73730d,W%-#&CD0R>Q5&#&CD718;*#&2db215)C.(%-2G71(+0R*#+0h+0Dt#&0h8;#A<e" OHaJf^_N"$4;490#/%-#&h V*-,10@Pmln-n-TWVUYe" OHaJ8;#&h)8;Cd%7302G(+*fi 5&73730d,.%-#&CD02%,10<,.04;%730h73*71(+0Nh&8;21CD*5+,W230kf^_?0%-#&2$*->SDwxGsx3|ksrt|:1sdfiGsx3|wwfizr]@^r[Qzwr+~WVeX<(+0@86#730d,1'),10d71%7189*#*->71(+0230e>Q5&#&CD7189*#)2f)5&8;4;h)2G71(+0e%-h3%-CD0#&CD_]O!')%-89,R2373,.5&CD715+,.0-V86#&%-4;49_-ba*5+,Y73*-'t8;CB2373,.5&CD715&,10B0Da()89f)8971271(+0F21%-?0F>0%715+,102%-271(+0NQxmsr&~DsQzQwrH2373,W5&CD715+,10R*-> V%,.4;0d7371%Gs9a*-,71(+0!s~.N9ddgh+0Dt#+0h/f]_"$4;490#c%-#&Eh V*-,10-V]gZ#ffU fi,%-230h5+'\*#i71(+0N%f\*E-0DO?0#]7189*#+0hH%-#)#+*-71%7189*#b%-#%-#&%')(+*-,W8;Ck%-CdCD0212.89f)8;4;8;7_c23')%-CD0N8;2R'&,1*-'\*230h>*-,=^')%-#&8;2.(8;#:*-,.h&0d,B73*i,1023*49E-0%-#&%'t(+*-,.2B8;#:71(+0>*-,.?*->U'[0d,W23*#&%-4'&,1*#+*5)#&2dbh+0?*#&2173,.%7189E-0'&,1*#&*5&#&2db+%-#&hi%-hm0CD7189E%-4g%-#&%'t(+*-,.2dVu)~E}ff/ys"$CdCD*-,.h&8;#+L73*+* Pmln-o-TWb71(+0At,.237e?0#]7189*#*->Z%,10d>{0d,.0#7@8;#%i230^5+0#&CD0/*->ZCD*#730Da712N8;2e'\0d,3O>*-,.?0h<8971(%>Q5&4;4K#+*5&#:')(&,.%-230-VN"<>730d,e71(&%7dbSf]_:5&218;#+L%-#%-#&%'t(+*-,B71(+0A23'\0%-0d,eh&8;21')4;%_a2F%-#5&#&h&0d,.2371%-#&h&86#+L71(&%7@210]5+0#)CD0/(&%-2@#+*-7kf\0d0#`Cd49*230hh+*<#gV 0%-21210d,17k71(&%7@7U*h&8\0d,10#7=230DO^5+0#&CD02=L-0#+0d,.%730?*237e*->Z71(+0%-#&%')(+*-,W2e73*f\0A>*5&#&h8;#h&8;%-4;*-L5+02dpk71(&0/%-h1%-CD0#&CD_H')%-89,@%-#&h71(+0N73*-')8;C@21CD*-'\0-VeXY(+0@>*-,.?0d,FL-0#+0d,.%7302B,.0d>{0d,10#)CD02F73*%-#]_4;*^Cd%-4K#+*5&#')(+,W%-230-b%-#&h:71(+04;%73730d,L-0#+0d,.%7302R,10d>0d,10#&CD02Z73*/71(+0e?A%-8;#73*-'t8;CB*->71(+0kh&8;%-4;*-L5+0-V%-230h*#i71(&8;2b+0e'),1*-'\*230B71(&%7Y71(+0=%-#&%')(+*-,.86CB%-CdCD0212189f)864;897_23')%-CD0e>*-,R%-#]_L89E-0#%-#)%')(+*-,?A%_f\0eh+0D[#+0hc%-2Z71(+0k210d7Y*->#&*5&#c')(+,W%-230271%-0#>,1*?cp{71(&0k%-h1%-CD0#&CD_')%-89,YCD*#]71%-8;#&8;#+L71(&0k%-#&%')(+*-,b+')4;5&2{71(&0k%-h1%-CD0#&CD_')%-89,Z'&,10CD0h)8;#+LN71(+0k%-h1%-CD0#&CD_')%-89,YCD*#]71%-8;#&86#+L71(+0k%-#&%'t(+*-,b+')4;5)2{%-#]_c%-h1%-CD0#&CD_')%-89,Y8;#&Cd465&h&8;#+L=71(+0k%-h1%-CD0#&CD_')%-89,YCD*#]71%-8;#&86#+L71(+0k%-#&%'t(+*-,b+')4;5)2{71(&0k#+*5&#')(&,.%-230B,10d'&,.0230#7186#+LN71(+0k?A%-8;#73*-'t8;CF*->K71(+0kh&8;%-4;*-L5+0-Vq2t y{z|qy uuwys}yiy ~q2v^ 0dE-0d,.%-4*-,.^2$%f\*5+7<%-5+73*?A%7186Ce73*-')8;C=h+0d730CD7189*#:(&%E-0@f\0d0#c')5+ft4;8;21(+0h! Y0d_a#&%,ePmln-n-nTWb#"*5aO?A%-#&2FPmln-nalTU*-, j 0%,.237ePmln-n]T$! V # O%,17?R Q #+0dDO%,.CD*ds9Pmln-n-nTU%-#%-5+73*?%718;C$73*-')8;C$h+0d730CO7189*#i%-4;L-*-,.8971(&? %-2R%'&')4;890h73*%-#)%')(+*-,.%N,1021*4;5+7189*#c8;2Y'&,10230#]730hVXY()8;2Z%-49L-*-,.8971()? 230490CD712<#&*5&#')(+,.%-2102ePQIRMTU*^CdCd5&,1,.8;#+LNf\0d>*-,10e%-#i%-#&%')(&*-,VXY(+0230eI$MG2R%,108;#&Cd465&h+0hB8;#e%R4;8;23771(&%7S8;271(+0#eU089L(]730hV LG%-C.(@718;?A071(+0I$M:%'&'\0%,.28;#=%<#+0d`715+,.#P>,10^5+0#&CD_&TWb89712UU089L(7Y862U86#&CD,10%-230hba%-#&h0%-CW(c718;?0F71(+0BI$Mh+*^02U#&*-7%')'[0%,Y86#/%N#+0d 715+,W#PQ86#+>{,.0]5+0#)CD_+TWb89712UU089L(7Z8;2h+0CD,.0%-230hVG"$CdCD*-,.h&8;#&L=73*71(&862U%-4;L-*-,.8971(&?cb^71(+0Bh&8;%-4;*-L5+0R73*-'t8;CF?A%_/f[0Fh+0d730d,.?8;#+0hf^_:89712B2.%-4;890#&CD0-bg8V0-V9bf]_h+0d730d,.?A86#&8;#+L/71(+0AIRM<8971(:71(+0A(+0%E^8;0237B08;L(7PQ(&8;L(>{,10^5+0#&CD_:8;#H%21(+*-,.7<h&8;2371%-#)CD0fiT*aCdCd5+,1,.8;#&Lf[0d>*-,10@%-#%-#&%')(&*-,V #*-,.h+0d,<73**-f&71%-8;#71(&8;2Y86#+>{*-,W?A%7189*#PU089L(]7WTWb71(+0k%-4;L-*-,.8971(&? 5&2102Z71(+0B>*4;49*R8;#+LN7U*/CD*^0 K/Cd890#]712dp{&%{pGCD*]0KCd890#7<*->>,10^5+0#&CD_pGCD*^0K/Cd890#]7Y*->K8;#+>,10^5+0#&CD_?>fi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22V % 8;#)CD,10%-2302B71(+0A2.%-4;890#&CD0N*->%c,10d>0d,1,.8;#+L0Da'&,1021218;*#<(+0#71(+00#]71897_H%'&'\0%,.2B86#71(+0ACd5+,1,10#]7;8 #]730d,1E-0#]7189*#c715+,.#gVV h&0CD,10%-2302Y71(&0e21%-4;890#&CD0B*->0Da'&,1021218;*#&271(&%7<%'&'\0%,10hc86#'&,10dEa89*5&2Z8;#]730d,3OE-0#]7189*#c715+,.#)2f)5+7Y#+*-7Y8;#71(&0eCd5+,1,10#]7Z*#+0-b)8;#)h&8;Cd%718;#+LN%A49*2.2*->K86?'\*-,171%-#&CD0-VU*-71(CD*^0K/Cd890#]712*-f^E^89*5)2149_i%\0CD7B71(+021%-4;890#&CD0@*->G0Da'&,102.2189*#&2$8;#,10D)0CD718;#+L71(+089,F>,10^5+0#&CD_%-#&h:71(+08;,$h&862371%-#&CD0>,1*?71(&0RCd5+,1,.0#78;#]730d,1E-0#718;*#715+,W#A<(+0d,.0<71(+0$%-#&%')(+*-,(&%-2f[0d0#/>*5&#&hVKXY(+0R0D^'&,.0212189*#<8971(71(+0(&89L(+0237@21%-4;890#)CD0A<8;4;4f[071(+0?A*237k>Q%E-*-,10hCd%-#)h&8;h&%730%-#730CD0h+0#]7N*#71(&0<(+*4;0/4;8;217k%-#&h71(+0d,10d>*-,10e71(&0e?*237Y,104;0dE%-#]7Y73*-')8;CF>*-,Y71(+0=Cd5+,1,10#]7Y8;#]730d,1E-0#718;*#c715+,.#VXY()8;2%-5+73*?A%718;CY73*-')8;CZh+0d730CD7189*#/?0d71(+*ahA(&%-271(&0Z>{*4;4;*<8;#&LF%-h&E%-#]71%L-0<*fiE-0d,*-71(+0d,?0d71(+*ah&2dp897Fh+*^02$#&*-7R*-f&71%-86#:%218;#&L490k73*-')86Cb[ft5+7R,W%71(+0d,B%/4;86237<*->73*-')8;C@Cd%-#&h&8;h&%7302$*-,.h&0d,10hf^_21%-46890#&CD0-VXY(&%78;2U8;?'\*-,171%-#]7>*-,*5+,%-#&%')(+*-,.%=,1023*465+7189*#23_^21730?f\0Cd%-5&210-ba8;>g71(+0F(&89L(+0237mO!,W%-#+-0hCd%-#&h&8Oh&%730Fh+*^02#+*-7U>Q5&4t4;4^71(+0$,10490dE%-#]7UCD*#&2173,.%-8;#]712db]71(&0#71(+0$#+0Da7U(&8;L(+0237GCd%-#&h)8;h&%730FCd%-#f\0<73021730hVh V VGX<(+0230#&89718;%-4649_-b]E%-4;5+02Y*->l '5&#&89712Z%-#&hHlk5&#&897dba,1023'\0CD7189E-04;_-b&0d,.0k%-212189L#&0h73* V % %-#&CE%-4;5+02ZU0d,10k%,1,W89E-0hc%7Y0Da'[0d,W8;?0#]71%-4;49_-baf)5+7Z>Q5+,171(+0d,Y21715&h+_CD*5&4;hc490%-hc73*/?*-,10e'&,.0Cd8;230FE%-465+02dV! *)1 G g[U ?#71(&8;2A210CD7189*#b71(+0%-#&%'t(+*-,.%H,1021*4;5+7189*#%-49L-*-,W8971(&? f)%-210h*#%`CD*#&2373,.%-8;#]7%-#&h'&,10d>0d,10#&CD0%'&'&,.*%-C.(862'&,10230#]730hV(K+,Qys~E}q{s!~Oq2s}u.- uw}us#ur~qg~q2sqg#}y2q$aq{sqg#y2}q}u)~Eyvty{s"$CdCD*-,.h&8;#+L/73*/F%-(&490f %-/ C1Pmln-nalTWb71(+0d,10@%,10=%7$'&,10210#7R7U*/f)%-2.8;Ce%'&'&,.*%-C.(+02F8;#i%-#)%')(+*-,.%,102mO*4;5+718;*#p=PmlT<71(+0N73,.%-h&89718;*#&%-4S%')'&,1*%-C.(gb<(&8;CW(L-0#+0d,W%-4;49_h+0d'\0#&h)2<5+'\*#:4;8;#+L5&8623718;CBa#+*R490h+L-0-b%-#&h PT=71(+0ch&8;2.CD*5+,.230DO!*-,.8;0#730h%'&'&,1*%-CW(b86#<()8;C.(`71(+0,10230%,.CW(+0d,73,.8902@73*?*ah+04UCD*?')490Dh&8;2.CD*5+,.230B2373,.5)CD715+,102Y%-#&hi71(+0#i5&2302Y71(+0230k2373,W5&CD715+,10273*A,.023*49E-0k%-#&%'t(+*-,.%aV"$?*#+L`71(+073,.%-h)897189*#&%-4Z%'&'),1*%-C.(+02bY71(+0iU*-,1*-> O8;73-*E Pmln-n-oTWb$U%-46h+<8;#Pmln-n-TWb$%-#&h+0d,1, %-Q #&h+0dAds9Pmln-n-nTU%,10R%-4;4)f)%-230h*#/%@CD*?kft8;#&%7189*#*->g4;8;#+L5&8623718;CU^#&*<490h&L-0@PQ490D+8;Cd%-4b^?*-,3O')(+*4;*-L8;Cd%-4b23_a#]71%-CD718;Cb%-#)htfi*-,=230?%-#718;CTF>{*-,=71(+0A,1023*465+7189*#*->Z%-#&%')(+*-,W%aVXY(+0230A%')'&,1*%-C.(&02%'&')4;_:4;86#+L5&8;237186C=a#+*fi<490h+L-0-b8;#H71(&0%_*->YCD*#&2173,.%-8;#]712k%-#&h'&,10d>0d,10#&CD02dbK>*4;49*R8;#+Lc71(+0/*-,1*-> V%,1f\*#+0464%-#&hU,1*fi<#Pmln-o-oTR%-#&h<8;CW(%-#&hJ5+'\0d,.&*_Pmln-o-oTWbg8;#cR(&8;C.(215&C.(:23_a23730?A2$%,10'&,1*-'\*230hc%-2R%N730C.(&#)8;]5&0e>{*-,RCD*?kf)86#&8;#+L230dE-0d,.%-48;#+>*-,.?A%7189*#c23*5&,.CD02dVXY(&0230/%'&'),1*%-C.(+02%,.0/f)%-210hb8;#715)897189E-049_-b*#71(&0/>*4;49*fi<8;#+Li71(&,10d021730d')2dpPmlTkh+0Dt#&8;#&L%-#%-#&%')(&*-,.8;CF%-CdCD0212189ft8;4;897_/23')%-CD0-bKPT%'&')4;_^8;#&L@CD*#&2173,.%-8;#]712db)%-#&hPTZ%'&')49_a8;#+L@'&,10d>0d,10#&CD02dV"CD*#&2373,.%-86#7<%-#)h'&,10d>0d,10#&CD0k23_a23730? ?@5&237Yh&0Dt#+0-b+*#c71(+0B*#&0k(&%-#&hba71(+0=%-#&%')(+*-,.86C$%-CdCD023O2189ft8;4;897_=23')%-CD0-VXY(&%7862db]897U?=5)237G*-f&71%-86#/%@4;8;237G<8971(%-464&71(+0$'\*212189f)4;0YCd%-#&h&8;h&%730$%-#730CD0h&0#712dVZF#71(+0F*-71(+0d,Y(&%-#)hba71(+0B23_^21730? ?=5&217U%-4;21*Nh&0Dt#+0$71(+0B730D^7Z230dL?A0#712Y86#/R(&8;C.(/71(+0e%-#]730CD0h+0#]7<Cd%-#f\0B>{*5)#&hVXY(&862Z23730d'(&%-2R%L-,10%7R86?'\*-,171%-#&CD0F>{*-,R71(+0e,10?%-8;#&8;#+LN23730d')2R8;#71(+0e'),1*^CD02.2Zf\0Cd%-5&230%h+0Dt#&89718;*#c*->71(+0@%-#&%')(+*-,.86Ck%-CdCD021218;f)8;4;897_c23')%-CD0@71(&%7$862<73*^*#)%,1,1*,10215)49712<8;#71(+0=0DaCd4;5)2189*#*->E%-4;8;h%-#730CD0h+0#]712dVkJS89-0d<8;210-b[%h+0Dt#&8;7189*#i*->71(&0@%-#&%'t(+*-,.8;C=%-CdCD0212189f)864;897_i21')%-CD0N71(&%7$862<73*^*f&,1*%-h,10215&4971286#4;%,1L-0Cd%-#)h&8;h&%730i4;8623712dbGR8971(%CD*-,1,1021'[*#)h&8;#+LH8;#&CD,.0%-230i8;#71(+0i4689-04;8;(+*^*ah`*->0d,1,1*#&0d*5&2N%-#&%')(+*-,.%:,1021*4;5+7189*#V $215&%-4;4;_-b%-#&%')(+*-,.%:,1021*4;5+7189*#23_a23730?A2Nf)%-230h*#4;86#+L5&8;237186Ca#+*<4;0h+L-0/PQ+0d,1, %-Q #&h+0d@0d7<%-4V9bSln-n-nTRh+0D[#+0e%-#%-CdCD0212.89f)8;4;8;7_23')%-CD0=5)218;#+Lcr'&,10dEa89*5&2<230#730#)CD0273*A71(+0=%-#&%')(+*-,b+R(+0d,10r8;2E%,W8;%f)490e%-CdCD*-,.h)8;#+L73*A71(+0k^8;#)h/*->K71(+0e%-#)%')(+*-,.%aVF#)CD0Y71(+0<4;86237K*->['\*212.89f)490Cd%-#&h&8;h)%7302G8;2h+0D[#+0hb230dE-0d,W%-4)CD*#&2373,W%-8;#712%,10<%'&'t4;890h8;#N*-,.h&0d,73*,10?*fiE-0A8;#&CD*?'t%7189f)490@%-#730CD0h+0#]712dVNXY(+0CD*#&2373,W%-8;#7B23_a23730? CD*#&2.8;23712$*->CD*#&h)897189*#&2$71(&%7B?@5&237f\0@?A0d7db\%-#)h:Cd%-#)h&8;h&%7302$71(&%7Bh+*#+*-7$>5&49t4;471(+0210NCD*#)h&897189*#&2R<8;464g#+*-7Ff\0=CD*#&2186h+0d,10h'[*2.2189f)490?>fii{9 ] DA22{~i{%-#]730CD0h+0#712Y>{*-,U71(+0F%-#&%')(+*-,VJ0Da86Cd%-4b^?A*-,1')(+*49*-L86Cd%-4b]23_a#]71%-CD718;Cd%-4b+%-#&h230?A%-#]718;CF8;#+>*-,.?A%7189*#%,10e73,W%-h&897189*#&%-4649_5&230h73*/h+0Dt#+0B71(+0=CD*#&2373,.%-8;#]712dVK8;#&%-4649_-bY%>{730d,c,.0?*Ea8;#+L8;#&CD*?A')%7189f)490Cd%-#&h&8;h&%7302bR89>B71(+0,10?%-8;#&8;#+L`4;8;237CD*#71%-8;#)2c?*-,1071(&%-#*#+0B%-#]730CD0h+0#]7db&'&,10d>0d,10#&CD02Z%,10B%'&'t4;890h8;#*-,.h+0d,73*AC.(+*^*230e%N218;#&L490R%-#]730CD0h+0#]7dV #71(&8;2Cd%-230-b+5&#&4689-0Y71(&%7U*->gCD*#&2373,.%-86#712db^'&,10d>0d,10#&CD02U%,10F%-2123*aCd8;%730h<8971(/4;89-04;8;(&*]*ah49*U0d,71(&%-#:l '1',NVV%-#&h)8;h&%7302B>Q5&4t464;8;#+L%i'&,10d>0d,10#&CD0-b71(&0#bS(&%E-0/%cL-,.0%730d,@4;8;-04;8;(+*^*^h*->f\08;#+L71(+0%-#]730CD0h+0#]771(&%-#71(+*230#+*-7R>5&49t4;4;8;#&LN8;7dVRXY(+0='&,10d>0d,10#&CD0@23_^21730??@5&237$f\0=h+02.89L#+0hif\0%,.86#+L8;#:?A8;#&hi71(&%7*#&49_*#+0ACd%-#&h&86h&%730?=5&217B,10?A%-8;#%7B71(+00#&hgV@XY()8;2Rt#&%-4KCd%-#&h&8;h)%730<8;4;4Sf\0@'),1*-'\*230h%-2B71(+0%-#]730CD0h+0#7>*-,@71(+0%-#)%')(+*-,VJg0D+8;Cd%-4b?*-,1't(+*49*-L8;Cd%-4b23_a#]71%-CD718;Cb%-#&h230?A%-#]718;C8;#+>*-,.?A%7189*#%,10k5)215&%-4;49_/5&230hc8;#c*-,Wh+0d,Z73*/h+0D[#+0F71(+0e'&,10d>0d,10#&CD0e21_^23730?iVXY(&0$U*-,1a2Z*-> O8973-*fiEPmln-n-oTZ%-#&hi&0d,1, %-Q #&h+0d/s9Pmln-n-nTY21(&* 71(&%7<%-#)%')(+*-,.%@,1023*465+7189*#23_a23730?A2cft%-230h *#CD*#&2173,.%-8;#]712i%-#&h '&,10d>0d,10#&CD02Cd%-# _^8;04;h 215&CdCD02121>5&4$,102.5&49712<(+0# %')')4;890h73*`#&*#aOh&8;%-49*-L5&0i730D^712V j *fi0dE-0d,bR71(+0230*-,1a24;%-C1%-h+0^5&%730:'&,1*-'\*21%-4;2A>{*-,/71(+0%-#&%'t(+*-,.8;C%-CdCD021218;f)8;4;897_23')%-CD0-V&5&,171(+0d,.?*-,.0-bY71(+0230:%'&'&,1*%-CW(+024;%-C1}CD*#)218;23730#&CD_86#71(+073,10%71?0#]7*->*-71(+0d,R^8;#)h&2U*->730Da712db&>*-,Y0D+%-?')490-bth&8;%-49*-L5+02V+,x 32w uq2s#qg#y2}q}ur~y{v't ysIq2v/2y2}ff!zz#i71(&8;2R230CD7189*#bt71(+0=86#715&8;7189E-0k%-49L-*-,.8;71(&? >*-,R%-#&%'t(+*-,.%A,.023*4;5+7189*#8;#23'\*--0#h&8;%-49*-L5+0=23_^21730?A2PQ"$<F8{TN8;2N'),10230#]730hV}"$<F8Z*-'\0d,.%7302AR8971(23_a#71%-CD718;C8;#+>*-,.?A%7189*#'&,.*Ea8;h+0hf^_`71(+0PRMM')%,17186%-4K')%,.230d,/PQ&0d,1, %-Q #&h+0d-bKMK%-49*?A%,5b 4 O*-,10#+*+bln-n-oTWViP $MGM 8;2Ff)%-230hH*#%c')%,1718;%-4K,.0d'&,10DO230#]71%7189*#*->2149*-7R5)#&8tCd%7189*#iL-,.%-?A?A%,F%-#&%-49_a218;2kPQ&0d,1, %-Q #&h+0d@0d7F%-4V9bSln-n-nTWV$XY(&8;2<')%,1718;%-4,.0d'&,10DO230#]71%7189*#HL89E-02k23*?0*->U71(+0A5+73730d,.%-#&CD0/CD*#&237189715+0#]712db2.5&C.(H%-2eI$MG2bMGM2dbgE-0d,1f)%-4CW(]5)#+^2b%-#&h')%,17186%-4t8;#&>{*-,.?%7189*#/%f\*5+7215+f\*-,.h)8;#&%730hCd46%-5&2302dVXY(^5&2dba"$<F8\CD*?kf)86#+02U7U*@a8;#&h)2G*->ga#+*fi<4O0h+L-0Y%f\*5+7h&8;%-4;*-L5+02dpPmlTK468;#+L5&8;21718;Ca#+*<4;0h+L-0-b215&CW(%-2490D+8;Cd%-4b-?*-,1')(&*49*-L8;Cd%-4b-%-#&h23_a#]71%-CD718;Ca#+*<4;0h+L-0-g%-#&hPTR^#&*<490h&L-0N%f\*5+7$71(+0h&8;%-4;*-L5+0-2F2373,.5&CD715+,.0@897121049>b[<(&86C.(:8;2$f)%-230h:*#71(+0%-#&#+*-71%718;*#*->Y%-h1%-CD0#&CD_'t%-89,.2 * %-#&h^#&*<490h&L-0/%f\*5+7e71(+0/73*-')8;C*->Z71(+0/h&86%-49*-L5+0PQ?A%-#^5&%-4;4;_%-#&#+*-71%730h[TWVK89L5+,10kA21(+*R2Z71(+0e%-#&%')(&*-,.%,1023*465+7189*#'&,1*aCD0h&5+,10-V"$<F8g8;2Yf)%-230hb&8;#]715&89718;E-049_-ba*#c71(+0e>*4;49*fi<8;#+LN71(+,10d0e21730d')2dplV$Ff&71%-8;#c%-4;4'\*212.89f)490F%-#730CD0h&0#712R>{,.*? h&8;%-49*-L5&0F2173,.5&CD715+,10e%-#)hc73*-')8;CB%-2<>{*4;4;*<2dpPQ%T71%-071(+*210UI$MG2S71(&%7S%,.0U8;#)Cd4;5&h+0hB8;#k71(+02.%-?0U%-h3%-CD0#&CD_k')%-89,UPQ"$MUT%-2S71(+0%-#&%'t(+*-,b%-#)hPf[T/71%-0H71(&*230HIRM2/71()%7%,.086#&Cd4;5&h+0h}8;#}71(&0:'),10dE^8;*5&2/"$M73*71(&%7cCD*#71%-86#&8;#+L71(+0%-#)%')(+*-,b&%-#&hPQCT71%-0B71(&*230BIRM271(&%7Z%,10B8;#&Cd4;5&h&0h8;#/71(+0F?*237,10CD0#]7Y5&#&Cd49*230h"$MCD*#71%-86#&8;#+L@71(+0"$M CD*#71%-8;#)8;#+L71(+0e%-#&%'t(+*-,b&%-#&hPQhtT/71%-0=71(+0e73*-')86CF*->71(&0eh&8;%-49*-L5+0^V<F8;2.Cd%,.hi8;#&CD*?A')%7189f)490B%-#]730CD0h+0#]712<f^_%')')49_a8;#+LN4;8;#+L5&8623718;C$CD*#&2373,.%-8;#]712db&%-2<>{*4;4;*<2dpPQ%T>*-,Y'&,.*#+*?A8;#&%-4\%-#&%'t(+*-,.%ap6h\$BQWm /.!<.R WWefi!WRWfiWk!mfi!c uW3/!fi$\.6/fffi."%"2n*87#Q9 ;:=< j> )NgN!= mQ!.G_.6.fiWFgAW-m.!! <@_Z=fi . fimS!!g!fi$BWQ WmfiRW3?dfi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22@BA1CEDGFH?IBAJFLKBMJNBO?PGQJRSOGTVUXWZY[P\UXWBWJNE]B]P1FG^_WBTWB@B`EOGKba_^cEFedGfJdGgBcEC?AhWP1FG^_WBW1Nea_dGfEdgBcEC?Ai?DjdEDBDGFJkBk1ilminEi=^Boek=gEdEDFep?AJC=qrWP1FG^sP.SN?Rtasd_nEik^tP\U[WBWJNu]jCp_d1nBnvTB@ukwUxdGf1^JFEDFH1FGf1^tDGdGfJHuiH1d?^JFJk1]pA1C=qrWBWJNyJCGArFBdJD=ctTB@zifrPuSN?RZY{dGgBgEnGorDGCGfk=^BAJduif.kjCpjqC?AgcEC1nC?|.iDGd1nd?|AJFBF=qFf1^vlEF?^?}EFBFGfhT@rdGf1HeWTBWB@B`EOKh^JC_Cl1^JduiftPuSN?R~FGf1H_p1CGAyJCGArFBdJD=ctTB@zifrPuSN?R~mY&dgBgunGoDGCGf.k^BAJduifkCpkofB^JdED^i?DbDGCGfJHui=^iCGf.klEFG^}EFBFGfbTB@rdfJHtWTBWB@B`EOKb^JCtCGl1^JduiftP.SN?RJFGf1H_p1CGAyJCGArd1nnbT@ifsP.SNGRJ\Y&dGgBgEnGo_nEif1|?Imik^i?DjdGfJHeH.ikDGCGI1A.kFtk^BAI.D^I1AJdBng1A1Fp1F?AJFfDGFEkUift^cEFtC?A1H1FGAeH1FEkBDA.ilEFHsifk^1FGgshlEFBnCG}z]IBfB^iGnP.SN?RJ5fia~FGf1H_p1CGAKJFG^I1AftP.SN?RJFGf1Heg1A1CEDGFH?IBAJFK89L5+,10k^pG"$#&%')(&*-,.%N,1023*4;5&7189*#'&,1*aCD0h&5+,108VYh)8;21Cd%,.h71(+*210k%-#730CD0h&0#712R71(&%7<h+*/#+*-7Y%L-,10d0=86#L-0#&h+0d,b&#^5&?=f[0d,b&%-#&h'\0d,.23*#8;8!Vh)8;21Cd%,.h:71(+0A%-#]730CD0h+0#]712e71(&%7e%,10A#&*#aOCD*O!,10d>0d,10#7=%-CdCD*-,.h&8;#+L73*c71(+0N>*4;49*fi<8;#+L,W5&490-p" '&,1*#+*5)#M8;2N#+*#aOCD*O!,10d>0d,10#]718;%-4<8971(%PQ#+*#aO!,10Dt0Da89E-0*-,A#+*#+O!,10Cd89'&,1*aCd%-4{T#&*5&#c')(+,W%-230BI8;>S%-#]_*->71(+0e>*4;49*fi<8;#+LCD*#&h)897189*#&2 3 (+*4;hgp{ M}%-#&hcI %,.0e8;#71(+0e21%-?0e5+73730d,W%-#&CD0e%-#&hcCd4;%-5&210-b&%-#&hcM%-#&hcI?*ah&89>_A71(+0(&0%-hc*->K71(+0e21%-?0kI$M{ M%-#&hI%,10A8;#:71(+021%-?A0A5+73730d,.%-#&CD0A%-#&hCd4;%-5)230-bg%-#&hHMh+*^02F#+*-7e?*ah&89>_71(&0e(+0%-hi*->K%-#_cI$MPf[T/>*-,<%-h30CD7189E-0@%-#&%')(+*-,.%ap8VYh)8;21Cd%,.h71(+*210k%-#730CD0h&0#712R71(&%7<h+*/#+*-7Y%L-,10d0=86#L-0#&h+0d,8;8!Vh)8;21Cd%,.h71(&*230%-#]730CD0h+0#]712/R(+*230(+0%-h#+*5&#862A#+*-7A*->F71(+0:490Da86Cd%-4YCd%730dL-*-,1_OEOHFV<^V >G?*-,.0=71(&%-#*#+0N%-#730CD0h&0#7e8;2$490d>7db[t49730d,$71(+0=,.0?A%-8;#&8;#&LA%-#730CD0h+0#]712Bf^_%'&')4;_^8;#&LA71(+0>*4;49*fi<8;#+LNU089L(]730hi'&,10d>0d,10#&CD02pPQ%T>*-,Y'&,.*#+*?A8;#&%-4\%-#&%'t(+*-,.%ap8VY%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k21%-?0k"$M}%-2<71(+0e%-#&%')(&*-,=P08;L(7 -#fi6m_YZY.1D6fi!K31!.!mQ!!t.!\!-m,d.W6 .!mm.9Q;:^ >.3$<!mS!mQ!!<!fi!fi6m6fi !"!fimKm!g]WfiF3WQ9 :: j=>[Kfi!W-mfi!fiWffdfg6fi fi!Wcifi6m;fi !!Y.fi!3(. ]q\h fimZmfi!fi1!YWfi3=!R!fiQidW!Gi.6Y.!efi!1 fi3d$!fi.! W+.!3\h B.!UJ. !3.KZ-.fim 3WfiG[fiufiWd!!.6Y.!$RS!-W!W9?fii{9 ] DA22{~i{8;8!V%-#]730CD0h+0#]712i71(&%7i%,.086#71(&0:'),10dE^8;*5&2/"$M 73*71(&%7cCD*#]71%-8;#&8;#&L`71(+0%-#)%')(+*-,PU089L(]fi7 B 'T8;868VU%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k?*237Y,.0CD0#7<5)#&Cd49*230hc"$MPU089L(]7 B'T89EtVY%-#]730CD0h+0#]712F8;#71(+0B73*-')8;C/P089L(]7 lEtVY%-#]730CD0h+0#]712K71(&%7S%')'[0%,S<8971(k71(+0E-0d,1f@*->+71(+0%-#)%')(+*-,S?A*-,1071(&%-#=*#&CD0$PU089L(]7E^8VY%-#]730CD0h+0#]712B71(&%7F%,10N8;#71(&0@21%-?A0='\*2189718;*#c<8971(,10d>0d,10#&CD0@73*/71(+0@E-0d,1fH%-2$71(+0%-#)%')(+*-,=Pf\0d>*-,10B*-,R%>730d,TDPU089L(7E^8;8!V%-#]730CD0h+0#]712Y71(&%7Y%,.0e8;#71(&0e21%-?0F'\*21897189*#/<8971(,10d>0d,10#&CD0B73*N71(+0e5+73730d,W%-#&CD0e%-271(&0k%-#&%')(+*-,@P089L(]7E^8;868V71(&0e#+0%,10237Z%-#]730CD0h+0#7<73*71(+0B%-#&%')(+*-,kPQ5&210h<(+0#?*-,10F71(&%-#*#+0BCd%-#&h)8;h&%730*-f)71%-8;#&2Z71(+0=(&89L(+0237E%-4;5+0fiTPf[T/>*-,<%-h30CD7189E%-4%-#&%'t(+*-,.%ap8VY%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k21%-?0k"$M}%-2<71(+0e%-#&%')(&*-,=P08;L(7 -8;8!V%-#]730CD0h+0#]712i71(&%7i%,.086#71(&0:'),10dE^8;*5&2/"$M 73*71(&%7cCD*#]71%-8;#&8;#&L`71(+0%-#)%')(+*-,PU089L(]fi7 l 'T8;868VU%-#]730CD0h+0#]712$71(&%7<%,10e8;#71(&0k?*237Y,.0CD0#7<5)#&Cd49*230hc"$MPU089L(]7 l 'T89EtVY%-#]730CD0h+0#]712F8;#71(+0B73*-')8;C/P089L(]7 -EtVY%-#]730CD0h+0#]71271(&%721(&%,.071(+021%-?0a8;#&hF*->a?*ah&8)0d,W2P0-VL+V9b'),10d'\*21897189*#&%-4')(&,.%-2302db%-hm0CD7189E-02bt%-#&hc23**#tTBPU089L(fi7E^8VY%-#]730CD0h+0#]712F<8971(c0D+%-CD7149_c71(+0=21%-?0=?A*^h&89)0d,.2eP0-VL+V9b\71(+0=2.%-?0k%-h30CD7189E-0,10hPU089L(]fi7E^8;8!V%-#]730CD0h+0#]712$71(&%7<%L-,10d0k86#c#]5&?=f\0d,kP08;L(7E^8;868V71(&0e#+0%,10237Z%-#]730CD0h+0#7<73*71(+0B%-#&%')(+*-,kPQ5&210h<(+0#?*-,10F71(&%-#*#+0BCd%-#&h)8;h&%730*-f)71%-8;#&2Z71(+0=(&89L(+0237E%-4;5+0fiTXY(&0230'&,10d>0d,10#&CD02NU0d,10ch+0dE-049*-'\0h%-2A%:,10215&497@*-><71(&00?A')89,.8;Cd%-4U23715&h&_0D^'t4;%-8;#+0h8;#71(+0>*4;49*R8;#+L230CD7189*#VTt#71(&8;2F230CD7189*#bS%-#0D^'\0d,.8;?A0#71%-4K23715&h&_*->U71(+0%-49L-*-,.8971(&? 862R'),10230#]730hb8;#&Cd465&h&8;#+L/%ch+0d0d'h+0DO21CD,.8;'&7189*#B*->+71(+0G0D^'\0d,.8;?A0#712dbCD*-,1'\*-,.%R%-#&he73*^*4;25)230hb%-2U04;4%-2%<21715&h+_B%f\*5+7g71(+0U8;?'\*-,171%-#&CD0*->K71(+0e%-#&%')(&*-,.8;CB%-CdCD021218;f)8;4;897_/23't%-CD0-VK{\Qy{}!y2}q\y]y{v/~1?q2su)~E}ff=#y{sIy-)ur\iu}ff'zusi~#c*-,.h+0d,Y73*0dE%-4;5)%730e71(+0e%-#&%')(&*-,.%,1023*465+7189*#c%-49L-*-,.8;71(&?'&,1*-'\*230hc8;#71()8;2Z')%'\0d,ba71(+0eL-0#&0d,.%-4'&,1*aCD0212Z*5&714;8;#+0h8;#iK89L5&,10eNU%-2<>{*4649*U0hVF%71%/>{*-,Y71(&0e0dE%-465&%7189*#cU0d,10e71%-0#>{,.*? 71(+L0 wxut^~ ffWrDw &x1Dr RDxW~Dwr)bt%ACD*-,1't5&2Z*->B '73,.%-#&2.CD,.89f\0h23'\*--0#`^')%-#&8621(h&8;%-49*-L5+02e'&,1*Ea8;h+0h:f^_71(+0A%-215+,.h+0AMG,1*30CD7/PQ%-215+,.h+0/M,1*30CD7dbln-n-oTWVGXY(&0230Yh&8;%-49*-L5&02%,10YCD*#E-0d,W21%7189*#&2Gf[0d70d0#%B,.%-8;49%_@CD*?')%-#]_N0?')49*fi_-0d0Y%-#&hA%BCd4;890#]7dVXY(+0U73,.%-#&2.CD,.89'&73*-,K5&230h@8;#=71(+0U%-215&,.h+0M,1*30CD7K'&,1*Ea8;h+02S715+,.#@%-#&h@23'\0%-0d,?A%,1a5+'gVF5+7*->\B 'h&8;%-4;*-L5+02dbgJ 'cU0d,10A2304;0CD730h>*-,e71(+073,.%-8;#)8;#+LP73,.%-8;#&86#+LcCD*-,1')5&2WT$%-#)h71(+0A,10?A%-86#&8;#+LliU0d,10?fi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22X x $xux= $x$XxxxXXx$X x $x $X GG8X$ ?X$Gx=x$xXX$x$xXx$X$Xx$$$xx $XBx x;xXX=[==XG 8u $8;L5+,10k^pG&5)4;4\0dE%-465&%7189*#c'&,.*^CD0212,10230d,.E-0h>{*-,71(+0Rt#&%-4t0dE%-465&%7189*#HP730237YCD*-,1')5)2WTWVXY(+0230BB'h&8;%-49*-L5&02UCD*#]71%-8;#i='&,1*#&*?A8;#&%-4%-#&%')(&*-,.2Y%-#&hi-A%-hm0CD718;E%-4g%-#)%')(+*-,.2dV0(&%-hH7U*%-8;?A2e8;#H5)218;#+Lc71(+073,.%-8;#&8;#&LCD*-,.')5&2dp/PmlTB73*i023718;?%73071(+086?'\*-,171%-#&CD0*->71(+02373,.5)CD715+,.%-4%-#&%')(+*-,W8;C%-CdCD0212.89f)8;4;8;7_23't%-CD0-b%-#&h PT=73*Hh+0Dt#+0%-#%-h+0^5&%730i230d7N*->RCD*#)2373,.%-8;#]712%-#&h'&,.0d>{0d,10#)CD02P0D^'\0d,.86?0#712 'abGlb^b%-#&hTWVAXY(+0730217kCD*-,1')5&2F%-2B,10210d,1E-0hH73*i*-f&71%-86#H71(+0t#&%-4\0dE%-4;5&%718;*#V#%-h)h&897189*#bt71(+0@0#7189,.0@CD*-,1't5&2<%-2F?A%-#^5&%-4;49_i%-#&#&*-71%730hR8971(7*ch&89[0d,10#]7<L-*%-462dp=PmlT<73*8;h+0#]7189>_F>5+,.71(+0d,Sh&8621CD*5+,.2302373,.5&CD715+,W%-4'&,1*-'\0d,1718;02215&CW(=%-2%-h1%-CD0#&CD_e')%-8;,.2%-#&h=73*-')8;Cd2b%-#)hPTg73*8;h+0#]7189>_R%-#&%'t(+*-,.2g%-#&hk%-#730CD0h+0#]712dV"$4971(+*5+L(BU0G%-#&#&*-71%730he71(+0GCD*-,.')5&2g?A%-#^5&%-4;4;_-b71(+0d,10%,.0G%7'&,10210#7K23*?0%-5+73*?A%718;C23_a23730?A2>*-,K'[0d,.>{*-,.?8;#+L<%-h1%-CD0#&CD_e't%-89,S71%L-L86#+LAP71(+0U%-215&,.h+0M,1*30CD7PQ%-215+,.h&0UMG,1*m0CD7dbtln-n-oTWb>*-,0D+%-?')4;0fiTWb%-2K04;4^%-2K>*-,K%-5&73*?A%718;CU73*-')8;C71%L-L8;#+LPQ<0d_^#&%,b&ln-n-n*-,Z%-5+73*?A%718;CF73*-'t8;C<0Da73,.%-CD7189*#PQ210d0$71(&0F?A0d71(+*^h>*-,Z%-#&%')(+*-,.%=,1023*465+7189*#h+021CD,.89f\0h/8;#a0CD7189*#]TWVXY(&0%-#&#+*-71%7189*#*->eCD*#]E-0d,.21%7189*#&%-4$2373,.5)CD715+,10i%-2/Cd%,.,.890h*5&7/%-2h&021CD,.89f\0h8;#71(+0#+0Da7')%,.%L-,W%')(V"R#8;?A'[*-,.71%-#7%-23'\0CD7*->Rh)8;%-49*-L5+0c2373,.5)CD715+,10c%-#&#+*-71%7189*#}8;2@71(+0c73,.%-8;#&86#+L't(&%-230-b<(&86C.(c%-21215&,102Z,104;86%f)8;4;897_A%-?*#+L%-#)#+*-71%73*-,.2dVXY(&0%-#&#+*-71%7189*#')(&%-230%-2k%-CdCD*?A')4;8;21(&0h%-2e>*4;49*fi<2dp/PmlTB7U*%-#&#+*-71%73*-,W2kU0d,102304;0CD730hbPT<%-#%L-,10d0?A0#7 9 %-2<,10%-CW(+0h:f\0d7U0d0#71(&0k7U*%-#&#+*-71%73*-,.2F<8;71(c,10dL%,.h:73*71(&0@%-#&#&*-71%7189*#21CW(+0?0R5)218;#+Le%B73,W%-8;#&8;#+LeCD*-,.')5&2dbtPT71(+0R%-#)#+*-71%7189*#A%-271(+0#Cd%,1,W890h*5+7f^_f\*-71(A%-#&#+*-71%73*-,W28;#N')%,W%-4;4904^*E-0d,U71(+0Z730237GCD*-,.')5&2db%-#)hiP]TK%B,104;86%f)8;4;897_e23715&h+_=U%-2Cd%,1,.890hN*5&7*#71(+0<%-#&#&*-71%7189*#6P V%,.4;0d7371%/dKs9\ln-n-TWVGXY(+0Z,10468;%f)8;4;8;7_e23715&h&_@5&210h71(+0B-sWuuasR2371%718;237186CZ71(&%7G?0%-2.5+,10271(+0R% K/#aO<h\.!mZdg-Wfigg1SDYZm\!UmDR!..!WggfiF .3R!!Km.!fim?dfii{9 ] DA22{~i{897_f\0d70d0#71(+0=%-#)#+*-71%7189*#&2<*->71(+0e7U*%-#&#+*-71%73*-,.2Rf]_c?A%a8;#+LB35&h&L?0#712R%f\*5+7<Cd%730dL-*-,.8902V+*-,$CD*?')5+718;#&L71(+0NsWuuasHPdT2171%718;23718;Cb)210d0@a890dL-04g%-#)h V%-237304;4;%-#`Pmln-o-oTWV 8U0Cd%-5&230Z715&,.#&2%,10Z?A%,1-0hh&5+,W8;#+LY71(+073,.%-#)21CD,.89'&718;*#k')()%-230-b-71(+0Z%-#&#+*-71%73*-,?0d,.049_kCd4;%-212.8)02715+,.#)2=%-CdCD*-,.h)8;#+L:73*:71(&0/715+,W#7_]'\02h+021CD,W89f\0h8;#^0CD7189*#%-#&h71(+0#,104;%7302@0%-C.(8;#)89718;%7189E-08;#]730d,1E-0#]7189*e# 1 73*89712F,.0%-CD7189*#8;#]730d,1E-0#]7189*e# J bg71(+0d,10df^_h+0Dt#&8;#&L%-h3%-CD0#&CD_:')%-89,W2dVa8;#&CD071(&8;271%-212.8;?')49_,10]5)89,102ZCd4;%-212.8tCd%7189*#b&8;7Y8;20%-218;49_?0%-215+,.0hi5&218;#&L@71(&0sWuuas2371%718;237186CVVU*#)Cd5+,1,10#]7149_-bg73*-')86Cd2B0d,.08;h+0#]718)0hVXY()8;2$71%-23U%-2=%-4;23*i218;?A')490-bg218;#)CD071(+0ACD*-,1')5&2k5&230h>*-,G71(+0230R0D^'\0d,.86?0#712G8;2*-,1L%-#&8;d0h8;#]73*=21(&*-,17h&8;%-49*-L5&02G%-#&h0%-CW(h&8;%-49*-L5+0Y()%-2*#&49_N*#+0R?A%-8;#73*-')8;C$*-,Y71(&0?0-b&%-#&hc218;#)CD0$71(&0230e%,10e8;#]73,1*ah&5&CD0hCd490%,.49_/f]_?0%-#&2*->71(+0eCd4;890#]7d2Z8;#]730d,1E-0#]7189*#%7e71(+0f\0dL8;#)#&8;#+L*->0%-CW(h&86%-49*-L5+0-V"R2=%,10215&4;7db0h&0d730CD730h#+*ih&8621CD,10d')%-#&Cd8;02Ff[0d70d0#`%-#aO#+*-71%73*-,.2e<8971(,10dL%,.h73*c71(+0N73*-')8;CN8;h&0#718[Cd%7189*#VeXY(+0d,.0d>{*-,10-b71(&0d,10NU%-2B#+*c#+0d0h:73*i?0%-2.5+,1071(&8;271%-215)218;#+LN71(+0-sWuuas=2371%718;21718;CV"$CdCD*-,.h&8;#&L=73* V%,.4;0d7371%cGs9;b+%/?0%-215&,10?0#]7Uf\0d70d0# ' -oN%-#&h ' Bo 'N%-4;49*fi<25&2U73*?A%-0'\*21897189E-0cCD*#&Cd465&2189*#&2b%-#&h8;> 8;2NL-,.0%730d,/71(&%-# ' Bo 'abZ0i(&%E-073*-71%-4<,104;8;%f)864;897_f[0d70d0#}71(+0,10215)49712*->K71(+0e%-#&#+*-71%73*-,.2V#71(+*230iCd%-2102A<(+0d,.0i%Hh&8;21CD,10d't%-#&CD_%-2A>*5&#&hf\0d7U0d0#71(+0i%-#)#+*-71%73*-,.2db71(+0c>*4;49*fi<8;#+LCD,.89730d,W89*#c%-2R%'&'t4;890hp0%-CW(h&8;%-49*-L5+0kU%-2$%-212189L#&0hi%?A%-86#%-#&#+*-71%73*-,$<(+*210=%-#&#+*-71%718;*#%-2CD*#&2186h+0d,10hh&0Dt#&897189E-0@8;#i71(&0=0dE-0#]7F71(&%7R71(&0d,10=U0d,10Nh&8;21CD,.0d')%-#&Cd8902Zf\0d70d0#71(+0=7U*c%-CdCD*5&#712V#*-,Wh+0d,R73*cL5)%,.%-#730d0Nf)%-46%-#&CD0-b0%-C.(H%-#&#&*-71%73*-,eU%-2$71(+0?A%-86#%-#&#&*-71%73*-,e>{*-,F0D+%-CD7149_:B ',N*->71(+0kh)8;%-49*-L5+02dVF#)CD0<f\*-71(A%-#&#+*-71%73*-,W2U()%-hNt#&8;2.(+0hN71(+0R%-#)#+*-71%7189*#b^71(+0Y,10468;%f)8;4;8;7_=21715&h+_@U%-2UCd%,1,.890hA*5+7db<8971(%:,10215)4971%-#7-sWuuas?0%-215&,10?0#]7@*-fi> z' nalV 0c71(&0d,10d>{*-,.0iCD*#&218;h+0d,N71(+0c%-#&#&*-71%7189*#*-f&71%-8;#&0hc>{*-,<71(+0B0dE%-465&%7189*#c73*Af\0B73*-71%-4;4;_,.04;8;%f)490-Va86#&CD071(+0c%-#&#+*-71%730h730Da712U*5&4;hf\0'&,1*aCD021230hf^_%-#%-#&%'t(+*-,.%:,1023*4;5&7189*#23_^21730?cbGU0h+0dE-049*-'\0hi%-#:&O:J71%L-L8;#+L/>{*-,W?A%7dV$0#&0d,.%-4;49_-b+71(&862R&O:J?A%,.^5+'cR8;4;4\(&%E-0k71(+0e>*4;49*R8;#+LN>{*-,W?cpfiff Ju.E.u1E.Ju.E.u1E.E.E,JmuJ.E.ZEEmZ.u;XY(^5&2db+71(&0B>{*4;4;*<8;#&LN#&*-71%7189*#&2<%,.0e5&230hi8;#0%-CW(Cd%-210-pXS*-')8;Cp{#ffE ffV1#.J"$h1%-CD0#&CD_')%-89,.2p{"!#E$%&" m&ffwJmR(+0d,10 8;2%-#A8;h+0#]718tCd%718;*##]5&?=f\0d,5&230hN73*k%,.,.%-#+L-0Y71(+0R%-h3%-CD0#)CD_@'t%-89,.28;#230^5+0#]718;%-4*-,Wh+0d,{#]730d,1E-0#718;*#i715+,.#)2dp'uZ)(;+*..,Em&-ZG ". ff" ""fifi!W&!.6Y.!@-Wfi!..!=fi!dmGm-!k=Gfi. 3e!m-W! 09 /F123 1 fi1!m!&454 56/F.731 fi .!m98 f+WY.0:4544 >?Dfi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22R(+0d,10kX "BMffL ?A%_cf[0 A*-, PQY0%-CD718;*#*-, #)89718;%7189E-0fiT%-#)h:aMLG"<;(LG 8;2Y71(+0=8;#&h&8OCd%73*-,$>*-,Y71(+0k23'\0%-0d,YR(+*230B715+,.#897Z8;2{V*#718;#^5&8;#&L@715&,.#&2dp=*..,Em&-ZG> ff? @ff? m""" EmEXY(&0B>{*-,.?%7<8;20Da0?')4;8t0h86#c8;L5+,10B+VCBAED JZFBCFHMGJIL@N?K IL?K,K B KsPNaPOQNILKFRSK"BAED PB HGJILiK KBCFM @NIL,K sK PaN POQN ILK KBAED C PFB M@NILKrKePNaPOQNILKaCRSKBAED P@B BAED CFM@NILKrKePNaPOQNILKaKBAED P@B BAED0;?6/iZ5i! " (ffa siZ !eeg,6/!a!ii3a 0 gi P,c3gui-i! p (& ff?;,!p!?m!a-Zu0& 00qi!/ffa!?i3& != )a05i 8( !u r6/aip&\!Z5K89L5+,10B+pL+%-?')490F*->G&O:J%-#&#&*-71%7189*#" 20Da')4;%-86#+0h%f\*E-0-b@8;#%-h&h)897189*# 73*71(&8;22173,.5&CD715+,.%-4k%-#&#+*-71%7189*#b=71(+0`CD*-,.')5&2i%-2:%-4;23*$%-#&%')(&*-,.8;Cd%-4;49_%-#&#+*-71%730h f^_?A%,1a8;#+L5+'}71(&0:%-#&%'t(+*-,.8;Cc,.04;%7189*#&2/f\0d7U0d0# %-464Y'&,1*#&*?A8;#&%-4%-#&h`%-hm0CD718;E%-4%-#)%')(+*-,.2=%-#&hH71(+089,@CD*-,1,10CD7@%-#730CD0h+0#]712dV #H*-,.h+0d,=73*L5&%,W%-#730d071(+0A,102.5&49712db71(&8;2%-#)#+*-71%7189*#%-2'\0d,1>*-,.?0hNf^_=7*kh)8[0d,.0#7%-#&#+*-71%73*-,W2G8;#N')%,W%-4;4904a%-#&h%B,10468;%f)8;4;8;7_e23715&h&_*->71(+0$215+f)230^5+0#]7G%-#&#+*-71%718;*#/%-271(+0#/Cd%,.,.890hA*5&7dVB#&CD0R%L%-8;#gb]71(+0$%-#&#+*-71%7189*#%-2G73,.0%730h%-2%Cd4;%-212189tCd%7189*#71%-23[bCD*#&218623718;#+L*->R230490CD7186#+L71(+0c%'&'&,1*-'&,W8;%730/04;0?0#71286#71(+0cCd%-#&h)8;h&%7304;8;217PU0A0237186?A%730h%-#%E-0d,.%L-0*->^V '\*212.89f)490N%-#730CD0h&0#712@'\0d,e%-#&%')(+*-,e%>730d,=%')')49_a8;#+LCD*#aO2373,.%-86#712WTWV XY(+0i,.04;8;%f)8;46897_23715)h+_`*->F71(+0?A%-#]5)%-4<%-#&%')(&*-,.8;C%-#&#+*-71%7189*#,10215)49730h8;#%-sWuuas?0%-215&,10?0#]7Y*-5> w']V#%-h&h&89718;*#b71(+0ZCD*-,1')5&2K%-2K71%L-L-0h5&2.8;#+L$71(+0ZMUe=71%L-L-0d,730CW(&#&8;^5+0Zh+021CD,W89f\0h=f^_=M4;%F%-#&hM,W890d73*Pmln-n-oTWV=+,1*?71(&8;2btU0N*-f&71%-8;#+0h:?*-,1')(&*49*-L8;Cd%-4%-#&h490Da86Cd%-4S8;#&>{*-,.?%7189*#VRX<(+0@CD*-,.')5&2%-2G71(+0#')%,.230h5&218;#+LB71(&0$P $MGM`')%,1718;%-4+'t%,.230d,G'),1*-'\*230hf^l_ O:%,1?7 R Q #&0dDOU%,WCD*cKs-Pmln-n-oTG8;#*-,.h+0d,73*N*-f&71%-8;#23_a#]71%-CD718;CF8;#+>*-,.?A%7189*#VK8;#&%-4649_-b71(+0F'&,.*-'[*210h/%-#&%'t(+*-,.%=,1023*4;5+718;*#/%-49L-*-,W8971(&?%-2<%'&')46890hV?fffiK1E<:1^ff>fi >fi{EE ?! 6i{9 ] DA22{~i{6ff>ETU:!fiff fiWVWXUJUZYL[ \W -E1.<:<611:6w1<_\ fiff1E`_ <:1a_g fi K?]1?6ffnWh\Kd!mm3dgR$!fiK!ZWQWmfiFWSW!K.fiW\h Kd!mm3dgR$!fiKfi!mfiQ Wm R.g!U!fiKfimd.fiU!fiWfiW\h Kd!mm3dgR$!fi WR.SdW!!W .mfi$WmU!fiWfiW7W\h Kd!mm3dgR$!fi!fi! WW% \h Kd!mm3dgRmgfi!bX%f)490AlpUa73,.5&CD715+,.%-4%-#)%')(+*-,.8;CF%-CdCD0212.89f)8;4;8;7_/21')%-CD0e,10215)49712^0dE-0d,W%-4g23715&h&8;020d,10k71(+0#cCd%,1,.890hi*5+7Y8;#*-,.h+0d,<73*A8;h+0#]7189>{_/71(+0e8;?'\*-,171%-#)CD0B*->h+0D[#&8;#+LN%-#-% h+0^5&%730A%-#&%')(&*-,.8;CN%-CdCD0212189ft8;4;897_23')%-CD0%-#&h*->Uh+0Dt#&8;#&L%CD*#&2373,W%-8;#7e%-#)h'&,10d>0d,10#&CD023_a23730?f)%-230h*#:71(&8;2$23')%-CD0-V #71(+0230N23715&h)8902db)U0NCD*?')%,10h:71(+0@*5+73')5+7R*->71(+0N%-#&%')(+*-,W%A,1023*465+7189*#23_a23730? R8971(71(+0e?A%-#^5&%-4g%-#&#&*-71%7189*#i%-#&hcL-0#&0d,.%730h210dE-0d,.%-4g2371%718;21718;Cd%-4g,102.5&49712dV\ac}Eziy2}q2s#uy-Xuq2sq #y2}ffq$ur~?~ 'v'~?q$u#*-,.h+0d,=73*:2.(+*71(+0/8;?A'[*-,.71%-#&CD0A*->Yh+0Dt#)8;#+Li%-#%-h&0]5&%730%-#&%')(&*-,.8;CA%-CdCD0212.89f)8;4;8;7_23')%-CD0-b%23715&h&_*-><71(+0c49*aCd%7189*#*->R71(+0c%-#730CD0h+0#]7A*->R0%-C.('&,.*#+*?A8;#&%-4U%-#&h%-h30CD7189E%-4Z%-#&%')(+*-,.%:%-2h+*#+0e5)218;#+LN71(+0e73,W%-8;#&8;#+LNCD*-,1')5)2dVXY(+0B,102.5&49712Z%,10eL8;E-0#i8;#iX%f)490AlVed"$2Cd%-#Nf\0210d0#8;#@71(+071%f)490-bn-^V n N *->t71(+0Z%-#730CD0h&0#712G0d,10Y4;*^Cd%730h8;#@71(+0'&,.*-'[*210h@2173,.5&CO715+,.%-4K%-#&%'t(+*-,.8;C@%-CdCD0212189ft8;4;897_i23')%-CD0-V 7B8;2$023718;?A%730h71(&%7F71(+0N,10?%-8;#&8;#+L%-#730CD0h&0#712P+V;il NT%,10i49*aCd%730h8;#71(+0c215+f)73*-')8;Cd2@*->R71(&0h)8;%-49*-L5+02dV ( / #*-,.h&0d,@73*86#&CD*-,1'\*-,.%73071(+0230c,10?%-8;#&8;#+L%-#]730CD0h+0#712@8;#]73*71(+0A%-#&%')(+*-,W8;CN%-CdCD0212189f)864;897_23')%-CD0-b*#&0A?A89L(]7$0?A')49*_%c2373,.%730dL-_71(&%7e5)230271(+0 -1tvv~i#q$u PQ8V0-V9ba%-4;4&71(+0$#+*5&#')(+,.%-2302G>{,.*?71(+0Rf\0dL8;#&#&8;#&L$*->71(&0Rh&8;%-4;*-L5+0<73*=71(+0$%-#)%')(+*-,?A89L(]7f\0F5)230htTWV j *U0dE-0d,bt%-2Z21(&*<#c8;#X%f)490e^b+*5+,Z'&,.*-'[*2.%-4t>*-,Z71(+0e%-#&%'t(+*-,.8;C$%-CdCD0212189ft8;4;897_23')%-CD0PQ(+0d,10%>730d,F,10d>{0d,.,10hi73*%-2 ~E}t#t#}q2v TWbt,10h)5&CD02Y71(+0@%E-0d,.%L-0A#^5&?=f\0d,Y*->Cd%-#&h&8;h)%7302<'\0d,%-#&%')(&*-,Pf\0d>*-,10%')')49_a8;#+LCD*#&2173,.%-8;#]712WTB73*l 'aV fiH>,1*? 71(+0+V;lDH71()%7@U*5&4;hf\0/*-f&71%-86#+0h`8;>71(+0 -1tv'v(~?q$u %')'&,1*%-C.(U0d,10%-h+*-'&730hV #`*-71(+0d,.2@U*-,.h&2db5&2.8;#+Li71(+0 -1tv'vc~i#q$u %'&'&,1*%-CW(U*5&4;h:8;#&CD,10%-230@71(+0#^5&?kf\0d,$*->G'\*21218;f)490kCd%-#&h)8;h&%7302$f]_%/>Q%-CD73*-,B*->G71(&,10d0-b\71(+0d,10df^_L-,10%7149_:8;#aOCD,10%-2186#+Lf[*-71(71(+0,10^5&89,.0h`CD*?'t5+71%7189*#&%-40D\*-,17%-#&h71(+0'\*212189ft8;4;897_*->$230490CD718;#+LH8;#)CD*-,1,10CD7%-#]730CD0h+0#712V<I<*-7186CD0-bt73*^*+bt71()%7<71(+0230=0D^'\0d,.86?0#712Y0d,10='\0d,1>{*-,W?0hc*E-0d,B%ACD*46490CD7189*#*->K2.(+*-,17h&8;%-4;*-L5+02iPQ%,1*5&#&h--*-,Wh&2N'\0d,Ah&8;%-49*-L5+0fiTWVXY(&0230c'&,1*-f)4;0?A2N<8;4;4f\00dE-0#}?*-,10i%-Cd5&7308;#49*#+L-0d,Rh&8;%-49*-L5+02V$71(&0d,k,10230%,WC.(+0d,.2@(&%E-0'&,1*-'\*230h5&218;#+Li%i<8;#&h+*fi <8971(%&a0h#^5&?kf\0d,e*->Z230#]730#&CD02=73*h+0Dt#&0G71(+0U%-#&%')(+*-,.86CG%-CdCD021218;f)8;4;897_B23')%-CD0-VXY(&8;2g7_^'[0U*->&%'&'&,.*%-C.(N?A89L(]7f\0Cd%-46490h=%)f 'sy f y~Eususu)~ %'&'),1*%-C.(V&*-,0Da%-?A')490-b+0d,., %-Q #&h+0d@s-[Pmln-n-nTK'&,.*-'[*210Y5&218;#+L$71(+0Z71(+,.0d0Z'&,10dEa89*5&2230#]730#&CD02R73*h+0Dt#+0B71(&0k%-CdCD0212189ft8;4;897_/23')%-CD0k>{*-,R'&,1*#+*5&#)2Z%-#&hc71(+0B>*5+,Y'&,.0dE^89*5)2Z230#730#)CD02<>*-,%-h30CD7189E%-4+%-#&%')(+*-,.%F8;#A^'t%-#&8;21(VS+*-ff, LG#&L4;8;21(b ;e%-?A0d_%-?A%APmln-n-TK'&,.*-'[*2102S71(&0Y21%-?0Z23')%-CD0Z>*-,71(+0U'&,1*#+*?8;#&%-4V j *U0dE-0d,b]71(+0d,108;2S#&*$2373,W5&CD715+,.%-435)23718tCd%7189*#k>{*-,K71(+0210h&0Dt#&897189*#)2dVg+0d,1, %-Q #)h+0d: d.!mS!.\!fiSQ!Z^!WfiW!K.mmmfi R.mS\WfiW31!3RWfifi!Wfi!fifiJ!!fi.!fi!Y1!S..K!mfi!RQQ!t1!!!YWfiW.!099 9!gm.!mW ! >< !fi fi [Z3$dAf !.gfiW!fiYWR!W+!fifi .fifffifigmd!fifi!m\!fi `324?>fi@ 2~,72 AK$)B"$#&%')(&*-,.8;CF%-CdCD0212189ft8;4;897_/23')%-CD0XS*-71%-4gCd%-#&h)8;h&%7302VZ%-#&h&8;h&%7302'\0d,Y%-#&%'t(+*-,MG,1*-'\*-,17189*#$CA2B2{EDX<{$7a73,.5&CD715+,.%-4lb '-l 'aV fil'1',N&5)4;423')%-CD0^b -oB'+V;lDaloNGF7BEHK.{JI228;#&h+*fi*->5+73730d,.%-#&CD02lb -n-l^V 'l-NX%f)490k^pV%-#&h&8;h)%730273*f\0F'&,1*aCD021230hc>*-,Y0%-C.(:%-#&%')(&*-,.8;CF%-CdCD0212189ft8;4;897_/23')%-CD0dSs%-#&gh ;e%-?0d_%-?A%$'\0d,1>*-,.?0h@230dE-0d,.%-4a0?'t89,.8;Cd%-4]23715&h&8902S73*B21(+*fi71(&0U*-')718;?A%-4^23')%-CD0>{*-,K0%-CW(0Da'[0d,W8;?0#]7dVSX%f)490GZf\049*fi21(+*fi<2g71(&0,10215&4;712*->+%<23715&h&_R<()8;C.(BU0'\0d,1>*-,.?0he5)218;#+L71(+0& wx!u[]~ffWrdw-Qx1Dr RDxW~Dwr&b+71(&0BL-*%-4\*-><(&86C.(U%-273*Ah&0Dt#+0F%-#c%-#&%')(+*-,.86CR%-CdCD0212.89f)8;4;8;7_23't%-CD0$ft%-230h*#h% f 'sy f y-_~Eusuws#u)~ 71(&%7ZCd%-#71(+0#f\0$%-h)%'&730h73*h&8;%-49*-L5+02Uf^_?0%-#&2*->Si% f sy f yl '@5+73730d,.%-#)CD02tEuw}q2s#u)~ V"$2G71(+0$71%f)490$21(+*fi<2db\l-lR5+73730d,W%-#&CD02U>{*-,'&,1*#&*?A8;#&%-4&%-#)%')(+*-,.%=%-#&h>*-,N%-hm0CD7189E%-4Z%-#&%')(&*-,.%%,10c#+0d0h+0h8;#`*-,.h+0d,73*HCD*E-0d,/71(+0c21%-?0c#]5)?kf\0d,@*->R%-#]730CD0h+0#712/%-2%-2YCD*E-0d,10h5&218;#&L=71(+0B2373,W5&CD715+,.%-4%-#&%'t(+*-,.8;C$%-CdCD0212189ft8;4;897_23')%-CD0P<()8;C.(%-2Yh+0Dt#&0h/ft%-230h*#%-h1%-CD0#&CD_'t%-89,.2k%-#)h71(+073*-')8;CTWVa86#&CD071(+0%-#&%')(&*-,.8;C21')%-CD05)218;#+L:%<86#&h+**-><5+73730d,.%-#)CD028;2B#+*-7Bft%-230hH*#%-#]_'),.8;#&Cd89't490-btft5+7F,.%71(+0d,e*#H0?A')89,.8;Cd%-4K23715)h&8902dbg897e?%_:E%,1_:>,1*? *#+0730Da773*%-#+*-71(&0d,%-#&h71(+0d,10d>*-,10i8;286#&%-h+0^5&%730-V O*-,10d*fiE-0d,bZ71(+0i2373,W5&CD715+,.%-4%-#&%')(&*-,.8;C%-CdCD0212189ft8;4;897_23')%-CD0eCd%-#CD*E-0d,$*#&49_71(&*230eCd%-2302Y71()%7Z,10d>{0d,<73*IRM2Z8;#]73,1*^h)5&CD0h%7Y71(+0B*5+71230d7<*->S71(+0eh)8;%-49*-L5+0P73*-')8;Cd2TWb)#+*-7Y71(+*210e<8971(c%N<86#&h+* *->230#]730#&CD02W5&73730d,.%-#&CD02F%'&'&,1*%-CW(V#HCD*#&Cd4;5&2.89*#bg897FU*5&4;h%'&'\0%,B71(&%7e71(+0 ~}t#t#}q{v %-#)%')(+*-,.8;CN%-CdCD0212.89f)8;4;8;7_23't%-CD0A8;2F73*f\0B'&,10d>0d,1,10hb+%7<4;0%-237Y>*-,<%-#&%')(+*-,W%N,1023*4;5+718;*#c8;#ch&8;%-49*-L5&02dVjesyfy-FtEuw}q2su`kxmw q$rtsu)v^wxl ~+dxmsr[WN!w["R#)%')(+*-,2Y5&73730d,.%-#&CD0O.lO!OoO.l'O.l-lO.lO.lO.lDp&' ,.*#+*?A8;#&%-4%-#&%')(+*-,W%%-#730CD0h+0#]712]V+V;l'aV-]V''aVBo-^Vo-o^VnalVnalVn-^V;ln-^VNmnn-o^Vn-o^Vl'1'aV'N%-hm0CD7189E%-4%-#&%')(+*-,W%%-#730CD0h+0#]712lo^V-+V-^V-^V]V n^lV'^V^VoalVoalV\n+Vn]Vn]Vl'1'aV'XS%f)4;0k^pffLG?'t89,.8;Cd%-4\23715&h&_/*->K%-#&%')(+*-,W8;CB%-CdCD0212189ft8;4;897_/23')%-CD0Bft%-230hi*#i%A<8;#&h+*fi *->K5&73730d,.%-#&CD02?Gfi$230hc'&,10d>0d,10#&CD02L^'\0d,.8;?A0#7I<*+Vp{{{{{{{{{{{{{l'r{qL^'\0d,.8;?A0#7I<*+Vll'li{9 ] DA22{~i{MG,1*#+*?A8;#)%-4%-#&%')(+*-,.%n{{{{l'l-ll{{{{{{{{{{{{{{{pM,10Cd8;2.89*#"$h30CD7189E%-4%-#&%')(+*-,.%{{{{{{{{{{{{{{{{{{{{{{{{{{{{{N-n^V'-^V^VoalVN-^V-^Vo^V noalVnWf+!! mK[md!3sYWZd+f !! mK[m d!3sYW ZbXS%ft490B+pffLa'\0d,.8;?0#]7Z215&?A?%,1_ts\Qys~E}q{sq{s#}u.- uw}usuE~Eu"$2B>{*-,k71(+08;?'\*-,171%-#)CD0@*->Zh+0D[#&8;#+L%-#%-h+0^5&%730/CD*#)2373,.%-8;#]7e%-#&hH'&,.0d>{0d,10#)CD0A230d7ef)%-230h*#h&8O%-49*-L5+02373,.5)CD715+,10/5)218;#+L71(+0/%-CdCD0212.89f)8;4;8;7_23')%-CD0h+0Dt#&0h8;#^0CD7189*#`+bU0/f\0dL8;#f]_%-h&*-'&718;#+L71(+0CD*#&2373,.%-8;#]7k%-#&h'&,10d>0d,10#&CD0210d7=h+0dE-049*-'\0hf]_H+0d,1, %-Q #&h+0d$s-ZPmln-n-nT=%-#&h`h+021CD,.89f\0hf\0DO49*fi 8;#a0CD7189*#^V+V@X<(&8;2$CD*#&2373,.%-8;#]7B%-#&h:'&,10d>0d,10#&CD0230d7e(&%-2Ff\0d0#21(+*fi<#:73*cf\0@%-h+0^5&%730>*-,'&,1*#&*?A8;#&%-4%-#&h%-hm0CD718;E%-4Y%-#)%')(+*-,.%86##+*#aOh&8;%-4;*-L5+0ih&8;21CD*5&,.230-V}XS*71(&8;2210d7dbY8;#+>*-,.?A%7189*#%f\*5+7=h)8;%-49*-L5+02173,.5&CD715+,10<8;4;4Kf\0%'&'t4;890h8;#*-,.h+0d,@73*71%-0c%-h+E%-#71%L-0*->Y89712@8;#at5+0#)CD0-VIR*-7*#&49_8;2Zh&8;%-4;*-L5+0e2373,.5&CD715&,10e5&230h73*h&0Dt#+0F71(+0e%-#&%')(&*-,.8;CB%-CdCD021218;f)8;4;897_/23't%-CD0-b&f)5+7Z897Y8;2Z5)230h73*h+0Dt#&0B'&,10d>0d,10#&CD02Y%-2ZU04;4V+*-,=71(&8;2e21715&h+_-b230dE-0d,W%-40Da'[0d,W8;?0#]712B0d,.0Cd%,1,.890h*5&7k5&218;#&L71(&0A73,.%-8;#&86#+LcCD*-,1')5&2dVAX<(+02300Da'[0d,W8;?0#]712@86#E-*49E-0hCW(&%-#+L-02A86#`71(&0CD*#)2373,.%-8;#]7A%-#&h'&,10d>0d,10#&CD0c230d7A8;#*-,.h&0d,@73*h&0Dt#+071(+0CD*#a)L5&,.%7189*# (( 71(&%7YU*5&4;h(&%E-0e*-')718;?=5)? '&,10Cd8;2.89*#VKY0215&4;712Y%,10k215)?A?A%,.89d0h8;#XS%f)4;0B+Vuvxwvzy|{~}C}CQfi9FFFJ)JXY(+0d,.0%,107U*:h&89[0d,10#]7=%')'&,1*%-C.(&02k73*?A%-#&%L8;#&L71(+0/'&,10d>0d,10#&CD0/210d7db*-,Wh+0d,10h?%-#&%L-0?0#]7%-#&hU089L(730hc?%-#&%L-0?0#]7dV$,.h&0d,10h?A%-#&%L-0?0#]7Y8;2Uf)%-230h*#ch&8;2.Cd%,.h&8;#+L=71(+*230B%-#]730CD0h+0#71271(&%7Kh+*R#&*-7>Q5&4t4;4-%<'&,10d>0d,10#&CD0U89>a71(+0d,10862%-#]_kCd%-#&h&8;h)%730G71(&%7S>5&49t4;4;2897dV 089L(]730h@?%-#&%L-0?0#]78;2f)%-230h*#%-21218;L#&8;#+L@%=U089L(]773*@0%-CW('&,10d>0d,10#&CD0B%-#&h/71(+0#c230490CD7186#+L=71(&0$Cd%-#&h)8;h&%730F<8971(/71(+0?A%+8;?@5&?E%-465+0-V+*-,G71(+02300D^'\0d,.86?0#712b-71(+0Z23_^21730? U%-273,W%-8;#+0hN23*B%-2K73*B*-f&71%-8;#@71(+0Zf\0237K230d7*->)'),10d>{0d,.0#&CD02dVa5+ft230]5&0#7149_-b[U0N%')')4;890hf[*-71(:*->71(+0@%')'&,1*%-C.(&02F73*'),10d>{0d,.0#&CD0?A%-#&%L-0?0#]7B73**-f&71%-8;#:71(+0f\0237A,102.5&497N<8971(71(&0i73,.%-8;#&86#+LHCD*-,1')5&2dV F#&CD0iU0i*-f&71%-86#+0h71(+0f[0217A230d7*->F'&,10d>0d,10#&CD02/%-#&hJh\!6 o6#$2ki+-n2x#$AS3B!!<fi `!GK[Q.!KB!! mmS!.YDF!fiQQ! fi3e.SUmfi!!Qm+!Kfi-!Z .fi!dmmm?dfi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI2289712f\0237?A%-#&%L-0?0#]7dbRU00dE%-465&%730h 71(+0H23_^21730? R8971(}71(&0:730217CD*-,.')5&28;#*-,.h+0d,73**-f)71%-8;#8;#&h&0d'[0#)h+0#7U,10215)49712dV^*+ba>*-,0D^'\0d,.8;?A0#712 'ablba%-#)h^ba*-,.h&0d,10h?A%-#&%L-0?0#]7U%-2Z%'&'t4;890hA73*N*-f&71%-86#71(+0Ff\0237U230d7*->Y'&,.0d>{0d,10#)CD02dVXY(&0#b86#0Da'[0d,W8;?0#]7@^bU0%'&'t4;890hHU089L(]730h?%-#&%L-0?0#]7@73*8;?'),1*E-071(+0,10215)49712Z8;#71(+0e73,W%-8;#&8;#+LNCD*-,1')5)2dV\2x c\iuw}'z|uws?qg~Euv's#u z's{t=~E'sZ-1y2}ffzqysys#v=0 f\0dL%-#<8;71(71(+0iCD*#&2373,.%-86#7A%-#&h'),10d>{0d,.0#&CD0i230d75&210hf]_+0d,1, %-Q #)h+0dd=sFPmln-n-nTWV XY(&8;2%-49L-*-,.8;71(&? 8;2f)%-230h*#468;#+L5&8;21718;C8;#+>*-,.?A%7189*#*#)49_-bY%-#&h}8;712,102.5&49712A(&%E-0f[0d0#215&CdCD02121>5&4649_73023730hN*fiE-0d,G%F#+*#aOh&8;%-4;*-L5+0UCD*-,.')5&2<8971(@%$,10215&497186#+L<'&,.0Cd8;2189*#k*->[o- N >*-,'&,1*#+*?A86#&%-4%-#&%'t(+*-,.%,1023*465+7189*#PU0k(&%E-0@#+*A8;#+>*-,.?A%718;*#c%f[*5&7Z71(+0B'&,10Cd8;2.89*#>{*-,R%-hm0CD718;E%-4g%-#)%')(+*-,.%TWVXY(&0@8;#)89718;%-4gCD*#atL5+,.%7189*#:8;#&Cd4;5)h+0hc71(+0@>{*4649*<86#+LCD*#&2373,W%-8;#7F%-#&h:'&,10d>0d,10#&CD0N230d7F%-#&h:h+0D&O#&89718;*#*->%-#&%'t(+*-,.8;CB%-CdCD0212.89f)8;4;8;7_/21')%-CD0-VuvHCvzyhFFQJ}C`F@fifi?`aafiFfi+ *-,'&,1*#+*?A86#&%-4]%-#)%')(+*-,.%F,1021*4;5+7189*#b-71(&0Y%-#&%')(+*-,.86C%-CdCD0212.89f)8;4;8;7_=21')%-CD0YCD*#&218;21730h*->t71(&0Z71(+,10d0'&,10dEa89*5&2G715+,.#&2G73*N71(+0R%-#&%'t(+*-,V+*-,Y%-h30CD7189E%-4t%-#&%'t(+*-,.%ab^71(+0$21')%-CD0$CD*#)218;23730h/*->g71(+0R'&,10dEa89*5&2>*5+,Y715+,.#)2dVuvHCv0JQS@}CFaJC#c71(+0eCd%-210k*->'&,1*#+*?A86#&%-4\%-#&%')(+*-,.%ab)71(+0kCD*#&2373,W%-8;#712<8;#&Cd4;5&h&0hp{lV<?A*-,1')(+*49*-L86Cd%-4%L-,10d0?0#]7dpYh&8;2.Cd%,.hi71(+0@%-#730CD0h&0#712F<()8;C.(%,10=8;#)CD*?')%7189f)4;0e?*-,3O't(+*49*-L8;Cd%-4;4;_:PL-0#&h+0d,b)#]5)?kf\0d,b+%-#&hc'\0d,.21*#tT^V<21_^#]71%-CD718;CCD*#]730Da7dpNh)8;21Cd%,.hH71(&0%-#730CD0h&0#712@<(&86C.(%,10/#+*#aOCD*O!,10d>0d,10#]7@%-CdCD*-,.h)8;#+L73*/J%'&')86#c%-#&hcJg0%-212@Pmln-n]T#c71(+0eCd%-210k*->K%-hm0CD718;E%-4S%-#&%')(+*-,.%ab+71(&0kCD*#&2373,.%-86#712Y86#&Cd4;5&h+0hgp{lV<?A*-,1')(+*49*-L86Cd%-4%L-,10d0?0#]7dpYh&8;2.Cd%,.hi71(+0@%-#730CD0h&0#712F<()8;C.(%,10=8;#)CD*?')%7189f)4;0e?*-,3O't(+*49*-L8;Cd%-4;4;_:PL-0#&h+0d,DT^V<MG,1*-'\0d,3O#+*5&#+O!')(+,.%-230F0D+Cd4;5&218;*#p0D+Cd4;5&h+0e#+*5)#c')(+,.%-2102Y(&%Ea8;#+L/%'&,1*-'\0d,<#+*5)# ( - %-2(&0%-huvHCvxw{~}C}CQfifi{#c71(+0eCd%-210k*->'&,1*#+*?A86#&%-4\%-#&%')(+*-,.%ab)71(+0e'&,10d>0d,10#&CD02<%,10B>{*-,pl V<Cd%-#)h&8;h&%7302Y86#71(+0k21%-?0k715+,.#c%-2Y71()%7Y*->S71(&0k%-#&%')(+*-,^V<Cd%-#)h&8;h&%7302Y86#71(+0e'&,10dEa89*5&2715&,.#^V<Cd%-#)h&8;h&%730B'&,.*-'[0d,Y#&*5&#&2*-,R86#&h+0Dt#&8;730$I$MG2Jf+!-\fifi.!Wgfi. qZfiZ`3_<Wm!Dmmh\iW<Wm1!-\fi!$.3W.!fiWg DmR3 fi 1!mW d!mmmfi d!g&W m!.a Wfi.!m?dfii{9 ] DA22{~i{+V=P>*-,<'\0d,.21*#&%-4\'&,1*#+*5)#&2WTCd%-#&h&8;h)%730B'&,1*-'\0d,Y#+*5&#&2^V<Cd%-#)h&8;h&%7302S71(&%7S()%E-0f\0d0#e,10d'\0%730h@?*-,10G71()%-#k*#&CD0BP,10d'\0%730h=>{*-,.?2%-#&h=,10d'\0%730h?A0#7189*#)2WT^V<Cd%-#)h&8;h&%7302<71(&%7R(&%E-0=%'&'\0%,10h?*-,10e71()%-#i*#&CD0@8;#cCD*#&2373,.5)CD7189*#i<8;71(c71(+0eE-0d,1f:8;#CD*#)2373,.5&CD7189*#i<8971(71(+0k%-#)%')(+*-,]V<Cd%-#)h&8;h&%730286#=71(&0Y21%-?0Z'\*21897189*#N%-271(&0Y%-#&%')(+*-,<8;71(N,10d>{0d,.0#&CD0Z73*B71(+0ZE-0d,1fPf\0d>*-,10*-,$%>{730d,DTo^V<Cd%-#)h&8;h&%7302Y86#71(+0k21%-?0k'[*2.897189*#<8971(,10d>0d,10#&CD0k73*A71(+0k5+73730d,W%-#&CD0k%-2Y71(&0e%-#&%')(+*-,n^V<Cd%-#)h&8;h&%7302Y#&*-7<8;#cCd89,.Cd5)?A2371%-#]718;%-4%-h15&#&CD712l'aV<Cd%-#)h&8;h&%7302Y?A*237Y,10d'\0%730hi8;#i71(+0B730D^7l-lV<Cd%-#)h&8;h&%7302=?*237k*->730#%')'[0%,W8;#+Li8;#CD*#)2373,.5&CD7189*#<8971(H71(&0AE-0d,1f`86#CD*#&2373,.5)CD7189*#R8971(71(+0k%-#&%'t(+*-,l^VY71(&0kCd49*230237RCd%-#&h&8;h&%730B73*71(+0k%-#&%')(&*-,{#c71(+0eCd%-210k*->K%-hm0CD718;E%-4S%-#&%')(+*-,.%ab+71(&0e'&,10d>0d,10#&CD02Y%,.0e>{*-,pl V<Cd%-#)h&8;h&%7302Y86#71(+0k21%-?0k715+,.#c%-2Y71()%7Y*->S71(&0k%-#&%')(+*-,^V<Cd%-#)h&8;h&%7302Y86#71(+0e'&,10dEa89*5&2715&,.#^V<Cd%-#)h&8;h&%7302K21(&%,W8;#+L<71(&02.%-?0a8;#&h=*->)?*ah&8t0d,%-271(+0Z%-#&%')(&*-,P0-VL+V9b^%R'),10d'\*21897189*#&%-4't(+,.%-230fiT+V<Cd%-#)h&8;h&%7302e2.(&%,.8;#+L71(+0A2.%-?0?*ah&8)0d,B%-2B71(&0A%-#&%')(+*-,/P0-VL+V9b71(+0A21%-?A0%-h30CD7189E-0-p,.*3%a&,.0htT^V<Cd%-#)h&8;h&%7302Y%L-,.0d08;#+L8;#c#^5&?=f\0d,^V<Cd%-#)h&8;h&%7302Y?A*237Y*->730#i,10d'\0%730hi8;#71(&0e730D^7]V<Cd%-#)h&8;h&%7302=%'&'\0%,.8;#+Li?*217k*->730#8;#CD*#)2373,.5&CD7189*#<8971(H71(&0AE-0d,1f`86#CD*#&2373,.5)CD7189*#R8971(71(+0k%-#&%'t(+*-,o^VY71(&0kCd49*230237RCd%-#&h&8;h&%730B73*71(+0k%-#&%')(&*-,uvHCvHh`?zFF89E-0#71(&8;2R),.237BCD*#atL5+,.%7189*#bS%-#0dE%-4;5)%7189*#U%-2kCd%,1,.890h*5+7BR(&8;C.(,.0215&49730h8;#H%'&,.0Cd8;2189*#*->-n^V',N>{*-,Z'&,.*#+*?A8;#&%-4t%-#&%')(+*-,W%=,.023*4;5+7189*#%-#&hc-^V &N >*-,Y%-h30CD7189E%-4[%-#)%')(+*-,.%@,1023*465+7189*#VIR0d0h&490212N73*H21%_-b71(+0210,.0215&49712N%,10E-0d,1_49* >*-,N'&,1*#+*?A86#&%-4%-#)%')(+*-,.%%-#&h0Da73,10?049_`'[*^*-,>*-,R%-h30CD7189E%-4%-#&%')(&*-,.%aV #i0dE%-4;5&%7186#+L71(+0k0d,.,1*-,.2db&U0=CD*#)Cd4;5&h+0hc71()%7Y71(+0=h&0Dt#+0hi%-#&%'t(+*-,.8;C%-CdCD021218;f)8;4;897_23't%-CD0%-2e73*^*CD*#&2373,.%-86#+0h%-#&hH73*^*%,.f)8973,.%,.8649_h+0Dt#&0hV 7=218;?')4;_h&8;23,.0dL%,.h+0h71(+0e,.04;%7189*#&21()89'cf\0d7U0d0#%-#&%')(&*-,.%A%-#&hh&8;%-49*-L5+0e2173,.5&CD715+,10-_V VU*#&230^5+0#]7149_-b&U0k'&,.*-'[*210hc71(+0>*4;49*R8;#+LC.(&%-#&L-02Y>*-,Y71(+0k230CD*#)hc0D^'\0d,.86?0#7dV\ +\iuw}'z|uwsq2vy {t#u~}fftt}uZs - y{}z|qysy{sv=+*-,R71(&8;20Da'[0d,W8;?0#]7db^71(&0eh+0Dt#&89718;*#/*->71(+0e%-#&%'t(+*-,.8;CF%-CdCD021218;f)8;4;897_23')%-CD0kU%-2YCW(&%-#+L-0h73*A0?NO')49*fi_B8;#+>*-,.?A%7189*#B'),1*Ea8;h+0hBf^_B71(+0Uh&8;%-49*-L5+02373,.5&CD715+,.0-b%-2215+L-L-023730h=f^_(O%,17?R Q #+0dDO%,.CD*NPmln-n-nTWV#e%-h&h&89718;*#b71(+0G'&,10d>0d,10#&CD02%\0CD730h@f]_F71(&862,10dEa8;230heh+0D[#&897189*#F*->+%-#&%')(&*-,.8;C%-CdCD0212.89f)8;4;8;7_R21')%-CD0U0d,10k?*ah&8)0h%-2<04;4!Vfi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22uv0fivzyhFFQJ}C`F@fifi?`aafiFfiXY(+0$%-h1%-CD0#&CD_')%-89,U%-#&h71(&0<73*-')8;C<*->71(+0Rh)8;%-49*-L5+0R0d,10$5&230h/8;#A*-,.h&0d,73*@h+0Dt#+0R71(+0R%-#&%'t(+*-,.8;C%-CdCD021218;f)8;4;897_A23')%-CD0-V VU*#)CD,10d73049_-ba0Bh+0D[#+0h/%-#%-#&%'t(+*-,.8;CR%-CdCD0212189f)864;897_A21')%-CD0Rf^_?0%-#)2*->S71(+0%-h1%-CD0#&CD_')%-89,N*-><71(+0i%-#)%')(+*-,b71(&0'),10dE^8;*5&2N%-h3%-CD0#)CD_`')%-8;,@73*H71(&0%-h3%-CD0#&CD_')%-89,N*->$71(+0%-#&%')(&*-,bG%-h1%-CD0#&CD_')%-89,.2NCD*#]71%-8;#&8;#+L:71(+0i%-h1%-CD0#&CD_')%-89,@*->R71(&0%-#)%')(+*-,bG%-#)hbt#&%-4649_-b71(+0?A%-8;#73*-'t8;CB*->71(+0kh&8;%-4;*-L5+0AP>{*-,R'&,1*#+*?A86#&%-4\%-2Z0464g%-2Y%-h30CD7189E%-4g%-#&%')(+*-,W%TWVuv0fiv0{~}C}CQfifi+*-, La'[0d,W8;?0#]7lbU0c,.0?*E-0h}71(+0c'&,1*#+*?8;#&%-4%-#&%')(+*-,W%'&,10d>0d,10#&CD02h+021CD,W89f\0h%f\*fiE-08;#89730?A2=71(+,1*5+L(:l-lF%-#&h/71(+0$%-hm0CD7189E%-4\%-#&%')(+*-,W%e'&,10d>0d,10#&CD02h+02.CD,.89f\0h8;#/89730?A2Zk71(+,1*5+L(c]V"$4;23*+ba'&,10d>0d,10#&CD02FlF%-#&hc@%f[*fiE-0F0d,10F,10d't4;%-CD0hf]_/71(+0R>*4;49*fi<8;#+L=>{*5&,#&0d '),10d>{0d,.0#&CD02dVXY(^5&2dbf\*-71(c>*-,Y'&,1*#+*?8;#&%-4\%-#&hi%-h30CD7189E%-4g%-#&%')(&*-,.%ab+71(+0e'&,.0d>{0d,10#)CD02Y%,10e>*-,p{lVCd%-#&h&8;h&%7302<8;#71(+0k21%-?A0k%-h1%-CD0#&CD_')%-89,Y%-2Y71()%7Y*->S71(&0k%-#&%')(+*-,{^VCd%-#&h&8;h&%7302<8;#71(+0e'&,.0dE^89*5)2Z%-h3%-CD0#)CD_'t%-89,Z73*A71(+0k%-#)%')(+*-,oGV Cd%-#&h&86h&%7302Y8;#c%-#]_c%-h3%-CD0#)CD_'t%-89,YCD*#71%-86#&8;#+L71(+0=%-h3%-CD0#)CD_'t%-89,Z*->S71(&0k%-#&%')(+*-,{pDVCd%-#&h&8;h&%7302Y71(&%7<%,10e8;#i71(+0B73*-')8;C{XY()8;2YC.()%-#+L-0=%-2F?A%-h+0k86#i*-,.h+0d,R73*/730217R71(+0@23_a23730?c2R'[0d,.>{*-,.?%-#&CD0e<(+0#4;8;#+L5)8;23718;CF8;#+>*-,3O?A%7189*#8;2R,10?*fiE-0h%-#&h:*#&49_ih&8;%-4;*-L5+0=2373,W5&CD715+,10@8;#+>*-,.?A%7189*#8;2R5)230hP'),10d>{0d,.0#&CD02Nl=71(&,1*5+L(p.TWV #*-,Wh+0d,A73*HL5&%,.%-#]730d0%H2.8;#+L490/t#&%-4Z23*465+7189*#b*#)49_`4;86#+L5&8;237186CA'&,10d>0d,10#&CD0c89730? l^b>*-,'&,1*#&*?A8;#&%-4\%-#&%')(&*-,.%ab)%-#&hc89730?o^b&>{*-,$%-h30CD7189E%-4%-#&%')(+*-,.%iP71(&0kCd49*230237RCd%-#&h&8;h&%730fiTWb+,.0?A%-8;#Vuv0fivxwh`?zF"R>{730d,86#&Cd4;5&h&86#+Li8;#+>*-,.?A%7189*#%f\*5+7h&8;%-4;*-L5+0c2373,.5&CD715+,.0%-#)h`,.0?*Ea8;#+LH71(+0c4;86#+L5&8;237186C'&,10d>0d,3O0#&CD02dbF'&,.0Cd8;2189*# ,.%7302c,.*230H73*-^V N >*-,i'&,.*#+*?A8;#&%-4$%-#&%')(&*-,.%,1023*4;5&7189*# %-#&h-^V >*-,%-h30CD7189E%-4[%-#)%')(+*-,.%=,1023*4;5&7189*#V"CD*#&2.8;h+0d,.%f)4;0<8;#&CD,10%-210F862GL%-8;#&0h86#71(+0F,1021*4;5+7189*#/*->%-h30CO7189E%-4%-#&%'t(+*-,.%Af^_i218;?A')49_C.(&%-#+L86#+L71(+0@h+0Dt#&8;7189*#*->71(+0@%-CdCD0212189f)864;897_c23't%-CD0-V<XY(&%7$8;2<h&5&0e73*71(+0e>Q%-CD7Y71(&%7R%-hm0CD718;E%-4g%-#)%')(+*-,.%#+0d0h%A4;%,1L-0d,<21')%-CD0e71(&%-#c71()%7<5&230hi86# La'[0d,W8;?0#]7 'aV5+7K71(+0230,102.5&49712K%,10Z23718;4;4]49*%-#)h@h&0?*#&2373,.%73071(&%7h)8;%-49*-L5+02373,.5&CD715&,10U86#+>{*-,W?A%7189*#@%-49*#+08;2e#&*-7=21P5 KCd890#7dVXY(^5&2dbS%i71(&89,.hH0Da'\0d,.8;?0#]7B%-2kCd%,1,.8;0h*5+7k5)218;#+Lcf\*-71(h&86%-49*-L5+0A2373,.5)CD715+,10%-#&h4;8;#&L5&8;23718;C86#+>{*-,W?A%7189*#V^0dE-0d,.%-4E%,.8;%7189*#)2=8;#`71(+0'&,10d>0d,10#&CD023_a23730? 0d,.086#E-023718;L%730h8;#&h&0d'[0#)h+0#714;_-V\x f\iuw}'z|uwsy2}u}ur's{t/~'s - y2}ffz|qy{sz|q2sq 2uzv't~bq2vy{t#uC~E}t#t#}uusOy-q}uu-1u}uws#u)~ z's - y2}ffz|qy{s+*4;4;*<8;#&L+b+71(+0e'&,10d>0d,10#&CD02<5&230hc8;#71(&862Z0D^'\0d,.86?0#7Z%-#&hi71(+089,15&23718tCd%718;*#c%,10k21(+*fi<#Vuvxuvzy|{~}C}CQfifi#=71()8;20Da'\0d,.8;?0#]7db0),.2175&210h=%$'&,10d>0d,10#&CD0230d7K71(&%78;#&Cd465&h+0he%-4;4]71(+0Z4;8;#&L5&8;23718;C%-#)h@h)8;%-49*-L5+02373,.5)CD715+,10c'&,10d>0d,10#&CD02/h+021CD,.8;f[0h%f\*fiE-0-V X<(+0#bGE%,.89*5)2A%-49730d,.#&%718;E-02U0d,105&210h8;#*-,.h&0d,A73*fii{9 ] DA22{~i{*-f&71%-8;#:%-#:*-'&718;?A%-4SCD*#a)L5+,W%7189*#VF"R2$%,.0215&497db[71(+0@>{*4;4;*<8;#&LA'&,10d>0d,10#&CD02$U0d,10@%,.,.89E-0h:%7R>*-,71(+0B[#&%-4CD*#a)L5+,W%7189*#p{ &*-,<'&,1*#&*?A8;#&%-4\%-#&%')(&*-,.%ab&71(+0e'),10d>{0d,.0#&CD02Y%,10B>*-,ph)8;%-49*-L5+0e2373,W5&CD715+,10B'&,.0d>{0d,10#)CD02dpYlB71(+,1*5&L(p468;#+L5&8;21718;C<'),10d>{0d,.0#&CD02dpG^b[]bto^bt%-#&hl{ &*-,R%-h30CD7189E%-4g%-#&%')(+*-,W%ab&71(+0e'&,.0d>{0d,10#)CD02Y%,10e>*-,ph)8;%-49*-L5+0e2373,W5&CD715+,10B'&,.0d>{0d,10#)CD02dpYlB71(+,1*5&L(p468;#+L5&8;21718;C<'),10d>{0d,.0#&CD02dpG^b&+bt^bt%-#&hoXY()8;2Ut#&%-4230d7<*->CD*#&2173,.%-8;#]712<%-#&h'&,.0d>{0d,10#)CD02<8;271(+0k*#+0B71(&%7<8;2Y'&,10230#]730hi8;#^0CD718;*#^V ^Vuvxuv0h`?zF>JF5QS@0z@zF7Y21(+*5&4;hf\0B#+*-730hc71(&%7R8;#+>*-,.?A%7189*#%f\*5+7,10d'\0%730hiCd%-#&h&86h&%7302x!>*-,Z0Da%-?A')490-b+71(+0B'&,.*#+*?NO8;#&%-4\%-#&%'t(+*-,.%N'&,10d>0d,10#&CD02Y^bSl 'ab&%-#&hl-lb+*-,Y71(+0e%-hm0CD7189E%-4%-#&%')(&*-,.%N'&,10d>0d,10#&CD02YN%-#&h: ! 8;25&215)%-4;49_i8;#&210d,1730h86#73*71(+0N'&,10d>0d,10#&CD023_a23730? 8;#:*-,.h&0d,$73*i%-CW(&890dE-0a#+*R490h+L-0%f\*5+7F71(+0?A%-8;#0#]7189718902Y*->71(&0=h&8;%-4;*-L5+0-V j *fi0dE-0d,b8;#71(&8;2Z0Da'\0d,.8;?0#]7db)8;#&>{*-,.?%7189*#i%f\*5+7<71(&0=?A%-8;#i73*-')8;Ce*->71(+0Uh&8;%-49*-L5+0(&%-2f\0d0#=8;#&Cd4;5&h&0he%-#&hk21*R8;#+>*-,.?A%718;*#e%f\*5+7,10d'\0%730h@Cd%-#&h&8;h)%7302S8;2S5&#&#+0CD02.21%,1_-VXY(+*210B'&,10d>0d,10#&CD02ZU0d,10e71(+0d,.0d>{*-,10k,10?*E-0hgbt8;?'),1*Ea8;#+L@71(+0e,102.5&49712dV&5&,171(+0d,.?*-,.0-b^U0B>*5&#&h/71(&%7Z'&,1*#+*?8;#&%-4)%-#)%')(+*-,.%@'&,10d>0d,10#&CD02Y@%-#&hN>*-,Z'&,1*-'\0d,U#&*5&#&2Cd%-5&230h0d,.,1*-,.2dVXY()8;2862f\0Cd%-5&210F86#71(+0Bh+*?%-8;#*->71(+0F0Da'[0d,W8;?0#]771(+0d,.0F862U%-#0D+%L-L-0d,.%730h5&230*->g')46%-CD0R#&%-?02<(+0d,.0<71(+0230$'&,10d>0d,10#&CD028;#)CD*-,1,10CD7149_%'&')4;_-VKU_A,.0?*Ea8;#+L=71(+0?cbaf\0d73730d,,102.5&49712U0d,10e*-f&71%-8;#&0hVK8;#&%-4649_-b218;#&CD0N71(+0A5&210d>5&46#+0212$*->'),10d>{0d,.0#&CD0AnHPQCd%-#&h&8;h&%7302e71(&%7e%,10A#+*-7e8;#Cd89,WCd5&?A2371%-#]718;%-4%-h15&#&CD7WT(&%-2#+0dE-0d,Zf\0d0#k35)23718)0h/'&,1*-'\0d,.49_-b^89773*]*N%-2*?A8973730hV"R>730d,Z,10?*E%-4b+71(+0F'&,.0Cd8;2189*#>*-,Y'&,1*#+*?8;#&%-4\%-#&%')(+*-,W%2371%_-0h71(+0k21%-?A0-VXY(^5&2dbK(&%E^8;#&LCD*#&2186h+0d,10h%-464'\*212189ft490A%'&')4;86Cd%7189*#&2B>*-,=*-,Wh+0d,10h`'&,10d>0d,10#&CD0/?%-#&%L-0?0#]7db%-#&hcL8;E-0#i71(&%7R71(&8;2Ut#&%-4230d7Y*->K'&,10d>0d,10#&CD02<,10d'&,10230#]730hi71(&0k?A8;#&86?=5&?230d7<*->'),10d>{0d,.0#&CD02db&U0CD*#&2186h+0d,10h897A73*f[0c71(&0i*-'&718;?A%-4<230d7dV 071(+0#%'&')46890h71(&8;2*-'&7186?A%-4Y230d7A*->F'&,.0d>{0d,10#)CD0273*71(+0$73,.%-8;#&86#+LkCD*-,1')5)2db]*-f)71%-8;#&8;#+L@%k'),10Cd8;2189*#*->^V N>*-,U'),1*#+*?A8;#)%-4&%-#&%')(+*-,W%k,1021*4;5+7189*#%-#&ho^V n N >{*-,<%-hm0CD7189E%-4g%-#&%'t(+*-,.%aV`\xf\iuw}'z|uws' s{t/~'s - y2}ffz|qy{s v't~bq2vy{t#uC~E}t#t#}uuw/urIz 2q s#qg{uwz|uwsOy-q}u.- uw}us#ur~ zf's - y2}ffz|qy{s+*4;4;*<8;#&L+b+71(+0e'&,10d>0d,10#&CD02<5&230hc8;#71(&862Z0D^'\0d,.86?0#7Z%-#&hi71(+089,15&23718tCd%718;*#c%,10k21(+*fi<#Vuv0fivzy|{~}C}CQfifi#71(&8;2Rt#&%-4K0Da'\0d,.8;?0#]7db71(+0N'&,10d>0d,10#&CD0A230d7B*-f)71%-8;#+0hH8;#:71(+0'&,.0dE^89*5)2R0Da'\0d,.8;?0#]7FU%-2k5&230hPQ8;#&Cd465&h&8;#+L=71(+0k?A86#&8;?@5&?210d7Y*->S'),10d>{0d,.0#&CD02Y71(&%7ZU0kCD*#&2.8;h+0d,10h73*Af\0B71(+0k*-'&718;?A%-4CD*#atL5+,.%O7189*#tTWVX<(+0#b+230dE-0d,.%-4%-49730d,W#&%7189E-02ZU0d,10e5&230h8;#*-,.h&0d,U73**-f)71%-8;#c%-#*-'&718;?A%-4['&,.0d>{0d,10#)CD0$U089L(]7%-21218;L#&?0#]7dVX%f)4902:%-#&h:21(+*71(+0'&,.0d>{0d,10#)CD0/U089L(]7N%-2.2189L#&?0#]712@>{*-,N'&,.*#+*?A8;#&%-4%-#&h%-h30CD7189E%-4g%-#&%')(+*-,W%ab&,1023'\0CD7189E-049_-VXY()8;2Ut#&%-4230d7<*->CD*#&2173,.%-8;#]712<%-#&h'&,.0d>{0d,10#)CD02Y%-2Z'&,10230#]730h86#^0CD7189*#^V ^Vfifi@ 2~,7MG,10d>VIR*+Vlpl2 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22$021CD,.8;'&7189*#"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k21%-?A0e"RM %-2Z71(+0k%-#)%')(+*-,"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0e'&,.0dE^89*5)2U"$M73*A71(&%7CD*#]71%-8;#&8;#&L71(+0e%-#&%')(+*-,"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k?*217Z,10CD0#7$5&#&Cd49*210hc"RM"$#730CD0h&0#712$8;#71(+0e73*-'t8;C"$#730CD0h&0#712R71(&%7<%'&'\0%,YR8971(71(+0eE-0d,1f*->S71(+0=%-#&%')(+*-,<?A*-,1071(&%-#i*#&CD0"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k21%-?A0B'[*2.897189*#<8971(,.0d>{0d,10#)CD073*A71(&0eE-0d,1f%-2<71(+0e%-#&%')(+*-,@Pf[0d>*-,10B*-,$%>{730d,T"$#730CD0h&0#712R71(&%7<%,10=8;#71(+0k21%-?A0B'[*2.897189*#<8971(,.0d>{0d,10#)CD073*A71(&0k5+73730d,.%-#&CD0=%-2Y71(+0e%-#&%'t(+*-,XY(&0e#+0%,10237<%-#]730CD0h+0#]7<73*A71(&0k%-#&%')(+*-,089L(]7-B'B'l"LX%f)490k^pGMG,10d>0d,10#&CD0BU089L(7R%-212189L#&?A0#7Z>*-,<'&,.*#+*?A8;#&%-4\%-#&%'t(+*-,.%MG,10d>VI<*+Vlp$021CD,.8;'&7189*#"$#730CD0h&0#712$71(&%7<%,.0e8;#71(+0k21%-?A0k"RM%-2Y71(+0e%-#)%')(+*-,"$#730CD0h&0#712$71(&%7<%,.0e8;#71(+0e'&,.0dE^89*5)2Z"RM}73*A71(&%7CD*#]71%-8;#&8;#&L71(+0k%-#&%')(&*-,"$#730CD0h&0#712$71(&%7<%,.0e8;#71(+0k?*217Y,10CD0#]7<5&#&Cd49*210hc"RM"$#730CD0h&0#712F8;#71(+0B73*-'t8;C"$#730CD0h&0#712$71(&%7<2.(&%,10B71(+0e21%-?A0e^86#&h*->?A*^h&89)0d,.2"$#730CD0h&0#712$<8971(0D+%-CD7149_71(+0e21%-?A0k?*ah&8)0d,.2"$#730CD0h&0#712$71(&%7<%L-,.0d0k8;#c#^5&?kf\0d,XY(&0e#+0%,10237<%-#]730CD0h+0#]7R73*71(+0e%-#&%')(+*-,X%f)490k^pGMG,10d>0d,10#&CD0eU089L(]7<%-212189L#)?0#7Z>*-,<%-h30CD7189E%-4g%-#&%')(&*-,.%089L(7-l'l'-"Lfii{9 ] DA22{~i{uv0fiv0h`?zF>JF5QS@0z@zF#`*-,Wh+0d,N73*:*-f)71%-8;#71(+0*-'&718;?A%-4U'&,10d>0d,10#&CD0U089L(7%-212.89L#&?0#]7dbU0'\0d,1>*-,.?0h230dE-0d,.%-473021712<8971(71(+073,.%-86#&8;#+L:CD*-,1')5&2dV`XY(]5)2db%>{730d,A4;*]*-a8;#+L%7A%-4;4U71(+0'\*212189f)864;89718902B%-#&hL8;E-0#`71()%771(&8;2%-2i71(+0210d7i*->N'&,10d>0d,10#&CD02i(&%E^86#+L71(+0f\0237c,102.5&49712db$0`CD*#&218;h+0d,.0h897c73*f\0H71(+0*-')718;?A%-4CD*#a)L5&,.%7189*#V 8;71(`71()8;2=CD*#+)L5+,.%7189*#gb0*-f&71%-8;#+0h%'&,10Cd8;2.89*#*->$Bo 'aV N >{*-,N'&,1*#&*?A8;#&%-4%-#&%')(&*-,.%N,1023*4;5&7189*#c%-#&hn-^V;il N >{*-,R%-hm0CD718;E%-4g%-#)%')(+*-,.%N,1021*4;5+7189*#V\n's#q2v,u,|q2v't#qy{sxu)~y{}!t~ z$218;#+L71(+0Nt#)%-4S'),10d>{0d,.0#&CD0A230d7eh+0Dt#&0hH8;# La'[0d,W8;?0#]7Fc%-#)h71(+0'&,1*-'\*230hCD*#&2373,W%-8;#7e210d7dbS%f)4;86#&hN0dE%-465&%7189*#/U%-2UCd%,1,.890h*5+7U*E-0d,71(+0<0#]7189,10R730237CD*-,1')5&2dVXY()8;20dE%-4;5&%7189*#/U%-2'\0d,1>*-,.?0h8;#&h&0d'[0#)h+0#7N*->$71(+0i73,.%-86#&8;#+L'&,1*aCD0212/23*%-2A73*L5&%,.%-#]730d071(&%7/71(+0i73,.%-8;#)8;#+L*5)4;h(&%E-0:#+*8;#a[5+0#&CD0F*E-0d,R71(+0Bt#&%-4\'\0d,.CD0#]71%L-02dV"$2B%,10215&4;7db[U0*-f&71%-8;#&0hH%/'),10Cd8;2189*#:*->oalV N>*-,B'&,1*#+*?A86#&%-4S%-#)%')(+*-,.%,1023*465+7189*#%-#&hoalV N >{*-,<%-hm0CD7189E%-4g%-#&%'t(+*-,.%N,1023*465+7189*#V,!#71()8;2<'t%'[0d,$U0N()%E-0'&,10210#730h%-#%-49L-*-,.8971()? >*-,e8;h+0#]7189>_^8;#&LA71(+0N#+*5&#')(+,.%-230N%-#]730CD0h+0#712*->'&,1*#&*5&#&2%-#&h%-h30CD7189E%-4)%-#&%')(&*-,.286#/^')%-#&8621(Ah&8;%-4;*-L5+02dVKXY(&8;2%-49L-*-,.8971(&?0D^'t49*89712h&89[0d,10#]7a8;#&h&2F*->Y8;#&>{*-,.?%7189*#pe4;8;#&L5&8;23718;C@a#+*R490h+L-0-bKh&8;21CD*5+,W230fih&8;%-49*-L5&0N2173,.5&CD715+,10/8;#+>*-,.?A%7189*#b%-#&hh&8;2.CD*5+,.230Y73*-'t8;C<a#+*fi<490h+L-0-V 7U862f)%-230h*#%=210d7*->CD*#)2373,.%-8;#]712%-#&h'),10d>{0d,.0#&CD02GR(&8;C.(h+0d'\0#&h*#i%-4;4%E%-8;4;%f)490Fa#+*R490h+L-0k8;#*-,Wh+0d,Y73*A,1021*49E-0e%-#&%')(+*-,W%aV#A%-h&h&8;7189*#b-%eh+0Dt#)897189*#@*->\71(+0Y%-#&%')(+*-,W8;C%-CdCD0212189f)864;897_@23')%-CD0Yft%-230h*#Ah&8621CD*5+,.230fih)8;%-49*-L5+02373,.5)CD715+,10A8;#+>*-,.?A%718;*#HU%-2k'&,10230#]730hV 0(&%E-0/21(&*<#H71(&08;?'\*-,171%-#&CD0*->71(&862e%-CdCD0212189ft8;4;897_23')%-CD0e86#%-#)%')(+*-,.%@,1023*465+7189*#ba8;#CD*#73,W%-237Z73*A%-49L-*-,.8971()?A2U71(&%7Yh+*#+*-7,1049_/*#c%-#_215&C.(c21')%-CD0-VY02.5&49712Z21(+*fi71(&%7$n-^V n N*->K71(+0e%-#]730CD0h+0#712$U0d,10k49*aCd%730hi8;#71(&0e'&,1*-'\*230hc23't%-CD0-VK8;#&%-4649_-bU0/h+02.CD,.89f\0h%210d7=*->Z0Da'\0d,.8;?0#]712eCD*#&CD0d,.#)8;#+L71()8;2e%-49L-*-,.8;71(&? %-#&h`%-CdCD0212189ft8;4;897_23')%-CD05&218;#&L%CD*-,1')5&2k*->ZB ':h&8;%-49*-L5&02dVXY(+0/%-49L-*-,.8971(&? U%-2=8;?')490?A0#730h5)218;#+LcM,.*49*-L+V #*5+,t#&%-4)0D^'\0d,.8;?A0#7db^%e'&,10Cd862189*#A*->oalV N%-2U%-C.(&890dE-0h>*-,'),1*#+*?A8;#)%-4&%-#&%')(+*-,W%e,1023*465+7189*#%-#&hi%A'&,10Cd8;218;*#/*->oalV N U%-2R%-C.(&890dE-0h>{*-,R%-hm0CD718;E%-4g%-#)%')(+*-,.%,.023*4;5+7189*#gV"$2F%/73*^*4>{*-,F,1021*49E^86#+LA'&,1*#&*?A8;#&%-4S%-#&h%-hm0CD718;E%-4%-#&%')(+*-,W%>*-,k^')%-#&8;2.(h&8;%-4;*-L5+02db[71(&8;223_a23730?Cd%-#f\0k5&210h8;#215+'&'\*-,17Z*->E%,.89*5&2<IRJSM71%-21^2db\8;#&Cd465&h&8;#+LN?A%-CW(&8;#+0=73,.%-#&214;%718;*#b)8;#+>*-,3O?A%7189*#i0D^73,.%-CD718;*#b&,10d73,.8;0dE%-4g86#+>{*-,W?A%7189*#ba*-,<^5+0237189*#+O%-#&23U0d,.8;#+L+VV5&,1,10#]7149_-b\71(+0A%-5+71(+*-,.2B%,.0*-,1a8;#+L*#H8;#&CD*-,.'[*-,W%718;#+L230?A%-#]718;C8;#+>*-,.?A%7189*#:8;#]73*71(+0A%-4OL-*-,.8971()?cV)XY(+0A%-5&71(+*-,.2B<8621(73*71(&%-#&:I$%7189Ea8;h&%-hMG,.890d73*+bS&0d,1,.%-#M4;%ab%-#&h"R#]73*#&89* O*4;8;#)%>{*-,k()%Ea8;#+LCD*#]73,.89f)5+730h71(+089,=71%L-L-0d,JS8;h&8;% O*-,10#+*>{*-,N(+0d,=(&049'&>Q5&4K,10dEa8;2189*#&2e*->Z71(+0/8;h&0%-2e'&,10210#730h8;#71(&8;2')%'\0d,e%-#)h R%>%04 O:5 #+ *--b O:%a8;?8;4;8;%-#+*a%-89DOIR*]0h&%abF"$#73*#&8;*&0d,1, %-Q #&h+0d-bF%-#&h0J2 5&Q 2M0d,.%-4\>*-,U71(&089,ZCD*4;4;%f\*-,.%7189*#8;#'\0d,1>*-,.?A8;#+Lk71(+0F0D^'\0d,.8;?A0#712dV 0e%,10e%-4623*=L-,W%730d>5&4\73*A210dE-0d,.%-4%-#+*#]_^?A*5&2,10dEa890dU0d,.2*->\71(+0B+waxWrts-[wmZq$xQz zQs ffWr)D z9]drtW~<~d.sx3DvF>{*-,G(&049'&>Q5&4aCD*?A?0#]712*#c0%,.46890d,<h+,.%>712*->K71(+0e')%'\0d,Vfi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22XY()8;2B,10230%,WC.((&%-2ef\0d0#215+'&'\*-,1730hf]_71(+0VU*?A8;2.8?*Q # #730d,.?8;#&8;23730d,W8;%-4h+0 V8;0#&Cd8;%c_XS0CO#+*49*-LgR Q %=P6V V "BXRT[*->&71(+0Z^')%-#&8621(FL-*E-0d,.#)?0#7db]5&#&h+0d,g'),1*m0CD7K#^5&?kf\0d,.2X VYnO['^lO V 'fiO['+l'%-#&h j Fln-n-ofiO['1'-o^VgUm )"$4;490#b+V9b4VU*-,10-bgO`VSPmln-n-TWVU$,.%>7Z*->Y"sOaJGp)F8;%-49*-LA%-CD7<?%,1^5&'i8;#c230dE-0d,.%-4g46%_-0d,.2dVX0CW(V,.0d'gV9b)XY(+0 O:5&497189't%,17_F8;21CD*5+,.210=$,1*5+'ggV $#&89E-0d,W21897_*->KY*aC.(+023730d,btY*aC.(&023730d,b Ba"=V%-215+,.h&0YM,1*30CD7$Pmln-n-oTWV-u+wr)!sr[.w^~WZ-u+W1DvkzQs-w1)9)~dzrKz@zQ1|@wAszr+~V\V V "BXPQX VZn-ofiO!-fi V 'TWV $<rJ | ~2""J"fi5@ ".fi?#&$ ! ! V%-4;h+<86#b<$VePmln-n-TWV V*-L"qV$p j 89L( '&,10Cd8;218;*# CD*-,.0d>{0d,10#)CD0H<8971( 4;8;?A8;730ha#+*<4;0h+L-0%-#&h468;#+L5&8;21718;CY,1021*5+,.CD02dV #jx3wWW1|zr]-~@wm$q{ FGq Fw-x.fi~.v^wWuw-rSu+dxmsQzQwr[sCks!w-x.~zjr x3sQz.s- PZwD^~DKq$r[sWu)v^wx3sYD~Dw+QzQw-r&bt')'gV&-oO:%-h+,.8;hP!a')%-8;#tTWVU_],.*#b)@V9b,4^730#7db\"=VSPmln-n-oTWV<"'&,104;86?A8;#&%,1_A?A*^h+04g*->CD0#730d,.86#+L8;#ih)8;%-49*-L+V #vZxmwW..|zr]~w3v+v}q$r&r)+s-~`.dQzr]wm:v+qB~.~dwdzs-Qzwrdwzx wRut+!s-Qzwrts<z{r^-az6~DQzQd~sr[|{v ffWr)dxWr[s-QzQw-rts wrDx1Dr[W=w_r wRut+!s-Qzwrts Kzr]-az{~QzD~= WZff2{q Fl "Dfib^'&'gVlD] tlD]- O*#]73,10%-46P V%-#)%-h&%TWV#)W2l "V%,.4;0d7371%ab+V9b+0d7Y%-4VPmln-n-TWVGX<(+0F,104;8;%f)864;897_N*->K%h&8;%-49*-L5&0$2373,W5&CD715+,10BCD*ah&8;#+L21CW(+0?0-V wRut+!sQzwrts-Kzr]^z{~QzD~b K PmlTWbl^ -^VF%-(&49f %-/ C.tbSIkVPmln-nalTWVYutx3D~ddr)!s-Qzwr+~wmk z{~D.w-^xW~dd= w.-r&zQQz{-srt|s wRut+!s-QzQw-rtsKqB~!u&1~VV%,1f\*#+0464b &V9b54U,1*<#gbeVZPmln-o-oTWV"$#&%')(&*-,.%i,1021*4;5+7189*#p%:?=5)49718O2373,.%730dL-_`%'&'&,1*%-CW(VZxmwW..|zr]~wmvrffWr)dxWrtsQzQwr[s& w-rddx3drtWwr wRut+!s-Qzwrts z{r]az6~DQzQd~`ffDfibt'&'gV&n- tl'+l@U5)h&%'\0237kP j 5)#+L-,1_&TWVM(V@V71(+021862db$0d')%,.71?0#7S*-> UV *?')5+730d,S%-#&h #+>{*-,W?A%7189*#=aCd8;0#&CD0-bfiJS8;#+\*-/ ')8;#+L_$#&89E-0d,.218;7_-bJS8;#+\ *-/ ')8;#+L+b)^U0h+0#VLGC.-0d,17dbO`V9b54^73,.5+f\0-bOVPmln-n-nTWV:F8;%-49*-L5&0/%-CD712db23_a#&CW(+,1*#&8;2.8;#+Lc5&#&89712k%-#&h`%-#)%')(+*-,.%c,.023*O465+7189*#V #vx3w.1|-z{r]-~w3Bq$@~DDx3|wxW~Wv^wWuw-rva \dAsr)QzD~Ns-rt|x3sQzQd~wmkzs9w1-)qF"R?23730d,.h&%-? P j *4;4;%-#)htTWV< CW~gFl "+0d,1,%-Q #&h+0d-b"=V9bMK%-49*?A%,bO`V9bE4 O*-,10#&*+bJV&Pmln-n-oTWV)"$#&%')(+*-,.%R,1023*465+7189*#k86#=5&#&,102373,.8;CD730h=730Da712R8971(')%,.718;%-4')%,.2.8;#+L+V #rx3wWW1|zr]~cwm/v+vq$r)r&&sWdQzr]HwmvaqF~W~DwzQsQzQwrdwLx w-<u[a!sQzQwr[sz{r^-az6~DQzQd~srt| vv ffWr)dxWr[s-QzQw-rtsw-rddx3drtWw-r w-<u[a!sQzQwr[sz{r^-az6~DQzQd~ W ff2!{q Fl Db+'&'gV&-o- ^-nall O*#]73,10%-4U6P V%-#&%-h&%TWV+0d,1,%-Q #&h+0d-bF"kV9bBMK%-49*?A%,bO`V9bfi4 O*-,10#+*+bBJVePmln-n-nTWV "$# 0?')89,.86Cd%-4R%'&'),1*%-C.( 73*^'t%-#&8;21(%-#)%')(+*-,.%,.023*4;5+7189*#gPVDv]z{r[ &xms-r+~W9s-Qzwr&b P]TWbKlnal^al^V+*[b$VZPmln-o-TWVkz{~D.w-^xW~dtQx+Qax3srt|q$rtsWutv^wx3scxzdr srt|`.wr)DxW~DsQzQwr[sLr^-z6~WvVVZ%-?kf&,W8;h+L-0=^715&h)89028;#cJ8;#&L5&8;23718;Cd2V V%-?=f&,.86h+L-(0 R#)89E-0d,.21897_/MG,10212dbJVZ%-?kf&,W8;h+L-0-VF%-4;46%,.h+*+b-$VaPmln-n-TWVtq$rgs z{~Wz{~ wr&dx.~dsdzwrts-&x3s-|s- Qz.sN|d"<1Wu[!wxVVU*490CdCd8?*Q #Aa86#&%')218;2VLh&8;Cd89*#&0_2 L')8;21730?0-bt[VJV9b%-4;0#&Cd8;%aVfifffii{9 ] DA22{~i{$,1*21-bK$VPmln--TWVXY(+0,10d'&,10230#]71%7189*#%-#&h5)230A*->Z>*^Cd5&2=8;#%23_^21730? >*-,=5&#)h+0d,.2371%-#&h)8;#+Lch&8O%-4;*-L2dV # ZxmwW..|zr]~ewmLkGz &v ffWrtDxrts-Qzwrts[aw-z{r) wrddx3drtWkwr/q$xDQz zQs-.ffWr)Dz^DrtffW,gq ffl " fib)'&'gV)V%-?kf),.8;h+L-0-b O:"-P Ba"BTWV$,1*21-bgRVPmln-oalTWVk+*aCd5&2186#+L%-#)hh+02.CD,.89'&7189*#8;#:#&%715+,.%-44;%-#+L5&%L-0Nh&8;%-4;*-L5+02dV #;DDrt~wmkz{~DWwax.~ Srt|]DxW~!srt|-z{r]V V%-?=f&,.86h+L-(0 R#)89E-0d,.21897_/MG,10212db V%-?=f&,.86h+L-0-V$,1*21-b\$V9bJ*21(&8b["kV9b4 08;#&2373086#b\VPmln-o-TWVkMG,1*Ea8;h&8;#&L%/5)#&8)0h%-CdCD*5&#7F*->Gh&0Dt#&89730@#+*5&#'t(+,.%-23028;#h&8;21CD*5&,.230-V # ZxmwW..|zr]~ewmRv+ ~Dq$r&r&&s.Qz{r^wmRva<qF~W~DwzQs-Qzwredwxw-<u[a!sQzQwr[sJKzr]-az{~QzD~Wb+')'gV+- ^B' V%-?=f&,.86h+L-0-bgO" P-Ba"BTWV$,1*21-bG$V9bE-*21()8b"kV9b4 086#&237308;#bG[VZPmln-n-TWV V0#730d,.86#+L+p" >,.%-?0dU*-,1>*-,?*ah+04;8;#+L71(+04;*^Cd%-4gCD*(&0d,10#&CD0e*->h&8;2.CD*5+,.230-V wRut+!s-QzwrtsJz{r]az6~DQzQd~Wb PTWb\B'^--^Vj 0%,.237db_OV$Pmln-n]TWV O:5&497189O!')%,.%L-,.%')(210dL?0#71%718;*#*->F0D^'\*218;73*-,1_`730Da7dV #Zxmw..|z{r^~:wmrt|q$r&r&&sfi `.Qz{r]wmevaFqB~.~dwdzs-QzwrNDwx w-<u[a!sQzQwr[sCz{r^-az6~DQzQd~Wba'&'gV&ntlJS%-2V,.5&CD02db&IR0d O0Da86CD*+Vj 89,.237dbt@VPmln-oalTWVZq$r[sWu)v^wx3szr=s-Qax3ssr]-&s^Sr[|DxW~!sr[|z{r^-Va'&,.8;#+L-0d,1O0d,.4;%L+b&U0d,.4;8;#gV;e%-?0d_%-?%abaO`V]Pmln-n-TWV^Y0CD*-L#&8986#+LY,10d>0d,10#]718;%-44;8;#&^2dp\"$#e8;#+>*-,.?A%7189*#F0Da73,.%-CD7189*#='\0d,.23'\0CD7189E-0-Vq F wxW~Wv^wWuwrS u+dxms-Qzwrts-gk s!wxW~kzrZxmsQzQWs yZ wd]~D#jx3w.1|-z{r]-~@wmRq{ FGqFrtsWu)v^w-xms<~Dw- +Qzwr&b['&'gVa^ -O:%-h+,.86hP!^')%-8;#tTWVJ%')')8;#b+[V9b4J0%-212db j VPmln-n]TWV"R#%-49L-*-,W8971(&?>{*-,'&,1*#&*?A8;#&%-4t%-#&%')(+*-,.%=,1023*465+7189*#V wRuta!sQzQwr[sC z{r^-az6~DQzQd~Wb P]TWb--^-alVO:%,17?R Q #+0dDO%,.CD*+bgMVPmln-n-nTWVF"$49L-*-,.8;71?*/h+0=,1023*4;5)Cd8?*Q #h+0N4;%/%-#u%Q >{*-,W%'&,.*#+*?A8;#&%-4g0#h&8i%-Q 49*-L-*2dVZxmwW~dsNzdr)!wi|d dr]-&s =s-Qaxmsbb[ ^o-^V@7?hO:%,17?R Q #+0dDO%,.CD*+bgMVPB'1'+lTWV YD~Dw&dz wr wRut+!szQwr[sG|@9sq$r s3Dwx3sdr ez s9w1w~= U~DQxW&dQax3s|D kz6~ddaxW~Dwjwrtwz{Nz!Dr)!w Kzr] ~Qz.wVM(V@V^71(&0218;2db$#&89E-0d,.2186h&%-h/h&0$"$4;8;Cd%-#]730-b"$4;8;Cd%-#]730-b[^'t%-8;#VLEO:%,17?R Q #+0dDO%,.CD*+baMV9b.4%-49*?A%,b,OV[PB'1'1'TWVgY023*4;5)Cd8?*Q #h+0<4;%B%-#q%Q >{*-,.%ap02373,.5)CD715+,.%eh+04+h)8?%-Q 49*-L-*K_cCD*#+*aCd8;?A8;0#73*A4;86#+L,5\/ R Q 237186CD*+V Zxmw~dsNzdr)!wi|d@dr]-&s7ksQ^x3sb b&]S^-^VO:%,17?R Q #+0dDO%,.CD*+b&MV9ba0d7U%-4!V\Pmln-n-oTWVK"R#)%-4;89%-h+*-,U')%,.Cd8;%-4\P$MGMYV #VU*^04;(+*+bWff r)d z9]drtdzsq$xDQz zQs- b+'&'V)--n ^&l=JS8;23f\*#PQM*-,1715+L%-4{TWVj VP-LGhV TWbx3w1x3D~.~DwO:%,17?R Q #+0dDO%,.CD*+bMV9b0d7B%-4VPmln-n-nTWVcLE%-4;5&%718;*#*->'&,1*#+*5&#,1023*4;5&7189*#%-4;L-*-,.8971(&?>{*-,k^'t%-#&8;21(h)8;%-49*-L5+02dV #vZxmwW..|zr]~Awm=v+ )dr[ dzQseu+dx=z &xms!sDr)!wq$+!wAs-Qz.wi|d{; z{r^-)3^ qfib+')'gV)-- ^-- 0#&8;CD0P 71%-49_+TWV@W <l ":O:8973-*E[bSkVGPmln-n-oTWVY*-f)5)237B'&,1*#+*5)#,.023*4;5+7189*#:<8;71(H4;8;?A89730ha#+*<4;0h+L-0-V #tZxmw..|z{r^~wmv+ vq$r&r&&s `.dQzr]:wmvaNqF~W~DwzQsQzQwrdwxjwRut+!s-Qzwrts Kzr]^z{~QzD~Asrt|vWff rtDxrts-QzwrtswrDx1Dr[WBwrtw-<u[a!sQzQwr[s Kzr]-az{~QzD~kff !q{dfib'&'Vo--n*#]73,10%-4UP6V %-#&%-h&%TWVQi>PW 2 Flfi@ 2~,72 AK$)B$CA2B2{EDX<{$7GF7BEHK.{JI22MG46%ab[UV9b\4MG,.890d73*+b\IkVPmln-n-oTWV(R2.8;#+LAL-,.%-??A%718;Cd%-4K8;#+>0d,10#&CD0@?0d71(+*ah&2<>*-,F%-5+73*?A%718;C=')%,17mO!*->{O21'[0d0CW(71%L-L8;#+L+V# ZxmwW..|zr]~wmkGzx.~D ffWr)dxWrtsQzQwr[s wrDx1Dr[W:wr gsr]&s]YD~dwaxm~@s-rt| &s-Qzwr` Q l D=$,W%-#&%-h&%iP!^')%-86#tTWVY086#&(&%,17dbXBVZPmln-o-TWVq$rtsu)v^wx3s`s-rt|\ds-r)QzQ3ffWr)Dxutx1d!s-Qzwr&V UV ,1*^*? j 04;?cbJ*#&h+*#%-#&ha_^h&#&0d_-VY0d_a#&%,b+VV$VYPmln-n-nTWV a71%718;23718;Cd%-4Z?*ah+04;2@>*-,A73*-')8;C230dL?A0#71%7189*#gV #Zxmw..|z{r^~wm vqFr&r&&s `.Qz{r]wmRvaRqF~W~DwzQsQzQwr=Dw-x wRut+!s-QzwrtsKzr]-az{~QzD~kq Fl "fib^'&'gV^-- O%,._^4;%-#)h-P Fa"BTWV<86C.(b\L<V9b\4JS5+'\0d,.+*fi_-b[VPmln-o-oTWV"R#&%'t(+*-,.%%,.C.()89730CD715+,10>*-,e%-#&%')(+*-,W%/,.023*4;5+7189*#gV #tZxmw..|z{r^~/wmg\..wr[s| w-rddx3drtWwrquutz.| ks-Qax3s sr]-&s^&x3wWD~.~Wzr]Q9q <Zl "dfib')'gVglo ^/"$5&23718;#gb&X0D+%-2=-P Ba"BTWVY*aC.()%abO`VPmln-n-oTWViq wx!u[]~$s~1|tQ&|wm@q$r[sWu)v^wx3szrkzs9w1-)~Azrr]z{~.vsrt|<wxWQ&D~ddVMG(V@V&71(+02.8;2dbg$#&89E-0d,.218;7_*->Ga5)21230D\b&+5&21230D\Vg9;AVa%-C.^2db j V9b++C.(+0dL49*KbPLYV9b4|0D[0d,.21*#b+NV\Pmlnfi]TWVK" 12 8;?'t49023723_a23730?A%718;Cd2U>*-,71(&0<*-,1L%-#&8;%7189*#*->K715+,W#71%^8;#&L>{*-,$CD*#E-0d,.2.%7189*#VLsr]-&s^DbQ P ]TWb-n-a-^Va890dL-04!b][V9bE4 V%-237304;46%-#b+V&Pmln-o-oTWVFkwr-uasx3sdQxzQt!s-Qz{~QzD~gdwxYva~Fvaszwx3s[zdrtWD~kP#&h0h)897189*#tTWVO:C$,.%ZO j 864;4V^73,.5&f[0-bO`V9bZ4 j %-(&#b=VGPmln-n-nTWV@)5&#&CD7189*#&%-4KCD0#]730d,.8;#+L+pe$,1*5)#&h&8;#+L,10d>{0d,.0#718;%-4KCD*(+0d,.0#&CD0A8;#86#+>{*-,W?A%7189*#c2373,.5)CD715+,10-V wRut+!s-QzwrtsJz{r]az6~DQzQd~Wb PTWb\B'n^-+V"*5&?A%-#)2db@VaPmln-nalTWV+"#&0d73*^*4>*-,h)8;21CD*5+,.210G%-#&%-49_a218;2dpgX<(+0GE-*aCd%f)5&4;%,._F?%-#&%L-0?0#]7'),1*t490-Vsr]+s]Db P]TWbg-ao-n^VfiJournal Artificial Intelligence Research 15 (2001) 115-161Submitted 4/01; published 8/01GRT Planning System: Backward Heuristic ConstructionForward State-Space PlanningYREFANID@CSD.AUTH.GRVLAHAVAS@CSD.AUTH.GRIoannis RefanidisIoannis VlahavasAristotle UniversityDept. Informatics54006 Thessaloniki, GreeceAbstractpaper presents GRT, domain-independent heuristic planning system STRIPS worlds.GRT solves problems two phases. pre-processing phase, estimates distancefact goals problem, backward direction. Then, search phase,estimates used order estimate distance intermediate stategoals, guiding search process forward direction best-first basis. paperpresents benefits adoption opposite directions preprocessingsearch phases, discusses difficulties arise pre-processing phase introducestechniques cope them. Moreover, presents several methods improving efficiencyheuristic, enriching representation reducing size problem. Finally,method overcoming local optimal states, based domain axioms, proposed. According it,difficult problems decomposed easier sub-problems solved sequentially.performance results various domains, including recent planning competitions,show GRT among fastest planners.1. Introductionfar, planning problems considered special kind particularly difficult searchproblems (Newell & Simon, 1972) many algorithms decomposition, abstraction, leastcommitment etc. proposed cope them. early 90's, researchers arguingplan-space planning efficient state-space planning (Barrett & Weld, 1994;McAllester & Rosenblitt, 1991; Minton, Bresina & Drummond, 1994; Penberthy & Weld, 1992).mid 90's, new algorithms appeared achieved even better performance transformingplanning problems either graph solving problems (Blum & Furst, 1995, 1997)satisfiability ones (Kautz & Selman, 1992, 1996, 1998). However, shown simplesearch strategies use domain-dependent heuristics solve large problems (Gupta &Nau, 1992; Korf & Taylor, 1996; Pearl, 1983; Slaney & Thiebaux, 1996).recent years, part planning community turned towards heuristic planning, adoptingknown search strategies developing powerful domain-independent heuristics achievesignificant performance. first planner UNPOP (McDermott 1996, 1999) followedASP (Bonet, Loerings & Geffner, 1997), HSP (Bonet & Geffner, 1998), HSPr (Bonet & Geffner,1999), GRT (Refanidis & Vlahavas, 1999b), FF (Hoffmann & Nebel, 2000) ALTALT (Nigenda,Nguyen & Kambhampati, 2000). domain independent heuristic planners search solutionseither state-space regression space. use variations relativelysimple idea guide: estimate distance two states, based estimatesdistances fact problem one two states.2001 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiREFANIDIS & VLAHAVASplanners primarily classified based forward backward direction,heuristic constructed state-space traversed. distinguish followingthree categories:Forward heuristic construction, forward search (ASP, HSP, FF).Forward heuristic construction, backward search (HSPr, ALTALT).Backward heuristic construction, forward search (UNPOP, GRT).Generally, forward direction seems advantageous backward one,constructing heuristic searching, backward direction caseincomplete goal states, problems invalid states unreachable facts usually arise.However, using forward direction tasks requires reconstructing heuristic functionvisited state, spending way significant portion processing time, usingopposite directions tasks allows constructing heuristic once, pre-processing phase.paper presents GRT planning system. domain independent heuristicplanner constructs heuristic once, backward direction pre-processing phase.UNPOP, although uses directions, reconstructs heuristic scratch visitedstate. GRT, pre-processing phase estimates distance fact goalsproblem. search phase, estimates used order estimate distancevisited state goals, guiding search process forward directionbest-first basis. Constructing heuristic offers ability evaluate statesquickly, traversing state-space forward direction allows planner avoid invalidstates arise regression space.paper substantially extends previous work (Refanidis & Vlahavas, 1999b, 1999c, 2000a2000b), presents proves fundamental theory planner, along manynew techniques developed it, extensively tests contribution technique overallperformance provides thorough comparison planning systems.rest paper organized follows: Section 2 presents data structures mainalgorithms planner. Section 3 discusses difficulties incomplete goal states causebackward direction construction heuristic presents methods cope them.methods also applied identify enrich poor domain representations.Two approaches reduce problem's size presented Section 4. first one dealsidentification elimination irrelevant objects second one concerns adoptionnumerical representation resources.Section 5 deals problem local optimal states proposes method copethem. Specifically, XOR-constraints introduced used order decompose difficultproblems easier sub-problems solved sequentially. Section 6 presentsoperation GRT, Section 7 presents related work Section 8 presents performance results,show GRT among fastest domain-independent planners. Finally, Section 9concludes paper poses future directions.2. GRT HeuristicSTRIPS (Fikes & Nilsson, 1971), action represented three sets facts:precondition list Pre(a), add-list Add(a) delete-list Del(a), Del(a) Pre(a).state defined finite set facts. action applicable state if:Pre(a)state resulting application action state defined as:116(1)fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGS' = res(S,a) = \ Del(a) Add(a)(2)Inductively define state resulting application sequence actions (a1,a2, ..., aN) state as:S' = res(S, (a1, a2, ..., aN)) = res( res(S, (a1, a2, ..., aN-1)), aN)(3)requirement action ai applicable state res(S, (a1, a2, ..., ai-1)),i=1, 2, ..., N. formalization used henceforth, set problem constants assumedfinite function symbols used, set actions finite.planning problem P triplet P=(O, Initial, Goals), set ground actions,Initial initial state Goals set facts. task find sequence actions a1, a2,..., applied initial state, state resulting applicationsuperset Goals. sequences actions called Plans. plan appliedinitial state called valid plan. valid plan achieves Goals called solutionplanning problem. planning problem may several solutions. latter caseproblem described unsolvable.next sub-section gives brief presentation ASP heuristic, motivationhelps understand following concepts, whereas subsequent sub-sections presentGRT heuristic detail.2.1ASP HeuristicASP heuristic, action fact p Add(a), rule Cp formed,C=Pre(a). Assuming set rules, said fact p reachable state prule C p fact q C reachable S.So, function g(p,S) defined, inductively assigns number fact p,estimate number steps needed achieve p S, i.e. distance p S.specifically, g(p,S) set 0 every fact p S, g(p,S) set i+1, 0, fact prule C p exists, g (r , ) = . Thus:defg ( p, ) ={rC0,pi+1,Cp,g (r, ) =rC,(4)p reachablecase one rules Cp fact p, rule minimumcost chosen. Note fact p initially achieved rule C1p, may re-achieved,later, another rule C2p smaller cost. preconditionssecond rule achieved time first rule applied. task applyingrules continues rule achieve fact smaller cost exists. distancescomputed way unique.set facts P, distance defined as:defg ( P, ) = g ( p , )pP(5)ASP planner uses g(P,S) estimate distances intermediate stateGoals. So, ASP heuristic function defined as:117fiREFANIDIS & VLAHAVASdefH( ) = g (Goals , )ASP(6)ASP heuristic take account delete lists actions. simplifiedproblem created ignoring delete lists referred relaxed problemcorresponding actions referred relaxed actions. complexity constructingHASP(S) linear, respect number ground actions number ground facts.2.2Backward Heuristic ConstructionInstead estimating distance fact current state forward direction,ASP does, GRT estimates distance fact goals backward direction.task performed once, pre-processing phase. search phase, estimatesused estimate distance intermediate state goals. backwardforward estimation distance two states often results different values, sinceheuristic precise. However, two directions result estimates equal quality average.estimates distances fact goals stored table, recordsindexed facts. call table Greedy Regression Table (byacronym GRT comes from), since estimates obtained greedy regressiongoals.order construct heuristic backwards, actions problem inverted. Letaction S' two states, applicable S' = res(S,a).inverted action a' action applicable S', = res(S', a'). inverted actiondefined original action follows:Pre(a')=Add(a) Pre(a) \ Del(a)Del(a')=Add(a)Add(a')=Del(a)(7)inverted ground actions applied goals, assigning progressively groundfact p estimate distance goals, way similar ASP. Applying inverted actionsgoals presupposes goals form complete state. Section 2 assumedalways case, whereas Section 3 case incomplete goal states treated.2.3Related Factsorder obtain precise estimates, GRT heuristic tries track interactions ariseestimating distances fact goals. word 'interaction' meanachieving fact may affect achieving facts positively negatively. order trackinteractions notion related facts introduced.Definition 1 (Related facts). fact q related another fact p, achieving p causes fact qachieved well.use notation q%relp denote q related p. set facts relatedspecific fact p denoted rel(p), i.e.:rel ( p ) = {q : q %rel p}(8)set related facts set facts P defined union related facts P-facts:118fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGrel ( P ) =rel ( p)(9)pPProposition 1. inverted action achieving fact p, related facts p defined as:rel(p) = Pre(a) rel(Pre(a)) Add(a) \ Del(a)(10)Proof: Formula 10 inductive, since defines related facts fact p based relatedfacts preconditions action achieving fact. Thus, prove induction.formula holds goal facts, suppose hypothetical inverted actionwithout preconditions achieving them. So, goal facts related other. Then, supposeFormula 10 holds preconditions inverted action a. enough proveholds also facts action adds. Let p fact. facts holdapplication action, related facts p, holdapplication, i.e. preconditions action together related facts, plus factsaction achieves, minus facts action deletes, exactly Formula 10 states.According Formula 10, facts achieved action related facts.Moreover, fact least related itself.single path achieve specific fact, related facts would definedunique way. However, rare situation. Thus, many actions achieve fact,many paths achieve preconditions actions; therefore, extremely largenumber possible combinations. Storing, fact, related facts possible waysachieving it, requires huge amounts time space. efficiency reasons decidedstore one set related facts fact, set corresponds shortest pathachieves fact, according heuristic.Proposition 2. relationProof: relation%rel%relreflexive, neither symmetric, transitive.reflexive, since fact related itself. relationsymmetric, since fact q, pre-requisite achieve p, qachieving p delete q) p%rel%rel%relp may hold (if actionq may hold, since q may achieved% transitive, since relations q % p p %cannot conclude q % r holds, since possible action achieving r delete q.p. Finally, relationrelrelrelrelrfact p, dist(p) denotes estimated distance goals. Next, present axiomsconcerning distances facts.Axiom 1. cost achieving set facts {p1, p2, ..., pN} simultaneously, cannot lowermaximum individual distances.Ndist({p1, p2, ..., pN})max (dist(pi))i=1(11)Axiom 2. inverted action achieves fact p, distance p equal costsimultaneously achieving a's preconditions plus one.dist(p)=dist({p1,p2, ...})+1, pi Pre(a)119(12)fiREFANIDIS & VLAHAVASProposition 3. q%relp true two facts q p, dist(q)dist(p).Proof: prove Proposition 3 induction. Proposition 3 holds Goals, sincegoal facts zero distances related other. Suppose Proposition 3 holdsset currently achieved facts Facts. suffices prove action a,Pre(a)Facts, Proposition 3 holds set FactsAdd(a).Suppose fact pAdd(a) achieved, re-achieved smallercost. another fact q FactsAdd(a), q rel p, either q also%achieved hence dist(q)=dist(p), q precondition then, according Axiom2,dist(q)<dist(p), finally q related fact a's precondition, say q' dist(q')<dist(p)(Axiom 2) dist(q)dist(q') (Proposition 3 holds Facts), dist(q)<dist(p).Let us suppose another fact q, p rel q. q achieved a,%dist(p)=dist(q). q achieved a, q previously achievedanother action, q Facts. case, p would also previously achieved anotheraction, re-achieved a, also p Facts. Since Proposition 3 holds Facts,distOLD(p)dist(q), distOLD(p) previous distance p. new distance p smallerprevious distance, dist(p)<distOLD(p), dist(p)<dist(q). Therefore, Proposition 3 holdsevery case.Corollary 1. q%Corollary 2. q%relrelp p%relp pq, dist(p)=dist(q).%relq, q achieved p.two corollaries follow directly Proposition 3. Concerning Corollary 2,expression 'has achieved before' means pre-processing phase, distancesgoals estimated progressively, dist(q) computed dist(p). casefact re-achieved smaller distance, consider last time.Corollary 3. sequence facts p1, p2, ..., pN, N>2, piwithout pi+1%relpi also holding, impossible pN%rel%relpi+1, i=1,2,...,N-1, hold,p1.Corollary 3 follows directly Corollary's 2 time ordering relation.Proposition 4. Facts related achieved action.Proof: Let p q two facts related other, i.e. q%relp p%relq. Let a1 actionachieves p a2 action achieves q, pAdd(a1) qAdd(a2). provea1a2. Suppose a1a2. Since q rel p, q may add effect a1, precondition a1,%related fact a1's precondition. However, according Corollary 1, dist(p)=dist(q). Thus, qcannot anything else add effect a1, case dist(q) < dist(p) would hold.way prove pAdd(a2). Thus, {p,q}Add(a1)Add(a2). However,case, first action applied computing distances would achieve facts. So, factsachieved action.120fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGrelated facts play critical role estimating cost achieving set factssimultaneously. GRT groups related facts sums maximum individual cost group.example, q rel p, p rel r q rel r hold three facts q, p r, three facts%%%grouped together contribute total cost maximum cost, dist(r).However, q rel r hold (since relationtransitive), p rrel%%grouped together, q included group. case, q belongs anothergroup, contributes separately total cost.aggregation process performed function AGGREGATE, described below.function takes set facts {p1, p2, ...., pN} input, together distances dist(pi)lists related facts rel(pi), estimates cost achieving simultaneously.function used pre-processing phase, order estimate application costinverted actions, search phase, order estimate distance intermediate stategoals.Function AGGREGATEInput: set facts {p1, p2, ..., pN }, distances dist(pi) lists related facts rel(pi).Output: estimate cost achieving facts simultaneously.1. Set M1 = {p1, p2, ..., pN }. Set Cost = 0.2. (M1 ) do:a) Let M2 set facts pi M1 included listrelated facts another fact pj M1, without pj alsoincluded list related facts. formally:M2 = { pi: pi M1, pj M1, pi rel(pj) pj rel(pi) }b) Let M3 set facts M1 included M2,included least one lists related factselements M2.M3 = { pi: pi M1 \ M2, pj M2, pi rel(pj) }c) Divide M2 disjoint groups facts relatedother. group add common cost facts Cost.d) Set M1 = M1 \ (M2M3).3. Return CostAGGREGATE function illustrated blocks-world problem Figure 1. PartGreedy Regression Table problem shown Table 1. simplicity, fact pconsider related facts zero distances (i.e. Goals) fact p itself.simplification affect estimated distances.cbbcInitial StateGoal StateFigure 1: 3-blocks problem.121fiREFANIDIS & VLAHAVASLet us compute distance initial goal state. initial state consistsfollowing set facts:( (on table) (clear a) (on b table) (on c b) (clear c) )1results Table 1, initial state facts related (on c b), whereas (on c b)related fact. Thus, first iteration AGGREGATION loop, M2 set ((on cb)) (step 2a) M3 set ((on table) (clear a) (on b table) (clear c)) (step 2b). So, Costbecomes equal distance (on c b), i.e. 3 (step 2c) M1 becomes empty. seconditeration performed value 3, actual distance initial goalstate, returned.FactDistancegoalsRelated facts(on c table)0()(on b c)0()(on b)0()(clear a)0()(on table)1( (clear b) )(clear B)1( (on table) )(on b table)2( (on table) (clear a) (clear b) (clear c) )(clear c)2( (on table) (clear a) (clear b) (on b table) )(on c b)3( (on table) (clear a) (on b table) (clear c) ).........Table 1: Part Greedy Regression Table 3-blocks problem.Corollary 3 ensures set M2 (step 2a function AGGREGATE) never empty.Proposition 4 ensures M2 always partitioned groups facts achievedaction (step 2c). number iterations function AGGREGATE performsbounded initial size M1, however usually single iteration performed.2.4Pre-Processing Algorithmestimation distance fact Goals computation listsrelated facts facts problem performed following algorithm:1representation facts, actions states adopt PDDL (Planning Domain Definition Language) syntaxthroughout paper. manual PDDL language found URLhttp://www.cs.yale.edu/pub/mcdermott/software/pddl.tar.gz122fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGPre-Processing AlgorithmInput:action predicate definitions domain objects problem.Output:distance estimate goals dist(p) related facts rel(p)ground fact p problem.1. Let Actions set inverted ground actions givenproblem. Actions, set dist()=+.2. Let Agenda list inverted actions. Set Agenda=.3. Let Facts set problem's ground facts. fFacts set dist(f)= +.4. f Goals set dist(f)=0 rel(f)=Goals.5. action Actions, AGGREGATE(Pre())<+,dist()=AGGREGATE(Pre())+1 add end Agenda.set6. Agenda do:a) Extract first action Agenda, say .b) every fact f Add(), dist(f)>dist(), then:- dist(f)=dist()- rel(f) = Pre() rel(Pre()) Add()\Del()- every action b Actions, f Pre(b),AGGREGATE(Pre(b))+1<dist(b), dist(b)=AGGREGATE(Pre(b))+1push action b end Agenda.Agenda works FIFO basis. action re-inserted Agenda costbecomes smaller. Thus, fact achieved several times, time smaller cost.cost applying Pre-Processing Algorithm polynomial number problem groundfacts ground actions.Proposition 5. Pre-Processing Algorithm preserves Axiom 2.Proof: step 6b, cost applying action set equal cost achievingsimultaneously preconditions action plus one. cost assigned add effectsaction, except lower costs already assigned them. Thus, Axiom 2 preserved.Proposition 6. Function AGGREGATE preserves Axiom 1.Proof: prove Proposition 6 induction. Axiom 1 holds Goals, zerodistances related other. Besides, Propositions 3 4Corollaries 1, 2 3 hold also them. Suppose next Axiom 1 inducedPropositions Corollaries hold currently achieved facts Facts. suffices proveaction a, Pre(a) Facts, Axiom 1 holds new set achieved factsFacts'=Facts Add(a).Consider set facts P Facts'. prove function AGGREGATE preserves Axiom 1,regard randomly selected set P. Let p fact maximum distance amongfacts P. According definition AGGREGATE function, suffices prove panother fact equal distance included M2.123fiREFANIDIS & VLAHAVASp P\Add(a), every fact qP\Add(a), p%relq, dist(q)dist(p)(according Proposition 3, holds Facts) finally dist(q)=dist(p), pmaximum distance among facts P (the rationale used casesequence facts q1, q2, ..., qN, p rel q1 qi rel qi+1, i=1, 2, ..., N-1). q Add(a)p%%rel%q, p would precondition a, related fact precondition a. However,case would possible p%relq, distance q would greater costp (according Axiom 2, holds preconditions action a)contradiction hypothesis p maximum distance among facts P.Let us consider case p Add(a). p firstly achieved, factsq, p rel q hold, certainly achieved re-achieved add effects action%a, application cost. p re-achieved smaller cost,impossible hold p rel q another fact q P\Add(a). Actually, hypothetical case%would dist(q)distOLD(p), since Proposition 3 holds q previous distance p,distOLD(p)>distNEW(p), dist(q)>distNEW(p), contradiction hypothesis pmaximum distance among facts P. Therefore, case, p another fact equalcost included M2 cost achieving simultaneously facts P equal highermaximum distance.close section mentioning two types facts, static facts dynamicfacts, found problem. first type concerns facts neither addeddeleted action, second concerns rest facts. GRT classifies automaticallyfacts, analyzing action schemas domain. procedures presented Section 2,i.e. distance estimates related facts, concern dynamic facts.3. Detecting Enhancing Incomplete StatesBackward heuristic construction induces problem: problems goalsconstitute complete state description, possible apply inverted actions them.example, commonly used logistics problems, packages movedseveral locations via trucks planes, goals determine final locations trucksplanes. source problem GRT heuristic constructed using stricterusual regression, i.e. uses actions, add effects non-deleted preconditions(i.e. preconditions corresponding inverted actions) included within goals(in usual regression, actions least one add effect within goals used). wayGRT succeeds obtaining precise estimates avoiding unreachable facts.solution adopted GRT confront problem incomplete goal states enhancegoals new facts, contradiction existing ones. example, sincegoals 'logistics.a' problem (Veloso, 1992) determine final locations twoplanes, supposed one planes could three airports. So,ground facts:(at plane1 pgh_air) (at plane1 bos_air) (at plane1 la_air)(at plane2 pgh_air) (at plane2 bos_air) (at plane2 la_air)added new goal state, called henceforth enhanced goal state.noted enhanced goal state used pre-processing phase,construction heuristic. search phase, attention paid reach original124fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGgoals. way, completeness never lost, even case wrong factsselected enhance Goals. However, selecting wrong facts may significantly affectefficiency heuristic function.Two issues arise trying enhance goals: first one detect candidatenew goal facts second one use. Sections 3.1 3.2 examineissues, Section 3.3 similar technique used identifying enriching poor domainrepresentations.3.1Detecting Missing Goal FactsRegarding identification candidate facts enhance goals, two automaticapproaches. first one consists forward GRAPHPLAN-like (Blum & Furst, 1999) prepreprocessing phase computes binary mutual exclusion relations (or simply "mutex"relations) among facts problem. number optimizations approachpresented (Refanidis & Vlahavas, 1999c), based primarily monotonic behaviormutual exclusion relations (Long & Fox, 1999; Smith & Weld, 1999) secondly factnecessary construct complete planning graph, since used extractingplan. computation mutual exclusion relations, facts mutuallyexclusive goal fact considered candidates enhancement goals.advantage extra information needed, apart usual STRIPS domainrepresentation. Moreover, mutual exclusion relations easily recognized humanexpert detected way. Finally, approach also exploited coarse-grainedreachability analysis problem's facts. disadvantages approach timeconsuming detect mutual exclusion relations higher order two.second approach use domain specific knowledge form axioms. example,axiom state truck plane always located place. So, goalsdetermine truck is, deduce set candidate goal facts using axiom.advantage approach time needed deduce candidate facts negligible,comparison time needed rest planning process. Moreover, complicatedrelations simple binary mutual exclusion ones encoded. disadvantage extralabor required domain encoding. However, several methods automatic discoverydomain axioms proposed, e.g. DISCOPLAN system (Gerevini & Schubert, 1998)work Fox Long automated inference invariants (Fox & Long, 2000),future plans adopt method GRT.GRT planner uses first approach detect missing goal facts. Thus, overheadtotal solution time imposed extra pre-processing work. contribution worktotal problem solving time varies less 10% domains like blocks-world,20% domains like logistics. ratio depends difficulty domain, i.e.much time consumed search phase. Logistics problems easier blocks-worldproblems, domain overhead severe. future, intend adoptautomatic method detecting domain axioms, order avoid overhead.3.2Enhancing GoalsGRT supports three methods selecting among candidate new goal facts:Select candidate facts.Use initial state facts.Favor promising facts.125fiREFANIDIS & VLAHAVASfirst method considers found facts goal facts assigns zero distances them.cases, enhanced goal state obtained way valid state, since new factsmay mutually exclusive (but original goals). advantageapproach heuristic construction fast, since many facts achievedbeginning large number actions become initially applicable. disadvantageobtained heuristic less informative, since small differences obtainedestimates. So, best-first strategy tends towards breadth-first, visits states, consumestime, generally produces better plans two methods.second method enhances goals candidate facts also includedinitial state, whereas facts mutually exclusive selected ones, rejected.advantage method, compared first one, results greater differencesfacts' distances, therefore faster search phase. hand, preferenceinitial state facts risk, - even worse - cannot included withingoals, search process may become disoriented, leading longer plans. methodsuitable problems, objects' properties unnecessary solve problemleft undetermined goals.third method tries combine advantages two. contrast them,enhancement goals performed single step, prior construction heuristic,method adds facts goals progressively, parallel heuristic construction.Actually, facts added goals case Agenda (Section 2.4) becomes empty.case, candidate facts progressively assigned zero distances, new inverted actionsatisfies preconditions. time fact selected, candidate facts mutuallyexclusive selected one rejected set candidate facts.method favors facts combined already achieved facts, order makeinverted action applicable. following four rules applied decreasing preference:facts combined original goals selected first.Then, facts combined already achieved facts selected.Next, facts included initial state selected.Finally, remaining candidate facts selected randomly.Generally, method results best solving speed and, many cases, produces equaleven better plans first two methods. However, especially terms plan quality,many exceptions depending specific problem. difficult create problemsmethods presented performs best. default method GRT plannerfirst one, method used AIPS-00 competition2.Note domains, like blocks-world, freecell elevator AIPS-00 competition,gripper movie domains AIPS-98 competition3, goals completenear-complete state descriptions; therefore method used domains affectneither solution time solution quality. domains, mystery (AIPS-98),impossible predict, without solving planning problem, candidate facts couldactually goal facts, case acceptable method goal completion firstone.23official WEB page AIPS-00 competition found URL http://www.cs.toronto.edu/aips2000/.official WEB page AIPS-98 competition found URLftp://ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html126fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING3.3Domain Enrichmentsection, present approach adopted GRT planner, order deal poordomain descriptions. word 'poor' refer domains negative facts implicitlypresent initial state actions' preconditions. GRT faced problem twice,movie elevator domains.order explain problem, let us consider elevator domain, one elevator,several floors several passengers. passenger located initial floor wantsmove her/his destination floor. domain described four action schemas, (board FloorPassenger) (depart Floor Passenger) boarding leaving elevator (up Floor1Floor2) (down Floor1 Floor2) moving elevator.action schema (board Floor Passenger) defined following PDDL formula:(:action board:parameters (?f ?p):precondition (and (floor ?f) (passenger ?p)(lift-at ?f) (origin ?p ?f)):effect (boarded ?p))dynamic predicate definition action schema board boarded, add effectdenoting passenger boarded elevator. precondition requiringpassenger boarded. problem definition twofold. Firstly, actionapplied several times passenger plan, i.e. passenger may boardelevator although she/he already boarded. Secondly, specifically GRT, statedexplicitly passengers initially boarded. Actually, initial state contains static factsonly, removed successive states. However, GRT takes account dynamicfacts order estimate distances. result initial state subsequentstates assigned zero distances Goals best-first strategy behaves breadthfirst one.needed definition new predicate, say not_boarded. Facts predicateadded initial state, denoting passenger initially boarded,action schema board changed accordingly.GRT performs domain enrichment run-time. identification situationperformed way similar identification incomplete goal states. case, G RTlooks dynamic facts problem mutually exclusive initial state fact.case facts, negations identified facts defined run-time addedinitial state. Furthermore, negations added preconditions lists delete listsactions achieve identified facts.elevator domain case board depart actions boardedserved predicates. not_boarded not_served predicates defined run-time, initialstate enhanced facts determining passenger neither boarded served yetactions board depart transformed accordingly. example, action schema boardtransformed following definition:(:action board:parameters (?f ?p):precondition (and (floor ?f) (passenger ?p)(lift-at ?f)(origin ?p ?f) (not_boarded ?p)):effect (and (not (not_boarded ?p))(boarded ?p))127fiREFANIDIS & VLAHAVASsimilar situation arises movie domain. domain, goal enough snackswatch movie. several action schemas form:(:action get-chips:parameters (?x):precondition (and (chips ?x)):effect (and (have-chips)))action schema static fact (chips ?x) precondition produces dynamic fact(have-chips). action applied several times, however enough achieve goalchips. difficulty domain initial state implicitly declareschips (and dips pops etc), specific dynamic fact make clear.Therefore, case domain enrichment process takes place, GRT assigns initial state zerodistance goals. domain enrichment feature, GRT detects facts likehave-chips, have-dips etc mutually exclusive initial state, definesnegations (not_have-chips, not_have-dips etc.), adds initial state transformsactions accordingly.domains, without domain enrichment feature GRT planner couldsolve easiest problems. However, feature able tackleproblems efficiently.Adding negative predicates preconditions actions may lead loss completeness,since actions may able applied states, otherwise could. orderprevent completeness, GRT treats new preconditions conditional preconditions, i.e.necessary application action state, however, presentcurrent state removed successor one.4. Reducing Size Problemssection, two methods reduce size problem, i.e. number ground factsactions, presented. first method refers identification elimination objects,certainly part solution. second method concerns adoptionnumerical representation resources, instead problematic atom-based representationnumbers used domains like mystery freecell. Reducing size problemreduces effort needed solve it, especially pre-processing phase, distancesfacts problem computed.4.1Eliminating Irrelevant Objectsmany domains, objects irrelevant solution. typical examplesfound transportation domains, like logistics, mystery elevator,packages initially found destinations specific destination determined.So, objects, together facts actions containing them, removedproblem description, without losing completeness.GRT developed method detects removes irrelevant objects. methodconcerns pure STRIPS domains without negation preconditions actions goalformula; however, easily extended cover cases. objects identifiedpre-processing phase using following two rules:object irrelevant solution specific planning problem, if:128fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGappear goal fact, unless fact also included initial state,action containing object preconditions, unless object also containedaction's effects.conditions strict, ensure detected object certainlyirrelevant, maintain completeness problem solving process.Proposition 7. object satisfying rules safely removed problemdescription, without sacrificing completeness.Proof: Suppose object obj identified, two rules hold.show obj necessary achieve goal fact, contain obj. Let usassume fact g Goals, contain obj. Suppose actionachieves g, precondition containing obj. case, second rule violated, sinceaction including obj preconditions, without obj appearing effect. So, fact gachieved actions without preconditions containing obj. Thus, regress goalsusing actions achieving g, established subgoals contain obj. However, wayreject actions including obj preconditions achieve new established subgoals.So, obj necessary achieve goal subgoal problem. Moreover, goalfact containing obj, achieved; even one, already present initialstate. Therefore, obj safely removed problem.application rules elimination irrelevant objects doneprogressively. Let us consider enhanced logistics domain, added colors. Specifically,define dynamic predicate (painted ?object ?color) denoting color package, staticpredicate (color ?color) declaring available colors, action schema (paint ?object?old_color ?new_color) painting package. Let us assume goal statedetermine colors packages. case, colors irrelevant objects safelyremoved, together facts actions include colors.Suppose also brushes used perform paint operation. twonew action schemas, (get ?brush) (leave ?brush) predicate (have ?brush),effect get action precondition enhanced action (paint ?package ?color ?brush).case, brushes also irrelevant eliminated. However, since action paintneeds brushes effects containing (i.e. (painted ?package ?color) ), brushesremoved, due second rule. However, removing color objects, paintactions removed; thus, brushes violate second rule remaining actionssafely removed.disadvantage approach elimination irrelevant objectsremove objects eventually appear plan, better (i.e. shorter) plansusing them. example, logistics domain, suppose three cities, city1, city2city3 package transferred one location city1 another location city2.case, city3, together locations truck, necessary solve planningproblem, since package transferred directly city1 city2, without going via city3.However, easy identify irrelevance city3. Actually, plans transportpackages city1 city2 via city3. decide remove city3 objectsproblem representation, take risk sacrificing completeness, since problem maybecome unsolvable. Deciding safely, without loss completeness, city3 objectsremoved, hard solving original problem.129fiREFANIDIS & VLAHAVASapproaches elimination irrelevant redundant information, order achievebetter performance, proposed Nebel, Dimopoulos & Koehler (1997), Scholz (1999)Haslum & Jonsson (2000). work Nebel, Dimopoulos & Koehler concerns ignoringirrelevant facts actions (not objects), based heuristics approximate planbackchaining goals without taking account conflicts. Although approachpowerful, terms elimination, one presented section, solutionpreserving. Furthermore, may time-consuming, since demands constructioninitial approximate plan.Scholz introduces action constraints, i.e. patterns action sequences appliedstates produce overall effects. Action constraints used pruningpurposes state-space planners, reducing size search space levelspartial-order planners (Minton, Bresina & Drummond, 1994), without losing completeness.work Scholz actually re-investigation sleep sets actions originallypresented Godefroid & Kabanza (1991) also examined us, nameprohibited actions, earlier version GRT (1999a). experience authorsdetecting pruning redundant actions sequences time consuming, effectiveapproach employ closed list visited states, paying however cost terms memory.latter approach adopted GRT planning system. However Scholz considers actionsequences length two, makes approach fast enough less effective closed listvisited states structure.Haslum Jonsson compute reduced set actions problem, ignoring actionsequivalently replaced sequences actions. approach solution preserving,adopted STRIPS planner pre-instantiates actions problem,results, planners, considerable speed-up also longer plans.4.2Numerical Representation Resourcessection, present enhanced STRIPS formalism, resources representednumbers, instead atoms. work motivated mystery domain, suitabledomain resources. Moreover, easily extended cover domainsreasoning numbers required.GRT supports explicit representation resources natural format, i.e.numerical format. According this, resources distinguished types objectsseparately declared using following statement:(:resources R1 R2 ... RN )Ri various resources. Furthermore, declarations following form addedinitial state description :(amount R1 V1) (amount R2 V2) ... (amount RN VN)denoting initial quantity resource. Moreover, allowed resources participaterelations atomic facts. Finally, action definitions enhanced, declare explicitlyconsumed resources.example, consider mystery domain, comprises cities, connected viaedges, packages transferred initial locations destinationstrucks. beginning, city amount fuel. truck travel cityc1 adjacent city c2, c1 must least one unit fuel. journey, fuel c1decreased one.130fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGoriginal domain representation, different fuel quantities represented relationsform4:(fuel fuel0) (fuel fuel1) (fuel fuel2)etc.orderings quantities represented relations follows:(adjacent_fuel fuel0 fuel1) (adjacent_fuel fuel1 fuel2) etc.initial amount resources city as:(city_fuel city1 fuel3) etc.Finally, actions consume resources, e.g. moving truck, following form:(:action move:parameters (?tr ?c1 ?c2 ?f1 ?f2):precondition (and (truck ?tr) (city ?c1) (city ?c2)(adjacent_cities ?c1 ?c2) (fuel ?f1) (fuel ?f2) (at ?tr ?c1)(adjacent_fuel ?f1 ?f2) (city_fuels ?c1 ?f2)):effect (and (not (at ?tr ?c1)) (not (city_fuel ?c1 ?f2))(at ?tr ?c2) (city_fuel ?c1 ?f1)))order idea resources represented GRT, let us consider STRIPSMYSTY-X-1 problem mystery domain. problem 6 cities, 6 resource objectsdeclared:(:resources r1 r2 r3 r4 r5 r6)resources related corresponding cities:(city_fuel city1 r1) (city_fuel city2 r1) ... (city_fuel city6 r6)Propositions added initial state, denoting initial availability resource:(amount r1 1) (amount r2 2) ... (amount r6 3)Finally, action move defined way separates resource requirementsprecondition effect lists:(:action move:parameters (?tr ?c1 ?c2 ?f):precondition (and (truck ?tr) (city ?c1) (city ?c2) (at ?tr ?c1)(adjacent_cities ?c1 ?c2) (city_fuel ?c1 ?f)):effect (and (not (at ?tr ?c1)) (at ?tr ?c2)):resources (amount ?f 1))Table 2 shows number ground facts ground actions first five problemsmystery distribution, two alternative resource representations. clear table,numerical representation resources important reduction numberground facts, considerable case ground actions. evenimportant size problem atom-based representation grow illimitably,levels resource availability added, whereas numerical representation sizeproblem remains constant.4AIPS-98 competition, different predicate object names used; however, papertranslated meaningful ones simplicity.131fiREFANIDIS & VLAHAVASAtom representationground factsground actionsProblemstrips-mysty-x-1strips-mysty-x-2strips-mysty-x-3strips-mysty-x-4strips-mysty-x-5101359277178299Numerical Representationground factsground actions150359616762102325563102301442694812008161681032Table 2: Size problem (number ground facts actions)two alternative resource representations.5.Using XOR Constraints avoid Local Optimal Statessection, tackle problem local optimal states. Firstly, illustrate problem,introduce XOR-constraints finally present exploited GRT orderavoid local optima.5.1Local Optimal Statessearch phase, GRT always selects expand promising state, accordingheuristic. various facts problem independent even GRT always managedtrack interactions related facts, strategy would optimal. However,always case times search led local optimal states. Therefore, plannertemporarily backtrack less promising states, selecting promising ones.Figure 2 presents example situation:210Initial stateKR01Goal state2102K01R2Figure 2: 3x3 grid problem.problem refers grid-like domain (McDermott, 1999), K key R robot.robot proceed adjacent positions. valid actions get leave keymove robot. Table 3 shows part Greedy Regression Table problem Figure 2.According Table, distance initial goal state 10. twoapplicable initial state actions, moving R n1_0 moving R n0_1. moving Rn1_0 resulting state distance goals equal 9, whereas moving R n0_1resulting state distance goals equal 11. planner decides move Rn1_0 subsequently n2_0. However, obvious optimal first movementsmoving robot n0_1, next n0_2, getting key etc.132fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGFactDistanceGoalsRelated Facts(at R n2_0)(at K n2_2)(at R n1_0)(at R n0_0)(at R n0_1)(at R n2_1)(at R n2_2)(in R K)(at R n1_2)(at K n1_2)(at R n0_2)(at K n0_2)001231233748()()()()()()()( (at R n2_2) )()( (at R n1_2) )()( (at R n0_2) )Table 3: Part Greedy Regression Table 3x3 grid problem.Initially planner select optimal action, since leads state greaterdistance goals, according heuristic. order decide move robot towardskey, planner go valid plans, backtrack move robotworse states (this requires planner maintains closed list visited statesrevisit them). difficult problems, number states planner visitfollowing optimal direction, extremely large. main reason GRT, like manyheuristic planners, handle grid-like domains efficiently.3x3 grid problem Figure 2, ideal planner detect that, order movekey n0_2 n2_2, necessary robot gets key, fact (at R n0_2)achieved fact (at R n2_0). However, planner know facts (at Rn0_0), (at R n2_0) (at R n0_2) related way, domain definitionprovide piece information. Therefore, necessary provide planner informationrelations hold facts problem.5.2Defining XOR-constraintsorder avoid local optimal states, provide GRT knowledge relations facts,exactly one facts hold state. call relations XOR-constraints.Definition 2 (XOR-constraint). XOR-constraint relation ground facts.relation valid state, exactly one participating facts holds state.general form XOR-constraint schema following:((xor f1 f2 ...) c1 c2 ...)fi facts cannot co-appear state ci static facts providesupplementary conditions type constraints, relations objects, etc.XOR-constraints formalized almost domain. example, logistics domaincould define following XOR-constraints:( (xor ( ?Truck * ) ) ( truck ?Truck ) )( (xor ( ?Plane * ) ) ( plane ?Plane ) )( (xor ( ?Package * ) (in ?Package * ) ) ( package ?Package ))133fiREFANIDIS & VLAHAVASQuestion marks (?) precede named variables, whereas asterisks (*) denote no-named ones.definitions mean every instantiation named variables appear XORconstraint valid instantiations no-named variables, according predicatedefinitions, exactly one ground fact hold valid complete state. XORconstraints schemas general definitions grounded several ways, accordingdifferent ways named variables instantiated.cases, possible XOR-constraints incorporate relations.example, logistics domain predicate (out ?Package) defined, meanspackage loaded either truck plane, relevant constraint written:( ( xor ( ( ( ?Package * ) ( ?Package ) ) ( ?Package * ) ) ( package ?Package ) )Note facts may appear XOR-constraint, others may appearone. Henceforth, refer facts appear least one XOR-constraint XORconstrained facts.requirement current version GRT XOR-constraints includeddomain definition. However, could computed analytically, based mutual exclusionrelations facts problem, since mutually exclusive facts cannot appearsimultaneously valid state. However, providing manually allows formguidance, since domain engineer leave them, since would lead pointlessdecompositions.notion XOR-constraints new planning. Gerevini Schubert (1998) proposedmethod automatic inference state constraints action definitions initialstate. Single valuedness constraints sv constraints closest XOR-constraints. svconstraints concern instantiations predicate, XOR-constraints relationsground facts different predicates. However, recent work (2000a, 2000b),extended work also infer XOR-constraints.object oriented domain specification formalism introduced McCluskey & Porteous(1997) similar XOR-constraints. According this, states defined collectionsfacts collections objects, object internal status. So, XOR-constraintsimplicitly defined requirement object attributes single valued.5.3Decomposing Problems Sub-problems using XOR-constraintssection illustrate GRT exploits XOR-constraints within pre-processing phase,order avoid local optimal states. Specifically, using GRT manages establish new orderedsubgoals achieved achieving original goals. subgoals groupedordered intermediate states, thus original difficult problem decomposed sequenceeasier subproblems solved sequentially.present steps problem decomposition process example Figure3, 4x4 grid problem two keys (K1 K2) two robots (R1 R2).Initial StateK2R232100R1123210K13Goal StateR2 K2K1R101Figure 3: 4x4 grid problem.13423fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGGoal facts(at R1 n0_0)distance=0-(at R1 n1_0)distance=1(at R1 n1_1)distance=2(at R1 n2_0)distance=2(at R1 n3_0)distance=3(move R1 n1_0 n0_0)(move R1 n1_1 n1_0)(move R1 n2_0 n1_0)(move R1 n3_0 n2_0)(at K1 n1_1)distance=0-(at R2 n0_3)distance=0-(holding R1 K1)distance=3(at K1 n3_0)distance=7(leave R1 K1 n1_1)(at R2 n2_2)distance=3(get R1 K1 n3_0)(move R2 n2_2 n2_3)(at R2 n1_3)distance=1(at R2 n2_3)distance=2(move R2 n1_3 n0_3)(move R1 n2_3 n1_3)(at R2 n3_3)distance=3(move R2 n3_3 n2_3)(at K2 n1_3)distance=0-(holding R2 K2)distance=2(at K2 n3_3)distance=6(leave R2 K2 n1_3)(get R2 K2 n3_3)Figure 4: Part Greedy Regression Graph 4x4 Grid problem.domain following XOR-constraints defined:( ( xor ( ?Robot * ) ) ( robot ?Robot ) )( ( xor ( ?Key * ) ( holding ?Key ) ) ( key ?Key ) )definitions four ground instantiations, one Robot one Key.Henceforth notation XOROBJ refer ground XOR-constraint concerning object OBJ.first information extracted pairs facts, one initial state onegoals, belong ground XOR-constraint. problem Figure 3following pairs identified:XORR1: (at R1 n1_0)XORR2: (at R2 n2_2)XORK1: (at K1 n3_0)XORK2: (at K2 n3_3)-(at R1 n0_0)(at R2 n0_3)(at K1 n1_1)(at K2 n1_3)original GRT planner store information inverted actions, achievedvarious facts heuristic construction phase. However, order exploit XORconstraints, information stored. storing actions, table structure usedGRT heuristic transformed directed acyclic graph. call structure GreedyRegression Graph simply GRG.nodes graph labeled facts problem. node retains alsoestimated distance fact goals corresponding related facts. retains alsoname inverted action achieved fact. arcs point node originatenodes preconditions inverted action achieved node's fact. Figure 4 showspart GRG structure 4x4 grid problem (the related facts omitted).Based GRG, every ground XOR-constraint, sequence actions abletransform initial state fact corresponding goal state fact derived. interestedactions change XOR-constraint's facts actions provide auxiliarypreconditions. problem Figure 3, actions' sequences shown Table 4:135fiREFANIDIS & VLAHAVASInitial stateIntermediate goalsGoal stateXORR1(at R1 n1_0)(at R1 n3_0)(at R1 n1_1)(at R1 n0_0)XORR2(at R2 n2_2)(at R2 n3_3)(at R2 n1_3)(at R2 n0_3)XORK1(at K1 n3_0)(holding R1 K1)(at K1 n1_1)XORK2(at K2 n3_3)(holding R2 K2)(at K2 n1_3)Figure 5: ordering graph 4x4 grid problem.XORconstraintsInitial StateFactsGoal StateFactsXORR1XORR2(at R1 n1_0)(at R2 n2_2)(at R1 n0_0)(at R2 n0_3)XORK1XORK1(at K1 n3_0)(at K2 n3_3)(at K1 n1_1)(at K2 n1_3)Sequences actions(move R1 n1_0 n0_0)(move R2 n2_2 n2_3) (move R2 n2_3 n1_3)(move R2 n1_3 n0_3)(get R1 K1 n3_0) (leave R1 K1 n1_1)(get R2 K2 n3_3) (leave R2 K2 n1_3)Table 4: Sequences actions transform initial state factscorresponding goal facts.Checking preconditions actions, find facts members foreignXOR-constraints. facts subgoals temporarily established,achieving original goals, forward search phase. Table 4, actions (get R1 K1 n3_0)(leave R1 K1 n1_1) XORK1 sequence (at R1 n3_0) (at R1 n1_1)preconditions respectively, members XORR1 relation. Similarly, actions (getR2 K2 n3_3) (leave R2 K2 n1_3) XORK2 sequence (at R2 n3_3) (at R2 n1_3)preconditions respectively, members XORR2 relation.two types subgoals. XOR-constrained facts either:(I)(II)preconditions ground action foreign XOR sequence,add-effects action, XOR sequence, foreign precondition.identified subgoals, construct graph, conjoining new subgoals arcsdenote ordering constraints, using following rules:1. subgoals ordered initial state fact goal fact (if any).2. Subgoals type (II) members XOR-constraint ordered accordingordering actions.3. Subgoals type (I) ordered together corresponding subgoals type (II),resulted action.4. specific XOR-constraint, subgoals type (I) ordered subgoals type (II).136fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGcall resulted graph ordering graph problem, since denotes ordersubgoals achieved. Figure 5 shows ordering graph problemFigure 3. Lines arcs denote ordering constraints. Double-lines without arcs denote twofacts ordered together.Proposition 8. ordering graph acyclic graph.Proof sketch: proof based way facts achieved PreProcessing Algorithm (Section 2.4). Actually, facts achieved specific time order (in casefact re-achieved smaller cost, consider last timeachieved). define ordering relation < facts, denoting fact achievedanother Pre-Processing Algorithm. Similarly define relation.Ordering relations subgoals originate two ways. Firstly, subgoals type (II)XOR-constraint ordered explicitly other, according timeachieved (in Figure 5 ordering relations denoted non-dashed lines arcs).Secondly, subgoal type (I) ordered least timeprevious one corresponding type (II) subgoal (in Figure 5 ordering relations denoteddashed lines arcs). Using equivalences, transform ordering graphequivalent time-ordering graph. Since time-ordering relation cannot include cycles,happens ordering graph.ordering graph makes possible construct intermediate, possibly incomplete, states,achieved sequentially. Starting initial state, GRT attempts insert onesubgoal XOR-constraint intermediate state. fact must followingproperties:inserted previous intermediate state,ordered fact XOR-constraint yet insertedprevious intermediate state, finallyordered together fact another XOR-constraint cannot insertedcurrent intermediate state.case one facts properties single XORconstraint, selection among done arbitrarily. Finally, case factproperties exists XOR-constraint, intermediate state left incomplete.Corollary 4. always possible construct intermediate states.Corollary 4 follows Proposition 8. Since ordering graph directed acyclic graph,always possible find least one subgoal included next intermediate state.number subgoals upper bound number intermediate statesconstructed.ordering graph Figure 5, following intermediate states extracted:Intermediate state 1: ( (at R1 n3_0) (at R2 n3_3) (in K1 R1) (in K2 R2) )Intermediate state 2: ( (at R1 n1_1) (at R2 n1_3) (at K1 n1_1) (at K2 n1_3) )Intermediate state 3: ( (at R1 n0_0) (at R2 n0_3) (at K1n1_1) (at K2 n1_3) )last state goal state.construction intermediate states, planner solve three sub-problems,easier original one; thus, overall time solve shorter time137fiREFANIDIS & VLAHAVASneeded solve original problem. Note, however, decomposition may lead losscompleteness. domains deadlock exists, solutions may pruned. domainsdeadlocks exist, decomposition may produce unsolvable sub-problems. ordermaintain completeness, algorithm backtrack possible inverted actionscould achieve facts Pre-Processing Algorithm, even large application costs.However, due combinatorial explosion problem, approach adopted GRT.usual situation case sub-problems need decomposition. situationarises two cases. first two objects need achieve goals,case grid domain, keys robot, second case sequentialinteraction three objects. cases, ordering graph initial problemencodes one aspect interaction, ordering graphs sub-problems encodeaspects. However, order avoid infinite decompositions, cutoff level defined.6. GRT OperationGRT implemented C++5. operation consists several stages, shownFigure 6a.Domain fileProblem fileParsingFactsActionscomputationMutexcomputationDomainenrichmentProblemprocessingPlan(a) GRT operation stagesProblem processingIrrelevantobjectseliminationGoalscompletionHeuristicconstructionProblemdecompositionState-spacesearchPartialsolutionmerging(b) problem processing stageFigure 6: overall operation GRT planning system.first stage domain problem files parsed initial data structuresconstructed. second stage consists computing facts actions problem.facts stored tree structure, indexed predicates objects allowsfast access, actions stored linked list. Moreover, multiple pointers connectfact actions, fact appears. computation facts actionsperformed incrementally, repeatedly applying following steps:fact reached, create new actions include fact others already reached,preconditions.action created, add add effects tree structure.process starts initial state facts continues facts actionsreached. approach time efficient succeeds generating many unreachable factsactions. example, logistics domain, facts denoting truck located city5GRT available on-line http://www.csd.auth.gr/~lpis/GRT/main.html.138fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGdifferent initial location, corresponding actions, created. Notestage, normal inverted actions computed; former used mutexcomputation stage, latter used heuristic construction stage. However, preinstantiated actions used state-space search, applicable actionsstate computed progressively instantiating action schemas, using constraint satisfactiontechniques (forward checking intelligent backtracking).stages follow computation mutual exclusion relations, enrichmentdomain, problem processing. latter stage consists several sub-stages,shown Figure 6b, important ones construction heuristicstate-space search. Note refer pre-processing phase GRT, mean stagesprecede state-space search.case XOR-constraints provided, GRT attempts decompose currentproblem sub-problems. attempt successful, problem processing stage executedrecursively sub-problem, otherwise current problem solved. Finally, casedecompositions, partial solutions merged overall solution returned.7. Related Worksection briefly presents domain independent heuristic state-space planning systems,emphasizing similarities differences GRT, terms way constructheuristic direction traverse state-space. omit certain pieces relatedwork concern specific pre-processing techniques implemented GRT, exampleelimination irrelevant objects, since already presented previous sections.recent evolvement domain independent heuristic planning started workDrew McDermott (1996, 1999) UNPOP (UN-Partial Order Planner, UN- stands non-).McDermott's planner restricted pure STRIPS representations, supportingexpressive language ADL (Pednault, 1989). planner proceeds forward state-space.Distance estimates states based so-called regression graph, builtgoals using non fully-instantiated actions. UNPOP consider subgoals interactionsreconstructs regression graph scratch intermediate state. Although plannercompetitive enough, compared subsequent heuristic planners, faster onetime appearance. However, note UNPOP developed LISP, whereasheuristic planners highly optimized C C++ programs.Although UNPOP first domain independent heuristic planner, area pushedforward ASP (Action Selection Planner, Bonet, Loerings & Geffner, 1997) HSP(Heuristic Search Planner, Bonet & Geffner, 1998) planners. attractive featureplanners simple way heuristic constructed, presented Section 2.1. ASP used bestfirst strategy limited agenda, H SP uses hill-climbing one limited plateau searchrestarts (an in-depth presentation state-space search algorithms given Zhang, 1999).ASP HSP reconstruct heuristic scratch intermediate state.variation, called HSPr (r stands regression), constructs heuristic (Bonet &Geffner, 1999). approach resembles GRT, although HSPr constructs heuristic forwardsearches backwards. approaches problem incomplete goal states, however arisesdifferent phases planning process. GRT faces problem pre-processing phase,enhancing goals, described Section 3. HSPr, problem arises searchphase, form invalid states regression state space. cope problem, HSPrcomputes mutual exclusion relations checks state regression state space139fiREFANIDIS & VLAHAVASpossible violation relations. disadvantage approach considerablytime consuming GRT approach, since HSPr check visited state.variation HSP, named HSP-2, changed hill-climbing strategy best-first one, thuspreserving completeness producing better plans (Bonet & Geffner, 2001). Moreover, HSP-2uses weighted A* algorithm (WA*) (Pearl, 1983) form f(S)=g(S)+Wh(S),intermediate state, g(S) accumulated cost initial state, h(S) estimated costreach Goals W parameter. W=0, search algorithm behaves breadth-firstone, W=1 behaves typical A* W behaves best-first. h(S)function, HSP-2 supports several heuristic functions, apart one presented Section 2.1.Recently, two new planners, FF ALTALT, appeared, use GRAPHPLAN-basedapproach estimate distances intermediate states goals. ALTALT (A LittleThis, Little That) regression planner based HSPr, faces problemsinvalid states HSPr (Nigenda, Nguyen & Kambhampati, 2000). ALTALT creates planning graphpre-processing phase uses several techniques extract heuristic estimates distancesintermediate states initial state. example, one returns levelplanning graph, facts intermediate state appear, without mutualexclusion relation them.FF (Fast Forward) forward heuristic planner (Hoffmann & Nebel, 2001). orderestimate distance intermediate state goals, FF creates planning graphstate goals, using relaxed actions. Since delete effects, mutualexclusion relations planning graph. graph, FF extracts relaxed plan, lengthdistance estimate. Note that, since mutual exclusion relations,backtracking occurs extraction relaxed plan, thus extraction accomplishedfast enough. FF heuristic resembles GRT one, aim obtaining under-estimates,adopt different approaches. relaxations FF performs stronger, sincecompletely ignores delete effects. FF estimates usually smaller GRT's onestimes underestimates, whereas GRT not-rarely produces overestimates.FF adopts variation hill-climbing strategy, called enforced hill climbing, accordingwhich, planner always seeks move state closer goals, according heuristic. FFachieves performing bounded breadth-first search current state, maximumdepth defined user; improving state direct successorcurrent state. improving state found, new actions added endcurrent plan hill-climbing search continues new state. casebounded breadth-first search find improving state, FF restarts search initialstate adopting best-first search strategy.FF exhibited distinguishable performance AIPS-00 planning competition. Onefeatures FF resulting good performance compute applicable actionsintermediate state. Actually, FF gives priority first level actions relaxed plan.action produces better state found, applied next state processed.Moreover, times, new relaxed plan constructed, since sufficesremove lastly applied action beginning previous relaxed plan. So, FF succeedsreducing drastically cost processing intermediate state, paying however costloosing completeness.bottleneck occurs determining applicable actions intermediate statealso identified Vrakas et al. (1999, 2000). work, process findingapplying applicable actions parallelized, resulting almost linear speedup.Parallelizing process finding applicable actions, instead ignoring them, FF140fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGdoes, presents advantage preserving completeness; however, cost parallelmachine required.close reference heuristic state-space planners STAN planning system(Fox & Long, 1998; Long & Fox, 1999). STAN heuristic state-space planner, leastbasic architecture, graph-based planner, uses several pre-processing techniquesextracting useful domain information exploited efficient graph constructionsolution extraction. However, AIPS-00 competition hybrid architecture used (Long &Fox, 2000; Fox & Long, 2001), heuristic state-space planning module employedsolve specific identified sub-problems. Thus STAN succeeded improving performance,especially cases transportation domains.Concerning problem decomposition, work done goal ordering (Cheng & Irani,1989; Drummond & Currie, 1989). Recently similar approach proposed Koehler(1998) extended Koehler Hoffmann (2000). approach automaticallyderives ordering relation goal facts, used planner searchincreasing sets subgoals. advantage approach extra information needed,except usual domain definition, disadvantage, respect XOR-constraintsapproach, goal facts taken account intermediate statesconstructed. approach adopted FF planning system.8. Performance Resultssection, present performance results several domains, taken literaturetwo planning competitions. First, investigate several techniques GRTcontribute overall performance compare GRT planners.measurements follow taken SUN Enterprise 3000 machine running167MHz, 256 MB main memory operating system Solaris 2.5.1. experimentsset 5 minutes time limit experiments planners6.8.1Measuring Effectiveness Related Factsorder measure contribution related facts overall performance GRT,tested planner, without related facts, problems various domains. results(solution length time) presented Figure 7 (a-f)./HQJWK7LPH:LWKRXW 5HODWHG:LWK 5HODWHG:LWKRXW 5HODWHG:LWK 5HODWHG(a) Logistics problems (the goals enhanced promising facts selection method)6URL http://www.csd.auth.gr/~lpis/GRT/JAIR/OnlineAppendix1.htmlfound executable files planners took part comparison, source code GRT, detailedresults (in MS-Excel format), original data files, problem description files script files planner.141fiREFANIDIS & VLAHAVAS/HQJWK:LWKRXW 5HODWHG:LWK 5HODWHG7LPH:LWKRXW 5HODWHG:LWK 5HODWHG(b) Blocks-world problems 4 action schemas (push, pop, pick-up, put-down):LWKRXW 5HODWHG:LWK 5HODWHG/HQJWK7LPH:LWKRXW 5HODWHG:LWK 5HODWHG(c) Blocks-world problems 3 action schemas (several cases move)/HQJWK:LWKRXW 5HODWHG:LWK 5HODWHG7LPH:LWKRXW 5HODWHG:LWK 5HODWHG(d) FreeCell Problems/HQJWK:LWKRXW 5HODWHG:LWK 5HODWHG7LPH:LWKRXW 5HODWHG:LWK 5HODWHG(e) Elevator problems/HQJWK:LWKRXW 5HODWHG:LWK 5HODWHG7LPH:LWKRXW 5HODWHG:LWK 5HODWHG(f) Puzzle problemsFigure 7: Solution length time (in msecs) without use related factsproblems several domains.142fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGclassify domains three groups. first group includes domainsuse related facts clearly improves solution length time. group compriseslogistics domain (6a), blocks-world, 3-action schemas representation (move actions)used (6c), puzzle domain (6f). domains, many cases GRTwithout related facts solve problems, related facts did. Moreover,cases versions solved problem, version related facts fastercame shorter plan.second group includes domains use related facts affecteffectiveness planning process. group comprises elevator domain, alonggripper, movie mystery ones. domains, usually single way achievegoals, versions produce identical plans. However, due processing overhead,imposed computation related facts, version related facts slightly slowerversion without them.Finally, third group includes domains apparent predominancetwo versions. freecell domain blocks-world domain, 4-action schemasrepresentation used (push, pop, pick-up, put-down), fall class. domains twoversions equal performance, problems one version surpassesvice-versa.conclusion drawn measurements effectiveness related factsdepends domain. suitable domains several ways achievegoals, logistics blocks-world.Additionally, efficiency depends way domain codified. typical exampleblocks-world domain 4- 3-action schemas representations. problem 4action schemas representation pushing stacking block anywhere alwaysfact precondition, i.e. block held arm. consequence neitherrelated facts, distances computed correctly. However problem relatedfacts, common problem domain independent heuristic planning, results lastplanning competition. hand, 3-action schemas representation used,paths achieve facts domain better tracked, larger problems solvedcontribution related facts significant. believe, finally, also freecell domainrepresentation inefficiency, however yet tried construct alternative one.8.2Using Several Methods Enhance Goalsorder measure effectiveness three proposed methods enhance goals, ranGRT using logistics problems AIPS-00 competition. selected domain,since domains competition goal state either complete, near complete,difference among three methods. Figure 8 shows solution length timeeasiest logistics problems.regard solution length, first method, considers candidate facts goalfacts, always came better plans. mentioned Section 3.2, method producessmall differences among estimated distances, search process tends breadth-first.However, cases, third method found plans equal quality. regardsolution time, last two methods work faster, since produce greater differencesdistances.Section 3.3 also presented method enriching domain representation. alreadymentioned, motivated need treat domains like movie elevator.present comparative performance results domain enrichment method pureGRT planner domains, since without technique impossible GRT solve143fiREFANIDIS & VLAHAVASproblems. However, would interesting test efficiency method heuristicstate space planners./HQJWK7LPH$OO,QLWLDO*UHHG\$OO,QLWLDO*UHHG\Figure 8: Results logistics problems using different methods complete goals.= Consider candidate facts goal facts.Initial = Select initial state facts.Greedy = Favor promising facts.8.3Reducing Size Problemwork detecting eliminating irrelevant objects motivated needsimplify sub-problems resulting decomposition problem, using XORconstraints. Performance results case presented Section 8.4. section presentsindicative results concerning effectiveness technique colored logistics domainmentioned Section 4.1. purpose enhanced first group logisticsproblems AIPS-00 competition required predicates actions addedpropositions defining original color package initial states. Figure 9 presentstime needed solve problems, without irrelevant objects elimination technique.results experimental data, improvement solution time 20%.Note cases plans found; however, would probablycase domains.order measure efficiency numerical representation resources, ran GRToriginal mystery domain modified domain, resources representednumbers. Figure 10 presents time needed solve problems cases GRT.Note experiments solvable mystery problems taken account.results Figure 10, GRT significantly faster, numerical representation used.improvement 65% average. solution length, casesfound again.techniques evaluated section gain speedup mainly pre-processingphase, since distances significantly smaller number facts estimated.search phase, also speedup, less important. Actually, number applicableactions state two alternative representations resources, sinceequivalent. Moreover, detection applicable actions atom-based representationtakes time, due effective constraint-satisfaction techniques GRT usesinstantiating action schemata. Concerning elimination irrelevant objects, withouttechnique, applicable actions state, however usually selected,144fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGsince lead improving state. However, time spent detectionactions may negligible.significance two techniques lies overall time needed solve problemsremains same, case irrelevant objects used, exactly same,case resource levels used. case irrelevant objects,detected (in negligible cost) eliminated subsequent stages (Figure 6). However,overhead imposed stages precede irrelevant objects elimination stage,objects eliminated.case resource levels, lead generation new ground factsactions, pre-processing stages consume exactly time. state-spacesearch, also executed time, case neither initialavailability resources, consumption actions, finally constraintschanged. case, dealing different planning problem,may harder solve.7LPH(OLPLQDWLQJ LUUHOHYDQW REMHFWV8VLQJ DOO REMHFWVFigure 9: Time (in msecs) needed solve colored logistics problems,without irrelevant object elimination technique.$WRP EDVHG UHSUHVHQWDWLRQ1XPHULFDO UHSUHVHQWDWLRQ7LPHFigure 10: Time (in msecs) needed solve solvable mystery problems,original atom-based number-based representation resources used.8.4XOR Constraintstested efficiency XOR-constraints based decomposition two domains: simplifiedmystery domain, resources removed, grid domain AIPS-98competition. use logistics domain experiments, since logistics problems145fiREFANIDIS & VLAHAVASdifficult original GRT small profit solving easier sub-problemscompensated extra pre-processing cost sub-problem.removed resources original mystery domain otherwise wouldprobable obtain unsolvable subproblems. noted Section 5, decomposingproblem may lead loss completeness, thus technique unsuitable domainsdeadlocks may arise, original mystery one. Note removing resources, mysteryproblems become solvable.XOR-constraints defined simplified mystery domainfollowing:( ( xor ( ?Truck * ) ) (truck ?Truck ))( ( xor ( ?Package * ) (in ?Package * ) ) ( package ?Package ) )grid domain following ones:( ( xor ( at-robot * ) ) )( ( xor ( locked ?Place ) ( open ?Place ) ) ( place ?Place ) )( ( xor ( ?Key * ) ( holding ?Key ) ) ( key ?Key ) )Note grid domain XOR-constraint denoting arm either empty,robot holds key defined, since would lead pointless decompositions.domains, ran GRT without problem decomposition technique.Additionally, order demonstrate contribution irrelevant objects eliminationtechnique solving sub-problems, conducted experiments case simplifiedmystery domain. consider case grid domain, irrelevant objectsdetected there. Figure 11 presents results.1R ;25V/HQJWK;25V7LPH;25V1R HOLP LQDWLRQ1R ;25V;25V;25V1R HOLP LQDWLRQ(a) Simplified Mystery/HQJWK7LP HZLWKRXW ;256ZLWKRXW ;256ZLWK ;256ZLWK ;256(b) Grid DomainFigure 11: Solution time (in msecs) length withoutXOR-constraints based problem decomposition technique.146fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGsimplified mystery domain, GRT without problem decomposition techniquegenerally produced shorter plans, expected. hand, use XOR-constraintsaccelerated problem decomposition process, especially case difficult problems. Actually,consider seven difficult problems, improvement achieveddecomposition 60% average. Note however that, irrelevant objects eliminationtechnique used, improvement. difficult problemsacceleration, since, case logistics problems, small profit faster solutioneasier sub-problems compensated cost repeating pre-processing phaseone them.grid domain difficult one AIPS-98 competition. contestantsmanaged solve first problem. GRT without XOR-constraints could solve firstproblem, too. hand, XOR-constraints based decomposition, GRT ablesolve first four problems time limit 5 minutes, fifth problem ranmemory. worth noting domain produces multiple levels decompositions. Figure 12presents levels strips-grid-y-2 problem.far know, planner cope grid problems effectively FF.ran FF five grid problems solved first four, within time limit 5 minutes,following results (length/time): 14/230, 39/840, 40/7810 45/3280, considerablybetter compared performance GRT.Main problemSub-problem 1Sub-problem 2Sub-problem 3.1Sub-problem 3.1.1Sub-problem 3.1.1.1Sub-problem 3.1.2Sub-problem 3.1.1.2Sub-problem 3Sub-problem 3.2Sub-problem 3.3Sub-problem 4.1Sub-problem 3.1.3Sub-problem 4Sub-problem 4.2Sub-problem 4.3Sub-problem 3.1.1.3Figure 12: Decomposition strips-grid-y-2 problem using XOR-constraints.8.5Best-First Hill-Climbing StrategiesRecently equipped GRT planner two new features: second optional search strategy,well known hill-climbing, closed-list visited states, order avoid revisiting them.GRT adopts enforced hill-climbing strategy, originally presented Hoffmann & Nebel(2001), according which, intermediate state limited breadth first searchperformed, improving state reached. improving state cannot found, GRTrestarts search initial state typical best-first strategy.Moreover, hill-climbing strategy enhanced fast action selection mechanism.presented Section 5.3, GRT estimates distances problem'sfacts goals pre-processing phase, stores GRG structure actionachieved fact. So, order find improving successor state quickly, hill-climbingsearch strategy first attempts apply actions achieved current state's facts.147fiREFANIDIS & VLAHAVASimproving successor state found, remaining actions processed, thus avoidingcompute applicable current state actions. Note however guaranteedactions always applied current state. case improving statefound, remaining applicable current state actions taken account.Figure 13 presents comparative performance results logistics elevator problems, usingsearch strategies. logistics problems, promising facts selection methodenhancing goals used. results experimental data, logisticsproblems use hill-climbing strategy, significant reductionsolution time 52%. cost increment 3% length plans.elevator problems, also reduction solution time 29%, whereasproduced plans identical./HQJWK7LP H+LOO &OLP ELQJ+LOO &OLP ELQJ%HV W )LUV W%HV W )LUV W(a) Logistics domain/HQJWK7LP H+LOO&OLP ELQJ+LOO&OLP ELQJ%HV W )LUV W%HV W )LUV W(b) Elevator domainFigure 13: Comparative results (solution length time) hill-climbingbest-first strategies.tested efficiency fast action selection mechanism, also running GRThill-climbing strategy without mechanism logistics elevator problems.Concerning logistics problems, speedup 47%, increment solutionlength 3% average again. Concerning elevator problems, speedup 28%, whereasproduced plans identical. conclusion additional measurementsspeedup primarily due hill-climbing strategy secondly due fast actionselection mechanism. contribution mechanism depends domainimportant logistics less elevator. inefficiency elevator domain meansactions selected mechanism usually lead improving stateapplicable, applicable actions computed.Results domains, like blocks-world freecell, presented, sincedomains hill-climbing usually fails find plan GRT restarts best-first basis. However,148fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGdomains closed-list states proved invaluable, improving drasticallyperformance GRT. example, freecell domain without closed list visitedstates, GRT planner AIPS-00 planning competition succeeded solving problems6 cards per suit, data structure solve difficult ones (13cards per suit). Note efficient implementation closed-list visited states hashtable data structure adopted.8.6Comparison Plannerssection, present comparative results GRT planner planners.decided use HSP-2 (Bonet & Geffner, 2001), FF (Hoffman & Nebel, 2001), STAN (Long & Fox,2000; Fox & Long, 2000, 2001) ALTALT (Nigenda, Nguyen & Kambhampati, 2000)7.planners took part domain independent track AIPS-00 planning competition.selected planners HSP-2 STAN state-ofthe-art planning systems, FFawarded outstanding performance last competition ALTALT newpromising domain-independent state-space heuristic planner.aim experiments overall view performance evaluatedsystems. Performing pair wise comparisons specific optimization techniquespossible, since techniques implemented top different systems. Moreover, kindcomparisons scope paper, focuses use specific directionsconstructing heuristic traversing space states, area domain-independentheuristic state-space planning, evaluation numerous pre-processingoptimization techniques. However, cases identify contribution specificfeature performance planner, comment this.order fair comparisons, used exactly problem domain descriptionfiles planners. So, GRT ran without XOR-constraints numerical representationresources. Moreover, although irrelevant object elimination technique integral featureGRT, contribution domains, since irrelevant objects. believeabsence irrelevant objects domains mean technique limitedapplicability, indication real domains testing purposes usedfuture, since planning tasks real-life full irrelevant objects. Finally, domainenrichment technique proved valuable elevator domain only. However, technique,well goal enhancement one, seen optimization technique, wayovercome problems arise backward direction heuristic construction.tested planners several domains taken planning competitionsliterature, workstation within 5 minutes time limit. results presentedfollowing.8.6.1LOGISTICSlogistics domain used test suite AIPS-00 competition. results shownFigure 14. domain GRT, well FF STAN, performed well, solving problems.HSP ALTALT failed solve large problems within time-limit. general, best plansfound STAN, uses special domain-dependent heuristics problems identified7STAN available http://www.dur.ac.uk/~dcs0www/research/stanstuff/stanpage.htmlFF available http://www.informatik.uni-freiburg.de/~hoffmann/ff.htmlHSP-2 available http://www.ldc.usb.ve/~hector/ALTALT available http://rakaposhi.eas.asu.edu/altweb/altalt.html149fiREFANIDIS & VLAHAVAStransportation problems. Best solution times achieved FF STAN small problemsGRT large ones./HQJWK7LPH))))*5 7*57+ 63+ 63$OW$OW$OW$OW67$167$1Figure 14: Solution length time (msecs) logistics problems AIPS-00 competition.logistics problems Figure 14 incomplete goal states. GRT ranpromising facts goals-completion method hill-climbing strategy. However,incompleteness goal state advantage planners construct heuristicforward direction. Motivated remark, forced planners solve logistics problemscomplete goal states, requiring trucks planes return initial location.results shown Figure 15./HQJWK7LPH+ 63*57$OW$OW67$1))+ 63*5 7$OW$OW67$1))Figure 15: Solution length time (msecs) logistics problems complete goal states.new logistics problems, GRT, STAN HSP-2 exhibited stable performance, solvingproblems time. GRT, means goal completion mechanism behaveswell, least domain. FF failed solve large problems. Finally, ALTALT solved150fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGproblems regression mechanism encounter invalid states. Notethat, although goal state complete case, GRT treated problems usual,attempting enhance goals.8.6.2BLOCKS-WORLDblocks-world problems AIPS-00 competition four-actions representation used, i.e.actions push, pop, stack unstack. representation unsuitable GRT,explained Section 7.1. So, GRT solve blocks-world problems. Figure 16presents results planners blocks-world problems.shown Figure 16, FF exhibits best performance, solving majority problemsproducing better plans planners. superiority FF domain duetechnique called Added Goal Deletion, according goal facts ordered achievedprogressive manner (Hoffmann & Nebel, 2001; Koehler Hoffmann, 2000). techniqueespecially suited blocks-world domain 4-action schemas representation. However,technique always succeeds produce good orderings reason FFfails solve easiest problems, solved planners.remaining planners, HSP-2 succeeded solving problems 18 blocksone problem 24 blocks, GRT ALTALT solved problems 14 blocks STAN12 blocks. Moreover, GRT produced plans low quality./HQJWK7LPH))*5 7+ 6367$1$OW$OW))*5 7+ 6367$1$OW$OWFigure 16: Solution length time (msecs) blocks-world problemsusing 4-action schemas domain representation.order demonstrate influence domain representation efficiency GRT,ran planners problems using alternative 3-action schemas domainrepresentation. results shown Figure 17.performance GRT significantly improved, solving problems 33 blocksproducing better plans planners. Moreover, exception smallestproblems, GRT faster planners, FF. latter solved less large problems,151fiREFANIDIS & VLAHAVASsolved smallest ones. HSP-2 solved problems 19 blocks, ALTALTSTAN stopped 14 blocks.7LPH/HQJWK))))*57*57+ 63+ 63$OW$OW67$1$OW$OW67$1Figure 17: Solution length time (msecs) blocks-world problemsusing 3-action schemas domain representation.8.6.3FREECELLFreecell famous card game taken MS-Windows 98 distribution. domaininitially introduced AIPS-00 competition proved one difficult domains.Figure 18 presents performance results domain. Note ALTALT could solveproblems also case competition.freecell domain, planners succeeded solve difficult problemsGRT FF. Actually, planners solved problems 12 13 cards per suit.HSP-2 solved problems 6 cards per suit STAN 3 cards per suit. Regardingsolution quality, GRT produced better plans FF. Regarding solution time, FF fastersmall problems, whereas big ones two planners equal performance.8.6.4ELEVATORelevator (or miconic-10) domain presented Section 3.3. least pure STRIPSversion, relatively easy domain. So, planners found plans equal quality (withexception HSP-2, produced slightly lengthy plans). However, plannersdifferent performance terms solution time.Specifically, FF fastest, followed STAN, GRT, HSP-2 finally ALTALT.domain favors FF, relaxed plan produced heuristic mechanism initialstate actually solution, since original actions domain contain delete lists.STAN identifies domain transportation domain uses suitable techniques solveproblem. Finally, GRT faster HSP-2 ALTALT, since GRT constructs heuristic fasterHSP-2. results presented Figure 19.152fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING/HQJWK7LPH))*57+6367$1))*57+6367$1Figure 18: Solution length time (msecs) freecell domain.7LPH$OW$OW+63*5767$1))Figure 19: Solution time (in msecs) elevator domain.8.6.5GRIPPERgripper domain introduced AIPS-98 planning competition. domain concernsrobot two grippers must transport set balls one room another. AIPS-98competition, HSP managed solve 20 problems. Figure 20 presents resultsdomain.153fiREFANIDIS & VLAHAVAS/HQJWK7LPH*57*57))))+ 63+ 63$OW$OW$OW$OW67$167$1Figure 20: Solution length time (msecs) gripper domain.Regarding solution length, five planners divided two groups: GRT,ALTALT STAN produced identical plans higher quality, FF HSP-2 producedidentical plans lower quality. Regarding solution time, GRT fastest planner problemsapart easiest, followed closely STAN, next comes FF, next ALTALT lastHSP-2. Note domain STAN takes advantage symmetry analysis, identifiesset balls two grippers symmetric objects (Fox Long, 1999).8.6.6HANOIran planners 6 hanoi problems, taken Bonet Geffner (2001). six problemsthree eight disks respectively. Figure 21 presents results./HQJWK*57$OW$OW$OW$OW))))+ 637LPH*57+ 6367$167$1Figure 21: Solution length time (msecs) hanoi domain.Regarding solution length, planners found identical plans, exceptionlast two problems, GRT found worse plans. Regarding solution time, FF faster,came GRT HSP-2, ALTALT last came STAN.154fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNING8.6.7PUZZLEran planners four 8-puzzle problems two 15-puzzle ones, taken BonetGeffner (2001). Two four 8-puzzle hard optimal solution involves 31 actions,maximum plan length domain. 15-puzzle problems medium difficulty. Figure22 presents results.+ 63+ 63$OW$OW))/HQJWK*5767$1*577LPH$OW$OW67$1))Figure 22: Solution length time (msecs) puzzle domain.STAN solved 8-puzzle instances, produced best plans. plannerssolved problems, presented variations quality plans, FFplanning system producing worst plans cases. Regarding solution time, FFfastest easier problems GRT difficult ones, followed HSP-2 ALTALT.STAN slowest planner domain.9. Conclusion Future Workpaper presented GRT planning system, heuristic state-space planner,constructs heuristic domain-independent way. fundamental difference GRTheuristic state-space planners GRT constructs heuristic once, pre-processingphase backward direction, using regression goals. GRT attempts trackpositive negative interactions occur problem facts trying achievethem, order produce better estimates.GRT employs several new techniques improve efficiency. automatedidentification incomplete goal states, identification enrichment inadequate domainrepresentations, elimination irrelevant objects adoption numerical representationresources. Finally, knowledge-based method uses domain axioms form XORconstraints, order decompose difficult problems easier sub-problemssolved sequentially, adopted.paper presented extensive comparative results large number domains.comparisons, besides GRT, four powerful domain independent planners took part.results showed planner clearly outperforms others.Concerning solution time, domains GRT FF fastest planners.explanation behind observation lies planners construct heuristic either(in case GRT), times (in case FF). example, elevator domain,delete effects exist FF constructs relaxed planning graph once,extremely fast. contrary, gripper puzzle domains, FF needs155fiREFANIDIS & VLAHAVASreconstruct relaxed planning graphs, efficiency decreases drastically respectGRT's one.HSP-2 faster planners domain, always outperformed FF.expected, since two planners use forward direction constructionheuristics traversing state-space, however FF constructs heuristic less timesHSP-2. impression FF heuristic also informative accurateone HSP-2. Concerning ALTALT, although constructs heuristic once, managefaster others domain (we believe) due problems arisebackward direction traverses state-space. So, indication caseopposite directions used heuristic construction search phase, GRT,ALTALT HSPr do, preferable use backward direction heuristic constructionforward direction search phase. problems ariseconstructing heuristic backwards may confronted easily problems arisetraversing state-space backwards.Domain analysis techniques, occur pre-processing phase, also play important role.STAN, primarily based techniques, many variations performance.transportation domains, like logistics elevator ones, STAN exploits specializedheuristics, among fastest planners. gripper domain, STAN exploitssymmetry analysis, performance also excellent. domains, examplefreecell blocks, competitive due GRAPHPLAN basic architecture,considered fast technology more.FF also employed domain analysis technique concerning goal ordering, playedimportant role blocks problems. would interesting see adaptationimpact technique planners well. far know, HSP-2 ALTALTusing domain analysis technique. GRT exploited domain enrichment techniqueelevator domain, however technique integral part heuristic mechanism, orderovercome problems arise backward heuristic construction.interesting observation concerns performance GRT bigger problemslogistics, freecell, gripper puzzle domains, GRT exhibited better performancesmaller problems domains, compared planners. believe duefact GRT constructs heuristic once, repeated construction heuristicsplanners inhibitory factor bigger problems.conclusions drawn ignore significant factor, specific implementation,i.e. approaches adopted various planners "trivial" tasks, computationground facts actions problem computation applicable actions givenstate, optimization code course potential "bugs". example, order findapplicable actions state, GRT uses constraint satisfaction techniques progressively instantiateaction schemas state, whereas planners exploit connectivity graphsfacts problem pre-instantiated actions. experiments GRTshown significant portion processing time spent determinationapplicable actions state. reason developed parallel version GRT,named PGRT (Vrakas et. al., 1999; 2000), makes use observationproved efficient domains. However, future plans develop connectivitygraph also GRT compare existent approach.Differences due code optimization potential "bugs" cannot easily detected,believe planners, oldest newest ones well-optimizedprograms. future would like see theoretical comparisons computational156fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGcomplexities various techniques algorithms, apart experimental evaluationusually adopted.Concerning plan length, GRT produced better plans planners freecelldomain, gripper domain (along planners), many blocks problems 3action schemas representation used logistics problems. STAN exhibited bestbehavior domains believe due GRAPHPLAN basic architecture,always produces optimal parallel plans and, many cases, sequential plans also. FF behavedwell logistics blocks problems, 4-action schemas representation (in lattercase probably due goal ordering technique), however produced lengthy plansdomains, freecell, gripper puzzle ones.HSP-2 produced longer plans GRT many domains, example logistics,freecell gripper domains blocks one, 3-actions representation used.observation means domains related facts employed GRT heuristicproved valuable forward repeated reconstruction HSP-2 heuristic. Finally,ALTALT distinguished quality plans domain.general impression experiments specific domains favorspecific planners. So, important investigate reasons that. currentlyworking exploring internal characteristics domain, classifyinggeneral categories share common features, associate features specific heuristicsearch techniques. first attempt domain classification also found (Hoffmann,2001).alternative view problem concerns way domain encoded.planner domain may alter performance different representation adopted.faced problem blocks-world, 4- 3-actions schemas domainrepresentations, performance GRT varies significantly, performanceplanners also altered. also faced problem elevator movie domains,motivation development domain enrichment technique. convictiondomain-independent planning strongly domain-representation dependent.Concerning GRT, plan extend handle expressive domains, supportingfeatures PDDL language (types, quantifications, negations, disjunctions, etc).time working extension GRT, ability take account multiplecriteria (i.e. solution time, resources, safety, profit etc.). also interested incorporatingdomain analysis techniques, developed STAN DISCOPLAN, order takeadvantage specialized methods handling specific types problems sub-problems. Finally,investigate possibility utility combining domain independent planningtechniques domain dependent ones, without loosing generality planning system.Acknowledgmentsauthors would like thank Thomas Eiter, editor charge paper,anonymous reviewers helpful comments. would like also thank Dimitris Vrakascareful reading suggestions final version paper. Finally, would like thankresearchers planning community making planners available,specifically Blai Bonet, Hector Geffner, Joerg Hoffman, Bernhard Nebel, Derek Long, Maria Fox,Romeo Sanchez Nigenda, XuanLong Nguyen Subbarao Kambhampati.157fiREFANIDIS & VLAHAVASReferencesBarrett, A. & Weld, D. S. (1994). Partial order planning: Evaluating possible efficiency gains.Artificial Intelligence, 67, 71-112Biundo, S. & Fox, M. (2000). Recent advances AI planning. 5th European ConferencePlanning (ECP-99). Durham, UK, Springer-Verlag.Blum, A. & Furst, M. (1997). Fast planning planning graph analysis. ProceedingsIJCAI-95.Blum, A. & Furst, M. (1995). Fast planning planning graph analysis. ArtificialIntelligence, 90, 281-300.Bonet, B. & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1-2), pp.5-33.Bonet, B. & Geffner, H. (1999). Heuristic planning: New results. (Biundo & Fox, 1999).Bonet, B. & Geffner, H. (1998). HSP: Heuristic search planner. Entry 4th InternationalConference Artificial Intelligence Planning Systems (AIPS) Planning Competition.Pittsburgh, 1998.Bonet, B., Loerincs, G. & Geffner, H. (1997). robust fast action selection mechanismplanning. Proceedings AAAI-97.Cheng, J. & Irani, K. B. (1989). Ordering problem subgoals. Proceedings IJCAI-89.Drummond, M. & Currie, K. (1989). Goal ordering partially ordered plans. ProceedingsIJCAI-89.Fikes, R. E. & Nilsson, N. J. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189-208.Fox, M. & Long, D. (2001). Hybrid STAN: Identifying managing combinatorial optimizationsub-problems planning. Proceedings IJCAI-2001.Fox, M. & Long, D. (2000). Using automatically inferred invariants graph constructionsearch. Proceedings AIPS-2000.Fox, M. & Long, D. (1999). detection exploitation symmetry planning problems.Proceedings IJCAI-99.Fox, M. & Long, D. (1998). automatic inference state invariants TIM. JournalArtificial Intelligence Research, 9, 367-421.Gerevini, A. & Schubert, L. (2000b). Discovering state constraints DISCOPLAN: newresults. Proceedings AAAI-00.158fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGGerevini, A. & Schubert, L. (2000a). Extending types state constraints discoveredDISCOPLAN. Proceedings AIPS-00 Workshop Analysing ExploitingDomain Knowledge Efficient Planning.Gerevini, A. & Schubert, L. (1998). Inferring state constraints domain-independent planning.Proceedings AAAI-98.Godefroid, P. & Kabanza, F. (1991). efficient reactive planner synthesizing reactive plans.Proceedings AAAI-91.Gupta, N. & Nau, D.S. (1992). complexity blocks world planning. Artificial Intelligence56 (2-3), 223-254.Haslum, P. & Jonsson, P. (2000). Planning reduced operator sets. Proceedings AIPS2000.Hoffmann, J. & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence 14, 253-302.Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis.Proceedings IJCAI-2001.Kautz, H. & Selman, B. (1998). BLACKBOX: new approach application theoremproving problem solving. AIPS-98 Workshop Planning Combinatorial Search.Kautz, H. & Selman, B. (1996). Pushing envelope: Planning, propositional logic stochasticsearch. Proceedings AAAI-96.Kautz, H. & Selman, B. (1992). Planning satisfiability. Proceedings ECAI-92.Koehler, J. (1998). Solving complex planning tasks extraction subproblems.Proceedings 4th Intl. Conf. Artificial Intelligence Planning Systems (AIPS-98).Koehler, J. & Hoffmann, J. (2000). reasonable forced goals orderings useagenda-driven planning algorithm. Journal Artificial Intelligence Research, 12, 339-386.Korf, R. & Taylor, L. (1996). Finding optimal solutions twenty-four puzzle. ProceedingsAAAI-96.Long, D. & Fox, M. (2000). Automatic synthesis use generic types planning.Proceedings 5th Intl. Conf. AI Planning Scheduling Systems (AIPS-00).Long, D. & Fox, M. (1999). Efficient implementation plan graph STAN. JournalArtificial Intelligence Research, 10, 87-115.McAllester, D. & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings AAAI91.McCluskey, T.L. & Porteous, J.M. (1997). Engineering compiling planning domain modelspromote validity efficiency. Artificial Intelligence, 95, 1-65.159fiREFANIDIS & VLAHAVASMcDermott, D. (1999). Using regression-match graphs control search planning. ArtificialIntelligence, 109 (1-2), 111-159.McDermott, D. (1996). heuristic estimator means-ends analysis planning. Proceedings3rd International Conference Artificial Intelligence Planning Systems (AIPS-96).Minton, S., Bresina, J. & Drummond, M. (1994). Total-order partial-order planning:comparative analysis. Journal Artificial Intelligence Research, 2, 227-261.Nebel, B., Dimopoulos, Y. & Koehler, J. (1997). Ignoring irrelevant facts operators plangeneration. Proceedings 4th European Conference Planning (ECP-97).Newell, A. & Simon, H. (1972). Human problem solving. Englewood Cliffs, NJ. Prentice-Hall.Nigenda R.S., Nguyen, X. & Kambhampati, S. (2000). AltAlt: Combining advantagesgraphplan heuristic state search. Technical Report, Arizona State University.Pearl, J. (1983). Heuristics. Morgan Kaufmann.Pednault, E. (1989). ADL: Exploring middle ground STRIPS situationcalculus. Proceedings KR-89.Penberthy, J. & Weld, D. (1992). UCPOP: sound complete, partial order planner ADL.Proceedings KR-92.Refanidis, I. & Vlahavas, I. (2000b). Heuristic planning resources. Proceedings ECAI2000.Refanidis, I. & Vlahavas, I. (2000a). Exploiting state constraints heuristic state-space planning.Proceedings 5th Intl. Conf. Artificial Intelligence Planning SchedulingSystems (AIPS-00).Refanidis, I. & Vlahavas, I. (1999c). determining completing incomplete states STRIPSDomains. Proceedings IEEE Intl. Conf. Information, Intelligence Systems.Refanidis, I. & Vlahavas, I. (1999b). GRT: domain independent heuristic STRIPS worldsbased greedy regression tables. (Biundo & Fox, 1999).Refanidis, I. & Vlahavas, I. (1999a). SSPOP: state-space partial-order planner. Proceedings3rd World Multiconference Systemics, Cybernetics Informatics.Scholz, U. (1999). Action constraints planning. (Biundo & Fox, 1999).Slaney, J. & Thiebaux, S. (1996). Linear-time near-optimal planning blocks world.Proceedings AAAI-96.Smith, D. & Weld, D. (1999). Temporal graphplan mutual exclusion reasoning.Proceedings IJCAI-99.160fiBACKWARD HEURISTIC CONSTRUCTION FORWARD STATE-SPACE PLANNINGVeloso, M. (1992). Learning analogical reasoning general problem solving. Ph.D. thesis,Department Computer Science, Carnegie Mellon University.Vrakas, D., Refanidis, I. & Vlahavas, I. (2000). operator distribution method parallelplanning. AAAI-2000 Workshop Parallel Distributed Search Reasoning.Vrakas, D., Refanidis, I., Milcent, F. & Vlahavas, I. (1999). parallelizing greedy regressiontables. Proceedings 18th Workshop UK Planning Scheduling SIG.Zhang, W. (1999). State-space search: Algorithms, complexity, extensions applications.Springer.161fi