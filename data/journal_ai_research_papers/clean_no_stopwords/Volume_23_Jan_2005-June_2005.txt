Journal Artificial Intelligence Research 23 (2005) 625-666Submitted 07/04; published 06/05Expressive Language Efficient Execution SystemSoftware Agentsgbarish@fetch.comGreg BarishFetch Technologies2041 Rosecrans Avenue, Suite 245El Segundo, CA 90245 USAknoblock@isi.eduCraig A. KnoblockUniversity Southern CaliforniaInformation Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292 USAAbstractSoftware agents used automate many tedious, time-consuminginformation processing tasks humans currently complete manually.However, so, agent plans must capable representing myriad actionscontrol flows required perform tasks. addition, since tasks requireintegrating multiple sources remote information typically, slow, I/O-bound processdesirable make execution efficient possible. addressneeds, present flexible software agent plan language highly parallel executionsystem enable efficient execution expressive agent plans. plan languageallows complex tasks easily expressed providing variety operatorsflexibly processing data well supporting subplans (for modularity) recursion(for indeterminate looping). executor based streaming dataflow modelexecution maximize amount operator data parallelism possible runtime.implemented language executor system called THESEUS.results testing THESEUS show streaming dataflow execution yieldsignificant speedups traditional serial (von Neumann) well non-streamingdataflow-style execution existing software robot agent execution systemscurrently support. addition, show plans written language presentrepresent certain types subtasks cannot accomplished using languagessupported network query engines. Finally, demonstrate increasedexpressivity plan language hamper performance; specifically, showdata integrated multiple remote sources efficiently usingarchitecture possible state-of-the-art streaming-dataflow network queryengine.1. Introductiongoal software agents automate tasks require interacting oneaccessible software systems. Past research yielded several types agents agentframeworks capable automating wide range tasks, including: processing sequencesoperating system commands (Golden, Etzioni, & Weld, 1994), mediation heterogeneous datasources (Wiederhold 1996; Bayardo, Bohrer, Brice, Cichocki, Fowler, Helal, Kashyap, Ksiezyk,Martin, Nodine, Rashid, Rusinkiewicz, Shea, Unnikrishnan, Unruh, & Woelk 1997; Knoblock,Minton, Ambite, Ashish, Muslea, & Tejada 2001), online comparison shopping (Doorenbos,2005 AI Access Foundation. Rights Reserved.fiBARISH & KNOBLOCKEtzioni, & Weld, 1996), continual financial portfolio analysis (Decker, Sycara, & Zeng, 1996),airline ticket monitoring (Etzioni, Tuchinda, Knoblock, & Yates, 2004), name few.Despite software agent heterogeneity, two recurring characteristics (i) wide varietytasks agents used automate (ii) frequent need process route informationagent execution.Perhaps domain poses many tantalizing possibilities software agent automationWeb. ubiquity practicality Web suggests many potential benefitsgained automating tasks related sources web. Furthermore, Web ripeautomation given sheer number online applications complete lackcoordination them, agents could address endless list needs problemssolved people use Web practical purposes. Furthermore, like softwareagent domains, Web tasks vary widely complexity and, definition, involve routingprocessing information part task.paper, describe software agent plan language execution system enablesone express wide range tasks software agent plan planefficiently executed. implemented language executor system calledTHESEUS. Throughout paper, discuss THESEUS context Web informationgathering processing, since Web represents domain (if all)challenges software agents face found.1.1 Web Information Agentsrecent years, Web experienced rapid rate growth, usefulinformation becoming available online. Today, exists enormous amount online datapeople view, also use order accomplish real tasks. Hundredsthousands people use Web every day research airfares, monitor financial portfolios,keep date latest news headlines. addition enormity, compellingInternet practical tool dynamic, up-to-the-minute nature. example,although information stock quotes ticket availabilities change frequently, manysources Internet capable reporting updates immediately. reason,breadth depth information provides, Web become certaintasks timely necessary medium even daily newspaper, radio, television.degree complexity gathering information Web varies significantly.types tasks accomplished manually size data gathered smallneed query infrequent. example, finding address restaurant theaterparticular city using Yellow Pages type Web site easy enough people themselves.need automated, since query need done result returnedsmall easy manage. However, information gathering tasks simple.often times amount data involved large, answer requires integrating datamultiple sites, answer requires multiple queries period time. example,consider shopping expensive product period time using multiple sourcesupdated daily. tasks become quickly tedious require greater amountmanual work, making desirable automate.1.1.1. COMPLICATED TASKSOne type difficult Web information gathering task involves interleaved gatheringnavigation. benefit people use Web browser access online data, many Websources display large sets query results spread series web pages connectedNext Page links. example, querying online classified listings source automobilessale generate many results. Instead displaying results single long Web page,many classified listings sites group sets results series hyperlinked pages. orderautomatically collect data, system needs interleave navigation gathering626fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSindeterminate number times: is, needs collect results given page, navigatenext, gather next set results, navigate, on, reaches end setresults. work addressing theoretically incorporate navigationgathering process (Friedman, Levy, & Millstein, 1999), attention givenefficient execution plans engage type interleaved retrieval.second example monitoring Web source. Since Web containbuilt-in trigger facility, one forced manually check sources updated data. updatesfrequent need identify update immediately urgent, becomes desirableautomate monitoring updates, notifying user one conditionsmet. example, suppose want alerted soon particular type used car listedsale one online classified ad sources. Repeated manual checking changesobviously tedious. Mediators network query engines automate query,additional software programming languages Java C must written handlemonitoring process itself, something requires conditional execution, comparison pastresults, possible notification user, actions.1.1.2. NEED FLEXIBILITYexamples show automatically querying processing Web data involvenumber subtasks, interleaved navigation gathering integration localdatabases. needs, traditional database query languages like SQL insufficientWeb. root problem lack flexibility, expressivity, languages -typically, querying supported. complicated types Web information gatheringtasks, described articles (Etzioni & Weld, 1994; Doorenbos et al.,1997; Chalupsky, Gil, Knoblock, Lerman, Oh, Pynadath, Russ, & Tambe, 2001; Ambite, Barish,Knoblock, Muslea, Oh, & Minton, 2002; Sycara, Paolucci, van Velsen, & Giampapa, 2003;Graham, Decker, & Mersic, 2003), usually involve actions beyond needed merelyquerying (i.e., beyond filtering combining) require plans capable varietyactions, conditional execution, integration local databases, asynchronousnotification users. short, Web information gathering tasks require expressive queryplan language describe solution.XQuery (Boag, Chamberlin, Fernandez, Florescu, Robie, & Simeon, 2002), used queryingXML documents, one language offers flexibility. example, XQuery supportsFLWOR expressions allow one easily specify iterate data. XQuery alsosupports conditional expressions, UDFs, recursive functions.Support expressive agent plans also found number software agent robotagent frameworks, INFOSLEUTH (Bayardo et al., 1997), RETSINA (Sycara et al., 2003),DECAF (Graham et al., 2003), RAPs (Firby 1994) PRS-LITE (Myers 1996). systemssupport concurrent execution operators ability execute complicated typesplans, require conditionals. addition, unlike database systems, softwareagent robot agent execution plans contain many different types operators,limited querying filtering data.1.1.3. NEED EFFICIENCYDespite support expressive plans, existing software agent robot agent plan executionsystems lack efficiency problem painfully realized kind large scaledata integration working remote sources operate less optimal speeds.particular, systems like RETSINA, DECAF, RAPs PRS-LITE ensure high-degreeoperator parallelism (independent operators execute concurrently), ensuretype data parallelism (independent elements data processed concurrently).example, possible one operator systems stream information another.understandable case robot plan execution systems, address robot627fiBARISH & KNOBLOCKinteracts physical world, typically concerned communicating effects,object X direction north, relatively speaking small amounts localinformation. Interestingly, software agent frameworks like DECAF INFOSLEUTHexpressed desire support sort streaming architecture (Bayardo et al., 1997),research constrained part use data transport layers (such KQML)contain infrastructure necessary support streaming.However, software agent process large amounts remote information efficiently,types parallelism critical. Dataflow-style parallelism important order scheduleindependent operations concurrently; streaming important order able process remoteinformation becomes available make maximum use local processing resources.Consider agent engages two types image processing image data downloadedsurveillance satellite. normally takes one minute download data another minutetype processing, streaming dataflow execution theoretically reduce overallexecution time two-thirds. Even greater speedups possible different informationprocessing tasks.Though existing software agent robot plan execution systems support streaming,substantial amount previous work gone building architectures databasesystems (Wilschut & Apers, 1993) recently network query engines (Ives, Florescu,Friedman, Levy, & Weld, 1999; Hellerstein, Franklin, Chandrasekaran., Deshpande, Hildrum,Madden, Raman, & Shah, 2000; Naughton, DeWitt, Maier, Aboulnaga, Chen, Galanis, Kang,Krishnamurthy, Luo, Prakash, Ramamurthy, Shanmugasundaram, Tian, Tufte, Viglas, Wang,Zhang, Jackson, Gupta, & Che, 2001). systems employ special iterative-style operatorsaware underlying support streaming1 exploit feature minimizeoperator blocking. Examples include pipelined hash join (Wilschut & Apers, 1993; Ives, etal., 1999) eddy data structure (Avnur & Hellerstein, 2000), efficiently routes streamingdata operators. Despite support streaming dataflow model execution, network queryengines lack generality flexibility existing agent frameworks systems. XQueryprovide powerful flexible language Web data gathering manipulation.However, network query engines support subset XQuery related XML queryprocessing operators support constructs conditionals recursion2,essential complex types information processing tasks.1.2 Contributionssummary, desirable automate gathering processing data Web,currently possible build agent flexible efficient using existingtechnologies. Existing agent execution systems flexible types plans support,lack ability stream information, critical feature needs builtunderlying architecture well individual operators (i.e., operators need implementediterators). Network query engines contain support streaming dataflow, lackexpressivity provided existing agent plan languages.paper, address need combine presenting expressive plan languageefficient execution system software agents. specifically, paper makes twocontributions. first software agent plan language extends features existing agentplan languages expressive query languages existing informationintegration systems network query engines. language proposed consists rich setoperators that, beyond gathering manipulating data, support conditional execution,management data local persistent sources, asynchronous notification results users,1Note: term pipelining common database literature (e.g., Graefe, 1993), although streamingoften used network query engine literature (see recent publications Niagara Telegraph).2example, Tukwila supports subset Xquery (Ives et al., 2002).628fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSintegration relational XML sources, extensibility (i.e., user-defined functions).addition, language modular encourages re-use: existing plans calledplans subplans plans called recursively. operators constructsprovide expressivity necessary address complicated types software agent tasks,monitoring interleaved navigation gathering Web data.second contribution paper design executor efficiently processesagent plans written proposed language. core executor implements streamingdataflow architecture, data dispatched consuming operators becomes availableoperators execute whenever possible. design allows plans realize maximumdegree operational (horizontal) data (vertical) parallelism possible. design alsosupports recursive streaming, resulting efficient execution plans requireindeterminate looping, agents interleave navigation gathering informationWeb. short, executor supports highly parallel execution software agent plans,leading significant performance improvement provided expressive, lessefficient agent executors.implemented plan language executor system called THESEUS.Throughout paper, refer example plans deployed THESEUS orderbetter illustrate plan expressivity and, later, validate efficiency claims.1.3 Organizationrest paper organized follows. Section 2 provides background basicterminology dataflow computing (Arvind & Nikhil, 1990; Papdopoulos & Culler, 1990;Gurd & Snelling, 1992), generic information integration (Chawathe, Garcia-Molina, Hammer,Ireland, Papakonstantinou, Ullman, & Widom, 1994; Arens, Knoblock, & Shen, 1996; Levy,Rajaraman, & Ordille, 1996; Weiderhold 1996; Genesereth, Keller, & Duschka, 1997)automated Web information gathering (Knoblock et al., 2001; Ives et al., 1999; Barish &Knoblock, 2002; Thakkar, Knoblock, & Ambite, 2003; Tuchinda & Knoblock, 2004). Section 3describes details involved one type complex software agent information gathering task,example used throughout rest paper. Section 4, describeproposed plan language detail. Section 5 deals design streaming dataflowexecutor provides high degrees horizontal vertical parallelism runtime.Section 6, present experimental results, describing plan language executorimplemented THESEUS measure provided systems. Section 7,discuss related work greater detail. Finally, present overall conclusions discussfuture work.2. Preliminarieslanguage execution system present paper build upon foundation priorresearch related dataflow computing (Dennis 1974) Web information integration(Wiederhold 1996; Bayardo et al., 1997, Knoblock et al., 2001). Although seemingly orthogonaldisciplines, effective complements parallelism asynchrony provideddataflow computing lends performance problems associated Web informationgathering.2.1 Dataflow Computingpure dataflow model computation first introduced Dennis (1974) alternativestandard von Neumann execution model. foundations share much common pastwork computation graphs (Karp & Miller, 1955), process networks (Kahn 1974),communicating sequential processes (Hoare 1978). Dataflow computing long theoreticalexperimental history, first machines proposed early 1970s real629fiBARISH & KNOBLOCKphysical systems constructed late 1970s throughout 1980s early 1990s(Arvind & Nikhil, 1990; Papdopoulos & Culler, 1990; Gurd & Snelling, 1992).dataflow model computation describes program execution terms datadependencies instructions. dataflow graph directed acyclic graph (DAG) nodesedges. nodes called actors. consume produce data tokens along edgesconnect actors. actors run concurrently able execute, fire,time input tokens arrive. Input tokens come initial program inputresult earlier execution (i.e., output prior actor firings). potential overallconcurrency execution thus function data dependencies exist program,degree parallelism referred dataflow limit.key observation made dataflow computing execution inherentlyparallel actors function independently (asynchronously) fire necessary. contrast,von Neumann execution model involves sequential processing pre-ordered setinstructions. Thus, execution inherently serial. comparing dataflow von Neumann,subtle difference (yet one heart distinction two) notedscheduling instructions determined run-time (i.e., dynamic scheduling), whereasvon Neumann system occurs compile-time (i.e., static scheduling). Figure 1 illustratesdifference dataflow von Neumann approaches applied executionsimple program. program requires multiplication two independent additions.von Neumann style execution, ADD operations must executed sequentially, eventhough independent other, instruction counter schedules oneinstruction time. contrast, since availability data drives scheduling dataflowmachine, ADD operations executed soon input dependencies fulfilled.Dataflow systems evolved classic static (Dennis 1974) model dynamictagged token models (Arvind & Nikhil, 1990) allowed multiple tokens per arc, hybridmodels combine von Neumann traditional dataflow styles execution (Iannucci, 1988;Evripidou & Gaudiot, 1991; Gao, 1993). models applied digital signalprocessing include boolean dataflow synchronous dataflow (Lee & Messerschmitt, 1987),resulting architectures known dataflow networks. work described paperrelevant specific hybrid dataflow approach, known threaded dataflow(Papadopoulos & Traub, 1991), maintains data-driven model execution associatesFigure 1: Comparing von Neuman dataflow computing630fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSinstruction streams individual threads execute von Neumann fashion. distinctpure von Neumann multithreading sense data, instruction counter, remainsbasis scheduling instructions (operators). also distinct pure dataflowsense execution instruction streams statically scheduled sequential task, unliketypical dynamic scheduling found dataflow machines. result, threaded dataflow alsoviewed data-driven multithreading.Recent advances processor architecture, Simultaneous Multithreading (SMT)project (Tullsen, Eggers, & Levy, 1995) demonstrated benefits data-drivenmultithreading. SMT-style processors differ conventional CPUs (such Intel Pentium)partitioning on-chip resources multiple threads execute concurrently, making betteruse available functional units amount chip real estate. resulting executionreduces vertical waste (the wasting cycles) occur sequence instructionsexecuted using one thread, well horizontal waste (the wasting available functionalunits) occur executing multiple threads. so, technique effectively tradesinstruction-level parallelism (ILP) benefits thread-level parallelism (TLP) benefits. Insteaddeep processor pipeline (which becomes less useful depth increases), SMTprocessors contain multiple shorter pipelines, associated single thread. resultcan, highly parallel applications, substantially improve scheduling on-chip resourcesthat, conventional CPUs, would normally starved result I/O stalls wellthread context-switching.work described applies threaded dataflow design higher level executioninformation gathering plan level. Instead executing fine-grained instructions,interested execution coarse-grained operators. Still, believe threaded dataflowgenerally efficient strategy executing I/O-bound information gathering plans integratemultiple remote sources allows coarse-grained I/O requests (such network requestsmultiple Web sources) automatically scheduled parallel. plans similarsystems maintain high degrees concurrent network connections, Webserver database system. Prior studies Web servers (Redstone, Eggers, & Levy, 2000)database systems (Lo, Barroso, Eggers, Gharachorloo, Levy, & Parekh, 1998) alreadyshown systems run efficiently SMT-style processors; believehold true execution dataflow-style information gathering plans.2.2 Web-based Information Gathering IntegrationGeneric information integration systems (Chawathe et al., 1994; Arens et al., 1996; Levy et al.,1996; Genesereth et al., 1997) concerned problem allowing multiple distributedinformation sources queried logical whole. systems typically dealheterogeneous sources addition traditional databases, provide transparent accessflat files, information agents, structured data sources. high-level domain model mapsdomain-level entities attributes underlying sources information provide.information mediator (Wiederhold 1996) responsible query processing, using domainmodel information sources compile query plan. traditional databases, queryprocessing involves three major phases: (a) parsing query, (b) query plan generationoptimization (c) execution. Query processing information integration involvesphases builds upon traditional query plan optimization techniques addressing casesinvolve duplicate, slow, and/or unreliable information sources.Web-based information integration differs types information integrationfocusing specific case information sources Web sites (Knoblock et al., 2001).adds two additional challenges basic integration problem: (1) retrievingstructured information (i.e., relation) semi-structured source (Web pages writtenHTML) (2) querying data organized manner facilitates human visualconsumption, necessarily strictly relational manner. address first challenge, Web631fiBARISH & KNOBLOCKsite wrappers used convert semi-structured HTML structured relations, allowing Websites queried databases. Wrappers take queries (such expressedquery language like SQL) process data extracted Web site, thus providingtransparent way accessing unstructured information structured. Wrappersconstructed manually automatically, latter using machine learning techniques (Knoblock,Lerman, Minton, & Muslea 2000; Kushmerick, 2000). wrappers used extractdata many Web sites, sites problematic data extractedpresented. One common case Web site distributes single logical relational answermultiple physical Web pages, case online classifieds example describedearlier. Automating interleaved navigation gathering required scenarios, yetreceived little attention literature. One approach extend traditional query answeringinformation integration systems incorporate capability navigation (Friedman et al.,1999). However, solutions mostly address query processing phase remainsopen issue regarding execute types information gathering plans efficiently.recent technology querying Web network query engine (Ives et al.,1999; Hellerstein et al., 2000; Naughton et al., 2001). systems are, like mediators,capable querying sets Web sources, greater focus challengesefficient query plan execution, robustness face network failure large data sets,processing XML data. Many network query engines rely adaptive execution techniques,dynamic reordering tuples among query plan operators (Avnur & Hellerstein 2000)double pipelined hash join (Ives et al., 1999), overcome inherent latency unpredictableavailability Web sites.important aspect network query engine research focus dataflow-styleexecution. Research parallel database systems long regarded dataflow-style queryexecution efficient (Grafe, 1993; Wilschut & Apers, 1993). However, applied Web,dataflow-style processing yield even greater speedups (a) Web sources remote,base latency access much higher accessing local data (b) Web datacannot strategically pre-partitioned, shared-nothing architectures (DeWitt & Gray,1992). Thus, average latency Web data access high, parallelizing capabilitydataflow-style execution even compelling traditional parallel databasesystems potential speedups greater.3. Motivating Examplediscussed earlier, mediators network query engines allow distributed Web dataqueried efficiently, cannot handle complicated types informationgathering tasks query (and thus plan) languages support degreeexpressivity required. better motivate discussion, describe detailed exampleinformation gathering problem requires complex plan. Throughout restpaper, refer example describe details proposed agent planlanguage execution system.example involves using Web search new house buy. Suppose wantuse online real estate listings site, Homeseekers (http://www.homeseekers.com),locate houses meet certain set price, location, room constraints. so,want query run periodically medium duration time (e.g., weeks)new updates (i.e., new houses meet criteria) e-mailed us found.understand automate gathering part task, let us first discuss userswould complete manually. Figures 2a, 2b, 2c show user interface result pages632fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSFigure 2a: Initial query form Yahoo Real EstateFigure 2b: Initial results Yahoo Real EstateFigure 2c: Detailed result Yahoo Real Estate633fiBARISH & KNOBLOCKHomeseekers. query new homes, users initially fill criteria shown Figure 2aspecifically, enter information includes city, state, maximum price, etc. fillform, submit query site initial set results returnedshown Figure 2b. However, notice page contains results 1 15 22.get remainder results, "Next" link (circled Figure 2b) must followed pagecontaining results 16 22. Finally, get details house, users must followURL link associated listing. sample detail screen shown Figure 2c. detailscreen useful often contains pictures information, MLS(multiple listing services) information, house. example, detailed pagehouse must investigated order identify houses contain number rooms desired.Users would repeat process period days, weeks, even months.user must query site periodically keep track new results hand. latteraspect require great deal work users must note houses result list newentries identify changes (e.g., selling price updates) houses previouslyviewed.already discussed, possible accomplish part task using existing Webquery techniques, provided mediators network query engines. However,notice task requires actions beyond gathering filtering data. involves periodicexecution, comparison past results, conditional execution, asynchronous notificationuser. actions traditional Web query languages support indeed,actions involve gathering filtering. Instead query plan language,needed agent plan language supports operators constructs necessary completetask.consider agent plans generally might look. Figure 3 shows abstract planmonitoring Homeseekers. figure shows, search criteria used input generateone pages house listing results. URLs house results pageextracted compared houses already existed local database. New housesweb page database subsequently queried detailsappended database future queries distinguish new results. extractionhouses given Homeseekers results page, "Next" link (if any) pagefollowed houses page go process. next-link processingcycle stops last result page, page without Next link, reached. Then,details last house gathered, update set new houses founde-mailed user.LOAD DAT AB ASEh ous espre viousl eenEXTRACThous e URLssearchcriteriaGET h ouseresults p ag eFILTERthos e h ousespre viousl eenEXTRACT"ne xt pag e" lin kGET h ousedet ail pag eUPDATE ATAB ASEne w ho usesFigure 3: Abstract plan monitoring Yahoo Real Estate634SEND E-MAILuserfiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTS4. Expressive Plan Language Software Agentssection, present agent plan language makes possible construct planscapable complicated tasks. Throughout section, focus information gatheringtasks, Homeseekers example shown Figure 3.4.1 Plan Representationlanguage, plans textual representations dataflow graphs describing set inputdata, series operations data (and intermediate results leads to), setoutput data. discussed earlier, dataflow naturally efficient paradigm informationgathering plans. Graphs consist set operator sequences (flows) data oneoperator given flow iteratively processed flows successive operatorsflow, eventually merged another flow output plan.example, Figure 4 illustrates dataflow graph form plan named Example_plan.shows plan consists six nodes (operators) connected set edges (variables).solid directed edges (labeled a, b, c, d, f, g) represent stream data, dasheddirected edge (labeled e) represents signal used synchronization purposes.cbOp1Op2fOp4geOp3Op5Figure 4: Graph form Example_planFigure 5 shows text form plan. header consists name plan(example_plan), set input variables (a b), set output variables (f). bodysection plan contains set operators. set inputs operator appearsleft colon delimiter set outputs appears right delimiter. Oneoperator (Op3) WAIT clause associated production signal indicatedFigure 4 e. ENABLE clause later operator (Op5) describes consumptionsignal.graph text forms example plan describe following execution.Variables b plan input variables. Together, trigger execution Op1,produces variable c. Op2 fires c becomes available, leads output variabled. Op3 fires upon availability produces signal e. Op4 uses compute f (thePLAN example_plan{INPUT: a, bOUTPUT: fBODY{Op1Op2Op3Op4Op5}(a, b : c)(c : d)(c : ) {ENABLE: e}(d : f, g)(g : ) {WAIT : e}}Figure 5: Text form Example_plan635fiBARISH & KNOBLOCKplan output variable) g. Finally, availability g signal e triggers executionOp5.Note although body part text form plan lists operators linear order,ordering affect actually executed. Per dataflow modelprocessing, operators fire whenever individual data dependencies fulfilled. example,although Op3 follows Op2 order specified plan text, actually executeslogical time Op2. Also note plan output, f, produced plan still running(i.e., Op5 still processing).4.1.1. FORMAL DEFINITIONSFormally, define following:Definition 1: information gathering plan P represented directed graphoperators Ops nodes connected set variables Vars edges. planassociated subset Vars plan input variables PlanIn another subsetvariables plan output variables PlanOut. specifically, let plan P representedtupleP = <Vars, Ops, PlanIn, PlanOut>Vars = {v1, ..., vn}, n > 0Ops = {Op1, ..., Opm}, > 0PlanIn = {va1, ..., vax}, x > 0, s.t. {va1, ..., vax} VarsPlanOut = {vb1, ..., vby}, >= 0, s.t. {vb1, ..., vby} VarsDefinition 2: plan operator Op encapsulates function Func computes set operatoroutput variables OpOut set operator input variables OpIn. specifically, letoperator Opi P represented tupleOpi = <OpIn, OpOut, Func>OpIn = {vi1, ..., vic}, c > 0, s.t. {vi1, ..., vic} VarsOpOut = {vo1, ..., vog}, g >= 0, s.t. {vo1, ..., vog} VarsFunc = Function computes {vo1, ..., vog} {vi1, ..., vic}Furthermore, plan Pa also called another plan Pb operator. case,plan Pa known subplan.Definition 3: schedule execution operator instance Opi described firingrule depends OpIn, optional second set input wait variables OpWait, resultsgeneration OpOut optional second set output enablement variables OpEnable.initial firing operator conditional availability least one OpInOpWait. initial firing, OpEnable variables declared also produced.OpOut variables produced accordance semantics operator.specifically, let us define:(Opi) = <OpIn, OpWait, OpOut, OpEnable>OpWait = {vw1, ..., vwd}, >= 0, s.t. {vw1, ..., vwd} VarsOpEnable = {ve1, ..., veh}, h >= 0, s.t. {ve1, ..., veh} VarsWait enable variables synchronization mechanisms allow operator executionconditional beyond normal set input data variables. understand how, let us firstdistinguish standard data variable synchronization variable. standard datavariable one contains information meant interpreted, specifically,636fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSprocessed function operator encapsulates. example, PlanIn, PlanOut, OpIn,OpOut consist normal data variables. synchronization variable (earlier calledsignal) one consists data meant interpreted rather, variablesmerely used additional conditions execution. Since control dataflow systems drivenavailability data, synchronization variables dataflow style plans usefulprovide control flow flexibility. example, certain static operation occurtime given data flow active, synchronization variables allow us declare behavior.Definition 3 indicates that, like actors traditional dataflow programs, operatorsinformation gathering plans firing rule describes operator processinput. example, dataflow computer specified (Dennis 1974), actors fireincoming arcs contain data. plans language described paper, firingrule slightly different:operator may fire upon receipt input variable, providing receivedwait variables.Note plans operators require least one input because, firing rule implies,plans operators without least one input would fire continuously.4.2 Data StructuresOperators process transmit data terms relations. relation R consists setattributes (i.e., columns) a1..ac set zero tuples (i.e., rows) t1..tr, tuple ticontaining values vi1..vic. express relations attributes set tuples containingvalues attributes as:R (a1, ..., ac) = {{v11, ..., v1c}, {v21, ..., v2c}, ..., {vr1, ..., vrc}}attribute relation one five types: char, number, date, relation (embedded),document (i.e., DOM object).Embedded relations (Schek & Scholl, 1986) within particular relation Rx treatedopaque objects vij processed operator. However, extracted, becomeseparate relation Ry processed rest system. Embedded relationsuseful allow set values (the non-embedded objects) associatedentire relation. example, operator performs COUNT function relationdetermine number tuples contained relation, resulting tuple emittedoperator consist two attributes: (a) embedded relation object (b) value equalnumber rows embedded relation. Embedded relations thus allow setsassociated singletons, rather forcing join two. sense, preserverelationship particular tuple relation without requiring spaceadditional key repeating data (as join would require).XML data supported document attribute type. XML one type documentspecified Document Object Model (DOM). proposed language contains specificoperators allow DOM objects converted relations, relations convertedDOM objects, DOM objects XML documents queried native formusing XQuery. Thus, language supports querying XML documents nativeflattened form.4.3 Plan Operatorsavailable operators plan language represent rich set functions usedaddress challenges complex information gathering tasks, monitoring.Specifically, operators support following classes actions:data gathering: retrieval data network traditional relationaldatabases, Oracle DB2.637fiBARISH & KNOBLOCKdata manipulation: including standard relational data manipulation, SelectJoin, well XML-style manipulations XQuery.data storage: export updating data traditional relational databases.conditional execution: routing data based contents run-time.asynchronous notification: communication intermediate/periodic resultsmediums/devices transmitted data queued (e.g., e-mail).task administration: dynamic scheduling unscheduling plans externaltask database.extensibility: ability embed special type computation (single-rowaggregate) directly streaming dataflow query planThough operators differ exact semantics, share similaritiesprocess input generate output. particular, two modes worth noting: automaticjoining output input (a dependent join) packing (embedding) unpacking(extracting) relations.information gathering plans, common use data collected one source basisquerying additional sources. Later, often becomes desirable associate inputsource output produces. However, join separate step tediousrequires creation another key existing set data plus cost join.simplify plans improve efficiency execution, many operators languageperform dependent join input tuples onto output tuples produce. dependentjoin simply combines contents input tuple output tuple(s) generates,preserving parity two. example, operator ROUND converts floatingpoint value column nearest whole integer value. Thus, input data consistedtuples {{Jack, 89.73}, {Jill, 98.21}} result ROUND operator executes would{{Jack, 89.73, 90}, {Jill, 98.21, 98}}. Without dependent join, primary key would needadded (if one already exist) separate join would doneROUND computation. Thus, dependent joins simplify plans reduce total numberoperators plan (by reducing number decoupled joins) eliminate need ensureentity integrity prior processing.Another processing mode operators involves packing unpacking relations3.operations relevant context embedded relations. Instead creatingmanaging two distinct results (which often need joined later), cleaner spaceefficient perform dependent join packed version input relation resultoutput aggregate-type operator. example, using AVERAGE operatorinput data above, result dependent join packed form original relationwould be: {{{Jack, 89.73}, {Jill, 98.21}}, 93.97}. Unpacking would necessary getoriginal data. short, embedded relations make easy associate aggregates valuesled derivation. Packing unpacking useful data handling techniquesfacilitate goal.Table 1 shows entire set operators proposed language. (suchSelect Join) well-known semantics (Abiteboul, Hull, & Vianu, 1995) useddatabase information gathering systems. result, discussdetail. However, many operators new provide ability expresscomplicated types plans. focus purpose mechanicsoperators.3Note: operations also referred NEST UNNEST database literature.638fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSOperatorPurposeFetch extract data web sites relations.Filters data relation.Filters attributes relation.Combines data two relations, based specified condition.Performs set union two relations.Finds intersection two relations.Subtracts one relation another.Returns tuples unique across one attributes.Conditionally routes one two streams based existence tuples thirdEmbeds relation within new relation consisting single tuple.Extracts embedded relation tuples input relation.Generates new formatted text attribute based tuple values.Converts relation XML document.Converts XML document relation.Queries XML document attribute tuples input relation using languagespecified Xquery standard, returning XML document result attributeXquerycontained tuples output relation.DbImport Scan table local database.DbQuery Query schema local database using SQL.DbAppend Appends relation existing table creates table none exists.DbExport Exports relation single table.DbUpdate Executes SQL-style update query; results returned.Uses SMTP communicate email message valid email address.EmailSends text message valid cell phone number.PhoneFaxes data recipient valid fax number.FaxSchedule Adds task task database scheduling information.Unschedule Removes task database.Executes user-defined function tuple relation.ApplyAggregate Executes user-defined function entire relation.WrapperSelectProjectJoinUnionIntersectMinusDistinctNullPackUnpackFormatRel2xmlXml2relTable 1: complete set operators4.3.1. INTERACTING LOCAL DATABASEStwo major reasons useful able interact local database systemsplan execution. One reason local database may contain informationwish integrate online information. second reason abilitylocal database act memory plans run continuously plan run latertime needs use results plan run earlier time.address needs, database operators DbImport, DbQuery, DbExport, DbAppendprovided. common use operators implement monitoring-style query.example, suppose wish gradually collect data period time, collectionhouse data Homeseekers example. accomplish this, DbImport DbQueryused bring previously queried data plan compared newly querieddata (gathered Wrapper operator) using set-theoretic operators, Minus)result difference written back database DbAppend DbExport.4.3.2. SUPPORTING CONDITIONAL EXECUTIONConditional execution important plans need perform different actions data basedrun-time value data. analyze conditionally route data plan, language639fiBARISH & KNOBLOCKsupports Null operator. Null acts switch, conditionally routing one set data basedstatus another set data. Null refers predicate Null, conditionalexecutes different actions depending result evaluation. data null, actionperformed; null, action B performed. accomplish dataflow,Null operator publishes different sets data, one either case.example, suppose desirable stock quotes automatically communicateduser every 30 minutes. Normally, quotes retrieved e-mailed. However,percentage price change stock portfolio greater 20%, quotessent via cell phone messaging (since communication immediate). Nullwould useful case would allow Select condition process checkprice changes exist tuples match filtering criteria allow data triggeroperator communicated results via cell phone. Otherwise, Null would route dataoperator communicated information via e-mail. short, Null powerfuldynamic form conditional execution used operators(like Select) activate/deactivate flows based runtime content data.input output Null summarized Figure 6. input data analyzed d,data forwarded upon true (null) dt, data forwarded upon false df. null(i.e., contains zero tuples), dt copied output variable t. Otherwise, df copied outputf. example, contains three tuples {x1, x2, x3} dt contains five tuples {t1, t2, t3, t4,t5} df contains two tuples {f1, f2}, variable containing {t1, t2, t3, t4, t5}output. Consumers f never receive data.dtdfNullfFigure 6: NULL operator4.3.3. CALLING USER-DEFINED FUNCTIONSdesigning number agent plans, found times agents neededexecute special logic (e.g., business logic) execution. Usually, logicinvolve relational information processing plan writer simply wanted able codestandard programming language (such Java C). example, plans writtenElectric Elves travel agents (Ambite et al., 2002), necessary agent sendupdates users via DARPA CoAbs Agent Grid network. plans, needednormalize formats date strings produced different Web sources. Instead expandingoperator set unique type logic encountered, developed two special operatorsallowed plans make calls arbitrary functions written standard programminglanguages. goal operators (a) make easier write plansrequired special calculations library calls, (b) encourage non-relational information processing(which could benefit efficiency dataflow style processing) modularizedoutside plan, (c) simplify plans.two operators, Apply Aggregate, provide extensibility tuple relationlevel. Apply calls user-defined single-row functions tuple relational data performsdependent join input tuple corresponding result. example, user-definedsingle-row function called SQRT might return tuple consisting two values: input valuesquare root. user defined function written standard programming language,Java, executed per-tuple basis. Thus, type external functionsimilar use stored procedures UDFs commercial relational database systems.Aggregate operator calls user-defined multi-row functions performs dependent joinpacked form input result. example, COUNT function might return640fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSrelation consisting single tuple two values: first packed form inputsecond count number distinct rows relation. Apply,user-defined multi-row function written standard programming language like Java.However, contrast called per-tuple basis, executed per-relation basis.4.3.4. XML INTEGRATIONpurposes efficiency flexibility, often convenient package transform datato/from XML mid-plan execution. example, contents large data set oftendescribed compactly leveraging hierarchy XML document. addition,Web sources (such Web services) already provide query answers XML format. analyzeprocess data, often simpler efficient deal native form ratherconvert relations, process it, convert back XML. However, cases,relatively small amount XML data might need joined large set relational data.provide flexible XML manipulation integration, language supports Rel2xml,Xml2rel, Xquery operators. first two convert relations XML documents viceversa, using straightforward algorithms. Xml2Rel allows one specify iterating element(which map tuples relation) attribute elements (which map attributesrelation), generates tuples include index referring order originalXML element parsed. Cross product style flattening deeper child elements performedautomatically. Rel2Xml even straightforward: creates parent XML elementstuple inserts attribute elements children, order appear relation. allowXML processed native form, support Xquery operator, based XQuerystandard (Boag et al., 2002).Xml2Rel, Rel2Xml, Xquery complementary terms functionality. Xml2Relhandles basic conversion XML relational data, noting order data document.Rel2Xml handles basic conversion back XML, without regards order notenature streaming dataflow parallelism order processing tuplesdeliberately guaranteed. However, order XML document generated Rel2Xmlimportant, Xquery used post-processing step address requirement. short,Xml2Rel Rel2Xml focus simple task converting relation document;complex processing XML accomplished Xquery operator.4.3.5. ASYNCHRONOUS NOTIFICATIONMany continuously running plans, Homeseekers, involve interactive sessionsusers. Instead, users request plan run given schedule expect receive updatesperiodic execution plan. updates delivered asynchronousmeans, e-mail, cell-phone messaging, facsimile. facilitate notification,language includes Email, Fax, Phone operators communicating data via devices.operators works similar fashion. Input data received operator reformatted form suitable transmission target device. datatransmitted: Email sends e-mail message, Fax contacts facsimile server data,Phone routes data cell phone capable receiving messages.4.3.6. AUTOMATIC TASK ADMINISTRATIONoverall system accompanies language includes task database daemon processperiodically reads task database executes plans according schedule.architecture shown Figure 7. Task entries consist plan name, set input provideplan, scheduling information. latter data represented format similarUNIX crontab entry. format allows minute, hour, day month, month, yearplan supposed run. example, task entry05 08-17 1,3,5 * * homeseekers.plan641fiBARISH & KNOBLOCKFigure 7: Task administration processmeans: run homeseekers.plan five minutes every hour 8am 5pm 1st,3rd, 5th days every month every year.tasks scheduled manually, language developed also allows plansautomatically update scheduling plans, including it. so, support two specialscheduling operators, Schedule Unschedule. former allows plan register new planrun. creates updates plan schedule data task database. input Scheduleconsists plan name schedule description, one shown above. operatorproduces single tuple output indicates assigned task ID scheduled task.Unschedule removes scheduled plan task database. Unschedule usedplan remove monitoring activity often used tandem notificationoperator. example, plan monitor set available houses market entiremonth September, send email end month user containing results,unschedule execution, schedule new plan (perhaps, example, cleandatabase stored monitoring data). input Unschedule task IDscheduled plan output tuple indicating success failure attempt removeplan task database.4.4 Subplanspromote reusability, modularity, capability recursion, plan language supportsnotion subplans. Recall plans named, consist set input outputstreams, set operators. consider series operators amounts complexfunction input data, plans present interface operators. particular,using earlier definitions, possible Opi = P OpIn = PlanIn, OpOut = PlanOut,OpWait = , OpEnable = , Func = {Op1, ..., Opn}. Thus, plan referenced withinanother plan operator. execution, subplan called likeoperator would inputs subplan arrive, executed within body subplanoperators subplan. example, consider Example_plan, introducedearlier, referenced another plan called Parent_plan. Figure 8 illustrates textform Parent_plan treats Example_plan merely another operator.642fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSPLAN parent_plan{INPUT: w, xOUTPUT: zBODY{Op6 (w : y)example_plan (x, : z)}}Figure 8: Text parent_planSubplans encourage modularity re-use. written, plan used operatornumber future plans. Complicated manipulations data thus abstracted away,making plan construction simpler efficient.example, one could develop simple subplan called Persistent_diff, shown Figure 9,uses existing operators DbQuery, Minus, Null, DbAppend take relation,compare named relation stored local database. plan determinesupdate, appends result, returns difference. Many types monitoring style plansoperate updated results incorporate subplan existing plan. Homeseekersplan could subplan returns house details given set search parameters.MINUSrelationdiffDBQUERYNULLDBAPPENDFigure 9: Persistent_diff subplan4.4.1. RECURSIONaddition promoting modularity re-use, subplans make another form control flowpossible: recursion. Recursive execution useful number scenarios related Webquery processing. describe two: reformulating data integration queries iteratingNext Page links.One application recursion THESEUS involves reformulating data integration queries.example, efficient version Duschkas Inverse Rules algorithm (Duschka 1997)implemented using recursive streaming dataflow execution THESEUS (Thakkar & Knoblock,2003). Support recursion query reformulation allowed Thakkar Knoblock developsystem produced complete answers query reformulation algorithms,MiniCon (Pottinger & Levy, 2001), support recursion.Another practical use recursion Web data integration involves iterating listdescribed multiple documents. described earlier, number online informationgathering tasks require sort looping-style (repeat until) control flow. Resultssingle query spanned across multiple Web pages. Recursion provides elegant wayaddress type interleaved information gathering navigation streaming dataflowenvironment.example, processing results search engine query, automated informationgathering system needs collect results page, follow "next page" link, collectresults next page, collect "next page" link page, runs"next page" links. express von Neumann style programming language,Do...While loop might used accomplish task. However, implementing types loops643fiBARISH & KNOBLOCKdataflow environment problematic requires cycles within plan. leadsdata one loop iteration possibly colliding data different iteration. practice,loops dataflow graphs require fair amount synchronization additional operators.Instead, problem solved simply recursion. use subplan referencemeans repeat body functionality use Null operatortest, exit condition. resulting simplicity lack synchronization complexity makesrecursion elegant solution addressing cases navigation interleaved retrievalnumber iterations looping style information gathering knownruntime. example recursion used, consider abstract plan processingresults search engine query. higher level plan called Query_search_engine, shownFigure 10a, posts initial query search engine retrieves initial results.processes results subplan called Gather_and_follow, shown Figure 10b. searchresults go Union operator next link eventually used callGather_and_follow recursively. results recursive call combined Unionoperator first flow.WRAPPERsearch termGATHER_AND_FOLLOWinitial-resultweb pagesFigure 10a: Query_search_engine planfalseurlsDISTINCTne xt -pag e -linkWRAPPERne xt-re sultsGATHER_AND_FOLLOWtrueNULLPROJECTUNIONurlFigure 10b: Gather_and_follow recursive subplan4.4.2. REVISITING EXAMPLELet us revisit earlier house search example see plan would expressedproposed plan language. Figure 11a shows one two plans, Get_houses, requiredimplement abstract real estate plan Figure 3. Get_houses calls subplan Get_urls shownFigure 11b, nearly identical plan Gather_and_follow, described above. restGet_houses works follows:(a) Wrapper operator fetches initial set houses link next page (if any)passes Get_urls recursive subplan.(b) Minus operator determines houses distinct previously seen;new houses appended persistent store.(c) Another Wrapper operator investigates detail link house fullset criteria (including picture) returned.(d) Using details, Select operator filters meet specified searchcriteria.(e) result e-mailed user.644fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTScriteriaPROJECTWRAPPERprice -infhouse -urlsGET_URLSWRAPPERSELECTraw-ho use -de tailsco ndFORMAT"be ds = %s"Figure 11a: Get_houses planWRAPPERfalseurlsDISTINCTne xt -p ag e -linkNULLGET_URLSnext -pag e -linktruePROJECTUNIONho use -urlFigure 11b: Get_urls recursive subplan5. Efficient Plan Execution Architecturedefinition, Web information gathering involves processing data gathered remote sources.execution information gathering plan, often case multipleindependent requests made different sets remote data. dataindependently processed series operations combined output. Networklatencies, bandwidth limitations, slow Web sites, queries yield large result setsdramatically curtail execution performance information gathering plans. especiallycase plan operators executed serially: one issues mentionedbottleneck execution entire plan.efficiency standpoint, two problems standard von Neumann executioninformation gathering plans. One exploit independence data flowscommon plan multiple unrelated requests remote data cannot parallelized. planlanguage designed addresses problem somewhat allowing plans expressedterms minimal data dependencies: still, dictate operatorsactually executed.second efficiency problem von Neumann execution exploitindependence tuples common relation: example, large data setprogressively retrieved remote source, tuples already retrieved couldconceivably operated successive operators plan. often reasonable, sinceCPU local system often under-utilized remote data fetched.remedy problems, designed streaming dataflow execution systemsoftware agent plans. system allows maximum degree operator data parallelismpotentially realized runtime, executing multiple operators concurrently pipeliningdata operators throughout execution. network query engines implementeddesigns bear similarity present below. However, discussionextends existing work three ways:describe details execution (i.e., threads interact firing ruleswork). exception (Shah, Madden, Franklin, & Hellerstein, 2001),able locate similar discussion details executionsystems.645fiBARISH & KNOBLOCKpresent novel thread-pooling approach execution, multiple threadsshared operators plan. allows significant parallelism without exhaustingresources.describe recursive streaming dataflow execution implemented using datacoloring approach.5.1 Dataflow Executorplan language allows dataflow-style plans coded text, specifyactual execution process works. Thus, complement language efficiently executeplans, developed true dataflow-style executor. executor allows plans realizeparallelization opportunities independent flows data, thus enabling greater horizontalparallelism runtime.executor functions virtual threaded dataflow machine. assigns user-level threadsexecute operators ready fire. type execution said virtual dataflowthread creation assignment done natively CPU, even kernel spaceoperating system, application program (the executor) running user space.using threads parallelize execution plan, executor realize better degrees trueparallelism, even single CPU machines. use threads reduces impactI/O penalties caused currently executing operator. is, multiple threads reduceeffect vertical waste occur single-threaded execution reaches operationblocks I/O.example, consider case plan containing two independent Wrapper operatorsexecuted machine single CPU. Suppose Wrapper operatorsinput fire. operators assigned distinct threads. single CPU executecode issues network request first Wrapper operator, wait datareturned, finish issuing network request second Wrapper operator. Thus,matter microseconds, operators issued requests (which typically takeorder hundreds milliseconds complete) retrieval data (on remote sites)parallelized. Thus, overall execution time equal slowertwo requests complete. contrasts execution time required serial execution,equal sum time required request.5.1.1. PROMOTING BOUNDING PARALLELISM THREAD POOLSusing threaded dataflow benefits, past research dataflow computing operatingsystems shown cases parallelism must throttled overheadthread management (i.e., creation destruction threads) overly taxing.example, threads created whenever operator ready, cost create addsignificant overhead. Also, significant parallelism execution, numberthreads employed might result context switching costs outweigh parallelism benefits.address issues, developed thread pooling architecture allows executorrealize significant parallelism opportunities within fixed bounds.start plan execution, finite number threads created (this number easilyadjustable external configuration file) arranged thread pool. threadscreated, execution begins. data becomes available (either via inputoperator production), thread pool assigned execute method consumingoperator data. time operator produces output, hands output zerothreads consumer(s), any, process output. pool containavailable threads, output queued spillover work queue, picked laterthreads return queue. behavior occurs operator input events.Thus, parallelism ensured existence multiple threads pool boundedlatter case, degree true parallelism execution never exceed pool646fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSsize. Demands parallelism beyond number threads pool handled workqueue.Figure 12 illustrates details thread pool used executor runtime.figure shows four key parts executor:thread pool: collection threads ready process input collectedqueue. single thread pool partitioned certainsources guaranteed number threads available operators querysources. available threads wait new objects queue. Typically, contentionqueue machines single CPU issue (even hundredsthreads). However, configuration options exist multiple work queuescreated thread pool partitioned across queues.spillover work queue: data received externally transmitted internally (i.e.,result operator execution) cannot immediately assigned availablethread collected queue. threads return pool, checkobjects queue: are, process them, otherwise thread waitsactivated future input. queue asynchronous FIFO queue implementedcircular buffer. queue full, grows incrementally needed. initialsize queue configurable. structure queue element described detailbelow.routing table: data structure describes dataflow plan graph termsproducer/consumer operator method associations. example, Select operatorproduces data consumed Project operator, data structure marshals outputSelect associated Project input method consumedata. table computed prior execution performanceoperator-to-operator I/O impacted runtime repetitive lookups consumersproducers. Instead, pre-computation allows data structure associatedproducing method immediately route output data proper set consuming inputmethods.Runtime planinternal data structureOperator obje cts431PlanInputRouting tableThre adPool2aThre adsavailable ?PlanOutput2bSpillov erwor k queu e5Figure 12: Detailed design executor647fiBARISH & KNOBLOCKset operator objects: collection operator classes (includinginput/output methods state data structures). exists one operator object perinstance plan.queue object consists tuple describes:session IDiteration IDcontent (i.e., data)destination operator interface (i.e., function pointer).session ID used distinguish independent sessions iteration ID distinguishcurrent call-graph level session, ensures safety concurrent re-entrancyruntime. IDs provide unique key indexing operator state information. example,recursive execution, IDs ensure concurrent firing operatordifferent levels call graph co-mingle state information. Finally, destinationoperator interface pointer code thread assigned queue object run.runtime, system works follows. Initial plan input arrives assigned threadsthread pool (#1 Figure 12), one thread input tuple (#2a), threadsavailable data added spillover work queue (#2b). assigned thread pooltakes queue object and, based description target, fetches appropriate operatorobject execute proper function data (#3). executionoperator, state information previous firings may accessed using (session ID, iterationID) pair key. result operator firing may result output. does, operatoruses routing table (#4) determine set consumers output. composes newdata queue objects consumer hands objects (#5) either availablethread thread pool (#2a) deposits work queue (#2b) threadsavailable. reduce memory demands, producers deep-copy data producemultiple consumers. Finally, operators produce plan output data route dataplan becomes available.5.2 Data Streaminglogical level, variables plan language describe relations. However,provide parallelism thus efficiency runtime, tuples common relationstreamed operators. stream consists stream elements (the tuples relation),followed end stream (EOS) marker. Thus, communicating relationproducer consumer, producing operators communicate individual tuples consumer operatorsfollow final tuple EOS token.Streaming relations operators increases degree vertical parallelismplan execution. revisiting firing rule described earlier, clarify read:operator may fire upon receipt input tuple, providing receivedfirst tuple wait variables.Thus, operator receives single tuple inputs, consume processtuple. Afterwards, potentially emit output that, turn, consumeddownstream operator output plan. resulting parallelism vertical sensetwo operators (e.g., one producer one consumers) concurrentlyoperate relation data. Remote sources return significant amounts dataefficiently processed streaming, since operator receives networktransmission pass along data processing becomes available restdata received.648fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSSupport kind streaming implies state must kept operators firings.operation performed logically entire relation, even thoughphysically involves tuple relation. operator maintain statefirings, cannot necessarily produce correct results. example, consider set-theoreticMinus operator takes two inputs, lhs rhs, outputs result lhs - rhs.operator begin emitting output soon received rhs EOS token. However,operator must still keep track rhs data receives EOS both; not, may emitresult later found incorrect. see could happen, suppose orderinput received instance Minus operator was:lhs: (Dell)lhs: (Gateway)rhs: (HP)rhs: (Gateway)rhs: EOSlhs: (HP)lhs: EOScorrect output, lhs-rhs,lhs-rhs: (Dell)lhs-rhs: EOSHowever, achieved waiting EOS emitting output alsokeeping track (i.e., maintaining state) inputs. example, lhs data retained,rhs instance (HP) would memory lhs instance (HP) occurredtuple would incorrectly emitted.summary, streaming technique improves efficiency operator I/Oincreasing degree vertical parallelism possible runtime. allowing producersemit tuples soon possible forcing wait consumers receiveproducers consumers work fast able. main tradeoff increasedmemory, queue required facilitate streaming state needsmaintained firings.5.2.1. RECURSIVE STREAMING: SIMPLICITY + EFFICIENCYStreaming complement simplicity many types recursive plans highly efficientexecution. Looping theoretical dataflow systems non-trivial desire singleassignment need synchronization loop iterations. Streamingcomplicates this: data different loop iterations collide, requiring mechanismcolor data iteration. result, looping becomes even difficult challenge.address problem, use data coloring approach. time data enters flow,given session value iteration value (initially 0). Upon re-entrancy, iteration valueincremented. leaving re-entrant module, iteration value decremented. newvalue equal 0, flow routed recursive module; otherwise, data flowcontinues unravel iteration value 0. tail-recursive situations, systemoptimizes process simply decrements iteration value 0 immediately exitsrecursive module. two pronged data-coloring approach, similar strategies useddataflow computing literature, maintains property single assignment levelcall graph. Streaming easily fits model without changes. result, manylevels call graph active parallel effectively parallelizing loop.649fiBARISH & KNOBLOCKsee works, return Get_houses example Figures 11a 11b.input tuple arrives, initial page houses fetched. happens, Next linkfollowed parallel projecting house URLs Union operatorMinus operator. Since Union operator emit results immediately, Minusoperator inputs, data flow continues next Wrapper operator,queries URL extracts details house. Thus, details housesfirst page queried parallel following Next link, exists. Datanext page extracted parallel following Next link second pageon. Meanwhile, results Get_urls subplan (the house URLs) streamed backfirst level plan, Union operator. continue detailsgathered parallel.short, recursive streaming powerful capability made possible combinationexpressivity THESEUS plan language efficient execution system. resultallows one write plans gather, extract, process data soon possible evenlogical set results distributed collection pages (a common case Internet).6. Experimental Resultsdemonstrate contributions paper, conducted set experiments highlightincreased expressivity efficient execution supported plan language executionsystem. method consists verifying three hypotheses fundamental claims:Hypothesis 1:streaming dataflow plan execution system ensures faster planexecution times possible von Neumann nonstreaming dataflow execution.Hypothesis 2:agent plan language described supports plans cannotrepresented query languages network query engines.Hypothesis 3:additional expressivity permitted plan language describedresult increased plan execution time.brief introduction implemented system used experiments, restsection divided three subsections, focuses verifyinghypotheses.6.1 THESEUS Information Gathering Systemimplemented approach described paper system called THESEUS. THESEUSwritten entirely Java (approximately 15,000 lines code) thus runs operatingsystem Java virtual machine (JVM) ported. ran experimentsdescribed Intel Pentium III 833MHz machine 256MB RAM, running Windows2000 Professional Edition, using JVM API provided Sun Microsystems Java StandardEdition (JSE), version 1.4. machine connected Internet via 10Mbps Ethernetnetwork card.6.2 Hypothesis 1: Streaming Dataflow Ensures Fast Information Agentssupport first hypothesis, measured efficiency Homeseekers informationagent. experiments show without parallelism features plan languageexecution system, agents Homeseekers would take significantly longer execute.graphical plan Homeseekers shown Figures 11a 11b. Noteplan monitor Homeseekers (we get next section), simplygathers data Web site. textual plans required simply translations650fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSFigures 11a 11b using plan language described paper. textual formGet_houses plan shown Figure 13a textual form Get_urls plan shownFigure 13b.demonstrate efficiency streaming dataflow provides, ran HomeseekersGet_houses plan three different configurations THESEUS. first configuration (D-)consisted thread pool one thread effectively preventing true multi-threaded dataflowexecution also makes streaming irrelevant. resulting execution thus similarcase plan programmed directly (without threads) using language like JavaC++. second THESEUS configuration (D+S-) used multiple threads dataflow-styleprocessing, stream data operators. Finally, third configuration (D+S+)consisted running THESEUS normal streaming dataflow mode, enabling typesparallelism. D+S- D+S+ cases, number threads set 15.Note configurations done purposes running experiments.practice, THESEUS runs one configuration: streaming dataflow n threads threadpool (n typically set 10 20). one wants modify number threadspool need alter configuration file. rarely necessary.ran configuration three times (interleaved, negate temporary benefitsnetwork source availability) averaged measurements three runs. searchconstraints consisted finding houses Irvine, CA priced $500,000$550,000. query returned 72 results (tuples), spread across 12 pages (6 results per page).Figure 14 shows average performance results three configurations termstime took obtain first tuple (beginning output) time took obtain lasttuple (end output). series unpaired t-tests measurements indicatesPLAN get_houses{INPUT: criteriaOUTPUT: filtered-house-detailsBODY{project (criteria, price-range, price-info)format (beds = %s, beds : bed-info)wrapper (initial, price-info : result-page-info)get_urls (house_urls : all-house-urls)wrapper (detail, all-house-urls : all-house-details)select (raw-house-details, bed-info : filtered-house-details)}}Figure 13a: Text Get_houses planPLAN get_urls{INPUT: result-page-infoOUTPUT: combined-urlsBODY{project(result-page-info, house-url : curr-urls)distinct(result-page-info, next-page-link : next-status)null (next-status, next-status, next-status : next-page-info, next-urls)wrapper (result-page, next-page-info : next-urls)union ( curr-urls, next-urls : combined-urls)}}Figure 13b: Text Get_urls plan651fiBARISH & KNOBLOCKstatistically significant 0.05 level.4time first tuple important shows earliest time data becomesavailable. Callers information agent plan often interested early results comeback, especially substantial amount data returned time tuples great,since allows processing results begin soon possible. time last tuple alsoimportant metric associated time data returned.Callers plan require entire set results, caller executes aggregatefunction data, thus interested measurement.Figure 14 shows, parallelism provided streaming dataflow significant impact.Typical von Neumann style execution, (D-), cannot leverage opportunitiesparallelism suffers heavily cumulative effects I/O delays. D+S- faresbetter concurrent I/O requests issued parallel, inability stream datathroughout plan prevents result pages queried parallel. Also,lack streaming, results obtained early execution (i.e., first tuple) cannotcommunicated last tuple ready. Note D+S- case reflects performanceprovided plan executed robot plan execution systems like RAPs PRS-LITE,support operational (horizontal) parallelism data (vertical) parallelism.Finally, D+S+ case shows streaming alleviate problems, allowing firsttuple output soon possible, supporting ability query result pagesparallel (and process detail pages soon possible, parallel). short, Figure 14 showsstreaming dataflow efficient execution paradigm I/O-bound Web-informationgathering plans require interleaved navigation gathering.also sought compare execution performance Get_houses planperformance achieved using another type information gathering system,network query engine. However, since systems support ability express loopsrecursive information gathering, possible simply run planexecutors. address this, calculated theoretical performance network query enginesupported streaming dataflow, ability loop result pages.solve type challenge sites like Homeseekers pose, systems would needgather data one result page time. Note loops recursion systemspossible (i.e., possible gather data spread across set pages parallel), given80000Time (ms)700006000050000D-40000D+S-3000020000D+S+100000First tupleLast tupleFigure 14: Performance benefits streaming dataflow4Two-tailed P results D+S vs. D+S- D+S- vs. D- time-to-first-tuple cases 0.00010.0024 respectively. Two-tailed P results D+S+ vs D+S- D+S- vs. D- time-to-last tuple cases0.0001 0.0026, respectively:652fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTStype intermediate plan language support, still used drilldetails particular result (i.e., gather data set pages) parallel. Thus, networkquery engine could leverage dataflow streaming capabilities process single page,could used parallelize information gathering set linked result pages.page (and details) would processed one time.simulate behavior, used THESEUS extract house URLs details one pagetime, twelve pages results obtained initial query. average timerequired gather details six housing results 3204 ms. Note timeretrieve first detailed result THESEUS D+S+ case: 1852ms. taketime extract six detailed results multiply number pages query (12),get time last tuple equal (3204 * 12) = 38448ms. Figure 15 shows resultscompare D+S+ case THESEUS.Thus, ad-hoc solution using network query engine could allow first tupleresults returned fast THESEUS inability Next links navigatedimmediately would result less loop parallelism and, result, would lead slowerproduction last tuple data. Therefore, network query engines could usedgather results spread across multiple hyperlinked web pages, inability natively supportmechanism looping negates potential streaming parallelize loopingprocess.summary, verify first hypothesis, described expressivity planlanguage presented enables complex queries (like Homeseekers) answered efficiently.results apply Homeseekers, type site reports result listseries hyperlinked pages.6.3 Hypothesis 2: Better Plan Language Expressivitysupport second hypothesis, investigated complex task monitoringHomeseekers could accomplished using approach versus existing Web query systems.previously described monitoring cases would useful searchinghouse process requires weeks, months executing kind query. Thus,corresponding information gathering plan would query Homeseekers per day sendnewly found matches end user e-mail. Again, type problem generaloften desirable able monitor many Internet sites produce lists results. However,requires support plans capable expressing monitoring task, persistencemonitoring data, ability notify users asynchronously.plan monitor Homeseekers shown Figure 16. plan shownFigure 13a, additional modifications. particular, uses two database operators(DbImport DbAppend) integrate local commercial database system persistence45000Time (ms)4000035000Theoretical netw orkquery engine30000Theseus D+S+2500020000150001000050000First tupleLast tupleFigure 15: Comparison hypothetical network query engine653fiBARISH & KNOBLOCKDB-IMPORTDBAPPENDho use s-se e ncriteriaPROJECTWRAPPERprice -infho use -u rlsGET_URLSMINUSWRAPPERSELECTraw-hou se -de ailsco ndEMAILFORMAT"b e ds = %s"Figure 16: Modifying Homeseekers support monitoring requirementsresults. allows future queries return new results stored past results. Noticeinitial DbImport triggered synchronization variable. plan also communicates newresults asynchronously users via Email operator.measure expressivity, consider comparison plan Figure 16capable produced TELEGRAPH NIAGARA network query engines.comparison focuses TELEGRAPHCQ (Chandrasekaran, Cooper, Deshpande, Franklin,Hellerstein, Hong, Krishnamurthy, Madden, Raman, Reiss, & Shah, 2003) NIAGARACQ(Chen, DeWitt, Tian, & Wang, 2000), modifications original systemssupport continuous queries monitoring streaming data sources.SinceTELEGRAPHCQ NIAGARACQ query languages similar, present detailedcomparison former general comparison latter.CQ systems allow continuous Select-Project-Join (SPJ) queries expressed.TELEGRAPHCQ provides SQL-like language extensions expressing operationswindows streaming data. Specifically, language allows one express SPJ style queriesstreaming data also includes support loop constructs allow frequencyquerying streams. example, treat Homeseekers streaming data sourcequery per day (for 10 days) houses Manhattan Beach, CA, less$800,000:Select street_address, num_rooms, priceHomeseekersprice < 800000 city = Manhattan Beach state = CA(t=ST; t<ST+10; t++) {WindowIs(Homeseekers, t-1, t)}NIAGARACQ also allows complicated operations, Email, accomplishedcalling function declared stored procedure language. format NIAGARACQquery is:CREATE CQ_nameXML-QL queryaction{START s_time} {EVERY time_interval} {EXPIRE e_time}example, query would XML-QL equivalent selecting house informationmet query criteria.action part would something similarMailTo:user@example.com.Generally, query language limitations comes flexiblemonitoring sources, limitations THESEUS have. First, abilityinterleave gathering data navigation (in fact, NIAGARACQ assumes Homeseekersqueried XML source provides single set XML data). Second,support actions (like e-mail) based differentials data monitored periodtime. Although allow one write stored procedure could accomplish action,654fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSrequires separate programming task execution efficient rest query(this could issue complicated intensive CPU I/O-bound activities pertuple). Finally, CQ systems, way terminate querytemporal constraints.6.4 Hypothesis 3: Increased Expressivity Increase Execution TimeThough demonstrated THESEUS performs well complex informationgathering tasks, useful assess whether increased expressivity THESEUS impactsperformance simpler tasks particular, ones network query engines typically process.this, explored performance THESEUS traditional, database style queryplan online information gathering compared type plan executednetwork query engine.chose single, common type SPJ query involved multiple data sources servebasis comparison. canonical data integration query. claimunderstanding THESEUS compares network query engine respectperformance SPJ query heart efficiency comparison two typessystems. Since types systems execute dataflow-style plans pipelined fashion,theoretical performance expected differences would dueimplementation environment biases (e.g., different LAN infrastructures). Nevertheless,support efficiency claim, felt important use concrete SPJ query comparison.experiment, chose reproduce query paper another network queryengine Telegraph. measure performance partial results query processingtechnique, Raman Hellerstein ran query gathered data three sourcesjoined together (Raman & Hellerstein, 2002). specific query involved gatheringinformation contributors 2000 U.S. Presidential campaign, combinedinformation neighborhood demographic information crime index information. Table 2lists sources data provide. Bulk scannable sources dataextracted read directly (i.e., exists static Web page file). Index sourcesprovide answers based queries via Web forms. Index sources thus sourcesrequire binding patterns. Table 3 shows query used evaluateperformance TELEGRAPH.important note Raman Hellerstein measured performance queryTable 3 standard pipelined mode compared JuggleEddy partial resultsapproach. interested results former, measure wellunoptimized network query engine call baseline gathers dataprocessing traditional, database-style query. optimization, JuggleEddy,complementary system described here. Since types systems rely streamingdataflow execution consisting tuples routed iterative-style query operators, woulddifficult extend THESEUS support types adaptive query processingtechniques.SourceFECYahooRealEstateCrimeSitewww.fec.govType dataBulk scannable source provides information(including zip code) contributor candidate2000 Presidential campaign.realestsate.yahoo.com Index source returns neighborhood demographicinformation particular zip code.www.apbnews.comIndex source returns crime level ratingsparticular zip code.Table 2: Sources used FEC-Yahoo-Crime query655fiBARISH & KNOBLOCKQuerySELECT F.Name, C.Crime, Y.incomeFEC F, Crime C, YahooF.zip = Y.zip F.zip = C.zipTable 3: SQL query associates crime income statisticspolitical campaign contributionswrote simple THESEUS plan allowed query Table 3 executed. usedexactly sources, except found latency Crime source increasedsubstantially, compared times recorded Raman Hellerstein. Instead, usedanother source (Yahoo Real Estate) added artificial delay tuple processedsource, new source performed similarly. Raman Hellersteins results showperformance pipeline plan slow Crime source, 250ms pertuple. match this, added 150ms delay tuple processing new source,Yahoo, normally fetching data 100ms per tuple. results shownFigure 17.results show THESEUS able execute plan least fastbaseline TELEGRAPH plan, non-optimized result shown Figure 8 paperRaman Hellerstein, THESEUS execution efficient depending numberthreads thread pool. example, THESEUS-3 describes case THESEUSthread pool contains 3 threads. result run performs slightly worseTELEGRAPH baseline minor differences could due changes source behaviordifferent proximities network sources. However, running THESEUS threadsthread pool (i.e., THESEUS-6 THESEUS-10) shows much better performance.degree vertical parallelism demanded execution better accommodatedthreads. noted reason TELEGRAPH perform wellTHESEUS-6 THESEUS-10 likely system assigned single threadoperator (Raman 2002). is, THESEUS-6 THESEUS-10 execution involves 6 10concurrent threads, respectively, whereas TELEGRAPH plan uses 3 concurrent threads.7. Related WorkTheseus-10 Theseus-6200000180000160000140000120000100000800006000040000200000Telegraph0120001000800060004000Theseus-320000Cell updateslanguage system discussed paper relevant efforts focus agentexecution querying Web data. understand work presented contextapproaches, consider past work software agent execution, robot agent execution,network query engines. first area relevant, software agent systemsTime (seconds)Figure 17: Comparing THESEUS TELEGRAPH baseline (FEC-Yahoo-Crime)656fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTShistorically addressed expressivity issues and, recent years, also attempted addressefficiency issues. Robot plan executors represent slightly greater contrastless experience processing large amounts data. hand, network query enginesexplored large-scale remote data processing, though plan/query expressivity tendsquite narrow.7.1 Software Agent Execution SystemsInternet Softbot (Eztioni & Weld, 1994) software agent automates variousinformation processing tasks, including UNIX command processing Web informationgathering. support execution incomplete information world, systeminterleaves planning execution. XII (Golden et al., 1994) later Puccini (Golden1998) planners generate partially-ordered plans effects actionknown execution verified execution. Softbot makesclear distinction information goals satisfaction goals, specifically addressneed efficiently flexibly handle information processed. example, systemsupport kind parallel processing information (to capitalize I/O-boundnature execution). terms expressivity, XII Puccini allow universalquantification expressed (i.e. iteration possible), requires setiterated known advance. pointed earlier example Next Pagelinks, always case set next pages processed discoverediterating indeterminate, do..while fashion. contrast, althoughinterleave planning execution, system described support expressiveplan language capable handling next-link type processing, well streaming dataflowmodel execution enables efficient large scale information processing. great extent,contributions research efforts viewed complementary.research, INFOSLEUTH (Bayardo et al., 1997) recognized importanceconcurrent task/action execution, close spirit true dataflow computing.time, work generally investigated impact streaming combined dataflow.INFOSLEUTH describes collection agents that, combined working together, presentcohesive view data integration across multiple heterogeneous sources. INFOSLEUTHcentralizes execution Task Execution Agent, coordinates high-level informationgathering subtasks necessary fulfill user queries routing appropriate queries resourcesaccommodate queries. Task Execution Agent data-driven and, thus, taskfulfillment proceeds dataflow-style manner. addition, multi-threading architecturesupports concurrent, asynchronous communication agents. However, streamingcomponent exist fact, INFOSLEUTH intends large scale informationprocessing, specifically notes limitations KQML (the basis message transportagents) streaming feasible time implementation.INFOSLEUTH THESEUS similar desire support efficient, large-scale informationprocessing. However, THESEUS supports streaming operators, wellexpressive plan language, capable support complex types plans, including supportconditionals recursion.contrast INFOSLEUTH, BIG (Lesser, Horling, Klassner, Raja, Wagner, & Zhang, 2000)general software agent separates components agent planning, scheduling,execution (among components). BIG agents execute plans based tasks modeledTMS modeling language. execution, BIG reasons resource tradeoffs attemptsparallelize non-local requests (such Web requests), least terms actionsscheduled. terms expressivity, TMS include support conditionalslooping constructs (see DECAF, below), unlike system described paper. termsexecution, BIG may perform operations concurrently, execute puredataflow manner: instead, parallelizes certain operations, based whether657fiBARISH & KNOBLOCKblocking. significantly reduces additional opportunities dataflow-style parallelism.example, possible parallelize CPU-bound operations (desirable hyperthreadedprocessors multi-CPU machines) possible leverage additional I/O-bound parallelismtwo different instruction flows. example latter, consider plan usescommon input data query set sources, performing different computations input data(e.g., form query) remote request. Since I/O-bound operationsparallelized, way execute flows simultaneously, even though flowseventually end I/O-bound second larger difference BIG THESEUSlatter supports capability stream data operators, maximizing degreevertical parallelism possible, former not. shown, better verticalparallelism execution yield significant performance gains.RETSINA (Sycara et al., 2003) general, multi-agent system attempts automatewide range tasks, including information processing. RETSINA unique attemptsinterleave planning execution (as XII Internet Softbot), alsoinformation gathering. RETSINA agent composed four modules: communication,planning, scheduling, execution monitoring. modules run separate threads,communication, planning scheduling occur information gathering (which oftenI/O-bound). addition, multiple actions RETSINA executed concurrently,dataflow-style manner, separate threads. execution, actions communicateinformation one another via provision/outcome links (Williamson, Decker, & Sycara,1996), similar notion operator input output variables describedhere. dataflow aspect agent execution RETSINA similar THESEUS,plan language less expressive (no support conditionals kind looping, includingindeterminate) execution support streaming.DECAF (Graham et al., 2003) extension RETSINA TMS task languagesupport agent plans contain if-then-else looping constructs. addition, DECAFincorporates advanced notion task scheduling views mode operationanalogous operating system example, execution, concernednumber I/O-bound CPU-bound tasks one time, optimize task scheduling.DECAF employs expressive task language, closer supported THESEUS,support streaming execution. Again, shown, benefitsincreased vertical parallelism streaming make significant differenceprocessing large amounts data working slow, remote sources, casecommon environments like Web. fact, shown going beyond dataflowlimit (maximum vertical horizontal parallelism) though techniques speculativeexecution (Barish & Knoblock, 2002; Barish & Knoblock, 2003) yield even greaterperformance benefits. Streaming simple feature add execution system; wayoperators execute must change (i.e., become iterators), end-of-stream ordering mustmanaged care, support operator state management needed, addition relatedchallenges.7.2 Robot Agent Execution Systemswork THESEUS also related past work robot agent execution systems. mainsimilarity emphasis providing plan language execution system agents.main difference, however, robot agent execution systems built primarily robots,act physical world, lack support critical features softwareagents like Web information agents require. discussing specifics, focus two well-knownrobot agent executors: RAP system (Firby 1994) PRS-LITE (Myers 1996).RAP PRS-LITE offer general plan languages execution systems supportconcurrent execution actions. Like expressive plan languages, RPL (McDermott1991), RAP PRS-LITE also support additional action synchronization WAIT-658fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSclause, triggers action particular signal received. similaruse WAIT ENABLE THESEUS plan language. PRS-LITE supports even greaterexpressivity, including notion sequencing goals, enable conditional goals wellparallel sequential goal execution. example, PRS-LITE supports SPLITmodalities two different ways specify parallel goal execution, former decoupledparent task latter tightly coupled.Despite expressivity supported RAPs PRS-LITE, clear plan languagesprimarily meant handle needs robots. example, operator execution involvesprocessing signals, streams tuples, operators. contrast, THESEUSlanguage executor built stream potentially large amounts relational data.plan like Homeseekers executed RAPs PRS-LITE, lack streaming would resultsignificantly worse performance make poor use available resources. sayRAPs PRS-LITE contain design flaws: rather, systems simply better facilitate needsrobots process small amounts local data (such target presence locationinformation) perform actions physical world. contrast, Web information agentsact physical objects, software objects, Web sites, need dealproblems associated unreliable remote I/O potentially large amounts data.Streaming thus critical feature agents, allows much faster performancelocal resources, CPU, better utilized.Another significant difference language presented RAPsPRS-LITE support recursion. understandable robot agent execution systemslack feature none primary tasks require control flow. fact, neitherPRS-LITE RAP supports kind looping mechanism. contrast, looping often requiredWeb information agents, frequently need gather logical set data distributedacross indeterminate number pages connected Next page links. Recursivestreaming enables high-performance looping dataflow environment without kindcomplicated synchronization.cannot understated features like streaming recursion make significantdifference terms agent performance. example, execution Homeseekers withoutrecursive streaming would fare better D+S- example Section 6, performedmuch worse D+S+ case.7.3 Network Query EnginesNetwork query engines TUKWILA (Ives et al., 1999), TELEGRAPH (Hellerstein et al.,2000) NIAGARA (Naughton et al., 2001) focused primarily efficient adaptiveexecution (Avnur & Hellerstein 2000; Ives et al., 2000; Shanmugasundaram et al., 2000; Raman& Hellerstein 2002), processing XML data (Ives et al., 2001), continuous queries(Chen et al., 2000; Chandrasekaran et al., 2003). systems take queries users,form query plans, execute plans set remote data sources incoming streams.THESEUS, network query engines rely streaming dataflow efficient, parallelprocessing remote data.work described differs network query engines two ways. first,important difference, plan language. Plans network query engines consistmostly relational-style operators required additional adaptive XML-styleprocessing. example, TUKWILA includes double pipelined hash join dynamic collectoroperators adaptive execution (Ives et al., 1999), x-scan web-join operators facilitatestreaming XML data binding tuples. TELEGRAPH contains Eddy operator (Avnur &Hellerstein 2000) dynamic tuple routing SteMs operator leverage benefitscompeting sources access methods. NIAGARA contains Nest operator XMLprocessing operators managing partial results (Shanmugasundaram et al., 2000).Outside special operators adaptive execution XML processing, plans network659fiBARISH & KNOBLOCKquery engines look similar database style query plans. plans also inaccessibleusers alter queries generate plans, plans themselves.contrast, plan language presented expressive agent plansaccessible. Like network query engines, language described includes relational-styleoperators processing XML data. However, also includes operators supportconditional execution, interaction local databases, asynchronous notification, userdefined single-row aggregate functions. plan language developed also supportssubplans modularity, re-use, recursive execution looping-style information gathering.contrast, network query engines support kinds constructs. result,systems cannot represent interleaved navigation gathering required tasksHomeseekers example. Consider Telegraph approach handling Next Page links.logic iterating set Next Page type links located wrapper itself, separatequery plan5. simplifies wrappers somewhat (each wrapper returnsdata particular site), limits flexibility describing gather remote data.example, one develops Google wrapper Telegraph gathers results search (overseveral pages), easy way express requirement stop 10 pages stop5 links site extracted. short, since logic dealingNext Page type links decoupled plan, expressivity limited.addition, build wrapper handles Next Page links Telegraph, one must write customJava class referenced engine runtime. contrast, THESEUS languagehandle interleaved navigation gathering using recursion loop set Next Pagelinks, streaming tuples back system extracted, immediate postprocessing conditional checks (i.e., know stop gathering results).final difference worth noting accessibility. contrast network queryengines, plans language described accessible user. Althoughgenerated query processors (Thakkar et al., 2003) types applications (Tuchinda &Knoblock, 2004), like plans produced network query engines, also constructedmodified using text editor. provides ability users specify complicatedplans could otherwise represented query. network query engines,NIAGARACQ (Chen et al., 2000) support means specifying complicatedtypes actions associated continuous queries, support native systemthus possible execute complex actions middle queries (such actions needoccur certain times, example certain events occur). example, NIAGARACQrequires one specify actions stored procedure language, introducing barrier (query planstored procedure) exist system. Furthermore, logic separatequery plan (i.e., integrated query plan operators) executecondition met.8. Conclusion Future WorkSoftware agents potential automate many types tedious time-consuming tasksinvolve interactions one software systems. so, however, requiresagent systems support plans expressive enough capture complexity tasks,time execute plans efficiently. needed way marry generalityexisting software agent robot agent execution systems efficiency network queryengines.paper, presented expressive plan language efficient approachexecution addresses needs. implemented ideas THESEUS applied5See Advanced TESS Wrapper Writing section TESS manual,http://telegraph.cs.berkeley.edu/tess/advanced.html660fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSsystem automate many types Web information processing tasks. Webcompelling domain medium demands agent flexibility efficiency.existing software agent robot agent plan execution systems support complex plansconsisting many different types operators, systems designed processinformation efficiently technologies developed database research communities.paper, presented plan language execution system combines key aspectsagent execution systems state-of-the-art query engines, software agentsefficiently accomplish complex tasks. plan language described makes possiblebuild agents accomplish complex tasks supported network queryengines. Agents written using language executed efficiently state-of-theart network query engines efficiently existing agent execution systems. Beyondwork here, also proposed continuing work method speculativeexecution information gathering plans (Barish & Knoblock 2002). technique leveragesmachine learning techniques analyze data produced early execution accuratepredictions made data needed later execution (Barish & Knoblock2003). result new form dynamic runtime parallelism lead significantspeedups, beyond dataflow limit allows.also currently working Agent Wizard (Tuchinda & Knoblock, 2004),allows user define agents monitoring tasks simply answering set questionstask. Wizard works similar Microsoft Excel Chart Wizard, buildssophisticated charts asking user set simple questions. Wizard generateinformation gathering plans using language described paper scheduleperiodic execution.Acknowledgementsresearch based upon work supported part National Science FoundationAward No. IIS-0324955, part Defense Advanced Research Projects Agency (DARPA),Department Interior, NBC, Acquisition Services Division, Contract No.NBCHD030010, part Air Force Office Scientific Research grant numbersF49620-01-1-0053 FA9550-04-1-0105, part United States Air Force contractnumber F49620-02-C-0103, part gift Intel Corporation, part giftMicrosoft Corporation.U.S. Government authorized reproduce distribute reports Governmentalpurposes notwithstanding copyright annotation thereon. views conclusionscontained herein authors interpreted necessarily representingofficial policies endorsements, either expressed implied,organizations person connected them.661fiBARISH & KNOBLOCKReferencesAbiteboul, S., Hull, R. S., & Vianu, V. (1995). Foundations Databases, Addison-Wesley.Ambite, J.-L, Barish, G., Knoblock, C. A., Muslea, M., Oh, J. & Minton, S. (2002). GettingThere: Interactive Planning Agent Execution Optimizing Travel. Proceedings14th Innovative Applications Artificial Intelligence (IAAI-2002). Edmonton, Alberta,Canada.Arens, Y, Knoblock, C. A., & Shen, W-M. (1996). "Query Reformulation DynamicInformation Integration." Journal Intelligent Information Systems - Special Issue IntelligentInformation Integration 6(2/3): 99-130.Arvind, Gostelow, K. P., & Plouffe, W. (1978). Id Report: Asynchronous ProgrammingLanguage Computing Machine, University California, 114.Arvind & Nikhil. R. S. (1990). "Executing Program MIT Tagged-Token DataflowArchitecture." IEEE Transactions Computers 39(3): 300-318.Avnur, R. & Hellerstein, J. M. (2000). Eddies: Continuously Adaptive Query Processing.Proceedings ACM SIGMOD International Conference Management Data. Dallas,TX: 261-272.Barish, G. & Knoblock, C. A. (2002). Speculative Execution Information Gathering Plans.Proceedings Sixth International Conference AI Planning Scheduling (AIPS 2002).Tolouse, France: 184-193Barish, G. & Knoblock, C. A. (2003). Learning Value Predictors Speculative ExecutionInformation Gathering Plans. Proceedings 18th International Joint Conference ArtificialIntelligence (IJCAI 2003). Acapulco, Mexico: 1-8.Boag, S., Chamberlin, D., Fernandez, M. F., Florescu, D., Robie, J., & Simeon, J. (2002).XQuery 1.0: XML Query Language. World Wide Web Consortium, http://www.w3.org.Bayardo Jr., R. J., Bohrer, W., Brice, R. S., Cichocki, A., Fowler, J., Helal, A., Kashyap, V.,Ksiezyk, T., Martin, G., Nodine, M., Rashid, M., Rusinkiewicz, M., Shea, R., Unnikrishnan, C.,Unruh, A., & Woelk, D. (1997). InfoSleuth: Semantic Integration Information OpenDynamic Environments. Proceedings ACM SIGMOD International ConferenceManagement Data (SIGMOD 1997), Tucson, AZ: 195-206Chalupsky, H., Gil, Y., Knoblock, C. A., Lerman, K., Oh, J., Pynadath, D., Russ, T. A., &Tambe, M. (2001). Electric Elves: Applying Agent Technology Support Human Organizations.Proceedings 13th Innovative Applications Artificial Intelligence (IAAI-2001). Seattle,WA.Chandrasekaran, S., Cooper, O., Deshpande, A., Franklin, M. J., Hellerstein, J. M., Hong, W.,Krishnamurthy, S., Madden, S., Raman, V., Reiss, F., & Shah, M.A. (2003). TelegraphCQ:Continuous Dataflow Processing Uncertain World. Proceedings First BiennialConference Innovative Data Systems Research. Monterey, CA.662fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSChawathe, S., Garcia-Molina, H., Hammer, J., Ireland, K., Papakonstantinou, Y., Ullman, J., &Widom, J. (1994). Tsimmis Project: Integration Heterogenous Information Sources.Proceedings 16th Meeting Information Processing Society Japan. Tokyo, Japan:7-18.Chen, J., DeWitt, D. J., Tian, F., & Wang, Y. (2000). NiagaraCQ: Scalable Continuous QuerySystem Internet Databases. Proceedings ACM SIGMOD International ConferenceManagement Data. Dallas, TX: 379-390.Decker, K., Sycara, K., & Zeng, D. (1996). Designing multi-agent portfolio managementsystem. Proceedings AAAI Workshop Internet Information Systems.Dennis, J. B. (1974). "First Version Data Flow Procedure Language." Lecture NotesComputer Science 19: 362-376.DeWitt, D. & Gray, J. (1992). "Parallel Database Systems: Future High PerformanceDatabase Systems." Communications ACM 35(6): 85-98.Doorenbos, R. B., Etzioni, O., & Weld, D.S. (1997). Scalable Comparison-Shopping AgentWorld-Wide Web. Proceedings First International Conference AutonomousAgents, Marina del Rey, CA: 39-48.Duschka, O.M. (1997). Query Planning Optimization Information Integration. Ph.D.Thesis, Stanford University, Computer Science Technical Report STAN-CS-TR-97-1598.Etzioni, O. & Weld, D. S. (1994) "A softbot-based interface internet". CommunicationsACM, 37(7):72-76.Etzioni, O., Tuchinda, R., Knoblock, C.A., & Yates, A. (2003). buy buy: miningairfare data minimize ticket purchase price. Proceedings Ninth ACM SIGKDDInternational Conference Knowledge Discovery Data Mining, 119-128.Evripidou, P. & Gaudiot, J. L. (1991). Input/Output Operations Hybrid Data-Flow/ControlFlow Systems. Fifth International Parallel Processing Symposium. Anaheim, California:318-323.Firby, R. J. (1994). Task Networks Controlling Continuous Processes. Proceedings 2ndInternational Conference Artificial Intelligence Planning Systems. Chicago, IL: 49-54.Friedman, M., Levy A. Y., & Millstein, T. D. (1999). Navigational Plans Data Integration.Proceedings 16th National Conference Artificial Intelligence (AAAI-1999). Orlando, FL:67-73.Gao, G. R. (1993). "An Efficient Hybrid Dataflow Architecture Model." International JournalParallel Distributed Computing 19(4): 293-307.Genesereth, M. R., Keller, A. M., & Duschka, O. M. (1997). Infomaster: InformationIntegration System. Proceedings ACM SIGMOD International Conference ManagementData (SIGMOD 1997).. Tucson, AZ: 539-542.663fiBARISH & KNOBLOCKGolden, K., Etzioni, O., & Weld, D. S. (1994). Omnipotence Without Omniscience: EfficientSensor Management Planning. Proceedings 12th National Conference ArtificialIntelligence (AAAI-1994). Seattle, WA: 10481054.Golden, K. (1998). Leap Look: Information Gathering PUCCINI Planner.Proceedings 4th International Conference Planning Scheduling (AIPS 1998). 70-77Graham, J. R.., Decker, K., & Mersic M. (2003). "DECAF - Flexible Multi Agent SystemArchitecture." Autonomous Agents Multi-Agent Systems 7(1-2): 7-27. Kluwer Publishers.Graefe, G. (1993). "Query evaluation techniques large databases." ACM Computing Surveys25(2): 73-169.Gurd, J. R. & Snelling, D. F. (1992). Manchester Data-Flow: Progress Report. Proceedings6th International Conference Supercomputing. Washington, D.C., United States, ACMPress: 216-225.Hellerstein, J. M., Franklin, M. J., Chandrasekaran, S., Deshpande, A., Hildrum, K., Madden, S.,Raman, V., & Shah, M. A. (2000). "Adaptive Query Processing: Technology Evolution." IEEEData Engineering Bulletin 23(2): 7-18.Hoare, C. A. R. (1978). "Communicating Sequential Processes." Communications ACM21(8): 666-677.Iannucci, R. A. (1988). Toward Dataflow/Von Neumann Hybrid Architecture. 15th AnnualInternational Symposium Computer Architecture. Honolulu, Hawaii, IEEE Computer SocietyPress: 131-140.Ives, Z. G., Florescu, D., Friedman, M., Levy, A., & Weld D. S. (1999). Adaptive QueryExecution System Data Integration. Proceedings ACM SIGMOD InternationalConference Management Data (SIGMOD 1999). Philadelphia, PA: 299-310.Ives, Z. G., Halevy, A. Y., & Weld, D. S. (2001). "Integrating Network-Bound Xml Data." IEEEData Engineering Bulletin 24(2): 20-26.Ives, Z. G., Levy, A. Y., Weld, D. S., Florescu, D., & Friedman, M. (2000). "Adaptive QueryProcessing Internet Applications." IEEE Data Engineering Bulletin 23(2): 19-26.Ives, Z. G., Levy, A. Y., & Weld, D. S. (2002). XML Query Engine Network-boundData. VLDB Journal 11(4): 380-402Kahn, G. (1974). "The Semantics Simple Language Parallel Programming." InformationProcessing Letters 74: 471-475.Karp, R. M. & Miller, R. E. (1955). "Properties Model Parallel Computations:Determinancy, Termination, Queuing." SIAM Journal Applied Mathematics 14: 1390-1411.Knoblock, C. A., Lerman, K., Minton, S., & Muslea, I. (2000). "Accurately ReliablyExtracting Data Web: Machine Learning Approach." IEEE Data Engineering Bulletin23(4): 33-41.664fiAN EXPRESSIVE LANGUAGE EFFICIENT EXECUTION SYSTEM SOFTWARE AGENTSKnoblock, C. A., Minton, S., Ambite, J.-L., Ashish, N., Muslea, I., Philpot, A., & Tejada, S.(2001). "The Ariadne Approach Web-Based Information Integration." International JournalCooperative Information Systems 10(1-2): 145-169.Kushmerick, N. (2000). "Wrapper Induction: Efficiency Expressiveness." ArtificialIntelligence 118(1-2): 15-68.Lesser, V., Horling, B., Klassner, F., Raja, A., Wagner, T., & Zhang, S. (2000). "BIG: AgentResource-Bounded Information Gathering Decision Making." Artificial IntelligenceJournal, Special Issue Internet Information Agents. 118(1-2): 197-244.Levy, A. Y., Rajaraman, A., & Ordille, J. J. (1996). Querying Heterogeneous InformationSources Using Source Descriptions. Proceedings Twenty-Second International ConferenceLarge Databases. Bombay, India: 251-262.Lo, J. L., Barroso, L. A., Eggers, S. J., Gharachorloo, K., Levy, H. M., & Parekh, S. S. (1998).Analysis Database Workload Performance Simultaneous Multithreaded Processors.Proceedings 25th Annual International Symposium Computer Architecture. Barcelona,Spain, IEEE Press: 39-50.McDermott, D. (1991). Reactive Plan Language, Yale University, CSD-RR-864Myers, K. L. (1996). Procedural Knowledge Approach Task-Level Control. Proceedings3rd International Conference Ai Planning Scheduling. Edinburgh, UK: 158-165.Naughton, J. F., DeWitt, D. J., Maier, D., Aboulnaga, A., Chen, J., Galanis, L., Kang, J.,Krishnamurthy, R., Luo, Q., Prakash, N., Ramamurthy, R., Shanmugasundaram, J., Tian, F.,Tufte, K., Viglas, S., Wang, Y., Zhang, C., Jackson, B., Gupta, A., & Che, R. (2001). "TheNIAGARA Internet Query System." IEEE Data Engineering Bulletin 24(2): 27-33.Nikhil, R. S. & Arvind (2001). Implicit Parallel Programming pH, Morgan KaufmannPublishers Inc.Papadopoulos, G. M. & Traub, K. R. (1991). Multithreading: Revisionist View DataflowArchitectures. Proceedings 18th International Symposium Computer Architecture (ISCA1991). New York, NY: 342-351.Papdopoulos, G. M. & Culler, D. E. (1990). Monsoon: Explicit Token Store Architecture.Proceedings 17th International Symposium Computer Architecture. Seattle,Washington.Pottinger, R., & Halevy, A. Y. (2001). MiniCon: Scalable Algorithm Answering QueriesUsing Views. VLDB Journal 10(2-3): 182-198Raman, V. (2002). Personal Communication.Raman, V. & Hellerstein, J.. M. (2002). Partial Results Online Query Processing. ProceedingsACM Sigmod International Conference Management Data. Madison, Wisconsin,ACM Press: 275-286.665fiBARISH & KNOBLOCKRedstone, J. A., Eggers, S. J., & Levy, H. M. (2000). Analysis Operating System BehaviorSimultaneous Multithreaded Architecture. Proceedings Ninth InternationalConference Architectural Support Programming Languages Operating Systems.Cambridge, Massachusetts, ACM Press: 245-256.Schek, H. J., & Scholl, M. H., (1986). "The Relational Model Relation-Valued Attributes."Information Systems 11(2): 137-147.Shah, M. A., Madden, S., Franklin, M. J., & Hellerstein, J. M. (2001). "Java Support DataIntensive Systems: Experiences Building Telegraph Dataflow System." SIGMOD Record30(4): 103-114.Shanmugasundaram, J., Tufte, K., DeWitt, D. J., Naughton, J. F., & Maier, D. (2000).Architecting Network Query Engine Producing Partial Results. Proceedings ACMSIGMOD 3rd International Workshop Web Databases (WebDB 2000). Dallas, TX: 17-22.Sycara, K., Paolucci, M., van Velsen, M. & Giampapa, J. (2003). "The RETSINA MASInfrastructure. Autonomous Agents Multi-Agent Systems."7(1-2): 29-48. KluwerPublishers.Thakkar, S. & Knoblock, C. A. (2003). Efficient execution recursive data integration plans.Workshop Information Integration Web, 18th International Joint ConferenceArtificial Intelligence (IJCAI 2003). Acapulco, Mexico.Thakkar, S., Knoblock, C. A., & Ambite, J.-L. (2003). view integration approach dynamiccomposition web services. Workshop Planning Web Services, 13th InternationalConference Automated Planning & Scheduling (ICAPS 2003), Trento, Italy.Tuchinda, R. & Knoblock, C. A. (2004). Agent wizard: building agents answering questions.Proceedings 2004 International Conference Intelligent User Interfaces, Funchal,Madeira, Portugal: 340-342.Tullsen, D. M., Eggers, S., & Levy, H. M. (1995). Simultaneous Multithreading: Maximizing onChip Parallelism. Proceedings 22nd Annual ACM International Symposium ComputerArchitecture. Santa Magherita Ligure, Italy: 392-403.Wiederhold, G. (1996). "Intelligent Integration Information." Journal IntelligentInformation Systems 6(2): 281-291.Williamson, M., Decker, K., & Sycara, K. (1996). Unified Information Control FlowHierarchical Task Networks. Theories Action, Planning, Robot Control: Bridging Gap:Proceedings 1996 AAAI Workshop. Menlo Park, California, AAAI Press: 142-150.Wilschut, A. N. & Apers, P. M. G. (1993). "Dataflow Query Execution Parallel MainMemory Environment." Distributed Parallel Databases 1(1): 103-128.666fiJournal Artificial Intelligence Research 23 (2005) 167-243Submitted 07/04; published 02/05Combining Spatial Temporal Logics:Expressiveness vs. ComplexityDavid GabelaiaRoman KontchakovAgi Kuruczgabelaia@dcs.kcl.ac.ukromanvk@dcs.kcl.ac.ukkuag@dcs.kcl.ac.ukDepartment Computer Science, Kings College LondonStrand, London WC2R 2LS, U.K.Frank Wolterfrank@csc.liv.ac.ukDepartment Computer Science, University LiverpoolLiverpool L69 7ZF, U.K.Michael Zakharyaschevmz@dcs.kcl.ac.ukDepartment Computer Science, Kings College LondonStrand, London WC2R 2LS, U.K.Abstractpaper, construct investigate hierarchy spatio-temporal formalismsresult various combinations propositional spatial temporal logicspropositional temporal logic PT L, spatial logics RCC-8, BRCC-8, S4ufragments. obtained results give clear picture trade-off expressivenesscomputational realisability within hierarchy. demonstrate different combining principles well spatial temporal primitives produce NP-, PSPACE-,EXPSPACE-, 2EXPSPACE-complete, even undecidable spatio-temporal logicscomponents NP- PSPACE-complete.1. IntroductionQualitative representation reasoning quite successful dealingtime space. exists wide spectrum temporal logics (see, e.g., Allen, 1983;Clarke & Emerson, 1981; Manna & Pnueli, 1992; Gabbay, Hodkinson, & Reynolds, 1994;van Benthem, 1995). variety spatial formalisms (e.g., Clarke, 1981; Egenhofer& Franzosa, 1991; Randell, Cui, & Cohn, 1992; Asher & Vieu, 1995; Lemon & Pratt,1998). cases determining computational complexity respective reasoningproblems one important research issues. example, Renz Nebel(1999) analysed complexity RCC-8, fragment region connection calculus RCCeight jointly exhaustive pairwise disjoint base relations spatial regionsintroduced Egenhofer Franzosa (1991) Randell colleagues (1992); NebelBurckert (1995) investigated complexity Allens interval algebra; numerous resultscomputational complexity point-based propositional linear temporal logic PT Lvarious flows time obtained Sistla Clarke (1985) Reynolds (2003,2004). many cases investigations resulted development implementationeffective reasoning algorithms (see, e.g., Wolper, 1985; Smith & Park, 1992; Egenhofer& Sharma, 1993; Schwendimann, 1998; Fisher, Dixon, & Peim, 2001; Renz & Nebel, 2001;Hustadt & Konev, 2003).c2005AI Access Foundation. rights reserved.fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevspace.XXXXX.F-0123timeFigure 1: Topological temporal model.next apparent natural step combine two kinds reasoning.course, attempts construct spatio-temporal hybrids. example,intended interpretation Clarkes (1981, 1985) region-based calculus spatio-temporal.Region connection calculus RCC (Randell et al., 1992) contained function space(X, t)representing space occupied object X moment time t. Muller (1998a)developed first-order theory reasoning motion spatial entities. However,formalisms turn expressive computational point view:undecidable. Moreover, far know, serious attempts investigateimplement partial (say, incomplete) algorithms capable spatio-temporal reasoninglogics made.problem constructing spatio-temporal logics better algorithmic properties analysing computational complexity first attacked Wolter Zakharyaschev (2000b); see also popular extended version (Wolter & Zakharyaschev,2002) conference paper, well (Bennett & Cohn, 1999; Bennett, Cohn, Wolter,& Zakharyschev, 2002; Gerevini & Nebel, 2002).main idea underlying papers consider various combinations wellbehaved spatial temporal logics. intended spatio-temporal structuresregarded Cartesian products intended time-line topological (orother) spaces used model spatial dimension. Figure 1 shows product(of flow time F = hN, <i two-dimensional Euclidean space T) movingspatial object X. moving object viewed either 3D spatio-temporal entity(in particular case) collection snapshots slices entitymoment time; discussion see, e.g., (Muller, 1998b) references therein.paper, use snapshot terminology understand moving spatial object (or,precisely, interpret object as) set pairs hX, ti where, point168fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityflow time, X subset topological spacethe state spatial objectmoment t.expressive power (and consequently computational complexity) combinedspatio-temporal formalisms obviously depends three parameters:1. expressivity spatial component,2. expressivity temporal component,3. interaction two components allowed combined logic.Regardless chosen component languages, minimal requirement spatiotemporal combination useful abilityexpress changes time truth-values purely spatial propositions.(PC)Typical examples logics meeting spatial propositions truth change principlecombinations RCC-8 Allens interval calculus (Bennett et al., 2002; Gerevini & Nebel,2002) combinations RCC-8 PT L introduced Wolter Zakharyaschev(2000b) allow applications temporal operators Boolean combinations RCC-8 relations. Languages satisfying (PC) capture, instance, aspects continuitychange principle (see, e.g., Cohn, 1997)(A) two images computer screen disconnected now, either remaindisconnected become externally connected one quantum computers time.Another example following statement geography Europe:(B) Kaliningrad disconnected EU moment Poland becomestangential proper part EU, Kaliningrad EUexternally connected forever.However, languages meeting (PC) necessarily satisfy second fundamentalspatial object change principle according ableexpress changes evolutions spatial objects time.(OC)logical terms, (PC) refers change truth-values propositions, (OC)change extensions predicates; see Fig. 2 X moment denotes stateX moment + 1. examples motivating (OC):(C) Continuity change: cyclones current position overlaps position hour.(D) Two physical objects cannot occupy space: tomorrow object Xplace object today, move tomorrow.(E) Geographic regions change: space occupied Europe never changes.(F) Geographic regions change: two years EU extended RomaniaBulgaria.(G) Fairness conditions regions: raining every part England everever again.169fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevspace.XXXXX-F.t+1t+2timeFigure 2: Temporal operators regions.(H) Mutual exclusion: Earth consists water land, space occupiedwater expands, space occupied land shrinks.clear represent statements refer evolutionspatial objects time (say, compare objects X X)it enough takeaccount change truth-values propositions speaking spatial objects.main aim paper investigate trade-off expressive powercomputational behaviour spatio-temporal hybrids satisfying (PC) (OC)principles interpreted various spatio-temporal structures. purpose showcomputational obstacles one expect application domain requireskind interactions temporal spatial operators.spatio-temporal logics consider combinations fragments PT Linterpreted different flows time fragments propositional spatial logic S4u(equipped interior closure operators, universal existential quantifierspoints space well Booleans) interpreted topological spaces. choicemotivated following reasons:component logics well understood established temporal spatialknowledge representation; supported reasonably effective reasoningprocedures.definition, implicit explicit temporal quantification necessary capture (OC),fragments PT L weakest languages quantification know of.170fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityAllens interval calculus, example, provide means quantificationintervals. certainly suitable spatio-temporal hybrids satisfying (PC) (seeBennett et al., 2002; Gerevini & Nebel, 2002) natural conservativeway combining spatial formalisms meet (OC). hand,embedded PT L (Blackburn, 1992). natural alternative PT L wouldextension Allens calculus means quantification intervals introducedHalpern Shoham (1986), unfortunately temporal logic turnshighly undecidable.Although logic S4u originally introduced realm modal logic (seedetails), work Bennett (1994), Nutt (1999), Renz (2002) WolterZakharyaschev (2000a) showed regarded unifying languagecontains many spatial formalisms like RCC-8, BRCC-8 9-intersectionsEgenhofer Herring (1991) fragments.Apart choice component languages level interaction, expressive power computational complexity spatio-temporal logics strongly dependrestrictions may want impose intended spatio-temporal structuresinterpretations spatial objects.choose among different flows time (say, discrete dense, infinite finite)among different topological spaces (say, arbitrary, Euclidean Aleksandrov).time point interpret spatial objects arbitrary subsets topological space, regular closed (or open) ones, polygons, etc.represent assumption everything eventually comes end,know when, one restrict class intended models imposingfinite change assumption states spatial object change spatialconfiguration infinitely often, liberal finite state assumption accordingevery spatial object finitely many possible states (althoughmay change states infinitely often).paper organised follows. Section 2 introduce full detail componentspatial temporal logics combined later on. particular, besides standardspatial logics like RCC-8 9-intersections Egenhofer Herring (1991), considergeneralisations framework S4u investigate computational complexity. example, show maximal fragment S4u dealing regular closedspatial objects turns PSPACE-complete, natural generalisation9-intersections still NP. Section 3 introduce hierarchy spatio-temporal logicsoutlined above, provide topological-temporal semantics, analyse computational properties. First show spatio-temporal logics satisfying (PC)principle complex components. consider maximal combinations S4u (fragments of) PT L meeting (PC) (OC) seestraightforward approach work: resulting logics turn undecidable.Finally, systematically investigate trade-off expressivity complexityspatio-temporal formalisms construct hierarchy decidable logics satisfying (PC)171fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev(OC) whose complexity ranges PSPACE 2EXPSPACE. results, possible implementations well open problems discussed Section 4.readers convenience important (un)decidability complexity results obtainedpaper summarised Table 1 page 193. technical definitions detailedproofs found appendices.2. Propositional Logics Space Timebegin introducing discussing spatial temporal formalismsgoing combine later paper.2.1 Logics Spacedealing number logics suitable qualitative spatial representationreasoning: well-known RCC-8, BRCC-8 S4u , well certain fragmentslast one. intended interpretations logics topological spaces.topological space pair = hU, Ii U nonempty set, universespace, interior operator U satisfying standard Kuratowski axioms:X, U ,I(X ) = IX IY,IX IIX,IX XIU = U.operator dual called closure operator denoted C: every X U ,CX = U I(U X). Thus, IX interior set X, CX closure.X called open X = IX closed X = CX. complement open setclosed vice versa. boundary set X U defined CX IX. Note XU X boundary.2.1.1 S4uexpressive spatial formalism S4u i.e., propositional modal logic S4 extended universal modalities. pedigree logic quite unusual. S4introduced independently Orlov (1928), Lewis (in Lewis & Langford, 1932), Godel(1933) without intention reason space. Orlov Godel understoodlogic provability (in order provide classical interpretation intuitionisticlogic Brouwer Heyting) Lewis logic necessity possibility, is,modal logic. Besides Boolean connectives propositional variables, languageS4 contains two modal operators: (it necessary provable) C, dual (itpossible consistent). words, formulas S4 defined follows:::=p|| 1 u 2| I,(1)p variables. Set C = . denote modal operators C(rather conventional 2 3) understand, following observationmade several logicians late thirties early forties (Stone, 1937; Tarski, 1938;Tsao Chen, 1938; McKinsey, 1941), S4 logic topological spaces: interpretpropositional variables subsets topological space, Booleans standard settheoretic operations, C as, respectively, interior closure operators172fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityspace, S4-formula modally consistent satisfiabletopological spacei.e., value empty interpretation.1precisely, topological model pair form = hT, Ui, = hU, Iitopological space U, valuation, map associating every variable p setU(p) U . valuation U inductively extended arbitrary S4-formulas taking:U( ) = U U( ),U(1 u 2 ) = U(1 ) U(2 ),U(I ) = IU( ).Expressions form (1) interpreted subsets topological spaces;call spatial terms. particular, propositional variables S4 understoodspatial variables.language S4u extends S4 universal existential quantifiers 23, respectively (known modal logic universal modalities). Given spatialsay part space (represented by) empty (thereterm , write 3means occupies whole space (all points belong ).least one point ); 2taking Boolean combinations expressions arrive called spatialformulas. BNF definition looks follows:2::= 2|| 1 2 ,. Spatial formulas either true false= 2spatial terms. Set 3topological models. truth-relation |= spatial formula true topologicalmodel Mis defined standard way:|= 2iffU( ) = U ,|=iff6|= ,|= 1 2iff|= 1 |= 2 .Say spatial formula satisfiable topological model |= .seemingly simple query language S4u express rather complex relationssets topological spaces. example, formula(q @ p) 2(p @ Cq) 3p 3Iq2says set q dense nonempty set p, interior (here 1 @ 2abbreviation 1 u 2 ).following folklore complexity result proved different settings (see, e.g.,Nutt, 1999; Areces, Blackburn, & Marx, 2000):Theorem 2.1. (i) S4u enjoys exponential finite model property; i.e., every satisfiablespatial formula satisfiable topological space whose size exponentialsize .(ii) Satisfiability spatial formulas topological models PSPACE-complete.1. Moreover, according McKinsey (1941) McKinsey Tarski (1944), n-dimensional Euclideanspace, n 1, enough satisfy consistent S4-formulas.2. Formally, language S4u defined weaker standard one, say, GorankoPassy (1992). However, one easily show precisely expressive power:see, e.g., (Hughes & Cresswell, 1996) (Aiello & van Benthem, 2002b).173fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevOne way proving theorem first observe every satisfiable spatial formulasatisfied Aleksandrov model, i.e., model based Aleksandrov topologicalspacealias standard Kripke frame S4 (see, e.g., McKinsey & Tarski, 1944; Goranko& Passy, 1992).remind reader topological space called Aleksandrov space (Alexandroff, 1937) arbitrary (not finite) intersections open sets open. Kripke frame(or simply frame) S4 pair form G = hV, Ri, V nonempty setR transitive reflexive relation (i.e., quasi-order ) V . Every frame G inducesinterior operator IG V : every X V ,IG X = {x X | V (xRy X)}.words, open sets topological space TG = hV, IG upward closed(or R-closed ) subsets V . minimal neighbourhood point x TG (thatminimal open set contain x) consists points R-accessible x.well-known (see, e.g., Bourbaki, 1966) TG Aleksandrov space and, conversely,every Aleksandrov space induced quasi-order.Now, complete proof, suffices recall S4 PSPACE-hard (Ladner,1977) use, say, standard tableau technique establish exponential finite modelproperty construct PSPACE satisfiability checking algorithm spatial formulas.Although computational complexity S4, logic S4uexpressive. standard example spatial formulas distinguish arbitraryconnected3 topological spaces. Consider, instance, formula(Cp @ p) 2(p @ Ip) 3pp 22(2)saying p closed open, nonempty coincide whole space.satisfied model whose underlying topological space connected,satisfiable S4-formulas satisfied connected (e.g., Euclidean) spaces.Another example illustrating expressive power S4u formula(p @ Cp) 2(p @ Cp)p 23(3)defining nonempty set p p p empty interiors. fact, secondthird conjuncts say p p consist boundary points only.2.1.2 RCC-8 Fragment S4uqualitative spatial representation reasoning, quite often assumed spatialterms interpreted regular closed (or open) sets topological spaces (see,e.g., Davis, 1990; Asher & Vieu, 1995; Gotts, 1996). One reasons imposingrestriction exclude consideration pathological sets p (3). Recallset X regular closed X = CIX, clearly hold set p satisfying (3).Another reason ensure space occupied physical body homogeneoussense contain parts different dimensionality. example,3. remind reader topological space connected universe cannot representedunion two disjoint nonempty open sets.174fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity.XIXCIX.Figure 3: Regular closure.subset X Euclidean plane Fig. 3 consists three parts: 2D ellipse hole,2D circle, 1D curve connecting them. curve disappears form set CIX,regular closed CICIX = CIX, every X every topological space.paper, consider several fragments S4u dealing regular closed sets.call sets regions. Perhaps, best known language devisedspeaking regions RCC-8 introduced area GeographicalInformation Systems (see Egenhofer & Franzosa, 1991; Smith & Park, 1992)decidable subset Region Connection Calculus RCC (Randell et al., 1992). syntaxRCC-8 contains eight binary predicates,DC(X, ) regions X disconnected,EC(X, ) X externally connected,EQ(X, ) X equal,PO(X, ) X partially overlap,TPP(X, ) X tangential proper part ,NTPP(X, ) X nontangential proper part ,inverses last twoTPPi(X, ) NTPPi(X, ),combined using Boolean connectives. example, given spatial databasedescribing geography Europe, query whether United KingdomRepublic Ireland share common border. answer found checking whetherRCC-8 formula EC(UK, RoI) follows database.arguments RCC-8 predicates called region variables; interpretedregular closed setsi.e., regionsof topological spaces. satisfiability problemRCC-8 formulas interpretations NP-complete (Renz & Nebel, 1999).expressive power RCC-8 rather limited. operates simple regions distinguish connected disconnected ones, regionswithout holes, etc. (Egenhofer & Herring, 1991). RCC-8 represent complex relations two regions. Consider, example, three countries (say, Russia,Lithuania Poland) one adjacent others,point three meet. express fact may need ternarypredicate likeEC3(Russia, Lithuania, Poland).(4)175fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevanalyse possible ways extending expressive power RCC-8, convenient view fragment S4u (that RCC-8 embedded S4u first shownBennett, 1994). Observe first that, every spatial variable p, spatial termCIp(5)interpreted regular closed set every topological model. So, every regionvariable X RCC-8 associate spatial term %X = CIpX , pX spatialvariable, translate RCC-8 predicates spatial formulas taking:(%(I%EC(X, ) = 3X u %Y ) 3X u I%Y ),(%DC(X, ) = 3X u %Y ),(%(%EQ(X, ) = 2X @ %Y ) 2@ %X ),(%(%(I%PO(X, ) = 3X u I%Y ) 2X @ %Y ) 2@ %X ),(%(%(%TPP(X, ) = 2X @ %Y ) 2@ %X ) 2X @ I%Y ),(%(%NTPP(X, ) = 2X @ I%Y ) 2@ %X )(TPPi NTPPi mirror images TPP NTPP, respectively). firstformulas, instance, says two regions externally connected iff intersectionregions empty, whereas intersection interiors is. clearRCC-8 formula satisfiable topological space translationS4u defined satisfiable topological model.translation also shows RCC-8 two regions related termstruth/falsity atomic spatial formulas form(% u % ),212(I% u I% ),212(%21 @ %2 )(%21 @ I%2 ),%1 %2 spatial terms form (5). example, first formulassays intersection two regions empty, whereas last one states one regioncontained interior another one. words, RCC-8 regarded partfollowing fragment S4u :%::= CIp,::= %1 u %2::= 2|| I%1 u I%2| %1 @ %2| %1 @ I%2 ,| 1 2 .distinguish two types spatial terms. form %called atomic region termsthey represent (regular closed) regions want compare.Spatial terms form used relate regions (note extensionsnecessarily regular closed).Actually, fragment introduced bit expressive RCC-8: example, contains (appropriately modified) formula (2) satisfied disconnected topological spaces, satisfiable RCC-8 formulas satisfiableEuclidean space (Renz, 1998). However, convenient us distinguishtwo spatial logics. First, turn technical results regarding computational complexity hold even combined temporal176fiCombining Spatial Temporal Logics: Expressiveness vs. Complexitylogics. second, intuitive concise language RCC-8 suitableillustrations. instance, distinguish region variable X(% u % ).region term %X use DC(%1 , %2 ) abbreviation 312definition suggests two ways increasing expressive power RCC-8(while keeping regions regular closed):(i) allowing complex region terms %,(ii) allowing ways relating (i.e., complex terms ).2.1.3 BRCC-8 Fragment S4ulanguage BRCC-8 Wolter Zakharyaschev (2000a) (see also Balbiani, Tinchev, &Vakarelov, 2004) extends RCC-8 direction (i). uses eight binary predicatesRCC-8 allows atomic regions also intersections, unions complements. instance, BRCC-8 express fact region (say, SwissAlps) intersection two regions (Switzerland Alps case):EQ(SwissAlps, Switzerland u Alps).(6)embed BRCC-8 S4u using almost translation case RCC-8.difference now, since Boolean combinations regular closed setsnecessarily regular closed, prefix compound spatial terms CI. wayobtain, example, spatial termCI (Switzerland u Alps)representing Swiss Alps. manner treat set-theoretic operations,leads us following definition Boolean region terms:%::=CIp| CI%| CI(%1 u %2 ).words, Boolean region terms denote precisely members well-knownBoolean algebra regular closed sets. (The union expressible via intersectioncomplement usual way.) simplify notation, given spatial term , writedenote result prefixing CI every subterm ; particular,p = CIp,= CI1 u 2 = CI( 1 u 2 ).Note (equivalent to) Boolean region term, every spatial term .Swiss Alps example represented Switzerland u Alps .interest note Boolean region terms increase complexityreasoning arbitrary topological models: satisfiability problem BRCC-8 formulasstill NP-complete (however, becomes PSPACE-complete intended models basedconnected spaces). hand, BRCC-8 allows restricted comparisonstwo regions as, e.g., (6). Nevertheless, shall see below, ternary relationslike (4) still unavailable BRCC-8: require different ways comparing regions;cf. (ii).177fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev2.1.4 RCEgenhofer Herring (1991) proposed relate two regions terms 9-intersections33-matrix specifying emptiness/nonemptiness (nine) possible intersectionsinteriors, boundaries exteriors regions. Recall that, region X,three disjoint parts space hU, Ii representedIX,X (U IX)U X,respectively. generalising approach finite number regions, obtainfollowing fragment RC S4u :%::= Boolean region terms,::= %::= 2| I%||| 1 u 2 ,| 1 2 .words, RC define relations regions terms emptiness/nonemptiness sets formed using arbitrary set-theoretic operations regionsinteriors. However, nested applications topological operators allowed (anexample applications required found next section).Clearly, RCC-8 BRCC-8 fragments RC. Moreover, unlike BRCC-8,language RC allows us consider complex relations regions. instance,ternary relation required (4) defined follows:(%(I%(I%(I%EC3(X, Y, Z) = 3X u %Y u %Z ) 3X u I%Y ) 3u I%Z ) 3Z u I%X ).Another, abstract, example formula% u u % I%31i+1 u u I%j u %j+1 u u %k u I%k+1 u u I%nsaysregions %1 , . . . , %i meet somewhere inside region occupied jointly%i+1 , . . . , %j , outside regions %j+1 , . . . , %k inside %k+1 , . . . , %n .Although RC expressive RCC-8 BRCC-8, reasoning language still computational complexity:Theorem 2.2. satisfiability problem RC-formulas arbitrary topological modelsNP-complete.result proved Appendix A. Lemma A.1 shows every satisfiable RCformula satisfied model based Aleksandrov space induceddisjoint union n-broomsi.e., quasi-orders form depicted Fig. 4. Topologicalspaces kind rather primitive structure satisfying following property:(rc) roots n-brooms boundary points, minimal neighbourhoodevery boundary pointi.e., n-broom containing pointmust containleast one internal point least one external point.178fiCombining Spatial Temporal Logics: Expressiveness vs. Complexitybbbb*HHJ]HHHJHJ bdepth 0depth 1Figure 4: n-broom (for n = 4).example, spatial formula (3) cannot satisfied model property,RC.Lemma A.2, size satisfying model polynomial (in fact, quadratical)length input RC-formula, nondeterministic polynomial timealgorithm. Actually, proof straightforward generalisation complexity proofBRCC-8 given Wolter Zakharyaschev (2000a): differencecase BRCC-8 sufficient consider 2-brooms (which called forks).means, particular, ternary relation (4)which satisfiable modeln-broom, n 3is indeed expressible BRCC-8.Remark 2.3. topological terms, n-brooms examples so-called door spacesevery subset either open closed. However, modal theory n-brooms defineswider interesting topological class known submaximal spaces everydense subset open. Submaximal spaces around since early 1960sgenerated interesting challenging problems topology. survey systematicstudy spaces see (Arhangelskii & Collins, 1995) references therein.2.1.5 RC maxOne could go even direction (ii) impose restrictions whatsoeverways relating Boolean region terms. leads us maximal fragment RC maxS4u spatial terms interpreted regular closed sets. syntax definedfollows:%::= Boolean region terms,::= %::= 2||| 1 u 2| I,| 1 2 ,understand difference RC RC max , consider RC max -formula3q1 u q1 2q1 u q1 @ C q1 u q2 u q2.(7)says boundary q1 emptyevery neighbourhood everypointboundary contains internal point q1 belongs boundaryq2 (compare property (rc) above). simplest Aleksandrov model satisfyingformula depth 2; shown Fig. 5.price pay expressivity complexity RC maxfull S4u :179fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevq1 q2q1 q2q1 q2bb]JJJ bbdepth 0q1 q2]JJJq1 q2 bdepth 1depth 2Figure 5: Model satisfying formula (7).Theorem 2.4. satisfiability problem RC max -formulas PSPACE-complete.upper bound follows Theorem 2.1 lower bound proved Appendix A, construct sequence RC max -formulassatisfiable Aleksandrov space cardinality least exponential lengthformula. first formula sequence similar (7) above.interest note, however, RC max still expressive enough definepathological sets p (3) clearly regular closed.conclude section, summarise inclusions spatial languagesintroduced above:RCC-8$BRCC-8$RC$RC max$S4u .discussions spatial logics kind refer reader paper (PrattHartmann, 2002).2.2 Temporal Logicssaid introduction, temporal components spatio-temporal hybrids(fragments of) propositional temporal logic PT L interpreted various flows timemodelled strict linear orders F = hW, <i, W nonempty set timepoints < (connected, transitive irreflexive) precedence relation W .language PT L based following alphabet:propositional variables p0 , p1 , . . . ,Booleans ,binary temporal operators U (until) (since).set PT L-formulas defined standard way:::=p|| 1 2| 1 U 2| 1 2 .PT L-models pairs form = hF, Vi F = hW, <i flow timeV, valuation, map associating variable p set V(p) W timepoints (where p supposed true). truth-relation (M, w) |= , arbitraryPT L-formula w W , defined inductively follows, (u, v) denotes openinterval {w W | u < w < v}:180fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity(M, w) |= pw V(p),iff(M, w) |=(M, w) 6|= ,iff(M, w) |= 1 2(M, w) |= 1 (M, w) |= 2 ,iff(M, w) |= 1 U 2u (w, v),iffv > w (M, v) |= 2 (M, u) |= 1(M, w) |= 1 2u (v, w).iffv < w (M, v) |= 2 (M, u) |= 1PT L-formula satisfied (M, w) |= w W .took operators U primitive simply important temporaloperators defined via them. example, 3F (sometime future) 2F(always future) expressible via U3F = > U ,2F = 3F ,(> logical constant true) means(M, w) |= 3Fiffv > w (M, v) |= ,(M, w) |= 2Fiff(M, v) |= v > w.intended flows time strict linear orders, next-time operatordefinable via U taking= Ualso( logical constant false) perfectly reflects intuition: F discrete(M, w) |=iff(M, w + 1) |= ,w + 1 immediate successor w F. reader problemsdefining past versions 3F , 2F .following results due Sistla Clarke (1985) Reynolds (2003, 2004):Theorem 2.5. satisfiability problem PT L-formulas PSPACE-completefollowing classes flows time: strict linear orders, finite strict linear orders,hN, <i, hZ, <i, hQ, <i, hR, <i.Note, however, reasoning becomes somewhat simpler take 3F , 2Fpast counterparts (but , U S) temporal primitives. Denote PT L2corresponding fragment PT L. Then, according results Ono Nakamura(1980), Sistla Clarke (1985), Wolter (1996), have:Theorem 2.6. satisfiability problem PT L2 -formulas NP-completeclasses flows time mentioned Theorem 2.5.181fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev3. Combinations Spatial Temporal Logicssection introduce discuss various ways combining logics space time.First construct spatio-temporal logics satisfying (PC) principle (see introduction) show inherit good computational properties components.encouraged results, consider maximal combinations S4u(fragments of) PT L meeting (PC) (OC) see straightforward approach work: end undecidable logics. leads us systematicinvestigation trade-off expressivity computational complexity spatiotemporal formalisms. result hierarchy decidable logics satisfying (PC) (OC)whose complexity ranges PSPACE 2EXPSPACE.3.1 Spatio-Temporal Logics (PC)begin investigation combinations spatial temporal logics introducedconsidering language PT L[S4u ] temporal operators appliedspatial formulas spatial terms (this way temporalising logic firstintroduced Finger Gabbay, 1992). precise syntactic definition PT L[S4u ]-termsPT L[S4u ]-formulas follows:::= p::= 2||| 1 u 2| I,| 1 2| 1 U 2| 1 2 .Note definition PT L[S4u ]-terms coincides definition spatial termsS4u reflects fact PT L[S4u ] cannot capture change spatial objectstime. imposed restrictions upon temporal operators formulassocombined language still full expressive power PT L. (Clearly, S4u fragmentPT L[S4u ].)similar way introduce spatio-temporal logics based spatiallanguages dealing with: RCC-8, BRCC-8, RC RC max . example, temporalisation PT L[BRCC-8] BRCC-8 (denoted ST 0 hierarchy WolterZakharyaschev 2002) allows applications temporal operators RCC-8 predicatesBoolean region terms. languages regarded fragments PT L[S4u ]precisely way spatial components treated fragments S4u .illustrate expressive power PT L[RCC-8] formalising sentences (A) (B)introduction:DC(Image1 , Image2 ) DC(Image1 , Image2 ) EC(Image1 , Image2 ),DC(Kaliningrad, EU) U TPP(Poland, EU)2F(A)(B)TPP(Poland, EU) EC(Kaliningrad, EU) .Sentences (C)(H) cannot expressed language (or even PT L[S4u ]): requirecomparisons states spatial objects different time instants.intended semantics PT L[S4u ] (and spatio-temporal logics consideredpaper) rather straightforward. topological temporal model (a tt-model, short)triple form = hF, T, Ui, F = hW, <i flow time, = hU, Ii182fiCombining Spatial Temporal Logics: Expressiveness vs. Complexitytopological space, U, valuation, map associating every spatial variable pevery time point w W set U(p, w) U space occupied p momentw; see Fig. 1. valuation U inductively extended arbitrary PT L[S4u ]-terms (i.e.,spatial terms) precisely way S4u , add time pointparameter:U( , w) = U U(, w),U(1 u 2 , w) = U(1 , w) U(2 , w),U(I, w) = IU(, w).truth-values PT L[S4u ]-formulas defined way PT L:(M, w) |= 2(M, w) |=iffiffU(, w) = U ,(M, w) 6|= ,(M, w) |= 1 2iff(M, w) |= 1(M, w) |= 1 U 2u (w, v),iffv > w (M, v) |= 2 (M, u) |= 1(M, w) |= 1 2u (v, w).iffv < w (M, v) |= 2 (M, u) |= 1(M, w) |= 2 ,pure temporal case, operators 2F , 3F , well past counterpartsdefined terms U S.PT L[S4u ]-formula said satisfiable exists tt-model(M, w) |= time point w.following optimal complexity result obtained Appendix B.1:Theorem 3.1. satisfiability problem PT L[S4u ]-formulas tt-models basedarbitrary flows time, (arbitrary) finite flows time, hN, <i, hZ, <i, hQ, <i, hR, <i,PSPACE-complete.proof theorem based fact interaction spatialtemporal components PT L[S4u ] restricted. fact, every PT L[S4u ]-formulaone construct PT L-formula replacing every occurrence (spatial) subformulafresh propositional variable p . Then, given PT L-model N = hF, Vi2moment time w, take set| (N, w) |= p } {2| (N, w) |= p }w = {2spatial formulas. hard see w satisfiable every w F,tt-model satisfying based flow F. Now, check whether satisfiable,suffices use suitable nondeterministic algorithm (see, e.g., Sistla & Clarke, 1985;Reynolds, 2003, 2004) guesses PT L-model then, time point w,check satisfiability w . done using polynomial space length .Theorem 3.1 (together Theorem 2.5) shows spatio-temporal logicsform PT L[L], L {RCC-8, BRCC-8, RC, RC max }, also PSPACE-completestandard flows time.183fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevlet us consider temporalisations spatial logics (NP-complete) fragment PT L2 PT L. Theorems 2.4 3.1, PT L2 [S4u ] PT L2 [RC max ]PSPACE-complete. However, simpler (NP-complete) spatial components obtainbetter result:Theorem 3.2. satisfiability problem PT L2 [RC]-formulas tt-models basedclasses flows time mentioned Theorem 3.1 NP-complete.proof essentially Theorem 3.1, nondeterministicpolynomial-time algorithms component logics available. follows Theorem 3.2 PT L2 [RCC-8] PT L2 [BRCC-8] NP-complete well.3.2 Maximal Combinations (PC) (OC)saw previous section, computational complexity spatio-temporal logicswithout (OC) maximum complexity components, reflectslimited interaction spatial temporal operators languages withoutmeans expressing (OC).maximalist approach constructing spatio-temporal logics capable capturing(PC) (OC) allow unrestricted applications Booleans, topologicaltemporal operators form spatio-temporal terms.Denote PT L S4u spatio-temporal language given following definition:::= p::= 2||| 1 u 2|| 1 2| 1 U 2| 1 U 2| 1 2 ,| 1 2 .Expressions form called spatio-temporal terms. Unlike previous section,terms time-dependent. definition expressions formPT L[S4u ]; called PT L S4u -formulas. languagesSection 3.1, including PT L[S4u ], clearly fragments PT L S4u .before, introduce temporal operators 2F , 3F , well pastcounterparts applicable formulas. Moreover, operators used formspatio-temporal terms: example,3F = > U ,2F = 3F= U ,denotes empty set > whole space.Spatio-temporal formulas supposed represent propositions speaking movingspatial objects represented spatio-temporal terms. truth-values propositionsspatio-temporal structures vary time, depend points spacestheydefined precisely way case PT L[S4u ]. understandtemporalised terms?meaning clear: moment w, denotes space occupiednext moment w + 1 (see Fig. 2). example, writeCyclone3u Cyclone184(C)fiCombining Spatial Temporal Logics: Expressiveness vs. Complexitysay regions Cycloneintroduction). formulaCycloneoverlap (thereby formalising sentence (C)EQ( EU, EU Romania Bulgaria)(F)says two years EU (as today) extended Romania Bulgaria.Note EQ(EU, EU Romania Bulgaria) different meaning EUmay expand shrink year. also hard formalise sentences (D), (E) (H)introduction:EQ( X, ) EQ(Y, ),(D)2F EQ( Europe, Europe),(E)EQ(Earth, W L) EC(W, L) P(W, W ) P( L, L),(H)P(X, )X part denotes disjunction EQ(X, ), TPP(X, )NTPP(X, ).intended interpretation terms form 3F , 2F (and past counterparts)bit sophisticated. reflects standard temporal meanings propositions3F x 2F x , points x topological space:moment w, term 3F interpreted union spatial extensionsmoments v > w;moment w, term 2F interpreted intersection spatial extensionsmoments v > w.example, consider Fig. 2 moving spatial object X depicted three consecutivemoments time (it change + 2). 3F X union XX 2F X intersection X X (i.e., X).another example, take spatial object Rain.3F Rain moment w occupies space raining time pointsv > w (which may different different places). 2F Rain w occupies spacealways raining w.2F 3F Rain w space raining ever ever w,3F 2F Rain comprises places always raining startingfuture moments time.interpretation shows formalise sentence (G) introduction:P(England, 2F 3F Rain).(G)Now, meaning Rain U Snow? Similarly readings 2F3F above, adopt following definition:moment w, spatial extension 1 U 2 consists points x topologicalspace v > w x belongs 2 moment v x 1u whenever w < u < v.185fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevpast counterpart Ui.e., operator since Scan used say partRussia remaining Russian since 1917 connected part Germany(Konigsberg) became Russian Second World War (Kaliningrad):DC(Russia Russian Empire, Russia Germany).models = hF, T, Ui PT L S4u precisely topological temporalmodels introduced PT L[S4u ]. However, need additional clauses definingextensions spatio-temporal terms:[\U(1 U 2 , w) =U(2 , v)U(1 , u) ,v>wU(1 2 , w) =[u(w,v)U(2 , v)v<w\U(1 , u) .u(v,w)also have:U(3F , w) =[U(, v)U(2F , w) =v>w\U(, v),v>wand, discrete F,U( , w) = U(, w + 1).truth-values PT L S4u -formulas computed precisely waycase PT L[S4u ]. PT L S4u -formula called satisfiable exists tt-model(M, w) |= time point w.first sight may appear computational properties constructed logic badafter all, spatial temporal components PSPACEcomplete. turns out, however, case:Theorem 3.3. satisfiability problem PT L S4u -formulas tt-models basedflows time hN, <i hZ, <i undecidable.Without going details proof theorem, one might immediately conjecture use infinitary operators U, 2F 3F constructionspatio-temporal terms makes logic over-expressive. Moreover, whole ideatopological temporal models based infinite flows time may look counterintuitivecontext spatio-temporal representation reasoning (unlike, say, models usedrepresent behaviour reactive computer systems).different approaches avoid infinity tt-models. radical oneallow finite flows time. cautious approach impose following finitechange assumption models (based infinite flows time):FCA term change spatial extension infinitely often.means FCA consider valuations U tt-models hF, T, Uisatisfy following condition: every spatio-temporal term , pairwisedisjoint intervals I1 , . . . , F = hW, <i W = I1 stateremains constant Ij , i.e., U(, u) = U(, v) u, v Ij . turns out, however,186fiCombining Spatial Temporal Logics: Expressiveness vs. Complexitycase discrete flows time FCA give us anything new comparedarbitrary finite flows time. precisely, one easily show satisfiabilityproblem PT L S4u -formulas tt-models satisfying FCA based hN, <ihZ, <i polynomially reducible satisfiability tt-models based finite flows time,way round. Note also flows time mentioned above, FCAcaptured formulas 3F 2F EQ(, F ) (and past counterpart hZ, <i),every spatio-temporal term .liberal way reducing infinite unions intersections finite onesadopt finite state assumption:FSA Every term may finitely many possible states (although maychange states infinitely often).Say tt-model hF, T, Ui satisfies FSA if, every spatio-temporal term ,finitely many sets A1 , . . . , space {U(, w) | w W } = {A1 , . . . , }.models used, instance, capture periodic fluctuations due seasonclimate changes, say, daily tide. Similarly FCA finitising flow time, FSAvirtually makes underlying topological space finite. following propositionproved Appendix B:Proposition 3.4. PT L S4u -formula satisfiable tt-model FSA basedflow time F iff satisfiable tt-model based F finite (Aleksandrov )topological space.Unfortunately, none approaches works PT L S4u still have:Theorem 3.5. (i) satisfiability problem PT L S4u -formulas tt-models based(arbitrary) finite flows time undecidable.(ii) satisfiability problem PT L S4u -formulas tt-models based flowstime hN, <i hZ, <i satisfying FSA undecidable.next-time operator look harmful infinitary U, 2F , 3F ,still capture aspects (OC) (see formulas (C), (D), (F) (G) above). letus consider fragment PT L S4u PT L S4u spatio-temporal terms form:::=p|| 1 u 2||.words, PT L S4u allow applications temporal operators differentform spatio-temporal terms (but still available formula constructors).means compare states spatial object X bounded set timepoints only: time point natural numbers n, 0, comparestate X + n state + m.fragment definitely less expressive full PT L S4u . instance, accordingLemma B.1, PT L S4u -formulas distinguish arbitrary tt-modelsbased Aleksandrov topological spaceswe call Aleksandrov tt-models.hand, set PT L S4u -formulas satisfiable Aleksandrov modelsproper subset satisfiable arbitrary tt-models. Consider, example,PT L S4u -formula(2 Ip @ I2 p).2FF187fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevOne readily see true every Aleksandrov tt-model, negationsatisfied topological model. suffices take flow F = hN, <i topology= hR, Iistandard interior operator real line, select sequence Xnopen sets nN Xn open, e.g., Xn = (1/n, 1/n), put U(p, n) = Xn .However, even seemingly weak interaction topological temporal operators turns dangerous:Theorem 3.6. satisfiability problem PT L S4u -formulas tt-models basedflows time hN, <i hZ, <i undecidable. undecidable well tt-modelssatisfying FSA based (arbitrary) finite flows time.Theorem 2.6 might suggest considering fragment PT L2 S4u 2F pastcounterpart 2P temporal primitives applicable formulas terms:::= p::= 2||| 1 u 2|| 1 2| 2F| 2F| 2P ,| 2P .Yet result negative:Theorem 3.7. satisfiability problem PT L2 S4u -formulas tt-models (withwithout FSA) based flows time hN, <i hZ, <i undecidable. undecidablewell tt-models based (arbitrary) finite flows time.undecidability results (the strongest ones, Theorems 3.6 3.7,precise) proved Appendix B.2 reduction Posts correspondence problemknown undecidable (Post, 1946). see proofs,theorems actually hold future fragments corresponding languages.3.3 Decidable Spatio-Temporal Logics (PC) (OC)important lesson learn (the proofs of) negative results Section 3.2full S4u expressive computationally well-behaved combinations fragmentsPT L. hand, said Section 2.1.2, qualitative spatial representationreasoning often requires extensions spatial variables regular closed (i.e., regions).restriction important constructing decidable spatio-temporal logics(PC) (OC). First, undecidability proofs Appendix B.2 gocase. second, shown below, decidable combinations PT Lfragments S4u introduced Section 2.1 exist. fact, constructhierarchy decidable spatio-temporal logics different computational complexityimposing various restrictions regions themselves, ways compared,interactions spatial temporal constructors.begin considering simplest combination PT L RCC-8 capturing (PC)(OC). logic called PT LRCC-8 (it introduced name ST1 WolterZakharyaschev, 2002) operates spatio-temporal region terms form%::=CIp| CI %.relate terms, allowed use eight binary predicates RCC-8; arbitrary temporal operators Boolean connectives applied produce PT L RCC-8188fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityformulas. Typical examples formulas (A), (B), (D) (E) above. Note(C) regarded PT L RCC-8 formula well (two regions overlap iffneither disconnected externally connected). hand, (F), (H) (G)PT LRCC-8 formulas first two use operation region terms (G)uses temporal operators 2F 3F region terms.before, PT L RCC-8 formulas interpreted topological temporal models (ortt-models). However, discrete flows time make sense language. Althoughinteraction topological temporal operators similar PT L S4u(clearly, PT LRCC-8 fragment PT LS4u ), following rather unexpectedencouraging result:Theorem 3.8. satisfiability problem PT L RCC-8 formulas tt-models basedhN, <i, hZ, <i (arbitrary) finite flows time PSPACE-complete.theorem proved Appendix C.5. idea proof similarTheorem 3.1: consider spatial temporal parts given formula separately.However, take account interaction parts, use so-calledcompletion property RCC-8 (cf. Balbiani & Condotta, 2002) respect certainclass C models: given satisfiable set RCC-8 formulas model C satisfyingsubset , one extend partial model model C satisfying whole .happens extend expressive power spatial component allowingBoolean operators spatio-temporal region terms, i.e., jump RCC-8 BRCC-8?Define spatio-temporal Boolean region terms taking%::=CIp| CI%| CI(%1 u %2 ) | CI %.Denote PT L BRCC-8 language obtained PT L RCC-8 allowing spatiotemporal Boolean region terms arguments RCC-8 predicates (this languagecalled ST 1 Wolter Zakharyaschev, 2002). Formulas (A)(F) (H) belongPT L BRCC-8, (G) uses 2F 3F operators regions PT LBRCC-8.Now, another surprise replacement RCC-8 BRCC-8 temporalcontext results exponential jump computational complexity (rememberRCC-8 BRCC-8 NP-complete):Theorem 3.9. satisfiability problem PT L BRCC-8 formulas tt-models basedflows time hN, <i hZ, <i EXPSPACE-complete. EXPSPACE-completewell models satisfying FSA based (arbitrary) finite flows time.EXPSPACE upper bound (see Appendix C.3) proved polynomial embedding PT L BRCC-8 one-variable fragment QT L1 first-order temporal logic,known EXPSPACE-complete (Hodkinson, Kontchakov, Kurucz, Wolter, &Zakharyaschev, 2003). construct embedding, first show PT L BRCC-8complete respect Aleksandrov tt-models. fact, prove every satisfiableformula expressive logic PT L S4u introduced Section 3.2 satisfiedAleksandrov tt-model (see Lemma B.1 discussion above). Lemma C.1shows satisfy PT L BRCC-8 formula, suffices take Aleksandrov tt-model189fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevbased partial order depth 1. Lemma C.2, width partial orderbounded 2 (just case BRCC-8), therefore unions forks (or 2-brooms)enough satisfy PT L BRCC-8 formulas. Aleksandrov tt-models basedunions forks encoded means unary predicates QT L1 .EXPSPACE lower bound proved Appendix C.1 encoding corridortiling problem. also established direct polynomial embedding QT L1PT LBRCC-8. illustrate idea, consider QT L1 -formula x (P (x) P (x)) sayingthat, every point space, either P tomorrow.statement expressed PT L BRCC-8 formula EQ(P P, E) DC(E, E),last conjunct makes E empty.let us make one step space extend BRCC-8 RC, thus obtainingspatio-temporal language PT L RC following syntax:%::= CIp::= %::= 2| CI%| I%|| CI(%1 u %2 ) | CI %,|| 1 u 2 ,| 1 2| 1 U 2| 2 2 .reader surprised (although authors were) extra expressivity results one exponential gap:Theorem 3.10. satisfiability problem PT L RC-formulas tt-models basedflows time hN, <i hZ, <i 2EXPSPACE-complete. 2EXPSPACE-completewell models satisfying FSA based (arbitrary) finite flows time.lower bound established Appendix C.1 upper bound Appendix C.2.Perhaps, proper time closer look emerging landscape.exactly causes exponential jumps ? locate precise borders ladderPSPACEEXPSPACE2EXPSPACE?analysing proof Theorem 3.8 (see Appendix C.5), note muchadded RCC-8. fact, maximal spatio-temporal logic (denoted PT LRC 2 )proof goes based spatio-temporal terms form| CI %,%::= CIp::= %::= 1 u 2 .| I%| %| I%,hand, even addition predicates form EQ(X, Z) enoughmake logic EXPSPACE-hard (see Remark C.3). Thus, PT L RCC-8 (or ratherextension PT L RC 2 ) located pretty close border PSPACEEXPSPACE spatio-temporal logics.following fragment RC RC indicates border EXPSPACE2EXPSPACE may lie:%::= Boolean region terms,::= %| ,::= I%|::= 1 u u| 1 u 2 ,190| u| .fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityIntuitively, spatial terms interpreted regular closed regular open4sets, respectively (the interior region regular open, complement regular closedset regular open (and vice versa), regular closed sets closed unions regularopen ones closed intersections). Thus, regarded generalisationregion terms generalisation interiors regions. words, RCfragment RC following ways relating regions available:point regions meet;region intersects interior another one;interior region empty.readily checked BRCC-8 fragment RC . Moreover, proper fragment(4) belongs latter former. formula( N orthKorea2u SouthKorea ) @ DmZone(8)(saying demilitarised zone North Korea South Korea consistsborder along adjacent territories) shows RCproper subset RC:BRCC-8 $ RC $ RC.Although RC extends BRCC-8, gives rise spatio-temporal logiccomputational complexity:Theorem 3.11. satisfiability problem PT L RC -formulas tt-models basedflows time hN, <i hZ, <i EXPSPACE-complete. EXPSPACE-completewell models satisfying FSA based (arbitrary) finite flows time.lower bound follows immediately Theorem 3.9 proof upperbound similar Theorem 3.9 (see Appendix C.3). Again, due restrictionpossible ways relating regions, polynomially bound width n n-broomsrequired satisfy PT LRC -formulas (cf. Lemma C.2). fact, need formulassimilar (8) order increase complexity 2EXPSPACE.constructed hierarchy decidable spatio-temporal logics still leaves least oneimportant question: exist decidable spatio-temporal logics allow applicationstemporal operators U, 2F , 3F region terms complexity? Considerlanguages PT L L, L {BRCC-8, RC , RC}, differ PT L Ldefinition spatio-temporal region terms:%::=CIp| CI%| CI(%1 u %2 ) | CI(%1 U %2 ) | CI(%1 %2 ).following two theorems provide positive (though partial) answer question:Theorem 3.12. satisfiability problem PT L BRCC-8 PT L RC -formulastt-models based hN, <i hZ, <i satisfying FSA, based (arbitrary) finiteflows time EXPSPACE-complete.4. Remember set X regular open ICX = X.191fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevTheorem 3.13. satisfiability problem PT L RC-formulas tt-models basedhN, <i hZ, <i satisfying FSA, based (arbitrary) finite flows time2EXPSPACE-complete.upper bounds mentioned two theorems proved Appendices C.3C.2, respectively. lower bounds follow results PT LBRCC-8 (Theorem 3.9)PT L RC (Theorem 3.10).appreciate following theorem, reader recall PT L2 RCNP-complete:Theorem 3.14. satisfiability problem PT L2 BRCC-8 PT L2 RC -formulastt-models based hN, <i hZ, <i satisfying FSA, based (arbitrary) finiteflows time EXPSPACE-complete.Actually consequence EXPSPACE-hardness QT L1 sole temporaloperator 2F (see Hodkinson et al., 2003).Unfortunately, little known complexity spatio-temporal languages interpreted tt-models based dense arbitrary flows time. fact,result know proved using recent work (Hodkinson, 2004; Hodkinson et al.,2003):Theorem 3.15. satisfiability problem PT L BRCC-8 PT L RC -formulastt-models satisfying FSA based hQ, <i, hR, <i arbitrary flows time belongs2EXPTIME EXPSPACE-hard.4. Conclusionprovided in-depth analysis computational complexity various spatiotemporal logics interpreted Cartesian products flows time topological spaces.results collected Table 1. design languages drivenidea cover basic features spatio-temporal hybrids combining standard logicstime mereotopology, aim see complex reasoninghybrids could be. try fine-tune languages real-world applications.contrary, tried keep pure representative possible determinecomputational challenges multi-dimensional approach reasoning spacetime would face. research objective mind, discuss conclusionsdrawn Table 1.conclusion drawn undecidability results easy: tryimplement sound, complete terminating algorithm supposed decidesatisfiability problem PT L S4u , PT L S4u PT L2 S4u never succeed.decision procedures required, alternative languages devised.interpretation complexity results decidable logics transparent:well-known results provide us immediate conclusions regardingbehaviour implemented systems. example, sometimes algorithms runningexponential time worst-case perform better practical problems worst-caseoptimal algorithms run polynomial time. Indeed, complexity resultsanalysed together proofsif significant conclusions required (cf. Nebel, 1996).192filanguagen/aspatial component LflowRCC-8PT L[L]N, Z,Q, R,finitearbitraryN, ZPT L2 LRCRC maxNPPSPACEPSPACE(Thm. 2.4)(Thm. 2.1)NPPSPACE(Thm. 3.2)(Thm. 3.1)PSPACE(Thm. 3.1)PSPACE(Thm. 3.8)finiteEXPSPACEPSPACEN, Z+FSAEXPSPACE2EXPSPACE(Thm. 3.9)(Thm. 3.10)??finiteEXPSPACE EXPSPACE2EXPSPACENPEXPSPACE(Thm. 3.14)N, Z+FSAarbitrary2EXPTIME2EXPTIME?Q, RNPEXPSPACEFSAundecidable(Thm. 3.6)undecidable(Thm. 3.7)N, ZS4u(Thm. 2.2)NPN, ZPT L LBRCC-8N, Z,Q, R,finitearbitraryPT L LPT L2 [L]timeLCombining Spatial Temporal Logics: Expressiveness vs. Complexity???undecidable?(Thm. 3.3)finiteEXPSPACE EXPSPACEPSPACE(Thm. 3.12)N, Z+FSAarbitrary2EXPTIME2EXPTIMEEXPSPACEQ, RPSPACE(Thm. 3.15)FSA2EXPSPACE?(Thm. 3.13)?undecidable(Thm. 3.5)??Table 1: Complexity satisfiability problem spatial spatio-temporal logics.193fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevproofs show sources complexity whether couldrelevant practical problems implementation algorithms.respect proofs actually rather informative. decidability proofPT L[S4u ] immediately provides us modular algorithm combining known procedures components. EXPSPACE-completeness results PT L BRCC-8(with FSA) PT L BRCC-8 show extremely close link spatio-temporallanguages one-variable fragment first-order temporal logic. algorithmicproblems investigated context first-order temporal logic are, therefore,character deal spatio-temporal context. Thus, experienceworking algorithms (fragments of) first-order temporal logics (Hodkinson, Wolter,& Zakharyaschev, 2000; Degtyarev, Fisher, & Konev, 2003; Kontchakov, Lutz, Wolter, &Zakharyaschev, 2004) pretty good knowledge almost directlytranslates insights possible algorithms spatio-temporal logics. PSPACEcompleteness result PT L RCC-8 obtained means reduction (modulo RCC-8reasoning) PT L. conclude proof sufficientgood solvers RCC-8 PT L obtain reasonable prover PT L RCC-8.interaction two components turned rather weak.conclusion, complexity proofs clearly show algorithmic problems solveddealing spatio-temporal logics presented paper. particular, devisingalgorithms logics conceived part general enterprisedeveloping algorithms propositional one-variable fragment first-order temporallogic.comments explanations important results Table 1:1. undecidability result PT L S4u , PT L S4u PT L2 S4u solves majoropen problem Wolter Zakharyaschev (2002). shows that, S4usuitable candidate efficient pure spatial reasoning (Bennett, 1996; Renz & Nebel,1998; Aiello & van Benthem, 2002a), temporal extensions satisfying (PC)(OC) suitable practical spatio-temporal representation reasoning.2. Logics like PT L BRCC-8 may turn undecidable interpretedarbitrary topological temporal models. One main origins expressivepower possibility form infinite intersections unions regions. However,tame computational behaviour logics imposing natural restrictionsclasses admissible models FSA.3. PSPACE upper bound PT L RCC-8 EXPSPACE lower boundPT L BRCC-8 solve two major open problems Wolter Zakharyaschev(2002). interest note spatial fragments PT L RCC-8PT L BRCC-8 computational complexity: NP-completearbitrary topological spaces. Thus additional Boolean connectives spatialregions interacting next-time operator make logic substantiallycomplex.4. 2EXPSPACE-completeness result PT L RC FSA PT L RC another example seemingly tiny increase expressiveness results significantjump complexity.194fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity5. PSPACE-completeness PT L RCC-8 particularly good news, since showscombination PT L RCC-8 computational complexityPT L itself, surprisingly fast systems implemented (Schwendimann, 1998; Hustadt & Konev, 2003). gives us hope practical algorithmsPT LRCC-8 implemented. Indeed, proof shows may possibleencode satisfiability problem PT LRCC-8 satisfiability problemPT L use PT L provers. note complexity result conjectured Demri DSouza (2002) proof uses ideas BalbianiCondotta (2002).6. hand, EXPSPACE lower bounds PT L BRCC-8 FSAPT LBRCC-8 necessarily mean reasoning logics hopeless.fact, show regarded fragments one-variable firstorder temporal logic, tableau- resolution-based decision proceduresdeveloped implemented (Degtyarev et al., 2003; Kontchakov et al., 2004).course, many directions research spatio-temporal knowledge representation reasoning. mention closely relatedlogics considered above.paper, confined considering linear flows time. mayinterest, however, investigate computational properties spatio-temporallogics based branching time paradigm (see, e.g., Clarke & Emerson, 1981;Emerson & Halpern, 1985) order model uncertainty future. Recentresults Hodkinson, Wolter Zakharyaschev (2001, 2002) give hopelogics decidable.confined considering mereotopological formalisms spatialdimension. would also interest consider spatial logics directions (Ligozat,1998), shape (Galton & Meathrel, 1999), size (Zimmermann, 1995), position (Clementini, Di Felice, & Hernandez, 1997), even hybrids (Gerevini & Renz, 2002).note results direction recently obtained BalbianiCondotta (2002) Demri DSouza (2002).Another interesting important perspective spatial spatio-temporalrepresentation reasoning move arbitrary topological spacesinduced metric spaces introduce explicit and/or implicit numerical parameters.First encouraging steps direction made work (Kutz, Sturm,Suzuki, Wolter, & Zakharyaschev, 2003).conclude paper number open problems:1. precise computational complexity PT L BRCC-8 FSAdense flows time arbitrary strict linear orders?2. logics form PT L L PT L2 L, L {RC, BRCC-8, RCC-8},decidable without FSA?195fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev3. combinations PT L PT L2 RC max (satisfying (PC) (OC))decidable?4. PT L S4u undecidable dense flows time arbitrary strict linear orders?5. PT L RCC-8 FSA decidable PSPACE?Acknowledgmentswork paper partially supported U.K. EPSRC grants no. GR/R45369/01,GR/R42474/01, GR/S61966/01 GR/S63182/01. work third author alsopartially supported Hungarian Foundation Scientific Research grants T30314035192.Special thanks due referees first version paper whose remarks,criticism constructive suggestions led many days intensive excitingresearch, new results and, hopefully, better paper.Appendix A. Complexity Spatial Logicsappendix prove Theorems 2.2 2.4. proofs use fact S4u(as well fragments) complete respect (finite) Aleksandrov topological spaces(McKinsey & Tarski, 1944; Goranko & Passy, 1992). Recall p. 174 Aleksandrov(topological ) model pair form = hG, Vi, G = hV, Ri quasi-orderV map set spatial variables 2V . convenient usunify notation spatial formulas spatial terms write (M, x) |= insteadx V( ), spatial term x point V . particular, definitioninterior closure operators Aleksandrov spaces,(M, x) |=iff(M, x) |= CiffV xRy (M, y) |= ,V xRy (M, y) |= .length `() formula understand number subformulas subterms occurring .Proof Theorem 2.2. proof follows Lemmas A.1 A.2 showtogether every satisfiable RC-formula satisfied Aleksandrov model sizepolynomial (in fact, quadratical) length input formula (in words, RCpolynomial finite model property). Thus, nondeterministic polynomial timealgorithm satisfiability problem.qfact, Lemma A.1 shows RC complete respect subclass Aleksandrovspaces, namely, finite disjoint unions finite brooms. Recall p. 179 broompartial order b form h{r} V0 , Ri, R reflexive closure {r} V0(see Fig. 4). call r root b points V0 leaves b; also referredpoints depth 1 0, respectively. broom b said -broom, ,|V0 | . particular, call broom finite n-broom, n < .196fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityLemma A.1. Every satisfiable RC-formula satisfied Aleksandrov model basedfinite disjoint union finite brooms.Proof. well-known, RC-formula satisfiable satisfied finiteAleksandrov model = hG, Vi, G = hV, Ri. Define new relation R0 V taking R0reflexive closure R (V1 V0 ),V0 = {x V | (xRy yRx)}V1 = V V0 .(Without loss generality may assume V1 6= V0 oneproper R-predecessor.) Let G0 = hV, R0 M0 = hG0 , Vi. Clearly, G0 partial orderrequired. prove that, every RC-formula ,|=iffM0 |= .(9)First show that, every Boolean region term % every x V ,(M0 , x) |= %iff(M, x) |= %.(10)definition, (M0 , x) |= p iff (M, x) |= p, every spatial variable p. readily seenevery V0 every spatial term , (M0 , y) |= iff (M, y) |= . Now, %Boolean region term % = CI spatial term , clearly have:(M, x) |= CI iff V xRy z V (yRz (M, z) |= )iff V0 xR0 (M, y) |=iff V0 xR0 (M0 , y) |=iff V0 xR0 (M0 , y) |=iff(M0 , x) |= CI.Next, extend (10) spatial terms form I% % Boolean region term.(M, x) |= I% (M, y) |= % whenever xRy, so, R0 R, (M0 , x) |= I%.Conversely, suppose (M0 , x) |= I%. Take xRy z V0 yRz.claim (M, z) |= %. Indeed, x V1 follows IH xR0 z. x V0zRx. Since (M0 , x) |= %, IH % = CI , obtain (M, z) |= %. (M, y) |= %follows yRz % = CI . Thus, (M, x) |= I%.Finally, easily extend (10) arbitrary spatial terms formulas RCconstructed spatial terms form % I%, % Boolean region term,using operators depend structure underlying partial order. Thus(9).qLemma A.2. Every satisfiable RC-formula satisfied Aleksandrov model baseddisjoint union `() many 2`()-brooms.Proof. Remember every RC-formula (equivalent to) Boolean combination5,...,3, spatial termspatial formulas set = {31}. 35. following proof considerabbreviation 3primary 2.3197fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevalso Boolean (or rather set-theoretic) combination %1 , . . . , %k , I%01 , . . . , I%0m ,%i %0i Boolean region terms.follows Lemma A.1 satisfied Aleksandrov model = hG, Vi,G = hV, Ri finite disjoint union finite brooms. every 3|= 3 , fix point x V (M, x ) |= . may assume x.pairwise distinct roots brooms points form x 3.Therefore, G disjoint union `() many finite brooms b , 3,Let us construct new model M0 follows. broom b , 3% , pickleaf y,% b (if any) (M, y,% ) |= %,leaf y,% b (if any) (M, y,% ) |= %remove leaves b . Denote b0 resulting broom. Clearly, 2`() , M0 = hG0 , Vi.broom. Let G0 = hV 0 , R0 disjoint union b0 , 3easy see G0 required.,Now, show satisfied M0 , suffices prove that, 3M0 |= 3iff.|= 3(11)definition M0 , leaves G0 spatial terms ,(M0 , y) |=iff(M, y) |= .Next, every root x b , every 3every % , (M, x ) |= % iffleaf x Ry (M, y) |= % (simply % = CI, ).follows construction M0 (M, x ) |= % iff (M0 , x ) |= %, every % .also follows (M, x ) |= I% implies (M0 , x ) |= I%. Conversely, (M0 , x ) |= I%,(M, x ) 6|= I% leaf x Ry (M, y) 6|= % contradiction.Since intersection complement depend structure underlying frame,(M0 , x ) |= iff (M, x ) |= , every root x b , proves (11).qProof Theorem 2.4. PSPACE upper bound follows Theorem 2.1. proofPSPACE-hardness reduction validity problem quantified Boolean formulasknown PSPACE-complete (Stockmeyer, 1987). slightly modifyproof Ladner (1977) (that shows PSPACE-hardness S4), order takeaccount variables RC max -formulas always prefixed CI.may assume quantified Boolean formulas form= Q1 p1 . . . Qn pn 0 ,Qi {, } 0 Boolean formula variables p1 , . . . , pn . well known,possible truth assignments p1 , . . . , pn arranged leaves full binarytree depth n. left subtree root contains truth assignments p1 trueright subtree p1 false; branch p2 , p3 , on.determine whether valid pruning full binary tree: whenever Qi ,keep subtrees ith level, whenever Qi one them.198fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity00q 3 , p 1 , p2 , p 3r3@00q 3 , p 1 , p200q 3 , p 2 , p3r300q 3 , p2rr33@@@@q ,p ,p2@r - r 2 1 261@@2 r -r6r - r q 1 , p1YHHHHH1r -rq 2 , p2q1*HHr rqH00Figure 6: Aleksandrov model may satisfy , = p1 p2 p3 0 .way end tree leaves evaluate 0 true, valid,otherwise not.generate leaves binary tree Aleksandrov models helpRC max -formula. precisely, construct RC max -formulalength polynomial length ,satisfied Aleksandrov model iff valid.Take fresh spatial variables q0 , . . . , qn , put, = 0, . . . , n,q0 u q1= 0;=qi1 u qi u qi+1 ,0 < < n;qn1 u qn ,= n.consider variables p1 . . . , pnvariables, let 00 resultspatialreplacing every occurrence pi pi 0 . Put^^++00= 3220i1 @ (i )i1 @ (i u ) 2n @ ,Qi =Qi =where, = 1, . . . , n,= C u pii+ = C u pi .Clearly, RC max -formula length polynomial length .Suppose first valid. Fig. 6 shows structure possible Aleksandrovmodel satisfying .converse direction similar Ladners proof (1977). SupposesatisfiedAleksandrov model M. Then, necessary sequence truth valuesp1 , . . . , pn , point reflecting sequence (we use structurespatial terms here). Since, last conjunct , 00 holdspoints, obtain quantified Boolean formula must valid.q199fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevAppendix B. Spatio-Temporal Logics Based S4uappendix prove Theorems 3.1, 3.2, 3.6 3.7 well Proposition 3.4.Theorems 3.3 3.5 immediate corollaries Theorem 3.6. first, generalresults established used later on.remind reader Aleksandrov tt-model mean tt-model basedAleksandrov (topological) space. Every model regarded triple formK = hF, G, Vi, F = hW, <i flow time, G = hV, Ri quasi-order, V mapassociating every spatial variable p every time point w W set V(p, w) V .Appendix A, instead x V(, w) write (K, hw, xi) |= unify notationspatio-temporal formulas terms.Given spatio-temporal formula , denote sub set subformulasterm set spatio-temporal terms occurring .Lemma B.1. (i) PT L S4u -formula satisfied tt-model FSA basedflow time F, satisfied Aleksandrov tt-model FSA basedF.(ii) PT L S4u -formula satisfied tt-model based flow time F,satisfied Aleksandrov tt-model based F well.Moreover, cases choose Aleksandrov tt-model K = hF, G, Vi satisfying(with F = hW, <i G = hV, Ri) way w W , x Vspatio-temporal terms , setAw,x, = {y V | xRy (K, hw, yi) |= }contains R-maximal point 6 (provided course Aw,x, 6= ).Proof. proof uses StoneJonssonTarski representation topological Booleanalgebras (in particular, topological spaces) form general frames (see, e.g., Goldblatt,1976 Chagrov & Zakharyaschev, 1997).(i) Suppose satisfied tt-model = hF, T, Ui FSA basedtopological space = hU, Ii. Denote V set ultrafilters U . twoultrafilters x1 , x2 V , put x1 Rx2 iff U (IA x1 x2 ). easy see Rquasi-order V . Define Aleksandrov tt-model K = hF, G, Vi taking G = hV, RiV(p, w) = {x V | U(p, w) x}. show induction constructionspatio-temporal term that, w W x V ,(K, hw, xi) |=iffU(, w) x.(12)basis induction case Booleans trivial. case = 0standard (consult Goldblatt, 1976 Chagrov & Zakharyaschev, 1997).Case = 1 U 2 . Assume (K, hw, xi) |= 1 U 2 . v > w(K, hv, xi) |= 2 (K, hu, xi) |= 1 u interval (w, v). IH, U(2 , v) xU(1 , u) x u (w, v). Since\U(1 U 2 , w) U(2 , v)U(1 , u),u(w,v)6. point z said R-maximal V if, every z 0 A, z 0 Rz whenever zRz 0 .200fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityshall U(1 U 2 , w) x show\U(1 , u) x.U(2 , v)(13)u(w,v)view FSA, find time points u1 , . . . , ul (w, v)\U(1 , u),U(1 , u1 ) U(1 , ul ) =u(w,v)yields (13) ultrafilters closed finite intersections.Conversely, let U(1 U 2 , w) x. FSA, time points v1 , . . . vl[\U(1 , u) .U(1 U 2 , w) =U(2 , vi )1ilu(w,vi )since x ultrafilter,U(2 , vi )\U(1 , u) x,u(w,vi )i, 1 l. Therefore, IH, (K, hvi , xi) |= 2 (K, hu, xi) |= 1u (w, vi ). Hence (K, hw, xi) |= 1 U 2 .Case = 1 2 considered analogously.Now, show that, w W spatio-temporal terms ,(K, w) |= 2iffU(, w) = U.. (K, hw, yi) |= V , so, IH, U(, w)Suppose (K, w) |= 2V . U(, w) = U . Conversely, U(, w) = U U(, w).V , which, IH, (K, w) |= 2follows immediately satisfied K. also clear K satisfiesFSA. proves (i). existence R-maximal points sets form Aw,x, (wherew W , x V spatio-temporal term) follows result Fine (1974); seealso (Chagrov & Zakharyaschev, 1997, Theorem 10.36).(ii) construction (i). First show induction that, everyspatio-temporal term PT L S4u , (K, hw, xi) |= iff U(, w) x. time, however,instead U need inductive step .Case = 0 . (K, hw, xi) |= 0 iff exists immediate successor w0w (K, hw0 , xi) |= 0 iff, IH, immediate successor w0 wU( 0 , w0 ) x. remains recall U( 0 , w) = U( 0 , w0 ) whenever w0 immediatesuccessor w U( 0 , w) = whenever w immediate successor.remaining part proof (i).qProof Proposition 3.4. implication () follows immediately definition.() Suppose PT LS4u -formula satisfied tt-model FSA flowtime F = hW, <i. Then, Lemma B.1 (i), satisfiable Aleksandrov tt-model= hF, G, Vi FSA based quasi-order G = hV, Ri. view FSA,201fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevevery term , finitely many sets A1 , . . . , Ak V {V(, w) | wW } = {A1 , . . . , Ak }. Therefore, finitely many time points w1 , . . . , wm Wthat, every w W , wi , 1 m, V(, w) = V(, wi ) term .use Lemmon filtration (see, e.g., Chagrov & Zakharyaschev, 1997) constructtt-model based finite Aleksandrov topological space. First, define equivalencerelation V taking x(M, hwi , xi) |=iff(M, hwi , yi) |= ,i, 1 m, term .Denote [x] equivalence class x V . set V / pairwise distinct equivalenceclasses clearly finite. Define binary relation V / taking [x]S[y](M, hwi , yi) |=whenever (M, hwi , xi) |= I,i, 1 m, term .Clearly, well-defined, reflexive transitive, G0 = hV / , Si finite quasiorder. Let V0 (p, w) = {[x] | x V(p, w)}, every spatial variable p every w W .Consider tt-model M0 = hF, G0 , V0 i. First show term , x Vw W ,(M, hw, xi) |=iff(M0 , hw, [x]i) |= .basis induction follows definition V0 , cases intersection complement trivial, temporal operators follow IH.Suppose (M, hw, xi) |= [x]S[y]. moment wi(M, hw, zi) |= iff (M, hwi , zi) |= , term z V . definition S,(M, hwi , yi) |= , (M, hw, yi) |= . Finally, IH, (M0 , hw, [y]i) |= ,since arbitrary, obtain (M0 , hw, [x]i) |= .Conversely, let (M0 , hw, [x]i) |= xRy. [x]S[y], (M0 , hw, [y]i) |= ,which, IH, (M, hw, yi) |= . Thus, (M, hw, xi) |= .Finally, straightforward induction structure , one show(M, w) |=iff(M0 , w) |= ,sub w W . follows satisfied M0 .qB.1 Temporalisations S4uLemma B.2. Let finite set S4u -formulas. finite quasi-order Gevery satisfiable subset satisfied Aleksandrov model based G.Proof. every satisfiable , fix model based finite quasi-order G = hV , Rsatisfying . Let n = max{|V | : , satisfiable} let G disjointunion n full n-ary (transitive) trees depth n whose nodes clusters cardinalityn. difficult see every G p-morphic image G. Therefore, everysatisfiable satisfied Aleksandrov model based G.qProof Theorem 3.1. PSPACE-hardness follows Theorem 2.1 2.5. showmatching upper bound.Let PT L[S4u ]-formula. Since PT L S4u -formula, Lemma B.1 (ii),satisfiable tt-model iff satisfiable Aleksandrov tt-model based202fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityassociate fresh propositionalflow time. every (spatial) subformula 2variable p denote PT L-formula results replacingp .subformulas form 2claim satisfiable Aleksandrovtt-model flow time F = hW, <i iffexists temporal model N = hF, Ui satisfying and,| (N, w) |= p } {2| (N, w) |= p } spatialevery w W , set w = {2formulas satisfiable.implication () obvious. Conversely,suppose temporal model Nsatisfying conditions above. Let = wW w . Lemma B.2, finitequasi-order G that, every w W , hG, Vw |= w valuationVw . clear satisfied Aleksandrov tt-model hF, G, Vi,V(p, w) = Vw (p), every spatial variable p every w W .Now, devise decision procedure PT L[S4u ] uses polynomial spacelength input formula, one take corresponding nondeterministic PSPACEalgorithm PT L (Sistla & Clarke, 1985; Reynolds, 2004, 2003) modify follows.algorithm constructs pure temporal model N = hF, Ui every timeproduces state time instant w W , additionally checks whether set wspatial formulas satisfiable. Theorem 2.1, extra test also performedPSPACE algorithm, increase complexity combined algorithm. qProof Theorem 3.2. proof essentially Theorem 3.1,nondeterministic polynomial-time algorithms component logics available.qB.2 Undecidability PT L S4u PT L2 S4uNote although spatio-temporal languages contain propositional variables,p regarded proposition.still simulate them: spatial variable p, formula 2p, spatialThus, follows propositional variable p mean formula 2variable p (note different typefaces used denote propositional spatial variables).Proof Theorem 3.6. proof reduction undecidable Posts (1946) correspondence problem PCP, short. formulated follows. Given finite alphabetfinite set P pairs hv1 , u1 , . . . , hvk , uk nonempty finite wordsffffvi = bi1 , . . . , bili ,ui = ci1 , . . . , ciri(i = 1, . . . , k)A, instance PCP, decide whether exist N 1 sequence i1 , . . . ,indicesvi1 viN = ui1 uiN ,(14)concatenation operation. construct (using future-time temporaloperators) PT L S4u -formula A,P(i) length A,P polynomial function size P ;(ii) A,P satisfiable tt-model based hN, <i exist N 1sequence i1 , . . . , indices (14) holds;203fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev(iii) exist N 1 sequence i1 , . . . , indices (14) holdsA,P satisfiable tt-model FSA based hN, <i;(iv) A,P satisfiable tt-model based hN, <i iff A,P satisfiable tt-modelbased finite flow time.case hZ, <i follows immediately. Lemma B.1 (ii), suffices considerAleksandrov tt-models A,P .build A,P using spatial variables lefta righta (a A), left, right stripe,well propositional variables pairi , every pair hvi , ui i, 1 k, range.variable range required relativise temporal operators 2F 3F orderensure construct model based finite flow time. variable stripeused introduce new strict closure operator Aleksandrov spaces taking, everyspatio-temporal term ,= stripe @ C(stripe u C ) u stripe @ C(stripe u C ) .Denote Sn sequence n operators S. abbreviations need 1 2stands (1 @ 2 ) u (2 @ 1 ) 2+F replaces 2F .formula A,P defined conjunctionA,P = range stripe pair eq left right ,range = range 3F range 2F (range 2F range),_^3rangepair(pairpair),pair = 2+FjF1ik(stripe stripe) ,3F range 2^(left= 3F range2right),stripe =eq1i<jk2+FaAleft conjunction (15)(21), 1 k,^G+2+lefta ,F 3 lefta u leftb 2F 2 leftaAa6=ba,bA^(15)2+F pairi 2(lefta @ lefta ) ,(16)aAleft 2+ 22F (left @ Sleft),2+F2+F(17)(left @pairi 2,^((Sj left u Sj+1 left) @ left2pairibSli left)li jj<lileftpairi 3,(18)) ,(19)(20)((left u Sleft) @2F pairi 2204left) ,(21)fiCombining Spatial Temporal Logics: Expressiveness vs. Complexitybbbbyn4 b......bbb.........bbbyn3 +1 byn3 b......yn2 +1 byn2 b......yn1 +1 byn1 b.....li.1by1pairi10bb......bbbtrbli3bbtrli4trbbili4vi4. 4..brbi14brbili3. 3..vi3rbbrbi13rbbrbili2. 2....l.i2brbrbbrbi12trbrbrbbrbili1vi2. 1..vi1rbrbpairi21b = leftr = left= left u Sleftrbpairi32rangepairi43brbi114...Figure 7: Model satisfying left , N = 4.ileft = leftbi u leftbi u S(leftbi u u Sleftbi ) . . .123li(remember li length word vi ). conjunct right defined replacingleft occurrences left right, lefta righta (for A), li ri ileftiright , defined similarly. (Note pairi occurs left right .)Let us prove A,P required. Suppose (M, 0) |= A,P , Aleksandrovtt-model = hhN, <i , G, Vi G = hV, Ri. Since (M, 0) |= eq , find N ,1 N < ,^(left(M, N ) |= range2(22)righta ).aAview range , (M, j) |= range j, 0 j N . Let i1 , . . . ,sequence indices that, 1 j N , (M, j 1) |= pairij (pair ensuresunique sequence sort). claim (14) holds sequence.Since stripe holds 0, have, every V , (M, h0, yi) |= stripe iff(M, hj, yi) |= stripe j, 0 j N . Denote Rs transitive binary relationV defined taking xRs z V xRzRy (M, h0, xi) |= stripeholds iff (M, h0, zi) 6|= stripe. clearly that, every j, 0 j N , everyxV,(M, hj, xi) |=iffV xRs (M, hj, yi) |= .Call sequence hy1 , . . . , yl (not necessarily distinct) points V Rs -pathV(left, j) length l y1 , . . . , yl V(left, j) y1 Rs y2 Rs . . . Rs yl . every sequence205fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevz1 , . . . , zl points V(left, j) defineleftwordj (z1 , . . . , zl ) = ha1 , . . . , al ,ai (uniquely determined (15)) symbols (M, hj, zi i) |= leftai .show that, every j, 1 j N , following holds:ff(a) exists Rs -path y1 , . . . , ynj V(left, j) length nj = li1 + + lijleftwordj (y1 , . . . , ynj ) = vi1 . . . vij ;(b) every Rs -path V(left, j) length nj ;ff(c) every Rs -path y1 , . . . , ynj V(left, j),leftwordj (y1 , . . . , ynj ) = vi1 . . . vij .Indeed, j = 1, (a) (M, 0) |= pairi1 (20), (b) (17) (18),(c)(19).ff assume inductively (a)(c) hold j, 1 j < N . Lety1 , . . . , ynj maximal Rs -path V(left, j). First, (16), y1 , . . . , ynj V(left, j + 1).ffSecond, since (M, j, ynj ) |= left u Sleft (M, j) |= pairij+1 , (21) impliesffexist ynj +1 , . . . , ynj +lij+1 y1 , . . . , ynj +lij+1 Rs -path V(left, j + 1),required(a). (b)ff (c), observe first every Rs -path hy1 , . . . , ylV(left, j + 1), y1 , . . . , yllij+1 Rs -path V(left, j), (18). l nj+1 musthold. l = nj+1 leftwordj (y1 , . . . , yllij+1 ) = vi1 . . . vij induction hypothesis, leftwordj+1 (y1 , . . . , yllij+1 ) = vi1 . . . vij (16). hand,leftwordj+1 (yllij+1 +1 , . . . , yl ) = vij+1 (19), leftwordj+1 (y1 , . . . , yl ) =vi1 . . . vij vij+1 , required.repeat argument right side well. every sequencez1 , . . . , zl points V(right, j), definerightwordj (z1 , . . . , zl ) = ha1 , . . . , al ,ai uniquely determined elements (M, hj, zi i) |= rightai .have, every 1 j N :ff(a0 ) Rs -path y1 , . . . , ymj V(right, j) length mj = ri1 + + rijrightwordj (y1 , . . . , ymj ) = ui1 . . . uij ;(b0 ) every Rs -path V(right, j) length mj ;ff(c0 ) every Rs -path y1 , . . . , ymj V(right, j),rightwordj (y1 , . . . , ymj ) = ui1 . . . uij .206fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityNow, (15) (22), V(left, N ) = V(right, N ). (a), exists Rs path hy1 , . . . , yl V(left, N ) l = nN leftwordN (y1 , . . . , yl ) = vi1 . . . viN .(b0 ), nN mN . Similarly, using (a0 ) (b), obtain mN nN ,nN = mN . Hence, (c0 ), rightwordN (y1 , . . . , yl ) = ui1 . . . uiN . Since, (22),leftwordN (y1 , . . . , yl ) = rightwordN (y1 , . . . , yl ),finally obtain vi1 . . . viN = ui1 . . . uiN , required.Conversely, suppose N 1 sequence i1 , . . . , (14) holds.show A,P satisfiable Aleksandrov tt-model = hhN, <i , hN, , ViFSA. Let nj = li1 + + lij mj = ri1 + + rij every j, 1 j N .assumption, nN = mNvi1 . . . viN = ha1 , . . . , anN = ui1 . . . uiN .Define valuation V takingV(range, j) true iff 0 j N ,V(stripe, j) = {2m | < , 0 j N },V(pairi , j 1) true iff = ij 1 j N ,V(lefta , j) = {k | 1 k nj , ak = a} 1 j N ,V(righta , j) = {k | 1 k mj , ak = a} 1 j N ,V(righta , j).V(lefta , j) V(right, j) =V(left, j) =aAaAOne easily check valuation (M, 0) |= A,P satisfiesFSA. also readily seen A,P satisfiable tt-model based hN, <i iffsatisfiable tt-model based finite flow time.qProof Theorem 3.7. show modifying formulas proof Theorem 3.6. First, replace stripe+2+F 2(stripe @ 2F stripe) 2F 2(stripe @ 2F stripe).Then, left conjunction (150 )(210 ), 1 k,^G+2+lefta ,F 3 lefta u leftb 2F 2 leftaAa6=ba,bA^(150 )2+F pairi 2(lefta @ 2F lefta ) ,(160 )aAleft 2+ 22F (left @ Sleft),2+F2+F(170 )(left @ 3 Sli left) ,pairi 2F^(left u 2 left) @ 2 ((Sj left u Sj+1 left) @ leftpairi2FFbli jj<lileftpairi 2F 3,2F(180 )) ,(190 )(200 )left((left u Sleft) @ 2pairi 2F) ,207(210 )fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevileft defined exactly proof Theorem 3.6. Formula right modifiedsimilar way.qRemark B.3. fact, set PCP instances without solutions recursively enumerable therefore, proofs show sets PT L S4u PT L2 S4u formulas true models based hN, <i, hZ, <i finite flows timerecursively enumerable either. Therefore, logics recursively axiomatisable.Appendix C. Spatio-Temporal Logics Based RCappendix establish lower upper complexity bounds wide rangedecidable spatio-temporal combinations and, particular, prove Theorems 3.83.15.begin straightforward generalisation Lemma A.1 spatio-temporal case:Lemma C.1. (i) PT L RC-formula satisfiable tt-model FSA basedflow time F satisfiable Aleksandrov tt-model based F finitedisjoint union finite brooms.(ii) PT L RC-formula satisfiable tt-model based flow time Fsatisfiable Aleksandrov tt-model based F (possibly infinite) disjoint union-brooms.Proof. (i) Lemma B.1 (i), satisfiable Aleksandrov tt-model based Ffinite quasi-order G. rest proof similar Lemma A.1. detailsleft reader.(ii) Lemma B.1 (ii), satisfiable Aleksandrov tt-model based Fquasi-order G = hV, Ri. rest proof similar Lemma A.1.note although G infinite, still every x V V0xRy. guaranteed condition set Aw,x,> maximal point.qObserve Aleksandrov spaces essentially infinite case (ii) Lemma C.1generalisation Lemma A.2 go through. First, easily enforce topologicalspace infinite using PT L RCC-8 formula2+F NTTP(p, p).Moreover, formula( pp )3u p ) 2+F 2( p @2+F2p u p @ p u p u psatisfied Aleksandrov tt-model based single -broom, cannot satisfiedAleksandrov tt-model based union n-brooms finite n.hand, Aleksandrov tt-models based disjoint unions n-brooms,n bounded width formula, enough spatio-temporal logics basedRC . Recall spatial terms PT L RC (and PT L RC ) defined follows::= %| ,::= I%|::= 1 u u| 1 u 2 ,208| u| ,fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity% spatio-temporal Boolean region terms PT L BRCC-8 (and PT LBRCC-8, respectively). hard see that, every tt-model = hF, T, ViF = hW, <i, = hU, Ii every w W ,V(, w) = CIV(, w)V(, w) = ICV(, w),(23)i.e., always interpreted regular closed sets, whereas regular open ones.define width w() PT L RC -formula maximal number( u uconjuncts subformulas form 21), subformulas exist, putw() = 1 otherwise.Lemma C.2. (i) PT L RC -formula satisfiable tt-model FSAbased flow time F satisfiable Aleksandrov tt-model based Ffinite disjoint union w()-brooms.(ii) PT L RC -formula satisfiable tt-model based flow time Fsatisfiable Aleksandrov tt-model based F (possibly infinite) disjointunion w()-brooms.Proof. Lemma C.1, may assume satisfied Aleksandrov tt-model =hF, G, Vi, F = hW, <i G = hV, Ri disjoint union brooms (in (i), unionbrooms finite). Without loss generality may assume composed,...,3},7(using temporal operators Booleans) formulas set = {31nevery one following forms1 u u ,u,(24), defined above., fix point xevery 3every w W (M, w) |= 3,w V(M, hw, x,w i) |= . may assume x,w pairwise distinct.roots brooms points form x,w w W 3Therefore, G disjoint union brooms b,w , 3w W .Let us construct model M0 = hF, G0 , V0 follows. Given broom b,w , deleteleaves depending form . Three cases possible:Case = 1 u u : take leaves y1 , . . . , ym b,w (M, hw, yi i) |=x,w Ryi = 1, . . . , remove leaves different y1 , . . . , ym .Case = u : take leaf b,w (M, hw, yi) |= x,w Ry removeleaves. Note that, (23), (M, hw, yi) |= , therefore (M, hw, yi) |= .Case = : take leaf b,w x,w Ry remove leaves. (23),(M, hw, yi) |= .Denote b0,w resulting broom. Clearly, w()-broom. Let G0 = hV 0 , R00disjoint union b,w , 3w W . clear G0required. Finally, define V taking every spatial variable p, every w Wevery x V 0 ,x V0 (p, w)7. treatiffV 0 depth 0 xR0 V(p, w).abbreviation.primitive 23209fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev,show satisfied M0 , first prove that, w W 3(M0 , w) |= 3iff.(M, w) |= 3readily proved induction (M0 , hw, xi) |= iff (M, hw, xi) |= ,points x V 0 depth 0, w W spatio-temporal terms .Then, construction, also that, formulas 3w W ,0implies(M, w) |= 3 implies (M , w) |= 3 . remains show (M, w) |= 3003(M , w) |= 3w W . Suppose (M , hw, xi) |=. Consider three possible cases :(M, w) |= 3Case = 1 u u . Then, every i, 1 m, yi V 0 depth 0xR0 yi (M0 , hw, yi i) |= . (M, hw, yi i) |= and, (23), (M, hw, xi) |= ..Therefore, (M, hw, xi) |= , contrary (M, w) |= 30Case = u . V depth 0 xR0 y, (M0 , hw, yi) |= and,(23), (M0 , hw, yi) |= . Thus (M0 , hw, yi) |= . (M, hw, yi) |= , contrary.(M, w) |= 3Case = . V 0 depth 0 xR0 and, (23), (M0 , hw, yi) |= ..(M, hw, yi) |= , contrary (M, w) |= 3Now, straightforward induction easily show that, w Wformulas built using temporal operators Booleans,(M0 , w) |=iff(M, w) |= .follows satisfied M0 .qC.1 Lower Complexity Bounds (I)Proof Theorem 3.10, lower bound. proof reduction arbitrary problem 2EXPSPACE satisfiability problem PT L RC. Let (single-tape,deterministic) Turing machine halts every input (accepting rejecting it),f (n)uses 22cells tape input length n, polynomial f . GivenTuring machine input x it, construct PT L RC-formulaA,x (using future-time temporal operators)(i) length A,x polynomial size x;(ii) A,x satisfiable tt-model based hN, <i accepts x;(iii) accepts x A,x satisfiable tt-model FSA based hN, <i.case hZ, <i flow time (with without FSA) follows immediately. casefinite flows time proved relativising temporal operators A,x (say,propositional variable range proof Theorem 3.6 Appendix B.2proof lower bound Theorem 3.9 below): obtain formula 0A,x0A,x satisfiable Aleksandrov tt-model based hN, <i iff satisfiableAleksandrov tt-model based quasi-order finite flow time.way lower bound results theorem follow.210fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityGiven Turing machine A, polynomial f , input x = hx1 , . . . , xn above, let= f (n),exp(1, d) = 2d exp(2, d) = exp(1, d) 2exp(1,d) .22f (n)exp(2, d).(25)plan follows. First, show yardsticks length exp(2, d) (similarused Stockmeyer, 1974 Halpern Vardi, 1989) encoded PT L RCformulas length polynomial d. yardsticks used define temporaloperator exp(2,d) . Then, using operator, encode computationinput x.Lemma C.1 (ii), PT LRC-formula A,x satisfied tt-model based flowtime hN, <i, satisfied Aleksandrov tt-model = hhN, <i , G, Ui,G = hV, Ri disjoint union -brooms. Take model supposePT L RC-formula8aux(26)2+F 2 auxtrue moment 0. Since region aux change time, dividepointsV three disjoint sets: external, boundary internal points respectaux i.e., satisfyingep(aux) = aux ,bp(aux) = aux u auxaux ,respectively. Note every boundary point non-boundary R-successor, boundarypoints depth 1. followssimply speak external boundarypoints mentioning respect aux .define exp(2,d) operator PT L RC-formula length polynomialfollows:(a) First, encode yardsticks length d. use different formulas yardsticksexternal points yardsticks boundary points.(b) Then, help d-yardsticks, encode yardsticks length exp(1, d).use different formulas external boundary points.(c) Next, help exp(1, d)-yardsticks boundary external points,encode yardsticks length exp(2, d) boundary points.(d) Finally, help exp(2, d)-yardsticks boundary points, define polynomial-length exp(2,d) operator applicable propositional variables.Step (a). Suppose (26) following formula hold 0:+ext2+F 2 bp(aux) @ 0,d 2F 2 ep(aux) @ 0,d0,d =(27)ld1j delim0,delim0 delim0 udelim0 @j=18. Recall 1 2 stands (1 @ 2 ) u (2 @ 1 ). assume u bind stronger .211fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevext results0,d0,d replacing occurrence delim0 ext delim0 .Take boundary point z. Suppose v N (M, hv, xi) |= delim0 .0,d , every time moment w v,(M, hw, zi) |= delim0iffw v (mod d),is, z, delim0 holds ineverytime instants, starting v.By secondconjunct (27), external points aux behave similarly respect ext delim0 .Step (b). encode yardsticks length exp(1, d), recall first every number < 2drepresented binary asequencea0 . . . ad1 bits. mark bitsbinary numbers region term bit1follows. Given boundary point z timemoment v (M, hv, zi) |= delim0 , say interval [w, w + 1],w = v + j d, j N, encodes number < 2d z, every < d,(M, hw + i, zi) |= bit1iffai = 1.Recall binary representation b0 . . . bd1 successor a0 . . . ad1 modulofollowing holds: i, 0 < d, ai = bi iff aj = 0, j, < juse d-intervals starting v encode < 2d numbers wayconsecutive intervals encode consecutive (modulo 2d ) numbers, starting 0.So, suppose (26), (27) following formula hold 0:extext2+2+F 2 ep(aux) @ 1,d u 1,d ,F 2 bp(aux) @ 1,d u 1,d2d< d.(28)1,d=1,d=lwr1 delim0 bit1 u lwr1uzr1 bit1 u delim0 zr1u delim1 delim0 u zr1 ,lwr1bit1 bit1 ,ext ext result1,d1,d 1,d , respectively, attaching prefix ext1,dspatial variables (save aux).Take boundary point z. Suppose v N(M, hv, zi) |= delim1 .Then, last conjunct 1,d , (M, hv, zi) |= delim0 . Since, (a), delim0holds every time instants z, delim0 marks starting momentd-interval. Then, first conjunct 1,d , every i, 0 < d, have9(M, hv + i, zi) |= lwr1iff(M, hv + j, zi) |= bit1 , j, < j < d.Therefore, 1,d says consecutive < 2d numbers (starting 0) encoded consecutive d-intervals (starting v). Similarly first conjunct 1,d , second conjunctensures that, every i, 0 < d,(M, hv + i, zi) |= zr1iff(M, hv + j, zi) |= bit1 , j, j < d.9. Sinceapply U operatorcannotformspatio-temporalterms,auxiliary regionsused instead:lwr1 delim0 bit1 u lwr1 ensures lwr1 behaves bit1 U delim0 .equality term indeed regarded fixed point characterisation U operator.Notealsoneed require (as fixed point characterisation) lwr1 @ 3F delim0true eventuality already enforced 0,d .212fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexitySo, last conjunct 1,d , delim1 holds z every exp(1, d) = 2d timeinstants, startingv.second conjunct (28), external points behave similarlyrespect ext delim1 .Step (c). construct yardsticks length exp(2, d), using exp(1, d)-yardsticksconstructed (b). Suppose (26)(28) following formulas hold 0:2+F 2 bp(aux) @ext delim12+@ (ep(aux) bp(aux)) ,F 2 ext delim12+F 2 ep(aux) @ 1,d (bit2 ) ,2+F 2 bp(aux) @ 2,d u 2,d ,(29)(30)(31)2,d defined similarly 1,d1,d (bit2 )=jm1 bit2delim1 u bit2ext delim1 u jm1 bit2 ,=bit2 bit2u lwr2bit2 J1,d bit2 ,= (aux u ext delim1 ) @ jm1 bit2 .ext2,dJ1,d bit2Take boundary point z. Suppose v time moment (M, hv, zi) |= delim2 .Then, last conjunct 2,d , (M, hv, zi) |= delim1 . know (b) delim1holds z every exp(1, d) time instants starting v. So, 2,d firstconjunct 2,d intend express consecutive < 2exp(1,d) numbers (starting0) encoded consecutiveexp(1, d)-intervals starting v. could then,last conjunct 2,d , delim2 would hold z every exp(2, d) time instantsstarting v. problem (andstep (b)) markdifferenceexp(1,d)bits < 2binary numbers term bit2 , need show (polynomiallength) term J1,d bit2 actually defines exp(1,d) bit2 sense that, every w v,(M, hw, zi) |= J1,d bit2ff(M, w + exp(1, d), z ) |= bit2 .iff(32)Suppose first (M, hw, zi) |= J1,d bit2 . Then,(29),ywexternal R-successorz (of depth 0) (M, hw, yw i) |= ext delim1 , (M, hw, yw i) |= jm1 bit2 .hand, hard see (M, hw, zi) 6|= J1,d bit2 ,00external R-successor yw z (of depth 0) (M, hw, yw i) |= ext delim10 i) |= jm bit .(M, hw, yw21cases, readily checked (M, hw, yi) |= ext delim1 , externalpoint y, then, (30),(M, hw, yi) |= jm1 bit2ff(M, w + exp(1, d), ) |= bit2 .iff(32) follows first conjunct 2,d .Step (d). position define polynomial-length exp(2,d) operator J2,dapplicable propositional variables. Recall propositional variable p stands spatialp, p spatial variable associated p. Now, every propositionalformula 2213fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevvariable p intend apply new operator to, introduce fresh spatial variablejm2 p. Suppose (26)(31) following formulas hold 0:2+F 3 bp(aux) u delim2 ,2+2+F 2 p 2 pF 2 2,d (p),(33)(34)2,d (p) obtained replacing bit2 , jm1 bit2 ext delim1 1,d (bit2 ) p,jm2 p delim2 , respectively. Let(bp(aux) udelim2 ) @ jm2 p .J2,d p = 2claim that, every time moment w every propositional variable p,(M, w) |= J2,d p(M, w + exp(2, d)) |= p.iff(35)Suppose first (M,point zw) |= J2,d p. Then, (33), boundary(M, hw, zi) |= delim2 , therefore (M, hw, zi) |= jm2 p . hand,(M, w) 6|= J2,d p, boundary point z 0 (M, hw, z 0 i) |= delim2(M, hw, z 0 i) |= jm2 p . cases, readily checked (M, hw, zi) |= delim2 ,boundary point z, then, second conjunct (34),(M, hw, zi) |= jm2 pff(M, w + exp(2, d), z ) |= p .iff(35) follows first conjunct (34).Finally, position define PT L RC-formula A,x encodescomputation Turing machine input x. Let tape alphabet (with blanksymbol b A) set states (with two halt states syes sno S) A. usesymbol/ mark left end tape. know space usedf (n)input x = hx1 , . . . , xn 22 , exp(2, d) (25). representconfiguration computation x finite wordh, a1 , . . . , ai1 , hs, ai , ai+1 , . . . , , b, . . . , bilength exp(2, d), a1 , . . . , hs, ai represents current stateactive cell. transition function takes triples form hai , hs, aj , ak(for ai {}, aj , ak A, {syes , sno }) similar triples. instance,(ai , hs, aj , ak ) = hai , aj , hs0 , ak iimeans that, state reading symbol aj , new state s0head move one cell right. also assume that, ai {}aj , ak A, (ai , hsyes , aj , ak ) = hai , aj , ak (ai , hsno , aj , ak ) = hai , aj , akmeaning head removed halted.Now, every {} (S A), introduce fresh propositional variable p .Let A,x conjunction (26)(31), (33) instance (34), p , well214fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity'$ 'exp(1, d) many l0jexp(1,d)l0ccrcccH1*HH@6@ep(aux)auxHH@r0 - rdbp(aux)&...jexp(1, d) many lexp(2,d)1exp(1,d)lexp(2,d)1crccccH1*HH@6@ep(aux)auxHH@ rd-rexp(2,d)1% &|$bp(aux){zexp(2, d) many (exp(1, d) + 1)-brooms%}Figure 8: Structure yardsticks.following formulas:^2+F p p ,(36),A{}SA6=p (phs0 ,x1 (px2 ( (pxn pb U p ) ))),2+Fafhead_phs,ai ,(37)(38)hs,aiSA^2+Fafhead p J2,d p0 p J2,d p 0 p J2,d p 0 , (39)(,,)=h0 , 0 , 02+F^afhead af head af head pa J2,d pa ,(40)aA{}3F_phsyes ,ai 3FaA_phsno ,ai .(41)aASuppose first A,x holds time moment 0. (36)(40) (35), consecutiveconfigurations computation input x properly encoded along timeaxis. (For instance, p holds every exp(2, d) time moments.) Finally, (41) saysaccepts input x.Conversely, suppose accepts input x. define Aleksandrov tt-model= hhN, <i , G, Ui FSA satisfies A,x . Let partial order G = hV, Ridisjoint union exp(2, d) many (exp(1, d) + 1)-brooms (see Fig. 8):V = {ri | < exp(2, d)} {lij | < exp(2, d), j exp(1, d)},zRyiffz=yz = ri , = lij , i, j.Suppose number steps computation x m.prefix length N = exp(2, d) final configuration (without haltingstate) repeats infinity. w N, letexp(1,d)U(w, aux) = {li215| < exp(2, d)}.fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyascheveasy see boundary points ri , external pointslij , < exp(1, d). put, every w N,U(w, delim2 ) = {liexp(1,d)|iw(mod exp(2, d))},exp(1,d)U(w, delim1 ) = {liexp(1,d)U(w, delim0 ) = {liU(w, ext delim1 ) = {liv |U(w, ext delim0 ) = {liv ||iw(mod exp(1, d))},|iw(mod d)},vw(mod exp(1, d)), < exp(2, d)},vw(mod d), < exp(2, d)}.valuations variables clear.exp(1,d)(M, hw, zi) |= delim2iff z = ri z = liw (mod exp(2, d)),exp(1,d)(M, hw, zi) |= delim1iff z = ri z = liw (mod exp(1, d)),v(M, hw, zi) |= ext delim1iff z = ri z = li v w (mod exp(2, d))< exp(2, d),on, required. hard see satisfies FSA (M, 0) |= A,x .qProof Theorem 3.9, lower bound. proof reduction 2n -corridor tilingproblem known EXPSPACE-complete (Chlebus, 1986; van Emde Boas, 1997).problem formulated follows: given instance = hT, t0 , t1 , ni,finite set tile types, t0 , t1 n > 0, decide whether Ntiles 2n -grid (or corridor) way t0 placed onto h0, 0i, t1 ontohm 1, 0i, top bottom sides corridor fixed colour, say, white.Suppose = hT, t0 , t1 , ni given. aim construct (using future-timetemporal operators) PT L BRCC-8 formula(i) length polynomial function |T | n;(ii) satisfiable tt-model based hN, <i N tiles2n -corridor;(iii) N tiles 2n -corridor, satisfiablett-model FSA based hN, <i;(iv) satisfiable tt-model based hN, <i iff satisfiable tt-model basedfinite flow time.case hZ, <i follows immediately.Recall that, Lemma C.2 (ii), satisfied tt-model satisfiedAleksandrov tt-model = hhN, <i , G, Vi, G = hV, Ri disjoint union brooms. explain meaning subformulas, assume modelgiven. Throughout proof use restricted subset RCC-8 predicates: spatiotemporal terms 1 2 constructed spatial variables using complement,intersection next-time operator , need EQ(1 , 2 ) well two abbreviationsP(1 , 2 ) = EQ(1 , 2 ) TPP(1 , 2 ) NTPP(1 , 2 ) E 1 = DC(1 , 1 ) standing 1216fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity2n0(m + 1) 2ncountrange0011223430561273890110211312013114215316...0Figure 9: Counting formulas = 3 n = 2.part 2 1 nonempty, respectively. Clearly, language forms subsetPT L BRCC-8 (in fact, show Remark C.3 below, proof goeseven restricted subset langauge).first step construction (which contain, among many others, spatialvariables ) write formulas forcing sequence y0 , y1 , . . . , ym2n 1distinct points (of depth 0) V , N, that, < 2n ,(M, hi, yi i) |= unique tile type . = k 2n + j, k < m, j < 2n ,use yi (at time i) encode pair hk, ji 2n -grid. Thus,neighbour hk, j + 1i hk, ji coded point yi+1 time + 1, rightneighbour hk + 1, ji yi+2n moment + 2n (see Fig. 10).Let q0 , . . . , qn1 pairwise distinct propositional variablesn1j = qd00 qn1,dn1 . . . d0 binary representation j < 2n , q0i = qi q1i = qi , i.Suppose formula+count 0 count U (0 2+(42)F count) 2F counttrue 0, count fresh propositional variable followingcounting formula (the length polynomial n)^^ ^^qi qk=qi qk(qi qi )2n 1 0 .k<ni<ki<kk<i<nN count true moment (m + 1) 2n false starting(m+1)2n . sequence 0 , 1 , . . . , 2n 1 repeated m+1 times along time-line,i.e., count true. Letrange = 3F (count 0 ).Clearly, range true moment 2n always false (see Fig. 9).Let equ, p0 , . . . , pn1 e0 , . . . , en1 fresh distinct spatial variables,n1j = pd00 u u pn1,dn1 . . . d0 binary representation j < 2n , p0i = pi p1i = pi , i.Suppose (42)l^^+2+e22+EQequ,qEQ(e,p)(43)FFF EQ pi , pii<ni<ni<n217fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevtrue 0. Then, first two conjuncts (43), N Vdepth 0, j < 2n (M, hi, yi) |= equ iff (M, i) |= j (M, hi, yi) |= j .last conjunct (43),(M, hi, yi) |= equ iff j < 2n (M, i) |= j (M, hk, yi) |= j , k N . ()generate required sequence points yi using formulas:range 2+(range E tile),FG l2+EQtile,equuufuture,FtT^2+F P future,(44)(45)tTu future ,(46)tTtile future (for ) fresh spatial variables. Indeed, supposeconjunction (42)(46) holds time 0 M. Then, first conjunct (44)(42), (M, 0) |= range 0 and, second conjunct (44), (M, h0, y0 i) |= tiley0 V . may assume y0 depth 0. Then, (45),(a0 ) (M, h0, y0 i) |= equ, and, (), (M, hk, y0 i) |= 0 k N;(b0 ) , (M, h0, y0 i) |= future and, (46), (M, hk, y0 i) |= k > 0.Next, (42), (M, 1) |= range 1 and, (44), y1 V (again, depth0) (M, h1, y1 i) |= tile. particular, have:(a1 ) (M, h1, y1 i) |= equ, and, (), (M, hk, y1 i) |= 1 k N;(b1 ) , (M, h1, y1 i) |= future and, (46), (M, hk, y1 i) |= k > 1.(b0 ), (M, h1, y0 i) |= t, , thus y1 6= y0 . consider y1 moment 1use argument find point y2 V (which different y1 (b1 )),forth; see Fig. 10. gives us points y0 , y1 , . . . , ym2n 1 (of depth 0) V need.next aim write formulas could serve pointers rightneighbours given pair corridor (at moment bother topborder). Consider formulastile ,2+(47)F EQ up,+2F EQ right, equ u equ U tile ,(48)+2F EQ equ U tile, tile equ u equ U tile ,(49)up, right equ U tile fresh spatial variables.i, j < 2n ,(M, hi, yj i) |=(M, hi, yj i) |= rightiffj = + 1;iffj = + 2n .218claim that,fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityb =q q= equ UrangeV3y11qqqequqqqq2y10qqequqqqq1y9qequqqqq0qy8 equqqq3y7qqqequqrightequqrightequqrightequqrightequqright2y6qqequqright1y5q0y4equqright3y3qq2y2qq1y1q0ry0 equtile00qequrtileqqqqqqequqrightrq equbtilerqqq equbbtilerqq equbbbtilerq equbbb equbtileequrbbb equbbtilebbb equbbbqqbbequbbbbequbbbbequb1234567891011126right6rqqq equtilerqqq equbbb equbbbbtileqq equbbb equbbbb equbrtilerq equbbb equbbbb equbbtileequrbbb equbbbb equbbbtilebbb equbbbb equbbbbb12301230tTtile1236 66c- right... |{z}3 22 corridor0Figure 10: Satisfying , n = 2, tt-model based space 3 22 points.former obvious. Let us prove latter. show (M, hi, yj i) |= right,j = + 2n , first observe (M, hj, yj i) |= equ (M, hi, yj i) |= equ (). follows(M, hj, yj i) |= tile (49) (M, hj 1, yj i) |= equ U tile. Then, applying(49) (from right left) sufficiently many times, obtain (M, hi, yj i) |= equ U tile,(M, hi 1, yj i) 6|= equ U tile, (M, hi, yj i) |= right.Conversely, suppose (M, hi, yj i) |= right yj . (M, hi, yj i) |= equ and,() (note + 2n < (m + 1) 2n , count still true + 2n ),(M, hi + 2n , yj i) |= equ.()(M, hi, yj i) |= equ U tile. applying (49) (from left right) sufficientlymany times arrive (M, hi + 2n 1, yj i) |= equ U tile together ()gives (M, hi + 2n , yj i) |= tile. j = + 2n .noted every time point extension equ U tile coincidesextension term equ U tile elements sequence y0 , . . . , ym2n , (49)indeed fixed point characterisation U operator.Finally, formulas ensure every point 2n -corridor coveredone tile, h0, 0i covered t0 , hm 1, 0i t1 , top bottom sides white219fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevcolours adjacent edges adjacent tiles match:^02+F E (t u ),(50)t,t0t6=t0P(tile, t0 ) 2+range3rangePtile,,001FF_n2+P tile, ,F 2 1(51)(52)tTup(t)=white_2+Ptile,,0F(53)tTdown(t)=white^0nfuture,2+EPup,2 1F(54)t,t0up(t)6=down(t0 )^0.EPright,future2+F(55)t,t0right(t)6=left(t0 )Let conjunction (42)(55). Suppose holds 0 M.N (M, 2n 1) |= range and, every 2n , (M, i) |= range.define map : 2n taking(k, j) =iff(M, hi, yi i) |= = k 2n + j.leave reader check tiling 2n , required.direction, suppose tiling 2n -corridor ,> 0. satisfied Aleksandrov tt-model = hhN, <i , hV, Ri , Vi,V = {y0 , . . . , ym2n 1 }, R minimal reflexive relation V ,V(t, i) = {yi V | (k, j) = = k 2n + j},variables interpreted shown Fig. 10. Clearly, satisfiesFSA. Moreover, satisfiable tt-models finite flows time iff satisfiablett-models hN, <i. Details left reader.qRemark C.3. may interest note language used proofrather limited. fact, enough extend PSPACE-complete logic PT L RCC-8predicates form EQ(%1 , %2 %3 ) (where %i atomic spatio-temporal regionterms) make EXPSPACE-hard. show this, transform PT LBRCC-8 formulaconstructed following way. First, take fresh spatial variable u (denotinguniverse) add conjunct 2+F EQ(u, u). Next, every spatio-temporalBoolean region term % , introduce spatial variable neg % (the complement %+respect u), add conjuncts 2+F EQ(u, % neg %) 2F DC(%, neg %), replaceevery occurrence % resulting formula neg %. Finally, every spatio-temporalterm form %1 u %2 , introduce fresh spatial variable %1 %2 , add conjuncts++2+F P(%1 %2 , %1 ) 2F P(%1 %2 , %2 ) 2F P(%1 , neg %2 %1 %2 )220fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityreplace occurrences %1 u %2 %1 %2 . One readily see (i) lengthresulting formula 0T linear length (ii) 0T satisfiable tt-modelbased hN, <i (with FSA) iff satisfiable tt-model based hN, <i (with FSA).C.2 Upper Complexity Bounds (I): Quasimodels PT L RCappendix define quasimodels PT L RC spirit paper (Hodkinsonet al., 2000) order establish upper complexity bounds Theorems 3.10 3.13.remind reader spatio-temporal terms PT L RC form:| I%::= %%::= CIp|| CI%| 1 u 2 ,| CI(%1 u %2 ) | CI(%1 U %2 ) | CI(%1 %2 ),PT L RC forms sublanguage PT L RCit differs latterdefinition spatio-temporal region terms:%::=CIp| CI%| CI(%1 u %2 ) | CI %.Let PT L RC-formula. Recall p. 200 sub denote setsubformulas term set spatio-temporal terms includingform %. type subset termevery 1 u 2 term ,every term ,1 u 2iffiff1 2 t;/ t.Clearly, number [() different types bounded 2|term | .broom type b pair hhT, , ti, hT, broom (with 0leaves) labelling function associating x type t(x)following conditions hold:(bt0) t(x) 6= t(y), pair distinct points x, 0 ;(bt1) every x 0 ,every CI(%1 u%2 ) term , CI(%1 u%2 ) t(x) iff %1 t(x) %2 t(x),every CI% term , CI% t(x) iff %/ t(x);(bt2) every I% term ,(bt3) every % term ,I% t(x)% t(x)iffiff% t(y) every , x y;0 x % t(y).Broom types b1 = hhT1 , 1 , t1 b2 = hhT2 , 2 , t2 said isomorphicevery x1 T10 , x2 T20 t1 (x1 ) = t2 (x2 )every x2 T20 , x1 T10 t1 (x1 ) = t2 (x2 ).Clearly, given two isomorphic broom types b1 b2 , also t1 (r1 ) = t2 (r2 ),r1 r2 roots b1 b2 , respectively.quasistate pair hs, mi, Boolean-saturated subset subdisjoint union hhT, , ti broom types b1 , . . . , bn following conditionshold:221fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev(qs0) bi bj isomorphic, 6= j;sub ,(qs1) every 22ifft(x) every x .[()Clearly, number ]() quasistates bounded 222|sub | .Fix flow time F = hW, <i. basic structure pair hF, qi, qfunction associating w W quasistate q(w) = hsw , mw that,w W ,every 1 U 2 sub , 1 U 2 sw iff v > w 2 sv1 su u (w, v);every 1 2 sub , 1 2 sw iff v < w 2 sv1 su u (v, w).Let hF, qi basic structure , q(w) = hsw , mw mw = hhTw , w , tww W . Denote Tw0 set leaves hTw , w Tw1 set rootsbrooms it. 1-run hF, qi function r giving w W pointr(w) Tw1 ; coherent saturated 0-run hF, qi function r givingw W point r(w) Tw0 following conditions hold:every CI(%1 U %2 ) term , CI(%1 U %2 ) tw (r(w)) iff v > w%2 tv (r(v)) %1 tu (r(u)) u (w, v);every CI(%1 %2 ) term , CI(%1 %2 ) tw (r(w)) iff v < w%2 tv (r(v)) %1 tu (r(u)) u (v, w).Say quadruple Q = hF, q, R, Ci quasimodel based F hF, qi basicstructure , R = R0 R1 , R1 set 1-runs R0 set coherentsaturated 0-runs hF, qi, C reflexive closure subset R1 R0(qm2) w0 W sw0 ;(qm3) every w W every x Tw , r R r(w) = x;(qm4) r, r0 R, r C r0 r(w) w r0 (w) w W ;(qm5) r R, w W x Tw0 , r(w) w x r0 R0r0 (w) = x r C r0 .quasimodel Q said finitary set R runs finite.Lemma C.4. PT L RC-formula satisfiable Aleksandrov tt-model basedflow time F (finite) disjoint union (finite) brooms iff (finitary)quasimodel based F.Proof. () Let PT L RC-formula Q = hF, q, R, Ci quasimodel ,F = hW, <i q(w) = hsw , hhTw , w , tw ii w W . construct Aleksandrovtt-model = hF, G, Vi taking G = hR, Ci and, spatial variable p w W ,V(p, w) = {r | CIp tw (r(w))}.222fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityClearly, Q finitary G finite. Thus, remains prove satisfied M.First, show induction construction region term % term that,every w W every r R,(M, hw, ri) |= %iff% tw (r(w)).(56)basis induction: % = CIp. Let (M, hw, ri) |= %. r0 Rr C r0 (M, hw, r0 i) |= Ip. (qm4), r(w) w r0 (w). Take Tw0 , r0 (w) w y.(qm5), run r00 R0 r0 C r00 r00 (w) = y. (M, hw, r00 i) |= pand, definition V, CIp tw (r00 (w)) and, (bt3), % tw (r(w)).Conversely, % tw (r(w)) then, (bt3), Tw0 r(w) w% tw (y). (qm5), r00 R0 , r C r00 , r00 (w) = y. CIp tw (r00 (w))and, definition V, (M, hw, r00 i) |= p. Therefore, (M, hw, ri) |= %.induction steps % = CI%1 , CI(%1 u %2 ), CI(%1 U %2 ) CI(%1 %2 ) similar,instead definition V, use (bt1) cases Booleans coherencesaturatedness r00 cases temporal operators.Next, extend (56) arbitrary spatio-temporal terms term .Case = I%. Suppose (M, hw, ri) |= I%. Take Tw , r(w) w y. Tw0then, (qm5), r0 R0 r C r0 r0 (w) = y./ Tw0 clearly= r(w) take r0 = r. (M, hw, r0 i) |= %, which, IH, implies % tw (r0 (w)).Therefore, % tw (y) every w r(w) and, (bt2), I% tw (r(w)).Conversely, I% tw (r(w)) then, (bt2), % tw (y), every w r(w). Takerun r0 R r C r0 . (qm4), r(w) w r0 (w), % tw (r0 (w)), which,IH, (M, hw, r0 i) |= %. Hence, (M, hw, ri) |= I%.Cases = 1 u 2 1 follow IH definition type.Finally, show induction construction sub that, every w W ,(M, w) |=iffsw .(57). Suppose (M, w) |= 2. Take x . (qm3), r RCase = 2wr(w) = x. (M, hw, ri) |= and, IH, tw (r(w)). Therefore, (qs1),. Conversely, let 2. Take run r R. (qs1), (r(w)),2www.which, IH, (M, hw, ri) |= . Hence, (M, w) |= 2Cases = 1 2 1 follow IH Boolean-saturatedness sw .follows (57) (qm2) satisfiable M.() Let PT L RC-formula suppose satisfied Aleksandrovtt-model = hF, G, Vi, F = hW, <i G = h, disjoint union brooms.Denote 0 1 leaves roots brooms G, respectively. everypair hw, xi W associate typet(w, x) = { term | (M, hw, xi) |= }.Fix w W define binary relation follows. x, x0 0 , let x w x0 ifft(w, x) = t(w, x0 ) and, z, z 0 1 , let z w z 0 iff brooms generated z z 0isomorphic, i.e.,x 0 (z x x0 0 (z 0 x0 x w x0 ))x0 0 (z 0 x0 x 0 (z x x w x0 )).223fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevClearly, w equivalence relation . Denote [x]w w -equivalence class xdefine map fw taking, x ,([x]w ,x 1 ,fw (x) =h[z]w , [x]w , x 0 z 1 z x.Since G disjoint union brooms, fw well-defined. putTw = {fw (x) | x },u w viffx,tw (fw (x)) = t(w, x),x y, u = fw (x) v = fw (y),x .definition fw , hTw , w union brooms tw well-defined. Considerstructure hsw , mw i,mw = hhTw , w , twsw = { sub | (M, w) |= }.readily seen brooms mw (bt0) mw satisfies(qs0). Moreover, fw p-morphism h, onto hTw , w i, also (bt1)(bt3) (qs1). So, taking q(w) = hsw , mw w W obtain basic structurehF, qi satisfying (qm2).remains define appropriate runs hF, qi. k = 0, 1, let Rk setmaps r : w 7 fw (x) x k . Clearly, R1 R0 sets 1- coherentsaturated 0-runs, respectively. Put R = R0 R1 r, r0 R, r C r0 iff r(w) w r0 (w)w W . (qm4) holds definition. Let v W Tv .x fv (x) = y. Clearly, R contains run r : w 7 fw (x), proves(qm3). Finally, let r R, v W Tv0 r(v) v y.z, x fw (z) = r(w), every w W , fv (x) = y. clearly z xx 0 . take run r0 : w 7 fw (x). definition, r C r0 , proves (qm5).Thus, Q = hF, q, R, Ci quasimodel . Note G finite R finitewell therefore, Q finitary.qposition establish upper complexity bounds satisfiabilityproblem PT L RC- PT L RC-formulas tt-models based hN, <i, hZ, <iarbitrary finite flows time.Proof Theorem 3.10, upper bound. consider cases hN, <i hZ, <i.case arbitrary finite flows time tt-models FSA basedhN, <i hZ, <i follow Theorem 3.13.One readily check propositional temporal logic PT L,following polynomial reductions PT L RC:satisfiability tt-models based hZ, <i polynomially reduced satisfiabilitytt-models based hN, <i;satisfiability tt-models based hN, <i polynomially reduced satisfiabilityformulas without past-time temporal operators.224fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexitySo, follows consider simplest case satisfiability problem,PT L RC-formulas without past-time temporal operators tt-models based hN, <i.present nondeterministic 2EXPSPACE satisfiability checking algorithmsimilar Sistla Clarke (1985). First, one prove (with help Lemmas C.1 (ii) C.4) analogue (Hodkinson et al., 2000, Theorem 24) statesPT L RC-formula satisfiable tt-model based hN, <i iff l1 , l2 N2l1 ](),0 < l2 |term | 2[() ]() + ]()balloon-like quasimodel Q = hhN, <i , q, R, Ci q(l1 + n) = q(l1 + l2 + n)every n N. Although Theorem 24 (Hodkinson et al., 2000) provedmonodic fragment first-order temporal logic, basic idea extracting balloon-likequasimodel arbitrary one works PT L RC well. differencequasistates complex: regarded sets sets types (notsets types) thus, l1 l2 triple exponential length `() .quasimodel Q guessed 2EXPSPACE algorithm similarproof (Hodkinson et al., 2003, Theorem 4.1).qProof Theorem 3.13, upper bound. proof similar Theorem 3.10.Again, one show cases polynomially reducible case satisfiabilityPT L RC-formulas without past-time temporal operators tt-models FSAbased hN, <i. take FSA account, prove (using Lemmas C.1 (i)C.4) analogues Theorems 29 35 (Hodkinson et al., 2000) statePT L RC-formula satisfiable tt-model FSA based hN, <i ifffinitary balloon-like quasimodel based hN, <i. condition finitenessset runs also ensured algorithm similar Theorem 3.10.qC.3 Upper Complexity Bounds (II):Embedding First-Order Temporal Logicappendix introduce first-order temporal language QT L use knowncomplexity results fragments QT L obtain upper complexity bounds spatiotemporal logics based RC (and therefore, BRCC-8).alphabet QT L consists individual variables x1 , x2 , . . . , predicate symbolsP1 , P2 , . . . , fixed arity, Booleans, universal x existential x quantifiers variable x, temporal operators U, (withderivatives , 3F , 2F , etc.). Note language contains neither constant symbolsequality (we simply need obtain complexity results).QT L interpreted first-order temporal models form = hF, D, Ii,F = hW, <i flow time, nonempty set, domain M, functionassociating every moment time w W first-order structureEI(w)I(w)I(w) = D, P0 , P1 , . . . ,I(w)state moment w, Pirelation arity Pi .assignment function set individual variables D. Givenassignment QT L-formula , define truth-relation (M, w) |=a taking225fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevu = CIpx1bdepth 0depth 1e = CIp'xn1bx2b$xnbueeu...*YHH@H @HH@ uHb=Pj1 [db ]Pj2 [db ] . . .Pjn1 [db ]Pjn [db ]&%x0bdbFigure 11: Representing n-broom b region CIpj point first-order model.I(w)(M, w) |=a Pi (x1 , . . . , xm ) iff ha(x1 ), . . . , a(xm )i Pi,0(M, w) |=a x iff (M, w) |=a , every assignment a0 differx,plus standard clauses Booleans temporal operators. say QT Lformula satisfied (M, w) |=a w W assignment D.free variables among x1 , . . . , xm , instead (M, w) |=a often write(M, w) |= [d1 , . . . , dm ], di = a(xi ) i, 1 m.Denote QT L1 one-variable fragment QT L, i.e., set QT L-formulascontain one individual variable, say, x. Without loss generality mayassume predicate symbols QT L1 unary.define embedding spatio-temporal languages based RC QT L1 .Recall that, Lemma C.2 (i), PT L RC -formula width n satisfiedtt-model FSA also satisfiable Aleksandrov tt-model basedflow time finite disjoint union n-brooms. Similarly, PT L RC -formulawidth n satisfiable also satisfiable Aleksandrov tt-model basedflow time possibly infinite disjoint union n-brooms.cover cases, let PT L RC -formula width n. showconstruct QT L1 -formula n length linear `() every Aleksandrov tt-modelbased (finite) union n-brooms satisfying gives rise first-order temporal model(with finite domain, respectively) satisfying n vice versa. Thus, polynomiallyreduce satisfiability problem spatio-temporal languages QT L1 .Suppose satisfied Aleksandrov tt-model = hF, G, Vi, F = hW, <iG (finite infinite) disjoint union n-brooms. every n-broom b Gassociate element db first-order domain D. Then, every spatial variable pj ,fix n different unary predicate symbols Pj1 (x), . . . , Pjn (x) following meaning:Pji (x) true db moment w W iff i-th leaf b (xib Fig. 11) belongsregion CIp w. Define n distinct translations n , 1 n, encoding truth valuesspatio-temporal region terms leaves G taking, spatial variable pjterms %1 %2 ,(CIpj )n = Pji (x),(CI%1 )n = (%1 )n ,(CI(%1 U %2 ))n = (%1 )n U (%2 )n ,(CI(%1 u %2 ))n = (%1 )n (%2 )n ,(CI(%1 %2 ))n = (%1 )n (%2 )n .226fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityNext extend n translations arbitrary spatio-temporal terms . First0introduce translation n encode truth value arbitrary spatio-temporal termsroots n-brooms G: region term %, let0n(%)n_=k(%)n .k=10formula shows, particular, n redundant region terms since0truth values roots computed defined n . spatio-temporal termform I%, % region term, take0n(I%)n^=k(%)n(I%)n = (%)ni, 1 n,k=1then, spatio-temporal terms 1 2 ,10(1 )n = (1 )n(1 u 2 )n = (1 )n (2 )ni, 0 n.Finally, define translation n subformulas : spatio-temporal term ,n(2 )0n= x ( )n^kx ( )nk=1and, spatio-temporal formulas 1 2 ,(1 )n = 1n ,(1 2 )n = 1n 2n ,(1 U 2 )n = 1n U 2n ,(1 2 )n = 1n 2n ,Clearly, length n linear n `().Lemma C.5. PT L RC -formula width n satisfiable Aleksandrov tt-modelbased (finite) disjoint union n-brooms iff n satisfiable first-order temporalmodel (with finite domain) based flow time.Proof. () Suppose satisfied Aleksandrov tt-model = hF, G, Vi,0 1nF = hW, <i, G = hV, Ri disjointunionffof n-brooms0 n ffb = hWb , Rb i, Wb = {xb , xb , . . . , xb }01Rb reflexive closure { xb , xb , . . . , xb , xb } (see Fig. 11).Construct first-order temporal model N = hF, D, Ii taking setdb n-brooms b G and, every w W ,EI(w)I(w)I(w)I(w)I(w) = D, P11 , . . . , P1n , P21 , . . . , P2n , . . . ,spatial variable pj i, 1 n,I(w)Pjiff= {db | (M, w, xib ) |= pj }.10. brevity, definition follow syntax PT L RC rather PT L RC .227fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevNote finite whenever G finite.Now, induction construction spatio-temporal region term % ,easily shown every w W , every n-broom b G every i, 1 n,ff(58)(N, w) |= (%)n [db ] iff (M, w, xib ) |= %.Next, (58) extended arbitrary spatio-temporal terms i, 0 n:(N, w) |= ( )n [db ]ffiff (M, w, xib ) |= .(59)cases i, 1 n, trivially follow (58) fact leavessuccessors themselves. Consider = 0. case = % holds simply regionterms interpreted regular closed sets:ffff(M, w, x0b ) |= %iff(M, w, xkb ) |= %, k, 1 k n,(60)= I% then, one hand,ff(M, w, x0b ) |= I%iffff(M, w, xkb ) |= %,k, 0 k n,0other, definition n ,0(N, w) |= (I%)n [db ]iffk(N, w) |= (%)n [db ],k, 1 k n,together (60) IH yields (59). cases Booleans trivial.Finally, show every sub ,(N, w) |= niff(M, w) |= .:Case = 2)n(N, w) |= (2kiffdb k {0, 1, . . . , n} (N, w) |= ( )n [db ]ffb G k {0, 1, . . . , n} (M, w, xkb ) |=iff.(M, w) |= 2iffremaining cases trivial. follows n satisfied N.() Assume satisfied first-order temporal model N = hF, D, Ii,F = hW, <i and, every w W ,EI(w)I(w)I(w)I(w)I(w) = D, P11 , . . . , P1n , P21 , . . . , P2n , . . . .every point associate n-broom bd = hWbd , Rbd sets Wbd ,D, pairwise disjoint contains n + 1 distinct elements x0bd , . . . , xnbd .Construct Aleksandrov tt-model = hF, G, Vi takingG disjoint union n-brooms {bd | D},V(pj , w) = xibd | (N, w) |= (CIpj )n [d], 0 n .228fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityClearly, finite G finite well.straightforward induction one show w W , D, spatio-temporalregion terms %, spatio-temporal terms , subformulas , i, 0 n,ffiff(M, w, xibd ) |= %(i > 0),(N, w) |= (%)n [d]ff(N, w) |= ( ) [d]iff(M, w, xbd ) |= ,(N, w) |= niff(M, w) |= .example,0(N, w) |= (I%)n [d]iffiffiffk(N, w) |= (%)n [d], k, 0 k nff(M, w, xkbd ) |= %, k, 0 k nff(M, w, x0bd ) |= I%.qfollows satisfied M.obtain upper complexity bounds combinations PT L RC :Proof Theorem 3.11, upper bound. Follows Lemmas C.2 (ii) C.5 togetherresults complexity one-variable fragment QT L (Halpern & Vardi,1989; Sistla & German, 1987; Hodkinson et al., 2000, 2003).qProof Theorem 3.12, upper bound. Similar proof above.qProof Theorem 3.15, upper bound. proof follows Lemmas C.2 (i) C.5together upper complexity bound guarded monodic (and one-variable)fragment QT L (Hodkinson, 2004).qC.4 Lower Complexity Bounds (II): Embedding First-Order Temporal Logicposition prove Theorem 3.14 establish lower complexity boundsspatio-temporal logics based BRCC-8 (and based RC well). DenoteQT L12 one-variable fragment QT L sole temporal operator 2F . definepolynomial embedding QT L12 PT L2 BRCC-8. Note similar embeddingfull one-variable fragment QT L1 PT L BRCC-8 regarded alternativeway prove lower complexity bound Theorem 3.12.QT L12 -formula said basic Q-formula form x (x),(x) quantifier-free contains propositional variables. QT L12 -sentence Qnormal form built basic Q-formulas using Booleans temporal operator2F . words, sentences Q-normal form contain nested quantifiers useunary predicate symbols. following observation come surprise (see,e.g., Hughes & Cresswell, 1996):Lemma C.6. every QT L12 -sentence one effectively construct QT L12 -sentenceb Q-normal form satisfiable first-order temporal model flowtime F (and finite domain) iffb satisfiable first-order temporal model basedF (and finite domain). Moreover, lengthb linear length .229fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevProof. Without loss generality may assume contains occurrences .transform Q-normal form, first introduce fresh unary predicate symbol Pi (x)every propositional variable pi replace occurrence pi x Pi (x).Denote resulting formula 0 . every subformula 0 define formula ]taking inductively(P (x))] = P (x),()] = ] ,(x )] = Px (x),(1 2 )] = 1] 2] ,Px (x) fresh unary predicate symbol. Let^2+x Px (x) x Px (x)b = x ]0F(2F )] = 2F ] ,x Px (x) x ].xsub0One readily show inductionb satisfiable first-order temporal model basedF (and finite domain) iff satisfiable first-order temporal model basedF (and finite domain). Moreover,b Q-normal form.qNow, given QT L12 -formula Q-normal form, denote result replacingoccurrences basic Q-formulas x (x) EQ( , >), > region termrepresenting whole space (for instance, CIu CIu fresh spatial variable u),translation quantifier-free formulas (x) defined taking:(P (x)) = CIp,() = CI ,(1 2 ) = CI(1 u 2 ),(2F ) = CI2F ,P (x) unary predicate symbol p spatial variable standing P (x). Clearly,belongs PT L2 BRCC-8.Lemma C.7. QT L12 -sentence Q-normal form satisfiable first-order temporalmodel based flow time F finite domain iff satisfiable tt-modelbased F satisfying FSA.Proof. () Suppose Q-normal form = hF, D, Ii first-order temporalffI(w)model, F = hW, <i and, w W , I(w) = D, P0 , . . . , . Let (M, w0 ) |=w0 W . Construct Aleksandrov tt-model M0 = hF, G, Vi taking G = hD, Ri,I(w)R = {hd, di | D} V(pi , w) = hw, di | Pi. Note topologicalspace TG = hD, IG induced G discrete, i.e., X D,IG X = CG X = X.follows induction every quantifier-free QT L12 -formula , every w Wevery(M, w) |= [d]iff(M0 , hw, di) |= .Therefore, every basic Q-formula x (x) every w W , (M, w) |= x (x) iff(M0 , w) |= EQ( , >). follows induction (M0 , w0 ) |= .230fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity() Suppose satisfied tt-model based F = hW, <i. Lemma C.1 (i),satisfied Aleksandrov tt-model = hF, G, Vi, G = hV, Ri disjointunion brooms. Denote V0 V set leaves G define first-order temporalmodel M0 = hF, V0 , Ii taking, w W ,ffI(w)I(w)I(w) = V0 , P0 , . . .Pi= V(pi , w) V0 .Clearly, every X V , IG X V0 = CG X V0 = X V0 , TG = hV, IGtopological space induced G. obtain induction every quantifier-freeQT L12 -formula , w W V0(M0 , w) |= [d]iff(M, hw, di) |= .regular closed set X V TG coincides V iff contains V0 . So, basicQ-formulas x (x) w W , (M0 , w) |= x (x) iff (M, w) |= EQ( , >). followsinduction satisfied M0 .qProof Theorem 3.14, lower bound. Lemmas C.6 C.7 satisfiability problem QT L12 -formulas first-order temporal models finite domains basedhN, <i, hZ, <i arbitrary finite flows time polynomially reducible satisfiability PT L2 BRCC-8 formulas tt-models FSA. Since former knownEXPSPACE-hard (Hodkinson et al., 2003) hN, <i hZ, <i, latter alsoEXPSPACE-hard cases. noted result Hodkinsoncolleagues (2003) readily extended case arbitrary finite flows time(by reduction finite version corridor tiling problem). gives us lowercomplexity bound PT L2 BRCC-8 case finite flows time.qC.5 PSPACE-complete Spatio-Temporal Logicappendix prove Theorem 3.8. fact, show satisfiability problemPT L RC 2 extension PT L RCC-8is decidable PSPACE, RC 2sublanguage S4u spatial terms restricted following:%::= CIp,::= %::= I%::= 1 2|I%,|%,|1 2|.before, denote spatial terms representing regular closed sets (regions)representing regular open sets (the interiors regions). Clearly, definitionequivalent definition p. 190 (where make explicit distinction). easy see RC 2 contains RCC-8, less expressive BRCC-8.Spatio-temporal terms PT L RC 2 constructed region terms form%::=CIp|CI %way spatial terms RC 2 . Finally, PT L RC 2 -formulas composedusing Booleans temporal operators.atomic formulas form 2231fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevreduce satisfiability problem PT LRC 2 PT L. reductiondone number steps.Let F = hW, <i flow time (as formulation Theorem 3.8)PT L RC 2 -formula. begin removing next-time operator subterms .end, let 0 = variable p set1={p | CI CIp term 0 },introduce fresh spatial variable p0 , put^+(CI CIp CIp0 ) ,1 = 12+2>2P Fp11 result replacing occurrence CI CIp 0 CIp0(% % ). Next, p(%(% % ) 2212121 %2 ) stands 22={p | CI CIp term 1 },introduce fresh spatial variable p0 , set^+2 = 22+P 2F>(CI CIp CIp0 ) ,2p1 22 result replacing occurrence CI CIp 1 CIp0 . repeatingprocess sufficiently many times obtain formula^+(CI CIp CIp0 ) ,2>2(61)e =2+P Fpsuitable set spatial variables, contains region terms,is, PT L[RC 2 ]-formula. (Note spatial variable p occurseither CI CIp/ term p .) clear lengthelinear length , satisfiable tt-model based F iffe satisfiablett-model based F.Thus, suffices reduce satisfiability problem PT L RC 2 -formulasform (61) satisfiability problem PT L-formulas. Let us recall functionAppendix B.1 maps PT L[S4u ]-formulas (in particular, PT L[RC 2 ]-formulas), let (2) = p , pPT L-formulas. Namely, every atomic RC 2 -formula 2fresh propositional variable. Then, given PT L[RC 2 ]-formula , define(2) .result replacing every occurrence 2shown proofTheorem 3.1, satisfiable tt-model F = hW, <i iff(s1) exists temporal model N = hF, Ui satisfying and,(s2) every w W , set| (N, w) |= p , term } {2| (N, w) |= p , term }w = {2(62)RC 2 -formulas satisfiable.232fiCombining Spatial Temporal Logics: Expressiveness vs. Complexitypreserve satisfiability whole ,e ensure somehow(s3) points satisfying w predecessors successors satisfying w1w+1 , respectively.remainder appendix first describe encoding satisfiabilityproblem sets RC 2 -formulas form (62) Boolean logic, usedpart final reduction. prove completion property RC 2 (cf. Balbiani &Condotta, 2002) class exhaustive models contain sufficiently many pointsevery type. Roughly, completion property says that, given set form (62)exhaustive model satisfying subset , one extend valuation modelsatisfy whole . property make possible solve problem (s3) above.worth noting similar construction works stronger languages BRCC-8,then, enjoy completion property, sets (62) may need exponentially many formulas (innumber spatial variables) and, therefore, reduction PT L exponentialwell. RC 2 suffices consider sets (62) quadratic number formulas,results quadratic reduction.C.5.1 Properties RC 2 -formulasfinite set = {p1 , . . . , pn } spatial variables, letAtFm =2| RC 2 -term variables .Clearly, every RC 2 -formula spatial variables Boolean combination spatialformulas AtFm . also clear |AtFm | 16 ||2 .width RC 2 -formulas 2 (see p. 209 definition), Lemmas A.1C.2 (ii), RC 2 -formula satisfiable iff satisfiable Aleksandrov topological modelbased disjoint union 2-brooms, alias forks. follows regard everymodel disjoint union fork models = hf, vi, f = hW, Ri, W = {x0 , x1 , x2 },R reflexive closure {hx0 , x1 i, hx0 , x2 i} v valuation spatial variables.Given 0 , say fork models m1 = hf, v1 m2 = hf, v2 0 -equivalentwrite m1 0 m2 , v1 (CIp) = v2 (CIp) every p 0 .Given AtFm AtFm , say f-consequencewrite |=f |= implies |= every fork model based f. saidclosed (underf-consequences) if,, whenever |=f .every AtFmc| 2AtFmLet c = 2. satisfiable iff closed satisfiable.means, particular, check whether set w (62) satisfiable, enough| (N, w) |= p , term }.consider closure {2characterise |=f terms Boolean consequence relation |=. knowAppendix C.3, spatial formulas embedded one-variable fragmentfirst-order logic. precisely, easily shown first-order translationsformulas AtFm (equivalent to) formulas form (which actually Kromformulas; see, e.g., Borger, Gradel, & Gurevich, 1997):1122( ))2 = x 2 2(2x 12 22 ,12121122( ))2 = x 2 2(2x 12 22 ,1212233(63)(64)fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev11( ))2 = x 2 2(2121212x 12 2221x 12 2222x 12 22 , (65)i2(Pji (x),= CIpj ,=Pji (x), = ICIpji2(Pji (x),= ICIpj ,=Pji (x), = CIpj ,= 1, 2.follows proof Lemma C.5 RC 2 -formula satisfied Aleksandrov2 satisfiedmodel based disjoint union forks iff first-ordertranslationff0120first-order model every fork f = hW, Ri M, W = x , x , x , x Rx1 x0 Rx2 ,encoded domain element df Pji (x) true df iff (M, xi ) |= CIpj ,= 1, 2 (see Fig. 11). Since definition closed sets consider Aleksandrovmodels based single fork f, domains respective first-order models contain singleelement df . means (63)(65) encoded Boolean formulas221 2 ,1122( )) =(21 2 1 2 ,122111( )) =(21 2 1 21211( )) =(21 212211 2221 2 ,(qji ,= CIpj ,=qji , = ICIpj(qji ,= ICIpj ,=qji , = CIpj ,= 1, 2.Thus, every AtFm associate conjunction -translationsformulas following holds:Claim C.8. every AtFm , |=fiff|= .construct closure AtFm check whether satisfiable,use following resolution-like inference rules:()()( %)21(I% )22()1( )212%2%22(1 )()(I% )21(% )212(02 )( )212()2(% )21(I% )210= %, = I%;= %, 0 = %;= I%, 0 = I%;together equivalences:% = 2I%,2% = 2I%,2(% ) = 2(I% ),211(% ) = 2(I% ),211% = CIp p , 1 2 form % I%, 1 2 formI% %. readily checked rules sound, derivable ,satisfiable. hand, satisfiable regarded234fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityunsatisfiable set binary unary propositional clauses and, using standardresolution procedure, one construct derivation empty clause which,turn, mimicked applications rules (and equivalences) derive. Moreover, since propositional resolution subsumption complete (see, e.g.,Slagle, Chang, & Lee, 1969), also derive consequences , thereby obtainingclosure.encode rules equivalences Boolean formulas variables p ,AtFm . instance, () () encoded2% 2%( )( %) 2(I% ) 222,2121respectively. Denote conjunction formulas spatial variables. following:Claim C.9. every AtFm , closed satisfiable iff Boolean formulah ^^pp(66)AtFm22satisfiable.Finally, ensure (s3), need following completion property RC 2 :Lemma C.10. Let closed subset AtFm , 0 0 = AtFm0 .(i) 0 closed (ii) every fork model m0 , m0 |= 0 fork modelm0 0 |= .Proof. Claim (i) clear. show (ii), define characteristic formula m0 0taking:(^qji , (m0 , xi ) 6|= CIpj ,=ljilji =qji ,(m0 , xi ) |= CIpj .p , i=1,2j0m0 |= 0 follows immediately definitions 0 satisfiable.aim show also satisfiable, would mean fork modelrequired. Suppose otherwise. |= . regard set unary. Accordingbinary clauses clause 2 |0 | literals lji , negations ljisubsumption theorem (Slagle et al., 1969), applying standard resolution rule, derive clause lj1 i1 lj2 i2 subsumes (i.e., literals occur). Since closed, lj1 i1 lj2 i2 among clauses ljk ikk -translations spatial terms spatial variables 0 , conclude lj1 i1 lj2 i2indeed among clauses 0 , contrary 0 satisfiable.qC.5.2 Polynomial Translation PT L RC 2 PT Lposition define polynomial (at quadratic) translationPT L RC 2 PT L. Starting given formula , construct PT L RC 2 formulae form (61):^+(CI CIp CIp0 ) ,e =2+>2P 2Fp235fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevPT L[RC 2 ]-formula. Let 0 = {p0 | p } let denote smallestset spatial variables containing 0 spatial variables occurring . GivenAtFm0 formula AtFm 02, denote 2obtained 2 replacing00every occurrence p p . Consider PT L-formula=+2+P 2 F+2+P 2F>^20 ) .( 2AtFm2Lemma C.11. every PT L RC 2 -formula ,e satisfiable tt-model basedF = hW, <i iff satisfiable temporal model based F.Proof. () Let (M, w0 ) |= .e Construct temporal model N = hF, Vi taking,2 AtFm ,}.V(p ) = {w W | (M, w) |= 2easy see (N, w0 ) |= .() Let (N, w0 ) |= w0 W . every w W , setAtFmw = {2| (N, w) |= p }.Let w , w W , set non--equivalent fork models |= w .Claim C.9, w closed satisfiable, sets w nonempty. useelements w building blocks exhaustive states tt-model goingconstruct order satisfy .First show element w successor w+1 predecessorw1 (provided w successor predecessor, respectively). precisely,say pair fork models = hf, vi m0 = hf, v0 suitable write m0v(CIp0 ) = v0 (CIp), every p .(succ) Let w , = hf, vi, let w W successor w + 1. thirdconjunct ,w AtFm0=0 AtFm 0{2| (N, w) |= p 0 }=0 AtFm 0{2| (N, w + 1) |= p }.Therefore,w+1 AtFm=AtFm{2| (N, w) |= p 0 }.Now, w , |= w AtFm0 . define fork model m0 = hf, v0taking v0 (p) = v(p0 ), p (and arbitrary otherwise), m0 |= w+1 AtFmfollows. Since w+1 closed, Lemma C.10, find fork model m00 = hf, v00m00 m0 m00 |= w+1 . follows m00 m00 -equivalentfork model w+1 (i.e., may assume m00 w+1 ).(pred ) Similarly, every , = hf, vi, every w W predecessorw 1, m00 = hf, v00 m00 w1 m00 m.clear every fork model w every w W , definefunction rm,w gives u W fork model rm,w (u) u rm,w (w) =236fiCombining Spatial Temporal Logics: Expressiveness vs. Complexityrm,w (u) rm,w (u + 1), whenever u + 1 successor u. Let setfunctions rm,w , w W w .ready define Aleksandrov tt-model = hF, G, Vi satisfying .e LetG = hW, Ri disjoint union ||-many forks fr = hWr , Rr i, Wr = {x0r , x1r , x2r }, x0r Rr x1rx0r Rr x2r , r , let V(p, w) = {xir W | (r(w), xir ) |= CIp}, pw W . show induction construction sub that, every w W ,(M, w) |=iff(N, w) |= .. Suppose (M, w) |= 2(N, w) 6|= p . 2Case = 2/ w and, since. followsw closed (by Claim C.9 true w), w 6|=f 2, r r(w) = m,fork model w |= 2. Conversely, (N, w) |= pcontrary (M, w) |= 2then, construction, (M, w) |= 2 .cases Booleans temporal operators trivial.second conjuncte satisfied construction, obtain (M, w0 ) |= .eqReferencesAiello, M., & van Benthem, J. (2002a). Logical patterns space. Barker-Plummer,D., Beaver, D. I., van Benthem, J., & Scotto di Luzio, P. (Eds.), Words, ProofsDiagrams, pp. 525. CSLI Publications, Stanford.Aiello, M., & van Benthem, J. (2002b). modal walk space. Journal AppliedNon-Classical Logics, 12 (34), 319364.Alexandroff, P. (1937). Diskrete Raume. Matematicheskii Sbornik, 2 (44), 501518.Allen, J. (1983). Maintaining knowledge temporal intervals. CommunicationsACM, 26, 832843.Areces, C., Blackburn, P., & Marx, M. (2000). computational complexity hybridtemporal logics. Logic Journal IGPL, 8, 653679.Arhangelskii, A., & Collins, P. (1995). submaximal spaces. Topology Applications, 64, 219241.Asher, N., & Vieu, L. (1995). Toward geometry common sense: semanticscomplete axiomatization mereotopology. Mellish, C. (Ed.), Proceedings14th International Joint Conference Artificial Intelligence (IJCAI-95), pp. 846852. Morgan Kaufmann.Balbiani, P., & Condotta, J.-F. (2002). Computational complexity propositional lineartemporal logics based qualitative spatial temporal reasoning. Armando, A.(Ed.), Proceedings Frontiers Combining Systems (FroCoS 2002), Vol. 2309Lecture Notes Computer Science, pp. 162176. Springer.Balbiani, P., Tinchev, T., & Vakarelov, D. (2004). Modal logics region-based theoriesspace. Manuscript.Bennett, B. (1994). Spatial reasoning propositional logic. Proceedings 4thInternational Conference Knowledge Representation Reasoning, pp. 5162.Morgan Kaufmann.237fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevBennett, B. (1996). Modal logics qualitative spatial reasoning. Logic JournalIGPL, 4, 2345.Bennett, B., & Cohn, A. (1999). Multi-dimensional multi-modal logics frameworkspatio-temporal reasoning. Proceedings Hot topics Spatio-temporalreasoning workshop, IJCAI-99, Stockholm.Bennett, B., Cohn, A., Wolter, F., & Zakharyschev, M. (2002). Multi-dimensional modallogic framework spatio-temporal reasoning. Applied Intelligence, 17, 239251.Blackburn, P. (1992). Fine grained theories time. Aurnague, M., Borillo, A., Borillo,M., & Bras, M. (Eds.), Proceedings 4th European Workshop SemanticsTime, Space, Movement Spatio-Temporal Reasoning, pp. 299320, Chateaude Bonas, France. Groupe Langue, Raisonnement, Calcul, Toulouse.Borger, E., Gradel, E., & Gurevich, Y. (1997). Classical Decision Problem. PerspectivesMathematical Logic. Springer.Bourbaki, N. (1966). General topology, Part 1. Hermann, Paris Addison-Wesley.Chagrov, A., & Zakharyaschev, M. (1997). Modal Logic, Vol. 35 Oxford Logic Guides.Clarendon Press, Oxford.Chlebus, B. (1986). Domino-tiling games. Journal Computer System Sciences, 32,374392.Clarke, B. (1981). calculus individuals based connection. Notre Dame JournalFormal Logic, 23, 204218.Clarke, B. (1985). Individuals points. Notre Dame Journal Formal Logic, 26, 6175.Clarke, E., & Emerson, E. (1981). Design synthesis synchronisation skeletons usingbranching time temporal logic. Kozen, D. (Ed.), Logic Programs, Vol. 131Lecture Notes Computer Science, pp. 5271. Springer.Clementini, E., Di Felice, P., & Hernandez, D. (1997). Qualitative representation positional information. Artificial Intelligence, 95, 317356.Cohn, A. (1997). Qualitative spatial representation reasoning techniques. Brewka,G., Habel, C., & Nebel, B. (Eds.), KI-97: Advances Artificial Intelligence, Vol. 1303Lecture Notes Computer Science, pp. 130. Springer.Davis, E. (1990). Representations Commonsense Knowledge. Morgan Kaufmann.Degtyarev, A., Fisher, M., & Konev, B. (2003). Monodic temporal resolution. Baader,F. (Ed.), Proceedings 19th International Conference Automated Deduction (CADE-19), Vol. 2741 Lecture Notes Artificial Intelligence, pp. 397411.Springer.Demri, S., & DSouza, D. (2002). automata-theoretic approach constraint LTL.Agrawal, M., & Seth, A. (Eds.), Proceedings 22nd Conference FoundationsSoftware Technology Theoretical Computer Science (FST TCS 2002), Vol. 2556Lecture Notes Computer Science, pp. 121132. Springer.Egenhofer, M., & Franzosa, R. (1991). Point-set topological spatial relations. InternationalJournal Geographical Information Systems, 5, 161174.238fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityEgenhofer, M., & Herring, J. (1991). Categorizing topological relationships regions,lines points geographic databases. Tech. rep., University Maine.Egenhofer, M., & Sharma, J. (1993). Assessing consistency complete incompletetopological information. Geographical Systems, 1, 4768.Emerson, E., & Halpern, J. (1985). Decision procedures expressiveness temporallogic branching time. Journal Computer System Sciences, 30, 124.Fine, K. (1974). Logics containing K4, part I. Journal Symbolic Logic, 39, 229237.Finger, M., & Gabbay, D. (1992). Adding temporal dimension logic system. JournalLogic, Language Information, 2, 203233.Fisher, M., Dixon, C., & Peim, M. (2001). Clausal temporal resolution. ACM TransactionsComputational Logic (TOCL), 2, 1256.Gabbay, D., Hodkinson, I., & Reynolds, M. (1994). Temporal Logic: Mathematical Foundations Computational Aspects, Volume 1. Oxford University Press.Galton, A., & Meathrel, R. (1999). Qualitative outline theory. Dean, T. (Ed.), Proceedings16th International Joint Conference Artificial Intelligence (IJCAI-99), pp.10611066. Morgan Kaufmann.Gerevini, A., & Nebel, B. (2002). Qualitative spatio-temporal reasoning RCC-8 Allens interval calculus: Computational complexity. Proceedings 15th EuropeanConference Artificial Intelligence (ECAI02), pp. 312316. IOS Press.Gerevini, A., & Renz, J. (2002). Combining topological size constraints spatialreasoning. Artificial Intelligence, 137, 142.Godel, K. (1933). Eine Interpretation des intuitionistischen Aussagenkalkuls. Ergebnisseeines mathematischen Kolloquiums, 4, 3940.Goldblatt, R. (1976). Metamathematics modal logic, Part I. Reports MathematicalLogic, 6, 4178.Goranko, V., & Passy, S. (1992). Using universal modality: gains questions. JournalLogic Computation, 2, 530.Gotts, N. (1996). axiomatic approach topology spatial information systems. Tech.rep. 96.25, School Computer Studies, University Leeds.Halpern, J., & Shoham, Y. (1986). propositional modal logic time intervals. Proceedings 1st Annual IEEE Symposium Logic Computer Science (LICS86),pp. 279292. IEEE Computer Society.Halpern, J., & Vardi, M. (1989). complexity reasoning knowledge time I:lower bounds. Journal Computer System Sciences, 38, 195237.Hodkinson, I. (2004). Complexity monodic packed fragment linear real time.appear Annals Pure Applied Logic, available http://www.doc.ic.ac.uk//~imh/papers/cxmonlin.pdf.Hodkinson, I., Kontchakov, R., Kurucz, A., Wolter, F., & Zakharyaschev, M. (2003).computational complexity decidable fragments first-order linear temporal239fiGabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschevlogics. Reynolds, M., & Sattar, A. (Eds.), Proceedings TIME-ICTL 2003, pp.9198. IEEE Computer Society.Hodkinson, I., Wolter, F., & Zakharyaschev, M. (2000). Decidable fragments first-ordertemporal logics. Annals Pure Applied Logic, 106, 85134.Hodkinson, I., Wolter, F., & Zakharyaschev, M. (2001). Monodic fragments first-ordertemporal logics: 20002001 A.D. Nieuwenhuis, R., & Voronkov, A. (Eds.), LogicProgramming, Artificial Intelligence Reasoning, Vol. 2250 Lecture NotesArtificial Intelligence, pp. 123. Springer.Hodkinson, I., Wolter, F., & Zakharyaschev, M. (2002). Decidable undecidable fragments first-order branching temporal logics. Proceedings 17th AnnualIEEE Symposium Logic Computer Science (LICS 2002), pp. 393402. IEEEComputer Society.Hughes, G., & Cresswell, M. (1996). New Introduction Modal Logic. Methuen, London.Hustadt, U., & Konev, B. (2003). TRP++ 2.0: temporal resolution prover. Baader,F. (Ed.), Proceedings 19th International Conference Automated Deduction(CADE-19), Vol. 2741 Lecture Notes Computer Science, pp. 274278. Springer.Kontchakov, R., Lutz, C., Wolter, F., & Zakharyaschev, M. (2004). Temporalising tableaux.Studia Logica, 76, 91134.Kutz, O., Sturm, H., Suzuki, N.-Y., Wolter, F., & Zakharyaschev, M. (2003). Logicsmetric spaces. ACM Transactions Computational Logic, 4, 260294.Ladner, R. (1977). computational complexity provability systems modal logic.SIAM Journal Computing, 6, 467480.Lemon, O., & Pratt, I. (1998). incompleteness modal logics space: advancing complete modal logics place. Kracht, M., de Rijke, M., Wansing, H., &Zakharyaschev, M. (Eds.), Advances Modal Logic, Volume 1, pp. 115132. CSLIPublications, Stanford.Lewis, C., & Langford, C. (1932). Symbolic Logic. Appleton-Century-Crofts, New York.Ligozat, G. (1998). Reasoning cardinal directions. Journal Visual LanguagesComputing, 9, 2344.Manna, Z., & Pnueli, A. (1992). Temporal Logic Reactive Concurrent Systems.Springer.McKinsey, J. (1941). solution decision problem Lewis systems S2 S4,application topology. Journal Symbolic Logic, 6, 117134.McKinsey, J., & Tarski, A. (1944). algebra topology. Annals Mathematics, 45,141191.Muller, P. (1998a). qualitative theory motion based spatio-temporal primitives.Cohn, A., Schubert, L., & Shapiro, S. (Eds.), Proceedings 6th InternationalConference Principles Knowledge Representation Reasoning (KR98), pp.131142. Morgan Kaufmann.240fiCombining Spatial Temporal Logics: Expressiveness vs. ComplexityMuller, P. (1998b). Space-time primitive space motion. Guarino, N. (Ed.),Proceedings International Conference Formal Ontology Information Systems (FOIS98), Vol. 46 Frontiers Artificial Intelligence Applications, pp.6376. IOS Press.Nebel, B., & Burckert, H. (1995). Reasoning relations: maximal tractable subclassAllens interval algebra. Journal ACM, 42, 4366.Nebel, B. (1996). Artificial intelligence: computational perspective. Brewka, G. (Ed.),Principles Knowledge Representation, pp. 237266. CSLI Publications.Nutt, W. (1999). translation qualitative spatial reasoning problems modallogics. Burgard, W., Christaller, T., & Cremers, A. (Eds.), Advances Artificial Intelligence. Proceedings 23rd Annual German Conference ArtificialIntelligence (KI99), Vol. 1701 Lecture Notes Computer Science, pp. 113124.Springer.Ono, H., & Nakamura, A. (1980). size refutation Kripke models linearmodal tense logics. Studia Logica, 39, 325333.Orlov, I. (1928). calculus compatibility propositions. Mathematics USSR,Sbornik, 35, 263286. (In Russian).Post, E. (1946). variant recursively unsolvable problem. Bulletin AMS, 52,264268.Pratt-Hartmann, I. (2002). topological constraint language component counting.Journal Applied Non-Classical Logics, 12, 441467.Randell, D., Cui, Z., & Cohn, A. (1992). spatial logic based regions connection.Nebel, B., Rich, C., & Swartout, W. (Eds.), Proceedings 3rd InternationalConference Principles Knowledge Representation Reasoning (KR92), pp.165176. Morgan Kaufmann.Renz, J. (1998). canonical model region connection calculus. Cohn, A., Schubert,L., & Shapiro, S. (Eds.), Proceedings 6th International Conference Principles Knowledge Representation Reasoning (KR98), pp. 330341. MorganKaufmann.Renz, J., & Nebel, B. (1998). Spatial reasoning topological information. Freksa, C.,Habel, C., & Wender, K. (Eds.), Spatial CognitionAn Interdisciplinary ApproachRepresentation Processing Spatial Knowledge, Vol. 1404 Lecture NotesComputer Science, pp. 351372. Springer.Renz, J., & Nebel, B. (1999). complexity qualitative spatial reasoning. ArtificialIntelligence, 108, 69123.Renz, J. (2002). canonical model region connection calculus. Journal AppliedNon-Classical Logics, 12, 469494.Renz, J., & Nebel, B. (2001). Efficient methods qualitative spatial reasoning. JournalArtificial Intelligence Research, 15, 289318.Reynolds, M. (2003). complexity temporal logic general lineartime. Journal Computer System Science, 66, 393426.241fiGabelaia, Kontchakov, Kurucz, Wolter, & ZakharyaschevReynolds, M. (2004). complexity temporal logic reals. Submitted,available http://www.csse.uwa.edu.au/~mark/research/Online/CORT.htm.Schwendimann, S. (1998). new one-pass tableau calculus PLTL. de Swart, H. (Ed.),Proceedings International Conference Automated Reasoning AnalyticTableaux Related Methods (TABLEAUX-98), Vol. 1397 Lecture Notes Artificial Intelligence, pp. 277291. Springer.Sistla, A., & Clarke, E. (1985). complexity propositional linear temporal logics.Journal Association Computing Machinery, 32, 733749.Sistla, A., & German, S. (1987). Reasoning many processes. ProceedingsSecond IEEE Symposium Logic Computer Science (LICS87), pp. 138153. IEEEComputer Society.Slagle, J., Chang, C.-L., & Lee, R. (1969). Completeness theorems semantic resolutionconsequence-finding. Proceedings 1st International Joint ConferenceArtificial Intelligence (IJCAI69), pp. 281286. William Kaufmann.Smith, T., & Park, K. (1992). algebraic approach spatial reasoning. InternationalJournal Geographical Information Systems, 6, 177192.Stockmeyer, L. (1974). Complexity Decision Problems Automata TheoryLogic. Ph.D. thesis, MIT.Stockmeyer, L. (1987). Classifying computational complexity problems. JournalSymbolic Logic, 52, 143.Stone, M. (1937). Application theory Boolean rings general topology. Transactions AMS, 41, 321364.Tarski, A. (1938). Der Aussagenkalkul und die Topologie. Fundamenta Mathematicae, 31,103134.Tsao Chen, T. (1938). Algebraic postulates geometric interpretation Lewiscalculus strict implication. Bulletin AMS, 44, 737744.van Benthem, J. (1995). Temporal logic. Gabbay, D., Hogger, C., & Robinson, J. (Eds.),Handbook Logic Artificial Intelligence Logic Programming, Vol. 4, pp. 241350. Oxford Scientific Publishers.van Emde Boas, P. (1997). convenience tilings. Sorbi, A. (Ed.), Complexity, LogicRecursion Theory, Vol. 187 Lecture Notes Pure Applied Mathematics,pp. 331363. Marcel Dekker Inc.Wolper, P. (1985). tableau method temporal logic: overview. Logique et Analyse,28, 119152.Wolter, F. (1996). Properties tense logics. Mathematical Logic Quarterly, 42, 481500.Wolter, F., & Zakharyaschev, M. (2000a). Spatial reasoning RCC-8 Boolean regionterms. Horn, W. (Ed.), Proceedings 14th European Conference ArtificialIntelligence (ECAI 2000), pp. 244248. IOS Press.Wolter, F., & Zakharyaschev, M. (2000b). Spatio-temporal representation reasoningbased RCC-8. Cohn, A., Giunchiglia, F., & Seltman, B. (Eds.), Proceedings242fiCombining Spatial Temporal Logics: Expressiveness vs. Complexity7th Conference Principles Knowledge Representation Reasoning (KR2000), pp. 314. Morgan Kaufmann.Wolter, F., & Zakharyaschev, M. (2002). Qualitative spatio-temporal representationreasoning: computational perspective. Lakemeyer, G., & Nebel, B. (Eds.), Exploring Artificial Intelligence New Millenium, pp. 175216. Morgan Kaufmann.Zimmermann, K. (1995). Measuring without measures: delta-calculus. Frank, A., &Kuhn, W. (Eds.), Proceedings 2nd International Conference Spatial Information Theory (COSIT), Vol. 988 Lecture Notes Computer Science, pp. 5967.Springer.243fiJournal Artificial Intelligence Research 23 (2005) 441-531Submitted 11/04; published 4/05Generalizing Boolean Satisfiability III: ImplementationHeidi E. DixonMatthew L. Ginsbergdixon@otsys.comginsberg@otsys.comTime Systems, Inc.1850 Millrace, Suite 1Eugene, 97403 USADavid HoferEugene M. Lukshofer@cs.uoregon.eduluks@cs.uoregon.eduComputer Information ScienceUniversity OregonEugene, 97403 USAAndrew J. Parkesparkes@cirl.uoregon.eduCIRL1269 University OregonEugene, 97403 USAAbstractthird three papers describing zap, satisfiability engine substantiallygeneralizes existing tools retaining performance characteristics modern highperformance solvers. fundamental idea underlying zap many problems passedengines contain rich internal structure obscured Boolean representationused; goal define representation structure apparentexploited improve computational performance. first paper surveyed existingwork (knowingly not) exploited problem structure improve performancesatisfiability engines, second paper showed structure could understoodterms groups permutations acting individual clauses particular Booleantheory. conclude series discussing techniques needed implement ideas,reporting performance variety problem instances.1. Introductionthird series three papers describing zap, satisfiability enginesubstantially generalizes existing tools retaining performance characteristicsmodern high-performance solvers zChaff (Moskewicz, Madigan, Zhao, Zhang, &Malik, 2001). first two papers series, made arguments effect that:Many Boolean satisfiability problems incorporate rich structure reflects properties domain problems arise, recent improvementsperformance satisfiability engines understood terms abilityexploit structure (Dixon, Ginsberg, & Parkes, 2004b, referzap1).structure understood terms groups (in algebraic sense)permutations acting individual clauses (Dixon, Ginsberg, Luks, & Parkes, 2004a,refer zap2).c2005AI Access Foundation. rights reserved.fiDixon, Ginsberg, Hofer, Luks & Parkesshowed implementation based ideas could expected combineattractive computational properties variety recent ideas, including efficient implementations unit propagation (Zhang & Stickel, 2000) extensions Boolean language include cardinality pseudo-Boolean constraints (Barth, 1995; Dixon & Ginsberg,2000; Hooker, 1988), parity problems (Tseitin, 1970), limited form quantificationknown qprop (Ginsberg & Parkes, 2000). paper, discuss implementationprover based ideas, describe performance pigeonhole, parityclique coloring problems. classes problems known exponentially difficultconventional Boolean satisfiability engines, formalization also highlightsgroup-based nature reasoning involved.technical point view, difficult three zap papers; needdraw algorithms theoretical constructions zap2 results computational group theory (GAP Group, 2004; Seress, 2003) regarding implementation.overall plan describing implementation follows:1. Section 2 review material zap2. begin Section 2.1 presentingBoolean satisfiability algorithms hope generalize basic algebraicideas underlying zap. Section 2.2 describes group-theoretic computations requiredzap implementation.2. Section 3 gives brief necessarily incomplete introduction ideascomputational group theory use.3. Sections 4 5 describe implementations computations discussed Section 2. basic construction, describe algorithm used giveexample computation action. existing implementation something public domain system gap (2004), provide pointerimplementation; concepts needed implement scratch, additionaldetail provided.4. Section 6 extends basic algorithms Section 5 deal unit propagation,want compute single unit clause instance, listunit consequences augmented clause.5. Section 7 discusses implementation Zhang Stickels (2000) watched literalidea setting.6. Section 8 describes technique used select among possible resolventstwo augmented clauses. functionality analog conventionalprover, single ground reason truth falsity givenvariable. reasons augmented clauses, may variety waysground instances clauses combined.7. describing algorithms, present experimental results regarding performance Sections 9 10. Section 9 reports performance zaps individualalgorithmic components, Section 10 contrasts zaps overall performancecnf-based predecessors.1 Since focus paper algorithms1. description zaps input language contained Appendix B.442fiZAP 3: Implementationneeded zap, report performance relatively theoretical examplesclearly involve group-based reasoning. Performance wider range problemclasses reported elsewhere.8. Concluding remarks appear Section 11.Except Section 3, proofs generally deferred Appendix interests maintaining continuity exposition. Given importance computational grouptheory ideas presenting, strongly suggest reader workproofs Section 3 paper.long complex paper; make apologies. Zap attempt synthesizetwo different fields, complex right: computational group theoryimplementations Boolean satisfiability engines. Computational group theory, additioninherent complexity, likely foreign AI audience. Work completealgorithms Boolean satisfiability also become increasingly sophisticatedpast decade so, introduction substantial nonintuitive modificationsoriginal dpll algorithm relevance-bounded learning (Bayardo & Miranker, 1996;Bayardo & Schrag, 1997; Ginsberg, 1993) watched literals (Zhang & Stickel, 2000).bring two fields together, see wide range techniquescomputational group theory relevant problems interest us; goal alsosimply translate dpll new setting, show recent workBoolean satisfiability moved across. least one case (Lemma 5.26), alsoneed extend existing computational group theory results. finally, newsatisfiability techniques possibilities arise synthesisproposing (Section 8), describe well.paper intended self-contained. assume throughout readerfamiliar material presented zap2; results paperrepeated convenience, accompanying text intended stand alone.Finally spite disclaimers previous two paragraphs paperintended complete. goal present practical minimum requiredimplement effective group-based reasoning system. results obtained,theoretical described zap2 practical described here, excite us.excited number issues yet explored. primary goalpresent foundation needed interested researchers explore ideasus.2. ZAP Fundamentals Basic Structureoverview zap involves summarizing work two distinct areas: existing Booleansatisfiability engines, group-theoretic elements underlying zap.2.1 Boolean Satisfiabilitybegin description architecture modern Boolean satisfiability engines.start unit propagation procedure, describe follows:443fiDixon, Ginsberg, Hofer, Luks & ParkesDefinition 2.1 Given Boolean satisfiability problem described terms set Cclauses, partial assignment assignment values (true false) subsetvariables appearing C. represent partial assignment P sequenceconsistent literals P = hli appearance vi sequence means viset true, appearance vi means vi set false.annotated partial assignment sequence P = h(li , ci )i ci reasonassociated choice li . ci = true, means variable set resultbranching decision; otherwise, ci clause entails li virtue choicesprevious lj j < i. annotated partial assignment called sound respectset constraints C C |= ci reason ci . (See zap2 additional details.)Given (possibly annotated) partial assignment P , denote S(P ) literalssatisfied P , U (P ) set literals unvalued P .Procedure 2.2 (Unit propagation) compute Unit-Propagate(C, P ) set Cclauses annotated partial assignment P = h(l1 , c1 ), . . . , (ln , cn )i:1 c C c S(P ) = |c U (P )| 12c U (P ) =3li literal c highest index P4return htrue, resolve(c, ci )i5else l literal c unassigned P6P hP, (l, c)i7 return hfalse, Presult returned depends whether contradiction encounteredpropagation, first result returned true contradiction foundfalse none found. former case, clause c unvalued literals(line 2), li last literal set c, ci reason li set way causedc unsatisfiable. resolve c ci return result new nogoodproblem question. Otherwise, eventually return partial assignment, augmentedinclude variables set propagation process.Given unit propagation, overall inference procedure following:Procedure 2.3 (Relevance-bounded learning, rbl) Given sat problem C, setlearned nogoods annotated partial assignment P , compute rbl(C, D, P ):444fiZAP 3: Implementation1 hx, yi unit-propagate(C D, P )2 x = true3c4c empty5return failure6else remove successive elements P c unit7learn(D, P, c)8return rbl(C, D, P )9else P10P solution C11return P12else l literal assigned value P13return rbl(C, D, hP, (l, true)i)might expected, procedure recursive. point unit propagation produces contradiction c, use (currently unspecified) learn procedure incorporate csolvers current state, recurse. c empty, means derivedcontradiction procedure fails. backtracking step (line 6), backtrackc satisfiable, enables unit propagation. technique usedzChaff (Moskewicz et al., 2001). leads increased flexibility choice variableassigned backtrack complete, generally improves performance.unit propagation indicate presence contradiction produce solutionproblem question, pick unvalued literal, set true, recurse again.Note dont need set literal l true false; eventually need backtrackset l false, handled modification P line 6.Finally, need present procedure used incorporate new nogoodclausal database C. order that, make following definition:Definition 2.4 Let li clause, denote c, let P partialassignment. say possible value c P givenposs(c, P ) = |{i|li 6 P }| 1ambiguity possible, write simply poss(c) instead poss(c, P ).words, poss(c) number literals either already satisfied valued P ,reduced one (since clause requires least one true literal).Note poss(c, P ) = |c [U (P ) S(P )]| 1, since expression one lessnumber potentially satisfied literals c.possible value clause essentially measure authors calledirrelevance (Bayardo & Miranker, 1996; Bayardo & Schrag, 1997; Ginsberg, 1993).unsatisfied clause c poss(c, P ) = 0 used unit propagation; sayclause unit. poss(c, P ) = 1, means change single variablelead unit propagation, on. notion learning used relevance-boundedinference captured by:445fiDixon, Ginsberg, Hofer, Luks & ParkesProcedure 2.5 Given set clauses C annotated partial assignment P , compute learn(C, P, c), result adding C clause c removing irrelevant clauses:12remove C C poss(d, P ) > kreturn C {c}hope familiar; not, please refer zap2 paperscited fuller explanations.zap, continue work procedures approximately current form,replace idea clause (a disjunction literals) augmented clause:Definition 2.6 augmented clause n-variable Boolean satisfiability problempair (c, G) c Boolean clause G group G Wn . (nonaugmented) clause c0 instance augmented clause (c, G) g Gc0 = cg .2 clause c called base instance (c, G).Roughly speaking, augmented clause consists conventional clause group Gpermutations literals theory; intent act clauseelement group still get clause part original theory.group G required subgroup group permutations complementations(Harrison, 1989) Wn = S2 Sn , permutation g G permute variablesproblem flip signs arbitrary subset well. showed zap2suitably chosen groups correspond cardinality constraints, parity constraints (the groupflips signs even number variables), universal quantification finitedomains.must lift previous three procedures augmented setting. unitpropagation, example, instead checking see clause c C unit givenassignments P , check see augmented clause (c, G) unit instance.that, procedure essentially unchanged Procedure 2.2:Procedure 2.7 (Unit propagation) compute Unit-Propagate(C, P ) setclauses C annotated partial assignment P = h(l1 , c1 ), . . . , (ln , cn )i:1234567(c, G) C g G cg S(P ) = |cg U (P )| 1cg U (P ) =li literal cg highest index Preturn htrue, resolve((cg , G), ci )ielse l literal cg unassigned PP hP, (l, (cg , G))ireturn hfalse, Pbasic inference procedure also virtually unchanged:2. zap2 used computational group theory community, denote image clausec group element g cg instead possibly familiar g(c). explained zap2,reflects fact composition f g two permutations acts f first g second.446fiZAP 3: ImplementationProcedure 2.8 (Relevance-bounded learning, rbl) Given sat problem C, setlearned clauses D, annotated partial assignment P , compute rbl(C, D, P ):1 hx, yi unit-propagate(C D, P )2 x = true3(c, G)4c empty5return failure6else remove successive elements P c unit7learn(D, P, (c, G))8return rbl(C, D, P )9else P10P solution C11return P12else l literal assigned value P13return rbl(C, D, hP, (l, true)i)line 3, although unit propagation returns augmented clause (c, G), base instancec still reason backtrack virtue line 6 Procedure 2.7. followsline 6 Procedure 2.8 unchanged Boolean version.lift Procedure 2.5 setting, need augmented version Definition 2.4:Definition 2.9 Let (c, G) augmented clause, P partial assignment.poss((c, G), P ) mean minimum possible value instance (c, G),poss((c, G), P ) = min poss(cg , P )gGProcedure 2.5 used unchanged, augmented clause insteadsimple one. effect Definition 2.9 cause us remove augmented clausesevery instance irrelevant. Presumably, useful retain clause longrelevant instance.zap2, showed proof engine built around three procedures wouldfollowing properties:Since number generators group made logarithmic group size,would achieve exponential improvements basic representational efficiency.Since k-relevant nogoods retained search proceeds, memory requirements remain polynomial size problem solved.produce polynomially sized proofs pigeonhole clique coloring problems, parity problem.generalizes first-order inference provided quantifiers universaldomains quantification finite.stated without proof (and show paper) unit propagation procedure 2.7 implemented way generalizes subsearch (Ginsberg & Parkes,2000) Zhang Stickels (2000) watched literal idea.447fiDixon, Ginsberg, Hofer, Luks & Parkes2.2 Group-Theoretic ElementsExamining three procedures, elements new relative Boolean enginesfollowing:1. line 1 unit propagation procedure 2.7, need find unit instancesaugmented clause (c, G).2. line 4 procedure 2.7, need compute resolvent two augmentedclauses.3. line 1 learning procedure 2.5, need determine augmented clauserelevant instances.first third needs different second. resolution, needfollowing definitions:Definition 2.10 permutation p set p = S, p|S meanrestriction p given set, say p lifting p|S back originalset p acts.Definition 2.11 set , denote Sym() group permutations .G Sym() subgroup group , say G acts S.3Definition 2.12 Suppose G acts set S. x S, orbit x G,denoted xG , given xG = {xg |g G}. S, G-closure ,denoted G , setG = {tg |t g G}Definition 2.13 K1 , . . . , Kn G1 , . . . , Gn Sym(), say permutation Sym() stable extension G1 , . . . , Gn K1 , . . . , Kn gi Gii, |K Gi = gi |K Gi . denote set stable extensions G1 , . . . , GnK1 , . . . , Kn stab(Ki , Gi ).set stable extensions stab(Ki , Gi ) closed composition, thereforesubgroup Sym().Definition 2.14 Suppose (c1 , G1 ) (c2 , G2 ) augmented clauses. result resolving (c1 , G1 ) (c2 , G2 ), denoted resolve((c1 , G1 ), (c2 , G2 )),augmented clause (resolve(c1 , c2 ), stab(ci , Gi ) Wn ).follows definitions computing resolvent two augmentedclauses required Procedure 2.7 essentially matter computing set stableextensions groups question. return problem Section 4.two problems viewed instances following:3. convenience, depart standard usage permit G map points images outsideS.448fiZAP 3: ImplementationDefinition 2.15 Let c clause, viewed set literals, G group permutationsacting c. fix sets literals U , integer k. say ktransporter problem finding g G cg = |cg U | k,reporting g exists.find unit instance (c, G), set set satisfied literals Uset unvalued literals. Taking k = 1 implies searching instancesatisfied one unvalued literal.find relevant instance, set = U set satisfied unvaluedliterals. Taking k relevance bound corresponds search relevant instance.remainder theoretical material paper therefore focused twoproblems: computing stable extensions pair groups, solving k-transporterproblem. discuss techniques used solve two problems, presentbrief overview computational group theory generally.3. Computational Group Theorygroup theory large computational group theory specifically (the study effective computational algorithms solve group-theoretic problems) far broadallow detailed presentations single journal paper. generally referRotmans Introduction Theory Groups (1994) general information,Seress Permutation Group Algorithms (2003) computational group theory specifically, although many excellent texts areas. also abbreviatedintroduction group theory zap2.cannot substitute references, goal provide enoughgeneral understanding computational group theory possible workexamples follows. mind, three basic ideas hopeconvey:1. Stabilizer chains. underlie fundamental technique whereby large groupsrepresented efficiently. also underlie many subsequent computations doneusing groups.2. Group decompositions. Given group G subgroup H < G, H usednatural way partition G. partitions partitioned usingsubgroup H, on; gradual refinement underpins many search-basedgroup algorithms developed.3. Lex-leader search. general, possible establish lexicographic orderingelements permutation group; searching element groupparticular property (as k-transporter problem), assume without lossgenerality looking element minimal ordering.often allows search pruned, since portion searchshown contain minimal element eliminated.449fiDixon, Ginsberg, Hofer, Luks & Parkes3.1 Stabilizer Chainsfact group G described terms exponentially smaller numbergenerators attractive representational point view, many issuesarise large set clauses represented way. Perhaps fundamentalsimple membership: tell fixed clause c0 instanceaugmented clause (c, G)?general, instance 0-transporter problem; need g Gcg , image c g, intersect complement c0 . simplerclearly related problem assumes fixed permutation g cg = c0 ;g G not? Given representation G terms simply generators,obvious determined quickly.course, G represented via list elements, could sort elementslexicographically use binary search determine g included. Virtuallyproblem interest us solved time polynomial size groups involved,would like better, solving problems time polynomial total sizegenerators, therefore generally polynomial logarithm sizegroups (and polylog size original clausal database). call procedurepolynomial indeed polytime number generators G sizeset literals G acts. polynomial proceduresassured zaps representational efficiencies mature computational gains.4membership problem, determining g G given representation Gterms generators, need coherent way understanding structuregroup G itself. suppose G subgroup group Sym() symmetriesset , enumerate elements = {l1 , . . . , ln }.subset G[2] G fixes l1 h G[2] ,hl1 = l1 . easy see G[2] closed composition, since two elements fixl1 , composition. follows G[2] subgroup G. fact, have:Definition 3.1 Given group G acting set subset L , point stabilizerL subgroup GL G g G lg = l every l L. set stabilizerL subgroup G{L} G g G Lg = L.defined G[2] point stabilizer l1 , go define G[3]point stabilizer l2 within G[2] , G[3] fact point stabilizer {l1 , l2 } G.Similarly, define G[i+1] point stabilizer li G[i] thereby constructchain stabilizersG = G[1] G[2] G[n] = 1last group necessarily trivial n 1 points stabilized,last point must also.want describe G terms generators, assume describeG[i] terms generators, furthermore, generators G[i]superset generators G[i+1] . G[i+1] subgroup G[i] .4. development computationally efficient procedures solving permutation group problems appearsbegun Sims (1970) pioneering work stabilizer chains.450fiZAP 3: ImplementationDefinition 3.2 strong generating set group G Sym(l1 , . . . , ln ) setgenerators G propertyhS G[i] = G[i]= 1, . . . , n.usual, hgi denotes group generated gi .easy see generating set strong case property discussedabove, G[i] generated incrementally G[i+1] generatorsfact elements G[i] G[i+1] .example, suppose G = S4 , symmetric group 4 elements (whichdenote 1, 2, 3, 4). hard see S4 generated 4-cycle (1, 2, 3, 4)transposition (3, 4), strong generating set. G[2] subgroupS4 stabilizes 1 (and therefore isomorphic S3 , since randomly permuteremaining three points)hS G[2] = h(3, 4)i = G[3] 6= G[2](1)want strong generating set, need add (2, 3, 4) similar permutationgenerating set, (1) becomeshS G[2] = h(2, 3, 4), (3, 4)i = G[2]slightly interesting example. Given permutation, always possiblewrite permutation composition transpositions. One possible constructionmaps 1 supposed go, ignores rest construction,on. Thus example(1, 2, 3, 4) = (1, 2)(1, 3)(1, 4)(2)order composition left right, 1 maps 2 virtuefirst transposition left unaffected two, on.representation permutation terms transpositions unique,parity number transpositions is; permutation always representedproduct even odd number transpositions, both. Furthermore,product two transposition products lengths l1 l2 obviously representedproduct length l1 + l2 , follows product two even permutationseven, have:Definition 3.3 alternating group order n, denoted , subgroupeven permutations Sn .strong generating set ? fix first n 2 points,[n1]transposition (n 1, n) obviously odd, must= 1, trivial group.[i]smaller i, get subset taking generators Sn operatingnecessary transposition (n 1, n) make even. hard451fiDixon, Ginsberg, Hofer, Luks & Parkessee n-cycle odd n even (consider (2) above), given stronggenerating set{(n 1, n), (n 2, n 1, n), . . . , (2, 3, . . . , n), (1, 2, . . . , n)}Sn , strong generating set n odd{(n 2, n 1, n), (n 1, n)(n 3, n 2, n 1, n), . . . , (n 1, n)(2, 3, . . . , n), (1, 2, . . . , n)}n even{(n 2, n 1, n), (n 1, n)(n 3, n 2, n 1, n), . . . , (2, 3, . . . , n), (n 1, n)(1, 2, . . . , n)}simplify expressions slightly get{(n 2, n 1, n), (n 3, n 2, n 1), . . . , (2, 3, . . . , n 1), (1, 2, . . . , n)}n odd{(n 2, n 1, n), (n 3, n 2, n 1), . . . , (2, 3, . . . , n), (1, 2, . . . , n 1)}n even.Given strong generating set, easy compute size original group G.this, need following well known definition result:Definition 3.4 Given groups H G g G, define Hg set hgh H. g, say Hg (right) coset H G.Proposition 3.5 Let Hg1 Hg2 two cosets H G. |Hg1 | = |Hg2 |cosets either identical disjoint.words, given subgroup H group G, cosets H partition G.leads to:Definition 3.6 groups H G, index H G, denoted [G : H], numberdistinct cosets H G.Corollary 3.7 finite group G, [G : H] =|G||H| .Given cosets partition original group G, natural thinkdefining equivalence relation G, x x belongcoset H. have:Proposition 3.8 x xy 1 H.Proof. xy 1 = h H x coset Hg x = h0 g h0 H,= h1 x = h1 h0 g coset. Conversely, x = hg = h0 gcoset, xy 1 = hgg 1 h01 = hh01 H.Many equivalence relations groups form. Indeed, right invariantequivalence relation elements group G (so x y, xz yzz G), H G cosets H define equivalence relation.[i]Returning stabilizer chains, recall denote liG orbit li G[i](i.e, set points G[i] maps li ). have:452fiZAP 3: ImplementationProposition 3.9 Given group G acting set {l1 , . . . , ln } associated stabilizerchain G[1] G[n] ,[i]|G| =|liG |(3)Proof. know|G| =|G||G[2] | = [G : G[2] ]|G[2] ||G[2] |inductively|G| =[G[i] : G[i+1] ]easy see distinct cosets G[i+1] G[i] correspond exactly pointsG[i] maps li ,[i][G[i] : G[i+1] ] = |liG |result follows.Note expression (3) easy compute given strong generating set.example, given strong generating set {(1, 2, 3, 4), (2, 3, 4), (3, 4)} S4 , clear[3][2]S4 = h(3, 4)i orbit 3 size 2. orbit 2 S4 = h(2, 3, 4), (3, 4)i[1]size 3, orbit 1 S4 size 4. total size group 4! = 24, hardlysurprise.A4 , strong generating set {(3, 4)(1, 2, 3, 4), (2, 3, 4)} = {(1, 2, 3), (2, 3, 4)}.[2][1]orbit 2 A4 = h(2, 3, 4)i clearly size 3, orbit 1 A4 = A4size 4. |A4 | = 12. general, course, exactly two cosets alternatinggroup odd permutations constructed multiplying evenpermutations fixed transposition t. Thus |An | = n!/2.evaluate size using strong generators realizing orbit 1size n, 2 size n 1, on, orbit n 2 size 3.orbit n 1 size 1, however, since transposition (n 1, n) . Thus|An | = n!/2 before.also use strong generating set test membership following way.Suppose group G described terms strong generating set (and thereforestabilizer chain G[1] G[n] ), specific permutation . (1) = k,two possibilities:1. k orbit 1 G = G[1] , clearly 6 G.2. k orbit 1 G[1] , select g1 G[1] 1g1 = g1 (1) = k. construct1 = g11 , fixes 1, determine recursively 1 G[2] .end process, stabilized elements moved G,n+1 = 1. so, original G; not, 6 G. procedure knownsifting.Continuing example, let us see 4-cycle = (1, 2, 3, 4) S4 A4 .[1]former, see (1) = 2 (1, 2, 3, 4) S4 . produces 1 = 1,stop conclude S4 (once again, hardly surprise).453fiDixon, Ginsberg, Hofer, Luks & Parkes[1]second, know (1, 2, 3) A4 get 1 = (1, 2, 3, 4)(1, 2, 3)1 =(3, 4). could actually stop, since (3, 4) obviously odd, let us continueprocedure. Since 2 fixed 1 , 2 = 1 . 3 moved 4 2 ,[3]A4 trivial group, conclude correctly (1, 2, 3, 4) 6 A4 .3.2 Coset Decompositiongroup problems considering (e.g., k-transporter problem)subsume described zap1 subsearch (Dixon et al., 2004b; Ginsberg & Parkes,2000). Subsearch known NP-hard, follows k-transporter must well.suggests group-theoretic methods solving involve searchway.search involves potential examination instances augmentedclause (c, G), or, group theoretic terms, potential examination membergroup G. computational group theory community often approaches searchproblem gradually decomposing G smaller smaller cosets. callcoset decomposition tree produced, root tree entire group Gleaf nodes individual elements G:Definition 3.10 Let G group, G[1] G[n] stabilizer chain it. cosetdecomposition tree G tree whose vertices ith level cosets G[i]parent particular G[i] g coset G[i1] contains it.particular level i, cosets correspond points sequence hl1 , . . . , limapped, points image li identifying children particularnode level 1.example, suppose consider augmented clause(a b, Sym(a, b, c, d))(4)corresponding collection ground clausesabacadbcbdcdSuppose also working assignment b true cfalse, trying determine instance (4) unsatisfied. Assumingtake l1 l4 = d, coset decomposition tree associated S4following:454fiZAP 3: Implementationb, c, d)sPSym(a,PP@PP@PPPP@PP@PPPP (ad)Sym(b, c, d)(ab)s@P@s(ac)PsSym(c, d)s(bc)(bd)(bc)(bd)(bc)(bd)(bc)AAs(bd)111BBBBEEEEBBBBEEEEBBBBEEEEBBBBEEEEEEs BBs EEs BBs EEs BBs EEs BBs1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd)* *explanation notation surely order. nodes lefthandedge labeled associated groups; example, node level 2 labeledSym(b, c, d) point fixed b, c still allowedvary.move across row, find representatives cosets considered. moving across second row, first entry (ab) means takingcoset basic group Sym(b, c, d) obtained multiplying element (ab)right. coset maps uniformly b.lower rows, multiply coset representatives associated nodesleading root. third node third row, labeled (bd), correspondscoset Sym(c, d) (bd).5 two elements coset (bd) (cd)(bd) = (bdc).point b uniformly mapped d, fixed, c either fixed mapped b.fourth point row corresponds cosetSym(c, d) (ab) = {(ab), (cd)(ab)}point uniformly mapped b, b uniformly mapped a. cswapped not.fifth point cosetSym(c, d) (bc)(ab) = Sym(c, d) (abc) = {(abc), (abcd)}(5)still uniformly mapped b, b uniformly mapped c. c mappedeither d.fourth line, basic group trivial single member cosetobtained multiplying coset representatives path root. Thus ninthtenth nodes (marked asterisks tree) correspond permutations (abc)(abcd) respectively, indeed partition coset (5).5. here, occasionally denote group multiplication operator explicitly improveclarity typesetting.455fiDixon, Ginsberg, Hofer, Luks & ParkesUnderstanding structure used search straightforward. root,original augmented clause (4) may indeed unsatisfiable instances. movefirst child, know image a, instance clausequestion x x. Since true assignment question, followsclause must satisfied. similar way, mapping b also must produce satisfiedclause. search space already reduced to:b, c, d)sPSym(a,@PPPPP@PP@PPPP@PP@PP@s(ac)Ps(ad)1s1ss(bc) AAs(bd)s(bc) AAs(bd)BBEEBBEEEEBBBBEEEEBEs Bs Es BBsSym(b, c, d)s(ab)s1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd) 1 (cd)map c, first point next row corresponds mapping b b,producing satisfiable clause. map b (the next node; b mapped cnode c mapped permutation (ac) labeling parent), also getsatisfiable clause. map b d, eventually get unsatisfiable clause, althoughclear recognize without expanding two children. casemapped similar, final search tree is:Sym(a, b, c, d)P@PPPPP@PP@PPPP@PP(ac)@PP@sPs(ad)(bc)(bd)(bc)AAs(bd)1s1BEBEBEBEBBsEEsSym(b, c, d)(ab)s1 (cd)4561 (cd)fiZAP 3: ImplementationInstead six clauses might need examined instances original(4), four leaf nodes need considered. internal nodes prunedpruned without generation, since values need considerednecessarily c (the unsatisfied literals theory). level, then,search space becomes:Sym(a, b, c, d)P@PPPPP@PP@PPPP@PP(ac)@PP@sPs(ad)AAs(bd)s(bc)BEBEBEBEBBsEEs1 (cd)1 (cd)3.3 Lex LeadersAlthough remaining search space example already examines fewer leaf nodesoriginal, still appears redundancy. understand one possiblesimplification, recall searching group element g cg unsatisfiedgiven current assignment. Since group element suffices, (if wish)search group element smallest lexicographic ordering groupitself:Definition 3.11 Let G Sym() group, = 1 , . . . , n orderingelements . g1 , g2 G, write g1 < g2 jg1 = jg2j < ig1 < ig2 .Since ordering defined Definition 3.11 total order, immediately have:Lemma 3.12 Sym() ordered set , unique minimalelement.minimal element typically called lexicographic leader lex leader S.example, imagine solution (i.e., group element correspondingunsatisfied instance) right hand node depth three. wouldnecessarily also analogous solution preceding node depth three,since two search spaces sense identical. two hypothetical group elementswould identical except images b would swapped. Since group elementsleft hand node precede right hand node lexicographic457fiDixon, Ginsberg, Hofer, Luks & Parkesordering, follows lexicographically least element (which lookingfor) right hand node, therefore pruned. search spacebecomes:sPSym(a, b, c, d)@PPPPP@PP@PPPP@PP(ac)@PP@sPs(ad)AAs(bd)BBBBBBs1 (cd)particular technique quite general: whenever searching group element particular property, restrict search lex leaders setelements prune search space basis. Seress (2003) providescomplete discussion context problems typically considered computationalgroup theory; example context k-transporter problem specificallyfound Section 5.5.Finally, note two remaining leaf nodes equivalent, since referinstance know images b, overall instance fixedchoices relevant. assuming variables problem orderedclause considered first, finally prune search depththree get:sPSym(a, b, c, d)@PPPPP@PPPP@PP@PP@PPPs(ad)@s(ac)AAs(bd)single leaf node need considered.return application ideas zap, stressscratched surface computational group theory whole. field broad458fiZAP 3: Implementationdeveloping rapidly, implementation zap based ideas appearSeress gap code. Indeed, name chosen reflect zaps heritageoutgrowth zChaff Gap.64. Augmented Resolutionturn zap-specific requirements. First, definition augmentedresolution, involves computing group stable extensions groups appearingresolvents. Specifically, augmented clauses (c1 , G1 ) (c2 , G2 ) needcompute group G stable extensions G1 G2 . Recalling Definition 2.13,group permutations property g1 G1|cG1 = g1 |cG111similarly g2 , G2 c2 . viewing clauses ci sets, cGclosure ci Gi (recall Definition 2.12).example, consider two clauses(c1 , G1 ) = (a b, h(ad), (be), (bf )i)(c2 , G2 ) = (c b, h(be), (bg)i)2closure c1 G1 {a, b, d, e, f } cG= {b, c, e, g}. therefore need2find permutation restricted {a, b, d, e, f }, elementh(ad), (be), (bf )i, restricted {b, c, e, g} element h(be), (bg)i.second condition, know c cannot moved , permutationb, e g acceptable (be) (bg) generate symmetric group Sym(b, e, g).second restriction impact image a, f .first condition, know swapped left unchanged,permutation b, e f acceptable. recall second conditionmust also permute b, e g. conditions combine imply cannot move fg, since move either would break condition other. swap b enot, group stable extensions h(ad), (be)i, constructionreturn.Procedure 4.1 Given augmented clauses (c1 , G1 ) (c2 , G2 ), compute stab(ci , Gi ):6. authors zChaff Moskewicz, Madigan, Zhao, Zhang Malik; selection Zinclude acronym surely unfair Moskewicz, Madigan Malik. Zmap didnt quitering it, however, hope implicitly excluded authors accept apologieschoice.459fiDixon, Ginsberg, Hofer, Luks & Parkes123456789G21c closure1 cG1 , c closure2 c2g restrict1 G1 |c closure1 , g restrict2 G2 |c closure2C c closure1 c closure2g stab1 g restrict1{C } , g stab2 g restrict2{C }g int g stab1 |C g stab2 |C{gi } {generators g int}{l1i } {gi , lifted g stab1 }, {l2i } {gi , lifted g stab2 }0 } {l |{l2i2i c closure2 C }0 }ireturn hg restrict1C , g restrict2C , {l1i l2iProposition 4.2 result returned Procedure 4.1 stab(ci , Gi ).proof Appendix A; here, present example computation usediscuss computational issues surrounding Procedure 4.1. example usebegan section, modify G1 h(ad), (be), (bf ), (xy)i insteadearlier h(ad), (be), (bf )i. new points x dont affect set instancesway, thus affect resolution computation, either.11. c closurei cG1 . amounts computing closures ci Gi ;described earlier, c closure1 = {a, b, d, e, f } c closure2 = {b, c, e, g}.2. g restricti Gi |c closurei . Here, restrict group act corresponding c closurei . example, g restrict2 = G2 g restrict1 =h(ad), (be), (bf )i irrelevant points x removed.Note always possible restrict group arbitrary set; one cannotrestrict permutation (xy) set {x} need add well.case, possible restrict Gi c closurei , since latter set closedaction group.3. C c closure1 c closure2 . construction works considering threeseparate sets intersection closures two original clauses (wherecomputation interesting various must agree), pointsclosure c1 closure c2 . analysis latter setsstraightforward; need agree element G1 G2 setquestion.step, compute intersection region C . example, C = {b, e}.4. g stabi g restricti{C } . find subgroup g restricti set stabilizesC , case subgroup set stabilizes pair {b, e}. g restrict1 =h(ad), (be), (bf )i, h(ad), (be)i longer swap b f ,g restrict2 = h(be), (bg)i, get g stab2 = h(be)i.5. g int g stab1 |C g stab2 |C . Since must simultaneously agreeG1 G2 restricted C (and thus g restrict1 g restrict2well), restriction C must lie within intersection. example,g int = h(be)i.460fiZAP 3: Implementation6. {gi } {generators g int}. element g int lead elementgroup stable extensions provided extend appropriately C backG21full set cG1 c2 ; step begins process building extensions.suffices work generators g int, construct generatorshere. {gi } = {(be)}.7. {lki } {gi , lifted g stabk }. goal build permutationc closure1 c closure2 that, restricted C , matches generator gi .lifting gi separately c closure1 c closure2 . liftingsuffices, take (for example)l11 = (be)(ad)l21 = (be)first case, inclusion swap neither precluded required;could well used l11 = (be).0 } {l |8. {l2i2i c closure2 C }. cannot simply compose l11 l21 get desiredpermutation c closure1 c closure2 part permutations actingintersection c closure1 c closure2 acted twice. case,would get l11 l21 = (ad) longer captures freedom exchange b e.deal restricting l21 away C combining l11 .example, restricting (be) away C = {b, e} produces trivial permutation0 = ( ).l210 }i. compute final answer9. Return hg restrict1C , g restrict2C , {l1i l2i0three sources: combined l1i l2i working construct, alongelements g restrict1 fix every point closure c2 elementsg restrict2 fix every point closure c1 . latter two sets obviouslyconsist stable extensions. element g restrict1 point stabilizes closurec2 point stabilizes points closure c1 (tog restrict1 restricted) closure c2 ; words,point stabilizes C .example,g restrict1C= h(ad)ig restrict2C= 1{l1i0l2i}= {(be)(ad)}final group returnedh(ad), (be)(ad)igroup identical obvioush(ad), (be)i461fiDixon, Ginsberg, Hofer, Luks & Parkesswap either (a, d) pair (b, e) pair, see fit. first swap (ad)sanctioned first resolvent (c1 , G1 ) = (a b, h(ad), (be), (bf )i)mention relevant variable second (c2 , G2 ) = (c b, h(be), (bg)i). secondswap (be) sanctioned cases.Computational issues conclude section discussing computationalissues arise implement Procedure 4.1, including complexity variousoperations required.1. c closurei cG. Efficient algorithms exist computing closure setgroup. basic method use flood-fill like approach, adding markingresult acting set single generator, recurring new pointsadded.2. g restricti Gi |c closurei . group restricted set stabilizesrestricting generating permutations individually.3. C c closure1 c closure2 . Set intersection straightforward.4. g stabi g restricti{C } . Set stabilizer straightforward, knownpolynomial total size generators group considered(Seress, 2003).7 effective implementations work coset decompositiondescribed Section 3.2; computing G{S} set S, node prunedmaps point inside vice versa. Gap implements (butsee comments end Section 10.2).5. g int g stab1 |C g stab2 |C . Group intersection also known polynomial total size generators; again, coset decomposition used.Coset decompositions constructed groups combined,search spaces pruned appropriately. Gap implements well.6. {gi } {generators g int}. Groups typically represented termsgenerators, reconstructing list generators trivial. Even generatorsknown, constructing strong generating set known polynomialnumber generators constructed.7. {lki } {gi , lifted g stabk }. Suppose group G acting set ,subset V permutation h acting V know hrestriction V g G, h = g|V . find g, first constructstabilizer chain G using ordering puts elements V first.basically looking g G sifting procedure Section 3.1produces h point points V fixed. findg polynomial time inverting sifting procedure itself.0 } {l |8. {l2i2i c closure2 C }. line 2, restriction still easy.7. Unlike k-transporter problem, mentioned beginning Section 3.2 NP-hard,neither set stabilizer group intersection (see step 5) likely NP-hard (Babai & Moran, 1988).462fiZAP 3: Implementation0 }i. Since groups typically rep9. Return hg restrict1C , g restrict2C , {l1i l2iresented generators, need simply take union generatorsthree arguments. Point stabilizers (needed first two arguments) straightforward compute using stabilizer chains.5. Unit Propagation (Ir)relevance Testremarked, main computational requirement augmented satisfiability engine ability solve k-transporter problem: Given augmented clause(c, G) c viewed set literals, sets U literalsinteger k, want find g G cg = |cg U | k, g exists.5.1 Warmupbegin somewhat simpler problem, assuming U = simply lookingg cg = .need following definitions:Definition 5.1 Let H G groups. transversal H G subset Gcontains one element coset H. denote transversal (G : H).Note since H one cosets, transversal must contain (unique) elementH. generally assume identity unique element.Definition 5.2 Suppose G acts set c . cG denoteelements c fixed G.search proceeds, gradually fix points clause question.notation Definition 5.2 let us refer easily points fixed thusfar.Procedure 5.3 Given groups H G, element G, sets c S, find groupelement g = map(G, H, t, c, S) g H cgt = :12345678910ctH 6=return failurec = cHreturn 1element c cHt0 (H : H )r map(G, H , t0 t, c, S)r 6= failurereturn rt0return failure463fiDixon, Ginsberg, Hofer, Luks & Parkesessentially codification example presented Section 3.2.terminate search clause fixed remaining group H,yet included analog lex-leader pruning discussed Section 3.3.recursive call line 7, retain original group, use subsequentversions procedure.precise description procedure would state explicitly G acts cS, G Sym() c, . elsewhere, believe conditionsobvious context elected clutter procedural descriptionsthem.Proposition 5.4 map(G, G, 1, c, S) returns element g G cg = ,element exists, returns failure otherwise.Proof. proof Appendix shows slightly stronger result map(G, H, t, c, S)returns element g H cgt = element exists.Given procedure terminates search elements c stabilizedG include lex-leader considerations, search space examinedexample Section 3.2 following, replaced variables a, b, c,x1 , x2 , x3 , x4 avoid confusion current use c represent clausequestion.Sym(x1 , x2 , x3 , x4 )P@PPPPP@PP@PPPP@PP@PP@s(x1 x3 )Ps(x1 x4 )AAs(x2 x4 )s(x2 x3 )still important prune node lower right, since larger problem, nodemay expanded significant search subtree. discuss pruning Section 5.5.interests clarity, let us go example explicitly. Recall clausec = x1 x2 , G = Sym(x1 , x2 , x3 , x4 ) permutes xi arbitrarily, = {x1 , x2 }.initial pass procedure, cH = ; suppose select x1 stabilizefirst. Line 6 selects point x1 mapped; select x1 x2 ,x1 mapped recursive call fail line 2. suppose pickx3 image x1 .cH = {x1 }, need fix image another point; x2 thats leftoriginal clause c. before, selecting x1 x2 image x2 leads failure. x3already taken (its image x1 ), map x2 x4 . every elementc fixed, next recursive call returns trivial permutation line 4.combined (x2 x4 ) line 9 caller fix x4 image x2 . originalinvocation combines (x1 x3 ) produce final answer (x2 x4 )(x1 x3 ).464fiZAP 3: Implementation5.2 k-Transporter ProblemExtending algorithm solve k-transporter problem straightforward;addition requiring ctH = line 2, also need keep track numberpoints (or be) mapped set U make sure wontforced exceed limit k.understand this, suppose examining node coset decompositiontree labeled permutation t, node corresponds permutations gtvarious g subgroup considered level. want ensureg |cgt U | k. Since cgt assumed avoid set completely,replace slightly stronger|cgt (S U )| kturn equivalent1|cg (S U )t | k(6)(7)since set (7) simply result operating set (6) permutationt1 .present variety ways bound (7) approximated;moment, simply introduce auxiliary function overlap(H, c, V ), assumecomputes lower bound |ch V | h H. Procedure 5.3 becomes:Procedure 5.5 Given groups H G, element G, sets c, U integerk, find group element g = transport(G, H, t, c, S, U, k) g H, cgt =|cgt U | k:123456789101112ctH 6=return failure1overlap(H, c, (S U )t ) > kreturn failurec = cHreturn 1element c cHt0 (H : H )r transport(G, H , t0 t, c, S, U, k)r 6= failurereturn rt0return failureconvenience, denote transport(G, G, 1, c, S, U, k) transport(G, c, S, U, k).top level function corresponding original invocation Procedure 5.5.Proposition 5.6 Provided |ch V | overlap(H, c, V ) |cH V | h H,transport(G, c, S, U, k) computed Procedure 5.5 returns element g Gcg = |cg U | k, element exists, returns failure otherwise.465fiDixon, Ginsberg, Hofer, Luks & Parkessecond condition overlap (that overlap(H, c, V ) |cH V |) needed ensureprocedure terminates line 4 overlap limit reached, rathersucceeding line 6.Procedure 5.5 simplified significantly fact need return single gdesired properties, opposed g. examples arising (ir)relevancecalculations, single answer suffices. want compute unit consequencesgiven literal, need unit instances clause question.considerations work case, however, defer discussion topicSection 6.initial version overlap is:Procedure 5.7 Given group H, two sets c, V , compute overlap(H, c, V ), lowerbound overlap ch V h H:1return |cH V |defined overlap, may well use replace test line 1 Proce1dure 5.5 check see overlap(H, c, ) > 0, indicating h H,1|ch | > 0 or, equivalently, cht 6= . simple version overlap definedabove, difference two procedures. overlap matures,change lead additional pruning cases.5.3 Orbit Pruningtwo general ways nodes pruned k-transporter problem.Lexicographic pruning bit difficult, defer Section 5.5. understandother, begin following example.Consider clause c = x1 x2 x3 group G permutes variables{x1 , x2 , x3 , x4 , x5 , x6 } arbitrarily. = {x1 , x2 , x3 , x4 }, g G cg = ?Clearly not; isnt enough room image c size three,way 3-element set avoid 4-element set 6-elementuniverse {x1 , x2 , x3 , x4 , x5 , x6 }.bit better many cases. Suppose group G h(x1 x4 ), (x2 x5 ), (x3 x6 )iswap x1 x4 (or not), x2 x5 , x3 x6 . = {x1 , x4 },find g G cg = ?again, answer clearly no. orbit x1 G {x1 , x4 } since {x1 , x4 }S, x1 image cannot avoid set S.general case appearing Procedure 5.5, consider initial call,identity permutation. Given group G, consider orbits points c.orbit W |W c| > |W S|, prune search. reasonpoints W c must remain W acted element G;definition orbit requires. many points W c stayaway S, manage cg = .general case, 6= 1 necessarily? fixed clause c,construct image gt , acting first g t. interested466fiZAP 3: Implementation1whether gt or, equivalently, g . g necessarily orbit, prune1|W c| > |W |similar reasons, also prune1|W c| > |W U | + kfact, prune1|W c| > |W (S U )t | + kstill enough space fit image without either intersectingputting least k points U .better still. seen, particular orbit, number pointseventually mapped U least1|W c| |W (S U )t |cases, expression negative; number points mappedU therefore least1max(|W c| |W (S U )t |, 0)prune nodeX1max(|W c| |W (S U )t |, 0) > k(8)Wsum orbits group.somewhat convenient rewrite using fact11|W c| + |W c| = |W | = |W (S U )t | + |W (S U )t |(8) becomesX1max(|W (S U )t | |W c|, 0) > k(9)WIncorporating type analysis Procedure 5.7 gives:Procedure 5.8 Given group H, two sets c, V , compute overlap(H, c, V ), lowerbound overlap ch V h H:1234m0orbit W H+ max(|W V | |W c|, 0)returnProposition 5.9 Let H group c, V sets acted H. h H,|ch V | overlap(H, c, V ) |cH V | overlap computed Procedure 5.8.467fiDixon, Ginsberg, Hofer, Luks & Parkes5.4 Block Pruningpruning described previous section improved further. see why, considerfollowing example, might arise solving instance pigeonhole problem.two cardinality constraints:x1 + x2 + x3 + x4 2(10)x5 + x6 + x7 + x8 2(11)presumably saying least two four pigeons hole least twohole n n.8 Rewriting individual cardinality constraintsaugmented clauses produces(x1 x2 x3 , Sym(x1 , x2 , x3 , x4 ))(x5 x6 x7 , Sym(x5 , x6 , x7 , x8 ))or, terms generators,(x1 x2 x3 , h(x1 x2 ), (x2 x3 x4 )i)(12)(x5 x6 x7 , h(x5 x6 ), (x6 x7 x8 )i)(13)would really like do, however, capture full symmetry single axiom.realizing obtain (13) (12) switching x1 x5 ,x2 x6 , x3 x7 (in case want switch x4 x8 well). addgenerator (x1 x5 )(x2 x6 )(x3 x7 )(x4 x8 ) overall group, modify permutations(x1 x2 ) (x2 x3 x4 ) (which generate Sym(x1 , x2 , x3 , x4 )) permute x5 , x6 , x7 , x8appropriately well. single augmented clause obtain(x1 x2 x3 , h(x1 x2 )(x5 x6 ), (x2 x3 x4 )(x6 x7 x8 ), (x1 x5 )(x2 x6 )(x3 x7 )(x4 x8 )i)(14)hard see indeed capture (12) (13).suppose x1 x5 false, variables unvalued. (14)unit instance?regard pruning condition previous section, group singleorbit, condition (with = 1)|W (S U )| |W c| > 1(15)W= {x1 , x2 , x3 , x4 , x5 , x6 , x7 , x8 }=U= {x2 , x3 , x4 , x6 , x7 , x8 }c = {x1 , x2 , x3 }8. actual pigeonhole instance, variables would negated. dropped negationsconvenience.468fiZAP 3: Implementation|W (S U )| = 6, |W c| = 5 (15) fails.possible conclude immediately unit instances(14). all, unit instances (10) (11) one variableclause set, three unvalued variables remain. Equivalently,unit instance (12) one {x1 , x2 , x3 , x4 } valued, two needvalued make x1 x2 x3 another instance unit. Similarly, unit instance(13). went wrong?went wrong pruning heuristic thinks x1 x5mapped clause instance, case indeed possible instancequestion unit. heuristic doesnt realize x1 x5 separate blocksaction group question.formalize this, let us first make following definition:Definition 5.10 Suppose G acts set . say G acts transitivelyorbit G.Put somewhat differently, G acts transitively case x,g G xg = y.Definition 5.11 Suppose group G acts transitively set . block systemG partitioning sets B1 , . . . , Bn G permutes Bi .words, g G block Bi , Big = Bj j. j = i,image Bi g Bi itself. j 6= i, image Bi g disjointBi , since blocks partition .Every group acting transitively nontrivially set least two block systems:Definition 5.12 group G acting transitively set , block system B1 , . . . , Bncalled trivial either n = 1 n = |T |.former case, single block consisting entire set (which obviouslyblock system). n = |T |, point block; since G permutes points,obviously permutes blocks.Lemma 5.13 blocks block system identical size.example considering, B1 = {x1 , x2 , x3 , x4 } B2 = {x5 , x6 , x7 , x8 }also block system action group set = {x1 , x2 , x3 , x4 , x5 , x6 , x7 , x8 }.conceivable clause image unit within overall set , impossiblefewer two unvalued literals within particular block. Insteadlooking overall expression|W (S U )| |W c| > 1work individual blocks.469(16)fiDixon, Ginsberg, Hofer, Luks & Parkesclause x1 x2 x3 single block block system, therefore remainsingle block acted g G. clause winds block Bi ,condition (16) replaced|Bi (S U )| |Bi c| > 1or, case,|Bi (S U )| > |Bi c| + 1 = 2prune two unvalued literals block question.all, three unvalued literals, must least twoclause instance considered, cannot unit.course, dont know exactly block eventually contain image c,still prunemin(|Bi (S U )|) > 2since case target block generate prune. exampleconsidering,|Bi (S U )| = 3block block system.Generalizing idea straightforward. notational convenience, introduce:Definition 5.14 Let = {T1 , . . . , Tk } sets,Ti1 , . . . , Tin nPnsuppose minelements smallest size. denote j=1 |Tij | Ti .Proposition 5.15 Let G group acting transitively set , let c, V .Suppose also {B1 , . . . , Bk } block system G c Bi 6= nblocks {B1 , . . . , Bk }. b size individual block Bi g G,|cg V | |c| + min(Bi V ) nb(17)Proposition 5.16 block system trivial (in either sense), (17) equivalent|cg V | |T V | |T c|(18)Proposition 5.17 Let {B1 , . . . , Bk } block system group G acting transitivelyset . (17) never weaker (18).event, shown strengthen Procedure 5.8 to:Procedure 5.18 Given group H, two sets c, V , compute overlap(H, c, V ),lower bound overlap ch V h H:470fiZAP 3: Implementation123456m0orbit W H{B1 , . . . , Bk } block system W Hn = |{i|Bi c 6= }|+ max(|c W | + min(Bi V ) n|B1 |, 0)returnblock system use line 3 procedure? seemsgeneral best answer question, although seen Proposition 5.17block system better one trivial ones. practice, best choice appearsminimal block system (i.e., one blocks smallest size) c containedwithin single block. Procedure 5.18 becomes:Procedure 5.19 Given group H, two sets c, V , compute overlap(H, c, V ),lower bound overlap ch V h H:12345m0orbit W H{B1 , . . . , Bk } minimal block system W Hc W Bi+ max(|c W | + min(Bi V ) |B1 |, 0)returnProposition 5.20 Let H group c, V sets acted H. h H,|ch V | overlap(H, c, V ) |cH V | overlap computed Procedure 5.19.Note block system used depends group H originalclause c. means implementation possible compute blocksystems use even changes sets U satisfiedunvalued literals respectively.Gap includes algorithms finding minimal block systems given setelements (called seed gap) contained within single block. basic ideaform initial block system points seed one block pointoutside seed block own. algorithm repeatedly runsgenerators group, seeing generator g maps elements x, one blockxg g different blocks. happens, blocks containing xg gmerged. continues every generator respects candidate block system,point procedure complete.95.5 Lexicographic PruningBlock pruning help us example end Section 5.1. final spacesearched is:9. faster implementation makes use procedure designed testing equivalence finite automata (Aho, Hopcroft, & Ullman, 1974, chapter 4) takes O(snA(n)) time, sizegenerating set A(n) inverse Ackerman function.471fiDixon, Ginsberg, Hofer, Luks & ParkessPSym(a, b, c, d)@PPPPP@PP@PPPP@PP(ac)@PP@sPs(ad)AAs(bd)s(bc)remarked, first leaf node (where mapped c b d) essentiallyidentical second (where mapped b c). important expandsince complicated examples may involve substantial amount searchnodes leaf nodes figure.sort situation lexicographic pruning generally applied.want identify two leaf nodes equivalent way, expandlexicographically least member equivalence class. particular node n,need computationally effective way determining n lexicographically leastmember equivalence class.begin identifying conditions two nodes equivalent. understandthis, recall interested image clause c particular groupelement g. means dont care particular literal l mapped,care image entire clause c. also dont careimage literal isnt c.formal point view, begin extending set stabilizer notation somewhat:Definition 5.21 permutation group G sets S1 , . . . , Sk acted G, G{S1 ,...,Sk }mean subgroup G simultaneously set stabilizes Si ; equivalently, G{S1 ,...,Sk } = G{Si } .computing multiset stabilizer G{S1 ,...,Sk } = G{Si } , need compute individual set stabilizers take intersection. Instead, recall set stabilizerscomputed using coset decomposition; stabilized point moved eitherset question, given node pruned set stabilizer computation. straightforward modify set stabilizer algorithm stabilizedpoint moved Si , node question pruned. allowsG{S1 ,...,Sk } computed single traversal Gs decomposition tree.suppose j permutation G stabilizes set c. cg satisfiesconditions transporter problem, cjg . all, acting j first doesntaffect set corresponding c, image clause jg therefore identicalimage g. means two permutations g h equivalent h = jgj G{c} , set stabilizer c G. Alternatively, permutation g equivalentelement coset Jg, J = G{c} .hand, suppose k permutation simultaneously stabilizessets U satisfied unvalued literals respectively. possible show472fiZAP 3: Implementationoperate k operating successfully g, also dont impact questionwhether cg solution transporter problem. upshotfollowing:Definition 5.22 Let G group J G K G, let g G. doublecoset JgK set elements G form jgk j J k K.Proposition 5.23 Let G group permutations, c set acted G. Supposealso U sets acted G. instance k-transporterproblem g G, either every element G{c} gG{S,U } solution I, none is.understand important, imagine prune overall search treepermutations g remaining ones minimal double cosetsJgK, J = G{c} K = G{S,U } above. impact solubilityinstance k-transporter problem?not. particular instance solutions, pruning tree obviouslyintroduce any. particular instance solution g, every element JgKalso solution, specifically minimal element JgK solution, minimalelement pruned assumptions.see, then, prune node n show every permutation g underneath n minimal double coset JgK. state precise conditionslets us prune node n, suppose coset decompositiongroup G, xj point fixed depth j tree. n nodedepth tree, know n corresponds coset Ht G, H stabilizesxj j i. denote image xj zj . g Htminimal double coset JgK J = G{c} K = G{S,U } Proposition 5.23,node n corresponding Ht pruned.Jx,...,xk1Lemma 5.24 (Leon, 1991) xl xk 1g Ht first element JgK.Kz1 ,z2 ,...,zk1k l zk > min(zlJx),,...,xLemma 5.25 (reported Seress, 2003) Let length orbit xl 1 l1 .zl among last 1 elements orbit Gz1 ,z2 ,...,zl1 , g Ht firstelement JgK.results give conditions node coset decompositionpruned searching solution instance k-transporter problem. Letus consider example each.begin Lemma 5.24. return example end Section 5.1,G = Sym(a, b, c, d), c = {a, b} = S, U = . Thus J = K = G{a,b} =Sym(a, b) Sym(c, d) = h(ab), (cd)i.Consider node repeatedly remarked pruned depth 1,fix image d. case, x1 = z1 = d. take k = lJx ,...,xstatement lemma, xl xl 1 l1 since 1 Jx1 ,...,xl1 . Thus pruneKz1 ,z2 ,...,zl1zl > min(zl473)fiDixon, Ginsberg, Hofer, Luks & Parkesrestricting l = 1 gives usz1 > min(z1K )(19)example, z1 = d, z1K = {c, d} (19) holds (assuming > c ordering).node pruned, finally get reduced search space:sPSym(a, b, c, d)@PPPPP@PP@PPPP@PP@PP@s(ac)Ps(ad)AAs(bd)desired.node pruned Lemma 5.25 well. conditions lemma requiretake length orbit J (since l = 1 here), = |{a, b}| = 2.Thus image cannot among last 2 1 = 1 points orbit G. Sinceorbit G {a, b, c, d}, prune node. (The previousnode, maps c, cannot pruned, course.)particular example simple. nodes examined depth one,significant overlap groups question. node prunedeither lemma here, lemmas prune different nodes complex cases. Note alsogroups J = G{c} K = G{S,U } computed root tree,group J independent sets U therefore cached augmentedclause (c, G).Lemmas 5.24 5.25 well known results computational group theorycommunity. also use following:Lemma 5.26 Suppose permutation labeling node Ht coset decomgroupposition tree depth k, xti = zi k H = Gx1 ,...,xk residualJM,x1 ,...,xi1level. Let set points moved Gx1 ,...,xk . zi > min xik, g Ht first element JgK.example, consider cardinality constraintx1 + + xm ncorresponding augmented clause (c, G)c = x1 xmn+1G = Sym(X), X set xi .474fiZAP 3: ImplementationSuppose fix images xi order, considering nodeimage x1 fixed z1 image x2 fixed z2 , z2 < z1 .J = G{c} = Sym(x1 , . . . , xmn+1 ) Sym(xmn+2 , . . . , xm ), taking = 1 k = 2Lemma 5.26 gives us Jxk+1 ,...,xm = Sym(x1 , x2 ) since need fix xj x2 .Jx,...,xm= {z1 , z2 }, since z1 smallest element set,x1 k+1enough prune node. See proof Proposition 6.9 another example.refer Lemmas 5.245.26 pruning lemmas.Adding lexicographic pruning k-transporter procedure gives us:Procedure 5.27 Given groups H G, element G, sets c, U integerk, find group element g = transport(G, H, t, c, S, U, k) g H, cgt =|cgt U | k:12345678910111213141overlap(H, c, ) > 0return failure1overlap(H, c, (S U )t ) > kreturn failurec = cHreturn 1pruning lemma appliedreturn failureelement c cHt0 (H : H )r transport(G, H , t0 t, c, S, U, k)r 6= failurereturn rt0return failureNote test line 7 requires access groups J K, thereforeoriginal group G procedure called. retain copygroup recursive call line 11.might seem brought much mathematical power beark-transporter problem specifically, disagree; recall Figure 1, repeated zap1.High-performance satisfiability engines, running difficult problems, spend excess90% CPU time unit propagation, seen instancek-transporter problem. Effort spent improving efficiency Procedure 5.27 (andpredecessors) expected lead substantial performance improvementspractical application. See also Figure 8 experimental results Section 9.2.do, however, note lexicographic pruning important, also expensive.defer line 7 Procedure 5.27. earlier lexicographic prune wouldindependent U sets, count-based pruning much fasterdefer lexicographic check extent possible.475fiDixon, Ginsberg, Hofer, Luks & Parkes100ZCHAFF data% time spent9590858075700102030405060708090total CPU time (sec)Figure 1: Fraction CPU time spent unit propagation6. Unit PropagationProcedure 5.27 designed around need find single permutation g G satisfyingconditions k-transporter problem, technically suffices zaps needs.unit propagation, however, useful collect unit consequencesaugmented clause (c, G) once, opposed collecting via repeated traversalsGs coset decomposition tree.work consequences observation, help exampleillustrates points going making. end, consideraugmented clause(a b e, Sym(a, b, c, d) Sym(e, f ))(20)situation a, b c false d, e f unvalued. group (20)allows arbitrary permutations {a, b, c, d} {e, f }, e f unitconsequences instances given augmented clause.Note cannot simply collect group elements associated unitinstance, since many group elements may correspond clause instance cgunit literal cg U . example, ( ) (ab) correspondidentical clause b e, clause c e lead conclusion egiven current partial assignment.goal therefore compute set permutations, associated setunit conclusions:Definition 6.1 Let (c, G) augmented clause, P partial assignment. unitconsequences (c, G) given P set literals l g Gcg S(P ) = cg U (P ) = {l}. fixed literal w, unit w-consequences (c, G)given P set literals l g G w cg , cg S(P ) =cg U (P ) = {l}.476fiZAP 3: Implementationunit w-consequences involve additional requirement literal w appearclause instance question. useful discuss watched literals nextsection.example, unit consequences (20) e f . unit c-consequencessame, although longer use identity permutation ( ), since needed cbase instance (20). unit d-consequences (20).partial assignment annotated, need unit consequences,reasons well:Definition 6.2 Let X set pairs hl, gi, g G l literal pair.X = {hl1 , g1 i, . . . , hln , gn i}, denote {l1 , . . . , ln } L(X).(c, G) augmented clause P partial assignment, X called annotated set unit consequences (c, G) given P if:1. cg S(P ) = cg U (P ) = {l} every hl, gi X2. L(X) set unit consequences (c, G) given P .returning example, he, ( )i annotated consequence, he, (abc)i.hf, (ef )i hf, (abc)(ef )i. set {he, (abc)i, hf, (ef )i} annotated set unitconsequences, {he, (abc)i, hf, (ef )i, hf, (abc)(ef )i}. {hf, (ef )i, hf, (abc)(ef )i}annotated set unit consequences, since e appear consequence.modify k-transporter procedure search entire treeaccumulating annotated set unit consequences. need careful, however,pruning lemmas may prune node includes permutation gminimal double coset JgK. problem g minimal elementJgK may correspond distinct unit consequences. running example, may wellnone minimal elements JgK supports f conclusion; accumulateminimal elements, get full set unit consequences result.Given successful g minimal double coset, reconstructing relevantorbits J K easy, begin introducing definitions cater this.basic idea want minimal g entail, sense, conclusionsdrawn permutations double coset JgK.example, subgroup G simultaneously stabilizes U G{S,U } =Sym(a, b, c) Sym(e, f ). permutation g1 allows us conclude e,operate g1 (ef ) g1 G{S,U } conclude f well. formalize follows:Definition 6.3 Given group G, say hl1 , g1 G-entails hl2 , g2 i, denotedhl1 , g1 |=G hl2 , g2 i, g G l2 = l1g g2 = g1 g. sayset pairs X G-entails set pairs , writing X |=G , every pair G-entailedpair X.skeletal set unit consequences (c, G) given P set X unit consequencesG{S(P ),U (P )} -entails annotated set unit consequences (c, G) given P .running example, l1 = e g = (ef ) first paragraph, allowing(for example) he, ( )i G{S,U } -entail hf, (ef )i. Thus see {he, ( )i} skeletal setunit consequences (20) given partial assignment {a, b, c}.477fiDixon, Ginsberg, Hofer, Luks & ParkesLemma 6.4 X |=G , L(Y ) L(X)G .Proof. Every pair form hl1g , g1 gi hl1 , g1 X g G. Thusassociated literal L(X)G .construct full set unit consequences skeletal set, repeatedly find newunit conclusions possible:Procedure 6.5 Given set X pairs hl, gi group G, compute complete(X, G),X |=G complete(X, G) L(complete(X, G)) = L(X)G :123456hl, gi Xl0 lG L(Y )select h G lh = l0hl0 , ghireturnProposition 6.6 X |=G complete(X, G) L(complete(X, G)) = L(X)G .apply pruning lemmas search proceeds, eventually returningskeletal set unit consequences clause question. addition, unitinstance fact unsatisfiable, return failure marker sort.handle returning two values. first indicates whether contradictionfound, second skeletal set unit consequences.Procedure 6.7 Given groups H G, element G, sets c, U , findTransport(G, H, t, c, S, U ), skeletal set unit consequences (c, G) given P :1234567891011121314151617181overlap(H, c, ) > 0return hfalse,1overlap(H, c, (S U )t ) > 1return hfalse,c = cHct U =return htrue, 1ielse return hfalse, hct U, 1iipruning lemma appliedreturn hfalse,element c cHt0 (H : H )hu, V Transport(G, H , t0 t, c, S, U )u = truereturn htrue, V t0else {hl, gt0 i|hl, gi V }return hfalse,478fiZAP 3: ImplementationProposition 6.8 Assume |ch V | overlap(H, c, V ) |cH V | h H,let Transport(G, c, S, U ) computed Procedure 6.7. g Gcg = cg U = , Transport(G, c, S, U ) = htrue, gi g.g, Transport(G, c, S, U ) = hfalse, Zi, Z skeletal set unit consequences(c, G) given P .application pruning lemmas, have:Proposition 6.9 Let (c, G) augmented clause corresponding cardinality constraint. sets U , Procedure 6.7 expand linear numbernodes finding skeletal set unit consequences (c, G).original formulation cardinality constraints (as zap1), determiningparticular constraint unit (and finding implied literals so) takes time linearlength constraint, since involves simple walk along constraint itself.therefore seems appropriate linear number nodes expanded case.7. Watched Literalsone pruning technique yet considered, possibilityfinding analog setting Zhang Stickels (2000) watched literal idea.understand basic idea, suppose checking see clause b cunit situation b unvalued. follows clause cannot unit,independent value assigned c.point, watch literals b; long remain unvalued,clause cannot unit. practice, data structures representing b include pointerclause question, unit test needs performed clauses pointedliterals changing value.continue discuss ideas, useful distinguish among three differenttypes clauses: satisfied given current partial assignment,unit, neither:Definition 7.1 Let C clause, P (possibly annotated) partial assignment.say C settled P either satisfied unit; otherwise unsettled.have:Definition 7.2 Let C clause, P (possibly annotated) partial assignment. Cunsettled P , watching set C P set literals W|W C U (P )| > 1.words, W contains least two unvalued literals C C unsettledcurrent partial assignment.C satisfied unit? watching set case?sense, doesnt matter. Assuming notice clause changesunsettled unit (so either unit propagate detect potential contradiction),479fiDixon, Ginsberg, Hofer, Luks & Parkessettled clauses uninteresting perspective, since never generatesecond unit propagation. watch settled clause not, see fit.another sense, however, matter. One properties would likewatching sets remain valid backtrack. meanssettled clause C becomes unsettled backtrack, must two watchedunvalued variables backtrack.order discuss backtracking formal way, introduce:Definition 7.3 Let P partial assignment set (possibly augmented) clauses.say P -closed clause C unit consequence given P .-closure P minimal, sound -closed extension P , denotedeither PT simply P clear context.definition closure makes sense intersection two closed partialassignments closed well. compute closure, simply add unit consequencesone time available. Note still ambiguity;one unit consequence added point, add unitconsequences order.Definition 7.4 Let P = hl1 , . . . , ln partial assignment. subassignment Pinitial subsequence hl1 , . . . , lj j n. say subassignment P 0 Pbacktrack point P either P 0 = P P 0 = P 0 . denote P largestbacktrack point P P itself.C clause, say P -retraction C, denoted PC , largestbacktrack point P C unsettled.Note require backtrack point C unsettled, opposed simplyunsatisfied. P closed, difference Definition 7.4 permitbacktrack point C unit. C unit P , retract Creverting point C became unit. Otherwise, C simply reassertedunit propagation computes P .Since P backtrack point P , immediately have:Lemma 7.5 C unsettled P , PC = P .example, suppose following annotated partial assignment P :literalbcereasontruetrueb ctrueb eclause C b e f , P -retraction C ha, b, ci. Removing e sufficientmake C unsettled, ha, b, c, di closed therefore legal backtrack point.b e theory, retraction fact hai ha, b, ci backtrackpoint unit conclusion e drawn.generalize Definition 7.2 include settled clauses:480fiZAP 3: ImplementationDefinition 7.6 Let C clause, P annotated partial assignment. watching setC P set literals W |W C U (PC )| > 1.words, W contain least two unvalued literals C replace PP -retraction C. discussed earlier, first point could backtrackC longer satisfied unit. Continuing earlier example, {e, f } watchingset b e f , {b, e} watching set b e. watching set b e {b, e};recall definition forces us backtrack way hai.Lemma 7.7 W watching set C P , superset W .order watching sets useful, course, must maintain searchproceeds. Ideally, maintenance would involve modifying watching sets infrequently possible, could adjust required variables take newvalues, backtracking all. Recall example beginningsection, b unvalued constitute watching set clause b c.b becomes satisfied, need nothing since clause satisfied {a, b}still watching set. Note (for example) becomes satisfied, cant remove bwatching set, since would need replace backtrack pointunvalued again. Leaving b watching set required satisfy Definition 7.6needed ensure sets need adjusted backtrack.hand, (for example) becomes unsatisfied, need check clausesee whether become unit. clause unit, b set trueunit propagation, maintenance required. clause unsettled, c mustunvalued, replace c set literals watching clause. Finally,clause already satisfied, unvalued P -retraction clausewatching set need modified.general, have:Proposition 7.8 Suppose W watching set C P l literal. Then:1. W watching set C backtrack point P .2. C settled hP, li, W watching set C hP, li.3. C settled hP, li, |(W {l}) C U (PC )| > 1, W {l}watching set C hP, li.4. l 6 W C, W watching set C hP, li.proposition tells us modify watching sets search proceeds.modification required backtrack (claim 1). modification requiredclause satisfied unit (claim 2), also remove newly valued literalwatching set enough unvalued variables present (claim 3). modificationrequired unless add negation already watched literal (claim 4).sum, modification watching sets required add negationwatched literal partial assignment watched clause settled; case,481fiDixon, Ginsberg, Hofer, Luks & Parkesadd one remaining unvalued literals watching set. addition,remove literals watching set enough unvalued literals already it. Sincelast possibility used zChaff ground systems, exampleit.Suppose are, usual, watching b b c. point, becomestrue. either leave watching set alone virtue condition 4, extendwatching set include c (extending watching set always admissible, virtueLemma 7.7), remove watching set. change unneeded groundprover, useful augmented version 7.10 proposition below.lift ideas augmented setting, begin modifying Definition 7.6obvious way get:Definition 7.9 Let (c, G) augmented clause, P annotated partial assignment.watching set (c, G) P set literals W watching set everyinstance cg (c, G) P .leads following augmented analog Proposition 7.8. (Althoughfour clauses Proposition 7.8 four following proposition, clause-forclause correspondence two results.)Proposition 7.10 Suppose W watching set (c, G) P l literal.Then:1. W watching set (c, G) backtrack point P .2. l 6 W cG , W watching set (c, G) hP, li.3. |(W V ) cg U (hP, li)| > 1 every g G cg unsettled hP, li,W V watching set (c, G) hP, li.4. |(W V ) cg [U (hP, li) (S(P ) S(P ))]| > 1 every g G, W V {l}watching set (c, G) hP, li.example, suppose return augmented clause consideredprevious section, (abe, Sym(a, b, c, d)Sym(e, f )). Suppose initially watchinga, b, c d, e false, imagine becomes false well.need augment W |W cg U (P )| > 1 every unsettled instance cg(c, G) contains a. instances b f , c f f . Since b, calready W , need add f . f watching set b, cd, would add three points instead.case, since clause unit instance (a b e, example), cannotremove watching set. reason later backtrack pastpoint, danger watching b unsatisfied clause.Suppose, however, e unvalued became false. wouldadd e f watching set would free remove a. sanctionedProposition 7.10, since (c, G) settled instances cg S(P ) = g Gwell, conditions claims three four equivalent.482fiZAP 3: Implementatione, instead false unvalued, true? add fwatching set, remove new watching set {a, b, c, d, f }? cannot:instance b e would one watched literal did.cases, however, remove literal became falsewatching set. surely every clause instance still two unvalued literalswatching set. would correspond requirement|(W V ) cg U (hP, li)| > 1every instance. stronger condition claim four proposition allows usslightly better cases satisfied literal clause became satisfied sufficientlyrecently know backtrack unvalue it.fourth conclusion Proposition 7.10 essential effective functioningoverall prover; replace watched literal l become false newunvalued literal, important stop watching original watched literal l.last claim proposition allows us (although all)practical cases. Without fourth conclusion, watching sets would get largersearch proceeded. Eventually, every literal every clause would watchedcomputational power idea would lost.use watching sets reduce number clauses must examined line 1 unit propagation procedure 2.7. augmented clause needsassociated watching set initialized updated sanctioned Proposition 7.10.Initialization straightforward; clause (c, G) c length least two,need define associated watching set W property |W cg | > 1 everyg G. fact, take W simply cG , union instances cg ,rely subsequent unit tests gradually reduce size W . (Once again, usingfourth clause Proposition 7.10.) challenge modify Procedure 6.7 wayfacilitates maintenance watching sets.this, let us understand bit detail watching sets usedsearching unit instances particular augmented clause. Consider augmentedclause corresponding quantified clausexy . [q(x) r(y) s]Q set instances q(x) R set instances r(y), becomesaugmented clause(q(0) r(0) s, Sym(Q) Sym(R))(21)q(0) r(0) elements Q R respectively.suppose r(y) true y, q(x) unvalued, s, clause(21) unit instances. Suppose also search unit instances (21) firststabilizing image r q (s stabilized group Sym(Q) Sym(R)itself). four possible bindings (which denote 0, 1, 2, 3) threex (0, 1, 2), search space looks like this:483fiDixon, Ginsberg, Hofer, Luks & ParkesSym(R)sPSym(Q)PP@PP@PPPP@PP@PPPP (r0 r3 )Sym(Q)(r0 r1 )@P@s(r0 r2 )Ps(q0 q2 )(q0 q2 )(q0 q2 )1111AAs(q0 q2 )(q0 q1 )(q0 q1 )(q0 q1 )(q0 q1 )interests conserving space, written qi instead q(i) similarly rj .leaf nodes fails relevant instance q(x) unvalued,construct new watching set entire clause (21) watchesq(x).Note causes us lose significant amounts information regarding portionssearch space need reexamined. example, responsible literalsleaf node follows:PPP@PP@PPPP@PP@PPPP@P@sPsq0 ,q2 ,q0 ,q2 ,q0 ,q2 ,q0 ,AAsq2 ,q1 ,q1 ,q1 ,q1 ,simply accumulate literals root search tree, concludereason failure watching set {q0 , q1 , q2 , s}. watched literalschanges value, potentially reexamine entire search tree.address changing order variable stabilization, replacing searchspace depicted following one:Sym(Q) Sym(R)PPPPPPPPPPPPSym(R)EEAEE1EEs AAs(r0 r3 )(r0 r1 ) (r0 r2 )(q0 q1 )AEEAEE1s EEs AAs(r0 r3 )(r0 r1 ) (r0 r2 )484PPPPPs(q0 q2 )EAEAEE1sEEs AAs(r0 r3 )(r0 r1 ) (r0 r2 )fiZAP 3: Implementationcenter node needs reexpansion value q1 changes, sincenode q1 appears. search space becomes simply:Sym(Q) Sym(R)(q0 q1 )EEAEE1EEs AAs(r0 r3 )(r0 r1 ) (r0 r2 )one would expect q1 changes value.upshot collect new watching set original augmentedclause corresponding (21), also need modify unit propagation procedurefirst stabilize points mapped specific watched literal becomeunsatisfied.see keep watching set updated, consider Proposition 7.10. searchingunit instances augmented clause (c, G), need compute set W|W cg U (P )| > 1 every unsettled instance cg (c, G) contains fixed literalw. this?solution lies Procedure 6.7, describes search unit instances.remaining clause instances particular search node determinednonunit test line 3, instead simply recognizing every instancenode nonunit, need able identify set unvalued literals meets everyunsettled instance cg least twice. modify overlap procedure 5.19 become:Procedure 7.11 Given group H, two sets c, V acted H, bound k 0,compute overlap(H, c, V, k), collection elements V sufficient guaranteeh H, |ch V | > k, collection exists:1 m02 W3 orbit X H4{B1 , . . . , Bk } minimal block system W Hc W Bi5= |c X| + min(Bi V ) |B1 |6> 07+8W W (X V )9> k10return W11 return485fiDixon, Ginsberg, Hofer, Luks & ParkesProposition 7.12 Procedure 7.11 returns nonempty set W Procedure 5.19returns value excess k. case, |ch W | > k every h H.finally position replace Procedure 6.7 version uses watchedliterals:Procedure 7.13 Given groups H G, element G, sets c, U , optionally watched element w, find Transport(G, H, t, c, S, U, w), skeletal set unitw-consequences (c, G) given P :1234567891011121314151617181920212223241w supplied wt 6 cHreturn hfalse, ,1V overlap(H, c, , 0)V 6=return hfalse, ,1V overlap(H, c, (S U )t , 1)V 6=return hfalse, , Vc = cHct U =return htrue, 1,else return hfalse, hct U, 1i,pruning lemma appliedreturn hfalse, ,1element c cH . w supplied w 6 ctH , choose wt H .Wt0 (H : H )hu, V, Xi Transport(G, H , t0 t, c, S, U, w)u = truereturn htrue, V t0 ,else W W X{hl, gt0 i|hl, gi V }return hfalse, Y, Wapplication pruning lemmas line 13, need use restricted groupG{S,U,{w}} , prune group element g w cg basis anothergroup element jgk w 6 cjgk , since jgk might pruned line 2.Proposition 7.14 Suppose overlap(H, c, V, k) computed using Procedure 7.11,otherwise satisfies conclusion Proposition 7.12. g Gw cg cg = cg U = , Transport(G, c, S, U, w) computed Procedure 7.13returns htrue, g, g. g, Procedure 7.13 returns hfalse, Z, W i,Z skeletal set unit w-consequences (c, G) given P , W|W G{S,U,{w}} ch U | > 1 every h H w ch ch unsettled P .486fiZAP 3: ImplementationNote pruning lemmas applied relatively late procedure (line 13) eventhough successful application prunes space without increasing size watchingset. might seem pruning lemmas applied earlier.appears case. discussed end Section 5, pruning lemmasrelatively complex check; moving test earlier (to precede line 6, presumably)actually slows unit propagation procedure factor approximately two, primarilydue need compute set stabilizer G{S,U } even cases simple countingargument suffices. addition, absolute impact watching sets expectedquite small.understand why, suppose executing procedure instanceeventually fail. n node pruned either counting argument(with new contribution Wn set watched literals) lexicographic argumentusing another node n0 , since node n0 eventually fail, contributewatching set Wn0 eventually returned value. possible Wn 6= Wn0(different elements selected overlap function line 6, example),expect vast majority cases Wn = Wn0 non-lexicographicprune impact eventual watching set computed.Proposition 7.14 implies watching set returned Procedure 7.13 usedupdate watching set third claim Proposition 7.10. fourth claim,hope remove l new watching set, need check see|W cg [U (hP, li) (S(P ) S(P ))]| > 1g G, W new watching set. determined single calltransport; g G|cg [W (U (hP, li) (S(P ) S(P )))]| 1(22)remove l W . cases, save call transport exploitingfact (as shown proof Proposition 7.10) (22) cannot satisfied hP, liunit consequence.finally position describe watched literals augmented setting.start, have:Definition 7.15 watched augmented clause pair h(c, G), W (c, G) augmented clause W watching set (c, G).Procedure 7.16 (Unit propagation) compute Unit-Propagate(C, P, L) Cset watched augmented clauses, P annotated partial assignment, L setpairs hl, ri literals l reasons r:487fiDixon, Ginsberg, Hofer, Luks & Parkes1 L 6=2hl, ri element L3L L hl, ri4P hP, hl, rii5h(c, G), W C6l W7hr, H, V Transport(G, c, S(P ), U (P ), l)8r = true9li literal cH highest index P10return htrue, resolve((cH , G), ci )i11H 0 complete(H, G{S(P ),U (P ),{l}} )12h H 013z literal ch unassigned P14hz, r0 L15L L hz, ch16W W (U (P ) V G{S(P ),U (P ),{l}} )17U U (P ) (S(P ) S(P ))18H = transport(G, c, , W U, 1, l) = failure19W W {l}20 return hfalse, Pline 18, invoke version transport function accepts additional argument literal required included clause instance sought.modification similar introduction literal w Transport procedure 7.13.Proposition 7.17 Let P annotated partial assignment, C set watched augmented clauses, every h(c, G), W C, W watching set (c, G) P .Let L set unit consequences clauses C. Unit-Propagate(C, P, L) returnshtrue, ci augmented clause c, c nogood P , modified watchingsets C still watching sets P . Otherwise, value returned hfalse, Pwatching sets C replaced watching sets P .Procedure 7.16 modified incorporated fairly obvious way Procedure 2.8, literal recently added partial assignment added Lthereby passed unit propagation procedure.8. Resolution Revisitedone additional theoretical point need discuss turning attentionexperimental matters.goal augmented resolution produce many (if all) resolventssanctioned instances augmented clauses resolved. showed zap2,however, always possible produce resolvents. another examplephenomenon.488fiZAP 3: ImplementationSuppose resolving two clauses(a c, (ab))(23)(b c, (ab))(24)(a b, (ab))(25)result is10consider example. instances (23) ac bc; (24) bcc. Surely better resolvent (a, (ab)) instead (25). general,never want conclude (c, G) possible conclude (c0 , G) c0 cset inclusion proper. resolvent c0 properly stronger c.additional consideration well. Suppose resolving two augmented clauses, choose instances resolving clauses resolvent(a c, G) (b c, G), b literals two possible resolvents distinct(ab) 6 G. select?know general answer, reasonable heuristic make choice basedorder literals added current partial assignment. Assumingresolvent nogood, presumably b false current partial assignmentP . select resolvent allows larger backjump; case, resolventinvolving literal added P first.considerations direct analog conventional Boolean satisfiabilityengine. particular literal l, resolvent reasons l l that;flexibility possible.11Definition 8.1 Let (, G) (, H) two augmented clauses resolving literal l,l l . l-resolvent (, G) (, H) clause obtainedresolving g h g G h H l g l h .Note group Z resolvent clause (resolve(g , h ), Z) independentresolvent selected, focus attention strictly syntactic propertiesresolvent.next formalize fact partial assignment P induces natural lexicographicordering set nogoods given theory:Definition 8.2 Let P partial assignment, c ground clause. l literalc whose negation maximal index P , say falsification depth cposition P literal l. falsification depth zero literal c;event, falsification depth c denoted c?P .c1 c2 two nogoods, say c1 falsified earlier c2 P , writing?P?P?Pc1 <P c2 , either c?P1 < c2 , c1 = c2 c1 lc?P <P c2 lc?P .1210. result obtained direct computation applying resolution stability property discussed zap2, since groups identical.11. weak analog present zChaff, replace one nogood n another n0 n0 leadsgreater backjump n does. functionality part zChaff code appeardocumented.489fiDixon, Ginsberg, Hofer, Luks & Parkesexample, suppose P ha, b, c, d, ei. falsification depth cthree, since c third variable assigned P . falsification depth b four.Thus c <P b d; would rather learn c allows us backjumpc instead d. Similarly c e <P b e; common elemente eliminated, would still rather backtrack c d. general, goalresolving two augmented clauses select resolvent minimal <P . Notehave:Lemma 8.3 c1 c2 two nogoods P , c1 <P c2 .Procedure 8.4 Suppose given two augmented clauses (, G) (, H)unit partial assignment P = hl1 , . . . , ln i, l l . find <P -minimall-resolvent (, G) (, H):12345678910111213U {l, l}literals cant avoidffp [( ) U ]?Pp > 0g transport(G, , {lp , . . . , ln } U, , 0, l)h transport(H, , {lp , . . . , ln } U, , 0, l)g = failure h = failureU U {lp }else f gf hp [(f f ) U ]?Preturn resolve(f , f )basic idea gradually force two clause instances away endpartial assignment; back up, keep track literals unavoidableassociated call transport failed. unavoidable literals accumulated setU above, continue call transporter function, objection oneclause instances includes elements U . point, refocus attentiondeepest variable yet known either avoidable unavoidable;reach root partial assignment, return instances found.example. Suppose P = ha, b, c, d, ei before, (, G)instances c l e l. second clause (, H) single instanceb e l.resolve <P -minimal instances two augmented clauses, resolvec l b e l get b c e. better resolve e lb e l instead get b e. literals b e appear case,better c d.Suppose follow example procedure, U initially set{l, l} (say) therefore f set c l. f set b e l,since instance (, H). initial value p five, since last literalU = {b, c, d, e} e.490fiZAP 3: Implementationtry find way avoid e appear final resolvent.looking instance (, G) includes l (the literal resolving)avoids e (and subsequent literal, arent any). instance givenitself. instance (, H) avoids e, call line 7 fails.therefore add e U leave clauses f f unchanged. decrement p four,since e longer (f f ) U .next pass loop, looking clause instances avoid{d, e} U = {d}. know well forced include e final result,dont worry it. hope point exclude d.Here, successful finding instances. existing instance suffices,instance e l (, G). becomes new f p gets reducedtwo, since (f f ) U = {a, b}.next pass loop tries avoid b continuing avoid c(which know avoid current f f so). turnsimpossible, b added U p decremented one. Avoiding impossiblewell, p decremented zero procedure correctly returns b e.Proposition 8.5 Suppose given two augmented clauses (, G) (, H)unit partial assignment P , l l . valuereturned Procedure 8.4 <P -minimal l-resolvent (, G) (, H).procedure implemented somewhat efficiently described above;f , example, already satisfies condition implicit line 6, need reinvoketransport function g.important relatively slender improvement, however, factresolution involves repeated calls transport function. general, Booleansatisfiability engines need worry time used resolution function, sinceunit propagation dominates running time. naive implementation Procedure 8.4,however, involves calls transport unit propagation procedure,resolution comes dominate zaps overall runtime.correct this, remember point Procedure 8.4. procedure neededcorrectness; needed find improved resolution instances. amount timespent looking instances less computational savings achievedthem. Put slightly differently, requirement produce resolventabsolutely minimal <P ordering. resolvent nearly minimalsuffice, especially producing truly minimal instance involves large computational cost.achieve goal working modified transport function lines 6 7Procedure 8.4. Instead expanding coset decomposition tree completely, limitednumber nodes examined. Zaps current implementation prunes transporter search100 nodes examined; solving pigeonhole problem, example,turns sufficient ensure resulting proof length wouldstrictly <P -minimal resolvents found. also modify pruningcomputation, pruning K = GSU instead difficult compute G{S,U } .Since GSU G{S,U } (stabilizing every element set surely stabilizes set itself),approximation saves time reduces amount possible pruning. appropriate491fiDixon, Ginsberg, Hofer, Luks & Parkes10CPU time1.65e-06 n**4.61secs0.10.010.0011e-045101520pigeonsFigure 2: CPU time resolution pigeonhole problemgiven artificially reduced size overall search tree need produceanswer quickly.9. Experimental Results: Componentsfinally position describe experimental performance algorithmspresented. remarked introduction, begin describing performancezaps algorithmic components, resolution unit propagation algorithms. Performance results complete inference tool build using ideas next section.experiments performed 2GHz Pentium-M 1GB main memory.9.1 Resolutionimplemented resolution procedure described Section 4, resultspigeonhole problem shown Figure 2. particular example involves resolvingtwo basic axioms pigeonhole problem containing n pigeons n 1 holes:(p11 p1,n1 , G)(p11 p12 , G)492fiZAP 3: Implementationfirst axiom says pigeon 1 must hole; second, first twopigeons cannot first hole. group G corresponds global symmetrygroup pigeons holes interchanged freely.resolvent two axioms fact computed without grouptheoretic computation all, using result zap2 group stable extensions(c1 , G) (c2 , G) always superset group G. algorithm Section 4computing augmented resolvents include check see groups identical,implementation include check. test disabled producedata Figure 2.plot observed time (in seconds) resolution function numberpigeons involved, time plotted log scale. Memory usage typically approximately 5MB; CPU usage dominated need compute stabilizer chainsgroups question. algorithms used take time O(d5 )size domain group operating (Furst, Hopcroft, & Luks, 1980; Knuth,1991). case, symmetries pigeons holes stabilized independently therefore expect stabilizer chain computation take time O(n5 ),n number pigeons. fit data curve axb , best fit occurringb 4.6. consistent stabilizer chain computation dominating runtime.reinsert check see groups same, running times reduceduniformly approximately 35%. Testing group equality involves checking seegenerator G1 member G2 vice versa, therefore still involves computingstabilizer chains groups question. again, need compute stabilizerchains dominates computation.9.2 Unit PropagationFigure 3 give data showing average time needed unit test pigeonholeproblem. naturally occurring unit tests arise run proverproblem question. memory used program remained far less1GB available; example, maximum usage approximately 20MB 13 pigeons.12Since unit test NP-complete, customary give mean medianrunning times; present means Figure 3 mean running times appeargrowing polynomially (compare two lines best fit figure),medians appear modestly smaller means. shown Figure 4,appears ratio mean median running times growing linearlyproblem size.earlier figure 3 also shows average CPU time failed tests (where clausequestion unit instances) successful tests (where unit instances exist);seen, failed unit tests generally complete far quickly successfulcounterparts similar size various pruning heuristics come play. cases,however, scaling continues appear polynomial problem size.12. Accurately measuring peak memory usage difficult group operations regularly allocatefree relatively large blocks memory. measured usage simply starting system monitorobserving it, practical problem instances took extended amounts timecomplete. reason report memory usage approximately, one probleminstance.493fiDixon, Ginsberg, Hofer, Luks & Parkes10averagefailsucceedpolynomial fitexponential fit1secs0.10.010.0011e-044681012pigeons14161820Figure 3: CPU time unit test pigeonhole problem10. Experimental Results: ZAPconclude discussion zaps experimental performance results probleminstances entirety, opposed performance individual algorithmic components. presenting results, however, let us describe domainsconsidered expectations regard performance zap existingsystems areas.examining performance three domains:1. pigeonhole problem, goal show cannot put n + 1 pigeons nholes pigeon get hole.PP2. parity problem, goal show iI xi + iJ xi cannot oddsets J equal (Tseitin, 1970).3. clique-coloring problem, goal show map containing m-cliquecannot colored n colors n < m.reasons chosen particular problem classes follows:1.easy.PP obvious cant put n + 1 pigeons n holes,iI xi + iJ xi even xi appears exactly twice. also obviouscant color graph containing m-clique user fewer colors.494fiZAP 3: Implementation2.1ratio21.9mean/median ratio1.81.71.61.51.41.31.24681012pigeons14161820Figure 4: Mean vs. median CPU time unit test pigeonhole problemlast case especially, note solving easy problem.case trying color specific graph containing m-clique; goalshow graph containing m-clique anywhere cannot colored.different graph coloring generally.Put somewhat differently, problems examining P.Given suitable representations, easy.2. problems known exponentially difficult resolution-based methods. shown pigeonhole problems Haken (1985) parity problemsTseitin (1970). Clique-coloring problems known exponentially difficultresolution, linear programming methods well (Pudlak, 1997).fact, know implemented system scales polynomially classproblem.3. Finally, problems involve structure captured group-basedsetting.data present compares zaps performance zChaff; Section 10.4 discusses performance Boolean tools problem classesdiscussing. chose zChaff comparison partlydiscussed throughout series papers, partly appears best495fiDixon, Ginsberg, Hofer, Luks & Parkes1e+06zapzchaff10000secs10010.011e-041e-064681012pigeons14161820Figure 5: CPU time pigeonhole instances, zap zChaffoverall performance three problem classes considering. (Once again,see Section 10.4 additional details.)ZAP expectations proceeding, let us point theoretical basis,known short group-based proofs exist problems. showed zap2group-based pigeonhole proofs expected short, also parity problemsshort group-based proofs mimic Gaussian elimination. also showed shortgroup-based proofs existed clique coloring, although proof fairly intricate.goal determine whether implementation ideas discover shortproofs practice, whether control group-based inference require additionaltheoretical ideas yet understand.Please understand goal point test zap standard NP-completesearch problems Boolean form, graph coloring quasigroup completion problems (Gomes & Selman, 1997). involves significant effort ensuring zapsconstant factors data structures comparable systems; preliminary indications possible modest impact performance(approximately factor two), work yet complete reported elsewhere.496fiZAP 3: Implementation100000zapexponential fitpolynomial fit100001000secs1001010.10.010.0014681012pigeons14161820Figure 6: zap scaling pigeonhole instances10.1 Pigeonhole ResultsFigure 5 shows running times zap zChaff pigeonhole instances. Figure 6 repeats zap data, also including best exponential polynomial fits timespent. overall running time appears polynomial, varying approximately n8.1n number pigeons. rough terms, factor O(n5 ) neededstabilizer chain constructions. branch positive literals, know (see zap2)O(n) resolutions needed solve problem, resolutionlead O(n2 ) unit propagations. total time thus expected approximatelyO(n8 ), assuming unit propagation involves stabilizer chain computationsactual search. observed performance close theoretical value.practice, zap branches positive literals, negative ones. reasonnegative literals appear far clauses positive ones (O(n) clausesnegative literal opposed single clause positive literal), usualbranching heuristic Boolean satisfiability community initially assigns variablevalue satisfies many clauses possible.number nodes expanded zap solving particular instance pigeonhole problem shown Figure 7, also presents similar data zChaff.number nodes expanded zap fact exactly n2 3n + 1; curiously, alsodepth zChaff search next smaller instance n 1 pigeons.497fiDixon, Ginsberg, Hofer, Luks & Parkes1e+07zapzchaff1e+06100000nodes1000010001001014681012pigeons14161820Figure 7: Nodes expanded pigeonhole problemknow small size pigeonhole proofs found zap result effectivenessuse <P -optimal resolvents, fundamental argument madezap proofs pigeonhole problem short.moving parity problems, allow us comment importancevarious algorithmic techniques described. recognize manyalgorithms presented quite involved, important demonstrateassociated algorithmic complexity leads legitimate computational gains.Figure 8 shows time needed solve pigeonhole instances either abandonpruning lemmas avoid search <P -optimal resolvents. cleardata, techniques essential obtaining overall performance exhibitedsystem.abandon search <P -optimal resolvents, proof lengths increase significantly appear remain polynomial n. length increase learned axiomsleads increased running times unit propagation, appears primaryreason performance degradation figure. overall running times scale exponentially.Abandoning pruning lemmas also leads exponential running times.expected level; still exponentially many learned ground axiomscannot prune search unit instances, exponential behavior expected.498fiZAP 3: Implementation1e+06100000100001000secs1001010.10.010.001zappruningresolution instances1e-044681012pigeons14161820Figure 8: Improvement due pruning lemmas <P -optimal resolution instances.circles mark zaps performance. xs indicate performance pruninglemmas disabled unit propagation, boxes give performance resolutions use original base instances clauses resolved, opposedsearching resolving <P -optimal instances.ways could reduced zaps algorithmic complexitywell. could, example, removed watched literals computational machinery needed maintain them. turns out, change virtually impactzaps pigeonhole performance provers behavior typically backtrack-free(Dixon et al., 2004a). general, however, watched literals expected playimportant role zap dpll-style prover. overall focusseries papers show group-based augmentations could implementedwithout sacrificing ability use recent techniques made Booleansatisfiability engines effective practice, watched literals certainly numberedamongst techniques.also evaluate possibility learning augmented clauses all, perhapslearning instead ground versions. would avoid need implement Procedure 4.1, would also avoid computational gains zap theoreticallyaccess. learning augmented clauses theoretical reductions proof499fiDixon, Ginsberg, Hofer, Luks & Parkessize obtained; otherwise, proof would necessarily unchangeddpll-style approach.10.2 Tseitin Resultsnext problem class present experimental data one due Tseitin (1970)shown Urquhart (1987) require resolution proofs exponential length.problem based graph G. associate Boolean variable edge G,every vertex v G associated charge 0 1 equal sum mod 2variables adjacent v. charge entire graph G sum mod 2 chargesvertices. require connected graph G charge one, setconstraints associated vertices unsatisfiable (Tseitin, 1970). graphproblem size four, together associated constraints:10u@b@ue@c@@@u0f@@u0a+b+c1d+e+a0f +b+d0c+e+f 0language zap (see Appendix B),fcbebecf%2=%2=%2=%2=1000;;;;axiom set unsatisfiable adding axioms gives us2a + 2b + 2c + 2d + 2e + 2f 1problems known exponentially difficult resolution-based methods (Urquhart,1987).Times solution zap zChaff shown Figure 9. ZChaff clearly scalingexponentially; best fit zap times 0.00043n1.60 log(n) , n problemsize.500fiZAP 3: Implementation1e+06zapzchaff10000secs10010.011e-041e-065101520sizeFigure 9: CPU time Tseitin instances, zap zChaff. ZChaff scaling exponentially; zap scaling O(n1.6 log(n) ).Figure 10 shows number nodes expanded two systems. numbersearch nodes expanded zap appears growing polynomially sizeproblem (O(n2.6 ), give take), keeping result zap2 showing zap proofspolynomial length always exist parity problems. pigeonhole instances,see short proofs exist theory, apparently practice well.Given polynomial number nodes expanded super-polynomial amounttime consumed, seems likely unit propagation procedure culprit,taking super-polynomial amount time per unit propagation. shown Figure 11,fact case. unit test easy all, groupssimply flip even number variables question. want knowaugmented clause unit instance, find unvalued variables contains.one, clause unit. exactly one, clause always unit variable mustvalued make parity sum take desired value. seemsreason unit tests scaling nlog(n) .nlog(n) scaling appears consequence multiset stabilizer computation underlies k-transporter pruning. Here, too, scaling polynomial,since show polytime (O(n3 )) methods exist set stabilizer groups501fiDixon, Ginsberg, Hofer, Luks & Parkes1e+07zapzchaff1e+06100000nodes1000010001001015101520sizeFigure 10: Nodes expanded Tseitin problems. ZChaff scaling exponentially; zapscaling polynomially O(n2.6 ).question.13 general methods implemented gap zap exploitAbelian nature parity groups, however, scaling shown. obvious extension existing implementation would include efficient set stabilizer algorithmsgroups.10.3 Clique Coloringfinal problem class present experimental data clique coloring.class problems related pigeonhole problem far difficult.mentioned previously, domain graph coloring, two nodes connected edge must assigned different colors. graph clique size m,obvious graph cannot colored 1 colors. equivalentinstance pigeonhole problem. clique coloring problem, toldgraph clique size m, contains clique size m. factknow exact location clique widens search considerably.13. argument made either fact groups Abelian, factgroup orbits size two, set stabilizer problem thus converted one linearalgebra Z2 .502fiZAP 3: Implementation1average3.21e-05 x**log xsecs0.10.010.0011e-045101520sizeFigure 11: CPU time unit test Tseitin problems. Zap scaling approximatelyO(nlog(n) ).know (other) automated proof system scales polynomially problemsclass; resolution linear programming methods inevitably scale exponentially (Pudlak, 1997). showed zap2 zap could produce polynomial-length proofstheory, suggestions made proofs would easy find practice.present details zaps performance problem class, let us reiterateobservation clique-coloring problems thought unsatisfiableinstances graph-coloring problems generally. particular instance problem classdescribe specific graph needs colored; says graphcontains m-clique needs colored 1 colors.axiomatization problem follows. use eij describe graph, cijdescribe coloring graph, qij describe embedding cliquegraph. graph nodes, clique size n + 1, n colors available.ci1 cin= 1, . . . ,(26)qi1 qim= 1, . . . , n + 1(27)1 < j m, l = 1, . . . , n(28)1 < k n + 1, j = 1, . . . ,(29)eij cil cjlqij qkj503fiDixon, Ginsberg, Hofer, Luks & Parkeseij qki qlj1 < j m, 1 k 6= l n + 1(30)eij means edge graph nodes j, cij means graphnode colored jth color, qij means ith element cliquemapped graph node j. Thus first axiom (26) says every graph node color.(27) says every element clique appears graph. (28) says twonodes graph cannot color (of n colors available) connectededge. (29) says two elements clique map node graph.Finally, (30) says clique indeed clique two clique elements mapdisconnected nodes graph.encoding passed zap group-based, follows:SORT color 2 ;SORT node 4 ;SORT clique 3 ;PREDICATE edge( node node ) ;PREDICATE color( node color ) ;PREDICATE clique( clique node ) ;GROUP COLOR <(( color[1 1] color[1 2])( color[2 1] color[2 2])( color[3 1] color[3 2])( color[4 1] color[4 2]))> ;GROUP CLIQUE <(( clique[1 1] clique[2 1])( clique[1 2] clique[2 2])( clique[1 3] clique[2 3])( clique[1 4] clique[2 4]))(( clique[2 1] clique[3 1])( clique[2 2] clique[3 2])( clique[2 3] clique[3 3])( clique[2 4] clique[3 4]))> ;GROUP NODES <(( edge[1 3] edge[2 3])( edge[1 4] edge[2 4])( color[1 1] color[2 1])( color[1 2] color[2 2])( clique[1 1] clique[1 2])( clique[2 1] clique[2 2])( clique[3 1] clique[3 2]))(( color[2 1] color[3 1] color[4 1])( color[2 2] color[3 2] color[4 2])( edge[1 2] edge[1 3] edge[1 4])( edge[2 3] edge[3 4] edge[2 4])( clique[1 2] clique[1 3] clique[1 4])( clique[2 2] clique[2 3] clique[2 4])( clique[3 2] clique[3 3] clique[3 4]))504fiZAP 3: Implementation1e+06zapzchaff10000secs10010.011e-041e-064681012graph size (clique size one less)141618Figure 12: CPU time clique instances, zap zChaff> ;color[1 1] color[1 2] GROUP NODES ;clique[1 1] clique[1 2] clique[1 3] GROUP CLIQUE ;-edge[1 2] -color[1 1] -color[2 1] GROUP NODES COLOR ;-clique[1 1] -clique[2 1] GROUP NODES CLIQUE ;-clique[1 1] -clique[2 2] edge[1 2] GROUP NODES CLIQUE ;version 3-clique graph size four, tryinguse two colors. first group symmetry colors alone, secondelements clique, third symmetry nodes. axiomatizationidentical presented earlier. Note although common symmetryproblem, axiomatization obscures sense, since includedrelevant symmetry symmetries particular axiom.Times solution zap zChaff shown Figure 12. might expected,zChaff scaling exponentially; zap appears scaling n8.5 . order allowdata presented along single axis, problem instances selectedclique size one smaller graph size.Figure 13 shows number nodes expanded two systems. again,number nodes expanded zChaff growing exponentially problem size,number expanded zap growing polynomially. pigeonhole problem,505fiDixon, Ginsberg, Hofer, Luks & Parkes1e+07zapzchaff1e+06100000nodes1000010001001014681012graph size (clique size one less)141618Figure 13: Nodes expanded clique problemssee short proofs whose existence guaranteed theory foundpractice.Figures 14 15 display zaps performance somewhat wider range probleminstances clique graph sizes allowed vary independently. numbernodes expanded general(c + g)2 13c g + 142c size clique g size graph. handful outliers,notably c = 11, g = 13 instance expanded larger number nodes.exceptions expanded fewer nodes.regard total CPU time (Figure 15), time appears scaling (cg)3.89 .again, c = 11, g = 13 outlier polynomial performance observed generally.best knowledge, zap first system exhibit polynomial performanceproblem class; remarked, approaches proven scaleexponentially.10.4 Related WorkFinally, compare experimental results obtained using systemsattempt exploit problem structure improve performance satisfiability solvers.506fiZAP 3: Implementationzap0.075 (x+y)**2.521000100nodes1012graph size46810412clique sizeFigure 14: Nodes expanded clique problemssection provides high-level summary experimental results numberefforts compares results zap benchmark problems describedprevious sections.Recall benchmark problems highly structured, different type structure. Theoretically, problems allow polynomial-time solutions,provably hard conventional solvers. solver solves problems efficiently ability exploit range different types problem structureautomates strong proof system. course, interesting, solver must alsopractical general purpose solver. example, Tseitin problems solved polynomialtime form Gaussian elimination (Schaefer, 1978), pigeonhole problemssolved polynomial time linear programming method simplex method.However, neither solutions constitutes practical general purpose solver.ran number solvers benchmark problems, obtaining following results:507fiDixon, Ginsberg, Hofer, Luks & Parkeszap3.54e-06 (xy)**3.89100001000100101secs0.10.0112graph size46481012clique sizeFigure 15: CPU time expended clique problemszapzChaffpbchaffeqsatzmarch eqresolutioncutting-planesinteger programmingpigeonholePEPEEETseitinnlog nEEEE (P)E (?)clique coloringPEEEEEP?ERather presenting numerous graphs, summarize results above, simply reporting overall scaling solver problem class. Polynomial-time scalingindicated P exponential-time scaling E. Scaling shown threeproblem classes discussed, two separate encodings considered Tseitinproblems. first encoding Booleanization encoding Section 10.2;second involves introduction new variables reduce clause length describedbelow. performance improved introduction, new scaling given parenthetically. final two rows give known proof complexity results resolutioncutting-planes proof systems thus provide lower bounds corresponding rowsthem.508fiZAP 3: ImplementationReducing performance results exponential polynomial scaling omits valuable information. Clearly difference n100 n2 scaling something care about,although polynomial. details specific scaling factors includeddiscussion follows; goal table merely summarize strengthsolvers underlying proof system.Details solvers appearing table follows:pbchaff pseudo-Boolean version dpll algorithm. represents problemspseudo-Boolean form automates cutting-planes proof system. cuttingplanes proof system allows polynomial-length proofs pigeonhole problempbchaff able solve problems efficiently. Scaling pbchaff pigeonholeinstances n4.8 , n number pigeons. improvementn8.1 scaling seen zap. However, performance pbchaff Tseitinclique coloring problems exponential, since cutting-planes inference ablecapture exploit structure problems.eqsatz (Li, 2000) march eq (Heule & van Maaren, 2004) dpll-based solversmodified incorporate equivalence reasoning, enablesolve parity problems efficiently. expected, eqsatz march eqexhibited exponential scaling pigeonhole clique coloring problems, sincesolvers designed recognize structure problems. surprisingexponential scaling observed eqsatz march eq initialencoding Tseitin problems.Eqsatz scales exponentially recognize structure presentencoding parity problems.14 performance improved modifying cnf encoding reduce size make structure apparentsolver. involves introduction significant number new auxiliary variables, experimental results new encoding discussed below.March eq recognize structure original encoding, solvespreprocessing phase. exponential scaling due simply factsize Boolean encoding growing exponentially function graph size (seeSection 10.2).parity constraint rewritten set parity constraints, lengththree (Li, 2000). parity constraint formx1 + x2 + . . . + xn kequivalent set parity constraintsx1 + A1 kA1 + x2 + A2 0A2 + x3 + A3 0...An2 + xn1 + An1 0An1 + xn 014. Li, personal communication (2005).509(31)fiDixon, Ginsberg, Hofer, Luks & ParkesSumming set parity constraints gives2A1 + 2A2 + + 2An1 + x1 + + xn kequivalent (31). Tseitin encoding Section 10.2 translatedparity constraints way converted cnf, exponential blowupsize existing cnf encoding avoided. (It clear, however, resolutionproduce polynomially sized proof unsatisfiability resulting theory.)Eqsatz, march eq zap exhibit improved performance new encodingused; results shown parenthetically Tseitin column table. March eqsolves encoding Tseitin problems virtually instantaneously. Eqsatz substantially outperforms zChaff, reported Li (2003). running times eqsatz,however, remain exponential system unable solve instance size tenwithin 10,000 seconds. performance zap improved well, overall scalingunchanged.introduction new variables accepted practice reducing size cnfencodings, also potential reduce length proofs constructed solvers.Indeed, classes problems known hard extended resolution, versionresolution introduction new variables permitted. general, however,introducing new variables order reduce proof length considered cheatingproof complexity perspective; new variables introduced, proof systemsessentially equivalent. addition, general method introducing variables knownknow implemented system so. One advantage zap group-basedannotations avoid need syntactic reworkings sort.Another approach solving highly symmetric problems seen solver sSatz (Li,Jurkowiak, & Purdom, Jr., 2002). solver also based dpll algorithm,accepts input problem cnf set matrices describing global symmetryvariables. global symmetry used partition set variable assignmentsequivalence classes. addition normal pruning techniques used dpll, searchalso pruned eliminating partial assignment minimalequivalence corresponding global symmetry. sSatz scales polynomially pigeonholeproblems; however, class input symmetry groups allowed sSatz currentlylimited applied Tseitin clique coloring problems. clear whetherlimitation overcome work matures, includedsSatz table.solvers tested, zap solver provide efficient solutions testproblems, solver scales polynomially clique coloring. Pbchaffbetter scaling pigeonhole problems, march eq better scaling Tseitinproblems; however, solvers exploit narrowly defined type problem structuretherefore perform poorly domains. performance zap also likelyimprove basic group primitives underlying zaps procedures optimized.11. Conclusion Future WorkZap represents appears new synthesis two distant fields: computational group theory Boolean satisfiability. algorithmic point view,510fiZAP 3: Implementationfields fairly mature complex, synthesis inherits significant algorithmiccomplexity result. goal paper present initial versionsalgorithms group-based theorem prover need, describe performanceprototype implementation ideas. seen, zap easily outperformsconventional counterparts difficult problem instances group structureconcealed Boolean axiomatization.said, important realize results scratch surfacezaps underlying representational shift allows. Tseitin problems, example,seems likely incorporation sophisticated set stabilizer algorithms allow usimprove zaps performance; fact polynomially many nodes expandedsolving problems bodes well eventual performance system.improvements also possible. pigeonhole clique coloring problems,computational performance dominated O(n5 ) stabilizer chain computationsgroups question; groups products full symmetry groups. well knownfull symmetry groups extremely difficult usual stabilizer chain algorithms,cases possible produce stabilizer chains directly, taking timeO(n3 ) even O(n2 ) stabilizer chain data structure modified (Jerrum, 1986).modifications expected improve zaps performance significantly domain.simply much do. extensions beginning; alsoobviously need experiment zap wide range problem instances.also two general points would like make regarding future work area.First, left unmentioned problem discovering group structure existingclausal databases. practical impact would substantial, several reasons.would make possible apply zap directly problems already encodedusing Boolean axioms, would also make possible discover emergent groupstructure appears search begun. example, perhaps symmetryexists particular problem hidden existing axiomatization;inferences, symmetry may become apparent still needs noticed.Second, perhaps important, zap provides us broad stagework. Progress computational group theory expected lead performanceimprovements inference; dually, applying zap wide range reasoning problemsprovide new set examples computational group theorists usetest ideas. Lifting heuristics one area AI group-based setting may makeanalogs heuristics available other, practical domains. newsyntheses, seems reasonable hope zap allow ideas Boolean satisfiability,computational group theory search-based AI combined, leading new insightslevels performance areas.Acknowledgmentswould like thank members cirl technical staff Time Systemsassistance ideas series papers. would also like thankimplementers maintainers gap; many elements zap implementation baseddirectly either implementations appear gap descriptions Seressbook (2003). Finally, would especially like thank anonymous reviewers511fiDixon, Ginsberg, Hofer, Luks & Parkeszap papers care effort put reviewing series papers span200 journal pages entirety. three papers substantially improvedefforts.work sponsored part grants Air Force Office Scientific Research (afosr) number F49620-92-J-0384, Air Force Research Laboratory (afrl) number F30602-97-0294, Small Business Technology Transfer Research, Advanced TechnologyInstitute (sttr-ati) number 20000766, Office Naval Research (onr) number N0001400-C-0233, Defense Advanced Research Projects Agency (darpa) Air Force Research Laboratory, Rome, NY, agreements numbered F30602-95-1-0023, F30602-971-0294, F30602-98-2-0181, F30602-00-2-0534, F33615-02-C-4032, darpaagreement number HR0011-05-C-0039. views expressed authors.Appendix A. ProofsProcedure 4.1 Given augmented clauses (c1 , G1 ) (c2 , G2 ), compute stab(ci , Gi ):123456789G21c closure1 cG1 , c closure2 c2g restrict1 G1 |c closure1 , g restrict2 G2 |c closure2C c closure1 c closure2g stab1 g restrict1{C } , g stab2 g restrict2{C }g int g stab1 |C g stab2 |C{gi } {generators g int}{l1i } {gi , lifted g stab1 }, {l2i } {gi , lifted g stab2 }0 } {l |{l2i2i c closure2 C }0 }ireturn hg restrict1C , g restrict2C , {l1i l2iProposition 4.2 result returned Procedure 4.1 stab(ci , Gi ).Proof. show every element group returned stable extension showinggenerators line 9 stable extensions; recall set stable extensionssubgroup. show every stable extension returned showingconstructed via procedure.first claim, argued main text elements g restrictiC0 } well. elementstable; must show elements {l1i l2i, however, note |cG1 = l1i |cG1 = gi similarly |cG2 , since agrees1120 stable.l1i = l2i = gi C l2i outside C . Thus l1i l2isecond claim, suppose stable extension ; consider restrictionG2G1G21cG1 c2 . intersection c1 c2 , must agree elements G1G2 ; call elements agrees l1 l2 . Restricting l2 awayintersection get l20 , see element l group generated0 } matches cG1 cG2 .{l1i l2i12G2G1G21consider l1 . identity cG1 c2 . Restricting either c1 c2G21get element G1 G2 point stabilizes cG1 c2 , elementsincluded directly line 9 resolution procedure. follows l1 elementhg restrict1C , g restrict2C i,0hg restrict1C , g restrict2C , {l1i l2i}i512fiZAP 3: ImplementationProcedure 5.3 Given groups H G, element G, sets c S, find groupelement g = map(G, H, t, c, S) g H cgt = :12345678910ctH 6=return failurec = cHreturn 1element c cHt0 (H : H )r map(G, H , t0 t, c, S)r 6= failurereturn rt0return failureProposition 5.4 map(G, G, 1, c, S) returns element g G cg = ,element exists, returns failure otherwise.Proof. remarked main text, prove slightly stronger resultmap(G, H, t, c, S) returns element g H cgt = element exists.proposition stated special case = 1.proof proceeds induction number elements c movedH. none are, either ct 6= procedure return failure line 2,ct = return 1 line 4.inductive step, assume H moves least one point c. Lines 14 dontaffect correctness procedure point, allow early terminationalready fixed point moved inside t. interesting case, formtransversal line 6. Every element H represented gt0 g Ht0 transversal. gt0 returned solution, knowinductive hypothesis g found recursive call line 7.Procedure 5.5 Given groups H G, element G, sets c, U integerk, find group element g = transport(G, H, t, c, S, U, k) g H, cgt =|cgt U | k:123456789101112ctH 6=return failure1overlap(H, c, (S U )t ) > kreturn failurec = cHreturn 1element c cHt0 (H : H )r transport(G, H , t0 t, c, S, U, k)r 6= failurereturn rt0return failure513fiDixon, Ginsberg, Hofer, Luks & ParkesProposition 5.6 Provided |ch V | overlap(H, c, V ) |cH V | h H,transport(G, c, S, U, k) computed Procedure 5.5 returns element g Gcg = |cg U | k, element exists, returns failure otherwise.1Proof. remarked main text, |c (S U )t | = |ct (S U )|. since ctrequired empty, |ct (S U )| = |ct U |. proof proceeds essentially unchangedProposition 5.4.two conditions overlap function necessary. need knowh|c V | overlap(H, c, V ) order avoid terminating search early line 3.need overlap(H, c, V ) |cH V | ensure fixed every element c,line 3 identify failure |ct U | > k dont return successfully line 6case.Procedure 5.8 Given group H, two sets c, V , compute overlap(H, c, V ), lowerbound overlap ch V h H:1234m0orbit W H+ max(|W V | |W c|, 0)returnProposition 5.9 Let H group c, V sets acted H. h H,|ch V | overlap(H, c, V ) |cH V | overlap computed Procedure 5.8.Proof. subtlety involves contribution fixed points clause makesum. since fixed point orbit, fixed points contribute either1 0 sum depending whether already V .Proposition 5.15 Let G group acting transitively set , let c, V .Suppose also {B1 , . . . , Bk } block system G c Bi 6= nblocks {B1 , . . . , Bk }. b size individual block Bi g G,|cg V | |c| + min(Bi V ) nb(32)Proof. g G, set n blocks collectively contain image cg .therefore use usual counting argument. Within n blocks, c contain|c| points, set V contain least min(Bi V ) points. nbpoints available, result follows.Proposition 5.16 block system trivial (in either sense), (32) equivalent|cg V | |T V | |T c|(33)Proof. Suppose first single block. n = 1, b = |T | oneset take minimum (32), therefore becomes|cg V | |c| + |T V | |T |= |T V | |T c|514fiZAP 3: ImplementationIf, hand, block system trivial point block,n = |c|, b = 1min(Bi V )smallest number points V must set size n,min(Bi V ) = n + |T V | |T |(32) becomes|cg V | |c| + |c| + |T V | |T | |c|= |c| + |T V | |T |= |T V | |T c|Proposition 5.17 Let {B1 , . . . , Bk } block system group G acting transitivelyset . (32) never weaker (33).Proof. Comparing (32) (33), see trying show|c| + min(Bi V ) nb |T V | |T c|= |c| + |T V | |T |min(Bi V ) nb |T V | |T |q blocks block system, equivalentminmin(Bi V ) nb iq (Bi V ) bqminbq nb miniq (Bi V ) (Bi V )(34)lefthand side (34) total amount space q b blocks includedmin(Bi V ), righthand side amount space used V within q bblocks. Thus (34) follows result proved.Lemma A.1 Let G group permutations, c set acted G. Suppose alsoU sets acted G. j G{c} g G permutation G,|cg S| = |cjg S||cg U | = |cjg U |Proof. immediate, since cj = c.515fiDixon, Ginsberg, Hofer, Luks & ParkesLemma A.2 Let G group permutations, c set acted G. Suppose alsoU sets acted G. k G{S,U } g G permutationG,|cg S| = |cgk S||cg U | = |cgk U |Proof. clearly suffices show result S; U equivalent.1|cgk S| = |cg k |= |cg S|1k = k set stabilizer therefore k 1 well (becauseset stabilizer group).Proposition 5.23 Let G group permutations, c set acted G. Supposealso U sets acted G. instance k-transporterproblem g G, either every element G{c} gG{S,U } solution I, none is.Proof. Combine lemmas A.1 A.2.Lemma A.3 Let G, J Sym() (ordered) set {x1 , . . . , xn } supposeSym() satisfies xtl = zl 1 l k k n. Suppose fixedk set Z = J{xi ,...,xk } . Suppose finallyZx ,...,xzi > min xi 1 i1h Gx1 ,...,xk first element Jh.Proof. given existence j Zx1 ,...,xi1 zi > xjt. Consider h = gtg Gx1 ,...,xk . Since j Z, j stabilizes set {xi , . . . , xk }. Since g stabilizes everyjgtjtpoint set, fixes xi xji . Thus xgt= xi xi = xi ,jtjgtxgt= xi = zi > xi = xijgthand, l < i, g j fix xl , xgtl = xl . Since jgt thus precedesgt, gt minimal Jgt.Lemma 5.26 Suppose permutation labeling node Ht coset decomposition tree depth k, xti = zi k H = Gx1 ,...,xk residualgroupJM,x,...,xlevel. Let set points moved Gx1 ,...,xk . zi > min xi 1 i1k, g Ht first element JgK.Proof. direct consequence Lemma A.3. Let permutation JM,x1 ,...,xi1 .Since fixes every point moved Gx1 ,...,xk , also fixes x1 , . . . , xi1 , followsmust permute remaining points xi , . . . , xk . Thus JM,x1 ,...,xi1 Zx1 ,...,xi1Z set stabilizer statement Lemma A.3, therefore g firstelement Jg. Since Jg JgK, result follows.Procedure 6.5 Given set X pairs hl, gi group G, compute complete(X, G),X |=G complete(X, G) L(complete(X, G)) = L(X)G :516fiZAP 3: Implementation123456hl, gi Xl0 lG L(Y )select h G lh = l0hl0 , ghireturnProposition 6.6 X |=G complete(X, G) L(complete(X, G)) = L(X)G .Proof. X |=G complete(X, G) every entry added clearly G-entailedX. L(complete(X, G)) = L(X)G entire image L(X) G eventuallyadded.Procedure 6.7 Given groups H G, element G, sets c, U , findTransport(G, H, t, c, S, U ), skeletal set unit consequences (c, G) given P :1234567891011121314151617181overlap(H, c, ) > 0return hfalse,1overlap(H, c, (S U )t ) > 1return hfalse,c = cHct U =return htrue, 1ielse return hfalse, hct U, 1iipruning lemma appliedreturn hfalse,element c cHt0 (H : H )hu, V Transport(G, H , t0 t, c, S, U )u = truereturn htrue, V t0else {hl, gt0 i|hl, gi V }return hfalse,Proposition 6.8 Assume |ch V | overlap(H, c, V ) |cH V | h H,let Transport(G, c, S, U ) computed Procedure 6.7. g Gcg = cg U = , Transport(G, c, S, U ) = htrue, gi g.g, Transport(G, c, S, U ) = hfalse, Zi, Z skeletal set unit consequences(c, G) given P .Proof. Procedure 6.7 identical Procedure 5.27 k = 1 except value returned. g cg = cg U = well, htrue, gi returnedline 7, cause htrue, gt0 returned recursive call(s) line 16also.g cg = cg U = , argument proceeds usualinduction number points c moved H. none, know correctanswer returned line 8 usual reasons; remains consider recursive case517fiDixon, Ginsberg, Hofer, Luks & Parkesline 18. know every g cg unit, accumulate resultg 0 minimal JgK J = G{c} K = G{S,U } usual. needshow set hl, gi collected indeed skeletal set unit consequences.see this, suppose hl, gi annotated unit consequence.minimal jgk accumulated set pairs accumulated line 17,associated literal l0 = cjgk U . since j G{c} set stabilizes clause c, cj = cl0 = cgk U . Thus taking given k G{S,U } produces given unit consequenceelement proposed skeleton, returned Procedure 6.7 indeedskeletal set unit consequences.Proposition 6.9 Let (c, G) augmented clause corresponding cardinality constraint. sets U , Procedure 6.7 expand linear numbernodes finding skeletal set unit consequences (c, G).Proof. original cardinality constraintx1 + + xm nG Sym(X) X set xi cx1 xmn+1first show Leons pruning lemma 5.24 suffices reduce searchquadratic size. basic idea part proof follows.Suppose expanding particular node, corresponding selectionimage point xi c. image xi selected S, pruneimmediately. image selected either U X U , imagesmallest available point set question lexicographic reasons. addition,original symmetry literals c used require literalsneither satisfied unvalued selected order expansion.make argument formally, note first J = G{c} = Sym(c) Sym(X c)K = G{S,U } = Sym(S) Sym(U ) Sym(X U ). assume without loss generalitypoints fixed coset decomposition tree xi order n + 1,continue denote fixed image xi particular search node zi .denote sequence zi less depth node question,fixed part image clause c. also set l = |X U |, total numberpoints valued unsatisfied.prune node which:1. 6= . nodes pruned image c meets setsatisfied literals.2. | U| > 1. above, nodes pruned image c includes twounsatisfied literals.3. = hy1 , ..., yj , ui, yi X U S, u U minimal U.Leons lemma 5.24 k = l requires u = zj+1 min(uKy1 ,...,yj ). sinceyi outside U , Ky1 ,...,yj Sym(U ) uKy1 ,...,yj U . Since u assumednonminimal U , node pruned.518fiZAP 3: Implementation4. (X U) = hy1 , . . . , yj i, y1 , . . . , yj1 first j 1 elementsX U order, yj X U next elementX U S. argument identical previous paragraph used, sinceKy1 ,...,yj1 includes full symmetry group remaining elements X U S.follows unpruned nodes search either= hy1 , . . . , yk k min(l, n + 1),= hy1 , . . . , yj , u, yj+1 , . . . , yk(35)k min(l, n), u minimal element U , yi smallest elementsX U order. need k l many possible values,k n + 1 k n depth tree clause ccompletely instantiated. linear number nodes first typequadratic number nodes second.reduce total number nodes searched linear, repeat argumentused discussion example following Lemma 5.26. There, considered nodeimage x1 z1 x2 z2 , z1 > z2 . Here, considerslightly general case, = hz1 , . . . , zk1 , zk i, zi sequence exceptzk1 > zk .Lemma 5.26, Gx1 ,...,xk full symmetry group remaining xi ,= {xk+1 , . . . , xm }. also J = Sym(x1 , . . . , xmn+1 ) Sym(xmn+2 , . . . , xm ).since k n + 1, taking = k 1 statement lemma gives usJM,x1 ,...,xi1 = JM,x1 ,...,xk2 Sym(xk1 , xk )result,(xk1zk1 > xk1xk )t= xtk = zknode pruned.fixes us position list point sequence amongyi thus reduces number search nodes linear.Proposition 7.8 Suppose W watching set C P l literal. Then:1. W watching set C backtrack point P .2. C settled hP, li, W watching set C hP, li.3. C settled hP, li, |(W {l}) C U (PC )| > 1, W {l}watching set C hP, li.4. l 6 W C, W watching set C hP, li.0Proof. None hard. First, note P 0 backtrack point P , Pcsubassignment Pc , watching set C P also watching setC P 0 .second claim, C settled hP, li, two possibilities:519fiDixon, Ginsberg, Hofer, Luks & Parkes1. C unsettled P (so addition l P caused C settled),hP, liC subassignment P (the subassignment proper P 6= P ). SinceC unsettled P , PC = P . Thus U (hP, liC ) U (PC ), W still watchingset.2. C settled P , hP, liC = PC , W still watching set.third claim follows second, since W {l} assumed watchingset C P .fourth claim, suppose l 6 C l 6 C. C U (P ) = C U (hP, li),W remains watching set. l C, C satisfied (and therefore settled)l added P . W continues watching set virtue second claim.remaining case, l C C U potentially smaller l removedl adjoined P . impact intersection W lW ; otherwise, W still watching set. W still watching set unless lC W , proves final claim.Proposition 7.10 Suppose W watching set (c, G) P l literal.Then:1. W watching set (c, G) backtrack point P .2. l 6 W cG , W watching set (c, G) hP, li.3. |(W V ) cg U (hP, li)| > 1 every g G cg unsettled hP, li,W V watching set (c, G) hP, li.4. |(W V ) cg [U (hP, li) (S(P ) S(P ))]| > 1 every g G, W V {l}watching set (c, G) hP, li.Proof. know W watching set every instance (c, G) P , useProposition 7.8 show claims follows.First, Proposition 7.8 states directly W watching set every instance (c, G)backtrack point P .Second, l 6 W cG , g G, l 6 W cg . second claim thusfollows fourth claim Proposition 7.8.remaining two claims interesting. third, suppose cginstance (c, G). cg settled hP, li, know W still watchingset hP, li. Therefore W V also watching set cg hP, li. cgunsettled hP, li, condition claim says |(W V ) cg U (hP, li)| > 1,W V watching set cg hP, li. completes proof thirdclaim.fourth final claim, three cases.1. cg unsettled hP, li, note first cg S(P ) = ,(W V ) cg [U (hP, li) (S(P ) S(P ))] = (W V ) cg U (hP, li)W V watching set cg hP, li. Since l 6 U (hP, li),(W V ) cg U (hP, li) = (W V {l}) cg U (hP, li)520fiZAP 3: ImplementationW V {l} watching set well.2. cg unit hP, li, consider:(a) l 6 cg , know fourth claim Proposition 7.8 Wwatching set cg hP, li. follows W {l} must well, sincel 6 cg . Thus W V {l}.(b) l cg , cg must formcg = x1 xk l unew unit consequence u, xi S(P ). Note also l cannoteither U (hP, li) S(P ). Thuscg [U (hP, li) (S(P ) S(P ))] = {u}violation premise claim.3. Finally, cg satisfied hP, li, know W (and therefore W V ) watchingset cg hP, li; trick show remove l W V safely.l 6 cg , obviously so.l cg , need show third claim Proposition 7.8 applied,need show|(W V {l}) cg U (Pcg )| > 1(36)Given assumption|(W V ) cg [U (hP, li) (S(P ) S(P ))]| > 1(37)note first since l 6 U (hP, li) (S(P ) S(P )), l intersection(37), therefore equivalent|(W V {l}) cg [U (hP, li) (S(P ) S(P ))]| > 1follows (36) follow showU (Pcg ) U (hP, li) (S(P ) S(P ))(38)U (Pcg ) U (hP, li)(39)Pcg (proper) subassignment hP, li. alsoU (Pcg ) U (P ) S(P ) S(P )(40)first inclusion holds since l cg cg satisfied hP, li, cg mustsatisfied P well. Thus Pc involves backtrack P , since Plast backtrack point P , Pcg subassignment P U (Pcg ) U (P ).second inclusion (40) holds literals satisfied PP must necessarily unvalued P . Combining (39) (40) gives us(38), result proved.521fiDixon, Ginsberg, Hofer, Luks & ParkesProcedure 7.11 Given group H, two sets c, V acted H, bound k 0,compute overlap(H, c, V, k), collection elements V sufficient guaranteeh H, |ch V | > k, collection exists:1 m02 W3 orbit X H4{B1 , . . . , Bk } minimal block system W Hc W Bi5= |c X| + min(Bi V ) |B1 |6> 07+8W W (X V )9> k10return W11 returnProposition 7.12 Procedure 7.11 returns nonempty set W Procedure 5.19returns value excess k. case, |ch W | > k every h H.Proof. first claim, examine two procedures. clear Procedure 7.11returns soon Procedure 5.19 concludes minimum overlap greater k;need simply argue W nonempty. increment W line 8 mustnonempty, since X V = , zero line 6.second part, imagine replacing V procedure set W returned.computation unchanged every step, conclusion follows.Procedure 7.13 Given groups H G, element G, sets c, U , optionally watched element w, find Transport(G, H, t, c, S, U, w), skeletal set unitw-consequences (c, G) given P :522fiZAP 3: Implementation1234567891011121314151617181920212223241w supplied wt 6 cHreturn hfalse, ,1V overlap(H, c, , 0)V 6=return hfalse, ,1V overlap(H, c, (S U )t , 1)V 6=return hfalse, , Vc = cHct U =return htrue, 1,else return hfalse, hct U, 1i,pruning lemma appliedreturn hfalse, ,1element c cH . w supplied w 6 ctH , choose wt H .Wt0 (H : H )hu, V, Xi Transport(G, H , t0 t, c, S, U, w)u = truereturn htrue, V t0 ,else W W X{hl, gt0 i|hl, gi V }return hfalse, Y, WProposition 7.14 Suppose overlap(H, c, V, k) computed using Procedure 7.11,otherwise satisfies conclusion Proposition 7.12. g Gw cg cg = cg U = , Transport(G, c, S, U, w) computed Procedure 7.13returns htrue, g, g. g, Procedure 7.13 returns hfalse, Z, W i,Z skeletal set unit w-consequences (c, G) given P , W|W G{S,U,{w}} ch U | > 1 every h H w ch ch unsettled P .Proof. restriction permutations g w cg enforced first twolines procedure; note contradiction found line 11, pointsc fixed, w cg certain. Note prune basiswithout affecting overall correctness procedure, since pruning lemmasrestricted group K = G{S,U,{w}} , leaves watched literal w intact.difference Procedure 7.14 Procedure 6.7 involves computation set W watched literals. set produced line 8, knowProposition 7.12 set W sufficient guarantee |W cht U | > 1every cht current residual search tree. must therefore show h satisfyingconditions proposition covered W G{S,U,{w}} . see this, consider everypoint node pruned procedure, show points coveredexclusions statement proposition:1. prune line 2 occur w 6 cht h H.523fiDixon, Ginsberg, Hofer, Luks & Parkes2. prune line 5 occur cht 6= every h H, cht settledP .3. pruning lemma applied, must eventual solution g shownminimal usual double coset G{c} gG{S,U,{w}} . case,watching set operated G{S,U,{w}} statement propositionitself.Procedure 7.16 (Unit propagation) compute Unit-Propagate(C, P, L) Cset watched augmented clauses, P annotated partial assignment, L setpairs hl, ri literals l reasons r:1 L 6=2hl, ri element L3L L hl, ri4P hP, hl, rii5h(c, G), W C6l W7hr, H, V Transport(G, c, S(P ), U (P ), l)8r = true9li literal cH highest index P10return htrue, resolve((cH , G), ci )i011H complete(H, G{S(P ),U (P ),{l}} )12h H 013z literal ch unassigned P14hz, r0 L15L L hz, ch16W W (U (P ) V G{S(P ),U (P ),{l}} )17U U (P ) (S(P ) S(P ))18H = transport(G, c, , W U, 1, l) = failure19W W {l}20 return hfalse, PProposition 7.17 Let P annotated partial assignment, C set watchedaugmented clauses, every h(c, G), W C, W watching set (c, G) P .Let L set unit consequences clauses C. Unit-Propagate(C, P, L) returnshtrue, ci augmented clause c, c nogood P , modified watchingsets C still watching sets P . Otherwise, value returned hfalse, Pwatching sets C replaced watching sets P .Proof. really matter assembling pieces. Procedure 7.16 essentiallyloop literals L, much like original procedure 2.7. literall, find unit clauses contain l appropriate call Transportclause l watched. Transport call reveals presence contradiction,return resolvent reasons l l usual. contradiction found,adjust partial assignment Procedure 2.7, add new unit consequences524fiZAP 3: Implementationlist remains analyzed, update watching set accordancePropositions 7.10 7.14.remaining issue removal l watching set W line 19Procedure 7.16. precisely fourth claim Proposition 7.10applied. Note call transport, use U (P ) instead U (hP, li), since lalready added P line 4. also require l instance cg , sinceotherwise intersection cg obviously unaffected removal l.Lemma 8.3 c1 c2 two nogoods P , c1 <P c2 .Proof. immediate. soon last literal c2 c1 (which must happeneventually literals removed Definition 8.2), falsification depth c2 exceedc1 .Procedure 8.4 Suppose given two augmented clauses (, G) (, H)unit partial assignment P = hl1 , . . . , ln i, l l . find <P -minimall-resolvent (, G) (, H):12345678910111213U {l, l}literals cant avoidffp [( ) U ]?Pp > 0g transport(G, , {lp , . . . , ln } U, , 0, l)h transport(H, , {lp , . . . , ln } U, , 0, l)g = failure h = failureU U {lp }else f gf hp [(f f ) U ]?Preturn resolve(f , f )Proposition 8.5 Suppose given two augmented clauses (, G) (, H)unit partial assignment P , l l . valuereturned Procedure 8.4 <P -minimal l-resolvent (, G) (, H).Proof. need show procedure terminates, returns l-resolvent,result <P -minimal.show Procedure 8.4 terminates, show p reduced every iterationmain loop. beginning iteration, knowlp (f f ) U(41)end iteration, line 9 selected, f f unchanged lpadded U . means (41) longer satisfied, still satisfiedli > p. Thus p reduced line 12.If, hand, lines 10 11 selected, know definition gh lines 6 7 literal l {lp , . . . , ln } U , l 6 (f f ).words, l {lp , . . . , ln }, l 6 (f f ) U . Thus preduced, procedure therefore terminates. returns resolvent clear.525fiDixon, Ginsberg, Hofer, Luks & Parkessee value returned <P -minimal, suppose gm hmgm hm <P f f . show f f cannot permutations returnedline 13.Set z = [(f f ) (gm hm )]?P ; last point included f imagesproduced procedure images provided hypothetical counterexample. Since gm hm <P f f , two sets agree literals index greaterz.Since lz (f f ), initial value p set line 4 least z; sinceprocedure terminates p < 0, final value less z.Consider point procedure p changes value less z oneless z. change lp added U , one transport callsmust failed, impossible (say) image avoid {lp , . . . , ln }U .know f avoids {lp+1 , . . . , ln } U . Thus gm avoids {lp+1 , . . . , ln } U ,assuming lp 6 gm , transport(Gl,l , , {lp , . . . , ln } U, , 0)succeeded all.follows change p must lines 10 11. alsoimpossible, since fact successfully managed avoid lz contradictsassumption z = [(f f ) (gm hm )]?P lz f f .Appendix B. ZAP Problem FormatHistorically, Boolean satisfiability problems typically format variables correspond positive integers, literals nonzero integers (negative integers negatedliterals), clauses terminated zeroes. dimacs format precedes actualclauses problem single line p cnf 220 1122 indicating220 variables appearing 1,122 clauses problem.numerical format makes impossible exploit existing understandinguser might problem question; may problem conventionalBoolean tool (since problem structure obscured Boolean encodingevent), felt inappropriate building augmented solver. feltimportant user able to:1. Specify numerical constraints appear cardinality parity constraints,2. Quantify axioms finite domains,3. Provide group augmentations explicitly mechanisms insufficient.discussing specific provisions zap makes areas, remarkzap input file begins list domain specifications, giving namessizes domain used theory. followed predicate specifications, givingarity predicate domain type argument. predicatesdomains defined, possible refer predicate instances directly (e.g.,in[1 3] indicating first pigeon third hole) nonground fashion (e.g.,in[x y]).526fiZAP 3: ImplementationGroup definition group specified directly, assigned symbolic designatorused augmented clause. group syntax conventional one,group described terms generators, permutation.permutation list cycles, cycle space-separated list literals.augmented clause uses previously defined group formclauseGROUPgroup1groupn(ground) clause essentially sequence literals groupidesignator group used. group augmented clause groupcollectively generated groupi s.example, group-based encoding pigeonhole instance involvingfour pigeons three holes:// domain specsSORT pigeon 4 ;SORT hole 3 ;// predicate specsPREDICATE in(pigeon hole) ;// group specsGROUP G < ((in[1((in[1(in[1((in[1(in[4((in[1(in[41]1]3]1]1]1]1]in[2in[3in[3in[1in[4in[1in[41]) (in[1 2] in[21] in[4 1]) (in[13] [4 3]))2]) (in[2 1] in[22]))3]) (in[2 1] in[23])) > ;2]) (in[1 3] in[2 3]))2] in[3 2] [4 2])// permute pigeons2]) (in[3 1] in[3 2])// permute holes3]) (in[3 1] in[3 3])// group-based encoding-in[1 1] -in[2 1] GROUP G ;in[1 1] in[1 2] in[1 3] GROUP G ;two types domain variables, pigeons (of four) holes (ofthree). single predicate indicating given pigeonparticular hole. single group, corresponds symmetries holespigeons.generate group, use four generators. first two correspond symmetrypigeons, first generator swapping first two pigeons second generatorrotating pigeons one, three four. (Recall permutations (1, 2) (1, 3, 4)generate symmetry group S4 pigeons.)second pair generators generate symmetry holes similarly, firstgenerator swapping first two holes second generator swapping holes onethree. (Once again, (1, 2) (1, 3) generate S3 .)Turning axioms, first says first hole cannot contain firsttwo pigeons, therefore hole contain two distinct pigeons virtuegroup action. second axiom says first pigeon hole,therefore every pigeon does.527fiDixon, Ginsberg, Hofer, Luks & ParkesCardinality parity constraints group specified directly, generalform zap axiomquantifiers clause resultquantifiers described below. result includes informationdesired right hand side axiom, following:simple terminator, indicating clause Boolean,comparison operator (>, <=, =, etc.) followed integer, indicatingclause cardinality constraint,mod-2 operator (%2=) followed integer m, indicating sumvalues literals required congruent mod 2.Quantificationquantifiers form(x1 , . . . , xk )(x1 , . . . , xk )xi variables appear future predicate instances.addition two classical quantifiers above, also introduce(x1 , . . . , xk )quantifier means variables take values causequantified predicates instances become identical. example, axiom sayingone pigeon hole becomes(p1 , p2 , h) . in(p1 , h) in(p2 , h)(42)Contrast conventional(p1 , p2 , h) . in(p1 , h) in(p2 , h)(43)specific pigeon p hole h,in(p, h) in(p, h)(44)instance (43) (42). Since (44) equivalent in(p, h), inappropriateinclusion pigeonhole formulation.introduction new quantifier understood light discussionSection 6.1 zap2, argued many cases, quantification givenfact natural provided . quantification also far easierrepresent using augmented clauses, avoids many cases need introducereason equality. event, zap supports forms universal quantification.quantifier-based encoding pigeonhole problem:528fiZAP 3: ImplementationSORT pigeon 9;SORT hole 8;PREDICATE in(pigeon hole);// quantification-based encodingNOTEQ (x z) -in[x z] -in[y z] ;FORALL(z) EXISTS(h) in[z h] ;nine pigeon instance. two axioms say directly hole z containtwo distinct pigeons x (note use NOTEQ ), every pigeon zhole h. encoding presumably intuitive previous one.ReferencesAho, A. V., Hopcroft, J. E., & Ullman, J. D. (1974). Design Analysis ComputerAlgorithms. Addison-Wesley.Babai, L., & Moran, S. (1988). Arthur-Merlin games: randomized proof system,hierarchy complexity classes. J. Comput. System Sci., 36, 254276.Barth, P. (1995). Davis-Putnam based enumeration algorithm linear pseudoboolean optimization. Tech. rep. MPI-I-95-2-003, Max Planck Institut fur Informatik,Saarbrucken, Germany.Bayardo, R. J., & Miranker, D. P. (1996). complexity analysis space-bounded learningalgorithms constraint satisfaction problem. Proceedings ThirteenthNational Conference Artificial Intelligence, pp. 298304.Bayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques solve real-worldSAT instances. Proceedings Fourteenth National Conference ArtificialIntelligence, pp. 203208.Dixon, H. E., & Ginsberg, M. L. (2000). Combining satisfiability techniques AIOR. Knowledge Engrg. Rev., 15, 3145.Dixon, H. E., Ginsberg, M. L., Luks, E. M., & Parkes, A. J. (2004a). Generalizing Booleansatisfiability II: Theory. Journal Artificial Intelligence Research, 22, 481534.Dixon, H. E., Ginsberg, M. L., & Parkes, A. J. (2004b). Generalizing Boolean satisfiabilityI: Background survey existing work. Journal Artificial Intelligence Research,21, 193243.Furst, M., Hopcroft, J., & Luks, E. (1980). Polynomial time algorithsm permutationgroups. Proceedings 21st Annual IEEE Symp. Foundations Computer Science(FOCS-80), pp. 3641. IEEE.GAP Group (2004).GAP Groups, Algorithms Programming, Version 4.4.http://www.gap-system.org.Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,1, 2546.Ginsberg, M. L., & Parkes, A. J. (2000). Search, subsearch QPROP. ProceedingsSeventh International Conference Principles Knowledge RepresentationReasoning, Breckenridge, Colorado.529fiDixon, Ginsberg, Hofer, Luks & ParkesGomes, C. P., & Selman, B. (1997). Problem structure presence perturbations.Proceedings Fourteenth National Conference Artificial Intelligence, pp.221226, Providence, RI.Haken, A. (1985). intractability resolution. Theoretical Computer Science, 39, 297308.Harrison, M. A. (1989). Introduction Switching Automata Theory. McGraw-Hill.Heule, M., & van Maaren, H. (2004). Aligning CNF- equivalence-reasoning.Seventh International Conference Theory Applications Satisfiability Testing,pp. 174180. Also available http://www.satisfiability.org/SAT04/programme/72.pdf.Hooker, J. N. (1988). Generalized resolution cutting planes. Annals OperationsResearch, 12, 217239.Jerrum, M. (1986). compact representation permutation groups. J. Algorithms, 7,6078.Knuth, D. E. (1991). Notes efficient representation permutation groups. Combinatorica, 11, 5768.Leon, J. (1991). Permutation group algorithms based partitions I: Theory algorithms.J. Symbolic Comput., 12, 533583.Li, C. M. (2000). Integrating equivalency reasoning Davis-Putnam procedure.Proceedings Seventeenth National Conference Artificial Intelligence, pp. 291296.Li, C. M. (2003). Equivalent literal propagation Davis-Putnam procedure. Discrete App.Math., 130 (2), 251276.Li, C. M., Jurkowiak, B., & Purdom, Jr., P. W. (2002). Integrating symmetry breakingDLL procedure. Fifth International Symposium Theory ApplicationsSatisfiability Testing (SAT2002), pp. 149155.Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineeringefficient SAT solver. 39th Design Automation Conference.Pudlak, P. (1997). Lower bounds resolution cutting planes proofs monotonecomputations. J. Symbolic Logic, 62 (3), 981998.Rotman, J. J. (1994). Introduction Theory Groups. Springer.Schaefer, T. J. (1978). complexity satisfiability problems. ProceedingsTenth Annual ACM Symposium Theory Computing, pp. 216226.Seress, A. (2003). Permutation Group Algorithms, Vol. 152 Cambridge Tracts Mathematics. Cambridge University Press, Cambridge, UK.Sims, C. C. (1970). Computational methods study permutation groups. Leech, J.(Ed.), Computational Problems Abstract Algebra, Proc. Conf. Oxford, 1967. Pergamon Press.Tseitin, G. (1970). complexity derivation propositional calculus. Slisenko,A. (Ed.), Studies Constructive Mathematics Mathematical Logic, Part 2, pp.466483. Consultants Bureau.530fiZAP 3: ImplementationUrquhart, A. (1987). Hard examples resolution. JACM, 34, 209219.Zhang, H., & Stickel, M. E. (2000). Implementing Davis-Putnam method. JournalAutomated Reasoning, 24 (1/2), 277296.531fiJournal Artificial Intelligence Research 23 (2005) 667-726Submitted 07/04; published 06/05Keys, Nominals, Concrete DomainsCarsten Lutzlutz@tcs.inf.tu-dresden.deTheoretical Computer Science, TU DresdenD-01062 Dresden, GermanyCarlos Arecesareces@loria.frINRIA Lorraine, Nancy54602 Villers les Nancy Cedex, FranceIan Horrockshorrocks@cs.man.ac.ukDepartment Computer ScienceUniversity ManchesterOxford Road, Manchester M13 9PL, UKUlrike Sattlersattler@cs.man.ac.ukDepartment Computer ScienceUniversity ManchesterOxford Road, Manchester M13 9PL, UKAbstractMany description logics (DLs) combine knowledge representation abstract, logicallevel interface concrete domains like numbers strings built-in predicates <, +, prefix-of. hybrid DLs turned useful severalapplication areas, reasoning conceptual database models. proposeextend DLs key constraints allow expression statements likeUS citizens uniquely identified social security number. Based idea,introduce number natural description logics perform detailed analysisdecidability computational complexity. turns naive extensionskey constraints easily lead undecidability, whereas careful extensions yield NExpTime-complete DLs variety useful concrete domains.1. MotivationDescription logics (DLs) family formalisms allow representationreasoning conceptual knowledge structured semantically well-understoodmanner (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003). centralentities representing knowledge concepts, constructed atomicconcept names (unary predicates) role names (binary relations) means conceptrole constructors offered particular DL. example, basic propositionallyclosed description logic ALC (Schmidt-Schau & Smolka, 1991), describe companypart-time employees full-time managers using conceptCompany u employee.Parttime u employee.(Manager Parttime).example, words beginning uppercase letters denote concept namesemployee denotes role name.c2005AI Access Foundation. rights reserved.fiLutz, Areces, Horrocks, & SattlerRather viewed conceptual entities knowledge base, conceptscan, generally, understood central notion various kinds class-centeredformalisms. last decade, observation given rise various new challenging applications description logics reasoning database conceptual modelsexpressed entity-relationship diagrams object-oriented schemas (Calvanese, Lenzerini,& Nardi, 1998; Calvanese, De Giacomo, & Lenzerini, 1998) reasoning ontologiesuse semantic web (Baader, Horrocks, & Sattler, 2002a; Horrocks, 2002; Horrocks,Patel-Schneider, & van Harmelen, 2002). new applications have, turn, stimulatedresearch description logics since expressive power existing DLs insufficientnew tasks. One important extension providing expressive means allowintegration numbers datatypes: suppose, example, wantextend earlier descriptions companies employees include founding yearcompany hiring year employee. Then, may want describe companiesfounded 1970 state hiring year employees priorfounding year employing company. this, obviously need way talknatural numbers (such 1970) comparisons natural numbers.Nowadays, standard approach integrate datatypes description logicsextend DLs concrete domains, first proposed Baader Hanschke (1991a)recently surveyed Lutz (2003). precisely, concrete domain consists set(such natural numbers) predicates associated fixed extensionset1 (such unary =0 , binary <, ternary +). integrationconcrete domains into, say, description logic ALC achieved adding1. abstract features, i.e. functional roles;2. concrete features, i.e. (partial) functions associating values concrete domain(e.g., natural numbers) logical objects;3. concrete domain-based concept constructor.DL obtained extending ALC way called ALC(D), denotesconcrete domain viewed parameter logic. example, usingsuitable concrete domain describe constraints formulated above: conceptEmployee u employer.foundingyear.<1970 u hiringyear, (employer foundingyear).describes set employees employed company founded 1970hiring year prior companys founding year. example, termfoundingyear.<1970 instance concrete domain concept constructor (notconfused existential value restriction employee.Parttime), thirdconjunct. <1970 unary predicate thus former instance takes oneconcrete feature foundingyear argument, second instance uses binary predicaterequiring two arguments: concrete feature hiringyear sequence features(employer foundingyear) consisting abstract feature employer concrete featurefoundingyear.Concrete domains rather important many applications DLs, including twomentioned above:1. fixed extension predicates often called built-in.668fiKeys, Nominals Concrete Domainsstandard way using description logics reasoning conceptual databasemodels translate given model DL representation use DL reasoner FaCT (Horrocks, 1998) RACER (Haarslev & Moller, 2001) computeconsequences information provided explicitly model. includesdetecting inconsistencies inferring additional, implicit containments entities/classes (Calvanese et al., 1998). Since databases store concrete datalike numbers strings, constraints concerning data usually partconceptual model thus also captured description logic usedreasoning. Indeed, example concepts viewed DL encodingconstraints database companies employees. discussedLutz (2002c), description logics concrete domains well-suited conceptual modeling applications involving concrete datatypes.So-called concrete datatypes play prominent role construction ontologies (Horrocks et al., 2002). Say, example, want construct ontologyused describing car dealers web pages web services.ontology, concrete datatypes prices, manufacturing years, names carmodels doubtlessly important. formulate ontology using DL,need way represent concrete datatypes. Consequently, almost DLsproposed ontology language equipped form concretedomain (Fensel, van Harmelen, Horrocks, McGuinness, & Patel-Schneider, 2001; Horrocks et al., 2002; Dean, Connolly, van Harmelen, Hendler, Horrocks, McGuinness,Patel-Schneider, & Stein, 2002). Furthermore, since ontology languages provideinverse abstract roles functional restrictions, users ontology designersquite surprised find provide inverse concrete functionalfeatureswhich due fact features correspond concrete keyconstraints, reasoning algorithms known whose effectdecidability/complexity yet investigated.paper, propose enhance expressive power description logicsconcrete domains extending concrete key constraints. extensionuseful knowledge representation two applications sketched above.following three examples describe basic idea.1. Suppose that, knowledge representation application, represent nationalitiesconcept names US German and, US citizens, store socialsecurity number using concrete feature ssn. would natural stateUS citizens uniquely identified social security number, i.e. two distinctinstancesHuman u nationality.USmust different values ssn feature. extension DLs concretedomains, expressed using key assertion 2(ssn keyfor Human u nationality.US).2. Readers familiarVrelationship DLs first order logic notice key assertionequivalent x1 x2 .(( i{1,2} (Human(xi )z.(nationality(xi , z)US(z)))(x1 = x2 )) (ssn(x1 ) =ssn(x2 ))).669fiLutz, Areces, Horrocks, & Sattler2. Returning database companies employees, could usefulequip every employee (i) concrete feature branch storing branch-IDworking (ii) concrete feature id storing personnel-ID. wouldnatural enforce branch-ID together personnel-ID uniquelyidentifies employees, even though personnel-IDs unique.using composite key assertion(branch, id keyfor Employee).3. car dealers ontology, may assume cars well manufacturersequipped identification numbers every car uniquely identifiedcombination identification number manufacturers one. expressthis, could employ composite key assertion referring sequences features,case (manufacturer id):(id, (manufacturer id) keyfor Car).formally, propose extend DLs provide concrete domains key boxes,sets key assertions form(u1 , . . . , un keyfor C),ui sequence f1 fn g abstract features fj followed single concretefeature g, C concept. examples illustrate, idea key constraintsnatural. Since, moreover, keys play important role databases and, mentionedabove, reasoning database conceptual models important, challenging applicationdescription logics, several approaches extend description logics keys alreadyinvestigated (Borgida & Weddell, 1997; Calvanese, De Giacomo, & Lenzerini, 2000;Khizder, Toman, & Weddell, 2001). distinguishes approach existing ones,however, idea using concrete domains constructing key constraints, ratherdefining keys abstract, logical level.goal paper provide comprehensive analysis effects decidability computational complexity adding key boxes description logics concretedomains. end, extend two description logics ALC(D) SHOQ(D) keyboxes, way obtaining ALCK(D) SHOQK(D), respectively. basic DLconcrete domains ALC(D) already discussed above, SHOQ(D) proposedontology language (Horrocks & Sattler, 2001). provides wealth expressivepossibilities general concept inclusion axioms (GCIs), transitive roles, role hierarchies, nominals, qualifying number restrictions. Moreover, offers restricted variantconcrete domain constructor disallows use sequences features orderavoid undecidability reasoning. main outcome investigations keyconstraints dramatic impact decidability complexity reasoning:example, whereas satisfiability ALC(D)-concepts known PSpace-complete (Lutz,2002b), show satisfiability ALCK(D)-concepts w.r.t. key boxes is, general,undecidable. Decidability regained restrict concepts used key boxes670fiKeys, Nominals Concrete DomainsBoolean combinations concept names (Boolean key boxes). Interestingly, satisfiability ALCK(D)-concepts w.r.t. Boolean key boxes still NExpTime-complete evensimple concrete domains. case SHOQ(D) SHOQK(D), leapcomplexity somewhat less dramatic since SHOQ(D)-concept satisfiability already ExpTime-complete: again, addition key boxes results NExpTime-complete reasoningproblems.interesting note exists close connection key assertionsso-called nominals, i.e. concept names one instance,Pope. Nominals standard means expressivity description logics sometimesappear disguise one-of operator (Borgida & Patel-Schneider, 1994; Horrockset al., 2002). hard see key boxes simulate nominals: if, example,use concrete domain based natural numbers providing unary predicates=n equality n , key assertion (g keyfor >), > standslogical truth, obviously makes concept g.=n behave like nominal, n. reason, also consider ALCO(D), extension ALC(D) nominals,ALCOK(D), extension ALCK(D) nominals.3 main result concerningnominals that, although general lower expressive power key boxes,already make reasoning NExpTime-hard combined concrete domains: existconcrete domains ALCO(D)-concept satisfiability NExpTime-complete.like stress NExpTime-hardness results obtainedpaper accordance observation made (Lutz, 2004) PSpace-upperbound reasoning ALC(D) robust w.r.t. extensions logic: existseveral seemingly harmless extensions ALC(D) (for example acyclic TBoxesinverse roles) make complexity reasoning leap PSpace-completenessNExpTime-completeness many natural concrete domains.NNremainder paper organized follows: Section 2, formally introduceconcrete domains, key boxes, DL ALCOK(D) together fragments ALCK(D)ALCO(D). Moreover, define Boolean key boxes, allow Boolean combinations concept names appear key definitions. Additionally, introduceimportant properties key boxes: path-free key boxes prohibit use sequencesfeatures key assertions; unary key boxes, key assertion involves exactly onesequence features; composite key boxes simply non-unary ones.Section 3 devoted establishing lower bounds extensions ALC(D) keyboxes nominals. Section 3.1, use reduction Post Correspondence Problemprove ALCK(D)-concept satisfiability w.r.t. (non-Boolean) key boxes undecidablelarge class concrete domains. shift attention Boolean key boxessince, Section 4, show restriction restores decidability. Section 3.2,introduce NExpTime-complete variant domino problem three concretedomains useful reduction problem concept satisfiability DLsBoolean key boxes nominals. Section 3.3, use concrete domainsprove ALCK(D)-concept satisfiability w.r.t. Boolean, path-free unary key boxesNExpTime-hard natural concrete domains. Section 3.4, proveexist concrete domains ALCO(D)-concept satisfiability without reference3. Note logic SHOQ(D) already provides nominals.671fiLutz, Areces, Horrocks, & Sattlerkey boxes already NExpTime-hard; show true even concretedomains computationally simple (PTime) considered isolation.purpose Section 4 develop reasoning procedures description logicskey boxes prove upper complexity bounds matching NExpTime lower boundsestablished previous section. start Section 4.1 tableau algorithmdecides ALCOK(D)-concept satisfiability w.r.t. Boolean key boxes, provided concrete domain key-admissible. Intuitively, concrete domain key-admissibleexists algorithm takes finite conjunction c predicates setvariables, decides whether conjunction satisfiable and, so, chooses solution creturns information variables take values it. callalgorithm D-tester. chosen tableau algorithm since type reasoningprocedure potential implemented efficient reasoners shownbehave well practice (Horrocks, Sattler, & Tobies, 2000; Haarslev & Moller, 2001).algorithm implies following upper complexity bound: key-admissible concretedomain non-deterministic polynomial time D-tester exists, ALCO(D)concept satisfiability w.r.t. Boolean key boxes NExpTime.Section 4.2, devise tableau algorithm SHOQK(D)-concept satisfiabilityw.r.t. path-free key boxes might involve non-Boolean concepts. decidabilityALCOK(D), restricted key boxes Boolean ones. SHOQK(D), restriction possible since SHOQ(D) provides TBoxes, thus longer distinguishBoolean non-Boolean concepts. hand, follows undecidability proof Baader Hanschke (1992) SHOQ(D) undecidable allowsequences features concrete domain constructors. Thus restrict key assertionsanalogously path-free ones, show yields indeed decidable logic. expressive power orthogonal one ALCOK(D), previous undecidabilityresults imply combination ALCOK(D) SHOQK(D) undecidable.by-product correctness proof algorithm, obtain bounded model property SHOQK(D), implies SHOQK(D)-concept satisfiability w.r.t. path-freekey boxes NExpTime key-admissible concrete domain nondeterministic polynomial time D-tester exists.Section 5, summarize results obtained give outlook possible futureresearch.2. Description Logics Concrete Domainsfollowing, introduce description logic ALCOK(D). Let us start definingconcrete domains:Definition 2.1 (Concrete Domain). concrete domain pair (D , ),set set predicate names. predicate name P associatedarity n n-ary predicate P nD .Based concrete domains, define ALCOK(D)-concepts key boxes.Definition 2.2 (ALCOK(D) Syntax). Let NC , , NR , NcF pairwise disjoint countably infinite sets concept names, nominals, role names, concrete features. Furthermore, assume NR contains countably infinite subset NaF abstract features.672fiKeys, Nominals Concrete Domainspath u composition f1 fn g n abstract features f1 , . . . , fn (n 0) concretefeature g. Let concrete domain. set ALCOK(D)-concepts smallest setevery concept name every nominal concept,C concepts, R role name, g concrete feature, u1 , . . . , un paths,P predicate arity n, following expressions also concepts:C, C u D, C D, R.C, R.C, u1 , . . . , un .P, g.key assertion expression(u1 , . . . , uk keyfor C),u1 , . . . , uk (k 1) paths C concept. finite set key assertionscalled key box.usual, use > abbreviation arbitrary propositional tautology,abbreviation >, C abbreviation C D, C abbreviation(C D) u (D C). Throughout paper, also consider several fragmentsdescription logic ALCOK(D). DL ALCO(D) obtained ALCOK(D)admitting empty key boxes. particular, set ALCO(D)-concepts setALCOK(D)-concepts. Furthermore, disallowing use nominals, obtainfragment ALC(D) ALCO(D) ALCK(D) ALCOK(D).description logic ALCOK(D) equipped Tarski-style set-theoretic semantics.Along semantics, introduce two standard inference problems: conceptsatisfiability concept subsumption.Definition 2.3 (ALCOK(D) Semantics). interpretation pair (I , ),non-empty set, called domain, interpretation function. interpretationfunction mapsconcept name C subset C ,nominal N singleton subset N ,role name R subset RI ,abstract feature f partial function f ,concrete feature g partial function g .673fiLutz, Areces, Horrocks, & Sattleru = f1 fn g path, uI (d) defined g (fnI (f1I (d)) ). interpretationfunction extended arbitrary concepts follows:(C)I := \ C(C u D)I := C DI(C D)I := C DI(R.C)I := {d | e (d, e) RI e C }(R.C)I := {d | e , (d, e) RI , e C }(u1 , . . . , un .P )I := {d | x1 , . . . , xn : uIi (d) = xi (x1 , . . . , xn ) P }(g)I := {d | g (d) undefined}.Let interpretation. model concept C iff C 6= . Moreover,satisfies key assertion (u1 , . . . , un keyfor C) if, a, b C ,uI1 (a) = uI1 (b), . . . , uIn (a) = uIn (b) implies = b.model key box K iff satisfies key assertions K. concept C satisfiablew.r.t. key box K iff C K common model. C subsumed concept w.r.t.key box K (written C vK D) iff C DI models K.well-known that, description logics providing Boolean operators, subsumptionreduced (un)satisfiability vice versa: C vK iff C u unsatisfiablew.r.t. K C satisfiable w.r.t. K iff C 6vK . allows us concentrate conceptsatisfiability devising complexity bounds reasoning description logics: lowerupper complexity bounds concept satisfiability imply corresponding boundsconcept subsumptiononly complementary complexity class.decision procedures description logics concrete domains devisedwithout committing particular concrete domain, well-defined interfacedecision procedure concrete domain reasoner needed. Usually, interfacebased assumption concrete domain admissible (Baader & Hanschke,1991a; Lutz, 2002a, 2003):Definition 2.4 (D-conjunction, Admissibility). Let concrete domain V setvariables. D-conjunction (finite) predicate conjunction form^ (i)c=(x0 , . . . , x(i)ni ) : Pi ,i<k(i)Pi ni -ary predicate < k xj variables V. D-conjunctionc satisfiable iff exists function mapping variables c elements(i)(i)((x0 ), . . . , (xni )) PiD < k. function called solution c.say concrete domain admissible iff1. contains unary predicate >D >D= ;2. closed negation, i.e., n-ary predicate P , predicateP arity n P = nD \ P ;674fiKeys, Nominals Concrete Domains3. satisfiability D-conjunctions decidable.refer satisfiability D-conjunctions D-satisfiability.shall see, sometimes makes considerable difference w.r.t. complexity decidability restrict key boxes various ways, example disallow paths length greaterone. Therefore, introduce useful notions.Definition 2.5 (Boolean, Path-free, Simple). key box K calledBoolean concepts appearing (key assertions in) K Boolean combinationsconcept names;path-free if, key assertions (u1 , . . . , un keyfor C) K, u1 , . . . , un NcF ;simple path-free Boolean;unary key assertions K unary key assertions, i.e. form (u keyfor C).concept C called path-free if, subconcepts form u1 , . . . , un .P , u1 , . . . , unconcrete features.emphasize key box might necessarily Boolean path-free, sometimescall key box general. Similarly, emphasize key box necessarilyunary key box, sometimes call key box composite.3. Lower Boundssection, prove lower complexity bounds description logics concrete domains key boxes and/or nominals. Section 3.1, start showing satisfiability ALCK(D)-concepts w.r.t. (general) key boxes undecidable many interestingconcrete domains. discouraging picture painted result mitigated factthat, Section 4.1, shall prove restriction Boolean key boxes restores decidability. thus interesting look lower complexity bounds applyrestriction. preparation this, introduce Section 3.2 NExpTime-complete variant domino problem three concrete domains well-suited reductionsproblem.Section 3.3, prove satisfiability path-free ALCK(D)-concepts w.r.t.simple key boxes NExpTime-hard large class concrete domains that,many concrete domains, holds even restrict key boxes unary ones. Finally,consider description logic ALCO(D) Section 3.4 identify several concretedomains ALCO(D)-concept satisfiability (without key boxes!) NExpTimehard. already mentioned, key boxes nominals closely related: key boxesexpress nominals, general powerful.3.1 Undecidability ALCK(D) General Key Boxesprove satisfiability ALCK(D)-concepts w.r.t. key boxes undecidablelarge class concrete domains allow complex ALCK(D)-concepts occur keyassertions. proof reduction well-known undecidable Post CorrespondenceProblem (Post, 1946; Hopcroft & Ullman, 1979).675fiLutz, Areces, Horrocks, & SattlerDefinition 3.1 (PCP). instance P Post Correspondence Problem (PCP) givenfinite, non-empty list (`1 , r1 ), . . . , (`k , rk ) pairs words alphabet .sequence integers i1 , . . . , im , 1, called solution P `i1 `im = ri1 rim .PCP decide whether given instance P solution.reducing PCP satisfiability DLs, need appropriate concretedomain. obviously natural use concrete domain based words concatenation.later see results obtained concrete domain carryconcrete domains based numbers arithmetics. following concrete domainintroduced Lutz (2004). definition presupposes fixed alphabet leastbinary.Definition 3.2 (Concrete domain W). concrete domain W defined setting W :=defining W smallest set containing following predicates:unary predicates word nword wordW = W nwordW = ,W+unary predicates = 6= =W= {} 6= = ,binary equality predicate = binary inequality predicate 6= obviousinterpretation,w + , two binary predicates concw nconcwWconcWw = {(u, v) | v = uw} nconcw = {(u, v) | v 6= uw}.readily checked W satisfies properties 1 2 admissibility (see Definition 2.4).Moreover, W-satisfiability decidable:Theorem 3.1 (Lutz, 2004). W-satisfiability PTime.Thus, W admissible even low complexity. important since aimdemonstrate undecidability ALCK(W)-concept satisfiability duepresence keys, due high complexity W-satisfiability.discuss reduction PCP. given instance (`1 , r1 ), . . . , (`k , rk )translated ALCK(D)-concept CP key box KP defined Figure 1P solution iff CP unsatisfiable w.r.t. KP . idea behind reductioncommon model CP KP encodes potential solutions P (i.e., sequences i1 , . . . ,integers ij 1 k) makes sure none fact solution.Figure 1, f1 , . . . , fk denote abstract features g, `, r denote concrete features.definition concept Step serves abbreviation confusedso-called TBoxes (see Section 4.2 definition TBoxes). Models CP KP ,one displayed Figure 2, form infinite k-ary tree whose rootconnected extra node x via role R. Intuitively, node tree representsone partial solution i1 , . . . , , `-successor represents corresponding left concatenation`i1 `in , r-successor corresponding right concatenation ri1 rin .enforce existence infinite tree, employ key box KP : considerexample root nodes f1 -successor Figure 2let us call node y. Due Line 3676fiKeys, Nominals Concrete DomainsStep :=u f .(A u g.= u `, r.6=)u u (`, f `.conc u r, f r.conc1ik1ik`iri )CP := `.= u r.=u R.(A u g.= u Step)u StepKP := {g keyfor Step}Figure 1: ALCK(W) reduction concept CP key box KP .R=conc`1`r=xfkconcrkf1g.=concr1 conc`k`f1rfkf1r`fkFigure 2: example model CP KP .CP Line 1 Step, (g.= )I . Due Line 2 CP , alsox (g.= )I x (Step)I , x extra node mentioned above. viewkey box KP , implies either (i) x = (ii) StepI . easy see(i) impossible since Line 2 CP Line 1 Step imply x AI (A)I .Hence StepI and, Line 2 Step, appropriate fi -successors 1 n.way, construction tree continued ad infinitum. secondline definition Step enforces `I (z) = `i1 `in rI (z) = ri1 rin zfi1 fin -successor root node. Finally, concept `, r.6= Line 1 Step implies`I (z) 6= rI (z) holds nodes z tree (except root), impliespotential solution solution.Since size CP KP clearly polynomial k key box KP unarykey box, obtain following proposition.Proposition 3.2. satisfiability ALCK(W)-concepts w.r.t. (non-Boolean) path-freeunary key boxes undecidable.677fiLutz, Areces, Horrocks, & Sattleremphasize undecidability result obtained using simple concretedomain, let us combine Theorem 3.1 Proposition 3.2.Theorem 3.3. exists concrete domain D-satisfiability PTimesatisfiability ALCK(D)-concepts w.r.t. (non-Boolean) path-free unary key boxesundecidable.first sight, concrete domain W might look artificial one may question relevance lower bounds obtained using W. However, straightforwardencode words natural numbers define concatenation words rather simple operations natural numbers (Baader & Hanschke, 1992): word w 6=alphabet cardinality # interpreted number written base # + 1symbol 0 digit occur. Hence, use corresponding natural number (e.g., base 10) represent word w, number 0represent empty word. concatenation two words v w expressedvw = v (#+1)|w| +w, |w| denotes length word w. Moreover, exponentiation expressed multiple multiplications, multiplication multiple additions,addition multiple incrementation: shown Section 5.6 (Lutz, 2004)case ALC(D) extended TBoxes (c.f. Section 4.2) easily adaptedALC(D) non-Boolean key boxes. observation gives rise following theorem:NTheorem 3.4. Let concrete domain , contains unary predicate =0 (=0 )D = {0}, binary equality inequality predicates, binary predicateincr incrD {(n, x) | n x } = {(k, k + 1) | k }. satisfiabilityALCK(D)-concepts w.r.t. (non-Boolean) path-free unary key boxes undecidable.NN3.2 Domino Problems Concrete Domainssection, introduce NExpTime-complete variant well-known, undecidabledomino problem (Berger, 1966; Knuth, 1968), define three concrete domains D1 ,D2 , D3 . concrete domains used Sections 3.3 3.4 establishlower bounds reasoning ALCK(D) Boolean key boxes, reasoningALCO(D).general, domino problem given finite set tile types. Intuitively, tiletypes size, type square shape colored edges. unlimitednumber tiles type available. NExpTime-hard variant dominoproblem use, task tile 2n+1 2n+1 -torus (i.e., 2n+1 2n+1 -rectanglewhose borders glued together) neighboring edges color.NDefinition 3.3 (Domino System). domino system triple (T, H, V ), (finite set tile types H, V represent horizontal vertical matchingconditions. Let domino system = a0 , . . . , an1 initial condition, i.e.n-tuple tiles. mapping : {0, . . . , 2n+1 1} {0, . . . , 2n+1 1} solutioniff, x, < 2n+1 , following holds:(x, y) = (x 2n+1 1, y) = t0 , (t, t0 ) H(x, y) = (x, 2n+1 1) = t0 , (t, t0 ) V678fiKeys, Nominals Concrete Domains(i, 0) = ai < n.denotes addition modulo i.follows results (Borger, Gradel, & Gurevich, 1997) variantdomino problem NExpTime-complete.define concrete domain D1 used reduction NExpTimecomplete domino problem ALCK(D1 )-concept satisfiability w.r.t. Boolean key boxes.Definition 3.4 (Concrete Domain D1 ). concrete domain D1 defined settingD1 := {0, 1} D1 (smallest) set containing following predicates:unary predicates >D1 (>D1 )D1 = D1 D1 (D1 )D1 = ;unary predicates =0 =1 (=i )D1 = {i}, {0, 1}.second concrete domain D2 used reduction NExpTime-completedomino problem ALCK(D2 )-concept satisfiability w.r.t. Boolean unary key boxes.reduction need store vectors bits single concrete domain elements.NDefinition 3.5 (Concrete Domain D2 ). every n , function v : {0, . . . , n 1}{0, 1} called bit vector dimension n. use BVn denote theSset bit vectorsdimension n. concrete domain D2 defined setting D2 := i>0 BVi D2(smallest) set containing following predicates:unary predicates >D2 (>D2 )D2 = D2 D2 (D2 )D2 = ;every k,N < k, unary predicates bit0ik bit1ik(bitnik )D2 = {v D2 | v BVk v(i) = n},unary predicates bit0ik bit1ik (bitnik )D2 = D2 \ (bitnik )D2 .last concrete domain D3 used reduction NExpTime-complete dominoproblem ALCO(D3 )-concept satisfiability. reduction, concrete domain D3contains two kinds elements: firstly, elements D3 representwhole 2n+1 2n+1 -torus, so-called domino arrays. Secondly, elements D3represent positions torus. technical reasons discussed later, elementsvectors natural numbers rather bit vectors, following shall callvectors. domino array function mapping pair vectors (of certainlength) natural number represents tile type.NNDefinition 3.6 (Concrete Domain D3 ). every k , function v : {0, . . . , k 1}called vector dimension k. use VEk denote set vectors dimension k.every k , function k : VEk VEkcalled domino array dimension k.use DAk denote setSof dominoarraysdimension k. concrete domain D3defined setting D3 := i>0 VEi i>0 DAi D3 (smallest) set containingfollowing predicates:NNunary predicates >D3 (>D3 )D3 = D3 D3 (D3 )D3 = ;679fiLutz, Areces, Horrocks, & Sattlerevery k,N < k, unary predicates pos0ik pos1ik(posnik )D3 = {v D3 | v VEk v(i) = n}unary predicates pos0ik pos1ik (posnik )D3 = D3 \ (posnik )D3 ;every k,N, predicate tileik arity 3(tileik )D3 = {(vx , vy , d) | vx , vy VEk , DAk , d(vx , vy ) = i}predicate tileik arity 3 (tileik )D3 = (D3 )3 \ (tileik )D3 .reason using vectors natural numbers rather bit vectors definitionD3 want D3 -satisfiability low complexity, preferably PTime: considerD3 -conjunctionpos002 (x) pos002 (y) pos002 (z)tile72 (x, v, d) tile82 (y, v, d) tile92 (z, v, d).use bit vectors rather vectors natural numbers, upper line enforcesleast two three variables x, y, z must take value. Sincevalue v fixed, lower line makes conjunction unsatisfiable: tries assignthree different values 7, 8, 9 two different positions domino array. seemsunlikely kind inconsistency detected polynomial time. problemcircumvented using vectors natural numbers definition D3 (but enforcingbit vectors reduction): case, conjunction clearlysatisfiable.Proposition 3.5. {1, 2, 3}, concrete domain Di admissible satisfiability Di -conjunctions PTime.D1 , trivial. D2 , proof found Appendix A. D3 , prooffound (Lutz, Areces, Horrocks, & Sattler, 2002).3.3 NExpTime-hardness ALCK(D) Boolean Key Boxessection, prove two NExpTime-lower bounds ALCK(D)-concept satisfiabilityw.r.t. Boolean key boxes reducing NExpTime-complete domino problem introducedprevious section. first reduction uses simple concrete domain D1 ,depends composite key assertions. second reduction uses slightly complexconcrete domain D2 , needs unary key assertions. see, two reductionsyield different, incomparable results.first reduce NExpTime-complete domino problem ALCK(D1 )-concept satisfiability w.r.t. Boolean composite key boxes. domino system = (T, H, V ) initialcondition = a0 , . . . , an1 translated ALCK(D1 )-concept CD,a displayedFigure 3. Names TreeX TreeY used abbreviations only. use Ri .Cabbreviation n-fold nesting R. R.C. names xposi yposi usedfigure denote concrete features. definition Init concept, n , biti (n)N680fiKeys, Nominals Concrete DomainsTreeX := R.X0 u R.X0 uu R .(DistXu R.Xi u R.Xi )i1i=1..nTreeY := DistXn u R.Y0 u R.Y0 uu R .(DistY u DistX u R.Y u R.Y )DistX := u ((X R.X ) u (X R.X ))DistY := u ((Y R.Y ) u (Y R.Y ))TransXPos := u (X xpos . = ) u (X xpos . = )TransYPos := u (Y ypos . = ) u (Y ypos . = )i1i=1..nkki=0..ki=0..ni=0..ki=0..nn1100Succs := Rx .(TransXPos u TransYPos) u Ry .(TransXPos u TransYPos)XSuccOk :=(Yi Rx .Yi ) u (Yi Rx .Yi )i=0..nXj (Xk Rx .Xk ) u (Xk Rx .Xk )uu uu X (X R .X ) u (X R .X )YSuccOk := u (X R .X ) u (X R .X )u u (Y R .Y ) u (Y R .Y )u (Y R .Y ) u (Y R .Y )Label := u u (D u )CheckMatch := (D u R .D ) u (D u R .D )u X u u X u uInit := uk=0..nj=0..kk=0..nj=0..ki=0..nj=0..kk=0..nj=0..k(i,j)Hi=0..n1jkjj=0..n,bitj (i)=0xkkxkji,jT,i6=jxkk=0..njkkkkkkkj(i,j)Vjjj=0..n,bitj (i)=1jj=0..njaiCD,a := TreeX u Rn+1 .TreeYu R2(n+1) .(TransXPos u TransYPos u Succs u XSuccOk u YSuccOk)u R2(n+1) .(Label u CheckMatch u Init)Figure 3: ALCK(D1 ) reduction concept CD,a .supposed denote ith bit binary representation n. claim CD,asatisfiable w.r.t. key box{(xpos0 , . . . , xposn , ypos0 , . . . , yposn keyfor >)}iff exists solution a. substantiate claim, let us goreduction explain various parts concept CD,a . first step towards under681fiLutz, Areces, Horrocks, & Sattlerstanding structure models CD,a (which key understanding reductionitself) note purpose first line CD,a enforce tree structuredepth 2(n + 1), whose leaves correspond positions 2n+1 2n+1 -torus.precisely, TreeX concept guarantees that, every model CD,a , exists binarytree depth n + 1. Moreover, DistXk concepts (there exists one k {0, . . . , n})ensure leaves tree binarily numbered (from 0 2n+1 1) conceptnames X0 , . . . , Xn . precisely, domain object , set1 XiInxpsn(d) = i=0 (d) 2 (d) =0 otherwise.TreeX DistX concepts ensure exist nodes d0 , . . . , d2n+1 1 level n + 1tree xpsn(di ) = i. Intuitively, numbering represents horizontalpositions 2n+1 2n+1 -torus. vertical positions coded similar wayY0 , . . . , Yn concept names. specifically, concepts TreeY, DistX, DistY ensureevery di (i 2n+1 1) root another tree, (i) every nodeX0 , . . . , Xn -configuration root node, (ii) leaves numbered binarilyusing concept names Y0 , . . . , Yn (note TreeY concept appears CD,a insideRn+1 value restriction). Define1 YiInypsn(d) = i=0 (d) 2 (d) =0 otherwise.set leaf nodes trees enforced TreeY concept, exists,i, j < 2n+1 , object4 ei,j xpsn(ei,j ) = ypsn(ei,j ) = j, i.e., ei,jrepresents position (i, j) 2n+1 2n+1 -torus.next step translate individual bits numbering ei,j -objects,represented concept names, concrete domain values.done TransXPos TransYPos concepts ensure that, ` n,xposI` (ei,j ) = 0 ei,j X` , xposI` (ei,j ) = 1 ei,j X` , similarly ypos` Y` .Since model key box{(xpos0 , . . . , xposn , ypos0 , . . . , yposn keyfor >)},grid positions uniquely represented domain elements (TransXPos u TransYPos)I ,i.e., d, e (TransXPos u TransYPos)I xpsn(d) = xpsn(e) ypsn(d) = yxpsn(e),= e. fact used concepts Succs, XSuccOk, YSuccOk enforce that,two roles Rx Ry i, j n, following holds:RxI ({ei,j } ) = {(ei,j , e(i2n+1 1),j }RyI ({ei,j } ) = {(ei,j , ei,(j2n+1 1) }.()Succs concept ensures that, ei,j , exists Rx -successor Ry successor, (TransXPos u TransYPos)I . Let Rx -successor ei,j .XSuccOk concept ensures xpsn(d) = 2n+1 1 ypsn(d) = j.4. matter one object.682fiKeys, Nominals Concrete Domainsexplain this, let us note that, since ei,j (TransXPos u TransYPos)Igrid positions uniquely represented elements (TransXPos u TransYPos)I ,implies = e(i2n+1 1),j shows upper line () indeed hold.Let us consider XSuccOk concept detail. essentiallyDL-formulation well-known propositional formulan k1n k1^^^_(xj = 1) (xk = 1 x0k = 0)(xj = 0) (xk = x0k )k=0 j=0k=0 j=0encodes incrementation modulo 2n+1 , i.e., number (binarily) encodedpropositional variables x0 , . . . , xn t0 number encoded propositionalvariables x00 , . . . , x0n , t0 = + 1 modulo 2n+1 (see Borger et al., 1997). Takingaccount Rx quantifiers XSuccOk, readily checked conceptdesired effect: ensure that, every Rx -successor ei,j , xpsn(d) =xpsn(e(i2n+1 1),j ) = 2n+1 1. explanation YSuccOk enforces lowerline () analogous XSuccOk case.remains ensure every grid position labeled precisely one tileinitial condition well horizontal vertical matching conditions satisfied.tiles represented concept names Di (where set tiles )described tasks accomplished standard way concepts Label, Init,CheckMatch.worth noting reduction concept path-free key box simple,i.e., path-free Boolean. Path-freeness concepts often used tame complexitydescription logics concrete domains, although largely sacrifices expressivepower (Lutz, 2003; Baader, Lutz, Sturm, & Wolter, 2002b; Haarslev, Moller, & Wessel, 2001;Horrocks & Sattler, 2001). example, ALC(D) augmented general TBoxes,reasoning arbitrary concepts undecidable reasoning path-free conceptsExpTime-complete admissible D-satisfiability ExpTime (Lutz, 2002a).taming approach work presence key boxes since,seen, satisfiability ALC(D)-concepts w.r.t. key boxes (under natural assumptions)NExpTime-hard, even concept key box path-free.Since size CD,a used key box clearly polynomial n, obtainfollowing proposition.Proposition 3.6. satisfiability path-free ALCK(D1 )-concepts w.r.t. simple key boxesNExpTime-hard.shown (non path-free) ALC(D)-concept satisfiability PSpace-completeD-satisfiability PSpace (Lutz, 2002b). Hence, follows Proposition 3.5ALC(D1 )-concept satisfiability PSpace-complete. Thus, rather dramatic increase complexity key boxes added ALC(D1 ). stress increase duekey boxes complexity D1 -satisfiability, reformulateProposition 3.6:Theorem 3.7. exists concrete domain D-satisfiability PTimesatisfiability path-free ALCK(D)-concepts w.r.t. simple key boxes NExpTime-hard.683fiLutz, Areces, Horrocks, & SattlerSuccs2 := Rx .TransPos u Ry .TransPosTransPos :=uui=0..ni=0..n(Xi bv.bit1i2(n+1) ) u Xi bv.bit0i2(n+1) ) un+i+1n+i+1(Yi bv.bit12(n+1)) u Yi bv.bit02(n+1))CD,a := TreeX u Rn+1 .TreeYu R2(n+1) .(TransPos u Succs2 u XSuccOk u YSuccOk)u R2(n+1) .(Label u CheckMatch u Init)Figure 4: ALCK(D2 ) reduction concept CD,a .Although, due low expressivity, concrete domain D1 naturalknowledge representation, fragment many concrete domainsproposed literature (Baader & Hanschke, 1992; Haarslev & Moller, 2001; Lutz, 2003,2002b). Indeed, presented reduction strategy adapted several standardconcrete domains. Let us formulate (very weak) condition concrete domain mustsatisfy order presented reduction strategy applicable.Theorem 3.8. Let concrete domain. exist a, b 6= b P1 , P2P1D = {a} P2D = {b}, satisfiability path-free ALCK(D)-conceptsw.r.t. simple key boxes NExpTime-hard.present second NExpTime-hardness result ALCK(D)-concept satisfiability.time, reduce NExpTime-complete domino problem satisfiability pathfree ALCK(D2 )-concepts w.r.t. simple unary key boxes. reduction similarprevious one discuss differences.first reduction, represented individual bits grid positions individualconcrete features xposi yposi used composite key box ensure pointtorus represented one element. second reduction, use singleconcrete feature bv represent entire position (i, j) torus using bit vectorconcrete domain D2 . allows us enforce mentioned uniquenessrepresentations using unary key box.modified reduction concept CD,a found Figure 4, conceptsTreeX, TreeY, DistXk , DistYk , XSuccOk, YSuccOk, Label, CheckMatch, Init definedFigure 3. translation position torus encoded X0 , . . . , Xn , Y0 , . . . , Ynbit vector done TransPos concept straightforward manner. Givensaid first reduction, hard see CD,a satisfiable w.r.t. keybox {(bv keyfor >)} iff exists solution a. thus obtain followingproposition.Proposition 3.9. satisfiability path-free ALCK(D2 )-concepts w.r.t. simple unarykey boxes NExpTime-hard.Again, relate NExpTime lower bound complexity D2 -satisfiability,determined Proposition 3.5.684fiKeys, Nominals Concrete DomainsTheorem 3.10. exists concrete domain D-satisfiability PTimesatisfiability path-free ALCK(D)-concepts w.r.t. simple unary key boxes NExpTime-hard.Since elements D2 bit vectors, concrete domain D2 cannot considerednatural choice many application areas. But, reduction, D2 replacedseveral natural concrete domains.central observation use bit vectors injectively translate sequencesbits values concrete domain, i.e., translate sequences 2(n + 1) bits(represented concept names X0 , . . . , Xn Y0 , . . . , Yn ) elements D2that, distinct sequences, results translation also distinct. Duerestricted use bit vectors, several ways replace natural numbers.example, replace TransPos following concept TransPos0 ensuresthat, TransPos0I , sI2n+1 (d) = xpsn(d) + 2n+1 ypsn(d):uTransPos0 := zero.=0 uti .=2i u (X0 s0 .=0 ) u (X0 s0 .=1 ) ui=1...2n+1Xi (si1 , zero, si ).+ u Xi (si1 , ti , si ).+ ui=1..nYi(n+1) (si1 , zero, si ).+ u (Yi(n+1) (si1 , ti , si ).+uui=n+1..2n+1Nzero, si , ti concrete features, =k (with k ) denotes unary predicateobvious extension, + denotes ternary addition predicate that, intuitively,first two arguments addends third one sum.easy check that, whenever two objects d, e TransPos0 agreeinterpretation X0 , . . . , Xn , Y0 , . . . , Yn , sI2n+1 (d) 6= sI2n+1 (e), thus keybox {(s2n+1 keyfor >)} used reduction. size TransPos0 obviouslypolynomial n numbers k appearing =k predicates coded binary. thusobtain following theorem:Theorem 3.11. Let concrete domain1.N ,N2. contains, k , predicate =k (=k )D = {k} size (therepresentation ) =k logarithmic k,3. contains predicate + (+)D {(k1 , k2 , x) | k1 , k2{(k1 , k2 , k1 + k2 ) | k1 , k2 }.NN x} =satisfiability path-free ALCK(D)-concepts w.r.t. simple unary key boxesNExpTime-hard.example, theorem yields NExpTime-lower bounds ALCK(D) instantiatedconcrete domains proposed (Baader & Hanschke, 1992; Haarslev & Moller, 2001; Lutz,2003, 2002b). alternative addition predicate use multiplication injectively685fiLutz, Areces, Horrocks, & Sattlertranslate sequences bits natural numbers. precisely, let p1 , . . . , p2n+1first 2n + 1 prime numbers define another version TransPos follows:TransPos00 := one.=1 uuui=1..nuti .=pi u (X0 s0 .=0 ) u (X0 s0 .=1 ) ui=1...2n+1Xi (si1 , one, si ). u Xi (si1 , ti , si ). uYi(n+1) (si1 , one, si ). u Yi(n+1) (si1 , ti , si ).i=n+1..2n+1ternary multiplication predicate.Since factorization natural numbers prime numbers unique,use key box {(s2n+1 keyfor >)} reduction. Moreover, well-knownkth prime polynomial k (Graham, Knuth, & Patashnik, 1990), thus sizeconcept TransPos00 polynomial n even numbers k =k predicates codedunarily. thus obtain another theorem concerning quite natural concrete domains:Theorem 3.12. Let concrete domain1.N ,N, predicate =k (=k )D = {k},3. contains predicate ()D {(k1 , k2 , x) | k1 , k2 N x{(k1 , k2 , k1 k2 ) | k1 , k2 N}.2. contains, k} =satisfiability path-free ALCK(D)-concepts w.r.t. simple unary key boxesNExpTime-hard.3.4 NExpTime-hardness ALCO(D)already pointed Section 1, relationship key boxes nominalsrather close: latter simulated former concrete domain providespredicates used uniquely describe elements . example, ALCK(D1 )concept g.=0 behaves nominal use key assertion (g keyfor >).even define n nominals using n single concrete features unary-key assertions.logics ALCK(D2 ) ALCK(D3 ), single concrete feature unary key assertionssufficient simulate arbitrary number nominals: example, ALCK(D2 )concept C = g.bit002 u g.bit112 uniquely describes bit vector (0, 1) BV2 D2 , i.e.,C implies g (a) = (0, 1). Obviously, bit vector (of length!)described similar way.illustrates that, non-trivial concrete domains D, logic ALCK(D)(at least) expressive ALCO(D). Although converse hold, expressivepower ALCO(D) still sufficient prove NExpTime-hardness concept satisfiability,provided suitable concrete domain used. Since ALCO concept satisfiabilityPSpace-complete (Areces, Blackburn, & Marx, 1999), yet another example DLeven seemingly harmless extension concrete domains dramatic effectcomputational complexity (Lutz, 2003).686fiKeys, Nominals Concrete DomainsNominal := f.NXSucc :=YSucc :=u u X (X X ) u u X (X X )u u (Y ) u u (Y )k=0..nj=0..kk=0..nj=0..kj0kkj0kkk=0..nk=0..njj=0..kj=0..kji=0..nn+10n+10n+10n+1i,jVui=0..n1n+10i,jHInit2 :=n+1n+1i=0..ni=0..nn+1i=0..nu0kku (X bvx.pos1 ) u (X bvx.pos0 )TransYPos := u (Y bvy.pos1) u (Y bvy.pos0)TransXSucc := u (X bvxs.pos1) u (X bvxs.pos0)TransYSucc := u (Y bvys.pos1) u (Y bvys.pos0)CheckHMatch := ((bvx, bvy, f darr).tileu (bvxs, bvy, f darr).tileCheckVMatch := ((bvx, bvy, f darr).tileu (bvx, bvys, f darr).tileTransXPos :=0kkn+1jn+1 )n+1jn+1 )Xj uuuXj uYjj=0..nj=0..n,bitj (i)=0j=0..n,bitj (i)=1(bvx, bvy, f darr).tilean+1CD,a := TreeX u Rn+1 .TreeY u R2(n+1) .Nominal uR2(n+1) .(TransXPos u TransYPos uXSucc u YSucc u TransXSucc u TransYSucc uInit2 u CheckHMatch u CheckVMatch)Figure 5: ALCO(D3 ) reduction concept CD,a .section, reduce NExpTime-complete domino-problem ALCO(D3 )concept satisfiability. Again, let = (T, H, V ) domino system = a0 , . . . , an1initial condition. modified reduction concept CD,a defined Figure 5, bvx,bvy, bvxs, bvys, darr denote concrete features, N denotes nominal, conceptsTreeX, TreeY, DistXk , DistYk defined Figure 3. previous reductions,give detailed explanation reduction strategy show CD,a satisfiableiff exists solution a. Formal details easily workedinterested reader.Let model CD,a . explain structure I, convenient startfirst line CD,a . previous reductions, TreeX TreeY conceptsused ensure contains tree-shaped substructure depth n + 1 whose leafnodes roots additional trees depth n + 1 set leafs687fiLutz, Areces, Horrocks, & SattlerTreeXTreeY...TreeY......ffTreeY...fNdarrFigure 6: structure models CD,a .latter trees correspond positions 2n+1 2n+1 -torus, i.e., position,leaf node representing it. torus positions binarily encoded conceptnames X0 , . . . , Xn Y0 , . . . , Yn use ei,j refer leaf xpsn(ei,j ) =ypsn(ei,j ) = j (see Section 3.3).previous reductions, numbers coded X0 , . . . , Xn Y0 , . . . , Yntranslated concrete domain values, done TransXPos TransYPosconcepts. Note that, contrast ALCK(D2 )-reduction, x-position yposition stored bit vector, rather two distinct ones bvxbvy. Also contrast previous reduction, actual tiling torusrepresented leaf nodes ei,j , rather domino array: last conjunctfirst line CD,a ensures every leaf ei,j connected via abstract feature f(unique) element w N .domain element w associated domino array via concrete feature darr (asshall see later, guaranteed CheckHMatch CheckVMatch concepts).domino array represents tiling 2n+1 2n+1 -torus. Summing up, structureroughly shown Figure 6.Since tiling stored domino array, need explain purpose leafnodes ei,j : nodes used enforce initial condition horizontalvertical matching condition. Let us discuss horizontal matching condition (the verticalmatching condition enforced analogously): XSucc concept DL reformulationpropositional logic formula incrementation modulo 2n+1 ensures that,ei,j , concept names X00 , . . . , Xn0 encode number 2n+1 1, i.e., horizontalposition ei,j horizontal neighbor. addition storage horizontal verticalposition ei,j bvx(ei,j ) bvy(ei,j ), also store horizontal position i2n+1 1 ei,jhorizontal successor bvxs(ei,j ). Finally, CheckHMatch verifies tiles positions688fiKeys, Nominals Concrete Domains(i, j) (i 2n+1 1, j), stored domino array, compatiblehorizontal matching condition.Note CheckHMatch also ensures domain element w (with {w} = N )domino array attached via concrete feature darr that, position (i, j),(unique!) tile stored domino array set . initial condition ensuredvia Init2 concept similar way. (again) use bitj (i) denote jth bitbinary encoding natural number i.Using considerations, correctness reduction readily checked.Moreover, size CD,a polynomial n. Note CD,a path-free:paths length two appear concepts CheckHMatch, CheckVMatch, Init2. Summingup, reduction described yields following result:Proposition 3.13. satisfiability ALCO(D3 )-concepts NExpTime-hard.Again, relate NExpTime lower bound complexity D3 -satisfiability,determined Proposition 3.5.Theorem 3.14. exists concrete domain D-satisfiability PTimesatisfiability ALCO(D)-concepts NExpTime-hard.Note reduction uses single nominal N . dramatic increase complexity since shown satisfiability ALC(D)-concepts (i.e., without nominalskey boxes) PSpace-complete provided admissible D-satisfiabilityPSpace (Lutz, 2002b).previous sections, note D3 replaced natural concretedomains NExpTime-hardness proof presented. idea represent wholedomino array single natural number use arithmetic operations accessindividual positions: natural number k viewed domino array partitioningbinary representation 2n+1 2n+1 = 22(n+1) sections length dlog(#T )e,#T denotes cardinality set tile types . section describes tilesingle position torus. sections accessed using integer divisionreminder operations: k natural number representing torus, tileposisition computed(k div 2idlog(#T )e ) mod 2dlog(#T )e + 1.Thus, introduce ternary predicates div integer division mod computingremainder division, binary predicate 2x expressing exponentiation basis 2.modify reduction follows: replace TransXPos TransYPosTransPos0 concept Section 3.3 translate two numbers encoded X1 , . . . , XnY1 , . . . , Yn single natural number stored concrete feature s2n+1 .devise new concept Tile[i] (for ) enforcing position identifiedfeature s2n+1 labeled tile i:Tile[i] := r.=dlog(#T )e u s2n+1 , r, r0 . u r0 , r00 .2x u one.=1 u r, one, t.+ u t, t0 .2xu f torus, r00 , u.div u u, t00 , tile.mod u tile.=i .689fiLutz, Areces, Horrocks, & SattlerHere, r, r0 , r00 , t, t0 , u, one, torus, tile concrete features. torus feature counterpart darr feature original reduction, i.e., stores natural numberrepresents tiling array. use Tile[i] concept obvious way insideCheckHMatch, CheckVMatch, Init2 concepts. size resulting reduction conceptpolynomial n numbers k appearing =k predicates coded binary.thus obtain following theorem:Theorem 3.15. Let concrete domain1.N ,2. contains predicates predicate =k (for kfollowing extensions(2x )D{(k, x) | k(+)D {(k1 , k2 , x) | k1 , k2()D {(k1 , k2 , x) | k1 , k2(div)D {(k1 , k2 , x) | k1 , k2(mod)D {(k1 , k2 , x) | k1 , k2NNNNN(=k )Dx }x }x }x }x }======N), 2x, +, , div, mod{k}{(k, 2k ) | k }{(k1 , k2 , k1 + k2 ) | k1 , k2 }{(k1 , k2 , k1 k2 ) | k1 , k2 }{(k1 , k2 , k1 div k2 ) | k1 , k2 }{(k1 , k2 , k1 mod k2 ) | k1 , k2 }NNNNNsatisfiability ALCO(D)-concepts NExpTime-hard.4. Reasoning Proceduressection devoted developing reasoning procedures DLs concrete domains,nominals, keys. start devising tableau algorithm decides satisfiabilityALCOK(D)-concepts w.r.t. Boolean key boxes. algorithm yields NExpTime uppercomplexity bound matching lower bounds established Section 3.3.consider rather powerful description logic SHOQK(D). DL,extension SHOQ(D) (Horrocks & Sattler, 2001; Pan & Horrocks, 2002), provideswealth expressive means transitive roles, role hierarchies, nominals, qualifyingnumber restrictions. Moreover, SHOQK(D) equipped restricted variantconcrete domain constructor key boxes. develop tableau algorithmdeciding satisfiability SHOQK(D)-concepts w.r.t. path-free key boxes. Duerestrictedness SHOQK(D)s concrete domain constructor, even admit generalrather Boolean key boxes. Again, algorithm yields tight NExpTime uppercomplexity bound.4.1 Tableau Algorithm ALCOK(D) Boolean Key BoxesTableau algorithms decide satisfiability input concept (in case w.r.t. inputkey box) attempting construct model it. precisely, tableau algorithmstarts initial data structure induced input concept repeatedly applies so-called completion rules it. rule application thought attemptingconstruct model input concept. Finally, either algorithm find obvious contradiction encounter situation contradiction-free690fiKeys, Nominals Concrete Domainscompletion rules applicable. former case, input concept unsatisfiable,satisfiable latter.devising tableau algorithm description logic concrete domainswithout committing particular concrete domain, commonly assumed concrete domain admissible, implies decidability satisfiability D-conjunctions.presence keys, however, enough: D-conjunction satisfiable, alsowant know variables take values arbitrary fixed solution.example, consider concrete domain N = ( , {<n | n }) N-conjunctionNNc = <2 (v1 ) <2 (v2 ) <2 (v3 ).Obviously, one solution c satisfies (v1 ) = (v2 ), another satisfies (v1 ) = (v3 ),on. tableau algorithm uses identity information passed concrete domainreasoner since, presence key boxes, impact structureconstructed model. example, information reveals unsatisfiabilityR.A u R.(A u B) u R.(A u B) u R.g.<2 w.r.t. (g keyfor >).formalize requirement, strengthen notion admissibility key-admissibility.Since tableau algorithm developed section non-deterministic, formulate keyadmissibility non-deterministic way.Definition 4.1 (Key-admissible). concrete domain key-admissible iff satisfiesfollowing properties:1. contains name >D ;2. closed negation;3. exists algorithm takes input D-conjunction c, returns clash cunsatisfiable, otherwise non-deterministically outputs equivalence relationset variables V used c exists solution cfollowing property: v, v 0 V(v) = (v 0 ) iff v v 0 .algorithm showing behaviour described item 3 called D-tester,equivalence relations called concrete equivalences. say extended Dsatisfiability NP exists D-tester running polynomial time.Please note key-admissibility less esoteric might seem: concrete domainadmissible provides equality predicate also key-admissible. Dueadmissibility, presence equality predicate implies inequality predicatealso available. thus construct D-tester algorithm D-satisfiability:presented predicate conjunction c, simply guess equivalence relationset variablesused c. VThen decide (non-extended) satisfiabilityVconjunction c vv0 =(v, v 0 ) v6v0 6=(v, v 0 ), return clash unsatisfiableotherwise. rather weak condition equality predicate present691fiLutz, Areces, Horrocks, & Sattler(C u D)(R.C)C (C D)R.C(R.C)(u1 , . . . , un .P )(g)C uR.CCCu1 , . . . , un .P u1 ung.>DFigure 7: NNF rewrite rules.satisfied almost concrete domains proposed literature (see, e.g. (Lutz, 2003;Baader & Hanschke, 1991b; Kamp & Wache, 1996; Haarslev, Lutz, & Moller, 1998; Baader& Sattler, 1998)).Throughout chapter, assume concrete domain equippedequality predicate. assumption w.l.o.g. since D-conjunction using equalitytranslated equivalent one without equality identifying variables accordingstated equalities. assumption must confused discussedprevious paragraph: even concrete domain admissible set predicatesthus closed negation, assumption imply presence inequalitypredicate.need prerequisites start presentation tableaualgorithm: concept negation normal form (NNF) negation occurs frontconcept names nominals. easily seen that, concrete domain admissible,every ALCOK(D)-concept converted equivalent one NNF exhaustively applying rewrite rules displayed Figure 7. use C denote resultconverting C NNF. key box NNF concepts occurring key assertionsNNF. follows, generally assume input concepts key boxes NNF.Let C ALCOK(D)-concept K key box. use sub(C) denote setsubconcepts C (including C itself) con(K) denote set concepts appearingright-hand side key assertions K. set concepts , sub() denotesset C sub(C). Moreover, write cl(C, K) abbreviation setsub(C) sub(con(K)) {D| sub(con(K))}.start presentation tableau algorithm introducing underlying datastructure.Definition 4.2 (Completion System). Let Oa Oc disjoint countably infinitesets abstract concrete nodes. completion tree ALCOK(D)-concept Ckey box K finite, labeled tree = (Va , Vc , E, L) nodes Va Vc Va Oa ,Vc Oc , nodes Vc leaves. tree labeled follows:node Va labeled subset L(a) cl(C, K);edge (a, b) E a, b Va labeled role name L(a, b) occurring CK;edge (a, x) E Va x Vc labeled concrete feature L(a, x)occurring C K.692fiKeys, Nominals Concrete DomainsVa , use levT (a) denote depth occurs (startingroot node depth 0). completion system ALCOK(D)-concept C key boxK tuple (T, P, , ),= (Va , Vc , E, L) completion tree C K,P function mapping P arity n C subset Vcn ,linear ordering Va levT (a) levT (b) implies b,equivalence relation Vc .Let (Va , Vc , E, L) completion tree. node b Va R-successor node Va(a, b) E L(a, b) = R, node x Vc g-successor (a, x) EL(a, x) = g. path u, notion u-successor defined obvious way.Intuitively, relation records equalities concrete nodes found(non-deterministic) model construction process. recording necessary since equalities concrete nodes induce equalities abstract nodes which, turn,imply equalities concrete nodes. seen following example: assume completion tree contains, {1, 2}, abstract node aiconcrete g-successor xi concrete g 0 -successor yi . assume key box contains (g keyfor >), D-tester returns x1 x2 . consequence, a1 a2represent element thus functionality g 0 implies also y1 y2 represent(concrete) element. deal effects, define equivalence relationabstract nodes second equivalence relation c concrete nodes.Definition 4.3 (a c Relations). Let = (T, P, , ) completion systemconcept C key box K = (Va , Vc , E, L), let equivalence relationVa . R NR , node b Va R/-neighbor node Va existsnode c Va c b R-successor c. Similarly, g NcF ,node x Vc g/-neighbor exists node c Va c xg-successor c. paths u, notion u/-neighbor defined obvious way.define sequence equivalence relations 0a 1a Va follows:0a = {(a, a) Va2 }{(a, b) Va2 | N N L(a) L(b)}i+1= ia{(a, b) Va2 | c Va f NaFb f /ia -neighbors c}{(a, b) Va2 | (u1 , . . . , un keyfor C) K,ui /ia -neighbors xi 1 n,ui /ia -neighbors yi b 1 nC L(a) L(b) xi yi 1 n}.Finally, set =i0 .definec = {(x, y) Vc2 | Va g NcFx g/a -neighbors a}.693fiLutz, Areces, Horrocks, & Sattlerdefinition reflects mentioned tight coupling concrete abstract equalities: D-tester finds (or guesses) two concrete nodes equal,tableau algorithm may use deduce (via computation c ) evenequalities concrete nodes.Let key-admissible concrete domain. decide satisfiability ALCOK(D)concept C0 w.r.t. Boolean key box K (both NNF), tableau algorithm startedinitial completion treeTC0 = ({a0 }, , , {a0 7 {C0 }})initial completion systemSC0 = (TC0 , P , , ),P maps P occurring C0 . introduce operationused completion rules add new nodes completion trees.Definition 4.4 (+ Operation). abstract concrete node called fresh completion tree appear T. Let = (T, P, , ) completion system= (Va , Vc , E, L). use following notions:Let Va , b Oa fresh T, R NR . write +aRb denote completionsystem 0 obtained adding b Va (a, b) E settingL(a, b) = R L(b) = . Moreover, b inserted b c implieslevT (b) levT (c).Let Va , x Oc fresh g NcF . write +agx denote completionsystem 0 obtained adding x Vc (a, x) E settingL(a, x) = g.nesting + operation, omit brackets, writing, example, + aR1 b + bR2 c(S + aR1 b) + bR2 c. Let u = f1 fn g path. Va x Oc fresh T,use + aux denote completion system obtained taking distinctnodes b1 , . . . , bn Oa fresh setting+ aux := + af1 b1 + + bn1 fn bn + bn gx.Strictly speaking, + aRb operation non-deterministic since specifyprecisely node b inserted . However, since dont care non-determinism,view + operation deterministic.completion rules found Figure 8. Note Rt Rch rulesnon-deterministic, i.e., one possible outcome (this true dont knownon-determinism). remarks completion rules order: upperfive rules well-known existing tableau algorithms ALC(D)-concept satisfiability(see, e.g., Lutz, 2002a). use R/ -neighbors u/ -neighbors rulesR, R, Rc deserves comment. Take example R: intuitively, btwo abstract nodes b completion tree, b describedomain element constructed model (and similarly c relation concrete694fiKeys, Nominals Concrete DomainsRuC1 u C2 L(a) {C1 , C2 } 6 L(a)L(a) := L(a) {C1 , C2 }RtC1 C2 L(a) {C1 , C2 } L(a) =L(a) := L(a) {C} C {C1 , C2 }RR.C L(a) R/a -neighbor b C L(b),set := + aRb fresh b Oa L(b) := {C}RR.C L(a), b R/a -neighbor a, C/ L(b)set L(b) := L(b) {C}Rcu1 , . . . , un .P L(a) exist x1 , . . . , xn Vcxi ui /a -neighbor 1 n (x1 , . . . , xn ) P(P )set := (S + au1 x1 + + aun xn ) x1 , . . . , xn Oc freshP(P ) := P(P ) {(x1 , . . . , xn )}Rch(u1 , . . . , un keyfor C) K exist x1 , . . . , xn Vcxi ui /a -neighbor 1 n {C, C}L(a) =set L(a) := L(a) {D} {C, C}RpL(b) 6 L(a) Va minimal w.r.t. bset L(a) := L(a) L(b)Figure 8: Completion rules ALCOK(D).nodes). Thus b c R-successor a, c also R-successorb. However, since want completion tree tree, make lattersuccessorship explicit. compensate this, R rule talks R/a -neighborsrather R-successors.lower two rules necessary dealing key boxes. Rch ruleso-called choose rule (Hollunder & Baader, 1991; Horrocks et al., 2000): intuitively,guesses whether abstract node satisfies C exists key assertion(u1 , . . . , un keyfor C) K neighbors paths ui .necessary since possibilities may ramifications: satisfies C, musttaken account construction relation ; satisfy C,must deal consequences satisfying C(e.g. case C >).Rp rule deals equalities abstract nodes recorded relation:since b means b describe node constructed model,node labels identical. suffices, however, choose one representativeequivalence class make sure representatives node label containslabels -equivalent nodes. representative, use node minimalw.r.t. ordering , introduced solely reason. Rp ruleappropriate copying node labels.Let us formalize means completion system contain contradiction.Definition 4.5 (Clash). Let = (T, P, , ) completion system concept Ckey box K = (Va , Vc , , ). say completion system concrete695fiLutz, Areces, Horrocks, & Sattlerdefine procedure sat(S)contains clashreturn unsatisfiable:= test(S )computecompute c=6 ccontains clashreturn unsatisfiablecompletereturn satisfiable0:= application completion rulereturn sat(S 0 )Figure 9: ALCOK(D) tableau algorithm.domain satisfiable iff conjunction^=^P (x1 , . . . , xn )P used C (x1 ,...,xn )P(P )^=(x, y)xcsatisfiable. said contain clash iff1. Va NC {A, A} L(a),2. Va x Vc g L(a) x g/a -neighbor a,3. concrete domain satisfiable.contain clash, called clash-free. called complete iff completionrule applicable S.tableau algorithm described Figure 9 pseudo-code notation. figure, testcalls D-tester specified Definition 4.1. Let us say words loop.obviously exist close relationships relations c predicateconjunction :c (note c depend thus recomputedstep loop);definition D-tester, result test(S ) yields relation containing c(and thus also ).Using facts, one may check that, step loop, new tuples addedrelation, none deleted (see proof Lemma B.2 appendix).loop needed (i) defined using , (ii), c defined using ,696fiKeys, Nominals Concrete Domains(iii) new concrete equalities c may imply even concrete and/or abstractequalities, on.similar concrete-abstract interplay takes place course several recursion steps:equalities concrete nodes provided D-tester may make new rules applicable(for example Rp Rc) changes P thus also . may subsequently leaddetection equalities concrete nodes D-tester, on.considerations show that, presence keys, exists close interplayconcrete domain reasoner tableau algorithm, needed keyspresent: without keys, suffices apply concrete domain satisfiability checkcompletion rules exhaustively applied (Baader & Hanschke, 1991a).detailed proof termination, soundness, completeness together complexity analysis tableau algorithm defined section given Appendix B.Theorem 4.1. Let key-admissible concrete domain. extended D-satisfiabilityNP, ALCOK(D)-concept satisfiability w.r.t. Boolean key boxes NExpTime.note that, way presented here, algorithm leaves considerableroom optimizations. One possible optimization concerns re-use f -successors(for abstract features f ): example, applying R rule concept f.C L(a),already f -successor b, could simply add C L(b) instead addingnew f -successor c recording b c.Another candidate optimizations test function. Recall function takespredicate conjunction c set variables V non-deterministically returns concreteequivalence, i.e., relation exists solution c vi vj iff(vi ) = (vj ) (see Definition 4.1). hard devise ALC(D)-concept forcescompletion systems exponentially many concrete nodes slightly adapting wellknown ALC-concepts require models exponential size (Halpern & Moses, 1992).Hence, size input conjunctions c test exponential size inputconcept. Even trivial D-conjunctionsc = >D (v1 ) >D (vk )exponential number distinct concrete equivalences . Thus, numberpossible outcomes call test function may double exponential sizeinput concept. Considering example, natural response problemrequire test return minimal concrete equivalences: intuitively, equivalenceminimal variables equivalent whose equality enforced conjunction.precisely, called minimal exists concrete equivalence 0{(x, y) | x 0 y} {(x, y) | x y}. conjecture restricting test waydestroy soundness completeness tableau algorithm. However, althoughdefinitely worthwhile optimization, help overcome existencedoubly exponentially many outcomes test worst caseat least concretedomains D: consider concrete domain N Page 691 conjunctions formci = <i (v1 ) <i (v2i ).readily checked that, 1, number minimal concrete equivalencesci exponential i. Moreover, hard devise concept Ci size logarithmic697fiLutz, Areces, Horrocks, & Sattlerleads completion systems = ci . Hence, still doublyexponentially many possible outcomes test function.example discussed, exponential branching test clearly duediscreteness natural numbers. Indeed, use dense structure defining concretedomains, seems restriction minimal concrete equivalences desiredeffect, namely number tests possible outcomes becomes polynomial sizeinput thus exponential size input concept. example, considerconcrete domain Q, defined follows:Q setQ rational numbers;Q contains unary predicates >Q negation Q , unary predicates =q 6=qq , binary comparison predicates {<, , =, 6=, , >}, ternary additionpredicate +, negation + (all obvious semantics).Qreadily checked Q key-admissible (note provides binary equality predicate) thus falls framework. conjecture exists one minimalconcrete equivalence every Q-predicate conjunction c: intuitively, seems possible(inductively) determine relation set variables V used c (i) ximplies (x) = (y) every solution c (ii) exists solution cv 6 v 0 implies (v) 6= (v 0 ). Clearly, minimal concrete equivalence. Moreover,due (i) one.4.2 Tableau Algorithm SHOQK(D)Although ALCOK(D) quite powerful DL, lacks several expressive meansfound state-of-the-art description logic systems FaCT RACER (Horrocks,1998; Horrocks et al., 2000; Haarslev & Moller, 2001). section, considerexpressive description logic SHOQK(D) provides concrete domains, keyboxes, nominals, also many means expressivity transitiveroles, role hierarchies, qualifying number restrictions, general TBoxes. Modulodetails, SHOQK(D) viewed extension DL SHOQ(D) key boxes.SHOQ(D) proposed Horrocks Sattler (2001) (see also Pan & Horrocks, 2002)tool ontology reasoning context semantic web (Berners-Lee, Hendler,& Lassila, 2001; Baader et al., 2002a).One important feature SHOQK(D) so-called TBoxes, i.e. concept equations5.form C = used background theory reasoning. Since wellknown combining general TBoxes concrete domain constructor easily leadsundecidability (Baader & Hanschke, 1992; Lutz, 2004), SHOQK(D) offers pathfree variant concrete domain constructori.e. concrete features admittedinside constructor rather paths arbitrary length. restriction indeed regainsdecidability (Haarslev et al., 2001; Horrocks & Sattler, 2001). Path-freeness concretedomain constructor obviously renders abstract features unnecessary, thus syntactictype available SHOQK(D).5. TBox formalisms also allow concept inclusions C v D, re-writtenequivalent equations, see Section 2.2.2.5 (Baader et al., 2003).698fiKeys, Nominals Concrete Domains4.2.1 Description Logic SHOQK(D)Let us define SHOQK(D) formal way, starting syntax.Definition 4.6 (SHOQK(D) Syntax). role axiom either role inclusion,form R v R, NR , transitivity axiom Trans(R) R NR . rolebox R finite set role axioms. Let v* reflexive-transitive closure roleinclusions R. role name R called simple v* R implies Trans(S)/ R rolenames S. Let concrete domain. set SHOQK(D)-concepts smallest setevery concept name every nominal concept,C concepts, R role name, simple role name, n k naturalnumbers, g1 , . . . , gn concrete features, P predicate arity n,following expressions also concepts:C, C u D, C D, R.C, R.C, (> k C), (6 k C), g1 , . . . , gn .P, g1 ..concept equation expression C = C concepts. TBox finite setconcept equations.SHOQK(D), consider key boxes differ two aspects ones considered ALCOK(D): following, assume key boxes path-free, admitcomplex concepts occur key assertions. Note abstract features pathsoccur syntax SHOQK(D)as become clear semanticsdefined, former simulated general number restrictions (6 n R C).usual description logics SHIQ/SHOQ family, require role namesnumber restrictions simple since admitting arbitrary roles yields undecidabilityreasoning (Horrocks et al., 2000; Horrocks & Sattler, 2001). role box R clearcontext, usually write Trans(R) instead Trans(R) R. introducesemantics SHOQK(D) relevant reasoning problems.Definition 4.7 (SHOQK(D) Semantics). Interpretations = (I , ) definedDefinition 2.3, function extended novel SHOQK(D)-conceptsfollows:(6 k R C)I := {d | ]{e | (d, e) RI } k}(> k R C)I := {d | ]{e | (d, e) RI } k}..Let interpretation. satisfies concept equation C = C = DI .model TBox satisfies concept equations . Similarly, satisfies roleinclusion R v RI transitivity axiom Trans(R) RI transitive relation.model role box R satisfies role inclusions transitivity axioms R.Let TBox, R role box, K key box. concept C satisfiable w.r.t. ,R, K iff C, , R, K common model. C subsumed concept w.r.t., R, K (written C vT ,R,K D) iff C DI common models , R, K.699fiLutz, Areces, Horrocks, & SattlerNote that, due requirement role names used inside number restrictionssimple, existential universal value restrictions syntactic sugar: contrastnumber restrictions, used roles.well-known that, many expressive description logics, reasoning TBoxesreduced reasoning without (Schild, 1991; Horrocks & Sattler, 2001):SHOQK(D), concept C satisfiable w.r.t. , R, K iff conceptR.C u R.uDE u.D=ETuR.Nnominal N usedC, , Ksatisfiable w.r.t. R0 , K, empty TBox, R fresh role appearingC, R, ,[{S v R}.R0 := R {Trans(R)}role name usedC, , R, KSince subsumption reduced satisfiability described Section 2, followingconsider satisfiability concepts w.r.t. role boxes key boxes, withoutTBoxes. also generally assume role boxes R acyclic, i.e. satisfy followingcondition: role name R, role names R1 , . . . , Rk R = R1 = RkRi v Ri+1 R 1 < k. hard see restriction sincecycles eliminated: R1 , . . . , Rk cycle R, R1I = = RkIinterpretations I. Thus simply remove cycle R replace everyoccurrence R2 , . . . , Rk C, R, K R1 , add Trans(R1 ) if, cycleelimination, Trans(Ri ) 1 n.turn attention construction tableau algorithm SHOQK(D),let us comment minor differences SHOQK(D) introducedoriginal version SHOQ(D) described (Horrocks & Sattler, 2001). maindifference logic, like extensions investigated (Haarslev et al., 2001; Pan &Horrocks, 2002), allows n-ary predicates Horrocks Sattler restrictunary predicates. Moreover, SHOQ(D) introduced (Horrocks & Sattler, 2001) usesconcrete roles rather concrete features, difference concrete rolesnecessarily functional. Due non-functionality, original SHOQ(D) admits twovariants T.P T.P concrete domain constructor (where concrete roleP unary predicate). SHOQK(D), simulate universal variant writingg.P g since concrete features g interpreted partial functions and, contrastHorrocks Sattler, undefinedness constructor g available. Exceptn-ary predicates provide important additional expressivity, view deviationsminor ones since easy see affect decidability complexityreasoning.4.2.2 Tableau Algorithm SHOQK(D)basic intuitions SHOQK(D) tableau algorithm similar ALCOK(D)algorithm, one exception: deal various expressive means SHOQK(D),700fiKeys, Nominals Concrete Domains(> n R C)(> 0 R C)(6 n R C)(6 (n 1) R C) n 1(> (n + 1) R C)Figure 10: SHOQK(D) NNF rewrite rules.convenient introduce certain abstraction models, so-called tableaux. maindifference tableaux models that, tableaux, roles declared transitivenecessarily described transitive relations. show exists tableaugiven concept key box common model. aimSHOQK(D) algorithm construct tableau input rather tryingconstruct model. this, algorithm employs completion forests underlyingdata structure.first introduce tableaux. Let us start discussing preliminaries.ALCOK(D), assume concepts key boxes NNF, i.e. negation occursfront concept names nominals. use C denote NNF C.additional NNF rewrite rules SHOQK(D) found Figure 10 completegiven ALCOK(D) Figure 7.concept D, role box R, key box K, definecl(D, K) := sub(D) sub(con(K)) {C| C sub(D) sub(con(K))}cl(D, R, K) := cl(D, K) {R.C | R v* S.C cl(D, K)}.Obviously, cardinality cl(D, R, K) linear size D, R, K.D,Kdenote set role names occurring D, R, K, NcFfollows, write ND,R,KRdenote sets concrete features occurring K. ready definetableaux.Definition 4.8 (Tableau). Let SHOQK(D)-concept NNF, R role box, Kpath-free key box NNF. tableau w.r.t. R K tuple (Sa , Sc , L, E, e, P)Sa , Sc sets abstract concrete individuals,L : Sa 2cl(D,R,K) maps abstract individual subset cl(D, R, K),D,R,KE : Sa Sa 2NRmaps pairs abstract individuals sets roles,e : Sa ND,KcF Sc maps pairs abstract individuals concrete features concreteindividuals,P maps n-ary concrete predicate cl(D, R, K) set n-tuples Sc ,abstract individual s0 Sa L(s0 ),s, Sa , C, C1 , C2 cl(D, R, K), R, ND,R,K,R(s, C) := {t Sa | E(s, t) C L(t)},case that:701fiLutz, Areces, Horrocks, & Sattler(T1) C L(s), C/ L(s),(T2) C1 u C2 L(s), C1 L(s) C2 L(s),(T3) C1 C2 L(s), C1 L(s) C2 L(s),(T4) R E(s, t) R v* S, E(s, t),(T5) R.C L(s) R E(s, t), C L(t),(T6) R.C L(s), Sa R E(s, t) C L(t),(T7) S.C L(s) R E(s, t) R v* Trans(R), R.C L(t),(T8) (> n C) L(s), ]S (s, C) > n,(T9) (6 n C) L(s), ]S (s, C) 6 n,(T10) either (6 n C) L(s) E(s, t) (g1 , . . . , gn keyfor C) K e(t, gi )defined 1 n, {C, C} L(t) 6= ,(T11) N L(s) L(t), = t,(T12) g1 , . . . , gn .P L(s), x1 , . . . , xn Sc e(s, gi ) = xi(x1 , . . . , xn ) P(P ),VVV(T13) P used D,K (x1 ,...,xn )P(P ) P (x1 , . . . , xn ) x6=y x 6= satisfiable,(T14) (g1 , . . . , gn keyfor C) K, C L(s) L(t), e(s, gi ) = e(t, gi ) 1 n,= t,(T15) g L(s), e(s, g) undefined.Note predicate conjunction (T13) uses binary inequality predicate. general,require concrete domain equipped predicate thuspredicate conjunction necessarily D-conjunction. However, nevertheless safeuse (T13) given form since tableaux used proofs needconcrete domain reasoner capable deciding satisfiability conjunction.following lemma, whose proof provided Appendix C, shows definitiontableaux provides adequate abstraction models.Lemma 4.2. Let SHOQK(D)-concept NNF, R role box, K key boxNNF. satisfiable w.r.t. R K iff tableau w.r.t. R K.Given Lemma 4.2, order decide satisfiability SHOQK(D)-concepts w.r.t. rolekey boxes, may use (tableau) algorithm tries construct tableau input.following, describe algorithm detail.previous section, algorithm works completion systems. However,case SHOQK(D) core component completion systems completion forestrather completion tree. reason completion rules removenodes edges completion system way disconnect one treetwo subtrees.702fiKeys, Nominals Concrete DomainsDefinition 4.9 (Completion System). Let SHOQK(D)-concept NNF, R rolebox, K path-free key box NNF. concept (> n R C) cl(D, R, K)1 n, reserve concept name AnRCappearing cl(D, R, K) defineextended closurenRccl+ (D, R, K) := cl(D, R, K) {AnRc| (> n R C) cl(D, R, K)}.1 , . . . ,Let Oa Oc disjoint countably infinite sets abstract concrete nodes.completion forest D, R, K finite forest F = (Va , Vc , E, L) nodes Va VcVa Oa , Vc Oc , nodes Vc leaves. forest labelledfollows:node Va labelled subset L(a) cl+ (D, R, K),edge (a, b) E a, b Va labeled non-empty set role namesL(a, b) occurring D, R, K,edge (a, x) E Va x Vc labeled concrete feature L(a, x)occurring D, R, K.completion system D, R, K tuple = (F, P, c , )F = (Va , Vc , E, L) completion forest D, R, K,P maps n-ary concrete predicate cl(D, R, K) set n-tuples Vc ,c equivalence relation Vc ,linear ordering Va .node Va called R-successor node Va if, R0 R0 v* R,R0 L(s, t). node x Vc called g-successor node Va L(s, x) = g. Finally,.write =6 R-successors node AnRCL(s)nRCAjL(t) 6= j.remarks order here. Firstly, contrast ALCOK(D) case, relationlonger required respect level node. due fact (a)enforce termination artificially mentioned property usedensure automatic termination, (b) level node might change since nodemight become root node completion rules remove nodes edges.Secondly, relation c returned D-tester, used computerelation used tableau algorithm. However, needcompute relation c ALCOK(D) case since concepts keyboxes assumed path-free.Thirdly, new concept names AnRCused ensure successors nodex generated (> n R C) L(x) merged later due concept (6n0 R C 0 ) L(x): generated successor labelled different concept AnRC;since merging two nodes means unifying node labels, suffices disallow703fiLutz, Areces, Horrocks, & Sattleroccurrence distinct concepts AnRCnode label suitable definitionclash.Since SHOQK(D) provides transitive roles, need cycle-detection mechanismorder guarantee termination algorithm: roughly speaking, encounternode similar already existing one, node needexplored. Speaking terms (Horrocks et al., 2000; Baader & Sattler, 2000),employ mechanism called subset blocking.Definition 4.10 (Blocked). Let reflexive closure . node Va blockednode Va L(t) L(s), s0 , s0 L(t) L(s0 ).Note that, unlike done, e.g., (Horrocks et al., 2000), blocking nodenecessarily ancestor blocked node, anywhere forest. may evenblocked nodes unblocked successors. modification used later obtainNExpTime upper bound.decide satisfiability ALCOK(D)-concept w.r.t. role box R pathfree key box K (where K NNF), tableau algorithm startedinitial completion systemSD = (FD , P , , ),FD = ({s0 }, , , {s0 7 {D}})Pmaps P occurring K .algorithm repeatedly applies completion rules. actual rules given,introduce new notions: firstly, define equivalence relation Vafollows: one following conditions satisfied:N L(s) L(t) nominal N(g1 . . . , gn keyfor C) K, C L(s)L(t), xi , yi gi E(s, xi )E(t, yi ) xi c yi 1 n.Intuitively, two abstract nodes related via relation describe individualtableau.Secondly, use following abbreviations formulation rules (writtenitalic):remove abstract node incoming outgoing edges, removeVa (s, t) (t, s) E Va Vc .Adding g-successor abstract node means nothing existsg-successor x Vc and, otherwise, adding E(s, x) = g x Ocyet occur completion forest.update relation c , D-tester asked decide satisfiability Dconjunction^^:=P (x1 , . . . , xn )x=yP used D,K(x1 ,...,xn )P(P )xcreturns, case conjunction satisfiable, updated concrete equivalence c defined Definition 4.1.704fiKeys, Nominals Concrete DomainsConcerning predicate conjunction used updates, recall w.l.o.g. assumeconcrete domain contain equality predicate discussed Definition 4.1.completion rules given Figure 11. generally assume new nodes xintroduced completion forest x already existing nodes y.describing tableau algorithm, comment completion rules.rules Rt, R6, Rc, Rch non-deterministic, i.e., application onepossible outcome. Rc rule, due update operation performed cusing D-tester: discussed end Section 4.1, computing concrete equivalencegiven D-conjunction may result high degree non-determinism. Please note that,contrast ALCOK(D), need call D-tester ruleandrule application.Next, Ra rule takes care abstract nodes related via . Since nodes-equivalence class denote individual, choose one representative whosenode label contains labels nodes class. representative simply-minimal node equivalence class Ra rule performs appropriatecopying node labels.R6 rule rule remove nodes edges: removes surplus R-successornode (6 n R C) L(s). Since subtree removed, ts successorsnew, additional root nodes. behavior reason work completionforest.ALCOK(D) case, tableau algorithm stops applying rules findsobvious contradiction, clash, completion rules applicable.Definition 4.11 (Clash). Let = (F, P, c , ) completion system D, R K,F = (Va , Vc , E, L). said contain clash one following conditionsapplies:(C1) concept name NC node Va , {A, A} L(s);(C2) D-conjunction defined satisfiable;.(C3) =6 Va ;(C4) Va g NcF , g L(s) g-successor.completion system containing clash called clash-free. completion systemcomplete none completion rules applicable.Due simplicity algorithm, refrain describing pseudo-code notation: algorithm starts initial completion system repeatedly appliescompletion rules, checking clashes rule application. clash detected, returns unsatisfiable. complete clash-free completion system found,algorithm returns satisfiable. Note that, since completion rulesnon-deterministic, algorithm also non-deterministic.Details proof termination, soundness, completeness given Appendix C. Unfortunately, leave complexity algorithm openproblem: hard prove runs double exponential time, clearwhether exponential time also suffices. However, still use algorithm obtain705fiLutz, Areces, Horrocks, & SattlerRuC1 u C2 L(s), blocked, {C1 , C2 } 6 L(s),L(s) := L(s) {C1 , C2 }RtC1 C2 L(s), blocked, {C1 , C2 } L(s) = ,L(s) := L(s) {C} C {C1 , C2 }RR.C L(s), blocked, R-successor C L(t)create new node t0 t0 Vaset E(s, t) := {R} L(t) := {C}R>(> n C) L(s), blocked, n S-successors.t1 , . . . , tn C L(ti ) ti =6 tj 1 < j n,create n new nodes t1 , . . . , tn s.t. t0 ti 1 n t0 Va ,set E(s, ti ) := {S} L(ti ) := {C, AnSC} 1 nR6(6 n C) L(s), blocked, n + 1 S-successors t0 , . . . , tnC L(ti ) 0 n,choose i, j ti tj , set L(ti ) := L(ti ) L(tj ),L(s, ti ) := L(s, ti ) L(s, tj ), remove tj incomingoutgoing edgesRcg1 , . . . , gn .P L(s), blocked,gi -successors xi (x1 , . . . , xn ) P(P )add gi -successor 1 n,yi gi -successor s, add (y1 , . . . , yn ) P(P ),update cRR.C L(s), blocked,R-successor C/ L(t),L(t) := L(t) {C}R+S.C L(s), blocked, RTrans(R) R v* S, R-successor R.C/ L(t),L(t) := L(t) {R.C}RchS-successor s0 (6 n C) L(s0 )gi -successors xi 1 n (g1 , . . . gn keyfor C) Kblocked {C, C} L(s) = ,L(s) := L(s) {E} E {C, C}Rat, L(t) 6 L(s), t, blocked,set L(s) := L(s) L(t)Figure 11: completion rules SHOQK(D).706fiKeys, Nominals Concrete Domainstight complexity bound SHOQK(D): following corollary easy by-productcorrectness proofs (for proof see Appendix C).Corollary 4.3. SHOQK(D)-concept satisfiable w.r.t. role box R path-freekey box K, satisfiable w.r.t. R K model size |I | 2m= # cl+ (D, R, K).Thus following alternative algorithm deciding satisfiability SHOQK(D)concept w.r.t. role box R path-free key box K: first, guess interpretationcardinality bounded 2m , using placeholder variables Oc insteadconcrete values interpretation concrete features. Let Vc set variablesOc occuring I. Additionally guess interpretation P concrete domainpredicates: completion forests, P maps n-ary concrete predicate usedK n-ary relation Vc . perform standard (polynomial-time) model checkingensure model D. this, treat concepts form g1 , . . . , gn .P usinginterpretation predicates P. easily checked polynomial time alsomodel R Kfor latter, assume placeholder variables stand differentvalues. Finally, use concrete domain D-tester check whether conjunction^P (x1 , . . . , xn )P used inD,K(x1 ,...,xn )P(P )satisfiable. Answer yes otherwise. Since algorithm clearlyimplemented NExpTime provided D-tester running non-deterministicpolynomial time, obtain following:Theorem 4.4. Let key-admissible concrete domain extended D-satisfiabilityNP, SHOQK(D)-concept satisfiability w.r.t. TBoxes, role boxes, path-freekey boxes NExpTime.5. Conclusionpaper, identified key constraints interesting extension descriptionlogics concrete domains. Starting observation, introduced numbernatural description logics provided comprehensive analysis decidabilitycomplexity reasoning. main observation investigations key boxesdramatic consequences complexity reasoning: example, PSpacecomplete DL ALC(D) becomes NExpTime-complete extended path-free, unary,Boolean key boxes undecidable extended path-free, unary, non-Boolean keyboxes. Thus effect key boxes complexity quite different effectkey assertions abstract features allowed (Calvanese et al., 2000):abstract key assertions said free since increase complexityexpressive description logics.show restriction Boolean key boxes (in ALCOK(D) case)path-free key boxes (in SHOQK(D) case) yield decidabile NExpTime-completereasoning problems. selected ALC(D) SHOQ(D) basis analysis since,707fiLutz, Areces, Horrocks, & Sattleropinion, fundamental description logics concrete domains.Going one step further, would interesting combine key boxes extensionsconcrete domains, ones presented Lutz (2003, 2004). name onepossibility, extension ALCOK(D) SHOQ(D) inverse roles seemsnatural idea. Note inverse roles interact several available meansexpressivity: ALC inverse roles PSpace complete (Horrocks, Sattler, & Tobies,1999), ALCO inverse roles ExpTime-complete (Areces et al., 1999) ALC(D)inverse roles even NExpTime-complete (Lutz, 2004).options future research closely related material presentedpaper. example, SHOQK(D)-concept satisfiability still decidable droprequirement key boxes path-free? Moreover, leave exact timerequirements tableau algorithm open problem. algorithm runs (nondeterministic) exponential time, directly yields Theorem 4.4 rather via boundedmodel property.Acknowledgmentswould like thank anonymous reviewers valuable comments. paperextended version (Lutz, Areces, Horrocks, & Sattler, 2003).Appendix A. Proofs Section 3.2prove D2 -satisfiability decided PTime.Proposition A.1. D2 -satisfiability PTime.Proof. Let c D2 -conjunction. show c satisfiable iff none followingconditions applies:1. c contains conjunct D2 (x);2. c contains conjuncts bit0ik (x) bit1ik (x);3. c contains conjuncts bitnik (x) bitmj` (x) k 6= `;4. c contains conjuncts bitnik (x) bitnik (x);5. c contains conjuncts bitnik (x), bit0jk (x), bit1jk (x).easily seen c unsatisfiable one conditions applies. AssumeConditions 1 5 apply c let X set variables used c.x X, set t(x) = k bitnik (x) c n, .6 bitnik (x)/ c n, i, k ,set t(x) = r r appearing index r predicate c. mappingwell-defined since c finite, Condition 3 apply, predicates availablebitnik (), D2 (), >D2 (). define solution c follows: x X, set(x) bit vector v BVt(x) ith bit 1 bit1it(x) (x) c bit0it(x) (x) c,0 otherwise. remains prove indeed solution c:N6. use P (x) c abbreviation P (x) conjunct c.708NfiKeys, Nominals Concrete DomainsLet bit0ik (x) c. t(x) = k thus (x) BVk . Since Condition 2/ c. Moreover, non-applicability Condition 4 impliesapply, bit1ik (x)/ c. definition , ith bit (x) thus 0.bit0k (x)Let bit1ik (x) c. t(x) = k (x) BVk . definition , ith bit(x) 1.Let bit0ik (x) c. t(x) 6= k, (x)/ BVk . Thus (x) (bit0ik )D2done. t(x) = k, ith bit (x) 1 definition thus(x) (bit0ik )D2 ./ BVk done. t(x) = k,Let bit1ik (x) c. t(x) 6= k, (x)jbitnk (x) c n, j . Since Condition 5 apply, thusN/ c. Thus,/ c. Moreover, non-applicability Condition 4 yields bit1ik (x)definition , ith bit (x) 0.bit0ik (x)obvious listed properties checked polynomial time.Appendix B. Proofs Section 4.1prove termination, soundness, completeness ALCOK(D) tableau algorithmpresented Section 4.1, starting termination. start establishing notionstechnical lemmas.Let C concept K key box. use |C| denoteP length C, i.e.number symbols used write down, |K| denote (u1 ,...,uk keyfor C)K |C|.path u = f1 fk g, use |u| denote k + 1. role depth concepts definedinductively follows:rd(A) = rd(N ) = rd(g) = 0rd(u1 , . . . , un .P ) = max{|ui | | 1 n} 1rd(C u D) = rd(C D) = max{rd(C), rd(D)}rd(R.C) = rd(R.C) = rd(C) + 1.following series lemmas eventually allow us prove termination.Lemma B.1. constant k that, tableau algorithm started inputC0 , K = (Va , Vc , E, L) completion tree constructed run algorithm,kk#Va 2|C0 | #Vc 2|C0 | .Proof. Using induction number rule applications case distinction accordingapplied rule, straightforward showC L(a) implies rd(C) |C0 | levT (a)()constructed completion trees T. omit details note that, (1) treatingRch rule, one needs employ fact K Boolean thus adds conceptsrole depth 0 node labels, (2) treating Rp rule, use b implieslevT (a) levT (b).709fiLutz, Areces, Horrocks, & Sattlerimplies upper bound depth constructed completion trees: first,R Rc rules generate new nodes, application either rule nodeVa implies L(a) 6= thus levT (a) |C0 | (). Second, new (abstractconcrete) node b generated application rules node Va clearly satisfieslevT (b) levT (a) + max(1, mpl(C0 )), mpl(C0 ) denotes maximum length pathsC0 (note concepts K may contain paths since Boolean). Sincempl(C0 ) |C0 |, observations imply depth constructed completiontrees bounded 2 |C0 |.out-degree. node generated, due applicationrule R Rc and, initially, one successor. Let us analyze numbersuccessors generated later applications rules R Rc a: rulesapplied concept form R.C u1 , . . . , un .P L(a).definition cl(C0 , K) since K Boolean, number concepts per nodelabel bounded #sub(C0 ) |C0 |. Moreover, rule application creates |C0 |successors. Hence, out-degree constructed completion trees bounded |C0 |2 + 1.Lemma B.2. constant k that, tableau algorithm started C0 , K,kthen, every recursion step, loop terminates 2|C0 | steps.Proof. Fix argument = (T, P, , ) = (Va , Vc , E, L) passed sat function,let 1 , 2 , . . . sequence concrete equivalences computed loop, let1c , 2c , . . . corresponding c relations. Since test(S ) calls D-tester,calls indeed terminates.show1 ( 2 ( ,()kimplies Lemma B.2: Lemma B.1, exists constant k #Vc 2|C0 | .kHence, #i 22|C0 | which, together (), implies number stepskperformed loop also bounded 22|C0 | .proof (). loop reaches i-th step, i1 6= i1cstep 1. Since i1 i1definition, implies i1 ( ci1 . definitionc, easy see i11. Hence i1 ( .cLemma B.3. constant k that, tableau algorithm started C0 , K,knumber recursive calls bounded 2(|C0 |+|K|) .Proof. obviously suffices establish appropriate upper bound number ruleapplications. Ru, Rt, R, Rc rules applied conceptnode label. Lemma B.1, number nodes exponential |C0 | + |K|.Since neither nodes concepts node labels ever deleted, fact node labelssubsets cl(C0 , K) thus implies number applications rulesexponential |C0 | + |K|. holds rules R Rp, appliedevery concept C cl(C0 , K) every pair (abstract) nodes. Finally,number Rch applications exponential |C0 | + |K| since ruleapplied every abstract node every key assertion K.710fiKeys, Nominals Concrete DomainsTermination obvious consequence Lemmas B.2 B.3.Corollary B.4 (Termination). tableau algorithm terminates input.Let us prove soundness algorithm.Lemma B.5 (Soundness). tableau algorithm returns satisfiable, input conceptC0 satisfiable w.r.t. input key box K.Proof. tableau algorithm returns satisfiable, exists complete clashfree completion system = (T, P, , ) C0 . Let = (Va , Vc , E, L). definitiontableau algorithm, completion system 0 = (T, P, , 0 ) calltest(S 0 ) returned . Moreover, = c S. Thus, exists solution0(x) = (y) iff x c y.()0Clearly, also solution : since^ second^ component P ,solution first partP (x1 , . . . , xn ) . Moreover,P used C (x1 ,...,xn )P(P )conjunct =(x, y) second part , x c definitionthus (x) = (y) ().use construct interpretation setting= {a Va | b Va b b a} {w}AI= {a | L(a)}{a | N L(a)} N L(a)={w}otherwiseNIRI= {(a, b) | a0 , b0 Va a0 , b b0 ,b0 R-successor a0 }gI= {(a, (x)) | x g/a -neighbor a}NC , N , R NR , g NcF . first show well-defined:N singleton N . Assume exist a, b 6= bN L(a) L(b). definition (Definition 4.3), N L(a) L(b) impliesb. This, together a, b , yields b b a, contradictinglinear ordering.f functional f NaF . Assume exist a, b, c{(a, b), (a, c)} f b 6= c. exist a1 , a2 , b0 , c0 Va a1a2 , b b0 , c c0 , b0 f -successor a1 , c0 f -successor a2 .definition , thus b0 c0 implying b c. Since b, c , yieldsb c c b, contradiction.g functional g NcF . Assume exist x, Vc{(a, (x)), (a, (y))} f (x) 6= (y). x g/a neighbors a. definition c , thus x c implying (x) = (y) (),contradiction.711fiLutz, Areces, Horrocks, & Sattlershow following claim. proof, use notion f1 fk /a -neighbors(with f1 , . . . fk abstract features), defined analogously u/a -neighbors paths u.Claim 1: paths u, uI (a) = iff ui / -neighborx (x) = .Proof: Let u = f1 fk g. Using induction easily proved that,b , fiI ( (f1I (a)) ) = b iff f1 fi /a -neighbor b0b b0 . Thus particular fkI ( (f1I (a)) ) = b iff f1 fk /a neighbor b0 b b0 . prove claim, hence remains use definitiong together ().following claim central showing model C0 K.Claim 2: C cl(C0 , K), C L(a), C .Since C0 label root node, Claim 2 clearly implies model C0 .Moreover, use prove satisfies key assertions (u1 , . . . , un keyfor C)K: fix a, b C uIi (a) = uIi (b) 1 n. Non-applicability Rch yields{C, C} L(a) 6= . C L(a), Claim 2 implies ( C)I contradictionC . Thus obtain C L(a). analogous way, argue C L(b). SinceuIi (a) uIi (b) defined 1 n, Claim 1 yields ui /a -neighbor xi(xi ) = uIi (a) b ui /a -neighbor yi (yi ) = uIi (b) 1 n. Thusfact uIi (a) = uIi (b) yields (xi ) = (yi ) 1 n. () obtain xi c yithus xi yi 1 n. definition , thus get b. Since a, b ,obtain 6 b b 6 definition thus = b.remains prove Claim 2, using structural induction:C concept name nominal. Easy construction I.C = D. Since C cl(C0 , K), C NNF concept name. Sinceclash-free, C L(a) implies/ L(a). Thus,/ DI construction I,yields (D) .C = u1 , . . . , un .P . Since Rc rule applicable, exist x1 , . . . , xn Vcxi ui /a -neighbor 1 n (x1 , . . . , xn ) P(P ). Claim 1yields uIi (a) = (xi ) 1 n. Since (x1 , . . . , xn ) P(P ) solution, ((x1 ), . . . , (xn )) P thus C .C = g. Since clash-free, exists x Vc x g/a -neighbora. Thus Claim 1 (a, ) g .C = u E C = E. Straightforward using completeness inductionhypothesis.C = R.D. Since R rule applicable, R/a -neighbor bL(b). Let b0 minimal w.r.t. b b0 . definition I,(a, b0 ) RI . Non-applicability Rp rule yields L(b0 ). induction, getb0 DI thus C .712fiKeys, Nominals Concrete DomainsC = R.D. Let (a, b) RI . definition I, implies exist a0 , b0 Vaminimal w.r.t. a0 , b minimal w.r.t. b b0 , b0R-successor a0 . Since b0 clearly R/a -neighbor a, non-applicabilityR yields L(b0 ), implies L(b) due non-applicability Rp.induction, get b DI . Since holds independently choice b, obtain(R.D)I .Lemma B.6 (Completeness). input concept C0 satisfiable w.r.t. input key boxK, tableau algorithm returns satisfiable.Proof. Let model C0 K. use guide (the non-deterministic partsof) algorithm constructs complete clash-free completion system.completion system = (T, P, , ) = (Va , Vc , E, L) called I-compatibleexist mappings : Va : Vc(Ca) C L(a) (a) C(Cb) b R-successor ((a), (b)) RI(Cc) x g-successor g ((a)) = (x)(Cd) (x1 , . . . , xn ) P(P ) ( (x1 ), . . . , (xn )) P(Ce) x (x) = (y).first establish following claim:Claim 1: completion system I-compatible, (i) b implies (a) = (b)(ii) x c implies (x) = (y).Proof: show induction ia b implies (a) = (b) (see Definition 4.3),yields (i).Start. 0a b, exists nominal N N L(a) L(b). (Ca)obtain (a) N (b) N , yields (a) = (b) definitionsemantics.Step. ia b, distinguish three cases:1. i1b, (a) = (b) induction.2. c Va f NaF b f /i1-neighborsi1 c , f -successorc. Hence, exist c1 , c2 Va c i1c12c1 , b f -successor c2 . induction, (c) = (c1 ) = (c2 ).Thus (Cb) yields {((c), (a)), ((c), (b))} f , implies (a) = (b)definition semantics.3. exist (u1 , . . . , un keyfor C) K, ui /ai1 -neighbors xi ui /ai1 neighbors yi b 1 n C L(a)L(b) xi yi 1 n.(Ca) yields a, b C . Using induction, (Cb), (Cc), straightforward713fiLutz, Areces, Horrocks, & Sattlershow uIi ((a)) = (xi ) uIi ((b)) = (yi ) 1 n. (Ce),implies uIi ((a)) = uIi ((b)) 1 k. Since model key box K,yields (a) = (b) definition semantics.Part (ii) Claim 1. x c y, either x Va g NcFx g/a -neighbors a. former case, (Ce) yields (x) = (y).latter case, Part (i) claim (Cc) yields {((a), (x)), ((a), (y))} gimplies (x) = (y). finishes proof Claim 1.show completion rules applied I-compatibilitypreserved.Claim 2: completion system I-compatible rule R applicable S, Rapplied I-compatible completion system 0 obtained.Proof: Let I-compatible completion system, let functions satisfying(Ca) (Ce), let R completion rule applicable S. make case distinctionaccording type R.Ru rule applied concept C1 u C2 L(a). (Ca), C1 u C2 L(a) implies(a) (C1 u C2 )I hence (a) C1I (a) C2I . Since rule adds C1C2 L(a), yields completion system I-compatible via .Rt rule applied C1 tC2 L(a). C1 tC2 L(a) implies (a) C1I (a) C2I .Since rule adds either C1 C2 L(a), applied yieldscompletion system I-compatible via .R rule applied concept R.C L(a), generates new R-successor bsets L(b) = {C}. (Ca), (a) (R.C)I and, hence, exists((a), d) RI C . Set 0 := {b 7 d}. readily checkedresulting completion system I-compatible via 0 .R rule applied concept R.C L(a) adds C L(b) existingR/a -neighbor b a. Hence, exists a0 a0 b Rsuccessor a0 . Part (i) Claim 1, (a) = (a0 ). Thus, (Ca)(a0 ) (R.C)I (Cb) yields (((a0 ), (b)) RI . definition semantics,(b) C thus resulting completion system I-compatible via .(i)(i)Rc rule applied concept u1 , . . . , un .P L(a) ui = f1 fki gi(i)1 n. rule application generates new abstract nodes bj xj 1 n1 j ki(i)(i)(i)(i)b1 f1 -successor 1 n,(i)bj fj -successor bj1 1 n 2 j ki ,(i)xi gi -successor bki 1 n,(x1 , . . . , xn ) P(P ).714fiKeys, Nominals Concrete Domains(i)(Ca), (a) (u1 , . . . , un .P )I . Hence, exist dj 1 n1 j ki 1 , . . . , n(i)(i)(i)(i)((a), d1 ) (f1 )I 1 n,(i)(dj1 , dj ) (fj )I 1 n 2 j ki ,(i)giI (dki ) = 1 n,(1 , . . . , n ) P .(i)(i)Set 0 := 1in 1jki {bj 7 dj } 0 := 1in {xi 7 }.resulting completion system I-compatible via 0 0 .Rch rule applied abstract node key assertion (u1 , . . . , un keyfor C)K non-deterministically adds either C C. definition semantics,(a) C (a) ( C)I . Hence, Rch applied resultingcompletion system I-compatible via .Rp rule applied concept C L(a) adds C label L(b) node bb. (Ca), (a) C . Since Claim 1 yields (a) = (b), followsresulting completion system I-compatible via .Finally, show I-compatibility implies clash-freeness.Claim 3: Every I-compatible completion system clash-free.Proof: Let = (T, P, , ) I-compatible completion system. Consider threekinds clash:Due (Ca), clash form {A, A} L(a) clearly contradicts semantics.Assume Va x Vc g L(a) x g/a -neighbora. exists b Va b x g-successor b. Claim 1,b implies (a) = (b). Thus, g L(a) (Ca) give (b) (g)I . obtaincontradiction since (Cc) yields ((b), (x)) g .Properties (Cd) (Ce) Part (ii) Claim 1 imply solution .Thus, concrete domain satisfiable.describe guidance tableau algorithm model detail:ensure that, times, considered completion systems I-compatible.obviously holds initial completion systemSC0 = (TC0 , P , , ) TC0 = ({a0 }, , , {a0 7 {C}}).guide non-deterministic test function that, given predicate conjunctionset variables Vc Oc input, returns relation defined setting xiff (x) = (y) x, V . relation concrete equivalence since solution(see above). guidance, (Ce) obviously satisfied call test,properties affected call. According Claim 2, apply715fiLutz, Areces, Horrocks, & Sattlercompletion rules I-compatibility preserved. Corollary B.4, algorithmalways terminates, hence also guided way. Since, Claim 3, findclash, algorithm returns satisfiable.tableau algorithm yields decidability tight upper complexity bound ALCOK(D)concept satisfiability w.r.t. key boxes.Theorem B.7 (Theorem 4.1 Section 4.1). Let key-admissible concrete domain.extended D-satisfiability NP, ALCOK(D)-concept satisfiability w.r.t. Booleankey boxes NExpTime.Proof. Corollary B.4 Lemmas B.5 B.6 yield decidability ALCOK(D)-conceptsatisfiability w.r.t. Boolean key boxes. complexity, Lemma B.3 provides exponentialbound number recursive calls. Hence, remains show single recursionstep needs exponential time. Lemma B.2, loop terminatesexponentially many steps. step, compute relations c ,used construction predicate conjunction checking terminationloop. Since, Lemma B.1, exists exponential bound numberabstract concrete nodes completion system S, obviously doneexponential time. Moreover, Lemma B.1 implies size exponential.together fact extended D-satisfiability NP implies calltest needs exponential time. remaining tasks (checking clashes, completeness,rule applicability) clearly also performed exponential time.Appendix C. Proofs Section 4.2first provide proof Lemma 4.2 shows notion tableaux introducedSection 4.2 adequate abstraction models.Lemma C.1 (Lemma 4.2 Section 4.2). Let SHOQK(D)-concept NNF, Rrole box, K path-free key box NNF. satisfiable w.r.t. R K ifftableau w.r.t. R K.Proof. only-if direction, construct tableau common model D,R, K follows:Sa :=Sc := {x | g (s) = x Sa }L(s) := {C cl(D, R, K) | C }E(s, t) := {S ND,R,K| (s, t) }Re(s, g) := g (s) g (s) definedP(P ) := {(x1 , . . . , xn ) Snc | (x1 , . . . , xn ) P }.easily verified tableau w.r.t. R K: proof satisfies(T1) (T9) identical corresponding cases (Horrocks et al., 2000; Horrocks &Sattler, 2001); (T10) holds definition L; (T11) definition L factnominals interpreted singleton sets; (T12) definition L, e, P together716fiKeys, Nominals Concrete Domainssemantics concepts g1 , . . . , gn .P ; (T13) since identity function Sc clearlysolution listed predicate conjunction; (T14) definition L e togethersemantics key constraints; finally (T15) definition L e togethersemantics concepts g.direction, let = (Sa , Sc , L, E, e, P) tableau w.r.t. R Klet solution predicate conjunction (T13). construct modelfollows::= SaAI:= {s | L(s)}concept namesNI:= {s | N L(s)} nominals N(R NR \ NcF Trans(R)v* R {(s, t) | R E(s, t)}S6=RR :={(s, t) | R E(s, t)}+R NR \ NcF Trans(R)(x)e(s, g) = xg (s) :=g NcF .undefined e(s, g) undefinedDue (T11), interpretation nominals singleton. Moreover, interpretationroles well-defined since role boxes acyclic. following claim central provingindeed model D, R, K:Claim: C cl(D, R, K), C L(s) implies C .Proof: proceed induction norm ||C|| C, defined follows:||A||||g||||C1 u C2 ||||(> n R C)||:=:=:=:=||A||||u1 , . . . , un .P ||||C1 C2 ||||(6 n R C)||:=:=:=:=0 concept name01 + ||C1 || + ||C2 ||1 + ||C||concept names nominals N , claim follows definition AI N .negation concept names nominals N (note C NNF), claim followsdefinition AI N together (T1). Concepts C form C1 u C2 C1 C2treated using (T2) (T3) together induction hypothesis. existential,universal, number restrictions, proof analogous one SHIQ (Horrockset al., 2000). concepts form C = g1 , . . . gn .P L(s), C immediateconsequence (T12), definition giI , fact (x1 , . . . , xn ) P(P ) implies((x1 ), . . . , (xn )) P (T13). Finally, concepts C = g, C immediateconsequence definition g together (T15). finishes proofclaim.definition tableaux, exists s0 Sa C L(s0 ). claim,s0 C thus model C.Next, show model R. definition RI , obvious Trans(R)R implies RI transitive relation. let v R R. Trans(R)/ R,RI definition RI . let Trans(R) R (s, t) . E(s, t),(T4) implies R E(s, t), thus (s, t) RI . Otherwise, 0 v*Trans(S 0 ) R (s, t) {(u, v) | 0 E(u, v)}+ . (T4) together 0 v* R implies717fiLutz, Areces, Horrocks, & Sattler{(u, v) | 0 E(u, v)} {(u, v) | R E(u, v)}, thus Trans(R) R implies(s, t) RI .remains show model K. end, let (g1 , . . . , gn keyfor C) Ks, C giI (s) = giI (t) 1 n. Since predicate conjunction(T13) contains explicit inequalities distinct concrete individuals, impliese(s, gi ) = e(t, gi ) 1 n. (T10) implies {C, C} L(s) 6= {C, C} L(t) 6= .C L(s), claim yields ( C)I contradicting C . Thus obtainC L(s) and, similar way, C L(t). Finally, (T14) implies = t, thussatisfies K.proceed prove termination, soundness, completeness tableau algorithmpresented Section 4.2, starting termination. following, use |D, R, K|denote | cl+ (D, R, K)|. Recall number polynomial size D, R, K.Lemma C.2 (Termination). Let key-admissible concrete domain. startedSHOQK(D) concept NNF, role box R, path-free key box K NNF,tableau algorithm terminates.Proof. Assume D, R, K tableau algorithm terminate. Since key-admissible, means infinite sequence S0 , S1 , . . .completion systems (a) S0 initial completion system SD (b) Si+1result applying completion rule Si .possible R R> rules applied infinitely often: easily seenrules Ru, Rt, R6, Rc, R, R+ , Rch, Ra applied finitely oftencompletion systems whose set abstract nodes Va increase since eitheradd concepts node labels (whose size bounded), add concrete nodes (whosenumber bounded linearly number abstract nodes), remove abstractnodes forest. Hence sub-sequence Si1 , Si2 , . . . S0 , S1 , . . .Sij result applying R R> rule Sij 1 . Let si` abstract nodeR R> rule applied Si` 1 . Since impliesgenerated s, linear ordering well-founded. Thus, find infinite subsequence Sj1 , Sj2 , . . . Si1 , Si2 , . . . either sj` = sj`+1 ` 1 sj` sj`+1` 1. former, however, possible since R R> rulesapplied per node concept cl(D, R, K): even node removed,label copying performed R6 rule together clashes type (C3) ensuresR> rule re-applied concept node. Thus second optionremains: subsequence Sj1 , Sj2 , . . . Si1 , Si2 , . . . sj` sj`+1` 1. Let Lj labeling function Sj . Since abstract node labeledsubset Lj cl+ (D, R, K), nodes sjk sj` k fi ` Ljk (sjk ) = Lj` (sj` ).node labels increase and, node removed, label conjoinedlabel node t. Thus node completion system Sj`sj` Lj` (sj` ) Lj` (t). definition, sj` thus blocked Sj` , contradictingassumption R R> rule applied sj` Sj` .Lemma C.3 (Soundness). expansion rules applied SHOQK(D) conceptNNF, role box R, path-free key box K yield completeclash-free completion forest, tableau w.r.t. R K.718fiKeys, Nominals Concrete DomainsProof. Let = ((Va , Vc , E, L), P, c , ) complete clash-free completion system.find solution (x) = (y) iff x c y: Rc rule updatespredicate conjunction , rule application c relation updatedusing concrete equivalence D-tester returns (note satisfiable dueclash-freeness). According Definition 4.1, thus find solution required., define finite tableau = (Sa , Sc , E, L, P) follows:Sa := {s Va | occurs blocked}Sc := {(x) | (s, x) E(g) Sa g}L(s) := L(s) cl(D, R, K) (the intersection due auxiliary concepts AnRC),E(s, t) := {R | R-successor blocks R-successor t0 s}(x)x g-successore(s, g) :=undefined x g-successorP := restriction P Sc .Note function e well-defined due definition adding g-successors.remains show satisfies (T1)(T14), basically consequenceclash-free complete.(T1) satisfied since contain clash (C1).(T2) satisfied since Ru rule cannot applied, thus C1 u C2 L(s) impliesC1 , C2 L(s).(T3) satisfied since Rt rule cannot applied, thus C1 C2 L(s) implies{C1 , C2 } L(s) 6= .(T4), consider s, Sa R E(s, t) R v* R0 . R E(s, t) impliesblocks R-successor s. definition successor, blocksR0 -successor s, thus R0 E(s, t).(T5), let R.C L(s) R E(s, t). R-successor s,blocked implies C L(t) since R rule cannot applied. blocksR-successor t0 s, blocked fact R rule cannotapplied yields C L(t0 ), blocking condition implies C L(t).cases, thus C L(t).(T6) (T7) satisfied reasons (T5) R replaced RR+ .(T8), consider (> n R C) L(s). Hence (> n R C) L(s)completeness implies existence R-successors t1 , . . . , tn C L(ti ).ti =6 tj 6= j. latter implies, 6= j, existence integers k, `k 6= `, AnRCL(ti ), AnRCL(tj ). (T8) satisfied, remainsk`verifyti block tj : case, blocking condition would imply{AnRC, AnRC} L(ti ).k`719fiLutz, Areces, Horrocks, & Sattlerblock ti tj 6= j: similarly, would imply{AnRC, AnRC} L(t).k`case, would clash (C3), contradiction clash-free.(T9), consider (6 n R C) L(s). Hence (6 n R C) L(s) and, sinceR6 rule cannot applied, n R-successors ti s. Sinceti either blocked blocked exactly one node (due linearordering), n ui Sa R E(s, ui ) C L(ui ).(T10), let (6 n R C) L(s) R E(s, t). Hence (6 n R C) L(s)either R-successor blocks R-successor s. first case, nonapplicability Rch rule implies {C, C} L(t) 6= . second case,{C, C} L(t0 ) 6= t0 R-successor blocked t, thus blockingcondition yields {C, C} L(t) 6= . cases, implies {C, C} L(t) 6= .Next, consider (g1 , . . . , gn keyfor C) K e(s, gi ) definedi. Hence gi -successor i, thus blocked nonapplicability Rch rule imply {C, C} L(t) 6= .(T11), consider N L(s) L(t). definition, N L(s) L(t) thus t.Moreover, totality implies assume without loss generality= t. Thus non-applicability Ra rule implies L(t) L(s),thus blocked implies = t.(T12) satisfied since rule Rc cannot applied.(T13), clash-freeness implies satisfiability^^P (x1 , . . . , xn ).P used D,K (x1 ,...,xn )P(P )choice , (x) = (y) iff x c y, thus (T13) satisfied.(T14), let (g1 , . . . , gn keyfor C) K, C L(s) L(t), e(s, gi ) = e(t, gi ),1 n. Thus C L(s) L(t) and, choice e , xi c yigi E(s, xi ) E(t, yi ). Hence t. Without loss generality, assume= t. Thus non-applicability Ra rule implies L(t) L(s),thus blocked implies = t.(T15) satisfied definition since contain clash (C4).Lemma C.4 (Completeness). SHOQK(D)-concept NNF tableau w.r.t.role box R path-free key box K, expansion rules applied D, R,K yield complete clash-free completion forest.720fiKeys, Nominals Concrete DomainsProof. Given tableau = (Sa , Sc , L, E, e, P) w.r.t. R K, guidenon-deterministic rules Rt, Rch, Ra way rule application preservesclash-freeness. together termination Lemma C.2 finishes proof.Along rule application, perform stepwise construction total mappingtakes abstract nodes completion forest elements Sa concrete nodescompletion forest elements Sc .L(s) cl(D, R, K) L((s)) Va ,R-successor s, R E((s), (t)),x g-successor s, e((s), g) = (x),x c iff (x) = (y),.=6 t, (s) 6= (t).mapping satisfying four conditions called correct following. Notecompletion system exists correct mapping contain clash: due(T1) first property, encounter clash (C1). clash (C3) cannot occurdue last property. first third property together (T15) ensureclash (C4) occur. Finally, clash (C2) cannot occur following reason:construction P since edges labelled abstract features never removed,tuple (x1 , . . . , xn ) P(P ), find abstract node paths u1 , . . . , unu1 , . . . , un .P L(s) xi ui -successor 1 n. Thus, first, second,third property together (T12) (T13) ensure conjunction^P ((x1 ), . . . , (xn ))P used inD,K(x1 ,...,xn )P(P )solution ((x)) 6= ((x)) iff (x) 6= (y). fourth property, setting0 (x) := ((x)) x Vc thus yields solution 0 .total mapping inductively defined follows: let solution equation(T13). Choose node s0 L(s0 ), set (s0 ) := s0 s0 (only) nodeinitial completion forest. Obviously, correct. show completionrule applied way either still correct extendedcorrect mapping.application rule Ru preserves correctness due (T2).Due (T3), rule Rt applied correctness preserved.rule R adds new node R.C L(s), correctness implies R.CL((s)), thus (T6) implies existence Sa R E((s), t)C L(t). Thus extending (t) := obviously yields correct mapping.rule R> adds n nodes ti (> n R C) L(s), correctness implies(> n R C) L((s)), thus (T8) implies existence t1 , . . . , tn Sati 6= tj 6= j, R E((s), ti ), C L(ti ). Thus extending (ti ) := tiobviously yields correct mapping.721fiLutz, Areces, Horrocks, & SattlerAssume R6 rule applicable node (6 n R C) L(s)n R-successors ti C L(ti ). correctness implies (6 n R C)L((s)), R E((s), (ti )), C L(ti ). Thus, (T9), 6= j.(ti ) = (tj ). Again, correctness implies ti =6 tj and, without loss generality, assume ti tj . Hence applying rule thereby merging L(tj )L(ti ) preserves correctness.rule Rc, extended similar way R: new gi -successor xiadded, extending (xi ) := e((s), gi ) yields correct . Moreover,(T13) ensures c updated way fourth conditionpreserved.R rule, need extended, (T5), (T4), definitionR-successors imply correctness preserved.R+ rule similar, difference (T7) takes place (T5).Due (T10), rule Rch applied without violating correctness.Ra , consider two reasons Ra applicable:N L(s) L(t). correctness (T11) imply (s) = (t).(g1 , . . . , gn keyfor C) K, C L(s) L(t), gi E(s, xi ) E(t, yi )xi c yi 1 n. correctness implies e((s), gi ) = e((t), gi ),thus (T14) together first property correctness imply (s) = (t).cases, applying Ra preserves correctness.immediate consequence Lemmas 4.2, C.2, C.3, C.4, tableau algorithmalways terminates answers satisfiable w.r.t. R K inputconcept satisfiable w.r.t. input role box R input key box K. Since conceptsatisfiability w.r.t. TBoxes reduced concept satisfiability without TBoxes,obtain following result:Proposition C.5. Let key-admissible concrete domain. tableau algorithmdecides satisfiability SHOQK(D) concepts w.r.t. TBoxes, role boxes, path-free keyboxes.hard verify proof Lemma C.4 together Lemmas 4.2 C.2yield bounded model property SHOQK(D), bound exponential.Corollary C.6. SHOQK(D)-concept satisfiable w.r.t. role box R pathfree key box K, satisfiable w.r.t. R K model size |I | 2m= # cl+ (D, R, K).722fiKeys, Nominals Concrete DomainsProof. SHOQK(D)-concept satisfiable w.r.t. role box R path-free keybox K, Lemma C.4 implies tableau algorithm constructs complete clash-freecompletion forest D, R, K. definition blocking, number abstractnodes completion forest blocked bounded 2m : 6= Vaabstract nodes completion forest L(s) = L(t), either blocks t, blocks s,blocked another node u. Moreover, easily seen numberconcrete successors per abstract node bounded number concrete features C, R,K. Now, proof Lemma C.4, abstract nodes tableau constructedcomplete clash-free completion forest coincide nodes blockedcompletion forest. Finally, proof Lemma 4.2 interpretation domainmodel constructed tableau coincides abstract nodes tableau.Summing up, SHOQK(D)-concept satisfiable w.r.t. R K model size|I | 2m .ReferencesAreces, C., Blackburn, P., & Marx, M. (1999). road-map complexity hybrid logics.Flum, J., & Rodrguez-Artalejo, M. (Eds.), Computer Science Logic, No. 1683Lecture Notes Computer Science, pp. 307321. Springer-Verlag.Baader, F., Horrocks, I., & Sattler, U. (2002a). Description logics semantic web. KIKunstliche Intelligenz, 16 (4), 5759.Baader, F., Lutz, C., Sturm, H., & Wolter, F. (2002b). Fusions description logicsabstract description systems. Journal Artificial Intelligence Research (JAIR), 16,158.Baader, F., & Sattler, U. (1998). Description logics concrete domains aggregation. Prade, H. (Ed.), Proceedings 13th European Conference ArtificialIntelligence (ECAI98), pp. 336340. John Wiley & Sons.Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F. (2003).Description Logic Handbook: Theory, implementation applications. Cambridge University Press, Cambridge, MA, USA.Baader, F., & Hanschke, P. (1991a). scheme integrating concrete domains conceptlanguages. Proceedings 12th International Joint Conference ArtificialIntelligence (IJCAI-91), pp. 452457, Sydney, Australia.Baader, F., & Hanschke, P. (1991b). scheme integrating concrete domains conceptlanguages. DFKI research report RR-91-10, German Research Center ArtificialIntelligence (DFKI).Baader, F., & Hanschke, P. (1992). Extensions concept languages mechanicalengineering application. Proceedings 16th German AI-Conference (GWAI92), Vol. 671 Lecture Notes Computer Science, pp. 132143. Springer-Verlag.Baader, F., & Sattler, U. (2000). Tableau algorithms description logics. Dyckhoff,R. (Ed.), Proceedings International Conference Automated ReasoningTableaux Related Methods (Tableaux 2000), Vol. 1847 Lecture Notes ArtificialIntelligence, pp. 118. Springer-Verlag.723fiLutz, Areces, Horrocks, & SattlerBerger, R. (1966). undecidability domino problem. Memoirs AmericanMathematical Society, 66, 172.Berners-Lee, T., Hendler, J., & Lassila, O. (2001). semantic web. Scientific American,284 (5), 3443.Borger, E., Gradel, E., & Gurevich, Y. (1997). Classical Decision Problem. PerspectivesMathematical Logic. Springer-Verlag.Borgida, A., & Patel-Schneider, P. F. (1994). semantics complete algorithmsubsumption CLASSIC description logic. Journal Artificial Intelligence Research, 1, 277308.Borgida, A., & Weddell, G. E. (1997). Adding uniqueness constraints description logics(preliminary report). Bry, F., Ramakrishnan, R., & Ramamohanarao, K. (Eds.),Proceedings 5th International Conference Deductive Object-OrientedDatabases (DOOD97), Vol. 1341 LNCS, pp. 85102. Springer.Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998). decidability querycontainment constraints. Proceedings 17th ACM SIGACT-SIGMODSIGART Symposium Principles Database Systems (PODS98), pp. 149158.Calvanese, D., De Giacomo, G., & Lenzerini, M. (2000). Keys free description logics.Baader, F., & Sattler, U. (Eds.), Proceedings 2000 International WorkshopDescription Logics (DL2000), No. 33 CEUR-WS (http://ceur-ws.org/), pp. 7988.Calvanese, D., Lenzerini, M., & Nardi, D. (1998). Description logics conceptual datamodeling. Chomicki, J., & Saake, G. (Eds.), Logics Databases InformationSystems, pp. 229263. Kluwer Academic Publisher.Dean, M., Connolly, D., van Harmelen, F., Hendler, J., Horrocks, I., McGuinness, D. L.,Patel-Schneider, P. F., & Stein, L. A. (2002). Web ontology language (OWL) referenceversion 1.0. W3C Working Draft.Fensel, D., van Harmelen, F., Horrocks, I., McGuinness, D. L., & Patel-Schneider, P. F.(2001). OIL: ontology infrastructure semantic web. IEEE IntelligentSystems, 16 (2), 3845.Graham, R. L., Knuth, D. E., & Patashnik, O. (1990). Concrete Mathematics. AddisonWesley Publ. Co., Reading, Massachussetts.Haarslev, V., Lutz, C., & Moller, R. (1998). Foundations spatioterminological reasoningdescription logics. Cohn, A., Schubert, L., & S.C.Shapiro (Eds.), Proceedings6th International Conference Principles Knowledge RepresentationReasoning (KR98), pp. 112124. Morgan Kaufman.Haarslev, V., & Moller, R. (2001). RACER system description. Gore, R., Leitsch,A., & Nipkow, T. (Eds.), Proceedings 1st International Joint ConferenceAutomated Reasoning (IJCAR01), No. 2083 Lecture Notes Artificial Intelligence,pp. 701705. Springer-Verlag.Haarslev, V., Moller, R., & Wessel, M. (2001). description logic ALCN HR+ extendedconcrete domains: practically motivated approach. Gore, R., Leitsch, A.,724fiKeys, Nominals Concrete Domains& Nipkow, T. (Eds.), Proceedings 1st International Joint Conference Automated Reasoning IJCAR01, No. 2083 Lecture Notes Artificial Intelligence, pp.2944. Springer-Verlag.Halpern, J. Y., & Moses, Y. (1992). guide completeness complexity modallogics knowledge belief. Artificial Intelligence, 54 (3), 319380.Hollunder, B., & Baader, F. (1991). Qualifying number restrictions concept languages.Proceedings 2nd International Conference Principles Knowledge Representation Reasoning (KR91), pp. 335346, Boston, MA, USA.Hopcroft, J. E., & Ullman, J. D. (1979). Introduction Automata Theory, LanguagesComputation. Addison-Wesley.Horrocks, I., Sattler, U., & Tobies, S. (2000). Practical reasoning expressive description logics. Logic Journal IGPL, 8 (3), 239264.Horrocks, I. (1998). Using expressive description logic: FaCT fiction?. Proceedings6th International Conference Principles Knowledge RepresentationReasoning (KR98), pp. 636647.Horrocks, I. (2002). Reasoning expressive description logics: Theory practice.Voronkov, A. (Ed.), Proceedings 18th International Conference AutomatedDeduction (CADE 2002), No. 2392 Lecture Notes Artificial Intelligence, pp. 115.Springer.Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2002). Reviewing designDAML+OIL: ontology language semantic web. Proceedings 18thNational Conference Artificial Intelligence (AAAI 2002), pp. 792797.Horrocks, I., & Sattler, U. (2001). Ontology reasoning SHOQ(D) description logic.Nebel, B. (Ed.), Proceedings 17th International Joint Conference ArtificialIntelligence (IJCAI01), pp. 199204. Morgan-Kaufmann.Horrocks, I., Sattler, U., & Tobies, S. (1999). Practical reasoning expressive descriptionlogics. Ganzinger, H., McAllester, D., & Voronkov, A. (Eds.), Proceedings6th International Conference Logic Programming Automated Reasoning(LPAR99), No. 1705 Lecture Notes Artificial Intelligence, pp. 161180. SpringerVerlag.Kamp, G., & Wache, H. (1996). CTL - description logic expressive concrete domains.Tech. rep. LKI-M-96/01, Laboratory Artificial Intelligence (LKI), UniversitityHamburg, Germany.Khizder, V. L., Toman, D., & Weddell, G. E. (2001). decidability complexity description logics uniqueness constraints. den Bussche, J. V., & Vianu, V. (Eds.),Proceedings 8th International Conference Database Theory (ICDT2001), Vol.1973 LNCS, pp. 5467. Springer.Knuth, D. (1968). Art Computer Programming, Vol. 1. Addison-Wesley.Lutz, C. (2003). Description logics concrete domainsa survey. Advances ModalLogics Volume 4, pp. 265296. World Scientific Publishing Co. Pte. LTd.725fiLutz, Areces, Horrocks, & SattlerLutz, C. (2002a). Complexity Reasoning Concrete Domains. Ph.D. thesis,LuFG Theoretical Computer Science, RWTH Aachen, Germany.Lutz, C. (2002b). PSpace reasoning description logic ALCF(D). Logic JournalIGPL, 10 (5), 535568.Lutz, C. (2002c). Reasoning entity relationship diagrams complex attributedependencies. Horrocks, I., & Tessaris, S. (Eds.), Proceedings InternationalWorkshop Description Logics 2002 (DL2002), No. 53 CEUR-WS (http://ceurws.org/), pp. 185194.Lutz, C. (2004). NExpTime-complete description logics concrete domains. ACMTransactions Computational Logic, 5 (4), 669705.Lutz, C., Areces, C., Horrocks, I., & Sattler, U. (2002). Keys, nominals, concretedomains. LTCS-report 02-04, Technical University Dresden. See http://lat.inf.tudresden.de/research/reports.html.Lutz, C., Areces, C., Horrocks, I., & Sattler, U. (2003). Keys, nominals, concretedomains. Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI03), pp. 349354. Morgan-Kaufmann Publishers.Pan, J. Z., & Horrocks, I. (2002). Reasoning SHOQ(Dn ) description logic. Horrocks, I., & Tessaris, S. (Eds.), Proceedings International Workshop Description Logics 2002 (DL2002), No. 53 CEUR-WS (http://ceur-ws.org/), pp. 5362.Post, E. M. (1946). variant recursively unsolvable problem. Bulletin AmericanMathematical Society, 52, 264268.Schild, K. D. (1991). correspondence theory terminological logics: Preliminary report.Mylopoulos, J., & Reiter, R. (Eds.), Proceedings 12th International JointConference Artificial Intelligence (IJCAI-91), pp. 466471. Morgan Kaufmann.Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 126.726fiJournal Artificial Intelligence Research 23 (2005) 421-440Submitted 07/04; published 04/05Practical use Variable Elimination ConstraintOptimization Problems: Still-life Case StudyJavier LarrosaEnric MoranchoDavid Nisolarrosa@lsi.upc.eduenricm@ac.upc.eduniso57@casal.upc.eduUniversitat Politecnica de CatalunyaJordi Girona 1-3, 08034 Barcelona, SpainAbstractVariable elimination general technique constraint processing. often discarded high space complexity. However, extremely usefulcombined techniques. paper study applicability variable elimination challenging problem finding still-lifes. illustrate several alternatives:variable elimination stand-alone algorithm, interleaved search, sourcegood quality lower bounds. show techniques best known optiontheoretically empirically. experiments able solve n = 20instance, far beyond reach alternative approaches.1. IntroductionMany problems arising domains resource allocation (Cabon, de Givry, Lobjois,Schiex, & Warners, 1999), combinatorial auctions (Sandholm, 1999), bioinformaticsprobabilistic reasoning (Pearl, 1988) naturally modeled constraint satisfactionoptimization problems. two main solving schemas search inference. Searchalgorithms constitute usual solving approach. transform problem setsubproblems selecting one variable instantiating different alternatives.Subproblems solved applying recursively transformation rule. recursiondefines search tree normally traversed depth-first manner,benefit requiring polynomial space. practical efficiency search algorithmsgreatly depends ability detect prune redundant subtrees. worst-case,search algorithms need explore whole search tree. Nevertheless, pruning techniquesmake much effective.Inference algorithms (also known decomposition methods) solve problem sequence transformations reduce problem size, preserving optimal cost.well known example bucket elimination (BE, also known variable elimination) (Bertele& Brioschi, 1972; Dechter, 1999). algorithm proceeds selecting one variabletime replacing new constraint summarizes effect chosen variable. main drawback new constraints may large arities requireexponentially time space process store. However, nice propertyworst-case time space complexities tightly bounded structural parameter called induced width. exponential space complexity limits severely algorithmsc2005AI Access Foundation. rights reserved.fiLarrosa, Morancho & Nisopractical usefulness. Thus, constraint satisfaction community variable eliminationoften disregarded.paper consider challenging problem finding still-lifes stablepatterns maximum density game life. academic problem recentlyincluded CSPlib repository1 dedicated web page2 set maintainup-to-date results. Bosch Trick (2002), still-life problem solved using twodifferent approaches: integer programming constraint programming, basedsearch. None could solve n = 8 problem within reasonable time.best results obtained hybrid approach combines two techniquesexploits problem symmetries order reduce search space. algorithm,solved n = 15 case 8 days cpu. Smith (2002) proposed interestingalternative using pure constraint programming techniques, solving problemdual form. work, Smith could improve n = 15 limit. Although explicitly2mentioned, two works use algorithms worst-case time complexity O(2(n ) ).paper show usefulness variable elimination techniques. First applyplain BE. could expected, observe competitive stateof-the-art alternatives. Next, introduce sophisticated algorithm combinessearch variable elimination (following ideas Larrosa & Dechter, 2003) useslower bound based mini-buckets (following ideas Kask & Dechter, 2001).algorithm, solve one minute n = 15 instance. able solven = 20 instance, far beyond reach previous techniques. readabilityreasons, describe main ideas omit algorithmic details.3structure paper following: next Section give preliminarydefinitions. Section 3 solve problem plain BE. Section 4 introducehybrid algorithm obtained results reported Section 5. Section 6discuss ideas explored article extended domains. Besides,report additional experimental results. Finally, Section 7 gives conclusionslines future work.2. PreliminariesSection first define still-life problem. Next, define weighted CSPframework formulate still-life weighted CSP. Finally, review mainsolving techniques weighted CSPS.2.1 Life Still-Lifegame life (Gardner, 1970) played infinite checkerboard, squarecalled cell. cell eight neighbors: eight cells share one two cornersit. player places checkers cells. checker it, cellalive, else dead. state board evolves iteratively according followingthree rules: (1) cell exactly two living neighbors state remains1. www.csplib.org2. www.ai.sri.com/~ nysmith/life3. interested reader find extended version, along source code implementationwww.lsi.upc.edu/~ larrosa/publications422fiOn practical use variable elimination3131131Xc4222B2CEFigure 1: A: 3 3 still-life. B: constraint graph simple WCSP instance fourvariables three cost functions. C: constraint graph assigning variablex4 . D: constraint graph clustering variables x3 x4 . E: constraintgraph eliminating variable x4 .next iteration, (2) cell exactly three living neighbors alivenext iteration (3) cell fewer two three living neighbors,dead next iteration. Although defined terms extremely simple rules,game life proven mathematically rich attracted interestmathematicians computer scientists.still-life problem SL(n) consist finding nn stable pattern maximum densitygame life. cells outside pattern assumed dead. Consideringrules game, easy see cell (i, j) must satisfy following threeconditions: (1) cell alive, must exactly two three living neighbors, (2)cell dead, must three living neighbors, (3) cell gridboundary (i.e, = 1 = n j = 1 j = n), cannot part sequence threeconsecutive living cells along boundary. last condition needed threeconsecutive living cells boundary would produce living cells outside grid.Example 1 Figure 1.A shows solution SL(3). easy verify cellssatisfy previous conditions, hence stable. pattern optimal 6living cells 3 3 stable pattern 6 living cells exists.2.2 Weighted CSPweighted constraint satisfaction problem (WCSP) (Bistarelli, Montanari, & Rossi, 1997)defined tuple (X, D, F), X = {x1 , . . . , xn } set variables taking valuesfinite domains Di D. F set weighted constraints (i.e., cost functions).f F defined subset variables, var(f ), called scope. objectivefunction sum functions F,F =Xff Fgoal find instantiation variables minimizes objective function.Example 2 Consider WCSP four variables X = {xi }4i=1 domains Di = {0, 1}three cost functions: f1 (x1 , x4 ) = x1 + x4 , f2 (x2 , x3 ) = x2 x3 f3 (x2 , x4 ) = x2 + x4 .423fiLarrosa, Morancho & Nisoobjective function F (x1 , x2 , x3 , x4 ) = x1 + x4 + x2 x3 + x2 + x4 . Clearly, optimalcost 0, obtained every variable taking value 0.Constraints given explicitly means tables, implicitly mathematicalexpressions computing procedures. Infeasible partial assignments specified constraints assign cost them. assignment value variable xi notedxi = a. partial assignment tuple = (xi1 = v1 , xi2 = v2 , , xij = vj ). extensionxi = noted (xi = a). WCSPs instances graphically depicted meansinteraction constraint graph, one node per variable one edge connecting two nodes appear scope cost function. instance,Figure 1.B shows constraint graph problem previous example.2.3 Overview Solving TechniquesSubsection review solving techniques widely used reasoningconstraints.2.3.1 searchWCSPs typically solved depth-first search. Search algorithms definedterms instantiating functions,Definition 1 Let P = (X, D, F) WCSP instance, f function F, xi variablevar(f ), v value Di . Instantiating f xi = v new function scopevar(f ) {xi } returns tuple t, f (t (xi = v)). Instantiating P xi = vnew problem P |xi =v = (X {xi }, {Di }, F 0 ), F 0 obtained instantiatingfunctions F mention xi xi = v.instance, instantiating problem Example 2 x4 = 1, produces newproblem three variables {xi }3i=1 three cost functions: f1 (x1 , x4 = 1) = x1 + 1,f2 (x2 , x3 ) = x2 x3 f3 (x2 , x4 = 1) = x2 + 1. Figure 1.C shows correspondingconstraint graph, obtained original graph removing instantiated variable x4adjacent edges. Observe new graph depends instantiated variable,depend value assigned it.Search algorithms transform current problem P set subproblems. Usuallydone selecting one variable xi instantiated different domain values(P |xi =v1 , P |xi =v2 , , P |xi =vd ). transformation called branching. subproblem process recursively applied, defines tree subproblems. Searchalgorithms expand subproblems trivial case achieved: variable left,pruning condition detected. optimization problems, pruning conditions usuallydefined terms lower upper bounds. Search keeps cost best solutionfar, upper bound optimal cost. node, lower bound bestcost obtainable underneath computed. lower bound greater equalupper bound, safe backtrack.size search tree O(dn ) (being size largest domain) boundstime complexity. tree traversed depth-first, space complexity polynomial.424fiOn practical use variable elimination2.3.2 clusteringwell-known technique constraint processing clustering (Dechter & Pearl, 1989).merges several variables one meta-variable, preserving problem semantics.Clustering variables xi xj produces meta-variable xk , whose domain Di Dj . Costfunctions must accordingly clustered. instance, problem Example 2, clustering variables x3 x4 produces variable xc domain Dc = {(0, 0), (0, 1), (1, 0), (1, 1)}.Cost functions f2 f3 clustered fc (x2 , xc ) = f2 + f3 . new variablenotation fc = x2 xc [1] + x2 + xc [2], xc [i] denotes i-th component xc . Functionf1 needs reformulated f1 (x1 , xc ) = x1 + xc [2]. constraint graph resultingproblem obtained merging clustered variables connecting meta-nodenodes adjacent clustered variables. Figure 1.D shows constraint graph clustering x3 x4 . typical use clustering transformcyclic constraint graph acyclic one, solved efficiently thereafter.2.3.3 variable eliminationVariable elimination based following two operations,Definition 2 sum two functions f g, noted (f + g), new functionscope var(f ) var(g) returns tuple sum costs f g,(f + g)(t) = f (t) + g(t)Definition 3 elimination variable xi f , noted f xi , new functionscope var(f ) {xi } returns tuple cost best extension xi ,(f xi )(t) = min {f (t (xi = a))}aDiObserve f unary function (i.e., arity one), eliminating variablescope produces constant.Definition 4 Let P = (X, D, F) WCSP instance. Let xi X arbitrary variablelet Bi set cost functions xi scope (Bi called bucketxi ). define giXgi = (f ) xif Bielimination xi transforms P new problem P xi = {X {xi }, {Di }, (FBi ) {gi }}. words, P xi obtained replacing xi functions bucketgi .P P xi optimal cost because, construction, gi compensatesabsence xi . constraint graph P xi obtained forming cliquenodes adjacent node xi removing xi adjacent edges. example,eliminating x4 problem Example 2 produces new problem three variables{xi }3i=1 two cost functions: f2 g4 . scope g4 {x1 , x2 } defined as,425fiLarrosa, Morancho & Nisog4 = (f1 + f3 ) x4 = (x1 + x4 + x2 + x4 ) x4 = x1 + x2 . Figure 1.D shows constraintgraph elimination.previous example, new function g4 could expressed mathematical expression. Unfortunately, general, result summing functions eliminating variablescannot expressed intensionally, new cost functions must stored extensionallytables. Consequently, space complexity computing P xi proportional numQber entries gi , is: ( xj var(gi ) |Dj |). Since xj var(gi ) iff xj adjacent xiQconstraint graph, previous expression rewritten ( xj N (i,GP ) |Dj |),GP constraint graph P N (i, GP ) set neighbors xi GP .time complexity computing P xi space complexity multiplied costcomputing entry gi .Bucket elimination (BE) works two phases. first phase, eliminates variablesone time reverse order. elimination xi , new gi function computedadded corresponding bucket. elimination x1 produces empty-scopefunction (i.e., constant) optimal cost problem. second phase,considers variables increasing order generates optimal assignment variables.time space complexity exponential structural parameterconstraint graph, called induced width, captures maximum arity amonggi functions. Without additional overhead also compute number optimalsolutions (see Dechter, 1999, details).2.3.4 super-bucketscases, may convenient eliminate set variables simultaneously (Dechter& Fatah, 2001). elimination set variables performed collectingset functions mentioning least one variable . Variables functionsreplaced new function gY defined as,gY = (Xf)fset called super-bucket. Note elimination seenclustering variables meta-variable xY followed elimination.2.3.5 mini-bucketsspace complexity high, approximation, called mini buckets(Dechter & Rish, 2003), used. Consider elimination xi , associatedbucket Bi = {fi1 , . . . , fik }. would compute,gi = (Xf ) xif Bitime space complexity computation depends arity gi . beyondavailable resources, partition bucket Bi so-called mini-buckets Bi1 , . . . , Biknumber variables scopes mini-bucket bounded parameter.compute,Xgij = (f ) xi , j = 1..kf Bij426fiOn practical use variable elimination676122289351828993131895554444BCFigure 2: constraint graph evolution sequence variable eliminationsinstantiations.gij bounded arity. Since,gijgizX }|(f Bi{f ) xik z X }|X({f ) xij=1 f Bijelimination variables using mini-buckets yields lower bound actual optimalcost.2.3.6 combining search variable eliminationplain costly space, combine search (Larrosa & Dechter,2003). Consider WCSP whose constraint graph depicted Figure 2.A. Supposewant eliminate variable want compute store constraintsarity higher two. take consideration variables connectedtwo variables. example, variable x7 one selected.elimination transforms problem another one whose constraint graph depictedFigure 2.B. x6 degree decreased two, also eliminated.new constraint graph depicted Figure 2.C. point, every variable degreegreater two, switch search schema selects variable, say x3 , branchesvalues produces set subproblems, one value domain.constraint graph, depicted Figure 2.D. subproblem,possible eliminate variable x8 x4 . elimination possible eliminatex2 x9 , subsequently x5 x1 . Eliminations branching doneevery subproblem since new constraints eliminated variables replaceddiffer one subproblem another. example, one branching made.Therefore, elimination variables reduced search tree size d9 d,size domains. example, bounded arity new constraintstwo, generalized arbitrary value.3. Solving Still-life Variable EliminationSL(n) easily formulated WCSP. natural formulation associates onevariable xij cell (i, j). variable two domain values. xij = 0 cell427fiLarrosa, Morancho & NisoX1j 2j 1j2j+1j+2X21X3X4i+1X5+2X6BFigure 3: A: Structure constraint graph SL(n). node center, associatedcell (i, j), linked cells interacts with. shadowed area indicatesscope fij . B (left): Constraint graph SL(6) clustering cellsrow variables. B (from left right: Evolution constraint graphexecution BE.dead, xij = 1 alive. cost function fij variable xij . scopefij xij neighbors. evaluates stability xij : xij unstable givenneighbors, fij returns ; else fij returns 1 xij .4 objective function minimizedis,F =n XnXfiji=1 j=1instantiation X represents unstable pattern, F (X) returns ; else returnsnumber dead cells. fij stored table 29 entries evaluated constanttime.Figure 3.A illustrates structure constraint graph SL(n). picture showsarbitrary node xij linked nodes interacts with. instance, edgexij xi,j+1 xi,j+1 neighbor xij grid and, consequently,variables scope fij . edge xij xi1,j2cells neighbors xi1,j1 grid and, therefore, appear scopefi1,j1 . shadowed area represents scope fij (namely, xij neighbors).complete graph obtained extending connectivity pattern nodesgraph.sake clarity, use equivalent compact SL(n) formulationmakes easier describe implement: cluster variables rowsingle meta-variable. Thus, xi denotes state cells i-th row (namely,xi = (xi1 , xi2 , . . . , xin ) xij {0, 1}). Accordingly, takes values sequencesn bits or, equivalently, natural numbers interval [0..2n 1]. Cost functionsaccordingly clustered: cost function fi associated row i, defined as,fi =nXfijj=14. Recall that, WCSP, task minimize number dead cells. Therefore, give cost 1dead cells cost 0 living cells.428fiOn practical use variable eliminationinternal rows, scope fi {xi1 , xi , xi+1 }. cost function top row, f1 ,scope {x1 , x2 }. cost function bottom row, fn , scope {xn1 , xn }.unstable cell xi , fi (xi1 , xi , xi+1 ) = . Else, returns number dead cellsxi . Evaluating fi (n) bits arguments need checked.new, equivalent, objective function is,F =nXfii=1Figure 3.B (left) shows constraint graph SL(6) formulation. arbitraryvariable xi connected two variables two variables below.sequential structure constraint graph makes intuitive. eliminates variablesdecreasing orders. elimination xi produces new function gi = (fi1 + gi+1 ) xiscope {xi2 , xi1 }. Figure 3.B (from left right) shows evolution constraintgraph along elimination variables. Formally, applies recursion transformssubproblem P P xi , xi variable P highest index. satisfiesfollowing property,Property 1 Let gi function added replace xi . gi (a, b) costbest extension (xi2 = a, xi1 = b) eliminated variables (xi , . . . , xn ). Formally,gi (a, b) =minvi Di ,...,vn Dn{fi1 (a, b, vi ) + fi (b, vi , vi+1 ) ++fi+1 (vi , vi+1 , vi+2 ) + . . .+fn1 (vn2 , vn1 , vn ) + fn (vn1 , vn )}gi (a, b) = , means pattern a, b cannot extended inferior rowsstable pattern. gi (a, b) = k (with k 6= ), means a, b extendedoptimal extension k dead cells xi1 xn .space complexity (n 22n ), due space required store n functionsgi extensionally (2n 2n entries each). Regarding time, computing entry gicost (n 2n ) (finding minimum 2n alternatives, computation one(n)). Since gi 22n entries, total time complexity (n2 23n ). Observesolving SL(n) exponential improvement search algorithms,2time complexity O(2n ).Table 4 reports empirical results. obtained 2 Ghz Pentium IVmachine 2 Gb memory. first columns reports problem size, secondreports optimal cost number dead cells (in parenthesis, number livingcells), third column reports number optimal solutions. count differenttwo solutions even one transformed problem symmetry.fourth column reports CPU time seconds. fifth, sixth seventhcolumns report results obtained three approaches tried Bosch Trick(2002):5 constraint programming (CP), integer programming (IP), sophisticatedalgorithm (CP/IP) combines CP IP, exploits problem symmetries.5. corresponding OPL code available http://mat.gsia.cmu.edu/LIFE.429fiLarrosa, Morancho & Nison56789101112131415opt9(16)18(18)21(28)28(36)38(43)46(54)57(64)68(76)79(90)92(104)106(119)n. sol.1482176359073129126168211?0000427210163813788105*CP00476> 600******IP01326> 600******CP/IP0002206015311536120505 1057 105Figure 4: Experimental results four different algorithms still-life problem. Timesseconds.observed clearly outperforms CP IP orders magnitude.n = 14 case largest instance could solve due exhausting availablespace. Comparing CP/IP, observe clear winner. additionalobservation scales regularly, execution requiring roughly eight timestime four times space previous, clear accordancealgorithm complexity.4. Combining Search Variable EliminationOne way overcome high space complexity combine search variableelimination hybrid approach HYB (Larrosa & Schiex, 2003). idea use search(i.e, instantiations) order break problem independent smaller partsvariable elimination efficiently performed.Let us reformulate problem convenient way hybrid algorithm.sake simplicity without loss generality consider n even. clusterRrow variables three meta-variables: xCdenotes two central cells row i, xinLxi denote 2 1 remaining cells right left, respectively (see Figure 5.A).LRConsequently, xCtakes values range [0..3], xi xi take values rangen1[0..2 2 1]. Cost functions accordingly clustered,nfiL=2XfiR =fij ,nXj= n+12j=1new, equivalent, objective function is,F =nX(fiL + fiR )i=1430fijfiOn practical use variable eliminationLeftXL1CenterXC1RightXLeftR1CenterRightX1X2X3XLXCXRX4XLnXCnXX5RnX6BLeftCenterRightLeftCenterRightX1X1X2X2X3X3X4X4X5X5X6X6CFigure 5: Formulation SL(n) used hybrid algorithm. A: row clusteredthree variables. B: Constraint graph SL(6). C: Constraint graphCCassignment xCn , xn1 xn2 . D: Constraint graph eliminationLRxn xn .431fiLarrosa, Morancho & NisoCL CLCscopes internal row functions, fiL fiR , {xLi1 , xi1 , xi , xi , xi+1 , xi+1 }CRCRCRLRLCC{xi1 , xi1 , xi , xi , xi+1 , xi+1 }. Top functions f1 f1 scopes {x1 , x1 , xL2 , x2 }R CRLRLCL C{xC1 , x1 , x2 , x2 }. Bottom functions fn fn scopes {xn1 , xn1 , xn , xn }RCRC{xn1 , xn1 , xn , xn }. Figure 5.B shows corresponding constraint graph. imporRtance formulation xLxi independent (i.e, edgeconstraint graph connecting left right variables).hybrid algorithm HYB searches central variables eliminates lateralvariables. Variables considered decreasing order index. Thus, algorithmCCstarts instantiating xCn , xn1 xn2 , produces subproblem constraintRgraph shown Figure 5.C. Observe variable xLn (respectively, xn ) connectedLLRRvariables xn1 xn2 (respectively, xn1 xn2 ). eliminated producingLRRRnew function gnL scope {xLn2 , xn1 } (respectively, gn scope {xn2 , xn1 }).Figure 5.D shows resulting constraint graph. Lateral variables domains sizenn2 2 1 . Hence, elimination space (2n ) time (23 2 ). important noteCCeliminations subject current assignment xCn , xn1 xn2 . Therefore,recomputed value change. elimination xLnCxR,algorithmwouldassignvariablexmakepossibleeliminationnn3LRCxn1 xn1 , on. arbitrary level search, algorithm assigns xi ,Rmakes xLi+2 xi+2 independent central columns related twoLvariables above. Then, eliminates replacing variables functions gi+2R scopes {xL , xL } {xR , xR }, respectively. Formally, HYB applies recursiongi+2i+1i+1transforms subproblem P 4 simpler subproblems {((P |xC =v ) xL ) xR }3v=0 .i+2i+2satisfies following property,Property 2 Let giL function computed HYB used replace variable xL.LgiL (a, b) cost best extension (xL=a,x=b)eliminatedvariablesi2i1LR(xL, . . . , xn ), conditioned current assignment. Similarly, right side, gi (a, b)RRRcost best extension (xi2 = a, xi1 = b) eliminated variables (xi , . . . , xRn ),conditioned current assignment.L (a, b) among comA consequence previous Property minimum gi+2binations b lower bound best cost obtained leftL (a, b)} +part grid continue current line search. Therefore, mina,b {gi+2Rmina,b {gi+2 (a, b)} valid lower bound current node used pruningpurposes.space complexity algorithm (n 2n ), due giL giR functionsneed explicitly stored. time complexity O(n 23.5n ), O(4n )nodes may visited (n variables domains size 4) cost processingnnode (n 23 2 ) due variable eliminations.Thus, comparing BE, time complexity increases (n2 23n ) O(n23.5n ).prize HYB pays space decrement (n 22n ) (n 2n ).432fiOn practical use variable elimination4.1 Refining Lower Boundwell-known average-case efficiency search algorithms depends greatlylower bound use. algorithm using poor lower bound based giLgiR functions, only.Kask Dechter (2001) proposed general method incorporate informationyet-unprocessed variables lower bound. Roughly, idea run mini buckets(MB) prior search save intermediate functions future use. MB executed usingreverse order search instantiate variables. execution MBcompleted, search algorithm executed. node, uses mini-bucket functionscompiled look-ahead information. Subsection, show adaptedidea SL(n) integrated HYB.CRConsider SL(n) formulated terms left, central right variables (xL, xi , xi ).LCRexact elimination first row variables (x1 , x1 , x1 ) done using super-bucketB1 = {f1L , f1R , f2L , f2R } computing function,CRh1 = (f1L + f1R + f2L + f2R ) {xL1 , x1 , x1 }CR L CRscope h1 {xL2 , x2 , x2 , x3 , x3 , x3 }. Using mini-buckets idea, partitionLLLRbucket B1 = {f1 , f2 } B1 = {f1R , f2R }. Then, approximate h1 two smallerRfunctions hL1 h1 ,LLL ChL1 = (f1 + f2 ) {x1 , x1 }RRCRhR1 = (f1 + f2 ) {x1 , x1 }RL CL CCR CRscopes hL1 h1 {x2 , x2 , x3 , x3 } {x2 , x2 , x3 , x3 }, respectively.idea repeated row row increasing order. general, processing row i, yields twofunctions,LLL ChL= (hi1 + fi+1 ) {xi , xi }RRCRhR= (hi1 + fi+1 ) {xi , xi }RLCLCCRCRscopes hLhi {xi+1 , xi+1 , xi+2 , xi+2 } {xi+1 , xi+1 , xi+2 , xi+2 }, respecL00tively. construction, hi (a, , b, b ) contains cost best extension a, a0 , b, b0CL Cprocessed variables xL, xi , . . . , x1 , x1 considering left functions only.00property hR(a , a, b , b) right functions.complexity MB space (n2n ) time (n2 21.5n ). Since complexitiessmaller complexity HYB, running pre-process affect overallcomplexity.RMB executed, HYB use information recorded hLhi functions.LRConsider arbitrary node HYB assigns xCeliminates xi+2 xi+2 . LetLLL (a, b)b domain values variables xi xi+1 . Property 2 gi+2contains best extension a, b attained left part rows + 1n long current assignment X C maintained. Additionally,CChLi1 (a, xi , b, xi+1 ) contains best extension a, b attained left partL (a, b) + hL (a, xC , b, xC ) lower bound a, b X Crows 1. Therefore, gi+2i1i+1left part grid. Consequently,LCCmina,b[0..2 n2 1 1] {gi+2(a, b) + hLi1 (a, xi , b, xi+1 )}433fiLarrosa, Morancho & Nisolower bound left part grid current assignment.reasoning right part that,LCCmina,b[0..2 n2 1 1] {gi+2(a, b) + hLi1 (a, xi , b, xi+1 )} +RCC+mina,b[0..2 n2 1 1] {gi+2(a, b) + hRi1 (xi , a, xi+1 , b)}lower bound current assignment.4.2 Refining Upper Boundefficiency algorithm also depends initial value upper bound.good upper bound facilitates pruning earlier search tree. Bosch Trick (2002)suggested modify SL(n) adding additional constraint considering symmetricpatterns, only. Since space solutions becomes considerably smaller, problempresumably simpler. Clearly, cost optimal symmetric stable pattern upperbound optimal cost SL(n). observed upper boundstight.Since motivation work use variable elimination techniques,considered still-lifes symmetric vertical reflection,efficiently solved using BE. symmetric still-life problem SSL(n) consists findingn n stable pattern maximum density game life subject vertical reflectionsymmetry (namely, state cells (i, j) (i, n j + 1) must same.6Adapting solve SSL(n) extremely simple: need remove symmetricalvalues domains. Let us assume n even number (the odd case similar).represent symmetric sequences bits length n considering left sidesequence (i.e, first n/2 bits). right part implicit left part. Thus,nrepresent symmetrical sequences n bits integers interval [0..2 2 1]. Reversingsequence bits noted a. Hence, sequence n/2 bits, correspondingsymmetrical sequence n bits.complexity BE, applied SSL(n) time (n2 21.5n ) space (n2n ).Therefore, executing prior HYB setting upper bound optimal costaffect overall complexity hybrid.4.3 Exploitation SymmetriesSL(n) highly symmetric problem. stable pattern, possible createequivalent pattern by: (i) rotating board 90, 180 270 degrees, (ii) reflectingboard horizontally, vertically along one diagonal (iii) combinationrotations reflections.Symmetries exploited different algorithmic levels. general,save computation whose outcome equivalent previous computation duesymmetry kept outcome. instance, MB necessary compute00L00hR(a , a, b , b) equal hi (a, , b, b ) due vertical reflection symmetry.CCAnother example occurs HYB. Let xn = vn , xCn1 = vn1 , . . . , xi = vi current6. Unlike Smiths (2002) work cannot easily exploit larger variety symmetries rotationsdiagonal reflections.434fiOn practical use variable eliminationn131415161718192022242628opt79(90)92(104)106(119)120(136)137(152)153(171)171(190)190(210)????opt-SSL7992106120137154172192232276326378CP/IP120505 1057 105*********13788105**********HYB2258710912029560272 105****HYB LB275074002 1056 105********HYB UB23614926122311568652 105****Figure 6: Experimental results three different algorithms still-life problem. Timesseconds.CCassignment. reversed assignment xCn = vn , xn1 = vn1 , . . . , xi = vi equivalent duevertical reflection symmetry. Thus, already considered, algorithmbacktrack. implementation uses tricks othersreport would require much lower level description algorithms.5. Experimental ResultsFigure 6 shows empirical performance hybrid algorithm. first column containsproblem size. second column contains optimal value number deadcells (in parenthesis corresponding number living cells). third column containsoptimal value symmetrical problem SSL(n), obtained executing BE.observed SSL(n) provides tight upper bounds SL(n). fourth columnreports time obtained CP/IP algorithm (Bosch & Trick, 2002). fifthcolumn reports times obtained BE. sixth column contains times obtainedhybrid algorithm HYB. seen, performance HYB spectacular.n = 14 n = 15 instances, require several days CPU, solved HYBseconds. Instances n = 18 solved less one hour. largest instancesolve n = 20, requires two days CPU (Figure 7 shows optimaln = 19 n = 20 still-lifes). Regarding space, computer handle executionsHYB n = 22. However, neither n = 21 n = 22 instance could solvedwithin week CPU. may seem solving n = 20 instance petty progressrespect previous results problem. clearly case. search space22n = 15 n = 20 instances size 215 = 2225 220 = 2400 , respectively. Thus,able solve problem search space 2175 times larger before.Since scales regularly, accurately predict would require 4000 Gbmemory 7 centuries solve n = 20 instance.435fiLarrosa, Morancho & NisoFigure 7: Maximum density still-lifes n = 19 n = 20.Since HYB combines several techniques, interesting assess impactone. seventh column reports times obtained HYB without using mini-bucketsinformation lower bound. seen, algorithm still better plain BE,performance dramatically affected. information gathered preprocessimproves quality lower bound anticipates pruning. Finally, eighth columnreports times obtained HYB without upper bound initialized SSL(n).case see importance technique quite limited. reasonHYB, even bad initial upper bound, finds optimum rapidly and,moment, quality initial upper bound becomes irrelevant.6. Extension DomainsSL(n) problem well defined structure, hybrid algorithmproposed makes ad hoc exploitation it. easy find right variablesinstantiate eliminate. also easy find variable order mini bucketsproduces good quality lower bounds. natural question whether possible applysimilar ideas well structured problems. answer often possible,although need rely naive consequently less efficient exploitationproblems structure. Section support claim reporting additional experimental results different benchmarks. particular, consider spot5 DIMACSinstances. Spot5 instances optimization problems taken scheduling earthobservation satellite (Bensana, Lemaitre, & Verfaillie, 1999). DIMACS benchmark contains SAT instances several domain. Since concerned optimization tasks,selected unsatisfiable instances solved Max-SAT task (i.e, givenunsatisfiable SAT instance, find maximum number clauses simultaneouslysatisfied), modeled WCSP (de Givry, Larrosa, Meseguer, & Schiex, 2003).consider aim instances (artificially generated random 3-SAT), pret (graph coloring), ssabf (circuit fault analysis).Figure 8 shows constraint graph one instance domain, visualizedLEDA graph editor. observed graphs obvious pattern436fiOn practical use variable eliminationFigure 8: Constraint graph four WCSP instances. top-left corner, clockwise,aim-100-1-6-no-1, pret60-25, ssa0432-003 Spot5-404.exploited. Thus, use variable elimination techniques naive way.solve problems generic WCSP solver toolbar7 (TB). performs depthfirst branch-and-bound search enhanced general-purpose dynamic variablevalue ordering heuristics. modified toolbar combine search variable eliminationfollows: arbitrary subproblem, every variable degree less 3 eliminated.variables degree larger equal 3, unassigned variableheuristically selected domain values heuristically ordered sequentiallyinstantiated. process recursively applied subproblems. Notegeneric version HYB algorithm decision variablesinstantiated variables eliminated left heuristic, instead establishing7. Available http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/SoftCSP.437fiLarrosa, Morancho & Nisohand. refer implementation TBHY B . Toolbar offers varietylower bounds based different forms local consistency (Larrosa & Schiex, 2003).One them, directional arc consistency (DAC*), essentially equivalent mini-bucketssize 2 and, therefore, similar spirit lower bound computed HYB. However,unlike HYB mini-buckets executed pre-process, toolbar executesDAC* every search state, subject current subproblem. shown Kask(2000) approach generally efficient. main difference respectHYB, toolbar executes DAC* subject arbitrary variable ordering (in HYBgood order identified problem structure). lower bounds availabletoolbar node consistency (NC*) weaker DAC*, full directionalarc consistency (FDAC*) seen (stronger) refinement DAC*.F DACBexperimented four algorithms: TBN C , TBDAC , TBDACHY B TBHY B ,denotes algorithm lower bound B.spot5 instances difficult toolbar. Therefore, decreased sizeletting toolbar make sequence k greedy assignments driven default variablevalue ordering heuristics. result subproblem k less variables.following, Ik denotes instance k variables greedily assigned toolbardefault parameters.Table 9 reports result experiments. first column indicates instancessubsequent columns indicate CPU time (in seconds) required different algorithms. time limit 3600 seconds set execution. observedtoolbar weakest lower bound (TBN C ) usually inefficient alternative.cannot solve spot5 instances also fails several aim ssa instances.toolbar enhanced mini buckets lower bound (TBDAC ) spot5 problemssolved. domains, new lower bound produce significant effect. add variable elimination (TBDACHY B ) problems solved.general, clear speed-up. worst improvements pret instancestime divided factor 2 best ones obtained spot5 50340ssa7552-158 instances solved instantly. Typical speed-ups range 5 10.DAC ) limitedFinally, observe addition stronger lower bound (TBFHYBeffect problems. execution instance ssa7552-038 clearly accelerated.Therefore, experiments conclude main techniques usedsolve still-life problem also successfully applied domains.7. Conclusionspaper studied applicability variable elimination problemfinding still-lifes. Finding still-lifes challenging problem developing new solvingtechniques interesting task per se. Thus, first contribution paperobservation plain variable elimination (i.e, BE) competitive practice providestime complexity exponentially better search-based approaches. Besides, developed algorithm able solve n = 20 instance,clearly improved previous results. second contribution paperdeeper insight. algorithm uses recent techniques based variable elimination.Since techniques little known rarely applied constraints community,438fiOn practical use variable eliminationProblemSpot5 4040Spot5 408100Spot5 412200Spot5 414260Spot5 50340Spot5 505120Spot5 507200Spot5 509240aim-100-1-6-no-1aim-100-1-6-no-2aim-100-1-6-no-3aim-100-1-6-no-4aim-100-2-0-no-1aim-100-2-0-no-2aim-100-2-0-no-3aim-100-2-0-no-4bf0432-007pret60-25pret60-40ssa0432-003ssa2670-141ssa7552-038ssa7552-158BN C251611911222216211011022-BDAC242314223153354633532046842007931850159912012022-DACBHYB40484722108458166166570719602716830479319738120649485749200F DACBHYB4043421390844212114275711627237558328527860013125656576721Figure 9: Experimental results WCSP instances four different algorithms.column reports CPU time seconds. Symbol - indicates time limit3600 seconds reached.results presented paper add new evidence potential. also shownvariable elimination used beyond academic still-life problem providingexperimental results unstructured realistic problems different domains.Acknowledgmentsauthors grateful Barbara Smith, Neil Yorke-Smith anonymous reviewersuseful comments different stages work reported article. MartiSanchez kindly made plots Figure 8. research funded SpanishCICYT project TIC2002-04470-C03-01.ReferencesBensana, E., Lemaitre, M., & Verfaillie, G. (1999). Earth observation satellite management.Constraints, 4(3), 293299.Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press.439fiLarrosa, Morancho & NisoBistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint satisfactionoptimization. Journal ACM, 44 (2), 201236.Bosch, R., & Trick, M. (2002). Constraint programming hybrid formulations threelife designs. Proceedings International Workshop Integration AITechniques Constraint Programming Combinatorial Optimization Problems,CP-AI-OR02, pp. 7791.Cabon, B., de Givry, S., Lobjois, L., Schiex, T., & Warners, J. (1999). Radio link frequencyassignment. Constraints, 4, 7989.de Givry, S., Larrosa, J., Meseguer, P., & Schiex, T. (2003). Solving max-sat weightedcsp. Proc. 9th CP, pp. 363376, Kinsale, Ireland. LNCS 2833. SpringerVerlag.Dechter, R. (1999). Bucket elimination: unifying framework reasoning. ArtificialIntelligence, 113, 4185.Dechter, R., & Pearl, J. (1989). Tree clustering constraint networks. Artificial Intelligence, 38, 353366.Dechter, R., & Fatah, Y. E. (2001). Topological parameters time-space tradeoff. ArtificialIntelligence, 125 (12), 93118.Dechter, R., & Rish, I. (2003). Mini-buckets: general scheme bounded inference.Journal ACM, 50 (2), 107153.Gardner, M. (1970). fantastic combinations john conways new solitary game. Scientific American, 223, 120123.Kask, K. (2000). New search heuristics max-csp. Proc. 6th CP, pp. 262277,Singapore. LNCS 1894. Springer Verlag.Kask, K., & Dechter, R. (2001). general scheme automatic generation searchheuristics specification dependencies. Artificial Intelligence, 129, 91131.Larrosa, J., & Dechter, R. (2003). Boosting search variable elimination constraintoptimization constraint satisfaction problems. Constraints, 8 (3), 303326.Larrosa, J., & Schiex, T. (2003). quest best form local consistencyweighted csp. Proc. 18th IJCAI, Acapulco, Mexico.Pearl, J. (1988). Probabilistic Inference Intelligent Systems. Networks Plausible Inference. Morgan Kaufmann, San Mateo, CA.Sandholm, T. (1999). algorithm optimal winner determination combinatorialauctions. IJCAI-99, pp. 542547.Smith, B. (2002). dual graph translation problem life. Proc. CP-2002, pp.01, Ithaca, USA. LNCS. Springer Verlag.440fiJournal Artificial Intelligence Research 23 (2005) 299-330Submitted 07/04; published 03/05Combining Knowledge- Corpus-basedWord-Sense-Disambiguation MethodsAndres Montoyomontoyo@dlsi.ua.esDept. Software Computing SystemsUniversity Alicante, SpainArmando Suarezarmando@dlsi.ua.esDept. Software Computing SystemsUniversity Alicante, SpainGerman Rigaurigau@si.ehu.esIXA Research GroupComputer Science DepartmentBasque Country University, DonostiaManuel Palomarmpalomar@dlsi.ua.esDept. Software Computing SystemsUniversity Alicante, SpainAbstractpaper concentrate resolution lexical ambiguity arisesgiven word several different meanings. specific task commonly referredword sense disambiguation (WSD). task WSD consists assigning correctsense words using electronic dictionary source word definitions. presenttwo WSD methods based two main methodological approaches research area:knowledge-based method corpus-based method. hypothesis word-sensedisambiguation requires several knowledge sources order solve semantic ambiguitywords. sources different kinds example, syntagmatic, paradigmatic statistical information. approach combines various sources knowledge,combinations two WSD methods mentioned above. Mainly, paper concentrates combine methods sources information order achievegood results disambiguation. Finally, paper presents comprehensive studyexperimental work evaluation methods combinations.1. IntroductionKnowledge technologies aim provide meaning petabytes information contentmultilingual societies generate near future. Specifically, wide rangeadvanced techniques required progressively automate knowledge lifecycle.include analyzing, automatically representing managing, high-level meaningslarge collections content data. However, able build next generationintelligent open-domain knowledge application systems, need deal conceptsrather words.c2005AI Access Foundation. rights reserved.fiMontoyo, Suarez, Rigau, & Palomar1.1 Dealing Word Sensesnatural language processing (NLP), word sense disambiguation (WSD) definedtask assigning appropriate meaning (sense) given word text discourse.example, consider following three sentences:1. Many cruise missiles fallen Baghdad.2. Music sales fall 15% year.3. U.S. officials expected Basra fall early.system tries determine meanings three sentences needrepresent somehow three different senses verb fall. first sentence, missileslaunched Baghdad. second sentence, sales decrease,third city surrender early. WordNet 2.0 (Miller, 1995; Fellbaum, 1998)1 containsthirty-two different senses verb fall well twelve different senses nounfall. Note also first third sentence belong same, military domain,use verb fall two different meanings.Thus, WSD system must able assign correct sense given word,examples, fall, depending context word occurs. examplesentences, are, respectively, senses 1, 2 9, listed below.1. falldescend free fall influence gravity (The branch felltree; unfortunate hiker fell crevasse).2. descend, fall, go down, come downmove downward necessarilyway (The temperature going down; barometer falling; Real estateprices coming down).9. fallbe captured (The cities fell enemy).Providing innovative technology solve problem one main challengeslanguage engineering access advanced knowledge technology systems.1.2 Word-Sense DisambiguationWord sense ambiguity central problem many established Human Language Technology applications (e.g., machine translation, information extraction, question answering,information retrieval, text classification, text summarization) (Ide & Veronis, 1998).also case associated subtasks (e.g., reference resolution, acquisition subcategorization patterns, parsing, and, obviously, semantic interpretation). reason,many international research groups working WSD, using wide range approaches.However, date, large-scale, broad-coverage, accurate WSD system built (Snyder & Palmer, 2004). current state-of-the-art accuracy range 6070%, WSDone important open problems NLP.1. http://www.cogsci.princeton.edu/wn/300fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsEven though techniques WSD usually presented stand-alonetechniques, belief, following McRoy (1992), full-fledged lexical ambiguityresolution require integrate several information sources techniques.paper, present two complementary WSD methods based two differentmethodological approaches, knowledge-based corpus-based methods, well severalmethods combine hybrid approaches.knowledge-based method disambiguates nouns matching context information prescribed knowledge source. WordNet used combines characteristics dictionary structured semantic network, providing definitionsdifferent senses English words defining groups synonymous wordsmeans synsets, represent distinct lexical concepts. WordNet also organizes wordsconceptual structure representing number semantic relationships (hyponymy,hypernymy, meronymy, etc.) among synsets.corpus-based method implements supervised machine-learning (ML) algorithmlearns annotated sense examples. corpus-based system usually representslinguistic information context sentence (e.g., usage ambiguous word)form feature vectors. features may distinct nature: word collocations,part-of-speech labels, keywords, topic domain information, grammatical relationships,etc. Based two approaches, main objectives work presented paperare:study performance different mechanisms combining information sourcesusing knowledge-based corpus-based WSD methods together.show knowledge-based method help corpus-based method betterperform disambiguation process vice versa.show combination approaches outperforms methodstaken individually, demonstrating two approaches play complementaryroles.Finally, show approaches applied several languages. particular, perform several experiments Spanish English.following section summary background word sense disambiguationpresented. Sections 2.1 2.2 describe knowledge-based corpus-based systemsused work. Section 3 describes two WSD methods: specification marks methodmaximum entropy-based method. Section 4 presents evaluation resultsusing different system combinations. Finally, conclusions presented, alongbrief discussion work progress.2. Background WSDSince 1950s, many approaches proposed assigning senses wordscontext, although early attempts served models toy systems. Currently,two main methodological approaches area: knowledge-based corpus-basedmethods. Knowledge-based methods use external knowledge resources, define explicit301fiMontoyo, Suarez, Rigau, & Palomarsense distinctions assigning correct sense word context. Corpus-based methodsuse machine-learning techniques induce models word usages large collectionstext examples. knowledge-based corpus-based methods present different benefitsdrawbacks.2.1 Knowledge-based WSDWork WSD reached turning point 1980s 1990s large-scale lexicalresources dictionaries, thesauri, corpora became widely available. workdone earlier WSD theoretically interesting practical extremely limiteddomains. Since Lesk (1986), many researchers used machine-readable dictionaries(MRDs) structured source lexical knowledge deal WSD. approaches,exploiting knowledge contained dictionaries, mainly seek avoid needlarge amounts training material. Agirre Martinez (2001b) distinguish ten differenttypes information useful WSD. located MRDs,include part speech, semantic word associations, syntactic cues, selectional preferences,frequency senses, among others.general, WSD techniques using pre-existing structured lexical knowledge resourcesdiffer in:lexical resource used (monolingual and/or bilingual MRDs, thesauri, lexical knowledge base, etc.);information contained resource, exploited method;property used relate words senses.Lesk (1986) proposes method guessing correct word sense counting wordoverlaps dictionary definitions words context ambiguous word.Cowie et al. (1992) uses simulated annealing technique overcoming combinatorialexplosion Lesk method. Wilks et al. (1993) use co-occurrence data extractedMRD construct word-context vectors, thus word-sense vectors, perform large setexperiments test relatedness functions words vector-similarity functions.approaches measure relatedness words, taking reference structured semantic net. Thus, Sussna (1993) employs notion conceptual distancenetwork nodes order improve precision document indexing. Agirre Rigau(1996) present method resolution lexical ambiguity nouns using WordNet noun taxonomy notion conceptual density. Rigau et al. (1997) combineset knowledge-based algorithms accurately disambiguate definitions MRDs. Mihalcea Moldovan (1999) suggest method attempts disambiguate nouns,verbs, adverbs, adjectives given text referring senses provided WordNet. Magnini et al. (2002) explore role domain information WSD using WordNetdomains (Magnini & Strapparava, 2000); case, underlying hypothesisinformation provided domain labels offers natural way establish semantic relationsamong word senses, profitably used disambiguation process.Although knowledge-based systems proven ready-to-use scalabletools all-words WSD require sense-annotated data (Montoyo et al.,302fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation Methods2001), general, supervised, corpus-based algorithms obtained better precisionknowledge-based ones.2.2 Corpus-based WSDlast fifteen years, empirical statistical approaches significantly increased impact NLP. increasing interest algorithms techniques comemachine-learning (ML) community since applied large varietyNLP tasks remarkable success. reader find excellent introduction ML,relation NLP, articles Mitchell (1997), Manning Schutze (1999),Cardie Mooney (1999), respectively. types NLP problems initially addressedstatistical machine-learning techniques language- ambiguity resolution,correct interpretation selected among set alternativesparticular context (e.g., word-choice selection speech recognition machine translation,part-of-speech tagging, word-sense disambiguation, co-reference resolution, etc.).techniques particularly adequate NLP regarded classificationproblems, studied extensively ML community. Regarding automaticWSD, one successful approaches last ten years supervised learningexamples, statistical ML classification models induced semantically annotated corpora. Generally, supervised systems obtained better resultsunsupervised ones, conclusion based experimental work international competitions2 . approach uses semantically annotated corpora train machinelearning(ML) algorithms decide word sense choose contexts. wordsannotated corpora tagged manually using semantic classes taken particularlexical semantic resource (most commonly WordNet). Many standard ML techniquestried, including Bayesian learning (Bruce & Wiebe, 1994), Maximum Entropy (Suarez& Palomar, 2002a), exemplar-based learning (Ng, 1997; Hoste et al., 2002), decision lists(Yarowsky, 1994; Agirre & Martinez, 2001a), neural networks (Towell & Voorhees, 1998),and, recently, margin-based classifiers like boosting (Escudero et al., 2000) supportvector machines (Cabezas et al., 2001).Corpus-based methods called supervised learn previously senseannotated data, therefore usually require large amount human interventionannotate training data (Ng, 1997). Although several attempts made (e.g.,Leackock et al., 1998; Mihalcea & Moldovan, 1999; Cuadros et al., 2004), knowledgeacquisition bottleneck (too many languages, many words, many senses, manyexamples per sense) still open problem poses serious challenges supervisedlearning approach WSD.3. WSD Methodssection present two WSD methods based, respectively, two main methodological approaches outlined above: specification marks method (SM) (Montoyo & Palomar, 2001) knowledge-based method, maximum entropy-based method (ME)(Suarez & Palomar, 2002b) corpus-based method. selected methods seen2. http://www.senseval.org303fiMontoyo, Suarez, Rigau, & Palomarrepresentatives methodological approaches. specification marks methodinspired conceptual density method (Agirre & Rigau, 1996) maximumentropy method also used WSD systems (Dang et al., 2002).3.1 Specification Marks Methodunderlying hypothesis knowledge base method higher similaritytwo words, larger amount information shared two concepts.case, information commonly shared several concepts indicatedspecific concept subsumes taxonomy.input WSD module group nouns W = {w1 , w2 , ..., wn } context. word wi sought WordNet, associated set possible sensesSi = {Si1 , Si2 , ..., Sin }, sense set concepts IS-A taxonomy (hypernymy/hyponymy relations). First, method obtains common conceptsenses words form context. concept marked initial specification mark (ISM). initial specification mark resolve ambiguityword, descend WordNet hierarchy, one level another, assigningnew specification marks. specification mark, number concepts containedwithin subhierarchy counted. sense corresponds specificationmark highest number words one chosen sense disambiguated withingiven context. Figure 1 illustrates graphically word plant, four differentsenses, disambiguated context also words tree, perennial, leaf.seen initial specification mark resolve lexical ambiguity, sinceword plant appears two subhierarchies different senses. specification markidentified {plant#2, flora#2}, however, contains highest number words (three)context therefore one chosen resolve sense two wordplant. words tree perennial also disambiguated, choosing senseone. word leaf appear subhierarchy specification mark {plant#2,flora#2}, therefore word disambiguated. words beyondscope disambiguation algorithm. left aside processedcomplementary set heuristics (see section 3.1.2).3.1.1 Disambiguation Algorithmsection, formally describe SM algorithm consists following fivesteps:Step 1:nouns extracted given context. nouns constitute input context,Context = {w1 , w2 , ..., wn }. example, Context = {plant, tree, perennial, leaf }.Step 2:noun wi context, possible senses Si = {Si1 , Si2 , ..., Sin }obtained WordNet. sense Sij , hypernym chain obtained storedorder stacks. example, Table 1 shows hypernyms synsetssense word Plant.Step 3:sense appearing stacks, method associates list subsumed senses304fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsInicialSpecificationMark (ISM){entity#1}{object#1}SM{life form#1}SM{natural object#1}{plant#2, flora#2} (*){substance#1}{part#4}{artifact#1}{person#1}{material#1}{section#4}{plant part#1}{perennial#1}{vascular plant#1}{Structure#1}{paper#1}{entertainer#1}{woody plant#1}{plant organ#1}{building complex#1}{performer#1}{leaf#3}{sheet#2}{leaf#1}{leaf#2}{tree#1}{plant#1}{actor#1}{plant#4}Figure 1: Specification Marksplant#1building complex#1structure#1artifact#1object#1entity#1plant#2life form#1entity#1plant#3contrivance#3scheme#1plan action#1plan#1idea#1content#5cognition#1psychological feature#1plant#4actor#1performer#1entertainer#1person#1life form#1entity#1Table 1: Hypernyms synsets plantcontext (see Figure 2, illustrates list subsumed senses plant#1plant#2 ).Step 4:Beginning initial specification marks (the top synsets), program descendsrecursively hierarchy, one level another, assigning specification mark number context words subsumed.Figure 3 shows word counts plant#1 plant#4 located within specification mark entity#1, ..., life form#1, flora#2. entity#1 specification mark,senses #1, #2, #4 maximal word counts (4). Therefore,possible disambiguate word plant using entity#1 specification mark,necessary go one level hyponym hierarchy changingspecification mark. Choosing specification mark life form#1, senses #2 #4plant maximal word counts (3). Finally, possible disambiguateword plant sense #2 using {plant#2, flora#2} specification mark,sense higher word density (in case, 3).305fiMontoyo, Suarez, Rigau, & PalomarPLANT:PLANT#1:plant#1 plant#1building complex#1 plant#1structure#1 plant#1artifact#1 plant#1object#1 plant#1, leaf#1, leaf#2, leaf#3entity#1 plant#1, plant#2, plant#4, tree#1, perennial#1, leaf#1, leaf#2, leaf#3PLANT#2:plant#2 plant#2, tree#1, perennial#1life form#1 plant#2, plant#4, tree#1, perennial#1entity#1 plant#1, plant#2, plant#4, tree#1, perennial#1, leaf#1, leaf#2, leaf#3Figure 2: Data Structure Senses Word PlantPLANTlocated within specification mark {entity#1}PLANT#1 : 4 (plant, tree, perennial, leaf)PLANT#2 : 4 (plant, tree, perennial, leaf)PLANT#3 : 1 (plant)PLANT#4 : 4 (plant, tree, perennial, leaf)located within specification mark {life form#1}PLANT#1 : 1 (plant)PLANT#2 : 3 (plant, tree, perennial)PLANT#3 : 1 (plant)PLANT#4 : 3 (plant, tree, perennial)located within specification mark {plant #2, flora#2}PLANT#1 : 1 (plant)PLANT#2 : 3 (plant, tree, perennial)PLANT#3 : 1 (plant)PLANT#4 : 1 (plant)Figure 3: Word Counts Four Senses Word PlantStep 5:step, method selects word sense(s) greatest number wordscounted Step 4. one sense, one obviously chosen.one sense, repeat Step 4, moving level withintaxonomy single sense obtained program reach leaf specificationmark. Figure 3 shows word counts sense plant (#1 #4) locatedwithin specification mark entity#1, ..., life form#1, flora#2. word cannotdisambiguated way, necessary continue disambiguationprocess applying complementary set heuristics.3.1.2 Heuristicsspecification marks method combined set five knowledge-based heuristics:hypernym/hyponym, definition, gloss hypernym/hyponym, common specification mark,domain heuristics. short description methods provided below.306fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation Methods3.1.3 Hypernym/Hyponym Heuristicheuristic solves ambiguity words explicitly related WordNet(i.e., leaf directly related plant, rather follows hypernym chain plus PARTOF relation). hypernyms/hyponyms ambiguous word checked, lookingsynsets compounds match word context.synset hypernym/hyponym chain weighted accordance depth withinsubhierarchy. sense greatest weight chosen. Figure 4 shows that,leaf#1 hyponym plant organ#1 disambiguated (obtain greatest weight,P45levelweight(leaf #1) = depthi=1 ( total levels ) = ( 6 ) + ( 6 ) = 1.5) plant contained withincontext leaf.Context: plant, tree, leaf, perennialWord non disambiguated: leaf.Senses: leaf#1, leaf#2, leaf#3.leaf#1=> entity, something=> object, physical object=> natural object=> plant part=> plant organ=> leaf#1, leafage, foliageLevel 1Level 2Level 3Level 4Level 5Level 6Figure 4: Application Hypernym Heuristic3.1.4 Definition Heuristiccase, glosses synsets ambiguous word checked lookingcontain words context. match increases synset count one.sense greatest count chosen. Figure 5 shows exampleheuristic. sense sister#1 chosen, greatest weight.Context: person, sister, musician.Words non disambiguated: sister,musician.Senses: sister#1, sister#2, sister#3 sister#4.sister#1 Weight = 21. sister, sis -- (a female person parents another person; "my sister marriedmusician")sister#3 Weight = 13. sister -- (a female person fellow member (of sorority labor union group);"none sisters would betray her")Figure 5: Application Definition Heuristic307fiMontoyo, Suarez, Rigau, & Palomar3.1.5 Gloss Hypernym/Hyponym Heuristicmethod extends previously defined hypernym/hyponym heuristic using glosseshypernym/hyponym synsets ambiguous word. disambiguate given word,glosses hypernym/hyponym synsets checked looking words occurringcontext. Coincidences counted. before, synset greatest countchosen. Figure 6 shows example heuristic. sense plane#1 chosen,greatest weight.Context: plane, airWords non disambiguated: planeSenses: plane#1, plane#2, plane#3, plane#4, plane#5.Plane#1: Weight = 1airplane, aeroplane, plane -- (an aircraft fixed wing powered propellers jets; "theflight delayed due trouble airplane")=> aircraft -- (a vehicle fly)=> craft -- (a vehicle designed navigation water air outer space)=> vehicle -- (a conveyance transports people objects)=> conveyance, transport -- (something serves means transportation)=> instrumentality, instrumentation -- (an artifact (or system artifacts)instrumental accomplishing end)=> artifact, artefact -- (a man-made object)=> object, physical object -- (a physical (tangible visible) entity; "it fullrackets, balls objects")=> entity, something -- (anything existence (living nonliving))Figure 6: Application Gloss Hypernym Heuristic3.1.6 Common Specification Mark Heuristiccases, senses words disambiguated closediffer subtle differences nuances. Common Specification Mark heuristic reduceambiguity word without trying provide full disambiguation. Thus, selectspecification mark common senses context words, reporting sensesinstead choosing single sense among them. illustrate heuristic, considerFigure 7. example, word month able discriminate completely amongfour senses word year. However, case, presence word monthhelp select two possible senses word year selecting time period, periodcommon specification mark. specification mark represents specific commonsynset particular set words. Therefore, heuristic selects sense month#1senses year#1 year#2 instead attempting choose single sense leavingcompletely ambiguous.3.1.7 Domain WSD Heuristicheuristic uses derived resource, relevant domains (Montoyo et al., 2003),obtained combining WordNet glosses WordNet Domains (Magnini & Strap308fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsContext: year, month. Words non disambiguated: year. Senses: year#1, year#2, year#3, year#4.year#1:year#2:month#1:=> abstraction=> abstraction=> measure, quantity=> measure, quantity=> time period, period=> time period, period=> year#1, twelvemonth=> year#2=> abstraction=> measure, quantity=> time period, period=> month#1Figure 7: Example Common Specification Mark Heuristicparava, 2000)3 . WordNet Domains establish semantic relation word sensesgrouping semantic domain (Sports, Medicine, etc.). word bank,example, ten senses WordNet 2.0, three them, bank#1, bank#3bank#6 grouped domain label, Economy, whereas bank#2bank#7 grouped domain labels Geography Geology. domain labels selected set 165 labels hierarchically organized. way, domainconnects words belong different subhierarchies partof-speech.Relevant domains lexicon derived WordNet glosses using WordNet Domains. fact, use WordNet corpus categorized domain labels.English word appearing gloses WordNet, obtain list representative domain labels. relevance obtained weighting possible labelAssociation Ratio formula (AR), w word domain.AR(w|D) = P (w|D) logP (w|D)P (w)(1)list also considered weighted vector (or point multidimensionalspace). Using word vectors Relevant domains, derive new vectorsrepresent sets wordsfor instance, contexts glosses. comparesimilarity given context possible senses polysemous wordusing instance cosine function.Figure 8 shows example disambiguating word genotype following text:number ways chromosome structure change,detrimentally change genotype phenotype organism. First, glossesword disambiguated context postagged analyzed morphologically.Second, build context vector (CV) combines one structure relevant representative domains related words text disambiguated.Third, way, build sense vectors (SV) group relevantrepresentative domains gloss associated one word senses.example, genotype#1 (a group organisms sharing specific genetic constitution)genotype#2 (the particular alleles specified loci present organism). Finally,order select appropriate sense, made comparison sense vectorscontext vector, select senses approximate context vector.3. http://wndomains.itc.it/309fiMontoyo, Suarez, Rigau, & Palomarexample, show sense vector sense genotype#1 select genotype#1sense, cosine higher.Bio logEcologyBotanyZoologyCV = AnatomyPhysiologyChemistryGeologyMeteorology...0.001028370.004028553.20408e - 061.77959e - 051.29592e - 050.0002265310.0001798571.66327e - 050.00371308...AREcologyBiologyBowlingSV = ArchaeologySociologyAlimentationLinguistics...AR0.0847780.0476270.0196870.0164510.0142510.0065100.005297...Sense vector genotype#1.Context vectorSelected sensegenotype#1 = 0.00804111genotype#2 = 0.00340548Figure 8: Example Domain WSD HeuristicDefining heuristic knowledge-based corpus-based seen controversial heuristic uses WordNet gloses (and WordNet Domains) corpusderive relevant domains. is, using corpus techniques WordNet. However,WordNet Domains constructed semi-automatically (prescribed) following hierarchyWordNet.3.1.8 Evaluation Specification Marks MethodObviously, also use different strategies combine set knowledge-based heuristics. instance, heuristics described previous section appliedorder passing next heuristic remaining ambiguity previous heuristicsable solve.order evaluate performance knowledge-based heuristics previously defined, used SemCor collection (Miller et al., 1993), content wordsannotated appropriate WordNet sense.In case, used windowfifteen nouns (seven context nouns target noun).results obtained specification marks method using heuristics applied one one shown Table 2. table shows results polysemous nounsonly, polysemous monosemous nouns combined.310fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsHeuristicsPrecision Recall CoveragePolysemic monosemic nouns0.5530.5220.943polysemic nouns0.3770.3110.943Table 2: Results Using Heuristics Applied Order SemCorresults obtained heuristics applied independently shown Table 3.shown, heuristics perform differently, providing different precision/recall figures.HeuristicsPrecisionRecallCoverageMono+Poly Polysemic Mono+Poly Polysemic Mono+Poly PolysemicSpec. Mark Method0.3830.3000.3410.2920.9750.948Hypernym0.5630.4200.4470.3130.7950.745Definition0.4800.3000.3630.2090.7580.699Hyponym0.5560.3930.4360.2850.7840.726Gloss hypernym0.5550.4120.4500.3160.8110.7640.6170.4810.4940.3580.7980.745Gloss hyponymCommon specification0.5650.4230.4430.3100.7840.732Domain WSD0.5850.4530.4830.3300.8940.832Table 3: Results Using Heuristics Applied IndependentlyAnother possibility combine heuristics using majority voting schema (Rigauet al., 1997). simple schema, heuristic provides vote, method selectssynset obtains votes. results shown Table 4 illustrateheuristics working independently, method achieves 39.1% recall polysemousnouns (with full coverage), represents improvement 8 percentual pointsmethod heuristics applied order (one one).PrecisionRecallMono+Poly Polysemic Mono+Poly PolysemicVoting heuristics0.5670.4360.5460.391Table 4: Results using majority voting SemCoralso show Table 5 results domain heuristic applied Englishall-words task Senseval-2. table, polysemy reduction caused domainclustering profitably help WSD. Since domains coarser synsets, word domaindisambiguation (WDD) (Magnini & Strapparava, 2000) obtain better results WSD.goal perform preliminary domain disambiguation order provide informedsearchspace reduction.3.1.9 Comparison Knowledge-based Methodssection compare three different knowledge-based methods: conceptual density(Agirre & Rigau, 1996), variant conceptual density algorithm (Fernandez-Amoroset al., 2001); Lesk method (Lesk, 1986) ; specification marks method.311fiMontoyo, Suarez, Rigau, & PalomarLevel WSD Precision RecallSense0.440.32Domain0.540.43Table 5: Results Use Domain WSD HeuristicTable 6 shows recall results three methods applied entire SemCorcollection. best result achieved 39.1% recall. important improvementrespect methods, results still far frequent sense heuristic. Obviously, none knowledge-based techniques heuristics presentedsufficient, isolation, perform accurate WSD. However, empirically demonstrated simple combination knowledge-based heuristics lead improvementsWSD process.WSD MethodRecallSM Voting Heuristics0.391UNED Method0.313SM Cascade Heuristics 0.311Lesk0.274Conceptual Density0.220Table 6: Recall results using three different knowledgebased WSD methods3.2 Maximum Entropy-based MethodMaximum Entropy modeling provides framework integrating information classification many heterogeneous information sources (Manning & Schutze, 1999; Bergeret al., 1996). probability models successfully applied NLP tasks,POS tagging sentence-boundary detection (Ratnaparkhi, 1998).WSD method used work based conditional models.implemented using supervised learning method consists building word-sense classifiers using semantically annotated corpus. classifier obtained meanstechnique consists set parameters coefficients estimated using optimization procedure. coefficient associated one feature observed trainingdata. goal obtain probability distribution maximizes entropythatis, maximum ignorance assumed nothing apart training data considered.One advantage using framework even knowledge-poor features may applied accurately; framework thus allows virtually unrestricted ability representproblem-specific knowledge form features (Ratnaparkhi, 1998).Let us assume set contexts X set classes C. function cl : X C choosesclass c highest conditional probability context x: cl(x) = arg maxc p(c|x).feature calculated function associated specific class c0 ,takes form equation (2), cp(x) represents observable characteristic312fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation Methodscontext4 . conditional probability p(c|x) defined equation (3),parameter weight feature i, K number features defined, Z(x)normalization factor ensures sum conditional probabilitiescontext equal 1.f (x, c) =(1 c0 = c cp(x) = true0 otherwiseK1f (x,c)p(c|x) =Z(x) i=1(2)(3)learning module produces classifiers word using corpus syntactically semantically annotated. module processes learning corpus orderdefine functions apprise linguistic features context.example, consider want build classifier noun interest usingPOS label previous word feature also following threeexamples training corpus:... widespread interest#1 ...... best interest#5 ...... persons expressing interest#1 ...learning module performs sequential processing corpus, lookingpairs <POS-label, sense>. Then, following pairs used define three functions(each context vector composed three features).<adjective,#1><adjective,#5><verb,#1>define another type feature merging POS occurrences sense:< {adjective,verb},#1><adjective,#5>form defining pairs means reduction feature space information(of kind linguistic data, e.g., POS label position -1) sense containedone feature. Obviously, form feature function 2 must adapted Equation4. Thus,f(c0 ,i) (x, c) =(W(c0 ) = {data sense c0 }(4)1 c0 = c CP (x) W(c0 )0 otherwise4. approach limited binary features, optimization procedure used estimationparameters, Generalized Iterative Scaling procedure, uses kind features.313fiMontoyo, Suarez, Rigau, & Palomarrefer feature function expressed Equation 4 collapsed features.previous Equation 2 call non-collapsed features. two feature definitionscomplementary used together learning phase.Due nature disambiguation task, number times featuregenerated first type function (non-collapsed) activated low,feature vectors large number null values. new function drastically reducesnumber features, minimal degradation evaluation results. way,new features incorporated learning process, compensating lossaccuracy.Therefore, classification module carries disambiguation new contexts usingpreviously stored classification functions. enough informationspecific context, several senses may achieve maximum probabilitythus classification cannot done properly. cases, frequent sensecorpus assigned. However, heuristic necessary minimum numbercontexts set linguistic attributes processed small.3.2.1 Description Featuresset features defined training system described Figure 9based features described Ng Lee (1996) Escudero et al. (2000).features represent words, collocations, POS tags local context. collapsednon-collapsed functions used.0: word form target words: words positions 1, 2, 3p: POS-tags words positions 1, 2, 3b: lemmas collocations positions (2, 1), (1, +1), (+1, +2)c: collocations positions (2, 1), (1, +1), (+1, +2)k m: lemmas nouns position context, occurring least m% times senser : grammatical relation ambiguous word: word ambiguous word dependsm: multi-word identified parserL: lemmas content-words positions 1, 2, 3 (collapsed definition)W : content-words positions 1, 2, 3 (collapsed definition)S, B, C, P, : collapsed versions (see Equation 4)Figure 9: Features Used Training SystemActually, item Figure 9 groups several sets features. majoritydepend nearest words (e.g., comprises possible features defined wordsoccurring sample positions w3 , w2 , w1 , w+1 , w+2 , w+3 related ambiguous word). Types nominated capital letters based collapsed functionform; is, features simply recognize attribute belonging training data.Keyword features (km) inspired Ng Lee work. Noun filtering done usingfrequency information nouns co-occurring particular sense. example, let us314fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation Methodssuppose = 10 set 100 examples interest#4 : noun bank found 10 timesposition, feature defined.Moreover, new features also defined using grammatical properties: relationship features (r) refer grammatical relationship ambiguous word(subject, object, complement, ...) dependency features (d D) extract wordrelated ambiguous one dependency parse tree.3.2.2 Evaluation Maximum Entropy Methodsubsection present results evaluation training testing dataSenseval-2 Spanish lexicalsample task. corpus parsed using ConexorFunctional Dependency Grammar parser Spanish (Tapanainen & Jarvinen, 1997).classifiers built training data evaluated test data. Table7 shows combination groups features works better every POSwork better words together.NounsVerbsAdjectivesAccuracy Feature selection0.683LWSBCk50.595sk50.783LWsBCp0.6710LWSBCk5Table 7: Baseline: Accuracy Results Applying Senseval-2 Spanish Datawork entails exhaustive search looking accurate combinationfeatures. values presented merely informative indicate maximumaccuracy system achieve particular set features.3.3 Improving accuracymain goal find method automatically obtain best feature selection(Veenstra et al., 2000; Mihalcea, 2002; Suarez & Palomar, 2002b) training data.performed 3-fold cross-validation process. Data divided 3 folds; then, 3 testsdone, one 2 folds training data remaining one testing data.final result average accuracy. decided three tests smallsize training data. Then, tested several combinations features trainingdata Senseval-2 Spanish lexicalsample analyzed results obtainedword.order perform 3-fold cross-validation process word, preprocessingcorpus done. word, senses uniformly distributed threefolds (each fold contains one-third examples sense). sensesfewer three examples original corpus file rejected processed.Table 8 shows best results obtained using three-fold cross-validation trainingdata. Several feature combinations tested order find best set selectedword. purpose obtain relevant information wordcorpus rather applying combination features them. Therefore,information column Features lists feature selection best result.315fiMontoyo, Suarez, Rigau, & PalomarWordautoridad,Nbomba,Ncanal,Ncircuito,Ncorazon,Ncorona,Ngracia,Ngrano,Nhermano,Nmasa,Nnaturaleza,Noperacion,Norgano,Npartido,Npasaje,Nprograma,Ntabla,Nactuar,Vapoyar,Vapuntar,VFeaturesAccursbcp0.5890LWSBCk50.762sbcprdk30.5790LWSBCk50.5360Sbcpk50.781sbcp0.7220sk50.6340LWSBCr0.6810Sprd0.731LWSBCk50.756sbcprdk30.5270LWSBCk50.5430LWSBCPDk5 0.7150LWSBCk50.839sk50.6850LWSBCr0.587sk50.663sk50.5140sbcprdk30.7300LWsBCPDk5 0.661MFS0.5030.7070.3070.3920.6070.4890.2950.4830.6020.4550.4240.3770.5150.5240.4510.4860.4880.2930.6350.478Wordclavar,Vconducir,Vcopiar,Vcoronar,Vexplotar,Vsaltar,Vtocar,Vtratar,Vusar,Vvencer,Vbrillante,Aciego,Aclaro,Alocal,Anatural,Apopular,Asimple,Averde,Avital,AFeatures Accursbcprdk3 0.561LWsBCPD 0.5340sbcprdk3 0.457sk50.6980LWSBCk5 0.593LWsBC0.4030sbcprdk3 0.583sbcpk50.5270Sprd0.732sbcprdk3 0.696sbcprdk3 0.7560spdk50.8120Sprd0.9190LWSBCr 0.798sbcprdk10 0.471sbcprdk10 0.865LWsBCPD 0.776LWSBCk5 0.601Sbcp0.774MFS0.4490.3580.3380.3270.3180.1320.3130.2080.6690.6180.5120.5650.8540.7500.2670.6320.6210.3170.441Table 8: Three-fold Cross-Validation Results Senseval-2 Spanish Training Data: Best Averaged Accuracies per WordStrings row represent entire set features used training classifier.example, autoridad obtains best result using nearest words, collocations two lemmas,collocations two words, POS information is, s, b, c, p features, respectively(see Figure 9). column Accur (for accuracy) shows number correctly classifiedcontexts divided total number contexts (because always classifies precisionequal recall). Column MFS shows accuracy obtained frequent senseselected.data summarized Table 8 reveal using collapsed features methoduseful; collapsed non-collapsed functions used, even word.example, adjective vital obtains best result Sbcp (the collapsed versionwords window (3.. + 3), collocations two lemmas two words window(2.. + 2), POS labels, window (3.. + 3) too); infer single-wordinformation less important collocations order disambiguate vital correctly.target word (feature 0) useful nouns, verbs, adjectives, manywords use best feature selection. general, wordsrelevant relationship shape senses. hand, POS information (pP features) selected less often. comparing lemma features word features(e.g., L versus W , B versus C), complementary majority cases.Grammatical relationships (r features) wordword dependencies (d features)seem useful, too, combined types attributes. Moreover, keywords (km316fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation Methodsfeatures) used often, possibly due source size contexts Senseval-2Spanish lexicalsample data.Table 9 shows best feature selections part-of-speech words.data presented Tables 8 9 used build four different sets classifiers ordercompare accuracy: MEfix uses overall best feature selection words;MEbfs trains word best selection features (in Table 8); MEbfs.pos usesbest selection per POS nouns, verbs adjectives, respectively (in Table 9); and,finally, vME majority voting system input answers precedingsystems.POSNounsVerbsAdjectivesAcc0.6200.5590.7260.615FeaturesSystemLWSBCk5sbcprdk3 MEbfs.pos0spdk5sbcprdk3MEfixTable 9: Three-fold Cross-Validation Results Senseval-2 Spanish Training Data: Best Averaged Accuracies per POSTable 10 shows comparison four systems. MEfix lower results.classifier applies set types features words. However, best featureselection per word (MEbfs) best, probably training examplesnecessary. best choice seems select fixed set types features POS(MEbfs.pos).NounsMEbfs.pos 0.683 MEbfs.posvME0.678 vME0.661 MEbfsMEbfsMEfix0.646 MEfixVerbsAdjectives0.583 vME0.774 vME0.583 MEbfs.pos 0.772 MEbfs.pos0.583 MEfix0.771 MEbfs0.580 MEbfs0.756 MEfixMEfix: sbcprdk3 wordsMEbfs: wordbest feature selectionMEbfs.pos: LWSBCk5 nouns,sbcprdk3 verbs,0spdk5 adjectivesvME: majority voting MEfix,MEbfs.pos, MEbfs0.6770.6760.6670.658Table 10: Evaluation Systems317fiMontoyo, Suarez, Rigau, & PalomarMEbfs predicts, word training data, individually selectedfeatures could best ones evaluated testing data, MEbfs.posaveraged prediction, selection features that, training data, performed goodenough disambiguation majority words belonging particular POS.averaged prediction applied real testing data, MEbfs.pos performs betterMEbfs.Another important issue MEbfs.pos obtains accuracy slightly betterbest possible evaluation result achieved (see Table 7)that is, best-featureselection per POS strategy training data guarantees improvement ME-basedWSD.general, verbs difficult learn accuracy method lowerPOS; opinion, information (knowledge-based, perhaps) neededbuild classifiers. case, voting system (vME) based agreementthree systems, improve accuracy.Finally Table 11, results method compared systemscompeted Senseval-2 Spanish lexicalsample task5 . results obtainedsystems excellent nouns adjectives, verbs. However, comparingPOS, systems seem perform comparable best Senseval-2 systems.0.7130.6820.6770.6760.6700.6670.6580.6270.6170.6100.5950.5950.5820.5780.5600.5480.524jhu(R)jhuMEbfs.posvMEcss244MEbfsMEfixumd-sstduluth 8duluth 10duluth Zduluth 7duluth 6duluth Xduluth 9uaduluth0.7020.6830.6810.6780.6610.6520.6460.6210.6120.6110.6030.5920.5900.5860.5570.5140.464Nounsjhu(R)MEbfs.posjhuvMEMEbfscss244MEfixduluth 8duluth Zduluth 10umd-sstduluth 6duluth 7duluth Xduluth 9duluthua0.6430.6090.5950.5840.5830.5830.5830.5800.5150.5130.5110.4980.4900.4780.4770.4740.431Verbsjhu(R)jhucss244umd-sstvMEMEbfs.posMEfixMEbfsduluth 10duluth 8uaduluth 7duluth Zduluth Xduluth 9duluth 6duluth0.8020.7740.7720.7720.7710.7640.7560.7250.7120.7060.7030.6890.6890.6870.6780.6550.637Adjectivesjhu(R)vMEMEbfs.poscss244MEbfsjhuMEfixduluth 8duluth 10duluth 7umd-sstduluth 6duluth Zuaduluth Xduluth 9duluthTable 11: Comparison Spanish Senseval-2 systems5. JHU(R) Johns Hopkins University; CSS244 Stanford University; UMD-SST UniversityMaryland; Duluth systems University Minnesota - Duluth; UA University Alicante.318fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation Methods3.4 Comparing Specification Marks Method Maximum Entropy-basedMethodmain goal section evaluate Specification Marks Method (Montoyo &Suarez, 2001) Maximum Entropy-based Method (in particular, MEfix System)common data set, allow direct comparisons. individual evaluationmethod carried noun set (17 nouns) Spanish lexical-sample task(Rigau et al., 2001) Senseval-26 . Table 12 shows precision, recall coveragemethods.Precision Recall CoverageSM0.4640.4640.9410.6460.6461Table 12: Comparison SM nouns Senseval-2 Spanish lexical sampleorder study possible cooperation methods, count casesthat: two methods return correct sense occurrence, least onemethods provides correct sense finally, none provides correct sense.summary obtained results shown Table 13. results clearly showlarge room improvement combining system outcomes. fact,provide also possible upper bound precision technology, set 0.798(more 15 percentual points higher current best system). Table 14 presentscomplementary view: wins, ties loses SM contextexamined. Although performs better SM, 122 cases (15 %) solvedSM method.Contexts PercentageOK2400.3003980.498One OKZero OK1610.202Table 13: Correct classifications SM nouns Senseval-2 Spanish lexical sampleWins Ties LosesSM 267 240 122Table 14: Wins, ties loses SM systems nouns Senseval-2 Spanish lexicalsample6. Spanish English Senseval-2 corpora, applying Specification Marks methodused whole example context window target noun319fiMontoyo, Suarez, Rigau, & Palomar4. Experimental Worksection attempt confirm hypothesis corpus-based knowledgebased methods improve accuracy other. first subsection showsresults preprocessing test data maximum entropy method (ME) orderhelp specification marks method (SM). Next, test opposite, preprocessingtest data domain heuristic help maximum entropy method disambiguateaccurately.last experiment combines vME system (the majority voting system) SMmethod. Actually, relies simply adding SM one heuristic votingscheme.4.1 Integrating Corpus-based WSD System Knowledge-based WSDSystemexperiment designed study evaluate whether integration corpus-basedsystem within knowledge-based helps improve word-sense disambiguation nouns.Therefore, help SM labelling nouns context target word.is, reducing number possible senses nouns context. fact,reduce search space SM method. ensures sense target wordone related noun senses labelled ME.case, used noun words English lexical-sample task Senseval2. helps SM labelling words context target word. wordssense tagged using SemCor collection learning corpus. performed threefold cross-validation nouns 10 occurrences. selected nounsdisambiguated high precision, is, nouns percentagerates accuracy 90% more. classifiers nouns used disambiguatetesting data. total number different noun classifiers (noun) activatedtarget word across testing corpus shown Table 15.Next, SM applied, using heuristics disambiguating target wordstesting data, advantage knowing senses nouns formedcontext targets words.Table 15 shows results precision recall SM applied withoutfirst applying ME, is, without fixing sense nouns formcontext. small consistent improvement obtained completetest set (3.56% precision 3.61% recall). Although improvement low,experiment empirically demonstrates corpus-based method maximum entropyintegrated help knowledge-based system specification marks method.4.2 Integrating Knowledge-based WSD system Corpus-based WSDsystemcase, used domain heuristic improve informationadded directly domain features. problem data sparseness WSDsystem based features suffers could increased fine-grained sense distinctionsprovided WordNet. contrary, domain information significantly reduces320fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsTarget wordsartauthoritybarbumchairchannelchildchurchcircuitdaydetentiondykefacilityfatiguefeelinggriphearthholidayladymaterialmouthnationnaturepostrestraintsensespadestressyewTotalWithout fixed senses fixed sensesnoun classifiers PrecisionRecallPrecision Recall6380104375932595049136221514384838292340585125374131371737240.4750.1370.2220.4210.2060.5000.5000.5090.3560.0380.4540.9330.8750.2360.3060.1840.3210.8180.3750.3430.0940.2690.2630.3120.2000.2600.8230.2280.4800.4750.1230.2030.2160.1900.3430.2000.5090.3460.0350.4540.9330.8750.2300.3000.1790.3100.3460.1360.3380.0940.2690.2630.3060.1930.2400.8230.2160.4800.5240.1440.2320.4210.3160.5210.5180.5400.3690.0540.4760.93310.2970.3460.2160.3210.8330.6150.3590.1320.3070.2890.3540.2060.2820.9410.2570.5410.5240.1350.2200.2160.3010.3750.2330.5290.3600.0490.4540.93310.2820.3400.2050.3100.3840.3630.3530.1320.3070.2890.3460.1930.2600.9410.2430.52012940.3000.2670.3360.303Table 15: Precision Recall Results Using SM Disambiguate Words, Without Fixing Noun Senseword polysemy (i.e., number categories word generally lower numbersenses word) results obtained heuristic better precisionobtained whole SM method, turn obtain better recall.shown subsection 3.1.7, domain heuristic annotate word senses characterized domains. Thus, domains used additional type featurescontext window 1, 2, 3 target word. addition,three relevant domains calculated also context incorporatedtraining form features.experiment also carried English lexical-sample task dataSenseval-2, used generate two groups classifiers training data.first group classifiers used corpus without information domains; second,previously domain disambiguated SM, incorporating domain labeladjacent nouns, three relevant domains context. is, providingclassifier richer set features (adding domain features). However, case,perform feature selection.test data disambiguated twice, without SM domain labelling,using 0lW sbcpdm (see Figure 9) common set features order performcomparison. results experiment shown Table 16.table shows 7 29 nouns obtained worse results using domains,whereas 13 obtained better results. Although, case, obtained smallimprovement terms precision (2%)7 .7. difference proves statistically significant applying test corrected differencetwo proportions (Dietterich, 1998; Snedecor & Cochran, 1989)321fiMontoyo, Suarez, Rigau, & PalomarTarget wordsWithout domains domains Improvementartauthoritybarbumchairchannelchildchurchcircuitdaydetentiondykefacilityfatiguefeelinggriphearthholidayladymaterialmouthnationnaturepostrestraintsensespadestressyew0.6670.6000.6250.8650.8980.5670.6610.5600.4080.6760.9090.8000.4290.8500.7080.5400.7591.0000.9000.5340.5690.7200.4590.4630.5160.6760.7650.3780.7920.7780.7000.6150.9190.8980.5970.6950.6000.3880.6690.9090.8000.5000.8500.6880.6200.7930.9570.9000.5520.5880.7200.4590.5120.4520.6220.8820.3780.7920.1110.100-0.0100.0540.6490.6690.0200.0300.0340.040-0.020-0.0070.071-0.0210.0800.034-0.0430.0170.0200.049-0.065-0.0540.118Table 16: Precision Results Using Disambiguate Words, Without Domains(recall precision values equal)obtained important conclusions relevance domain informationword. general, larger improvements appear words well-differentiateddomains (spade, authority). Conversely, word stress senses belongingFACTOTUM domain improves all. example, spade, art authority(with accuracy improvement 10%) domain data seems important sourceknowledge information captured types features. wordsprecision decrease 6.5%, domain information confusing. Three reasonsexposed order explain behavior: clear domain examplesrepresent correctly context, domains differentiate appropriatelysenses, number training examples low perform valid assessment.cross-validation testing, examples available, could appropriate performdomain tuning word order determine words must use preprocessnot.Nevertheless, experiment empirically demonstrates knowledge-based method,domain heuristic, integrated successfully corpus-based system,maximum entropy, obtain small improvement.4.3 Combining Results with(in) Voting Systemprevious sections, demonstrated possible integrate two different WSDapproaches. section evaluate performance combining knowledge-basedsystem, specification marks, corpus-based system, maximum entropy,simple voting schema.322fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation Methodstwo previous experiments attempted provide information predisambiguating data. Here, use methods parallel combineclassifications voting system, Senseval-2 Spanish English lexicalsampletasks.4.3.1 Senseval-2 Spanish lexicalsample taskvME+SM enrichment vME: added SM classifier combinationthree systems vME (see Section 3.3). results Spanish lexicalsample taskSenseval-2 shown Table 17. works nouns, vME+SMimproves accuracy only, obtains score JHU(R) overallscore reaches second place.0.7130.6840.6820.6770.6760.6700.6670.6580.6270.6170.6100.5950.5950.5820.5780.5600.5480.524jhu(R)vME+SMjhuMEbfs.posvMEcss244MEbfsMEfixumd-sstduluth 8duluth 10duluth Zduluth 7duluth 6duluth Xduluth 9uaduluth0.7020.7020.6830.6810.6780.6610.6520.6460.6210.6120.6110.6030.5920.5900.5860.5570.5140.464Nounsjhu(R)vME+SMMEbfs.posjhuvMEMEbfscss244MEfixduluth 8duluth Zduluth 10umd-sstduluth 6duluth 7duluth Xduluth 9duluthuaTable 17: vME+SM Spanish lexicalsample task Senseval-2results show methods like SM combined order achievegood disambiguation results. results line Pedersen (2002),also presents comparative evaluation systems participated SpanishEnglish lexical-sample tasks Senseval-2. focus pair comparisonssystems assess degree agree, measuring difficulty testinstances included tasks. several systems largely agreement,little benefit combining since redundant simply reinforceother. However, systems disambiguate instances others not,systems complementary may possible combine take advantagedifferent strengths system improve overall accuracy.results nouns (only applying SM), shown Table 18, indicate SMlow level agreement methods. However, measure optimalcombination quite high, reaching 89% (1.000.11) pairing SM JHU.323fiMontoyo, Suarez, Rigau, & Palomarfact, seven methods achieved highest optimal combination valuepaired SM method.System pair nounsSM JHUSM Duluth7SM DuluthYSM Duluth8SM Cs224SM UmcpSM Duluth9OKa One OK0.290.320.270.340.250.350.280.320.280.320.260.330.260.31bZero OK0.110.120.120.130.130.140.16cKappa0.060.030.010.080.090.060.14Table 18: Optimal combination systems participated Spanishlexicalsample tasks Senseval-2a.b.c.d.Percentage instances systems answers correct.Percentage instances one answer correct.Percentage instances none answers correct.kappa statistic (Cohen, 1960) measure agreement multiple systems (or judges)scaled agreement would expected chance. value 1.00 suggests completeagreement, 0.00 indicates pure chance agreement.combination circumstances suggests SM, knowledge-based method,fundamentally different others (i.e., corpus-based) methods, abledisambiguate certain set instances methods fail. fact, SM differentmethod uses structure WordNet.4.3.2 Senseval-2 English lexicalsample taskexperiment done Senseval-2 English lexicalsample task dataresults shown Table 19. details different systems builtconsulted Section 3.2Again, see Table 19 BFS per POS better per word, mainlyreasons explained Section 3.3.Nevertheless, improvement nouns using vME+SM system highSpanish data. differences corpora significant relevanceprecision values obtained. example, English data includesmulti-words sense inventory extracted WordNet, Spanish datasmaller dictionary built task specifically, smaller polysemydegree.results vME+SM comparable systems presented Senseval-2best system (Johns Hopkins University) reported 64.2% precision (68.2%, 58.5%73.9% nouns, verbs adjectives, respectively).Comparing results obtained section 4.2, also see usingvoting system best feature selection Specification Marks vME+SM,using nonoptimized relevant domain heuristic, obtain similarperformance. is, seems obtain comparable performance combining different324fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsNouns Verbs AdjectivesMEfix0.601 0.656 0.5190.696MEbfs 0.606 0.658 0.5190.696MEbfs.pos 0.609 0.664 0.5190.696vME+SM 0.619 0.667 0.5350.707MEfix: 0mcbWsdrvK3 wordsMEbfs: wordbest feature selectionMEbfs.pos: 0Wsrdm nouns,0sbcprdmK10 verbs,0mcbWsdrvK3 adjectivesvME+SM: majority voting MEfix,MEbfs.pos, MEbfs, Specification MarksTable 19: Precision Results Using Best Feature Selection Specification MarksSenseval-2 English lexicalsample task dataclassifiers resulting feature selection process using richer set features (addingdomain features) much less computational overhead.analysis results Senseval-2 English Spanish lexicalsampletasks demonstrates knowledge-based corpus-based WSD systems cooperatecombined obtain improved WSD systems. results empirically demonstrate combination approaches outperforms individually,demonstrating approaches could considered complementary.5. Conclusionsmain hypothesis work WSD requires different kinds knowledge sources(linguistic information, statistical information, structural information, etc.) techniques.aim paper explore methods collaboration complementaryknowledge-based corpus-based WSD methods. Two complementary methodspresented: specification marks (SM) maximum entropy (ME). Individually,benefits drawbacks. shown methods collaborate obtain betterresults WSD.order demonstrate hypothesis, three different schemes combiningapproaches presented. presented different mechanisms combininginformation sources around knowledge-based corpus-based WSD methods.also shown combination approaches outperforms methods individually, demonstrating approaches could considered complementary. Finally,shown knowledge-based method help corpus-based method betterperform disambiguation process, vice versa.order help specification marks method, disambiguates nounscontext target word. selects nouns means previous analysistraining data order identify ones seem highly accurately disambiguated.325fiMontoyo, Suarez, Rigau, & Palomarpreprocess fixes nouns reducing search space knowledge-based method.turn, helped SM providing domain information nouns contexts.information incorporated learning process form features.comparing accuracy methods, without contributionother, demonstrated combining schemes WSD methods possiblesuccessful.Finally, presented voting system nouns included four classifiers, threebased ME, one based SM. cooperation scheme obtainedbest score nouns compared systems submitted Senseval-2 Spanishlexicalsample task comparable results submitted Senseval-2 Englishlexicalsample task.presently studying possible improvements collaborationmethods, extending information two methods providetaking advantage merits one.Acknowledgmentsauthors wish thank anonymous reviewers Journal Artificial Intelligence Research COLING 2002, 19th International Conference ComputationalLinguistics, helpful comments earlier drafts paper. earlier paper (Suarez &Palomar, 2002b) corpus-based method (subsection 3.2) presented COLING2002.research partially funded Spanish Government project CICyT number TIC2000-0664-C02-02 PROFIT number FIT-340100-2004-14 Valencia Government project number GV04B-276 EU funded project MEANING (IST-2001-34460).ReferencesAgirre, E., & Martinez, D. (2001a). Decision lists english basque. ProceedingsSENSEVAL-2 Workshop. conjunction ACL2001/EACL2001 Toulouse,France.Agirre, E., & Martinez, D. (2001b). Knowledge sources word sense disambiguation.Proceedings International Conference Text, Speech Dialogue (TSD2001)Selezna Ruda, Czech Republic.Agirre, E., & Rigau, G. (1996). Word Sense Disambiguation using Conceptual Density.Proceedings 16th International Conference Computational Linguistic (COLING96 Copenhagen, Denmark.Berger, A. L., Pietra, S. A. D., & Pietra, V. J. D. (1996). maximum entropy approachnatural language processing. Computational Linguistics, 22 (1), 3971.326fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsBruce, R., & Wiebe, J. (1994). Word sense disambiguation using decomposable models.Proceedings 32nd Annual Meeting Association Computational Linguistics (ACL1994), pp. 139145 Las Cruces, US.Cabezas, C., Resnik, P., & Stevens, J. (2001). Supervised Sense Tagging using SupportVector Machines. Proceedings Second International Workshop EvaluatingWord Sense Disambiguation Systems (SENSEVAL-2) Toulouse, France.Cardie, C., & Mooney, R. J. (1999). Guest editors introduction: Machine learningnatural language. Machine Learning, 34 (1-3), 59.Cohen, J. (1960). coefficient agreement nominal scales. Educ. Psychol. Meas., 20,3746.Cowie, J., Guthrie, J., & Guthrie, L. (1992). Lexical disambiguation using simulated annealing. Proceedings 14th International Conference Computational Linguistic,COLING92, pp. 359365 Nantes, France.Cuadros, M., Atserias, J., Castillo, M., & Rigau, G. (2004). Automatic acquisition senseexamples using exretriever. IBERAMIA Workshop Lexical ResourcesWeb Word Sense Disambiguation. Puebla, Mexico.Dang, H. T., yi Chia, C., Palmer, M., & Chiou, F.-D. (2002). Simple features chineseword sense disambiguation. Chen, H.-H., & Lin, C.-Y. (Eds.), Proceedings19th International Conference Computational Linguistics (COLING2002).Dietterich, T. G. (1998). Approximate statistical test comparing supervised classificationlearning algorithms. Neural Computation, 10 (7), 18951923.Escudero, G., Marquez, L., & Rigau, G. (2000). Boosting applied word sense disambiguation. Proceedings 12th Conference Machine Learning ECML2000Barcelona, Spain.Fellbaum, C. (Ed.). (1998). WordNet. Electronic Lexical Database. MIT Press.Fernandez-Amoros, D., Gonzalo, J., & Verdejo, F. (2001). Role Conceptual Relations Word Sense Disambiguation. Proceedings 6th International ConferenceApplication Natural Language Information Systems (NLDB2001)., pp. 8798Madrid, Spain.Hoste, V., Daelemans, W., Hendrickx, I., & van den Bosch, A. (2002). Evaluating resultsmemory-based word-expert approach unrestricted word sense disambiguation.Proceedings ACL2002 Workshop Word Sense Disambiguation: RecentSuccesses Future Directions, pp. 95101 PA, USA.Ide, N., & Veronis, J. (1998). Introduction Special Issue Word Sense Disambiguation: State Art. Computational Linguistics, 24 (1), 140.Leackock, C., Chodorow, M., & Miller, G. (1998). Using corpus statistics wordnetrelations sense identification. Computational Linguistics. Special Issue WSD,24 (1).327fiMontoyo, Suarez, Rigau, & PalomarLesk, M. (1986). Automated sense disambiguation using machine-readable dictionaries:tell pine cone ice cream cone. Proceedings 1986 SIGDOCConference, Association Computing Machinery, pp. 2426 Toronto, Canada.Magnini, B., & Strapparava, C. (2000). Experiments Word Domain DisambiguationParallel Texts. Proceedings ACL Workshop Word Senses Multilinguality Hong Kong, China.Magnini, B., Strapparava, C., Pezzulo, G., & Gliozzo, A. (2002). Role DomainInformation Word Sense Disambiguation. Natural Language Engineering, 8 (4),359373.Manning, C., & Schutze, H. (Eds.). (1999). Foundations Statistical Natural LanguageProcessing. MIT Press.Manning, C. D., & Schutze, H. (1999). Foundations Statistical Natural Language Processing. MIT Press, Cambridge, Massachusetts.McRoy, S. W. (1992). Using multiple knowledge sources word sense discrimination.Computational Linguistics, 18 (1), 130.Mihalcea, R. (2002). Instance based learning automatic feature selection appliedword sense disambiguation. Chen, H.-H., & Lin, C.-Y. (Eds.), Proceedings19th International Conference Computational Linguistics (COLING2002).Mihalcea, R., & Moldovan, D. (1999). Method word sense disambiguation unrestricted text. Proceedings 37th Annual Meeting AssociationComputational Linguistic, ACL99, pp. 152158 Maryland, Usa.Miller, G. A. (1995). Wordnet: lexical database english. Communications ACM,38 (11), 3941.Miller, G. A., Leacock, C., Tengi, R., & Bunker, T. (1993). Semantic Concordance.Proceedings ARPA Workshop Human Language Technology, pp. 303308Plainsboro, New Jersey.Mitchell, T. M. (Ed.). (1997). Machine Learning. McGraw Hill.Montoyo, A., & Palomar, M. (2001). Specification Marks Word Sense Disambiguation:New Development. Gelbukh, A. F. (Ed.), CICLing, Vol. 2004 Lecture NotesComputer Science, pp. 182191. Springer.Montoyo, A., & Suarez, A. (2001). University Alicante word sense disambiguationsystem.. Preiss, & Yarowsky (Preiss & Yarowsky, 2001), pp. 131134.Montoyo, A., Palomar, M., & Rigau, G. (2001). WordNet Enrichment ClassificationSystems.. Proceedings WordNet Lexical Resources: Applications,Extensions Customisations Workshop. (NAACL-01) Second MeetingNorth American Chapter Association Computational Linguistics, pp. 101106 Carnegie Mellon University. Pittsburgh, PA, USA.328fiCombining Knowledge- Corpus-based Word-Sense-Disambiguation MethodsMontoyo, A., Vazquez, S., & Rigau, G. (2003). Metodo de desambiguacion lexica basadaen el recurso lexico Dominios Relevantes. Procesamiento del Lenguaje Natural, 31,141148.Ng, H. (1997). Exemplar-Base Word Sense Disambiguation: Recent Improvements.Proceedings 2nd Conference Empirical Methods Natural LanguageProcessing, EMNLP.Ng, H. T., & Lee, H. B. (1996). Integrating multiple knowledge sources disambiguate wordsenses: exemplar-based approach. Joshi, A., & Palmer, M. (Eds.), Proceedings34th Annual Meeting Association Computational Linguistics SanFrancisco. Morgan Kaufmann Publishers.Pedersen, T. (2002). Assessing System Agreement Instance Difficulty LexicalSample Tasks Senseval-2. Proceedings Workshop Word Sense Disambiguation: Recent Successes Future Directions, ACL2002 Philadelphia, USA.Preiss, J., & Yarowsky, D. (Eds.). (2001). Proceedings SENSEVAL-2, Toulouse, France.ACL-SIGLEX.Ratnaparkhi, A. (1998). Maximum Entropy Models Natural Language Ambiguity Resolution. Ph.D. thesis, University Pennsylvania.Rigau, G., Agirre, E., & Atserias, J. (1997). Combining unsupervised lexical knowledgemethods word sense disambiguation. Proceedings joint 35th Annual MeetingAssociation Computational Linguistics 8th Conference EuropeanChapter Association Computational Linguistics ACL/EACL97 Madrid,Spain.Rigau, G., Taule, M., Fernandez, A., & Gonzalo, J. (2001). Framework resultsspanish senseval.. Preiss, & Yarowsky (Preiss & Yarowsky, 2001), pp. 4144.Snedecor, G. W., & Cochran, W. G. (1989). Statistical Methods (8 edition). Iowa StateUniversity Press, Ames, IA.Snyder, B., & Palmer, M. (2004). english all-words task. Proceedings3rd ACL workshop Evaluation Systems Semantic Analysis Text(SENSEVAL-3). Barcelona, Spain.Suarez, A., & Palomar, M. (2002a). Feature selection analysis maximum entropy-basedwsd. Gelbukh, A. F. (Ed.), CICLing, Vol. 2276 Lecture Notes ComputerScience, pp. 146155. Springer.Suarez, A., & Palomar, M. (2002b). maximum entropy-based word sense disambiguationsystem. Chen, H.-H., & Lin, C.-Y. (Eds.), Proceedings 19th InternationalConference Computational Linguistics (COLING2002), pp. 960966.Sussna, M. (1993). Word sense disamiguation free-text indexing using massive semanticnetwork. . Proceedings Second International Conference InformationKnowledge Base Management, CIKM93, pp. 6774 Arlington, VA.329fiMontoyo, Suarez, Rigau, & PalomarTapanainen, P., & Jarvinen, T. (1997). non-projective dependency parser. ProceedingsFifth Conference Applied Natural Language Processing, pp. 6471.Towell, G. G., & Voorhees, E. M. (1998). Disambiguating highly ambiguous words. Computational Linguistics, 24 (1), 125145.Veenstra, J., den Bosch, A. V., Buchholz, S., Daelemans, W., & Zavrel, J. (2000). Memorybased word sense disambiguation. Computers Humanities, Special IssueSENSEVAL, 34 (12), 171177.Wilks, Y., Fass, D., Guo, C.-M., McDonald, J., Plate, T., & Slator, B. (1993). Providing machine tractable dictionary tools. Pustejovsky, J. (Ed.), Semanticslexicon, pp. 341401. Kluwer Academic Publishers.Yarowsky, D. (1994). Decision lists lexical ambiguity resolution: Application accentrestoration spanish french.. Proceedings 32nd Annual MeetingAssociation Computational Linguistics (ACL1994) Las Cruces, NM,.330fiJournal Artificial Intelligence Research 23 (2005) 587-623Submitted 7/04; published 5/05Improved Search AlgorithmOptimal Multiple-Sequence AlignmentStefan Schroedlstefan.schroedl@gmx.de848 14th StSan Francisco CA 94114+1 (415) 522-1148AbstractMultiple sequence alignment (MSA) ubiquitous problem computational biology.Although NP -hard find optimal solution arbitrary number sequences,due importance problem researchers trying push limits exactalgorithms further. Since MSA cast classical path finding problem, attracting growing number AI researchers interested heuristic search algorithmschallenge actual practical relevance.paper, first review two previous, complementary lines research. BasedHirschbergs algorithm, Dynamic Programming needs O(kN k1 ) space storesearch frontier nodes needed reconstruct solution path, k sequenceslength N . Best first search, hand, advantage bounding searchspace explored using heuristic. However, necessary maintainexplored nodes final solution order prevent search re-expandinghigher cost. Earlier approaches reduce Closed list either incompatiblepruning methods Open list, must retain least boundary Closedlist.article, present algorithm attempts combining respectiveadvantages; like uses heuristic pruning search space, reducesmaximum Open Closed size O(kN k1 ), Dynamic Programming.underlying idea conduct series searches successively increasing upper bounds,using DP ordering key Open priority queue. suitable choicethresholds, practice, running time four times expected.experiments show algorithm outperforms one currentlysuccessful algorithms optimal multiple sequence alignments, Partial Expansion ,time memory. Moreover, apply refined heuristic based optimal alignmentspairs sequences, larger subsets. idea new; however,make practically relevant show equally important bound heuristiccomputation appropriately, overhead obliterate possible gain.Furthermore, discuss number improvements time space efficiencyregard practical implementations.algorithm, used conjunction higher-dimensional heuristics, able calculate first time optimal alignment almost problems Reference 1benchmark database BAliBASE .1. Introduction: Multiple Sequence Alignmentmultiple sequence alignment problem (MSA) computational biology consists aligning several sequences, e.g. related genes different organisms, order reveal simic2005AI Access Foundation. rights reserved.fiSchroedllarities differences across group. Either DNA directly compared,underlying alphabet consists set {C,G,A,T} four standard nucleotide basescytosine, guanine, adenine thymine; compare proteins, casecomprises twenty amino acids.Roughly speaking, try write sequences onecolumns matching letters maximized; thereby gaps (denoted additionalletter ) may inserted either order shift remaining charactersbetter corresponding positions. Different letters column interpretedcaused point mutations course evolution substituted one aminoacid another one; gaps seen insertions deletions (since directionchange often known, also collectively referred indels). Presumably,alignment fewest mismatches indels constitutes biologically plausibleexplanation.host applications MSA within computational biology; e.g., determining evolutionary relationship species, detecting functionally active sitestend preserved best across homologous sequences, predicting threedimensional protein structure.Formally, one associates cost alignment tries find (mathematically)optimal alignment, i.e., one minimum cost. designing cost function,computational efficiency biological meaning taken account.widely-used definition sum-of-pairs cost function. First, given symmetric(|| + 1)2 matrix containing penalties (scores) substituting letter another one(or gap). simplest case, could one mismatch zero match,biologically relevant scores developed. Dayhoff, Schwartz, Orcutt(1978) proposed model molecular evolution estimate exchangeprobabilities amino acids different amounts evolutionary divergence; gives riseso-called PAM matrices, PAM250 generally widely used; Jones,Taylor, Thornton (1992) refined statistics based larger body experimentaldata. Based substitution matrix, sum-of-pairs cost alignment definedsum penalties letter pairs corresponding column positions.pairwise alignment conveniently depicted path two oppositecorners two-dimensional grid (Needleman Wunsch, 1981): one sequence placedhorizontal axis left right, one vertical axis topbottom. gap either string, path moves diagonally right; gapvertical (horizontal) string represented horizontal (vertical) move right (down),since letter consumed one strings. alignment graph directedacyclic, (non-border) vertex incoming edges left, top, top-leftadjacent vertices, outgoing edges right, bottom, bottom-right vertices.Pairwise alignment readily generalized simultaneous alignment multiplesequences, considering higher-dimensional lattices. example, alignment threesequences visualized path cube. Fig. 1 illustrates example stringsABCB, BCD, DB. also shows computation sum-of-pairs cost, hypotheticalsubstitution matrix. real example (problem 2trx BAliBASE , see Sec. 7.3) givenFig. 2.588fiAn Improved Search Algorithm Optimal Multiple-Sequence AlignmentAlignment:Substitution matrix:B C _ B_ B C __ _ _ BB C _0 2 4 2 3B1 3 3 3C2 2 31 3_0Cost: 6+7+8+7+7 = 35endCBBBCBstartFigure 1: Fictitious alignment problem: Column representation, cost matrix, threedimensional visualization alignment path cube.number improvements integrated sum-of-pairs cost, like associatingweights sequences, using different substitution matrices sequences varyingevolutionary distance. major issue multiple sequence alignment algorithmsability handle gaps. Gap penalties made dependent neighbor letters.Moreover, found (Altschul, 1989) assigning fixed score indelsometimes produce biologically plausible alignment. Since insertionsequence x letters likely x separate insertions single letter, gap costfunctions introduced depend length gap. useful approximationaffine gap costs, distinguish opening extension gap charge+ b x gap length x, appropriate b. Another frequently used modificationwaive penalties gaps beginning end sequence.Technically, order deal affine gap costs longer identify nodessearch graph lattice vertices, since cost associated edge dependspreceding edge path. Therefore, suitable store lattice edges priority589fiSchroedl1thx1grx1erv2trcP_aeqpvlvyfwaswcgpcqlmsplinlaantysdrlkvvkleidpnpttvkkyk______vegvpal__mqtvi__fgrsgcpysvrakdlaeklsnerdd_fqyqyvdiraegitkedlqqkagkpvetvp__agdklvvvdfsatwcgpckmikpffhslsekysn_viflevdvddcqdvasece______vksmptf_kvttivvniyedgvrgcdalnssleclaaeypm_vkfckira_sntgagdrfs______sdvlptl1thx1grx1erv2trcPrlvkgeqildstegvis__kdkllsf_ldthln_________qifvdqqhiggytdfaawvken_____lda____________qffkkgqkvgefsgan___kek_____leatine__lv____lvykggelisnfisvaeqfaedffaadvesflneygllper_Figure 2: Alignment problem 2trx BAliBASE , computed algorithm settingsdescribed Sec. 7.3.BCg = 53cost(_,C)=3gap penalty = 4g = 60Bcost(A,_)=3gap penalty = 4g = 60cost(A,C)=4gap penalty = 0g = 57Figure 3: Example computing path costs affine gap function; substitution matrixFig. 1 gap opening penalty 4 used.queue, let transition costs u v, v w sum-of-pairs substitution costsusing one character sequence gap, plus incurred gap penaltiesv w followed u v. representation adopted program MSA (Gupta,Kececioglu, & Schaeffer, 1995). Note state space representation growsfactor 2k . example successor costs calculated, cost matrixFig. 1 gap opening penalty 4, shown Fig. 3.convenience terminology sequel still refer nodes dealingsearch algorithm.590fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment2. OverviewWang Jiang (1994) shown optimal multiple sequence alignment problemNP -hard; therefore, cannot hope achieve efficient algorithm arbitrary numbersequences. consequence, alignment tools widely used practice sacrificesound theoretical basis exact algorithms, heuristic nature (Chan, Wong, &Chiu, 1992). wide variety techniques developed. Progressive methods buildalignment gradually, starting closest sequences successively addingdistant ones. Iterative strategies refine initial alignment sequenceimprovement steps.Despite limitation moderate number sequences, however, researchexact algorithms still going on, trying push practical boundaries further. stillform building block heuristic techniques, incorporating existing toolscould improve them. example, algorithm iteratively aligning two groups sequencestime could three more, better avoid local minima. Moreover,theoretically important gold standard available evaluation comparison,even problems.Since MSA cast minimum-cost path finding problem, turnsamenable heuristic search algorithms developed AI community; actuallyamong currently best approaches. Therefore, many researchers areaoften used puzzles games past study heuristic search algorithms, recentlyrising interest MSA testbed practical relevance, e.g., (Korf, 1999;Korf & Zhang, 2000; Yoshizumi, Miura, & Ishida, 2000; Zhou & Hansen, 2003b); studyalso led major improvements general search techniques.pointed definition MSA problem givenone; competes attempts formalizing biological meaning, oftenimprecise depends type question biologist investigator pursuing. E.g.,paper concerned global alignment methods, find alignmententire sequences. Local methods, contrast, geared towards finding maximally similarpartial sequences, possibly ignoring remainder.next section, briefly review previous approaches, based dynamic programming incorporating lower upper bounds. Sec. 4, describe new algorithmcombines extends ideas, allows reduce storage Closednodes partially recomputing solution path end (Sec. 5). Moreover, turnsalgorithms iterative deepening strategy transferred find good balancecomputation improved heuristics main search (Sec. 6), issuepreviously major obstacle practical application. Sec. 7 presentsexperimental comparison Partial Expansion (Yoshizumi, Miura, & Ishida, 2000),one currently successful approaches. also solve two problemsReference 1 widely used benchmark database BAliBASE (Thompson, Plewniak, &Poch, 1999). best knowledge, achieved previouslyexact algorithm.591fiSchroedl3. Previous Worknumber exact algorithms developed previously compute alignmentsmoderate number sequences. mostly constrained availablememory, required computation time, both. roughlygroup two categories: based dynamic programming paradigm,proceed primarily breadth-first fashion; best-first search, utilizing lower upperbounds prune search space. recent research, including new algorithmintroduced Sec. 4, attempts beneficially combine approaches.3.1 Dijkstras Algorithm Dynamic ProgrammingDijkstra (1959) presented general algorithm finding shortest (resp. minimum cost)path directed graph. uses priority queue (heap) store nodes v togethershortest found distance start node (i.e., top-left corner grid) v(also called g-value v). Starting priority queue, step,edge minimum g-value removed priority queue; expansion consistsgenerating successors (vertices right and/or below) reachable one step,computing respective g-value adding edge cost previous g-value,inserting turn priority queue case newly found distance smallerprevious g-value. time node expanded, g-value guaranteedminimal path cost start node, g (v) = d(s, v). procedure runspriority queue becomes empty, target node (the bottom-right corner grid)reached; g-value constitutes optimal solution cost g (t) = d(s, t)alignment problem. order trace back path corresponding cost, movebackwards start node choosing predecessors minimum cost. nodes eitherstored fixed matrix structure corresponding grid, dynamicallygenerated; latter case, explicitly store node backtrack-pointeroptimal parent.integer edge costs, priority queue implemented bucket array pointingdoubly linked lists (Dial, 1969), operations performed constant time(To precise, DeleteMin-operation also needs pointer runs differentg-values once; however, neglect comparison number expansions).expand vertex, 2k 1 successor vertices generated, sincechoice introducing gap sequence. Thus, Dijkstras algorithm solvemultiple sequence alignment problem O(2k N k ) time O(N k ) space k sequenceslength N .means reduce number nodes stored path reconstructionassociating counter node maintains number children whosebacktrack-pointer refers (Gupta et al., 1995). Since node expandedonce, number referring backtrack-pointers decrease, namely,whenever cheaper path one children found. nodes reference count goeszero, whether immediately expansion later loses child,deleted good. way, keep nodes memory least onedescendant currently priority queue. Moreover, auxiliary data structures vertices592fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignmentcoordinates efficiently stored tries (prefix trees); equippedreference counters well freed accordingly longer used edge.complexity Dijkstras algorithm holds dynamic programming (DP);differs former one scans nodes fixed order knownbeforehand (hence, contrary name exploration scheme actually static).exact order scan vary (e.g., row-wise column-wise), long compatibletopological ordering graph (e.g., two sequences cells left, top,diagonally top-left explored prior cell). One particular orderingantidiagonals, diagonals running upper-right lower-left. calculationantidiagonal node merely amounts summing k coordinates.Hirschberg (1975) noticed order determine cost optimal alignment g (t), would necessary store whole matrix; instead, proceedinge.g. rows suffices keep track k time, deleting row soonnext one completed. reduces space requirement one dimensionO(N k ) O(kN k1 ). order recover solution path end, re-computationlost cell values needed. Divide-and-conquer -strategy applies algorithm twicehalf grid each, forward backward direction, meeting fixedmiddle row. adding corresponding forward backward distances middlerow finding minimum, one cell lying optimal path recovered.cell essentially splits problem two smaller subproblems, one upper leftcorner it, one lower right corner; recursively solvedusing method. two dimensions, computation time doubled,overhead reduces even higher dimensions.FastLSA algorithm (Davidson, 2001) refines Hirschbergs algorithm exploiting additionally available memory store one node optimal path,thereby reducing number re-computations.3.2 Algorithms Utilizing BoundsDijkstras algorithm dynamic programming viewed variants breadthfirst search, achieve best first search expand nodes v order estimate(lower bound) total cost path passing v. Rather usingg-value Dijkstras algorithm, use f (v) := g(v) + h(v) heap key,h(v) lower bound cost optimal path v t. h indeed admissible,first solution found guaranteed optimal (Hart, Nilsson, & Raphael, 1968).classical best-first search algorithm, algorithm, well known artificialintelligence community. context, priority queue maintaining generated nodesoften also called Open list, nodes already expandedremoved constitute Closed list. Fig. 4 schematically depicts snapshottwo-dimensional alignment problem, nodes f -value larger currentfmin expanded. Since accuracy heuristic decreases distancegoal, typical onion-shaped distribution results, bulk located closerstart node, tapering towards higher levels.algorithm significantly reduce total number expanded generatednodes; therefore, higher dimensions clearly superior dynamic programming. How593fiSchroedlaxumiaeretClosedOpenPossible back leakLels(antidiagonals)XStartX XXXXXXXXXXEndFigure 4: Snapshot best-first search pairwise alignment (schematically).ever, contrast Hirschberg algorithm, still stores explored nodesClosed list. Apart keeping track solution path, necessary preventsearch leaking back, following sense.heuristic h called consistent h(x) h(x0 )+c(x, x0 ), node x child x0 .consistent heuristic ensures (as case Dijkstras algorithm) time nodeexpanded, g-value optimal, hence never expanded again. However, trydelete Closed nodes, topologically smaller nodes Openhigher f -value; expanded later stage, lead re-generationnode non-optimal g-value, since first instantiation longer availableduplicate checking. Fig. 4, nodes might subject spurious re-expansionmarked X.Researchers tried avoid leaks, retaining basic search scheme.Korf proposed store list forbidden operators node, place parentsdeleted node Open f -value infinity (Korf, 1999; Korf & Zhang, 2000). However,Zhou Hansen (2003a) remark, hard combine algorithm techniquesreduction Open list, moreover storage operators lets sizenodes grow exponentially number sequences. algorithm, keeptrack kernel Closed list, defined set nodesClosed nodes parents; otherwise Closed node said boundary. keyidea boundary nodes maintained, since shield kernelre-expansions. algorithm gets close memory limit nodeskernel deleted; backtrack pointer children changed parents594fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignmentdeleted nodes, become relay nodes them. final reconstructionoptimal solution path, algorithm called recursively relay node bridgegap missing edges.addition Closed list, also Open list grow rapidly sequence alignmentproblems. Particularly, since original algorithm expansion node generateschildren once, whose f -value larger optimal cost g (t) keptheap end, waste much available space.upper bound U optimal solution cost g (t) known, nodes vf (v) > U pruned right away; idea used several articles (Spouge, 1989; Guptaet al., 1995). One successful approaches Yoshizumi et al.s (2000) PartialExpansion (PEA ). node stores additional value F , minimumf -value yet ungenerated children. step, node minimumF -value expanded, children f = F generated. algorithmclearly generates nodes f value larger optimal cost, cannotavoided altogether. However, overhead computation time considerable:straightforward implementation, want maintain nodes constant size, generatingone edge requires determining f -values successors, interior nodeeventually fully expanded computation time order squarenumber successors, grows O(2k ) number sequences k.remedy, paper proposed relax condition generating childrenf F + C, small C.alternative general search strategy uses linear space iterativedeepening (IDA ) (Korf, 1985). basic algorithm conducts depth-first searchpre-determined threshold f -value. search, keeps track smallestf -value generated successor larger threshold. solution found,provides increased threshold used next search iteration.Wah Shang (1995) suggested liberal schemes determining next threshold dynamically order minimize number recomputations. IDA efficienttree structured search spaces. However, difficult detect duplicate expansions without additional memory; Therefore, unfortunately applicable lattice-structuredgraphs like sequence alignment problem due combinatorially explosive numberpaths two given nodes.different line research tries restrict search space breadth-first approaches incorporating bounds. Ukkonen (1985) presented algorithm pairwisealignment problem particularly efficient similar sequences; computation timescales O(dm), optimal solution cost. First consider problem decidingwhether solution exists whose cost less upper threshold U . restrictevaluation DP matrix band diagonals minimum numberindels required reach diagonal, times minimum indel cost, exceed U .general, starting minimum U value, successively double G testreturns solution; increase computation time due recomputations alsobounded factor 2.Another approach multiple sequence alignment make use lower bounds h. key idea following: Since nodes f -value lower g (t)expanded anyway order guarantee optimality, might well explore595fiSchroedlreasonable order, like Dijkstras algorithm DP, knew optimalcost. Even slightly higher upper bounds still help pruning. Spouge (1989) proposedbound DP vertices v g(v) + h(v) smaller upper bound g (t).Linear Bounded Diagonal Alignment (LBD-Align) (Davidson, 2001) uses upperbound order reduce computation time memory solving pairwise alignmentproblem dynamic programming. algorithm calculates DP matrix one antidiagonal time, starting top left corner, working towards bottom-right.would check bound every expansion, LBD-Align checkstop bottom cell diagonal. e.g. top cell diagonal pruned,remaining cells row pruned well, since reachableit; means pruning frontier next row shifted one. Thus,pruning overhead reduced quadratic linear amount termssequence length.3.3 Obtaining Heuristic Boundsassumed lower upper bounds, without specifying derive them.Obtaining inaccurate upper bound g (t) fairly easy, since use costvalid path lattice. Better estimates e.g. available heuristic linear-timealignment programs FASTA BLAST (Altschul, Gish, Miller, Myers, & Lipman,1990), standard method database searches. Davidson (2001) employedlocal beam search scheme.Gusfield (1993) proposed approximation called star-alignment.sequences aligned, one consensus sequence chosen sum pairwisealignment costs rest sequences minimal. Using best sequencecenter, ones aligned using gap, always gap rule. Gusfieldshowed cost optimal alignment greater equal cost staralignment, divided (2 2/k).use heuristic estimates, lower bounds k-alignment often basedoptimal alignments subsets < k sequences. general, vertex v k-space,looking lower bound path v target corner t. Consider firstcase = 2. cost path is, definition, sum edge costs,edge cost turn sum pairwise (replacement gap) penalties. multiplesequence alignment induces pairwise alignment sequences j, simply copyingrows j ignoring columns rows. pairwise alignmentsvisualized projection alignment onto faces, cf. Fig. 1.interchange summation order, sum-of-pairs cost sum pairwisealignment costs respective paths projected face, cannot smalleroptimal pairwise path cost. Thus, construct admissible heuristic hpaircomputing, pairwise alignment cell pairwise problem,cheapest path cost goal node.optimal solutions pairwise alignment problems needed lower bound hvalues usually computed prior main search preprocessing step (Ikeda & Imai,1994). end, suffices apply ordinary DP procedure; however, since timeinterested lowest cost path v t, runs backward direction,596fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignmentproceeding lower right corner upper left, expanding possible parentsvertex step.Let U upper bound cost optimal multiple sequence alignment G.sum optimal alignment costs Lij = d(sij , tij ) pairwise subproblems i, j{1, . . . , k}, < j, call L, lower bound G. Carrillo Lipman (1988) pointedadditivity sum-of-pairs cost function, pairwise alignment inducedoptimal multiple sequence alignment = U L largerrespective optimal pairwise alignment. bound used restrict numbervalues computed preprocessing stage storedcalculation heuristic: pair sequences i, j, nodes v feasiblepath start node si,j goal node ti,j exists total costLi,j + . optimize storage requirements, combine results twosearches. First, forward pass determines relevant node v minimum distanced(sij , v) start node. subsequent backward pass uses distance like exactheuristic stores distance d(v, tij ) target node nodesd(sij , v) + d(v, tij ) d(s, t) + 1 .Still, larger alignment problems required storage size extensive.program MSA (Gupta et al., 1995) allows user adjust values CarrilloLipman bound individually pair sequences. makes possible generateleast heuristic alignments time memory doesnt allow complete solution;moreover, recorded search -bound actually reached.negative case, optimality found solution still guaranteed; otherwise, usertry run program slightly increased bounds.general idea precomputing simplified problems storing solutions useheuristic explored name pattern databases (Culberson & Schaeffer,1998). However, approaches implicitly assume computational costamortized many search instances target. contrast, case MSA,heuristics instance-specific, strike balance. discussgreater depth Sec. 6.2.4. Iterative-Deepening Dynamic Programmingseen, fixed search order dynamic programming several advantages pure best-first selection.Since Closed nodes never reached search, safedelete useless ones (those part shortest path current Open1. slight technical complication arises affine gap costs: recall DP implementations usually chargegap opening penalty g-value edge e starting gap, edge e0 ending gapcarries extra penalty all. However, since sum pairs heuristics h computed backwarddirection, using algorithm would assign penalty path instead e0 .means heuristic f = g + h would longer guaranteed lower bound, sincecontains penalty twice. remedy, necessary make computation symmetric chargingbeginning end gap half cost each. case beginning endsequences handled conveniently starting search dummy diagonal edge((1, . . . , 1), (0, . . . , 0)), defining target edge dummy diagonal edge ((N, . . . , N ), (N +1, . . . , N + 1)), similar arrows shown Fig. 1.597fiSchroedlnodes) apply path compression schemes, Hirschberg algorithm.sophisticated schemes avoiding back leaks required, abovementioned methods core set maintenance dummy node insertion Open.Besides size Closed list, memory requirement Open list determined maximum number nodes open simultaneouslytime algorithm running. f -value used keypriority queue, Open list usually contains nodes f -values range(fmin , fmin + ); set nodes generally spread across search space,since g (and accordingly h = (f g)) vary arbitrarily 0 fmin + .opposed that, DP proceeds along levels antidiagonals rows, iterationk levels maintained time, hence sizeOpen list controlled effectively. Fig. 4, pairwise alignment partitioned antidiagonals: maximum number open nodes two adjacentlevels four, total amounts seventeen2 .practical purposes, running time measured termsnumber node expansions, one also take account execution timeneeded expansion. arranging exploration order edgeshead node (or generally, sharing common coordinate prefix)dealt one other, much computation cached, edgegeneration sped significantly. come back point Sec. 6.remaining issue static exploration scheme consists adequately boundingsearch space using h-values. known minimal terms number nodeexpansions. knew cost g (t) cheapest solution path beforehand, couldsimply proceed level level grid, however immediately prune generated edgese whenever f (e) > g (t). would ensure generate edges wouldgenerated algorithm , well. upper threshold would additionally helpreduce size Closed list, since node pruned children lie beyondthreshold; additionally, node child parent, give risepropagating chain ancestor deletions.propose apply search scheme carries series searches successively larger thresholds, solution found (or run memory patience).use upper bound parallels IDA algorithm.resulting algorithm, refer Iterative-Deepening Dynamic Programming (IDDP), sketched Fig. 5. outer loop initializes thresholdlower bound (e.g., h(s)), and, unless solution found, increases upper bound.manner IDA algorithm, order make sure least one additional edge explored iteration threshold increased correspondinglyleast minimum cost fringe edge exceeded previous threshold.fringe increment maintained variable minNextThresh, initially estimatedupper bound, repeatedly decreased course following expansions.2. Contrary figure might suggest, open two nodes per level pairwisealignments, set nodes worse fmin contains holes.598fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignmentprocedure IDDP(Edge startEdge, Edge targetEdge, int lowerBound, int upperBound)int thresh = lowerBound{Outer loop: Iterative deepening phases}(thresh upperBound)Heap h = {(startEdge, 0)}int minNextThresh = upperBound{Inner loop: Bounded dynamic programming}(not h.IsEmpty())Edge e = h.DeleteMin() {Find remove edge minimum level}(e == targetEdge){Optimal alignment found}return TraceBackPath(startEdge, targetEdge)endExpand(e, thresh, minNextThresh)endint threshIncr = ComputeThreshIncr() {Compute search threshold next iteration, see text}thresh = max(thresh + threshIncr, minNextThresh)endprint(No alignment cost upperBound found)Figure 5: Algorithm Iterative-Deepening Dynamic Programming.step inner loop, select remove node priority queuewhose level minimal. explained later Sec. 6, favorable break ties accordinglexicographic order target nodes. Since total number possible levelscomparatively small known advance, priority queue implemented usingarray linked lists (Dial, 1969); provides constant time operations insertiondeletion.expansion edge e partial (Fig. 6). child edge might already existearlier expansion edge head vertex; test decreaseg-value. Otherwise, generate new edge, temporarily sake calculating f -value; is, f -value exceeds search threshold current iteration,memory immediately reclaimed. Moreover, case fringe threshold minNextThresh updated. practical implementation, prune unnecessary accessespartial alignments inside calculation heuristic e.GetH() soon searchthreshold already reached.relaxation child edge within threshold performed subprocedureUpdateEdge (cf. Fig. 7). similar corresponding relaxation step , updatingchilds g- f values, parent pointers, inserting Open, alreadycontained. However, contrast best-first search, inserted heap accordingantidiagonal level head vertex. Note event former parent loseslast child, propagation deletions (Fig. 8) ensure Closed nodescontinue stored belong solution path. Edge deletions also ensuedeletion dependent vertex coordinate data structures (not shown pseudocode).situation gives rise deletions immediately expansionnode children pointing back (the children might either reachable cheaplydifferent nodes, f -value might exceed threshold).599fiSchroedlprocedure Expand(Edge e, int thresh, int minNextThresh)Edge child Succ(e){Retrieve child tentatively generate yet existing, set boolean variable createdaccordingly}int newG = e.GetG() + GapCost(e, child)+ child.GetCost()int newF = newG + child.GetH()(newF thresh newG < child.GetG()){Shorter path current best found, estimate within threshold}child.SetG(newG)UpdateEdge(e, child, h) {Update search structures}else (newF > thresh)minNextThresh =min(minNextThresh, newF){Record minimum pruned edges}(created)Delete(child) {Make sure promising edges stored}endendend(e.ref == 0)DeleteRec(e) {No promising children could inserted heap}endFigure 6: Edge expansion IDDP.procedure UpdateEdge(Edge parent, Edge child, Heap h)parent.ref++child.GetBacktrack().ref(child.GetBacktrack().ref == 0)DeleteRec(child.GetBacktrack()) {The former parent lost last child becomes useless}endchild.SetBacktrack(parent)(not h.Contains(child))h.Insert(child, child.GetHead().GetLevel())endFigure 7: Edge relaxation IDDP.correctness algorithm shown analogously soundness proof .threshold smaller g (t), DP search terminate without encounteringsolution; otherwise, nodes pruned cannot part optimal path.invariant holds always node level lies optimal pathOpen list. Therefore, algorithm terminates heap runs empty,best found solution indeed optimal.iterative deepening strategy results overhead computation time due reexpansions, trying restrict overhead much possible. precisely,600fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignmentprocedure DeleteRec(Edge e)(e.GetBacktrack() 6= nil)e.GetBacktrack().ref(e.GetBacktrack().ref == 0)DeleteRec(e.GetBacktrack())endendDelete(e)Figure 8: Recursive deletion edges longer part solution path.procedure TraceBack(Edge startEdge, Edge e)(e == startEdge)return {End recursion}end(e.GetBackTrack().GetTarget() 6= e.GetSource()){Relay node: recursive path reconstruction}IDDP( e.GetBackTrack(), e, e.GetF(), e.GetF())endOutputEdge(e)TraceBack(startEdge, e.GetBackTrack())Figure 9: Divide-and-Conquer solution reconstruction reverse order.want minimize ratio=nIDDP,nAnIDDP nA denote number expansions IDDP , respectively. Oneway (Wah & Shang, 1995) choose threshold sequence 1 , 2 , . . .number expansions ni stage satisfiesni = rni1 ,fixed ratio r. choose r small, number re-expansions hencecomputation time grow rapidly, choose big, thresholdlast iteration exceed optimal solution cost significantly, explore manyirrelevant edges. Suppose n0 rp < nA n0 rp+1 . algorithm performs p + 1iterations. worst case, overshoot maximal finds optimal solutionprevious threshold, nA = n0 rp + 1. total number expansionsPr(r p+1 1)r2n0 p+1, ratio becomes approximately r1. settingi=0 r = n0r1derivative expression zero, find optimal value r 2; numberexpansions double one search stage next. achieve doubling,expand four times many nodes .Like Wah Shangs (1995) scheme, dynamically adjust threshold using runtime information. Procedure ComputeThreshIncr stores sequence expansion numbersthresholds previous search stages, uses curve fitting extrapolation(in first iterations without sufficient data available, small default thresholdapplied). found distribution nodes n() f -value smaller equal601fiSchroedlthreshold modeled accurately according exponential approachn() = B .Consequently, order attempt double number expansions, choose nextthreshold according1i+1 = +.log2 B5. Sparse Representation Solution Pathssearch progresses along antidiagonals, fear back leaks,free prune Closed nodes. Similarly Zhou Hansens (2003a) work, however,want delete lazily incrementally forced algorithmapproaching computers memory limit.deleting edge e, backtrack-pointers child edges referredirected respective predecessor e, whose reference count increased accordingly.resulting sparse solution path representation, backtrack pointers pointoptimal ancestors.termination main search, trace back pointers starting goaledge; outlined Procedure TraceBack (Fig. 9), prints solution pathreverse order. Whenever edge e points back ancestor e0 directparent, apply auxiliary search start edge e0 goal edge e order reconstructmissing links optimal solution path. search threshold fixedknown solution cost; moreover, auxiliary search prune edges cannotancestors e coordinate greater corresponding coordinatee. Since also shortest distance e e0 known, stop first pathfound cost. improve efficiency auxiliary search even further,heuristic could recomputed suit new target. Therefore, cost restoringsolution path usually marginal compared main search.edges going prune, order? simplicity, assumemoment Closed list consists single solution path. According Hirschbergapproach, would keep one edge, preferably lying near center searchspace (e.g., longest anti-diagonal), order minimize complexity twoauxiliary searches. additional available space allowing store three relay edges,would divide search space four subspaces equal size (e.g., additionallystoring antidiagonals half-way middle antidiagonal start node resp.target node). extension, order incrementally save space diminishingresources would first keep every level, every fourth, on,start edge, target edge, one edge half-way path would left.Since general Closed list contains multiple solution paths (more precisely, treesolution paths), would like density relay edgesthem. case k sequences, edge reaching level l head node originatetail node level l 1, . . . , l k. Thus, every solution path passeslevel, deleting every level could result leaving one path completely intact,extinguishing another totally. Thus, better consider contiguous bands k602fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignmentprocedure SparsifyClosed()(int sparse = 1 blog2 N c)(UsedMemory() > maxMemory exists {Edge e Open | e.GetLastSparse() <sparse})Edge pred = e.GetBacktrack(){Trace back solution path}(pred 6= nil e.GetLastSparse() < sparse)e.SetLastSparse(sparse) {Mark avoid repeated trace-back}(bpred.GetHead().GetLevel() / kc mod 2sparse 6= 0){pred lies prunable band: redirect pointer}e.SetBacktrack(pred.GetBacktrack())e.GetBacktrack().ref++pred.ref(pred.ref == 0){e last remaining edge referring pred}DeleteRec(pred)endelse{Not prunable band: continue traversal}e = e.GetBacktrack()endpred = e.GetBacktrack()endendendFigure 10: Sparsification Closed list restricted memory.levels each, instead individual levels. Bands size cannot skipped path.total number antidiagonals alignment problem k sequences length Nk N 1; thus, decrease density blog2 N c steps.technical implementation issue concerns ability enumerate edges reference given prunable edge, without explicitly storing list. However,reference counting method described ensures Closed edge reachedfollowing path bottom-up edge Open. procedure sketched Fig. 10.variable sparse denotes interval level bands maintainedmemory. inner loop, paths Open nodes traversed backward direction;edge e0 falls prunable band, pointer successor e pathredirected respective backtrack pointer. e last edge referencing e0 ,latter one deleted, path traversal continues start edge. Opennodes visited memory bound still exceeded, outer loop triesdouble number prunable bands increasing sparse.Procedure SparsifyClosed called regularly search, e.g., expansion.However, naive version described would incur huge overhead computationtime, particularly algorithms memory consumption close limit. Therefore, optimizations necessary. First, avoid tracing back solution path(or lower) sparse interval recording edge interval603fiSchroedltraversed last time (initially zero); increased variable sparseanything left pruning. worst case, edge inspected blog2 N ctimes. Secondly, would inefficient actually inspect Open node innerloop, find solution path traversed previously, highersparse value; however, appropriate bookkeeping strategy possible reducetime search overhead O(k).6. Use Improved Heuristicsseen, estimator hpair , sum optimal pairwise goal distances, giveslower bound actual path length. However, powerful heuristics alsoconceivable. computation require resources, trade-off proveworthwhile; tighter estimator is, smaller space main searchneeds explore.6.1 Beyond Pairwise AlignmentsKobayashi Imai (1998) suggested generalize hpair considering optimal solutionssubproblems size > 2. proved following heuristics admissibleinformed pairwise estimate.hall,m sum m-dimensional optimal costs, dividedk2m2 .hone,m splits sequences two sets sizes k m; heuristic sumoptimal cost first subset, plus second one, plus sum2-dimensional optimal costs pairs sequences different subsets. Usually,chosen close k/2.improved heuristics reduce main search effort orders magnitudes.However, contrast pairwise sub-alignments, time space resources devoted compute store higher-dimensional heuristics general longer negligible comparedmain search. Kobayashi Imai (1998) noticed even case = 3triples sequences, impractical compute entire subheuristic hall,m . onereduction, show suffices restrict oneself nodes path costexceed optimal path cost subproblem!=Xk2Ud(si1 ,...,im , ti1 ,...,im );m2,...,i1threshold seen generalization Carrillo-Lipman bound. However,stillincur excessive overhead space computation time computationklower-dimensional subproblems. drawback requires upper boundU , whose accuracy also algorithms efficiency hinges. could improve boundapplying sophisticated heuristic methods, seems counterintuitive spendtime would rather use calculate exact solution. spiteadvantages main search, expensiveness heuristic calculation appearsmajor obstacle.604fiAn Improved Search Algorithm Optimal Multiple-Sequence AlignmentMcNaughton, Lu, Schaeffer, Szafron (2002) suggested partition heuristic(hyper-) cubes using hierarchical oct-tree data structure; contrast full cells,empty cells retain values surface. main search tries use onethem, interior values recomputed demand. Still, work assumesnode entire heuristic calculated least using dynamic programming.see one cause dilemma implicit assumption complete computationnecessary. bound refers worst-case, generally include manynodes actually required main search. However, since dealingheuristic, actually afford miss values occasionally; mightslow main search, cannot compromise optimality final solution.Therefore, propose generate heuristics much smaller bound . Wheneverattempt retrieve value m-dimensional subheuristicfails mainsearch, simply revert replacing sum 2 optimal pairwise goal distancescovers.believe IDDP algorithm lends well make productive use higherdimensional heuristics. Firstly importantly, strategy searching adaptivelyincreasing thresholds transferred -bound well; addresseddetail next section.Secondly, far practical implementation concerned, important takeaccount higher-dimensional heuristic affects number node expansions,also time complexity. time dominated number accesses subalignments. k sequences, worst case edge 2k 1 successors, leadingtotal!kk(2 1)evaluations hall,m . One possible improvement enumerate edges emerginggiven vertex lexicographic order, store partial sums heuristics prefix subsetssequences later re-use. way, allow cache linear size, numberaccesses reduced!i=kXi1;2m1i=mcorrespondingly, quadratic cache needi=kXi=m!2i2m2evaluations. instance, aligning 12 sequences using hall,3 , linear cache reducesevaluations 37 percent within one expansion.mentioned above, contrast , IDDP gives us freedom chooseparticular expansion order edges within given level. Therefore, sort edgeslexicographically according target nodes, much cached prefix informationshared additionally across consecutively expanded edges. higher dimensionsubalignments, larger savings. experiments, experienced speedupseighty percent heuristic evaluation.605fiSchroedlExecution time [s]100Main searchHeuristicTotal time1010.10102030 40 50 60 70Heuristic miss ratio r [%]8090100Figure 11: Trade-off heuristic main search: Execution times problem 1tvxAfunction heuristic miss ratio.6.2 Trade-Off Computation Heuristic Main Searchseen, control size precomputed sub-alignments choosingbound f -values edges generated beyond respective optimalsolution cost. obviously trade-off auxiliary main searches.instructive consider heuristic miss ratio r, i.e., fraction calculationsheuristic h main search requested entry partial MSAprecomputed. optimum main search achieved heuristiccomputed every requested edge (r = 0). Going beyond point generateunnecessarily large heuristic containing many entries never actually used.hand, free allocate less effort heuristic, resulting r > 0consequently decreasing performance main search. Generally, dependenceS-shaped form, exemplified Fig. 11 case problem 1tvxA BAliBASE(cf. next section). Here, execution time one iteration main search fixedthreshold 45 lower bound shown, includes optimal solution.Fig. 11 illustrates overall time trade-off auxiliary main search, fixdifferent levels. minimum total execution time, sum auxiliarymain search, attained r = 0.15 (5.86 seconds). plot correspondingmemory usage trade-off similar shape.Unfortunately, general know advance right amount auxiliary search.mentioned above, choosing according Carrillo-Lipman bound ensure606fiAn Improved Search Algorithm Optimal Multiple-Sequence AlignmentExecution time [s]1001010.1010203040506070Heuristic miss ratio r [%]8090100Figure 12: Time last iteration main search problem 1tvxA functionheuristic miss ratio.every requested sub-alignment cost precomputed; however, generalconsiderably overestimate necessary size heuristic.remedy, algorithm IDDP gives us opportunity recompute heuristicthreshold iteration main search. way, adaptively strike balancetwo.currently experienced miss rate r rises threshold, suspendcurrent search, recompute pairwise alignments increased threshold ,resume main search improved heuristics.Like main search, accurately predict auxiliary computation timespace threshold using exponential fitting. Due lower dimensionality,generally increase less steeply; however, constant factor might higherkheuristic, due combinatorial numberalignment problems solved.doubling scheme explained bound overhead within constantfactor effort last iteration. way, also limiting heuristiccomputation time fixed fraction main search, ensure expectedupper bound overall execution time stays within constant factor searchtime would required using pairwise heuristic.knew exact relation , r, speedup main search, idealstrategy would double heuristic whenever expected computation time smallertime saved main search. However, illustrated Fig. 12, dependencecomplex simple exponential growth, varies search depth specificsproblem. Either would need elaborate model search space,607fiSchroedlalgorithm would conduct exploratory searches order estimate relation.leave issue future work, restrict simplified, conservativeheuristic: hypothesize main search made twice fast heuristicdoubling miss rate r rises 25 percent; experiments, foundassumption almost always true. event, since effective branching factormain search reduced improved heuristic, also ignore history main searchtimes exponential extrapolation procedure subsequent iterations.7. Experimental Resultsfollowing, compare IDDP one currently successful approaches,Partial Expansion . empirically explore benefit higher-dimensional heuristics;finally, show feasibility means benchmark database BAliBASE .7.1 Comparison Partial Expansionfirst series evaluations, ran IDDP set sequences chosenYoshizumi et al. (2000) (elongation factors EF-TU EF-1 various species,high degree similarity). work, substitution costs chosen accordingPAM-250 matrix. applied heuristic sum optimal pairwise goal distances.expansion numbers completely match results, however, since appliedbiologically realistic affine gap costs: gaps length x charged 8+8x, exceptbeginning end sequence, penalty 8 x.following experiments run RedHat Linux 7.3 Intel XeonTCPU 3.06 GHz, main memory 2 Gigabytes; used gcc 2.96 compiler.total space consumption search algorithm determined peak numberOpen Closed edges entire running time. Table 1 Fig. 13 give valuesseries successively larger sets input sequences (with sequences numbereddefined Yoshizumi et al., 2000) 1 4, 1 5, . . ., 1 12.implementation, basic algorithm could carried 9sequences, exhausting computers main memory.Confirming results Yoshizumi et al. (2000), Partial Expansion requiresone percent space. Interestingly, iteration peak total numbersnodes held memory, nodes actually closed except problem 6. mightexplained high degree similarity sequences example. RecallPEA closes node successors f -valueoptimal solution cost; span lower bound small, node leastone bad successor exceeds difference.IDDP reduces memory requirements factor 6. diagramalso shows maximum size Open list alone. sequences, differencetwo dominated linear length store solution path.problem size increases, however, proportion Closed list total memory drops12 percent 12 sequences. total number expansions (includingsearch stages) slightly higher PEA ; however, due optimizations made possiblecontrol expansion order, execution time 12 sequences reducedthird.608fiAn Improved Search Algorithm Optimal Multiple-Sequence AlignmentNumExpTime[sec]MaxOpenMaxOpen +Closed62615993267107811162612469550.010.050.251.9449.32318.587805321781245416660989314734358696718432337781278096768809430996361166273456789101112448716261063042327033094678039954534182088762736078736PEA0.010.010.050.332.6387.24457.987203.1762173.78237640.1444262615983328108741182772492791569815562092692659494426261598333110874118277249279156981556209269265949345678910111249613676776127702602636277957089844192972177486936202456IDDP0.010.020.140.592.4673.62250.484101.9643708.14158987.804917141488913620215061602408608801417151434443501972174919512300091923959971631616480456789Table 1: Algorithm comparison varying number input sequences (elongation factorsEF-TU EF-1).Since PEA prune edges, maximum space usage always total numberedges f -value smaller g (t) (call edges relevant edges, sinceinspected admissible algorithm). IDDP, hand, Open listcomprise k adjacent levels edges (not counting possible thresholdovershoot, would contribute factor 2). Thus, improvement IDDPPEA tend increase overall number levels (which sum609fiSchroedl1e+081e+07Edges memory1e+06100000100001000100A* max open+closedPEA* max open+closedIDDP max open+closedIDDP max open1013456789Number sequences101112Figure 13: Memory requirements , IDDP, PEA (elongation factors EF-TUEF-1).string lengths), divided number sequences; words, averagesequence length.Moreover, ratio depends well heuristic suits particular problem.Fig. 14 shows distribution edges f value smaller equal g (t),case 9 example sequences. problem quite extreme bulk edgesconcentrated small level band 1050 1150. exampleeven distribution, Fig. 15 depicts situation problem 1cpt Reference 1benchmark set BAliBASE (Thompson et al., 1999) heuristic hall,3 . case,proportion overall 19492675 relevant edges maximal among 4 adjacentlevels amounts 0.2 percent. maximum Open size IDDP 7196,total number edges generated PEA 327259, improvement factor45.7.2 Multidimensional Heuristicsset sequences, compared different improved heuristics order getimpression respective potential. Specifically, ran IDDP heuristics hpair ,hall,3 , hall,4 , hone,k/2 various thresholds . Fig. 16 shows total execution timecomputing heuristics, performing main search. case, manuallyselected value minimized time. seen times hone,k/2lie little bit hpair ; sequences (less six), computationheuristics hall,3 hall,4 dominates overall time. increasing dimensions, how610fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment0.016Open edges / sum open edges [%]0.0140.0120.010.0080.0060.0040.00200500100015002000Level2500300035004000Figure 14: Distribution relevant edges levels (elongation factors EF-TU EF-1);compare schematic projection Fig. 4.ever, investment starts yield growing returns, hall,3 fastest algorithm,requiring 5 percent time hpair 12 sequences.far memory concerned, Fig. 17 reveals maximum size OpenClosed list, chosen values, similar hpair hone,k/2 one hand,hall,3 hall,4 hand.12 sequences, hone,6 saves 60 percent edges, hall,3 needs 2.6percent hall,4 0.4 percent space required pairwise heuristic. UsingIDDP, never ran main memory; even larger test sets could aligned, rangeshown diagrams limited patience wait results twodays.Based experienced burden computing heuristic, Kobayashi Imai (1998)concluded hone,m preferred hall,m . quite agree judgment. see heuristic hall,m able reduce search space main searchconsiderably stronger hone,m , beneficial appropriateamount heuristic computation.7.3 Benchmark Database BAliBASEBAliBASE (Thompson et al., 1999) widely used database manually-refined multiplesequence alignments specifically designed evaluation comparison multiple sequence alignment programs. alignments classified 8 reference sets. Reference 1contains alignments six equidistant sequences. sequences sim611fiSchroedlOpen edges / sum open edges [%]0.000120.00018e-056e-054e-052e-0500200400600800Level1000120014001600Figure 15: Distribution relevant edges levels, problem 1cpt BAliBASE .ilar length; grouped 9 classes, indexed sequence length percentageidentical amino acids columns. Note many problems indeed much harder elongation factor examples previous section; despiteconsisting fewer sequences, dissimilarities much pronounced.applied algorithm Reference 1, substitution costs according PET91matrix (Jones et al., 1992) affine gap costs 9x+8, except leading trailing gaps,gap opening penalty charged. instances, precomputed pairwisesub-alignments fixed bound 300 optimal solution; optimal solutionfound within bound cases, effort generally marginal comparedoverall computation. problems involving three sequences, heuristichall,3 applied.82 alignment problems Reference 1, algorithm could solve 2problems (namely, 1pamA gal4 ) computer. Detailed results listed Tables 210.Thompson, Plewniak, Poch (1999) compared number widely used heuristicalignment tools using so-called SP -score; software calculates percentagecorrectly aligned pairs within biologically significant motifs. found programs perform equally well sequences medium high amino acididentity; differences occurred case distant sequences less25 percent identity, so-called twilight zone. Particularly challenginggroup short sequences. subgroup, three highest scoring programs PRRP,CLUSTALX, SAGA, respective median scores 0.560, 0.687, 0.529.medium score alignments found experiments amounts 0.558; hence,good PRRP, beaten CLUSTALX. focused exper612fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment1e+0610000010000Total time [sec]10001001010.12-fold heuristicdiv-conq heuristic3-fold heuristic4-fold heuristic0.010.001246810Number sequences1214Figure 16: Comparison execution times (including calculation heuristics), elongationfactors EF-TU EF-1.iments algorithmic feasibility rather solution quality, would worthwhileattempt improve alignments found program using refinedpenalty functions. CLUSTALX, example, uses different PAM matrices dependingevolutionary distance sequences; moreover, assigns weights sequences (basedphylogenetic tree), gap penalties made position-specific. improvements easily integrated basic sum-of-pairs cost function, couldattempt compute optimal alignment respect metrics. leave lineresearch future work.Fig. 18 shows maximum number edges stored Opensearch, dependence search threshold final iteration. better comparability,included problems diagram consist 5 sequences. logarithmicscale emphasizes growth fits exponential curve quite well. Roughly speaking,increase cost threshold 50 leads ten-fold increase space requirements.relation similarly applicable number expansions (Fig. 19).Fig. 20 depicts proportion maximum Open list size combinedmaximum size Open Closed. clearly visible due pruning edgesoutside possible solution paths, Closed list contributes less less overallspace requirements difficult problems become.Finally, estimate reduction size Open list compared relevantedges ratio maximum Open size last iteration IDDP totalnumber expansions stage, equal number edges f -valueless equal threshold. Considering possible overshoot IDDP, algorithm PEA613fiSchroedlMaximum size open + closed1e+071e+061000001000010002-fold heuristicdiv-conq heuristic3-fold heuristic4-fold heuristic100246810Number sequences1214Figure 17: Combined maximum size Open Closed, different heuristics (elongationfactors EF-TU EF-1).1e+071e+06Max open10000010000100010010ShortMedium lengthLong1050100150200Threshold - Lower bound250300Figure 18: Maximum size Open list, dependent final search threshold (BAliBASE ).614fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment1e+081e+07Expansions1e+06100000100001000100ShortMedium lengthLong10050100150200Threshold - Lower bound250300Figure 19: Number expansions final search iteration (BAliBASE ).80Max open/ Max open + closed [%]70605040302010ShortMedium lengthLong0050100150200Threshold - Lower bound250300Figure 20: Maximum number Open edges, divided combined maximum OpenClosed (BAliBASE ).615fiSchroedl5ShortMedium lengthLongMax Open / Expansions [%]43210050100150200Threshold - Lower bound250300Figure 21: Percentage reduction Open size (BAliBASE ).would expand least half nodes. proportion ranges 0.5 5 percent(cf. Fig. 21). considerable scatter indicates dependence individual problem properties; however, slight average decrease noticed difficult problems.616fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment8. Conclusion Discussionpresented new search algorithm optimal multiple sequence alignmentcombines effective use heuristic bound best-first search abilitydynamic programming approach reduce maximum size Open Closed listsone order magnitude sequence length. algorithm performs seriessearches successively increasing bounds explore search space DP order;thresholds chosen adaptively expected overhead recomputationsbounded constant factor.demonstrated algorithm outperform one currentlysuccessful algorithms optimal multiple sequence alignments, Partial Expansion ,terms computation time memory consumption. Moreover, iterative-deepeningstrategy alleviates use partially computed higher-dimensional heuristics. bestknowledge, algorithm first one able solve standard benchmarkalignment problems BAliBASE biologically realistic cost function including affinegap costs without end gap penalties. quality alignment rangebest heuristic programs; concentrated algorithmic feasibility, deemworthwhile incorporate refined cost metrics better results; studyquestion future work.Recently, learned related approaches developed simultaneously independently Zhou Hansen (2003b, 2004). SweepA explores search graph accordinglayers partial order, still uses f -value selecting nodes within one layer.Breadth-First Heuristic Search implicitly defines layers graph uniform costsaccording breadth-first traversal. algorithms incorporate upper boundsoptimal solution cost pruning; however, idea adaptive threshold determinationlimit re-expansion overhead constant factor described. Moreover,consider flexible use additional memory minimize divide-and-conquer solutionreconstruction phase.Although described algorithm entirely within framework MSA problem,straightforward transfer domain state space graph directedacyclic. Natural candidates include applications ordering imposedtime space coordinates, e.g., finding likely path Markov model.Two BAliBASE benchmark problems could still solved algorithmwithin computers main memory limit. Future work include integrationtechniques exploiting secondary memory. expect level-wise exploration schemealgorithm lends naturally external search algorithms, another currentlyactive research topic Artificial Intelligence theoretical computer science.Acknowledgmentsauthor would like thank reviewers article whose comments helpedsignificantly improving it.617fiSchroedlAppendixTable 2: Results BAliBASE Reference 1, group short sequences low amino acididentity. columns denote: number aligned sequences; upperbound precomputing optimal solutions partial problems last iterationmain search; g (t) optimal solution cost; h(s) lower bound solution cost,using heuristics; #Exp total number expansions iterations mainsearch; #Op peak number edges Open list course search;#Op+Cl peak combined number edges either Open Closed listsearch; #Heu peak number subalignment edge costs stored heuristic;Time: total running time including auxiliary main search, seconds; Mempeak total memory usage face alignments, heuristic, main search,KB.1aboA1idy1r691tvxA1ubi1wit2trx554445457502044306920g (t)90068165621555327395142877918h(s)88988075618354887357141767899#Exp3413786173200863484412638491614286623137863692#Op104613748651993824226263152090613502#Op+Cl1761261214044171948633540593515825790#Heu1654547970933888024766222895992442098127490Time331.029167.86722.51752.86062.133578.9074.572Mem1556810893356852785448272731861Table 3: Short sequences, medium similarity.1aab1fjlA1hfh1hpi1csy1pfc1tgxA1ycc3cyr451c465455444520203020303020204849g (t)600213673165565858140771534148918926848011440h(s)598413625165045835140261527748568903843111333#Exp26390013791415605271811854318987540495832601213162#Op121064852833872647754311181342238004618#Op+Cl83155846516456138905108020102580654115#Heu4404195737047152695619155887550777156193690583363Time0.5720.98514.0770.6796.16511.8501.1963.78022.592111.675Mem6911589288265622522478649164430766529fiAn Improved Search Algorithm Optimal Multiple-Sequence AlignmentTable 4: Short sequences, high similarity.55454555551aho1csp1dox1fkj1fmb1krn1plc2fxb2mhr9rnt20202020202020202020g (t)82518434741613554757197521217769501431712382h(s)81878427740513515756897471215269501430612367#Exp3020090782262117210145488256350#Op225525014041252419#Op+Cl3074781862221088710371121108#Heu1097135288406109251804624410641143278536100Time3.1750.5690.6520.9450.5400.6230.7280.5340.6680.695Mem104278482315117881035141561715581250Table 5: Medium-length sequences, low similarity.1bbt31sbp1havA1uky2hsdA2pia3grskinase555444451602002009496161126200g (t)3059842925316001804621707227552022245985h(s)3027742512312341791521604226162006145520#Exp9027257892144000052248880644417980279165580608976694701076820322446667393#Op1113460868392691089127165943529335778944664039113931051#Op+Cl15739188118829901632137612813396689261673807139698219688961#Heu2382176765341855586398511523333812497761257187702410471032422084Time43860.175106907.000132576.0007006.5602646.8804310.0304267.880125170.460Mem92773573505392773510618467788142318130425927734Table 6: Medium-length sequences, medium similarity.1ad21aym31gdoA1ldg1mrj1pgtA1pii1ton2cba44444445520205820205020102160g (t)168521900720696257642079017442208373256440196h(s)168431897820613257362075117398208253242839914#Exp379466536107950404461232526011870204252561357188760545205#Op1648015711049814067192005843511741037828619#Op+Cl2218914102615905273803247614145261021595955#Heu27887836341265777169038339424859471166701154990819186631Time0.95915.386363.54916.1158.69473.0663.0891373.1802904.651Mem2186316312028448429055869333858704140712fiSchroedlTable 7: Medium-length sequences, high similarity.54545445451amk1ar5A1ezm1led1ppn1pysA1thm1tis1zin5ptp20202020202020202020g (t)31473152093739618795272031924221470354441656229776h(s)31453151863738118760271591921521460353951654629735#Exp4473985613932201851710810361319967716558#Op712842956489190244823309#Op+Cl2593563244951864801293915225539#Heu131202222015751399622020914344809042716661937883Time0.8251.0660.8363.7612.5451.2000.6824.4090.6541.767Mem3366175539002564299122242469412217673600Table 8: Long sequences, low similarity.1ajsA1cpt1lvl1ped2myr4enl4443431601601605020050g (t)383823974543997153514341416146h(s)381733962843775152074308416011#Exp318460012873548537914936256605237400176455169296#Op112669752601335670798675967309650#Op+Cl2310632129542706940277184548890830991#Heu27102589104945643749141601187471840Time9827.233223.92616473.42020.035136874.98041.716#Heu184641199617610181684912801019147615460403753131836459626403585721758199943836853022622910Time6815.7607.8298795.000843.402334.475348.1342251.190505.778463.96232965.52215972.000733.202Mem2089513211925512344479277355589Table 9: Long sequences, medium similarity.1ac51adj1bgl1dlc1eft1fieA1gowA1pkm1sesA2ackarpglg444444445555922024310656861668958250143160g (t)371473281578366474303137753321387843635657670769375493974282h(s)370203278578215473373130153241386323625657557764665469674059#Exp1697798712070721884291181499331793799996905957455907391119789047559839942258561826351679251905#Op732333310685700865288426204677927525675144960148077412129118587916620#Op+Cl1513853514517441491266087250290937544800140472136677124369282160263120180Mem124877459529161843158131152688499537272442745276571519336472148fiAn Improved Search Algorithm Optimal Multiple-Sequence AlignmentTable 10: Long sequences, high similarity.1ad31gpb1gtr1lcf1rthA1taq3pmgactin455655452054601601282505153g (t)3364110129655242149249692961337234219348924h(s)3360410123155133148854691331333214213348826#Exp104627123270720376331818101481489153816935016281036943824295621#Op221862184544963235312710819384718851135283#Op+Cl346198476916563824010105082172984561554053009#Heu34539270294919161272861421524587882145223167777639777058Time4.196178.610226.79115363.0511721.0705713.24050.79696.147Mem39682569818050294688705691170673813311198fiSchroedlReferencesAltschul, S., Gish, W., Miller, W., Myers, E., & Lipman, D. (1990). Basic local alignmentsearch tool. Journal Molecular Biology, 215, 403410.Altschul, S. F. (1989). Gap costs multiple sequence alignment. Journal TheoreticalBiology, 138, 297309.Carrillo, H., & Lipman, D. (1988). multiple sequence alignment problem biology.SIAM Journal Applied Mathematics, 5 (48), 10731082.Chan, S. C., Wong, A. K. C., & Chiu, D. K. Y. (1992). survey multiple sequencecomparison techniques. Bulletin Mathematical Biology, 54 (4), 563598.Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence,14 (4), 318334.Davidson, A. (2001). fast pruning algorithm optimal sequence alignment. Proceedings 2nd IEEE International Symposium Bioinformatics Bioengineering(BIBE2001), pp. 4956.Dayhoff, M. O., Schwartz, R. M., & Orcutt, B. C. (1978). model evolutionary changeproteins. Dayhoff, M. O. (Ed.), Atlas Protein Sequence Structure, pp.345352, Washington, D.C. National Biomedical Research Foundation.Dial, R. B. (1969). Shortest-path forest topological ordering. Comm. ACM, 12 (11),632633.Dijkstra, E. W. (1959). note two problems connection graphs.. NumerischeMathematik, 1, 269271.Gupta, S., Kececioglu, J., & Schaeffer, A. (1995). Improving practical space timeefficiency shortest-paths approach sum-of-pairs multiple sequence alignment.J. Computational Biology, 2 (3), 459472.Gusfield, D. (1993). Efficient methods multiple sequence alignment guaranteederror bounds. Bull. Math. Biol., 55 (1), 141154.Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determinationminimum path cost. IEEE Trans. Systems Science Cybernetics, 4, 100107.Hirschberg, D. S. (1975). linear space algorithm computing maximal common subsequences. Comm. ACM, 6 (18), 341343.Ikeda, T., & Imai, H. (1994). Fast A* algorithms multiple sequence alignment.Proceedings Genome Informatics Workshop, pp. 9099.Jones, D. T., Taylor, W. R., & Thornton, J. M. (1992). rapid generation mutationdata matrices protein sequences. CABIOS, 3, 275282.Kobayashi, H., & Imai, H. (1998). Improvement A* algorithm multiple sequencealignment. Miyano, S., & Takagi, T. (Eds.), Genome Informatics, pp. 120130,Tokyo. Universal Academy Press.Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.Artificial Intelligence, 27 (1), 97109.622fiAn Improved Search Algorithm Optimal Multiple-Sequence AlignmentKorf, R. E. (1999). Divide-and-conquer bidirectional search: First results. ProceedingsSixteenth International Conference Artificial Intelligence (IJCAI-99), pp.11811189, Stockholm, Sweden.Korf, R. E., & Zhang, W. (2000). Divide-and-conquer frontier search applied optimalsequence alignment. Proceedings Eighteenth National Conference ArtificialIntelligence (AAAI-00), pp. 210216.McNaughton, M., Lu, P., Schaeffer, J., & Szafron, D. (2002). Memory-efficient A* heuristicsmultiple sequence alignment. Proceedings Eighteenth National ConferenceArtificial Intelligence (AAAI-02), Edmonton, Alberta, Canada.Spouge, J. L. (1989). Speeding dynamic programming algorithms finding optimallattice paths. SIAM J. Applied Mathematics, 49 (5), 15521566.Thompson, J. D., Plewniak, F., & Poch, O. (1999). comprehensive comparison multiplesequence alignment programs. Nucleic Acids Res., 13 (27), 26822690.Ukkonen, E. (1985). Algorithms approximate string matching. Information Control,64, 110118.Wah, B. W., & Shang, Y. (1995). comparison class IDA* search algorithms.International Journal Tools Artificial Intelligence, 3 (4), 493523.Wang, L., & Jiang, T. (1994). complexity multiple sequence alignment. JournalComputational Biology, 1, 337348.Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branchingfactor problems. AAAI/IAAI, pp. 923929.Zhou, R., & Hansen, E. A. (2003a). Sparse-memory graph search. 18th InternationalJoint Conference Artificial Intelligence (IJCAI-03), Acapulco, Mexico.Zhou, R., & Hansen, E. A. (2003b). Sweep A*: Space-efficient heuristic search partiallyordered graphs. 15th IEEE International Conference Tools Artificial Intelligence, Sacramento, CA.Zhou, R., & Hansen, E. A. (2004). Breadth-first heuristic search. Fourteenth International Conference Automated Planning Scheduling (ICAPS-04), Whistler, BC,Canada.623fiJournal Artificial Intelligence Research 23 (2005) 1-40Submitted 05/04; published 01/05Finding Approximate POMDP Solutions BeliefCompressionNicholas Roynickroy@mit.eduMassachusetts Institute Technology,Computer Science Artificial Intelligence LaboratoryCambridge,Geoffrey Gordonggordon@cs.cmu.eduCarnegie Mellon University, School Computer SciencePittsburgh, PASebastian Thrunthrun@stanford.eduStanford University, Computer Science DepartmentStanford, CAAbstractStandard value function approaches finding policies Partially Observable MarkovDecision Processes (POMDPs) generally considered intractable large models.intractability algorithms large extent consequence computingexact, optimal policy entire belief space. However, real-world POMDPproblems, computing optimal policy full belief space often unnecessarygood control even problems complicated policy classes. beliefs experiencedcontroller often lie near structured, low-dimensional subspace embeddedhigh-dimensional belief space. Finding good approximation optimal value functionsubspace much easier computing full value function.introduce new method solving large-scale POMDPs reducing dimensionality belief space. use Exponential family Principal Components Analysis (Collins, Dasgupta, & Schapire, 2002) represent sparse, high-dimensional belief spacesusing small sets learned features belief state. plan termslow-dimensional belief features. planning low-dimensional space, findpolicies POMDP models orders magnitude larger modelshandled conventional techniques.demonstrate use algorithm synthetic problem mobile robotnavigation tasks.1. IntroductionDecision making one central problems artificial intelligence robotics.robots deployed world accomplish specific tasks, real worlddifficult place actactions serious consequences. Figure 1(a) depictsmobile robot, Pearl, designed operate environment shown Figure 1(b),Longwood retirement facility Pittsburgh. Real world environments Longwoodcharacterized uncertainty; sensors cameras range finders noisyentire world always observable. large number state estimation techniquesexplicitly recognize impossibility correctly identifying true state world(Gutmann, Burgard, Fox, & Konolige, 1998; Olson, 2000; Gutmann & Fox, 2002; Kanazawa,c2005AI Access Foundation. rights reserved.fiRoy, Gordon, & ThrunKoller, & Russell, 1995; Isard & Blake, 1998) using probabilistic techniques tracklocation robot. state estimators Kalman filter (Leonard & DurrantWhyte, 1991) Markov localization (Fox, Burgard, & Thrun, 1999; Thrun, Fox, Burgard,& Dellaert, 2000) provide (possibly factored, Boyen & Koller, 1998) distributionpossible states world instead single (possibly incorrect) state estimate.(a)Figure 1:(b)planner mobile robot Pearl, shown (a), must able navigatereliably real environments Longwood Oakmont retirement facility,shown (b). white areas map free space, black pixelsobstacles, grey areas regions map uncertainty. Noticelarge open spaces, many symmetries lead ambiguity robotsposition. map 53.6m 37.9m, resolution 0.1m 0.1m per pixel.contrast, controllers motion planners, dialogue systems, etc. rarely modelnotions uncertainty. state estimate full probability distribution,controller often uses heuristic extract single best state, distributionsmean mode. planners compensate inevitable estimation errors robust control (Chen, 2000; Bagnell & Schneider, 2001), deployed systems incorporatefull probabilistic state estimate planning. Although most-likely-state methodsimple used successfully real applications (Nourbakhsh, Powers, &Birchfield, 1995), substantial control errors result distribution possiblestates uncertain. single state estimate wrong, planner likely chooseunreasonable action.Figure 2 illustrates difference conventional controllers modeluncertainty. figure, robot must navigate bottom right corner topleft, limited range sensing (up 2m) noisy dead reckoning.1 impoverished1. purposes example sensing dead reckoning artificially poor,phenomenon would occur naturally larger-scale environments.2fiFinding Approximate POMDP Solutions Belief Compressionsensor data cause robots state estimate become quite uncertain straysfar environmental structures use localize itself. left (Figure 2a)example trajectory motion planner knowledge uncertaintystate estimate mechanism taking uncertainty account. robotstrajectory diverges desired path, robot incorrectly believes arrivedgoal. shown state estimates reflect high uncertaintyrobot position. right (Figure 2b) example trajectory controllermodel positional uncertainty, take action keep uncertainty small followingwalls, arrive reliably goal.GoalGoalMeasured PathMeasured PathTrue PathTrue PathStartStart(a) Conventional controllerFigure 2:(b) Robust controllerTwo possible trajectories navigation Longwood Oakmont environment. robot limited range sensing (up 2m) poor dead-reckoningodometry. (a) trajectory conventional motion planner usessingle state estimate, minimizes travel distance. (b) trajectoryrobust controller models state uncertainty minimize traveldistance uncertainty.controller Figure 2(b) derived representation called partially observable Markov decision process (POMDP). POMDPs technique making decisionsbased probabilistic estimates state world, rather absolute knowledgetrue state. POMDP uses priori model world together historyactions taken observations received order infer probability distribution,belief, possible states world. controller chooses actions, based uponcurrent belief, maximize reward expects receive time.advantage using POMDPs decision making resulting policieshandle uncertainty well. POMDP planning process take advantage actionsimplicitly reduce uncertainty, even problem specification (e.g., reward function)explicitly reward actions. disadvantage POMDPs findingoptimal policy computationally intractable. Existing techniques finding exact optimal3fiRoy, Gordon, & Thrunplans POMDPs typically cannot handle problems hundred states(Hauskrecht, 2000; Zhang & Zhang, 2001). planning problems involving real, physicalsystems cannot expressed compactly; would like deploy robots planthousands possible states world (e.g., map grid cells), thousands possibleobservations (e.g., laser range measurements) actions (e.g., velocities).paper, describe algorithm finding approximate solutions realworld POMDPs. algorithm arises insight exact POMDP policies useunnecessarily complex, high-dimensional representations beliefs controllerexpect experience. finding low-dimensional representations, planning processbecomes much tractable.first describe find low-dimensional representations beliefs realworld POMDPs; use variant common dimensionality-reduction techniquecalled Principal Components Analysis. particular variant use modifies lossfunction PCA order better model data probability distributions. Usinglow-dimensional representations, describe plan low-dimensional space,conclude experimental results robot control tasks.2. Partially Observable Markov Decision Processespartially observable Markov decision process (POMDP) model decidingact accessible, stochastic environment known transition model (RussellNorvig (1995), pg. 500). POMDP described following:set states = {s1 , s2 , . . . s|S| }set actions = {a1 , a2 , . . . , a|A| }set observations Z = {z1 , z2 , . . . , z|Z| }set transition probabilities (si , a, sj ) = p(sj |si , a)set observation probabilities O(zi , a, sj ) = p(zi |sj , a)set rewards R : 7 Rdiscount factor [0, 1]initial belief p0 (s)transition probabilities describe state evolves actions, also represent Markov assumption: next state depends current (unobservable)state action independent preceding (unobserved) states actions.reward function describes objective control, discount factor usedensure reasonable behaviour face unlimited time. optimal policy knownalways exist discounted ( < 1) case bounded immediate reward (Howard,1960).POMDP policies often computed using value function belief space.value function V (b) given policy defined long-term expected rewardcontroller receive starting belief b executing policy horizon time,may infinite. optimal POMDP policy maximizes value function.value function POMDP policy finite horizon described using piecewise linear function space beliefs. Many algorithms compute value functioniteratively, evaluating refining current value function estimate4fiFinding Approximate POMDP Solutions Belief Compressionrefinements improve expected reward policy belief. Figure 3(a)shows belief space three-state problem. belief space two-dimensional,shaded simplex. point simplex corresponds particular belief (a threedimensional vector), corners simplex represent beliefs stateknown 100% certainty. value function shown Figure 3(b) gives long-termexpected reward policy, starting belief simplex.11090.8870.6650.4430.2200100.20.20.40.60.8100.20.40.60.80.410.60.81(a) belief spaceFigure 3:00.20.40.60.81(b) value function(a) belief space three-state problem two-dimensional, shadedsimplex. (b) value function defined belief space. purposesvisualization, set beliefs constitutes belief space shown (a)projected onto XY plane (b); value function rises alongpositive Z axis. point belief space corresponds specificdistribution, value function point gives expected rewardpolicy starting belief. belief space (and therefore valuefunction) one fewer dimension total number statesproblem.process evaluating refining value function core solvingPOMDPs considered intractable. value function defined spacebeliefs, continuous high-dimensional; belief space one fewerdimension number states model. navigation problem mapthousands possible states, computing value function optimization problemcontinuous space many thousands dimensions, feasible existingalgorithms.However, careful consideration real-world problems suggests possible approachfinding approximate value functions. examine beliefs navigating mobilerobot encounters, beliefs share common attributes. beliefs typicallysmall number modes, particular shape modes fairly generic. modesmove change variance, ways modes change relativelyconstrained. fact, even real world navigation problems large belief spaces,beliefs degrees freedom.Figure 4(a) illustrates idea: shows typical belief mobile robot mightexperience navigating nursing home environment Figure 1(b). visualizedistribution sample set poses (also called particles) according distribution5fiRoy, Gordon, & Thrunplot particles map. distribution unimodal probability massmostly concentrated small area. Figure 4(b) shows different kind belief:probability mass spread wide area, multiple modes, locationsparticles bear little relationship map. would difficult find sequenceactions observations would result belief.particles(a) common beliefFigure 4:(b) unlikely beliefTwo example probability distributions robot pose. small black dotsparticles drawn distribution discrete grid positions. leftdistribution robots location relatively certain; kind compact,unimodal distribution common robot navigation. rightdifferent, implausible distribution. right hand distribution sufficientlyunlikely afford ignore it; even unable distinguishbelief belief result fail identify optimal action,quality controller unaffected.real-world beliefs degrees freedom, concentrated nearlow-dimensional subset high-dimensional belief spacethat is, beliefs experiencedcontroller lie near structured, low-dimensional surface embedded beliefspace. find surface, representation belief state termssmall set bases features. One benefit representation needplan terms small set features: finding value functions low-dimensionalspaces typically easier finding value functions high-dimensional spaces.two potential disadvantages sort representation. firstcontains approximation: longer finding complete, optimal POMDP policy.Instead (as suggested Figure 5) trying find representations beliefrich enough allow good control also sufficiently parsimonious make6fiFinding Approximate POMDP Solutions Belief Compressionplanning problem tractable. second disadvantage technical one:making nonlinear transformation belief space, POMDP planning algorithmsassume convex value function longer work. discuss problem detailSection 6.ConventionalPath PlannerPOMDPTractableRobustFigure 5:IntractableRobustuseful planner lies somewhere continuum MDP-styleapproximations full POMDP solution.3. Dimensionality Reductionorder find low-dimensional representation beliefs, use statistical dimensionality reduction algorithms (Cox & Cox, 1994). algorithms search projectionoriginal high-dimensional representation beliefs lower-dimensional compact representation. is, search low-dimensional surface, embeddedhigh-dimensional belief space, passes near sample beliefs. considerevolution beliefs POMDP trajectory inside belief space, assumption trajectories large, real world POMDPs lie near low-dimensionalsurface embedded belief space. Figure 6 depicts example low-dimensional surfaceembedded belief space three-state POMDP described previous section.10.80.60.40.2000.20.40.60.81Figure 6:00.20.40.60.81one-dimensional surface (black line) embedded two-dimensional belief space(gray triangle). black dot represents single belief probability distributionexperienced controller. beliefs lie near low-dimensional surface.Ideally, dimensionality reduction involves information lossall aspects datarecovered equally well low-dimensional representation highdimensional one. practice, though, see use lossy representationsbelief (that is, representations may allow original data beliefsrecovered without error) still get good control. But, also see findingrepresentations probability distributions require careful trade-off7fiRoy, Gordon, & Thrunpreserving important aspects distributions using dimensions possible.measure quality representation penalizing reconstruction errorsloss function (Collins et al., 2002). loss function provides quantitative waymeasure errors representing data, different loss functions result differentlow-dimensional representations.Principal Components AnalysisOne common forms dimensionality reduction Principal Components Analysis (Joliffe, 1986). Given set data, PCA finds linear lower-dimensional representation data variance reconstructed data preserved. Intuitively,PCA finds low-dimensional hyperplane that, project data ontohyperplane, variance data changed little possible. transformationpreserves variance seems appealing maximally preserve ability distinguish beliefs far apart Euclidean norm. see below, however,Euclidean norm appropriate way measure distance beliefsgoal preserve ability choose good actions.first assume data set n beliefs {b1 , . . . , bn } B, belief biB, high-dimensional belief space. write beliefs column vectorsmatrix B = [b1 | . . . |bn ], B R|S|n . use PCA compute low-dimensionalrepresentation beliefs factoring B matrices U B,B = U B .(1)equation (1), U R|S|l corresponds matrix bases span low-dimensionalspace l < |S| dimensions. B Rnl represents data low-dimensional space.2geometric perspective, U comprises set bases span hyperplane Bhigh-dimensional space B; B co-ordinates data hyperplane.hyperplane dimensionality l exists contains data exactly, PCA find surface given dimensionality best preserves variance data, projectingdata onto hyperplane reconstructing it. Minimizing change variance original data B reconstruction U B equivalent minimizingsum squared error loss:L(B, U, B) = kB U B k2F .(2)PCA PerformanceFigure 7 shows toy problem use evaluate success PCA findinglow-dimensional representations. abstract model two-dimensional state space:one dimension position along one two circular corridors, one binary variabledetermines corridor in. States s1 . . . s100 inclusive correspond one corridor,states s101 . . . s200 correspond other. reward known positiondifferent corridor; therefore, agent needs discover corridor, move2. Many descriptions PCA based factorization U SV , U V column-orthonormaldiagonal. could enforce similar constraint identifying B = V S; case columns Uwould orthonormal B would orthogonal.8fiFinding Approximate POMDP Solutions Belief Compressionappropriate position, declare arrived goal. goal declaredsystem resets (regardless whether agent actually goal). agent4 actions: left, right, sense_corridor, declare_goal. observationtransition probabilities given discretized von Mises distributions (Mardia & Jupp,2000; Shatkay & Kaelbling, 2002), exponential family distribution defined [ : ).von Mises distribution wrapped analog Gaussian; accounts facttwo ends corridor connected. sum two von Mises variatesanother von Mises variate, product two von Mises likelihoodsscaled von Mises likelihood, guarantee true belief distribution alwaysvon Mises distribution corridor action observation.instance problem consists 200 states, 4 actions 102 observations.Actions 1 2 move controller left right (with von Mises noise) action3 returns observation uniquely correctly identifies half mazeagent (the top half bottom half). Observations returned actions 1 2identify current state modulo 100: probability observation von Misesdistribution mean equal true state (modulo 100). is, observationsindicate approximately agent horizontally.Max Prob.Obs. = #11Max Prob.Obs. = #32Max Prob.Obs. = #534103104561051067Reward101102107......Max Prob.Obs. = #100100Observation "top"action #3 prob. 1RewardObservation "bottom"action #3 prob. 1200Figure 7: toy maze 200 states.maze interesting relatively large POMDP standards (200 states)contains particular kind uncertaintythe agent must use action 3 pointuniquely identify half maze in; remaining actions result observationscontain information corridor agent in. problem largesolved conventional POMDP value iteration, structured heuristicpolicies also perform poorly.collected data set 500 beliefs assessed performance PCA beliefsproblem. data collected using hand-coded controller, alternatingrandom exploration actions MDP solution, taking current statemaximum-likelihood state belief. Figure 8 shows 4 sample beliefs dataset. Notice beliefs essentially two discretized von Mises distributionsdifferent weights, one half maze. starting belief stateleft-most distribution Figure 8: equal probability top bottom corridors,position along corridor following discretized von Mises distribution concentrationparameter 1.0 (meaning p(state) falls 1/e maximum value move 1/4way around corridor likely state).9fiRoy, Gordon, & ThrunSample BeliefSample Belief0.040.040.0350.0350.030.030.0250.0250.020.0150.010.020.0150.010.0050.00500-0.0050204060-0.00580 100 120 140 160 180 200StateProbability0.030.025ProbabilityProbabilitySample Belief0.040.0350.020.0150.010.00500204060-0.00580 100 120 140 160 180 200State020406080 100 120 140 160 180 200StateSample Belief0.140.12Probability0.10.080.060.040.020Figure 8:020406080100 120 140 160 180 200StateSample beliefs toy problem, sample set 500, different (noncontiguous) points time. left-most belief initial belief state.Figure 9 examines performance PCA representing beliefs data setcomputing average error original beliefs B reconstructions U B.3Figure 9(a) see average squared error (squared L2 ) compared numberbases, Figure 9(b), see average Kullbach-Leibler (KL) divergence.KL divergence belief b reconstruction r = U b low-dimensionalrepresentation b givenKL(b k r) =|S|Xb(si ) lni=1b(si )r(si )(3)Minimizing squared L2 error explicit objective PCA, KL divergenceappropriate measure much two probability distributions differ. 4Unfortunately, PCA performs poorly representing probability distributions. Despitefact probability distributions collected data set 3 degreesfreedom, reconstruction error remains relatively high somewhere 1015 basis functions. examine reconstruction sample belief, seekinds errors PCA making. Figure 10 shows sample belief (the solid line)reconstruction (the dotted line). Notice reconstructed belief strangeartifacts: contains ringing (multiple small modes), also negative regions.PCA purely geometric process; notion original data probabilitydistributions, therefore free generate reconstructions data containnegative numbers sum 1.3. use popular implementation PCA based Golub-Reinsche algorithm (Golub & Reinsch,1970) available GNU Scientific Library (Galassi, Davies, Theiler, Gough, Jungman, Booth,& Rossi, 2002).4. Note computing KL divergence reconstruction original belief,shift reconstruction non-negative, rescale sum 1.10fiFinding Approximate POMDP Solutions Belief CompressionAverage L2 Error vs. Number BasesAverage KL Divergence vs. Number Bases0.021.6Average KL Divergence1.4Average L2 Error0.0150.010.00501.210.80.60.40.2005101520Number Bases25300(a) Average Squared L-2 ErrorFigure 9:5101520Number Bases2530(b) Average KL Divergenceaverage error original sample set B reconstructions U B.(a) Squared L2 error, explicitly minimized PCA, (b) KL divergence.error bars represent standard deviation mean error500 beliefs.Example Belief Reconstruction0.045Original BeliefReconstructed Belief0.04Probability0.0350.030.0250.020.0150.010.0050-0.005020406080100 120 140 160 180 200StateFigure 10: example belief reconstruction, using 10 bases.Notice also PCA process making significant errors lowprobability regions belief. particularly unfortunate real-world probability distributions tend characterized compact masses probability, surroundedlarge regions zero probability (e.g., Figure 4a). therefore need modifyPCA ensure reconstructions probability distributions, improve representation sparse probability distributions reducing errors made low-probabilityevents.question answered loss functions available instead sumsquared errors, equation (2). would like loss function better reflectsneed represent probability distributions.11fiRoy, Gordon, & Thrun4. Exponential Family PCAconventional view PCA geometric one, finding low-dimensional projectionminimizes squared-error loss. alternate view probabilistic one:data consist samples drawn probability distribution, PCA algorithmfinding parameters generative distribution maximize likelihooddata. squared-error loss function corresponds assumption datagenerated Gaussian distribution. Collins et al. (2002) demonstrated PCAgeneralized range loss functions modeling data different exponentialfamilies probability distributions Gaussian, binomial, Poisson.exponential family distribution corresponds different loss function variantPCA, Collins et al. (2002) refer generalization PCA arbitrary exponentialfamily data-likelihood models Exponential family PCA E-PCA.E-PCA model represents reconstructed data using low-dimensional weightvector b, basis matrix U , link function f :b f (U b)(4)E-PCA model uses different link function, derived datalikelihood model (and corresponding error distribution loss function). linkfunction mapping data space another space datalinearly represented.link function f mechanism E-PCA generalizes dimensionality reduction non-linear models. example, identity link function correspondsGaussian errors reduces E-PCA regular PCA, sigmoid link functioncorresponds Bernoulli errors produces kind logistic PCA 0-1 valued data.nonlinear link functions correspond non-Gaussian exponential familiesdistributions.find parameters E-PCA model maximizing log-likelihooddata model, shown (Collins et al., 2002) equivalentminimizing generalized Bregman divergenceBF (b k U b) = F (U b) b U b + F (b)(5)low-dimensional high-dimensional representations, solve usingconvex optimization techniques. (Here F convex function whose derivative f ,F convex dual F . ignore F purpose minimizing equation 5since value b fixed.) relationship PCA E-PCA linkfunctions reminiscent relationship linear regression Generalized LinearModels (McCullagh & Nelder, 1983).apply E-PCA belief compression, need choose link function accurately reflects fact beliefs probability distributions. choose linkfunctionf (U b) = eU b(6)P U bPhard verify F (U b) =e F (b) = b ln b b. So, equation 5becomesXXBF (b k U b) =eU b b U b + b ln bb(7)12fiFinding Approximate POMDP Solutions Belief Compressionwrite b = f (U b), equation 7 becomesBF (b k U b) = b ln b b ln b +XbXb = U KL(b k b)U KL unnormalized KL divergence. Thus, choosing exponential link function (6) corresponds minimizing unnormalized KL divergence originalbelief reconstruction. loss function intuitively reasonable choice measuring error reconstructing probability distribution.5 exponential link functioncorresponds Poisson error model component reconstructed belief.choice loss link functions two advantages: first, exponential linkfunction constrains low-dimensional representation eU b positive. Second, errormodel predicts variance belief component proportional expectedvalue. Since PCA makes significant errors close 0, wish increase penaltyerrors small probabilities, error model accomplishes that.compute loss bi , ignoring terms depend data b, then6L(B, U, B) =|B|Xi=1eU bi bi U bi .(8)introduction link function raises question: instead using complexmachinery E-PCA, could choose non-linear function project dataspace linear, use conventional PCA? difficultyapproach course identifying function; general, good link functions E-PCArelated good nonlinear functions application regular PCA. So,might appear reasonable use PCA find low-dimensional representation logbeliefs, rather use E-PCA exponential link function find representationbeliefs directly, approach performs poorly surface locallywell-approximated log projection. E-PCA viewed minimizing weightedleast-squares chooses distance metric appropriately local. Using conventionalPCA log beliefs also performs poorly situations beliefs contain extremelysmall zero probability entries.P5. chosen link function eU b / eU b would arrived normalized KL divergence,perhaps even intuitively reasonable way measure error reconstructingprobability distribution. more-complicated link function would made difficultderive Newton equations following pages, impossible; experimentedresulting algorithm found produces qualitatively similar results algorithm describedhere. Using normalized KL divergence one advantage: allow us get awayone fewer basis function planning, since unnormalized KL divergence E-PCA optimizationmust learn basis explicitly represent normalization constant.6. E-PCA related Lee Seungs (1999) non-negative matrix factorization. One NMF lossfunctions presented Lee Seung (1999) penalizes KL-divergence matrixreconstruction, equation 8; but, NMF loss incorporate link functionE-PCA loss. Another NMF loss function presented Lee Seung (1999) penalizes squarederror constrains factors nonnegative; resulting model example (GL) 2 M,generalization E-PCA described Gordon (2003).13fiRoy, Gordon, & ThrunFinding E-PCA ParametersAlgorithms conventional PCA guaranteed converge unique answer independent initialization. general, E-PCA property: loss function (8)may multiple distinct local minima. However, problem finding best B givenB U convex; convex optimization problems well studied unique globalsolutions (Rockafellar, 1970). Similarly, problem finding best U given B Bconvex. So, possible local minima joint space U B highly constrained,finding U B require solving general non-convex optimization problem.Gordon (2003) describes fast, Newtons Method approach computing U Bsummarize here. algorithm related Iteratively Reweighted Least Squares,popular algorithm generalized linear regression (McCullagh & Nelder, 1983). orderuse Newtons Method minimize equation (8), need derivative respect UB:(U B)L(B, U, B) =eB U B(9)UUU= e(U B) B B B(10)= (e(U B) B)B(11)(U B)L(B, U, B) =eB U BBBB= U e(U B) U B= U (e(U B)B).(12)(13)(14)set right hand side equation (14) zero, iteratively compute Bj ,column B, Newtons method. Let us set q(Bj ) = U (e(U Bj ) Bj ), linearizeBj find roots q(). givesj thBjnew = BjBjnew Bj=q(Bj )q 0 (Bj )U (e(U Bj ) Bj )q 0 (Bj )(15)(16)Note equation 15 formulation Newtons method finding roots q, typicallywrittenf (xn )xn+1 = xn 0.(17)f (xn )need expression q 0 :qBj==U (e(U Bj ) Bj )BjU e(U Bj )Bj= U Dj U14(18)(19)(20)fiFinding Approximate POMDP Solutions Belief Compressiondefine Dj terms diag operator returns diagonal matrix:Dj = diag(eU Bj ),(21)b(s0 ) . . .0.. ...diag(b) = .....0. . . b(s|S| )(22)Combining equation (15) equation (20), get(U Dj U )(Bjnew Bj ) = U (Bj eU Bj )(23)U Dj U Bjnew = (U Dj U )Bj + U Dj Dj1 (Bj eU Bj )= U Dj (U Bj + Dj1 (Bj eU Bj ),(24)(25)weighted least-squares problem solved standard linear algebratechniques. order ensure solution numerically well-conditioned, typicallyadd regularizer divisor,Bjnew =U Dj (U Bj + Dj1 (Bj eU Bj )(U Dj U + 105 Il ).(26)Il l l identity matrix. Similarly, compute new U computing Ui ,ith row U ,(Ui B + (Bi eUi B )Di1 )Di B.(27)Uinew =(BDi B + 105 Il )E-PCA Algorithmalgorithm automatically finding good low-dimensional representationB high-dimensional belief set B. algorithm given Table 1; optimizationiterated termination condition reached, finite number iterations,minimum error achieved.steps 7 9 raise one issue. Although solving row U column Bseparately convex optimization problem, solving two matrices simultaneouslynot. therefore subject potential local minima; experimentsfind problem, expect need find ways address localminimum problem order scale even complicated domains.bases U found, finding low-dimensional representation highdimensional belief convex problem; compute best answer iterating equation (26). Recovering full-dimensional belief b low-dimensional representation balso straightforward:x = eU b .(28)definition PCA explicitly factor data U , B manypresentations do. three-part representation PCA, contains singular values15fiRoy, Gordon, & Thrun1. Collect set sample beliefs high-dimensional belief space2. Assemble samples data matrix B = [b1 | . . . |b|B| ]3. Choose appropriate loss function, L(B, U, B)4. Fix initial estimate B U randomly5.6.column Bj B,Compute Bjnew using current U estimate equation (26)7.8.row Ui U ,9.Compute Uinew using new B estimate equation (27)10. L(B, U, B) >Table 1:E-PCA Algorithm finding low-dimensional representation POMDP,including Gordons Newtons method (2003).decomposition, U B orthonormal. use two-part representationB f (U B) quantity E-PCA decomposition correspondssingular values PCA. result, U B general orthonormal.desired, though, possible orthonormalize U additional step optimizationusing conventional PCA adjust B accordingly.5. E-PCA PerformanceUsing loss function equation (8) iterative optimization procedure describedequation (26) equation (27) find low-dimensional factorization, lookwell dimensionality-reduction procedure performs POMDP examples.Toy ProblemRecall Figure 9 unable find good representations datafewer 10 15 bases, even though domain knowledge indicated data3 degrees freedom (horizontal position mode along corridor, concentrationmode, probability top bottom corridor). Examining onesample beliefs Figure 10, saw representation worst lowprobability regions. take data set toy example, use E-PCAfind low-dimensional representation compare performance PCA E-PCA.Figure 11(a) shows E-PCA substantially efficient representing data,see KL divergence falling close 0 4 bases. Additionally, squared L 2error 4 bases 4.64 104 . (We need 4 bases perfect reconstruction, rather3, since must include constant basis function. small amount reconstruction16fiFinding Approximate POMDP Solutions Belief Compressionerror 4 bases remains stopped optimization procedure fullyconverged.)Average KL Divergence vs. Number Bases (E-PCA)Example Belief Reconstruction Using 3 Bases1.60.0450.040.0350.031.21ProbabilityAverage KL Divergence1.40.80.60.4005101520Number Bases2530(a) Reconstruction PerformanceProbabilityProbability0.0360.0340.0320.030.028406080100 120 140 160 180 200State2e-091.5e-091e-095e-100.0260146148150State15215490(c) Belief Reconstruction NearPeakFigure 11:20Example Belief Reconstruction Using 3 Bases3e-09Original BeliefReconstructed Belief2.5e-09Original BeliefReconstructed Belief0.0380(b) Example Belief ReconstructionExample Belief Reconstruction Using 3 Bases0.040.0250.020.0150.010.0050-0.0050.2Original BeliefReconstructed Belief95100State105110(d) Belief Reconstruction LowProbability Region(a) average KL divergence original sample set reconstructions. KL divergence 0.018 4 bases. error bars representstandard deviation mean 500 beliefs. (b) examplebelief Figure 10 reconstruction using 3 bases. reconstructionshows small errors peak mode. shown reconstructionusing 4 bases, original belief reconstruction indistinguishable naked eye. (c) (d) show fine detail original beliefreconstruction two parts state space. Although reconstructionperfect, low-probability area, see error approximately2 109 .17fiRoy, Gordon, & ThrunFigure 11(b) shows E-PCA reconstruction example belief Figure 10.see many artifacts present PCA reconstruction absent. Using3 bases, see E-PCA reconstruction already substantially better PCAusing 10 bases, although small errors peaks (e.g., Figure 11c)two modes. (Using 4 bases, E-PCA reconstruction indistinguishable naked eyeoriginal belief.) kind accuracy 3 4 bases typicaldata set.Robot BeliefsAlthough performance E-PCA finding good representations abstract problemcompelling, would ideally like able use algorithm real-world problems,robot navigation problem Figure 2. Figures 12 13 show results tworobot navigation problems, performed using physically-realistic simulation (althoughartificially limited sensing dead-reckoning). collected sample set 500 beliefsmoving robot around environment using heuristic controller, computedlow-dimensional belief space B according algorithm Table 1. full state space47.7m 17m, discretized resolution 1m 1m per pixel, total 799 states.Figure 12(a) shows sample belief, Figure 12(b) reconstruction using 5 bases.Figure 12(c) see average reconstruction performance E-PCA approach,measured average KL-divergence sample belief reconstruction.comparison, performance PCA E-PCA plotted. E-PCA error falls0.02 5 bases, suggesting 5 bases sufficient good reconstruction.substantial reduction, allowing us represent beliefs problem using5 parameters, rather 799 parameters. Notice many states lie regionsoutside map; is, states never receive probability massremoved. removing states would trivial operation, E-PCA correctlyable automatically.Figure 13, similar results shown different environment. sample set 500beliefs collected using heuristic controller, low-dimensional belief spaceB computed using E-PCA. full state space 53.6m 37.9m, resolution.5m .5m per pixel. example belief shown Figure 13(a), reconstructionusing 6 bases shown Figure 13(b). reconstruction performance measuredaverage KL divergence shown Figure 13(c); error falls close 0 around 6bases, minimal improvement thereafter.6. Computing POMDP policiesExponential-family Principal Components Analysis model gives us way findlow-dimensional representation beliefs occur particular problem.two real-world navigation problems tried, algorithm proved effectivefinding low-dimensional representations, showing reductions 800 states2, 000 states 5 6 bases. 5 6 dimensional belief space allow muchtractable computation value function, able solve muchlarger POMDPs could solved previously.18fiFinding Approximate POMDP Solutions Belief CompressionKL Divergence Sampled Beliefs ReconstructionsParticles formbimodal distribution45E-PCAPCA40KL Divergence35(a) Original Belief302520151050123456789Number Bases(c) Reconstruction performance(b) ReconstructionFigure 12:(a) sample belief robot navigation task. (b) reconstructionbelief learned E-PCA representation using 5 bases. (c) averageKL divergence sample beliefs reconstructionsnumber bases used. Notice E-PCA error falls close 0 5 bases,whereas conventional PCA much worse reconstruction error even 9 bases,improving rapidly.KL Divergence Sampled Beliefs Reconstructions43.5KL Divergence32.521.510.50(a) sample beliefFigure 13:(b) reconstruction0246810Number Bases(c) Averageperformance121416reconstruction(a) sample belief navigation problem Longwood, cf. Figure 2. (b)reconstruction learned E-PCA representation using 6 bases. (c)average KL divergence sample beliefs reconstructionsnumber bases used.Unfortunately, longer use conventional POMDP value iteration findoptimal policy given low-dimensional set belief space features. POMDP value iteration depends fact value function convex belief space.19fiRoy, Gordon, & Thruncompute non-linear transformation beliefs recover coordinateslow-dimensional belief surface, lose convexity value function (compare Figure 3 Figure 6 see why). result, value function cannot expressedsupremum set hyperplanes low-dimensional belief space.So, instead using POMDP value iteration, build low-dimensional discretebelief space MDP use MDP value iteration. Since know formvalue function, turn function approximation. Gordon (1995) provedfitted value iteration algorithm guaranteed find bounded-error approximation(possibly discounted) MDPs value function, long use combinationfunction approximator averager. Averagers function approximatorsnon-expansions max-norm; is, exaggerate errors training data.experiments below, use regular grids well irregular, variable-resolution gridsbased 1-nearest-neighbour discretization, represented set low-dimensional beliefsB ,B = {b1 , b2 , . . . , b|B | }.(29)approximations averagers; averagers include linear interpolation, knearest-neighbours, local weighted averaging. focus detail exactmechanism discretizing low-dimensional space, outside scopepaper. resolution regular grid cases chosen empirically; section 7describe specific variable resolution discretization scheme worked well empirically.reader consult Munos Moore (2002) Zhou Hansen (2001)sophisticated representations.fitted value iteration algorithm uses following update rule compute t-steplookahead value function V (t 1)-step lookahead value function V t1 :|B |XV (bi ) = max R (bi , a) +(bi , a, bj ) V t1 (bj )(30)j=1R approximate reward transition functions based dynamicsPOMDP, result E-PCA, finite set low-dimensional belief samplesB using function approximator. Note problems describedpaper, problem require discounting ( = 1). following sections describecompute model parameters R .Computing Reward Functionoriginal reward function R(s, a) represents immediate reward taking actionstate s. cannot know, given either low-dimensional high-dimensional belief,immediate reward be, compute expected reward. thereforerepresent reward expected value immediate reward full model,current belief:R (b , a) = Eb (R(s, a))(31)|S|=Xi=120R(si , a)b(si ).(32)fiFinding Approximate POMDP Solutions Belief CompressionEquation (32) requires us recover high-dimensional belief b low-dimensionalrepresentation b , shown equation (28).many problems, reward function R effect giving low immediatereward belief states high entropy. is, many problems plannerdriven towards beliefs centred high-reward states low uncertainty.property intuitively desirable: beliefs robot worryimmediate bad outcome.Computing Transition FunctionComputing low-dimensional transition function = p(bj |a, bi ) simplecomputing low-dimensional reward function R : need consider pairs lowdimensional beliefs, bi bj . original high-dimensional belief space, transitionprior belief bi posterior belief bj described Bayes filter equation:bj (s) = O(s, a, z)|S|X(sk , a, s)bi (sk )(33)k=1action selected z observation saw; original POMDPtransition probability distribution, original POMDP observation probabilitydistribution.Equation (33) describes deterministic transition conditioned upon prior belief,action observation. transition posterior bj stochastic observation known; is, transition bi bj occurs specific zgenerated, probability transition probability generating observationz. So, separate full transition process deterministic transition b ,belief acting sensing, stochastic transition b j , full posterior:ba (s) =|S|X(sj , a, s)bi (sj )(34)j=1bj (s) = O(s, a, z)ba (s).(35)Equations 34 35 describe transitions high-dimensional beliefsoriginal POMDP. Based high-dimensional transitions, compute transitions low-dimensional approximate belief space MDP. Figure 14 depicts process.figure shows, start low-dimensional belief bi . bi reconstructhigh-dimensional belief b according equation (28). apply actionobservation z described equation (34) equation (35) find new beliefb0 . b0 compress low-dimensional representation b0 iteratingequation (26). Finally, since b0 may member sample B low-dimensionalbelief states, map b0 nearby bj B according function approximator.function approximator grid, last step means replacing b0prototypical bj shares grid cell. generally, function approximator mayrepresent b0 combination several states, putting weight w(bj , b0 ) bj . (Forexample, approximator k-nearest-neighbour, w(bj , b0 ) = k1 closest k21fiRoy, Gordon, & Thrun~*bi~b~*bjLowdimensionalactionbbabHighdimensionalobservationzFigure 14: process computing single transition probability.samples B .) case replace transition bi b0 several transitions,bi bj , scale probability one w(bj , b0 ).transition bi b ba b0 b0 bj assign probabilityp(z, j|i, a) =p(z|ba ) w(bj , b0 )=w(bj , b0 )|S|Xp(z|sl )ba (sl )(36)l=1total transition probability (bi , a, bj ) sum, observations z, p(z, j|i, a).Step 3 Table 2 performs computation, shares work computation(bi , a, bj ) different posterior beliefs bj reachable prior beliefbi action a.Computing Value Functionreward transition functions computed previous sections, usevalue iteration compute value function belief space MDP. full algorithmgiven Table 2.7. Solving Large POMDPssection, present application algorithm finding policies largePOMDPs.Toy problemfirst tested E-PCA belief features using regular grid representation versiontoy problem described earlier. ensure needed small set beliefsamples bi , made goal region larger. also used coarser discretizationunderlying state space (40 states instead 200) allow us compute low-dimensionalmodel quickly.Figure 15 shows comparison policies different algorithms. E-PCAapproximately twice well Maximum-Likelihood heuristic; heuristic guessescorridor, correct half time. AMDP Heuristic algorithmAugmented MDP algorithm reported Roy Thrun (1999). controller attempts22fiFinding Approximate POMDP Solutions Belief Compression1. Generate discrete low-dimensional belief space B using E-PCA (cf. Table 1)2. Compute low-dimensional reward function R :b B ,(a) Recover b b(b) Compute R (b, a) =P|S|i=1 R(si , a)b(si ).3. Compute low-dimensional transition function :bi B ,(a) bj : (bi , a, bj ) = 0(b) Recover bi bi(c) observation z(d)Compute bj Bayes filter equation (33) b.(e)Compute b0 bj iterating equation (26).(f)bj w(bj , b0 ) > 0Add p(z, j|i, a) equation (36) (bi , a, bj )(g)4. Compute value function B(a) = 0(b) bi B : V 0 (bi ) = 0(c)(d)change = 0(e)bi B :P|B |V (bi ) = maxa R (bi , a) + j=1 (bi , a, bj ) V t1 (bj )change = change + V (bi ) V t1 (bi )(f) change > 0Table 2: Value Iteration E-PCA POMDPfind policy result lowest-entropy belief reaching goal.controller poorly unable distinguish unimodal beliefknows corridor position within corridor, bimodalbelief knows position corridor. results Figure 15 averaged10,000 trials.noted problem sufficiently small conventional PCA faresreasonably well. next sections, see problems PCA representationpoorly compared E-PCA.23fiRoy, Gordon, & ThrunAverage reward vs. Number Bases120000E-PCAPCAAverage Reward100000800006000040000MDP Heuristic200000-20000AMDP Heuristic1234Number BasesFigure 15:comparison policy performance using different numbers bases, 10,000trials, regular grid discretization. Policy performance given totalreward accumulated trials.Robot Navigationtested E-PCA POMDP algorithm simulated robot navigation problems twoexample environments, Wean Hall corridor shown Figure 16 Longwood retirement facility shown Figure 1(b). model parameters given robot navigationmodels (see Fox et al., 1999).evaluated policy relatively simple problem depicted Figure 16. setrobots initial belief may one two locations corridor,objective get within 0.1m goal state (each grid cell 0.2m0.2m).controller received reward +1000 arriving goal state taking at_goalaction; reward 1000 given (incorrectly) taking action non-goal state.reward 1 motion. states used planning example500 states along corridor, actions forward backward motion.Figure 16 shows sample robot trajectory using E-PCA policy 5 basis functions.Notice robot drives past goal lab door order verify orientationreturning goal; robot know true position, cannot knowfact passing goal. robot started end corridor,orientation would become apparent way goal.Figure 17 shows average policy performance three different techniques.Maximum-Likelihood heuristic could distinguish orientations, therefore approximately 50% time declared goal wrong place. also evaluated policylearned using best 5 bases conventional PCA. policy performed substantiallybetter maximum-likelihood heuristic controller incorrectly declare robot arrived goal. However, representation could detectrobot goal, also chose sub-optimal (with respect E-PCApolicy) motion actions regularly. E-PCA outperformed techniques example able model belief accurately, contrast result Figure 15PCA sufficient representation perform well better E-PCA.24fiFinding Approximate POMDP Solutions Belief CompressionTrue PositionGoal StateFinal EstimatedPositionTrue Start StateFigure 16:Goal PositionStart Positionexample robot trajectory, using policy learned using 5 basis functions.left start conditions goal. right robottrajectory. Notice robot drives past goal lab door localizeitself, returning goal.Policy perfomance Mobile Robot Navigation400000Average Reward3000002000001000000-268500.0-1000.033233.0-100000-200000-300000Figure 17:ML HeuristicPCAE-PCAcomparison policy performance using E-PCA, conventional PCAMaximum Likelihood heuristic, 1,000 trials.Figure 18(a) shows second example navigation simulation. Notice initialbelief problem bi-modal; good policy take actions disambiguatemodes proceeding goal. Using sample set 500 beliefs, computedlow-dimensional belief space B. Figure 18(b) shows average KL divergenceoriginal reconstructed beliefs. improvement KL divergence error measureslowed substantially around 6 bases; therefore used 6 bases represent beliefspace.Figure 18(c) shows example execution policy computed using E-PCA.reward parameters previous navigation example. robotparameters maximum laser range 2m, high motion model variance. firstaction policy chose turn robot around move closer nearest wall.effect eliminating second distribution mode right. robotfollowed essentially coastal trajectory left-hand wall order stay localized,although uncertainty direction became relatively pronounced. seeuncertainty eventually resolved top image, robot movedgoal.25fiRoy, Gordon, & ThrunKL Divergence Sampled Beliefs Reconstructions43.5True (hidden) start3KL DivergenceGoal2.521.510.50Start distribution modes(a) Initial Distribution0246810Number Bases121416(b) Reconstruction PerformancePositional Accuracy Goal8Distance goal metres754.54443210(c) Complete TrajectoryFigure 18:6.03061.075E-PCAAMDPMDP(d) Policy Performance(a) sample navigation problem Longwood, cf. Figure 2. probleminvolves multi-modal distributions. (c) average KL divergencesample beliefs reconstructions number bases used, 500samples beliefs navigating mobile robot environment. (d) comparison policy performance using E-PCA, conventional MDP AMDPheuristic.interesting note policy contains similar coastal attributeheuristic policies (e.g., Entropy heuristic AMDP, Cassandra, Kaelbling, &Kurien, 1996; Roy & Thrun, 1999). However, unlike heuristics, E-PCA representation able reach goal accurately (that is, get closer goal).representation successful able accurately represent beliefseffects actions beliefs.26fiFinding Approximate POMDP Solutions Belief CompressionFinding People(a) Original Belief(b) Reconstruction PCA(c) Reconstruction E-PCAFigure 19:performance PCA E-PCA sample belief. map 238 85grid cells, 0.2m resolution. (a) sample belief. (b) PCA reconstruction,using 40 bases. (c) E-PCA reconstruction, using 6 bases.addition synthetic problem robot navigation problems describedprevious sections, also tested algorithm complicated POMDP problem,finding person object moving around environment. problemmotivated Nursebot domain, residents experiencing cognitive declinesometimes become disoriented start wander. order make better usehealth-care providers time, would like use robot Pearl (Figure 1a) findresidents quickly. assume person adversarial.state space problem much larger previous robot navigation problems: cross-product persons position robots position. However,assume simplicity robots position known, therefore belief distribution persons position. transitions person state featuremodelled Brownian motion fixed, known velocity, models personsmotion random, independent robot position. (If person moving avoidcaptured robot, different transition model would required.) assumeposition person unobservable robot close enough seeperson (when robot line-of-sight person, maximum range, usually3 metres); observation model 1% false negatives false positives. rewardfunction maximal person robot location.27fiRoy, Gordon, & ThrunFigure 19(a) shows example probability distribution occur problem(not shown robots position). grey dots particles drawn distributionperson could environment. distribution initially uniformreachable areas (inside black walls). robot receives sensor data,probability mass extinguished within sensor range robot. robotmoves around, probability mass extinguished, focusing distributionremaining places person be. However, probability distribution startsrecover mass places robot visits leaves. particle filter,visualized particles leaking areas previously emptied out.collected set 500 belief samples using heuristic controller given drivingrobot maximum likelihood location person, used E-PCA find goodlow-dimensional representation beliefs. Figure 19(b) shows reconstructionexample belief Figure 19(a), using conventional PCA 40 bases. figurereinforce idea PCA performs poorly representing probability distributions. Figure 19(c) shows reconstruction using E-PCA 6 bases, qualitatively betterrepresentation original belief.Recall section 6 use function approximator representing valuefunction. preceding examples used regular grid low-dimensional surfaceperformed well finding good policies. However, problem finding people empirically requires finer resolution representation would computationally tractableregular grid. therefore turn different function approximator, 1-nearestneighbour variable resolution representation. add new low-dimensional belief statesmodel periodically re-evaluating model grid cell, splitting gridcell smaller discrete cells statistic predicted model disagreesstatistic computed experience. number different statistics suggestedtesting model data real world (Munos & Moore, 1999),reduction reward variance, value function disagreement. opted insteadsimpler criterion transition probability disagreement. examine policy computedusing fixed representation, also policy computed using incrementally refinedrepresentation. Note fully explored effect different variable resolution representations value function, e.g., using k-nearest-neighbour interpolationsdescribed Hauskrecht (2000). experiments beyond scopepaper, focus utility E-PCA decomposition. variable resolutionrepresentation value function shown scale effectively beyond tensdimensions best (Munos & Moore, 2002).problem shares many attributes robot navigation problem, seeFigure 19 figures 20 21 problem generates spatial distributions highercomplexity. somewhat surprising E-PCA able find good representationbeliefs using 6 bases, indeed average KL divergence generally higherrobot navigation task. Regardless, able find good controllers,example problem PCA performs poorly even large numberbases.Figure 20 shows example trajectory heuristic control strategy, drivingrobot maximum likelihood location person time step. open circlerobot position, starting far right. solid black circle position28fiFinding Approximate POMDP Solutions Belief CompressionFigure 20:(a)(b)(c)(d)(e)(f)example suboptimal person finding policy. grey particles drawndistribution person might be, initially uniformly distributed (a). black dot true (unobservable) position person.open circle observable position robot. robots pooraction selection, person able escape previously explored areas.person, unobservable robot within 3m range. person startsroom corridor (a), moves corridor robotmoved far end corridor (b). robot returns search inside room (c)(d), person moves unobserved previously searched corridor (e). Althoughdeliberately chosen example heuristic performs poorly, personfollowing unlikely adversarial trajectory: times solid black circle remainsregions high probability. robots belief accurately reflects possibilityperson slip past, heuristic control algorithm way take possibilityaccount.Using policy found low-dimensional belief space described previoussections, able find much better controller. sample trajectory controller29fiRoy, Gordon, & ThrunFigure 21:(a)(b)(c)(d)(e)(f)policy computed using E-PCA representation. initial conditionspanel (a) Figure 20. Notice that, unlike previous figure,strategy ensures probability mass located one place, allowingrobot find person significantly higher probability.shown Figure 21. robot travels right-most position corridor (a)part-way corridor (b), returns explore room (c)(d). example, persons starting position different one givenprevious examplethe E-PCA policy would find person point, startinginitial conditions previous example). exploring room eliminatingpossibility person inside room (e), policy reduced possiblelocations person left-hand end corridor, able findperson reliably location.Note figures 20 21 target person worst-case start positionplanner. person start position Figure 21 Figure 20,policy would found person panel (d). Similarly, person started30fiFinding Approximate POMDP Solutions Belief Compressionend corridor Figure 21, policy shown Figure 20 would foundperson panel (b).Performance Different PoliciesAverage # Actions Find Person250200150100Fully Observable Policy500Figure 22:ClosestDensestMDPPCAE-PCA Refined E-PCAcomparison 6 policies person finding simple environment.baseline fully-observable, i.e., cheating, solution (the solid line). EPCA policy fixed (variable resolution) discretization. Refined E-PCAdiscretization additional belief samples added. PCApolicy approximately 6 times worse best E-PCA policy.Figure 22 shows quantitative comparison performance E-PCAnumber heuristic controllers simulation, comparing average time findperson different controllers. solid line depicts baseline performance,using controller access true state person times (i.e., fullyobservable lower bound best possible performance). travel time casesolely function distance person; searching necessary performed.course, realizable controller reality. controllers are:Closest: robot driven nearest state non-zero probability.Densest: robot driven location probability massvisible.MDP: robot driven maximum-likelihood state.PCA: controller found using PCA representation fixed discretizationlow-dimensional surface.E-PCA: E-PCA controller using fixed discretization low-dimensional surfacecompute value function.Refined E-PCA: E-PCA controller using incrementally refined variable resolutiondiscretization surface computing value function.performance best E-PCA controller surprisingly close theoretical bestperformance, terms time find person, result also demonstrates needcareful choice discretization belief space computing value function.31fiRoy, Gordon, & Thruninitial variable resolution representation proved poor function approximator, however, using iteratively-refined variable resolution discretization, able improveperformance substantially. controller using conventional PCA representationcase computed fixed discretization low-dimensional representation using40 bases 500 grid points. quality belief representation PCA poorinvestigate complex policy approximators.8. Discussionexperiments demonstrate E-PCA algorithm scale finding low-dimensional surfaces embedded high-dimensional spaces.Time Complexityalgorithm iterative therefore simple expression total running timeavailable. data set |B| samples dimensionality n, computing surface sizel, iteration algorithm O(|B|nl 2 + |B|l3 + nl3 ). step Newtonsalgorithm dominated set matrix multiplies final step inverting l lmatrix, O(l3 ). U step consists |B| iterations, iteration O(nl)multiplies O(l3 ) inversion. V step consists n iterations, iterationO(|B|l) multiplies O(l 3 ) inversion, leading total complexity given above.Figure 23 shows time compute E-PCA bases 500 sample beliefs,20,230 states. implementation used Java 1.4.0 Colt 1.0.2, 1 GHz AthlonCPU 900M RAM. Also shown computation times conventional PCAdecomposition. small state space problems, E-PCA decomposition fasterPCA small number bases, implementation PCA always computesfull decomposition (l = n, l reduced dimensionality n fulldimensionality).Exponential Family PCA Running Time3500030000Time secs25000200001500010000Conventional PCA = 4151sec50000Figure 23:02468Number Bases1012time compute E-PCA representations different discretizationsstate space.32fiFinding Approximate POMDP Solutions Belief Compressionfar dominant term running time algorithm time computeE-PCA bases. bases found low-dimensional spacediscretized, running time required value iteration converge policyproblems described order 50 100ms.Sample Belief Collectionexample problems addressed, used standard sample size 500sample beliefs. Additionally, used hand-coded heuristic controllers sample beliefsmodel. practice, found 500 sample beliefs collected using semi-random controller sufficient example problems. However, may able improve overallperformance algorithm future problems iterating phases buildingbelief space representation (i.e., collecting beliefs generating low-dimensionalrepresentation) computing good controller. initial set beliefscollected used build initial set bases corresponding policy, continueevaluate error representation (e.g., K-L divergence current belieflow-dimensional representation). initial representation learnedbeliefs, representation may over-fit beliefs; detect situationnoticing representation poor job representing new beliefs. Validationtechniques cross-validation may also useful determining enough beliefsacquired.Model SelectionOne open questions addressed far choosing appropriatenumber bases representation. Unless problem-specific information,true number degrees freedom belief space (as toy examplesection 3), difficult identify appropriate dimensionality underlying surfacecontrol. One common approach examine eigenvalues decomposition,recovered using orthonormalization step algorithm Table 1.(This assumes particular link function capable expressing surfacedata lies on.) eigenvalues conventional PCA often used determineappropriate dimensionality underlying surface; certainly reconstructionlossless use many bases non-zero eigenvalues.Unfortunately, recall description E-PCA section 4 generateset singular values, eigenvalues. non-linear projection introduced linkfunction causes eigenvalues U matrix uninformative contributionbasis representation. Instead using eigenvalues choose appropriatesurface dimensionality, use reconstruction quality, Figure 11. Using reconstructionquality estimate appropriate dimensionality common choice PCAdimensionality reduction techniques (Tenenbaum, de Silva, & Langford, 2000). Onealternate choice would evaluate reward policies computed different dimensionalities choose compact representation achieves highest reward,essentially using control error rather reconstruction quality determine dimensionality.33fiRoy, Gordon, & ThrunRecall discussion section 2 using dimensionality reductionrepresent beliefs POMDPs specific kind structure. particular, E-PCArepresentation useful representing beliefs relatively sparsesmall number degrees freedom. However, E-PCA unable find good lowdimensional representations POMDP models exhibit kind structureis, beliefs cannot represented lying low-dimensional hyperplane linkedfull belief space via appropriate link function. One additional problemknow priori whether specific POMDP appropriate structure. unlikelygeneral technique determine usefulness E-PCA,take advantage model selection techniques also determine whether E-PCAfind usefully low dimensional representation specific POMDP. example,KL divergence set sample beliefs reconstructions large even usinglarge number bases, problem may right structure.9. Related WorkMany attempts made use reachability analysis constrain set beliefsplanning (Washington, 1997; Hauskrecht, 2000; Zhou & Hansen, 2001; Pineau, Gordon,& Thrun, 2003a). reachable set beliefs relatively small, forward searchfind set perfectly reasonable approach. policy computed beliefs course optimal, although relatively rare real world problems ableenumerate reachable beliefs. Reachability analysis also usedsuccess heuristic guiding search methods, especially focusing computationfinding function approximators (Washington, 1997; Hansen, 1998). approach,problem still remains compute low-dimensional representation given finiteset representative beliefs. Discretization belief space explorednumber times, regular grid-based discretization (Lovejoy, 1991), regular variableresolution approaches (Zhou & Hansen, 2001) non-regular variable resolution representations (Brafman, 1997; Hauskrecht, 2000). vein, state abstraction (Boutilier &Poole, 1996) explored take advantage factored state spaces, particularinterest algorithm Hansen Feng (2000) perform state abstractionabsence prior factorization. far, however, approaches fallenvictim curse dimensionality failed scale dozenstates most.value-directed POMDP compression algorithm Poupart Boutilier (2002)dimensionality-reduction technique closer spirit ours, technique.algorithm computes low-dimensional representation POMDP directly modelparameters R, , finding Krylov subspace reward function beliefpropagation. Krylov subspace vector matrix smallest subspacecontains vector closed multiplication matrix. POMDPs,authors use smallest subspace contains immediate reward vector closedset linear functions defined state transitions observation model.major advantage approach optimizes correct criterion: value-directedcompression distinguish beliefs different value. majordisadvantage approach Krylov subspace constrained linear. Using34fiFinding Approximate POMDP Solutions Belief Compressionalgorithm PCA instead E-PCA, realize much compressionPoupart Boutilier (2002) method: take advantage regularitiestransition matrices a,z reward function R. Unfortunately,seen, beliefs unlikely lie low-dimensional hyperplane, results reportedsection 3 indicate linear compression scale size problems wishaddress.Possibly promising approaches finding approximate value-functionspoint-based methods, instead optimizing value function entirebelief space, specific beliefs. Cheng (1988) described method backingvalue function specific belief points procedure called point-based dynamicprogramming (PB-DP). PB-DP steps interleaved standard backupsfull value iteration. Zhang Zhang (2001) improved method choosing Witnesspoints backup belief points, iteratively increasing number points.essential idea point-based backups significantly cheaper full backup steps.Indeed, algorithm described Zhang Zhang (2001) out-performs Hansens exactpolicy-search method order magnitude small problems. However, needperiodic backups across full belief space still limits applicability algorithmssmall abstract problems.recently, Pineau et al. (2003a) abandoned full value function backupsfavour point-based backups point-based value iteration (PBVI) algorithm.backing discrete belief points, backup operator polynomial insteadexponential (as value iteration), and, even importantly, complexityvalue function remains constant. PBVI uses fundamentally different approach findingPOMDP policies, still remains constrained curse dimensionality large statespaces. However, applied successfully problems least order magnitudelarger predecessors, another example algorithms used makelarge POMDPs tractable.E-PCA possible technique non-linear dimensionality reduction;exists large body work containing different techniques Self-Organizing Maps (Kohonen, 1982), Generative Topographic Mapping (Bishop, Svensen, & Williams, 1998),Stochastic Neighbour Embedding (Hinton & Roweis, 2003). Two successfulalgorithms emerge recently Isomap (Tenenbaum et al., 2000) Locally Linear Embedding (Roweis & Saul, 2000). Isomap extends PCA-like methods non-linearsurfaces using geodesic distances distance metric data samples, ratherEuclidean distances. Locally Linear Embedding (LLE) considered local alternativeglobal reduction Isomap represents point weighted combination neighbours operates two phases: computing weights k nearestneighbours high-dimensional point, reconstructing data lowdimensional co-ordinate frame weights. However, algorithms containexplicit models kind data (e.g., probability distributions) attemptingmodel. One interesting line research, however, may extend algorithms usingdifferent loss functions manner PCA extended E-PCA.35fiRoy, Gordon, & Thrun10. ConclusionPartially Observable Markov Decision Processes considered intractable findinggood controllers real world domains. particular, best algorithms datefinding approximate value function full belief space scaled beyondhundred states (Pineau et al., 2003a). However, demonstrated real worldPOMDPs contain structured belief spaces; finding using structure,able solve POMDPs order magnitude larger solved conventionalvalue iteration techniques. Additionally, able solve different kinds POMDPs,simple highly-structured synthetic problem robot navigation problemproblem factored belief space relatively complicated probability distributions.algorithm used find structure related Principal Components Analysisloss function specifically chosen representing probability distributions. realworld POMDPs able solve characterized sparse distributions,Exponential family PCA algorithm particularly effective compressing data.exist POMDP problems structure,dimensionality reduction technique work well; however, questioninvestigation other, related dimensionality-reduction techniques (e.g., Isomap LocallyLinear Embedding, Tenenbaum et al., 2000; Roweis, Saul, & Hinton, 2002) applied.number interesting possibilities extending algorithm orderimprove efficiency increase domain applicability. loss functionchose dimensionality reduction based reconstruction error,L(B, U, B) = e(U B) B U B,(37)(cf. equation 8). Minimizing reconstruction error allow near-optimal policieslearned. However, would ideally like find compact representationminimizes control errors. could possibly better approximated taking advantagetransition probability structure. example, dimensionality reduction minimizesprediction errors would correspond loss function:L(B, U, B, ) = e(U b) B U b + kB,2...n B,1...n1 k2(38)B,1...n1 l n 1 matrix first n 1 column vectors B, B,2...nl n 1 matrix n 1 column vectors V starting second vector.effect finding representation allows bt+1 predicted bt ,caveat B must arranged action. plan address issuefuture work.Another shortcoming approach described work containsassumption beliefs described using low-dimensional representation.However, relatively easy construct example problem generates beliefslie two distinct low-dimensional surfaces, current formulation would makeapparent dimensionality beliefs appear much higher set beliefs sampledone surface alone.work largely motivated finding better representations beliefs,approach solving large POMDPs. Policy search methods (Meuleau,36fiFinding Approximate POMDP Solutions Belief CompressionPeshkin, Kim, & Kaelbling, 1999) hierarchical methods (Pineau, Gordon, & Thrun,2003b) also able solve large POMDPs. interesting note controllersbased E-PCA representations often essentially independent policy complexitystrongly dependent belief complexity, whereas policy search hierarchicalmethods strongly dependent policy complexity largely independent beliefspace complexity. seems likely progress solving large POMDPs general liecombination approaches.E-PCA algorithm finds low-dimensional representation B full belief space Bsampled data. demonstrated reliance sampled data obstaclereal world problems. Furthermore, using sampled beliefs could assetlarge problems generating tracking beliefs considerably easierplanning. may however preferable try compute low-dimensional representationdirectly model parameters. Poupart Boutilier (2002) use notion Krylovsubspace this. subspace computed algorithm may correspond exactlyconventional PCA seen instances PCA poor job findinglow-dimensional representations. likely explanation real-world beliefslie low-dimensional planes problems, instead curved surfaces.extremely useful algorithm would one finds subset belief space closedtransition observation function, constrained find planes.AcknowledgementsThanks Tom Mitchell, Leslie Kaelbling, Reid Simmons, Drew Bagnell, Aaron Courville,Mike Montemerlo Joelle Pineau useful comments insight work. NicholasRoy funded National Science Foundation ITR grant # IIS-0121426. Geoffrey Gordon funded AFRL contract F3060201C0219, DARPAs MICA program,AFRL contract F306029820137, DARPAs CoABS program.ReferencesBagnell, J. A., & Schneider, J. (2001). Autonomous helicopter control using reinforcementlearning policy search methods. Proceedings IEEE International ConferenceRobotics Automation (ICRA), pp. 16151620, Seoul, South Korea. IEEE Press.Bishop, C., Svensen, M., & Williams, C. (1998). GTM: generative topographic mapping.Neural Computation, 10 (1), 215234.Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observableMarkov decision processes using compact representations. Proceedings 13thNational Conference Artificial Intelligence (AAAI-96), pp. 11681175.Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.Proceedings 14th Annual Conference Uncertainty AI (UAI), pp. 3342,Madison, Wisconsin.Brafman, R. I. (1997). heuristic variable grid solution method POMDPs. Kuipers,B. K., & Webber, B. (Eds.), Proceedings 14th National Conference ArtificialIntelligence (AAAI), pp. 727733, Providence, RI.37fiRoy, Gordon, & ThrunCassandra, A. R., Kaelbling, L., & Kurien, J. A. (1996). Acting uncertainty: Discrete Bayesian models mobile-robot navigation. Proceedings IEEE/RSJInternational Conference Intelligent Robots Systems.Chen, B. M. (2000). Robust H- Control. Springer-Verlag.Cheng, H.-T. (1988). Algorithms Partially Observable Markov Decision Processes. Ph.D.thesis, University British Columbia, Vancouver, Canada.Collins, M., Dasgupta, S., & Schapire, R. (2002). generalization principal componentsanalysis exponential family. Dietterich, T. G., Becker, S., & Ghahramani, Z.(Eds.), Advances Neural Information Processing Systems 14 (NIPS), Cambridge,MA. MIT Press.Cox, T., & Cox, M. (1994). Multidimensional Scaling. Chapman & Hall, London.Fox, D., Burgard, W., & Thrun, S. (1999). Markov localization mobile robots dynamicenvironments. Journal Artificial Intelligence Research, 11, 391427.Galassi, M., Davies, J., Theiler, J., Gough, B., Jungman, G., Booth, M., & Rossi,F. (2002).GNU Scientific Library Reference Manual (3rd Edition edition).http://www.gnu.org/software/gsl/.Golub, G., & Reinsch, C. (1970). Singular value decomposition least squares solutions.Numerische Mathematik, pp. 403420.Gordon, G. (1995). Stable function approximation dynamic programming. Prieditis,A., & Russell, S. (Eds.), Proceedings 12 International Conference MachineLearning (ICML), pp. 261268, San Francisco, CA. Morgan Kaufmann.Gordon, G. (2003). Generalized2 linear2 models. Becker, S., Thrun, S., & Obermayer, K.(Eds.), Advances Neural Information Processing Systems 15 (NIPS). MIT Press.Gutmann, J.-S., Burgard, W., Fox, D., & Konolige, K. (1998). experimental comparisonlocalization methods. Proceedings IEEE/RSJ International ConferenceIntelligent Robots Systems, Victoria, Canada.Gutmann, J.-S., & Fox, D. (2002). experimental comparison localization methodscontinued. Proceedings IEEE/RSJ International Conference IntelligentRobots Systems, Lausanne, Switzerland.Hansen, E., & Feng, Z. (2000). Dynamic programming POMDPs using factored staterepresentation. Proceedings Fifth International Conference ArtificialIntelligence Planning Scheduling (AIPS-00), Breckenridge, CO.Hansen, E. (1998). Solving POMDPs searching policy space. Proceedings14th Conference Uncertainty Artifical Intelligence (UAI), pp. 211219, Madison,WI.Hauskrecht, M. (2000). Value-function approximations partially observable Markovdecision processes. Journal Artificial Intelligence Research, 13, 3394.Hinton, G., & Roweis, S. (2003). Stochastic neighbor embedding. Becker, S., Thrun,S., & Obermayer, K. (Eds.), Advances Neural Information Processing Systems 15(NIPS). MIT Press.38fiFinding Approximate POMDP Solutions Belief CompressionHoward, R. A. (1960). Dynamic Programming Markov Processes. MIT.Isard, M., & Blake, A. (1998). CONDENSATION conditional density propagationvisual tracking. International Journal Computer Vision, 29 (1), 528.Joliffe, I. T. (1986). Principal Component Analysis. Springer-Verlag.Kanazawa, K., Koller, D., & Russell, S. (1995). Stochastic simulation algorithms dynamicprobabilistic networks. Proceedings 11th Annual Conference UncertaintyAI (UAI), pp. 346351, Montreal, Canada.Kohonen, T. (1982). Self-organized formation topologically correct feature maps. Biological Cybernetics, 48, 5969.Lee, D. D., & Seung, H. S. (1999). Learning parts objects non-negative matrixfactorization. Nature, 401, 788791.Leonard, J., & Durrant-Whyte, H. (1991). Mobile robot localization tracking geometricbeacons. IEEE Transactions Robotics Automation, 7 (3), 376382.Lovejoy, W. S. (1991). Computationally feasible bounds partially observable Markovdecison processes. Operations Research, 39, 192175.Mardia, K. V., & Jupp, P. E. (2000). Directional Statistics (2nd edition). Wiley, Chichester,NY.McCullagh, P., & Nelder, J. A. (1983). Generalized Linear Models (2nd edition). ChapmanHall, London.Meuleau, N., Peshkin, L., Kim, K.-E., & Kaelbling, L. P. (1999). Learning finite-state controllers partially observable environments. Laskey, K. B., & Prade, H. (Eds.),Proceedings Fifteenth International Conference Uncertainty Artificial Intelligence, pp. 427436, Stockholm, Sweden. Morgan Kaufmann.Munos, R., & Moore, A. (1999). Variable resolution discretization high-accuracy solutions optimal control problems. Dean, T. (Ed.), Proceedings 16th International Joint Conference Artificial Intelligence (IJCAI), pp. 13481355, StockholmSweden. Morgan Kaufmann.Munos, R., & Moore, A. (2002). Variable resolution discretization optimal control. Machine Learning, 49 (2-3), 291323.Nourbakhsh, I., Powers, R., & Birchfield, S. (1995). DERVISH office-navigating robot.AI Magazine, 16 (2), 5360.Olson, C. F. (2000). Probabilistic self-localization mobile robots. IEEE TransactionsRobotics Automation, 16 (1), 5566.Pineau, J., Gordon, G., & Thrun, S. (2003a). Point-based value iteration: anytimealgorithm POMDPs. Proceedings 18th International Joint ConferenceArtificial Intelligence (IJCAI 2003), Acapulco, Mexico.Pineau, J., Gordon, G., & Thrun, S. (2003b). Policy-contingent abstraction robust robotcontrol. Meek, C., & Kjlruff, U. (Eds.), Proceedings 19th Annual ConferenceUncertainty Artificial Intelligence (UAI), Acapulco, Mexico.39fiRoy, Gordon, & ThrunPoupart, P., & Boutilier, C. (2002). Value-directed compression POMDPs. Becker,S., Thrun, S., & Obermayer, K. (Eds.), Advances Neural Information ProcessingSystems 15 (NIPS), Vancouver, Canada. MIT Press.Rockafellar, R. T. (1970). Convex Analysis. Princeton University Press, New Jersey.Roweis, S., & Saul, L. (2000). Nonlinear dimensionality reduction locally linear embedding.. Science, 290 (5500), 23232326.Roweis, S. T., Saul, L. K., & Hinton, G. E. (2002). Global coordination local linearmodels. Dietterich, T. G., Becker, S., & Ghahramani, Z. (Eds.), AdvancesNeural Information Processing Systems, Vol. 14, Cambridge, MA. MIT Press.Roy, N., & Thrun, S. (1999). Coastal navigation mobile robots. Solla, S. A., toddK. Leen, & Muller, K. R. (Eds.), Advances Neural Processing Systems 12 (NIPS),pp. 10431049, Denver, CO. MIT Press.Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall.Shatkay, H., & Kaelbling, L. P. (2002). Learning geometrically-constrained hidden markovmodels robot navigation: Bridging geometrical-topological gap. Journal AIResearch.Tenenbaum, J. B., de Silva, V., & Langford, J. C. (2000). global geometric frameworknonlinear dimensionality reduction. Science, 290 (5500), 23192323.Thrun, S., Fox, D., Burgard, W., & Dellaert, F. (2000). Robust Monte Carlo localizationmobile robots. Artificial Intelligence, 128 (1-2), 99141.Washington, R. (1997). BI-POMDP: Bounded, incremental partially-observable Markovmodel planning. Proceedings 4th European Conference Planning (ECP).Zhang, N. L., & Zhang, W. (2001). Speeding convergence value iteration partially observable Markov decision processes. Journal Artificial Intelligence Research,14, 128.Zhou, R., & Hansen, E. (2001). improved grid-based approximation algorithmPOMDPs. Nebel, B. (Ed.), Proceedings 17th International Joint Conference Artificial Intelligence (IJCAI), pp. 707716, Seattle, Washington. MorganKaufmann.40fiJournal Artificial Intelligence Research 23 (2005) 367-420Submitted 07/04; published 04/05Hybrid BDI-POMDP Framework Multiagent TeamingRanjit Nairranjit.nair@honeywell.comAutomation Control SolutionsHoneywell Laboratories, Minneapolis, MN 55416Milind Tambetambe@usc.eduDepartment Computer ScienceUniversity Southern California, Los Angeles, CA 90089AbstractMany current large-scale multiagent team implementations characterizedfollowing belief-desire-intention (BDI) paradigm, explicit representation teamplans. Despite promise, current BDI team approaches lack tools quantitativeperformance analysis uncertainty. Distributed partially observable Markov decisionproblems (POMDPs) well suited analysis, complexity finding optimalpolicies models highly intractable. key contribution articlehybrid BDI-POMDP approach, BDI team plans exploited improve POMDPtractability POMDP analysis improves BDI team plan performance.Concretely, focus role allocation, fundamental problem BDI teams:agents allocate different roles team. article provides three key contributions. First, describe role allocation technique takes account futureuncertainties domain; prior work multiagent role allocation failed addressuncertainties. end, introduce RMTDP (Role-based Markov Team Decision Problem), new distributed POMDP model analysis role allocations.technique gains tractability significantly curtailing RMTDP policy search; particular, BDI team plans provide incomplete RMTDP policies, RMTDP policy searchfills gaps incomplete policies searching best role allocation.second key contribution novel decomposition technique improve RMTDPpolicy search efficiency. Even though limited searching role allocations, stillcombinatorially many role allocations, evaluating RMTDP identify bestextremely difficult. decomposition technique exploits structure BDI teamplans significantly prune search space role allocations. third key contributionsignificantly faster policy evaluation algorithm suited BDI-POMDP hybrid approach. Finally, also present experimental results two domains: mission rehearsalsimulation RoboCupRescue disaster rescue simulation.1. IntroductionTeamwork, whether among software agents, robots (and people) critical capabilitylarge number multiagent domains ranging mission rehearsal simulations,RoboCup soccer disaster rescue, personal assistant teams. Already large number multiagent teams developed range domains (Pynadath & Tambe,2003; Yen, Yin, Ioerger, Miller, Xu, & Volz, 2001; Stone & Veloso, 1999; Jennings, 1995;Grosz, Hunsberger, & Kraus, 1999; Decker & Lesser, 1993; Tambe, Pynadath, & Chauvat,2000; da Silva & Demazeau, 2002). existing practical approaches characterized situated within general belief-desire-intention (BDI) approach, paradigmc2005AI Access Foundation. rights reserved.fiNair & Tambedesigning multiagent systems, made increasingly popular due programming frameworks (Tambe et al., 2000; Decker & Lesser, 1993; Tidhar, 1993b) facilitate designlarge-scale teams. Within approach, inspired explicitly implicitly BDI logics,agents explicitly represent reason team goals plans (Wooldridge, 2002).article focuses analysis BDI teams, provide feedback aid humandevelopers possibly agents participating team, team performancecomplex dynamic domains improved. particular, focuses criticalchallenge role allocation building teams (Tidhar, Rao, & Sonenberg, 1996; Hunsberger& Grosz, 2000), i.e. agents allocate various roles team. instance,mission rehearsal simulations (Tambe et al., 2000), need select numberstypes helicopter agents allocate different roles team. Similarly, disasterrescue (Kitano, Tadokoro, Noda, Matsubara, Takahashi, Shinjoh, & Shimada, 1999), roleallocation refers allocating fire engines ambulances fires greatly impactteam performance. domains, performance teamlinked important metrics loss human life property thus criticalanalyze team performance suggest improvements.BDI frameworks facilitate human design large scale teams, key difficultyanalyzing role allocation teams due uncertainty arises complexdomains. example, actions may fail world state may partially observableagents owing physical properties environment imperfect sensing. Roleallocation demands future uncertainties taken account, e.g. factagent may fail execution may may replaced another must takenaccount determining role allocation. Yet current role allocation algorithms address uncertainty (see Section 7.4). Indeed, uncertainty requiresquantitative comparison different role allocations. However, tools quantitativeevaluations BDI teams currently absent. Thus, given uncertainties, mayrequired experimentally recreate large number possible scenarios (in real domainsimulations) evaluate compare different role allocations.Fortunately, emergence distributed Partially Observable Markov Decision Problems (POMDPs) provides models (Bernstein, Zilberstein, & Immerman, 2000; Boutilier,1996; Pynadath & Tambe, 2002; Xuan, Lesser, & Zilberstein, 2001) usedquantitative analysis agent teams uncertain domains. Distributed POMDPs represent class formal models powerful enough express uncertaintydynamic domains arising result non-determinism partial observabilityprinciple, used generate evaluate complete policies multiagent team.However, two shortcomings models prevents applicationanalysis role allocation. First, previous work analysis focused communication (Pynadath & Tambe, 2002; Xuan et al., 2001), rather role allocationcoordination decisions. Second, shown Bernstein et al. (2000), problemderiving optimal policy generally computationally intractable (the correspondingdecision problem NEXP-complete). Thus, applying optimal policies analysis highlyintractable.address first difficulty, derive RMTDP (Role-based Multiagent Team DecisionProblem), distributed POMDP framework quantitatively analyzing role allocations.Using framework, show that, general, problem finding optimal role368fiHybrid BDI-POMDP Framework Multiagent Teamingcompleted policy =additions BDI team planBDI team planRMTDPSearch Policy SpaceIncomplete policyBDI InterpreterDomainRMTDP modelFigure 1: Integration BDI POMDP.allocation policy computationally intractable (the corresponding decision problem stillNEXP-complete). shows improving tractability analysis techniques roleallocation critically important issue.Therefore, order make quantitative analysis multiagent teams using RMTDPtractable, second contribution provides hybrid BDI-POMDP approachcombines native strengths BDI POMDP approaches, i.e., ability BDIframeworks encode large-scale team plans POMDP ability quantitativelyevaluate plans. hybrid approach based three key interactions improvetractability RMTDP optimality BDI agent teams. first interactionshown Figure 1. particular, suppose wish analyze BDI agent team (each agentconsisting BDI team plan domain independent interpreter helps coordinateplans) acting domain. shown Figure 1, model domain viaRMTDP, rely BDI team plan interpreter providing incomplete policyRMTDP. RMTDP model evaluates different completions incompletepolicy provides optimally completed policy feedback BDI system. Thus,RMTDP fills gaps incompletely specified BDI team plan optimally.gaps concentrate role allocations, method appliedkey coordination decisions. restricting optimization role allocation decisionsfixing policy points, able come restricted policyspace. use RMTDPs effectively search restricted space order findoptimal role allocation.restricted policy search one key positive interaction hybrid approach,second interaction consists efficient policy representation used convertingBDI team plan interpreter corresponding policy (see Figure 1) newalgorithm policy evaluation. general, agents policy distributed POMDPindexed observation history (Bernstein et al., 2000; Pynadath & Tambe, 2002).369fiNair & TambeHowever, BDI system, agent performs action selection based setprivately held beliefs obtained agents observations applying beliefrevision function. order evaluate teams performance, sufficient RMTDPindex agents policies belief state (represented privately held beliefs)instead observation histories. shift representation results considerablesavings amount time needed evaluate policy space requiredrepresent policy.third key interaction hybrid approach exploits BDI team plan structure increasing efficiency RMTDP-based analysis. Even though RMTDPpolicy space restricted filling gaps incomplete policies, many policies may resultgiven large number possible role allocations. Thus enumerating evaluatingpossible policy given domain difficult. Instead, provide branch-and-bound algorithm exploits task decomposition among sub-teams team significantly prunesearch space provide correctness proof worst-case analysis algorithm.order empirically validate approach, applied RMTDP allocationBDI teams two concrete domains: mission rehearsal simulations (Tambe et al., 2000)RoboCupRescue (Kitano et al., 1999). first present (significant) speed-upgained three interactions mentioned above. Next, domains, comparedrole allocations found approach state-of-the-art techniques allocateroles without uncertainty reasoning. comparison shows importance reasoninguncertainty determining role allocation complex multiagent domains.RoboCupRescue domain, also compared allocations found allocations chosenhumans actual RoboCupRescue simulation environment. results showedrole allocation technique presented article capable performing humanexpert levels RoboCupRescue domain.article organized follows: Section 2 presents background motivation.Section 3, introduce RMTDP model present key complexity results. Section4 explains BDI team plan evaluated using RMTDP. Section 5 describesanalysis methodology finding optimal role allocation, Section 6 presentsempirical evaluation methodology. Section 7, present related workSection 8, list conclusions.2. Backgroundsection first describes two domains consider article: abstractmission rehearsal domain (Tambe et al., 2000) RoboCupRescue domain (Kitanoet al., 1999). domain requires us allocate roles agents team. Next, teamoriented programming (TOP), framework describing team plans describedcontext two domains. focus TOP, discussed Section 7.1,techniques would applicable frameworks tasking teams (Stone & Veloso,1999; Decker & Lesser, 1993).2.1 Domainsfirst domain consider based mission rehearsal simulations (Tambe et al.,2000). expository purposes, intentionally simplified. scenario370fiHybrid BDI-POMDP Framework Multiagent Teamingfollows: helicopter team executing mission transporting valuable cargo pointX point enemy terrain (see Figure 2). three paths Xdifferent lengths different risk due enemy fire. One scouting sub-teams mustsent (one path X Y), larger size scouting sub-teamsafer is. scouts clear one path X Y, transportsmove safely along path. However, scouts may fail along path, mayneed replaced transport cost transporting cargo. Owing partialobservability, transports may receive observation scout failedroute cleared. wish transport amount cargo quickestpossible manner within mission deadline.key role allocation decision given fixed number helicopters,allocated scouting transport roles? Allocating scouts meansscouting task likely succeed, fewer helicopters leftused transport cargo consequently less reward. However, allocatingscouts could result mission failing altogether. Also, allocating scouts,routes scouts sent on? shortest route would preferablerisky. Sending scouts route decreases likelihood failureindividual scout; however, might beneficial send different routes, e.g.scouts risky short route others safe longer route.Thus many role allocations consider. Evaluating difficultrole allocation must look-ahead consider future implications uncertainty, e.g. scouthelicopters fail scouting may need replaced transport. Furthermore, failure success scout may visible transport helicopters hencetransport may replace scout transports may never fly destination.scouttransportsXroute 1route 2enemy gunroute 3Figure 2: Mission rehearsal domain.second example scenario (see Figure 3), set RoboCupRescue disastersimulation environment (Kitano et al., 1999), consists five fire engines three differentfire stations (two stations 1 & 3 last station 2) five ambulancesstationed ambulance center. Two fires (in top left bottom right cornersmap) start need extinguished fire engines. fire extinguished,ambulance agents need save surviving civilians. number civilians371fiNair & Tambelocation known ahead time, although total number civilians known.time passes, high likelihood health civilians deteriorate firesincrease intensity. Yet agents need rescue many civilians possibleminimal damage buildings. first part goal scenario thereforefirst determine fire engines assign fire. fire engines gatheredinformation number civilians fire, transmitted ambulances.next part goal allocate ambulances particular fire rescuecivilians trapped there. However, ambulances cannot rescue civilians fires fullyextinguished. Here, partial observability (each agent view objects within visualrange), uncertainty related fire intensity, well location civilianshealth add significantly difficulty.C1F3F2F1C2Figure 3: RoboCupRescue Scenario: C1 C2 denote two fire locations, F1, F2F3 denote fire stations 1, 2 3 respectively denotes ambulancecenter.2.2 Team-Oriented Programmingaim team-oriented programming (TOP) (Pynadath & Tambe, 2003; Tambe et al.,2000; Tidhar, 1993b) framework provide human developers (or automated symbolicplanners) useful abstraction tasking teams. domains describedSection 2.1, consists three key aspects team: (i) team organization hierarchyconsisting roles; (ii) team (reactive) plan hierarchy; (iii) assignment rolessub-plans plan hierarchy. developer need specify low-level coordinationdetails. Instead, TOP interpreter (the underlying coordination infrastructure) automatically enables agents decide communicate reallocate372fiHybrid BDI-POMDP Framework Multiagent Teamingroles upon failure. TOP abstraction enables humans rapidly provide team planslarge-scale teams, unfortunately, qualitative assessment team performancefeasible. Thus, key TOP weakness inability quantitatively evaluate optimizeteam performance, e.g., allocating roles agents qualitative matching capabilities may feasible. discussed later, hybrid BDI-POMDP model addressesweakness providing techniques quantitative evaluation.concrete example, consider TOP mission rehearsal domain. firstspecify team organization hierarchy (see Figure 4(a)). Task Force highest levelteam organization consists two roles Scouting Transport,Scouting sub-team roles three scouting sub-sub-teams. Next specifyhierarchy reactive team plans (Figure 4(b)). Reactive team plans explicitly expressjoint activities relevant team consist of: (i) pre-conditions planproposed; (ii) termination conditions plan ended; (iii)team-level actions executed part plan (an example plan discussedshortly). Figure 4(b), highest level plan Execute Mission three sub-plans:DoScouting make one path X safe transports, DoTransportmove transports along scouted path, RemainingScouts scoutsreached destination yet get there.Execute Mission [Task Force]DoScouting[Task Force]RemainingScoutsDoTransport[Scouting Team] [Transport Team]Task ForceScoutRoutesWaitAtBase[Transport Team] [Scouting Team]Scouting TeamTransport TeamSctTeamA SctTeamB SctTeamCScoutRoute1 ScoutRoute2 ScoutRoute3[SctTeamA] [SctTeamB] [SctTeamC](a)(b)Figure 4: TOP mission rehearsal domain a: Organization hierarchy; b: Plan hierarchy.Figure 4(b) also shows coordination relationships: relationship indicatedsolid arc, relationship indicated dashed arc. Thus, WaitAtBase ScoutRoutes must done least one ScoutRoute1,ScoutRoute2 ScoutRoute3 need performed. also temporal dependence relationship among sub-plans, implies sub-teams assigned performDoTransport RemainingScouts cannot DoScouting plan completed. However, DoTransport RemainingScouts execute parallel. Finally,assign roles plans Figure 4(b) shows assignment brackets adjacent plans.instance, Task Force team assigned jointly perform Execute Mission SctTeamA assigned ScoutRoute1.team plan corresponding Execute Mission shown Figure 5.seen, team plan consists context, pre-conditions, post-conditions, body constraints. context describes conditions must fulfilled parent planpre-conditions particular conditions cause sub-plan begin exe373fiNair & Tambecution. Thus, Execute Mission, pre-condition team mutually believes(MB)1 start location. post-conditions divided Achieved,Unachievable Irrelevant conditions sub-plan terminated.body consists sub-plans exist within team plan. Lastly, constraints describetemporal constraints exist sub-plans body. descriptionplans plan hierarchy Figure 4(b) given Appendix A.ExecuteMission:Context:Pre-conditions: (MB <TaskForce> location(TaskForce) = START)Achieved: (MB <TaskForce> (Achieved(DoScouting) Achieved(DoTransport))) (time> (MB <TaskForce>Achieved(RemainingScouts) ( helo ScoutingTeam, alive(helo)location(helo) 6= END)))Unachievable: (MB <TaskForce> Unachievable(DoScouting)) (MB <TaskForce>Unachievable(DoTransport)(Achieved(RemainingScouts) ( helo ScoutingTeam, alive(helo)location(helo) 6= END)))Irrelevant:Body:DoScoutingDoTransportRemainingScoutsConstraints: DoScouting DoTransport, DoScouting RemainingScoutsFigure 5: Example team plan. MB refers mutual belief.HTN (Dix, Muoz-Avila, Nau, & Zhang, 2003; Erol, Hendler, & Nau, 1994),plan hierarchy TOP gives decomposition task smaller tasks. However,language TOPs richer language early HTN planning (Erol et al., 1994)contained simple ordering constraints. seen example, plan hierarchyTOPs also contain relationships like OR. addition, like recentwork HTN planning (Dix et al., 2003), sub-plans TOPs contain pre-conditionspost-conditions, thus allowing conditional plan execution. main differencesTOPs HTN planning are: (i) TOPs contain organization hierarchy additionplan hierarchy, (ii) TOP interpreter ensures team executes plans coherently.seen later, TOPs analyzed expressiveness including conditionalexecution; however, since analysis focus fixed time horizon, loopstask description unrolled time horizon.1. Mutual Belief (Wooldridge, 2002), shown (MB hteami x) Figure 5, refers private belief heldagent team believe fact x true, agentsteam believe x true, every agent believes every agent believes xtrue on. infinite levels nesting difficult realize practice. Thus, practicalBDI implementations, purposes article, mutual belief approximated privatebelief held agent agents team believe x true.374fiHybrid BDI-POMDP Framework Multiagent Teamingnew observationagentBelief UpdatefunctionPrivate beliefsagentFigure 6: Mapping observations beliefs.execution, agent copy TOP. agent also maintains setprivate beliefs, set propositions agent believes true (seeFigure 6). agent receives new beliefs, i.e. observations (including communication),belief update function used update set privately held beliefs. instance,upon seeing last scout crashed, transport may update privately held beliefsinclude belief CriticalFailure(DoScouting). practical BDI systems, beliefupdate computation low complexity (e.g. constant linear time). beliefsupdated, agent selects plan execute matching beliefs preconditions plans. basic execution cycle similar standard reactive planningsystems PRS (Georgeff & Lansky, 1986).team plan execution, observations form communications often arisecoordination actions executed TOP interpreter. instance, TOPinterpreters exploited BDI theories teamwork, Levesque et al.s theoryjoint intentions (Levesque, Cohen, & Nunes, 1990) require agentcomes privately believe fact terminates current team plan (i.e. matchesachievement unachievability conditions team plan), communicates factrest team. performing coordination actions automatically, TOPinterpreter enables coherence initiation termination team plans within TOP.details examples TOPs seen work PynadathTambe (2003), Tambe et al. (2000) Tidhar (1993b).concretely illustrate key challenges role allocation mentionedearlier. First, human developer must allocate available agents organization hierarchy (Figure 4(a)), find best role allocation. However, combinatorially manyallocations choose (Hunsberger & Grosz, 2000; Tambe et al., 2000). instance,starting 6 homogeneous helicopters results 84 different ways decidingmany agents assign scouting transport sub-team. problem exacerbated fact best allocation varies significantly based domain variations.example, Figure 7 shows three different assignments agents team organization hierarchy, found analysis best given setting failureobservation probabilities (details Section 6). example, increasing probabilityfailures routes resulted number transports best allocation changingfour (see Figure 7(b)) three (see Figure 7(a)), additional scout addedSctTeamB. failures possible all, number transports increasedfive (see Figure 7(c)). analysis takes step towards selecting best amongallocations.375fiNair & TambeTask ForceScouting TeamTask ForceTransport Team=3Scouting TeamSctTeamA=2 SctTeamB=1 SctTeamC=0Transport Team=4SctTeamA=2 SctTeamB=0 SctTeamC=0(a) Medium probability(b) Low probabilityTask ForceScouting TeamTransport Team=5SctTeamA=0 SctTeamB=0 SctTeamC=1(c) Zero probabilityFigure 7: Best role allocations different probabilities scout failure.Figure 8 shows TOP RoboCupRescue scenario. seen, plan hierarchy scenario consists pair ExtinguishFire RescueCivilians plansdone parallel, decompose individual plans. (These individual plans get fire engines ambulances move streets using specificsearch algorithms, however, individual plans relevant discussionsarticle; interested readers refer description RoboCupRescue teamentered RoboCup competitions 2001 (Nair, Ito, Tambe, & Marsella, 2002).)organizational hierarchy consists Task Force comprising two Engine sub-teams, onefire Ambulance Team, engine teams assigned extinguishingfires ambulance team assigned rescuing civilians. particular TOP,assignment ambulances AmbulanceTeamA AmbulanceTeamB conditionedcommunication c, indicated AmbulanceTeamA|c AmbulanceTeamB|c.c described detail figure, refers communication received fire engines describes number civilians present fire.problem engines assign Engine Team possible value c,ambulances assign Ambulance Team. Note engines differingcapabilities owing differing distances fires ambulances identicalcapabilities.Task ForceEngineTeamAEngineTeamBAmbulanceTeamAmbulanceTeamA |cAmbulanceTeamB |c(a)ExecuteMission[Task Force]ExtinguishFire1[EngineTeamA]RescueCivilians1[AmbulanceTeamA]ExtinguishFire2[EngineTeamB]RescueCivilians2[AmbulanceTeamB](b)Figure 8: TOP RoboCupRescue scenario a: Organization hierarchy; b: Plan hierarchy.376fiHybrid BDI-POMDP Framework Multiagent Teaming3. Role-based Multiagent Team Decision ProblemMultiagent Team Decision Problem (MTDP) (Pynadath & Tambe, 2002) inspiredeconomic theory teams (Marschak & Radner, 1972; Ho, 1980; Yoshikawa, 1978).order quantitative analysis key coordination decisions multiagent teams,extend MTDP analysis coordination actions interest. example,COM-MTDP (Pynadath & Tambe, 2002) extension MTDP analysis communication. article, illustrate general methodology analysis aspectscoordination present RMTDP model quantitative analysis role allocationreallocation concrete example. contrast BDI systems introduced previous section, RMTDP enables explicit quantitative optimization team performance. Notethat, use MTDP, possible distributed POMDP models could potentially alsoserve basis (Bernstein et al., 2000; Xuan et al., 2001).3.1 Multiagent Team Decision ProblemGiven team n agents, MTDP (Pynadath & Tambe, 2002) defined tuple:hS, A, P, , O, Ri. consists finite set states = 1 j ,1 j m, feature world state. agent perform actionset actions Ai , 1in Ai = A. P (s, < a1 , . . . , >, ) gives probabilitytransitioning state state given agents perform actions < a1 , . . . , >jointly. agent receives observation (1in = ) based functionO(s, < a1 , . . . , >, 1 , . . . , n ), gives probability agents receiveobservations, 1 , . . . , n given world state perform < a1 , . . . , >jointly. agents receive single joint reward R(s, < a1 , . . . , >) based statejoint action < a1 , . . . , >. joint reward shared equally membersprivate reward individual agents receive actions. Thus,agents motivated behave team, taking actions jointly yieldmaximum expected reward.agent MTDP chooses actions based local policy, ,mapping observation history actions. Thus, time t, agent perform action(i0 , . . . , ). contrasts single-agent POMDP, index agentspolicy belief state probability distribution world state (Kaelbling, Littman,& Cassandra, 1998), shown sufficient statistic order computeoptimal policy (Sondik, 1971). Unfortunately, cannot directly use single-agent POMDPtechniques (Kaelbling et al., 1998) maintaining updating belief states (Kaelbling et al.,1998) MTDP unlike single agent POMDP, MTDP, agents observationdepends actions, also unknown actions agents. Thus,distributed POMDP models (Bernstein et al., 2000; Xuan et al., 2001),MTDP, local policies indexed observation histories. =< 1 , . . . , n > refersjoint policy team agents.3.2 Extension Explicit CoordinationBeginning MTDP, next step methodology make explicit separationdomain-level actions coordination actions interest. Earlier work intro377fiNair & Tambeduced COM-MTDP model (Pynadath & Tambe, 2002), coordination actionfixed communication action, got separated out. However, coordination actions could also separated domain-level actions order investigateimpact. Thus, investigate role allocation reallocations, actions allocating agentsroles reallocate roles separated out. end, define RMTDP(Role-based Multiagent Team Decision Problem) tuple hS, A, P, , O, R, RLinew component, RL. particular, RL = {r1 , . . . , rs } set roles agentsundertake. instance role rj may assigned agent fulfill it.actions agent distinguishable two types:Role-Taking actions: = {irj } contains role-taking actions agent i. irjmeans agent takes role rj RL.Role-Execution Actions: = rj RL irj contains execution actions agentirj set agent actions executing role rj RLaddition define set states = 1 roles, feature roles (a vector) gives current role agent taken on. reasonintroducing new feature assist us mapping BDI team planRMTDP. Thus time agent performs new role-taking action successfully, valuefeature roles updated reflect change. keymodel agents initial role-taking action also subsequent role reallocation. Modelingallocation reallocation important accurate analysis BDI teams. Noteagent observe part feature pertaining current rolemay observe parts pertaining agents roles.introduction roles allows us represent specialized behaviors associatedrole, e.g. transport vs. scout role. filling particular role, rj , agentperform role-execution actions, irj , may different roleexecution actions irl role rl . Thus, feature roles used filter actionsrole-execution actions correspond agents current role permitted.worst case, filtering affect computational complexity (see Theorem 1below) practice, significantly improve performance trying findoptimal policy team, since number domain actions agent chooserestricted role agent taken on. Also, different rolesproduce varied effects world state (modeled via transition probabilities, P )teams reward. Thus, policies must ensure agents role capabilitiesbenefit team most.MTDP, agent chooses action perform indexing local policyobservation history. epoch agents could role-takingactions others role-execution actions. Thus, agents local policydivided local role-taking role-execution policies observationhistories, i0 , . . . , , either (i0 , . . . , ) = null (i0 , . . . , ) = null. =<1 , . . . , n > refers joint role-taking policy team agents =<1 , . . . , n > refers joint role-execution policy.378fiHybrid BDI-POMDP Framework Multiagent Teamingarticle explicitly model communicative actions special action.Thus communication treated like role-execution action communicationreceived agents treated observations.23.3 Complexity Results RMTDPSection 2.2 qualitatively emphasized difficulty role allocation, RMTDP helpsus understanding complexity precisely. goal RMTDP comejoint policies maximize total expected reward finite horizon. Note agents change roles according local role-taking policies.agents role-execution policy subsequent change would contain actions pertainingnew role. following theorem illustrates complexity finding optimal jointpolicies.Theorem 1 decision problem determining exist policies, ,RMTDP, yield expected reward least K finite horizon NEXPcomplete.Proof sketch: Proof follows reduction MTDP (Pynadath & Tambe, 2002)to/from RMTDP. reduce MTDP RMTDP, set RMTDPs role taking actions, ,null set RMTDPs role-execution actions, , MTDPs set actions, A.reduce RMTDPMTDP, generate new MTDP set actions,equal . Finding required policy MTDP NEXP-complete (Pynadath &Tambe, 2002).theorem shows us, solving RMTDP optimal joint role-taking roleexecution policies even finite horizon highly intractable. Hence, focuscomplexity determining optimal role-taking policy, given fixed role-executionpolicy. fixed role-execution policy, mean action selection agentpredetermined role executing.Theorem 2 decision problem determining exists role-taking policy, ,RMTDP, yields expected reward least K together fixed role-executionpolicy , finite horizon NEXP-complete.Proof sketch: reduce MTDP RMTDP different role-takingrole-execution action corresponding action MTDP. Hence, RMTDProle-taking action irj agent take role rj created action aj AiMTDP role rj contains single role-execution action, i.e. |irj | = 1.RMTDP, construct transition function role-taking action alwayssucceeds affected state feature roles . role-execution action irj ,transition probability MTDP action, aj Ai correspondinglast role-taking action irj . fixed role-execution policy simply performaction, irj , corresponding last successful role-taking action, irj . Thus,decision problem RMTDP fixed role-execution policy least hard2. explicit analysis communication please refer work done Pynadath Tambe (2002)Goldman et al. (2003).379fiNair & Tambedecision problem MTDP. Furthermore, given Theorem 1, concludeNEXP-Completeness.result suggests even fixing role-execution policy, solving RMTDPoptimal role-taking policy still intractable. Note Theorem 2 refers completelygeneral globally optimal role-taking policy, number agents change rolespoint time. Given result, general globally optimal role-taking policylikely doubly exponential complexity, may left choice runbrute-force policy search, i.e. enumerate role-taking policies evaluatethem, together determinethe run-time finding globally optimal policy.number policies||||T 1||1n, i.e. doubly exponential number observationhistories number agents. Thus, RMTDP enables quantitative evaluationteams policies, computing optimal policies intractable; furthermore, given low levelabstraction, contrast TOP, difficult human understand optimal policy.contrast RMTDP TOP root hybrid model describedfollowing section.4. Hybrid BDI-POMDP Approachexplained TOP RMTDP, present detailed viewhybrid methodology quantitatively evaluate TOP. first provide detailedinterpretation Figure 1. BDI team plans essentially TOP plans, BDIinterpreter TOP coordination layer. shown Figure 1, RMTDP modelconstructed corresponding domain TOP interpreter convertedcorresponding (incomplete) RMTDP policy. analyze TOP usinganalysis techniques rely evaluating RMTDP policy using RMTDP modeldomain.Thus, hybrid approach combines strengths TOPs (enabling humansspecify TOPs coordinate large-scale teams) strengths RMTDP (enablingquantitative evaluation different role allocations). one hand, synergisticinteraction enables RMTDPs improve performance TOP-based BDI teams.hand, identified least six specific ways TOPs make easierbuild RMTDPs efficiently search RMTDP policies: two discussedsection, four next section. particular, six ways are:1. TOPs exploited constructing RMTDP models domain (Section 4.1);2. TOPs exploited present incomplete policies RMTDPs, restricting RMTDPpolicy search (Section 5.1);3. TOP belief representation exploited enabling faster RMTDP policy evaluation(Section 4.2);4. TOP organization hierarchy exploited hierarchically grouping RMTDP policies(Section 5.1);5. TOP plan hierarchy exploited decomposing RMTDPs (Section 5.3);380fiHybrid BDI-POMDP Framework Multiagent Teaming6. TOP plan hierarchies also exploited cutting observation beliefhistories RMTDPs (Section 5.3).end result efficient policy search completed RMTDP policy improvesTOP performance. exploit TOP framework, frameworks taskingteams, e.g. Decker Lesser (1993) Stone Veloso (1999) could benefitsimilar synergistic interaction.4.1 Guidelines Constructing RMTDPshown Figure 1, analysis approach uses input RMTDP model domain,well incomplete RMTDP policy. Fortunately, TOP servedirect mapping RMTDP policy, also utilized actually constructingRMTDP model domain. particular, TOP used determinedomain features important model. addition, structure TOPexploited decomposing construction RMTDP.elements RMTDP tuple, hS, A, P, , O, R, RLi, defined using procedure relies TOP well underlying domain. procedureautomated, key contribution recognizing exploitation TOP structuresconstructing RMTDP model. First, order determine set states, S,critical model variables tested pre-conditions, termination conditionscontext components (i.e. sub-plans) TOP. Note state needsmodel features tested TOP; TOP pre-condition expresses complex testfeature, test modeled state, instead gets used definingincomplete policy input RMTDP. Next define set roles, RL, leaf-levelroles organization hierarchy TOP. Furthermore, specified Section 3.2,define state feature roles vector containing current role agent.defined RL roles , define actions, follows. role rj RL,define corresponding role-taking action, irj succeed fail dependingagent performs action state action performed in.role-execution actions, irj agent role rj , allowed role accordingTOP.Thus, defined S, RL based TOP. illustrate steps, considerplans Figure 4(b). pre-conditions leaf-level plan ScoutRoute1 (SeeAppendix A), instance, tests start location helicopters start location X,termination conditions test scouts end location Y. Thus, locationshelicopters modeled features set states RMTDP. Usingorganization hierarchy, define set roles RL role correspondingfour different kinds leaf-level roles, i.e. RL = {memberSctT eamA, memberSctT eamB,memberSctT eamC, memberT ransportT eam}. role-taking role-execution actionsdefined follows:role-taking action defined corresponding four roles RL, i.e.becoming member one three scouting teams transport team.domain specifies transport change scout thus role-takingaction, jointTransportTeam, fail agent i, current role agent scout.381fiNair & TambeRole-execution actions obtained TOP plans corresponding agentsrole. mission rehearsal scenario, agent, fulfilling scout role (membersSctTeamA, SctTeamB SctTeamC), always goes forward, making currentposition safe, reaches destination execution actionconsider move-making-safe. agent transport role (members TransportTeam) waits X obtains observation signal one scouting sub-teamreached hence role-execution actions wait move-forward.must define , P, O, R. obtain set observations agentdirectly domain. instance, transport helos may observe status scouthelos (normal destroyed), well signal path safe. Finally, determiningfunctions, P, O, R requires combination human domain expertise empiricaldata domain behavior. However, shown later Section 6, even approximatemodel transitional observational uncertainty sufficient deliver significant benefits. Defining reward transition function may sometimes require additional statevariables modeled, implicitly modeled TOP. missionrehearsal domain, time scouting transport mission completeddetermined amount reward. Thus, time implicitly modeled TOPneeded explicitly modeled RMTDP.Since interested analyzing particular TOP respect uncertainty,procedure constructing RMTDP model simplified exploiting hierarchical decomposition TOP order decompose construction RMTDPmodel. high-level components TOP often represent plans executed differentsub-teams, may loosely interact other. Within component,sub-team members may exhibit tight interaction, focus loose couplingacross components, end results one component feed another,components independently contribute team goal. Thus, procedure constructing RMTDP exploits loose coupling components plan hierarchyorder build RMTDP model represented combination smaller RMTDPs (factors). Note decomposition infeasible, approach still applies exceptbenefits hierarchical decomposition unavailable.classify sibling components either parallel sequentially executed (contains temporal constraint). Components executed parallel could either independentdependent. independent components, define RMTDPscomponents sub-team executing one component cannot affect transitions, observations reward obtained sub-teams executing components. procedure determining elements RMTDP tuple component k,hSk , Ak , Pk , k , Ok , Rk , RLk i, identical procedure described earlier constructingoverall RMTDP. However, component smaller set relevant variablesroles hence specifying elements corresponding RMTDP easier.combine RMTDPs independent components obtainRMTDP corresponding higher-level component. higher level component l,whose childcomponents independent, set states, Sl = x FSl xFSl = k s.t. Child(k,l)=true FSk FSl FSk sets features setstates Sl set states Sk . state sl Sl said correspond statesk Sk x FSk , sl [x ] = sk [x ], i.e. state sl value state sk382fiHybrid BDI-POMDP Framework Multiagent Teamingdefined follows, Pl (sl , al , sl ) =Q features state sk . transition functionk s.t. Child(k,l)=true Pk (sk , ak , sk ), sl sl component l corresponds statessk sk component k ak joint action performed sub-team assigned component k corresponding joint action al performed sub-teamassignedcomponent l. observation function defined similarly Ol (sl , al , l ) =QOk (sk , ak , k ). reward function component l definedk s.t. Child(k,l)=truePRl (sl , al ) = k s.t. Child(k,l)=true Rk (sk , ak ).case sequentially executed components (those connected temporal constraint), components loosely coupled since end states preceding componentspecify start states succeeding component. Thus, since one componentactive time, transition function defined follows, Pl (sl , al , sl ) = Pk (sk , ak , sk ),component k active child component, sk sk represent statescomponent k corresponding states sl sl component l ak joint actionperformed sub-team assigned component k corresponding joint actional performed sub-team corresponding component l. Similarly, defineOl (sl , al , l ) = Ok (sk , ak , k ) Rl (sl , al ) = Rk (sk , ak ), k active childcomponent.Consider following example mission rehearsal domain componentsexhibit sequential dependence parallel independence. Concretely, componentDoScouting executed first followed DoTransport RemainingScouts,parallel independent hence, either DoScouting active DoTransportRemainingScouts active point execution. Hence, transition, observation reward functions parent Execute Mission given correspondingfunctions either DoScouting combination corresponding functionsDoTransport RemainingScouts.use top-down approach order determine construct factored RMTDPplan hierarchy. shown Algorithm 1, replace particular sub-planconstituent sub-plans either independent sequentially executed. not,RMTDP defined using particular sub-plan. process applied recursivelystarting root component plan hierarchy. concrete example, considermission rehearsal simulation domain hierarchy illustrated Figure 4(b).Given temporal constraints DoScouting DoTransport, DoScouting RemainingScouts, exploited sequential decomposition, DoTransportRemainingScouts parallel independent components. Hence, replaceExecuteMission DoScouting, DoTransport RemainingScouts. apply process DoScouting. constituent components DoScoutingneither independent sequentially executed thus DoScouting cannot replacedconstituent components. Thus, RMTDP mission rehearsal domain comprisedsmaller RMTDPs DoScouting, DoTransport RemainingScouts.Thus, using TOP identify relevant variables building factored RMTDPutilizing structure TOP decompose construction procedure, reduce loaddomain expert model construction. Furthermore, shown Section 5.3,factored model greatly improves performance search best role allocation.383fiNair & TambeAlgorithm 1 Build-RMTDP(TOP top, Sub-plan subplan)1: children subplanchildren() {subplanchildren() returns sub-plans within subplan}2: children = null children (loosely coupled independent)3:rmtdp Define-RMTDP(subplan) {not automated}4:return rmtdp5: else6:child children7:factors[child] Build-RMTDP(top,child)8:rmtdp ConstructFromFactors(factors)9:return rmtdp4.2 Exploiting TOP Beliefs Evaluation RMTDP Policiespresent technique exploiting TOPs speeding evaluation RMTDPpolicies. explain improvement, first describe original algorithmdetermining expected reward joint policy, local policies agentindexed entire observation histories (Pynadath & Tambe, 2002; Nair, Pynadath,Yokoo, Tambe, & Marsella, 2003a). Here, obtain RMTDP policy TOPfollows. obtain (~), i.e. action performed agent observation history~i , action performed agent following TOP set privatelyheld beliefs corresponding observation history, ~it . compute expected rewardRMTDP policy projecting teams execution possible branchesdifferent world states different observations. time step, computeexpected value joint policy, =< 1 , . . . , n >, team starting given state, st ,given set past observations,~ 1t , . . . ,~ nt , follows:Xffffff~ nt ) = R(st , 1 (~Vt (st , ~1t , . . . ,1t ), . . . , n (~nt ) ) +P , 1~ 1t , . . . , n~ nt , st+1st+1Xffffffst+1, 1~ 1t , . . . , n~ nt , 1t+1, . . . , nt+1 Vt+1 st+1 , ~1t+1 , . . . ,~ nt+1(1)t+1expected reward joint policy given V0 (s0 , < null, . . . , null >) s0start state. time step t, computation Vt performs summationpossible world states agent observations time complexity (|S| ||).computationrepeated states observation histories length t, i.e.|S| ||t times. Therefore,given time horizon , overall complexity algo2+1rithm |S| ||.discussed Section 2.2, team-oriented program, agents action selectionbased currently held private beliefs (note mutual beliefs modeledprivately held beliefs agents per footnote 2). similar techniqueexploited mapping TOP RMTDP policy. Indeed, evaluation RMTDPpolicy corresponds TOP speeded agents local policy indexedprivate beliefs, . refer , TOP-congruent belief state agent384fiHybrid BDI-POMDP Framework Multiagent TeamingRMTDP. Note belief state probability distribution worldstates single agent POMDP, rather privately held beliefs (from BDIprogram) agent time t. similar idea representing policyfinite-state controller (Hansen & Zhou, 2003; Poupart & Boutilier, 2003). case,private beliefs would map states finite-state controller.Belief-based RMTDP policy evaluation leads speedup multiple observationhistories map belief state, . speedup key illustration exploitationsynergistic interactions TOP RMTDP. instance, belief representation techniques used TOP reflected RMTDP, resulting faster policy evaluationhelp us optimize TOP performance. detailed example belief state presented laterbrief explanation belief-based RMTDP policies evaluated.evaluation using observation histories, compute expected rewardbelief-based policy projecting teams execution possible branchesdifferent world states different observations. time step, computeexpected value joint policy, =< 1 , . . . , n >, team starting given state, st ,given team belief state, < 1t , . . . , nt > follows:ffff XffVt (st , 1t . . . nt ) = R(st , 1 (1t ), . . . , n (nt ) ) + P st , 1 1t , . . . , n nt , st+1st+1Xffffffst+1, 1 1t , . . . , n nt , 1t+1, . . . , nt+1 Vt+1 st+1 , 1t+1 , . . . , nt+1t+1(2)t+1= BeliefUpdateFunction, it+1complexity computing function (expression 2) (|S| ||) BF , BFrepresents complexity belief update function, BeliefUpdateFunction.time step computation value function done every state possiblereachable belief states. Let |i | = max1tT (|it |) represent maximum numberpossible belief states agent point time, |it | numberbelief states agent t. Therefore complexity algorithmgiven O(|S|2 || (|1 | . . . |n |) ) BF . Note that, algorithmexponent unlike algorithm expression 1. Thus, evaluation methodgive large time savings if: (i) quantity (|1 | . . . |n |) much less ||T(ii) belief update cost low. practical BDI systems, multiple observation historiesmap often onto belief state, thus usually, (|1 | . . . |n |) much less||T . Furthermore, since belief update function mirrors practical BDI systems,complexity also low polynomial constant. Indeed, experimental resultsshow significant speedups result switching TOP-congruent belief states. However, absolute worst case, belief update function may simply appendnew observation history past observations (i.e., TOP-congruent beliefsequivalent keeping entire observation histories) thus belief-based evaluationcomplexity observation history-based evaluation.turn example belief-based policy evaluation mission rehearsaldomain. time step, transport helicopters may receive observation385fiNair & Tambewhether scout failed based observation function. use observationhistory representation policy, transport agent would maintain completehistory observations could receive time step. example, settingtwo scout helicopters, one route 1 route 2, particular transporthelicopter may several different observation histories length two. every time step,transports may receive observation scout alive failed.Thus, time = 2, transport helicopter might one following observation histories length two, < {sct1OnRoute1Alive, sct2OnRoute2Alive}1 , {sct1OnRoute1F ailed,sct2OnRoute2F ailed}2 >, < {sct1OnRoute1Alive, sct2OnRoute2F ailed}1 , {sct1OnRoute1F ailed}2 >, < {sct1OnRoute1F ailed, sct2OnRoute2Alive}1 , {sct2OnRoute2F ailed}2 >,etc. However, action selection transport helicopters depends whethercritical failure (i.e. last remaining scout crashed) taken place changerole. Whether failure critical determined passing observationbelief-update function. exact order observations receivedprecise times failure non-failure observations received relevantdetermining critical failure taken place consequently whether transportchange role scout. Thus, many observation histories map ontobelief states. example, three observation histories map beliefCriticalF ailure(DoScouting) i.e. critical failure taken place. results significant speedups using belief-based evaluation, Equation 2 needs executedsmaller number belief states, linear domains, opposed observationhistory-based evaluation, Equation 1 executed exponential number observation histories (||T ). actual speedup obtained mission rehearsal domaindemonstrated empirically Section 6.5. Optimizing Role AllocationSection 4 focused mapping domain interest onto RMTDP algorithmspolicy evaluation, section focuses efficient techniques RMTDP policy search,service improving BDI/TOP team plans. TOP essence provides incomplete,fixed policy, policy search optimizes decisions left open incomplete policy;policy thus completed optimizes original TOP (see Figure 1). enabling RMTDPfocus search incomplete policies, providing ready-made decompositions,TOPs assist RMTDPs quickly searching policy space, illustratedsection. focus, particular, problem role allocation (Hunsberger & Grosz,2000; Modi, Shen, Tambe, & Yokoo, 2003; Tidhar et al., 1996; Fatima & Wooldridge, 2001),critical problem teams. TOP provides incomplete policy, keeping openrole allocation decision agent, RMTDP policy search provides optimalrole-taking action role allocation decision points. contrast previousrole allocation approaches, approach determines best role allocation, takingconsideration uncertainty domain future costs. Although demonstratedsolving role allocation problem, methodology general enough applycoordination decisions.386fiHybrid BDI-POMDP Framework Multiagent Teaming5.1 Hierarchical Grouping RMTDP Policiesmentioned earlier, address role allocation, TOP provides policy complete,except role allocation decisions. RMTDP policy search optimally fillsrole allocation decisions. understand RMTDP policy search, useful gainunderstanding role allocation search space. First, note role allocation focusesdeciding many types agents allocate different roles organizationhierarchy. role allocation decision may made time = 0 may madelater time conditioned available observations. Figure 9 shows partially expanded roleallocation space defined TOP organization hierarchy Figure 4(a) six helicopters.node role allocation space completely specifies allocation agents rolescorresponding level organization hierarchy (ignore now, numberright node). instance, root node role allocation space specifiessix helicopters assigned Task Force (level one) organization hierarchyleftmost leaf node (at level three) Figure 9 specifies one helicopter assignedSctTeamA, zero SctTeamB, zero SctTeamC five helicopters Transport Team.Thus, see, leaf node role allocation space complete, valid roleallocation agents roles organization hierarchy.order determine one leaf node (role allocation) superior another evaluateusing RMTDP constructing RMTDP policy each. particularexample, role allocation specified leaf node corresponds role-taking actionsagent execute time = 0. example, case leftmost leafFigure 9, time = 0, one agent (recall Section 2.2 homogeneous teamhence specific agent matter) become member SctTeamAagents become members Transport Team. Thus, one agent i, roletaking policy include (null) = joinSctT eamA agents, j, j 6= i,include j (null) = joinT ransportT eam. case, assume restrole-taking policy, i.e. roles reallocated scout fails, obtained rolereallocation algorithm BDI/TOP interpreter, STEAM algorithm (Tambeet al., 2000). Thus example, role reallocation indeed performed STEAMalgorithm, STEAMs reallocation policy included incomplete policyRMTDP initially provided. Thus, best role allocation computed keepingmind STEAMs reallocation policy. STEAM, given failure agent playing RoleF ,agent playing RoleR replace if:Criticality (RoleF ) Criticality (RoleR ) > 0Criticality (x) = 1 x critical; = 0 otherwiseThus, based agents observations, critical failure taken place,replacing agents decision replace computed using expressionincluded incomplete policy input RMTDP. Since incompletepolicy completed role allocation leaf node using technique above,able construct policy RMTDP corresponds role allocation.domains like RoboCupRescue, allocation decisions made time= 0. domains, possible role allocation conditioned observations(or communication) obtained course execution. instance,shown Figure 8(a), RoboCupRescue scenario, ambulances allocatedsub-team AmbulanceTeamA AmbulanceTeamB information location387fiNair & Tambe606[0]616[4167]526[3420]436[2773]346[1926]256[1179]166[432]06 1359.576 2926.086 1500.126 613.812 42 41 51 51 1 00 0 20 0 11 0 0Figure 9: Partially expanded role allocation space mission rehearsal domain(six helos).civilians conveyed fire engines. allocation ambulancesconditioned communication, i.e. number civilians location.Figure 10 shows partially expanded role allocation scaled-down rescue scenariothree civilians, two ambulances two fire engines (one station 1station 2). Figure, 1;1;2 depicts fact two ambulances,one fire engine station. shown, level allocation fire enginesEngineTeamA EngineTeamB gives number engines assignedEngineTeam station. next level (leaf level) different leaf nodespossible assignment ambulances AmbulanceTeamA AmbulanceTeamB dependingupon value communication c. Since three civilians excludecase civilians present particular fire, two possible messages i.e.one civilian fire 1 two civilians fire 1 (c = 1 2).TaskForce=1;1;21;1;21;1;2EngineTeamA=0;1 EngineTeamB=1;0 AmbTeam=2c=1EngineTeamA=1;0 EngineTeamB=0;1 AmbTeam=21;1;21;1;20;1 1;0 20;1 1;0 2c=2c=1AmbTeamA=2 AmbTeamB=0 AmbTeamA=1 AmbTeamB=1c=2AmbTeamA=1 AmbTeamB=1 AmbTeamA=1 AmbTeamB=1Figure 10: Partially expanded role allocation space Rescue domain (one fire enginestation 1, one fire engine station 2, two ambulances, three civilians).thus able exploit TOP organization hierarchy create hierarchicalgrouping RMTDP policies. particular, leaf node represents completeRMTDP policy (with role allocation specified leaf node), parent noderepresents group policies. Evaluating policy specified leaf node equivalentevaluating specific role allocation taking future uncertainties account. could388fiHybrid BDI-POMDP Framework Multiagent Teamingbrute force search role allocations, evaluating order determinebest role allocation. However, number possible role allocations exponentialleaf roles organization hierarchy. Thus, must prune search space.5.2 Pruning Role Allocation Spaceprune space valid role allocations using upper bounds (MaxEstimates)parents leaves role allocation space admissible heuristics (Section 5.3).leaf role allocation space represents completely specified policy MaxEstimate upper bound maximum value policies parent nodeevaluated using RMTDP. obtain MaxEstimates parent nodes (shownbrackets right parent node Figure 9), use branch-and-bound stylepruning (see Algorithm 2). discuss Algorithm 2 below, note essenceperforms branch-and-bound style pruning; key novelty step 2 discussSection 5.3.branch-and-bound algorithm works follows: First, sort parent nodesestimates start evaluating children parent highest MaxEstimate (Algorithm 2: steps 3-13). Evaluate(RMTDP, child) refers evaluationleaf-level policy, child, using RMTDP model. evaluation leaf-level policies (step13) done using either methods described Section 4. caserole allocation space Figure 9, would start evaluating leaves parentnode one helicopter Scouting Team five Transport Team. valueevaluating leaf node shown right leaf node. obtainedvalue best leaf node (Algorithm 2: steps 14,15), case 1500.12, compareMaxEstimates parents role allocation space (Algorithm 2:steps 16-18). see Figure 9 would result pruning three parent nodes(leftmost parent right two parents) avoid evaluation 65 84 leaf-levelpolicies. Next, would proceed evaluate leaf nodes parenttwo helos Scouting Team four Transport Team. would result pruningremaining unexpanded parent nodes return leaf highest value,case node corresponding two helos allocated SctTeamA fourTransport Team. Although demonstrated 3-level hierarchy, methodologyapplying deeper hierarchies straightforward.5.3 Exploiting TOP Calculate Upper Bounds Parentsdiscuss upper bounds parents, called MaxEstimates, calculated parent. MaxEstimate parent defined strict upper boundmaximum expected reward leaf nodes it. necessaryMaxEstimate upper bound else might end pruning potentially useful roleallocations. order calculate MaxEstimate parent could evaluateleaf nodes using RMTDP, would nullify benefit subsequent pruning. We, therefore, turn TOP plan hierarchy (see Figure 4(b)) breakevaluation parent node components, evaluated separately thusdecomposing problem. words, approach exploits structure BDIprogram construct small-scale RMTDPs unlike decomposition techniques389fiNair & TambeAlgorithm 2 Branch-and-bound algorithm policy search.1: Parents list parent nodes2: Compute MAXEXP(Parents) {Algorithm 3}3: Sort Parents decreasing order MAXEXP4: bestVal5: parent Parents6:done[parent] false; pruned[parent] false7: parent Parents8:done[parent] = false pruned[parent] = false9:child parentnextChild() {child leaf-level policy parent}10:child = null11:done[parent] true12:else13:childVal Evaluate(RMTDP,child)14:childVal > bestVal15:bestVal childVal;best child16:parent1 Parents17:MAXEXP[parent1] < bestVal18:pruned[parent1] true19: return bestassume decomposition ultimately rely domain experts identify interactionsagents reward transition functions (Dean & Lin, 1995; Guestrin, Venkataraman,& Koller, 2002).parent role allocation space, use small-scale RMTDPs evaluate values TOP component. Fortunately, discussed Section 4.1,exploited small-scale RMTDPs corresponding TOP components constructing largerscale RMTDPs. put small-scale RMTDPs use again, evaluating policies withincomponent obtain upper bounds. Note like evaluation leaf-levelpolicies, evaluation components parent node done using eitherobservation histories (see Equation 1) belief states (see Equation 2). describesection using observation history-based evaluation method computing valuescomponents parent, summed obtain MaxEstimate (anupper bound childrens values). Thus, whereas parent role allocation spacerepresents group policies, TOP components (sub-plans) allow component-wiseevaluation group obtain upper bound expected reward policywithin group.Algorithm 3 exploits smaller-scale RMTDP components, discussed Section 4.1,obtain upper bounds parents. First, order evaluate MaxEstimateparent node role allocation space, identify start states componentevaluate RMTDPs. explain step using parent node Figure 9Scouting Team = two helos, Transport Team = four helos (see Figure 11). firstcomponent preceding components, start states correspondsstart states policy TOP mapped onto. next390fiHybrid BDI-POMDP Framework Multiagent Teamingcomponents next component one linked sequential dependencestart states end states preceding component. However, explained latersection, significantly reduce list start states componentevaluated.Algorithm 3 MAXEXP method calculating upper bounds parents role allocation space.1: parent search space2:MAXEXP[parent] 03:component corresponding factors RMTDP Section 4.14:component preceding component j5:Obtain start states, states[i] endStates[j]6:states[i] removeIrrelevantFeatures(states[i]) {discard features presentSi }7:Obtain corresponding observation histories start OHistories[i]endOHistories[j]8:OHistories[i] removeIrrelevantObservations(OHistories[i])9:else10:Obtain start states, states[i]11:Observation histories start OHistories[i] null12:maxEval[i] 013:leaf-level policies parent14:maxEval[i] max(maxEval[i], maxsi states[i],ohi OHistories[i](Evaluate(RM DPi ,si , ohi , )))+15:MAXEXP[parent] maxEval[i]Similarly, starting observation histories component observation histories completing preceding component (no observation history firstcomponent). BDI plans normally refer entire observation histories relykey beliefs typically referred pre-conditions component.starting observation history shortened include relevant observations,thus obtaining reduced list starting observation sequences. Divergence private observations problematic, e.g. cause agents trigger different team plans.indicated earlier Section 2.2, TOP interpreters guarantee coherencekey aspects observation histories. instance, discussed earlier, TOP interpreterensures coherence key beliefs initiating terminating team plans TOP; thusavoiding divergence observation histories.order compute maximum value particular component, evaluatepossible leaf-level policies within component possible start states observation histories obtain maximum (Algorithm 3:steps 13-14). evaluation,store end states ending observation histories usedevaluation subsequent components. shown Figure 11, evaluationDoScouting component parent node two helicopters assignedScouting Team four helos Transport Team, leaf-level policies correspondpossible ways helicopters could assigned teams SctTeamA, SctTeamB, Sct391fiNair & TambeTeamC Transport Team, e.g. one helo SctTeamB, one helo SctTeamC fourhelos Transport Team, two helos SctTeamA four helos Transport Team, etc.role allocation tells agents role take first step. remainderrole-taking policy specified role replacement policy TOP infrastructurerole-execution policy specified DoScouting component TOP.obtain MaxEstimate parent node role allocation space, simplysum maximum values obtained component (Algorithm 3:steps 15), e.g.maximum values component (see right component Figure 11)summed obtain MaxEstimate (84 + 3330 + 36 = 3420). seen Figure 9, thirdnode left indeed upper bound 3420.calculation MaxEstimate parent nodes much fasterevaluating leaf nodes cases two reasons. Firstly, parent nodesevaluated component-wise. Thus, multiple leaf-level policies within one component resultend state, remove duplicates get start states next component. Since component contains state features relevant it, numberduplicates greatly increased. duplication evaluation effort cannot avoidedleaf nodes, policy evaluated independently start finish. instance, DoScouting component, role allocations, SctTeamA=1, SctTeamB=1,SctTeamC=0, TransportTeam=4 SctTeamA=1, SctTeamB=0, SctTeamC=1, TransportTeam=4, end states common eliminating irrelevant featuresscout SctTeamB former allocation scout SctTeamC latter allocation fail. feature elimination (Algorithm 3:steps 6),state features retained DoTransport scouted route number transports(some transports may replaced failed scouts) shown Figure 11.second reason computation MaxEstimates parents much fasternumber starting observation sequences much less number ending observation histories preceding components. observationsobservation histories component relevant succeeding components (Algorithm 3:steps 8). Thus, function removeIrrelevantObservations reduces numberstarting observation histories observation histories preceding component.refer methodology obtaining MaxEstimates parent MAXEXP. variation this, maximum expected reward failures (NOFAIL),obtained similar fashion except assume probability agent failing 0. able make assumption evaluating parent node, sincefocus obtaining upper bounds parents, obtaining exact value.result less branching hence evaluation component proceed muchquicker. NOFAIL heuristic works evaluation policy without failuresoccurring higher evaluation policy failures possible.normally case domains. evaluation NOFAIL heuristicsrole allocation space six helicopters shown square brackets Figure 9.following theorem shows MAXEXP method finding upper boundsindeed finds upper bound thus yields admissible search heuristic branchand-bound search role allocation space.Theorem 3 MAXEXP method always yield upper bound.392fiHybrid BDI-POMDP Framework Multiagent Teaming[84]DoScouting[ScoutingTeam=2,TransportTeam=4]Alloc:SctTeamA=2SctTeamB=0SctTeamC=0TransportTeam=4Alloc:SctTeamA=0SctTeamB=1SctTeamC=1TransportTeam=4[3300]DoTransport[TransportTeam=4]StartState:RouteScouted=1Transports=4[36]RemainingScouts[ScoutTeam=2]StartState:RouteScouted=1Transports=3StartState:RouteScouted=1Transports=0Figure 11: Component-wise decomposition parent exploiting TOP.Proof: See Appendix C.Theorem 3, conclude branch-and-bound policy search algorithmalways find best role allocation, since MaxEstimates parents trueupper bounds. Also, help Theorem 4, show worst case,branch-and-bound policy search complexity brute force search.Theorem 4 Worst-case complexity evaluating single parent node using MAXEXPevaluating every leaf node within constant factor.Proof sketch:worst case complexity MAXEXP arises when:1. Let ESj end states component j executing policy removingfeatures irrelevant succeeding component k. Similarly, let ESjend states component j executing policyTremoving featuresirrelevant succeeding component k. ESj ESj = nullduplication end states occur.2. Let OHj ending observation histories component j executing policyremoving observations irrelevant succeeding componentk. Similarly, let OHj ending observation histories component j executing policy removing observationhistories irrelevantsucceeding component k. OHj OHj = null duplicationobservation histories occur. Note belief-based evaluation usedwould replace observation histories TOP congruent belief states(see Sect 4).case, computational advantage evaluating componentsMaxEstimate separately. Thus, equivalent evaluating child nodeparent. Thus, worst case, MAXEXP computation parentevaluating children within constant factor.addition, worst case, pruning result using MAXEXP everyleaf node need evaluated. equivalent evaluating leaf node twice.393fiNair & TambeThus, worst case complexity branch-and-bound search using MAXEXPfinding best role allocation evaluating every leaf node. referbrute-force approach NOPRUNE. Thus, worst case complexity MAXEXPNOPRUNE. However, owing pruning savings decomposition computation MaxEstimates, significant savings likely averagecase. Section 6 highlights savings mission rehearsal RoboCupRescuedomains.6. Experimental Resultssection presents four sets results context two domains introducedSection 2.1, viz. mission rehearsal RoboCupRescue (Kitano et al., 1999). First,investigated empirically speedups result using TOP-congruent beliefstates (belief-based evaluation) observation history-based evaluation usingalgorithm Section 5 brute-force search. focus determiningbest assignment agents roles; assume fixed TOP TOP infrastructure.Second, conducted experiments investigate benefits considering uncertaintydetermining role allocations. this, compared allocations found RMTDProle allocation algorithm (i) allocations consider kind uncertainty,(ii) allocations consider observational uncertainty consider actionuncertainty. Third, conducted experiments domains determine sensitivityresults changes model. Fourth, compare performance allocationsfound RMTDP role allocation algorithm allocations human subjectscomplex domains RoboCupRescue simulations.6.1 Results Mission Rehearsal Domainmission rehearsal domain, TOP one discussed Section 2.2.seen Figure 4(a), organization hierarchy requires determining number agentsallocated three scouting sub-teams remaining helos must allocatedtransport sub-team. Different numbers initial helicopters attempted, varyingthree ten. details RMTDP constructed domain givenAppendix B. probability failure scout time step routes 1, 2 30.1, 0.15 0.2, respectively. probability transport observing alive scoutroutes 1, 2 3 0.95, 0.94 0.93, respectively. False positives possible,i.e. transport observe scout alive failed. probabilitytransport observing scout failure routes 1, 2 3 0.98, 0.97 0.96, respectively.too, false positives possible hence transport observe failureunless actually taken place.Figure 12 shows results comparing different methods searching roleallocation space. show four methods. method adds new speedup techniquesprevious:1. NOPRUNE-OBS: brute force evaluation every role allocation determinebest. Here, agent maintains complete observation history evaluationalgorithm Equation 1 used. ten agents, RMTDP projected394fiHybrid BDI-POMDP Framework Multiagent Teamingorder 10,000 reachable states order 100,000 observation historiesper role allocation evaluated (thus largest experiment category limitedseven agents).2. NOPRUNE-BEL: brute force evaluation every role allocation. differencemethod NOPRUNE-OBS use belief-based evaluationalgorithm (see Equation 2).3. MAXEXP: branch-and-bound search algorithm described Section 5.2uses upper bounds evaluation parent nodes find best allocation.Evaluation parent leaf nodes uses belief-based evaluation.4. NOFAIL: modification branch-and-bound heuristic mentioned Section 5.3.essence MAXEXP, except upper bounds computed makingassumption agents fail. heuristic correct domainstotal expected reward failures always less failures presentgive significant speedups agent failures one primary sourcesstochasticity. method, too, evaluation parent leaf nodes usesbelief-based evaluation. (Note upper bounds computed usingno-failure assumption changes assumed actual domains.)Figure 12(a), Y-axis number nodes role allocation space evaluated(includes leaf nodes well parent nodes), Figure 12(b) Y-axis representsruntime seconds logarithmic scale. figures, vary number agentsX-axis. Experimental results previous work using distributed POMDPs oftenrestricted two agents; exploiting hybrid models, able vary numberagents three ten shown Figure 12(a). clearly seen Figure 12(a),pruning, significant reductions obtained MAXEXP NOFAIL NOPRUNEBEL terms numbers nodes evaluated. reduction grows quadratically10-fold ten agents.3 NOPRUNE-OBS identical NOPRUNE-BEL termsnumber nodes evaluated, since methods leaf-level policies evaluated,method evaluation differs. important note although NOFAILMAXEXP result number nodes evaluated domains,necessarily true always. general, NOFAIL evaluate least many nodesMAXEXP since estimate least high MAXEXP estimate. However,upper bounds computed quicker NOFAIL.Figure 12(b) shows NOPRUNE-BEL method provides significant speedupNOPRUNE-OBS actual run-time. instance, 12-fold speedup usingNOPRUNE-BEL instead NOPRUNE-OBS seven agent case (NOPRUNE-OBScould executed within day problem settings greater seven agents).empirically demonstrates computational savings possible using belief-based evaluation instead observation history-based evaluation (see Section 4). reason,use belief-based evaluation MAXEXP NOFAIL approaches also3. number nodes NOPRUNE eight agents obtained experiments, restcalculated using formula [m]n /n! = (m + n 1) . . . m/n!, represents numberheterogeneous role types n number homogeneous agents. [m]n = (m + n 1) . . .referred rising factorial.395fiNair & Tamberemaining experiments paper. MAXEXP heuristic results 16-fold speedupNOPRUNE-BEL eight agent case.NOFAIL heuristic quick compute upper bounds far outperformsMAXEXP heuristic (47-fold speedup MAXEXP ten agents). SpeedupsMAXEXP NOFAIL continually increase increasing number agents. speedupNOFAIL method MAXEXP marked because, domain, ignoringfailures results much less branching.350NOFAIL, MAXEXPNumber nodes300NOPRUNE-OBS,NOPRUNE-BEL250200150100500345678910Number agents100000MAXEXPNOFAILNOPRUNE-BELNOPRUNE-OBSTime secs (log scale)1000010001001010.10.01345678910Number agentsFigure 12: Performance role allocation space search mission rehearsal domain, a) (left)Number nodes evaluated, b) (right)Run-time seconds log scale.Next, conducted experiments illustrating importance RMTDPs reasoningaction observation uncertainties role allocations. this, comparedallocations found RMTDP role allocation algorithm allocations found using twodifferent methods (see Figure 13):1. Role allocation via constraint optimization (COP) (Modi et al., 2003; Mailler & Lesser,2004) allocation approach: COP approach4 , leaf-level sub-teams or4. Modi et al.s work (2003) focused decentralized COP, investigation emphasisresulting role allocation generated COP, decentralization per se.396fiHybrid BDI-POMDP Framework Multiagent Teamingganization hierarchy treated variables number helicoptersdomain variable (thus, domain may 1, 2, 3,..helicopters).reward allocating agents sub-teams expressed terms constraints:Allocating helicopter scout route assigned reward correspondingroutes distance ignoring possibility failure (i.e. ignoring transitionprobability). Allocating helicopters subteam obtained proportionally higher reward.Allocating helicopter transport role assigned large reward transporting cargo destination. Allocating helicopters subteamobtained proportionally higher reward.allocating least one scout role assigned reward negative infinityExceeding total number agents assigned reward negative infinity2. RMTDP complete observability: approach, consider transitionprobability, ignore partial observability; achieved assuming complete observability RMTDP. MTDP complete observability equivalentMarkov Decision Problem (MDP) (Pynadath & Tambe, 2002) actionsjoint actions. We, thus, refer allocation method MDP method.Figure 13(a) shows comparison RMTDP-based allocation MDP allocation COP allocation increasing number helicopters (X-axis). compareusing expected number transports get destination (Y-axis) metriccomparison since primary objective domain. seen, considering forms uncertainty (RMTDP) performs better considering transitionuncertainty (MDP) turn performs better considering uncertainty (COP).Figure 13(b) shows actual allocations found three methods four helicopterssix helicopters. case four helicopters (first three bars), RMTDP MDPidentical, two helicopters scouting route 2 two helicopters taking transport role.COP allocation however consists one scout route 3 three transports.allocation proves myopic results fewer transports getting destinationsafely. case six helicopters, COP chooses one scout helicopter route 3,shortest route. MDP approach results two scouts route 1,longest route albeit safest. RMTDP approach, also considers observationaluncertainty chooses additional scout route 2, order take care casesfailures scouts go undetected transports.noted performance RMTDP-based allocation dependvalues elements RMTDP model. However, next experimentrevealed, getting values exactly correct necessary. order test sensitivityperformance allocations actual model values, introduced errorvarious parameters model see allocations found using incorrect modelwould perform original model (without errors). emulates situationmodel correctly represent domain. Figure 14 shows expected numbertransports reach destination (Y-axis) mission rehearsal scenario sixhelicopters error (X-axis) introduced various parameters model. instance,397fiNair & Tambe7Number transports65RMTDPCOPMDP4321045678Number agents76 helosRMxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxRt3Rt2xxxxxxRt1xxxTransportsxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxDPTDP0xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxTDPxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxRM2xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxDP3xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxP4CONumber helos5PxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxCO4 helos6Figure 13: a) Comparison performance different allocation methods, b)Allocationsfound using different allocation methods.398fiHybrid BDI-POMDP Framework Multiagent Teamingpercentage error failure rate route 1 (route1-failure-rate) -15%(i.e. erroneous failure rate 85% actual failure rate) 10%, differencenumber transports reached destination (3.498). Howeverpercentage error greater 10%, allocation found conservative resultingfewer transports getting destination. Similarly, percentage error less-15%, allocation found risky, scouts assigned, resultingfailures. general, Figure 14 shows model insensitive errors 5 10%model parameters mission rehearsal domain, model parametersoutside range, non-optimal allocations would result. comparing non-optimalallocations COP, find always perform better COP rangeerrors tested (+/-25%) failure rate well observability routes. instance,error 25% failure rate route 1, RMTDP managed 2.554 transportssafely reach destination, COP managed get 1.997 transports reach safely.comparing non-optimal allocations MDP, also find performed betterMDP within range +/- 25% error observability routes. Thus,although allocations found using incorrect model non-optimal performedbetter COP MDP large ranges errors model. shows gettingmodel exactly correct necessary find good allocations. thus ableobtain benefits RMTDP even without insisting accurate model.4route1-failure-rateroute-2-failure-rateroute3-failure-rateroute1-observabilityNumber Transports3.532.521.510.50-25 -20 -15 -10 -50510152025Percentage errorFigure 14: Model sensitivity mission rehearsal domain.6.2 Results RoboCupRescue Domain6.2.1 Speedups RoboCupRescue Domainnext set experiments, highlight computational savings obtainedRoboCupRescue domain. scenario experiment consisted two fires differentlocations city. fires different initially unknown number civiliansit, however total number civilians distribution locationscivilians chosen known ahead time. experiment, fix numbercivilians five set distribution used choose civilians locations uniform.number fire engines set five, located three different fire stations described399fiNair & TambeSection 2.1 vary number ambulances, co-located ambulance center,two seven. reason chose change number ambulancessmall number fire engines unable extinguish fires, changing problem completely.goal determine fire engines allocate fire informationcivilians transmitted, many ambulances send fire location.Figure 15 highlights savings terms number nodes evaluated actualruntime increase number agents. show results NOPRUNE-BELMAXEXP. NOPRUNE-OBS could run slowness. NOFAILheuristic identical MAXEXP since agents cannot fail scenario. RMTDPcase 30,000 reachable states.Figures 15(a) 15(b), increase number ambulances along Xaxis. Figure 15(a), show number nodes evaluated (parent nodes + leaf nodes)5logarithmic scale. seen, MAXEXP method results 89-folddecrease number nodes evaluated compared NOPRUNE-BEL sevenambulances, decrease becomes pronounced number ambulancesincreased. Figure 15(b) shows time seconds logarithmic scale Y-axiscompares run-times MAXEXP NOPRUNE-BEL methods finding bestrole allocation. NOPRUNE-BEL method could find best allocation withinday number ambulances increased beyond four. four ambulances (andfive fire engines), MAXEXP resulted 29-fold speedup NOPRUNE-BEL.6.2.2 Allocation RoboCupRescuenext set experiments shows practical utility role allocation analysiscomplex domains. able show significant performance improvements actualRoboCupRescue domain using role allocations generated analysis. First,construct RMTDP rescue scenario, described Section 2.1, taking guidanceTOP underlying domain (as described Section 4.1). useMAXEXP heuristic determine best role allocation. compared RMTDPallocation allocations chosen human subjects. goal comparing RMTDPallocations human subjects mainly show RMTDP capable performingnear human expert levels domain. addition, order determinereasoning uncertainty actually impacts allocations, compared RMTDPallocations allocations determined two additional allocation methods:1. RescueISI: Allocations used RoboCupRescue agents enteredRoboCupRescue competitions 2001(RescueISI) (Nair et al., 2002),finished third place. agents used local reasoning decision making,ignoring transitional well observational uncertainty.2. RMTDP complete observability: discussed earlier, complete observabilityRMTDP leads MDP, refer method MDP method.5. number nodes evaluated using NOPRUNE-BEL computed (f1 + 1) (f2 + 1) (f3 + 1)(a + 1)c+1 , f1 , f2 f3 number fire engines station 1, 2 3, respectively,number ambulances c number civilians. node provides complete conditionalrole allocation, assuming different numbers civilians fire station.400fiHybrid BDI-POMDP Framework Multiagent TeamingNumber nodes (log scale)10000000MAXEXPNOPRUNE1000000100000100001000100101234567Number ambulancesRun time secs (log scale)100000MAXEXPNOPRUNE1000010001001012345Number ambulances67Figure 15: Performance role allocation space search RoboCupRescue, a: (left) Numbernodes evaluated log scale, b: (right) Run-time seconds logscale.401fiNair & TambeNote comparisons performed using RoboCupRescue simulatormultiple runs deal stochasticity6 . scenario described Section 6.2.1.fix number fire engines, ambulances civilians five each. experiment,consider two settings, location civilians drawn from:Uniform distribution 25% cases four civilians fire 1 one civilianfire 2, 25% three civilians fire 1 two fire 2, 25% two civiliansfire 1 three fire 2 remaining 25% one civilian fire 1four civilians fire 2. speedup results Section 6.2.1 obtained usingdistribution.Skewed distribution 80% cases four civilians fire 1 one civilianfire 2 remaining 20% one civilian fire 1 four civilians fire 2.Note consider case civilians located fireoptimal ambulance allocation simply assign ambulances firecivilians located. skewed distribution chosen highlight casesbecomes difficult humans reason allocation choose.three human subjects used experiment researchers USC. threefamiliar RoboCupRescue. given time study setupgiven time limit provide allocations. subject told allocationsgoing judged first basis number civilian lives lost nextdamage sustained due fire. exactly criteria used RoboCupRescue (Kitanoet al., 1999).compared RMTDP allocation human subjectsRoboCupRescue simulator RescueISI MDP. Figure 16, comparedperformance allocations basis number civilians diedaverage damage two buildings (lower values better criteria). twocriteria main two criteria used RoboCupRescue (Kitano et al., 1999). values shown Figure 16 obtained averaging forty simulator runs uniformdistribution twenty runs skewed distribution allocation. averagevalues plotted account stochasticity domain. Error bars providedshow standard error allocation method.seen Figure 16(a), RMTDP allocation better fiveallocations terms lower number civilians dead (although human3 quite close).example, averaging forty runs, RMTDP allocation resulted 1.95 civilian deathshuman2s allocation resulted 2.55 civilian deaths. terms average buildingdamage, six allocations almost indifferentiable, humans actually performing marginally better. Using skewed distribution, difference allocationsmuch perceptible (see Figure 16(b)). particular, notice RMTDPallocation much better humans terms number civilians dead. Here,human3 particularly badly bad allocation fire engines. resulteddamage buildings consequently number civilians dead.6. mission rehearsal domain, could run actual mission rehearsal simulator sincesimulator public domain longer accessible, hence difference tested roleallocations mission rehearsal RoboCupRescue domains.402fiHybrid BDI-POMDP Framework Multiagent TeamingComparing RMTDP RescueISI MDP approach showed reasoningtransitional uncertainty (MDP) better static reactive allocation method(RescueISI) well reasoning transitional observational uncertainty. uniform distribution case, found RMTDP better MDPRescueISI, MDP method performing better RescueISI. skewed distribution case, improvement allocations using RMTDP greater. Averaging twentysimulation runs, RMTDP allocations resulted 1.54 civilians deaths MDP resulted1.98 RescueISI 3.52. allocation method used RescueISI often resultedone fires allocated fire engines. allocations determinedMDP approach turned human1.two-tailed t-test performed order test statistical significance meansallocations Figure 16. means number civilians dead RMTDPallocation human allocations found statistically different (confidence> 96%) uniform well skewed distributions. difference firedamage statistically significant uniform case, however, differenceRMTDP allocation human3 fire damage statistically significant (> 96%)skewed case.6Civilians casualtiesBuilding damage54321DPue3sc2huhu1huRMTDP06Civilians casualtiesBuilding damage54321DPscue3hu2hu1huRMTDP0Figure 16: Comparison performance RoboCupRescue, a: (left) uniform, b: (right)skewed.403fiNair & TambeConsidering average performance different allocations highlightindividual cases marked differences seen performance. Figure 17,present comparison particular settings allocation methods showedbigger difference RMTDP terms allocations. standard error shownerror bars allocation. Figures 17(a) 17(b) compare allocations uniformcivilian distributions setting one civilian fire 1 four civiliansfire 2 (1-4 civilian setting) four civilians fire 1 one fire 2 (4-1 civilian setting)respectively. seen figure, RMTDP allocation results fewer civiliancasualties slightly damage buildings due fire (difference fire damagestatistically significant damage values close). Figures 17(c)17(d) compare allocations skewed civilian distribution. key differencearises human3. seen, human3 results damage due fire.human3 allocated fire engines one buildings, turn resultedbuilding burnt completely. Consequently, civilians located firelocation could rescued ambulances. Thus, see specific instancesallocation done using RMTDP-based allocation algorithm superior allocationshuman comes with.3.5Civilians casualtiesBuilding damage34.5Civilians casualtiesBuilding damage43.52.5322.521.51.513.5DPue3sc2huhuPTDCivilians casualtiesBuilding damage3huRMDP3uehuschuhuTDRM2010P0.5110.54.5Civilians casualtiesBuilding damage43.52.5322.521.51.5110.50.5DPscue3hu2huhuPRMTDDPue3schu2hu1huTDPRM100Figure 17: Comparison performance RoboCupRescue particular settings, a: (topleft) uniform 1-4 civilian setting b:(top-right) uniform 4-1 civilian setting, c:(bottom-left) skewed 1-4 civilian setting d:(bottom-right) skewed 4-1 civiliansetting.404fiHybrid BDI-POMDP Framework Multiagent TeamingTable 1 shows allocations fire 1 (agents assigned fire 1 allocated fire2) found RMTDP role allocation algorithm used human subjectsskewed 4-1 civilian setting (we consider case since shows difference).particular, table highlights differences various allocators skewed4-1 civilian setting helps account differences seen performanceactual simulator. seen Figure 17(d), main difference performanceterms number civilians saved. Recall scenario, fourcivilians fire 1, one fire 2. human subjects MDP chosesend one ambulance fire 2 (number ambulances allocated f ire 2 = 5number ambulances allocated f ire 1). lone ambulance unable rescuecivilian fire 1, resulting humans MDP saving fewer civilians. RescueISI chosesend ambulances fire 2 using greedy selection method based proximitycivilians resulting civilians fire 1 dying7 . terms fire engine allocation,human3 sent four fire engines fire 1 civilians likely located(number engines allocated f ire 2 = 5 number engines allocated f ire 1).Unfortunately, backfired since lone fire engine fire 2 able extinguishfire there, causing fire spread parts city.DistributionSkewed 4-1Engines station 1Engines station 2Engines station 3AmbulancesRMTDP0113human12104human22104human31124RescueISI2100MDP2104Table 1: Allocations ambulances fire engines fire 1.experiments show allocations found RMTDP role allocation algorithm performs significantly better allocations chosen human subjects RescueISIMDP cases (and significantly worse case). particulardistribution civilians uniform, difficult humans comeallocation difference human allocations RMTDP allocationbecomes significant. conclude RMTDP allocation performsnear-human expertise.last experiment done using RoboCupRescue simulator, introduced errorRMTDP model order determine sensitive model errorsparameters model. Figure 18 compares allocations found, fiveambulances, 5 fire engines 5 civilians, terms number civilian casualties (Yaxis) error (X-axis) introduced probability fire spread probabilitycivilian health deterioration. seen increasing error probability firespread 20% higher results allocations save fewer civilians fire brigadeschoose concentrate effort one fires. resulting allocationfound value terms number civilians casualties usedRescueISI, consider uncertainty. Reducing error probabilityfire impact allocations found. Increasing error probability7. strategy ambulances going closest civilian worked fairly well ambulancesusually well spread405fiNair & Tambecivilian health deterioration 15% higher caused civilians sacrificed.allocation found value terms number civilians casualtiesused RescueISI. Decreasing error probability civilian health deterioration-5% lower (more negative) caused number ambulances allocated firenumber civilians fire (same human1).3Civilian casualties2.52fire-ratecivilian-health1.510.50-25 -20 -15 -10 -50510152025Percentage errorFigure 18: Model sensitivity RoboCupRescue scenario.7. Related Workfour related areas research, wish highlight. First,considerable amount work done field multiagent teamwork (Section 7.1).second related area research use decision theoretic models, particulardistributed POMDPs (Section 7.2). third area related work describe (Section 7.3)hybrid systems used Markov Decision Process BDI approaches. Finally,Section 7.4, related work role allocation reallocation multiagent teamsdescribed.7.1 BDI-based TeamworkSeveral formal teamwork theories Joint Intentions (Cohen & Levesque, 1991),SharedPlans (Grosz & Kraus, 1996) proposed tried capture essencemultiagent teamwork logic Beliefs-Desires-Intentions. Next, practical modelsteamwork COLLAGEN (Rich & Sidner, 1997), GRATE* (Jennings, 1995),STEAM (Tambe, 1997) built teamwork theories (Cohen & Levesque, 1991; Grosz& Kraus, 1996) attempted capture aspects teamwork reusableacross domains. addition, complement practical teamwork models, teamoriented programming approach (Pynadath & Tambe, 2003; Tidhar, 1993a, 1993b)introduced allow large number agents programmed teams. approachexpanded applied variety domains (Pynadath & Tambe, 2003; Yenet al., 2001; da Silva & Demazeau, 2002). approaches building practical multia406fiHybrid BDI-POMDP Framework Multiagent Teaminggent systems (Stone & Veloso, 1999; Decker & Lesser, 1993), explicitly basedteam-oriented programming, could considered family.research reported article complements research teamwork introducing hybrid BDI-POMDP models exploit synergy BDI POMDPapproaches. particular, TOP teamwork models traditionally addresseduncertainty cost. hybrid model provides capability, illustratedbenefits reasoning via detailed experiments.article uses team-oriented programming (Tambe et al., 2000; da Silva &Demazeau, 2002; Tidhar, 1993a, 1993b) example BDI approach, relevantsimilar techniques modeling tasking collectives agents, DeckerLessers (1993) TAEMS approach. particular, TAEMS language provides abstraction tasking collaborative groups agents similar TOP, GPGP infrastructure used executing TAEMS-based tasks analogous TOP interpreterinfrastructure shown Figure 1. Lesser et al. explored use distributedMDPs analyses GPGP coordination (Xuan & Lesser, 2002), exploiteduse TAEMS structures decomposition abstraction searching optimal policiesdistributed MDPs, suggested article. Thus, article complements Lesseret al.s work illustrating significant avenue efficiency improvementsanalyses.7.2 Distributed POMDP ModelsDistributed POMDP models represent collection formal models expressiveenough capture uncertainty domain costs rewards associatedstates actions. Given group agents, problem deriving separate policies maximize joint reward modeled using distributed POMDPmodels. particular, DEC-POMDP (Decentralized POMDP) (Bernstein et al., 2000)MTDP (Multiagent Team Decision Problem) (Pynadath & Tambe, 2002) generalizations POMDPs case multiple, distributed agents, basingactions separate observations. frameworks allow us formulateconstitutes optimal policy multiagent team principle derive policy.However, exceptions, effective algorithms deriving policies distributedPOMDPs developed. Significant progress achieved efficientsingle-agent POMDP policy generation algorithms (Monahan, 1982; Cassandra, Littman,& Zhang, 1997; Kaelbling et al., 1998). However, unlikely research directlycarried distributed case. Finding optimal policies distributed POMDPsNEXP-complete (Bernstein et al., 2000). contrast, finding optimal policy singleagent POMDP PSPACE-complete (Papadimitriou & Tsitsiklis, 1987). Bernstein etal. note (Bernstein et al., 2000), suggests fundamental difference natureproblems. distributed problem cannot treated one separate POMDPsindividual policies generated individual agents possible cross-agentinteractions reward, transition observation functions. (For one action oneagent, may many different rewards possible, based actions agentsmay take.)407fiNair & TambeThree approaches used solve distributed POMDPs. One approachtypically taken make simplifying assumptions domain. instance,Guestrin et al. (2002), assumed agent completely observe world state.addition, assumed reward function (and transition function) teamexpressed sum (product) reward (transition) functions agentsteam. Becker et al. (2003) assume domain factored agentcompletely observable local state also domain transition-independent(one agent cannot affect another agents local state).second approach taken simplify nature policies consideredagents. example, Chades et al. (2002) restrict agent policies memoryless(reactive) policies, thereby simplifying problem solving multiple MDPs. Peshkin etal. (2000) take different approach using gradient descent search find local optimumfinite-controllers bounded memory. Nair et al. (2003a) present algorithm findinglocally optimal policy space unrestricted finite-horizon policies. thirdapproach, taken Hansen et al. (2004), involves trying determine globally optimalsolution without making simplifying assumptions domain. approach,attempt prune space possible complete policies eliminating dominatedpolicies. Although brave frontal assault problem, method expectedface significant difficulties scaling due fundamental complexity obtainingglobally optimal solution.key difference work research focused hybrid systemsleverage advantages BDI team plans, used practical systems,distributed POMDPs quantitatively reason uncertainty cost. particular,use TOPs specify large-scale team plans complex domains use RMTDPsfinding best role allocation teams.7.3 Hybrid BDI-POMDP ApproachesPOMDP models used context analysis single agent (Schut,Wooldridge, & Parsons, 2001) multiagent (Pynadath & Tambe, 2002; Xuan et al., 2001)behavior. Schut et al. compare various strategies intention reconsideration (decidingdeliberate intentions) modeling BDI system using POMDP.key differences work approach apply analysis singleagent case consider issues exploiting BDI system structure improvingPOMDP efficiency.Xuan Lesser (2001) Pynadath Tambe (2002), analyze multiagentcommunication. Xuan Lesser dealt finding evaluating various communication policies, Pynadath Tambe used COM-MTDP model deal problem comparing various communication strategies empirically analytically.approach general explain approach analyzing coordination actions including communication. concretely demonstrate approach analysis roleallocation. Additional key differences earlier work Pynadath Tambe (2002)follows: (i) RMTDP, illustrate techniques exploit team plan decompositionspeeding policy search, absent COM-MTDP, (ii) also introduce techniquesbelief-based evaluation absent previous work. Nonetheless, combining RMTDP408fiHybrid BDI-POMDP Framework Multiagent TeamingCOM-MTDP interesting avenue research preliminary stepsdirection presented Nair, Tambe Marsella (2003b).Among hybrid systems focused analysis, Scerri et al. (2002) employ MarkovDecision Processes within team-oriented programs adjustable autonomy. key difference work MDPs used execute particularsub-plan within TOPs plan hierarchy making improvements TOP.DTGolog (Boutilier, Reiter, Soutchanski, & Thrun, 2000) provides first-order languagelimits MDP policy search via logical constraints actions. Although shareswork key idea synergistic interactions MDPs Golog, differswork focuses single agent MDPs fully observable domains,exploit plan structure improving MDP performance. ISAAC (Nair, Tambe, Marsella,& Raines, 2004), system analyzing multiagent teams, also employs decision theoreticmethods analyzing multiagent teams. work, probabilistic finite automaton(PFA) represents probability distribution key patterns teams behaviorlearned logs teams behaviors. key difference workanalysis performed without access actual team plans agentsexecuting hence advice provided cannot directly applied improving team,need human developer change team behavior per advice generated.7.4 Role Allocation Reallocationseveral different approaches problem role allocation reallocation.example, Tidhar et al. (1996) Tambe et al. (2000) performed role allocation basedmatching capabilities, Hunsberger Grosz (2000) proposed use combinatorial auctions decide roles assigned. Modi et al. (2003) showedrole allocation modeled distributed constraint optimization problemapplied problem tracking multiple moving targets using distributed sensors.Shehory Kraus (1998) suggested use coalition formation algorithms decidingquickly agent took role. Fatima Wooldridge (2001) use auctionsdecide task allocation. important note competing techniquesfree problem model problem, even though modeltransition probabilities. approaches reforming team reconfiguration methods due Dunin-Keplicz Verbrugge (2001), self-adapting organizations HorlingLesser (2001) dynamic re-organizing groups (Barber & Martin, 2001). Scerri etal. (2003) present role (re)allocation algorithm allows autonomy role reallocationshift human supervisor agents.key difference prior work use stochastic models (RMTDPs)evaluate allocations: enables us compute benefits role allocation, takingaccount uncertainty costs reallocation upon failure. example, missionrehearsal domain, uncertainties considered, one scout wouldallocated, leading costly future reallocations even mission failure. Instead,lookahead, depending probability failure, multiple scouts sent oneroutes, resulting fewer future reallocations higher expected reward.409fiNair & Tambe8. ConclusionBDI approach agent teamwork provided successful applications, toolstechniques provide quantitative analyses team coordination team behaviors uncertainty lacking. emerging field distributed POMDPs providesdecision theoretic method quantitatively obtaining optimal policy teamagents, faces serious intractability challenge. Therefore, article leveragesbenefits BDI POMDP approaches analyze improve key coordinationdecisions within BDI-based team plans using POMDP-based methods. order demonstrate analysis methods, concentrated role allocation fundamental aspectagent teamwork provided three key contributions. First, introduced RMTDP,distributed POMDP based framework, analysis role allocation. Second, articlepresented RMTDP-based methodology optimizing key coordination decisions withinBDI team plan given domain. Concretely, article described methodologyfinding best role allocation fixed team plan. Given combinatorially manyrole allocations, introduced methods exploit task decompositions among sub-teamssignificantly prune search space role allocations.Third, hybrid BDI-POMDP approach uncovered several synergistic interactionsBDI team plans distributed POMDPs:1. TOPs useful constructing RMTDP model domain, identifyingfeatures need modeled well decomposing model constructionaccording structure TOP. RMTDP model could usedevaluate TOP.2. TOPs restricted policy search providing RMTDPs incomplete policieslimited number open decisions.3. BDI approach helped coming novel efficient belief-based representation policies suited hybrid BDI-POMDP approach correspondingalgorithm evaluating policies. resulted faster evaluation alsocompact policy representation.4. structure TOP exploited decompose problem evaluatingabstract policies, resulting significant pruning search optimal roleallocations.constructed RMTDPs two domains RoboCupRescue mission rehearsalsimulation determined best role allocation domains. Furthermore,illustrated significant speedups RMTDP policy search due techniques introducedarticle. Detailed experiments revealed advantages approach state-ofthe-art role allocation approaches failed reason uncertainty.key agenda future work continue scale-up RMTDPs even largerscale agent teams. scale-up require efficiency improvements. proposecontinue exploit interaction BDI POMDP approaches achievingscale-up. instance, besides disaster rescue, distributed sensor nets large areamonitoring applications could benefit scale-up.410fiHybrid BDI-POMDP Framework Multiagent TeamingAcknowledgmentsresearch supported NSF grant #0208580. would like thank Jim Blythe,Anthony Cassandra, Hyuckchul Jung, Spiros Kapetanakis, Sven Koenig, Michael Littman,Stacy Marsella, David Pynadath Paul Scerri discussions related article.would also like thank reviewers article whose comments helpedsignificantly improving article.Appendix A. TOP detailssection, describe TOP helicopter scenario. detailssubplan Figure 4(b) shown below:ExecuteMission:Context:Pre-conditions: (MB <TaskForce> location(TaskForce) = START)Achieved: (MB <TaskForce> (Achieved(DoScouting) Achieved(DoTransport)))(time > (MB <TaskForce> Achieved(RemainingScouts)( helo ScoutingTeam, alive(helo) location(helo) 6= END)))Unachievable: (MB <TaskForce> Unachievable(DoScouting))(MB <TaskForce> (Unachievable(DoTransport)(Achieved(RemainingScouts)( helo ScoutingTeam, alive(helo) location(helo) 6= END))))Irrelevant:Body:DoScoutingDoTransportRemainingScoutsConstraints:DoScouting DoTransportDoScouting RemainingScoutsDoScouting:Context:ExecuteMission <TaskForce>Pre-conditions:Achieved:Unachievable:Irrelevant:Body:WaitAtBaseScoutRoutesConstraints:WaitAtBase ScoutRoutesWaitAtBase:Context: DoScouting <TaskForce>Pre-conditions:Achieved:Unachievable: (MB <TransportTeam> helo TransportTeam, alive(helo))411fiNair & TambeIrrelevant:Body:no-opScoutRoutes:Context: DoScouting <TaskForce>Achieved:Unachievable:Irrelevant:(MB <ScoutingTeam> helo TransportTeam, alive(helo))Body:ScoutRoute1ScoutRoute2ScoutRoute3Constraints:ScoutRoute1 ScoutRoute2 ScoutRoute3ScoutRoute1:Context: ScoutRoutes <ScoutingTeam>Pre-conditions:Achieved: (MB <SctTeamA> helo SctTeamA, location(helo) = END)Unachievable: time > (MB <SctTeamA> helo SctTeamA, alive(helo))Irrelevant:Body:(location(SctTeamA) = START) route(SctTeamA) 1(location(SctTeamA) 6= END) move-forwardScoutRoute2:Context: ScoutRoutes <ScoutingTeam>Pre-conditions:Achieved: (MB <SctTeamB> helo SctTeamB, location(helo) = END)Unachievable: time > (MB <SctTeamB> helo SctTeamB, alive(helo))Irrelevant:Body:(location(SctTeamB) = START) route(SctTeamB) 2(location(SctTeamB) 6= END) move-forwardScoutRoute2:Context: ScoutRoutes <ScoutingTeam>Pre-conditions:Achieved: (MB <SctTeamA> helo SctTeamA, location(helo) = END)Unachievable: time > (MB <SctTeamA> helo SctTeamA, alive(helo))Irrelevant:Body:(location(SctTeamA) = START) route(SctTeamA) 1(location(SctTeamA) 6= END) move-forwardDoTransport:Context: ExecuteMission <TaskForce>Pre-conditions:412fiHybrid BDI-POMDP Framework Multiagent TeamingAchieved: (MB <TransportTeam> location(TransportTeam) = END)Unachievable: time > (MB <TransportTeam> helo TransportTeam, alive(helo))Irrelevant:Body:(location(TransportTeam) = start)(MB <TransportTeam> Achieved(ScoutRoute1))route(TransportTeam) 1elseif (MB <TransportTeam> Achieved(ScoutRoute2))route(TransportTeam) 2elseif (MB <TransportTeam> Achieved(ScoutRoute3))route(TransportTeam) 3(route(TransportTeam) 6= null) (location(TransportTeam) 6= END)move-forwardRemainingScouts:Context: ExecuteMission <TaskForce>Pre-conditions:Achieved: (MB <ScoutingTeam> location(ScoutingTeam) = END)Unachievable: time > (MB <ScoutingTeam> ( helo ScoutingTeamalive(helo) location(helo) 6= END))Irrelevant:Body:(location(ScoutingTeam) 6= END) move-forwardpredicate Achieved(tplan) true Achieved conditions tplan true. Similarly, predicates Unachievable(tplan) Irrelevant(tplan) true Unachievable conditions Irrelevant conditions tplan true, respectively. predicate(location(team) = END) true members team END.Figure 4(b) also shows coordination relationships: relationship indicatedsolid arc, relationship indicated dotted arc. coordination relationships indicate unachievability, achievability irrelevance conditionsenforced TOP infrastructure. relationship team sub-plansmeans team sub-plans fail, parent team plan fail. Also,parent team plan achieved, child sub-plans must achieved. Thus,DoScouting, WaitAtBase ScoutRoutes must done:Achieved: (MB <TaskForce> Achieved(WaitAtBase) Achieved(ScoutRoutes))Unachievable: (MB <TaskForce> Unachievable(WaitAtBase)Unachievable(ScoutRoutes))relationship means subplans must fail parent fail successsubplans means parent plan succeeded. Thus, ScoutingRoutes,least one ScoutRoute1, ScoutRoute2 ScoutRoute3 need performed:(MB <ScoutingTeam> Achieved(ScoutRoute1)Achieved(ScoutRoute2) Achieved(ScoutRoute3))Unachievable: (MB <TaskForce> Unachievable(ScoutRoute1)Unachievable(ScoutRoute2) Unachievable(ScoutRoute3))Achieved:413fiNair & TambeAlso relationship affects irrelevance conditions subplans joins.parent unachievable subplans still executing become irrelevant.Thus, WaitAtBase:Irrelevant:(MB <TaskForce> Unachievable(ScoutRoutes))Similarly ScoutingRoutes:Irrelevant:(MB <TaskForce> Unachievable(ScoutRoutes)).Finally, assign roles plans Figure 4(b) shows assignment brackets adjacent plans. instance, Task Force team assigned jointly perform ExecuteMission.Appendix B. RMTDP detailssection, present details RMTDP constructed TOP Figure 4.S: get features state attributes tested preconditionsachieved, unachievable irrelevant conditions body team plansindividual agent plans. Thus relevant state variables are:locationhelicopter, role helicopter,route helicopter, status helicopter(alive not) time. team n helicopters, state given tuple< time, role1 , . . . , rolen , loc1 , . . . , locn , route1 , . . . , routen , status1 , . . . , statusn >.A: consider actions primitive actions agent performwithin individual plans. TOP infrastructure enforces mutual beliefcommunication actions. Since analyzing cost focusresearch consider communication implicit model effectcommunication directly observation function.consider 2 kinds actions role-taking role-execution actions. assumeinitial allocation specify roles agents. specifies whetheragent scout transport scout scout team assigned to.scout cannot become transport change team initial allocationtransport change role taking one role-taking actions.The role-takingrole-execution actions agent given by:i,memberT ransportT eam = {joinSctT eamA, joinSctT eamB, joinSctT eamC}i,memberSctT eamA = i,memberSctT eamB = i,memberSctT eamCx =i,memberT ransportT eam = {chooseRoute, moveF orward}i,memberSctT eamA = i,memberSctT eamB = i,memberSctT eamC = {moveF orward}P : obtain transition function help human expertsimulations simulator available. domain, helicopters crash (be shotdown) START, END already scouted location. probabilityscouts get shot depends route on, i.e. probabilitycrash route1 p1 , probability crash route2 p2 probability crashroute3 p3 many scouts spot. assume414fiHybrid BDI-POMDP Framework Multiagent Teamingprobability transport shot unscouted location 1scouted location 0. probability multiple crashes obtainedmultiplying probabilities individual crashes.action, moveForward, effect routei = null loci = ENDstatusi = dead. cases, location agent gets incremented.assume role-taking actions scoutRoutex always succeed roleperforming agent transport assigned route already.: transport START observe status agentsprobability depending positions. helicopter particular routeobserve helicopters route completely cannot observe helicoptersroutes.O: observation function gives probability group agents receiveparticular joint observation. domain assume observations one agentindependent observations agents, given current stateprevious joint action. Thus probability joint observation computedmultiplying probabilities individual agents observations.probability transport START observing status alive scoutroute 1 0.95. probability transport START observing nothingalive scout 0.05 since dont false negatives. Similarly scoutroute 1 crashes, probability visible transport START 0.98probability transport doesnt see failure 0.02. Similarlyprobabilities observing alive scout route 2 route 3 0.94 0.93respectively probabilities observing crash route 2 route 30.97 0.96 respectively.R: reward function obtained help human expert helpsassign value various states cost performing various actions.analysis, assume actions moveForward chooseRoute cost.consider negative reward (cost) replacement action, scoutRoutex,R , negative reward failure helicopter RF , rewardscout reaching END Rscout reward transport reaching ENDRtransport . E.g. R = 10, RF = 50, Rscout = 5, Rtransport = 75.RL: roles individual agents take TOP organization hierarchy.RL = {transport, scoutOnRoute1, scoutOnRoute2, scoutOnRoute3}.Appendix C. TheoremsTheorem 3 MAXEXP method always yield upper bound.Proof sketch:Let policy leaf-level policy highest expected reward particular parent node, i, restricted policy space.V = maxChildren(i) V415(3)fiNair & TambeSince reward function specified separately component, separate expected reward V rewards constituent components givenstarting states starting observation histories components. Letteam plan divided components components parallelindependent sequentially executed.XVmaxstates[j],oHistories[j]Vj1jmexpected value obtained component j, 1 j cannot greaterhighest value obtained j using policy.maxstates[j],oHistories[j]Vj maxChildren(i) maxstates[j],oHistories[j](Vj )(4)Hence,VXmaxChildren(i) maxstates[j],oHistories[j](Vj )1jmV MaxEstimate(i)(5)ReferencesBarber, S., & Martin, C. (2001). Dynamic reorganization decision-making groups.Proceedings Fifth International Conference Autonomous Agents (Agents-01),pp. 513520.Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2003). Transition-independentdecentralized Markov decision processes. Proceedings Second InternationalJoint Conference Autonomous Agents Multi Agent Systems (AAMAS-03), pp.4148.Bernstein, D. S., Zilberstein, S., & Immerman, N. (2000). complexity decentralized control MDPs. Proceedings Sixteenth Conference UncertaintyArtificial Intelligence(UAI-00), pp. 3237.Boutilier, C. (1996). Planning, learning & coordination multiagent decision processes.Proceedings Sixth Conference Theoretical Aspects Rationality Knowledge (TARK-96), pp. 195210.Boutilier, C., Reiter, R., Soutchanski, M., & Thrun, S. (2000). Decision-theoretic, highlevel agent programming situation calculus. Proceedings SeventeenthNational Conference Artificial Intelligence (AAAI-00), pp. 355362.Cassandra, A., Littman, M., & Zhang, N. (1997). Incremental pruning: simple, fast,exact method partially observable Markov decision processes. ProceedingsThirteenth Annual Conference Uncertainty Artificial Intelligence (UAI-97),pp. 5461.416fiHybrid BDI-POMDP Framework Multiagent TeamingChades, I., Scherrer, B., & Charpillet, F. (2002). heuristic approach solvingdecentralized-pomdp: Assessment pursuit problem. Proceedings 2002ACM Symposium Applied Computing (SAC-02), pp. 5762.Cohen, P. R., & Levesque, H. J. (1991). Teamwork. Nous, 25 (4), 487512.da Silva, J. L. T., & Demazeau, Y. (2002). Vowels co-ordination model. ProceedingsFirst International Joint Conference Autonomous Agents MultiagentSystems (AAMAS-2002), pp. 11291136.Dean, T., & Lin, S. H. (1995). Decomposition techniques planning stochastic domains. Proceedings Fourteenth International Joint Conference ArtificialIntelligence (IJCAI-95), pp. 11211129.Decker, K., & Lesser, V. (1993). Quantitative modeling complex computational taskenvironments. Proceedings Eleventh National Conference Artificial Intelligence (AAAI-93), pp. 217224.Dix, J., Muoz-Avila, H., Nau, D. S., & Zhang, L. (2003). Impacting shop: Puttingai planner multi-agent environment. Annals Mathematics ArtificialIntelligence, 37 (4), 381407.Dunin-Keplicz, B., & Verbrugge, R. (2001). reconfiguration algorithm distributedproblem solving. Engineering Simulation, 18, 227246.Erol, K., Hendler, J., & Nau, D. S. (1994). HTN planning: Complexity expressivity.Proceedings Twelfth National Conference Artificial Intelligence (AAAI-94),pp. 11231128.Fatima, S. S., & Wooldridge, M. (2001). Adaptive task resource allocation multiagent systems. Proceedings Fifth International Conference AutonomousAgents (Agents-01), pp. 537544.Georgeff, M. P., & Lansky, A. L. (1986). Procedural knowledge. Proceedings IEEEspecial issue knowledge representation, 74, 13831398.Goldman, C. V., & Zilberstein, S. (2003). Optimizing information exchange cooperativemulti-agent systems. Proceedings Second International Joint ConferenceAutonomous Agents Multi Agent Systems (AAMAS-03), pp. 137144.Grosz, B., Hunsberger, L., & Kraus, S. (1999). Planning acting together. AI Magazine,20 (4), 2334.Grosz, B., & Kraus, S. (1996). Collaborative plans complex group action. ArtificialIntelligence, 86 (2), 269357.Guestrin, C., Venkataraman, S., & Koller, D. (2002). Context specific multiagent coordination planning factored MDPs. Proceedings Eighteenth NationalConference Artificial Intelligence (AAAI-02), pp. 253259.Hansen, E., & Zhou, R. (2003). Synthesis hierarchical finite-state controllers pomdps.Proceedings Thirteenth International Conference Automated PlanningScheduling (ICAPS-03), pp. 113122.417fiNair & TambeHansen, E. A., Bernstein, D. S., & Zilberstein, S. (2004). Dynamic programming partiallyobservable stochastic games. Proceedings Nineteenth National ConferenceArtificial Intelligence (AAAI-04), pp. 709715.Ho, Y.-C. (1980). Team decision theory information structures. ProceedingsIEEE, 68 (6), 644654.Horling, B., Benyo, B., & Lesser, V. (2001). Using self-diagnosis adapt organizationalstructures. Proceedings Fifth International Conference AutonomousAgents (Agents-01), pp. 529536.Hunsberger, L., & Grosz, B. (2000). combinatorial auction collaborative planning.Proceedings Fourth International Conference Multiagent Systems (ICMAS2000), pp. 151158.Jennings, N. (1995). Controlling cooperative problem solving industrial multi-agentsystems using joint intentions. Artificial Intelligence, 75 (2), 195240.Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partiallyobservable stochastic domains. Artificial Intelligence, 101 (2), 99134.Kitano, H., Tadokoro, S., Noda, I., Matsubara, H., Takahashi, T., Shinjoh, A., & Shimada,S. (1999). RoboCup-Rescue: Search rescue large scale disasters domainmultiagent research. Proceedings IEEE Conference Systems, Men,Cybernetics (SMC-99), pp. 739743.Levesque, H. J., Cohen, P. R., & Nunes, J. (1990). acting together. ProceedingsNational Conference Artificial Intelligence, pp. 9499. Menlo Park, Calif.: AAAIpress.Mailler, R. T., & Lesser, V. (2004). Solving distributed constraint optimization problems using cooperative mediation. Proceedings Third International Joint ConferenceAgents Multiagent Systems (AAMAS-04), pp. 438445.Marschak, J., & Radner, R. (1972). Economic Theory Teams. Cowles FoundationYale University Press, New Haven, CT.Modi, P. J., Shen, W.-M., Tambe, M., & Yokoo, M. (2003). asynchronous completemethod distributed constraint optimization. Proceedings Second International Joint Conference Agents Multiagent Systems (AAMAS-03), pp.161168.Monahan, G. (1982). survey partially observable Markov decision processes: Theory,models algorithms. Management Science, 101 (1), 116.Nair, R., Ito, T., Tambe, M., & Marsella, S. (2002). Task allocation rescue simulationdomain. RoboCup 2001: Robot Soccer World Cup V, Vol. 2377 Lecture NotesComputer Science, pp. 751754. Springer-Verlag, Heidelberg, Germany.Nair, R., Pynadath, D., Yokoo, M., Tambe, M., & Marsella, S. (2003a). Taming decentralizedPOMDPs: Towards efficient policy computation multiagent settings. ProceedingsEighteenth International Joint Conference Artificial Intelligence (IJCAI-03),pp. 705711.418fiHybrid BDI-POMDP Framework Multiagent TeamingNair, R., Tambe, M., & Marsella, S. (2003b). Team formation reformation multiagent domains like RoboCupRescue. Kaminka, G., Lima, P., & Roja, R. (Eds.),Proceedings RoboCup-2002 International Symposium, pp. 150161. Lecture NotesComputer Science, Springer Verlag.Nair, R., Tambe, M., Marsella, S., & Raines, T. (2004). Automated assistants analyzeteam behavior. Journal Autonomous Agents Multi-Agent Systems, 8 (1), 69111.Papadimitriou, C., & Tsitsiklis, J. (1987). Complexity Markov decision processes. Mathematics Operations Research, 12 (3), 441450.Peshkin, L., Meuleau, N., Kim, K.-E., & Kaelbling, L. (2000). Learning cooperate viapolicy search. Proceedings Sixteenth Conference Uncertainty ArtificialIntelligence (UAI-00), pp. 489496.Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. ProceedingsAdvances Neural Information Processing Systems 16 (NIPS).Pynadath, D. V., & Tambe, M. (2002). communicative multiagent team decisionproblem: Analyzing teamwork theories models. Journal Artificial IntelligenceResearch, 16, 389423.Pynadath, D. V., & Tambe, M. (2003). Automated teamwork among heterogeneous software agents humans. Journal Autonomous Agents Multi-Agent Systems(JAAMAS), 7, 71100.Rich, C., & Sidner, C. (1997). COLLAGEN: agents collaborate people.Proceedings First International Conference Autonomous Agents (Agents97), pp. 284291.Scerri, P., Johnson, L., Pynadath, D., Rosenbloom, P., Si, M., Schurr, N., & Tambe, M.(2003). prototype infrastructure distributed robot, agent, person teams.Proceedings Second International Joint Conference Agents MultiagentSystems (AAMAS-03), pp. 433440.Scerri, P., Pynadath, D. V., & Tambe, M. (2002). Towards adjustable autonomyreal-world. Journal Artificial Intelligence (JAIR), 17, 171228.Schut, M. C., Wooldridge, M., & Parsons, S. (2001). Reasoning intentions uncertain domains. Proceedings Sixth European Conference SymbolicQuantitative Approaches Reasoning Uncertainty (ECSQARU-2001), pp. 8495.Shehory, O., & Kraus, S. (1998). Methods task allocation via agent coalition formation.Artificial Intelligence, 101 (1-2), 165200.Sondik, E. J. (1971). optimal control partially observable Markov processes. Ph.D.Thesis, Stanford.Stone, P., & Veloso, M. (1999). Task decomposition, dynamic role assignment, lowbandwidth communication real-time strategic teamwork. Artificial Intelligence,110 (2), 241273.419fiNair & TambeTambe, M. (1997). Towards flexible teamwork. Journal Artificial Intelligence Research,7, 83124.Tambe, M., Pynadath, D., & Chauvat, N. (2000). Building dynamic agent organizationscyberspace. IEEE Internet Computing, 4 (2), 6573.Tidhar, G. (1993a). Team-oriented programming: Preliminary report. Tech. rep. 41, Australian Artificial Intelligence Institute.Tidhar, G. (1993b). Team-oriented programming: Social structures. Tech. rep. 47, Australian Artificial Intelligence Institute.Tidhar, G., Rao, A., & Sonenberg, E. (1996). Guided team selection. ProceedingsSecond International Conference Multi-agent Systems (ICMAS-96), pp. 369376.Wooldridge, M. (2002). Introduction Multiagent Systems. John Wiley & Sons.Xuan, P., & Lesser, V. (2002). Multi-agent policies: centralized ones decentralized ones. Proceedings First International Joint Conference AgentsMultiagent Systems (AAMAS-02), pp. 10981105.Xuan, P., Lesser, V., & Zilberstein, S. (2001). Communication decisions multiagentcooperation. Proceedings Fifth International Conference AutonomousAgents (Agents-01), pp. 616623.Yen, J., Yin, J., Ioerger, T. R., Miller, M. S., Xu, D., & Volz, R. A. (2001). Cast: Collaborative agents simulating teamwork. Proceedings Seventeenth InternationalJoint Conference Artificial Intelligence (IJCAI-01), pp. 11351144.Yoshikawa, T. (1978). Decomposition dynamic team decision problems. IEEE Transactions Automatic Control, AC-23 (4), 627632.420fiJournal Artificial Intelligence Research 23 (2005) 79-122Submitted 2/04; published 2/05Reinforcement Learning Agents Many SensorsActuators Acting Categorizable EnvironmentsJosep Portaporta@science.uva.nlIAS Group, Informatics InstituteUniversity AmsterdamKruislaan 403, 1098SJ, Amsterdam, NetherlandsEnric Celayacelaya@iri.upc.eduInstitut de Robotica Informatica IndustrialSpanish Council Scientific Research (CSIC)Llorens Artigas 4-6, 08028, Barcelona, SpainAbstractpaper, confront problem applying reinforcement learning agentsperceive environment many sensors perform parallel actions usingmany actuators case complex autonomous robots. argue reinforcementlearning successfully applied case strong assumptions madecharacteristics environment learning performed,relevant sensor readings motor commands readily identified. introductionassumptions leads strongly-biased learning systems eventually losegenerality traditional reinforcement-learning algorithms.line, observe that, realistic situations, reward received robotdepends reduced subset executed actions reduced subsetsensor inputs (possibly different situation action) relevantpredict reward. formalize property called categorizability assumptionpresent algorithm takes advantage categorizability environment,allowing decrease learning time respect existing reinforcement-learningalgorithms. Results application algorithm couple simulated realisticrobotic problems (landmark-based navigation six-legged robot gait generation)reported validate approach compare existing flat generalizationbased reinforcement-learning approaches.1. Introductiondivision knowledge-based behavior-based artificial intelligencefundamental achieving successful applications within field autonomous robots (Arkin,1998). However, now, division repercussions reinforcement learning. Within artificial intelligence, reinforcement learning formalizedgeneral way borrowing ideas dynamic programming decision-theory fields.Within formalization, objective reinforcement-learning methods establishcorrect mapping set abstract observations (formalized states) sethigh level actions, without worried sets states actionsdefined (for introduction reinforcement learning check Kaelbling, Littman,& Moore, 1996; Sutton & Barto, 1998, among many others). Algorithms developed withingeneral framework used different fields without modification.c2005AI Access Foundation. rights reserved.fiPorta & Celayaparticular application, definition sets states actions responsibilityprogrammer supposed part reinforcement-learning problem.However, clearly pointed Brooks (1991), autonomous robots major hurdlesrelated perception action representations. reason, robotictask, traditional reinforcement-learning research assumes major problem(connecting states actions) simpler assumes given (the definitionstates actions). consequence existing reinforcement-learning methodsbest suited problems fall symbolic artificial intelligence domainbelong robotics. Due generality existing reinforcement-learningalgorithms, robotic problem analyzed re-formulated tackledavailable reinforcement-learning tools but, many cases, re-formulationawkward introducing unnecessary complexity learning process. alternativeexplore paper new reinforcement-learning algorithm appliedrobotic problems are, without re-formulation.Brooks (1991) remarked, dealing real environment necessarily problemsince real environments properties exploited reduce complexityrobots controller. Brooks works, find simple robot controllers achievegood performance particular environments. clearly contrast generalitypursued within reinforcement learning. Following idea parallel Brooks,paper, present new reinforcement-learning algorithm takes advantage specificenvironment-related property (that call categorizability) efficiently learn achievegiven task. formalize categorizability property present representationsystem (partial rules) exploit property. remarkable feature representationsystem allows generalization spaces sensors actions, usinguniform mechanism. ability generalize state action spacesfundamental successfully apply reinforcement learning autonomous robots.paper organized follows. First, Section 2, formalize reinforcement learning point view use field autonomous robotics describeproblems make flat (and, cases, also generalization-based) reinforcementlearning algorithms adequate case. Section 3 presents categorizability assumption plausible robotics environments. Then, Section 4, describealternative reinforcement-learning algorithm exploits categorizability assumption circumvent problems present existing approaches. Section 5, analyzepoints contact proposal already existing work. Next, Section 6,present experiments validate approach. experiments performedsimulations mimic realistic robotic applications categorizability assumptionlikely valid. Finally, Section 7, conclude analyzing strengthsweaknesses proposed learning system.Additionally, Appendix provides detailed description partial-rule learningalgorithm introduced paper, Appendix B devoted enhancementalgorithm make execution efficient, Appendix C summarizes notationuse throughout paper.80fiReinforcement Learning Categorizable Environments2. Problem Formalizationsimplicity, assume robot perceives environment set binaryfeature detectors1 F = {fdi | = 1..nf }. feature detector devised processidentifies specific combinations present (and possibly past) sensor readings.use feature detectors common robotics. field, feature detectorsdefined programmer attending special characteristics environment,robot sensors, task executed order extract potentially useful information(presence landmarks obstacles, . . . ) raw sensor readings.similar way, instead working directly space actions providedrobot motors (that define low-level way controlling robot), commonpractice define set elementary actions EA = {eai |i = 1..ne }. elementary actionspecific sequence/combination motor commands defined programmer attendingcharacteristics robot task achieved. simplify, assumeelementary actions form (mi k) (i [1..nm ]) mi motor kvalue range valid inputs motor mi . framework quite flexible sincemotor mi either one physical motors robot high-level, abstractmotor combines movements actual motors. formalization, givenmoment, robot execute parallel many elementary actions available motors.robot controller seen procedure executes (combinations elementary)actions response specific situations (i.e., activation specific feature detectors)objective achieving given task. Reinforcement-learning approaches automaticallydefine controller using information provided reward signal. contextreinforcement learning, controller called policy learner.objective value-function-based reinforcement-learning algorithms (thecommon reinforcement-learning algorithms) predict reward directlyindirectly obtained execution action (i.e., combination elementaryactions) possible situation, described combination active inactive featuredetectors. prediction available, action executed situationone maximum reward expected.predict reward, classic reinforcement-learning algorithms rely Markovassumption, requires state signal carry enough information determine effectsactions given situation.2 Additionally, non-generalizing reinforcement-learningalgorithms assume states system must learned independently. So,information gathered effects action given state s, denoted Q(s, a),cannot safely transferred similar states actions. assumption, costreinforcement-learning algorithm general problem(ns na ),ns number states na number actions.action tried least state. Since state defined observed1. Non-binary feature detectors providing discrete range values readily binarized.2. Non-Markovian problems, confronted, converted Markovian ones.scope paper, although one relevant points achieve successfulreal-world reinforcement-learning application.81fiPorta & Celayacombination feature detectors, potential number statesns = 2 nf ,nf number feature detectors. Consequently,(ns na ) = (2nf na ),exponential number feature detectors. Since number feature detectors used robotic applications tends high, non-generalizing reinforcement learningbecomes impractical realistic problems. well known curse dimensionalityintroduced Bellman (1957), whose research presaged work reinforcementlearning.Although size action set (na ) important size state set (ns )curse dimensionality, less attention paid actions reinforcement-learningliterature. However, robot many degrees freedom execute many elementaryactions simultaneously makes cost learning algorithms also increaseexponentially number motors robot (nm ).Suppose address task two different sets feature detectors F 1F D2 F D1 F D2 . Using plain reinforcement-learning algorithm, costfinding proper policy would larger using larger set features (F 2 ).even one features F D2 F D1 stronger correlation rewardfeatures F D1 . Non-generalizing reinforcement-learning algorithmsable take advantage situation, and, even better input information,performance decreases. similar argument made actions additionfeature detectors.Generalizing reinforcement-learning algorithms using gradient-descenttechniques (Widrow & Hoff, 1960), coarse codings (Hinton, McClelland, & Rumelhart,1986), radial-basis functions (Poggio & Girosi, 1990), tile coding (Sutton, 1996) decisiontrees (Chapman & Kaelbling, 1991; McCallum, 1995) partially palliate problemsince deal large state spaces. However, approach complex realisticproblems, number dimensions state-space grows point making usegeneralization techniques impractical function approximationtechniques must used (Sutton & Barto, 1998, page 209).Adding relevant inputs actions task make task easier leastdifficult. methods whose complexity depends relevance available inputs actions number would scale well real domain problems.Examples systems fulfilling property are, instance, Kanerva coding system presented Kanerva (1988) random representation method Sutton Whitehead(1993). systems rely large collections fixed prototypes (i.e., combinationsfeature detectors) selected random, proposal search appropriate prototypes, using strong bias search performed reasonable time.strong bias based categorizability assumption plausible assumptioncase autonomous robots, allows large speed learning process.Additionally, existing systems address problem determining relevanceactions, since assume learning agent single actuator (that is, obviously,82fiReinforcement Learning Categorizable Environmentsrelevant one). simple set adequate robotics. approach (presented below), combinations feature detectors elementary actions consideredusing unified framework.3. Categorizability Assumptionexperience developing controllers autonomous robots, observe that, manyrealistic situations, reward received robot depends reduced subsetactions executed robot sensor inputs irrelevantpredict reward. Thus, example, value resulting action graspingobject front robot depend object is: object robotbring user, electrified cable, unimportant object. However, resultprobably whether robot moving cameras graspingobject, day night, robot is, time, checking distancenearest wall, see red light nearby (aspects, them, maybecome important circumstances).agent observes acts environment reduced fraction available inputs actuators considered time, say agentcategorizable environment.Categorizability binary predicate graded property. completelycategorizable case, would necessary pay attention one sensor/motorsituation. extreme spectrum, motors carefullycoordinated achieve task effect action could predictedtaking account value feature detectors, would say environmentcategorizable all.Since robots large collection sensors providing heterogeneous collectioninputs many actuators affecting quite different degrees freedom, hypothesisthat, robotic problems, environments highly categorizable and, cases,algorithm biased categorizability assumption would result advantageous.4. Reinforcement Learning Categorizable Environments: PartialRule Approachimplement algorithm able exploit potential categorizability environment,need representation system able transfer information similar situationsalso similar actions.Clustering techniques successive subdivisions state space (as, instance,presented McCallum, 1995) focus perception side problem aimdetermining reward expected given state consideringfeature detectors perceived state. subset relevant feature detectorsused compute expected reward state possible action (the Q(s, a)function). However, way posing problem curse dimensionality problemcompletely avoided since features relevant one actionanother produces unnecessary (from point view action)differentiation equivalent situations, decreasing learning speed. problem83fiPorta & Celayaavoided finding specific set relevant feature detectors action.case, Q function computed Q(fs (a), a), state definition functionaction consideration. technique used, instance, MahadevanConnell (1992). Unfortunately, problem confronting, enough since,case, actions composed combinations elementary actions also wanttransfer reward information similar combinations actions. Therefore,estimate Q(fs (a), a) taking account elementary actions composea. However, principle, relevance elementary actions function situation (or,equivalently, state): given elementary action relevant situationsothers. reason, function approximate becomes Q(f (a), fa (s))cross-dependency state defined function action, f (a),action defined function state, fa (s). proposal detail next solvescross-dependency working Cartesian product spaces feature detectorselementary actions combinations.formalize proposal, introduce definitions.say agent perceives (or observes) partial view order k, v(fd i1 , . . . , fdik ),k nf whenever predicate fdi1 ... fdik holds.3 Obviously, many partial viewsperceived time.given moment, agent executes action issues different commandone agents motors = {ea1 , . . . , eanm }, nm number motors.partial command order k, noted c(eai1 , . . . , eaik ), k nm , executed wheneverelementary actions {eai1 , . . . , eaik } executed simultaneously. say partialcommand c action accordance c subset a. Note executiongiven action supposes execution partial commands accordanceit.partial rule w defined pair w = (v, c), v partial view cpartial command. say partial rule w = (v, c) active v observed, wused whenever partial view v perceived partial command c executed.partial rule covers sub-area Cartesian product feature detectors elementaryactions and, thus, defines situation-action rule used partially determineactions robot many situations (all partial view ruleactive). order partial rule defined sum order partial vieworder partial command compose rule.associate quantiy qw partial rule. qw estimation value (i.e.,discounted cumulative reward) obtained executing c v observedtime t:Xqw =t+i rt+i ,i=0rt+i reward received learner time step + rule w used timet. So, partial rule interpreted as: partial view v observed executionpartial command c results value qw .3. partial view also include negations feature detectors since non-detection featurerelevant detection.84fiReinforcement Learning Categorizable Environmentsobjective learning process deriving set partial rules adjustingcorresponding qw values desired task properly achieved.apparent drawback partial-rule representation number possiblepartial rules much larger number state action pairs: numberpartial rules defined set nf binary feature detectors nm binarymotors 3nf +nm , number different states action pairs 2nf +nm .arbitrary problems confronted (as case synthetic learning situations),partial-rule approach could useful. However, problems confronted robotsarbitrary since, mentioned, environments present regularities properties (ascategorizability) exploited reduce complexity controller necessaryachieve given task.Using partial-rule framework, categorizability assumption formally definedas:Definition 1 say environment/task highly categorizable exists setlow-order partial rules allows us predict reward accuracystatistics possible state-action combination considered. lower orderrules controller higher categorizability environment/task.extent categorizability assumption fulfilled, number partial rulesnecessary control robot becomes much smaller number state-action pairsdefined using sets feature detectors elementary actionspartial views partial commands based. Additionally, categorizability impliesrules necessary controller mostly lower ordereasily exploited bias search space partial rules. So, environmentcategorizable, use partial-rule approach suppose important increaselearning speed reduction use memory respect traditionalnon-generalizing reinforcement-learning algorithms.following sections, describe possible estimate effectaction given fixed set partial rules. evaluation, repeated actions, useddetermine best action executed given moment. Next, detailpossible adjust value predictions fixed set partial rules. Finally, describecategorizability assumption allows us use incremental strategy generationnew partial rules. strategy results faster learning existing generalizingnon-generalizing reinforcement-learning algorithms. procedures described highlevel form make explanation clear. Details implementation foundAppendix A.4.1 Value Prediction using Partial Rulesgiven situation, many partial views simultaneously active triggering subsetpartial rules controller C. call subset active partial rules denoteC 0 . evaluate given action take account rules C 0partial command accordance a. denote subset C 0 (a). Note that,approach, refer action, mean corresponding set elementary actions(one per motor) single element, general case reinforcement learning.85fiPorta & CelayaEvery rule w = (v, c) C 0 (a) provides value prediction a: qw associatedpartial rule. averaged value provides information accuracyprediction. also pointed Wilson (1995), favor use partialrules high accuracy value prediction or, say it, rules high relevance.seems clear relevance rule (w ) depends distribution valuesaround qw . Distributions low dispersion indicative coherent value predictionsand, so, highly relevant rule. measure dispersion maintain error estimationew approximation qw . Another factor (not used Wilson, 1995) takenaccount relevance determination confidence qw ew statistics: lowconfidence (i.e., insufficiently sampled) measures qw ew reduce relevancerule. confidence value prediction given rule (cw ) numberinterval [0, 1], initialized 0, increasing partial rule used (i.e., ruleactive partial command executed). confidence would decreasevalue model given partial rule consistently wrong.Using confidence, approximate real error value prediction partialrule ww = ew cw + e (1 cw ),value e average error value prediction. Observe importancee reduced confidence increases and, consequently, w converges ew .definitions, relevance partial rule definedw =1.1 + wNote exact formula relevance important far w1 w2w1 w2 . formula provides value range [0, 1] could directlyused scale factor, necessary.problem then, derive single value prediction using qw statisticsrules C 0 (a) corresponding relevance value, w ? Two possible solutionscome mind: using weighted sum values predicted partial rules usingrelevance weighting factor, using competitive approach,relevant partial rule used determine predicted value. weighted sum assumeslinear relation inputs (the value prediction provided individual rule)output (the value prediction a). assumption proved powerful manysystems but, general, compatible categorizability assumption since,although one partial rules involved sum low order, takingaccount means using large set different feature detectors elementaryactions predict effect given action. reason, learning system useswinner-take-all solution value prediction relevant partial ruletaken account predict value action. So, action determinewinner rulew =winner (C 0 , a) =argmax {w0 },w0 C 0 (a)use range likely value rule, Iw = [qw 2w , qw + 2w ], randomlydetermine value prediction action a. probability distribution inside intervaldepends distribution assume value.86fiReinforcement Learning Categorizable Environmentsprocedure outlined used time step obtain value predictionaction. action maximal value one want robot executenext.Observe obtain probabilistic value prediction: situationstatistics, get different value predictions action. way,action obtains maximal evaluation always one maximal q wand, consequently, favor exploration promising actions. probabilistic action selection provides exploratory mechanism uses information typicalreinforcement-learning exploration mechanisms (the error confidence value predictions available reinforcement-learning algorithms) resultsophisticated exploration schema (see Wilson, 1996, survey different explorationmechanisms reinforcement learning).4.2 Partial Rules Value Adjustmentadjust value predictions rules C 0 (a) last executed action.rule adjusted, update qw , ew , cw statistics.effect action accordance partial command c attendingpartial rule w = (v, c) defined (using Bellman-like equation)qw= rw +Xp(w, C 0 ) v (C 0 ),C 0r w average reward obtained immediately executing c v observed,discount factor used balance importance immediate respect delayedreward, v (C 0 ) represents goodness (or value) situation rules C 0 active,p(w, C 0 ) probability reaching situation execution c vobserved. value situation assessed using best action executablesituationv (C 0 ) = max{qw|w = winner(C 0 , a0 )},0since gives us information well robot perform (at most)situation.many existing reinforcement-learning approaches, values q w ewrules adjusted modified using temporal difference ruleerror measure. Rules direct relationprogressively approach qwreceived reward would provide value prediction (qw ) coherent actuallyobtained one and, consequently, statistics adjustment, prediction errordecreased. Contrariwise, rules related observed reward would predict valuedifferent obtained one error statistics increased. way,rule really important generation received reward, relevance increaseddecreased. Rules low relevance chances used driverobot and, extreme cases, could removed controller.confidence cw also adjusted. adjustment depends confidence measured. related number samples used qw ewstatistics, cw simply slightly incremented every time statistics rule w87fiPorta & Celayaupdated. However, also decrease confidence value model given partialrule consistently wrong (i.e., value observed systematically interval w ).Observe learning rule equivalent used state-based reinforcementlearning methods. instance, Q-learning (Watkins & Dayan, 1992), Q (s, a),state action, definedXp(s, a, s0 ) V (s0 ),Q (s, a) = r w +s0p(s, a, s0 ) probability transition s0 executedV (s0 ) = max{Q (s0 , a0 )}0approach, set rules active given situation C 0 plays role stateinsteadand, thus, v (C 0 ) V (s0 ) equivalent. hand, estimate qwQ (s, a), rule w includes information (partial) state actionsQ (s, a) play similar role. value prediction given rule, q ,making qwwcorresponds average value predictions cells Cartesian productfeature detectors elementary actions covered rule. case completerules (i.e., rules involving feature detectors actions motors), sub-areacovered rule includes one cell Cartesian product and, therefore,controller includes complete rules, described learning rule exactlyused Q-learning. particular case, C 0 (a) one rule that, consequently,winner rule. statistics rule (and updatedway) Q(s, a) entry table used Q-learning. Thus, learning rulegeneralization learning rule normally used reinforcement learning.4.3 Controller Initialization Partial Rule Creation/EliminationSince assume working categorizable environment, use incrementalstrategy learn adequate set partial rules: initialize controller ruleslowest order generate new partial rules necessary (i.e., casescorrectly categorized using available set rules). So, initial controller contain,instance, rules order two include one feature detector one elementaryaction ((v(fdi ), c(aej )), (v(fdi ), c(aej )) i, j). case, sensible includeempty rule (the rule order 0, w ) initial controller. rule always activeprovides average value average error value prediction. Additionally,knowledge user task achieved easily introduced initialcontroller form partial rules. available, estimation value predictionsuser-defined rules also included. hand-crafted rules (and valuepredictions) correct learning process accelerated. correct,learning algorithm would take care correcting them.create new rule large error value prediction detected. newrule defined combination two rules C 0 (a), rules forecasteffects last executed action, a, current situation. selecting couplerules combined, favor selection value prediction close88fiReinforcement Learning Categorizable Environmentsactually observed one, since likely involve features elementary actions(partially) relevant value prediction try refine.problem possible determine priori whether incorrectlypredicted value would correctly predicted rule adjustments reallynecessary create new partial rule account received reward. So, create newrules large error value prediction, possible create unnecessaryrules. existence (almost) redundant rules necessarily negative, sinceprovide robustness controller, called degeneracy effect introduced Edelman(1989). must avoided generate rule twice, since usefulall. Two rules identical respect lexicographic criteria (they containfeature detectors elementary actions) also respect semantic ones (theyget active situations propose equivalent actions). identical rulescreated, detected removed soon possible. Preservingrules proved useful avoids number rules controller growingreasonable limit.Since create new rules significant error value prediction,necessary, could end generating complete rules (provided limitnumber rules controller). case, assuming specificrule accurate value prediction, system would behave normal tablebased reinforcement-learning algorithm: specific rules (i.e., relevantones) would used evaluate actions and, explained before, statisticsrules would exactly table-based reinforcement-learning algorithms.Thus, limit, system deal type problems non-generalizingreinforcement-learning algorithms. However, regard limit situation improbable impose limits number rules controllers. Observeasymptotic convergence table-based reinforcement learning possibleuse winner-takes-all strategy action evaluation. weighted-sum strategy,value estimation non-complete rules possibly present controller wouldadded complete rules leading action evaluation differenttable-based reinforcement-learning algorithms.5. Partial Rule Approach Contextcategorizability assumption closely related complexity theory principlesMinimum Description Length (MDL) used authors Schmidhuber (2002) bias learning algorithms. complexity results try formalizewell-known Occams Razor principle enforces choosing simplest modelset otherwise equivalent models.Boutilier, Dean, Hanks (1999) presents good review representation methodsreduce computational complexity planning algorithms exploiting particularcharacteristics given environment. representation based partial rules seenanother representation systems. However, partial rule representationformalism that, without bias introduced categorizability assumption, wouldefficient enough applied realistic applications.89fiPorta & Celayapartial-rule formalism seen generalization XCS classifiersystems described Wilson (1995). XCS learning system aims determining setclassifiers (that combinations features associated action) associated value relevance predictions. main difference approachWilsons work pursues generic learner bias learning process usingcategorizability assumption. allows us use incremental rule-generation strategylikely efficient robotic problems. Additionally, categorizability assumption also modifies way value given action evaluated: Wilsonsapproach uses weighted sum predictions classifier advocating actiondetermine expected effect action, while, fulfill categorizability assumption (i.e., minimize number feature detectors elementary actions involvedgiven evaluation), propose use winner-takes-all strategy. critical pointsince winner-takes-all strategy takes full advantage categorizability assumptionallows partial-rule system asymptotically converge table-basedreinforcement-learning system. case weighted sum strategy used.Furthermore, XCS formalism generalization action space and,already commented, requirement robotic-like applications.general, reinforcement learning pay attention necessity generalizingspace actions, although exceptions exists. instance, work MaesBrooks (1990) includes possible execution elementary actions parallel. Howeversystem include mechanism detecting interactions actions and,thus, coordination actions relies sensory conditions. instance, systemdifficulties detecting execution two actions results always (i.e., independentlyactive/inactive feature detectors) positive/negative reward.CASCADE algorithm Kaelbling (1993) learns bit complex actionseparately. algorithm presents clear sequential structure learninggiven action bit depends previously learned ones. approachpredefined order learning outputs result flexible learningschema.multiagent learning (Claus & Boutilier, 1998; Sen, 1994; Tan, 1997) objectivelearn optimal behavior group agents trying cooperatively solve giventask. Thus, field, case, multiple actions issued parallel considered. However, one main issues multiagent learning, coordinationdifferent learners irrelevant case since one learner.Finally, way define complex actions elementary actionspoints common works reinforcement learning macro-actions definedlearner confronts different tasks (Sutton, Precup, & Singh, 1999; Drummond, 2002).However, useful combinations elementary actions detected algorithmguaranteed relevant task hand (although likely also relevantrelated tasks).6. Experimentsshow results applying learning algorithm two robotics-like simulated problems: robot landmark-based navigation legged robot walking. first problem90fiReinforcement Learning Categorizable EnvironmentsFlowersBushesBoatTreeLakeGoalA7A6A5A4fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififiA1fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifiA2A3fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fifififififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififi fififififi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifi fifiRockBushesStartNorthBushFigure 1: Landscape simple landmark-based navigation task. landscape divided areas (the dashed ovals) subsets landmarks visible.simpler (although includes delayed reward) use clearly describeworkings algorithm. second problem approaches realistic robotic application,objective long term. use two examples compare performancelearning system generalizing non-generalizing reinforcement-learningalgorithms. confronted problems different enough show generalityproposed learning system.6.1 Simulated Landmark-Based Navigationconfront simple simulated landmark-based navigation task forest-like environment shown Figure 1. objective learner go start position(marked cross bottom figure) goal positionfood (marked cross top right corner environment). agentneither walk lake escape depicted terrain.agent make use binary landmark (i.e., feature) detectors identifyposition environment decide action execute next. example,landmark detectors agent are:1. Rock detector: Active rock seen.2. Boat detector: Active boat seen.3. Flower detector: Active bunch flowers seen.91fiPorta & Celaya4. Tree detector: Active tree seen.5. Bush detector: Active whenever bush seen.6. Water detector: Active water nearby.7. Bird detector: Active bird flying agent.8. Cow detector: Active cow nearby.9. Sun detector: Active sun shining.10. Cloud detector: Active cloudy.detectors, first 5 relevant task. water detector alwaysactive, rest landmark detectors become active random. 10 landmarkdetectors differentiate 210 = 1024 situations.simplify problem clustering possible positions learner environment 7 areas (shown Figure 1): area includes positionsset relevant landmarks seen.far actions concerned, use three actions West-East movementrobot: move West (denoted W ), stay place (), move East (E).three indicate movement along North-South dimension (move NorthN , stay latitude , move South S). two independent groupsthree actions combined giving rise 9 different actions (move North-West, North,North-East, etc.). assume agent executes one actions,stop nearest area terrain direction movement reached.agent tries move lake terrain, remainsposition was. Figure 1 shows possible transitions contiguous areasenvironment.described landmark detectors elementary actions maximum possible order given rule 12, define 944784 (310 42 ) syntactically differentpartial rules. taking account rules one feature detector one elementary action (that ones initially included controller) 90 differentpartial rules.agent receives reward (with value 100) reaches goal. Consequently,problem delayed reward since agent must transmit information provided reward signal actions situations directly relatedobservation reward.parameters partial-rule learning algorithm used task = 0.9,= 0.99, = 5, = 0.1, = 5, = 200 and, = 0.95 (see Appendix detaileddescription parameters). Observe that, maximum number partial rules= 200 initial controller containing 90 rules, little room left generationrules order higher 2.learning organized sequence trials. trial consists placinglearner starting position letting move goal reached, allowingexecution 150 actions reach goal. performing optimally, threeactions required reach objective starting position.92fiReinforcement Learning Categorizable Environments180160Steps Goal140120100806040200050100150200250TrialPR AlgorithmXCSFigure 2: Performance landmark-based navigation task. Results shown average 10 runs.Figure 2 shows that, 40 learning trials, agent approaches optimal behavior(represented flat dashed line = 3).dashed line Figure 2 performance XCS problem. performtest, used implementation Wilsons XCS developed Butz (1999).make XCS work search space partial-rule algorithm, modifiedXCS implementation able deal non-binary actions. modification,parameter adjustment, introduced original code. results presentedcorresponds average 10 runs using set parameters gave betterresult. Nominally, parameters were: learning rate = 0.1, decay rate = 0.9,maximum number classifiers = 200 (however, initial set empty), geneticalgorithm applied average every 5 time steps, deletion experience 5, subsumeexperience 15, fall rate 0.1, minimum error 0.01, prediction threshold0.5, crossover probability 0.8, mutation probability 0.04 initial dontcare probability 1/3. prediction fitness new classifiers initialized 10error 0. detailed explanation meaning parameters providedWilson (1995) also comments code Butz (1999).see XCS reaches performance partial-rule approach,using four times trials. difference performance partially explainedXCSs lack generalization action space. However factor relevantcase since action space two dimensions. main factor explainsbetter performance partial-rule approach bias introduced categorizability93fiPorta & Celaya1PositionA2V812A4903A6100Action(W, N )(W, )(, N )(E, N )(E, )(E, )Winner Rulew1 = (v(Rock, Boat), c(W, N ))w2 = (v(Rock, W ater), c(W ))w3 = (v(Boat, ree), c(N ))w4 = (v(T ree), c(E, N ))w5 = (v(Rock, Boat), c(E))w6 = (v(Bush), c(E, ))qw80.6379.7389.6190.086.71100.0ew1.162.192.040.04.580.0Guess79.8777.6588.8889.8679.5699.87Table 1: Partial execution trace landmark-based navigation task. Elementary action means movement along corresponding dimension. time stept, action highest guess executed. time step 3, goalreached.assumption present XCS system that, case, allowsefficient learning process. XCS powerful partial-rule approach senseXCS makes assumption categorizability environment,assume high. result XCS learning process includes identificationdegree categorizability environment case is, sense,pre-defined. generality XCS, however, produces slower learning process.initialize classifiers XCS high dont care probability initializerules partial-rule algorithm generalization used action space(i.e., rules include command motor), two systems become closer.case, main (but only) difference two approachesassumption relation inputs value: XCS assumes linearrelation, assume environment categorizable, or, same, assumevalue depend inputs. Due difference, confrontedproblem, two systems would learn policy valuesaction, values would computed using different rules different associatedvalues, independently parameter/rule initialization used case.system smaller learning time would assumption closerreality. results obtained particular example presented showcategorizability assumption valid hypothesis would caserobotics-like applications.Table 1 shows evaluation actions different situations agent encounters path start goal 50 learning trials. Analyzing trace,extract insight partial-rule learning algorithm works.instance, time step 1, see rule w2 = (v(Rock, W ater), c(W )) useddetermine value action (W, ). Since landmark detector Water always active,rule equivalent w = (v(Rock), c(W )), one rules used generate w 2 .examine statistics w find qw = 74.70 ew = 15.02. Obviously,value distributions qw qw2 look different (74.70 vs. 79.73 15.02 vs. 2.19).w2 generated later stages learning and, thus, statisticsupdated using subsample values used adjusts statistics w.94fiReinforcement Learning Categorizable Environmentsparticular case, qw updated 250 times qw2 updated 27times. learning continues, distributions become similar rule w 2eventually eliminated.Table 1, see sometimes non-optimal actions getevaluation close optimal ones. reason, agent executes, times,non-optimal actions increases number steps necessary reach goal.general, adjustment statistics rules solve problem but,particular case, need create new rules fix situation. instance, time step 2,value rule w4 increased towards 90, value rules active time stepproposing actions accordance action rule w4 also converge toward 90.So, long term, rule proposing action (N ) get value close 90.absence specific rules, rule used estimate value action(, N ) and, due probabilistic nature action selection procedure,action can, eventually, executed delaying agent reaching goal 1 timestep. However, execution (, N ) results error value prediction and, thus,creation new rules better characterize situation. soon specific ruleaction (, N ) generated, error longer repeated.time step 3, see rule w6 = (v(Bush), c(E, )) value 100 error0 guess rule 99.87. maximum confidence () lower1.0 (0.99 case) makes agent keep always certain degreeexploration.agent receives reward task totally achieved, function valuesituation computed V (s) = n1 r n distance (in actions)situation target one r reward finally obtained. Table 1, seesituations get correct evaluation: 80.63( 81 = 100 0.9 2 ) A2, 90(= 100 0.9)A4, 100 A6.Observe problem solved using 200 partial rules 9216possible situation-action combinations domain. So, say problemcertainly categorizable. main conclusion extract toy examplethat, particular case confronted problem categorizable, presentedalgorithm able determine relevant rules adjust values (includingeffect delayed reward) optimal action determinedsituation.6.2 Gait Generation Six-Legged Robotalso applied algorithm task learning generate appropriate gait (i.e.,sequence steps) six-legged robot (Figure 3). apply learning algorithmreal robot would possible, dangerous: initial phases learning robotwould fall many times damaging motors. reason used simulatorlearning and, afterward, applied learned policy real robot.problem learning walk six legged robot chosen many authorsparadigmatic robotic-learning problem. instance, Maes Brooks (1990)implemented specific method based immediate reward derive preconditionsleg perform step. Pendrith Ryan (1996) used simplified version95fiPorta & Celayasix-legged walking problem test algorithm able deal Non-Markovian spacesstates Kirchner (1998) presented hierarchical version Q-learning learnlow-level movements leg, well coordination scheme low-levellearned behaviors. Ilg, Muhlfriedel, Berns (1997) introduced learning architecturebased self-organizing neural networks, Kodjabachia Meyer (1998) proposedevolutionary strategy develop neural network control gait robot. VallejoRamos (2000) used parallel genetic algorithm architecture Parker (2000) describedevolutionary computation robot executes best controller foundgiven moment new optimal controller computed off-line simulation.algorithms usually tested flat terrain aim generating periodic gaits (i.e.,gaits sequence steps repeated cyclically). However, general locomotion(turns, irregular terrain, etc) problem free gait generation needs considered.Figure 3: Genghis II walking robot 2D simulation environment.simulator (see Figure 3) allows controller command leg robottwo independent degrees freedom (horizontal vertical) able detectrobot unstable position (in robot happens two neighboring legsair simultaneously). Using simulator, implemented behaviors describedCelaya Porta (1996) except charge gait generation. Therefore,task learned consists deciding every moment legs must step (that is, leaveground move advanced position), must descend stayground support propel body.defined set 12 feature detectors that, due experience legged robots,knew could useful different situations gait-generation task:air(x): Active leg x air.Advanced(x): Active leg x advanced neighboring leg clockwisecircuit around robot.Attending activation non-activation 12 feature detectors,differentiate 4096 different situations.action side, work two different elementary actions per leg: oneissues step leg another descends leg touches ground.96fiReinforcement Learning Categorizable EnvironmentsThus, cardinality set elementary actions 12 and, time step, robotissues action containing 6 elementary elements (one per leg). Thus, thinkleg virtual motor accepts two possible values, 0 remain contactground 1 perform step.reward signal includes two aspects:Stability: action causes robot fall down, reward 50 given.Efficiency: robot fall down, reward equal distanceadvanced robot given. Observe legs descend recover contactground advance robot obtained movement necessaryable get reward next time steps. So, problem delayedreward.efficient stable gait tripod gait two sets three non-adjacentlegs step alternately. Using gait, robot would obtain reward 0 (when one groupthree legs lifted advanced) followed reward 50 (when legs contactground move backward reaction advance legs moved previoustime step). Thus, optimal average reward 25.experiments, robot set initial posture legs contactground random advance position.Figure 4 shows results applying partial-rule algorithm compared obtained using standard Q-learning 4096 distinct states 64 different actions.partial-rule algorithm, used following set parameters: = 0.2, =0.99, = 22, = 0.1, = 150, = 10000 and, = 0.95 (see Appendix descriptionparameters). Q-learning, learning rate set = 0.5 useaction selection rule performs exploratory actions probability 0.1.Figure 4, see stability subproblem (i.e., falling down,corresponds getting reward greater zero) learned quickly. because,stability subproblem, take advantage generalization provided usingseparate elementary actions and, single rule, avoid executing several dangerousactions. However, advance subproblem (i.e., getting reward close 25) learnedslowly. little generalization possible learning system must generatespecific rules. words, sub-problem less categorizable stabilityone.landmark-based navigation example discussed previous section,observe controller contains (slightly) overly general rules responsiblenon optimal performance robot. However, dont regard problemsince interested efficiently learning correct enough policyfrequent situations finding optimal behaviors particular cases.Figure 5 shows performance Q-learning longer run using different exploration rates. shows Q-learning eventually converge optimal policymany iterations approach (about factor 10). Observe lowerexploration rate allows algorithm achieve higher performance (around 19learning rate 0.1 around 24 learning rate 0.01) using longer period.careful adjustment exploration rate combine initial faster learning97fiPorta & Celaya20Average Reward100-10-20-30-40-500100020003000Time SlicePR Algorithm40005000QLearningFigure 4: Performance partial-rule approach compared standard Q-learning.Results smoothed average 10 experiments.better convergence long term. Experiments Q-learning using learning rates0.5 showed insignificant differences compared results shown here.advantage algorithm non-generalizing ones increased problemssensors provide information related task. test point,set experiment 6 feature detectors become active randomlyadded 12 initial ones. new features, number possible combinationsfeature activations increases, number states considered Q-learning.Figure 6 shows comparison algorithm Q-learning problem.Q-learning able learn reasonable gait strategy 5000 time steps shownfigure, performance partial-rule algorithm almostbefore. means partial-rule algorithm able detect sets featuresrelevant use effectively determine robots behavior. remarkablethat, case, ratio memory used algorithm respect usednon-generalizing algorithms 0.2%. exemplifies performancenon-generalizing algorithms degrades number features increases,necessarily case using partial-rule approach.importance generation partial rules improvement categorization seen comparing results obtained problem withoutmechanism (Figure 7). results show task cannot learned usingpartial rules order 2. aspect gait-generation problem learnedrules order 2 avoid lifting leg one neighboring legs already98fiReinforcement Learning Categorizable Environments20Average Reward100-10-20-30-40-50050000Exploration 0.1100000150000Time Slice200000Exploration 0.01250000ReferencesFigure 5: Performance Q-learning algorithm different exploration rates.reference values 19 24 upper bound performance attainableusing exploration rate 0.1 0.01.20Average Reward100-10-20-30-40-500100020003000Time SlicePR Algorithm40005000QLearningFigure 6: Performance algorithm compared Q-learning irrelevantfeatures.99fiPorta & Celaya20Average Reward100-10-20-30-40-500100020003000Time SliceWithout Generation40005000GenerationFigure 7: Performance without partial-rule generation procedure.air. instance, rulev(In air(1)) c(Step(2)),forecasts highly relevant negative reward prevents leg 2 raisedleg 1 air.Rules order higher 2 (i.e., provided robot initial controller)necessary, instance, avoid raising two neighboring legs simultaneously. rule likev(In air(1)) c(Step(1), Step(2))becomes active robot evaluates action implies raising leg 1 leg 2time. Since value prediction rule negative relevancehigh, action evaluation would discarded, preventing robot fallingdown. Similar rules generated pair neighboring legs. makerobot advance, need generate rules even higher order.Figure 8, see performance algorithm start learningprocess correct rule set (i.e., rule set learned previous experiment),statistics initialized 0. experiment, compare complexitylearning values rules compared complexity learning rulesvalue time. see values rules needlearned learning process two times faster normal applicationalgorithm.final experiment, issue frequent changes heading direction robot(generated randomly every 10 time steps). way, periodic gaits become suboptimal100fiReinforcement Learning Categorizable Environments20Average Reward100-10-20-30-40-5005001000150020002500Time SlicePR correct rule set300035004000PR AlgorithmFigure 8: Performance partial-rule approach learning started correctrule set compared standard approach rules also learned.controller produce free gait, i.e., gait includes sequence stepswithout periodic repetition.case, focus advance subproblem and, thus, introduced handcrafted rules initial controller prevent robot falling down. rulesform:leg lifted execution action results value 50 confidence 1,actions lift one two legs contiguous i.set parameters used case was: = 0.2, = 0.99, = 5, = 0.1,= 150, = 10000 and, = 0.95.Figure 9 shows average results obtained using partial-rule learning algorithmcompared obtained best hand-coded gait-generation strategy. figure, horizontal dashed line shows average performance using best gait-generationstrategy implemented (Celaya & Porta, 1998). seen learned gaitgeneration strategy (the increasing continuous line) produces performance similarbest hand-coded strategy that, cases, even outperforms it. Figure 10shows situation learned controller produces better behavior handcoded one. Using hand-coded strategy, robot starts walk raising two legs (36) and, time steps reaches state tripod gait generated. Initially,leg 2 advanced legs 1 4 and, general, suboptimal execute stepleg neighboring legs less advances itself. particular casehowever, general rule hold. learned strategy detects exception101fiPorta & Celaya25Average Reward201510500100020003000Time SlicePR Algorithm40005000Hand CodedFigure 9: Performance partial-rule approach learning free gait.generates tripod gait beginning resulting larger advance robotinitial stages movement.7. Conclusionspaper, introduced categorizability assumption states robotdriven achieve given task using simple rules: i.e., rules including reducedset feature detectors elementary actions. assumption supportedexperience within behavior-based approach controllers formed sets rulesrelatively simple conditions actions. shown learning algorithmbased categorizability assumption allows large speed learning processmany realistic robotic applications respect existing algorithms.exploit categorizability assumption observations action spaces,introduced new representation formalism based concept partial rulesconcepts independent states independent actions kernelmany existing reinforcement-learning approaches.introduction partial-rule concept provides large flexibility problemsformalized. structure algorithms, confront problemsgeneralization perception side (usually considered reinforcement learning),action side (usually considered), them.generalization possible via partial rules, use complete rules:rules involving available inputs outputs. case, partial-rule approachequivalent non-generalizing reinforcement learning. algorithm presented102fiReinforcement Learning Categorizable EnvironmentsLeg Numbering1200Step 3,6Step 2,3,625323456Step 1,4,5Step 1,4,55982Step 2,3,6Step 2,3,6109132Figure 10: hand-programmed gait strategy (top sequence) vs. learned one (bottomsequence). advance position robot snapshot indicatedpicture.can, necessary, generate complete rules and, consequently, can, principle, solveproblem solved using traditional reinforcement-learning algorithm. However,take categorizability assumption valid so, generation complete rulesextreme case likely occur limit situation. Therefore,approach, forego generality order increase efficiently learning processclass problems want address.Another advantage partial-rule framework allows easy robustintroduction initial knowledge learning process form rules easily understood programmer. contrast usual reinforcement-learningalgorithms introduction initial knowledge is, general, rather difficult.partial-rule approach, subtle change emphasis main goallearning: work reinforcement learning emphasis learningvalue action state, main purpose learn relevance (subsets of)elementary actions feature detectors. relevant subsets elementary actionsfeature detectors identified, learning becomes straightforward.103fiPorta & Celayamain limitation work possible know priori (except trivial cases) whether environment categorizable given robot. Non-generalizingreinforcement learning implicitly assumes environment non-categorizablethat, consequently, possible combination features actions takenaccount separately. approach assumes opposite: environmentcategorizable and, so, reduced combinations features actions need takenaccount. drawback using non-generalizing approach robotic tasksbecome intractable curse dimensionality. generalization techniquesproblem partially alleviated, enough general. approach takeradical approach order much less affected curse dimensionality:introduce strong bias learning process drastically limit use combinationsfeatures actions.tested partial-rule learning algorithm many robotic-inspired problemstwo discussed paper (landmark based-navigation sixlegged robot gait generation) categorizability assumption proved validcases tested. algorithm out-performs generalizing non-generalizing reinforcementlearning algorithms memory requirements convergence time. Additionally,shown approach scales well number inputs increases,performance existing algorithms largely degraded. important resultlets us think could possible use approach control complex robots,use existing approaches discarded.work presented paper, extract two main proposals. First,apply reinforcement learning agents many sensors actuators,concentrate efforts determining relevance inputs outputs and, second,achieve efficient learning complex environments could necessary introduceadditional assumptions reinforcement-learning algorithms, even risk losinggenerality.Acknowledgmentsauthors would like express gratitude anonymous reviewers paper.contributions toward improving quality paper relevant enoughconsidered, sense, co-authors paper. shortcomings still paperattributed nominal authors.second author partially supported Spanish Ministerio de Ciencia Tecnologa FEDER funds, project DPI2003-05193-C02-01 PlanNacional de I+D+I.104fiReinforcement Learning Categorizable EnvironmentsAppendix A: Partial-Rule Learning Algorithmappendix, describe detail approach described main bodypaper.Partial Rule Learning Algorithm(Initialize)F Set features detectorsEA Set elementary actionsC {w } {(v(fd), c(ea)), (v(fd), c(ea))|fd F D, ea EA}w Cqw 0ew 0iw 0endfore0episodeC 0 {w C|w active}Repeat (for step episode):(Action Selection)Action Evaluation(Computes guess(a0 ) a0 )0arg max{guess(a )}0Execute(System Update)ra Reward generated0CantC00C {w C|w active}Statistics UpdatePartial-Rule Managementterminal situationenddoFigure 11: partial-rule learning algorithm. Text inside parentheses comments.Action Evaluation, Statistics Update, Partial-Rule Management proceduresdescribed next.partial-rule learning algorithm (whose top level form shown Figure 11) storesfollowing information partial rulevalue (i.e., discounted cumulative reward) estimation qw ,error estimation ew ,confidence index iw .105fiPorta & Celaya1.00.90.80.7cw0.60.50.40.30.20.112345iw678910Figure 12: Confidence function =7 =0.8.estimate confidence qw ew use confidence index iw that, roughlyspeaking, keeps track number times partial rule used. confidencederived iw using confidence function following way:cw =confidence function(iw ),confidence function non-decreasing function range [0, ].less 1 since, way, system always keeps certain degree exploration and,consequently, able adapt changes environment. Different confidence schemesimplemented changing confidence function. implementation, usesigmoid-like function (see Figure 12) increases slowly low values w reducingconfidence provided first obtained rewards. way avoid prematureincrease confidence (and, thus, decrease error exploration)insufficiently-sampled rules. parameter () determines point functionreaches top value .Additionally, confidence index used define learning rate (i.e., weightnew observed rewards statistics update). purpose implement MAMfunction (Venturini, 1994) rule:mw = max{, 1/(iw + 1)}.Using MAM-based updating rule, that, lower confidence, highereffect last observed rewards statistics, faster adaptationstatistics. adaptive learning rate strategy related presented Sutton (1991)Kaelbling (1993), contrasts traditional reinforcement-learning algorithmsconstant learning rate used.initialization phase, algorithm enters continuous loop taskepisode consisting estimating possible effects actions, executing promis106fiReinforcement Learning Categorizable EnvironmentsAction Evaluationaction a0w winner(C 0 , a0 )guess(a0 ) qw + 2 random(w , w )endforFigure 13: Action Evaluation procedure.ing one, updating system performance improves future. systemupdate includes statistics update partial-rule management.Action Evaluationsimplest procedure get estimated value actions brute-force approachconsisting independent evaluation one them. simple cases, approachwould enough but, number valid combinations elementary actions (i.e.,actions) large, separate evaluation action would take long time, increasingtime robot decision decreasing reactivity control. avoid this,Appendix B presents efficient procedure get value action.Figure 13 summarizes action-evaluation procedure using partial rules. valueaction guessed using relevant rule action (i.e., winner rule).winner rule computedwinner (C 0 , a) =argmax {w },wC 0 (a)w relevance rule ww =1.1 + wvalue estimation using winner rule selected random (uniformly)intervalIw = [qw 2w , qw + 2w ],w = ew cw + e (1 cw ).Here, e average error value prediction (i.e., value error predictionempty rule, w ).Statistics Updatestatistics-update procedure (Figure 14), qw ew adjusted rulesactive previous time step proposed partial command accordance(the last executed action).107fiPorta & CelayaStatistics Updateterminal situationv0elsev max{qw |w = winner(C 0 , a0 )}0endifq ra + v0w = (v, c) Cantc accordanceq Iwiw iw + 1elseiw min( 1, iw 1)endifqw qw (1 mw ) + q mwew ew (1 mw ) + |qw q| mwendifendfore ewFigure 14: Statistics update procedure.qw ew updated using learning rate (mw ) computed using MAMfunction, initially 1, consequently, initial values qw ewinfluence future values variables. initial values become relevantusing constant learning rate, many existing reinforcement-learning algorithms do.observed effects last executed action agree current estimatedinterval value (Iw ), confidence index increased one unit. Otherwise,confidence index decreased allowing faster adaptation statistics lastobtained, surprising values reward.Partial-Rule Managementprocedure (Figure 15) includes generation new partial rules removalpreviously generated ones proved useless.implementation, apply heuristic produces generation new partialrules value prediction error exceeds e. way, concentrate effortsimprove categorization situations larger errors value prediction.Every time wrong prediction made, new partial rules generated0 (a). Recall set includescombination pairs rules included set Cantrules active previous time step accordance executed action a. Thus,rules related situation-action whose value prediction needimprove.108fiReinforcement Learning Categorizable Environmentscombination two partial rules w1 w2 consists new partial rule partialview includes features included partial views either w1 w2partial command includes elementary actions partial commands eitherw1 w2 . words, feature set w1 w2 union feature sets w1w2 elementary actions w1 w2 union w10 (a), simultaneously activew2 . Note that, since w1 w2 Cantaccordance action and, thus, incompatible(i.e., include inconsistent features elementary actions).partial-rule creation, bias system favor combination rules(wi ) whose value prediction (qwi ) closer observed one (q). Finally, generationrules lexicographically equivalent already existing ones allowed.According categorizability assumption, low-order partial rules requiredachieve task hand. reason, improve efficiency, limit numberpartial rules maximum . However, partial-rule generation procedure alwaysgenerating new rules (concentrating situations larger error). Therefore,need create new rules room them, must eliminate less usefulpartial rules.partial rule removed value prediction similar rulesituations.similarity two rules measured using normalized degree intersection value distributions number times rules usedsimultaneously:similarity(w, w 0 ) =U (w w0 )kIw Iw0 k,max{kIw k, kIw0 k} min{U (w), U (w 0 )}U (w) indicates number times rule w actually used.similarity assessment pair partial rules controller expensiveand, general, determining similarity rule respectgenerated (that rules tried refine new rule created)sufficient. Thus, based similarity measure, define redundancypartial rule w = (w1 w2 ) as:redundancy(w) = max{similarity(w, w1 ), similarity(w, w2 )}.Observe w = (w1 w2 ), w w1 = w U (w) U (w1 ).ThereforeU (w w1 )U (w)U (w)=== 1.min{U (w), U (w1 )}min{U (w), U (w1 )}U (w)reasoning done w2 and, consequently,redundancy(w) = max{kIw Iw2 kkIw Iw1 k,}.max{kIw k, kIw1 k} max{kIw k, kIw2 k}need create new rules maximum number rules ()reached, partial rules redundancy given threshold () eliminated.Since redundancy partial rule estimated observing number109fiPorta & CelayaPartial Rule Management0w winner(Cant, a)|qw q| > e(If time create new rules)(Partial Rule Elimination)(Test room new rules)kCk >(Rule elimination based redundancy)C C {w C | redundancy(w) > }(Rule elimination based creation error)kCk > (If still room)SC partial rules C with:- Lowest creation error(w),- creation error(w) < |qw q|C C SCendifendif(Partial Rule Generation)t0kCk < <(Create new rule w 0 )0(a)Select two different rules w1 , w2 Cantpreferring minimize|qwi q| cwi + e (1 cwi )w0 = (w1 w2 )creation error(w 0 ) |qw q|(Insert new rule controller)C C {w 0 }tt+1endwhileendifFigure 15: Partial Rule Management procedure. value q calculated StatisticsUpdate procedure last executed action.times, redundancy partial rules low confidence indexes set 0,immediately removed creation.Observe that, compute redundancy rule w, use partial rulesw derived. reason, rule w 0 cannot removed controller Cexists rule w C w = w 0 w00 . Additionally, way eliminatefirst useless rules higher order.110fiReinforcement Learning Categorizable EnvironmentsAppendix B: Efficient Action Evaluationnon-generalizing reinforcement learning cost executing single learning stepneglected. However, algorithms generalization spaces sensors and/or actuatorssimple execution time iteration increased substantially.extreme case, increase limit reactivity learnerdangerous working autonomous robot.expensive procedure algorithm computing valueactions (i.e., valid combinations elementary actions). cost procedureespecially critical since used twice step: get guess action(in Action Evaluation procedure detailed Figure 13) get goodnessnew achieved situation action execution (when computing v valueStatistics Update procedure detailed Figure 14). trivial re-order algorithmavoid double use expensive procedure learning step: selectaction executed next time evaluate goodness newachieved situation. drawback re-order action selected withouttaking account information provided last reward value (the goodnesssituation assessed value adjustment). However, problem tasksrequire many learning steps.Even use action-evaluation procedure per learning step,optimize much possible since brute-force approach described before,evaluates action sequentially, feasible simple problems.action-evaluation method presented next based observation manyactions would value since highest relevant partial rule givenmoment would provide value actions accordance partialcommand rule. separate computation value two actions would endevaluated using rule waste time. avoided performingaction evaluation attending set active rules first place setpossible actions, brute-force approach does.Figure 16 shows general form algorithm propose. algorithm, partialrules considered one time, ordered relevant rule least relevantone. partial command rule consideration (cow ) used processactions accordance partial command. already processed sub-setactions need considered action-evaluation procedure.rules processed, update current situation assessment (v) actionexecuted next (a) attending, respectively, value prediction (qw ) guess (gw )rules.Observe partial rules maintained sorted relevance statistics updateprocedure, since procedure rule relevance modified. relevancerule changed, position list also modified accordingly. wayre-sort list rules every time want apply proceduredescribed.elementary actions form (m k) motor k valuerange possible values motor, algorithm implementedespecially efficient way since need explicitly compute set actions A.111fiPorta & CelayaAction Evaluation(Initialization)L List active rules sorted relevance.EA Set elementary actionsSet combinations EAv(Situation assessment)(Optimal action)g(Optimal action value prediction)(Process)w first element(L)cow partial command wgw qw + 2 random(w , w )Aw {a A|cow accordance a}qw > vv qwendifgw > gg gwcowendifAww next element(L)6=Figure 16: General form proposed situation-assessment action-selection procedure.case (see Figure 17 18), construct decision tree using motors decisionattributes groups leaf actions evaluated partialrule (all actions removed set iteration algorithm Figure 16).internal node tree classifies action according one motor commands included action. internal nodes store following information:Partial command: partial command accordance action classified node. partial command constructed collectingmotors whose values fixed nodes root tree nodeconsideration.Motor: motor used node classify actions. node open (i.e.,still decided motor attend) motor value set .node closed deciding motor pay attention (and addingcorresponding subtrees) converting node leaf.112fiReinforcement Learning Categorizable EnvironmentsAction Evaluation(Initialization)L List active rules sorted relevance.vgtree new node(c )open 1closed 0(Process)w first element(L)gw qw + 2 random(w , w )Include Rule(tree, w, gw )w next element(L)closed = openFigure 17: Top level algorithm efficient action evaluation algorithm. endalgorithm, v goodness current situation used StatisticsUpdate algorithm (see Figure 14), action executed next guessexpected value. Include Rule procedure detailed next figure.Subtrees: list subtrees start node. subtreeassociated value corresponds one possible actions executable motor node. actions included given subtree elementary action(m k) motor node k value correspondingsubtree.leaves tree information value actions classifiedleaf. information represented following set attributes leaf:Value: expected value actions classified leaf. maximumvalue leaves used assess goodness, v, new achieved situation.Guess: value altered noise exploratory reasons. leaf maximalguess set actions select action executed next.Relevance: relevance value predictions (of value guess).Partial command: partial command accordance actionsclassified leaf. case internal nodes, partial commandconstructed collecting motors whose values fixed roottree leaf consideration.113fiPorta & CelayaInclude rule(n, w, gw )not(is leaf(n))cow command(w)con command(n)motor(n) 6=(Closed Node: Search compatible sub-nodes)ea cow motor(ea) = motor(n)Include Rule(get subtree(value(ea), n), w, gw )elsesubtrees(n)Include Rule(s, w, gw )endforendifelse(Open Node: Specialize node)cow con 6=(Extend node)ea action in(cow con )set motor(n, motor(ea))closed closed + 1k values(motor(ea))new subtree(n, {k, new node(con (motor(ea) k))})open open + 1endforInclude Rule(n, w, gw )else(Transform node leaf )transform leaf(n, qw , gw , w , cow )closed closed + 1qw > vv qwendifgw > guessg gwcowendifendifendifendifFigure 18: Include rule algorithm searches nodes node n partial command compatible partial command rule w extends nodesinsert leave tree.given moment, inclusion new partial rule tree produces specialization open nodes compatible rule (see Figure 18). say opennode n compatible given rule w partial command node conpartial command rule cow assign different values motor.specialization open node result extension node (i.e., new branches114fiReinforcement Learning Categorizable EnvironmentsPartial rulesPartial ViewPartial CommandRU Ev(m1 v1 ) (m2 v1 )RU Ev(m1 v1 )RU Ev(m2 v1 ) (m3 v1 )RU Ev(m2 v1 )RU Ev(m1 v0 )RU Ev(m2 v0 )RU Ev(m3 v1 )RU Ev(m3 v0 )qe5783210160.10.92.03.13.53.64.04.50.830.520.330.240.220.210.200.18guess5.16.56.06.25.34.15.212.7Table 2: Set rules controller. values q e stored guesscomputed them. define partial views RU Ev indicateactive current time step.added tree node) transformation node leaf.node extended partial command rule affects motors includedpartial command node. means motor values takenaccount tree used action evaluation accordingrule consideration. node extended, one motors presentlayers tree used generate layer open nodes current node.that, node considered closed inclusion rule procedure repeatednode (with different effects node closed). motors affectedpartial command rule also affected partial command node,node transformed leaf storing value, guess, relevance attributesextracted information associated rule.process stopped soon detect nodes closed (i.e.external nodes tree leaves). case, rules still processedeffect tree form and, consequently useful action evaluation. ruleconsistently used action evaluation, removed controller.toy-size example illustrate tree-based action-evaluation algorithm. Supposerobot three motors accept two different values (named v 0v1 ). produces set 8 different actions. Suppose that, given moment, robotcontroller includes set rules shown Table 2. Action Evaluation algorithm(Figure 17), rules processed least relevant one expandinginitially empty tree using algorithm Figure 18. inclusion rule tree resultsextension tree (see stages B, E Figure 19) closing branchesconverting open nodes leaves (stages C F). particular case tree becomescompletely closed processing 5 rules 8 active rules controller.end process, tree five leaves. Three include two actionstwo represent single action. Using tree say valuesituation tree constructed, v, 8 (this given leaf circledsolid line figure). Additionally, next action executed form115fiPorta & CelayaMotor: m1Command:TRUE cBOpenNodev1v0Motor: m2Command:(m1,v1)v0OpenNodev1Value: 5Guess: 5.1Relevance: 0.83Command:(m1,v1)(m2,v1)OpenNodeCMotor: m2Command:(m1,v1)v0OpenNodeValue: 7Guess: 6.5Relevance: 0.52Command:(m1,v1)(m2,v0)EOpenNodev0v1v1OpenNodeValue: 5Guess: 5.1Relevance: 0.83Command:(m1,v1)(m2,v1)Motor: m3Command:(m1,v0)(m2,v1)v0v1v1Motor: m3Command:(m1,v0)(m2,v1)v0Value: 3Guess: 6.2Relevance: 0.24Command:(m1,v0)(m2,v1)(m3,v0)v1v1v0Value: 7Guess: 6.5Relevance: 0.52Command:(m1,v1)(m2,v0)Motor: m2Command:(m1,v1)v0Motor: m2Command:(m1,v0)v1v0Value: 5Guess: 5.1Relevance: 0.83Command:(m1,v1)(m2,v1)Value: 2Guess: 5.3Relevance: 0.22Command:(m1,v0)(m2,v0)Value: 8Guess: 6.0Relevance: 0.33Command:(m1,v0)(m2,v1)(m3,v1)Value: 5Guess: 5.1Relevance: 0.83Command:(m1,v1)(m2,v1)Motor: m1Command:TRUE cv1Motor: m2Command:(m1,v1)v0v1Value: 7Guess: 6.5Relevance: 0.52Command:(m1,v1)(m2,v0)Value: 8Guess: 6.0Relevance: 0.33Command:(m1,v0)(m2,v1)(m3,v1)OpenNodeFMotor: m2Command:(m1,v0)Motor: m2Command:(m1,v1)v0Motor: m2Command:(m1,v0)Motor: m1Command:TRUE cv0v1v0v1v0v0Motor: m1Command:TRUE cMotor: m1Command:TRUE cv1Motor: m3Command:(m1,v0)(m2,v1)v0Value: 3Guess: 6.2Relevance: 0.24Command:(m1,v0)(m2,v1)(m3,v0)v1Value: 7Guess: 6.5Relevance: 0.52Command:(m1,v1)(m2,v0)v1Value: 5Guess: 5.1Relevance: 0.83Command:(m1,v1)(m2,v1)Value: 8Guess: 6.0Relevance: 0.33Command:(m1,v0)(m2,v1)(m3,v1)Figure 19: Six different stages construction tree action evaluation.stage corresponds insertion one rule Table 2.116fiReinforcement Learning Categorizable Environments87log(Time)65432100123Number Void MotorsBrute Force Evaluation45TreeBased EvaluationFigure 20: Log execution time (in seconds) brute-force approach vs. treebased one.(m1 v1 , m2 v0 , m3 ]) ] represents possible action. optimal actiongiven leaf circled dashed line leaf larger guess value.cost algorithm largely depends specific set partial rulesprocessed. worst case, cost algorithm is:O(nr lnm ),nr number rules, nm number motors and, l maximal range valuesaccepted motors. because, worst case, insert given rule,visit nodes maximally expanded tree (i.e., tree node l subtreesfinal nodes branches still opened). number nodestreenmXlnm +1 1li == O(lnm ).l1i=0transform cost expression taking account l nm total numberpossible combinations elementary actions (nc ) or, words, total amountactions. Therefore, cost presented algorithmO(nr nc ).hand, cost brute-force approach always(nr nc ).117fiPorta & CelayaSo, worst case, cost presented algorithm order costbrute-force approach. However, since l rules would enough closemaximally expanded tree (one rule different values motor used laststill-open layer tree), cost tree-based algorithm would be, average,much smaller brute-force approach.Figure 20 exemplifies different performance brute-force action-evaluation procedure tree-based one. figure shows time taken executiontoy example Section 6.1. experiment, defined void motors motorswhose actions effect environment. seen, number voidmotors increases, cost tree-based evaluation significantly lessbrute-force approach.118fiReinforcement Learning Categorizable EnvironmentsAppendix C: NotationUppercase used sets, Greek letters represent parameters algorithms.Set states.0s,Individual states. Full views.nsNumber states.F = {fdi | = 1..nf }Set feature detectors.Partial view order k.v(fdi1 , . . . , fdik )Set actions robot.naNumber actions.EA = {eai | = 1..ne }Set elementary actions.nmNumber motors robot.eai = (mi k)Elementary action assigns value k motor mi .c(eai1 , . . . , eaik )Partial command order k.= (ea1 , . . . , eanm )Action. Combination elementary actions. Full command.w = (v, c)Partial rule composed partial view v partial command c.wempty partial rule.w1 w 2Composition two partial rules.C = {wi | = 1..nr }Controller set partial rules.Maximum number elements C.00C , CantSubset rules active given time step previous one.C 0 (a)Active rules partial command accordance a.qwExpected value partial rule w.ewExpected error value estimation partial rule w.eAverage error value prediction.iwConfidence index.cwConfidence statistics partial rule w.Top value confidence.Index confidence function reaches value .w = ew cw + e (1 cw ) Error return prediction partial rule w.w = 1/(1 + w )Relevance rule w.Iw = [qw 2w ]Value interval partial rule w.mwUpdating ratio statistics partial rule w.Learning rate. Top value mw .U (w)Number times rule w used.0winner(C , a)relevant active partial rule w.r.t. action a.guess(a)reliable value estimation action a.raReward received execution a.Discount factor.vGoodness given situation.q = ra + vValue executing action given situation.Number new partial rules created time.Redundancy threshold used partial-rule elimination.119fiPorta & CelayaReferencesArkin, R. C. (1998). Behavior-Based Robotics. Intelligent Robotics Autonomous Agents.MIT Press.Bellman, R. E. (1957). Dynamic Programming. Princeton University Press, Princeton.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 194.Brooks, R. A. (1991). Intelligence without representation. Artificial Intelligence, 47, 139159.Butz,M. (1999).C-XCS: implementation(http://www.cs.bath.ac.uk/ amb/LCSWEB/computer.htm).XCSC.Celaya, E., & Porta, J. M. (1996). Control six-legged robot walking abrupt terrain.Proceedings IEEE International Conference Robotics Automation,pp. 27312736.Celaya, E., & Porta, J. M. (1998). control structure locomotion leggedrobot difficult terrain. IEEE Robotics Automation Magazine, Special IssueWalking Robots, 5 (2), 4351.Chapman, D., & Kaelbling, L. P. (1991). Input generalization delayed reinforcementlearning: algorithm performance comparisons. Proceedings International Joint Conference Artificial Intelligence, pp. 726731.Claus, C., & Boutilier, C. (1998). dynamics reinforcement learning cooperativemultiagent systems. Proceedings Fifteenth National Conference ArtificialIntelligence, pp. 746752. American Association Artificial Intelligence.Drummond, C. (2002). Accelerating reinforcement learning composing solutions automatically identified subtasks. Journal Artificial Intelligence Research, 16, 59104.Edelman, G. M. (1989). Neuronal Darwinism. Oxford University Press.Hinton, G., McClelland, J., & Rumelhart, D. (1986). Parallel Distributed Processing: Explorations Microstructure Cognition. Volume 1: Foundations, chap. DistributedRepresentations. MIT Press, Cambridge, MA.Ilg, W., Muhlfriedel, T., & Berns, K. (1997). Hybrid learning architecture based neuralnetworks adaptive control walking machine. Proceedings 1997 IEEEInternational Conference Robotics Automation, pp. 26262631.Kaelbling, L. P. (1993). Learning Embedded Systems. Bradford Book. MIT Press,Cambridge MA.Kaelbling, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: survey.Journal Artificial Intelligence Research, 4, 237 285.Kanerva, P. (1988). Sparse Distributed Memory. MIT Press, Cambridge, MA.Kirchner, F. (1998). Q-learning complex behaviors six-legged walking machine.Robotics Autonomous Systems, 25, 253262.120fiReinforcement Learning Categorizable EnvironmentsKodjabachia, J., & Meyer, J. A. (1998). Evolution development modular controlarchitectures 1-d locomotion six-legged animats. Connection Science, 2, 211237.Maes, P., & Brooks, R. A. (1990). Learning coordinate behaviors. ProceedingsAAAI-90, pp. 796802.Mahadevan, S., & Connell, J. H. (1992). Automatic programming behavior-based robotsusing reinforcement learning. Artificial Intelligence, 55, 311363.McCallum, A. K. (1995). Reinforcement Learning Selective Perception HiddenState. Ph.D. thesis, Department Computer Science.Parker, G. B. (2000). Co-evolving model parameters anytime learning evolutionaryrobotics. Robotics Autonomous Systems, 33, 1330.Pendrith, M. D., & Ryan, M. R. K. (1996). C-trace: new algorithm reinforcementlearning robotic control. Proceedings 1996 International WorkshopLearning Autonomous Robots (Robotlearn96).Poggio, T., & Girosi, F. (1990). Regularization algorithms learning equivalentmultilayer networks. Science, pp. 978982.Schmidhuber, J. (2002). speed prior: new simplicity measure yielding near-optimalcomputable predictions. Proceedings 15th Annual Conference Computational Learning Theory (COLT 2OO2). Lecture Notes Artificial Intelligence.Springer., pp. 216228.Sen, S. (1994). Learning coordinate without sharing information. ProceedingsTwelfth National Conference Artificial Intelligence, pp. 426431. AmericanAssociation Artificial Intelligence.Sutton, R. S. (1991). Reinforcement learning architectures animats. Meyer, J. A., &Wilson, S. W. (Eds.), Proceedings First International Conference Simulation Adaptive Behavior. Animals Animats, pp. 288296. MIT Press,Bradford Books.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. BradfordBook. MIT Press.Sutton, R. S., & Whitehead, S. D. (1993). Online learning random representations.Proceedings Eleventh International Conference Machine Learning, pp.314321. Morgan Kaufman, San Francisco, CA.Sutton, R. (1996). Generalization reinforcement learning: Successful examples usingsparse coarse coding. Proceedings 1995 Conference Advances NeuralInformation Processing, pp. 10381044.Sutton, R., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: frameworktemporal abstraction reinforcement learning. Artificial Intelligence, 12, 181211.Tan, M. (1997). Multi-agent reinforcement learning: Independent vs. cooperative agents.Reading Agents, pp. 487494. Morgan Kaufmann Publishers Inc.121fiPorta & CelayaVallejo, E. E., & Ramos, F. (2000). distributed genetic programming architectureevolution robust insect locomotion controllers. Meyer, J. A., Berthoz, A.,Floreano, D., Roitblat, H. L., & Wilson, S. W. (Eds.), Supplement ProceedingsSixth International Conference Simulation Adaptive Behavior: AnimalsAnimats, pp. 235244. International Society Adaptive Behavior.Venturini, G. (1994). Apprentissage Adaptatif et Apprentissage Supervise par AlgorithmeGenetique. Ph.D. thesis.Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.Widrow, B., & Hoff, M. (1960). Adaptive switching circuits. Western Electronic ShowConvention, Volume 4, pp. 96104. Institute Radio Engineers (now IEEE).Wilson, S. W. (1995). Classifier fitness based accuracy. Evolutionary Computation, 3,149175.Wilson, S. W. (1996). Explore/exploit strategies autonomy. Animals Animats 4: Proceedings 4th International Conference Simulation AdaptiveBehavior, pp. 325332.122fiJournal Artificial Intelligence Research 23 (2005) 245-297Submitted 12/03; published 03/05Graduality ArgumentationClaudette CayrolMarie-Christine Lagasquie-Schiexccayrol@irit.frlagasq@irit.frIRIT-UPS, 118 route de Narbonne31062 Toulouse Cedex, FRANCEAbstractArgumentation based exchange valuation interacting arguments, followedselection acceptable (for example, order take decision,make choice). Starting framework proposed Dung 1995, purposeintroduce graduality selection best arguments, i.e. ablepartition set arguments two usual subsets selectednon-selected arguments order represent different levels selection. basic ideaargument acceptable preferred attackers. First,discuss general principles underlying gradual valuation arguments basedinteractions. Following principles, define several valuation models abstractargumentation system. Then, introduce graduality concept acceptabilityarguments. propose new acceptability classes refinement existing classestaking advantage available gradual valuation.1. Introductionshown Dung (1995), argumentation frameworks provide unifying powerfultool study several formal systems developed common-sense reasoning, wellgiving semantics logic programs. Argumentation based exchangevaluation interacting arguments support opinions assertions. applied,among others, legal domain, collective decision support systems negotiationsupport.fundamental characteristic argumentation system interaction arguments. particular, relation attack may exist arguments. example,argument takes form logical proof, arguments proposition argumentsproposition advanced. case, attack relation relies logicalinconsistency.argumentation process usually divided two steps: valuation relativestrength arguments, followed selection acceptable arguments.valuation step, usual distinguish two different types valuations:intrinsic valuation: here, value argument independent interactionsarguments. enables simply express extent argumentincreases confidence statement supports (see Pollock, 1992; Krause, Ambler, Elvang, & Fox, 1995; Parsons, 1997; Prakken & Sartor, 1997; Amgoud & Cayrol,1998; Kohlas, Haenni, & Berzati, 2000; Pollock, 2001).c2005AI Access Foundation. rights reserved.fiCayrol, Lagasquie-Schiexexample, work Krause et al. (1995), using following knowledge base,composed (formula, probability) pairs {(1 , 0.8), (2 , 0.8), (3 , 0.8), ((1 24 ), 1), ((1 3 4 ), 1)}, two arguments produced1 :A1 =< {1 , 2 , (1 2 4 )}, 4 >A2 =< {1 , 3 , (1 3 4 )}, 4 >.arguments weight 0.8 0.8 1 = 0.64, formula 4weight 0.64 + 0.64 0.512 = 0.7682 .interaction-based valuation: value argument depends attackers(the arguments attacking it), attackers attackers (the defenders), etc. 3Several approaches proposed along line (see Dung, 1995; Amgoud &Cayrol, 1998; Jakobovits & Vermeir, 1999; Besnard & Hunter, 2001) differsets values used. Usually, two values considered. However,proposals use two values (three values Jakobovits & Vermeir,1999, infinity values Besnard & Hunter, 2001).example, work Besnard Hunter (2001), set valuesinterval real line [0, 1]. case, set arguments4 {A1 , A2 , A3 }considering A1 attacks A2 attacks A3 , value argument A1(resp. A2 , A3 ) 1 (resp. 21 , 32 ).Intrinsic valuation interaction-based valuation often used separately, according considered applications. recent works however consider combinationapproaches (see Amgoud & Cayrol, 1998; Karacapilidis & Papadias, 2001; Pollock,2001).Considering selection acceptable arguments, usual distinguishtwo approaches:individual acceptability: here, acceptability argument dependsproperties. example, argument said acceptableattacker (in case, interaction arguments considered,see Elvang-Goransson et al., 1993). context intrinsic valuation, argument also said acceptable better attackers(see Amgoud & Cayrol, 1998).collective acceptability: case, acceptability set arguments explicitlydefined. example, acceptable, set arguments may contain two1. Here, arguments form Explanation-Conclusion Pair. one possible waycompute arguments (see also Lin & Shoham, 1989; Vreeswijk, 1997; Pollock, 1992; Prakken & Sartor,1997; Simari & Loui, 1992; Elvang-Goransson, Fox, & Krause, 1993; Kohlas et al., 2000; Amgoud &Cayrol, 2002).2. Weights probabilities, weight argument probability conjunctionformulae argument, weight 4 probability disjunction A1 A2 .3. Here, consider interactions corresponding attacks arguments. exist alsotypes interactions (for example, arguments reinforce arguments instead attacking them, see Karacapilidis & Papadias, 2001; Verheij, 2002). kind interaction, gradualityconsidered.4. Here, initial knowledge base useless.246fiGraduality argumentationarguments one attacks (interactions arguments used).Dungs (1995) framework well suited kind approach allowsbinary classification: argument belongs belong acceptable set.clear except intrinsic valuations, proposals allow gradualnotion valuation acceptability (i.e. low number levels describe valuesacceptability usually binary). aim therefore introduce gradualitytwo steps.However, processes valuation selection often linked together.case selection done basis value arguments5 selectiondefines binary valuation arguments. therefore:first consider discuss general principles concerning definition gradualinteraction-based valuation define valuation models abstractargumentation system,then, introduce notion graduality definition acceptability usingpreviously defined gradual valuations, also classical mechanisms.graduality already introduced argumentation systems. instance,work Pollock (2001), degrees justification beliefs computed. Argumentssequences conclusive and/or prima-facie inferences. Arguments collected graphnode represents conclusion argument, support link ties node nodesinferred, attack link indicates attack nodes. degreejustification belief computed strength arguments concludingbelief strength arguments concluding attacker belief.work takes place abstract framework since consider argumentstructure. valuation models based interactions arguments directlyapply arguments.use framework defined Dung (1995): set arguments binary attackrelation arguments. also use graphical representation argumentation systems (see Section 2). gradualisation interaction-based valuations presentedSection 3. Then, Section 4, consider different mechanisms leading gradualacceptability, sometimes relying gradual valuations defined Section 3.conclude Section 5.proofs properties stated Sections 3 4 given Appendix A.2. Dungs (1995) framework graphical representationconsider abstract framework introduced Dung (1995). argumentation system<A, R> set arguments binary relation R called attack relation:consider Ai Aj A, Ai RAj means Ai attacks Aj Aj attacked Ai (alsodenoted (Ai , Aj ) R).5. example, using Besnard Hunters (2001) valuation, decide arguments whosevalue > 0.5 selected, 0.5 mean value set values; Another possibility,different valuations (interaction-based intrinsic), accept argument value bettervalue attackers.247fiCayrol, Lagasquie-Schiexargumentation system well-founded infinite sequence 0 , A1 ,. . . , , . . . i, Ai Ai+1 RAi .Here, interested structure arguments consider arbitraryattack relation.Notation: <A, R> defines directed graph G called attack graph. Consider A,set R (A) set arguments attacking A6 set R+ (A) setarguments attacked A7 .Example 1system <A = {A1 , A2 , A3 , A4 }, R = {(A2 , A3 ), (A4 , A3 ), (A1 , A2 )}> defines following graph G root8 A3 :A1A2A3A4Definition 1 (Graphical representation argumentation system) Let Gattack graph associated argumentation system <A, R>, define:Leaf attack graph leaf G argument without attackers9 .Path attack graph path B sequence arguments C = A1. . . that:= A1 ,A1 RA2 ,...,An1 RAn ,= B.length path n 1 (the number edges used path)denoted lC .special case path10 whose length 0.set paths B denoted C(A, B).6. R (A) = {Ai A|Ai RA}.7. R+ (A) = {Ai A|ARAi }.8. word root used informal sense (it means graph pathsleading node). term terms (leaf, branch, path, . . . ) useddocument standard graph theory may different definition. usual termsargumentation domain. Please see Definition 1 order know precise meaning document.definitions simply take account fact directed edges graph link attackersattacked argument).9. leaf iff R (A) = .10. assume exists infinity paths. assumption greatly simplifies handlingleaves later paper.248fiGraduality argumentationDependence, independence, root-dependence pathConsider 2 paths CA C(A1 , ) CB C(B1 , Bm ).two paths said dependent iff Ai CA , Bj CB Ai = Bj .Otherwise independent.two paths said root-dependent iff = Bm Ai 6= CA ,6 Bj CB Ai = Bj .Cycles attack graph cycle11 path C = A1 . . . A1 i, j[1, n], 6= j, Ai 6= Aj .cycle C isolated iff C, 6 B BRA B 6 C.Two cycles CA = A1 . . . A1 CB = B1 . . . Bm B1 interconnectediff [1, n], j [1, m] Ai = Bj .use notions direct indirect attackers defenders. notions introducedinspired related definitions first introduced Dung (1995) strictlyequivalent12 .Definition 2 (Direct/Indirect Attackers/Defenders argument) ConsiderA:direct attackers elements R (A).direct defenders direct attackers elements R (A).indirect attackers elements Ai defined by:C C(Ai , A) lC = 2k + 1, k 1.indirect defenders elements Ai defined by:C C(Ai , A) lC = 2k, k 2.argument attacker (direct indirect) argument B, sayattacks B (or B attacked A). way, argument defender(direct indirect) argument B, defends B (or B defended A).Note attacker also defender (for example, A1 attacks A2 attacksA3 , A1 also attacks A3 ). way, direct attacker indirect attacker(for example, A1 attacks A2 attacks A3 attacks A4 , A1 also attacks A4 )thing may occur defenders.Definition 3 (Attack branch defence branch argument) ConsiderA, attack branch (resp. defence branch) path G leaf whoselength odd (resp. even). say root attack branch (resp. defencebranch).11. definition cycle corresponds definition elementary cycle graph theory (anelementary cycle contain 2 edges initial extremity, ending extremity).12. Dungs (1995) work, direct attackers (resp. defenders) also indirect attackers (resp. defenders)true definitions.249fiCayrol, Lagasquie-SchiexNote notion defence basis usual notion reinstatement (B attacksC, attacks B C reinstated A). paper, reinstatement takenaccount indirectly, value argument C possibility selectingC increased thanks presence A.notions illustrated following example:Example 2graph G, see:path C2 whose length 2 (C2 B1 A),2 cycles A1 A3 A2 A1 A1 A3 A4 A1 , length3, isolated (note A1 A3 A2 A1A3 A4 A1 cycle definition),two previous cycles interconnected (in A1 A3 ),paths D1 C1 B1 C3 B2 independent,paths D1 C1 B1 C3 B2 root-dependentpaths D1 C1 B1 C2 B1 dependent,D1 , C2 , E1 leaves G,D1 C1 B1 attack branch whose length3, C2 B1 defence branch whose length 2,C2 , B1 B2 direct attackers A,C1 , C2 (which already direct attacker A) C3direct defenders A,D1 D2 two indirect attackers A,E1 indirect defender A.A3A4A1A2B2B1C1D1C2C3D2E13. Graduality interaction-based valuationsconsider two different valuation methods taking account quality attackersdefenders argument order define value argument usinginteraction arguments13 :first approach, value argument depends values directattackers argument. Therefore, defenders taken accountattackers. approach called local.second approach, value argument represents set attackdefence branches argument. approach called global.main difference two approaches illustrated following example:C1CBBC213. pursue work initiated (Cayrol & Lagasquie-Schiex, 2003c) propose improvements.250fiGraduality argumentationlocal approach, B two direct attackers (C2 C1 ) whereas B 0 one(C 0 ). Thus B 0 better B (since B 0 suffers one attack whereas B suffers two attacks).global approach, two branches (one attack one defence) lead B whereasone branch attack leads B 0 . Thus B better B 0 (since least onedefence whereas B 0 none). case, C1 loses negative status attacker, sincefact carrying defence B.3.1 Local approach (generic valuation)existing proposals already considered examples local valuations.Jakobovits Vermeirs (1999) approach, labelling set arguments assignsstatus (accepted, rejected, undecided) argument using labels set {+, , ?}.+ (resp. , ?) represents accepted (resp. rejected, undecided) status. Intuitively,argument labelled ? supported weakened.Definition 4 (Jakobovits Vermeirs labellings, 1999) Let <A, R> argumentation system. complete labelling <A, R> function Lab : {+, ?, }that:1. Lab(A) {?, } B R (A) Lab(B) {+, ?}2. Lab(A) {+, ?} B R (A) R+ (A), Lab(B) {?, }underlying intuition argument weakened (label ?) onedirect attackers supported (condition 1); argument get supportdirect attackers weakened argument supported (label + ?) weakensarguments attacks (condition 2). So:attacker Lab(A) = +.Lab(A) =? B R (A) Lab(B) =?.(B R (A), Lab(B) = ) Lab(A) = +.Lab(A) = + B R (A) R+ (A), Lab(B) = .Every argumentation system completely labelled. associated semanticsacceptable set arguments iff exists complete labelling Lab <A, R>= {A|Lab(A) = +}.types labellings introduced Jakobovits Vermeir (1999) amongso-called rooted labelling induces corresponding rooted semantics. ideareject arguments attacked accepted arguments: attack undecidedargument rooted since undecided attacker may become rejected.Definition 5 (Jakobovits Vermeirs labellings, 1999 continuation)complete labelling Lab rooted iff A, Lab(A) = B R (A)Lab(B) = +.rooted semantics enables clarify links semantics introducedJakobovits Vermeir (1999) semantics introduced Dung (1995).251fiCayrol, Lagasquie-SchiexExample 3 following example:An1A2A1n even, obtain Lab(An ) = Lab(An2 ) = . . . = Lab(A2 ) = + Lab(An1 ) =Lab(An3 ) = . . . = Lab(A1 ) = .n odd, obtain Lab(An ) = Lab(An2 ) = . . . = Lab(A1 ) = + Lab(An1 ) =Lab(An3 ) = . . . = Lab(A2 ) =Another type local valuation introduced recently Besnard Hunter (2001)deductive arguments. approach characterised follows. argumentstructured pair hsupport, conclusioni, support consistent set formulaeenables prove formula conclusion. attack relation considered strictcycles allowed. notion tree arguments allows conciseexhaustive representation attackers defenders given argument, root tree.function, called categoriser, assigns value tree arguments. valuerepresents relative strength argument (root tree) given attackersdefenders. Another function, called accumulator, synthesises values assignedargument trees whose root argument (resp. against) given conclusion.phase categorisation therefore corresponds interaction-based valuation. BesnardHunter (2001) introduce following function Cat:R (A) = , Cat(A) = 1R (A) 6= R (A) = {A1 , . . . , }, Cat(A) =11+Cat(A1 )+...+Cat(An )Intuitively, larger number direct attackers argument, lower value.larger number defenders argument, larger value.Example 3 (continuation) obtain:Cat(An ) = 1, Cat(An1 ) = 0.5, Cat(An2 ) = 0.66, Cat(An3 ) = 0.6, . . . , Cat(A1 ) =( 5 1)/2 n (this value inverse golden ratio14 ).So, have:n even Cat(An1 ) . . . Cat(A3 ) Cat(A1 ) Cat(A2 ) . . . Cat(An ) = 1n odd Cat(An1 ) . . . Cat(A2 ) Cat(A1 ) Cat(A3 ) . . . Cat(An ) = 1approach local valuations generalisation two previous proposalssense Besnard Hunters (2001) Cat function Jakobovits Vermeirs (1999)labellings instances approach.main idea value argument obtained composition twofunctions:one aggregating values direct attackers argument; so,function computes value direct attack;computing effect direct attack value argument:value direct attack increases value argument decreases,value direct attack decreases value argument increases.14. golden ratio famous number since antiquity several interesting propertiesseveral domains (architecture, example).252fiGraduality argumentationLet (W, ) totally ordered set minimum element (VMin ) subset V W ,contains VMin maximum element VMax .Definition 6 (Generic gradual valuation) Let <A, R> argumentation system.valuation function v : V that:1. A, v(A) VMin2. A, R (A) = , v(A) = VMax3. A, R (A) = {A1 , . . . , } 6= , v(A) = g(h(v(A1 ), . . . , v(An )))h : V W (V denotes set finite sequences elements V )h(x) = xh() = VMinpermutation (xi1 , . . . , xin ) (x1 , . . . , xn ), h(xi1 , . . . , xin ) = h(x1 , . . . , xn )h(x1 , . . . , xn , xn+1 ) h(x1 , . . . , xn )xi x0i h(x1 , . . . , xi , . . . , xn ) h(x1 , . . . , x0i , . . . , xn )g : W Vg(VMin ) = VMaxg(VMax ) < VMaxg non-increasing (if x g(x) g(y))Note h(x1 , . . . , xn ) max(x1 , . . . , xn ) logical consequence propertiesfunction h.first property function g explains behaviour local valuation caseargument root one branch (like Example 3):Property 1 function g satisfies n 1:g(VMax ) g 3 (VMax ) . . . g 2n+1 (VMax ) g 2n (VMax ) . . . g 2 (VMax ) VMaxMoreover, g strictly non-increasing g(VMax ) > VMin , previous inequalitiesbecome strict.second property shows local valuation induces ordering relation arguments:Property 2 (Complete preordering) Let v valuation sense Definition 6.v induces complete15 preordering set arguments defined by: B iffv(A) v(B).third property handles cycles:15. complete preordering means two elements comparable.253fiCayrol, Lagasquie-SchiexProperty 3 (Value cycle) Let C isolated cycle attack graph, whoselength n. n odd, arguments cycle value valuefixpoint function g. n even, value argument cyclefixpoint function g n .following property shows underlying principles satisfied local valuationsdefined according schema:Property 4 (Underlying principles) gradual valuation given Definition 6 respects following principles:P1 valuation maximal argument without attackers non maximalattacked undefended argument.P2 valuation argument function valuation direct attackers (thedirect attack).P3 valuation argument non-increasing function valuation directattack.P4 attacker argument contributes increase valuation directattack argument.last properties explain Jakobovits Vermeir (1999) Besnard Hunter(2001) propose instances local valuation described Definition 6:Property 5 (Link Jakobovits & Vermeir, 1999)Every rooted labelling <A, R> sense Jakobovits Vermeir (1999)defined instance generic valuation that:V = W = {, ?, +} < ? < +,VMin = ,VMax = +,g defined g() = +, g(+) = , g(?) =?h function max.Property 6 (Link Besnard & Hunter, 2001) gradual valuation BesnardHunter (2001) defined instance generic valuation that:V = [0, 1],W = [0, [,VMin = 0,VMax = 1,1g : W V defined g(x) = 1+xh defined h(x1 , . . . , xn ) = x1 + . . . + xn .254fiGraduality argumentationNote that, work Besnard Hunter (2001), valued graphs acyclic. However, easy show valuation proposed Besnard Hunter (2001)generalised graphs cycles (in case, must solve second degree equations seeExample 5).B1B2B3C1C3C2C4D1D2D3E1Example 4 Consider following graph:B4example, generic valuation, obtain:v(E1 ) = v(D2 ) = v(D3 ) = v(C4 ) = v(B4 ) = VMaxv(D1 ) = v(C2 ) = v(C3 ) = v(B3 ) = g(VMax )v(C1 ) = v(B2 ) = g 2 (VMax )v(B1 ) = g(h(g 2 (VMax ), g(VMax )))v(A) = g(h(g(h(g 2 (VMax ), g(VMax ))), g 2 (VMax ), g(VMax ), VMax ))So, have:E 1 , 2 , 3 , C 4 , B4C 1 , B21 , C 2 , C 3 , B3However, constraints v(A) v(B1 ) insufficient compare B1arguments.problem exists reduce example hatched part graphprevious figure; obtain E1 , D2 C1 D1 , C2 , B1 cannot comparedarguments16 .Now, use instance generic valuation proposed Besnard Hunter (2001):v(E1 ) = v(D2 ) = v(D3 ) = v(C4 ) = v(B4 ) = 1,v(D1 ) = v(C2 ) = v(C3 ) = v(B3 ) = 12 ,v(C1 ) = v(B2 ) = 23 ,16. v(A) = g 2 (h(g 2 (VMax , g(VMax ))) v(B1 ) = g(h(g 2 (VMax ), g(VMax ))).255fiCayrol, Lagasquie-Schiex6,v(B1 ) = 1378v(A) = 283 .So, have:E 1 , 2 , 3 , C 4 , B4C 1 , B21 , C 2 , C 3 , B3B1However, reduce example hatched part graph, value1319 . So, v(A) better v(B1 ) v(D1 ), also v(C1 ) (A becomes betterdefender).Example 5 (Isolated cycle) Consider following graph reduced isolated cycle:B.generic valuation gives v(A) = v(B) = fixpoint g 2 .use instance proposed Besnard Hunter (2001), v(A) v(B) solutionsfollowing second degree equation:x2 + x 1 = 0.1+ 5So, obtain: v(A) = v(B) =0.618 (the inverse golden ratio again).23.2 Global approach (with tuples)consider second approach valuation step, called global approach. Here,key idea value must describe subgraph whose root A. So,want memorise length branch leading tuple (for attack branch,odd integer, defence branch, even integer).approach, main constraint must able identify branchesleading argument compute lengths. easy caseacyclic graph. therefore introduce first global gradual valuation acyclic graphs.Then, next sections, extend proposition case graphs cycles,study properties global gradual valuation.3.2.1 Gradual valuation tuples acyclic graphsFirst, order record lengths branches leading arguments, usenotion tuples define operations tuples:256fiGraduality argumentationDefinition 7 (Tuple) tuple sequence integers. tuple (0, . . . , 0, . . .)|{z}denoted 0 . tuple (1, . . . , 1, . . .) denoted 1 .|{z}Notation 1 denotes set tuples built positive integers.Definition 8 (Operations tuples) two kinds operations tuples:concatenation two tuples defined function ? :0 ? = ? 0 = 6= ()(x1 , . . . , xn , . . .) ? (x01 , . . . , x0n , . . .) = Sort(x1 , . . . , xn , . . . , x01 , . . . , x0n , . . .)Sort function orders tuple increasing values.addition tuple integer defined function :0 k = (k)() k = ()(x1 , . . . , xn ) k = (x1 + k, . . . , xn + k)(x1 , . . . , xn , . . .) k = (x1 + k, . . . , xn + k, . . .) (x1 , . . . , xn , . . .) 6= 0Note allow infinite tuples, among reasons, needed laterorder compute ordering relations described Section 3.2.4 (in particulargraph cyclic).operations tuples following properties:Property 7 (Properties ? )concatenation ? commutative associative.tuple integers k k 0 , (t k) k 0 = (k + k 0 ).integer k tuples t0 different 017 , (t ? t0 ) k = (t k) ? (t0 k).order valuate arguments, split set lengths branches leadingargument two subsets, one lengths defence branches (even integers)one lengths attack branches (odd integers). capturednotion tupled values:Definition 9 (Tupled value) tupled value pair tuples vt = [vtp , vti ] with:vtp tuple even integers ordered increased values; tuple called evencomponent vt;vti tuple odd integers ordered increased values; tuple called oddcomponent vt.17. Otherwise false : (0 ? (p)) k = (p + k), whereas (0 k) ? ((p) k) = (k) ? (p + k) = (k, p + k).257fiCayrol, Lagasquie-SchiexNotation 2 V denotes subset tupled values (so, vt V, vt pairtuples satisfying Definition 9).Using notion tupled-values, define computation process gradualvaluation tuples18 case acyclic graphs.Definition 10 (Valuation tuples acyclic graphs) Let <A, R> argumentation system without cycles. valuation tuples function v : Vthat:leafv(A) = [0 , ()].direct attackers denoted B1 , . . . , Bn , . . .v(A) = [vp (A), vi (A)] with:vp (A) = (vi (B1 )1)?. . .?(vi (Bn )1)?. . .vi (A) = (vp (B1 )1)?. . .?(vp (Bn )1)?. . .Notes: choice value [0 , ()] leaves justified fact valueargument memorises lengths branches leading argument. Usingconstraint, either vp (A) vi (A) may empty both19 .Note also set direct attackers argument infinite (this propertyused take account argumentation graph cycles).Example 6 graph, valuation tuples gives following results:B2B1C1D1graph G, have:C2C3D2v(D1 ) = v(C2 ) = v(E1 ) = [0 , ()],v(C1 ) = v(D2 ) = [(), (1)],v(C3 ) = [(2), ()],v(B1 ) = [(2), (1)],v(B2 ) = [(), (3)],v(A) = [(2, 4), (1, 3)].E118. definition different definition given (Cayrol & Lagasquie-Schiex, 2003c). ideasformalisation different.19. proof following:.leaf, least one tuples empty, exists least one branchwhose length > 0 leading (see Definitions 8 10).And, leaf, also exists least one defence branch pathallowed length 0 (in fact, infinity paths see Definition 1) attackbranch leading leaf (see Definition 10).So, value leaf [0 , ()], impossible vp (A) = vi (A) = ().258fiGraduality argumentation3.2.2 Study cyclesHandling cycles raises important issues: notion branch always usefulcycle (for example, unattacked cycle like Examples 5 7), notionuseful, length branch defined different ways.Let us consider different examples:Example 7 (Unattacked cycle) graph reduced unattacked cycle Battacks argument C:BCnotion branch useless case, leaf graph.two possibilities:First, one consider cycle like infinite branch; (resp. B)root one branch whose length . parity length branchundefined, impossible say branch attack branch defencebranch.second possibility consider cycle like infinity branches;(resp. B) root infinity attack branches defence branches whoselengths known finite.second possibility means cycle may two representations acyclicalso infinite graphs (one root one root B).rewriting process cycle:B4A4B1B5B6A1A2A3B2B3B4A1A5A6B1B2B3A2A3A4BAi Bi must new arguments created rewriting process cycle.Example 8 (Attacked cycle) cycle B attacked least one argumentbelong cycle (here, attacker unattacked argument D):259fiCayrol, Lagasquie-SchiexBCEcase, notion branch useful exists one leaf graph,difficulty compute length branch. Example 7, consider eitherone infinite branch (so, impossible know branch attackdefence branch), infinity attack branches defence brancheswhose lengths known finite.second case, graph rewritten following structures:A6A3B3A4A5B3A1A2B1B2B1B2A1A2A3BCEAi Bi must new arguments created rewriting process graph.previous examples, chosen manage cycle infinity attackbranches defence branches whose lengths known finite would likeable apply Definition 10 cases (acyclic graphs graphs cycles). However,need rewriting process graph cycles acyclic graph. twodifferent cases, one unattacked cycles one attacked cycles:Definition 11 (Rewriting unattacked cycle) Let C = A0 A1 . . . An1 A0unattacked cycle. graph G contains C rewritten follows:260fiGraduality argumentation1. cycle C removed,2. replaced infinite acyclic graphs, one Ai , = 0 . . . n 1:%Ai 11%Ai 21Ai 22Ai...............-Ai n11Ai n12...Ai n1n1Ai n1Ai n2...Ai nn1Ai nn-Ai n+11Ai n+12...Ai n+1n1Ai n+1nAi n+1n+1.................................3. edges Ai argument belong C kept.Example 7 Unattacked cycle (continuation) graph G containing unattackedcycle B argument C, attacked A, rewritten follows:C%A11%A21A22BA31A32A33%B11..................%B12B22B13B23B33..................Alk Bkl new arguments.Definition 12 (Rewriting attacked cycle) Let C = A0 A1 . . . An1 A0attacked cycle, direct attacker Ai denoted Bi , exists. graph Gcontains C rewritten follows:1. cycle C removed,2. replaced infinite acyclic graphs, one Ai = 0 . . . n 1:261fiCayrol, Lagasquie-Schiex%Bi%Ai 11B(i1+n) mod nAi...............Ai n11Ai n12...Ai n1n1Ai n1Ai n2...Ai nn1Ai nnBiB(i+1) mod nAi n+11Ai n+12...Ai n+1n1Ai n+1nAi n+1n+1B(i1+n) mod n.......................................(the branches leading Bk exist iff Bk exists20 ).3. edges Ai argument belong C kept.4. edges Bi argument belong C kept.Example 8 Attacked cycle (continuation) graph G containing cycleB attacked argument argument C (resp. E) attacked(resp. B) rewritten follows:EBC%A21A22A41A42A43A44%B11..............................Alk Bkl new arguments.20. operator mod modulo function.262B13B23B33B15B25B35B45B55....................................fiGraduality argumentationNote: exist several cycles graph, two cases.interconnected, rewrite cycle, valuation resultinggraph rewriting depend order cycles select rewritevaluation process uses length branches.interconnected, considered metacyle turn attacked unattacked previous methodology used leadingcomplex rewriting process formalized (see details examplesAppendix B).3.2.3 gradual valuation tuples general graphsUsing definitions given Sections 3.2.1 3.2.2, gradual valuation tuplesgiven Definition 10 applicable arbitrary graphs rewriting process.Let us apply rewriting process Definition 10 different examples.Example 7 Unattacked cycle (continuation)Consider following graph:BCrewriting graph given Section 3.2.2.Definition 10 produces:vp (A) = (vi (A11 ) 1) ? . . . ? (vi (An1 ) 1) ? . . .vi (A) = (vp (A11 ) 1) ? . . . ? (vp (An1 ) 1) ? . . .Applying Definition 10 different arguments rewritten graph produces followingequalities:v(Ann ) = [0 , ()] n 1v(Ann1 ) = [(), (1)] n 2v(Amn ) = [vp (An+2 ) 2, vi (An+2 ) 2] n 1 n + 2So, using equalities formulae giving vp (A) vi (A), define two sequences tuples : sequence (xk , k 1) infinite tuples even integers, sequence(yk , k 1) infinite tuples odd integersnxk = (2) ? (vi (A2k+12k1 ) 1) ? . . . ? (vi (A2k1 ) 1) ? . . .nyk = (1) ? (vp (A2k+12k1 ) 1) ? . . . ? (vp (A2k1 ) 1) ? . . .263fiCayrol, Lagasquie-Schiexresults stated Property 7, easy prove vp (A) = x1 k 1,xk = (2) ? (xk+1 2).Similarly, vi (A) = y1 k 1, yk = (1) ? (yk+1 2).equations enable prove :even integer p p > 0, p belongs tuple xi , 1.odd integer p, p belongs tuple yi , 1.proof done induction p.So, v(A) = v(B) = [(2, 4, 6, . . .), (1, 3, 5, . . .)].Then, v(C) = [(2, 4, 6, . . .), (3, 5, 7, . . .)].Note results readily extended unattacked cycle length n,n 2.Property 8 (Properties unattacked cycles)unattacked cycle, argument cycle, v(A) = [(2, 4, 6, . . .), (1, 3, 5, . . .)].Example 8 Attacked cycle (continuation)Consider following graph:BCErewriting graph given Section 3.2.2.Definition 10 produces:vp (A) = (vi (D) 1) ? (vi (A21 ) 1) ? . . . ? (vi (A2n1 ) 1) ? . . .vi (A) = (vp (D) 1) ? (vp (A21 ) 1) ? . . . ? (vp (A2n1 ) 1) ? . . .alsov(D) = [0 , ()]v(Ann ) = [(), (1)] n 2done treatment Example 7, formulae giving vp (A) vi (A) rewrittenorder bring light interesting sequences tuples.264fiGraduality argumentation2(k+p)x0k = (vi (A2k2k1 ) 1) ? . . . ? (vi (A2k1 ) 1) ? . . .2(k+p)yk0 = (1) ? (vp (A2k2k1 ) 1) ? . . . ? (vp (A2k1 ) 1) ? . . .Then, easy prove vp (A) = x01 k 1, x0k = (x0k+1 2).02).Similarly, vi (A) = y10 k 1, yk0 = (1) ? (yk+1first equation enables prove x01 empty tuple21 .second equation already solved produces y10 = (1, 3, 5, . . .).So, v(A) = [(), (1, 3, 5, . . .)]. B, reason A, v(B) = [(2, 4, 6, . . .), ()].Then, v(C) = [(2, 4, 6, . . .), ()], v(E) = [(), (3, 5, 7 . . .)].Notation: order simplify writing, repeat values inside tuples(we indicate value many times appears). example:[(2, 4, 4, 6, 6, 6, 8, 8, 8, 8 . . .), (3, 5, 5, 7, 7, 7, 9, 9, 9, 9 . . .)]denoted[(2, |{z}4 , |{z}6 , |{z}8 , . . .), (3, |{z}5 , |{z}7 , |{z}9 , . . .)]234234Conclusion cycles Cycles expensive since values obtained infinite.appendix B, introduce algorithm computing tupled values. usesprocess value propagation parameterised maximum number runscycle. number used order stop propagation mechanismobtain finite (thus incomplete) tupled values.3.2.4 Comparison tupled valuessection, define comparison relation arguments (so, particular tupled values), using following idea: argument better argumentB iff better defence (for it) lower attack (against it).first idea use lexicographic ordering tuples. lexicographic orderingdenoted lex defined by:21. proof following:.x01 contains even integers.k, x0k 6= 0 since x0k result addition tuple integer.x01 empty, let e1 denote least even integer present x01 . x01 = x02 2, x02 emptye2 denote least integer present x02 . e1 = e2 + 2. So, able buildsequence positive even integers e1 , e2 , . . ., strictly decreasing. impossible. So,x01 = ().265fiCayrol, Lagasquie-SchiexDefinition 13 (Lexicographic ordering tuples)Let (x1 , . . . , xn , . . .) (y1 , . . . , ym , . . .) 2 finite infinite tuples .(x1 , . . . , xn , . . .) <lex (y1 , . . . , ym , . . .) iff 1 that:j < i, xj = yjyi exists and:either tuple (x1 , . . . , xn , . . .) finite number elements equal 1(so, xi exist),xi exists xi < yi .(x1 , . . . , xn , . . .) =lex (y1 , . . . , ym , . . .) iff tuples contain number p {}elements i, 1 p, xi = yi .So, define: (x1 , . . . , xn , . . .) lex (y1 , . . . , ym , . . .) iff(x1 , . . . , xn , . . .) =lex (y1 , . . . , ym , . . .) (x1 , . . . , xn , . . .) <lex (y1 , . . . , ym , . . .).ordering <lex generalisation classical lexicographic ordering (see Xuong,1992) case infinite tuples. ordering complete well-founded (thereexist infinite sequences strictly non-increasing: (0) <lex (0, 0) <lex . . . <lex(0, . . . , 0, . . .) <lex . . . <lex (0, 1)).Since even values odd values tupled value argument playrole, cannot use classical lexicographic comparison. So, compare tupledvalues two steps:first step compares number attack branches number defencebranches argument. So, two criteria (one defenceattack). criteria aggregated using cautious method: concludeone arguments defence branches (it better according defencecriterion) less attack branches argument (it also better accordingattack criterion). Note conclude positively criteriaagree: one arguments defence branches (it better accordingdefence criterion) attack branches argument (it worseaccording attack criterion), arguments considered incomparable.Else, arguments number defence branches numberattack branches, second step compares quality attacksquality defences using length branch. comparison madelexicographic principle (see Definition 13) gives two criteriaaggregated using cautious method. case disagreement, argumentsconsidered incomparable.Let us consider examples:[(2), (1)] better [(2), (1, 1)] less attack branches firsttupled value second tupled value, numbers defence branches(first step).[(2), (1)] incomparable [(2, 2), (1, 1)] less defence branchesless attack branches first tupled value second tupled value (firststep).266fiGraduality argumentation[(2), (3)] better [(2), (1)] weaker attack branches firsttupled value second tupled value (the attack branch first tupledvalue longer one second tupled value), defence branches(second step, using lexicographic comparison applied even partsodd parts tupled values).[(2), (3)] better [(4), (3)] stronger defence branchesfirst tupled value second tupled value (the defence branch shorterfirst tupled value second tupled value), attack branches(second step).[(2), (1)] incomparable [(4), (3)] worse attack branchesbetter defence branches first tupled value second tupled value(second step).comparison arguments done using Algorithm 1 implements principledouble comparison (first quantitative, qualitative) two criteria (one defencecriterion one attack criterion) using cautious method.Algorithm 1: Comparison two tupled values% Description parameters:% v, w: 2 tupled values% Notations:%|vp | (resp. |wp |): number elements even component v (resp. w)%vp (resp. wp ) infinite |vp | (resp. |wp |) taken equal%|vi | (resp. |wi |): number elements odd component v (resp. w)%vi (resp. wi ) infinite |vi | (resp. |wi |) taken equal%usual, denote strict relation associated defined by:%v w iff v w not(w v).%%%%%%%%%beginv = w v w w v% Case 1 %2else3|vi | = |wi | |vp | = |wp |% lexicographic comparisons vp wp vi wi %4vp lex wp vi lex wi v w% case 2 %5else6vp lex wp vi lex wi v w% case 3 %7else v 6 w v 6 w% Incomparable tupled values. case 4 %189101112else|vi | |wi | |vp | |wp | v w% case 5 %else|vi | |wi | |vp | |wp | v w% case 6 %else v 6 w v 6 w% Incomparable tupled values. Case 7 %endAlgorithm 1 defines partial preordering set v(A):Property 9 (Partial preordering) Algorithm 1 defines partial preorderingset v(A).267fiCayrol, Lagasquie-Schiextupled value [0 , ()] maximal value partial preordering .tupled value [(), 1 ] minimal value partial preordering .Notation: partial preordering set v(A) induces partial preorderingarguments (the partial preordering denoted like partial preorderingv(A)): B v(A) v(B)22 .order present underlying principles satisfied global valuation, firstconsider different ways modifying defence part attack part argument:Definition 14 (Adding/removing branch argument)Let argument whose tupled value v(A) = [vp (A), vi (A)] vp (A) = (xp1 , . . . , xpn )vi (A) = (xi1 , . . . , xim ) (vp (A) vi (A) may empty simultaneously).Adding (resp. removing) defence branch defined by:vp (A) becomes Sort(xp1 , . . . , xpn , xpn+1 ) xpn+1 length added branch (resp.j [1..n] vp (A) becomes (xp1 , . . . , xpj1 , xpj+1 , . . . , xpn )).thing vi (A) adding (resp. removing) attack branch A.Definition 15 (Increasing/decreasing length branch argument)Let argument whose tupled value v(A) = [vp (A), vi (A)] vp (A) = (xp1 , . . . , xpn )vi (A) = (xi1 , . . . , xim ) (vp (A) vi (A) may empty simultaneously).Increasing (resp. decreasing) length defence branch defined by:pp0ppj [1..n] vp (A) becomes (xp1 , . . . , xpj1 , x0pj , xj+1 , . . . , xn ) xj > xj (resp.p0ppx0pj < xj ) parity xj parity xj .thing vi (A) increasing (resp. decreasing) attack branch A.Definition 16 (Improvement/degradation defences/attacks)Let argument whose tupled value v(A) = [vp (A), vi (A)] (vp (A) vi (A) mayempty simultaneously). define:improvement (resp. degradation) defence consistsadding defence branch initially vp (A) 6= 0 (resp. removingdefence branch A);decreasing (resp. increasing) length defence branch A;removing defence branch leading (resp. adding defence branch leading initially vp (A) = 0 );improvement (resp. degradation) attack consistsadding (resp. removing) attack branch A;decreasing (resp. increasing) length attack branch A.Property 10 (Underlying principles) Let v valuation tuples (Definition 10)associated Algorithm 1, v respects following principles:P10 valuation maximal argument without attackers non maximalargument attacked (whether defended not).22. also use notation B defined by: B iff B.268fiGraduality argumentationP20 valuation argument takes account branches rootedargument.P30 improvement defence degradation attack argument leadsincrease value argument.P40 improvement attack degradation defence argument leadsdecrease value argument.Example 4 (continuation)valuation tuples, obtain:v(E1 ) = v(D2 ) = v(D3 ) = v(C4 ) = v(B4 ) = [0 , ()],v(D1 ) = v(C2 ) = v(C3 ) = v(B3 ) = [(), (1)],v(C1 ) = v(B2 ) = [(2), ()],v(B1 ) = [(2), (3)],v(A) = [(2, 4), (1, 3, 3)].So, have:E 1 , 2 , 3 , C 4 , B4C 1 , B2B11 , C 2 , C 3 , B3alsoE 1 , 2 , 3 , C 4 , B4incomparable almost arguments (except leaves graph).Similarly, hatched part graph, obtain following results:E1 , D2 C 1 B 1 1 , C 2comparable arguments (in particular, worsedefender C1 direct attacker B1 ).3.3 Main differences local global valuationsCayrol Lagasquie-Schiex (2003c) give comparison approaches existing approaches (Dung, 1995; Jakobovits & Vermeir, 1999; Besnard & Hunter, 2001),also comparison local approaches global approach. improvementglobal approach proposed paper modify main resultscomparison.Let us recall example essential point differentiates (this examplealready presented beginning Section 3):C1CBC2269BfiCayrol, Lagasquie-Schiexlocal approach, B 0 better B (since B 0 suffers one attack whereas B sufferstwo attacks).global approach, B better B 0 (since least defence whereas B 0none). case, C1 loses negative status attacker, since fact carryingdefence B.following table synthesises results different proposed valuations:global approachargumentsingbrancheshavattackargumentsattackbranchesdefencebranchesargumentsdefencebranchesargumentsnever attackedlocal approachargumentsargumentshavonly one attackedingonedirectattackerunattacked direct(possiblydefended)attackerarguments several attacked direct attackers (possibly defended)argumentsseveral unattackeddirect attackersargumentsnever attackeddifference local approaches global approach also illustratedfollowing property:Property 11 (Independence branches global approach)Let argument following direct attackers:A1 whose value v(A1 ) = [(a1p1 , . . . , a1pm ), (a1i1 , . . . , a1im )],11...,whose value v(An ) = [(anp1 , . . . , anpmn ), (ani1 , . . . , animn )].Let A0 argument following direct attackers:A1p1 whose value v(A1p1 ) = [(a1p1 )()],...,A1pm whose value v(A1pm ) = [(a1pm )()],111A1i1 whose value v(A1i1 ) = [()(a1i1 )],...,A1im whose value v(A1im ) = [()(a1im )],111...,Anp1 whose value v(Anp1 ) = [(anp1 )()],...,270fiGraduality argumentationAnpmn whose value v(Anpmn ) = [(anpmn )()],Ani1 whose value v(Ani1 ) = [()(ani1 )],...,Animn whose value v(Animn ) = [()(animn )].v(A) = v(A0 ).property illustrates independence branches computationvalues global approach, even branches graphically independent.following example, A0 value [(2, 2)()] though rootdifferent subgraphs:C1C1BB1C2C2B2property satisfied local approach since, using underlying principleslocal approach (see Property 4), value argument must leastgood (and sometimes better than23 ) value argument A0 (A one directattacker, A0 two direct attackers).3.4 Conclusion valuation stepproposed two different gradual valuation models able makedistinction different arguments using preordering associated valuationmodel. valuations used selection arguments (see Section 4).4. Graduality acceptabilitysection, shift selection step introduce graduality notionacceptability24 .basic idea select argument depending non-selection direct attackers.Following idea, propose two different methods:first method consists refining classical partition issued Dungs collective acceptability; refinement may achieved using gradual valuationsdefined Section 3.second method takes place individual acceptability consists definingnew acceptability using gradual valuations defined Section 3.4.1 Dungs (1995) collective acceptabilityframework collective acceptability, consider acceptability setarguments. acceptability defined respect properties setssatisfy properties called acceptable sets extensions. argumentsaid acceptable belongs extension.23. valuation proposed Besnard Hunter (2001), obtain: v(A) = 34 v(A0 ) = 12 .24. work presented workshop (Cayrol & Lagasquie-Schiex, 2003b).271fiCayrol, Lagasquie-SchiexDefinition 17 (Basic properties extensions following Dung, 1995)Let <A, R> argumentation system, have:Conflict-free set set E conflict-free 6 A, B E ARB.Collective defence Consider E A, A. E collectively defendsB A, BRA, C E CRB. E defends elementsE, E collectively defends A.Dung (1995) defines several semantics collective acceptability: mainly, admissiblesemantics, preferred semantics stable semantics (with corresponding extensions:admissible sets, preferred extensions stable extensions).Definition 18 (Some semantics extensions following Dung, 1995) Let <A, R>argumentation system.Admissible semantics (admissible set) set E admissible Econflict-free E defends elements.Preferred semantics (preferred extension) set E preferred extensionE maximal set inclusion among admissible sets.Stable semantics (stable extension) set E stable extension Econflict-free E attacks argument belong E (A \ E,B E BRA).Note definitions, attacker given argument consideredseparately (the direct attack whole considered). Dung (1995) proves that:admissible set <A, R> included preferred extension <A, R>.always exists least one preferred extension <A, R>.<A, R> well-founded one preferred extension alsostable extension.stable extension also preferred extension (the converse false).always stable extension.Property 12 set leaves (i.e. {A|R (A) = }) included every preferred extension every stable extension.4.2 Different levels collective acceptabilitygiven semantics, following Dung, acceptability argument dependsmembership extension semantics. consider three possible cases 25 :25. terminology used section also used domain nonmonotonic reasoning (see Pinkas& Loui, 1992): word uni comes word universal synonym word skeptical,word exi comes word existential synonym word credulous.chosen use words uni exi recall logical quantificators (for all) (existsleast one).272fiGraduality argumentationargument uni-accepted, belongs extensions semantics,argument exi-accepted, belongs least one extensionsemantics,argument not-accepted belong extensionsemantics.However, three levels seem insufficient. example, concludedcase two arguments B exi-accepted ARB BRA?So, introduce new definition takes account situation argumentw.r.t. attackers. refines class exi-accepted arguments givensemantics S.Definition 19 (Cleanly-accepted argument) Consider A, cleanly-acceptedbelongs least one extension B BRA, Bbelong extension S.Thus, capture idea argument better accepted, attackersnot-accepted.Property 13 Consider semantics extension conflictfree. uni-accepted cleanly-accepted. converse false.notion cleanly-accepted argument refines class exi-accepted arguments.semantics argument A, following states:uni-accepted, belongs extensions (so, alsocleanly-accepted);cleanly-accepted (so, definition also exi-accepted); notepossible argument also uni-accepted;only-exi-accepted, cleanly-accepted, exi-accepted;not-accepted belong extension S.Example 9 Consider following argumentation system.two preferred extensions {D, C2 , A, G}J{D, C2 , E, G, I}. So, preferred semantics, acIceptabilitylevels following:EGHBFC1C2D, C2 G uni-accepted,cleanly-accepted uni-accepted,E only-exi-accepted,B, C1 , F , H J not-accepted.Note that, cases one extension, first three levels acceptability coincide26 . case:26. one extension fact belongs extensions equivalentfact belongs least one extension. Moreover, one extension containing A,attackers belong extension. So, cleanly-accepted.273fiCayrol, Lagasquie-Schiexpreferred semantics, even cycle (see Doutre, 2002).basic semantics (another semantics proposed Dung see Dung, 1995;Doutre, 2002 presented one extension).Looking closely, prove following result (proof Appendix A):Property 14 stable semantics, class uni-accepted arguments coincidesclass cleanly-accepted arguments.Then, using result issued work Dunne Bench-Capon (2001, 2002)reused Doutre (2002) shows that, odd cycle, preferredextensions stable27 , apply Property 14 obtain following consequence:Consequence 1 preferred semantics, odd cycle, classuni-accepted arguments coincides class cleanly-accepted arguments.Finally, exploitation gradual interaction-based valuations (see Section 3) allowsus define new levels collective acceptability.Let v gradual valuation let associated preordering (partial complete)A. preordering used inside acceptability level (for example, levelexi-accepted arguments) order identify arguments better acceptedothers.Example 9 (continuation)graph:Two different gradual valuations applied0,6740,5900,482JE0,694HG 0,6660,4410,4 B1C1F0,5C2 10.5Besnard & Hunters (2001) valuationinstance generic valuation proposed Besnard Hunter (2001) (seeSection 3.1), obtain following comparisons:D, C2 E G J C1 , F H B27. corresponds consistent argumentation system proposed Dung (1995).274fiGraduality argumentation{{[(6,8,10,12,...),2 3{{{(7,9,10,11,...)]2 2 3J[(4,6,8,10,...),(3,5,7,9,...)]EH2 2 32 3[(2,4,6,8,...),(3,5,7,9...)]G [(2),()]{{{{{[(4,6,8,10,...),2 3(5,7,9,11,...)]{{{[(6,8,10,12,...),2 2 3(5,7,9,11,...)]{{[(2),(1)]BC1[(0,...,0),()]F [(),(1)]C2 [(0,...,0),()][(),(1)]Valuation tuplesglobal valuation tuples presented Section 3.2, obtain following comparisons:D, C2 G B F, C1D, C2 ED, C2 H ED, C2D, C2 JSo, arguments belonging cycle incomparable G, B, F , C 1 and, eventhem, comparison results.apply preordering induced valuation without respecting acceptabilitylevels defined section, counter-intuitive situations may happen. Example 9,obtain:valuation Besnard Hunter (2001) preferred semantics,E G despite fact G uni-accepted E only-exi-accepted.valuation tuples preferred semantics, H E despitefact E only-exi-accepted H not-accepted.counter-intuitive situations illustrate difference acceptability definition valuation definitions (even use interaction arguments,use way).275fiCayrol, Lagasquie-Schiex4.3 Towards gradual individual acceptabilityindividual acceptability based comparison argument attackers.first proposal select argument attacker(see Elvang-Goransson et al., 1993).later extended Amgoud Cayrol (1998) where, using preferencerelation arguments (an intrinsic valuation), argument acceptedpreferred attackers.Following proposal, propose mechanism interaction-basedvaluation.Given v gradual valuation, preordering induced v directly used ordercompare, acceptability point view, argument attackers 28 .defines new class acceptable arguments: well-defended arguments.Definition 20 (Well-defended argument) Consider A, well-defended (for v)B BRA, B 6 A.Thus, capture idea argument better accepted least gooddirect attackers (or incomparable case partial ordering).set well-defended arguments depend valuation used.Using new notion, set arguments partitioned three classes:first class contains arguments attacked,second class contains arguments attacked well-defended,third class contains arguments (attacked well-defended).Note set well-defended arguments corresponds union two firstclasses. refinement uses gradual valuation inside classesSection 4.2.Example 9 presented Section 4.2, well-defended arguments are:D, C2 , G, H (A incomparable B better E) valuationtuples,though valuation Besnard Hunter (2001) well-defended argumentsD, C2 , G, E (E better A).Note also that, semantics Dung (1995), Definition 20 considers attackersone one. suitable valuation handles direct attack whole(as valuation Besnard Hunter (2001) see counterexamples presentedSection 4.4).28. idea also used notion defeat proposed Bench-Capon (2002). So, linkwell-defended argument argument attacked sense BenchCapon (2002) direct attackers. Note that, work Bench-Capon (2002), valuationextra knowledge added argumentation framework. contrast, here, v-preference extractedattack graph.276fiGraduality argumentation4.4 Compatibility acceptability gradual valuationFollowing previous sections, set arguments partitioned two differentways:First, given semantics gradual valuation v, possible use partitionissued Dung (1995) refined:UniacceptedCleanlyacceptedExiacceptedOnlyExiacceptedacceptedRefinement level gradual valuation vSecond, given gradual valuation v, possible use partition inducednotion well-defended arguments:AttakedWelldefendedArgumentsAttakedArgumentsWellDefendedvaluationvUnattackedArgumentsnatural interesting question is: possible find semantics gradualvaluation v associated partitions compatibilities?following examples show class well-defended arguments correspond class cleanly-accepted arguments (in cases, uni-acceptedarguments even well-defended).277fiCayrol, Lagasquie-Schiex4.4.1 Examples showing non-compatibility general casegive examples usual valuation (the global valuation tuples 2 instancesgeneric local valuation: Besnard & Hunter, 2001; Jakobovits & Vermeir, 1999)classical semantics acceptability (preferred semantics stable semanticsDung, 1995).Cleanly-accepted argument well-defended: 3 examples (each using distinct valuation: one global valuation two two well-known instanceslocal valuation):argument cleanly-accepted well-defended:0.40.5B1B2B30.5C2C310.5C1111 preferred stable extension = { C1, C2, C3, A}B1, B2, B3 belong preferred extensionBiforall = 1, 2, 3argument cleanly-accepted well-defended:?C2 preferred stable extensions : {C,A} {D,A}B doesnt belong preferred extensionBB??argument cleanly-accepted well-defended:[(4,4),(3)][(0,...0),()]BC[(),(1)][(2),()][(),(3)]H[(),(3)]EF[(4),(5,5)]G[(6,6),(5)][(6),(7,7)]1 preferred stable extension = {A,C,F,I}G doesnt belong preferred extensionGWell-defended argument cleanly-accepted: Similarly, three valuations,have:argument C well-defended cleanly-accepted:?+?BC?1 preferred stable extension : {D, B}CBC doesnt belong preferred stable extensionargument F well-defended cleanly-accepted:278fiGraduality argumentation0.6182 preferred stable extensions = {A,H,E} {B,H,F}F belongs preferred stable extensionFE E belongs also preferred stable extensionE attacks F0.618BEG0.50.472H1F0.679argument G well-defended cleanly-accepted:[(4,4),(3)][(0,...,0),()]BC[(),(1)][(2),()][(),(3)]EF[(4),(5,5)]G[(6,6),(5)][(6),(7,7)]H[(),(3)]1 preferred stable extension = {A,C,F,I}GFG doesnt belong preferred stable extension4.4.2 Particular cases leading compatibilitycontext argumentation system finite relation R without cycles 29 ,stable preferred semantics provide one extension levels uni-accepted,exi-accepted, cleanly-accepted coincide.context, least two particular cases leading compatibility.First case: deals global valuation tuples.Theorem 1 Let G graph associated <A, R>, <A, R> argumentationsystem finite relation R without cycles satisfying following condition:Xi , leaf G, one path Xi A, Xi1 . . . Xili Xi1 = Xili length path (if li even, path defence branch A, elseattack branch),paths Xi root-dependent A,Ai A, Xj leaf G Ai belongs path Xj A.Let v valuation tuples. Let semantics {preferred, stable}.1. B A, B 6= A, B (exi, uni, cleanly) accepted iff B well-defended v.2. (exi, uni, cleanly) accepted well-defended v (the conversefalse).3. well-defended v branches leading defence branches(exi, uni, cleanly) accepted S.29. So, (A, R) well-founded.279fiCayrol, Lagasquie-SchiexNote Theorem 1 is, general, satisfied local valuation. See followingcounterexample valuation Besnard Hunter (2001):0,40,51B1C10,5B21 C20,5B31 C3graph satisfies condition stated Theorem 1. set well-defended arguments{C1 , C2 , C3 } (so, well-defended). Nevertheless, {C1 , C2 , C3 , A} preferredextension.Second case: second case concerns generic local valuation:Theorem 2 Let <A, R> argumentation system finite relation R withoutcycles. Let semantics {preferred, stable}. Let v generic local valuationsatisfying following condition ():(i = 1 . . . n, g(xi ) xi ) (g(h(x1 , . . . , xn )) h(x1 , . . . , xn ))()A, (exi, uni, cleanly) accepted iff well-defended v.theorem direct consequence following lemma:Lemma 1 Let <A, R> argumentation system finite relation R without cycles.Let semantics {preferred, stable}. Let v generic local valuation satisfyingcondition ().(i) exi-accepted one direct attacker B B.(ii) B not-accepted B one direct attacker C C B.Remark: condition () stated Theorem 2 is:false local valuation proposed Besnard Hunter (2001) shownfollowing graph:0,40,51know g(x) =11+xB1C10,5B20,5B31 C21 C3h(x1 , . . . , xn ) = ni=1 xi(see Property 6). get:= 1 . . . 3, xi = v(Bi ) = 0.5,= 1 . . . 3, g(xi ) = 0.66, g(xi ) xi ,nevertheless g(h(x1 , x2 , x3 )) = v(A) = 0.4 6 h(x1 , x2 , x3 ) = 1.5.280fiGraduality argumentationfalse local valuations defined h n > 1 h(x1 , . . . , xn ) >max(x1 , . . . , xn ) (for functions g strictly non-increasing): see previous graphh(x1 , x2 , x3 ) = 1.5 max(x1 , x2 , x3 ) = 0.5.true local valuations defined h = max (for functions g): h = maxg(h(x1 , . . . , xn )) = g(max(x1 , . . . , xn )) = g(xj ), xj maximum xi ;and, assumption, g(xi ) xi , xi , particular xj ; so, get:g(h(x1 , . . . , xn )) = g(xj ) xj = max(x1 , . . . , xn ) = h(x1 , . . . , xn ).5. Conclusionpaper, introduced graduality two main related issues argumentationsystems:valuation arguments,acceptability arguments.Regarding first issue, defined two formalisms introducing interaction-basedgradual valuation arguments.First, generic gradual valuation covers existing proposals (for example Besnard& Hunter, 2001 Jakobovits & Vermeir, 1999). approach essentially localsince computes value argument value direct attackers.Then, approach based labelling takes form pair tuples;labelling memorises structure graph representing interactions (theattack graph), associating branch length (number edgesleaf current node) attack graph (if length branch eveninteger, branch defence branch current node, otherwise branchattack branch current node). approach said global sincecomputes value argument using whole attack graph influencingargument.shown valuations induces preordering set arguments, brought light main differences two approaches.Regarding second issue, two distinct approaches proposed:First, context collective acceptability Dung (1995): three levelsacceptability (uni-accepted, exi-accepted, not-accepted) already defined.graduality introduced collective acceptability using notion cleanlyaccepted arguments (those whose direct attackers not-accepted).Then, context individual acceptability: using previously defined gradualvaluations, new notion well-defended arguments introduced (thosepreferred direct attackers sense given gradual valuationv).first concept induces refinement level exi-accepted two sublevels (cleanlyaccepted arguments only-exi-accepted arguments). gradual valuation allows graduality inside level collective acceptability.281fiCayrol, Lagasquie-Schiexsecond concept induces two new levels acceptability (well-defended argumentsnot-well-defended arguments). gradual valuation also allows graduality insidelevel individual acceptability.Regarding initial purpose introducing graduality definition acceptability,adopted basic principle:acceptability strongly related interactions arguments (representedgraph interactions),argument acceptable preferred direct attackers.Then, followed two different directions. One based refinement existingpartition remains framework Dungs work. one basedoriginal concept well-defended, deserves investigation, particularcomputational point view.AcknowledgementsThanks reviewers interesting constructive comments.Thanks Thomas Schiex help.Appendix A. proofssection, give proofs properties presented Sections 3 4.Proof(of Property 1) induction VMin g(VMax ) < VMax applyingfunction g twice.Proof(of Property 2) valuation function v associates argumentvalue v(A) belonging set V subset completely ordered setW.Proof(of Property 3) Let C = An1 . . . A2 A1 cycle:n even: n = 2k v(A1 ) = g(v(A2 )) = . . . = g 2k1 (v(A2k )) =g 2k (v(A1 )); so, v(A1 ) fixpoint g 2k = g n . Ai ,1 2k.However, Ai may different values: example, n = 2,valuation Jakobovits Vermeir (1999), v(A1 ) = + v(A2 ) =g(+) = g() = +. Ai value,value fixpoint g (because v(A1 ) = g(v(A2 )) = g(v(A1 ))).282fiGraduality argumentationn odd: n = 2k + 1 v(A1 ) = g(v(A2 )) = . . . = g 2k (v(A2k+1 )) =g 2k+1 (v(A1 )); so, v(A1 ) fixpoint g 2k+1 = g n .Ai , 1 2k + 1.Since function g non-increasing, function g 2k+1 also nonincreasing apply following result: non-increasing function fixpoints, fixpoints identical30 . So, v(A1 ) = . . . =v(A2k+1 ). But, v(A1 ) = g(v(A2 )) = g(v(A1 )), v(A1 ) fixpoint g.So, 1 2k + 1, v(Ai ) fixpoint g.Proof(of Property 4)P1 satisfied because: A, direct attacker (R (A) empty),v(A) = VMax g(VMax ) < VMax .P2 satisfied R (A) = {A1 , . . . , }, h(v(A1 ), . . . , v(An )) evaluatesdirect attack A.P3 satisfied function g supposed non-increasing.P4 satisfied due properties function h.Proof(of Property 5) valuation proposed Jakobovits Vermeir (1999)following:Let <A, R> argumentation system. complete labelling <A, R>function Et : {+, ?, } that:1. Et(A) {?, } B R (A) Et(B) {+, ?}2. Et(A) {+, ?} B R (A) R+ (A), Et(B) {?, }Moreover, Jakobovits Vermeir (1999) also define complete rooted labellingEt with: A, Et(A) = B R (A) Et(B) = +.translation Et local gradual valuation easy:g defined g() = +, g(+) = , g(?) =? h function max.Proof(of Property 6) Besnard Hunter (2001) introduce following functionCat (in context deductive arguments acyclic graph):R (A) = , Cat(A) = 130. Proof: let g non-increasing function, let two fixpoints g. 6= , may suppose> , g() g() (since g non-increasing), (since fixpoints g),contradiction assumption > .283fiCayrol, Lagasquie-SchiexR (A) 6= R (A) = {A1 , . . . , }, Cat(A) =11+Cat(A1 )+...+Cat(An )translation Cat gradual valuation is: V = [0, 1], W = [0, [,1hVMin = 0 VMax = 1 g : W V defined g(x) = 1+xdefined h({x1 , . . . , xn }) = x1 + + xn .Proof(of Property 7) Let = (x1 , . . . , xn , . . .), t0 = (y1 , . . . , yn , . . .), t00 = (z1 , . . . , zn , . . .)tuples.Commutativity ?: ? t0 = t0 ? two cases:t0 = 0 , property given Definition 8.t0 6= 0 :? t0 = Sort(x1 , . . . , xn , . . . , y1 , . . . , yn , . . .)= Sort(y1 , . . . , yn , . . . , x1 , . . . , xn , . . .)= t0 ?Associativity ?: (t ? t0 ) ? t00 = ? (t0 ? t00 ) two cases:t0 t00 = 0 , simplify expression. example,= 0 :(t ? t0 ) ? t00 = t0 ? t00= ? (t0 ? t00 )t, t0 t00 6= 0 :(t ? t0 ) ? t00 = Sort(x1 , . . . , xn , . . . , y1 , . . . , yn , . . . , z1 , . . . , zn , . . .)= ? (t0 ? t00 )Property : (t k) k 0 = (k + k 0 ) have:(t k) k 0 = (x1 + k, . . . , xn + k, . . .) k 0= (x1 + k + k 0 , . . . , xn + k + k 0 , . . .)= (k + k 0 )Distributivity: (t ? t0 ) k = (t k) ? (t0 k) have:(t ? t0 ) k = Sort(x1 , . . . , xn , . . . , x01 , . . . , x0n , . . .) k= Sort(x1 + k, . . . , xn + k, . . . , x01 + k, . . . , x0n + k, . . .)= (t k) ? (t0 k)284fiGraduality argumentationProof(of Property 9) First, show relation defined Algorithm 1partial ordering:Let u, v, w three tupled values, relation defined Algorithm 1 is:reflexive: u u u = u, u u u u (case 1Algorithm 1);transitive: suppose u v v w considerpossible cases:u = v:v = w: u = w u w,|vi | |wi | |vp | > |wp |: |vi | = |ui | |wi ||vp | = |up | > |wp |, u w,|vi | < |wi | |vp | |wp |: |vi | = |ui | < |wi ||vp | = |up | |wp |, u w,|vi | = |wi | |vp | = |wp | vp lex wpvi lex wi : |vi | = |ui | = |wi | |vp | = |up | = |wp |vp = lex wp vi = ui lex wi , u w;|ui | |vi | |up | > |vp |:v = w: |ui | |vi | = |wi | |up | > |vp | = |wp |u w,|vi | |wi | |vp | > |wp |: |ui | |vi | |wi ||up | > |vp | > |wp |, u w,|vi | < |wi | |vp | |wp |: |ui | |vi | < |wi ||up | > |vp | |wp |, u w,|vi | = |wi | |vp | = |wp |: |ui | |vi | = |wi ||up | > |vp | = |wp |, u w;|ui | < |vi | |up | |vp |:v = w: |ui | < |vi | = |wi | |up | |vp | = |wp |u w,|vi | |wi | |vp | > |wp |: |ui | < |vi | |wi ||up | |vp | > |wp |, u w,|vi | < |wi | |vp | |wp |: |ui | < |vi | < |wi ||up | |vp | |wp |, u w,|vi | = |wi | |vp | = |wp |: |ui | < |vi | = |wi ||up | |vp | = |wp |, u w;|ui | = |vi | |up | = |vp | lex vp ui lexvi :v = w: |ui | = |vi | = |wi | |up | = |vp | = |wp |lex vp = wp ui lex vi = wi u w,|vi | |wi | |vp | > |wp |: |ui | = |vi | |wi ||up | = |vp | > |wp |, u w,285fiCayrol, Lagasquie-Schiex|vi | < |wi | |vp | |wp |: |ui | = |vi | < |wi ||up | = |vp | |wp |, u w,|vi | = |wi | |vp | = |wp | vp lex wpvi lex wi : |ui | = |vi | = |wi | |up | = |vp | = |wp |lex vp lex wp ui lex vi lex wi ,u w.cases, u w.Now, consider maximal minimal values:tupled value [0 , ()] unique maximal element preordering: let v tupled value v 6= [0 , ()], |vp | |vi | 0.Compare [0 , ()] v Algorithm 1: [0 , ()] 6= v case number1 used; then, |()| = 0 |vi | |0 | = |vp | twocases:|vp | = |vi | = 0, case 3 Algorithm 1 applied[0 , ()] v,else |vp | |vi | 0, case 5 Algorithm 1 applied[0 , ()] v.tupled value [(), 1 ] unique minimal element preordering: let v tupled value v 6= [(), 1 ], |vi | |vp | 0.Compare [(), 1 ] v Algorithm 1: [(), 1 ] 6= v case number1 used; then, |()| = 0 |vp | |1 | = |vi | twocases:|vi | = |vp | = 0, case 2 Algorithm 1 applied[(), 1 ] v,else |vi | |vp | 0, case 6 Algorithm 1 applied[(), 1 ] v.Proof(of Property 10) principle P10 satisfied Definition 10fact [0 , ()] unique maximal element v(A) (see Property 9).principle P20 satisfied Definition 10.principles P30 P40 satisfied: possible cases improvement/degradation defence/attack given argument (see Definition 16)applied case case31 . case leads new argument. Using Algorithm 1, comparison argument applicationcase shows principle P30 (or P40 , depending applied case)31. work case case order avoid complex cases several simultaneous simplemodifications. example, modification length branch changes statusbranch (an even integer replaced odd integer) complex case corresponding two simple cases:removal branch given status, addition new branch different status.286fiGraduality argumentationsatisfied.Proof(of Property 11) Definition 10.Proof(of Property 12) First, consider case preferred extensions: LetE preferred extension A, assume E containunattacked arguments A. So, let unattacked argument6 E.Consider E {A}:E {A} conflict-free then, unattacked argument Epreferred extension, E {A} collectively defends itself, E {A}admissible E E {A}. contradicts fact E preferredextension.E {A} contains least one conflict, then:B E BRA. impossible since unattacked.B E ARB. But, since unattacked, @C ECRA. So, E collectively defend B,contradiction fact E preferred extension.So, assumption E contain unattacked argumentscannot hold.Now, consider stable extensions: Let E stable extension A, assumeE contain unattacked arguments A. So, letunattacked argument 6 E.Since 6 E exists E another argument B attacks A;impossible since unattacked.So, assumption E contain unattacked argumentscannot hold.Proof(of Property 13) argument one direct attackers cannot belongextension sense Dung (1995) extension mustconflict-free. So, since uni-accepted, means belongsextensions, none direct attackers belongs extensions.converse, use following counterexample case preferredsemantics:287fiCayrol, Lagasquie-SchiexFKCBHJEGtwo preferred extensions{K, H, G} {A, E, K, H}. argument cleanly-accepted (BC belong preferred extension, belongs least onetwo extensions). But,uni-accepted belongpreferred extensions.Proof(of Property 14) First, uni-accepted cleanly-accepted resultProperty 13.Conversely, let cleanly-accepted argument, exists least one stable extension E E B, BRA, B 6 E 0 , E 0 stable extension.Using reductio ad absurdum, assume exists stable extensionE 00 6 E 00 ; but, 6 E 00 , means B E 00 BRA,so, direct attacker B belongs stable extension; so, contradiction assumption (A cleanly-accepted); so, E 00 existuni-accepted.Proof(of Theorem 1)1. consider arguments B B 6= A. Let Xi leaf,path C C(Xi , A) Xi1 . . . Xili Xi1 = Xi li denotinglength path (if li even, path defence branch A, elseattack branch).constraints Xi1 Xili following:Xi1 Xi3 . . . Xili Xili 1 . . . Xi4 Xi2 li odd 1Xi1 Xi3 . . . Xili 1 Xili . . . Xi4 Xi2 li even 2So, path Xi1 . . . Xili , set well-defended arguments{Xi1 , Xi3 , . . . , Xili } li odd, {Xi1 , Xi3 , . . . , Xili 1 } otherwise (thisset arguments value strictly betterdirect attackers). set denoted Accepi .definition, set conflict-free, defends elements (becausecontains leaf path arguments defendedleaf) attacks arguments path. try288fiGraduality argumentationinclude another argument path X {Xi1 , . . . , Xili }\ Accepi ,obtain conflict (because arguments path attackedelements Accepi ). So, {Xi1 , . . . , Xili }, Accepipreferred stable extension.Consider A0 = \ {A}, R0 restriction R A032Union Accep= Accepi , Union Accep preferredstable extension <A0 , R0 >.So, B A, B 6= A, B accepted iff B well-defended.2. Now, consider A. accepted Union Accep {A}preferred stable extension <A, R>. So, i, Xili belongextension. Then, i, Xili 1 Xili . Therefore, branch leadingdefence branch A. So, i, v(Xili ) = [()(li 1)]. So, v(A) =[(l1 , l2 , . . . , ln )()]. Then, i, v(A) v(Xili ). Therefore, well-defended.Using following example, show converse false:[(2,2)(3)]A1[()(1)]B1C1[(0...0)()][()(1)]B2[()(1)]C2[(0...0)()][(2)()]B3C3[(0...0)()]well-defended (A B1 , B2 incomparable A1 )accepted.3. Now, well-defended branches leading defencebranches A, Union Accep {A} conflict-free defendeddirect attackers (because Xili 1 Union Accepbranch i). So, Union Accep {A} preferred stable extension<A, R> accepted.Proof(of Lemma 1) Let <A, R> argumentation system finite relationR without cycles (so, one non empty preferred stable extensiondenoted E). know that:exi-accepted direct attacker denoted B Bnot-accepted,32. R0 restriction R A0 R0 = {(a, b)|aRb, A0 , b A0 }.289fiCayrol, Lagasquie-SchiexB not-accepted exists least one argument CCRB C exi-accepted (because B belong E Estable, C must E). So, fortiori, B not-acceptedone direct attacker C, C exi-accepted.proof done induction depth proof tree C.Basic case (i): exi-accepted one direct attacker B (BRA)C1 . . . Cn direct attackers B; so, proof tree whosedepth 2 one unattacked Ci , example C1 ; so:v(B) = g(h(v(C1 ), . . . , v(Cn )))g(v(C1 ))h(v(C1 ), . . . , v(Cn )) h(v(C1 )) = v(C1 )g non-increasingg(VMax )v(C1 ) = VMaxso:v(A) = g(v(B))g 2 (VMax )But, Property 1 says g 2 (VMax ) g(VMax ), v(A) v(B).Basic case (ii): CRB C direct attacker B; so,proof tree whose depth 0 C, i.e. C unattacked; so, v(C) = VMaxv(B) = g(VMax ) v(C) (following Definition 6).General case (i): exi-accepted one direct attacker B(BRA) C1 . . . Cn direct attackers B, one Ci exiaccepted, example C1 ; consider subgraph leading C1add C1 RBRA, assume:g(v(C1 )) v(C1 ) (induction assumption issued (ii))So:v(B) = g(h(v(C1 ), . . . , v(Cn )))g(v(C1 ))v(C1 )reasons basic caseinduction assumptionh(v(C1 ), . . . , v(Cn ))property hnon-increasing g:v(A) = g(v(B))g(h(v(C1 ), . . . , v(Cn ))) = v(B)290fiGraduality argumentationGeneral case (ii): B not-accepted, C exi-accepted; assumeC several direct attackers D1 . . . Dp not-accepted(because C exi-accepted); consider subgraph leading Diadd Di RCRB assume:= 1 . . . p, g(v(Di )) v(Di ) (induction assumption issued (i))so:v(C) = g(h(v(D1 ), . . . , v(Dp )))h(v(D1 ), . . . , v(Dp ))application condition ()since induction assumptioncorresponds premise ()so:v(B) = g(v(C))g(h(v(D1 ), . . . , v(Dp ))) = v(C)Proof(of Theorem 2) Assume () true consider exiaccepted. Let Bi , = 1 . . . n, direct attackers A. Then, =1 . . . n, subgraph leading Bi completed Bi RA, applylemma obtain: g(v(Bi )) v(Bi ), = 1 . . . n. Thus, have:v(A) = g(h(v(B1 ), . . . , v(Bn )))h(v(B1 ), . . . , v(Bn ))v(Bi ), = 1 . . . napplying ()property hSo, well-defended.converse, let well-defended. Let B1 , . . . , Bn directattackers assume exi-accepted. Then, existsleast one direct attacker Bi Bi exi-accepted (becauseone preferred stable extension). apply (ii) lemmasubgraph leading Bi completed Bi RA obtain g(v(Bi )) v(Bi ).So, exists Bi direct attacker that:v(A) = g(h(v(B1 ), . . . , v(Bn )))g(v(Bi ))v(Bi )property h non-increasing gusing lemma291fiCayrol, Lagasquie-Schiexcontradiction well-defended. So, exi-accepted.Appendix B. Computation tupled valuespropose algorithm computing tupled values arbitrary graph (cyclicacyclic, cycles may isolated not). algorithm uses principle propagationvalues: argument evaluated values direct attackers known.must consider cycles meta-arguments evaluated directattackers cycle (i.e. direct attackers one elements cyclebelong cycle) evaluated.beginning process follows: consider argumentsinitial value [0 , ()], leaves graph marked finalvalues. Thus, following partition graph G:Gv : part graph already evaluated (at beginning, part containsleaves graph),Gv : part graph evaluated (at beginning, part containsarguments graph G except leaves).algorithm also relies special data structure denoted L giving listcycles graph main characteristics:list arguments belong cycle,list arguments belong cycle direct attackers outsidecycle (these arguments called inputs cycle; usedorder propagate values across cycle case non isolated cycle);list empty case isolated cycle.Remark: sake efficiency, interconnected cycles (see Definition 1)considered whole algorithm used like meta-cycle. example,two cycles B B C B direct attacker outsidecycles, described data structure L one meta-cyclefollowing lists:A, B, C,nothing (because isolated meta-cycle).order avoid ambiguity, meta-cycles defined mcycles:Definition 21 (mcycle) Let G attack graph. Let CC set cyclesG. Let CC 0 CC CC 0 = {C1 , . . . , Cn } set cycles.Let ACC 0 set: {Aj Ci CC 0 Aj Ci }.CC 0 satisfies following properties:Aj , Ak ACC 0 , path Aj Ak element (arguments edgesarguments) path belongs cycles CC 0 ,Ck CC \ CC 0 , 6 Ci CC 0 Ck interconnected Ci .292fiGraduality argumentationunion Ci belonging CC 0 mcycle.Thus, make partition CC using notion interconnection cycles,element partition different mcycle. See following example:JCBEFGKLgraph, 6 cycles:{J},{I, J, K},{K, L},{B, C, D},{C, E},{F, G}.3 mcycles:{I, J, K, L},{B, C, D, E},{F, G}.Algorithm 2 main algorithm used computing tupled values.function Add-Node (respectively Remove-Node) whose parameters subgraphGx attack graph node s, adds (resp. removes) (resp. of) Gx .functions described (Cayrol & Lagasquie-Schiex, 2003a).Algorithm 2 applied example step rewriting (see Figure 1). Noteorder make understanding results easier, created newarguments (as Definitions 11 12), course, would necessary rigorousformalization.293fiCayrol, Lagasquie-SchiexAlgorithm 2: Algorithm computing tupled values% Description parameters:%G: attack graph (partitioned Gv Gv )%L: data structure describing mcycles%n: number propagation steps mcycles% Used variables:%A: current argument (to evaluated)%C: current mcycle (to evaluated) (containing A)%LAD: list direct attackers C%Bi : current direct attackers A, Cbeginleast one argument Gv2= Choose-Argument(Gv )3belong mcycle C described L4Bi R (A), Bi already evaluated5Gv = Add-Node(Gv ,Evaluate-Node(A, R (A), 1))%%%%%%%%%1Gv = Remove-Node(Gv , A)6789101112131415% value% value% direct attackers% add 1% see Definition 10elseC isolatedGv = Add-Mcycle(Gv ,Evaluate-Mcycle-Isolated(G, C, n))Gv = Remove-Mcycle(Gv , C)elseLAD = Find-Direct-Attackers-Mcycle(C, G)Bi LAD, Bi already evaluatedGv = Add-Mcycle(Gv ,Evaluate-Mcycle-Not-Isolated(G, C, LAD,n))Gv = Remove-Mcycle(Gv , C)return Gend16294%%%%%fiGraduality argumentationCBEGFprevious argumentation graph rewritten follows:BBBCCCBBBBECCECCCBBBCCBCBBCBBECCCCCBBB........BC........EGFresults valuation obtained one propagation step are:v(A) = [(0, . . . , 0)()],v(B) = [(6, 8, 8, . . .)(1, 3, 5, . . .)],v(C) = [(2, 4, 6, . . .)(5, . . .)],v(D) = [(6, . . .)(3, 5, . . .)],v(E) = [(4, 6, . . .)()],v(F ) = [(8, . . .)(3, 5, 5, 7, 7, . . .)],v(G) = [(2, 4, 6, . . .)(7, . . .)],Figure 1: Example rewriting295fiCayrol, Lagasquie-SchiexReferencesAmgoud, L., & Cayrol, C. (1998). acceptability arguments preference-basedargumentation. Cooper, G. F., & Moral, S. (Eds.), Proc. 14th UncertaintyArtificial Intelligence, pp. 17, Madison, Wisconsin. Morgan-Kaufmann.Amgoud, L., & Cayrol, C. (2002). Inferring inconsistency preference-based argumentation frameworks. Journal Automated Reasoning, 29, 125169.Bench-Capon, T. J. (2002). Value based argumentation frameworks. Benferhat, &Giunchiglia (Eds.), Proc. 9th International Workshop Nonmonotonic Reasoning (session Argument, Dialogue Decision), pp. 444453, Toulouse, France.Besnard, P., & Hunter, A. (2001). logic-based theory deductive arguments. ArtificialIntelligence, 128 (1-2), 203235.Cayrol, C., & Lagasquie-Schiex, M.-C. (2003a). Critique et amelioration de levaluationgraduelle par tuples pour le traitement des circuits. Rapport de recherche 2003-13-R,Institut de Recherche en Informatique de Toulouse (I.R.I.T.), France.Cayrol, C., & Lagasquie-Schiex, M.-C. (2003b). Gradual acceptability argumentationsystems. Proc. 3rd CMNA (International workshop computational modelsnatural argument), pp. 5558, Acapulco, Mexique.Cayrol, C., & Lagasquie-Schiex, M.-C. (2003c). Gradual handling contradiction argumentation frameworks. Bouchon-Meunier, B., L.Foulloy, & Yager, R. (Eds.),Intelligent Systems Information Processing: representation Applications,chap. Reasoning, pp. 179190. Elsevier.Doutre, S. (2002). Autour de la semantique preferee des systemes dargumentation. These,Universite Paul Sabatier, IRIT.Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person games. Artificial Intelligence,77, 321357.Dunne, P. E., & Bench-Capon, T. J. (2001). Coherence finite argument systems. Technicalreport 01-006, University Liverpool, Department Computer Science (U.L.C.S.).Dunne, P. E., & Bench-Capon, T. J. (2002). Coherence finite argument system. ArtificialIntelligence, 141 (1-2), 187203.Elvang-Goransson, M., Fox, J., & Krause, P. (1993). Dialectic reasoning inconsistentinformation. Heckerman, D., & Mamdani, A. (Eds.), Proc. 9th UAI, pp.114121, Washington, DC. Morgan-Kaufmann.Jakobovits, H., & Vermeir, D. (1999). Robust semantics argumentation frameworks.Journal logic computation, 9(2), 215261.Karacapilidis, N., & Papadias, D. (2001). Computer supported argumentation collaborative decision making: hermes system. Information systems, 26 (4), 259277.Kohlas, J., Haenni, R., & Berzati, D. (2000). Probabilistic argumentation systemsabduction. Proc. 8th International Workshop Non-Monotonic Reasoning- special session Uncertainty Frameworks Non-Monotonic Reasoning, pp. 391398, Breckenridge, Colorado.296fiGraduality argumentationKrause, P., Ambler, S., Elvang, M., & Fox, J. (1995). logic argumentation reasoninguncertainty. Computational Intelligence, 11 (1), 113131.Lin, F., & Shoham, Y. (1989). Argument systems - uniform basis non-monotonicreasoning. Proc. first International Conference Principles KnowledgeRepresentation Reasoning (KR), pp. 245255.Parsons, S. (1997). Normative argumentation qualitative probability. Proc.first International Joint Conference Qualitative quantitative practical reasoning, ECSQARU-FAPR, LNAI 1244, pp. 466480, Germany.Pinkas, G., & Loui, R. P. (1992). Reasoning inconsistency: taxonomy principlesresolving conflict. Allen, J., Fikes, R., & Sandewall, E. (Eds.), Proc. 3rdKR, pp. 709719, Cambridge, MA. Morgan-Kaufmann.Pollock, J. L. (1992). reason defeasibly. Artificial Intelligence, 57, 142.Pollock, J. L. (2001). Defeasible reasoning variable degrees justification. ArtificialIntelligence, 133, 233282.Prakken, H., & Sartor, G. (1997). Argument-based extended logic programming defeasible priorities. Journal Applied Non-Classical Logics, 7, 2575.Simari, G., & Loui, R. (1992). mathematical treatment defeasible reasoningimplementation. Artificial Intelligence, 53, 125157.Verheij, B. (2002). existence multiplicity extension dialectical argumentation. Benferhat, S., & Giunchiglia, E. (Eds.), Proceedings 9th InternationalWorkshop Non-Monotonic Reasoning (NMR2002), pp. 416425.Vreeswijk, G. (1997). Abstract argumentation systems. Artificial Intelligence, 90, 225279.Xuong, N. (1992). Mathematiques discretes et informatique. Masson.297fiJournal Artificial Intelligence Research 23 (2005) 533-585Submitted 4/04; published 5/05Using Memory Transform Search Planning GraphTerry ZimmermanWIZIM@CS.CMU.EDURobotics Institute, Carnegie Mellon UniversityPittsburgh, PA 15213-3890Subbarao KambhampatiRAO@ASU.EDUDepartment Computer Science & EngineeringArizona State University, Tempe AZ 85287-5406AbstractGraphplan algorithm generating optimal make-span plans containing parallel sets actions remains one effective ways generate plans. However, despite enhancements range fronts, approach currently dominated terms speed, state spaceplanners employ distance-based heuristics quickly generate serial plans. report family strategies employ available memory construct search trace learn variousaspects Graphplans iterative search episodes order expedite search subsequent episodes.planning approaches partitioned two classes according type extentsearch experience captured trace. planners using aggressive tracing methodable avoid much Graphplans redundant search effort, planners second class tradeaspect favor much higher degree freedom Graphplan traversing spacestates generated regression search planning graph. tactic favored second approach, exploiting search trace transform depth-first, IDA* nature Graphplanssearch iterative state space view, shown powerful. demonstratedistance-based, state space heuristics adapted informed traversal search trace usedsecond class planners develop augmentation targeted specifically planning graphsearch. Guided heuristic, step-optimal version planner class clearlydominates even highly enhanced version Graphplan. adopting beam search searchtrace show virtually optimal parallel plans generated speeds quite competitivemodern heuristic state space planner.1. IntroductionGraphplan introduced 1995 (Blum & Furst, 1995) became one fastest programssolving benchmark planning problems time and, accounts, constituted radically different approach automated planning. Despite recent dominance heuristic state-searchplanners Graphplan-style planners, Graphplan approach still one effective waysgenerate so-called optimal parallel plans. State-space planners drowned exponentialbranching factors search space parallel plans (the exponential branching result factplanner needs consider subset non-interfering actions). 8 years sinceintroduction, Graphplan system enhanced numerous fronts, ranging planninggraph construction efficiencies reduce size build time one orders magnitude (Smith & Weld, 1998; Long & Fox, 1999), search speedup techniques variablevalue ordering, dependency-directed backtracking, explanation based learning (Kambhampati,2000). spite advances, Graphplan ceded lead planning speed variety heuristic-guided planners (Bonet & Geffner, 1999; Nguyen & Kambhampati, 2000; Gerevini & Serina,2002). Notably, several exploit planning graph powerful state-space heuristics,2005 AI Access Foundation. rights reserved.fiZIMMERMAN & KAMBHAMPATIeschewing search graph itself. Nonetheless, Graphplan approach remains perhaps fastest parallel planning mainly way combines iterative deepening A* (IDA*,Korf, 1985) search style highly efficient CSP-based incremental generation applicable actionsubsets.investigate use available memory surmount Graphplans majordrawbacks, redundant search effort need exhaustively search k-length planninggraph proceeding k+1 length graph. time wish retain attractive features Graphplans IDA* search rapid generation parallel action steps abilityfind step optimal plans. approach describe remains rooted iterative search planninggraph greatly expedites search building maintaining concise search trace.Graphplan alternates two phases; one data structure called planning graphincrementally extended, backward phase planning graph searched extractvalid plan. first regression search phase space explored given episode closelycorrelated conducted preceding episode. strategy pursue work employ appropriately designed trace search conducted episode n (which failed find solution) identify avoid aspects search provably unchanged episode n+1,focus effort features may evolved. identified precisely features dynamic across Graphplan search episodes construct search traces capture exploit features different degrees. Depending design search trace may provide benefits 1)avoidance much Graphplans redundant search effort, 2) learning iterative search experience improve heuristics constraints embodied planning graph, 3)realizing much higher degree freedom Graphplan, traversing space states generated regression search process. show third advantage particularly keysearch trace effectiveness, allows planner focus attention promising areassearch space.issue much memory right amount use boost algorithms performancecuts across range computational approaches search paging process operating systems, Internet browsing database processing operations. investigation explore several alternative search trace based methods differ markedly terms memory demands.describe four approaches paper. Figure 1 depicts pedigree family searchtrace-based planners, well primary impetus leading evolution systempredecessor. figure also suggests relative degree planner steps awayoriginal IDA* search process underlying Graphplan. two tracks correspond two genressearch trace developed;left track: EGBG planners (Explanation Guided Backward search Graphplan) employcomprehensive search trace focused minimizing redundant search.right track: PEGG planners (Pilot Explanation Guided Graphplan) use skeletaltrace, incurring Graphplans redundant search effort exchange reduced memorydemands increased ability exploit state space view search space.EGBG planner (Zimmerman & Kambhampati, 1999) adopts memory intensive structuresearch trace seeks primarily minimize redundant consistency-checking across Graphplanssearch iterations. proves effective range smaller problems memory constraints534fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHXYSearchTraceExploiting GraphplanSymmetry & RedundancyExploitingstate space viewEGBGLeveraging CSP & memory efficiencyso-PEGGme-EGBGTrading step-optimalityspeedup episodesPEGGFigure 1: Applying available memory step away Graphplan search process;family search trace-based plannersimpede ability scale up. Noting Graphplans search process viewed specializedform CSP search (Kambhampati, 2000), explore middle ground terms memory usage augmenting EGBG several methods known effective speedup techniques CSPproblems.primary interest techniques, however, impact memory reduction describe accomplish beyond search speedup benefit afford. implemented planner, me-EGBG, markedly outperforms EGBG speed capabilities, varietyproblems still lie beyond planners reach due memory constraints.search trace structure used PEGG track planners trades minimization redundantsearch exchange much smaller memory footprint. addition greatly reduced memorydemands, PEGG search trace structure exploited intrinsic state space viewessentially Graphplans CSP-oriented search space. significant speedup advantage approachGraphplan EGBG track planners derives ability employ distance-basedheuristics power many current generation state-space planners (Bonet & Geffner, 1999;Nguyen & Kambhampati, 2000; Hoffman, 2001). adapt heuristics task identifyingpromising states visit search trace implement approach first so-PEGGplanner (step-optimal PEGG, Zimmerman & Kambhampati, 2003). So-PEGG outperforms evenhighly enhanced version Graphplan two orders magnitude terms speed,maintaining guarantee finding step-optimal plan.Finally explore adoption beam search approach visiting state space implicitPEGG-style trace. employ distance-based heuristics extracted planning graphitself, direct order search trace states visited, also prune restrictspace heuristically best set states, according user-specified metric. showplanning graph leveraged provide measure likelihood previously generated regression state might spawn new search branches higher planning graph level.535fiZIMMERMAN & KAMBHAMPATIterm metric flux employ effective filter states skipped eventhough might appear promising based distance-based heuristic. Implemented PEGGsystem (Zimmerman & Kambhampati, 2003), approach exploiting search trace producestwo-fold benefit previous approaches; 1) reduction search trace memory demands2) effective release Graphplans exhaustive search planning graph search episodes. PEGG exhibits speedups ranging 300x enhanced version Graphplanquite competitive recent state space planner using similar heuristics. adopting beamsearch PEGG necessarily sacrifices guarantee step-optimality empirical evidence indicatessecondary heuristics remarkably effective ensuring make-span solutions producedvirtually optimal.fact systems successfully employ search trace noteworthy. general,tactic adopting search trace algorithms explicitly generate node-states iterativesearch episodes, found infeasible due memory demands exponentialdepth solution. Sections 2 3 describe tight integration search traceplanning graph permits EGBG PEGG planners largely circumvent issue.planning graph structure costly construct, terms memory time;well-known problems even domains problematic planners employ it. (PostGraphplan planners employ planning graph purpose include STAN, Long & Fox,1999, Blackbox, Kautz & Selman, 1999, IPP, Koehler et al., 1997, AltAlt, Nguyen & Kambhampati, 2000, LPG Gerevini & Serina, 2002). planning systems described sharememory overhead course, interestingly, found search trace memory demandsPEGG class planners significantly limited range problems solve.remainder paper organized follows: Section 2 provides brief overviewplanning graph Graphplans search process. discussion CSP nature manner process viewed IDA* search motivates potential employing available memory accelerate solution extraction. Section 3 addresses two primary challenges attempting build use search trace advantage Graphplan: 1) done withinreasonable memory constraints given Graphplans CSP-style search planning graph? and, 2)trace available, effectively used? section briefly describes EGBG(Zimmerman & Kambhampati, 1999), first system use search trace guide Graphplanssearch, outlines limitations method (Details algorithm contained AppendixA.) Section 4 summarizes investigations variety memory reduction techniques reports impact combination six performance EGBG. PEGG plannersdiscussed Section 5 performance so-PEGG PEGG (using beam search) compared enhanced version Graphplan, EGBG, modern, serial state-space planner. Section6 contains discussion findings Section 7 compares work related research. Finally,Section 8 wraps conclusions.2. Background & Motivation: Planning Graphs Nature DirectGraph Searchoutline Graphplan algorithm discuss traits suggesting judicious use additionalmemory might greatly improve performance. touch three related views Graphplanssearch; 1) form CSP, 2) IDA* search and, 3) state space aspect.536fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHActionsLevel 1InitialStateWPlanning GraphPropositionsPropositionsActionsLevel 1Level 2Level 2nopnop~WWnopa1ActionsLevel 3~Wnop~WWnopWa1a1nop~YnopnopnopX~YZHa2nopa3a3nopHnopnop~YnopHPropositionsLevel 3a3a4a5a5nopJa5JnopJDomain Actionsa1IHWHJa2Xaction descriptions:a3~WIJa4Za5J ~Yaction-ID [effects][preconditions]Figure 2: Planning graph representation three levels Alpha domain2.1 Construction Search Planning GraphGraphplan algorithm employs two interleaved phases forward phase, data structurecalled planning graph incrementally extended, backward phase planning graphsearched extract valid plan. planning graph consists two alternating structures, calledproposition lists action lists. bottom Figure 2 depicted simple domain referAlpha domain use illustration study. figure shows four action proposition levels planning graph engendered simple initial state given domain. startinitial state zeroth level proposition list. Given k-level planning graph, extensiongraph structure level k+1 involves introducing actions whose preconditions presentkth level proposition list. addition actions domain model, operation actionsintroduced, one condition kth level proposition list (abbreviated nop papersfigures, also termed persists others). nop-C action C precondition Ceffect. Given kth level actions, proposition list level k+1 constructed unioneffects introduced actions. planning graph maintains dependency links537fiZIMMERMAN & KAMBHAMPATIactions level k+1, preconditions level k proposition list, effects levelk+1 proposition list.planning graph construction binary "mutex'' constraints computed propagated.Figure 2, arcs denote mutex relations pairs propositions pairs actions.propagation starts level 1 labeling mutex pairs actions statically interfering(static mutex), preconditions effects logically inconsistent. Mutexespropagated level forward using two simple propagation rules. Two propositionslevel k marked mutex actions level k support one proposition mutex actions support second proposition. Two actions level 2 mutex staticallyinterfering precondition first action mutually exclusive precondition second . (We term latter dynamic mutex, since constraint may relax higher planning graphlevel).1 propositions also either static mutex (one negates other) dynamic mutex (all actions supporting one proposition mutex actions supporting other).reduce Figure 2 clutter mutex arcs propositions negations omitted.search phase k-level planning graph involves checking see sub-graphplanning graph corresponds valid solution problem. Figure 3 depicts Graphplan searchmanner similar CSP variable-value assignment process. Beginning propositionscorresponding goals level k, incrementally select set actions level k actionlist support goals, two actions selected supporting two different goalsmutually exclusive (if are, backtrack try change selection actions). essentially CSP problem goal propositions level variables, actions establishproposition values, mutex conditions constitute constraints. search proceedsdepth-first fashion: goals level supported, recursively call search process k-1 level planning graph, preconditions actions selected level kgoals k-1 level search. search succeeds reach level 0 (the initial state)solution extracted unwinding recursive goal assignment calls. process viewedsystem solving Dynamic CSPs (DCSP) (Mittal & Falkenhainer, 1990; Kambhampati 2000),wherein standard CSP formalism augmented concept variables appear(a.k.a. get activated) variables assigned.interleaved planning graph extension search phases, graph may extendedstasis condition, changes occur actions, propositions, mutex conditions.sufficient condition defining level-off level new actions introducedexisting mutex conditions propositions go away. refer planning graph levelslevel-off static levels. Note although graph becomes static point, findingsolution may require many episodes composed adding identical static levels conductingregression search problem goals.Like many fielded CSP solvers, Graphplan's search process benefits simple form nogood learning. set (sub)goals level k determined unsolvable, memoized level hash table. Subsequently, backward search process later enters level kset subgoals first checked hash table, match found search1static mutex condition also called eternal mutex dynamic mutex termed conditional mutex (Smith& Weld, 1998).538fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHJ nopa3a5WJa5a5Ja3YJa3WZ nopJJa4nopnopH nopa1a5Ja3nopJnopa2Xa3nopLevel 1a1XYH Ja5Wa4Ha1 nopa5nopnopa1nopJa1nopa3Z nopWXYZH nopa1nop Ja5nopnopWYHIJInitial Statea5Goal Statenopa1a2a3a3nopHa1a5Level 2Level 3YHIIcon explanation:Action a5 assigned giveAssigned actionAssigned actionJgoal Jstatic mutexdynamic mutexa5previous assigned actionprevious assigned actiona1Goal already satisfiedSet regressed subgoalspreviously assigned action a1satisfied next lower levelFigure 3: CSP-style trace Graphplans regression search Figure 2 planning graphprocess backtracks. constitutes one three conditions backtracking: two others ariseattempts assign static mutex actions dynamic mutex actions (See Figure 3 legend).next discuss Graphplans search higher-level view abstracts away CSP nature.2.2 Graphplan State Space Searchabstract perspective, Graphplan viewed conducting regression state spacesearch problem goals initial state. view, states generated expanded subgoals result CSP process given set subgoals finds consistentset actions satisfying subgoals planning graph level (c.f. Kambhampati & Sanchez,2000). view state-generator function effectively Graphplans CSP-style goal assignment routine seeks non-mutex set actions given set subgoals within given planninggraph level. view depicted Figure 4, top graph casts CSP-style search trace539fiZIMMERMAN & KAMBHAMPATI1InitStateW2Proposition Levels62 valid sets actionassignments satisfygoals WXYZ level 7J a112InitStateW7Wa2 a4HGoalWXZH a1, a246Proposition LevelsS11S6S5S9S87S4WHS7S10S18S128S14S13S15JGoalWXZS19S17S16HS20S21123S23S24S22W8S8S27S25S7WHS14S13S26S15JHS29S19S179S5S11S127S4S10S18S30S6S9S28InitStateProposition LevelsS16S21GoalWXZS20Figure 4: Graphplans regression search space: Three consecutive search episodesFigure 3 high-level state-space search trace. terms box depict set (positive)subgoals result action assignment process goals higher-level statebox linked.2Recognizing state-space aspect Graphplans search helps understanding connectionIDA* search. First noted briefly discussed (Bonet & Geffner, 1999), highlight expandupon relationship here. three correspondences algorithms:1. Graphplans episodic search process nodes generated previous episode regenerated new episode (and possibly new nodes), corresponds IDA*s iterativesearch. Graphplan nodes states (sets subgoals) result regres2Figure 4 facilitates discussion search trace next section, conjuring hypothetical problemfirst search episode begins level 7 planning graph instead level 3, Figure 3.540fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHsion search given plan graph level succeeds. perspective node-generatorfunction effectively Graphplans CSP-style goal assignment routine seeks non-mutexset actions given set propositions within given planning graph level.2. state space view Graphplans search (ala Figure 4), within given search episode/iteration algorithm conducts search depth-first fashion IDA*. ensuresspace requirements linear depth solution node.3. upper bound iteratively deepened ala IDA* node-state heuristic f-value;f = g + h. context h distance terms associated planning graph levelsstate generated Graphplans regression search initial state3 g cost reachingstate goal state terms number CSP epochs (i.e. numerical difference highest graph level states level).purposes, perhaps important observation implicit f-value boundgiven iteration length planning graph associated iteration. is,node-state, associated planning graph level determines distance initial state (h)cost reach goal state (g), total must always equal length plan graph.heuristic clearly admissible; shorter distance goal Graphplanexhaustively searches shorter length planning graphs (any) previous iterations. heuristicimplicit Graphplan algorithm guarantees step-optimal solution returned. Noteperspective nodes visited given Graphplan search iteration implicitlyf-value: g + h = length planning graph. consider implications propertyaddress informed traversal Graphplans search space Section 5.primary shortcoming standard IDA* approach search regenerates manynodes iterations. long recognized IDA*s difficultiesproblem spaces traced using little memory (Russell, 1992; Sen & Bagchi, 1989).information carried one iteration next upper bound f-value. Graphplan partially addresses shortcoming memo caches store no-goods -states foundinconsistent successive episodes. However, IDA* nature search make inefficient planner problems goal propositions appear non-mutex planning graphmany levels valid plan actually extracted.second shortcoming IDA* nature Graphplans search node-states generatedgiven Graphplan episode f-value (i.e. length graph). such, withiniteration (search episode) discernible preference visiting one state another.next discuss use available memory target shortcomings Graphplans search.3. Efficient Use Search Trace Guide Planning Graph Searchsearch space Graphplan explores given search episode defined constrained threefactors: problem goals, plan graph associated episode, cache memoized nogood states created previous search episodes. Typical IDA* search considerable3Bonet & Geffner define hG (the Graphplan h-value) somewhat differently first level goalsstate appear non-mutex memoized. definition (which necessarily first levelSm goals appear non-mutex) produces informed admissible estimate cases.guarantees states generated Graphplan f-value equal planning graph length,property primary interest us.541fiZIMMERMAN & KAMBHAMPATIsimilarity (i.e. redundancy) search space successive episodes plan graph extended.fact, discussed below, backward search conducted level k+1 graph essentiallyreplay search conducted previous level k certain well-defined extensions.specifically, essentially every set subgoals generated backward search episode n, startinglevel k, regenerated Graphplan episode n+1 starting level k+1 (unless solutionfound first).4returning Figure 4 entirety, note depicts state space tree structure corresponding Graphplans search three consecutive iterations. top graph, discussed above, represents subgoal states generated course Graphplans first attempt satisfy WXYZgoal problem resembling running example. (It implied W,X,Y,Z propositionspresent planning graph level 7 first level pairmutex.) second search episode (the middle Figure 4 graph), states generated again,one level higher. addition, states expanded generate number children,shown darker shade. (Since Figure 4 hypothetical variation Alpha domain problemdetailed Figures 2 3, states created beyond first episode labeled state numbers representing order generated.) Finally, third episode, Graphplan regenerates states previous two episodes attempting satisfy WXYZ level 9, ultimately finds solution (the assigned actions associated figures double outlined subgoalsets) generating states shown darkest shading bottom graph Figure 4.Noting extent consecutive iterations Graphplans search overlap, investigateapplication additional memory store trace explored search tree. first implementedapproach, EGBG (which summarized following subsection), seeks leverage appropriately designed search trace avoid much inter-episode redundant search effort possible(Zimmerman & Kambhampati, 1999).3.1 Aggressive Use Memory Tracing Search: EGBG PlannerLike types CSP-based algorithms, Graphplan consumes computational effortgiven problem checking constraints. instrumented version planner reveals typically,60 - 90% cpu run-time spent creating checking action proposition mutexes -bothplanning graph construction search process. (Mutex relations incorporated planning graph primary constraints CSP view Graphplan, Kambhampati, 2000)such, obvious starting point seeking efficiency improvements plannerprimary tactic adopted EGBG. provide overview approach, referringinterested reader Appendix details.EGBG exploits four features planning graph Graphplans search process:4set actions establish given proposition level k+1 always supersetestablishing proposition level k.Strictly speaking, always case due impact Graphplans memoizing process. problemsparticular branch search tree generated search episode n rooted planning graph level k may revisitedepisode n+1 level k+1 due no-good proposition set memoized level k+1. However, memo merely actsavoid redundant search neglecting relatively rare cases serves simplify visualization symmetryacross Graphplans search episodes. .542fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHconstraints (mutexes) active level k monotonically decrease increasingplanning graph levels. is, mutex active level k may may continueactive level k+1 becomes inactive never gets re-activated future levels.Two actions level statically mutex (i.e. effects preconditions conflictother) mutex succeeding levels.problem goal set satisfied level k set searchedlevel k+1 planning graph extended. is, subgoal set present level ktwo propositions mutex, remain future levels.Given appropriate trace search conducted episode n (which failed find solution)would like ignore aspects search provably unchanged episode n+1, focus effort features may evolved. previous search failed extract solutionk-length planning graph, search k+1 length graph succeed onefollowing conditions holds:1. dynamic mutex condition pair actions whose concurrent assignmentattempted episode n longer holds episode n+1.2. subgoal generated regression search episode n planning graph levelk, action establishes episode n+1 first appears level k+1.3. episode n regression state (subgoal set) level k matched cached memolevel memo-match generated level k+1 episode n+1.(The discussion Appendix formalizes conditions.) instance oneconditions hold, complete policy must resume backward search search parameters associated instance previous episode, n. resumed partial search episodeseither find solution generate additional trace subgoal sets augment parent trace. specialized search trace used direct future backward search episodes problem,viewed explanation failure search process episode. hereafter useterms pilot explanation (PE) search trace interchangeably. following definitions useful describing search process:Search segment: essentially state, specifically set planning graph level-specific subgoalsgenerated regression search goal state (which first search segment).EGBG search segment Sn , generated planning graph level k contains:subgoal set propositions satisfiedpointer parent search segment (Sp ), (the state level k+1 gave rise Sn)list actions assigned Sp resulted subgoals Snpointer PE level (as defined below) associated Snsequential list results action consistency-checking process attempt satisfy Sns subgoals. possible trace results given consistency check are: static mutex,dynamic mutex, action consistent prior assigned actions. Trace resultsstored list bit vectors efficiency.search segment therefore represents state plus path information, often use searchsegment state interchangeably. such, boxes Figure 4 (whether state goalsexplicitly shown not) viewed search segments.543fiZIMMERMAN & KAMBHAMPATIPilot explanation (PE): search trace. consists entire linked set search segmentsrepresenting search space visited Graphplan backward search episode. convenientvisualize Figure 4: tiered structure separate caches segments associated searchplanning graph level. adopt convention numbering PE levels reverseorder plan graph: top PE level 0 (it contains single search segment whose goalsproblem goals) level number incremented move towards initial state.solution found, PE necessarily extend highest plan graph level initial state,shown third graph Figure 4.PE transposition: state first generated search episode n associated specificplanning graph level, say k. premise using search trace guide search episode n+1based idea re-associating PE search segment (state) generated (or updated) episode nnext higher planning graph level. is, define transposing PE as: searchsegment PE associated planning graph level k search episode n, associatelevel k+1 episode n+1.Given definitions, note states PE search episode n plan graphlevel k, loosely constitute minimal set 5 states visited backward search conducted episode n+1 level k+1. (This bound visualized sliding fixed tree searchsegments first graph Figure 4 one level.)3.2 Conducting Search EGBG Search TraceEGBG builds initial pilot explanation first regression search episode tracingsearch process augmented version Graphplans assign-goals routine. solutionpossible k-length planning graph, PE transposed one level, key features previous search replayed significant new search effort occurs points onethree conditions described holds. new search process PE augmented according search space visited.EGBG search algorithm exploits search trace essentially bi-modal fashion: alternatesinformed selection state search trace previous experience focused CSP-typesearch states subgoals. discussion EGBGs bi-modal algorithm revolves aroundsecond mode; minimizing redundant search effort state chosen visitation.describe PEGGs use search trace Section 5 see greater potentialdramatic efficiency increases lies first mode; selection promising statesearch trace.choosing state visit, EGBG uses trace previous episode focusaspects entailed search could possibly changed. search segment Siplanning graph level k+1, visitation 4step process:1. Perform memo check ensure subgoals Si valid level k+12. Replay previous episodes action assignment sequence subgoals Si, usingsegments ordered trace vectors. Mutex checking conducted pairs actionsdynamic mutex level k. actions longer dynamic mutex, add can5possible Graphplans memoizing process preclude states regenerated subsequent episode.See footnote 2 brief explanation conditions may occur.544fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHdidate action Sis list consistent assignments resume Graphplan-style search remaining goals. Si ,is augmented PE extended process. Whenever Sis goalssuccessfully assigned, entailing new set subgoals satisfied lower level k, childsearch segment created, linked Si , added PE.3. Si subgoal replay sequence, check also new actions appearing level k+1establish subgoal. New actions inconsistent previously assigned actionlogged Sis assignments. new actions conflict previously assigned, assign resume Graphplan-style search point step 2.4. Memoize Sis goals level k+1 solution found via search process steps 2 3.long segments PE visited manner, planner guaranteed findoptimal plan search episode Graphplan. Hereafter refer PE search segmentvisited extended via backward search find valid plan, seed segment. addition,segments part plan extracted PE call plan segments. Thus, thirdgraph Figure 4, S18 apparent seed segment plan segments (in bottom order) are;S30, S29, S18, S17, S16, S15, labeled segments YH, YHI, goal state WXYZ.principle freedom traverse search states encapsulated PE orderlonger restricted (non-informed) depth-first nature Graphplans search process.Unfortunately, EGBG incurs high overhead associated visiting search segments order bottom (in terms PE levels). ancestor state represented PEvisited state itself, EGBGs search process would regenerate statedescendents (unless first finds solution). non-trivial cost associated generatingassignment trace information EGBGs search segments; search advantage lies reusing trace data without regenerate it.hand, top-down visitation segments PE levels degenerate mode.search process essentially mimics Graphplans, since episode begins searchproblem goal set, (with exception replay top-level search segments assignments)regenerates states generated previous episode -plus possibly new states-regression search. search trace provides significant advantage top-down visitationpolicy.bottom-up policy, hand, intuitive appeal since lowest levels PE correspond portions search space lie closest initial state (in terms plan steps).state one lower levels fact extended solution, planner avoids searcheffort Graphplan would expend reaching state top-level problem goals.Adopting bottom-up visitation policy amounts layering secondary heuristic primaryIDA* heuristic, planning graph length iteratively deepened. Recalling Section 2.2 states PE f-value terms primary heuristic, essentially biasing favor states low h-values. Support policy comes workheuristic guided state-space planning (Bonet & Geffner, 1999; Nguyen & Kambhampati, 2000)weighting h factor 5 relative g component heuristic f-value generally improved performance. However, unlike state-space planning systems, primary heuristic, EGBG employs secondary heuristic guarantee step optimality545fiZIMMERMAN & KAMBHAMPATIStandard GraphplanSpeedup RatiosEGBGProblemTimeBktrksMutexChks79192.7x3.2x5.5x3,400 K102010.0x11.4x22x240 K548 K272224.5x33x42x977 K8901 K66115.1x6.0x9.1xTotalTimeBacktracksMutexChecksTotalTimeBacktracksMutexChecksSizePEBW-Large-B(18/18)2132823 K121,400 K79880 K21,900 KRocket-ext-a(7/36)4028128 K74,900 K40712 KTower-5(31/31)8117907 K23040 K33Ferry-6(39/39)3195909 K81000 K62Table 1: Comparison EGBG standard Graphplan.Numbers parentheses give number time steps / number actions respectively. Search backtracksmutex checks performed search shown. "Size PE" pilot explanation size termsfinal number search segments. Standard Graphplan Lisp version Smith Peot.depend admissibility. found bottom-up visitation efficient modeEGBG default order EGBG results reported study.3.3 EGBG Experimental ResultsTable 1 shows performance results reported first version EGBG (Zimmerman &Kambhampati, 1999). Amongst search trace designs tried, version memoryintensive records greatest extent search experience. Runtime, number searchbacktracks, number search mutex checks performed compared Lisp implementation original Graphplan algorithm. EGBG exhibits clear advantage Graphplansmall set problems;total problem runtime: 2.7 - 24.5x improvementNumber backtracks search: 3.2 - 33x improvementNumber mutex checking operations search: 5.5 - 42x improvementSince total time is, course, highly dependent machine well coding language 6(EGBG performance particularly sensitive available memory), backtrack mutex checkingmetrics provide better comparative measure search efficiency. Graphplan, mutex checkingfar biggest consumer computation time and, such, latter metric perhapscomplete indicator search process improvements. problem-to-problem variationEGBGs effectiveness attributed static/dynamic mutex ratio characterizing Graphplansaction assignment routine. action assignments rejected due pair-wise statically mutexactions, greater advantage enjoyed system doesnt need retest them. Tower-ofHanoi problems fall classification.noted original study (Zimmerman & Kambhampati, 1999) range problems6planners developed report coded Allegro Lisp run Pentium 900 mhz, 384 RAM.Runtimes include plangraph construction time exclude garbage collection time. Values Table 1 differpublished 1999 problems re-run platform. also reflect changes tracking statistics.546fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHhandled implementation significantly restricted amount memory availableprogram runtime. example, PE consisting almost 8,000 search segments,modest sized BW-Large-B problem challenges available memory limit test machine.consider next approach (me-EGBG Figure 1) occupies middle ground terms memorydemands amongst search trace approaches investigated.4. Engineering Reduce EGBG Memory Requirements: me-EGBG Plannermemory demands associated Graphplans search process major concern, sinceconducts depth-first search search space requirements linear depth solution node.Since seek avoid redundancy inherent IDA* episodes Graphplans search usingsearch trace, must deal much different memory-demand profile. search trace designemployed EGBG memory requirements exponential depth solution. However, search trace grows direct proportion search space actually visited, techniquesprune search also act greatly reduce memory demands.examined variety methods respect issue, eventually implemented suiteseven together proven instrumental helping EGBG (and later, PEGG) overcome memorybound limitations. Six known techniques planning CSP fields: variable ordering, value ordering, explanation based learning (EBL), dependency directed backtracking (DDB),domain preprocessing invariant analysis, transitioning bi-partite planning graph. Foursix effective methods CSP speedup techniques, however interest lies primarilyimpact search trace memory demands. challenging aspects adaptingmethods planning graph search trace context, focus paper. Thus detailsmotivation implementation methods relegated Appendix B.seventh method, novel variant variable ordering call EBL-based reordering, exploitsfact using EBL search trace available. Although method readily implemented PEGG, strict ordering trace vectors required EGBG search trace makecostly implement planner. such, memory-efficient EGBG (me-EGBG) useEBL-based reordering defer discussion PEGG introduced Section 5.4.1 Impact Enhancements EGBG Memory Demandstwo major modes first six techniques impact memory demand me-EGBG:1) Reduction size pilot explanation (search trace), either number search segments(states), average trace content within segments, 2) Reduction requirementsstructures compete pilot explanation available memory (i.e. planning graphmemo caches). Admittedly, two dimensions independent, since numbermemos (though size) linear number search segments. nonetheless considerpartition discussion facilitate comparison methods impact searchtrace.general, impact enhancements search process depends significantly,particular problem, also presence (or absence) methods.single configuration techniques proves optimal across wide range problems. Indeed, duecomputational overhead associated methods, generally possible find classproblems planner performance degrades due presence method. chose547fi90DDB4050607080six combination( me-EGBG )30EBL20Domain preprocess /Invariant AnalysisValue Ordering10% reduction PE (search trace) memory requirement100ZIMMERMAN & KAMBHAMPATIVariable Ordering102030Bi-partite graph405060708090100% reduction planning graph, memo cache memory requirementsFigure 5: Memory demand impact along two dimensions six memory reduction/speeduptechniques. Plots applied independently suite (within EGBG).set techniques then, based joint average impact me-EGBG / PEGG memory footprintextensive variety problems.Figure 5 illustrates method impact memory reduction relative two dimensions above, method operates isolation others. plot reflects results basedtwelve problems three domains (logistics, blocksworld, tower-of-hanoi), chosen includemix problems entailing large planning graphs, problems requiring extensive search, problemsrequiring both. horizontal axis plots percent reduction end-of-run memory footprintcombined memo caches planning graph. ratios along ordinate assessed basedruns Graphplan (no search trace employed) memo cache planning graphglobally defined structures significant size remain Lisp interpreted environmentrun completion.7 Similarly, vertical axis plots percent reduction space required PEend EGBG runs without method activated, planning graphmemo cache structures purged working memory.plot crossbars method depict spread reduction values seen across twelveproblems along dimensions, intersection average. bi-partite planninggraph, surprisingly, impacts graph aspect, five six methods seenimpact search trace size graph/memo cache size. these, DDB greatest influence PE size little impact graph memo cache size, EBL modest influence former larger impact latter (due smaller memos creates7Allegro Common Lisp global scavenging function used purge target global data structuresworkspace.548fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHproduction general memos, engender backtracks). Domain preprocessing/ invariant analysis major impact graph size PE size due processesextraction invariants operator preconditions. highly domain dependent, little effect case blocksworld problems, great consequence tower-ofHanoi logistics problems.six methods combined complement evidenced crossbars plotting space reduction six employed once. twelve problems average reductionPE size approaches 90% average reduction planning graph/memo cache aspect exceeds80%. single method isolation averages 55% reduction along dimensions.runtime reduction associated methods isolation also highly dependentproblem methods active. general, relative time reductiontwo methods correlate closely relative memory reduction. However, foundsimilarly, techniques broadly complement net speedup accrues.techniques listed (and been) used improve Graphplans performance also, terms speed. order focus impact planning search trace, useversion Graphplan enhanced six methods comparisons me-EGBGPEGG study (We hereafter refer enhanced version Graphplan GP-e).4.2 Experimental Results me-EGBGTable 2 illustrates impact six augmentations discussed previous section EGBGs(and Graphplans) performance, terms space runtime. Standard Graphplan, GP-e,EGBG, me-EGBG compared across 37 benchmark problems wide range domains, including problems first three AIPS planning competitions held date. problemsselected satisfy three objectives: subset standard Graphplan EGBG could solvecomparison me-EGBG, different subsets exceed memory limitations threeplanners terms either planning graph PE size, subset gives rough impressionsearch time limitations.surprisingly, memory efficient EGBG clearly outperforms early version problems attempted. importantly, me-EGBG able solve variety problems beyond reachstandard Graphplan EGBG. 37 problems, standard Graphplan solves 12, original EGBG solves 14, GP-e solves 32, me-EGBG solves 32. Wherever me-EGBG GP-e solveproblem, me-EGBG faster factor 62x, averages ~4x speedup. StandardGraphplan (on twelve problems solve), bested me-EGBG factors ranging 3x1000x.striking improvement memory efficient version EGBG first versionsimply due speedup associated five techniques discussed previous section,directly tied impact search trace memory requirements. Table 2 indicates one three reasons instance problem solved planner: 1) s: planner still search30 cpu minutes, 2) pg: memory exhausted exceeded 30 minutes planning graph building phase, 3) pe: memory exhausted search due pilot explanation extension. third reason clearly favors me-EGBG size PE (reported terms search segments timeproblem solved) indicates generates retains trace 100x fewer statesEGBG. translates much broader reach me-EGBG; exhausts memory 14%549fiZIMMERMAN & KAMBHAMPATITable 2 problems compared 49% first version EGBG. Regardless, GP-e solves threeproblems me-EGBG fails 30 minutes due search trace memory demandstable also illustrates dramatic impact speedup techniques Graphplan itself.enhanced version, GP-e, well 10x faster original version problemssolve 30 minutes, solve many problems entirely beyond standard Graphplans reach.Nonetheless, me-EGBG modestly outperforms GP-e majority problemssolve. Since EGBG (and PEGG) planners derive strength using PE shortcutGraphplans episodic search process, advantage realized problems multiple searchepisodes high fraction runtime devoted search. Thus, speedup seen grid-y-1problems mystery, movie, mprime domains solution extractedsoon planning graph reaches level containing problem goals non-mutex state.bottom-up order EGBG visits PE search segments turns surprisingly effective many problems. Table 2 problems found great majority PE finalepisode contains seed segment (a state search reach initial state) withindeepest two three PE levels. supports intuition discussed Section 3.2 suggestsadvantage low h-value bias observed heuristic state-space planners (Bonet & Geffner,1999; Nguyen & Kambhampati, 2000) trans-lates search planning graph.Results even memory efficient version EGBG reveal two primary weaknesses:1. action assignment trace vectors allow EGBG avoid redundant search somewhatcostly generate, make significant demands available memory problems elicit largesearch (e.g. Table 2 problems: log-y-4, 8puzzle-1, freecell-2-1), difficult revisesearch experience alters drastically subsequent visits.2. Despite surprising effectiveness many problems, bottom visitation PE searchsegments inefficient others. Table 2 problems freecell-2-1 essentiallyschedule domain problems, planning graph gets extended levelsolution extracted, solution arises via new search branch generated rootsearch segment (i.e. problem goal state). Thus, seed segment PE topmost search segment, bottom-up visitation PE states costly Graphplanstop-down approach.first shortcoming particularly manifest problems allow EGBG exploitPE (e.g. problems solution extracted first search episode). hit EGBGtakes problems relative Graphplan closely tied overhead associated buildingsearch trace. compelling tactic address second shortcoming traverse search spaceimplicit PE according state space heuristics. might wish, example, exploitvariety state-space heuristics revolutionized state space planners recent years(Bonet & Geffner, 1999; Nguyen & Kambhampati, 2000; Gerevini & Serina, 2002). However,noted Section 3.2, depart policy visiting EGBG search segments level-bylevel, bottom-up order, face costly bookkeeping high memory management overhead.informed traversal state-space view Graphplans search space taken next,argue perhaps key benefit afforded trace search planning graph.550fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHProblem(steps/actions)bw-large-B (18/18)huge-fct(18/18)rocket-ext-a (7/34)att-log-a(11/79)gripper-8 (15/23)Tower-6(63/63)Tower-7 (127/127)8puzzle-1 (31/31)8puzzle-2 (30/30)TSP-12(12/12)AIPS 1998grid-y-1 (14/14)grid-y-2 (??/??)gripper-x-3 (15/23)gripper-x-4 (19/29)gripper-x-5 (23/35)log-y-4(11/56)mprime-x-29 (4/6)movie-x-30 (2/7)mysty-x-30 (6/14)AIPS 2000blocks-10-1 (32/32)blocks-12-0 (34/34)logistics-10-0 (15/56)logistics-11-0 (13/56)logistics-12-1 (15/77)freecell-2-1 (6/10)schedule-8-5 (4/14)schedule-9-2 (5/13)AIPS 2002depot-6512 (10/26)depot-7654a (10/28)driverlog-2-3-6a (10/24)driverlog-2-3-6e (12/28)roverprob1425 (10/32)roverprob1423 (9/30)strips-sat-x-5 (7/22)strips-sat-x-9 (6/35)ztravel-3-8a (7/25)ztravel-3-7a (10/21)EGBGGraphplancpu secStnd.126165GP-ecpu sec(enhanced)11.413.03.512.212514.243.115866757.130448.3454GraphplanGP-e38816.7pgpg29116.1190pg47015.75.5.1.058313.5GraphplanGP-e10124.230.078.698.0pg63.5pg58.1GraphplanGP-e2395.132.512802.816918.917031347.0972799840.3pe8839.1pepepe393pg200pepepg6.6.0685sizePE79198410102097903303EGBG1998884232EGBGpepepepepepgpg219807979pe272pepeEGBG42721569100284111me-EGBGSPEEDUP(me-EGBGvs. GP-e)209029641741115231380166pe>1600026.91039297.07155me-EGBG16.915pg8.4229965.7635143313572pe>250005.54.05213.519me-EGBG16.1678814.5322016.3125910.0111712057101pe>1200042.9646.86me-EGBG4.145614.811991.023083.3769110.3152294.71021723.0271784.430615.61353>20000pe1.2x1.4x1.9x1.7x1.8x5.7x7.9x(pe)1.8x4.7xSpeedup1x~1.9x2.9x> 5x(pe)1x1x1xSpeedup6.3x1.7x1.8x7.9x> 2x(pe)1.5x1.2xSpeedup1.25x2.2x2.8x2x1.8x1.8x2.0x>21x62x~(memory efficient EGBG)cpu secsizePE9.29.11.87.27.97.620.0Table 2: Search step-optimal plans: EGBG, me-EGBG, standard & enhanced GraphplanStandard Graphplan: Lisp version Smith PeotGP-e: Graphplan enhanced per Section 4.1 me-EGBG: memory efficient EGBGSize PE final search trace size terms number "search segments"Search failure modes: pg Exceeded 30 mins. memory constraints graph buildingpe Exceeded memory limit search due size PEExceeded 30 mins. searchParentheses adjacent cpu time give (# steps / # actions) solution.551fiZIMMERMAN & KAMBHAMPATI5. Focusing State Space View: so-PEGG PEGG Plannerscosts associated EGBGs generation use search trace directly attributablestorage, updating, replay CSP value assignments search segments subgoals.therefore investigated stripped version search trace abandons tactic focusesinstead embodied state space information. show PEGG planners employingsearch trace (both so-PEGG, step-optimal version PEGG, version using beam search),outperform EGBG planners larger problems. key difference EGBGs pilot explanation pared down, skeletal PE used PEGG planners, elimination detailedmutex-checking information contained bit vectors former (i.e. last item bulletlist EGBG search segment contents Section 3.1). PEGG planners apply state-spaceheuristics rank PE search segments based associated subgoal sets (states) freevisit state space informed manner. tradeoff PE state visitedplanner must regenerate CSP effort finding consistent action assignments subgoals.Figure 6 illustrates PEGG advantage small hypothetical search trace final search episode. search segments PE onset episode appear solid lines plansegments (states extendable valid plan) shown double-lined boxes. figure reflectsfact typically may many latent plan segments diverse branches search tracesolution-bearing episode. Clearly planner discriminate plan segment statesstates PE could solve problem quickly planner restricted bottom-up traversal (deepest PE level first). State space heuristics endow PEGG planners capability.so-PEGG planner visits every search segment PE search episode (comparable Graphplans exhaustive search given length graph) thereby guaranteeing returnedplans step-optimal. such, advantage heuristic-guided traversal realizedfinal episode. many problems, computational effort expended Graphplan last searchepisode greatly exceeds previous episodes combined, still powerful advantage. However, scale problems larger terms number size searchepisodes, cost exhaustive search even intermediate episodes becomes prohibitive.3InitStateGoal1WWXZ24......123.....Proposition Levels78Figure 6: PE final search episode hypothetical problem. Search segments PEonset search appear solid lines, double-lined boxes represent plan segments,dashed lined boxes states newly generated regression search episode.Visitation order dictated secondary heuristic shown via numbering.552fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHplanner refer simply PEGG employs beam search, applying search trace heuristicsintermediate search episodes visit select subset PE segments. PEGGtrades step-optimality guarantee often greatly reduced solution times.several challenges must dealt effectively use pared search traceemployed so-PEGG PEGG, including adaptation augmentation distance-based heuristics guide search trace traversal dealing memory management problems inducedtactic skipping search space. describe addressed issuesgive complete description algorithm, first present results provide perspective effectiveness planners.5.1 Experimental Results so-PEGG PEGGTable 3 compares Graphplan (standard GP-e), me-EGBG, so-PEGG, PEGGproblems Table 2, adds variety larger problems latter two systemshandle. Table 2 problems easily solved GP-e me-EGBG (e.g. AIPS-98movie mystery domains) omitted Table 3. Here, planners employ variablevalue ordering (i.e. except standard Graphplan), configured use value ordering basedplanning graph level action first appears goal ordering based proposition distancedetermined adjusted-sum heuristic (which defined below). varietyparameters so-PEGG PEGG planners optimal configurations tendproblem-dependent. defer discussion Sections 5.3, 5.4, 5.6 noteTable 3 results following parameter settings used based good performance averageacross variety domains problems:Secondary heuristic visiting states: adjusted-sum w0=1 (eqn 5-1)Beam search: visit best 20% (lowest f-value) search segments per search episode,minimum 25 maximum 50. Search segments flux lower 10% averagevisited regardless heuristic rank. (wcf = .01, see section 5.6.1)Focusing first GP-e, me-EGBG, so-PEGG columns, clearly see impacttradeoff storing exploiting intra-segment action assignment information PE.set 37 problems, 16 result me-EGBG exceeding available memory due sizePE one pushes limit so-PEGG. Seven problems cause me-EGBG runmemory actually solved so-PEGG remainder exceed time limitsearch. addition, so-PEGG handles five problems table GP-e fails on. problemstypically entail extensive search final episode, PE efficiently shortcuts full-graphsearch conducted GP-e. speedup advantage so-PEGG relative GP-e rangesmodest slowdown three problems almost 87x Zeno-Travel problems, average5x. (Note speedup values reported table so-PEGG.)Generally, planner using search trace perform GP-e single search episode problems grid-y-1, cost building trace recovered. low overhead associated building so-PEGGs search trace means suffers little relative GP-e case.problems me-EGBG so-PEGG solve, me-EGBG upper hand dueability avoid redundant consistency-checking effort. fact me-EGBGs advantage soPEGG greater problems attributable so-PEGGs ability move PEsearch space final search episode (versus me-EGBGs bottom-up traversal) lower553fiZIMMERMAN & KAMBHAMPATIGraphplanProblemcpu sec (steps/acts)Stnd.bw-large-Bbw-large-Cbw-large-Datt-log-aatt-log-bGripper-8Gripper-15Tower-7Tower-98puzzle-18puzzle-2TSP-12AIPS 1998grid-y-1gripper-x-5gripper-x-8log-y-5AIPS 2000blocks-10-1blocks-12-0blocks-16-2logistics-10-0logistics-12-1logistics-14-0freecell-2-1freecell-3-5schedule-8-9AIPS 2002depot-7654adepot-4321depot-1212driverlog-2-3-6edriverlog-3-3-6broverprob1423roverprob4135roverprob8271sat-x-5sat-x-9ztravel-3-8aztravel-3-7a194.824441546Stnd GP388pgStnd GP~~pgpgpgStnd GP313GP-eme-EGBGcpu sec(steps/acts)(enhanced )11.4 (18/18)(28/28)(38/38)31.8 (11/79)14.2 (15/23)158 (127/127)(511/511)57.1 (31/31)48.3 (30/30)454 (12/12)GP-e16.7 (14/14)470 (16/41)GP-e95.4 (32/32)26.6 (34/34)30.0 (15/56)98.0 (6/10)1885 (7/16)300 (5/12)GP-e32.5 (10/28)166 (12/28)170 (9/30)45 (7/22)972 (7/25)9.2so-PEGGheur:istic:adjsumcpu sec(steps/acts)7.01104pe7.22.9 (11/72)pe7.930.6pe20.014.3232118pe31.126.931.397.0390me-EGBGso-PEGG17.916.8433512pepe361me-EGBGso-PEGG16.118.714.523.0pe16.6211205 (15/77) 1101 (15/75)pepe102pe511615719me-EGBGso-PEGG14.812.983.3109pe1437 (11/39)pe63.4pepe43.027.09189.915.611.2pepepePEGGheur: adjsum-ucpu sec(steps/acts)Speedup(PEGGvs. GP-e)4.124.23882.221.65.546.76.123.69.27.06.9(18/18)(28/28)(38/38)(11/62)(13/64)(15/23)(31/45)(127/127)(511/511)(31/31)(32/32)(12/12)PEGG16.8 (14/14)110 (23/35)520 (35/53)30.5 (16/34)PEGG6.9 (32/32)9.4 (34/34)28.1 (56/56)7.3 (15/53)17.4 (15/75)678 (13/74)19.5 (6/10)101 (7/17)719 (5/12)PEGG13.2 (10/26)42.6 (14/37)79.1 (22/53)80.6 (12/26)169 (14/45)15.0 (9/26)379 (12 / 43)220 (11 / 39)25.1 (7 / 22)9.9(6 / 35)15.1 (9/26)101 (10/23)2.8x> 74x> 4.6x14.5x> 83x2.6x> 38.5x26x> 76x6.2x6.9x51xSpeedup1x> 16x> 3.5x15.4xSpeedup13.8x2.8x> 64 x4.1x> 103x> 2.7x>92x18.7x(.42x)Speedup2.7x>42x>22.8x2.1x> 10.7x11.3x> 4.7x> 8.2x1.7x>182x119x> 18xTable 3: so-PEGG PEGG comparison Graphplan, GP-e, me-EGBGGP-e: Graphplan enhanced per Section 4.1 me-EGBG: memory efficient EGBGso-PEGG: step-optimal, search via PE, segments ordered adjusted-sum-u heuristicPEGG: beam search, best 20% segments PE ordered adjusted-sum-u heuristicParentheses give (# steps/ # actions) plan. Boldface values exceed knownstep-optimal.See Table 2 definitions s, pg, pe554fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHoverhead due concise search trace. Note obvious reason prefer one statetraversal order non solution-bearing episodes since step-optimal planners visitstates PE search episodes. 8turning attention PEGG results, apparent beam search greatly extendssize problems handled. PEGG solves ten larger problems Table 3 couldsolved either so-PEGG enhanced Graphplan. Speed-wise PEGG handily outperformsplanners every problem except schedule-8-9, GP-e factor 2.3x advantage. indicated tables right-hand column, speedup PEGG GP-e ranges .42x182x. conservative bound PEGGs maximum advantage relative GP-e since speedupvalues seventeen problems GP-e fails solve conservatively assessed timelimit 1800 seconds.defer analysis results Section 6 order first describe PEGG algorithmadvantages extracts search trace.5.2 Algorithm PEGG Plannershigh-level algorithm so-PEGG PEGG given Figure 7. Graphplan, search begins planning graph extended level problem goals first appearbinary mutex conditions. (The routine, find_1st_level_with_goals virtuallyGraphplans defined here). first search episode conducted Graphplan fashion,except assign_goals assign_next_level_goals routines Figure 8 initialize PEcreate search segments hold states generated regression search process. assign_goals pseudo-code outlines process compiling conflict sets (see Appendix B) meansimplementing DDB EBL action assignment search. assign_next_level_goalsroutine illustrates role top-level conflict set recording minimal no-good searchstate completed (EBL) depicts variable ordering need done state(when search segment created). child segment created linked parent (extendingPE) assign_next_level_goals whenever parent goals successfully assigned. assign_next_level_goals routine determines subgoals child search segment regressingparents goals actions assigned checks see either initial statereached remaining goals. so, success signaled returning child search segment used extract ordered actions plan.Subsequent first episode, PEGG_plan enters outer loop employs PE conductsuccessive search episodes. episode, newly generated search segments previousepisode evaluated according state space heuristic, ranked, merged already orderedPE. inner loop search segment visited turn passing subgoals Graphplanlike assign_goals routine.exit conditions inner loop primarily differentiate so-PEGG PEGG.Whereas so-PEGG visit every search segment whose goals found match memo,PEGG restricts visitation best subset, based user-specified criterion. such, expansionplanning graph deferred segment chosen visitation transposes planning graph level exceeding current graph length. consequence, problems PEGG8fact found advantages respect traversal order even intermediate search episodes problems. However, highly problem-dependent, consider study.555fiZIMMERMAN & KAMBHAMPATIPEGG_PLAN (Ops, Init, Goals) /*{ Ops, Init, Goals} constitutes planning problem *//* build plangraph, PG, level n goals first occur non-mutex state*/Let PG find_1st_level_with_goals( Ops, Init, Goals )PG reached level-off goals present non-mutex state Return FAILLet n number levels PGReorder Goals according variable ordering methodLet SS0 new search segment fields:goalsGoals, parent root, PE-level 0, parent-actions {}Let PE pilot explanation structure fields: ranked-segs {SS0}, new-segs {}/* Conduct Graphplan-style backward search n-length planning graph, storing trace PE..*/Let search-reslt assign_goals(Goals, {}, n, SS0, PG, PE)search-reslt search segment /* Success */Let Plan extract plan actions ancestors linked search-resltReturn Planelse /* n-length solution possible ...use PE search longer length solution */loop forevern n+1/* rank newly generated states merge existing ordered PE segments list */PE<ranked-segs> merge sort(PE<ranked-segs> U heuristic_sort( PE<new-segs> ) )loop unvisited search segments PE[ranked-segs] (optionally: segmentsheuristic threshold)Let SS highest ranked, unvisited segment PEs ranked-segsLet k = n (PE-level SS)/*... planning graph level SS based transposed PE */k = n PG extend_plangraph(PG) /*.. delays extending graph unavoidable! */optionally: flux metric SS goals < user-specified threshold continue loop.SS goals memos level k PG remove SS PEs ranked-segselse /* visit search segment SS... */search-reslt assign_goals (SS<goals>, {}, k, SS, PG, PE)search-reslt search segment /* Success...*/Let Plan extract plan actions ancestors linked search-resltReturn Planelse search-reslt conflict set..add conflict set level k memos PG /* memoize minimal nogood */reorder SS goals goals conflict set appear first /* EBL-based reordering */endend-loopendFigure 7: Top-level algorithm PEGG so-PEGG planners.planners may able extract step-optimal solution building one less level Graphplan-based planners.99Interestingly, PEGG beam search could conceivably extract optimal solution planning graph arbitrary number levels shorter required Graphplan. Consider case PE, average, extends leastone level deeper episode subset PE search segments visited always resides deepest levels PE.arbitrary number search episodes might completed without extending planning graph. Based experiments problems date however, advantage seldom saves one planning graph level extension.556fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHConduct DDB & EBL-enhanced Graphplan-style search building search tracearguments> G: goals still assigned, A: action set already assigned, k: PG level,SS1: search segment, PG: planning graph, PE: pilot explanation (search trace)ASSIGN_GOALS (G, A, k, SS1, PG, PE)Let g goal selected GLet Ag actions PG level k support g, ordered value-ordering heuristicLet cs {g} /* initialize conflict set DDB */loop act AgLet search-reslt = {}act mutex actionLet b goal conflicted action assigned supportcs cs U {b} /* augment conflict set continue loop*/else /* act conflict actions already */G-{g} empty/* continue goal assignment level */search-reslt assign_goals (G-{g}, U{act}, k, SS1, PG, PE)else /* SS1 goals left satisfy...setup search next lower level */search-reslt assign_next_level-goals (A U{act}, k, SS1, PG, PE)search-reslt conflict set, check contains current goal..g search-reslt/* absorb returned conflict set & try next action */cs cs U search-resltelse Return search-reslt /*just return conflict set */else search-reslt search segment: /* Success.. */Return search-resltend loop (actions)Return cs /* soln reached .. compiled conflict set returned*/end-ifendSet search graph level k-1 given SS1 goals satisfied actions level kASSIGN_NEXT_LEVEL_GOALS (A, k, SS1, PG, PE)Let nextgoals regress SS1 goals (the actions assigned satisfy goals)nextgoals empty k = 0 (its initial state)Return SS1 /* Success */else memos level k-1 PG nextgoalsReturn conflict set /* backtrack due nogood */else /* initiate search next lower PG level*/Let SS2 new search segment holding nextgoals, pointer SS1, & actions assigned SS1Add SS2 PE new-segs listLet search-reslt assign_goals (nextgoals, {}, k-1, SS2, PG, PE)search-reslt search segment /* Success.. */Return search-resltelse search-reslt conflict set: /*memoize minimal nogood return conflict set */add conflict set level k-1 memos PGreorder SS2 goals goals conflict set appear first /* .. EBL-based reordering */Return search-resltend-ifendFigure 8: PEGG / so-PEGG regression search algorithm Graphplan-style regression searchsubgoals concurrently building search trace (PE)557fiZIMMERMAN & KAMBHAMPATINote PEGGs algorithm combines state-space CSP-based aspects search:chooses expansion promising state based previous search iterationstate space heuristics. PEGG so-PEGG free traverse states search traceorder.selected state expanded Graphplans CSP-style, depth-first fashion, making full useCSP speedup techniques outlined above.first aspect clearly distinguishes PEGG EGBG: traversal state space PElonger constrained bottom-up level-by-level. EGBG, managementmemory associated search trace challenge PEGG stray bottom-up traversal, less daunting. easier outline address first discussdevelopment adaptation heuristics search trace traversal.5.3 Informed Traversal Search Trace SpaceHSP HSP-R state space planners (Bonet & Geffner, 1999) introduced idea usingreachability propositions sets propositions (states) assess difficulty degree relaxed version problem. concept underlies powerful distance based heuristics selecting promising state visit. Subsequent work demonstrated planning graphfunction rich source heuristics (Nguyen & Kambhampati, 2000). Since planninggraph already available PEGG, adapt extend heuristics latter work servesecondary heuristic role direct PEGGs traversal search trace states. Again, primary heuristic planning graph length iteratively deepened (Section 2.2), step-optimalityguarantee so-PEGG planner depend admissibility secondary heuristic.important differences heuristic ranking states generated state space planner ordering search segments (states) PEGGs search trace. example, state spaceplanner chooses visit given state PEGG planners often must consider whetherrevisit state many consecutive search episodes. Ideally, heuristic rank states searchtrace reflect level-by-level evolutions planning graph, since transposition processassociates search segment higher level successive episode. higher planninggraph level given state associated with, effective regression search spacechanges complex function number new actions appear graph, numberdynamic mutexes relax, no-goods memo caches. Moreover, unlike state spaceplanners queue previously unvisited states, states search trace include childrenstate generated last visited. Ideally value visiting state assessed independently value associated children, since assessed turn. Referring back search trace depicted Figure 6, desire heuristic can, example, discriminate #4 ranked search segment ancestor, top goal segment (WXYZ).would like heuristic assessment segment WXYZ discount value associated children already present trace, ranked based potential generating new local search branches.next discuss adaptation known planning graph based heuristics effective usesearch trace.558fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPH5.3.1 ADOPTION DISTANCE-BASED STATE SPACE HEURISTICSheuristic value state, S, generated backward search problem goals expressed as:5-1)f ( ) = g ( ) + w0 * h( )where: g(S) distance problem goals (e.g. terms steps)h(S) distance estimate initial state (e.g. steps)w0 optional weighting factorvalue g state generated search (e.g. states PE) easily assessedcumulative cost assigned actions point. h values consider takendistance heuristics adapted exploit planning graph (Nguyen & Kambhampati,2000). One heuristic readily extractable planning graph based notionlevel set propositions:Set Level heuristic: Given set propositions, denote lev(S) index first levelleveled serial planning graph propositions appear non-mutex one another. (If singleton, lev(S) index first level singleton elementoccurs.) level exists, lev(S) = .admissible heuristic embodies lower bound number actions needed achieveinitial state also captures negative interactions actions (due planning graph binary mutexes). Nguyen & Kambhampati, 2000 study, set level heuristicfound moderately effective backward state space (BSS) planner AltAlt, tended result many states f-value. directing search PEGGs search tracesomewhat effective, still suffers lower level discriminationheuristics examined -especially problems engender planning graph relativelylevels. Nonetheless, noted Appendix B discussion memory efficiency improvementsuse planning graph construction default heuristic value ordering, due lowcomputational cost synergy building using bi-partite planning graph.inadmissible heuristics investigated Nguyen & Kambhampati, 2000 work basedcomputing heuristic cost h(p) single proposition iteratively fixed point follows.proposition p assigned cost 0 initial state otherwise. action, a, addsp, h(p) updated as:5-2) h(p) := min{ h(p), 1+h(Prec(a) }h(Prec(a)) sum h values preconditions action a.Given estimate propositions h-value, variety heuristic estimates statestudied, including summing h values subgoal taking maximum subgoal hvalues. study focus heuristic termed adjusted-sum (Nguyen & Kambhampati, 2000), combines set-level heuristic measure sum h-values statesgoals. Though powerful heuristic tested them, computationally cheap planning graph based planner found quite effective BSS planners tested.Adjusted-sum heuristic: Define lev(p) first level p appears plan graphlev(S) first level plan graph propositions state appear nonmutexed one another. adjusted-sum heuristic may stated as:559fiZIMMERMAN & KAMBHAMPATI5-3)hadjsum ( ) :=h( p ) + ( lev(S ) max lev( p ) )pipi2-part heuristic; summation, estimate cost achieving assumption goals independent, estimate cost incurred negative interactionsamongst actions must assigned achieve goals. latter factor estimated takingdifference planning graph level propositions first become non-mutexlevel propositions first appear together graph.complex heuristics proposed include measure positive interactions subgoals state, is, extent action establishes one relevant subgoal. so-called relaxed plan distance-based heuristics focus positive interactions,several studies demonstrated power backward forward state-space planners(Nguyen & Kambhampati, 2000; Hoffman, 2001). However, reported former study, primary advantage adding positive interactions adjusted-sum heuristic produce shortermake-span plans expense modest increase planning time. Since PEGGs IDA* searchalready ensures optimal make-span little incentive incur expense relaxed plancalculation, restricted work simpler adjusted-sum heuristic eqn 5-3.adjusted-sum heuristic adapted search planning graph leveraginginformation PEGGs search trace. takes form heuristic updating dynamically improve h value estimate states PE. lev(S) term adjusted-sum heuristic representsfirst planning graph level subgoals state appear binary non-mutexother. However, regression search graph level k fails given episode, searchprocess essentially discovered n-ary mutex condition subset goalslevel k (This subset conflict set, C, gets memoized PEGG algorithm Figures 78). point lev(S) value updated k+1, indicating k+1 conservative estimatefirst level goals appear n-ary non-mutex state. desirable propertyranking search trace states; longer state resides search trace, often h-value getsincreased, less appealing becomes candidate visit again. is, heuristic updatebiases states visited failed extend solution. useaugmented adjusted-sum heuristic PEGG runs work refer adjusted-sum-u.Experimentally, find advantage given heuristic ordering PE states highlydomain dependent (but less sensitive particular domain problem). example, comparedsimple bottom-up visitation strategy, adjusted-sum-u heuristic improves so-PEGG runtimesorder magnitude domains (e.g. Freecell and, Satellite) degradingfactor 2x 7x others (e.g. Zenotravel). Figure 9 depicts performance adjusted-sum-uheuristic relative bottom-up heuristic so-PEGG several sets problems. heuristics compared terms so-PEGGs average computation time percentage GP-esfinal search episode -the important measure exhaustive search planning graph.informed heuristic find seed segment sooner but, event many(typical logistics domains), find one lies planning graph level closerinitial state. less informed heuristic may cause PEGG end conducting search finalepisode GP-e, may many states PE would regenerated Graphplanfinal regression search finds solution. direct measure power560fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHbottom-upadjusted-sum-uDepotScheduleProblem SetZenoTravelFreecellDriverlogSatelliteLogisticsBlocksTSP0.0020.0040.0060.0080.00 100.00 120.00 140.00% Graphplan's search cost final episodeFigure 9: Heuristic accuracy so-PEGG final search episode --relative GP-esearch segment selection heuristic. Since performance vary considerably specific problem results figure averages three representative examples domain10.5.4 Memory Management Arbitrary Search Trace Traversal Orderreturn memory management problems induced strategy skippingsearch space. Consider PE time final search episode Figure 6. search segments visited order deepest PE level first, encounter problem regenerating states already contained PE. visitation order depicted numbered segmentsfigure could result fairly informed heuristic (the 4th segment chooses visit plansegment), implies many states already resident PE regenerated. includes,example, yet unvisited descendents third segment visited. Unchecked, processsignificantly inflate search trace memory demands well overhead associated regenerating search segments. addition, heuristic information state lost state regenerated instead revisited extant PE search segment. due adjustedsum-u secondary heuristic PEGG learns improved n-ary mutex level search segments goalsupdates f-value accordingly search episode.address issue hashing every search segment generated associated PE state hashtable according canonically ordered goal set. One hash table built PE level.Prior initiating regression search subgoal set search segment, Sn , PEGG first checksplanning graph memo caches and, relevant memo found, checks PE state hash tablesee Sns goals already embodied existing PE search segment relevant PE level.10Problem sets used- Blocksworld: bw-large-b, blocks-10-1 12-0 Logistics: att-log-a, logistics-10-0, 12-0, Gripper:gripper8, gripper-x-3, x-5, Depot: depotprob6512, -5646, 6587, Driverlog: dlog-3-36a, -2-3-6a, 2-3-6e, Zenotravel:ztravel-3-8a, -3-8b, 3-7b, Freecell: freecell-2-1, -2-2, -3-5, Satellite: strips-sat-x-4, x-5, x-9.561fiZIMMERMAN & KAMBHAMPATIsearch segment, Se,, returned PE state check, Se made child Sn (if already) establishing link, search proceed Se goals.11Another search trace memory management issue associated fact PEGG visitssubset PE states -a set call active PE. tempting pursue minimal memoryfootprint strategy retaining memory active search segments PE. However unlikeGraphplan, initial state reached PEGG cannot extract solution unwinding complete sequence action assignment calls since may begun regression search arbitrary state branch search trace tree. PEGG depends instead link childsearch segment parent extract plan actions solution found. mustretain minimum, active search segments ancestor segments root node.Beyond requirement retain search segments tied active PE, many strategiesmight used managing inactive portion. study attempted reducePE memory requirements manner, instead focusing might termed search spacefield view. beam search, heuristic effectiveness depends informed is,search trace states available rank. reduced memory footprint PEGGs skeletalsearch trace allows us adopt strategy retaining memory search segments generated.segments f-values updated ranked, giving beam search wide selection states contending active status given search episode.5.5 Learning Order States SubgoalsPEGG planners employ EBL search trace, allows overlay yetsophisticated version variable ordering top distance-based ordering heuristic. guidingprinciple variable ordering search fail early, failure inevitable. terms Graphplan-style search regressed state, translates Since state goals must assigned action, best attempt satisfy difficult goals first. adjusted-sum heuristic describedabove, applied single goal, provides estimate difficulty based structureplanning graph. However, EBL provides additional information difficulty goal achievementbased directly search experience. wit, conflict set returned PEGGs assign_goals routine search goal set explicitly identifies goals responsible search failure. intuition behind EBL-based reordering technique then,goals likely difficult assign search segment revisited nextsearch episode. constitutes dynamic form variable ordering that, unlike distance-basedordering, search segments goals may reordered successive search episodes basedrecent search experience.Figure 10 compares influence adjusted sum variable ordering EBL-based reorderingmethods memory demand, manner similar Figure 5. impact EBL-based reordering EGBGs performance reported PEGG tightly integrates various CSP efficiency methods, independent influence cannot readily assessed.12 isolate impactEBL-based reordering EBL activating EBL using produced con1112interests simplicity, Figure 8 algorithm outline memory management process.Given success various memory-efficiency methods within EGBG, versions PEGG implementdefault. graph analogous Figure 5 PEGG planner would differ terms actual memory reduction values, confident overall benefits methods would persist, would relative benefit relationshipmethods.562fi3020Variable Ordering (adjsum) & EBLReorderingVariable orderingEBL- Reordering10% reduction PE (search trace) memory requirementUSING MEMORY TRANSFORM SEARCH PLANNING GRAPH102030% reduction planning graph, memo cache memory requirementsFigure 10: Memory demand impact along two dimensions adjusted-sumvariable ordering EBL-based reordering techniques appliedindependently together.flict sets reordering, memoization. average reduction search trace memory12-problem sample seen 18% EBL-based reordering alone. comparesfavorably 22% average reduction distance-based ordering, especially since, unlikeadjusted sum ordering, EBL-based reordering takes effect 2nd search episode. plotalso reveals two modes ordering quite complimentary.Across variety problems domains found following approach effectivecombining distance-based variable ordering EBL-based reordering: 1) newly created searchsegments goals ordered according distance-based heuristic. 2) visit searchsegment, subset goals appear conflict set reordered appear first. 3) goalsconflict set ordered distance-based heuristic appended non-conflict goals,also set distance-based order.indicated Figure 10, hybrid form variable ordering boosts average memory reduction almost 30%, also significantly reduces wide fluctuation performanceeither method isolation. re-emphasize search experience-informed goal orderingavailable search algorithm maintains memory states visited. thereforeportable Graphplan-based planner know of.5.6 Trading Guaranteed Step-Optimality Speed Reach:PEGG Beam SearchMany difficult benchmark problems Graphplans IDA* style search 20search episodes reaching episode solution extracted. cumulative search time tied episodes large portion total search time and, indicatedTable 3, so-PEGG exhausts search time limits well reaching episode solutionextracted. strategy exhaustively searching planning graph, episodesolution bearing level, gives step-optimal guarantee Graphplans solutions exact563fiZIMMERMAN & KAMBHAMPATIhigh cost ensure is, all, one aspect plan quality. explore PEGG, nonexhaustive search version so-PEGG, extent search episodes truncatedproducing plans virtually makespan Graphplans solution.PEGG shortcuts time spent search intermediate episodes using secondaryheuristic direct order PE states visited prune search space visitedepisode. beam search seeks visit promising PE states, measuredf-values user-specified limit. addition, beam search important dual benefitPEGG reduces memory demands search trace and, dependingproblem, even planning graph. PEGG algorithm Figure 8, loop statementpoint beam search f-value threshold optionally applied PE states candidates visitation. first segment exceeding threshold reached sorted queuesearch episode ends.devise effective threshold test must reconcile competing goals: minimizing search nonsolution bearing episodes maximizing likelihood PE retains visits (preferablyearly possible), search segment thats extendable solution graph reaches firstlevel extant solution. narrower window states visited, difficultheuristic ranks states ensure includes plan segment, i.e. one part stepoptimal plan. PEGG return step-optimal plan long search strategy leads visitplan segment (including top, root segment PE) belonging plan latent PE, search first solution-bearing planning graph. heuristics job selecting windowsearch segments visit made less daunting many problems many step-optimalplans latent solution-bearing level.next describe effective planning graph based metric augments state space heuristicchoosing set PE states visit search episode.5.6.1 MINING PLANNING GRAPH FILTER BEAMBeyond heuristic updating introduced Section 3, distance-based heuristics virtuallyinsensitive planning graph evolution search segment transposed successive levels. Sincesearch trace contains children states generated regression search state episode n, heuristic preference include states trace visit episode n+1reflect chance directly generate new promising search branches. child statessearch episode n competitors S, ideally heuristics rank reflectsense value visiting state beyond importance children.Consider sensitivity adjusted-sum heuristic (or distance-based heuristics)possible differences implicit regression search space set propositions, S, planning graph level k versus level k+1. Given propositions present binary non-mutexlevel k, cost summation factor equation 5-3 could conceivably changeevaluated level k+1. would require two conditions: new action must establish onepropositions first time level k+1 actions precondition costs must sum lessprecondition costs establisher proposition. practice happens infrequently since later action appears graph construction process, higher cost tendsbe. Consequently h-values states based distance-based heuristics remain remarkably constant planning graph levels beyond propositions appear binary non564fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHmutex13. desire means compensating static h-value state transposed planning graph level promising new branches regression search open up.likelihood state visited episode n graph level k give rise new child statesvisited episode n+1 level k+1 rooted graph dynamics summarized Observations A-1A-2 Appendix A. Three planning graph memo cache properties determine whether regression search subgoal set evolve successive episodes:1. new actions level k+1 establish subgoal2. dynamic mutexes level k actions establishing subgoals relaxlevel k+13. no-good memos encountered regression search state episode nencountered level k+1 (and also converse).set measures potential new search branches result visiting state PErefer flux; intuition higher flux, likely searchgiven state differ seen previous search episode (and captured PE). nonethree factors applies state consideration, point visiting it, newsearch result relative previous episode.first factor readily assessed state (thanks part bi-partite graph structure). second flux factor unfortunately expensive assess; direct measure requires storingpairs attempted action assignments goals inconsistent episode n retesting new planning graph level. However, graph mechanics relaxationdynamic mutex two actions level k requires relaxation dynamic mutex conditionpair preconditions level k-1 (one precondition action). relaxation, turn, either due one new establishing actions preconditions level k-1recursively, relaxations existing actions establishing preconditions. such, number newactions establishing subgoals state PE (factor 1 above) provide measureflux S, also predictor flux due factor 2 parent (and higher ancestors) S.Thus, turns simply tracking number new actions state subgoal current level propagating appropriately weighted measure parent, compile usefulestimate flux factors 1 2 above.third flux factor unwieldy costly estimate; exact measure requiresstoring child states generated regression search level k caused backtracking duecached memos, retesting see memos present level k+1.14 Ignoringfactor, sum two flux measures depend new actions derive filtering metricused assist largely static adjusted-sum distance-based heuristic cullingbeam. resulting (inexact) metric sensitive evolution search potential state transposed higher planning graph levels:13This, part, explains observation (Nguyen & Kambhampati, 2000) AltAlt state space planner performancegenerally degrades little planning graph used extract heuristic values built level problem goals appear non-mutex, rather extending level-off.14Note long using EBL/DDB, sufficient test whether memo exists child state.no-good goals contribute conflict set used direct search within whenever backtracking occurs.565fiZIMMERMAN & KAMBHAMPATI5-4)flux( ) =newacts( p )pi|S|+ wcfchildflux(s )si cwhere: pi proposition statenewacts(pi) number new actions establish proposition piassociated planning graph level| | normalization factor; number propositionsSc set child states currently represented search tracechildflux(si) sum two flux terms eqn 5-4 applied child state siwcf weights contribution flux child states parent statenumber new actions establishing subgoals state normalized relative number subgoals state.report elsewhere (Zimmerman, 2003) use flux directly augment secondaryheuristic. Depending domain weighting flux contribution adjusted-sum heuristic, speedups order magnitude observed15. However impact highly domaindependent since primarily concerned performance general purpose planner,study consider use beam filter.beam search, flux measure strongly impact every search episode, influencesstates actually included active PE. used mode, search segments assessedflux specified threshold skipped even f-value places active PE.Flux proves broadly effective across domains used mode. mentionedSection 5.1, use flux cutoff search episode 10% average flux search segments PE; segment value visited regardless heuristic rank.setting impact speedup PEGG column problems Table 3 ranges nil factor9x PEGGs performance without flux filter. Higher settings dramatically speedsolution search, often expense greater solution makespan.5.6.2 PEGGS ABILITY FIND STEP-OPTIMAL PLANSvariety parameters associated beam search approach described admits considerable flexibility biasing PEGG towards producing plans different quality. Shorter makespan plansfavored extensive search PE states episode heuristically truncatedsearch tends generate non-optimal plans quickly, often containing redundant unnecessaryactions. settings used study clearly bias PEGG solutions towards step-optimality:step-optimal plan produced enhanced Graphplan matched PEGG four 37problems reported Table 3, indicated annotated steps actions numbers given parenthesis next successful GP-e PEGG runs16. (PEGG solutions longer makespanstep-optimal boldface step/action values.) four problems, PEGG returns solutions15example, compared simple bottom-up visitation strategy, flux-augmented adjusted-sum heuristic improvesso-PEGG runtimes 11x domains (e.g. Freecell and, Satellite) degrading much 2x 7xothers (e.g. Zenotravel).16one guaranteed step-optimal planners (GP-e, me-EGBG so-PEGG) finds solution stepsactions reported one them, since makespan.566fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHProblemN-best firstPEGG[N=100, state-space search] [ adjusted-sum-u heuristic beam search100 best search segments]SATPLAN(optimal)bw-large-a86(.1 s)6bw-large-b129 (4.5 s)9bw-large-c2114 (39.0 s)14bw-large-d2518 (412 s)18Table 4: Quality comparison (in terms plan steps) PEGG N-best beam searchforward state space planner (Bonet et al., 1997).within four steps optimum, spite highly pruned search. proved fairly robustproperty PEGGs beam search settings across problems tested date.PEGG adjusted-sum-u secondary heuristic often finds plans fewer actionsGP-e parallel domains, Graphplan hybrid system also impressive serial domainsblocksworld (which exactly Graphplans forte).tactic trading optimal plan length favor reduced search effort well knownplanning community. comparison, PEGGs beam search approach biased towards producinghigh quality plan possibly expense runtime. example, paper focusingaction selection mechanism planning, Bonet et. al. briefly describe work N-bestfirst algorithm (Bonet, Loerincs, & Geffner, 1997). employ distance-based heuristicconduct beam search forward state space planning. report small set results case100 best states retained queue considered search.Table 4 reproduces results alongside PEGGs performance problems using beamsearch. Here, approximate N-best algorithm, PEGG also run 100 states visitedintermediate search episode. 1997 study compared N-best first approach SATPLAN,produces optimal length plan, make point approach could produce plans reasonably close optimal much less search. N-best first code available runtest platform, PEGGs runtime reported. Focusing plan makespan, clear evenserial domain, parallel planner PEGG produces much shorter plan N-best firststate space approach, fact finds optimum length plan generated SATPLAN cases.recently LPG (Gerevini & Serina, 2002), another planner whose search tightly integratedplanning graph, awarded top honors AIPS-2002 planning competition, dueability quickly produce high quality plans across variety domains currently interest.Figure 11 scatter plot, solution quality terms steps LPG PEGG comparedoptimal 22 problems three domains 2002 AIPS planning competition. choseparticular problems optimal solution known, interested comparingquality baseline. LPGs results particularly apt case, planner also nonexhaustively searches planning graph level extending it, although search processdiffers markedly PEGGs. LPG, too, biased produce plans higher quality (generallyexpense speed) report competition results quality mode. termsnumber actions solutions neither planner consistently dominates problemsPEGG clearly excels step-optimality. maximum deviation optimum four steps567fiZIMMERMAN & KAMBHAMPATI18LPG: dlog16LPG: depotSteps optimal14LPG: ztravel12PEGG: dlog10PEGG: depot8PEGG: ztravel64200246810Problem number12141618Figure 11: Makespan comparison PEGG LPG -Departure step-optimalplan length. (LPG data taken AIPS 2002 competition results.)plot points solutions lie right optimal makespan axis. possiblesets actions within LPGs solutions could conducted parallel algorithms qualitymode heuristic insensitive .noted LPG produced solutions difficult problems domainsPEGG currently solve within reasonable time limit. investigating characteristicsproblems make difficult PEGG.5.6.3 PEGG COMPARED HEURISTIC STATE SPACE SEARCHattempted run PEGG head-to-head speed recent IPC planners, partdue platform difficulties (PEGG written Lisp competition planners generallycoded C published results based execution competition machines) partlydue focus near-optimal makespan parallel plans rather speed. Given PEGGs closecoupling planning graph, relevant comparisons parallel plannersalso employ graph form. comparisons, would like isolate search component runtime planning graph construction, since variety routines produce essentially graph widely different expenditures computational time memory. reported runtimes LPG planner AIPS-02 competition generally muchsmaller PEGGs, difficult isolate impact graph construction platform-relatedeffects, mention disparity makespan plans produced.Table 5 compares PEGG Lisp version fast distance-based heuristic state space planner using problems Table 3. AltAlt (Srivastava et al., 2001), like PEGG, dependsplanning graph derive powerful heuristics uses direct regression searchproblem goals. facilitates planner performance comparison based differences search without confusing graph construction time issues. last column Table 5 reports AltAlt performance(runtime makespan) two effective heuristics developed planner (Nguyen &Kambhampati, 2000), first adjusted-sum heuristic described Section 5.3.1.568fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHProblembw-large-Bbw-large-Cbw-large-Drocket-ext-aatt-log-aatt-log-bGripper-8Gripper-15Gripper-20Tower-7Tower-98puzzle-18puzzle-2TSP-12AIPS 1998grid-y-1gripper-x-5gripper-x-8log-y-5mprime-1AIPS 2000blocks-10-1blocks-12-0blocks-16-2logistics-10-0logistics-12-1freecell-2-1schedule-8-9AIPS 2002depot-6512depot-1212driverlog-2-3-6edriverlog-4-4-8roverprob1423roverprob4135roverprob8271sat-x-5sat-x-9ztravel-3-7aztravel-3-8aPEGGheuristic: adjusted-sum-ucpu sec (steps/acts)4.124.23881.12.221.65.546.71110.86.123.69.27.06.9(18/18)(28/28)(38/38)(7/34)(11/62)(13/64)(15/23)(36/45)(40/59)(127/127)(511/511)(31/31)(32/32)(12/12)PEGG16.8 (14/14)110(23/35)520(35/53)30.5 (16/34)2.1 (4/6)PEGG6.9 (32/32)9.4 (34/34)40.9 (56/56)7.3 (15/ 53)17.4 (15/75)19.1 (6/10)297(5/12)PEGG2.1 (14/31)79.1 (22/53)80.6 (12/26)889(23/38)15(9/28)379(12 / 43)220(11 / 39)25.1 (7/22)9.1 (6/35)101(10/23)15.1 (9/26)Alt Alt (Lisp version)cpu sec ( / acts)heuristics:comboadjusum267.1 (/ 18 ) 19.5 (/28 )608 (/ 28) 100.9 (/38)950 (/ 38)~23.6 (/ 40) 1.26 (/ 34)16.7 ( /56) 2.27( / 64)189 (/ 72) 85.0 (/77)6.6 (/ 23)*10.1 (/ 45)6.98 (/45)38.2 (/ 59) 20.9 (/59)7.0 (/127)*28.0 (/511)*33.7 ( / 31) 9.5 ( /39)28.3 (/ 30)5.5 (/ 48)21.1 (/12) 18.9 (/12)Alt Alt17.4 (/14)17.5 (/14)9.9 (/35)8.0 (/37)73 (/48)25.0 (/53)44 (/38)29.0 (/42)722.6 (/ 4)79.6 (/ 4)Alt Alt13.3 (/32)7.1 (/36)17.0 (/34)61.9 (/56)31.5 (/53)80 (/77)49 (/12)123 (/15)Alt Alt1.2 (/33)290 (/61)50.9 (/28)461 (/44)2.0 ( /33)292 ( /45)300 ( / 45)3.1 (/25)5.9 (/ 35)77 (/28)15.4 (/31)Table 5: PEGG state space planner using variations adjusted-sum heuristicPEGG: bounded PE search, best 20% search segments visited search episode, orderedadjusted-sum-u state space heuristicAltAlt: Lisp version, state space planner two effective planning graph distance-basedheuristics: adjusum2 combo (combo results reported problems sinceadjusum2 produces plans competitive PEGG terms makespan.)569fiZIMMERMAN & KAMBHAMPATISurprisingly, majority problems PEGG returns parallel, generally step-optimal plan fasterAltAlt returns serial plan. (AltAlt cannot construct plan parallel actions, however recentwork highly modified version AltAlt does, fact, construct plans -Nigenda & Kambhampati, 2003). PEGG plans also seen comparable length, terms number actions, best AltAlt plans.6. Discussion Resultsdistinguishing feature EGBG PEGG planners relative planners exploitplanning graph, aggressive use available memory learn online episodic searchexperience expedite search subsequent episodes. Although employ search tracestructure log experience, EGBG PEGG systems differ content granularity search experience track aggressiveness use memory. also differconfront common problem faced learning systems; utility learned informationversus cost storing accessing needed.first efforts focused primarily using search trace learn mutex-related redundanciesepisodic search process. Although resulting planners, EGBG me-EGBG, avoid virtually redundant mutex checking based search experience embodied PEs, empiricallyfind limited class problems winning strategy. utility trackingmutex checking experience search function number times informationsubsequently used. Specifically:EPS ( p )6 1) U mt ( p)PEvisit( e)PEadd(e)e =1EPS ( p )e =1where: Umt utility tracking mutex checking experiencep planning problemEPS(p) number search episodes problem pPEvisit (e) number PE search segments visited search episode ePEadd (e)is number new search segments added PE episode eThus payback EGBGs incurred overhead tracing consistency-checking experiencesearch depends number times sets revisited relative total number subgoalsets generated (and added PE) problem run. characteristic explains less2x speedups observed me-EGBG many Table 2 problems. approach handicap single search episode problems. also ineffectual problems final search episode search generates large number states relative previous episodes seed segment(s)top levels PE (due need bottom-up visitation search segments EGBGssearch trace).PE thought snapshot regression search reachable (RS reachable) statessearch episode. is, regression search process generates state level kplanning graph, state reachable search higher levels graph future searchepisodes. Essentially, search segments PE represent RS reachable states,570fispeedup wrt enhanced GraphplanUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHso-PEGG: log1000.0PEGG: logso-PEGG: ztravelPEGG:ztravel100.010.01.010.1234567search episodes problemFigure 12: Speedup vs. number search episodes: Logistics '00 Zenotravel '02 domainscandidate set partial plans segments state current tail state plan. Table 3 5 results indicate utility learning states RS reachable given searchepisode generally outweighs utility learning details episodes consistency-checking,require much less memory. Freed need regenerate RS reachable states IDA* fashion search episode, PEGG visit states heuristically preferred order.Tables 2, 3 5 shed light several classes problems problematic search traceguided search planning graph:1. Domains high branching factors operator descriptions thwart DDB EBL(e.g. larger Schedule, Satellite, Zenotravel domain problems)2. Problems significant fraction runtime consumed planning graph construction.(e.g. Grid domain,, dlog-2-3-6e, freecell-2-1)3. Problems one two search episodes ( grid-y-1, schedule-8-5)problems first class, Graphplan-style CSP assignment search prone boggingcertain PE states selected visitation. second class search timereduction dominated large graph construction time (a problem shared plannerbuilds complete planning graph). Problems third class give PEGG sufficientopportunity exploit PE, since built first episode (and first episode PE typicallysmall) benefit subsequent episodes. aspect PEGGs behavior illustratedFigure 12. speedup factors so-PEGG PEGG (under beam search) plottedseries problems ordered according number search episodes Graphplan would conduct prior finding solution. data gathered running GP-e, so-PEGG, PEGGplanners two different domains (the Logistics domain AIPS-00 planning competition,Zenotravel domain AIPS-02 competition) averaging speedups observedproblems number observed search episodes. downturn PEGG/ Ztravelcurve seven episodes surprising given one problemmany factors beyond number search episodes impact solution time. Noting speed571fiZIMMERMAN & KAMBHAMPATIups plotted logarithmic scale, power search trace given multiple search episode problems evident. PEGG using beam search handily outperforms so-PEGG problems threesearch episodes, largely shortcuts exhaustive search intermediate episodes.several avenues addressing above-listed limitations PEGG explored anticipate investigating. example, unlike N-best first state space planner reportedTable 4, PEGG enforces user-specified limit state f-values selecting PE searchsegments visit. search segment chosen visitation, Graphplan-style regression searchstate goals continues either solution found sub-branches fail. greedyapproach would also apply heuristic bound regression search. is, couldbacktrack whenever state generated exceeds f-value threshold applied search segmentsvisited. translates Greedy Best First Search (GBFS) algorithm employedHSP-r (Bonet & Geffner, 1999) state space search, form hill-climbing search planning graph.Experimentally find PEGG adapted enforce PE state f-value limitregression search, improvements unpredictable best. Speedups factor 100observed cases (all logistics problems) many cases runtimes increased search failedentirely within time limit. addition, quality (make-span) returned solutions sufferedacross broad range problems. two factors may explain result: 1) PEGGs regression search greatly expedited DDB EBL, regressed conflict set relyundefined regression search space state fully explored, fvalue limit enforced. Without conducting search informed basis returning anything full set subgoals state, essentially forces search towards chronological backtracking. 2) Assessing f-value newly generated state compare fvalue bound based states generated previous episodes problematic.heuristic values PE states determine f-value bound increased PEGGs usesearch experience improve h-value estimates (Section 5.1.2).Degradation solution quality shift PEGG closer greedy search approach may indicator PEGGs ability return step-optimal plans (as evidenced Table 3 results) rootedinterleaving best-state selection PE Graphplan-style depth-first searchstates subgoals.7. Related Workfocus related alternative strategies employing search heuristics planning, generating parallel plans, making use memory expedite search. Related work pertainingsearch techniques, efficiencies, data structures enable EGBG PEGG successfullyemploy search trace cited arose considered here.17noted Section 2.2, shortcoming IDA* search (and Graphplan) inadequate useavailable memory: information carried one iteration next upperbound f-value. Exploitation search trace directly addresses shortcoming servingmemory states visited search space previous episode order reduce redun17Support methodologies include memory efficient bi-partite planning graph models, explanation based learning dependency directed backtracking context planning graph search, variable value ordering strategies, evolutionextraction distance-based heuristics planning graph.572fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHdant regeneration. respect PEGGs search closely related methods MREC (Sen,Anup & Bagchi, 1989), MA*, SMA* (Russell, 1992) lie middle groundmemory intensive A* IDA*s scant use memory. central concern algorithmsusing prescribed amount available memory efficiently possible. Like EGBG PEGG,retain much search experience memory permits avoid repeating regeneratingnodes, depend heuristic order nodes memory visitation. Unlike search tracebased algorithms though, three algorithms backup deleted nodes f-value parent node. ensures deleted branch re-expanded promising node remains open list. implemented extended memory management PEGG(though would straight-forward so) primarily because, least beam search, PEGGseldom confronted PE-related memory limitations.EGBG PEGG first planners directly interleave CSP state space views problem search, related approaches synthesize different views planning problem.Blackbox system (Kautz & Selman 1999) constructs planning graph instead exploitingCSP nature, converted SAT encoding extension k-step solutionsought. GP-CSP (Do & Kambhampati, 2000), similarly alternates extending planninggraph converting it, transforms graph CSP format seeks satisfy constraintset search phase.beam search concept employed context propositional satisfiability GSAT (Selman, Levesque, & Mitchell, 1992) option Blackbox planner (Kautz & Selman, 1999).systems greedy local search conducted assessing episode, n-best flipsvariable values randomly generated truth assignment (Where best flips leadgreatest number satisfied clauses). n flips fail find solution, GSAT restarts newrandom variable assignment tries n-best flips. several important differencesrelative PEGGs visitation n-best search trace states. search trace captures state aspect engendered Graphplans regression search problem goals such, PEGG exploitsreachability information implicit planning graph. conducting search purely propositional level, SAT solvers leverage global view problem constraints cannot exploitstate-space information. Whereas GSAT (and Blackbox) improve performance basedexperience one n-best search episode next, PEGG learns variety modes; improving heuristic estimate states visited, reordering state goals based prior search experience, memorizing general no-goods based use EBL.Like PEGG, LPG system (Gerevini & Serina, 2002) heavily exploits structure planning graph, leverages variety heuristics expedite search, generates parallel plans. However,LPG conducts greedy local search space composed subgraphs given length planninggraph, PEGG combines state space view search experience Graphplans CSP-stylesearch graph itself. LPG systematically search planning graph heuristicallymoving extend it, guarantee step-optimality forfeited. PEGG operate eitherstep-optimal mode modes trade optimality speed varying degrees.currently investigating interesting parallel LPGs ability simultaneously considercandidate partial plans different lengths. principle, nothing prevents PEGGsimultaneously considering given PE search segment Sn, terms heuristic rankingstransposed onto various levels planning graph. tantamount simultaneously consider573fiZIMMERMAN & KAMBHAMPATIing arbitrary number candidate partial plans different implied lengths extend first(each partial plan Sn tail state). search trace proves usefulregard state contains transposed desired number levels -subjectability extend planning graph needed- heuristics re-evaluated level. Referring back Figure 4, first search episode pictured (top), YJ state PE couldexpanded multiple distinct states transposing graph level 5 levels 6, 7, higher,heuristically evaluating level. graph-level indexed instances YJsimultaneously compared. Ideally wed like move directly visiting YJ planning graph level 7,since point becomes plan segment problem (bottom graph Figure 4). secondary heuristic discriminate solution potential state sequential levelstransposed to, effective means shortcutting Graphplans level-bylevel search process. flux adjunct likely one key boosting sensitivity distancebased heuristic regard.Generating assessing arbitrarily large number graph-level transposed instances PEstates would prohibitive terms memory requirements store multiple versionsPE. However simply store level-specific heuristic information search segmentssingle PE values indexed associated planning graph levels. Challenging issues includethings range plan lengths considered one time potential planssteps consisting entirely persists actions.havent examined PEGG context real-time planning here, use searchtrace reflects flavor real-time search methods, LRTA* (Korf, 1990)variants B-LRTA* (Bonet, Loerincs, & Geffner, 1997), -a variant applies distance-basedheuristic oriented planning problems. Real-time search algorithms interleave search execution,performing action limited local search. LRTA* employs search heuristic basedfinding less-than-optimal solution improving heuristic estimate series iterations.associates h-value every state estimate goal distance state (similar h-valuesA*). always first updates h-value current state uses h-values successors move successor believed minimum-cost path current state goal.Unlike traditional search methods, act real-time also amortize learning consecutive planning episodes solves planning task repeatedly. allows find suboptimal plan fast improve plan converges minimum-cost plan.Like LRTA*, PEGG search process iteratively improves h-value estimates statesgenerated determines optimal make-span plan. Unlike LRTA*, PEGG doesnt actuallyfind sub-optimal plan first. Instead converges minimum-cost plan either exhaustively extending candidate partial plans monotonically increasing length (so-PEGG) extendingpromising candidates according secondary heuristic (PEGG beam search). realtime version PEGG closely related LRTA* might based method described above,search segments simultaneously transposed onto multiple planning graph levels.mode PEGG would biased search quickly plan length, search anytimefashion progressively shorter length planning graphs lower cost plans.methodology direct relevance work reported elsewhere multi-PEGG(Zimmerman & Kambhampati, 2002; Zimmerman 2003), version PEGG operates anytime fashion, seeking optimize multiple plan quality criteria. Currently multi-PEGG first re-574fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHturns optimal make-span plan, exploits search trace novel way efficientlystream plans monotonically improve terms quality metrics. discussed paper,important step away multi-PEGGs bias towards make-span plan quality metric wouldmodification. Co-mingling versions state transposed onto multiple planninggraph levels would enable planner concurrently consider visitation candidate search segments might seed segments latent plans various lengths.8. Conclusionsinvestigated presented family methods make efficient use available memorylearn different aspects Graphplans iterative search episodes order expedite searchsubsequent episodes. motivation, design, performance four different planners buildexploit search trace described. methods differ significantly either informationcontent trace manner leverage it. However, cases high-levelimpact transform IDA* nature Graphplans search capturing aspect searchexperience first episode using guide search subsequent episodes, dynamically updating along way.EGBG planners employ aggressive mode tracing search experience PEGGplanners. track use action assignment consistency checking performed searchsubgoal set (state) minimize effort expended state next visited. EGBG approach found memory intensive, motivating incorporation variety techniquesplanning CSP fields which, apart well-known speedup benefits, showndramatic impact search trace planning graph memory demands. resulting planner,me-EGBG, frequently two orders magnitude faster either standard Graphplan EGBGproblems handle, generally fastest guaranteed step-optimal approachesinvestigated. comparisons GP-e, version Graphplan enhanced space savingspeedup techniques, me-EGBG solves problems average 5 times faster.PEGG planners adopt skeletal search trace, design conducive informed traversal search space. Ultimately proves powerful approach exploitingepisodic search experience. adapt distance-based, state space heuristics support informed traversal states implicit search trace describe metric call flux effectivelyfocuses search states worth visiting. flux measure sensitive potential searchtrace state seed new search branches transposed higher planning graph levels. alsodescribe new techniques leverage search experience captured search tracedemonstrate effectiveness.so-PEGG planner, like me-EGBG, produces guaranteed optimal parallel plans similarlyaverages 5x speedup GP-e. greatly reduced memory demands allow so-PEGG handlesone 16 problems me-EGBG exceeds available memory. compelling evidence speedup potential search trace guided planner provided PEGG beamsearch. Since longer exhaustively searches planning graph episode, PEGG sacrificesguarantee returning optimal make-span plan. Nonetheless, even beam search limitedbest 20% PE states episode, PEGG returns step-optimal plan almost 90%test bed problems comes within steps optimal others. speedups575fiZIMMERMAN & KAMBHAMPATIranging almost two orders magnitude GP-e, quite competitively modern statespace planner (which finds serial plans).code PEGG planners (including GP-e) instructions running variousmodes available download http://rakaposhi.eas.asu.edu/pegg.htmlAcknowledgementsresearch improved many discussions Binh Minh Do, XuanLong Nguyen, RomeoSanchez Nigenda William Cushing. Thanks also David Smith anonymous reviewers,whose copious suggestions greatly improved presentation paper. research supportedpart NSF grants IRI-9801676 IIS-0308139, DARPA AASERT Grant DAAH04-96-10247 NASA grants NAG2-1461 NCC-1225.Appendix A: EGBG Plannerinsight behind EGBGs use search trace based characterization Graphplanssearch given beginning Section 3.1 entailed observations:Observation A-1) intra-level CSP-style search process conducted Graphplan set propositions (subgoals) , planning graph level k+1 episode n+1 identical search processlevel k episode n IF:1. mutexes pairs actions establishers propositions level k remainmutex level k+1. (this concerns dynamic mutexes; static mutexes persist definition)2. actions establishing proposition level k+1 also present level k.Observation A-2) trace Graphplans search episode n+1, set goals G, planninggraph level m+1, identical episode n search level IF:1. two conditions observation A-1 hold every subgoal set (state) generated Graphplanepisode n+1 regression search G.2. every subgoal set planning graph level j search episode n matchinglevel j memo, exists equivalent memo level j+1 generated episode n+1.Conversely, every subgoal set level j search episode n matching level j memoexisted time generated, also matching memo level j+1 time generated episode n+1.Now, suppose search trace states (including no-good states) generated Graphplans regression search problem goals planning graph level episode n. searchfailed extract solution m-length planning graph (i.e. reach initial state), necessary condition extract solution m+1 length graph one conditionsobservations A-1 A-2 fails hold states episode n search trace.observations A-1 A-2 mind, exploit search trace new episodesound complete manner focusing search effort three situations could leadsolution: 1) state variables newly extended value ranges (i.e. search segment goalsleast one new establishing action newly associated graph level), 2) points previous search episode backtracked due violation dynamic constraint (i.e. two actions576fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHWnop a1OK OK17nop a3OK SMnop a3OK SM2nop a1OK OKH368nop a3 a1OK SM OK4 nop a55JDM SMnop a5 nop a5DM SM DM SMnop a5DM SMFigure A1: Bit vector representation search trace WYHIJ state Figure 3.Semantics: OK > assigned (no action conflicts) SM > action static mutex previous assignDM > action dynamic mutex previous assignNG > no-conflict action results no-good state lower graph leveldynamic mutex), 3) states matched cached memo episode n. assignment mutex checking operations involved satisfying set subgoals static across searchepisodes.experimented several search trace designs capturing key decision points. designadopted EGBG employs ordered sequence bit vectors, vector contains resultsGraphplans CSP-style action assignment process related given subgoal search segment.Efficient action assignment replay possible trace uses vectors two-bit tags representfour possible assignment outcomes: 1) dynamic mutex, 2) static mutex, 3) conflict, 4) complete, consistent set assignments rejected next level due memoized no-good. Figure A1 illustrates sequence eight bit vectors used capture search experience search segment state goals WYHIJ Figure 3 Alpha problem. propositional goals (the variables) appear left sets bit vectors (depicted segmented bars)encode outcome possible action assignment (the values). possible establishingaction goal appears bit vector tag.numbered edges reflect order trace vectors initially created firstgoal action tried. Note whenever candidate action goal conflict free respectpreviously assigned actions (indicated OK figure), action checking goal suspended, process jumps next goal, new bit vector initialized goals possibleestablishers. edge numbering also reflects order vectors poppedsearch segment trace list segment revisited next episode. scheme work,bit vectors must pushed onto search segment trace list actions goal tried,reverse numbered edge order. Long edges skip one goals indicategoals already established previously assigned actions.long order actions appearing establishers list planning graph proposition remains constant, bit vectors used replay search next episode nexthigher planning graph level. graph building routine EGBG enforces constraint.577fiZIMMERMAN & KAMBHAMPATIEGBG Algorithmhigh-level EGBG algorithm given Figure A2. Graphplan, search planninggraph occurs extended level problem goals first appearbinary mutex conditions. (the call find_1st_level_with_goals). first search episode conductedGraphplan fashion except assign_goals routines Figure A3 create search segmentshold states trace information generated regression search process. necessarytrace information search segment captured trace vectors described above. segments stored PE structure indexed according level generated(where current highest planning graph level corresponds 0 contains problem goals).Subsequent first episode, EGBG_plan enters outer loop employs PE conductsuccessive episodes (Referred search trace guided). search strategy alternatesselection visitation promising state trace previous experience (select_searchseg_from_PE routine), focused CSP-type search states subgoals (the replay_trace_goals assign_goals routines Figures A3 A4).episode, inner loop visits PE search segments level-by-level, bottom-up fashion(for reasons discussed Section 3). extend_plangraph routine called statevisited corresponds level beyond current graph length.replay_trace_goals routine counterpart Graphplans assign_goals routine, exceptavoids latters full-blown mutex checking stepping trace vectors capturedprevious search experience given state. Unlike assign_goals, branch childstates already contained PE. conditional checking trace vectors establishingactions initiates new search calling assign_goals two conditions: 1) dynamic mutexesprevious episodes longer hold 2) new establishing actions appear subgoal (Thesetried establishers replayed.) dynamic mutex longer holds newestablishing action considered trace vector modified accordingly EGBG resumes Graphplans CSP-style search, adding new trace vectors search segment process.578fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHEGBG-PLAN ( Ops, Init, Goals) /* {Ops,Init,Goals} planning problem *//* build plangraph, PG, level n goals first occur non-mutex state*/Let PG find_1st_level_with_goals( Ops, Init, Goals )PG reached level-off goals present non-mutex state Return FAILLet n number levels PGLet SS0 new search segment fields:goalsGoals, parentroot, PE-level 0, parent-actions {} trace {}Let PE pilot explanation structure fields hold search segments plangraph levelPE[0] {SS0} /* 0 top level PE *//* Conduct Graphplan-style backward search n-length plangraph, store trace PE...*/Let search-reslt assign_goals(Goals, {}, n, SS0, PG, PE)search-reslt search segment /* Success */Plan extract plan actions ancestors linked search-resltReturn Planelse /* n-length solution possible ...use PE search longer length solution */loop forevern n+1loop pe-lev ranging number deepest level PE 0 (top level)let k planning graph level associated PE level pe-lev= n pe-lev /* ..essentially translates PE one planning graph level */pe-lev = 0 PG extend_plangraph(PG) /*.. must extend plangraph point */loop search segments PE[pe-lev]SS select_searchseg_from_PE[pe-lev]SSassigns SS<trace> /* get ordered, goal-by-goal trace vectors search segment */SS<trace> {} /* Clear search segment trace vectors field */SS<goals> memos(k, PG) /*check nogoods level k */goals match nogood level, loop next search segmentelse /* use SS trace avoid redundant search effort SS goals.. */search-reslt replay_trace_goals (SS<goals>, {}, k, SSassigns, SS, PG, PE)search-reslt search segmentPlan extract plan actions ancestors linked search-resltReturn Planelse Add SS<goals> memos(k, PG) /*memoize nogood */end loop (search segments)end loop (PE levels)end-loop (PG level)endFigure A2: EGBG planner top level algorithm579fiZIMMERMAN & KAMBHAMPATIConduct Graphplan-style search subgoal set planning graph level karguments> G: goals still assigned, A: actions already assigned, k: PG level,SS1: search segment, PG: planning graph, PE: pilot explanation (search trace)ASSIGN_GOALS (G, A, k, SS1, PG, PE)G empty k = 0 (the initial state) Return SS1 /* Success */else /* goals left satisfy*/Let g-assigns ={} /* trace vector hold ordered action assignment tags */Let g goal selected GLet Ag = actions PG level k support g, ordered value-ordering heuristicloop act AgLet search-reslt = {}action dynamic mutex act append dm tag g-assignselse action static mutex act append sm tag g-assignselse /* act conflict actions already */G empty/* done G goals, setup search next lower level */search-reslt assign_next_level_goals (A U{act}, k, SS1, PG, PE)search-reslt nogood append ng tag g-assignselse append ok tag g-assigns /* search occurred lower level */else /* search continues level next goal */append ok tag g-assignssearch-reslt assign_goals (G-{g}, U{act}, k, SS1, PG, PE)end-ifsearch-reslt search segment Return search-reslt /* Success *//* else loop try another action*/end-ifend loop (actions)push g-assigns trace field SS1Return nil /* solution found */end-ifend/*add trace data search segment */Setup search graph level k-1 given actions satisfy goals SS1 level kASSIGN_NEXT_LEVEL_GOALS (A, k, SS1, PG, PE)Let nextgoals regress SS1 goals assigned actionsnextgoals memos PG level k-1 Return nogood /* backtrack nogood goals */else /* initiate search next lower PG level*/Let SS2 new search segment fields:goalsnextgoals, parentSS1, parent-actionsA, trace{}Add SS2 PE level: (maximum PG level) (k-1)Let search-reslt assign_goals (nextgoals, {}, k-1, SS2, PG, PE)search-reslt nil /* search level k-1 failed */Add nextgoals memos level k-1 PG /*memoize nogood */Return search-resltend-ifendASSIGN_NEW_ACTIONS (G, A, Ag, g, g-assigns, k, SS, PG, PE)/* Routine essentially assign_goals, except attempts satisfy goal g actionsnew actions (i.e. first appearing recent plangraph extension */Figure A3: EGBGs non-guided regression search algorithm580fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHRegression search using search trace (PE) replayarguments> G: goals still assigned, A: actions already assigned, k: PG level,SS1: search segment, PG: planning graph, PE: pilot explanation (search trace)REPLAY_TRACE_GOALS (G, A, k, SS1, PG, PE)G empty /* SS1 goals branch successfully assigned last episode...*/Return /* .. continue level k replay, ignoring search replay next lower level */else /* goals left satisfy*/Let g select goal GLet g-assigns pop front trace vector SS<trace>Let Ag set actions level k PG support g/* replay assignments g previous episode, rechecking may changed..*/loop tag g-assignsLet search-reslt {}, Let act pop action Agtag = ok /* act conflict actions last episode.. go next goal */search-reslt replay_trace_goals (G-{g}, U{act}, k, SSassigns, SS1, PG, PE)else-if tag =ng loop /* last action assign level & act mutex lastepisode --So next-level regressed goals reside child search segment already visited */else tag = sm loop /* act static mutex action last episode */else tag = dm /* act dynamic mutex action last episode retest it...*/dynamic mutex persists loopelse change tag ok g-assigns vector /* act longer mutex actions */G-{g} empty /* resume backward search level */search-reslt assign_goals (G-{g}, U{act}, k, SS1, PG,PE)else /* goals left satisfy SS1, setup search lower level */search-reslt assign_next_level_goals (A U{act}, k, SS1, PG, PE)search-reslt =nogood change g-assigns vector tag ngend-ifsearch-reslt search segment Return search-reslt (Success)else loop (check next action)end-loop /* establishment possibilities prior episode tried ..Now check new actions */Ag still contains actions /* new actions establishing g level .. attempt assign */search-reslt assign_new_actions(G, A, Ag, g, g-assigns, k, SS1, PG, PE)search-reslt search segment Return search-reslt /* Success */else push g-assigns SS1<trace>Return nil /* solution found search stemming SS1 goals */end-ifendFigure A4: EGBGs search-trace guided algorithm581fiZIMMERMAN & KAMBHAMPATIAppendix B: Exploiting CSP Speedup Methods Reduce Memory DemandsBackground implementation details provided six techniques planningCSP fields proved key controlling memory demands search trace basedplanners. variable ordering, value ordering, explanation based learning (EBL), dependencydirected backtracking (DDB), domain preprocessing invariant analysis, replacing redundant multi-level planning graph bi-partite version.Domain preprocessing invariant analysis:speedups attainable preprocessing domain problem specifications welldocumented (Fox & Long, 1998; Gerevini & Schubert, 1996). Static analysis prior planningprocess used infer certain invariant conditions implicit domain theory and/or problemspecification. domain preprocessing me-EGBG PEGG fairly basic, focusing identification extraction invariants action descriptions, typing constructs, subsequent rewritedomain form efficiently handled planning graph build routines. implementation discriminates static (or permanent) mutex relations dynamic mutex relations(in mutex condition may eventually relax) actions proposition pairs. information used expedite graph construction me-EGBGs replay action assignments search segment visited.Domain preprocessing significantly reduce memory requirements extent identifiespropositions need explicitly represented level graph. (Examplesterms extracted action preconditions -and hence get explicitly representedplanning graph levels- include (SMALLER ?X ?Y) term MOVE action towers Hanoi domain typing terms (AUTO ?X) (PLACE ?Y) logistics domains.) benefitcompounded EGBG PEGG since propositions removed action preconditions directly reduce size subgoal sets generated regression search episodes,hence size search trace.Bi-partite planning graph:original Graphplan maintains level-by-level action, proposition, mutex informationdistinct structures level, thereby duplicating -often many times over- information contained previous levels. multi-level planning graph efficiently represented indexedtwo-part structure finite differencing techniques employed focus aspectsgraph structure possibly change extension. leads rapid constructionconcise planning graph (Fox & Long 1998; Smith & Weld, 1998).me-EGBG PEGG, bi-partite graph offers benefit beyond reduced memory demands faster graph construction time; PE transposition process described section 3.1 reduced simply incrementing search segments graph level index. straightforwardmulti-level graph built Graphplan, since proposition (and action) referencedsearch segments unique data structure itself.Explanation Based Learning Dependency Directed Backtracking:application explanation based learning (EBL) dependency directed backtracking (DDB)investigated preliminary way (Zimmerman & Kambhampati, 1999), primaryinterest speedup benefits. techniques shown result modest speedups582fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHseveral small problems complexity integrating maintenance PE replayvectors limited size problem could handled. since succeeded implementingrobust version methods, results reported reflect that.EBL DDB based explaining failures leaf-nodes search tree, propagating explanations upwards search tree (Kambhampati, 1998). DDB involves using propagation failure explanations support intelligent backtracking, EBL involvesstoring interior-node failure explanations, pruning future search nodes. approach implements complimentary techniques Graphplan reported (Kambhampati, 2000)speedups ranged ~2x blocksworld problems ~100x ferry domain problems.refer study full description EBL/DDB Graphplan context, note aspects particularly relevant me-EGBG PEGG.conflict directed back-jumping (Prosser, 1993), failure explanations compactly represented terms conflict sets identify specific action/goal assignments gave risebacktracking. liberates search chronological backtracking, allowing jump backrecent variable taking part conflict set. attempts satisfy set subgoals (astate) fail, conflict set regressed back represents useful minimal no-good memoization. (See PEGG algorithm Figures 8 9 depiction process.) conflict setmemo usually shorter hence general one generated stored standardGraphplan. Additionally, EBL-augmented Graphplan generally requires less memory memocaches.Less obvious speedup benefit perhaps, role EBL DDB often play dramatically reducing memory footprint pilot explanation. Together EBL DDB shortcutsearch process steering away areas search space provably devoid solutions.Search trace memory demands decrease proportionally.me-EGBG PEGG outfitted EBL/DDB non-PE directed Graphplan-style search. me-EGBG however, use EBL/DDB replay action assignment results PE search segment due complexity retract parts assignmentvectors whenever conflict set new episode entails new replay order.Value Variable Ordering:Value variable ordering also well known speedup methods CSP solvers. contextGraphplans regression search given planning graph level k, variables regressed subgoals values possible actions give propositions level k graph.original paper, Blum Furst (1997) argue variable value ordering heuristicsparticularly useful improving Graphplan, mainly exhaustive search required levelssolution bearing level anyway. Nonetheless, impact dynamic variable ordering(DVO) Graphplan performance examined (Kambhampati, 2000), modest speedupsachieved using standard CSP technique selecting assignment subgoal (variable)least number remaining establishers (values). impressive results reportedlater study (Nguyen & Kambhampati, 2000) distance-based heuristics rooted planninggraph exploited order subgoals goal establishers. configuration, Graphplanexhibits speedups ranging 1.3 100x, depending particular heuristic problem.583fiZIMMERMAN & KAMBHAMPATIstudy fix variable ordering according adjusted sum heuristic value orderingaccording set level heuristic, found combination reasonably robust acrossrange test bed problems. heuristics described Section 5 useddirect traversal PE states discussed. Section 4.1 describes highly problem-dependentperformance distance-based variable value ordering search trace-based planners.manner EGBG/PEGG builds maintains planning graph search tracestructures actually reduces cost variable value ordering. default order Graphplan considers establishers (values) satisfying proposition (variable) given level setorder appear planning graph structure. graph construction me-EGBGPEGG set order correspond desired value ordering heuristic, ordering computed once. part, PE constructed search recordheuristically-best ordering regression states goals, variable ordering also donegiven state. contrasts versions Graphplan outfittedvariable value ordering (Kambhampati, 2000) ordering reassessed time stateregenerated successive search episodes.ReferencesBlum, A. & Furst, M.L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90(1-2).Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanismplanning. Proceedings AAAI-97.Bonet, B. & Geffner, H. (1999). Planning heuristic search: New results. ProceedingsECP-99.Do, M.B. & Kambhampati, S. (2000). Solving Planning-Graph compiling CSP.Proceedings AIPS-00.Fox, M., & Long, D. (1998). automatic inference state invariants TIM. JournalArtificial Intelligence Research, 9, 317-371.Frost, D. & Dechter, R. (1994). search best constraint satisfaction search. ProceedingsAAAI-94.Gerevini , A., & Schubert, L. (1996). Accelerating Partial Order Planners: techniqueseffective search control pruning. Journal Artificial Intelligence Research 5, 95-137.Gerevini, A. & Serina, I., (2002). LPG: planner based local search planning graphsaction costs. Proceedings AIPS-02.Haslum, P., & Geffner, H. (2000). Admissible Heuristics Optimal Planning. Proceedings.AIPS-00.Hoffman, J. (2001) heuristic domain independent planning use enforced hillclimbing algorithm. Technical Report No. 133, Albert Ludwigs University.Kambhampati, S. (1998). relations Intelligent Backtracking Failure-drivenExplanation Based Learning Constraint Satisfaction Planning. Artificial Intelligence,105(1-2).Kambhampati, S. (2000). Planning Graph (dynamic) CSP: Exploiting EBL, DDBCSP search techniques Graphplan. Journal Artificial Intelligence Research, 12, 1-34.Kambhampati, S. & Sanchez, R. (2000). Distance-based Goal-ordering heuristics Graphplan.Proceedings AIPS-00.584fiUSING MEMORY TRANSFORM SEARCH PLANNING GRAPHKambhampati, S., Parker, E., & Lambrecht, E. (1997). Understanding extending Graphplan.Proceedings ECP-97.Kautz, H. & Selman, B. (1996). Pushing envelope:stochastic search. Proceedings AAAI-96.Planning, prepositional logicKautz, H. & Selman, B. (1999). Unifying SAT-based Graph-based Planning. ProceedingsIJCAI-99, Vol 1.Koehler, D., Nebel, B., Hoffman, J., & Dimopoulos, Y., (1997). Extending planning graphsADL subset. Proceedings ECP-97, 273-285.Korf, R. (1985). Depth-first iterative-deepening: optimal admissible tree search. ArtificialIntelligence, 27(1), 97-109.Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42, 189-211.Long, D. & Fox, M. (1999). Efficient implementation plan graph STAN. JournalArtificial Intelligence Research, 10, 87-115.Mittal, S., & Falkenhainer, B. (1990). Dynamic constraint satisfaction problems. ProceedingsAAAI-90.McDermott, D. (1999). Using regression graphs control search planning. ArtificialIntelligence, 109(1-2), 111-160.Nigenda, R., & Kambhampati, S. (2003). AltAltp: Online Parallelization Plans HeuristicState Search. Journal Artificial Intelligence Research, 19, 631-657.Nguyen, X. & Kambhampati, S. (2000). Extracting effective admissible state space heuristicsplanning graph. Proceedings AAAI-00.Prosser, P. (1993). Domain filtering degrade intelligent backtracking search. ProceedingsIJCAI-93.Russell, S.J., (1992). Efficient memory-bounded search methods. Proceedings ECAI 92.Sen, A.K., & Bagchi, A., (1989). Fast recursive formulations best-first search allowcontrolled use memory. Proceedings IJCAI-89.Selman, B, Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiabilityproblems. Proceedings AAAI-92.Smith, D., Weld, D. (1998). Incremental Graphplan. Technical Report 98-09-06. Univ. Wash.Srivastava, B., Nguyen, X., Kambhampati, S., Do, M., Nambiar, U. Nie, Z., Nigenda, R.,Zimmerman, T. (2001). AltAlt: Combining Graphplan Heuristic State Search. AIMagazine, 22(3), American Association Artificial Intelligence, Fall 2001.Zimmerman, T. (2003). Exploiting memory search high quality plans planninggraph. PhD dissertation, Arizona State University.Zimmerman, T. & Kambhampati, S. (1999). Exploiting Symmetry Planning-graph viaExplanation-Guided Search. Proceedings AAAI-99.Zimmerman, T., Kambhampati, S. (2002). Generating parallel plans satisfying multiple criteriaanytime fashion. Proceedings workshop Planning Scheduling MultipleCriteria, AIPS-02.Zimmerman, T. & Kambhampati, S. (2003). Using available memory transform Graphplanssearch. Poster paper Proceedings IJCAI-03.585fiJournal Artificial Intelligence Research 23 (2005) 331 -- 366Submitted 06/04; published 03/05Learning Labeled Unlabeled Data: Empirical StudyAcross Techniques DomainsNitesh V. ChawlaDepartment Computer Science & Engg.,University Notre Dame,46556, USAGrigoris KarakoulasDepartment Computer ScienceUniversity TorontoToronto, OntarioCanada M5S 1A4NCHAWLA@CSE.ND.EDUGRIGORIS@CS.TORONTO.EDUAbstractincreased interest devising learning techniques combine unlabeled datalabeled data i.e. semi-supervised learning. However, best knowledge, studyperformed across various techniques different types amounts labeledunlabeled data. Moreover, published work semi-supervised learning techniquesassumes labeled unlabeled data come distribution. possiblelabeling process associated selection bias distributions data pointslabeled unlabeled sets different. correcting bias result biased functionapproximation potentially poor performance. paper, present empirical studyvarious semi-supervised learning techniques variety datasets. attempt answer variousquestions effect independence relevance amongst features, effect sizelabeled unlabeled sets effect noise. also investigate impactsample-selection bias semi -supervised learning techniques study implementbivariate probit technique particularly designed correct bias.1. Introductionavailability vast amounts data applications made imperative need combineunsupervised supervised learning (Shahshahni & Landgrebe, 1994; Miller & Uyar, 1997;Nigam et al., 2000; Seeger, 2000; Ghani et al., 2003). cost assigning labelsdata expensive, and/or data might labels due selectionbias. applications include, limited to, text classification, credit scoring, fraudintrusion detection. underlying challenge formulate learning task useslabeled unlabeled data generalization learned model improved.recent years various techniques proposed utilizing unlabeled data (Miller &Uyar, 1997; Blum & Mitchell, 1998; Goldman & Zhou, 2000; Nigam et al., 2000; Blum & Chawla,2001; Bennett et al., 2002; Joachims, 2003). However, best knowledge,empirical study evaluating different techniques across domains data distributions. goal2005 AI Access Foundation. rights reserved.fiCHAWLA & KARAKOULASpaper examine various scenarios dealing labeled unlabeled data conjunctionmultiple learning techniques.Incorporating unlabeled data might always useful, data characteristics and/ortechnique particulars might dictate labeled data sufficient even presencecorpus unlabeled data. conflicting experiences reported literature.one hand, NIPS01 competition semi-supervised learning required contestants achievebetter classification results cases supervised learning (Kremer & Stacey,2001). implies expectation cases semi-supervised techniques could help.However, results competition meet expectation. ShahshahniLandgrebe (1994) note unlabeled data delay occurrence Hughes phenomenonclassif ication performance improved. Zhang Oles (2000), using FisherInformation criterion, show parametric models unlabeled data always help.hand, Cozman et al. (2002; 2003), using asymptotic analysis, show unlabeled datafact decrease classification accuracy. concluded modeling assumptions labeleddata incorrect, unlabeled data would increase classification error, assuming labeledunlabeled data come distribution. formulate asymptoticbehavior semi-supervised techniques scenarios labeled unlabeled data comedifferent distributions. addition, evaluate algorithm one real dataset,varying amount labeled unlabeled data.aforementioned semi-supervised learning techniques distinguish differentreasons data missing. techniques assume data missingcompletely random (MCAR), i.e. P(labeled=1| x, y) = P(labeled=1) class labelassigned labeled=1 given example labeled (Little & Rubin, 1987). caselabeling process function variables occurring feature space. labeledunlabeled data assumed come distribution.labeling process function feature vector x class label missingrandom (MAR), i.e. P(labeled=1| x, y) = P(labeled=1|x). scenario MAR labeling occur,example, credit scoring applications since many creditors use quantitative modelsapproving customers. case class label observed (deterministic) functiong variables x exceeds threshold value, i.e. g(x)c, c constant.definition MAR follows P(y=1| x, labeled=1) = P(y=1| x, labeled=0)=P(y = 1|x), i.e.fixed value x distribution observed distribution missingy. However, due aforementioned screening, conditional distribution x givenlabeled unlabeled data, i.e. bias. Thus, modeling techniques aimlearn conditional distributions one needs correct bias incorporating informationunlabeled data.contrast, labeling depends y, class label missing random (MNAR), i.e.P(labeled=1| x, y) P(labeled=0| x, y). case sample-selection bias constructinglabeled set corrected (Heckman, 1979). example, sample -selection biasoccur credit scoring applications selection (approval) customers (labels)performed based human judgment rather deterministic model (Greene, 1998; Crook &Banasik, 2002; Feelders, 2000). Sample -selection bias also occur datasets marketing332fiLearning Labeled Unlabeled Datacampaigns. MNAR scenario labeled unlabeled data come different distributionsassociated censoring mechanism, i.e. P(y=1| x, labeled=1) P(y=1| x, labeled=0).scenario learning labeled data give estimates biased downwards.selection bias associated labeling process necessary model underlying missingdata mechanism. Shahshahani Landgrebe (1994) also note training samplerepresentative distribution population unlabeled data might help.paper present empirical study existing techniques learninglabeled unlabeled data three different missing data mechanisms, i.e. MCAR, MARMNAR. best knowledge, effect unlabeled data different missing datamechanisms previously addressed semi-supervised learning literature. alsointroduce two techniques Econometrics, namely reweighting bivariate probit,semi-supervised learning. try answer various questions important learninglabele unlabeled datasets, as:process data become labeled vs. unlabeled?many unlabeled vs. labeled examples dataset?effect label noise semi-supervised learning techniques?characteristics feature space dictate successfulcombination labeled unlabeled data?effect sample-selection bias semi-supervised learning methods?experiments chosen datasets unbalanced class distributions, sincetypical real-world applications unlabeled data, information filtering, creditscoring, customer marketing drug design. datasets, accuracy misleadingmetric treats kinds errors, false positives false negatives, equally. Thus, useAUC, Area Receiver Operating Curve (ROC), performance metric (Swets, 1988;Bradley, 1987). AUC become popular performance measure learning unbalanceddatasets (Provost & Fawcett, 2000; Chawla et al., 2002).paper organized follows. Section 2 present overview techniquesevaluated work. techniques mainly applicable MCAR MAR typedata. Section 3 present two techniques purport deal sample -selection biasMNAR data. Section 4 describe experimental framework Section 5 analyzeresults experiments. conclude paper discussion main findings.2. Semi-Supervised Learning Methodstechniques evaluate learning labeled unlabeled data are: Co-training (Blum &Mitchell, 1998; Goldman & Zhou, 2000), Reweighting (Crook & Banasik, 2002), ASSEMBLE(Bennett et al., 2002) Common-component mixture EM (Ghahramani & Jordan, 1994;Miller & Uyar, 1997). chose variant co-training algorithm proposed GoldmanZhou (2000) since make assumption redundant independent views data.datasets considered, "natural" feature split would offerredundant views. One could try random feature split, in-lineoriginal assumption Blum Mitchell (1998). Essentially, two different algorithms looking333fiCHAWLA & KARAKOULASdata potentially provide better random information processlabeling. construction, co-training ASSEMBLE assume labeled unlabeled datasampled distribution, namely based MCAR assumption.re-weighting common-component mixture techniques based assumption dataMAR type. Thus, applied cases conditional distribution x givenlabeled unlabeled data. Details techniques given restSection.sample -selection correction MNAR data use Bivariate Probit technique(Heckman, 1979; Greene, 1998) Sample -Select, adapted version technique usedZadrozny Elkan (2000). techniques presented Section 3.worth pointing selected popular algorithms learninglabeled unlabeled data. However, list algorithms study meantexhaustive. main goal evaluate behavior algorithmsdifferent amounts, distributions, characteristics labeled unlabeled data.used Nave Bayes algorithm underlying supervised learneraforementioned semi-supervised learning methods. chose Nave Bayes due popularitysemi-supervised learning framework well need generative modelcommon-component mixture technique. Thus, choice base learner helped us achieveconsistency comparability experimental framework. co-trainingexperiments, design require two classifiers, also used C4.5 decision tree release 8(Quinlan, 1992). Please note rest paper, use Nave Bayes supervisedlearner, interchangeably.next introduce notation used describing various methods paper.Consider classification problem K classes k , k = 0,1,...,K 1 . assumetraining set consists two subsets: X = {X L , X U } ,X L = {( x1 , y1 ), ( x2 , 2 ),..., ( xl , yl )} labeled subset,X U = {xl +1 , x l + 2 ,..., xl + u } unlabeled subset,l u number examples labeled unlabeled sets, respectively,x n-dimensional feature vector.2.1 Co-trainingCo-training, proposed Blum Mitchell (1998), assumes exist two independentcompatible feature sets views data. is, feature set (or view) defining problemindependently sufficient learning classification purposes. instance, web pagedescription partitioned two feature subsets: words exist web page wordsexist links leading web page. classifier learned redundantfeature subsets used label data thus expand others training set.informative assigning random labels unlabeled data. However,real-world application, finding independent redundant feature splits unrealistic,lead deterioration performance (Nigam & Ghani, 2001).Goldman Zhou (2000) proposed co-training strategy assume featureindependence redundancy. Instead, learn two different classifiers (using two different334fiLearning Labeled Unlabeled Datasupervised learning algorithms) dataset. idea behind strategy since twoalgorit hms use different representations hypotheses learn two diverse modelscomplement labeling unlabeled data enlarging training setother. Goldman Zhou derive confidence intervals deciding unlabeled examplesclassifier label. adopt co-training strategy allows us apply variousreal-world datasets thus compare semi-supervised learning techniques.illustration purposes, let us assume two classifiers B. labels data B,B labels data unlabeled data left none labeled due lackenough confidence label. decision label data classifier takenbasis statistical techniques. Following Goldman Zhou (2000) construct confidenceintervals B using 10-fold cross-validation. Let lA , lB , h , h B , lower upperconfidence intervals B, respectively. Additionally, upper lower confidenceintervals class k defined lAk, h Ak, l Bk, h Bk. intervals define confidenceassigned classifiers labeling mechanism. addition, amount datalabeled subject noise control mechanism.Let us consider co-training round labeling data B (the followsimilarly). Let XL original labeled training set (which B), XLB datalabeled B, wB conservative estimate mislabeling errors XLB , = |XL XLB |sample size, = wB /|XL XLB | noise rate. relationship samplesize m, classification noise rate , hypothesis error givenm=k2 (1 2 ),k constant, assumed 1relationship used decide amount additional data labeled compensateincrease classification noise rate. Thus, based expressions ,conservative estimate 1/ 2 classifier B, q B , givenq B = X L X LB12wB2X L X LB2Similarly, compute conservative estimate 1/2 , qk, class k labeled set:q k = X L X LB X Uk2( w B + w k )1X L X LB X Uk2,| X Uk | = Examples X U mapped class kw k = (1 l k ) | X Uk |335fiCHAWLA & KARAKOULASThus, classifier labeling process consists two tests:(i)(ii)h Ak > lBq k > qBfirst test ensures class k used classifier label data accuracy leastgood accuracy classifier B. second test help prevent degradation performanceclassifier B due increased noise labels. unlabeled examples satisfy criteriala beled classifier classifier B vice versa. process repeatedunlabeled examples satisfy criteria either classifier. end co-training procedure(no unlabeled examples labeled), classifiers learned corresponding final labeled setsevaluated test set.experiments used two different classification algorithms Nave Bayes C4.5decision tree. modified C4.5 decision tree program convert leaf frequenciesprobabilities using Laplace correction (Provost & Domingos, 2003). final prediction,probability estimates Nave Bayes C4.5 averaged.2.2 ASSEMBLEASSEMBLE algorithm (Bennett et al., 2002) NIPS 2001 Unlabeled data competition.intuition behind algorithm one build ensemble works consistentlyunlabeled data maximizing margin function space labeled unlabeled data.allow margin used labeled unlabeled data, Bennett et al. introduceconcept pseudo-class. pseudo-class unlabeled data point definedpredicted class ensemble point. One variations ASSEMBLE algorithmbased AdaBoost (Freund & Schapire, 1996) adapted case mixture labeledunlabeled data. used ASSEMBLE.AdaBoost algorithm used authorsNIPS Challenge.ASSEMBLE.AdaBoost starts procedure assigning pseudo-classes instancesunlabeled set, allows supervised learning procedure algorithm applied. initialpseudo-classes assigned using 1-nearest-neighbor algorithm, ASSEMBLE-1NN,simply assigning majority class instance unlabeled datasets, ASSEMBLE-Class0.treat majority class class 0 minority class class 1 datasets. sizetraining set boosting iterations size labeled set. Figure 1 showspseudo code ASSEMBLE.AdaBoost algorithm.pseudo code, L signifies labeled set, U signifies unlabeled set, l (size labeledset) sample size within iteration weight assigned labeled unlabeled datadistribution D0 . initial misclassification costs biased towards labeled data, dueconfidence labels. subsequent iterations algorithm, a, indicates relativeweight given type error either labeled data unlabeled data error. pseudo-code,f indicates supervised learning algorithm, Nave Bayes experiments. indicatesnumber iterations, f (xi ) = 1 instance xi correctly classified f (xi ) = -1,incorrectly classified; error computed iteration t, Dt samplingdistribution.336fiLearning Labeled Unlabeled Data1. l :=| L | u :=| U |/ l2. D1 ( i) :=(1 ) / lLU3. yi := c, c class 1NN U class 0 U,original class L4. f 1 = NaiveBayes (L + U)5. := 16. Let := f (x ), = 1,..., L + U7. = Dt [yi i], = 1,..., L + U8. > 0.5 Stop1 -9. w = 0.5 * log10. Let Ft := Ft -1 + w f11. Let = Ft (x ) U12. Dt +1 =e yi Ft +1 ( xi )eyi Ft +1 ( xi )13. = Sample(L + U, Y, Dt + 1)14. f +1 = NaiveBayes (S)15. end16. return Ft+1Figure 1: ASSEMBLE.AdaBoost pseudo-code2.3 Re-weightingRe-weighting (Crook & Banasik, 2002) popular simple technique reject-inferencingcredit scoring, considered semi-supervised learning technique. usesinformation examples approved credit applications, i.e. labeled data, inferconditional class probabilities rejected applications, i.e. unlabeled data.apply re-weighting one assumes unlabeled data MAR, i.e.P(y = 1 | x,labeled = 1) = P(y = 1 | x,labeled = 0) = P(y = 1 | x)is, x, distribution labeled cases label distributionmissing (in unlabeled population).several variants re-weighting. According one adopt here, also calledextrapolation, goal first estimate distribution classes la beled data within337fiCHAWLA & KARAKOULASscore group, extrapolate distribution unlabeled data. Thus, model learnedlabeled training set applied unlabeled data. labeled unlabeled datagrouped score, i.e. posterior class probability model. probabilitiespercentile -binned, bin forms score group. unlabeled data assigned labels baseddistribution classes corresponding score group labeled data. Thus, keyassumption corresponding score-bands labeled unlabeled datadistribution classes. formulated as:P( k | j , X L ) = P( yk | j , X U )kjL / X Lj = Ukj / X Ujj score band group j, kjL number labeled examples belonging class ykgroup j, Ukj proportion unlabeled examples could class k score group j.number labeled cases j weighted (|XLj +XUj |)/|XLj |, probability samplingweight.explain re-weighting concept, let us consider example given Table 1. Let 0 1two classes datasets. score group (0.6 - 0.7) bin posterior classprobabilities model. group weight example Table 1 computed(XL+XU )/XL = 1.2. Therefore, weighting number class0 class1 group, get class0= 12; class1 = 108. Thus, label random 2 (=12-10) data points unlabeled setclass0, 18 (=108-90) data points unlabeled set class1.labeling unlabeled examples learn new model expanded training set(inclusive labeled unlabeled data).Score Group0.6 - 0.7Unlabeled20LabeledClass 0Class 11001090Table 1: Re-weighting example2.4 Common Components Using EMidea behind technique eliminate bias estimation generative modellabeled/unlabeled data MAR type. reason bias case datadistributions x given labeled unlabeled sets different. remove biasestimating generative model labeled unlabeled data modeling missinglabels hidden variable within mixture model framework.particular, suppose data generated components (clusters),components well modeled densities p ( x | j , j ) , j = 1,2,..., , j denotingcorresponding parameter vector. feature vectors generated accordingdensity:p ( x | ) = j p ( x | j , j )j =1338fiLearning Labeled Unlabeled Dataj p( j ) mixing proportions sum one.joint data log-likelihood incorporates labeled unlabeled data takes form:L( ) =( xi , yi ) X llog j p( xi | j , j ) p ( yi | xi , j , j ) +j =1xi X ulog j p ( xi | j , j )j =1Note likelihood function contains "supervised" term, derived X l labeleddata, "unsupervised" term, based X u unlabeled data.Consider applying following simplistic assumption: posterior probability classlabel conditionally independent feature vector given mixture component, i.e.p ( | xi , j , j ) = p( yi | j ) . type model makes assumption class conditionaldensities function common component (CC) mixture (Ghahramani & Jordan, 1994;Miller & Uyar, 1997). general, interested applying CC mixture model solveclassification problem. Therefore need compute posterior probability class labelgiven observation feature vector. posterior takes form:p ( | xi , ) =p ( j | xi , ) p ( | xi , j, j ) =j =1p( x | j , )jjp( | j )p(x|l,)j =1 l =1 llOne could also consider applying separate component (SC) mixture model, classconditional density modeled mixture components. model essentially presentedNigam et al. (2000) case labeled/unlabeled data document classification.models, well powerful ones condition input feature vector, unitedmixture-of-experts framework (Jacobs et al., 1991). application frameworksemi-supervised setting studied Karakoulas Salakhutdinov (2003).2.4.1 Model TrainingAssume p ( x | j , j ) parameterized Gaussian mixture component distributioncontinuous data. define parameter vector component, j, j = ( j , j )j = 1, 2,..., ; j mean, j covariance matrix jth component.experiments constrain covariance matrix diagonal. also twomodel parameters estimated: mixing proportion components, j = p ( j ) ,| j = p ( | j ) posterior class probability.According general mixture model assumptions, hidden variable directly relateddata generated mixture components. Due labeled/unlabeled naturedata, additional hidden variable missing class labels unlabeled data.hidden variables introduced log-likelihood L() .general method maximum likelihood estimation model parameters presencehidden variables Expectation-Maximization (EM) algorithm (Dempster et al., 1977).EM algorithm alternates estimating expectations hidden variables (incomplete data)given current model parameters refitting model parameters given estimated,complete data. derive fixed-point EM iterations updating model parameters.339fiCHAWLA & KARAKOULASmixture component, j, feature vector, i, compute expectedresponsibility component via one following two equations, depending whetherith vector belongs labeled unlabeled set (E-Step):tj yi | j p( xi | j , tj )p ( j | xi , yi , ) =lt |l p (x | l , lt )l =1p ( j | xi , ) =tj p ( x | j , tj )l =1ltxi X Lxi X Up ( x | l , lt )Given equations solution model parameters takes form (M-Step):1p(j|x,,)+p(j|x,)N ( x , )Xxi X ultj+1 =+1k| jp ( j | xi , , )=xi X l = kp ( j | x , , )( xi , yi )X ltj +1 =p(j|x,,)x+p(j|x,)x+1N j ( xi , yi )X lxi X utj+1 =p(j|x,,)+p(j|x,)ijijN tj+1 ( xi , yi )X lxi X u11define N =| X l | + | X u | , Sij ( xi j )( xi j ) .Iterating E-step M-step guarantees increase likelihood function.discrete-valued data, instead using mixture Gaussians, apply mixture multinomials(Kontkanen et al., 1996).general, number components tuned via cross-validation. However, largenumber experiments reported work makes application tuning acrossexperiments impractical, computational overhead would entail. Furthermore,purpose paper provide insight learning labeled unlabeled datadifferent techniques, rather find technique performs best. reasonreport results experiments using two, six, twelve twenty-four components.340fiLearning Labeled Unlabeled Datadiscuss point Section 4.3. Dealing Sample Selection Biascensoring mechanism rules assignment label instances datamodel learned labeled data sample selection bias. case decisionlabeling due unobserved features create dependency assigning labelclass label itself. Thus data MNAR type. example, suppose interestedassigning relevance text corpus, e.g., web pages, someone subjectively decideddocuments label. estimates probability relevance underestimated,training set might representative complete population. resultincrease estimation bias model, thus increasing error.present two techniques, previously proposed literature, dealing MNAR data.3.1 Bivariate ProbitHeckman (1979) first studied sample -selection bias modeling labor supply fieldEconometrics. Heckman's sample selection model canonical form consists linearregression model binary probit selection model. probit model variant regressionmodel latent variable normally distributed. Heckman's method two-stepestimation process, probit model selection equation regression modelobservation equation. selection equation represents parameters classificationlabeled unlabeled data namely purpose explicitly model censoring mechanismcorrect bias observation equation represents actual values (to regress on)labeled data. regression model computed cases satisfy selectionequation therefore observed. Based probit parameters correctselection bias, linear regression model developed labeled cases.following equations present regression probit models. probit modelestimated y2 . dependent variable y2 represents whether data labeled not; y2 = 1data labeled, y2 = 0 data unlabeled. equation y1 , variable interest,regression equation. dependent variable y1 known label value labeled data.latent variables u 1 u 2 assumed bivariate normally distributed correlation .observation equation selected cases (the cases satisfy y2 >0). Let usdenote y1 * observed values y1 . have:y1 = ' x1 + u12 = ' x 2 + u22u1 , u2 N [ 0,0, u1 , ]y1 = y1* , 2>0y1 missing y2 0estimate unbiased latent variables u 1 u2 uncorrelated,341fiCHAWLA & KARAKOULAScase data MNAR. taking account bias results. biasregression depends sign (biased upwards positive, downwardsnegative). amount bias depends magnitude . crux Heckmansmethod estimate conditional expectation u 1 given u 2 use additional variableregression equation y1 . Let us denote univariate normal density CDF u 1, respectively. Then,E[ y1* | x1 , 2 > 0] = ' x1 + u1( x2 ' )=( x2 ' )also called Inverse Mills Ratio (IMR), calculated parameter estimates.Heckman's canonical form requires one models regression based. However,paper deal semi-supervised classification problems. problems class assignedlabeled data, y1 = 0 1, y2 = 1. Given two equations Heckmans method,labeled data observed y2 = 1. Thus, interested E[y1 |x, 2 = 1] P(y1 |x, 2 = 1).example, predict whether someone default loan (bad customer), model needslearnt accepted cases. Thus, scenarios one use bivariate probit modeltwo outcomes, default accept (Crook & Banasik, 2002; Greene, 1998). bivariate probitmodel written follows:y1 = x1 +u12 = x 2 +u 2y1 = y1* 2 = 1Cov(u1 , u 2 ) == 0 sample -selection bias associated datasets, latentvariables correlated using single probit model sufficient. log-likelihoodbivariate model written (where 2 bivariate normal CDF univariatenormal CDF).Log ( L ) =2 =1, y1 =1log F 2 [ 1 x1 , 2 x 2 , ]+2 =1, y1 =1log F 2 [ 1 x 1 , 2 x 2 , ]2=0 log F [ 2 x 2 ]apply bivariate probit model semi-supervised learning framework introducingselection bias various datasets.3.2 Sample -SelectZadrozny Elkan (2000) applied sample -selection model KDDCup-98 donors' datasetassign mailing costs potential donors. sample sele ction bias one tries predictdonation amount donors data. Using Nave Bayes probabilistic version C4.5,342fiLearning Labeled Unlabeled Datacomputed probabilistic estimates membership person ''donate'' ''not donate''category, i.e. P(labeled=1|x). imputed membership probability additionalfeature linear regression model predicts amount donation. Zadrozny Elkancast problem semi-supervised learning one. adapted methodsemi-supervised classification setting follows:= P( labeled = 1 | x, L U )n +1P( = 1 |x x, L)n +1xL labeled training set, U unlabeled set, labeled=1 denotes instance labeled,labeled = 0 denotes instance unlabeled, label assigned instancelabeled set. new training set labeled unlabeled datasets (L U ) constructed, whereinclass label 1 assigned labeled data class label 0 assigned unlabeled data. Thus,probabilistic mode l learned classify data labeled unlabeled data. probabilities,P(labeled = 1|x), assigned labeled data included another feature labeled dataonly. Then, classifier learned modified labeled data (with additional feature).classifier learns "actual" labels existing labeled data.experiments, learn Nave Bayes classifier L U, impute posteriorprobabilities another feature L, relearn Nave Bayes classifier L. restpaper call method Sample-Select.apply Sample -Select method along semi-supervised techniques,apply bivariate probit model datasets particularly constructedsample-selection bias. Sample -Select appropriate MAR case ratherMNAR case due limiting assumption makes. specifically, MNAR caseP(labeled,y|x,,)=P(y|x,labeled,)*P(labeled|x,)However, since Sample -Select assumesP(y|x,labeled=0,)= P(y|x,labeled=1,)reduces problem MAR.4. Experimental Set-upgoal experiments investigate following questions using aforementionedtechniques variety datasets:(i)(ii)(iii)(iv)(v)effect independence dependence among features?much unlabeled vs. labeled data help?effect label noise semi-supervised techniques?effect sample -selection bias semi-supervised techniques?semi-supervised learning always provide improvement supervisedlearning?questions designed series experiments real-world artificial343fiCHAWLA & KARAKOULASdatasets. latter datasets used providing insights effects unlabeled data withincontrolled experimental framework. Since datasets come fixedlabeled/unlabeled split, randomly divided ten splits built ten modelstechnique. reported results average performance ten models technique.Details splitting given Section 4.1. datasets came pre-defined testset. used test sets evaluate performance model. definition AUCperformance measure given Section 4.2.mentioned earlier, purpose work provide insight learning labeledunlabeled data different techniques, rather find technique performsbest. latter would required fine-tuning technique. However, understandsensitivity various techniques respect key parameters, run experimentsdifferent parameter settings. Thus, common-component technique, tried 2, 6, 12, 24components; ASSEMBLE-1NN ASSEMBLE-Class0 tried 0.4, 0.7 1.0 values, parameter controls misclassification cost; co-training tried 90%, 95%99% confidence intervals deciding label. Appendix (Tables 6 9) presentsresults four techniques, respectively. common-component technique 6components gave consistently good performance across datasets. found marginaldifference performance co-training different confidence intervals. found smallsensitivity value lower amounts labeled data, labeled data increasesdifferences values various datasets becomes smaller. Moreover, datasetsexhibited sensitivity value a. observations agree Bennett et al. (2002) choicemight critical cost function.Thus, analyzing questions set parameters techniques follows: 6components common-component mixture, = 1 ASSEMBLE-1NNASSEMBLE-Class0, confidence 95% co-training.4.1 Datasetsevaluated methods discussed Sections 2 3 various datasets, artificialreal-world, order answer questions. Table 2 summarizes datasets.datasets binary classes unbalanced class distributions. feature makesdatasets relevant real-world applications well difficultsemi-supervised techniques, since techniques inductive bias towards majorityclass. study effects feature relevance noise constructed 5 artificial datasetsdifferent feature characteristics presence noise. modified artificial data generationcode provided Isabelle Guyon NIPS 2001 Workshop Variable Feature Selection(Guyon, 2001). convention used datasets is: A_B_C_D,indicates percentage independent features,B indicates percentage relevant independent features,C indicates percentage noise datasets,indicates percentage positive (or minority) class datasets.independent features artificial datasets drawn N(0,1). Random noise added344fiLearning Labeled Unlabeled Datafeatures N(0,0.1). features rescaled shifted randomly. relevantfeatures centered rescaled standard deviation 1. class labels assignedaccording linear classification random weight vector, drawn N(0,1), usinguseful features, centered mean. mislabeling noise, specified, addedrandomly changing labels datasets. naming artificial datasets Table 2self-explanatory using convention outlined earlier.DatasetsTraining Size|L+U|TestingSizeClass-distribution(majority:minority)Features30_30_00_058000400095:53030_80_00_058000400095:53080_30_00_058000400095:53080_80_00_058000400095:53030_80_05_058000400095:53030_80_10_058000400095:53030_80_20_058000400095:530SATIMAGE (UCI)4435200090.64:9.3636WAVEFORM (UCI)3330166667:3321ADULT (UCI)325601628176:2414271071.7:28.31280061.75:38.25250.6:99.4200NEURON (NIPS)L530 +2130 UHORSE-SHOE (NIPS)400 L +400 UKDDCUP-98 (UCI)4843 L +9636790569 UTable 2: Datasets detailsThree real-world datasets waveform, satimage, adult UCI repository(Blake et al., 1999). transformed original six-class satimage datasets binary classproblem taking class 4 goal class (y=1), since least prevalent one (9.73%),merging remaining classes single one. Two datasets come NIPS 2001(Kremer & Stacey, 2001) competition semi-supervised learning pre-definedlabeled/unlabeled subsets.randomly divided ten times artificial UCI datasets five differentlabeled-unlabeled partitions: (1,99)%, (10,90)%, (33,67)%, (67,33)%, (90,10)%. provided usdiverse test bed varying labeled unlabeled amounts. report results averaged345fiCHAWLA & KARAKOULASten random runs.last real-world dataset KDDCup-98 Cup (Heittich & Bay, 1999; Zadrozny &Elkan, 2000). typical case sample selection bias, i.e. MNAR. converted originalKDDCup-98 donors regression problem classification problem consistentsemi-supervised classification setting experiments. considered respondentsdonation mailing campaign labeled set non-respondents unlabeled set.transformed labeled set classification problem, assigning label 1individuals make donation greater $2, label 0 individualsmake donation less $2. gave us difficult dataset since due sampleselection bias built dataset labeled unlabeled sets markedly different classdistributions. positive class training set 99.5%, testing set 5%.also created biased version Adult dataset (30_80_00_05) artificial datasetMAR labels order study effect missing label mechanism techniques.specifically, biased Adult dataset constructed labeled unlabeled partitionstraining set conditioning education individual. Using censoringmechanism individuals without post high-school education put unlabeledset, rest labeled set. Thus, converted original classification problemproblem return wages adults post high-school education. (30_80_00_05)dataset divided labeled unlabeled sets conditioning two features that:(xin <= ci || x jn <= cj ), n U. introduced selection bias construction labeledunlabeled sets. datasets test set changed. discuss threebiased datasets Section 5.3.4.2 Learning Performance Measurementexperiments use Nave Bayes algorithm base learner.co-training experiments use C4.5 decision tree learner addition Nave Bayes. applyNave Bayes algorithm, pre-discretize continuous features using Fayyad Irani'sentropy heuristic (Fayyad & Irani, 1993).use Area Receiver Operating Characteristic (ROC) curve (AUC)performance metric experiments (Hand, 1997). Due imbalanced class distributiondatasets studied paper chose use AUC standard classification accuracymetric, classification accuracy misleading unbalanced datasets. compareperformance model random model define AUCAUC := 2 * auc 1auc original area AUC normalized one. Thus, formulation, AUCnormalized respect diagonal line ROC space represents random performance.ROC curve model diagonal line, AUC worse random hencenegative.346fiLearning Labeled Unlabeled Data5. Empirical Analysisfollowing present analysis results experiments. structureanalysis around questions stated Section 4. Figures 2 6 show AUCs variousdatasets. Figures show performance semi-supervised technique,(supervised) Nave Bayes classifier. x-axis shows percentage labeled/unlabeled datadataset (Labeled, Unlabeled)%, y-axis shows AUC applyingsemi-supervised supervised techniques. datasets comepre-defined labeled/unlabeled split average AUC 10 random (labeled/unlabeled split)runs. present results charts using following convention order techniques:Supervised: Supervised Nave BayesASS1NN: ASSEMBLE-1NNASSCLS0: ASSEMBLE-Class0Samp-Sel: Sample-SelectReweight: ReweightingCo-train: Co-trainingCC: Common-Component Mixture5.1 Effect Independence Dependence Among Features?first investigate effect feature independence semi-supervised learning.purpose use artificial datasets. consider first four artificial datasets Table 2noise. Since datasets constructed varying amounts featureindependence relevance, offer diverse test-bed. results shown Figure 2.results averaged 10 different runs (labeled, unlabeled)% splits.two graphs left Figure 2 show effect increasing amount featureindependence, whereas two graphs right show effect increasing amountfeature relevance amongst independent features. worth pointing amountfeature independence increased without increasing amount feature relevance (top-leftbottom-left) adding unlabeled data hurts performance. amount independencerelevance increases (bottom-right graph) semi-supervised learning techniques improveperformance supervised learner different amounts labeled/unlabeled data.case Naive Bayes model underlying semi-supervised techniques betterapproximation true generative model.semi-supervised techniques either comparable better learningclassifier labeled datasets. largest improvement average AUC observed(1,99)% case across four combinations feature independence relevance, one wouldexpect. However, (some of) results statistically significant (random)labeled unlabeled splits, labeled set contained one two examples class 1, thusmaking highly skewed training set. cases, performance worse random.led high variance AUC, causing confidence intervals overlap. lowest gainobserved using semi-supervised learning techniques learning supervised Nave Bayesclassifier case artificial datasets 30% independent 30% relevant347fiCHAWLA & KARAKOULAS30_30_00_0530_80_00_05110.80.80.60.60.40.4AUCAUC0.20.20-0.20-0.4-0.2-0.6-0.4(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%(90,10)(1,99)SupervisedASS1NNASSCLS0Samp-SelReweightCo-trainCC80_30_00_05110.80.80.60.60.40.40.20.2AUCAUC-0.80-0.2-0.4-0.4-0.6-0.6-0.8-0.8(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%(90,10)80_80_00_050-0.2-1(10,90)(33,67)(67,33)(Labeled, Unlabeled)%-1(90,10)(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%(90,10)Figure 2 : Artificial datasets without noise. Effect different amounts feature independence (top bottom)relevance (left right) different percentages labeled unlabeled data.348fiLearning Labeled Unlabeled Datafeatures. Naive Bayes model achieves relatively high AUC even 1/3 rdinstances labeled set, addition unlabeled data help much.Regarding specific techniques, re-weighting consistently lower learning Nave Bayesclassifier labeled set only. re-weighting, labels assigned unlabeled datafunction P(y|x). smaller amounts labeled data function could overfitting givenrich feature space. also evident much lower performance Naive Bayes modeltesting set. Sample -Select perform better supervised learner even(1,99)% case.higher amounts independence relevance, ASSEMBLE-1NN ASSEMBLE-Class0(almost) always better supervised technique. Co-training also sensitive amountfeature relevance independence. higher amounts independence relevance,co-training becomes sensitive amount labeled unlabeled data mixture.common-component mixture approach provides large improvement average AUCacross experiments amount labeled data small, i.e. (1,99)%, one wouldexpect. common-component mixture model seems sensitive amountindependent features (top vs. bottom graphs Figure 2) semi-supervised techniquesconsidered paper. probably features correlatedmight useful clustering. goal clustering group feature vectorscohesive distinct (Fisher, 1987). Thus, correlated features likely relevantclustering independent features. fact, Talavera (2000) proposes feature-dependencymeasure based Fisher's results selecting features clustering. Thus, decreaseperformance common-component mixture technique (top vs. bottom graphs Figure 2)attributed increase number independent features.5.2 Much Unlabeled vs. Labeled Data Help?discuss trade -off labeled unlabeled data, present results UCINIPS competition datasets. Figure 3 shows result three UCI datasets satimage,waveform, adult. evident graphs that, artificial datasets, maximalgain semi-supervised learning supervised learning occurs smaller amounts labeleddata. lower amounts labeled data, common-mixture model gives biggest gainNaive Bayes amongst semi-supervised learning techniques. Also, common componentrelatively stable performance amount labeled data increased. notewaveform dataset helped unlabeled data even (90,10)% split, usingASSEMBLE-1NN, ASSEMBLE-Class0 common component. adult dataset,semi-supervised techniques help amount labeled/unlabeled split. general,addition labeled data helped co-training, re-weighting, Sample -Select. Co-training notedlargest improvement compared techniques increased (90,10)% split, namelylabeled data.Figure 4 shows results two NIPS datasets neuron horseshoe. neurondataset, ASSEMBLE-1NN provides marginal improvement Nave Bayes. Co-trainingtechnique helps horseshoe dataset. worth pointing horseshoe (50,50)% split labeled unlabeled data.349fiCHAWLA & KARAKOULASSatimageWaveform0.910.80.80.70.60.60.4AUCAUC0.50.40.20.300.2-0.20.10(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%(90,10)-0.4(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%Adult0.90.80.7SupervisedASS1NNASSCLS0Samp-SelReweightCo-trainCC0.6AUC0.50.40.30.20.10(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%(90,10)Figure 3: Effect different percentages labeled unlabeled data three UCI datasets.350(90,10)fiLearning Labeled Unlabeled Data0.7SupervisedASS1NNASSCLS0Samp-SelReweightCo-trainCC0.60.5AUC0.40.30.20.10NeuronHorse-shoeData setFigure 4: Performance comparison two datasets NIPS semi -supervised learningcompetition.Thus, amount labeled unlabeled data much domain dependent. consistentobservation drawn experiments. Nevertheless, averagesemi-supervised techniques common-component ASSEMBLE-1NN show improvementsupervised learner datasets, particularly (1,99)% split.prior work states unlabeled data help small amountlabeled data (Nigam et al., 2000; Cozman et al., 2003). However, observe evensmall amount labeled data, depending technique unlabeled data might help (seeadult Figure 3). even large amount labeled data unlabeled data help (seewaveform Figure 3).5.3 Effect Label Noise Semi-supervised Techniques?considered question label noise could detrimental learning. Thereforeinitial label estimates semi-supervised learning technique based labeled dataaccurate adding unlabeled data might provide minimal gain, any. understandsensitivity semi-supervised techniques amount noise, added 5%, 10%, 20%mislabeling noise 30_80_*_05 artificial datasets, * denotes level mislabelingnoise.Figure 5 shows effect noise semi-supervised techniques. before, unlabeleddata help amount labeled data relatively small, i.e. (1,99)%. again,common-component mixture ASSEMBLE-1NN ones exhibiting biggestimprovement Naive Bayes, particularly (1,99)%. (10,90)%, ASSEMBLE-Class0 alsoimproves Nave Bayes. observed across noise levels. worth pointingdatasets 20% mislabeling noise adding unlabeled data improves performance even351fiCHAWLA & KARAKOULAS30_80_05_0530_80_10_0510.80.80.60.60.40.40.2AUCAUC0.200-0.2-0.2-0.4-0.4-0.6-0.6-0.8(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%(90,10)-0.8(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%30_80_20_050.60.4SupervisedASS1NNASSCLS0Samp-SelReweightCo-trainCC0.2AUC0-0.2-0.4-0.6-0.8-1(1,99)(10,90)(33,67)(67,33)(Labeled, Unlabeled)%(90,10)Figure 5: Effect noise artificial datasets varying percentages labeled unlabeled data.352(90,10)fiLearning Labeled Unlabeled Data(10,90)% labeled/unlabeled mix. contrast one would expect since mislabelingnoise could caused model learned labeled data deviate underlyingdistribution. Hence, could eliminated potential improvement adding unlabeleddata. improvement probably supervised learner overfitting (1,99)%(10,90)% datasets 20% mislabeling noise, due high level noise small amountlabeled data. overfitting occur lower levels noise. Thus, two datasetsunlabeled data acting regularizer preventing semi-supervised learneroverfitting.5.4 Effect Sample-selection Bias Semi-supervised Techniques?used three datasets sample selection bias adult, 30_80_00_05, KDDCup-98.Section 4.1 detailed procedure introducing MAR label bias first two datasets.KDDCup-98 dataset comes built-in MNAR bias. Table 3 summarizes sizes classdistributions training set three datasets. worth noting different classdistributions labeled unlabeled partitions training set.DatasetsTraining Size (Labeled;Unlabeled)Class Distribution (Labeled;Unlabeled)Adult(17807; 14754)(66.75, 33.25; 87, 13)30_80_00_05(2033; 5967)(88.15, 11.85; 97.33, 2.67)KDDCup-98(4843; 90569)(0.5, 99.5; 100, 0)Table 3: Composition training set biased datasetsTable 4 shows effect sample selection bias feature distributions adult30_80_00_05 datasets. specifically, compared feature distributionslabeled unlabeled sets two datasets two different missing data scenarios:biased random. used Kolmogorov-Smirnov statistical test continuous featuresChi-squared statistical test nominal features. results show that, expected, MCARdata statistically significant difference feature distributions labeledunlabeled sets. contrast differences feature distributions two setsbias missing data mechanism.Adult30_80_00_05MAR MNAR data13 14 different20 30 differentMCAR data0 different0 differentTable 4: Differences feature distributions labeled unlabeled data different missing datamechanisms.353fiCHAWLA & KARAKOULASFigure 6 shows supervised learner (Nave Bayes) well semi-supervisedtechniques perform reasonably good level two MAR datasets, perform poorlyMNAR dataset. particular, co-training ASSEMBLE-1NN, moderately wellassumption MCAR, exhibit significantly worse performance. fact, ASSEMBLE-Class0much better ASSEMBLE-1NN 30_80_00_05 dataset. due selectionbias labeled unlabeled sets different feature distributions. Thus, 1NN weakerclassification model initialization class labels ASSEMBLE dataset biased.1.2SupervisedASS1NNASSCLS0Samp-SelReweighCo-trainCCProbitBivar Probit10.8AUC0.60.40.20-0.230-30-00-05AdultDatasetKDDCup-98Figure 6: AUC performance biased datasets.Re-weighting better supervised classifier adult 30_80_00_05 MARdatasets fails KDDCup-98 MNAR dataset. re-weighting suitableMNAR datasets since randomly assigns labels based biased posterior probabilitydistribution. Sample -Select performance comparable supervised classifier. Thus,exhibits poor performance KDDCup-98 MNAR dataset. explained Section 3.2,Sample-Select appropriate MNAR datasets. common-component mixture algorithmseem sensitive sample selection bias, even MNAR datasets.common-component technique better semi-supervised techniques consideredpaper presence bias. Although common-component technique scores lesssupervised classifier 30_80_00_05 dataset, performance consistentobserved without sample selection bias. exception bivariate probitcommon-components technique best performance amongst semi-supervised techniquesacross three datasets. supervised Nave Bayes learner significantly affectedintroduced selection bias, performance decreases 0.89 0.82 (approximately)corresponding amounts labeled unlabeled data 30_80_00_05 dataset.similar effect bias adult dataset.354fiLearning Labeled Unlabeled Datanoteworthy improvement provided bivariate probit model probitmodel three datasets. bivariate probit successfully corrects sample selection biastraining set. provides evidence using biased dataset predictiongeneral population detrimental classification performance, especially caseMNAR dataset. Part reason probit bivariate probit perform well artificialdatasets versus techniques assumption log-normal feature distributionsatisfied data. However, perform well Adult dataset since consistsnominal real-valued features. KDDCup-98 datasets, bivariate model bestperformance amongst techniques biggest improvement probit degreeselection bias datasets. dataset comes selection bias built in,true MNAR case. two datasets MAR bias.Based results believe presence sample -selection bias availabilityunlabeled data would help since better representation population couldinduced. course, choosing appropriate learning technique data, like bivariateprobit even common-component mixture, also critical.5.5 Semi-Supervised Learning Always Provide Improvement SupervisedLearning?Figure 7 summarizes performance semi-supervised technique across datasets.y-axis average AUC (over 10 runs) datasets partitioned labeledunlabeled sets 10 random times, datasets AUC obtained availablelabeled-unlabeled split biased labeled-unlabeled split. bar box-plot showsmedian performance across datasets labeled-unlabeled partition. observedfigure, ASSEMBLE-1NN common components never worse random. Although,median bar common component lower median bar supervised model, boxcompact all. highlights relatively less sensitivity common componentssize labeled unlabeled data. average, techniques usually betterlearning labeled data one observe distribution outliers.Table 5 contains statistical significance comparisons varioussemi-supervised learning methods supervised learning technique (Nave Bayes). derivegrouped AUCs obtained 10 different random runs technique acrossdatasets. Thus, 100 observation points (10 datasets times 10 random runs)technique. Since one observation point NIPS biased datasets,include analysis. Using Kruskal-Wallis statistical test applied multiplecomparison procedure comparing different techniques. Kruskal-Wallis non-parametricone-way ANOVA test assume values coming normal distribution.test performs analysis variance based ranks different valuesmeans. report Wins-Losses (W-T-L) counts semi-supervised learning techniquesupervised learning method. 1% labeled data, ASSEMBLE-1NNcommon-components mixture wins ties 1 0 loss. common-componentmodel well larger amounts labeled data, smaller amounts labeled355fiCHAWLA & KARAKOULASdata prevalent scenario seems help. general semi-supervised techniques tiesupervised one.10.80.60.40.2UC0-0.2-0.4-0.6-0.8-1Supervised ASS-1NNASS-CLS0CoTrainTechniqueReweighSample-SelCCFigure 7: Box plots summarizing AUC's obtained various techniques across datasets. y-axis indicatesAUC spread, x-axis indicates corresponding method. box lines lower quartile, median(red line) upper quartile. + symbol denotes outliers.(Labeled, Unlabeled)%(1,99)(10,90)(33,67)(67,33)(90,10)MethodW-T-LW-T-LW-T-LW-T-LW-T-LAssemble -1NN5-4-11-5-41-7-21-7-22-7-1Assemble -Class00-9-12-7-12-7-11-6-32-6-2Re-weighting0-10-00-7-31-4-50-6-40-9-1Sample-Select0-10-00-10-00-10-00-10-01-9-0Co-training0-10-00-10-00-10-02-8-04-6-0Common Component6-4-02-4-41-1-81-2-71-4-5Table 5: Win-Tie-Loss (W-T-L) tally various techniques versus supervised learning varyingproportions labeled unlabeled data.356fiLearning Labeled Unlabeled Data6. Conclusionspresented various existing techniques machine learning econometrics learninglabeled unlabeled data. introduced concept sample -selection biasprevalent real-world labeled sets potentially detrimental supervised learning.reason also introduced bias correction technique econometrics bivariate probit.empirically evaluated technique set five main objectives (hypotheses)collection artificial real-world datasets. dataset varied proportion labeledunlabeled data compared performance technique performancesupervised classifier. tried include datasets various domains differentcharacteristics order make study generalizable possible. observed, differentcharacteristics data favorable different kinds semi-supervised learning frameworks.Moreover, one may need perform parameter tuning optimizing performance specifictechnique since optimization focus paper.main conclusions five objectives enlisted follows:effect independence dependence amongst features?investigated objective using artificial datasets. observed fewerindependent relevant features (30_*) higher amounts labeled data,semi-supervised techniques generally provide much improvement supervisedlearning method. Given 3 4 10 independent features relevant, fewerlabeled examples usually sufficient learning classifier. amount featureindependence increased without increasing amount relevant features adding unlabeleddata hurts performance. amount independence relevance increasestechniques, particularly ASSEMBLE-1NN ASSEMBLE-Class0, improve performancesupervised technique. common-component mixture technique seemssensitive (less effective) amount independent features increasessemi-supervised techniques. correlated features relevantclustering.much unlabeled vs. labeled data help?objective used artificial real-world datasets. observeconsistent pattern lower amounts labeled data, unlabeled data would always helpregardless technique domain. saw even small amount labeleddata unlabeled data might help depending technique domain. Moreover, evenlarge amount labeled data, unlabeled data still help (for example, seeWaveform). average common-component mixture ASSEMBLE-1NN helped(1,99)% labeled/unlabeled mix. Also, common component relatively stableperformance amount labeled data increased. is, performancedeviate much scored lower amounts labeled data. increasedamount labeled data, wins ASSEMBLE-1NN common component changedties losses, compared supervised learner. contrary, additionlabeled data helped co-training, re-weighting, Sample -Select. techniques ranked357fiCHAWLA & KARAKOULASlow (1,99)% split. Co-training noted largest improvement comparedtechniques increased (90,10)% split, namely labeled data.effect label noise semi-supervised learning?investigated objective using artificial datasets. Noise detrimentaleffect semi-supervised learning. contrary, fewer semi-supervised modelsperformed worse single supervised model compared no-noise cases.despite significant reduction performance single Naive Bayes model. believesingle Naive Bayes learner overfitting noise level increases.cases unlabeled data acting regularizer preventing semi-supervised learneroverfit. fact, 20% mislabeling noise adding unlabeled data improves performance even(10,90)% labeled/unlabeled mix.effect sample-selection bias semi-supervised learning?objective used two real-world datasets transformed MARreal-world MNAR dataset. Selection bias, especially MNAR case, detrimentalperformance supervised learner semi-supervised techniques.type problem choosing appropriate learning technique, bivariateprobit specifically addresses selection bias even common-component mixture,critical. observed ASSEMBLE, reasonably well datasetslabels missing completely random, perform well biased datasets(MAR MNAR). expected, Sample -Select well MNAR dataset. onetechnique reasonably well fairly consistent common componenttechnique. Bivariate probit best performance amongst techniques MNARdataset. presence selection bias unlabeled data conjunctionappropriate technique seem always improve performance.semi-supervised techniques considered consistently better supervisedlearning?single technique consistently better supervised Nave Bayesclassifier labeled/unlabeled splits. (1,99)% mix, ASSEMBLE-1NNcommon-component mixture generally better Nave Bayes.semi-supervised techniques considered neither better worse Nave Bayes.increase amount labeled data, wins ASSEMBLE-1NN common componentmove ties losses. Common component losses added labeled data,particularly artificial datasets. Sample -select comparable Nave Bayesclassifier, sometimes slightly better. Re-weighting generally worse Nave Bayes.Co-training noted largest improvement (over Nave Bayes) compared techniquesincreased percentage labeled data.Semi-supervised learning still open problem, especially context MNAR. Currenttechniques behave differently depending nature datasets. Understanding typemissing data mechanism data assumptions key devising appropriate358fiLearning Labeled Unlabeled Datasemi-supervised learning technique improving performance adding unlabeled data.work, dealt datasets varying amounts imbalance class distribution.purpose, utilized AUC performance measure. extension work couldutilization performance metrics, e.g. classification error, analysis effectsunlabeled data.AcknowledgmentsThanks Ruslan Salakhutdinov help experiments. Also, thanks BrianChambers, Danny Roobaert anonymous reviewers comments suggestionsearlier versions paper.AppendixTables 6 9 present results experiments different parameter settingssemi-supervised techniques: number components common-component mixture,parameter ASSEMBLE, significance level confidence intervals co-training.359fiCHAWLA & KARAKOULASDataset30_30_00_0530_80_00_0580_30_00_0580_80_00_05AdultSatimageWaveformHorseshoeNeuron(Labeled,Unlabeled)%(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)20.54880.68700.68910.69110.69270.41050.51450.51500.51600.51670.22530.22680.23170.23790.24310.13230.22220.22890.23920.24540.65900.57360.74650.71600.75780.01900.02640.08900.05750.08320.71090.71350.72250.73110.73480.30520.5570Number Mixture Components612AUC0.69040.35360.83690.72450.83770.72770.87540.75580.88330.74580.67530.21070.74540.48740.76050.53440.77600.55200.78810.55770.39140.09820.67280.15670.69540.24990.70570.25160.71380.22240.50540.30140.68210.45530.69210.48060.73100.51160.75950.50990.79540.68050.82100.73770.82370.75230.83780.76070.84320.76340.79720.69190.83620.81990.84540.82590.85440.82950.85650.82640.90740.89860.90530.93840.92090.93940.93340.94370.94070.94550.40000.33000.65000.6539240.45290.76760.80920.80570.81710.31380.48340.54300.56700.58310.10460.21900.26740.32470.35600.27130.43860.50730.53020.57100.70760.74530.76760.76930.78070.64470.82990.84380.85190.85200.87580.92980.93930.94430.94490.34000.6600Table 6. Sensitivity common components respect number components different datasetslabeled/unlabeled split. bold entries show components maximum AUC.360fiLearning Labeled Unlabeled DataDataset30_30_00_0530_80_00_0580_30_00_0580_80_00_05AdultSatimageWaveformHorseshoeNeuron(Labeled,Unlabeled)%(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)0.40.72440.86210.92950.95570.95990.55380.70470.85020.89890.89920.27300.88240.93050.94160.94090.47600.86100.90460.92070.91270.30590.77540.80270.82100.83230.69400.85660.85820.84020.81650.82060.85170.89980.90410.89230.03970.7108Value0.7AUC0.76020.84850.91110.94960.95950.56730.66900.80110.89270.90040.30850.87410.93880.94270.94520.45630.82830.90110.92610.91970.29550.76870.79970.81920.83130.67970.85450.86000.84830.82140.82970.83810.89470.91190.89690.17780.695610.69890.83860.90240.94400.95870.55420.65340.76030.88400.89900.30110.86770.94090.94840.94400.45310.80390.89690.92890.91740.27730.30550.79590.81570.8310.71330.85170.86000.85060.82580.81600.83270.88150.91370.89890.23470.6929Table 7. Sensitivity ASSEMBLE-1NN respect value different datasetslabeled/unlabeled split. bold entries show value maximum AUC.361fiCHAWLA & KARAKOULASDataset30_30_00_0530_80_00_0580_30_00_0580_80_00_05AdultSatimageWaveformHorseshoeNeuron(Labeled,Unlabeled)%(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)0.40.25210.90820.93970.95650.9605-0.17390.83980.87340.89850.9007-0.74050.88740.93340.94100.9412-0.67670.86180.90730.92020.91520.68750.77540.80220.82020.83230.21130.82850.86130.83210.81070.00170.84240.89020.89450.88840.22540.6572Value0.7AUC0.01390.89310.93020.95150.9587-0.37210.81050.84660.89470.9025-0.61040.87600.94470.94770.9427-0.85870.85070.91120.92570.91370.67430.76870.79910.81820.83130.20240.82550.86190.84550.8162-0.21230.82470.87940.90570.89020.16410.67541-0.35050.88490.92350.94730.9578-0.67300.79460.82080.88770.8979-0.83550.86770.94650.94990.9441-0.89900.80960.91120.92900.92010.65730.76710.79750.81480.83060.20240.81920.86240.85250.8245-0.36010.81580.87180.90670.89280.37110.6436Table 8. Sensitivity ASSEMBLE-Class0 respect value different datasetslabeled/unlabeled split. bold entries show value maximum AUC.362fiLearning Labeled Unlabeled DataDataset30_30_00_0530_80_00_0580_30_00_0580_80_00_05AdultSatimageWaveformHorseshoeNeuron(Labeled,Unlabeled)%(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)(1,99)(10,90)(33,67)(67,33)(90,10)90%0.32550.93380.96510.98200.9852-0.12810.81690.88580.91320.9224-0.35320.66240.87340.92290.9331-0.54790.48280.81450.87340.88390.72080.78710.80500.81310.82640.52130.83080.85660.86250.86500.80000.84000.86790.88560.89310.47350.6234Confidence Value95%AUC0.32550.93430.95710.97990.9851-0.12810.81290.87480.91210.9227-0.35320.66940.87340.92290.9331-0.54790.48280.81450.87340.88390.72080.78710.80500.81310.82640.52130.83460.85660.86250.86500.80000.83910.86810.88550.89270.47350.623499%0.32550.93160.95380.97680.9844-0.12810.80510.87090.90990.9200-0.35320.71080.87340.92290.9331-0.54790.48280.81450.87340.88390.72080.78710.80500.81310.82640.52130.83460.85660.86250.86500.80000.83770.86810.88590.89300.47350.6234Table 9. Sensitivity Co-training respect confidence value different datasetslabeled/unlabeled split. bold entries show value maximum AUC.363fiCHAWLA & KARAKOULASReferencesBennett, K., Demiriz, A. & Maclin, R. (2002). Exploiting unlabeled data ensemble methods.Proceedings Sixth International Conference Knowledge Discovery Databases, pp.289-296, Edmonton, Canada.Blake, C., Keogh, E., & Merz, C.J. (1999). UCI repository machine learning databases. (URL:http://www.ics.uci.edu/~mlearn/MLRepository.html)Blum, A. & Chawla, S. (2001). Learning Labeled Unlabeled Data using Graph Mincuts.Proceedings Eighteenth International Conference Machine Learning, pp. 19-26,San Francisco, CA.Blum, A. & Mitchell, T. (1998). Combining labeled unlabeled data co-training.Proceedings Workshop Computational Learning Theory, pp. 92-100, Madison, WI.Bradley, A.P. (1997). Use Area ROC Curve Evaluation MachineLearning Algorithms. Pattern Recognition, 30(6), 145-1159.Chawla, N.V., Bowyer, K.W., Hall, L.O. & Kegelmeyer, W.P. (2002). SMOTE: SyntheticMinority Over-sampling Technique. Journal Artificial Intelligence Research, 16, 321-357.Cozman, F., Cohen, I., & Cirelo, M. (2002). Unlabeled data degrade classification performancegenerative classifiers. Proceedings Fifteenth International Florida Artificial IntelligenceSociety Conference, pp. 327-331, Pensacola, FL.Cozman, F., Cohen, I., & Cirelo, M. (2003). Semi-supervised learning mixture models.Proceedings Twentieth International Conference Machine Learning, pp. 99-106,Washington, DC.Crook, J. & Banasik, J (2002). Sample selection bias credit scoring models. InternationalConference Credit Risk Modeling Decisioning, Philadelphia, PA.Dempster, A., Laird, N. & Rubin, D. (1977). Maximum Likelihood incomplete data viaEM algorithm. Journal Royal Statistical Society, Series B, 39(1), 1-38.Fayyad, U.M. & Irani, K.B. (1993). Multi-Interval discretization continuous-valued attributesclassification learning. Proceedings Thirteenth International Joint Conference AI,pp 1022-1027, San Francisco, CA.Feelders, A.J. (2000). Credit scoring reject inferencing mixture models. InternationalJournal Intelligent Systems Accounting, Finance & Management, 9, 1-8.Freund, Y. & Schapire, R. (1996). Experiments new boosting algorithm. ProceedingsThirteenth International Conference Machine Learning, pp. 148-156, Bari, Italy.Ghahramani, Z. & Jordan, M.I. (1994). Learning incomplete data. Technical Report 108, MITCenter Biological Computational Learning.Ghani, R., Jones, R. & Rosenberg, C. (2003). Workshop Continuum Labeled364fiLearning Labeled Unlabeled DataUnlabeled Data Machine Learning Data Mining. Twenty-first InternationalConference Machine Learning, Washington, D.C.Goldman, S. & Zhou, Y. (2000). Enhancing supervised learning unlabeled data.Proceedings Seventeenth International Conference Machine Learning, pp.327-334,San Francisco, CA.Greene, W. (1998). Sample selection credit-scoring models. Japan World Economy, 10:299-316.Guyon, I. (2001). NIPS 2001 Workshop variable feature Selection.http://www.clopinet.com/isabelle/Projects/NIPS2001/.Hand, D.J. (1997). Construction assessment classification rules. Chichester: John WileySons.Hettich, S. Bay, S. D. (1999). UCI KDD Archive, http://kdd.ics.uci.edu. UniversityCalifornia Irvine, Department Information Computer Science.Heckman, J. (1979). Sample selection bias specification error. Econometrica, 47, 153-161.Jacobs, B.A., Jordan, M.I., Nowlan, S.J., Hinton, G.E. (1991). Adaptive mixtures localexperts. Neural Computation, 3(1), 79-87.Joachims, T. (2003). Transductive Learning via Spectral Graph Partitioning. ProceedingsTwentieth International Conference Machine Learning, pp. 290-297, Washington, DC.Karakoulas, G & Salakhutdinov, R. (2003). Semi-supervised Mixture Experts Classification.Proceedings Fourth IEEE International Conference Data Mining, pp. 138-145,Brighton UK.Kontkanen, P., Myllymaki, P., & Tirri, H. (1996). Constructing bayesian finite mixture modelsEM algorithm. Technical Report NC-TR-97-003, ESPRIT: Neural ComputationalLearning (NeuroCOLT).Kremer, S. & Stacey, D. (2001). NIPS 2001 Workshop Competition unlabeled datasupervised learning. http://q.cis.guelph.ca/~skremer/NIPS2001/.Little, R.J.A & Rubin, D.R. (1987). Statistical Analysis Missing Data. Wiley: New York.Miller, D. & Uyar, S. (1997). mixture experts classifier learning based labeledunlabeled data. Advances Neural Information Processing Systems 9, pp. 571-578, MITPress.Nigam, K., McCallum, A., Thrun, S., & Mitchell, T. (2000). Text classification labeledunlabeled documents using EM. Machine Learning, 39(2/3), 103-134.Nigam, K. & Ghani, R. (2000). Analyzing effectiveness applicability co-training.Proceedings Ninth International Conference Information Knowledge Managementpp. 86-93.365fiCHAWLA & KARAKOULASProvost, F. & Fawcett, T. (2001). Robust classification imprecise environments. MachineLearning, 42, 203-231.Provost, F. & Domingos, P. (2003). Tree induction probability based ranking. MachineLearning, 52, 199-215.Quinlan R. (1992) C4.5: Programs Machine Learning. San Mateo, CA: Morgan Kaufmann.Seeger, M. (2000). Learning labeled unlabeled data. Technical report, Institute ANC,Edinburgh, UK. http://www.dai.ed.ac.uk/~seeger/papers.html.Shahshahni, B. & Landgrebe, D. (1994). effect unlabeled samples reducing smallsample size problem mitigating Hughes phenomenon. IEEE TransactionsGeoscience Remote Sensing, 32(5), 1087-1095.Talavera, L. (2000). Dependency-based feature selection clustering symbolic data. IntelligentData Analysis, 4(1), 19-28.Swets, J. (1988). Measuring Accuracy Diagnostic Systems. Science, 240, 1285-1293.Zadrozny, B. & Elkan, C. (2000). Learning making decisions costs probabilitiesunknown. Proceedings Seventh International Conference KnowledgeDiscovery Data Mining, pp 204-213, San Francisco, CA.Zhang, T., & Oles, F.J. (2000). probability analysis value unlabeled dataclassification problems. Proceedings Seventeenth International conference MachineLearning, pp 1191-1198, Stanford, CA.366fiJournal Artificial Intelligence Research 23 (2005) 123-165Submitted 10/03; published 2/05Restricted Value Iteration: Theory AlgorithmsWeihong Zhangwzhang@cs.wustl.eduDepartment Computer ScienceWashington University, Saint Louis, MO 63130 USANevin L. Zhanglzhang@cs.ust.hkDepartment Computer ScienceHong Kong University Science & TechnologyClear Water Bay Road, Kowloon, Hong Kong, CHINAAbstractValue iteration popular algorithm finding near optimal policies POMDPs.inefficient due need account entire belief space, necessitatessolution large numbers linear programs. paper, study value iterationrestricted belief subsets. show that, together properly chosen belief subsets,restricted value iteration yields near-optimal policies give condition determining whether given belief subset would bring savings space time. alsoapply restricted value iteration two interesting classes POMDPs, namely informativePOMDPs near-discernible POMDPs.1. IntroductionPartially Observable Markov Decision Processes (POMDPs) provide general frameworksequential decision-making tasks effects agents actions nondeterministic states world environment known certainty. Duemodel generality, POMDPs found variety potential applications reality (Monahan, 1982; Cassandra, 1998b). However, solving POMDPs computationally intractable.Extensive efforts devoted developing efficient algorithms finding solutionsPOMDPs (Parr & Russell, 1995; Cassandra, Littman, & Zhang, 1997; Cassandra, 1998a;Hansen, 1998; Zhang, 2001).Value iteration popular algorithm solving POMDPs. Two central conceptsvalue iteration belief state value function. belief state, probability distributionstate space, measures probability environment state.possible belief states constitute belief space. value function specifies payoff costbelief state belief space. Value iteration proceeds iterative fashion.iteration, referred dynamic programming (DP) update, computes new valuefunction current one. algorithm terminates, final value functionused agents action selection. Value iteration computationally expensive because,iteration, updates current value function entire belief space,necessitates solution large number linear programs.One generic strategy accelerate value iteration restrict value iteration, is, DPupdates, subset belief space. simplicity, subset belief space referredbelief subset. Existing value iteration algorithms working belief subsets includefamily grid-based algorithms DP updates calculate values finite grid (Lovejoy,c2005AI Access Foundation. rights reserved.fiZhang & Zhang1991; Hauskrecht, 1997; Zhou & Hansen, 2001), several (maybe anytime) algorithmsDP updates calculate values growing belief subset (Dean, Kaelbling, Kirman,& Nicholson, 1993; Washington, 1997; Hansen & Ziberstein, 1998; Hansen, 1998; Bonet &Geffner, 2000). restricting value iteration belief subset, complexity valuefunctions reduced also DP updates efficient. advantagesobserved several researchers (Hauskrecht & Fraser, 1998; Roy & Gordon, 2002; Zhang& Zhang, 2001b; Pineau, Gordon, & Thrun, 2003).fundamental issue restricted value iteration select belief subset.efficiency value iteration quality generated value functions strongly dependselected belief subset. one extreme case, subset chosen singletonset, value iteration efficient, quality value functions arbitrarily poor.extreme case, subset belief space, quality value functionsretained, algorithm inefficient. exists tradeoff sizebelief subset quality value functions.paper, show indeed possible value iteration workbelief subset also retain quality value functions. achieved deliberatelyselecting belief subset value iteration. Sometimes, refer algorithm workingselected belief subset subset value iteration. (For distinction, restricted valueiteration refers value iteration working belief subset.) efficiency subsetvalue iteration depends size selected subset. characterize conditionpriori determine whether subset proper 1 respect belief space givenPOMDP. case, subset value iteration carries space time advantages.also study two special POMDP classes, namely informative POMDPs neardiscernible POMDPs. informative POMDP assumes agent good albeitimperfect idea world states time point. informative POMDP,exists natural belief subset value iteration restricted efficientstandard value iteration (Zhang & Liu, 1997). near-discernible POMDP assumesagent good idea world states while. near-discerniblePOMDP, propose restricted value iteration algorithm starts small beliefsubset grows gradually. algorithm terminates proper tradeoff sizesubset policy quality found. near-discernibility, algorithmable find good tradeoff subset grows large.algorithms developed paper tested variety small maze problems designed possess various properties desired, number problems adaptedexisting research created office environment. results showexploiting problem characteristics, restricted value iterations solve larger POMDPsstandard value iteration. show algorithmic performances varyproperties selected belief subset maze problems. small problems facilitate exposition properties chosen belief subsets. Meanwhile, experimentsprovide clues POMDP classes amenable perspective algorithms.rest paper organized follows. next section, introducePOMDP model value iteration. two subsequent sections, present subsetvalue iteration algorithm analyze theoretical properties. particular, Section1. Set proper subset set B (1) subset B, (2) exists least one element Bbelong A.124fiRestricted Value Iteration: Theory Algorithms3, show select belief subset selected subset relatedbelief space. Section 4, describe subset value iteration algorithm discussable achieve near optimality. Section 5, examine informative POMDPsshow algorithm exploits informativeness related general subsetvalue iteration (Zhang & Liu, 1997). Section 6, examine near-discernible POMDPsdevelop anytime algorithm. empirically demonstrate algorithm ablecompute value functions high quality. Section 7, survey related workresearch.2. POMDPs Value Iterationsection gives brief overview POMDP model value iteration.2.1 POMDPsPOMDP sequential decision model agent acts stochastic environmentpartial knowledge state environment. set possible statesenvironment referred state space denoted S. pointtime, environment one possible states. agent directly observestate. Rather, receives observation it. denote set possibleobservations Z. receiving observation, agent chooses action setpossible actions executes action. Thereafter, agent receives immediatereward environment evolves stochastically next state.Mathematically, POMDP specified by: three sets S, Z, A; reward functionr(s, a) A; transition probability function P (s0 |s, a); observationprobability function P (z|s0 , a) z Z s0 S. reward function characterizesdependency immediate reward current state current action a.transition probability characterizes dependency next state s0 current statecurrent action a. observation probability characterizes dependencyobservation z next time point next state s0 current action a.2.2 Policies Value FunctionsSince current observation necessarily fully reveal identity currentstate, agent needs consider previous observations actions choosingaction. Information current state contained current observation, previousobservations, previous actions summarized probability distributionstate space (Astrom, 1965). probability distribution sometimes called beliefstate denoted b. possible state s, b(s) probability currentstate s. set possible belief states called belief space. denote B.policy prescribes action possible belief state. words,mapping B A. Associated policy value function V . beliefstate b, V (b) expected total discounted reward agent receives followingPpolicy starting b, i.e., V (b) = E,b [t=0 rt ] rt reward receivedtime (0<1) discount factor. known exists policyV (b)V (b) policy belief state b (Puterman, 1994).125fiZhang & Zhangpolicy called optimal policy. value function optimal policy calledoptimal value function. denote V . positive number , policy-optimal V (b) + V (b) b B.2.3 Value Iterationexplain value iteration, need consider belief state evolves time. Let bcurrent belief state. belief state next point time determinedcurrent belief state, current action a, next observation z. denote (b, a, z).state s0 , (b, a, z) givenPP (z,(b, a, z)(s0 ) =0 |s, a)b(s)P (z|b, a),(1)PP (z, s0 |s, a)=P (z|s0 , a)P (s0 |s, a) P (z|b, a)= s,s0 P (z, s0 |s, a)b(s) renormalization constant. notation suggests, constant also interpretedprobability observing z taking action belief state b.concept belief state, POMDP model transformed belief spaceMDP follows.state space B action space A.Given belief state b action a, transition model specifies transitionprobability follows.(0P (b |b, a) =P (z|b, a) b0 = (b, a, z) z,0otherwise.Given belief state b action a, reward model specifies immediate rewardPr(b, a) r(b, a) = sS b(s)r(s, a).Due reformulation, task solving POMDP accomplished solvingreformulated MDP. proven reformulated MDP stationaryoptimal policy, found stochastic dynamic programming (Bellman, 1957;Puterman, 1994).Value iteration dynamic programming algorithm finding -optimal policiesMDP. starts initial value function V0 iterates using following formula:Vn+1 (b) = max[r(b, a) +XP (z|b, a)Vn ( (b, a, z))] b B(2)zVn referred nth-step value function. known Vn geometricallyconverges V n goes infinity.given value function V , policy said V -improving(b) = arg max[r(b, a) +XP (z|b, a)V ( (b, a, z))]b B.(3)zfollowing theorem tells one terminate value iteration given precision requirement (Puterman, 1994). stopping criterion depends quantity maxbB |Vn (b)Vn1 (b)|, maximum difference Vn Vn1 belief space.quantity often called Bellman residual Vn Vn1 (Puterman, 1994).126fiRestricted Value Iteration: Theory AlgorithmsTheorem 1 maxb |Vn (b) Vn1 (b)| (1 )/(2), Vn1 -improving policy-optimal.Since infinitely many belief states, value functions cannot explicitly represented. Fortunately, value functions one encounters process value iterationadmit implicit finite representations (Sondik, 1971).2.4 Technical Notational Considerationsconvenience, view functions state space vectors size |S|. use lowercase Greek letters refer vectors script letters V U refer setsvectors. contrast, upper case letters V U always refer value functions,functions belief space B.set V vectors induces piecewise linear convex value function (say f ) follows:f (b) = maxV b b B b inner product b. convenience,shall abuse notation use V denote set vectors value functioninduced set. convention, quantity f (b) written V(b).vector set useless removal affect function set induces.useful otherwise. set vectors minimal contains useless vectors. Letvector set V. known useful least one beliefstate b b > 0 b, 0 V\{}. belief state called witness pointtestifies fact useful (Kaelbling, Littman, & Cassandra, 1998).determine usefulness vector set, sufficient solve one linear program.compute minimal set given set V vectors, sufficient solve |V| linearprograms. procedure computing minimal set given set vectors oftenreferred pruning set.2.5 Finite Representation Value Functions Value Iterationvalue function V represented set vectors equals value function inducedset. value function representable finite set vectors,unique minimal set represents function (Littman, Cassandra, & Kaelbling, 1995).Sondik (1971) shown value function representable finite setvectors, subsequent value functions derived DP updates. processobtaining minimal representation Vn+1 minimal representation Vnusually referred dynamic programming (DP) update.practice, value iteration POMDPs carried directly terms valuefunctions themselves. Rather, carried terms sets vectors representvalue functions. One begins initial set vectors V0 (often set zero-vector).iteration, one performs DP update previous minimal set Vn vectorsobtains new minimal set Vn+1 vectors. One continues Bellman residualmaxb |Vn+1 (b) Vn (b)|, determined solving sequence linear programs, fallsthreshold.127fiZhang & Zhang3. Belief Subset Selectionsection, show select belief subset value iteration. describecondition determining whether selected subset proper w.r.t. belief space.addition, discuss minimal representation value functions w.r.t. selected subset.next section, develop subset value iteration algorithm show ableachieve near optimality.3.1 Subset Selectionbelief subset selection rests belief updating. Let agents current belief b.next belief state (b, a, z) performs action receives observation z. varybelief state b belief space B, obtain set { (b, a, z)|b B}. Abusingnotation, denote set (B, a, z). words, matter belief state agentstarts with, receives z performing a, next belief state must (B, a, z).union a,z (B, a, z) takes account sets belief states possible combinations actions observations. contains belief states agentencounter. words, agents belief state time point must belongset regardless initial belief state, performed actions received observations.denote set (B, A, Z) simply (B). closed set sense actionlead agent belief states outside (B) agent starts belief state it.Furthermore, belief subset set (B) belief space B closed.Lemma 1 set (B) closed. Moreover, (B) B0 B, B0 closed.apparent, set (B) subset belief space B. definition applicationreachability analysis (Boutilier, Brafman, & Geib, 1998; Dean et al., 1993).terminology reachability analysis, subset (B, a, z) comprises one-step reachablebelief states agent performs action receives observation z, subset (B)comprises one-step reachable belief states regardless performed actions receivedobservations. Although belief subset (B) set one-step reachable belief states,appealing property, shown next subsection, value iteration workingpreserve quality generated value functions.3.2 Subset RepresentationSubset representation addresses represent subsets (B, a, z) (B). this,introduce concept belief simplex.Definition 1 Let B = {b1 , b2 , ..., bk } set belief states. belief simplex generatedPPB set belief states { ki=1 bi |i 0 ki=1 = 1.0}.set B said basis belief simplex . definition, beliefsimplex (or simply simplex) set convex combinations belief statesbasis. Following standard terms linear algebra, also talk minimumbasis simplex. convenience, use notation B denote basis given simplex. Additionally, simplex basis {b1 , b2 , , bk } denoted (b1 , b2 , , bk ).result z, subset (B, a, z) simplex. intuitionfollows. Let number states POMDP n. {1, 2, . . . , n}, bi unit128fiRestricted Value Iteration: Theory Algorithmsvector, i.e., bi (s) equals 1.0 = 0.0 otherwise. belief state bi , P (z|bi , a) > 0,(bi , a, z) belief state (B, a, z); P (z|bi , a) = 0, belief update equation(bi , a, z) undefined. belief space B, trivial note belief staterepresented convex combination belief states {b1 , b2 , , bn }. Correspondingly,belief subset (B, a, z), belief state represented convex combinationbelief states { (bi , a, z)|P (z|bi , a) > 0}. Hence, { (bi , a, z)|P (z|bi , a) > 0} basis(B, a, z). convenience, denote basis B (B,a,z) .Theorem 2 pair [a, z], subset (B, a, z) simplex.Proof: See Appendix A.2theorem, subset (B) union simplices. Although subset(B) linearly representable own, union linearly representable sets.Later section, property crucial exploited finding minimalrepresenting sets value functions w.r.t. belief subset (B).concretize ideas subset representation, give POMDP example visualize simplices actions observations. presenting example, mentionshall use additional purposes later paper. First, shall useshow difference two conditions determining whether subset (B)proper subset belief space. Second, shall use demonstrate fundamentaldifferences two restricted value iteration algorithms.Example POMDP three states {s1 , s2 , s3 }, two actions {a1 , a2 } two observations {z1 , z2 }. define transition observation model action a1 . modelsa2 defined similarly. shorten notations, use pij denote transitionprobability P (sj |si , a1 ) qij denote observation probability P (zj |si , a1 ). assume (1) state si , probability pi1 equal pi2 , i.e., pi1 = pi2 ; (2)state si , observations z1 z2 received probability, i.e., qi1 = qi2 = 0.5i; (3) p11 > p21 > p31 . assumptions, matrixPa1 z10.5p110.5p11=0.5(1 2p11 )0.5p210.5p210.5(1 2p21 )0.5p310.5p31.0.5(1 2p31 )(4)first assumption, first two rows matrix same. thirdrow, probability pi3 replaced 1 pi1 pi2 , i.e., 1 2pi1 .compute basis belief subset (B, a1 , z1 ). Let basis belief spaceB set {(1.0, 0, 0)T , (0, 1.0, 0)T , (0, 0, 1.0)T }. (For matrix vector A, denotestranspose.) action a1 observation z1 , next belief states, denoted Ai s, are:A1A2A3= ((1.0, 0, 0)T , a1 , z1 ) = (p11 , p11 , 1.0 2p11 )T= ((0, 1.0, 0)T , a1 , z1 ) = (p21 , p21 , 1.0 2p21 )T= ((0, 0, 1.0)T , a1 , z1 ) = (p31 , p31 , 1.0 2p31 )T(5)Interestingly, shown A2 convex combination A1 A3 . fact,verified((0, 1.0, 0)T , a1 , z1 ) = 1 ((1.0, 0, 0)T , a1 , z1 ) + 2 ((0, 0, 1.0)T , a1 , z1 )129fiZhang & Zhangp31p211 = pp212 = pp11. Thus 1 + 2 = 1.0. third assumption ensures11 p3111 p311 2 greater 0.0. A2 convex combination A1 A3 ,three belief states A1 A3 lie straight line.Figure 1 visualizes belief space B left simplex (B, a1 , z1 )right. right chart based parameters: p11 = 0.5, p21 = 0.4 p31 = 0.1.belief states Ai following: A1 = (0.5, 0.5, 0.0)T , A2 = (0.4, 0.4, 0.2)TA3 = (0.1, 0.1, 0.8)T . see belief space triangle area belief simplexline segment area. next subsection, shall return point showwhy.b(s3)b(s3)1111111100000000(0,0,1.0)1111111100000000(0,0,1.0)111111110000000011111111000000001111111100000000b(s1)11111111000000001111111100000000111111110000000011111111000000001111111100000000(1.0,0,0)111111110000000000000000(0,0,0) 111111111111111100000000111111110000000011111111000000001111111100000000111111110000000011111111000000000000000011111111(0,1.0,0)* A3b(s1)A2(1.0,0,0)*(0,0,0)* A1b(s2)(0,1.0,0)b(s2)Figure 1: graphical representation belief space belief simplex. See text explanations.show belief subset (B), continue define transition observationmodels action a2 .2 may follow three assumptions a1 define modelsa2 , give different set transition probabilities a2 differs a1 .second assumption observation z1 z2 received probability, matrix Pai ,z1 identical Pai ,z2 {1, 2}. So, simplex (B, ai , z1 )identical (B, ai , z2 ) i. such, subset (B) consists two line segmentsentire belief space.23.3 Belief Subset Belief Spacediscuss relationship set (B) belief space B. Since set (B)union simplices, helps show simplex (B, a, z) related beliefspace B. action observation z, turns matrix derivedtransition observation models plays central role determining simplex.matrix, denoted Paz , dimension |S| |S| entry (s, s0 ) jointprobability P (s0 , z|s, a), i.e.,Paz =P (s01 , z|s1 , a)P (s02 , z|s1 , a)0P (sn , z|s1 , a)P (s01 , z|s2 , a)P (s02 , z|s2 , a)0P (sn , z|s2 , a)P (s01 , z|sn , a)P (s02 , z|sn , a)0P (sn , z|sn , a).2. components POMDP affect discussions omitted convenience.130fiRestricted Value Iteration: Theory Algorithmsmatrix used relate next belief (b, a, z) current b. b(b, a, z) viewed column vector form, belief update Equation (1) rewritten1(b, a, z) = p(z|b,a)Paz b. Hence, (b, a, z) transformation b matrix Pazcalled transformational matrix. following lemma characterizes conditionsimplex (B, a, z) belief space B.Lemma 2 [a, z], exists bijection simplex (B, a, z)space B matrix Paz invertible 3 .1Paz b (B, a, z) setseen fact (b, a, z) = p(z|b,a)transformed belief states belief space. Consequently, simplex (B, a, z)proper subset B matrix Paz degenerate. note matrix Paz degenerateexists state s0 P (z|s0 , a) = 0.0, i.e., state agentnever receive observation z (if action performed). entriesrow corresponding s0 0.0 matrix. case, lemma, set(B, a, z) must proper subset belief space B.Corollary 1 state P (z|s, a) = 0.0, set (B, a, z) propersubset belief space B.However, (B, a, z) proper subset necessarily imply existsstate P (z|s, a) = 0.0. Consequently, determine belief simplexproper, corollary provides sufficient condition; contrast, Lemma 2 providessufficient necessary condition. illustrated continuing discussionsPOMDP example.Example (Continued) consider simplex (B, a1 , z1 ). second assumption,z1 observed state. So, exist state P (z1 |s, a1 ) = 0.0.hand, matrix Pa1 z1 degenerate two rows.Lemma 2, simplex (B, a1 , z1 ) proper set belief space. fact, seenFigure 1, line segment, viewed degenerate belief space.2proceed discover relationship belief set (B, a, z) beliefspace B. Since (B, a, z) union simplices (B, a, z), proper subsetbelief space simplex. turn, requires transformational matrixdegenerate.Theorem 3 subset (B) proper subset belief space B transformationalmatrices actions observations degenerate.3.4 Subset Value Functionsdiscuss value functions whose domains belief subset (B, a, z) (B). simplicity,refer subset value functions. problem examine is, given setvectors representing subset value function, compute minimal set w.r.t. beliefsubset. first consider case subset simplex.3. matrix invertible determinant non-zero. degenerate otherwise.131fiZhang & Zhangorder calculate minimal set vectors, one needs determine usefulnessvector set w.r.t. simplex. Let vector set V simplex (B, a, z).vector useful w.r.t. (B, a, z) belief state b simplexb b + x x sufficiently small positive number vectorset V{}. Moreover, belief state b exists, since simplex, b mustPrepresentable belief states basis B (B,a,z) , i.e., b = (bi , a, z).Preplace b (bi , a, z) b b + x, condition determining usefulnessequivalent this: whether exists series nonnegative numbersvector V,X(bi , a, z)X(bi , a, z) + x.Rewriting inequality,X[ (bi , a, z)]X[ (bi , a, z)] + x.(6)determine usefulness, procedure simplexLP Table 1 used.optimality linear program reached, one checks objective x. positive,exists belief state belief simplex (B, a, z) belief state dominatesPvectors. belief state witness point . represented (bi , a, z)solutions (values variables) linear program. case,Pbelief state (bi , a, z) returned. cases, belief state returneduseless vector.simplexLP(, V, B (B,a,z) ):1. Variables: x,2. Maximize: x.3. Constraints:PP4.[ (bi , a, z)][ (bi , a, z)] + x V {}i, (bi , a, z) B (B,a,z)P5.= 1, 0 i.simplexPrune(V, B (B,a,z) ):1. U V, V2. U3.b simplexLP(, U, B (B,a,z) )4.b 6= null5.V V {}6. Return VTable 1: procedure compute minimal set vectors simplexdetermine vectors usefulness given set, one linear program needs solved.vector useless, removal change value function set induces.132fiRestricted Value Iteration: Theory AlgorithmsTherefore, compute minimal set given set V w.r.t. simplex, one needs solve|V| linear programs.procedure implemented simplexPrune Table 1. input two arguments:set vectors V 4 basis simplex B (B,a,z) . set U initializedset V set V empty line 1. Useful vectors added set Vsequel. vector set U, line 3 procedure simplexLP called determineuselessness. returns belief state, vector added set V line 5. Eventually,set V becomes minimal representation U w.r.t. simplex (B, a, z).compute minimal set vectors w.r.t. subset (B), one needs determinevectors usefulness w.r.t. subset. turn, one needs determine usefulness w.r.t.simplex. Again, let set V vector . useful w.r.t. simplex,must useful w.r.t. subset. However, useless w.r.t. simplex, may usefulw.r.t. another simplex. Hence, simplex, identified useful,need check subsequent simplices. simplices examined,useless w.r.t. simplices, useless w.r.t. subset. removing uselessvectors w.r.t. subset, one obtains minimal set.4. Subset Value Iterationsection, first describe value iteration algorithm belief subset (B).show algorithm able achieve near optimality. Finally, analyzecomplexity report empirical studies.4.1 Belief Subset MDPsubset (B) closed, able define so-called belief subset MDP (orsimply subset MDP). state space chosen subset (B) componentsMDP transformed original POMDP (Section 2.3).difference two MDPs lies state spaces: state space beliefsubset MDP subset state space belief space MDP.4.2 Subset DP Updates(B)MDP theory, subset MDP admits following DP update equation Vnrepresents nth-step value function.(B)Vn+1 (b) = max{r(b, a) +XP (z|b, a)Vn (B) ( (b, a, z))} b (B).(7)z(B)Following equation, implicit DP update computes minimal set Vn+1 represent (B)(B)(B)ing value function Vn+1 Vnrepresenting Vn . Note domains valuefunctions belief subset (B). simplicity, step called subset DP update.Implicit subset DP updates carried standard DP updates. Here, presenttwo-pass algorithm due conceptual simplicity (Monahan, 1982). constructs4. simplicity, assume set V contain duplicate vectors. Duplicates removedsimple componentwise check.133fiZhang & Zhangnext set vectors two steps enumeration step enumerating possible vectorsreduction step removing useless vectors. following, focus enumerationstep. reduction step, since usefulness vector w.r.t. subset (B),techniques preceding section used.(B)(B)Given set Vn , vector representing set Vn+1 defined pair(B)action mapping set Z observations set Vn . precise,action mapping , vector, denoted a, , defined follows 5 . S,a, (s) = r(s, a) +XXzP (s0 |s, a)P (z|s0 , a)z (s0 )(8)s0z mapped vector observation z.enumerate possible combinations actions mappings above, definevarious vectors. vectors form set{a, |a A, : Z Vn (B) & z, z Vn (B) }.(9)(B)(B)set denoted Vn+1 . MDP theory, represents value function Vn+1(B)set Vn(B)represents Vn.(B)(B)(B)Lemma 3 set Vn+1 represents value function Vn+1 Vn(B)represents Vn.DP update works collective fashion directly computes valuefunctions (B). alternative way conduct DP updates compute value functions individual simplices one one. rationale that, letting DP updatework finer-grained belief subsets, could efficient collective ver (B,a,z)sion. DP update individual fashion constructs collection {Vn+1 } vector sets(B,a,z)(B,a,z)(B)given collection {Vn|a A, z Z} Vnrepresents Vn(B,a0 ,z 0 )simplex (B, a, z). consider construct set Vn+1one simplex (B, a0 , z 0 ).(B,a0 ,z 0 )Likewise, vector a, Vn+1defined action mapping .fact (b, a, z) must (B, a, z) b implies z, z restricted(B,a,z)vector set Vn. altering actions mappings, one obtains followingset:{a, |a A,: Z a,z Vn (B,a,z) , & z, z Vn (B,a,z) }.(10)differs (8) observation z, mapped vector restricted(B,a,z)(B,a0 ,z 0 )set Vn. set denoted Vn+1. obtain minimal representation,one removes useless vectors set w.r.t. simplex (B, a0 , z 0 ). value function(B,a0 ,z 0 )(B)set Vn+1induces equal value function Vnbelief simplex(B, a0 , z 0 ).5. procedure defining vector actually constructs (n+1)th-step policy tree. (See, e.g., ZhangLiu 1997, details.)134fiRestricted Value Iteration: Theory Algorithms(B,a,z)Lemma 4 action observation z, set Vn+1functionplex.(B)Vn+1simplex (B, a, z)(B,a,z)Vnrepresents value(B)represents Vnsim-Although subset DP updates carried either collectively individually,essentially equivalent terms value functions induced.(B,a,z)Theorem 4 Let U = a,z Vn+1(B). b (B), U(b) = Vn+1 (b).worthwhile note two pairs actions observations, simplices(B, a1 , z1 ) (B, a2 , z2 ) might disjoint. remarks order(B,a ,z )case. First, Theorem 4, b intersection simplices, Vn+1 1 1 (b) =(B,a ,z )(B)Vn+1 2 2 (b). sets represent Vn+1 (B). Second, subset DPupdate carried individually, may generate vectors collective version.(B,a ,z )(B,a ,z )two sets Vn+1 1 1 Vn+1 2 2 may contain duplicate vectors.Finally, note achieve computational savings, sophisticated algorithmsstandard DP updates applied subset DP updates. Let us take incremental pruning,one efficient algorithms, example (Cassandra et al., 1997; Zhang & Liu,1997). standard incremental pruning, pruning operations w.r.t. beliefspace; however, used subset DP updates, pruning operations w.r.t.belief subsets.4.3 Analysisanalyze several theoretical properties subset value iteration algorithm. mainresults include: value functions generated subset value iteration equivalentstandard value iteration sense; achieve near optimality, value iteration needsaccount least belief subset (B); value function generated subset valueiteration used near optimal decision-making entire belief spacealgorithm appropriately terminated.4.3.1 Belief Subset, Value Functions Value Iterations(B)Subset value iteration generates series {Vn } value functions. initial value(B)function V0initial V0 standard value iteration (B), subset valueiteration generates series value functions standard value iteration (B).(B)Theorem 5 V0b (B).(B)(b) = V0 (b) b (B), Vn(b) = Vn (b) nProof: first consider one DP update computing value function Vn+1 currentVn DP Equation (2). right hand side, since (b, a, z) must belong subset(B), notation Vn ( (., ., .)) interpreted value function subset (B) ratherbelief space B. Comparing DP Equation (2) belief space B Equation (7)(B)belief subset (B), see Vn+1 Vn+1 represent value function (B)(B)Vn Vn.135fiZhang & Zhangtheorem true n = 0 given condition. true n > 0 induction.2(B)interestingly, value function Vnstep n used derive valuefunction Vn+1 standard value iteration. see why, first note subset value function V (B) used define value function (say V ) one-step lookahead operationfollows:V (b) = max{r(b, a) +XP (z|b, a)V (B) ( (b, a, z))} b B.(11)zso-defined V called V (B) -improving value function. Second, comparing Equations(B)(B)(11) (2), see Vn -improving value function actually Vn+1 Vnequal Vn (B).Consequently, although subset value iteration works (B), value functions generated standard value iteration derived. sense, say (B) sufficientbelief subset since enables subset value iteration preserve standard value functionswithout loss.Since subset value iteration retains quality value functions, regardedexact algorithm. One interesting question is, value iteration intends retain quality,work proper subset (B)? general, answer no. reason follows.(B)compute Vn+1 , one needs keep values Vnbelief states (B). Otherwise,one accounts proper subset B0 (B), proven exists belief stateb B, action observation z (b, a, z) belong B0 .known value update Vn+1 (b) depends values possible next belief(B)states. Due unavailability Vn ( (b, a, z)), value Vn+1 (b) cannot calculatedexactly. Consequently, value iteration works proper subset (B), cannotexact. words, approximate algorithm. make exact, valueiteration needs consider least (B). sense, subset (B) said minimalsufficient set.Informally use Figure 2 illustrate relationship belief subsets valueiteration. figure, circles represent belief sets. minimum belief subset valueiteration retain quality (B), maximum subset belief space B itself.value iteration works belief subset B0 (denoted dashed circles) (B)B, quality also retained. However, works proper belief subset (B),general unable retain quality value functions.(B)BBFigure 2: relationship belief subsets value iteration136fiRestricted Value Iteration: Theory Algorithms4.3.2 Stopping criterion decision makingSubset value iteration starts initial value function. continues, Bellman(B)(B)residual maxb (B) |Vn (b) Vn1 (b)|, maximum difference two value functions subset (B), must become smaller. MDP theory, quantity falls(B)(1 )/(2), value function Vn1 -optimal w.r.t. subset MDP. following,show -optimality extended entire belief space appropriatelyterminating subset value iteration algorithm.(B)Let output value function Vn1 . used define policy belief(B)state B Equation (3) V replaced Vn1 . policy said(B)Vn1 -improving. Note policy prescribes action belief state beliefspace. following theorem tells one terminate subset value iteration(B)Vn1 -improving policy -optimal belief space.(B)(B)(B)Theorem 6 maxb (B) |Vn (b)Vn1 (b)| (1 )/(22 |Z|), Vn1 -improvingpolicy -optimal entire belief space B.Proof: See Appendix A.2theorem important two reasons. First, although subset value iteration outputssubset value function, -optimal value functions entire space induced(B)one-step lookahead operation. Second, implies Vn1 -improving policy optimal condition met. know (B) consists possible belief statesagent encounters initial belief state. However, assumptioninitial belief state. may may belong set. theorem means agentstill able select near optimal action initial belief state evensubset. fact, agent always select near optimal action belief stateentire belief space.Finally, note guarantee -optimality, compared conditionTheorem 1, subset value iteration uses restrictive condition. convenience,sometimes called strict stopping criterion. contrast, condition standard valueiteration called loose stopping criterion.4.4 Complexityput use POMDP, subset value iteration algorithm would take two steps:determining algorithm bring savings time running subsetvalue iteration can. first step needs compute |A||Z| determinants |Paz |. Sincecomplexity computing |Paz | |S|3 , first step complexity O(|A||Z||S|3 ).polynomial part complexity subset value iteration. second stepmuch harder first step. known finding optimal policy evensimplified finite horizon POMDP PSPACE-complete (Papadimitriou & Tsitsiklis, 1987;Burago, de Rougemont, & Slissekno, 1996; Littman, Goldsmith, & Mundhenk, 1998). Recently, proven finding optimal policy infinite-horizon POMDPincomputable (Madani., Hanks, & Condon, 1999).compare subset value iteration standard value iteration. Standard DPupdates improve values space B, subset DP updates improve values137fiZhang & Zhang(B)subset (B). initial set V0equal initial set V0 standard value iteration,(B)(B)(B) subset B, vectors V1must V1 , V1subset(B)V1 . Inductively, Vnsubset Vn n. analysis suggests two advantagessubset value iteration subset (B) proper subset belief space B. First,fewer vectors needed represent value function belief subset.representational advantage space. Vn+1 , size large |A||Vn ||Z| .(B)(B) |Z|Vn+1 , size large |A||Vn | . Clearly, subset DP update generates fewervectors. Second, fewer vectors means lesser degree time complexity since computingvectors needs solve linear programs. computational advantage time.However, advantages strongly depend upon size subset (B).simplex (B, a, z) belief space B DP updates conductedindividual fashion, subset DP updates could |A||Z| times slower standard DPupdates. worst case complexity. Fortunately, discussions previoussection (Theorem 3), know given POMDP able determine whetherselected subset (B) proper subset belief space solving it.Although Theorem 3 gives condition determine subset value iterationefficient standard value iteration POMDP, answer questionmuch savings algorithm bring about, turns difficultproblem theoretical analysis. difficulty lies size set (B)also vectors representing step optimal value functions. Let us assume(B) proper subset belief space. imagine least two cases. one case,iteration step value function useful vectors subset (B),subset value iteration efficient. case, iterationstep value function useful vectors subset (B), subset value iterationcomplexity standard value iteration asymptotic sense. general, givenPOMDP, difficult predict vectors scatter around belief subsetsbelief space. Consequently, hard predict much saving subset value iterationalgorithm bring POMDP without solving it.4.5 Empirical Studiespresent empirical results two variants designed maze problemproblems standard test-bed subsection. common settings experimentspaper follows. experiments conducted UltraSparc II machinedual CPUs 256MB RAM. codes written C executedUNIX operating system Sola 2.6. solving linear programs, use commercialpackage CPLEX V6.0. discount factor set 0.95 round-off precision set106 . stated otherwise, quality requirement set 0.01. useincremental pruning compute representing sets value functions belief spacebelief subsets.compare performances subset standard value iteration. simplicity,denote respectively ssVI VI. iteration, compare VI ssVItwo measures: sizes sets representing value functions total time DP updates.138fiRestricted Value Iteration: Theory Algorithms4.5.1 Maze Problemmaze problem specified Figure 3. 10 locations goal location 9.robot agent execute four move actions change position, optionally lookaction observe surroundings declare action announce success goalattainment. move actions achieve intended effects probability 0.8,might effects probability 0.1 (the agents position remains unchanged)lead overshooting probability 0.1. Moving maze walls leaves agentoriginal location. actions change agents position. time point,robot receives null observation giving useful information all, reads four sensorsreason current position. sensor informs robot whetherwall nothing along direction. figure thick lines stand walls thin linesnothing (open). instance, agent location 2, ideally string owow (inorder East, South, West North) received. Specific parameters instantiatedrelevant empirical analysis. robot required maximize infinite discountedsum rewards.12910783456Figure 3: maze problemTwo variants maze designed test ssVI VI. denotedmaze1 maze2. maze1, ssVI efficient; maze2, ssVI less efficient.Case I: (B) Bmaze1 problem state space 10 locations, action space size 5 (fourmove one declare) observation space size 6 (strings four letters).ideal string received certainty action performed. agent declaresgoal location 9, receives reward 1 unit; location 10, receivesreward 1. combinations actions observations lead reward.collect results Figure 4. first chart figure depicts total timeDP updates log-scale VI loose stopping criterion ssVI strict one(Section 4.3.2). compute 0.01-optimal value function, VI took 20,000 seconds 162iterations ssVI strict stopping criterion took 900 seconds 197 iterations.note ssVI needs iterations still takes much less time. performancedifference big. Moreover, iterations means value function generatedssVI closer optimality.surprising result take look matrix Paz actionobservation z. know matrix impacts size simplex (B, a, z).dimension matrix 10 10. entry Paz (i, j) producttransition probability P (sj |si , a) observation probability P (z|sj , a). Let us assume139fisizes representing sets(logscale)Zhang & ZhangCPU seconds(logscale)10000010000100010010VIssVI10.10.010 20 40 60 80 100 120 140 160 180 200number iterations10000100010010VIssVI10 20 40 60 80 100 120 140 160 180 200number iterationsFigure 4: Comparative studies VI ssVI Maze1observation owow. Hence, possible locations may 2 5. Regardless actionsexecuted, entries row 2 5 Paz non-zero. Therefore, matrix highlysparse non-invertible simplex (B, a, z) much smaller B. analysisholds similarly combinations actions observations. Hence, ssVI accountssmall portion belief space. explains ssVI efficientVI. addition, expect sets generated ssVI much smallerVI.confirmed second chart figure. depicts sizes setsrepresenting value functions generated ssVI VI iteration. counting(B)size Vn , collect sum sizes representing sets |A||Z| simplices.note iteration VI always generates much vectors ssVI.sizes curves increase sharply first iterations stabilize. size VIreaches peak 2466 iteration 11 maximum size ssVI 139 iteration10. size VI 20 times many ssVI. magnitude consistentperformance difference. sizes stabilize, sizes sets generatedVI around 130 around 50 ssVI.Case II: (B) = Bproblem maze2 designed show ssVI could less efficient VIselected belief subset (B) equal belief space B. problem state space10 locations, action space size 6 (four moves, one stay one declare)observation space size 7 (6 strings null telling nothing). action staychange agents position. maze2 complications observation model. Duehardware limitations, move action, probability 0.1, agent receiveswrong report string owow collected owww woww wowo. declareaction executed, agent always receives null observation. addition, agentexecutes stay, receives either null observation probability 0.9 ideal stringsurrounding locations probability 0.1.reward model accordingly changed reflect new design considerations.assume agent needs pay information states. purpose,140fiRestricted Value Iteration: Theory Algorithmssizes representing sets(logscale)agent executes stay, really nothing thus yields cost (i.e., negative reward).contrast, move actions always cause cost 2. Depending locationsexecutes declare, receives rewards costs: location state 9, receivesreward 1; state 10, receives cost 1; otherwise, leads rewards.stay action attractive yields cost leads useful observationstates small likelihood.empirical results collected Figure 5. First, note VI ssVIable run 11 iterations within reasonable time limit (8 hours). first chartfigure presents time costs along iterations. run 11 iterations, ssVI takes 53,000seconds VI takes around 30,900 seconds. Therefore, ssVI slower VIproblem. However, magnitude performance difference big. explain this, letus consider matrix Paz action stay observation null. transition matrixidentity state lead null observation probability 0.9stay executed. Therefore, matrix Paz invertible simplex (B, a, z)belief space B. ssVI needs account additional simplicescombinations actions observations, ssVI must less efficient VI. explainsperformance difference time ssVI VI.CPU seconds(logscale)10000010000ssVIVI10001001010.10.010246810number iterations1210000ssVIVI100010010102468number iterations1012Figure 5: Comparative studies VI ssVI maze2also anticipated ssVI generate vectors VI(B)iteration size Vndefined sum individual sets it.confirmed demonstrated second chart Figure 5. curve ssVI alwaysupper side VI. 11th iteration, ssVI generates 3,300 vectorsVI generates around 1,700 vectors.4.5.2 Experiments Test-Bedvalidate performance subset value iteration different problem domains,collected results algorithm standard test-bed maintained TonyCassandra 6 . literature, eight problems commonly referred 4x3CO,Cheese, 4x4, Part Painting, Tiger, Shuttle, Network, Aircraft. Table 2 presents detailed6. See URL http://pomdp.org/pomdp/examples/index.shtml141fiZhang & Zhang|S||Z||A|VI(Time)ssVI(Time)VI(#)ssVI(#)subspace4x3CO114113.5263.28443/1yesCheese114714.0685.441432/2yes4x4162427.4785.442042/10yesPaint44238.7585.20922/9Tiger22382.40145.21922/9Shuttle8236130.691437.3220898/45yesNetwork72413283.152810.21491201/50yesAircraft12561723193.34425786.4920713236/428yesTable 2: Comparative studies ssVI VI standard test-bedstatistics problems. table, Rows 24 give sizes problem parameters,namely number states, observations actions. Row 5 6 show CPU secondsstandard subset value iteration algorithms compute 0.01-optimal policyproblem. Row 7 shows number vectors representing 0.01-optimalvalue function standard value iteration. experiments, implemented subsetvalue iteration individual fashion. Row 8, entry takes form /, denotingtotal number vectors |A| |Z| simplices maximum number vectorsamong simplices subset value iteration terminates. last row showswhether belief subset (B) proper subset belief space.discussing performances subset value iteration algorithm, categorizetested problems three classes. first class, subset (B) actuallybelief space. Subset value iteration must less efficient standard value iteration.reason follows: exists least one belief simplex value iterationcomplexity standard value iteration; moreover, subset value iterationneeds account simplices. Example problems tiger paint. Let us takepaint problem instance. results show two simplicesbelief space. 0.01-optimal value functions represented 9 vectors,number vectors representing 0.01-optimal value functionentire belief space. second class tested problems, set (B)proper subset belief space, meanwhile numbers vectors representingvalue functions belief space individual simplices small. Subset valueiteration may efficient standard value iteration overheadaccounting large number simplices. Example problems include 4X3CO, cheese4X4. Let us take 4X3CO instance. 0.01-optimal value function entirebelief space represented 4 vectors, whereas 0.01-optimal value functionsimplex represented 1 vector. Since subset value iteration account44 simplices, subset value iteration less efficient standard value iteration.third class tested problems, set (B) proper subset belief space,meanwhile numbers vectors representing value functions belief spacemoderately large. subset value iteration algorithm efficient standardvalue iteration algorithm. Examples include shuttle, network aircraft. Let us takenetwork instance. 0.01-optimal value function belief space represented142fiRestricted Value Iteration: Theory Algorithms491 vectors, whereas 0.01-optimal value function (B) represented less201 vectors (note duplicates across belief simplices). maximum sizerepresenting sets simplices 50. case, expect savings broughtsubset value iteration outweighs overhead accounting simplices.result shows subset value iteration 5 times faster standard value iteration.Combining results maze problem, see computationalsavings brought subset value iteration vary different problem domains. Theorem3 used determine whether subset value iteration bring computationalsavings POMDP. event belief set (B) proper subset beliefspace, magnitude savings needs determined empirical evaluation.5. Informative POMDPssection, study special POMDP class, namely informative POMDPs.POMDP class, natural belief subsets value iteration work with.show formally define subsets. value iteration belief subsetsdescribed (Zhang & Liu, 1997), focus compare algorithmgeneral subset value iteration developed previous section.5.1 Motivationnoted authors, reality agent often good, although imperfect, idealocations (Roy & Gordon, 2002). instance, mobile robots real worldsystems local uncertainty, rarely encounter global uncertainty. Let us exemplifyusing maze Figure 3. Suppose time point agent receives stringfour letters certainty. total, 6 observations, owww, owow, owoo, wwow,wowo woww regardless executed actions. enumerate possible observationsset locations agent receives observations, endfollowing table.observationsowwwowoowowostates{1 }{ 3,4 }{ 7,8}observationsowowwwowwowwstates{ 2, 5}{6}{ 9,10 }hand, strings used infer agents locations. instance,string owoo received, world must location 3 4. Hence, observation owoorestricts world small range world states. fact, observation restrictworld two states although world ten. reason, POMDPsaid informative.general, agent perceives world via observations. Starting state,agent executes action receives observation z, world states categorizedtwo classes observation model: states agent states cannot.Formally, former {s|s P (z|s, a) > 0}. set denoted az . useset define informativeness. [a, z] pair said informative size |S az |much smaller |S|. observation z informative [a, z] informative everyaction giving rise z. POMDP informative observations informative.143fiZhang & Zhanginformative POMDPs, since observation restricts world small setstates, agent knows world cannot state outside small set.words, states outside set, agent zero beliefs. Consequently,observation also restrict belief states belief subset.5.2 Belief Subset Selectioninformative POMDPs, select belief subset (B) before. Combining informativeness assumption Corollary 1, know (B) proper subset beliefspace. So, value iteration (B) carries space time savings. section,choose alternative belief subset value iteration. Compared subset (B),subset choose yields several advantages. First, conceptually simplegeometrically intuitive. Second, facilitates employing low dimensional representationvectors. Third, may lead additional savings time observation modelsPOMDP independent actions. latter two advantages shown later.define belief subset (say (B)), first define subset (B, a, z) actionobservation pair. Then, belief subset (B) formed taking union (B, a, z)action observation pairs. specific,X(B, a, z) = {b|b(s) = 1.0, az , b(s) 0}(12)sS az(B) = a,z (B, a, z).trivial see (B, a, z) belief simplex. proven belief stateb, (b, a, z) must (B, a, z). Therefore, (B, a, z) subset (B, a, z). Consequently,(B) subset (B). summarized lemma below. lemma usefuldiscuss value iteration algorithm working belief subset (B).Lemma 5 POMDP, (B) (B).interest compare -simplex -simplex pair z. Althoughsimplices generated list belief states, -simplex intuitive geometricmeaning. belief state basis (B, a, z) unit vector, i.e., probabilitymass one state. Therefore, belief state basis must boundary pointbelief space. contrast, belief state basis -simplex interior point.See Figure 1 example, A2 , A3 interior points A1 boundary pointbelief space.5.3 Value Iteration (B)theoretical perspective, feasibility conducting value iteration (B)justified Lemma 1. Combined Lemma 5, subset (B) closed set. Hence,MDP theory applicable defining DP update equation. discussionsrelationship value iteration Section 4.3, value iteration working (B) retainsquality value functions.exploit informative feature value iteration (B). briefly outlinesubset value iteration algorithm refer readers detailed description (Zhang144fiRestricted Value Iteration: Theory Algorithms& Liu, 1997). basic idea reduce dimensions vectors representing setsvalue functions. Note pair [a, z], since beliefs states outside az zero,vector representing set value function simplex (B, a, z) needs|S az | components. individual fashion, DP update (B) computes collection(B,a,z)(B,a,z)(B,a,z){Vn+1 } collection {Vn} Vnnth-step value functionazvectors |S | dimensions. procedure conducting DP update parallelSection 4.2 except (B, a, z) replaced (B, a, z). enumerationstep, building vector belief simplex (B, a0 , z 0 ) using Equation (10), need0 0define components corresponding set z . reduction step,00(B,a ,z )constructed set Vn+1, pruning procedure called remove useless vectors obtainminimal representation set. Note lower dimension feature also usedcut number variables setting linear programs.Interestingly, DP updates (B) account larger subset (B).Hopefully, since DP updates (B) explicitly employ economy representation,could efficient. addition, DP updates (B) another advantageevent observation models POMDP independent actions, i.e.,probabilities P (z|s, a) independent a. Hence, given observation z, simplices(B, a, z) actions. Therefore, DP updates (B) account|Z| -simplices. However, DP updates (B) usually need account |A||Z|-simplices observation determines different -simplices combineddifferent actions.5.4 Empirical Studiesconducted experiments compare VI, ssVI infoVI, refers value iteration exploiting low-dimension feature. experiments maze1 (defined Section4.5) found elsewhere (Zhang & Zhang, 2001; Zhang, 2001). results, togetherexisting results (Zhang & Liu, 1997), showed value iteration (B)significantly efficient standard value iteration. reference, mentionfeasible integrate point-based technique value iteration (B) ordertake advantage reducing iteration number accelerating iterative steps(Zhang & Zhang, 2001b). demonstrate this, include results 96-state POMDPAppendix B.5.5 Restricted Value Iteration Dimension Reductioncompare value iteration algorithms previous section.comparison, would like emphasize working belief subsets implyworking low-dimensional vectors.Although algorithms work belief subsets, mechanisms exploited achievecomputational gains different. general value iteration works beliefsubset (B) dimension representing vectors number states,whereas value iteration (B) works superset (B) dimensionvectors smaller number states. facilitate demonstrating reducedbelief set low-dimensional representation respectively contribute computational gains, experimented carefully designed maze problem amenable145fiZhang & Zhangalgorithms. However, worth pointing working reduced belief setmean vectors represented low dimensions. illustratepoint continuing discussions example Section 3.3. example showsprimary advantage value iteration (B) stems size chosenbelief subset rather dimension reduction representing vectors.Example (Continued) POMDP example presented Section 3.2, subset (B)consists two line segments entire belief space. Clearly value iteration(B) efficient standard value iteration. However, one runs value iteration(B) POMDP anyhow, algorithm less efficient standard valueiteration algorithm. follows (1) set ai zj equal set statesaction ai observation zj second assumption, (2) -simplex actuallybelief space definition Equation (12). solve POMDP,susbet value iteration algorithm definitely better choice value iterationalgorithm informative POMDPs.26. Near-Discernible POMDPssection, study near-discernible POMDPs. POMDP class, developanytime value iteration algorithm working growing belief subsets.6.1 Motivationdiscernible POMDP assumes uncertainty world statesvanishes particular action executed observations pertain action fullyreveal identities world (Hansen, 1998). research near-discernible POMDPsmotivated two aspects. One arises origin applying POMDPframework planning uncertainty. achieve goal location, agentchange positions performing goal-achieving actions also reasonsurroundings performing information-gathering actions. However, one time pointagent cannot simultaneously move positions observe environments. instance,information-gathering action performed, agent cannot move positions meanwhile. aspect motivating concept near-discernibility arises existingresearch community. Near-discernible POMDPs generalize discernible POMDPseven information-gathering action performed, agent get rough,rather exact, idea world states uncertainty vanishes sense.revise maze problem fix ideas first motivation. action space consistssix actions: four moving actions, look declare. move actions declareperformed, observation null received agent gets information all.look performed, ideal string received agent gets imperfect information sincedifferent locations might yield string. one hand, achieve goal location,agent change positions. hand, declare goal attainmentconfidence, perform look reason environment. Arbitrarily declaringgoal attainment leads penalty. Consequently, time point agent facesproblem choosing move look.146fiRestricted Value Iteration: Theory Algorithmsnote subset value iteration algorithm usually yields computational advantage near-discernible POMDPs. give example subset (B)belief space B assumptions. Suppose maze square grid.Locations numbered row indices locations increaseleft right. assume move action achieves intended effects high likelihood, may effect (i.e., agents location remains unchanged) may leadovershooting small probability. assumptions, transition matrixaction east upper-triangular invertible. location null receivedpositive probability move, transformational matrix Peast,null invertible.Theorem 3, belief subset (B, east, null) equal belief space B.solution near-discernible POMDPs rests intuition agent needsinterleave goal-achieving actions information-gathering actions. typical sequenceexecuted actions consist several goal-achieving actions informationgathering action. difficulty frequently agent execute informationgathering action. section, consider action observation sequences containing goal-achieving actions incrementally. show sequencesused determine belief simplices. sequences added, union beliefsimplices grows. following, give technical preparations describealgorithm designed near-discernible POMDPs. order put discussionsgeneral context, shall use information-rich information-poor actions insteadinformation-gathering goal-achieving actions respectively.6.2 Histories, Belief Subsets Value Functionshistory sequence ordered pairs actions observations. usually denotehistory h. number pairs actions observations referred lengthhistory. history length l denoted [a1 , z1 , , al , zl ]. agents initial beliefstate b history h length l realized, belief state updatedtime step. notation (b, h) denotes belief time point l. set (B, h)defined bB (b, h), consisting possible belief states agentstep l starts belief history h realized. Note h length 1(sayh = [a, z]), (B, h) degenerates previous notation (B, a, z).Lemma 6 history h, belief subset (B, h) simplex.set histories usually denoted H. belief subset (B, H) denotes unionsimplices histories set H, i.e., hH (B, h). Value functions simplex(B, h) belief subset (B, H) referred V (B,h) V (B,H) respectively. Givenset V (B,h) representing value function V (B,h) , procedure simplexPrune(V, B (B,h) )Table 1 computes minimal representation V (B,h) . context history,occurrences basis B (B,a,z) replaced B (B,h) .6.3 Space Progressive Value Iterationdescribe space progressive value iteration (SPVI) algorithm. anytime algorithm, SPVI begins belief subset gradually grows it. certain stopping147fiZhang & Zhangcriterion met, SPVI terminates returns set vectors agents decision making.6.3.1 Algorithmic structureSPVI interleaves value iteration (computing value function belief subset) subsetexpansion (expanding current belief subset larger one). belief subsets SPVIintroduced sets histories. Subset expansion achieved incorporatinghistories. convenience, set histories determining i-th belief subset denotedHi . belief subset determined Hi (B, Hi ). value function constructedSPVI Hi V (B,Hi ) .pseudo-code Table 3 implements SPVI. set histories H0 (and thereforebelief subset (B, H0 )), value function V (B,H0 ) quality precision initializedline 1. step regarded 0th-step expansion belief subset. Noteset initial value function minimum reward pairs actions states.(This convergence issue discussed later.) Value iteration current subset(B, Hi ) conducted line 3, belief subset expanded subset (B, Hi+1 )constructing superset Hi+1 current set Hi line 4. Value function V (B,Hi )current belief subset set initial value function next subsetline 5. stopping condition satisfied line 7, SPVI goes next iteration;otherwise, terminates returns latest value function V (B,Hi1 ) .ensure efficiency SPVI, initial belief subset chosen small.end, set H0 {[a, z] | AIR , z ZIR } AIR set information-richactions ZIR set observations led actions. subset (B, H0 )small due discernability property.sequel, discuss value iteration belief subset, subset expansionstopping criterion detail.6.3.2 Value iteration belief subsetGiven set V vectors, set H histories precision threshold , value iterationcomputes improved value function belief subset (B, H). accomplishedconducting sequence DP updates. following, discuss implicit DP updates,convergence issue stopping criterion value iteration step.implicit DP update computes new value function current one beliefsubset (B, H). Let Uj (U0 = V) denote j-step value function. Thus, DP updatecomputes value function Uj+1 Uj . procedure computing Uj+1 Uj parallelcollective DP update Section 4. particular, defining vector a, given(B)action mapping Equation (9), occurrences Vnreplaced Uj .enumerating actions mappings, defined vectors form set Uj+1 . minimalrepresentation obtained removing useless vectors w.r.t. subset (B, H).convergence issue arises subset (B, H) may closed set.guarantee convergence value iteration, set Uj+1 union set Uj+1Uj DP update. Together fact initial value function setminimum reward actions states, sequence {Uj } monotonicallyincreases terms induced value functions. hand, value functions148fiRestricted Value Iteration: Theory AlgorithmsSPVI:1. 0, initialize H0 , V (B,H0 ) minsS,aA r(s, a), (1 )/22.3.V (B,Hi ) subsetVI(V (B,Hi ) , Hi , )4.< Hi+1 , (B, Hi+1 ) > expandSubset(V (B,Hi ) , Hi )5.V (B,Hi+1 ) V (B,Hi )6.ii+17. (stopping condition met)8. Return V (B,Hi1 )subsetVI(V, H, ):1. j 0, U0 V2.3.Uj+1 subsetDPUpdate(Uj , (B, H))4.Uj+1 Uj+1 Uj5.j j+16. ( maxb (B,H) |Uj (b) Uj1 (b)| )7. Return Uj1expandSubset(V, H)1. H0 H2. set V3..history maximal H .action information-poor4.[a, z] AIP ZIP5.H0 H0 {[h, a, z]}06. Return < H , (B, H0 ) >Table 3: Space progressive value iteration (SPVI)sequence upper bounded optimal value function. Consequently, value iteration(B, H) must converge. result, Bellman residual value functions,maxb (B,H) |Uj+1 (b)Uj (b)|, becomes smaller (B, H) value iteration continues.residual falls threshold , value iteration terminates.value iteration step implemented procedure subsetVI Table 3. Givenset V vectors, set H histories threshold , procedure computes improvedvalue function belief subset (B, H). Value function U0 set input set Vline 1. new value function Uj+1 computed DP update line 3. guaranteeconvergence, Uj+1 set union Uj Uj+1 line 4. stopping criteriontested line 6. met, latest value function Uj1 returned.6.3.3 Subset expansionGiven set V vectors set H histories, subset expansion step expands beliefsubset (B, H) larger one. achieved generating superset H0 H. new149fiZhang & Zhangbelief subset (B, H0 ) thus superset (B, H). Hence, key subset expansiongenerate history set H0 . following, propose two approaches generatinghistory set using intuition near-discernible POMDPs. approaches generatenew histories exploiting vectors V. begin analysis vectorsset V show use generate histories.Let vector set V. Remember defined pair actionmapping . convenience, action said associated action .addition, useful set V w.r.t. belief subset (B, H), must exist historyh H useful w.r.t. belief simplex (B, h). history h saidassociated history . associated history vector used generate newhistories extending history, i.e., appending pairs informative-poor actionsobservations history. Let AIP set information-poor actions ZIPset observations led actions. Extending history h results set{[h, a, z]|a AIP , z ZIP }. set contains |AIP ||ZIP | histories. history setcalled extension history h.generate H0 set H set V, one generic approach works follows.vector set V examined. associated history long associatedaction information-poor, produce extensions associated history. extensionadded H0 H0 . (The reason associated action vectorinformation-rich associated history sufficiently long.) ensure H0superset H, set H0 H beginning. Apparently, approach generatinghistories suffers exponential increase size |H0 | |AIP | |ZIP |.worst case vectors V associated information-poor actions, size|H0 | |H||AIP ||ZIP |. Consequently, i-step subset expansion, |Hi+1 |large |AIR ||ZIR |(|AIP ||ZIP |)i |AIR ||ZIR | size initial history set.alleviate problem, use heuristic approach generating H0 hopesize H0 increases moderately. exhaustive approach extends historiesassociated vectors prescribing informative-poor actions. heuristic approachextend histories. Instead extends maximal histories setH. (A history said maximal set none extensions set.)change made approach. indicated experiments,restriction effectively cut size history sets. Nonetheless, heuristicapproach shares worst-case complexity exhaustive approach.subset expansion step implemented procedure subsetExpansion Table3. Given set V vectors set H histories, computes expanded set H0expanded belief subset (B, H0 ). set H0 initialized H line 1. vectorV line 2, associated history maximal H action information-poor(line 3), extensions associated history added H0 (line 5). expandedset H0 also expanded belief subset (B, H0 ) returned line 6.6.3.4 Stopping criterion Decision-Makinganytime algorithm, SPVI terminated hard deadline reached. Anotherstopping criterion interest set follows. Given sufficiently large amounttime, SPVI would account many histories possible. (near) optimal policy150fiRestricted Value Iteration: Theory AlgorithmsPOMDP requires information-rich actions executed sequence informationpoor actions, SPVI able compute value function belief subset,consists possible belief states agent encounters guidedpolicy. sufficiently many expansions history sets hence belief subsets,vector associated maximal history prescribes information-rich action.vectors representing set prescribe information-rich actions, SPVI terminates.(near) optimal policy desired structure sequence actions, output valuefunction near optimal final belief subset.SPVI terminates, value function V (B,Hi1 ) used decision making.Similarly Equation (3), V (B,Hi1 ) -improving policy defined belief space.6.3.5 Efficiency SPVIefficiency SPVI depends selected belief subsets. belief subsetsclose belief space size, SPVI must inefficient. Fortunately, approachbelief subset expansion ensures initial belief subset small subsequentsubsets grow slowly. First, since H0 set pairs information-rich actionsobservations, initial belief (B, H0 ) relatively small. Second, subsequent beliefsubsets (B, Hi ) grow quickly. reason follows. extending history,information-poor pairs added end. Hence, first action observation pairhistories set Hi must information-rich. Therefore, history h set Hi ,(B, h) small size. Meanwhile, due heuristic generating history sets, sizes|Hi | would increase fast. characteristics make SPVI efficient comparedstandard value iteration algorithm.Although analysis empirically confirmed experiments below,worthy mention worst case number belief simplices grows exponentiallynumber |AIP ||ZIP |. Since history determines belief simplex, worstcase number belief simplices i-step subset expansionnumber histories, i.e., |AIR ||ZIR |(|AIP ||ZIP |)i (see third paragraph Section 6.3.3).6.4 Empirical ResultsSince SPVI works anytime manner, primary interest demonstratequality generated value functions varies time cost. However, availabilityoptimal solutions strongly depends tractability problems. nearoptimality available, compare directly value function generated SPVIsimulations. Otherwise, simply compare value functions SPVIapproximate algorithm QMDP (Littman et al., 1995; Hauskrecht, 2000). Althoughcomparison strict formal sense, provide clues quality valuefunctions.report results two variants base maze problem office navigationproblem. one variant, SPVI terminated finite number iterations outputvalue function near optimal; variant, SPVI quickly find high-qualityvalue function time goes (Zhang & Zhang, 2001a; Zhang, 2001). restsection, report results office navigation problem.151fiZhang & Zhangenvironment modeled floor plan authors home department.layout shown Figure 6. 35 states: 34 locations plus one terminal state.action space size 6 (four move, one look one beep replacing declaremaze problem). action except look leads null observation. introduceobservations, note figure, black bars represents doors grey bars representwalls display boards. look action yields observation strings four letterslocation indicating, four directions, door (d), emptywall (w), wall display board (b), nothing (o). total, 22 differentstrings. Hence, plus null observation, observation space size 23. Transitionprobabilities moves specified identically maze problem. Neither lookbeep changes states environment. location, look produces idealstring location probability 0.75. probability 0.05, produces nullobservation. Also probability 0.05, produces string ideallocation differs ideal string current location 1 character.robot receives reward 50 beeping location 22 reward -10beeping location (we dont want robot make lot noise). moveactions bring reward -2 lead robot bumping walls doors.rewards otherwise. reward look action always -1. robotneeds get location 22 beep someone main office comehand robot mail.32161116195101518914174781213MainOffice202122233425262728293433323031Figure 6: HKUST-CSD office environmentconduct simulations generated value functions existing exactalgorithm find near optimal value function. simulation consists 1000 trials.trial starts random initial belief state allowed run 100 steps.average reward across trials used measurement quality policiesderived value functions.Figure 7 presents results quality time costs. see SPVIfound policy whose average reward 19.6 80,000 seconds. SPVI manuallyterminated running 24 hours. found algorithm conducted threesteps subset expansion. data, first second expansion steps,152fiRestricted Value Iteration: Theory Algorithmsrewards simulation 18.4. far 19.6 obtained third expansionstep although difficult say close polices optimal. Comparedsolutions generated QMDP, policies generated SPVI clearly better.Quality Value Functions201918171615SPVIQMDP141312100100010000Time Seconds (in log-scale)100000Figure 7: Performance SPVI office navigation problemreference, Table 4 gives detailed statistics number histories, iterationsvectors subset expansion. note number iterationsthird column: conducting value iteration subsets, also use point-basedimprovements (Zhang, 2001). column, number point-based steps excluded.fourth column number vectors provides idea SPVI takes longtime problem. generates great number vectors.third expansion, uses 7,225 vectors represent value function belief subset.i-step expansion012histories#5386131iterations#467vectors#46451787225rewards18.4418.4419.65time1631615778183Table 4: Statistics HKUST-CSD environment SPVI7. Related Workpaper, propose restricted value iteration algorithms accelerate value iterationPOMDPs. Two basic ideas behind restricted value iterations (1) reducing complexity DP updates (2) reducing complexity value functions. section,discuss related work two categories. addition, give overview specialPOMDPs literature algorithms exploiting problem characteristics.153fiZhang & Zhang7.1 Reducing Complexity DP Updatesbroad sense, approaches reducing complexity DP updates roughly categorized two classes: approaches conducting value updates (stationary) belief subsetapproaches conducting value updates growing subset, although boundarytwo classes ambiguous cases.first class includes family grid-based algorithms, algorithms based reachability analysis, algorithms using state-space decomposition others. Grid-based algorithmsupdate values finite grid extrapolate values non-grid belief states (Lovejoy,1991; Hauskrecht, 1997; Zhou & Hansen, 2001). However, guarantee optimality,grid size often exponential dimension state space. tackle POMDPslarge state spaces, reachability analysis generally applicable technique. agentinformed initial belief, belief states encounter form finite set casefinite decision horizon. belief states structured decision tree AND/ORtree (Washington, 1997; Hansen & Ziberstein, 1998; Hansen, 1998; Bonet & Geffner, 2000).Although sometimes near optimality achieved initial belief state (Hansen,1998), algorithms cited articles cannot applied case unknowninitial belief. State-space decomposition effective way alleviate curse dimensionality. approach successfully applied MDPs (Dean & Lin, 1995; Dean,Givan, & Kim, 1998; Parr, 1998; Koller & Parr, 2000). Typically, solve MDP, onesolves number small MDPs uses solutions approximate originalMDP. However, state-space decomposition approach cannot directly generalizePOMDP context inherent difficulty incurred continuum beliefspace.theory algorithms restricted value iteration significant differencesapproaches. well chosen belief subset, restricted value iterationsachieve convergence optimality. differs grid-based algorithms computesvector-based representations value functions. Despite difference, possiblegrid-based algorithms benefit theory belief subset selection. possibilityyet investigated. instance, choosing grid points, one choosewithin belief subset (B). reason follows. Since belief states outside setnever reachable, values directly contribute value updates beliefsgrid. regard differences aforementioned algorithms ours,approach assumption agents initial belief, although belief subsetchosen via reachability analysis. algorithm differs decomposition techniquessolves reformulated MDP instead set small MDPs.Approaches conducting value updates growing belief subset include real-time dynamic programming (RTDP) POMDP context (Barto, Bradtke, & Singh, 1995;Geffner & Bonet, 1998), synthetic projection algorithm (Drummond & Bresina, 1990)envelope algorithm Plexus planner MDP context (Dean et al., 1993).Naturally, run anytime algorithms. RTDP, value updates carriedbelief subset, grows agent explores belief space. main differenceSPVI algorithms expand belief/state subsetchoose beliefs/states value updates. subset expansion, SPVI addsbelief simplices, often contains infinite number belief states,154fiRestricted Value Iteration: Theory Algorithmsalgorithms mostly add finite number belief states. (It also noted reachabilityanalysis used expansions.) value updates, SPVI improves valuesentire belief subset, algorithms typically select limited number beliefsstates current subset.7.2 Reducing Complexity Value FunctionsAnother idea behind restricted value iteration concerned representational complexity value functions. Intuitively, representing set value function beliefsubset contains fewer vectors value function belief space.fact observed (Boutilier & Poole, 1996; Hauskrecht & Fraser, 1998),POMDPs represented compactly. states depicted set variables,classified observable variables hidden variables. also notedbelief states cannot reached certain combinations observable variables hidden variables. fact exploited approximating solution medicaltreatment example (Hauskrecht & Fraser, 1998). Recent work along thread includesstate-space compression technique exploiting representational advantage (Poupart &Boutilier, 2002), technique Principle Component Analysis (PCA) aiming reducing complexity value functions (Roy & Gordon, 2002). However, unclear whetherfeasible combine state-space compression subset value iteration knowconduct value iteration belief space induced compressed state space.7.3 Solving Special POMDPsSince solving POMDP generally computationally intractable, advisable studyPOMDPs special characteristics. hope characteristics may exploited find near optimal solutions efficiently. Special POMDPs examinedliterature include regional-observable POMDPs (Zhang & Liu, 1997), memory-resettingdiscernible POMDPs (Hansen, 1998), even-odd POMDPs (Zubek & Dietterich, 2000)generalized near-discernible POMDPs (Zhang, 2001). Interestingly, POMDPsassume existence informative actions observations somehow agentable get information world. following, briefly discussassumptions behind informative POMDPs near-discernible POMDPs review existing work closely related them. concluding subsection, also mentionedcouple extensions current work.informative POMDP assumes observation restricts world smallset states. assumption validated problem instances compact representations state space. literature, POMDP examples actually informativePOMDPs. One example slotted Aloha protocol problem (Bertsekas & Gallagher, 1995;Cassandra, 1998a), state system consists number backlogged messages channel status. channel status observable possible assignmentsform observation space. However, system access number backloggedmessages. maximum number backlogged messages set n possible values channel status, number states n. particular assignmentchannel status restrict system states n. similar problem155fiZhang & Zhangcharacteristic also exists non-stationary environment model proposed reinforcementlearning (Choi, Yeung, & Zhang, 1999).regional observable POMDP assumes point time agent restrictedhandful world states (Zhang & Liu, 1997). assumption leads value iterationalgorithm works belief subset also exploits low dimensional representation vectors. used algorithm solve informative POMDPs. However, wouldlike discuss several differences. First, conceptually assumptions differenttwo POMDP classes. regional observable POMDPs, agent restricted setstates (i.e., region), states set geometrically neighboring ones. However, informative POMDPs, agent restricted set states, statesset obtained formally analyzing observation model POMDP. possiblestates set spatially distant one another. Second, algorithmstwo POMDP classes work quite different way. ease presentation, use infoVIroVI respectively denote value iteration informative POMDPsregional observation POMDPs. infoVI, number state sets productnumber actions number observations, roVI, number regionssubjectively chosen. addition, observations roVI augmented. augmentedobservation consists original observation specific region. So, number augmented observations product number original observations numberregions. Hence, roVI account many observations infoVI.fact useful comparing efficiency infoVI roVI. Imagine happensroVI works region system, consists state sets defined infoVI,informative POMDP. infoVI accounts fewer observations roVI,efficient. Finally, quality value function returned infoVIguaranteed entire belief space terminates strict stopping criterion.However, quality value function roVI original description problematiceven considered belief subset.POMDP class examined paper near-discernible POMDPs. neardiscernible POMDP assumes actions classified information-rich onesinformation-poor ones. assumption reasonable several realistic domains. firstdomain path planning problems (Cassandra, 1998a). actions categorizedgoal-achieving information-gathering ones, discussed earlier. Another applicationdomain machine maintenance problems (Smallwood & Sondik, 1973; Hansen, 1998),agent usually execute following set actions: manufacture, examine,inspect replace. Among actions, inspect information-rich remainingthree actions information-poor.near discernible POMDP generalization memory-resetting (discernible)POMDP, assumes exists actions resetting world unique state.actions performed, agent knows world must definite state.initial belief state known optimal policy must execute one actions periodically, number belief states agent visits finite. Accordingly, DP updatesfinite set beliefs much cheaper. However, discernibility assumptionrelaxed, agent may visit infinite number states DP updates becomeexpensive. therefore developed anytime algorithm seeking tradeoffsolution quality size belief subset.156fiRestricted Value Iteration: Theory Algorithmsalso experimented one extension using SPVI approximate solutionsgeneral POMDPs (Zhang, 2001). approximation scheme employs thresholdingtechnique. Given POMDP threshold, POMDP transformed new one,differs original one observation model. observation modeltransformed POMDP obtained ignoring probabilities (in original model) lessthreshold 7 . transformed POMDP near discernible, solutionfound SPVI used approximate original POMDP. designedanother maze problem informative action/observation pair thereforeexpected amenable SPVI (Zhang, 2001). However, transformed POMDPamenable SPVI. experiments show SPVI quickly find high quality solutiontransformed POMDP. another case, transformed POMDP informative,algorithm exploiting low dimensional representations informative POMDPsapplied.8. Conclusionspaper, studied value iterations working belief subset. applied reachabilityanalysis select particular subset. subset (1)closed actions leadagent belief states outside it; (2)sufficient value function definedextended belief space; (3)minimal value iteration needs considerleast subset intends achieve quality value functions. subsetclosed enables one formulate subset MDP. addressed issues representingsubset pruning set vectors w.r.t. subset. described subset valueiteration algorithm. given POMDP, whether subset proper determinedpriori. case, subset value iteration carries advantages representationspace efficiency time. also studied informative POMDPs near-discerniblePOMDPs. informative POMDPs, natural belief subsets value iterationwork with. near-discernible POMDPs, developed anytime value iterationalgorithm seeking tradeoff policy quality size belief subsets.AcknowledgmentsResearch partially supported Hong Kong Research Grants Council grantHKUST6088 / 01E. authors thank Tony Cassandra Eric Hansen sharing usprograms. first author would like thank Eric Hansen in-depth discussionsbelief subset selection low dimensional representation, Judy Goldsmith valuablecomments earlier writeup ideas paper. also grateful threeanonymous reviewers provided insightful comments suggestions paper.Appendix A. ProofsTheorem 2 pair [a, z], subset (B, a, z) simplex.7. complete definition approximate observation model, one needs re-normalize modelparameters action state, probabilities observations sum 1.0.157fiZhang & ZhangProof: Suppose bi belief state bi (s) = 1.0 = si 0 otherwise.seen {b1 , b2 , , bn } basis belief space B. belief state b(=P(b(s1 ), b(s2 ), , b(sn )) represented ni=1 b(si )bi .Let k cardinality set { (bi , a, z)|P (z|bi , a) > 0}. Without loss generality,enumerate set { (b1 , a, z), , (bk , a, z)}. suffices show (B, a, z) =( (b1 , a, z), (b2 , a, z), , (bk , a, z)). prove it, prove:(1) (B, a, z) ( (b1 , a, z), (b2 , a, z), , (bk , a, z))(2) ( (b1 , a, z), (b2 , a, z), , (bk , a, z)) (B, a, z).First, prove (1). suffices show belief state b0 (B, a, z) must belongsimplex . Since b0 (B, a, z), must exist belief state b Bb0 = (b, a, z). define constants follows.{1, , k}, Cbi probability observing z action executedPbelief state bi . Formally, Cbi = s0 ,s P (z|s0 , a)P (s0 |s, a)bi (s).Cb probability observing z action performed b. Formally, Cb =P00s0 ,s P (z|s , a)P (s |s, a)b(s).{1, , k}, define = Cbi /Cb .PGiven constants, going prove b0 = (bi , a, z). true, i.e., b0represented convex combination vectors basis, (1) proven.start b0 = (b, a, z). (b, a, z) replaced definition, state s0 ,b0 (s0 ) =1 XP (z|s0 , a)P (s0 |s, a)b(s)Cbdefinition belief state bi , rewrite equationb0 (s0 ) =1 X XP (z|s0 , a)P (s0 |s, a)bi (s).Cb i{1,,k}Trivially,Xb0 (s0 ) =1 XCbP (z|s0 , a)P (s0 |s, a)bi (s)CbiCbi.definition (bi , a, z), rewriting equation,b0 (s0 ) =X Cb(Cb) (bi , a, z)(s0 ).definition , equation yieldsb0 (s0 ) =X(bi , a, z)(s0 ).158fiRestricted Value Iteration: Theory Algorithmsb0 (bi , a, z) regarded column vectors, equation meansb0 =X(bi , a, z).Therefore, prove belief state b b0 = (b, a, z), b0represented convex combination vectors basis. means b0 mustsimplex .prove (2), prove belief state b0 simplex must subset(B, a, z). suffices show exists belief state b B b0 = (b, a, z).PSince b0 , must exist set nonnegative b0 = ki=1 (bi , a, z).replace (bi , a, z) definition, then: state s0 ,00b (s ) =denoteXPPP (z|s0 , a)P (s0 |s, a)bi (s)P.00s0 ,s P (z|s00s0 ,s P (z|s , a)P (s |s, a)bi (s)b0 (s0 ) =XX, a)P (s |s, a)bi (s)constant Cbi ,P (z|s0 , a)P (s0 |s, a)bi (s).CbiExchanging summation order making use definition bs (i),XP (z|s0 , a)P (s0 |s, a).b0 (s0 ) =Cbsdefine belief state b follows: s,/Cbs.b(s) = X/CbsseenPP (z|s0 , a)P (s0 |s, a)b(s).b (s ) = P0000s0 ,s P (z|s, a)P (s |s, a)b(s)Therefore, proved b0 exists belief state b b0 = (b, a, z).Consequently, b0 (B, a, z).2(B)(B)(B)Theorem 6 maxb (B) |Vn (b)Vn1 (b)| (1 )/(22 |Z|), Vn1 -improvingpolicy -optimal entire belief space B.Proof: suffices show maxbB |Vn+1 (b) Vn (b)| (1 )/(2). b B,=|Vn+1 (b) Vn (b)|PP(B,a,z)(B,a,z)| maxa {r(b, a)+ z Vn( (b, a, z))} maxa {r(b, a)+ z Vn1( (b, a, z))}|PP(B,a ,z)(B,a ,z)|r(b, ) + z Vn( (b, , z)) r(b, ) z Vn1( (b, , z))|P(B,a ,z)(B,a ,z)| z (Vn( (b, , z)) Vn1( (b, , z)))|(B,a ,z)(B,a ,z)|Z| maxz |Vn( (b, , z)) Vn1( (b, , z))||Z|(1 )/(22 |Z|)(1 )/(2)159(1)(2)(3)(4)(5)(6)fiZhang & ZhangStep (1), value functions replaced definitions;(B)Step (2), Vnimproving;(B)-improving action b necessarily Vn1 -Step (5), given condition used;steps trivial.2Appendix B. Informative POMDPs: Elevator Problemappendix describes 96-state informative POMDP empirical results valueiteration (B). problem adapted existing research (Choi et al., 1999).purpose show restricted value iteration able solve larger POMDPsstandard value iteration.Problem Formulationelevator operates two-floor residential building. three patternspassengers arrival: high arrival rate first floor low second floor; lowarrival rate first floor high second floor; equal arrival rates. time variesmorning night day, patterns change according probabilitydistribution. keep track pick-up drop-off requests, elevator sets fourbuttons control panel: two buttons record pick-up drop-off requestsfirst floor, two buttons keep information second floor. elevatoralso aware floor on. order fulfill requests floor, elevatorfirst moves upwards downwards reaches floor; then, elevator staysfloor passengers finish entering exiting. objective elevatorminimize certain penalty cost long run.problem formulated POMDP framework. state consists sixcomponents: arrival pattern, pick-up requests two floors, drop-off requeststwo floors elevators position. use six variables denote componentsrespectively. state assignment variables. arrival pattern takes threepossible values three different patterns. passengers waiting lobbyfirst floor, pick-up request set; otherwise, unset. passengerselevator intending get first floor, drop-off request first floor set;otherwise, unset. Similarly, second floor, variables pick-up/drop-offrequests set accordingly. elevator first floor, position set first;second floor, position set second. number states 322222 = 96.observation five components; components state exceptarrival pattern. many 2 2 2 2 2 = 32 observations. elevator mayexecute one three actions, namely go.up, go.down stay. restriction is,first floor, cannot perform go.down; second floor, actiongo.up cannot performed.160fiRestricted Value Iteration: Theory Algorithmsuncertainty stems probabilities changes arrival patterns.elevator executes go.up, component evolves follows. arrival patternchanges according predetermined probability distribution. components pickup/drop-off requests remain. position changes first second. effectsaction go.down described similarly. elevator performs action stay,arrival pattern changes similarly. requests floor fulfilledcorresponding variables reset. instance, passenger would like getfirst floor, elevator first floor performs stay, passenger able getoff. say elevator fulfills drop-off requests first floor. anotherinstance, passengers like enter elevator second floor,elevator performs action stay second floor. say pickup requestsecond floor fulfilled case. also allowable elevator fulfill tworequests one time point. example, pick-up drop-off requestsfirst floor, elevator performs action stay, passengers enter exitwithin one time point. say fulfills two requests. Note action stayperformed, elevator fulfill request. Since variable arrival pattern changestime moment, elevator changes states probabilistically performingaction.elevator informed partial knowledge state transition. elevatorperforms action, knows changes components states: variables pick-updrop-off floor position. However, since know arrivalpattern component state, observations cannot reveal identitiesstates. partial observability. However, since three possiblearrival patterns, observation reveals elevator must three possiblestates. Therefore, POMDP informative.performance elevator measured different ways diverse applications. define measure minimize unsatisfactory degree service elevatorprovides. encode reward model. time point, elevator servesone four requests: pick-up requests first/second floor, drop-off requestsfirst/second floor. performing action, 4 requests unfulfilled,elevator receives penalty 0.25. instance, elevator un-fulfills either pick-updrop-off request(if set) first floor, receives penalty 0.25 2 = 0.5.objective elevator minimize total discounted penalty long run.convenience, use A.i denote arrival patterns = 1, 2, 3. experiments,transition probabilities set following table. Basically, pattern remainsfixed probability 0.90 changes another 0.05.A.1A.2A.3A.10.900.050.05A.20.050.900.05161A.30.050.050.90fisizes representing sets(logscale)Zhang & ZhangCPU seconds(logscale)1e+06100000100001000VIssVIinfoVIinfoVIPB1001010.10510 15 20 25number iterations3035100000100001000100VIssVIinfoVIinfoVIPB1010510 15 20 25number iterations3035Figure 8: Performance VI, ssVI, infoVI infoVIPB ElevatorEmpirical Studiescollect time costs actual number vectors generated iterationalgorithms VI, ssVI, infoVI infoVIPB referring infoVI integrated pointbased procedure (Zhang, 2001). results presented Figure 8.first chart figure shows time costs iterations. algorithmsset compute 0.1-optimal value function. infoVIPB, exclude iterationspoint-based improvements. Overall, see VI ssVI means solveproblem, infoVI likely solve given sufficient time infoVIPB able solveeasily. infoVIPB runs, uses loose stopping criterion.strict one used, threshold close round-off precision parameter.first seven iterations, ssVI takes 190,000 seconds, infoVI 32 seconds.performance difference drastic. infoVI proceeds, takes 1,100 secondsone iteration. evident infoVI able compute near optimal value functiongiven sufficient time. point-based technique integrated, infoVIPB ableterminate 94 seconds five steps DP updates (B). Sincealgorithms cannot terminate within reasonable time limit, compare data6th iteration among them. last iteration able gather statistics VI.iteration, VI takes 76,000 seconds, ssVI 6,000 seconds, infoVIPB 8 seconds.second chart Figure 8 depicts number vectors generated iterationtested algorithms. ssVI, collect sum numbers vectors representingvalue functions |A| |Z| -simplices. infoVI infoVIPB, collect sumnumbers representing vectors |Z| -simplices. problemobservation models independent actions.chart, see VI generates significantly vectors ssVIinfoVI. experiments, infoVIPB terminates, produces 1,132 vectors.reason above, compare numbers vectors 6th iterationsalgorithms. iteration, VI generates 12,000 vectors. ssVI infoVI,number 252 136 respectively. DP updates proceed, conceivablenumber vectors generated VI increase sharply hence DP updatesextremely inefficient. infoVIPB, since final number generated vectors rather162fiRestricted Value Iteration: Theory Algorithmssmall, together fact point-based improvement effectively reduces numberiterations (B), possible compute near optimal value function withinrather small time limit turns out.ReferencesAstrom, K. J. (1965). Optimal control Markov decision processes incomplete stateestimation. Journal Mathematical Analysis Applications, 10, 403406.Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamicprogramming. Artificial Intelligence, 72, 81138.Bellman, R. (1957). Dynamic Programming. Princeton University Press.Bertsekas, D. P., & Gallagher, R. G. (1995). Data Networks. Prentice Hall.Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic searchbelief space. Proceedings 6th International Conference Artificial Intelligence Planning Systems (AIPS), pp. 5261. AAAI Press.Boutilier, C., Brafman, R. I., & Geib, C. (1998). Structured reachability analysis Markovdecision processes. Proceedings 14th Conference Uncertainty ArtificialIntelligence (UAI), pp. 2432.Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observabledecision processes using compact representations. Thirteenth National ConferenceArtificial Intelligence (AAAI), pp. 11681175. Portland, Oregon.Burago, D., de Rougemont, M., & Slissekno, A. (1996). complexity partiallyobserved Markov decision processes. Theoretical Computer Science, 157 (2), 161183.Cassandra, A. R. (1998a). Exact approximate algorithms partially observable Markovdecision processes. Ph.D. thesis, Department Computer science, Brown university.Cassandra, A. R. (1998b). survey POMDP applications. Working Notes AAAI1998 Fall Symposium Planning Partially Observable Markov Decision Processes, pp. 1724.Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple,fast, exact method partially observable Markov decision processes. Proceedings13th Conference Uncertainty Artificial Intelligence, pp. 5461.Choi, S. P. M., Yeung, D. Y., & Zhang, N. L. (1999). environment model nonstationary reinforcement learning. Advances Neural Information Processing Systems12, pp. 987993.Dean, T., Givan, R., & Kim, K. (1998). Solving planning problems large stateaction spaces. Proceedings 4th International Conference Artificial Intelligence Planning Systems (AIPS), pp. 102110. Pittsburgh, Pennsylvania.Dean, T. L., Kaelbling, L. P., Kirman, J., & Nicholson, A. (1993). Planning deadlinesstochastic domains. Proceedings 9th National Conference ArtificialIntelligence (AAAI), pp. 574579.163fiZhang & ZhangDean, T. L., & Lin, S. H. (1995). Decomposition techniques planning stochasticdomains. Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI), pp. 11211127.Drummond, M., & Bresina, J. (1990). Anytime synthetic projection: maximizing probability goal satisfaction. Proceedings National Conference Artificial Intelligence (AAAI), pp. 138144.Geffner, H., & Bonet, B. (1998). Solving large POMDPs using real time dynamic programming. Working Notes Fall AAAI Symposium POMDPs, pp. 6168.Hansen, E. A. (1998). Finite memory control partially observable systems. Ph.D. thesis,Dept Computer Science, University Massachusetts Amherst.Hansen, E. A., & Ziberstein, S. (1998). Heuristic search cyclic AND/OR graphs.Proceedings National Conference Artificial Intelligence (AAAI), pp. 412417.Hauskrecht, M. (1997). Incremental methods computing bounds partially observable Markov decision processes. Proceedings National Conference ArtificialIntelligence (AAAI), pp. 734739.Hauskrecht, M. (2000). Value-function approximations partially observable Markovdecision processes. Journal Artificial Intelligence Research, 13, 3394.Hauskrecht, M., & Fraser, H. (1998). Modeling treatment ischemic heart diseasepartially observable Markov decision processes. American Medical InformaticsAssociation annual symposium Computer Applications Health Care, pp. 538542. Orlando, Florida.Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning actingpartially observable stochastic domains. Artificial Intelligence, 101 (1-2).Koller, D., & Parr, R. (2000). Policy iteration factored MDPs. ProceedingsSixteenth Conference Uncertainty Artificial Intelligence (UAI), pp. 326334.Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Efficient dynamic programming updates partially observable Markov decision processes. Tech. rep. CS-95-19,Department Computer Science, Brown University.Littman, M. L., Goldsmith, J., & Mundhenk, M. (1998). computational complexityprobabilistic planning. Journal Artificial Intelligence Research, 9, 136.Lovejoy, W. S. (1991). Computationally feasible bounds partially observed Markovdecision processes. Operations Research, 39 (1), 162175.Madani., O., Hanks, S., & Condon, A. (1999). undecidability probabilistic planning infinite horizon partially observable Markov decision problems..Monahan, G. E. (1982). survey partially observable Markov decision processes: theory,models, algorithms. Management Science, 28 (1), 116.Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov decision processes. Mathematics Operations Research, 12 (3), 441450.Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decisionproblems. Proceedings 14th Conference Uncertainty Artificial Intelligence (UAI), pp. 422430.164fiRestricted Value Iteration: Theory AlgorithmsParr, R., & Russell, S. (1995). Approximating optimal policies partially observablestochastic domains. Proceedings 14th International Joint ConferenceArtificial Intelligence (IJCAI), pp. 10881094.Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration: anytime algorithm POMDPs. International Joint Conference Artificial Intelligence(IJCAI), pp. 10251032.Poupart, P., & Boutilier, C. (2002). Value-directed compresseion POMDPs. Proceedings Advances Neural Information Processing Systems (NIPS), pp. 15471554.Puterman, M. L. (1994). Markov decision processes: discrete stochastic dynamic programming. Wiley, New York, NY.Roy, N., & Gordon, G. (2002). Exponential family PCA belief compression POMDPs.Proceedings Advances Neural Information Processing Systems (NIPS), pp.16351642.Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observableMarkov processes finite horizon. Operations Research, 21, 10711088.Sondik, E. J. (1971). optimal control partially observable decision processes. Ph.D.thesis, Stanford University, Stanford, California, USA.Washington, R. (1997). BI-POMDP: Bounded, incremental partially-observable Markovmodel planning. Proceedings 4th European Conference Planning (ECP),pp. 440451.Zhang, N. L., & Liu, W. (1997). model approximation scheme planning partiallyobservable stochastic domains. Journal Artificial Intelligence Research, 7, 199230.Zhang, N. L., & Zhang, W. (2001a). Space-progressive value iteration: anytime algorithmclass POMDPs. Sixth European Conference Symbolic QuantitativeApproaches Reasoning Uncertainty (ECSQARU), pp. 7283.Zhang, N. L., & Zhang, W. (2001b). Speeding convergence value iterationpartially observable Markov decision processes. Journal Artificial Intelligence Research, 14, 2951.Zhang, W. (2001). Algorithms partially observable Markov decision processes. Ph.D.thesis, Department Computer Science, Hong Kong University ScienceTechnology.Zhang, W., & Zhang, N. L. (2001). Solving informative partially observable Markov decisionprocesses. Proceedings 6th European Conference Planning (ECP).Zhou, R., & Hansen, E. (2001). improved grid-based approximation algorithmPOMDPs. Proceedings 17th International Joint Conference ArtificialIntelligence, pp. 707716.Zubek, V. B., & Dietterich, T. G. (2000). POMDP approximation algorithm anticipates need observe. Proceedings PRICAI-2000, pp. 521532. LectureNotes Computer Science, New York: Springer-Verlag.165fiJournal Artificial Intelligence Research 23 (2005) 4178Submitted 07/04; published 01/05Research NoteExtremal Behaviour Multiagent Contract NegotiationPaul E. Dunneped@csc.liv.ac.ukDepartment Computer ScienceUniversity Liverpool, Liverpool, UKAbstractexamine properties model resource allocation several agents exchange resources order optimise individual holdings. schemes discussed relate well-known negotiation protocols proposed earlier work consider numberalternative notions rationality covering quantitative measures, e.g. cooperativeindividual rationality qualitative forms, e.g. Pigou-Dalton transfers.known imposing particular rationality structural restrictions may resultreallocations resource set becoming unrealisable, paper addressissue number restricted rational deals may required implement particular reallocation possible so. construct examples showingnumber may exponential (in number resources m), even agentutility functions monotonic. show k agents may achieve singledeal reallocation requiring exponentially many rational deals k 1 agentsparticipate, reallocation unrealisable sequences rational dealsk 2 agents involved.1. IntroductionMechanisms negotiating allocation resources within group agents form important body work within study multiagent systems. Typical abstract modelsderive game-theoretic perspectives economics among issuesaddressed strategies agents use obtain particular subset resources available, e.g. (Kraus, 2001; Rosenschein & Zlotkin, 1994; Sandholm, 1999), protocolsprocess settling upon allocation resources among agents involvedagreed, e.g. (Dignum & Greaves, 2000; Dunne, 2003; Dunne & McBurney, 2003; McBurneyet al., 2002).setting concerned encapsulated following definition.Definition 1 resource allocation setting defined triple hA, R, Ui= {A1 , A2 , . . . , };R = {r1 , r2 , . . . , rm }are, respectively, set (at least two) agents collection (non-shareable) resources.utility function, u, mapping subsets R rational values. agent Aiassociated particular utility function ui , U hu1 , u2 , . . . , un i.allocation P R partition hP1 , P2 , . . . , Pn R. value ui (Pi ) calledutility resources assigned Ai . utility function, u, monotone wheneverholds u(S ) u(T ), i.e. value assigned u set resources, ,never less value u attaches subset, .c2005AI Access Foundation. rights reserved.fiDunneTwo major applications abstract view Definition 1 exploitede-commerce distributed task realisation. first R represents collectioncommodities offered sale individual agents seek acquire subset these,value agent attaches specific set described agents utility function.task planning, resource set describes collection sub-tasks performedorder realise complex task, e.g. complex task may transport goodscentral warehouse set cities. example R describes locationsgoods must dispatched given allocation defines placesagent must arrange deliveries. utility functions cases model cost agentassociates carrying alloted sub-tasks.Within general context Definition 1, number issues arise stemmingobservation unlikely initial allocation seen satisfactoryeither respect views agents system respect divers globalconsiderations. Thus, proposing changes initial assignment individual agentsseek obtain better allocation. scenario raises two immediate questions:evaluate given partition thus basis forming improved optimal allocations;and, issue underlying main results paper, restrictions imposedform proposed deals may take.shall subsequently review widely studied approaches definingconditions allocations seen better others. purposesintroduction simply observe criteria may either quantitativequalitative nature. example former approach whereinvalue allocation P simply sum values given agents utilityPfunctions subsets R apportioned within P , i.e. ni=1 ui (Pi ):so-called utilitarian social welfare, avoid repetition denote u (P ).natural aim agents within commodity trading context seek allocationu maximised. One example qualitative criterion envy freeness: informally,allocation, P , envy-free agent assigns greater utility resource set (Pj ) heldanother agent respect resource set (Pi ) actuallyallocated, i.e. distinct pair hi , j i, ui (Pi ) ui (Pj ).general terms two approaches considered treatingquestion finite collection resources might distributed among set agentsorder optimise criterion interest: contract-net based methods, e.g. (Dunneet al., 2003; Endriss et al., 2003; Endriss & Maudet, 2004b; Sandholm, 1998, 1999) derivingwork Smith (1980); combinatorial auctions, e.g. (Parkes & Ungar, 2000a,2000b; Sandholm et al., 2001; Sandholm, 2002; Sandholm & Suri, 2003; Tennenholz, 2000;Yokoo et al., 2004, amongst others). significant difference extentcentralized controlling agent determines eventual distribution resourcesamong agents.One may view strategy underlying combinatorial auctions investing computational effort pre-processing stage following given allocation determined.Thus controlling agent (the auctioneer) supplied set bids pairs hSj , pjwherein Sj subset available resources pj price agent Aj preparedpay order acquire Sj . problem faced auctioneer decide bids42fiExtremal Behaviour Multiagent Contract Negotiationaccept order maximise overall profit subject constraint itemobtained one agent.shall refer contract-net schemes typically eschew precomputationstage subordination controlling arbiter employed auction mechanisms, seekinginstead realise suitable allocation agreed sequence deals. contract-net (ingeneral instantiation) scenarios resources distributed among n agentscomplete directed graph n vertices (each associated distinctallocation). way possible deal hP , Qi represented edge directedvertex labelled P labelled Q. Viewed thus, identifying sequence dealsinterpreted search process which, principle, individual agents may conductautonomous fashion.Centralized schemes effective contexts participants cooperate (insense accepting auctioneers arbritration). environments within agentshighly self-interested extent aims conflict auction processhigh degree uncertainty outcome, working towardsfinal allocation, agents involved may prepared proceed cautiously: is,agent accept proposed reallocation satisfied would resultimmediate improvement perspective. cases, process movinginitial allocation, Pinit , eventual reallocation Pfin sequence local rationaldeals, e.g. agent might refuse accept deals reduced u possibilitysuffers uncompensated loss utility. key issue following: dealprotocol allows moves stage agent Aj offers single resourceanother agent Aj rational reallocation hPinit , Pfin always implemented; if,however, every single move must rational hPinit , Pfin may realisable.may, informally, regard view agents myopic, senseunwilling accept short-term loss (a deal hP , Qi might incur lossutility) despite prospect long-term gain (assuming u (Pfin ) > u (Pinit ) holds).number reasons agent may adopt views, e.g. considerfollowing simple protocol agreeing reallocation.reallocation resources agreed sequence stages,involves communication two agents, Ai Aj . communicationconsists Ai issuing proposal Aj form (buy, r , p), offering purchaser Aj payment p; (sell , r , p), offering transfer r Aj returnpayment p. response Aj simply accept (followingdeal implemented) reject.This, course, simple negotiation structure, however consider operation withintwo agent setting one agent, A1 say, wishes bring allocation Pfin(and thus devise plan sequence deals realise initial allocationPinit ) agent, A2 , know Pfin . addition, assume A1agent makes proposals final allocation fixed either A1 satisfiedsoon A2 rejects offer.A2 could better Pfin realised, may case proposalsA2 accept lose, e.g. agents may scepticalbona fides others accept deals perceive43fiDunneimmediate benefit. several reasons agent may embrace attitudeswithin schema outlined: deal implemented A2 may lose utilityproposals made A1 loss permanent. note evenenrich basic protocol A1 describe Pfin , A2 may still reject offerssuffers loss, since unwilling rely subsequent deals would ameliorateloss actually proposed. Although position taken A2 settingdescribed may appear unduly cautious, would claim reflect real behaviourcertain contexts. Outside arena automated allocation negotiation multiagentsystems, many examples actions individuals promised long-term gainsinsufficient engender acceptance short term loss. Consider chain letterschemes (or subtle manifestation pyramid selling enterprises):natural lifetime bounded size population circulate, maybreak reached. Faced request send $10 five nameshead list forward letter ten others adding name despitepossibility significant gain temporary loss $50, ignore blandishmentsseen overly sceptical cautious: may reluctance accept oneeventually receive sufficient recompense return suspicion name ordermanipulated.summary, identify two important influences lead contextsagents prefer move towards reallocation via sequence rational deals. Firstly,agents self-interested operating unstable environment, e.g. chainletter setting, agent cannot reliably predict exact point chain fail.second factor computational restrictions may limit decisions individualagent make whether accept proposed deal. example settingsdeals involve one resource time, A2 may reject proposal acceptresource, r , since r useful following sequence deals: numberdeals small A2 could decide accept proposed deal sincesufficient computational power determine context r value;number large however, A2 may lack sufficient power scan searchspace future possibilities would allow accept r . Notice extremecase, A2 makes decision solely whether r immediate use, i.e. A2 myopic.powerful A2 may able consider whether r useful k dealstake place: case, A2 could still refuse accept r since, although use, A2 cannotdetermine bounded look ahead.total scenario described, A1 wishes bring allocation Pfinfaced view adopted A2 limitations imposed deal protocol,effective plan A1 could adopt find sequence rational dealspropose A2 .aim article show combining structural restrictions (e.g. oneresource time involved local reallocation) rationality restrictions resultsettings sequence realise reallocation hP , Qi must involve exponentiallymany (in |R|) separate stages. refine ideas next sub-section.44fiExtremal Behaviour Multiagent Contract Negotiation1.1 Preliminary Definitionsbegin, first formalise concepts deal contract path.Definition 2 Let hA, R, Ui resource allocation setting. deal pair hP , QiP = hP1 , . . . , Pn Q = hQ1 , . . . , Qn distinct partitions R. effect implementing deal hP , Qi allocation resources specified P replacedspecified Q. Following notation (Endriss & Maudet, 2004b) deal = hP , Qi,use indicate subset involved, i.e. Ak Pk 6= Qk .Let = hP , Qi deal. contract path realising sequence allocations= hP (1) , P (2) , . . . , P (t1) , P (t)P = P (1) P (t) = Q. length , denoted || 1, i.e. numberdeals .two methods use reduce number deals singleagent may consider seeking move allocation another, therebyavoiding need choose exponentially many alternatives: structural rationalityconstraints. Structural constraints limit permitted deals boundnumber resources and/or number agents involved, take considerationview agent may whether allocation improved. contrast, rationalityconstraints restrict deals hP , Qi Q improves upon P accordingparticular criteria. article consider two classes structural constraint: Ocontracts, defined considered (Sandholm, 1998), shall refer (k )contracts.Definition 3 Let = hP , Qi deal involving reallocation R among A.a. one contract (O-contract)O1. = {i , j }.O2. unique resource r Pi Pj Qi = Pi {r } Qj = Pj \ {r }(with r Pj ) Qj = Pj {r } Qi = Pi \ {r } (with r Pi )b. value k 2, deal = hP , Qi (k )-contract 2 |A | kiA Qi = iA Pi .Thus, O-contracts involve transfer exactly one resource particular agentanother, resulting number deals compatible given allocation exactly(n 1)m: resources reassigned current ownern 1 agents.Rationality constraints arise number different ways. example,standpoint individual agent Ai given deal hP , Qi may three different outcomes:ui (Pi ) < ui (Qi ), i.e. Ai values allocation Qi superior Pi ; ui (Pi ) = ui (Qi ), i.e.Ai indifferent Pi Qi ; ui (Pi ) > ui (Qi ), i.e. Ai worsedeal. global optima utilitarian social welfare maximised,question incentive agent accept deal hP , Qi45fiDunneleft less valuable resource holding. standard approach latter questionintroduce notion pay-off function, i.e. order Ai accept dealsuffers reduction utility, Ai receives payment sufficient compensateloss. course compensation must made agents systemproviding wish pay excess gain. defining notions pay-offinterpretation transaction agent Ai makes payment, : < 0Ai given return accepting deal; > 0 Ai contributesamount distributed among agents whose pay-off negative.notion sensible transfer captured concept individual rationality,often defined terms appropriate pay-off vector existing. difficult,however, show definitions equivalent following.Definition 4 deal hP , Qi individually rational (IR) u (Q) > u (P ).shall consider alternative bases rationality constraints later: primarilyinterest within so-called money free settings (so compensatory payment lossutility option).central issue interest paper concerns properties contract-netgraph allowed deals must satisfy structural rationality constraint.Thus, consider arbitrary predicates deals hP , Qi cases interestcombining structural rationality condition have,Definition 5 predicate distinct pairs allocations, contract pathhP (1) , P (2) , . . . , P (t1) , P (t)realising hP , Qi -path 1 < t, hP (i) , P (i+1) -deal,(P (i) , P (i+1) ) holds. say complete deal may realised -path.We, further, say complete respect -deals (where predicatedistinct pairs allocations) deal () holds may realised -path.main interest earlier studies ideas areas identifyingnecessary and/or sufficient conditions deals complete respect particularcriteria, e.g. (Sandholm, 1998); establishing convergence termination properties, e.g. Endriss et al. (2003), Endriss Maudet (2004b) consider deal types, ,every maximal1 -path ends Pareto optimal allocation, i.e. onereallocation agent improves utility lead another agent sufferingloss. Sandholm (1998) examines restrictions e.g. (P , Q) = >hP , Qi O-contract, may affect existence contract paths realise deals.particular interest, viewpoint heuristics exploring contract-net graph,cases (P , Q) = > deal hP , Qi individually rational.case O-contracts following known:Theorem 1a. O-contracts complete.1. Maximal sense hP (1) , . . . , P (t) path, every allocation, Q, (P (t) , Q)hold.46fiExtremal Behaviour Multiagent Contract Negotiationb. IR O-contracts complete respect IR deals.consideration algorithmic complexity issues presented (Dunne et al., 2003)one difficulty attempting formulate reallocation plans rational O-contractsalready apparent, is:Theorem 2 Even case n = 2 monotone utility functions problemdeciding IR O-contract path exists realise IR deal hP , Qi nphard.Thus deciding rational plan possible already computationally hard.article demonstrate that, even appropriate rational plan exists, extreme cases,may significant problems: number deals required could exponentialnumber resources, affecting time take schema outlinedconclude space agent dedicate storing it. Thus proofTheorem 1 (b), Sandholm observes IR O-contract path exists givenIR deal, may case length exceeds m, i.e. agent passes resourceanother accepts resource later stage.typical form results derive summarised as:structural constraint (O-contract (k )-contract) rationalityconstraint, e.g. (P , Q) holds hP , Qi individually rational, resource allocation settings hAn , Rm , Ui deal hP , Qi satisfyingfollowing.a. hP , Qi -deal.b. hP , Qi realised contract path every deal satisfiesstructural constraint rationality constraint .c. Every contract path length least g(m).example, show instances shortest IR O-contract pathlength exponential m.2 next section interested lower boundsvalues following functions: introduce general terms avoid unnecessarysubsequent repetition.Definition 6 Let hA, R, Ui resource allocation setting. Additionally lettwo predicates deals. deal = hP , Qi partial function Lopt (, hA, R, Ui, )length shortest -contract path realising hP , Qi path exists (andundefined path possible). partial function Lmax (hA, R, Ui, , )Lmax (hA, R, Ui, , ) =maxLopt (, hA, R, Ui, )-dealsFinally, partial function max (n, m, , )max (n, m, , ) =maxU=hu1 ,u2 ,...,unLmax (hAn , Rm , Ui, , )consideration restricted -deals = hP , Qi realising -pathexists.2. Sandholm (1998) gives upper bound length paths also exponential m,explicitly state lower bound already referred to.47fiDunnethree measures, Lopt , Lmax max distinguish different aspects regarding lengthcontract-paths. function Lopt concerned -paths realising single deal hP , Qigiven resource allocation setting hA, R, Ui: property interest numberdeals shortest, i.e. optimal length, -path. stress Lopt partial functionwhose value undefined event hP , Qi cannot realised -pathsetting hA, R, Ui. function Lmax defined terms Lopt , contextspecific resource allocation setting. behaviour interest Lmax , however,simply length -paths realising specific hP , Qi worst-case value Loptdeals -deals. note qualification Lmax defined -dealscapable realised -paths, thus consider casesappropriate contract path exists. Thus, case -deal settinghA, R, Ui realised -path value Lmax (hA, R, Ui, , ) undefined, i.e.Lmax also partial function. may interpret upper bound Lmax followingterms: Lmax (hA, R, Ui, , ) K -deal -path existsrealised -path length K .main interest centre max concerned behaviour Lmaxfunction n ranges n-tuples utility functions hu : 2R Qin .approach obtaining lower bounds function constructive, i.e. h,considered, show utility functions U may defined settingresources yield lower bound max (n, m, , ). contrast measures LoptLmax , function max described terms single fixed resource allocationsetting. is, however, still partial function: depending hn, m, , may caseevery n agent, resource allocation setting, regardless choice utilityfunctions made, -deal, hP , Qi capable realised -path,cases value max (n, m, , ) undefined.3noted, point, definition max allows arbitrary utility functionsemployed constructing worst-case instances. reasonable termsgeneral lower bound results, apparent given constructions utilityfunctions actually employed highly artificial (and unlikely feature real applicationsettings). shall attempt address objection considering boundsfollowing variant max :maxmono (n, m, , ) =U=hu1 ,u2 ,...,unmaxLmax (hAn , Rm , Ui, , ): ui monotoneThus, maxmono deals resource allocation settings within utility functionsmust satisfy monotonicity constraint.main results article presented next sections. consider twogeneral classes contract path: O-contract paths various rationality conditions3. recognising possibility max (n, m, , ) could undefined, claimingbehaviour arises instantiations h, considered subsequently: factmaxclear constructions that, denoting max(n, m, , ) fixed, (n, m) functioninstantiation h, i, restricted deal types rationality conditions examined, functionmax, (n, m) total function. Whether possible formulate sensible choices h,max, (n, m) undefined values hn, mi (and, so, demonstrating examples such) is,primarily, question combinatorial interest, whose development central concernscurrent article.48fiExtremal Behaviour Multiagent Contract NegotiationSection 2; and, similarly, (k )-contract paths arbitrary values k 2 Section 3.results concerned construction resource allocation settings hA, Rm , Uigiven rationality requirement, e.g. deals individually rational,deal hP , Qi satisfies rationality condition, realised rationalO-contract path (respectively, (k )-contract path), number deals requiredpaths exponential m. additionally obtain slightly weaker (but stillexponential) lower bounds rational O-contract paths within settings monotone utilityfunctions, i.e. measure maxmono , outlining similar results may derived(k )-contract paths.resource allocation settings constructed demonstrating properties(k )-contract paths, constructed deal hP , Qi realisable single (k + 1)contract unrealisable rational (k 1)-contract path. discuss related work,particular recent study (Endriss & Maudet, 2004a) addresses similar issuesconsidered present article, Section 4. Conclusions directionswork presented final section.2. Lower Bounds Path Length O-contractssection consider issue contract path length structural restrictionrequires individual deals O-contracts. first give overview constructionmethod, following subsections analysing cases unrestricted utility functionsand, subsequently, monotone utility functions.2.1 Overviewstrategy employed proving results involves two parts: given class restricted contract paths proceed follows obtaining lower bounds max (n, m, , ).a. contract-net graph partitioning resources among n agents, constructpath, = hP (1) , P (2) , . . . , P (t) realising deal hP (1) , P (t) i. structuralconstraint, 0 influencing proved that:a1. contract path 0 -path, i.e. 1 < t, deal hP (i) , P (i+1satisfies structural constraint 0 .a2. pair allocations P (i) P (i+j ) occurring , j 2deal hP (i) , P (i+j ) 0 -deal.Thus (a1) ensures suitable contract path, (a2) guaranteeexactly one allocation, P (i+1) , reached within givenallocation P (i) means 0 -deal.b. Define utility functions Un = hu1 , . . . , un following propertiesb1. deal hP (1) , P (t) -deal.b2. rationality constraint, 00 influencing , every deal hP (i) , P (i+1)00 -deal.49fiDunneb3. every allocation P (i) contract path every allocation QP (i+1) deal hP (i) , Qi -deal, i.e. violates either stucturalconstraint 0 rationality constraint 00 .Thus, (a1) (b2) ensure hP (1) , P (t) defined value respectfunction Lopt -deal hP (1) , P (t) i, i.e. -path realising deal possible.properties given (a2) (b3) indicate (within constructed resourceallocation setting) path unique -path realising hP (1) , P (t) i. follows1, length path, gives lower bound value Lmax hencelower bound max (n, m, , ).continuing useful fix notational details.use Hm denote m-dimensional hypercube. Interpreted directed graph, Hm2m vertices identified distinct m-bit label. Using = a1 a2 . . .denote arbitrary label, edges Hm formed{ h, : differ exactly one bit position}identify m-bit labels = a1 a2 . . . subsets Rm , via riai = 1. Similarly, subset R described binary word, (S ), length m,i.e. (S ) = b1 b2 . . . bm bi = 1 ri . label use || denotenumber bits value 1, || size subset . m-bitlabels, 2m-bit label, Rm Tm disjoint sets, describesunion subset Rm subset Tm . Finally = a1 a2 . . .m-bit label denotes label formed changing 0 values 1vice versa. way, subset Rm described describes setRm \ . avoid excess superscripts will, ambiguity arises, usedenote m-bit label subset Rm described it, e.g. write rather.n = 2 contract-net graph induced O-contracts viewed mdimensional hypercube Hm : m-bit label, associated vertex Hm describingallocation h, hA1 , A2 i. way set IR O-contracts define subgraph,Gm Hm directed path (P ) (Q) Gm corresponding possible IRO-contract path allocation hP , R \ P allocation hQ, R \ Qi.2.2 O-contract Paths Unrestricted Utility Functionsfirst result clarifies one issue presentation (Sandholm, 1998, Proposition 2):upper bound exponential proved length IR O-contractpaths, i.e. terms notation, (Sandholm, 1998, Proposition 2) establishes upperbound max (n, m, , ). prove similar order lower bound.Theorem 3 Let (P , Q) predicate holds whenever hP , Qi IR O-contract(P , Q) holds whenever hP , Qi IR. 7max (2, m, , )50772562m 2fiExtremal Behaviour Multiagent Contract NegotiationProof. Consider path C = h1 , 2 , . . . , Hm , following property41 < j (j + 2) (i j differ least 2 positions)(SC)e.g. = 4, {r1 }, {r1 , r3 }, {r1 , r2 , r3 }, {r2 , r3 }, {r2 , r3 , r4 }, {r2 , r4 }, {r1 , r2 , r4 }path corresponds sequence h0000, 1000, 1010, 1110, 0110, 0111, 0101, 1101i.Choose C (m) longest path property could formed Hm ,letting = hP (1) , P (2) , . . . , P (t) sequence allocations P (i) = hi , i.define utility functions u1 u2 Rm ,(u1 () + u2 () =k0= k6 {1 , 2 , . . . , }choice, contract path describes unique IR O-contract path realisingIR deal hP (1) , P (t) i: IR O-contract path immediate, sinceu (P (i+1) ) = + 1 > = u (P (i) )unique follows fact 1 + 2 j t, dealhP (i) , P (j ) O-contract (hence short-cuts possible),P (i) exactly one IR O-contract follow it, i.e. P (i+1) .5preceding argument follows lower bound length C (m) ,i.e. sequence satisfying condition (SC), lower bound max (2, m, , ).paths Hm originally studied Kautz (1958) context coding theorylower bound length (77/256)2m 2 established (Abbott & Katchalski,1991).2Example 1 Using pathC (4)==h0000, 1000, 1010, 1110, 0110, 0111, 0101, 1101ih1 , 2 , 3 , 4 , 5 , 6 , 7 , 8resource allocation setting h{a1 , a2 }, {r1 , r2 , r3 , r4 }, hu1 , u2 ii, utility functionsspecified Table 1 u (h1 , 1 i) = 1 u (h8 , 8 i) = 8. Furthermore,C (4) describes unique IR O-contract path realising reallocation hh1 , 1 i, h8 , 8 iinumber alternative formulations rationality also considered.exampleDefinition 7 Let = hP , Qi deal.4. defines so-called snake-in-the-box codes introduced (Kautz, 1958).5. example = 4, sequence h0000, 1000, 1001, 1101i, although defining O-contract pathgives rise deal IR, namely corresponding h1000, 1001i.51fiDunne00000001001000110100010101100111R\S11111110110111001011101010011000u1 (S )10000433u2 (R \ )00000323u10000756175610001001101010111100110111101111R\S01110110010101000011001000010000u1 (S )10200420u2 (R \ )10100420u203008402384Table 1: Utility function definitions = 4 example.a. cooperatively rational every agent, Ai , ui (Qi ) ui (Pi ) leastone agent, Aj , uj (Qj ) > uj (Pj ).b. equitable miniA ui (Qi ) > miniA ui (Pi ).c. Pigou-Dalton deal = {i , j }, ui (Pi ) + uj (Pj ) = ui (Qi ) + uj (Qj )|ui (Qi ) uj (Qj )| < |ui (Pi ) uj (Pj )| (where | . . . | absolute value).number views take concerning rationality conditions given Definition 7. One shared feature that, unlike concept individual rationalityprovision compensate agents suffer loss utility needed, i.e. individualrationality presumes money-based system, forms defined Definition 7 allow concepts rationality given money-free enviroments. Thus, cooperativelyrational deal, agent involved suffers loss utility least one better off. maynoted given characterisation Definition 4 immediate cooperatively rational deal perforce also individually rational; converse, however, clearlyhold general. settings, equitable deal may neither cooperativelyindividually rational. One may interpret deals one method reducing inequalityvalues agents place allocations: involved equitable deal,ensured agent places least value current allocation obtainresource set valued highly. may, course, case agentssuffer loss utility: condition deal equitable limits great losscould be. Finally concept Pigou-Dalton deal originates studieddepth within theory exchange economies. one many approachesproposed, order describe deals reduce inequality membersagent society, e.g. (Endriss & Maudet, 2004b). terms definition given,deals encapsulate so-called Pigou-Dalton principle economic theory:transfer income wealthy individual poorer one reduce disparitythem. note that, principle, could define related rationality conceptsbased several extensions principle suggested, e.g. (Atkinson, 1970;Chateauneaf et al., 2002; Kolm, 1976).Using O-contract path constructed Theorem 3, need varydefinitions utility functions employed order obtain,Corollary 1 cases below,52fiExtremal Behaviour Multiagent Contract Negotiationa. () holds cooperatively rational O-contract.() holds cooperatively rational.b. () holds equitable O-contract.() holds equitable.c. () holds Pigou-Dalton O-contract.() holds Pigou-Dalton deal.max(2, m, , )772m 2256Proof. employ exactly sequence allocations described proofTheorem 3 modify utility functions hu1 , u2 case.a. Choose hu1 , u2 u2 () = 0 R(u1 () =k0= k6 {1 , . . . , }resulting O-contract path cooperatively rational: utility enjoyed A2 remains constant enjoyed A1 increases 1 deal. deviationcontract path (employing alternative O-contract) result lossutility A1 .b. Choose hu1 , u2 u2 () = u1 ()(u1 () =k0= k6 {1 , . . . , }O-contract path equitable: A1 A2 increase respective utilityvalues 1 deal. Again, O-contract deviating resultagents losing utility.c. Choose hu1 , u2(u1 () =k0= k6 {1 , . . . , }(;u2 () =2m k2m= k6 {1 , . . . , }see O-contract path consists Pigou-Dalton deals, suffices noteu1 (i ) + u2 (i ) = 2m 1 t. addition, |u2 (i+1 ) u1 (i+1 )| = 2m 2i 2strictly less |u2 (i ) u1 (i )| = 2m 2i . Finally, O-contract hP , Qideviates sequence Pigou-Dalton deal since|u2 (Q2 ) u1 (Q1 )| = 2m > |u2 (P2 ) u1 (P1 )|violates one conditions required Pigou-Dalton deals.construction two agent settings, easily extends larger numbers.532fiDunneCorollary 2 choices h, considered Theorem 3 Corollary 1,n 2,77max(n, m, , )2m 2256Proof. Fix allocations A1 given 1 , A2 allocated 1 , Aj assigned3 j n. Using identical utility functions hu1 , u2 previous cases,employ uj : uj () = 1, uj (S ) = 0 whenever 6= (h, Theorem 3); uj (S ) = 0(Corollary 1(a)); uj () = 2m , uj (S ) = 0 whenever 6= (Corollary 1(b)); and, finally,uj (S ) = 2m , (Corollary 1(c)). Considering realisation -deal hP (1) , P (t)-contract path admissible path defined related proofs. giveslower bound stated.2note, point, consequences Corollary 1 respect (Endriss &Maudet, 2004b, Theorems 1, 3), stateFact 1 recall -path, hP (1) , . . . , P (t) maximal allocation Q, hP (t) , Qi-deal.a. hP (1) , . . . , P (t) maximal path cooperatively rational deals P (t)Pareto optimal.b. hP (1) , . . . , P (t) maximal path equitable deals P (t) maximisesvalue e (P ) = min1in ui (Pi ), i.e. so-called egalitarian social welfare.sequence cooperatively rational deals Corollary 1(a) terminates Paretooptimal allocation P (t) : allocation A2 always utility 0 allocationA1 whose utility exceed t. Similarly, sequence equitable deals Corollary 1(b)terminates allocation P (t) , e (P (t) ) = maximum attainedinstance defined. cases, however, optima reached sequencesexponentially many (in m) deals: thus, although Fact 1 guarantees convergence particulardeal sequences optimal states may case, illustrated Corollary 1(ab),process convergence takes considerable time.2.3 O-contract Paths Monotone Utility Functionsconclude results concerning O-contracts presenting lower bound maxmono , i.e.length paths utility functions required monotone.principle one could attempt construct appropriate monotone utility functionswould desired properties respect path used Theorem 3. is, however,far clear whether construction possible. attempt resolvequestion here. Whether exact translation could accomplished is, ultimately, questionpurely combinatorial interest: since aim demonstrate exponential lengthcontract paths needed monotone utility functions not, primarily, concernedobtaining optimal bound.54fiExtremal Behaviour Multiagent Contract NegotiationTheorem 4 (P , Q) (P , Q) defined Theorem 3 14maxmono (2, m, , )77m/2 3128 2evenodd771282(m1)/2 3Proof. describe details case even: resultodd obtained simple modification shall merely provide outline.Let = 2s 7. path= h1 , 2 , . . . ,Hs (where describes subset Rs s-bit label), path double(s ) H2sdefineddouble(s )==h 1 1 , 2 2 , . . . , , i+1 i+1 , . . . ,h1 , 3 , . . . , 2i1 , 2i+1 , . . . , 2t1(The reason successive indices increasing 2 become clear subsequently)course, double(s ) describe O-contract path6 : is, however, difficultinterpolate appropriate allocations, 2i , order convert path. Considersubsets 2i (with 1 < t) defined follows:(2i =i+1i+1i+1i+1consider path, ext(s ), within H2s givenext(s ) = h1 , 2 , 3 , . . . , 2(t1) , 2t1satisfies,a. property (SC) Theorem 3 Hs ext(s ) property (SC) H2s .b. j odd |j | = s.c. j even |j | = + 1.(a) bounds proved (Abbott & Katchalski, 1991) deduce ext(s )chosen P (i) denoting allocation hi ,d. ext(s ) describes O-contract path P (1) P (2t1) .e. pair hi , j j + 2, deal hP (i) , P (j ) O-contract.f. chosen proof Theorem 3 number deals ext(s )given statement present theorem.6. terms classification described Sandholm (1998), contains swap deals (S -contracts):deal swaps exactly one item 2i1 item 2i1 order give 2i+1 .55fiDunnetherefore fix path Theorem 3 order complete proofneed construct utility functions hu1 , u2 monotone ext(s )defines unique IR O-contract path realising reallocation hP (1) , P (2t1) i.choice u2 relatively simple. Given R2s ,u2 (S ) =02t + 12t + 2|S | 2|S | = 1|S |number allocations . behaviour u2 clearly monotone.construction u1 rather complicated. main idea make usefact size set occurring ext(s ) tightly constrained: |i |either + 1 according whether odd even. first demonstrateset size + 1 two strict subsets (of size s) occurring within ext(s ):thus, every size + 1 exactly 2 1 0 subsets size ext(s ). seesuppose contrary. Let , 2i1 , 2j 1 , 2k 1 || = + 12i1 ; 2j 1 ; 2k 1Noting 2i1 = property (SC) must case (atleast) two s-bit labels {i , j , k } differ least two positions. Without lossgenerality suppose true k . result deduce sets 2i12k 1 2 elements common, i.e. |2i1 2k 1 | 2: 2i1 =2k 1 = k k position differs k , differs kexactly position. total |2i1 \ 2k 1 | 2, i.e. (at least) two elements2i1 occur 2k 1 ; way |2k 1 \ 2i1 | 2, i.e.(at least) two elements 2k 1 occur 2i1 . set , however,+ 1 members cannot 2i1 2k 1 subsets: would require2i1 2k 1 2i1 \ 2k 1 2k 1 \ 2i1but, seen,| 2i1 2k 1 2i1 \ 2k 1 2k 1 \ 2i1 | + 2One immediate consequence argument given set size +1exactly two strict subsets occurring ext(s ) = 2i1 2i+1 = 2ivalue 1 < t. characterise subset R2s size + 1falling one three categories.C1. Good sets, given { : = 2i }.C2. Digressions, consisting{ : 2i1 , 6= 2i < t}C3. Inaccessible sets, consisting{ : neither Good Digression}56fiExtremal Behaviour Multiagent Contract NegotiationGood sets describing allocations A1 within path defined ext(s );Digressions allocations could reached using O-contract setsize ext(s ), i.e. 2i1 , differ set actually occurs ext(s ), i.e.2i . Finally, Inaccessible sets occur ext(s ) cannot reachedvia O-contract set ext(s ). note view set size + 1could reached O-contract 2t1 inaccessible: principlepossible extend O-contract path beyond 2t1 , however, choose complicateconstruction way.define u1u1 () =2i 12i + 12i002t 1= 2i1= 2i|| = + 1 Digression 2i1|| 1|| = 6 ext(s )Inaccessible || + 2remains prove choices hu1 , u2 O-contract path hP (1) , . . . , P (2t1)defined ext(s ) unique IR O-contract path realising IR deal hP (1) , P (2t1)u1 monotone.show hP (1) , . . . , P (2t1) IR need demonstrate1 j < 2t 1 u1 (j ) + u2 (j ) < u1 (j +1 ) + u2 (j +1 )via definition hu1 , u2u1 (2i1 ) + u2 (2i1 )=<=<=2(t + ) + 1u1 (2i ) + u2 (2i )2(t + ) + 2u1 (2i+1 ) + u2 (2i+1 )2(t + ) + 3Thus, via Definition 4, follows ext(s ) gives rise IR O-contract path.see path unique IR O-contract path implementing hP (1) , P (2t1) i,consider position P (j ) = hj , j allocation Q P (j +1) P (j 1) . mayassumed deal hP (j ) , Qi O-contract. j = 2i 1 u (P (2i1) ) = 2(t +i )+1|j | = s. Hence |Q1 | {s 1, +1}. former case, u1 (Q1 ) = 0 u2 (Q2 ) = 2t +2u (Q) = 2t + 2 thus hP (j ) , Qi IR. latter case u1 (Q1 ) = 2isince Q1 Digression 2i1 u2 (Q2 ) = 2t + 1 giving u (Q) = 2(t + ) + 1.hP (j ) , Qi fails IR since Q fails give increase value u . leftcase j = 2i u (P (2i) ) = 2(t + ) + 2 |j | = + 1. Since hP (j ) , Qi assumedO-contract gives |Q1 | {s, + 2}. first possibility Q1 couldset ext(s ): 2i1 2i+1 subsets 2i twosubsets occurring ext(s ). follows, therefore, u1 (Q1 ) = 0 giving u (Q) = 2t + 2hP (j ) , Qi IR. second possibility, u1 (Q1 ) = 2t 1 u2 (Q2 ) = 0|Q2 | = 2 deal would result overall loss. deduce P (j )IR O-contract consistent deal hP (j ) , P (j +1) i.57fiDunnefinal stage prove utility function u1 indeed monotone function.Suppose subsets R2s . need show u1 (S ) u1 (T ).may assume |S | = s, occurs set within ext(s ), |T | = + 1.|S | < |S | = occur ext(s ) u1 (S ) = 0 requiredinequality holds; |S | + 1 order possible would need|T | + 2, would give u1 (T ) = 2t 1 maximum valuesubset assigned u1 . left |S | = s, |T | = + 1 ext(s )consider. already shown two subsets occurext(s ). Consider different possibilities:a. = 2i exactly two subsets occur ext(s ): 2i1 2i+1 . Sinceu1 (2i ) = 2i + 1 least max{u1 (2i1 ), u1 (2i+1 )}, either2i1 2i+1 u1 (S ) u1 (T ) required.b. Digression = 2i1 , u1 (T ) = 2i u1 (S ) = 2i 1 and, again,u1 (S ) u1 (T ).deduce u1 monotone completing lower bound proof maxmono even valuesm.conclude observing similar construction used = 2s + 1 odd:use path ext(s ) described modifying one resource (rm ) alwaysheld A2 . minor modifications utility function definitions needed.2Example 2 = 3, choose 3 = h000, 001, 101, 111, 110i = 5.gives double(3 )h000111, 001110, 101010, 111000, 110001iO-contract path defined ext(3 )=h000111, 001111, 001110, 101110, 101010, 111010, 111000, 111001, 110001ih1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9Considering 15 subsets size + 1 = 4, givesGoodDigressionInaccessible==={001111, 101110, 111010, 111001}{010111, 100111, 101011, 011110, 111100}{011011, 011101, 101101, 110110, 110011, 110101}Notice sets {110011, 110101} Inaccessible: principle couldcontinue 9 = 110001 using either, however, order simplify constructionpath halted 9 .Following construction presented Theorem 4, gives following utility functiondefinitions R = {r1 , r2 , r3 , r4 , r5 , r6 }.u2 (S ) =0111258|S | 1|S | = 2|S | 3fiExtremal Behaviour Multiagent Contract Negotiationu1 obtainu1 (S ) =00122334556778999|S | 2|S | = 3 6 {000111, 001110, 101010, 111000, 110001}= 000111 (1 )= 010111 (digression 1 )= 100111 (digression 1 )= 001111 (2 )= 001110 (3 )= 011110 (digression 3 )= 101110 (4 )= 101010 (5 )= 101011 (digression 5 )= 111010 (6 )= 111000 (7 )= 111100 (digression 7 )= 111001 (8 )= 110001 (9 )|S | 5 {011011, 011101, 101101, 110110, 110011, 110101}monotone utility functions, hu1 , u2 i, employed proving Theorem 4 definedpath arising ext(s ) IR: event either agent suffering loss utilitygain made sufficient provide compensatory payment. natural questionarises whether bound obtained Theorem 4 shown applyrationality conditions preclude monetary payment, e.g. cases conceptrationality one given Definition 7. next result shows setrationality condition enforce cooperatively rational equitable deals boundTheorem 4 still holds.Theorem 5 cases 14a. () holds cooperatively rational O-contract.() holds cooperatively rational.b. () holds equitable O-contract.() holds equitable.maxmono (2, m, , )77m/2 3128 2evenodd771282(m1)/2 3Proof. illustrate constructions case even, notingmodification deal odd values outlined end proof Theorem 4.path ext(s ) used cases.59fiDunne(a), require hu1 , u2 defined monotone functions ext(s )unique cooperatively rational O-contract path realise cooperatively rationaldeal hP (1) , P (2t1) P (j ) = hj , j i. case set hu1 , u2 be,hu1 (), u2 ()i =hi ,hi+ 1,hi , 1ih0, 2t 1ih0, 2t 1ih2t 1, 0i= 2i1= 2i|| = + 1 Digression 2i1|| 1|| = 6 ext(s )Inaccessible || + 2Since,hu1 (2i1 ), u2 (2i1 )ihu1 (2i ), u2 (2i )ihu1 (2i+1 ), u2 (2i+1 )i===hi ,hi + 1,hi + 1, + 1icertainly case hP (1) , P (2t1) deals O-contract path definedext(s ) cooperatively rational. Furthermore Q = h, allocationP (j +1) deal hP (j ) , Qi fail cooperatively rational O-contract.suppose contrary letting hP (j ) , Qi without loss generality O-contract,Q 6 {P (j 1) , P (j +1) } rule former case since already showndeal cooperatively rational. j = 2i 1 hu1 (j ), u2 (j )i = hi ,|| {s 1, + 1}: former case leads loss utility A1 ; latter,(since Digression 2i1 ) loss utility A2 . Similarly, j = 2ihu1 (j ), u2 (j )i = hi + 1, || {s, + 2}: first 6 ext(s ) leading lossutility A1 ; second results loss utility A2 . follows path definedext(s ) unique cooperatively rational O-contract path realises hP (1) , P (2t1) i.remains show choices hu1 , u2 define monotone utility functions.Consider u1 suppose subsets R2s . |S | 1,occur ext(s ) u1 (S ) = 0. |T | + 2 Inaccessibleu1 (T ) = 2t 1 maximum value attainable u1 . may assume|S | = s, occurs ext(s ), i.e. = 2i1 , , |T | = + 1 eitherGood set Digression. definition u1 , u1 (S ) = : {2i , 2i2 }u1 (T ) = u1 (S ); Digression 2i1 u1 (T ) = = u1 (S ). deduceu1 (S ) u1 (T ), i.e. utility function monotone.consider u2 subsets R2s . |T | + 1R2s \ occur ext(s ) u2 (T ) = 2t 1 maximal value. |S | 2R2s \ Inaccessible u2 (S ) = 0. Thus may assume = 2i1 givingu2 (T ) = |S | = 1, R2s \ either Digression one Good sets{2i , 2i2 }. R2s \ Digression u2 (S ) = 1; Good set 2i2u2 (S ) = 1 < u2 (T ); Good set 2i u2 (S ) = = u2 (T ). followsu2 monotone completing proof part (a).60fiExtremal Behaviour Multiagent Contract Negotiation(b) use,hu1 (), u2 ()i =h2i 1, 2ih2i + 1, 2ih2i , 2i 1ih0, 2t 1ih0, 2t 1ih2t 1, 0i= 2i1= 2i|| = + 1 Digression 2i1|| 1|| = 6 ext(s )Inaccessible || + 2choices give ext(s ) unique equitable O-contract path realise equitabledeal hP (1) , P (2t1) i, sincemin{u1 (2i1 ), u2 (2i1 )}min{u1 (2i ), u2 (2i )}min{u1 (2i+1 ), u2 (2i+1 )}===2i 12i2i + 1deal hP (j ) , P (j +1) equitable. Q = h, allocation P (j +1)deal hP (j ) , Qi equitable O-contract. Assume hP (j ) , Qi Ocontract, Q 6 {P (j 1) , P (j +1) }. j = 2i 1, P (j ) = h2i1 , 2i1min{u1 (2i1 ), u2 (2i1 )} = 2i 1 || {s 1, + 1}. firstmin{u1 (), u2 ()} = 0; second min{u1 (), u2 ()} = 2i 1 since mustDigression. leaves j = 2i P (j ) = h2i , 2i min{u1 (2i ), u2 (2i )} = 2i .this, || {s, + 2}: || = min{u1 (), u2 ()} 2i 1 (with equality= 2i1 ); || = + 2 min{u1 (), u2 ()} = 0. total establish ext(s )unique equitable O-contract path realising equitable deal hP (1) , P (2t1) i.choices hu1 , u2 describe monotone utility functions shownsimilar argument part (a).2Example 3 = 3 using O-contract path ext(3 ) previous example,i.e.=h000111, 001111, 001110, 101110, 101010, 111010, 111000, 111001, 110001ih1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9hu1 , u2 (a) obtainhu1 (S ), u2 (R \ )i =h0, 9ih0, 9ih1, 1ih1, 0ih1, 0ih2, 1ih2, 2ih2, 1ih3, 2ih3, 3ih3, 2ih4, 3ih4, 4ih4, 3ih5, 4ih5, 5ih9, 0i|S | 2|S | = 3 6 {000111, 001110, 101010, 111000, 110001}= 000111 (1 )= 010111 digression 1= 100111 digression 1= 001111 (2 )= 001110 (3 )= 011110 digression 3= 101110 (4 )= 101010 (5 )= 101011 digression 5= 111010 (6 )= 111000 (7 )= 111100 digression 7= 111001 (8 )= 110001 (9 )|S | 5 {011011, 011101, 101101, 110110, 110011, 110101}61fiDunneSimilarly, (b)hu1 (S ), u2 (R \ )i =h0, 9ih0, 9ih1, 2ih2, 1ih2, 1ih3, 2ih3, 4ih4, 3ih5, 4ih5, 6ih6, 5ih7, 6ih7, 8ih8, 7ih9, 8ih9, 10ih9, 0i|S | 2|S | = 3 6 {000111, 001110, 101010, 111000, 110001}= 000111 (1 )= 010111 digression 1= 100111 digression 1= 001111 (2 )= 001110 (3 )= 011110 digression 3= 101110 (4 )= 101010 (5 )= 101011 digression 5= 111010 (6 )= 111000 (7 )= 111100 digression 7= 111001 (8 )= 110001 (9 )|S | 5 {011011, 011101, 101101, 110110, 110011, 110101}demonstrate similar extremal behaviours contract path lengthrationality constraints money-based (individual rationality) money-free (cooperative rationality, equitable) settings irrespective whether monotonicity propertiesassumed, interesting parallels contexts monotonicity relevant. particular observe common complexity results alreadynoted (Dunne et al., 2003) deciding allocation Pareto optimal, allocation maximises u , IR O-contract path exists requiring utility functionsmonotone result setting computationally tractable.3. (k )-contract pathsturn similar issues respect (k )-contracts, recalling one respectoffer form deal fit classification Sandholm (1998).classification defines four forms contract type: O-contracts, considered previoussection; -contracts, involve exactly 2 agents swapping single resources; C -contracts,one agent tranfers least two resources another; -contractsthree agents reallocate resource holding amongst themselves. definition(k )-contracts permits two agents exchange resources (thus -contractsSandholms (1998) scheme) deals permitted restricted O, , C contracts. one regard, however, (k )-contracts general -contracts sincepreset bound (k ) specified number agents involved.main result (k )-contract paths following development Theorem 3.Theorem 6 Let k (P , Q) predicateholds whenever hP , Qi IR (k )kcontract. k 3, n k, resource allocation setting2hA, R, Ui IR deal = hP , Qi which,Lopt (, hA, R, Ui, k )Lopt (, hA, R, Ui, k 1 )Lopt (, hA, R, Ui, k 2 )=6212b2m/k (k 1)c1undefined(a)(b)(c)fiExtremal Behaviour Multiagent Contract Negotiationpresenting proof, comment formulation theorem statementgive overview proof structure.first note lower bounds (where defined) phrased termsfunction Lopt opposed max used various results O-contract pathsSection 2.2. is, course, case bound claimed Lopt (, hA, R, Ui, k 1 )also lower bound max (n, m, k 1 , ) n k (P , Q) holds wheneverdeal hP , Qi IR. statement Theorem 6, however, claims rather this,namely specific resource allocation setting hA, R, Ui defined n km, together IR deal hP , Qi way that: hP , Qi achievedsingle (k )-contract cannot realised IR (k 2)-contract path. RecallingLopt partial function, latter property equivalent claim made part(c) deal hP , Qi theorem statement. Furthermore, deal althoughachievable IR (k 1)-contract path realised one whose lengthgiven part (b) theorem statement.Regarding proof itself, number notational complexitiesattempted ameliorate making simplifying assumptions concerning relationship size resource set R k number agentsneeded realise hP, Qisingle IR deal. particular, shall assumeexact multiple k2 . observe employing similar device usedproofTheorem 4 deal casesproperty:k= 2 + q integer values 1 1 q < k2 , simply employ exactlyconstruction using q resources missing q resources Rm allocated A1 never reallocated within (k 1)-contract path. approachaccounts rounding operation (b. . .c) exponent term lower bound.shall also assume number agents exactly k . Within proof userunning example k = 4 = 18 = 3 6 illustrate specific features.first give outline structure.Given hA, R, Ui resource allocation setting involving k agents resources,aim define IR (k 1)-contract path= hP (1) , P (2) , . . . , P (t)realises IR (k ) deal hP (1) , P (t) i. use index particular allocationswithin , 1 t.order simplify presentation employsetting k agents= {A0 , A1 , . . . , Ak 1 }. Recalling = k2 , resource set Rm formedunionk2pairwise disjoint sets size s. Given distinct values j{i,j }{i,j }{i,j }0 < j k 1, use Ri,j denote one subsets {r1 , r2, . . . , rs }{i,j}resources form R.two main ideas underpinning structure (k 1)-contract .Firstly, initial subsequent allocations, resource set R{i,j } partitionedAi Aj reallocation resources Ai Aj takes placewithin deal hP (d) , P (d+1) involve resources set. Thus, every al(d)location P (d) pair {i , j }, h 6 {i , j } Ph R{i,j } = . Furthermore,63fiDunne= hP (d) , P (d+1) Ai Aj involved, i.e. {Ai , Aj } , reallocation R{i,j } Ai Aj O-contract. is, either exactly one(d)(d+1)element R{i,j } moved Pi become member allocation Pj(d)exactly one element R{i,j } moved Pjbecome member allocation(d+1)Pi . Intotal, every (k 1)-contract consists simultaneous implementation1kO-contracts: single O-contract distinct pairs {Ai , Aj } agents2k 1 agents .second key idea exploit one well-known property s-dimensional hypercube network: every 2, Hs contains Hamiltonian cycle, i.e. simple directed cycleformed using edges Hs containing 2s vertices.7 Now, suppose(v ) = v (0) , v (1) , . . . , v (i) , . . . , v (21), v (0)Hamiltonian cycle hypercube Hs(w ) = w (0) , w (1) , . . . , w (i) , . . . , w (21), w (0)Hamiltonian cycle w (i) obtained complementing bit v (i) .described overview Section 2.1 interpret s-bit label v = v1 v2 . . . vs{i,j }describing particular subset R{i,j } , i.e. subset rkoccurs{i,j}vk = 1. Similarly subset Rmay define unique s-bit word. suppose(d)Pi allocation held Ai allocation P (d) . deal = hP (d) , P (d+1)(d)(d+1)affect Pi R{i,j } following way: 6 j 6 PiR{i,j } =(d)(d+1)(d)Pi R{i,j } PjR{i,j } = Pj R{i,j } . Otherwise {i , j }(d)(d)(complementary) holdings Pi R{i,j } Pj R{i,j } define (complementary) s-bitlabels vertices Hs : correspond places hv (h) , w (h) Hamiltonian cycles,(d+1)(d+1)(d+1)(d+1)PiPjs-bit labels defined PiR{i,j } PjR{i,j }produce s-bit labels v (h+1) w (h+1) , i.e. vertices succeed v (h) w (h)Hamiltonian cycles. total, j , Ai initially holds either subset R{i,j }maps v (0) maps w (0) and, conclusion (k 1)-path, holdssubset maps v (2 1) (or w (2 1) ). final detail progressionHamiltonian cycles conducted series rounds round comprising k (k 1)deals.(d)(d+1) occurs pathnoted(k1)-contract, hP , Pk 1interpreted setdistinct O-contracts. important property utility2functions employed unless p k 1 beno individuallyrational (p)1contract path realises deal hP (d) , P (d+1) i, i.e. kO-contractdeals must2occur simultaneously order progression P (d) P (d+1) IR. Althoughrequired deal could realised sequence O-contracts (or, generally,suitable (k 2)-contract path), realisations describe IR contract path.7. shown easy inductive argument. = 2, sequence h00, 01, 11, 10, 00i definesHamiltonian cycle H2 . Inductively assume h1 , 2 , . . . , p , 1 (with p = 2s ) cycleHs h01 , 11 , 1p , 1p1 , . . . , 12 , 02 . . . , 0p , 01 defines Hamiltonian cycle Hs+1 .64fiExtremal Behaviour Multiagent Contract Negotiationconstruction utility functions guarantee behaviour provides principalcomponent showing IR deal hP (1) , P (t) cannot realised IR (k 2)contract path: Q allocation hP (1) , Qi (k 2)-contracthP (1) , Qi IR.proceed proof Theorem 6.Proof. (of Theorem 6) Fix = {A0 , A1 , . . . , Ak 1 }. R consistssets resources{i,j } {i,j }R{i,j } = {r1 , r2 , . . . , rs{i,j } }k2pairwise disjointk = 4 = 3 yield = {A0 , A1 , A2 , A3 }R{0,1}R{0,2}R{0,3}R{1,2}R{1,3}R{2,3}======{0,1}{0,1}{0,1}, r2, r3}{r1{0,2} {0,2} {0,2}{r1, r2, r3}{0,3} {0,3} {0,3}{r1, r2, r3}{1,2} {1,2} {1,2}, r2, r3}{r1{1,3} {1,3} {1,3}{r1, r2, r3}{2,3} {2,3} {2,3}{r1, r2, r3}use two ordering structures defining (k 1)-contract path.a.(v ) = v (0) , v (1) , . . . , v (i) , . . . , v (21), v (0)Hamiltonian cycle Hs , without loss generality, v (0) = 111 . . . 11.b.(w ) = w (0) , w (1) , . . . , w (i) , . . . , w (21), w (0)complementary Hamiltonian cycle this, w (0) = 000 . . . 00.Thus k = 4 = 3 obtaina.b.(v ) = h111, 110, 010, 011, 001, 000, 100, 101i(w ) = h000, 001, 101, 100, 110, 111, 011, 010idescribe (k 1)-contract path.= hP (1) , P (2) , . . . , P (t)Initial Allocation: P (1) .Define k k Boolean matrix, B = [bi,j ] (with 0 , j k 1)bi,j =bj ,ibi,j 165=j>j<jfiDunne1 k ,(1)Pi=i1[{ R {j ,i} : bi,j = >}j =0k[1{ R {i,j } : bi,j = >}j =i+1Thus, example,B =>>>>>>Yielding starting allocation(1)P0(1)P1(1)P2(1)P3====R{0,1} R{0,3}R{1,2}R{0,2} R{2,3}R{1,3}====h111, 000, 111ih000, 111, 000ih111, 000, 111ih000, 111, 000iR{0,1} R{0,2} R{0,3}R{0,1} R{1,2} R{1,3}R{0,2} R{1,2} R{2,3}R{0,3} R{1,3} R{2,3}(1)third column Pi indicating 3-bit labels characterising subsetsR{i,j } three values j assume.Rounds: initial allocation changed series roundsQ 1, Q 2, . . . , Q zinvolves exactly k distinct (k 1)-contracts. use Q x ,p indicateallocation resulting stage p round x 0 p k 1. note following:a. initial allocation, P (1) denoted Q 0,k 1 .b. Q x ,0 obtained using single (k 1)-contract Q x 1,k 1 (when x 1).c. Q x ,p obtained using single (k 1)-contract Q x ,p1 (when 0 < p k 1).final item notation cube position respect j allocationP , denoted (i , j , P ). Letting u s-bit string describing Pi R{i,j } allocation(1)P , (i , j , P ) index u Hamiltonian cycle (v ) (when R{i,j } Pi )(1)Hamiltonian cycle (w ) (when R{i,j } Pj ). P = Q x ,p allocationsequence construction employ notation (i , j , x , p), noting one invariantpath (i , j , x , p) = (j , , x , p), property certainly holds true P (1) =Q 0,k 1 since (i , j , 0, k 1) = (j , , 0, k 1) = 0.sequence allocations built follows. Since Q 1,0 immediate successorinitial allocation Q 0,k 1 , suffices describe Q x ,p formed Q x ,p1 (whenp > 0) Q x +1,0 Q x ,k 1 . Let Q y,q allocation formed Q x ,p .deal = hQ x ,p , Q y,q (k 1) contract = \ {Aq }. pair{i , j } (i , j , x , p) = (j , , x , p) allocation Q x ,p . moving Q y,qexactly one element R{i,j } reallocated Ai Aj way Q y,q ,66fiExtremal Behaviour Multiagent Contract Negotiation(i , j , y, q) = (i , j , x , p)+1, since Ai Aj tracing complementary Hamiltonian cyclesrespect R{i,j } ensures (j , , y, q) = (j , , x , p) + 1, thereby maintaininginvariant property.Noting distinct pair hi , j i, either R{i,j } allocated Ai P (1)R{i,j } allocated Aj P (1) , description outlined indicates allocationP (d) = Q x ,p completely specified follows.cube position, (i , j , x , p), satisfies,(i , j , x , p) =01 + (i , j , x 1, k 1)(i , j , x 1, k 1)1 + (i , j , x , p 1)(i , j , x , p 1)x = 0 p = k 1x 1, p = 0, p 6 {i , j }x 1, p = 0, p {i , j }1 p k 1, p 6 {i , j }1 p k 1, p {i , j }, subset R{i,j } held Ai allocation Q x ,p is,v ((i,j ,x ,p))w ((i,j ,x ,p))(1)R{i,j } Pi(1)R{i,j } Pj(where recall s-bit labels hypercube Hs identified subsetsR{i,j } .)tables illustrates process example.123456789...x011112222...p301230123...j01111111111110010010010011001A0j j02 03000 111000 111001 110001 010101 010101 011100 001100 001110 001...Subsetsj10000000000001101101101100110A1j12111110110110010011011011001...j13000001001101101100100110110j20111111110110010010011011001R{i,j } held Ai67A2j j21 23000 111001 110001 010001 010101 010100 011100 001100 001110 001...Q x ,p (kj30000000001101101101100110110= 4,A3(d1),P (d)j j AhP31 32111 000110 001 {A1 , A2 , A3 }110 101 {A0 , A2 , A3 }010 101 {A0 , A1 , A3 }010 101 {A0 , A1 , A2 }011 100 {A1 , A2 , A3 }011 110 {A0 , A2 , A3 }001 110 {A0 , A1 , A3 }001 110 {A0 , A1 , A2 }......= 3)fiDunne123456789...x011112222...p301230123...A0A1A2A3(d1) ,P (d)j j j j j j j j j j j j AhP01 02 03 10 12 13 20 21 23 30 31 32000000000000000011011011 {A1 , A2 , A3 }011011112112 {A0 , A2 , A3 }112112112222 {A0 , A1 , A3 }222222222222 {A0 , A1 , A2 }222233233233 {A1 , A2 , A3 }233233334334 {A0 , A2 , A3 }334334334444 {A0 , A1 , A3 }444444444444 {A0 , A1 , A2 }...............Cube Positions (i , j , x , p) (k = 4, = 3)certainly case process applying successive rounds k deals couldcontinued, however, wish long possible goallocation P (d) sequence another P (d+r ) r 2 via (k 1)-contract.Q x ,p Q y,q distinct allocations generated processdeal = hQ x ,p , Q y,q (k 1)-contract Ai , Qix ,p = Qiy,q .follows hP (d) , P (d+r ) (k 1)-contract r > 1,(d+r )(d)j 6= , PiR{i,j } = Pi R{i,j } .(d+r )(d)determine minimum value r > 1 Pi= Pi , observewithout loss generality need consider case = = 0, i.e. determine(1)minimum number deals P0 reappears. First note round, Q x ,(0, j , x 1, k 1) = p (0, j , x , k 1) = p + k 2, i.e. round advances cubeposition k 2 places: (0, j , x 1, k 1) = (0, j , x , 0) (0, j , x , j ) = (0, j , x , j 1).(1)also observe P0 = Q00,k 1 6= Q0x ,p p 0 < p < k 1, since(0, 1, x , p) = (0, 2, x , p) = . . . = (0, k 1, x , p)cases p = 0 p = k 1. follows value r > 1 must formqk q must q(k 2) exact multiple 2s . observationsee that,(1)min{ r > 1 : P0(1+r )= P0} = min{ qk : q(k 2) multiple 2s }Now, k odd q = 2s minimal value, r = k 2s . k evenmay uniquely written form z 2l + 2 z odd giving q 1 (if l s)2sl (if l s), give r = k r = z 2s + 2sl+1 , e.g. k = 4 = 3,(1)(17)get k = 1 21 + 2 r = 23 + 231+1 = 16 example P0 = P0 mayeasily verified. total,rk2k2sk oddk = z 2l + 2, z odd, lk = z 2l + 2, z odd l68fiExtremal Behaviour Multiagent Contract Negotiationimmediately give r 2s (in second case k 2s , inequality holdstrivially), thuscontinue chain (k 1) contracts least 2 moves.Recalling = k2 , gives length (k 1)-contract path= hP (1) , P (2) , . . . , P (t)written terms k least8m/2k22m1 = 2 k (k 1) 1remains define appropriate utility functions U = hu0 , . . . , uk 1 order ensureunique IR (k 1)-contract path realising IR (k )-deal hP (1) , P (t) i.defining U convenient denote path= hQ 0,k 1 , Q 1,0 , Q 1,1 , . . . , Q 1,k 1 , . . . , Q x ,p , . . . , Q r ,k 1and, since rk 2s , may without loss generality, focus first 2s allocationscontract path.Recalling (i , j , x , p) index s-bit label u corresponding Qix ,p R{i,j }relevant Hamiltonian cycle i.e. (v ) R{i,j } Qi0,k , (w ) R{i,j } Qj0,k 1note following properties sequence allocations defined holddistinct j .P1. x , p (i , j , x , p) = (j , , x , p)P2. Q y,q immediate successor Q x ,p (i , j , y, q) (i , j , x , p) + 1equality q 6 {i , j }.P3. 0 , j 0 0 0 , j 0 k 1, (i , j , x , k 1) = (i 0 , j 0 , x , k 1).first two properties already established description . thirdfollows observation within round Q x , cube position advancedexactly k 2 progressing Q x 1,0 Q x ,k 1 .utility function ui given, Rm ,( Pj 6=i2kmui (S ) =(i , j , x , p)= Qix ,p 0 x r , 0 p k 1otherwiseclaim that, choices,= hQ 0,k 1 , Q 1,0 , Q 1,1 , . . . , Q 1,k 1 , . . . , Q x ,p , . . . , Q r ,k 1unique IR (k 1)-contract path realising IR (k )-deal hQ 0,k 1 , Q r ,k 1 i. Certainly, IR (k 1)-contract path: deal = hQ x ,p , Q y,q path|A | = k 1 since agent Ai = \ {Aq } utility Qiy,q increased8. omitoperation b. . .c exponent, significant exactroundingmultiplek2, event device described overview proof applied.69fiDunneexactly k 2, i.e. cube position respect j whenever q 6 {i , j }increased, follows u (Q y,q ) > u (Q x ,p ) hence hQ x ,p , Q y,q IR.show unique IR (k 1)-contract path continuation Q 0,k 1Suppose = hQ x ,p , P deal deviates contract path (having followedallocation Q x ,p ). Certainly following must hold P :, Pi j 6=i R{i,j } ; k -tuple pairs h(x0 , p0 ), . . . , (xk 1 , pk 1 )iPi = Qixi ,pi , either fail case , ui (Pi ) = 2kmconsequent effect u (P ) < 0 thence IR. Now, Q y,q allocationwould succeed Q x ,p P 6= Q y,q , thus least one agent, Qixi ,pi 6= Qiy,q .cannot case Qixi ,pi corresponds allocation occurring strictly laterQiy,q since allocations could realised (k 1)-contract. addition,since Pi = Qixi ,pi must case |A | = k 1 since exactly k 1 cube positionsholding Ai must change. follows two possibilities (yi , pi ):Pi reverts allocation immediately preceding Qix ,p advances holding Qiy,q .suffices observe deal agents satisfy firstremainder proceed accordance second either give rise validallocation cannot realised (k 1)-contract. hand P correspondsallocation preceding Q x ,p IR. deduce, therefore, IR(k 1) deal consistent Q x ,p prescribed Q y,q .completes analysis needed proof part (b) theorem.clear since system contains k agents, deal hP , Qi effectedsingle (k )-contract, thereby establishing part (a). part (c) IR dealhP (1) , P (t) cannot realised using individually rational (k 2)-contract path,suffices observe since class IR (k 2)-contracts subset classIR (k 1)-contracts, case IR (k 2)-contract path existedimplement hP (1) , P (t) i, would imply unique IR (k 1)-contractpath. have, however, proved unique, part (c) theorem follows. 2obtain similar development Corollary 1Corollary 3 k 3, n k ,k2cases below,a. k () holds cooperatively rational (k )-contract.() holds cooperatively rational.b. k () holds equitable (k )-contract.() holds equitable.resource allocation setting hA, R, Ui -deal = hP , QiLopt (, hA, R, Ui, k )Lopt (, hA, R, Ui, k 1 )Lopt (, hA, R, Ui, k 2 )=12b2m/k (k 1)c 1undefined(a)(b)(c)Proof. proof Corollary 1 relation Theorem 3, case employcontract path proof Theorem 6, varying definition U = hu1 , u2 , . . . , ukorder establish result. Thus let==hP (1) , P (2) , . . . , P (r ) , . . . , P (t)hQ 0,k 1 , Q 1,0 , . . . , Q x ,p , . . . , Q z ,r70fiExtremal Behaviour Multiagent Contract Negotiation(k 1)-contract path realising (k )-deal hP (1) , P (t) described proofTheorem 6, path length 2b2m/k (k 1) 1.a. utility functions U = hu0 , . . . , uk 1 Theorem 6 ensure hP (1) , P (t)cooperatively rational cooperatively rational (k 1)-contractpath realising hP (1) , P (t) i: utility held Ai never decreases valueleast one agent (in fact exactly k 1) whose utility increases value. Furthermoreunique cooperatively rational (k 1)-contract path realising hP (1) , P (t)since, argument used Theorem 6, deviation resultagent suffering loss utility.b. Set utility functions U = hu0 , . . . , uk 1 as,ui (S ) =1xk 2 + k2(x 1)k + k + p(x 1)k 2 + k + p + 1xk 2 + 1xk 2 + 1 + p6= Qix ,p Q x ,p= Qix ,k 1= Q0x ,p , p < k 1 = 0= Qix ,p , p < 1 6= 0.= Qix ,i1 = Qix ,i 6= 0.= Qix ,p , p > 6= 0see choices admit equitable (k 1)-contract path realisingequitable deal hQ 0,k 1 , Q z ,r i, first notemin0ik 1{ui (Qiz ,r )} > 1 =min0ik 1{ui (Qi0,k 1 )}thus, hQ 0,k 1 , Q z ,r indeed equitable. Consider deal = hQ x ,p , Q y,q occurringwithin . suffices showmin0ik 1{ui (Qix ,p )} 6= uq (Qqx ,p )since Aq 6 , agents ui (Qiy,q ) > ui (Qix ,p ). two possibilities:q = 0 (in case p = k 1 = x + 1); q > 0 (in case p = q 1).Consider first these: u0 (Q0x ,k 1 ) = xk 2 + k , however,,k 1)min{ui (Qix ,k 1 )} = xk 2 + 1 = uk 1 (Qkx1hence every deal hQ x ,k 1 , Q x +1,0 forming part equitable.remaining case, uq (Qqx ,q1 ) = xk 2 + 1min{ui (Qix ,q1 )}=<=<=u0 (Q0x ,q1 )(x 1)k 2 + k + q 1xk 2 (k 2 2k + 1)xk 2 (k 1)2xk 2 + 1uq (Qqx ,q1 )thus remaining deals hQ x ,q1 , Q x ,q within equitable. similarargument employed Theorem 6 follows unique equitable(k 1)-contract path realising hQ 0,k 1 , Q z ,r i.271fiDunneMonotone Utility Functions (k )-contract pathsdevice used develop Theorem 3 obtain path Theorem 4 appliedrather intricate construction Theorem 6, thereby allowing exponential lowerbounds maxmono (n, m, k , ) derived. merely outline approach ratherpresent detailed technical exposition. recall became relatively straightforwarddefine suitable monotone utility functions ensured subset sizesinterest i.e. allocations arising O-contract path forced fallquite restricted range. main difficulty arises applying similar methodspath Theorem 6 following: proof Theorem 4 consider two agentsconverting setting resources Theorem 3 ext(s ) 2sresources Theorem 4 achieved combining complementary allocations, i.e. RsTs . exploit two facts, however, develop path multi ()monotoneutility functions could defined: resource set Rm Theorem 6 consistskdisjoint sets size s; deal path involves reallocation R{i,j }2Ai Aj {i , j } . Thus letting Tm formed{i,j } size s, suppose(d)(d)Pi(d)k2disjoint sets,described(d)(d)(d)i,0 i,1 i,i1 i,i+1 i,k 1(d)i,j s-bit label corresponding subset R {i,j } held Ai P (d) .Consider sequence allocations,multi () = hC (1) , C (2) , . . . , C (t)(d)resource allocation setting k agents 2m resources Rm Tm Cicharacterised(d) (d)(d)(d)(d)i,0 i,1 i,i1 i,i+1 i,k 1(d)this, i,j , indicates subset R{i,j } {i,j } described 2s-bit label,(d)i,j(d)(d)(d)= i,j i,j(d)i.e. i,j selects subset R{i,j } i,j subset {i,j } .immediate construction allocation C (d) multi ()(d)Ai , always case |Ci | = (k 1)s. follows, therefore, subsetsrelevant definition monotone utility functions analogousresult Theorem 6 path multi () could derived, size (k 1)s:Rm Tm |S | < (k 1)s, fix ui (S ) small enough negative value; similarly|S | > (k 1)s ui (S ) set large enough positive value.9description preceding paragraphs, summarised following result, whose proof omitted: extending outline given formal lower bound9. worth noting interpolation stage used Theorem 4 needed forming multi():deal hC (d) , C (d+1) (k 1)-contract. recall going Theorem 3 ext(s )intermediate stage double(s ) O-contract path.72fiExtremal Behaviour Multiagent Contract Negotiationproof, largely technical exercise employing much analysis already introduced,since nothing signifcantly new required analysis shall give detailedpresentation it.Theorem 7 Let k (P , Q) predicateholds whenever hP , Qi IR (k )contract. k 3, n k 2 k2 , resource allocation settinghA, R, Ui every u U monotone, IR deal = hP , Qi which,Lopt (, hA, R, Ui, k )Lopt (, hA, R, Ui, k 1 )Lopt (, hA, R, Ui, k 2 )=12bm/k (k 1)c1undefined(a)(b)(c)4. Related Workprincipal focus article considered property contract paths realising rational reallocations hP , Qi constituent deals required conform structuralrestriction satisfy rationality constraint. Section 2 structural restriction limiteddeals involving single resource, i.e. O-contracts. rationality constraintforcing deals strictly improve utilitarian social welfare, i.e. individually rational(IR) following properties.a. resource allocation settings hA, R, Ui within IR reallocationshP , Qi cannot realised sequence IR O-contracts. (Sandholm, 1998,Proposition 2)b. Every IR reallocation, hP , Qi, realised IR O-contract path,realised IR O-contract path length n (n 1)m. (Sandholm, 1998,Proposition 2)c. Given hA, R, Ui together IR reallocation hP , Qi problem decidinghP , Qi implemented IR O-contract path nphard, even |A| = 2utility functions monotone. (Dunne et al., 2003, Theorem 11).d. resource allocation settings hA, R, Ui within IR reallocationshP , Qi realised IR O-contract path, pathlength exponential m. holds even case |A| = 2 utility functionsmonotone. (Theorem 3 Theorem 4 Section 2)recent article Endriss Maudet (2004a) analyse contract path length also consideringO-contracts various rationality constraints. Although approach ratherdifferent perspective, central question addressed many rational deals requiredreach optimal allocation?, (Endriss & Maudet, 2004a, Table 1, p. 629) closelyrelated issues discussed above. One significant difference analysis rational Ocontracts Sandholms (1998) treatment results Section 2 (Endriss& Maudet, 2004a) utility functions restricted every rational reallocationhP , Qi realised rational O-contract path. two main restrictions examinedPrequiring utility functions additive, i.e. every R, u(S ) = r u(r );73fiDunneand, requiring value returned either 0 1, so-called 0 1 utility functions.Additive utility functions considered case IR O-contracts (Endriss & Maudet,2004a, Theorems 3, 9), whereas 01 utility functions cooperatively rational O-contractsmax(Endriss & Maudet, 2004a, Theorems 4, 11). Using maxadd (n, m, , ) 01 (n, m, , )denote functions introduced Definition 6 utility functions additive(respectively 01), cf. definition maxmono , 1 (P , Q) holding hP , Qi IRO-contract; 2 (P , Q) holding hP , Qi cooperatively rational O-contract (P , Q)true hP , Qi IR, may formulate Theorems 9 11 (Endriss & Maudet, 2004a)terms framework used Definition 6,maxadd (n, m, 1 , )max01 (n, m, 2 , )==(Endriss & Maudet, 2004a, Theorem 9)(Endriss & Maudet, 2004a, Theorem 11)can, course, equally couch Theorems 3 4 Section 2 terms shortestpath convention adopted (Endriss & Maudet, 2004a), provided domainsutility reallocation instances restricted appropriate O-contractpath exists. Thus, obtain following development (Endriss & Maudet, 2004a,Table 1) case O-contracts.Utility FunctionsRationalityShortest PathCompleteAdditiveIRYes0-1CRYesUnrestrictedIR(2m )MonotoneIR(2m/2 )UnrestrictedCR(2m )MonotoneCR(2m/2 )Table 2: many O-contract rational deals required reach allocation?Extension Table 1 (Endriss & Maudet, 2004a, p. 629)5. Conclusions Workaim article develop earlier studies Sandholm (1998) concerningscope limits particular practical contract forms. Sandholm (1998)established insisting individual rationality addition structural restrictionprescribed O-contracts leads scenarios incomplete (in senseindividually rational deals cannot realised individually rational O-contracts)focus respect deals realised restricted contract paths,intention determining extent combination structural rationality conditions increases number deals required. shown that, using numbernatural definitions rationality, settings involving resources, rational O-contractpaths length (2m ) needed, whereas without rationality restriction individualdeals, O-contracts suffice realise deal. also considered classdeals (k )-contracts examined (Sandholm, 1998), establishingcases that, particular rationality conditions imposed, (k 1)-contract2paths length (22m/k ) needed realise deal achieved single(k )-contract.note analyses primarily focused worst-case lower boundspath length appropriate paths exist, several questions74fiExtremal Behaviour Multiagent Contract Negotiationpractical interest merit discussion. may noted path structuresassociated utility functions rather artificial, directed attaining pathspecific length meeting given rationality criterion. seen, however, Theorems 45 outlined discussion concluding Section 3 issue exponential lengthcontract paths continues arise even require utility functions satisfymonotonicity condition. identify two classes open question ariseresults.Firstly, focusing IR O-contract paths, would interest identify naturalrestrictions utility functions would ensure that, deal hP , Qi implementedIR O-contract path, realised one whose length polynomiallybounded m, e.g. additivity mentioned preceding section. interpretTheorem 4, indicating monotonicity guarantee short IR contract paths.note, however, restrictions suffice. use rather trivialexample, number distinct values u assume pconstant p IR O-contract path length exceeding p : successive dealsmust strictly increase u take K different values IR contractpath length exceeding K . well practical interest, classes utilityfunction property considered would also interest regarding onecomplexity issue. result proved (Dunne et al., 2003) establishing decidingIR O-contract path exists np-hard, gives lower bound computational complexityproblem. present, (non-trivial) upper bound problems complexitydemonstrated. results Theorems 3 4 indicate decisionproblem np (thus complexity would npcomplete rather nphard)required polynomial length existence certificate may somethingpath itself.10 note proof nphardness (Dunne et al., 2003) constructsinstance u take O(m) distinct values: thus, examplerestriction ensuring present IR O-contract paths short,result (Dunne et al., 2003) indicates question deciding existence mightremain computationally hard.Considering restrictions form utility functions one approach couldtaken regarding finding tractable cases. alternative would gain insightaverage path length likely be. attempting address question,however, number challenging issues arise. immediate concerns,course, notion modeling distribution utility function given definitionsrationality terms value agents attach resource holdings. principleaverage-case analysis scenarios involving exactly two agents could carriedpurely graph-theoretic terms, i.e. without complication considering utility functionsdirectly. unclear, however, whether graph-theoretic analysis obviating needconsideration literal utility functions, extended beyond settings involvingexactly two agents. One difficulty arising three agents utility10. use may rather must needed convention representing utility functionsemployed (Dunne et al., 2003).75fiDunnefunctions allocative externalities, i.e. given allocation hX , , Z three agents,u1 (X ) unchanged Z redistributed among A2 A3 .11one final set issues may merit study raise following.constructions, individual deals contract path must satisfy structuralcondition (be O-contract involve k agents), rationality constraint.Focusing O-contracts following extremes: (Sandholm, 1998),O-contracts suffice realise rational deal; results above, (2m ) rationalO-contracts needed realise rational deals. number mechanismsemploy relax condition every single deal O-contractrational. example, allow path contain number deals Ocontracts (but must still IR) insist deals O-contracts allowirrational. Thus, latter case, go extent allowing irrationalO-contracts, rational deal realised efficiently. would interestexamine issues effect allowing constant number, t, irrational dealsquestions whether situations irrational contracts yieldshort contract path 1 force one exponential length. particular interest,application viewpoint, following: define ((m), O)-path O-contractpath containing (m) O-contracts individually rational. know(m) = 0 individually rational (0, O)-paths complete respectindividually rational deals; similarly (m) = (m, O)-paths completerespect individually rational deals. question interest would establish(m) = o(m) ((m), O)-paths complete respectindividually rational deals maximum length contract path boundedpolynomial function m.Acknowledgementsauthor thanks reviewers earlier version article valuable comments suggestions contributed significantly content organisation.work reported article carried support EPSRC GrantGR/R60836/01.ReferencesAbbott, H. L., & Katchalski, M. (1991). construction snake box codes.Utilitas Mathematica, 40, 97116.Atkinson, A. (1970). measurement inequality. Jnl. Econ. Theory, 2, 244263.Chateauneaf, A., Gajdos, T., & Wilthien, P.-H. (2002). principle strong diminishingtransfer. Jnl. Econ. Theory, 103, 311333.11. preliminary investigation complexity-theoretic questions arising settings allocativeexternalities presented (Dunne, 2004) referred contextdependent:utility functions appear neglected computational algorithmic analysis resourceallocation problems, although idea well-known game-theoretic models economicsterm allocative externality originates.76fiExtremal Behaviour Multiagent Contract NegotiationDignum, F., & Greaves, M. (2000). Issues Agent Communication, Vol. 1916 LNCS.Springer-Verlag.Dunne, P. (2003). Prevarication dispute protocols. Proc. Ninth International Conf.A.I. Law (ICAIL03), pp. 1221, Edinburgh. ACM Press.Dunne, P. (2004). Context dependence multiagent resource allocation. Proc. ECAI04,pp. 100001, Valencia.Dunne, P., & McBurney, P. (2003). Optimal utterances dialogue protocols. Proc. Second International Joint Conf. Autonomous Agents Multiagent Systems (AAMAS03), pp. 608615. ACM Press.Dunne, P., Wooldridge, M., & Laurence, M. (2003). complexity contract negotiation.Tech. rep. ULCS-03-002, Dept. Computer Science, Univ. Liverpool. (to appearArtificial Intelligence).Endriss, U., & Maudet, N. (2004a). communication complexity multilateral trading. Proc. Third International Joint Conf. Autonomous Agents MultiagentSystems (AAMAS04), pp. 622629.Endriss, U., & Maudet, N. (2004b). Welfare engineering multiagent systems. Omicini,A., Petta, P., & Pitt, J. (Eds.), Proc. Fourth International Workshop EngineeringSocieties Agents World (ESAW-2003), Vol. 3071 LNAI, pp. 93106. SpringerVerlag.Endriss, U., Maudet, N., Sadri, F., & Toni, F. (2003). optimal outcomes negotiationsresources. Proc. Second International Joint Conf. Autonomous AgentsMultiagent Systems (AAMAS03), pp. 177184. ACM Press.Kautz, W. H. (1958). Unit distance error checking codes. IRE Trans. Electronic Computers, 7, 179180.Kolm, S.-C. (1976). Unequal inequalities. Jnl. Econ. Theory, 13, 82111.Kraus, S. (2001). Strategic negotiation multiagent environments. MIT Press.McBurney, P., Parsons, S., & Wooldridge, M. (2002). Desiderata argumentation protocols. Proc. First International. Joint Conf. Autonomous Agents MultiagentSystems (AAMAS02), pp. 402409. ACM Press.Parkes, D. C., & Ungar, L. H. (2000a). Iterative combinatorial auctions: theory practice.Proc. 17th National Conf. Artificial Intelligence (AAAI-00), pp. 7481.Parkes, D. C., & Ungar, L. H. (2000b). Preventing strategic manipulation iterativeauctions: proxy agents price adjustment. Proc. 17th National Conf. ArtificialIntelligence (AAAI-00), pp. 8289.Rosenschein, J. S., & Zlotkin, G. (1994). Rules Encounter. MIT Press.Sandholm, T. W. (1998). Contract types satisficing task allocation: theoretical results.AAAI Spring Symposium: Satisficing Models.Sandholm, T. W. (1999). Distributed rational decision making. Wei, G. (Ed.), Multiagent Systems, pp. 201258. MIT Press.77fiDunneSandholm, T. W. (2002). Algorithm optimal winner determination combinatorialauctions. Artificial Intelligence, 135, 154.Sandholm, T. W., & Suri, S. (2003). Bob: Improved winner determination combinatorialauctions generalizations. Artificial Intelligence, 145, 3358.Sandholm, T. W., Suri, S., Gilpin, A., & Levine, D. (2001). Cabob: fast optimal algorithmcombinatorial auctions.. Proc. IJCAI-01, pp. 11021108.Smith, R. G. (1980). contract net protocol: high-level communication controldistributed problem solver. IEEE Trans. Computers, C-29 (12), 11041113.Tennenholz, M. (2000). tractable combinatorial auctions. Proc. 17th NationalConf. Artificial Intelligence (AAAI-00).Yokoo, M., Sakurai, Y., & Matsubara, S. (2004). effect false-name bids combinatorial auctions: new fraud internet auctions. Games Economic Behavior,46 (1), 174188.78fi